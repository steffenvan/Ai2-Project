<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000080">
<title confidence="0.985325">
On the Use of Virtual Evidence in Conditional Random Fields
</title>
<author confidence="0.992045">
Xiao Li
</author>
<affiliation confidence="0.960348">
Microsoft Research
</affiliation>
<address confidence="0.9262795">
One Microsoft Way
Redmond, WA 98052 USA
</address>
<email confidence="0.998416">
xiaol@microsoft.com
</email>
<sectionHeader confidence="0.997377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999927368421053">
Virtual evidence (VE), first introduced
by (Pearl, 1988), provides a convenient
way of incorporating prior knowledge into
Bayesian networks. This work general-
izes the use of VE to undirected graph-
ical models and, in particular, to condi-
tional random fields (CRFs). We show
that VE can be naturally encoded into a
CRF model as potential functions. More
importantly, we propose a novel semi-
supervised machine learning objective for
estimating a CRF model integrated with
VE. The objective can be optimized us-
ing the Expectation-Maximization algo-
rithm while maintaining the discriminative
nature of CRFs. When evaluated on the
CLASSIFIEDS data, our approach signif-
icantly outperforms the best known solu-
tions reported on this task.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999937660377359">
Statistical approaches to sequential labeling prob-
lems rely on necessary training data to model the
uncertainty of a sequence of events. Human’s
prior knowledge about the task, on the other hand,
often requires minimum cognitive load to spec-
ify, and yet can provide information often com-
plementary to that offered by a limited amount of
training data. Whenever prior knowledge becomes
available, it is desired that such information is in-
tegrated to a probabilistic model to improve learn-
ing.
Virtual evidence (VE), first introduced by Pearl
(1988), offers a principled and convenient way of
incorporating external knowledge into Bayesian
networks. In contrast to standard evidence (also
known as observed variables), VE expresses a
prior belief over values of random variables. It
has been shown that VE can significantly extend
the modeling power of Bayesian networks without
complicating the fundamental inference method-
ology (Bilmes, 2004; Reynolds and Bilmes,
2005).
This work extends the use of VE to undi-
rected graphical models and, in particular, to con-
ditional random fields (CRFs). We show that
VE can be naturally encoded into an undirected
graphical model as potential functions. More im-
portantly, we discuss a semi-supervised machine
learning setting for estimating CRFs with the pres-
ence of VE. As the conditional likelihood objec-
tive of CRFs is not directly maximizable with re-
spect to unlabeled data, we propose a novel semi-
supervised learning objective that can be opti-
mized using the Expectation-Maximization (EM)
algorithm while maintaining the discriminative
nature of CRFs.
We apply our model to the CLASSIFIEDS data
(Grenager et al., 2005). Specifically, we use VE to
incorporate into a CRF model two types of prior
knowledge specified in previous works. The first
is defined based on the notion of prototypes, i.e.,
example words for a given label; and the other as-
sumes that adjacent tokens tend to have the same
label. When unlabeled data becomes available,
we further extend the sparse prototype informa-
tion to other words based on distributional similar-
ity. This results in so-called collocation lists, each
consisting of a relatively large number of noisy
“prototypes” for a label. Given the fact that these
noisy prototypes are often located close to each
other in an input sequence, we create a new type
of VE based on word collocation to reduce ambi-
guity.
</bodyText>
<page confidence="0.955499">
1289
</page>
<note confidence="0.9965825">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1289–1297,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999904">
We compare our CRF model integrated with VE
with two state-of-the-art models, i.e., constraint-
driven learning (Chang et al., 2007) and gener-
alized expectation criteria (Mann and McCallum,
2008). Experiments show that our approach leads
to sequential labeling accuracies superior to the
best results reported on this task in both supervised
and semi-supervised learning.
</bodyText>
<sectionHeader confidence="0.999909" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99994175">
There have been various works that make use
of prior knowledge in sequential labeling tasks.
Grenager et al. (2005) explicitly constrain the
transition matrix of a hidden Markov model
(HMM) to favor self transitions, assuming that
fields tend to consist of consecutive runs of the
same label.
Prototype-drive learning (Haghighi and Klein,
2006) specifies prior knowledge by providing a
few prototypes (i.e., canonical example words) for
each label. This sparse prototype information is
then propagated to other words based on distri-
butional similarity. The relation between words
and their prototypes are then used as features in
a Markov random field (MRF) model. Since an
MRF model aims to optimize the joint probability
p(x, y) of input and state sequences, it is possible
to apply the EM algorithm for unsupervised/semi-
supervised learning.
Constraint-driven learning (Chang et al., 2007)
expresses several kinds of constraints in a unified
form. In inference, a new decision function is pro-
posed to penalize the violation of the desired con-
straints as follows,
</bodyText>
<equation confidence="0.986594">
argmax λ · F(x, y) − � ρkd(y, 1Ck (x)) (1)
Y k
</equation>
<bodyText confidence="0.99945295">
Here λ · F(x, y) is a linear decision function ap-
plicable to a number of sequential models, such
as HMMs, MRFs and CRFs. Function d is imple-
mented as the Hamming distance (or its approx-
imation) between a hypothesis sequence and the
space of state sequences that satisfy the constraint
Ci. Due to the nature of the distance function,
their work approximates EM training by finding
the top K hypothesis sequences and using them as
newly labeled instances to update the model. This
process is repeated for a number of iterations in a
self-training fashion (Yarowsky, 1995).
Generalized expectation criteria (Mann and
McCallum, 2008) represent prior knowledge as la-
beled features, and use such information to reg-
ularize semi-supervised learning for CRFs. For-
mally, their learning objective consists of the stan-
dard CRF training objective, plus a Gaussian prior
on model parameters and an additional regulariza-
tion term:1
</bodyText>
<equation confidence="0.998737">
� log pλ(y(i)|x(i))−1
i 2σ2 kλk2−ρD(ˆp||˜pλ) (2)
</equation>
<bodyText confidence="0.999210545454545">
In the last term, pˆ and ˜pλ both refer to conditional
distributions of labels given a feature. While the
former is specified by prior knowledge, and the
latter is estimated from unlabeled data.
Our approach incorporates prior knowledge as
virtual evidence to express preferences over the
values of a set of random variables. The no-
tion of VE was first introduced by Pearl (1998)
and further developed by Bilmes (2004), both in
the context of Bayesian networks. Different from
constraint-driven learning, VE can be formally en-
coded as part of a graphical model. The funda-
mental inference methodology, therefore, does not
need to be altered. Moreover, VE has the flexibil-
ity of representing various kinds of prior knowl-
edge. For example, Reynolds and Bilmes (2005)
use VE that explicitly favors self transitions in dy-
namic Bayesian networks.
This work extends the use of VE to CRFs. In
essence, VE herein can be viewed as probabilistic
constraints in an undirected graph that allow exact
inference. One of the biggest challenges of such a
model lies in the semi-supervised machine learn-
ing setting. Since the entire state sequence of an
unlabeled instance remains hidden, the conditional
likelihood objective of CRFs is not directly opti-
mizable. There have been a number of works that
address this problem for conditional models. For
example, minimum entropy regularization (Grand-
valet and Bengio, 2004; Jiao et al., 2006), aims
to maximize the conditional likelihood of labeled
data while minimizing the conditional entropy of
unlabeled data:
</bodyText>
<equation confidence="0.988434">
log pλ(y(i)|x(i))− 1
2σ2 kλk2 −ρH(y|x) (3)
</equation>
<bodyText confidence="0.999661">
This approach generally would result in “sharper”
models which can be data-sensitive in practice.
Another approach (Suzuki and Isozaki, 2008)
embeds a joint probability model (HMM in their
</bodyText>
<footnote confidence="0.9599655">
1We slightly modify the notation here to be consistent
with the rest of the paper.
</footnote>
<equation confidence="0.413874">
�
i
</equation>
<page confidence="0.90486">
1290
</page>
<bodyText confidence="0.9975866">
case) into a CRF model as a new potential func-
tion. Semi-supervised learning is then conducted
by iteratively (1) fixing the HMM and updating
CRF parameters on labeled data and (2) fixing the
CRF model and updating the HMM on unlabeled
data.
Additionally, when unlabeled instances have
partial labeling information, it is possible to op-
timize a marginal distribution of the conditional
likelihood, i.e., pλ(y(i)
</bodyText>
<listItem confidence="0.910304833333333">
o |x), on unlabeled data.
Here y(i)
o is a subvector of y(i) that denotes the set
of observed state variables. The optimization can
be done in a similar fashion as training a hidden-
state CRF model (Quattoni et al., 2007).
</listItem>
<sectionHeader confidence="0.996927" genericHeader="method">
3 Task
</sectionHeader>
<bodyText confidence="0.983390647058823">
We consider the problem of extracting fields from
free-text advertisements. We use the CLASSI-
FIEDS data (Grenager et al., 2005) which consists
of 8767 ads for apartment rental. 302 of the ads
in the CLASSIFIEDS data have been manually-
labeled with 12 fields, including size, rent, neigh-
borhood and so on. The labeled data has been di-
vided into train/dev/test sets with 102/100/100 ads
respectively. The evaluation metric is the token-
level accuracy where tokens include both words
and punctuations.
Our goal in this work is two folds: (1) lever-
age both the training data and the prior knowledge
specified for this task for supervised learning, and
(2) additionally use the unlabeled data for semi-
supervised learning. We exploit two types of prior
knowledge:
</bodyText>
<listItem confidence="0.995158">
• K1: label consistency with prototypes;
</listItem>
<sectionHeader confidence="0.955599" genericHeader="method">
4 Conditional Random Fields
</sectionHeader>
<bodyText confidence="0.9916325">
Conditional random fields are a probabilistic
model that directly optimizes the conditional prob-
ability of a state (label) sequence given an input
sequence (Lafferty et al., 2001). Formally, we let
x = (x1, x2, ... , xT) denote an input sequence
of T tokens, and y = (y1, y2, ... , yT) the cor-
responding state sequence. We further augment
y with two special states, Start and End,2 repre-
sented by y0 and yT+1 respectively. A linear-chain
CRF model is an undirected graphical model as
depicted in Figure 1(a), with the conditional prob-
ability given by
</bodyText>
<equation confidence="0.9998165">
1 pλ(y|x) = Zλ(x)
Hψjt)(x,yt−1,yt) (4) t
</equation>
<bodyText confidence="0.990312">
The partition function Zλ(x) normalizes the expo-
nential form to be a probability distribution. ψ(t)
λ
are a set of potential functions defined on the max-
imum cliques of the graph, i.e., (x, yt−1, yt) in the
case of a linear-chain CRF model. The potential
functions are typically in the form of
</bodyText>
<equation confidence="0.974345">
ψjt) (x, yt−1, yt) = exp ( λ · f(x, yt−1, yt, t)
</equation>
<bodyText confidence="0.987819777777778">
(5)
where λ is a weight vector and f is a feature vector
of arbitrary functions of the corresponding clique.
Given a set of labeled examples
{x(i),y(i))lmi=1, we can estimate model pa-
rameters in a supervised machine learning setting.
The objective is to estimate λ that maximizes
the conditional likelihood while regularizing the
model size:
</bodyText>
<listItem confidence="0.721742">
• K2: label consistency within a sentence. L1 = m log pλ(y(i)|x(i)) − 1
</listItem>
<equation confidence="0.986358">
i=1 2σ2 Jλ112 (6)
</equation>
<bodyText confidence="0.999663941176471">
K1 involves a set of prototype lists. Each list is
attached with a label and consists of a set of ex-
ample words for that label. In this work, we use
the prototype lists originally defined by Haghighi
and Klein (2006) (HK06) and subsequently used
by Chang et al. (2005) (CRR07) and Mann and
McCallum (2008) (MM08). The labels as well as
their prototypes are shown in the first two columns
of Table 1. Our model is desired to be consistent
with such prototype information. Secondly, K2
means that tokens tend to have consistent labels
within a sentence. A similar type of prior knowl-
edge is implemented by CRR07 as a constraint in
inference.
In this work, we optimize L1 using stochastic gra-
dient descent and use the accuracy on the develop-
ment set as the stopping criterion.
</bodyText>
<sectionHeader confidence="0.930992" genericHeader="method">
5 CRFs with Virtual Evidence
</sectionHeader>
<bodyText confidence="0.9995015">
A canonical way of using virtual evidence (VE)
in Bayesian networks is to have a directed edge
from a hidden variable h to a VE variable v. The
variable v will always be observed with a partic-
ular value, e.g., v = 1, but the actual value itself
does not matter. The prior knowledge about h is
</bodyText>
<footnote confidence="0.422376">
2Start and End are with regard to a document, which are
different from start and end of a sentence.
</footnote>
<page confidence="0.967767">
1291
</page>
<figure confidence="0.847129">
corresponding potential functions as follows,
Start y1 y2 yT End
(a)
</figure>
<figureCaption confidence="0.93457575">
Figure 1: Graphical model representations of (a) a
CRF model and (b) a CRF model integrated with
virtual evidence. Solid and empty nodes denote
observed and hidden variables respectively.
</figureCaption>
<bodyText confidence="0.999039708333333">
expressed via the conditional probability p(v =
1|h). For example, by setting p(v = 1|h = a) &gt;
p(v = 1|h = b), we know that h = a is more
likely a event than h = b. This conditional distri-
bution is not learned from data, Instead, it is pre-
defined in such a way that reflects a prior belief
over the value of h.
VE can be encoded in an undirected graphical
model in a similar fashion. For our task, we mod-
ify the structure of a linear-chain CRF model as
depicted in Figure 1(b) — we create a sequence
of VE variables, denoted by v1, v2, ... , vT+1, in
parallel to the state variables. Each vt is assigned
a constant 1 (one), and is connected with yt−1
and yt, forming a new set of maximum cliques
(yt−1, yt, vt), t = 1, ... , T + 1. We create cliques
of size 3 because it is the minimum size required to
represent the prior knowledge used in our task, as
will be discussed shortly. However, it is possible
to have a different graph structure to incorporate
other types of prior knowledge, e.g., using large
cliques to represent constraints that involve more
variables.
Next, in analogy to Equation (5), we define the
</bodyText>
<equation confidence="0.8457185">
(0(t)(yt−1, yt, vt) = exp w - s(yt−1, yt, vt, t)
(7)
</equation>
<bodyText confidence="0.969575666666667">
s is a vector of VE feature functions and w is the
corresponding weight vector with pre-defined val-
ues. Given the new graphical model in Figure 1(b).
It is natural to model the conditional probability
of the state sequence given both the standard evi-
dence and the VE as follows,
</bodyText>
<equation confidence="0.99285175">
pλ(y|x,v)
1
ψ(t)
λ (x, yt−1, yt)0(t)(yt−1, yt, vt)
</equation>
<bodyText confidence="0.999541555555556">
Analogous to using p(v = 1|h) in Bayesian net-
works, we can utilize 0(t)(yt−1, yt, v = 1) to ex-
press preferences over state hypotheses in a CRF
model. In general, the function form of 0(t) may
or may not depend on the input x. Even when 0(t)
does depend on x, the relation is completely deter-
mined by external knowledge/systems (as opposed
to by data). Thus we do not explicitly connect v
with x in the graph.
</bodyText>
<subsectionHeader confidence="0.98962">
5.1 Incorporating prior knowledge
</subsectionHeader>
<bodyText confidence="0.993578727272727">
Now we show how to represent the prior knowl-
edge introduced in Section 3 using the VE fea-
ture functions. Unless otherwise stated, we as-
sume vt = 1 for all t = 1, ... , T and simply use
vt instead of vt = 1 in all equations. First, we
define a VE function s1 that represents K1: label
consistency with prototypes. We let Pl denote a
prototype list associated with the label l. If xt be-
longs to Pl, we should prefer yt = l as opposed to
other values. To this end, for cases where xt E Pl,
we set s1 as
</bodyText>
<equation confidence="0.974237">
t,
s1(yt, v) ( t =� 1 if yt = l 9)
0 otherwise
</equation>
<bodyText confidence="0.999548">
On the other hand, if xt is not a prototype, we will
always have s1(yt, vt, t) = 0 for all hypotheses
of yt. The impact of this prior knowledge is con-
trolled by the weight of s1, denote by w1. At one
extreme where w1 = 0, the prior knowledge is
completely ignored in training. At the other ex-
treme where w1 —* +oo, we constrain the values
of state variables to agree with the prior knowl-
edge. Note that although s1 is implicitly related to
x, we do not write s1 as a function of x for consis-
tency with the general definition of VE.
</bodyText>
<figure confidence="0.994724111111111">
vj1 v2=1 vT=1 vT+j1
X
(b)
Start
y1 y2
yT
End
Zλ(x, v) t
(8)
</figure>
<page confidence="0.984264">
1292
</page>
<bodyText confidence="0.999479833333333">
To represent K2: label consistency within a sen-
tence, we define a second VE feature function s2
with weight W2. Assume that we have an exter-
nal system that detects sentence boundaries. If it
is determined that xt is not the start of a sentence,
we set s2 as
</bodyText>
<equation confidence="0.953799333333333">
� 1 if yt−1 = yt
s2(yt−1, yt, vt, t) = (10)
0 otherwise
</equation>
<bodyText confidence="0.999851333333333">
It is easy to see that this would penalize state tran-
sitions within a sentence. On the other hand, if xt
is a sentence start, we set s2(yt−1, yt, vt, t) = 0 for
all possible (yt−1, yt) pairs. In this work, we use
a simple heuristics to detect sentence boundaries:
we determine that xt is the start of a sentence if its
previous token xt−1 is a period (.), a semi-colon
(;) or an acclamation mark (!), and if xt is not a
punctuation.
</bodyText>
<subsectionHeader confidence="0.979272">
5.2 Semi-supervised learning
</subsectionHeader>
<bodyText confidence="0.999959111111111">
When a large amount of unlabeled data is avail-
able, it is often helpful to leverage such data
to improve learning. However, we cannot di-
rectly optimize p(y|x, v) since the correct state
sequences of the unlabeled data are hidden. One
heuristic approach is to adapt the self-training al-
gorithm (Yarowsky, 1995) to our model. More
specifically, for each input in the unlabeled dataset
{x(i)}ni=m+1, we decode the best state sequence,
</bodyText>
<equation confidence="0.996748">
ˆy(i) = argmax p(y(i)|x(i),v(i)) (11)
Y(z)
</equation>
<bodyText confidence="0.983165684210526">
Then we use {(x(i), ˆy(i))}ni=m+1 in addition to the
labeled data to train a supervised CRF model. This
approach, however, does not have a theoretical
guarantee on optimality unless certain nontrivial
conditions are satisfied (Abney, 2004).
On the other hand, it is well known that unla-
beled data can be naturally incorporated using a
generative approach that models a joint probabil-
ity (Nigam et al., 2000). This is achieved by max-
imizing a marginal distribution of the joint proba-
bility over hidden variables. Inspired by the gen-
erative approach, we propose to explicitly model
p(y, v|x). In contrast to Equation (8), here we
jointly model y and v but the probability is still
conditioned on x. This “joint” distribution should
be chosen such that it results in the same condi-
tional distribution p(y|x, v) as defined in Equa-
tion (8). To this end, we define pλ(y, v|x) as
pλ(y,v|x)
</bodyText>
<equation confidence="0.938917">
1 Z0λ (x) H Dat) (x, yt−1, yt)φ(t) (yt−1, yt, vt)
t
(12)
</equation>
<bodyText confidence="0.948504">
Here Z0λ(x) is a normalization function obtained
by summing the numerator over both y and v.
By applying the Bayes rule, it is easy to see that
p(y|x, v) is exactly equal to Equation (8).
Given unlabeled data {x(i)}ni=m+1, we aim to
optimize the following objective,3
</bodyText>
<equation confidence="0.997099">
log pλ(v(i)|x(i)) − 1
2σ2 11A112 (13)
</equation>
<bodyText confidence="0.999284105263158">
This is essentially the marginal distribution of
p(y, v|x) over hidden variables y. Here we ig-
nore the labels of the dataset {(x(i), y(i))}mi=1, but
we do use the label information in initializing the
model which will described in Section 6. To op-
timize such an objective, we apply the EM algo-
rithm in the same fashion as is used in a generative
approach. In other words, we iteratively optimize
Q(A) = EY pλg(y|x,v)log pλ(y,v|x) where Ag
denotes the model estimated from the previous it-
eration. The gradient of the Q function is straight-
forward to compute with the result given by
We keep two sets of accumulators in running the
Forward-Backward algorithm, one for comput-
ing pλ(yt−1, yt|x, v) and the other for computing
pλ(yt−1,yt|x). Loosely speaking, the model will
converge to a local optimum if the difference be-
tween these two posterior probabilities becomes
trivial.
</bodyText>
<subsectionHeader confidence="0.998635">
5.3 Collocation based virtual evidence
</subsectionHeader>
<bodyText confidence="0.999895142857143">
Prior knowledge represented by prototypes is typ-
ically sparse. This sparse information, however,
can be propagated across all data based on dis-
tributional similarity (Haghighi and Klein, 2006).
Following the same idea, we extend the prototype
lists as follows. (1) We merge all prototypes in
Pl into a single word type wl. (2) For each word
</bodyText>
<footnote confidence="0.7120685">
3In Equation (13), the fact that v is assigned a constant 1
does not mean p(v = 1Jx) = 1(Bilmes, 2004)
</footnote>
<equation confidence="0.972790538461538">
m+n
L2 =
i=1
fk(yt−1, yt, x, t)·
� �
pλ(yt−1, yt|x, v) − pλ(yt−1, yt|x)
(14)
∂Q(A)
∂Ak
�=
t
�
yt−1,yt
</equation>
<page confidence="0.985841">
1293
</page>
<tableCaption confidence="0.989052">
Table 1: Field labels (except other) for the CLASSIFIEDS task, their respective prototype lists specified
by prior knowledge, and collocation lists mined from unlabeled data.
</tableCaption>
<figure confidence="0.9936625">
Label Prototype lists of HK06 Collocation lists (top examples)
ADDRESS
AVAILABLE
CONTACT
FEATURES
NEIGHBORHOOD
PHOTOS
address carlmont
immediately begin cheaper
[phone] call [time]
kitchen laundry parking
close near shopping
pictures image link
[4-digit] street [3-digit] streets
available
[email] appointment email see today ...
room new covered building garage ...
transportation center located restaurants ...
[url] click view photos
RENT $ month [amount] lease deposit security year agreement ...
RESTRICTIONS pets smoking dog ok sorry please allowed negotiable ...
ROOMMATES roommate respectful drama
SIZE [1-digit] br sq [4-digit] [3-digit] ft bath ba ...
UTILITIES utilities pays electricity water included owner garbage paid
</figure>
<bodyText confidence="0.999721185185185">
in the corpus, we collect a context vector of the
counts of all words (excluding stop words) that
occur within a window of size k in either direc-
tion, where the window is applied only within sen-
tence boundaries. (3) Latent semantic analysis
(Deerwester et al., 1990) is performed on the con-
structed context vectors. (4) In the resulting latent
semantic space, all words (except stop words) that
have a high enough dot product with wl will be
grouped to form a new set, denoted as Cl, which
is a superset of Pl. In this regard, Cl can be viewed
as lists of noisy “prototypes”. As observed in
HK06, another consequence of this method is that
many neighboring tokens will share the same pro-
totypes.
Differently from previous works, we use Cl
directly as virtual evidence. We could apply
sl in Equation (9) when xt E Cl (as opposed
to when xt E Pl). This, however, would con-
taminate our model since Cl are often noisy.
For example, “water” is found to be distribu-
tionally similar to the prototypes of utilities.
Although in most cases “water” indeed means
utilities, it can mean features in the context
of “water front view”. To maximally reduce
ambiguity, we propose to apply si in Equa-
tion (9) if both of the following conditions hold,
</bodyText>
<listItem confidence="0.86116475">
(1) xt E Cl
(2) There exists T s.t. |T − t |&lt; k, and xT E Cl
In other words, we will impose a non-uniform
prior on yt if xt E Cl “collocates”, within k
</listItem>
<bodyText confidence="0.957869555555556">
tokens, with another word that belongs to Cl.
Based on K2, it is reasonable to believe that
neighboring tokens tend to share the same label.
Therefore, knowing that two tokens close to each
other both belong to Cl would strengthen our
belief that either word is likely to have label l.
We thus refer to this type of virtual evidence
as collocation-based VE, and refer to Cl as
collocation lists.
</bodyText>
<sectionHeader confidence="0.997101" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999815321428571">
We use the CLASSIFIEDS data provided by
Grenager et al. (2005) and compare with re-
sults reported by CRR07 (Chang et al., 2007) and
MM08 (Mann and McCallum, 2008) for both su-
pervised and semi-supervised learning. Following
all previous works conducted on this task, we to-
kenized both words and punctuations, and created
a number of regular expression tokens for phone
numbers, email addresses, URLs, dates, money
amounts and so on. However, we did not tokenize
newline breaks, as CRR07 did, which might be
useful in determining sentence boundaries. Based
on such tokenization, we extract n-grams, n =
1, 2, 3, from the corpus as features for CRFs.
As described in Section 3, we integrate the prior
knowledge K1 and K2 in our CRF model. The
prototypes that represent K1 are given in Table 1.
CRR07 used the same two kinds of prior knowl-
edge in the form of constraints, and they imple-
mented another constraint on the minimum num-
ber of words in a field chunk. MM08 used almost
the same set of prototypes as labeled features, but
they exploited two sets of 33 additional features
for some experiments. In this regard, the compar-
ison between CRR07, MM08 and the method pre-
sented here cannot be exact. However, we show
that while our prior knowledge is no more than
that used in previous works, our approach is able
</bodyText>
<page confidence="0.968532">
1294
</page>
<table confidence="0.999814111111111">
Supervised model # labeled examples
10 25 100
CRR07: HMM 61.6 70.0 76.3
+ Constr in decoding 66.1 73.7 80.4
MM08: CRF 64.6 72.9 79.4
CRF 62.3 71.4 79.1
+ VE in decoding 68.9 74.6 81.1
CRF + VE (auto weights) 48.0 54.8 59.8
+ VE in decoding 66.0 72.5 80.9
</table>
<tableCaption confidence="0.96373325">
Table 2: Token-level accuracy of supervised learn-
ing methods; “+ VE” refers to the cases where
both kinds of prior knowledge, K1 and K2, are in-
corporated as VE in the CRF model.
</tableCaption>
<bodyText confidence="0.819036">
to achieve the state-of-art performance.
</bodyText>
<subsectionHeader confidence="0.998757">
6.1 Decoding settings
</subsectionHeader>
<bodyText confidence="0.9994395">
Depending on whether VE is used at test time, we
explore two decoding settings in all experiments:
</bodyText>
<listItem confidence="0.9438475">
1. Find y that maximizes pλ(y|x) as in standard
CRF decoding, ignoring virtual evidence.
2. Find y that maximizes p(yIx, v). We use “+
VE in decoding” to represent this setting.
</listItem>
<bodyText confidence="0.999898923076923">
These two scenarios are analogous to those in
CRR07 which conducted HMM decoding with-
out/with constraints applied. We use “+ constr. in
decoding” to represent the latter scenario of their
work. MM08, on the other hand, found no accu-
racy improvement when adding constraints at test
time.
Note that in our second decoding setting, the
weights for the VE feature functions, i.e., ω1 and
ω2, are tuned on the development set. This is done
by a greedy search that first finds the best ω1, and
then finds the best ω2 while fixing the value of ω1,
both with a step size 0.5.
</bodyText>
<subsectionHeader confidence="0.99976">
6.2 Supervised learning results
</subsectionHeader>
<bodyText confidence="0.999950727272727">
First, we experimented with a standard CRF
model with VE applied neither in training nor in
decoding. As shown in Table 2, our CRF imple-
mentation performed slightly worse than the im-
plementation by MM08, probably due to slight
difference in tokenization. Secondly, we used the
same CRF model but additionally applied VE in
decoding, corresponding to the second setting in
Section 6.1. This method gave a significant boost
to the tagging performance, yielding the best su-
pervised learning results (shown as bolded in the
</bodyText>
<table confidence="0.999590909090909">
Semi-supervised models # labeled examples
10 25 100
CRR07: HMM + Constr 70.9 74.8 78.6
+ Constr in decoding 74.7 78.5 81.7
MM08: CRF + GE 72.6 76.3 80.1
CRF + VE (Self-train) 69.0 74.2 81.4
+ VE in decoding 69.1 75.2 81.2
CRF + Col-VE (Self-train) 73.1 76.4 81.8
+ Col-VE in decoding 75.7 77.6 82.9
CRF + Col-VE (EM) 78.3 79.1 82.7
+ Col-VE in decoding 78.8 79.5 82.9
</table>
<tableCaption confidence="0.996916">
Table 3: Token-level accuracy of semi-supervised
</tableCaption>
<bodyText confidence="0.98827">
learning methods. “+ Col-VE” refers to cases
where collocation-based VE is integrated in the
CRF model in addition to the VE representing K1
and K2.
table). This proves that the prior knowledge is in-
deed complementary to the information offered by
the training data.
Similar to the second decoding setting that in-
corporates VE, we can have a counterpart setting
at training time. In other words, we can optimize
pλ(y|x, v) instead of pλ(y|x) during learning. In
deciding ω = (ω1, ω2), it is possible to learn ω
from data in the same way as how we learn λ.
This, however, might undermine the role of other
useful features since we do not always have suffi-
cient training data to reliably estimate the weight
of prior knowledge. As shown in Table 2, we ex-
perimented with learning ω automatically (shown
as “auto weights”). While applying VE with such
weights in both training and decoding worked rea-
sonably well, applying VE only in training but not
in decoding yielded very poor performance (prob-
ably due to excessively large estimates of ω1 and
ω2). Additionally, we repeated the above experi-
ment with manually specified weights, but did not
find further accuracy improvement over the best
supervised learning results.
</bodyText>
<subsectionHeader confidence="0.99829">
6.3 Semi-supervised learning results
</subsectionHeader>
<bodyText confidence="0.99998575">
One natural way of leveraging the unlabeled data
(more than 8K examples) is to perform semi-
supervised learning in a self-training fashion. To
this end, we used our best supervised model in Ta-
ble 2 to decode the unlabeled examples as well
as the test-set examples (by treating them as un-
labeled). Note that by doing this our comparison
with CRR07 and MM08 cannot be exact as they
</bodyText>
<page confidence="0.963875">
1295
</page>
<bodyText confidence="0.99997654">
sampled the unlabeled examples, with different
rates, for semi-supervised learning, while we used
as much data as possible. We applied the same w
that was used for the supervised model, and then
combined the newly labeled examples, in addition
to the manually labeled ones, as training data to
learn a supervised CRF model. On this particu-
lar dataset, we did not find it helpful by selecting
automatically labeled data based on a confidence
threshold. We simply used all data available in
self-training. This paradigm is referred to as “CRF
+ VE (self-train)” in Table 3. When no VE is ap-
plied at test time, this semi-supervised CRF model
significantly outperformed the best model in Ta-
ble 2. When applying VE at test time, however,
the improvement over its supervised counterpart
became trivial.
Next, following Section 5.3, we collected con-
text vectors on the unlabeled data using a win-
dow size k = 3, and extracted the top 50 singular
vectors therefrom.4 We created collocation lists
that contain words close to the merged prototype
words in the latent semantic space. Some exam-
ples are given in the last column of Table 1. We
then augmented the prototype-based VE based on
the following rules: If xt belongs to any prototype
list Pl, we directly apply si in Equation (9); oth-
erwise, we apply sl if xt and at least one neigh-
bor (within 3 tokens from xt) belong to the same
collocation list Cl. In our experiments, we let
“Col-VE” represent such collocation-based VE.
We conducted self-training using a CRF model in-
tegrated with Col-VE, where w was tuned a pri-
ori by testing the same model on the develop-
ment set. As shown in the table, “CRF + Col-VE
(self-train)” gave significant accuracy improve-
ment over “CRF + VE”, while adding Col-VE at
test time further boosted the performance. The ac-
curacies were already on par with the best results
previously reported on this task.
Finally, we implemented the EM algorithm pro-
posed in Section 5.2 that iteratively optimizes
p(v|x) on all data. The model was initial-
ized by the one obtained from “CRF + Col-VE
(self-train)”. After the model was initialized,
we performed the EM algorithm until the model
reached a maximum accuracy on the develop-
ment set. Note that in some cases, we observed
a development-set accuracy degradation after the
first iteration of the EM, but the accuracy quickly
</bodyText>
<footnote confidence="0.686164">
4The same configuration is used in HK06.
</footnote>
<bodyText confidence="0.999618882352941">
recovered from the second iteration and kept in-
creasing until a maximum accuracy was reached.5
As shown in the last two rows in Table 3, this
method is clearly advantageous over self-training,
leading to the best tagging accuracies in both de-
coding settings. Our model achieved 2.6%−5.7%
absolute accuracy increases in the three training
settings compared with MM08 which had the best
results without using any constraints in decoding.
When applying VE at test time, our model was
1.2% − 4.1% better than CRR07 which had the
best overall results. Additionally, when compared
with supervised learning results, our best semi-
supervised model trained on only 10 labeled ex-
amples performed almost as well as a standard su-
pervised CRF model trained on 100 labeled exam-
ples.
</bodyText>
<sectionHeader confidence="0.999807" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999992533333333">
We have presented the use of virtual evidence as
a principled way of incorporating prior knowledge
into conditional random fields. A key contribu-
tion of our work is the introduction of a novel
semi-supervised learning objective for training a
CRF model integrated with VE. We also found it
useful to create so-called collocation-based VE,
assuming that tokens close to each other tend to
have consistent labels. Our evaluation on the
CLASSIFIEDS data showed that the learning ob-
jective presented here, combined with the use of
collocation-based VE, yielded remarkably good
accuracy performance. In the future, we would
like to see the application of our approach to other
tasks such as (Li et al., 2009).
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.904534071428571">
Steven Abney. 2004. Understanding the Yarowsky
algorithm. Association for Computational Linguis-
tics, 30(3):365–395.
Jeff Bilmes. 2004. On soft evidence in Bayesian
networks. Technical Report UWEETR-2004-0016,
University of Washington, Dept. of Electrical Engi-
neering.
Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007.
Guiding semi-supervision with constraint-driven
learning. In Proceedings ofACL.
5The initial degradation is probably due to the fact that
self-training can result in an initial model with decent accu-
racy but low p(vIx); thus the EM algorithm that maximizes
p(vIx) may temporarily decrease the accuracy.
</reference>
<page confidence="0.851929">
1296
</page>
<reference confidence="0.999805618181818">
Scott Deerwester, Susan Dumais, Thomas Landauer,
George Furnas, and Richard Harshman. 1990.
Indexing by latent semantic analysis. Journal
of the American Society of Information Science,
41(6):391–407.
Yves Grandvalet and Yoshua Bengio. 2004. Semi-
supervised learning by entropy minimization. In Ad-
vances in Neural Information Processing Systems.
Trond Grenager, Dan Klein, and Christopher D. Man-
ning. 2005. Unsupervised learning for field seg-
mentation models for information extraction. In
Proceedings of Association of Computational Lin-
guistics.
Aria Haghighi and Dan Klein. 2006. Prototype-driven
learning for sequence models. In Proceedings of
HLT-NAACL.
Feng Jiao, Shaojun Wang, Chi-Hoon Lee, Russell
Greiner, and Dale Schuurmans. 2006. Semi-
supervised conditional random fields for improved
sequence segmentation and labeling. In Proceed-
ings ofACL.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the International
Conference on Machine Learning, pages 282–289.
Xiao Li, Ye-Yi Wang, and Alex Acero. 2009. Extract-
ing structured information from user queries with
semi-supervised conditional random fields. In Pro-
ceedings of SIGIR.
Gideon Mann and Andrew McCallum. 2008. General-
ized expectation criteria for semi-supervised learn-
ing of conditional random fields. In Proceedings of
ACL.
Kamal Nigam, Andrew Kachites Mccallum, Sebastian
Thrun, and Tom Mitchell. 2000. Text classification
from labeled and unlabeled documents using EM.
Machine Learning, 39:103–134.
Judea Pearl. 1988. Probabilistic Reasoning in In-
telligent Systems: Networks of Plausible Inference.
Morgan Kaufmann, 2nd printing edition edition.
A. Quattoni, S. Wang, L.-P. Morency, M. Collins, and
T. Darrell. 2007. Hidden conditional random fields.
IEEE Transaction on Pattern Analysis and Machine
Intellegence, 29(10):1848–1852.
Sheila Reynolds and Jeff Bilmes. 2005. Part-of-speech
tagging using virtual evidence and negative training.
In Proceedings ofHLT/EMNLP.
Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised
sequential labeling and segmentation using giga-
word scale unlabeled data. In Proceedings of
ACL/HLT.
David Yarowsky. 1995. Unsupervised word sense dis-
ambiguation rivaling supervised methods. In Pro-
ceedings ofACL, pages 189–196.
</reference>
<page confidence="0.99214">
1297
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.954123">
<title confidence="0.999946">On the Use of Virtual Evidence in Conditional Random Fields</title>
<author confidence="0.999641">Xiao Li</author>
<affiliation confidence="0.999933">Microsoft Research</affiliation>
<address confidence="0.9944855">One Microsoft Way Redmond, WA 98052</address>
<email confidence="0.999638">xiaol@microsoft.com</email>
<abstract confidence="0.9982627">evidence first introduced by (Pearl, 1988), provides a convenient way of incorporating prior knowledge into Bayesian networks. This work generalizes the use of VE to undirected graphical models and, in particular, to conditional random fields (CRFs). We show that VE can be naturally encoded into a CRF model as potential functions. More importantly, we propose a novel semisupervised machine learning objective for estimating a CRF model integrated with VE. The objective can be optimized using the Expectation-Maximization algorithm while maintaining the discriminative nature of CRFs. When evaluated on the our approach significantly outperforms the best known solutions reported on this task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Understanding the Yarowsky algorithm.</title>
<date>2004</date>
<journal>Association for Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="16642" citStr="Abney, 2004" startWordPosition="2851" endWordPosition="2852">ve learning. However, we cannot directly optimize p(y|x, v) since the correct state sequences of the unlabeled data are hidden. One heuristic approach is to adapt the self-training algorithm (Yarowsky, 1995) to our model. More specifically, for each input in the unlabeled dataset {x(i)}ni=m+1, we decode the best state sequence, ˆy(i) = argmax p(y(i)|x(i),v(i)) (11) Y(z) Then we use {(x(i), ˆy(i))}ni=m+1 in addition to the labeled data to train a supervised CRF model. This approach, however, does not have a theoretical guarantee on optimality unless certain nontrivial conditions are satisfied (Abney, 2004). On the other hand, it is well known that unlabeled data can be naturally incorporated using a generative approach that models a joint probability (Nigam et al., 2000). This is achieved by maximizing a marginal distribution of the joint probability over hidden variables. Inspired by the generative approach, we propose to explicitly model p(y, v|x). In contrast to Equation (8), here we jointly model y and v but the probability is still conditioned on x. This “joint” distribution should be chosen such that it results in the same conditional distribution p(y|x, v) as defined in Equation (8). To </context>
</contexts>
<marker>Abney, 2004</marker>
<rawString>Steven Abney. 2004. Understanding the Yarowsky algorithm. Association for Computational Linguistics, 30(3):365–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Bilmes</author>
</authors>
<title>On soft evidence in Bayesian networks.</title>
<date>2004</date>
<tech>Technical Report UWEETR-2004-0016,</tech>
<institution>University of Washington, Dept. of Electrical Engineering.</institution>
<contexts>
<context position="1841" citStr="Bilmes, 2004" startWordPosition="280" endWordPosition="281">ount of training data. Whenever prior knowledge becomes available, it is desired that such information is integrated to a probabilistic model to improve learning. Virtual evidence (VE), first introduced by Pearl (1988), offers a principled and convenient way of incorporating external knowledge into Bayesian networks. In contrast to standard evidence (also known as observed variables), VE expresses a prior belief over values of random variables. It has been shown that VE can significantly extend the modeling power of Bayesian networks without complicating the fundamental inference methodology (Bilmes, 2004; Reynolds and Bilmes, 2005). This work extends the use of VE to undirected graphical models and, in particular, to conditional random fields (CRFs). We show that VE can be naturally encoded into an undirected graphical model as potential functions. More importantly, we discuss a semi-supervised machine learning setting for estimating CRFs with the presence of VE. As the conditional likelihood objective of CRFs is not directly maximizable with respect to unlabeled data, we propose a novel semisupervised learning objective that can be optimized using the Expectation-Maximization (EM) algorithm </context>
<context position="6326" citStr="Bilmes (2004)" startWordPosition="1003" endWordPosition="1004">ning objective consists of the standard CRF training objective, plus a Gaussian prior on model parameters and an additional regularization term:1 � log pλ(y(i)|x(i))−1 i 2σ2 kλk2−ρD(ˆp||˜pλ) (2) In the last term, pˆ and ˜pλ both refer to conditional distributions of labels given a feature. While the former is specified by prior knowledge, and the latter is estimated from unlabeled data. Our approach incorporates prior knowledge as virtual evidence to express preferences over the values of a set of random variables. The notion of VE was first introduced by Pearl (1998) and further developed by Bilmes (2004), both in the context of Bayesian networks. Different from constraint-driven learning, VE can be formally encoded as part of a graphical model. The fundamental inference methodology, therefore, does not need to be altered. Moreover, VE has the flexibility of representing various kinds of prior knowledge. For example, Reynolds and Bilmes (2005) use VE that explicitly favors self transitions in dynamic Bayesian networks. This work extends the use of VE to CRFs. In essence, VE herein can be viewed as probabilistic constraints in an undirected graph that allow exact inference. One of the biggest c</context>
<context position="19006" citStr="Bilmes, 2004" startWordPosition="3259" endWordPosition="3260"> speaking, the model will converge to a local optimum if the difference between these two posterior probabilities becomes trivial. 5.3 Collocation based virtual evidence Prior knowledge represented by prototypes is typically sparse. This sparse information, however, can be propagated across all data based on distributional similarity (Haghighi and Klein, 2006). Following the same idea, we extend the prototype lists as follows. (1) We merge all prototypes in Pl into a single word type wl. (2) For each word 3In Equation (13), the fact that v is assigned a constant 1 does not mean p(v = 1Jx) = 1(Bilmes, 2004) m+n L2 = i=1 fk(yt−1, yt, x, t)· � � pλ(yt−1, yt|x, v) − pλ(yt−1, yt|x) (14) ∂Q(A) ∂Ak �= t � yt−1,yt 1293 Table 1: Field labels (except other) for the CLASSIFIEDS task, their respective prototype lists specified by prior knowledge, and collocation lists mined from unlabeled data. Label Prototype lists of HK06 Collocation lists (top examples) ADDRESS AVAILABLE CONTACT FEATURES NEIGHBORHOOD PHOTOS address carlmont immediately begin cheaper [phone] call [time] kitchen laundry parking close near shopping pictures image link [4-digit] street [3-digit] streets available [email] appointment email s</context>
</contexts>
<marker>Bilmes, 2004</marker>
<rawString>Jeff Bilmes. 2004. On soft evidence in Bayesian networks. Technical Report UWEETR-2004-0016, University of Washington, Dept. of Electrical Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Guiding semi-supervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="3575" citStr="Chang et al., 2007" startWordPosition="559" endWordPosition="562"> distributional similarity. This results in so-called collocation lists, each consisting of a relatively large number of noisy “prototypes” for a label. Given the fact that these noisy prototypes are often located close to each other in an input sequence, we create a new type of VE based on word collocation to reduce ambiguity. 1289 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1289–1297, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP We compare our CRF model integrated with VE with two state-of-the-art models, i.e., constraintdriven learning (Chang et al., 2007) and generalized expectation criteria (Mann and McCallum, 2008). Experiments show that our approach leads to sequential labeling accuracies superior to the best results reported on this task in both supervised and semi-supervised learning. 2 Related work There have been various works that make use of prior knowledge in sequential labeling tasks. Grenager et al. (2005) explicitly constrain the transition matrix of a hidden Markov model (HMM) to favor self transitions, assuming that fields tend to consist of consecutive runs of the same label. Prototype-drive learning (Haghighi and Klein, 2006) </context>
<context position="21943" citStr="Chang et al., 2007" startWordPosition="3758" endWordPosition="3761">r words, we will impose a non-uniform prior on yt if xt E Cl “collocates”, within k tokens, with another word that belongs to Cl. Based on K2, it is reasonable to believe that neighboring tokens tend to share the same label. Therefore, knowing that two tokens close to each other both belong to Cl would strengthen our belief that either word is likely to have label l. We thus refer to this type of virtual evidence as collocation-based VE, and refer to Cl as collocation lists. 6 Evaluation We use the CLASSIFIEDS data provided by Grenager et al. (2005) and compare with results reported by CRR07 (Chang et al., 2007) and MM08 (Mann and McCallum, 2008) for both supervised and semi-supervised learning. Following all previous works conducted on this task, we tokenized both words and punctuations, and created a number of regular expression tokens for phone numbers, email addresses, URLs, dates, money amounts and so on. However, we did not tokenize newline breaks, as CRR07 did, which might be useful in determining sentence boundaries. Based on such tokenization, we extract n-grams, n = 1, 2, 3, from the corpus as features for CRFs. As described in Section 3, we integrate the prior knowledge K1 and K2 in our CR</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraint-driven learning. In Proceedings ofACL.</rawString>
</citation>
<citation valid="false">
<title>5The initial degradation is probably due to the fact that self-training can result in an initial model with decent accuracy but low p(vIx); thus the EM algorithm that maximizes p(vIx) may temporarily decrease the accuracy.</title>
<marker></marker>
<rawString>5The initial degradation is probably due to the fact that self-training can result in an initial model with decent accuracy but low p(vIx); thus the EM algorithm that maximizes p(vIx) may temporarily decrease the accuracy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan Dumais</author>
<author>Thomas Landauer</author>
<author>George Furnas</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society of Information Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="20288" citStr="Deerwester et al., 1990" startWordPosition="3454" endWordPosition="3457">tation center located restaurants ... [url] click view photos RENT $ month [amount] lease deposit security year agreement ... RESTRICTIONS pets smoking dog ok sorry please allowed negotiable ... ROOMMATES roommate respectful drama SIZE [1-digit] br sq [4-digit] [3-digit] ft bath ba ... UTILITIES utilities pays electricity water included owner garbage paid in the corpus, we collect a context vector of the counts of all words (excluding stop words) that occur within a window of size k in either direction, where the window is applied only within sentence boundaries. (3) Latent semantic analysis (Deerwester et al., 1990) is performed on the constructed context vectors. (4) In the resulting latent semantic space, all words (except stop words) that have a high enough dot product with wl will be grouped to form a new set, denoted as Cl, which is a superset of Pl. In this regard, Cl can be viewed as lists of noisy “prototypes”. As observed in HK06, another consequence of this method is that many neighboring tokens will share the same prototypes. Differently from previous works, we use Cl directly as virtual evidence. We could apply sl in Equation (9) when xt E Cl (as opposed to when xt E Pl). This, however, would</context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan Dumais, Thomas Landauer, George Furnas, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American Society of Information Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Grandvalet</author>
<author>Yoshua Bengio</author>
</authors>
<title>Semisupervised learning by entropy minimization.</title>
<date>2004</date>
<booktitle>In Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="7309" citStr="Grandvalet and Bengio, 2004" startWordPosition="1157" endWordPosition="1161">t explicitly favors self transitions in dynamic Bayesian networks. This work extends the use of VE to CRFs. In essence, VE herein can be viewed as probabilistic constraints in an undirected graph that allow exact inference. One of the biggest challenges of such a model lies in the semi-supervised machine learning setting. Since the entire state sequence of an unlabeled instance remains hidden, the conditional likelihood objective of CRFs is not directly optimizable. There have been a number of works that address this problem for conditional models. For example, minimum entropy regularization (Grandvalet and Bengio, 2004; Jiao et al., 2006), aims to maximize the conditional likelihood of labeled data while minimizing the conditional entropy of unlabeled data: log pλ(y(i)|x(i))− 1 2σ2 kλk2 −ρH(y|x) (3) This approach generally would result in “sharper” models which can be data-sensitive in practice. Another approach (Suzuki and Isozaki, 2008) embeds a joint probability model (HMM in their 1We slightly modify the notation here to be consistent with the rest of the paper. � i 1290 case) into a CRF model as a new potential function. Semi-supervised learning is then conducted by iteratively (1) fixing the HMM and u</context>
</contexts>
<marker>Grandvalet, Bengio, 2004</marker>
<rawString>Yves Grandvalet and Yoshua Bengio. 2004. Semisupervised learning by entropy minimization. In Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trond Grenager</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Unsupervised learning for field segmentation models for information extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of Association of Computational Linguistics.</booktitle>
<contexts>
<context position="2560" citStr="Grenager et al., 2005" startWordPosition="393" endWordPosition="396"> in particular, to conditional random fields (CRFs). We show that VE can be naturally encoded into an undirected graphical model as potential functions. More importantly, we discuss a semi-supervised machine learning setting for estimating CRFs with the presence of VE. As the conditional likelihood objective of CRFs is not directly maximizable with respect to unlabeled data, we propose a novel semisupervised learning objective that can be optimized using the Expectation-Maximization (EM) algorithm while maintaining the discriminative nature of CRFs. We apply our model to the CLASSIFIEDS data (Grenager et al., 2005). Specifically, we use VE to incorporate into a CRF model two types of prior knowledge specified in previous works. The first is defined based on the notion of prototypes, i.e., example words for a given label; and the other assumes that adjacent tokens tend to have the same label. When unlabeled data becomes available, we further extend the sparse prototype information to other words based on distributional similarity. This results in so-called collocation lists, each consisting of a relatively large number of noisy “prototypes” for a label. Given the fact that these noisy prototypes are ofte</context>
<context position="3945" citStr="Grenager et al. (2005)" startWordPosition="615" endWordPosition="618">ce on Empirical Methods in Natural Language Processing, pages 1289–1297, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP We compare our CRF model integrated with VE with two state-of-the-art models, i.e., constraintdriven learning (Chang et al., 2007) and generalized expectation criteria (Mann and McCallum, 2008). Experiments show that our approach leads to sequential labeling accuracies superior to the best results reported on this task in both supervised and semi-supervised learning. 2 Related work There have been various works that make use of prior knowledge in sequential labeling tasks. Grenager et al. (2005) explicitly constrain the transition matrix of a hidden Markov model (HMM) to favor self transitions, assuming that fields tend to consist of consecutive runs of the same label. Prototype-drive learning (Haghighi and Klein, 2006) specifies prior knowledge by providing a few prototypes (i.e., canonical example words) for each label. This sparse prototype information is then propagated to other words based on distributional similarity. The relation between words and their prototypes are then used as features in a Markov random field (MRF) model. Since an MRF model aims to optimize the joint prob</context>
<context position="8543" citStr="Grenager et al., 2005" startWordPosition="1360" endWordPosition="1363">parameters on labeled data and (2) fixing the CRF model and updating the HMM on unlabeled data. Additionally, when unlabeled instances have partial labeling information, it is possible to optimize a marginal distribution of the conditional likelihood, i.e., pλ(y(i) o |x), on unlabeled data. Here y(i) o is a subvector of y(i) that denotes the set of observed state variables. The optimization can be done in a similar fashion as training a hiddenstate CRF model (Quattoni et al., 2007). 3 Task We consider the problem of extracting fields from free-text advertisements. We use the CLASSIFIEDS data (Grenager et al., 2005) which consists of 8767 ads for apartment rental. 302 of the ads in the CLASSIFIEDS data have been manuallylabeled with 12 fields, including size, rent, neighborhood and so on. The labeled data has been divided into train/dev/test sets with 102/100/100 ads respectively. The evaluation metric is the tokenlevel accuracy where tokens include both words and punctuations. Our goal in this work is two folds: (1) leverage both the training data and the prior knowledge specified for this task for supervised learning, and (2) additionally use the unlabeled data for semisupervised learning. We exploit t</context>
<context position="21879" citStr="Grenager et al. (2005)" startWordPosition="3746" endWordPosition="3749">1) xt E Cl (2) There exists T s.t. |T − t |&lt; k, and xT E Cl In other words, we will impose a non-uniform prior on yt if xt E Cl “collocates”, within k tokens, with another word that belongs to Cl. Based on K2, it is reasonable to believe that neighboring tokens tend to share the same label. Therefore, knowing that two tokens close to each other both belong to Cl would strengthen our belief that either word is likely to have label l. We thus refer to this type of virtual evidence as collocation-based VE, and refer to Cl as collocation lists. 6 Evaluation We use the CLASSIFIEDS data provided by Grenager et al. (2005) and compare with results reported by CRR07 (Chang et al., 2007) and MM08 (Mann and McCallum, 2008) for both supervised and semi-supervised learning. Following all previous works conducted on this task, we tokenized both words and punctuations, and created a number of regular expression tokens for phone numbers, email addresses, URLs, dates, money amounts and so on. However, we did not tokenize newline breaks, as CRR07 did, which might be useful in determining sentence boundaries. Based on such tokenization, we extract n-grams, n = 1, 2, 3, from the corpus as features for CRFs. As described in</context>
</contexts>
<marker>Grenager, Klein, Manning, 2005</marker>
<rawString>Trond Grenager, Dan Klein, and Christopher D. Manning. 2005. Unsupervised learning for field segmentation models for information extraction. In Proceedings of Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Prototype-driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="4174" citStr="Haghighi and Klein, 2006" startWordPosition="649" endWordPosition="652">rning (Chang et al., 2007) and generalized expectation criteria (Mann and McCallum, 2008). Experiments show that our approach leads to sequential labeling accuracies superior to the best results reported on this task in both supervised and semi-supervised learning. 2 Related work There have been various works that make use of prior knowledge in sequential labeling tasks. Grenager et al. (2005) explicitly constrain the transition matrix of a hidden Markov model (HMM) to favor self transitions, assuming that fields tend to consist of consecutive runs of the same label. Prototype-drive learning (Haghighi and Klein, 2006) specifies prior knowledge by providing a few prototypes (i.e., canonical example words) for each label. This sparse prototype information is then propagated to other words based on distributional similarity. The relation between words and their prototypes are then used as features in a Markov random field (MRF) model. Since an MRF model aims to optimize the joint probability p(x, y) of input and state sequences, it is possible to apply the EM algorithm for unsupervised/semisupervised learning. Constraint-driven learning (Chang et al., 2007) expresses several kinds of constraints in a unified </context>
<context position="10824" citStr="Haghighi and Klein (2006)" startWordPosition="1756" endWordPosition="1759"> vector and f is a feature vector of arbitrary functions of the corresponding clique. Given a set of labeled examples {x(i),y(i))lmi=1, we can estimate model parameters in a supervised machine learning setting. The objective is to estimate λ that maximizes the conditional likelihood while regularizing the model size: • K2: label consistency within a sentence. L1 = m log pλ(y(i)|x(i)) − 1 i=1 2σ2 Jλ112 (6) K1 involves a set of prototype lists. Each list is attached with a label and consists of a set of example words for that label. In this work, we use the prototype lists originally defined by Haghighi and Klein (2006) (HK06) and subsequently used by Chang et al. (2005) (CRR07) and Mann and McCallum (2008) (MM08). The labels as well as their prototypes are shown in the first two columns of Table 1. Our model is desired to be consistent with such prototype information. Secondly, K2 means that tokens tend to have consistent labels within a sentence. A similar type of prior knowledge is implemented by CRR07 as a constraint in inference. In this work, we optimize L1 using stochastic gradient descent and use the accuracy on the development set as the stopping criterion. 5 CRFs with Virtual Evidence A canonical w</context>
<context position="18755" citStr="Haghighi and Klein, 2006" startWordPosition="3208" endWordPosition="3211">ous iteration. The gradient of the Q function is straightforward to compute with the result given by We keep two sets of accumulators in running the Forward-Backward algorithm, one for computing pλ(yt−1, yt|x, v) and the other for computing pλ(yt−1,yt|x). Loosely speaking, the model will converge to a local optimum if the difference between these two posterior probabilities becomes trivial. 5.3 Collocation based virtual evidence Prior knowledge represented by prototypes is typically sparse. This sparse information, however, can be propagated across all data based on distributional similarity (Haghighi and Klein, 2006). Following the same idea, we extend the prototype lists as follows. (1) We merge all prototypes in Pl into a single word type wl. (2) For each word 3In Equation (13), the fact that v is assigned a constant 1 does not mean p(v = 1Jx) = 1(Bilmes, 2004) m+n L2 = i=1 fk(yt−1, yt, x, t)· � � pλ(yt−1, yt|x, v) − pλ(yt−1, yt|x) (14) ∂Q(A) ∂Ak �= t � yt−1,yt 1293 Table 1: Field labels (except other) for the CLASSIFIEDS task, their respective prototype lists specified by prior knowledge, and collocation lists mined from unlabeled data. Label Prototype lists of HK06 Collocation lists (top examples) ADD</context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>Aria Haghighi and Dan Klein. 2006. Prototype-driven learning for sequence models. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng Jiao</author>
<author>Shaojun Wang</author>
<author>Chi-Hoon Lee</author>
<author>Russell Greiner</author>
<author>Dale Schuurmans</author>
</authors>
<title>Semisupervised conditional random fields for improved sequence segmentation and labeling.</title>
<date>2006</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="7329" citStr="Jiao et al., 2006" startWordPosition="1162" endWordPosition="1165">sitions in dynamic Bayesian networks. This work extends the use of VE to CRFs. In essence, VE herein can be viewed as probabilistic constraints in an undirected graph that allow exact inference. One of the biggest challenges of such a model lies in the semi-supervised machine learning setting. Since the entire state sequence of an unlabeled instance remains hidden, the conditional likelihood objective of CRFs is not directly optimizable. There have been a number of works that address this problem for conditional models. For example, minimum entropy regularization (Grandvalet and Bengio, 2004; Jiao et al., 2006), aims to maximize the conditional likelihood of labeled data while minimizing the conditional entropy of unlabeled data: log pλ(y(i)|x(i))− 1 2σ2 kλk2 −ρH(y|x) (3) This approach generally would result in “sharper” models which can be data-sensitive in practice. Another approach (Suzuki and Isozaki, 2008) embeds a joint probability model (HMM in their 1We slightly modify the notation here to be consistent with the rest of the paper. � i 1290 case) into a CRF model as a new potential function. Semi-supervised learning is then conducted by iteratively (1) fixing the HMM and updating CRF paramete</context>
</contexts>
<marker>Jiao, Wang, Lee, Greiner, Schuurmans, 2006</marker>
<rawString>Feng Jiao, Shaojun Wang, Chi-Hoon Lee, Russell Greiner, and Dale Schuurmans. 2006. Semisupervised conditional random fields for improved sequence segmentation and labeling. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="9420" citStr="Lafferty et al., 2001" startWordPosition="1501" endWordPosition="1504">s respectively. The evaluation metric is the tokenlevel accuracy where tokens include both words and punctuations. Our goal in this work is two folds: (1) leverage both the training data and the prior knowledge specified for this task for supervised learning, and (2) additionally use the unlabeled data for semisupervised learning. We exploit two types of prior knowledge: • K1: label consistency with prototypes; 4 Conditional Random Fields Conditional random fields are a probabilistic model that directly optimizes the conditional probability of a state (label) sequence given an input sequence (Lafferty et al., 2001). Formally, we let x = (x1, x2, ... , xT) denote an input sequence of T tokens, and y = (y1, y2, ... , yT) the corresponding state sequence. We further augment y with two special states, Start and End,2 represented by y0 and yT+1 respectively. A linear-chain CRF model is an undirected graphical model as depicted in Figure 1(a), with the conditional probability given by 1 pλ(y|x) = Zλ(x) Hψjt)(x,yt−1,yt) (4) t The partition function Zλ(x) normalizes the exponential form to be a probability distribution. ψ(t) λ are a set of potential functions defined on the maximum cliques of the graph, i.e., (</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Li</author>
<author>Ye-Yi Wang</author>
<author>Alex Acero</author>
</authors>
<title>Extracting structured information from user queries with semi-supervised conditional random fields.</title>
<date>2009</date>
<booktitle>In Proceedings of SIGIR.</booktitle>
<marker>Li, Wang, Acero, 2009</marker>
<rawString>Xiao Li, Ye-Yi Wang, and Alex Acero. 2009. Extracting structured information from user queries with semi-supervised conditional random fields. In Proceedings of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning of conditional random fields.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="3638" citStr="Mann and McCallum, 2008" startWordPosition="568" endWordPosition="571">ocation lists, each consisting of a relatively large number of noisy “prototypes” for a label. Given the fact that these noisy prototypes are often located close to each other in an input sequence, we create a new type of VE based on word collocation to reduce ambiguity. 1289 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1289–1297, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP We compare our CRF model integrated with VE with two state-of-the-art models, i.e., constraintdriven learning (Chang et al., 2007) and generalized expectation criteria (Mann and McCallum, 2008). Experiments show that our approach leads to sequential labeling accuracies superior to the best results reported on this task in both supervised and semi-supervised learning. 2 Related work There have been various works that make use of prior knowledge in sequential labeling tasks. Grenager et al. (2005) explicitly constrain the transition matrix of a hidden Markov model (HMM) to favor self transitions, assuming that fields tend to consist of consecutive runs of the same label. Prototype-drive learning (Haghighi and Klein, 2006) specifies prior knowledge by providing a few prototypes (i.e., </context>
<context position="5571" citStr="Mann and McCallum, 2008" startWordPosition="880" endWordPosition="883">λ · F(x, y) is a linear decision function applicable to a number of sequential models, such as HMMs, MRFs and CRFs. Function d is implemented as the Hamming distance (or its approximation) between a hypothesis sequence and the space of state sequences that satisfy the constraint Ci. Due to the nature of the distance function, their work approximates EM training by finding the top K hypothesis sequences and using them as newly labeled instances to update the model. This process is repeated for a number of iterations in a self-training fashion (Yarowsky, 1995). Generalized expectation criteria (Mann and McCallum, 2008) represent prior knowledge as labeled features, and use such information to regularize semi-supervised learning for CRFs. Formally, their learning objective consists of the standard CRF training objective, plus a Gaussian prior on model parameters and an additional regularization term:1 � log pλ(y(i)|x(i))−1 i 2σ2 kλk2−ρD(ˆp||˜pλ) (2) In the last term, pˆ and ˜pλ both refer to conditional distributions of labels given a feature. While the former is specified by prior knowledge, and the latter is estimated from unlabeled data. Our approach incorporates prior knowledge as virtual evidence to exp</context>
<context position="10913" citStr="Mann and McCallum (2008)" startWordPosition="1771" endWordPosition="1774">n a set of labeled examples {x(i),y(i))lmi=1, we can estimate model parameters in a supervised machine learning setting. The objective is to estimate λ that maximizes the conditional likelihood while regularizing the model size: • K2: label consistency within a sentence. L1 = m log pλ(y(i)|x(i)) − 1 i=1 2σ2 Jλ112 (6) K1 involves a set of prototype lists. Each list is attached with a label and consists of a set of example words for that label. In this work, we use the prototype lists originally defined by Haghighi and Klein (2006) (HK06) and subsequently used by Chang et al. (2005) (CRR07) and Mann and McCallum (2008) (MM08). The labels as well as their prototypes are shown in the first two columns of Table 1. Our model is desired to be consistent with such prototype information. Secondly, K2 means that tokens tend to have consistent labels within a sentence. A similar type of prior knowledge is implemented by CRR07 as a constraint in inference. In this work, we optimize L1 using stochastic gradient descent and use the accuracy on the development set as the stopping criterion. 5 CRFs with Virtual Evidence A canonical way of using virtual evidence (VE) in Bayesian networks is to have a directed edge from a </context>
<context position="21978" citStr="Mann and McCallum, 2008" startWordPosition="3764" endWordPosition="3767">uniform prior on yt if xt E Cl “collocates”, within k tokens, with another word that belongs to Cl. Based on K2, it is reasonable to believe that neighboring tokens tend to share the same label. Therefore, knowing that two tokens close to each other both belong to Cl would strengthen our belief that either word is likely to have label l. We thus refer to this type of virtual evidence as collocation-based VE, and refer to Cl as collocation lists. 6 Evaluation We use the CLASSIFIEDS data provided by Grenager et al. (2005) and compare with results reported by CRR07 (Chang et al., 2007) and MM08 (Mann and McCallum, 2008) for both supervised and semi-supervised learning. Following all previous works conducted on this task, we tokenized both words and punctuations, and created a number of regular expression tokens for phone numbers, email addresses, URLs, dates, money amounts and so on. However, we did not tokenize newline breaks, as CRR07 did, which might be useful in determining sentence boundaries. Based on such tokenization, we extract n-grams, n = 1, 2, 3, from the corpus as features for CRFs. As described in Section 3, we integrate the prior knowledge K1 and K2 in our CRF model. The prototypes that repres</context>
</contexts>
<marker>Mann, McCallum, 2008</marker>
<rawString>Gideon Mann and Andrew McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamal Nigam</author>
<author>Andrew Kachites Mccallum</author>
<author>Sebastian Thrun</author>
<author>Tom Mitchell</author>
</authors>
<title>Text classification from labeled and unlabeled documents using EM.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--103</pages>
<contexts>
<context position="16810" citStr="Nigam et al., 2000" startWordPosition="2879" endWordPosition="2882">t the self-training algorithm (Yarowsky, 1995) to our model. More specifically, for each input in the unlabeled dataset {x(i)}ni=m+1, we decode the best state sequence, ˆy(i) = argmax p(y(i)|x(i),v(i)) (11) Y(z) Then we use {(x(i), ˆy(i))}ni=m+1 in addition to the labeled data to train a supervised CRF model. This approach, however, does not have a theoretical guarantee on optimality unless certain nontrivial conditions are satisfied (Abney, 2004). On the other hand, it is well known that unlabeled data can be naturally incorporated using a generative approach that models a joint probability (Nigam et al., 2000). This is achieved by maximizing a marginal distribution of the joint probability over hidden variables. Inspired by the generative approach, we propose to explicitly model p(y, v|x). In contrast to Equation (8), here we jointly model y and v but the probability is still conditioned on x. This “joint” distribution should be chosen such that it results in the same conditional distribution p(y|x, v) as defined in Equation (8). To this end, we define pλ(y, v|x) as pλ(y,v|x) 1 Z0λ (x) H Dat) (x, yt−1, yt)φ(t) (yt−1, yt, vt) t (12) Here Z0λ(x) is a normalization function obtained by summing the num</context>
</contexts>
<marker>Nigam, Mccallum, Thrun, Mitchell, 2000</marker>
<rawString>Kamal Nigam, Andrew Kachites Mccallum, Sebastian Thrun, and Tom Mitchell. 2000. Text classification from labeled and unlabeled documents using EM. Machine Learning, 39:103–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judea Pearl</author>
</authors>
<title>Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference.</title>
<date>1988</date>
<publisher>Morgan Kaufmann,</publisher>
<contexts>
<context position="1447" citStr="Pearl (1988)" startWordPosition="223" endWordPosition="224">s the best known solutions reported on this task. 1 Introduction Statistical approaches to sequential labeling problems rely on necessary training data to model the uncertainty of a sequence of events. Human’s prior knowledge about the task, on the other hand, often requires minimum cognitive load to specify, and yet can provide information often complementary to that offered by a limited amount of training data. Whenever prior knowledge becomes available, it is desired that such information is integrated to a probabilistic model to improve learning. Virtual evidence (VE), first introduced by Pearl (1988), offers a principled and convenient way of incorporating external knowledge into Bayesian networks. In contrast to standard evidence (also known as observed variables), VE expresses a prior belief over values of random variables. It has been shown that VE can significantly extend the modeling power of Bayesian networks without complicating the fundamental inference methodology (Bilmes, 2004; Reynolds and Bilmes, 2005). This work extends the use of VE to undirected graphical models and, in particular, to conditional random fields (CRFs). We show that VE can be naturally encoded into an undirec</context>
</contexts>
<marker>Pearl, 1988</marker>
<rawString>Judea Pearl. 1988. Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, 2nd printing edition edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Quattoni</author>
<author>S Wang</author>
<author>L-P Morency</author>
<author>M Collins</author>
<author>T Darrell</author>
</authors>
<title>Hidden conditional random fields.</title>
<date>2007</date>
<journal>IEEE Transaction on Pattern Analysis and Machine Intellegence,</journal>
<volume>29</volume>
<issue>10</issue>
<contexts>
<context position="8407" citStr="Quattoni et al., 2007" startWordPosition="1338" endWordPosition="1341"> a CRF model as a new potential function. Semi-supervised learning is then conducted by iteratively (1) fixing the HMM and updating CRF parameters on labeled data and (2) fixing the CRF model and updating the HMM on unlabeled data. Additionally, when unlabeled instances have partial labeling information, it is possible to optimize a marginal distribution of the conditional likelihood, i.e., pλ(y(i) o |x), on unlabeled data. Here y(i) o is a subvector of y(i) that denotes the set of observed state variables. The optimization can be done in a similar fashion as training a hiddenstate CRF model (Quattoni et al., 2007). 3 Task We consider the problem of extracting fields from free-text advertisements. We use the CLASSIFIEDS data (Grenager et al., 2005) which consists of 8767 ads for apartment rental. 302 of the ads in the CLASSIFIEDS data have been manuallylabeled with 12 fields, including size, rent, neighborhood and so on. The labeled data has been divided into train/dev/test sets with 102/100/100 ads respectively. The evaluation metric is the tokenlevel accuracy where tokens include both words and punctuations. Our goal in this work is two folds: (1) leverage both the training data and the prior knowledg</context>
</contexts>
<marker>Quattoni, Wang, Morency, Collins, Darrell, 2007</marker>
<rawString>A. Quattoni, S. Wang, L.-P. Morency, M. Collins, and T. Darrell. 2007. Hidden conditional random fields. IEEE Transaction on Pattern Analysis and Machine Intellegence, 29(10):1848–1852.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheila Reynolds</author>
<author>Jeff Bilmes</author>
</authors>
<title>Part-of-speech tagging using virtual evidence and negative training.</title>
<date>2005</date>
<booktitle>In Proceedings ofHLT/EMNLP.</booktitle>
<contexts>
<context position="1869" citStr="Reynolds and Bilmes, 2005" startWordPosition="282" endWordPosition="285">ng data. Whenever prior knowledge becomes available, it is desired that such information is integrated to a probabilistic model to improve learning. Virtual evidence (VE), first introduced by Pearl (1988), offers a principled and convenient way of incorporating external knowledge into Bayesian networks. In contrast to standard evidence (also known as observed variables), VE expresses a prior belief over values of random variables. It has been shown that VE can significantly extend the modeling power of Bayesian networks without complicating the fundamental inference methodology (Bilmes, 2004; Reynolds and Bilmes, 2005). This work extends the use of VE to undirected graphical models and, in particular, to conditional random fields (CRFs). We show that VE can be naturally encoded into an undirected graphical model as potential functions. More importantly, we discuss a semi-supervised machine learning setting for estimating CRFs with the presence of VE. As the conditional likelihood objective of CRFs is not directly maximizable with respect to unlabeled data, we propose a novel semisupervised learning objective that can be optimized using the Expectation-Maximization (EM) algorithm while maintaining the discri</context>
<context position="6671" citStr="Reynolds and Bilmes (2005)" startWordPosition="1056" endWordPosition="1059">owledge, and the latter is estimated from unlabeled data. Our approach incorporates prior knowledge as virtual evidence to express preferences over the values of a set of random variables. The notion of VE was first introduced by Pearl (1998) and further developed by Bilmes (2004), both in the context of Bayesian networks. Different from constraint-driven learning, VE can be formally encoded as part of a graphical model. The fundamental inference methodology, therefore, does not need to be altered. Moreover, VE has the flexibility of representing various kinds of prior knowledge. For example, Reynolds and Bilmes (2005) use VE that explicitly favors self transitions in dynamic Bayesian networks. This work extends the use of VE to CRFs. In essence, VE herein can be viewed as probabilistic constraints in an undirected graph that allow exact inference. One of the biggest challenges of such a model lies in the semi-supervised machine learning setting. Since the entire state sequence of an unlabeled instance remains hidden, the conditional likelihood objective of CRFs is not directly optimizable. There have been a number of works that address this problem for conditional models. For example, minimum entropy regul</context>
</contexts>
<marker>Reynolds, Bilmes, 2005</marker>
<rawString>Sheila Reynolds and Jeff Bilmes. 2005. Part-of-speech tagging using virtual evidence and negative training. In Proceedings ofHLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
</authors>
<title>Semi-supervised sequential labeling and segmentation using gigaword scale unlabeled data.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL/HLT.</booktitle>
<contexts>
<context position="7635" citStr="Suzuki and Isozaki, 2008" startWordPosition="1206" endWordPosition="1209">e the entire state sequence of an unlabeled instance remains hidden, the conditional likelihood objective of CRFs is not directly optimizable. There have been a number of works that address this problem for conditional models. For example, minimum entropy regularization (Grandvalet and Bengio, 2004; Jiao et al., 2006), aims to maximize the conditional likelihood of labeled data while minimizing the conditional entropy of unlabeled data: log pλ(y(i)|x(i))− 1 2σ2 kλk2 −ρH(y|x) (3) This approach generally would result in “sharper” models which can be data-sensitive in practice. Another approach (Suzuki and Isozaki, 2008) embeds a joint probability model (HMM in their 1We slightly modify the notation here to be consistent with the rest of the paper. � i 1290 case) into a CRF model as a new potential function. Semi-supervised learning is then conducted by iteratively (1) fixing the HMM and updating CRF parameters on labeled data and (2) fixing the CRF model and updating the HMM on unlabeled data. Additionally, when unlabeled instances have partial labeling information, it is possible to optimize a marginal distribution of the conditional likelihood, i.e., pλ(y(i) o |x), on unlabeled data. Here y(i) o is a subve</context>
</contexts>
<marker>Suzuki, Isozaki, 2008</marker>
<rawString>Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised sequential labeling and segmentation using gigaword scale unlabeled data. In Proceedings of ACL/HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="5511" citStr="Yarowsky, 1995" startWordPosition="875" endWordPosition="876">rgmax λ · F(x, y) − � ρkd(y, 1Ck (x)) (1) Y k Here λ · F(x, y) is a linear decision function applicable to a number of sequential models, such as HMMs, MRFs and CRFs. Function d is implemented as the Hamming distance (or its approximation) between a hypothesis sequence and the space of state sequences that satisfy the constraint Ci. Due to the nature of the distance function, their work approximates EM training by finding the top K hypothesis sequences and using them as newly labeled instances to update the model. This process is repeated for a number of iterations in a self-training fashion (Yarowsky, 1995). Generalized expectation criteria (Mann and McCallum, 2008) represent prior knowledge as labeled features, and use such information to regularize semi-supervised learning for CRFs. Formally, their learning objective consists of the standard CRF training objective, plus a Gaussian prior on model parameters and an additional regularization term:1 � log pλ(y(i)|x(i))−1 i 2σ2 kλk2−ρD(ˆp||˜pλ) (2) In the last term, pˆ and ˜pλ both refer to conditional distributions of labels given a feature. While the former is specified by prior knowledge, and the latter is estimated from unlabeled data. Our appr</context>
<context position="16237" citStr="Yarowsky, 1995" startWordPosition="2790" endWordPosition="2791"> for all possible (yt−1, yt) pairs. In this work, we use a simple heuristics to detect sentence boundaries: we determine that xt is the start of a sentence if its previous token xt−1 is a period (.), a semi-colon (;) or an acclamation mark (!), and if xt is not a punctuation. 5.2 Semi-supervised learning When a large amount of unlabeled data is available, it is often helpful to leverage such data to improve learning. However, we cannot directly optimize p(y|x, v) since the correct state sequences of the unlabeled data are hidden. One heuristic approach is to adapt the self-training algorithm (Yarowsky, 1995) to our model. More specifically, for each input in the unlabeled dataset {x(i)}ni=m+1, we decode the best state sequence, ˆy(i) = argmax p(y(i)|x(i),v(i)) (11) Y(z) Then we use {(x(i), ˆy(i))}ni=m+1 in addition to the labeled data to train a supervised CRF model. This approach, however, does not have a theoretical guarantee on optimality unless certain nontrivial conditions are satisfied (Abney, 2004). On the other hand, it is well known that unlabeled data can be naturally incorporated using a generative approach that models a joint probability (Nigam et al., 2000). This is achieved by maxim</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings ofACL, pages 189–196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>