<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000675">
<title confidence="0.998557">
Multi-Task Transfer Learning for Weakly-Supervised Relation Extraction
</title>
<author confidence="0.99945">
Jing Jiang
</author>
<affiliation confidence="0.8852075">
School of Information Systems
Singapore Management University
</affiliation>
<address confidence="0.990217">
80 Stamford Road, Singapore 178902
</address>
<email confidence="0.99911">
jingjiang@smu.edu.sg
</email>
<sectionHeader confidence="0.993904" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999499875">
Creating labeled training data for rela-
tion extraction is expensive. In this pa-
per, we study relation extraction in a spe-
cial weakly-supervised setting when we
have only a few seed instances of the tar-
get relation type we want to extract but
we also have a large amount of labeled
instances of other relation types. Ob-
serving that different relation types can
share certain common structures, we pro-
pose to use a multi-task learning method
coupled with human guidance to address
this weakly-supervised relation extraction
problem. The proposed framework mod-
els the commonality among different re-
lation types through a shared weight vec-
tor, enables knowledge learned from the
auxiliary relation types to be transferred
to the target relation type, and allows easy
control of the tradeoff between precision
and recall. Empirical evaluation on the
ACE 2004 data set shows that the pro-
posed method substantially improves over
two baseline methods.
</bodyText>
<sectionHeader confidence="0.999129" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963111111111">
Relation extraction is the task of detecting and
characterizing semantic relations between entities
from free text. Recent work on relation extraction
has shown that supervised machine learning cou-
pled with intelligent feature engineering or ker-
nel design provides state-of-the-art solutions to the
problem (Culotta and Sorensen, 2004; Zhou et al.,
2005; Bunescu and Mooney, 2005; Qian et al.,
2008). However, supervised learning heavily re-
lies on a sufficient amount of labeled data for train-
ing, which is not always available in practice due
to the labor-intensive nature of human annotation.
This problem is especially serious for relation ex-
traction because the types of relations to be ex-
tracted are highly dependent on the application do-
main. For example, when working in the financial
domain we may be interested in the employment
relation, but when moving to the terrorism domain
we now may be interested in the ethnic and ide-
ology affiliation relation, and thus have to create
training data for the new relation type.
However, is the old training data really useless?
Inspired by recent work on transfer learning and
domain adaptation, in this paper, we study how
we can leverage labeled data of some old relation
types to help the extraction of a new relation type
in a weakly-supervised setting, where only a few
seed instances of the new relation type are avail-
able. While transfer learning was proposed more
than a decade ago (Thrun, 1996; Caruana, 1997),
its application in natural language processing is
still a relatively new territory (Blitzer et al., 2006;
Daume III, 2007; Jiang and Zhai, 2007a; Arnold et
al., 2008; Dredze and Crammer, 2008), and its ap-
plication in relation extraction is still unexplored.
Our idea of performing transfer learning is mo-
tivated by the observation that different relation
types share certain common syntactic structures,
which can possibly be transferred from the old
types to the new type. We therefore propose to use
a general multi-task learning framework in which
classification models for a number of related tasks
are forced to share a common model component
and trained together. By treating classification
of different relation types as related tasks, the
learning framework can naturally model the com-
mon syntactic structures among different relation
types in a principled manner. It also allows us
to introduce human guidance in separating the
common model component from the type-specific
components. The framework naturally transfers
the knowledge learned from the old relation types
to the new relation type and helps improve the re-
call of the relation extractor. We also exploit ad-
</bodyText>
<page confidence="0.968145">
1012
</page>
<note confidence="0.999609">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 1012–1020,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9998816">
ditional human knowledge about the entity type
constraints on the relation arguments, which can
usually be derived from the definition of a relation
type. Imposing these constraints further improves
the precision of the final relation extractor. Em-
pirical evaluation on the ACE 2004 data set shows
that our proposed method largely outperforms two
baseline methods, improving the average F1 mea-
sure from 0.1532 to 0.4132 when only 10 seed in-
stances of the new relation type are used.
</bodyText>
<sectionHeader confidence="0.999621" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999949061538462">
Recent work on relation extraction has been dom-
inated by feature-based and kernel-based super-
vised learning methods. Zhou et al. (2005) and
Zhao and Grishman (2005) studied various fea-
tures and feature combinations for relation extrac-
tion. We systematically explored the feature space
for relation extraction (Jiang and Zhai, 2007b) .
Kernel methods allow a large set of features to be
used without being explicitly extracted. A num-
ber of relation extraction kernels have been pro-
posed, including dependency tree kernels (Culotta
and Sorensen, 2004), shortest dependency path
kernels (Bunescu and Mooney, 2005) and more re-
cently convolution tree kernels (Zhang et al., 2006;
Qian et al., 2008). However, in both feature-based
and kernel-based studies, availability of sufficient
labeled training data is always assumed.
Chen et al. (2006) explored semi-supervised
learning for relation extraction using label prop-
agation, which makes use of unlabeled data.
Zhou et al. (2008) proposed a hierarchical learning
strategy to address the data sparseness problem in
relation extraction. They also considered the com-
monality among different relation types, but com-
pared with our work, they had a different problem
setting and a different way of modeling the com-
monality. Banko and Etzioni (2008) studied open
domain relation extraction, for which they man-
ually identified several common relation patterns.
In contrast, our method obtains common patterns
through statistical learning. Xu et al. (2008) stud-
ied the problem of adapting a rule-based relation
extraction system to new domains, but the types
of relations to be extracted remain the same.
Transfer learning aims at transferring knowl-
edge learned from one or a number of old tasks
to a new task. Domain adaptation is a spe-
cial case of transfer learning where the learn-
ing task remains the same but the distribution
of data changes. There has been an increasing
amount of work on transfer learning and domain
adaptation in natural language processing recently.
Blitzer et al. (2006) proposed a structural cor-
respondence learning method for domain adap-
tation and applied it to part-of-speech tagging.
Daume III (2007) proposed a simple feature aug-
mentation method to achieve domain adaptation.
Arnold et al. (2008) used a hierarchical prior struc-
ture to help transfer learning and domain adap-
tation for named entity recognition. Dredze and
Crammer (2008) proposed an online method for
multi-domain learning and adaptation.
Multi-task learning is another learning
paradigm in which multiple related tasks are
learned simultaneously in order to achieve better
performance for each individual task (Caruana,
1997; Evgeniou and Pontil, 2004). Although it
was not originally proposed to transfer knowledge
to a particular new task, it can be naturally used to
achieve this goal because it models the common-
ality among tasks, which is the knowledge that
should be transferred to a new task. In our work,
transfer learning is done through a multi-task
learning framework similar to Evgeniou and
Pontil (2004).
</bodyText>
<sectionHeader confidence="0.985045" genericHeader="method">
3 Task definition
</sectionHeader>
<bodyText confidence="0.999769095238095">
Our study is conducted using data from the Au-
tomatic Content Extraction (ACE) program1. We
focus on extracting binary relation instances be-
tween two relation arguments occurring in the
same sentence. Some example relation instances
and their corresponding relation types as defined
by ACE can be found in Table 1.
We consider the following weakly-supervised
problem setting. We are interested in extracting
instances of a target relation type T , but this re-
lation type is only specified by a small set of seed
instances. We may possibly have some additional
knowledge about the target type not in the form of
labeled instances. For example, we may be given
the entity type restrictions on the two relation ar-
guments. In addition to such limited information
about the target relation type, we also have a large
amount of labeled instances for K auxiliary rela-
tion types Al, ... , Ax. Our goal is to learn a re-
lation extractor for T, leveraging all the data and
information we have.
</bodyText>
<footnote confidence="0.992437">
1http://projects.ldc.upenn.edu/ace/
</footnote>
<page confidence="0.915367">
1013
</page>
<table confidence="0.9991067">
Syntactic Pattern Relation Instance Relation Type (Subtype)
arg-2 arg-1 Arab leaders OTHER-AFF (Ethnic)
his father PER-SOC (Family)
South Jakarta Prosecution Office GPE-AFF (Based-In)
arg-1 of arg-2 leader of a minority government EMP-ORG (Employ-Executive)
the youngest son of ex-director Suharto PER-SOC (Family)
the Socialist People’s Party of Montenegro GPE-AFF (Based-In)
arg-1 [verb] arg-2 Yemen [sent] planes to Baghdad ART (User-or-Owner)
his wife [had] three young children PER-SOC (Family)
Jody Scheckter [paced] Ferrari to both victories EMP-ORG (Employ-Staff)
</table>
<tableCaption confidence="0.9883875">
Table 1: Examples of similar syntactic structures across different relation types. The head words of the
first and the second arguments are shown in italic and bold, respectively.
</tableCaption>
<bodyText confidence="0.99994275">
Before introducing our transfer learning solu-
tion, let us first briefly explain our basic classifi-
cation approach and the features we use, as well
as two baseline solutions.
</bodyText>
<subsectionHeader confidence="0.997986">
3.1 Feature configuration
</subsectionHeader>
<bodyText confidence="0.999994333333333">
We treat relation extraction as a classification
problem. Each pair of entities within a single sen-
tence is considered a candidate relation instance,
and the task becomes predicting whether or not
each candidate is a true instance of T . We use
feature-based logistic regression classifiers. Fol-
lowing our previous work (Jiang and Zhai, 2007b),
we extract features from a sequence representa-
tion and a parse tree representation of each rela-
tion instance. Each node in the sequence or the
parse tree is augmented by an argument tag that
indicates whether the node subsumes arg-1, arg-
2, both or neither. Nodes that represent the argu-
ments are also labeled with the entity type, subtype
and mention type as defined by ACE. Based on the
findings of Qian et al. (2008), we trim the parse
tree of a relation instance so that it contains only
the most essential components. We extract uni-
gram features (consisting of a single node) and bi-
gram features (consisting of two connected nodes)
from the graphic representations. An example of
the graphic representation of a relation instance
is shown in Figure 1 and some features extracted
from this instance are shown in Table 2. This
feature configuration gives state-of-the-art perfor-
mance (F1 = 0.7223) on the ACE 2004 data set in
a standard setting with sufficient data for training.
</bodyText>
<subsectionHeader confidence="0.998328">
3.2 Baseline solutions
</subsectionHeader>
<bodyText confidence="0.9986265">
We consider two baseline solutions to the weakly-
supervised relation extraction problem. In the first
</bodyText>
<figureCaption confidence="0.723327">
Figure 1: The combined sequence and parse tree
</figureCaption>
<bodyText confidence="0.9131878">
representation of the relation instance “leader of
a minority government.” The non-essential nodes
for “a” and for “minority” are removed based on
the algorithm from Qian et al. (2008).
Feature Explanation
ORG2 arg-2 is an ORG entity.
of0 government2 arg-2 is “government” and
follows the word “of.”
NP3 , PP2 There is a noun phrase
containing both arguments,
with arg-2 contained in a
prepositional phrase inside
the noun phrase.
Table 2: Examples of unigram and bigram features
extracted from Figure 1.
baseline, we use only the few seed instances of the
target relation type together with labeled negative
relation instances (i.e. pairs of entities within the
same sentence but having no relation) to train a
binary classifier. In the second baseline, we take
the union of the positive instances of both the tar-
get relation type and the auxiliary relation types as
our positive training set, and together with the neg-
ative instances we train a binary classifier. Note
that the second baseline method essentially learns
</bodyText>
<page confidence="0.979064">
1014
</page>
<bodyText confidence="0.991671428571429">
a classifier for any relation type.
Another existing solution to weakly-supervised
learning problems is semi-supervised learning,
e.g. bootstrapping. However, because our pro-
posed transfer learning method can be combined
with semi-supervised learning, here we do not in-
clude semi-supervised learning as a baseline.
</bodyText>
<sectionHeader confidence="0.984647" genericHeader="method">
4 A multi-task transfer learning solution
</sectionHeader>
<bodyText confidence="0.99998075">
We now present a multi-task transfer learning so-
lution to the weakly-supervised relation extraction
problem, which makes use of the labeled data from
the auxiliary relation types.
</bodyText>
<subsectionHeader confidence="0.9295115">
4.1 Syntactic similarity between relation
types
</subsectionHeader>
<bodyText confidence="0.999954222222222">
To see why the auxiliary relation types may help
the identification of the target relation type, let us
first look at how different relation types may be re-
lated and even similar to each other. Based on our
inspection of a sample of the ACE data, we find
that instances of different relation types can share
certain common syntactic structures. For example,
the syntactic pattern “arg-1 of arg-2” strongly in-
dicates that there exists some relation between the
two arguments, although the nature of the relation
may be well dependent on the semantic meanings
of the two arguments. More examples are shown
in Table 1. This observation suggests that some
of the syntactic patterns learned from the auxiliary
relation types may be transferable to the target re-
lation type, making it easier to learn the target rela-
tion type and thus alleviating the insufficient train-
ing data problem with the target type.
How can we incorporate this desired knowledge
transfer process into our learning method? While
one can make explicit use of these general syntac-
tic patterns in a rule-based relation extraction sys-
tem, here we restrict our attention to feature-based
linear classifiers. We note that in feature-based lin-
ear classifiers, a useful syntactic pattern is trans-
lated into large weights for features related to the
syntactic pattern. For example, if “arg-1 of arg-2”
is a useful pattern, in the learned linear classifier
we should have relatively large weights for fea-
tures such as “the word of occurs before arg-2” or
“a preposition occurs before arg-2,” or even more
complex features such as “there is a prepositional
phrase containing arg-2 attached to arg-1.” It is
the weights of these generally useful features that
are transferable from the auxiliary relation types
to the target relation type.
</bodyText>
<subsectionHeader confidence="0.980989">
4.2 Statistical learning model
</subsectionHeader>
<bodyText confidence="0.999588466666667">
As we have discussed, we want to force the linear
classifiers for different relation types to share their
model weights for those features that are related
to the common syntactic patterns. Formally, we
consider the following statistical learning model.
Let ωk denote the weight vector of the linear
classifier that separates positive instances of aux-
iliary type Ak from negative instances, and let ωT
denote a similar weight vector for the target type
T . If different relation types are totally unrelated,
these weight vectors should also be independent of
each other. But because we observe similar syn-
tactic structures across different relation types, we
now assume that these weight vectors are related
through a common component ν:
</bodyText>
<equation confidence="0.999672">
= µT + ν,
ωk = µk + ν for k = 1,..., K.
</equation>
<bodyText confidence="0.986616904761905">
If we assume that only weights of certain gen-
eral features can be shared between different rela-
tion types, we can force certain dimensions of ν to
be 0. We express this constraint by introducing a
matrix F and setting Fν = 0. Here F is a square
matrix with all entries set to 0 except that Fi,i = 1
if we want to force νi = 0.
Now we can learn these weight vectors in a
multi-task learning framework. Let x represent
the feature vector of a candidate relation instance,
and y E {+1, −1} represent a class label. Let
DT = {(xT i , yT i )}NT
i=1 denote the set of labeled
instances for the target type T . (Note that the
number of positive instances in DT is very small.)
And let Dk = {(xki , yk i )}Nk
i=1 denote the labeled
instances for the auxiliary type Ak.
We learn the optimal weight vectors {µk}Kk=1,
µT and ν� by optimizing the following objective
function:
</bodyText>
<equation confidence="0.977484733333333">
C )
{�µk}K k=1, �µT , ν�
I
= arg min L(DT , µT + ν)
{µk},µ7&apos; ,ν,Fν=0
K
+E
k=1
Jλk µ�µk�2 + λν�ν�2 . (1)
T
ω
L(Dk, µk + ν)
K
+λTµ IIµTII2 + E
k=1
</equation>
<page confidence="0.944896">
1015
</page>
<bodyText confidence="0.996010166666667">
The objective function follows standard empir-
ical risk minimization with regularization. Here
L(D, w) is the aggregated loss of labeling x with
y for all (x, y) in D, using weight vector w. In
logistic regression models, the loss function is the
negative log likelihood, that is,
</bodyText>
<equation confidence="0.9614085">
L(D, w) = − � log p(y|x, w),
(x,y)ED
</equation>
<bodyText confidence="0.999955875">
ATµ , Ak µ and Aν are regularization parameters.
By adjusting their values, we can control the de-
gree of weight sharing among the relation types.
The larger the ratio ATµ /Aν (or Ak µ/Aν) is, the more
we believe that the model for T (or Ak) should
conform to the common model, and the smaller
the type-specific weight vector µT (or µk) will be.
The model presented above is based on our pre-
vious work (Jiang and Zhai, 2007c), which bears
the same spirit of some other recent work on multi-
task learning (Ando and Zhang, 2005; Evgeniou
and Pontil, 2004; Daume III, 2007). It is general
for any transfer learning problem with auxiliary la-
beled data from similar tasks. Here we are mostly
interested in the model’s applicability and effec-
tiveness on the relation extraction problem.
</bodyText>
<subsectionHeader confidence="0.996019">
4.3 Feature separation
</subsectionHeader>
<bodyText confidence="0.999959875">
Recall that we impose a constraint Fv = 0 when
optimizing the objective function. This constraint
gives us the freedom to force only the weights of a
subset of the features to be shared among different
relation types. A remaining question is how to set
this matrix F, that is, how to determine the set of
general features to use. We propose two ways of
setting this matrix F.
</bodyText>
<sectionHeader confidence="0.450106" genericHeader="method">
Automatically setting F
</sectionHeader>
<bodyText confidence="0.9999822">
One way is to fix the number of non-zero entries
in v to be a pre-defined number H of general fea-
tures, and allow F to change during the optimiza-
tion process. This can be done by repeating the
following two steps until F converges:
</bodyText>
<listItem confidence="0.9976975">
1. Fix F, and optimize the objective function as
in Equation (1).
2. Fix (µT + v) and (µk + v), and search for
µT , {µk} and v that minimizes (ATµ 11µT 112 +
</listItem>
<bodyText confidence="0.957741918918919">
EKk�1 Akµ11µk112 + Aν11v112), subject to the
constraint that at most H entries of v are non-
zero.
Human guidance
Another way to select the general features is to fol-
low some guidance from human knowledge. Re-
call that in Section 4.1 we find that the common-
ality among different relation types usually lies
in the syntactic structures between the two ar-
guments. This observation gives some intuition
about how to separate general features from type-
specific features. In particular, here we consider
two hypotheses regarding the generality of differ-
ent kinds of features.
Argument word features: We hypothesize that
the head words of the relation arguments are more
likely to be strong indicators of specific relation
types rather than any relation type. For example, if
an argument has the head word “sister,” it strongly
indicates a family relation. We refer to the set of
features that contain any head word of an argu-
ment as “arg-word” features.
Entity type features: We hypothesize that the
entity types and subtypes of the relation arguments
are also more likely to be associated with specific
relation types. For example, arguments that are
location entities may be strongly correlated with
physical proximity relations. We refer to the set of
features that contain the entity type or subtype of
an argument as “arg-NE” features.
We hypothesize that the arg-word and arg-NE
features are type-specific and therefore should be
excluded from the set of general features. We
can force the weights of these hypothesized type-
specific features to be 0 in the shared weight vec-
tor v, i.e. we can set the matrix F to achieve this
feature separation.
</bodyText>
<subsectionHeader confidence="0.771502">
Combined method
</subsectionHeader>
<bodyText confidence="0.9999865">
We can also combine the automatic way of setting
F with human guidance. Specifically, we still fol-
low the first automatic procedure to choose gen-
eral features, but we then filter out any hypothe-
sized type-specific feature from the set of general
features chosen by the automatic procedure.
</bodyText>
<subsectionHeader confidence="0.997016">
4.4 Imposing entity type constraints
</subsectionHeader>
<bodyText confidence="0.999996857142857">
Finally, we consider how we can exploit additional
human knowledge about the target relation type T
to further improve the classifier. We note that usu-
ally when a relation type is defined, we often have
strong preferences or even hard constraints on the
types of entities that can possibly be the two rela-
tion arguments. These type constraints can help us
</bodyText>
<equation confidence="0.997996333333333">
exp(wy · x)
p(y|x, w) =
Ey&apos;E1+1,−11 exp(wy&apos; · x)
</equation>
<page confidence="0.980376">
1016
</page>
<table confidence="0.99994896">
Target Type T BL BL-A TL-auto TL-guide TL-comb TL-NE
P 0.0000 0.1692 0.2920 0.2934 0.3325 0.5056
Physical R 0.0000 0.0848 0.1696 0.1722 0.2383 0.2316
F 0.0000 0.1130 0.2146 0.2170 0.2777 0.3176
Personal P 1.0000 0.0804 0.1005 0.3069 0.3214 0.6412
/Social R 0.0386 0.1708 0.1598 0.7245 0.7686 0.7631
F 0.0743 0.1093 0.1234 0.4311 0.4533 0.6969
Employment P 0.9231 0.3561 0.5230 0.5428 0.5973 0.7145
/Membership R 0.0075 0.1850 0.2617 0.2648 0.3632 0.3601
/Subsidiary F 0.0148 0.2435 0.3488 0.3559 0.4518 0.4789
Agent- P 0.8750 0.0603 0.1813 0.1825 0.1835 0.1967
Artifact R 0.0343 0.2353 0.6471 0.6225 0.6422 0.6373
F 0.0660 0.0960 0.2833 0.2822 0.2854 0.3006
PER/ORG P 0.8889 0.0838 0.1510 0.1592 0.1667 0.1844
Affiliation R 0.0567 0.4965 0.6950 0.8369 0.8794 0.8723
F 0.1067 0.1434 0.2481 0.2676 0.2802 0.3045
GPE P 1.0000 0.2530 0.3904 0.3604 0.3560 0.5824
Affiliation R 0.0077 0.4509 0.6416 0.5992 0.6166 0.6127
F 0.0153 0.3241 0.4854 0.4501 0.4513 0.5972
P 1.0000 0.0298 0.0503 0.0471 0.1370 0.1370
Discourse R 0.0036 0.0789 0.1075 0.1147 0.3477 0.3477
F 0.0071 0.0433 0.0685 0.0668 0.1966 0.1966
P 0.8124 0.1475 0.2412 0.2703 0.2992 0.4231
Average R 0.0212 0.2432 0.3832 0.4764 0.5509 0.5464
F 0.0406 0.1532 0.2532 0.2958 0.3423 0.4132
</table>
<tableCaption confidence="0.7664455">
Table 3: Comparison of different methods on ACE 2004 data set. P, R and F stand for precision, recall
and F1, respectively.
</tableCaption>
<bodyText confidence="0.999532857142857">
remove some false positive instances. We there-
fore manually identify the entity type constraints
for each target relation type based on the defini-
tion of the relation type given in the ACE annota-
tion guidelines, and impose these type constraints
as a final refinement step on top of the predicted
positive instances.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99996">
5.1 Data set and experiment setup
</subsectionHeader>
<bodyText confidence="0.999995291666667">
We used the ACE 2004 data set to evaluate our
proposed methods. There are seven relation types
defined in ACE 2004. After data cleaning, we ob-
tained 4290 positive instances among 48614 can-
didate relation instances. We took each relation
type as the target type and used the remaining
types as auxiliary types. This gave us seven sets
of experiments. In each set of experiments for a
single target relation type, we randomly divided
all the data into five subsets, and used each subset
for testing while using the other four subsets for
training, i.e. each experiment was repeated five
times with different training and test sets. Each
time, we removed most of the positive instances
of the target type from the training set except only
a small number S of seed instances. This gave
us the weakly-supervised setting. We kept all the
positive instances of the target type in the test set.
In order to concentrate on the classification accu-
racy for the target relation type, we removed the
positive instances of the auxiliary relation types
from the test set, although in practice we need
to extract these auxiliary relation instances using
learned classifiers for these relation types.
</bodyText>
<subsectionHeader confidence="0.999934">
5.2 Comparison of different methods
</subsectionHeader>
<bodyText confidence="0.999988428571429">
We first show the comparison of our proposed
multi-task transfer learning methods with the two
baseline methods described in Section 3.2. The
performance on each target relation type and the
average performance across seven types are shown
in Table 3. BL refers to the first baseline and BL-
A refers to the second baseline which uses auxil-
</bodyText>
<page confidence="0.979876">
1017
</page>
<table confidence="0.9995585">
λT µ 100 1000 10000
P 0.6265 0.3162 0.2992
R 0.1170 0.3959 0.5509
F 0.1847 0.2983 0.3423
</table>
<tableCaption confidence="0.901089">
Table 4: The average performance of TL-comb
</tableCaption>
<bodyText confidence="0.994265256410257">
with different λTµ . (λk µ = 104 and λ„ = 1.)
iary relation instances. The four TL methods are
all based on the multi-task transfer learning frame-
work. TL-auto sets F automatically within the
optimization problem itself. TL-guide chooses all
features except arg-word and arg-NE features as
general features and sets F accordingly. TL-comb
combines TL-auto and TL-guide, as described in
Section 4.3. Finally, TL-NE builds on top of TL-
comb and uses the entity type constraints to re-
fine the predictions. In this set of experiments,
the number of seed instances for each target re-
lation type was set to 10. The parameters were
set to their optimal values (λTµ = 104, λk µ = 104,
λ„ = 1, and H = 500).
As we can see from the table, first of all, BL
generally has high precision but very low recall.
BL-A performs better than BL in terms of F1 be-
cause it gives better recall. However, BL-A still
cannot achieve as high recall as the TL methods.
This is probably because the model learned by BL-
A still focuses more on type-specific features for
each relation type rather than on the commonly
useful general features, and therefore does not
help much in classifying the target relation type.
The four TL methods all outperform the two
baseline methods. TL-comb performs better than
both TL-auto and TL-guide, which shows that
while we can either choose general features au-
tomatically by the learning algorithm or manu-
ally with human knowledge, it is more effective
to combine human knowledge with the multi-task
learning framework. Not surprisingly, TL-NE im-
proves the precision over TL-comb without hurt-
ing the recall much. Ideally, TL-NE should not
decrease recall if the type constraints are strictly
observed in the data. We find that it is not always
the case with the ACE data, leading to the small
decrease of recall from TL-comb to TL-NE.
</bodyText>
<subsectionHeader confidence="0.965315">
5.3 The effect of λTµ
</subsectionHeader>
<bodyText confidence="0.998728333333333">
Let us now take a look at the effect of using dif-
ferent λTµ . As we can see from Table 4, smaller
λTµ gives higher precision while larger λTµ gives
</bodyText>
<figureCaption confidence="0.9042585">
Figure 2: Performance of TL-comb and TL-auto
as H changes.
</figureCaption>
<bodyText confidence="0.999916428571429">
higher recall. These results make sense because
the larger λTµ is, the more we penalize large
weights of µT . As a result, the model for the tar-
get type is forced to conform to the shared model
ν and prevented from overfitting the few seed tar-
get instances. λT µ is therefore a useful parameter
to help us control the tradeoff between precision
and recall for the target type.
While varying λk µ also gives similar effect for
type Ak, we found that setting λk µ to smaller values
would not help T because in this case the auxiliary
relation instances would be used more for train-
ing the type-specific component µk rather than the
common component ν.
</bodyText>
<subsectionHeader confidence="0.998807">
5.4 Sensitivity of H
</subsectionHeader>
<bodyText confidence="0.999992083333333">
Another parameter in the multi-task transfer learn-
ing framework is the number of general features
H, i.e. the number of non-zero entries in the
shared weight vector ν. To see how the perfor-
mance may vary as H changes, we plot the per-
formance of TL-comb and TL-auto in terms of the
average F1 across the seven target relation types,
with H ranging from 100 to 50000. As we can see
in Figure 2, the performance is relatively stable,
and always above BL-A. This suggests that the
performance of TL-comb and TL-auto is not very
sensitive to the value of H.
</bodyText>
<subsectionHeader confidence="0.991917">
5.5 Hypothesized type-specific features
</subsectionHeader>
<bodyText confidence="0.958001375">
In Section 4.3, we showed two sets of hypoth-
esized type-specific features, namely, arg-word
features and arg-NE features. We also experi-
mented with each set separately to see whether
both sets are useful. The comparison is shown in
Table 5. As we can see, using either set of type-
specific features in either TL-guide or TL-comb
can improve the performance over BL-A, but the
</bodyText>
<figure confidence="0.997932933333333">
100 1000 10000
H
avg F1
0.45
0.35
0.25
0.15
0.5
0.4
0.3
0.2
0.1
TL-comb
TL-auto
BL-A
</figure>
<page confidence="0.930237">
1018
</page>
<table confidence="0.9869185">
arg-word arg-NE union
TL-guide 0.2095 0.2983 0.2958
TL-comb 0.2215 0.3331 0.3423
BL-A 0.1532
</table>
<tableCaption confidence="0.9855975">
Table 5: Average F1 using different hypothesized
type-specific features.
</tableCaption>
<figure confidence="0.98565">
10 100 1000
S
</figure>
<figureCaption confidence="0.999388">
Figure 3: Performance of TL-NE, BL and BL-A
</figureCaption>
<bodyText confidence="0.856589666666666">
as the number of seed instances S of the target type
increases. (H = 500. aµ was set to 104 and 102).
arg-NE features are probably more type-specific
than arg-word features because they give better
performance. Using the union of the two sets is
still the best for TL-comb.
</bodyText>
<subsectionHeader confidence="0.991336">
5.6 Changing the number of seed instances
</subsectionHeader>
<bodyText confidence="0.999965863636364">
Finally, we compare TL-NE with BL and BL-A
when the number of seed instances increases. We
set S from 5 up to 1000. When S is large, the
problem becomes more like traditional supervised
learning, and our setting of aµ = 104 is no longer
optimal because we are now not afraid of overfit-
ting the large set of seed target instances. There-
fore we also included another TL-NE experiment
with aµ set to 102. The comparison of the perfor-
mance is shown in Figure 3. We see that as S in-
creases, both BL and BL-A catch up, and BL over-
takes BL-A when S is sufficiently large because
BL uses positive training examples only from the
target type. Overall, TL-NE still outperforms the
two baselines in most of the cases over the wide
range of values of S, but the optimal value for aµ
decreases as S increases, as we have suspected.
The results show that if aµ is set appropriately,
our multi-task transfer learning method is robust
and advantageous over the baselines under both
the weakly-supervised setting and the traditional
supervised setting.
</bodyText>
<sectionHeader confidence="0.991538" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999980837209302">
In this paper, we applied multi-task transfer learn-
ing to solve a weakly-supervised relation extrac-
tion problem, leveraging both labeled instances of
auxiliary relation types and human knowledge in-
cluding hypotheses on feature generality and en-
tity type constraints. In the multi-task learning
framework that we introduced, different relation
types are treated as different but related tasks that
are learned together, with the common structures
among the relation types modeled by a shared
weight vector. The shared weight vector corre-
sponds to the general features across different re-
lation types. We proposed to choose the general
features either automatically inside the learning al-
gorithm or guided by human knowledge. We also
leveraged additional human knowledge about the
target relation type in the form of entity type con-
straints. Experiment results on the ACE 2004 data
show that the multi-task transfer learning method
achieves the best performance when we combine
human guidance with automatic general feature
selection, followed by imposing the entity type
constraints. The final method substantially outper-
forms two baseline methods, improving the aver-
age F1 measure from 0.1532 to 0.4132 when only
10 seed target instances are used.
Our work is the first to explore transfer learning
for relation extraction, and we have achieved very
promising results. Because of the practical impor-
tance of transfer learning and adaptation for rela-
tion extraction due to lack of training data in new
domains, we hope our study and findings will lead
to further investigation into this problem. There
are still many issues that remain unsolved. For ex-
ample, we have not looked at the degrees of re-
latedness between different pairs of relation types.
Presumably, when adapting to a specific target re-
lation type, we want to choose the most similar
auxiliary relation types to use. Our current study
is based on ACE relation types. It would also be
interesting to study similar problems in other do-
mains, for example, the protein-protein interaction
extraction problem in biomedical text mining.
</bodyText>
<sectionHeader confidence="0.985409" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.56013925">
Rie Kubota Ando and Tong Zhang. 2005. A frame-
work for learning predictive structures from multi-
ple tasks and unlabeled data. Journal of Machine
Learning Research, 6:1817–1853, November.
</bodyText>
<figure confidence="0.997818666666666">
avg F1
0.6
0.5
0.4
0.3
0.2
0.1
0
TL-NE (102)
TL-NE (10 )
BL
BL-A
</figure>
<page confidence="0.980625">
1019
</page>
<reference confidence="0.999924467391304">
Andrew Arnold, Ramesh Nallapati, and William W.
Cohen. 2008. Exploiting feature hierarchy for
transfer learning in named entity recognition. In
Proceedings of the 46th Annual Meeting of the As-
sociation for Computational Linguistics, pages 245–
253.
Michele Banko and Oren Etzioni. 2008. The tradeoffs
between open and traditional relation extraction. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 28–36.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 120–128.
Razvan Bunescu and Raymond Mooney. 2005. A
shortest path dependency kernel for relation extrac-
tion. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
724–731.
Rich Caruana. 1997. Multitask learning. Machine
Learning, 28:41–75.
Jinxiu Chen, Donghong Ji, Chew Lim Tan, and
Zhengyu Niu. 2006. Relation extraction using la-
bel propagation based semi-supervised learning. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 129–136.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings
of the 42nd Meeting of the Association for Compu-
tational Linguistics, pages 423–429.
Hal Daume III. 2007. Frustratingly easy domain adap-
tation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 256–263.
Mark Dredze and Koby Crammer. 2008. Online
methods for multi-domain learning and adaptation.
In Proceedings of the 2008 Conference on Empiri-
cal Methods in Natural Language Processing, pages
689–697.
Theodoros Evgeniou and Massimiliano Pontil. 2004.
Regularized multi-task learning. In Proceedings of
the 10th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pages 109–
117.
Jing Jiang and ChengXiang Zhai. 2007a. Instance
weighting for domain adaptation in nlp. In Proceed-
ings of the 45th Annual Meeting of the Association
for Computational Linguistics, pages 264–271.
Jing Jiang and ChengXiang Zhai. 2007b. A systematic
exploration of the feature space for relation extrac-
tion. In Proceedings of the Human Language Tech-
nologies Conference, pages 113–120.
Jing Jiang and ChengXiang Zhai. 2007c. A two-stage
approach to domain adaptation for statistical classi-
fiers. In Proceedings of the 16th ACM Conference
on Information and Knowledge Management, pages
401–410.
Longhua Qian, Guodong Zhou, Fang Kong, Qiaom-
ing Zhu, and Peide Qian. 2008. Exploiting con-
stituent dependencies for tree kernel-based semantic
relation extraction. In Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics, pages 697–704.
Sebastian Thrun. 1996. Is learning the n-th thing any
easier than learning the first? In Advances in Neural
Information Processing Systems 8, pages 640–646.
Feiyu Xu, Hans Uszkoreit, Hong Li, and Niko Felger.
2008. Adaptation of relation extraction rules to new
domains. In Proceedings of the 6th International
Conference on Language Resources and Evaluation,
pages 2446–2450.
Min Zhang, Jie Zhang, and Jian Su. 2006. Exploring
syntactic features for relation extraction using a con-
volution tree kernel. In Proceedings of the Human
Language Technology Conference, pages 288–295.
Shubin Zhao and Ralph Grishman. 2005. Extracting
relations with integrated information using kernel
methods. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 419–426.
GuoDong Zhou, Jian Su, Jie Zhang, and Min Zhang.
2005. Exploring various knowledge in relation ex-
traction. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 427–434.
GuoDong Zhou, Min Zhang, DongHong Ji, and
QiaoMing Zhu. 2008. Hierarchical learning strat-
egy in semantic relation extraction. Information
Processing and Management, 44(3):1008–1021.
</reference>
<page confidence="0.990656">
1020
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.972694">
<title confidence="0.999679">Multi-Task Transfer Learning for Weakly-Supervised Relation Extraction</title>
<author confidence="0.999681">Jing Jiang</author>
<affiliation confidence="0.998002">School of Information Systems Singapore Management University</affiliation>
<address confidence="0.998027">80 Stamford Road, Singapore 178902</address>
<email confidence="0.98443">jingjiang@smu.edu.sg</email>
<abstract confidence="0.99976868">Creating labeled training data for relation extraction is expensive. In this paper, we study relation extraction in a special weakly-supervised setting when we have only a few seed instances of the target relation type we want to extract but we also have a large amount of labeled instances of other relation types. Observing that different relation types can share certain common structures, we propose to use a multi-task learning method coupled with human guidance to address this weakly-supervised relation extraction problem. The proposed framework models the commonality among different relation types through a shared weight vector, enables knowledge learned from the auxiliary relation types to be transferred to the target relation type, and allows easy control of the tradeoff between precision and recall. Empirical evaluation on the ACE 2004 data set shows that the proposed method substantially improves over two baseline methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrew Arnold</author>
<author>Ramesh Nallapati</author>
<author>William W Cohen</author>
</authors>
<title>Exploiting feature hierarchy for transfer learning in named entity recognition.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>245--253</pages>
<contexts>
<context position="2802" citStr="Arnold et al., 2008" startWordPosition="439" endWordPosition="442">ation type. However, is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a number of related tasks are forced to share a common model component and trained together. By treating classification of different relation types as related tasks, the learning framework</context>
<context position="6739" citStr="Arnold et al. (2008)" startWordPosition="1058" endWordPosition="1061">ansfer learning aims at transferring knowledge learned from one or a number of old tasks to a new task. Domain adaptation is a special case of transfer learning where the learning task remains the same but the distribution of data changes. There has been an increasing amount of work on transfer learning and domain adaptation in natural language processing recently. Blitzer et al. (2006) proposed a structural correspondence learning method for domain adaptation and applied it to part-of-speech tagging. Daume III (2007) proposed a simple feature augmentation method to achieve domain adaptation. Arnold et al. (2008) used a hierarchical prior structure to help transfer learning and domain adaptation for named entity recognition. Dredze and Crammer (2008) proposed an online method for multi-domain learning and adaptation. Multi-task learning is another learning paradigm in which multiple related tasks are learned simultaneously in order to achieve better performance for each individual task (Caruana, 1997; Evgeniou and Pontil, 2004). Although it was not originally proposed to transfer knowledge to a particular new task, it can be naturally used to achieve this goal because it models the commonality among t</context>
</contexts>
<marker>Arnold, Nallapati, Cohen, 2008</marker>
<rawString>Andrew Arnold, Ramesh Nallapati, and William W. Cohen. 2008. Exploiting feature hierarchy for transfer learning in named entity recognition. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, pages 245– 253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
</authors>
<title>The tradeoffs between open and traditional relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>28--36</pages>
<contexts>
<context position="5763" citStr="Banko and Etzioni (2008)" startWordPosition="902" endWordPosition="905">al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types, but compared with our work, they had a different problem setting and a different way of modeling the commonality. Banko and Etzioni (2008) studied open domain relation extraction, for which they manually identified several common relation patterns. In contrast, our method obtains common patterns through statistical learning. Xu et al. (2008) studied the problem of adapting a rule-based relation extraction system to new domains, but the types of relations to be extracted remain the same. Transfer learning aims at transferring knowledge learned from one or a number of old tasks to a new task. Domain adaptation is a special case of transfer learning where the learning task remains the same but the distribution of data changes. Ther</context>
</contexts>
<marker>Banko, Etzioni, 2008</marker>
<rawString>Michele Banko and Oren Etzioni. 2008. The tradeoffs between open and traditional relation extraction. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>120--128</pages>
<contexts>
<context position="2741" citStr="Blitzer et al., 2006" startWordPosition="428" endWordPosition="431">elation, and thus have to create training data for the new relation type. However, is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a number of related tasks are forced to share a common model component and trained together. By treating classification of diff</context>
<context position="6508" citStr="Blitzer et al. (2006)" startWordPosition="1023" endWordPosition="1026">our method obtains common patterns through statistical learning. Xu et al. (2008) studied the problem of adapting a rule-based relation extraction system to new domains, but the types of relations to be extracted remain the same. Transfer learning aims at transferring knowledge learned from one or a number of old tasks to a new task. Domain adaptation is a special case of transfer learning where the learning task remains the same but the distribution of data changes. There has been an increasing amount of work on transfer learning and domain adaptation in natural language processing recently. Blitzer et al. (2006) proposed a structural correspondence learning method for domain adaptation and applied it to part-of-speech tagging. Daume III (2007) proposed a simple feature augmentation method to achieve domain adaptation. Arnold et al. (2008) used a hierarchical prior structure to help transfer learning and domain adaptation for named entity recognition. Dredze and Crammer (2008) proposed an online method for multi-domain learning and adaptation. Multi-task learning is another learning paradigm in which multiple related tasks are learned simultaneously in order to achieve better performance for each indi</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 120–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>724--731</pages>
<contexts>
<context position="1547" citStr="Bunescu and Mooney, 2005" startWordPosition="228" endWordPosition="231">red to the target relation type, and allows easy control of the tradeoff between precision and recall. Empirical evaluation on the ACE 2004 data set shows that the proposed method substantially improves over two baseline methods. 1 Introduction Relation extraction is the task of detecting and characterizing semantic relations between entities from free text. Recent work on relation extraction has shown that supervised machine learning coupled with intelligent feature engineering or kernel design provides state-of-the-art solutions to the problem (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008). However, supervised learning heavily relies on a sufficient amount of labeled data for training, which is not always available in practice due to the labor-intensive nature of human annotation. This problem is especially serious for relation extraction because the types of relations to be extracted are highly dependent on the application domain. For example, when working in the financial domain we may be interested in the employment relation, but when moving to the terrorism domain we now may be interested in the ethnic and ideology affiliation relation, and thus have to </context>
<context position="5085" citStr="Bunescu and Mooney, 2005" startWordPosition="798" endWordPosition="801">2 Related work Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types, but compared with our work, they had a different problem set</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan Bunescu and Raymond Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 724–731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich Caruana</author>
</authors>
<date>1997</date>
<booktitle>Multitask learning. Machine Learning,</booktitle>
<pages>28--41</pages>
<contexts>
<context position="2635" citStr="Caruana, 1997" startWordPosition="414" endWordPosition="415">hen moving to the terrorism domain we now may be interested in the ethnic and ideology affiliation relation, and thus have to create training data for the new relation type. However, is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a number of related t</context>
<context position="7134" citStr="Caruana, 1997" startWordPosition="1117" endWordPosition="1118">tructural correspondence learning method for domain adaptation and applied it to part-of-speech tagging. Daume III (2007) proposed a simple feature augmentation method to achieve domain adaptation. Arnold et al. (2008) used a hierarchical prior structure to help transfer learning and domain adaptation for named entity recognition. Dredze and Crammer (2008) proposed an online method for multi-domain learning and adaptation. Multi-task learning is another learning paradigm in which multiple related tasks are learned simultaneously in order to achieve better performance for each individual task (Caruana, 1997; Evgeniou and Pontil, 2004). Although it was not originally proposed to transfer knowledge to a particular new task, it can be naturally used to achieve this goal because it models the commonality among tasks, which is the knowledge that should be transferred to a new task. In our work, transfer learning is done through a multi-task learning framework similar to Evgeniou and Pontil (2004). 3 Task definition Our study is conducted using data from the Automatic Content Extraction (ACE) program1. We focus on extracting binary relation instances between two relation arguments occurring in the sam</context>
</contexts>
<marker>Caruana, 1997</marker>
<rawString>Rich Caruana. 1997. Multitask learning. Machine Learning, 28:41–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxiu Chen</author>
<author>Donghong Ji</author>
<author>Chew Lim Tan</author>
<author>Zhengyu Niu</author>
</authors>
<title>Relation extraction using label propagation based semi-supervised learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>129--136</pages>
<contexts>
<context position="5313" citStr="Chen et al. (2006)" startWordPosition="833" endWordPosition="836">elation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types, but compared with our work, they had a different problem setting and a different way of modeling the commonality. Banko and Etzioni (2008) studied open domain relation extraction, for which they manually identified several common relation patterns. In contrast, our method obtains common </context>
</contexts>
<marker>Chen, Ji, Tan, Niu, 2006</marker>
<rawString>Jinxiu Chen, Donghong Ji, Chew Lim Tan, and Zhengyu Niu. 2006. Relation extraction using label propagation based semi-supervised learning. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 129–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--429</pages>
<contexts>
<context position="1502" citStr="Culotta and Sorensen, 2004" startWordPosition="220" endWordPosition="223">rom the auxiliary relation types to be transferred to the target relation type, and allows easy control of the tradeoff between precision and recall. Empirical evaluation on the ACE 2004 data set shows that the proposed method substantially improves over two baseline methods. 1 Introduction Relation extraction is the task of detecting and characterizing semantic relations between entities from free text. Recent work on relation extraction has shown that supervised machine learning coupled with intelligent feature engineering or kernel design provides state-of-the-art solutions to the problem (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008). However, supervised learning heavily relies on a sufficient amount of labeled data for training, which is not always available in practice due to the labor-intensive nature of human annotation. This problem is especially serious for relation extraction because the types of relations to be extracted are highly dependent on the application domain. For example, when working in the financial domain we may be interested in the employment relation, but when moving to the terrorism domain we now may be interested in the ethnic and ide</context>
<context position="5024" citStr="Culotta and Sorensen, 2004" startWordPosition="790" endWordPosition="793">when only 10 seed instances of the new relation type are used. 2 Related work Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types,</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, pages 423–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>256--263</pages>
<marker>Daume, 2007</marker>
<rawString>Hal Daume III. 2007. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 256–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
</authors>
<title>Online methods for multi-domain learning and adaptation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>689--697</pages>
<contexts>
<context position="2829" citStr="Dredze and Crammer, 2008" startWordPosition="443" endWordPosition="446">is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a number of related tasks are forced to share a common model component and trained together. By treating classification of different relation types as related tasks, the learning framework can naturally model the co</context>
<context position="6879" citStr="Dredze and Crammer (2008)" startWordPosition="1080" endWordPosition="1083">case of transfer learning where the learning task remains the same but the distribution of data changes. There has been an increasing amount of work on transfer learning and domain adaptation in natural language processing recently. Blitzer et al. (2006) proposed a structural correspondence learning method for domain adaptation and applied it to part-of-speech tagging. Daume III (2007) proposed a simple feature augmentation method to achieve domain adaptation. Arnold et al. (2008) used a hierarchical prior structure to help transfer learning and domain adaptation for named entity recognition. Dredze and Crammer (2008) proposed an online method for multi-domain learning and adaptation. Multi-task learning is another learning paradigm in which multiple related tasks are learned simultaneously in order to achieve better performance for each individual task (Caruana, 1997; Evgeniou and Pontil, 2004). Although it was not originally proposed to transfer knowledge to a particular new task, it can be naturally used to achieve this goal because it models the commonality among tasks, which is the knowledge that should be transferred to a new task. In our work, transfer learning is done through a multi-task learning </context>
</contexts>
<marker>Dredze, Crammer, 2008</marker>
<rawString>Mark Dredze and Koby Crammer. 2008. Online methods for multi-domain learning and adaptation. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 689–697.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theodoros Evgeniou</author>
<author>Massimiliano Pontil</author>
</authors>
<title>Regularized multi-task learning.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>109--117</pages>
<contexts>
<context position="7162" citStr="Evgeniou and Pontil, 2004" startWordPosition="1119" endWordPosition="1122">spondence learning method for domain adaptation and applied it to part-of-speech tagging. Daume III (2007) proposed a simple feature augmentation method to achieve domain adaptation. Arnold et al. (2008) used a hierarchical prior structure to help transfer learning and domain adaptation for named entity recognition. Dredze and Crammer (2008) proposed an online method for multi-domain learning and adaptation. Multi-task learning is another learning paradigm in which multiple related tasks are learned simultaneously in order to achieve better performance for each individual task (Caruana, 1997; Evgeniou and Pontil, 2004). Although it was not originally proposed to transfer knowledge to a particular new task, it can be naturally used to achieve this goal because it models the commonality among tasks, which is the knowledge that should be transferred to a new task. In our work, transfer learning is done through a multi-task learning framework similar to Evgeniou and Pontil (2004). 3 Task definition Our study is conducted using data from the Automatic Content Extraction (ACE) program1. We focus on extracting binary relation instances between two relation arguments occurring in the same sentence. Some example rel</context>
<context position="17118" citStr="Evgeniou and Pontil, 2004" startWordPosition="2784" endWordPosition="2787">the negative log likelihood, that is, L(D, w) = − � log p(y|x, w), (x,y)ED ATµ , Ak µ and Aν are regularization parameters. By adjusting their values, we can control the degree of weight sharing among the relation types. The larger the ratio ATµ /Aν (or Ak µ/Aν) is, the more we believe that the model for T (or Ak) should conform to the common model, and the smaller the type-specific weight vector µT (or µk) will be. The model presented above is based on our previous work (Jiang and Zhai, 2007c), which bears the same spirit of some other recent work on multitask learning (Ando and Zhang, 2005; Evgeniou and Pontil, 2004; Daume III, 2007). It is general for any transfer learning problem with auxiliary labeled data from similar tasks. Here we are mostly interested in the model’s applicability and effectiveness on the relation extraction problem. 4.3 Feature separation Recall that we impose a constraint Fv = 0 when optimizing the objective function. This constraint gives us the freedom to force only the weights of a subset of the features to be shared among different relation types. A remaining question is how to set this matrix F, that is, how to determine the set of general features to use. We propose two way</context>
</contexts>
<marker>Evgeniou, Pontil, 2004</marker>
<rawString>Theodoros Evgeniou and Massimiliano Pontil. 2004. Regularized multi-task learning. In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 109– 117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Instance weighting for domain adaptation in nlp.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>264--271</pages>
<contexts>
<context position="2780" citStr="Jiang and Zhai, 2007" startWordPosition="435" endWordPosition="438">ng data for the new relation type. However, is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a number of related tasks are forced to share a common model component and trained together. By treating classification of different relation types as related tasks, </context>
<context position="4805" citStr="Jiang and Zhai, 2007" startWordPosition="755" endWordPosition="758">sion of the final relation extractor. Empirical evaluation on the ACE 2004 data set shows that our proposed method largely outperforms two baseline methods, improving the average F1 measure from 0.1532 to 0.4132 when only 10 seed instances of the new relation type are used. 2 Related work Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which ma</context>
<context position="9862" citStr="Jiang and Zhai, 2007" startWordPosition="1543" endWordPosition="1546">the first and the second arguments are shown in italic and bold, respectively. Before introducing our transfer learning solution, let us first briefly explain our basic classification approach and the features we use, as well as two baseline solutions. 3.1 Feature configuration We treat relation extraction as a classification problem. Each pair of entities within a single sentence is considered a candidate relation instance, and the task becomes predicting whether or not each candidate is a true instance of T . We use feature-based logistic regression classifiers. Following our previous work (Jiang and Zhai, 2007b), we extract features from a sequence representation and a parse tree representation of each relation instance. Each node in the sequence or the parse tree is augmented by an argument tag that indicates whether the node subsumes arg-1, arg2, both or neither. Nodes that represent the arguments are also labeled with the entity type, subtype and mention type as defined by ACE. Based on the findings of Qian et al. (2008), we trim the parse tree of a relation instance so that it contains only the most essential components. We extract unigram features (consisting of a single node) and bigram featu</context>
<context position="16990" citStr="Jiang and Zhai, 2007" startWordPosition="2762" endWordPosition="2765"> loss of labeling x with y for all (x, y) in D, using weight vector w. In logistic regression models, the loss function is the negative log likelihood, that is, L(D, w) = − � log p(y|x, w), (x,y)ED ATµ , Ak µ and Aν are regularization parameters. By adjusting their values, we can control the degree of weight sharing among the relation types. The larger the ratio ATµ /Aν (or Ak µ/Aν) is, the more we believe that the model for T (or Ak) should conform to the common model, and the smaller the type-specific weight vector µT (or µk) will be. The model presented above is based on our previous work (Jiang and Zhai, 2007c), which bears the same spirit of some other recent work on multitask learning (Ando and Zhang, 2005; Evgeniou and Pontil, 2004; Daume III, 2007). It is general for any transfer learning problem with auxiliary labeled data from similar tasks. Here we are mostly interested in the model’s applicability and effectiveness on the relation extraction problem. 4.3 Feature separation Recall that we impose a constraint Fv = 0 when optimizing the objective function. This constraint gives us the freedom to force only the weights of a subset of the features to be shared among different relation types. A </context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007a. Instance weighting for domain adaptation in nlp. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, pages 264–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A systematic exploration of the feature space for relation extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the Human Language Technologies Conference,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="2780" citStr="Jiang and Zhai, 2007" startWordPosition="435" endWordPosition="438">ng data for the new relation type. However, is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a number of related tasks are forced to share a common model component and trained together. By treating classification of different relation types as related tasks, </context>
<context position="4805" citStr="Jiang and Zhai, 2007" startWordPosition="755" endWordPosition="758">sion of the final relation extractor. Empirical evaluation on the ACE 2004 data set shows that our proposed method largely outperforms two baseline methods, improving the average F1 measure from 0.1532 to 0.4132 when only 10 seed instances of the new relation type are used. 2 Related work Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which ma</context>
<context position="9862" citStr="Jiang and Zhai, 2007" startWordPosition="1543" endWordPosition="1546">the first and the second arguments are shown in italic and bold, respectively. Before introducing our transfer learning solution, let us first briefly explain our basic classification approach and the features we use, as well as two baseline solutions. 3.1 Feature configuration We treat relation extraction as a classification problem. Each pair of entities within a single sentence is considered a candidate relation instance, and the task becomes predicting whether or not each candidate is a true instance of T . We use feature-based logistic regression classifiers. Following our previous work (Jiang and Zhai, 2007b), we extract features from a sequence representation and a parse tree representation of each relation instance. Each node in the sequence or the parse tree is augmented by an argument tag that indicates whether the node subsumes arg-1, arg2, both or neither. Nodes that represent the arguments are also labeled with the entity type, subtype and mention type as defined by ACE. Based on the findings of Qian et al. (2008), we trim the parse tree of a relation instance so that it contains only the most essential components. We extract unigram features (consisting of a single node) and bigram featu</context>
<context position="16990" citStr="Jiang and Zhai, 2007" startWordPosition="2762" endWordPosition="2765"> loss of labeling x with y for all (x, y) in D, using weight vector w. In logistic regression models, the loss function is the negative log likelihood, that is, L(D, w) = − � log p(y|x, w), (x,y)ED ATµ , Ak µ and Aν are regularization parameters. By adjusting their values, we can control the degree of weight sharing among the relation types. The larger the ratio ATµ /Aν (or Ak µ/Aν) is, the more we believe that the model for T (or Ak) should conform to the common model, and the smaller the type-specific weight vector µT (or µk) will be. The model presented above is based on our previous work (Jiang and Zhai, 2007c), which bears the same spirit of some other recent work on multitask learning (Ando and Zhang, 2005; Evgeniou and Pontil, 2004; Daume III, 2007). It is general for any transfer learning problem with auxiliary labeled data from similar tasks. Here we are mostly interested in the model’s applicability and effectiveness on the relation extraction problem. 4.3 Feature separation Recall that we impose a constraint Fv = 0 when optimizing the objective function. This constraint gives us the freedom to force only the weights of a subset of the features to be shared among different relation types. A </context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007b. A systematic exploration of the feature space for relation extraction. In Proceedings of the Human Language Technologies Conference, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Jiang</author>
<author>ChengXiang Zhai</author>
</authors>
<title>A two-stage approach to domain adaptation for statistical classifiers.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th ACM Conference on Information and Knowledge Management,</booktitle>
<pages>401--410</pages>
<contexts>
<context position="2780" citStr="Jiang and Zhai, 2007" startWordPosition="435" endWordPosition="438">ng data for the new relation type. However, is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a number of related tasks are forced to share a common model component and trained together. By treating classification of different relation types as related tasks, </context>
<context position="4805" citStr="Jiang and Zhai, 2007" startWordPosition="755" endWordPosition="758">sion of the final relation extractor. Empirical evaluation on the ACE 2004 data set shows that our proposed method largely outperforms two baseline methods, improving the average F1 measure from 0.1532 to 0.4132 when only 10 seed instances of the new relation type are used. 2 Related work Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which ma</context>
<context position="9862" citStr="Jiang and Zhai, 2007" startWordPosition="1543" endWordPosition="1546">the first and the second arguments are shown in italic and bold, respectively. Before introducing our transfer learning solution, let us first briefly explain our basic classification approach and the features we use, as well as two baseline solutions. 3.1 Feature configuration We treat relation extraction as a classification problem. Each pair of entities within a single sentence is considered a candidate relation instance, and the task becomes predicting whether or not each candidate is a true instance of T . We use feature-based logistic regression classifiers. Following our previous work (Jiang and Zhai, 2007b), we extract features from a sequence representation and a parse tree representation of each relation instance. Each node in the sequence or the parse tree is augmented by an argument tag that indicates whether the node subsumes arg-1, arg2, both or neither. Nodes that represent the arguments are also labeled with the entity type, subtype and mention type as defined by ACE. Based on the findings of Qian et al. (2008), we trim the parse tree of a relation instance so that it contains only the most essential components. We extract unigram features (consisting of a single node) and bigram featu</context>
<context position="16990" citStr="Jiang and Zhai, 2007" startWordPosition="2762" endWordPosition="2765"> loss of labeling x with y for all (x, y) in D, using weight vector w. In logistic regression models, the loss function is the negative log likelihood, that is, L(D, w) = − � log p(y|x, w), (x,y)ED ATµ , Ak µ and Aν are regularization parameters. By adjusting their values, we can control the degree of weight sharing among the relation types. The larger the ratio ATµ /Aν (or Ak µ/Aν) is, the more we believe that the model for T (or Ak) should conform to the common model, and the smaller the type-specific weight vector µT (or µk) will be. The model presented above is based on our previous work (Jiang and Zhai, 2007c), which bears the same spirit of some other recent work on multitask learning (Ando and Zhang, 2005; Evgeniou and Pontil, 2004; Daume III, 2007). It is general for any transfer learning problem with auxiliary labeled data from similar tasks. Here we are mostly interested in the model’s applicability and effectiveness on the relation extraction problem. 4.3 Feature separation Recall that we impose a constraint Fv = 0 when optimizing the objective function. This constraint gives us the freedom to force only the weights of a subset of the features to be shared among different relation types. A </context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>Jing Jiang and ChengXiang Zhai. 2007c. A two-stage approach to domain adaptation for statistical classifiers. In Proceedings of the 16th ACM Conference on Information and Knowledge Management, pages 401–410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longhua Qian</author>
<author>Guodong Zhou</author>
<author>Fang Kong</author>
<author>Qiaoming Zhu</author>
<author>Peide Qian</author>
</authors>
<title>Exploiting constituent dependencies for tree kernel-based semantic relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>697--704</pages>
<contexts>
<context position="1567" citStr="Qian et al., 2008" startWordPosition="232" endWordPosition="235"> type, and allows easy control of the tradeoff between precision and recall. Empirical evaluation on the ACE 2004 data set shows that the proposed method substantially improves over two baseline methods. 1 Introduction Relation extraction is the task of detecting and characterizing semantic relations between entities from free text. Recent work on relation extraction has shown that supervised machine learning coupled with intelligent feature engineering or kernel design provides state-of-the-art solutions to the problem (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008). However, supervised learning heavily relies on a sufficient amount of labeled data for training, which is not always available in practice due to the labor-intensive nature of human annotation. This problem is especially serious for relation extraction because the types of relations to be extracted are highly dependent on the application domain. For example, when working in the financial domain we may be interested in the employment relation, but when moving to the terrorism domain we now may be interested in the ethnic and ideology affiliation relation, and thus have to create training data</context>
<context position="5168" citStr="Qian et al., 2008" startWordPosition="813" endWordPosition="816">kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types, but compared with our work, they had a different problem setting and a different way of modeling the commonality. Banko and Etzioni (2008) stud</context>
<context position="10284" citStr="Qian et al. (2008)" startWordPosition="1618" endWordPosition="1621">nce, and the task becomes predicting whether or not each candidate is a true instance of T . We use feature-based logistic regression classifiers. Following our previous work (Jiang and Zhai, 2007b), we extract features from a sequence representation and a parse tree representation of each relation instance. Each node in the sequence or the parse tree is augmented by an argument tag that indicates whether the node subsumes arg-1, arg2, both or neither. Nodes that represent the arguments are also labeled with the entity type, subtype and mention type as defined by ACE. Based on the findings of Qian et al. (2008), we trim the parse tree of a relation instance so that it contains only the most essential components. We extract unigram features (consisting of a single node) and bigram features (consisting of two connected nodes) from the graphic representations. An example of the graphic representation of a relation instance is shown in Figure 1 and some features extracted from this instance are shown in Table 2. This feature configuration gives state-of-the-art performance (F1 = 0.7223) on the ACE 2004 data set in a standard setting with sufficient data for training. 3.2 Baseline solutions We consider t</context>
</contexts>
<marker>Qian, Zhou, Kong, Zhu, Qian, 2008</marker>
<rawString>Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming Zhu, and Peide Qian. 2008. Exploiting constituent dependencies for tree kernel-based semantic relation extraction. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 697–704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Thrun</author>
</authors>
<title>Is learning the n-th thing any easier than learning the first?</title>
<date>1996</date>
<booktitle>In Advances in Neural Information Processing Systems 8,</booktitle>
<pages>640--646</pages>
<contexts>
<context position="2619" citStr="Thrun, 1996" startWordPosition="412" endWordPosition="413">lation, but when moving to the terrorism domain we now may be interested in the ethnic and ideology affiliation relation, and thus have to create training data for the new relation type. However, is the old training data really useless? Inspired by recent work on transfer learning and domain adaptation, in this paper, we study how we can leverage labeled data of some old relation types to help the extraction of a new relation type in a weakly-supervised setting, where only a few seed instances of the new relation type are available. While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored. Our idea of performing transfer learning is motivated by the observation that different relation types share certain common syntactic structures, which can possibly be transferred from the old types to the new type. We therefore propose to use a general multi-task learning framework in which classification models for a num</context>
</contexts>
<marker>Thrun, 1996</marker>
<rawString>Sebastian Thrun. 1996. Is learning the n-th thing any easier than learning the first? In Advances in Neural Information Processing Systems 8, pages 640–646.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feiyu Xu</author>
<author>Hans Uszkoreit</author>
<author>Hong Li</author>
<author>Niko Felger</author>
</authors>
<title>Adaptation of relation extraction rules to new domains.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation,</booktitle>
<pages>2446--2450</pages>
<contexts>
<context position="5968" citStr="Xu et al. (2008)" startWordPosition="931" endWordPosition="934">relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types, but compared with our work, they had a different problem setting and a different way of modeling the commonality. Banko and Etzioni (2008) studied open domain relation extraction, for which they manually identified several common relation patterns. In contrast, our method obtains common patterns through statistical learning. Xu et al. (2008) studied the problem of adapting a rule-based relation extraction system to new domains, but the types of relations to be extracted remain the same. Transfer learning aims at transferring knowledge learned from one or a number of old tasks to a new task. Domain adaptation is a special case of transfer learning where the learning task remains the same but the distribution of data changes. There has been an increasing amount of work on transfer learning and domain adaptation in natural language processing recently. Blitzer et al. (2006) proposed a structural correspondence learning method for do</context>
</contexts>
<marker>Xu, Uszkoreit, Li, Felger, 2008</marker>
<rawString>Feiyu Xu, Hans Uszkoreit, Hong Li, and Niko Felger. 2008. Adaptation of relation extraction rules to new domains. In Proceedings of the 6th International Conference on Language Resources and Evaluation, pages 2446–2450.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
</authors>
<title>Exploring syntactic features for relation extraction using a convolution tree kernel.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference,</booktitle>
<pages>288--295</pages>
<contexts>
<context position="5148" citStr="Zhang et al., 2006" startWordPosition="809" endWordPosition="812">y feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types, but compared with our work, they had a different problem setting and a different way of modeling the commonality. Banko and</context>
</contexts>
<marker>Zhang, Zhang, Su, 2006</marker>
<rawString>Min Zhang, Jie Zhang, and Jian Su. 2006. Exploring syntactic features for relation extraction using a convolution tree kernel. In Proceedings of the Human Language Technology Conference, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shubin Zhao</author>
<author>Ralph Grishman</author>
</authors>
<title>Extracting relations with integrated information using kernel methods.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>419--426</pages>
<contexts>
<context position="4639" citStr="Zhao and Grishman (2005)" startWordPosition="731" endWordPosition="734">ity type constraints on the relation arguments, which can usually be derived from the definition of a relation type. Imposing these constraints further improves the precision of the final relation extractor. Empirical evaluation on the ACE 2004 data set shows that our proposed method largely outperforms two baseline methods, improving the average F1 measure from 0.1532 to 0.4132 when only 10 seed instances of the new relation type are used. 2 Related work Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability</context>
</contexts>
<marker>Zhao, Grishman, 2005</marker>
<rawString>Shubin Zhao and Ralph Grishman. 2005. Extracting relations with integrated information using kernel methods. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 419–426.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Jian Su</author>
<author>Jie Zhang</author>
<author>Min Zhang</author>
</authors>
<title>Exploring various knowledge in relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>427--434</pages>
<contexts>
<context position="1521" citStr="Zhou et al., 2005" startWordPosition="224" endWordPosition="227">ypes to be transferred to the target relation type, and allows easy control of the tradeoff between precision and recall. Empirical evaluation on the ACE 2004 data set shows that the proposed method substantially improves over two baseline methods. 1 Introduction Relation extraction is the task of detecting and characterizing semantic relations between entities from free text. Recent work on relation extraction has shown that supervised machine learning coupled with intelligent feature engineering or kernel design provides state-of-the-art solutions to the problem (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008). However, supervised learning heavily relies on a sufficient amount of labeled data for training, which is not always available in practice due to the labor-intensive nature of human annotation. This problem is especially serious for relation extraction because the types of relations to be extracted are highly dependent on the application domain. For example, when working in the financial domain we may be interested in the employment relation, but when moving to the terrorism domain we now may be interested in the ethnic and ideology affiliation r</context>
<context position="4610" citStr="Zhou et al. (2005)" startWordPosition="726" endWordPosition="729">knowledge about the entity type constraints on the relation arguments, which can usually be derived from the definition of a relation type. Imposing these constraints further improves the precision of the final relation extractor. Empirical evaluation on the ACE 2004 data set shows that our proposed method largely outperforms two baseline methods, improving the average F1 measure from 0.1532 to 0.4132 when only 10 seed instances of the new relation type are used. 2 Related work Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods. Zhou et al. (2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction. We systematically explored the feature space for relation extraction (Jiang and Zhai, 2007b) . Kernel methods allow a large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kerne</context>
</contexts>
<marker>Zhou, Su, Zhang, Zhang, 2005</marker>
<rawString>GuoDong Zhou, Jian Su, Jie Zhang, and Min Zhang. 2005. Exploring various knowledge in relation extraction. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 427–434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Min Zhang</author>
<author>DongHong Ji</author>
<author>QiaoMing Zhu</author>
</authors>
<title>Hierarchical learning strategy in semantic relation extraction.</title>
<date>2008</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>44</volume>
<issue>3</issue>
<contexts>
<context position="5450" citStr="Zhou et al. (2008)" startWordPosition="853" endWordPosition="856"> large set of features to be used without being explicitly extracted. A number of relation extraction kernels have been proposed, including dependency tree kernels (Culotta and Sorensen, 2004), shortest dependency path kernels (Bunescu and Mooney, 2005) and more recently convolution tree kernels (Zhang et al., 2006; Qian et al., 2008). However, in both feature-based and kernel-based studies, availability of sufficient labeled training data is always assumed. Chen et al. (2006) explored semi-supervised learning for relation extraction using label propagation, which makes use of unlabeled data. Zhou et al. (2008) proposed a hierarchical learning strategy to address the data sparseness problem in relation extraction. They also considered the commonality among different relation types, but compared with our work, they had a different problem setting and a different way of modeling the commonality. Banko and Etzioni (2008) studied open domain relation extraction, for which they manually identified several common relation patterns. In contrast, our method obtains common patterns through statistical learning. Xu et al. (2008) studied the problem of adapting a rule-based relation extraction system to new do</context>
</contexts>
<marker>Zhou, Zhang, Ji, Zhu, 2008</marker>
<rawString>GuoDong Zhou, Min Zhang, DongHong Ji, and QiaoMing Zhu. 2008. Hierarchical learning strategy in semantic relation extraction. Information Processing and Management, 44(3):1008–1021.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>