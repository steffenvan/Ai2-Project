<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002196">
<title confidence="0.996307">
A Convolution Kernel Approach to Identifying Comparisons in Text
</title>
<author confidence="0.979444">
Maksim Tkachenko Hady W. Lauw
</author>
<affiliation confidence="0.9694365">
School of Information Systems School of Information Systems
Singapore Management University Singapore Management University
</affiliation>
<email confidence="0.989205">
maksim.tkatchenko@gmail.com hadywlauw@smu.edu.sg
</email>
<sectionHeader confidence="0.994567" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999892592592593">
Comparisons in text, such as in online re-
views, serve as useful decision aids. In
this paper, we focus on the task of iden-
tifying whether a comparison exists be-
tween a specific pair of entity mentions
in a sentence. This formulation is trans-
formative, as previous work only seeks
to determine whether a sentence is com-
parative, which is presumptuous in the
event the sentence mentions multiple en-
tities and is comparing only some, not all,
of them. Our approach leverages not only
lexical features such as salient words, but
also structural features expressing the re-
lationships among words and entity men-
tions. To model these features seamlessly,
we rely on a dependency tree representa-
tion, and investigate the applicability of a
series of tree kernels. This leads to the de-
velopment of a new context-sensitive tree
kernel: Skip-node Kernel (SNK). We fur-
ther describe both its exact and approxi-
mate computations. Through experiments
on real-life datasets, we evaluate the effec-
tiveness of our kernel-based approach for
comparison identification, as well as the
utility of SNK and its approximations.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998868461538461">
When weighing various alternatives, users in-
creasingly turn to the social media, by scouring
online reviews, discussion forums, etc. Our goal
is to extract from such corpora those text snip-
pets where users make direct comparisons of en-
tities. While sentiment analysis (Pang and Lee,
2008) may be helpful in evaluating individual en-
tities, comparison by the same author within a sen-
tence provides an unambiguous and more equi-
table basis for the relative positions of two enti-
ties on some aspect. For example, the sentence s1
in Table 1, taken from an Amazon review about
a digital camera, makes two distinct comparisons:
</bodyText>
<listItem confidence="0.722240333333333">
#1) between “A630” and “A-series cameras” and
#2) between “A630” and “its competition”, with a
clear sense of which entity mention is the greater
on some aspect (“larger”). Moreover, comparisons
may be objective (e.g., larger) or subjective (e.g.,
better), while sentiments are primarily subjective.
</listItem>
<bodyText confidence="0.991201575757576">
Problem Given a sentence and a specific pair
of entity mentions, we seek to determine if a com-
parison exists between those two mentions. In pre-
vious work, the problem was formulated as identi-
fying comparative sentences, i.e., those containing
at least one comparison (Jindal and Liu, 2006a).
This is not ideal because a sentence may contain
more than two entity mentions, and may be com-
paring only some of them. For instance, s1 is com-
parative with respect to the pair (A630, A-series
cameras) and the pair (A630, its competition), but
not the pair (A-series cameras, its competition).
We therefore postulate that the more appropri-
ate formulation is comparisons within sentences.
If a sentence compares two entities (A, B) with re-
spect to some aspect Z, it should be possible to
reformulate it into another sentence such as: “A
is better than B with respect to Z” (Kessler and
Kuhn, 2014a). Based on this definition, there is no
comparison between (A-series cameras, its com-
petition) in s1. Here, we adopt this apt definition
with a slight restriction to make it more practical,
and seek to identify such comparisons automati-
cally. We consider only sentences with at least
two entity mentions involved in gradable compar-
isons, i.e., a clear sense of scaling in the compar-
ison (e.g., A is better than B.). Such comparisons
are more useful in investigating the pros and cons
of entities, as opposed to equative comparisons ex-
pressing parity between two mentions (e.g., A is as
good as B.), or superlative comparisons expressing
the primacy of an entity with respect to unknown
reference entities (e.g., A is the best.).
</bodyText>
<page confidence="0.982466">
376
</page>
<note confidence="0.996409333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 376–386,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
ID Sentence Remarks
s1 The A630 is slightly larger than previous generation A- Contains two comparisons: (A630, A-series cam-
series cameras, and also larger than much of its competition. eras) and (A630, its competition).
s2 I got 30D for my wife because she wanted a better camera. Includes comparative predicate “better”, but con-
tains no comparison.
s3 I had D3100 and it was nice but the D5100 is truly amazing. No comparative predicate, but has a comparison:
(D3100, D5100).
s4 D7000 and D7100 do better at high ISO than D300s. Contains two comparisons: (D7000, D300s) and
(D7100, D300s).
</note>
<tableCaption confidence="0.996629">
Table 1: Example Sentences with ≥ 2 Entity Mentions from Amazon.com Digital Cameras Reviews
</tableCaption>
<bodyText confidence="0.999902325">
Approach For English, there usually is a com-
parative predicate that anchors a comparison, such
as “better” or “worse”. However, many sentences
with such predicate words are not comparisons.
The sentence s2 in Table 1 has the word “better”,
but does not contain any comparison between the
entity mentions. Yet, other words (e.g., “amaz-
ing”), though not a comparative predicate, could
signify a comparison, e.g., in s3 in Table 1.
(Jindal and Liu, 2006a) considered the “con-
text” around a predicate. A sentence is trans-
formed into a sequence involving the predicate and
the part of speech (POS) within a text window
around the predicate (usually three words before
and after). For instance, s2 in Table 1 would be
transformed into the sequence (PRP VBD DT bet-
ter NN). Such sequences are labeled comparative
or non-comparative, upon which (Jindal and Liu,
2006a) applies sequential pattern mining (Agrawal
and Srikant, 1995; Ayres et al., 2002; Pei et al.,
2001) to learn class sequential rule (CSR). These
CSRs are then used as features in classifying com-
parative sentences.
While (Jindal and Liu, 2006a) makes some
progress by considering context, its performance
may be affected by several factors. First, CSRs are
not sensitive to entity mentions. It may classify
s1 as comparative generally, missing the nuance
that s1 is not comparing the pair (A-series cam-
eras, its competition). Second, as CSRs requires a
list of comparative predicates, the quality and the
completeness of the list are crucial. For instance,
“amazing” is not in their list, and thus the compar-
ison in s3 may not be identifiable. Third, due to
the windowing effect, CSRs has a limited ability to
model long-range dependencies. For s4, a window
of three words around the predicate “better” ex-
cludes the word “than” that would have been very
informative. Yet, enlarging the window might then
bring in irrelevant associations.
What is important then is not so much whether
a sentence is comparative as whether two entity
mentions are related by a comparative relation.
One insight we draw is how comparison identifi-
cation is effectively a form of relation extraction.
While there are diverse relation extraction formu-
lations (Culotta and Sorensen, 2004; Bunescu and
Mooney, 2005; Nguyen et al., 2009), our distinct
relation type is comparison of two entity mentions.
Armed with this insight, we propose a kernel-
based approach based on a dependency tree rep-
resentation (Nivre, 2005), with significant innova-
tions motivated by the comparative identification
task. This proposed approach has several advan-
tages over CSR. Most importantly, it models de-
pendencies between any pair of words (including
entity mentions), whereas CSR only relates a com-
parative predicate to nearby POS tags. For other
advantages, unlike CSR, this approach is contin-
gent on neither a pre-specified list of comparative
predicates, nor a specific window length.
Contributions In this paper, we make the fol-
lowing contributions. First, we re-formulate the
problem of automatic identification of compara-
tive sentences into the more general task of iden-
tifying comparisons within sentences. Second, we
propose to frame comparison identification as a re-
lation extraction problem. This entails: #1) deriv-
ing an appropriate dependency tree representation
of sentences to enable discrimination of compari-
son vs. non-comparison within the same sentence
(see Section 2), and #2) a systematic exploration
of the applicability of various tree kernel spaces
to our task (see Section 3). Third, due to the lim-
itation of the existing tree kernels, we propose a
new tree kernel: Skip-node Kernel that is context-
sensitive, and discuss both its exact and approx-
imate computations (see Section 4). Fourth, we
validate its effectiveness and efficiency through
experiments on real-life datasets (see Section 5).
</bodyText>
<page confidence="0.998508">
377
</page>
<sectionHeader confidence="0.965482" genericHeader="introduction">
2 Overview
</sectionHeader>
<bodyText confidence="0.999606180000001">
Task The input is a corpus of sentences S con-
cerning a set of entities within a certain domain
(e.g., digital cameras). Every sentence s E S con-
tains at least two entity mentions. The set of entity
mentions in s is denoted M3. For instance, the
sentence s4 in Table 1 contains three entity men-
tions: D7000, D7100, and D300s. The same entity
may be mentioned more than once in a sentence,
in which case every mention is a distinct instance.
As output, we seek to determine, for each pair
of entity mentions (mi &lt; mj) E M3 in a sen-
tence s E S, a binary class label of whether s con-
tains a comparison between mi and mj. For the
pair (D7000, D7100) in s4, the correct class is 0
(no comparison). For the other two pairs (D7000,
D300s) and (D7100, D300s), the correct class is 1
(comparisons). We do not seek to identify the as-
pect of comparison, which is a different problem
of independent research interest (see Section 6).
Dependency Tree In order to represent both
the lexical units (words) as well their structural
dependencies seamlessly, we represent each
sentence s as a dependency tree T. For example,
Figure 1(a) shows the dependency tree of s4 in
Table 1. The tree is rooted at the main verb (“do”),
and each dependency relation associates a head
word and a dependent word. To describe a tree
or any of its substructures, we use the bracket
notation. Figure 1(a) in this notation is [do
[D7000 [and] [D7100]] [better [at
[ISO [high]]] [than [D300s]]]].
Here, we make two observations. First, there
is one tree even for a sentence with multiple pairs
of entity mentions. Second, the information sig-
nalling a comparison is borne by the structures
around the mentions (e.g., [better [than]],
rather than the actual mentions (e.g., “D7000”).
These lead us to introduce a modified dependency
tree that is distinct for every pair of mentions,
achieved by replacing each entity mention of in-
terest by a placeholder token. Here, we use the to-
ken “#camera” for illustration. Figure 1(b) shows
the modified tree for the pair (D7000, D7100).
This enables learning in an entity-agnostic way,
because the token ensures that sentences about dif-
ferent cameras are interpreted similarly.
Convolution Kernel Observe how the trees of
the pair (D7000, D300s) in Figure 1(c) and the pair
(D7100, D300s) in Figure 1(d), which are both
comparisons, share certain substructures, such
</bodyText>
<figure confidence="0.94444175">
D7000 and D7100 do better at high ISO than D300s
(a) original dependency tree
#camera and #camera do better at high ISO than D300s
(b) modified dependency tree for (D7000, D7100)
#camera and D7100 do better at high ISO than #camera
(c) modified dependency tree for (D7000, D300s)
D7000 and #camera do better at high ISO than #camera
(d) modified dependency tree for (D7100, D300s)
</figure>
<figureCaption confidence="0.999972">
Figure 1: Modified dependency trees.
</figureCaption>
<bodyText confidence="0.999908875">
as [do [better [than [#camera]]]. In
contrast, the tree in Figure 1(b) for the pair
(D7000, D7100), which is not a comparison, does
not contain this substructure. What we need is a
way to systematically examine tree substructures
to determine the similarity between two trees.
Kernel methods offer a way to measure the sim-
ilarity by exploring an implicit feature space with-
out enumerating all substructures explicitly. Sup-
pose that T denotes the space of all possible in-
stances. A kernel function K is a symmetric and
positive semidefinite function that maps the in-
stance space T x T to a real value in the range
of [0, oo) (Haussler, 1999). A tree kernel func-
tion can be reformulated into a convolution kernel
(Collins and Duffy, 2001), shown in Equation 1.
</bodyText>
<equation confidence="0.99954">
K(T1, T2) = � � D(ni, nj) (1)
ni∈T1 nj∈T2
</equation>
<bodyText confidence="0.999752615384615">
Here, ni and nj denote each node in their re-
spective tree instances T1 and T2. D(ni, nj) is
the number of common substructure instances be-
tween the two sub-trees rooted in ni and nj re-
spectively. The exact form of D(ni, nj) depends
on the specific definition of the tree kernel space.
In Section 3, we systematically explore the appli-
cability of various tree kernel spaces, leading to
the introduction of the new Skip-node Kernel.
The appropriate kernel function can be embed-
ded seamlessly in kernel methods for classifica-
tion. In this work, we use the Support Vector Ma-
chines (SVM) (Steinwart and Christmann, 2008).
</bodyText>
<page confidence="0.997647">
378
</page>
<sectionHeader confidence="0.990018" genericHeader="method">
3 Tree Kernel Spaces
</sectionHeader>
<bodyText confidence="0.994486">
Tree kernels count substructures of a tree in some
high-dimensional feature space. Different tree
kernel spaces vary in the amount and the type of
information they can capture, and thus may suit
different purposes. To find a suitable tree kernel
for the comparison identification task, we first sys-
tematically explore a progression of known tree
kernel spaces, including Sub-tree, Subset Tree,
and Partial Tree. Through the use of appropriate
examples, we show how these existing tree ker-
nel spaces may not be appropriate for certain in-
stances. This section culminates in the introduc-
tion of a new feature space that we call Skip-node.
Sub-tree (ST) Space In this space, the ba-
sic substructure is a subgraph formed by a node
along with all its descendants. Applying this ker-
nel to two dependency trees of similar sentences
may not be appropriate due to, for example, mod-
ifier words that change the dependency structure.
To illustrate this, let us examine the two depen-
dency parses in Figure 2. Both support compar-
isons, and ideally we can detect some level of sim-
ilarity. However, if we consider only sub-trees, the
two dependency trees share in common only two
fragments: [#camera] and [is]. Neither of
these fragments is indicative of a comparison.
#camera is better than #camera
</bodyText>
<figureCaption confidence="0.7389425">
Figure 2: Dependency parses. Working example
for the Sub-tree, Subset Tree, Partial Tree kernels.
</figureCaption>
<bodyText confidence="0.9717575">
Subset Tree (SST) Space We next consider
the SST kernel, which computes similarity in
a more general space of substructures than ST.
Any subgraph of a tree that preserves produc-
tion rules is counted. This definition suggests
SST is intended more for a constituency parse
(Moschitti, 2006a). In this feature space, the
parses in Figure 2 now have in common the fol-
lowing fragments: [#camera], [is], [than
[#camera]]. This representation is better than
ST’s, e.g., the fragment [than [#camera]] is
informative. However, as a whole, the set of fea-
tures are still insufficient to identify a comparison.
#camera is twice as expensive as #camera
</bodyText>
<figure confidence="0.8919455">
Previously I had D60 and D7100 and #camera is twice as good as #camera
Previously I had D60 and #camera and this camera is twice as good as #camera
</figure>
<figureCaption confidence="0.927393">
Figure 3: Dependency parses. Working example
for the Partial Tree, Skip-node kernels.
</figureCaption>
<bodyText confidence="0.997033090909091">
Partial Tree (PT) Space In turn, the PT space
allows breaking of production rules, making it a
better choice than SST for dependency parses. PT
kernel would find that the parse in Figure 2(a) with
all its subgraphs can be matched as a whole within
the parse in Figure 2(b), identifying a close match.
However, PT kernel is prone to two drawbacks.
By generating an exponential feature space, it may
overfit and degrade generalization (Cumby and
Roth, 2003). More importantly, PT considers tree
fragments independently from their contexts, re-
sulting in features involving non-related parts of a
sentence. This is particularly apparent when we
consider multiple entities within a sentence.
Suppose that Figure 3(a) is in our training set,
and we have the sentence below in the testing set:
Previously, I had D60 and D7100, and
this camera is twice as good as D60.
Figure 3(b) shows the parse for (this camera, D60),
and Figure 3(c) for (D7100, D60). The former
is a comparison, and should match Figure 3(a).
The latter is not and should not match. PT ker-
nel cannot resolve this ambiguity, computing the
same similarity value to Figure 3(a) for both.
The common features are: [#camera], [is],
[twice], [as], and [as [#camera]].
Skip-node (SN) Space Figures 3(a) and 3(b)
share a similar substructure “twice as ... as”, but
because they use different words to express the
comparisons (“expensive” vs. “good”), previous
kernels treat their features disjointly, missing out
on their similarity. To reduce this over-reliance on
exact word similarity, we seek a feature space that
</bodyText>
<page confidence="0.993118">
379
</page>
<figure confidence="0.6130565">
#camera is twice as as #camera
Previously I had D60 and D7100 and #camera is twice as as #camera
</figure>
<figureCaption confidence="0.999514">
Figure 4: Dependency parses with skipped nodes.
</figureCaption>
<bodyText confidence="0.999725243243243">
would allow some degree of relaxation in deter-
mining the structural similarity between trees.
We therefore propose the Skip-node (SN) space,
which represents a generalized space of tree frag-
ments, where some nodes can be “skipped” or re-
labeled to a special symbol ‘*’ that would match
nodes of any label. A restriction on this space is
that each skip symbol must connect two non-skip
(regular) nodes. The implication is that skips code
for some notion of connecting distance between
non-skip nodes. Moreover, the space would not
include features such as [* [* [#camera]]]
that serve only to indicate the presence of ances-
tors, and not any relationship of non-skip nodes.
Figure 4 resolves the ambiguity in Fig-
ure 3 by skipping the words “expensive” and
“good”, introducing a new set of features: [*
[#camera] [is] [twice] [as] [as
[#camera]]]. Note how in this case the skip
symbol effectively serves as a “context” that pulls
together the previously disjoint features identified
by the PT kernel. These new context-sensitive
features would allow a match between the earlier
Figures 3(a) and 3(b), but not Figure 3(c).
Thus, SN space effectively generalizes over the
PT space, and enriches it with context-sensitive
features. To avoid overfitting, in addition to decay
parameter λ used in PT kernel, we associate SN
kernel with two other parameters. The SN space
consists of rooted ordered trees where some nodes
are labeled with a special skip symbol ‘*’, such
that the number of regular nodes (not marked with
‘*’) is at most S, and each skip node is within a
distance of L from a non-skip node. This engen-
ders a graceful gradation of similarity as the num-
ber of skip nodes in a substructure grows, yet im-
poses a limit to the extent of relaxation.
</bodyText>
<sectionHeader confidence="0.976632" genericHeader="method">
4 Skip-node Kernel Computation
</sectionHeader>
<bodyText confidence="0.9998255">
We now discuss the computation of Skip-node
Kernel, first exactly, and thereafter approximately.
</bodyText>
<subsectionHeader confidence="0.99014">
4.1 Exact Computation
</subsectionHeader>
<bodyText confidence="0.973887073170732">
We define the alignment of common fragments be-
tween two trees in the Skip-node space. When
S = 1, only singleton nodes with the same labels
contribute to the kernel, and alignment is straight-
forward. When aligning fragments with two reg-
ular nodes (S &gt; 1), we consider their connection
structure and the order of the child nodes to pre-
vent over-counting substructures with the same la-
bels (e.g., [*[as][as]] in Figure 4). To pre-
serve the natural order of words in a sentence, we
enumerate the tree nodes according to preorder,
left-to-right depth-first search (DFS) traversal.
In turn, the connection structure is defined by
the skip-node path connecting two regular nodes.
This can be expressed as a sequence of upward
(towards the root) and downward (towards the
leaves) steps we need to perform to get from
the leftmost to the rightmost regular node. Due
to the natural ordering of regular nodes, upward
steps are followed by downward steps. The se-
quence can be expressed as a pair of numbers:
(ρ(nl, u), ρ(nr, u)), where nl is the leftmost reg-
ular node of a fragment, nr is the rightmost one,
u = σ(nl, nr) is the lowest common ancestor of
nodes nl, nr, and ρ returns the number of edges in
the shortest path connecting two nodes.
Suppose a rooted tree T = (N, E) has pre-
order DFS enumeration N = (n1, n2,..., nlNl).
For i &lt; j, we define a function π(ni, nj), which
canonically represents the way two nodes are con-
nected in a tree, as follows:
π(ni, nj) = (ρ(ni, σ(ni, nj)), ρ(nj, σ(ni, nj))).
DEFINITION 1 (STRUCTURAL ISOMOR-
PHISM): Given two trees T1 = (N1, E1),
T2 = (N2, E2), we say that pairs of nodes
(vi, ui0), (vj, uj0) E N1 x N2 are structurally
isomorphic and write (vi, ui0) — (vj, uj0) when
π(vi, vj) = π(ui0, uj0) on the valid domain.
It can be shown that structural isomorphism is a
transitive relation. This property allows us to grow
aligned fragments by adding one node at a time:
</bodyText>
<equation confidence="0.990643">
(vi,ui0) — (vj,uj0) n (vj,vj0) E&amp;quot;^&amp;quot;&apos; (vk, uk0) ⇒
(vi, ui0) — (vk, uk0).
</equation>
<page confidence="0.931556">
380
</page>
<bodyText confidence="0.9999344">
To compute the kernel, we use a graph-based
approach to enumerate all the common substruc-
tures in the Skip-node space. Given two trees T1
and T2, we begin by aligning their nodes. The sets
of nodes in T1 and T2 are N1 and N2 respectively.
Let NG be a set of pairs (ni, nj) E N1xN2, where
ni and nj have the same label. On top of NG, we
build a graph G = (NG, EG). We draw an edge
between two vertices (vi, vk), (uj, ul) E NG, if
(vi, uj) *&amp;quot; (vk, ul) and P(vi, vk) G L.
Any connected subgraph of G represents a fea-
ture in the Skip-node space common to both T1
and T2. The kernel then needs to count the num-
ber of connected subgraphs of sizes not more than
S. To see that this procedure is correct, we sim-
ply need to trace back the construction of graph
G, and build an bijection from a subgraph of G to
the corresponding fragments of T1 and T2.
Enumerating all the connected subgraphs of a
given graph requires exponential time. The al-
gorithm described above requires O(|N1||N2 |+
ES=1 (|Nc|)) time, assuming that the distance be-
tween two nodes in a tree can be computed in O(1)
with appropriate linear preprocessing. See (Ben-
der and Farach-Colton, 2000) for insight. The ex-
act computation is still tractable on the condition
that S and L are not very large. This condition
would probably hold in most realistic scenarios.
Yet, to improve the practicality of the kernel, we
propose a couple of approximations as follows.
</bodyText>
<subsectionHeader confidence="0.98059">
4.2 Approximate Computation
</subsectionHeader>
<bodyText confidence="0.998715565217391">
One reason for the complexity of the Skip-node
kernel is that although the graph G is formed
by aligning two trees, by allowing connections
through skips, G itself may not necessarily be in
the form of a tree. In deriving an approximation,
our strategy is to form G through alignment of lin-
ear substructures of the original two trees. A Skip-
node space over linear structures can be computed
in polynomial time using dynamic programming.
Linear Skip-node One approximation is to
consider linear substructures in the form of root-
paths. A root-path is a path from the root of a
tree to a leaf. Given two trees T1 and T2, with
DFS enumerated nodes N1 = (v1, v2,..., vm1)
and N2 = (u1, u2,..., um2) respectively. Here, v1
and u1 are roots, and vm1 and um2 are the leaves.
Starting with common fragments at the leaves, we
grow them into larger common fragments towards
the root. We call this approximation Linear Skip-
node. Figure 5(a) shows examples of features con-
sidered by Linear Skip-node for the illustrated tree
T in skip-node space (S = 3, L = 2).
The kernel function can be decomposed into:
</bodyText>
<equation confidence="0.903683333333333">
�
K(T1,T2) =
viEN1
</equation>
<bodyText confidence="0.999336">
where D(vi, uj, s) is the number of common sub-
structures of size s with the leftmost regular nodes
vi and uj. A is a decay factor for substructure size.
The recursive definition of the kernel is:
</bodyText>
<equation confidence="0.999471333333333">
D(vi, uj, s) =
� � I(vi,vk, uj, ul)D(vk,ul,s − 1),
i&lt;k&lt;m1 j&lt;l&lt;m2
�
1 if label(vi) = label(uj),
D(vi, uj, 1) =
0 otherwise;
I(vi, vk, uj, ul) = 1(vi,uj),.,,,..,(vk,ul)
1ρ(vi,vk)&lt;L &apos; 1(vi is an ancestor of vk),
</equation>
<bodyText confidence="0.999509333333333">
where 1c equals 1 when constraint c is satisfied
and 0 otherwise. Note that the first two factors
of indicator function I just represent the general
Skip-node space constraints, the last factor ensures
that features are computed along the root-paths.
Lookahead Skip-node The second approxi-
mation, Lookahead Skip-node, is related to the ob-
servation that when growing a substructure, we do
not have to confine the growth only towards an-
cestors, as DFS traversal already ensures iterative
manner of computation. In other words, the con-
straint vi is an ancestor of vk can be dropped:
</bodyText>
<equation confidence="0.736484">
I(vi, vk, uj, ul) = 1(vi,uj),.,,,..,(vk,ul) &apos; 1ρ(vi,vk)&lt;L.
</equation>
<bodyText confidence="0.999932466666667">
In addition to those features generated by Linear
Skip-node in Figure 5(a), Lookahead Skip-node
can generate additional tree substructures, shown
in Figure 5(b). The approximation can be com-
puted using different DFS enumerations, which
may result in different feature sets. In our exper-
iments, we used pre-order left-to-right enumera-
tion. Given the enumeration of tree T as in Fig-
ure 5, we start to grow feature fragments from
node n4. According to the Skip-node space con-
straints, the growth can only proceed to nodes n1
or n2. Once any of these nodes is attached to n4,
we lose tree fragments containing n3, as the pro-
cedure allows us to grow substructures only to-
wards nodes with smaller (earlier) DFS enumer-
</bodyText>
<figure confidence="0.586693666666667">
AsD(vi, uj, s),
� S
ujEN2 s=1
</figure>
<page confidence="0.901456">
381
</page>
<figureCaption confidence="0.998687">
Figure 5: Features of T in skip-node space (S = 3, L = 2). Numbers indicates pre-order left-to-right
DFS enumeration of T. Dashed circles represent skip nodes. Subfigures: (a) - modeled by all; (b) -
modeled by Lookahead Skip-node, not by Linear Skip-node; (c) - modeled only by Exact Skip-node.
</figureCaption>
<table confidence="0.99725">
Domain # sentences % comp. # pairs % comp.
Camera 1716 59.4% 2170 49.9%
Cell 821 35.2% 1110 30.5%
</table>
<tableCaption confidence="0.999782">
Table 2: The dataset size for each domain.
</tableCaption>
<bodyText confidence="0.97947075">
ation numbers. Figure 5(c) shows the fragments
that Lookahead Skip-node cannot capture1.
The computation procedure is similar for both
approximations and requires O(S|N1|2|N2|2).
</bodyText>
<sectionHeader confidence="0.999276" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999720826086956">
Data For experiments, we compiled two anno-
tated datasets in two domains: Digital Camera and
Cell Phone from online review sentences. The re-
views were collected from Amazon and Epinions2.
We identified the entity mentions through dic-
tionary matching, followed by manual annotation
to weed out false positives. Each dictionary entry
is a product name (e.g., Canon PowerShot D20,
D7100) or a common product reference (e.g., this
camera, that phone). The dataset includes only
sentences that contain at least two entity mentions.
Every pair of entities within a sentence was an-
notated with a comparative label according to the
definition given in Section 2. A sentence is com-
parative if at least one pair of entities within it is in
a comparative relation. Table 2 shows the dataset
properties, in terms of the number sentences and
the percentage that are comparative sentences, as
well as the number of pairs of entity mentions
and the percentage that are comparative relations.
There are more pairs than sentences, i.e., many
sentences mention more than two entities.
This dataset subsumes the annotated gradable
</bodyText>
<footnote confidence="0.9998154">
1In this particular case, all features could have been com-
puted by Lookahead Skip-node using preorder right-to-left
DFS enumeration, although it may not be true in general.
2We used already available snapshots for Epinions
dataset: http://groups.csail.mit.edu/rbg/code/precis/.
</footnote>
<table confidence="0.999922166666667">
P Camera P Cell F1
R F1 R
CSR 74.3 52.3 61.3 48.9 61.5* 54.3
BoW 76.9 76.3 76.6 62.2 58.0 59.8
BoW† 77.3 71.9 74.4 69.0 56.3 61.8
SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1*
</table>
<tableCaption confidence="0.99993">
Table 3: Comparison identification task
</tableCaption>
<bodyText confidence="0.9969095">
comparisons of (Kessler and Kuhn, 2014a) derived
from Epinions reviews on Digital Cameras. (Jin-
dal and Liu, 2006a)’s dataset is inapplicable, due
to its lack of entity-centric comparison.
Evaluation The experiments were carried out
with SVM-light-TK framework3 (Joachims, 1999;
Moschitti, 2006b), into which we built Skip-node
Kernel. We further release a separate standalone
library that we built, called Tree-SVM4, which
does SVM optimization using the tree kernels de-
scribed in this paper. The sentences were parsed
and lemmatized with the use of the Stanford NLP
software (Chen and Manning, 2014).
The experiments were done on 10 random data
splits in 80:20 proportion of training vs. testing.
Performance is measured by using F1, which is
the harmonic mean of precision P and recall R:
F1 = 2PR
P+R. The statistical significance5 is mea-
sured by randomization test (Yeh, 2000). The
hyper-parameters, including the baselines’, were
optimized for F1 through grid-search.
</bodyText>
<subsectionHeader confidence="0.980854">
5.1 Comparison Identification
</subsectionHeader>
<bodyText confidence="0.999927">
Our first and primary objective is to investigate the
effectiveness of the proposed approach on the task
of identifying comparisons between a pair of en-
</bodyText>
<footnote confidence="0.9987894">
3http://disi.unitn.it/moschitti/Tree-Kernel.htm
4http://github.com/sitfoxfly/tree-svm
5When presenting the results, an asterisk indicates that the
outperformance over the second-best result is significant at
0.05 level. Two asterisks indicate the same at 0.1 level.
</footnote>
<page confidence="0.991095">
382
</page>
<table confidence="0.9998875">
P Camera P Cell F1
R F1 R
CSR 74.6 51.7 60.9 50.9 61.2* 55.3
BoW 77.5 76.3 76.8 63.4 57.7 60.2
BoW† 77.6 72.4 74.9 70.9 57.3 63.2
SNK 81.0* 75.2 78.0** 77.9* 54.8 64.2
</table>
<tableCaption confidence="0.999909">
Table 4: Comparative sentence identification task
</tableCaption>
<bodyText confidence="0.997736848484849">
tity mentions. Previous work focused on identify-
ing comparative sentences. We compare to three
baselines. One is CSR, implemented following the
description in (Jindal and Liu, 2006a). Another
is BoW, classification using bag-of-words as fea-
tures. For the baselines, if a comparative sentence
contains more than one pair of entities, we assume
that every pair is in comparative relation. The third
baseline, BoW†, considers only the words in be-
tween of the two target entities.
Table 3 shows the performance on the compar-
ison identification task (best results are in bold).
In terms of F1, it is evident that SNK outperforms
the baselines. This is achieved through significant
gains in precision. It is expected that the base-
lines tend to have a high recall. CSR benefits from
the human-constructed predefined list of compara-
tive keywords and key phrases that a kernel-based
method is unable to learn from a training split.
BoW† tends to have a higher precision than the
other baselines, as it is able to distinguish between
different pairs of entities within one sentence.
While SNK may have an inherent advantage
over CSR or BoW due to its entity orientation,
to investigate the effectiveness of the method it-
self, we now compare them on the previous task
of comparative sentence identification. Table 4
shows that even in this task, SNK still performs
better than the baselines. Comparing Table 3 and
Table 4, the results also concur with the intuition:
once we fold up multiple entity pairs in a sentence
into a comparative sentence, we observe a drop in
recall and an increase in precision.
</bodyText>
<subsectionHeader confidence="0.999641">
5.2 Tree Kernel Spaces
</subsectionHeader>
<bodyText confidence="0.999948714285714">
Our second objective is to explore the progres-
sion of feature spaces discussed in Section 3. Ta-
ble 5 reports the results on comparison identifi-
cation task. The F1 columns show that the per-
formance gradually increases from STK to SNK
along with the increase in the complexity of fea-
ture space. PTK and SNK can be considered high-
</bodyText>
<table confidence="0.999877166666667">
P Camera P Cell F1
R F1 R
STK 67.5 64.0 64.9 43.7 41.9 42.6
SSTK 72.1 72.6 71.8 79.6 42.4 54.9
PTK 79.2 74.9 76.9 72.3 56.0** 62.7
SNK 80.5* 75.2 77.7** 77.2 55.1 64.1*
</table>
<tableCaption confidence="0.937286">
Table 5: Tree kernels
</tableCaption>
<table confidence="0.999954">
P Camera F1 P Cell F1
R R
STKBoW 79.9 65.1 71.7 77.5 45.3 56.8
SSTKBoW 78.0 73.5 75.6 71.8 54.5 61.6
PTKBoW 78.6 74.1 76.2 71.0 53.8 60.8
SNK 80.5 75.2** 77.7* 77.2 55.1 64.1**
</table>
<tableCaption confidence="0.998625">
Table 6: Tree kernels combined with bag-of-words
</tableCaption>
<bodyText confidence="0.999841684210526">
variance estimators due to the power of their fea-
ture spaces. The data is such that these kernels
may not have fully modeled the feature space com-
pletely enough to show even sharper differences.
SNK’s parameters were optimized to non-trivial
cases (5 &gt; 1 and L &gt; 1) by the grid-search, i.e.,
5 = 3 and L = 2 for Digital Camera and 5 = 2
and L = 3 for Cell Phone. The trivial case 5 = 1
represents a standard bag-of-words feature space,
i.e., this space is embedded into Skip-node space
whenever 5 &gt; 1. To show that SNK does not
merely take advantage of this simple space to com-
pete with structural kernels, we carried out another
experiment where we combined STK, SSTK, and
PTK with bag-of-word representation of a sen-
tence. Table 6 shows that surprisingly this combi-
nation harms the quality of PTK. STK and SSTK
gain more from bag-of-words features. Neverthe-
less, the overall outperformance by SNK remains.
</bodyText>
<subsectionHeader confidence="0.999735">
5.3 Skip-node Kernel Approximations
</subsectionHeader>
<bodyText confidence="0.9994835">
Our third objective is to study the utility of the ap-
proximations of SNK described in Section 4. Ta-
ble 7 reports the performance of the approxima-
tions. For Camera, the performance of Lookahead
</bodyText>
<table confidence="0.999675">
P Camera F1 P Cell F1
R R
Linear SNK 78.9 77.1* 77.9 71.8 55.3 62.2
Lookahead SNK 80.5 75.2 77.7 71.8 55.3 62.2
SNK 80.5 75.2 77.7 77.2* 55.1 64.1
</table>
<tableCaption confidence="0.999229">
Table 7: Effectiveness: SNK vs. approximations
</tableCaption>
<page confidence="0.998318">
383
</page>
<figureCaption confidence="0.999197">
Figure 6: Efficiency: SNK vs. approximations
</figureCaption>
<bodyText confidence="0.999916095238095">
SNK and SNK are the same. In turn, Linear SNK
represents more restricted features, yielding a drop
in precision and a gain in recall, resulting in the
best Fl. For Cell Phone, the approximations are
close, but the original SNK has the best Fl.
To study the running time, we randomly select
500 sentences. Figure 6 shows the time for ap-
plying a kernel function to 250k pairs of sentences
when we vary two parameters: S and L. When
S varies, SNK running time has exponential be-
haviour, whereas the approximations show fairly
linear curves. L seems to influence the computa-
tion time linearly for SNK and and its approxima-
tions. The experiments were carried out on a PC
with Intel Core i5 CPU 3.2 GHz and 4Gb RAM.
This experiment shows that the original SNK is
still tractable for small S and L, which turn out to
be the case for optimal effectiveness. If efficiency
is of paramount importance, the two approxima-
tions are significantly faster, without much degra-
dation (none in some cases) of effectiveness.
</bodyText>
<sectionHeader confidence="0.999892" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.998395617021277">
Exploiting comparisons in text begins with iden-
tifying comparisons within sentences. The previ-
ous state of the art for English is the baseline CSR
approach (Jindal and Liu, 2006a). For scientific
text, (Park and Blake, 2012) explored handcrafted
syntactic rules that might not cross domains well.
Comparisons are also studied in other languages,
such as Chinese, Japanese, and Korean (Huang et
al., 2008; Yang and Ko, 2009; Kurashima et al.,
2008; Yang and Ko, 2009; Zhang and Jin, 2012).
A different task seeks to identify the “com-
ponents” within comparative sentences, i.e., en-
tities, aspect, comparative predicate (Jindal and
Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn,
2014b; Kessler and Kuhn, 2013; Feldman et al.,
2007). Others are interested in yet another task to
identify the direction of the comparisons (Ganap-
athibhotla and Liu, 2008; Tkachenko and Lauw,
2014), or the aggregated ranking (Kurashima et
al., 2008; Zhang et al., 2013; Li et al., 2011). Our
task precedes these tasks in the pipeline.
Other than comparison identification, depen-
dency grammar has also found applications in
natural language-related tasks, such as sentiment
classification (Nakagawa et al., 2010), question
answering (Punyakanok et al., 2004; Lin and Pan-
tel, 2001), as well as relation extraction (Culotta
and Sorensen, 2004; Bunescu and Mooney, 2005).
(Collins and Duffy, 2001) applied convolution
kernels (Haussler, 1999; Watkins, 1999) to natural
language objects, which evolved into tree kernels,
e.g., sub-tree (Vishwanathan and Smola, 2004),
subset tree (Collins and Duffy, 2002), descending-
path kernel (Lin et al., 2014), partial tree (Mos-
chitti, 2006a). Skip-node kernel joins the list of
tree kernels applicable to dependency trees. These
kernels may also apply to other types of trees, e.g.,
constituency trees (Zhou et al., 2007).
(Croce et al., 2011; Srivastava et al., 2013) pro-
posed to capture semantic information along with
tree structure, by allowing soft label matching via
lexical similarity over distributional word repre-
sentation. Skip-node gives another perspective
on sparsity, using structural alignment of the tree
fragments with non-matching labels. As lexical
similarity can be incorporated into Skip-node ker-
nel, we consider it orthogonal and complementary.
</bodyText>
<sectionHeader confidence="0.998191" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999899222222222">
We study the effectiveness of a convolution ker-
nel approach for the novel formulation of extract-
ing comparisons within sentences. Our approach
outperforms the baselines in identifying compar-
isons and comparative sentences. Skip-node ker-
nel and its approximations are particularly effec-
tive for comparison identification, and potentially
applicable to other relation extraction or natural-
language tasks (the direction of our future work).
</bodyText>
<figure confidence="0.998782896551724">
(a) L = 3, S ∈ 1..10
S = 3
SNK
Linear SNK
Lookahead SNK
1 2 3 4 5 6 7 8 9 10
L: Length of a Skip
(b) S = 3, L ∈ 1..10
104
1 2 3 4 5 6 7 8 9 10
S: Size of a Substructure
L = 3
SNK
Linear SNK
Lookahead SNK
CPU Seconds
103
102
101
100
5.0
CPU Seconds
4.5
4.0
3.5
3.0
2.5
2.0
1.5
</figure>
<page confidence="0.995664">
384
</page>
<sectionHeader confidence="0.980115" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999444809090909">
Rakesh Agrawal and Ramakrishnan Srikant. 1995.
Mining sequential patterns. In Proceedings of
the International Conference on Data Engineering
(ICDE), pages 3–14.
Jay Ayres, Jason Flannick, Johannes Gehrke, and Tomi
Yiu. 2002. Sequential pattern mining using a
bitmap representation. In Proceedings of the ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD), pages 429–435.
Michael A. Bender and Martin Farach-Colton. 2000.
The lca problem revisited. In Proceedings of the
Latin American Symposium on Theoretical Infor-
matics, LATIN ’00, pages 88–94, London, UK, UK.
Springer-Verlag.
Razvan C. Bunescu and Raymond J. Mooney. 2005.
A shortest path dependency kernel for relation ex-
traction. In Proceedings of the Conference on Hu-
man Language Technology and Empirical Methods
in Natural Language Processing (HLT), pages 724–
731.
Danqi Chen and Christopher D Manning. 2014. A
fast and accurate dependency parser using neural
networks. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 740–750.
Michael Collins and Nigel Duffy. 2001. Convolution
kernels for natural language. In Advances in Neural
Information Processing Systems (NIPS), pages 625–
632.
Michael Collins and Nigel Duffy. 2002. New rank-
ing algorithms for parsing and tagging: Kernels over
discrete structures, and the voted perceptron. In Pro-
ceedings of the Annual Meeting on Association for
Computational Linguistics (COLING), pages 263–
270.
Danilo Croce, Alessandro Moschitti, and Roberto
Basili. 2011. Structured lexical similarity via con-
volution kernels on dependency trees. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing, pages 1034–1046. Asso-
ciation for Computational Linguistics.
Aron Culotta and Jeffrey Sorensen. 2004. Dependency
tree kernels for relation extraction. In Proceedings
of the Annual Meeting on Association for Computa-
tional Linguistics (COLING).
Chad Cumby and Dan Roth. 2003. On kernel methods
for relational learning. In Proceedings of the Inter-
national Conference on Machine Learning (ICML),
pages 107–114.
Ronen Feldman, Moshe Fresko, Jacob Goldenberg,
Oded Netzer, and Lyle Ungar. 2007. Extracting
product comparisons from discussion boards. In
Proceedings of the IEEE International Conference
on Data Mining (ICDM), pages 469–474.
Murthy Ganapathibhotla and Bing Liu. 2008. Mining
opinions in comparative sentences. In Proceedings
of the International Conference on Computational
Linguistics (COLING), pages 241–248.
David Haussler. 1999. Convolution kernels on dis-
crete structures. Technical report, Department of
Computer Science, University of California at Santa
Cruz.
Feng Hou and Guo-Hui Li. 2008. Mining Chinese
comparative sentences by semantic role labeling. In
International Conference on Machine Learning and
Cybernetics, volume 5, pages 2563–2568.
Xiaojiang Huang, Xiaojun Wan, Jianwu Yang, and
Jianguo Xiao. 2008. Learning to identify compara-
tive sentences in Chinese text. In Pacific Rim Inter-
national Conference on Artificial Intelligence, pages
187–198.
Nitin Jindal and Bing Liu. 2006a. Identifying com-
parative sentences in text documents. In Proceed-
ings of the International ACM SIGIR Conference on
Research and Development in Information Retrieval
(SIGIR), pages 244–251.
Nitin Jindal and Bing Liu. 2006b. Mining compara-
tive sentences and relations. In Proceedings of the
AAAI Conference on Artificial Intelligence (AAAI),
volume 22, pages 1331–1336.
Thorsten Joachims. 1999. Advances in kernel meth-
ods. chapter Making Large-scale Support Vector
Machine Learning Practical, pages 169–184. MIT
Press, Cambridge, MA, USA.
Wiltrud Kessler and Jonas Kuhn. 2013. Detection of
product comparisons-how far does an out-of-the-box
semantic role labeling system take you? In Pro-
ceedings of the Conference on Empirical Methods
on Natural Language Processing (EMNLP), pages
1892–1897.
Wiltrud Kessler and Jonas Kuhn. 2014a. A corpus
of comparisons in product reviews. In Proceedings
of the International Conference on Language Re-
sources and Evaluation (LREC), may.
Wiltrud Kessler and Jonas Kuhn. 2014b. Detecting
comparative sentiment expressions – a case study in
annotation design decisions. In Proceedings of Kon-
ferenz zur Verarbeitung Natrlicher Sprache (KON-
VENS), October.
Takeshi Kurashima, Katsuji Bessho, Hiroyuki Toda,
Toshio Uchiyama, and Ryoji Kataoka. 2008.
Ranking entities using comparative relations. In
Database and Expert Systems Applications (DEXA),
pages 124–133.
Si Li, Zheng-Jun Zha, Zhaoyan Ming, Meng Wang,
Tat-Seng Chua, Jun Guo, and Weiran Xu. 2011.
Product comparison using comparative relations. In
Proceedings of the International ACM SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval (SIGIR), pages 1151–1152.
</reference>
<page confidence="0.986737">
385
</page>
<reference confidence="0.999439336842105">
Dekang Lin and Patrick Pantel. 2001. Discovery of in-
ference rules for question-answering. Natural Lan-
guage Engineering, 7(04):343–360.
Chen Lin, Timothy Miller, Alvin Kho, Steven Bethard,
Dmitriy Dligach, Sameer Pradhan, and Guergana
Savova. 2014. Descending-path convolution ker-
nel for syntactic structures. In Proceedings of the
52nd Annual Meeting of the Association for Com-
putational Linguistics, pages 81–86. Association for
Computational Linguistics.
Alessandro Moschitti. 2006a. Efficient convolution
kernels for dependency and constituent syntactic
trees. In European Conference on Machine Learn-
ing (ECML), pages 318–329.
Alessandro Moschitti. 2006b. Making tree kernels
practical for natural language learning. In 11th Con-
ference of the European Chapter of the Association
for Computational Linguistics, pages 113–120.
Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classifi-
cation using crfs with hidden variables. In Hu-
man Language Technologies: Annual Conference
of the North American Chapter of the Association
for Computational Linguistics (NAACL-HLT), pages
786–794.
Truc-Vien T Nguyen, Alessandro Moschitti, and
Giuseppe Riccardi. 2009. Convolution kernels on
constituent, dependency and sequential structures
for relation extraction. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 1378–1387.
Joakim Nivre. 2005. Dependency grammar and de-
pendency parsing. MSI report, 5133(1959):1–32.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2):1–135.
Dae Hoon Park and Catherine Blake. 2012. Identi-
fying comparative claim sentences in full-text scien-
tific articles. In Proceedings of the Workshop on De-
tecting Structure in Scholarly Discourse, pages 1–9.
Jian Pei, Jiawei Han, Behzad Mortazavi-Asl, Helen
Pinto, Qiming Chen, Umeshwar Dayal, and Mei-
Chun Hsu. 2001. Prefixspan: Mining sequen-
tial patterns efficiently by prefix-projected pattern
growth. In Proceedings of the International Con-
ference on Data Engineering (ICDE), pages 0215–
0215.
Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2004.
Natural language inference via dependency tree
mapping: An application to question answering.
Computational Linguistics, 6(9).
Shashank Srivastava, Dirk Hovy, and Eduard Hovy.
2013. A walk-based semantically enriched tree ker-
nel over distributed word representations. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1411–
1416. Association for Computational Linguistics.
Ingo Steinwart and Andreas Christmann. 2008. Sup-
port vector machines. Springer.
Maksim Tkachenko and Hady W Lauw. 2014. Genera-
tive modeling of entity comparisons in text. In Pro-
ceedings of the ACM International Conference on
Information and Knowledge Management (CIKM),
pages 859–868.
SVN Vishwanathan and Alexander Johannes Smola.
2004. Fast kernels for string and tree matching. Ker-
nel Methods in Computational Biology, pages 113–
130.
Chris Watkins. 1999. Dynamic alignment kernels.
Advances in Neural Information Processing Systems
(NIPS), pages 39–50.
Seon Yang and Youngjoong Ko. 2009. Extract-
ing comparative sentences from Korean text docu-
ments using comparative lexical patterns and ma-
chine learning techniques. In Proceedings of the
ACL-IJCNLP Conference Short Papers, pages 153–
156.
Alexander Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In Pro-
ceedings of the Conference on Computational Lin-
guistics (COLING), pages 947–953. Association for
Computational Linguistics.
Runxiang Zhang and Yaohong Jin. 2012. Identifica-
tion and transformation of comparative sentences in
patent Chinese-English machine translation. In In-
ternational Conference on Asian Language Process-
ing (IALP), pages 217–220.
Zhu Zhang, Chenhui Guo, and Paulo Goes. 2013.
Product comparison networks for competitive analy-
sis of online word-of-mouth. ACM Transactions on
Management Information Systems (TMIS), 3(4):20.
GuoDong Zhou, Min Zhang, Dong Hong Ji, and
Qiaoming Zhu. 2007. Tree kernel-based relation
extraction with context-sensitive structured parse
tree information. EMNLP-CoNLL, page 728.
</reference>
<page confidence="0.998993">
386
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.892413">
<title confidence="0.999826">A Convolution Kernel Approach to Identifying Comparisons in Text</title>
<author confidence="0.999735">Maksim Tkachenko Hady W Lauw</author>
<affiliation confidence="0.9997825">School of Information Systems School of Information Systems Singapore Management University Singapore Management University</affiliation>
<email confidence="0.897589">maksim.tkatchenko@gmail.comhadywlauw@smu.edu.sg</email>
<abstract confidence="0.999813321428571">Comparisons in text, such as in online reviews, serve as useful decision aids. In this paper, we focus on the task of identifying whether a comparison exists between a specific pair of entity mentions in a sentence. This formulation is transformative, as previous work only seeks to determine whether a sentence is comparative, which is presumptuous in the event the sentence mentions multiple entities and is comparing only some, not all, of them. Our approach leverages not only lexical features such as salient words, but also structural features expressing the relationships among words and entity mentions. To model these features seamlessly, we rely on a dependency tree representation, and investigate the applicability of a series of tree kernels. This leads to the development of a new context-sensitive tree kernel: Skip-node Kernel (SNK). We further describe both its exact and approximate computations. Through experiments on real-life datasets, we evaluate the effectiveness of our kernel-based approach for comparison identification, as well as the utility of SNK and its approximations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rakesh Agrawal</author>
<author>Ramakrishnan Srikant</author>
</authors>
<title>Mining sequential patterns.</title>
<date>1995</date>
<booktitle>In Proceedings of the International Conference on Data Engineering (ICDE),</booktitle>
<pages>3--14</pages>
<contexts>
<context position="5801" citStr="Agrawal and Srikant, 1995" startWordPosition="926" endWordPosition="929">mentions. Yet, other words (e.g., “amazing”), though not a comparative predicate, could signify a comparison, e.g., in s3 in Table 1. (Jindal and Liu, 2006a) considered the “context” around a predicate. A sentence is transformed into a sequence involving the predicate and the part of speech (POS) within a text window around the predicate (usually three words before and after). For instance, s2 in Table 1 would be transformed into the sequence (PRP VBD DT better NN). Such sequences are labeled comparative or non-comparative, upon which (Jindal and Liu, 2006a) applies sequential pattern mining (Agrawal and Srikant, 1995; Ayres et al., 2002; Pei et al., 2001) to learn class sequential rule (CSR). These CSRs are then used as features in classifying comparative sentences. While (Jindal and Liu, 2006a) makes some progress by considering context, its performance may be affected by several factors. First, CSRs are not sensitive to entity mentions. It may classify s1 as comparative generally, missing the nuance that s1 is not comparing the pair (A-series cameras, its competition). Second, as CSRs requires a list of comparative predicates, the quality and the completeness of the list are crucial. For instance, “amaz</context>
</contexts>
<marker>Agrawal, Srikant, 1995</marker>
<rawString>Rakesh Agrawal and Ramakrishnan Srikant. 1995. Mining sequential patterns. In Proceedings of the International Conference on Data Engineering (ICDE), pages 3–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Ayres</author>
<author>Jason Flannick</author>
<author>Johannes Gehrke</author>
<author>Tomi Yiu</author>
</authors>
<title>Sequential pattern mining using a bitmap representation.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<pages>429--435</pages>
<contexts>
<context position="5821" citStr="Ayres et al., 2002" startWordPosition="930" endWordPosition="933">(e.g., “amazing”), though not a comparative predicate, could signify a comparison, e.g., in s3 in Table 1. (Jindal and Liu, 2006a) considered the “context” around a predicate. A sentence is transformed into a sequence involving the predicate and the part of speech (POS) within a text window around the predicate (usually three words before and after). For instance, s2 in Table 1 would be transformed into the sequence (PRP VBD DT better NN). Such sequences are labeled comparative or non-comparative, upon which (Jindal and Liu, 2006a) applies sequential pattern mining (Agrawal and Srikant, 1995; Ayres et al., 2002; Pei et al., 2001) to learn class sequential rule (CSR). These CSRs are then used as features in classifying comparative sentences. While (Jindal and Liu, 2006a) makes some progress by considering context, its performance may be affected by several factors. First, CSRs are not sensitive to entity mentions. It may classify s1 as comparative generally, missing the nuance that s1 is not comparing the pair (A-series cameras, its competition). Second, as CSRs requires a list of comparative predicates, the quality and the completeness of the list are crucial. For instance, “amazing” is not in their</context>
</contexts>
<marker>Ayres, Flannick, Gehrke, Yiu, 2002</marker>
<rawString>Jay Ayres, Jason Flannick, Johannes Gehrke, and Tomi Yiu. 2002. Sequential pattern mining using a bitmap representation. In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), pages 429–435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Bender</author>
<author>Martin Farach-Colton</author>
</authors>
<title>The lca problem revisited.</title>
<date>2000</date>
<booktitle>In Proceedings of the Latin American Symposium on Theoretical Informatics, LATIN ’00,</booktitle>
<pages>88--94</pages>
<publisher>UK. Springer-Verlag.</publisher>
<location>London, UK,</location>
<contexts>
<context position="21961" citStr="Bender and Farach-Colton, 2000" startWordPosition="3675" endWordPosition="3679">he Skip-node space common to both T1 and T2. The kernel then needs to count the number of connected subgraphs of sizes not more than S. To see that this procedure is correct, we simply need to trace back the construction of graph G, and build an bijection from a subgraph of G to the corresponding fragments of T1 and T2. Enumerating all the connected subgraphs of a given graph requires exponential time. The algorithm described above requires O(|N1||N2 |+ ES=1 (|Nc|)) time, assuming that the distance between two nodes in a tree can be computed in O(1) with appropriate linear preprocessing. See (Bender and Farach-Colton, 2000) for insight. The exact computation is still tractable on the condition that S and L are not very large. This condition would probably hold in most realistic scenarios. Yet, to improve the practicality of the kernel, we propose a couple of approximations as follows. 4.2 Approximate Computation One reason for the complexity of the Skip-node kernel is that although the graph G is formed by aligning two trees, by allowing connections through skips, G itself may not necessarily be in the form of a tree. In deriving an approximation, our strategy is to form G through alignment of linear substructur</context>
</contexts>
<marker>Bender, Farach-Colton, 2000</marker>
<rawString>Michael A. Bender and Martin Farach-Colton. 2000. The lca problem revisited. In Proceedings of the Latin American Symposium on Theoretical Informatics, LATIN ’00, pages 88–94, London, UK, UK. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT),</booktitle>
<pages>724--731</pages>
<contexts>
<context position="7128" citStr="Bunescu and Mooney, 2005" startWordPosition="1142" endWordPosition="1145">dowing effect, CSRs has a limited ability to model long-range dependencies. For s4, a window of three words around the predicate “better” excludes the word “than” that would have been very informative. Yet, enlarging the window might then bring in irrelevant associations. What is important then is not so much whether a sentence is comparative as whether two entity mentions are related by a comparative relation. One insight we draw is how comparison identification is effectively a form of relation extraction. While there are diverse relation extraction formulations (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Nguyen et al., 2009), our distinct relation type is comparison of two entity mentions. Armed with this insight, we propose a kernelbased approach based on a dependency tree representation (Nivre, 2005), with significant innovations motivated by the comparative identification task. This proposed approach has several advantages over CSR. Most importantly, it models dependencies between any pair of words (including entity mentions), whereas CSR only relates a comparative predicate to nearby POS tags. For other advantages, unlike CSR, this approach is contingent on neither a pre-specified list o</context>
<context position="35133" citStr="Bunescu and Mooney, 2005" startWordPosition="5885" endWordPosition="5888">al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree struct</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT), pages 724– 731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danqi Chen</author>
<author>Christopher D Manning</author>
</authors>
<title>A fast and accurate dependency parser using neural networks.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>740--750</pages>
<contexts>
<context position="27985" citStr="Chen and Manning, 2014" startWordPosition="4678" endWordPosition="4681">on identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 random data splits in 80:20 proportion of training vs. testing. Performance is measured by using F1, which is the harmonic mean of precision P and recall R: F1 = 2PR P+R. The statistical significance5 is measured by randomization test (Yeh, 2000). The hyper-parameters, including the baselines’, were optimized for F1 through grid-search. 5.1 Comparison Identification Our first and primary objective is to investigate the effectiveness of the proposed approach on the task of identifying comparisons between a pair of en3http://disi.unitn.it/moschitti/Tree-Kernel.h</context>
</contexts>
<marker>Chen, Manning, 2014</marker>
<rawString>Danqi Chen and Christopher D Manning. 2014. A fast and accurate dependency parser using neural networks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 740–750.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>Convolution kernels for natural language.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>625--632</pages>
<contexts>
<context position="12250" citStr="Collins and Duffy, 2001" startWordPosition="1995" endWordPosition="1998"> a comparison, does not contain this substructure. What we need is a way to systematically examine tree substructures to determine the similarity between two trees. Kernel methods offer a way to measure the similarity by exploring an implicit feature space without enumerating all substructures explicitly. Suppose that T denotes the space of all possible instances. A kernel function K is a symmetric and positive semidefinite function that maps the instance space T x T to a real value in the range of [0, oo) (Haussler, 1999). A tree kernel function can be reformulated into a convolution kernel (Collins and Duffy, 2001), shown in Equation 1. K(T1, T2) = � � D(ni, nj) (1) ni∈T1 nj∈T2 Here, ni and nj denote each node in their respective tree instances T1 and T2. D(ni, nj) is the number of common substructure instances between the two sub-trees rooted in ni and nj respectively. The exact form of D(ni, nj) depends on the specific definition of the tree kernel space. In Section 3, we systematically explore the applicability of various tree kernel spaces, leading to the introduction of the new Skip-node Kernel. The appropriate kernel function can be embedded seamlessly in kernel methods for classification. In this</context>
<context position="35160" citStr="Collins and Duffy, 2001" startWordPosition="5889" endWordPosition="5892">ested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label</context>
</contexts>
<marker>Collins, Duffy, 2001</marker>
<rawString>Michael Collins and Nigel Duffy. 2001. Convolution kernels for natural language. In Advances in Neural Information Processing Systems (NIPS), pages 625– 632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron.</title>
<date>2002</date>
<booktitle>In Proceedings of the Annual Meeting on Association for Computational Linguistics (COLING),</booktitle>
<pages>263--270</pages>
<contexts>
<context position="35367" citStr="Collins and Duffy, 2002" startWordPosition="5917" endWordPosition="5920">al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragments with non-matching labels. As lexica</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron. In Proceedings of the Annual Meeting on Association for Computational Linguistics (COLING), pages 263– 270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Structured lexical similarity via convolution kernels on dependency trees.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1034--1046</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="35643" citStr="Croce et al., 2011" startWordPosition="5962" endWordPosition="5965">Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragments with non-matching labels. As lexical similarity can be incorporated into Skip-node kernel, we consider it orthogonal and complementary. 7 Conclusion We study the effectiveness of a convolution kernel approach for the novel formulation of extracting comparisons within sentences. Our approach outperforms the bas</context>
</contexts>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>Danilo Croce, Alessandro Moschitti, and Roberto Basili. 2011. Structured lexical similarity via convolution kernels on dependency trees. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1034–1046. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Jeffrey Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Meeting on Association for Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="7102" citStr="Culotta and Sorensen, 2004" startWordPosition="1138" endWordPosition="1141">iable. Third, due to the windowing effect, CSRs has a limited ability to model long-range dependencies. For s4, a window of three words around the predicate “better” excludes the word “than” that would have been very informative. Yet, enlarging the window might then bring in irrelevant associations. What is important then is not so much whether a sentence is comparative as whether two entity mentions are related by a comparative relation. One insight we draw is how comparison identification is effectively a form of relation extraction. While there are diverse relation extraction formulations (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Nguyen et al., 2009), our distinct relation type is comparison of two entity mentions. Armed with this insight, we propose a kernelbased approach based on a dependency tree representation (Nivre, 2005), with significant innovations motivated by the comparative identification task. This proposed approach has several advantages over CSR. Most importantly, it models dependencies between any pair of words (including entity mentions), whereas CSR only relates a comparative predicate to nearby POS tags. For other advantages, unlike CSR, this approach is contingent on neit</context>
<context position="35106" citStr="Culotta and Sorensen, 2004" startWordPosition="5881" endWordPosition="5884"> and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic informa</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>Aron Culotta and Jeffrey Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the Annual Meeting on Association for Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chad Cumby</author>
<author>Dan Roth</author>
</authors>
<title>On kernel methods for relational learning.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML),</booktitle>
<pages>107--114</pages>
<contexts>
<context position="15666" citStr="Cumby and Roth, 2003" startWordPosition="2570" endWordPosition="2573">ra Previously I had D60 and #camera and this camera is twice as good as #camera Figure 3: Dependency parses. Working example for the Partial Tree, Skip-node kernels. Partial Tree (PT) Space In turn, the PT space allows breaking of production rules, making it a better choice than SST for dependency parses. PT kernel would find that the parse in Figure 2(a) with all its subgraphs can be matched as a whole within the parse in Figure 2(b), identifying a close match. However, PT kernel is prone to two drawbacks. By generating an exponential feature space, it may overfit and degrade generalization (Cumby and Roth, 2003). More importantly, PT considers tree fragments independently from their contexts, resulting in features involving non-related parts of a sentence. This is particularly apparent when we consider multiple entities within a sentence. Suppose that Figure 3(a) is in our training set, and we have the sentence below in the testing set: Previously, I had D60 and D7100, and this camera is twice as good as D60. Figure 3(b) shows the parse for (this camera, D60), and Figure 3(c) for (D7100, D60). The former is a comparison, and should match Figure 3(a). The latter is not and should not match. PT kernel </context>
</contexts>
<marker>Cumby, Roth, 2003</marker>
<rawString>Chad Cumby and Dan Roth. 2003. On kernel methods for relational learning. In Proceedings of the International Conference on Machine Learning (ICML), pages 107–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
<author>Moshe Fresko</author>
<author>Jacob Goldenberg</author>
<author>Oded Netzer</author>
<author>Lyle Ungar</author>
</authors>
<title>Extracting product comparisons from discussion boards.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE International Conference on Data Mining (ICDM),</booktitle>
<pages>469--474</pages>
<contexts>
<context position="34518" citStr="Feldman et al., 2007" startWordPosition="5791" endWordPosition="5794">he art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu an</context>
</contexts>
<marker>Feldman, Fresko, Goldenberg, Netzer, Ungar, 2007</marker>
<rawString>Ronen Feldman, Moshe Fresko, Jacob Goldenberg, Oded Netzer, and Lyle Ungar. 2007. Extracting product comparisons from discussion boards. In Proceedings of the IEEE International Conference on Data Mining (ICDM), pages 469–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Murthy Ganapathibhotla</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinions in comparative sentences.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>241--248</pages>
<contexts>
<context position="34637" citStr="Ganapathibhotla and Liu, 2008" startWordPosition="5809" endWordPosition="5813">2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural langu</context>
</contexts>
<marker>Ganapathibhotla, Liu, 2008</marker>
<rawString>Murthy Ganapathibhotla and Bing Liu. 2008. Mining opinions in comparative sentences. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 241–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Haussler</author>
</authors>
<title>Convolution kernels on discrete structures.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>Department of Computer Science, University of California at Santa Cruz.</institution>
<contexts>
<context position="12154" citStr="Haussler, 1999" startWordPosition="1981" endWordPosition="1982">mera]]]. In contrast, the tree in Figure 1(b) for the pair (D7000, D7100), which is not a comparison, does not contain this substructure. What we need is a way to systematically examine tree substructures to determine the similarity between two trees. Kernel methods offer a way to measure the similarity by exploring an implicit feature space without enumerating all substructures explicitly. Suppose that T denotes the space of all possible instances. A kernel function K is a symmetric and positive semidefinite function that maps the instance space T x T to a real value in the range of [0, oo) (Haussler, 1999). A tree kernel function can be reformulated into a convolution kernel (Collins and Duffy, 2001), shown in Equation 1. K(T1, T2) = � � D(ni, nj) (1) ni∈T1 nj∈T2 Here, ni and nj denote each node in their respective tree instances T1 and T2. D(ni, nj) is the number of common substructure instances between the two sub-trees rooted in ni and nj respectively. The exact form of D(ni, nj) depends on the specific definition of the tree kernel space. In Section 3, we systematically explore the applicability of various tree kernel spaces, leading to the introduction of the new Skip-node Kernel. The appr</context>
<context position="35204" citStr="Haussler, 1999" startWordPosition="5896" endWordPosition="5897"> the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distri</context>
</contexts>
<marker>Haussler, 1999</marker>
<rawString>David Haussler. 1999. Convolution kernels on discrete structures. Technical report, Department of Computer Science, University of California at Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng Hou</author>
<author>Guo-Hui Li</author>
</authors>
<title>Mining Chinese comparative sentences by semantic role labeling.</title>
<date>2008</date>
<booktitle>In International Conference on Machine Learning and Cybernetics,</booktitle>
<volume>5</volume>
<pages>2563--2568</pages>
<contexts>
<context position="34446" citStr="Hou and Li, 2008" startWordPosition="5779" endWordPosition="5782">h identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001)</context>
</contexts>
<marker>Hou, Li, 2008</marker>
<rawString>Feng Hou and Guo-Hui Li. 2008. Mining Chinese comparative sentences by semantic role labeling. In International Conference on Machine Learning and Cybernetics, volume 5, pages 2563–2568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojiang Huang</author>
<author>Xiaojun Wan</author>
<author>Jianwu Yang</author>
<author>Jianguo Xiao</author>
</authors>
<title>Learning to identify comparative sentences in Chinese text.</title>
<date>2008</date>
<booktitle>In Pacific Rim International Conference on Artificial Intelligence,</booktitle>
<pages>187--198</pages>
<contexts>
<context position="34192" citStr="Huang et al., 2008" startWordPosition="5737" endWordPosition="5740">ut to be the case for optimal effectiveness. If efficiency is of paramount importance, the two approximations are significantly faster, without much degradation (none in some cases) of effectiveness. 6 Related Work Exploiting comparisons in text begins with identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the </context>
</contexts>
<marker>Huang, Wan, Yang, Xiao, 2008</marker>
<rawString>Xiaojiang Huang, Xiaojun Wan, Jianwu Yang, and Jianguo Xiao. 2008. Learning to identify comparative sentences in Chinese text. In Pacific Rim International Conference on Artificial Intelligence, pages 187–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Identifying comparative sentences in text documents.</title>
<date>2006</date>
<booktitle>In Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>244--251</pages>
<contexts>
<context position="2602" citStr="Jindal and Liu, 2006" startWordPosition="404" endWordPosition="407">makes two distinct comparisons: #1) between “A630” and “A-series cameras” and #2) between “A630” and “its competition”, with a clear sense of which entity mention is the greater on some aspect (“larger”). Moreover, comparisons may be objective (e.g., larger) or subjective (e.g., better), while sentiments are primarily subjective. Problem Given a sentence and a specific pair of entity mentions, we seek to determine if a comparison exists between those two mentions. In previous work, the problem was formulated as identifying comparative sentences, i.e., those containing at least one comparison (Jindal and Liu, 2006a). This is not ideal because a sentence may contain more than two entity mentions, and may be comparing only some of them. For instance, s1 is comparative with respect to the pair (A630, A-series cameras) and the pair (A630, its competition), but not the pair (A-series cameras, its competition). We therefore postulate that the more appropriate formulation is comparisons within sentences. If a sentence compares two entities (A, B) with respect to some aspect Z, it should be possible to reformulate it into another sentence such as: “A is better than B with respect to Z” (Kessler and Kuhn, 2014a</context>
<context position="5331" citStr="Jindal and Liu, 2006" startWordPosition="850" endWordPosition="853"> ISO than D300s. Contains two comparisons: (D7000, D300s) and (D7100, D300s). Table 1: Example Sentences with ≥ 2 Entity Mentions from Amazon.com Digital Cameras Reviews Approach For English, there usually is a comparative predicate that anchors a comparison, such as “better” or “worse”. However, many sentences with such predicate words are not comparisons. The sentence s2 in Table 1 has the word “better”, but does not contain any comparison between the entity mentions. Yet, other words (e.g., “amazing”), though not a comparative predicate, could signify a comparison, e.g., in s3 in Table 1. (Jindal and Liu, 2006a) considered the “context” around a predicate. A sentence is transformed into a sequence involving the predicate and the part of speech (POS) within a text window around the predicate (usually three words before and after). For instance, s2 in Table 1 would be transformed into the sequence (PRP VBD DT better NN). Such sequences are labeled comparative or non-comparative, upon which (Jindal and Liu, 2006a) applies sequential pattern mining (Agrawal and Srikant, 1995; Ayres et al., 2002; Pei et al., 2001) to learn class sequential rule (CSR). These CSRs are then used as features in classifying </context>
<context position="27497" citStr="Jindal and Liu, 2006" startWordPosition="4605" endWordPosition="4609">e annotated gradable 1In this particular case, all features could have been computed by Lookahead Skip-node using preorder right-to-left DFS enumeration, although it may not be true in general. 2We used already available snapshots for Epinions dataset: http://groups.csail.mit.edu/rbg/code/precis/. P Camera P Cell F1 R F1 R CSR 74.3 52.3 61.3 48.9 61.5* 54.3 BoW 76.9 76.3 76.6 62.2 58.0 59.8 BoW† 77.3 71.9 74.4 69.0 56.3 61.8 SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1* Table 3: Comparison identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 random data splits in 80:20 proportion of training vs. testing. Performance is</context>
<context position="29208" citStr="Jindal and Liu, 2006" startWordPosition="4864" endWordPosition="4867">4http://github.com/sitfoxfly/tree-svm 5When presenting the results, an asterisk indicates that the outperformance over the second-best result is significant at 0.05 level. Two asterisks indicate the same at 0.1 level. 382 P Camera P Cell F1 R F1 R CSR 74.6 51.7 60.9 50.9 61.2* 55.3 BoW 77.5 76.3 76.8 63.4 57.7 60.2 BoW† 77.6 72.4 74.9 70.9 57.3 63.2 SNK 81.0* 75.2 78.0** 77.9* 54.8 64.2 Table 4: Comparative sentence identification task tity mentions. Previous work focused on identifying comparative sentences. We compare to three baselines. One is CSR, implemented following the description in (Jindal and Liu, 2006a). Another is BoW, classification using bag-of-words as features. For the baselines, if a comparative sentence contains more than one pair of entities, we assume that every pair is in comparative relation. The third baseline, BoW†, considers only the words in between of the two target entities. Table 3 shows the performance on the comparison identification task (best results are in bold). In terms of F1, it is evident that SNK outperforms the baselines. This is achieved through significant gains in precision. It is expected that the baselines tend to have a high recall. CSR benefits from the </context>
<context position="33966" citStr="Jindal and Liu, 2006" startWordPosition="5703" endWordPosition="5706">ime linearly for SNK and and its approximations. The experiments were carried out on a PC with Intel Core i5 CPU 3.2 GHz and 4Gb RAM. This experiment shows that the original SNK is still tractable for small S and L, which turn out to be the case for optimal effectiveness. If efficiency is of paramount importance, the two approximations are significantly faster, without much degradation (none in some cases) of effectiveness. 6 Related Work Exploiting comparisons in text begins with identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to i</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006a. Identifying comparative sentences in text documents. In Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 244–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Mining comparative sentences and relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),</booktitle>
<volume>22</volume>
<pages>1331--1336</pages>
<contexts>
<context position="2602" citStr="Jindal and Liu, 2006" startWordPosition="404" endWordPosition="407">makes two distinct comparisons: #1) between “A630” and “A-series cameras” and #2) between “A630” and “its competition”, with a clear sense of which entity mention is the greater on some aspect (“larger”). Moreover, comparisons may be objective (e.g., larger) or subjective (e.g., better), while sentiments are primarily subjective. Problem Given a sentence and a specific pair of entity mentions, we seek to determine if a comparison exists between those two mentions. In previous work, the problem was formulated as identifying comparative sentences, i.e., those containing at least one comparison (Jindal and Liu, 2006a). This is not ideal because a sentence may contain more than two entity mentions, and may be comparing only some of them. For instance, s1 is comparative with respect to the pair (A630, A-series cameras) and the pair (A630, its competition), but not the pair (A-series cameras, its competition). We therefore postulate that the more appropriate formulation is comparisons within sentences. If a sentence compares two entities (A, B) with respect to some aspect Z, it should be possible to reformulate it into another sentence such as: “A is better than B with respect to Z” (Kessler and Kuhn, 2014a</context>
<context position="5331" citStr="Jindal and Liu, 2006" startWordPosition="850" endWordPosition="853"> ISO than D300s. Contains two comparisons: (D7000, D300s) and (D7100, D300s). Table 1: Example Sentences with ≥ 2 Entity Mentions from Amazon.com Digital Cameras Reviews Approach For English, there usually is a comparative predicate that anchors a comparison, such as “better” or “worse”. However, many sentences with such predicate words are not comparisons. The sentence s2 in Table 1 has the word “better”, but does not contain any comparison between the entity mentions. Yet, other words (e.g., “amazing”), though not a comparative predicate, could signify a comparison, e.g., in s3 in Table 1. (Jindal and Liu, 2006a) considered the “context” around a predicate. A sentence is transformed into a sequence involving the predicate and the part of speech (POS) within a text window around the predicate (usually three words before and after). For instance, s2 in Table 1 would be transformed into the sequence (PRP VBD DT better NN). Such sequences are labeled comparative or non-comparative, upon which (Jindal and Liu, 2006a) applies sequential pattern mining (Agrawal and Srikant, 1995; Ayres et al., 2002; Pei et al., 2001) to learn class sequential rule (CSR). These CSRs are then used as features in classifying </context>
<context position="27497" citStr="Jindal and Liu, 2006" startWordPosition="4605" endWordPosition="4609">e annotated gradable 1In this particular case, all features could have been computed by Lookahead Skip-node using preorder right-to-left DFS enumeration, although it may not be true in general. 2We used already available snapshots for Epinions dataset: http://groups.csail.mit.edu/rbg/code/precis/. P Camera P Cell F1 R F1 R CSR 74.3 52.3 61.3 48.9 61.5* 54.3 BoW 76.9 76.3 76.6 62.2 58.0 59.8 BoW† 77.3 71.9 74.4 69.0 56.3 61.8 SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1* Table 3: Comparison identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 random data splits in 80:20 proportion of training vs. testing. Performance is</context>
<context position="29208" citStr="Jindal and Liu, 2006" startWordPosition="4864" endWordPosition="4867">4http://github.com/sitfoxfly/tree-svm 5When presenting the results, an asterisk indicates that the outperformance over the second-best result is significant at 0.05 level. Two asterisks indicate the same at 0.1 level. 382 P Camera P Cell F1 R F1 R CSR 74.6 51.7 60.9 50.9 61.2* 55.3 BoW 77.5 76.3 76.8 63.4 57.7 60.2 BoW† 77.6 72.4 74.9 70.9 57.3 63.2 SNK 81.0* 75.2 78.0** 77.9* 54.8 64.2 Table 4: Comparative sentence identification task tity mentions. Previous work focused on identifying comparative sentences. We compare to three baselines. One is CSR, implemented following the description in (Jindal and Liu, 2006a). Another is BoW, classification using bag-of-words as features. For the baselines, if a comparative sentence contains more than one pair of entities, we assume that every pair is in comparative relation. The third baseline, BoW†, considers only the words in between of the two target entities. Table 3 shows the performance on the comparison identification task (best results are in bold). In terms of F1, it is evident that SNK outperforms the baselines. This is achieved through significant gains in precision. It is expected that the baselines tend to have a high recall. CSR benefits from the </context>
<context position="33966" citStr="Jindal and Liu, 2006" startWordPosition="5703" endWordPosition="5706">ime linearly for SNK and and its approximations. The experiments were carried out on a PC with Intel Core i5 CPU 3.2 GHz and 4Gb RAM. This experiment shows that the original SNK is still tractable for small S and L, which turn out to be the case for optimal effectiveness. If efficiency is of paramount importance, the two approximations are significantly faster, without much degradation (none in some cases) of effectiveness. 6 Related Work Exploiting comparisons in text begins with identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to i</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006b. Mining comparative sentences and relations. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), volume 22, pages 1331–1336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Advances in kernel methods. chapter Making Large-scale Support Vector Machine Learning Practical,</title>
<date>1999</date>
<pages>169--184</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="27661" citStr="Joachims, 1999" startWordPosition="4629" endWordPosition="4630">not be true in general. 2We used already available snapshots for Epinions dataset: http://groups.csail.mit.edu/rbg/code/precis/. P Camera P Cell F1 R F1 R CSR 74.3 52.3 61.3 48.9 61.5* 54.3 BoW 76.9 76.3 76.6 62.2 58.0 59.8 BoW† 77.3 71.9 74.4 69.0 56.3 61.8 SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1* Table 3: Comparison identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 random data splits in 80:20 proportion of training vs. testing. Performance is measured by using F1, which is the harmonic mean of precision P and recall R: F1 = 2PR P+R. The statistical significance5 is measured by randomization test (Yeh, 2</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Advances in kernel methods. chapter Making Large-scale Support Vector Machine Learning Practical, pages 169–184. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wiltrud Kessler</author>
<author>Jonas Kuhn</author>
</authors>
<title>Detection of product comparisons-how far does an out-of-the-box semantic role labeling system take you?</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP),</booktitle>
<pages>1892--1897</pages>
<contexts>
<context position="34495" citStr="Kessler and Kuhn, 2013" startWordPosition="5787" endWordPosition="5790"> The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sor</context>
</contexts>
<marker>Kessler, Kuhn, 2013</marker>
<rawString>Wiltrud Kessler and Jonas Kuhn. 2013. Detection of product comparisons-how far does an out-of-the-box semantic role labeling system take you? In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP), pages 1892–1897.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wiltrud Kessler</author>
<author>Jonas Kuhn</author>
</authors>
<title>A corpus of comparisons in product reviews.</title>
<date>2014</date>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation (LREC),</booktitle>
<contexts>
<context position="3201" citStr="Kessler and Kuhn, 2014" startWordPosition="508" endWordPosition="511">n (Jindal and Liu, 2006a). This is not ideal because a sentence may contain more than two entity mentions, and may be comparing only some of them. For instance, s1 is comparative with respect to the pair (A630, A-series cameras) and the pair (A630, its competition), but not the pair (A-series cameras, its competition). We therefore postulate that the more appropriate formulation is comparisons within sentences. If a sentence compares two entities (A, B) with respect to some aspect Z, it should be possible to reformulate it into another sentence such as: “A is better than B with respect to Z” (Kessler and Kuhn, 2014a). Based on this definition, there is no comparison between (A-series cameras, its competition) in s1. Here, we adopt this apt definition with a slight restriction to make it more practical, and seek to identify such comparisons automatically. We consider only sentences with at least two entity mentions involved in gradable comparisons, i.e., a clear sense of scaling in the comparison (e.g., A is better than B.). Such comparisons are more useful in investigating the pros and cons of entities, as opposed to equative comparisons expressing parity between two mentions (e.g., A is as good as B.),</context>
<context position="27423" citStr="Kessler and Kuhn, 2014" startWordPosition="4594" endWordPosition="4597">.e., many sentences mention more than two entities. This dataset subsumes the annotated gradable 1In this particular case, all features could have been computed by Lookahead Skip-node using preorder right-to-left DFS enumeration, although it may not be true in general. 2We used already available snapshots for Epinions dataset: http://groups.csail.mit.edu/rbg/code/precis/. P Camera P Cell F1 R F1 R CSR 74.3 52.3 61.3 48.9 61.5* 54.3 BoW 76.9 76.3 76.6 62.2 58.0 59.8 BoW† 77.3 71.9 74.4 69.0 56.3 61.8 SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1* Table 3: Comparison identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 rand</context>
<context position="34470" citStr="Kessler and Kuhn, 2014" startWordPosition="5783" endWordPosition="5786">arisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation ex</context>
</contexts>
<marker>Kessler, Kuhn, 2014</marker>
<rawString>Wiltrud Kessler and Jonas Kuhn. 2014a. A corpus of comparisons in product reviews. In Proceedings of the International Conference on Language Resources and Evaluation (LREC), may.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wiltrud Kessler</author>
<author>Jonas Kuhn</author>
</authors>
<title>Detecting comparative sentiment expressions – a case study in annotation design decisions.</title>
<date>2014</date>
<booktitle>In Proceedings of Konferenz zur Verarbeitung Natrlicher Sprache (KONVENS),</booktitle>
<contexts>
<context position="3201" citStr="Kessler and Kuhn, 2014" startWordPosition="508" endWordPosition="511">n (Jindal and Liu, 2006a). This is not ideal because a sentence may contain more than two entity mentions, and may be comparing only some of them. For instance, s1 is comparative with respect to the pair (A630, A-series cameras) and the pair (A630, its competition), but not the pair (A-series cameras, its competition). We therefore postulate that the more appropriate formulation is comparisons within sentences. If a sentence compares two entities (A, B) with respect to some aspect Z, it should be possible to reformulate it into another sentence such as: “A is better than B with respect to Z” (Kessler and Kuhn, 2014a). Based on this definition, there is no comparison between (A-series cameras, its competition) in s1. Here, we adopt this apt definition with a slight restriction to make it more practical, and seek to identify such comparisons automatically. We consider only sentences with at least two entity mentions involved in gradable comparisons, i.e., a clear sense of scaling in the comparison (e.g., A is better than B.). Such comparisons are more useful in investigating the pros and cons of entities, as opposed to equative comparisons expressing parity between two mentions (e.g., A is as good as B.),</context>
<context position="27423" citStr="Kessler and Kuhn, 2014" startWordPosition="4594" endWordPosition="4597">.e., many sentences mention more than two entities. This dataset subsumes the annotated gradable 1In this particular case, all features could have been computed by Lookahead Skip-node using preorder right-to-left DFS enumeration, although it may not be true in general. 2We used already available snapshots for Epinions dataset: http://groups.csail.mit.edu/rbg/code/precis/. P Camera P Cell F1 R F1 R CSR 74.3 52.3 61.3 48.9 61.5* 54.3 BoW 76.9 76.3 76.6 62.2 58.0 59.8 BoW† 77.3 71.9 74.4 69.0 56.3 61.8 SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1* Table 3: Comparison identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 rand</context>
<context position="34470" citStr="Kessler and Kuhn, 2014" startWordPosition="5783" endWordPosition="5786">arisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation ex</context>
</contexts>
<marker>Kessler, Kuhn, 2014</marker>
<rawString>Wiltrud Kessler and Jonas Kuhn. 2014b. Detecting comparative sentiment expressions – a case study in annotation design decisions. In Proceedings of Konferenz zur Verarbeitung Natrlicher Sprache (KONVENS), October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Kurashima</author>
<author>Katsuji Bessho</author>
<author>Hiroyuki Toda</author>
<author>Toshio Uchiyama</author>
<author>Ryoji Kataoka</author>
</authors>
<title>Ranking entities using comparative relations.</title>
<date>2008</date>
<booktitle>In Database and Expert Systems Applications (DEXA),</booktitle>
<pages>124--133</pages>
<contexts>
<context position="34235" citStr="Kurashima et al., 2008" startWordPosition="5745" endWordPosition="5748">ness. If efficiency is of paramount importance, the two approximations are significantly faster, without much degradation (none in some cases) of effectiveness. 6 Related Work Exploiting comparisons in text begins with identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identificat</context>
</contexts>
<marker>Kurashima, Bessho, Toda, Uchiyama, Kataoka, 2008</marker>
<rawString>Takeshi Kurashima, Katsuji Bessho, Hiroyuki Toda, Toshio Uchiyama, and Ryoji Kataoka. 2008. Ranking entities using comparative relations. In Database and Expert Systems Applications (DEXA), pages 124–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Si Li</author>
<author>Zheng-Jun Zha</author>
<author>Zhaoyan Ming</author>
<author>Meng Wang</author>
<author>Tat-Seng Chua</author>
<author>Jun Guo</author>
<author>Weiran Xu</author>
</authors>
<title>Product comparison using comparative relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>1151--1152</pages>
<contexts>
<context position="34753" citStr="Li et al., 2011" startWordPosition="5830" endWordPosition="5833">ch as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins an</context>
</contexts>
<marker>Li, Zha, Ming, Wang, Chua, Guo, Xu, 2011</marker>
<rawString>Si Li, Zheng-Jun Zha, Zhaoyan Ming, Meng Wang, Tat-Seng Chua, Jun Guo, and Weiran Xu. 2011. Product comparison using comparative relations. In Proceedings of the International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), pages 1151–1152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question-answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>04</issue>
<contexts>
<context position="35046" citStr="Lin and Pantel, 2001" startWordPosition="5871" endWordPosition="5875">06b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; S</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question-answering. Natural Language Engineering, 7(04):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Lin</author>
<author>Timothy Miller</author>
<author>Alvin Kho</author>
<author>Steven Bethard</author>
<author>Dmitriy Dligach</author>
<author>Sameer Pradhan</author>
<author>Guergana Savova</author>
</authors>
<title>Descending-path convolution kernel for syntactic structures.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>81--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="35409" citStr="Lin et al., 2014" startWordPosition="5924" endWordPosition="5927">pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragments with non-matching labels. As lexical similarity can be incorporated into Skip</context>
</contexts>
<marker>Lin, Miller, Kho, Bethard, Dligach, Pradhan, Savova, 2014</marker>
<rawString>Chen Lin, Timothy Miller, Alvin Kho, Steven Bethard, Dmitriy Dligach, Sameer Pradhan, and Guergana Savova. 2014. Descending-path convolution kernel for syntactic structures. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 81–86. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In European Conference on Machine Learning (ECML),</booktitle>
<pages>318--329</pages>
<contexts>
<context position="14624" citStr="Moschitti, 2006" startWordPosition="2396" endWordPosition="2397">evel of similarity. However, if we consider only sub-trees, the two dependency trees share in common only two fragments: [#camera] and [is]. Neither of these fragments is indicative of a comparison. #camera is better than #camera Figure 2: Dependency parses. Working example for the Sub-tree, Subset Tree, Partial Tree kernels. Subset Tree (SST) Space We next consider the SST kernel, which computes similarity in a more general space of substructures than ST. Any subgraph of a tree that preserves production rules is counted. This definition suggests SST is intended more for a constituency parse (Moschitti, 2006a). In this feature space, the parses in Figure 2 now have in common the following fragments: [#camera], [is], [than [#camera]]. This representation is better than ST’s, e.g., the fragment [than [#camera]] is informative. However, as a whole, the set of features are still insufficient to identify a comparison. #camera is twice as expensive as #camera Previously I had D60 and D7100 and #camera is twice as good as #camera Previously I had D60 and #camera and this camera is twice as good as #camera Figure 3: Dependency parses. Working example for the Partial Tree, Skip-node kernels. Partial Tree </context>
<context position="27678" citStr="Moschitti, 2006" startWordPosition="4631" endWordPosition="4632">eneral. 2We used already available snapshots for Epinions dataset: http://groups.csail.mit.edu/rbg/code/precis/. P Camera P Cell F1 R F1 R CSR 74.3 52.3 61.3 48.9 61.5* 54.3 BoW 76.9 76.3 76.6 62.2 58.0 59.8 BoW† 77.3 71.9 74.4 69.0 56.3 61.8 SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1* Table 3: Comparison identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 random data splits in 80:20 proportion of training vs. testing. Performance is measured by using F1, which is the harmonic mean of precision P and recall R: F1 = 2PR P+R. The statistical significance5 is measured by randomization test (Yeh, 2000). The hyper-p</context>
<context position="35440" citStr="Moschitti, 2006" startWordPosition="5930" endWordPosition="5932">dentification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragments with non-matching labels. As lexical similarity can be incorporated into Skip-node kernel, we consider it or</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006a. Efficient convolution kernels for dependency and constituent syntactic trees. In European Conference on Machine Learning (ECML), pages 318–329.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="14624" citStr="Moschitti, 2006" startWordPosition="2396" endWordPosition="2397">evel of similarity. However, if we consider only sub-trees, the two dependency trees share in common only two fragments: [#camera] and [is]. Neither of these fragments is indicative of a comparison. #camera is better than #camera Figure 2: Dependency parses. Working example for the Sub-tree, Subset Tree, Partial Tree kernels. Subset Tree (SST) Space We next consider the SST kernel, which computes similarity in a more general space of substructures than ST. Any subgraph of a tree that preserves production rules is counted. This definition suggests SST is intended more for a constituency parse (Moschitti, 2006a). In this feature space, the parses in Figure 2 now have in common the following fragments: [#camera], [is], [than [#camera]]. This representation is better than ST’s, e.g., the fragment [than [#camera]] is informative. However, as a whole, the set of features are still insufficient to identify a comparison. #camera is twice as expensive as #camera Previously I had D60 and D7100 and #camera is twice as good as #camera Previously I had D60 and #camera and this camera is twice as good as #camera Figure 3: Dependency parses. Working example for the Partial Tree, Skip-node kernels. Partial Tree </context>
<context position="27678" citStr="Moschitti, 2006" startWordPosition="4631" endWordPosition="4632">eneral. 2We used already available snapshots for Epinions dataset: http://groups.csail.mit.edu/rbg/code/precis/. P Camera P Cell F1 R F1 R CSR 74.3 52.3 61.3 48.9 61.5* 54.3 BoW 76.9 76.3 76.6 62.2 58.0 59.8 BoW† 77.3 71.9 74.4 69.0 56.3 61.8 SNK 80.5* 75.2 77.7** 77.2* 55.1 64.1* Table 3: Comparison identification task comparisons of (Kessler and Kuhn, 2014a) derived from Epinions reviews on Digital Cameras. (Jindal and Liu, 2006a)’s dataset is inapplicable, due to its lack of entity-centric comparison. Evaluation The experiments were carried out with SVM-light-TK framework3 (Joachims, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 random data splits in 80:20 proportion of training vs. testing. Performance is measured by using F1, which is the harmonic mean of precision P and recall R: F1 = 2PR P+R. The statistical significance5 is measured by randomization test (Yeh, 2000). The hyper-p</context>
<context position="35440" citStr="Moschitti, 2006" startWordPosition="5930" endWordPosition="5932">dentification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragments with non-matching labels. As lexical similarity can be incorporated into Skip-node kernel, we consider it or</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006b. Making tree kernels practical for natural language learning. In 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
<author>Kentaro Inui</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using crfs with hidden variables.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT),</booktitle>
<pages>786--794</pages>
<contexts>
<context position="34978" citStr="Nakagawa et al., 2010" startWordPosition="5861" endWordPosition="5864">es, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, </context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi. 2010. Dependency tree-based sentiment classification using crfs with hidden variables. In Human Language Technologies: Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT), pages 786–794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Truc-Vien T Nguyen</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Convolution kernels on constituent, dependency and sequential structures for relation extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1378--1387</pages>
<contexts>
<context position="7150" citStr="Nguyen et al., 2009" startWordPosition="1146" endWordPosition="1149">limited ability to model long-range dependencies. For s4, a window of three words around the predicate “better” excludes the word “than” that would have been very informative. Yet, enlarging the window might then bring in irrelevant associations. What is important then is not so much whether a sentence is comparative as whether two entity mentions are related by a comparative relation. One insight we draw is how comparison identification is effectively a form of relation extraction. While there are diverse relation extraction formulations (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Nguyen et al., 2009), our distinct relation type is comparison of two entity mentions. Armed with this insight, we propose a kernelbased approach based on a dependency tree representation (Nivre, 2005), with significant innovations motivated by the comparative identification task. This proposed approach has several advantages over CSR. Most importantly, it models dependencies between any pair of words (including entity mentions), whereas CSR only relates a comparative predicate to nearby POS tags. For other advantages, unlike CSR, this approach is contingent on neither a pre-specified list of comparative predicat</context>
</contexts>
<marker>Nguyen, Moschitti, Riccardi, 2009</marker>
<rawString>Truc-Vien T Nguyen, Alessandro Moschitti, and Giuseppe Riccardi. 2009. Convolution kernels on constituent, dependency and sequential structures for relation extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1378–1387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Dependency grammar and dependency parsing.</title>
<date>2005</date>
<tech>MSI report, 5133(1959):1–32.</tech>
<contexts>
<context position="7331" citStr="Nivre, 2005" startWordPosition="1177" endWordPosition="1178">g the window might then bring in irrelevant associations. What is important then is not so much whether a sentence is comparative as whether two entity mentions are related by a comparative relation. One insight we draw is how comparison identification is effectively a form of relation extraction. While there are diverse relation extraction formulations (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Nguyen et al., 2009), our distinct relation type is comparison of two entity mentions. Armed with this insight, we propose a kernelbased approach based on a dependency tree representation (Nivre, 2005), with significant innovations motivated by the comparative identification task. This proposed approach has several advantages over CSR. Most importantly, it models dependencies between any pair of words (including entity mentions), whereas CSR only relates a comparative predicate to nearby POS tags. For other advantages, unlike CSR, this approach is contingent on neither a pre-specified list of comparative predicates, nor a specific window length. Contributions In this paper, we make the following contributions. First, we re-formulate the problem of automatic identification of comparative sen</context>
</contexts>
<marker>Nivre, 2005</marker>
<rawString>Joakim Nivre. 2005. Dependency grammar and dependency parsing. MSI report, 5133(1959):1–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="1682" citStr="Pang and Lee, 2008" startWordPosition="255" endWordPosition="258">of a new context-sensitive tree kernel: Skip-node Kernel (SNK). We further describe both its exact and approximate computations. Through experiments on real-life datasets, we evaluate the effectiveness of our kernel-based approach for comparison identification, as well as the utility of SNK and its approximations. 1 Introduction When weighing various alternatives, users increasingly turn to the social media, by scouring online reviews, discussion forums, etc. Our goal is to extract from such corpora those text snippets where users make direct comparisons of entities. While sentiment analysis (Pang and Lee, 2008) may be helpful in evaluating individual entities, comparison by the same author within a sentence provides an unambiguous and more equitable basis for the relative positions of two entities on some aspect. For example, the sentence s1 in Table 1, taken from an Amazon review about a digital camera, makes two distinct comparisons: #1) between “A630” and “A-series cameras” and #2) between “A630” and “its competition”, with a clear sense of which entity mention is the greater on some aspect (“larger”). Moreover, comparisons may be objective (e.g., larger) or subjective (e.g., better), while senti</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dae Hoon Park</author>
<author>Catherine Blake</author>
</authors>
<title>Identifying comparative claim sentences in full-text scientific articles.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Detecting Structure in Scholarly Discourse,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="34013" citStr="Park and Blake, 2012" startWordPosition="5710" endWordPosition="5713">s. The experiments were carried out on a PC with Intel Core i5 CPU 3.2 GHz and 4Gb RAM. This experiment shows that the original SNK is still tractable for small S and L, which turn out to be the case for optimal effectiveness. If efficiency is of paramount importance, the two approximations are significantly faster, without much degradation (none in some cases) of effectiveness. 6 Related Work Exploiting comparisons in text begins with identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganap</context>
</contexts>
<marker>Park, Blake, 2012</marker>
<rawString>Dae Hoon Park and Catherine Blake. 2012. Identifying comparative claim sentences in full-text scientific articles. In Proceedings of the Workshop on Detecting Structure in Scholarly Discourse, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Pei</author>
<author>Jiawei Han</author>
<author>Behzad Mortazavi-Asl</author>
<author>Helen Pinto</author>
<author>Qiming Chen</author>
<author>Umeshwar Dayal</author>
<author>MeiChun Hsu</author>
</authors>
<title>Prefixspan: Mining sequential patterns efficiently by prefix-projected pattern growth.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Data Engineering (ICDE),</booktitle>
<pages>0215--0215</pages>
<contexts>
<context position="5840" citStr="Pei et al., 2001" startWordPosition="934" endWordPosition="937">hough not a comparative predicate, could signify a comparison, e.g., in s3 in Table 1. (Jindal and Liu, 2006a) considered the “context” around a predicate. A sentence is transformed into a sequence involving the predicate and the part of speech (POS) within a text window around the predicate (usually three words before and after). For instance, s2 in Table 1 would be transformed into the sequence (PRP VBD DT better NN). Such sequences are labeled comparative or non-comparative, upon which (Jindal and Liu, 2006a) applies sequential pattern mining (Agrawal and Srikant, 1995; Ayres et al., 2002; Pei et al., 2001) to learn class sequential rule (CSR). These CSRs are then used as features in classifying comparative sentences. While (Jindal and Liu, 2006a) makes some progress by considering context, its performance may be affected by several factors. First, CSRs are not sensitive to entity mentions. It may classify s1 as comparative generally, missing the nuance that s1 is not comparing the pair (A-series cameras, its competition). Second, as CSRs requires a list of comparative predicates, the quality and the completeness of the list are crucial. For instance, “amazing” is not in their list, and thus the</context>
</contexts>
<marker>Pei, Han, Mortazavi-Asl, Pinto, Chen, Dayal, Hsu, 2001</marker>
<rawString>Jian Pei, Jiawei Han, Behzad Mortazavi-Asl, Helen Pinto, Qiming Chen, Umeshwar Dayal, and MeiChun Hsu. 2001. Prefixspan: Mining sequential patterns efficiently by prefix-projected pattern growth. In Proceedings of the International Conference on Data Engineering (ICDE), pages 0215– 0215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Natural language inference via dependency tree mapping: An application to question answering.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>6</volume>
<issue>9</issue>
<contexts>
<context position="35023" citStr="Punyakanok et al., 2004" startWordPosition="5867" endWordPosition="5870">icate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007).</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2004</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2004. Natural language inference via dependency tree mapping: An application to question answering. Computational Linguistics, 6(9).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shashank Srivastava</author>
<author>Dirk Hovy</author>
<author>Eduard Hovy</author>
</authors>
<title>A walk-based semantically enriched tree kernel over distributed word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1411--1416</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="35669" citStr="Srivastava et al., 2013" startWordPosition="5966" endWordPosition="5969">), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragments with non-matching labels. As lexical similarity can be incorporated into Skip-node kernel, we consider it orthogonal and complementary. 7 Conclusion We study the effectiveness of a convolution kernel approach for the novel formulation of extracting comparisons within sentences. Our approach outperforms the baselines in identifying comp</context>
</contexts>
<marker>Srivastava, Hovy, Hovy, 2013</marker>
<rawString>Shashank Srivastava, Dirk Hovy, and Eduard Hovy. 2013. A walk-based semantically enriched tree kernel over distributed word representations. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1411– 1416. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingo Steinwart</author>
<author>Andreas Christmann</author>
</authors>
<title>Support vector machines.</title>
<date>2008</date>
<publisher>Springer.</publisher>
<contexts>
<context position="12930" citStr="Steinwart and Christmann, 2008" startWordPosition="2115" endWordPosition="2118">(1) ni∈T1 nj∈T2 Here, ni and nj denote each node in their respective tree instances T1 and T2. D(ni, nj) is the number of common substructure instances between the two sub-trees rooted in ni and nj respectively. The exact form of D(ni, nj) depends on the specific definition of the tree kernel space. In Section 3, we systematically explore the applicability of various tree kernel spaces, leading to the introduction of the new Skip-node Kernel. The appropriate kernel function can be embedded seamlessly in kernel methods for classification. In this work, we use the Support Vector Machines (SVM) (Steinwart and Christmann, 2008). 378 3 Tree Kernel Spaces Tree kernels count substructures of a tree in some high-dimensional feature space. Different tree kernel spaces vary in the amount and the type of information they can capture, and thus may suit different purposes. To find a suitable tree kernel for the comparison identification task, we first systematically explore a progression of known tree kernel spaces, including Sub-tree, Subset Tree, and Partial Tree. Through the use of appropriate examples, we show how these existing tree kernel spaces may not be appropriate for certain instances. This section culminates in t</context>
</contexts>
<marker>Steinwart, Christmann, 2008</marker>
<rawString>Ingo Steinwart and Andreas Christmann. 2008. Support vector machines. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maksim Tkachenko</author>
<author>Hady W Lauw</author>
</authors>
<title>Generative modeling of entity comparisons in text.</title>
<date>2014</date>
<booktitle>In Proceedings of the ACM International Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>859--868</pages>
<contexts>
<context position="34664" citStr="Tkachenko and Lauw, 2014" startWordPosition="5814" endWordPosition="5817">actic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved </context>
</contexts>
<marker>Tkachenko, Lauw, 2014</marker>
<rawString>Maksim Tkachenko and Hady W Lauw. 2014. Generative modeling of entity comparisons in text. In Proceedings of the ACM International Conference on Information and Knowledge Management (CIKM), pages 859–868.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SVN Vishwanathan</author>
<author>Alexander Johannes Smola</author>
</authors>
<title>Fast kernels for string and tree matching.</title>
<date>2004</date>
<booktitle>Kernel Methods in Computational Biology,</booktitle>
<pages>113--130</pages>
<contexts>
<context position="35328" citStr="Vishwanathan and Smola, 2004" startWordPosition="5911" endWordPosition="5914">ima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragme</context>
</contexts>
<marker>Vishwanathan, Smola, 2004</marker>
<rawString>SVN Vishwanathan and Alexander Johannes Smola. 2004. Fast kernels for string and tree matching. Kernel Methods in Computational Biology, pages 113– 130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Watkins</author>
</authors>
<title>Dynamic alignment kernels.</title>
<date>1999</date>
<booktitle>Advances in Neural Information Processing Systems (NIPS),</booktitle>
<pages>39--50</pages>
<contexts>
<context position="35220" citStr="Watkins, 1999" startWordPosition="5898" endWordPosition="5899"> (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word re</context>
</contexts>
<marker>Watkins, 1999</marker>
<rawString>Chris Watkins. 1999. Dynamic alignment kernels. Advances in Neural Information Processing Systems (NIPS), pages 39–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seon Yang</author>
<author>Youngjoong Ko</author>
</authors>
<title>Extracting comparative sentences from Korean text documents using comparative lexical patterns and machine learning techniques.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP Conference Short Papers,</booktitle>
<pages>153--156</pages>
<contexts>
<context position="34211" citStr="Yang and Ko, 2009" startWordPosition="5741" endWordPosition="5744">r optimal effectiveness. If efficiency is of paramount importance, the two approximations are significantly faster, without much degradation (none in some cases) of effectiveness. 6 Related Work Exploiting comparisons in text begins with identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other tha</context>
</contexts>
<marker>Yang, Ko, 2009</marker>
<rawString>Seon Yang and Youngjoong Ko. 2009. Extracting comparative sentences from Korean text documents using comparative lexical patterns and machine learning techniques. In Proceedings of the ACL-IJCNLP Conference Short Papers, pages 153– 156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics (COLING),</booktitle>
<pages>947--953</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="28265" citStr="Yeh, 2000" startWordPosition="4728" endWordPosition="4729">, 1999; Moschitti, 2006b), into which we built Skip-node Kernel. We further release a separate standalone library that we built, called Tree-SVM4, which does SVM optimization using the tree kernels described in this paper. The sentences were parsed and lemmatized with the use of the Stanford NLP software (Chen and Manning, 2014). The experiments were done on 10 random data splits in 80:20 proportion of training vs. testing. Performance is measured by using F1, which is the harmonic mean of precision P and recall R: F1 = 2PR P+R. The statistical significance5 is measured by randomization test (Yeh, 2000). The hyper-parameters, including the baselines’, were optimized for F1 through grid-search. 5.1 Comparison Identification Our first and primary objective is to investigate the effectiveness of the proposed approach on the task of identifying comparisons between a pair of en3http://disi.unitn.it/moschitti/Tree-Kernel.htm 4http://github.com/sitfoxfly/tree-svm 5When presenting the results, an asterisk indicates that the outperformance over the second-best result is significant at 0.05 level. Two asterisks indicate the same at 0.1 level. 382 P Camera P Cell F1 R F1 R CSR 74.6 51.7 60.9 50.9 61.2*</context>
</contexts>
<marker>Yeh, 2000</marker>
<rawString>Alexander Yeh. 2000. More accurate tests for the statistical significance of result differences. In Proceedings of the Conference on Computational Linguistics (COLING), pages 947–953. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Runxiang Zhang</author>
<author>Yaohong Jin</author>
</authors>
<title>Identification and transformation of comparative sentences in patent Chinese-English machine translation.</title>
<date>2012</date>
<booktitle>In International Conference on Asian Language Processing (IALP),</booktitle>
<pages>217--220</pages>
<contexts>
<context position="34276" citStr="Zhang and Jin, 2012" startWordPosition="5753" endWordPosition="5756">nce, the two approximations are significantly faster, without much degradation (none in some cases) of effectiveness. 6 Related Work Exploiting comparisons in text begins with identifying comparisons within sentences. The previous state of the art for English is the baseline CSR approach (Jindal and Liu, 2006a). For scientific text, (Park and Blake, 2012) explored handcrafted syntactic rules that might not cross domains well. Comparisons are also studied in other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found ap</context>
</contexts>
<marker>Zhang, Jin, 2012</marker>
<rawString>Runxiang Zhang and Yaohong Jin. 2012. Identification and transformation of comparative sentences in patent Chinese-English machine translation. In International Conference on Asian Language Processing (IALP), pages 217–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhu Zhang</author>
<author>Chenhui Guo</author>
<author>Paulo Goes</author>
</authors>
<title>Product comparison networks for competitive analysis of online word-of-mouth.</title>
<date>2013</date>
<journal>ACM Transactions on Management Information Systems (TMIS),</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="34735" citStr="Zhang et al., 2013" startWordPosition="5826" endWordPosition="5829"> other languages, such as Chinese, Japanese, and Korean (Huang et al., 2008; Yang and Ko, 2009; Kurashima et al., 2008; Yang and Ko, 2009; Zhang and Jin, 2012). A different task seeks to identify the “components” within comparative sentences, i.e., entities, aspect, comparative predicate (Jindal and Liu, 2006b; Hou and Li, 2008; Kessler and Kuhn, 2014b; Kessler and Kuhn, 2013; Feldman et al., 2007). Others are interested in yet another task to identify the direction of the comparisons (Ganapathibhotla and Liu, 2008; Tkachenko and Lauw, 2014), or the aggregated ranking (Kurashima et al., 2008; Zhang et al., 2013; Li et al., 2011). Our task precedes these tasks in the pipeline. Other than comparison identification, dependency grammar has also found applications in natural language-related tasks, such as sentiment classification (Nakagawa et al., 2010), question answering (Punyakanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subse</context>
</contexts>
<marker>Zhang, Guo, Goes, 2013</marker>
<rawString>Zhu Zhang, Chenhui Guo, and Paulo Goes. 2013. Product comparison networks for competitive analysis of online word-of-mouth. ACM Transactions on Management Information Systems (TMIS), 3(4):20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GuoDong Zhou</author>
<author>Min Zhang</author>
<author>Dong Hong Ji</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Tree kernel-based relation extraction with context-sensitive structured parse tree information. EMNLP-CoNLL,</title>
<date>2007</date>
<pages>728</pages>
<contexts>
<context position="35622" citStr="Zhou et al., 2007" startWordPosition="5958" endWordPosition="5961">akanok et al., 2004; Lin and Pantel, 2001), as well as relation extraction (Culotta and Sorensen, 2004; Bunescu and Mooney, 2005). (Collins and Duffy, 2001) applied convolution kernels (Haussler, 1999; Watkins, 1999) to natural language objects, which evolved into tree kernels, e.g., sub-tree (Vishwanathan and Smola, 2004), subset tree (Collins and Duffy, 2002), descendingpath kernel (Lin et al., 2014), partial tree (Moschitti, 2006a). Skip-node kernel joins the list of tree kernels applicable to dependency trees. These kernels may also apply to other types of trees, e.g., constituency trees (Zhou et al., 2007). (Croce et al., 2011; Srivastava et al., 2013) proposed to capture semantic information along with tree structure, by allowing soft label matching via lexical similarity over distributional word representation. Skip-node gives another perspective on sparsity, using structural alignment of the tree fragments with non-matching labels. As lexical similarity can be incorporated into Skip-node kernel, we consider it orthogonal and complementary. 7 Conclusion We study the effectiveness of a convolution kernel approach for the novel formulation of extracting comparisons within sentences. Our approac</context>
</contexts>
<marker>Zhou, Zhang, Ji, Zhu, 2007</marker>
<rawString>GuoDong Zhou, Min Zhang, Dong Hong Ji, and Qiaoming Zhu. 2007. Tree kernel-based relation extraction with context-sensitive structured parse tree information. EMNLP-CoNLL, page 728.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>