<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000334">
<title confidence="0.941481">
Fully Lexicalising CCGbank with Hat Categories
</title>
<author confidence="0.968406">
Matthew Honnibal and James R. Curran
</author>
<affiliation confidence="0.954025">
School of Information Technologies
University of Sydney
</affiliation>
<note confidence="0.76407">
NSW 2006, Australia
</note>
<email confidence="0.995448">
{mhonn,james}@it.usyd.edu.au
</email>
<sectionHeader confidence="0.994741" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999796733333334">
We introduce an extension to CCG that al-
lows form and function to be represented
simultaneously, reducing the proliferation
of modifier categories seen in standard
CCG analyses.
We can then remove the non-combinatory
rules CCGbank uses to address this prob-
lem, producing a grammar that is fully lex-
icalised and far less ambiguous.
There are intrinsic benefits to full lexi-
calisation, such as semantic transparency
and simpler domain adaptation. The clear-
est advantage is a 52-88% improvement
in parse speeds, which comes with only a
small reduction in accuracy.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998913852941177">
Deep grammars return parses that map transpar-
ently to semantic analyses, allowing information
extraction systems to deal directly with content
representations. Usually, this mapping is lexically
specified, by linking lexical entries to semantic
analyses. This property, lexicalisation, is central to
some of the linguistic theories behind deep gram-
mars, particularly Combinatory Categorial Gram-
mar (Steedman, 2000) and Lexicalised Tree Ad-
joining Grammar (Joshi, 1999).
Lexicalisation can also help deep grammars
achieve satisfactory parse times. Lexicalised
grammars use few rules, which simply manipu-
late the lexical categories. The categories can be
quickly assigned in a supertagging pre-process,
dramatically reducing the search space the parser
must explore (Bangalore and Joshi, 1999).
Combinatory Categorial Grammar (CCG) is
well suited to this strategy, and Clark and Curran
(2007) have highlighted the division of labour be-
tween the parser and the supertagger as one of the
critical aspects of their approach to statistical CCG
parsing. In their system, the division is managed
with parameters that control how many categories
the parser’s chart is seeded with. But even if the
parser is only given one category per word, it still
has a lot of freedom — because the grammar it
uses is not fully lexicalised.
In a fully lexicalised CCG grammar, modifier
categories refer to the category of their head. This
category does not necessarily represent the head’s
constituent type. For instance, the category of an
adverb like still depends on whether it is modify-
ing a predicate verb (1), or a clausal adjunct (2):
</bodyText>
<figure confidence="0.96515575">
(1) The lion
NP
(2) The lion
NP
</figure>
<bodyText confidence="0.999405869565217">
Analyses like these are problematic because the
training data is unlikely to include examples of
each word in every syntactic environment that re-
quires a new category. Hockenmaier and Steed-
man’s (2007) solution was to add category spe-
cific phrase-structure rules to the grammar, which
disrupts the linguistic principles of the formalism,
and introduces over-generation and ambiguity as
shown in Figure 1.
This paper proposes a new way to balance lex-
ical and grammatical ambiguity in CCG. We in-
troduce an extension to the formalism that allows
type-changing rules to be lexically specified. The
extension adds anew field to the category objects,
and one additional rule to utilise it. This allows the
formalism to express type-changing operations in
a theoretically desirable way.
Lexically specifying the type-changing rules re-
duces the ambiguity in the grammar substantially,
which leads to substantial improvements in pars-
ing efficiency. After modifying the C&amp;C parser and
CCGbank, the parser runs almost twice as quickly,
with only a 0.5% reduction in accuracy.
</bodyText>
<figure confidence="0.966772625">
was lying still
VP/VP VP VP\VP
waited,
VP
lying
VP\VP
still
(VP\VP)\(VP\VP)
</figure>
<page confidence="0.946397">
1212
</page>
<note confidence="0.997053">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1212–1221,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<figure confidence="0.993628">
Jamie Pat Robin loves
NP NP NP (S[dcl]\NP)/NP
PSG &gt;T
S/(S/NP) S/(S\NP)
S[dcl]/NP
PSG &gt;
S[dcl]
PSG
&lt;
NP
</figure>
<figureCaption confidence="0.999659">
Figure 1: Over-generation by CCGbank rules.
</figureCaption>
<sectionHeader confidence="0.976403" genericHeader="introduction">
2 Combinatory Categorial Grammar
</sectionHeader>
<bodyText confidence="0.999446694444445">
Combinatory Categorial Grammar (CCG) (Steed-
man, 2000) is a lexicalised grammar formalism
based on categorial grammar (Bar-Hillel, 1953).
CCG can be distinguished from other CG exten-
sions, such as categorial type-logic (Moortgat,
1997) by its attention to linguistic minimalism.
One aim of the theory is to explain universal con-
straints on natural language syntax, so the genera-
tive power of the formalism is intended to closely
match what natural language seems to require.
Steedman and Baldridge (2007) argue that the
requirements can be fulfilled almost entirely by
two basic rule types: application and composition.
Direction specific instances of these types yields a
grammar that consists of just six rules.
Initially, it seemed that some of the rules
had to be restricted to certain contexts, particu-
larly in languages that did not allow scrambling.
Baldridge and Kruijff (2003) have since shown
that rules could be restricted lexically, using a hier-
archy of slash subtypes. This relieved the need for
any language specific meta-rules, allowing CCG to
offer a completely universal grammar, and there-
fore a theory of the innate human language faculty.
With a universal grammar, language specific
variation is confined to the lexicon. A CCG lexi-
cal category is either an atomic type, like N, or a
function that specifies an argument in a particular
direction, and a result, like S\NP (where S is the
result, NP the argument, and \ indicates the argu-
ment must be found to the left).
Hockenmaier and Steedman (2007) showed that
a CCG corpus could be created by adapting the
Penn Treebank (Marcus et al., 1993). CCGbank
has since been used to train fast and accurate CCG
parsers (Clark and Curran, 2007).
</bodyText>
<sectionHeader confidence="0.907715" genericHeader="method">
3 The Need for Type-changing in CCG
</sectionHeader>
<bodyText confidence="0.999966882352941">
We argue that there is a clear need for some sort of
type-changing mechanism in CCG. The practical
need for this has been known since at least Hock-
enmaier (2003), who introduced a type-changing
mechanism into CCGbank in order to control the
problem referred to as modifier category prolifer-
ation. We briefly describe the problem, and then
the prominent solutions that have been proposed.
Unlike formalisms like LTAG and HPSG, CCG
does not use different grammatical rules for argu-
ments and adjuncts. Instead, modifier categories
take the form X1|X1, where X is the category of
the constituent being modified, and the subscript
indicates that the result should inherit from the ar-
gument via unification. The modifier can then use
the application rule to attach to its head, and return
the head unchanged:
</bodyText>
<listItem confidence="0.776254">
(3) unusually resilient
(S[adj]\NP)/(S[adj]\NP) S[adj]\NP
</listItem>
<bodyText confidence="0.998698875">
unusually here modifies the predicative adjec-
tive resilient, attaching it as an argument using
forward application. This prevents resilient from
having to subcategorise for adjuncts, since they are
optional. The problem is that unusually must sub-
categorise for the function of its head. If resilient
changes function and becomes a noun modifier, its
modifiers must change category too:
</bodyText>
<listItem confidence="0.902881">
(4) an unusually resilient strain
NP/N (N/N)/(N/N) N/N N
</listItem>
<bodyText confidence="0.99980545">
There is often a way to analyse around the need
for type-changing operations in CCG. However,
these solutions tend to cause new difficulties, and
the resulting category ambiguity is quite problem-
atic (Hockenmaier and Steedman, 2002). The fact
is that form-to-function coercions are quite com-
mon in English, so the grammar needs a way to
have a constituent be modified according to its
form, before undergoing a type-change to its func-
tion category.
One way to describe the problem is to say that
CCG categories have an over-extended domain of
locality (Joshi, 1999), the part of the derivation
that it describes. A category should specify all and
only the dependencies it governs, but CCG mod-
ifier categories are often forced to specify their
heads’ dependencies as well. These undesirable
notational dependencies can also prevent modi-
fier categories from factoring recursion away from
their domain of locality.
</bodyText>
<figure confidence="0.981086642857143">
&gt;B
NP\NP
1213
S
✭✭ ✭ ✭ ✭ ✭ ✭ ✭ ✭✭✭✭✭❤❤❤❤❤❤❤❤❤❤❤❤❤
✥✥ ✥✥✥ ✥S❵❵❵❵❵❵ S\S
✦ ❛❛❛
✦ ✦
NP ✭✭ ✭ ✭ ✭ ✭ ✭✭ , ✏ ✏NP PPPP
S[dcl]\NP ✏ ✏
❤❤❤❤❤❤❤❤
It (S[dc]\NP)/NP NP , NP/NP ✏ NP PPPP
✘ ✘ ✘ ✘✘ ❳❳❳❳❳ ✏✏ ✏
N
of
NP\NP
❜❜
✧ ✧
(NP\NP)/N
this
NP\NP
S[dcl]
it has happened
NP\NP
❜❜
✧ ✧
(NP\NP)/NP
life
is ✏NP
✏✏ ✏ PPPP
NP
NP
almost
� ❅
N
NP/N
a
way
NP
the fourth time
N
week
</figure>
<figureCaption confidence="0.998937">
Figure 2: CCGbank derivation showing PSG rules.
</figureCaption>
<sectionHeader confidence="0.89132" genericHeader="method">
4 Problems with Existing Proposals
</sectionHeader>
<bodyText confidence="0.99992675">
This section completes the motivation of the pa-
per by arguing that the existing proposals for type-
changing are linguistically unsatisfactory, practi-
cally difficult, or a combination of the two.
</bodyText>
<subsectionHeader confidence="0.999477">
4.1 Problems with PSG Rules
</subsectionHeader>
<bodyText confidence="0.9996789">
Hockenmaier and Steedman (2002) includes a
brief discussion of the modifier category prolif-
eration problem, and introduces unary phrase-
structure rules to address the situation. Figure 2
shows two such rules. The &lt;S[dcl] → NP\NP&gt;1
rule allows the reduced relative clause, it has hap-
pened, to be analysed as a modifier without affect-
ing the category any modifiers that might attach to
it. The other PSG type-changing rule in the deriva-
tion, &lt;, NP → S\S&gt; enables the extraposition, us-
ing the punctuation to make the rule more precise.
One alternative to type-changing rules here
would be to have time subcategorise for the clause,
with a category like NP/S[dcl]. This would cap-
ture the constraint that only a restricted subset of
nouns can be extracted as adjuncts in this way.
The problem is that the extra argument would in-
terfere with the attachment of adjuncts like this
week to the NP, because the NP\NP category can-
not be allowed to participate in backwards cross-
composition rules (Baldridge and Kruijff, 2003).
There are 204 type-changing PSG rules in the
training partition of CCGbank. 53 of the frequent
rules transform produce modifier categories, 48
of them transforming verbal categories. The PSG
1Phrase-structure rules are presented in bottom-up notation.
rules also handle a variety of other constructions,
such as form/function discrepancies like gerund
nominals. By far the most frequent rule, with
115,333 occurrences, is &lt;N → NP&gt;, which trans-
forms bare nominals into noun phrases.
Steedman and Baldridge (2007) describes the
CCG grammar as consisting of just 6 language uni-
versal combinatory rules, plus two lexical opera-
tions (type raising). Not only do the 204 category
specific type-changing rules in CCGbank make
the grammar ambiguous, they also run contrary to
the design principles of the formalism.
CCG is a linguistically motivated formalism,
which means it is not only interested in providing a
convenient, computable notation for grammar de-
velopment. In addition, it constitutes a hypothesis
about the nature of the human language faculty.
Like other lexicalised formalisms, part of the the-
ory is that it is the grammar that is innate, and the
lexicon is acquired.
If the grammar is innate, it must be language
universal, confining all language specific varia-
tion to the lexicon. Baldridge and Kruijff (2003)
described how the remaining language specific
grammatical constraints described by Steedman
(2000) could be controlled in the lexicon, using
multi-modal slashes that have since become inte-
grated into the main body of the theory (Steedman
and Baldridge, 2007).
In addition to being linguistically undesirable,
the PSG rules in CCGbank produce practical dif-
ficulties. Every additional rule increases ambigu-
ity, motivating the C&amp;C system to choose to im-
plement only the most frequent. This decreases
</bodyText>
<page confidence="0.963353">
1214
</page>
<bodyText confidence="0.9999744">
the parser’s coverage, and introduces another di-
mension of domain sensitivity. For instance, the
type-changing rule that allows gerund nominals,
&lt;S[ng]\NP → NP&gt;, occurs roughly 300 times in
the training data. The parser does not implement
this rule, so if it is ported to a new domain, where
the construction is frequent, the rule will have to
be added. Presumably, the parser would also ben-
efit from the removal of rules which are infrequent
in some new, target domain.
The restricted set of PSG rules the parser does
implement results in considerable added ambigu-
ity to the grammar. Figure 1 shows how the rules
interact to produce over-generation.
The PSG rules are also a barrier to the semantic
transparency of the theory, one of its most attrac-
tive properties for natural language engineering.
CCG derivations are isomorphic to semantic analy-
ses, because the derivation instantiates dependen-
cies between CCG categories that can be paired
with semantic categories. This isomorphism is
disrupted by the addition of PSG rules, since the
grammar is no longer lexicalised. Often, the rules
can be semantically annotated, restoring the iso-
morphism; but sometimes, this cannot be done.
For instance, the extraposition rule in Figure 2
transforms the NP category into S\S. There is no
syntactic argument on the NP category to map the
dependency to, so the dependency cannot be cre-
ated (and is in fact missing from CCGbank).
</bodyText>
<subsectionHeader confidence="0.999711">
4.2 Lexical Rules and Zero Morphemes
</subsectionHeader>
<bodyText confidence="0.999973459459459">
The CCGbank PSG extension is closely related to
the zero morpheme categories proposed by Aone
and Wittenburg (1990), which they suggest be
compiled into unary type-changing rules for pro-
cessing. At first glance, it seems that conceptual-
ising the rules as zero morphemes offers a way to
locate them in the lexicon, avoiding the linguistic
difficulties of having a language-specific grammar.
However, CCG aims to provide a transparent inter-
face between the surface form and the semantic
analysis, so epsilon categories, traces, movement
rules and other unrealised structures are explicitly
banned (Steedman, 2000).
From a processing standpoint, if zero mor-
pheme categories are not compiled into phrase-
structure rules, then they will complicate the cate-
gory assignment phase considerably, since we can
no longer assume that exactly one category will be
assigned per word. We are not aware of any pro-
posal for how this difficulty might be overcome.
Carpenter (1992) provides a different sugges-
tion for how sparse modifier categories can be ac-
commodated. His solution is to use meta-rules
that systematically expand the lexicon, much like
the lexical rules used in HPSG (Flickinger, 1987),
which exploit structural regularities to ensure that
the lexicon is more complete.
The problem with this is that it does not actu-
ally make the category set less sparse, so the su-
pertagger’s task is just as difficult. The only ad-
vantage is that its dictionary will be more com-
plete. This is important, but does not solve the
underlying inefficiency in the grammar: CCG cat-
egories have an over-extended domain of locality,
because they cannot represent form and function
simultaneously. This is why some type-changing
mechanism is required.
</bodyText>
<sectionHeader confidence="0.950974" genericHeader="method">
5 Lexically Specified Type-Changing
</sectionHeader>
<bodyText confidence="0.999853">
This section describes our mechanism for lexi-
cally specifying the PSG rules in CCGbank. Figure
3 shows an example of a reduced relative clause
analysed using our extension, hat categories.
CCGbank deploys a solution that achieves form
transparency at the expense of type transparency,
by allowing type-changing rules that are not lexi-
cally specified. One way to recover the lost type
transparency would be to demand that lexical cat-
egories specify what type changing rule (if any)
the category can eventually undergo. For instance,
imagine we have two type-changing rules we wish
to include in our grammar:
</bodyText>
<equation confidence="0.531208">
a) S[ng]\NP NP\NP
b) S[ng]\NP VP\VP2
</equation>
<bodyText confidence="0.997441">
With these two rules, there will be three ways
the S[ng]\NP category might behave in a deriva-
tion. What we need are two extra categories to
control this:
</bodyText>
<listItem confidence="0.999619333333333">
1. S[ng]\NP only allows combinatory rules.
2. (S[ng]\NP)a allows rule a, but not rule b.
3. (S[ng]\NP)b allows rule b, but not rule a.
</listItem>
<bodyText confidence="0.7658555">
Instead of encoding a reference to a rule, we
encode the production rule itself in the category.
</bodyText>
<footnote confidence="0.883614">
2S\NP is occasionally abbreviated as VP.
</footnote>
<page confidence="0.94312">
1215
</page>
<table confidence="0.938566846153846">
asbestos once used in cigarette filters
NNP VP/VP (S[pss]\NP)(NP\NP) (VP\VP)/NP N/N NNP
H &gt; &gt;
NP (S[pss]\NP)(NP\NP) N
NP
&gt;
&lt;
H
&lt;
VP\VP
S[pss](NP\NP)
NP\NP
NP
</table>
<figureCaption confidence="0.991236">
Figure 3: Analysis of a reduced relative clause with lexicalised type-changing.
</figureCaption>
<equation confidence="0.899178875">
H
⎤
⎦ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥
CAT (S[ng]\NP)NP\NP/NP
⎡ CAT (S[ng]\NP)NP\NP
⎢ � �
⎢CAT S
⎢ ⎢RES
⎢ FEAT ng
RES ⎢ ⎢ ⎢
ARG NP1
⎢ ⎣DIR \
HAT NP\NP1
ARG NP
DIR /
HAT [-]
</equation>
<figureCaption confidence="0.998375">
Figure 4: AVM of a hat category.
</figureCaption>
<bodyText confidence="0.99976425">
This allows us to remove the rule from the gram-
mar. Since the bottom of the production will al-
ways be the category itself, we can just specify
how the category can be rewritten:
</bodyText>
<listItem confidence="0.999868">
1. S[ng]\NP can be combined, but not rewritten.
2. (S[ng]\NP)NP\NP can be rewritten as NP\NP.
3. (S[ng]\NP)VP\VP can be rewritten as VP\VP.
</listItem>
<bodyText confidence="0.9999235">
We refer to the superscript category as a hat cat-
egory, as a reference to the notation, but also to
denote the fact that it allows the category to per-
form a different function, or put a different ‘hat’
on. Categories that have a hat specified are re-
ferred to as hatted categories.
</bodyText>
<subsectionHeader confidence="0.970418">
5.1 Changes to Category Objects
</subsectionHeader>
<bodyText confidence="0.997410820512821">
Figure 4 shows an AVM representation of the
(S[ng]\NP)NP\NP/NP category. A field, labelled
hat, has been added to store the destination cate-
gory of the result, NP\NP. The NP argument in
the hat category is co-indexed with the NP argu-
ment in the hatted category. The NP argument is
also co indexed with the result of the destination
category, reflecting the fact that the NP\NP cate-
gory is a modifier, whose head will be the head of
its argument.
Hat categories are handled the same as any other
field during unification. If the two hat fields can-
not be unified, unification fails; and if one hat field
has an empty value, it inherits the value of the hat
field of the other category when unification suc-
ceeds. CCG already requires a unification process
for agreement features (Hockenmaier and Steed-
man, 2007); the hat categories we have introduced
behave identically.
As Figure 4 shows, hat categories can be added
to inner results, allowing arguments to be applied
before the type-changing rule. We add a restriction
that prevents categories with an outermost hat field
from applying arguments — essentially equiva-
lent to stipulating that the slash in a category like
S[ng]\NP must have a null mode.
We also stipulate that only adjuncts may ap-
ply hatted arguments, which can also be lexically
represented by assuming that all non-adjunct cate-
gories have a null value in their hat field, causing
unification with a hatted category to fail.
Together, these restrictions ensure that the unary
rule is used. The hatted category cannot function
as a non-hatted category, because it cannot use its
own arguments, and cannot be used as an argu-
ment of another category. This prevents hat cate-
gories from forming categories that are function-
ally disjunctive: the notation cannot be used to
simulate something like an optional argument.
</bodyText>
<subsectionHeader confidence="0.999271">
5.2 The Type-Change Rule
</subsectionHeader>
<bodyText confidence="0.998865333333333">
To replace the 204 PSG rules in CCGbank, we only
need to introduce one extra schematic rule into the
grammar:
</bodyText>
<equation confidence="0.984198">
XY ⇒ Y (5)
</equation>
<bodyText confidence="0.9868985">
This rule simply unpacks the category, performing
the lexically specified type-change.
</bodyText>
<page confidence="0.976679">
1216
</page>
<subsectionHeader confidence="0.954021">
5.3 Generative Power
</subsectionHeader>
<bodyText confidence="0.999985888888889">
Because hat fields are only transmitted when cate-
gories are successfully unified, there is no way to
produce a novel X ⇒ Y unary production during a
derivation. This means that any derivation that can
be produced using the schematic type-change rule
we have added to the grammar can be produced by
adding a set of unary phrase-structure rules instead
— ensuring that we do not require any extra gen-
erative power than is required to parse CCGbank.
The hat categories do increase the strong gen-
erative power of a CCG grammar that does
not include the CCGbank type-changing rules.
We suggest that this is desirable, in line with
Joshi’s (1999) argument that formalisms should be
designed to have the maximum expressivity while
maintaining the minimum weak generative power
necessary to produce the constructions that have
been observed in natural language.
</bodyText>
<sectionHeader confidence="0.987774" genericHeader="method">
6 Lexicalising Type-raising
</sectionHeader>
<bodyText confidence="0.999692666666667">
So far, we have focused on replacing the phrase-
structure rules added to CCGbank, which are not
part of the CCG linguistic theory. However, the
theory does include some type-changing rules, re-
ferred to as type-raising. Forward and backward
type-raising are used to transform a category X
into the logically equivalent categories T/(T\X)
and T\(T/X) respectively.
Type-raising is generally described as a lexical
operation, rather than a grammatical rule, because
only certain language specific combinations of T
and X produce valid type-raise categories. How-
ever, no specific mechanism for controlling type-
raising has been proposed.
Hat categories are an obvious candidate for this,
so we perform an additional set of experiments
which lexicalise the type-raising rules in CCG-
bank, in addition to the PSG rules.
</bodyText>
<sectionHeader confidence="0.923327" genericHeader="method">
7 Adapting CCGbank
</sectionHeader>
<bodyText confidence="0.999976636363636">
This section describes how we converted CCG-
bank’s PSG rules into analyses that used hat cat-
egories. Most of the PSG rules are unary, which
meant that our changes were limited to adding hat
categories to the child of the unary production and
its subtree. The binary PSG rules that we con-
verted effectively just used punctuation as a cue
for a unary type-change, as seen in the extrapo-
sition rule in Figure 2. These were handled by
adding an extra node for the punctuation applica-
tion, leaving a unary production:
</bodyText>
<equation confidence="0.382452">
NP
</equation>
<bodyText confidence="0.999667290322581">
An alternative analysis would be to assign the
punctuation mark a category to perform the type-
change — in this case, (S\S)/NP. However, this
analysis will be unreliable for many genres, where
punctuation is used inconsistently, so we preferred
that hat category analysis, which we found pro-
duced slightly better results.
We used the same method to convert cases
where CCGbank used conjunctions to cue a type-
change, where the Penn Treebank conversion pro-
cess produced a derivation where two sides of a
coordination had different categories. There were
90 such conjunction coercion rules, which we have
not counted amongst the 204 PSG rules, since they
are ultimately caused by conversion noise.
The main complication when adapting CCG-
bank was the fact that CCG node labels are inter-
dependent through a derivation. If one node label
is changed, its immediate children have to change
node label too, and the changes must be propa-
gated further from there.
Since the dependency between the parent and its
two children is different for each combinator, our
node change rules determine the rule used for the
original production, and then invoke the appropri-
ate replacement rule. In general, the rules find the
result (Ar) and argument (Aa) of the original parent
A and replace them with the appropriate part of the
new parent B. If one of the children is an adjunct
category, a different rule is used. The node change
rules for forward combinators are:
</bodyText>
<table confidence="0.96258925">
App A/Y Y ⇒ B/Y Y
Comp Ar/Y Y/Aa ⇒ Br/Y Y/Ba
Adj. app A/A A ⇒ B/B B
Adj. comp Ar/Ar Ar/Aa ⇒ Br/Br Br/Ba
</table>
<bodyText confidence="0.995911666666667">
The translation rules for backward and crossed
combinators are directly analogous, with the
slashes permuted appropriately.
</bodyText>
<sectionHeader confidence="0.924342" genericHeader="method">
8 Adapting the CCG Parser
</sectionHeader>
<bodyText confidence="0.9983805">
We took the standard 1.02 release of the C&amp;C
parser Clark and Curran (2007) and implemented
the changes required for lexically specified type-
changing.
</bodyText>
<figure confidence="0.987511428571429">
S\S
✪❡
,NP
−→ S\S
✪❡
,S\S
(6)
</figure>
<page confidence="0.970493">
1217
</page>
<table confidence="0.998154125">
LP LR Section 00 sent cat cov LP LR Section 23 sent cat cov
LF LFa„to LF LFa„to
CCGbank derivs 87.18 86.31 86.74 84.78 35.15 94.04 99.06 87.76 86.99 87.38 84.84 37.03 94.26 99.63
Hat derivs 86.64 86.91 86.77 84.44 35.03 93.27 99.53 86.94 87.26 87.10 84.76 36.62 93.35 99.71
Hat+TR derivs 86.58 86.87 86.73 84.16 34.47 93.10 99.63 86.83 87.16 87.00 84.67 36.73 93.17 99.75
CCGbank hybrid 88.07 86.49 87.27 85.30 35.94 94.16 99.06 88.36 87.02 87.68 85.27 36.74 94.33 99.63
Hat hybrid 87.30 86.94 87.12 84.85 35.40 93.31 99.53 87.26 87.03 87.15 84.79 36.25 93.24 99.71
Hat+TR hybrid 85.79 85.30 85.55 83.13 31.90 92.48 99.63 85.93 85.65 85.79 83.39 32.03 92.46 99.75
</table>
<tableCaption confidence="0.999931">
Table 1: Labelled Precision, Recall and F-measure, coverage results on Section 00 and Section 23.
</tableCaption>
<bodyText confidence="0.999979666666667">
The most significant change was building hat
passing and unification into the existing unifica-
tion engine. For many parsers, this would have
been straightforward since they already support
unification with complex feature structures. How-
ever, one of the advantages of CCGbank is that
the unification required is quite simple, which is
one of the reasons why the C&amp;C parser is very fast.
We would estimate that adding hat passing dou-
bled the complexity of the unification engine.
The second step was to add support for hat pass-
ing to all of the existing combinators, because they
do not use the unification engine to construct the
result category. Since each of the combinators
is hard-coded for speed, this was time-consuming
and error prone. However, we created a detailed
set of regression tests for the new versions which
greatly reduced our development time.
Finally, we needed to turn off the existing unary
rules in the parser, and add the simple additional
type-change rule.
</bodyText>
<sectionHeader confidence="0.536295" genericHeader="method">
9 Setting Dictionary Thresholds
</sectionHeader>
<bodyText confidence="0.995577529411765">
The main parameterisation we performed on the
development section was to tune the K parame-
ter of the parser, which controls the frequency at
which a word’s tag dictionary is used during su-
pertagging. For words more frequent than K, the
supertagger is restricted to choosing between cat-
egories that have been assigned to the word in the
training data. Otherwise, the POS dictionary is
used instead. The K parameter has multiple val-
ues, because the supertagger and parser are inte-
grated such that the supertagger initially supplies
only a narrow beam of categories to the parser,
which is widened if parsing fails.
Since we have made the category set larger, the
default values of K = 20,20,20,20,150 produces
poor performance, up to 1.5% lower than the fig-
ures we report in Table 1. We set the K parameter
</bodyText>
<table confidence="0.999929">
Training Section 00 Section 23
Gold Auto Gold Auto
CCGbank derivs 399 413 639 544
Hat derivs 552 566 1070 827
Hat+TR derivs 718 677 1072 906
CCGbank hybrid 369 379 564 480
Hat hybrid 505 513 921 678
Hat+TR hybrid 645 601 913 785
</table>
<tableCaption confidence="0.936258">
Table 2: Parse speeds in words per second.
</tableCaption>
<table confidence="0.999778285714286">
Original Hat
Types Frequency Types Frequency
Binary CCG 2,714 1,097,809 3,840 1,097,358
Type-raise 52 3,998 52 3,996
Unhat 0 0 241 161,069
Binary PSG 215 1,615 74 172
Unary PSG 157 159,663 0 0
</table>
<tableCaption confidence="0.99986">
Table 3: Production types and frequencies.
</tableCaption>
<bodyText confidence="0.999762571428572">
to 50,300,80,80,3000. We investigated the effect
of this setting on the original model, and found
that it had little effect, so we continued using the
default values for the original model.
We also experimented with altering the β values
for the hat parser, which did not improve the per-
formance of the state-of-the-art parsing models.
</bodyText>
<subsectionHeader confidence="0.747953">
10 Parsing Results
</subsectionHeader>
<bodyText confidence="0.999983230769231">
The left side of Table 1 shows our performance
on the development data, Section 00. All of the
dependency results we report refer to the original
dependencies distributed with CCGbank. To en-
sure our results were comparable, we produced a
mapping table of dependency labels from sections
02-21, used for parser training. The table maps
the dependency labels in our corpus to the most
frequent label assigned to matching dependencies
in CCGbank. The correct label is assigned 99.94%
of the time. The hat categories move to the the lex-
icon information that used to be represented in the
grammar, resulting in a larger, more informative
</bodyText>
<page confidence="0.979027">
1218
</page>
<bodyText confidence="0.999944166666667">
category set, making the category accuracies (the
cat column in the table) not comparable.
We experimented with two of the parsing mod-
els described by Clark and Curran (2007). The
derivs model uses features calculated over the
derivations, while the hybrid model uses features
calculated on the dependency structures. How-
ever, unlike the deps model Clark and Curran
(2007) describe, the hybrid model uses two sets
of derivation-based constraints. One set are the
normal form constraints, as described by Eisner
(1996). It also uses constraints that prevent the
parser from using productions that were not seen
in the training data. The hybrid model is slightly
more accurate, but also slightly slower, because
the dependency-based decoding is less efficient.
All of the systems were within 0.5% in accuracy
on the development set, with one exception. The
HAT+TR version performed very poorly with the
hybrid model, while its performance with the de-
rivs model was comparable to the other systems.
The same drop in performance occurs on the eval-
uation set. We do not currently have a convincing
explanation for this, but we presume it is the re-
sult of some unforeseen interaction between the
removal of the type-raising rules from the gram-
mar and the dependency-based features.
The accuracy results on the test data, Section
23, saw similar trends, except that the gap be-
tween the hat systems and the original CCGbank
increased slightly. The CCGbank hybrid model
was only 0.1% more accurate than the HAT hybrid
model on Section 00, but is 0.5% more accurate
on Section 23.
Table 2 compares the parse speeds for the lexi-
calised hat corpora against a parser trained on the
original CCGbank, using the two models. Exactly
the same settings were used to obtain parse times
as were used in the accuracy experiments. The
experiments were all performed on a single core
2.6GHz Pentium 4 Xeon. Speeds are reported as
words parsed per second.
On both Section 00 and Section 23, with both
the derivs and hybrid models, the HAT system was
substantially faster than the original parser. The
HAT+TR system was faster than the HAT system
using automatic POS tags, and slightly faster on
Section 00.
The hat categories allow quite favourable trade-
offs between speed and accuracy to be made. The
original models allow us to parse with automatic
POS tags at 480 words per second with 85.27%
accuracy with the hybrid model, or at 544 words
per second with 84.86% accuracy using the derivs
model. Using the HAT derivs model, we could in-
stead parse at 827 words per second with 84.76%
accuracy, or at 906 words per second and 84.67%
accuracy using the HAT+TR system.
In summary, the HAT and CCGbank derivs mod-
els are equivalent in accuracy, but the HAT ver-
sion is 52% faster. The CCGbank hybrid model
remains the most accurate, but there will also be
many tasks where the 88% improvement in speed
will make it worth using the HAT+TR derivs parser
instead of the CCGbank hybrid model, at a cost of
0.6% accuracy.
</bodyText>
<sectionHeader confidence="0.79521" genericHeader="method">
11 Corpus Statistics
</sectionHeader>
<bodyText confidence="0.999574631578947">
Table 3 shows the number of types and the number
of occurrences of CCG combinatory rules and PSG
rules occurred in CCGbank and the hat corpus.
The hat corpus removes almost all unlicensed
productions, leaving only a long tail of rare pro-
ductions that are the result of noisy derivations.
These productions are generally symptomatic of
problematic analyses, and are difficult to address
automatically because they do not conform to any
consistent pattern. We have omitted the hat+TR
corpus in these figures, because it only differs
from the the hat corpus with respect to type-raising
productions.
Lexicalising the corpus increases the number of
categories required substantially. There are 407
categories that occur 10 or more times in the train-
ing section of CCGbank. The equivalent figure for
the HAT corpus is 507, and for the HAT+TR corpus
it is 540.
</bodyText>
<sectionHeader confidence="0.86777" genericHeader="method">
12 Cleaner Analyses with Hat Categories
</sectionHeader>
<bodyText confidence="0.999970846153846">
The lexicalised type-changing scheme we have
proposed offers many opportunities for favourable
analyses, because it allows form and function to
be represented simultaneously. However, we have
limited our changes to replacing the existing CCG-
bank non-combinatory rules. This allows us to
compare the two strategies for controlling modi-
fier category proliferation more closely, but still
offers some improved analyses.
The most frequent unary production in CCG-
bank, the N⇒NP rule, ensures that nominals can
always take the N category, so adjectives sel-
dom need to be assigned NP/NP. Because ad-
</bodyText>
<page confidence="0.983222">
1219
</page>
<bodyText confidence="0.999525571428571">
jectives and nouns are open class, and bare noun
phrases are fairly common, this reduction in cate-
gory sparseness is quite important.
Lexicalising the type changing rule forces the
head noun to acquire a different category, but does
ensure that its modifiers can attach at the N level
— which is also more linguistically desirable:
</bodyText>
<figure confidence="0.873402733333334">
service lift maintenance contracts
NN/N
H
N/N
&gt;
H
N
This analysis also prevents the extreme category
proliferation problem caused by left-branching
noun phrases:
service lift maintenance contracts
((N/N)...(N/N)) (N/N)/(N/N) N/N N
&gt;
&gt;
N
</figure>
<bodyText confidence="0.970139">
Figure 3 shows a more typical example of an
improved analysis. The non-finite clause is func-
tioning as an adnominal, but its modifier is able to
select its canonical category.
One of the advantages of the CCGbank phrase-
structure rules is that they allow the corpus to in-
clude derivations for which no valid CCG parse can
be formed. The C&amp;C parser has difficulty taking
advantage of these extra sentences, however, be-
cause only so many of the arbitrary binary PSG
rules can be added to the grammar without making
it too ambiguous. Once these rules are lexicalised,
the categories that produce them can be added to
the lexicon as unexceptional, albeit rare, cases.
</bodyText>
<sectionHeader confidence="0.971637" genericHeader="conclusions">
13 Conclusion
</sectionHeader>
<bodyText confidence="0.999965081081081">
Lexicalised grammars represent most of the infor-
mation in a derivation with a sequence of lexi-
cal categories. Traditional CCG analyses require
redundancy between categories whenever there
is nested modification, which suggests that such
analyses will encounter sparse data problems.
While the addition of phrase-structure rules pre-
vents this proliferation of modifier categories, it
does so at a high price. The bulk of the type-
changing rules in CCGbank are not implemented
in the C&amp;C parser, because to do so would increase
the ambiguity in the grammar enormously.
CCG parsers must carefully manage ambiguity,
because there are many ways to bracket the same
CCG derivation. Even with a restricted set of PSG
rules, the C&amp;C parser experiences very large chart
sizes. In addition to making the grammar more
ambiguous, the PSG rules make it less theoreti-
cally sound, and more difficult to produce seman-
tic analyses from the parser’s output.
We have show how CCG analyses can be fully
lexicalised in a way that closely mirrors the in-
troduction of phrase-structure rules. The result is
a corpus that produces faster, accurate parsers, is
well suited for domain adaptation, and allows for
more transparent semantic analysis. We can also
use the same mechanism to lexically specify type-
raising, the first concrete proposal to handle type-
raising as a lexical transformation we are aware of.
From an immediate, empirical perspective, we
have substantially improved the parsing speed of
what is already the fastest deep parser available.
Improvements in parsing efficiency are important
in making parsing a practical technology, since the
volume of text we have available for processing is
growing even faster than the processing resources
we have available.
</bodyText>
<sectionHeader confidence="0.996739" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999223833333333">
We would like to thank Stephen Clark and the
anonymous reviewers for EMNLP and the Gram-
mar Engineering Across Frameworks workshop
for their valuable feedback. This work was sup-
ported by the Australian Research Council under
Discovery Project DP0665973.
</bodyText>
<sectionHeader confidence="0.998963" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999072692307692">
Chinatsu Aone and Kent Wittenburg. 1990. Zero
morphemes in unification-based combinatory
categorial grammar. In ACL, pages 188–193.
Jason Baldridge and Geert-Jan Kruijff. 2003.
Multi-Modal Combinatory Categorial Gram-
mar. In Proceedings of the European Associ-
ation of Computational Linguistics (EACL).
Srinivas Bangalore and Aravind Joshi. 1999. Su-
pertagging: An approach to almost parsing.
Computational Linguistics, 25(2):237–265.
Yehoshua Bar-Hillel. 1953. A quasi-arithmetical
notation for syntactic description. Language,
29:47–58.
</reference>
<figure confidence="0.99660425">
N/N NN/N NN/N N
&gt;
NN/N
N/N
&gt;
(N/N)/(N/N)
N/N
&gt;
</figure>
<page confidence="0.87467">
1220
</page>
<reference confidence="0.989986065217391">
Bob Carpenter. 1992. Categorial grammars, lex-
ical rules, and the English predicative, chap-
ter 3. Oxford University Press.
Stephen Clark and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguis-
tics, 33(4):493–552.
Jason Eisner. 1996. Efficient normal-form parsing
for Combinatory Categorial Grammar. In Pro-
ceedings of the 34th Annual Meeting of the As-
sociation for Computational Linguistics (ACL-
96), pages 79–86. Santa Cruz, CA, USA.
Dan Flickinger. 1987. Lexical Rules in the Hierar-
chical Lexicon. Ph.D. thesis, Stanford Univer-
sity, Stanford, CA.
Julia Hockenmaier. 2003. Data and Models for
Statistical Parsing with Combinatory Catego-
rial Grammar. Ph.D. thesis, University of Ed-
inburgh.
Julia Hockenmaier and Mark Steedman. 2002. Ac-
quiring compact lexicalized grammars from a
cleaner treebank. In Third LREC, pages 1974–
1981.
Julia Hockenmaier and Mark Steedman. 2007.
CCGbank: a corpus of CCG derivations
and dependency structures extracted from the
Penn Treebank. Computational Linguistics,
33(3):355–396.
Aravind K. Joshi. 1999. Explorations of a domain
of locality: Lexicalized tree-adjoining gram-
mar. In CLIN.
Mitchell Marcus, Beatrice Santorini, and Mary
Marcinkiewicz. 1993. Building a large anno-
tated corpus of English: The Penn Treebank.
Computational Linguistics, 19(2):313–330.
Michael Moortgat. 1997. Categorial type logics.
In Johan van Benthem and Alice ter Meulen, ed-
itors, Handbook of Logic and Language, chap-
ter 2, pages 93–177. Elsevier, Amsterdam and
MIT Press, Cambridge MA.
Mark Steedman. 2000. The Syntactic Process. The
MIT Press, Cambridge, MA.
Mark Steedman and Jason Baldridge. 2007.
Combinatory categorial grammar. In Robert
Borsley and Kersti Borjars, editors, Non-
Transformational Syntax. Blackwells.
</reference>
<page confidence="0.991299">
1221
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966343">
<title confidence="0.998686">Fully Lexicalising CCGbank with Hat Categories</title>
<author confidence="0.988912">R Honnibal</author>
<affiliation confidence="0.999824">School of Information University of Sydney</affiliation>
<address confidence="0.983823">NSW 2006, Australia</address>
<abstract confidence="0.9996066">introduce an extension to allows form and function to be represented simultaneously, reducing the proliferation of modifier categories seen in standard We can then remove the non-combinatory rules CCGbank uses to address this problem, producing a grammar that is fully lexicalised and far less ambiguous. There are intrinsic benefits to full lexicalisation, such as semantic transparency and simpler domain adaptation. The clearest advantage is a 52-88% improvement in parse speeds, which comes with only a small reduction in accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Kent Wittenburg</author>
</authors>
<title>Zero morphemes in unification-based combinatory categorial grammar.</title>
<date>1990</date>
<booktitle>In ACL,</booktitle>
<pages>188--193</pages>
<contexts>
<context position="12934" citStr="Aone and Wittenburg (1990)" startWordPosition="2076" endWordPosition="2079"> semantic categories. This isomorphism is disrupted by the addition of PSG rules, since the grammar is no longer lexicalised. Often, the rules can be semantically annotated, restoring the isomorphism; but sometimes, this cannot be done. For instance, the extraposition rule in Figure 2 transforms the NP category into S\S. There is no syntactic argument on the NP category to map the dependency to, so the dependency cannot be created (and is in fact missing from CCGbank). 4.2 Lexical Rules and Zero Morphemes The CCGbank PSG extension is closely related to the zero morpheme categories proposed by Aone and Wittenburg (1990), which they suggest be compiled into unary type-changing rules for processing. At first glance, it seems that conceptualising the rules as zero morphemes offers a way to locate them in the lexicon, avoiding the linguistic difficulties of having a language-specific grammar. However, CCG aims to provide a transparent interface between the surface form and the semantic analysis, so epsilon categories, traces, movement rules and other unrealised structures are explicitly banned (Steedman, 2000). From a processing standpoint, if zero morpheme categories are not compiled into phrasestructure rules,</context>
</contexts>
<marker>Aone, Wittenburg, 1990</marker>
<rawString>Chinatsu Aone and Kent Wittenburg. 1990. Zero morphemes in unification-based combinatory categorial grammar. In ACL, pages 188–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
<author>Geert-Jan Kruijff</author>
</authors>
<title>Multi-Modal Combinatory Categorial Grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of the European Association of Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="4789" citStr="Baldridge and Kruijff (2003)" startWordPosition="734" endWordPosition="737">inguistic minimalism. One aim of the theory is to explain universal constraints on natural language syntax, so the generative power of the formalism is intended to closely match what natural language seems to require. Steedman and Baldridge (2007) argue that the requirements can be fulfilled almost entirely by two basic rule types: application and composition. Direction specific instances of these types yields a grammar that consists of just six rules. Initially, it seemed that some of the rules had to be restricted to certain contexts, particularly in languages that did not allow scrambling. Baldridge and Kruijff (2003) have since shown that rules could be restricted lexically, using a hierarchy of slash subtypes. This relieved the need for any language specific meta-rules, allowing CCG to offer a completely universal grammar, and therefore a theory of the innate human language faculty. With a universal grammar, language specific variation is confined to the lexicon. A CCG lexical category is either an atomic type, like N, or a function that specifies an argument in a particular direction, and a result, like S\NP (where S is the result, NP the argument, and \ indicates the argument must be found to the left)</context>
<context position="9536" citStr="Baldridge and Kruijff, 2003" startWordPosition="1538" endWordPosition="1541">. The other PSG type-changing rule in the derivation, &lt;, NP → S\S&gt; enables the extraposition, using the punctuation to make the rule more precise. One alternative to type-changing rules here would be to have time subcategorise for the clause, with a category like NP/S[dcl]. This would capture the constraint that only a restricted subset of nouns can be extracted as adjuncts in this way. The problem is that the extra argument would interfere with the attachment of adjuncts like this week to the NP, because the NP\NP category cannot be allowed to participate in backwards crosscomposition rules (Baldridge and Kruijff, 2003). There are 204 type-changing PSG rules in the training partition of CCGbank. 53 of the frequent rules transform produce modifier categories, 48 of them transforming verbal categories. The PSG 1Phrase-structure rules are presented in bottom-up notation. rules also handle a variety of other constructions, such as form/function discrepancies like gerund nominals. By far the most frequent rule, with 115,333 occurrences, is &lt;N → NP&gt;, which transforms bare nominals into noun phrases. Steedman and Baldridge (2007) describes the CCG grammar as consisting of just 6 language universal combinatory rules</context>
<context position="10857" citStr="Baldridge and Kruijff (2003)" startWordPosition="1744" endWordPosition="1747">ging rules in CCGbank make the grammar ambiguous, they also run contrary to the design principles of the formalism. CCG is a linguistically motivated formalism, which means it is not only interested in providing a convenient, computable notation for grammar development. In addition, it constitutes a hypothesis about the nature of the human language faculty. Like other lexicalised formalisms, part of the theory is that it is the grammar that is innate, and the lexicon is acquired. If the grammar is innate, it must be language universal, confining all language specific variation to the lexicon. Baldridge and Kruijff (2003) described how the remaining language specific grammatical constraints described by Steedman (2000) could be controlled in the lexicon, using multi-modal slashes that have since become integrated into the main body of the theory (Steedman and Baldridge, 2007). In addition to being linguistically undesirable, the PSG rules in CCGbank produce practical difficulties. Every additional rule increases ambiguity, motivating the C&amp;C system to choose to implement only the most frequent. This decreases 1214 the parser’s coverage, and introduces another dimension of domain sensitivity. For instance, the </context>
</contexts>
<marker>Baldridge, Kruijff, 2003</marker>
<rawString>Jason Baldridge and Geert-Jan Kruijff. 2003. Multi-Modal Combinatory Categorial Grammar. In Proceedings of the European Association of Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Aravind Joshi</author>
</authors>
<title>Supertagging: An approach to almost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="1565" citStr="Bangalore and Joshi, 1999" startWordPosition="220" endWordPosition="223">lly, this mapping is lexically specified, by linking lexical entries to semantic analyses. This property, lexicalisation, is central to some of the linguistic theories behind deep grammars, particularly Combinatory Categorial Grammar (Steedman, 2000) and Lexicalised Tree Adjoining Grammar (Joshi, 1999). Lexicalisation can also help deep grammars achieve satisfactory parse times. Lexicalised grammars use few rules, which simply manipulate the lexical categories. The categories can be quickly assigned in a supertagging pre-process, dramatically reducing the search space the parser must explore (Bangalore and Joshi, 1999). Combinatory Categorial Grammar (CCG) is well suited to this strategy, and Clark and Curran (2007) have highlighted the division of labour between the parser and the supertagger as one of the critical aspects of their approach to statistical CCG parsing. In their system, the division is managed with parameters that control how many categories the parser’s chart is seeded with. But even if the parser is only given one category per word, it still has a lot of freedom — because the grammar it uses is not fully lexicalised. In a fully lexicalised CCG grammar, modifier categories refer to the cate</context>
</contexts>
<marker>Bangalore, Joshi, 1999</marker>
<rawString>Srinivas Bangalore and Aravind Joshi. 1999. Supertagging: An approach to almost parsing. Computational Linguistics, 25(2):237–265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yehoshua Bar-Hillel</author>
</authors>
<title>A quasi-arithmetical notation for syntactic description.</title>
<date>1953</date>
<journal>Language,</journal>
<pages>29--47</pages>
<contexts>
<context position="4040" citStr="Bar-Hillel, 1953" startWordPosition="617" endWordPosition="618">s almost twice as quickly, with only a 0.5% reduction in accuracy. was lying still VP/VP VP VP\VP waited, VP lying VP\VP still (VP\VP)\(VP\VP) 1212 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1212–1221, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP Jamie Pat Robin loves NP NP NP (S[dcl]\NP)/NP PSG &gt;T S/(S/NP) S/(S\NP) S[dcl]/NP PSG &gt; S[dcl] PSG &lt; NP Figure 1: Over-generation by CCGbank rules. 2 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (Steedman, 2000) is a lexicalised grammar formalism based on categorial grammar (Bar-Hillel, 1953). CCG can be distinguished from other CG extensions, such as categorial type-logic (Moortgat, 1997) by its attention to linguistic minimalism. One aim of the theory is to explain universal constraints on natural language syntax, so the generative power of the formalism is intended to closely match what natural language seems to require. Steedman and Baldridge (2007) argue that the requirements can be fulfilled almost entirely by two basic rule types: application and composition. Direction specific instances of these types yields a grammar that consists of just six rules. Initially, it seemed t</context>
</contexts>
<marker>Bar-Hillel, 1953</marker>
<rawString>Yehoshua Bar-Hillel. 1953. A quasi-arithmetical notation for syntactic description. Language, 29:47–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Categorial grammars, lexical rules, and the English predicative, chapter 3.</title>
<date>1992</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="13780" citStr="Carpenter (1992)" startWordPosition="2211" endWordPosition="2212">lties of having a language-specific grammar. However, CCG aims to provide a transparent interface between the surface form and the semantic analysis, so epsilon categories, traces, movement rules and other unrealised structures are explicitly banned (Steedman, 2000). From a processing standpoint, if zero morpheme categories are not compiled into phrasestructure rules, then they will complicate the category assignment phase considerably, since we can no longer assume that exactly one category will be assigned per word. We are not aware of any proposal for how this difficulty might be overcome. Carpenter (1992) provides a different suggestion for how sparse modifier categories can be accommodated. His solution is to use meta-rules that systematically expand the lexicon, much like the lexical rules used in HPSG (Flickinger, 1987), which exploit structural regularities to ensure that the lexicon is more complete. The problem with this is that it does not actually make the category set less sparse, so the supertagger’s task is just as difficult. The only advantage is that its dictionary will be more complete. This is important, but does not solve the underlying inefficiency in the grammar: CCG categori</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Bob Carpenter. 1992. Categorial grammars, lexical rules, and the English predicative, chapter 3. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="1664" citStr="Clark and Curran (2007)" startWordPosition="235" endWordPosition="238">ty, lexicalisation, is central to some of the linguistic theories behind deep grammars, particularly Combinatory Categorial Grammar (Steedman, 2000) and Lexicalised Tree Adjoining Grammar (Joshi, 1999). Lexicalisation can also help deep grammars achieve satisfactory parse times. Lexicalised grammars use few rules, which simply manipulate the lexical categories. The categories can be quickly assigned in a supertagging pre-process, dramatically reducing the search space the parser must explore (Bangalore and Joshi, 1999). Combinatory Categorial Grammar (CCG) is well suited to this strategy, and Clark and Curran (2007) have highlighted the division of labour between the parser and the supertagger as one of the critical aspects of their approach to statistical CCG parsing. In their system, the division is managed with parameters that control how many categories the parser’s chart is seeded with. But even if the parser is only given one category per word, it still has a lot of freedom — because the grammar it uses is not fully lexicalised. In a fully lexicalised CCG grammar, modifier categories refer to the category of their head. This category does not necessarily represent the head’s constituent type. For i</context>
<context position="5609" citStr="Clark and Curran, 2007" startWordPosition="875" endWordPosition="878">ersal grammar, and therefore a theory of the innate human language faculty. With a universal grammar, language specific variation is confined to the lexicon. A CCG lexical category is either an atomic type, like N, or a function that specifies an argument in a particular direction, and a result, like S\NP (where S is the result, NP the argument, and \ indicates the argument must be found to the left). Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al., 1993). CCGbank has since been used to train fast and accurate CCG parsers (Clark and Curran, 2007). 3 The Need for Type-changing in CCG We argue that there is a clear need for some sort of type-changing mechanism in CCG. The practical need for this has been known since at least Hockenmaier (2003), who introduced a type-changing mechanism into CCGbank in order to control the problem referred to as modifier category proliferation. We briefly describe the problem, and then the prominent solutions that have been proposed. Unlike formalisms like LTAG and HPSG, CCG does not use different grammatical rules for arguments and adjuncts. Instead, modifier categories take the form X1|X1, where X is th</context>
<context position="22826" citStr="Clark and Curran (2007)" startWordPosition="3746" endWordPosition="3749">e replacement rule. In general, the rules find the result (Ar) and argument (Aa) of the original parent A and replace them with the appropriate part of the new parent B. If one of the children is an adjunct category, a different rule is used. The node change rules for forward combinators are: App A/Y Y ⇒ B/Y Y Comp Ar/Y Y/Aa ⇒ Br/Y Y/Ba Adj. app A/A A ⇒ B/B B Adj. comp Ar/Ar Ar/Aa ⇒ Br/Br Br/Ba The translation rules for backward and crossed combinators are directly analogous, with the slashes permuted appropriately. 8 Adapting the CCG Parser We took the standard 1.02 release of the C&amp;C parser Clark and Curran (2007) and implemented the changes required for lexically specified typechanging. S\S ✪❡ ,NP −→ S\S ✪❡ ,S\S (6) 1217 LP LR Section 00 sent cat cov LP LR Section 23 sent cat cov LF LFa„to LF LFa„to CCGbank derivs 87.18 86.31 86.74 84.78 35.15 94.04 99.06 87.76 86.99 87.38 84.84 37.03 94.26 99.63 Hat derivs 86.64 86.91 86.77 84.44 35.03 93.27 99.53 86.94 87.26 87.10 84.76 36.62 93.35 99.71 Hat+TR derivs 86.58 86.87 86.73 84.16 34.47 93.10 99.63 86.83 87.16 87.00 84.67 36.73 93.17 99.75 CCGbank hybrid 88.07 86.49 87.27 85.30 35.94 94.16 99.06 88.36 87.02 87.68 85.27 36.74 94.33 99.63 Hat hybrid 87.30 8</context>
<context position="27193" citStr="Clark and Curran (2007)" startWordPosition="4484" endWordPosition="4487">nsure our results were comparable, we produced a mapping table of dependency labels from sections 02-21, used for parser training. The table maps the dependency labels in our corpus to the most frequent label assigned to matching dependencies in CCGbank. The correct label is assigned 99.94% of the time. The hat categories move to the the lexicon information that used to be represented in the grammar, resulting in a larger, more informative 1218 category set, making the category accuracies (the cat column in the table) not comparable. We experimented with two of the parsing models described by Clark and Curran (2007). The derivs model uses features calculated over the derivations, while the hybrid model uses features calculated on the dependency structures. However, unlike the deps model Clark and Curran (2007) describe, the hybrid model uses two sets of derivation-based constraints. One set are the normal form constraints, as described by Eisner (1996). It also uses constraints that prevent the parser from using productions that were not seen in the training data. The hybrid model is slightly more accurate, but also slightly slower, because the dependency-based decoding is less efficient. All of the syst</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R. Curran. 2007. Widecoverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics, 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Efficient normal-form parsing for Combinatory Categorial Grammar.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics (ACL96),</booktitle>
<pages>79--86</pages>
<location>Santa Cruz, CA, USA.</location>
<contexts>
<context position="27536" citStr="Eisner (1996)" startWordPosition="4538" endWordPosition="4539">mation that used to be represented in the grammar, resulting in a larger, more informative 1218 category set, making the category accuracies (the cat column in the table) not comparable. We experimented with two of the parsing models described by Clark and Curran (2007). The derivs model uses features calculated over the derivations, while the hybrid model uses features calculated on the dependency structures. However, unlike the deps model Clark and Curran (2007) describe, the hybrid model uses two sets of derivation-based constraints. One set are the normal form constraints, as described by Eisner (1996). It also uses constraints that prevent the parser from using productions that were not seen in the training data. The hybrid model is slightly more accurate, but also slightly slower, because the dependency-based decoding is less efficient. All of the systems were within 0.5% in accuracy on the development set, with one exception. The HAT+TR version performed very poorly with the hybrid model, while its performance with the derivs model was comparable to the other systems. The same drop in performance occurs on the evaluation set. We do not currently have a convincing explanation for this, bu</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996. Efficient normal-form parsing for Combinatory Categorial Grammar. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics (ACL96), pages 79–86. Santa Cruz, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<date>1987</date>
<booktitle>Lexical Rules in the Hierarchical Lexicon. Ph.D. thesis,</booktitle>
<institution>Stanford University,</institution>
<location>Stanford, CA.</location>
<contexts>
<context position="14002" citStr="Flickinger, 1987" startWordPosition="2246" endWordPosition="2247">ctures are explicitly banned (Steedman, 2000). From a processing standpoint, if zero morpheme categories are not compiled into phrasestructure rules, then they will complicate the category assignment phase considerably, since we can no longer assume that exactly one category will be assigned per word. We are not aware of any proposal for how this difficulty might be overcome. Carpenter (1992) provides a different suggestion for how sparse modifier categories can be accommodated. His solution is to use meta-rules that systematically expand the lexicon, much like the lexical rules used in HPSG (Flickinger, 1987), which exploit structural regularities to ensure that the lexicon is more complete. The problem with this is that it does not actually make the category set less sparse, so the supertagger’s task is just as difficult. The only advantage is that its dictionary will be more complete. This is important, but does not solve the underlying inefficiency in the grammar: CCG categories have an over-extended domain of locality, because they cannot represent form and function simultaneously. This is why some type-changing mechanism is required. 5 Lexically Specified Type-Changing This section describes </context>
</contexts>
<marker>Flickinger, 1987</marker>
<rawString>Dan Flickinger. 1987. Lexical Rules in the Hierarchical Lexicon. Ph.D. thesis, Stanford University, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
</authors>
<title>Data and Models for Statistical Parsing with Combinatory Categorial Grammar.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="5808" citStr="Hockenmaier (2003)" startWordPosition="913" endWordPosition="915">e, like N, or a function that specifies an argument in a particular direction, and a result, like S\NP (where S is the result, NP the argument, and \ indicates the argument must be found to the left). Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al., 1993). CCGbank has since been used to train fast and accurate CCG parsers (Clark and Curran, 2007). 3 The Need for Type-changing in CCG We argue that there is a clear need for some sort of type-changing mechanism in CCG. The practical need for this has been known since at least Hockenmaier (2003), who introduced a type-changing mechanism into CCGbank in order to control the problem referred to as modifier category proliferation. We briefly describe the problem, and then the prominent solutions that have been proposed. Unlike formalisms like LTAG and HPSG, CCG does not use different grammatical rules for arguments and adjuncts. Instead, modifier categories take the form X1|X1, where X is the category of the constituent being modified, and the subscript indicates that the result should inherit from the argument via unification. The modifier can then use the application rule to attach to</context>
</contexts>
<marker>Hockenmaier, 2003</marker>
<rawString>Julia Hockenmaier. 2003. Data and Models for Statistical Parsing with Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Acquiring compact lexicalized grammars from a cleaner treebank.</title>
<date>2002</date>
<booktitle>In Third LREC,</booktitle>
<pages>pages</pages>
<contexts>
<context position="7183" citStr="Hockenmaier and Steedman, 2002" startWordPosition="1122" endWordPosition="1125">ctive resilient, attaching it as an argument using forward application. This prevents resilient from having to subcategorise for adjuncts, since they are optional. The problem is that unusually must subcategorise for the function of its head. If resilient changes function and becomes a noun modifier, its modifiers must change category too: (4) an unusually resilient strain NP/N (N/N)/(N/N) N/N N There is often a way to analyse around the need for type-changing operations in CCG. However, these solutions tend to cause new difficulties, and the resulting category ambiguity is quite problematic (Hockenmaier and Steedman, 2002). The fact is that form-to-function coercions are quite common in English, so the grammar needs a way to have a constituent be modified according to its form, before undergoing a type-change to its function category. One way to describe the problem is to say that CCG categories have an over-extended domain of locality (Joshi, 1999), the part of the derivation that it describes. A category should specify all and only the dependencies it governs, but CCG modifier categories are often forced to specify their heads’ dependencies as well. These undesirable notational dependencies can also prevent m</context>
<context position="8554" citStr="Hockenmaier and Steedman (2002)" startWordPosition="1372" endWordPosition="1375">❵❵❵❵❵ S\S ✦ ❛❛❛ ✦ ✦ NP ✭✭ ✭ ✭ ✭ ✭ ✭✭ , ✏ ✏NP PPPP S[dcl]\NP ✏ ✏ ❤❤❤❤❤❤❤❤ It (S[dc]\NP)/NP NP , NP/NP ✏ NP PPPP ✘ ✘ ✘ ✘✘ ❳❳❳❳❳ ✏✏ ✏ N of NP\NP ❜❜ ✧ ✧ (NP\NP)/N this NP\NP S[dcl] it has happened NP\NP ❜❜ ✧ ✧ (NP\NP)/NP life is ✏NP ✏✏ ✏ PPPP NP NP almost � ❅ N NP/N a way NP the fourth time N week Figure 2: CCGbank derivation showing PSG rules. 4 Problems with Existing Proposals This section completes the motivation of the paper by arguing that the existing proposals for typechanging are linguistically unsatisfactory, practically difficult, or a combination of the two. 4.1 Problems with PSG Rules Hockenmaier and Steedman (2002) includes a brief discussion of the modifier category proliferation problem, and introduces unary phrasestructure rules to address the situation. Figure 2 shows two such rules. The &lt;S[dcl] → NP\NP&gt;1 rule allows the reduced relative clause, it has happened, to be analysed as a modifier without affecting the category any modifiers that might attach to it. The other PSG type-changing rule in the derivation, &lt;, NP → S\S&gt; enables the extraposition, using the punctuation to make the rule more precise. One alternative to type-changing rules here would be to have time subcategorise for the clause, wit</context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2002. Acquiring compact lexicalized grammars from a cleaner treebank. In Third LREC, pages 1974– 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="5422" citStr="Hockenmaier and Steedman (2007)" startWordPosition="842" endWordPosition="845">ave since shown that rules could be restricted lexically, using a hierarchy of slash subtypes. This relieved the need for any language specific meta-rules, allowing CCG to offer a completely universal grammar, and therefore a theory of the innate human language faculty. With a universal grammar, language specific variation is confined to the lexicon. A CCG lexical category is either an atomic type, like N, or a function that specifies an argument in a particular direction, and a result, like S\NP (where S is the result, NP the argument, and \ indicates the argument must be found to the left). Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al., 1993). CCGbank has since been used to train fast and accurate CCG parsers (Clark and Curran, 2007). 3 The Need for Type-changing in CCG We argue that there is a clear need for some sort of type-changing mechanism in CCG. The practical need for this has been known since at least Hockenmaier (2003), who introduced a type-changing mechanism into CCGbank in order to control the problem referred to as modifier category proliferation. We briefly describe the problem, and then the prominent solutions that have be</context>
<context position="17545" citStr="Hockenmaier and Steedman, 2007" startWordPosition="2870" endWordPosition="2874">ument in the hat category is co-indexed with the NP argument in the hatted category. The NP argument is also co indexed with the result of the destination category, reflecting the fact that the NP\NP category is a modifier, whose head will be the head of its argument. Hat categories are handled the same as any other field during unification. If the two hat fields cannot be unified, unification fails; and if one hat field has an empty value, it inherits the value of the hat field of the other category when unification succeeds. CCG already requires a unification process for agreement features (Hockenmaier and Steedman, 2007); the hat categories we have introduced behave identically. As Figure 4 shows, hat categories can be added to inner results, allowing arguments to be applied before the type-changing rule. We add a restriction that prevents categories with an outermost hat field from applying arguments — essentially equivalent to stipulating that the slash in a category like S[ng]\NP must have a null mode. We also stipulate that only adjuncts may apply hatted arguments, which can also be lexically represented by assuming that all non-adjunct categories have a null value in their hat field, causing unification </context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2007. CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank. Computational Linguistics, 33(3):355–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Explorations of a domain of locality: Lexicalized tree-adjoining grammar.</title>
<date>1999</date>
<booktitle>In CLIN.</booktitle>
<contexts>
<context position="1242" citStr="Joshi, 1999" startWordPosition="177" endWordPosition="178"> adaptation. The clearest advantage is a 52-88% improvement in parse speeds, which comes with only a small reduction in accuracy. 1 Introduction Deep grammars return parses that map transparently to semantic analyses, allowing information extraction systems to deal directly with content representations. Usually, this mapping is lexically specified, by linking lexical entries to semantic analyses. This property, lexicalisation, is central to some of the linguistic theories behind deep grammars, particularly Combinatory Categorial Grammar (Steedman, 2000) and Lexicalised Tree Adjoining Grammar (Joshi, 1999). Lexicalisation can also help deep grammars achieve satisfactory parse times. Lexicalised grammars use few rules, which simply manipulate the lexical categories. The categories can be quickly assigned in a supertagging pre-process, dramatically reducing the search space the parser must explore (Bangalore and Joshi, 1999). Combinatory Categorial Grammar (CCG) is well suited to this strategy, and Clark and Curran (2007) have highlighted the division of labour between the parser and the supertagger as one of the critical aspects of their approach to statistical CCG parsing. In their system, the </context>
<context position="7516" citStr="Joshi, 1999" startWordPosition="1181" endWordPosition="1182">sually resilient strain NP/N (N/N)/(N/N) N/N N There is often a way to analyse around the need for type-changing operations in CCG. However, these solutions tend to cause new difficulties, and the resulting category ambiguity is quite problematic (Hockenmaier and Steedman, 2002). The fact is that form-to-function coercions are quite common in English, so the grammar needs a way to have a constituent be modified according to its form, before undergoing a type-change to its function category. One way to describe the problem is to say that CCG categories have an over-extended domain of locality (Joshi, 1999), the part of the derivation that it describes. A category should specify all and only the dependencies it governs, but CCG modifier categories are often forced to specify their heads’ dependencies as well. These undesirable notational dependencies can also prevent modifier categories from factoring recursion away from their domain of locality. &gt;B NP\NP 1213 S ✭✭ ✭ ✭ ✭ ✭ ✭ ✭ ✭✭✭✭✭❤❤❤❤❤❤❤❤❤❤❤❤❤ ✥✥ ✥✥✥ ✥S❵❵❵❵❵❵ S\S ✦ ❛❛❛ ✦ ✦ NP ✭✭ ✭ ✭ ✭ ✭ ✭✭ , ✏ ✏NP PPPP S[dcl]\NP ✏ ✏ ❤❤❤❤❤❤❤❤ It (S[dc]\NP)/NP NP , NP/NP ✏ NP PPPP ✘ ✘ ✘ ✘✘ ❳❳❳❳❳ ✏✏ ✏ N of NP\NP ❜❜ ✧ ✧ (NP\NP)/N this NP\NP S[dcl] it has happened </context>
</contexts>
<marker>Joshi, 1999</marker>
<rawString>Aravind K. Joshi. 1999. Explorations of a domain of locality: Lexicalized tree-adjoining grammar. In CLIN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="5516" citStr="Marcus et al., 1993" startWordPosition="859" endWordPosition="862">ved the need for any language specific meta-rules, allowing CCG to offer a completely universal grammar, and therefore a theory of the innate human language faculty. With a universal grammar, language specific variation is confined to the lexicon. A CCG lexical category is either an atomic type, like N, or a function that specifies an argument in a particular direction, and a result, like S\NP (where S is the result, NP the argument, and \ indicates the argument must be found to the left). Hockenmaier and Steedman (2007) showed that a CCG corpus could be created by adapting the Penn Treebank (Marcus et al., 1993). CCGbank has since been used to train fast and accurate CCG parsers (Clark and Curran, 2007). 3 The Need for Type-changing in CCG We argue that there is a clear need for some sort of type-changing mechanism in CCG. The practical need for this has been known since at least Hockenmaier (2003), who introduced a type-changing mechanism into CCGbank in order to control the problem referred to as modifier category proliferation. We briefly describe the problem, and then the prominent solutions that have been proposed. Unlike formalisms like LTAG and HPSG, CCG does not use different grammatical rule</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Categorial type logics.</title>
<date>1997</date>
<booktitle>In Johan van Benthem and Alice ter Meulen, editors, Handbook of Logic and Language, chapter 2,</booktitle>
<pages>93--177</pages>
<publisher>Elsevier,</publisher>
<location>Amsterdam and</location>
<contexts>
<context position="4139" citStr="Moortgat, 1997" startWordPosition="632" endWordPosition="633">ted, VP lying VP\VP still (VP\VP)\(VP\VP) 1212 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1212–1221, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP Jamie Pat Robin loves NP NP NP (S[dcl]\NP)/NP PSG &gt;T S/(S/NP) S/(S\NP) S[dcl]/NP PSG &gt; S[dcl] PSG &lt; NP Figure 1: Over-generation by CCGbank rules. 2 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (Steedman, 2000) is a lexicalised grammar formalism based on categorial grammar (Bar-Hillel, 1953). CCG can be distinguished from other CG extensions, such as categorial type-logic (Moortgat, 1997) by its attention to linguistic minimalism. One aim of the theory is to explain universal constraints on natural language syntax, so the generative power of the formalism is intended to closely match what natural language seems to require. Steedman and Baldridge (2007) argue that the requirements can be fulfilled almost entirely by two basic rule types: application and composition. Direction specific instances of these types yields a grammar that consists of just six rules. Initially, it seemed that some of the rules had to be restricted to certain contexts, particularly in languages that did </context>
</contexts>
<marker>Moortgat, 1997</marker>
<rawString>Michael Moortgat. 1997. Categorial type logics. In Johan van Benthem and Alice ter Meulen, editors, Handbook of Logic and Language, chapter 2, pages 93–177. Elsevier, Amsterdam and MIT Press, Cambridge MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1189" citStr="Steedman, 2000" startWordPosition="169" endWordPosition="170">sation, such as semantic transparency and simpler domain adaptation. The clearest advantage is a 52-88% improvement in parse speeds, which comes with only a small reduction in accuracy. 1 Introduction Deep grammars return parses that map transparently to semantic analyses, allowing information extraction systems to deal directly with content representations. Usually, this mapping is lexically specified, by linking lexical entries to semantic analyses. This property, lexicalisation, is central to some of the linguistic theories behind deep grammars, particularly Combinatory Categorial Grammar (Steedman, 2000) and Lexicalised Tree Adjoining Grammar (Joshi, 1999). Lexicalisation can also help deep grammars achieve satisfactory parse times. Lexicalised grammars use few rules, which simply manipulate the lexical categories. The categories can be quickly assigned in a supertagging pre-process, dramatically reducing the search space the parser must explore (Bangalore and Joshi, 1999). Combinatory Categorial Grammar (CCG) is well suited to this strategy, and Clark and Curran (2007) have highlighted the division of labour between the parser and the supertagger as one of the critical aspects of their appro</context>
<context position="3958" citStr="Steedman, 2000" startWordPosition="605" endWordPosition="607">n parsing efficiency. After modifying the C&amp;C parser and CCGbank, the parser runs almost twice as quickly, with only a 0.5% reduction in accuracy. was lying still VP/VP VP VP\VP waited, VP lying VP\VP still (VP\VP)\(VP\VP) 1212 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1212–1221, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP Jamie Pat Robin loves NP NP NP (S[dcl]\NP)/NP PSG &gt;T S/(S/NP) S/(S\NP) S[dcl]/NP PSG &gt; S[dcl] PSG &lt; NP Figure 1: Over-generation by CCGbank rules. 2 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (Steedman, 2000) is a lexicalised grammar formalism based on categorial grammar (Bar-Hillel, 1953). CCG can be distinguished from other CG extensions, such as categorial type-logic (Moortgat, 1997) by its attention to linguistic minimalism. One aim of the theory is to explain universal constraints on natural language syntax, so the generative power of the formalism is intended to closely match what natural language seems to require. Steedman and Baldridge (2007) argue that the requirements can be fulfilled almost entirely by two basic rule types: application and composition. Direction specific instances of th</context>
<context position="10956" citStr="Steedman (2000)" startWordPosition="1758" endWordPosition="1759">sm. CCG is a linguistically motivated formalism, which means it is not only interested in providing a convenient, computable notation for grammar development. In addition, it constitutes a hypothesis about the nature of the human language faculty. Like other lexicalised formalisms, part of the theory is that it is the grammar that is innate, and the lexicon is acquired. If the grammar is innate, it must be language universal, confining all language specific variation to the lexicon. Baldridge and Kruijff (2003) described how the remaining language specific grammatical constraints described by Steedman (2000) could be controlled in the lexicon, using multi-modal slashes that have since become integrated into the main body of the theory (Steedman and Baldridge, 2007). In addition to being linguistically undesirable, the PSG rules in CCGbank produce practical difficulties. Every additional rule increases ambiguity, motivating the C&amp;C system to choose to implement only the most frequent. This decreases 1214 the parser’s coverage, and introduces another dimension of domain sensitivity. For instance, the type-changing rule that allows gerund nominals, &lt;S[ng]\NP → NP&gt;, occurs roughly 300 times in the tr</context>
<context position="13430" citStr="Steedman, 2000" startWordPosition="2153" endWordPosition="2154">mes The CCGbank PSG extension is closely related to the zero morpheme categories proposed by Aone and Wittenburg (1990), which they suggest be compiled into unary type-changing rules for processing. At first glance, it seems that conceptualising the rules as zero morphemes offers a way to locate them in the lexicon, avoiding the linguistic difficulties of having a language-specific grammar. However, CCG aims to provide a transparent interface between the surface form and the semantic analysis, so epsilon categories, traces, movement rules and other unrealised structures are explicitly banned (Steedman, 2000). From a processing standpoint, if zero morpheme categories are not compiled into phrasestructure rules, then they will complicate the category assignment phase considerably, since we can no longer assume that exactly one category will be assigned per word. We are not aware of any proposal for how this difficulty might be overcome. Carpenter (1992) provides a different suggestion for how sparse modifier categories can be accommodated. His solution is to use meta-rules that systematically expand the lexicon, much like the lexical rules used in HPSG (Flickinger, 1987), which exploit structural r</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
<author>Jason Baldridge</author>
</authors>
<title>Combinatory categorial grammar.</title>
<date>2007</date>
<editor>In Robert Borsley and Kersti Borjars, editors, NonTransformational Syntax.</editor>
<publisher>Blackwells.</publisher>
<contexts>
<context position="4408" citStr="Steedman and Baldridge (2007)" startWordPosition="674" endWordPosition="677">/(S/NP) S/(S\NP) S[dcl]/NP PSG &gt; S[dcl] PSG &lt; NP Figure 1: Over-generation by CCGbank rules. 2 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG) (Steedman, 2000) is a lexicalised grammar formalism based on categorial grammar (Bar-Hillel, 1953). CCG can be distinguished from other CG extensions, such as categorial type-logic (Moortgat, 1997) by its attention to linguistic minimalism. One aim of the theory is to explain universal constraints on natural language syntax, so the generative power of the formalism is intended to closely match what natural language seems to require. Steedman and Baldridge (2007) argue that the requirements can be fulfilled almost entirely by two basic rule types: application and composition. Direction specific instances of these types yields a grammar that consists of just six rules. Initially, it seemed that some of the rules had to be restricted to certain contexts, particularly in languages that did not allow scrambling. Baldridge and Kruijff (2003) have since shown that rules could be restricted lexically, using a hierarchy of slash subtypes. This relieved the need for any language specific meta-rules, allowing CCG to offer a completely universal grammar, and the</context>
<context position="10049" citStr="Steedman and Baldridge (2007)" startWordPosition="1614" endWordPosition="1617">he NP\NP category cannot be allowed to participate in backwards crosscomposition rules (Baldridge and Kruijff, 2003). There are 204 type-changing PSG rules in the training partition of CCGbank. 53 of the frequent rules transform produce modifier categories, 48 of them transforming verbal categories. The PSG 1Phrase-structure rules are presented in bottom-up notation. rules also handle a variety of other constructions, such as form/function discrepancies like gerund nominals. By far the most frequent rule, with 115,333 occurrences, is &lt;N → NP&gt;, which transforms bare nominals into noun phrases. Steedman and Baldridge (2007) describes the CCG grammar as consisting of just 6 language universal combinatory rules, plus two lexical operations (type raising). Not only do the 204 category specific type-changing rules in CCGbank make the grammar ambiguous, they also run contrary to the design principles of the formalism. CCG is a linguistically motivated formalism, which means it is not only interested in providing a convenient, computable notation for grammar development. In addition, it constitutes a hypothesis about the nature of the human language faculty. Like other lexicalised formalisms, part of the theory is tha</context>
</contexts>
<marker>Steedman, Baldridge, 2007</marker>
<rawString>Mark Steedman and Jason Baldridge. 2007. Combinatory categorial grammar. In Robert Borsley and Kersti Borjars, editors, NonTransformational Syntax. Blackwells.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>