<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000718">
<title confidence="0.965486">
Clustering to Find Exemplar Terms for Keyphrase Extraction
</title>
<author confidence="0.994201">
Zhiyuan Liu, Peng Li, Yabin Zheng, Maosong Sun
</author>
<affiliation confidence="0.990723">
Department of Computer Science and Technology
</affiliation>
<note confidence="0.894144">
State Key Lab on Intelligent Technology and Systems
National Lab for Information Science and Technology
Tsinghua University, Beijing 100084, China
</note>
<email confidence="0.988177">
{lzy.thu, pengli09, yabin.zheng}@gmail.com, sms@tsinghua.edu.cn
</email>
<sectionHeader confidence="0.994665" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999374857142857">
Keyphrases are widely used as a brief
summary of documents. Since man-
ual assignment is time-consuming, vari-
ous unsupervised ranking methods based
on importance scores are proposed for
keyphrase extraction. In practice, the
keyphrases of a document should not only
be statistically important in the docu-
ment, but also have a good coverage of
the document. Based on this observa-
tion, we propose an unsupervised method
for keyphrase extraction. Firstly, the
method finds exemplar terms by leverag-
ing clustering techniques, which guaran-
tees the document to be semantically cov-
ered by these exemplar terms. Then the
keyphrases are extracted from the doc-
ument using the exemplar terms. Our
method outperforms sate-of-the-art graph-
based ranking methods (TextRank) by
9.5% in F1-measure.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999815822222223">
With the development of Internet, information on
the web is emerging exponentially. How to effec-
tively seek and manage information becomes an
important research issue. Keyphrases, as a brief
summary of a document, provide a solution to help
organize, manage and retrieve documents, and are
widely used in digital libraries and information re-
trieval.
Keyphrases in articles of journals and books
are usually assigned by authors. However,
most articles on the web usually do not have
human-assigned keyphrases. Therefore, automatic
keyphrase extraction is an important research task.
Existing methods can be divided into supervised
and unsupervised approaches.
The supervised approach (Turney, 1999) re-
gards keyphrase extraction as a classification task.
In this approach, a model is trained to determine
whether a candidate term of the document is a
keyphrase, based on statistical and linguistic fea-
tures. For the supervised keyphrase extraction
approach, a document set with human-assigned
keyphrases is required as training set. However,
human labelling is time-consuming. Therefore, in
this study we focus on unsupervised approach.
As an example of an unsupervised keyphrase
extraction approach, the graph-based ranking (Mi-
halcea and Tarau, 2004) regards keyphrase extrac-
tion as a ranking task, where a document is repre-
sented by a term graph based on term relatedness,
and then a graph-based ranking algorithm is used
to assign importance scores to each term. Existing
methods usually use term cooccurrences within a
specified window size in the given document as an
approximation of term relatedness (Mihalcea and
Tarau, 2004).
As we know, none of these existing works
gives an explicit definition on what are appropri-
ate keyphrases for a document. In fact, the existing
methods only judge the importance of each term,
and extract the most important ones as keyphrases.
From the observation of human-assigned
keyphrases, we conclude that good keyphrases
of a document should satisfy the following
properties:
</bodyText>
<listItem confidence="0.977590454545455">
1. Understandable. The keyphrases are un-
derstandable to people. This indicates the
extracted keyphrases should be grammatical.
For example, “machine learning” is a gram-
matical phrase, but “machine learned” is not.
2. Relevant. The keyphrases are semantically
relevant with the document theme. For ex-
ample, for a document about “machine learn-
ing”, we want the keyphrases all about this
theme.
3. Good coverage. The keyphrases should
</listItem>
<page confidence="0.95789">
257
</page>
<note confidence="0.996592">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 257–266,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999300024390244">
cover the whole document well. Sup-
pose we have a document describing “Bei-
jing” from various aspects of “location”,
“atmosphere” and “culture”, the extracted
keyphrases should cover all the three aspects,
instead of just a partial subset of them.
The classification-based approach determines
whether a term is a keyphrase in isolation, which
could not guarantee Property 3. Neither does the
graph-based approach guarantee the top-ranked
keyphrases could cover the whole document. This
may cause the resulting keyphrases to be inappro-
priate or badly-grouped.
To extract the appropriate keyphrases for a doc-
ument, we suggest an unsupervised clustering-
based method. Firstly the terms in a document are
grouped into clusters based on semantic related-
ness. Each cluster is represented by an exemplar
term, which is also the centroid of each cluster.
Then the keyphrases are extracted from the docu-
ment using these exemplar terms.
In this method, we group terms based on se-
mantic relatedness, which guarantees a good cov-
erage of the document and meets Property 2 and
3. Moreover, we only extract the keyphrases in ac-
cordance with noun group (chunk) patterns, which
guarantees the keyphrases satisfy Property 1.
Experiments show that the clustering-based
method outperforms the state-of-the-art graph-
based approach on precision, recall and F1-
measure. Moreover, this method is unsupervised
and language-independent, which is applicable in
the web era with enormous information.
The rest of the paper is organized as follows.
In Section 2, we introduce and discuss the re-
lated work in this area. In Section 3, we give an
overview of our method for keyphrase extraction.
From Section 4 to Section 7, the algorithm is de-
scribed in detail. Empirical experiment results are
demonstrated in Section 8, followed by our con-
clusions and plans for future work in Section 9.
</bodyText>
<sectionHeader confidence="0.999809" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999812293103448">
A straightforward method for keyphrase extrac-
tion is to select keyphrases according to frequency
criteria. However, the poor performance of this
method drives people to explore other methods. A
pioneering achievement is carried out in (Turney,
1999), as mentioned in Section 1, a supervised ma-
chine learning method was suggested in this paper
which regards keyphrase extraction as a classifi-
cation task. In this work, parameterized heuristic
rules are combined with a genetic algorithm into a
system for keyphrase extraction. A different learn-
ing algorithm, Naive Bayes method, is applied in
(Frank et al., 1999) with improved results on the
same data used in (Turney, 1999). Hulth (Hulth,
2003; Hulth, 2004) adds more linguistic knowl-
edge, such as syntactic features, to enrich term
representation, which significantly improves the
performance. Generally, the supervised methods
need manually annotated training set, which may
sometimes not be practical, especially in the web
scenario.
Starting with TextRank (Mihalcea and Tarau,
2004), graph-based ranking methods are becom-
ing the most widely used unsupervised approach
for keyphrase extraction. The work in (Litvak
and Last, 2008) applies HITS algorithm on the
word graph of a document under the assumption
that the top-ranked nodes should be the document
keywords. Experiments show that classification-
based supervised method provides the highest key-
word identification accuracy, while the HITS al-
gorithm gets the highest F-measure. Work in
(Huang et al., 2006) also considers each document
as a term graph where the structural dynamics of
these graphs can be used to identify keyphrases.
Wan and Xiao (Wan and Xiao, 2008b) use a
small number of nearest neighbor documents to
provide more knowledge to improve graph-based
keyphrase extraction algorithm for single docu-
ment. Motivated by similar idea, Wan and Xiao
(Wan and Xiao, 2008a) propose to adopt cluster-
ing methods to find a small number of similar doc-
uments to provide more knowledge for building
word graphs for keyword extraction. Moreover,
after our submission of this paper, we find that
a method using community detection on seman-
tic term graphs is proposed for keyphrase extrac-
tion from multi-theme documents (Grineva et al.,
2009). In addition, some practical systems, such
as KP-Miner (Elbeltagy and Rafea, 2009), also
do not need to be trained on a particular human-
annotated document set.
In recent years, a number of systems are de-
veloped for extracting keyphrases from web docu-
ments (Kelleher and Luz, 2005; Chen et al., 2005),
email (Dredze et al., 2008) and some other spe-
cific sources, which indicates the importance of
keyphrase extraction in the web era. However,
</bodyText>
<page confidence="0.994739">
258
</page>
<bodyText confidence="0.999933">
none of these previous works has overall consid-
eration on the essential properties of appropriate
keyphrases mentioned in Section 1.
We should also note that, although the preci-
sion and recall of most current keyphrase extrac-
tors are still much lower compared to other NLP-
tasks, it does not indicate the performance is poor
because even different annotators may assign dif-
ferent keyphrases to the same document. As de-
scribed in (Wan and Xiao, 2008b), when two anno-
tators were asked to label keyphrases on 308 doc-
uments, the Kappa statistic for measuring inter-
agreement among them was only 0.70.
</bodyText>
<sectionHeader confidence="0.960967" genericHeader="method">
3 Algorithm Overview
</sectionHeader>
<bodyText confidence="0.999297318181818">
The method proposed in this paper is mainly in-
spired by the nature of appropriate keyphrases
mentioned in Section 1, namely understandable,
semantically relevant with the document and high
coverage of the whole document.
Let’s analyze the document describing “Bei-
jing” from the aspects of “location”, “atmosphere”
and “culture”. Under the bag-of-words assump-
tion, each term in the document, except for func-
tion words, is used to describe an aspect of the
theme. Based on these aspects, terms are grouped
into different clusters. The terms in the same clus-
ter are more relevant with each other than with
the ones in other clusters. Taking the terms “tem-
perature”, “cold” and “winter” for example, they
may serve the aspect “atmosphere” instead of “lo-
cation” or some other aspects when talking about
“Beijing”.
Based on above description, it is thus reason-
able to propose a clustering-based method for
keyphrase extraction. The overview of the method
is:
</bodyText>
<listItem confidence="0.9966405">
1. Candidate term selection. We first filter out
the stop words and select candidate terms for
keyphrase extraction.
2. Calculating term relatedness. We use some
measures to calculate the semantic related-
ness of candidate terms.
3. Term clustering. Based on term relatedness,
we group candidate terms into clusters and
find the exemplar terms of each cluster.
4. From exemplar terms to keyphrases. Fi-
</listItem>
<bodyText confidence="0.9833175">
nally, we use these exemplar terms to extract
keyphrases from the document.
In the next four sections we describe the algo-
rithm in detail.
</bodyText>
<sectionHeader confidence="0.917644" genericHeader="method">
4 Candidate Term Selection
</sectionHeader>
<bodyText confidence="0.999913411764706">
Not all words in a document are possible to be se-
lected as keyphrases. In order to filter out the noisy
words in advance, we select candidate terms using
some heuristic rules. This step proceeds as fol-
lows. Firstly the text is tokenized for English or
segmented into words for Chinese and other lan-
guages without word-separators. Then we remove
the stop words and consider the remaining single
terms as candidates for calculating semantic relat-
edness and clustering.
In methods like (Turney, 1999; Elbeltagy and
Rafea, 2009), candidate keyphrases were first
found using n-gram. Instead, in this method, we
just find the single-word terms as the candidate
terms at the beginning. After identifying the ex-
emplar terms within the candidate terms, we ex-
tract multi-word keyphrases using the exemplars.
</bodyText>
<sectionHeader confidence="0.87782" genericHeader="method">
5 Calculating Term Relatedness
</sectionHeader>
<bodyText confidence="0.9999485">
After selecting candidate terms, it is important to
measure term relatedness for clustering. In this pa-
per, we propose two approaches to calculate term
relatedness: one is based on term cooccurrence
within the document, and the other by leveraging
human knowledge bases.
</bodyText>
<subsectionHeader confidence="0.997863">
5.1 Cooccurrence-based Term Relatedness
</subsectionHeader>
<bodyText confidence="0.99997345">
An intuitive method for measuring term relat-
edness is based on term cooccurrence relations
within the given document. The cooccurrence
relation expresses the cohesion relationships be-
tween terms.
In this paper, cooccurrence-based relatedness is
simply set to the count of cooccurrences within a
window of maximum w words in the whole doc-
ument. In the following experiments, the window
size w is set from 2 to 10 words.
Each document can be regarded as a word se-
quence for computing cooccurrence-based relat-
edness. There are two types of word sequence
for counting term cooccurrences. One is the origi-
nal word sequence without filtering out any words,
and the other is after filtering out the stop words
or the words with specified part-of-speech (POS)
tags. In this paper we select the first type because
each word in the sequence takes important role for
measuring term cooccurrences, no matter whether
</bodyText>
<page confidence="0.987925">
259
</page>
<bodyText confidence="0.999816333333333">
it is a stop word or something else. If we filter
out some words, the term relatedness will not be
as precise as before.
In experiments, we will investigate how the
window size influences the performance of
keyphrase extraction.
</bodyText>
<subsectionHeader confidence="0.999539">
5.2 Wikipedia-based Term Relatedness
</subsectionHeader>
<bodyText confidence="0.999955066666667">
Many methods have been proposed for measuring
the relatedness between terms using external re-
sources. One principled method is leveraging hu-
man knowledge bases. Inspired by (Gabrilovich
and Markovitch, 2007), we adopt Wikipedia, the
largest encyclopedia collected and organized by
human on the web, as the knowledge base to mea-
sure term relatedness.
The basic idea of computing term related-
ness by leveragting Wikipedia is to consider each
Wikipedia article as a concept. Then the se-
mantic meaning of a term could be represented
as a weighted vector of Wikipedia concepts, of
which the values are the term’s TFIDF within cor-
responding Wikipedia articles. We could com-
pute the term relatedness by comparing the con-
cept vectors of the terms. Empirical evaluations
confirm that the idea is effective and practical
for computing term relatedness (Gabrilovich and
Markovitch, 2007).
In this paper, we select cosine similarity, Eu-
clidean distance, Point-wise Mutual Information
and Normalized Google Similarity Distance (Cili-
brasi and Vitanyi, 2007) for measuring term relat-
edness based on the vector of Wikipedia concepts.
Denote the Wikipedia-concept vector of the
term ti as Ci = {ci1, ci2, ..., ciN1, where N in-
dicates the number of Wikipedia articles, and cik
is the TFIDF value of wi in the kth Wikipedia ar-
ticle. The cosine similarity is defined as
</bodyText>
<equation confidence="0.970740333333333">
Ci Cj
cos(i, j) = (1)
llCillllCjll
</equation>
<bodyText confidence="0.959468833333333">
The definition of Euclidean distance is
(cik − cjk)2 (2)
Point-wise Mutual Information (PMI) is a com-
mon approach to quantify relatedness. Here we
take three ways to measure term relatedness using
PMI. One is based on Wikipedia page count,
</bodyText>
<equation confidence="0.997632">
N x p(i, j)
pmip(i,j) = log2 p(i) x p(j) (3)
</equation>
<bodyText confidence="0.999983">
where p(i, j) is the number of Wikipedia articles
containing both ti and tj, while p(i) is the number
of articles which contain ti. The second is based
on the term count in Wikipedia articles,
</bodyText>
<equation confidence="0.99934">
x t(i, j)
pmit (i, j) = log2 Tx t (j) (4)
</equation>
<bodyText confidence="0.9995">
where T is the number of terms in Wikipedia,
t(i, j) is the number of ti and tj occurred adja-
cently in Wikipedia, and t(i) is the number of ti in
Wikipedia. The third one is a combination of the
above two PMI ways,
</bodyText>
<equation confidence="0.998576">
N x pt(i, j)
pmic(i,j) = log2 p(i) x p(j) (5)
</equation>
<bodyText confidence="0.966066466666667">
where pt(i, j) indicates the number of Wikipedia
articles containing ti and tj as adjacency. It is ob-
vious that pmic(i, j) G pmip(i, j), and pmic(i, j)
is more strict and accurate for measuring related-
ness.
Normalized Google Similarity Distance (NGD)
is a new measure for measuring similarity between
terms proposed by (Cilibrasi and Vitanyi, 2007)
based on information distance and Kolmogorov
complexity. It could be applied to compute term
similarity from the World Wide Web or any large
enough corpus using the page counts of terms.
NGD used in this paper is based on Wikipedia ar-
ticle count, defined as
max(log p(i), log p(j)) − logp(i, j)
</bodyText>
<equation confidence="0.9709725">
ngd(i,j) =
log N − min(logp(i), logp(j))
</equation>
<bodyText confidence="0.932251333333333">
(6)
where N is the number of Wikipedia articles used
as normalized factor.
Once we get the term relatedness, we could then
group the terms using clustering techniques and
find exemplar terms for each cluster.
</bodyText>
<sectionHeader confidence="0.994767" genericHeader="method">
6 Term Clustering
</sectionHeader>
<bodyText confidence="0.9976762">
Clustering is an important unsupervised learning
problem, which is the assignment of objects into
groups so that objects from the same cluster are
more similar to each other than objects from dif-
ferent clusters (Han and Kamber, 2005). In this
paper, we use three widely used clustering algo-
rithms, hierarchical clustering, spectral clustering
and Affinity Propagation, to cluster the candidate
terms of a given document based on the semantic
relatedness between them.
</bodyText>
<equation confidence="0.980247333333333">
euc(i, j) =
N
k=1
</equation>
<page confidence="0.982354">
260
</page>
<subsectionHeader confidence="0.990423">
6.1 Hierarchical Clustering
</subsectionHeader>
<bodyText confidence="0.9996088">
Hierarchical clustering groups data over a variety
of scales by creating a cluster tree. The tree is a
multilevel hierarchy, where clusters at one level
are joined as clusters at the next level. The hier-
archical clustering follows this procedure:
</bodyText>
<listItem confidence="0.988814875">
1. Find the distance or similarity between every
pair of data points in the dataset;
2. Group the data points into a binary and hier-
archical cluster tree;
3. Determine where to cut the hierarchical tree
into clusters. In hierarchical clustering, we
have to specify the cluster number m in ad-
vance.
</listItem>
<bodyText confidence="0.9993948">
In this paper, we use the hierarchical cluster-
ing implemented in Matlab Statistics Toolbox.
Note that although we use hierarchical clustering
here, the cluster hierarchy is not necessary for the
clustering-based method.
</bodyText>
<subsectionHeader confidence="0.998684">
6.2 Spectral Clustering
</subsectionHeader>
<bodyText confidence="0.999926238095238">
In recent years, spectral clustering has become one
of the most popular modern clustering algorithms.
Spectral clustering makes use of the spectrum of
the similarity matrix of the data to perform dimen-
sionality reduction for clustering into fewer di-
mensions, which is simple to implement and often
outperforms traditional clustering methods such as
k-means. Detailed introduction to spectral cluster-
ing could be found in (von Luxburg, 2006).
In this paper, we use the spectral clustering tool-
box developed by Wen-Yen Chen, et al. (Chen et
al., 2008) 1. Since the cooccurrence-based term
relatedness is usually sparse, the traditional eigen-
value decomposition in spectral clustering will
sometimes get run-time error. In this paper, we
use the singular value decomposition (SVD) tech-
nique for spectral clustering instead.
For spectral clustering, two parameters are re-
quired to be set by the user: the cluster number
m, and σ which is used in computing similarities
from object distances
</bodyText>
<equation confidence="0.931426">
2
s(i, j) = exp(−d(i,2)) (7)
</equation>
<bodyText confidence="0.998323">
where s(i, j) and d(i, j) are the similarity and dis-
tance between i and j respectively.
</bodyText>
<footnote confidence="0.963649">
1The package could be accessed via http://www.cs.
ucsb.edu/˜wychen/sc.html.
</footnote>
<subsectionHeader confidence="0.987583">
6.3 Affinity Propagation
</subsectionHeader>
<bodyText confidence="0.9989166">
Another powerful clustering method, Affinity
Propagation, is based on message passing tech-
niques. AP was proposed in (Frey and Dueck,
2007), where AP was reported to find clusters with
much lower error than those found by other meth-
ods. In this paper, we use the toolbox developed
by Frey, et al. 2.
Detailed description of the algorithm could be
found in (Frey and Dueck, 2007). Here we intro-
duced three parameters for AP:
</bodyText>
<listItem confidence="0.9998998">
• Preference. Rather than requiring prede-
fined number of clusters, Affinity Propaga-
tion takes as input a real number p for each
term, so that the terms with larger p are more
likely to be chosen as exemplars, i.e., cen-
troids of clusters. These values are referred
to as “preferences”. The preferences are usu-
ally be set as the maximum, minimum, mean
or median of s(i, j), i =� j.
• Convergence criterion. AP terminates if (1)
the local decisions stay constant for I1 itera-
tions; or (2) the number of iterations reaches
I2. In this work, we set I1 to 100 and I2 to
1,000.
• Damping factor. When updating the mes-
</listItem>
<bodyText confidence="0.811603857142857">
sages, it is important to avoid numerical os-
cillations by using damping factor. Each
message is set to λ times its value from the
previous iteration plus 1 − λ times its pre-
scribed updated value, where the damping
factor λ is between 0 and 1. In this paper we
set λ = 0.9.
</bodyText>
<sectionHeader confidence="0.935241" genericHeader="method">
7 From Exemplar Terms to Keyphrases
</sectionHeader>
<bodyText confidence="0.999898090909091">
After term clustering, we select the exemplar
terms of each clusters as seed terms. In Affinity
Propagation, the exemplar terms are directly ob-
tained from the clustering results. In hierarchical
clustering, exemplar terms could also be obtained
by the Matlab toolbox. While in spectral cluster-
ing, we select the terms that are most close to the
centroid of a cluster as exemplar terms.
As reported in (Hulth, 2003), most manually
assigned keyphrases turn out to be noun groups.
Therefore, we annotate the document with POS
</bodyText>
<footnote confidence="0.983024">
2The package could be accessed via http://www.
psi.toronto.edu/affinitypropagation/.
</footnote>
<page confidence="0.997669">
261
</page>
<bodyText confidence="0.999059">
tags using Stanford Log-Linear Tagger 3, and then
extract the noun groups whose pattern is zero or
more adjectives followed by one or more nouns.
The pattern can be represented using regular ex-
pressions as follows
</bodyText>
<equation confidence="0.74064">
(JJ) ∗ (NN|NNS|NNP)+
</equation>
<bodyText confidence="0.999955090909091">
where JJ indicates adjectives and various forms
of nouns are represented using NN, NNS and
NNP. From these noun groups, we select the
ones that contain one or more exemplar terms to
be the keyphrases of the document.
In this process, we may find single-word
keyphrases. In practice, only a small fraction of
keyphrases are single-word. Thus, as a part of
postprocessing process, we have to use a frequent
word list to filter out the terms that are too com-
mon to be keyphrases.
</bodyText>
<sectionHeader confidence="0.998372" genericHeader="evaluation">
8 Experiment Results
</sectionHeader>
<subsectionHeader confidence="0.996749">
8.1 Datasets and Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.9999548">
The dataset used in the experiments is a collec-
tion of scientific publication abstracts from the In-
spec database and the corresponding manually as-
signed keyphrases 4. The dataset is used in both
(Hulth, 2003) and (Mihalcea and Tarau, 2004).
Each abstract has two kinds of keyphrases: con-
trolled keyphrases, restricted to a given dictionary,
and uncontrolled keyphrases, freely assigned by
the experts. We use the uncontrolled keyphrases
for evaluation as proposed in (Hulth, 2003) and
followed by (Mihalcea and Tarau, 2004).
As indicated in (Hulth, 2003; Mihalcea and
Tarau, 2004), in uncontrolled manually assigned
keyphrases, only the ones that occur in the cor-
responding abstracts are considered in evaluation.
The extracted keyphrases of various methods and
manually assigned keyphrases are compared after
stemming.
In the experiments of (Hulth, 2003), for her su-
pervised method, Hulth splits a total of 2, 000 ab-
stracts into 1, 000 for training, 500 for validation
and 500 for test. In (Mihalcea and Tarau, 2004),
due to the unsupervised method, only the test set
was used for comparing the performance of Tex-
tRank and Hulth’s method.
</bodyText>
<footnote confidence="0.999310333333333">
3The package could be accessed via http://http://
nlp.stanford.edu/software/tagger.shtml.
4Many thanks to Anette Hulth for providing us the dataset.
</footnote>
<bodyText confidence="0.999962125">
For computing Wikipedia-based relatedness,
we use a snapshot on November 11, 2005 5. The
frequent word list used in the postprocessing step
for filtering single-word phrases is also computed
from Wikipedia. In the experiments of this pa-
per, we add the words that occur more than 1, 000
times in Wikipedia into the list.
The clustering-based method is completely un-
supervised. Here, we mainly run our method on
test set and investigate the influence of relatedness
measurements and clustering methods with differ-
ent parameters. Then we compare our method
with two baseline methods: Hulth’s method and
TextRank. Finally, we analyze and discuss the per-
formance of the method by taking the abstract of
this paper as a demonstration.
</bodyText>
<subsectionHeader confidence="0.994317">
8.2 Influence of Relatedness Measurements
</subsectionHeader>
<bodyText confidence="0.986006692307692">
We first investigate the influence of semantic re-
latedness measurements. By systematic experi-
ments, we find that Wikipedia-based relatedness
outperforms cooccurrence-based relatedness for
keyphrase extraction, though the improvement is
not significant. In Table 1, we list the perfor-
mance of spectral clustering with various related-
ness measurements for demonstration. In this ta-
ble, the w indicates the window size for counting
cooccurrences in cooccurrence-based relatedness.
cos, euc, etc. are different measures for com-
puting Wikipedia-based relatedness which we pre-
sented in Section 5.2.
</bodyText>
<tableCaption confidence="0.846087">
Table 1: Influence of relatedness measurements
for keyphrase extraction.
</tableCaption>
<table confidence="0.999468714285714">
Parameters Precision Recall F1-measure
Cooccurrence-based Relatedness
w = 2 0.331 0.626 0.433
w = 4 0.333 0.621 0.434
w = 6 0.331 0.630 0.434
w = 8 0.330 0.623 0.432
w = 10 0.333 0.632 0.436
Wikipedia-based Relatedness
cos 0.348 0.655 0.455
euc 0.344 0.634 0.446
pmip 0.344 0.621 0.443
pmit 0.344 0.619 0.442
pmic 0.350 0.660 0.457
ngd 0.343 0.620 0.442
</table>
<footnote confidence="0.997893333333333">
5The dataset could be get from http://www.cs.
technion.ac.il/˜gabr/resources/code/
wikiprep/.
</footnote>
<page confidence="0.994702">
262
</page>
<bodyText confidence="0.999986741935484">
We use spectral clustering here because it out-
performs other clustering techniques, which will
be shown in the next subsection. The results in Ta-
ble 1 are obtained when the cluster number m =
23n, where n is the number of candidate terms ob-
tained in Section 5. Besides, for Euclidean dis-
tance and Google distance, we set Q = 36 of For-
mula 7 to convert them to corresponding similari-
ties, where we get the best result when we conduct
different trails with Q = 9, 18, 36, 54, though there
are only a small margin among them.
As shown in Table 1, although the method using
Wikipedia-based relatedness outperforms that us-
ing cooccurrence-based relatedness, the improve-
ment is not prominent. Wikipedia-based related-
ness is computed according to global statistical in-
formation on Wikipedia. Therefore it is more pre-
cise than cooccurrence-based relatedness, which is
reflected in the performance of the keyphrase ex-
traction. However, on the other hand, Wikipedia-
based relatedness does not catch the document-
specific relatedness, which is represented by the
cooccurrence-based relatedness. It will be an in-
teresting future work to combine these two types
of relatedness measurements.
From this subsection, we conclude that, al-
though the method using Wikipedia-based related-
ness performs better than cooccurrence-based one,
due to the expensive computation of Wikipedia-
based relatedness, the cooccurrence-based one is
good enough for practical applications.
</bodyText>
<subsectionHeader confidence="0.9976545">
8.3 Influence of Clustering Methods and
Their Parameters
</subsectionHeader>
<bodyText confidence="0.998332">
To demonstrate the influence of clustering meth-
ods for keyphrase extraction, we fix the relat-
edness measurement as Wikipedia-based pmi,,
which has been shown in Section 8.2 to be the best
relatedness measurement.
In Table 2, we show the performance of three
clustering techniques for keyphrase extraction.
For hierarchical clustering and spectral clustering,
the cluster number m are set explicitly as the pro-
portion of candidate terms n, while for Affinity
Propagation, we set preferences as the minimum,
mean, median and maximum of s(i, j) to get dif-
ferent number of clusters, denoted as min, mean,
median and max in the table respectively.
As shown in the table, when cluster number m
is large, spectral clustering outperforms hierarchi-
cal clustering and Affinity Propagation. Among
</bodyText>
<tableCaption confidence="0.8368895">
Table 2: Influence of clustering methods for
keyphrase extraction.
</tableCaption>
<table confidence="0.99956675">
Parameters Precision Recall F1-measure
Hierarchical Clustering
1 0.365 0.369 0.367
m = 4n 0.369 0.367
m = 1 3n 0.365 0.562 0.432
1 0.351 0.629 0.446
m = 2n 0.657 0.448
m = 2 3n 0.346
4
m = 5n 0.340
Spectral Clustering
m = 4n 0.409 0.397
1 0.385 0.497 0.427
m = 1 3n 0.374 0.497 0.427
1 0.374 0.660 0.457
m =2n 0.679 0.453
m = 2 3n 0.350
4
m = 5n 0.340
Affinity Propagation
p = max 0.331 0.688 0.447
p = mean 0.433 0.070 0.121
p = median 0.422 0.078 0.132
p = min 0.419 0.059 0.103
</table>
<bodyText confidence="0.595684">
these methods, only Affinity Propagation under
some parameters performs poorly.
</bodyText>
<subsectionHeader confidence="0.999615">
8.4 Comparing with Other Algorithms
</subsectionHeader>
<bodyText confidence="0.99998428">
Table 3 lists the results of the clustering-based
method compared with the best results reported
in (Hulth, 2003; Mihalcea and Tarau, 2004) on
the same dataset. For each method, the table lists
the total number of assigned keyphrases, the mean
number of keyphrases per abstract, the total num-
ber of correct keyphrases, and the mean number of
correct keyphrases. The table also lists precision,
recall and F1-measure. In this table, hierarchical
clustering, spectral clustering and Affinity Propa-
gation are abbreviated by “HC”, “SC” and “AP”
respectively.
The result of Hulth’s method listed in this ta-
ble is the best one reported in (Hulth, 2003) on the
same dataset. This is a supervised classification-
based method, which takes more linguistic fea-
tures in consideration for keyphrase extraction.
The best result is obtained using n-gram as candi-
date keyphrases and adding POS tags as candidate
features for classification.
The result of TextRank listed here is the best
one reported in (Mihalcea and Tarau, 2004) on the
same dataset. To obtain the best result, the authors
built an undirected graph using window w = 2
on word sequence of the given document, and ran
</bodyText>
<page confidence="0.999198">
263
</page>
<tableCaption confidence="0.999822">
Table 3: Comparison results of Hulth’s method, TextRank and our clustering-based method.
</tableCaption>
<table confidence="0.999585571428572">
Method Assigned Correct Recall F1-measure
Total Mean Total Mean Precision
Hulth’s 7,815 15.6 1,973 3.9 0.252 0.517 0.339
TextRank 6,784 13.7 2,116 4.2 0.312 0.431 0.362
HC 7,303 14.6 2,494 5.0 0.342 0.657 0.449
SC 7,158 14.3 2,505 5.0 0.350 0.660 0.457
AP 8,013 16.0 2,648 5.3 0.330 0.697 0.448
</table>
<bodyText confidence="0.980804642857143">
PageRank on it.
In this table, the best result of hierarchical clus-
tering is obtained by setting the cluster number
m = 3n and using Euclidean distance for comput-
ing Wikipedia-based relatedness. The parameters
of spectral clustering are the same as in last sub-
section. For Affinity Propagation, the best result
is obtained under p = max and using Wikipedia-
based Euclidean distance as relatedness measure.
From this table, we can see clustering-
based method outperforms TextRank and Hulth’s
method. For spectral clustering, F1-measure
achieves an approximately 9.5% improvement as
compared to TextRank.
Furthermore, since the clustering-based method
is unsupervised, we do not need any set for train-
ing and validation. In this paper, we also carry out
an experiment on the whole Hulth’s dataset with
2, 000 abstracts. The performance is similar to
that on 500 abstracts as shown above. The best
result is obtained when we use spectral clustering
by setting m = 3n with Wikipedia-based pmi,
relatedness, which is the same in 500 abstracts. In
this result, we extract 29,517 keyphrases, among
which 9,655 are correctly extracted. The preci-
sion, recall and F1-measure are 0.327, 0.653 and
0.436 respectively. The experiment results show
that the clustering-based method is stable.
</bodyText>
<subsectionHeader confidence="0.989315">
8.5 Analysis and Discussions
</subsectionHeader>
<bodyText confidence="0.999996487804878">
From the above experiment results, we can see the
clustering-based method is both robust and effec-
tive for keyphrase extraction as an unsupervised
method.
Here, as an demonstration, we use spectral clus-
tering and Wikipedia-based pmi, relatedness to
extract keyphrases from the abstract of this pa-
per. The extracted stemmed keyphrases under var-
ious cluster numbers are shown in Figure 1. In
this figure, we find that when m = 4n, sn, 2n,
the extracted keyphrases are identical, where the
exemplar terms under m = sn are marked in
boldface. We find several aspects like “unsuper-
vised”, “exemplar term” and “keyphrase extrac-
tion” are extracted correctly. In fact, “clustering
technique” in the abstract should also be extracted
as a keyphrase. However, since “clustering” is
tagged as a verb that ends in -ing, which disagrees
the noun group patterns, thus the phrase is not
among the extracted keyphrases.
When m = 3n, the extracted keyphrases
are noisy with many single-word phrases. As
the cluster number increases, more exemplar
terms are identified from these clusters, and more
keyphrases will be extracted from the document
based on exemplar terms. If we set the cluster
number to m = n, all terms will be selected as
exemplar terms. In this extreme case, all noun
groups will be extracted as keyphrases, which
is obviously not proper for keyphrase extraction.
Thus, it is important for this method to appropri-
ately specify the cluster number.
In the experiments, we also notice that frequent
word list is important for keyphrase extraction.
Without the list for filtering, the best F1-measure
will decrease by about 5 percent to 40%. How-
ever, the solution of using frequent word list is
somewhat too simple, and in future work, we plan
to investigate a better combination of clustering-
based method with traditional methods using term
frequency as the criteria.
</bodyText>
<sectionHeader confidence="0.979092" genericHeader="conclusions">
9 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999952555555556">
In this paper, we propose an unsupervised
clustering-based keyphrase extraction algorithm.
This method groups candidate terms into clus-
ters and identify the exemplar terms. Then
keyphrases are extracted from the document based
on the exemplar terms. The clustering based on
term semantic relatedness guarantees the extracted
keyphrases have a good coverage of the document.
Experiment results show the method has a good ef-
</bodyText>
<page confidence="0.996909">
264
</page>
<figureCaption confidence="0.919767384615385">
Figure 1: Keyphrases in stemmed form extracted
from this paper’s abstract.
Keyphrases when m= 4n, sn, 2n
unsupervis method; various unsupervis rank
method; exemplar term; state-of-the-art
graph-bas rank method; keyphras; keyphras
extract
Keyphrases when m = 3n
unsupervis method; manual assign; brief sum-
mari; various unsupervis rank method; exem-
plar term; document; state-of-the-art graph-bas
rank method; experi; keyphras; import score;
keyphras extract
</figureCaption>
<bodyText confidence="0.672200666666667">
fectiveness and robustness, and outperforms base-
lines significantly.
Future work may include:
</bodyText>
<listItem confidence="0.987253166666667">
1. Investigate the feasibility of clustering di-
rectly on noun groups;
2. Investigate the feasibility of combining
cooccurrence-based and Wikipedia-based re-
latedness for clustering;
3. Investigate the performance of the method on
</listItem>
<bodyText confidence="0.979134777777778">
other types of documents, such as long arti-
cles, product reviews and news;
4. The solution of using frequent word list
for filtering out too common single-word
keyphrases is undoubtedly simple, and we
plan to make a better combination of
the clustering-based method with traditional
frequency-based methods for keyphrase ex-
traction.
</bodyText>
<sectionHeader confidence="0.998238" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9980444">
This work is supported by the National 863 Project
under Grant No. 2007AA01Z148 and the Na-
tional Science Foundation of China under Grant
No. 60621062. The authors would like to thank
Anette Hulth for kindly sharing her datasets.
</bodyText>
<sectionHeader confidence="0.999185" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999660714285714">
Mo Chen, Jian-Tao Sun, Hua-Jun Zeng, and Kwok-Yan
Lam. 2005. A practical system of keyphrase extrac-
tion for web pages. In Proceedings of the 14th ACM
international conference on Information and knowl-
edge management, pages 277–278.
Wen Y. Chen, Yangqiu Song, Hongjie Bai, Chih J. Lin,
and Edward Chang. 2008. Psc: Paralel spectral
clustering. Submitted.
Rudi L. Cilibrasi and Paul M. B. Vitanyi. 2007. The
google similarity distance. IEEE Transactions on
Knowledge and Data Engineering, 19(3):370–383.
Mark Dredze, Hanna M. Wallach, Danny Puller, and
Fernando Pereira. 2008. Generating summary key-
words for emails using topics. In Proceedings of the
13th international conference on Intelligent user in-
terfaces, pages 199–206.
S. Elbeltagy and A. Rafea. 2009. Kp-miner: A
keyphrase extraction system for english and arabic
documents. Information Systems, 34(1):132–144.
Eibe Frank, Gordon W. Paynter, Ian H. Witten, Carl
Gutwin, and Craig G. Nevill-Manning. 1999.
Domain-specific keyphrase extraction. In Proceed-
ings of the 16th International Joint Conference on
Artificial Intelligence, pages 668–673.
Brendan J J. Frey and Delbert Dueck. 2007. Clustering
by passing messages between data points. Science.
E. Gabrilovich and S. Markovitch. 2007. Computing
semantic relatedness using wikipedia-based explicit
semantic analysis. In Proceedings of the 20th Inter-
national Joint Conference on Artificial Intelligence,
pages 6–12.
M. Grineva, M. Grinev, and D. Lizorkin. 2009. Ex-
tracting key terms from noisy and multi-theme docu-
ments. In Proceedings of the 18th international con-
ference on World wide web, pages 661–670. ACM
New York, NY, USA.
Jiawei Han and Micheline Kamber. 2005. Data Min-
ing: Concepts and Techniques, second edition. Mor-
gan Kaufmann.
Chong Huang, Yonghong Tian, Zhi Zhou, Charles X.
Ling, and Tiejun Huang. 2006. Keyphrase extrac-
tion using semantic networks structure analysis. In
Proceedings of the 6th International Conference on
Data Mining, pages 275–284.
Anette Hulth. 2003. Improved automatic keyword ex-
traction given more linguistic knowledge. In Pro-
ceedings of the 2003 conference on Empirical meth-
ods in natural language processing, pages 216–223.
A. Hulth. 2004. Reducing false positives by expert
combination in automatic keyword indexing. Re-
cent Advances in Natural Language Processing III:
Selected Papers from RANLP 2003, page 367.
Daniel Kelleher and Saturnino Luz. 2005. Automatic
hypertext keyphrase detection. In Proceedings of the
19th International Joint Conference on Artificial In-
telligence.
</reference>
<page confidence="0.974921">
265
</page>
<reference confidence="0.99961732">
Marina Litvak and Mark Last. 2008. Graph-based
keyword extraction for single-document summariza-
tion. In Proceedings of the workshop Multi-source
Multilingual Information Extraction and Summa-
rization, pages 17–24.
Rada Mihalcea and Paul Tarau. 2004. Textrank:
Bringing order into texts. In Proceedings of the
2004 Conference on Empirical Methods in Natural
Language Processing.
Peter D. Turney. 1999. Learning to Extract Keyphrases
from Text. National Research Council Canada, In-
stitute for Information Technology, Technical Report
ERB-1057.
U. von Luxburg. 2006. A tutorial on spectral clus-
tering. Technical report, Max Planck Institute for
Biological Cybernetics.
Xiaojun Wan and Jianguo Xiao. 2008a. Col-
labrank: Towards a collaborative approach to single-
document keyphrase extraction. In Proceedings of
COLING, pages 969–976.
Xiaojun Wan and Jianguo Xiao. 2008b. Single
document keyphrase extraction using neighborhood
knowledge. In Proceedings of the Twenty-Third
AAAI Conference on Artificial Intelligence, pages
855–860.
</reference>
<page confidence="0.998471">
266
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.164893">
<title confidence="0.999915">Clustering to Find Exemplar Terms for Keyphrase Extraction</title>
<author confidence="0.999275">Zhiyuan Liu</author>
<author confidence="0.999275">Peng Li</author>
<author confidence="0.999275">Yabin Zheng</author>
<author confidence="0.999275">Maosong</author>
<affiliation confidence="0.97222375">Department of Computer Science and State Key Lab on Intelligent Technology and National Lab for Information Science and Tsinghua University, Beijing 100084,</affiliation>
<address confidence="0.454306">pengli09, sms@tsinghua.edu.cn</address>
<abstract confidence="0.957155727272727">Keyphrases are widely used as a brief summary of documents. Since manual assignment is time-consuming, various unsupervised ranking methods based on importance scores are proposed for keyphrase extraction. In practice, the keyphrases of a document should not only be statistically important in the document, but also have a good coverage of the document. Based on this observation, we propose an unsupervised method for keyphrase extraction. Firstly, the method finds exemplar terms by leveraging clustering techniques, which guarantees the document to be semantically covered by these exemplar terms. Then the keyphrases are extracted from the document using the exemplar terms. Our method outperforms sate-of-the-art graphbased ranking methods (TextRank) by F1-measure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mo Chen</author>
<author>Jian-Tao Sun</author>
<author>Hua-Jun Zeng</author>
<author>Kwok-Yan Lam</author>
</authors>
<title>A practical system of keyphrase extraction for web pages.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM international conference on Information and knowledge management,</booktitle>
<pages>277--278</pages>
<contexts>
<context position="8190" citStr="Chen et al., 2005" startWordPosition="1258" endWordPosition="1261">nd a small number of similar documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method using community detection on semantic term graphs is proposed for keyphrase extraction from multi-theme documents (Grineva et al., 2009). In addition, some practical systems, such as KP-Miner (Elbeltagy and Rafea, 2009), also do not need to be trained on a particular humanannotated document set. In recent years, a number of systems are developed for extracting keyphrases from web documents (Kelleher and Luz, 2005; Chen et al., 2005), email (Dredze et al., 2008) and some other specific sources, which indicates the importance of keyphrase extraction in the web era. However, 258 none of these previous works has overall consideration on the essential properties of appropriate keyphrases mentioned in Section 1. We should also note that, although the precision and recall of most current keyphrase extractors are still much lower compared to other NLPtasks, it does not indicate the performance is poor because even different annotators may assign different keyphrases to the same document. As described in (Wan and Xiao, 2008b), wh</context>
</contexts>
<marker>Chen, Sun, Zeng, Lam, 2005</marker>
<rawString>Mo Chen, Jian-Tao Sun, Hua-Jun Zeng, and Kwok-Yan Lam. 2005. A practical system of keyphrase extraction for web pages. In Proceedings of the 14th ACM international conference on Information and knowledge management, pages 277–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen Y Chen</author>
<author>Yangqiu Song</author>
<author>Hongjie Bai</author>
<author>Chih J Lin</author>
<author>Edward Chang</author>
</authors>
<title>Psc: Paralel spectral clustering.</title>
<date>2008</date>
<note>Submitted.</note>
<contexts>
<context position="17720" citStr="Chen et al., 2008" startWordPosition="2827" endWordPosition="2830">t necessary for the clustering-based method. 6.2 Spectral Clustering In recent years, spectral clustering has become one of the most popular modern clustering algorithms. Spectral clustering makes use of the spectrum of the similarity matrix of the data to perform dimensionality reduction for clustering into fewer dimensions, which is simple to implement and often outperforms traditional clustering methods such as k-means. Detailed introduction to spectral clustering could be found in (von Luxburg, 2006). In this paper, we use the spectral clustering toolbox developed by Wen-Yen Chen, et al. (Chen et al., 2008) 1. Since the cooccurrence-based term relatedness is usually sparse, the traditional eigenvalue decomposition in spectral clustering will sometimes get run-time error. In this paper, we use the singular value decomposition (SVD) technique for spectral clustering instead. For spectral clustering, two parameters are required to be set by the user: the cluster number m, and σ which is used in computing similarities from object distances 2 s(i, j) = exp(−d(i,2)) (7) where s(i, j) and d(i, j) are the similarity and distance between i and j respectively. 1The package could be accessed via http://www</context>
</contexts>
<marker>Chen, Song, Bai, Lin, Chang, 2008</marker>
<rawString>Wen Y. Chen, Yangqiu Song, Hongjie Bai, Chih J. Lin, and Edward Chang. 2008. Psc: Paralel spectral clustering. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudi L Cilibrasi</author>
<author>Paul M B Vitanyi</author>
</authors>
<title>The google similarity distance.</title>
<date>2007</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="13829" citStr="Cilibrasi and Vitanyi, 2007" startWordPosition="2161" endWordPosition="2165">edia is to consider each Wikipedia article as a concept. Then the semantic meaning of a term could be represented as a weighted vector of Wikipedia concepts, of which the values are the term’s TFIDF within corresponding Wikipedia articles. We could compute the term relatedness by comparing the concept vectors of the terms. Empirical evaluations confirm that the idea is effective and practical for computing term relatedness (Gabrilovich and Markovitch, 2007). In this paper, we select cosine similarity, Euclidean distance, Point-wise Mutual Information and Normalized Google Similarity Distance (Cilibrasi and Vitanyi, 2007) for measuring term relatedness based on the vector of Wikipedia concepts. Denote the Wikipedia-concept vector of the term ti as Ci = {ci1, ci2, ..., ciN1, where N indicates the number of Wikipedia articles, and cik is the TFIDF value of wi in the kth Wikipedia article. The cosine similarity is defined as Ci Cj cos(i, j) = (1) llCillllCjll The definition of Euclidean distance is (cik − cjk)2 (2) Point-wise Mutual Information (PMI) is a common approach to quantify relatedness. Here we take three ways to measure term relatedness using PMI. One is based on Wikipedia page count, N x p(i, j) pmip(i</context>
<context position="15300" citStr="Cilibrasi and Vitanyi, 2007" startWordPosition="2435" endWordPosition="2438"> log2 Tx t (j) (4) where T is the number of terms in Wikipedia, t(i, j) is the number of ti and tj occurred adjacently in Wikipedia, and t(i) is the number of ti in Wikipedia. The third one is a combination of the above two PMI ways, N x pt(i, j) pmic(i,j) = log2 p(i) x p(j) (5) where pt(i, j) indicates the number of Wikipedia articles containing ti and tj as adjacency. It is obvious that pmic(i, j) G pmip(i, j), and pmic(i, j) is more strict and accurate for measuring relatedness. Normalized Google Similarity Distance (NGD) is a new measure for measuring similarity between terms proposed by (Cilibrasi and Vitanyi, 2007) based on information distance and Kolmogorov complexity. It could be applied to compute term similarity from the World Wide Web or any large enough corpus using the page counts of terms. NGD used in this paper is based on Wikipedia article count, defined as max(log p(i), log p(j)) − logp(i, j) ngd(i,j) = log N − min(logp(i), logp(j)) (6) where N is the number of Wikipedia articles used as normalized factor. Once we get the term relatedness, we could then group the terms using clustering techniques and find exemplar terms for each cluster. 6 Term Clustering Clustering is an important unsupervi</context>
</contexts>
<marker>Cilibrasi, Vitanyi, 2007</marker>
<rawString>Rudi L. Cilibrasi and Paul M. B. Vitanyi. 2007. The google similarity distance. IEEE Transactions on Knowledge and Data Engineering, 19(3):370–383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Hanna M Wallach</author>
<author>Danny Puller</author>
<author>Fernando Pereira</author>
</authors>
<title>Generating summary keywords for emails using topics.</title>
<date>2008</date>
<booktitle>In Proceedings of the 13th international conference on Intelligent user interfaces,</booktitle>
<pages>199--206</pages>
<contexts>
<context position="8219" citStr="Dredze et al., 2008" startWordPosition="1263" endWordPosition="1266">r documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method using community detection on semantic term graphs is proposed for keyphrase extraction from multi-theme documents (Grineva et al., 2009). In addition, some practical systems, such as KP-Miner (Elbeltagy and Rafea, 2009), also do not need to be trained on a particular humanannotated document set. In recent years, a number of systems are developed for extracting keyphrases from web documents (Kelleher and Luz, 2005; Chen et al., 2005), email (Dredze et al., 2008) and some other specific sources, which indicates the importance of keyphrase extraction in the web era. However, 258 none of these previous works has overall consideration on the essential properties of appropriate keyphrases mentioned in Section 1. We should also note that, although the precision and recall of most current keyphrase extractors are still much lower compared to other NLPtasks, it does not indicate the performance is poor because even different annotators may assign different keyphrases to the same document. As described in (Wan and Xiao, 2008b), when two annotators were asked </context>
</contexts>
<marker>Dredze, Wallach, Puller, Pereira, 2008</marker>
<rawString>Mark Dredze, Hanna M. Wallach, Danny Puller, and Fernando Pereira. 2008. Generating summary keywords for emails using topics. In Proceedings of the 13th international conference on Intelligent user interfaces, pages 199–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Elbeltagy</author>
<author>A Rafea</author>
</authors>
<title>Kp-miner: A keyphrase extraction system for english and arabic documents.</title>
<date>2009</date>
<journal>Information Systems,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="7973" citStr="Elbeltagy and Rafea, 2009" startWordPosition="1219" endWordPosition="1222">t neighbor documents to provide more knowledge to improve graph-based keyphrase extraction algorithm for single document. Motivated by similar idea, Wan and Xiao (Wan and Xiao, 2008a) propose to adopt clustering methods to find a small number of similar documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method using community detection on semantic term graphs is proposed for keyphrase extraction from multi-theme documents (Grineva et al., 2009). In addition, some practical systems, such as KP-Miner (Elbeltagy and Rafea, 2009), also do not need to be trained on a particular humanannotated document set. In recent years, a number of systems are developed for extracting keyphrases from web documents (Kelleher and Luz, 2005; Chen et al., 2005), email (Dredze et al., 2008) and some other specific sources, which indicates the importance of keyphrase extraction in the web era. However, 258 none of these previous works has overall consideration on the essential properties of appropriate keyphrases mentioned in Section 1. We should also note that, although the precision and recall of most current keyphrase extractors are st</context>
<context position="10996" citStr="Elbeltagy and Rafea, 2009" startWordPosition="1717" endWordPosition="1720">e document. In the next four sections we describe the algorithm in detail. 4 Candidate Term Selection Not all words in a document are possible to be selected as keyphrases. In order to filter out the noisy words in advance, we select candidate terms using some heuristic rules. This step proceeds as follows. Firstly the text is tokenized for English or segmented into words for Chinese and other languages without word-separators. Then we remove the stop words and consider the remaining single terms as candidates for calculating semantic relatedness and clustering. In methods like (Turney, 1999; Elbeltagy and Rafea, 2009), candidate keyphrases were first found using n-gram. Instead, in this method, we just find the single-word terms as the candidate terms at the beginning. After identifying the exemplar terms within the candidate terms, we extract multi-word keyphrases using the exemplars. 5 Calculating Term Relatedness After selecting candidate terms, it is important to measure term relatedness for clustering. In this paper, we propose two approaches to calculate term relatedness: one is based on term cooccurrence within the document, and the other by leveraging human knowledge bases. 5.1 Cooccurrence-based T</context>
</contexts>
<marker>Elbeltagy, Rafea, 2009</marker>
<rawString>S. Elbeltagy and A. Rafea. 2009. Kp-miner: A keyphrase extraction system for english and arabic documents. Information Systems, 34(1):132–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eibe Frank</author>
<author>Gordon W Paynter</author>
<author>Ian H Witten</author>
<author>Carl Gutwin</author>
<author>Craig G Nevill-Manning</author>
</authors>
<title>Domain-specific keyphrase extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>668--673</pages>
<contexts>
<context position="6253" citStr="Frank et al., 1999" startWordPosition="953" endWordPosition="956">d Work A straightforward method for keyphrase extraction is to select keyphrases according to frequency criteria. However, the poor performance of this method drives people to explore other methods. A pioneering achievement is carried out in (Turney, 1999), as mentioned in Section 1, a supervised machine learning method was suggested in this paper which regards keyphrase extraction as a classification task. In this work, parameterized heuristic rules are combined with a genetic algorithm into a system for keyphrase extraction. A different learning algorithm, Naive Bayes method, is applied in (Frank et al., 1999) with improved results on the same data used in (Turney, 1999). Hulth (Hulth, 2003; Hulth, 2004) adds more linguistic knowledge, such as syntactic features, to enrich term representation, which significantly improves the performance. Generally, the supervised methods need manually annotated training set, which may sometimes not be practical, especially in the web scenario. Starting with TextRank (Mihalcea and Tarau, 2004), graph-based ranking methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on t</context>
</contexts>
<marker>Frank, Paynter, Witten, Gutwin, Nevill-Manning, 1999</marker>
<rawString>Eibe Frank, Gordon W. Paynter, Ian H. Witten, Carl Gutwin, and Craig G. Nevill-Manning. 1999. Domain-specific keyphrase extraction. In Proceedings of the 16th International Joint Conference on Artificial Intelligence, pages 668–673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan J J Frey</author>
<author>Delbert Dueck</author>
</authors>
<title>Clustering by passing messages between data points.</title>
<date>2007</date>
<publisher>Science.</publisher>
<contexts>
<context position="18515" citStr="Frey and Dueck, 2007" startWordPosition="2949" endWordPosition="2952">s paper, we use the singular value decomposition (SVD) technique for spectral clustering instead. For spectral clustering, two parameters are required to be set by the user: the cluster number m, and σ which is used in computing similarities from object distances 2 s(i, j) = exp(−d(i,2)) (7) where s(i, j) and d(i, j) are the similarity and distance between i and j respectively. 1The package could be accessed via http://www.cs. ucsb.edu/˜wychen/sc.html. 6.3 Affinity Propagation Another powerful clustering method, Affinity Propagation, is based on message passing techniques. AP was proposed in (Frey and Dueck, 2007), where AP was reported to find clusters with much lower error than those found by other methods. In this paper, we use the toolbox developed by Frey, et al. 2. Detailed description of the algorithm could be found in (Frey and Dueck, 2007). Here we introduced three parameters for AP: • Preference. Rather than requiring predefined number of clusters, Affinity Propagation takes as input a real number p for each term, so that the terms with larger p are more likely to be chosen as exemplars, i.e., centroids of clusters. These values are referred to as “preferences”. The preferences are usually be</context>
</contexts>
<marker>Frey, Dueck, 2007</marker>
<rawString>Brendan J J. Frey and Delbert Dueck. 2007. Clustering by passing messages between data points. Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>6--12</pages>
<contexts>
<context position="12993" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="2031" endWordPosition="2034">OS) tags. In this paper we select the first type because each word in the sequence takes important role for measuring term cooccurrences, no matter whether 259 it is a stop word or something else. If we filter out some words, the term relatedness will not be as precise as before. In experiments, we will investigate how the window size influences the performance of keyphrase extraction. 5.2 Wikipedia-based Term Relatedness Many methods have been proposed for measuring the relatedness between terms using external resources. One principled method is leveraging human knowledge bases. Inspired by (Gabrilovich and Markovitch, 2007), we adopt Wikipedia, the largest encyclopedia collected and organized by human on the web, as the knowledge base to measure term relatedness. The basic idea of computing term relatedness by leveragting Wikipedia is to consider each Wikipedia article as a concept. Then the semantic meaning of a term could be represented as a weighted vector of Wikipedia concepts, of which the values are the term’s TFIDF within corresponding Wikipedia articles. We could compute the term relatedness by comparing the concept vectors of the terms. Empirical evaluations confirm that the idea is effective and practi</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>E. Gabrilovich and S. Markovitch. 2007. Computing semantic relatedness using wikipedia-based explicit semantic analysis. In Proceedings of the 20th International Joint Conference on Artificial Intelligence, pages 6–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Grineva</author>
<author>M Grinev</author>
<author>D Lizorkin</author>
</authors>
<title>Extracting key terms from noisy and multi-theme documents.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th international conference on World wide web,</booktitle>
<pages>661--670</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7890" citStr="Grineva et al., 2009" startWordPosition="1207" endWordPosition="1210">fy keyphrases. Wan and Xiao (Wan and Xiao, 2008b) use a small number of nearest neighbor documents to provide more knowledge to improve graph-based keyphrase extraction algorithm for single document. Motivated by similar idea, Wan and Xiao (Wan and Xiao, 2008a) propose to adopt clustering methods to find a small number of similar documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method using community detection on semantic term graphs is proposed for keyphrase extraction from multi-theme documents (Grineva et al., 2009). In addition, some practical systems, such as KP-Miner (Elbeltagy and Rafea, 2009), also do not need to be trained on a particular humanannotated document set. In recent years, a number of systems are developed for extracting keyphrases from web documents (Kelleher and Luz, 2005; Chen et al., 2005), email (Dredze et al., 2008) and some other specific sources, which indicates the importance of keyphrase extraction in the web era. However, 258 none of these previous works has overall consideration on the essential properties of appropriate keyphrases mentioned in Section 1. We should also note </context>
</contexts>
<marker>Grineva, Grinev, Lizorkin, 2009</marker>
<rawString>M. Grineva, M. Grinev, and D. Lizorkin. 2009. Extracting key terms from noisy and multi-theme documents. In Proceedings of the 18th international conference on World wide web, pages 661–670. ACM New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiawei Han</author>
<author>Micheline Kamber</author>
</authors>
<title>Data Mining: Concepts and Techniques, second edition.</title>
<date>2005</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="16097" citStr="Han and Kamber, 2005" startWordPosition="2570" endWordPosition="2573">s of terms. NGD used in this paper is based on Wikipedia article count, defined as max(log p(i), log p(j)) − logp(i, j) ngd(i,j) = log N − min(logp(i), logp(j)) (6) where N is the number of Wikipedia articles used as normalized factor. Once we get the term relatedness, we could then group the terms using clustering techniques and find exemplar terms for each cluster. 6 Term Clustering Clustering is an important unsupervised learning problem, which is the assignment of objects into groups so that objects from the same cluster are more similar to each other than objects from different clusters (Han and Kamber, 2005). In this paper, we use three widely used clustering algorithms, hierarchical clustering, spectral clustering and Affinity Propagation, to cluster the candidate terms of a given document based on the semantic relatedness between them. euc(i, j) = N k=1 260 6.1 Hierarchical Clustering Hierarchical clustering groups data over a variety of scales by creating a cluster tree. The tree is a multilevel hierarchy, where clusters at one level are joined as clusters at the next level. The hierarchical clustering follows this procedure: 1. Find the distance or similarity between every pair of data points</context>
</contexts>
<marker>Han, Kamber, 2005</marker>
<rawString>Jiawei Han and Micheline Kamber. 2005. Data Mining: Concepts and Techniques, second edition. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chong Huang</author>
<author>Yonghong Tian</author>
<author>Zhi Zhou</author>
<author>Charles X Ling</author>
<author>Tiejun Huang</author>
</authors>
<title>Keyphrase extraction using semantic networks structure analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the 6th International Conference on Data Mining,</booktitle>
<pages>275--284</pages>
<contexts>
<context position="7156" citStr="Huang et al., 2006" startWordPosition="1087" endWordPosition="1090">notated training set, which may sometimes not be practical, especially in the web scenario. Starting with TextRank (Mihalcea and Tarau, 2004), graph-based ranking methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on the word graph of a document under the assumption that the top-ranked nodes should be the document keywords. Experiments show that classificationbased supervised method provides the highest keyword identification accuracy, while the HITS algorithm gets the highest F-measure. Work in (Huang et al., 2006) also considers each document as a term graph where the structural dynamics of these graphs can be used to identify keyphrases. Wan and Xiao (Wan and Xiao, 2008b) use a small number of nearest neighbor documents to provide more knowledge to improve graph-based keyphrase extraction algorithm for single document. Motivated by similar idea, Wan and Xiao (Wan and Xiao, 2008a) propose to adopt clustering methods to find a small number of similar documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method us</context>
</contexts>
<marker>Huang, Tian, Zhou, Ling, Huang, 2006</marker>
<rawString>Chong Huang, Yonghong Tian, Zhi Zhou, Charles X. Ling, and Tiejun Huang. 2006. Keyphrase extraction using semantic networks structure analysis. In Proceedings of the 6th International Conference on Data Mining, pages 275–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anette Hulth</author>
</authors>
<title>Improved automatic keyword extraction given more linguistic knowledge.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 conference on Empirical methods in natural language processing,</booktitle>
<pages>216--223</pages>
<contexts>
<context position="6335" citStr="Hulth, 2003" startWordPosition="969" endWordPosition="970"> to frequency criteria. However, the poor performance of this method drives people to explore other methods. A pioneering achievement is carried out in (Turney, 1999), as mentioned in Section 1, a supervised machine learning method was suggested in this paper which regards keyphrase extraction as a classification task. In this work, parameterized heuristic rules are combined with a genetic algorithm into a system for keyphrase extraction. A different learning algorithm, Naive Bayes method, is applied in (Frank et al., 1999) with improved results on the same data used in (Turney, 1999). Hulth (Hulth, 2003; Hulth, 2004) adds more linguistic knowledge, such as syntactic features, to enrich term representation, which significantly improves the performance. Generally, the supervised methods need manually annotated training set, which may sometimes not be practical, especially in the web scenario. Starting with TextRank (Mihalcea and Tarau, 2004), graph-based ranking methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on the word graph of a document under the assumption that the top-ranked nodes should </context>
<context position="20133" citStr="Hulth, 2003" startWordPosition="3244" endWordPosition="3245">its value from the previous iteration plus 1 − λ times its prescribed updated value, where the damping factor λ is between 0 and 1. In this paper we set λ = 0.9. 7 From Exemplar Terms to Keyphrases After term clustering, we select the exemplar terms of each clusters as seed terms. In Affinity Propagation, the exemplar terms are directly obtained from the clustering results. In hierarchical clustering, exemplar terms could also be obtained by the Matlab toolbox. While in spectral clustering, we select the terms that are most close to the centroid of a cluster as exemplar terms. As reported in (Hulth, 2003), most manually assigned keyphrases turn out to be noun groups. Therefore, we annotate the document with POS 2The package could be accessed via http://www. psi.toronto.edu/affinitypropagation/. 261 tags using Stanford Log-Linear Tagger 3, and then extract the noun groups whose pattern is zero or more adjectives followed by one or more nouns. The pattern can be represented using regular expressions as follows (JJ) ∗ (NN|NNS|NNP)+ where JJ indicates adjectives and various forms of nouns are represented using NN, NNS and NNP. From these noun groups, we select the ones that contain one or more exe</context>
<context position="21579" citStr="Hulth, 2003" startWordPosition="3476" endWordPosition="3477">ent word list to filter out the terms that are too common to be keyphrases. 8 Experiment Results 8.1 Datasets and Evaluation Metric The dataset used in the experiments is a collection of scientific publication abstracts from the Inspec database and the corresponding manually assigned keyphrases 4. The dataset is used in both (Hulth, 2003) and (Mihalcea and Tarau, 2004). Each abstract has two kinds of keyphrases: controlled keyphrases, restricted to a given dictionary, and uncontrolled keyphrases, freely assigned by the experts. We use the uncontrolled keyphrases for evaluation as proposed in (Hulth, 2003) and followed by (Mihalcea and Tarau, 2004). As indicated in (Hulth, 2003; Mihalcea and Tarau, 2004), in uncontrolled manually assigned keyphrases, only the ones that occur in the corresponding abstracts are considered in evaluation. The extracted keyphrases of various methods and manually assigned keyphrases are compared after stemming. In the experiments of (Hulth, 2003), for her supervised method, Hulth splits a total of 2, 000 abstracts into 1, 000 for training, 500 for validation and 500 for test. In (Mihalcea and Tarau, 2004), due to the unsupervised method, only the test set was used fo</context>
<context position="27345" citStr="Hulth, 2003" startWordPosition="4395" endWordPosition="4396">367 m = 1 3n 0.365 0.562 0.432 1 0.351 0.629 0.446 m = 2n 0.657 0.448 m = 2 3n 0.346 4 m = 5n 0.340 Spectral Clustering m = 4n 0.409 0.397 1 0.385 0.497 0.427 m = 1 3n 0.374 0.497 0.427 1 0.374 0.660 0.457 m =2n 0.679 0.453 m = 2 3n 0.350 4 m = 5n 0.340 Affinity Propagation p = max 0.331 0.688 0.447 p = mean 0.433 0.070 0.121 p = median 0.422 0.078 0.132 p = min 0.419 0.059 0.103 these methods, only Affinity Propagation under some parameters performs poorly. 8.4 Comparing with Other Algorithms Table 3 lists the results of the clustering-based method compared with the best results reported in (Hulth, 2003; Mihalcea and Tarau, 2004) on the same dataset. For each method, the table lists the total number of assigned keyphrases, the mean number of keyphrases per abstract, the total number of correct keyphrases, and the mean number of correct keyphrases. The table also lists precision, recall and F1-measure. In this table, hierarchical clustering, spectral clustering and Affinity Propagation are abbreviated by “HC”, “SC” and “AP” respectively. The result of Hulth’s method listed in this table is the best one reported in (Hulth, 2003) on the same dataset. This is a supervised classificationbased met</context>
</contexts>
<marker>Hulth, 2003</marker>
<rawString>Anette Hulth. 2003. Improved automatic keyword extraction given more linguistic knowledge. In Proceedings of the 2003 conference on Empirical methods in natural language processing, pages 216–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hulth</author>
</authors>
<title>Reducing false positives by expert combination in automatic keyword indexing.</title>
<date>2004</date>
<booktitle>Recent Advances in Natural Language Processing III: Selected Papers from RANLP 2003,</booktitle>
<pages>367</pages>
<contexts>
<context position="6349" citStr="Hulth, 2004" startWordPosition="971" endWordPosition="972"> criteria. However, the poor performance of this method drives people to explore other methods. A pioneering achievement is carried out in (Turney, 1999), as mentioned in Section 1, a supervised machine learning method was suggested in this paper which regards keyphrase extraction as a classification task. In this work, parameterized heuristic rules are combined with a genetic algorithm into a system for keyphrase extraction. A different learning algorithm, Naive Bayes method, is applied in (Frank et al., 1999) with improved results on the same data used in (Turney, 1999). Hulth (Hulth, 2003; Hulth, 2004) adds more linguistic knowledge, such as syntactic features, to enrich term representation, which significantly improves the performance. Generally, the supervised methods need manually annotated training set, which may sometimes not be practical, especially in the web scenario. Starting with TextRank (Mihalcea and Tarau, 2004), graph-based ranking methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on the word graph of a document under the assumption that the top-ranked nodes should be the documen</context>
</contexts>
<marker>Hulth, 2004</marker>
<rawString>A. Hulth. 2004. Reducing false positives by expert combination in automatic keyword indexing. Recent Advances in Natural Language Processing III: Selected Papers from RANLP 2003, page 367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Kelleher</author>
<author>Saturnino Luz</author>
</authors>
<title>Automatic hypertext keyphrase detection.</title>
<date>2005</date>
<booktitle>In Proceedings of the 19th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="8170" citStr="Kelleher and Luz, 2005" startWordPosition="1254" endWordPosition="1257">clustering methods to find a small number of similar documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method using community detection on semantic term graphs is proposed for keyphrase extraction from multi-theme documents (Grineva et al., 2009). In addition, some practical systems, such as KP-Miner (Elbeltagy and Rafea, 2009), also do not need to be trained on a particular humanannotated document set. In recent years, a number of systems are developed for extracting keyphrases from web documents (Kelleher and Luz, 2005; Chen et al., 2005), email (Dredze et al., 2008) and some other specific sources, which indicates the importance of keyphrase extraction in the web era. However, 258 none of these previous works has overall consideration on the essential properties of appropriate keyphrases mentioned in Section 1. We should also note that, although the precision and recall of most current keyphrase extractors are still much lower compared to other NLPtasks, it does not indicate the performance is poor because even different annotators may assign different keyphrases to the same document. As described in (Wan </context>
</contexts>
<marker>Kelleher, Luz, 2005</marker>
<rawString>Daniel Kelleher and Saturnino Luz. 2005. Automatic hypertext keyphrase detection. In Proceedings of the 19th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Litvak</author>
<author>Mark Last</author>
</authors>
<title>Graph-based keyword extraction for single-document summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of the workshop Multi-source Multilingual Information Extraction and Summarization,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="6825" citStr="Litvak and Last, 2008" startWordPosition="1036" endWordPosition="1039">e Bayes method, is applied in (Frank et al., 1999) with improved results on the same data used in (Turney, 1999). Hulth (Hulth, 2003; Hulth, 2004) adds more linguistic knowledge, such as syntactic features, to enrich term representation, which significantly improves the performance. Generally, the supervised methods need manually annotated training set, which may sometimes not be practical, especially in the web scenario. Starting with TextRank (Mihalcea and Tarau, 2004), graph-based ranking methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on the word graph of a document under the assumption that the top-ranked nodes should be the document keywords. Experiments show that classificationbased supervised method provides the highest keyword identification accuracy, while the HITS algorithm gets the highest F-measure. Work in (Huang et al., 2006) also considers each document as a term graph where the structural dynamics of these graphs can be used to identify keyphrases. Wan and Xiao (Wan and Xiao, 2008b) use a small number of nearest neighbor documents to provide more knowledge to improve graph-based keyphras</context>
</contexts>
<marker>Litvak, Last, 2008</marker>
<rawString>Marina Litvak and Mark Last. 2008. Graph-based keyword extraction for single-document summarization. In Proceedings of the workshop Multi-source Multilingual Information Extraction and Summarization, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>Textrank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2416" citStr="Mihalcea and Tarau, 2004" startWordPosition="348" endWordPosition="352">vised and unsupervised approaches. The supervised approach (Turney, 1999) regards keyphrase extraction as a classification task. In this approach, a model is trained to determine whether a candidate term of the document is a keyphrase, based on statistical and linguistic features. For the supervised keyphrase extraction approach, a document set with human-assigned keyphrases is required as training set. However, human labelling is time-consuming. Therefore, in this study we focus on unsupervised approach. As an example of an unsupervised keyphrase extraction approach, the graph-based ranking (Mihalcea and Tarau, 2004) regards keyphrase extraction as a ranking task, where a document is represented by a term graph based on term relatedness, and then a graph-based ranking algorithm is used to assign importance scores to each term. Existing methods usually use term cooccurrences within a specified window size in the given document as an approximation of term relatedness (Mihalcea and Tarau, 2004). As we know, none of these existing works gives an explicit definition on what are appropriate keyphrases for a document. In fact, the existing methods only judge the importance of each term, and extract the most impo</context>
<context position="6678" citStr="Mihalcea and Tarau, 2004" startWordPosition="1014" endWordPosition="1017">work, parameterized heuristic rules are combined with a genetic algorithm into a system for keyphrase extraction. A different learning algorithm, Naive Bayes method, is applied in (Frank et al., 1999) with improved results on the same data used in (Turney, 1999). Hulth (Hulth, 2003; Hulth, 2004) adds more linguistic knowledge, such as syntactic features, to enrich term representation, which significantly improves the performance. Generally, the supervised methods need manually annotated training set, which may sometimes not be practical, especially in the web scenario. Starting with TextRank (Mihalcea and Tarau, 2004), graph-based ranking methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on the word graph of a document under the assumption that the top-ranked nodes should be the document keywords. Experiments show that classificationbased supervised method provides the highest keyword identification accuracy, while the HITS algorithm gets the highest F-measure. Work in (Huang et al., 2006) also considers each document as a term graph where the structural dynamics of these graphs can be used to identify keyphr</context>
<context position="21338" citStr="Mihalcea and Tarau, 2004" startWordPosition="3439" endWordPosition="3442">tain one or more exemplar terms to be the keyphrases of the document. In this process, we may find single-word keyphrases. In practice, only a small fraction of keyphrases are single-word. Thus, as a part of postprocessing process, we have to use a frequent word list to filter out the terms that are too common to be keyphrases. 8 Experiment Results 8.1 Datasets and Evaluation Metric The dataset used in the experiments is a collection of scientific publication abstracts from the Inspec database and the corresponding manually assigned keyphrases 4. The dataset is used in both (Hulth, 2003) and (Mihalcea and Tarau, 2004). Each abstract has two kinds of keyphrases: controlled keyphrases, restricted to a given dictionary, and uncontrolled keyphrases, freely assigned by the experts. We use the uncontrolled keyphrases for evaluation as proposed in (Hulth, 2003) and followed by (Mihalcea and Tarau, 2004). As indicated in (Hulth, 2003; Mihalcea and Tarau, 2004), in uncontrolled manually assigned keyphrases, only the ones that occur in the corresponding abstracts are considered in evaluation. The extracted keyphrases of various methods and manually assigned keyphrases are compared after stemming. In the experiments </context>
<context position="27372" citStr="Mihalcea and Tarau, 2004" startWordPosition="4397" endWordPosition="4400">0.365 0.562 0.432 1 0.351 0.629 0.446 m = 2n 0.657 0.448 m = 2 3n 0.346 4 m = 5n 0.340 Spectral Clustering m = 4n 0.409 0.397 1 0.385 0.497 0.427 m = 1 3n 0.374 0.497 0.427 1 0.374 0.660 0.457 m =2n 0.679 0.453 m = 2 3n 0.350 4 m = 5n 0.340 Affinity Propagation p = max 0.331 0.688 0.447 p = mean 0.433 0.070 0.121 p = median 0.422 0.078 0.132 p = min 0.419 0.059 0.103 these methods, only Affinity Propagation under some parameters performs poorly. 8.4 Comparing with Other Algorithms Table 3 lists the results of the clustering-based method compared with the best results reported in (Hulth, 2003; Mihalcea and Tarau, 2004) on the same dataset. For each method, the table lists the total number of assigned keyphrases, the mean number of keyphrases per abstract, the total number of correct keyphrases, and the mean number of correct keyphrases. The table also lists precision, recall and F1-measure. In this table, hierarchical clustering, spectral clustering and Affinity Propagation are abbreviated by “HC”, “SC” and “AP” respectively. The result of Hulth’s method listed in this table is the best one reported in (Hulth, 2003) on the same dataset. This is a supervised classificationbased method, which takes more lingu</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. Textrank: Bringing order into texts. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Learning to Extract Keyphrases from Text.</title>
<date>1999</date>
<tech>Technical Report ERB-1057.</tech>
<institution>National Research Council Canada, Institute for Information Technology,</institution>
<contexts>
<context position="1864" citStr="Turney, 1999" startWordPosition="269" endWordPosition="270">How to effectively seek and manage information becomes an important research issue. Keyphrases, as a brief summary of a document, provide a solution to help organize, manage and retrieve documents, and are widely used in digital libraries and information retrieval. Keyphrases in articles of journals and books are usually assigned by authors. However, most articles on the web usually do not have human-assigned keyphrases. Therefore, automatic keyphrase extraction is an important research task. Existing methods can be divided into supervised and unsupervised approaches. The supervised approach (Turney, 1999) regards keyphrase extraction as a classification task. In this approach, a model is trained to determine whether a candidate term of the document is a keyphrase, based on statistical and linguistic features. For the supervised keyphrase extraction approach, a document set with human-assigned keyphrases is required as training set. However, human labelling is time-consuming. Therefore, in this study we focus on unsupervised approach. As an example of an unsupervised keyphrase extraction approach, the graph-based ranking (Mihalcea and Tarau, 2004) regards keyphrase extraction as a ranking task,</context>
<context position="5890" citStr="Turney, 1999" startWordPosition="897" endWordPosition="898"> follows. In Section 2, we introduce and discuss the related work in this area. In Section 3, we give an overview of our method for keyphrase extraction. From Section 4 to Section 7, the algorithm is described in detail. Empirical experiment results are demonstrated in Section 8, followed by our conclusions and plans for future work in Section 9. 2 Related Work A straightforward method for keyphrase extraction is to select keyphrases according to frequency criteria. However, the poor performance of this method drives people to explore other methods. A pioneering achievement is carried out in (Turney, 1999), as mentioned in Section 1, a supervised machine learning method was suggested in this paper which regards keyphrase extraction as a classification task. In this work, parameterized heuristic rules are combined with a genetic algorithm into a system for keyphrase extraction. A different learning algorithm, Naive Bayes method, is applied in (Frank et al., 1999) with improved results on the same data used in (Turney, 1999). Hulth (Hulth, 2003; Hulth, 2004) adds more linguistic knowledge, such as syntactic features, to enrich term representation, which significantly improves the performance. Gen</context>
<context position="10968" citStr="Turney, 1999" startWordPosition="1715" endWordPosition="1716">hrases from the document. In the next four sections we describe the algorithm in detail. 4 Candidate Term Selection Not all words in a document are possible to be selected as keyphrases. In order to filter out the noisy words in advance, we select candidate terms using some heuristic rules. This step proceeds as follows. Firstly the text is tokenized for English or segmented into words for Chinese and other languages without word-separators. Then we remove the stop words and consider the remaining single terms as candidates for calculating semantic relatedness and clustering. In methods like (Turney, 1999; Elbeltagy and Rafea, 2009), candidate keyphrases were first found using n-gram. Instead, in this method, we just find the single-word terms as the candidate terms at the beginning. After identifying the exemplar terms within the candidate terms, we extract multi-word keyphrases using the exemplars. 5 Calculating Term Relatedness After selecting candidate terms, it is important to measure term relatedness for clustering. In this paper, we propose two approaches to calculate term relatedness: one is based on term cooccurrence within the document, and the other by leveraging human knowledge bas</context>
</contexts>
<marker>Turney, 1999</marker>
<rawString>Peter D. Turney. 1999. Learning to Extract Keyphrases from Text. National Research Council Canada, Institute for Information Technology, Technical Report ERB-1057.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U von Luxburg</author>
</authors>
<title>A tutorial on spectral clustering.</title>
<date>2006</date>
<tech>Technical report,</tech>
<institution>Max Planck Institute for Biological Cybernetics.</institution>
<marker>von Luxburg, 2006</marker>
<rawString>U. von Luxburg. 2006. A tutorial on spectral clustering. Technical report, Max Planck Institute for Biological Cybernetics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>Collabrank: Towards a collaborative approach to singledocument keyphrase extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>969--976</pages>
<contexts>
<context position="7316" citStr="Wan and Xiao, 2008" startWordPosition="1115" endWordPosition="1118">g methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on the word graph of a document under the assumption that the top-ranked nodes should be the document keywords. Experiments show that classificationbased supervised method provides the highest keyword identification accuracy, while the HITS algorithm gets the highest F-measure. Work in (Huang et al., 2006) also considers each document as a term graph where the structural dynamics of these graphs can be used to identify keyphrases. Wan and Xiao (Wan and Xiao, 2008b) use a small number of nearest neighbor documents to provide more knowledge to improve graph-based keyphrase extraction algorithm for single document. Motivated by similar idea, Wan and Xiao (Wan and Xiao, 2008a) propose to adopt clustering methods to find a small number of similar documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method using community detection on semantic term graphs is proposed for keyphrase extraction from multi-theme documents (Grineva et al., 2009). In addition, some practi</context>
<context position="8784" citStr="Wan and Xiao, 2008" startWordPosition="1357" endWordPosition="1360">2005; Chen et al., 2005), email (Dredze et al., 2008) and some other specific sources, which indicates the importance of keyphrase extraction in the web era. However, 258 none of these previous works has overall consideration on the essential properties of appropriate keyphrases mentioned in Section 1. We should also note that, although the precision and recall of most current keyphrase extractors are still much lower compared to other NLPtasks, it does not indicate the performance is poor because even different annotators may assign different keyphrases to the same document. As described in (Wan and Xiao, 2008b), when two annotators were asked to label keyphrases on 308 documents, the Kappa statistic for measuring interagreement among them was only 0.70. 3 Algorithm Overview The method proposed in this paper is mainly inspired by the nature of appropriate keyphrases mentioned in Section 1, namely understandable, semantically relevant with the document and high coverage of the whole document. Let’s analyze the document describing “Beijing” from the aspects of “location”, “atmosphere” and “culture”. Under the bag-of-words assumption, each term in the document, except for function words, is used to de</context>
</contexts>
<marker>Wan, Xiao, 2008</marker>
<rawString>Xiaojun Wan and Jianguo Xiao. 2008a. Collabrank: Towards a collaborative approach to singledocument keyphrase extraction. In Proceedings of COLING, pages 969–976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>Single document keyphrase extraction using neighborhood knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence,</booktitle>
<pages>855--860</pages>
<contexts>
<context position="7316" citStr="Wan and Xiao, 2008" startWordPosition="1115" endWordPosition="1118">g methods are becoming the most widely used unsupervised approach for keyphrase extraction. The work in (Litvak and Last, 2008) applies HITS algorithm on the word graph of a document under the assumption that the top-ranked nodes should be the document keywords. Experiments show that classificationbased supervised method provides the highest keyword identification accuracy, while the HITS algorithm gets the highest F-measure. Work in (Huang et al., 2006) also considers each document as a term graph where the structural dynamics of these graphs can be used to identify keyphrases. Wan and Xiao (Wan and Xiao, 2008b) use a small number of nearest neighbor documents to provide more knowledge to improve graph-based keyphrase extraction algorithm for single document. Motivated by similar idea, Wan and Xiao (Wan and Xiao, 2008a) propose to adopt clustering methods to find a small number of similar documents to provide more knowledge for building word graphs for keyword extraction. Moreover, after our submission of this paper, we find that a method using community detection on semantic term graphs is proposed for keyphrase extraction from multi-theme documents (Grineva et al., 2009). In addition, some practi</context>
<context position="8784" citStr="Wan and Xiao, 2008" startWordPosition="1357" endWordPosition="1360">2005; Chen et al., 2005), email (Dredze et al., 2008) and some other specific sources, which indicates the importance of keyphrase extraction in the web era. However, 258 none of these previous works has overall consideration on the essential properties of appropriate keyphrases mentioned in Section 1. We should also note that, although the precision and recall of most current keyphrase extractors are still much lower compared to other NLPtasks, it does not indicate the performance is poor because even different annotators may assign different keyphrases to the same document. As described in (Wan and Xiao, 2008b), when two annotators were asked to label keyphrases on 308 documents, the Kappa statistic for measuring interagreement among them was only 0.70. 3 Algorithm Overview The method proposed in this paper is mainly inspired by the nature of appropriate keyphrases mentioned in Section 1, namely understandable, semantically relevant with the document and high coverage of the whole document. Let’s analyze the document describing “Beijing” from the aspects of “location”, “atmosphere” and “culture”. Under the bag-of-words assumption, each term in the document, except for function words, is used to de</context>
</contexts>
<marker>Wan, Xiao, 2008</marker>
<rawString>Xiaojun Wan and Jianguo Xiao. 2008b. Single document keyphrase extraction using neighborhood knowledge. In Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence, pages 855–860.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>