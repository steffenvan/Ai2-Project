<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.98476">
Negation and Speculation Identification in Chinese Language
</title>
<author confidence="0.891049">
Bowei Zou Qiaoming Zhu Guodong Zhou*
</author>
<affiliation confidence="0.85647">
Natural Language Processing Lab, School of Computer Science and Technology
</affiliation>
<address confidence="0.877809">
Soochow University, Suzhou, 215006, China
</address>
<email confidence="0.998079">
zoubowei@gmail.com, {qmzhu, gdzhou}@suda.edu.cn
</email>
<sectionHeader confidence="0.993899" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999967037037037">
Identifying negative or speculative narra-
tive fragments from fact is crucial for
natural language processing (NLP) appli-
cations. Previous studies on negation and
speculation identification in Chinese lan-
guage suffers much from two problems:
corpus scarcity and the bottleneck in fun-
damental Chinese information processing.
To resolve these problems, this paper
constructs a Chinese corpus which con-
sists of three sub-corpora from different
resources. In order to detect the negative
and speculative cues, a sequence labeling
model is proposed. Moreover, a bilingual
cue expansion method is proposed to in-
crease the coverage in cue detection. In
addition, this paper presents a new syn-
tactic structure-based framework to iden-
tify the linguistic scope of a cue, instead
of the traditional chunking-based frame-
work. Experimental results justify the
usefulness of our Chinese corpus and the
appropriateness of our syntactic struc-
ture-based framework which obtained
significant improvement over the state-
of-the-art on negation and speculation
identification in Chinese language.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999634">
Negation and speculation are ubiquitous phe-
nomena in natural language. While negation is a
grammatical category which comprises various
kinds of devices to reverse the truth value of a
proposition, speculation is a grammatical catego-
ry which expresses the attitude of a speaker to-
wards a statement in terms of degree of certainty,
</bodyText>
<note confidence="0.479849">
* Corresponding author
</note>
<bodyText confidence="0.999330458333334">
reliability, subjectivity, sources of information,
and perspective (Morante and Sporleder, 2012).
Current studies on negation and speculation
identification mainly focus on two tasks: 1) cue
detection, which aims to detect the signal of a
negative or speculative expression, and 2) scope
resolution, which aims to determine the linguistic
coverage of a cue in sentence, in distinguishing
unreliable or uncertain information from facts.
For example, (E1) and (E2) include a negative
cue and a speculative cue respectively, both de-
noted in boldface with their linguistic scopes
denoted in square brackets (adopted hereinafter).
In sentence (E1), the negative cue “不(not)” trig-
gers the scope of “不会追究酒店的这次管理失
职(would not investigate the dereliction of ho-
tel)”, within which the fragment “investigate the
dereliction of hotel” is the part that is repudiated;
While the speculative cue “有望(expected)” in
sentence (E2) triggers the scope “后期仍有望反
弹(is still expected to rebound in the late)”, with-
in which the fragment “the benchmark Shanghai
Composite Index will rebound in the late” is the
speculative part.
</bodyText>
<equation confidence="0.5616555">
(E1) 所有住客均表示[不会追究酒店的这次管
理失职].
</equation>
<bodyText confidence="0.9333555">
(All of guests said that they [would not in-
vestigate the dereliction of hotel].)
</bodyText>
<equation confidence="0.56249">
(E2) 尽管上周五沪指盘中还受创业板的下跌
所拖累,但[后期仍有望反弹].
</equation>
<bodyText confidence="0.999556555555555">
(Although dragged down by GEM last Fri-
day, the benchmark Shanghai Composite In-
dex [is still expected to rebound in the late].)
Negation and speculation identification is very
relevant for almost all NLP applications involv-
ing text understanding which need to discrimi-
nate between factual and non-factual information.
The treatment of negation and speculation in
computational linguistics has been shown to be
</bodyText>
<page confidence="0.992732">
656
</page>
<note confidence="0.981017333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 656–665,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.974786648148148">
useful for biomedical text processing (Morante et
al., 2008; Chowdhury and Lavelli, 2013), infor-
mation retrieval (Averbuch, 2004), sentiment
analysis (Councill et al., 2010; Zhu et al., 2014),
recognizing textual entailment (Snow et al.,
2006), machine translation (Baker et al., 2010;
Wetzel and Bond, 2012), and so forth.
The research on negation and speculation
identification in English has received a noticea-
ble boost. However, in contrast to the significant
achievements concerning English, the research
progress in Chinese language is quite limited.
The main reason includes the following two as-
pects: First, the scarcity of linguistic resource
seriously limits the advance of related research.
To the best of our knowledge, there are no pub-
licly available standard Chinese corpus of rea-
sonable size annotated with negation and specu-
lation. Second, this may be attributed to the limi-
tations of Chinese information processing.
The contributions of this paper are as follows:
● To address the aforementioned first issue, this
paper seeks to fill this gap by presenting the
Chinese negation and speculation corpus
which consists of three kind of sub-corpora
annotated for negative and speculative cues,
and their linguistic scopes. The corpus has
been made publicly available for research
purposes and it is freely downloadable from
http://nlp.suda.edu.cn/corpus.
● For cue detection, we propose a feature-based
sequence labeling model to identify cues. It is
worth noting that the morpheme feature is
employed to better represent the composition-
al semantics inside Chinese words. Moreover,
for improving the low recall rate which suf-
fers from the unknown cues, we propose a
cross-lingual cue expansion strategy based on
parallel corpora.
● For scope resolution, we present a new syn-
tactic structure-based framework on depend-
ency tree. Evaluation justifies the appropri-
ateness and validity of this framework on
Chinese scope resolution, which outperforms
the chunking-based framework that widely
used in mainstream scope resolution systems.
The layout of the rest paper is organized as
follows. Section 2 describes related work. Sec-
tion 3 provides details about annotation guide-
lines and also presents statistics about corpus
characteristics. Section 4 describes our approach
in detail. Section 5 reports and discusses our ex-
perimental results. Finally, we conclude our
work and indicate some future work in Section 6.
</bodyText>
<sectionHeader confidence="0.999345" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999976210526316">
Currently, both cue detection task and scope res-
olution task are always modeled as a classifica-
tion problem with the purpose of predicting
whether a token is inside or outside the cue and
its scope. Among them, feature-based and ker-
nel-based approaches are most popular.
In the feature-based framework, Agarwal and
Yu (2010) employed a conditional random fields
(CRFs) model to detect speculative cues and
their scopes on the BioScope corpus. The CRFs-
based model achieved an F1-meature of 88% in
detecting speculative cues. We train this model
on our corpus as the baseline system for cue de-
tection. Our work is different from theirs in that
we employ a new feature (morpheme feature)
which is particularly appropriate for Chinese.
Besides, kernel-based approaches exploit the
structure of the tree that connects cue and its cor-
responding scope. Zou et al. (2013) developed a
tree kernel-based system to resolve the scope of
negation and speculation, which captures the
structured information in syntactic parsing trees.
To the best of our knowledge, this system is the
best English scope resolution system. For this
reason, we train this system on our corpus as the
baseline system for scope resolution.
Compared with a fair amount of works on
English negation and speculation identification,
unfortunately, few works has been published on
Chinese. Ji et al. (2010) developed a system to
detect speculation in Chinese news texts. How-
ever, only the speculative sentences have been
found out, with no more fine-grained information
such as scope. The insufficient study on Chinese
negation and speculation identification drives us
to construct a high-quality corpus and investigate
how to find an approach that is particularly ap-
propriate for Chinese language.
</bodyText>
<sectionHeader confidence="0.983344" genericHeader="method">
3 Corpus Construction
</sectionHeader>
<bodyText confidence="0.9990185">
In this section, we elaborate on the overall char-
acteristics of the Chinese Negation and Specula-
tion (abbr., CNeSp) corpus we constructed, in-
cluding a brief description of the sources that
constitute our corpus, general guidelines which
illustrated with lots of examples and some spe-
cial cases, and statistics on the overall results of
our corpus.
</bodyText>
<subsectionHeader confidence="0.996388">
3.1 Sources
</subsectionHeader>
<bodyText confidence="0.9950155">
To capture the heterogeneity of language use in
texts, the corpus consists of three different
</bodyText>
<page confidence="0.997452">
657
</page>
<bodyText confidence="0.999912757575758">
sources and types, including scientific literature,
product reviews, and financial articles.
Vincze et al. (2008) described that it is neces-
sary to separate negative and speculative infor-
mation from factual especially in science articles,
because conclusions of science experiment are
always described by using diversity of expres-
sions and include hypothetical asserts or view-
points. For this reason, we adopt the 19 articles
from Chinese Journal of Computers (Vol.35(11)),
an authoritative academic journal in Chinese, to
construct the Scientific Literature sub-corpus.
Another part of the corpus consists of 311 ar-
ticles from “股市及时雨(timely rain for stock
market)” column from Sina.com in April, 2013.
There are 22.3% and 40.2% sentences in the Fi-
nancial Article sub-corpus containing negation
and speculation respectively.
Many researches have investigated the role of
negation in sentiment analysis task, as an im-
portant linguistic qualifier which leads to a
change in polarity. For example, Councill et al.
(2010) investigated the problem of determining
the polarity of sentiment in movie reviews when
negation words occur in the sentences. On the
other hand, speculation is a linguistic expression
that tends to correlate with subjectivity which is
also crucial for sentiment analysis. Pang and Lee
(2004) showed that subjectivity detection in the
review domain helps to improve polarity classifi-
cation. Therefore, the Product Review sub-
corpus consists of 821 comments of hotel service
from the website Ctrip.com.
</bodyText>
<subsectionHeader confidence="0.999857">
3.2 Annotation Guidelines
</subsectionHeader>
<bodyText confidence="0.999366142857143">
The guidelines of our CNeSp corpus have partly
referred to the existing Bioscope corpus guide-
lines (BioScope, 2008) in order to fit the needs of
the Chinese language. In annotation process,
negative or speculative cues and their linguistic
scopes in sentence are annotated. There are sev-
eral general principles below:
</bodyText>
<listItem confidence="0.77841525">
(G1) Cue is contained in its scope.
(G2) The minimal unit that expresses negation or
speculation is annotated as a cue.
(E3) 该股极有可能再度出现涨停.
</listItem>
<bodyText confidence="0.937468833333333">
(The stock is very likely to hit limit up.)
To G2, the modifiers such as prepositions, de-
terminers, or adverbs are not annotated as parts
of the cue. For example, in Sentence (E3), “极
(very)” is only a modifier of the speculative cue
“可能(likely)”, but not a constituent of the cue.
For the drawbacks of the Bioscope corpus
guidelines either on itself or for Chinese lan-
guage, we introduced some modifications. These
main changes are summarized below:
(G3) A cue is annotated only relying on its actual
semantic in context.
</bodyText>
<equation confidence="0.659329">
(E4) 大盘不可能再次出现高开低走.
</equation>
<bodyText confidence="0.966279095238095">
(It is not possible that the broader market
opens high but slips later again.)
To G3, “不可能(not possible)” means that the
author denies the possibility of the situation that
“the broader market opens high but slips later
again”, which contains negative meanings than
speculative. Thus, the phrase “不可能(not possi-
ble)” should be labeled as a negative cue.
(G4) A scope should contain the subject which
contributes to the meaning of the content
being negated or speculated if possible.
(E5) *Once again, the Disorder module does
[not contribute positively to the prediction].
The BioScope corpus suggests that the scope
of negative adverbs usually starts with the cue
and ends at the end of the phrase, clause or sen-
tence (E5). However, in our view, the scope
should contain the subject for the integrity of
meaning. Following is an exceptional case.
(G5) Scope should be a continuous fragment in
sentence.
</bodyText>
<equation confidence="0.7213825">
(E6) 酒店有高档的配套设施,然而却[不能多给
我们提供一个枕头].
</equation>
<bodyText confidence="0.926302153846154">
(The hotel are furnished with upscale facili-
ties, but [cannot offer us one more pillow].)
Some rhetoric in Chinese language, such as
parallelism or ellipsis, often gives rise to separa-
tion of some sentence constituents from others.
For example, in Sentence (E6), the subject of the
second clause should be “ 酒 店 (the hotel)”,
which is omitted. In this situation, we only need
to identify the negative or speculative part in sen-
tence than all semantic constituents which can be
completed through other NLP technologies, such
as zero subject anaphora resolution or semantic
role labeling.
(G6) A negative or speculative character or word
may not be a cue.
(E7) 早茶的种类之多不得不赞.
(We are difficult not to give credit to the
variety of morning snack.)
We have come across several cases where the
presence of a negative or speculative character or
word does not denote negative or speculative
meaning. For example, there are lots of double
negatives in Chinese language only for empha-
sizing than negative meanings. In Sentence (E7),
obviously, the author wants to emphasis the
praise of the variety of breakfast buffet by using
</bodyText>
<page confidence="0.994347">
658
</page>
<bodyText confidence="0.999968222222222">
the phrase “不得不(be difficult not to)” which
does not imply a negative meaning.
The CNeSp corpus is annotated by two inde-
pendent annotators who are not allowed to com-
municate with each other. A linguist expert re-
solves the differences between the two annota-
tors and modified the guidelines when they are
confronted with problematic issues, yielding the
gold standard labeling of the corpus.
</bodyText>
<subsectionHeader confidence="0.999099">
3.3 Statistics and Agreement Analysis
</subsectionHeader>
<bodyText confidence="0.999153">
Table 1 summarizes the chief characteristics of
the three sub-corpora, including Scientific Litera-
ture (Sci., for short), Financial Article (Fin.), and
Product Review (Prod.). As shown in Table 1,
out of the total amount of 16,841 sentences more
than 20% contained negation or speculation, con-
firming the availability for corpus.
</bodyText>
<table confidence="0.977397454545455">
Item Sci. Fin. Prod.
#Documents 19 311 821
#Sentences 4,630 7,213 4,998
Avg. Length of Sentences 30.4 30.7 24.1
Negation
%Sentence 13.2 17.5 52.9
Avg. Length of Scopes 9.1 7.2 5.1
Speculation
%Sentence 21.6 30.5 22.6
Avg. Length of Scopes 12.3 15.0 6.9
(Avg. Length: The average number of Chinese characters.)
</table>
<tableCaption confidence="0.997373">
Table 1. Statistics of corpus.
</tableCaption>
<table confidence="0.9997536">
Type Sci. Fin. Prod.
Negation Cue 0.96 0.96 0.93
Cue &amp; Scope 0.90 0.91 0.88
Speculation Cue 0.94 0.90 0.93
Cue &amp; Scope 0.93 0.85 0.89
</table>
<tableCaption confidence="0.999765">
Table 2. Inter-annotator agreement.
</tableCaption>
<bodyText confidence="0.999993785714286">
We measured the inter-annotator agreement of
annotating cues and their linguistic scope for all
of three sub-corpora between the two independ-
ent annotators in terms of Kappa (Cohen, 1960).
The results are shown in Table 2. The 2nd and
4th rows of the table show the kappa value of
only cue annotation for negation and speculation,
respectively. The 3rd and 5th rows show the
agreement rate for both cue and its full scope.
The most obvious conclusions here are that the
identification of speculation is more complicated
than negation even for humans because of the
higher ambiguity of cues and the longer average
length of scopes in speculation.
</bodyText>
<sectionHeader confidence="0.997969" genericHeader="method">
4 Chinese Negation and Speculation
Identification
</sectionHeader>
<bodyText confidence="0.999976733333333">
As a pipeline task, negation and speculation
identification generally consists of two basic
stages, cue detection and scope resolution. The
former detects whether a word or phrase implies
negative or speculative meanings, while the latter
determines the sequences of terms which are
dominated by the corresponding cue in sentence.
In this section, we improve our cue detection
system by using the morpheme features of Chi-
nese characters and expanding the cue clusters
based on bilingual parallel corpora. Then, we
present a new syntactic structure-based frame-
work for Chinese language, which regards the
sub-structures of dependency tree selected by a
heuristic rule as scope candidates.
</bodyText>
<subsectionHeader confidence="0.995152">
4.1 Cue Detection
</subsectionHeader>
<bodyText confidence="0.987106052631579">
Most of the existing cue detection approaches are
proposed from feature engineering perspective.
They formulate cue detection as a classification
issue, which is to classify each token in sentence
as being the element of cue or not.
Feature-based sequence labeling model
At the beginning, we explore the performance of
an English cue detection system, as described in
Agarwal and Yu (2010), which employs a condi-
tional random fields (abbr., CRFs) model with
lexical and syntactic features. Unfortunately, the
performance is very low on Chinese texts (Sec-
tion 5.1). This may be attributed to the different
characteristic of Chinese language, for example,
no word boundaries and lack of morphologic
variations. Such low performance drives us to
investigate new effective features which are par-
ticularly appropriate for Chinese. We employed
three kinds of features for cue detection:
</bodyText>
<sectionHeader confidence="0.588625" genericHeader="method">
1) N-gram features
</sectionHeader>
<bodyText confidence="0.9899495">
For each character ci, assuming its 5-windows
characters are ci-2 ci-1 ci ci+1 ci+2, we adopt follow-
ing features: ci-2, ci-1, ci, ci+1, ci+2, ci-1ci, cici+1, ci-
2ci-1ci, ci-1cici+1, cici+1ci+2.
</bodyText>
<sectionHeader confidence="0.515045" genericHeader="method">
2) Lexical features
</sectionHeader>
<bodyText confidence="0.999794666666667">
To achieve high performance as much as pos-
sible, we also use some useful basic features
which are widely used in other NLP tasks on
Chinese. The basic feature set consists of POS
tag, the left/right character and its PoS tag. It is
worth noting that the cue candidates in our model
are characters. Thus, in order to get these fea-
tures, we substitute them with corresponding fea-
tures of the words which contain the characters.
</bodyText>
<sectionHeader confidence="0.607047" genericHeader="method">
3) Morpheme features
</sectionHeader>
<bodyText confidence="0.99866175">
The word-formation of Chinese implies that
almost all of the meanings of a word are made up
by the morphemes, a minimal meaningful unit in
Chinese language contained in words. This more
</bodyText>
<page confidence="0.996608">
659
</page>
<bodyText confidence="0.999743793103448">
fine-grained semantics are the compositional se-
mantics inside Chinese words namely. We as-
sume that the morphemes in a given cue are also
likely to be contained in other cues. For example,
“猜测(guess)” is a given speculative cue which
consists of “ 猜 (guess)” and “ 测 (speculate)”,
while the morpheme “猜(guess)” could be ap-
peared in “猜想(suppose)”. In consideration of
the Chinese characteristics, we use every poten-
tial character in cues to get the morpheme feature.
A Boolean feature is taken to represent the
morpheme information. Specifically, the charac-
ters which appear more than once within differ-
ent cues in training corpus were selected as the
features. The morpheme feature is set to 1, if the
character is a negative or speculative morpheme.
For the ability of capturing the local infor-
mation around a cue, we choose CRFs, a condi-
tional sequence model which represents the
probability of a hidden state sequence given
some observations, as classifier to label each
character with a tag indicating whether it is out
of a cue (O), the beginning of the cue (B) or a
part of the cue except the beginning one (I). In
this way, our CRFs-based cue identifier performs
sequential labeling by assigning each character
one of the three tags and a character assigned
with tag B is concatenated with following char-
acters with tag I to form a cue.
</bodyText>
<subsectionHeader confidence="0.673784">
Cross-lingual Cue Expansion Strategy
</subsectionHeader>
<bodyText confidence="0.9999765">
The feature-based cue detection approach men-
tioned above shows that a bottleneck lies in low
recall (see Table 4). This is probably due to the
absence of about 12% negation cues and 17%
speculation cues from the training data. It is a
challenging task to identify unknown cues with
the limited amount of training data. Hence, we
propose a cross-lingual cue expansion strategy.
In the approach, we take use of the top 5 Chi-
nese cues in training corpus as our “anchor set”.
For each cue, we search its automatically aligned
English words from a Chinese-English parallel
corpus to construct an English word cluster. The
parallel corpus consisting of 100,000 sentence
pairs is built by using Liu&apos;s approach (Liu et al.,
2014), which combines translation model with
language model to select high-quality translation
pairs from 16 million sentence pairs. The word
alignment was obtained by running Giza++ (Och
and Ney, 2003). In each cluster, we record the
frequency of each unique English word. Consid-
ering the word alignment errors in cross-lingual
clusters, we filter the clusters by word alignment
probability which is formulated as below:
</bodyText>
<equation confidence="0.9995572">
PA =aP(wE  |wC) +(1-a)P(wC  |wE)
=a P(wE,wC)+(1-a)P(wE,wC)
P(wC) P(wE)
(wE ,wC) +(1-a) align(wE,wC) (1)
align(wEi,wC) Eialign(wCi,wE)
</equation>
<bodyText confidence="0.999979722222223">
where P(wE  |wC) is the translation probability of
English word wE conditioned on Chinese word
wC, reversely, while P(wC  |wE) is the translation
probability of Chinese word wC conditioned on
English word wE. align(wm,wn) is the number of
alignments of word wm and word wn in parallel
corpus. ∑i align(wmi , wn) is the sum of the num-
ber of alignments which contain word wn. The
parameter α∈[0,1] is the coefficient controlling
the relative contributions from the two directions
of translation probability.
Then we conduct the same procedure in the
other direction to construct Chinese word clus-
ters anchored by English cues, until no new word
comes about. For example, applying the above
approach from the cue “可能(may)”, we obtain
59 Chinese speculative cues. All of words in the
final expansion cluster are identified as cues.
</bodyText>
<subsectionHeader confidence="0.992677">
4.2 Scope Resolution
</subsectionHeader>
<bodyText confidence="0.989727083333333">
Currently, mainstream approaches formulated
the scope resolution as a chunking problem,
which classifies every word of a sentence as be-
ing inside or outside the scope of a cue. However,
unlike in English, we found that plenty of errors
occurred in Chinese scope resolution by using
words as the basic identifying candidate.
In this paper we propose a new framework us-
ing the sub-structures of dependency tree as
scope candidates. Specifically, given a cue, we
adopt the following heuristic rule to get the scope
candidates in the dependency tree.
Setting constituent X and its siblings as the root
nodes of candidate structure of scope, X should
be the ancestor node of cue or cue itself.
For example, in the sentence “所有住客均表
示不会追究酒店的这次管理失职(All of guests
said that they would not investigate the derelic-
tion of hotel)”, the negative cue “不(not)” has
four constituent Xs and seven scope candidates,
as shown in Figure 1. According to the above
rule, three ancestor nodes {Xa: “表示(said)”, Xb:
“追究(investigate)”, and Xc: “会(would)”} cor-
respond to three scope candidates (a, b1, and c),
</bodyText>
<equation confidence="0.664088333333333">
align
= a
E i
</equation>
<page confidence="0.886807">
660
</page>
<figureCaption confidence="0.822165">
Figure 1. Examples of a negative cue and its seven scope candidates in dependency tree.
Feature Description Instantiation
</figureCaption>
<table confidence="0.964527588235294">
Cue:
C1: Itself Tokens of cue 不(not)
C2: PoS PoS of cue d(adverb)
Scope candidate:
S1: Itself Tokens of headword 追究(investigate)
S2: PoS PoS of headword v(verb)
S3: Dependency type Dependency type of headword VOB
S4: Dependency type of child nodes Dependency type of child nodes of headword ADV+VOB
S5: Distance&lt;candidate, left word&gt; Number of dependency arcs between the first word of can- 3
didate and its left word
S6: Distance&lt;candidate, right word&gt; Number of dependency arcs between the last word of can- 0
didate and its right word
Relationship between cue and scope candidate:
R1: Path Dependency relation path from cue to headword ADV-ADV
R2: Distance&lt;cue, headword&gt; Number of dependency arcs between cue and headword 2
R3: Compression path Compression version of path ADV
R4: Position Positional relationship of cue with scope candidate L N(Left-nested)
</table>
<tableCaption confidence="0.995061">
Table 3. Features and their instantiations for scope resolution.
</tableCaption>
<bodyText confidence="0.999863181818182">
and the cue itself is certainly a scope candidate
(d). In addition, the Xb node has two siblings in
dependency tree {“It-tr(guests)” and “Al(all
of)”}. Therefore, the two scope candidates cor-
responding to them are b2 and b3, respectively.
Similarly, the sibling of the Xc node is labeled as
candidate c2.
A binary classifier is applied to determine
each candidate as either part of scope or not. In
this paper, we employ some lexical and syntactic
features about cue and candidate. Table 3 lists all
of the features for scope resolution classification
(with candidate b1 as the focus constituent (i.e.,
the scope candidate) and “T-(not)” as the giv-
en cue, regarding candidate b1 in Figure 1(2)).
For clarity, we categorize the features into three
groups according to their relevance with the giv-
en cue (C, in short), scope candidate (S, in short),
and the relationship between cue andcandidate
(R, in short). Figure 2 shows four kinds of posi-
tional features between cue and scope candidate
we defined (R4).
</bodyText>
<figureCaption confidence="0.974668">
Figure 2. Positional features.
</figureCaption>
<bodyText confidence="0.9994546">
Some features proposed above may not be ef-
fective in classification. Therefore, we adopt a
greedy feature se-lection algorithm as described
in (Jiang and Ng, 2006) to pick up positive fea-
tures incrementally according to their contribu-
</bodyText>
<page confidence="0.996616">
661
</page>
<bodyText confidence="0.999909142857143">
tions on the development data. Additionally, a
cue should have one continuous block as its
scope, but the scope identifier may result in dis-
continuous scope due to independent candidate
in classification. For this reason, we employ a
post-processing algorithm as described in Zhu et
al. (2010) to identify the boundaries.
</bodyText>
<sectionHeader confidence="0.994649" genericHeader="method">
5 Experimentation
</sectionHeader>
<bodyText confidence="0.999953">
In this section, we evaluate our feature-based
sequence labeling model and cross-lingual cue
expansion strategy on cue detection, and report
the experimental results to justify the appropri-
ateness of our syntactic structure-based frame-
work on scope resolution in Chinese language.
The performance is measured by Precision (P),
Recall (R), and F1-score (F). In addition, for
scope resolution, we also report the accuracy in
PCS (Percentage of Correct Scopes), within
which a scope is fully correct if the output of
scope resolution system and the correct scope
have been matched exactly.
</bodyText>
<subsectionHeader confidence="0.9916315">
5.1 Cue Detection
Results of the Sequence Labeling Model
</subsectionHeader>
<bodyText confidence="0.99995636">
Every sub-corpus is randomly divided into ten
equal folds so as to perform ten-fold cross vali-
dation. Lexical features are gained by using an
open-source Chinese language processing plat-
form, LTP1(Che et al., 2010) to perform word
segmentation, POS tagging, and syntactic pars-
ing. CRF++0.582 toolkit is employed as our se-
quence labeling model for cue detection.
Table 4 lists the performances of cue detection
systems using a variety of features. It shows that
the morpheme features derived from the word-
formation of Chinese improve the performance
for both negation and speculation cue detection
systems on all kinds of sub-corpora. However,
the one exception occurs in negation cue detec-
tion on the Product Review sub-corpus, in which
the performance is decreased about 4.55% in
precision. By error analysis, we find out the main
reason is due to the pseudo cues. For example,
“非常(very)” is identified by the negative mor-
pheme “非(-un)”, which is a pseudo cue.
Table 4 also shows a bottleneck of our se-
quence labeling model, which lies in low recall.
Due to the diversity of Chinese language, many
cues only appear a few times in corpus. For ex-
</bodyText>
<footnote confidence="0.998529">
1 http://www.ltp-cloud.com
2 https://crfpp.googlecode.com/svn/trunk/doc/index.html
</footnote>
<bodyText confidence="0.99736825">
ample, 83% (233/280) of speculative cues appear
less than ten times in Financial Article sub-
corpus. This data sparse problem directly leads to
the low recall of cue detection.
</bodyText>
<table confidence="0.9997591875">
Negation Speculation
Sci. P R F1 P R F1
Agarwal’s 48.75 36.44 41.71 46.16 33.49 38.82
N-gram 64.07 49.64 55.94 62.15 42.87 50.74
+Lexical 76.68 57.36 65.63 70.47 48.31 57.32
+Morpheme 81.37 59.11 68.48 76.91 50.77 61.16
Fin.
Agarwal’s 41.93 39.15 40.49 50.39 42.80 46.29
N-gram 56.05 45.48 50.21 60.37 44.16 51.01
+Lexical 71.61 50.12 58.97 68.96 48.72 57.10
+Morpheme 78.94 53.37 63.68 75.43 51.29 61.06
Prod.
Agarwal’s 58.47 47.31 52.30 45.88 34.13 39.14
N-gram 71.33 54.69 61.91 49.38 39.31 43.77
+Lexical 86.76 65.41 74.59 64.85 44.63 52.87
+Morpheme 82.21 66.82 73.72 70.06 45.31 55.03
</table>
<tableCaption confidence="0.999902">
Table 4. Contribution of features to cue detection.
</tableCaption>
<subsectionHeader confidence="0.6326705">
Results of the Cross-lingual Cue Expansion
Strategy
</subsectionHeader>
<bodyText confidence="0.999852444444445">
Before cue expansion, we select the parameter α
as defined in formula (1) by optimizing the F1-
measure score of on Financial Article sub-corpus.
Figure 3 shows the effect on F1-measure of vary-
ing the coefficient from 0 to 1. We can see that
the best performance can be obtained by select-
ing parameter 0.6 for negation and 0.7 for specu-
lation. Then we apply these parameter values
directly for cue expansion.
</bodyText>
<figureCaption confidence="0.9923375">
Figure 3. The effect of varying the value of pa-
rameter α on Financial Article sub-corpus.
</figureCaption>
<bodyText confidence="0.996804111111111">
Table 5 lists the performances of feature-based
system, expansion-based system, and the com-
bined system. A word is identified as a cue by
combined system if it is identified by one of the
above systems (Feat-based or Exp-based) at least.
For both negation and speculation, the cross-
lingual cue expansion approach provides signifi-
cant improvement over the feature-based se-
quence labeling model, achieving about 15-20%
</bodyText>
<page confidence="0.995093">
662
</page>
<bodyText confidence="0.934522666666667">
better recall with little loss in precision. More
importantly, the combined system obtains the
best performance.
</bodyText>
<table confidence="0.999711923076923">
Negation Speculation
Sci. P R F1 P R F1
Feat-based 81.37 59.11 68.48 76.91 50.77 61.16
Exp-based 68.29 76.24 72.05 62.74 68.07 65.30
Combined 75.17 78.91 76.99 70.98 75.71 73.27
Fin.
Feat-based 78.94 53.37 63.68 75.43 51.29 61.06
Exp-based 70.31 64.49 67.27 67.46 68.78 68.11
Combined 72.77 67.02 69.78 71.60 69.03 70.29
Prod.
Feat-based 82.21 66.82 73.72 70.06 45.31 55.03
Exp-based 78.30 86.47 82.18 62.18 63.47 62.82
Combined 81.94 89.23 85.43 67.56 69.61 68.57
</table>
<tableCaption confidence="0.999642">
Table 5. Performance of cue detection.
</tableCaption>
<subsectionHeader confidence="0.965115">
5.2 Syntactic Structure-based Scope Reso-
lution
</subsectionHeader>
<bodyText confidence="0.999345833333333">
Considering the effectiveness of different fea-
tures, we divide the Financial Article sub-corpus
into 5 equal parts, within which 2 parts are used
for feature selection. Then, the feature selection
data are divided into 5 equal parts, within which
4 parts for training and the rest for developing.
On this data set, a greedy feature selection algo-
rithm (Jiang and Ng, 2006) is adopted to pick up
positive features proposed in Table 3. In addition,
SVMLighr3 with the default parameter is selected
as our classifier.
Table 6 lists the performance of selected fea-
tures. 7 features {C1, C2, S4, S5, S6, R1, R4}
are selected consecutively for negation scope
resolution, while 9 features {C2, S1, S3, S4, S5,
R1, R2, R3, R4} are selected for speculation
scope resolution. We will include those selected
features in all the remaining experiments.
</bodyText>
<table confidence="0.998839">
Type Feature set Sci. Fin. Prod.
Negation Selected features 62.16 56.07 60.93
All features 59.74 54.20 55.42
Speculation Selected features 54.16 49.64 52.89
All features 52.33 46.27 48.07
</table>
<tableCaption confidence="0.830022">
Table 6. Feature selection for scope resolution on
golden cues (PCS %).
</tableCaption>
<bodyText confidence="0.999585125">
The feature selection experiments suggest that
the feature C2 (POS of cue) plays a critical role
for both negation and speculation scope resolu-
tion. It may be due to the fact that cues of differ-
ent POS usually undertake different syntactic
roles. Thus, there are different characteristics in
triggering linguistic scopes. For example, an ad-
jective cue may treat a modificatory structure as
</bodyText>
<footnote confidence="0.710925">
3 http://svmlight.joachims.org
</footnote>
<bodyText confidence="0.999449875">
its scope, while a conjunction cue may take the
two connected components as its scope.
As a pipeline task, the negation and specula-
tion identification could be regarded as a combi-
nation of two sequential tasks: first, cue detection,
and then scope resolution. Hence, we turn to a
more realistic scenario in which cues are auto-
matically recognized.
</bodyText>
<table confidence="0.999351">
Type Corpus P R F1 PCS
Negation Sci. 55.32 53.06 54.17 59.08
Fin. 42.14 46.37 44.15 49.24
Prod. 50.57 48.55 49.54 52.17
Speculation Sci. 45.68 47.15 46.40 48.36
Fin. 34.21 31.80 32.96 41.33
Prod. 32.64 33.59 33.11 39.78
</table>
<tableCaption confidence="0.889206666666667">
Table 7. Performance of scope resolution with
automatic cue detection.
Table 7 lists the performance of scope resolu-
</tableCaption>
<bodyText confidence="0.984298045454545">
tion by using automatic cues. It shows that auto-
matic cue detection lowers the performance by
3.08, 6.83, and 8.76 in PCS for the three sub-
corpora, respectively; while it lowers the perfor-
mance by 5.80, 8.31 and 13.11 in PCS for specu-
lation scope resolution on the three sub-corpora,
respectively (refer to Table 6). The main reason
of performance lost is the error propagation from
the automatic cue detection.
We employ a start-of-the-art chunking-based
scope resolution system (described in Zou et al.,
(2013)) as a baseline, in which every word in
sentence has been labelled as being the element
of the scope or not. Table 8 compares our syntac-
tic structure-based framework with the chunking-
based framework on scope resolution. Note that
all the performances are achieved on Financial
Article sub-corpus by using golden cues. The
results in Table 8 shows that our scope resolution
system outperforms the chunking ones both on
negation and speculation, improving 8.75 and
7.44 in PCS, respectively.
</bodyText>
<table confidence="0.9984286">
Type System PCS
Negation Chunking-based 47.32
Ours 56.07
Speculation Chunking-based 42.20
Ours 49.64
</table>
<tableCaption confidence="0.9480505">
Table 8. Comparison with the chunking-based
system on Financial Article sub-corpus.
</tableCaption>
<sectionHeader confidence="0.998582" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9978182">
In this paper we construct a Chinese corpus for
negation and speculation identification, which
annotates cues and their linguistic scopes. For
cue detection, we present a feature-based se-
quence labeling model, in which the morpheme
</bodyText>
<page confidence="0.997003">
663
</page>
<bodyText confidence="0.999986705882353">
feature is employed to better catch the com-
position semantics inside the Chinese words.
Complementally, a cross-lingual cue expansion
strategy is pro-posed to increase the coverage in
cue detection. For scope resolution, we present a
new syntactic structure-based framework to iden-
tify the linguistic scope of a cue. Evaluation jus-
tifies the usefulness of our Chinese corpus and
the appropriateness of the syntactic structure-
based framework. It also shows that our ap-
proach outperforms the state-of-the-art chunking
ones on negation and speculation identification
in Chinese language.
In the future we will explore more effective
features to improve the negation and speculation
identification in Chinese language, and focus on
joint learning of the two subtasks.
</bodyText>
<sectionHeader confidence="0.998566" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.993119875">
This research is supported by the National Natu-
ral Science Foundation of China, No.61272260,
No.61331011, No.61273320, No.61373097, and
the Major Project of College Natural Science
Foundation of Jiangsu Province,
No.11KJA520003. The authors would like to
thank the anonymous reviewers for their insight-
ful comments and suggestions.
</bodyText>
<sectionHeader confidence="0.99012" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999795628205128">
Shashank Agarwal and Hong Yu. 2010. Detecting
hedge cues and their scope in biomedical text with
conditional random fields. Journal of Biomedical
Informatics, 43, 953-961.
Mordechai Averbuch, Tom H. Karson, Benjamin
Ben-Ami, Oded Maimon, and Lior Rokach. 2004.
Context-sensitive medical information retrieval. In
Proceedings of the 11th World Congress on Medi-
cal Informatics (MEDIIFO’04), 1-8.
Kathrin Baker, Michael Bloodgood, Bonnie Dorr,
Nathaniel W. Filardo, Lori Levin, and Christine Pi-
atko. 2010. A modality lexicon and its use in au-
tomatic tagging. In Proceedings of the Seventh
Conference on International Language Resources
and Evaluation (LREC’10), 1402-1407.
BioScope. 2008. Annotation guidelines.
http://www.inf.u-
szeged.hu/rgai/project/nlp/bioscope/Annotation
guidelines2.1.pdf
Wanxiang Che, Zhenghua Li, Ting Liu. 2010. LTP: A
Chinese language technology platform. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics (COLIIG&apos;10): Demon-
strations, 13-16.
Md. Faisal Mahbub Chowdhury and Alberto Lavelli.
2013. Exploiting the scope of negations and heter-
ogeneous features for relation extraction: A case
study for drug-drug interaction extraction. In Pro-
ceedings of the 2013 Conference of the Iorth
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(IAACL-HLT&apos;13), 765-771.
Jacob Cohen. 1960. A coefficient of agreement for
nominal scales. Educational and Psychological
Measurement, 20, 37-46.
Isaac Councill, Ryan McDonald, and Leonid Ve-
likovich. 2010. What’s great and what’s not:
Learning to classify the scope of negation for im-
proved sentiment analysis. In Proceedings of the
Workshop on Iegation and Speculation in Iatural
Language Processing, 51-59.
Zhengping Jiang and Hwee T. Ng. 2006. Semantic
role labeling of NomBank: A maximum entropy
approach. In Proceedings of the Human Language
Technology Conference and Conference on Empir-
ical Methods in Iatural Language Processing
(EMILP’06), 138-145.
Le Liu, Yu Hong, Hao Liu, Xing Wang, and Jianmin
Yao. 2014. Effective selection of translation model
training data. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL&apos;14), Short Papers, 569-573.
Feng Ji, Xipeng Qiu, Xuanjing Huang. 2010. Explor-
ing uncertainty sentences in Chinese. In Proceed-
ings of the 16th China Conference on Information
Retreval, 594-601.
Roser Morante, Anthony Liekens, and Walter Daele-
mans. 2008. Learning the scope of negation in bi-
omedical texts. In Proceedings of the Human Lan-
guage Technology Conference and Conference on
Empirical Methods in Iatural Language Pro-
cessing (EMILP’08), 715-724.
Roser Morante and Caroline Sporleder. 2012. Modali-
ty and negation: an introduction to the special issue.
Comput. Linguist. 38, 2, 223-260.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment
models. Comput. Linguist. 29, 1, 19-51.
Bo Pang and Lillian Lee. 2004. A sentimental educa-
tion: sentiment analysis using subjectivity. In Pro-
ceedings of the 42nd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL&apos;04),
271-278.
Rion Snow, Lucy Vanderwende, and Arul Menezes.
2006. Effectively using syntax for recognizing
false entailment. In Proceedings of the Main Con-
ference on Human Language Technology Confer-
ence of the Iorth American Chapter of the Associ-
</reference>
<page confidence="0.981775">
664
</page>
<reference confidence="0.999468466666667">
ation of Computational Linguistics (HLT-
IAACL’06), 33-40.
Veronika Vincze, György Szarvas, Richárd Farkas,
György Móra and János Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for un-
certainty, negation and their scopes. BMC Bioin-
formatics, 9(Suppl 11):S9.
Dominikus Wetzel, and Francis Bond. 2012. Enrich-
ing parallel corpora for statistical machine transla-
tion with semantic negation rephrasing. In Pro-
ceedings of the 6th Workshop on Syntax, Semantics
and Structure in Statistical Translation, 20-29.
Qiaoming Zhu, Junhui Li, Hongling Wang, and
Guodong Zhou. 2010. A Unified Framework for
Scope Learning via Simplified Shallow Semantic
Parsing. In Proceedings of the 2010 Conference on
Empirical Methods in Iatural Language Pro-
cessing (EMILP’10), 714-724.
Xiaodan Zhu, Hongyu Guo, Saif Mohammad, and
Svetlana Kiritchenko. 2014. An empirical study on
the effect of negation words on sentiment. In Pro-
ceedings of the 52nd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL’14),
304-313.
Bowei Zou, Guodong Zhou, and Qiaoming Zhu. 2013.
Tree kernel-based negation and speculation scope
detection with structured syntactic parse features.
In Proceedings of the 2013 Conference on Empiri-
cal Methods in Iatural Language Processing
(EMILP’13), 968-976.
</reference>
<page confidence="0.998395">
665
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.682700">
<title confidence="0.999885">Negation and Speculation Identification in Chinese Language</title>
<author confidence="0.99561">Zou Qiaoming Zhu Guodong</author>
<affiliation confidence="0.991939">Natural Language Processing Lab, School of Computer Science and</affiliation>
<address confidence="0.770736">Soochow University, Suzhou, 215006, China</address>
<email confidence="0.988918">zoubowei@gmail.com,{qmzhu,gdzhou}@suda.edu.cn</email>
<abstract confidence="0.996176892857143">Identifying negative or speculative narrative fragments from fact is crucial for natural language processing (NLP) applications. Previous studies on negation and speculation identification in Chinese language suffers much from two problems: corpus scarcity and the bottleneck in fundamental Chinese information processing. To resolve these problems, this paper constructs a Chinese corpus which consists of three sub-corpora from different resources. In order to detect the negative and speculative cues, a sequence labeling model is proposed. Moreover, a bilingual cue expansion method is proposed to increase the coverage in cue detection. In addition, this paper presents a new syntactic structure-based framework to identify the linguistic scope of a cue, instead of the traditional chunking-based framework. Experimental results justify the usefulness of our Chinese corpus and the appropriateness of our syntactic structure-based framework which obtained significant improvement over the stateof-the-art on negation and speculation identification in Chinese language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shashank Agarwal</author>
<author>Hong Yu</author>
</authors>
<title>Detecting hedge cues and their scope in biomedical text with conditional random fields.</title>
<date>2010</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>43</volume>
<pages>953--961</pages>
<contexts>
<context position="6403" citStr="Agarwal and Yu (2010)" startWordPosition="948" endWordPosition="951">3 provides details about annotation guidelines and also presents statistics about corpus characteristics. Section 4 describes our approach in detail. Section 5 reports and discusses our experimental results. Finally, we conclude our work and indicate some future work in Section 6. 2 Related Work Currently, both cue detection task and scope resolution task are always modeled as a classification problem with the purpose of predicting whether a token is inside or outside the cue and its scope. Among them, feature-based and kernel-based approaches are most popular. In the feature-based framework, Agarwal and Yu (2010) employed a conditional random fields (CRFs) model to detect speculative cues and their scopes on the BioScope corpus. The CRFsbased model achieved an F1-meature of 88% in detecting speculative cues. We train this model on our corpus as the baseline system for cue detection. Our work is different from theirs in that we employ a new feature (morpheme feature) which is particularly appropriate for Chinese. Besides, kernel-based approaches exploit the structure of the tree that connects cue and its corresponding scope. Zou et al. (2013) developed a tree kernel-based system to resolve the scope of</context>
<context position="15984" citStr="Agarwal and Yu (2010)" startWordPosition="2470" endWordPosition="2473">on bilingual parallel corpora. Then, we present a new syntactic structure-based framework for Chinese language, which regards the sub-structures of dependency tree selected by a heuristic rule as scope candidates. 4.1 Cue Detection Most of the existing cue detection approaches are proposed from feature engineering perspective. They formulate cue detection as a classification issue, which is to classify each token in sentence as being the element of cue or not. Feature-based sequence labeling model At the beginning, we explore the performance of an English cue detection system, as described in Agarwal and Yu (2010), which employs a conditional random fields (abbr., CRFs) model with lexical and syntactic features. Unfortunately, the performance is very low on Chinese texts (Section 5.1). This may be attributed to the different characteristic of Chinese language, for example, no word boundaries and lack of morphologic variations. Such low performance drives us to investigate new effective features which are particularly appropriate for Chinese. We employed three kinds of features for cue detection: 1) N-gram features For each character ci, assuming its 5-windows characters are ci-2 ci-1 ci ci+1 ci+2, we a</context>
</contexts>
<marker>Agarwal, Yu, 2010</marker>
<rawString>Shashank Agarwal and Hong Yu. 2010. Detecting hedge cues and their scope in biomedical text with conditional random fields. Journal of Biomedical Informatics, 43, 953-961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mordechai Averbuch</author>
<author>Tom H Karson</author>
<author>Benjamin Ben-Ami</author>
<author>Oded Maimon</author>
<author>Lior Rokach</author>
</authors>
<title>Context-sensitive medical information retrieval.</title>
<date>2004</date>
<booktitle>In Proceedings of the 11th World Congress on Medical Informatics (MEDIIFO’04),</booktitle>
<pages>1--8</pages>
<marker>Averbuch, Karson, Ben-Ami, Maimon, Rokach, 2004</marker>
<rawString>Mordechai Averbuch, Tom H. Karson, Benjamin Ben-Ami, Oded Maimon, and Lior Rokach. 2004. Context-sensitive medical information retrieval. In Proceedings of the 11th World Congress on Medical Informatics (MEDIIFO’04), 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathrin Baker</author>
<author>Michael Bloodgood</author>
<author>Bonnie Dorr</author>
<author>Nathaniel W Filardo</author>
<author>Lori Levin</author>
<author>Christine Piatko</author>
</authors>
<title>A modality lexicon and its use in automatic tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<pages>1402--1407</pages>
<contexts>
<context position="3925" citStr="Baker et al., 2010" startWordPosition="566" endWordPosition="569">on and speculation in computational linguistics has been shown to be 656 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 656–665, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics useful for biomedical text processing (Morante et al., 2008; Chowdhury and Lavelli, 2013), information retrieval (Averbuch, 2004), sentiment analysis (Councill et al., 2010; Zhu et al., 2014), recognizing textual entailment (Snow et al., 2006), machine translation (Baker et al., 2010; Wetzel and Bond, 2012), and so forth. The research on negation and speculation identification in English has received a noticeable boost. However, in contrast to the significant achievements concerning English, the research progress in Chinese language is quite limited. The main reason includes the following two aspects: First, the scarcity of linguistic resource seriously limits the advance of related research. To the best of our knowledge, there are no publicly available standard Chinese corpus of reasonable size annotated with negation and speculation. Second, this may be attributed to th</context>
</contexts>
<marker>Baker, Bloodgood, Dorr, Filardo, Levin, Piatko, 2010</marker>
<rawString>Kathrin Baker, Michael Bloodgood, Bonnie Dorr, Nathaniel W. Filardo, Lori Levin, and Christine Piatko. 2010. A modality lexicon and its use in automatic tagging. In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10), 1402-1407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>BioScope</author>
</authors>
<title>Annotation guidelines.</title>
<date>2008</date>
<note>http://www.inf.uszeged.hu/rgai/project/nlp/bioscope/Annotation guidelines2.1.pdf</note>
<contexts>
<context position="9978" citStr="BioScope, 2008" startWordPosition="1501" endWordPosition="1502"> determining the polarity of sentiment in movie reviews when negation words occur in the sentences. On the other hand, speculation is a linguistic expression that tends to correlate with subjectivity which is also crucial for sentiment analysis. Pang and Lee (2004) showed that subjectivity detection in the review domain helps to improve polarity classification. Therefore, the Product Review subcorpus consists of 821 comments of hotel service from the website Ctrip.com. 3.2 Annotation Guidelines The guidelines of our CNeSp corpus have partly referred to the existing Bioscope corpus guidelines (BioScope, 2008) in order to fit the needs of the Chinese language. In annotation process, negative or speculative cues and their linguistic scopes in sentence are annotated. There are several general principles below: (G1) Cue is contained in its scope. (G2) The minimal unit that expresses negation or speculation is annotated as a cue. (E3) 该股极有可能再度出现涨停. (The stock is very likely to hit limit up.) To G2, the modifiers such as prepositions, determiners, or adverbs are not annotated as parts of the cue. For example, in Sentence (E3), “极 (very)” is only a modifier of the speculative cue “可能(likely)”, but not a </context>
</contexts>
<marker>BioScope, 2008</marker>
<rawString>BioScope. 2008. Annotation guidelines. http://www.inf.uszeged.hu/rgai/project/nlp/bioscope/Annotation guidelines2.1.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Zhenghua Li</author>
<author>Ting Liu</author>
</authors>
<title>LTP: A Chinese language technology platform.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLIIG&apos;10): Demonstrations,</booktitle>
<pages>13--16</pages>
<contexts>
<context position="25467" citStr="Che et al., 2010" startWordPosition="4008" endWordPosition="4011">n scope resolution in Chinese language. The performance is measured by Precision (P), Recall (R), and F1-score (F). In addition, for scope resolution, we also report the accuracy in PCS (Percentage of Correct Scopes), within which a scope is fully correct if the output of scope resolution system and the correct scope have been matched exactly. 5.1 Cue Detection Results of the Sequence Labeling Model Every sub-corpus is randomly divided into ten equal folds so as to perform ten-fold cross validation. Lexical features are gained by using an open-source Chinese language processing platform, LTP1(Che et al., 2010) to perform word segmentation, POS tagging, and syntactic parsing. CRF++0.582 toolkit is employed as our sequence labeling model for cue detection. Table 4 lists the performances of cue detection systems using a variety of features. It shows that the morpheme features derived from the wordformation of Chinese improve the performance for both negation and speculation cue detection systems on all kinds of sub-corpora. However, the one exception occurs in negation cue detection on the Product Review sub-corpus, in which the performance is decreased about 4.55% in precision. By error analysis, we </context>
</contexts>
<marker>Che, Li, Liu, 2010</marker>
<rawString>Wanxiang Che, Zhenghua Li, Ting Liu. 2010. LTP: A Chinese language technology platform. In Proceedings of the 23rd International Conference on Computational Linguistics (COLIIG&apos;10): Demonstrations, 13-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Faisal Mahbub Chowdhury</author>
<author>Alberto Lavelli</author>
</authors>
<title>Exploiting the scope of negations and heterogeneous features for relation extraction: A case study for drug-drug interaction extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the Iorth American Chapter of the Association for Computational Linguistics: Human Language Technologies (IAACL-HLT&apos;13),</booktitle>
<pages>765--771</pages>
<contexts>
<context position="3730" citStr="Chowdhury and Lavelli, 2013" startWordPosition="538" endWordPosition="541"> and speculation identification is very relevant for almost all NLP applications involving text understanding which need to discriminate between factual and non-factual information. The treatment of negation and speculation in computational linguistics has been shown to be 656 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 656–665, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics useful for biomedical text processing (Morante et al., 2008; Chowdhury and Lavelli, 2013), information retrieval (Averbuch, 2004), sentiment analysis (Councill et al., 2010; Zhu et al., 2014), recognizing textual entailment (Snow et al., 2006), machine translation (Baker et al., 2010; Wetzel and Bond, 2012), and so forth. The research on negation and speculation identification in English has received a noticeable boost. However, in contrast to the significant achievements concerning English, the research progress in Chinese language is quite limited. The main reason includes the following two aspects: First, the scarcity of linguistic resource seriously limits the advance of relat</context>
</contexts>
<marker>Chowdhury, Lavelli, 2013</marker>
<rawString>Md. Faisal Mahbub Chowdhury and Alberto Lavelli. 2013. Exploiting the scope of negations and heterogeneous features for relation extraction: A case study for drug-drug interaction extraction. In Proceedings of the 2013 Conference of the Iorth American Chapter of the Association for Computational Linguistics: Human Language Technologies (IAACL-HLT&apos;13), 765-771.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<journal>Educational and Psychological Measurement,</journal>
<volume>20</volume>
<pages>37--46</pages>
<contexts>
<context position="14380" citStr="Cohen, 1960" startWordPosition="2219" endWordPosition="2220"> Sentences 30.4 30.7 24.1 Negation %Sentence 13.2 17.5 52.9 Avg. Length of Scopes 9.1 7.2 5.1 Speculation %Sentence 21.6 30.5 22.6 Avg. Length of Scopes 12.3 15.0 6.9 (Avg. Length: The average number of Chinese characters.) Table 1. Statistics of corpus. Type Sci. Fin. Prod. Negation Cue 0.96 0.96 0.93 Cue &amp; Scope 0.90 0.91 0.88 Speculation Cue 0.94 0.90 0.93 Cue &amp; Scope 0.93 0.85 0.89 Table 2. Inter-annotator agreement. We measured the inter-annotator agreement of annotating cues and their linguistic scope for all of three sub-corpora between the two independent annotators in terms of Kappa (Cohen, 1960). The results are shown in Table 2. The 2nd and 4th rows of the table show the kappa value of only cue annotation for negation and speculation, respectively. The 3rd and 5th rows show the agreement rate for both cue and its full scope. The most obvious conclusions here are that the identification of speculation is more complicated than negation even for humans because of the higher ambiguity of cues and the longer average length of scopes in speculation. 4 Chinese Negation and Speculation Identification As a pipeline task, negation and speculation identification generally consists of two basic</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20, 37-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isaac Councill</author>
<author>Ryan McDonald</author>
<author>Leonid Velikovich</author>
</authors>
<title>What’s great and what’s not: Learning to classify the scope of negation for improved sentiment analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Iegation and Speculation in Iatural Language Processing,</booktitle>
<pages>51--59</pages>
<contexts>
<context position="3813" citStr="Councill et al., 2010" startWordPosition="549" endWordPosition="552"> text understanding which need to discriminate between factual and non-factual information. The treatment of negation and speculation in computational linguistics has been shown to be 656 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 656–665, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics useful for biomedical text processing (Morante et al., 2008; Chowdhury and Lavelli, 2013), information retrieval (Averbuch, 2004), sentiment analysis (Councill et al., 2010; Zhu et al., 2014), recognizing textual entailment (Snow et al., 2006), machine translation (Baker et al., 2010; Wetzel and Bond, 2012), and so forth. The research on negation and speculation identification in English has received a noticeable boost. However, in contrast to the significant achievements concerning English, the research progress in Chinese language is quite limited. The main reason includes the following two aspects: First, the scarcity of linguistic resource seriously limits the advance of related research. To the best of our knowledge, there are no publicly available standard</context>
<context position="9335" citStr="Councill et al. (2010)" startWordPosition="1402" endWordPosition="1405">ason, we adopt the 19 articles from Chinese Journal of Computers (Vol.35(11)), an authoritative academic journal in Chinese, to construct the Scientific Literature sub-corpus. Another part of the corpus consists of 311 articles from “股市及时雨(timely rain for stock market)” column from Sina.com in April, 2013. There are 22.3% and 40.2% sentences in the Financial Article sub-corpus containing negation and speculation respectively. Many researches have investigated the role of negation in sentiment analysis task, as an important linguistic qualifier which leads to a change in polarity. For example, Councill et al. (2010) investigated the problem of determining the polarity of sentiment in movie reviews when negation words occur in the sentences. On the other hand, speculation is a linguistic expression that tends to correlate with subjectivity which is also crucial for sentiment analysis. Pang and Lee (2004) showed that subjectivity detection in the review domain helps to improve polarity classification. Therefore, the Product Review subcorpus consists of 821 comments of hotel service from the website Ctrip.com. 3.2 Annotation Guidelines The guidelines of our CNeSp corpus have partly referred to the existing </context>
</contexts>
<marker>Councill, McDonald, Velikovich, 2010</marker>
<rawString>Isaac Councill, Ryan McDonald, and Leonid Velikovich. 2010. What’s great and what’s not: Learning to classify the scope of negation for improved sentiment analysis. In Proceedings of the Workshop on Iegation and Speculation in Iatural Language Processing, 51-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhengping Jiang</author>
<author>Hwee T Ng</author>
</authors>
<title>Semantic role labeling of NomBank: A maximum entropy approach.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Iatural Language Processing (EMILP’06),</booktitle>
<pages>138--145</pages>
<contexts>
<context position="24194" citStr="Jiang and Ng, 2006" startWordPosition="3810" endWordPosition="3813">s constituent (i.e., the scope candidate) and “T-(not)” as the given cue, regarding candidate b1 in Figure 1(2)). For clarity, we categorize the features into three groups according to their relevance with the given cue (C, in short), scope candidate (S, in short), and the relationship between cue andcandidate (R, in short). Figure 2 shows four kinds of positional features between cue and scope candidate we defined (R4). Figure 2. Positional features. Some features proposed above may not be effective in classification. Therefore, we adopt a greedy feature se-lection algorithm as described in (Jiang and Ng, 2006) to pick up positive features incrementally according to their contribu661 tions on the development data. Additionally, a cue should have one continuous block as its scope, but the scope identifier may result in discontinuous scope due to independent candidate in classification. For this reason, we employ a post-processing algorithm as described in Zhu et al. (2010) to identify the boundaries. 5 Experimentation In this section, we evaluate our feature-based sequence labeling model and cross-lingual cue expansion strategy on cue detection, and report the experimental results to justify the appr</context>
<context position="29308" citStr="Jiang and Ng, 2006" startWordPosition="4626" endWordPosition="4629">1.60 69.03 70.29 Prod. Feat-based 82.21 66.82 73.72 70.06 45.31 55.03 Exp-based 78.30 86.47 82.18 62.18 63.47 62.82 Combined 81.94 89.23 85.43 67.56 69.61 68.57 Table 5. Performance of cue detection. 5.2 Syntactic Structure-based Scope Resolution Considering the effectiveness of different features, we divide the Financial Article sub-corpus into 5 equal parts, within which 2 parts are used for feature selection. Then, the feature selection data are divided into 5 equal parts, within which 4 parts for training and the rest for developing. On this data set, a greedy feature selection algorithm (Jiang and Ng, 2006) is adopted to pick up positive features proposed in Table 3. In addition, SVMLighr3 with the default parameter is selected as our classifier. Table 6 lists the performance of selected features. 7 features {C1, C2, S4, S5, S6, R1, R4} are selected consecutively for negation scope resolution, while 9 features {C2, S1, S3, S4, S5, R1, R2, R3, R4} are selected for speculation scope resolution. We will include those selected features in all the remaining experiments. Type Feature set Sci. Fin. Prod. Negation Selected features 62.16 56.07 60.93 All features 59.74 54.20 55.42 Speculation Selected fe</context>
</contexts>
<marker>Jiang, Ng, 2006</marker>
<rawString>Zhengping Jiang and Hwee T. Ng. 2006. Semantic role labeling of NomBank: A maximum entropy approach. In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Iatural Language Processing (EMILP’06), 138-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Hong Le Liu</author>
<author>Hao Liu</author>
<author>Xing Wang</author>
<author>Jianmin Yao</author>
</authors>
<title>Effective selection of translation model training data.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;14), Short Papers,</booktitle>
<pages>569--573</pages>
<marker>Le Liu, Liu, Wang, Yao, 2014</marker>
<rawString>Le Liu, Yu Hong, Hao Liu, Xing Wang, and Jianmin Yao. 2014. Effective selection of translation model training data. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;14), Short Papers, 569-573.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng Ji</author>
</authors>
<title>Xipeng Qiu, Xuanjing Huang.</title>
<date>2010</date>
<booktitle>In Proceedings of the 16th China Conference on Information Retreval,</booktitle>
<pages>594--601</pages>
<marker>Ji, 2010</marker>
<rawString>Feng Ji, Xipeng Qiu, Xuanjing Huang. 2010. Exploring uncertainty sentences in Chinese. In Proceedings of the 16th China Conference on Information Retreval, 594-601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Anthony Liekens</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of negation in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Iatural Language Processing (EMILP’08),</booktitle>
<pages>715--724</pages>
<contexts>
<context position="3700" citStr="Morante et al., 2008" startWordPosition="534" endWordPosition="537">n the late].) Negation and speculation identification is very relevant for almost all NLP applications involving text understanding which need to discriminate between factual and non-factual information. The treatment of negation and speculation in computational linguistics has been shown to be 656 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 656–665, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics useful for biomedical text processing (Morante et al., 2008; Chowdhury and Lavelli, 2013), information retrieval (Averbuch, 2004), sentiment analysis (Councill et al., 2010; Zhu et al., 2014), recognizing textual entailment (Snow et al., 2006), machine translation (Baker et al., 2010; Wetzel and Bond, 2012), and so forth. The research on negation and speculation identification in English has received a noticeable boost. However, in contrast to the significant achievements concerning English, the research progress in Chinese language is quite limited. The main reason includes the following two aspects: First, the scarcity of linguistic resource serious</context>
</contexts>
<marker>Morante, Liekens, Daelemans, 2008</marker>
<rawString>Roser Morante, Anthony Liekens, and Walter Daelemans. 2008. Learning the scope of negation in biomedical texts. In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Iatural Language Processing (EMILP’08), 715-724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Caroline Sporleder</author>
</authors>
<title>Modality and negation: an introduction to the special issue.</title>
<date>2012</date>
<journal>Comput. Linguist.</journal>
<volume>38</volume>
<pages>223--260</pages>
<contexts>
<context position="1810" citStr="Morante and Sporleder, 2012" startWordPosition="253" endWordPosition="256">yntactic structure-based framework which obtained significant improvement over the stateof-the-art on negation and speculation identification in Chinese language. 1 Introduction Negation and speculation are ubiquitous phenomena in natural language. While negation is a grammatical category which comprises various kinds of devices to reverse the truth value of a proposition, speculation is a grammatical category which expresses the attitude of a speaker towards a statement in terms of degree of certainty, * Corresponding author reliability, subjectivity, sources of information, and perspective (Morante and Sporleder, 2012). Current studies on negation and speculation identification mainly focus on two tasks: 1) cue detection, which aims to detect the signal of a negative or speculative expression, and 2) scope resolution, which aims to determine the linguistic coverage of a cue in sentence, in distinguishing unreliable or uncertain information from facts. For example, (E1) and (E2) include a negative cue and a speculative cue respectively, both denoted in boldface with their linguistic scopes denoted in square brackets (adopted hereinafter). In sentence (E1), the negative cue “不(not)” triggers the scope of “不会追</context>
</contexts>
<marker>Morante, Sporleder, 2012</marker>
<rawString>Roser Morante and Caroline Sporleder. 2012. Modality and negation: an introduction to the special issue. Comput. Linguist. 38, 2, 223-260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.</journal>
<volume>29</volume>
<contexts>
<context position="19643" citStr="Och and Ney, 2003" startWordPosition="3077" endWordPosition="3080"> of training data. Hence, we propose a cross-lingual cue expansion strategy. In the approach, we take use of the top 5 Chinese cues in training corpus as our “anchor set”. For each cue, we search its automatically aligned English words from a Chinese-English parallel corpus to construct an English word cluster. The parallel corpus consisting of 100,000 sentence pairs is built by using Liu&apos;s approach (Liu et al., 2014), which combines translation model with language model to select high-quality translation pairs from 16 million sentence pairs. The word alignment was obtained by running Giza++ (Och and Ney, 2003). In each cluster, we record the frequency of each unique English word. Considering the word alignment errors in cross-lingual clusters, we filter the clusters by word alignment probability which is formulated as below: PA =aP(wE |wC) +(1-a)P(wC |wE) =a P(wE,wC)+(1-a)P(wE,wC) P(wC) P(wE) (wE ,wC) +(1-a) align(wE,wC) (1) align(wEi,wC) Eialign(wCi,wE) where P(wE |wC) is the translation probability of English word wE conditioned on Chinese word wC, reversely, while P(wC |wE) is the translation probability of Chinese word wC conditioned on English word wE. align(wm,wn) is the number of alignments </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist. 29, 1, 19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: sentiment analysis using subjectivity.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;04),</booktitle>
<pages>271--278</pages>
<contexts>
<context position="9628" citStr="Pang and Lee (2004)" startWordPosition="1447" endWordPosition="1450">pril, 2013. There are 22.3% and 40.2% sentences in the Financial Article sub-corpus containing negation and speculation respectively. Many researches have investigated the role of negation in sentiment analysis task, as an important linguistic qualifier which leads to a change in polarity. For example, Councill et al. (2010) investigated the problem of determining the polarity of sentiment in movie reviews when negation words occur in the sentences. On the other hand, speculation is a linguistic expression that tends to correlate with subjectivity which is also crucial for sentiment analysis. Pang and Lee (2004) showed that subjectivity detection in the review domain helps to improve polarity classification. Therefore, the Product Review subcorpus consists of 821 comments of hotel service from the website Ctrip.com. 3.2 Annotation Guidelines The guidelines of our CNeSp corpus have partly referred to the existing Bioscope corpus guidelines (BioScope, 2008) in order to fit the needs of the Chinese language. In annotation process, negative or speculative cues and their linguistic scopes in sentence are annotated. There are several general principles below: (G1) Cue is contained in its scope. (G2) The mi</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: sentiment analysis using subjectivity. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL&apos;04), 271-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Lucy Vanderwende</author>
<author>Arul Menezes</author>
</authors>
<title>Effectively using syntax for recognizing false entailment.</title>
<date>2006</date>
<booktitle>In Proceedings of the Main Conference on Human Language Technology Conference of the Iorth American Chapter of the Association of Computational Linguistics (HLTIAACL’06),</booktitle>
<pages>33--40</pages>
<contexts>
<context position="3884" citStr="Snow et al., 2006" startWordPosition="560" endWordPosition="563">tual information. The treatment of negation and speculation in computational linguistics has been shown to be 656 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 656–665, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics useful for biomedical text processing (Morante et al., 2008; Chowdhury and Lavelli, 2013), information retrieval (Averbuch, 2004), sentiment analysis (Councill et al., 2010; Zhu et al., 2014), recognizing textual entailment (Snow et al., 2006), machine translation (Baker et al., 2010; Wetzel and Bond, 2012), and so forth. The research on negation and speculation identification in English has received a noticeable boost. However, in contrast to the significant achievements concerning English, the research progress in Chinese language is quite limited. The main reason includes the following two aspects: First, the scarcity of linguistic resource seriously limits the advance of related research. To the best of our knowledge, there are no publicly available standard Chinese corpus of reasonable size annotated with negation and speculat</context>
</contexts>
<marker>Snow, Vanderwende, Menezes, 2006</marker>
<rawString>Rion Snow, Lucy Vanderwende, and Arul Menezes. 2006. Effectively using syntax for recognizing false entailment. In Proceedings of the Main Conference on Human Language Technology Conference of the Iorth American Chapter of the Association of Computational Linguistics (HLTIAACL’06), 33-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
</authors>
<title>György Szarvas, Richárd Farkas, György Móra and János Csirik.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<marker>Vincze, 2008</marker>
<rawString>Veronika Vincze, György Szarvas, Richárd Farkas, György Móra and János Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominikus Wetzel</author>
<author>Francis Bond</author>
</authors>
<title>Enriching parallel corpora for statistical machine translation with semantic negation rephrasing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<contexts>
<context position="3949" citStr="Wetzel and Bond, 2012" startWordPosition="570" endWordPosition="573">n computational linguistics has been shown to be 656 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 656–665, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics useful for biomedical text processing (Morante et al., 2008; Chowdhury and Lavelli, 2013), information retrieval (Averbuch, 2004), sentiment analysis (Councill et al., 2010; Zhu et al., 2014), recognizing textual entailment (Snow et al., 2006), machine translation (Baker et al., 2010; Wetzel and Bond, 2012), and so forth. The research on negation and speculation identification in English has received a noticeable boost. However, in contrast to the significant achievements concerning English, the research progress in Chinese language is quite limited. The main reason includes the following two aspects: First, the scarcity of linguistic resource seriously limits the advance of related research. To the best of our knowledge, there are no publicly available standard Chinese corpus of reasonable size annotated with negation and speculation. Second, this may be attributed to the limitations of Chinese</context>
</contexts>
<marker>Wetzel, Bond, 2012</marker>
<rawString>Dominikus Wetzel, and Francis Bond. 2012. Enriching parallel corpora for statistical machine translation with semantic negation rephrasing. In Proceedings of the 6th Workshop on Syntax, Semantics and Structure in Statistical Translation, 20-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaoming Zhu</author>
<author>Junhui Li</author>
<author>Hongling Wang</author>
<author>Guodong Zhou</author>
</authors>
<title>A Unified Framework for Scope Learning via Simplified Shallow Semantic Parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Iatural Language Processing (EMILP’10),</booktitle>
<pages>714--724</pages>
<contexts>
<context position="24562" citStr="Zhu et al. (2010)" startWordPosition="3869" endWordPosition="3872">tures between cue and scope candidate we defined (R4). Figure 2. Positional features. Some features proposed above may not be effective in classification. Therefore, we adopt a greedy feature se-lection algorithm as described in (Jiang and Ng, 2006) to pick up positive features incrementally according to their contribu661 tions on the development data. Additionally, a cue should have one continuous block as its scope, but the scope identifier may result in discontinuous scope due to independent candidate in classification. For this reason, we employ a post-processing algorithm as described in Zhu et al. (2010) to identify the boundaries. 5 Experimentation In this section, we evaluate our feature-based sequence labeling model and cross-lingual cue expansion strategy on cue detection, and report the experimental results to justify the appropriateness of our syntactic structure-based framework on scope resolution in Chinese language. The performance is measured by Precision (P), Recall (R), and F1-score (F). In addition, for scope resolution, we also report the accuracy in PCS (Percentage of Correct Scopes), within which a scope is fully correct if the output of scope resolution system and the correct</context>
</contexts>
<marker>Zhu, Li, Wang, Zhou, 2010</marker>
<rawString>Qiaoming Zhu, Junhui Li, Hongling Wang, and Guodong Zhou. 2010. A Unified Framework for Scope Learning via Simplified Shallow Semantic Parsing. In Proceedings of the 2010 Conference on Empirical Methods in Iatural Language Processing (EMILP’10), 714-724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodan Zhu</author>
<author>Hongyu Guo</author>
<author>Saif Mohammad</author>
<author>Svetlana Kiritchenko</author>
</authors>
<title>An empirical study on the effect of negation words on sentiment.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL’14),</booktitle>
<pages>304--313</pages>
<contexts>
<context position="3832" citStr="Zhu et al., 2014" startWordPosition="553" endWordPosition="556">ch need to discriminate between factual and non-factual information. The treatment of negation and speculation in computational linguistics has been shown to be 656 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 656–665, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics useful for biomedical text processing (Morante et al., 2008; Chowdhury and Lavelli, 2013), information retrieval (Averbuch, 2004), sentiment analysis (Councill et al., 2010; Zhu et al., 2014), recognizing textual entailment (Snow et al., 2006), machine translation (Baker et al., 2010; Wetzel and Bond, 2012), and so forth. The research on negation and speculation identification in English has received a noticeable boost. However, in contrast to the significant achievements concerning English, the research progress in Chinese language is quite limited. The main reason includes the following two aspects: First, the scarcity of linguistic resource seriously limits the advance of related research. To the best of our knowledge, there are no publicly available standard Chinese corpus of </context>
</contexts>
<marker>Zhu, Guo, Mohammad, Kiritchenko, 2014</marker>
<rawString>Xiaodan Zhu, Hongyu Guo, Saif Mohammad, and Svetlana Kiritchenko. 2014. An empirical study on the effect of negation words on sentiment. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL’14), 304-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bowei Zou</author>
<author>Guodong Zhou</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Tree kernel-based negation and speculation scope detection with structured syntactic parse features.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Iatural Language Processing (EMILP’13),</booktitle>
<pages>968--976</pages>
<contexts>
<context position="6942" citStr="Zou et al. (2013)" startWordPosition="1036" endWordPosition="1039">oaches are most popular. In the feature-based framework, Agarwal and Yu (2010) employed a conditional random fields (CRFs) model to detect speculative cues and their scopes on the BioScope corpus. The CRFsbased model achieved an F1-meature of 88% in detecting speculative cues. We train this model on our corpus as the baseline system for cue detection. Our work is different from theirs in that we employ a new feature (morpheme feature) which is particularly appropriate for Chinese. Besides, kernel-based approaches exploit the structure of the tree that connects cue and its corresponding scope. Zou et al. (2013) developed a tree kernel-based system to resolve the scope of negation and speculation, which captures the structured information in syntactic parsing trees. To the best of our knowledge, this system is the best English scope resolution system. For this reason, we train this system on our corpus as the baseline system for scope resolution. Compared with a fair amount of works on English negation and speculation identification, unfortunately, few works has been published on Chinese. Ji et al. (2010) developed a system to detect speculation in Chinese news texts. However, only the speculative se</context>
<context position="31653" citStr="Zou et al., (2013)" startWordPosition="5006" endWordPosition="5009">erformance of scope resolution with automatic cue detection. Table 7 lists the performance of scope resolution by using automatic cues. It shows that automatic cue detection lowers the performance by 3.08, 6.83, and 8.76 in PCS for the three subcorpora, respectively; while it lowers the performance by 5.80, 8.31 and 13.11 in PCS for speculation scope resolution on the three sub-corpora, respectively (refer to Table 6). The main reason of performance lost is the error propagation from the automatic cue detection. We employ a start-of-the-art chunking-based scope resolution system (described in Zou et al., (2013)) as a baseline, in which every word in sentence has been labelled as being the element of the scope or not. Table 8 compares our syntactic structure-based framework with the chunkingbased framework on scope resolution. Note that all the performances are achieved on Financial Article sub-corpus by using golden cues. The results in Table 8 shows that our scope resolution system outperforms the chunking ones both on negation and speculation, improving 8.75 and 7.44 in PCS, respectively. Type System PCS Negation Chunking-based 47.32 Ours 56.07 Speculation Chunking-based 42.20 Ours 49.64 Table 8. </context>
</contexts>
<marker>Zou, Zhou, Zhu, 2013</marker>
<rawString>Bowei Zou, Guodong Zhou, and Qiaoming Zhu. 2013. Tree kernel-based negation and speculation scope detection with structured syntactic parse features. In Proceedings of the 2013 Conference on Empirical Methods in Iatural Language Processing (EMILP’13), 968-976.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>