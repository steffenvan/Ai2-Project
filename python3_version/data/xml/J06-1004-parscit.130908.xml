<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9991915">
Finite-State Registered Automata
for Non-Concatenative Morphology
</title>
<author confidence="0.998953">
Yael Cohen-Sygal* Shuly Wintner†
</author>
<affiliation confidence="0.998435">
University of Haifa University of Haifa
</affiliation>
<bodyText confidence="0.991632875">
We introduce finite-state registered automata (FSRAs), a new computational device within the
framework of finite-state technology, specifically tailored for implementing non-concatenative
morphological processes. This model extends and augments existing finite-state techniques,
which are presently not optimized for describing this kind of phenomena. We first define the
model and discuss its mathematical and computational properties. Then, we provide an extended
regular language whose expressions denote FSRAs. Finally, we exemplify the utility of the model
by providing several examples of complex morphological and phonological phenomena, which are
elegantly implemented with FSRAs.
</bodyText>
<sectionHeader confidence="0.994711" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9999502">
Finite-state (FS) technology has been considered adequate for describing the morpho-
logical processes of the world’s languages since the pioneering works of Koskenniemi
(1983) and Kaplan and Kay (1994). Several toolboxes provide extended regular expres-
sion description languages and compilers of the expressions to finite-state automata
(FSAs) and transducers (FSTs) (Karttunen et al. 1996; Mohri 1996; van Noord and
Gerdemann 2001a). While FS approaches to most natural languages have generally been
very successful, it is widely recognized that they are less suitable for non-concatenative
phenomena; in particular, FS techniques are assumed not to be able to efficiently account
for the non-concatenative word formation processes that Semitic languages exhibit
(Lavie et al. 1988).
While much of the inflectional morphology of Semitic languages can be rather
straightforwardly described using concatenation as the primary operation, the main
word formation process in such languages is inherently non-concatenative. The stan-
dard account describes words in Semitic languages as combinations of two morphemes:
a root and a pattern.1 The root consists of consonants only, by default three (although
longer roots are known). The pattern is a combination of vowels and, possibly, con-
sonants too, with “slots” into which the root consonants can be inserted. Words are
created by interdigitating roots into patterns: The first consonant of the root is inserted
into the first consonantal slot of the pattern, the second root consonant fills the second
slot, and the third fills the last slot. After the root combines with the pattern, some
</bodyText>
<affiliation confidence="0.7285685">
* Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: yaelc@cs.haifa.ac.il.
† Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly@cs.haifa.ac.il.
</affiliation>
<footnote confidence="0.962479">
1 An additional morpheme, vocalization, is used to abstract the pattern further; for the present purposes,
this distinction is irrelevant.
</footnote>
<note confidence="0.715748">
Submission received: 17 August 2004; revised submission received: 15 June 2005; accepted for publication: 26
September 2005.
© 2006 Association for Computational Linguistics
Computational Linguistics Volume 32, Number 1
</note>
<figureCaption confidence="0.976827">
Figure 1
</figureCaption>
<bodyText confidence="0.979075285714286">
Naive FSA with duplicated paths.
morpho-phonological alternations take place, which may be non-trivial but are mostly
concatenative.
The major problem that we tackle in this work is medium-distance dependencies,
whereby some elements that are related to each other in some deep-level representation
(e.g., the consonants of the root) are separated on the surface. While these phenomena
do not lie outside the descriptive power of FS systems, naively implementing them in
existing finite-state calculi is either impossible or, at best, results in large networks that
are inefficient to process, as the following examples demonstrate.
Example 1
We begin with a simplified problem, namely accounting for circumfixes. Consider three
Hebrew patterns: ha❑❑a❑a, hit❑a❑a❑ut, and mi❑❑a❑, where the empty boxes indi-
cate the slots in the patterns into which the consonants of the roots are inserted. Hebrew
orthography2 dictates that these patterns be written h❑❑❑a, ht❑❑❑ut, and m❑❑❑, re-
spectively, i.e., the consonants are inserted into the ‘❑’ slots as one unit (i.e., the patterns
can be viewed as circumfixes). An automaton that accepts all the possible combinations
of three-consonant stems and these three circumfixes is illustrated in Figure 1.3 Given r
stems and p circumfixes, the number of its states is (2r + 2)p + 2, i.e., increases linearly
with the number of stems and circumfixes. The number of arcs in this automaton is
3rp + 2p, i.e, also O(rp). Evidently, the three basic different paths that result from the
three circumfixes have the same body, which encodes the stems. An attempt to avoid
the duplication of paths is represented by the automaton of Figure 2, which accepts the
language denoted by the regular expression (ht + h + m)(root)(ut + a + c). The number
of states here is 2r + 4, i.e., is independent of the number of circumfixes. The number
of arcs is (3r + 2p), that is, O(r + p), and thus, the complexity of the number of arcs is
also reduced. Obviously, however, such an automaton over-generates by accepting also
invalid words such as m❑❑❑ut. In other words, it ignores the dependencies which hold
between prefixes and suffixes of the same circumfix. Since finite-state devices have no
</bodyText>
<footnote confidence="0.98421">
2 Many of the vowels are not explicitly depicted in the Hebrew script.
3 This is an over-simplified example; in practice, the process of combining roots with patterns is highly
idiosyncratic, like other derivational morphological processes.
</footnote>
<page confidence="0.987529">
50
</page>
<note confidence="0.908179">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<figureCaption confidence="0.957604">
Figure 2
</figureCaption>
<bodyText confidence="0.933138733333333">
Over-generating FSA.
memory, save for the states, there is no simple and space-efficient way to account for
such dependencies.
Example 2
Consider now a representation of Hebrew where all vowels are explicit, e.g., the pattern
hit❑a❑e❑. Consider also the roots r.g.z, b.$.l, and g.b.r. The consonants of a given root
are inserted into the ‘El’ slots to obtain bases such as hitragez, hitba$el, and hitgaber. The
finite state automaton of Figure 3 is the minimized automaton accepting the language;
it has fifteen states. If the number of three letter roots is r, then a general automaton
accepting the combinations of the roots with this pattern will have 4r + 3 states and 5r +
1 arcs. Notice the duplicated arcs which stem from copying the pattern in the different
paths.
Example 3
Another non-concatenative process is reduplication: The process in which a morpheme
or part of it is duplicated. Full reduplication is used as a pluralization process in Malay
and Indonesian; partial reduplication is found in Chamorro to indicate intensivity. It
can also be found in Hebrew as a diminutive formation of nouns and adjectives:
keleb klablab $apan $panpan zaqan zqanqan $axor $xarxar
dog puppy rabbit bunny beard goatee black dark
qatan qtantan
little tiny
Let E be a finite alphabet. The language L = {ww  |w E E∗} is known to be
trans-regular, therefore no finite-state automaton accepts it. However, the language
Ln = {ww  |w E E∗, |w |= n} for some constant n is regular. Recognizing Ln is a finite
approximation of the general problem of recognizing L. The length of the words in
natural languages can in most cases be bounded by some n E N, hence the amount
of reduplication in natural languages is practically limited. Therefore, the descriptive
power of Ln is sufficient for the amount of reduplication in natural languages (by
Figure 3
FSA for the pattern hit❑a❑e❑.
</bodyText>
<page confidence="0.995557">
51
</page>
<note confidence="0.804832">
Computational Linguistics Volume 32, Number 1
</note>
<bodyText confidence="0.989758482758621">
constructing Ln for a small number of different ns). An automaton that accepts Ln can
be constructed by listing a path for each accepted string (since E and n are finite, the
number of words in Ln is finite). The main drawback of such an automaton is the
growth in its size as |E |and n increase: The number of strings in Ln is |E|n. Thus, finite-
state techniques can account for limited reduplication, but the resulting networks are
space-inefficient.
As a final, non-linguistic, motivating example, consider the problem of n-bit incre-
mentation, introduced by Kornai (1996).
Example 4
The goal of this example is to construct a transducer over E = 10, 1} whose input is a
32 bit binary number and whose output is the result of adding 1 to the input. A
transducer that performs addition by 1 on binary numbers has only 5 states and 12 arcs,4
but this transducer is neither sequential nor sequentiable. The problem is that since the
input is scanned left to right but the carry moves right to left, the output of the first bit
has to be delayed, possibly even until the last input bit is scanned. Thus, for an n-bit
binary incrementor, 2n disjunctions have to be considered, and therefore a minimized
transducer has to assign a separate state to each combination of bits, resulting in 2n
states and a similar number of transitions.
In this work we propose a novel FS model which facilitates the expression of
medium-distance dependencies such as interdigitation and reduplication in an efficient
way. Our main motivation is theoretical, i.e., reducing the complexity of the number
of states and arcs in the networks; we show that these theoretical contributions result
in practical improvements. In Section 3 we define the model formally, show that it is
equivalent to FSAs and define many closure properties directly.5 We then (Section 4)
define a regular expression language for denoting FSRAs. In Section 5 we provide dedi-
cated regular expression operators for some non-concatenative phenomena and exem-
plify the usefulness of the model by efficiently accounting for the motivating examples.
In Section 6 we extend FSRAs to transducers. The model is evaluated through an actual
implementation in Section 7. We conclude with suggestions for future research.
</bodyText>
<sectionHeader confidence="0.99988" genericHeader="categories and subject descriptors">
2. Related Work
</sectionHeader>
<bodyText confidence="0.9999033">
In spite of the common view that FS technology is in general inadequate for describing
non-concatenative processes, several works address the above-mentioned problems in
various ways. We summarize existing approaches in this section.
Several works examine the applicability of traditional two-level systems for imple-
menting non-concatenative morphology. Two-Level Morphology was used by Kataja
and Koskenniemi (1988) to create a rule system for phonological and morphophonolog-
ical alternations in Akkadian, accounting for word inflection and regular verbal deriva-
tion. As this solution effectively defines lexical representations of word-forms, its main
disadvantage is that the final network is the naive one, suffering from the space com-
plexity problems discussed above. Lavie et al. (1988) examine the applicability of Two-
</bodyText>
<footnote confidence="0.98684625">
4 A complete explanation of the construction can be found in http://www.xrce.xerox.com/competencies/
content-analysis/fsCompiler/fsexamples.html#Add1.
5 Many of the formal proofs and constructions, especially the ones that are similar to the case of standard
FSAs, are suppressed; see Cohen-Sygal (2004) for the complete proofs and constructions.
</footnote>
<page confidence="0.992994">
52
</page>
<note confidence="0.894755">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<bodyText confidence="0.999775571428571">
Level Morphology to the description of Hebrew Morphology, and in particular to verb
inflection. Their lexicon consists of three parts: verb primary bases (the past tense, third
person, singular, masculine), verb prefixes, and verb suffixes. They attempt to describe
Hebrew verb inflection as a concatenation of prefix+base+suffix, implementable by the
Two-Level model. However, they conclude that “The Two-Level rules are not the natural
way to describe ... verb inflection process. The only alternative choice ... is to keep all
bases ... it seems wasteful to save all the secondary bases of verbs of the same pattern.”
Other works deal with non-concatenative morphology by extending ordinary FSAs
without extending their expressivity. The traditional two-level model of Koskenniemi
(1983) is expanded into n-tape automata by Kiraz (2000), following the insight of Kay
(1987) and Kataja and Koskenniemi (1988). The idea is to use more than two levels of
expression: The surface level employs one representation, but the lexical form employs
multiple representations (e.g., root, pattern) and therefore can be divided into different
levels, one for each representation. Elements that are separated on the surface (such as
the root’s consonants) are adjacent on a particular lexical level. For example, to describe
circumfixation using this model, a 4-tape automaton of the form (surface, PR pattern,
circumfix, stem) is constructed, so that each word is represented by 4 levels. The surface
level represents the final form of the word. The PR pattern is the pattern in which
the stem and the circumfix are combined (P represents the circumfix’s position and
R the root letter’s position), e.g., PRRRP. The circumfix and stem levels represent the
circumfix and the stem respectively.
For example, combining the Hebrew stem pqd with the circumfix ht-ut will have
the 4-level representation shown in Figure 4. Notice that the symbols representing the
circumfix in the PR pattern level (i.e., the occurrences of the symbol ‘P’), the circumfix
symbols in the circumfix level, and the circumfix symbols in the surface level are located
in correlating places in the different levels. The same holds for the stem symbols. In
this way, it is clear which symbols of the surface word belong to the circumfix, which
belong to the stem, and how they combine together to create the final form of the word.
The 4-tape automaton of Figure 5 accepts all the combinations created by circumfixing
roots with the three circumfixes of Example 1. Each arc is attributed with a quadruplet,
consisting of four correlating symbols in the four levels. Notice that as in FSAs, the paths
encoding the roots are duplicated for each circumfix, so that this automaton is as space-
inefficient as ordinary FSAs. Kiraz (2000) does not discuss the space complexity of this
model, but the number of states still seems to increase with the number of roots and
patterns. Moreover, the n-tape model requires specification of dependencies between
symbols in different levels, which may be non-trivial.
Walther (2000a) suggests a solution for describing natural language reduplication
using finite-state methods. The idea is to enrich finite-state automata with three new
operations: repeat, skip, and self loops. Repeat arcs allow moving backwards within a
string and thus repeat a part of it (to model reduplication). Skip arcs allow moving
forwards in a string while suppressing the spell out of some of its letters; self loop arcs
model infixation. In Walther (2000b), the above technique is used to describe Temiar
</bodyText>
<figureCaption confidence="0.449315">
Figure 4
</figureCaption>
<footnote confidence="0.924432">
4-tape representation for the Hebrew word htpqdut.
</footnote>
<page confidence="0.997307">
53
</page>
<figure confidence="0.859175">
Computational Linguistics Volume 32, Number 1
</figure>
<figureCaption confidence="0.907394">
Figure 5
</figureCaption>
<bodyText confidence="0.987215176470588">
4-tape automaton for circumfixation example.
reduplication, but no complexity analysis of the model is given. Moreover, this tech-
nique does not seem to be able to describe interdigitation.
Beesley and Karttunen (2000) describe a technique, called compile-replace, for
constructing FSTs, which involves reapplying the regular-expression compiler to its
own output. The compile-replace algorithm facilitates a compact definition of non-
concatenative morphological processes, but since such expressions compile to the naive
networks, no space is saved. Furthermore, this is a compile-time mechanism rather than
a theoretical and mathematically founded solution.
Other works extend the FS model by enabling some sort of context-sensitivity. Blank
(1985, 1989) presents a model, called Register Vector Grammar, introducing context-
sensitivity by representing the states and transitions of finite-state automata as ternary-
valued vectors, which need not be fully specified. No formal properties of this model are
discussed. In a similar vein, Kornai (1996) introduces vectorized finite-state automata,
where both the states and the transitions are represented by vectors of elements of
a partially ordered set. The vectors are manipulated by operations of unification and
overwriting. The vectors need not be fully determined, as some of the elements can
be unknown (free). In this way information can be moved through the transitions by
the overwriting operation and traversing these transitions can be sanctioned through
the unification operation. As one of the examples of the advantages of this model,
Kornai (1996) shows it can efficiently solve the problem of 32-bit binary incrementor
(Example 4). Using vectorized finite-state automata, a 32-bit incrementor is constructed
where first, using overwriting, the input is scanned and stored in the vectors, and
then, using unification, the result is calculated where the carry can be computed from
right to left. We return to this example in example 6, where we show how our own
model can solve it efficiently. The formalism presented by Kornai (1996) allows a
significant reduction in the network size, but its main disadvantage lies in the fact
that it significantly deviates from the standard methodology of developing finite-state
devices, and integration of vectorized automata with standard ones remains a challenge.
Moreover, it is unclear how, for a given problem, the corresponding network should be
constructed: Programming with vectorized automata seems to be unnatural, and no
regular expression language is provided for them.
A more general approach to the design of finite-state machines is introduced by
Mohri, Pereira, and Riley (2000). They introduce an object-oriented library for manipu-
</bodyText>
<page confidence="0.995054">
54
</page>
<subsectionHeader confidence="0.386117">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</subsectionHeader>
<bodyText confidence="0.99996178">
lating finite-state devices that is based on the algebraic concepts of rational power series
and semirings. This approach facilitates a high degree of generality as the algorithms
are defined for the general algebraic notions, which can then be specialized according
to the needs of the user. They exemplify the usefulness of this library by showing how to
specialize it for the manipulation of weighted automata and transducers. Our work can
be seen as another specialization of this general approach, tailored for ideally dealing
with our motivating examples.
Several works introduce the notion of registers, whether for solving similar prob-
lems or motivated by different considerations. Krauwer and des Tombe (1981) refer
to transducers with a finite number of registers when comparing transducers and
context free grammars with respect to their capabilities to describe languages. They
sketch a proof showing that such transducers are equivalent to ordinary finite-state
transducers. However, they never formally define the model and do not discuss its
ability to efficiently implement non-concatenative natural languages phenomena. More-
over, they do not show how the closure properties can be implemented directly on
these registered transducers, and do not provide any regular language denoting such
transducers.
Motivated by different considerations, Kaminski and Francez (1994) present a com-
putational model which extends finite state automata to the case of infinite alphabets.
This model is limited to recognizing only regular languages over infinite alphabets
while maintaining closure under Kleene star and boolean operations, with the excep-
tion of closure under complementation. The familiar automaton is augmented with
registers, used to store alphabet symbols, whose number is fixed for each automa-
ton and can vary from one automaton to another. The model is designed to deal
with infinite alphabets, and therefore it cannot distinguish between different symbols;
it can identify different patterns but cannot distinguish between different symbols
in the pattern as is often needed in natural languages. Our solution is reminiscent
of Kaminski and Francez (1994) in the sense that it augments finite-state automata
with finite memory (registers) in a restricted way, but we avoid the above-mentioned
problem. In addition, our model supports a register alphabet that differs from the
language alphabet, allowing the information stored in the registers to be more mean-
ingful. Moreover, our transition relation is a more simplified extension of the stan-
dard one in FSAs, rendering our model a conservative extension of standard FSAs
and allowing simple integration of existing networks with networks based on our
model.
Finally, Beesley (1998) directly addresses medium-distance dependencies between
separated morphemes in words. He proposes a method, called flag diacritics, which adds
features to symbols in regular expressions to enforce dependencies between separated
parts of a string. The dependencies are forced by different kinds of unification actions.
In this way, a small amount of finite memory is added, keeping the total size of the
network relatively small. Unfortunately, this method is not formally defined, nor are
its mathematical and computational properties proved. Furthermore, flag diacritics are
manipulated at the level of the extended regular expressions, although it is clear that
they are compiled into additional memory and operators in the networks themselves.
The presentations of Beesley (1998) and Beesley and Karttunen (2003) do not explicate
the implementation of such operators and do not provide an analysis of their com-
plexity. Our approach is similar in spirit, but we provide a complete mathematical and
computational analysis of such extended networks, including a proof that the model
is indeed regular and constructions of the main closure properties. We also provide
dedicated regular expression operations for non-concatenative processes and show
</bodyText>
<page confidence="0.994299">
55
</page>
<note confidence="0.29871">
Computational Linguistics Volume 32, Number 1
</note>
<bodyText confidence="0.9722085">
how they are compiled into extended networks, thereby accounting for the motivating
examples.
</bodyText>
<sectionHeader confidence="0.682455" genericHeader="general terms">
3. Finite-state Registered Automata
</sectionHeader>
<bodyText confidence="0.999952428571429">
We define a new model, finite-state registered automata (FSRA), aimed at facilitating
the expression of various non-concatenative morphological phenomena in an efficient
way. The model augments finite-state automata with finite memory (registers) in a
restricted way that saves space but does not add expressivity. The number of registers
is finite, usually small, and eliminates the need to duplicate paths as it enables the
automaton to “remember” a finite number of symbols. In addition to being associated
with an alphabet symbol, each arc is also associated with an action on the registers.
There are two kinds of actions, read and write. The read action, denoted R, allows
traversing an arc only if a designated register contains a specific symbol. The write
action, denoted W, allows traversing an arc while writing a specific symbol into a
designated register. In this section we define FSRAs and show that they are equivalent
to standard FSAs (Section 3.1). We then directly define several closure operations over
FSRAs (Section 3.2) and provide some optimizations in Section 3.3. We conclude this
section with a discussion of minimization (Section 3.4).
</bodyText>
<subsectionHeader confidence="0.934173">
3.1 Definitions and Examples
Definition
</subsectionHeader>
<bodyText confidence="0.978906">
A finite-state registered automaton (FSRA) is a tuple A = (Q, q0, E, IF, n, b, F), where:
</bodyText>
<listItem confidence="0.912982">
• Q is a finite set of states.
• q0 E Q is the initial state.
• E is a finite alphabet (the language alphabet).
• n E N (indicating the number of registers).
•
IF is a finite alphabet including the symbol ‘#’ (the registers alphabet).
We use meta-variables ui, vi to range over IF and u, v to range over IFn.
• The initial content of the registers is #n, meaning that the initial value
of all the registers is ‘empty’.
• b C Q x E U {c} x {R, W} x {0, 1, 2,. . . , n − 1} x IF x Q is the transition
relation. The intuitive meaning of b is as follows:
– (s, 6, R, i,-y, t) E b where i &gt; 0 implies that if A is in state s, the input
</listItem>
<bodyText confidence="0.665376666666667">
symbol is 6, and the content of the i-th register is -y, then A may
enter state t.
– (s, 6, W, i, -y, t) E b where i &gt; 0 implies that if A is in state s and the
input symbol is 6, then the content of the i-th register is changed
into -y (overwriting whatever was there before) and A may enter
state t.
</bodyText>
<listItem confidence="0.999658">
– (s, 6, R, 0, #, t) implies that if A is in state s and the input symbol is 6,
then A may enter state t. Notice that the content of register number 0
is always #. We use the shorthand notation (s, 6, t) for such transitions.
• F C Q is the set of final states.
</listItem>
<page confidence="0.993807">
56
</page>
<note confidence="0.586914">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<sectionHeader confidence="0.424046" genericHeader="keywords">
Definition
</sectionHeader>
<bodyText confidence="0.999619">
A configuration of A is a pair (q, u), where q E Q and u E Γn (q is the current state
and u represents the registers content). The set of all configurations of A is denoted by
Q c. The pair qc0 = (q0, #n) is called the initial configuration, and configurations with the
first component in F are called final configurations. The set of final configurations is
denoted by Fc.
</bodyText>
<subsectionHeader confidence="0.561935">
Definition
</subsectionHeader>
<bodyText confidence="0.999156666666667">
Let u = u0u1 ... un_1 and v = v0v1 ... vn_1. Given a symbol α E E U {c} and an FSRA
A, we say that a configuration (s, u) produces a configuration (t, v), denoted (s, u) �α,A
(t, v), iff either one of the following holds:
</bodyText>
<listItem confidence="0.99984925">
• There exists i, 0 &lt; i &lt; n − 1, and there exists -y E Γ, such that (s, α, R, i, -y, t) E
b and u = v and ui = vi = -y; or
• There exists i, 0 &lt; i &lt; n − 1, and there exists -y E Γ, such that (s, α, W, i,-y, t) E
b and for all k, k E {0, 1, ..., n − 1}, such that k =� i, uk = vk and vi = -y.
</listItem>
<bodyText confidence="0.999793">
Informally, a configuration c1 produces a configuration c2 iff the automaton can
move from c1 to c2 when scanning the input α (or without any input, when α = c) in one
step. If the register operation is R, then the contents of the registers in the two configura-
tions must be equal, and in particular the contents of the designated register in the two
configurations should be the expected symbol (-y). If the register operation is W, then the
contents of the registers in the two configurations is equal except for the designated reg-
ister, whose contents in the produced configuration should be the expected symbol (-y).
</bodyText>
<sectionHeader confidence="0.446883" genericHeader="introduction">
Definition
</sectionHeader>
<bodyText confidence="0.967329555555556">
A run of A on w is a sequence of configurations c0,..., cr such that c0 = qc0, cr E Fc, and
for every k, 1 &lt; k &lt; r, ck_1 �-αk,A ck and w = α1...αr. An FSRA A accepts a word w if
there exists a run of A on w. Notice that |w |may be less than r since some of the αi may
be c. The language recognized by an FSRA A, denoted by L(A), is the set of words over
E∗ accepted by A.
Example 5
Consider again example 1. We construct an efficient FSRA accepting all and only the
possible combinations of stems and circumfixes. If the number of stems is r, we define
an FSRA A = (Q, q0, E, Γ, 2, b, {qf}) where:
</bodyText>
<listItem confidence="0.999308">
• Q = {q0, q1,... , q2r+2, qf }
• E = {a,b,c,...,z,ht,ut}
• Γ = {ht❑❑❑ut,h❑❑❑a,m❑❑❑,#}
• b = {(q0,ht,W,1,ht❑❑❑ut,q1), (q0,h,W,1,h❑❑❑a,q1)}
</listItem>
<equation confidence="0.957194166666667">
U
{(q0, m, W,1, m❑❑❑, q1), (q2r+2, ut, R,1, ht❑❑❑ut, qf )}
U
{(q2r+2, a, R,1, h❑❑❑a, qf ), (q2r+2, c, R,1, m❑❑❑, qf )}
U
{(q1, α1, qi), (qi, α2, qi+1), (qi+1, α3, q2r+2)  |2 &lt; i &lt; 2r and
</equation>
<footnote confidence="0.679487">
α1α2α3 is the i-th stem}.
</footnote>
<page confidence="0.988315">
57
</page>
<note confidence="0.290606">
Computational Linguistics Volume 32, Number 1
</note>
<bodyText confidence="0.976953333333333">
This automaton is shown in Figure 6. The number of its states is 2r + 4 (like the FSA
of Figure 2), that is, O(r), and in particular independent of the number of circumfixes.
The number of arcs is also reduced from O(r × p), where p indicates the number of
circumfixes, to O(r + p).
Example 6
Consider again example 2. The FSRA of Figure 7 also accepts the same language. This
automaton has seven states and will have seven states for any number of roots. The
number of arcs is also reduced to 3r + 3.
Next, we show that finite-state registered automata and standard finite state au-
tomata recognize the same class of languages. Trivially, every finite-state automaton
has an equivalent FSRA: Every FSA is also an FSRA since every transition (s, 6, t) in an
FSRA is a shorthand notation for (s, 6, R, 0, #, t). The other direction is also simple.
Theorem 1
Every FSRA has an equivalent finite-state automaton.
We prove this by constructing an equivalent FSA to a given FSRA. The construction is
based on the fact that in FSRAs the number of registers is finite, as are the sets Γ and
Q, the register alphabet and states, respectively. Hence the number of configurations is
finite. The FSA’s states are the configurations of the FSRA, and the transition function
simulates the ‘produces’ relation. Notice that this relation holds between configurations
depending on E only, similarly to the transition function in an FSA. The constructed
FSA is non-deterministic, with possible c-moves. The formal proof is suppressed.
The number of configurations in A is |Q |× |Γ|n, hence the growth in the number of
states when constructing A&apos; from A might be in the worst case exponential in the num-
ber of registers. In other words, the move from FSAs to FSRAs can yield an exponential
reduction in the size of the network. As we show below, the reduction in the number of
states can be even more dramatic.
The FSRA model defined above allows only one register operation on each tran-
sition. We extend it to allow up to k register operations on each transition, where k
is determined for each automaton separately. The register operations are defined as a
sequence (rather than a set), in order to allow more than one operation on the same
</bodyText>
<figureCaption confidence="0.483473">
Figure 6
</figureCaption>
<bodyText confidence="0.567709">
FSRA for circumfixation.
</bodyText>
<page confidence="0.990627">
58
</page>
<note confidence="0.512132">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<figureCaption confidence="0.998826">
Figure 7
</figureCaption>
<bodyText confidence="0.967492">
FSRA for the pattern hit❑a❑e❑.
register over one transition. This extension allows further reduction of the network size
for some automata as well as other advantages that will be discussed presently.
</bodyText>
<sectionHeader confidence="0.487568" genericHeader="method">
Definition
</sectionHeader>
<bodyText confidence="0.9843575">
An order-k finite-state registered automaton (FSRA-k) is a tuple A = (Q, q0, Σ, Γ, n,
k, b, F), where:
</bodyText>
<listItem confidence="0.9997065">
• Q, q0, Σ, Γ, n, F and the initial content of the registers are as before.
• k E N (indicating the maximum number of register operations allowed
on each arc).
• Let ActionsΓn = 1R, W} x 10, 1, 2,. . . , n − 1} x Γ. Then
</listItem>
<equation confidence="0.97262575">
� �
k
b C Q x Σ U 1e} x U{ (a1,..., aj)  |for all i, 1 &lt; i &lt; j, ai E Actionsn } x Q
j=1
</equation>
<bodyText confidence="0.985308666666667">
is the transition relation. b is extended to allow each transition to be
associated with a series of up to k operations on the registers. Each
operation has the same meaning as before.
The register operations are executed in the order in which they are specified. Thus,
(s, 6, (a1, ..., ai), t) E b where i &lt; k implies that if A is in state s, the input symbol is 6 and
all the register operations a1, ..., ai are executed successfully, then A may enter state t.
</bodyText>
<subsectionHeader confidence="0.268563">
Definition
</subsectionHeader>
<bodyText confidence="0.415264">
Given a E ActionsΓn we define a relation over Γn, denoted u ~a v for u, v E Γn. We define
u ~a v where u = u0 ... un−1 and v = v0 ... vn−1 iff the following holds:
</bodyText>
<listItem confidence="0.97437175">
• if a = (R, i,-y) for some i, 0 &lt; i &lt; n − 1 and for some -y E Γ, then u = v
and ui = vi = -y. — —
• if a = (W, i,-y) for some i, 0 &lt; i &lt; n − 1 and for some -y E Γ, then for all
k E 10, 1, ... , n − 1} such that k =� i, uk = vk and vi = -y.
</listItem>
<bodyText confidence="0.996752333333333">
This relation is extended to series over ActionsΓn . Given a series (a1, ..., ap) E (ActionsΓn )p
where p E N, we define a relation over Γn denoted u I��a1,...,ap) v for u,v E Γn. We
define u I��a1,...,ap� v iff the following holds:
</bodyText>
<listItem confidence="0.9996995">
• if p = 1, then u I�a1 v.
• if p &gt; 1, then there exists w E Γn such that u ~a1 w and w ~(a2,...,ap) v.
</listItem>
<page confidence="0.98536">
59
</page>
<figure confidence="0.41435">
Computational Linguistics Volume 32, Number 1
Definition
</figure>
<bodyText confidence="0.938139333333333">
Let u, v E Γn. Given a symbol α E E U {c} and an FSRA-k A, we say that a configuration
(s, u) produces a configuration (t, v), denoted (s, u) �-α,A (t, v), iff there exist (a1, ... , ap) E
(ActionsΓn )p for some p E N such that (s, α, (a1, ...,ap), t) E b and u I��a1,...,ap) v.
</bodyText>
<subsectionHeader confidence="0.49441">
Definition
</subsectionHeader>
<bodyText confidence="0.99938325">
A run of A on w is a sequence of configurations c0,..., cr such that c0 = qc0, cr E Fc, and for
every l, 1 &lt; l &lt; r, cl−1 �-αl,A cl and w = α1...αr. An FSRA-k A accepts a word w if there
exists a run of A on w. The language recognized by an FSRA-k A, denoted by L(A), is
the set of words over E∗ accepted by A.
</bodyText>
<subsectionHeader confidence="0.539414">
Example 7
</subsectionHeader>
<bodyText confidence="0.999523588235294">
Consider the Arabic nouns qamar (moon), kitaab (book), $ams (sun), and daftar (note-
book). The definite article in Arabic is the prefix al, which is realized as al when pre-
ceding most consonants; however, the ‘l’ of the prefix assimilates to the first consonant
of the noun when the latter is ‘d’, ‘$’, etc. Furthermore, Arabic distinguishes between
definite and indefinite case markers. For example, nominative case is realized as the
suffix u on definite nouns, un on indefinite nouns. Examples of the different forms of
Arabic nouns are:
word nominative definite nominative indefinite
qamar ’alqamaru qamarun
kitaab ’alkitaabu kitaabun
$ams ’a$$amsu $amsun
daftar ’addaftaru daftarun
The FSRA-2 of Figure 8 accepts all the nominative definite and indefinite forms of
the above nouns. In order to account for the assimilation, register 2 stores information
about the actual form of the definite article. Furthermore, to ensure that definite nouns
occur with the correct case ending, register 1 stores information of whether or not a
definite article was seen.
</bodyText>
<figureCaption confidence="0.726376">
Figure 8
</figureCaption>
<bodyText confidence="0.234181">
FSRA-2 for Arabic nominative definite and indefinite nouns.
</bodyText>
<page confidence="0.980453">
60
</page>
<note confidence="0.418662">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<bodyText confidence="0.986895972222222">
FSRA-k and FSRAs recognize the same class of languages. Trivially, every FSRA has
an equivalent FSRA-k: Every FSRA is an FSRA-k for k = 1. The other direction is also
simple.
Theorem 2
Every FSRA-k has an equivalent FSRA.
We show how to construct an equivalent FSRA (or FSRA-1) A&apos; given an FSRA-k A. Each
transition in A is replaced by a series of transitions in A’, each of which performs one
operation on the registers. The first transition in the series deals with the new input
symbol and the rest are c-transitions. This construction requires additional states to
enable the addition of transitions. Each transition in A that is replaced requires the
addition of as many states as the number of register operations performed on this
transition minus one. The formal construction is suppressed.
In what follows, the term FSRA will be used to denote FSRA-k. Simple FRSA will
be referred to as FSRA-1. For the sake of emphasis, however, the term FSRA-k will still
be used in some cases.
FSRA is a very space-efficient finite-state device. The next theorem shows how
ordinary finite-state automata can be encoded efficiently by the FSRA-2 model. Given
a finite-state automaton A, an equivalent FSRA-2 A&apos; is constructed. A&apos; has three states
and two registers (in fact, only one register is used since register number 0 is never
addressed). One state functions as a representative for the final states in A, another
one functions as a representative for the non-final states in A, and the third as an
initial state. The register alphabet consists of the states of A and the symbol ‘#’. Each
arc in A has an equivalent arc in A&apos; with two register operations. The first reads
the current state of A from the register and the second writes the new state into the
register. If the source state of a transition in A is a final state, then the source state of
the corresponding transition in A&apos; will be the final states representative; if the source
state of a transition in A is a non-final state, then the source state of the corresponding
transition in A&apos; will be the non-final states representative. The same holds also for the
target states. The purpose of the initial state is to write the start state of A into the
register. In this way A&apos; simulates the behavior of A. Notice that the number of arcs in A&apos;
equals the number of arcs in A plus one, i.e., while FSRAs can dramatically reduce the
number of states, compared to standard FSAs, a reduction in the number of arcs is not
guaranteed.
Theorem 3
Every finite-state automaton has an equivalent FSRA-2 with three states and two
registers.
</bodyText>
<equation confidence="0.6807145">
Proof 1
{ }
</equation>
<bodyText confidence="0.803881">
Let A = �Q, q0, E, δ, F� be an FSA and let f : Q → qf, qnf be a total function defined
by
</bodyText>
<equation confidence="0.688436">
�f(q) = qf
q ∈ F
qnf q ∈/ F
</equation>
<page confidence="0.985577">
61
</page>
<figure confidence="0.289226">
Computational Linguistics Volume 32, Number 1
Construct an FSRA-2 A&apos; = (Q&apos;, qo, Σ&apos;, Γ&apos;, 2, 2, δ&apos;, F&apos;), where:
</figure>
<listItem confidence="0.9726295">
• Q&apos; = {qo, qnf, qf}. qo is the initial state, qf is the final states representative,
and qnf is the non-final states representative
• Σ&apos; = Σ
• Γ = Q U {#}
• F&apos;={qf}
• δ&apos; = {(f(s),σ,((R,1,s), (W, 1,t)),f(t)) I (s, σ, t) E δ}
U
{(qo, e, ((W,1, q0)),f(q0))}
</listItem>
<bodyText confidence="0.858056">
The formal proof that L(A) = L(A&apos;) is suppressed. ■
</bodyText>
<subsectionHeader confidence="0.996731">
3.2 Closure Properties
</subsectionHeader>
<bodyText confidence="0.998465433333333">
The equivalence shown in the previous section between the classes of languages recog-
nized by finite-state automata and finite-state registered automata immediately implies
that finite-state registered automata maintain the closure properties of regular lan-
guages. Applying the regular operations to finite-state registered automata can be easily
done by converting them first into finite-state automata. However, as shown above,
such a conversion may result in an exponential increase in the size of the automaton,
invalidating the advantages of this model. Therefore, we show how some of these
operations can be defined directly for FSRAs. The constructions are mostly based on
the standard constructions for FSAs with some essential modifications. In what follows,
let A1 = (Q1, q10, Σ1, Γ1, n1, k1, δ1, F1) and A2 = (Q2, q20, Σ2,Γ2, n2, k2, δ2, F2) be finite-state
registered automata.
3.2.1 Union. Two FSRAs, A1, A2, are unioned into an FSRA A in the same way as in FSAs:
by adding a new initial state and connecting it with c-arcs to each of the (former) initial
states of A1, A2. The number of registers and the maximal number of register operations
per arc in A is the maximum of the corresponding values in A1, A2. Notice that in
any specific run of A, the computation goes through just one of the original automata;
therefore the same set of registers can be used for strings of L(A1) or L(A2) as needed.
3.2.2 Concatenation. We show two different constructions of an FSRA A = (Q, q0, Σ,
Γ, n, k, δ, F) to recognize L(A1) · L(A2). Concatenation in finite-state automata is achieved
by leaving only the accepting states of the second automaton as accepting states and
adding an c-arc from every accepting state of the first automaton to the initial state of
the second automaton. Doing just this in FSRA is insufficient because using the same
registers might cause undesired effects: The result might be affected by the content left
in the registers after dealing with a substring from L(A1). Thus, this basic construction
is used with care. The first alternative is to employ more registers in the FSRA. In this
way when dealing with a substring from L(A1) the first n1 registers are used, and when
moving to deal with a substring from L(A2) the next n2 registers are used. The second
alternative is to use additional register operations that clear the content of the registers
before handling the next substring from L(A2). This solution may be less intuitive but
will be instrumental for Kleene closure below.
</bodyText>
<page confidence="0.995114">
62
</page>
<note confidence="0.740633">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<subsubsectionHeader confidence="0.817259">
3.2.3 Kleene Closure. The construction is based on the concatenation construction.
</subsubsectionHeader>
<bodyText confidence="0.990308821428571">
Notice that it cannot be based on the first alternative (adding registers) due to the fact
that the number of iterations in Kleene star is not limited, and therefore the number of
registers needed cannot be bounded. Thus, the second alternative is used: Register op-
erations are added to delete the content of registers. The construction is done by turning
the initial state into a final one (if it is not already final) and connecting each of the final
states to the initial state with an c-arc that is associated with a register operation that
deletes the contents of the registers, leaving them ready to handle the next substring.
3.2.4 Intersection. For the intersection construction, assume that A1 and A2 are c-free
(we show an algorithm for removing c-arcs in Section 3.3.1). The following construction
simulates the runs of A1 and A2 simultaneously. It is based on the basic construction for
intersection of finite-state automata, augmented by a simulation of the registers and
their behavior. Each transition is associated with two sequences of operations on the
registers, one for each automaton. The number of the registers is the sum of the number
of registers in the two automata. In the intersection automaton the first n1 registers
are designated to simulate the behavior of the registers of A1 and the next n2 registers
simulate the behavior of A2. In this way a word can be accepted by the intersection au-
tomaton iff it can be accepted by each one of the automata separately. Notice that register
operations from 61 and 62 cannot be associated with the same register. This guarantees
that no information is lost during the simulation of the two intersected automata.
3.2.5 Complementation. Ordinary FSAs are trivially closed under complementation.
However, given an FSA A whose language is L(A), the minimal FSA recognizing the
complement of L(A) can be exponentially large. More precisely, for any integer n &gt; 2,
there exists a non-deterministic finite-state automaton (NFA) with n states A, such that
any NFA that accepts the complement of L(A) needs at least 2n−2 states (Holzer and
Kutrib 2002). We have no reason to believe that FSRAs will demonstrate a different
behavior; therefore, we maintain that in the worst case, the best approach for com-
plementing an FSRA would be to convert it into FSA and complement the latter. We
therefore do not provide a dedicated construction for this operator.
</bodyText>
<subsectionHeader confidence="0.982477">
3.3 Optimizations
</subsectionHeader>
<bodyText confidence="0.950723">
3.3.1 c-removal. An c-arc in an FSRA is an arc of the form (s, c, (a), t) where a� is used
as a meta-variable over (ActionsΓ )+ (i.e., a� represents a vector of register operations).
n
Notice that this kind of arc might occur in an FSRA by its definition. Given an FSRA
that might contain c-arcs, an equivalent FSRA without c-arcs can be constructed. The
construction is based on the algorithm for c-removal in finite-state automata, but the
register operations that are associated with the c-arc have to be dealt with, and this
requires some care. The resulting FSRA has one more state than the original, and some
additional arcs may be added, too.
The main problem is c-loops; while these can be easily removed in standard FSAs,
here such loops can be associated with register operations which must be accounted for.
The number of possible sequences of register operations along an c-loop is unbounded,
but it is easy to prove that there are only finitely many equivalence classes of such
sequences: Two sequences are in the same equivalence class if and only if they have
the same effect on the state of the machine; since each machine has a finite number of
configurations (see theorem 1), there are only finitely many such equivalence classes.
Therefore, the basic idea behind the construction is as follows: If there exists an
c-path from q1 to q2 with the register operations a� over its arcs, and an arc (q2, 6, (b), q3)
</bodyText>
<page confidence="0.987839">
63
</page>
<figure confidence="0.807076">
Computational Linguistics Volume 32, Number 1
</figure>
<figureCaption confidence="0.973469">
Figure 9
</figureCaption>
<bodyText confidence="0.96484115625">
c removal paradigm.
where 6 =� c, and an c-path from q3 to q4 with the register operations c~ over its arcs,
then the equivalent c-free network will include the arcs (q2, 6, ( b), q3), (q1, 6, (a, b), q3),
(q2, 6, ( b,&apos;c), q4), and (q1, 6, (a, b,&apos;c), q3), with all the c-arcs removed. This is illustrated
in Figure 9. Notice that if q1 and q2 are the same state, then states q2 and q3 will be
connected by two parallel arcs differing in their associated register operations; the same
holds for states q2 and q4. Similarly, when q3 and q4 are the same state.
In addition to the above changes, special care is needed for the case in which the
empty word is accepted by the original automaton. The formal construction is similar
in spirit to the c-removal paradigm in weighted automata (Mohri 2000), where weights
along an c-path need to be gathered. Therefore, we suppress the formal construction
and the proof of its correctness.
3.3.2 Optimizing Register Operations. In FSRAs, traversing an arc depends not
only on the input symbol but also on satisfying the series of register operations.
Sometimes, a given series of register operations can never be satisfied, and thus
the arc to which it is attached cannot be traversed. For example, the series of reg-
ister operations ((W,1, a), (R, 1, b)) can never be satisfied, hence an arc of the form
(q1, 6, ((W,1, a), (R, 1, b)), q2) is redundant. In addition, the constructions of Sections 3.2
and 3.3.1 might result in redundant states and arcs that can never be reached or can
never lead to a final state. Moreover, in many cases a series of register operations can
be minimized into a shorter series with the same effect. For example, the series of
register operations ((W,1, a), (R, 1, a), (W, 1, b)) is equal in its effect to the series ((W,1, b)).
Therefore, we show an algorithm for optimizing a given FSRA by minimizing the series
of register operations over its arcs and removing redundant arcs and states.
For a given FSRA A = (Q, q0, Σ, Γ, n, b, F), we construct an equivalent FSRA A&apos; =
(Q, q0, Σ, Γ, n, b&apos;, F) = Opt(A), such that b&apos; is created from b by removing redundant
arcs and by optimizing all the series of register operations. We begin by defining
(Actionsn� + |i as the subset of �Actionsn) + that consists only of operations over the
i-th register. Define a total function sati : (Actionsn) + |i {true, false} by:
�false
true if there exist u, v E Γn such that u I �j v
sati(�a) = otherwise
</bodyText>
<page confidence="0.992056">
64
</page>
<note confidence="0.693434">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<bodyText confidence="0.899796222222222">
sati(a) = true iff the series of register operations a� is satisfiable, i.e., there exists a
configuration of register contents for which all the operations in the series can be
executed successfully. Determining whether sati(a) = true by exhaustively checking
all the vectors in Γn may be inefficient. Therefore, we show a necessary and sufficient
condition for determining whether sati(a) = true for some a� E (ActionsΓ �+|i, which can
n
be checked efficiently. In addition, this condition will be useful in optimizing the series
of register operations as will be shown later. A series of register operations over the i-th
register is not satisfiable if either one of the following holds:
</bodyText>
<listItem confidence="0.9996485">
• A write operation is followed by a read operation expecting a different
value.
• A read operation is immediately followed by a read operation expecting a
different value.
</listItem>
<equation confidence="0.54728375">
Theorem 4
For all a� = ((op1,i,Y1), (op2,i,Y2),..., (ops,i,Ys)) E (ActionsΓ �+|i, sati(�a) = false if and
n
only if either one of the following holds:
</equation>
<listItem confidence="0.998847666666667">
1. There exists k, 1 &lt; k &lt; s, such that opk = W and there exists m, k &lt; m &lt; s,
such that opm = R, Yk =� Ym and for all j, k &lt; j &lt; m, opj = R.
2. There exists k, 1 &lt; k &lt; s, such that opk = opk+1 = R and Yk =� Yk+1.
</listItem>
<bodyText confidence="0.9994825">
Notice that if i = 0, then by the definition of FSRAs, all the register operations in
the series are the same operation, which is (R, 0, #); and this operation can never fail.
In addition, if all the operations in the series are write operations, then again, by the
definition of FSRAs, these operations can never fail. If none of the two conditions of the
theorem holds, then the series of register operations is satisfiable.
We now show how to optimize a series of operations over a given register. An
optimized series is defined only over satisfiable series of register operations in the
following way:
</bodyText>
<listItem confidence="0.999074833333333">
• If all the operations are write operations, then leave only the last one (since
it will overwrite all its predecessors).
• If all the operations are read operations, then by theorem 4, they are all the
same operation, and in this case just leave one of them.
• If there are both read and write operations, then distinguish between two
cases:
</listItem>
<bodyText confidence="0.939621285714286">
– If the first operation is a write operation, leave only the last write
operation in the series.
– If the first operation is a read operation, leave the first operation
(which is read) and the last write operation in the series. If the last
write operation writes into the register the same symbol that the
read operation required, then the write is redundant; leave only the
read operation.
</bodyText>
<page confidence="0.993933">
65
</page>
<figure confidence="0.51493025">
Computational Linguistics Volume 32, Number 1
Definition
Define a function mini : (Actionsn) + |i (Actionsn� + i. Let d= ((op1 , i,&apos;y1 ), ... , (ops, i,
&apos;ys)). If sati(a) = true then:
</figure>
<listItem confidence="0.99381125">
• If for all k, 1 &lt; k &lt; s, opk = W, define mini(�a) = ((W, i,&apos;ys)).
• If for all k, 1 &lt; k &lt; s, opk = R then define mini(�a) = ((R, i,&apos;ys)).
• If there exists m, 1 &lt; m &lt; s such that opm = W and if there exists t,
1 &lt; t &lt; s, such that opt = R then:
</listItem>
<table confidence="0.859012">
mini(a) =  ((W,i,&apos;yj)) ifop1 = Wand
 for all k, j &lt; k &lt; s, opk = R
 ((R, i, &apos;y1), (W,i,&apos;yj)) if op1 = Rand
for all k, j &lt; k &lt; s, opk = R and &apos;y1 =� &apos;yj
((R, i, &apos;y1)) if op1 = R and if there exists j, 1 &lt; j &lt; s,
such that for all k, j &lt; k &lt; s,
opk = R and &apos;y1 = &apos;yj —
The formal proof that mini(-a) is the minimal equivalent series of register operations
of a~ is suppressed.
</table>
<bodyText confidence="0.680453">
We now show how to optimize a series of register operations. Define a function
</bodyText>
<equation confidence="0.640984">
min : �ActionsΓ �+ �� �ActionsΓ �+ U {null}. For all a~ E �ActionsΓ �+ define min(�a) = b~
n n n
</equation>
<bodyText confidence="0.987419">
where b~ is obtained from a by:
</bodyText>
<listItem confidence="0.861496428571429">
• Each subseries di of it, consisting of all the register operations on the i-th
register, is checked for satisfaction. If sati(ai) =false then the arc cannot be
traversed and min(a) = b� = null. If sati(ai) = true then di is replaced init by
min(di). Notice that the order of the minimized subseries in the complete
series is unimportant as they operate on different registers.
• If there exists i =� 0, such that a&apos;i is not empty, then the subseries a0
consisting only of operations of the form (R, 0, #) is deleted fromit.
</listItem>
<bodyText confidence="0.958234">
Finally, given an FSRA A = (Q, q0, E, Γ, n, b, F), construct an equivalent FSRA A&apos; =
(Q, q0, E, Γ, n, b&apos;, F) = Opt(A) where
</bodyText>
<equation confidence="0.841818">
b&apos; = {(q1, 6, (min(a)), q2)  |(q1, 6, (a&apos;), q2) E b and min(a) =� null}
Opt(A) is optimized with respect to register operations.
</equation>
<bodyText confidence="0.980973666666667">
Like FSAs, FSRAs may have states that can never be reached or can never lead to a
final state. These states (and their connected arcs) can be removed in the same way they
are removed in FSAs. In sum, FSRA optimization is done in two stages:
</bodyText>
<listItem confidence="0.930413">
1. Minimizing the series of register operations over the FSRA transitions.
2. Removing redundant states and arcs.
</listItem>
<bodyText confidence="0.997915666666667">
Notice that stage 1 must be performed before stage 2 as it can result in further re-
duction in the size of the network when performing the second stage. For a given FSRA
A, define OPT(A) as the FSRA obtained from Opt(A) by removing all the redundant
</bodyText>
<page confidence="0.956018">
66
</page>
<note confidence="0.65349">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<bodyText confidence="0.971455">
states and transitions. An FSRA A is optimized if OPT(A) = A (notice that OPT(A) is
unique, i.e., if B = OPT(A) and C = OPT(A), then B = C).
</bodyText>
<subsectionHeader confidence="0.818215">
3.4 FSRA Minimization
</subsectionHeader>
<bodyText confidence="0.992400631578947">
FSRAs can be minimized along three different axes: states, arcs, and registers. Reduc-
tion in the number of registers can always be achieved by converting an FSRA to an
FSA (Section 3.1), eliminating registers altogether. Since FSRAs are inherently non-
deterministic (see the discussion of linearization below), their minimization is related
to the problem of non-deterministic finite-state automata (NFA) minimization, which
is known to be NP-hard.6 However, while FSRA arc minimization is NP-hard, FSRA
state minimization is different. Recall that in theorem 3 we have shown that any FSA
has an equivalent FSRA-2 with 3 states and 2 registers. It thus follows that any FSRA
has an equivalent FSRA-2 with 3 states (simply convert the FSRA to an FSA and then
convert it to an FSRA-2 with 3 states). Notice that minimizing an FSRA in terms of states
or registers can significantly increase the number of arcs. As many implementations of
finite-state devices use space that is a function of the number of arcs, the benefit that lies
in such minimization is limited. Therefore, a different minimization function, involving
all the three axes, is called for. We do not address this problem in this work. As for
arc minimization, we cite the following theorem. As its proof is most similar to the
corresponding proof on NFA, we suppress it.
Theorem 5
FSRA arc minimization is NP-hard.
The main advantage of finite-state devices is their linear recognition time. In finite-
state automata, this is achieved by determinizing the network, ensuring that the
transition relation is a function. In FSRAs, in contrast, a functional transition re-
lation does not guarantee linear recognition time, since multiple possible transi-
tions can exist for a given state and a given input symbol. For example, given an
FSRA A = (Q, q0, E, Γ, n, k, b, F), and some q, q1, q2 E Q and 6 E E, two arcs such as
(q, 6, ((W,1, a)), q1), (q, 6, ((W,1, b)), q2) E b do not hamper the functionality of the FSRA
transition relation. However, they do imply that for the state q and for the same input
symbol (6), more than one possible arc can be traversed. We use deterministic to denote
FSRAs in which the transition relation is a function, and a new term, linearized, is used
to denote FSRAs for which linear recognition time is guaranteed.
Generally, a FSRA is linearized if it is optimized, c-free, and given a current state
and a new input symbol, and at most one transition can be traversed. Thus, if the
transition relation includes two arcs of the form (q, 6, (a), q1), (q, 6, ( b), q2), then a� and
b must be a contradicting series of register operations. Two series of register operations
are contradicting if at most one of them is satisfiable. Since the FSRA is optimized, each
series of register operations is a concatenation of subseries, each operating on a differ-
ent register; and the subseries operating on the i-th register must be either empty or
((W, i,7)) or ((R, i, 7)) or ((R, i,71), (W, i,72)). ((W, i,7)) contradicts neither ((R, i,7)) nor
((R,i,71), (W,i,72)). ((R,i,7)) and ((R, i, 71), (W, i, 72)) are contradicting only if 7 =� 71.
</bodyText>
<footnote confidence="0.8920695">
6 While this theorem is a part of folklore, we were unable to find a formal proof. We explicitly prove this
theorem in Cohen-Sygal (2004).
</footnote>
<page confidence="0.996611">
67
</page>
<figure confidence="0.469851">
Computational Linguistics Volume 32, Number 1
Definition
</figure>
<bodyText confidence="0.899762875">
An FSRA A = (Q, q0, Σ, Γ, n, k, δ, F), is linearized if it is optimized, a-free, and for
all (q, σ, (~a), q1), (q, σ, (b), q2) E δ such that (a-) =� (0, where () = ((op11, i11,γ11),... , (op1 k,
i1k,γ1k)) and (b) = ((opi,ii, γi), . . . , (op2m, i2m, γ2 m)) , there exists j1, 1 &lt; j1 &lt; k and there
exists j2, 1 &lt; j2 &lt; m, such that op1j1 = op2j2 = R, i1j1 = i2j2 and γ1j1 =� γ2j2.
A naive algorithm for converting a given FSRA into an equivalent linearized one
is to convert it to an FSA and then determinize it. In the worst case, this results in
an exponential increase in the network size. As the following theorem shows, FSRA
linearization is NP-complete.
</bodyText>
<equation confidence="0.753156333333333">
Theorem 6
FSRA linearization is NP-complete.
Proof 2
</equation>
<bodyText confidence="0.9497968">
Evidently, given an FSRA A, it can be verified in polynomial time that A is linearized.
Therefore, FSRA linearization is in NP.
Let φ be a CNF formula with m clauses and n variables. Construct an FSRA A such
that L(A) = {C} if φ is satisfiable, otherwise L(A) = 0.
Let x1, ... , xn be the variables of φ. Define A = (Q, q0, Σ, Γ, n,1, δ,F), such that:
</bodyText>
<equation confidence="0.714881">
0 Q = {q0, q1,... , qn+m}
</equation>
<listItem confidence="0.9207986">
• F = {qn+m}
• Σ is irrelevant (choose any Σ).
• Γ = {T, F}.
• δ = {(qi_1,C, (W,i,T),qi)  |1 &lt; i &lt; n} U {(qi_1,C, (W,i,F),qi)  |1 &lt; i &lt; n}
U
</listItem>
<equation confidence="0.925869">
{(qn+i_1, C, (R, j, T), qn+i)  |1 &lt; i &lt; m and xj occurs in the i-th clause}
U
{(qn+i_1, e, (R, j, F), qn+i)  |1 &lt; i &lt; m and xj occurs in the i-th clause}
</equation>
<bodyText confidence="0.9828789">
Notice that each path in A is of length m + n. The first n arcs in the path
write an assignment into the registers, then it is possible to traverse the
remaining m arcs in the path only if the assignment stored into the
registers satisfies φ.
For example, for the CNF formula (x1 V x2 V x5) n (x1 V x2) n (x3 V x4 V x5), the FSRA of
Figure 10 is constructed. Observe that the number of states and arcs in this FSRA is
O(mn). Now, linearize A into an FSRA A&apos; and assume this can be done in polynomial
time. By the definition of linearized FSRA, A&apos; does not contain a-arcs. Therefore, e E
L(A&apos;) iff the initial state of A&apos; is also a final one. Hence, φ is satisfiable iff the initial state
of A&apos; is also a final one. ■
</bodyText>
<sectionHeader confidence="0.922437" genericHeader="method">
4. A Regular Expression Language for FSRAs
</sectionHeader>
<bodyText confidence="0.984728666666667">
Regular expressions are a formal way for defining regular languages. Regular language
operations construct regular expressions in a convenient way. Several toolboxes (soft-
ware packages) provide extended regular expression description languages and compil-
</bodyText>
<page confidence="0.997478">
68
</page>
<note confidence="0.66307">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<figureCaption confidence="0.900482">
Figure 10
</figureCaption>
<bodyText confidence="0.9313534">
FSRA for a given CNF formula.
ers of the expressions to finite-state devices, automata, and transducers (see Section 1).
We provide a regular expression language for constructing FSRAs, the denotations
of whose expressions are FSRAs. In the following discussion we assume the regular
expression syntax of XFST (Beesley and Karttunen 2003) for basic expressions.7
</bodyText>
<sectionHeader confidence="0.65386" genericHeader="method">
Definition
</sectionHeader>
<bodyText confidence="0.941950068965517">
Let ActionsΓn = 1R, W} x 10, 1, 2, ... , n − 1} x Γ, where n is the number of registers and
Γ is the register alphabet. If R is a regular expression and a~ E (ActionsΓ )+ is a series of
n
register operations, then the following are also regular expressions: a�&gt; R, a�&gt; DR, a�&lt; R,
and a a a R.
We now define the denotation of each of the above expressions. Let R be a regular
expression whose denotation is the FSRA A, and let a~ E (ActionsΓ )+. The denotation
n
of a�&lt; R is an FSRA A&apos; obtained from A by adding a new node, q, which becomes the
initial node of A&apos;, and an arc from q to the initial node of A; this arc is labeled by a
and associated with it. Notice that in the regular expression a~ a R, R and a~ can contain
operations on joint registers. In some cases, one would like to distinguish between the
registers used in a~ and in R. Usually, it is up to the user to correctly manipulate the
usage of registers, but in some cases automatic distinction seems desirable. For example,
if R includes a circumfix operator (see below), its corresponding FSRA will contain
register operations created automatically by the operator. Instead of remembering that
circumfixation always uses register 1, one can simply distinguish between the registers
of a~ and R via the a�&lt; a R operator. This operator has the same general effect as the
previous one, but the transition relation in its FSRA uses fresh registers that are added
to the machine.
In a similar way, the operators a�&gt; R and a�&gt; &gt;R are translated into networks. The
difference between these operators and the previous ones is that here, the register
operations in a~ are executed after traversing all the arcs in the FSRA denoted by R.
Using these additional operators, it is easy to show that every FSRA has a corresponding
regular expression denoting it, by a trivial modification of the construction presented by
Kleene (1956).
Example 8
Consider the case of vowel harmony in Warlpiri (Sproat 1992), where the vowel of
suffixes agrees in certain aspects with the vowel of the stem to which it is attached.
</bodyText>
<page confidence="0.7944665">
7 In particular, concatenation is denoted by juxtaposition and a is denoted by 0.
69
</page>
<note confidence="0.498422">
Computational Linguistics Volume 32, Number 1
</note>
<bodyText confidence="0.999632">
A simplified account of the phenomenon is that suffixes come in two varieties, one with
‘i’ vowels and one with ‘u’ vowels. Stems whose last vowel is ‘i’ take suffixes of the
first variety, whereas stems whose last vowel is ‘u’ or ‘a’ take the other variety. The
following examples are from Sproat (1992) (citing Nash (1980)):
</bodyText>
<listItem confidence="0.552126125">
1. maliki+kil.i+l.i+lki+ji+li
(dog+PROP+ERG+then+me+they)
2. kud. u+kul.u+l.u+lku+ju+lu
(child+PROP+ERG+then+me+they)
3. minija+kul.u+l.u+lku+ju+lu
(cat+PROP+ERG+then+me+they)
An FSRA that accepts the above three words is denoted by the following complex
regular expression:
</listItem>
<bodyText confidence="0.64091576">
define LexI [m a l i k i]; % words ending in ‘i’
define LexU [k u d u]; % words ending in ‘u’
define LexA [m i n i j a]; % words ending in ‘a’
! Join all the lexicons and write to register 1 ‘u’ or ‘i’
! according to the stem‘s last vowel.
define Stem [&lt;(W,1,i)&gt; &lt; LexI]  |[&lt;(W,1,u)&gt; &lt; [LexU  |LexA]];
! Traverse the arc only if the scanned symbol is the content of
! register 1.
define V [&lt;(R,1,i)&gt; &gt; i]  |[&lt;(R,1,u)&gt; &gt; u];
define PROP [+ k V l V]; % PROP suffix
define ERG [+ l V]; % ERG suffix
define Then [+ l k V]; % suffix indicating ‘then’
define Me [+ j V]; % suffix indicating ‘me’
define They [+ l V]; % suffix indicating ‘they’
! define the whole network
define WarlpiriExample Stem PROP ERG Then Me They;
Register 1 stores the last vowel of the stem, eliminating the need to duplicate paths
for each of the different cases. The lexicon is divided into three separate lexicons
(LexI, LexU, LexA), one for each word ending (‘i’, ‘u’, or ‘a’ respectively). The separate
lexicons are joined into one (the variable Stem) and when reading the last letter of
the base word, its type is written into register 1. Then, when suffixing the lexicon
base words, the variable V uses the the content of register 1 to determine which of
the symbols ‘i’, ‘u’ should be scanned and allows traversing the arc only if the correct
symbol is scanned. Note that this solution is applicable independently of the size of the
lexicon, and can handle other suffixes in the same way.
</bodyText>
<subsectionHeader confidence="0.528293">
Example 9
</subsectionHeader>
<bodyText confidence="0.998499">
Consider again Example 7. The FSRA constructed for Arabic nominative definite and
indefinite nouns can be denoted by the following regular expression:
</bodyText>
<listItem confidence="0.764608">
! Read the definite article (if present).
! Store in register 1 whether the noun is definite or indefinite.
! Store in register 2 the actual form of the definite article.
</listItem>
<page confidence="0.968966">
70
</page>
<table confidence="0.844386071428571">
Cohen-Sygal and Wintner Non-Concatenative Morphology
define Prefix [&lt;(W,1,indef)&gt; &lt; 0]  |[&lt;(W,1,def),(W,2,l)&gt; &lt; ’al] |
[&lt;(W,1,def),(W,2,$)&gt; &lt; ’a$]  |[&lt;(W,1,def),(W,2,d)&gt; &lt; ’ad];
! Normal base - definite and indefinite
define Base [ [&lt;(R,2,l)&gt; &lt; 0]  |[&lt;(R,1,indef)&gt; &lt; 0] ]
[ [kitaab]  |[q a m a r] ];
! Bases beginning with $ - definite and indefinite
define $Base [ [&lt;(R,2,$)&gt; &lt; 0]  |[&lt;(R,1,indef)&gt; &lt; 0] ] [$ a m s];
! Bases beginning with d - definite and indefinite
define dBase [ [&lt;(R,2,d)&gt; &lt; 0]  |[&lt;(R,1,indef)&gt; &lt; 0] ] [d a f t a r];
! Read definite and indefinite suffixes.
define Suffix [&lt;(R,1,def)&gt; &gt; u]  |[&lt;(R,1,indef)&gt; &gt; un];
! The complete network.
define ArabicExample Prefix [Base  |$Base  |dBase] Suffix;
</table>
<bodyText confidence="0.992860909090909">
The variable Prefix denotes the arcs connecting the first two states of the FSRA,
in which the definite article (if present) is scanned and information indicating whether
the word is definite or not is saved into register 1. In addition, if the word is definite
then register 2 stores the actual form of the definite article. The lexicon is divided
into several parts: The Base variable denotes nouns that do not trigger assimilation.
Other variables ($Base, dBase) denote nouns that trigger assimilation, where for each
assimilation case, a different lexicon is constructed. Each part of the lexicon deals with
both its definite and indefinite nouns by allowing traversing the arcs only if the register
content is appropriate. The variable Suffix denotes the correct suffix, depending on
whether the noun is definite or indefinite. This is possible using the information that
was stored in register 1 by the variable Prefix.
</bodyText>
<sectionHeader confidence="0.972315" genericHeader="method">
5. Linguistic Applications
</sectionHeader>
<bodyText confidence="0.99999475">
We demonstrated in examples 5 and 6 that FSRAs can model some non-concatenative
phenomena more efficiently than standard finite-state devices. We now introduce new
regular expression operators, accounting for our motivating linguistic phenomena, and
show how expressions using these operators are compiled into the appropriate FSRA.
</bodyText>
<subsectionHeader confidence="0.989441">
5.1 Circumfixes
</subsectionHeader>
<bodyText confidence="0.999972571428572">
We introduce a dedicated regular expression operator for circumfixation and show how
expressions using this operator are compiled into the appropriate FSRA. The operator
accepts a regular expression, denoting a set of bases, and a set of circumfixes, each
of which is a pair of regular expressions (prefix, suffix). It yields as a result an FSRA
obtained by applying each circumfix to each of the bases. The main purpose of this
operator is to deal with cases in which the circumfixes are pairs of strings, but it is
defined such that the circumfixes can be arbitrary regular expressions.
</bodyText>
<subsectionHeader confidence="0.529504">
Definition
</subsectionHeader>
<bodyText confidence="0.99841">
Let Σ be a finite set such that ❑, {, }, (, ), ® ∈/ Σ. We define the ® operation to be of
the form
</bodyText>
<equation confidence="0.976051">
R ® {(β1❑γ1)(β2❑γ2) ... (βm❑γm)}
</equation>
<page confidence="0.993393">
71
</page>
<note confidence="0.597037">
Computational Linguistics Volume 32, Number 1
</note>
<bodyText confidence="0.966167125">
where: m E N is the number of circumfixes; R is a regular expression over Σ denoting
the set of bases; and βi, γi for 1 &lt; i &lt; m are regular expressions over Σ denoting the
prefix and suffix of the i-th circumfix, respectively.
Notice that R, βi,γi may denote infinite sets. To define the denotation of this op-
erator, let AP ,A�i be the FSRAs denoted by βi,γi, respectively. The operator yields an
FSRA constructed by concatenating three FSRAs. The first is the FSRA constructed from
the union of the FSRAs A&apos;i , ... , A&apos;m, where each A&apos;� is an FSRA obtained from AP
by adding a new node, q, which becomes the initial node of A&apos;P , and an arc from q
to the initial node of AP ; this arc is labeled by c and associated with ((W,1, βi❑γi))
(register 1 is used to store the circumfix). In addition, the register operations of the
FSRA AP are shifted by one register in order not to cause undesired effects by the
use of register 1. The second FSRA is the FSRA denoted by the regular expression R
(again, with one register shift) and the third is constructed in the same way as the
first one, the only difference being that the FSRAs are those denoted by γ1,...,γm
and the associated register operation is ((R,1, βi❑γi)). Notice that the concatenation
operation, defined in Section 3.2.2, adjusts the register operations in the FSRAs to be
concatenated, to avoid undesired effects caused by using joint registers. We use this
operation to concatenate the three FSRAs, leaving register 1 unaffected (to handle the
circumfix).
Example 10
Consider the participle-forming combinations in German, e.g., the circumfix ge-t. A
simplified account of the phenomenon is that German verbs in their present form take
an n suffix but in participle form they take the circumfix ge-t. The following examples
are from Sproat (1992):
s¨auseln ‘rustle’ ges¨auselt ‘rustled’
br¨usten ‘brag’ gebr¨ustet ‘bragged’
The FSRA of Figure 11, which accepts the four forms, is denoted by the regular
expression
[s a¨u s e l  |b r u¨ s t e] ® {(�❑n)(g e❑t)}
This regular expression can be easily extended to accept more German verbs in other
forms. More circumfixation phenomena in other languages such as Indonesian and
Arabic can be modeled in the same way using this operator.
</bodyText>
<footnote confidence="0.3798745">
Figure 11
Participle-forming combinations in German.
</footnote>
<page confidence="0.992507">
72
</page>
<note confidence="0.56138">
Cohen-Sygal and Wintner Non-Concatenative Morphology
Example 11
</note>
<bodyText confidence="0.998264333333333">
Consider again Example 5. The FSRA accepting all the possible combinations of stems
and the Hebrew circumfixes h-a, ht-ut, m-c can be denoted by the regular expression
R ⊗ {(h❑a)(ht❑ut)(m❑c)} where R denotes an FSA accepting the roots.
</bodyText>
<subsectionHeader confidence="0.994081">
5.2 Interdigitation
</subsectionHeader>
<bodyText confidence="0.9998055">
Next, we define a dedicated operator for interdigitation. It accepts a set of regular
expressions, representing a set of roots, and a list of patterns, each of which containing
exactly n slots. It yields as a result an FSRA denoting the set containing all the strings
created by splicing the roots into the slots in the patterns. For example, consider the He-
brew roots r.$.m, p.&amp;.l, p.q.d and the Hebrew patterns hit❑a❑e❑, mi❑❑a❑, ha❑❑a❑a.
The roots are all trilateral, and the patterns have three slots each. Given these two
inputs, the new operator yields an FSRA denoting the set {hitra$em, hitpa&amp;el, hitpaqed,
mir$am, mip&amp;al, mipqad, har$ama, hap&amp;ala, hapqada}.
</bodyText>
<sectionHeader confidence="0.421542" genericHeader="method">
Definition
</sectionHeader>
<bodyText confidence="0.9888635">
Let E be a finite set such that ❑, {, }, (, ), ⊕ ∈/ E. We define the splice operation to be of
the form
</bodyText>
<equation confidence="0.908279">
{(α11, α12, ..., α1n�, (α21, α22,..., α2n�, ..., (αm1, αm2, ..., αmn)}
⊕
</equation>
<bodyText confidence="0.5431925">
{(β11❑β12❑...β1n❑β1 n+1), (β21❑β22❑...β2n❑β2 n+1), ..., (βk1❑βk2❑...βkn❑βk n+1)}
where:
</bodyText>
<listItem confidence="0.994903833333333">
• n ∈ N is the number of slots (represented by ‘❑’) in the patterns into which
the roots letters should be inserted.
• m ∈ N is the number of roots to be inserted.
• k ∈ N is the number of patterns.
• αij, βij are regular expressions (including regular expressions denoting
FSRAs).
</listItem>
<bodyText confidence="0.998790571428571">
The left set is a set of roots to be inserted into the slots in the right set of patterns.
For the sake of brevity, βi and αi are used as shorthand notations for βi1❑βi2❑...❑βi(n+1)
and αi1αi2...αin, respectively.
Consider first the case where αij ∈ E ∪ {c} for 1 ≤ i ≤ m and 1 ≤ j ≤ n and βij ∈
E ∪ {c} for 1 ≤ i ≤ k and 1 ≤ j ≤ n + 1. In this case the splice operation yields as a result
an FSRA-1 A = (Q,q0,E, Γ, 3,δ,F), such that L(A) = {βj1αi1βj2αi2...βjnαinβj(n+1)  |1 ≤
i ≤ m , 1 ≤ j ≤ k}, where:
</bodyText>
<listItem confidence="0.999702">
• Q = {q0, q1,..., q2n+1}
• F = {q2n+1}
• E = ({αij |1 ≤ i ≤ m , 1 ≤ j ≤ n} ∪ {βij |1 ≤ i ≤ k , 1 ≤ j ≤ n + 1}) \ {e}
</listItem>
<page confidence="0.993457">
73
</page>
<figure confidence="0.707285">
Computational Linguistics Volume 32, Number 1
</figure>
<figureCaption confidence="0.788817">
Figure 12
</figureCaption>
<bodyText confidence="0.372727">
Interdigitation FSRA – general.
</bodyText>
<listItem confidence="0.8741945">
• r = {Ri |1 &lt; i &lt; k} U {αi |1 &lt; i &lt; m} U {#}.
• b = {(q0, Ri1, W,1, Ri,q1) |1 &lt; i &lt; k}
</listItem>
<equation confidence="0.972265666666667">
U
{(q1, αi1, W, 2, αi, q2) |1 &lt; i &lt; m}
U
{(q2j−2, Rij, R,1, Ri, q2j−1) |1 &lt; i &lt; k , 2 &lt; j &lt; n + 1}
U
{(q2j−1,αij, R, 2,αi,q2j) |1 &lt; i &lt; m , 2 &lt; j &lt; n}
</equation>
<bodyText confidence="0.999743">
This FSRA is shown in Figure 12. It has 3 registers, where register 1 remembers the
pattern and register 2 remembers the root. Notice that the FSRA will have 3 registers
and 2n + 2 states for any number of roots and patterns. The number of arcs is k x (n +
1) + m x n. In the (default) case of trilateral roots, for m roots and k patterns the resulting
machine has a constant number of states and O(k + m) arcs.
In the general case, where αij and Rij can be arbitrary regular expressions, the
construction of the FSRA denoted by this operation is done in the same way as in the
case of circumfixes with two main adjustments. The first is that in this case the final
FSRA is constructed by concatenating 2n + 1 intermediate FSRAs (n FSRAs for the n
parts of the roots and n + 1 FSRAs for the n + 1 parts of the patterns). The second is that
here, 2 registers are used to remember both the root and the pattern. We suppress the
detailed description of the construction.
</bodyText>
<subsectionHeader confidence="0.656924">
Example 12
</subsectionHeader>
<bodyText confidence="0.854091666666667">
Consider again the Hebrew roots r.$.m, p.&amp;.l, p.q.d and the Hebrew patterns hit❑a❑e❑,
mi❑❑a❑, and ha❑❑a❑a. The splice operation
{(r, $, m)(p, &amp;,l)(p, q, d)} ® {(hit❑a❑e❑)(mi❑❑a❑)(ha❑❑a❑a)}
</bodyText>
<page confidence="0.995961">
74
</page>
<note confidence="0.710232">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<bodyText confidence="0.999293">
yields the FSRA of Figure 13. The c-arc was added only for the convenience of the
drawing.
It should be noted that like other processes of derivational morphology, Hebrew
word formation is highly idiosyncratic: Not all roots combine with all patterns, and
there is no systematic way to determine when such combinations will be realized
in the language. Yet, this does not render our proposed operators useless: One can
naturally characterize classes of roots and classes of patterns for which all the com-
binations exist. Furthermore, even when such a characterization is difficult to come by,
the splice operator can be used, in combination with other extended regular expres-
sion operators, to define complex expressions for generating the required language.
This is compatible with the general approach for using finite-state techniques, imple-
menting each phenomenon independently and combining them together using closure
properties.
</bodyText>
<subsectionHeader confidence="0.990854">
5.3 Reduplication
</subsectionHeader>
<bodyText confidence="0.999887666666667">
We now return to the reduplication problem as was presented in example 3. We extend
the finite-state registered model to efficiently accept Ln = {ww  |w E E∗, |w |= n}, a
finite instance of the general problem, which is arguably sufficient for describing
reduplication in natural languages. Using FSRAs as defined above does not improve
space efficiency, because a separate path for each reduplication is still needed. Notice
that the different symbols in Ln have no significance except the pattern they create.
Therefore, FSRAs are extended in order to be able to identify a pattern without actually
distinguishing between different symbols in it. The extended model, FSRA*, is obtained
from the FSRA-1 model by adding a new symbol, ‘*’, assumed not to belong to E, and
by forcing IF to be equal to E. The ‘*’ indicates equality between the input symbol and
the designated register content, eliminating the need to duplicate paths for different
symbols.
</bodyText>
<figureCaption confidence="0.667596">
Figure 13
</figureCaption>
<bodyText confidence="0.418869">
Interdigitation example.
</bodyText>
<page confidence="0.975734">
75
</page>
<note confidence="0.531384">
Computational Linguistics Volume 32, Number 1
</note>
<sectionHeader confidence="0.615815" genericHeader="method">
Definition
</sectionHeader>
<bodyText confidence="0.997749333333333">
Let * E� E. An FSRA* is an FSRA-1 where E = IF (and thus includes ’#’) and the tran-
sition function is extended to be b C_ Q x E U {e, *} x {R, W} x {0, 1, 2,. .. , n − 1} x
E U {*} x Q. The extended meaning of b is as follows:
</bodyText>
<listItem confidence="0.993746916666666">
• (s, 6, R, i, &apos;y, t) E b, (s, 6, W, i, &apos;y, t) E b where 6,&apos;y =� * imply the same as
before.
• (s, 6, R, i, *, t) E b and (s, *, R, i, 6, t) E b for 6 =� e imply that if the
automaton is in state s, the input symbol is 6 and the content of the i-th
register is the same 6, then the automaton may enter state t.
• (s, 6, W, i, *, t) E b and (s, *, W, i, 6, t) E b for 6 =� e imply that if the
automaton is in state s and the input symbol is 6, then the content of the
i-th register is changed to 6, and the automaton may enter state t.
• (s, *, R, i, *, t) E b implies that if the automaton is in state s, the input
symbol is some 6 E E and the content of the i-th register is the same 6,
then the automaton may enter state t.
• (s, *, W, i, *, t) E b implies that if the automaton is in state s and the input
</listItem>
<bodyText confidence="0.972566363636364">
symbol is some 6 E E, then the content of the i-th register is changed to the
same 6, and the automaton may enter state t.
With this extended model we can construct an efficient registered automaton for
Ln: The number of registers is n+1. Registers 1, ..., n remember the first n symbols to be
duplicated. Figure 14 depicts an extended registered automaton that accepts Ln for n =
4. Notice that the number of states depends only on n and not on the size of E. Figure 15
schematically depicts an extended registered automaton that accepts Ln for some n E N.
The language {ww  ||w |&lt; n} for some n E N can be generated by a union of FSRA*,
each one generating Ln for some i &lt; n. Since n is usually small in natural language
reduplication, the resulting automaton is manageable, and in any case, considerably
smaller than the naive automaton.
</bodyText>
<subsectionHeader confidence="0.972652">
5.4 Assimilation
</subsectionHeader>
<bodyText confidence="0.999745333333333">
In example 7, FSRAs are used to model assimilation in Arabic nominative definite
nouns. Using the FSRA* model defined above, further reduction in the network size
can be achieved. The FSRA* of Figure 16 accepts all the nominative definite forms of the
Arabic nouns kitaab, qamar, and daftar (more nouns can be added in a similar way).
Register 1 stores information about the actual form of the definite article, to ensure that
assimilation occurs when needed and only then. Notice that in this FSRA, in contrast to
</bodyText>
<figureCaption confidence="0.763217">
Figure 14
</figureCaption>
<bodyText confidence="0.623409">
Reduplication for n = 4.
</bodyText>
<page confidence="0.870398">
76
</page>
<note confidence="0.674778">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<figureCaption confidence="0.948812">
Figure 15
</figureCaption>
<bodyText confidence="0.904813666666667">
Reduplication – general case.
the FSRA of Figure 8, the definite Arabic article al is not scanned as one symbol but as
two separate symbols.
</bodyText>
<sectionHeader confidence="0.98909" genericHeader="method">
6. Finite-state Registered Transducers
</sectionHeader>
<bodyText confidence="0.99992725">
We extend the FSRA model to finite-state registered transducers (FSRT), denoting
relations over two finite alphabets. The extension is done by adding to each transition an
output symbol. This facilitates an elegant solution to the problem of binary incrementors
which was introduced in Example 4.
</bodyText>
<subsectionHeader confidence="0.452975">
Example 13
</subsectionHeader>
<bodyText confidence="0.999252333333334">
Consider again the 32-bit incrementor example introduced in Example 4. Recall that
a sequential transducer for an n-bit binary incrementor would require 2n states and a
similar number of transitions. Using the FSRT model, a more efficient n-bit transducer
can be constructed. A 4-bit FSRT incrementor is shown in Figure 17. The first four
transitions copy the input string into the registers, then the input is scanned (using
the registers) from right to left (as the carry moves), calculating the result, and the
last four transitions output the result (in case the input is 1n, an extra 1 is added in
the beginning). Notice that this transducer guarantees linear recognition time, since
from each state only one arc can be traversed in each step, even when there are
c-arcs. In the same way, an n-bit transducer can be constructed for all n ∈ N. Such
a transducer will have n registers, 3n + 1 states and 6n arcs. The FSRT model solves
the incrementor problem in much the same way it is solved by vectorized finite-state
</bodyText>
<figureCaption confidence="0.654886">
Figure 16
</figureCaption>
<bodyText confidence="0.300209">
FSRA* for Arabic nominative definite nouns.
</bodyText>
<page confidence="0.958858">
77
</page>
<figure confidence="0.748818">
Computational Linguistics Volume 32, Number 1
</figure>
<figureCaption confidence="0.950088">
Figure 17
</figureCaption>
<bodyText confidence="0.966803">
4-bit incrementor using FSRT.
automata, but the FSRT solution is more intuitive and is based on existing finite-state
techniques.
It is easy to show that FSRTs, just like FSRAs, are equivalent to their non-registered
counterparts. It immediately implies that FSRTs maintain the closure properties of
regular relations. As in FSRAs, implementing the closure properties directly on FSRTs
is essential for benefiting from their space efficiency. The common operators such as
union, concatenation, etc., are implemented in the same ways as in FSRAs. A direct
implementation of FSRT composition is a naive extension of ordinary transducer com-
position, based on the intersection construction of FSRAs. We explicitly define these
operations in Cohen-Sygal (2004).
</bodyText>
<sectionHeader confidence="0.705126" genericHeader="method">
7. Implementation and Evaluation
</sectionHeader>
<bodyText confidence="0.99986">
In order to practically compare the space and time performance of FSRAs and FSAs, we
have implemented the special operators introduced in Sections 4 and 5 for circumfix-
ation and interdigitation, as well as direct construction of FSRAs. We have compared
FSRAs with ordinary FSAs by building corresponding networks for circumfixation,
interdigitation, and n-bit incrementation. For circumfixation, we constructed networks
for the circumfixation of 1,043 Hebrew roots and 4 circumfixes. For interdigitation we
constructed a network accepting the splicing of 1,043 roots into 20 patterns. For n-bit
incrementation we constructed networks for 10-bit, 50-bit, and 100-bit incrementors.
Table 1 displays the size of each of the networks in terms of states, arcs, and actual file
size.
</bodyText>
<page confidence="0.995565">
78
</page>
<note confidence="0.833328">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<tableCaption confidence="0.998584">
Table 1
</tableCaption>
<table confidence="0.986011666666667">
Space comparison between FSAs and FSRAs.
Operation Network type States Arcs Registers File size
Circumfixation FSA 811 3,824 – 47kB
(4 circumfixes, 1,043 roots) FSRA 356 360 1 16kB
Interdigitation FSA 12,527 31,077 – 451kB
(20 patterns, 1,043 roots) FSRA 58 3,259 2 67kB
10-bit incrementor Sequential FST 268 322 – 7kB
FSRT 31 60 10 2kB
50-bit incrementor Sequential FST 23,328 24,602 – 600kB
FSRT 151 300 50 8kB
100-bit incrementor Sequential FST 176,653 181,702 – 4.73Mb
FSRT 301 600 100 17kB
</table>
<tableCaption confidence="0.991925">
Table 2
</tableCaption>
<table confidence="0.9827736">
Time comparison between FSAs and FSRAs.
200 words 1,000 words 5,000 words
Circumfixation FSA 0.01s 0.02s 0.08s
(4 circumfixes, 1,043 roots) FSRA 0.01s 0.02s 0.09s
Interdigitation FSA 0.01s 0.02s 1s
(20 patterns, 1,043 roots) FSRA 0.35s 1.42s 10.11s
10-bit incrementor Sequential FST 0.01s 0.05s 0.17s
FSRT 0.01s 0.06s 0.23s
50-bit incrementor Sequential FST 0.13s 0.2s 0.59s
FSRT 0.08s 0.4s 1.6s
</table>
<bodyText confidence="0.999827705882353">
Clearly, FSRAs provide a significant reduction in the network size. In particular, we
could not construct an n-bit incrementor FSA for any n greater than 100 as a result of
memory problems, whereas using FSRAs we had no problem constructing networks
even for n = 50, 000.
In addition, we compared the recognition times of the two models. For that purpose,
we used the circumfixation, interdigitation, 10-bit incrementation, and 50-bit incremen-
tation networks to analyze 200, 1,000, and 5,000 words. As can be seen in Table 2, time
performance is comparable for the two models, except for interdigitation, where FSAs
outperform FSRAs by a constant factor. The reason is that in this network the usage of
registers is massive and thereby, there is a higher cost to the reduction of the network
size, in terms of analysis time. This is an instance of the common tradeoff of time versus
space: FSRAs improve the network size at the cost of slower analysis time in some cases.
When using finite-state devices for natural language processing, often the generated
networks become too large to be practical. In such cases, using FSRAs can make network
size manageable. Using the closure constructions one can build desired networks of
reasonable size, and at the end decide whether to convert them to ordinary FSAs, if
time performance is an issue.
</bodyText>
<sectionHeader confidence="0.98389" genericHeader="conclusions">
8. Conclusions
</sectionHeader>
<bodyText confidence="0.997106">
In this work we introduce finite-state registered networks (automata and transducers),
an extension of finite-state networks which adds a limited amount of memory, in the
</bodyText>
<page confidence="0.990984">
79
</page>
<note confidence="0.570187">
Computational Linguistics Volume 32, Number 1
</note>
<bodyText confidence="0.9999849">
form of registers, to each transition. We show how FSRAs can be used to efficiently
model several non-concatenative morphological phenomena, including circumfixation,
root and pattern word formation in Semitic languages, vowel harmony, and limited
reduplication.
The main advantage of finite-state registered networks is their space efficiency. We
show that every FSA can be simulated by an equivalent FSRA with three states and
two registers. For the motivating linguistic examples, we show a significant decrease
in the number of states and the number of transitions. For example, to account for all
the possible combinations of r roots and p patterns, an ordinary FSA requires O(r × p)
arcs whereas an FSRA requires only O(r + p). As a non-linguistic example, we show
a transducer that computes n-bit increments of binary numbers. While an ordinary
(sequential) FST requires O(2n) states and arcs, an FSRT which guarantees linear recog-
nition time requires only O(n) states and arcs.
In spite of their efficiency, finite-state registered networks are equivalent, in terms
of their expressive power, to ordinary finite state networks. We provide an algorithm for
converting FSRAs to FSAs and prove the equivalence of the models. Furthermore, we
provide direct constructions of the main closure properties of FSAs for FSRAs, including
concatenation, union, intersection, and composition.
In order for finite-state networks to be useful for linguistic processing, we provide
a regular expression language denoting FSRAs. In particular, we provide a set of
extended regular expression operators that denote FSRAs and FSRTs. We demonstrate
the utility of the operators by accounting for a variety of complex morphological and
phonological phenomena, including circumfixation (Hebrew and German), root-and-
pattern (Hebrew), vowel harmony (Warlpiri), assimilation (Arabic), and limited redu-
plication. These dedicated operators can be used in conjunction with standard finite
state calculi, thereby providing a complete set of tools for the computational treatment
of non-concatenative morphology.
This work opens a variety of directions for future research. An immediate question
is the conversion of FSAs to FSRAs. While it is always possible to convert a given FSA
to an FSRA (simply add one register which is never used), we believe that it is possible
to automatically convert space inefficient FSAs to more compact FSRAs. A pre-requisite
is a clear understanding of the parameters for minimization: These include the number
of states, arcs, and registers, and the size of the register alphabet. For a given FSRA, the
number of states can always be reduced to a constant (theorem 3) and registers can be
done away with entirely (by converting the FSRA to an FSA, Section 3.1). In contrast,
minimizing the number of arcs in an FSRA is NP-hard (Section 3.4). A useful conversion
of FSAs to FSRAs must minimize some combination of these parameters, and while it
may be intractable in general, it can be practical in many special cases. In particular,
the case of finite languages (acyclic FSAs) is both of practical importance and — we
conjecture — can result in good compaction.
More work is also needed in order to establish more properties of FSRTs. In particu-
lar, we did not address issues such as sequentiality or sequentiability for this model.
Similarly, FSRA* can benefit from further research. All the closure constructions for
FSRA*s can be done in a similar way to FSRAs, with the exception of intersection. For in-
tersection, we believe that the use of predicates (van Noord and Gerdemann 2001b) can
be beneficial. Furthermore, the use of predicates can be beneficial for describing natural
language reduplication where the reduplication is not as bounded as the example we
deal with in this work. In addition, the FSRA* model can be extended into transducers.
Finally, in Section 7 we discuss an implementation of FSRAs. Although we have
used this system to construct networks for several phenomena, we are interested in
</bodyText>
<page confidence="0.964483">
80
</page>
<note confidence="0.471067">
Cohen-Sygal and Wintner Non-Concatenative Morphology
</note>
<bodyText confidence="0.999532833333333">
constructing a network for describing the complete morphology of a natural language
containing many non-concatenative phenomena, e.g., Hebrew. A morphological ana-
lyzer for Hebrew, based on finite-state calculi, already exists (Yona and Wintner 2005),
but is very space-inefficient and, therefore, hard to maintain. It would be beneficial to
compact such a network using FSRTs, and to inspect the time versus space tradeoff on
such a comprehensive network.
</bodyText>
<sectionHeader confidence="0.998114" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999720555555556">
We are grateful to Dale Gerdemann for his
help and inspiration. We thank Victor Harnik
and Nissim Francez for their comments on
an earlier version of this paper. We are also
thankful to the anonymous reviewers, whose
comments helped substantially to improve
this article. This research was supported by
The Israel Science Foundation (grant
no. 136/01).
</bodyText>
<sectionHeader confidence="0.999163" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99975704494382">
Beesley, Kenneth R. 1998. Constraining
separated morphotactic dependencies in
finite-state grammars. In Proceedings of
FSMNLP-98, pages 118–127, Bilkent,
Turkey.
Beesley, Kenneth R. and Lauri Karttunen.
2000. Finite-state non-concatenative
morphotactics. In Proceedings of the
Fifth Workshop of the ACL Special Interest
Group in Computational Phonology,
SIGPHON-2000, pages 1–12,
Luxembourg.
Beesley, Kenneth R. and Lauri Karttunen.
2003. Finite-State Morphology. CSLI
Publications.
Blank, Glenn D. 1985. A new kind of
finite-state automaton: Register vector
grammar. In Proceedings of the International
Joint Conference on Artificial Intelligence,
pages 749–755, UCLA.
Blank, Glenn D. 1989. A finite and real-time
processor for natural language.
Communications of the ACM,
32(10):1174–1189.
Cohen-Sygal, Yael. 2004. Computational
implementation of non-concatenative
morphology. Master’s thesis, Department
of Computer Science, University of Haifa,
Israel.
Holzer, Markus and Martin Kutrib. 2002.
State complexity of basic operations on
nondeterministic finite automata. In
Jean-Marc Champarnaud and Denis
Maurel, editors, Implementation and
Application of Automata, 7th International
Conference, CIAA 2002, volume 2608 of
Lecture Notes in Computer Science,
Springer, pages 148–157.
Kaminski, Michael and Nissim Francez.
1994. Finite memory automata. Theoretical
Computer Science, 134(2):329–364.
Kaplan, Ronald M. and Martin Kay. 1994.
Regular models of phonological rule
systems. Computational Linguistics,
20(3):331–378.
Karttunen, Lauri, Jean-Pierre Chanod,
Gregory Grefenstette, and Anne Schiller.
1996. Regular expressions for language
engineering. Natural Language Engineering,
2(4):305–328.
Kataja, Laura and Kimmo Koskenniemi.
1988. Finite-state description of Semitic
morphology: A case study of ancient
Akkadian. In Proceedings of COLING 88,
International Conference on Computational
Linguistics, pages 313–315, Budapest.
Kay, Martin. 1987. Nonconcatenative
finite-state morphology. In Proceedings of
the Third Conference of the European Chapter
of the Association for Computational
Linguistics, pages 2–10, Copenhagen,
Denmark.
Kiraz, George Anton. 2000. Multitiered
nonlinear morphology using multitape
finite automata: A case study on Syriac
and Arabic. Computational Linguistics,
26(1):77–105.
Kleene, S. C. 1956. Representation of events
in nerve nets and finite automata. In C. E.
Shannon and J. McCarthy, editors,
Automata Studies. Princeton University
Press, pages 3–42.
Kornai, Andr´as. 1996. Vectorized finite-state
automata. In Proceedings of the Workshop on
Extended Finite-State Models of Languages in
the 12th European Conference on Artificial
Intelligence, pages 36–41, Budapest.
Koskenniemi, Kimmo.1983. Two-Level
Morphology: A General Computational Model
for Word-Form Recognition and Production.
The Department of General Linguistics,
University of Helsinki.
Krauwer, Steven and Louis des Tombe.1981.
Transducers and grammars as theories of
language. Theoretical Linguistics, 8:173–202.
Lavie, Alon, Alon Itai, Uzzi Ornan, and Mori
Rimon. 1988. On the applicability of
two-level morphology to the inflection of
Hebrew verbs. Technical Report 513,
</reference>
<page confidence="0.963197">
81
</page>
<reference confidence="0.9867336">
Computational Linguistics Volume 32, Number 1
Department of Computer Science,
Technion, 32000 Haifa, Israel.
Mohri, Mehryar. 1996. On some applications
of finite-state automata theory to natural
language processing. Natural Language
Engineering, 2(1):61–80.
Mohri, Mehryar. 2000. Generic
epsilon-removal algorithm for weighted
automata. In Sheng Yu and Andrei Paun,
editors, 5th International Conference, CIAA
2000, volume 2088, Springer-Verlag,
pages 230–242.
Mohri, Mehryar, Fernando Pereira, and
Michael Riley. 2000. The design principles
of a weighted finite-state transducer
library. Theoretical Computer Science,
231(1):17–32.
Nash, David. 1980. Topics in Warlpiri
Grammar. Ph.D. thesis, Massachusetts
Institute of Technology.
Sproat, Richard W. 1992. Morphology and
Computation. MIT Press, Cambridge, MA.
van Noord, Gertjan and Dale Gerdemann.
2001a. An extendible regular expression
compiler for finite-state approaches in
natural language processing. In O. Boldt
and H. J¨urgensen, editors, Automata
Implementation, 4th International Workshop
on Implementing Automata, WIA’99,
Potsdam, Germany, Revised Papers,
number 2214 in Lecture Notes in Computer
Science. Springer.
van Noord, Gertjan and Dale Gerdemann.
2001b. Finite state transducers with
predicates and identity. Grammars,
4(3):263–286.
Walther, Markus. 2000a. Finite-state
reduplication in one-level prosodic
morphology. In Proceedings of
the First Conference of the North
American Chapter of the Association
for Computational Linguistics,
pages 296–302, Seattle.
Walther, Markus. 2000b. Temiar
reduplication in one-level prosodic
morphology. In Proceedings of
SIGPHON, Workshop on Finite-State
Phonology, pages 13–21, Luxembourg.
Yona, Shlomo and Shuly Wintner.
2005. A finite-state morphological
grammar of Hebrew. In Proceedings of
the ACL-2005 Workshop on Computational
Approaches to Semitic Languages,
Ann Arbor.
</reference>
<page confidence="0.999072">
82
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.715909">
<title confidence="0.995076">Finite-State Registered Automata</title>
<author confidence="0.745074">for Non-Concatenative Morphology</author>
<affiliation confidence="0.929357">University of Haifa University of Haifa</affiliation>
<abstract confidence="0.9976">We introduce finite-state registered automata (FSRAs), a new computational device within the framework of finite-state technology, specifically tailored for implementing non-concatenative morphological processes. This model extends and augments existing finite-state techniques, which are presently not optimized for describing this kind of phenomena. We first define the model and discuss its mathematical and computational properties. Then, we provide an extended regular language whose expressions denote FSRAs. Finally, we exemplify the utility of the model by providing several examples of complex morphological and phonological phenomena, which are elegantly implemented with FSRAs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
</authors>
<title>Constraining separated morphotactic dependencies in finite-state grammars.</title>
<date>1998</date>
<booktitle>In Proceedings of FSMNLP-98,</booktitle>
<pages>118--127</pages>
<location>Bilkent, Turkey.</location>
<contexts>
<context position="20253" citStr="Beesley (1998)" startWordPosition="3110" endWordPosition="3111">scent of Kaminski and Francez (1994) in the sense that it augments finite-state automata with finite memory (registers) in a restricted way, but we avoid the above-mentioned problem. In addition, our model supports a register alphabet that differs from the language alphabet, allowing the information stored in the registers to be more meaningful. Moreover, our transition relation is a more simplified extension of the standard one in FSAs, rendering our model a conservative extension of standard FSAs and allowing simple integration of existing networks with networks based on our model. Finally, Beesley (1998) directly addresses medium-distance dependencies between separated morphemes in words. He proposes a method, called flag diacritics, which adds features to symbols in regular expressions to enforce dependencies between separated parts of a string. The dependencies are forced by different kinds of unification actions. In this way, a small amount of finite memory is added, keeping the total size of the network relatively small. Unfortunately, this method is not formally defined, nor are its mathematical and computational properties proved. Furthermore, flag diacritics are manipulated at the leve</context>
</contexts>
<marker>Beesley, 1998</marker>
<rawString>Beesley, Kenneth R. 1998. Constraining separated morphotactic dependencies in finite-state grammars. In Proceedings of FSMNLP-98, pages 118–127, Bilkent, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
<author>Lauri Karttunen</author>
</authors>
<title>Finite-state non-concatenative morphotactics.</title>
<date>2000</date>
<booktitle>In Proceedings of the Fifth Workshop of the ACL Special Interest Group in Computational Phonology, SIGPHON-2000,</booktitle>
<pages>1--12</pages>
<contexts>
<context position="14909" citStr="Beesley and Karttunen (2000)" startWordPosition="2314" endWordPosition="2317">llow moving backwards within a string and thus repeat a part of it (to model reduplication). Skip arcs allow moving forwards in a string while suppressing the spell out of some of its letters; self loop arcs model infixation. In Walther (2000b), the above technique is used to describe Temiar Figure 4 4-tape representation for the Hebrew word htpqdut. 53 Computational Linguistics Volume 32, Number 1 Figure 5 4-tape automaton for circumfixation example. reduplication, but no complexity analysis of the model is given. Moreover, this technique does not seem to be able to describe interdigitation. Beesley and Karttunen (2000) describe a technique, called compile-replace, for constructing FSTs, which involves reapplying the regular-expression compiler to its own output. The compile-replace algorithm facilitates a compact definition of nonconcatenative morphological processes, but since such expressions compile to the naive networks, no space is saved. Furthermore, this is a compile-time mechanism rather than a theoretical and mathematically founded solution. Other works extend the FS model by enabling some sort of context-sensitivity. Blank (1985, 1989) presents a model, called Register Vector Grammar, introducing </context>
</contexts>
<marker>Beesley, Karttunen, 2000</marker>
<rawString>Beesley, Kenneth R. and Lauri Karttunen. 2000. Finite-state non-concatenative morphotactics. In Proceedings of the Fifth Workshop of the ACL Special Interest Group in Computational Phonology, SIGPHON-2000, pages 1–12, Luxembourg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
<author>Lauri Karttunen</author>
</authors>
<title>Finite-State Morphology.</title>
<date>2003</date>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="21069" citStr="Beesley and Karttunen (2003)" startWordPosition="3226" endWordPosition="3229">o enforce dependencies between separated parts of a string. The dependencies are forced by different kinds of unification actions. In this way, a small amount of finite memory is added, keeping the total size of the network relatively small. Unfortunately, this method is not formally defined, nor are its mathematical and computational properties proved. Furthermore, flag diacritics are manipulated at the level of the extended regular expressions, although it is clear that they are compiled into additional memory and operators in the networks themselves. The presentations of Beesley (1998) and Beesley and Karttunen (2003) do not explicate the implementation of such operators and do not provide an analysis of their complexity. Our approach is similar in spirit, but we provide a complete mathematical and computational analysis of such extended networks, including a proof that the model is indeed regular and constructions of the main closure properties. We also provide dedicated regular expression operations for non-concatenative processes and show 55 Computational Linguistics Volume 32, Number 1 how they are compiled into extended networks, thereby accounting for the motivating examples. 3. Finite-state Register</context>
<context position="56375" citStr="Beesley and Karttunen 2003" startWordPosition="9732" endWordPosition="9735">l way for defining regular languages. Regular language operations construct regular expressions in a convenient way. Several toolboxes (software packages) provide extended regular expression description languages and compil68 Cohen-Sygal and Wintner Non-Concatenative Morphology Figure 10 FSRA for a given CNF formula. ers of the expressions to finite-state devices, automata, and transducers (see Section 1). We provide a regular expression language for constructing FSRAs, the denotations of whose expressions are FSRAs. In the following discussion we assume the regular expression syntax of XFST (Beesley and Karttunen 2003) for basic expressions.7 Definition Let ActionsΓn = 1R, W} x 10, 1, 2, ... , n − 1} x Γ, where n is the number of registers and Γ is the register alphabet. If R is a regular expression and a~ E (ActionsΓ )+ is a series of n register operations, then the following are also regular expressions: a�&gt; R, a�&gt; DR, a�&lt; R, and a a a R. We now define the denotation of each of the above expressions. Let R be a regular expression whose denotation is the FSRA A, and let a~ E (ActionsΓ )+. The denotation n of a�&lt; R is an FSRA A&apos; obtained from A by adding a new node, q, which becomes the initial node of A&apos;, </context>
</contexts>
<marker>Beesley, Karttunen, 2003</marker>
<rawString>Beesley, Kenneth R. and Lauri Karttunen. 2003. Finite-State Morphology. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn D Blank</author>
</authors>
<title>A new kind of finite-state automaton: Register vector grammar.</title>
<date>1985</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence,</booktitle>
<pages>749--755</pages>
<contexts>
<context position="15439" citStr="Blank (1985" startWordPosition="2387" endWordPosition="2388">oes not seem to be able to describe interdigitation. Beesley and Karttunen (2000) describe a technique, called compile-replace, for constructing FSTs, which involves reapplying the regular-expression compiler to its own output. The compile-replace algorithm facilitates a compact definition of nonconcatenative morphological processes, but since such expressions compile to the naive networks, no space is saved. Furthermore, this is a compile-time mechanism rather than a theoretical and mathematically founded solution. Other works extend the FS model by enabling some sort of context-sensitivity. Blank (1985, 1989) presents a model, called Register Vector Grammar, introducing contextsensitivity by representing the states and transitions of finite-state automata as ternaryvalued vectors, which need not be fully specified. No formal properties of this model are discussed. In a similar vein, Kornai (1996) introduces vectorized finite-state automata, where both the states and the transitions are represented by vectors of elements of a partially ordered set. The vectors are manipulated by operations of unification and overwriting. The vectors need not be fully determined, as some of the elements can b</context>
</contexts>
<marker>Blank, 1985</marker>
<rawString>Blank, Glenn D. 1985. A new kind of finite-state automaton: Register vector grammar. In Proceedings of the International Joint Conference on Artificial Intelligence, pages 749–755, UCLA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn D Blank</author>
</authors>
<title>A finite and real-time processor for natural language.</title>
<date>1989</date>
<journal>Communications of the ACM,</journal>
<volume>32</volume>
<issue>10</issue>
<marker>Blank, 1989</marker>
<rawString>Blank, Glenn D. 1989. A finite and real-time processor for natural language. Communications of the ACM, 32(10):1174–1189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Cohen-Sygal</author>
</authors>
<title>Computational implementation of non-concatenative morphology.</title>
<date>2004</date>
<tech>Master’s thesis,</tech>
<institution>Department of Computer Science, University of Haifa,</institution>
<contexts>
<context position="10896" citStr="Cohen-Sygal (2004)" startWordPosition="1688" endWordPosition="1689">ounting for word inflection and regular verbal derivation. As this solution effectively defines lexical representations of word-forms, its main disadvantage is that the final network is the naive one, suffering from the space complexity problems discussed above. Lavie et al. (1988) examine the applicability of Two4 A complete explanation of the construction can be found in http://www.xrce.xerox.com/competencies/ content-analysis/fsCompiler/fsexamples.html#Add1. 5 Many of the formal proofs and constructions, especially the ones that are similar to the case of standard FSAs, are suppressed; see Cohen-Sygal (2004) for the complete proofs and constructions. 52 Cohen-Sygal and Wintner Non-Concatenative Morphology Level Morphology to the description of Hebrew Morphology, and in particular to verb inflection. Their lexicon consists of three parts: verb primary bases (the past tense, third person, singular, masculine), verb prefixes, and verb suffixes. They attempt to describe Hebrew verb inflection as a concatenation of prefix+base+suffix, implementable by the Two-Level model. However, they conclude that “The Two-Level rules are not the natural way to describe ... verb inflection process. The only alternat</context>
<context position="53515" citStr="Cohen-Sygal (2004)" startWordPosition="9183" endWordPosition="9184">egister operations are contradicting if at most one of them is satisfiable. Since the FSRA is optimized, each series of register operations is a concatenation of subseries, each operating on a different register; and the subseries operating on the i-th register must be either empty or ((W, i,7)) or ((R, i, 7)) or ((R, i,71), (W, i,72)). ((W, i,7)) contradicts neither ((R, i,7)) nor ((R,i,71), (W,i,72)). ((R,i,7)) and ((R, i, 71), (W, i, 72)) are contradicting only if 7 =� 71. 6 While this theorem is a part of folklore, we were unable to find a formal proof. We explicitly prove this theorem in Cohen-Sygal (2004). 67 Computational Linguistics Volume 32, Number 1 Definition An FSRA A = (Q, q0, Σ, Γ, n, k, δ, F), is linearized if it is optimized, a-free, and for all (q, σ, (~a), q1), (q, σ, (b), q2) E δ such that (a-) =� (0, where () = ((op11, i11,γ11),... , (op1 k, i1k,γ1k)) and (b) = ((opi,ii, γi), . . . , (op2m, i2m, γ2 m)) , there exists j1, 1 &lt; j1 &lt; k and there exists j2, 1 &lt; j2 &lt; m, such that op1j1 = op2j2 = R, i1j1 = i2j2 and γ1j1 =� γ2j2. A naive algorithm for converting a given FSRA into an equivalent linearized one is to convert it to an FSA and then determinize it. In the worst case, this res</context>
<context position="76715" citStr="Cohen-Sygal (2004)" startWordPosition="13356" endWordPosition="13357">asy to show that FSRTs, just like FSRAs, are equivalent to their non-registered counterparts. It immediately implies that FSRTs maintain the closure properties of regular relations. As in FSRAs, implementing the closure properties directly on FSRTs is essential for benefiting from their space efficiency. The common operators such as union, concatenation, etc., are implemented in the same ways as in FSRAs. A direct implementation of FSRT composition is a naive extension of ordinary transducer composition, based on the intersection construction of FSRAs. We explicitly define these operations in Cohen-Sygal (2004). 7. Implementation and Evaluation In order to practically compare the space and time performance of FSRAs and FSAs, we have implemented the special operators introduced in Sections 4 and 5 for circumfixation and interdigitation, as well as direct construction of FSRAs. We have compared FSRAs with ordinary FSAs by building corresponding networks for circumfixation, interdigitation, and n-bit incrementation. For circumfixation, we constructed networks for the circumfixation of 1,043 Hebrew roots and 4 circumfixes. For interdigitation we constructed a network accepting the splicing of 1,043 root</context>
</contexts>
<marker>Cohen-Sygal, 2004</marker>
<rawString>Cohen-Sygal, Yael. 2004. Computational implementation of non-concatenative morphology. Master’s thesis, Department of Computer Science, University of Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Holzer</author>
<author>Martin Kutrib</author>
</authors>
<title>State complexity of basic operations on nondeterministic finite automata.</title>
<date>2002</date>
<booktitle>In Jean-Marc Champarnaud and Denis Maurel, editors, Implementation and Application of Automata, 7th International Conference, CIAA 2002,</booktitle>
<volume>2608</volume>
<pages>148--157</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="40724" citStr="Holzer and Kutrib 2002" startWordPosition="6842" endWordPosition="6845"> Notice that register operations from 61 and 62 cannot be associated with the same register. This guarantees that no information is lost during the simulation of the two intersected automata. 3.2.5 Complementation. Ordinary FSAs are trivially closed under complementation. However, given an FSA A whose language is L(A), the minimal FSA recognizing the complement of L(A) can be exponentially large. More precisely, for any integer n &gt; 2, there exists a non-deterministic finite-state automaton (NFA) with n states A, such that any NFA that accepts the complement of L(A) needs at least 2n−2 states (Holzer and Kutrib 2002). We have no reason to believe that FSRAs will demonstrate a different behavior; therefore, we maintain that in the worst case, the best approach for complementing an FSRA would be to convert it into FSA and complement the latter. We therefore do not provide a dedicated construction for this operator. 3.3 Optimizations 3.3.1 c-removal. An c-arc in an FSRA is an arc of the form (s, c, (a), t) where a� is used as a meta-variable over (ActionsΓ )+ (i.e., a� represents a vector of register operations). n Notice that this kind of arc might occur in an FSRA by its definition. Given an FSRA that migh</context>
</contexts>
<marker>Holzer, Kutrib, 2002</marker>
<rawString>Holzer, Markus and Martin Kutrib. 2002. State complexity of basic operations on nondeterministic finite automata. In Jean-Marc Champarnaud and Denis Maurel, editors, Implementation and Application of Automata, 7th International Conference, CIAA 2002, volume 2608 of Lecture Notes in Computer Science, Springer, pages 148–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kaminski</author>
<author>Nissim Francez</author>
</authors>
<title>Finite memory automata.</title>
<date>1994</date>
<journal>Theoretical Computer Science,</journal>
<volume>134</volume>
<issue>2</issue>
<contexts>
<context position="18883" citStr="Kaminski and Francez (1994)" startWordPosition="2899" endWordPosition="2902">er of registers when comparing transducers and context free grammars with respect to their capabilities to describe languages. They sketch a proof showing that such transducers are equivalent to ordinary finite-state transducers. However, they never formally define the model and do not discuss its ability to efficiently implement non-concatenative natural languages phenomena. Moreover, they do not show how the closure properties can be implemented directly on these registered transducers, and do not provide any regular language denoting such transducers. Motivated by different considerations, Kaminski and Francez (1994) present a computational model which extends finite state automata to the case of infinite alphabets. This model is limited to recognizing only regular languages over infinite alphabets while maintaining closure under Kleene star and boolean operations, with the exception of closure under complementation. The familiar automaton is augmented with registers, used to store alphabet symbols, whose number is fixed for each automaton and can vary from one automaton to another. The model is designed to deal with infinite alphabets, and therefore it cannot distinguish between different symbols; it can</context>
</contexts>
<marker>Kaminski, Francez, 1994</marker>
<rawString>Kaminski, Michael and Nissim Francez. 1994. Finite memory automata. Theoretical Computer Science, 134(2):329–364.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="1044" citStr="Kaplan and Kay (1994)" startWordPosition="132" endWordPosition="135"> are presently not optimized for describing this kind of phenomena. We first define the model and discuss its mathematical and computational properties. Then, we provide an extended regular language whose expressions denote FSRAs. Finally, we exemplify the utility of the model by providing several examples of complex morphological and phonological phenomena, which are elegantly implemented with FSRAs. 1. Introduction Finite-state (FS) technology has been considered adequate for describing the morphological processes of the world’s languages since the pioneering works of Koskenniemi (1983) and Kaplan and Kay (1994). Several toolboxes provide extended regular expression description languages and compilers of the expressions to finite-state automata (FSAs) and transducers (FSTs) (Karttunen et al. 1996; Mohri 1996; van Noord and Gerdemann 2001a). While FS approaches to most natural languages have generally been very successful, it is widely recognized that they are less suitable for non-concatenative phenomena; in particular, FS techniques are assumed not to be able to efficiently account for the non-concatenative word formation processes that Semitic languages exhibit (Lavie et al. 1988). While much of th</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Kaplan, Ronald M. and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics, 20(3):331–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Jean-Pierre Chanod</author>
<author>Gregory Grefenstette</author>
<author>Anne Schiller</author>
</authors>
<title>Regular expressions for language engineering.</title>
<date>1996</date>
<journal>Natural Language Engineering,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="1232" citStr="Karttunen et al. 1996" startWordPosition="157" endWordPosition="160">r language whose expressions denote FSRAs. Finally, we exemplify the utility of the model by providing several examples of complex morphological and phonological phenomena, which are elegantly implemented with FSRAs. 1. Introduction Finite-state (FS) technology has been considered adequate for describing the morphological processes of the world’s languages since the pioneering works of Koskenniemi (1983) and Kaplan and Kay (1994). Several toolboxes provide extended regular expression description languages and compilers of the expressions to finite-state automata (FSAs) and transducers (FSTs) (Karttunen et al. 1996; Mohri 1996; van Noord and Gerdemann 2001a). While FS approaches to most natural languages have generally been very successful, it is widely recognized that they are less suitable for non-concatenative phenomena; in particular, FS techniques are assumed not to be able to efficiently account for the non-concatenative word formation processes that Semitic languages exhibit (Lavie et al. 1988). While much of the inflectional morphology of Semitic languages can be rather straightforwardly described using concatenation as the primary operation, the main word formation process in such languages is </context>
</contexts>
<marker>Karttunen, Chanod, Grefenstette, Schiller, 1996</marker>
<rawString>Karttunen, Lauri, Jean-Pierre Chanod, Gregory Grefenstette, and Anne Schiller. 1996. Regular expressions for language engineering. Natural Language Engineering, 2(4):305–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Kataja</author>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Finite-state description of Semitic morphology: A case study of ancient Akkadian.</title>
<date>1988</date>
<booktitle>In Proceedings of COLING 88, International Conference on Computational Linguistics,</booktitle>
<pages>313--315</pages>
<location>Budapest.</location>
<contexts>
<context position="10184" citStr="Kataja and Koskenniemi (1988)" startWordPosition="1587" endWordPosition="1590">ng for the motivating examples. In Section 6 we extend FSRAs to transducers. The model is evaluated through an actual implementation in Section 7. We conclude with suggestions for future research. 2. Related Work In spite of the common view that FS technology is in general inadequate for describing non-concatenative processes, several works address the above-mentioned problems in various ways. We summarize existing approaches in this section. Several works examine the applicability of traditional two-level systems for implementing non-concatenative morphology. Two-Level Morphology was used by Kataja and Koskenniemi (1988) to create a rule system for phonological and morphophonological alternations in Akkadian, accounting for word inflection and regular verbal derivation. As this solution effectively defines lexical representations of word-forms, its main disadvantage is that the final network is the naive one, suffering from the space complexity problems discussed above. Lavie et al. (1988) examine the applicability of Two4 A complete explanation of the construction can be found in http://www.xrce.xerox.com/competencies/ content-analysis/fsCompiler/fsexamples.html#Add1. 5 Many of the formal proofs and construc</context>
<context position="11906" citStr="Kataja and Koskenniemi (1988)" startWordPosition="1834" endWordPosition="1837">lection as a concatenation of prefix+base+suffix, implementable by the Two-Level model. However, they conclude that “The Two-Level rules are not the natural way to describe ... verb inflection process. The only alternative choice ... is to keep all bases ... it seems wasteful to save all the secondary bases of verbs of the same pattern.” Other works deal with non-concatenative morphology by extending ordinary FSAs without extending their expressivity. The traditional two-level model of Koskenniemi (1983) is expanded into n-tape automata by Kiraz (2000), following the insight of Kay (1987) and Kataja and Koskenniemi (1988). The idea is to use more than two levels of expression: The surface level employs one representation, but the lexical form employs multiple representations (e.g., root, pattern) and therefore can be divided into different levels, one for each representation. Elements that are separated on the surface (such as the root’s consonants) are adjacent on a particular lexical level. For example, to describe circumfixation using this model, a 4-tape automaton of the form (surface, PR pattern, circumfix, stem) is constructed, so that each word is represented by 4 levels. The surface level represents th</context>
</contexts>
<marker>Kataja, Koskenniemi, 1988</marker>
<rawString>Kataja, Laura and Kimmo Koskenniemi. 1988. Finite-state description of Semitic morphology: A case study of ancient Akkadian. In Proceedings of COLING 88, International Conference on Computational Linguistics, pages 313–315, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Nonconcatenative finite-state morphology.</title>
<date>1987</date>
<booktitle>In Proceedings of the Third Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>2--10</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="11872" citStr="Kay (1987)" startWordPosition="1831" endWordPosition="1832">Hebrew verb inflection as a concatenation of prefix+base+suffix, implementable by the Two-Level model. However, they conclude that “The Two-Level rules are not the natural way to describe ... verb inflection process. The only alternative choice ... is to keep all bases ... it seems wasteful to save all the secondary bases of verbs of the same pattern.” Other works deal with non-concatenative morphology by extending ordinary FSAs without extending their expressivity. The traditional two-level model of Koskenniemi (1983) is expanded into n-tape automata by Kiraz (2000), following the insight of Kay (1987) and Kataja and Koskenniemi (1988). The idea is to use more than two levels of expression: The surface level employs one representation, but the lexical form employs multiple representations (e.g., root, pattern) and therefore can be divided into different levels, one for each representation. Elements that are separated on the surface (such as the root’s consonants) are adjacent on a particular lexical level. For example, to describe circumfixation using this model, a 4-tape automaton of the form (surface, PR pattern, circumfix, stem) is constructed, so that each word is represented by 4 level</context>
</contexts>
<marker>Kay, 1987</marker>
<rawString>Kay, Martin. 1987. Nonconcatenative finite-state morphology. In Proceedings of the Third Conference of the European Chapter of the Association for Computational Linguistics, pages 2–10, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Anton Kiraz</author>
</authors>
<title>Multitiered nonlinear morphology using multitape finite automata: A case study</title>
<date>2000</date>
<booktitle>on Syriac and Arabic. Computational Linguistics,</booktitle>
<pages>26--1</pages>
<contexts>
<context position="11835" citStr="Kiraz (2000)" startWordPosition="1825" endWordPosition="1826">erb suffixes. They attempt to describe Hebrew verb inflection as a concatenation of prefix+base+suffix, implementable by the Two-Level model. However, they conclude that “The Two-Level rules are not the natural way to describe ... verb inflection process. The only alternative choice ... is to keep all bases ... it seems wasteful to save all the secondary bases of verbs of the same pattern.” Other works deal with non-concatenative morphology by extending ordinary FSAs without extending their expressivity. The traditional two-level model of Koskenniemi (1983) is expanded into n-tape automata by Kiraz (2000), following the insight of Kay (1987) and Kataja and Koskenniemi (1988). The idea is to use more than two levels of expression: The surface level employs one representation, but the lexical form employs multiple representations (e.g., root, pattern) and therefore can be divided into different levels, one for each representation. Elements that are separated on the surface (such as the root’s consonants) are adjacent on a particular lexical level. For example, to describe circumfixation using this model, a 4-tape automaton of the form (surface, PR pattern, circumfix, stem) is constructed, so tha</context>
<context position="13786" citStr="Kiraz (2000)" startWordPosition="2143" endWordPosition="2144">he same holds for the stem symbols. In this way, it is clear which symbols of the surface word belong to the circumfix, which belong to the stem, and how they combine together to create the final form of the word. The 4-tape automaton of Figure 5 accepts all the combinations created by circumfixing roots with the three circumfixes of Example 1. Each arc is attributed with a quadruplet, consisting of four correlating symbols in the four levels. Notice that as in FSAs, the paths encoding the roots are duplicated for each circumfix, so that this automaton is as spaceinefficient as ordinary FSAs. Kiraz (2000) does not discuss the space complexity of this model, but the number of states still seems to increase with the number of roots and patterns. Moreover, the n-tape model requires specification of dependencies between symbols in different levels, which may be non-trivial. Walther (2000a) suggests a solution for describing natural language reduplication using finite-state methods. The idea is to enrich finite-state automata with three new operations: repeat, skip, and self loops. Repeat arcs allow moving backwards within a string and thus repeat a part of it (to model reduplication). Skip arcs al</context>
</contexts>
<marker>Kiraz, 2000</marker>
<rawString>Kiraz, George Anton. 2000. Multitiered nonlinear morphology using multitape finite automata: A case study on Syriac and Arabic. Computational Linguistics, 26(1):77–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kleene</author>
</authors>
<title>Representation of events in nerve nets and finite automata.</title>
<date>1956</date>
<pages>3--42</pages>
<editor>In C. E. Shannon and J. McCarthy, editors,</editor>
<publisher>Princeton University Press,</publisher>
<contexts>
<context position="58300" citStr="Kleene (1956)" startWordPosition="10086" endWordPosition="10087">R operator. This operator has the same general effect as the previous one, but the transition relation in its FSRA uses fresh registers that are added to the machine. In a similar way, the operators a�&gt; R and a�&gt; &gt;R are translated into networks. The difference between these operators and the previous ones is that here, the register operations in a~ are executed after traversing all the arcs in the FSRA denoted by R. Using these additional operators, it is easy to show that every FSRA has a corresponding regular expression denoting it, by a trivial modification of the construction presented by Kleene (1956). Example 8 Consider the case of vowel harmony in Warlpiri (Sproat 1992), where the vowel of suffixes agrees in certain aspects with the vowel of the stem to which it is attached. 7 In particular, concatenation is denoted by juxtaposition and a is denoted by 0. 69 Computational Linguistics Volume 32, Number 1 A simplified account of the phenomenon is that suffixes come in two varieties, one with ‘i’ vowels and one with ‘u’ vowels. Stems whose last vowel is ‘i’ take suffixes of the first variety, whereas stems whose last vowel is ‘u’ or ‘a’ take the other variety. The following examples are fro</context>
</contexts>
<marker>Kleene, 1956</marker>
<rawString>Kleene, S. C. 1956. Representation of events in nerve nets and finite automata. In C. E. Shannon and J. McCarthy, editors, Automata Studies. Princeton University Press, pages 3–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´as Kornai</author>
</authors>
<title>Vectorized finite-state automata.</title>
<date>1996</date>
<booktitle>In Proceedings of the Workshop on Extended Finite-State Models of Languages in the 12th European Conference on Artificial Intelligence,</booktitle>
<pages>36--41</pages>
<location>Budapest.</location>
<contexts>
<context position="8068" citStr="Kornai (1996)" startWordPosition="1250" endWordPosition="1251">ational Linguistics Volume 32, Number 1 constructing Ln for a small number of different ns). An automaton that accepts Ln can be constructed by listing a path for each accepted string (since E and n are finite, the number of words in Ln is finite). The main drawback of such an automaton is the growth in its size as |E |and n increase: The number of strings in Ln is |E|n. Thus, finitestate techniques can account for limited reduplication, but the resulting networks are space-inefficient. As a final, non-linguistic, motivating example, consider the problem of n-bit incrementation, introduced by Kornai (1996). Example 4 The goal of this example is to construct a transducer over E = 10, 1} whose input is a 32 bit binary number and whose output is the result of adding 1 to the input. A transducer that performs addition by 1 on binary numbers has only 5 states and 12 arcs,4 but this transducer is neither sequential nor sequentiable. The problem is that since the input is scanned left to right but the carry moves right to left, the output of the first bit has to be delayed, possibly even until the last input bit is scanned. Thus, for an n-bit binary incrementor, 2n disjunctions have to be considered, </context>
<context position="15739" citStr="Kornai (1996)" startWordPosition="2431" endWordPosition="2432">oncatenative morphological processes, but since such expressions compile to the naive networks, no space is saved. Furthermore, this is a compile-time mechanism rather than a theoretical and mathematically founded solution. Other works extend the FS model by enabling some sort of context-sensitivity. Blank (1985, 1989) presents a model, called Register Vector Grammar, introducing contextsensitivity by representing the states and transitions of finite-state automata as ternaryvalued vectors, which need not be fully specified. No formal properties of this model are discussed. In a similar vein, Kornai (1996) introduces vectorized finite-state automata, where both the states and the transitions are represented by vectors of elements of a partially ordered set. The vectors are manipulated by operations of unification and overwriting. The vectors need not be fully determined, as some of the elements can be unknown (free). In this way information can be moved through the transitions by the overwriting operation and traversing these transitions can be sanctioned through the unification operation. As one of the examples of the advantages of this model, Kornai (1996) shows it can efficiently solve the p</context>
</contexts>
<marker>Kornai, 1996</marker>
<rawString>Kornai, Andr´as. 1996. Vectorized finite-state automata. In Proceedings of the Workshop on Extended Finite-State Models of Languages in the 12th European Conference on Artificial Intelligence, pages 36–41, Budapest.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kimmo 1983 Koskenniemi</author>
</authors>
<title>Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production. The Department of General Linguistics,</title>
<institution>University of Helsinki.</institution>
<marker>Koskenniemi, </marker>
<rawString>Koskenniemi, Kimmo.1983. Two-Level Morphology: A General Computational Model for Word-Form Recognition and Production. The Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Steven Krauwer</author>
<author>Louis des Tombe 1981</author>
</authors>
<title>Transducers and grammars as theories of language. Theoretical Linguistics,</title>
<pages>8--173</pages>
<marker>Krauwer, 1981, </marker>
<rawString>Krauwer, Steven and Louis des Tombe.1981. Transducers and grammars as theories of language. Theoretical Linguistics, 8:173–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Alon Itai</author>
<author>Uzzi Ornan</author>
<author>Mori Rimon</author>
</authors>
<title>On the applicability of two-level morphology to the inflection of Hebrew verbs.</title>
<date>1988</date>
<tech>Technical Report 513,</tech>
<contexts>
<context position="1626" citStr="Lavie et al. 1988" startWordPosition="215" endWordPosition="218">emi (1983) and Kaplan and Kay (1994). Several toolboxes provide extended regular expression description languages and compilers of the expressions to finite-state automata (FSAs) and transducers (FSTs) (Karttunen et al. 1996; Mohri 1996; van Noord and Gerdemann 2001a). While FS approaches to most natural languages have generally been very successful, it is widely recognized that they are less suitable for non-concatenative phenomena; in particular, FS techniques are assumed not to be able to efficiently account for the non-concatenative word formation processes that Semitic languages exhibit (Lavie et al. 1988). While much of the inflectional morphology of Semitic languages can be rather straightforwardly described using concatenation as the primary operation, the main word formation process in such languages is inherently non-concatenative. The standard account describes words in Semitic languages as combinations of two morphemes: a root and a pattern.1 The root consists of consonants only, by default three (although longer roots are known). The pattern is a combination of vowels and, possibly, consonants too, with “slots” into which the root consonants can be inserted. Words are created by interdi</context>
<context position="10560" citStr="Lavie et al. (1988)" startWordPosition="1643" endWordPosition="1646">ious ways. We summarize existing approaches in this section. Several works examine the applicability of traditional two-level systems for implementing non-concatenative morphology. Two-Level Morphology was used by Kataja and Koskenniemi (1988) to create a rule system for phonological and morphophonological alternations in Akkadian, accounting for word inflection and regular verbal derivation. As this solution effectively defines lexical representations of word-forms, its main disadvantage is that the final network is the naive one, suffering from the space complexity problems discussed above. Lavie et al. (1988) examine the applicability of Two4 A complete explanation of the construction can be found in http://www.xrce.xerox.com/competencies/ content-analysis/fsCompiler/fsexamples.html#Add1. 5 Many of the formal proofs and constructions, especially the ones that are similar to the case of standard FSAs, are suppressed; see Cohen-Sygal (2004) for the complete proofs and constructions. 52 Cohen-Sygal and Wintner Non-Concatenative Morphology Level Morphology to the description of Hebrew Morphology, and in particular to verb inflection. Their lexicon consists of three parts: verb primary bases (the past </context>
</contexts>
<marker>Lavie, Itai, Ornan, Rimon, 1988</marker>
<rawString>Lavie, Alon, Alon Itai, Uzzi Ornan, and Mori Rimon. 1988. On the applicability of two-level morphology to the inflection of Hebrew verbs. Technical Report 513,</rawString>
</citation>
<citation valid="false">
<date></date>
<volume>32</volume>
<institution>Computational Linguistics</institution>
<location>Technion, 32000 Haifa,</location>
<marker></marker>
<rawString>Computational Linguistics Volume 32, Number 1 Department of Computer Science, Technion, 32000 Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>On some applications of finite-state automata theory to natural language processing.</title>
<date>1996</date>
<journal>Natural Language Engineering,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="1244" citStr="Mohri 1996" startWordPosition="161" endWordPosition="162">sions denote FSRAs. Finally, we exemplify the utility of the model by providing several examples of complex morphological and phonological phenomena, which are elegantly implemented with FSRAs. 1. Introduction Finite-state (FS) technology has been considered adequate for describing the morphological processes of the world’s languages since the pioneering works of Koskenniemi (1983) and Kaplan and Kay (1994). Several toolboxes provide extended regular expression description languages and compilers of the expressions to finite-state automata (FSAs) and transducers (FSTs) (Karttunen et al. 1996; Mohri 1996; van Noord and Gerdemann 2001a). While FS approaches to most natural languages have generally been very successful, it is widely recognized that they are less suitable for non-concatenative phenomena; in particular, FS techniques are assumed not to be able to efficiently account for the non-concatenative word formation processes that Semitic languages exhibit (Lavie et al. 1988). While much of the inflectional morphology of Semitic languages can be rather straightforwardly described using concatenation as the primary operation, the main word formation process in such languages is inherently n</context>
</contexts>
<marker>Mohri, 1996</marker>
<rawString>Mohri, Mehryar. 1996. On some applications of finite-state automata theory to natural language processing. Natural Language Engineering, 2(1):61–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Generic epsilon-removal algorithm for weighted automata.</title>
<date>2000</date>
<booktitle>In Sheng Yu and Andrei Paun, editors, 5th International Conference, CIAA 2000,</booktitle>
<volume>volume</volume>
<pages>230--242</pages>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="43327" citStr="Mohri 2000" startWordPosition="7304" endWordPosition="7305"> (q1, 6, (a, b), q3), (q2, 6, ( b,&apos;c), q4), and (q1, 6, (a, b,&apos;c), q3), with all the c-arcs removed. This is illustrated in Figure 9. Notice that if q1 and q2 are the same state, then states q2 and q3 will be connected by two parallel arcs differing in their associated register operations; the same holds for states q2 and q4. Similarly, when q3 and q4 are the same state. In addition to the above changes, special care is needed for the case in which the empty word is accepted by the original automaton. The formal construction is similar in spirit to the c-removal paradigm in weighted automata (Mohri 2000), where weights along an c-path need to be gathered. Therefore, we suppress the formal construction and the proof of its correctness. 3.3.2 Optimizing Register Operations. In FSRAs, traversing an arc depends not only on the input symbol but also on satisfying the series of register operations. Sometimes, a given series of register operations can never be satisfied, and thus the arc to which it is attached cannot be traversed. For example, the series of register operations ((W,1, a), (R, 1, b)) can never be satisfied, hence an arc of the form (q1, 6, ((W,1, a), (R, 1, b)), q2) is redundant. In </context>
</contexts>
<marker>Mohri, 2000</marker>
<rawString>Mohri, Mehryar. 2000. Generic epsilon-removal algorithm for weighted automata. In Sheng Yu and Andrei Paun, editors, 5th International Conference, CIAA 2000, volume 2088, Springer-Verlag, pages 230–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando Pereira</author>
<author>Michael Riley</author>
</authors>
<title>The design principles of a weighted finite-state transducer library.</title>
<date>2000</date>
<journal>Theoretical Computer Science,</journal>
<volume>231</volume>
<issue>1</issue>
<marker>Mohri, Pereira, Riley, 2000</marker>
<rawString>Mohri, Mehryar, Fernando Pereira, and Michael Riley. 2000. The design principles of a weighted finite-state transducer library. Theoretical Computer Science, 231(1):17–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nash</author>
</authors>
<title>Topics in Warlpiri Grammar.</title>
<date>1980</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="58935" citStr="Nash (1980)" startWordPosition="10196" endWordPosition="10197"> case of vowel harmony in Warlpiri (Sproat 1992), where the vowel of suffixes agrees in certain aspects with the vowel of the stem to which it is attached. 7 In particular, concatenation is denoted by juxtaposition and a is denoted by 0. 69 Computational Linguistics Volume 32, Number 1 A simplified account of the phenomenon is that suffixes come in two varieties, one with ‘i’ vowels and one with ‘u’ vowels. Stems whose last vowel is ‘i’ take suffixes of the first variety, whereas stems whose last vowel is ‘u’ or ‘a’ take the other variety. The following examples are from Sproat (1992) (citing Nash (1980)): 1. maliki+kil.i+l.i+lki+ji+li (dog+PROP+ERG+then+me+they) 2. kud. u+kul.u+l.u+lku+ju+lu (child+PROP+ERG+then+me+they) 3. minija+kul.u+l.u+lku+ju+lu (cat+PROP+ERG+then+me+they) An FSRA that accepts the above three words is denoted by the following complex regular expression: define LexI [m a l i k i]; % words ending in ‘i’ define LexU [k u d u]; % words ending in ‘u’ define LexA [m i n i j a]; % words ending in ‘a’ ! Join all the lexicons and write to register 1 ‘u’ or ‘i’ ! according to the stem‘s last vowel. define Stem [&lt;(W,1,i)&gt; &lt; LexI] |[&lt;(W,1,u)&gt; &lt; [LexU |LexA]]; ! Traverse the arc onl</context>
</contexts>
<marker>Nash, 1980</marker>
<rawString>Nash, David. 1980. Topics in Warlpiri Grammar. Ph.D. thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard W Sproat</author>
</authors>
<title>Morphology and Computation.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="58372" citStr="Sproat 1992" startWordPosition="10098" endWordPosition="10099">, but the transition relation in its FSRA uses fresh registers that are added to the machine. In a similar way, the operators a�&gt; R and a�&gt; &gt;R are translated into networks. The difference between these operators and the previous ones is that here, the register operations in a~ are executed after traversing all the arcs in the FSRA denoted by R. Using these additional operators, it is easy to show that every FSRA has a corresponding regular expression denoting it, by a trivial modification of the construction presented by Kleene (1956). Example 8 Consider the case of vowel harmony in Warlpiri (Sproat 1992), where the vowel of suffixes agrees in certain aspects with the vowel of the stem to which it is attached. 7 In particular, concatenation is denoted by juxtaposition and a is denoted by 0. 69 Computational Linguistics Volume 32, Number 1 A simplified account of the phenomenon is that suffixes come in two varieties, one with ‘i’ vowels and one with ‘u’ vowels. Stems whose last vowel is ‘i’ take suffixes of the first variety, whereas stems whose last vowel is ‘u’ or ‘a’ take the other variety. The following examples are from Sproat (1992) (citing Nash (1980)): 1. maliki+kil.i+l.i+lki+ji+li (dog</context>
<context position="65614" citStr="Sproat (1992)" startWordPosition="11333" endWordPosition="11334"> is ((R,1, βi❑γi)). Notice that the concatenation operation, defined in Section 3.2.2, adjusts the register operations in the FSRAs to be concatenated, to avoid undesired effects caused by using joint registers. We use this operation to concatenate the three FSRAs, leaving register 1 unaffected (to handle the circumfix). Example 10 Consider the participle-forming combinations in German, e.g., the circumfix ge-t. A simplified account of the phenomenon is that German verbs in their present form take an n suffix but in participle form they take the circumfix ge-t. The following examples are from Sproat (1992): s¨auseln ‘rustle’ ges¨auselt ‘rustled’ br¨usten ‘brag’ gebr¨ustet ‘bragged’ The FSRA of Figure 11, which accepts the four forms, is denoted by the regular expression [s a¨u s e l |b r u¨ s t e] ® {(�❑n)(g e❑t)} This regular expression can be easily extended to accept more German verbs in other forms. More circumfixation phenomena in other languages such as Indonesian and Arabic can be modeled in the same way using this operator. Figure 11 Participle-forming combinations in German. 72 Cohen-Sygal and Wintner Non-Concatenative Morphology Example 11 Consider again Example 5. The FSRA accepting </context>
</contexts>
<marker>Sproat, 1992</marker>
<rawString>Sproat, Richard W. 1992. Morphology and Computation. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
<author>Dale Gerdemann</author>
</authors>
<title>An extendible regular expression compiler for finite-state approaches in natural language processing.</title>
<date>2001</date>
<booktitle>Automata Implementation, 4th International Workshop on Implementing Automata, WIA’99, Potsdam, Germany, Revised Papers, number 2214 in Lecture Notes in Computer Science.</booktitle>
<editor>In O. Boldt and H. J¨urgensen, editors,</editor>
<publisher>Springer.</publisher>
<marker>van Noord, Gerdemann, 2001</marker>
<rawString>van Noord, Gertjan and Dale Gerdemann. 2001a. An extendible regular expression compiler for finite-state approaches in natural language processing. In O. Boldt and H. J¨urgensen, editors, Automata Implementation, 4th International Workshop on Implementing Automata, WIA’99, Potsdam, Germany, Revised Papers, number 2214 in Lecture Notes in Computer Science. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
<author>Dale Gerdemann</author>
</authors>
<title>Finite state transducers with predicates and identity.</title>
<date>2001</date>
<journal>Grammars,</journal>
<volume>4</volume>
<issue>3</issue>
<marker>van Noord, Gerdemann, 2001</marker>
<rawString>van Noord, Gertjan and Dale Gerdemann. 2001b. Finite state transducers with predicates and identity. Grammars, 4(3):263–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Walther</author>
</authors>
<title>Finite-state reduplication in one-level prosodic morphology.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>296--302</pages>
<location>Seattle.</location>
<contexts>
<context position="14070" citStr="Walther (2000" startWordPosition="2187" endWordPosition="2188"> by circumfixing roots with the three circumfixes of Example 1. Each arc is attributed with a quadruplet, consisting of four correlating symbols in the four levels. Notice that as in FSAs, the paths encoding the roots are duplicated for each circumfix, so that this automaton is as spaceinefficient as ordinary FSAs. Kiraz (2000) does not discuss the space complexity of this model, but the number of states still seems to increase with the number of roots and patterns. Moreover, the n-tape model requires specification of dependencies between symbols in different levels, which may be non-trivial. Walther (2000a) suggests a solution for describing natural language reduplication using finite-state methods. The idea is to enrich finite-state automata with three new operations: repeat, skip, and self loops. Repeat arcs allow moving backwards within a string and thus repeat a part of it (to model reduplication). Skip arcs allow moving forwards in a string while suppressing the spell out of some of its letters; self loop arcs model infixation. In Walther (2000b), the above technique is used to describe Temiar Figure 4 4-tape representation for the Hebrew word htpqdut. 53 Computational Linguistics Volume </context>
</contexts>
<marker>Walther, 2000</marker>
<rawString>Walther, Markus. 2000a. Finite-state reduplication in one-level prosodic morphology. In Proceedings of the First Conference of the North American Chapter of the Association for Computational Linguistics, pages 296–302, Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Walther</author>
</authors>
<title>Temiar reduplication in one-level prosodic morphology.</title>
<date>2000</date>
<booktitle>In Proceedings of SIGPHON, Workshop on Finite-State Phonology,</booktitle>
<pages>13--21</pages>
<contexts>
<context position="14070" citStr="Walther (2000" startWordPosition="2187" endWordPosition="2188"> by circumfixing roots with the three circumfixes of Example 1. Each arc is attributed with a quadruplet, consisting of four correlating symbols in the four levels. Notice that as in FSAs, the paths encoding the roots are duplicated for each circumfix, so that this automaton is as spaceinefficient as ordinary FSAs. Kiraz (2000) does not discuss the space complexity of this model, but the number of states still seems to increase with the number of roots and patterns. Moreover, the n-tape model requires specification of dependencies between symbols in different levels, which may be non-trivial. Walther (2000a) suggests a solution for describing natural language reduplication using finite-state methods. The idea is to enrich finite-state automata with three new operations: repeat, skip, and self loops. Repeat arcs allow moving backwards within a string and thus repeat a part of it (to model reduplication). Skip arcs allow moving forwards in a string while suppressing the spell out of some of its letters; self loop arcs model infixation. In Walther (2000b), the above technique is used to describe Temiar Figure 4 4-tape representation for the Hebrew word htpqdut. 53 Computational Linguistics Volume </context>
</contexts>
<marker>Walther, 2000</marker>
<rawString>Walther, Markus. 2000b. Temiar reduplication in one-level prosodic morphology. In Proceedings of SIGPHON, Workshop on Finite-State Phonology, pages 13–21, Luxembourg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shlomo Yona</author>
<author>Shuly Wintner</author>
</authors>
<title>A finite-state morphological grammar of Hebrew.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL-2005 Workshop on Computational Approaches to Semitic Languages,</booktitle>
<location>Ann Arbor.</location>
<marker>Yona, Wintner, 2005</marker>
<rawString>Yona, Shlomo and Shuly Wintner. 2005. A finite-state morphological grammar of Hebrew. In Proceedings of the ACL-2005 Workshop on Computational Approaches to Semitic Languages, Ann Arbor.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>