<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006824">
<note confidence="0.9045535">
Proceedings of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), Philadelphia, July 2002, pp. 207-214.
</note>
<bodyText confidence="0.999895655172414">
the underlying semantics of a verb may be ex-
pressed differentially in the syntax across differ-
ent languages, easily extractable features may ex-
ist in one language for properties that are not
overtly expressed in another language. For ex-
ample, we have improved the classification of En-
glish verbs by augmenting the English feature set
with features based on Chinese translations of the
verbs, achieving an accuracy of 83.5% (compared
to 67.6% using English-only features), on a task
with a 33.3% baseline.
These two strands of research exploit crosslin-
guistic similarities and differences, respectively,
in verb behaviour with respect to semantic
classes. What unifies the two approaches is the
foundation of the method in a feature-based anal-
ysis of one of the primitive building blocks of
verbal semantics specifically, thematic roles
and an analysis of the mapping of roles to syn-
tactic positions. Because thematic roles capture
crosslinguistically valid properties of arguments,
the approach allows, in at least some cases, for
thematic-based features to be ported directly
across languages. At the same time, crosslinguis-
tic variation in the surface realization of verbal ar-
guments is well-attested, entailing that thematic
features from multiple languages have a poten-
tial increase in information over monolingual fea-
tures.
</bodyText>
<sectionHeader confidence="0.561175" genericHeader="method">
2 The Verb Classes and Features
</sectionHeader>
<bodyText confidence="0.999747705882353">
As in MS01, we define lexical semantic verb
classes according to argument structure that is,
the pattern of thematic roles, such as Agent or
Theme, that the verbs assign to their arguments,
and their mapping to syntactic positions. The
use of argument structure provides a semantic
level of classification, since it identifies the general
roles assigned to participants in the event. Due
to the strong correlation between argument struc-
ture and subcategorization (Pinker, 1989; Levin,
1993), it is important to show that the method
is indeed capturing the semantic level of argu-
ment structure and not just subcategorization.
Experiments are thus focused on classes which
have the same subcategorizations, and are distin-
guished instead by the content of thematic roles
assigned to their arguments.
</bodyText>
<subsectionHeader confidence="0.835913">
2.1 Optionally Intransitive Classes
</subsectionHeader>
<bodyText confidence="0.990763862068966">
Specifically, we have investigated several English
classes whose verbs can appear both transitively
and intransitively, but differ in argument struc-
ture. While our definition of classes is broader
than the fine-grained classification developed by
(Levin, 1993), argument structure classes gener-
ally correspond to her broader groupings of verbs
(such as, e.g., class 45 instead of 45.1 or 45.2).
In our case, we look at: manner of motion verbs
(Levin&apos;s class 51), change of state verbs (Levin&apos;s
45), verbs of creation and transformation (Levin&apos;s
26), and psychological state verbs (Levin&apos;s 31.2).&apos;
The classes exhibit the following transitive and
intransitive constructions:
Manner of motion:
The lion jumped through the hoop.
The trainer jumped the lion through the hoop.
Change of State:
The butter melted in the pan.
The cook melted the butter in the pan.
Creation/Transformation: (Object Drop)
The contractor built the houses last summer.
The contractor built all summer.2
Psychological State:
The rich love their money.
The rich love too.
Table 1 shows that each class is uniquely distin-
guished by the pattern of thematic roles assigned
within these constructions.3
</bodyText>
<table confidence="0.981789333333333">
Classes Transitive Intrans
Subj Obj Subj
Manner0fMotion CausalAg Ag Ag
ChangeOfState CausalAg Th Th
Creation/Trans Ag Th Ag
PsychState Exp Stim Exp
</table>
<tableCaption confidence="0.998676">
Table 1: Thematic Roles by Class.
</tableCaption>
<sectionHeader confidence="0.386314" genericHeader="method">
Ag=Agent, CausalAg=Causal Agent,
Th=Theme, Exp,Experiencer, Stim=Stimulus
</sectionHeader>
<subsectionHeader confidence="0.983898">
2.2 Preliminary Statistical Features
</subsectionHeader>
<bodyText confidence="0.99980425">
MS01 investigated the first three of these classes
in their monolingual work on English, develop-
ing 5 numeric features that encoded summary
statistics over the usage of each verb across the
</bodyText>
<footnote confidence="0.9826697">
1The latter is a specific subclass of Levin&apos;s, because
this is a case in which her subclasses differ in argument
structure.
2 Note that the progressive, The contractor was building
all summer, may be more natural in this usage.
3Manner of motion and change of state verbs have a
causative transitive form (e.g., Levin, 1993), in which the
subject argument of the intransitive form becomes the ob-
ject of the transitive, with the insertion of a Causal Agent
as the transitive subject.
</footnote>
<bodyText confidence="0.998863705882353">
Wall Street Journal (WSJ, 65M words).4 The
statistics were shown to approximate the verbs&apos;
thematic relations, either directly or indirectly.
(Note that all of the features were counts over
tagged or parsed text, with no semantic anno-
tation.) The features are: animacy of subject
(ANIM), relative frequency of transitive use, cal-
culated in several variants (ThANsitive, PAssive,
VBN POS tag), and use in a causative construc-
tion (cAus). We adopted these same features as
the starting point for our multilingual work, and
refer the interested reader to MS01 for more de-
tail on these initial features.
For each verb, the frequency distributions of
the features yield a vector that represents the es-
timated value of each feature across the entire
corpus, such as:
</bodyText>
<equation confidence="0.9321705">
Vector template:
[verb, TRANS, PASS, VBN, CAUS, ANIM, class]
Example:
[open, .69, .09, .21, .16, .36, ChangeOfState]
</equation>
<bodyText confidence="0.9996114">
These vectors are the (supervised) training data
for an automatic classifier to determine, given the
feature values for a new verb (not from the train-
ing set), which of the three classes of verbs it
belongs to.
</bodyText>
<sectionHeader confidence="0.9785435" genericHeader="method">
3 Verb Classification in Multiple
Languages
</sectionHeader>
<bodyText confidence="0.9998785">
The first necessary test of this verb classification
approach from the perspective of multilinguality
is to verify that the methodology indeed carries
over to languages other than English.
</bodyText>
<subsectionHeader confidence="0.986798">
3.1 Classes and Features
</subsectionHeader>
<bodyText confidence="0.994488454545455">
We selected two of the three classes origi-
nally studied for English change of state and
object drop (the more general set of verbs
with the same argument structure as the cre-
ation/transformation verbs, as noted above) to
show that the same classes could be distinguished
within a new language, Italian. We also added
the psych verbs, to study whether the method
would extend to a new class as well. The psych
verbs were chosen as the novel class because they
introduce new thematic roles Experiencer and
</bodyText>
<footnote confidence="0.983884">
4The original work on English studied &amp;quot;object drop&amp;quot;
verbs, a broader class than creation/transformation verbs,
but with the same argument structure. More recent in-
vestigations on English have used the more homogeneous
creation/transformation class (Joanis and Stevenson, In
preparation).
</footnote>
<bodyText confidence="0.990909153846154">
Stimulus that had not been previously investi-
gated.
We adopted the three core features used by
MS01, ANIM, CAUS, and TRANS, to test whether
the features that were developed to distinguish
change of state and object drop verbs in En-
glish would be useful to make the same class dis-
tinction in Italian. We also expected the CAUS
and ANIM features to be useful in distinguishing
the new class, psych verbs, from change of state
verbs. Specifically, in contrast to change of state
verbs, psych verbs do not undergo the causative
alternation, so the CAUS feature should be lower.
Also, the subjects of psych verbs (which are Ex-
periencers) are more likely to be animate than
those of change of state verbs, so the ANIM fea-
ture should be higher. To distinguish psych verbs
from object drop verbs, we note that psych verbs
are stative, while object drop verbs are not. We
added two features to capture this discriminating
aspectual property: PRES, a measure of present
tense use, which should be relatively higher for
stative verbs, and GERUN, a measure of the gerun-
dive, therefore of progressive use, which is an indi-
cator of non-stativity in both English and Italian
(Bertinetto, 1986).
</bodyText>
<subsectionHeader confidence="0.996048">
3.2 Materials and Methods
</subsectionHeader>
<bodyText confidence="0.9998198">
For our experimental set, we chose 20 Italian
verbs from each of the three classes; one verb
had to be removed later because of initial mis-
classification, leaving a total of 59 verbs. We
were guided in our choice of verbs by the orig-
inal English verbs studied by MS01 in the change
of state and object drop classes, and by the En-
glish verbs in the admire subclass from (Levin,
1993) for the psych verbs. When Italian transla-
tions of these verbs were low frequency (accord-
ing to (De Mauro, 1993)), we replaced the origi-
nal translation with a more frequent synonym or
antonym.
The feature counts for the 59 verbs were
collected from the Italian corpus Parole
(ftp://ftp.ilc.pi.cnr.it/pub/parole)
put at our disposal by the research group of
Nicoletta Calzolari, of the CNR of Pisa, who
also kindly extracted the initial verb usages for
us. This 21-million word corpus provides a rep-
resentative sample of the Italian language, from
newspapers, periodicals and books. Because the
corpus is untagged, it was required to extract
the features manually; thus, counts were limited
to the first 100 occurrences of each verb. (For
</bodyText>
<table confidence="0.997782222222222">
Features Used Acc SE
(%) (%)
TRANS CAUS ANIM PRES GERUN 85.1 0.3
TRANS CAUS ANIM PRES 85.1 0.3
TRANS CAUS ANIM GERUN 85.4 0.2
TRANS CAUS ANIM 86.4 0.3
TRANS ANIM 86.4 0.3
TRANS CAUS 75.0 0.3
ANIM CAUS 57.4 0.5
</table>
<tableCaption confidence="0.933799333333333">
Table 2: Classification Accuracy (Acc) and Stan-
dard Error (SE) using 10-Fold Crossvalidation
(50 repeats)
</tableCaption>
<bodyText confidence="0.98818075">
details of the extraction process, see (Allaria,
2001).)
The TRANS feature is the relative frequency of
transitive uses in the sample (i.e., uses followed by
direct object). The ANIM feature records the per-
centage of animate subjects. The CAUS feature
records the overlap of subjects and objects, as an
indication of participation in the causative alter-
nation. (For more details on the precise calcula-
tion of this feature see MS01.) PRES and GERUN
record the relative frequency of use of present
tense and gerundive in the sample.
</bodyText>
<subsectionHeader confidence="0.996045">
3.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.996506571428571">
The result of our data collection is a set of
59 vectors one set of features per verb with
which we train an automatic classifier for the
three verb classes. The baseline for this task
is 33.9%. We used the C5.0 machine learning
system (http://www.rulequest.com), a newer ver-
sion of C4.5 (Quinlan, 1992), which is a decision-
tree induction algorithm. We ran experiments us-
ing both crossvalidation and leave-one-out train-
ing and testing methodologies.
Table 2 shows the results of the crossvalidation
experiments. First, we note that the classification
achieves a very good accuracy, of 86.4%, for a 79%
reduction in error rate. These results compare
very favorably to the English experiments (which
had reached 69.8% accuracy for a somewhat dif-
ferent combination of classes, as described above,
with the same baseline accuracy).
Second, we note the unexpected result that
all the classification burden appears to be car-
ried by features that were developed for English.
This is indicated by the results in Table 2, which
shows performance as one feature at a time is
removed from the classification input. In fact,
only two features TRANS and ANIM result in
a decrease in classification performance when re-
moved. This is very surprising not only do the
features directly carry over to a new language,
but they carry over to a new class of verbs (the
psych verbs), which assigns different thematic
roles than the roles for which these features were
developed.
Table 3 summarizes the results of the leave-
one-out experiments, giving F-scores by class, on
combinations Of TRANS, ANIM, and CAUS. (F
is 2PR/(P+R), where P is precision and R is
recall.) These results confirm the observations
above. CAUS appears to not contribute to learn-
ing (line 2). ANIM is crucial for discriminating
the change of state and object drop verbs (line
3), while TRANS is critical for all three classes,
especially psych verbs (line 4).
</bodyText>
<table confidence="0.998224833333333">
Features Used Psych COS ObDrp
F F F
1. TRANS CAUS ANIM .89 .93 .81
2. TRANS ANIM .89 .93 .81
3. TRANS CAUS .89 .76 .57
4. ANIM CAUS 0 .70 .62
</table>
<tableCaption confidence="0.965646666666667">
Table 3: Class-by-Class F-scores using Leave-one-
out Methodology. COS=change of state; Ob-
Drp=object drop.
</tableCaption>
<bodyText confidence="0.9523892">
These results show that statistical verb classifi-
cation, based on argument structure features, has
demonstrated usefulness in multiple languages.
Moreover, not only the general methodology, but
at least some exact features are transferable from
one language to another. Furthermore, at least
some features generalize to verb class distinctions
for which they were not developed. This latter
observation is intriguing, as it suggests that the-
matic roles may be decomposable into more prim-
itive features (cf. (Dowty, 1991)) which our syn-
tactic indicators are tapping into. That is, the
ability of features to discriminate new roles may
be a function of how much those features reflect
underlying commonalities across thematic roles.
</bodyText>
<sectionHeader confidence="0.9097955" genericHeader="method">
4 Verb Classification Using
Multilingual Data
</sectionHeader>
<bodyText confidence="0.989966">
Our first strand of work above illustrates one im-
portant potential of a multilingual perspective on
verb classification, by demonstrating its crosslin-
guistic applicability. Here we turn to a very dif-
ferent perspective on multilinguality, in which we
exploit the power of data from multiple languages
(Chinese and English) in training a classifier for
verbs in a single language (English). The suc-
cess of the Italian experiments above rely on a
commonality of verb classes and verb behaviour
across languages. The work we describe here
also relies on an underlying semantic common-
ality of verbs across the two languages, but uses
the crosslinguistic differences in how that seman-
tics is expressed to augment the feature set used
in classification.
</bodyText>
<subsectionHeader confidence="0.945359">
4.1 Classes and Features
</subsectionHeader>
<bodyText confidence="0.999679428571429">
We started with the three English classes
manner of motion, change of state, and
creation/transformation and adopted all five of
the original features (TRANS, PASS, VBN, CAUS,
ANIM) from MS01. We then analysed translations
of these types of verbs in Chinese to determine
features that potentially discriminate among the
three classes. Note that we do not assume that
the Chinese translations fall into exactly the same
classification structure as the English verbs. Yet,
there must be sufficient similarity among the un-
derlying semantics of the verbs across the two lan-
guages for the syntactic features in Chinese to be
helpful in classifying the original English verbs.
The linguistic analysis of the Chinese verbs
led to the determination of the following types
of features: Chinese POS tags, passive parti-
cles, periphrastic (causative) particles, and var-
ious sublexical morphemic properties. The verb
tags and particles are overt expressions of seman-
tic information that is not expressed as clearly
in English.5 The verb tags assigned using the
POS tagger from the Chinese Knowledge In-
formation Processing Group (CKIP) incorporate
both subcategorization and active/stative infor-
mation (Liu et al., 1995; Tsao, 1996). The parti-
cles are overt indicators of the passive construc-
tion (an approximate indicator of transitivity, as
in English) and of the causative construction (a
more reliable version of the English CAUS indi-
cator). The morphemic properties indicate sub-
lexical properties such as the POS of subparts of
compound words, and resultative constructions.
(More detail on the analysis of the features, and
the data collection below, can be found in (Tsang
</bodyText>
<footnote confidence="0.96711325">
5For example, one possible translation for I cracked an
egg is Wo (I) jiang (periphrastic particle) clan (egg) da
Ian (crack), in which the periphrastic particle in Chinese
explicitly indicates a causative construction.
</footnote>
<bodyText confidence="0.9990935">
et al., 2002).) We experimented with these fea-
tures alone, and in combination with the English
features, to determine their usefulness in discrim-
inating the English verb classes.
</bodyText>
<subsectionHeader confidence="0.972954">
4.2 Materials and Methods
</subsectionHeader>
<bodyText confidence="0.999954514285714">
We chose 20 English verbs from each class, and
extracted their features from the British Na-
tional Corpus (BNC, 100M words), which had
been tagged (Brill, 1995) and chunked (Abney,
1996). We collected the Chinese data from
a portion of the Mandarin Chinese News Text
(MNews, People&apos;s Daily and Xinhua newswire
sections, 165M characters), from the Linguistic
Data Consortium, which was POS-tagged us-
ing the CKIP tagger mentioned above. From
MNews, we automatically extracted all Chinese
compounds with a verb POS-tag, and then se-
lected those that are translations of the 60 En-
glish verbs in the appropriate semantic meaning,
i.e., manner-of-motion, change-of-state, and cre-
ation/transformation. Note that because we are
not classifying the Chinese verbs, we can use mul-
tiple translations; the average number of trans-
lations per English verb is 6.5. The extracted
Chinese verbs were manually matched to their
English equivalents to form a translation set.
All counts were collected automatically. The
Chinese features were calculated as follows. The
CKIP feature is the relative frequency of each
of the possible verb tags. PASS-PRT and PERI-
PRT are the relative frequencies of the passive
and causative particles, respectively. A number
of features, such as V-V-COMPOUND and V-RES-
COMPOUND, are the relative frequencies of vari-
ous morpheme combinations. Features are calcu-
lated together over all the verbs in the translation
set of a given English verb. That is, if C1, ..., 2
are translations of the English verb Ej, then the
value of Chinese feature fk for Ej is the normal-
ized frequency of counts across all occurrences of
</bodyText>
<subsectionHeader confidence="0.994519">
4.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999826444444444">
The data for each of our machine learning experi-
ments consists of a vector of the relevant features
for each verb: we experiment with English data
only, Chinese data only, and English and Chinese
data combined. We use the resulting vectors as
the training data for the C5.0 classification sys-
tem, as above. Again, we used both 10-fold cross-
validation (repeated 50 times) and leave-one-out
training methodologies for our experiments. The
</bodyText>
<table confidence="0.997687125">
Features Used Acc SE
(%) (%)
All English 61.8 0.4
Best English: ANIM,TRANS 67.6 0.4
All Chinese 78.8 0.3
Best Chinese: CKIP 82.0 0.3
All English k, Chinese 81.0 0.5
Best combo: ANIM,TRANS,CKIP 83.5 0.5
</table>
<tableCaption confidence="0.835355333333333">
Table 4: Classification Accuracy (Acc) and Stan-
dard Error (SE) using 10-Fold Crossvalidation
(50 repeats)
</tableCaption>
<bodyText confidence="0.998836086956522">
baseline accuracy is 33.3%.
The key results of the crossvalidation experi-
ments are in Table 4, which shows the perfor-
mance for all the features in one or both lan-
guages, as well as the best combination of fea-
tures in one or both languages. There are several
interesting things to note. First, our main result
is that a multilingual set of features outperforms
either set of monolingual features on their own.
Specifically, the best performance is attained by
the combination of the English features ANIM and
TRANS, and the Chinese feature CKIP, yielding an
accuracy of 83.5% (error rate reduction of 75%).
The accuracy rate is significantly different from
the next highest accuracy of 82.0% &lt; .01, t-
test with Welch correction, 80df ). This is confir-
mation of our claim that simultaneous use of mul-
tilingual data can improve performance in verb
classification.
Second, the next best accuracy is attained by
a single Chinese feature, the CKIP verb tags. It
is remarkable that one feature can so successfully
distinguish the three classes; we believe it does
so because this set of Chinese POS tags directly
captures both syntactic (transitivity) and seman-
tic (active/stative) information; see (Tsang et al.,
2002) for more details. This is further evidence
that it is extremely helpful to look to multilin-
gual data for increasing the potential of syntac-
tic features in revealing semantic information in
Chinese, a straightforward POS tagger can ap-
parently yield data in the form of a single feature
that far outperforms the available English fea-
tures. (The best performance in MS01 on these
same classes was 69.8%.) Thus, this suggests
a strategy of choosing multiple languages from
which to elicit data, such that the languages are
complementary in their syntactic expression of
the underlying semantics of verbs.
Finally, it is worth noting that the features that
do best monolingually (ANIM, TRANS in English;
CKIP in Chinese), are also the best in combina-
tion. We have performed numerous experiments,
of which the above are only a small set, and
though there are some exceptions, this trend gen-
erally holds. This is also important, because it al-
lows a selective strategy in feature combination
we can try many features monolingually, and have
confidence that those that perform well will also
do well in multilingual combinations.
The class-by-class results of the leave-one-
out experiments on the combinations of ANIM,
TRANS, and CKIP, summarized using F-scores
(2PR/(P+R)), are reported in Table 5. The per-
formance confirms that the multilingual features
interact to give the best overall performance.
While removing CKIP improves performance on
manner of motion and change of state verbs, it de-
grades discrimination of creation/transformation
verbs quite a bit (line 2). On the other hand,
the removal of ANIM hurts both change of state
and creation/transformation verbs but improves
manner of motion verbs (line 3). The removal of
TRANS somewhat degrades both manner of mo-
tion and change of state verbs (line 4). Clearly,
the different features are detecting properties of
differential benefit to the three classes, and the
use of the three together apparently achieves the
best balance.
</bodyText>
<table confidence="0.998320166666667">
Features Used MOM COS C/T
F F F
1. TRANS ANIM CKIP .93 .90 .92
2. TRANS ANIM .95 .93 .87
3. TRANS CKIP .95 .86 .88
4. ANIM CKIP .90 .88 .92
</table>
<tableCaption confidence="0.995408">
Table 5: Class-by-Class F-scores using
</tableCaption>
<bodyText confidence="0.849276">
Leave-one-out Methodology. MOM=manner
of motion; COS=change of state;
C/T=creation/transformation.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999831558823529">
The use of multilingual corpora has been invalu-
able in several areas of NLP. For example, the un-
derlying commonality of semantics across a paral-
lel corpus has been shown to aid in word sense dis-
ambiguation (WSD) in (Ide, 2000) and (Resnik
and Yarowsky, 1999), a parallel corpus was used
as a source for lexicalizing some fine-grained En-
glish senses. The notion of transferability of infor-
mation such as syntactic mark-up has also been
pursued within parallel corpora (Yarowsky et al.,
2001). (Siegel and McKeown, 2000) suggested
a potential use of parallel corpora in learning the
aspectual classification (i.e., state or event) of En-
glish verbs; our results using Chinese (where the
verb tags which indirectly indicate such informa-
tion performed very well) would further encour-
age such an approach.
However, our multilingual approach does not
rest on the use of parallel corpora, and in that
sense is perhaps closer to the work of (Dagan
and Itai, 1994), which used statistical data from a
monolingual corpus to aid in WSD in a different
language. We have also taken inspiration from
work on Second Language Acquisition, in which
evidence of &amp;quot;transfer&amp;quot; of knowledge from a first
language when learning a second has been shown
to occur in the acquisition of verb class knowledge
(e.g., (Helms-Park, 2001; Juffs, 2000)). Finally,
both strands of our work have further connections
to the machine translation and lexical acquisition
work of Dorr and colleagues (e.g., (Dorr, 1993)),
which is founded on the notion of underlying se-
mantic commonalities among verbs as the key to
crosslinguistic mappings.
</bodyText>
<sectionHeader confidence="0.980245" genericHeader="conclusions">
6 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.998641985507247">
The multilingual framework discussed here
demonstrates the usefulness of verb classification
based on the underlying abstract notion of ar-
gument structure. This representation captures
typological similarities and supports the straight-
forward extension of an existing classifier to new
languages. Moreover, in combination with a
method that exploits surface differences between
languages, this representation gives rise to signif-
icant improvements in performance in the multi-
lingual experiments.
We have established that the general method
for automatic verb classification developed for
English is indeed directly useful in another lan-
guage, Italian. Moreover, because they capture
the typologically valid notion of thematic rela-
tion, the very statistical features that are most
useful in English are also most useful in Ital-
ian. These results indicate that these languages
do share an underlying level at which verbs can
be classified similarly. There are also practical
benefits from the observation of similarities. One
obstacle facing the use of automatic verb classifi-
cation has been the lack of a definitive classifica-
tion of verbs in languages other than English (as
in Levin, 1993). Our work allows the investiga-
tion of the extent to which the same features that
distinguish verb classes in English carry over to
other languages, yielding a practical method to
investigate Levin-type classes crosslinguistically.
One question that naturally arises is whether
classes are similar enough across many languages
for this method to really work. The results of the
experiments that use data from more than one
language give an indication. These experiments
exploit surface differences, providing varied views
of the same data to the learning algorithm, and
thus increasing the amount of available infor-
mation. But the usefulness of this information
depends on the features providing different ex-
pressions of the same underlying classification
otherwise different types of features would in-
stead give evidence for different spaces of classes
and lead to poor results. The biggest practical
benefit in using multilingual resources is the con-
siderable increase in available data, not just in
size, but in increased richness of information pro-
vided to the classifier through the combination of
features across languages.
One unexpected result which deserves atten-
tion is the cross-class validity of certain features.
We think that our indicators are approximate
and partial representations of the thematic roles,
and therefore pick out only some characteristics
of a role and not all. If roles are decompos-
able, instead of atomic labels, then the defining
characteristics can be shared by several roles (cf.
(Dowty, 1991)). This would explain why our indi-
cators generalise across classes in a more power-
ful way than expected. Thus, the apparent abil-
ity of certain indicators which were developed for
one class, and hence one type of thematic as-
signment, to become useful indicators for other
classes seems to suggest that the inventory of the-
matic roles that we have explored here should be
decomposed into finer-grained primitives. We are
currently exploring that approach, along with our
on-going investigation of other languages, and ad-
ditional verb classes.
</bodyText>
<sectionHeader confidence="0.992648" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.992527333333333">
We thank Remo Bindi from CNR Pisa who extracted
the Italian data for us, and Eric Joanis from the Uni-
versity of Toronto who extracted the English data.
We gratefully acknowledge the generous support of
NSERC of Canada, and of the Swiss NSF under
grant 11-65328.01.
</bodyText>
<sectionHeader confidence="0.995921" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998944396226415">
Steven Abney. 1996. Partial parsing via finite-
state cascades. In John Carroll, editor, Pro-
ceedings of the Workshop on Robust Pars-
ing (8th ESSLI), pages 8-15. Univ. of Sussex,
Brighton.
Gianluca Allaria. 2001. Automatic verb classifi-
cation: Experiments on Italian. Master&apos;s the-
sis, Univ. of Geneva.
Chinatsu Aone and Douglas McKee. 1996. Ac-
quiring predicate-argument mapping informa-
tion in multilingual texts. In B. Boguraev and
J. Pustejovsky, editors, Corpus Processing for
Lexical Acquisition, pages 191-202. MIT Press.
Pier Marco Bertinetto. 1986. Tempo, as-
petto e azione nel verbo italiano. Il sis-
tema delEindicativo. Accademia della Crusca,
Firenze.
Eric Brill. 1995. Transformation-based error-
driven learning and natural language process-
ing: a case study in part-of-speech tagging.
Computational Linguistics, 21(4):543-565.
Ido Dagan and Alon Itai. 1994. Word sense dis-
ambiguation using a second language mono-
lingual corpus. Computational Linguistics,
20(4):563-596.
Tullio De Mauro. 1993. Il grande dizionario
ital-
iano delEuso. UTET, Torino.
Bonnie Dorr. 1993. Machine Translation: A
View from the Lexicon. MIT Press.
David Dowty. 1991. Thematic proto-roles and
argument selection. Language, 67(3):563-596.
Rena Helms-Park. 2001. Evidence of lexical
transfer in learner syntax. Studies in Second
Language Acquisition, 2301:71-102.
Nancy Ide. 2000. Cross-lingual sense determina-
tion: Can it work? Computers and the Hu-
manities, 34:223-234.
Eric Joanis and Suzanne Stevenson. In prepa-
ration. A general feature space for auto-
matic verb classification. Manuscript, Univ. of
Toronto.
Alan Juffs. 2000. An overview of the second lan-
guage acquisition of links between verb seman-
tics and morpho-syntax. In J. Archibald, edi-
tor, Second Language Acquisition and Linguis-
tic Theory, pages 170-179. Blackwell.
Maria Lapata and Chris Brew. 1999. Using sub-
categorization to resolve verb class ambiguity.
In Proceedings of Joint EMNLP and Workshop
on Very Large Corpora, pages 266-274, College
Park, MD.
Beth Levin. 1993. English Verb Classes and Al-
ternations. Univ. of Chicago Press.
Shing-Huan Liu, Keh-jiann Chen, Li-ping Chang,
and Yeh-Hao Chin. 1995. Automatic part-of-
speech tagging for chinese corpora. Computer
Processing of Chinese and Oriental Languages,
9(1):31-47.
Diana McCarthy. 2000. Using semantic pref-
erences to identify verbal participation in
role switching alternations. In Proceedings of
ANLP/NAACL 2000, pages 256-263, Seattle,
WA.
Paola Merlo and Suzanne Stevenson. 2001. Au-
tomatic verb classification based on statistical
distributions of argument structure. Computa-
tional Linguistics, 27(3):393-408.
Steven Pinker. 1989. Learnability and Cognition:
The Acquisition of Argument Structure. MIT
Press, Cambridge, MA.
Ross Quinlan. 1992. C4.5 : Programs for ma-
chine learning. In Series in Machine Learning.
Morgan Kaufmann, San Mateo, CA.
Philip Resnik and David Yarowsky. 1999. Dis-
tinguishing systems and distinguishing senses:
New evaluation methods for word sense dis-
ambiguation. Natural Language Engineering,
5(2):113-133.
Philip Resnik. 1996. Selectional constraints: an
information-theoretic model and its computa-
tional realization. Cognition, 61(1-2):127-160.
Ellen Riloff and Mark Schmelzenbach. 1998. An
empirical approach to conceptual case frame
acquisition. In Proceedings of the Sixth Work-
shop on Very Large Corpora, pages 49-56.
Sabine Schulte im Walde. 2000. Clustering verbs
semantically according to their alternation be-
haviour. In Proceedings of COLING 2000,
pages 747-753, Saarbriicken, Germany.
Eric V. Siegel and Kathleen R. McKeown. 2000.
Learning methods to combine linguistic indica-
tors: Improving aspectual classification and re-
vealing linguistic insights. Computational Lin-
guistics, 26 (4 ) :595-628.
Vivian Tsang, Suzanne Stevenson, and Paola
Merlo. 2002. Crosslinguistic transfer in au-
tomatic verb classification. In Proceedings of
COLING 2002, Taipei, Taiwan. To appear.
Feng-fu Tsao. 1996. On verb classification
in Chinese. Journal of Chinese Linguistics,
24(1):138-191.
David Yarowsky, Grace Ngai, and Richard Wi-
centowski. 2001. Inducing multilingual text
analysis tools via robust projection across
aligned corpora. In Proceedings of HLT 2001.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.905538">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, July 2002, pp. 207-214.</note>
<abstract confidence="0.973299636363636">the underlying semantics of a verb may be expressed differentially in the syntax across different languages, easily extractable features may exist in one language for properties that are not overtly expressed in another language. For example, we have improved the classification of English verbs by augmenting the English feature set with features based on Chinese translations of the verbs, achieving an accuracy of 83.5% (compared to 67.6% using English-only features), on a task with a 33.3% baseline. These two strands of research exploit crosslinguistic similarities and differences, respectively, in verb behaviour with respect to semantic classes. What unifies the two approaches is the foundation of the method in a feature-based analysis of one of the primitive building blocks of verbal semantics specifically, thematic roles and an analysis of the mapping of roles to syntactic positions. Because thematic roles capture crosslinguistically valid properties of arguments, the approach allows, in at least some cases, for thematic-based features to be ported directly across languages. At the same time, crosslinguistic variation in the surface realization of verbal arguments is well-attested, entailing that thematic features from multiple languages have a potential increase in information over monolingual features. 2 The Verb Classes and Features As in MS01, we define lexical semantic verb classes according to argument structure that is, the pattern of thematic roles, such as Agent or Theme, that the verbs assign to their arguments, and their mapping to syntactic positions. The use of argument structure provides a semantic level of classification, since it identifies the general roles assigned to participants in the event. Due to the strong correlation between argument structure and subcategorization (Pinker, 1989; Levin, 1993), it is important to show that the method is indeed capturing the semantic level of argument structure and not just subcategorization. Experiments are thus focused on classes which have the same subcategorizations, and are distinguished instead by the content of thematic roles assigned to their arguments. 2.1 Optionally Intransitive Classes Specifically, we have investigated several English classes whose verbs can appear both transitively intransitively, but differ in argument structure. While our definition of classes is broader than the fine-grained classification developed by (Levin, 1993), argument structure classes generally correspond to her broader groupings of verbs (such as, e.g., class 45 instead of 45.1 or 45.2). In our case, we look at: manner of motion verbs (Levin&apos;s class 51), change of state verbs (Levin&apos;s 45), verbs of creation and transformation (Levin&apos;s 26), and psychological state verbs (Levin&apos;s 31.2).&apos; The classes exhibit the following transitive and intransitive constructions: Manner of motion: The lion jumped through the hoop. The trainer jumped the lion through the hoop. Change of State: The butter melted in the pan. The cook melted the butter in the pan. Creation/Transformation: (Object Drop) The contractor built the houses last summer. contractor built all Psychological State: The rich love their money. The rich love too. Table 1 shows that each class is uniquely distinguished by the pattern of thematic roles assigned these</abstract>
<title confidence="0.516331666666667">Classes Transitive Intrans Subj Obj Subj Manner0fMotion ChangeOfState Creation/Trans PsychState CausalAg Ag Th Th Stim Ag Th Ag Exp CausalAg Ag Exp</title>
<note confidence="0.85953875">Table 1: Thematic Roles by Class. Ag=Agent, CausalAg=Causal Agent, Stim=Stimulus 2.2 Preliminary Statistical Features</note>
<abstract confidence="0.940201835398231">MS01 investigated the first three of these classes in their monolingual work on English, developing 5 numeric features that encoded summary statistics over the usage of each verb across the latter is a specific subclass of Levin&apos;s, because this is a case in which her subclasses differ in argument structure. 2Note that the progressive, contractor was building summer, be more natural in this usage. of motion and change of state verbs have a causative transitive form (e.g., Levin, 1993), in which the subject argument of the intransitive form becomes the object of the transitive, with the insertion of a Causal Agent as the transitive subject. Street Journal (WSJ, 65M The statistics were shown to approximate the verbs&apos; thematic relations, either directly or indirectly. (Note that all of the features were counts over tagged or parsed text, with no semantic annotation.) The features are: animacy of subject (ANIM), relative frequency of transitive use, calculated in several variants (ThANsitive, PAssive, tag), and use in a causative construction (cAus). We adopted these same features as the starting point for our multilingual work, and refer the interested reader to MS01 for more detail on these initial features. For each verb, the frequency distributions of the features yield a vector that represents the estimated value of each feature across the entire corpus, such as: Vector template: PASS, VBN, CAUS, ANIM, Example: [open, .69, .09, .21, .16, .36, ChangeOfState] These vectors are the (supervised) training data for an automatic classifier to determine, given the feature values for a new verb (not from the training set), which of the three classes of verbs it belongs to. 3 Verb Classification in Multiple Languages The first necessary test of this verb classification approach from the perspective of multilinguality is to verify that the methodology indeed carries over to languages other than English. 3.1 Classes and Features selected two of the three classes originally studied for English change of state and object drop (the more general set of verbs the same argument structure as the creation/transformation verbs, as noted above) to show that the same classes could be distinguished within a new language, Italian. We also added the psych verbs, to study whether the method would extend to a new class as well. The psych verbs were chosen as the novel class because they introduce new thematic roles Experiencer and original work on English studied &amp;quot;object drop&amp;quot; verbs, a broader class than creation/transformation verbs, but with the same argument structure. More recent investigations on English have used the more homogeneous creation/transformation class (Joanis and Stevenson, In preparation). that had not been previously investigated. We adopted the three core features used by CAUS, to whether the features that were developed to distinguish change of state and object drop verbs in English would be useful to make the same class disin Italian. We also expected the to be useful in distinguishing the new class, psych verbs, from change of state verbs. Specifically, in contrast to change of state verbs, psych verbs do not undergo the causative so the should be lower. Also, the subjects of psych verbs (which are Experiencers) are more likely to be animate than of change of state verbs, so the feature should be higher. To distinguish psych verbs from object drop verbs, we note that psych verbs are stative, while object drop verbs are not. We added two features to capture this discriminating property: measure of present tense use, which should be relatively higher for verbs, and measure of the gerundive, therefore of progressive use, which is an indicator of non-stativity in both English and Italian (Bertinetto, 1986). 3.2 Materials and Methods experimental set, we chose 20 Italian verbs from each of the three classes; one verb had to be removed later because of initial misclassification, leaving a total of 59 verbs. We were guided in our choice of verbs by the original English verbs studied by MS01 in the change of state and object drop classes, and by the Enverbs in the from (Levin, 1993) for the psych verbs. When Italian translations of these verbs were low frequency (according to (De Mauro, 1993)), we replaced the original translation with a more frequent synonym or antonym. The feature counts for the 59 verbs were collected from the Italian corpus Parole (ftp://ftp.ilc.pi.cnr.it/pub/parole) put at our disposal by the research group of Nicoletta Calzolari, of the CNR of Pisa, who also kindly extracted the initial verb usages for us. This 21-million word corpus provides a representative sample of the Italian language, from newspapers, periodicals and books. Because the is untagged, it required to extract the features manually; thus, counts were limited to the first 100 occurrences of each verb. (For Features Used Acc SE (%) (%) TRANS CAUS ANIM PRES GERUN 85.1 0.3 TRANS CAUS ANIM PRES 85.1 0.3 TRANS CAUS ANIM GERUN 85.4 0.2 TRANS CAUS ANIM 86.4 0.3 TRANS ANIM 86.4 0.3 TRANS CAUS 75.0 0.3 ANIM CAUS 57.4 0.5 Table 2: Classification Accuracy (Acc) and Standard Error (SE) using 10-Fold Crossvalidation (50 repeats) details of the extraction process, see (Allaria, 2001).) The TRANS feature is the relative frequency of transitive uses in the sample (i.e., uses followed by direct object). The ANIM feature records the percentage of animate subjects. The CAUS feature records the overlap of subjects and objects, as an indication of participation in the causative alternation. (For more details on the precise calculation of this feature see MS01.) PRES and GERUN record the relative frequency of use of present tense and gerundive in the sample. 3.3 Experimental Results The result of our data collection is a set of 59 vectors one set of features per verb with which we train an automatic classifier for the three verb classes. The baseline for this task is 33.9%. We used the C5.0 machine learning system (http://www.rulequest.com), a newer version of C4.5 (Quinlan, 1992), which is a decisiontree induction algorithm. We ran experiments using both crossvalidation and leave-one-out training and testing methodologies. Table 2 shows the results of the crossvalidation experiments. First, we note that the classification achieves a very good accuracy, of 86.4%, for a 79% reduction in error rate. These results compare very favorably to the English experiments (which had reached 69.8% accuracy for a somewhat different combination of classes, as described above, with the same baseline accuracy). Second, we note the unexpected result that all the classification burden appears to be carried by features that were developed for English. This is indicated by the results in Table 2, which shows performance as one feature at a time is removed from the classification input. In fact, only two features TRANS and ANIM result in decrease in classification performance when removed. This is very surprising not only do the features directly carry over to a new language, but they carry over to a new class of verbs (the psych verbs), which assigns different thematic roles than the roles for which these features were developed. Table 3 summarizes the results of the leaveone-out experiments, giving F-scores by class, on combinations Of TRANS, ANIM, and CAUS. (F is 2PR/(P+R), where P is precision and R is recall.) These results confirm the observations above. CAUS appears to not contribute to learning (line 2). ANIM is crucial for discriminating the change of state and object drop verbs (line 3), while TRANS is critical for all three classes, especially psych verbs (line 4). Features Used Psych F COS F ObDrp F 1. TRANS CAUS ANIM .89 .93 .81 2. TRANS ANIM .89 .93 .81 3. TRANS CAUS .89 .76 .57 4. ANIM CAUS 0 .70 .62 Table 3: Class-by-Class F-scores using Leave-oneout Methodology. COS=change of state; Ob- Drp=object drop. These results show that statistical verb classification, based on argument structure features, has demonstrated usefulness in multiple languages. Moreover, not only the general methodology, but at least some exact features are transferable from one language to another. Furthermore, at least some features generalize to verb class distinctions for which they were not developed. This latter observation is intriguing, as it suggests that thematic roles may be decomposable into more primitive features (cf. (Dowty, 1991)) which our syntactic indicators are tapping into. That is, the ability of features to discriminate new roles may be a function of how much those features reflect underlying commonalities across thematic roles. 4 Verb Classification Using Multilingual Data Our first strand of work above illustrates one important potential of a multilingual perspective on verb classification, by demonstrating its crosslinapplicability. Here we turn to a very different perspective on multilinguality, in which we exploit the power of data from multiple languages (Chinese and English) in training a classifier for verbs in a single language (English). The success of the Italian experiments above rely on a commonality of verb classes and verb behaviour across languages. The work we describe here also relies on an underlying semantic commonality of verbs across the two languages, but uses crosslinguistic how that semantics is expressed to augment the feature set used in classification. 4.1 Classes and Features We started with the three English classes manner of motion, change of state, and creation/transformation and adopted all five of original features PASS, VBN, CAUS, MS01. We then analysed translations of these types of verbs in Chinese to determine features that potentially discriminate among the three classes. Note that we do not assume that the Chinese translations fall into exactly the same classification structure as the English verbs. Yet, there must be sufficient similarity among the underlying semantics of the verbs across the two languages for the syntactic features in Chinese to be helpful in classifying the original English verbs. The linguistic analysis of the Chinese verbs led to the determination of the following types of features: Chinese POS tags, passive particles, periphrastic (causative) particles, and various sublexical morphemic properties. The verb tags and particles are overt expressions of semantic information that is not expressed as clearly The verb tags assigned using the POS tagger from the Chinese Knowledge Information Processing Group (CKIP) incorporate both subcategorization and active/stative information (Liu et al., 1995; Tsao, 1996). The particles are overt indicators of the passive construction (an approximate indicator of transitivity, as in English) and of the causative construction (a reliable version of the English indicator). The morphemic properties indicate sublexical properties such as the POS of subparts of compound words, and resultative constructions. (More detail on the analysis of the features, and the data collection below, can be found in (Tsang example, one possible translation for cracked an (I) jiang (periphrastic particle) clan (egg) da (crack), which the periphrastic particle in Chinese explicitly indicates a causative construction. et al., 2002).) We experimented with these features alone, and in combination with the English features, to determine their usefulness in discriminating the English verb classes. 4.2 Materials and Methods We chose 20 English verbs from each class, and extracted their features from the British National Corpus (BNC, 100M words), which had been tagged (Brill, 1995) and chunked (Abney, 1996). We collected the Chinese data from a portion of the Mandarin Chinese News Text (MNews, People&apos;s Daily and Xinhua newswire sections, 165M characters), from the Linguistic Data Consortium, which was POS-tagged using the CKIP tagger mentioned above. From MNews, we automatically extracted all Chinese compounds with a verb POS-tag, and then selected those that are translations of the 60 English verbs in the appropriate semantic meaning, i.e., manner-of-motion, change-of-state, and creation/transformation. Note that because we are not classifying the Chinese verbs, we can use multiple translations; the average number of translations per English verb is 6.5. The extracted Chinese verbs were manually matched to their English equivalents to form a translation set. All counts were collected automatically. The Chinese features were calculated as follows. The is the relative frequency of each the possible verb tags. PERIthe relative frequencies of the passive and causative particles, respectively. A number features, such as V-RESthe relative frequencies of various morpheme combinations. Features are calculated together over all the verbs in the translation of a given English verb. That is, if ..., are translations of the English verb Ej, then the of Chinese feature Ej is the normalized frequency of counts across all occurrences of 4.3 Experimental Results The data for each of our machine learning experiments consists of a vector of the relevant features for each verb: we experiment with English data only, Chinese data only, and English and Chinese data combined. We use the resulting vectors as the training data for the C5.0 classification system, as above. Again, we used both 10-fold crossvalidation (repeated 50 times) and leave-one-out training methodologies for our experiments. The Features Used Acc SE (%) (%) All English 61.8 0.4 English: 67.6 0.4 All Chinese 78.8 0.3 Chinese: 82.0 0.3 English 81.0 0.5 combo: 83.5 0.5 Table 4: Classification Accuracy (Acc) and Standard Error (SE) using 10-Fold Crossvalidation (50 repeats) accuracy is The key results of the crossvalidation experiments are in Table 4, which shows the performance for all the features in one or both languages, as well as the best combination of features in one or both languages. There are several interesting things to note. First, our main result is that a multilingual set of features outperforms either set of monolingual features on their own. Specifically, the best performance is attained by combination of the English features the Chinese feature an accuracy of 83.5% (error rate reduction of 75%). The accuracy rate is significantly different from next highest accuracy of 82.0% test with Welch correction, 80df ). This is confirmation of our claim that simultaneous use of multilingual data can improve performance in verb classification. Second, the next best accuracy is attained by single Chinese feature, the tags. It is remarkable that one feature can so successfully distinguish the three classes; we believe it does so because this set of Chinese POS tags directly captures both syntactic (transitivity) and semantic (active/stative) information; see (Tsang et al., 2002) for more details. This is further evidence that it is extremely helpful to look to multilindata for increasing the potential of syntactic features in revealing semantic information in Chinese, a straightforward POS tagger can apparently yield data in the form of a single feature that far outperforms the available English features. (The best performance in MS01 on these same classes was 69.8%.) Thus, this suggests a strategy of choosing multiple languages from which to elicit data, such that the languages are complementary in their syntactic expression of the underlying semantics of verbs. Finally, it is worth noting that the features that best monolingually TRANS English; Chinese), are also the best in combination. We have performed numerous experiments, of which the above are only a small set, and though there are some exceptions, this trend generally holds. This is also important, because it allows a selective strategy in feature combination we can try many features monolingually, and have confidence that those that perform well will also do well in multilingual combinations. The class-by-class results of the leave-oneexperiments on the combinations of using F-scores (2PR/(P+R)), are reported in Table 5. The performance confirms that the multilingual features interact to give the best overall performance. removing performance on manner of motion and change of state verbs, it degrades discrimination of creation/transformation verbs quite a bit (line 2). On the other hand, removal of both change of state and creation/transformation verbs but improves manner of motion verbs (line 3). The removal of degrades both manner of motion and change of state verbs (line 4). Clearly, the different features are detecting properties of differential benefit to the three classes, and the use of the three together apparently achieves the best balance. Features Used MOM F COS F C/T F 1. TRANS ANIM CKIP .93 .90 .92 ANIM .95 .93 .87 CKIP .95 .86 .88 CKIP .90 .88 .92 Table 5: Class-by-Class F-scores using Leave-one-out Methodology. MOM=manner of motion; COS=change of state; C/T=creation/transformation. 5 Related Work The use of multilingual corpora has been invaluable in several areas of NLP. For example, the underlying commonality of semantics across a paralcorpus has been shown to aid in word sense disambiguation (WSD) in (Ide, 2000) and (Resnik and Yarowsky, 1999), a parallel corpus was used as a source for lexicalizing some fine-grained English senses. The notion of transferability of information such as syntactic mark-up has also been pursued within parallel corpora (Yarowsky et al., 2001). (Siegel and McKeown, 2000) suggested a potential use of parallel corpora in learning the aspectual classification (i.e., state or event) of English verbs; our results using Chinese (where the verb tags which indirectly indicate such information performed very well) would further encourage such an approach. However, our multilingual approach does not rest on the use of parallel corpora, and in that sense is perhaps closer to the work of (Dagan and Itai, 1994), which used statistical data from a monolingual corpus to aid in WSD in a different language. We have also taken inspiration from work on Second Language Acquisition, in which evidence of &amp;quot;transfer&amp;quot; of knowledge from a first language when learning a second has been shown to occur in the acquisition of verb class knowledge (e.g., (Helms-Park, 2001; Juffs, 2000)). Finally, both strands of our work have further connections to the machine translation and lexical acquisition work of Dorr and colleagues (e.g., (Dorr, 1993)), which is founded on the notion of underlying semantic commonalities among verbs as the key to crosslinguistic mappings. 6 Conclusions and Future Directions The multilingual framework discussed here demonstrates the usefulness of verb classification based on the underlying abstract notion of argument structure. This representation captures typological similarities and supports the straightforward extension of an existing classifier to new languages. Moreover, in combination with a method that exploits surface differences between languages, this representation gives rise to significant improvements in performance in the multilingual experiments. We have established that the general method for automatic verb classification developed for English is indeed directly useful in another language, Italian. Moreover, because they capture the typologically valid notion of thematic relation, the very statistical features that are most useful in English are also most useful in Italian. These results indicate that these languages do share an underlying level at which verbs can be classified similarly. There are also practical benefits from the observation of similarities. One obstacle facing the use of automatic verb classification has been the lack of a definitive classification of verbs in languages other than English (as in Levin, 1993). Our work allows the investigation of the extent to which the same features that distinguish verb classes in English carry over to other languages, yielding a practical method to investigate Levin-type classes crosslinguistically. One question that naturally arises is whether classes are similar enough across many languages for this method to really work. The results of the experiments that use data from more than one language give an indication. These experiments exploit surface differences, providing varied views of the same data to the learning algorithm, and thus increasing the amount of available information. But the usefulness of this information depends on the features providing different expressions of the same underlying classification otherwise different types of features would instead give evidence for different spaces of classes and lead to poor results. The biggest practical benefit in using multilingual resources is the considerable increase in available data, not just in size, but in increased richness of information provided to the classifier through the combination of features across languages. One unexpected result which deserves attention is the cross-class validity of certain features. We think that our indicators are approximate and partial representations of the thematic roles, and therefore pick out only some characteristics of a role and not all. If roles are decomposable, instead of atomic labels, then the defining characteristics can be shared by several roles (cf. (Dowty, 1991)). This would explain why our indicators generalise across classes in a more powerful way than expected. Thus, the apparent ability of certain indicators which were developed for one class, and hence one type of thematic assignment, to become useful indicators for other classes seems to suggest that the inventory of thematic roles that we have explored here should be decomposed into finer-grained primitives. We are currently exploring that approach, along with our on-going investigation of other languages, and additional verb classes. Acknowledgements We thank Remo Bindi from CNR Pisa who extracted the Italian data for us, and Eric Joanis from the University of Toronto who extracted the English data. We gratefully acknowledge the generous support of NSERC of Canada, and of the Swiss NSF under grant 11-65328.01. References Abney. 1996. Partial parsing via finitecascades. In John Carroll, editor, Proceedings of the Workshop on Robust Pars- (8th ESSLI), 8-15. Univ. of Sussex, Brighton. Gianluca Allaria. 2001. Automatic verb classification: Experiments on Italian. Master&apos;s thesis, Univ. of Geneva. Chinatsu Aone and Douglas McKee. 1996. Acquiring predicate-argument mapping information in multilingual texts. In B. Boguraev and Pustejovsky, editors, Processing for Acquisition, 191-202. MIT Press. Marco Bertinetto. 1986. aspetto e azione nel verbo italiano. Il sisdelEindicativo. della Crusca, Firenze. Eric Brill. 1995. Transformation-based errordriven learning and natural language processing: a case study in part-of-speech tagging. Linguistics, Ido Dagan and Alon Itai. 1994. Word sense disambiguation using a second language monocorpus. Linguistics, 20(4):563-596. De Mauro. 1993. Il dizionario italdelEuso. Torino. Dorr. 1993. Translation: from the Lexicon. Press. David Dowty. 1991. Thematic proto-roles and selection. Rena Helms-Park. 2001. Evidence of lexical in learner syntax. in Second Acquisition, Nancy Ide. 2000. Cross-lingual sense determina- Can it work? and the Hu- Eric Joanis and Suzanne Stevenson. In preparation. A general feature space for automatic verb classification. Manuscript, Univ. of Toronto. Alan Juffs. 2000. An overview of the second language acquisition of links between verb semantics and morpho-syntax. In J. Archibald, edi- Language Acquisition and Linguis- Theory, 170-179. Blackwell. Maria Lapata and Chris Brew. 1999. Using subcategorization to resolve verb class ambiguity.</abstract>
<note confidence="0.749083161290323">of Joint EMNLP and Workshop Very Large Corpora, 266-274, College Park, MD. Levin. 1993. Verb Classes and Alof Chicago Press. Shing-Huan Liu, Keh-jiann Chen, Li-ping Chang, and Yeh-Hao Chin. 1995. Automatic part-oftagging for chinese corpora. Processing of Chinese and Oriental Languages, 9(1):31-47. Diana McCarthy. 2000. Using semantic preferences to identify verbal participation in switching alternations. In of 256-263, Seattle, WA. Paola Merlo and Suzanne Stevenson. 2001. Automatic verb classification based on statistical of argument structure. Computa- Linguistics, Pinker. 1989. and Cognition: Acquisition of Argument Structure. Press, Cambridge, MA. Ross Quinlan. 1992. C4.5 : Programs for malearning. In in Machine Learning. Morgan Kaufmann, San Mateo, CA. Philip Resnik and David Yarowsky. 1999. Distinguishing systems and distinguishing senses: New evaluation methods for word sense dis- Language Engineering, 5(2):113-133. Philip Resnik. 1996. Selectional constraints: an</note>
<abstract confidence="0.77365536">information-theoretic model and its computarealization. Ellen Riloff and Mark Schmelzenbach. 1998. An empirical approach to conceptual case frame In of the Sixth Workon Very Large Corpora, 49-56. Sabine Schulte im Walde. 2000. Clustering verbs semantically according to their alternation be- In of COLING pages 747-753, Saarbriicken, Germany. Eric V. Siegel and Kathleen R. McKeown. 2000. Learning methods to combine linguistic indicators: Improving aspectual classification and relinguistic insights. Lin- (4 ) :595-628. Vivian Tsang, Suzanne Stevenson, and Paola Merlo. 2002. Crosslinguistic transfer in auverb classification. In of Taiwan. To appear. Feng-fu Tsao. 1996. On verb classification Chinese. of Chinese Linguistics, 24(1):138-191. David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across</abstract>
<intro confidence="0.659855">corpora. In of HLT</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Partial parsing via finitestate cascades. In</title>
<date>1996</date>
<booktitle>Proceedings of the Workshop on Robust Parsing (8th ESSLI),</booktitle>
<pages>8--15</pages>
<editor>John Carroll, editor,</editor>
<publisher>Univ. of</publisher>
<location>Sussex, Brighton.</location>
<contexts>
<context position="15783" citStr="Abney, 1996" startWordPosition="2526" endWordPosition="2527">g 5For example, one possible translation for I cracked an egg is Wo (I) jiang (periphrastic particle) clan (egg) da Ian (crack), in which the periphrastic particle in Chinese explicitly indicates a causative construction. et al., 2002).) We experimented with these features alone, and in combination with the English features, to determine their usefulness in discriminating the English verb classes. 4.2 Materials and Methods We chose 20 English verbs from each class, and extracted their features from the British National Corpus (BNC, 100M words), which had been tagged (Brill, 1995) and chunked (Abney, 1996). We collected the Chinese data from a portion of the Mandarin Chinese News Text (MNews, People&apos;s Daily and Xinhua newswire sections, 165M characters), from the Linguistic Data Consortium, which was POS-tagged using the CKIP tagger mentioned above. From MNews, we automatically extracted all Chinese compounds with a verb POS-tag, and then selected those that are translations of the 60 English verbs in the appropriate semantic meaning, i.e., manner-of-motion, change-of-state, and creation/transformation. Note that because we are not classifying the Chinese verbs, we can use multiple translations</context>
</contexts>
<marker>Abney, 1996</marker>
<rawString>Steven Abney. 1996. Partial parsing via finitestate cascades. In John Carroll, editor, Proceedings of the Workshop on Robust Parsing (8th ESSLI), pages 8-15. Univ. of Sussex, Brighton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gianluca Allaria</author>
</authors>
<title>Automatic verb classification: Experiments on Italian.</title>
<date>2001</date>
<tech>Master&apos;s thesis,</tech>
<institution>Univ. of Geneva.</institution>
<contexts>
<context position="9298" citStr="Allaria, 2001" startWordPosition="1486" endWordPosition="1487"> representative sample of the Italian language, from newspapers, periodicals and books. Because the corpus is untagged, it was required to extract the features manually; thus, counts were limited to the first 100 occurrences of each verb. (For Features Used Acc SE (%) (%) TRANS CAUS ANIM PRES GERUN 85.1 0.3 TRANS CAUS ANIM PRES 85.1 0.3 TRANS CAUS ANIM GERUN 85.4 0.2 TRANS CAUS ANIM 86.4 0.3 TRANS ANIM 86.4 0.3 TRANS CAUS 75.0 0.3 ANIM CAUS 57.4 0.5 Table 2: Classification Accuracy (Acc) and Standard Error (SE) using 10-Fold Crossvalidation (50 repeats) details of the extraction process, see (Allaria, 2001).) The TRANS feature is the relative frequency of transitive uses in the sample (i.e., uses followed by direct object). The ANIM feature records the percentage of animate subjects. The CAUS feature records the overlap of subjects and objects, as an indication of participation in the causative alternation. (For more details on the precise calculation of this feature see MS01.) PRES and GERUN record the relative frequency of use of present tense and gerundive in the sample. 3.3 Experimental Results The result of our data collection is a set of 59 vectors one set of features per verb with which w</context>
</contexts>
<marker>Allaria, 2001</marker>
<rawString>Gianluca Allaria. 2001. Automatic verb classification: Experiments on Italian. Master&apos;s thesis, Univ. of Geneva.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Douglas McKee</author>
</authors>
<title>Acquiring predicate-argument mapping information in multilingual texts.</title>
<date>1996</date>
<booktitle>Corpus Processing for Lexical Acquisition,</booktitle>
<pages>191--202</pages>
<editor>In B. Boguraev and J. Pustejovsky, editors,</editor>
<publisher>MIT Press.</publisher>
<marker>Aone, McKee, 1996</marker>
<rawString>Chinatsu Aone and Douglas McKee. 1996. Acquiring predicate-argument mapping information in multilingual texts. In B. Boguraev and J. Pustejovsky, editors, Corpus Processing for Lexical Acquisition, pages 191-202. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pier Marco Bertinetto</author>
</authors>
<title>Tempo, aspetto e azione nel verbo italiano. Il sistema delEindicativo. Accademia della Crusca,</title>
<date>1986</date>
<location>Firenze.</location>
<contexts>
<context position="7780" citStr="Bertinetto, 1986" startWordPosition="1227" endWordPosition="1228">ld be lower. Also, the subjects of psych verbs (which are Experiencers) are more likely to be animate than those of change of state verbs, so the ANIM feature should be higher. To distinguish psych verbs from object drop verbs, we note that psych verbs are stative, while object drop verbs are not. We added two features to capture this discriminating aspectual property: PRES, a measure of present tense use, which should be relatively higher for stative verbs, and GERUN, a measure of the gerundive, therefore of progressive use, which is an indicator of non-stativity in both English and Italian (Bertinetto, 1986). 3.2 Materials and Methods For our experimental set, we chose 20 Italian verbs from each of the three classes; one verb had to be removed later because of initial misclassification, leaving a total of 59 verbs. We were guided in our choice of verbs by the original English verbs studied by MS01 in the change of state and object drop classes, and by the English verbs in the admire subclass from (Levin, 1993) for the psych verbs. When Italian translations of these verbs were low frequency (according to (De Mauro, 1993)), we replaced the original translation with a more frequent synonym or antony</context>
</contexts>
<marker>Bertinetto, 1986</marker>
<rawString>Pier Marco Bertinetto. 1986. Tempo, aspetto e azione nel verbo italiano. Il sistema delEindicativo. Accademia della Crusca, Firenze.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based errordriven learning and natural language processing: a case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--4</pages>
<contexts>
<context position="15757" citStr="Brill, 1995" startWordPosition="2522" endWordPosition="2523">low, can be found in (Tsang 5For example, one possible translation for I cracked an egg is Wo (I) jiang (periphrastic particle) clan (egg) da Ian (crack), in which the periphrastic particle in Chinese explicitly indicates a causative construction. et al., 2002).) We experimented with these features alone, and in combination with the English features, to determine their usefulness in discriminating the English verb classes. 4.2 Materials and Methods We chose 20 English verbs from each class, and extracted their features from the British National Corpus (BNC, 100M words), which had been tagged (Brill, 1995) and chunked (Abney, 1996). We collected the Chinese data from a portion of the Mandarin Chinese News Text (MNews, People&apos;s Daily and Xinhua newswire sections, 165M characters), from the Linguistic Data Consortium, which was POS-tagged using the CKIP tagger mentioned above. From MNews, we automatically extracted all Chinese compounds with a verb POS-tag, and then selected those that are translations of the 60 English verbs in the appropriate semantic meaning, i.e., manner-of-motion, change-of-state, and creation/transformation. Note that because we are not classifying the Chinese verbs, we can</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based errordriven learning and natural language processing: a case study in part-of-speech tagging. Computational Linguistics, 21(4):543-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
</authors>
<title>Word sense disambiguation using a second language monolingual corpus.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="22430" citStr="Dagan and Itai, 1994" startWordPosition="3604" endWordPosition="3607"> English senses. The notion of transferability of information such as syntactic mark-up has also been pursued within parallel corpora (Yarowsky et al., 2001). (Siegel and McKeown, 2000) suggested a potential use of parallel corpora in learning the aspectual classification (i.e., state or event) of English verbs; our results using Chinese (where the verb tags which indirectly indicate such information performed very well) would further encourage such an approach. However, our multilingual approach does not rest on the use of parallel corpora, and in that sense is perhaps closer to the work of (Dagan and Itai, 1994), which used statistical data from a monolingual corpus to aid in WSD in a different language. We have also taken inspiration from work on Second Language Acquisition, in which evidence of &amp;quot;transfer&amp;quot; of knowledge from a first language when learning a second has been shown to occur in the acquisition of verb class knowledge (e.g., (Helms-Park, 2001; Juffs, 2000)). Finally, both strands of our work have further connections to the machine translation and lexical acquisition work of Dorr and colleagues (e.g., (Dorr, 1993)), which is founded on the notion of underlying semantic commonalities among </context>
</contexts>
<marker>Dagan, Itai, 1994</marker>
<rawString>Ido Dagan and Alon Itai. 1994. Word sense disambiguation using a second language monolingual corpus. Computational Linguistics, 20(4):563-596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tullio De Mauro</author>
</authors>
<title>Il grande dizionario italiano delEuso.</title>
<date>1993</date>
<publisher>UTET,</publisher>
<location>Torino.</location>
<marker>De Mauro, 1993</marker>
<rawString>Tullio De Mauro. 1993. Il grande dizionario italiano delEuso. UTET, Torino.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Dorr</author>
</authors>
<title>Machine Translation: A View from the Lexicon.</title>
<date>1993</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="22953" citStr="Dorr, 1993" startWordPosition="3689" endWordPosition="3690">allel corpora, and in that sense is perhaps closer to the work of (Dagan and Itai, 1994), which used statistical data from a monolingual corpus to aid in WSD in a different language. We have also taken inspiration from work on Second Language Acquisition, in which evidence of &amp;quot;transfer&amp;quot; of knowledge from a first language when learning a second has been shown to occur in the acquisition of verb class knowledge (e.g., (Helms-Park, 2001; Juffs, 2000)). Finally, both strands of our work have further connections to the machine translation and lexical acquisition work of Dorr and colleagues (e.g., (Dorr, 1993)), which is founded on the notion of underlying semantic commonalities among verbs as the key to crosslinguistic mappings. 6 Conclusions and Future Directions The multilingual framework discussed here demonstrates the usefulness of verb classification based on the underlying abstract notion of argument structure. This representation captures typological similarities and supports the straightforward extension of an existing classifier to new languages. Moreover, in combination with a method that exploits surface differences between languages, this representation gives rise to significant improv</context>
</contexts>
<marker>Dorr, 1993</marker>
<rawString>Bonnie Dorr. 1993. Machine Translation: A View from the Lexicon. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>Thematic proto-roles and argument selection.</title>
<date>1991</date>
<journal>Language,</journal>
<pages>67--3</pages>
<contexts>
<context position="12478" citStr="Dowty, 1991" startWordPosition="2009" endWordPosition="2010">s-by-Class F-scores using Leave-oneout Methodology. COS=change of state; ObDrp=object drop. These results show that statistical verb classification, based on argument structure features, has demonstrated usefulness in multiple languages. Moreover, not only the general methodology, but at least some exact features are transferable from one language to another. Furthermore, at least some features generalize to verb class distinctions for which they were not developed. This latter observation is intriguing, as it suggests that thematic roles may be decomposable into more primitive features (cf. (Dowty, 1991)) which our syntactic indicators are tapping into. That is, the ability of features to discriminate new roles may be a function of how much those features reflect underlying commonalities across thematic roles. 4 Verb Classification Using Multilingual Data Our first strand of work above illustrates one important potential of a multilingual perspective on verb classification, by demonstrating its crosslinguistic applicability. Here we turn to a very different perspective on multilinguality, in which we exploit the power of data from multiple languages (Chinese and English) in training a classif</context>
<context position="25832" citStr="Dowty, 1991" startWordPosition="4124" endWordPosition="4125"> multilingual resources is the considerable increase in available data, not just in size, but in increased richness of information provided to the classifier through the combination of features across languages. One unexpected result which deserves attention is the cross-class validity of certain features. We think that our indicators are approximate and partial representations of the thematic roles, and therefore pick out only some characteristics of a role and not all. If roles are decomposable, instead of atomic labels, then the defining characteristics can be shared by several roles (cf. (Dowty, 1991)). This would explain why our indicators generalise across classes in a more powerful way than expected. Thus, the apparent ability of certain indicators which were developed for one class, and hence one type of thematic assignment, to become useful indicators for other classes seems to suggest that the inventory of thematic roles that we have explored here should be decomposed into finer-grained primitives. We are currently exploring that approach, along with our on-going investigation of other languages, and additional verb classes. Acknowledgements We thank Remo Bindi from CNR Pisa who extr</context>
</contexts>
<marker>Dowty, 1991</marker>
<rawString>David Dowty. 1991. Thematic proto-roles and argument selection. Language, 67(3):563-596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rena Helms-Park</author>
</authors>
<title>Evidence of lexical transfer in learner syntax.</title>
<date>2001</date>
<booktitle>Studies in Second Language Acquisition,</booktitle>
<pages>2301--71</pages>
<contexts>
<context position="22779" citStr="Helms-Park, 2001" startWordPosition="3663" endWordPosition="3664">b tags which indirectly indicate such information performed very well) would further encourage such an approach. However, our multilingual approach does not rest on the use of parallel corpora, and in that sense is perhaps closer to the work of (Dagan and Itai, 1994), which used statistical data from a monolingual corpus to aid in WSD in a different language. We have also taken inspiration from work on Second Language Acquisition, in which evidence of &amp;quot;transfer&amp;quot; of knowledge from a first language when learning a second has been shown to occur in the acquisition of verb class knowledge (e.g., (Helms-Park, 2001; Juffs, 2000)). Finally, both strands of our work have further connections to the machine translation and lexical acquisition work of Dorr and colleagues (e.g., (Dorr, 1993)), which is founded on the notion of underlying semantic commonalities among verbs as the key to crosslinguistic mappings. 6 Conclusions and Future Directions The multilingual framework discussed here demonstrates the usefulness of verb classification based on the underlying abstract notion of argument structure. This representation captures typological similarities and supports the straightforward extension of an existing</context>
</contexts>
<marker>Helms-Park, 2001</marker>
<rawString>Rena Helms-Park. 2001. Evidence of lexical transfer in learner syntax. Studies in Second Language Acquisition, 2301:71-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
</authors>
<title>Cross-lingual sense determination: Can it work? Computers and the Humanities,</title>
<date>2000</date>
<pages>34--223</pages>
<contexts>
<context position="21702" citStr="Ide, 2000" startWordPosition="3488" endWordPosition="3489">the three classes, and the use of the three together apparently achieves the best balance. Features Used MOM COS C/T F F F 1. TRANS ANIM CKIP .93 .90 .92 2. TRANS ANIM .95 .93 .87 3. TRANS CKIP .95 .86 .88 4. ANIM CKIP .90 .88 .92 Table 5: Class-by-Class F-scores using Leave-one-out Methodology. MOM=manner of motion; COS=change of state; C/T=creation/transformation. 5 Related Work The use of multilingual corpora has been invaluable in several areas of NLP. For example, the underlying commonality of semantics across a parallel corpus has been shown to aid in word sense disambiguation (WSD) in (Ide, 2000) and (Resnik and Yarowsky, 1999), a parallel corpus was used as a source for lexicalizing some fine-grained English senses. The notion of transferability of information such as syntactic mark-up has also been pursued within parallel corpora (Yarowsky et al., 2001). (Siegel and McKeown, 2000) suggested a potential use of parallel corpora in learning the aspectual classification (i.e., state or event) of English verbs; our results using Chinese (where the verb tags which indirectly indicate such information performed very well) would further encourage such an approach. However, our multilingual </context>
</contexts>
<marker>Ide, 2000</marker>
<rawString>Nancy Ide. 2000. Cross-lingual sense determination: Can it work? Computers and the Humanities, 34:223-234.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
</authors>
<title>In preparation. A general feature space for automatic verb classification.</title>
<tech>Manuscript,</tech>
<institution>Univ. of Toronto.</institution>
<marker>Joanis, Stevenson, </marker>
<rawString>Eric Joanis and Suzanne Stevenson. In preparation. A general feature space for automatic verb classification. Manuscript, Univ. of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Juffs</author>
</authors>
<title>An overview of the second language acquisition of links between verb semantics and morpho-syntax.</title>
<date>2000</date>
<booktitle>Second Language Acquisition and Linguistic Theory,</booktitle>
<pages>170--179</pages>
<editor>In J. Archibald, editor,</editor>
<publisher>Blackwell.</publisher>
<contexts>
<context position="22793" citStr="Juffs, 2000" startWordPosition="3665" endWordPosition="3666">ectly indicate such information performed very well) would further encourage such an approach. However, our multilingual approach does not rest on the use of parallel corpora, and in that sense is perhaps closer to the work of (Dagan and Itai, 1994), which used statistical data from a monolingual corpus to aid in WSD in a different language. We have also taken inspiration from work on Second Language Acquisition, in which evidence of &amp;quot;transfer&amp;quot; of knowledge from a first language when learning a second has been shown to occur in the acquisition of verb class knowledge (e.g., (Helms-Park, 2001; Juffs, 2000)). Finally, both strands of our work have further connections to the machine translation and lexical acquisition work of Dorr and colleagues (e.g., (Dorr, 1993)), which is founded on the notion of underlying semantic commonalities among verbs as the key to crosslinguistic mappings. 6 Conclusions and Future Directions The multilingual framework discussed here demonstrates the usefulness of verb classification based on the underlying abstract notion of argument structure. This representation captures typological similarities and supports the straightforward extension of an existing classifier to</context>
</contexts>
<marker>Juffs, 2000</marker>
<rawString>Alan Juffs. 2000. An overview of the second language acquisition of links between verb semantics and morpho-syntax. In J. Archibald, editor, Second Language Acquisition and Linguistic Theory, pages 170-179. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
<author>Chris Brew</author>
</authors>
<title>Using subcategorization to resolve verb class ambiguity.</title>
<date>1999</date>
<booktitle>In Proceedings of Joint EMNLP and Workshop on Very Large Corpora,</booktitle>
<pages>266--274</pages>
<location>College Park, MD.</location>
<marker>Lapata, Brew, 1999</marker>
<rawString>Maria Lapata and Chris Brew. 1999. Using subcategorization to resolve verb class ambiguity. In Proceedings of Joint EMNLP and Workshop on Very Large Corpora, pages 266-274, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>Univ. of Chicago Press.</publisher>
<contexts>
<context position="1984" citStr="Levin, 1993" startWordPosition="302" endWordPosition="303">om multiple languages have a potential increase in information over monolingual features. 2 The Verb Classes and Features As in MS01, we define lexical semantic verb classes according to argument structure that is, the pattern of thematic roles, such as Agent or Theme, that the verbs assign to their arguments, and their mapping to syntactic positions. The use of argument structure provides a semantic level of classification, since it identifies the general roles assigned to participants in the event. Due to the strong correlation between argument structure and subcategorization (Pinker, 1989; Levin, 1993), it is important to show that the method is indeed capturing the semantic level of argument structure and not just subcategorization. Experiments are thus focused on classes which have the same subcategorizations, and are distinguished instead by the content of thematic roles assigned to their arguments. 2.1 Optionally Intransitive Classes Specifically, we have investigated several English classes whose verbs can appear both transitively and intransitively, but differ in argument structure. While our definition of classes is broader than the fine-grained classification developed by (Levin, 19</context>
<context position="4304" citStr="Levin, 1993" startWordPosition="657" endWordPosition="658">salAg=Causal Agent, Th=Theme, Exp,Experiencer, Stim=Stimulus 2.2 Preliminary Statistical Features MS01 investigated the first three of these classes in their monolingual work on English, developing 5 numeric features that encoded summary statistics over the usage of each verb across the 1The latter is a specific subclass of Levin&apos;s, because this is a case in which her subclasses differ in argument structure. 2 Note that the progressive, The contractor was building all summer, may be more natural in this usage. 3Manner of motion and change of state verbs have a causative transitive form (e.g., Levin, 1993), in which the subject argument of the intransitive form becomes the object of the transitive, with the insertion of a Causal Agent as the transitive subject. Wall Street Journal (WSJ, 65M words).4 The statistics were shown to approximate the verbs&apos; thematic relations, either directly or indirectly. (Note that all of the features were counts over tagged or parsed text, with no semantic annotation.) The features are: animacy of subject (ANIM), relative frequency of transitive use, calculated in several variants (ThANsitive, PAssive, VBN POS tag), and use in a causative construction (cAus). We a</context>
<context position="8190" citStr="Levin, 1993" startWordPosition="1303" endWordPosition="1304"> should be relatively higher for stative verbs, and GERUN, a measure of the gerundive, therefore of progressive use, which is an indicator of non-stativity in both English and Italian (Bertinetto, 1986). 3.2 Materials and Methods For our experimental set, we chose 20 Italian verbs from each of the three classes; one verb had to be removed later because of initial misclassification, leaving a total of 59 verbs. We were guided in our choice of verbs by the original English verbs studied by MS01 in the change of state and object drop classes, and by the English verbs in the admire subclass from (Levin, 1993) for the psych verbs. When Italian translations of these verbs were low frequency (according to (De Mauro, 1993)), we replaced the original translation with a more frequent synonym or antonym. The feature counts for the 59 verbs were collected from the Italian corpus Parole (ftp://ftp.ilc.pi.cnr.it/pub/parole) put at our disposal by the research group of Nicoletta Calzolari, of the CNR of Pisa, who also kindly extracted the initial verb usages for us. This 21-million word corpus provides a representative sample of the Italian language, from newspapers, periodicals and books. Because the corpus</context>
<context position="24302" citStr="Levin, 1993" startWordPosition="3889" endWordPosition="3890">loped for English is indeed directly useful in another language, Italian. Moreover, because they capture the typologically valid notion of thematic relation, the very statistical features that are most useful in English are also most useful in Italian. These results indicate that these languages do share an underlying level at which verbs can be classified similarly. There are also practical benefits from the observation of similarities. One obstacle facing the use of automatic verb classification has been the lack of a definitive classification of verbs in languages other than English (as in Levin, 1993). Our work allows the investigation of the extent to which the same features that distinguish verb classes in English carry over to other languages, yielding a practical method to investigate Levin-type classes crosslinguistically. One question that naturally arises is whether classes are similar enough across many languages for this method to really work. The results of the experiments that use data from more than one language give an indication. These experiments exploit surface differences, providing varied views of the same data to the learning algorithm, and thus increasing the amount of </context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations. Univ. of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shing-Huan Liu</author>
<author>Keh-jiann Chen</author>
<author>Li-ping Chang</author>
<author>Yeh-Hao Chin</author>
</authors>
<title>Automatic part-ofspeech tagging for chinese corpora.</title>
<date>1995</date>
<booktitle>Computer Processing of Chinese and Oriental Languages,</booktitle>
<pages>9--1</pages>
<contexts>
<context position="14712" citStr="Liu et al., 1995" startWordPosition="2355" endWordPosition="2358">ctic features in Chinese to be helpful in classifying the original English verbs. The linguistic analysis of the Chinese verbs led to the determination of the following types of features: Chinese POS tags, passive particles, periphrastic (causative) particles, and various sublexical morphemic properties. The verb tags and particles are overt expressions of semantic information that is not expressed as clearly in English.5 The verb tags assigned using the POS tagger from the Chinese Knowledge Information Processing Group (CKIP) incorporate both subcategorization and active/stative information (Liu et al., 1995; Tsao, 1996). The particles are overt indicators of the passive construction (an approximate indicator of transitivity, as in English) and of the causative construction (a more reliable version of the English CAUS indicator). The morphemic properties indicate sublexical properties such as the POS of subparts of compound words, and resultative constructions. (More detail on the analysis of the features, and the data collection below, can be found in (Tsang 5For example, one possible translation for I cracked an egg is Wo (I) jiang (periphrastic particle) clan (egg) da Ian (crack), in which the</context>
</contexts>
<marker>Liu, Chen, Chang, Chin, 1995</marker>
<rawString>Shing-Huan Liu, Keh-jiann Chen, Li-ping Chang, and Yeh-Hao Chin. 1995. Automatic part-ofspeech tagging for chinese corpora. Computer Processing of Chinese and Oriental Languages, 9(1):31-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Using semantic preferences to identify verbal participation in role switching alternations.</title>
<date>2000</date>
<booktitle>In Proceedings of ANLP/NAACL</booktitle>
<pages>256--263</pages>
<location>Seattle, WA.</location>
<marker>McCarthy, 2000</marker>
<rawString>Diana McCarthy. 2000. Using semantic preferences to identify verbal participation in role switching alternations. In Proceedings of ANLP/NAACL 2000, pages 256-263, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distributions of argument structure.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<pages>27--3</pages>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distributions of argument structure. Computational Linguistics, 27(3):393-408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Pinker</author>
</authors>
<title>Learnability and Cognition: The Acquisition of Argument Structure.</title>
<date>1989</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1970" citStr="Pinker, 1989" startWordPosition="300" endWordPosition="301">ic features from multiple languages have a potential increase in information over monolingual features. 2 The Verb Classes and Features As in MS01, we define lexical semantic verb classes according to argument structure that is, the pattern of thematic roles, such as Agent or Theme, that the verbs assign to their arguments, and their mapping to syntactic positions. The use of argument structure provides a semantic level of classification, since it identifies the general roles assigned to participants in the event. Due to the strong correlation between argument structure and subcategorization (Pinker, 1989; Levin, 1993), it is important to show that the method is indeed capturing the semantic level of argument structure and not just subcategorization. Experiments are thus focused on classes which have the same subcategorizations, and are distinguished instead by the content of thematic roles assigned to their arguments. 2.1 Optionally Intransitive Classes Specifically, we have investigated several English classes whose verbs can appear both transitively and intransitively, but differ in argument structure. While our definition of classes is broader than the fine-grained classification developed</context>
</contexts>
<marker>Pinker, 1989</marker>
<rawString>Steven Pinker. 1989. Learnability and Cognition: The Acquisition of Argument Structure. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross Quinlan</author>
</authors>
<title>C4.5 : Programs for machine learning.</title>
<date>1992</date>
<booktitle>In Series in Machine Learning.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="10103" citStr="Quinlan, 1992" startWordPosition="1621" endWordPosition="1622">eature records the overlap of subjects and objects, as an indication of participation in the causative alternation. (For more details on the precise calculation of this feature see MS01.) PRES and GERUN record the relative frequency of use of present tense and gerundive in the sample. 3.3 Experimental Results The result of our data collection is a set of 59 vectors one set of features per verb with which we train an automatic classifier for the three verb classes. The baseline for this task is 33.9%. We used the C5.0 machine learning system (http://www.rulequest.com), a newer version of C4.5 (Quinlan, 1992), which is a decisiontree induction algorithm. We ran experiments using both crossvalidation and leave-one-out training and testing methodologies. Table 2 shows the results of the crossvalidation experiments. First, we note that the classification achieves a very good accuracy, of 86.4%, for a 79% reduction in error rate. These results compare very favorably to the English experiments (which had reached 69.8% accuracy for a somewhat different combination of classes, as described above, with the same baseline accuracy). Second, we note the unexpected result that all the classification burden ap</context>
</contexts>
<marker>Quinlan, 1992</marker>
<rawString>Ross Quinlan. 1992. C4.5 : Programs for machine learning. In Series in Machine Learning. Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>David Yarowsky</author>
</authors>
<title>Distinguishing systems and distinguishing senses: New evaluation methods for word sense disambiguation.</title>
<date>1999</date>
<journal>Natural Language Engineering,</journal>
<pages>5--2</pages>
<contexts>
<context position="21734" citStr="Resnik and Yarowsky, 1999" startWordPosition="3491" endWordPosition="3494">s, and the use of the three together apparently achieves the best balance. Features Used MOM COS C/T F F F 1. TRANS ANIM CKIP .93 .90 .92 2. TRANS ANIM .95 .93 .87 3. TRANS CKIP .95 .86 .88 4. ANIM CKIP .90 .88 .92 Table 5: Class-by-Class F-scores using Leave-one-out Methodology. MOM=manner of motion; COS=change of state; C/T=creation/transformation. 5 Related Work The use of multilingual corpora has been invaluable in several areas of NLP. For example, the underlying commonality of semantics across a parallel corpus has been shown to aid in word sense disambiguation (WSD) in (Ide, 2000) and (Resnik and Yarowsky, 1999), a parallel corpus was used as a source for lexicalizing some fine-grained English senses. The notion of transferability of information such as syntactic mark-up has also been pursued within parallel corpora (Yarowsky et al., 2001). (Siegel and McKeown, 2000) suggested a potential use of parallel corpora in learning the aspectual classification (i.e., state or event) of English verbs; our results using Chinese (where the verb tags which indirectly indicate such information performed very well) would further encourage such an approach. However, our multilingual approach does not rest on the us</context>
</contexts>
<marker>Resnik, Yarowsky, 1999</marker>
<rawString>Philip Resnik and David Yarowsky. 1999. Distinguishing systems and distinguishing senses: New evaluation methods for word sense disambiguation. Natural Language Engineering, 5(2):113-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional constraints: an information-theoretic model and its computational realization.</title>
<date>1996</date>
<journal>Cognition,</journal>
<pages>61--1</pages>
<marker>Resnik, 1996</marker>
<rawString>Philip Resnik. 1996. Selectional constraints: an information-theoretic model and its computational realization. Cognition, 61(1-2):127-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Mark Schmelzenbach</author>
</authors>
<title>An empirical approach to conceptual case frame acquisition.</title>
<date>1998</date>
<booktitle>In Proceedings of the Sixth Workshop on Very Large Corpora,</booktitle>
<pages>49--56</pages>
<marker>Riloff, Schmelzenbach, 1998</marker>
<rawString>Ellen Riloff and Mark Schmelzenbach. 1998. An empirical approach to conceptual case frame acquisition. In Proceedings of the Sixth Workshop on Very Large Corpora, pages 49-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Clustering verbs semantically according to their alternation behaviour.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING 2000,</booktitle>
<pages>747--753</pages>
<location>Saarbriicken, Germany.</location>
<marker>Walde, 2000</marker>
<rawString>Sabine Schulte im Walde. 2000. Clustering verbs semantically according to their alternation behaviour. In Proceedings of COLING 2000, pages 747-753, Saarbriicken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric V Siegel</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Learning methods to combine linguistic indicators: Improving aspectual classification and revealing linguistic insights.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<pages>595--628</pages>
<contexts>
<context position="21994" citStr="Siegel and McKeown, 2000" startWordPosition="3532" endWordPosition="3535">ne-out Methodology. MOM=manner of motion; COS=change of state; C/T=creation/transformation. 5 Related Work The use of multilingual corpora has been invaluable in several areas of NLP. For example, the underlying commonality of semantics across a parallel corpus has been shown to aid in word sense disambiguation (WSD) in (Ide, 2000) and (Resnik and Yarowsky, 1999), a parallel corpus was used as a source for lexicalizing some fine-grained English senses. The notion of transferability of information such as syntactic mark-up has also been pursued within parallel corpora (Yarowsky et al., 2001). (Siegel and McKeown, 2000) suggested a potential use of parallel corpora in learning the aspectual classification (i.e., state or event) of English verbs; our results using Chinese (where the verb tags which indirectly indicate such information performed very well) would further encourage such an approach. However, our multilingual approach does not rest on the use of parallel corpora, and in that sense is perhaps closer to the work of (Dagan and Itai, 1994), which used statistical data from a monolingual corpus to aid in WSD in a different language. We have also taken inspiration from work on Second Language Acquisiti</context>
</contexts>
<marker>Siegel, McKeown, 2000</marker>
<rawString>Eric V. Siegel and Kathleen R. McKeown. 2000. Learning methods to combine linguistic indicators: Improving aspectual classification and revealing linguistic insights. Computational Linguistics, 26 (4 ) :595-628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivian Tsang</author>
<author>Suzanne Stevenson</author>
<author>Paola Merlo</author>
</authors>
<title>Crosslinguistic transfer in automatic verb classification.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING 2002,</booktitle>
<location>Taipei, Taiwan.</location>
<note>To appear.</note>
<contexts>
<context position="19201" citStr="Tsang et al., 2002" startWordPosition="3078" endWordPosition="3081">tion of 75%). The accuracy rate is significantly different from the next highest accuracy of 82.0% &lt; .01, ttest with Welch correction, 80df ). This is confirmation of our claim that simultaneous use of multilingual data can improve performance in verb classification. Second, the next best accuracy is attained by a single Chinese feature, the CKIP verb tags. It is remarkable that one feature can so successfully distinguish the three classes; we believe it does so because this set of Chinese POS tags directly captures both syntactic (transitivity) and semantic (active/stative) information; see (Tsang et al., 2002) for more details. This is further evidence that it is extremely helpful to look to multilingual data for increasing the potential of syntactic features in revealing semantic information in Chinese, a straightforward POS tagger can apparently yield data in the form of a single feature that far outperforms the available English features. (The best performance in MS01 on these same classes was 69.8%.) Thus, this suggests a strategy of choosing multiple languages from which to elicit data, such that the languages are complementary in their syntactic expression of the underlying semantics of verbs</context>
</contexts>
<marker>Tsang, Stevenson, Merlo, 2002</marker>
<rawString>Vivian Tsang, Suzanne Stevenson, and Paola Merlo. 2002. Crosslinguistic transfer in automatic verb classification. In Proceedings of COLING 2002, Taipei, Taiwan. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng-fu Tsao</author>
</authors>
<title>On verb classification in Chinese.</title>
<date>1996</date>
<journal>Journal of Chinese Linguistics,</journal>
<pages>24--1</pages>
<contexts>
<context position="14725" citStr="Tsao, 1996" startWordPosition="2359" endWordPosition="2360">hinese to be helpful in classifying the original English verbs. The linguistic analysis of the Chinese verbs led to the determination of the following types of features: Chinese POS tags, passive particles, periphrastic (causative) particles, and various sublexical morphemic properties. The verb tags and particles are overt expressions of semantic information that is not expressed as clearly in English.5 The verb tags assigned using the POS tagger from the Chinese Knowledge Information Processing Group (CKIP) incorporate both subcategorization and active/stative information (Liu et al., 1995; Tsao, 1996). The particles are overt indicators of the passive construction (an approximate indicator of transitivity, as in English) and of the causative construction (a more reliable version of the English CAUS indicator). The morphemic properties indicate sublexical properties such as the POS of subparts of compound words, and resultative constructions. (More detail on the analysis of the features, and the data collection below, can be found in (Tsang 5For example, one possible translation for I cracked an egg is Wo (I) jiang (periphrastic particle) clan (egg) da Ian (crack), in which the periphrastic</context>
</contexts>
<marker>Tsao, 1996</marker>
<rawString>Feng-fu Tsao. 1996. On verb classification in Chinese. Journal of Chinese Linguistics, 24(1):138-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proceedings of HLT</booktitle>
<contexts>
<context position="21966" citStr="Yarowsky et al., 2001" startWordPosition="3528" endWordPosition="3531">ss F-scores using Leave-one-out Methodology. MOM=manner of motion; COS=change of state; C/T=creation/transformation. 5 Related Work The use of multilingual corpora has been invaluable in several areas of NLP. For example, the underlying commonality of semantics across a parallel corpus has been shown to aid in word sense disambiguation (WSD) in (Ide, 2000) and (Resnik and Yarowsky, 1999), a parallel corpus was used as a source for lexicalizing some fine-grained English senses. The notion of transferability of information such as syntactic mark-up has also been pursued within parallel corpora (Yarowsky et al., 2001). (Siegel and McKeown, 2000) suggested a potential use of parallel corpora in learning the aspectual classification (i.e., state or event) of English verbs; our results using Chinese (where the verb tags which indirectly indicate such information performed very well) would further encourage such an approach. However, our multilingual approach does not rest on the use of parallel corpora, and in that sense is perhaps closer to the work of (Dagan and Itai, 1994), which used statistical data from a monolingual corpus to aid in WSD in a different language. We have also taken inspiration from work </context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of HLT 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>