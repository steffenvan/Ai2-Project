<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000045">
<note confidence="0.677395714285714">
AN EFFICIENT CONTEXT-FREE PARSER
FOR AUGMENTED PHRASE-STRUCTURE GRAMMARS
Massimo Marino*, Antonella Spiezio, Giacomo Ferrari*, Irina Prodanof+
*Linguistics Department, University of Pisa,
Via S. Maria 36, 1-56100 Pisa - Italy
+ Computational Linguistics Institute - Cnr
Via Della Faggiola 32,1-56100 Pisa - Italy
</note>
<sectionHeader confidence="0.893865" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9994944">
In this paper we present an efficient
context-free (CF) bottom-up, non deterministic
parser. It is an extension of the ICA (Immediate
Constituent Analysis) parser proposed by
Grishman (1976), and its major improvements
are described.
It has been designed to run Augmented
Phrase-Structure Grammars (APSG) and
performs semantic interpretation in parallel
with syntactic analysis.
It has been implemented in Franz Lisp and
runs on VAX 11/780 and, recently, also on a
SUN workstation, as the main component of a
transportable Natural Language Interface (SAIL
= Sistema per l&apos;Analisi e l&apos;Interpretazione del
Linguaggio). Subsets of grammars of italian
written in different formalisms and for
different applications have been experimented
with SAIL. In particular, a toy application has
been developed in which SAIL has been used as
interface to build a knowledge base in MRS
(Genesereth et at. 1980, Genesereth 1981)
about ski paths in a ski environment, and to ask
for advice about the best touristic path under
specific weather and physical conditions.
</bodyText>
<sectionHeader confidence="0.99906" genericHeader="introduction">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.9999573">
Many parsers for natural language have
been developed in the past, which run different
types of grammars. Among them, the most
successful are the CF grammars, the
augmented phrase-structure grammars
(APSGs), and the semantic grammars. All of
them have different characteristics and
different advantages. In particular APSGs offer
a natural tool for the treatment of certain
natural language phenomena, such as subject-
verb agreement. Semantic grammars are prone
to a compositional algorithm for semantic
interpretation.
The aim of our work is to implement a
parser which associates the full extension of
an APSG to compositionality of semantics. The
parser relies on the well stabilized ICA
algorithm. This association allows a wide range
of applications in syntactic/semantic analyses
together with the efficiency of a CF parser.
</bodyText>
<sectionHeader confidence="0.855857" genericHeader="method">
2. Functional description of the
parsing algorithm
</sectionHeader>
<bodyText confidence="0.984329714285714">
The parsing algorithm consists of the
following modules:
- a preprocessor;
- a parser itself;
- a post-processor and interpreter;
and interacts with:
- a dictionary, which is used by the
preprocessor;
- the grammar, used by the parser.
Figure 1 shows the structure of the system we
have designed. Some of the modules, such as
the spelling corrector, the robusteness
component, and the NL answer generator, are
still being developed.
</bodyText>
<subsectionHeader confidence="0.992232">
2.1. The dictionary
</subsectionHeader>
<bodyText confidence="0.9832911875">
The dictionary contains the &apos;word-forms&apos;,
known to the interface, with the following
associated information, called &apos;interpretation&apos;:
- syntactic category;
- semantic value;
- syntactic features as gender, number, etc.;
A form can be single (a single word) Or
multiple (more than one word). Multiple forms
are frequent in natural language and are in
general referred to as &apos;idioms&apos;. However, in
semantic grammars, the use of multiple words
is wider than in syntactic ones as also some
simpler phrases may be more conveniently
treated in the dictionary. This is the reason
why multiple forms are treated by specific
algorithms which optimize storage and search.
</bodyText>
<page confidence="0.986687">
196
</page>
<bodyText confidence="0.9795256">
The description of this algorithm is not the aim The set of rules of a grammar is partitioned
of this paper. an example of such a into packets of rules sharing the same
Figure 2 shows contains the single forms rightmost symbol of the &lt;RIGHT-PATTERN&gt; of
dictionary, which conjunction), e&apos; (is), noto productions. This partitioning makes their
che (that as the multiple forms e&apos; noto application a semi-deterministic process, as
(well-known) and and e&apos; noto che (It&apos;s only a restricted set of them is tried, and no
(it&apos;s well-known) The mark EOW indicates other choice is given.
well-known that).
a final state in the interpretation of the form
currently being scanned.
</bodyText>
<subsectionHeader confidence="0.937591">
2.2. The grammar
</subsectionHeader>
<bodyText confidence="0.986964666666667">
The grammar is a set of complex
grammatical statements (CGS), represented in
BNF as follows:
</bodyText>
<equation confidence="0.443704333333333">
CGS::=&lt;RULE&gt; &lt;EXPRESSION&gt;
&lt;RULE&gt;::=&lt;PRODUCTION&gt; &lt;TESTS&gt; &lt;ACTIONS&gt;
&lt;PRODUCTION&gt;::=&lt;LEFT-SYMBOL&gt;
</equation>
<bodyText confidence="0.95983665625">
&lt;RIGHT-PATTERN&gt;
&lt;LEFT-SYMBOL&gt;::= a non terminal symbol
&lt;RIGHT-PATTERN&gt;::= a sequence of categories
&lt;TESTS&gt;::= a whatever predicate
&lt;ACTIONS&gt;::= a whatever action
&lt;EXPRESSION&gt;::= a semantic interpretation in
any chosen formalism
As we have already stated, the
&lt;PRODUCTION&gt;&apos;s can be instantiated both with
syntactic and with semantic grammars. The
schema of the rule and the order of the
operations are fixed, regardless of the chosen
instance grammar.
&lt;TESTS&gt; are evaluated before the application
of a rule and can inhibit it if they fail.
&lt;ACTIONS&gt; are activated after the application
of a rule and perform additional structuring and
structure moving. Both participate into a
process of syntactic recognition and are to be
considered as the syntactic augmentation of the
rules. When using a semantic grammar the
&lt;ACTIONS&gt; are, in general, not used.
&lt;EXPRESSION&gt;&apos;s are the semantic augmentation
and specify the interpretation of the sentence,
for top level rules, or (partial) constituents,
for the other rules. These two augmentations
improve the syntactic power of the grammar,
by adding context sensitiveness, and add a
semantic relevance to the structuring of
constituents, due to the one-to-one
correspondence between syntactic and
semantic rules.
</bodyText>
<subsectionHeader confidence="0.996366">
2.3. The preprocessor
</subsectionHeader>
<bodyText confidence="0.9999541">
The preprocessor scans the sentence from
left to right, performs the dictionary look-up
for each word in the input string, and returns a
structure with the syntactic and semantic
information taken from the dictionary. At the
end of the scanning the input string has been
transformed into a sequence of such lexical
interpretations. The look-up takes into account
also the possibility that a word in input is part
of a multiple form.
</bodyText>
<subsectionHeader confidence="0.996082">
2.4. The parser
</subsectionHeader>
<bodyText confidence="0.990589366666667">
The parser is an extension of the ICA
algorithm (Grishman 1976). It shares with ICA
the following characteristics:
- it performs the syntactic recognition
bottom-up, left-to-right, first selecting
reduction sets by an integrated breadth and
depth-first strategy. It does not reject
sentences on a syntactic basis, but it only
rejects rule by rule for a given input word. If
all the rules have been rejected with no
success, the next word in the preprocessed
string is read and the loop continues.
Termination occurs in a natural way, when
no more rule can be applied and the input string
has come to an end;
- it gives as output a graph of all possible
parse trees; the complete parse tree(s) is
(are) extracted from the graph in a following
step. This characterizes the algorithm as an all-
path-algorithm which returns all possible
derivations for a sentence. Therefore, the
parser is able to create structure pieces also
for ill-formed sentences, thus outputting, even
in this case, partial analyses. This is
particularly useful for diagnosis and debugging.
The following are the major extensions to
the basic ICA algotrithm:
- it is designed to run an APSG, in
particular it evaluates the tests before
applying a rule;
</bodyText>
<page confidence="0.950539">
197
</page>
<figure confidence="0.999527">
POSTPARSER
ANALYSIS
INPUT
USER
DICTIONARY
DICTIONARY
CONSTRUCTOR
;SPECIALIZ D USER
....••••&amp;quot;&amp;quot;
ANAPAR
USER
SENTENCES &amp;
PARSING
STRUCTURES
GRAMMAR
CONSTRUCTOR
K.B.
M. R. S.
USER
</figure>
<figureCaption confidence="0.999833">
Figure 1. The system.
</figureCaption>
<figure confidence="0.994662333333333">
DICTIONARY
che
EOW
( ...)
noto
EOW noto EOW
che EOW
Symbolic representation
tree
Representation list of
the dictionary above
with multiple forms
EOW
((e&apos; (noto (che (EOW (......)))
(EOW (......)))
(EOW (......)))
(che (EOW (......)))
(noto (EOW (... ...))))
</figure>
<figureCaption confidence="0.999965">
Figure 2. The dictionary representation.
</figureCaption>
<page confidence="0.991374">
198
</page>
<bodyText confidence="0.975674">
- it handles lexical ambiguities during
parsing by representing them in special
multiple nodes (see below);
- the partition of the rules into packets
makes the selection of the rules semi-
deterministic;
- it carries syntactic and semantic analysis
in parallel.
</bodyText>
<subsectionHeader confidence="0.936305">
2.5. Post-processor and interpreter
</subsectionHeader>
<bodyText confidence="0.986929636363636">
The graph built by the parser is the data
structure out of which the parse tree is
extracted by the post-processor. To this end
the necessary conditions are that:
a. there exists at least one top level node
among the nodes of the graph;
b. at least one of the top level nodes cover the
whole sentence.
If one of these conditions is not met, i.e. if
there is no top level node or no top level node
covers the entire sentence, the analyser does
not carry any interpretation but displays a
message to the user, indicating the more
complete partial parsing, where the parser
stopped.
In case of ambiguity more than one top level
node covers the entire sentence and more than
one semantic interpretation is proposed to the
user who will select the appropriate one. If,
instead, only one top level node is found, the
semantic interpretation is immediately
produced.
</bodyText>
<subsectionHeader confidence="0.811423">
3. Data structure and algorithm
3.1. Data structure
</subsectionHeader>
<bodyText confidence="0.978089102040816">
The algorithm takes in input a preprocessed
string and returns a graph of all possible parse
trees. The nodes in the graph can be either
terminals (forms), Or non terminals
(constituents). Nodes are identified as follows:
- the &apos;name&apos; can be either FORMi or
CONSTITUENTj, according to the type. i and j
are indexes, and forms and constituents have
two independent orderings;
- a general sequence number.
The following two types of structural
information are associated with each node:
a. the &apos;annotation&apos; specifies the associated
&apos;interpretation&apos;, i.e.:
- the syntactic category of the node
(the label);
- its semantic value;
- its features.
For terminal nodes, their interpretation, i.e.
their annotation coincides with the
interpretation associated to the form by the
preprocessor. For non terminal nodes, instead,
the interpretation is made during the building of
the node and the applied rule gives all
necessary information;
b. the &apos;covering structure&apos; of a node contains
the information necessary to identify in the
graph the subtree rooted in that node. Each
node in the graph dominates a subtree and
covers a part of the input, i.e. a sequence of
terminal nodes. In this sequence, the form
associated with the leftmost terminal node is a
&apos;first form&apos;. The form immediately to the right
of the form associated to rightmost terminal
node is the &apos;anchor&apos;. For terminal nodes the
covering structure contains:
- the first form (the node itself);
- the anchor (the next form in the input
string);
- the list of parent nodes;
- the list of anchored nodes, i.e. the nodes
which have as anchor the form itself;
while for non terminal nodes it consists of:
- the first form;
-the anchor;
- the list of parents;
-the list of sons.
Two trees Ti and T2 are called adjacent if the
anchor of Ti is the first form of T2.
</bodyText>
<subsectionHeader confidence="0.98917">
3.2. The algorithm
</subsectionHeader>
<bodyText confidence="0.999505">
The parser is a loop realized as a recursion.
It scans the preprocessed string and creates a
terminal node for every scanned form. As a
terminal node is created, the algorithm
attempts to perform all the reductions which
are possible at that point. A &apos;reduction set&apos; is
defined as the set of nodes N1,N2 ..... Nn which
are roots of adjacent subtrees and correspond,
in the same order, to the &lt;RIGHT-PATTERN&gt; of
the examined production. If no (more) reduction
is possible, the parser scans the next form.
The loop continues until the string is exhausted.
The parser operates on the graph and has in
input two more data structures, i.e.:
- the stack of the active nodes, which contains
all the nodes which are to be examined; this is
</bodyText>
<page confidence="0.997713">
199
</page>
<bodyText confidence="0.998285222222222">
accessed with a LIFO policy;
- the list of rule packets, which contains the
rules potentially applicable on the current node.
The loop starts from the first active node.
Its annotation is extracted and the
corresponding rule packet is selected, i.e. the
one whose rightmost symbol corresponds to
the current node category. The reduction sets
are thus selected. A reduction set is searched
by an integrated breadth and depth-first
strategy as alternatives are retrieved and
stored all together as for breadth-first search,
but are then expanded one by one.
The choice of the possible applicable rules is
not a blind one and the rules are not all tested,
but they are pre-selected by their partition
into packets. More than one set is possible at
each step, i.e. the same rule can be applied
more than once. During the matching step
reduction sets are searched in parallel;
reductions and the building of new nodes are
also carried in parallel.
Once a reduction set is identified, the tests
associated with the current rule are evaluated.
If they succeed, the corresponding rule is
applied and a new node which has as category
the &lt;LEFT-SYMBOL&gt; of the production is
created and inserted in the active node stack.
This becomes the root of the (sub)tree whose
sons are in the reduction set. The evaluation of
tests prior to entering a rule is a further
improvement in efficiency.
The annotation of the new nodes is now created
by the execution of the actions, which insert
new features for the node, and the evaluation
of the expression which assigns to it a
semantic value.
If the tests fail, the next reduction set is
processed in the same way. If there is no
(more) reduction set, the next rule in the
packet is examined until no more rule is left.
When the higher level loop is resumed the next
active node is examined. Termination occurs
when the input is consumed and no more rule
can be applied.
</bodyText>
<subsectionHeader confidence="0.995517">
3.3. Lexical ambiguity
</subsectionHeader>
<bodyText confidence="0.964284083333333">
The algorithm can efficiently handle lexical
ambiguity.
For those forms which have more than one
interpretation, a special annotation is provided.
It contains a certain number of interpretations
and each interpretation has the following form:
(#i ((&lt;cat&gt; &lt;sem_val&gt;)
((&lt;feat_name&gt; &lt;feat_val&gt;)&apos;)))
where #i is the ordering number of the
interpretation. This structure is called
&apos;multiple node&apos;. Figure 3 shows multiple nodes
participating to different structures.
</bodyText>
<sectionHeader confidence="0.706644" genericHeader="method">
4. An example
</sectionHeader>
<bodyText confidence="0.988201555555556">
The most relevant application of SAIL is its
use as a NL interface towards a knowledge base
about ski environments. Natural language
declarations about lifts, snow and weather
conditions, and classification of slopes are
translated into MRS facts, and correspondently
NL questions, including advice requests, are
processed and inserted.
Let&apos;s take the question:
</bodyText>
<figure confidence="0.898926888888889">
&apos;Come sl sale da Cerylnia al Plateau
Rosa?&apos;
&apos;How can one get on the Plateau Rosa
from Cervinla ?&apos;
and the grammar:
Rule1:
PROD: TG -&gt; come &lt;connette&gt; &lt;partenza&gt;
&lt;arrivo&gt;?
TESTS: t
ACTIONS: t
EXPRESSION:(trueps
&apos;(connette (SEMVAL &apos;&lt;partenza&gt;)
(SEMVAL &apos;&lt;arrivo&gt;)
$mezzo))
Rule2:
PROD: &lt;partenza&gt; -&gt; da &lt;luogo&gt;
TESTS: t
ACTIONS: t
EXPRESSION: (SEMVAL &apos;&lt;luogo&gt;)
Rule3:
PROD: &lt;arrivo&gt; -&gt; al &lt;luogo&gt;
TESTS: t
ACTIONS: t
EXPRESSION: (SEMVAL &apos;&lt;luogo&gt;)
200
CONSTITUENTS recognizes &apos;la nota polemica&apos; &apos;the polemic note&apos;
CONSTITUENT7 recognizes &apos;la nota polemlca&apos; &apos;the well-known controversy&apos;
</figure>
<figureCaption confidence="0.992503">
Figure 3. Multiple nodes.
</figureCaption>
<figure confidence="0.993829333333334">
10,TG
5,&lt;partenza&gt; 8,&lt;arnvo&gt;
CONSTITUENT5
CONSTITUENT7
CONSTITUENT6
FORM3 = la FORM4 = nota FORM5 = polemica
1, come 2,&lt;connette&gt;
3&apos; da
4,&lt;luogo&gt; 6, al
7,&lt; uogo&gt;
,
come SI sale da Cervinia al Plateau Rosa ?
</figure>
<figureCaption confidence="0.999867">
Figure 4. The parse-tree of the example.
</figureCaption>
<page confidence="0.903664">
201
</page>
<figure confidence="0.8315076">
DICTIONARY-FORM#1:&lt;connette&gt; -&gt; sl sale
DICTIONARY-FORM#2:&lt;connette&gt; -&gt; sl giunge
DICTIONARY-FORM#3:&lt;luogo&gt; -&gt; Cervinia
DICTIONARY-FORM#4:&lt;luogo&gt; -&gt; Plateau
Rosa
</figure>
<bodyText confidence="0.997151111111111">
SEMVAL is a function that gets the semantic
value from the node having the category
specified by its parameter; this category must
appear in the right-hand side of the production.
trueps is an MRS function that checks the
knowledge base for the presence or not of a
predicate.
The parser starts by creating the terminal
nodes:
</bodyText>
<listItem confidence="0.97764975">
node1: form° : come
node2: formi :sl sale
node3: form2 : da
node4: form3 : Cervinia
</listItem>
<bodyText confidence="0.9615185">
and the rule2 can be applied on nodes node3 and
node4. The following node is created:
</bodyText>
<reference confidence="0.584064375">
node5: constituent° : da Cervinia
In an analogous way other nodes are added.
node6: form4 : al
node7:form5 : Plateau Rosa
node8:constituent3 : al Plateau Rosa
node9: forms : ?
node10: constituent4 : come si sale da
Cervinia al Plateau Rosa?
</reference>
<bodyText confidence="0.990547547619048">
As the syntactic category of node10 is TG (Top
Grammar) and it covers the entire input, the
parsing is successful. Figure 4 shows the parse-
tree for this sentence.
5.Conclusions and future developments
At present the parser described above has
been efficiently employed as a component of a
natural language front-end. The natural
language is Italian and typical input sentences
either give information about the possible trips
(paths/alternative paths) and their
characteristics (type of lift, condition of snow,
weather), or have the following form:
&apos;Oual&apos;e II percorso migliore per
andare da X a Y per uno sciatore
provetto ?&apos;
&apos;What is the best path from X to Y for
an excellent skier?&apos;
Three different improvements are in
progress:
- the implementation of a spelling corrector
and of a dictionary update system.The parser
rejects such sentences where some forms
occur that are not in the dictionary. A form not
included in the dictionary cannot be
distinguished from a form incorrectly typed
but present in the dictionary. The two cases
correspond to different situations and need
distinct solutions. In the former case the
defective form may be inserted in the
dictionary by means of an appropriate update
procedure. In the latter case the typing error
may be corrected on the basis of a
classification of errors compiled according to
some user&apos;s model;
- another perspective is making the parser
more powerful also about more strictly
linguistic phenomena as the resolution of
ellipsis and anaphora;
- finally, the identification of general semantic
functions to be employed in the &lt;EXPRESSION&gt;
part of the rule has been started.
</bodyText>
<sectionHeader confidence="0.99948" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.800035055555556">
Genesereth, M. R., Greiner, R. &amp; Smith, D. E.
(1980). MRS Manual. Technical Report HPP-
80-24, Stanford University, Stanford CA.
Genesereth, M. R. (1981). The architecture
of a multiple representation system.
Technical Report HPP-81-6, Stanford
University, Stanford CA.
Grishman, R. (1976). A survey of syntactic
analysis procedures for natural language.
AJCL, Microfiches 47, 2-96.
Marino, M., Spiezio, A., Ferrari, G. &amp;
Prodanof, I. (1986). SAIL: a natural language
interface for the building of and interacting
with knowledge bases. In Proceedings of
AIMSA 86 (on microfiches), Varna, Bulgaria.
Winograd, T. (1983). Language as a
Cognitive Process. Vol.1: Syntax.
Addison-Wesley.
</reference>
<page confidence="0.997981">
202
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.599020">
<title confidence="0.9990585">AN EFFICIENT CONTEXT-FREE PARSER FOR AUGMENTED PHRASE-STRUCTURE GRAMMARS</title>
<author confidence="0.998398">Massimo Marino</author>
<author confidence="0.998398">Antonella Spiezio</author>
<author confidence="0.998398">Giacomo Ferrari</author>
<author confidence="0.998398">Irina Prodanof</author>
<affiliation confidence="0.998973">Linguistics Department, University of Pisa,</affiliation>
<address confidence="0.918367">Via S. Maria 36, 1-56100 Pisa - Italy</address>
<affiliation confidence="0.777057">Computational Linguistics Institute - Cnr</affiliation>
<address confidence="0.825596">Via Della Faggiola 32,1-56100 Pisa - Italy</address>
<abstract confidence="0.997879">In this paper we present an efficient context-free (CF) bottom-up, non deterministic parser. It is an extension of the ICA (Immediate Constituent Analysis) parser proposed by Grishman (1976), and its major improvements are described. It has been designed to run Augmented Phrase-Structure Grammars (APSG) and performs semantic interpretation in parallel with syntactic analysis. It has been implemented in Franz Lisp and runs on VAX 11/780 and, recently, also on a SUN workstation, as the main component of a transportable Natural Language Interface (SAIL = Sistema per l&apos;Analisi e l&apos;Interpretazione del Linguaggio). Subsets of grammars of italian written in different formalisms and for different applications have been experimented with SAIL. In particular, a toy application has been developed in which SAIL has been used as a knowledge base in MRS (Genesereth et at. 1980, Genesereth 1981) about ski paths in a ski environment, and to ask for advice about the best touristic path under specific weather and physical conditions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>node5: constituent° : da Cervinia In an analogous way other nodes are added.</title>
<booktitle>node6: form4 : al node7:form5 : Plateau Rosa node8:constituent3 : al Plateau Rosa node9: forms : ? node10: constituent4 : come</booktitle>
<marker></marker>
<rawString>node5: constituent° : da Cervinia In an analogous way other nodes are added. node6: form4 : al node7:form5 : Plateau Rosa node8:constituent3 : al Plateau Rosa node9: forms : ? node10: constituent4 : come si sale da Cervinia al Plateau Rosa?</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Genesereth</author>
<author>R Greiner</author>
<author>D E Smith</author>
</authors>
<date>1980</date>
<tech>MRS Manual. Technical Report HPP80-24,</tech>
<institution>Stanford University,</institution>
<location>Stanford CA.</location>
<marker>Genesereth, Greiner, Smith, 1980</marker>
<rawString>Genesereth, M. R., Greiner, R. &amp; Smith, D. E. (1980). MRS Manual. Technical Report HPP80-24, Stanford University, Stanford CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Genesereth</author>
</authors>
<title>The architecture of a multiple representation system.</title>
<date>1981</date>
<tech>Technical Report HPP-81-6,</tech>
<institution>Stanford University,</institution>
<location>Stanford CA.</location>
<contexts>
<context position="1234" citStr="Genesereth 1981" startWordPosition="179" endWordPosition="180">s (APSG) and performs semantic interpretation in parallel with syntactic analysis. It has been implemented in Franz Lisp and runs on VAX 11/780 and, recently, also on a SUN workstation, as the main component of a transportable Natural Language Interface (SAIL = Sistema per l&apos;Analisi e l&apos;Interpretazione del Linguaggio). Subsets of grammars of italian written in different formalisms and for different applications have been experimented with SAIL. In particular, a toy application has been developed in which SAIL has been used as interface to build a knowledge base in MRS (Genesereth et at. 1980, Genesereth 1981) about ski paths in a ski environment, and to ask for advice about the best touristic path under specific weather and physical conditions. 1. INTRODUCTION Many parsers for natural language have been developed in the past, which run different types of grammars. Among them, the most successful are the CF grammars, the augmented phrase-structure grammars (APSGs), and the semantic grammars. All of them have different characteristics and different advantages. In particular APSGs offer a natural tool for the treatment of certain natural language phenomena, such as subjectverb agreement. Semantic gra</context>
</contexts>
<marker>Genesereth, 1981</marker>
<rawString>Genesereth, M. R. (1981). The architecture of a multiple representation system. Technical Report HPP-81-6, Stanford University, Stanford CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
</authors>
<title>A survey of syntactic analysis procedures for natural language.</title>
<date>1976</date>
<journal>AJCL, Microfiches</journal>
<volume>47</volume>
<pages>2--96</pages>
<contexts>
<context position="6047" citStr="Grishman 1976" startWordPosition="922" endWordPosition="923">nts, due to the one-to-one correspondence between syntactic and semantic rules. 2.3. The preprocessor The preprocessor scans the sentence from left to right, performs the dictionary look-up for each word in the input string, and returns a structure with the syntactic and semantic information taken from the dictionary. At the end of the scanning the input string has been transformed into a sequence of such lexical interpretations. The look-up takes into account also the possibility that a word in input is part of a multiple form. 2.4. The parser The parser is an extension of the ICA algorithm (Grishman 1976). It shares with ICA the following characteristics: - it performs the syntactic recognition bottom-up, left-to-right, first selecting reduction sets by an integrated breadth and depth-first strategy. It does not reject sentences on a syntactic basis, but it only rejects rule by rule for a given input word. If all the rules have been rejected with no success, the next word in the preprocessed string is read and the loop continues. Termination occurs in a natural way, when no more rule can be applied and the input string has come to an end; - it gives as output a graph of all possible parse tree</context>
</contexts>
<marker>Grishman, 1976</marker>
<rawString>Grishman, R. (1976). A survey of syntactic analysis procedures for natural language. AJCL, Microfiches 47, 2-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marino</author>
<author>A Spiezio</author>
<author>G Ferrari</author>
<author>I Prodanof</author>
</authors>
<title>SAIL: a natural language interface for the building of and interacting with knowledge bases.</title>
<date>1986</date>
<booktitle>In Proceedings of AIMSA 86 (on microfiches),</booktitle>
<location>Varna, Bulgaria.</location>
<marker>Marino, Spiezio, Ferrari, Prodanof, 1986</marker>
<rawString>Marino, M., Spiezio, A., Ferrari, G. &amp; Prodanof, I. (1986). SAIL: a natural language interface for the building of and interacting with knowledge bases. In Proceedings of AIMSA 86 (on microfiches), Varna, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Language as a Cognitive Process. Vol.1: Syntax.</title>
<date>1983</date>
<publisher>Addison-Wesley.</publisher>
<marker>Winograd, 1983</marker>
<rawString>Winograd, T. (1983). Language as a Cognitive Process. Vol.1: Syntax. Addison-Wesley.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>