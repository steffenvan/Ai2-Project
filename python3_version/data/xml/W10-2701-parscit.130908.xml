<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025052">
<title confidence="0.983103">
Episodic Memory for Companion Dialogue
</title>
<author confidence="0.908319">
Gregor Sieber
</author>
<affiliation confidence="0.5044795">
OFAI
Vienna, Austria
</affiliation>
<email confidence="0.92201">
gregor.sieber@ofai.at
</email>
<note confidence="0.435021">
Brigitte Krenn
OFAI
Vienna, Austria
</note>
<email confidence="0.956837">
brigitte.krenn@ofai.at
</email>
<sectionHeader confidence="0.992615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999741769230769">
We present an episodic memory compo-
nent for enhancing the dialogue of artifi-
cial companions with the capability to re-
fer to, take up and comment on past in-
teractions with the user, and to take into
account in the dialogue long-term user
preferences and interests. The proposed
episodic memory is based on RDF repre-
sentations of the agent’s experiences and
is linked to the agent’s semantic memory
containing the agent’s knowledge base of
ontological data and information about the
user’s interests.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999925215384616">
Recently, research on artificial companions has
come more and more in focus. They are artifi-
cial agents (virtual or robotic) that are intended
to support the human user in aspects of everyday
life. They may range from virtual agents that as-
sist their users in accessing information from the
Internet in accordance with the users’ interests,
preferences and needs (Skowron et al., 2008), up
to assistive robots in home environments that sup-
port elderly in mastering their life at home (Graf et
al., 2009). In the long run when developing com-
panions, the goal is to model and implement arti-
ficial ”caring developing helpers” (Sloman, 2007)
that learn and develop over time to be of long-term
benefit for the user.
In order to come closer to the vision of artifi-
cial companions a number of research issues need
to be addressed such as: action-perception and
learning capabilities suitable to function with im-
perfect sensors in dynamically changing environ-
ments which can only be partially modelled; the
development of affect sensing capabilities that ex-
tend over the detection of basic emotions such as
joy, anger, fear, disgust etc. (Ekman, 1992); user
models that account for and adapt to the users’
interests, preferences, affective states, needs and
handicaps; approaches to multimodal dialogue
that allow the agent’s mental models and mem-
ories to be connected to its expressive behaviour
(Castellano et al., 2008), and where natural lan-
guage dialogue is semantically grounded (Benyon
and Mival, 2008). Companions need to be aware
of their own history and past interactions with their
individual users, so that the single user can believe
that her/his companion knows “what it is talking
about”. This is particularly important for creating
acceptable long–term interactions.
To account for this kind of requirements, we
propose a communication component for com-
panions where autobiographic episodic memory,
semantic memory and dialogue are closely con-
nected. In our approach, input analysis is per-
formed using information extraction techniques,
that yield RDF triples describing the content of a
user utterance in terms of the knowledge base (se-
mantic memory) of the companion, and an utter-
ance class describing the type of message (greet-
ing, question, agreement, rejection, etc.). Short
term memory holds the current user utterance and
a set of pointers to currently important and thus
activated parts of the companion’s knowledge. We
distinguish two parts of the long term memory: Se-
mantic memory is composed of a knowledge base
containing ontological data and a user model en-
coding e.g. elements of the ontology which the
user is especially interested in. Episodic memory
is based on RDF representations of the agent’s ex-
periences. It contains utterances of the user and
the companion, and representations of the com-
panion’s actions and their evaluation (for the cases
where it is known). The dialogue manager con-
sists of a set of parallel, independent components
for the different queries on the episodic mem-
ory described below and answer retrieval from the
knowledge base. Which component is finally used
</bodyText>
<page confidence="0.798793">
1
</page>
<note confidence="0.6233205">
Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 1–6,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999645777777778">
is decided by a scoring mechanism in connection
with a rule set.
In the remainder of this contribution, we will
concentrate on the interplay between episodic
memory and dialogue. In particular, we describe
how the episodic memory is represented (sec. 2),
how episodes are retrieved (sec. 3), and how nat-
ural language output is generated from memory
content (sec. 4).
</bodyText>
<sectionHeader confidence="0.986683" genericHeader="method">
2 Episodic Memory Representation
</sectionHeader>
<bodyText confidence="0.99943325">
An episodic memory component for companion
dialogue needs to provide adequate knowledge
representation in connection with the cognitive
model and the tasks of the agent. RDF-based1 data
stores are widely used for representing domain
knowledge as well as common sense knowledge
(e.g. the Open Mind Common Sense Database2,
or ConceptNet3). Accordingly, we have developed
an episodic memory component for artificial com-
panions that stores episodes as RDF graphs. Since
both memory, domain and common sense knowl-
edge bases are composed of RDF triples, they are
interoperable and can be easily extended. We use
a Sesame4 repository for hosting the data stores.
Episode encoding is automatic, since all user
input and its analysis is immediately transferred
from short-term memory to episodic memory.
Thus the agent is able to recall the same data from
an episode that was available at the time of the ex-
perience.
For episode retrieval, a similarity matching al-
gorithm is required that can find memories based
on similarity of the individuals and relations in-
volved. Thus, our retrieval mechanism neither
treats the RDF data as symbols in a similarity vec-
tor – such as for a nearest–neighbour search –, nor
as a graph matching problem, which often is too
slow for retrieval. Both of these approaches do
not take advantage of the RDF encoding of the
data, and as a consequence do not allow class or
superclass information of individuals to be used
for matching.
Our approach is to query the RDF reposito-
ries using a query language such as SeRQL and
SPARQL. While these query languages do not al-
low a direct search for a similar graph, a set of
</bodyText>
<footnote confidence="0.999927">
1http://www.w3.org/RDF/
2http://commons.media.mit.edu/en/
3http://conceptnet.media.mit.edu/
4http://www.openrdf.org/
</footnote>
<bodyText confidence="0.9940382">
queries can be generated from a target episode
making use of the full range of features of RDF
and the query language. The episode most similar
to the input episode is then selected from the result
set by applying a heuristic.
</bodyText>
<subsectionHeader confidence="0.942204">
2.1 Episodes
</subsectionHeader>
<bodyText confidence="0.999953488372093">
In our system, there are several types of episodes
which share a set of basic parameters, each rep-
resenting the different events and actions in the
world of the agent.
The different sub-types of episodes are RDF
subclasses of the basic episode concept and con-
tain specialised parameters applicable to the type
of action.
Basic properties stored with each episode are:
a) creation time of the episode and b) an episode
ID property which is used to trace back or forward
through the episodes in (reverse) order of creation,
to find the outcome and evaluation following an
episode retrieved from memory. This is necessary,
because triples in RDF are stored as graphs and not
database entries like in a relational database which
could easily be ordered by a primary key.
Action episodes are a subclass of episodes
that represent the actions the agent is capable of.
These are:
Answer from domain knowledge the agent maps
the user’s question to a SeRQL query and evalu-
ates the query against its domain knowledge base.
Find similar interactions represents deliberate
remembering, i.e. actively searching for similar
situations.
Pattern search allows the agent to check for a
set of patterns in the behaviour of the user and
its episodic memory which can be exploited for
dialogue.
Retrieve context is employed by the agent when
no other actions can be applied because parts of
the utterance are missing. The companion then
searches its memories to retrieve relevant context
of the dialogue.
Send message to the user, which can either
communicate the results of a query, memories
of the agent, statements based on results from
pattern search, or details about the situation of the
agent, which includes reporting errors.
Input episodes store textual user input. They
contain the analysis of the user input which is an
RDF description of the entities, classes and prop-
</bodyText>
<page confidence="0.962555">
2
</page>
<bodyText confidence="0.999972433333333">
erties of the domain ontology contained in the ut-
terance. For example, the question “When was
Charlie Parker born?” is classified as utterance
class WH-Question, and its analysis is an RDF
triple with the ontology individual of class Artist
representing Charlie Parker, the property birth-
Date, and a variable as the object since it is this
value the user wants to know.
Evaluation episodes can be either positive or
negative. They are crucial for the agent to be able
to learn from its past actions. If an evaluation is
available, the agent can decide based on its mem-
ories whether a past solution should be repeated or
not. Not all episodes have an evaluation. Evalua-
tion values can either come from direct user feed-
back or internal feedback such as empty query re-
sults or failure to retrieve a query result.
In order to be able to find the right associations
and memories, the agent also needs to have an in-
ternal notion of relative time that can be related to
interactions with the user. As noted e.g. by Brom
and Lukavsk´y (2009) humans commonly do not
use exact times, but instead refer to fuzzy cate-
gories. Thus, our (application specific) time model
of the companion allows to differentiate between
four coarse times of day – morning, noon, after-
noon, evening. For events that are further in the
past, the model contains the categories of: today,
yesterday, this week, this month, this year, last
year.
</bodyText>
<subsectionHeader confidence="0.997064">
2.2 Episode Dynamics
</subsectionHeader>
<bodyText confidence="0.999985673076923">
Due to available computing hardware and scalable
triple stores, the episodic memory component is
technically able to store a large amount of memo-
ries. But when the episode base grows too big, it
becomes increasingly difficult to retrieve episodes
within an acceptable time limit due to the grow-
ing number of search and comparison operations
required. Thus the companion needs a mechanism
of reducing the number of episodes in the mem-
ory. Generally, there are two approaches to this:
episode blending and forgetting.
Episode blending refers to a mechanism that
groups similar experiences into one episode. Less
important parameters of the memories are lost, and
the similarities strengthened. This would mean the
agent can remember what happened, and that it
happened more than once, but the exact situations
are lost. Episode blending is an interesting aspect
of episodic memory that will be pursued in our fu-
ture work.
Forgetting refers to the deletion of episodes.
Ideally, the episodes with least utility to the com-
panion should be deleted. Nuxoll (2007) provides
a list of possible approaches regarding forgetting:
1) remove the oldest memory first, 2) remove the
least activated memory, 3) remove the most redun-
dant memory, 4) memory decay.
Approach 1) does not take the importance of
episodes into account and may result in losing im-
portant information. Approaches 2) and 4) both
depend on assigning activation values to episodes,
and delete those with the least activation. The idea
of 3) is to locate two memories that are very simi-
lar to each other and remove one of them.
Our initial strategy is to assign a time-stamp of
last retrieval to each episode, since we currently
do not use activation values. Episode removal can
then be regularly performed by issuing a SeRQL
delete statement for all episodes whose retrieval
date is older than a certain time, depending on the
growth rate of the memory.
Note that the removal process described above
still bears the risk of losing important memories of
situations that are very rarely encountered. For our
dialogue application scenario, this risk might not
seem too critical, yet it might be e.g. for an agent
in an artificial life environment where seldomly
occurring enemies need to be recognised. A pos-
sible remedy would be the connection of episodic
memory with a model of emotion. This would al-
low the emotional intensity of a situation to be a
factor in episode retrieval and deletion.
</bodyText>
<sectionHeader confidence="0.984967" genericHeader="method">
3 Retrieval of Episodic Memories
</sectionHeader>
<bodyText confidence="0.9999020625">
One of the important aspects of any episodic mem-
ory component is to retrieve the right memories.
Since our episodic memory is realised using
RDF, a set of SeRQL queries is used for episode
retrieval. Queries are processed in parallel. The
construction of these queries depends on the type
of episode represented by the input situation.
The following section describes our model for
deliberate retrieval for dialogue situations. This
means that the companion actively chooses to
search its memory for episodes of relevance.
The current situation is characterised by a set of
features, expressed in RDF data, that are extracted
from short term memory: 1) the description of the
user utterance in terms of domain data, 2) the cur-
rent time, 3) a list of entities in the user utterance
</bodyText>
<page confidence="0.992609">
3
</page>
<bodyText confidence="0.999523183673469">
that are among the user’s preferred entities, if any.
A query is issued representing the input situa-
tion. This means, we search the memory to see if
the exact same situation has been encountered pre-
viously. Alternatively, queries using combinations
and subsets of the instance set and the set of rela-
tions present in the user utterance are issued. For
instance, given a popular music gossipping sce-
nario, if the user asks a question about Michael
Jackson, Janet Jackson, and Tina Turner, the agent
searches its memory for previous episodes involv-
ing the named artists and relations or subsets of
those, in order to connect to and take up previous
discussions. Moreover, the structure of the domain
data is used for generating a query containing the
classes of the individuals in the utterance. For ex-
ample, an agent that has talked about the birth-
day of any guitar player before, could relate a user
question about the birthday of Joe Satriani to the
previous experience by knowing that he is a guitar
player too, and use this knowledge in the ongoing
dialogue.
Queries related to classes can be iterated by fol-
lowing up the superclass hierarchy until a result
is found. The iteration stops either when there is
no further superclass, or when the property under
discussion is not a property of the superclass any
more. For example, talking about the birthday of
an Artist, the companion looks for episodes about
birthdays involving its superclass Person, but not
episodes with its superclass Entity, since the class
Entity has no birthday property.
The most similar episode is selected from
the result set by a heuristic which ranks those
episodes higher that resemble the input episode
more closely, so for example an episode that con-
tains the same entities and the same properties as
the input episode is ranked higher than an episode
that contains a matching entity with a different
property, and so on.
These content–driven retrieval strategies can be
used to support the selection of the next dialogue
move, taking into account available evaluations of
similar past episodes. Additionally to the content–
driven mechanism of remembering, the compan-
ion can also search its memories for recency- and
preference-driven patterns that can be used for dia-
logue, such as the following examples. In contrast
to the mechanisms mentioned above, these opera-
tions are automatically performed without requir-
ing the agent’s initiative.
Has the same question been discussed recently,
or ever before? The companion can make a com-
ment to the user about this – either noting as trivia
that the question has been asked a year ago, or re-
acting annoyed if the user asks the same question
for the fifth time within ten minutes.
Is there a property in a user utterance that is
among the user’s interests? Has this property been
asked for in the last 15 interactions? For exam-
ple, the user is very interested in the birth places
of artists. The companion can use this information
in the following ways: a) for the next artist under
discussion, automatically provide the birth place
to the user; b) the companion can comment on the
fact that the property is part of the user interests;
c) the companion can ask the user whether she
would like to know the birthplace of a randomly
selected artist from her preference list (the com-
panion would select an artist whose birth place has
not been inquired in the recent past, by checking
against its memories).
In the last 15 interactions that related to a cer-
tain property, is there a strong tendency (currently,
more than 66%) towards one specific value of that
property? The companion can then search for sim-
ilar cases among the data, and check whether there
is another artist – maybe even among the user’s
preferred artists – that shares this birth place.
Additionally, this type of information is stored
in the user model and leads to automatic retrieval
of episodes where appropriate. Continuing the ex-
ample of the birth place from above: a day after
being asked about artists born in New York, the
companion might notice while talking about the
albums recorded by Billy Joel that he was also
born in New York, and communicate it to the user.
Building upon the user preferences stored in the
user model, the remembering process additionally
contains queries related to the most prevalent pref-
erences of the user model. This is similar to find-
ing strengthened links in a connectionist model.
For example, if one of the currently high-ranked
user preferences is asking for information about
artists born in New York, a query is automatically
generated from the user model to look for this in-
formation connected to the individuals in the input
graph.
</bodyText>
<sectionHeader confidence="0.986231" genericHeader="method">
4 Output Generation
</sectionHeader>
<bodyText confidence="0.9736575">
Since our companion ”thinks” in RDF statements,
it requires mechanisms to communicate their con-
</bodyText>
<page confidence="0.995677">
4
</page>
<bodyText confidence="0.999945894736842">
tent to the user. We distinguish two classes of
RDF statements from which to generate natural-
language output. The first class is RDF data
that describes content from the domain ontologies,
e.g, that Duke Ellington was born in Washington,
DC. The second class are statements that describe
a certain type of communicative intent, such as
telling the user that she just asked the same ques-
tion as five minutes ago.
Our approach for the second case is that of
template–based generation, where each commu-
nicative intent from the ontology corresponds to
a different template. The templates are described
using the Velocity5 template language, and can
thus be extended separately from the program
code, while still offering the possibility to make
use of memory contents for filling slots in the tem-
plates.
The first case is handled by directly generating
a sentence structure from the subject – predicate
– object structure of the RDF graph. Triples are
sorted by subject; subjects that also appear as ob-
jects are inserted as relative clauses. Statements
that share the same subject are connected by coor-
dination or relative clauses, depending on the type
of relation, and so forth. The input may contain
negation markers, which are realised as negative
polarity items.
The surface string of predicates is generated by
using a set of templates and morphological pro-
cessing (e.g. pluralisation). For subjects and ob-
jects, a query on the knowledge base is performed
to retrieve an adequate natural language represen-
tation. For example, while the name of a person
is in the name property of the Person class, the
name of a music album is contained in the prop-
erty albumTitle. A mapping for each class to such
a property is stored in an annotation file.
</bodyText>
<sectionHeader confidence="0.999875" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.9998015">
Catizone et al. (2008) use an extended version of
GATE’s ANNIE subsystem, combined with a set
of gazetteers, to identify relationships in the in-
put to their Senior Companion system. The fo-
cus of the Senior Companion is to use the data
extracted from the user utterances to collect in-
formation about the user’s life. While our input
analysis system is similar, it uses regular expres-
sion patterns over annotations for the matching of
relations between, and properties of, individuals
</bodyText>
<footnote confidence="0.885363">
5http://velocity.apache.org/
</footnote>
<bodyText confidence="0.999846704545455">
and classes. In terms of functionality, our system
focuses on being able to answer user requests and
provide continued dialogue by taking into account
the previous interactions with the user.
Episodic memory has first been distinguished
from other memory types by Tulving (1972). Im-
plementations have for example been used in arti-
ficial life agents (Nuxoll, 2007; Ho et al., 2003), in
storytelling agents (Ho et al., 2007; Ho and Daut-
enhahn, 2008), and for non-player characters in
games (Brom et al., 2007; Brom and Lukavsk´y,
2009). Since our memory component is realised as
an RDF graph, nearest–neighbour search as in the
memory model proposed by Nuxoll (2007) does
not directly apply.
Brom and Lukavsk´y (2009) summarise impor-
tant aspects of episodic memory and propose a
more detailed concept of time categories than
ours. In contrast to their work, our memory is not
concerned with remembering locations, but with
finding items relevant for current dialogue in the
episodic memory of the agent, and thus stores dif-
ferent data.
Both the adaptive mind agent by Krenn et al.
(2009) and Gossip Galore (Xu et al., 2009) de-
scribe companion systems able to answer ques-
tions on domain data. Both agents only have lim-
ited knowledge of their own past and do not use
it for dialogue. Thus they cannot ground dialogue
in their own experiences, and are unable to lever-
age knowledge about user preferences for provid-
ing more interesting dialogue.
Cavazza et al. (2008) describe a companion sys-
tem for helping users plan a healthier lifestyle. Di-
alogue can be driven by the companion or by the
user, but revolves around agreeing upon a daily ex-
ercise plan or negotiating re-planning in case of
plan failure. Our system aims at a more open kind
of dialogue which does not revolve around a plan
model. Instead, the user is able to ask different
kinds of questions on all the domain data available,
which leaves the companion in a situation where
much less expectations can be made towards the
next user utterance.
</bodyText>
<sectionHeader confidence="0.999485" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9998758">
We have presented a model of a companion that
uses an RDF–based episodic memory component
for enhancing dialogue with the user and ground-
ing domain knowledge in interaction experiences
interconnected with the agent’s knowledge base.
</bodyText>
<page confidence="0.969216">
5
</page>
<bodyText confidence="0.999877625">
The full implementation of the model is currently
work in progress.
Retrieval of episodes is accomplished by using
a set of competing SeRQL queries. Our model
shows how the contents of past interactions and
their relation to current dialogue can be employed
by a companion for selecting the next dialogue
move and generating dialogue content.
</bodyText>
<sectionHeader confidence="0.994731" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999802">
The work presented is supported by the Austrian
Ministry for Transport, Innovation and Technol-
ogy (BMVIT) under the programme “FEMtech
Women in Research and Technology” grant nr.
821855, project C4U. The Austrian Research In-
stitute for Artificial Intelligence (OFAI) is sup-
ported by the Austrian ministries BMVIT and
BMWF.
</bodyText>
<sectionHeader confidence="0.998907" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999799965517241">
David Benyon and Oli Mival. 2008. Scenarios
for companions. In Austrian Artificial Intelligence
Workshop, September.
Cyril Brom and JiriLukavsk´y. 2009. Towards Vir-
tual Characters with a Full Episodic Memory II: The
Episodic Memory Strikes Back. In Proc. Empathic
Agents, AAMAS workshop, pages 1–9.
Cyril Brom, Kl´ara Peskov´a, and JiriLukavsk´y. 2007.
Towards characters with a full episodic memory.
In Catherine Pelachaud, Jean-Claude Martin, Elis-
abeth Andr´e, G´erard Chollet, Kostas Karpouzis, and
Danielle Pel´e, editors, IVA, volume 4722 of Lec-
ture Notes in Computer Science, pages 360–361.
Springer.
G. Castellano, R. Aylett, K. Dautenhahn, A. Paiva,
P. W. McOwan, and S. Ho. 2008. Long-Term Af-
fect Sensitive and Socially Interactive Companions.
In Proceedings of the 4th International Workshop on
Human-Computer Conversation.
Roberta Catizone, Alexiei Dingli, Hugo Pinto, and
Yorick Wilks. 2008. Information extraction tools
and methods for understanding dialogue in a com-
panion. In Proceedings of the Sixth International
Language Resources and Evaluation (LREC’08).
Marc Cavazza, Cameron Smith, Daniel Charlton,
Li Zhang, Markku Turunen, and Jaakko Hakulinen.
2008. A ’companion’ ECA with planning and activ-
ity modelling. In AAMAS ’08: Proceedings of the
7th international joint conference on Autonomous
agents and multiagent systems, pages 1281–1284.
Paul Ekman. 1992. An argument for basic emotions.
Cognition and Emotion, 6:169–200.
Birgit Graf, Ulrich Reiser, Martin H¨agele, Kathrin
Mauz, and Peter Klein. 2009. Robotic home as-
sistant care-o-bot 3 - product vision and innovation
platform. In IEEE / Robotics and Automation Soci-
ety: IEEE Workshop on Advanced Robotics and its
Social Impacts - ARSO 2009, pages 139–144, New
York, NY, USA. Piscataway.
Wan Ching Ho and Kerstin Dautenhahn. 2008. To-
wards a narrative mind: The creation of coherent
life stories for believable virtual agents. In IVA ’08:
Proceedings of the 8th international conference on
Intelligent Virtual Agents, pages 59–72, Berlin, Hei-
delberg. Springer.
Wan Ching Ho, Kerstin Dautenhahn, and Chrysto-
pher L. Nehaniv. 2003. Comparing different con-
trol architectures for autobiographic agents in static
virtual environments. In Thomas Rist, Ruth Aylett,
Daniel Ballin, and Jeff Rickel, editors, IVA, volume
2792 of Lecture Notes in Computer Science, pages
182–191. Springer.
Wan Ching Ho, Jo˜ao Dias, Rui Figueiredo, and Ana
Paiva. 2007. Agents that remember can tell sto-
ries: integrating autobiographic memory into emo-
tional agents. In Edmund H. Durfee, Makoto Yokoo,
Michael N. Huhns, and Onn Shehory, editors, AA-
MAS, page 10. IFAAMAS.
Brigitte Krenn, Marcin Skowron, Gregor Sieber, Erich
Gstrein, and J¨org Irran. 2009. Adaptive mind
agent. In IVA ’09: Proceedings of the 9th Inter-
national Conference on Intelligent Virtual Agents,
pages 519–520, Berlin, Heidelberg. Springer.
Andrew Nuxoll. 2007. Enhancing Intelligent Agents
with Episodic Memory. Ph.D. thesis, Univ. of
Michigan, Ann Arbor.
Marcin Skowron, J¨org Irran, and Brigitte Krenn. 2008.
Computational framework for and the realization of
cognitive agents providing intelligent assistance ca-
pabilities. In 18th European Conference on Ar-
tificial Intelligence, Cognitive Robotics Workshop,
pages 88–96.
Aaron Sloman. 2007. Requirements for Digital Com-
panions It’s harder than you think. In Position Paper
for Workshop on Artificial Companions in Society:
Perspectives on the Present and Future. Oxford In-
ternet Institute.
Endel Tulving. 1972. Episodic and semantic memory.
In E. Tulving and W. Donaldson, editors, Organi-
zation of Memory, pages 381–403. Academic Press,
New York.
Feiyu Xu, Peter Adolphs, Hans Uszkoreit, Xiwen
Cheng, and Hong Li. 2009. Gossip galore: A
conversational web agent for collecting and sharing
pop trivia. In Joaquim Filipe, Ana L. N. Fred, and
Bernadette Sharp, editors, ICAART, pages 115–122.
INSTICC Press.
</reference>
<page confidence="0.99878">
6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.336151">
<title confidence="0.999306">Episodic Memory for Companion Dialogue</title>
<author confidence="0.954978">Gregor</author>
<affiliation confidence="0.50215">Vienna,</affiliation>
<email confidence="0.972566">gregor.sieber@ofai.at</email>
<affiliation confidence="0.761128">Brigitte</affiliation>
<address confidence="0.881641">Vienna,</address>
<email confidence="0.995913">brigitte.krenn@ofai.at</email>
<abstract confidence="0.999367714285714">We present an episodic memory component for enhancing the dialogue of artificial companions with the capability to refer to, take up and comment on past interactions with the user, and to take into account in the dialogue long-term user preferences and interests. The proposed episodic memory is based on RDF representations of the agent’s experiences and is linked to the agent’s semantic memory containing the agent’s knowledge base of ontological data and information about the user’s interests.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Benyon</author>
<author>Oli Mival</author>
</authors>
<title>Scenarios for companions.</title>
<date>2008</date>
<booktitle>In Austrian Artificial Intelligence Workshop,</booktitle>
<contexts>
<context position="2180" citStr="Benyon and Mival, 2008" startWordPosition="341" endWordPosition="344">itable to function with imperfect sensors in dynamically changing environments which can only be partially modelled; the development of affect sensing capabilities that extend over the detection of basic emotions such as joy, anger, fear, disgust etc. (Ekman, 1992); user models that account for and adapt to the users’ interests, preferences, affective states, needs and handicaps; approaches to multimodal dialogue that allow the agent’s mental models and memories to be connected to its expressive behaviour (Castellano et al., 2008), and where natural language dialogue is semantically grounded (Benyon and Mival, 2008). Companions need to be aware of their own history and past interactions with their individual users, so that the single user can believe that her/his companion knows “what it is talking about”. This is particularly important for creating acceptable long–term interactions. To account for this kind of requirements, we propose a communication component for companions where autobiographic episodic memory, semantic memory and dialogue are closely connected. In our approach, input analysis is performed using information extraction techniques, that yield RDF triples describing the content of a user </context>
</contexts>
<marker>Benyon, Mival, 2008</marker>
<rawString>David Benyon and Oli Mival. 2008. Scenarios for companions. In Austrian Artificial Intelligence Workshop, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cyril Brom</author>
<author>JiriLukavsk´y</author>
</authors>
<title>Towards Virtual Characters with a Full Episodic Memory II: The Episodic Memory Strikes Back.</title>
<date>2009</date>
<booktitle>In Proc. Empathic Agents, AAMAS workshop,</booktitle>
<pages>1--9</pages>
<marker>Brom, JiriLukavsk´y, 2009</marker>
<rawString>Cyril Brom and JiriLukavsk´y. 2009. Towards Virtual Characters with a Full Episodic Memory II: The Episodic Memory Strikes Back. In Proc. Empathic Agents, AAMAS workshop, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cyril Brom</author>
<author>Kl´ara Peskov´a</author>
<author>JiriLukavsk´y</author>
</authors>
<title>Towards characters with a full episodic memory.</title>
<date>2007</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>4722</volume>
<pages>360--361</pages>
<editor>In Catherine Pelachaud, Jean-Claude Martin, Elisabeth Andr´e, G´erard Chollet, Kostas Karpouzis, and Danielle Pel´e, editors, IVA,</editor>
<publisher>Springer.</publisher>
<marker>Brom, Peskov´a, JiriLukavsk´y, 2007</marker>
<rawString>Cyril Brom, Kl´ara Peskov´a, and JiriLukavsk´y. 2007. Towards characters with a full episodic memory. In Catherine Pelachaud, Jean-Claude Martin, Elisabeth Andr´e, G´erard Chollet, Kostas Karpouzis, and Danielle Pel´e, editors, IVA, volume 4722 of Lecture Notes in Computer Science, pages 360–361. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Castellano</author>
<author>R Aylett</author>
<author>K Dautenhahn</author>
<author>A Paiva</author>
<author>P W McOwan</author>
<author>S Ho</author>
</authors>
<title>Long-Term Affect Sensitive and Socially Interactive Companions.</title>
<date>2008</date>
<booktitle>In Proceedings of the 4th International Workshop on Human-Computer Conversation.</booktitle>
<contexts>
<context position="2093" citStr="Castellano et al., 2008" startWordPosition="328" endWordPosition="331">arch issues need to be addressed such as: action-perception and learning capabilities suitable to function with imperfect sensors in dynamically changing environments which can only be partially modelled; the development of affect sensing capabilities that extend over the detection of basic emotions such as joy, anger, fear, disgust etc. (Ekman, 1992); user models that account for and adapt to the users’ interests, preferences, affective states, needs and handicaps; approaches to multimodal dialogue that allow the agent’s mental models and memories to be connected to its expressive behaviour (Castellano et al., 2008), and where natural language dialogue is semantically grounded (Benyon and Mival, 2008). Companions need to be aware of their own history and past interactions with their individual users, so that the single user can believe that her/his companion knows “what it is talking about”. This is particularly important for creating acceptable long–term interactions. To account for this kind of requirements, we propose a communication component for companions where autobiographic episodic memory, semantic memory and dialogue are closely connected. In our approach, input analysis is performed using info</context>
</contexts>
<marker>Castellano, Aylett, Dautenhahn, Paiva, McOwan, Ho, 2008</marker>
<rawString>G. Castellano, R. Aylett, K. Dautenhahn, A. Paiva, P. W. McOwan, and S. Ho. 2008. Long-Term Affect Sensitive and Socially Interactive Companions. In Proceedings of the 4th International Workshop on Human-Computer Conversation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberta Catizone</author>
<author>Alexiei Dingli</author>
<author>Hugo Pinto</author>
<author>Yorick Wilks</author>
</authors>
<title>Information extraction tools and methods for understanding dialogue in a companion.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</booktitle>
<contexts>
<context position="19485" citStr="Catizone et al. (2008)" startWordPosition="3213" endWordPosition="3216">on, and so forth. The input may contain negation markers, which are realised as negative polarity items. The surface string of predicates is generated by using a set of templates and morphological processing (e.g. pluralisation). For subjects and objects, a query on the knowledge base is performed to retrieve an adequate natural language representation. For example, while the name of a person is in the name property of the Person class, the name of a music album is contained in the property albumTitle. A mapping for each class to such a property is stored in an annotation file. 5 Related Work Catizone et al. (2008) use an extended version of GATE’s ANNIE subsystem, combined with a set of gazetteers, to identify relationships in the input to their Senior Companion system. The focus of the Senior Companion is to use the data extracted from the user utterances to collect information about the user’s life. While our input analysis system is similar, it uses regular expression patterns over annotations for the matching of relations between, and properties of, individuals 5http://velocity.apache.org/ and classes. In terms of functionality, our system focuses on being able to answer user requests and provide c</context>
</contexts>
<marker>Catizone, Dingli, Pinto, Wilks, 2008</marker>
<rawString>Roberta Catizone, Alexiei Dingli, Hugo Pinto, and Yorick Wilks. 2008. Information extraction tools and methods for understanding dialogue in a companion. In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Cavazza</author>
<author>Cameron Smith</author>
<author>Daniel Charlton</author>
<author>Li Zhang</author>
<author>Markku Turunen</author>
<author>Jaakko Hakulinen</author>
</authors>
<title>A ’companion’ ECA with planning and activity modelling.</title>
<date>2008</date>
<booktitle>In AAMAS ’08: Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems,</booktitle>
<pages>1281--1284</pages>
<contexts>
<context position="21436" citStr="Cavazza et al. (2008)" startWordPosition="3534" endWordPosition="3537"> to their work, our memory is not concerned with remembering locations, but with finding items relevant for current dialogue in the episodic memory of the agent, and thus stores different data. Both the adaptive mind agent by Krenn et al. (2009) and Gossip Galore (Xu et al., 2009) describe companion systems able to answer questions on domain data. Both agents only have limited knowledge of their own past and do not use it for dialogue. Thus they cannot ground dialogue in their own experiences, and are unable to leverage knowledge about user preferences for providing more interesting dialogue. Cavazza et al. (2008) describe a companion system for helping users plan a healthier lifestyle. Dialogue can be driven by the companion or by the user, but revolves around agreeing upon a daily exercise plan or negotiating re-planning in case of plan failure. Our system aims at a more open kind of dialogue which does not revolve around a plan model. Instead, the user is able to ask different kinds of questions on all the domain data available, which leaves the companion in a situation where much less expectations can be made towards the next user utterance. 6 Conclusion We have presented a model of a companion tha</context>
</contexts>
<marker>Cavazza, Smith, Charlton, Zhang, Turunen, Hakulinen, 2008</marker>
<rawString>Marc Cavazza, Cameron Smith, Daniel Charlton, Li Zhang, Markku Turunen, and Jaakko Hakulinen. 2008. A ’companion’ ECA with planning and activity modelling. In AAMAS ’08: Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems, pages 1281–1284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>An argument for basic emotions. Cognition and Emotion,</title>
<date>1992</date>
<pages>6--169</pages>
<contexts>
<context position="1822" citStr="Ekman, 1992" startWordPosition="289" endWordPosition="290">ping companions, the goal is to model and implement artificial ”caring developing helpers” (Sloman, 2007) that learn and develop over time to be of long-term benefit for the user. In order to come closer to the vision of artificial companions a number of research issues need to be addressed such as: action-perception and learning capabilities suitable to function with imperfect sensors in dynamically changing environments which can only be partially modelled; the development of affect sensing capabilities that extend over the detection of basic emotions such as joy, anger, fear, disgust etc. (Ekman, 1992); user models that account for and adapt to the users’ interests, preferences, affective states, needs and handicaps; approaches to multimodal dialogue that allow the agent’s mental models and memories to be connected to its expressive behaviour (Castellano et al., 2008), and where natural language dialogue is semantically grounded (Benyon and Mival, 2008). Companions need to be aware of their own history and past interactions with their individual users, so that the single user can believe that her/his companion knows “what it is talking about”. This is particularly important for creating acc</context>
</contexts>
<marker>Ekman, 1992</marker>
<rawString>Paul Ekman. 1992. An argument for basic emotions. Cognition and Emotion, 6:169–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Birgit Graf</author>
<author>Ulrich Reiser</author>
<author>Martin H¨agele</author>
<author>Kathrin Mauz</author>
<author>Peter Klein</author>
</authors>
<title>Robotic home assistant care-o-bot 3 - product vision and innovation platform.</title>
<date>2009</date>
<booktitle>In IEEE / Robotics and Automation Society: IEEE Workshop on Advanced Robotics and its Social Impacts - ARSO</booktitle>
<pages>139--144</pages>
<publisher>Piscataway.</publisher>
<location>New York, NY, USA.</location>
<marker>Graf, Reiser, H¨agele, Mauz, Klein, 2009</marker>
<rawString>Birgit Graf, Ulrich Reiser, Martin H¨agele, Kathrin Mauz, and Peter Klein. 2009. Robotic home assistant care-o-bot 3 - product vision and innovation platform. In IEEE / Robotics and Automation Society: IEEE Workshop on Advanced Robotics and its Social Impacts - ARSO 2009, pages 139–144, New York, NY, USA. Piscataway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wan Ching Ho</author>
<author>Kerstin Dautenhahn</author>
</authors>
<title>Towards a narrative mind: The creation of coherent life stories for believable virtual agents.</title>
<date>2008</date>
<booktitle>In IVA ’08: Proceedings of the 8th international conference on Intelligent Virtual Agents,</booktitle>
<pages>59--72</pages>
<publisher>Springer.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="20422" citStr="Ho and Dautenhahn, 2008" startWordPosition="3362" endWordPosition="3366">lysis system is similar, it uses regular expression patterns over annotations for the matching of relations between, and properties of, individuals 5http://velocity.apache.org/ and classes. In terms of functionality, our system focuses on being able to answer user requests and provide continued dialogue by taking into account the previous interactions with the user. Episodic memory has first been distinguished from other memory types by Tulving (1972). Implementations have for example been used in artificial life agents (Nuxoll, 2007; Ho et al., 2003), in storytelling agents (Ho et al., 2007; Ho and Dautenhahn, 2008), and for non-player characters in games (Brom et al., 2007; Brom and Lukavsk´y, 2009). Since our memory component is realised as an RDF graph, nearest–neighbour search as in the memory model proposed by Nuxoll (2007) does not directly apply. Brom and Lukavsk´y (2009) summarise important aspects of episodic memory and propose a more detailed concept of time categories than ours. In contrast to their work, our memory is not concerned with remembering locations, but with finding items relevant for current dialogue in the episodic memory of the agent, and thus stores different data. Both the adap</context>
</contexts>
<marker>Ho, Dautenhahn, 2008</marker>
<rawString>Wan Ching Ho and Kerstin Dautenhahn. 2008. Towards a narrative mind: The creation of coherent life stories for believable virtual agents. In IVA ’08: Proceedings of the 8th international conference on Intelligent Virtual Agents, pages 59–72, Berlin, Heidelberg. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wan Ching Ho</author>
<author>Kerstin Dautenhahn</author>
<author>Chrystopher L Nehaniv</author>
</authors>
<title>Comparing different control architectures for autobiographic agents in static virtual environments.</title>
<date>2003</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>2792</volume>
<pages>182--191</pages>
<editor>In Thomas Rist, Ruth Aylett, Daniel Ballin, and Jeff Rickel, editors, IVA,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="20355" citStr="Ho et al., 2003" startWordPosition="3351" endWordPosition="3354">lect information about the user’s life. While our input analysis system is similar, it uses regular expression patterns over annotations for the matching of relations between, and properties of, individuals 5http://velocity.apache.org/ and classes. In terms of functionality, our system focuses on being able to answer user requests and provide continued dialogue by taking into account the previous interactions with the user. Episodic memory has first been distinguished from other memory types by Tulving (1972). Implementations have for example been used in artificial life agents (Nuxoll, 2007; Ho et al., 2003), in storytelling agents (Ho et al., 2007; Ho and Dautenhahn, 2008), and for non-player characters in games (Brom et al., 2007; Brom and Lukavsk´y, 2009). Since our memory component is realised as an RDF graph, nearest–neighbour search as in the memory model proposed by Nuxoll (2007) does not directly apply. Brom and Lukavsk´y (2009) summarise important aspects of episodic memory and propose a more detailed concept of time categories than ours. In contrast to their work, our memory is not concerned with remembering locations, but with finding items relevant for current dialogue in the episodic</context>
</contexts>
<marker>Ho, Dautenhahn, Nehaniv, 2003</marker>
<rawString>Wan Ching Ho, Kerstin Dautenhahn, and Chrystopher L. Nehaniv. 2003. Comparing different control architectures for autobiographic agents in static virtual environments. In Thomas Rist, Ruth Aylett, Daniel Ballin, and Jeff Rickel, editors, IVA, volume 2792 of Lecture Notes in Computer Science, pages 182–191. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wan Ching Ho</author>
<author>Jo˜ao Dias</author>
<author>Rui Figueiredo</author>
<author>Ana Paiva</author>
</authors>
<title>Agents that remember can tell stories: integrating autobiographic memory into emotional agents.</title>
<date>2007</date>
<pages>10</pages>
<editor>In Edmund H. Durfee, Makoto Yokoo, Michael N. Huhns, and Onn Shehory, editors, AAMAS,</editor>
<publisher>IFAAMAS.</publisher>
<contexts>
<context position="20396" citStr="Ho et al., 2007" startWordPosition="3358" endWordPosition="3361">ile our input analysis system is similar, it uses regular expression patterns over annotations for the matching of relations between, and properties of, individuals 5http://velocity.apache.org/ and classes. In terms of functionality, our system focuses on being able to answer user requests and provide continued dialogue by taking into account the previous interactions with the user. Episodic memory has first been distinguished from other memory types by Tulving (1972). Implementations have for example been used in artificial life agents (Nuxoll, 2007; Ho et al., 2003), in storytelling agents (Ho et al., 2007; Ho and Dautenhahn, 2008), and for non-player characters in games (Brom et al., 2007; Brom and Lukavsk´y, 2009). Since our memory component is realised as an RDF graph, nearest–neighbour search as in the memory model proposed by Nuxoll (2007) does not directly apply. Brom and Lukavsk´y (2009) summarise important aspects of episodic memory and propose a more detailed concept of time categories than ours. In contrast to their work, our memory is not concerned with remembering locations, but with finding items relevant for current dialogue in the episodic memory of the agent, and thus stores dif</context>
</contexts>
<marker>Ho, Dias, Figueiredo, Paiva, 2007</marker>
<rawString>Wan Ching Ho, Jo˜ao Dias, Rui Figueiredo, and Ana Paiva. 2007. Agents that remember can tell stories: integrating autobiographic memory into emotional agents. In Edmund H. Durfee, Makoto Yokoo, Michael N. Huhns, and Onn Shehory, editors, AAMAS, page 10. IFAAMAS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Marcin Skowron</author>
<author>Gregor Sieber</author>
<author>Erich Gstrein</author>
<author>J¨org Irran</author>
</authors>
<title>Adaptive mind agent.</title>
<date>2009</date>
<booktitle>In IVA ’09: Proceedings of the 9th International Conference on Intelligent Virtual Agents,</booktitle>
<pages>519--520</pages>
<publisher>Springer.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="21060" citStr="Krenn et al. (2009)" startWordPosition="3468" endWordPosition="3471">r characters in games (Brom et al., 2007; Brom and Lukavsk´y, 2009). Since our memory component is realised as an RDF graph, nearest–neighbour search as in the memory model proposed by Nuxoll (2007) does not directly apply. Brom and Lukavsk´y (2009) summarise important aspects of episodic memory and propose a more detailed concept of time categories than ours. In contrast to their work, our memory is not concerned with remembering locations, but with finding items relevant for current dialogue in the episodic memory of the agent, and thus stores different data. Both the adaptive mind agent by Krenn et al. (2009) and Gossip Galore (Xu et al., 2009) describe companion systems able to answer questions on domain data. Both agents only have limited knowledge of their own past and do not use it for dialogue. Thus they cannot ground dialogue in their own experiences, and are unable to leverage knowledge about user preferences for providing more interesting dialogue. Cavazza et al. (2008) describe a companion system for helping users plan a healthier lifestyle. Dialogue can be driven by the companion or by the user, but revolves around agreeing upon a daily exercise plan or negotiating re-planning in case of</context>
</contexts>
<marker>Krenn, Skowron, Sieber, Gstrein, Irran, 2009</marker>
<rawString>Brigitte Krenn, Marcin Skowron, Gregor Sieber, Erich Gstrein, and J¨org Irran. 2009. Adaptive mind agent. In IVA ’09: Proceedings of the 9th International Conference on Intelligent Virtual Agents, pages 519–520, Berlin, Heidelberg. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Nuxoll</author>
</authors>
<title>Enhancing Intelligent Agents with Episodic Memory.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Univ. of Michigan,</institution>
<location>Ann Arbor.</location>
<contexts>
<context position="10704" citStr="Nuxoll (2007)" startWordPosition="1734" endWordPosition="1735">lly, there are two approaches to this: episode blending and forgetting. Episode blending refers to a mechanism that groups similar experiences into one episode. Less important parameters of the memories are lost, and the similarities strengthened. This would mean the agent can remember what happened, and that it happened more than once, but the exact situations are lost. Episode blending is an interesting aspect of episodic memory that will be pursued in our future work. Forgetting refers to the deletion of episodes. Ideally, the episodes with least utility to the companion should be deleted. Nuxoll (2007) provides a list of possible approaches regarding forgetting: 1) remove the oldest memory first, 2) remove the least activated memory, 3) remove the most redundant memory, 4) memory decay. Approach 1) does not take the importance of episodes into account and may result in losing important information. Approaches 2) and 4) both depend on assigning activation values to episodes, and delete those with the least activation. The idea of 3) is to locate two memories that are very similar to each other and remove one of them. Our initial strategy is to assign a time-stamp of last retrieval to each ep</context>
<context position="20337" citStr="Nuxoll, 2007" startWordPosition="3349" endWordPosition="3350">erances to collect information about the user’s life. While our input analysis system is similar, it uses regular expression patterns over annotations for the matching of relations between, and properties of, individuals 5http://velocity.apache.org/ and classes. In terms of functionality, our system focuses on being able to answer user requests and provide continued dialogue by taking into account the previous interactions with the user. Episodic memory has first been distinguished from other memory types by Tulving (1972). Implementations have for example been used in artificial life agents (Nuxoll, 2007; Ho et al., 2003), in storytelling agents (Ho et al., 2007; Ho and Dautenhahn, 2008), and for non-player characters in games (Brom et al., 2007; Brom and Lukavsk´y, 2009). Since our memory component is realised as an RDF graph, nearest–neighbour search as in the memory model proposed by Nuxoll (2007) does not directly apply. Brom and Lukavsk´y (2009) summarise important aspects of episodic memory and propose a more detailed concept of time categories than ours. In contrast to their work, our memory is not concerned with remembering locations, but with finding items relevant for current dialog</context>
</contexts>
<marker>Nuxoll, 2007</marker>
<rawString>Andrew Nuxoll. 2007. Enhancing Intelligent Agents with Episodic Memory. Ph.D. thesis, Univ. of Michigan, Ann Arbor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcin Skowron</author>
<author>J¨org Irran</author>
<author>Brigitte Krenn</author>
</authors>
<title>Computational framework for and the realization of cognitive agents providing intelligent assistance capabilities.</title>
<date>2008</date>
<booktitle>In 18th European Conference on Artificial Intelligence, Cognitive Robotics Workshop,</booktitle>
<pages>88--96</pages>
<contexts>
<context position="1063" citStr="Skowron et al., 2008" startWordPosition="161" endWordPosition="164">pisodic memory is based on RDF representations of the agent’s experiences and is linked to the agent’s semantic memory containing the agent’s knowledge base of ontological data and information about the user’s interests. 1 Introduction Recently, research on artificial companions has come more and more in focus. They are artificial agents (virtual or robotic) that are intended to support the human user in aspects of everyday life. They may range from virtual agents that assist their users in accessing information from the Internet in accordance with the users’ interests, preferences and needs (Skowron et al., 2008), up to assistive robots in home environments that support elderly in mastering their life at home (Graf et al., 2009). In the long run when developing companions, the goal is to model and implement artificial ”caring developing helpers” (Sloman, 2007) that learn and develop over time to be of long-term benefit for the user. In order to come closer to the vision of artificial companions a number of research issues need to be addressed such as: action-perception and learning capabilities suitable to function with imperfect sensors in dynamically changing environments which can only be partially</context>
</contexts>
<marker>Skowron, Irran, Krenn, 2008</marker>
<rawString>Marcin Skowron, J¨org Irran, and Brigitte Krenn. 2008. Computational framework for and the realization of cognitive agents providing intelligent assistance capabilities. In 18th European Conference on Artificial Intelligence, Cognitive Robotics Workshop, pages 88–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron Sloman</author>
</authors>
<title>Requirements for Digital Companions It’s harder than you think.</title>
<date>2007</date>
<booktitle>In Position Paper for Workshop on Artificial Companions in Society: Perspectives on the Present and</booktitle>
<institution>Future. Oxford Internet Institute.</institution>
<contexts>
<context position="1315" citStr="Sloman, 2007" startWordPosition="206" endWordPosition="207">tificial companions has come more and more in focus. They are artificial agents (virtual or robotic) that are intended to support the human user in aspects of everyday life. They may range from virtual agents that assist their users in accessing information from the Internet in accordance with the users’ interests, preferences and needs (Skowron et al., 2008), up to assistive robots in home environments that support elderly in mastering their life at home (Graf et al., 2009). In the long run when developing companions, the goal is to model and implement artificial ”caring developing helpers” (Sloman, 2007) that learn and develop over time to be of long-term benefit for the user. In order to come closer to the vision of artificial companions a number of research issues need to be addressed such as: action-perception and learning capabilities suitable to function with imperfect sensors in dynamically changing environments which can only be partially modelled; the development of affect sensing capabilities that extend over the detection of basic emotions such as joy, anger, fear, disgust etc. (Ekman, 1992); user models that account for and adapt to the users’ interests, preferences, affective stat</context>
</contexts>
<marker>Sloman, 2007</marker>
<rawString>Aaron Sloman. 2007. Requirements for Digital Companions It’s harder than you think. In Position Paper for Workshop on Artificial Companions in Society: Perspectives on the Present and Future. Oxford Internet Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Endel Tulving</author>
</authors>
<title>Episodic and semantic memory.</title>
<date>1972</date>
<booktitle>Organization of Memory,</booktitle>
<pages>381--403</pages>
<editor>In E. Tulving and W. Donaldson, editors,</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="20253" citStr="Tulving (1972)" startWordPosition="3335" endWordPosition="3336">stem. The focus of the Senior Companion is to use the data extracted from the user utterances to collect information about the user’s life. While our input analysis system is similar, it uses regular expression patterns over annotations for the matching of relations between, and properties of, individuals 5http://velocity.apache.org/ and classes. In terms of functionality, our system focuses on being able to answer user requests and provide continued dialogue by taking into account the previous interactions with the user. Episodic memory has first been distinguished from other memory types by Tulving (1972). Implementations have for example been used in artificial life agents (Nuxoll, 2007; Ho et al., 2003), in storytelling agents (Ho et al., 2007; Ho and Dautenhahn, 2008), and for non-player characters in games (Brom et al., 2007; Brom and Lukavsk´y, 2009). Since our memory component is realised as an RDF graph, nearest–neighbour search as in the memory model proposed by Nuxoll (2007) does not directly apply. Brom and Lukavsk´y (2009) summarise important aspects of episodic memory and propose a more detailed concept of time categories than ours. In contrast to their work, our memory is not conc</context>
</contexts>
<marker>Tulving, 1972</marker>
<rawString>Endel Tulving. 1972. Episodic and semantic memory. In E. Tulving and W. Donaldson, editors, Organization of Memory, pages 381–403. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feiyu Xu</author>
<author>Peter Adolphs</author>
<author>Hans Uszkoreit</author>
<author>Xiwen Cheng</author>
<author>Hong Li</author>
</authors>
<title>Gossip galore: A conversational web agent for collecting and sharing pop trivia.</title>
<date>2009</date>
<pages>115--122</pages>
<editor>In Joaquim Filipe, Ana L. N. Fred, and Bernadette Sharp, editors, ICAART,</editor>
<publisher>INSTICC Press.</publisher>
<contexts>
<context position="21096" citStr="Xu et al., 2009" startWordPosition="3475" endWordPosition="3478">7; Brom and Lukavsk´y, 2009). Since our memory component is realised as an RDF graph, nearest–neighbour search as in the memory model proposed by Nuxoll (2007) does not directly apply. Brom and Lukavsk´y (2009) summarise important aspects of episodic memory and propose a more detailed concept of time categories than ours. In contrast to their work, our memory is not concerned with remembering locations, but with finding items relevant for current dialogue in the episodic memory of the agent, and thus stores different data. Both the adaptive mind agent by Krenn et al. (2009) and Gossip Galore (Xu et al., 2009) describe companion systems able to answer questions on domain data. Both agents only have limited knowledge of their own past and do not use it for dialogue. Thus they cannot ground dialogue in their own experiences, and are unable to leverage knowledge about user preferences for providing more interesting dialogue. Cavazza et al. (2008) describe a companion system for helping users plan a healthier lifestyle. Dialogue can be driven by the companion or by the user, but revolves around agreeing upon a daily exercise plan or negotiating re-planning in case of plan failure. Our system aims at a </context>
</contexts>
<marker>Xu, Adolphs, Uszkoreit, Cheng, Li, 2009</marker>
<rawString>Feiyu Xu, Peter Adolphs, Hans Uszkoreit, Xiwen Cheng, and Hong Li. 2009. Gossip galore: A conversational web agent for collecting and sharing pop trivia. In Joaquim Filipe, Ana L. N. Fred, and Bernadette Sharp, editors, ICAART, pages 115–122. INSTICC Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>