<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.9948755">
Large-Scale Discriminative Training for Statistical Machine Translation
Using Held-Out Line Search
</title>
<author confidence="0.99766">
Jeffrey Flanigan Chris Dyer Jaime Carbonell
</author>
<affiliation confidence="0.889578666666667">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998867">
{jflanigan,cdyer,jgc}@cs.cmu.edu
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999663521739131">
We introduce a new large-scale discrimina-
tive learning algorithm for machine translation
that is capable of learning parameters in mod-
els with extremely sparse features. To ensure
their reliable estimation and to prevent over-
fitting, we use a two-phase learning algorithm.
First, the contribution of individual sparse fea-
tures is estimated using large amounts of par-
allel data. Second, a small development cor-
pus is used to determine the relative contri-
butions of the sparse features and standard
dense features. Not only does this two-phase
learning approach prevent overfitting, the sec-
ond pass optimizes corpus-level BLEU of the
Viterbi translation of the decoder. We demon-
strate significant improvements using sparse
rule indicator features in three different trans-
lation tasks. To our knowledge, this is the
first large-scale discriminative training algo-
rithm capable of showing improvements over
the MERT baseline with only rule indicator
features in addition to the standard MERT fea-
tures.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981113636364">
This paper is about large scale discriminative
training of machine translation systems. Like
MERT (Och, 2003), our procedure directly optimizes
the cost of the Viterbi output on corpus-level met-
rics, but does so while scaling to millions of features.
The training procedure, which we call the Held-Out
Line Search algorithm (HOLS), is a two-phase iter-
ative batch optimization procedure consisting of (1)
a gradient calculation on a differentiable approxima-
tion to the loss on a large amount of parallel training
data and (2) a line search (using the standard MERT
algorithm) to search in a subspace defined by the
gradient for the weights that minimize the true cost.
While sparse features are successfully used in
many NLP systems, such parameterizations pose a
number of learning challenges. First, since any one
feature is likely to occur infrequently, a large amount
of training data is necessary to reliably estimate their
weights. Therefore, we use the full parallel train-
ing data (rather than a small development set) to
estimate the contribution of the sparse features in
phase 1. Second, sparse features can lead to overfit-
ting. To prevent this from hurting our model’s ability
to generalize to new data, we do two things. First,
we use “grammar and language model folds” (trans-
lation grammars and language models built from
other portions of the training data than are being
used for discriminative training), and second, we
run the phase 2 line search on a held-out develop-
ment set. Finally, since our algorithm requires de-
coding the entire training corpus, it is desirable (on
computational grounds) to only require one or two
passes through the training data. To get the most out
of these passes, we rescale features by their inverse
frequency which improves the scaling of the opti-
mization problem. In addition to learning with few
passes through the training data, the HOLS algorithm
has the advantage that it is easily parallelizable.
After reviewing related work in the next section,
we analyze two obstacles to effective discriminative
learning for machine translation: overfitting (since
both rules and their weights must be learned, if they
are learned together degenerate solutions that fail to
generalize are possible) and poor scaling (since MT
</bodyText>
<page confidence="0.965982">
248
</page>
<note confidence="0.471781">
Proceedings of NAACL-HLT 2013, pages 248–258,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.99971">
decoding is so expensive, it is not feasible to make
many passes through large amounts of training data,
so optimization must be efficient). We then present
the details of our algorithm that addresses these is-
sues, give results on three language pairs, and con-
clude.
</bodyText>
<sectionHeader confidence="0.999929" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999758886363636">
Discriminative training of machine translation sys-
tems has been a widely studied problem for the
last ten years. The pattern of using small, high-
quality development sets to tune a relatively small
number of weights was established early (Och and
Ney, 2002; Och, 2003). More recently, standard
structured prediction algorithms that target linearly
decomposable approximations of translation qual-
ity metrics have been thoroughly explored (Liang et
al., 2006; Smith and Eisner, 2006; Watanabe et al.,
2007; Rosti et al., 2010; Hopkins and May, 2011;
Chiang, 2012; Gimpel and Smith, 2012; Cherry and
Foster, 2012; Saluja et al., 2012). These have with-
out exception used sentence-level approximations of
BLEU to determine oracles and update weights using
a variety of criteria and with a variety of different
theoretical justifications.
Despite advancements in discriminative training
for machine translation, large-scale discriminative
training with rule indicator features has remained
notoriously difficult. Rule indicator features are an
extremely sparse and expressive parameterization of
the translation model: every rule has a feature, each
of which has its own separately tuned weight, which
count how often a specific rule is used in a trans-
lation. Early experiments (Liang et al., 2006) used
the structured perceptron to tune a phrase-based sys-
tem on a large subset of the training data, show-
ing improvements when using rule indicator fea-
tures, word alignment features, and POS tag fea-
tures. Another early attempt (Tillmann and Zhang,
2006) used phrase pair and word features in a block
SMT system trained using stochastic gradient de-
scent for a convex loss function, but did not compare
to MERT. Problems of overfitting and degenerate
derivations were tackled with a probabilistic latent
variable model (Blunsom et al., 2008) which used
rule indicator features yet failed to improve upon
the MERT baseline for the standard Hiero features.
Techniques for distributed learning and feature se-
lection for the perceptron loss using rule indicator,
rule shape, and source side-bigram features have re-
cently been proposed (Simianer et al., 2012), but no
comparison to MERT was made.
</bodyText>
<sectionHeader confidence="0.992362" genericHeader="method">
3 Difficulties in Large-Scale Training
</sectionHeader>
<bodyText confidence="0.999980444444444">
Discriminative training for machine translation is
complicated by several factors. First, both transla-
tion rules and feature weights are learned from par-
allel data. If the same data is used for both tasks,
overfitting of the weights is very possible.1 Second,
the standard MT cost function, BLEU (Papineni et
al., 2002), does not decompose additively over train-
ing instances (because of the “brevity penalty”) and
so approximations are used—these often have prob-
lems with the length (Nakov et al., 2012). Finally,
state-of-the-art MT systems make extensive good
use of “dense” features, such as the log probabil-
ity of translation decisions under a simpler gener-
ative translation model. Our goal is to begin to
use much sparser features without abandoning the
proven dense features; however, extremely sparse
features leads to problems of scaling in the optimiza-
tion problem as we will show.
</bodyText>
<subsectionHeader confidence="0.999958">
3.1 Training Data and Overfitting
</subsectionHeader>
<bodyText confidence="0.999823235294118">
One of the big questions in discriminative train-
ing of machine translation systems is why standard
machine learning techniques can perform so poorly
when applied to large-scale learning on the train-
ing data. Figure 1 shows a good example of this.
The structured SVM (Tsochantaridis et al., 2004;
Cherry and Foster, 2012) was used to learn the
weights for a Chinese-English Hiero system (Chi-
ang, 2005) with just eight features, using stochastic
gradient descent (SGD) for online learning (Bottou,
1998; Bottou, 2010). The weights were initialized
from MERT values tuned on a 2k-sentence dev set
(MT06), and the figure shows the progress of the on-
line method during a single pass through the 300k-
sentence Chinese-English FBIS training set.
As the training progresses in Figure 1, BLEU
scores on the training data go up, but scores on the
</bodyText>
<footnote confidence="0.999485666666667">
1Previous work has attempted to mitigate the risk of overfit-
ting through careful regularization (Blunsom et al., 2008; Simi-
aner et al., 2012).
</footnote>
<page confidence="0.997724">
249
</page>
<figureCaption confidence="0.996568">
Figure 1: Progress of the online SVM training
</figureCaption>
<bodyText confidence="0.990844552631579">
method after each training instance on FBIS dataset.
The solid line is BLEU on the test set, training set is
the dashed line, and the dev set is dotted.
dev and test sets go down. If we hope to apply dis-
criminative training techniques for not eight but mil-
lions of features on the training data, we must find a
way to prevent this overfitting.
We suggest that an important reason why overfit-
ting occurs is that the training data is used not only to
tune the system but also to extract the grammar, and
the target side is included in the data used to build
the language model. To test this hypothesis, we
compare tuning using three different dev sets: 1000
sentences from the standard 4-reference MT06 dev
set (Dev1000), a random selection of 1000 sentences
that overlap with the corpus used to extract transla-
tion rules (In1000), and 1000 sentences that came
from the training data but were then excluded from
rule extraction (Out1000). We run MERT on each of
these and evaluate. For evaluation we compare three
different sets: a random 1000 sentences from the
training corpus that was used to create the grammars
but which do not overlap with In1000 (Train1000),
the 1000 sentence dev set (Dev1000), and the stan-
dard 4-reference MT02-03 test set (Test). The en-
tire experiment (including selection of the 1000 sen-
tences) was replicated 5 times.
Table 1 shows the results, averaging over repli-
cations. Out1000 gives much higher scores on the
testing data, validating our hypothesis that tuning on
data used to build the LM and grammar can lead to
overfitting. However, the results also show that tun-
ing on the training data, even when it is held-out, can
still lead to a small reduction in translation quality.
One possible reason is that, unlike the training data
which may come from various domains, the dev data
is in the same domain as the test data and is typically
of higher quality (e.g., it has multiple references).
</bodyText>
<tableCaption confidence="0.998771">
Table 1: MERT on Zh-En FBIS
</tableCaption>
<table confidence="0.9679505">
Tuning Set Train1000 Dev1000 Test
Dev1000 32.2±1.1 30.2±.1 34.1±.3
In1000 37.0±1.2 25.7±.7 30.1±.6
Out1000 34.9±.8 29.0±.4 33.6±.5
</table>
<subsectionHeader confidence="0.999519">
3.2 Poor Scaling
</subsectionHeader>
<bodyText confidence="0.969871485714286">
When features occur with different frequencies,
changing the weights of more frequent features has
a larger effect than changing the weights of less fre-
quent features.2 An example of frequent features
that have a large impact on the translation quality are
the language model and translation model features.
These features are non-zero for every sentence, and
changing their weights slightly has a large impact on
translation output. In contrast, changing the weight
drastically for a feature that is non-zero for only one
out of a million sentences has very little effect on
translation metrics. The sensitivity of the translation
output to some feature weights over others was also
pointed out in a recent paper (Chiang, 2012).
When the objective function is more sensitive
in some dimensions than others, the optimization
problem is said to be poorly scaled (Nocedal and
Wright, 2000), and can slow down the convergence
rate for some optimizers. A typical fix is to rescale
the dimensions, as we will do in Section 5.2.
To verify that BLEU is poorly scaled with respect
to weights of rule indicator features, we look at the
effect of changing the weights for individual rules.
We vary the feature weights for four randomly cho-
sen frequent rules and four randomly chosen infre-
quent rules on our FBIS dev set (Figure 2). One
can think of this plot as a “cross-section” of the
BLEU score in the direction of the feature weight.
The dense features are set to MERT-tuned values
which are normalized to one. All other rule indi-
cator features are set to zero, except the rule fea-
ture weight that is varied. The frequent features
2By the “frequency of a feature” we mean this: given a set of
input instances, how many input instances the feature is nonzero
in the space of possible outputs for that input.
</bodyText>
<figure confidence="0.992152666666667">
0 50000 150000 250000
BLEU
26 30 34
</figure>
<page confidence="0.981574">
250
</page>
<bodyText confidence="0.999781">
were selected randomly from the 20 most common
rule indictor features in the n-best lists on the dev
set, and the infrequent features were selected from
the features that only occurred once in these n-best
lists. The plots indicate that the BLEU score is
</bodyText>
<figure confidence="0.98810675">
Weight
(a) Four representative frequent sparse features.
Weight
(b) Four representative infrequent sparse features
</figure>
<figureCaption confidence="0.971837666666667">
Figure 2: The effect of varying weights for rule indicator
features on the BLEU score. Note the difference of scale
on the y axis.
</figureCaption>
<bodyText confidence="0.999928333333333">
poorly scaled for rule feature weights. Changing the
weights for one of the common features changes the
BLEU score by almost 2.5 BLEU points, while for
the infrequent features the BLEU score changes by
at most .02 BLEU points. We take this as a sign that
gradient descent based optimizers for machine trans-
lation with rule features could be slow to converge
due to poor scaling, and that rescaling will improve
convergence.
</bodyText>
<subsectionHeader confidence="0.999596">
3.3 Sentence Level Approximations to BLEU
</subsectionHeader>
<bodyText confidence="0.999990277777778">
Finally, we note that discriminative training methods
often use a sentence level approximation to BLEU. It
has been shown that optimizing corpus level BLEU
versus sentence level BLEU can lead to improve-
ments of up to nearly .4 BLEU points on the test
set (Nakov et al., 2012). Possible fixes to this prob-
lem include using a proper sentence level metric
such a METEOR (Denkowski and Lavie, 2011) or a
pseudo-corpus from the last few updates (Chiang et
al., 2008). However, in light of the result from sec-
tion 3.1 that tuning on the dev set is still better than
tuning on a held-out portion of the training data, we
observe that tuning a corpus level metric on a high-
quality dev set from the same domain as the test set
probably leads to the best translation quality. At-
tempts to improve upon this strong baseline lead us
to the development of the HOLS algorithm which we
describe next.
</bodyText>
<sectionHeader confidence="0.975656" genericHeader="method">
4 Held-Out Line Search Algorithm
</sectionHeader>
<bodyText confidence="0.999936875">
In this section we give the details of the learning al-
gorithm that we developed for use in large-scale dis-
criminative training for machine translation, which
we call the Held-Out Line Search algorithm (abbre-
viated HOLS). It optimizes millions of features using
evidence from the full set of parallel training data
to obtain optimal predictive performance on a sec-
ondary development set.
The learning algorithm is a batch optimizer where
each iteration has two phases: a gradient calcula-
tion phase and a line search phase. In the gradient
calculation phase, a surrogate loss function is used
to compute a gradient for the feature weights. The
gradient is computed over a subset of the training
data. In the line search phase, a separate optimizer
(MERT) is used to search along this gradient to opti-
</bodyText>
<equation confidence="0.510110833333333">
−2 −1 0 1 2
BLEU
27.0 28.0 29.0 30.0
−10 −5 0 5 10
BLEU
30.100 30.105 30.110 30.115 30.120
</equation>
<page confidence="0.983445">
251
</page>
<bodyText confidence="0.999667545454546">
mize the evaluation score of the one-best prediction
of a translation system on a secondary development
set.3 The secondary dev set is a crucial aspect of
the algorithm that helps reduce overfitting (we will
demonstrate this in the experiments section).
During the line search phase we allow some of
the feature weights to be adjusted independently of
the line search. We will call the features we opti-
mize independently the dense features, and the fea-
tures we include in the line search the sparse fea-
tures.4 The feature vector space V is the direct sum
V = Vd ® Vs, where Vd is the vector space of
the dense features and Vs is the vector space of the
sparse features. The feature and weight vectors de-
compose as f = fd + f,, and u� = wd + us. fd and
wd are in the dense vector space, and the fs and ws
are in the sparse vector space.
In the gradient phase, we calculate a gradient of
the surrogate loss function and project it onto the
subspace of the sparse features. Let Ps be the pro-
jection operator onto Vs. Then the gradient projected
onto the sparse feature space is
</bodyText>
<equation confidence="0.829194">
9 = PsVw �L(w, Dg)
</equation>
<bodyText confidence="0.9999105">
where Dg is the subset of the training data used to
calculate this gradient, and L is the surrogate loss
function. This just sets the dense components of the
gradient of L to zero.
In the line search phase, we use a separate opti-
mizer to optimize the weights for the dense features
and the stepsize α. Let L be the loss function we
wish to minimize, then
</bodyText>
<equation confidence="0.816387">
(w*d, α*) = arg min L(wd + us + αg, Dl)
wdp
</equation>
<bodyText confidence="0.99875375">
Note ws is held fixed from the previous iteration. Dl
is the portion of the training data which is used in
the line search phase, and must not overlap with Dg
used in the gradient calculation phase.5
After the line search, the dense weights are up-
dated to w*d, and the sparse weights are updated with
ws &lt;--- ws + α*g. The process repeats for another
iteration as desired (or until convergence).
</bodyText>
<footnote confidence="0.994448166666667">
3While we use BLEU any loss function whose sufficient
statistics decompose over training instances could be used.
4The split over the features does not have to be done this
way in practice.
5L(wd, α*, Dl) can be thought of as unbiased or more accu-
rately less biased estimator of expected loss when Dl nD9 = 0.
</footnote>
<sectionHeader confidence="0.978555" genericHeader="method">
5 Procedure for Large-Scale Training
</sectionHeader>
<bodyText confidence="0.99992325">
Now that we have described the HOLS algorithm in
general, we next describe how to apply it to large-
scale training of machine translation systems with
millions of features. We find that it is necessary to
use disjoint sets of training instances for grammar
extraction and gradient estimation (§5.1) and to deal
with the poor scaling of the optimization problem
(§5.2).
</bodyText>
<subsectionHeader confidence="0.908534">
5.1 Grammar and Language Model Folds
</subsectionHeader>
<bodyText confidence="0.999355805555556">
To address the problem of overfitting on the train-
ing data, we split the training data into n-folds, and
extract grammars for each fold using the data from
the other n −1 folds. Similarly, we build a language
model for each fold using a target language mono-
lingual corpus and the target side of the training data
from the other n − 1 folds. Whenever we decode a
sentence from the training data, we use the gram-
mar and language model for the appropriate fold.
This ensures that a sentence is never decoded using a
grammar or language model it helped build, thereby
reducing the overfitting effect demonstrated in §3.1.
To perform the training, the HOLS algorithm is
used on the training data. In our experiments, only
1-2 passes over the training data are necessary for
significant gains. Data from one of the grammar
folds is used for the line search, and the rest of the
training data is used to calculate the gradient.
The procedure is iterative, first decoding training
data to obtain a gradient, and then performing a line
search with data from a held-out grammar fold. In-
stead of decoding the whole set of sentences used for
the gradient updates at once, one can also decode a
portion of the data, do a gradient update, and then
continue the next iteration of HOLS on the remain-
ing data before repeating.
The last line search of the HOLS algorithm is done
using dev data, rather than training data. This is be-
cause the dev data is higher quality, and from Table
1 we can see that tuning on dev data produces bet-
ter results than tuning on training data (even if the
training data has been held out from the grammar
process). The initial weights are obtained by run-
ning MERT on a subset of the one of the grammar
folds.
If one has an existing implementation of an op-
</bodyText>
<page confidence="0.985021">
252
</page>
<bodyText confidence="0.971420071428571">
timizer for the loss function used during the line
search (in our case MERT), it can be used to perform
the line search. This is done simply by calling MERT
with two extra features in addition to the dense fea-
tures and omitting the sparse features.
To see how, notice that the feature weights
during the line search are decomposed as w~ =
~wdense + ~wsparse + α~g where g~ is in the sparse
feature subspace, so the model score decomposes
as score(x, y) = ~wd ·
~fs(x, y) where x is the input translation, y is
the output translation and derivation. If we cre-
ate two new features f1(x, y) = ~ws · ~fs(x, y) and
f2(x, y) = g~ · ~fs(x, y) then the score can be written
</bodyText>
<equation confidence="0.894175923076923">
score(x, y) = ~wd ·
y) +
y)
1,
f1,
+f1(x,
αf2(x,
=(~wd,
α)·(~fd,
f2)
ing
MERT with the features ( ~fd, f1, f2). 6
MERT on a
</equation>
<bodyText confidence="0.986380867924528">
subset of the remaining fold to do the
line search, 6) repeat steps 3-4 until convergence or
stop as desired, and 7) run MERT on the normal dev
set as a final step. We only run MERT on a
subset
of one of the folds so it does not require running
MERT on an entire fold.
In the special case where just one iteration of
HOLS is performed, the procedure is very simple:
decode the training data to get a gradient, include
the components of the gradient as an extra feature
f2 in addition to the dense features, an
10k
10k
d tune on a
dev set using MERT.
253 the gradient by the number of n-best lists in which
the feature was non-zero in.
The necessity for conditioning is evident when we
run the
algorithm as detailed so far on the
training data without conditioning. On subsequent
iterations, we observe that the features with the high-
est component of the gradient oscillate between iter-
ations, but the rest of the feature gradients stay the
same.
Based on our knowledge that the optimization
problem was poorly scaled, we divided by the fre-
quency of the feature. We can give the following
heuristic justification for our method of condition-
ing. For the ith feature weight, we will take a step
Assume that we want to take the step
pro-
portional to the average gradient
calculated from
n-best lists in which the feature is non-zero. In other
words, we want
=
Let gz be the total
gradient calculated by adding the gradients over all
n-best lists (i.e. summing over training examples
in the corpus). For a feature that is nonzero in ex-
actly nz n-best lists, the gradient from each example
will have been added up nz times, so the total gra-
Therefore we should take the step
In other words, we rescale each
component gz of the gradient by 1/nz before taking
the gradient step.
We can relate this argument back to the oscillation
we observed of the rule feature weights. For rules
that are used a thousand times more often than the
average rule, the corresponding component of the
weight should be a thousan
</bodyText>
<figure confidence="0.7377195">
HOLS
Δwz.
Δwz
ˆgz
Δwz
αˆgz.
nzˆgz.
Δwz
αgz/nz.
Δwz
d times larger in each it-
eration.
dient gz =
=
</figure>
<sectionHeader confidence="0.769075" genericHeader="method">
6 Experiments
</sectionHeader>
<equation confidence="0.988901">
~fd(x, y) + ~ws · ~fs(x, y) +
α~g ·
~fd(x, y)
</equation>
<bodyText confidence="0.9908455">
Thus we can do the line search simply by call
In summary our training algorithm is as follows:
</bodyText>
<listItem confidence="0.789442">
1) split the training data into n-folds (we use n = 5),
2) initialize the dense weights to MERT values, 3)
</listItem>
<bodyText confidence="0.6955895">
decode some or all the data in 4 of the 5 folds to get
a gradient, 4) condition as in §5.2 (see below), 5) run
</bodyText>
<subsectionHeader confidence="0.998349">
5.2 Conditioning
</subsectionHeader>
<bodyText confidence="0.997965352941176">
To address the problem of poor scaling, we use a
simple strategy of rescaling each component of the
gradient is roughly a thousand times larger. But that
does not indicate that the adjustment
to the rule
We evaluate and analyze the performance of our
training method with three sets of experiments. The
first set of experiments compares
to other
tuning algorithms used in machine translation in a
medium-scale discriminative setting. The second set
looks in detail at
for large scale discriminative
training for aChinese-English task. The third set
looks at two other languages.
All the experiments use a Hiero MT system with
rule indicator features for the sparse features an
</bodyText>
<sectionHeader confidence="0.709514" genericHeader="method">
HOLS
HOLS
</sectionHeader>
<bodyText confidence="0.663955857142857">
d the
gradient based on how fr equent the feature is. We
call this process “conditioning.” For each feature,
we simply divide the corresponding dimension of
6We could constrain the weight for fl to be 1, but this is not
necessary since since MERT is invariant to the overall scale of
the weights.
</bodyText>
<tableCaption confidence="0.984135">
Table 2: Corpora
</tableCaption>
<table confidence="0.998414133333333">
Language Corpus Sentences Tokens Target
Source
En Gigaword 24M 594M
Ar-En Train 1M 7M 31M
Dev (MT06) 1797 13K 236K
MT05 1,056 7K 144K
MT08nw 813 5K 116K
MT05wb 547 5K 89K
Mg-En Train 89K 2.1M 1.7M
Dev 1,359 34K 28K
Test 1,133 29K 24K
Zh-En Train (FBIS) 302K 1M 9.3M
Dev (MT06) 1,664 4K 192K
Test (MT02-03) 1,797 5K 223K
MT08 1,357 4K 167K
</table>
<bodyText confidence="0.999956739130435">
following 8 dense features: LM, phrasal and lexi-
cal p(e|f) and p(f|e), phrase and word penalties,
and glue rule. The total number of features is 2.2M
(Mg-En), 28.8M (Ar-En), and 10.8M (Zh-En). The
same features are used for all tuning methods, ex-
cept MERT baseline which uses only dense features.
Although we extract different grammars from vari-
ous subsets of the training corpus, word alignments
were done using the entire training corpus. We use
GIZA++ for word alignments (Och and Ney, 2003),
Thrax (Weese et al., 2011) to extract the grammars,
our decoder is cdec (Dyer et al., 2010) which uses
KenLM (Heafield, 2011), and we used a 4-gram LM
built using SRILM (Stolcke, 2002). Our optimizer
uses code implemented in the pycdec python inter-
face to cdec (Chahuneau et al., 2012). To speed up
decoding, for each source RHS we filtered the gram-
mars to the top 15 rules ranked by p(e  |f). Statistics
about the datasets we used are listed in Table 2.
We use the “soft ramp 3” loss function (Gimpel,
2012; Gimpel and Smith, 2012) as the surrogate loss
function for calculating the gradient in HOLS. It is
defined as
</bodyText>
<equation confidence="0.996591666666667">
��˜ = � log
i=1 yEGen(xi)
I~w· ~f(xi,y)+cost(yi,y)
</equation>
<bodyText confidence="0.9999514375">
where the sum over i ranges over training exam-
ples, Gen(x) is the space of possible outputs and
derivations for the input x, and cost(yi, y) is add one
smoothing sentence level BLEU.7
Except where noted, all experiments are repeated
5 times and results are averaged, initial weights for
the dense features are drawn from a standard nor-
mal, and initial weights for the sparse features are
set to zero. We evaluate using MultEval (Clark et
al., 2011) and report standard deviations across opti-
mizer runs and significance at p = .05 using MultE-
val’s built-in permutation test. In the large-scale ex-
periments for HOLS, we only run the full optimizer
once, and report standard deviations using multiple
runs of the last MERT run (i.e. the last line search on
the dev data).
</bodyText>
<subsectionHeader confidence="0.998618">
6.1 Comparison Experiments for ZH-EN
</subsectionHeader>
<bodyText confidence="0.999900928571429">
Our first set of experiments compares the perfor-
mance of the proposed HOLS algorithm to learn-
ing algorithms popularly used in machine transla-
tion on a Chinese-English task. We also compare to
a close relative of the HOLS algorithm: optimizing
the soft ramp 3 loss directly with online stochastic
gradient descent and with conditioning. As we will
see, SGD SOFTRAMP3 performs significantly worse
than HOLS, despite both algorithms optimizing sim-
ilar loss functions.
In the experiments in this section, we do not use
the full version of the training setup described in
§5 since we wish to compare to algorithms that do
not necessarily scale to large amounts of training
data. We therefore use only one fifth of the train-
ing data for learning the weights for both the dense
and sparse features.
In this section we refer to the subset of the train-
ing data used to learn the weights as the tuning set
(Tune). The grammar and LM are built using the
training data that is not in the tuning set (the LM also
includes the English monolingual corpus), and the
weights for the features are tuned using the tuning
set. This is similar to the typical train-dev-test split
commonly used to tune machine translation systems,
except that the tuning set is much larger (60k sen-
tence pairs versus the usual 1k-2k) and comes from
a random subset of the training data rather than a
</bodyText>
<footnote confidence="0.89287125">
7We found this loss function to work well, but other “soft”
loss functions (Gimpel, 2012; Gimpel and Smith, 2012) also
work. Gen(x) is restricted to a k-best size of 1000. Following
(Gimpel, 2012) cost(yi, y) is multiplied by a factor of 20.
</footnote>
<equation confidence="0.987953333333333">
e~w·~f(xi,y)−cost(yi,y)
+ log � e
yEGen(xi)
</equation>
<page confidence="0.999135">
254
</page>
<tableCaption confidence="0.999442">
Table 3: Comparison Experiments for Zh-En
</tableCaption>
<table confidence="0.996903428571429">
Algorithm Tune MT08 Runtime
MERT 22.1±.1 23.1±.1 6 hours
PRO 23.8±.05 23.6±.1 2 weeks
MIRA 21.7±.1 22.5±.1 19 hours
SOFTRAMP3 21.5±.3 22.3±.3 29 hours
HOLS 22.3±.1 23.4±.1 10 hours
HILS 24.3±.2 22.4±.1 10 hours
</table>
<bodyText confidence="0.994364796296296">
specialized development set.
We compare MERT, PRO (Hopkins and May,
2011), MIRA (Chiang, 2012), SOFTRAMP3, HOLS,
and a variant of HOLS which we call HILS (discussed
below). For HOLS, we used 10k of the 60k tun-
ing set for the line search, and the rest of the tun-
ing set was used for calculating the gradient. For
HILS (“Held-In” Line Search), the full 60k tuning
set was used to calculate the gradient, but the line
search was on a 10k subset of that set. For MERT,
we used a 10k subset of the tuning data because it
takes a long time to run on large datasets, and it only
has the eight dense features and so does not need the
entire 60k tuning set. All the subsets are drawn ran-
domly. Conditioning was performed only for HOLS,
HILS, and SOFTRAMP3 because conditioning would
affect the regularizer for PRO and require modifica-
tions to the MIRA algorithm. To do the condition-
ing for SOFTRAMP3 we used rule count during ex-
traction of the grammar and not the frequency in
the n-best lists because the online nature of SOFT-
RAMP3 prevents us from knowing how frequent a
rule will be (and the dense features are conditioned
using the corpus size). We chose MIRA’s best learn-
ing rate (,7 = .001) from 1.1, .01, .001}, used de-
fault settings for PRO in cdec, and for SOFTRAMP3
we used the same loss function as HOLS but included
an L2 regularizer of strength .001 and used a step-
size of 1 (which was scaled because of condition-
ing). To remedy problems of length bias for sentence
level BLEU, we used brevity penalty smoothed and
grounded BLEU+1 for sentence level scores (Nakov
et al., 2012). Tuning was repeated four times with
different initial weights, except for PRO which we
only ran three times (due to training costs). The ini-
tial weights for MERT were drawn from a standard
normal distribution, and final MERT weights were
used as the initial weights for the dense features for
the other algorithms. Initial weights for the sparse
features were set to zero. For HOLS, and HILS, tun-
ing set BLEU scores were evaluated on the set that
the line search was run on. We also report run times
for 8 threads on an Opteron 6220 processor.8
The results are shown in Table 3. PRO and HOLS
are a statistically significant improvement upon the
MERT baseline on the MT08 test data, but MIRA,
SOFTRAMP3, and HILS are not.
HILS dramatically overfits the tuning set, while
HOLS does not, justifying the use of a held-out
dataset for the line search. SOFTRAMP3 performs
significantly worse than HOLS on the test set. PRO is
a promising training algorithm, but does not scale to
the full FBIS corpus because it requires many itera-
tions.
</bodyText>
<subsectionHeader confidence="0.999486">
6.2 Full ZH-EN and Ablation Experiments
</subsectionHeader>
<bodyText confidence="0.999650357142857">
This set of experiments evaluates the performance
of the full HOLS algorithm described in §5 for
large-scale discriminative training on the full FBIS
Chinese-English dataset. Since this is a relatively
small and widely studied dataset, we also investigate
what happens if different aspects of the procedure
are omitted.
Table 4 gives the results. The number of updates
is the number of times the HOLS line search opti-
mizer is run (gradient updates). For 2 passes, 4 up-
dates, a line search is performed after a half pass
through the training data, which is repeated four
times for a total of two passes.
Using just one pass through the training data and
</bodyText>
<tableCaption confidence="0.8473045">
8Standard MIRA and SGD SOFTRAMP3 are not paralleliz-
able and only use a single thread. All of these algorithms were
run for one iteration, except for MERT which ran for at least
seven iterations, and PRO which we stopped after 20 iterations.
Table 4: Full-scale Chinese-English and Ablation
Experiments
</tableCaption>
<table confidence="0.999621166666667">
Configuration Dev Test
MERT Baseline 29.9±.3 34.0±.8
2 Pass, 4 updates 31.1±.2 35.1±.4
1 Pass, 1 update 30.7±.1 34.6±.5
−Folds 30.0±.2 34.0±.4
−Conditioning 30.1±.1 34.2±.2
</table>
<page confidence="0.955419">
255
</page>
<tableCaption confidence="0.997334">
Table 5: Arabic-English
</tableCaption>
<table confidence="0.9996505">
System Dev (MT06) MT05 MT08(nw) MT08(wb)
MERT Baseline 39.2±.4 50.3±.4 45.2±.2 29.4±.14
HOLS 1 Pass, 2 updates 39.9±.s 51.2±.4 45.8±.4 30.0±.4
OBLEU +.7 +.9 +.6 +.6
</table>
<tableCaption confidence="0.945416">
Table 6: Malagasy-English
</tableCaption>
<table confidence="0.99771625">
System Dev Test
MERT Baseline 19.8±.3 17.7±.2
HOLS 1 Pass, 1 update 20.5±.1 18.4±.2
OBLEU +.7 +.7
</table>
<bodyText confidence="0.9995978125">
one gradient update, HOLS improves upon the MERT
baseline by .6 BLEU points, which is a statistically
significant improvement. With 2 passes through the
training data and 4 gradient updates, HOLS performs
even better, obtaining a 1.1 BLEU point improve-
ment over the baseline and is also statistically signif-
icant. With 16 threads, 1 pass, 1 update completed
in 9 hours, and 2 pass, 4 updates, completed in 40
hours. The medium-scale PRO setup in §6.1 obtains
a result of 34.4 ±.1 on this test set, which is a statis-
tically significant improvement of .4 BLEU points
over the MERT baseline but does not beat the large-
scale HOLS results.
Is folding and conditioning necessary? We ex-
periment with what happens if grammar and LM
folds are not used and if conditioning is not done.
−Folds denotes 1 pass 1 update without folds, and
−Conditioning denotes 1 pass 1 update without con-
ditioning. We can see that both these steps are im-
portant for the training procedure to work well.
The decrease in performance of the training pro-
cedure without folds or conditioning is dramatic but
not too surprising. With just one gradient update,
one would expect conditioning to be very important.
And from the lessons learned in section 3.1, one
would also expect the procedure to perform poorly
or even worse than the MERT baseline without gram-
mar or LM folds. But because HOLS runs MERT on
the dev data for the last line search, it is almost im-
possible for HOLS to be worse than the MERT base-
line. (This, in fact, was part of our motivation when
we originally attempted the HOLS algorithm.)
</bodyText>
<subsectionHeader confidence="0.997919">
6.3 Other Language Pairs
</subsectionHeader>
<bodyText confidence="0.998126307692308">
The last set of experiments looks at the performance
of the learning algorithm for two other languages
and data scenarios for one pass through the training
data. Using the same setup for large-scale discrimi-
native training as before, we apply the training pro-
cedure to a large data scenario Arabic-English task
and a small data scenario Malagasy-English task
(Tables 5 and 6). The training procedure gives statis-
tically significant improvements over the baseline by
.6 to .9 BLEU for Arabic, and a statistically signif-
icant improvement of .7 BLEU for Malagasy. With
16 threads, the runtime was 44 hours for Arabic and
5 hours for Malagasy.
</bodyText>
<sectionHeader confidence="0.998891" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999955333333333">
We have explored the difficulties encountered
in large-scale discriminative training for machine
translation, and introduced a learning procedure de-
signed to overcome them and scale to large corpora.
We leave to future work to experiment with feature
sets designed for the large-scale discriminative set-
ting. In particular, we hope this framework will fa-
cilitate incorporation of richer linguistic knowledge
into machine translation.
</bodyText>
<sectionHeader confidence="0.998138" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998106">
This work was sponsored by the U. S. Army Research
Laboratory and the U. S. Army Research Office un-
der contract/grant number W911NF-10-1-0533. Jeffrey
Flanigan would like to thank his co-advisor Lori Levin
for support and encouragement during this work.
</bodyText>
<sectionHeader confidence="0.999221" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9923284">
Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
A discriminative latent variable model for statistical
machine translation. In Proc. ACL-HLT.
L´eon Bottou. 1998. Online algorithms and stochastic ap-
proximations. In David Saad, editor, Online Learning
</reference>
<page confidence="0.990122">
256
</page>
<reference confidence="0.999098205607476">
and Neural Networks. Cambridge University Press,
Cambridge, UK. revised, oct 2012.
L´eon Bottou. 2010. Large-scale machine learning with
stochastic gradient descent. In Yves Lechevallier and
Gilbert Saporta, editors, Proceedings of the 19th In-
ternational Conference on Computational Statistics
(COMPSTAT’2010), pages 177–187, Paris, France,
August. Springer.
V. Chahuneau, N. A. Smith, and C. Dyer. 2012. pycdec:
A python interface to cdec. The Prague Bulletin of
Mathematical Linguistics, 98:51–61.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Proc.
of NAACL.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, EMNLP ’08, pages 224–233, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In In ACL, pages
263–270.
David Chiang. 2012. Hope and fear for discriminative
training of statistical translation models. Journal of
Machine Learning Research, pages 1159–1187.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A.
Smith. 2011. Better hypothesis testing for statisti-
cal machine translation: controlling for optimizer in-
stability. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Hu-
man Language Technologies: short papers - Volume
2, HLT ’11, pages 176–181, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Michael Denkowski and Alon Lavie. 2011. Meteor 1.3:
Automatic Metric for Reliable Optimization and Eval-
uation of Machine Translation Systems. In Proceed-
ings of the EMNLP 2011 Workshop on Statistical Ma-
chine Translation.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan,
Vladimir Eidelman, and Philip Resnik. 2010. cdec: A
decoder, alignment, and learning framework for finite-
state and context-free translation models. In Proceed-
ings of ACL.
Kevin Gimpel and Noah A. Smith. 2012. Structured
ramp loss minimization for machine translation. In
Proc. of NAACL.
K. Gimpel. 2012. Discriminative Feature-Rich Modeling
for Syntax-Based Machine Translation. Ph.D. thesis,
Carnegie Mellon University.
Kenneth Heafield. 2011. KenLM: Faster and smaller
language model queries. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, Edin-
burgh, UK, July. Association for Computational Lin-
guistics.
Mark Hopkins and Jonathan May. 2011. Tuning as rank-
ing. In Proc. of EMNLP.
Percy Liang, Alexandre Bouchard-cˆot´e, Dan Klein, and
Ben Taskar. 2006. An end-to-end discriminative ap-
proach to machine translation. In In Proceedings of
the Joint International Conference on Computational
Linguistics and Association of Computational Linguis-
tics (COLING/ACL, pages 761–768.
Preslav Nakov, Francisco Guzm´an, and Stephan Vogel.
2012. Optimizing for sentence-level bleu+1 yields
short translations. In Martin Kay and Christian Boitet,
editors, COLING, pages 1979–1994. Indian Institute
of Technology Bombay.
Jorge Nocedal and Stephen J. Wright. 2000. Numerical
Optimization. Springer.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for statis-
tical machine translation. In Proc. of ACL.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Comput. Linguist., 29(1):19–51, March.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proc. ofACL.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th Annual Meeting on Association for Computa-
tional Linguistics, ACL ’02, pages 311–318, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Antti-Veiko Rosti, Bing Zhang, Spyros Matsoukas, and
Richard Schwartz. 2010. BBN system description for
WMT10 system combination task. In Proc. WMT.
Avneesh Saluja, Ian Lane, and Joy Zhang. 2012. Ma-
chine Translation with Binary Feedback: a large-
margin approach. In Proceedings of The Tenth Bien-
nial Conference of the Association for Machine Trans-
lation in the Americas, San Diego, CA, July.
Patrick Simianer, Chris Dyer, and Stefan Riezler. 2012.
Joint feature selection in distributed stochastic learn-
ing for large-scale discriminative training in SMT. In
Proc. ACL.
David A. Smith and Jason Eisner. 2006. Minimum risk
annealing for training log-linear models. In Proc. of
ACL.
Andreas Stolcke. 2002. Srilm - an extensible language
modeling toolkit. pages 901–904.
Christoph Tillmann and Tong Zhang. 2006. A discrim-
inative global training algorithm for statistical mt. In
Proceedings of the 21st International Conference on
</reference>
<page confidence="0.960324">
257
</page>
<reference confidence="0.9990283">
Computational Linguistics and the 44th annual meet-
ing of the Association for Computational Linguistics,
ACL-44, pages 721–728, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. In Proceedings of the twenty-first inter-
national conference on Machine learning, ICML ’04,
pages 104–, New York, NY, USA. ACM.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki
Isozaki. 2007. Online large-margin training for statis-
tical machine translation. In Proc. EMNLP-CoNLL.
Jonathan Weese, Juri Ganitkevitch, Chris Callison-
Burch, Matt Post, and Adam Lopez. 2011. Joshua
3.0: syntax-based machine translation with the thrax
grammar extractor. In Proceedings of the Sixth Work-
shop on Statistical Machine Translation, WMT ’11,
pages 478–484, Stroudsburg, PA, USA. Association
for Computational Linguistics.
</reference>
<page confidence="0.996136">
258
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.547855">
<title confidence="0.973366">Large-Scale Discriminative Training for Statistical Machine Using Held-Out Line Search</title>
<author confidence="0.998999">Jeffrey Flanigan Chris Dyer Jaime</author>
<affiliation confidence="0.82423">Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.99292">Pittsburgh, PA 15213,</address>
<abstract confidence="0.995489416666667">We introduce a new large-scale discriminative learning algorithm for machine translation that is capable of learning parameters in models with extremely sparse features. To ensure their reliable estimation and to prevent overfitting, we use a two-phase learning algorithm. First, the contribution of individual sparse features is estimated using large amounts of parallel data. Second, a small development corpus is used to determine the relative contributions of the sparse features and standard dense features. Not only does this two-phase learning approach prevent overfitting, the second pass optimizes corpus-level BLEU of the Viterbi translation of the decoder. We demonstrate significant improvements using sparse rule indicator features in three different translation tasks. To our knowledge, this is the first large-scale discriminative training algorithm capable of showing improvements over with only rule indicator in addition to the standard features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
<author>Miles Osborne</author>
</authors>
<title>A discriminative latent variable model for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proc. ACL-HLT.</booktitle>
<contexts>
<context position="5796" citStr="Blunsom et al., 2008" startWordPosition="890" endWordPosition="893"> a specific rule is used in a translation. Early experiments (Liang et al., 2006) used the structured perceptron to tune a phrase-based system on a large subset of the training data, showing improvements when using rule indicator features, word alignment features, and POS tag features. Another early attempt (Tillmann and Zhang, 2006) used phrase pair and word features in a block SMT system trained using stochastic gradient descent for a convex loss function, but did not compare to MERT. Problems of overfitting and degenerate derivations were tackled with a probabilistic latent variable model (Blunsom et al., 2008) which used rule indicator features yet failed to improve upon the MERT baseline for the standard Hiero features. Techniques for distributed learning and feature selection for the perceptron loss using rule indicator, rule shape, and source side-bigram features have recently been proposed (Simianer et al., 2012), but no comparison to MERT was made. 3 Difficulties in Large-Scale Training Discriminative training for machine translation is complicated by several factors. First, both translation rules and feature weights are learned from parallel data. If the same data is used for both tasks, over</context>
<context position="8064" citStr="Blunsom et al., 2008" startWordPosition="1252" endWordPosition="1255">learn the weights for a Chinese-English Hiero system (Chiang, 2005) with just eight features, using stochastic gradient descent (SGD) for online learning (Bottou, 1998; Bottou, 2010). The weights were initialized from MERT values tuned on a 2k-sentence dev set (MT06), and the figure shows the progress of the online method during a single pass through the 300ksentence Chinese-English FBIS training set. As the training progresses in Figure 1, BLEU scores on the training data go up, but scores on the 1Previous work has attempted to mitigate the risk of overfitting through careful regularization (Blunsom et al., 2008; Simianer et al., 2012). 249 Figure 1: Progress of the online SVM training method after each training instance on FBIS dataset. The solid line is BLEU on the test set, training set is the dashed line, and the dev set is dotted. dev and test sets go down. If we hope to apply discriminative training techniques for not eight but millions of features on the training data, we must find a way to prevent this overfitting. We suggest that an important reason why overfitting occurs is that the training data is used not only to tune the system but also to extract the grammar, and the target side is inc</context>
</contexts>
<marker>Blunsom, Cohn, Osborne, 2008</marker>
<rawString>Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008. A discriminative latent variable model for statistical machine translation. In Proc. ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L´eon Bottou</author>
</authors>
<title>Online algorithms and stochastic approximations.</title>
<date>1998</date>
<booktitle>Online Learning and Neural Networks.</booktitle>
<editor>In David Saad, editor,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK. revised,</location>
<contexts>
<context position="7611" citStr="Bottou, 1998" startWordPosition="1178" endWordPosition="1179">res leads to problems of scaling in the optimization problem as we will show. 3.1 Training Data and Overfitting One of the big questions in discriminative training of machine translation systems is why standard machine learning techniques can perform so poorly when applied to large-scale learning on the training data. Figure 1 shows a good example of this. The structured SVM (Tsochantaridis et al., 2004; Cherry and Foster, 2012) was used to learn the weights for a Chinese-English Hiero system (Chiang, 2005) with just eight features, using stochastic gradient descent (SGD) for online learning (Bottou, 1998; Bottou, 2010). The weights were initialized from MERT values tuned on a 2k-sentence dev set (MT06), and the figure shows the progress of the online method during a single pass through the 300ksentence Chinese-English FBIS training set. As the training progresses in Figure 1, BLEU scores on the training data go up, but scores on the 1Previous work has attempted to mitigate the risk of overfitting through careful regularization (Blunsom et al., 2008; Simianer et al., 2012). 249 Figure 1: Progress of the online SVM training method after each training instance on FBIS dataset. The solid line is </context>
</contexts>
<marker>Bottou, 1998</marker>
<rawString>L´eon Bottou. 1998. Online algorithms and stochastic approximations. In David Saad, editor, Online Learning and Neural Networks. Cambridge University Press, Cambridge, UK. revised, oct 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L´eon Bottou</author>
</authors>
<title>Large-scale machine learning with stochastic gradient descent.</title>
<date>2010</date>
<booktitle>In Yves Lechevallier and Gilbert Saporta, editors, Proceedings of the 19th International Conference on Computational Statistics (COMPSTAT’2010),</booktitle>
<pages>177--187</pages>
<publisher>August. Springer.</publisher>
<location>Paris, France,</location>
<contexts>
<context position="7626" citStr="Bottou, 2010" startWordPosition="1180" endWordPosition="1181">roblems of scaling in the optimization problem as we will show. 3.1 Training Data and Overfitting One of the big questions in discriminative training of machine translation systems is why standard machine learning techniques can perform so poorly when applied to large-scale learning on the training data. Figure 1 shows a good example of this. The structured SVM (Tsochantaridis et al., 2004; Cherry and Foster, 2012) was used to learn the weights for a Chinese-English Hiero system (Chiang, 2005) with just eight features, using stochastic gradient descent (SGD) for online learning (Bottou, 1998; Bottou, 2010). The weights were initialized from MERT values tuned on a 2k-sentence dev set (MT06), and the figure shows the progress of the online method during a single pass through the 300ksentence Chinese-English FBIS training set. As the training progresses in Figure 1, BLEU scores on the training data go up, but scores on the 1Previous work has attempted to mitigate the risk of overfitting through careful regularization (Blunsom et al., 2008; Simianer et al., 2012). 249 Figure 1: Progress of the online SVM training method after each training instance on FBIS dataset. The solid line is BLEU on the tes</context>
</contexts>
<marker>Bottou, 2010</marker>
<rawString>L´eon Bottou. 2010. Large-scale machine learning with stochastic gradient descent. In Yves Lechevallier and Gilbert Saporta, editors, Proceedings of the 19th International Conference on Computational Statistics (COMPSTAT’2010), pages 177–187, Paris, France, August. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Chahuneau</author>
<author>N A Smith</author>
<author>C Dyer</author>
</authors>
<title>pycdec: A python interface to cdec.</title>
<date>2012</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>98--51</pages>
<contexts>
<context position="24671" citStr="Chahuneau et al., 2012" startWordPosition="4219" endWordPosition="4222"> 28.8M (Ar-En), and 10.8M (Zh-En). The same features are used for all tuning methods, except MERT baseline which uses only dense features. Although we extract different grammars from various subsets of the training corpus, word alignments were done using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � log i=1 yEGen(xi) I~w· ~f(xi,y)+cost(yi,y) where the sum over i ranges over training examples, Gen(x) is the space of possible outputs and derivations for the input x, and cost(yi, y) is add one smoothing sentence level BLEU.7 Except where noted, all experime</context>
</contexts>
<marker>Chahuneau, Smith, Dyer, 2012</marker>
<rawString>V. Chahuneau, N. A. Smith, and C. Dyer. 2012. pycdec: A python interface to cdec. The Prague Bulletin of Mathematical Linguistics, 98:51–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>George Foster</author>
</authors>
<title>Batch tuning strategies for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="4573" citStr="Cherry and Foster, 2012" startWordPosition="703" endWordPosition="706">2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translation model: every rule has a feature, each of which has its own separately tuned weight, which count how oft</context>
<context position="7431" citStr="Cherry and Foster, 2012" startWordPosition="1148" endWordPosition="1151">nslation decisions under a simpler generative translation model. Our goal is to begin to use much sparser features without abandoning the proven dense features; however, extremely sparse features leads to problems of scaling in the optimization problem as we will show. 3.1 Training Data and Overfitting One of the big questions in discriminative training of machine translation systems is why standard machine learning techniques can perform so poorly when applied to large-scale learning on the training data. Figure 1 shows a good example of this. The structured SVM (Tsochantaridis et al., 2004; Cherry and Foster, 2012) was used to learn the weights for a Chinese-English Hiero system (Chiang, 2005) with just eight features, using stochastic gradient descent (SGD) for online learning (Bottou, 1998; Bottou, 2010). The weights were initialized from MERT values tuned on a 2k-sentence dev set (MT06), and the figure shows the progress of the online method during a single pass through the 300ksentence Chinese-English FBIS training set. As the training progresses in Figure 1, BLEU scores on the training data go up, but scores on the 1Previous work has attempted to mitigate the risk of overfitting through careful reg</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>224--233</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="13509" citStr="Chiang et al., 2008" startWordPosition="2183" endWordPosition="2186">ation with rule features could be slow to converge due to poor scaling, and that rescaling will improve convergence. 3.3 Sentence Level Approximations to BLEU Finally, we note that discriminative training methods often use a sentence level approximation to BLEU. It has been shown that optimizing corpus level BLEU versus sentence level BLEU can lead to improvements of up to nearly .4 BLEU points on the test set (Nakov et al., 2012). Possible fixes to this problem include using a proper sentence level metric such a METEOR (Denkowski and Lavie, 2011) or a pseudo-corpus from the last few updates (Chiang et al., 2008). However, in light of the result from section 3.1 that tuning on the dev set is still better than tuning on a held-out portion of the training data, we observe that tuning a corpus level metric on a highquality dev set from the same domain as the test set probably leads to the best translation quality. Attempts to improve upon this strong baseline lead us to the development of the HOLS algorithm which we describe next. 4 Held-Out Line Search Algorithm In this section we give the details of the learning algorithm that we developed for use in large-scale discriminative training for machine tran</context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 224–233, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation. In</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="7511" citStr="Chiang, 2005" startWordPosition="1163" endWordPosition="1165">e much sparser features without abandoning the proven dense features; however, extremely sparse features leads to problems of scaling in the optimization problem as we will show. 3.1 Training Data and Overfitting One of the big questions in discriminative training of machine translation systems is why standard machine learning techniques can perform so poorly when applied to large-scale learning on the training data. Figure 1 shows a good example of this. The structured SVM (Tsochantaridis et al., 2004; Cherry and Foster, 2012) was used to learn the weights for a Chinese-English Hiero system (Chiang, 2005) with just eight features, using stochastic gradient descent (SGD) for online learning (Bottou, 1998; Bottou, 2010). The weights were initialized from MERT values tuned on a 2k-sentence dev set (MT06), and the figure shows the progress of the online method during a single pass through the 300ksentence Chinese-English FBIS training set. As the training progresses in Figure 1, BLEU scores on the training data go up, but scores on the 1Previous work has attempted to mitigate the risk of overfitting through careful regularization (Blunsom et al., 2008; Simianer et al., 2012). 249 Figure 1: Progres</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In In ACL, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hope and fear for discriminative training of statistical translation models.</title>
<date>2012</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>1159--1187</pages>
<contexts>
<context position="4524" citStr="Chiang, 2012" startWordPosition="697" endWordPosition="698">n three language pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translation model: every rule has a feature, each of which has its</context>
<context position="10968" citStr="Chiang, 2012" startWordPosition="1746" endWordPosition="1747">than changing the weights of less frequent features.2 An example of frequent features that have a large impact on the translation quality are the language model and translation model features. These features are non-zero for every sentence, and changing their weights slightly has a large impact on translation output. In contrast, changing the weight drastically for a feature that is non-zero for only one out of a million sentences has very little effect on translation metrics. The sensitivity of the translation output to some feature weights over others was also pointed out in a recent paper (Chiang, 2012). When the objective function is more sensitive in some dimensions than others, the optimization problem is said to be poorly scaled (Nocedal and Wright, 2000), and can slow down the convergence rate for some optimizers. A typical fix is to rescale the dimensions, as we will do in Section 5.2. To verify that BLEU is poorly scaled with respect to weights of rule indicator features, we look at the effect of changing the weights for individual rules. We vary the feature weights for four randomly chosen frequent rules and four randomly chosen infrequent rules on our FBIS dev set (Figure 2). One ca</context>
<context position="27860" citStr="Chiang, 2012" startWordPosition="4769" endWordPosition="4770">tion to work well, but other “soft” loss functions (Gimpel, 2012; Gimpel and Smith, 2012) also work. Gen(x) is restricted to a k-best size of 1000. Following (Gimpel, 2012) cost(yi, y) is multiplied by a factor of 20. e~w·~f(xi,y)−cost(yi,y) + log � e yEGen(xi) 254 Table 3: Comparison Experiments for Zh-En Algorithm Tune MT08 Runtime MERT 22.1±.1 23.1±.1 6 hours PRO 23.8±.05 23.6±.1 2 weeks MIRA 21.7±.1 22.5±.1 19 hours SOFTRAMP3 21.5±.3 22.3±.3 29 hours HOLS 22.3±.1 23.4±.1 10 hours HILS 24.3±.2 22.4±.1 10 hours specialized development set. We compare MERT, PRO (Hopkins and May, 2011), MIRA (Chiang, 2012), SOFTRAMP3, HOLS, and a variant of HOLS which we call HILS (discussed below). For HOLS, we used 10k of the 60k tuning set for the line search, and the rest of the tuning set was used for calculating the gradient. For HILS (“Held-In” Line Search), the full 60k tuning set was used to calculate the gradient, but the line search was on a 10k subset of that set. For MERT, we used a 10k subset of the tuning data because it takes a long time to run on large datasets, and it only has the eight dense features and so does not need the entire 60k tuning set. All the subsets are drawn randomly. Condition</context>
</contexts>
<marker>Chiang, 2012</marker>
<rawString>David Chiang. 2012. Hope and fear for discriminative training of statistical translation models. Journal of Machine Learning Research, pages 1159–1187.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>176--181</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="25503" citStr="Clark et al., 2011" startWordPosition="4367" endWordPosition="4370">el, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � log i=1 yEGen(xi) I~w· ~f(xi,y)+cost(yi,y) where the sum over i ranges over training examples, Gen(x) is the space of possible outputs and derivations for the input x, and cost(yi, y) is add one smoothing sentence level BLEU.7 Except where noted, all experiments are repeated 5 times and results are averaged, initial weights for the dense features are drawn from a standard normal, and initial weights for the sparse features are set to zero. We evaluate using MultEval (Clark et al., 2011) and report standard deviations across optimizer runs and significance at p = .05 using MultEval’s built-in permutation test. In the large-scale experiments for HOLS, we only run the full optimizer once, and report standard deviations using multiple runs of the last MERT run (i.e. the last line search on the dev data). 6.1 Comparison Experiments for ZH-EN Our first set of experiments compares the performance of the proposed HOLS algorithm to learning algorithms popularly used in machine translation on a Chinese-English task. We also compare to a close relative of the HOLS algorithm: optimizing</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better hypothesis testing for statistical machine translation: controlling for optimizer instability. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 176–181, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Alon Lavie</author>
</authors>
<title>Meteor 1.3: Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems.</title>
<date>2011</date>
<booktitle>In Proceedings of the EMNLP 2011 Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="13442" citStr="Denkowski and Lavie, 2011" startWordPosition="2171" endWordPosition="2174"> this as a sign that gradient descent based optimizers for machine translation with rule features could be slow to converge due to poor scaling, and that rescaling will improve convergence. 3.3 Sentence Level Approximations to BLEU Finally, we note that discriminative training methods often use a sentence level approximation to BLEU. It has been shown that optimizing corpus level BLEU versus sentence level BLEU can lead to improvements of up to nearly .4 BLEU points on the test set (Nakov et al., 2012). Possible fixes to this problem include using a proper sentence level metric such a METEOR (Denkowski and Lavie, 2011) or a pseudo-corpus from the last few updates (Chiang et al., 2008). However, in light of the result from section 3.1 that tuning on the dev set is still better than tuning on a held-out portion of the training data, we observe that tuning a corpus level metric on a highquality dev set from the same domain as the test set probably leads to the best translation quality. Attempts to improve upon this strong baseline lead us to the development of the HOLS algorithm which we describe next. 4 Held-Out Line Search Algorithm In this section we give the details of the learning algorithm that we develo</context>
</contexts>
<marker>Denkowski, Lavie, 2011</marker>
<rawString>Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic Metric for Reliable Optimization and Evaluation of Machine Translation Systems. In Proceedings of the EMNLP 2011 Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Adam Lopez</author>
<author>Juri Ganitkevitch</author>
<author>Johnathan Weese</author>
<author>Ferhan Ture</author>
<author>Phil Blunsom</author>
<author>Hendra Setiawan</author>
<author>Vladimir Eidelman</author>
<author>Philip Resnik</author>
</authors>
<title>cdec: A decoder, alignment, and learning framework for finitestate and context-free translation models.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="24477" citStr="Dyer et al., 2010" startWordPosition="4186" endWordPosition="4189">797 5K 223K MT08 1,357 4K 167K following 8 dense features: LM, phrasal and lexical p(e|f) and p(f|e), phrase and word penalties, and glue rule. The total number of features is 2.2M (Mg-En), 28.8M (Ar-En), and 10.8M (Zh-En). The same features are used for all tuning methods, except MERT baseline which uses only dense features. Although we extract different grammars from various subsets of the training corpus, word alignments were done using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � log i=1 yEGen(xi) I~w· ~f(xi,y)+cost(yi,y) where the sum over i r</context>
</contexts>
<marker>Dyer, Lopez, Ganitkevitch, Weese, Ture, Blunsom, Setiawan, Eidelman, Resnik, 2010</marker>
<rawString>Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finitestate and context-free translation models. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah A Smith</author>
</authors>
<title>Structured ramp loss minimization for machine translation.</title>
<date>2012</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="4548" citStr="Gimpel and Smith, 2012" startWordPosition="699" endWordPosition="702">ge pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translation model: every rule has a feature, each of which has its own separately tuned we</context>
<context position="24917" citStr="Gimpel and Smith, 2012" startWordPosition="4266" endWordPosition="4269">ne using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � log i=1 yEGen(xi) I~w· ~f(xi,y)+cost(yi,y) where the sum over i ranges over training examples, Gen(x) is the space of possible outputs and derivations for the input x, and cost(yi, y) is add one smoothing sentence level BLEU.7 Except where noted, all experiments are repeated 5 times and results are averaged, initial weights for the dense features are drawn from a standard normal, and initial weights for the sparse features are set to zero. We evaluate using MultEval (Clark et al., 2011) and report st</context>
<context position="27336" citStr="Gimpel and Smith, 2012" startWordPosition="4683" endWordPosition="4686">used to learn the weights as the tuning set (Tune). The grammar and LM are built using the training data that is not in the tuning set (the LM also includes the English monolingual corpus), and the weights for the features are tuned using the tuning set. This is similar to the typical train-dev-test split commonly used to tune machine translation systems, except that the tuning set is much larger (60k sentence pairs versus the usual 1k-2k) and comes from a random subset of the training data rather than a 7We found this loss function to work well, but other “soft” loss functions (Gimpel, 2012; Gimpel and Smith, 2012) also work. Gen(x) is restricted to a k-best size of 1000. Following (Gimpel, 2012) cost(yi, y) is multiplied by a factor of 20. e~w·~f(xi,y)−cost(yi,y) + log � e yEGen(xi) 254 Table 3: Comparison Experiments for Zh-En Algorithm Tune MT08 Runtime MERT 22.1±.1 23.1±.1 6 hours PRO 23.8±.05 23.6±.1 2 weeks MIRA 21.7±.1 22.5±.1 19 hours SOFTRAMP3 21.5±.3 22.3±.3 29 hours HOLS 22.3±.1 23.4±.1 10 hours HILS 24.3±.2 22.4±.1 10 hours specialized development set. We compare MERT, PRO (Hopkins and May, 2011), MIRA (Chiang, 2012), SOFTRAMP3, HOLS, and a variant of HOLS which we call HILS (discussed below</context>
</contexts>
<marker>Gimpel, Smith, 2012</marker>
<rawString>Kevin Gimpel and Noah A. Smith. 2012. Structured ramp loss minimization for machine translation. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Gimpel</author>
</authors>
<title>Discriminative Feature-Rich Modeling for Syntax-Based Machine Translation.</title>
<date>2012</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="24892" citStr="Gimpel, 2012" startWordPosition="4264" endWordPosition="4265">nments were done using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � log i=1 yEGen(xi) I~w· ~f(xi,y)+cost(yi,y) where the sum over i ranges over training examples, Gen(x) is the space of possible outputs and derivations for the input x, and cost(yi, y) is add one smoothing sentence level BLEU.7 Except where noted, all experiments are repeated 5 times and results are averaged, initial weights for the dense features are drawn from a standard normal, and initial weights for the sparse features are set to zero. We evaluate using MultEval (Clark et</context>
<context position="27311" citStr="Gimpel, 2012" startWordPosition="4681" endWordPosition="4682">training data used to learn the weights as the tuning set (Tune). The grammar and LM are built using the training data that is not in the tuning set (the LM also includes the English monolingual corpus), and the weights for the features are tuned using the tuning set. This is similar to the typical train-dev-test split commonly used to tune machine translation systems, except that the tuning set is much larger (60k sentence pairs versus the usual 1k-2k) and comes from a random subset of the training data rather than a 7We found this loss function to work well, but other “soft” loss functions (Gimpel, 2012; Gimpel and Smith, 2012) also work. Gen(x) is restricted to a k-best size of 1000. Following (Gimpel, 2012) cost(yi, y) is multiplied by a factor of 20. e~w·~f(xi,y)−cost(yi,y) + log � e yEGen(xi) 254 Table 3: Comparison Experiments for Zh-En Algorithm Tune MT08 Runtime MERT 22.1±.1 23.1±.1 6 hours PRO 23.8±.05 23.6±.1 2 weeks MIRA 21.7±.1 22.5±.1 19 hours SOFTRAMP3 21.5±.3 22.3±.3 29 hours HOLS 22.3±.1 23.4±.1 10 hours HILS 24.3±.2 22.4±.1 10 hours specialized development set. We compare MERT, PRO (Hopkins and May, 2011), MIRA (Chiang, 2012), SOFTRAMP3, HOLS, and a variant of HOLS which we c</context>
</contexts>
<marker>Gimpel, 2012</marker>
<rawString>K. Gimpel. 2012. Discriminative Feature-Rich Modeling for Syntax-Based Machine Translation. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and smaller language model queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, UK,</location>
<contexts>
<context position="24511" citStr="Heafield, 2011" startWordPosition="4193" endWordPosition="4194">ing 8 dense features: LM, phrasal and lexical p(e|f) and p(f|e), phrase and word penalties, and glue rule. The total number of features is 2.2M (Mg-En), 28.8M (Ar-En), and 10.8M (Zh-En). The same features are used for all tuning methods, except MERT baseline which uses only dense features. Although we extract different grammars from various subsets of the training corpus, word alignments were done using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � log i=1 yEGen(xi) I~w· ~f(xi,y)+cost(yi,y) where the sum over i ranges over training examples, Gen(</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, Edinburgh, UK, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hopkins</author>
<author>Jonathan May</author>
</authors>
<title>Tuning as ranking.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="4510" citStr="Hopkins and May, 2011" startWordPosition="693" endWordPosition="696"> issues, give results on three language pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translation model: every rule has a feature, each of</context>
<context position="27839" citStr="Hopkins and May, 2011" startWordPosition="4764" endWordPosition="4767">han a 7We found this loss function to work well, but other “soft” loss functions (Gimpel, 2012; Gimpel and Smith, 2012) also work. Gen(x) is restricted to a k-best size of 1000. Following (Gimpel, 2012) cost(yi, y) is multiplied by a factor of 20. e~w·~f(xi,y)−cost(yi,y) + log � e yEGen(xi) 254 Table 3: Comparison Experiments for Zh-En Algorithm Tune MT08 Runtime MERT 22.1±.1 23.1±.1 6 hours PRO 23.8±.05 23.6±.1 2 weeks MIRA 21.7±.1 22.5±.1 19 hours SOFTRAMP3 21.5±.3 22.3±.3 29 hours HOLS 22.3±.1 23.4±.1 10 hours HILS 24.3±.2 22.4±.1 10 hours specialized development set. We compare MERT, PRO (Hopkins and May, 2011), MIRA (Chiang, 2012), SOFTRAMP3, HOLS, and a variant of HOLS which we call HILS (discussed below). For HOLS, we used 10k of the 60k tuning set for the line search, and the rest of the tuning set was used for calculating the gradient. For HILS (“Held-In” Line Search), the full 60k tuning set was used to calculate the gradient, but the line search was on a 10k subset of that set. For MERT, we used a 10k subset of the tuning data because it takes a long time to run on large datasets, and it only has the eight dense features and so does not need the entire 60k tuning set. All the subsets are draw</context>
</contexts>
<marker>Hopkins, May, 2011</marker>
<rawString>Mark Hopkins and Jonathan May. 2011. Tuning as ranking. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Bouchard-cˆot´e</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation. In</title>
<date>2006</date>
<booktitle>In Proceedings of the Joint International Conference on Computational Linguistics and Association of Computational Linguistics (COLING/ACL,</booktitle>
<pages>761--768</pages>
<marker>Liang, Bouchard-cˆot´e, Klein, Taskar, 2006</marker>
<rawString>Percy Liang, Alexandre Bouchard-cˆot´e, Dan Klein, and Ben Taskar. 2006. An end-to-end discriminative approach to machine translation. In In Proceedings of the Joint International Conference on Computational Linguistics and Association of Computational Linguistics (COLING/ACL, pages 761–768.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Francisco Guzm´an</author>
<author>Stephan Vogel</author>
</authors>
<title>Optimizing for sentence-level bleu+1 yields short translations.</title>
<date>2012</date>
<pages>1979--1994</pages>
<editor>In Martin Kay and Christian Boitet, editors, COLING,</editor>
<institution>Indian Institute of Technology Bombay.</institution>
<marker>Nakov, Guzm´an, Vogel, 2012</marker>
<rawString>Preslav Nakov, Francisco Guzm´an, and Stephan Vogel. 2012. Optimizing for sentence-level bleu+1 yields short translations. In Martin Kay and Christian Boitet, editors, COLING, pages 1979–1994. Indian Institute of Technology Bombay.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Nocedal</author>
<author>Stephen J Wright</author>
</authors>
<title>Numerical Optimization.</title>
<date>2000</date>
<publisher>Springer.</publisher>
<contexts>
<context position="11127" citStr="Nocedal and Wright, 2000" startWordPosition="1769" endWordPosition="1772">anguage model and translation model features. These features are non-zero for every sentence, and changing their weights slightly has a large impact on translation output. In contrast, changing the weight drastically for a feature that is non-zero for only one out of a million sentences has very little effect on translation metrics. The sensitivity of the translation output to some feature weights over others was also pointed out in a recent paper (Chiang, 2012). When the objective function is more sensitive in some dimensions than others, the optimization problem is said to be poorly scaled (Nocedal and Wright, 2000), and can slow down the convergence rate for some optimizers. A typical fix is to rescale the dimensions, as we will do in Section 5.2. To verify that BLEU is poorly scaled with respect to weights of rule indicator features, we look at the effect of changing the weights for individual rules. We vary the feature weights for four randomly chosen frequent rules and four randomly chosen infrequent rules on our FBIS dev set (Figure 2). One can think of this plot as a “cross-section” of the BLEU score in the direction of the feature weight. The dense features are set to MERT-tuned values which are n</context>
</contexts>
<marker>Nocedal, Wright, 2000</marker>
<rawString>Jorge Nocedal and Stephen J. Wright. 2000. Numerical Optimization. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="4220" citStr="Och and Ney, 2002" startWordPosition="651" endWordPosition="654">anta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics decoding is so expensive, it is not feasible to make many passes through large amounts of training data, so optimization must be efficient). We then present the details of our algorithm that addresses these issues, give results on three language pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="24384" citStr="Och and Ney, 2003" startWordPosition="4169" endWordPosition="4172">Test 1,133 29K 24K Zh-En Train (FBIS) 302K 1M 9.3M Dev (MT06) 1,664 4K 192K Test (MT02-03) 1,797 5K 223K MT08 1,357 4K 167K following 8 dense features: LM, phrasal and lexical p(e|f) and p(f|e), phrase and word penalties, and glue rule. The total number of features is 2.2M (Mg-En), 28.8M (Ar-En), and 10.8M (Zh-En). The same features are used for all tuning methods, except MERT baseline which uses only dense features. Although we extract different grammars from various subsets of the training corpus, word alignments were done using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOL</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ofACL.</booktitle>
<contexts>
<context position="1391" citStr="Och, 2003" startWordPosition="197" endWordPosition="198">. Not only does this two-phase learning approach prevent overfitting, the second pass optimizes corpus-level BLEU of the Viterbi translation of the decoder. We demonstrate significant improvements using sparse rule indicator features in three different translation tasks. To our knowledge, this is the first large-scale discriminative training algorithm capable of showing improvements over the MERT baseline with only rule indicator features in addition to the standard MERT features. 1 Introduction This paper is about large scale discriminative training of machine translation systems. Like MERT (Och, 2003), our procedure directly optimizes the cost of the Viterbi output on corpus-level metrics, but does so while scaling to millions of features. The training procedure, which we call the Held-Out Line Search algorithm (HOLS), is a two-phase iterative batch optimization procedure consisting of (1) a gradient calculation on a differentiable approximation to the loss on a large amount of parallel training data and (2) a line search (using the standard MERT algorithm) to search in a subspace defined by the gradient for the weights that minimize the true cost. While sparse features are successfully us</context>
<context position="4232" citStr="Och, 2003" startWordPosition="655" endWordPosition="656"> June 2013. c�2013 Association for Computational Linguistics decoding is so expensive, it is not feasible to make many passes through large amounts of training data, so optimization must be efficient). We then present the details of our algorithm that addresses these issues, give results on three language pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminat</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6505" citStr="Papineni et al., 2002" startWordPosition="1001" endWordPosition="1004">e standard Hiero features. Techniques for distributed learning and feature selection for the perceptron loss using rule indicator, rule shape, and source side-bigram features have recently been proposed (Simianer et al., 2012), but no comparison to MERT was made. 3 Difficulties in Large-Scale Training Discriminative training for machine translation is complicated by several factors. First, both translation rules and feature weights are learned from parallel data. If the same data is used for both tasks, overfitting of the weights is very possible.1 Second, the standard MT cost function, BLEU (Papineni et al., 2002), does not decompose additively over training instances (because of the “brevity penalty”) and so approximations are used—these often have problems with the length (Nakov et al., 2012). Finally, state-of-the-art MT systems make extensive good use of “dense” features, such as the log probability of translation decisions under a simpler generative translation model. Our goal is to begin to use much sparser features without abandoning the proven dense features; however, extremely sparse features leads to problems of scaling in the optimization problem as we will show. 3.1 Training Data and Overfi</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 311–318, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veiko Rosti</author>
<author>Bing Zhang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>BBN system description for WMT10 system combination task.</title>
<date>2010</date>
<booktitle>In Proc. WMT.</booktitle>
<contexts>
<context position="4487" citStr="Rosti et al., 2010" startWordPosition="689" endWordPosition="692">that addresses these issues, give results on three language pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translation model: every rule</context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2010</marker>
<rawString>Antti-Veiko Rosti, Bing Zhang, Spyros Matsoukas, and Richard Schwartz. 2010. BBN system description for WMT10 system combination task. In Proc. WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avneesh Saluja</author>
<author>Ian Lane</author>
<author>Joy Zhang</author>
</authors>
<title>Machine Translation with Binary Feedback: a largemargin approach.</title>
<date>2012</date>
<booktitle>In Proceedings of The Tenth Biennial Conference of the Association for Machine Translation in the Americas,</booktitle>
<location>San Diego, CA,</location>
<contexts>
<context position="4595" citStr="Saluja et al., 2012" startWordPosition="707" endWordPosition="710">tive training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translation model: every rule has a feature, each of which has its own separately tuned weight, which count how often a specific rule is </context>
</contexts>
<marker>Saluja, Lane, Zhang, 2012</marker>
<rawString>Avneesh Saluja, Ian Lane, and Joy Zhang. 2012. Machine Translation with Binary Feedback: a largemargin approach. In Proceedings of The Tenth Biennial Conference of the Association for Machine Translation in the Americas, San Diego, CA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Simianer</author>
<author>Chris Dyer</author>
<author>Stefan Riezler</author>
</authors>
<title>Joint feature selection in distributed stochastic learning for large-scale discriminative training in SMT.</title>
<date>2012</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="6109" citStr="Simianer et al., 2012" startWordPosition="938" endWordPosition="941">llmann and Zhang, 2006) used phrase pair and word features in a block SMT system trained using stochastic gradient descent for a convex loss function, but did not compare to MERT. Problems of overfitting and degenerate derivations were tackled with a probabilistic latent variable model (Blunsom et al., 2008) which used rule indicator features yet failed to improve upon the MERT baseline for the standard Hiero features. Techniques for distributed learning and feature selection for the perceptron loss using rule indicator, rule shape, and source side-bigram features have recently been proposed (Simianer et al., 2012), but no comparison to MERT was made. 3 Difficulties in Large-Scale Training Discriminative training for machine translation is complicated by several factors. First, both translation rules and feature weights are learned from parallel data. If the same data is used for both tasks, overfitting of the weights is very possible.1 Second, the standard MT cost function, BLEU (Papineni et al., 2002), does not decompose additively over training instances (because of the “brevity penalty”) and so approximations are used—these often have problems with the length (Nakov et al., 2012). Finally, state-of-</context>
<context position="8088" citStr="Simianer et al., 2012" startWordPosition="1256" endWordPosition="1260">a Chinese-English Hiero system (Chiang, 2005) with just eight features, using stochastic gradient descent (SGD) for online learning (Bottou, 1998; Bottou, 2010). The weights were initialized from MERT values tuned on a 2k-sentence dev set (MT06), and the figure shows the progress of the online method during a single pass through the 300ksentence Chinese-English FBIS training set. As the training progresses in Figure 1, BLEU scores on the training data go up, but scores on the 1Previous work has attempted to mitigate the risk of overfitting through careful regularization (Blunsom et al., 2008; Simianer et al., 2012). 249 Figure 1: Progress of the online SVM training method after each training instance on FBIS dataset. The solid line is BLEU on the test set, training set is the dashed line, and the dev set is dotted. dev and test sets go down. If we hope to apply discriminative training techniques for not eight but millions of features on the training data, we must find a way to prevent this overfitting. We suggest that an important reason why overfitting occurs is that the training data is used not only to tune the system but also to extract the grammar, and the target side is included in the data used t</context>
</contexts>
<marker>Simianer, Dyer, Riezler, 2012</marker>
<rawString>Patrick Simianer, Chris Dyer, and Stefan Riezler. 2012. Joint feature selection in distributed stochastic learning for large-scale discriminative training in SMT. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Minimum risk annealing for training log-linear models.</title>
<date>2006</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="4444" citStr="Smith and Eisner, 2006" startWordPosition="681" endWordPosition="684">. We then present the details of our algorithm that addresses these issues, give results on three language pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameteri</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>David A. Smith and Jason Eisner. 2006. Minimum risk annealing for training log-linear models. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm - an extensible language modeling toolkit.</title>
<date>2002</date>
<pages>901--904</pages>
<contexts>
<context position="24570" citStr="Stolcke, 2002" startWordPosition="4204" endWordPosition="4205">|e), phrase and word penalties, and glue rule. The total number of features is 2.2M (Mg-En), 28.8M (Ar-En), and 10.8M (Zh-En). The same features are used for all tuning methods, except MERT baseline which uses only dense features. Although we extract different grammars from various subsets of the training corpus, word alignments were done using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � log i=1 yEGen(xi) I~w· ~f(xi,y)+cost(yi,y) where the sum over i ranges over training examples, Gen(x) is the space of possible outputs and derivations for the</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm - an extensible language modeling toolkit. pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
<author>Tong Zhang</author>
</authors>
<title>A discriminative global training algorithm for statistical mt.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44,</booktitle>
<pages>721--728</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5510" citStr="Tillmann and Zhang, 2006" startWordPosition="844" endWordPosition="847">criminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translation model: every rule has a feature, each of which has its own separately tuned weight, which count how often a specific rule is used in a translation. Early experiments (Liang et al., 2006) used the structured perceptron to tune a phrase-based system on a large subset of the training data, showing improvements when using rule indicator features, word alignment features, and POS tag features. Another early attempt (Tillmann and Zhang, 2006) used phrase pair and word features in a block SMT system trained using stochastic gradient descent for a convex loss function, but did not compare to MERT. Problems of overfitting and degenerate derivations were tackled with a probabilistic latent variable model (Blunsom et al., 2008) which used rule indicator features yet failed to improve upon the MERT baseline for the standard Hiero features. Techniques for distributed learning and feature selection for the perceptron loss using rule indicator, rule shape, and source side-bigram features have recently been proposed (Simianer et al., 2012),</context>
</contexts>
<marker>Tillmann, Zhang, 2006</marker>
<rawString>Christoph Tillmann and Tong Zhang. 2006. A discriminative global training algorithm for statistical mt. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44, pages 721–728, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
<author>Thorsten Joachims</author>
<author>Yasemin Altun</author>
</authors>
<title>Support vector machine learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>In Proceedings of the twenty-first international conference on Machine learning, ICML ’04,</booktitle>
<pages>104</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7405" citStr="Tsochantaridis et al., 2004" startWordPosition="1144" endWordPosition="1147">as the log probability of translation decisions under a simpler generative translation model. Our goal is to begin to use much sparser features without abandoning the proven dense features; however, extremely sparse features leads to problems of scaling in the optimization problem as we will show. 3.1 Training Data and Overfitting One of the big questions in discriminative training of machine translation systems is why standard machine learning techniques can perform so poorly when applied to large-scale learning on the training data. Figure 1 shows a good example of this. The structured SVM (Tsochantaridis et al., 2004; Cherry and Foster, 2012) was used to learn the weights for a Chinese-English Hiero system (Chiang, 2005) with just eight features, using stochastic gradient descent (SGD) for online learning (Bottou, 1998; Bottou, 2010). The weights were initialized from MERT values tuned on a 2k-sentence dev set (MT06), and the figure shows the progress of the online method during a single pass through the 300ksentence Chinese-English FBIS training set. As the training progresses in Figure 1, BLEU scores on the training data go up, but scores on the 1Previous work has attempted to mitigate the risk of overf</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. 2004. Support vector machine learning for interdependent and structured output spaces. In Proceedings of the twenty-first international conference on Machine learning, ICML ’04, pages 104–, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>Online large-margin training for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. EMNLP-CoNLL.</booktitle>
<contexts>
<context position="4467" citStr="Watanabe et al., 2007" startWordPosition="685" endWordPosition="688">tails of our algorithm that addresses these issues, give results on three language pairs, and conclude. 2 Related Work Discriminative training of machine translation systems has been a widely studied problem for the last ten years. The pattern of using small, highquality development sets to tune a relatively small number of weights was established early (Och and Ney, 2002; Och, 2003). More recently, standard structured prediction algorithms that target linearly decomposable approximations of translation quality metrics have been thoroughly explored (Liang et al., 2006; Smith and Eisner, 2006; Watanabe et al., 2007; Rosti et al., 2010; Hopkins and May, 2011; Chiang, 2012; Gimpel and Smith, 2012; Cherry and Foster, 2012; Saluja et al., 2012). These have without exception used sentence-level approximations of BLEU to determine oracles and update weights using a variety of criteria and with a variety of different theoretical justifications. Despite advancements in discriminative training for machine translation, large-scale discriminative training with rule indicator features has remained notoriously difficult. Rule indicator features are an extremely sparse and expressive parameterization of the translati</context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2007</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2007. Online large-margin training for statistical machine translation. In Proc. EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Weese</author>
<author>Juri Ganitkevitch</author>
<author>Chris CallisonBurch</author>
<author>Matt Post</author>
<author>Adam Lopez</author>
</authors>
<title>Joshua 3.0: syntax-based machine translation with the thrax grammar extractor.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT ’11,</booktitle>
<pages>478--484</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="24412" citStr="Weese et al., 2011" startWordPosition="4174" endWordPosition="4177">ain (FBIS) 302K 1M 9.3M Dev (MT06) 1,664 4K 192K Test (MT02-03) 1,797 5K 223K MT08 1,357 4K 167K following 8 dense features: LM, phrasal and lexical p(e|f) and p(f|e), phrase and word penalties, and glue rule. The total number of features is 2.2M (Mg-En), 28.8M (Ar-En), and 10.8M (Zh-En). The same features are used for all tuning methods, except MERT baseline which uses only dense features. Although we extract different grammars from various subsets of the training corpus, word alignments were done using the entire training corpus. We use GIZA++ for word alignments (Och and Ney, 2003), Thrax (Weese et al., 2011) to extract the grammars, our decoder is cdec (Dyer et al., 2010) which uses KenLM (Heafield, 2011), and we used a 4-gram LM built using SRILM (Stolcke, 2002). Our optimizer uses code implemented in the pycdec python interface to cdec (Chahuneau et al., 2012). To speed up decoding, for each source RHS we filtered the grammars to the top 15 rules ranked by p(e |f). Statistics about the datasets we used are listed in Table 2. We use the “soft ramp 3” loss function (Gimpel, 2012; Gimpel and Smith, 2012) as the surrogate loss function for calculating the gradient in HOLS. It is defined as ��˜ = � </context>
</contexts>
<marker>Weese, Ganitkevitch, CallisonBurch, Post, Lopez, 2011</marker>
<rawString>Jonathan Weese, Juri Ganitkevitch, Chris CallisonBurch, Matt Post, and Adam Lopez. 2011. Joshua 3.0: syntax-based machine translation with the thrax grammar extractor. In Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT ’11, pages 478–484, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>