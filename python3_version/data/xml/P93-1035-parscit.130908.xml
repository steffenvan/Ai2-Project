<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9990725">
Automatic Grammar Induction and Parsing Free Text:
A Transformation-Based Approach
</title>
<author confidence="0.998051">
Eric Brill*
</author>
<affiliation confidence="0.999159">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<email confidence="0.996787">
brill@unagi.cis.upenn.edu
</email>
<sectionHeader confidence="0.997382" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999577857142857">
In this paper we describe a new technique for
parsing free text: a transformational grammar&apos;
is automatically learned that is capable of accu-
rately parsing text into binary-branching syntac-
tic trees with nonterminals unlabelled. The algo-
rithm works by beginning in a very naive state of
knowledge about phrase structure. By repeatedly
comparing the results of bracketing in the current
state to proper bracketing provided in the training
corpus, the system learns a set of simple structural
transformations that can be applied to reduce er-
ror. After describing the algorithm, we present
results and compare these results to other recent
results in automatic grammar induction.
</bodyText>
<sectionHeader confidence="0.998998" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999401722222222">
There has been a great deal of interest of late in
the automatic induction of natural language gram-
mar. Given the difficulty inherent in manually
building a robust parser, along with the availabil-
ity of large amounts of training material, auto-
matic grammar induction seems like a path worth
pursuing. A number of systems have been built
that can be trained automatically to bracket text
into syntactic constituents. In (MM90) mutual in-
formation statistics are extracted from a corpus of
text and this information is then used to parse
new text. (Sarn86) defines a function to score the
quality of parse trees, and then uses simulated an-
nealing to heuristically explore the entire space of
possible parses for a given sentence. In (BM92a),
distributional analysis techniques are applied to a
large corpus to learn a context-free grammar.
The most promising results to date have been
</bodyText>
<note confidence="0.77858">
The author would like to thank Mark Liberman,
Meiting Lu, David Magerman, Mitch Marcus, Rich
Pito, Giorgio Satta, Yves Schabes and Tom Veatch.
This work was supported by DARPA and AFOSR
</note>
<figureCaption confidence="0.2635155">
jointly under grant No. AFOSR-90-0066, and by ARO
grant No. DAAL 03-89-00031 PRI.
</figureCaption>
<bodyText confidence="0.97055925">
&apos;Not in the traditional sense of the term.
based on the inside-outside algorithm, which can
be used to train stochastic context-free grammars.
The inside-outside algorithm is an extension of
the finite-state based Hidden Markov Model (by
(Bak79)), which has been applied successfully in
many areas, including speech recognition and part
of speech tagging. A number of recent papers
have explored the potential of using the inside-
outside algorithm to automatically learn a gram-
mar (LY90, SJM90, PS92, BW92, CC92, SR093).
Below, we describe a new technique for gram-
mar induction. The algorithm works by beginning
in a very naive state of knowledge about phrase
structure. By repeatedly comparing the results of
parsing in the current state to the proper phrase
structure for each sentence in the training corpus,
the system learns a set of ordered transformations
which can be applied to reduce parsing error. We
believe this technique has advantages over other
methods of phrase structure induction. Some of
the advantages include: the system is very simple,
it requires only a very small set of transforma-
tions, a high degree of accuracy is achieved, and
only a very small training corpus is necessary. The
trained transformational parser is completely sym-
bolic and can bracket text in linear time with re-
spect to sentence length. In addition, since some
tokens in a sentence are not even considered in
parsing, the method could prove to be consid-
erably more robust than a CFG-based approach
when faced with noise or unfamiliar input. After
describing the algorithm, we present results and
compare these results to other recent results in
automatic phrase structure induction.
TRANSFORMATION-BASED
</bodyText>
<sectionHeader confidence="0.979859" genericHeader="method">
ERROR-DRIVEN LEARNING
</sectionHeader>
<bodyText confidence="0.999732166666667">
The phrase structure learning algorithm is a
transformation-based error-driven learner. This
learning paradigm, illustrated in figure 1, has
proven to be successful in a number of differ-
ent natural language applications, including part
of speech tagging (Bri92, BM92b), prepositional
</bodyText>
<page confidence="0.995592">
259
</page>
<figure confidence="0.997824">
UNANNOTATED
TEXT
INITIAL
STATE
ANNOTATED
TRUTH
TEXT
LEARNER RULES
</figure>
<figureCaption confidence="0.995082647058823">
Figure 1: Transformation-Based Error-Driven
Learning.
phrase attachment (BR93), and word classifica-
tion (Bri93). In its initial state, the learner is
capable of annotating text but is not very good
at doing so. The initial state is usually very easy
to create. In part of speech tagging, the initial
state annotator assigns every word its most likely
tag. In prepositional phrase attachment, the ini-
tial state annotator always attaches prepositional
phrases low. In word classification, all words are
initially classified as nouns. The naively annotated
text is compared to the true annotation as indi-
cated by a small manually annotated corpus, and
transformations are learned that can be applied to
the output of the initial state annotator to make
it better resemble the truth.
</figureCaption>
<sectionHeader confidence="0.942131" genericHeader="method">
LEARNING PHRASE
STRUCTURE
</sectionHeader>
<bodyText confidence="0.957364421052632">
The phrase structure learning algorithm is trained
on a small corpus of partially bracketed text which
is also annotated with part of speech informa-
tion. All of the experiments presented below
were done using the Penn Treebank annotated
corpus(MSM93). The learner begins in a naive
initial state, knowing very little about the phrase
structure of the target corpus. In particular, all
that is initially known is that English tends to
be right branching and that final punctuation
is final punctuation. Transformations are then
learned automatically which transform the out-
put of the naive parser into output which bet-
ter resembles the phrase structure found in the
training corpus. Once a set of transformations
has been learned, the system is capable of taking
sentences tagged with parts of speech and return-
ing a binary-branching structure with nontermi-
nals unlabelled.2
</bodyText>
<subsectionHeader confidence="0.822997">
The Initial State Of The Parser
</subsectionHeader>
<bodyText confidence="0.94747">
Initially, the parser operates by assigning a right-
linear structure to all sentences. The only excep-
tion is that final punctuation is attached high. So,
the sentence &amp;quot;The dog and old cat ate .&amp;quot; would be
incorrectly bracketed as:
</bodyText>
<equation confidence="0.494939">
( ( The ( dog ( and ( old ( cat ate ) ) ) ) )
</equation>
<bodyText confidence="0.993498857142857">
The parser in its initial state will obviously
not bracket sentences with great accuracy. In
some experiments below, we begin with an even
more naive initial state of knowledge: sentences
are parsed by assigning them a random binary-
branching structure with final punctuation always
attached high.
</bodyText>
<subsectionHeader confidence="0.955146">
Structural Transformations
</subsectionHeader>
<bodyText confidence="0.996459888888889">
The next stage involves learning a set of trans-
formations that can be applied to the output of
the naive parser to make these sentences better
conform to the proper structure specified in the
training corpus. The list of possible transforma-
tion types is prespecified. Transformations involve
making a simple change triggered by a simple en-
vironment. In the current implementation, there
are twelve allowable transformation types:
</bodyText>
<listItem confidence="0.99322525">
• (1-8) (Addldelete) a (le ftlrig ht) parenthesis to
the (le ftlright) of part of speech tag X.
• (9-12) (Addldelete) a (leftlright) parenthesis
between tags X and Y.
</listItem>
<bodyText confidence="0.99623575">
To carry out a transformation by adding or
deleting a parenthesis, a number of additional sim-
ple changes must take place to preserve balanced
parentheses and binary branching. To give an ex-
ample, to delete a left paren in a particular envi-
ronment, the following operations take place (as-
suming, of course, that there is a left paren to
delete):
</bodyText>
<listItem confidence="0.9632036">
1. Delete the left paren.
2. Delete the right paren that matches the just
deleted paren.
3. Add a left paren to the left of the constituent
immediately to the left of the deleted left paren.
</listItem>
<footnote confidence="0.965878">
2This is the same output given by systems de-
scribed in (MM90, Bri92, PS92, SR093).
</footnote>
<page confidence="0.988363">
260
</page>
<bodyText confidence="0.7954823">
4. Add a right paren to the right of the con-
stituent immediately to the right of the deleted
left paren.
5. If there is no constituent immediately to the
right, or none immediately to the left, then the
transformation fails to apply.
Structurally, the transformation can be seen
as follows. If we wish to delete a left paren to
the right of constituent X&apos;, where X appears in a
subtree of the form:
</bodyText>
<equation confidence="0.9007415">
X
YY Z
carrying out these operations will transform this
subtree into:4
. z
X YY
</equation>
<bodyText confidence="0.873066363636363">
Given the sentence:5
The dog barked .
this would initially be bracketed by the naive
parser as:
( ( The ( dog barked) ) . )
If the transformation delete a left paren to
the right of a determiner is applied, the structure
would be transformed to the correct bracketing:
( ( ( The dog) barked) )
To add a right parenthesis to the right of YY,
YY must once again be in a subtree of the form:
YY Z
3To the right of the rightmost terminal dominated
by X if X is a nonterminal.
4The twelve transformations can be decomposed
into two structural transformations, that shown
here and its converse, along with six triggering
environments.
&apos;Input sentences are also labelled with parts of
speech.
If it is, the following steps are carried out to
add the right paren:
</bodyText>
<listItem confidence="0.999585833333333">
1. Add the right paren.
2. Delete the left paren that now matches the
newly added paren.
3. Find the right paren that used to match the just
deleted paren and delete it.
4. Add a left paren to match the added right paren.
</listItem>
<bodyText confidence="0.946601375">
This results in the same structural change as
deleting a left paren to the right of X in this par-
ticular structure.
Applying the transformation add a right paren
to the right of a noun to the bracketing:
( ( The ( dog barked ) ) . )
will once again result in the correct bracketing:
( ( ( The dog) barked) . )
</bodyText>
<subsectionHeader confidence="0.624944">
Learning Transformations
</subsectionHeader>
<bodyText confidence="0.999929809523809">
Learning proceeds as follows. Sentences in the
training set are first parsed using the naive parser
which assigns right linear structure to all sen-
tences, attaching final punctuation high. Next, for
each possible instantiation of the twelve transfor-
mation templates, that particular transformation
is applied to the naively parsed sentences. The re-
sulting structures are then scored using some mea-
sure of success that compares these parses to the
correct structural descriptions for the sentences
provided in the training corpus. The transforma-
tion resulting in the best scoring structures then
becomes the first transformation of the ordered set
of transformations that are to be learned. That
transformation is applied to the right-linear struc-
tures, and then learning proceeds on the corpus
of improved sentence bracketings. The following
procedure is carried out repeatedly on the train-
ing corpus until no more transformations can be
found whose application reduces the error in pars-
ing the training corpus:
</bodyText>
<listItem confidence="0.999323">
1. The best transformation is found for the struc-
tures output by the parser in its current state.6
2. The transformation is applied to the output re-
sulting from bracketing the corpus using the
parser in its current state.
3. This transformation is added to the end of the
ordered list of transformations.
</listItem>
<footnote confidence="0.969946666666667">
6The state of the parser is defined as naive initial-
state knowledge plus all transformations that cur-
rently have been learned.
</footnote>
<page confidence="0.980082">
261
</page>
<bodyText confidence="0.967482421052631">
4. Go to 1. ( ( ( The cat) meowed ) . )
After a set of transformations has been
learned, it can be used to effectively parse fresh
text. To parse fresh text, the text is first naively
parsed and then every transformation is applied,
in order, to the naively parsed text.
One nice feature of this method is that dif-
ferent measures of bracketing success can be used:
learning can proceed in such a way as to try to
optimize any specified measure of success. The
measure we have chosen for our experiments is the
same measure described in (PS92), which is one of
the measures that arose out of a parser evaluation
workshop (ea91). The measure is the percentage
of constituents (strings of words between matching
parentheses) from sentences output by our system
which do not cross any constituents in the Penn
Treebank structural description of the sentence.
For example, if our system outputs:
</bodyText>
<equation confidence="0.383916">
( ( ( The big ) ( dog ate ) ) . )
</equation>
<bodyText confidence="0.872387666666667">
and the Penn Treebank bracketing for this sen-
tence was:
( ( ( The big dog ) ate ) . )
then the constituent the big would be judged cor-
rect whereas the constituent dog ate would not.
Below are the first seven transformations
found from one run of training on the Wall Street
Journal corpus, which was initially bracketed us-
ing the right-linear initial-state parser.
</bodyText>
<listItem confidence="0.999604571428572">
1. Delete a left paren to the left of a singular noun.
2. Delete a left paren to the left of a plural noun.
3. Delete a left paren between two proper nouns.
4. Delet a left paren to the right of a determiner.
5. Add a right paren to the left of a comma.
6. Add a right paren to the left of a period.
7. Delete a right paren to the left of a plural noun.
</listItem>
<bodyText confidence="0.954769428571429">
The first four transformations all extract noun
phrases from the right linear initial structure. The
sentence &amp;quot;The cat meowed .&amp;quot; would initially be
bracketed as:7
( ( The ( cat meowed ) ) . )
Applying the first transformation to this
bracketing would result in:
</bodyText>
<footnote confidence="0.3702805">
&apos;These examples are not actual sentences in the
corpus. We have chosen simple sentences for clarity.
</footnote>
<table confidence="0.6013516">
Applying the fifth transformation to the
bracketing:
( ( We ( ran ( , ( and ( they walked ) ) ) ) ) )
would result in
( ( ( We ran) ( , ( and ( they walked ) ) ) ) . )
</table>
<sectionHeader confidence="0.96701" genericHeader="evaluation">
RESULTS
</sectionHeader>
<bodyText confidence="0.999909">
In the first experiment we ran, training and test-
ing were done on the Texas Instruments Air Travel
Information System (ATIS) corpus(HGD90).8 In
table 1, we compare results we obtained to re-
sults cited in (PS92) using the inside-outside al-
gorithm on the same corpus. Accuracy is mea-
sured in terms of the percentage of noncrossing
constituents in the test corpus, as described above.
Our system was tested by using the training set
to learn a set of transformations, and then ap-
plying these transformations to the test set and
scoring the resulting output. In this experiment,
64 transformations were learned (compared with
4096 context-free rules and probabilities used in
the inside-outside algorithm experiment). It is sig-
nificant that we obtained comparable performance
using a training corpus only 21% as large as that
used to train the inside-outside algorithm.
</bodyText>
<table confidence="0.9938008">
Method # of Training Accuracy
Corpus Sentences
Inside-Outside 700 90.36%
Transformation 150 91.12%
Learner
</table>
<tableCaption confidence="0.9605065">
Table 1: Comparing two learning methods on the
ATIS corpus.
</tableCaption>
<bodyText confidence="0.99961325">
After applying all learned transformations to
the test corpus, 60% of the sentences had no cross-
ing constituents, 74% had fewer than two crossing
constituents, and 85% had fewer than three. The
mean sentence length of the test corpus was 11.3.
In figure 2, we have graphed percentage correct
as a function of the number of transformations
that have been applied to the test corpus. As
the transformation number increases, overtraining
sometimes occurs. In the current implementation
of the learner, a transformation is added to the
list if it results in any positive net change in the
</bodyText>
<footnote confidence="0.85111475">
&apos;In all experiments described in this paper, results
are calculated on a test corpus which was not used in
any way in either training the learning algorithm or in
developing the system.
</footnote>
<page confidence="0.996036">
262
</page>
<bodyText confidence="0.999536833333333">
training set. Toward the end of the learning proce-
dure, transformations are found that only affect a
very small percentage of training sentences. Since
small counts are less reliable than large counts, we
cannot reliably assume that these transformations
will also improve performance in the test corpus.
One way around this overtraining would be to set
a threshold: specify a minimum level of improve-
ment that must result for a transformation to be
learned. Another possibility is to use additional
training material to prune the set of learned trans-
formations.
</bodyText>
<figure confidence="0.68334">
cs)
PercentageCorrect co
co
N.
0 10 20 30 40 50 60
</figure>
<bodyText confidence="0.990585111111111">
measured as the percentage of constituents in the
test set which do not cross any Penn Treebank
constituents .1°
As a point of comparison, in (SR093) an ex-
periment was done using the inside-outside algo-
rithm on a corpus of WSJ sentences of length 1-15.
Training was carried out on a corpus of 1,095 sen-
tences, and an accuracy of 90.2% was obtained in
bracketing a test set.
</bodyText>
<table confidence="0.9983095">
Sent. # Training # of %
Length Corpus Trans- Accuracy
Sents formations
2-15 250 83 88.1
2-15 500 163 89.3
2-15 1000 221 91.6
2-20 250 145 86.2
2-25 250 160 83.8
</table>
<tableCaption confidence="0.973439">
Table 2: WSJ Sentences
</tableCaption>
<bodyText confidence="0.9997708">
In the corpus we used for the experiments of
sentence length 2-15, the mean sentence length
was 10.80. In the corpus used for the experi-
ment of sentence length 2-25, the mean length
was 16.82. As would be expected, performance
degrades somewhat as sentence length increases.
In table 3, we show the percentage of sentences in
the test corpus that have no crossing constituents,
and the percentage that have only a very small
number of crossing constituents.&apos;
</bodyText>
<figure confidence="0.638608">
RuleNumber
</figure>
<figureCaption confidence="0.9624585">
Figure 2: Results From the ATIS Corpus, Starting
With Right-Linear Structure.
</figureCaption>
<bodyText confidence="0.999554125">
We next ran an experiment to determine what
performance could be achieved if we dropped the
initial right-linear assumption. Using the same
training and test sets as above, sentences were ini-
tially assigned a random binary-branching struc-
ture, with final punctuation always attached high.
Since there was less regular structure in this case
than in the right-linear case, many more transfor-
mations were found, 147 transformations in total.
When these transformations were applied to the
test set, a bracketing accuracy of 87.13% resulted.
The ATIS corpus is structurally fairly regular.
To determine how well our algorithm performs on
a more complex corpus, we ran experiments on
the Wall Street Journal. Results from this exper-
iment can be found in table 2.9 Accuracy is again
</bodyText>
<footnote confidence="0.6459965">
9 For sentences of length 2-15, the initial right-linear
parser achieves 69% accuracy. For sentences of length
</footnote>
<table confidence="0.999822857142857">
Sent # % of % of % of
Length Training 0-error &lt;1-error &lt;2-error
Corpus Sents Sents Sents
Sents
2-15 500 53.7 72.3 84.6
2-15 1000 62.4 77.2 87.8
2-25 250 29.2 44.9 59.9
</table>
<tableCaption confidence="0.998114">
Table 3: WSJ Sentences.
</tableCaption>
<bodyText confidence="0.976329933333333">
In table 4, we show the standard deviation
measured from three different randomly chosen
training sets of each sample size and randomly
chosen test sets of 500 sentences each, as well as
2-20, 63% accuracy is achieved and for sentences of
length 2-25, accuracy is 59%.
&amp;quot;In all of our experiments carried out on the Wall
Street Journal, the test set was a randomly selected
set of 500 sentences.
&amp;quot;For sentences of length 2-15, the initial right linear
parser parses 17% of sentences with no crossing errors,
35% with one or fewer errors and 50% with two or
fewer. For sentences of length 2-25, 7% of sentences
are parsed with no crossing errors, 16% with one or
fewer, and 24% with two or fewer.
</bodyText>
<page confidence="0.996276">
263
</page>
<bodyText confidence="0.8473405">
the accuracy as a function of training corpus size
for sentences of length 2 to 20.
</bodyText>
<table confidence="0.999872375">
# Training % Std.
Corpus Sents Correct Dev.
0 63.0 0.69
10 75.8 2.95
50 82.1 1.94
100 84.7 0.56
250 86.2 0.46
750 87.3 0.61
</table>
<tableCaption confidence="0.997142">
Table 4: WSJ Sentences of Length 2 to 20.
</tableCaption>
<bodyText confidence="0.9962142">
We also ran an experiment on WSJ sen-
tences of length 2-15 starting with random binary-
branching structures with final punctuation at-
tached high. In this experiment, 325 transfor-
mations were found using a 250-sentence training
corpus, and the accuracy resulting from applying
these transformations to a test set was 84.72%.
Finally, in figure 3 we show the sentence
length distribution in the Wall Street Journal cor-
pus.
</bodyText>
<figure confidence="0.9840585">
0 20 40 60 80 100
Sentence Length
</figure>
<figureCaption confidence="0.994089">
Figure 3: The Distribution of Sentence Lengths in
the WSJ Corpus.
</figureCaption>
<bodyText confidence="0.997240296296297">
While the numbers presented above allow
us to compare the transformation learner with
systems trained and tested on comparable cor-
pora, these results are all based upon the as-
sumption that the test data is tagged fairly re-
liably (manually tagged text was used in all of
these experiments, as well in the experiments of
(PS92, SR093).) When parsing free text, we can-
not assume that the text will be tagged with the
accuracy of a human annotator. Instead, an au-
tomatic tagger would have to be used to first tag
the text before parsing. To address this issue, we
ran one experiment where we randomly induced a
5% tagging error rate beyond the error rate of the
human annotator. Errors were induced in such a
way as to preserve the unigram part of speech tag
probability distribution in the corpus. The exper-
iment was run for sentences of length 2-15, with a
training set of 1000 sentences and a test set of 500
sentences. The resulting bracketing accuracy was
90.1%, compared to 91.6% accuracy when using
an unadulterated training corpus. Accuracy only
degraded by a small amount when training on the
corpus with adulterated part of speech tags, sug-
gesting that high parsing accuracy rates could be
achieved if tagging of the input were done auto-
matically by a part of speech tagger.
</bodyText>
<sectionHeader confidence="0.991951" genericHeader="conclusions">
CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.997580085714286">
In this paper, we have described a new approach
for learning a grammar to automatically parse
text. The method can be used to obtain high
parsing accuracy with a very small training set.
Instead of learning a traditional grammar, an or-
dered set of structural transformations is learned
that can be applied to the output of a very naive
parser to obtain binary-branching trees with un-
labelled nonterminals. Experiments have shown
that these parses conform with high accuracy to
the structural descriptions specified in a manually
annotated corpus. Unlike other recent attempts
at automatic grammar induction that rely heav-
ily on statistics both in training and in the re-
sulting grammar, our learner is only very weakly
statistical. For training, only integers are needed
and the only mathematical operations carried out
are integer addition and integer comparison. The
resulting grammar is completely symbolic. Un-
like learners based on the inside-outside algorithm
which attempt to find a grammar to maximize
the probability of the training corpus in hope that
this grammar will match the grammar that pro-
vides the most accurate structural descriptions,
the transformation-based learner can readily use
any desired success measure in learning.
We have already begun the next step in this
project: automatically labelling the nonterminal
nodes. The parser will first use the transforma-
tional grammar to output a parse tree without
nonterminal labels, and then a separate algorithm
will be applied to that tree to label the nontermi-
nals. The nonterminal-node labelling algorithm
makes use of ideas suggested in (Bri92), where
nonterminals are labelled as a function of the la-
</bodyText>
<figure confidence="0.994935333333333">
Relative Count
a
eN
</figure>
<page confidence="0.995721">
264
</page>
<bodyText confidence="0.999940944444444">
bels of their daughters. In addition, we plan to
experiment with other types of transformations.
Currently, each transformation in the learned list
is only applied once in each appropriate environ-
ment. For a transformation to be applied more
than once in one environment, it must appear in
the transformation list more than once. One pos-
sible extension to the set of transformation types
would be to allow for transformations of the form:
add/delete a paren as many times as is possible
in a particular environment. We also plan to ex-
periment with other scoring functions and control
strategies for finding transformations and to use
this system as a postprocessor to other grammar
induction systems, learning transformations to im-
prove their performance. We hope these future
paths will lead to a trainable and very accurate
parser for free text.
</bodyText>
<sectionHeader confidence="0.997689" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.978484988636364">
[Bak79] J. Baker. Trainable grammars for
speech recognition. In Speech commu-
nication papers presented at the 97th
Meeting of the Acoustical Society of
America, 1979.
[BM92a] E. Brill and M. Marcus. Automatically
acquiring phrase structure using distri-
butional analysis. In Darpa Workshop
on Speech and Natural Language, Har-
riman, N.Y., 1992.
[BM92b] E. Brill and M. Marcus. Tagging an un-
familiar text with minimal human su-
pervision. In Proceedings of the Fall
Symposium on Probabilistic Approaches
to Natural Language — AAAI Technical
-Report. American Association for Arti-
ficial Intelligence, 1992.
[BR93] E. Brill and P. Resnik. A transformation
based approach to prepositional phrase
attachment. Technical report, Depart-
ment of Computer and Information Sci-
ence, University of Pennsylvania, 1993.
[Bri92] E. Brill. A simple rule-based part
of speech tagger. In Proceedings of
the Third Conference on Applied Natu-
ral Language Processing, ACL, Trento,
Italy, 1992.
[Bri93] E. Brill. A Corpus-Based Approach to
Language Learning. PhD thesis, De-
partment of Computer and Informa-
tion Science, University of Pennsylva-
nia, 1993. Forthcoming.
[BW92] T. Briscoe and N. Waegner. Ro-
bust stochastic parsing using the inside-
outside algorithm. In Workshop notes
from the AAAI Statistically-Based NLP
Techniques Workshop, 1992.
[CC92] G. Carroll and E. Charniak. Learn-
ing probabilistic dependency grammars
from labelled text — aaai technical re-
port. In Proceedings of the Fall Sym-
posium on Probabilistic Approaches to
Natural Language. American Associa-
tion for Artificial Intelligence, 1992.
[ea91] E. Black et al. A procedure for quan-
titatively comparing the syntactic cov-
erage of English grammars. In Proceed-
ings of Fourth DARPA Speech and Nat-
ural Language Workshop, pages 306-
311, 1991.
[HGD90] C. Hemphill, J. Godfrey, and G. Dod-
dington. The ATIS spoken language
systems pilot corpus. In Proceedings of
the DARPA Speech and Natural Lan-
guage Workshop, 1990.
[LY90] K. Lan i and S. Young. The estimation of
stochastic context-free grammars using
the inside-outside algorithm. Computer
Speech and Language, 4, 1990.
[MM90] D. Magerman and M. Marcus. Parsing
a natural language using mutual infor-
mation statistics. In Proceedings, Eighth
National Conference on Artificial Intel-
ligence (AAAI 90), 1990.
[MSM93] M. Marcus, B. Santorini,
and M. Marcinkiewicz. Building a large
annotated corpus of English: the Penn
Treebank. To appear in Computational
Linguistics, 1993.
[PS92] F. Pereira and Y. Schabes. Inside-
outside reestimation from partially
bracketed corpora. In Proceedings of the
30th Annual Meeting of the Association
for Computational Linguistics, Newark,
De., 1992.
[Sam86] G. Sampson. A stochastic approach
to parsing. In Proceedings of COLING
1986, Bonn, 1986.
[SJM901 R. Sharman, F. Jelinek, and R. Mer-
cer. Generating a grammar for sta-
tistical training. In Proceedings of the
1990 Darpa Speech and Natural Lan-
guage Workshop, 1990.
[SR093] Y. Schabes, M. Roth, and R. Osborne.
Parsing the Wall Street Journal with
the inside-outside algorithm. In Pro-
ceedings of the 1993 European ACL,
Uterich, The Netherlands, 1993.
</reference>
<page confidence="0.998436">
265
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.987831">
<title confidence="0.999431">Automatic Grammar Induction and Parsing Free Text: A Transformation-Based Approach</title>
<author confidence="0.999674">Eric Brill</author>
<affiliation confidence="0.9998935">Department of Computer and Information Science University of Pennsylvania</affiliation>
<email confidence="0.999841">brill@unagi.cis.upenn.edu</email>
<abstract confidence="0.999307466666666">In this paper we describe a new technique for parsing free text: a transformational grammar&apos; is automatically learned that is capable of accurately parsing text into binary-branching syntactic trees with nonterminals unlabelled. The algorithm works by beginning in a very naive state of knowledge about phrase structure. By repeatedly comparing the results of bracketing in the current state to proper bracketing provided in the training corpus, the system learns a set of simple structural transformations that can be applied to reduce error. After describing the algorithm, we present results and compare these results to other recent results in automatic grammar induction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Baker</author>
</authors>
<title>Trainable grammars for speech recognition. In Speech communication papers presented at the 97th Meeting of the Acoustical Society of America,</title>
<date>1979</date>
<marker>[Bak79]</marker>
<rawString>J. Baker. Trainable grammars for speech recognition. In Speech communication papers presented at the 97th Meeting of the Acoustical Society of America, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>M Marcus</author>
</authors>
<title>Automatically acquiring phrase structure using distributional analysis.</title>
<date>1992</date>
<booktitle>In Darpa Workshop on Speech and Natural Language,</booktitle>
<location>Harriman, N.Y.,</location>
<marker>[BM92a]</marker>
<rawString>E. Brill and M. Marcus. Automatically acquiring phrase structure using distributional analysis. In Darpa Workshop on Speech and Natural Language, Harriman, N.Y., 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>M Marcus</author>
</authors>
<title>Tagging an unfamiliar text with minimal human supervision.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fall Symposium on Probabilistic Approaches to Natural Language — AAAI Technical -Report. American Association for Artificial Intelligence,</booktitle>
<marker>[BM92b]</marker>
<rawString>E. Brill and M. Marcus. Tagging an unfamiliar text with minimal human supervision. In Proceedings of the Fall Symposium on Probabilistic Approaches to Natural Language — AAAI Technical -Report. American Association for Artificial Intelligence, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>P Resnik</author>
</authors>
<title>A transformation based approach to prepositional phrase attachment.</title>
<date>1993</date>
<tech>Technical report,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<marker>[BR93]</marker>
<rawString>E. Brill and P. Resnik. A transformation based approach to prepositional phrase attachment. Technical report, Department of Computer and Information Science, University of Pennsylvania, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing, ACL,</booktitle>
<location>Trento, Italy,</location>
<marker>[Bri92]</marker>
<rawString>E. Brill. A simple rule-based part of speech tagger. In Proceedings of the Third Conference on Applied Natural Language Processing, ACL, Trento, Italy, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A Corpus-Based Approach to Language Learning.</title>
<date>1993</date>
<tech>PhD thesis,</tech>
<publisher>Forthcoming.</publisher>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<marker>[Bri93]</marker>
<rawString>E. Brill. A Corpus-Based Approach to Language Learning. PhD thesis, Department of Computer and Information Science, University of Pennsylvania, 1993. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Briscoe</author>
<author>N Waegner</author>
</authors>
<title>Robust stochastic parsing using the insideoutside algorithm.</title>
<date>1992</date>
<booktitle>In Workshop notes from the AAAI Statistically-Based NLP Techniques Workshop,</booktitle>
<marker>[BW92]</marker>
<rawString>T. Briscoe and N. Waegner. Robust stochastic parsing using the insideoutside algorithm. In Workshop notes from the AAAI Statistically-Based NLP Techniques Workshop, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carroll</author>
<author>E Charniak</author>
</authors>
<title>Learning probabilistic dependency grammars from labelled text — aaai technical report.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fall Symposium on Probabilistic Approaches to Natural Language. American Association for Artificial Intelligence,</booktitle>
<marker>[CC92]</marker>
<rawString>G. Carroll and E. Charniak. Learning probabilistic dependency grammars from labelled text — aaai technical report. In Proceedings of the Fall Symposium on Probabilistic Approaches to Natural Language. American Association for Artificial Intelligence, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Black</author>
</authors>
<title>A procedure for quantitatively comparing the syntactic coverage of English grammars.</title>
<date>1991</date>
<booktitle>In Proceedings of Fourth DARPA Speech and Natural Language Workshop,</booktitle>
<pages>306--311</pages>
<marker>[ea91]</marker>
<rawString>E. Black et al. A procedure for quantitatively comparing the syntactic coverage of English grammars. In Proceedings of Fourth DARPA Speech and Natural Language Workshop, pages 306-311, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hemphill</author>
<author>J Godfrey</author>
<author>G Doddington</author>
</authors>
<title>The ATIS spoken language systems pilot corpus.</title>
<date>1990</date>
<booktitle>In Proceedings of the DARPA Speech and Natural Language Workshop,</booktitle>
<marker>[HGD90]</marker>
<rawString>C. Hemphill, J. Godfrey, and G. Doddington. The ATIS spoken language systems pilot corpus. In Proceedings of the DARPA Speech and Natural Language Workshop, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lan i</author>
<author>S Young</author>
</authors>
<title>The estimation of stochastic context-free grammars using the inside-outside algorithm.</title>
<date>1990</date>
<journal>Computer Speech and Language,</journal>
<volume>4</volume>
<marker>[LY90]</marker>
<rawString>K. Lan i and S. Young. The estimation of stochastic context-free grammars using the inside-outside algorithm. Computer Speech and Language, 4, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Magerman</author>
<author>M Marcus</author>
</authors>
<title>Parsing a natural language using mutual information statistics.</title>
<date>1990</date>
<booktitle>In Proceedings, Eighth National Conference on Artificial Intelligence (AAAI 90),</booktitle>
<marker>[MM90]</marker>
<rawString>D. Magerman and M. Marcus. Parsing a natural language using mutual information statistics. In Proceedings, Eighth National Conference on Artificial Intelligence (AAAI 90), 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank.</title>
<date>1993</date>
<note>To appear in Computational Linguistics,</note>
<marker>[MSM93]</marker>
<rawString>M. Marcus, B. Santorini, and M. Marcinkiewicz. Building a large annotated corpus of English: the Penn Treebank. To appear in Computational Linguistics, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>Y Schabes</author>
</authors>
<title>Insideoutside reestimation from partially bracketed corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Newark, De.,</location>
<marker>[PS92]</marker>
<rawString>F. Pereira and Y. Schabes. Insideoutside reestimation from partially bracketed corpora. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, Newark, De., 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sampson</author>
</authors>
<title>A stochastic approach to parsing.</title>
<date>1986</date>
<booktitle>In Proceedings of COLING 1986,</booktitle>
<location>Bonn,</location>
<marker>[Sam86]</marker>
<rawString>G. Sampson. A stochastic approach to parsing. In Proceedings of COLING 1986, Bonn, 1986. [SJM901 R. Sharman, F. Jelinek, and R. Mercer. Generating a grammar for statistical training. In Proceedings of the 1990 Darpa Speech and Natural Language Workshop, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>M Roth</author>
<author>R Osborne</author>
</authors>
<title>Parsing the Wall Street Journal with the inside-outside algorithm.</title>
<date>1993</date>
<booktitle>In Proceedings of the 1993 European ACL, Uterich, The Netherlands,</booktitle>
<marker>[SR093]</marker>
<rawString>Y. Schabes, M. Roth, and R. Osborne. Parsing the Wall Street Journal with the inside-outside algorithm. In Proceedings of the 1993 European ACL, Uterich, The Netherlands, 1993.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>