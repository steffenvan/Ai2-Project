<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9987445">
Recognizing Names in Biomedical Texts
using Hidden Markov Model and SVM plus Sigmoid
</title>
<author confidence="0.990439">
ZHOU GuoDong
</author>
<affiliation confidence="0.986928">
Institute for Infocomm Research
</affiliation>
<address confidence="0.977681">
21 Heng Mui Keng Terrace
Singapore 119613
</address>
<email confidence="0.997192">
Email: zhougd@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.980461" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999049777777778">
In this paper, we present a named entity
recognition system in the biomedical domain,
called PowerBioNE. In order to deal with the
special phenomena in the biomedical domain,
various evidential features are proposed and
integrated through a Hidden Markov Model
(HMM). In addition, a Support Vector Machine
(SVM) plus sigmoid is proposed to resolve the
data sparseness problem in our system. Finally,
we present two post-processing modules to deal
with the cascaded entity name and abbreviation
phenomena. Evaluation shows that our system
achieves the F-measure of 69.1 and 71.2 on the 23
classes of GENIA V1.1 and V3.0 respectively. In
particular, our system achieves the F-measure of
77.8 on the “protein” class of GENIA V3.0. It
shows that our system outperforms the best
published system on GENIA V1.1 and V3.0.
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="keywords">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999503803278689">
With an overwhelming amount of textual
information in molecular biology and biomedicine,
there is a need for effective and efficient literature
mining and knowledge discovery that can help
biologists to gather and make use of the knowledge
encoded in text documents. In order to make
organized and structured information available,
automatically recognizing biomedical entity names
becomes critical and is important for protein-
protein interaction extraction, pathway
construction, automatic database curation, etc.
Such a task, called named entity recognition,
has been well developed in the Information
Extraction literature (MUC-6; MUC-7). In MUC,
the task of named entity recognition is to recognize
the names of persons, locations, organizations, etc.
in the newswire domain. In the biomedical domain,
we care about entities like gene, protein, virus, etc.
In recent years, many explorations have been done
to port existing named entity recognition systems
into the biomedical domain (Kazama et al 2002;
Lee et al 2003; Shen et al 2003; Zhou et al 2004).
However, few of them have achieved satisfactory
performance due to the special characteristics in
the biomedical domain, such as long and
descriptive naming conventions, conjunctive and
disjunctive structure, causal naming convention
and rapidly emerging new biomedical names,
abbreviation, and cascaded construction. On all
accounts, we can say that the entity names in the
biomedical domain are much more complex than
those in the newswire domain.
In this paper, we present a named entity
recognition system in the biomedical domain,
called PowerBioNE. In order to deal with the
special phenomena in the biomedical domain,
various evidential features are proposed and
integrated effectively and efficiently through a
Hidden Markov Model (HMM). In addition, a
Support Vector Machine (SVM) plus sigmoid is
proposed to resolve the data sparseness problem in
our system. Finally, we present two post-
processing modules to deal with the cascaded
entity name and abbreviation phenomena to further
improve the performance.
All of our experiments are done on the GENIA
corpus, which is the largest annotated corpus in the
molecular biology domain available to public
(Ohta et al. 2002). In our experiments, two
versions are used: 1) Genia V1.1 which contains
670 MEDLINE abstracts of 123K words; 2) Genia
V3.0 which is a superset of GENIA V1.1 and
contains 2000 MEDLINE abstracts of 360K words.
The annotation of biomedical entities is based on
the GENIA ontology (Ohta et al. 2002), which
includes 23 distinct classes: multi-cell, mono-cell,
virus, body part, tissue, cell type, cell component,
organism, cell line, other artificial source, protein,
peptide, amino acid monomer, DNA, RNA, poly
nucleotide, nucleotide, lipid, carbohydrate, other
organic compound, inorganic, atom and other.
</bodyText>
<sectionHeader confidence="0.99972" genericHeader="introduction">
2. FEATURES
</sectionHeader>
<bodyText confidence="0.998381666666667">
In order to deal with the special phenomena in the
biomedical domain, various evidential features are
explored.
</bodyText>
<listItem confidence="0.958137666666667">
• Word Formation Pattern (FWFP): The purpose
of this feature is to capture capitalization,
digitalization and other word formation
</listItem>
<page confidence="0.97298">
1
</page>
<bodyText confidence="0.9996545">
information. This feature has been widely used in
the biomedical domain (Kazama et al 2002; Shen
et al 2003; Zhou et al 2004). In this paper, the
same feature as in Shen et al 2003 is used.
</bodyText>
<listItem confidence="0.9355755">
• Morphological Pattern (FMP): Morphological
information, such as prefix and suffix, is
considered as an important cue for terminology
identification and has been widely applied in the
biomedical domain (Kazama et al 2002; Lee et al
2003; Shen et al 2003; Zhou et al 2004). Same as
Shen et al 2003, we use a statistical method to get
the most useful prefixes/suffixes from the training
data.
• Part-of-Speech (FPOS): Since many of the
words in biomedical entity names are in lowercase,
capitalization information in the biomedical
domain is not as evidential as that in the newswire
domain. Moreover, many biomedical entity names
are descriptive and very long. Therefore, POS may
provide useful evidence about the boundaries of
biomedical entity names.
• Head Noun Trigger (FHEAD): The head noun,
which is the major noun of a noun phrase, often
describes the function or the property of the noun
phrase. In this paper, we automatically extract
unigram and bigram head nouns from the training
data, and rank them by frequency. For each entity
class, we select 50% of top ranked head nouns as
head noun triggers. Table 1 shows some of the
examples.
</listItem>
<tableCaption confidence="0.8491505">
Table 1: Examples of auto-generated head nouns
Class Unigram bigram
</tableCaption>
<bodyText confidence="0.720255166666667">
PROTEIN interleukin activator protein
interferon binding protein
kinase cell receptor
DNA X chromosome
cDNA binding motif
chromosome promoter element
</bodyText>
<listItem confidence="0.916159">
• Name Alias Feature (FALIAS): Besides the
</listItem>
<bodyText confidence="0.999619219512195">
above widely used features, we also propose a
novel name alias feature. The intuition behind this
feature is the name alias phenomenon that relevant
entities will be referred to in many ways
throughout a given text and thus success of named
entity recognition is conditional on success at
determining when one noun phrase refers to the
very same entity as another noun phrase.
During decoding, the entity names already
recognized from the previous sentences of the
document are stored in a list. When the system
encounters an entity name candidate (e.g. a word
with a special word formation pattern), a name
alias algorithm (similar to Schwartz et al 2003) is
invoked to first dynamically determine whether the
entity name candidate might be alias for a
previously recognized name in the recognized list.
This is done by checking whether all the characters
in the entity name candidate exist in a recognized
entity name in the same order and whether the first
character in the entity name candidate is same as
the first character in the recognized name. For a
relevant work, please see Jacquemin (2001). The
name alias feature FALIAS is represented as
ENTITYnLm (L indicates the locality of the name
alias phenomenon). Here ENTITY indicates the
class of the recognized entity name and n indicates
the number of the words in the recognized entity
name while m indicates the number of the words in
the recognized entity name from which the name
alias candidate is formed. For example, when the
decoding process encounters the word “TCF”, the
word “TCF” is proposed as an entity name
candidate and the name alias algorithm is invoked
to check if the word “TCF” is an alias of a
recognized named entity. If “T cell Factor” is a
“Protein” name recognized earlier in the
document, the word “TCF” is determined as an
alias of “T cell Factor” with the name alias feature
Protein3L3 by taking the three initial letters of the
three-word “protein” name “T cell Factor”.
</bodyText>
<sectionHeader confidence="0.999639" genericHeader="method">
3. METHODS
</sectionHeader>
<subsectionHeader confidence="0.999465">
3.1 Hidden Markov Model
</subsectionHeader>
<bodyText confidence="0.981029083333333">
Given above various features, the key problem is
how to effectively and efficiently integrate them
together and find the optimal resolution to
biomedical named entity recognition. Here, we use
the Hidden Markov Model (HMM) as described in
Zhou et al 2002. A HMM is a model where a
sequence of outputs is generated in addition to the
Markov state sequence. It is a latent variable model
in the sense that only the output sequence is
observed while the state sequence remains
“hidden”.
Given an observation sequence O n = o1o2 ... o ,
</bodyText>
<sectionHeader confidence="0.372885" genericHeader="method">
1 n
</sectionHeader>
<bodyText confidence="0.8121465">
the purpose of a HMM is to find the most likely
state sequence S n = s1s2 ... s that maximizes
</bodyText>
<equation confidence="0.866238625">
1 n
PVT |O1n ) . Here, the observation o i =&lt; fi , wi &gt; ,
where wi is the word and
f i F , F FPOS , F , F
=&lt; i i i i
WFP MP ,
i
HEAD ALIAS &gt;
</equation>
<bodyText confidence="0.974887">
feature set of the word w , and the state is
</bodyText>
<equation confidence="0.594385">
si
i
</equation>
<bodyText confidence="0.726918">
structural and
</bodyText>
<subsubsectionHeader confidence="0.680972">
s
</subsubsectionHeader>
<bodyText confidence="0.999168">
where BOUNDARY denotes the position of the
</bodyText>
<equation confidence="0.814948333333333">
i
current word in the entity; ENTITY indicates the
i
</equation>
<bodyText confidence="0.814776">
class of the entity; and FEATURE is the feature set
i
used to model the ngram more precisely.
By rewriting log ( 1  |1 ) , we have:
</bodyText>
<equation confidence="0.9949115">
P S n O n
DNA
is the
i = ENTITY ,
BOUNDARY i _
i _FEATURE i
2
logP(Si = logP(Sl) + log PVn, an )n
PVT) ⋅ P(O1
101&amp;quot;)
information between
S and . In order to
n O1 n
1
</equation>
<bodyText confidence="0.9684865">
simplify the computation of this term, we assume
mutual information independence:
</bodyText>
<equation confidence="0.99150092">
MI Sn On
( 1 , 1 )=∑= MI s O
( , 1 ) or
n
i i 1
P S O
( , )
n n n P s O
( , )
n
1 1 i 1
log = ∑= log
n n n
P S P O
( ) ( )
⋅ P s P O
( ) ( )
⋅
1 1 i 1 i 1
output sequence
O and independent on other tags
n 1
in the tag sequence S . This assumption is
n
1
</equation>
<bodyText confidence="0.99116">
reasonable because the dependence among the tags
in the tag sequence S has already been captured
</bodyText>
<equation confidence="0.9789785">
n
1
</equation>
<bodyText confidence="0.7227605">
by the first term in Equation (1). Applying the
assumption (2) to Equation (1), we have:
</bodyText>
<equation confidence="0.9942732">
n
logP(Sl
Oi) = logP(Sl)
|
−∑logP(si
</equation>
<bodyText confidence="0.996191333333333">
information sources is exponential. In this paper, a
Support Vector Machine (SVM) plus sigmoid is
proposed to resolve this problem in our system.
</bodyText>
<subsectionHeader confidence="0.999877">
3.2 Support Vector Machine plus Sigmoid
</subsectionHeader>
<bodyText confidence="0.996078375">
Support Vector Machines (SVMs) are a popular
machine learning approach first presented by
Vapnik (1995). Based on the structural risk
minimization of statistical learning theory, SVMs
seek an optimal separating hyper-plane to divide
decisions based on support vectors which are
calibrated value that is not probability. That is, the
unthresholded output of an SVM can
</bodyText>
<equation confidence="0.959759526315789">
be
represented as
f ( x ) a i y i k ( x i , x ) b
= ∑ ⋅ ⋅ + (4)
i SV
∈
) (1)
(2)
)
n i = 1 (3) train an additional sigmoid model(Platt
1999):
1
p(si  |fi) =1 + exp(Afi + B) (5)
+
logP(si  |On) 1
∑
i
=
1
</equation>
<listItem confidence="0.9760495">
• The third term corresponds to the
component (dictionary) of the tagger.
</listItem>
<bodyText confidence="0.9993705">
The idea behind the model is that it tries to
assign each output an appropriate tag (state), which
contains boundary and class information. For
example,
</bodyText>
<equation confidence="0.544559">
1 binds stronger than NF kB to
TCEd
</equation>
<bodyText confidence="0.9998979">
The tag assigned to token
should indicate that it is at the beginning of an
entity name and it belongs to the
and the tag assigned to token
should
indicate that it does not belong to an entity name.
Here, the Viterbi algorithm (Viterbi 1967) is
implemented to find the most likely tag sequence.
The problem with the above HMM lies in the
data sparseness problem raised by
</bodyText>
<equation confidence="0.951429375">
“lexical”
“TCF
DNA”.
“TCF”
“Protein” class;
“binds”
P (  |1 )
si O n in the
</equation>
<bodyText confidence="0.9996165625">
third term of Equation (3). Ideally, we would have
sufficient training data for every event whose
conditional probability we wish to calculate.
Unfortunately, there is rarely enough training data
to compute accurate probabilities when decoding
on new data. Generally, two smoothing approaches
(Chen et al 1996) are applied to resolve this
problem: linear interpolation and back-off.
However, these two approaches only work well
when the number of different information sources
is limited. When a few features and/or a long
the training examples into two classes and make
. Therefore, the sigmoid outputs are
selected as the only effective examples in the
training set. However, SVMs produce an un-
normalized to get a probability distribution using
</bodyText>
<equation confidence="0.993157666666667">
p(si  |O 1 )
n =
p
</equation>
<bodyText confidence="0.86805125">
The second term in Equation (1) is the mutual
n
That is, an individual tag is only dependent on the
From Equation (3), we can see that:
</bodyText>
<listItem confidence="0.954449285714286">
• The first term can be computed by applying
chain rules. In ngram modeling (Chen et al 1996),
each tag is assumed to be dependent on the N-1
previous tags.
• The second term is the summation of log
probabilities of all the individual tags.
To map the SVM output into the probability, we
</listItem>
<bodyText confidence="0.956609">
Basically, SVMs are binary classifiers.
Therefore, we must extend SVMs to multi-class
(e.g. K) classifiers. For efficiency, we apply the
one vs. others strategy, which builds K classifiers
so as to separate one class from all others, instead
of the
strategy, which builds K*(K-1)/2
classifiers considering all pairs of classes.
Moreover, we only apply the simple linear kernel,
although other kernels (e.g. polynomial kernel) and
pairwise strategy can have better performan
pairwise
ce.
Finally, for each state s , there is one sigmoid
i
</bodyText>
<subsectionHeader confidence="0.999737">
3.3 Post-Processing
</subsectionHeader>
<bodyText confidence="0.999724">
Two post-processing modules, namely cascaded
entity name resolution and abbreviation resolution,
are applied in our system to further improve the
performance.
</bodyText>
<subsectionHeader confidence="0.681467">
Cascaded Entity Name Resolution
</subsectionHeader>
<bodyText confidence="0.998929444444445">
It is found (Shen et al 2003) that 16.57% of entity
names in GENIA V3.0 have cascaded
constructions, e.g.
&lt;RNA&gt;&lt;DNA&gt;CIITA&lt;/DNA&gt; mRNA&lt;/RNA&gt;.
Therefore, it is important to resolve such
phenomenon.
Here, a pattern-based module is proposed to
resolve the cascaded entity names while the above
HMM is applied to recognize embedded entity
</bodyText>
<equation confidence="0.9407604">
p(si |fi)
)
p
(si  |fi
∑
i
.
)
(si  |fi
3 context are considered, the number of different
</equation>
<bodyText confidence="0.777704333333333">
names and non-cascaded entity names. In the
GENIA corpus, we find that there are six useful
patterns of cascaded entity name constructions:
</bodyText>
<listItem confidence="0.992471785714286">
• &lt;ENTITY&gt; := &lt;ENTITY&gt; + head noun, e.g.
&lt;PROTEIN&gt; binding motif4&lt;DNA&gt;
• &lt;ENTITY&gt; := &lt;ENTITY&gt; + &lt;ENTITY&gt;, e.g.
&lt;LIPID&gt; &lt;PROTEIN&gt;4&lt;PROTEIN&gt;
• &lt;ENTITY&gt; := modifier + &lt;ENTITY&gt;, e.g.
anti &lt;Protein&gt;4&lt;Protein&gt;
• &lt;ENTITY&gt; := &lt;ENTITY&gt; + word +
&lt;ENTITY&gt;, e.g.
&lt;VIRUS&gt; infected
&lt;MULTICELL&gt;4&lt;MULTICELL &gt;
• &lt;ENTITY&gt; := modifier + &lt;ENTITY&gt; + head
noun
• &lt;ENTITY&gt; := &lt;ENTITY&gt; + &lt;ENTITY&gt; +
head noun
</listItem>
<bodyText confidence="0.99878325">
In our experiments, all the rules of above six
patterns are extracted from the cascaded entity
names in the training data to deal with the
cascaded entity name phenomenon.
</bodyText>
<sectionHeader confidence="0.7202" genericHeader="method">
Abbreviation Resolution
</sectionHeader>
<bodyText confidence="0.999994630434783">
While the name alias feature is useful to detect the
inter-sentential name alias phenomenon, it is
unable to identify the inner-sentential name alias
phenomenon: the inner-sentential abbreviation.
Such abbreviations widely occur in the biomedical
domain.
In our system, we present an effective and
efficient algorithm to recognize the inner-sentential
abbreviations more accurately by mapping them to
their full expanded forms. In the GENIA corpus,
we observe that the expanded form and its
abbreviation often occur together via parentheses.
Generally, there are two patterns: “expanded form
(abbreviation)” and “abbreviation (expanded
form)”.
Our algorithm is based on the fact that it is
much harder to classify an abbreviation than its
expanded form. Generally, the expanded form is
more evidential than its abbreviation to determine
its class. The algorithm works as follows: Given a
sentence with parentheses, we use a similar
algorithm as in Schwartz et al 2003 to determine
whether it is an abbreviation with parentheses. This
is done by starting from the end of both the
abbreviation and the expanded form, moving from
right to left and trying to find the shortest
expanded form that matches the abbreviation. Any
character in the expanded form can match a
character in the abbreviation with one exception:
the match of the character at the beginning of the
abbreviation must match the first alphabetic
character of the first word in the expanded form. If
yes, we remove the abbreviation and the
parentheses from the sentence. After the sentence
is processed, we restore the abbreviation with
parentheses to its original position in the sentence.
Then, the abbreviation is classified as the same
class of the expanded form, if the expanded form is
recognized as an entity name. In the meanwhile,
we also adjust the boundaries of the expanded form
according to the abbreviation, if necessary. Finally,
the expanded form and its abbreviation are stored
in the recognized list of biomedical entity names
from the document to help the resolution of
forthcoming occurrences of the same abbreviation
in the document.
</bodyText>
<sectionHeader confidence="0.999756" genericHeader="method">
4. EXPERIMENTS AND EVALUATION
</sectionHeader>
<bodyText confidence="0.999855090909091">
We evaluate our PowerBioNE system on GENIA
V1.1 and GENIA V3.0 using precision/recall/F-
measure. For each evaluation, we select 20% of the
corpus as the held-out test data and the remaining
80% as the training data. All the experimentations
are done 5 times and the evaluations are averaged
over the held-out test data. For cascaded entity
name resolution, an average of 59 and 97 rules are
extracted from the cascaded entity names in the
training data of GENIA V1.1 and V3.0
respectively. For POS, all the POS taggers are
trained on the training data with POS imported
from the corresponding GENIA V3.02p with POS
annotated.
Table 2 shows the performance of our system
on GENIA V1.1 and GENIA V3.0, and the
comparison with that of the best reported system
(Shen et al 2003). It shows that our system
achieves the F-measure of 69.1 on GENIA V1.1
and the F-measure of 71.2 on GENIA V3.0
respectively, without help of any dictionaries. It
also shows that our system outperforms Shen et al
(2003) by 6.9 in F-measure on GENIA V1.1 and
4.6 in F-measure on GENIA V3.0. This is largely
due to the superiority of the SVM plus sigmoid in
our system (improvement of 3.7 in F-measure on
GENIA V3.0) over the back-off approach in Shen
et al (2003) and the novel name alias feature
(improvement of 1.2 in F-measure on GENIA
V3.0). Finally, evaluation also shows that the
cascaded entity name resolution and the
abbreviation resolution contribute 3.4 and 2.1
respectively in F-measure on GENIA V3.0.
</bodyText>
<tableCaption confidence="0.99623">
Table 2: Performance of our PowerBioNE system
</tableCaption>
<table confidence="0.5952206">
Performance P R F
Shen et al on GENIA V3.0 66.5 66.6 66.6
Shen et al on GENIA V1.1 63.1 61.2 62.2
Our system on GENIA V3.0 72.7 69.8 71.2
Our system on GENIA V1.1 70.4 67.9 69.1
</table>
<page confidence="0.983261">
4
</page>
<tableCaption confidence="0.855337">
Table 3: Performance of different entity classes on
GENIA V3.0
</tableCaption>
<table confidence="0.952512">
Entity Number of instances in F
Class the training data
Cell Type 6034 81.8
Lipid 1602 68.6
Multi-Cell 1463 78.1
Protein 21380 77.8
DNA 7538 70.8
Cell Line 3216 68.5
RNA 695 56.2
Virus 873 67.2
</table>
<bodyText confidence="0.999213">
One important question is about the
performance of different entity classes. Table 3
shows the performance of some of the biomedical
entity classes on GENIA V3.0. Of particular
interest, our system achieves the F-measure of 77.8
on the class “Protein”. It shows that the
performance varies a lot among different entity
classes. One reason may be due to different
difficulties in recognizing different entity classes.
Another reason may be due to the different
numbers of instances in different entity classes.
Though GENIA V3.0 provides a good basis for
named entity recognition in the biomedical domain
and probably the best available, it has clear bias.
Table 3 shows that, while GENIA V3.0 is of
enough size for recognizing the major classes, such
as “Protein”, “Cell Type”, “Cell Line”, “Lipid”
etc, it is of limited size in recognizing other classes,
such as “Virus”.
</bodyText>
<sectionHeader confidence="0.997178" genericHeader="method">
5. ERROR ANALYSIS
</sectionHeader>
<bodyText confidence="0.99913225">
In order to further evaluate our system and explore
possible improvement, we have implemented an
error analysis. This is done by randomly choosing
100 errors from our recognition results. During the
error analysis, we find many errors are due to the
strict annotation scheme and the annotation
inconsistence in the GENIA corpus, and can be
considered acceptable. Therefore, we will also
examine the acceptable F-measure of our system,
in particular, the acceptable F-measure on the
“protein” class.
All the 100 errors are classified as follows:
</bodyText>
<listItem confidence="0.656275666666667">
• Left boundary errors (14): It includes the
errors with correct class identification, correct right
boundary detection and only wrong left boundary
</listItem>
<bodyText confidence="0.973949631578947">
detection. We find that most of such errors come
from the long and descriptive naming convention.
We also find that 11 of 14 errors are acceptable
and ignorance of the descriptive words often does
not make a much difference for the entity names.
In fact, it is even hard for biologists to decide
whether the descriptive words should be a part of
the entity names, such as “normal”, “activated”,
etc. In particular, 4 of 14 errors belong to the
“protein” class. Among them, two errors are
acceptable, e.g. “classical &lt;PROTEIN&gt;1,25 (OH)
2D3 receptor&lt;/PROTEIN&gt;” =&gt;
“&lt;PROTEIN&gt;classical 1,25 (OH) 2D3
receptor&lt;/PROTEIN&gt;” (with format of
“annotation in the corpus =&gt; identification made
by our system”), while the other two are
unacceptable, e.g. “&lt;PROTEIN&gt;viral
transcription factor&lt;/PROTEIN&gt; _&gt; viral
&lt;PROTEIN&gt;transcription factor&lt;/PROTEIN&gt;”.
</bodyText>
<listItem confidence="0.75711303125">
• Cascaded entity name errors (15): It includes
the errors caused by the cascaded entity name
phenomenon. We find that most of such errors
come from the annotation inconsistence in the
GENIA corpus: In some cases, only the embedded
entity names are annotated while in other cases, the
embedded entity names are not annotated. Our
system tends to annotate both the embedded entity
names and the whole entity names. Among them,
we find that 13 of 16 errors are acceptable. In
particular, 2 of 16 errors belong to the “protein”
class and both are acceptable, e.g. “&lt;DNA&gt;NF
kappa B binding site&lt;/DNA&gt;” _&gt;
“&lt;DNA&gt;&lt;PROTEIN&gt;NF kappa B&lt;/PROTEIN&gt;
binding site&lt;/DNA&gt;”.
• Misclassification errors (18): It includes the
errors with wrong class identification, correct right
boundary detection and correct left boundary
detection. We find that this kind of errors mainly
comes from the sense ambiguity of biomedical
entity names and is very difficult to disambiguate.
Among them, 8 errors are related with the “DNA”
class and 6 errors are related with the “Cell Line”
and “Cell Type” classes. We also find that only 3
of 18 errors are acceptable. In particular, there are
6 errors related to the “protein” class. Finally, we
find that all the 6 errors are caused by
misclassification of the “DNA” class to the
“protein” class and all of them are unacceptable,
e.g. “&lt;DNA&gt;type I IFN&lt;DNA&gt;” _&gt;
“&lt;PROTEIN&gt;type I IFN&lt;/PROTEIN&gt;”.
• True negative (23): It includes the errors by
</listItem>
<bodyText confidence="0.986040888888889">
missing the identification of biomedical entity
names. We find that 16 errors come from the
“other” class and 10 errors from the “protein” class.
We also find that the GENIA corpus annotates
some general noun phrases as biomedical entity
names, e.g. “protein” in “the protein” and
“cofactor” in “a cofactor”. Finally, we find that 11
of 23 errors are acceptable. In particular, 9 of 23
errors related to the “protein” class. Among them,
</bodyText>
<footnote confidence="0.4891915">
3 errors are acceptable, e.g. “the
&lt;PROTEIN&gt;protein&lt;/PROTEIN&gt; _&gt; “the
</footnote>
<page confidence="0.982858">
5
</page>
<bodyText confidence="0.950218736842105">
protein”, while the other 6 are unacceptable, e.g.
“ &lt;PROTEIN&gt;80 kDa&lt;/PROTEIN&gt; _&gt; “80 kDa”.
• False positive (15): It includes the errors by
wrongly identifying biomedical entity names
which are not annotated in the GENIA corpus. We
find that 9 of 15 errors come from the “other” class.
This suggests that the annotation of the “other”
class is much lack of consistency and most
problematic in the GENIA corpus. We also find
that 7 of 15 errors are acceptable. In particular, 2 of
15 errors are related to the “protein” class and both
are acceptable, e.g. “affinity sites”_&gt;
“&lt;PROTEIN&gt;affinity sites&lt;/PROTEIN&gt;”.
• Miscellaneous (14): It includes all the other
errors, e.g. combination of the above errors and the
errors caused by parentheses. We find that only 1
of 14 errors is acceptable. We also find that,
among them, 2 errors are related with the “protein”
class and both are unacceptable, e.g.
</bodyText>
<construct confidence="0.772600666666667">
“&lt;PROTEIN&gt;17 amino acid
epitope&lt;/PROTEIN&gt;” _&gt; “17 &lt;RNA&gt;amino acid
epitope&lt;/RNA&gt;”.
</construct>
<bodyText confidence="0.999969">
From above error analysis, we find that about
half (46/100) of errors are acceptable and can be
avoided by flexible annotation scheme (e.g.
regarding the modifiers in the left boundaries) and
consistent annotation (e.g. in the annotation of the
“other” class and the cascaded entity name
phenomenon). In particular, about one third (9/25)
of errors are acceptable on the “protein” class. This
means that the acceptable F-measure can reach
about 84.4 on the 23 classes of GENIA V3.0. In
particular, the acceptable F-measure on the
“protein” class is about 85.8. In addition, this
performance is achieved without using any extra
resources (e.g. dictionaries). With help of extra
resources, we think an acceptable F-measure of
near 90 can be achieved in the near future.
</bodyText>
<sectionHeader confidence="0.999902" genericHeader="related work">
6. RELATED WORK
</sectionHeader>
<bodyText confidence="0.999878806451613">
Previous approaches in biomedical named entity
recognition typically use some domain specific
heuristic rules and heavily rely on existing
dictionaries (Fukuda et al 1998, Proux et al 1998
and Gaizauskas et al 2000).
The current trend is to apply machine learning
approaches in biomedical named entity recognition,
largely due to the development of the GENIA
corpus. The typical explorations include Kazama et
al 2002, Lee et al 2003, Tsuruoka et al 2003, Shen
et al 2003. Kazama et al 2002 applies SVM and
incorporates a rich feature set, including word
feature, POS, prefix feature, suffix feature,
previous class feature, word cache feature and
HMM state feature. The experiment on GENIA
V1.1 shows the F-measure of 54.4. Tsuruoka et al
2003 applies a dictionary-based approach and a
naïve Bayes classifier to filter out false positives. It
only evaluates against the “protein” class in
GENIA V3.0, and receives the F-measure of 70.2
with help of a large dictionary. Lee et al 2003 uses
a two phase SVM-based recognition approach and
incorporates word formation pattern and part-of-
speech. The evaluation on GENIA V3.0 shows the
F-measure of 66.5 with help of an entity name
dictionary. Shen et al 2003 proposes a HMM-based
approach and two post-processing modules
(cascaded entity name resolution and abbreviation
resolution). Evaluation shows the F-measure of
62.2 and 66.6 on GENIA V1.1 and V3.0
respectively.
</bodyText>
<sectionHeader confidence="0.977285" genericHeader="conclusions">
7. CONCLUSION
</sectionHeader>
<bodyText confidence="0.999976409090909">
In the paper, we describe our HMM-based named
entity recognition system in the biomedical domain,
named PowerBioNE. Various lexical,
morphological, syntactic, semantic and discourse
features are incorporated to cope with the special
phenomena in biomedical named entity recognition.
In addition, a SVM plus sigmoid is proposed to
effectively resolve the data sparseness problem.
Finally, we present two post-processing modules to
deal with cascaded entity name and abbreviation
phenomena.
The main contributions of our work are the
novel name alias feature in the biomedical domain,
the SVM plus sigmoid approach in the effective
resolution of the data sparseness problem in our
system and its integration with the Hidden Markov
Model.
In the near future, we will further improve the
performance by investigating more on conjunction
and disjunction construction, the synonym
phenomenon, and exploration of extra resources
(e.g. dictionary).
</bodyText>
<sectionHeader confidence="0.999836" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999417823529412">
Chen and Goodman. 1996. An Empirical Study of
Smoothing Technniques for Language Modeling.
In Proceedings of the 34th Annual Meeting of the
Association of Computational Linguistics
(ACL’1996). pp310-318. Santa Cruz, California,
USA.
Fukuda K., Tsunoda T., Tamura A., and Takagi T.
1998. Toward information extraction: identifying
protein names from biological papers. In Proc. of
the Pacific Symposium on Biocomputing’98
(PSB’98), 707-718.
Gaizauskas R., Demetriou G. and Humphreys K.
2000. Term Recognition and Classification in
Biological Science Journal Articles. In Proc. of the
Computational Terminology for Medical and
Biological Applications Workshop of the 2nd
International Conference on NLP, 37-44.
</reference>
<page confidence="0.987516">
6
</page>
<reference confidence="0.989339721311476">
Association for Computational Linguistics (ACL),
473-480.
Jacquemin C. 2001. Spotting and Discovering Terms
through Natural Language Processing, Cambridge:
MIT Press
Kazama J., Makino T., Ohta Y., and Tsujii J. 2002.
Tuning Support Vector Machines for Biomedical
Named Entity Recognition. In Proc. of the
Workshop on Natural Language Processing in the
Biomedical Domain (at ACL’2002), 1-8.
Lee K.J. Hwang Y.S. and Rim H.C. Two-phase
biomedical NE Recognition based on SVMs. In
Proceedings of the ACL’2003 Workshop on
Natural Language Processing in Biomedicine.
pp.33-40. Sapporo, Japan.
MUC6. 1995. Morgan Kaufmann Publishers, Inc. In
Proceedings of the Sixth Message Understanding
Conference (MUC-6). Columbia, Maryland.
MUC7. 1998. Morgan Kaufmann Publishers, Inc. In
Proceedings of the Seventh Message
Understanding Conference (MUC-7). Fairfax,
Virginia.
Ohta T., Tateisi Y., Kim J., Mima H., and Tsujii J.
2002. The GENIA corpus: An annotated research
abstract corpus in molecular biology domain. In
Proc. of HLT 2002.
Platt J. 1999. Probabilistic Outputs for Support
Vector Machines and comparisions to regularized
Likelihood Methods. MIT Press.
Proux D., Rechenmann F., Julliard L., Pillet V. and
Jacq B. 1998. Detecting Gene Symbols and
Names in Biological Texts: A First Step toward
Pertinent Information Extraction. In Proc. of
Genome Inform Ser Workshop Genome Inform,
72-80.
Schwartz A.S. and Hearst M.A. 2003. A Simple
Algorithm for Identifying Abbreviation
Definitions in Biomedical Text. In Proc. of the
Pacific Symposium on Biocomputing (PSB 2003)
Kauai.
Shen Dan, Zhang Jie, Zhou GuoDong, Su Jian and
Tan Chew Lim, Effective Adaptation of a Hidden
Markov Model-based Named Entity Recognizer
for Biomedical Domain, Proceedings of ACL’2003
Workshop on Natural Language Processing in
Biomedicine, Sapporo, Japan, 11 July 2003. pp49-
56.
Tsuruoka Y. and Tsujii J. 2003. Boosting precision
and recall of dictionary-based protein name
recognition. In Proceedings of the ACL’2003
Workshop on Natural Language Processing in
Biomedicine. pp.41-48. Sapporo, Japan.
Vapnik V. 1995. The Nature of Statistical Learning
Theory. NY, USA: Springer-Verlag.
Viterbi A.J. 1967. Error bounds for convolutional
codes and an asymptotically optimum decoding
algorithm. IEEE Transactions on Information
Theory, 260-269.
Zhou G.D. and Su J. 2002. Named Entity
Recognition using an HMM-based Chunk Tagger.
In Proc. of the 40th Annual Meeting of the
</reference>
<page confidence="0.99951">
7
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.287478">
<title confidence="0.999043">Recognizing Names in Biomedical Texts</title>
<author confidence="0.595803">using Hidden Markov Model</author>
<author confidence="0.595803">SVM plus Sigmoid</author>
<affiliation confidence="0.7712475">ZHOU Institute for Infocomm</affiliation>
<address confidence="0.9650485">21 Heng Mui Keng Singapore</address>
<email confidence="0.988922">zhougd@i2r.a-star.edu.sg</email>
<abstract confidence="0.978033631578947">In this paper, we present a named entity recognition system in the biomedical domain, called PowerBioNE. In order to deal with the special phenomena in the biomedical domain, various evidential features are proposed and integrated through a Hidden Markov Model (HMM). In addition, a Support Vector Machine (SVM) plus sigmoid is proposed to resolve the data sparseness problem in our system. Finally, we present two post-processing modules to deal with the cascaded entity name and abbreviation phenomena. Evaluation shows that our system achieves the F-measure of 69.1 and 71.2 on the 23 classes of GENIA V1.1 and V3.0 respectively. In particular, our system achieves the F-measure of on the class of GENIA V3.0. It shows that our system outperforms the best published system on GENIA V1.1 and V3.0.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chen</author>
<author>Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Technniques for Language Modeling.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association of Computational Linguistics (ACL’1996).</booktitle>
<pages>310--318</pages>
<location>Santa Cruz, California, USA.</location>
<marker>Chen, Goodman, 1996</marker>
<rawString>Chen and Goodman. 1996. An Empirical Study of Smoothing Technniques for Language Modeling. In Proceedings of the 34th Annual Meeting of the Association of Computational Linguistics (ACL’1996). pp310-318. Santa Cruz, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fukuda</author>
<author>T Tsunoda</author>
<author>A Tamura</author>
<author>T Takagi</author>
</authors>
<title>Toward information extraction: identifying protein names from biological papers.</title>
<date>1998</date>
<booktitle>In Proc. of the Pacific Symposium on Biocomputing’98 (PSB’98),</booktitle>
<pages>707--718</pages>
<contexts>
<context position="24522" citStr="Fukuda et al 1998" startWordPosition="4099" endWordPosition="4102">) of errors are acceptable on the “protein” class. This means that the acceptable F-measure can reach about 84.4 on the 23 classes of GENIA V3.0. In particular, the acceptable F-measure on the “protein” class is about 85.8. In addition, this performance is achieved without using any extra resources (e.g. dictionaries). With help of extra resources, we think an acceptable F-measure of near 90 can be achieved in the near future. 6. RELATED WORK Previous approaches in biomedical named entity recognition typically use some domain specific heuristic rules and heavily rely on existing dictionaries (Fukuda et al 1998, Proux et al 1998 and Gaizauskas et al 2000). The current trend is to apply machine learning approaches in biomedical named entity recognition, largely due to the development of the GENIA corpus. The typical explorations include Kazama et al 2002, Lee et al 2003, Tsuruoka et al 2003, Shen et al 2003. Kazama et al 2002 applies SVM and incorporates a rich feature set, including word feature, POS, prefix feature, suffix feature, previous class feature, word cache feature and HMM state feature. The experiment on GENIA V1.1 shows the F-measure of 54.4. Tsuruoka et al 2003 applies a dictionary-base</context>
</contexts>
<marker>Fukuda, Tsunoda, Tamura, Takagi, 1998</marker>
<rawString>Fukuda K., Tsunoda T., Tamura A., and Takagi T. 1998. Toward information extraction: identifying protein names from biological papers. In Proc. of the Pacific Symposium on Biocomputing’98 (PSB’98), 707-718.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
<author>G Demetriou</author>
<author>K Humphreys</author>
</authors>
<title>Term Recognition and Classification in Biological Science Journal Articles.</title>
<date>2000</date>
<booktitle>In Proc. of the Computational Terminology for Medical and Biological Applications Workshop of the 2nd International Conference on NLP,</booktitle>
<pages>37--44</pages>
<contexts>
<context position="24567" citStr="Gaizauskas et al 2000" startWordPosition="4108" endWordPosition="4111">in” class. This means that the acceptable F-measure can reach about 84.4 on the 23 classes of GENIA V3.0. In particular, the acceptable F-measure on the “protein” class is about 85.8. In addition, this performance is achieved without using any extra resources (e.g. dictionaries). With help of extra resources, we think an acceptable F-measure of near 90 can be achieved in the near future. 6. RELATED WORK Previous approaches in biomedical named entity recognition typically use some domain specific heuristic rules and heavily rely on existing dictionaries (Fukuda et al 1998, Proux et al 1998 and Gaizauskas et al 2000). The current trend is to apply machine learning approaches in biomedical named entity recognition, largely due to the development of the GENIA corpus. The typical explorations include Kazama et al 2002, Lee et al 2003, Tsuruoka et al 2003, Shen et al 2003. Kazama et al 2002 applies SVM and incorporates a rich feature set, including word feature, POS, prefix feature, suffix feature, previous class feature, word cache feature and HMM state feature. The experiment on GENIA V1.1 shows the F-measure of 54.4. Tsuruoka et al 2003 applies a dictionary-based approach and a naïve Bayes classifier to fi</context>
</contexts>
<marker>Gaizauskas, Demetriou, Humphreys, 2000</marker>
<rawString>Gaizauskas R., Demetriou G. and Humphreys K. 2000. Term Recognition and Classification in Biological Science Journal Articles. In Proc. of the Computational Terminology for Medical and Biological Applications Workshop of the 2nd International Conference on NLP, 37-44.</rawString>
</citation>
<citation valid="false">
<pages>473--480</pages>
<institution>Association for Computational Linguistics (ACL),</institution>
<marker></marker>
<rawString>Association for Computational Linguistics (ACL), 473-480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through Natural Language Processing,</title>
<date>2001</date>
<publisher>MIT Press</publisher>
<location>Cambridge:</location>
<contexts>
<context position="6844" citStr="Jacquemin (2001)" startWordPosition="1075" endWordPosition="1076">n a list. When the system encounters an entity name candidate (e.g. a word with a special word formation pattern), a name alias algorithm (similar to Schwartz et al 2003) is invoked to first dynamically determine whether the entity name candidate might be alias for a previously recognized name in the recognized list. This is done by checking whether all the characters in the entity name candidate exist in a recognized entity name in the same order and whether the first character in the entity name candidate is same as the first character in the recognized name. For a relevant work, please see Jacquemin (2001). The name alias feature FALIAS is represented as ENTITYnLm (L indicates the locality of the name alias phenomenon). Here ENTITY indicates the class of the recognized entity name and n indicates the number of the words in the recognized entity name while m indicates the number of the words in the recognized entity name from which the name alias candidate is formed. For example, when the decoding process encounters the word “TCF”, the word “TCF” is proposed as an entity name candidate and the name alias algorithm is invoked to check if the word “TCF” is an alias of a recognized named entity. If</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>Jacquemin C. 2001. Spotting and Discovering Terms through Natural Language Processing, Cambridge: MIT Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kazama</author>
<author>T Makino</author>
<author>Y Ohta</author>
<author>J Tsujii</author>
</authors>
<title>Tuning Support Vector Machines for Biomedical Named Entity Recognition.</title>
<date>2002</date>
<booktitle>In Proc. of the Workshop on Natural Language Processing in the Biomedical Domain (at ACL’2002),</booktitle>
<pages>1--8</pages>
<contexts>
<context position="2050" citStr="Kazama et al 2002" startWordPosition="304" endWordPosition="307"> critical and is important for proteinprotein interaction extraction, pathway construction, automatic database curation, etc. Such a task, called named entity recognition, has been well developed in the Information Extraction literature (MUC-6; MUC-7). In MUC, the task of named entity recognition is to recognize the names of persons, locations, organizations, etc. in the newswire domain. In the biomedical domain, we care about entities like gene, protein, virus, etc. In recent years, many explorations have been done to port existing named entity recognition systems into the biomedical domain (Kazama et al 2002; Lee et al 2003; Shen et al 2003; Zhou et al 2004). However, few of them have achieved satisfactory performance due to the special characteristics in the biomedical domain, such as long and descriptive naming conventions, conjunctive and disjunctive structure, causal naming convention and rapidly emerging new biomedical names, abbreviation, and cascaded construction. On all accounts, we can say that the entity names in the biomedical domain are much more complex than those in the newswire domain. In this paper, we present a named entity recognition system in the biomedical domain, called Powe</context>
<context position="4234" citStr="Kazama et al 2002" startWordPosition="640" endWordPosition="643">ulti-cell, mono-cell, virus, body part, tissue, cell type, cell component, organism, cell line, other artificial source, protein, peptide, amino acid monomer, DNA, RNA, poly nucleotide, nucleotide, lipid, carbohydrate, other organic compound, inorganic, atom and other. 2. FEATURES In order to deal with the special phenomena in the biomedical domain, various evidential features are explored. • Word Formation Pattern (FWFP): The purpose of this feature is to capture capitalization, digitalization and other word formation 1 information. This feature has been widely used in the biomedical domain (Kazama et al 2002; Shen et al 2003; Zhou et al 2004). In this paper, the same feature as in Shen et al 2003 is used. • Morphological Pattern (FMP): Morphological information, such as prefix and suffix, is considered as an important cue for terminology identification and has been widely applied in the biomedical domain (Kazama et al 2002; Lee et al 2003; Shen et al 2003; Zhou et al 2004). Same as Shen et al 2003, we use a statistical method to get the most useful prefixes/suffixes from the training data. • Part-of-Speech (FPOS): Since many of the words in biomedical entity names are in lowercase, capitalization</context>
<context position="24769" citStr="Kazama et al 2002" startWordPosition="4139" endWordPosition="4142">rmance is achieved without using any extra resources (e.g. dictionaries). With help of extra resources, we think an acceptable F-measure of near 90 can be achieved in the near future. 6. RELATED WORK Previous approaches in biomedical named entity recognition typically use some domain specific heuristic rules and heavily rely on existing dictionaries (Fukuda et al 1998, Proux et al 1998 and Gaizauskas et al 2000). The current trend is to apply machine learning approaches in biomedical named entity recognition, largely due to the development of the GENIA corpus. The typical explorations include Kazama et al 2002, Lee et al 2003, Tsuruoka et al 2003, Shen et al 2003. Kazama et al 2002 applies SVM and incorporates a rich feature set, including word feature, POS, prefix feature, suffix feature, previous class feature, word cache feature and HMM state feature. The experiment on GENIA V1.1 shows the F-measure of 54.4. Tsuruoka et al 2003 applies a dictionary-based approach and a naïve Bayes classifier to filter out false positives. It only evaluates against the “protein” class in GENIA V3.0, and receives the F-measure of 70.2 with help of a large dictionary. Lee et al 2003 uses a two phase SVM-based recog</context>
</contexts>
<marker>Kazama, Makino, Ohta, Tsujii, 2002</marker>
<rawString>Kazama J., Makino T., Ohta Y., and Tsujii J. 2002. Tuning Support Vector Machines for Biomedical Named Entity Recognition. In Proc. of the Workshop on Natural Language Processing in the Biomedical Domain (at ACL’2002), 1-8.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lee K J Hwang Y S</author>
<author>H C Rim</author>
</authors>
<title>Two-phase biomedical NE Recognition based on SVMs.</title>
<booktitle>In Proceedings of the ACL’2003 Workshop on Natural Language Processing in Biomedicine.</booktitle>
<pages>33--40</pages>
<location>Sapporo, Japan.</location>
<marker>S, Rim, </marker>
<rawString>Lee K.J. Hwang Y.S. and Rim H.C. Two-phase biomedical NE Recognition based on SVMs. In Proceedings of the ACL’2003 Workshop on Natural Language Processing in Biomedicine. pp.33-40. Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MUC6</author>
</authors>
<date>1995</date>
<booktitle>In Proceedings of the Sixth Message Understanding Conference (MUC-6).</booktitle>
<publisher>Morgan Kaufmann Publishers, Inc.</publisher>
<location>Columbia, Maryland.</location>
<marker>MUC6, 1995</marker>
<rawString>MUC6. 1995. Morgan Kaufmann Publishers, Inc. In Proceedings of the Sixth Message Understanding Conference (MUC-6). Columbia, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MUC7</author>
</authors>
<date>1998</date>
<booktitle>In Proceedings of the Seventh Message Understanding Conference (MUC-7).</booktitle>
<publisher>Morgan Kaufmann Publishers, Inc.</publisher>
<location>Fairfax, Virginia.</location>
<marker>MUC7, 1998</marker>
<rawString>MUC7. 1998. Morgan Kaufmann Publishers, Inc. In Proceedings of the Seventh Message Understanding Conference (MUC-7). Fairfax, Virginia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Ohta</author>
<author>Y Tateisi</author>
<author>J Kim</author>
<author>H Mima</author>
<author>J Tsujii</author>
</authors>
<title>The GENIA corpus: An annotated research abstract corpus in molecular biology domain.</title>
<date>2002</date>
<booktitle>In Proc. of HLT</booktitle>
<contexts>
<context position="3281" citStr="Ohta et al. 2002" startWordPosition="495" endWordPosition="498">er to deal with the special phenomena in the biomedical domain, various evidential features are proposed and integrated effectively and efficiently through a Hidden Markov Model (HMM). In addition, a Support Vector Machine (SVM) plus sigmoid is proposed to resolve the data sparseness problem in our system. Finally, we present two postprocessing modules to deal with the cascaded entity name and abbreviation phenomena to further improve the performance. All of our experiments are done on the GENIA corpus, which is the largest annotated corpus in the molecular biology domain available to public (Ohta et al. 2002). In our experiments, two versions are used: 1) Genia V1.1 which contains 670 MEDLINE abstracts of 123K words; 2) Genia V3.0 which is a superset of GENIA V1.1 and contains 2000 MEDLINE abstracts of 360K words. The annotation of biomedical entities is based on the GENIA ontology (Ohta et al. 2002), which includes 23 distinct classes: multi-cell, mono-cell, virus, body part, tissue, cell type, cell component, organism, cell line, other artificial source, protein, peptide, amino acid monomer, DNA, RNA, poly nucleotide, nucleotide, lipid, carbohydrate, other organic compound, inorganic, atom and o</context>
</contexts>
<marker>Ohta, Tateisi, Kim, Mima, Tsujii, 2002</marker>
<rawString>Ohta T., Tateisi Y., Kim J., Mima H., and Tsujii J. 2002. The GENIA corpus: An annotated research abstract corpus in molecular biology domain. In Proc. of HLT 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Platt</author>
</authors>
<title>Probabilistic Outputs for Support Vector Machines and comparisions to regularized Likelihood Methods.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="10226" citStr="Platt 1999" startWordPosition="1765" endWordPosition="1766">lus sigmoid is proposed to resolve this problem in our system. 3.2 Support Vector Machine plus Sigmoid Support Vector Machines (SVMs) are a popular machine learning approach first presented by Vapnik (1995). Based on the structural risk minimization of statistical learning theory, SVMs seek an optimal separating hyper-plane to divide decisions based on support vectors which are calibrated value that is not probability. That is, the unthresholded output of an SVM can be represented as f ( x ) a i y i k ( x i , x ) b = ∑ ⋅ ⋅ + (4) i SV ∈ ) (1) (2) ) n i = 1 (3) train an additional sigmoid model(Platt 1999): 1 p(si |fi) =1 + exp(Afi + B) (5) + logP(si |On) 1 ∑ i = 1 • The third term corresponds to the component (dictionary) of the tagger. The idea behind the model is that it tries to assign each output an appropriate tag (state), which contains boundary and class information. For example, 1 binds stronger than NF kB to TCEd The tag assigned to token should indicate that it is at the beginning of an entity name and it belongs to the and the tag assigned to token should indicate that it does not belong to an entity name. Here, the Viterbi algorithm (Viterbi 1967) is implemented to find the most li</context>
</contexts>
<marker>Platt, 1999</marker>
<rawString>Platt J. 1999. Probabilistic Outputs for Support Vector Machines and comparisions to regularized Likelihood Methods. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Proux</author>
<author>F Rechenmann</author>
<author>L Julliard</author>
<author>V Pillet</author>
<author>B Jacq</author>
</authors>
<title>Detecting Gene Symbols and Names in Biological Texts: A First Step toward Pertinent Information Extraction.</title>
<date>1998</date>
<booktitle>In Proc. of Genome Inform Ser Workshop Genome Inform,</booktitle>
<pages>72--80</pages>
<contexts>
<context position="24540" citStr="Proux et al 1998" startWordPosition="4103" endWordPosition="4106">eptable on the “protein” class. This means that the acceptable F-measure can reach about 84.4 on the 23 classes of GENIA V3.0. In particular, the acceptable F-measure on the “protein” class is about 85.8. In addition, this performance is achieved without using any extra resources (e.g. dictionaries). With help of extra resources, we think an acceptable F-measure of near 90 can be achieved in the near future. 6. RELATED WORK Previous approaches in biomedical named entity recognition typically use some domain specific heuristic rules and heavily rely on existing dictionaries (Fukuda et al 1998, Proux et al 1998 and Gaizauskas et al 2000). The current trend is to apply machine learning approaches in biomedical named entity recognition, largely due to the development of the GENIA corpus. The typical explorations include Kazama et al 2002, Lee et al 2003, Tsuruoka et al 2003, Shen et al 2003. Kazama et al 2002 applies SVM and incorporates a rich feature set, including word feature, POS, prefix feature, suffix feature, previous class feature, word cache feature and HMM state feature. The experiment on GENIA V1.1 shows the F-measure of 54.4. Tsuruoka et al 2003 applies a dictionary-based approach and a n</context>
</contexts>
<marker>Proux, Rechenmann, Julliard, Pillet, Jacq, 1998</marker>
<rawString>Proux D., Rechenmann F., Julliard L., Pillet V. and Jacq B. 1998. Detecting Gene Symbols and Names in Biological Texts: A First Step toward Pertinent Information Extraction. In Proc. of Genome Inform Ser Workshop Genome Inform, 72-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A S Schwartz</author>
<author>M A Hearst</author>
</authors>
<title>A Simple Algorithm for Identifying Abbreviation Definitions in Biomedical Text.</title>
<date>2003</date>
<booktitle>In Proc. of the Pacific Symposium on Biocomputing (PSB 2003) Kauai.</booktitle>
<marker>Schwartz, Hearst, 2003</marker>
<rawString>Schwartz A.S. and Hearst M.A. 2003. A Simple Algorithm for Identifying Abbreviation Definitions in Biomedical Text. In Proc. of the Pacific Symposium on Biocomputing (PSB 2003) Kauai.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shen Dan</author>
<author>Zhang Jie</author>
<author>Zhou GuoDong</author>
<author>Su Jian</author>
<author>Tan Chew Lim</author>
</authors>
<title>Effective Adaptation of a Hidden Markov Model-based Named Entity Recognizer for Biomedical Domain,</title>
<date>2003</date>
<booktitle>Proceedings of ACL’2003 Workshop on Natural Language Processing in Biomedicine,</booktitle>
<pages>49--56</pages>
<location>Sapporo,</location>
<marker>Dan, Jie, GuoDong, Jian, Lim, 2003</marker>
<rawString>Shen Dan, Zhang Jie, Zhou GuoDong, Su Jian and Tan Chew Lim, Effective Adaptation of a Hidden Markov Model-based Named Entity Recognizer for Biomedical Domain, Proceedings of ACL’2003 Workshop on Natural Language Processing in Biomedicine, Sapporo, Japan, 11 July 2003. pp49-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>J Tsujii</author>
</authors>
<title>Boosting precision and recall of dictionary-based protein name recognition.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL’2003 Workshop on Natural Language Processing in Biomedicine.</booktitle>
<pages>41--48</pages>
<location>Sapporo, Japan.</location>
<marker>Tsuruoka, Tsujii, 2003</marker>
<rawString>Tsuruoka Y. and Tsujii J. 2003. Boosting precision and recall of dictionary-based protein name recognition. In Proceedings of the ACL’2003 Workshop on Natural Language Processing in Biomedicine. pp.41-48. Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag.</publisher>
<location>NY, USA:</location>
<contexts>
<context position="9821" citStr="Vapnik (1995)" startWordPosition="1682" endWordPosition="1683">tput sequence O and independent on other tags n 1 in the tag sequence S . This assumption is n 1 reasonable because the dependence among the tags in the tag sequence S has already been captured n 1 by the first term in Equation (1). Applying the assumption (2) to Equation (1), we have: n logP(Sl Oi) = logP(Sl) | −∑logP(si information sources is exponential. In this paper, a Support Vector Machine (SVM) plus sigmoid is proposed to resolve this problem in our system. 3.2 Support Vector Machine plus Sigmoid Support Vector Machines (SVMs) are a popular machine learning approach first presented by Vapnik (1995). Based on the structural risk minimization of statistical learning theory, SVMs seek an optimal separating hyper-plane to divide decisions based on support vectors which are calibrated value that is not probability. That is, the unthresholded output of an SVM can be represented as f ( x ) a i y i k ( x i , x ) b = ∑ ⋅ ⋅ + (4) i SV ∈ ) (1) (2) ) n i = 1 (3) train an additional sigmoid model(Platt 1999): 1 p(si |fi) =1 + exp(Afi + B) (5) + logP(si |On) 1 ∑ i = 1 • The third term corresponds to the component (dictionary) of the tagger. The idea behind the model is that it tries to assign each ou</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vapnik V. 1995. The Nature of Statistical Learning Theory. NY, USA: Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Viterbi</author>
</authors>
<title>Error bounds for convolutional codes and an asymptotically optimum decoding algorithm.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<pages>260--269</pages>
<contexts>
<context position="10791" citStr="Viterbi 1967" startWordPosition="1872" endWordPosition="1873">3) train an additional sigmoid model(Platt 1999): 1 p(si |fi) =1 + exp(Afi + B) (5) + logP(si |On) 1 ∑ i = 1 • The third term corresponds to the component (dictionary) of the tagger. The idea behind the model is that it tries to assign each output an appropriate tag (state), which contains boundary and class information. For example, 1 binds stronger than NF kB to TCEd The tag assigned to token should indicate that it is at the beginning of an entity name and it belongs to the and the tag assigned to token should indicate that it does not belong to an entity name. Here, the Viterbi algorithm (Viterbi 1967) is implemented to find the most likely tag sequence. The problem with the above HMM lies in the data sparseness problem raised by “lexical” “TCF DNA”. “TCF” “Protein” class; “binds” P ( |1 ) si O n in the third term of Equation (3). Ideally, we would have sufficient training data for every event whose conditional probability we wish to calculate. Unfortunately, there is rarely enough training data to compute accurate probabilities when decoding on new data. Generally, two smoothing approaches (Chen et al 1996) are applied to resolve this problem: linear interpolation and back-off. However, th</context>
</contexts>
<marker>Viterbi, 1967</marker>
<rawString>Viterbi A.J. 1967. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE Transactions on Information Theory, 260-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Zhou</author>
<author>J Su</author>
</authors>
<title>Named Entity Recognition using an HMM-based Chunk Tagger.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Meeting of the</booktitle>
<marker>Zhou, Su, 2002</marker>
<rawString>Zhou G.D. and Su J. 2002. Named Entity Recognition using an HMM-based Chunk Tagger. In Proc. of the 40th Annual Meeting of the</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>