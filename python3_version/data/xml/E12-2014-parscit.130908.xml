<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.103006">
<title confidence="0.998952">
A Support Platform for Event Detection using Social Intelligence
</title>
<author confidence="0.9947765">
Timothy Baldwin, Paul Cook, Bo Han, Aaron Harwood,
Shanika Karunasekera and Masud Moshtaghi
</author>
<affiliation confidence="0.884391">
Department of Computing and Information Systems
The University of Melbourne
Victoria 3010, Australia
</affiliation>
<sectionHeader confidence="0.967467" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997724">
This paper describes a system designed
to support event detection over Twitter.
The system operates by querying the data
stream with a user-specified set of key-
words, filtering out non-English messages,
and probabilistically geolocating each mes-
sage. The user can dynamically set a proba-
bility threshold over the geolocation predic-
tions, and also the time interval to present
data for.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999912625">
Social media and micro-blogs have entered the
mainstream of society as a means for individu-
als to stay in touch with friends, for companies
to market products and services, and for agen-
cies to make official announcements. The attrac-
tions of social media include their reach (either
targeted within a social network or broadly across
a large user base), ability to selectively pub-
lish/filter information (selecting to publish cer-
tain information publicly or privately to certain
groups, and selecting which users to follow),
and real-time nature (information “push” happens
immediately at a scale unachievable with, e.g.,
email). The serendipitous takeoff in mobile de-
vices and widespread support for social media
across a range of devices, have been significant
contributors to the popularity and utility of social
media.
While much of the content on micro-blogs de-
scribes personal trivialities, there is also a vein of
high-value content ripe for mining. As such, or-
ganisations are increasingly targeting micro-blogs
for monitoring purposes, whether it is to gauge
product acceptance, detect events such as traffic
jams, or track complex unfolding events such as
natural disasters.
In this work, we present a system intended
to support real-time analysis and geolocation of
events based on Twitter. Our system consists of
the following steps: (1) user selection of key-
words for querying Twitter; (2) preprocessing of
the returned queries to rapidly filter out messages
not in a pre-selected set of languages, and option-
ally normalise language content; (3) probabilistic
geolocation of messages; and (4) rendering of the
data on a zoomable map via a purpose-built web
interface, with facility for rich user interaction.
Our starting in the development of this system
was the Ushahidi platform,1 which has high up-
take for social media surveillance and information
dissemination purposes across a range of organ-
isations. The reason for us choosing to imple-
ment our own platform was: (a) ease of integra-
tion of back-end processing modules; (b) extensi-
bility, e.g. to visualise probabilities of geolocation
predictions, and allow for dynamic thresholding;
(c) code maintainability; and (d) greater logging
facility, to better capture user interactions.
</bodyText>
<sectionHeader confidence="0.924122" genericHeader="method">
2 Example System Usage
</sectionHeader>
<bodyText confidence="0.999816454545455">
A typical user session begins with the user spec-
ifying a disjunctive set of keywords, which are
used as the basis for a query to the Twitter
Streaming API.2 Messages which match the query
are dynamically rendered on an OpenStreetMap
mash-up, indexed based on (grid cell-based) loca-
tion. When the user clicks on a location marker,
they are presented with a pop-up list of messages
matching the location. The user can manipulate a
time slider to alter the time period over which to
present results (e.g. in the last 10 minutes, or over
</bodyText>
<footnote confidence="0.995030666666667">
1http://ushahidi.com/
2https://dev.twitter.com/docs/
streaming-api
</footnote>
<page confidence="0.982282">
69
</page>
<note confidence="0.930375">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 69–72,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999871">
Figure 1: A screenshot of the system, with a pop-up presentation of the messages at the indicated location.
</figureCaption>
<bodyText confidence="0.999871285714286">
the last hour), to gain a better sense of report re-
cency. The user can further adjust the threshold of
the prediction accuracy for the probabilistic mes-
sage locations to view a smaller number of mes-
sages with higher-confidence locations, or more
messages that have lower-confidence locations.
A screenshot of the system for the following
query is presented in Figure 1:
study studying exam “end of semester”
examination test tests school exams uni-
versity pass fail “end of term” snow
snowy snowdrift storm blizzard flurry
flurries ice icy cold chilly freeze freez-
ing frigid winter
</bodyText>
<sectionHeader confidence="0.985905" genericHeader="method">
3 System Details
</sectionHeader>
<bodyText confidence="0.999923714285714">
The system is composed of a front-end, which
provides a GUI interface for query parameter in-
put, and a back-end, which computes a result for
each query. The front-end submits the query pa-
rameters to the back-end via a servlet. Since
the result for the query is time-dependent, the
back-end regularly re-evaluates the query, gener-
ating an up-to-date result at regular intervals. The
front-end regularly polls the back-end, via another
servlet, for the latest results that match its submit-
ted query. In this way, the front-end and back-end
are loosely coupled and asynchronous.
Below, we describe details of the various mod-
ules of the system.
</bodyText>
<subsectionHeader confidence="0.998616">
3.1 Twitter Querying
</subsectionHeader>
<bodyText confidence="0.99995">
When the user inputs a set of keywords, this is is-
sued as a disjunctive query to the Twitter Stream-
ing API, which returns a streamed set of results
in JSON format. The results are parsed, and
piped through to the language filtering, lexical
normalisation, and geolocation modules, and fi-
nally stored in a flat file, which the GUI interacts
with.
</bodyText>
<subsectionHeader confidence="0.999879">
3.2 Language Filtering
</subsectionHeader>
<bodyText confidence="0.999953411764706">
For language identification, we use langid.py,
a language identification toolkit developed at
The University of Melbourne (Lui and Baldwin,
2011).3 langid.py combines a naive Bayes
classifier with cross-domain feature selection to
provide domain-independent language identifica-
tion. It is available under a FOSS license as
a stand-alone module pre-trained over 97 lan-
guages. langid.py has been developed specif-
ically to be able to keep pace with the speed
of messages through the Twitter “garden hose”
feed on a single-CPU machine, making it par-
ticularly attractive for this project. Additionally,
in an in-house evaluation over three separate cor-
pora of Twitter data, we have found langid.py
to be overall more accurate than other state-of-
the-art language identification systems such as
</bodyText>
<footnote confidence="0.990096">
3http://www.csse.unimelb.edu.au/
research/lt/resources/langid
</footnote>
<page confidence="0.996777">
70
</page>
<bodyText confidence="0.9983268">
lang-detect4 and the Compact Language De-
tector (CLD) from the Chrome browser.5
langid.py returns a monolingual prediction
of the language content of a given message, and is
used to filter out all non-English tweets.
</bodyText>
<subsectionHeader confidence="0.998235">
3.3 Lexical Normalisation
</subsectionHeader>
<bodyText confidence="0.999756258064516">
The prevalence of noisy tokens in microblogs
(e.g. yr “your” and soooo “so”) potentially hin-
ders the readability of messages. Approaches
to lexical normalisation—i.e., replacing noisy to-
kens by their standard forms in messages (e.g.
replacing yr with your)—could potentially over-
come this problem. At present, lexical normali-
sation is an optional plug-in for post-processing
messages.
A further issue related to noisy tokens is that
it is possible that a relevant tweet might contain
a variant of a query term, but not that query term
itself. In future versions of the system we there-
fore aim to use query expansion to generate noisy
versions of query terms to retrieve additional rel-
evant tweets. We subsequently intend to perform
lexical normalisation to evaluate the precision of
the returned data.
The present lexical normalisation used by our
system is the dictionary lookup method of Han
and Baldwin (2011) which normalises noisy to-
kens only when the normalised form is known
with high confidence (e.g. you for u). Ultimately,
however, we are interested in performing context-
sensitive lexical normalisation, based on a reim-
plementation of the method of Han and Baldwin
(2011). This method will allow us to target a
wider variety of noisy tokens such as typos (e.g.
earthquak “earthquake”), abbreviations (e.g. lv
“love”), phonetic substitutions (e.g. b4 “before”)
and vowel lengthening (e.g. goooood “good”).
</bodyText>
<subsectionHeader confidence="0.948011">
3.4 Geolocation
</subsectionHeader>
<bodyText confidence="0.999957285714286">
A vital component of event detection is the de-
termination of where the event is happening, e.g.
to make sense of reports of traffic jams or floods.
While Twitter supports device-based geotagging
of messages, less than 1% of messages have geo-
tags (Cheng et al., 2010). One alternative is to re-
turn the user-level registered location as the event
</bodyText>
<footnote confidence="0.97768625">
4http://code.google.com/p/
language-detection/
5http://code.google.com/p/
chromium-compact-language-detector/
</footnote>
<bodyText confidence="0.999821264705882">
location, based on the assumption that most users
report on events in their local domicile. However,
only about one quarter of users have registered lo-
cations (Cheng et al., 2010), and even when there
is a registered location, there’s no guarantee of
its quality. A better solution would appear to be
the automatic prediction of the geolocation of the
message, along with a probabilistic indication of
the prediction quality.6
Geolocation prediction is based on the terms
used in a given message, based on the assumption
that it will contain explicit mentions of local place
names (e.g. London) or use locally-identifiable
language (e.g. jawn, which is characteristic of the
Philadelphia area). By including a probability
with the prediction, we can give the system user
control over what level of noise they are prepared
to see in the predictions, and hopefully filter out
messages where there is insufficient or conflicting
geolocating evidence.
We formulate the geolocation prediction prob-
lem as a multinomial naive Bayes classification
problem, based on its speed and accuracy over the
task. Given a message m, the task is to output the
most probable location locma, E {loci}&apos; for m.
User-level classification can be performed based
on a similar formulation, by combining the total
set of messages from a given user into a single
combined message.
Given a message m, the task is to find
arg maxi P(loci|m) where each loci is a grid cell
on the map. Based on Bayes’ theorem and stan-
dard assumptions in the naive Bayes formulation,
this is transformed into:
</bodyText>
<equation confidence="0.800479">
P(wj|loci)
</equation>
<bodyText confidence="0.970014076923077">
To avoid zero probabilities, we only consider to-
kens that occur at least twice in the training data,
and ignore unseen words. A probability is calcu-
lated for the most-probable location by normalis-
ing over the scores for each loci.
We employ the method of Ritter et al. (2011) to
tokenise messages, and use token unigrams as fea-
tures, including any hashtags, but ignoring twitter
mentions, URLs and purely numeric tokens. We
6Alternatively, we could consider a hybrid approach of
user- and message-level geolocation prediction, especially
for users where we have sufficient training data, which we
plan to incorporate into a future version of the system.
</bodyText>
<equation confidence="0.513316">
�v
j
P(loci)
arg max
i
</equation>
<page confidence="0.665571">
71
</page>
<figure confidence="0.99189925">
0.15 0.20 0.25 0.30 0.35 0.40
Prediction Accuracy
10000 20000 30000 40000
Feature Number
</figure>
<figureCaption confidence="0.9234865">
Figure 2: Accuracy of geolocation prediction, for
varying numbers of features based on information gain
</figureCaption>
<bodyText confidence="0.999987666666667">
also experimented with included the named en-
tity predictions of the Ritter et al. (2011) method
into our system, but found that it had no impact
on predictive accuracy. Finally, we apply feature
selection to the data, based on information gain
(Yang and Pedersen, 1997).
To evaluate the geolocation prediction mod-
ule, we use the user-level geolocation dataset
of Cheng et al. (2010), based on the lower 48
states of the USA. The user-level accuracy of our
method over this dataset, for varying numbers of
features based on information gain, can be seen
in Figure 2. Based on these results, we select the
top 36,000 features in the deployed version of the
system.
In the deployed system, the geolocation pre-
diction model is trained over one million geo-
tagged messages collected over a 4 month pe-
riod from July 2011, resolved to 0.1-degree lat-
itude/longitude grid cells (covering the whole
globe, excepting grid locations where there were
less than 8 messages). For any geotagged mes-
sages in the test data, we preserve the geotag and
simply set the probability of the prediction to 1.0.
</bodyText>
<subsectionHeader confidence="0.913803">
3.5 System Interface
</subsectionHeader>
<bodyText confidence="0.999933">
The final output of the various pre-processing
modules is a list of tweets that match the query,
in the form of an 8-tuple as follows:
</bodyText>
<listItem confidence="0.998115142857143">
• the Twitter user ID
• the Twitter message ID
• the geo-coordinates of the message (either
provided with the message, or automatically
predicted)
• the probability of the predicated geolocation
• the text of the tweet
</listItem>
<bodyText confidence="0.999970294117647">
In addition to specifying a set of keywords for
a given session, system users can dynamically se-
lect regions on the map, either via the manual
specification of a bounding box, or zooming the
map in and out. They can additionally change
the time scale to display messages over, specify
the refresh interval and also adjust the threshold
on the geolocation predictions, to not render any
messages which have a predictive probability be-
low the threshold. The size of each place marker
on the map is rendered proportional to the num-
ber of messages at that location, and a square is
superimposed over the box to represent the max-
imum predictive probability for a single message
at that location (to provide user feedback on both
the volume of predictions and the relative confi-
dence of the system at a given location).
</bodyText>
<sectionHeader confidence="0.999107" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999848733333334">
Zhiyuan Cheng, James Caverlee, and Kyumin Lee.
2010. You are where you tweet: a content-based ap-
proach to geo-locating twitter users. In Proceedings
of the 19th ACM international conference on In-
formation and knowledge management, CIKM ’10,
pages 759–768, Toronto, ON, Canada. ACM.
Bo Han and Timothy Baldwin. 2011. Lexical normal-
isation of short text messages: Makn sens a #twit-
ter. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies (ACL HLT 2011),
pages 368–378, Portland, USA.
Marco Lui and Timothy Baldwin. 2011. Cross-
domain feature selection for language identification.
In Proceedings of the 5th International Joint Con-
ference on Natural Language Processing (IJCNLP
2011), pages 553–561, Chiang Mai, Thailand.
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.
2011. Named entity recognition in tweets: An
experimental study. In Proceedings of the 2011
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1524–1534, Edinburgh,
Scotland, UK., July. Association for Computational
Linguistics.
Yiming Yang and Jan O. Pedersen. 1997. A compar-
ative study on feature selection in text categoriza-
tion. In Proceedings of the Fourteenth International
Conference on Machine Learning, ICML ’97, pages
412–420, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
</reference>
<figure confidence="0.998667666666667">
●
● ●
●
● ● ●
●
●
●
●
●
</figure>
<page confidence="0.953275">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.448177">
<title confidence="0.997792">A Support Platform for Event Detection using Social Intelligence</title>
<author confidence="0.997086">Timothy Baldwin</author>
<author confidence="0.997086">Paul Cook</author>
<author confidence="0.997086">Bo Han</author>
<author confidence="0.997086">Aaron</author>
<email confidence="0.466009">Karunasekera</email>
<affiliation confidence="0.998953">Department of Computing and Information The University of</affiliation>
<address confidence="0.991322">Victoria 3010, Australia</address>
<abstract confidence="0.997762727272727">This paper describes a system designed to support event detection over Twitter. The system operates by querying the data stream with a user-specified set of keywords, filtering out non-English messages, and probabilistically geolocating each message. The user can dynamically set a probability threshold over the geolocation predictions, and also the time interval to present data for.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Zhiyuan Cheng</author>
<author>James Caverlee</author>
<author>Kyumin Lee</author>
</authors>
<title>You are where you tweet: a content-based approach to geo-locating twitter users.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM ’10,</booktitle>
<pages>759--768</pages>
<publisher>ACM.</publisher>
<location>Toronto, ON,</location>
<contexts>
<context position="8281" citStr="Cheng et al., 2010" startWordPosition="1288" endWordPosition="1291">extsensitive lexical normalisation, based on a reimplementation of the method of Han and Baldwin (2011). This method will allow us to target a wider variety of noisy tokens such as typos (e.g. earthquak “earthquake”), abbreviations (e.g. lv “love”), phonetic substitutions (e.g. b4 “before”) and vowel lengthening (e.g. goooood “good”). 3.4 Geolocation A vital component of event detection is the determination of where the event is happening, e.g. to make sense of reports of traffic jams or floods. While Twitter supports device-based geotagging of messages, less than 1% of messages have geotags (Cheng et al., 2010). One alternative is to return the user-level registered location as the event 4http://code.google.com/p/ language-detection/ 5http://code.google.com/p/ chromium-compact-language-detector/ location, based on the assumption that most users report on events in their local domicile. However, only about one quarter of users have registered locations (Cheng et al., 2010), and even when there is a registered location, there’s no guarantee of its quality. A better solution would appear to be the automatic prediction of the geolocation of the message, along with a probabilistic indication of the predi</context>
<context position="11296" citStr="Cheng et al. (2010)" startWordPosition="1767" endWordPosition="1770">on of the system. �v j P(loci) arg max i 71 0.15 0.20 0.25 0.30 0.35 0.40 Prediction Accuracy 10000 20000 30000 40000 Feature Number Figure 2: Accuracy of geolocation prediction, for varying numbers of features based on information gain also experimented with included the named entity predictions of the Ritter et al. (2011) method into our system, but found that it had no impact on predictive accuracy. Finally, we apply feature selection to the data, based on information gain (Yang and Pedersen, 1997). To evaluate the geolocation prediction module, we use the user-level geolocation dataset of Cheng et al. (2010), based on the lower 48 states of the USA. The user-level accuracy of our method over this dataset, for varying numbers of features based on information gain, can be seen in Figure 2. Based on these results, we select the top 36,000 features in the deployed version of the system. In the deployed system, the geolocation prediction model is trained over one million geotagged messages collected over a 4 month period from July 2011, resolved to 0.1-degree latitude/longitude grid cells (covering the whole globe, excepting grid locations where there were less than 8 messages). For any geotagged mess</context>
</contexts>
<marker>Cheng, Caverlee, Lee, 2010</marker>
<rawString>Zhiyuan Cheng, James Caverlee, and Kyumin Lee. 2010. You are where you tweet: a content-based approach to geo-locating twitter users. In Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM ’10, pages 759–768, Toronto, ON, Canada. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: Makn sens a #twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011),</booktitle>
<pages>368--378</pages>
<location>Portland, USA.</location>
<contexts>
<context position="7496" citStr="Han and Baldwin (2011)" startWordPosition="1163" endWordPosition="1166">roblem. At present, lexical normalisation is an optional plug-in for post-processing messages. A further issue related to noisy tokens is that it is possible that a relevant tweet might contain a variant of a query term, but not that query term itself. In future versions of the system we therefore aim to use query expansion to generate noisy versions of query terms to retrieve additional relevant tweets. We subsequently intend to perform lexical normalisation to evaluate the precision of the returned data. The present lexical normalisation used by our system is the dictionary lookup method of Han and Baldwin (2011) which normalises noisy tokens only when the normalised form is known with high confidence (e.g. you for u). Ultimately, however, we are interested in performing contextsensitive lexical normalisation, based on a reimplementation of the method of Han and Baldwin (2011). This method will allow us to target a wider variety of noisy tokens such as typos (e.g. earthquak “earthquake”), abbreviations (e.g. lv “love”), phonetic substitutions (e.g. b4 “before”) and vowel lengthening (e.g. goooood “good”). 3.4 Geolocation A vital component of event detection is the determination of where the event is h</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a #twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL HLT 2011), pages 368–378, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>Crossdomain feature selection for language identification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011),</booktitle>
<pages>553--561</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="5634" citStr="Lui and Baldwin, 2011" startWordPosition="879" endWordPosition="882">led and asynchronous. Below, we describe details of the various modules of the system. 3.1 Twitter Querying When the user inputs a set of keywords, this is issued as a disjunctive query to the Twitter Streaming API, which returns a streamed set of results in JSON format. The results are parsed, and piped through to the language filtering, lexical normalisation, and geolocation modules, and finally stored in a flat file, which the GUI interacts with. 3.2 Language Filtering For language identification, we use langid.py, a language identification toolkit developed at The University of Melbourne (Lui and Baldwin, 2011).3 langid.py combines a naive Bayes classifier with cross-domain feature selection to provide domain-independent language identification. It is available under a FOSS license as a stand-alone module pre-trained over 97 languages. langid.py has been developed specifically to be able to keep pace with the speed of messages through the Twitter “garden hose” feed on a single-CPU machine, making it particularly attractive for this project. Additionally, in an in-house evaluation over three separate corpora of Twitter data, we have found langid.py to be overall more accurate than other state-ofthe-a</context>
</contexts>
<marker>Lui, Baldwin, 2011</marker>
<rawString>Marco Lui and Timothy Baldwin. 2011. Crossdomain feature selection for language identification. In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011), pages 553–561, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: An experimental study.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1524--1534</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="10316" citStr="Ritter et al. (2011)" startWordPosition="1611" endWordPosition="1614">rmed based on a similar formulation, by combining the total set of messages from a given user into a single combined message. Given a message m, the task is to find arg maxi P(loci|m) where each loci is a grid cell on the map. Based on Bayes’ theorem and standard assumptions in the naive Bayes formulation, this is transformed into: P(wj|loci) To avoid zero probabilities, we only consider tokens that occur at least twice in the training data, and ignore unseen words. A probability is calculated for the most-probable location by normalising over the scores for each loci. We employ the method of Ritter et al. (2011) to tokenise messages, and use token unigrams as features, including any hashtags, but ignoring twitter mentions, URLs and purely numeric tokens. We 6Alternatively, we could consider a hybrid approach of user- and message-level geolocation prediction, especially for users where we have sufficient training data, which we plan to incorporate into a future version of the system. �v j P(loci) arg max i 71 0.15 0.20 0.25 0.30 0.35 0.40 Prediction Accuracy 10000 20000 30000 40000 Feature Number Figure 2: Accuracy of geolocation prediction, for varying numbers of features based on information gain al</context>
</contexts>
<marker>Ritter, Clark, Mausam, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named entity recognition in tweets: An experimental study. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1524–1534, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Jan O Pedersen</author>
</authors>
<title>A comparative study on feature selection in text categorization.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Machine Learning, ICML ’97,</booktitle>
<pages>412--420</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="11183" citStr="Yang and Pedersen, 1997" startWordPosition="1749" endWordPosition="1752">diction, especially for users where we have sufficient training data, which we plan to incorporate into a future version of the system. �v j P(loci) arg max i 71 0.15 0.20 0.25 0.30 0.35 0.40 Prediction Accuracy 10000 20000 30000 40000 Feature Number Figure 2: Accuracy of geolocation prediction, for varying numbers of features based on information gain also experimented with included the named entity predictions of the Ritter et al. (2011) method into our system, but found that it had no impact on predictive accuracy. Finally, we apply feature selection to the data, based on information gain (Yang and Pedersen, 1997). To evaluate the geolocation prediction module, we use the user-level geolocation dataset of Cheng et al. (2010), based on the lower 48 states of the USA. The user-level accuracy of our method over this dataset, for varying numbers of features based on information gain, can be seen in Figure 2. Based on these results, we select the top 36,000 features in the deployed version of the system. In the deployed system, the geolocation prediction model is trained over one million geotagged messages collected over a 4 month period from July 2011, resolved to 0.1-degree latitude/longitude grid cells (</context>
</contexts>
<marker>Yang, Pedersen, 1997</marker>
<rawString>Yiming Yang and Jan O. Pedersen. 1997. A comparative study on feature selection in text categorization. In Proceedings of the Fourteenth International Conference on Machine Learning, ICML ’97, pages 412–420, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>