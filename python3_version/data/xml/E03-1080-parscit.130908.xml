<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.133753">
<title confidence="0.99529">
Experiments on Candidate Data for Collocation Extraction
</title>
<author confidence="0.983181">
Stefan Evert and Hannah Kermes
</author>
<affiliation confidence="0.831813">
Institut fiir Maschinelle Sprachverarbeitung
Universitat Stuttgart
</affiliation>
<email confidence="0.99129">
{evert,kermes}@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.998549" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999727090909091">
The paper describes ongoing work on
the evaluation of methods for extract-
ing collocation candidates from large
text corpora. Our research is based
on a German treebank corpus used as
gold standard. Results are available
for adjective+noun pairs, which proved
to be a comparatively easy extraction
task. We plan to extend the evalua-
tion to other types of collocations (e.g.,
PP+verb pairs).
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99953">
While a mostly British tradition based on the
ideas of J. R. Firth defines collocations as (sig-
nificantly) frequent combinations of words cooc-
curring within a given text span, applications in
terminology, lexicography, and natural language
processing prefer a more restricted view. Collo-
cations are understood as unpredictable combina-
tions of words in a particular (morpho-)syntactic
relation (adjectives modifying nouns, direct ob-
jects of verbs, or English noun-noun compounds).
The extraction of such collocations from text cor-
pora is usually performed in a three-stage process
(cf. Krenn (2000, 28-32) and references therein):
1. The source corpus is annotated with vary-
ing amounts of linguistic information (rang-
ing from part-of-speech tags to full parse
trees), depending on the tools available. Then
a list of word pairs satisfying the required
(morpho-)syntactic constraints is extracted
(typically based on part-of-speech patterns).
This first candidate list will contain both col-
locational and non-collocational pairs.
</bodyText>
<listItem confidence="0.831063909090909">
2. Linguistic and/or heuristic filters may be ap-
plied to reduce the size of the candidate set.
For instance, certain &amp;quot;generic&amp;quot; adjectives as
well as those derived from verb participles
are rarely found in adj+noun collocations.
3. The remaining candidates are ranked by sta-
tistical measures based on their frequency
&amp;quot;profiles&amp;quot;. Usually, word pairs are consid-
ered likely to be collocations if their cooccur-
rence frequency is much higher than expected
by chance.
</listItem>
<bodyText confidence="0.999745823529412">
Authors typically evaluate the performance of a
single collocation extraction system as a whole
(e.g. Smadj a (1993)). A small number of in-depth
comparative evaluations (mostly Daille (1994)
and Krenn (2000)) concentrate on the quality of
the statistical measures and the corresponding
ranking of the candidates, and to a lesser extent
on the performance of linguistic filters. Although
Evert and Krenn (2001) are aware of the influence
that the first extraction step has on their results,
they fail to give a quantitative evaluation of differ-
ent pre-processing and extraction methods.
Our research aims to fill this gap. Currently, we
are evaluating methods for the extraction of adjec-
tive+noun pairs from German newspaper text. It is
planned to extend our work to other types of collo-
cations, including PP+verb and noun+verb pairs.
</bodyText>
<page confidence="0.999291">
83
</page>
<sectionHeader confidence="0.968939" genericHeader="introduction">
2 Evaluation procedure
</sectionHeader>
<bodyText confidence="0.999735714285714">
With a collocation definition that is not based
purely on observed frequencies, the statistical
ranking of candidates has to be evaluated against
a manually confirmed list of true positives (cf.
Daille (1994) and Krenn (2000)). This methodol-
ogy is of little use for the evaluation of the candi-
date extraction step, though, for several reasons:
</bodyText>
<listItem confidence="0.999587857142857">
• The accuracy of the extraction step influences
the final results in two quite different ways:
(a) by changing the set of candidate types; (b)
by changing their frequency profiles.
• The influence of changes in the frequency
profiles depends crucially on the particular
statistical measure applied in the third stage.
• In many cases, different extraction meth-
ods will produce only minor changes in the
set of candidates, especially when frequency
thresholds are applied. These subtle effects
will be masked by the much greater impact
of the statistical ranking
• Simple extraction methods may find many
</listItem>
<bodyText confidence="0.985592393939394">
spurious candidates which do not satisfy
the required (morpho-)syntactic constraints.
Even though some of those might be true pos-
itives per se (i.e. they are accepted as collo-
cations by a human annotator), they are not a
part of the source corpus and thus should not
be included in the list of candidates.
Hence, it is necessary to evaluate the extraction
step independently, and to find an appropriate def-
inition of the expected goal of the first processing
stage, i.e. what results should ideally be produced.
Clearly, one cannot expect the extraction step
to distinguish collocations from non-collocations
without access to frequency information. The fre-
quency profiles of candidates should accurately re-
port the number of co-occurrences in the source
corpus, and spurious matches should be avoided.
This leads to the following evaluation goal:
Find all instances of word pairs that oc-
cur in a specific (morpho-)syntactic re-
lationship in the source corpus.
As a consequence, our evaluation is based on in-
stances of candidate pairs, i.e. tokens rather than
types. In our terminology, a pair type is a combi-
nation of two words, and the corresponding pair
tokens are the individual occurrences of this word
pair at specific positions in the corpus. Statistical
ranking methods are usually applied to and evalu-
ated on pair types.
The experiments reported here investigate the
extraction of German adjective+noun pairs, where
the noun is the head of a noun phrase (NP) and the
adjective appears as a modifier in the NP.
</bodyText>
<sectionHeader confidence="0.998307" genericHeader="method">
3 A gold standard
</sectionHeader>
<bodyText confidence="0.997622230769231">
It is theoretically easy to obtain a gold standard for
our evaluation, since the purely syntactic relation-
ships that have to be annotated are less ambiguous
than the distinction between collocations and non-
collocational candidates. However, the annotation
of tokens rather than types is a prohibitively labo-
rious task. Fortunately, a German treebank corpus
is available, from which the gold standard data can
be extracted by automatic means. The Negra cor-
pusl (Skut et al., 1998) consists of 355 096 tokens
of German newspaper text with manually cor-
rected part-of-speech tagging, morpho-syntactic
annotations, and parse trees.
We used XSLT stylesheets to extract a reference
list of 19 771 instances of adjective+noun pairs
from a version of the Negra corpus encoded in
the TigerXML format (Mengel and Lezius, 2000).
Unfortunately, the syntactic annotation scheme of
the Negra treebank (Skut et al., 1997), which omits
all projections that are not strictly necessary to de-
termine the constituent structure of a sentence, is
not very well suited for automatic extraction tasks.
So far, we have only been able to extract adjec-
tive+noun pairs. We plan to use the TIGERSearch
tool2 in combination with stylesheets to obtain ref-
erence data for PP+verb and noun+verb pairs.
</bodyText>
<sectionHeader confidence="0.979982" genericHeader="method">
4 Pre-processing and extraction methods
</sectionHeader>
<bodyText confidence="0.999781333333333">
In addition to the hand-corrected part-of-speech
tags in the Negra corpus, we used the IMS Tree-
Tagger (Schmid, 1994) for automatic tagging.
</bodyText>
<footnote confidence="0.999636">
http://www.coli.uni-sb.de/sfb378/negra-corpus/
2http://www.ims.uni-stuttgart.de/projekte/TIGER/
</footnote>
<page confidence="0.998391">
84
</page>
<bodyText confidence="0.999964641025641">
With its standard training corpus, a tagging accu-
racy of 94.82% was achieved. A substantial part
of the errors are due to proper nouns missing from
the tagger lexicon.
In the next step YAC, a recursive symbolic
chunk parser (Kermes and Evert, 2002), was ap-
plied to identify adjective phrases (APs), noun
phrases (NPs), and prepositional phrases (PPs).
An evaluation of YAC against NPs extracted from
the Negra treebank shows a precision of P =
88.78% and a recall of R = 90.80% based on the
hand-corrected tagging. With automatic tagging,
P = 82.33% and R= 86.15% are achieved.
YAC was specifically designed for automatic
extraction: all AP and NP projections are made ex-
plicit and annotated with head lemmas, which sim-
plifies candidate extraction with XSLT stylesheets
tremendously. We created two versions of the
chunk annotations, based on the hand-corrected
and the automatic tagging, respectively.
Finally, we used three common extraction meth-
ods to identify candidate pairs: (a) adjacent adjec-
tives and nouns (based on part-of-speech tagging);
(b) adjectives preceding nouns within a given win-
dow; (c) the lexical heads of APs and NPs in the
chunk annotations, where the AP node is a child
of the NP node.3 In (b), only the adjective nearest
to each noun was used, and no verbs, sentence-
ending punctuation, or nouns were allowed in be-
tween. We arbitrarily chose a window size of 10
tokens for this experiment. Further tests confirmed
that the evaluation results depend only minimally
on the exact size of the extraction window.
We have evaluated all six combinations of pre-
processing and extraction methods. In further ex-
periments, we plan to study the quantitative ef-
fects of linguistic filters (excluding adjectives de-
rived from verb participles and/or proper nouns)
and lemmatisation (wrt. candidate types).
</bodyText>
<sectionHeader confidence="0.989437" genericHeader="method">
5 First results
</sectionHeader>
<bodyText confidence="0.993645930232558">
The reference data extracted from Negra com-
prises 19 771 instances of adjective+noun pairs.
The numbers for automatic extraction range from
17 694 (adjacent pairs based on automatic tag-
ging) to 19 726 (YAC chunks on hand-corrected
3These candidates were extracted from the XML output
format of the chunker with a simple XSLT stylesheet.
tagging). Table 1 lists precision4 and recall5 for
all combinations of pre-processing and extraction
methods. On the hand-corrected tagging, adja-
cent pairs yield the highest precision, but recall is
much better for extraction from windows or YAC
chunks. The 5% error rate of the automatic tag-
ging reduces the extraction accuracy by approxi-
mately the same amount. The chunk-based extrac-
tion is slightly less sensitive to tagging errors and
achieves both best precision and best recall in this
realistic scenario.
Because of the small size of the Negra cor-
pus, the observed cooccurrence frequencies of pair
types rarely differ from the reference values by
more than 1. The few substantial differences
are mostly due to systematic errors in the auto-
matic tagging, e.g. Joe Cocker as a false positive
(Joe is wrongly tagged as an adjective) and Rotes
Kreuz (&amp;quot;Red Cross&amp;quot;) as a false negative (Rote(s) is
wrongly tagged as a noun).
Unsurprisingly — considering the large num-
ber of hapaxes among the candidates — there are
still considerable differences between the auto-
matically extracted sets of pair types and the gold
standard. Our gold standard contains 16 112 dif-
ferent pair types, whereas numbers for automatic
extraction range from 14 782 to 16056. The best
results for YAC chunks on perfect tagging include
660 pair types that are not found in the reference
data, while 716 pair types were missed by the au-
tomatic extraction. These differences are of little
practical importance, though, since they mostly af-
fect low-frequency types for which statistical as-
sociation measures are not reliable. Most appli-
cations will set a frequency threshold to exclude
such types.6
</bodyText>
<sectionHeader confidence="0.995672" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99925475">
The extraction of German adjective+noun pairs
has proven to be a comparatively easy task. De-
pending on tagging quality, almost perfect results
can be obtained. Moreover, even with a straight-
</bodyText>
<footnote confidence="0.91693575">
4precision = proportion of correct pair tokens among the
automatically extracted data
5recall = proportion of pair tokens in the reference data
that were correctly identified by the automatic extraction
</footnote>
<bodyText confidence="0.728266">
°Interestingly, the popular t-score measure (Church and
Hanks, 1990) effectively sets a frequency cut-off threshold
when only the n highest-ranking candidates are extracted.
</bodyText>
<page confidence="0.997517">
85
</page>
<table confidence="0.998694333333333">
candidates perfect tagging TreeTagger tagging
from
precision recall precision recall
adjacent pairs 98.47% 90.58% 94.81% 84.85%
window-based 97.14% 96.74% 93.85% 90.44%
YAC chunks 98.16% 97.94% 95.51% 91.67%
</table>
<tableCaption confidence="0.999478">
Table 1: Results for Adj+N extraction task
</tableCaption>
<bodyText confidence="0.999969785714286">
forward stochastic tagger and naive window-based
extraction precision and recall values above 90%
provide an excellent starting point for statistical
ranking
The considerable differences between the sets
of pair types primarily affect hapaxes and have
little impact on statistical methods for colloca-
tion identification (where hapaxes are rarely found
among the higher-ranking candidates). Likewise,
small changes in the frequency profiles of more
frequent pairs have little impact on the association
scores and the precise ranking of the candidates. It
will be interesting to see how these results trans-
late to more demanding extraction tasks.
</bodyText>
<sectionHeader confidence="0.996726" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996573847826087">
Kenneth W. Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Computational Linguistics, 16(1):22-29.
Beatrice Daille. 1994. Approche mixte pour
l&apos;extraction automatique de terminologie : statis-
tiques lexicales et filtres linguistiques. Ph.D. thesis,
Universite Paris 7.
Stefan Evert and Brigitte Krenn. 2001. Methods for
the qualitative evaluation of lexical association mea-
sures. In Proceedings of the 39th Annual Meeting
of the Association for Computational Linguistics,
Toulouse, France.
Hannah Kermes and Stefan Evert. 2002. YAC — a
recursive chunker for unrestricted german text. In
Manuel Gonzalez Rodriguez and Carmen PazSuarez
Araujo, editors, Proceedings of the Third Interna-
tional Conference on Language Resources and Eval-
uation (LREC), volume V, pages 1805-1812, Las
Palmas, Spain.
Brigitte Krenn. 2000. The Usual Suspects: Data-
Oriented Models for the Identification and Repre-
sentation of Lexical Collocations. DFKI &amp; Univer-
sitiit des Saarlandes, Saarbracken.
Andreas Mengel and Wolfgang Lezius. 2000. An
XML-based representation format for syntactically
annotated corpora. In Proceedings of the Second
International Conference on Language Resources
and Engineering (LREC), volume 1, pages 121-126,
Athens, Greece.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In International Con-
ference on New Methods in Language Processing,
pages 44-49, Manchester, UK.
Wojciech Skut, Brigitte Krenn, Thorsten Brants, and
Hans Uszkoreit. 1997. An annotation scheme for
free word order languages. In Proceedings of the
Fifth Conference on Applied Natural Language Pro-
cessing ANLP-97, Washington, DC.
W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998.
A linguistically interpreted corpus of german news-
paper texts. In Proceedings of the ESSLLI Work-
shop on Recent Advances in Corpus Annotation,
Saarbilicken, Germany.
Frank Smadja. 1993. Retrieving collocations from
text: Xtract. Computational Linguistics, 19(1):143-
177.
</reference>
<page confidence="0.998536">
86
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.859229">
<title confidence="0.99995">Experiments on Candidate Data for Collocation Extraction</title>
<author confidence="0.997959">Stefan Evert</author>
<author confidence="0.997959">Hannah Kermes</author>
<affiliation confidence="0.9967355">Institut fiir Maschinelle Sprachverarbeitung Universitat Stuttgart</affiliation>
<abstract confidence="0.988459083333333">The paper describes ongoing work on the evaluation of methods for extracting collocation candidates from large text corpora. Our research is based on a German treebank corpus used as gold standard. Results are available for adjective+noun pairs, which proved to be a comparatively easy extraction task. We plan to extend the evaluation to other types of collocations (e.g., PP+verb pairs).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--1</pages>
<contexts>
<context position="11300" citStr="Church and Hanks, 1990" startWordPosition="1768" endWordPosition="1771">requency types for which statistical association measures are not reliable. Most applications will set a frequency threshold to exclude such types.6 6 Conclusion The extraction of German adjective+noun pairs has proven to be a comparatively easy task. Depending on tagging quality, almost perfect results can be obtained. Moreover, even with a straight4precision = proportion of correct pair tokens among the automatically extracted data 5recall = proportion of pair tokens in the reference data that were correctly identified by the automatic extraction °Interestingly, the popular t-score measure (Church and Hanks, 1990) effectively sets a frequency cut-off threshold when only the n highest-ranking candidates are extracted. 85 candidates perfect tagging TreeTagger tagging from precision recall precision recall adjacent pairs 98.47% 90.58% 94.81% 84.85% window-based 97.14% 96.74% 93.85% 90.44% YAC chunks 98.16% 97.94% 95.51% 91.67% Table 1: Results for Adj+N extraction task forward stochastic tagger and naive window-based extraction precision and recall values above 90% provide an excellent starting point for statistical ranking The considerable differences between the sets of pair types primarily affect hapax</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
</authors>
<title>Approche mixte pour l&apos;extraction automatique de terminologie : statistiques lexicales et filtres linguistiques.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Universite Paris</institution>
<contexts>
<context position="2285" citStr="Daille (1994)" startWordPosition="332" endWordPosition="333">may be applied to reduce the size of the candidate set. For instance, certain &amp;quot;generic&amp;quot; adjectives as well as those derived from verb participles are rarely found in adj+noun collocations. 3. The remaining candidates are ranked by statistical measures based on their frequency &amp;quot;profiles&amp;quot;. Usually, word pairs are considered likely to be collocations if their cooccurrence frequency is much higher than expected by chance. Authors typically evaluate the performance of a single collocation extraction system as a whole (e.g. Smadj a (1993)). A small number of in-depth comparative evaluations (mostly Daille (1994) and Krenn (2000)) concentrate on the quality of the statistical measures and the corresponding ranking of the candidates, and to a lesser extent on the performance of linguistic filters. Although Evert and Krenn (2001) are aware of the influence that the first extraction step has on their results, they fail to give a quantitative evaluation of different pre-processing and extraction methods. Our research aims to fill this gap. Currently, we are evaluating methods for the extraction of adjective+noun pairs from German newspaper text. It is planned to extend our work to other types of collocati</context>
</contexts>
<marker>Daille, 1994</marker>
<rawString>Beatrice Daille. 1994. Approche mixte pour l&apos;extraction automatique de terminologie : statistiques lexicales et filtres linguistiques. Ph.D. thesis, Universite Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
</authors>
<title>Methods for the qualitative evaluation of lexical association measures.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="2504" citStr="Evert and Krenn (2001)" startWordPosition="364" endWordPosition="367">idates are ranked by statistical measures based on their frequency &amp;quot;profiles&amp;quot;. Usually, word pairs are considered likely to be collocations if their cooccurrence frequency is much higher than expected by chance. Authors typically evaluate the performance of a single collocation extraction system as a whole (e.g. Smadj a (1993)). A small number of in-depth comparative evaluations (mostly Daille (1994) and Krenn (2000)) concentrate on the quality of the statistical measures and the corresponding ranking of the candidates, and to a lesser extent on the performance of linguistic filters. Although Evert and Krenn (2001) are aware of the influence that the first extraction step has on their results, they fail to give a quantitative evaluation of different pre-processing and extraction methods. Our research aims to fill this gap. Currently, we are evaluating methods for the extraction of adjective+noun pairs from German newspaper text. It is planned to extend our work to other types of collocations, including PP+verb and noun+verb pairs. 83 2 Evaluation procedure With a collocation definition that is not based purely on observed frequencies, the statistical ranking of candidates has to be evaluated against a m</context>
</contexts>
<marker>Evert, Krenn, 2001</marker>
<rawString>Stefan Evert and Brigitte Krenn. 2001. Methods for the qualitative evaluation of lexical association measures. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hannah Kermes</author>
<author>Stefan Evert</author>
</authors>
<title>YAC — a recursive chunker for unrestricted german text.</title>
<date>2002</date>
<booktitle>In Manuel Gonzalez Rodriguez and Carmen PazSuarez Araujo, editors, Proceedings of the Third International Conference on Language Resources and Evaluation (LREC), volume V,</booktitle>
<pages>1805--1812</pages>
<location>Las Palmas, Spain.</location>
<contexts>
<context position="7235" citStr="Kermes and Evert, 2002" startWordPosition="1115" endWordPosition="1118">tool2 in combination with stylesheets to obtain reference data for PP+verb and noun+verb pairs. 4 Pre-processing and extraction methods In addition to the hand-corrected part-of-speech tags in the Negra corpus, we used the IMS TreeTagger (Schmid, 1994) for automatic tagging. http://www.coli.uni-sb.de/sfb378/negra-corpus/ 2http://www.ims.uni-stuttgart.de/projekte/TIGER/ 84 With its standard training corpus, a tagging accuracy of 94.82% was achieved. A substantial part of the errors are due to proper nouns missing from the tagger lexicon. In the next step YAC, a recursive symbolic chunk parser (Kermes and Evert, 2002), was applied to identify adjective phrases (APs), noun phrases (NPs), and prepositional phrases (PPs). An evaluation of YAC against NPs extracted from the Negra treebank shows a precision of P = 88.78% and a recall of R = 90.80% based on the hand-corrected tagging. With automatic tagging, P = 82.33% and R= 86.15% are achieved. YAC was specifically designed for automatic extraction: all AP and NP projections are made explicit and annotated with head lemmas, which simplifies candidate extraction with XSLT stylesheets tremendously. We created two versions of the chunk annotations, based on the h</context>
</contexts>
<marker>Kermes, Evert, 2002</marker>
<rawString>Hannah Kermes and Stefan Evert. 2002. YAC — a recursive chunker for unrestricted german text. In Manuel Gonzalez Rodriguez and Carmen PazSuarez Araujo, editors, Proceedings of the Third International Conference on Language Resources and Evaluation (LREC), volume V, pages 1805-1812, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
</authors>
<title>The Usual Suspects: DataOriented Models for the Identification and Representation of Lexical Collocations.</title>
<date>2000</date>
<booktitle>DFKI &amp; Universitiit des Saarlandes, Saarbracken.</booktitle>
<contexts>
<context position="1201" citStr="Krenn (2000" startWordPosition="170" endWordPosition="171">1 Introduction While a mostly British tradition based on the ideas of J. R. Firth defines collocations as (significantly) frequent combinations of words cooccurring within a given text span, applications in terminology, lexicography, and natural language processing prefer a more restricted view. Collocations are understood as unpredictable combinations of words in a particular (morpho-)syntactic relation (adjectives modifying nouns, direct objects of verbs, or English noun-noun compounds). The extraction of such collocations from text corpora is usually performed in a three-stage process (cf. Krenn (2000, 28-32) and references therein): 1. The source corpus is annotated with varying amounts of linguistic information (ranging from part-of-speech tags to full parse trees), depending on the tools available. Then a list of word pairs satisfying the required (morpho-)syntactic constraints is extracted (typically based on part-of-speech patterns). This first candidate list will contain both collocational and non-collocational pairs. 2. Linguistic and/or heuristic filters may be applied to reduce the size of the candidate set. For instance, certain &amp;quot;generic&amp;quot; adjectives as well as those derived from </context>
<context position="3180" citStr="Krenn (2000)" startWordPosition="474" endWordPosition="475">n their results, they fail to give a quantitative evaluation of different pre-processing and extraction methods. Our research aims to fill this gap. Currently, we are evaluating methods for the extraction of adjective+noun pairs from German newspaper text. It is planned to extend our work to other types of collocations, including PP+verb and noun+verb pairs. 83 2 Evaluation procedure With a collocation definition that is not based purely on observed frequencies, the statistical ranking of candidates has to be evaluated against a manually confirmed list of true positives (cf. Daille (1994) and Krenn (2000)). This methodology is of little use for the evaluation of the candidate extraction step, though, for several reasons: • The accuracy of the extraction step influences the final results in two quite different ways: (a) by changing the set of candidate types; (b) by changing their frequency profiles. • The influence of changes in the frequency profiles depends crucially on the particular statistical measure applied in the third stage. • In many cases, different extraction methods will produce only minor changes in the set of candidates, especially when frequency thresholds are applied. These su</context>
</contexts>
<marker>Krenn, 2000</marker>
<rawString>Brigitte Krenn. 2000. The Usual Suspects: DataOriented Models for the Identification and Representation of Lexical Collocations. DFKI &amp; Universitiit des Saarlandes, Saarbracken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Mengel</author>
<author>Wolfgang Lezius</author>
</authors>
<title>An XML-based representation format for syntactically annotated corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second International Conference on Language Resources and Engineering (LREC),</booktitle>
<volume>1</volume>
<pages>121--126</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="6255" citStr="Mengel and Lezius, 2000" startWordPosition="969" endWordPosition="972">cations and noncollocational candidates. However, the annotation of tokens rather than types is a prohibitively laborious task. Fortunately, a German treebank corpus is available, from which the gold standard data can be extracted by automatic means. The Negra corpusl (Skut et al., 1998) consists of 355 096 tokens of German newspaper text with manually corrected part-of-speech tagging, morpho-syntactic annotations, and parse trees. We used XSLT stylesheets to extract a reference list of 19 771 instances of adjective+noun pairs from a version of the Negra corpus encoded in the TigerXML format (Mengel and Lezius, 2000). Unfortunately, the syntactic annotation scheme of the Negra treebank (Skut et al., 1997), which omits all projections that are not strictly necessary to determine the constituent structure of a sentence, is not very well suited for automatic extraction tasks. So far, we have only been able to extract adjective+noun pairs. We plan to use the TIGERSearch tool2 in combination with stylesheets to obtain reference data for PP+verb and noun+verb pairs. 4 Pre-processing and extraction methods In addition to the hand-corrected part-of-speech tags in the Negra corpus, we used the IMS TreeTagger (Schm</context>
</contexts>
<marker>Mengel, Lezius, 2000</marker>
<rawString>Andreas Mengel and Wolfgang Lezius. 2000. An XML-based representation format for syntactically annotated corpora. In Proceedings of the Second International Conference on Language Resources and Engineering (LREC), volume 1, pages 121-126, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="6864" citStr="Schmid, 1994" startWordPosition="1068" endWordPosition="1069">000). Unfortunately, the syntactic annotation scheme of the Negra treebank (Skut et al., 1997), which omits all projections that are not strictly necessary to determine the constituent structure of a sentence, is not very well suited for automatic extraction tasks. So far, we have only been able to extract adjective+noun pairs. We plan to use the TIGERSearch tool2 in combination with stylesheets to obtain reference data for PP+verb and noun+verb pairs. 4 Pre-processing and extraction methods In addition to the hand-corrected part-of-speech tags in the Negra corpus, we used the IMS TreeTagger (Schmid, 1994) for automatic tagging. http://www.coli.uni-sb.de/sfb378/negra-corpus/ 2http://www.ims.uni-stuttgart.de/projekte/TIGER/ 84 With its standard training corpus, a tagging accuracy of 94.82% was achieved. A substantial part of the errors are due to proper nouns missing from the tagger lexicon. In the next step YAC, a recursive symbolic chunk parser (Kermes and Evert, 2002), was applied to identify adjective phrases (APs), noun phrases (NPs), and prepositional phrases (PPs). An evaluation of YAC against NPs extracted from the Negra treebank shows a precision of P = 88.78% and a recall of R = 90.80%</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing, pages 44-49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Skut</author>
<author>Brigitte Krenn</author>
<author>Thorsten Brants</author>
<author>Hans Uszkoreit</author>
</authors>
<title>An annotation scheme for free word order languages.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing ANLP-97,</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="6345" citStr="Skut et al., 1997" startWordPosition="982" endWordPosition="985">a prohibitively laborious task. Fortunately, a German treebank corpus is available, from which the gold standard data can be extracted by automatic means. The Negra corpusl (Skut et al., 1998) consists of 355 096 tokens of German newspaper text with manually corrected part-of-speech tagging, morpho-syntactic annotations, and parse trees. We used XSLT stylesheets to extract a reference list of 19 771 instances of adjective+noun pairs from a version of the Negra corpus encoded in the TigerXML format (Mengel and Lezius, 2000). Unfortunately, the syntactic annotation scheme of the Negra treebank (Skut et al., 1997), which omits all projections that are not strictly necessary to determine the constituent structure of a sentence, is not very well suited for automatic extraction tasks. So far, we have only been able to extract adjective+noun pairs. We plan to use the TIGERSearch tool2 in combination with stylesheets to obtain reference data for PP+verb and noun+verb pairs. 4 Pre-processing and extraction methods In addition to the hand-corrected part-of-speech tags in the Negra corpus, we used the IMS TreeTagger (Schmid, 1994) for automatic tagging. http://www.coli.uni-sb.de/sfb378/negra-corpus/ 2http://ww</context>
</contexts>
<marker>Skut, Krenn, Brants, Uszkoreit, 1997</marker>
<rawString>Wojciech Skut, Brigitte Krenn, Thorsten Brants, and Hans Uszkoreit. 1997. An annotation scheme for free word order languages. In Proceedings of the Fifth Conference on Applied Natural Language Processing ANLP-97, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Skut</author>
<author>T Brants</author>
<author>B Krenn</author>
<author>H Uszkoreit</author>
</authors>
<title>A linguistically interpreted corpus of german newspaper texts.</title>
<date>1998</date>
<booktitle>In Proceedings of the ESSLLI Workshop on Recent Advances in Corpus Annotation,</booktitle>
<location>Saarbilicken, Germany.</location>
<contexts>
<context position="5919" citStr="Skut et al., 1998" startWordPosition="917" endWordPosition="920">djective+noun pairs, where the noun is the head of a noun phrase (NP) and the adjective appears as a modifier in the NP. 3 A gold standard It is theoretically easy to obtain a gold standard for our evaluation, since the purely syntactic relationships that have to be annotated are less ambiguous than the distinction between collocations and noncollocational candidates. However, the annotation of tokens rather than types is a prohibitively laborious task. Fortunately, a German treebank corpus is available, from which the gold standard data can be extracted by automatic means. The Negra corpusl (Skut et al., 1998) consists of 355 096 tokens of German newspaper text with manually corrected part-of-speech tagging, morpho-syntactic annotations, and parse trees. We used XSLT stylesheets to extract a reference list of 19 771 instances of adjective+noun pairs from a version of the Negra corpus encoded in the TigerXML format (Mengel and Lezius, 2000). Unfortunately, the syntactic annotation scheme of the Negra treebank (Skut et al., 1997), which omits all projections that are not strictly necessary to determine the constituent structure of a sentence, is not very well suited for automatic extraction tasks. So</context>
</contexts>
<marker>Skut, Brants, Krenn, Uszkoreit, 1998</marker>
<rawString>W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998. A linguistically interpreted corpus of german newspaper texts. In Proceedings of the ESSLLI Workshop on Recent Advances in Corpus Annotation, Saarbilicken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<booktitle>Xtract. Computational Linguistics,</booktitle>
<pages>19--1</pages>
<marker>Smadja, 1993</marker>
<rawString>Frank Smadja. 1993. Retrieving collocations from text: Xtract. Computational Linguistics, 19(1):143-177.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>