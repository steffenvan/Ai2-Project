<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.035037">
<title confidence="0.998522">
A Probabilistic Modeling Framework for Lexical Entailment
</title>
<author confidence="0.995585">
Eyal Shnarch Jacob Goldberger Ido Dagan
</author>
<affiliation confidence="0.998697">
Computer Science Department School of Engineering Computer Science Department
Bar-Ilan University Bar-Ilan University Bar-Ilan University
</affiliation>
<address confidence="0.806153">
Ramat-Gan, Israel Ramat-Gan, Israel Ramat-Gan, Israel
</address>
<email confidence="0.998573">
shey@cs.biu.ac.il goldbej@eng.biu.ac.il dagan@cs.biu.ac.il
</email>
<sectionHeader confidence="0.995625" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997877857142857">
Recognizing entailment at the lexical level is
an important and commonly-addressed com-
ponent in textual inference. Yet, this task has
been mostly approached by simplified heuris-
tic methods. This paper proposes an initial
probabilistic modeling framework for lexical
entailment, with suitable EM-based parame-
ter estimation. Our model considers promi-
nent entailment factors, including differences
in lexical-resources reliability and the impacts
of transitivity and multiple evidence. Evalu-
ations show that the proposed model outper-
forms most prior systems while pointing at re-
quired future improvements.
</bodyText>
<sectionHeader confidence="0.979022" genericHeader="categories and subject descriptors">
1 Introduction and Background
</sectionHeader>
<bodyText confidence="0.9977496">
Textual Entailment was proposed as a generic
paradigm for applied semantic inference (Dagan et
al., 2006). This task requires deciding whether a tex-
tual statement (termed the hypothesis-H) can be in-
ferred (entailed) from another text (termed the text-
T). Since it was first introduced, the six rounds
of the Recognizing Textual Entailment (RTE) chal-
lenges1, currently organized under NIST, have be-
come a standard benchmark for entailment systems.
These systems tackle their complex task at vari-
ous levels of inference, including logical represen-
tation (Tatu and Moldovan, 2007; MacCartney and
Manning, 2007), semantic analysis (Burchardt et al.,
2007) and syntactic parsing (Bar-Haim et al., 2008;
Wang et al., 2009). Inference at these levels usually
</bodyText>
<footnote confidence="0.88391">
1http://www.nist.gov/tac/2010/RTE/index.html
</footnote>
<bodyText confidence="0.998467264705882">
requires substantial processing and resources (e.g.
parsing) aiming at high performance.
Nevertheless, simple entailment methods, per-
forming at the lexical level, provide strong baselines
which most systems did not outperform (Mirkin
et al., 2009; Majumdar and Bhattacharyya, 2010).
Within complex systems, lexical entailment model-
ing is an important component. Finally, there are
cases in which a full system cannot be used (e.g.
lacking a parser for a targeted language) and one
must resort to the simpler lexical approach.
While lexical entailment methods are widely
used, most of them apply ad hoc heuristics which do
not rely on a principled underlying framework. Typ-
ically, such methods quantify the degree of lexical
coverage of the hypothesis terms by the text’s terms.
Coverage is determined either by a direct match of
identical terms in T and H or by utilizing lexi-
cal semantic resources, such as WordNet (Fellbaum,
1998), that capture lexical entailment relations (de-
noted here as entailment rules). Common heuristics
for quantifying the degree of coverage are setting a
threshold on the percentage coverage of H’s terms
(Majumdar and Bhattacharyya, 2010), counting ab-
solute number of uncovered terms (Clark and Har-
rison, 2010), or applying an Information Retrieval-
style vector space similarity score (MacKinlay and
Baldwin, 2009). Other works (Corley and Mihal-
cea, 2005; Zanzotto and Moschitti, 2006) have ap-
plied a heuristic formula to estimate the similarity
between text fragments based on a similarity func-
tion between their terms.
These heuristics do not capture several important
aspects of entailment, such as varying reliability of
</bodyText>
<page confidence="0.954159">
558
</page>
<note confidence="0.587832">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 558–563,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999620625">
entailment resources and the impact of rule chaining
and multiple evidence on entailment likelihood. An
additional observation from these and other systems
is that their performance improves only moderately
when utilizing lexical resources2.
We believe that the textual entailment field would
benefit from more principled models for various en-
tailment phenomena. Inspired by the earlier steps
in the evolution of Statistical Machine Translation
methods (such as the initial IBM models (Brown et
al., 1993)), we formulate a concrete generative prob-
abilistic modeling framework that captures the basic
aspects of lexical entailment. Parameter estimation
is addressed by an EM-based approach, which en-
ables estimating the hidden lexical-level entailment
parameters from entailment annotations which are
available only at the sentence-level.
While heuristic methods are limited in their abil-
ity to wisely integrate indications for entailment,
probabilistic methods have the advantage of be-
ing extendable and enabling the utilization of well-
founded probabilistic methods such as the EM algo-
rithm.
We compared the performance of several model
variations to previously published results on RTE
data sets, as well as to our own implementation
of typical lexical baselines. Results show that
both the probabilistic model and our percentage-
coverage baseline perform favorably relative to prior
art. These results support the viability of the proba-
bilistic framework while pointing at certain model-
ing aspects that need to be improved.
</bodyText>
<sectionHeader confidence="0.994665" genericHeader="general terms">
2 Probabilistic Model
</sectionHeader>
<bodyText confidence="0.9999159">
Under the lexical entailment scope, our modeling
goal is obtaining a probabilistic score for the like-
lihood that all H’s terms are entailed by T. To that
end, we model prominent aspects of lexical entail-
ment, which were mostly neglected by previous lex-
ical methods: (1) distinguishing different reliabil-
ity levels of lexical resources; (2) allowing transi-
tive chains of rule applications and considering their
length when estimating their validity; and (3) con-
sidering multiple entailments when entailing a term.
</bodyText>
<footnote confidence="0.979553">
2See ablation tests reports in http://aclweb.org/aclwiki/ in-
dex.php?title=RTE Knowledge Resources#Ablation Tests
</footnote>
<figureCaption confidence="0.877456">
Figure 1: The generative process of entailing terms of a hy-
pothesis from a text. Edges represent entailment rules. There
are 3 evidences for the entailment of hi:a rule from Resource,,
another one from Resource3 both suggesting that tj entails it,
and a chain from t, through an intermediate term t&apos;.
</figureCaption>
<subsectionHeader confidence="0.990122">
2.1 Model Description
</subsectionHeader>
<bodyText confidence="0.999555689655172">
For T to entail H it is usually a necessary, but not
sufficient, that every term h E H would be en-
tailed by at least one term t E T (Glickman et al.,
2006). Figure 1 describes the process of entailing
hypothesis terms. The trivial case is when identical
terms, possibly at the stem or lemma level, appear
in T and H (a direct match as t,,, and hm in Fig-
ure 1). Alternatively, we can establish entailment
based on knowledge of entailing lexical-semantic
relations, such as synonyms, hypernyms and mor-
phological derivations, available in lexical resources
(e.g the rule inference —* reasoning from WordNet).
We denote by R(r) the resource which provided the
rule r.
Since entailment is a transitive relation, rules may
compose transitive chains that connect a term t E T
to a term h E H through intermediate terms. For
instance, from the rules infer —* inference and infer-
ence —* reasoning we can deduce the rule infer —*
reasoning (were inference is the intermediate term
as t&apos; in Figure 1).
Multiple chains may connect t to h (as for tj and
hi in Figure 1) or connect several terms in T to h
(as ti and tj are indicating the entailment of hi in
Figure 1), thus providing multiple evidence for h’s
entailment. It is reasonable to expect that if a term t
indeed entails a term h, it is likely to find evidences
for this relation in several resources.
Taking a probabilistic perspective, we assume a
</bodyText>
<figure confidence="0.9805934">
Text:
t1
Resour
Hypothesis:
h
</figure>
<page confidence="0.992007">
559
</page>
<bodyText confidence="0.999978233333333">
parameter BR for each resource R, denoting its re-
liability, i.e. the prior probability that applying a
rule from R corresponds to a valid entailment in-
stance. Direct matches are considered as a special
“resource”, called MATCH, for which BMATCH is ex-
pected to be close to 1.
We now present our probabilistic model. For a
text term t ∈ T to entail a hypothesis term h by a
chain c, denoted by t →−c h, the application of every
r ∈ c must be valid. Note that a rule r in a chain c
connects two terms (its left-hand-side and its right-
hand-side, denoted lhs → rhs). The lhs of the first
rule in c is t ∈ T and the rhs of the last rule in it is
h ∈ H. We denote the event of a valid rule applica-
tion by lhs →−r rhs. Since a-priori a rule r is valid
with probability BR(r), and assuming independence
of all r ∈ c, we obtain Eq. 1 to specify the prob-
ability of the event t →−c h. Next, let Qh) denote
the set of chains which suggest the entailment of h.
The probability that T does not entail h at all (by
any chain), specified in Eq. 2, is the probability that
all these chains are not valid. Finally, the probabil-
ity that T entails all of H, assuming independence
of H’s terms, is the probability that every h ∈ H is
entailed, as given in Eq. 3. Notice that there could
be a term h which is not covered by any available
rule chain. Under this formulation, we assume that
each such h is covered by a single rule coming from
a special “resource” called UNCOVERED (expecting
BUNCOVERED to be relatively small).
</bodyText>
<equation confidence="0.968011333333333">
Y Y
p(t →− c h) = p(lhs →− r rhs) =
r∈c r∈c
</equation>
<bodyText confidence="0.99814225">
(even though we do not have supporting knowledge
for their entailment). Thus, an alternative model is
to group all uncovered terms together and estimate
the overall probability of their joint entailment as a
function of the lexical coverage of the hypothesis.
We denote Hc as the subset of H’s terms which are
covered by some rule chain and Huc as the remain-
ing uncovered part. Eq. 3a then provides a refined
entailment model for H, in which the second term
specifies the probability that Huc is entailed given
that Hc is validly entailed and the corresponding
lengths:
</bodyText>
<equation confidence="0.989386333333333">
p(T→H) = [ Y p(T→h)]·p(T→Huc  ||Hc|,|H|)
h∈H�
(3a)
</equation>
<subsectionHeader confidence="0.9843">
2.2 Parameter Estimation
</subsectionHeader>
<bodyText confidence="0.9999888">
The difficulty in estimating the BR values is that
these are term-level parameters while the RTE-
training entailment annotation is given for the
sentence-level. Therefore, we use EM-based esti-
mation for the hidden parameters (Dempster et al.,
1977). In the E step we use the current BR values
to compute all whcr(T, H) values for each training
pair. whcr(T, H) stands for the posterior probability
that application of the rule r in the chain c for h ∈ H
is valid, given that either T entails H or not accord-
ing to the training annotation (see Eq. 4). Remember
that a rule r provides an entailment relation between
its left-hand-side (lhs) and its right-hand-side (rhs).
Therefore Eq. 4 uses the notation lhs →−r rhs to des-
ignate the application of the rule r (similar to Eq. 1).
</bodyText>
<equation confidence="0.9963022">
BR(r)(1)
p(T --/+ h) = Y [1 − p(t →−c h)] (2)
c∈C(h)
p(T → H) = Y p(T → h) (3)
h∈H
</equation>
<bodyText confidence="0.9997495">
As can be seen, our model indeed distinguishes
varying resource reliability, decreases entailment
probability as rule chains grow and increases it when
entailment of a term is supported by multiple chains.
The above treatment of uncovered terms in H,
as captured in Eq. 3, assumes that their entailment
probability is independent of the rest of the hypoth-
esis. However, when the number of covered hypoth-
esis terms increases the probability that the remain-
ing terms are actually entailed by T increases too
</bodyText>
<equation confidence="0.9854185">
p(lhs →−r rhs|T --/+ H) =
p(T-ssH|lhs —r*rhs)p(lhs�rhs)
p(T-ssH)
(4)
</equation>
<bodyText confidence="0.999617142857143">
After applying Bayes’ rule we get a fraction with
Eq. 3 in its denominator and BR(r) as the second term
of the numerator. The first numerator term is defined
as in Eq. 3 except that for the corresponding rule ap-
plication we substitute BR(r) by 1 (per the condition-
ing event). The probabilistic model defined by Eq.
1-3 is a loop-free directed acyclic graphical model
</bodyText>
<equation confidence="0.867732909090909">
E :
whcr(T, H) =
⎧
⎨⎪⎪⎪⎪⎪⎪⎪
⎪⎪⎪⎪⎪⎪⎪⎩
p(lhs →−r rhs|T → H) = ifT → H
p(T→H|lhs −→rhs)p(lhs
r −→rhs)
r
p(T→H)
if T --/+ H
</equation>
<page confidence="0.962992">
560
</page>
<bodyText confidence="0.99834805">
(aka a Bayesian network). Hence the E-step proba-
bilities can be efficiently calculated using the belief
propagation algorithm (Pearl, 1988).
The M step uses Eq. 5 to update the parameter set.
For each resource R we average the whcr(T, H) val-
ues for all its rule applications in the training, whose
total number is denoted nR.
(5)
For Eq. 3a we need to estimate also p(T→H.c |
|Hc|,|H|). This is done directly via maximum likeli-
hood estimation over the training set, by calculating
the proportion of entailing examples within the set
of all examples of a given hypothesis length (|H|)
and a given number of covered terms (|Hc|). As
|Hc |we take the number of identical terms in T and
H (exact match) since in almost all cases terms in
H which have an exact match in T are indeed en-
tailed. We also tried initializing the EM algorithm
with these direct estimations but did not obtain per-
formance improvements.
</bodyText>
<sectionHeader confidence="0.978763" genericHeader="keywords">
3 Evaluations and Results
</sectionHeader>
<bodyText confidence="0.9994735">
The 5th Recognizing Textual Entailment challenge
(RTE-5) introduced a new search task (Bentivogli
et al., 2009) which became the main task in RTE-
6 (Bentivogli et al., 2010). In this task participants
should find all sentences that entail a given hypothe-
sis in a given document cluster. This task’s data sets
reflect a natural distribution of entailments in a cor-
pus and demonstrate a more realistic scenario than
the previous RTE challenges.
In our system, sentences are tokenized and
stripped of stop words and terms are lemmatized and
tagged for part-of-speech. As lexical resources we
use WordNet (WN) (Fellbaum, 1998), taking as en-
tailment rules synonyms, derivations, hyponyms and
meronyms of the first senses of T and H terms, and
the CatVar (Categorial Variation) database (Habash
and Dorr, 2003). We allow rule chains of length up
to 4 in WordNet (WN4) .
We compare our model to two types of baselines:
(1) RTE published results: the average of the best
runs of all systems, the best and second best per-
forming lexical systems and the best full system of
each challenge; (2) our implementation of lexical
coverage model, tuning the percentage-of-coverage
threshold for entailment on the training set. This
model uses the same configuration as our probabilis-
tic model. We also implemented an Information Re-
trieval style baseline3 (both with and without lex-
ical expansions), but given its poorer performance
we omit its results here.
Table 1 presents the results. We can see that
both our implemented models (probabilistic and
coverage) outperform all RTE lexical baselines on
both data sets, apart from (Majumdar and Bhat-
tacharyya, 2010) which incorporates additional lex-
ical resources, a named entity recognizer and a
co-reference system. On RTE-5, the probabilis-
tic model is comparable in performance to the best
full system, while the coverage model achieves con-
siderably better results. We notice that our imple-
mented models successfully utilize resources to in-
crease performance, as opposed to typical smaller
or less consistent improvements in prior works (see
Section 1).
</bodyText>
<table confidence="0.999748375">
Model F1% RTE-6
RTE-5
avg. of all systems 30.5 33.8
2,d best lexical system 40.31 44.02
best lexical system 44.43 47.64
best full system 45.63 48.05
age no resource 39.5 44.8
co + WN 45.8 45.1
+ CatVar 47.2 45.5
+ WN + CatVar 48.5 44.7
+ WN4 46.3 43.1
listi no resource 41.8 42.1
p + WN 45.0 45.3
+ CatVar 42.0 45.9
+ WN + CatVar 42.8 45.5
+ WN4 45.8 42.6
</table>
<tableCaption confidence="0.95907925">
Table 1: Evaluation results on RTE-5 and RTE-6. RTE systems
are: (1)(MacKinlay and Baldwin, 2009), (2)(Clark and Harri-
son, 2010), (3)(Mirkin et al., 2009)(2 submitted runs), (4)(Ma-
jumdar and Bhattacharyya, 2010) and (5)(Jia et al., 2010).
</tableCaption>
<bodyText confidence="0.987825">
While the probabilistic and coverage models are
comparable on RTE-6 (with non-significant advan-
tage for the former), on RTE-5 the latter performs
</bodyText>
<footnote confidence="0.95849">
3Utilizing Lucene search engine (http://lucene.apache.org)
</footnote>
<equation confidence="0.9784995">
1
M : OR =
nR T,H hEH cEC(h) rEc|R(r)=R
� whcr(T, H)
</equation>
<page confidence="0.973392">
561
</page>
<bodyText confidence="0.995092794117647">
better, suggesting that the probabilistic model needs Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo
to be further improved. In particular, WN4 performs Giampiccolo, and Bernardo Magnini. 2009. The fifth
better than the single-step WN only on RTE-5, sug- PASCAL recognizing textual entailment challenge. In
gesting the need to improve the modeling of chain- Proceedings of Text Analysis Conference (TAC).
ing. The fluctuations over the data sets and impacts Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Trang
of resources suggest the need for further investiga- Dang, and Danilo Giampiccolo. 2010. The sixth
tion over additional data sets and resources. As for PASCAL recognizing textual entailment challenge. In
the coverage model, under our configuration it poses Proceedings of Text Analysis Conference (TAC).
a bigger challenge for RTE systems than perviously Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
reported baselines. It is thus proposed as an easy to Pietra, and Robert L. Mercer. 1993. The mathemat-
implement baseline for future entailment research. ics of statistical machine translation: parameter esti-
4 Conclusions and Future Work mation. Computational Linguistics, 19(2):263–311,
This paper presented, for the first time, a principled June.
and relatively rich probabilistic model for lexical en- Aljoscha Burchardt, Nils Reiter, Stefan Thater, and
tailment, amenable for estimation of hidden lexical- Anette Frank. 2007. A semantic approach to textual
level parameters from standard sentence-level an- entailment: System evaluation and task analysis. In
notations. The positive results of the probabilistic Proceedings of the ACL-PASCAL Workshop on Textual
model compared to prior art and its ability to exploit Entailment and Paraphrasing.
lexical resources indicate its future potential. Yet, Peter Clark and Phil Harrison. 2010. BLUE-Lite: a
further investigation is needed. For example, analyz- knowledge-based lexical entailment system for RTE6.
ing current model’s limitations, we observed that the In Proceedings of Text Analysis Conference (TAC).
multiplicative nature of eqs. 1 and 3 (reflecting inde- Courtney Corley and Rada Mihalcea. 2005. Measur-
pendence assumptions) is too restrictive, resembling ing the semantic similarity of texts. In Proceedings of
a logical AND. Accordingly we plan to explore re- the ACL Workshop on Empirical Modeling of Semantic
laxing this strict conjunctive behavior through mod- Equivalence and Entailment.
els such as noisy-AND (Pearl, 1988). We also in- Ido Dagan, Oren Glickman, and Bernardo Magnini.
tend to explore the contribution of our model, and 2006. The PASCAL recognising textual entailment
particularly its estimated parameter values, within a challenge. In Lecture Notes in Computer Science, vol-
complex system that integrates multiple levels of in- ume 3944, pages 177–190.
ference. A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Acknowledgments Maximum likelihood from incomplete data via the EM
This work was partially supported by the NEGEV algorithm. Journal of the royal statistical society, se-
Consortium of the Israeli Ministry of Industry, ries [B], 39(1):1–38.
Trade and Labor (www.negev-initiative.org), the Christiane Fellbaum, editor. 1998. WordNet: An Elec-
</bodyText>
<reference confidence="0.972044347826087">
PASCAL-2 Network of Excellence of the European tronic Lexical Database (Language, Speech, and Com-
Community FP7-ICT-2007-1-216886, the FIRB- munication). The MIT Press.
Israel research project N. RBIN045PXH and by the Oren Glickman, Eyal Shnarch, and Ido Dagan. 2006.
Israel Science Foundation grant 1112/08. Lexical reference: a semantic matching subtask. In
References Proceedings of the Conference on Empirical Methods
Roy Bar-Haim, Jonathan Berant, Ido Dagan, Iddo Green- in Natural Language Processing, pages 172–179. As-
tal, Shachar Mirkin, Eyal Shnarch, and Idan Szpektor. sociation for Computational Linguistics.
2008. Efficient semantic deduction and approximate Nizar Habash and Bonnie Dorr. 2003. A categorial vari-
matching over compact parse forests. In Proceedings ation database for english. In Proceedings of the North
of Text Analysis Conference (TAC). American Association for Computational Linguistics.
562 Houping Jia, Xiaojiang Huang, Tengfei Ma, Xiaojun
Wan, and Jianguo Xiao. 2010. PKUTM participa-
tion at TAC 2010 RTE and summarization track. In
Proceedings of Text Analysis Conference (TAC).
Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In Proceedings
of the ACL-PASCAL Workshop on Textual Entailment
and Paraphrasing.
Andrew MacKinlay and Timothy Baldwin. 2009. A
baseline approach to the RTE5 search pilot. In Pro-
ceedings of Text Analysis Conference (TAC).
Debarghya Majumdar and Pushpak Bhattacharyya.
2010. Lexical based text entailment system for main
task of RTE6. In Proceedings of Text Analysis Confer-
ence (TAC).
Shachar Mirkin, Roy Bar-Haim, Jonathan Berant, Ido
Dagan, Eyal Shnarch, Asher Stern, and Idan Szpektor.
2009. Addressing discourse and document structure in
the RTE search task. In Proceedings of Text Analysis
Conference (TAC).
Judea Pearl. 1988. Probabilistic reasoning in intelli-
gent systems: networks ofplausible inference. Morgan
Kaufmann.
Marta Tatu and Dan Moldovan. 2007. COGEX at RTE
3. In Proceedings of the ACL-PASCAL Workshop on
Textual Entailment and Paraphrasing.
Rui Wang, Yi Zhang, and Guenter Neumann. 2009. A
joint syntactic-semantic representation for recognizing
textual relatedness. In Proceedings of Text Analysis
Conference (TAC).
Fabio Massimo Zanzotto and Alessandro Moschitti.
2006. Automatic learning of textual entailments with
cross-pair similarities. In Proceedings of the 21st In-
ternational Conference on Computational Linguistics
and 44th Annual Meeting of the Association for Com-
putational Linguistics.
</reference>
<page confidence="0.998932">
563
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959840">
<title confidence="0.99934">A Probabilistic Modeling Framework for Lexical Entailment</title>
<author confidence="0.985473">Eyal Shnarch Jacob Goldberger Ido Dagan</author>
<affiliation confidence="0.999971">Computer Science Department School of Engineering Computer Science Department Bar-Ilan University Bar-Ilan University Bar-Ilan University</affiliation>
<address confidence="0.998215">Ramat-Gan, Israel Ramat-Gan, Israel Ramat-Gan, Israel</address>
<email confidence="0.996482">shey@cs.biu.ac.ilgoldbej@eng.biu.ac.ildagan@cs.biu.ac.il</email>
<abstract confidence="0.998599933333333">Recognizing entailment at the lexical level is an important and commonly-addressed component in textual inference. Yet, this task has been mostly approached by simplified heuristic methods. This paper proposes an initial probabilistic modeling framework for lexical entailment, with suitable EM-based parameter estimation. Our model considers prominent entailment factors, including differences in lexical-resources reliability and the impacts of transitivity and multiple evidence. Evaluations show that the proposed model outperforms most prior systems while pointing at required future improvements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>