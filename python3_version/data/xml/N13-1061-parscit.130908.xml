<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000193">
<title confidence="0.9980065">
Using Derivation Trees for Informative Treebank Inter-Annotator
Agreement Evaluation
</title>
<author confidence="0.769943">
Seth Kulick and Ann Bies and Justin Mott
and Mohamed Maamouri
</author>
<affiliation confidence="0.841614">
Linguistic Data Consortium
University of Pennsylvania
</affiliation>
<email confidence="0.7766505">
{skulick,bies,jmott,maamouri}
@ldc.upenn.edu
</email>
<author confidence="0.827712">
Beatrice Santorini and
Anthony Kroch
</author>
<affiliation confidence="0.9976295">
Department of Linguistics
University of Pennsylvania
</affiliation>
<email confidence="0.7744545">
{beatrice,kroch}
@ling.upenn.edu
</email>
<sectionHeader confidence="0.995581" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998929181818182">
This paper discusses the extension of a sys-
tem developed for automatic discovery of tree-
bank annotation inconsistencies over an entire
corpus to the particular case of evaluation of
inter-annotator agreement. This system makes
for a more informative IAA evaluation than
other systems because it pinpoints the incon-
sistencies and groups them by their structural
types. We evaluate the system on two corpora
- (1) a corpus of English web text, and (2) a
corpus of Modern British English.
</bodyText>
<sectionHeader confidence="0.998979" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999959520833333">
This paper discusses the extension of a system de-
veloped for automatic discovery of treebank annota-
tion inconsistencies over an entire corpus to the par-
ticular case of evaluation of inter-annotator agree-
ment (IAA). In IAA, two or more annotators anno-
tate the same sentences, and a comparison identi-
fies areas in which the annotators might need more
training, or the annotation guidelines some refine-
ment. Unlike other IAA evaluation systems, this
system application results in a precise pinpointing of
inconsistencies and the grouping of inconsistencies
by their structural types, making for a more infor-
mative IAA evaluation.
Treebank annotation, consisting of syntactic
structure with words as the terminals, is by its na-
ture more complex and therefore more prone to error
than many other annotation tasks. However, high an-
notation consistency is crucial to providing reliable
training and testing data for parsers and linguistic
research. Error detection is therefore an important
area of research, and the importance of work such as
Dickinson and Meurers (2003) is that errors and an-
notation inconsistencies might be automatically dis-
covered, and once discovered, be targeted for subse-
quent quality control.
A recent approach to this problem (Kulick et al.,
2011; Kulick et al., 2012) (which we will call the
KBM system) improves upon Dickinson and Meur-
ers (2003) by decomposing the full syntactic tree
into smaller units, using ideas from Tree Adjoining
Grammar (TAG) (Joshi and Schabes, 1997). This al-
lows the comparison to be based on small syntactic
units instead of string n-grams, improving the detec-
tion of inconsistent annotation.
The KBM system, like that of Dickinson and
Meurers (2003) before it, is based on the notion of
comparing identical strings. In the general case, this
is a problematic assumption, since annotation in-
consistencies are missed because of superficial word
differences between strings which one would want
to compare.1 However, this limitation is not present
for IAA evaluation, since the strings to compare are,
by definition, identical.2 The same is also true of
parser evaluation, since the parser output and the
gold standard are based on the same sentences.
We therefore take the logical step of applying the
KBM system developed for automatic discovery of
annotation inconsistency to the special case of IAA.3
</bodyText>
<footnote confidence="0.999478857142857">
1Boyd et al. (2007) and other current work tackles this prob-
lem. However, that is not the focus of this paper.
2Aside from possible tokenization differences by annotators.
3In this paper, we do not yet apply the system to parser eval-
uation, although it is conceptually the same problem as IAA
evaluation. We wanted to first refine the system using annota-
tor input for the IAA application before applying it to parser
</footnote>
<page confidence="0.972998">
550
</page>
<figure confidence="0.972136369863013">
Proceedings of NAACL-HLT 2013, pages 550–555,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
a2
(1) a. NP-SBJ (2) a.
NP NP
Rinascimento
in NP
NP
The word
NP
PP
-RRB-
renaissance
-LRB- NP
The
NP
word
a3
M
M
a5
NP
NP
M
renaissance
a4
M Rinascimento a6 M
PP
a8
-LRB- -RRB-
in
A
A
a1
NP a7
b.
b3
NP
Italian
renaissance
b5
A
PRN
b1
A
A
b2
FRAG
The
word
b4 A A b8
NP
A
-RRB-
-LRB-
b6
PP
Rinascimento
b7
in
A
NP
Italian
b. NP-SBJ
The word renaissance PRN
-LRB- FRAG
-RRB-
Italian
NP
Rinascimento
PP
in NP
Italian
</figure>
<figureCaption confidence="0.999989">
Figure 1: Two example trees showing a difference in IAA
</figureCaption>
<bodyText confidence="0.999984684210526">
To our knowledge, this work is the first to utilize
such a general system for this special case.
The advantages of the KBM system play out
somewhat differently in the context of IAA evalu-
ation than in the more general case. In this con-
text, the comparison of word sequences based on
syntactic units allows for a precise pinpointing of
differences. The system also retains the ability to
group inconsistencies together by their structural
type, which we have found to be useful for the more
general case. Together, these two properties make
for a useful and informative system for IAA evalua-
tion.
In Section 2 we describe the basic working of our
system. In Section 3 we discuss in more detail the
advantages of this approach. In Section 4 we evalu-
ate the system on two treebanks, a corpus of English
web text and a corpus of Modern British English.
Section 5 discusses future work.
</bodyText>
<sectionHeader confidence="0.953526" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.827317666666667">
The basic idea of the KBM system is to detect word
sequences that are annotated in inconsistent ways by
evaluation.
</bodyText>
<figureCaption confidence="0.9806985">
Figure 2: E-trees and derivation trees corresponding to
(1ab)
</figureCaption>
<bodyText confidence="0.99003772">
comparing local syntactic units. Following Dickin-
son and Meurers (2003), we refer to sequences ex-
amined for inconsistent annotation as nuclei. The
sentence excerpts (1ab) in Figure 1, from the test
corpora used in this work, illustrate an inconsistency
in the annotation of corresponding strings. We fo-
cus here on the difference in the annotation of the
nucleus The word renaissance, which in (1a) is an-
notated as an appositive structure, while in (1b) it is
flat.
Following the TAG approach, KBM decomposes
the full phrase structure into smaller chunks called
elementary trees (henceforth, e-trees). The relation-
ship of the e-trees underlying a full phrase struc-
ture to each other is recorded in a derivation tree,
in which each node is an e-tree, related to its par-
ent node by a composition operation, as shown in
(2ab).4
KBM uses two composition operations, each with
left and right variants, shown in Figure 3: (1) ad-
4The decomposition is based on head-finding heuristics,
with the result here that word is the head of (1a), while renais-
sance is the head of (1b), as reflected in their respective deriva-
tion trees (2a) and (2b). We omit the POS tags in (1ab) and
(2ab) to avoid clutter.
</bodyText>
<page confidence="0.996233">
551
</page>
<figureCaption confidence="0.999635">
Figure 3: Composition operations (left and right)
</figureCaption>
<bodyText confidence="0.9620914">
junction, which attaches one tree to a target node in
another tree by creating a copy of the target node,
and (2) sister adjunction, which attaches one tree as
a sister to a target node in another tree. Each arc in
Figure 2 is labeled by an “M” for adjunction and “A”
for sister-adjunction. 5
The system uses the tree decomposition and re-
sulting derivation tree for the comparison of differ-
ent instances of the same nucleus. The full deriva-
tion tree for a sentence is not used, but rather only
that slice of it having e-trees with words that are in
the nucleus being examined, which we call a deriva-
tion tree fragment. That is, for a given nucleus with
a set of instances, we compare the derivation frag-
ments for each instance.
For example, for the nucleus The word renais-
sance, the derivation tree fragment for the instance
in (1a) consists of the e-trees a1, a2, a3 (and their
arcs) in (2a), and likewise the derivation tree from
the instance in (1b) consists of the e-trees b1, b2, b3
in (2b). These derivation fragments have a differ-
ent structure, and so the two instances of The word
renaissance are recognized as inconsistent.
Two important aspects of the overall system re-
quire mention here: (1) Nuclei are identified by us-
ing sequences that occur as a constituent anywhere
5KBM is based on a variant of Spinal TAG (Shen et al.,
2008), and uses sister adjunction without substitution. Space
prohibits full discussion, but multiple adjunction to a single
node (e.g., a4, a6, a8 to a5 in (2a)) does not create multiple
levels of recursion, while a special specification handles the ex-
tra NP recursion for the apposition with a2, a3, and a5. For
reasons of space, we also leave aside a precise comparison to
Tree Insertion Grammar (Chiang, 2003) and Spinal TAG (Shen
et al., 2008).
in the corpus, even if other instances of the same
sequence are not constituents. Both instances of
The word renaissance are compared, because the
sequence occurs at least once as a constituent. (2)
We partition each comparison of the instances of a
nucleus by the lowest nonterminal in the derivation
tree fragment that covers the sequence. The two in-
stances of The word renaissance are compared be-
cause the lowest nonterminal is an NP in both in-
stances.
</bodyText>
<sectionHeader confidence="0.9436" genericHeader="method">
3 Advantages of this approach
</sectionHeader>
<bodyText confidence="0.966883777777777">
As Kulick et al. (2012) stressed, using derivation
tree fragments allows the comparison to abstract
away from interference by irrelevant modifiers, an
issue with Dickinson and Meurers (2003). However,
in the context of IAA, this advantage of KBM plays
out in a different way, in that it allows for a pre-
cise pinpointing of the inconsistencies. For IAA,
the concern is not whether an inconsistent annota-
tion will be reported, since at some level higher in
the tree every difference will be found, even if the
context is the entire tree. KBM, however, will find
the inconsistencies in a more informative way, for
example reporting just The word renaissance, not
some larger unit. Likewise, it reports Rinascimento
in Italian as an inconsistently annotated sequence.6
A critical desirable property of KBM that carries
over from the more general case is that it allows for
different nuclei to be grouped together in the sys-
tem’s output if they have the same annotation in-
consistency type. As in Kulick et al. (2011), each
nucleus found to be inconsistent is categorized by
an inconsistency type, which is simply the collec-
tion of different derivation tree fragments used for
the comparison of its instances, including POS tags
but not the words. For example, the inconsistency
type of the nucleus The word renaissance in (1ab) is
the pair of derivation tree fragments (a1,a2,a3) and
(b1,b2,b3) from (2ab), with the POS tags. This nu-
6Note however that it does not report -LRB- Rinascimento
in Italian -RRB- which is also a constituent, and so might be
expected to be compared. The lowest nonterminal above this
substring in the two derivation trees in Figure 2 is the NP in a5
and the FRAG in b5, thus exempting them from comparison. It
is exactly this sort of case that motivated the “external check”
discussed in Kulick et al. (2012), which we have not yet imple-
mented for IAA.
</bodyText>
<figure confidence="0.999516541666667">
Left Adjunction
Right Adjunction
Left Sister Adjunction
Right Sister Adjunction
ZP ZP
XP
XP
XP
XP
ZP
XP
XP
ZP
XP
XP
XP
XP
Y
ZP
Y
Y
Y
ZP ZP
ZP
</figure>
<page confidence="0.985433">
552
</page>
<table confidence="0.997986">
Inconsistency type # Found # Accurate
Function tags only 53 53
POS tags only 18 13
Structural 129 122
</table>
<tableCaption confidence="0.999834">
Table 1: Inconsistency types found for system evaluation
</tableCaption>
<bodyText confidence="0.997973333333333">
cleus is then reported together with other nuclei that
use the same derivation fragments. In this case, it
therefore also reports the nucleus The term renais-
sance, which appears elsewhere in the corpus with
the two annotations from the different annotators as
in (3):
</bodyText>
<equation confidence="0.929508">
(3) a. NP
NP
renaissance
</equation>
<bodyText confidence="0.996074444444445">
KBM reports The word renaissance and The term
renaissance together because they are inconsistently
annotated in exactly the same way, in spite of the dif-
ference in words. This grouping together of incon-
sistencies based on structural characteristics of the
inconsistency is critically important for understand-
ing the nature of the annotation inconsistencies.
It is the combination of these two characteristics -
(1) pinpointing of errors and (2) grouping by struc-
ture - that makes the system so useful for IAA. This
is an improvement over alternatives such as using
evalb (Sekine and Collins, 2008) for IAA. No other
system to our knowledge groups inconsistencies by
structural type, as KBM does. The use of the deriva-
tion tree fragments greatly lessens the multiple re-
porting of a single annotation difference, which is
a difficulty for using evalb (Manning and Schuetze,
1999, p. 436) or Dickinson and Meurers (2003).
</bodyText>
<sectionHeader confidence="0.999469" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.998314">
4.1 English web text
</subsectionHeader>
<bodyText confidence="0.999960256410257">
We applied our approach to pre-release subset of
(Bies et al., 2012), dually annotated and used for
annotator training, from which the examples in Sec-
tions 2 and 3 are taken. It is a small section of the
corpus, with 4,270 words dually annotated.
For this work, we also took the further step of
characterizing the inconsistency types themselves,
allowing for an even higher-level view of the incon-
sistencies found. In addition to grouping together
different strings as having the same inconsistent an-
notation, the types can also be grouped together for
comparison at a higher level. For this IAA sample,
we separated the inconsistency types into the three
groups in Table 1, with the derivation tree fragments
differing (1) only on function tags, (2) only on POS
tags7, and (3) on structural differences. We man-
ually examined each inconsistency group to deter-
mine if it was an actual inconsistency found, or a
spurious false positive. As shown in Table 1, the pre-
cision of the reported inconsistencies is very high.
It is in fact even higher than it appears, because
the seven (out of 129) instances incorrectly listed
as structural problems were actually either POS or
function tag inconsistencies, that were discovered
by the system only by a difference in the derivation
tree fragment, and so were categorized as structural
problems instead of POS or function tag inconsis-
tencies. 8
Because of the small size of the corpus, there
are relatively few nuclei grouped into inconsistency
types. The 129 structural inconsistency types in-
clude 130 nuclei, with the only inconsistency type
with more than one nucleus being the type with The
word renaissance and The term renaissance, as dis-
cussed above. There is more grouping together in
the “POS tags only” case (37 nuclei included in
the 18 inconsistency types), and the “function tags
only” case (56 nuclei included in the 53 inconsis-
tency types).
</bodyText>
<subsectionHeader confidence="0.998866">
4.2 Modern British English corpus
</subsectionHeader>
<bodyText confidence="0.99998875">
We also applied our approach to a supplemental sec-
tion (Kroch and Santorini, in preparation) to a cor-
pus of modern British English (Kroch et al., 2010),
part of a series of corpora used for research into lan-
guage change. The annotation style is similar to that
of the Penn Treebank, although with some differ-
ences. In this case, because neither the function tags
nor part-of-speech tags were part of the IAA work,
</bodyText>
<footnote confidence="0.995415833333333">
7As mentioned in footnote 4, although POS tags were left
out of Figure 2 for readability, they are included in the actual e-
trees. This allows POS differences in a similar syntactic context
to be naturally captured within the overall KBM framework.
8A small percentage of inconsistencies are the result of lin-
guistic ambiguities and not an error by one of the annotators.
</footnote>
<figure confidence="0.83407475">
NP
The term
b. NP
The term renaissance
</figure>
<page confidence="0.997846">
553
</page>
<bodyText confidence="0.9987228125">
we do not separate out the inconsistency types, as
done in Section 4.1.
The supplement section consisted of 82,701
words dually annotated. The larger size, as com-
pared with the corpus in Section 4.1, results in some
differences in the system output. Because of the
larger size, there are more substantial cases of dif-
ferent nuclei grouped together as the same inconsis-
tency type than in Section 4.1. The first inconsis-
tency type (sorted by number of nuclei) has 88 nu-
clei, and the second has 37 nuclei. In total, there are
1,532 inconsistency types found, consisting of 2,194
nuclei in total. We manually examined the first 20
inconsistency types (sorted by number of nuclei),
consisting in total of 375 nuclei. All were found to
be true instances of inconsistent annotation.
</bodyText>
<listItem confidence="0.48771075">
(4) a. NP b. NP
the ADJP thing the only true thing
only true
(5) a. NP b. NP
</listItem>
<bodyText confidence="0.912310857142857">
their ADJP argument their only actual argument
only actual
The trees in (4) and (5) show two of the 88 nu-
clei grouped into the first inconsistency type. As
with The word renaissance and The term renais-
sance in the English web corpus, nuclei with similar
(although not identical) words are often grouped into
the same inconsistency type. To repeat the point,
this is not because of any search for similarity of
the words in the nuclei. It arises from the fact that
the nuclei are annotated inconstantly in the same
way. Of course not all nuclei in an inconsistency
type have the same words. Nuclei found in this in-
consistency type include only true and only actual
as shown above, and also nuclei such as new En-
glish, greatest possible, thin square, only necessary.
Taken together, they clearly indicate an issue with
the annotation of multi-word adjective phrases.9
9Note that the inconsistencies discussed throughout this pa-
per are not taken from the the published corpora. These results
are only from internal annotator training files.
</bodyText>
<sectionHeader confidence="0.997959" genericHeader="conclusions">
5 Future work
</sectionHeader>
<bodyText confidence="0.99998547826087">
There are several ways in which we plan to improve
the current approach. As mentioned above, there is
a certain class of inconsistencies which KBM will
not pinpoint precisely, which requires adopting the
“external check” from Kulick et al. (2012). The ab-
straction on inconsistency types described in Sec-
tion 4 can also be taken further. For example, one
might want to examine in particular inconsistency
types that arise from PP attachment or that have to
do with the PRN function tag.
One main area for future work is the application
of this work to parser evaluation as well as IAA. For
this area, there is some connection to the work of
Goldberg and Elhadad (2010) and Dickinson (2010),
which are both concerned with examining depen-
dency structures of more than one edge. The con-
nection is that those works are focused on depen-
dency representations, and ithe KBM system does
phrase structure analysis using a TAG-like deriva-
tion tree, which strongly resembles a dependency
tree (Rambow and Joshi, 1997). There is much in
this area of common concern that is worth examin-
ing further.
</bodyText>
<sectionHeader confidence="0.997476" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999842153846154">
This material is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-11-C-0145.
The content does not necessarily reflect the position
or the policy of the Government, and no official en-
dorsement should be inferred. This applies to the
first four authors. The first, fifth, and sixth authors
were supported in part by National Science Foun-
dation Grant # BCS-114749. We would also like
to thank Colin Warner, Aravind Joshi, Mitch Mar-
cus, and the computational linguistics group at the
University of Pennsylvania for helpful conversations
and feedback.
</bodyText>
<page confidence="0.997827">
554
</page>
<sectionHeader confidence="0.995878" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99992021875">
Ann Bies, Justin Mott, Colin Warner, and Seth Kulick.
2012. English Web Treebank. LDC2012T13. Lin-
guistic Data Consortium.
Adriane Boyd, Markus Dickinson, and Detmar Meurers.
2007. Increasing the recall of corpus annotation er-
ror detection. In Proceedings of the Sixth Workshop
on Treebanks and Linguistic Theories (TLT 2007),
Bergen, Norway.
David Chiang. 2003. Statistical parsing with an auto-
matically extracted Tree Adjoining Grammar. In Data
Oriented Parsing. CSLI.
Markus Dickinson and Detmar Meurers. 2003. Detect-
ing inconsistencies in treebanks. In Proceedings of the
Second Workshop on Treebanks and Linguistic The-
ories (TLT 2003), Sweden. Treebanks and Linguistic
Theories.
Markus Dickinson. 2010. Detecting errors in
automatically-parsed dependency relations. In Pro-
ceedings of the 48th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 729–738,
Uppsala, Sweden, July. Association for Computational
Linguistics.
Yoav Goldberg and Michael Elhadad. 2010. Inspecting
the structural biases of dependency parsing algorithms.
In Proceedings of the Fourteenth Conference on Com-
putational Natural Language Learning, pages 234–
242, Uppsala, Sweden, July. Association for Compu-
tational Linguistics.
A.K. Joshi and Y. Schabes. 1997. Tree-adjoining gram-
mars. In G. Rozenberg and A. Salomaa, editors,
Handbook of Formal Languages, Volume 3: Beyond
Words, pages 69–124. Springer, New York.
Anthony Kroch and Beatrice Santorini. in preparation.
Supplement to the Penn Parsed Corpus of Modern
British English.
Anthony Kroch, Beatrice Santorini, and Ariel Dier-
tani. 2010. Penn Parsed Corpus of Mod-
ern British English. http://www.ling.upenn.edu/hist-
corpora/PPCMBE-RELEASE-1/index.html.
Seth Kulick, Ann Bies, and Justin Mott. 2011. Using
derivation trees for treebank error detection. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies, pages 693–698, Portland, Oregon, USA,
June. Association for Computational Linguistics.
Seth Kulick, Ann Bies, and Justin Mott. 2012. Further
developments in treebank error detection using deriva-
tion trees. In LREC 2012: 8th International Confer-
ence on Language Resources and Evaluation, Istanbul.
Christopher Manning and Hinrich Schuetze. 1999.
Foundations of Statistical Natural Language Process-
ing. MIT Press.
Owen Rambow and Aravind Joshi. 1997. A formal
look at dependency grammars and phrase-structure
grammars, with special consideration of word-order
phenomena. In L. Wanner, editor, Recent Trends
in Meaning-Text Theory, pages 167–190. John Ben-
jamins, Amsterdam and Philadelphia.
Satoshi Sekine and Michael Collins. 2008. Evalb.
http://nlp.cs.nyu.edu/evalb/.
Libin Shen, Lucas Champollion, and Aravind Joshi.
2008. LTAG-spinal and the Treebank: A new re-
source for incremental, dependency and semantic pars-
ing. Language Resources and Evaluation, 42(1):1–19.
</reference>
<page confidence="0.998524">
555
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.481552">
<title confidence="0.9992135">Using Derivation Trees for Informative Treebank Agreement Evaluation</title>
<author confidence="0.995918">Seth Kulick</author>
<author confidence="0.995918">Ann Bies</author>
<author confidence="0.995918">Justin</author>
<affiliation confidence="0.838091">and Mohamed Linguistic Data University of</affiliation>
<email confidence="0.994682">@ldc.upenn.edu</email>
<author confidence="0.9224315">Beatrice Santorini Anthony</author>
<affiliation confidence="0.999205">Department of University of</affiliation>
<email confidence="0.99867">@ling.upenn.edu</email>
<abstract confidence="0.995728083333333">This paper discusses the extension of a system developed for automatic discovery of treebank annotation inconsistencies over an entire corpus to the particular case of evaluation of inter-annotator agreement. This system makes for a more informative IAA evaluation than other systems because it pinpoints the inconsistencies and groups them by their structural types. We evaluate the system on two corpora - (1) a corpus of English web text, and (2) a corpus of Modern British English.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Justin Mott</author>
<author>Colin Warner</author>
<author>Seth Kulick</author>
</authors>
<date>2012</date>
<booktitle>English Web Treebank. LDC2012T13. Linguistic Data Consortium.</booktitle>
<contexts>
<context position="12330" citStr="Bies et al., 2012" startWordPosition="2073" endWordPosition="2076">stics - (1) pinpointing of errors and (2) grouping by structure - that makes the system so useful for IAA. This is an improvement over alternatives such as using evalb (Sekine and Collins, 2008) for IAA. No other system to our knowledge groups inconsistencies by structural type, as KBM does. The use of the derivation tree fragments greatly lessens the multiple reporting of a single annotation difference, which is a difficulty for using evalb (Manning and Schuetze, 1999, p. 436) or Dickinson and Meurers (2003). 4 Evaluation 4.1 English web text We applied our approach to pre-release subset of (Bies et al., 2012), dually annotated and used for annotator training, from which the examples in Sections 2 and 3 are taken. It is a small section of the corpus, with 4,270 words dually annotated. For this work, we also took the further step of characterizing the inconsistency types themselves, allowing for an even higher-level view of the inconsistencies found. In addition to grouping together different strings as having the same inconsistent annotation, the types can also be grouped together for comparison at a higher level. For this IAA sample, we separated the inconsistency types into the three groups in Ta</context>
</contexts>
<marker>Bies, Mott, Warner, Kulick, 2012</marker>
<rawString>Ann Bies, Justin Mott, Colin Warner, and Seth Kulick. 2012. English Web Treebank. LDC2012T13. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adriane Boyd</author>
<author>Markus Dickinson</author>
<author>Detmar Meurers</author>
</authors>
<title>Increasing the recall of corpus annotation error detection.</title>
<date>2007</date>
<booktitle>In Proceedings of the Sixth Workshop on Treebanks and Linguistic Theories (TLT</booktitle>
<location>Bergen, Norway.</location>
<contexts>
<context position="3251" citStr="Boyd et al. (2007)" startWordPosition="495" endWordPosition="498">cal strings. In the general case, this is a problematic assumption, since annotation inconsistencies are missed because of superficial word differences between strings which one would want to compare.1 However, this limitation is not present for IAA evaluation, since the strings to compare are, by definition, identical.2 The same is also true of parser evaluation, since the parser output and the gold standard are based on the same sentences. We therefore take the logical step of applying the KBM system developed for automatic discovery of annotation inconsistency to the special case of IAA.3 1Boyd et al. (2007) and other current work tackles this problem. However, that is not the focus of this paper. 2Aside from possible tokenization differences by annotators. 3In this paper, we do not yet apply the system to parser evaluation, although it is conceptually the same problem as IAA evaluation. We wanted to first refine the system using annotator input for the IAA application before applying it to parser 550 Proceedings of NAACL-HLT 2013, pages 550–555, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics a2 (1) a. NP-SBJ (2) a. NP NP Rinascimento in NP NP The word NP PP -R</context>
</contexts>
<marker>Boyd, Dickinson, Meurers, 2007</marker>
<rawString>Adriane Boyd, Markus Dickinson, and Detmar Meurers. 2007. Increasing the recall of corpus annotation error detection. In Proceedings of the Sixth Workshop on Treebanks and Linguistic Theories (TLT 2007), Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Statistical parsing with an automatically extracted Tree Adjoining Grammar. In Data Oriented Parsing.</title>
<date>2003</date>
<publisher>CSLI.</publisher>
<contexts>
<context position="8313" citStr="Chiang, 2003" startWordPosition="1392" endWordPosition="1393"> important aspects of the overall system require mention here: (1) Nuclei are identified by using sequences that occur as a constituent anywhere 5KBM is based on a variant of Spinal TAG (Shen et al., 2008), and uses sister adjunction without substitution. Space prohibits full discussion, but multiple adjunction to a single node (e.g., a4, a6, a8 to a5 in (2a)) does not create multiple levels of recursion, while a special specification handles the extra NP recursion for the apposition with a2, a3, and a5. For reasons of space, we also leave aside a precise comparison to Tree Insertion Grammar (Chiang, 2003) and Spinal TAG (Shen et al., 2008). in the corpus, even if other instances of the same sequence are not constituents. Both instances of The word renaissance are compared, because the sequence occurs at least once as a constituent. (2) We partition each comparison of the instances of a nucleus by the lowest nonterminal in the derivation tree fragment that covers the sequence. The two instances of The word renaissance are compared because the lowest nonterminal is an NP in both instances. 3 Advantages of this approach As Kulick et al. (2012) stressed, using derivation tree fragments allows the </context>
</contexts>
<marker>Chiang, 2003</marker>
<rawString>David Chiang. 2003. Statistical parsing with an automatically extracted Tree Adjoining Grammar. In Data Oriented Parsing. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dickinson</author>
<author>Detmar Meurers</author>
</authors>
<title>Detecting inconsistencies in treebanks.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second Workshop on Treebanks and Linguistic Theories (TLT</booktitle>
<contexts>
<context position="1944" citStr="Dickinson and Meurers (2003)" startWordPosition="285" endWordPosition="288">ems, this system application results in a precise pinpointing of inconsistencies and the grouping of inconsistencies by their structural types, making for a more informative IAA evaluation. Treebank annotation, consisting of syntactic structure with words as the terminals, is by its nature more complex and therefore more prone to error than many other annotation tasks. However, high annotation consistency is crucial to providing reliable training and testing data for parsers and linguistic research. Error detection is therefore an important area of research, and the importance of work such as Dickinson and Meurers (2003) is that errors and annotation inconsistencies might be automatically discovered, and once discovered, be targeted for subsequent quality control. A recent approach to this problem (Kulick et al., 2011; Kulick et al., 2012) (which we will call the KBM system) improves upon Dickinson and Meurers (2003) by decomposing the full syntactic tree into smaller units, using ideas from Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997). This allows the comparison to be based on small syntactic units instead of string n-grams, improving the detection of inconsistent annotation. The KBM system, like t</context>
<context position="5390" citStr="Dickinson and Meurers (2003)" startWordPosition="879" endWordPosition="883">wo properties make for a useful and informative system for IAA evaluation. In Section 2 we describe the basic working of our system. In Section 3 we discuss in more detail the advantages of this approach. In Section 4 we evaluate the system on two treebanks, a corpus of English web text and a corpus of Modern British English. Section 5 discusses future work. 2 System Overview The basic idea of the KBM system is to detect word sequences that are annotated in inconsistent ways by evaluation. Figure 2: E-trees and derivation trees corresponding to (1ab) comparing local syntactic units. Following Dickinson and Meurers (2003), we refer to sequences examined for inconsistent annotation as nuclei. The sentence excerpts (1ab) in Figure 1, from the test corpora used in this work, illustrate an inconsistency in the annotation of corresponding strings. We focus here on the difference in the annotation of the nucleus The word renaissance, which in (1a) is annotated as an appositive structure, while in (1b) it is flat. Following the TAG approach, KBM decomposes the full phrase structure into smaller chunks called elementary trees (henceforth, e-trees). The relationship of the e-trees underlying a full phrase structure to </context>
<context position="9026" citStr="Dickinson and Meurers (2003)" startWordPosition="1508" endWordPosition="1511">me sequence are not constituents. Both instances of The word renaissance are compared, because the sequence occurs at least once as a constituent. (2) We partition each comparison of the instances of a nucleus by the lowest nonterminal in the derivation tree fragment that covers the sequence. The two instances of The word renaissance are compared because the lowest nonterminal is an NP in both instances. 3 Advantages of this approach As Kulick et al. (2012) stressed, using derivation tree fragments allows the comparison to abstract away from interference by irrelevant modifiers, an issue with Dickinson and Meurers (2003). However, in the context of IAA, this advantage of KBM plays out in a different way, in that it allows for a precise pinpointing of the inconsistencies. For IAA, the concern is not whether an inconsistent annotation will be reported, since at some level higher in the tree every difference will be found, even if the context is the entire tree. KBM, however, will find the inconsistencies in a more informative way, for example reporting just The word renaissance, not some larger unit. Likewise, it reports Rinascimento in Italian as an inconsistently annotated sequence.6 A critical desirable prop</context>
<context position="12226" citStr="Dickinson and Meurers (2003)" startWordPosition="2055" endWordPosition="2058">tant for understanding the nature of the annotation inconsistencies. It is the combination of these two characteristics - (1) pinpointing of errors and (2) grouping by structure - that makes the system so useful for IAA. This is an improvement over alternatives such as using evalb (Sekine and Collins, 2008) for IAA. No other system to our knowledge groups inconsistencies by structural type, as KBM does. The use of the derivation tree fragments greatly lessens the multiple reporting of a single annotation difference, which is a difficulty for using evalb (Manning and Schuetze, 1999, p. 436) or Dickinson and Meurers (2003). 4 Evaluation 4.1 English web text We applied our approach to pre-release subset of (Bies et al., 2012), dually annotated and used for annotator training, from which the examples in Sections 2 and 3 are taken. It is a small section of the corpus, with 4,270 words dually annotated. For this work, we also took the further step of characterizing the inconsistency types themselves, allowing for an even higher-level view of the inconsistencies found. In addition to grouping together different strings as having the same inconsistent annotation, the types can also be grouped together for comparison </context>
</contexts>
<marker>Dickinson, Meurers, 2003</marker>
<rawString>Markus Dickinson and Detmar Meurers. 2003. Detecting inconsistencies in treebanks. In Proceedings of the Second Workshop on Treebanks and Linguistic Theories (TLT 2003), Sweden. Treebanks and Linguistic Theories.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Dickinson</author>
</authors>
<title>Detecting errors in automatically-parsed dependency relations.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>729--738</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="17614" citStr="Dickinson (2010)" startWordPosition="2976" endWordPosition="2977"> As mentioned above, there is a certain class of inconsistencies which KBM will not pinpoint precisely, which requires adopting the “external check” from Kulick et al. (2012). The abstraction on inconsistency types described in Section 4 can also be taken further. For example, one might want to examine in particular inconsistency types that arise from PP attachment or that have to do with the PRN function tag. One main area for future work is the application of this work to parser evaluation as well as IAA. For this area, there is some connection to the work of Goldberg and Elhadad (2010) and Dickinson (2010), which are both concerned with examining dependency structures of more than one edge. The connection is that those works are focused on dependency representations, and ithe KBM system does phrase structure analysis using a TAG-like derivation tree, which strongly resembles a dependency tree (Rambow and Joshi, 1997). There is much in this area of common concern that is worth examining further. Acknowledgments This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-11-C-0145. The content does not necessarily reflect the posit</context>
</contexts>
<marker>Dickinson, 2010</marker>
<rawString>Markus Dickinson. 2010. Detecting errors in automatically-parsed dependency relations. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 729–738, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>Inspecting the structural biases of dependency parsing algorithms.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>234--242</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="17593" citStr="Goldberg and Elhadad (2010)" startWordPosition="2971" endWordPosition="2974">to improve the current approach. As mentioned above, there is a certain class of inconsistencies which KBM will not pinpoint precisely, which requires adopting the “external check” from Kulick et al. (2012). The abstraction on inconsistency types described in Section 4 can also be taken further. For example, one might want to examine in particular inconsistency types that arise from PP attachment or that have to do with the PRN function tag. One main area for future work is the application of this work to parser evaluation as well as IAA. For this area, there is some connection to the work of Goldberg and Elhadad (2010) and Dickinson (2010), which are both concerned with examining dependency structures of more than one edge. The connection is that those works are focused on dependency representations, and ithe KBM system does phrase structure analysis using a TAG-like derivation tree, which strongly resembles a dependency tree (Rambow and Joshi, 1997). There is much in this area of common concern that is worth examining further. Acknowledgments This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-11-C-0145. The content does not necessar</context>
</contexts>
<marker>Goldberg, Elhadad, 2010</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2010. Inspecting the structural biases of dependency parsing algorithms. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 234– 242, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>Y Schabes</author>
</authors>
<title>Tree-adjoining grammars.</title>
<date>1997</date>
<booktitle>Handbook of Formal Languages, Volume 3: Beyond Words,</booktitle>
<pages>69--124</pages>
<editor>In G. Rozenberg and A. Salomaa, editors,</editor>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="2377" citStr="Joshi and Schabes, 1997" startWordPosition="355" endWordPosition="358">able training and testing data for parsers and linguistic research. Error detection is therefore an important area of research, and the importance of work such as Dickinson and Meurers (2003) is that errors and annotation inconsistencies might be automatically discovered, and once discovered, be targeted for subsequent quality control. A recent approach to this problem (Kulick et al., 2011; Kulick et al., 2012) (which we will call the KBM system) improves upon Dickinson and Meurers (2003) by decomposing the full syntactic tree into smaller units, using ideas from Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997). This allows the comparison to be based on small syntactic units instead of string n-grams, improving the detection of inconsistent annotation. The KBM system, like that of Dickinson and Meurers (2003) before it, is based on the notion of comparing identical strings. In the general case, this is a problematic assumption, since annotation inconsistencies are missed because of superficial word differences between strings which one would want to compare.1 However, this limitation is not present for IAA evaluation, since the strings to compare are, by definition, identical.2 The same is also true</context>
</contexts>
<marker>Joshi, Schabes, 1997</marker>
<rawString>A.K. Joshi and Y. Schabes. 1997. Tree-adjoining grammars. In G. Rozenberg and A. Salomaa, editors, Handbook of Formal Languages, Volume 3: Beyond Words, pages 69–124. Springer, New York.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Anthony Kroch</author>
<author>Beatrice Santorini</author>
</authors>
<title>in preparation. Supplement to the Penn Parsed Corpus of Modern British English.</title>
<marker>Kroch, Santorini, </marker>
<rawString>Anthony Kroch and Beatrice Santorini. in preparation. Supplement to the Penn Parsed Corpus of Modern British English.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Kroch</author>
<author>Beatrice Santorini</author>
<author>Ariel Diertani</author>
</authors>
<title>Penn Parsed Corpus of Modern British English.</title>
<date>2010</date>
<note>http://www.ling.upenn.edu/histcorpora/PPCMBE-RELEASE-1/index.html.</note>
<contexts>
<context position="14344" citStr="Kroch et al., 2010" startWordPosition="2409" endWordPosition="2412">ped into inconsistency types. The 129 structural inconsistency types include 130 nuclei, with the only inconsistency type with more than one nucleus being the type with The word renaissance and The term renaissance, as discussed above. There is more grouping together in the “POS tags only” case (37 nuclei included in the 18 inconsistency types), and the “function tags only” case (56 nuclei included in the 53 inconsistency types). 4.2 Modern British English corpus We also applied our approach to a supplemental section (Kroch and Santorini, in preparation) to a corpus of modern British English (Kroch et al., 2010), part of a series of corpora used for research into language change. The annotation style is similar to that of the Penn Treebank, although with some differences. In this case, because neither the function tags nor part-of-speech tags were part of the IAA work, 7As mentioned in footnote 4, although POS tags were left out of Figure 2 for readability, they are included in the actual etrees. This allows POS differences in a similar syntactic context to be naturally captured within the overall KBM framework. 8A small percentage of inconsistencies are the result of linguistic ambiguities and not a</context>
</contexts>
<marker>Kroch, Santorini, Diertani, 2010</marker>
<rawString>Anthony Kroch, Beatrice Santorini, and Ariel Diertani. 2010. Penn Parsed Corpus of Modern British English. http://www.ling.upenn.edu/histcorpora/PPCMBE-RELEASE-1/index.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
<author>Ann Bies</author>
<author>Justin Mott</author>
</authors>
<title>Using derivation trees for treebank error detection.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>693--698</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="2145" citStr="Kulick et al., 2011" startWordPosition="317" endWordPosition="320"> consisting of syntactic structure with words as the terminals, is by its nature more complex and therefore more prone to error than many other annotation tasks. However, high annotation consistency is crucial to providing reliable training and testing data for parsers and linguistic research. Error detection is therefore an important area of research, and the importance of work such as Dickinson and Meurers (2003) is that errors and annotation inconsistencies might be automatically discovered, and once discovered, be targeted for subsequent quality control. A recent approach to this problem (Kulick et al., 2011; Kulick et al., 2012) (which we will call the KBM system) improves upon Dickinson and Meurers (2003) by decomposing the full syntactic tree into smaller units, using ideas from Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997). This allows the comparison to be based on small syntactic units instead of string n-grams, improving the detection of inconsistent annotation. The KBM system, like that of Dickinson and Meurers (2003) before it, is based on the notion of comparing identical strings. In the general case, this is a problematic assumption, since annotation inconsistencies are missed </context>
<context position="9847" citStr="Kulick et al. (2011)" startWordPosition="1649" endWordPosition="1652">tent annotation will be reported, since at some level higher in the tree every difference will be found, even if the context is the entire tree. KBM, however, will find the inconsistencies in a more informative way, for example reporting just The word renaissance, not some larger unit. Likewise, it reports Rinascimento in Italian as an inconsistently annotated sequence.6 A critical desirable property of KBM that carries over from the more general case is that it allows for different nuclei to be grouped together in the system’s output if they have the same annotation inconsistency type. As in Kulick et al. (2011), each nucleus found to be inconsistent is categorized by an inconsistency type, which is simply the collection of different derivation tree fragments used for the comparison of its instances, including POS tags but not the words. For example, the inconsistency type of the nucleus The word renaissance in (1ab) is the pair of derivation tree fragments (a1,a2,a3) and (b1,b2,b3) from (2ab), with the POS tags. This nu6Note however that it does not report -LRB- Rinascimento in Italian -RRB- which is also a constituent, and so might be expected to be compared. The lowest nonterminal above this subst</context>
</contexts>
<marker>Kulick, Bies, Mott, 2011</marker>
<rawString>Seth Kulick, Ann Bies, and Justin Mott. 2011. Using derivation trees for treebank error detection. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 693–698, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
<author>Ann Bies</author>
<author>Justin Mott</author>
</authors>
<title>Further developments in treebank error detection using derivation trees.</title>
<date>2012</date>
<booktitle>In LREC 2012: 8th International Conference on Language Resources and Evaluation,</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="2167" citStr="Kulick et al., 2012" startWordPosition="321" endWordPosition="324">tic structure with words as the terminals, is by its nature more complex and therefore more prone to error than many other annotation tasks. However, high annotation consistency is crucial to providing reliable training and testing data for parsers and linguistic research. Error detection is therefore an important area of research, and the importance of work such as Dickinson and Meurers (2003) is that errors and annotation inconsistencies might be automatically discovered, and once discovered, be targeted for subsequent quality control. A recent approach to this problem (Kulick et al., 2011; Kulick et al., 2012) (which we will call the KBM system) improves upon Dickinson and Meurers (2003) by decomposing the full syntactic tree into smaller units, using ideas from Tree Adjoining Grammar (TAG) (Joshi and Schabes, 1997). This allows the comparison to be based on small syntactic units instead of string n-grams, improving the detection of inconsistent annotation. The KBM system, like that of Dickinson and Meurers (2003) before it, is based on the notion of comparing identical strings. In the general case, this is a problematic assumption, since annotation inconsistencies are missed because of superficial</context>
<context position="8859" citStr="Kulick et al. (2012)" startWordPosition="1485" endWordPosition="1488"> leave aside a precise comparison to Tree Insertion Grammar (Chiang, 2003) and Spinal TAG (Shen et al., 2008). in the corpus, even if other instances of the same sequence are not constituents. Both instances of The word renaissance are compared, because the sequence occurs at least once as a constituent. (2) We partition each comparison of the instances of a nucleus by the lowest nonterminal in the derivation tree fragment that covers the sequence. The two instances of The word renaissance are compared because the lowest nonterminal is an NP in both instances. 3 Advantages of this approach As Kulick et al. (2012) stressed, using derivation tree fragments allows the comparison to abstract away from interference by irrelevant modifiers, an issue with Dickinson and Meurers (2003). However, in the context of IAA, this advantage of KBM plays out in a different way, in that it allows for a precise pinpointing of the inconsistencies. For IAA, the concern is not whether an inconsistent annotation will be reported, since at some level higher in the tree every difference will be found, even if the context is the entire tree. KBM, however, will find the inconsistencies in a more informative way, for example repo</context>
<context position="10666" citStr="Kulick et al. (2012)" startWordPosition="1789" endWordPosition="1792">ing POS tags but not the words. For example, the inconsistency type of the nucleus The word renaissance in (1ab) is the pair of derivation tree fragments (a1,a2,a3) and (b1,b2,b3) from (2ab), with the POS tags. This nu6Note however that it does not report -LRB- Rinascimento in Italian -RRB- which is also a constituent, and so might be expected to be compared. The lowest nonterminal above this substring in the two derivation trees in Figure 2 is the NP in a5 and the FRAG in b5, thus exempting them from comparison. It is exactly this sort of case that motivated the “external check” discussed in Kulick et al. (2012), which we have not yet implemented for IAA. Left Adjunction Right Adjunction Left Sister Adjunction Right Sister Adjunction ZP ZP XP XP XP XP ZP XP XP ZP XP XP XP XP Y ZP Y Y Y ZP ZP ZP 552 Inconsistency type # Found # Accurate Function tags only 53 53 POS tags only 18 13 Structural 129 122 Table 1: Inconsistency types found for system evaluation cleus is then reported together with other nuclei that use the same derivation fragments. In this case, it therefore also reports the nucleus The term renaissance, which appears elsewhere in the corpus with the two annotations from the different anno</context>
<context position="17172" citStr="Kulick et al. (2012)" startWordPosition="2895" endWordPosition="2898">, and also nuclei such as new English, greatest possible, thin square, only necessary. Taken together, they clearly indicate an issue with the annotation of multi-word adjective phrases.9 9Note that the inconsistencies discussed throughout this paper are not taken from the the published corpora. These results are only from internal annotator training files. 5 Future work There are several ways in which we plan to improve the current approach. As mentioned above, there is a certain class of inconsistencies which KBM will not pinpoint precisely, which requires adopting the “external check” from Kulick et al. (2012). The abstraction on inconsistency types described in Section 4 can also be taken further. For example, one might want to examine in particular inconsistency types that arise from PP attachment or that have to do with the PRN function tag. One main area for future work is the application of this work to parser evaluation as well as IAA. For this area, there is some connection to the work of Goldberg and Elhadad (2010) and Dickinson (2010), which are both concerned with examining dependency structures of more than one edge. The connection is that those works are focused on dependency representa</context>
</contexts>
<marker>Kulick, Bies, Mott, 2012</marker>
<rawString>Seth Kulick, Ann Bies, and Justin Mott. 2012. Further developments in treebank error detection using derivation trees. In LREC 2012: 8th International Conference on Language Resources and Evaluation, Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Hinrich Schuetze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="12185" citStr="Manning and Schuetze, 1999" startWordPosition="2048" endWordPosition="2051">f the inconsistency is critically important for understanding the nature of the annotation inconsistencies. It is the combination of these two characteristics - (1) pinpointing of errors and (2) grouping by structure - that makes the system so useful for IAA. This is an improvement over alternatives such as using evalb (Sekine and Collins, 2008) for IAA. No other system to our knowledge groups inconsistencies by structural type, as KBM does. The use of the derivation tree fragments greatly lessens the multiple reporting of a single annotation difference, which is a difficulty for using evalb (Manning and Schuetze, 1999, p. 436) or Dickinson and Meurers (2003). 4 Evaluation 4.1 English web text We applied our approach to pre-release subset of (Bies et al., 2012), dually annotated and used for annotator training, from which the examples in Sections 2 and 3 are taken. It is a small section of the corpus, with 4,270 words dually annotated. For this work, we also took the further step of characterizing the inconsistency types themselves, allowing for an even higher-level view of the inconsistencies found. In addition to grouping together different strings as having the same inconsistent annotation, the types can</context>
</contexts>
<marker>Manning, Schuetze, 1999</marker>
<rawString>Christopher Manning and Hinrich Schuetze. 1999. Foundations of Statistical Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Aravind Joshi</author>
</authors>
<title>A formal look at dependency grammars and phrase-structure grammars, with special consideration of word-order phenomena.</title>
<date>1997</date>
<booktitle>Recent Trends in Meaning-Text Theory,</booktitle>
<pages>167--190</pages>
<editor>In L. Wanner, editor,</editor>
<location>Amsterdam and Philadelphia.</location>
<contexts>
<context position="17931" citStr="Rambow and Joshi, 1997" startWordPosition="3025" endWordPosition="3028">ticular inconsistency types that arise from PP attachment or that have to do with the PRN function tag. One main area for future work is the application of this work to parser evaluation as well as IAA. For this area, there is some connection to the work of Goldberg and Elhadad (2010) and Dickinson (2010), which are both concerned with examining dependency structures of more than one edge. The connection is that those works are focused on dependency representations, and ithe KBM system does phrase structure analysis using a TAG-like derivation tree, which strongly resembles a dependency tree (Rambow and Joshi, 1997). There is much in this area of common concern that is worth examining further. Acknowledgments This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR0011-11-C-0145. The content does not necessarily reflect the position or the policy of the Government, and no official endorsement should be inferred. This applies to the first four authors. The first, fifth, and sixth authors were supported in part by National Science Foundation Grant # BCS-114749. We would also like to thank Colin Warner, Aravind Joshi, Mitch Marcus, and the com</context>
</contexts>
<marker>Rambow, Joshi, 1997</marker>
<rawString>Owen Rambow and Aravind Joshi. 1997. A formal look at dependency grammars and phrase-structure grammars, with special consideration of word-order phenomena. In L. Wanner, editor, Recent Trends in Meaning-Text Theory, pages 167–190. John Benjamins, Amsterdam and Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
<author>Michael Collins</author>
</authors>
<date>2008</date>
<note>Evalb. http://nlp.cs.nyu.edu/evalb/.</note>
<contexts>
<context position="11906" citStr="Sekine and Collins, 2008" startWordPosition="2002" endWordPosition="2005">): (3) a. NP NP renaissance KBM reports The word renaissance and The term renaissance together because they are inconsistently annotated in exactly the same way, in spite of the difference in words. This grouping together of inconsistencies based on structural characteristics of the inconsistency is critically important for understanding the nature of the annotation inconsistencies. It is the combination of these two characteristics - (1) pinpointing of errors and (2) grouping by structure - that makes the system so useful for IAA. This is an improvement over alternatives such as using evalb (Sekine and Collins, 2008) for IAA. No other system to our knowledge groups inconsistencies by structural type, as KBM does. The use of the derivation tree fragments greatly lessens the multiple reporting of a single annotation difference, which is a difficulty for using evalb (Manning and Schuetze, 1999, p. 436) or Dickinson and Meurers (2003). 4 Evaluation 4.1 English web text We applied our approach to pre-release subset of (Bies et al., 2012), dually annotated and used for annotator training, from which the examples in Sections 2 and 3 are taken. It is a small section of the corpus, with 4,270 words dually annotate</context>
</contexts>
<marker>Sekine, Collins, 2008</marker>
<rawString>Satoshi Sekine and Michael Collins. 2008. Evalb. http://nlp.cs.nyu.edu/evalb/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Lucas Champollion</author>
<author>Aravind Joshi</author>
</authors>
<title>LTAG-spinal and the Treebank: A new resource for incremental, dependency and semantic parsing.</title>
<date>2008</date>
<journal>Language Resources and Evaluation,</journal>
<volume>42</volume>
<issue>1</issue>
<contexts>
<context position="7905" citStr="Shen et al., 2008" startWordPosition="1323" endWordPosition="1326">nce. For example, for the nucleus The word renaissance, the derivation tree fragment for the instance in (1a) consists of the e-trees a1, a2, a3 (and their arcs) in (2a), and likewise the derivation tree from the instance in (1b) consists of the e-trees b1, b2, b3 in (2b). These derivation fragments have a different structure, and so the two instances of The word renaissance are recognized as inconsistent. Two important aspects of the overall system require mention here: (1) Nuclei are identified by using sequences that occur as a constituent anywhere 5KBM is based on a variant of Spinal TAG (Shen et al., 2008), and uses sister adjunction without substitution. Space prohibits full discussion, but multiple adjunction to a single node (e.g., a4, a6, a8 to a5 in (2a)) does not create multiple levels of recursion, while a special specification handles the extra NP recursion for the apposition with a2, a3, and a5. For reasons of space, we also leave aside a precise comparison to Tree Insertion Grammar (Chiang, 2003) and Spinal TAG (Shen et al., 2008). in the corpus, even if other instances of the same sequence are not constituents. Both instances of The word renaissance are compared, because the sequence</context>
</contexts>
<marker>Shen, Champollion, Joshi, 2008</marker>
<rawString>Libin Shen, Lucas Champollion, and Aravind Joshi. 2008. LTAG-spinal and the Treebank: A new resource for incremental, dependency and semantic parsing. Language Resources and Evaluation, 42(1):1–19.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>