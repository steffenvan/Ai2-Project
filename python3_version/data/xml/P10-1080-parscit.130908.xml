<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003609">
<title confidence="0.969023">
Letter-Phoneme Alignment: An Exploration
</title>
<author confidence="0.987456">
Sittichai Jiampojamarn and Grzegorz Kondrak
</author>
<affiliation confidence="0.998087">
Department of Computing Science
University of Alberta
</affiliation>
<address confidence="0.916377">
Edmonton, AB, T6G 2E8, Canada
</address>
<email confidence="0.999295">
{sj,kondrak}@cs.ualberta.ca
</email>
<sectionHeader confidence="0.994773" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999567928571429">
Letter-phoneme alignment is usually gen-
erated by a straightforward application of
the EM algorithm. We explore several al-
ternative alignment methods that employ
phonetics, integer programming, and sets
of constraints, and propose a novel ap-
proach of refining the EM alignment by
aggregation of best alignments. We per-
form both intrinsic and extrinsic evalua-
tion of the assortment of methods. We
show that our proposed EM-Aggregation
algorithm leads to the improvement of the
state of the art in letter-to-phoneme con-
version on several different data sets.
</bodyText>
<sectionHeader confidence="0.998425" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967569230769">
Letter-to-phoneme (L2P) conversion (also called
grapheme-to-phoneme conversion) is the task of
predicting the pronunciation of a word given its
orthographic form by converting a sequence of
letters into a sequence of phonemes. The L2P
task plays a crucial role in speech synthesis sys-
tems (Schroeter et al., 2002), and is an important
part of other applications, including spelling cor-
rection (Toutanova and Moore, 2001) and speech-
to-speech machine translation (Engelbrecht and
Schultz, 2005). Many data-driven techniques have
been proposed for letter-to-phoneme conversion
systems, including neural networks (Sejnowski
and Rosenberg, 1987), decision trees (Black et al.,
1998), pronunciation by analogy (Marchand and
Damper, 2000), Hidden Markov Models (Taylor,
2005), and constraint satisfaction (Bosch and Can-
isius, 2006).
Letter-phoneme alignment is an important step
in the L2P task. The training data usually consists
of pairs of letter and phoneme sequences, which
are not aligned. Since there is no explicit infor-
mation indicating the relationships between indi-
vidual letter and phonemes, these must be inferred
by a letter-phoneme alignment algorithm before
a prediction model can be trained. The quality
of the alignment affects the accuracy of L2P con-
version. Letter-phoneme alignment is closely re-
lated to transliteration alignment (Pervouchine et
al., 2009), which involves graphemes representing
different writing scripts. Letter-phoneme align-
ment may also be considered as a task in itself; for
example, in the alignment of speech transcription
with text in spoken corpora.
Most previous L2P approaches induce the align-
ment between letters and phonemes with the ex-
pectation maximization (EM) algorithm. In this
paper, we propose a number of alternative align-
ment methods, and compare them to the EM-
based algorithms using both intrinsic and extrin-
sic evaluations. The intrinsic evaluation is con-
ducted by comparing the generated alignments to
a manually-constructed gold standard. The extrin-
sic evaluation uses two different generation tech-
niques to perform letter-to-phoneme conversion
on several different data sets. We discuss the ad-
vantages and disadvantages of various methods,
and show that better alignments tend to improve
the accuracy of the L2P systems regardless of the
actual technique. In particular, one of our pro-
posed methods advances the state of the art in L2P
conversion. We also examine the relationship be-
tween alignment entropy and alignment quality.
This paper is organized as follows. In Sec-
tion 2, we enumerate the assumptions that the
alignment methods commonly adopt. In Section 3,
we review previous work that employs the EM ap-
proach. In Sections 4, 5 and 6, we describe alter-
native approaches based on phonetics, manually-
constructed constraints, and Integer Programming,
respectively. In Section 7, we propose an algo-
rithm to refine the alignments produced by EM.
Sections 8 and 9 are devoted to the intrinsic and
extrinsic evaluation of various approaches. Sec-
tion 10 concludes the paper.
</bodyText>
<page confidence="0.951116">
780
</page>
<note confidence="0.9694745">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 780–788,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.971352" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999399875">
We define the letter-phoneme alignment task as
the problem of inducing links between units that
are related by pronunciation. Each link is an in-
stance of a specific mapping between letters and
phonemes. The leftmost example alignment of the
word accuse [@kjuz] below includes 1-1, 1-0, 1-
2, and 2-1 links. The letter e is considered to be
linked to special null phoneme.
</bodyText>
<figureCaption confidence="0.996094">
Figure 1: Two alignments of accuse.
</figureCaption>
<bodyText confidence="0.9881505">
The following constraints on links are assumed
by some or all alignment models:
</bodyText>
<listItem confidence="0.945225">
• the monotonicity constraint prevents links
from crossing each other;
• the representation constraint requires each
phoneme to be linked to at least one letter,
thus precluding nulls on the letter side;
</listItem>
<bodyText confidence="0.998724461538462">
example, a double phoneme U would replace a se-
quence of the phonemes j and u in Figure 1. This
solution requires a manual extension of the set of
phonemes present in the data. By convention, we
regard the models that include a restricted set of
1-2 mappings as 1-1 models.
Advanced L2P approaches, including the joint
n-gram models (Bisani and Ney, 2008) and the
joint discriminative approach (Jiampojamarn et
al., 2007) eliminate the one-to-one constraint en-
tirely, allowing for linking of multiple letters to
multiple phonemes. We refer to such models as
many-to-many (M-M) models.
</bodyText>
<sectionHeader confidence="0.995721" genericHeader="method">
3 EM Alignment
</sectionHeader>
<bodyText confidence="0.975581964285715">
Early EM-based alignment methods (Daelemans
and Bosch, 1997; Black et al., 1998; Damper et
al., 2005) were generally pure 1-1 models. The
1-1 alignment problem can be formulated as a dy-
namic programming problem to find the maximum
score of alignment, given a probability table of
aligning letter and phoneme as a mapping func-
tion. The dynamic programming recursion to find
the most likely alignment is the following:
• the one-to-one constraint stipulates that each Ci,j = max { Ci−1,j−1 + δ(xi, yj) (1)
letter and phoneme may participate in at most Ci−1,j + δ(xi, ǫ)
one link. Ci,j−1 + δ(ǫ, yj)
These constraints increasingly reduce the search
space and facilitate the training process for the
L2P generation models.
We refer to an alignment model that assumes all
three constraints as a pure one-to-one (1-1) model.
By allowing only 1-1 and 1-0 links, the align-
ment task is thus greatly simplified. In the sim-
plest case, when the number of letters is equal to
the number of phonemes, there is only one pos-
sible alignment that satisfies all three constraints.
When there are more letters than phonemes, the
search is reduced to identifying letters that must
be linked to null phonemes (the process referred
to as “epsilon scattering” by Black et al. (1998)).
In some words, however, one letter clearly repre-
sents more than one phoneme; for example, u in
Figure 1. Moreover, a pure 1-1 approach cannot
handle cases where the number of phonemes ex-
ceeds the number of letters. A typical solution to
overcome this problems is to introduce so-called
double phonemes by merging adjacent phonemes
that could be represented as a single letter. For
where δ(xi, ǫ) denotes a probability that a let-
ter xi aligns with a null phoneme and δ(ǫ, yj) de-
notes a probability that a null letter aligns with a
phoneme yj. In practice, the latter probability is
often set to zero in order to enforce the represen-
tation constraint, which facilitates the subsequent
phoneme generation process. The probability ta-
ble δ(xi, yj) can be initialized by a uniform dis-
tribution and is iteratively re-computed (M-step)
from the most likely alignments found at each it-
eration over the data set (E-step). The final align-
ments are constructed after the probability table
converges.
M2M-aligner (Jiampojamarn et al., 2007) is a
many-to-many (M-M) alignment algorithm based
on EM that allows for mapping of multiple let-
ters to multiple phonemes. Algorithm 1 describes
the E-step of the many-to-many alignment algo-
rithm. γ represents partial counts collected over
all possible mappings between substrings of let-
ters and phonemes. The maximum lengths of let-
ter and phoneme substrings are controlled by the
</bodyText>
<page confidence="0.9312835">
781
11
</page>
<equation confidence="0.954085333333333">
Algorithm 1: Many-to-many alignment
Input: x, y, maxX, maxY, γ
Output: γ
1 α := FORWARD-M2M (x, y, maxX, maxY)
2 β := BACKWARD-M2M (x, y, maxX, maxY)
3 T = jxj + 1 , V = jyj + 1
4 if (αT,V = 0) then
5 return
6 for t = 1..T , v = 1..V do
7 for i = 1..maxX st t − i &gt; 0 do
t�i��,ǫ)βt,v
γ(xt t−i+1, ǫ) += αt�i,vδ(xt
8 αT,V
9 for i = 1..maxX st t − i &gt; 0 do
10 for j = 1..maxY st v − j &gt; 0 do
v�j��)βt,v
γ(xtt−i+1, yvv−j+1) += αt�i,v�jδ(xt t�i��,yv
αT,V
</equation>
<bodyText confidence="0.994284375">
maxX and maxY parameters. The forward prob-
ability α is estimated by summing the probabilities
from left to right, while the backward probabil-
ity Q is estimated in the opposite direction. The
FORWARD-M2M procedure is similar to line 3 to
10 of Algorithm 1, except that it uses Equation 2
in line 8 and 3 in line 11. The BACKWARD-M2M
procedure is analogous to FORWARD-M2M.
</bodyText>
<equation confidence="0.999314">
t
αt,v += S(xt−i+1, E)αt−i,v (2)
αt,v += S(xtt−i+1, yvv−j+1)αt−i,v−j (3)
</equation>
<bodyText confidence="0.999930523809524">
In M-step, the partial counts are normalized
by using a conditional distribution to create the
mapping probability table S. The final many-to-
many alignments are created by finding the most
likely paths using the Viterbi algorithm based on
the learned mapping probability table. The source
code of M2M-aligner is publicly available.1
Although the many-to-many approach tends to
create relatively large models, it generates more
intuitive alignments and leads to improvement in
the L2P accuracy (Jiampojamarn et al., 2007).
However, since many links involve multiple let-
ters, it also introduces additional complexity in the
phoneme prediction phase. One possible solution
is to apply a letter segmentation algorithm at test
time to cluster letters according to the alignments
in the training data. This is problematic because
of error propagation inherent in such a process.
A better solution is to combine segmentation and
decoding using a phrasal decoder (e.g. (Zens and
Ney, 2004)).
</bodyText>
<footnote confidence="0.950365">
1http://code.google.com/p/m2m-aligner/
</footnote>
<sectionHeader confidence="0.913019" genericHeader="method">
4 Phonetic alignment
</sectionHeader>
<bodyText confidence="0.999577717391304">
The EM-based approaches to L2P alignment treat
both letters and phonemes as abstract symbols.
A completely different approach to L2P align-
ment is based on the phonetic similarity between
phonemes. The key idea of the approach is to rep-
resent each letter by a phoneme that is likely to be
represented by the letter. The actual phonemes on
the phoneme side and the phonemes representing
letters on the letter side can then be aligned on the
basis of phonetic similarity between phonemes.
The main advantage of the phonetic alignment is
that it requires no training data, and so can be read-
ily be applied to languages for which no pronunci-
ation lexicons are available.
The task of identifying the phoneme that is most
likely to be represented by a given letter may seem
complex and highly language-dependent. For ex-
ample, the letter a can represent no less than 12
different English vowels. In practice, however, ab-
solute precision is not necessary. Intuitively, the
letters that had been chosen (often centuries ago)
to represent phonemes in any orthographic system
tend to be close to the prototype phoneme in the
original script. For example, the letter ‘o’ rep-
resented a mid-high rounded vowel in Classical
Latin and is still generally used to represent simi-
lar vowels.
The following simple heuristic works well for a
number of languages: treat every letter as if it were
a symbol in the International Phonetic Alphabet
(IPA). The set of symbols employed by the IPA in-
cludes the 26 letters of the Latin alphabet, which
tend to correspond to the phonemes that they rep-
resent in the Latin script. For example, the IPA
symbol [m] denotes a voiced bilabial nasal con-
sonant, which is the phoneme represented by the
letter m in most languages that utilize Latin script.
ALINE (Kondrak, 2000) performs phonetic
alignment of two strings of phonemes. It combines
a dynamic programming alignment algorithm with
an appropriate scoring scheme for computing pho-
netic similarity on the basis of multivalued fea-
tures. The example below shows the alignment of
the word sheath to its phonetic transcription [SiT].
ALINE correctly links the most similar pairs of
phonemes (s: S, e:i, t:T).2
</bodyText>
<footnote confidence="0.667076333333333">
2ALINE can also be applied to non-Latin scripts by re-
placing every grapheme with the IPA symbol that is phoneti-
cally closest to it.
</footnote>
<page confidence="0.960111">
782
</page>
<equation confidence="0.802145666666667">
s h e a t h
� � � � � �
f-i-0-
</equation>
<bodyText confidence="0.999929291666667">
Since ALINE is designed to align phonemes
with phonemes, it does not incorporate the repre-
sentation constraint. In order to avoid the prob-
lem of unaligned phonemes, we apply a post-
processing algorithm, which also handles 1-2
links. The algorithm first attempts to remove 0-1
links by merging them with the adjacent 1-0 links.
If this is not possible, the algorithm scans a list of
valid 1-2 mappings, attempting to replace a pair of
0-1 and 1-1 links with a single 1-2 link. If this also
fails, the entire entry is removed from the training
set. Such entries often represent unusual foreign-
origin words or outright annotation errors. The
number of unaligned entries rarely exceeds 1% of
the data.
The post-processing algorithm produces an
alignment that contains 1-0, 1-1, and 1-2 links.
The list of valid 1-2 mappings must be prepared
manually. The length of such lists ranges from 1
for Spanish and German (x:[ks]) to 17 for English.
This approach is more robust than the double-
phoneme technique because the two phonemes are
clustered only if they can be linked to the corre-
sponding letter.
</bodyText>
<sectionHeader confidence="0.99715" genericHeader="method">
5 Constraint-based alignment
</sectionHeader>
<bodyText confidence="0.999988862068965">
One of the advantages of the phonetic alignment
is its ability to rule out phonetically implausible
letter-phoneme links, such as o:p. We are in-
terested in establishing whether a set of allow-
able letter-phoneme mappings could be derived di-
rectly from the data without relying on phonetic
features.
Black et al. (1998) report that constructing lists
of possible phonemes for each letter leads to L2P
improvement. They produce the lists in a “semi-
automatic”, interactive manner. The lists constrain
the alignments performed by the EM algorithm
and lead to better-quality alignments.
We implement a similar interactive program
that incrementally expands the lists of possible
phonemes for each letter by refining alignments
constrained by those lists. However, instead of
employing the EM algorithm, we induce align-
ments using the standard edit distance algorithm
with substitution and deletion assigned the same
cost. In cases when there are multiple alternative
alignments that have the same edit distance, we
randomly choose one of them. Furthermore, we
extend this idea also to many-to-many alignments.
In addition to lists of phonemes for each letter (1-
1 mappings), we also construct lists of many-to-
many mappings, such as ee:i, sch:f, and ew:�u. In
total, the English set contains 377 mappings, of
which more than half are of the 2-1 type.
</bodyText>
<sectionHeader confidence="0.998306" genericHeader="method">
6 IP Alignment
</sectionHeader>
<bodyText confidence="0.999985571428571">
The process of manually inducing allowable letter-
phoneme mappings is time-consuming and in-
volves a great deal of language-specific knowl-
edge. The Integer Programming (IP) framework
offers a way to induce similar mappings without a
human expert in the loop. The IP formulation aims
at identifying the smallest set of letter-phoneme
mappings that is sufficient to align all instances in
the data set.
Our IP formulation employs the three con-
straints enumerated in Section 2, except that the
one-to-one constraint is relaxed in order to identify
a small set of 1-2 mappings. We specify two types
of binary variables that correspond to local align-
ment links and global letter-phoneme mappings,
respectively. We distinguish three types of local
variables, X, Y , and Z, which correspond to 1-0,
1-1, and 1-2 links, respectively. In order to min-
imize the number of global mappings, we set the
following objective that includes variables corre-
sponding to 1-1 and 1-2 mappings:
</bodyText>
<equation confidence="0.9854825">
�minimize : G(l, p) + � G(l,p1p2) (4)
l,p l,p1,p2
</equation>
<bodyText confidence="0.999981">
We adopt a simplifying assumption that any let-
ter can be linked to a null phoneme, so no global
variables corresponding to 1-0 mappings are nec-
essary.
In the lexicon entry k, let lik be the letter at po-
sition i, and pjk the phoneme at position j. In or-
der to prevent the alignments from utilizing letter-
phoneme mappings which are not on the global
list, we impose the following constraints:
</bodyText>
<equation confidence="0.9962995">
bi,j,kY (i,j, k) :5 G(lik, pjk) (5)
bi,j,kZ(i,j, k) :5 G(lik, pj kp(j+1)k) (6)
</equation>
<bodyText confidence="0.975635666666667">
For example, the local variable Y (i, j, k) is set if
lik is linked to pjk. A corresponding global vari-
able G(lik,pjk) is set if the list of allowed letter-
phoneme mappings includes the link (lik,pjk).
Activating the local variable implies activating the
corresponding global variable, but not vice versa.
</bodyText>
<page confidence="0.997168">
783
</page>
<figureCaption confidence="0.999863">
Figure 2: A network of possible alignment links.
</figureCaption>
<bodyText confidence="0.997973222222222">
We create a network of possible alignment links
for each lexicon entry k, and assign a binary vari-
able to each link in the network. Figure 2 shows an
alignment network for the lexicon entry k: wriggle
[r I g @ L]. There are three 1-0 links (level), three
1-1 links (diagonal), and one 1-2 link (steep). The
local variables that receive the value of 1 are the
following: X(1,0,k), Y(2,1,k), Y(3,2,k), Y(4,3,k),
X(5,3,k), Z(6,5,k), and X(7,5,k). The correspond-
ing global variables are: G(r,r), G(i,I), G(g,g), and
G(l,@L).
We create constraints to ensure that the link
variables receiving a value of 1 form a left-to-right
path through the alignment network, and that all
other link variables receive a value of 0. We ac-
complish this by requiring the sum of the links
entering each node to equal the sum of the links
leaving each node.
</bodyText>
<equation confidence="0.991313333333333">
bz,7,k X(i, j, k) + Y (i, j, k) + Z(i, j, k) _
X(i + 1, j, k) + Y (i + 1,j + 1,k)
+Z(i + 1, j + 2,k)
</equation>
<bodyText confidence="0.999829181818182">
We found that inducing the IP model with the
full set of variables gives too much freedom to the
IP program and leads to inferior results. Instead,
we first run the full set of variables on a subset of
the training data which includes only the lexicon
entries in which the number of phonemes exceeds
the number of letters. This generates a small set
of plausible 1-2 mappings. In the second pass, we
run the model on the full data set, but we allow
only the 1-2 links that belong to the initial set of
1-2 mappings induced in the first pass.
</bodyText>
<subsectionHeader confidence="0.986658">
6.1 Combining IP with EM
</subsectionHeader>
<bodyText confidence="0.999978333333333">
The set of allowable letter-phoneme mappings can
also be used as an input to the EM alignment algo-
rithm. We call this approach IP-EM. After induc-
ing the minimal set of letter-phoneme mappings,
we constrain EM to use only those mappings with
the exclusion of all others. We initialize the prob-
ability of the minimal set with a uniform distribu-
tion, and set it to zero for other mappings. We train
the EM model in a similar fashion to the many-to-
many alignment algorithm presented in Section 3,
except that we limit the letter size to be one letter,
and that any letter-phoneme mapping that is not in
the minimal set is assigned zero count during the
E-step. The final alignments are generated after
the parameters converge.
</bodyText>
<sectionHeader confidence="0.802242" genericHeader="method">
7 Alignment by aggregation
</sectionHeader>
<bodyText confidence="0.999991413793103">
During our development experiments, we ob-
served that the technique that combines IP with
EM described in the previous section generally
leads to alignment quality improvement in com-
parison with the IP alignment. Nevertheless, be-
cause EM is constrained not to introduce any new
letter-phoneme mappings, many incorrect align-
ments are still proposed. We hypothesized that in-
stead of pre-constraining EM, a post-processing of
EM’s output may lead to better results.
M2M-aligner has the ability to create precise
links involving more than one letter, such as ph:f.
However, it also tends to create non-intuitive links
such as se:z for the word phrase [f r e z], where e
is clearly a case of a “silent” letter. We propose
an alternative EM-based alignment method that
instead utilizes a list of alternative one-to-many
alignments created with M2M-aligner and aggre-
gates 1-M links into M-M links in cases when
there is a disagreement between alignments within
the list. For example, if the list contains the two
alignments shown in Figure 3, the algorithm cre-
ates a single many-to-many alignment by merg-
ing the first pair of 1-1 and 1-0 links into a single
ph:f link. However, the two rightmost links are not
merged because there is no disagreement between
the two initial alignments. Therefore, the resulting
alignment reinforces the ph:f mapping, but avoids
the questionable se:z link.
</bodyText>
<equation confidence="0.776809666666667">
p h r a s e p h r a s e

f - r e z - - f r e z -
</equation>
<figureCaption confidence="0.989896">
Figure 3: Two alignments of phrase.
</figureCaption>
<bodyText confidence="0.99830225">
In order to generate the list of best alignments,
we use Algorithm 2, which is an adaptation of the
standard Viterbi algorithm. Each cell Qt,v con-
tains a list of n-best scores that correspond to al-
</bodyText>
<page confidence="0.956982">
784
</page>
<equation confidence="0.929379153846154">
Algorithm 2: Extracting n-best alignments
Input: x, y, 6
Output: QT,V
1
T = jxj + 1 , V = jyj + 1
2 for t = 1..T do
3 Qt,v = 0
4 for v = 1..V do
5 for q E Qt−1,v do
6 append q - 6(xt, e) to Qt,v
7 for j = 1..maxY st v − j &gt; 0 do
8 for q E Qt−1,v−j do
9 append q - 6(xt, yvv−j+1) to Qt,v
</equation>
<bodyText confidence="0.986980571428571">
Alignment entropy is a measure of alignment
quality proposed by Pervouchine et al. (2009) in
the context of transliteration. The entropy indi-
cates the uncertainty of mapping between letter
l and phoneme p resulting from the alignment:
We compute the alignment entropy for each of the
methods using the following formula:
</bodyText>
<equation confidence="0.91263">
H = − � P(l, p) log P(l|p) (7)
l,p
10 sort Qt,v
11 Qt,v = Qt,v[1 : n]
</equation>
<bodyText confidence="0.998821833333333">
ternative alignments during the forward pass. In
line 9, we consider all possible 1-M links between
letter xt and phoneme substring yvv_j+1. At the
end of the main loop, we keep at most n best align-
ments in each Qt,v list.
Algorithm 2 yields n-best alignments in the
QT,V list. However, in order to further restrict
the set of high-quality alignments, we also dis-
card the alignments with scores below threshold
R with respect to the best alignment score. Based
on the experiments with the development set, we
set R = 0.8 and n = 10.
</bodyText>
<sectionHeader confidence="0.994371" genericHeader="method">
8 Intrinsic evaluation
</sectionHeader>
<bodyText confidence="0.9999363125">
For the intrinsic evaluation, we compared the gen-
erated alignments to gold standard alignments ex-
tracted from the the core vocabulary of the Com-
bilex data set (Richmond et al., 2009). Combilex
is a high quality pronunciation lexicon with ex-
plicit expert manual alignments. We used a sub-
set of the lexicon composed of the core vocabu-
lary containing 18,145 word-phoneme pairs. The
alignments contain 550 mappings, which include
complex 4-1 and 2-3 types.
Each alignment approach creates alignments
from unaligned word-phoneme pairs in an un-
supervised fashion. We distinguish between the
1-1 and M-M approaches. We report the align-
ment quality in terms of precision, recall and F-
score. Since the gold standard includes many links
that involve multiple letters, the theoretical up-
per bound for recall achieved by a one-to-one ap-
proach is 90.02%. However, it is possible to obtain
the perfect precision because we count as correct
all 1-1 links that are consistent with the M-M links
in the gold standard. The F-score corresponding
to perfect precision and the upper-bound recall is
94.75%.
Table 1 includes the results of the intrinsic eval-
uation. (the two rightmost columns are discussed
in Section 9). The baseline BaseEM is an im-
plementation of the one-to-one alignment method
of (Black et al., 1998) without the allowable list.
ALINE is the phonetic method described in Sec-
tion 4. SeedMap is the hand-seeded method de-
scribed in Section 5. M-M-EM is the M2M-
aligner approach of Jiampojamarn et al. (2007).
1-M-EM is equivalent to M-M-EM but with the
restriction that each link contains exactly one let-
ter. IP-align is the alignment generated by the
IP formulation from Section 6. IP-EM is the
method that combines IP with EM described in
Section 6.1. EM-Aggr is our final many-to-many
alignment method described in Section 7. Oracle
corresponds to the gold-standard alignments from
Combilex.
Overall, the M-M models obtain lower preci-
sion but higher recall and F-score than 1-1 models,
which is to be expected as the gold standard is de-
fined in terms of M-M links. ALINE produces the
most accurate alignments among the 1-1 methods,
with the precision and recall values that are very
close to the theoretical upper bounds. Its preci-
sion is particularly impressive: on average, only
one link in a thousand is not consistent with the
gold standard. In terms of word accuracy, 98.97%
words have no incorrect links. Out of 18,145
words, only 112 words contain incorrect links, and
further 75 words could not be aligned. The rank-
ing of the 1-1 methods is quite clear: ALINE fol-
lowed by IP-EM, 1-M-EM, IP-align, and BaseEM.
Among the M-M methods, EM-Aggr has slightly
better precision than M-M-EM, but its recall is
much worse. This is probably caused by the ag-
gregation strategy causing EM-Aggr to “lose” a
significant number of correct links. In general, the
entropy measure does not mirror the quality of the
alignment.
</bodyText>
<page confidence="0.994914">
785
</page>
<table confidence="0.9998578">
Aligner Precision Recall F1 score Entropy L2P 1-1 L2P M-M
BaseEM 96.54 82.84 89.17 0.794 50.00 65.38
ALINE 99.90 89.54 94.44 0.672 54.85 68.74
1-M-EM 99.04 89.15 93.84 0.636 53.91 69.13
IP-align 98.30 88.49 93.14 0.706 52.66 68.25
IP-EM 99.31 89.40 94.09 0.651 53.86 68.91
M-M-EM 96.54 97.13 96.83 0.655 — 68.52
EM-Aggr 96.67 93.39 95.00 0.635 — 69.35
SeedMap 97.88 97.44 97.66 0.634 — 68.69
Oracle 100.0 100.0 100.0 0.640 — 69.35
</table>
<tableCaption confidence="0.99806">
Table 1: Alignment quality, entropy, and L2P conversion accuracy on the Combilex data set.
</tableCaption>
<table confidence="0.999836166666667">
Aligner Celex-En CMUDict NETtalk OALD Brulex
BaseEM 75.35 60.03 54.80 67.23 81.33
ALINE 81.50 66.46 54.90 72.12 89.37
1-M-EM 80.12 66.66 55.00 71.11 88.97
IP-align 78.88 62.34 53.10 70.46 83.72
IP-EM 80.95 67.19 54.70 71.24 87.81
</table>
<tableCaption confidence="0.999299">
Table 2: L2P word accuracy using the TiMBL-based generation system.
</tableCaption>
<sectionHeader confidence="0.802633" genericHeader="method">
9 Extrinsic evaluation
</sectionHeader>
<bodyText confidence="0.999197086206897">
In order to investigate the relationship between
the alignment quality and L2P performance, we
feed the alignments to two different L2P systems.
The first one is a classification-based learning sys-
tem employing TiMBL (Daelemans et al., 2009),
which can utilize either 1-1 or 1-M alignments.
The second system is the state-of-the-art online
discriminative training for letter-to-phoneme con-
version (Jiampojamarn et al., 2008), which ac-
cepts both 1-1 and M-M types of alignment. Ji-
ampojamarn et al. (2008) show that the online dis-
criminative training system outperforms a num-
ber of competitive approaches, including joint n-
grams (Demberg et al., 2007), constraint satisfac-
tion inference (Bosch and Canisius, 2006), pro-
nunciation by analogy (Marchand and Damper,
2006), and decision trees (Black et al., 1998). The
decoder module uses standard Viterbi for the 1-1
case, and a phrasal decoder (Zens and Ney, 2004)
for the M-M case. We report the L2P performance
in terms of word accuracy, which rewards only
the completely correct output phoneme sequences.
The data set is randomly split into 90% for training
and 10% for testing. For all experiments, we hold
out 5% of our training data to determine when to
stop the online training process.
Table 1 includes the results on the Combilex
data set. The two rightmost columns correspond
to our two test L2P systems. We observe that al-
though better alignment quality does not always
translate into better L2P accuracy, there is never-
theless a strong correlation between the two, espe-
cially for the weaker phoneme generation system.
Interestingly, EM-Aggr matches the L2P accuracy
obtained with the gold standard alignments. How-
ever, there is no reason to claim that the gold stan-
dard alignments are optimal for the L2P genera-
tion task, so that result should not be considered as
an upper bound. Finally, we note that alignment
entropy seems to match the L2P accuracy better
than it matches alignment quality.
Tables 2 and 3 show the L2P results on sev-
eral evaluation sets: English Celex, CMUDict,
NETTalk, OALD, and French Brulex. The train-
ing sizes range from 19K to 106K words. We fol-
low exactly the same data splits as in Bisani and
Ney (2008).
The TiMBL L2P generation method (Table 2)
is applicable only to the 1-1 alignment models.
ALINE produces the highest accuracy on four out
of six datasets (including Combilex). The perfor-
mance of IP-EM is comparable to 1-M-EM, but
not consistently better. IP-align does not seem to
measure up to the other algorithms.
The discriminative approach (Table 3) is flexi-
ble enough to utilize all kinds of alignments. How-
ever, the M-M models perform clearly better than
1-1 models. The only exception is NetTalk, which
</bodyText>
<page confidence="0.992969">
786
</page>
<table confidence="0.999875375">
Aligner Celex-En CMUDict NETTalk OALD Brulex
BaseEM 85.66 71.49 68.60 80.76 88.41
ALINE 87.96 75.05 69.52 81.57 94.56
1-M-EM 88.08 75.11 70.78 81.78 94.54
IP-EM 88.00 75.09 70.10 81.76 94.96
M-M-EM 88.54 75.41 70.18 82.43 95.03
EM-Aggr 89.11 75.52 71.10 83.32 95.07
joint n-gram 88.58 75.47 69.00 82.51 93.75
</table>
<tableCaption confidence="0.999856">
Table 3: L2P word accuracy using the online discriminative system.
</tableCaption>
<figureCaption confidence="0.958645">
Figure 4: L2P word accuracy vs. alignment en-
tropy.
</figureCaption>
<bodyText confidence="0.999174619047619">
can be attributed to the fact that NetTalk already
includes double-phonemes in its original formu-
lation. In general, the 1-M-EM method achieves
the best results among the 1-1 alignment methods,
Overall, EM-Aggr achieves the best word accuracy
in comparison to other alignment methods includ-
ing the joint n-gram results, which are taken di-
rectly from the original paper of Bisani and Ney
(2008). Except the Brulex and CMUDict data
sets, the differences between EM-Aggr and M-M-
EM are statistically significant according to Mc-
Nemar’s test at 90% confidence level.
Figure 4 contains a plot of alignment entropy
values vs. L2P word accuracy. Each point rep-
resent an application of a particular alignment
method to a different data sets. It appears that
there is only weak correlation between alignment
entropy and L2P accuracy. So far, we have been
unable to find either direct or indirect evidence that
alignment entropy is a reliable measure of letter-
phoneme alignment quality.
</bodyText>
<sectionHeader confidence="0.994029" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.999965190476191">
We investigated several new methods for gener-
ating letter-phoneme alignments. The phonetic
alignment is recommended for languages with lit-
tle or no training data. The constraint-based ap-
proach achieves excellent accuracy at the cost
of manual construction of seed mappings. The
IP alignment requires no linguistic expertise and
guarantees a minimal set of letter-phoneme map-
pings. The alignment by aggregation advances
the state-of-the-art results in L2P conversion. We
thoroughly evaluated the resulting alignments on
several data sets by using them as input to two dif-
ferent L2P generation systems. Finally, we em-
ployed an independently constructed lexicon to
demonstrate the close relationship between align-
ment quality and L2P conversion accuracy.
One open question that we would like to investi-
gate in the future is whether L2P conversion accu-
racy could be improved by treating letter-phoneme
alignment links as latent variables, instead of com-
mitting to a single best alignment.
</bodyText>
<sectionHeader confidence="0.997586" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.98596275">
This research was supported by the Alberta In-
genuity, Informatics Circle of Research Excel-
lence (iCORE), and Natural Science of Engineer-
ing Research Council of Canada (NSERC).
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999691384615385">
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434–451.
Alan W. Black, Kevin Lenzo, and Vincent Pagel. 1998.
Issues in building general letter to sound rules. In
The Third ESCA Workshop in Speech Synthesis,
pages 77–80.
Antal Van Den Bosch and Sander Canisius. 2006.
Improved morpho-phonological sequence process-
ing with constraint satisfaction inference. Proceed-
ings of the Eighth Meeting of the ACL Special Inter-
est Group in Computational Phonology, SIGPHON
’06, pages 41–49.
</reference>
<page confidence="0.969058">
787
</page>
<reference confidence="0.999896223529412">
Walter Daelemans and Antal Van Den Bosch. 1997.
Language-independent data-oriented grapheme-to-
phoneme conversion. In Progress in Speech Synthe-
sis, pages 77–89. New York, USA.
Walter Daelemans, Jakub Zavrel, Ko van der Sloot, and
Antal van den Bosch. 2009. TiMBL: Tilburg Mem-
ory Based Learner, version 6.2, Reference Guide.
ILK Research Group Technical Report Series no.
09-01.
Robert I. Damper, Yannick Marchand, John DS.
Marsters, and Alexander I. Bazin. 2005. Align-
ing text and phonemes for speech technology appli-
cations using an EM-like algorithm. International
Journal of Speech Technology, 8(2):147–160.
Vera Demberg, Helmut Schmid, and Gregor M¨ohler.
2007. Phonological constraints and morphologi-
cal preprocessing for grapheme-to-phoneme conver-
sion. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
96–103, Prague, Czech Republic.
Herman Engelbrecht and Tanja Schultz. 2005. Rapid
development of an afrikaans-english speech-to-
speech translator. In International Workshop of Spo-
ken Language Translation (IWSLT), Pittsburgh, PA,
USA.
Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek
Sherif. 2007. Applying many-to-many alignments
and hidden markov models to letter-to-phoneme
conversion. In Human Language Technologies
2007: The Conference of the North American Chap-
ter ofthe Association for Computational Linguistics;
Proceedings of the Main Conference, pages 372–
379, Rochester, New York, USA.
Sittichai Jiampojamarn, Colin Cherry, and Grzegorz
Kondrak. 2008. Joint processing and discriminative
training for letter-to-phoneme conversion. In Pro-
ceedings of ACL-08: HLT, pages 905–913, Colum-
bus, Ohio, June. Association for Computational Lin-
guistics.
Grzegorz Kondrak. 2000. A new algorithm for the
alignment of phonetic sequences. In Proceedings of
NAACL 2000: 1st Meeting of the North American
Chapter of the Association for Computational Lin-
guistics, pages 288–295.
Yannick Marchand and Robert I. Damper. 2000. A
multistrategy approach to improving pronunciation
by analogy. Computational Linguistics, 26(2):195–
219.
Yannick Marchand and Robert I. Damper. 2006. Can
syllabification improve pronunciation by analogy of
English? Natural Language Engineering, 13(1):1–
24.
Vladimir Pervouchine, Haizhou Li, and Bo Lin. 2009.
Transliteration alignment. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP, pages
136–144, Suntec, Singapore, August. Association
for Computational Linguistics.
Korin Richmond, Robert A. J. Clark, and Sue Fitt.
2009. Robust LTS rules with the Combilex speech
technology lexicon. In Proceedings od Interspeech,
pages 1295–1298.
Juergen Schroeter, Alistair Conkie, Ann Syrdal, Mark
Beutnagel, Matthias Jilka, Volker Strom, Yeon-Jun
Kim, Hong-Goo Kang, and David Kapilow. 2002.
A perspective on the next challenges for TTS re-
search. In IEEE 2002 Workshop on Speech Synthe-
sis.
Terrence J. Sejnowski and Charles R. Rosenberg.
1987. Parallel networks that learn to pronounce En-
glish text. In Complex Systems, pages 1:145–168.
Paul Taylor. 2005. Hidden Markov Models for
grapheme to phoneme conversion. In Proceedings
of the 9th European Conference on Speech Commu-
nication and Technology.
Kristina Toutanova and Robert C. Moore. 2001. Pro-
nunciation modeling for improved spelling correc-
tion. In ACL ’02: Proceedings of the 40th Annual
Meeting on Association for Computational Linguis-
tics, pages 144–151, Morristown, NJ, USA.
Richard Zens and Hermann Ney. 2004. Improvements
in phrase-based statistical machine translation. In
HLT-NAACL 2004: Main Proceedings, pages 257–
264, Boston, Massachusetts, USA.
</reference>
<page confidence="0.996958">
788
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.960059">
<title confidence="0.999599">Letter-Phoneme Alignment: An Exploration</title>
<author confidence="0.99908">Jiampojamarn Kondrak</author>
<affiliation confidence="0.999978">Department of Computing Science University of Alberta</affiliation>
<address confidence="0.998367">Edmonton, AB, T6G 2E8, Canada</address>
<abstract confidence="0.997517066666667">Letter-phoneme alignment is usually generated by a straightforward application of the EM algorithm. We explore several alternative alignment methods that employ phonetics, integer programming, and sets of constraints, and propose a novel approach of refining the EM alignment by aggregation of best alignments. We perform both intrinsic and extrinsic evaluation of the assortment of methods. We show that our proposed EM-Aggregation algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<issue>5</issue>
<contexts>
<context position="5060" citStr="Bisani and Ney, 2008" startWordPosition="771" endWordPosition="774">straints on links are assumed by some or all alignment models: • the monotonicity constraint prevents links from crossing each other; • the representation constraint requires each phoneme to be linked to at least one letter, thus precluding nulls on the letter side; example, a double phoneme U would replace a sequence of the phonemes j and u in Figure 1. This solution requires a manual extension of the set of phonemes present in the data. By convention, we regard the models that include a restricted set of 1-2 mappings as 1-1 models. Advanced L2P approaches, including the joint n-gram models (Bisani and Ney, 2008) and the joint discriminative approach (Jiampojamarn et al., 2007) eliminate the one-to-one constraint entirely, allowing for linking of multiple letters to multiple phonemes. We refer to such models as many-to-many (M-M) models. 3 EM Alignment Early EM-based alignment methods (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005) were generally pure 1-1 models. The 1-1 alignment problem can be formulated as a dynamic programming problem to find the maximum score of alignment, given a probability table of aligning letter and phoneme as a mapping function. The dynamic programming </context>
<context position="27691" citStr="Bisani and Ney (2008)" startWordPosition="4648" endWordPosition="4651">ystem. Interestingly, EM-Aggr matches the L2P accuracy obtained with the gold standard alignments. However, there is no reason to claim that the gold standard alignments are optimal for the L2P generation task, so that result should not be considered as an upper bound. Finally, we note that alignment entropy seems to match the L2P accuracy better than it matches alignment quality. Tables 2 and 3 show the L2P results on several evaluation sets: English Celex, CMUDict, NETTalk, OALD, and French Brulex. The training sizes range from 19K to 106K words. We follow exactly the same data splits as in Bisani and Ney (2008). The TiMBL L2P generation method (Table 2) is applicable only to the 1-1 alignment models. ALINE produces the highest accuracy on four out of six datasets (including Combilex). The performance of IP-EM is comparable to 1-M-EM, but not consistently better. IP-align does not seem to measure up to the other algorithms. The discriminative approach (Table 3) is flexible enough to utilize all kinds of alignments. However, the M-M models perform clearly better than 1-1 models. The only exception is NetTalk, which 786 Aligner Celex-En CMUDict NETTalk OALD Brulex BaseEM 85.66 71.49 68.60 80.76 88.41 A</context>
<context position="29028" citStr="Bisani and Ney (2008)" startWordPosition="4864" endWordPosition="4867">8.54 75.41 70.18 82.43 95.03 EM-Aggr 89.11 75.52 71.10 83.32 95.07 joint n-gram 88.58 75.47 69.00 82.51 93.75 Table 3: L2P word accuracy using the online discriminative system. Figure 4: L2P word accuracy vs. alignment entropy. can be attributed to the fact that NetTalk already includes double-phonemes in its original formulation. In general, the 1-M-EM method achieves the best results among the 1-1 alignment methods, Overall, EM-Aggr achieves the best word accuracy in comparison to other alignment methods including the joint n-gram results, which are taken directly from the original paper of Bisani and Ney (2008). Except the Brulex and CMUDict data sets, the differences between EM-Aggr and M-MEM are statistically significant according to McNemar’s test at 90% confidence level. Figure 4 contains a plot of alignment entropy values vs. L2P word accuracy. Each point represent an application of a particular alignment method to a different data sets. It appears that there is only weak correlation between alignment entropy and L2P accuracy. So far, we have been unable to find either direct or indirect evidence that alignment entropy is a reliable measure of letterphoneme alignment quality. 10 Conclusion We i</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50(5):434–451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan W Black</author>
<author>Kevin Lenzo</author>
<author>Vincent Pagel</author>
</authors>
<title>Issues in building general letter to sound rules.</title>
<date>1998</date>
<booktitle>In The Third ESCA Workshop in Speech Synthesis,</booktitle>
<pages>77--80</pages>
<contexts>
<context position="1454" citStr="Black et al., 1998" startWordPosition="203" endWordPosition="206">o-phoneme conversion) is the task of predicting the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phonemes, these must be inferred by a letter-phoneme alignment algorithm before a prediction model can be trained. The quality of the alignment affects the accuracy of L2P conversion. Letter</context>
<context position="5384" citStr="Black et al., 1998" startWordPosition="819" endWordPosition="822">phonemes j and u in Figure 1. This solution requires a manual extension of the set of phonemes present in the data. By convention, we regard the models that include a restricted set of 1-2 mappings as 1-1 models. Advanced L2P approaches, including the joint n-gram models (Bisani and Ney, 2008) and the joint discriminative approach (Jiampojamarn et al., 2007) eliminate the one-to-one constraint entirely, allowing for linking of multiple letters to multiple phonemes. We refer to such models as many-to-many (M-M) models. 3 EM Alignment Early EM-based alignment methods (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005) were generally pure 1-1 models. The 1-1 alignment problem can be formulated as a dynamic programming problem to find the maximum score of alignment, given a probability table of aligning letter and phoneme as a mapping function. The dynamic programming recursion to find the most likely alignment is the following: • the one-to-one constraint stipulates that each Ci,j = max { Ci−1,j−1 + δ(xi, yj) (1) letter and phoneme may participate in at most Ci−1,j + δ(xi, ǫ) one link. Ci,j−1 + δ(ǫ, yj) These constraints increasingly reduce the search space and facilitate the training </context>
<context position="13698" citStr="Black et al. (1998)" startWordPosition="2235" endWordPosition="2238">ust be prepared manually. The length of such lists ranges from 1 for Spanish and German (x:[ks]) to 17 for English. This approach is more robust than the doublephoneme technique because the two phonemes are clustered only if they can be linked to the corresponding letter. 5 Constraint-based alignment One of the advantages of the phonetic alignment is its ability to rule out phonetically implausible letter-phoneme links, such as o:p. We are interested in establishing whether a set of allowable letter-phoneme mappings could be derived directly from the data without relying on phonetic features. Black et al. (1998) report that constructing lists of possible phonemes for each letter leads to L2P improvement. They produce the lists in a “semiautomatic”, interactive manner. The lists constrain the alignments performed by the EM algorithm and lead to better-quality alignments. We implement a similar interactive program that incrementally expands the lists of possible phonemes for each letter by refining alignments constrained by those lists. However, instead of employing the EM algorithm, we induce alignments using the standard edit distance algorithm with substitution and deletion assigned the same cost. I</context>
<context position="23040" citStr="Black et al., 1998" startWordPosition="3878" endWordPosition="3881">e. Since the gold standard includes many links that involve multiple letters, the theoretical upper bound for recall achieved by a one-to-one approach is 90.02%. However, it is possible to obtain the perfect precision because we count as correct all 1-1 links that are consistent with the M-M links in the gold standard. The F-score corresponding to perfect precision and the upper-bound recall is 94.75%. Table 1 includes the results of the intrinsic evaluation. (the two rightmost columns are discussed in Section 9). The baseline BaseEM is an implementation of the one-to-one alignment method of (Black et al., 1998) without the allowable list. ALINE is the phonetic method described in Section 4. SeedMap is the hand-seeded method described in Section 5. M-M-EM is the M2Maligner approach of Jiampojamarn et al. (2007). 1-M-EM is equivalent to M-M-EM but with the restriction that each link contains exactly one letter. IP-align is the alignment generated by the IP formulation from Section 6. IP-EM is the method that combines IP with EM described in Section 6.1. EM-Aggr is our final many-to-many alignment method described in Section 7. Oracle corresponds to the gold-standard alignments from Combilex. Overall, </context>
<context position="26308" citStr="Black et al., 1998" startWordPosition="4410" endWordPosition="4413">arning system employing TiMBL (Daelemans et al., 2009), which can utilize either 1-1 or 1-M alignments. The second system is the state-of-the-art online discriminative training for letter-to-phoneme conversion (Jiampojamarn et al., 2008), which accepts both 1-1 and M-M types of alignment. Jiampojamarn et al. (2008) show that the online discriminative training system outperforms a number of competitive approaches, including joint ngrams (Demberg et al., 2007), constraint satisfaction inference (Bosch and Canisius, 2006), pronunciation by analogy (Marchand and Damper, 2006), and decision trees (Black et al., 1998). The decoder module uses standard Viterbi for the 1-1 case, and a phrasal decoder (Zens and Ney, 2004) for the M-M case. We report the L2P performance in terms of word accuracy, which rewards only the completely correct output phoneme sequences. The data set is randomly split into 90% for training and 10% for testing. For all experiments, we hold out 5% of our training data to determine when to stop the online training process. Table 1 includes the results on the Combilex data set. The two rightmost columns correspond to our two test L2P systems. We observe that although better alignment qual</context>
</contexts>
<marker>Black, Lenzo, Pagel, 1998</marker>
<rawString>Alan W. Black, Kevin Lenzo, and Vincent Pagel. 1998. Issues in building general letter to sound rules. In The Third ESCA Workshop in Speech Synthesis, pages 77–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal Van Den Bosch</author>
<author>Sander Canisius</author>
</authors>
<title>Improved morpho-phonological sequence processing with constraint satisfaction inference.</title>
<date>2006</date>
<booktitle>Proceedings of the Eighth Meeting of the ACL Special Interest Group in Computational Phonology, SIGPHON ’06,</booktitle>
<pages>41--49</pages>
<marker>Van Den Bosch, Canisius, 2006</marker>
<rawString>Antal Van Den Bosch and Sander Canisius. 2006. Improved morpho-phonological sequence processing with constraint satisfaction inference. Proceedings of the Eighth Meeting of the ACL Special Interest Group in Computational Phonology, SIGPHON ’06, pages 41–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal Van Den Bosch</author>
</authors>
<title>Language-independent data-oriented grapheme-tophoneme conversion.</title>
<date>1997</date>
<booktitle>In Progress in Speech Synthesis,</booktitle>
<pages>77--89</pages>
<location>New York, USA.</location>
<marker>Daelemans, Van Den Bosch, 1997</marker>
<rawString>Walter Daelemans and Antal Van Den Bosch. 1997. Language-independent data-oriented grapheme-tophoneme conversion. In Progress in Speech Synthesis, pages 77–89. New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Ko van der Sloot</author>
<author>Antal van den Bosch</author>
</authors>
<title>TiMBL: Tilburg Memory Based Learner, version 6.2, Reference Guide.</title>
<date>2009</date>
<journal>ILK Research Group</journal>
<tech>Technical Report Series no. 09-01.</tech>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2009</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Ko van der Sloot, and Antal van den Bosch. 2009. TiMBL: Tilburg Memory Based Learner, version 6.2, Reference Guide. ILK Research Group Technical Report Series no. 09-01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marsters</author>
<author>Alexander I Bazin</author>
</authors>
<title>Aligning text and phonemes for speech technology applications using an EM-like algorithm.</title>
<date>2005</date>
<journal>International Journal of Speech Technology,</journal>
<volume>8</volume>
<issue>2</issue>
<marker>Marsters, Bazin, 2005</marker>
<rawString>Robert I. Damper, Yannick Marchand, John DS. Marsters, and Alexander I. Bazin. 2005. Aligning text and phonemes for speech technology applications using an EM-like algorithm. International Journal of Speech Technology, 8(2):147–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Demberg</author>
<author>Helmut Schmid</author>
<author>Gregor M¨ohler</author>
</authors>
<title>Phonological constraints and morphological preprocessing for grapheme-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>96--103</pages>
<location>Prague, Czech Republic.</location>
<marker>Demberg, Schmid, M¨ohler, 2007</marker>
<rawString>Vera Demberg, Helmut Schmid, and Gregor M¨ohler. 2007. Phonological constraints and morphological preprocessing for grapheme-to-phoneme conversion. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 96–103, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herman Engelbrecht</author>
<author>Tanja Schultz</author>
</authors>
<title>Rapid development of an afrikaans-english speech-tospeech translator.</title>
<date>2005</date>
<booktitle>In International Workshop of Spoken Language Translation (IWSLT),</booktitle>
<location>Pittsburgh, PA, USA.</location>
<contexts>
<context position="1269" citStr="Engelbrecht and Schultz, 2005" startWordPosition="180" endWordPosition="183">algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets. 1 Introduction Letter-to-phoneme (L2P) conversion (also called grapheme-to-phoneme conversion) is the task of predicting the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phone</context>
</contexts>
<marker>Engelbrecht, Schultz, 2005</marker>
<rawString>Herman Engelbrecht and Tanja Schultz. 2005. Rapid development of an afrikaans-english speech-tospeech translator. In International Workshop of Spoken Language Translation (IWSLT), Pittsburgh, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter ofthe Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>372--379</pages>
<location>Rochester, New York, USA.</location>
<contexts>
<context position="5126" citStr="Jiampojamarn et al., 2007" startWordPosition="780" endWordPosition="783">: • the monotonicity constraint prevents links from crossing each other; • the representation constraint requires each phoneme to be linked to at least one letter, thus precluding nulls on the letter side; example, a double phoneme U would replace a sequence of the phonemes j and u in Figure 1. This solution requires a manual extension of the set of phonemes present in the data. By convention, we regard the models that include a restricted set of 1-2 mappings as 1-1 models. Advanced L2P approaches, including the joint n-gram models (Bisani and Ney, 2008) and the joint discriminative approach (Jiampojamarn et al., 2007) eliminate the one-to-one constraint entirely, allowing for linking of multiple letters to multiple phonemes. We refer to such models as many-to-many (M-M) models. 3 EM Alignment Early EM-based alignment methods (Daelemans and Bosch, 1997; Black et al., 1998; Damper et al., 2005) were generally pure 1-1 models. The 1-1 alignment problem can be formulated as a dynamic programming problem to find the maximum score of alignment, given a probability table of aligning letter and phoneme as a mapping function. The dynamic programming recursion to find the most likely alignment is the following: • th</context>
<context position="7592" citStr="Jiampojamarn et al., 2007" startWordPosition="1191" endWordPosition="1194">es a probability that a letter xi aligns with a null phoneme and δ(ǫ, yj) denotes a probability that a null letter aligns with a phoneme yj. In practice, the latter probability is often set to zero in order to enforce the representation constraint, which facilitates the subsequent phoneme generation process. The probability table δ(xi, yj) can be initialized by a uniform distribution and is iteratively re-computed (M-step) from the most likely alignments found at each iteration over the data set (E-step). The final alignments are constructed after the probability table converges. M2M-aligner (Jiampojamarn et al., 2007) is a many-to-many (M-M) alignment algorithm based on EM that allows for mapping of multiple letters to multiple phonemes. Algorithm 1 describes the E-step of the many-to-many alignment algorithm. γ represents partial counts collected over all possible mappings between substrings of letters and phonemes. The maximum lengths of letter and phoneme substrings are controlled by the 781 11 Algorithm 1: Many-to-many alignment Input: x, y, maxX, maxY, γ Output: γ 1 α := FORWARD-M2M (x, y, maxX, maxY) 2 β := BACKWARD-M2M (x, y, maxX, maxY) 3 T = jxj + 1 , V = jyj + 1 4 if (αT,V = 0) then 5 return 6 fo</context>
<context position="9394" citStr="Jiampojamarn et al., 2007" startWordPosition="1516" endWordPosition="1519">ure is analogous to FORWARD-M2M. t αt,v += S(xt−i+1, E)αt−i,v (2) αt,v += S(xtt−i+1, yvv−j+1)αt−i,v−j (3) In M-step, the partial counts are normalized by using a conditional distribution to create the mapping probability table S. The final many-tomany alignments are created by finding the most likely paths using the Viterbi algorithm based on the learned mapping probability table. The source code of M2M-aligner is publicly available.1 Although the many-to-many approach tends to create relatively large models, it generates more intuitive alignments and leads to improvement in the L2P accuracy (Jiampojamarn et al., 2007). However, since many links involve multiple letters, it also introduces additional complexity in the phoneme prediction phase. One possible solution is to apply a letter segmentation algorithm at test time to cluster letters according to the alignments in the training data. This is problematic because of error propagation inherent in such a process. A better solution is to combine segmentation and decoding using a phrasal decoder (e.g. (Zens and Ney, 2004)). 1http://code.google.com/p/m2m-aligner/ 4 Phonetic alignment The EM-based approaches to L2P alignment treat both letters and phonemes as </context>
<context position="23243" citStr="Jiampojamarn et al. (2007)" startWordPosition="3913" endWordPosition="3916">the perfect precision because we count as correct all 1-1 links that are consistent with the M-M links in the gold standard. The F-score corresponding to perfect precision and the upper-bound recall is 94.75%. Table 1 includes the results of the intrinsic evaluation. (the two rightmost columns are discussed in Section 9). The baseline BaseEM is an implementation of the one-to-one alignment method of (Black et al., 1998) without the allowable list. ALINE is the phonetic method described in Section 4. SeedMap is the hand-seeded method described in Section 5. M-M-EM is the M2Maligner approach of Jiampojamarn et al. (2007). 1-M-EM is equivalent to M-M-EM but with the restriction that each link contains exactly one letter. IP-align is the alignment generated by the IP formulation from Section 6. IP-EM is the method that combines IP with EM described in Section 6.1. EM-Aggr is our final many-to-many alignment method described in Section 7. Oracle corresponds to the gold-standard alignments from Combilex. Overall, the M-M models obtain lower precision but higher recall and F-score than 1-1 models, which is to be expected as the gold standard is defined in terms of M-M links. ALINE produces the most accurate alignm</context>
</contexts>
<marker>Jiampojamarn, Kondrak, Sherif, 2007</marker>
<rawString>Sittichai Jiampojamarn, Grzegorz Kondrak, and Tarek Sherif. 2007. Applying many-to-many alignments and hidden markov models to letter-to-phoneme conversion. In Human Language Technologies 2007: The Conference of the North American Chapter ofthe Association for Computational Linguistics; Proceedings of the Main Conference, pages 372– 379, Rochester, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Colin Cherry</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Joint processing and discriminative training for letter-to-phoneme conversion.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>905--913</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="25926" citStr="Jiampojamarn et al., 2008" startWordPosition="4349" endWordPosition="4352">-M-EM 80.12 66.66 55.00 71.11 88.97 IP-align 78.88 62.34 53.10 70.46 83.72 IP-EM 80.95 67.19 54.70 71.24 87.81 Table 2: L2P word accuracy using the TiMBL-based generation system. 9 Extrinsic evaluation In order to investigate the relationship between the alignment quality and L2P performance, we feed the alignments to two different L2P systems. The first one is a classification-based learning system employing TiMBL (Daelemans et al., 2009), which can utilize either 1-1 or 1-M alignments. The second system is the state-of-the-art online discriminative training for letter-to-phoneme conversion (Jiampojamarn et al., 2008), which accepts both 1-1 and M-M types of alignment. Jiampojamarn et al. (2008) show that the online discriminative training system outperforms a number of competitive approaches, including joint ngrams (Demberg et al., 2007), constraint satisfaction inference (Bosch and Canisius, 2006), pronunciation by analogy (Marchand and Damper, 2006), and decision trees (Black et al., 1998). The decoder module uses standard Viterbi for the 1-1 case, and a phrasal decoder (Zens and Ney, 2004) for the M-M case. We report the L2P performance in terms of word accuracy, which rewards only the completely corre</context>
</contexts>
<marker>Jiampojamarn, Cherry, Kondrak, 2008</marker>
<rawString>Sittichai Jiampojamarn, Colin Cherry, and Grzegorz Kondrak. 2008. Joint processing and discriminative training for letter-to-phoneme conversion. In Proceedings of ACL-08: HLT, pages 905–913, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>A new algorithm for the alignment of phonetic sequences.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL 2000: 1st Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>288--295</pages>
<contexts>
<context position="11704" citStr="Kondrak, 2000" startWordPosition="1898" endWordPosition="1899">mid-high rounded vowel in Classical Latin and is still generally used to represent similar vowels. The following simple heuristic works well for a number of languages: treat every letter as if it were a symbol in the International Phonetic Alphabet (IPA). The set of symbols employed by the IPA includes the 26 letters of the Latin alphabet, which tend to correspond to the phonemes that they represent in the Latin script. For example, the IPA symbol [m] denotes a voiced bilabial nasal consonant, which is the phoneme represented by the letter m in most languages that utilize Latin script. ALINE (Kondrak, 2000) performs phonetic alignment of two strings of phonemes. It combines a dynamic programming alignment algorithm with an appropriate scoring scheme for computing phonetic similarity on the basis of multivalued features. The example below shows the alignment of the word sheath to its phonetic transcription [SiT]. ALINE correctly links the most similar pairs of phonemes (s: S, e:i, t:T).2 2ALINE can also be applied to non-Latin scripts by replacing every grapheme with the IPA symbol that is phonetically closest to it. 782 s h e a t h � � � � � � f-i-0- Since ALINE is designed to align phonemes wit</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>Grzegorz Kondrak. 2000. A new algorithm for the alignment of phonetic sequences. In Proceedings of NAACL 2000: 1st Meeting of the North American Chapter of the Association for Computational Linguistics, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Marchand</author>
<author>Robert I Damper</author>
</authors>
<title>A multistrategy approach to improving pronunciation by analogy.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>2</issue>
<pages>219</pages>
<contexts>
<context position="1508" citStr="Marchand and Damper, 2000" startWordPosition="210" endWordPosition="213"> the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phonemes, these must be inferred by a letter-phoneme alignment algorithm before a prediction model can be trained. The quality of the alignment affects the accuracy of L2P conversion. Letter-phoneme alignment is closely related to transliterati</context>
</contexts>
<marker>Marchand, Damper, 2000</marker>
<rawString>Yannick Marchand and Robert I. Damper. 2000. A multistrategy approach to improving pronunciation by analogy. Computational Linguistics, 26(2):195– 219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Marchand</author>
<author>Robert I Damper</author>
</authors>
<title>Can syllabification improve pronunciation by analogy of English?</title>
<date>2006</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>1</issue>
<pages>24</pages>
<contexts>
<context position="26267" citStr="Marchand and Damper, 2006" startWordPosition="4403" endWordPosition="4406">tems. The first one is a classification-based learning system employing TiMBL (Daelemans et al., 2009), which can utilize either 1-1 or 1-M alignments. The second system is the state-of-the-art online discriminative training for letter-to-phoneme conversion (Jiampojamarn et al., 2008), which accepts both 1-1 and M-M types of alignment. Jiampojamarn et al. (2008) show that the online discriminative training system outperforms a number of competitive approaches, including joint ngrams (Demberg et al., 2007), constraint satisfaction inference (Bosch and Canisius, 2006), pronunciation by analogy (Marchand and Damper, 2006), and decision trees (Black et al., 1998). The decoder module uses standard Viterbi for the 1-1 case, and a phrasal decoder (Zens and Ney, 2004) for the M-M case. We report the L2P performance in terms of word accuracy, which rewards only the completely correct output phoneme sequences. The data set is randomly split into 90% for training and 10% for testing. For all experiments, we hold out 5% of our training data to determine when to stop the online training process. Table 1 includes the results on the Combilex data set. The two rightmost columns correspond to our two test L2P systems. We ob</context>
</contexts>
<marker>Marchand, Damper, 2006</marker>
<rawString>Yannick Marchand and Robert I. Damper. 2006. Can syllabification improve pronunciation by analogy of English? Natural Language Engineering, 13(1):1– 24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Pervouchine</author>
<author>Haizhou Li</author>
<author>Bo Lin</author>
</authors>
<title>Transliteration alignment.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>136--144</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="2147" citStr="Pervouchine et al., 2009" startWordPosition="306" endWordPosition="309">v Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phonemes, these must be inferred by a letter-phoneme alignment algorithm before a prediction model can be trained. The quality of the alignment affects the accuracy of L2P conversion. Letter-phoneme alignment is closely related to transliteration alignment (Pervouchine et al., 2009), which involves graphemes representing different writing scripts. Letter-phoneme alignment may also be considered as a task in itself; for example, in the alignment of speech transcription with text in spoken corpora. Most previous L2P approaches induce the alignment between letters and phonemes with the expectation maximization (EM) algorithm. In this paper, we propose a number of alternative alignment methods, and compare them to the EMbased algorithms using both intrinsic and extrinsic evaluations. The intrinsic evaluation is conducted by comparing the generated alignments to a manually-co</context>
<context position="20883" citStr="Pervouchine et al. (2009)" startWordPosition="3511" endWordPosition="3514">- f r e z - Figure 3: Two alignments of phrase. In order to generate the list of best alignments, we use Algorithm 2, which is an adaptation of the standard Viterbi algorithm. Each cell Qt,v contains a list of n-best scores that correspond to al784 Algorithm 2: Extracting n-best alignments Input: x, y, 6 Output: QT,V 1 T = jxj + 1 , V = jyj + 1 2 for t = 1..T do 3 Qt,v = 0 4 for v = 1..V do 5 for q E Qt−1,v do 6 append q - 6(xt, e) to Qt,v 7 for j = 1..maxY st v − j &gt; 0 do 8 for q E Qt−1,v−j do 9 append q - 6(xt, yvv−j+1) to Qt,v Alignment entropy is a measure of alignment quality proposed by Pervouchine et al. (2009) in the context of transliteration. The entropy indicates the uncertainty of mapping between letter l and phoneme p resulting from the alignment: We compute the alignment entropy for each of the methods using the following formula: H = − � P(l, p) log P(l|p) (7) l,p 10 sort Qt,v 11 Qt,v = Qt,v[1 : n] ternative alignments during the forward pass. In line 9, we consider all possible 1-M links between letter xt and phoneme substring yvv_j+1. At the end of the main loop, we keep at most n best alignments in each Qt,v list. Algorithm 2 yields n-best alignments in the QT,V list. However, in order to</context>
</contexts>
<marker>Pervouchine, Li, Lin, 2009</marker>
<rawString>Vladimir Pervouchine, Haizhou Li, and Bo Lin. 2009. Transliteration alignment. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 136–144, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Korin Richmond</author>
<author>Robert A J Clark</author>
<author>Sue Fitt</author>
</authors>
<title>Robust LTS rules with the Combilex speech technology lexicon.</title>
<date>2009</date>
<booktitle>In Proceedings od Interspeech,</booktitle>
<pages>1295--1298</pages>
<contexts>
<context position="21923" citStr="Richmond et al., 2009" startWordPosition="3697" endWordPosition="3700">oneme substring yvv_j+1. At the end of the main loop, we keep at most n best alignments in each Qt,v list. Algorithm 2 yields n-best alignments in the QT,V list. However, in order to further restrict the set of high-quality alignments, we also discard the alignments with scores below threshold R with respect to the best alignment score. Based on the experiments with the development set, we set R = 0.8 and n = 10. 8 Intrinsic evaluation For the intrinsic evaluation, we compared the generated alignments to gold standard alignments extracted from the the core vocabulary of the Combilex data set (Richmond et al., 2009). Combilex is a high quality pronunciation lexicon with explicit expert manual alignments. We used a subset of the lexicon composed of the core vocabulary containing 18,145 word-phoneme pairs. The alignments contain 550 mappings, which include complex 4-1 and 2-3 types. Each alignment approach creates alignments from unaligned word-phoneme pairs in an unsupervised fashion. We distinguish between the 1-1 and M-M approaches. We report the alignment quality in terms of precision, recall and Fscore. Since the gold standard includes many links that involve multiple letters, the theoretical upper bo</context>
</contexts>
<marker>Richmond, Clark, Fitt, 2009</marker>
<rawString>Korin Richmond, Robert A. J. Clark, and Sue Fitt. 2009. Robust LTS rules with the Combilex speech technology lexicon. In Proceedings od Interspeech, pages 1295–1298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juergen Schroeter</author>
<author>Alistair Conkie</author>
<author>Ann Syrdal</author>
<author>Mark Beutnagel</author>
<author>Matthias Jilka</author>
<author>Volker Strom</author>
<author>Yeon-Jun Kim</author>
<author>Hong-Goo Kang</author>
<author>David Kapilow</author>
</authors>
<title>A perspective on the next challenges for TTS research.</title>
<date>2002</date>
<booktitle>In IEEE 2002 Workshop on Speech Synthesis.</booktitle>
<contexts>
<context position="1090" citStr="Schroeter et al., 2002" startWordPosition="155" endWordPosition="158">e EM alignment by aggregation of best alignments. We perform both intrinsic and extrinsic evaluation of the assortment of methods. We show that our proposed EM-Aggregation algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets. 1 Introduction Letter-to-phoneme (L2P) conversion (also called grapheme-to-phoneme conversion) is the task of predicting the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usuall</context>
</contexts>
<marker>Schroeter, Conkie, Syrdal, Beutnagel, Jilka, Strom, Kim, Kang, Kapilow, 2002</marker>
<rawString>Juergen Schroeter, Alistair Conkie, Ann Syrdal, Mark Beutnagel, Matthias Jilka, Volker Strom, Yeon-Jun Kim, Hong-Goo Kang, and David Kapilow. 2002. A perspective on the next challenges for TTS research. In IEEE 2002 Workshop on Speech Synthesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terrence J Sejnowski</author>
<author>Charles R Rosenberg</author>
</authors>
<title>Parallel networks that learn to pronounce English text.</title>
<date>1987</date>
<booktitle>In Complex Systems,</booktitle>
<pages>1--145</pages>
<contexts>
<context position="1417" citStr="Sejnowski and Rosenberg, 1987" startWordPosition="197" endWordPosition="200">phoneme (L2P) conversion (also called grapheme-to-phoneme conversion) is the task of predicting the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phonemes, these must be inferred by a letter-phoneme alignment algorithm before a prediction model can be trained. The quality of the alignment affects t</context>
</contexts>
<marker>Sejnowski, Rosenberg, 1987</marker>
<rawString>Terrence J. Sejnowski and Charles R. Rosenberg. 1987. Parallel networks that learn to pronounce English text. In Complex Systems, pages 1:145–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Taylor</author>
</authors>
<title>Hidden Markov Models for grapheme to phoneme conversion.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th European Conference on Speech Communication and Technology.</booktitle>
<contexts>
<context position="1545" citStr="Taylor, 2005" startWordPosition="217" endWordPosition="218">c form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit information indicating the relationships between individual letter and phonemes, these must be inferred by a letter-phoneme alignment algorithm before a prediction model can be trained. The quality of the alignment affects the accuracy of L2P conversion. Letter-phoneme alignment is closely related to transliteration alignment (Pervouchine et al., 200</context>
</contexts>
<marker>Taylor, 2005</marker>
<rawString>Paul Taylor. 2005. Hidden Markov Models for grapheme to phoneme conversion. In Proceedings of the 9th European Conference on Speech Communication and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Robert C Moore</author>
</authors>
<title>Pronunciation modeling for improved spelling correction.</title>
<date>2001</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>144--151</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1197" citStr="Toutanova and Moore, 2001" startWordPosition="171" endWordPosition="174">the assortment of methods. We show that our proposed EM-Aggregation algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets. 1 Introduction Letter-to-phoneme (L2P) conversion (also called grapheme-to-phoneme conversion) is the task of predicting the pronunciation of a word given its orthographic form by converting a sequence of letters into a sequence of phonemes. The L2P task plays a crucial role in speech synthesis systems (Schroeter et al., 2002), and is an important part of other applications, including spelling correction (Toutanova and Moore, 2001) and speechto-speech machine translation (Engelbrecht and Schultz, 2005). Many data-driven techniques have been proposed for letter-to-phoneme conversion systems, including neural networks (Sejnowski and Rosenberg, 1987), decision trees (Black et al., 1998), pronunciation by analogy (Marchand and Damper, 2000), Hidden Markov Models (Taylor, 2005), and constraint satisfaction (Bosch and Canisius, 2006). Letter-phoneme alignment is an important step in the L2P task. The training data usually consists of pairs of letter and phoneme sequences, which are not aligned. Since there is no explicit info</context>
</contexts>
<marker>Toutanova, Moore, 2001</marker>
<rawString>Kristina Toutanova and Robert C. Moore. 2001. Pronunciation modeling for improved spelling correction. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 144–151, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Improvements in phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Main Proceedings,</booktitle>
<pages>257--264</pages>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="9855" citStr="Zens and Ney, 2004" startWordPosition="1588" endWordPosition="1591">roach tends to create relatively large models, it generates more intuitive alignments and leads to improvement in the L2P accuracy (Jiampojamarn et al., 2007). However, since many links involve multiple letters, it also introduces additional complexity in the phoneme prediction phase. One possible solution is to apply a letter segmentation algorithm at test time to cluster letters according to the alignments in the training data. This is problematic because of error propagation inherent in such a process. A better solution is to combine segmentation and decoding using a phrasal decoder (e.g. (Zens and Ney, 2004)). 1http://code.google.com/p/m2m-aligner/ 4 Phonetic alignment The EM-based approaches to L2P alignment treat both letters and phonemes as abstract symbols. A completely different approach to L2P alignment is based on the phonetic similarity between phonemes. The key idea of the approach is to represent each letter by a phoneme that is likely to be represented by the letter. The actual phonemes on the phoneme side and the phonemes representing letters on the letter side can then be aligned on the basis of phonetic similarity between phonemes. The main advantage of the phonetic alignment is tha</context>
<context position="26411" citStr="Zens and Ney, 2004" startWordPosition="4428" endWordPosition="4431"> The second system is the state-of-the-art online discriminative training for letter-to-phoneme conversion (Jiampojamarn et al., 2008), which accepts both 1-1 and M-M types of alignment. Jiampojamarn et al. (2008) show that the online discriminative training system outperforms a number of competitive approaches, including joint ngrams (Demberg et al., 2007), constraint satisfaction inference (Bosch and Canisius, 2006), pronunciation by analogy (Marchand and Damper, 2006), and decision trees (Black et al., 1998). The decoder module uses standard Viterbi for the 1-1 case, and a phrasal decoder (Zens and Ney, 2004) for the M-M case. We report the L2P performance in terms of word accuracy, which rewards only the completely correct output phoneme sequences. The data set is randomly split into 90% for training and 10% for testing. For all experiments, we hold out 5% of our training data to determine when to stop the online training process. Table 1 includes the results on the Combilex data set. The two rightmost columns correspond to our two test L2P systems. We observe that although better alignment quality does not always translate into better L2P accuracy, there is nevertheless a strong correlation betw</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>Richard Zens and Hermann Ney. 2004. Improvements in phrase-based statistical machine translation. In HLT-NAACL 2004: Main Proceedings, pages 257– 264, Boston, Massachusetts, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>