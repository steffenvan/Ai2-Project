<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006185">
<title confidence="0.996431">
Web-based Interfaces for Natural Language Processing Tools
</title>
<author confidence="0.988805">
Marc Light† and Robert Arens* and Xin Lu*
</author>
<affiliation confidence="0.8144598">
†Linguistics Department
†School of Library and Information Science
*†Computer Science Department
University of Iowa
Iowa, USA 52242
</affiliation>
<email confidence="0.999386">
{marc-light,robert-arens,xin-lu}@uiowa.edu
</email>
<sectionHeader confidence="0.998603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999872625">
We have built web interfaces to a number
of Natural Language Processing technolo-
gies. These interfaces allow students to
experiment with different inputs and view
corresponding output and inner workings
of the systems. When possible, the in-
terfaces also enable the student to mod-
ify the knowledge bases of the systems
and view the resulting change in behav-
ior. Such interfaces are important because
they allow students without computer sci-
ence background to learn by doing. Web
interfaces also sidestep issues of platform
dependency in software packages, avail-
able computer lab times, etc. We discuss
our basic approach and lessons learned.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993476041666667">
The Problem: Natural language processing (NLP)
technology is relevant to non-computer scientists:
our classes are populated by students from neuro-
science, speech pathology, linguistics, teaching of
foreign languages, health informatics, etc. To effec-
tively use NLP technology, it is helpful understand,
at some level, how it works. Hands-on experimen-
tation is an effective method for gaining such under-
standing. Unfortunately, to be able to experiment,
non-computer scientists often need to acquire some
programming skills and knowledge of the Unix op-
erating system. This can be time consuming and
tedious and can distract students from their central
28
goal of understanding how a technology works and
how best to employ it for their interests.
In addition, getting a technology to run on a set
lab machines can be problematic: the programs may
be developed for a different platform, e.g., a pro-
gram was developed for Linux but the lab machines
run MSWindows. Another hurdle is that machine
administrators are often loath to install applications
that they perceive as non-standard. Finally, lab times
can be restrictive and thus it is preferable to enable
students to use computers to which they have easy
access.
Our Solution: We built web interfaces to many
core NLP modules. These interfaces not only al-
low students to use a technology but also allow stu-
dents to modify and extend the technology. This en-
ables experimentation. We used server-side script-
ing languages to build such web interfaces. These
programs take input from a web browser, feed it to
the technology in question, gather the output from
the technology and send it back to the browser for
display to the student. Access to web browsers is
nearly ubiquitous and thus the issue of lab access is
side-stepped. Finally, the core technology need only
run on the web server platform. Many instructors
have access to web servers running on different plat-
forms and, in general, administering a web server is
easier than maintaining lab machines.
An Example: Finite state transduction is a core
NLP technology and one that students need to un-
derstand. The Cass partial parsing system (Abney,
1997) makes use of a cascade of FSTs. To use this
system, a student creates a grammar. This grammar
is compiled and then applied to sentences provided
</bodyText>
<note confidence="0.9505">
Proceedings of the Second ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 28–31,
Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999117">
Figure 1: Web interface to Cass
</figureCaption>
<table confidence="0.983323947368421">
Cass Parse Results
Cass Parse Results
PDS tagging:
The 1 sentence is
The/DT man/NN went/VBD home/NN yesterday/NN ./.
Parser messages (probably none...):
Syntax tagging: (&lt;s&gt; tags surround all sentences by default)
‹s›
[CLAUSE
[NP1
DT The
NN man
1
[VCOMPLEX
VBD went
NN home
NN yesterday
&lt;/s&gt;
%
</table>
<figureCaption confidence="0.965897">
Figure 2: Cass Output
</figureCaption>
<page confidence="0.798092">
29
</page>
<figure confidence="0.782116611111111">
rTh Th Cass Portal
(ass Portal
The man went home yesterday
nter Your Grammer Here.
rammar Explanation
:npl
NEI NN&amp;quot; INN INNS I NNE):
NAME -a NNP-r:
VIENSE = VBD I VBC VBPI VBZ;
VCOMPLEX VTENSE
(MD VBI
(MD VB PEN);
,PP
▪ = NAME NP1:
PP -, IN NR
:np2
NPPP NPI PR,
-EI au se
</figure>
<bodyText confidence="0.999562833333333">
by the student. Prior to our work, the only interface
to Cass involved the Unix command line shell. Fig-
ure 3 shows an example session with the command
line interface. It exemplifies the sort of interface that
users must master in order to work with current hu-
man language technology.
</bodyText>
<equation confidence="0.464809">
1 emacs input.txt &amp;
2 emacs grammar.txt &amp;
</equation>
<footnote confidence="0.91981125">
3source /usr/local/bin/setupEnv
3reg gram.txt
4 Montytagger.py inTagged input.txt
5cat inTagged |
</footnote>
<figure confidence="0.979942">
6 wordSlashTagInput.pl |
7 cass -v -g gram.txt.fsc &gt; cassOut
8 less cassOut
</figure>
<figureCaption confidence="0.999893">
Figure 3: Cass Command Line Interface
</figureCaption>
<bodyText confidence="0.992675">
A web-based interface hides many of the details, see
Figure 1 and Figure 2. For example, the use of an
ASCII-based text editor such as emacs become un-
necessary. In addition, the student does not need
to remembering flags such as -v -g and does not
need to know how to use Unix pipes, |, and out-
put redirection, &gt;. None of this knowledge is ter-
ribly difficult but the amount accumulates quickly
and such information does not help the student un-
derstand how Cass works.
</bodyText>
<sectionHeader confidence="0.663348" genericHeader="method">
2 What we have built
</sectionHeader>
<bodyText confidence="0.7645275">
To date, we have built web interfaces to nine NLP-
related technologies:
</bodyText>
<listItem confidence="0.9936">
• the Cass parser (Abney, 1997),
• the MontyTagger Brill-style part-of-speech tag-
ger (Liu, 2004),
• the NLTK statistical part-of-speech tagger,
• a NLTK context-free grammar parser (Loper
and Bird, 2002),
• the Gsearch context-free grammar parser (Cor-
ley et al., 2001),
• the SenseRelate word sense disambiguation
system (Pedersen et al., 2005),
• a Perl Regular expression evaluator,
• a linguistic feature annotator,
• and a decision tree classifier (Witten and Frank,
1999).
</listItem>
<bodyText confidence="0.99989725">
These interfaces have been used in an introduction
to computational linguistics course and an introduc-
tion to creating and using corpora course. Prior to
the interface construction, no hands-on lab assign-
ments were given; instead all assignments were pen-
cil and paper. The NLP technologies listed above
were chosen because they fit into the material of the
course and because of their availability.
</bodyText>
<subsectionHeader confidence="0.989491">
2.1 Allowing the student to process input
</subsectionHeader>
<bodyText confidence="0.999942705882353">
The simplest type of interface allows students to pro-
vide input and displays corresponding output. All
the interfaces above provide this ability. They all
start with HTML forms to collect input. In the sim-
plest case, PHP scripts process the forms, placing
input into files and then system calls are made to
run the NLP technology. Finally, output files are
wrapped in HTML and displayed to the user. The
basic PHP program remains largely unchanged from
one NLP technology to the next. In most cases, it
suffices to use the server file system to pass data
back and forth to the NLP program — PHP pro-
vides primitives for creating and removing unique
temporary files. In only one case was it necessary to
use a semaphore on a hard-coded filename. We also
experimented with Java server pages and Perl CGI
scripts instead of PHP.
</bodyText>
<subsectionHeader confidence="0.995034">
2.2 Allowing the student to modify knowledge
resources
</subsectionHeader>
<bodyText confidence="0.999658538461539">
The web interfaces to the Cass parser, Gsearch, and
MontyTagger allow the student to provide their cor-
responding knowledge base. For Cass and Gsearch,
an additional text box is provided for the grammars
they require. The rule sequence and lexicon that the
MontyTagger uses can be large and thus unwieldy
for a textarea form input element. We solved
the problem by preloading the textareas with a
“standard” rule sequence and lexicon which the stu-
dent can then modify. We also provided the ability to
upload the rule sequences and lexicon as files. One
problem with the file upload method is that it assume
that the students can generate ASCII-only files with
</bodyText>
<page confidence="0.995827">
30
</page>
<bodyText confidence="0.999803928571429">
the appropriate line break character. This assump-
tion is often false.
An additional problem with allowing students
to modify knowledge resources is providing use-
ful feedback when these student-provided resources
contain syntax or other types of errors. At this point
we simply capture the stderr output of the pro-
gram and display it.
Finally, with some systems such as Spew
(Schwartz, 1999), and The Dada Engine (Bulhak,
1996), allowing web-based specification of knowl-
edge bases amounts to allowing the student to exe-
cute arbitrary code on the server machine, an obvi-
ous security problem.
</bodyText>
<subsectionHeader confidence="0.9751835">
2.3 Allowing the student to examine internal
system processing
</subsectionHeader>
<bodyText confidence="0.999989333333333">
Displaying system output with a web interface is rel-
atively easy; however, showing the internal work-
ings of a system is more challenging with a web
interface. At this point, we have only displayed
traces of steps of an algorithm. For example, the
NLTK context-free grammar parser interface pro-
vides a trace of the steps of the parsing algorithm.
One possible solution would be to generate Flash
code to animate a system’s processing.
</bodyText>
<subsectionHeader confidence="0.964897">
2.4 Availability
</subsectionHeader>
<bodyText confidence="0.999969">
The web pages are currently available at que.info-
science.uiowa.edu/˜light/classes/compLing/ How-
ever, it is not our intent to provide server cycles for
the community but rather to provide the PHP scripts
open source so that others can run the interfaces
on their own servers. An instructor at another
university has already made use of our code.
</bodyText>
<sectionHeader confidence="0.995095" genericHeader="method">
3 Lessons learned
</sectionHeader>
<listItem confidence="0.998846714285714">
• PHP is easier to work with than Java Server
Pages and CGI scripts;
• requiring users to paste input into text boxes is
superior to allowing user to upload files (for se-
curity reasons and because it is easier to control
the character encoding used);
• getting debugging information back to the stu-
dent is very important;
• security is an issue since one is allowing users
to initiate computationally intensive processes;
• it is still possible for students to claim the inter-
face does not work for them (even though we
used no client-side scripting).
• Peer learning is less likely than in a lab set-
</listItem>
<bodyText confidence="0.6975335">
ting; however, we provided a web forum and
this seems to alleviated the problem somewhat.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="method">
4 Summary
</sectionHeader>
<bodyText confidence="0.999878">
At the University of Iowa, many students, who want
to learn about natural language processing, do not
have the requisite Unix and programming skills to
do labs using command line interfaces. In addition,
our lab machines run MSWindows, the instructors
do not administer the machines, and there are restric-
tive lab hours. Thus, until recently assignments con-
sisted of pencil-and-paper problems. We have built
web-based interfaces to a number of NLP modules
that allow students to use, modify, and learn.
</bodyText>
<sectionHeader confidence="0.999452" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999299208333333">
Steven Abney. 1997. Partial parsing via finite-state cas-
cades. Natural Language Engineering, 2(4).
Andrew Bulhak. 1996. The dada engine.
http://dev.null.org/dadaengine/.
S. Corley, M. Corley, F. Keller, M. Crocker, and
S. Trewin. 2001. Finding Syntactic Structure in Un-
parsed Corpora: The Gsearch Corpus Query System.
Computers and the Humanities, 35:81–94.
Hugo Liu. 2004. Montylingua: An end-to-end natural
language processor with common sense. homepage.
Edward Loper and Steven Bird. 2002. Nltk: The natural
language toolkit. In Proc. of the ACL-02 Workshop
on Effective Tools and Methods for Teaching Natural
Language Processing and Computational Linguistics.
Ted Pedersen, Satanjeev Banerjee, and Siddharth Pat-
wardhan. 2005. Maximizing Semantic Relatedness to
Perform Word Sense Disambiguation. Supercomput-
ing institute research report umsi 2005/25, University
of Minnesota.
Randal Schwartz. 1999. Random sentence generator.
Linux Magazine, September.
Ian H. Witten and Eibe Frank. 1999. Data Mining: Prac-
tical Machine Learning Tools and Techniques with
Java Implementations. Morgan Kaufmann.
</reference>
<page confidence="0.999913">
31
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.797100">
<title confidence="0.999376">Web-based Interfaces for Natural Language Processing Tools</title>
<author confidence="0.987617">Xin</author>
<affiliation confidence="0.988602666666667">of Library and Information Science University of</affiliation>
<address confidence="0.829225">Iowa, USA</address>
<abstract confidence="0.999505117647059">We have built web interfaces to a number of Natural Language Processing technologies. These interfaces allow students to experiment with different inputs and view corresponding output and inner workings of the systems. When possible, the interfaces also enable the student to modify the knowledge bases of the systems and view the resulting change in behavior. Such interfaces are important because allow students science background to learn by doing. Web interfaces also sidestep issues of platform dependency in software packages, available computer lab times, etc. We discuss our basic approach and lessons learned.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Partial parsing via finite-state cascades.</title>
<date>1997</date>
<journal>Natural Language Engineering,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="3100" citStr="Abney, 1997" startWordPosition="485" endWordPosition="486">feed it to the technology in question, gather the output from the technology and send it back to the browser for display to the student. Access to web browsers is nearly ubiquitous and thus the issue of lab access is side-stepped. Finally, the core technology need only run on the web server platform. Many instructors have access to web servers running on different platforms and, in general, administering a web server is easier than maintaining lab machines. An Example: Finite state transduction is a core NLP technology and one that students need to understand. The Cass partial parsing system (Abney, 1997) makes use of a cascade of FSTs. To use this system, a student creates a grammar. This grammar is compiled and then applied to sentences provided Proceedings of the Second ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 28–31, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics Figure 1: Web interface to Cass Cass Parse Results Cass Parse Results PDS tagging: The 1 sentence is The/DT man/NN went/VBD home/NN yesterday/NN ./. Parser messages (probably none...): Syntax tagging: (&lt;s&gt; tags surround all sentences by default) ‹s› [CLAUSE [NP1 DT The</context>
<context position="5182" citStr="Abney, 1997" startWordPosition="851" endWordPosition="852">mmand Line Interface A web-based interface hides many of the details, see Figure 1 and Figure 2. For example, the use of an ASCII-based text editor such as emacs become unnecessary. In addition, the student does not need to remembering flags such as -v -g and does not need to know how to use Unix pipes, |, and output redirection, &gt;. None of this knowledge is terribly difficult but the amount accumulates quickly and such information does not help the student understand how Cass works. 2 What we have built To date, we have built web interfaces to nine NLPrelated technologies: • the Cass parser (Abney, 1997), • the MontyTagger Brill-style part-of-speech tagger (Liu, 2004), • the NLTK statistical part-of-speech tagger, • a NLTK context-free grammar parser (Loper and Bird, 2002), • the Gsearch context-free grammar parser (Corley et al., 2001), • the SenseRelate word sense disambiguation system (Pedersen et al., 2005), • a Perl Regular expression evaluator, • a linguistic feature annotator, • and a decision tree classifier (Witten and Frank, 1999). These interfaces have been used in an introduction to computational linguistics course and an introduction to creating and using corpora course. Prior to</context>
</contexts>
<marker>Abney, 1997</marker>
<rawString>Steven Abney. 1997. Partial parsing via finite-state cascades. Natural Language Engineering, 2(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Bulhak</author>
</authors>
<date>1996</date>
<note>The dada engine. http://dev.null.org/dadaengine/.</note>
<contexts>
<context position="8038" citStr="Bulhak, 1996" startWordPosition="1321" endWordPosition="1322"> provided the ability to upload the rule sequences and lexicon as files. One problem with the file upload method is that it assume that the students can generate ASCII-only files with 30 the appropriate line break character. This assumption is often false. An additional problem with allowing students to modify knowledge resources is providing useful feedback when these student-provided resources contain syntax or other types of errors. At this point we simply capture the stderr output of the program and display it. Finally, with some systems such as Spew (Schwartz, 1999), and The Dada Engine (Bulhak, 1996), allowing web-based specification of knowledge bases amounts to allowing the student to execute arbitrary code on the server machine, an obvious security problem. 2.3 Allowing the student to examine internal system processing Displaying system output with a web interface is relatively easy; however, showing the internal workings of a system is more challenging with a web interface. At this point, we have only displayed traces of steps of an algorithm. For example, the NLTK context-free grammar parser interface provides a trace of the steps of the parsing algorithm. One possible solution would</context>
</contexts>
<marker>Bulhak, 1996</marker>
<rawString>Andrew Bulhak. 1996. The dada engine. http://dev.null.org/dadaengine/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Corley</author>
<author>M Corley</author>
<author>F Keller</author>
<author>M Crocker</author>
<author>S Trewin</author>
</authors>
<title>Finding Syntactic Structure in Unparsed Corpora: The Gsearch Corpus Query System. Computers and the Humanities,</title>
<date>2001</date>
<pages>35--81</pages>
<contexts>
<context position="5419" citStr="Corley et al., 2001" startWordPosition="884" endWordPosition="888">bering flags such as -v -g and does not need to know how to use Unix pipes, |, and output redirection, &gt;. None of this knowledge is terribly difficult but the amount accumulates quickly and such information does not help the student understand how Cass works. 2 What we have built To date, we have built web interfaces to nine NLPrelated technologies: • the Cass parser (Abney, 1997), • the MontyTagger Brill-style part-of-speech tagger (Liu, 2004), • the NLTK statistical part-of-speech tagger, • a NLTK context-free grammar parser (Loper and Bird, 2002), • the Gsearch context-free grammar parser (Corley et al., 2001), • the SenseRelate word sense disambiguation system (Pedersen et al., 2005), • a Perl Regular expression evaluator, • a linguistic feature annotator, • and a decision tree classifier (Witten and Frank, 1999). These interfaces have been used in an introduction to computational linguistics course and an introduction to creating and using corpora course. Prior to the interface construction, no hands-on lab assignments were given; instead all assignments were pencil and paper. The NLP technologies listed above were chosen because they fit into the material of the course and because of their avail</context>
</contexts>
<marker>Corley, Corley, Keller, Crocker, Trewin, 2001</marker>
<rawString>S. Corley, M. Corley, F. Keller, M. Crocker, and S. Trewin. 2001. Finding Syntactic Structure in Unparsed Corpora: The Gsearch Corpus Query System. Computers and the Humanities, 35:81–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Liu</author>
</authors>
<title>Montylingua: An end-to-end natural language processor with common sense.</title>
<date>2004</date>
<note>homepage.</note>
<contexts>
<context position="5247" citStr="Liu, 2004" startWordPosition="860" endWordPosition="861">s, see Figure 1 and Figure 2. For example, the use of an ASCII-based text editor such as emacs become unnecessary. In addition, the student does not need to remembering flags such as -v -g and does not need to know how to use Unix pipes, |, and output redirection, &gt;. None of this knowledge is terribly difficult but the amount accumulates quickly and such information does not help the student understand how Cass works. 2 What we have built To date, we have built web interfaces to nine NLPrelated technologies: • the Cass parser (Abney, 1997), • the MontyTagger Brill-style part-of-speech tagger (Liu, 2004), • the NLTK statistical part-of-speech tagger, • a NLTK context-free grammar parser (Loper and Bird, 2002), • the Gsearch context-free grammar parser (Corley et al., 2001), • the SenseRelate word sense disambiguation system (Pedersen et al., 2005), • a Perl Regular expression evaluator, • a linguistic feature annotator, • and a decision tree classifier (Witten and Frank, 1999). These interfaces have been used in an introduction to computational linguistics course and an introduction to creating and using corpora course. Prior to the interface construction, no hands-on lab assignments were giv</context>
</contexts>
<marker>Liu, 2004</marker>
<rawString>Hugo Liu. 2004. Montylingua: An end-to-end natural language processor with common sense. homepage.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Steven Bird</author>
</authors>
<title>Nltk: The natural language toolkit.</title>
<date>2002</date>
<booktitle>In Proc. of the ACL-02 Workshop on Effective Tools and Methods for Teaching Natural Language Processing and Computational Linguistics.</booktitle>
<contexts>
<context position="5354" citStr="Loper and Bird, 2002" startWordPosition="874" endWordPosition="877">ecome unnecessary. In addition, the student does not need to remembering flags such as -v -g and does not need to know how to use Unix pipes, |, and output redirection, &gt;. None of this knowledge is terribly difficult but the amount accumulates quickly and such information does not help the student understand how Cass works. 2 What we have built To date, we have built web interfaces to nine NLPrelated technologies: • the Cass parser (Abney, 1997), • the MontyTagger Brill-style part-of-speech tagger (Liu, 2004), • the NLTK statistical part-of-speech tagger, • a NLTK context-free grammar parser (Loper and Bird, 2002), • the Gsearch context-free grammar parser (Corley et al., 2001), • the SenseRelate word sense disambiguation system (Pedersen et al., 2005), • a Perl Regular expression evaluator, • a linguistic feature annotator, • and a decision tree classifier (Witten and Frank, 1999). These interfaces have been used in an introduction to computational linguistics course and an introduction to creating and using corpora course. Prior to the interface construction, no hands-on lab assignments were given; instead all assignments were pencil and paper. The NLP technologies listed above were chosen because th</context>
</contexts>
<marker>Loper, Bird, 2002</marker>
<rawString>Edward Loper and Steven Bird. 2002. Nltk: The natural language toolkit. In Proc. of the ACL-02 Workshop on Effective Tools and Methods for Teaching Natural Language Processing and Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Satanjeev Banerjee</author>
<author>Siddharth Patwardhan</author>
</authors>
<title>Maximizing Semantic Relatedness to Perform Word Sense Disambiguation. Supercomputing institute research report umsi 2005/25,</title>
<date>2005</date>
<institution>University of Minnesota.</institution>
<contexts>
<context position="5495" citStr="Pedersen et al., 2005" startWordPosition="896" endWordPosition="899">, |, and output redirection, &gt;. None of this knowledge is terribly difficult but the amount accumulates quickly and such information does not help the student understand how Cass works. 2 What we have built To date, we have built web interfaces to nine NLPrelated technologies: • the Cass parser (Abney, 1997), • the MontyTagger Brill-style part-of-speech tagger (Liu, 2004), • the NLTK statistical part-of-speech tagger, • a NLTK context-free grammar parser (Loper and Bird, 2002), • the Gsearch context-free grammar parser (Corley et al., 2001), • the SenseRelate word sense disambiguation system (Pedersen et al., 2005), • a Perl Regular expression evaluator, • a linguistic feature annotator, • and a decision tree classifier (Witten and Frank, 1999). These interfaces have been used in an introduction to computational linguistics course and an introduction to creating and using corpora course. Prior to the interface construction, no hands-on lab assignments were given; instead all assignments were pencil and paper. The NLP technologies listed above were chosen because they fit into the material of the course and because of their availability. 2.1 Allowing the student to process input The simplest type of inte</context>
</contexts>
<marker>Pedersen, Banerjee, Patwardhan, 2005</marker>
<rawString>Ted Pedersen, Satanjeev Banerjee, and Siddharth Patwardhan. 2005. Maximizing Semantic Relatedness to Perform Word Sense Disambiguation. Supercomputing institute research report umsi 2005/25, University of Minnesota.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randal Schwartz</author>
</authors>
<title>Random sentence generator. Linux Magazine,</title>
<date>1999</date>
<contexts>
<context position="8002" citStr="Schwartz, 1999" startWordPosition="1315" endWordPosition="1316">h the student can then modify. We also provided the ability to upload the rule sequences and lexicon as files. One problem with the file upload method is that it assume that the students can generate ASCII-only files with 30 the appropriate line break character. This assumption is often false. An additional problem with allowing students to modify knowledge resources is providing useful feedback when these student-provided resources contain syntax or other types of errors. At this point we simply capture the stderr output of the program and display it. Finally, with some systems such as Spew (Schwartz, 1999), and The Dada Engine (Bulhak, 1996), allowing web-based specification of knowledge bases amounts to allowing the student to execute arbitrary code on the server machine, an obvious security problem. 2.3 Allowing the student to examine internal system processing Displaying system output with a web interface is relatively easy; however, showing the internal workings of a system is more challenging with a web interface. At this point, we have only displayed traces of steps of an algorithm. For example, the NLTK context-free grammar parser interface provides a trace of the steps of the parsing al</context>
</contexts>
<marker>Schwartz, 1999</marker>
<rawString>Randal Schwartz. 1999. Random sentence generator. Linux Magazine, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>1999</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="5627" citStr="Witten and Frank, 1999" startWordPosition="917" endWordPosition="920">n does not help the student understand how Cass works. 2 What we have built To date, we have built web interfaces to nine NLPrelated technologies: • the Cass parser (Abney, 1997), • the MontyTagger Brill-style part-of-speech tagger (Liu, 2004), • the NLTK statistical part-of-speech tagger, • a NLTK context-free grammar parser (Loper and Bird, 2002), • the Gsearch context-free grammar parser (Corley et al., 2001), • the SenseRelate word sense disambiguation system (Pedersen et al., 2005), • a Perl Regular expression evaluator, • a linguistic feature annotator, • and a decision tree classifier (Witten and Frank, 1999). These interfaces have been used in an introduction to computational linguistics course and an introduction to creating and using corpora course. Prior to the interface construction, no hands-on lab assignments were given; instead all assignments were pencil and paper. The NLP technologies listed above were chosen because they fit into the material of the course and because of their availability. 2.1 Allowing the student to process input The simplest type of interface allows students to provide input and displays corresponding output. All the interfaces above provide this ability. They all st</context>
</contexts>
<marker>Witten, Frank, 1999</marker>
<rawString>Ian H. Witten and Eibe Frank. 1999. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>