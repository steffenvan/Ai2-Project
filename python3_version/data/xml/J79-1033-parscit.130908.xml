<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.833308">
American Journal of Computational Linguistics Microfiche 33
</note>
<sectionHeader confidence="0.98733925" genericHeader="abstract">
PROCEEDINGS
13TH ANNUAL rIEETING
ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
2: LANGUAGE GENERATION SYSTEMS
</sectionHeader>
<note confidence="0.443203">
Timothy C. Diller, Editor
Sperry-Univac
St. Paul, Minnesota 55101
Copyright 0 1975 by the Association for Computational Linguistics
PREFACE
</note>
<title confidence="0.335960538461538">
The papers comprising this microfiche (the second of
five) present in expanded form (as submitted by their
authors) the six talks given in Session 2: Language Gene-
ration Systems. Various aspects of generation are consi-
dered, among them: relationsHips between parsing and
generation (Knaus), planning modules and data structures
basic to story development (Meehan), semantic networks and
linguistic generator t (Shapiro and Slocum), message struc-
tures and translation strategies (MeDonald), and lexical
processes in compound noun formation (Rhyne). Thanks to
Martin Kay for chairing this session.
Timothy C. Diller
Program Committee Chairman
</title>
<page confidence="0.696157">
2
</page>
<note confidence="0.410358">
3
TABLE OF CONTENTS
SESSION at LANGUAGE GENERATION SYSTEMS
</note>
<title confidence="0.704641222222222">
A Ptediework for Writing Generation Grammars for Inter-
active Computer Programs David McDonald • . • • • • . 4
Incremental Sentence Processing Rodger Knaus . . . . . 18
A:Lexical Process Model of Nominal Compounding in
English James R. Rhyne . . &apos; • . • • • . , . . . . 33
Generation as Parsing from a Network into a Linear
String Stuart C. Shapiro . • • • • • • • .• • • . . 45
Speech Generation from Semantic Nets Jonathan Slocum . . . 63
Using Planning Structures to Generate Stories James R.
</title>
<author confidence="0.876683">
Meehan . • • • • • . . 78
</author>
<affiliation confidence="0.656339">
American Journal of Computational Linguistics Microfiche 33 : 4
</affiliation>
<sectionHeader confidence="0.9714625" genericHeader="method">
A FRAMEWORK FOR WRITING GENERATION GRAMMARS FOR INTERACTIVE
COMPUTER PROGRAMS
</sectionHeader>
<author confidence="0.760776">
DAVID MCDONALD
</author>
<affiliation confidence="0.869654333333333">
Artificial Intelligence Laboratory
Massachusetts Institute of Technology
Cambridge, Massachusetts 02139
</affiliation>
<sectionHeader confidence="0.925833" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.98743347368421">
This paper outlines the stucture and operation of the
linguistic component from a language generation system in an
interactive program. The component receives messages
describing what is to be said formulated in the
representation of the main program and produces fluent
English utterances appropriate to the current discourse
situation. The component is data-directed and uses a
procedural grammar, organized as a set of strategies.
Interactive, specialist programs presently under development will
need to produce fluent, intentional English utterances in responce to
particular, complex situations. This creates a requirement for language
generating facilities that Is not faced in transformational grammar,
mechanical translation programs, or paraphrase generating programs. As
A component of an interactive, specialist program, the production of the
English must be driven directly by the communicative intentions of the
program and by the discourse situation.
We can imagine that the overall program consists of a number of
cooperating modules - for parsing and interpreting what is said to it,
for solving problems in its domain, for managing its memory, and, in
</bodyText>
<page confidence="0.644207">
5
</page>
<tableCaption confidence="0.75181325">
particular, for generating utterances to communicate with its users.
This generation component can be profitably viewed as having three
aspects or &amp;quot;sub-components&amp;quot;.
1) Situation/domain specialists that are activated when the program
</tableCaption>
<bodyText confidence="0.985436777777778">
recognizes what situation it is in. They then decide what message
will be produced. They will decide what effect on the listener is
desired, and exactly what objects and relations are to be mentioned.
For example, an appointment scheduling program might be told to
wscrleaule a group meeting for Friday&amp;quot; and then find that a critical
member of the group is unavailable. The situation specialists in
the scheduling program are the ones to decide whether it is more
appropriate to simply say &amp;quot;1 can&apos;t&amp;quot;, or whether to volunter
Information - &amp;quot;1 can&apos;t, Mitch won&apos;t be back until Monday.
</bodyText>
<listItem confidence="0.735074">
2) Models of the audience and the discourse situation to use in
constructing utterances. There must be a record of the past
</listItem>
<bodyText confidence="0.973972">
conversation to guide in the selection of pronouns. Also, the
program must have models of, and heuristics about what the audience
already knows and therefore doesn&apos;t have to be told. This
information say be very specific and domain dependent. For example,
in chess, one can say &amp;quot;the white queen could take a knight&amp;quot;. There
is no need to say &amp;quot;a black knight&amp;quot;, because this information is
supplied by inferences from what one knows about chess - inferences
that the speaxer assumes the listener shares.
3) Linguistic knowledge about how to construct understandable utterances
in the English language. Obviously, this information will include a
lexicon associating objects and relations from the main program with
strategies for realizing them in English (part-icular words, phrases,
</bodyText>
<page confidence="0.854405">
6
</page>
<bodyText confidence="0.99490975">
syntactic constructions, etc.). There is also a tremendous amount
of information which describes the characteristics of the English
language and the conditions of its use. It specifies the allowable
arrangements of strategies and what modifications or alternatives to
them may be appropriate in particular circumstances.
Of the three aspects just described, my work has concentrated on
the third. What follows is drawn from my thesis (McDonald &apos;75) and from
ongoing research.
</bodyText>
<subsectionHeader confidence="0.658337">
Inue Linguistic Component
</subsectionHeader>
<bodyText confidence="0.963614764705882">
The linguistic knowledge required for generating utterances is put
into one component whose Job is to take a message from the situation
specialists and construct a translatioa of that message in English. The
messages are in the representation used by the main program and the
situation specialists. The translation is done by a data-directed
process wherein the elements and structure of the message itself provide
the control.
The design of the linguistics component was arrived at independent
of any particular main program, for the simple reason that no programs
of adequate complexity were available at the time. However, at the
present time a grammar and lexicon Is being developed to use with at
least two programs being developed by other people at MIT. They are an
appointment scheduling program (Goldstein &apos;75) and an advisor to aid
users of MACSYMA (Genesereth &apos;75). The short dialog below is an example
of the degree of fluency we are hoping to eventually achieve. The
dialog ts between a scheduling program acting as an appointment
secretary (P), and a student (5).
</bodyText>
<page confidence="0.828251">
7
</page>
<note confidence="0.4560682">
(S) I want to see Professor Winston sometime in the next few days.
(P) He&apos;s pretty busy all week. Can it wait?
(S) No, it can&apos;t. All I need is his signature on a form.
(P) Well, maybe he can squeeze you in tommorrow morning. Give me
your name and check back in an hour.
</note>
<subsectionHeader confidence="0.592564">
Messages
</subsectionHeader>
<bodyText confidence="0.8233298">
Using the current message format and ignoring the details of the
scheduler&apos;s representation, the phrase &amp;quot;maybe he can squeeze you in
tommorrow&amp;quot; could have come from a message like this one, put together by
one of the situation specialists.
Message-1 features z ( prediction )
event (event actor &lt;Winston&gt;
action &lt;fit person-into full schedule&gt;
time &lt;31-10-75,9am-12am&gt;)
hedge &lt;is possible&gt;
aim-at-audience hedge
</bodyText>
<subsectionHeader confidence="0.5155305">
Messages have features describing the program&apos;s communicative intentions
what sort of utterance is this to be; what effect is it to have.
</subsectionHeader>
<bodyText confidence="0.990796">
Messages list the objects to be described (the right hand column) along
with annotations for each object (left hand column) to show how they
relate to the rest of the message. The phrases on the right in angle
brackets represent actual structures from the scheduler with those
meanings.
</bodyText>
<subsectionHeader confidence="0.957698">
Time Lexicon
</subsectionHeader>
<bodyText confidence="0.918065583333333">
Translation from the internal representaiton of a computer program
to natural language has the same sort of problems as translating between
two natural languages. The same concepts may not be available as
primitives in both representations, and the conventions of the target
language may require additional information that was not in the source.
Generally speaking translation cannot be one for one.
a
What English phrase is best for a particular element in a program&apos;s
message will depend on what is in the rest of the message and of what
the external conteet is. In such circumstances, translation by table-
lookup is inadequate. In this component, in order to allow all factors
to be considered, the translation of each element rs done by
individualized procedures called &amp;quot;composers&amp;quot;.
For each main program that the linguistic component becomes
associated with, a lexicon must be created which will list the elements
of the main program&apos;s representation that could appear in a message
(i.e. &amp;quot;prediction&amp;quot;,&amp;quot;event&amp;quot;,&amp;quot;&lt;Winston&gt;&amp;quot;, etc.). With each element is
recorded the composer that will be run when the time comes to produce an
English description for it (examples will be given shortly). Some
composers may be applicable for a whole class of elements, such as
&amp;quot;events&amp;quot;. They would know the structure that all events have in common
(e.g. actor, action, time) and would know how to interpret the
idiosyncratic details of each event by using data in the lexicon
associated with them.
</bodyText>
<subsectionHeader confidence="0.840987">
The Grammar - strategies
</subsectionHeader>
<bodyText confidence="0.952065357142857">
The bulk of the grammar consists of &amp;quot;strategies&amp;quot;. Strategies are
associated with particular languages rather than with particular main
programs as composers are. A given strategy may be used for several
different purposes. A, typical case is the strategy use-simple-present-
tense: a clause in the simple present (&amp;quot;prices rise&amp;quot;) may be understood
as future, conditional, or timeless, according to what other phrases are
present.
Each composer ray know of several strategies, or tombinations of
stTategies which it could use in describing an element from the message.
It will choose between then according to the context — usually details
of the element or syntactic constraints imposed by previously selected
strategies. The strategies themselves do no reasoning; they are
implemented as functions which the composers call to do all the actual
Construction of the utterance.
</bodyText>
<subsectionHeader confidence="0.49491">
The Translation Process
</subsectionHeader>
<bodyText confidence="0.999787909090909">
At this point, the outline of the data-driven translation process
can be summarized. A message is given for translation. The elements of
the message are associated in a lexicon with procedures to describe
them. The procedures are run; they call grammatical strategies; and
the strategies construct the English utterance.
Of course, if this were all there was to it, the process would
never run, because all of the subprocesses must be throughly coordinated
if they are not to &amp;quot;trip over their own feet&amp;quot;, or, for that matter, if
ordinary human beings are to be able to design them. In a system where
the knowledge of what to do is distributed over a large number of
separate procedures, control structure assumes central importance.
</bodyText>
<subsectionHeader confidence="0.879874">
Plane
</subsectionHeader>
<bodyText confidence="0.980495">
Before describing the control structure, I must lay out some
additional aspects of the design of the linguistics component. Messages
are translated directly into English surface structure form. There is no
interlingua or intermediate level of structure comparable to the deep
structures of Transformational Grarmar, or the semantic nets of Simmons
(73) or Goldman (74).
Determining the appropriate surface structure, however, requires
planning, if for no other reason than that the message can only be
</bodyText>
<page confidence="0.696796">
10
</page>
<bodyText confidence="0.974238416666667">
examined one piece at a time. The entire utterance must be organized
before a detailed analysis and translation can get underway. As this is
done, the &amp;quot;proto-utterance&amp;quot; is represented in terms of a sort of
scaffolding - a representativ of the ultimate surface structure tree
insofar as its details are known with extensive annotation, explicit and
implicit, to point out where elements that are not yet described may be
positioned, and to implement the grammatical restrictions on possible
future details as dictated by what has already been done.
The scaffolding that is constructed in the translation of each
message is called its &amp;quot;plan&amp;quot;. Plans are made up of syntactic nodes of
the usual sort - clauses, noun groups, etc. - and nodes may have
features in the manner of systemi:# grammar (Winograd &apos;72). Nodes have
</bodyText>
<subsectionHeader confidence="0.89045">
subplans consisting of a list of named slots marking the possible
positions for sub-constituents, given in the order of the eventual
</subsectionHeader>
<bodyText confidence="0.927072">
surface structure. Possible slots would be &amp;quot;subject&amp;quot;, &amp;quot;main verb&amp;quot;,
&amp;quot;noun head&amp;quot;, &amp;quot;pre-verb-adverb&amp;quot;, and so on. The syntactic node types
will each have a number of possible plans, corresponding v to the
different possible arrangements Or sub-constituents that may occur with
the different combinations of features that the nbde may have.
Depending on the stage of the translation process, a slot may be
&amp;quot;filled&amp;quot; with a pointer to an Internal object from the message, a
syntactic node, a word or idiom, or nothing.
</bodyText>
<subsectionHeader confidence="0.786948">
The translation &apos;process
</subsectionHeader>
<bodyText confidence="0.998394666666667">
The translation is done in two phases. The second phase does not
begin until the first is completely finished. During the first phase, a
plan is selected and the elements of the message are transferred,
</bodyText>
<page confidence="0.847633">
11
</page>
<bodyText confidence="0.991070807692308">
largely untouched; to the slots of the plan and features added to its
nodes. During the second phase, the plan is Nalked&amp;quot; topdown and from
left to right. Compostrs for message elements in the plan&apos;s slots are
activated to produce English descriptions for the elements as they are
reached in turn. Both processes are data-directed, the first by the
particular contents of the message and the secpnd by the structure of
the plan and the contents of its slots.
There are sound linguistic reasons for this two stage processing.
Most parts of a message may be translated in terms of very modular
syntactic and lexical units. But other parts are translated in terns of
relations between such units, expressed usually by ordering or clause-
level syntactic mechanisms. Th t exact form of the smaller units cannot
be determined until their larger scale relations have been fixed.
Accordingly, the objective of the first phase is to determine what
global relationships are required and to choose the plan, features, and
positions of message elements within the plan&apos;s slots that will realize
those relationships. Once this has been done, English descriptions for
the elements can be made independent of each other and will not need to
be changed after they are initially created.
One of the most important features of natural language is the
ability to omit, pronominalize, or otherwise abbreviate elements in
certain contexts. The only known rules and huristics for using this
feature are phrased in terms of surface structure configurations and
temporal ordering. Because the second phase works directly in these
terms, stating and using the available heuristics becomes a
straightforward, tractable problem.
</bodyText>
<page confidence="0.709682">
12
</page>
<bodyText confidence="0.8732319">
&amp;quot;Maybe he can squeeze you in tommorow morning&amp;quot;
The rest of this paper will try to put some flesh on your picture
of how this linguistics component works by following the translation of
the message given in the beginning to the sentence above. The message
was this.
message-1 features= ( prediction )
event (event actor &lt;Winston&gt;
action &lt;fit person into full schedule&gt;
time &lt;31-10-75,9am-12am&gt;)
heOge &lt;is possible&gt;
aim-at-audience hedge
The intentional features of a message tend to require the most global
representation in the final utterance, because tbat is where indicators
for questions, special emphasis, special formats e.g.( comparison), and
the like will be found. By convention then, the composers associated
with the intentions are given the job of arranging for the disposition
of all of the message elements. The total operation of phase one
consists of executing the composer associated with each feature, one
after the other.
This message has only one feature, so its composer will assume all
the work. The linguistics component is implemented in MACL1SP, features
(and annotations and slots and nodes) are atoms, and composers are
functions on their property lists.
Prediction
composer-with (lambda ... )
Making a prediction is a speech act, and we may expect there to be
particular forms in a language for expressing them, for example, the use
of the explicit &amp;quot;will&amp;quot; for the future tense. Knowledge of these would
De part of the composer. Inside the main program, or the situation
specialist, the concept of a prediction may always include certain
</bodyText>
<page confidence="0.824993">
13
</page>
<bodyText confidence="0.935814714285714">
parts: what is predicted, the time, any hedges, and so on. These part
are directly reflected in thc makeup of the elements present in the
message, and their annotations mark what internal roles they have.
There does not need to be a direct correspondence between these and the
parts in the linguistic forms used, the actual correspondence is part of
the knowledge of the prediction composer.
Typically, for any feature, one particular annotated element will
be of greatest importance in seting the character of the whole
utterance. For predictions, this is the &amp;quot;event&amp;quot;. The prediction
composer chooses a plan for the utterance to fit the requirements of the
event-element. The realization of any other elements will be restricted
to be compatible with it.
The prediction composer does not need to know the element&apos;s
linguistic correlates itself, it can delegate the work to the composer
for the element itself. The element look like this.
(event actor &lt;Winston&gt;
action &lt;fit person into full schedule&gt;
time &lt;31-10-75,9am-12am&gt;)
The first word points to the name of the composer, and the pairs give
particular details. There is nothing special about the words used here
(actor, action, time), just as long as the composer is designed to
expect the information in those places that the message-assembler wants
to put it. The event composer&apos;s strategy is to use a clause, and the
choice of plan is determined by the character of the event&apos;s &amp;quot;action&amp;quot;
The action is &amp;quot;&lt;fit person into full schedule&gt;&amp;quot;, and it will have
two relevant properties in the lexicon: &amp;quot;plan&amp;quot;, and &amp;quot;mapping&amp;quot;. Illan is
either the name of a standard plan to be used, or an actual plan,
partially filled with words (i.e. it can be a phrase). &amp;quot;Mapping&amp;quot; is an
</bodyText>
<page confidence="0.767065">
14
</page>
<bodyText confidence="0.7608415">
association list showing how the subelements of the message are to be
transferred to the plan.
</bodyText>
<figure confidence="0.777162">
&lt;fit person into full schedule&gt;
PLAN
node-i (clause transl particle)
slots frontings nil
subject nil
vg node-j (verb-group particle)
slots modal nil
pre-vb-adv nil
mvb &amp;quot;squeeze&amp;quot;
prt &amp;quot;in&amp;quot;
objectl &lt;person being talked about&gt;
post-modifiers nil
MAPPING
(( &amp;ctor subject )
( time post-modifiers))
</figure>
<bodyText confidence="0.989087764705882">
The event composer proceeds to Instanticte the nodes in the phrase and
make the transfers; the prediction composer then takes the resulting
plan, and makes it the plan of the whole utterance.
Two message elements remain, but actually there is only one,
because &amp;quot;aim-at-audience&amp;quot; is supplying additional information about the
hedge, The annotation means that the contents of the hedge ((is
possible&gt;) are more something that we want to tell the audience than a
detail of the prediction. This will affect how the element is
positioned in the plan.
The prediction composer looks in the lexicon to see what
grammatical unit will be used to realize &lt;is possible&gt;, and sees, let us
say, two possibilities involving different configurations of the adverb
&amp;quot;maybe&amp;quot; and the modal &amp;quot;can be able to&amp;quot;, with the differences hinging
on the placement of the adverb. Theoretically, adverbs can be
positioned in a number of places in a clause, depending on their
characteristics. In this instance, the choice is forced because of a
heuristic written into the grammar of adverbs and accessible to the
</bodyText>
<page confidence="0.620004">
15
</page>
<bodyText confidence="0.988072161290322">
composer, that says that when the intent of an adverb is directed to the
audience, it should be in the first position (the &amp;quot;frontings&amp;quot; slot).
This choice Implies putting &amp;quot;can&amp;quot; in the modal slot directly. The
alternative with &amp;quot;maybe&amp;quot; in the pre-vb-adv slot would have necessitated
a different form of the modal, yielding &amp;quot;say be able to&amp;quot;, These details
would have been taken care o-r. by syntactic routines associated with the
verb group node.
All the message elerents have been placed and the first phase is
over. The plan is now as below.
node-I (clause transl particle)
slots frontings &amp;quot;maybe&amp;quot;
subject cwinston&gt;
vg node-2 (verb-group particle)
slots modal &amp;quot;can&amp;quot;
pre-vb-adv nil
mvb &amp;quot;squeeze&amp;quot;
prt &amp;quot;in&amp;quot;
objecti &lt;person being talked about)
post-modifiers nil
The second phase controller is a simple dispaching function that moves
from slot to slot. &amp;quot;Frontings&amp;quot; contains a wora, so the word is printed
directly (there is a trap for morphological adjustments when necessary).
&amp;quot;Subject&amp;quot; contains an internal object, so the controller should go to
the lexicon for its composer and then come back to handle whatever the
composer replaced the element with.
However, there is always an intervening step to check for the
possibility of pronominalizing. This check is rade with the element
still in its internal form. The record of the discourse is given
directly in terms of the internal representation and test for prior
accurence can be as simple as identity checks against a reference list,
avoiding potentially intricate string matching operations with words.
</bodyText>
<page confidence="0.632354">
16
</page>
<bodyText confidence="0.976916777777778">
In the dialog that this message came from, there is clear reference to
&lt;winSton), so it can be pronominalized and &amp;quot;he&amp;quot; is printed.
Any slot, or any node type may have procedures associated with it
that are executed when the slot or node is reached during the second
phase. These procedures will handle syntactic processes like agreement,
rearangement of slots to realize features, add function words, watch
Scope relationships, and in particular, position the particle in verb-
particle pairs.
Generally, particle position (&amp;quot;squeeze John in&amp;quot; vs. &amp;quot;squerze in
John&amp;quot;) is not specified by the grammar - except when the object is a
pronoun and the particle must be displaced. This, of course, will not
be known untill after the verb group has been passed. To deal with
this, a subroutine in the &amp;quot;when-entered&amp;quot; procedure of the verb group is
activated by the &amp;quot;particle&amp;quot; procedure. First, it records the particle
and removes it from the VG plan so it will not be generated
automatically. A &amp;quot;hook&amp;quot; is available on any slot for a, procedure which
can be run after pronominalization is checked and before the composer is
called (if it is to be called). The subroutine incorporates the
particle into a standard procedure and places it on that hook for the
objectl slot. The procedure will check if the object has been printed
as a pronoun, and if so, prints out the particle (which is now in the
proper displaced position). If the object wasn&apos;t pronominalized, then
it does nothing, nothing has yet been printed beyond the verb group, and
other heuristics will be free to apply to choose the proper position.
Since &lt;person being talked about&gt; is here equal to the student, the
person the program is talking with, it is realized as the pronoun &amp;quot;you&amp;quot;
and the particle is displaced.
</bodyText>
<page confidence="0.608157">
17
</page>
<bodyText confidence="0.9984035">
Going from &lt;31-10-75,9am-12am&gt; to &amp;quot;tomorrow morning&amp;quot; may be little
more than table lookup by a &amp;quot;time&amp;quot; composer that has been designed tv
know the formats of the time expressions inside the scheduler.
This presentation has had to be unfortunately short for the amount
of new material involved. A large number of interesting details and
questions about the processing have had to be omitted. At the torient
(September, 1975), the data and control structures mentioned have been
fully implemented and tests are underway on gedanken data. Hopefully,
by the end of 1975 the component will have a reasonable grarnar and will
be working with messages and lexicons form the two programs mentioned
before. A MIT A. I. lab technical report describing this work in depth
should be ready in the spring of next year.
</bodyText>
<subsectionHeader confidence="0.624108">
David McDonald
Cavbridge, Mass.
</subsectionHeader>
<bodyText confidence="0.928849666666667">
References cited in the text:
Genesereth, M. (1975) A MACSYMA Advisor. Project MAC, MIT, Cambridge,
Mass.
Goldman, N. (1774) &amp;quot;Computer Generation of Natural Language from a Deep
Conceptual Base&amp;quot;. memo AIM-247, Stanford Artificial Intelligence
Lab., Stanford, Calif.
Goldstein, I. (1975) &amp;quot;Barganing Between Goals&amp;quot;. in the proceedings of
IJCAI-4, available from the MIT Al lab.
McDonald, D. (1975) The Design of a Program for Generating NatL.ml
Language. unpublished Master&apos;s Thesis, MIT Dept. of Electical
Engineering.
Simmons, R. (1973) &amp;quot;Semantic Networks: Their Computation and Use for
</bodyText>
<subsectionHeader confidence="0.99746">
Understanding English Sentences&amp;quot;. in Schank and Colby eds.
Computer Models of Thought and Language.
</subsectionHeader>
<bodyText confidence="0.810112">
Winograd, T. (1972) Understanding Natural Language. Academic Press, New
York, NY.
American Journal of Computational Linguistics Microfiche 33 : 18
</bodyText>
<sectionHeader confidence="0.9949445" genericHeader="method">
INCREMENTAL SENTENCE PROCESSING
RODGER KNAUS
</sectionHeader>
<subsectionHeader confidence="0.942516333333333">
Systems Software Division
Social and Economic Statistics Administration
Bureau of the Census
</subsectionHeader>
<bodyText confidence="0.983253428571429">
Washington, D. C. 20233
A human who learns a language can both parse and generate
sentences in the language. In contrast most artificial lan-
guage processors operate in one direction only or require
separate grammars for parsing and generation. This paper
describes a model for human language processing which uses
a single language description for parsing and generation.
</bodyText>
<listItem confidence="0.614815">
1. Choice of Parsing Strategy
</listItem>
<bodyText confidence="0.99727525">
A number of constraints limit the processors suitable as
models of human language processing. Because short term
memory is limited, the listener must absorb incoming words
into larger chunks as the sentence is heard. Also because
he is expected to reply within a couple seconds after the
speaker finishes, regardless of length of the speaker&apos;s
utterance, the listener must do much of the semantic proc-
essing of a sentence as he hears it.
</bodyText>
<page confidence="0.357365">
19
</page>
<subsectionHeader confidence="0.737297">
Bever and Watt point out that the difficulty in under-
</subsectionHeader>
<bodyText confidence="0.99661925">
standing a sentence S is not predicted by the number of
transformations used to generate S. Furthermore the process
of detransformation appears too time-consumin9 (Petrick) for
the approximately two seconds before a listener is expected
to reply.
A depth first transition network parser (Woods, Kaplan),
in which parsing difficulty is measured by the number of arcs
traversed, correctly predicts the relative difficulty of
active and passive sentences progressive and adjectival presEnt
participle sentences and the extreme difficulty of multiple
center embeddings. However a syntactically directed depth
first parser does not explain why syntactically similar
</bodyText>
<subsectionHeader confidence="0.93676">
sentences such as
</subsectionHeader>
<bodyText confidence="0.998786727272727">
(5A) The horse sold at the fair escaped.
(BB) The horse raced past the barn fell.
vary in difficulty, nor does it explain experiments on the
completion and verification of ambiguous sentences (MacKay,
Olsen and MacKay) which suggest that a pruned breadth first
strategy is used to pane sentences. Sentences with two
equally plausible alternatives took longer to process than
sentences With only one likely interpretation. This extra
processing time may be attributed to the construction of two
alternate interpretations over a longer portion of t[)e s•entence
when more than one interpretation is plausible.
</bodyText>
<subsectionHeader confidence="0.856216">
In addition subjec-ts sometimes become confused by the two
</subsectionHeader>
<bodyText confidence="0.978668666666667">
interpretations of an ambiguous sentence. Finally in experi-
ments in which subjects hear an ambiguous sentence in ore ear
and a disimbiguating sentence simultaneously in the other ear
(Garrett) the interpretation of the ambiguity actually per-
ceived by the subject may be switched between the possibilities
by changing the disambiguating sentences.
</bodyText>
<subsectionHeader confidence="0.396302">
21
</subsectionHeader>
<bodyText confidence="0.883036">
Step 3 (a): (S OP (N mail) (N Boxes))
(V like) (.NP) (PP*))
</bodyText>
<listItem confidence="0.914435">
(b): (S (NT (NP (N mail) (N Boxes))
(PP (PREP like) NP) (PP*))
V(NP) (pp*))
(c): (S (NP (N mail)) (V Boxes)
(PP (PREP like) NP) (PP*))
(d): (S (V mail) (RP (N Boxes))
(PP (PREP like) NP) (PP*))
(e): (S (V mail)
(NP (NP (N Boxes))
</listItem>
<bodyText confidence="0.971091306122449">
(PP (PREP like) NP) (pp*))
(PI&amp;quot;))
After completing the sentence after Step 4, the parser
produces phrase markers from a, c, d and e by adding the last
word and deleting unfilled optional nodes. The phrase marker
obtained from 4B is rejected because it contains an unfilled
obligatory V node.
The incremental parser adds each successive sentence word
to the partially completed phrase markers built from the earlier
part of the sentence. The new word is added at the leftmost oblig
unfilled node of each partial phrase marker and at all optional
nodes to the left of this node.
Three different operations are used to add a new word to
a partial parse. The word may be directly added to an unexpanded
node, as in Step 3a above. Alternatively, a new word may be
attached to an unfilled node with a left branching acyclic tree
built from the grammar such as (PP PREP NP) or (S (NP N. (N*)) V
(NP) (PP*)). Attaching occurs in steps 1 and 3c.
Finally a subtrke of an existing partial phrase marker
may be left embedded in a larger structure of the same gram-
matical category, as in steps 3b and 3e above. The embedding
operation uses at most two left branching trees built from the
22
grammar: a tree Ti with a single cycle on the left branch is
used to replace the existing subtree E being embedded. In
step 3e, for example, the structure (S (V mail) (NP NP (PP*))
(PP*)) would be obtained. The E is used to expand the left-
most unexpanded node of T1 for 3 la this results in:
3e. (S (V mail) (NP (NP (N Boxes) (N*)) PP*) (PP*)).
Finally to the resulting structure the new sentence word is
added through direct node expansion or attaching with an
Acyclic left branching tree; in the example above this produces
3e from 3e:
Using direct expansion attaching and embedding, the
incremental parser finds all the phrase markers of sentences
in context free or regular expression language; a formal
definition of the parser and a proof of its correctness appear
in [10].
Sometimes, as at steps 3b and 3e, the same structure (a
prepositional phrase in step 2) is used in more than one partial
parse. Following Earley&apos;s Algodrithm, the incremental parser
builds a single copy of the shared substructure SO and maintains
pointers linking SO to nodes in larger structures which SO
expands.
For all its tree building operations the incremental parser
uses a finite set of trees i.e., the trees with only left sub-
nodes expanded and at most oneicycle on the leftmost branch.
These trees may be computed directly from the grammar and ref-
erenced by root and leftmost unexpanded node during the parse.
</bodyText>
<subsectionHeader confidence="0.449595">
23
</subsectionHeader>
<bodyText confidence="0.998494777777778">
Using these preconstructed trees, the incremental parser requires
only a fixed number of operations to add a new word to a partial
parse: a retrieVIal on a doubly indexed set, copying the left
branching tree, and at most four structure changing operations
+0 paste words and trees together.
Like Earley&apos;s Algorithm, IP processes each word proportion-
ally to sentence length. However on sentences satisfying a depth
difference bound, the parsing time per word is constant. Because
humans can&apos;t remember large numbers of sentence words but must,
process speech at an approximately constant rate, a constant
parsing time per word is a necessary property of any algorithm
modeling human language processing.
Let the depth of constituent C in phrase marker P be
defined as the length of the path from the root of C to the root
of P. If TI and T2 are two adjacent terminals with Ti preceding
T2, the depth difference from Ti to T2 is defined as the dif-
ference in depth between Ti and the root of the smallest tree
containing Ti and T2. For example ip the phrase marker
</bodyText>
<equation confidence="0.464764">
(9) (S (NP (NP (DET the) (N telephone)),
(PP (PREP IN) (DET the) (N room)))
(V rang) (ADV loudly))
</equation>
<bodyText confidence="0.992349285714286">
the depth difference between &amp;quot;the&amp;quot; and &amp;quot;telephone&amp;quot; is 1 and
between &amp;quot;room&amp;quot; and &amp;quot;rang&amp;quot; is 3.
The depth difference between Ti and 12 is the number of
nodes from Ti to the node expanded when adding T2 on a postorder
traversal from Ti in the partial phrase marker containing Ti but
not 12. The depth difference between Ti and Tg also represents
the number of constituents of which Ti is the rightmost word.
</bodyText>
<subsectionHeader confidence="0.30756">
24
</subsectionHeader>
<bodyText confidence="0.950366">
A proof (requiring a forma.1 definition of the incremental
parse) that parsing time per word is constant in depth difference
bounded sentences appears in [10]. Informally the depth dif-
ference bound places a bound both on the number of next nodes to
expand which may follow a given terminal and on the amount of
tree traversal which the parser must perform to find each next
unexpanded node. Since each modification requires only a fixed
number of operations, each of which is bounded on the finite set
of at most once cyclic left branching trees, the computation
adding a new word to existing partial parses is bounded inde
pendently of sentence length.
Natural language sentences tend to have small depth dif-
ferenc-es. Both right branching sentences and left branching
sentences (found in Japanese for example) have an average depth
difference over each three or four word segment of two or less
On the other hand sentences are difficult to understand when
they have two consecutive large depth differences,, such as the
multiple center embedding
(10) The ra.t the cat the dog bit chased diedL
or the complex noun phrase in
The pad on a clarinet in the last row whicn I
fixed earlier for Eb fell out.
</bodyText>
<subsectionHeader confidence="0.81467">
Furthermore in ambiguous sentences such as
</subsectionHeader>
<bodyText confidence="0.9571825">
(11) Joe figured that it was time to take the cat out.
Kimball observes that subjects prfer the reading with the
smaller depth difference. Finally, Blumenthal found that subjects
tended to understand a multiple center embedded sentence as a
</bodyText>
<subsectionHeader confidence="0.301672">
25
</subsectionHeader>
<bodyText confidence="0.908470666666667">
conjunctive sentence. The conjunctive sentence contains a re-
arrangement with lower depth differences of the constituents of
the center embedded sentence.
</bodyText>
<sectionHeader confidence="0.928101" genericHeader="method">
3. Sentence Generation
</sectionHeader>
<bodyText confidence="0.960891833333333">
The syntactic form given to a sentence depends on the infor-
mation being communicated in a sentence and on the cultural con-
text in which the sentence appears. Clark and Haviland show that
a speaker uses various syntactic devices sentences to place the
&amp;quot;given&amp;quot; information known to the listener before the information
&amp;quot;new&amp;quot; to the listener. Particular syntactic structures are also
used to emphasize or suppress particular kinds of information;
for example newspaper traffic accident reports usually begin
with a passive sentence such as
(12) An elderly Lakewood man was injured when...,
presumably to emphasize the result of the
accident.
</bodyText>
<subsectionHeader confidence="0.79540525">
To capture the dependence of syntax on semantic content and
social context, the sentence generator uses function-like grammar
rules of the form
(Rulewame Cat Variables Predicate Forms).
</subsectionHeader>
<bodyText confidence="0.998275857142857">
Rulename is the name of the rule and cat is the grammatical
category of the constituent generated by the rule.
Variables is a list of formal parameters. Usually the
variable list contains a vartable bound during rule execution
to a node in a semantic network and another variable bound to
a control association list containing information about the con-
text in which the generated constituent will appear and possibly
</bodyText>
<table confidence="0.784440307692308">
26
the syntactic form the constituent should have.
Predicate is a Boolean-valued form on the parameters in
Variables. A rule is used only when Predicate is true.
Forms is a list of forms depending on Variables which
generate terminals or calls to the grammar for subconstituerits
of CAT.
An example of a generation rule is
(SPI S*(X Y) (Equal (Voice Y) (Quote Passive))
(NP (Object X) Y)
(Beverb X)
(Pap (Action X))
(M* X Y))
</table>
<tableCaption confidence="0.524085875">
which generates simple passive sentences. The variable X is
bound to a node in a semantic network and Y to a control
association list. The rule is applied only if the control
alist -contains a passive flag and if the semantic node has an
object and action; in general a rule is applied only if the
semantic subnodes called in the rule body appear in the
semantic net. The form (NP (Obj X) Y) generates a form (NP
XO YO), where XO is the semantic node on the object indicator
</tableCaption>
<bodyText confidence="0.932497722222222">
from X, and YO is the value of Y. Beverb and Pap are procedures
which generate respectively a form of the verb &amp;quot;to be&amp;quot; and a
past participle form of the verb Action(X). M* is a procedure
which generates a list depending on X and Y such as (PP&lt;Value
of Time(X)&gt; &lt;Value of Y&gt;) for generating optional prepositi.mal
phrases or relative clauses.
As each rule is applied, the list of terminals and calls to
grammar rules generated by the rule is added to a phrase marker
representing the structure of the sentence being generated.
27
Grammar calls in the phrase marker are expanded top down-and
left to right, in a preorder traversal of the growing phrase
marker. As terminals are generated they are printed out.
As an example, illustrating the effect of semantic and
social contest on sentence generation, an initial sentence of
a traffic accident report,
(13). A man was killed when a car hit him in Irvine.
was generated from the semantic nodes
</bodyText>
<table confidence="0.950226714285714">
Al: Agent AO A2: Agent AO: Class man
Object VO Action hit
Action Kill Object VO
Place Irvine Instrument Car
Cause AZ
and the control alist.
Purpose: Introduction;cases: object, cause, place
</table>
<bodyText confidence="0.996036142857143">
using a grammar built for generating traffic accident report
sentences. To summarize a trace of the generation, a call to
the sentence rule with purpose = introduction generates a sentence
call with voice = passive. The passive rule applies and a noun
phrase on AO is called for. Because Purpose = Introduction a
NP rule applies which calls for a NP to be generated on the
semantic class to which AO belongs. Because CASES contains
TIME and CAUSE, the passive rule generated calls for modifying
structures of these CASEs. Because the causE semantic node A2
has an action, the modifier rule M =&gt; Relative conjunction S
generates the cause while the time is described by a preposi-
tional phrase. The pronoun &amp;quot;him&amp;quot; is generated by a noun phrase
rule NP-1 which generates a pronoun when the first semantic
argument to the left of the NP-1 call in the generation phrase
</bodyText>
<page confidence="0.271866">
28
</page>
<bodyText confidence="0.759945">
marker Ithich is described by the same pronoun as the semantic
argument A of NP-1 is in fact equal to A.
</bodyText>
<sectionHeader confidence="0.759724" genericHeader="method">
4. Finding $emantic Preimages
</sectionHeader>
<bodyText confidence="0.968614818181818">
While the generator described in section 3 produces sentences
from semantic and contextual information, the incremental parser
described in section 2 recovers merely the syntactic structure
of a sentence. To obtain the semantic arguments from which a
sentence might have been generated a procedure to invert the
generation rule forms must be added to the incremented parser.
While the incremental parser begins the construction of con-
stituents top down, it completes them syntactically in a bottom
up direction. In fact IP executes postorder traversals on all
the syntactic parse trees it builds; of course if a particular
partial phrase marker can not be finished, the traversal is not
completed. However each node not a tree terminal of a syntactic
phrase marker visited by the incremental parser is a syntactically
complete constituent.
When the parser visits a syntactically complete constituent
C, it applies a function INVERT to find the semantic preimages
of C. In finding the semantic structure of C, INVERT has avail-
able not only the syntactic structure of C, but also the semantic
preimages which it found for subconstituents of C. INVERT finds
the set of generation rules which might proeuce a constituent
having the same syntactic form as C. For each such rule R.,
INVERT constructs all the possible parings between each output-
</bodyText>
<table confidence="0.941580714285714">
generating form F of R and the constituents of C which F might
29
produce. For example if C is
(S (NP Man) (Beverb is) (PAP Injured))
the pairing established for the passive sentence rule would be
(NP (Object X) Y) (NP the man)
(Beverb X) (Beverb is)
(Pap (Action X)) (Pap Injured)
(M* X Y) NIL
The pair ((Equal (Voice Y) PASSIVE) T) is also created, since
the rule predicate is true whenever a rule applies.
Each indicidual pair P in slia a pairing of a rule form and
rule form outputs is processed by a function FIND which returns
an association list containing possible values of the rule
parameters (X and Y in the example above) which would produce
the output appearing in P. For the example above FIND would
produce
(( X((Object Man))) (Y NIL))
(( X ((Time Past))) (Y NIL))
(( X NIL) (Y (( Cases Nil)))).
(( X NIL) (Y (( Voice Passive))))
Using an extension to association lists of the computational
logic Unification Algorithm, these association lists are unified
into a single association list, which for the example is
(( X ((Agent man) (Time Past) (Action Injure))
(( Y ((Cases Nil) (Voice Passive))))
Finally INVERT creates a grammar rule call,
(S ((Agent man)(Time Past)(Action Injure))
</table>
<subsectionHeader confidence="0.681207">
((Cases Ni1)(Voice Passive))))
</subsectionHeader>
<bodyText confidence="0.891988">
from the association list and stores the result in the inverse
image of C.
</bodyText>
<subsectionHeader confidence="0.393692">
In finding a semantic preimaoe, the INVERT function must
</subsectionHeader>
<bodyText confidence="0.946138857142857">
30
know which grammar rules might produce a particular grammatical
constituent. This information is computed by symbolically eval-
uating the grammar rules to produce the strings of regular
expression grammar nonterminals (as opposed to grammar calls)
representing the possible output of each rule. The resulting
relation from rules to strings is inverted into a table giving
possible rules generating each string.
The heart of this symbolic evaluator is a function ETERM on
the output generating forms of a rule which returns a list all
lists of regular expression nonterminals representing the out-
put of a form. ETERM takes advantage of the similar syntax of
most grammar rule forms, and is defined in simplified form
(with comments in angle brackets) as
</bodyText>
<figure confidence="0.8316315">
Eterm (form) =
if atom (form) then NIL
&lt;terminates recursion&gt;
else if car (form) is a grammatical category
then list (list (car (form)))
&lt;these forms generate a single grammar call&gt;
else if car (form) = FUNCTION ar LAMBDA
then ETERM (cadr (form))
else if car (form) = LAMBDA
then ETERM (caddr (form))
else if car (form) = LIST
if form is not properly contained in a LIST
expression
then Mapcar((Function Concatenate)
(Cartesian
((Mapcar (Function ETERM)
cdr (form))))
&lt;outer LISTS are used to create lists of grammar calls&gt;
else if form is inside a LIST expression
ETERM (cadr (form))
&lt;inner lists are used to create grammatically&gt;
else if car (form) = MAPCONC then make optional
</figure>
<figureCaption confidence="0.4666215">
and repeatable all the nonterminals returned
in ETERM ([function argument of MAPCONC])
</figureCaption>
<page confidence="0.726186">
31
</page>
<tableCaption confidence="0.318825">
else if car (form) = COND
then MAPCONC((LAMBDA(X) ETERM ([last form in X])
(cdr form)
&lt;returns alternatives from each branch of the COND&gt;
else if car (form) is a user-defined function
then ETERM ([definition of function])
</tableCaption>
<bodyText confidence="0.6070732">
else if there is a stored value for ETERM (form)
then that value
else ask the the user for help
The function FIND which returns possible bindings for rule
variables when given a rule form and its output is defined below.
The variable ALLST holds the value of the association list being
hypothesized by FIND; this variable is NIL when FIND is called
from INVERT.
Like ETERM, the definition of FIND is based on the rules
for evaluating recursive functions.
</bodyText>
<table confidence="0.8549473125">
FIND (Alist form value)=
if eval(form alist)=value then list (Alist)
else if recursion depth exceeded, then NIL
else if atom (form) then list (Merge (list (cons
(form Value)) Alist)
else if car (form) = COND
let L = clauses which might be entered by
evaluating form
then Mapconc (FM 1) where
FM (clause) = list (Merge Find (Alist Car (clause)T)
Find (Alist last (clause)))
else if car (form) = Quote then if cadr (form) = value
then Alist else NIL
else if car (form) is a defined function
then FIND (Alist (Substitute cdr (form) for
formal parameters in definition
</table>
<figure confidence="0.897167464285714">
of car (form))
Value)
else if car (form) = MAPCONC (fn 1st)
then Merge (Find (Alist 1st value)
For each X in 1st, Merge (Alist for X))
&lt;this clause makes the assumption, which works in
practice, that fn generates either one-element
or empty lists&gt;
else NIL
32
With a definition of FIND similar to the one above, the
parser found the preimage
(S (((place ((class (park))))
(agent ((class (man))))
(action (walked]
[the extra parentheses denote lists of alternatives] for the
sentence
(13) The man walked in the park.
generated by the grammar
[SO S (X) T (NP (Agent X)) (V(Action X))
(Optional ((PP (Place X) ((Case Place]
[NPO NP (X) T (Det X) (N (Class X]
[PPO PP (XY) T (Prep XY) (NPX]
and the preposition function
Prep (XY) = Selectiol(Assoc CASE Y)
(Place IN)
(Instrument WITH)
(Source FROM]
</figure>
<sectionHeader confidence="0.518383" genericHeader="method">
5. Implementation
</sectionHeader>
<bodyText confidence="0.92682">
The processors described in this paper have been programmed
in University of California, Irvine, LISP and run in about 45K on
a PDP-10 computer.
</bodyText>
<sectionHeader confidence="0.973122" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.999232888888889">
1. Bever, Thomas G. 1970. In [7] and [5].
2. Clark, Herbert H. and Haviland, Susan E. 1975 Social Sciences
Working Paper, 67. U.C. Irvine.
3. Colby, Benjamin N. 1973. American Anthropologist 75, 645-62.
4. Florres d&apos;Arcaio and Levalt, eds. 1970 Advances in Psycholin-
guistics, North Holland, Amsterdam.
5. Garrett, Merrill, F. 1970. in [5].
6. Haynes, John R. 1970. Cognition and the Development of Language.
John Wiley.
7. Kaplan, Ronald M. 1972. A.I. 3, 77-100
8. Kimball, John 1974. Cognition 2,1,15-47.
9. Knaus, Rodger. 1975. Ph.D Thesis. U.C. Irvine.
10. MacKay, Donald G. 1966. Perception and Psychophysics. 426-36.
11. Olson, James N. and MacKay, Donald G. JVLVB 13, 45770.
12. Petrick, S. R. In [14].
13. Rustin, Randall. 1973. Natural Language Processing.
14. Watt, Wm. 1970. In [7].
15. Woods, Wm. 1973. In [14].
</reference>
<title confidence="0.422839">
American Journal of Computational Linguistics Microfiche 33 : 33
A LEXICAL PROCESS MODEL OF NOMINAL COMPOUNDING IN ENGLISH
</title>
<author confidence="0.653239">
JAMES R. RHYNE
</author>
<affiliation confidence="0.680618">
Department of Computer Science
University of Houston
Houston, Texas 77004
</affiliation>
<sectionHeader confidence="0.778497" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999087454545455">
A theoretical model for nominal compound formation in English
is presented in which the rules are representations of lexical
processes. It is argued that such rules can be generalized to
account for many nominal compounds with similar structure and
to enable new compounds to be produced and understood. It is
shown that nominal compounding depends crucially on the existence
of a &amp;quot;characteristic&amp;quot; relationship between a nominal and the
verb which occurs in a relative clause paraphrase of a compound
which contains the nominal. A computer implementation of the
model is presented and the problems of binding and rule selection
are discussed.
</bodyText>
<page confidence="0.435508">
34
</page>
<sectionHeader confidence="0.291558" genericHeader="method">
Linguistic Issues.
</sectionHeader>
<subsectionHeader confidence="0.78936">
Nominal compounds are sequences of two or more nominals
</subsectionHeader>
<bodyText confidence="0.9773383">
which have the semantic effect of noun phrases with attached
relative clauses. The rightmost nominal is generally tine primary
referent of the compound the other nominals restrict the
reference of the rightmost nominal in much the same fashion that
a relative clause does. There are, of course, exceptions in
which the rightmost nominal is figurative or euphemistic
(e.g. family jewels). Compounds occur frequently in English and
Germanic languages, but infrequently in the Romance languages
where their function is largely performed by nominal-preposition-
nominal sequences (e.g. chemin de fer, agent de change).
</bodyText>
<subsectionHeader confidence="0.666457">
The syntactic structure of nominal compounds is quite simple
</subsectionHeader>
<bodyText confidence="0.941073318181818">
--the three variants are N.-N, N-participle-N, and N-gerund-N.
In the N-N form, either of the two nominals may in fact be yet
another nominal compound, giving a structure like (N-N)-N or
N-(N-N); the first of these forms seems to occur much more often
than the second (examples of each type are: typewriter mechanic,
liquid roach poison).
I assume that the process of nominal compounding is syntac-
tically a process in which a relative clause is reduced by delet-
ing all elements of the relative clause but one and preposing the
single remaining element is front of the antecedent nominal. In
addition, the clause verb may be nominalized ,And preposed. Other
linguists have proposed different derivations for nominal
compounds; Lees [3], for example, derives nominal compounds from
nominal-preposition-nominal sequences. There are two reasons why
I feel that Lees approach is wrong: (1) there are English
compounds for which no reasonable equivalent nominal-preposition-
nominal paraphrase can be given (e.g. windmill), and (2) there
are subtle meaning differences between the nominal compounds and
their nominal-preposition-nominal counterparts (county clerk vs.
clerk for the county). If nominal compounds and nominal-
preposition-nominal sequences are derived from forms like
relative clauses, then the differences in meaning can be accounted
</bodyText>
<page confidence="0.506317">
35
</page>
<bodyText confidence="0.938064857142857">
for by deriving each form from a distinct relative clause; the
relative clauses may, of course, be quite closely related to
each other.
I have spoken rather loosely about deriving nominal compounds
from relative clauses; I am not proposing a derivation system
which operates on surface forms of the language, and what I
intend that the reader should understand is that an underlying
form for a nominal compound is derived from an underlying form
for a relative clause by a language process which I term a
lexical rule because, as we shall see, the operation of such
rules depends crucially on the specific lexical items which are
present in the underlying structures. Linguists have identified
a number of lexical processes in English; some examples of such
processes may be found in [1] and [2].
</bodyText>
<subsectionHeader confidence="0.536958">
The underlying forms associated with relative clauses and
</subsectionHeader>
<bodyText confidence="0.93638265">
nominal compounds in the model of nominal compounding being
presented here are networks (trees for the most part) defined
in terms of a case grammar which is closely related to that
used by Simmons [ 5]. The cases which appear in this system fall
into two general categories: (1) cases of the clause verb, which
are the following -- Performer, Object, Goal, Source, Location,
Means, Cause, and Enabler and (2) structural cases, which are
RELCL (relative clause) and COMP (compound). I will not explain
these cases- in detail, as that is the subject of a forthcoming
paper. But the following observations will illuminate the case
system for verb cases. The case system distinguishes the
immediate performer of an act from a remote cause or agent of
the act. The reason for this distinction lies in an intimate
connection between verbs and the assumed or habitual performer
of the act which is the reference of the verb. The case system
also distinguishes an active causative agent of an act from
an agent which merely permits the act to occur; this distinction
in the case system permits two classes of verbs to be distinguished
according to whether the surface subject commonly causes the act
or permits the act to occur.
</bodyText>
<page confidence="0.66195">
36
</page>
<bodyText confidence="0.994607514285714">
The case system used in the present model of nominal
compounding is not a deep case system; on the contrary, it seems
that nominal compounding is a lexical process which occurs
rather near the surface in a derivatidnal grammar model. An
example which can be given to support this is the compound
ignition key; this is a key &apos;which turns a switch which enables
a- complex sequence of events to take place that ultimately result
in the ignition of a fuel/air mixture in an engine, or one may
describe it equivalently as a key which causes ignition. The
first aescription corresponds to a deep case level of description
while the second corresponds to the level at which the compound
ignition key is formed. I would argue that if one takes the
deep case approach, then one is forced to include a great deal
of structure in the rules for nominal compounding; in particular,
the rule for ignition key must remove all .of the links in the
causal chain leading to the ignition act. The deletion of this
intermediate information must be done to obtain the description
given in the second case, and to include the deletion procedure
in both a compounding rule and in the rule process which leads
to t&apos;ae shorter description means unnecessarily duplicating the
procedure. Moreover, if one derives compounds from paradigm
relative clauses of the second sort, e.g. key which causes an
action to occur, then it is possible to generalize compound
forming rules so that a single rule may produce several
compounds. It will not be possible to do this if deep cases are
used as the deep case structure of firing key will be quite
different from that of ignition key.
In order to understand the model of compounding which is
being presented here, it is essential to consider the function
of compounding in language. In my view, compounding is a process
which allows a speaker to systematically delete information from
an utterance just when the speaker has reason to expect that the
hearer can reconstruct that information. In effect, I consider
compounding (and a great many other linguistic processes) to be
examples of linguistic encoding which are used to speed up
</bodyText>
<subsectionHeader confidence="0.464091">
37
</subsectionHeader>
<bodyText confidence="0.999537222222222">
communication, and the grammar shared by the speaker and hearer
must include the encodihg and decoding functions.
Consider the nominal compound steam distillation, which
refers to the distillation of some substance with steam, the
hearer of the compound steam distillation knows that distillation
is the derived nominal form of distill. The hearer also knows
what the common or characteristic cases of the verb distill are:
the agent is invariably a person or machine (this would be the
occupant of the Cause case slot in my system), the instrument
(or Means) may be an apparatus or a heated medium such as steam
and the Goal is a liquid which is missing some of the constituents
that it entered the distillation process with.
It happens that in English, whenever a derived nominal of an
act is the right element in a compound, then the left element is
almbst always an occupant of one of the case slots of the verb.
In order to recreate the underlying relative clause structure, it
is only necessary for the hearer to properly choose the case for
the nominal steam. A great deal of lexical information can be
brought to bear on this question, for example, steam is not a
liquid, it is water vapor and thus it cannot be the starting
substance or the end product of a distillation process. Steam
might be the Cause of the act of distillation except that there
do not seem to be any compounds in English which have distillation
as the right element and A Cause as the left element. Thus the
hearer can assign steam to the Means case with some assurance.
In another example, shrimp boat, the hearer can ascertain
by lexical relations involving the ward boat, that boats are
characteristically used to catch marine life. One choice for the
main verb in a synonymous relative clause is catch, which will
have boat as an element of the Means case. The Cause for catch
is commonly a person or perhaps a sophisticated machine designed
to catch things (i.e. a trap). The Object. is characteristically
an animal. There is a strong characteristic relation between
the animal being caught and the means used to catch it, for example
mink is trapped, calves are roped, birds are netted, and fish are
caught with a boat. This relation exists as a rule in the ltaxicon
</bodyText>
<subsectionHeader confidence="0.492177">
38
</subsectionHeader>
<bodyText confidence="0.999622378378378">
of both the speaker and the hearer and it enables the speaker to
produce the nominal compound and the hearer to understand it.
Furthermore, shrimp boat is one member of a class of
closely related nominal compounds which includes lobster boat,
whale boat, tuna boat and many others. It would be most
_
interesting if a single rule could be formulated which would
generate all of these compounds. A lobster boat is a boat
which is used to catch lobster, a tuna boat is a boat which is
used to catch tuna, and so forth. All of these examples are
identical except for the particular marine animal being caught.
The logical next step is the creation of a rule which generalizes
the individual marine animals to the common category of marine
animal. This rule state that a marine animal boat is a boat
which is used to catch marine animals.
In making this generalization, I have given the rule the
power to help interpret novel compounds and to generate them.
With this power comes a difficulty, Which is constraining the
rule so that it does not generate bad compounds or produce
incorrect interpretations. The key to this constraint lies
in what I will term the characteristic or habitual aspect of
nominal compounds. In the case of the boat compounds, a boat
will only be a shrimp boat if it is characteristically, usually,
habitually or invariably used to catch shrimp. So the operation
of a compounding rule is enabled only if a characteristic aspect
is associated with the verb, in English, this is usually indicated
by an adverb or an adverbial phrase. If the speaker is willing
to assert that a boat is characteristically used to catch turtles,
then the nominal compound turtle boat may be used. The hearer
will use the general rule to place turtle and boat in the proper
case slots, and because a compound was used by the speaker, the
hearer will infer that the boat is one which is characteristically
used to catch turtles.
There are other problems which arise with the generalization
of rules, for example, compounding never produces a compound in
which the lelt element is a proper noun, unless the proper noun
is the name of a process (e.g. Markov process) or is a Source,
</bodyText>
<subsectionHeader confidence="0.472376">
39
</subsectionHeader>
<bodyText confidence="0.898408">
Performer, or Goal of an act of giving. It also seems to be true
that compounds are not generally formed when a lexical item is
several levels below the gendral term which appears in the rule
(e.g. repairmidget) or when a cross-classificatory term is used
(e.g. automobile Indian as an Indian who repairs automobiles).
With all of the preceding discussion in mind, I would now like to
turn to the model of nominal compounding which I have presently
implemented and running.
The Computer Model
The computer model of compounding accepts relative clause
structures as input and produces nominal compound structures as
output when the input is appropriate. It is written in a language
with many parentheses the language was chosen for its program
development facilities, i.e. built-in editor, rather than for its
interpretive capabilities. The program which produces nominal
compounds is a pattern matching interpreter; it applies a rule
of compound formation by matching one side of the rule with the
input structure, and if certain criteria are satisfied by the
match, items from the input structure are bound into the rule,
transferred to the other side of the rule, and a copy is then
made cf the other side of the rule. The result is a nominal
compound structure.
The model has two components; a rule interpreter and a
lexicon of rules for compounding. There is nothing tricky
about rule application. Consider the nominal compound flower
market and its associated relative clause paraphrase market
where flowers are characteristically sold. These phrases have
in my system the underlying structures shown in Figure 1.
The notation in square braces means that the verb sell has the
characteristic aspect in this instance.
market market
IRELCL COMP
sell [4-char] flower
LOC/BJ
market flowers
</bodyText>
<figureCaption confidence="0.990392">
Figure 1.
</figureCaption>
<subsectionHeader confidence="0.388888">
40
</subsectionHeader>
<bodyText confidence="0.998773722222222">
These two structures can be made into a rule by linking them
together. Whenever a relative clause structure identical to
that in Figure 1 is received, the rule applies and a copy is
created of the nominal compound flower market. The matching
procedure is a relatively straightforward, top down, recursive
process which has backtracking capability in the event that
a structure or case occurs more than once at any given level of
the structure. There are two problems which arise; however:
if tbe rule is generalized to account for compounds other than
flower market, then the lexical items in the rule will behave as
variables and some provisions must be made for binding of values
to these variables; also, the rule interpreter must have some
heuristics for selecting appropriate rules if the time required
to produce a compound is not to increase exponentially with the
size of the lexicon.
The present version of the model only partly solves the
binding problem. Consider the rule given in Figure 2 which is a
generalization of that given in Figure 1.
</bodyText>
<figure confidence="0.8483362">
market market
IRELCL COMP
sell [+char] goods
LOC OBJ
market goods
</figure>
<figureCaption confidence="0.996648">
Figure 2.
</figureCaption>
<bodyText confidence="0.951223636363636">
If this rule is to apply to the relative clause structure given in
Figure 1 and generate the compound flower market, then the rule
interpreter must recognize that the relative clause in Figure 1
is an instance of that given in Figure 2. The matching procedure
does this by determining that the reference set of the nominal
flowers is a subset of the reference set of the nominal goods.
In addition, the nominal flowers must be carried across to
the other side of the rule and substituted there for goods before
the other side of the rule is copied. Thus market and goods must
be bound across the rule so that whatever lexical item matches
either of these nominals becomes the value associated with these
</bodyText>
<page confidence="0.465746">
41
</page>
<bodyText confidence="0.994608">
nominals on the other side of the rule.
In the initial version of the model, this binding was
established explicitly when the rule was entered into the lexicon,
but this seemed unsatisfactorily ad hoc. In a subsequent version,
the identity of the lexical items on both sides of the rule was
the relation used to establish binding relationships. Consider,
however, the structure shown in Flgure 3.
</bodyText>
<figure confidence="0.785750428571428">
person
person thief
IRELCL I COMP
steal [+char] valuables
OBJ
valuables
PERF
</figure>
<figureCaption confidence="0.5803835">
Figure 3
Here person should be bound to thief but the previous technique
Is not able to establish this binding. The reason that we know
that person and thief should be bound is because we know that a
thief is a person who steals characteristically. In the most
recent version pf the model, this information is used to find the
binding relationships when the rule of identity does not work.
The lexicon is searched for a rule which can be used to establish
this binding. The rule which is used in the example shown in
Figure 3 is displayed below in Figure 4.
</figureCaption>
<figure confidence="0.6667692">
person thief
I RELCL
steal (+char]
I PERF
person
</figure>
<figureCaption confidence="0.942844">
Figure 4
</figureCaption>
<bodyText confidence="0.989899">
From the structures given in Figure 4, one can see that person
shOuld be bound to thief because the rule states that the reference
set of thief is the same as the reference set of person as
restricted by the relative clause.
The technique of using lexical rules to establish bindings
works in virtually every instance, but it has the defect of
</bodyText>
<page confidence="0.405899">
42
</page>
<bodyText confidence="0.998681277777778">
requiring that the information that a thief is a person who steals
things be represented in the lexicon twice at least. A new model
is under construction which attempts to reduce this redundancy
by allowing the rules to have multiple left and right parts.
The problem of selecting appropriate rules is rather easier
to solve. In most compounds in English, there is a characteristic
association between the right element of the nominal compound and
the main verb of the associated relative clause paraphrase. These
two elements which occur on opposite sides of the compounding rule
supply a great deal of information about the possibilities for
application of the rule. So, in the model, each rule in the
lexicon is indexed by the main verb of the relative clause and
by the right element of the nominal compound. This index actually
contains some environmental information as well; for the clause
verb, this environmental information is the case frame of the verb
and the fact that it is the main verb of the relative clause --
for the compound nominal, the environmental information is just
the fact that the nominal is the rightmost one in a nominal
compound.
The basic model has been tested with a set of several
hundred nominal compounds and is very successful in coping with
a wide va,riety of compound types. The productivity of the rules
varies greatly; some rules may produce hundreds of compounds while
other rules may only result in one or two compounds. Frozen forms
such as keel boat are handled by a rule which generates only
one compound; there is a rule for each frozen form. The rule
structures contain exclusion lists associated with each lexical
item in the rule, and these exclusion lists prevent the rule from
operating whenever a lexical item matches one Of the items on an
excltsion list if the items occur at corresponding locations in
the structures.
The model is quite quick in operation; on a high speed
diSplay console, it will generally produce compounds much faster.
than a person sitting at the console can conveniently read them.
This is mainly due to the rule selection heuristic, but the match
procedure has been carefully optimized as well.
</bodyText>
<page confidence="0.613087">
43
</page>
<sectionHeader confidence="0.524785" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.619592">
The model program is an excellent demonstration of the
</bodyText>
<subsectionHeader confidence="0.680863">
appropriateness of the basic theory, moreover, the rules
themselves can be generalized to deal with syntactic processes,
</subsectionHeader>
<bodyText confidence="0.991244419354839">
so there is no discontinuity in the grammar model between the
lexical processes and the syntactic processes. It seems clear
that the rules could also be used to represent other lexical
processes in language and this is currently being pursued.
There is no reason why the rules could not be used for
recognition as well as for the production of nominal compounds.
The bindings are not one-way, and the matching procedure will
work equally well for compound structures. The reasons why the
computer model is a production model are: (1) that the computer
model assumes the semantic correctness of the input relative
clause structures, and (2) that compounds are often ambiguous
and may be paraphrased by two or more relative clauses, while the
converse of this is almost never true. A recognition model would
have to generate underlying relative clause structures for each
ambiguity and a semantic component would have to-screen the
relative clauses for semantic errors.
I hope that the reader has noticed the avoidance of rule
procedures in this model. When 1 began working on the design of
the computer programs, I had in mind the creation of a model which
once implemented in LISP could be extended merely by adding new
rules without having to construct any additional LISP programs.
I ultimately wanted to have a model which could &amp;quot;learn&amp;quot; new rules
by systematic generalization and restriction of existing rules.
I feel that this would be relatively easy with rule structures and
extremely difficult with rule procedures written in a programming
language. Furthermore, I subscribe to Karl Popper&apos;s ideas of
scientific endeavour, and rule structures appealed because it
would be more difficult to bury flaws or ill understood aspects
of compounding and rule processes in structures than in procedures
where the computational power of the programming language permits
and even encourages ad hoc solutions to be found to problems.
</bodyText>
<page confidence="0.718248">
44
</page>
<sectionHeader confidence="0.996113" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.975629444444444">
I would like to here acknowledge the suggestions made by
Robert F. Simmons, Carlota Smith, Mary Ross T. Rhyne, Laurent
Siklossy, and Stanley Peters which have helped imprbve my
understanding of nominal compounding.
1. Chomsky, N. &amp;quot;Remarks on Nominalization,&amp;quot; in Readings in
English Transformational Grammar, Jacobs, R. and Rosenbaum,
P. eds. Ginn, Waltham, Massachusetts, 1970.
2. Gruber, J. &amp;quot;Studies in Lexical Relations.&amp;quot; Pb. D. thesis,
MIT, 1965.
3. Lees, R. The Grammar of English Nominalizations. Mouton,
The Hague, 1968.
4. Rhyne, J. &amp;quot;Lexical Rules and Structures in a Computer Model
of Nominal Compounding in English.&amp;quot; Ph. D. thesis, The
University of Texas at Austin, 1975.
5. Simmons, R. &amp;quot;Semantic Networks: Their Computation and Use
for Understanding English Sentences,&amp;quot; in Computer Models of
Thought and Language, Schank, R. and Colby, K. eds. W. H.
Freeman, San Francisco, 1973.
</reference>
<title confidence="0.497594">
American Journal of Computational Linguistics Microfiche 33 : 45
</title>
<sectionHeader confidence="0.9890245" genericHeader="conclusions">
GENERATION AS PARSING FROM A NETWORK INTO A LINEAR STRING
STUART C. SHAPIRO
</sectionHeader>
<subsectionHeader confidence="0.804462">
Computer Science Department
Indiana University
Bloomington 47401
</subsectionHeader>
<sectionHeader confidence="0.854747" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<subsectionHeader confidence="0.458726">
Generation of English surface strings from a semantic network
</subsectionHeader>
<bodyText confidence="0.979631816091954">
Is viewed as the creation of a linear surface string that describes
a node of the semantic network. The form of the surface string is
qontrolled by a recursive augmented transition network grammar,
which is capable of examining the form and content of the semantic
network connected to the semantic node being described. A single
node of the grammar network may result in different forms of sur-
face strings depending on the semantic node it is given, and a
single semantic node may be described by different surface strings
depending on the grammar node it is given to. Since generation
from a semantic network rather than from disconnected phrase markers,)
the surface string may be generated directly, left to right.
Introduction
In this paper, we discuss the approach being taken in the English
generation subsystem of a natural language understanding system
presently under development at Indiana University. The core of
the understander is a semantic network processing system, SNePS
(Shapiro, 1975), which is a descendant of the MENTAL semantic sub-
system (Shapiro, 1971a, 1971b) of the MIND system (Kay, 1973).
The role of the generator is to describe, in English, any of the
nodes in the semantic network, all of which represent concepts of
the understanding system.
46
and other computations are required in the process of pasting these
trees tog ther in appropriate places until a single phrase marker
Is attained which will lead to the surface string. Since we are
generating from a semantic network, all the pasting together is
already done. Grabbing the network by the node of interest and
Letting the network dangle from it gives a structure whicn may be
searched appropriately in order to generate the surface string
directly in left to right fashion.
Our system bears a superficial resemblance to that described
in Simmons and Slocum, 1972 and in Simmons, 1973. That system,
however, stores surface information such as tense and voice in its
semantic network and its ATN takes as input a linear list contain-
ing the semantic node and a generation pattern consisting of a
&amp;quot;series of constraints on the modality&amp;quot; (Simmons et al., 1973, p. 92
The generator described in Schank et al., 1973, translates from
a &amp;quot;conceptual structure&amp;quot; into a network of the form of Simmons&apos;
network which is then given to a version of Simmons generation
program. The two stages use different mechanisms. Our system
amounts to a unificatio of these two stages.
The generator, as described in this paper, as well as SNePS,
a parser and an inference mechanism have been written in LISP 1.6
and are running interactively on a DEC system-10 on the Indiana
University Computing Network.
Representation in the Semantic_Network
Conceptual information derived from parsed sentences or deduced
from other Information (or input directly via the SNePS user&apos;s lan-
guage) is stored in a semantic network. The nodes in the network
represent concepts which may be discussed and reasoned about.. The
edges represent semantic but non-conceptual binary relations
between nodes. There are also auxiliary nodes which SNePS can
use or which the user can use as SNePS variables. (For a more
complete discussion of SNePS and the network see Shapiro, 1975.)
The semantic network representati.on being used does not in- 47
elude information considered No be features of the surface string
such as tense, voice or main vs. relative clause. Instead of tense,
temporal information is stored relative to a growing time line
in a manner similar to that of Bruce, 1972. From this information
a tense can be generated for an output sentence, but it may be a
different tense than that of the original input sentence if time
has progressed in t-he interim. The voice of a generated sentence
is usually determined by the top level call to the generator func-
tion. However, sometimes it is determined by the generator gram-
mar. For example, when generating a relative clause, voice is
determined by whether the noun being modified .is the agent or ob-
ject of the action described by the relative clause. The main
clause of a generated sentence depends on which semantic node is
given to the generator in the top level call. Other nodes con-
nected to it may result in relative clauses being generated. These
roles may be reversed in other top level calls to the generator.
The generator is driven by two sets of data: the semantic net-
work and a grammar in the form of a recursive augmented transition
network (ATN) similar to that of Woods, 1973. The edges on
our ATN are somewhat different from those of Woods since our view
is that the generator is a tranducer from a network into a linear
string, whereas a parser is a transducer from a linear string into
a tree or network. The changes this entails are discussed below.
During any point in generation, the generator is working on some
particular semantic node. Functions on the edges of the ATN can
examine the network connecteld to this node and fail or succeed
accordingly. In this way, nodes of the ATN can &amp;quot;decide&amp;quot; what sur-
face form is most appropriate for describing a semantic node, while
different ATN nodes may generate different surface forms to des-
cribe the same semantic node.
A common assumption among linguists is that generation begins
with a set of disconnected deep phrase markers. Transformations
</bodyText>
<figure confidence="0.982258871794872">
------&apos;
:VAT,
--NOW
M0001
Nuuu2&apos;
it-
0
4k to
4v tA
M002 13EFORE
-P M002-)
a
M0022 BEFO M0026
48
M00,23
M0004
M0009 moon
LEX
M0003
LEX
NO 008
LEX
m M0007
m
w
&gt; M0017 If •M001.4
ii
q
3M0012 &amp;quot;r M0019 l*A +
..1:.. 10013
WHICH
140016 )-D M0020 M0005
m
44M0018
LEX LEX LEX LEX LEX
DOG
a 8 8 3 8
LUCY PERSON CHARLIE BELIEVE
KISS YOUNG SWEET
</figure>
<figureCaption confidence="0.980241333333333">
Figure 1: Semantic Network Representation for &amp;quot;Charlie believes
that a dog kissed sweet young Lucy,&amp;quot; &amp;quot;Charlie is a person,&amp;quot; and
&amp;quot;&apos;Lucy is a person.&amp;quot;
</figureCaption>
<bodyText confidence="0.999729833333333">
4_2srmation considered to be features of surface strings are not
stored in the semantic network, but are used by the parser in con-
structing the network from the input sentence and by the generator
for generating a surface string from the network. For example,
tense is mapped into and from temporal relations between a node
representing that some action has, is, or will occur and a growing
time line. Restrictive relative clauses are used by the parser
to identify a node being discussed, while non-restrictive relative
clauses may result in new information being added to the network.
The example used in this paper is designed to illustrate the
generation issues being discussed. Although it also illustrates
our general approach to representational issues, some details will
</bodyText>
<figure confidence="0.939180379310345">
49
*(SNEG M002b)
(CHARLIE IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY)
*(SNEG M0023)
(A DOG KISSED SWEET YOUNG LUCY)
*(SNEG M0007)
(CHARLIE WHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY)
*(SNEG 10004)
(CHARLIE IS A PERSON WHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY)
*(SNEG M0006)
(CHARLIENHO IS BELIEVING THAT A DOG KISSED SWEET YOUNG LUCY IS A PERSON)
*(SNEG M0008)
(THE BEL,IEVING THAT A DOG KISSED SWEET YOUNG LUCY BY CHARLIE)
*(SNEG M0011)
(A DOG WHICH KISSED SWEET YOUNG LUCY)
*(SNEG M0010)
(THAT WHICH KISSED SWEET YOUNG LUCY IS A DOG)
*(SNEG M0012)
(THE KISSING OF SWEET YOUNG LUCY BY A DOG)
*(SNEG M0020)
(SWEET YOUNG LUCY WHO WAS KISSED BY A DOG)
*(SNEG M0014)
(LUCY IS A SWEET YOUNG PERSON WHO WAS KISSED BY A DOG)
*(SNEG M0015)
(SWEET YOUNG LUCY WHO WAS KISSED BY A DOG IS A PERSON)
*(SNEG M0017)
(SWEET LUCY WHO WAS KLSSED BY A DOG IS YOUNG)
*(SNEG M0019)
(YOUNG LUCY WHO WAS KISSED BY A DOG IS SWEET)
</figure>
<figureCaption confidence="0.999999">
Figure 2: Results of calls to the generator with nodes from
Figure 1- User input is on lines beginn.ing with *.
</figureCaption>
<bodyText confidence="0.990863454545455">
certainly change as work progresses. Figure 1 shows the semantic
network representation for the information in the selAtencesi, &amp;quot;Charlie
believes that a dog kissed sweet young Lucy,&amp;quot; &amp;quot;Charlie is a person,&amp;quot;
and &amp;quot;Lucy is a person.&amp;quot; Converse edges are not shown, but
in all cases the label of a converse edge Is the label of the for-
ward edge with &apos;*&apos; appended except for BEFORE, whose converse edge
is labelled AFTER. LEX pointers point to nodes containing ;lexical
entries. STIME points to the starting time of an action and ETIME
to its ending time. Nodes representing instants of time are re-
lated to each other by the BEFORE/AFTER edges. The auxiliary node
NOW has a :VAL pointer to the current instant of time.
</bodyText>
<figureCaption confidence="0.999855">
Figure 2 shows the generator&apos;s output for many of the nodes of
Figure 1. Figure 3 shows the lexicon used in the example.
</figureCaption>
<figure confidence="0.998597454545455">
50
(BELIEVE((CTGY.V)(INF.BELIEVE)
(PRES.BELIEVES)(PAST.BELIEVED) (PASTP.BELIEVEDMPRESP.BELIEVING)))
(CHARLIE((CTCY.NPR)(PI.CHARLIE) ))
(DOG1(CTGY.N)(SING.DOG)(PLUR.DOGS)))
(KISS((CTGY.V)(INF.KISS)
(PRES.KISSES)(PAST.KISSED) (PASTP.KISSED)(PRESPAISSING)))
(LUCWCTGY.NPR)(PI.LUCY)))
(PERSON(CCTGY.E(SING.PERSON)(PLUR.PEOPLE)))
(SWEET((CTGY.ADJ)(PI.SWEET)))
(YOUNG((CTGY.ADJ)(PI.YOUNG)))
</figure>
<figureCaption confidence="0.999958">
Figure 3: The lexicon used in the example of Figures 1 and 2.
</figureCaption>
<bodyText confidence="0.985172772727273">
Generation as Parsing
Normal parsing involves taking input from a linear atring and
producing a tree or network structure as output. Viewing this
in terms of an ATLI grammar as described in Woods, 1973, there is a
well-defined next input function which simply places successive
words into the.* register. The output function, however, is more
complicated, using BUILDQ to build pieces of trees, or, as in our
parser, a BUILD function to build pieces of network.
If we now consider generating in these terms, we see that there
is no simple next input function. The generator will focus on
some semantic node for a while, recursively shifting its attention
to adjacent nodes and back. Since there are several adjacent nodes,
connected by variously labelled edges, the grammar author must
specify which edge to follow when the generator is to move to another
semantic node. For these reasons, the same focal semantic node
is used when traversing edges of the grammar network and a new se-
mantic node is specified by giving a path from the current semantic
node when pushing to a new grammar node. The register SNODE is
used to hold the current semantic node.
The output function of generation is straightorward, simply
being concatenation onto a growing string. Since the output string
is analogous to the parser&apos;s input string, we store it in the reg-
</bodyText>
<figure confidence="0.829984166666667">
St
garc ::= (TEST test [action]*(TO gnode))
(JUMP [action]*(TO gnode))
(MEM wform (word*) test [action]*(TO gnode))
(NOTMEM wform (word*) test [action]*(TO gnode))
(TRANSR ([regname] regname regname) test [action]*(TO gnode))
(GEN gnode sform [action]*regname [action]*(TO gnode))
sform ::= wform
SNODE
wform ::= (CONCAT fqrm form*)
(GETF sarc [sform])
(GETR regname)
(LEXLOOK lfeat [sform])
sexp
form.:: = wform
sform
action ::= (SETR regname form
(ADDTO regname form*)
(ADDON regname form*)
sexp
test ::= (MEMS form form)
(PATH sform sarc* sform)
form
sexp
gnode ::= &lt;any LISP atom which represents a grammar node&gt;
word ::= &lt;any LISP atom&gt;
regname ::= &lt;any non-numeric LISP atom used as a register name&gt;
sarc ::= &lt;any LISP atom used as a semantic arc label&gt;
lfeat ::= &lt;any LISP atom used as a lexical feature&gt;
sexp ::= &lt;any LISP s-expression&gt;
</figure>
<figureCaption confidence="0.999895">
Figure 4: Syntax of edges of generator ATN grammars
</figureCaption>
<bodyText confidence="0.829002076923077">
ister *. When a pop occurs, it is always the current value of *
that is retUrned.
Figure 4 shows the syntax of the generator ATN grammar. Object
language symbols are )„ (1 and elements in capital letters. Meta-
language symbols are in lower case, Square brackets enclose op-
tional elements. Elements followed by * may be repeated one or more
times. Angle brackets enclose informal English descriptions
Semantics of Edge Functions
In this section, the semantics of the
tests ahe presented and compared to those
t All comparisons are with Woods, 1973.
grammar arcs, forms and
of Woods, ATNs.t The
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000003">
<note confidence="0.658368">Journal of Computational Linguistics 33 PROCEEDINGS 13TH ANNUAL rIEETING</note>
<title confidence="0.985122">ASSOCIATION FOR COMPUTATIONAL LINGUISTICS LANGUAGE SYSTEMS</title>
<author confidence="0.998018">Timothy C Diller</author>
<author confidence="0.998018">Editor</author>
<affiliation confidence="0.390553">Sperry-Univac</affiliation>
<address confidence="0.826409">St. Paul, Minnesota 55101</address>
<note confidence="0.968501">Copyright 0 1975 by the Association for Computational Linguistics</note>
<abstract confidence="0.928060416666667">PREFACE The papers comprising this microfiche (the second of five) present in expanded form (as submitted by their authors) the six talks given in Session 2: Language Generation Systems. Various aspects of generation are considered, among them: relationsHips between parsing and generation (Knaus), planning modules and data structures basic to story development (Meehan), semantic networks and linguistic generator t (Shapiro and Slocum), message structures and translation strategies (MeDonald), and lexical processes in compound noun formation (Rhyne). Thanks to Martin Kay for chairing this session.</abstract>
<author confidence="0.975269">Timothy C Diller</author>
<affiliation confidence="0.940297">Program Committee Chairman</affiliation>
<address confidence="0.499719">2</address>
<pubnum confidence="0.256258">3</pubnum>
<title confidence="0.750748333333333">TABLE OF CONTENTS GENERATION SYSTEMS Ptediework for Writing Generation Grammars for Inter-</title>
<note confidence="0.942916">Computer Programs McDonald • . • • • • 4 Sentence Processing Knaus . . . . 18 A:Lexical Process Model of Nominal Compounding in R. . . &apos; • . • • • . , . . . 33 Generation as Parsing from a Network into a Linear Stuart . • • • • • • • .• • • . . Generation from Semantic Slocum . . 63 Planning Structures to Generate Stories R. . • • • • . 78 Journal of Computational Linguistics 33 : 4</note>
<title confidence="0.9881395">FOR WRITING GENERATION GRAMMARS FOR INTERACTIVE COMPUTER PROGRAMS</title>
<author confidence="0.99692">DAVID MCDONALD</author>
<affiliation confidence="0.9999925">Artificial Intelligence Laboratory Massachusetts Institute of Technology</affiliation>
<address confidence="0.999987">Cambridge, Massachusetts 02139</address>
<abstract confidence="0.999308868073879">This paper outlines the stucture and operation of the linguistic component from a language generation system in an interactive program. The component receives messages what is to be in the representation of the main program and produces fluent English utterances appropriate to the current discourse situation. The component is data-directed and uses procedural grammar, organized as a set of strategies. Interactive, specialist programs presently under development will to produce fluent, intentional in responce to situations. This creates a requirement for language facilities that Is faced in transformational grammar, mechanical translation programs, or paraphrase generating programs. of an interactive, the production of the must be driven directlyby the communicative intentions of the and by the discourse can imagine that the program consists a number of cooperating modules for parsing and interpreting what is said to it, solving problems in domain, for managing memory, and, in 5 particular, for generating utterances to communicate with its users. This generation component can be profitably viewed as having three aspects or &amp;quot;sub-components&amp;quot;. Situation/domain specialiststhat are activated when the program recognizes what situation it is in. They then decide what message be produced. They will decide on the listener is desired, and exactly what objects and relations are to be mentioned. For example, an appointment scheduling program might be told to wscrleaule a group meeting for Friday&amp;quot; and then find that a critical member of the group is unavailable. The situation specialists in the scheduling program are the ones to decide whether it is more to simply say can&apos;t&amp;quot;, or whether to volunter Information - &amp;quot;1 can&apos;t, Mitch won&apos;t be back until Monday. Models of the audience and the discourse situationto use in constructing utterances. There must be a record of the past conversation to guide in the selection of pronouns. Also, program must have models of, and heuristics about what the audience knows and therefore doesn&apos;t have to be This information say be very specific and domain dependent. For example, chess, one can &amp;quot;the white queen could take a knight&amp;quot;. There is no need to say &amp;quot;a black knight&amp;quot;, because this information is supplied by inferences from what one knows about chess inferences that the speaxer assumes the listener shares. 3) Linguisticknowledgeabout how to construct understandable utterances in the English language. Obviously, this information will include a lexicon associating objects and relations from the main program with for realizing them in English words, phrases, 6 syntactic constructions, etc.). There is also a tremendous amount information which describes the of the English language and the conditions of its use. It specifies the allowable arrangements of strategies and what modifications or alternatives to them may be appropriate in particular circumstances. the three aspects described, my work has concentrated on the third. What follows is drawn from my thesis (McDonald &apos;75) and from ongoing research. Linguistic The linguistic knowledge required for generating utterances is put into one component whose Job is to take a message from the situation and a translatioaof that message in English. The in the representation used by the main program and the specialists. The translation is done by a wherein the elements structure of the message itself provide the control. design of the component was arrived at of any particular main program, for the simple reason that no programs complexity were available at the time. However, at present time a grammar and lexicon Is being developed to use with at least two programs being developed by other people at MIT. They are an appointment scheduling program (Goldstein &apos;75) and an advisor to aid of MACSYMA &apos;75). The short dialog below is an example of the degree of fluency we are hoping to eventually achieve. ts between a scheduling program acting as an secretary (P), and a student (5). 7 (S) I want to see Professor Winston sometime in the next few days. He&apos;s pretty busy all Can wait? (S) No, it can&apos;t. All I need is his signature on a form. Well, maybe he can squeeze you in tommorrow morning. Give your name and check back in an hour. Messages Using the current message format and ignoring the details of the scheduler&apos;s representation, the phrase &amp;quot;maybe he can squeeze you in tommorrow&amp;quot; could have come from a message like this one, put together by one of the situation specialists. Message-1 features z ( prediction ) event (event actor &lt;Winston&gt; &lt;fit full schedule&gt; time &lt;31-10-75,9am-12am&gt;) aim-at-audience hedge have features describing the program&apos;s communicative what sort of utterance is this to be; what effect is it to have. Messages list the objects to be described (the right hand column) along with annotations for each object (left hand column) to show how they relate to the rest of the message. The phrases on the right in angle brackets represent actual structures from the scheduler with those meanings. Time Lexicon Translation from the internal representaiton of a computer program natural language has the same of problems as translating between two natural languages. The same concepts may not be available as primitives in both representations, and the conventions of the target language may require additional information that was not in the source. Generally speaking translation cannot be one for one. a What English phrase is best for a particular element in a program&apos;s message will depend on what is in the rest of the message and of what external conteet is. In such circumstances, translation by lookup is inadequate. In this component, in order to allow all factors to be considered, the translation of each element rs done by &amp;quot;composers&amp;quot;. For each main program that the linguistic component becomes with, a lexicon must be created which will elements the representation that could appear in a message (i.e. &amp;quot;prediction&amp;quot;,&amp;quot;event&amp;quot;,&amp;quot;&lt;Winston&gt;&amp;quot;, etc.). With each element is recorded the composer that will be run when the time comes to produce an English description for it (examples will be given shortly). composers may be applicable for a whole class of elements, such as They know the structure that all events have in (e.g. actor, action, time) and would know how to interpret the idiosyncratic details of each event by using data in the lexicon associated with them. Grammar of the grammar &amp;quot;strategies&amp;quot;. Strategies with particular languages rather with particular main programs as composers are. A given strategy may be used for several purposes. A, case is the strategy a clause in the present (&amp;quot;prices rise&amp;quot;) may be understood future, or timeless, according to what other phrases are present. Each composer ray know of several strategies, or tombinations of stTategies which it could use in describing an element from the message. will between then according to the context details the element or constraints imposed by previously selected strategies. The strategies themselves do no reasoning; they are implemented as functions which the composers call to do all the actual Construction of the utterance. The Translation Process At this point, the outline of the data-driven translation process can be summarized. A message is given for translation. The elements of the message are associated in a lexicon with procedures to describe them. The procedures are run; they call grammatical strategies; and the strategies construct the English utterance. Of course, if this were all there was to it, the process would never run, because all of the subprocesses must be throughly coordinated if they are not to &amp;quot;trip over their own feet&amp;quot;, or, for that matter, if ordinary human beings are to be able to design them. In a system where the knowledge of what to do is distributed over a large number of separate procedures, control structure assumes central importance. Plane describing the structure, I lay aspects of the design of the linguistics component. translated directly into surface structure form.There is no interlingua or intermediate level of structure comparable to the deep of Transformational Grarmar, or semantic nets of Simmons or Goldman the appropriate structure, however, requires planning, if for no other reason than that the message can only be 10 examined one piece at a time. The entire utterance must be organized before a detailed analysis and translation can get underway. As this is the is in terms of a sort of a representativ of the ultimate surface structure as its are known with extensive annotation, explicit and implicit, to point out where elements that are not yet described may be positioned, and to implement the grammatical restrictions on possible details as dictated by has already done. scaffolding is in the translation of each is called its &amp;quot;plan&amp;quot;. Plans made up of syntactic nodes of usual sort noun groups, etc. nodes may have in the manner of systemi:# (Winograd &apos;72). Nodes subplans consisting of a list of named slots marking the possible sub-constituents, given in the order of the eventual surface structure. Possible slots would be &amp;quot;subject&amp;quot;, &amp;quot;main &amp;quot;noun head&amp;quot;, &amp;quot;pre-verb-adverb&amp;quot;, and so on. The syntactic node types each have a number of possible corresponding the arrangements that may occur with different combinations of that the nbde on the stage of translation process, a slot may be a an Internal object from the message, node, a word or idiom, nothing. &apos;process The translation is done in two phases. The second phase does not begin until the first is completely finished. During the first phase, a is selected and the elements of message are transferred, largely untouched; to the slots of the plan and features added to its nodes. During the second phase, the plan is Nalked&amp;quot; topdown and from left to right. Compostrs for message elements in the plan&apos;s slots activated to produce English descriptions for the elements as they are reached in turn. Both processes are data-directed, the first by the of the message and the secpnd by the structure the plan and the contents of its slots. There are sound linguistic reasons for this two stage processing. Most parts of a message may be translated in terms of very modular syntactic and lexical units. But other parts are translated in terns of betweensuch expressed usually by ordering or clausesyntactic mechanisms. t exact form the smaller units cannot determined until their larger relations have been Accordingly, the objective of the first phase is to determine what global relationships are required and to choose the plan, features, and positions of message elements within the plan&apos;s slots that will realize those relationships. Once this has been done, English descriptions for the elements can be made independent of each other and will not need to changed after they are created. One of the most important features of natural language is the to omit, pronominalize, or otherwise abbreviate elements contexts. The known rules huristics for using this feature are phrased in terms of surface structure configurations and ordering. Because the phase works directly in terms, stating and using the available heuristics becomes a straightforward, tractable problem. 12 &amp;quot;Maybe he can squeeze you in tommorow morning&amp;quot; The rest of this paper will try to put some flesh on your picture of how this linguistics component works by following the translation of the message given in the beginning to the sentence above. The message was this. message-1 features= ( prediction ) event (event actor &lt;Winston&gt; action &lt;fit person into full schedule&gt; time &lt;31-10-75,9am-12am&gt;) aim-at-audience hedge The intentional features of a message tend to require the most global representation in the final utterance, because tbat is where indicators for questions, special emphasis, special formats e.g.( comparison), the like will be found. By convention then, the composers associated with the intentions are given the job of arranging for the disposition of all of the message elements. The total operation of phase one consists of executing the composer associated with each feature, one after the other. This message has only one feature, so its composer will assume all The linguistics component is implemented in MACL1SP, features (and annotations and slots and nodes) are atoms, and composers are functions on their property lists. Prediction composer-with (lambda ... ) Making a prediction is a speech act, and we may expect there to be particular forms in a language for expressing them, for example, the use of the explicit &amp;quot;will&amp;quot; for the future tense. Knowledge of these would of the composer. Inside the main program, or the the concept a may always include certain 13 parts: what is predicted, the time, any hedges, and so on. These part directly reflected in of the elements present in the message, and their annotations mark what internal roles they have. There does not need to be a direct correspondence between these and the in the linguisticforms used, the actual correspondence is part of the knowledge of the prediction composer. Typically, for any feature, one particular annotated element will be of greatest importance in seting the character of the whole utterance. For predictions, this is the &amp;quot;event&amp;quot;. The prediction composer chooses a plan for the utterance to fit the requirements of the event-element. The realization of any other elements will be restricted to be compatible with it. The prediction composer does not need to know the element&apos;s linguistic correlates itself, it can delegate the work to the composer for the element itself. The element look like this. (event actor &lt;Winston&gt; action &lt;fit person into full schedule&gt; time &lt;31-10-75,9am-12am&gt;) The first word points to the name of the composer, and the pairs give particular details. There is nothing special about the words used here (actor, action, time), just as long as the composer is designed to the information in places that the message-assembler wants to put it. The event composer&apos;s strategy is to use a clause, and the choice of plan is determined by the character of the event&apos;s &amp;quot;action&amp;quot; The action is &amp;quot;&lt;fit person into full schedule&gt;&amp;quot;, and it will have relevant properties in the lexicon: &amp;quot;plan&amp;quot;, &amp;quot;mapping&amp;quot;. Illan is either the name of a standard plan to be used, or an actual plan, partially filled with words (i.e. it can be a phrase). &amp;quot;Mapping&amp;quot; is an 14 association list showing how the subelements of the message are to be transferred to the plan. &lt;fit person into full schedule&gt; PLAN node-i (clause transl particle) slots frontings nil subject nil vg node-j (verb-group particle) slots modal nil pre-vb-adv nil mvb &amp;quot;squeeze&amp;quot; prt &amp;quot;in&amp;quot; objectl &lt;person being talked about&gt; post-modifiers nil MAPPING (( &amp;ctor subject ) ( time post-modifiers)) The event composer proceeds to Instanticte the nodes in the phrase and make the transfers; the prediction composer then takes the resulting plan, and makes it the plan of the whole utterance. Two message elements remain, but actually there is only one, &amp;quot;aim-at-audience&amp;quot; is supplying additional information about hedge, The annotation means that the contents of the hedge ((is are something that we want to tell the audience than of the This will affect how the element is positioned in the plan. composer in the lexicon to see what grammatical unit will be used to realize &lt;is possible&gt;, and sees, let us say, two possibilities involving different configurations of the adverb &amp;quot;maybe&amp;quot; and the modal &amp;quot;can be able to&amp;quot;, with the differences on the placement of the adverb. Theoretically, adverbs can be positioned in a number of places in a clause, depending on their characteristics. In this instance, the choice is forced because of a heuristic written into the grammar of adverbs and accessible to the 15 composer, that says that when the intent of an adverb is directed to the audience, it should be in the first position (the &amp;quot;frontings&amp;quot; slot). choice Implies putting &amp;quot;can&amp;quot; in the modal alternative with &amp;quot;maybe&amp;quot; in the pre-vb-adv slot would have necessitated a different form of the modal, yielding &amp;quot;say be able to&amp;quot;, These details have been taken care by syntactic routines associated with the verb group node. All the message elerents have been placed and the first phase is over. The plan is now as below. node-I (clause transl particle) slots frontings &amp;quot;maybe&amp;quot; subject cwinston&gt; vg node-2 (verb-group particle) slots modal &amp;quot;can&amp;quot; pre-vb-adv nil mvb &amp;quot;squeeze&amp;quot; prt &amp;quot;in&amp;quot; &lt;person talked about) post-modifiers nil second phase controller is a dispaching that moves from slot to slot. &amp;quot;Frontings&amp;quot; contains a wora, so the word is printed directly (there is a trap for morphological adjustments when necessary). contains an internal so the controller should go to lexicon for its composer and come back to handle whatever composer replaced the element with. there is always an step to check for possibility of pronominalizing. This check is rade with the element in its internal form. The of the discourse is given terms the internal representation and test for prior can be as simple as identity checks against a reference avoiding potentially intricate string matching operations with words. 16 In the dialog that this message came from, there is clear reference to &lt;winSton), so it can be pronominalized and &amp;quot;he&amp;quot; is printed. Any slot, or any node type may have procedures associated with it that are executed when the slot or node is reached during the second phase. These procedures will handle syntactic processes like agreement, rearangement of slots to realize features, add function words, watch relationships, and in particular, position the particle in verbparticle pairs. Generally, particle position (&amp;quot;squeeze John in&amp;quot; vs. &amp;quot;squerze John&amp;quot;) is not specified by the grammar except when the object is a pronoun and the particle must be displaced. This, of course, will not be known untill after the verb group has been passed. To deal with this, a subroutine in the &amp;quot;when-entered&amp;quot; procedure of the verb group is by the &amp;quot;particle&amp;quot; procedure. First, it particle and removes it from the VG plan so it will not be generated is available on any slot for a, procedure which can be run after pronominalization is checked and before the composer is called (if it is to be called). The subroutine incorporates the into a standard procedure and it on that hook for slot. The procedure will if the object has been a and if out the particle (which is now in the proper displaced position). If the object wasn&apos;t pronominalized, does nothing, has yet been printed beyond the verb group, and heuristics will be free to apply to choose the proper &lt;person being talked is here equal to the student, person the program is talking with, it is realized as the pronoun &amp;quot;you&amp;quot; and the particle is displaced. 17 Going from &lt;31-10-75,9am-12am&gt; to &amp;quot;tomorrow morning&amp;quot; may be little than table lookup by a &amp;quot;time&amp;quot; composer that has been designed know the formats of the time expressions inside the scheduler. This presentation has had to be unfortunately short for the amount of new material involved. A large number of interesting details and questions about the processing have had to be omitted. At the 1975), the data and structures mentioned have been fully implemented and tests are underway on gedanken data. Hopefully, by the end of 1975 the component will have a reasonable grarnar and will be working with messages and lexicons form the two programs mentioned before. A MIT A. I. lab technical report describing this work in should be ready in the spring of next year.</abstract>
<author confidence="0.871254">David McDonald</author>
<note confidence="0.817171888888889">Cavbridge, Mass. References cited in the text: Genesereth, M. (1975) A MACSYMA Advisor. Project MAC, MIT, Cambridge, Mass. (1774) Generation of Natural Language from a Deep Conceptual Base&amp;quot;. memo AIM-247, Stanford Artificial Lab., Stanford, Calif. (1975) &amp;quot;Barganing Between Goals&amp;quot;. in the proceedings IJCAI-4, available from the MIT Al lab. (1975) The Design of a Program for Generating Language. unpublished Master&apos;s Thesis, MIT Dept. of Electical Engineering. (1973) &amp;quot;Semantic Networks: Their and Use for English Sentences&amp;quot;. in Schank and Computer Models of Thought and Language. Winograd, T. (1972) Understanding Natural Language. Academic Press, New York, NY. Journal of Computational Linguistics 33 : 18</note>
<title confidence="0.952442">INCREMENTAL SENTENCE PROCESSING</title>
<author confidence="0.977413">RODGER KNAUS</author>
<affiliation confidence="0.747846">Systems Software Division and Economic Statistics</affiliation>
<degree confidence="0.848771">of the</degree>
<address confidence="0.711012">Washington, D. C. 20233</address>
<abstract confidence="0.998820083333333">A human who learns a language can both parse and generate in the language. In contrast most artificial guage processors operate in one direction only or require separate grammars for parsing and generation. This paper describes a model for human language processing which uses a single language description for parsing and generation. 1. Choice of Parsing Strategy A number of constraints limit the processors suitable as models of human language processing. Because short term memory is limited, the listener must absorb incoming words into larger chunks as the sentence is heard. Also because he is expected to reply within a couple seconds after the speaker finishes, regardless of length of the speaker&apos;s utterance, the listener must do much of the semantic processing of a sentence as he hears it. 19 and Watt point out that the difficulty in understanding a sentence S is not predicted by the number of used to S. Furthermore the process of detransformation appears too time-consumin9 (Petrick) for the approximately two seconds before a listener is expected to reply. A depth first transition network parser (Woods, Kaplan), which parsing difficulty is measured by number of traversed, correctly predicts the relative difficulty of active and passive sentences progressive and adjectival presEnt sentences and extreme difficulty of multiple embeddings. However a directed depth parser does not why similar sentences such as (5A) The horse sold at the fair escaped. The horse past the barn fell. vary in difficulty, nor does it explain experiments on the and verification of ambiguous (MacKay, Olsen and MacKay) which suggest that a pruned breadth first is used to pane Sentences with two plausible alternatives took longer to process With only interpretation. This extra time may be attributed to the construction two interpretations over a portion of t[)e more one is plausible. In addition subjec-ts sometimes become confused by the two of an ambiguous sentence. Finally in in which subjects hear ambiguous sentence in ore ear and a disimbiguating sentence simultaneously in the other ear of the ambiguity actually perby the may be switched the possibilities by changing the disambiguating sentences.</abstract>
<note confidence="0.577389333333333">21 Step 3 (a): (S OP (N mail) (N Boxes)) (V like) (.NP) (PP*)) (b): (S (NT (NP (N mail) (N Boxes)) (PP (PREP like) NP) (PP*)) V(NP) (pp*)) (c): (S (NP (N mail)) (V Boxes) (PP (PREP like) NP) (PP*)) (d): (S (V mail) (RP (N Boxes)) (PP (PREP like) NP) (PP*)) (e): (S (V mail) (NP (NP (N Boxes)) (PP (PREP like) NP) (pp*)) (PI&amp;quot;)) After completing the sentence after Step 4, the parser</note>
<abstract confidence="0.995611360946745">produces phrase markers from a, c, d and e by adding the last word and deleting unfilled optional nodes. The phrase marker obtained from 4B is rejected because it contains an unfilled obligatory V node. The incremental parser adds each successive sentence word to the partially completed phrase markers built from the earlier part of the sentence. The new word is added at the leftmost oblig unfilled node of each partial phrase marker and at all optional to the of Three different operations are used to add a new word to a partial parse. The word may be directly added to an unexpanded as in Step 3a may be attachedto an unfilled node with a left acyclic tree the grammar such as (PP PREP NP) or (S (NP N. (N*)) V (NP) (PP*)). Attaching occurs in steps 1 and 3c. subtrke of an existing partial phrase marker be left embeddedin a larger structure of the same grammatical category, as in steps 3b and 3e above. The embedding operation uses at most two left branching trees built from the 22 grammar: a tree Ti with a single cycle on the left branch is used to replace the existing subtree E being embedded. step 3e, for example, the structure (S (V mail) (NP NP (PP*)) would be obtained. The E is used to expand the leftmost unexpanded node of T1 for 3 la this results in: 3e. (S (V mail) (NP (NP (N Boxes) (N*)) PP*) Finally to the resulting structure the new sentence word is added through direct node expansion or attaching with an Acyclic left branching tree; in the example above this produces 3e from 3e: Using direct expansion attaching and embedding, the incremental parser finds all the phrase markers of sentences in context free or regular expression language; a formal definition of the parser and a proof of its correctness appear in [10]. Sometimes, as at steps 3b and 3e, the same structure (a prepositional phrase in step 2) is used in more than one partial parse. Following Earley&apos;s Algodrithm, the incremental builds a single copy of the shared substructure SO and maintains pointers linking SO to nodes in larger structures which SO expands. For all its tree building operations the incremental parser uses a finite set of trees i.e., the trees with only left subnodes expanded and at most oneicycle on the leftmost branch. These trees may be computed directly from the grammar and referenced by root and leftmost unexpanded node during the parse. 23 these preconstructed trees, incremental parser requires a fixed number of operations to add a new word a partial a retrieVIal on indexed set, copying left at most structure operations words and trees together. Earley&apos;s Algorithm, IP processes each word proportionto sentence length. However on sentences satisfying a bound,the parsing time per word constant. Because can&apos;t of words but must, process speech at an approximately constant rate, a constant parsing time per word is a necessary property of any algorithm modeling human language processing. the of constituent C phrase marker P be as of the the root of C to the root of P. If TI and T2 are two adjacent terminals with Ti the depth difference from Ti to T2 is defined as difference in depth between Ti and the root of the smallest tree containing Ti and T2. For example ip the phrase marker (S (NP (NP (DET the) (N (PP (PREP IN) (DET the) (N room))) (V rang) (ADV loudly)) the depth difference between &amp;quot;the&amp;quot; and &amp;quot;telephone&amp;quot; is 1 and &amp;quot;room&amp;quot; &amp;quot;rang&amp;quot; is 3. The depth difference between Ti and 12 is the number of nodes from Ti to the node expanded when adding T2 on a postorder from Ti the marker containing Ti but 12. The depth difference between and represents number of constituents of which Ti is the word. 24 proof (requiring a forma.1 definition of the parse) that parsing time per word is constant in depth difference sentences appears in [10]. Informally the depth bound places a bound the number next nodes to which may follow a given and on the of tree traversal which the parser must perform to find each next unexpanded node. Since each modification requires only a fixed of operations, each of which is bounded on the set of at most once cyclic left branching trees, the computation adding a new word to existing partial parses is bounded inde pendently of sentence length. Natural language sentences tend to have small depth dif- Both right sentences and left branching (found Japanese example) have an average depth difference over each three or four word segment of two or less On the other hand sentences are difficult to understand when have two consecutive large differences,, such as the multiple center embedding (10) The ra.t the cat the dog bit chased diedL the complex noun in The pad on a clarinet in the last row whicn I fixed earlier for Eb fell out. Furthermore in ambiguous sentences such as (11) Joe figured that it was time to take the cat out. Kimball observes that subjects prfer the reading with the smaller depth difference. Finally, Blumenthal found that subjects to understand a multiple embedded as a 25 sentence rewith lower depth differences of the of center sentence. 3. Sentence Generation The syntactic form given to a sentence depends on the inforbeing communicated in sentence and on the conin the and Haviland show that speaker uses various syntactic devices to place information known to the listener before the to listener. structures are also used to emphasize or suppress particular kinds of information; example newspaper accident reports begin a passive sentence as An elderly Lakewood was when..., presumably to emphasize the result of the accident. capture the dependence of syntax on and the generator uses function-like grammar rules of the form (Rulewame Cat Variables Predicate Forms). is the name of the rule and cat is the category of the constituent generated by the rule. Variables is a list of formal parameters. Usually list contains a bound during rule execution a node in a semantic network variable bound to association listcontaining information about the context in which the generated constituent will appear and possibly 26 syntactic form the should have. Predicate is a Boolean-valued form on the parameters in Variables. A rule is used only when Predicate is true. Forms is a list of forms depending on Variables which generate terminals or calls to the grammar for subconstituerits of CAT. An example of a generation rule is (SPI S*(X Y) (Equal (Voice Y) (Quote Passive)) (NP (Object X) Y) (Beverb X) (Pap (Action X)) (M* X Y)) generates passive sentences. X is bound to a node in a semantic network and Y to a control association list. The rule is applied only if the control a passive flag and if the semantic node has an action; in general a rule is applied only if the semantic subnodes called in the rule body appear in the semantic net. The form (NP (Obj X) Y) generates a form (NP XO YO), where XO is the semantic node on the object indicator X, and YO is the value of and Pap are procedures which generate respectively a form of the verb &amp;quot;to be&amp;quot; and a past participle form of the verb Action(X). M* is a procedure which generates a list depending on X and Y such as (PP&lt;Value Time(X)&gt; &lt;Value of Y&gt;) for optional prepositi.mal phrases or relative clauses. As each rule is applied, the list of terminals and calls to grammar rules generated by the rule is added to a phrase marker representing the structure of the sentence being generated. 27 Grammar calls in the phrase marker are expanded top down-and to in a preorder traversal of the growing phrase marker. As terminals are generated they are printed out. As an example, illustrating the effect of semantic and social contest on sentence generation, an initial sentence of a traffic accident report, (13). A man was killed when a car hit him in Irvine.</abstract>
<title confidence="0.829477666666667">was generated from the semantic nodes Object VO Action Kill Place Irvine Cause AZ A2: Agent Class Object VO</title>
<author confidence="0.743672">Instrument Car</author>
<note confidence="0.514034">and the control alist.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thomas G Bever</author>
</authors>
<date>1970</date>
<note>In [7] and [5].</note>
<marker>1.</marker>
<rawString>Bever, Thomas G. 1970. In [7] and [5].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Susan E Haviland</author>
</authors>
<date>1975</date>
<journal>Social Sciences Working Paper,</journal>
<volume>67</volume>
<publisher>U.C. Irvine.</publisher>
<marker>2.</marker>
<rawString>Clark, Herbert H. and Haviland, Susan E. 1975 Social Sciences Working Paper, 67. U.C. Irvine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin N Colby</author>
</authors>
<date>1973</date>
<journal>American Anthropologist</journal>
<volume>75</volume>
<pages>645--62</pages>
<marker>3.</marker>
<rawString>Colby, Benjamin N. 1973. American Anthropologist 75, 645-62.</rawString>
</citation>
<citation valid="false">
<booktitle>Florres d&apos;Arcaio and Levalt, eds. 1970 Advances in Psycholinguistics, North Holland,</booktitle>
<location>Amsterdam.</location>
<marker>4.</marker>
<rawString>Florres d&apos;Arcaio and Levalt, eds. 1970 Advances in Psycholinguistics, North Holland, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Merrill Garrett</author>
<author>F</author>
</authors>
<date>1970</date>
<note>in [5].</note>
<contexts>
<context position="6271" citStr="(5)" startWordPosition="981" endWordPosition="981">rrived at independent of any particular main program, for the simple reason that no programs of adequate complexity were available at the time. However, at the present time a grammar and lexicon Is being developed to use with at least two programs being developed by other people at MIT. They are an appointment scheduling program (Goldstein &apos;75) and an advisor to aid users of MACSYMA (Genesereth &apos;75). The short dialog below is an example of the degree of fluency we are hoping to eventually achieve. The dialog ts between a scheduling program acting as an appointment secretary (P), and a student (5). 7 (S) I want to see Professor Winston sometime in the next few days. (P) He&apos;s pretty busy all week. Can it wait? (S) No, it can&apos;t. All I need is his signature on a form. (P) Well, maybe he can squeeze you in tommorrow morning. Give me your name and check back in an hour. Messages Using the current message format and ignoring the details of the scheduler&apos;s representation, the phrase &amp;quot;maybe he can squeeze you in tommorrow&amp;quot; could have come from a message like this one, put together by one of the situation specialists. Message-1 features z ( prediction ) event (event actor &lt;Winston&gt; action &lt;fit </context>
</contexts>
<marker>5.</marker>
<rawString>Garrett, Merrill, F. 1970. in [5].</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Haynes</author>
</authors>
<title>Cognition and the Development of Language.</title>
<date>1970</date>
<publisher>John Wiley.</publisher>
<marker>6.</marker>
<rawString>Haynes, John R. 1970. Cognition and the Development of Language. John Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
</authors>
<date>1972</date>
<journal>A.I.</journal>
<volume>3</volume>
<pages>77--100</pages>
<marker>7.</marker>
<rawString>Kaplan, Ronald M. 1972. A.I. 3, 77-100</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kimball</author>
</authors>
<date>1974</date>
<journal>Cognition</journal>
<pages>2--1</pages>
<marker>8.</marker>
<rawString>Kimball, John 1974. Cognition 2,1,15-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodger Knaus</author>
</authors>
<title>Ph.D Thesis.</title>
<date>1975</date>
<publisher>U.C. Irvine.</publisher>
<contexts>
<context position="30875" citStr="(9)" startWordPosition="5002" endWordPosition="5002">onstant. Because humans can&apos;t remember large numbers of sentence words but must, process speech at an approximately constant rate, a constant parsing time per word is a necessary property of any algorithm modeling human language processing. Let the depth of constituent C in phrase marker P be defined as the length of the path from the root of C to the root of P. If TI and T2 are two adjacent terminals with Ti preceding T2, the depth difference from Ti to T2 is defined as the difference in depth between Ti and the root of the smallest tree containing Ti and T2. For example ip the phrase marker (9) (S (NP (NP (DET the) (N telephone)), (PP (PREP IN) (DET the) (N room))) (V rang) (ADV loudly)) the depth difference between &amp;quot;the&amp;quot; and &amp;quot;telephone&amp;quot; is 1 and between &amp;quot;room&amp;quot; and &amp;quot;rang&amp;quot; is 3. The depth difference between Ti and 12 is the number of nodes from Ti to the node expanded when adding T2 on a postorder traversal from Ti in the partial phrase marker containing Ti but not 12. The depth difference between Ti and Tg also represents the number of constituents of which Ti is the rightmost word. 24 A proof (requiring a forma.1 definition of the incremental parse) that parsing time per word is co</context>
</contexts>
<marker>9.</marker>
<rawString>Knaus, Rodger. 1975. Ph.D Thesis. U.C. Irvine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald G MacKay</author>
</authors>
<title>Perception and Psychophysics.</title>
<date>1966</date>
<pages>426--36</pages>
<contexts>
<context position="29184" citStr="[10]" startWordPosition="4711" endWordPosition="4711">(PP*)) (PP*)) would be obtained. The E is used to expand the leftmost unexpanded node of T1 for 3 la this results in: 3e. (S (V mail) (NP (NP (N Boxes) (N*)) PP*) (PP*)). Finally to the resulting structure the new sentence word is added through direct node expansion or attaching with an Acyclic left branching tree; in the example above this produces 3e from 3e: Using direct expansion attaching and embedding, the incremental parser finds all the phrase markers of sentences in context free or regular expression language; a formal definition of the parser and a proof of its correctness appear in [10]. Sometimes, as at steps 3b and 3e, the same structure (a prepositional phrase in step 2) is used in more than one partial parse. Following Earley&apos;s Algodrithm, the incremental parser builds a single copy of the shared substructure SO and maintains pointers linking SO to nodes in larger structures which SO expands. For all its tree building operations the incremental parser uses a finite set of trees i.e., the trees with only left subnodes expanded and at most oneicycle on the leftmost branch. These trees may be computed directly from the grammar and referenced by root and leftmost unexpanded </context>
<context position="31535" citStr="[10]" startWordPosition="5119" endWordPosition="5119"> the) (N room))) (V rang) (ADV loudly)) the depth difference between &amp;quot;the&amp;quot; and &amp;quot;telephone&amp;quot; is 1 and between &amp;quot;room&amp;quot; and &amp;quot;rang&amp;quot; is 3. The depth difference between Ti and 12 is the number of nodes from Ti to the node expanded when adding T2 on a postorder traversal from Ti in the partial phrase marker containing Ti but not 12. The depth difference between Ti and Tg also represents the number of constituents of which Ti is the rightmost word. 24 A proof (requiring a forma.1 definition of the incremental parse) that parsing time per word is constant in depth difference bounded sentences appears in [10]. Informally the depth difference bound places a bound both on the number of next nodes to expand which may follow a given terminal and on the amount of tree traversal which the parser must perform to find each next unexpanded node. Since each modification requires only a fixed number of operations, each of which is bounded on the finite set of at most once cyclic left branching trees, the computation adding a new word to existing partial parses is bounded inde pendently of sentence length. Natural language sentences tend to have small depth differenc-es. Both right branching sentences and lef</context>
</contexts>
<marker>10.</marker>
<rawString>MacKay, Donald G. 1966. Perception and Psychophysics. 426-36.</rawString>
</citation>
<citation valid="false">
<authors>
<author>James N Olson</author>
<author>Donald G MacKay</author>
</authors>
<journal>JVLVB</journal>
<volume>13</volume>
<pages>45770</pages>
<contexts>
<context position="32626" citStr="(11)" startWordPosition="5307" endWordPosition="5307"> length. Natural language sentences tend to have small depth differenc-es. Both right branching sentences and left branching sentences (found in Japanese for example) have an average depth difference over each three or four word segment of two or less On the other hand sentences are difficult to understand when they have two consecutive large depth differences,, such as the multiple center embedding (10) The ra.t the cat the dog bit chased diedL or the complex noun phrase in The pad on a clarinet in the last row whicn I fixed earlier for Eb fell out. Furthermore in ambiguous sentences such as (11) Joe figured that it was time to take the cat out. Kimball observes that subjects prfer the reading with the smaller depth difference. Finally, Blumenthal found that subjects tended to understand a multiple center embedded sentence as a 25 conjunctive sentence. The conjunctive sentence contains a rearrangement with lower depth differences of the constituents of the center embedded sentence. 3. Sentence Generation The syntactic form given to a sentence depends on the information being communicated in a sentence and on the cultural context in which the sentence appears. Clark and Haviland show t</context>
</contexts>
<marker>11.</marker>
<rawString>Olson, James N. and MacKay, Donald G. JVLVB 13, 45770.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S R Petrick</author>
</authors>
<note>In [14].</note>
<contexts>
<context position="33583" citStr="(12)" startWordPosition="5455" endWordPosition="5455">ituents of the center embedded sentence. 3. Sentence Generation The syntactic form given to a sentence depends on the information being communicated in a sentence and on the cultural context in which the sentence appears. Clark and Haviland show that a speaker uses various syntactic devices sentences to place the &amp;quot;given&amp;quot; information known to the listener before the information &amp;quot;new&amp;quot; to the listener. Particular syntactic structures are also used to emphasize or suppress particular kinds of information; for example newspaper traffic accident reports usually begin with a passive sentence such as (12) An elderly Lakewood man was injured when..., presumably to emphasize the result of the accident. To capture the dependence of syntax on semantic content and social context, the sentence generator uses function-like grammar rules of the form (Rulewame Cat Variables Predicate Forms). Rulename is the name of the rule and cat is the grammatical category of the constituent generated by the rule. Variables is a list of formal parameters. Usually the variable list contains a vartable bound during rule execution to a node in a semantic network and another variable bound to a control association list </context>
</contexts>
<marker>12.</marker>
<rawString>Petrick, S. R. In [14].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randall Rustin</author>
</authors>
<date>1973</date>
<journal>Natural Language Processing.</journal>
<contexts>
<context position="36041" citStr="(13)" startWordPosition="5879" endWordPosition="5879">Time(X)&gt; &lt;Value of Y&gt;) for generating optional prepositi.mal phrases or relative clauses. As each rule is applied, the list of terminals and calls to grammar rules generated by the rule is added to a phrase marker representing the structure of the sentence being generated. 27 Grammar calls in the phrase marker are expanded top down-and left to right, in a preorder traversal of the growing phrase marker. As terminals are generated they are printed out. As an example, illustrating the effect of semantic and social contest on sentence generation, an initial sentence of a traffic accident report, (13). A man was killed when a car hit him in Irvine. was generated from the semantic nodes Al: Agent AO A2: Agent AO: Class man Object VO Action hit Action Kill Object VO Place Irvine Instrument Car Cause AZ and the control alist. Purpose: Introduction;cases: object, cause, place using a grammar built for generating traffic accident report sentences. To summarize a trace of the generation, a call to the sentence rule with purpose = introduction generates a sentence call with voice = passive. The passive rule applies and a noun phrase on AO is called for. Because Purpose = Introduction a NP rule ap</context>
</contexts>
<marker>13.</marker>
<rawString>Rustin, Randall. 1973. Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wm Watt</author>
</authors>
<date>1970</date>
<note>In [7].</note>
<marker>14.</marker>
<rawString>Watt, Wm. 1970. In [7].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wm Woods</author>
</authors>
<title>In [14]. I would like to here acknowledge the suggestions made by</title>
<date>1973</date>
<marker>15.</marker>
<rawString>Woods, Wm. 1973. In [14]. I would like to here acknowledge the suggestions made by Robert F. Simmons, Carlota Smith, Mary Ross T. Rhyne, Laurent Siklossy, and Stanley Peters which have helped imprbve my understanding of nominal compounding.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Remarks on Nominalization,&amp;quot;</title>
<date>1970</date>
<booktitle>in Readings in English Transformational Grammar,</booktitle>
<editor>Jacobs, R. and Rosenbaum, P. eds. Ginn,</editor>
<location>Waltham, Massachusetts,</location>
<marker>1.</marker>
<rawString>Chomsky, N. &amp;quot;Remarks on Nominalization,&amp;quot; in Readings in English Transformational Grammar, Jacobs, R. and Rosenbaum, P. eds. Ginn, Waltham, Massachusetts, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gruber</author>
</authors>
<title>Studies in Lexical Relations.&amp;quot;</title>
<date>1965</date>
<booktitle>Pb. D. thesis, MIT,</booktitle>
<marker>2.</marker>
<rawString>Gruber, J. &amp;quot;Studies in Lexical Relations.&amp;quot; Pb. D. thesis, MIT, 1965.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Lees</author>
</authors>
<title>The Grammar of English Nominalizations.</title>
<date>1968</date>
<location>Mouton, The Hague,</location>
<marker>3.</marker>
<rawString>Lees, R. The Grammar of English Nominalizations. Mouton, The Hague, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rhyne</author>
</authors>
<title>Lexical Rules and Structures in a Computer Model of Nominal Compounding in English.&amp;quot;</title>
<date>1975</date>
<tech>Ph. D. thesis,</tech>
<institution>The University of Texas at Austin,</institution>
<marker>4.</marker>
<rawString>Rhyne, J. &amp;quot;Lexical Rules and Structures in a Computer Model of Nominal Compounding in English.&amp;quot; Ph. D. thesis, The University of Texas at Austin, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Simmons</author>
</authors>
<title>Semantic Networks: Their Computation and Use for Understanding English Sentences,&amp;quot;</title>
<date>1973</date>
<booktitle>in Computer Models of Thought</booktitle>
<editor>and Language, Schank, R. and Colby, K. eds. W. H. Freeman,</editor>
<location>San Francisco,</location>
<contexts>
<context position="6271" citStr="(5)" startWordPosition="981" endWordPosition="981">rrived at independent of any particular main program, for the simple reason that no programs of adequate complexity were available at the time. However, at the present time a grammar and lexicon Is being developed to use with at least two programs being developed by other people at MIT. They are an appointment scheduling program (Goldstein &apos;75) and an advisor to aid users of MACSYMA (Genesereth &apos;75). The short dialog below is an example of the degree of fluency we are hoping to eventually achieve. The dialog ts between a scheduling program acting as an appointment secretary (P), and a student (5). 7 (S) I want to see Professor Winston sometime in the next few days. (P) He&apos;s pretty busy all week. Can it wait? (S) No, it can&apos;t. All I need is his signature on a form. (P) Well, maybe he can squeeze you in tommorrow morning. Give me your name and check back in an hour. Messages Using the current message format and ignoring the details of the scheduler&apos;s representation, the phrase &amp;quot;maybe he can squeeze you in tommorrow&amp;quot; could have come from a message like this one, put together by one of the situation specialists. Message-1 features z ( prediction ) event (event actor &lt;Winston&gt; action &lt;fit </context>
</contexts>
<marker>5.</marker>
<rawString>Simmons, R. &amp;quot;Semantic Networks: Their Computation and Use for Understanding English Sentences,&amp;quot; in Computer Models of Thought and Language, Schank, R. and Colby, K. eds. W. H. Freeman, San Francisco, 1973.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>