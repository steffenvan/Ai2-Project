<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000125">
<title confidence="0.987719">
Aspect Extraction through Semi-Supervised Modeling
</title>
<author confidence="0.998854">
Arjun Mukherjee Bing Liu
</author>
<affiliation confidence="0.934641666666667">
Department of Computer Science Department of Computer Science
University of Illinois at Chicago University of Illinois at Chicago
Chicago, IL 60607, USA Chicago, IL 60607, USA
</affiliation>
<email confidence="0.996202">
arjun4787@gmail.com liub@cs.uic.edu
</email>
<sectionHeader confidence="0.998569" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999919565217391">
Aspect extraction is a central problem in
sentiment analysis. Current methods either
extract aspects without categorizing them,
or extract and categorize them using
unsupervised topic modeling. By
categorizing, we mean the synonymous
aspects should be clustered into the same
category. In this paper, we solve the
problem in a different setting where the
user provides some seed words for a few
aspect categories and the model extracts
and clusters aspect terms into categories
simultaneously. This setting is important
because categorizing aspects is a subjective
task. For different application purposes,
different categorizations may be needed.
Some form of user guidance is desired. In
this paper, we propose two statistical
models to solve this seeded problem, which
aim to discover exactly what the user
wants. Our experimental results show that
the two proposed models are indeed able to
perform the task effectively.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999926888888889">
Aspect-based sentiment analysis is one of the main
frameworks for sentiment analysis (Hu and Liu,
2004; Pang and Lee, 2008; Liu, 2012). A key task
of the framework is to extract aspects of entities
that have been commented in opinion documents.
The task consists of two sub-tasks. The first sub-
task extracts aspect terms from an opinion corpus.
The second sub-task clusters synonymous aspect
terms into categories where each category
represents a single aspect, which we call an aspect
category. Existing research has proposed many
methods for aspect extraction. They largely fall
into two main types. The first type only extracts
aspect terms without grouping them into categories
(although a subsequent step may be used for the
grouping, see Section 2). The second type uses
statistical topic models to extract aspects and group
them at the same time in an unsupervised manner.
Both approaches are useful. However, in practice,
one also encounters another setting, where
grouping is not straightforward because for
different applications the user may need different
groupings to reflect the application needs. This
problem was reported in (Zhai et al., 2010), which
gave the following example. In car reviews,
internal design and external design can be regarded
as two separate aspects, but can also be regarded as
one aspect, called “design”, based on the level of
details that the user wants to study. It is also
possible that the same word may be put in different
categories based on different needs. However,
(Zhai et al., 2010) did not extract aspect terms. It
only categorizes a set of given aspect terms.
In this work, we propose two novel statistical
models to extract and categorize aspect terms
automatically given some seeds in the user
interested categories. It is thus able to best meet the
user’s specific needs. Our models also jointly
model both aspects and aspect specific sentiments.
The first model is called SAS and the second
model is called ME-SAS. ME-SAS improves SAS
by using Maximum-Entropy (or Max-Ent for short)
priors to help separate aspects and sentiment terms.
However, to train Max-Ent, we do not need
manually labeled training data (see Section 4).
</bodyText>
<page confidence="0.976925">
339
</page>
<note confidence="0.985825">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 339–348,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999971096774193">
In practical applications, asking users to provide
some seeds is easy as they are normally experts in
their trades and have a good knowledge what are
important in their domains.
Our models are related to topic models in
general (Blei et al., 2003) and joint models of
aspects and sentiments in sentiment analysis in
specific (e.g., Zhao et al., 2010). However, these
current models are typically unsupervised. None of
them can use seeds. With seeds, our models are
thus semi-supervised and need a different
formulation. Our models are also related to the DF-
LDA model in (Andrzejewski et al., 2009), which
allows the user to set must-link and cannot-link
constraints. A must-link means that two terms must
be in the same topic (aspect category), and a
cannot-link means that two terms cannot be in the
same topic. Seeds may be expressed with must-
links and cannot-links constraints. However, our
models are very different from DF-LDA. First of
all, we jointly model aspect and sentiment, while
DF-LDA is only for topics/aspects. Joint modeling
ensures clear separation of aspects from sentiments
producing better results. Second, our way of
treating seeds is also different from DF-LDA. We
discuss these and other related work in Section 2.
The proposed models are evaluated using a large
number of hotel reviews. They are also compared
with two state-of-the-art baselines. Experimental
results show that the proposed models outperform
the two baselines by large margins.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998388897058824">
There are many existing works on aspect
extraction. One approach is to find frequent noun
terms and possibly with the help of dependency
relations (Hu and Liu, 2004; Popescu and Etzioni,
2005; Zhuang et al., 2006; Blair-Goldensohn et al.,
2008; Ku et al., 2006; Wu et al., 2009;
Somasundaran and Wiebe, 2009; Qiu et al., 2011).
Another approach is to use supervised sequence
labeling (Liu, Hu and Cheng 2005; Jin and Ho,
2009; Jakob and Gurevych, 2010; Li et al., 2010;
Choi and Cardie, 2010; Kobayashi et al., 2007; Yu
et al., 2011). Ma and Wan (2010) also exploited
centering theory, and (Yi et al., 2003) used
language models. However, all these methods do
not group extracted aspect terms into categories.
Although there are works on grouping aspect terms
(Carenini et al., 2005; Zhai et al., 2010; Zhai et al.,
2011; Guo et al., 2010), they all assume that aspect
terms have been extracted beforehand.
In recent years, topic models have been used to
perform extraction and grouping at the same time.
Existing works are based on two basic models,
pLSA (Hofmann, 1999) and LDA (Blei et al.,
2003). Some existing works include discovering
global and local aspects (Titov and McDonald,
2008), extracting key phrases (Branavan et al.,
2008), rating multi-aspects (Wang et al., 2010;
Moghaddam and Ester, 2011), summarizing
aspects and sentiments (Lu et al., 2009), and
modeling attitudes (Sauper et al., 2011). In (Lu and
Zhai, 2008), a semi-supervised model was
proposed. However, their method is entirely
different from ours as they use expert reviews to
guide the analysis of user reviews.
Aspect and sentiment extraction using topic
modeling come in two flavors: discovering aspect
words sentiment wise (i.e., discovering positive
and negative aspect words and/or sentiments for
each aspect without separating aspect and
sentiment terms) (Lin and He, 2009; Brody and
Elhadad, 2010, Jo and Oh, 2011) and separately
discovering both aspects and sentiments (e.g., Mei
et al., 2007; Zhao et al., 2010). Zhao et al. (2010)
used Maximum-Entropy to train a switch variable
to separate aspect and sentiment words. We adopt
this method as well but with no use of manually
labeled data in training. One problem with these
existing models is that many discovered aspects
are not understandable/meaningful to users. Chang
et al. (2009) stated that one reason is that the
objective function of topic models does not always
correlate well with human judgments. Our seeded
models are designed to overcome this problem.
Researchers have tried to generate “meaningful”
and “specific” topics/aspects. Blei and McAuliffe
(2007) and Ramage et al. (2009) used document
label information in a supervised setting. Hu et al.
(2011) relied on user feedback during Gibbs
sampling iterations. Andrzejewski et al. (2011)
incorporated first-order logic with Markov Logic
Networks. However, it has a practical limitation
for reasonably large corpora since the number of
non-trivial groundings can grow to O(N2) where N
is the number of unique tokens in the corpus.
Andrzejewski et al. (2009) used another approach
(DF-LDA) by introducing must-link and cannot-
link constraints as Dirichlet Forest priors. Zhai et
al. (2011) reported that the model does not scale up
</bodyText>
<page confidence="0.998099">
340
</page>
<figureCaption confidence="0.9988">
Figure 1: Prior structure: (a) Standard ASMs, (b) Two-level tree structured distribution. Graphical models in plate
notation: (c) SAS and (d) ME-SAS.
</figureCaption>
<figure confidence="0.999077807692308">
u a
xa
u a
wa
wa
Nd, s
Nd, s
Sd
Sd
D
D
φO
a
φA Ω
a
φA Ω
a a
φO
a
C
C
T
T
T
T
φA
α a
room stain bed staff linens service shower pillows walls friendly
θ a
z ψa
a
δa
αa
θ a
za
ra
r a
ψa
Seeds:
{staff, service}
{linens, bed, pillows}
φA
stain walls Ω shower Ω friendly room
staff service bed linens pillows
βO
a
βAa
γ βO βA
a a a
γa
(b) (c) (d)
λ a
</figure>
<figureCaption confidence="0.600058714285714">
when the number of cannot-links go beyond 1000
because the number of maximal cliques Q(r) in a
connected component of size |r |in the cannot-link
graph is exponential in r. Note that we could still
experiment with DF-LDA as our problem size is
not so large. We will show in Section 4 that the
proposed models outperform it by a large margin.
</figureCaption>
<sectionHeader confidence="0.981224" genericHeader="method">
3 Proposed Seeded Models
</sectionHeader>
<bodyText confidence="0.97854670212766">
The standard LDA and existing aspect and
sentiment models (ASMs) are mostly governed by
the phenomenon called “higher-order co-
occurrence” (Heinrich, 2009), i.e., based on how
often terms co-occur in different contexts1. This
unfortunately results in many “non-specific” terms
being pulled and clustered. We employ seed sets to
address this issue by “guiding” the model to group
semantically related terms in the same aspect thus
making the aspect more specific and related to the
seeds (which reflect the user needs). For easy
presentation, we will use aspect to mean aspect
category from now on. We replace the multinomial
distribution over words for each aspect (as in
ASMs) with a special two-level tree structured
distribution. The generative process of ASMs
assumes that each vocabulary word is
independently (i.e., not dependent upon other
word-aspect association) and equally probable to
be associated with any aspect. Due to higher-order
co-occurrences, we find conceptually different
terms yet related in contexts (e.g., in hotel domain
terms like stain, shower, walls in aspect
1 w1 co-occurring with w2 which in turn co-occurs with w3 denotes a
second-order co-occurrence between w1 and w3.
Maintenance; bed, linens, pillows in aspect
Cleanliness) equally probable of emission for any
aspect. Figure 1(a) shows an example tree. Upon
adding the seed sets {bed, linens, pillows} and
{staff, service}, the prior structure now changes to
the correlated distribution in Figure 1 (b). Thus,
each aspect has a top level distribution over non-
seed words and seed sets. Each seed set in each
aspect further has a second level distribution over
seeds in that seed set. The aspect term (word)
emission now requires two steps: first sampling at
level one to obtain a non-seed word or a seed set. If
a non-seed word is sampled we emit it else we
further sample at the second seed set level and emit
a seed word. This ensures that seed words together
have either all high or low aspect associations.
Furthermore, seed sets preserve conjugacy between
related concepts and also shape more specific
aspects by clustering based on higher order co-
occurrences with seeds rather than only with
standard one level multinomial distribution over
words (or terms) alone.
</bodyText>
<subsectionHeader confidence="0.981552">
3.1 SAS Model
</subsectionHeader>
<bodyText confidence="0.960446846153846">
We now present the proposed Seeded Aspect and
Sentiment model (SAS). Let ݒଵ...௏ denote the
entries in our vocabulary where ܸ is the number of
unique non-seed terms. Let there be ܥ seed sets
ܳ௟ୀଵ...஼ where each seed set ܳ௟ is a group of
semantically related terms. Let ߮௧ୀଵ...்
஺ , ߮௧ୀଵ...்
ை
denote T aspect and aspect specific sentiment
models. Also let ߗ௧,௟ denote the aspect specific
distribution of seeds in the seed set ܳ௟. Following
the approach of (Zhao et al., 2010), we too assume
that a review sentence usually talks about one
</bodyText>
<page confidence="0.967096">
341
</page>
<figure confidence="0.8211038">
ۓ
ۖ
۔
ۖ
ە
</figure>
<bodyText confidence="0.994743">
aspect. A review document ݀ଵ...஽ comprises of ܵௗ
sentences and each sentence ݏ א ܵௗ has ܰௗ,௦words.
Also, let ܵ݁݊ݐ௦ௗ denote the sentence ݏ of document
݀. To distinguish between aspect and sentiment
terms, we introduce an indicator (switch) variable
ݎௗ,௦,௝ א ሼܽො, ݋ොሽ for the ݆௧௛term of ܵ݁݊ݐ௦ௗ, ݓௗ,௦,௝.
Further, let ߰ௗ,௦ denote the distribution of aspects
and sentiments in ܵ݁݊ݐ௦ௗ. The generative process of
the SAS model (see Figure 1(c)) is given by:
</bodyText>
<figure confidence="0.827932136363636">
1. For each aspect ݐ א ሼ1, ..., ܶሽ:
i. Draw ߮௧ை ~ ܦ݅ݎሺߚைሻ
ii. Draw a distribution over terms and seed sets ߮௧஺ ~ ܦ݅ݎሺߚ஺ሻ
a) For each seed set ݈ א ሼܳଵ, ... , ܳ஼ሽ
Draw a distribution over seeds ߗ௧,௟ ~ ܦ݅ݎሺߛሻ
2. For each (review) document ݀ א ሼ1, ..., ܦሽ:
i. Draw ߠௗ ~ ܦ݅ݎሺߙሻ
ii. For each sentence ݏ א ሼ1, ... , ܵௗሽ:
a) Draw ݖௗ,௦ ~ ܯݑ݈ݐሺߠௗሻ
b) Draw ߰ௗ,௦ ~ ܤ݁ݐܽሺߜሻ
c) For each term ݓௗ,௦,௝ where ݆ א ሼ1, ..., ܰௗ,௦ሽ:
I. Draw ݎௗ,௦,௝ ~ ܤ݁ݎ݊݋ݑ݈݈݅൫߰ௗ,௦൯, ݎௗ,௦,௝ א ሼܽො, ݋ොሽ
II. if ݎௗ,௦,௝ ൌ ݋ො // ݓௗ,௦,௝ is a sentiment
Emit ݓௗ,௦,௝ ~ ܯݑ݈ݐሺ߮௭೏,ೞ
ை ሻ
else // ݎௗ,௦,௝ ൌ ܽො , ݓௗ,௦,௝ is an aspect
A. Draw ݑௗ,௦,௝ ~ ܯݑ݈ݐሺ߮௭೏,ೞ
஺ ሻ
B. if ݑௗ,௦,௝ א ܸ // non-seed term
Emit ݓௗ,௦,௝ ൌ ݑௗ,௦,௝
else // ݑௗ,௦,௝ is some seed set index say ݈ௗ,௦,௝
Emit ݓௗ,௦,௝ ~ ߗ௭೏,ೞ ,௟೏,ೞ,ೕ
</figure>
<bodyText confidence="0.99987425">
We employ collapsed Gibbs sampling (Griffiths
and Steyvers, 2004) for posterior inference. As ݖ
and ݎ are at different hierarchical levels, we derive
their samplers separately as follows:
</bodyText>
<equation confidence="0.997584617021277">
ܤ൫݊௧,ሾሿ
ை ൅ ߚை൯
݌൫ݖௗ,௦ ൌ ݐ หܼ൓ௗ,௦, ܴ൓ௗ,௦, ܹ൓ௗ,௦ , ܷ൓ௗ,௦ሻ ן ൈ
ை ை
ܤ ቀ݊௧,ሾሿ൓ௗ,௦ ൅
ೄ೐೙೟.
஻ሺ௡೟,ሾሿ
ೆ,ಲା ఉಲሻ ାఈ
஼ ൓೏,ೞ
ఉಲሻ ൈ ∏ ஻ሺ௡೟,೗,ሾሿ
ೄ,ಲ ା ఊሻ ௡೏,೟
ൈ
௟ୀଵ
஻ሺ௡೟,ሾሿ
ೆ,ಲ ൓೏,ೞା ஻ሺ௡೟,೗,ሾሿ
ೄ,ಲ ା்ఈ (1)
൓೏,ೞା ఊሻ ௡೏,ሺ·ሻ
ೄ೐೙೟.
൓೏,ೞ݌൫ݎௗ,௦,௝ ൌ ݋ොหܼ൓ௗ,௦, ܴ൓ௗ,௦,௝, ܹ൓ௗ,௦,௝ , ܷ൓ௗ,௦,௝, ݖௗ,௦ ൌ ݐ, ݓௗ,௦,௝ ൌ ݓ൯ ן
௡೟,ሺ·ሻ
ೀ ൓೏,ೞ,ೕ
௡೟,ೢೀ൓೏,ೞ,ೕାఉೀ
ା|௏׫ڂ ೗ொ ೗|ఉೀ ൈ ௡೏,ೞ
ಲ ൓೏,ೞ,ೕାఋೌା ௡೏,ೞ
௡೏,ೞ
ೀ൓೏,ೞ,ೕାఋ್
ೀ ൓೏,ೞ,ೕାఋ್ (2)
݌൫ݎௗ,௦,௝ ൌ ܽොห ... ൯ ן
௡೟,೗,ሺ·ሻ
ೄ,ಲ ௡೟,ሺ·ሻ
௡೟,೗,ೢ൓೏,ೞ,ೕ ାఊ ௡೟,೗
ೄ,ಲ
൓೏,ೞ,ೕ ା|ொ೗|ఊ ൈ ೾ ାሺ௏ା஼ሻఉಲ ൈ
೾ ାఉಲ
ಲ ൓೏,ೞ,ೕାఋ್ ;
௡೏,ೞ ݓ א ܳ௟ (3)
ೀ ൓೏,ೞ,ೕାఋ್
ಲ ൓೏,ೞ,ೕାఋೌା ௡೏,ೞ
௡೏,ೞ
௡೏,ೞ
ಲ ൓೏,ೞ,ೕାఋ್ ൓೏,ೞ,ೕାఋ್ ;׍݈, ݓ א ܳ௟
௡೏,ೞ
ಲ ൓೏,ೞ,ೕାఋೌା ௡೏,ೞ
ೀ
ౚ౟ౣ ሺೣሬሬԦሻ
∏ ௰ሺ௫೔ሻ
೔సభ
</equation>
<bodyText confidence="0.836275">
where ܤሺݔԦሻ ൌ is the multinomial Beta
</bodyText>
<equation confidence="0.94352275">
ሺೣሬሬԦሻ
௰ሺ∑ ౚ౟ౣ
೔సభ ሻ
௫೔
</equation>
<bodyText confidence="0.993151517857143">
function. ݊௧,௩ ை is the number of times term ݒ was
assigned to aspect ݐ as an opinion/sentiment word.
݊௧,௩௎,஺ is the number of times non-seed term ݒ א ܸ
was assigned to aspect ݐ as an aspect. ݊௧,௟,௩
ௌ,஺ is the
number of times seed term ݒ א ܸ௟ was assigned to
aspect ݐ as an aspect. ݊ௗ,௧
ௌ௘௡௧. is the number of
sentences in document ݀ that were assigned to
aspect ݐ. ݊ௗ,௦
஺ and ݊ௗ,௦
ை denote the number of terms
in ܵ݁݊ݐ௦ௗ that were assigned to aspects and opinions
respectively. ݊௧,௟
ఆ is the number of times any term of
seed set ܳ௟ was assigned to aspect ݐ. Omission of a
latter index denoted by [] in the above notation
represents the corresponding row vector spanning
over the latter index. For example, ݊௧,ሾሿ
௎,஺ ൌ
ሾ݊௧,௩ୀଵ
௎,஺ , ... , ݊௧,௩ୀ௏
௎,஺ ሿ and (·) denotes the marginalized
sum over the latter index. The subscript ൓݀, ݏ
denotes the counts excluding assignments of all
terms in ܵ݁݊ݐ௦ௗ. ൓݀, ݏ, ݆ denotes counts excluding
ݓௗ,௦,௝.We perform hierarchical sampling. First, an
aspect is sampled for each sentence ݖௗ,௦ using Eq.
(1). After sampling the aspect, we sample ݎௗ,௦,௝.
The probability of ݓௗ,௦,௝ being an opinion or
sentiment term, ݌ሺݎௗ,௦,௝ ൌ ݋ොሻ is given by Eq. (2).
However, for ݌ሺݎௗ,௦,௝ ൌ ܽොሻ we have two cases: (a)
the observed term ݓ ൌ ݓௗ,௦,௝ א ܳ௟ or (b) does not
belong to any seed set, ׍݈, ݓ א ܳ௟, i.e., w is an non-
seed term. These cases are dealt in Eq. (3).
Asymmetric Beta priors: Hyper-parameters α, βO,
βA are not very sensitive and the heuristic values
suggested in (Griffiths and Steyvers, 2004) usually
hold well in practice (Wallach et al. 2009).
However, the smoothing hyper-parameter ߜ
(Figure 1(c)) is crucial as it governs the aspect or
sentiment switch. Essentially, ߰ௗ,௦~ܤ݁ݐܽሺߜߦԦሻ is the
probability of emitting an aspect term2 in ܵ݁݊ݐ௦ௗ
with concentration parameter ߜ and base measure
Ԧ
ߦ ൌ ሾߦ௔,ߦ௕ሿ. Without any prior belief, uniform
base measures ߦ௔ ൌ ߦ௕ ൌ 0.5 are used resulting in
symmetric Beta priors. However, aspects are often
more probable than sentiments in a sentence (e.g.,
“The beds, sheets, and bedding were dirty.”). Thus,
it is more principled to employ asymmetric priors.
Using a labeled set of sentences, ܵ௟௔௕௘௟௘ௗ, where
we know the per sentence probability of aspect
emission (߰ௗ,௦), we can employ the method of
moments to estimate the smoothing hyper-
parameter ߜ ൌ ሾߜ௔, ߜ௕ሿ:
</bodyText>
<equation confidence="0.993996">
ߜ௔ ൌ ߤ ቀఓሺଵିఓሻ
ఙ െ 1ቁ , ߜ௕ ൌߜ௔ ቀଵ ఓ െ 1ቁ ; ߤ ൌ ܧൣ߰ௗ,௦൧, ߪ ൌ ܸܽݎൣ߰ௗ,௦൧
(4)
</equation>
<bodyText confidence="0.5200125">
2 ݎௗ,௦,௝~ ܤ݁ݎ݊݋ݑ݈݈݅ሺ߰ௗ,௦ሻ. ߰ௗ,௦ , 1 െ ߰ௗ,௦ are the success and failure
probability of emitting an aspect/sentiment term.
</bodyText>
<equation confidence="0.931059">
௡೟,ሺ·ሻ
ೆ,ಲାሺ௏ା஼ሻ ఉಲ
௡೟,ೢ ೆ,ಲା ఉಲ ൈ
</equation>
<page confidence="0.943573">
342
</page>
<figure confidence="0.991685857142857">
ۓ
ۖ
ۖ
۔
ۖ
ۖ
ە
</figure>
<subsectionHeader confidence="0.513776">
3.2 ME-SAS Model
</subsectionHeader>
<bodyText confidence="0.93138245">
We can further improve SAS by employing
Maximum Entropy (Max-Ent) priors for aspect and
sentiment switching. We call this new model ME-
SAS. The motivation is that aspect and sentiment
terms play different syntactic roles in a sentence.
Aspect terms tend to be nouns or noun phrases
while sentiment terms tend to be adjectives,
adverbs, etc. POS tag information can be elegantly
encoded by moving ߰ௗ,௦ to the term plate (see
Figure 1(d)) and drawing it from a Max-
Entሺݔ݀,ݏ,݆; ߣሻ model. Let
ݔௗ,௦,ఫሬሬሬሬሬሬሬԦ ൌ ሾܱܲܵ௪೏,ೞ,ೕିଵ, ܱܲܵ௪೏,ೞ,ೕ, ܱܲܵ௪೏,ೞ,ೕାଵ,ݓௗ,௦,௝ െ 1, ݓௗ,௦,௝, ݓௗ,௦,௝ ൅
1ሿ denote the feature vector associated with ݓௗ,௦,௝
encoding lexical and POS features of the previous,
current and next term. Using a training data set, we
can learn Max-Ent priors. Note that unlike
traditional Max-Ent training, we do not need
manually labeled data for training (see Section 4
for details). For ME-SAS, only the sampler for the
switch variable r changes as follows:
</bodyText>
<equation confidence="0.998897133333333">
݌൫ݎௗ,௦,௝ ൌ ݋ොหܼ൓ௗ,௦, ܴ൓ௗ,௦,௝, ܹ൓ௗ,௦,௝ , ܷ൓ௗ,௦,௝, ݖௗ,௦ ൌ ݐ, ݓௗ,௦,௝ ൌ ݓ൯ ן
௘௫௣൫∑ఒ೔௙೔൫௫೏,ೞ,ೕ,௢ො൯
೙ ൯
೔సభ
(5)
∑ ௘௫௣൫∑ ఒ೔௙೔൫௫೏,ೞ,ೕ,௬൯
೙
೤אሼೌෝ,೚ෝሽ ൯
೔సభ
݌൫ݎௗ,௦,௝ ൌ ܽොห ... ൯ ן
ೄ,ಲ
௡೟,೗,ೢ൓೏,ೞ,ೕାఊ ௡೟,೗
೾ ାఉಲ
ൈ
௡೟,೗,ሺ·ሻ
ೄ,ಲ ௡೟,ሺ·ሻ
೾ ାሺ௏ା஼ሻఉಲ ൈ
ା|ொ೗|ఊ
൓೏,ೞ,ೕ
௘௫௣൫∑ ఒ೔௙೔൫௫೏,ೞ,ೕ,௔ො൯
೙ ൯
೔సభ
; ݓ א ܳ௟
∑೤אሼೌෝ,೚ෝሽ ௘௫௣൫∑೔೙సభ ఒ೔௙೔൫௫೏,ೞ,ೕ,௬൯൯
௘௫௣൫∑ ఒ೔௙೔൫௫೏,ೞ,ೕ,௔ො൯
೙ ൯
೔సభ ൯; ׍݈, ݓ א ܳ௟
∑ ௘௫௣൫∑ ఒ೔௙೔൫௫೏,ೞ,ೕ,௬൯
೙
೤אሼೌෝ,೚ෝሽ ೔సభ
</equation>
<bodyText confidence="0.999600666666667">
where ߣଵ...௡ are the parameters of the learned Max-
Ent model corresponding to the ݊ binary feature
functions ݂ଵ...௡ of Max-Ent.
</bodyText>
<sectionHeader confidence="0.999819" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999909548387097">
This section evaluates the proposed models. Since
the focus in this paper is to generate high quality
aspects using seeds, we will not evaluate
sentiments although both SAS and ME-SAS can
also discover sentiments. To compare the
performance with our models, we use two existing
state-of-the-art models, ME-LDA (Zhao et al.
2010) and DF-LDA (Andrzejewski et al., 2009).
As discussed in Section 2, there are two main
flavors of aspect and sentiment models. The first
flavor does not separate aspect and sentiment, and
the second flavor uses a switch to perform the
separation. Since our models also perform a
switch, it is natural to compare with the latter
flavor, which is also more advanced. ME-LDA is
the representative model in this flavor. DF-LDA
adds constraints to LDA. We use our seeds to
generate constraints for DF-LDA. While ME-LDA
cannot consider constraints, DF-LDA does not
separate sentiments and aspects. Apart from other
modeling differences, our models can do both,
which enable them to produce much better results.
Dataset and Settings: We used hotel reviews from
tripadvisor.com. Our corpus consisted of 101,234
reviews and 692,783 sentences. Punctuations, stop
words 3, and words appearing less than 5 times in
the corpus were removed.
For all models, the posterior inference was
drawn after 5000 Gibbs iterations with an initial
burn-in of 1000 iterations. For SAS and ME-SAS,
we set α = 50/T, βA = βO = 0.1 as suggested in
(Griffiths and Steyvers, 2004). To make the seeds
more effective, we set the seed set word-
distribution hyper-parameter γ to be much larger
than βA, the hyper-parameter for the distribution
over seed sets and aspect terms. This results in
higher weights to seeded words which in turn
guide the sampler to cluster relevant terms better.
A more theoretical approach would involve
performing hyper-parameter estimation (Wallach
et al., 2009) which may reveal specific properties
of the dataset like the estimate of α (indicating how
different documents are in terms of their latent
semantics), β (suggesting how large the groups of
frequently appearing aspect and sentiment terms
are) and γ (giving a sense of which and how large
groupings of seeds are good). These are interesting
questions and we defer it to our future work. In this
work, we found that the setting γ = 250, a larger
value compared to βA, produced good results.
For SAS, the asymmetric Beta priors were
estimated using the method of moments (Section
3.1). We sampled 500 random sentences from the
corpus and for each sentence identified the aspects.
We thus computed the per-sentence probability of
aspect emission (߰ௗ,௦) and used Eq. (4) to compute
the final estimates, which give δd = 2.35, δb = 3.44.
To learn the Max-Ent parameters λ of ME-SAS,
we used the sentiment lexicon 4 of (Hu and Liu,
2004) to automatically generate training data (no
manual labeling). We randomly sampled 1000
terms from the corpus which have appeared at least
</bodyText>
<footnote confidence="0.96044">
3 http://jmlr.csail.mit.edu/papers/volume5/lewis04a/a11-smart-stop-
list/english.stop
4 http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar
</footnote>
<equation confidence="0.95580725">
ೀ ఉೀ
௡೟,ೢ൓೏,ೞ,ೕା
ೀ ା|௏׫ڂ ೗ொ ೗|ఉೀ ൈ
൓೏,ೞ,ೕ
(6)
௡೟,ೢೆ,ಲା ఉಲ
௡ೆ,ಲାሺ௏ା஼ሻ ఉಲ ൈ
೟,ሺ·ሻ
</equation>
<page confidence="0.998093">
343
</page>
<table confidence="0.998126484848485">
Aspect ME-SAS SAS ME-LDA DF-LDA
(seeds)
Aspect Sentiment Aspect Sentiment Aspect Sentiment Topic
Staff attendant friendly attendant friendly staff friendly staff
(staff manager attentive waiter nice maintenance nice friendly
service waitress polite waitress dirty room courteous helpful
waiter maintenance nice manager comfortable upkeep extremely beds
hospitality bartender clean maintenance nice linens nice front
upkeep) waiters pleasant helpful clean room-service clean room
housekeeping slow waiters polite receptionist polite comfortable
receptionist courteous housekeeping extremely wait little large
waitstaff rude receptionist courteous pillow helpful receptionist
janitor professional polite efficient waiters better housekeeping
Cleanliness carpets clean hall clean cleanliness clean clean
(curtains hall dirty carpets dirty floor good pool
restroom towels comfortable towels fresh carpets dirty beach
floor bathtub fresh pillow old bed hot carpets
beds couch wet stain nice lobby large parking
cleanliness) mattress filthy mattress good bathroom nice bed
linens extra filthy enough staff fresh bathroom
wardrobe stain linens new closet thin nice
spa front interior front spa new comfortable
pillow worn bathtub friendly décor little suite
Comfort bedding comfortable bed nice bed great bed
(comfort bedcover clean linens dirty mattress clean mattress
mattress sofa soft sofa comfortable suites awesome nice
furniture linens nice bedcover large furniture dirty stay
couch bedroom uncomfortable hard clean lighting best lighting
pillows) suites spacious bedroom best décor comfortable lobby
décor hard privacy spacious room soft comfort
comforter comfy double only bedroom nice room
blanket dirty comfy big hallway only dirty
futon quiet futon extra carpet extra sofa
</table>
<tableCaption confidence="0.999966">
Table 1: Top ranked aspect and sentiment words in three aspects (please see the explanation in Section 4.1).
</tableCaption>
<bodyText confidence="0.9997594">
20 times (to ensure that the training set is
reasonably representative of the corpus). Of those
1000 terms if they appeared in the sentiment
lexicon, they were treated as sentiment terms, else
aspect terms. Clearly, labeling words not in the
sentiment lexicon as aspect terms may not always
be correct. Even with this noisy automatically-
labeled data, the proposed models can produce
good results. Since ME-LDA used manually
labeled training data for Max-Ent, we again
randomly sampled 1000 terms from our corpus
appearing at least 20 times and labeled them as
aspect terms or sentiment terms, so this labeled
data clearly has less noise than our automatically
labeled data. For both ME-SAS and ME-LDA we
used the corresponding feature vector of each
labeled term (in the context of sentences where it
occurs) to train the Max-Ent model. As DF-LDA
requires must-link and cannot-link constraints, we
used our seed sets to generate intra-seed set must-
link and inter-seed set cannot-link constraints. For
its hyper-parameters, we used the default values in
the package5 (Andrzejewski et al., 2009).
Setting the number of topics/aspects in topic
models is often tricky as it is difficult to know the
</bodyText>
<footnote confidence="0.486332">
5 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html
</footnote>
<bodyText confidence="0.999880238095238">
exact number of topics that a corpus has. While
non-parametric Bayesian approaches (Teh et al.,
2006) do exist for estimating the number of topics,
T, they strongly depend on the hyper-parameters
(Heinrich, 2009). As we use fixed hyper-
parameters, we do not learn T from Bayesian non-
parametrics. We used 9 major aspects (T = 9)
based on commonsense knowledge of what people
usually talk about hotels and some experiments.
These are Dining, Staff, Maintenance, Check In,
Cleanliness, Comfort, Amenities, Location and
Value for Money (VFM). However, it is important
to note that the proposed models are flexible and
do not need to have seeds for every aspect/topic.
Our experiments simulate the real-life situation
where the user may not know all aspects or have
no seeds for some aspects. Thus, we provided
seeds only to the first 6 of the 9 aspects/topics. We
will see that without seeds for all aspects, our
models not only can improve the seeded aspects
but also improve the non-seeded aspects.
</bodyText>
<subsectionHeader confidence="0.998508">
4.1 Qualitative Results
</subsectionHeader>
<bodyText confidence="0.99996975">
This section shows some qualitative results to give
an intuitive feeling of the results from different
models. Table 1 shows the aspect terms and
sentiment terms discovered by the 4 models for
</bodyText>
<page confidence="0.997342">
344
</page>
<bodyText confidence="0.999985090909091">
three aspects. Due to space limitations, we are
unable to show all 6 aspects for which we have
seeds. Since DF-LDA cannot separate aspects and
sentiments, we only show its topics (aspects). Red
(bold) colored words show semantic clustering
errors or inappropriate terms for different groups.
It is important to note that we judge the results
based on how they are related to the user seeds
(which represent the user need). The judgment is to
some extent subjective. What we reported here are
based on our judgments what are appropriate and
what are not for each aspect. For SAS, ME-SAS
and ME-LDA, we mark sentiment terms as errors
when they are grouped under aspects as these
models are supposed to separate sentiments and
aspects. For DF-LDA, the situation is different as it
is not meant to separate sentiment and aspect
terms, we use red italic font to indicate those
adjectives which are aspect specific adjectives (see
more discussion below). Our judgment may be
slightly unfair to ME-LDA and DF-LDA as their
results may make sense in some other ways.
However, that is precisely the purpose of this
work, to produce results that suit the user’s need
rather than something generic.
We can see from Table 1 that ME-SAS performs
the best. Next in order are SAS, ME-LDA, and
DF-LDA. We see that only providing a handful of
seeds (5) for the aspect Staff, ME-SAS can
discover highly specific words like manager,
attendant, bartender, and janitor. By specific, we
mean they are highly related to the given seeds.
While SAS also discovers specific words
benefiting from seeds, relying on Beta priors for
aspect and sentiment switching was less effective.
Next in performance is ME-LDA which although
produces reasonable results in general, several
aspect terms are far from what the user wants
based on the seeds, e.g., room, linens, wait, pillow.
Finally, we observe that DF-LDA does not perform
well either. One reason is that it is unable to
separate aspects and sentiments. Although
encoding the intra-seed set must-link and inter-
seed set cannot-link constraints in DF-LDA
discovers some specific words as ME-SAS, they
are much lower in the ranked order and hence do
not show up in the top 10 words in Table 1. As
DF-LDA is not meant to perform extraction and to
group both aspect and sentiment terms, we relax
the errors of DF-LDA due to correct aspect
specific sentiments (e.g., friendly, helpful for Staff
are correct aspect specific sentiments, but still
regard incorrect sentiments like front, comfortable,
large as errors) placed in aspect models. We call
this model DF-LDA-Relaxed.
</bodyText>
<subsectionHeader confidence="0.998713">
4.2 Quantitative Results
</subsectionHeader>
<bodyText confidence="0.999910863636364">
Topic models are often evaluated quantitatively
using perplexity and likelihood on held-out test
data (Blei et al., 2003). However, perplexity does
not reflect our purpose since our aim is not to
predict whether an unseen document is likely to be
a review of some particular aspect. Nor are we
trying to evaluate how well the unseen review data
fits our seeded models. Instead our focus is to
evaluate how well our learned aspects perform in
clustering specific terms guided by seeds. So we
directly evaluate the discovered aspect terms. Note
again we do not evaluate sentiment terms as they
are not the focus of this paper 6. Since aspects
produced by the models are rankings and we do
not know the number of correct aspect terms, a
natural way to evaluate these rankings is to use
precision @ n (or p@n), where n is a rank position.
Varying number of seeds: Instead of a fixed
number of seeds, we want to see the effect of the
number of seeds on aspect discovery. Table 2
reports the average p@n vs. the number of seeds.
The average is a two-way averaging. The first
average was taken over all combinations of actual
seeds selected for each aspect, e.g., when the
number of seeds is 3, out of the 5 seeds in each
aspect, all (3) combinations of seeds were tried and
the results averaged. The results were further
averaged over p@n for 6 aspects with seeds. We
start with 2 seeds and progressively increase them
to 5. Using only 1 seed per seed set (or per aspect)
has practically no effect because the top level
distribution V&apos; encodes which seed sets (and non-
seed words) to include; the lower-level distribution
Ω constrains the probabilities of the seed words to
be correlated for each of the seed sets. Thus,
having only one seed per seed set will result in
sampling that single word whenever that seed set is
chosen which will not have the effect of correlating
seed words so as to pull other words based on co-
occurrence with constrained seed words. From
Table 2, we can see that for all models p@n
progressively improves as the number of seeds
increases. Again ME-SAS performs the best
followed by SAS and DF-LDA.
</bodyText>
<footnote confidence="0.562182">
6 A qualitative evaluation of sentiment extraction based on Table 1 yields
the following order: ME-SAS, SAS, ME-LDA.
</footnote>
<page confidence="0.986042">
345
</page>
<table confidence="0.999232333333333">
No. of Seeds DF-LDA DF-LDA-Relaxed SAS ME-SAS
P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30
2 0.51 0.53 0.49 0.67 0.69 0.70 0.69 0.71 0.67 0.74 0.72 0.70
3 0.53 0.54 0.50 0.71 0.70 0.71 0.71 0.72 0.70 0.78 0.75 0.72
4 0.57 0.56 0.53 0.73 0.73 0.73 0.75 0.74 0.73 0.83 0.79 0.76
5 0.59 0.57 0.54 0.75 0.74 0.75 0.77 0.76 0.74 0.86 0.81 0.77
</table>
<tableCaption confidence="0.964968">
Table 2: Average p@n of the seeded aspects with the no. of seeds.
</tableCaption>
<table confidence="0.9999865">
Aspect ME-LDA DF-LDA DF-LDA-Relaxed SAS ME-SAS
P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30 P@10 P@20 P@30
Dining 0.70 0.65 0.67 0.50 0.60 0.63 0.70 0.70 0.70 0.80 0.75 0.73 0.90 0.85 0.80
Staff 0.60 0.70 0.67 0.40 0.65 0.60 0.60 0.75 0.67 0.80 0.80 0.70 1.00 0.90 0.77
Maintenance 0.80 0.75 0.73 0.40 0.55 0.56 0.60 0.70 0.73 0.70 0.75 0.76 0.90 0.85 0.80
Check In 0.70 0.70 0.67 0.50 0.65 0.60 0.80 0.75 0.70 0.80 0.70 0.73 0.90 0.80 0.76
Cleanliness 0.70 0.75 0.67 0.70 0.70 0.63 0.70 0.75 0.70 0.80 0.75 0.70 1.00 0.85 0.83
Comfort 0.60 0.70 0.63 0.60 0.65 0.50 0.70 0.75 0.63 0.60 0.75 0.67 0.90 0.80 0.73
Amenities 0.80 0.80 0.67 0.70 0.65 0.53 0.90 0.75 0.73 0.90 0.80 0.70 1.00 0.85 0.73
Location 0.60 0.70 0.63 0.50 0.60 0.56 0.70 0.70 0.67 0.60 0.70 0.63 0.70 0.75 0.67
VFM 0.50 0.55 0.50 0.40 0.50 0.46 0.60 0.60 0.60 0.50 0.50 0.50 0.60 0.55 0.53
Avg. 0.67 0.70 0.65 0.52 0.62 0.56 0.70 0.72 0.68 0.72 0.72 0.68 0.88 0.80 0.74
</table>
<tableCaption confidence="0.999913">
Table 3: Effect of performance on seeded and non-seeded aspects (5 seeds were used for the 6 seeded aspects).
</tableCaption>
<bodyText confidence="0.984285543478261">
Effect of seeds on non-seeded aspects: Here we
compare all models aspect wise and see the results
of seeded models SAS and ME-SAS on non-
seeded aspects (Table 3). Shaded cells in Table 3
give the p@n values for DF-LDA, DF-LDA-
Relaxed, SAS, and ME-SAS on three non-seeded
aspects (Amenities, Location, and VFM)7.
We see that across all the first 6 aspects with (5)
seeds ME-SAS outperforms all other models by
large margins in all top 3 ranked buckets p@10,
p@20 and p@30. Next in order are SAS, ME-LDA
and DF-LDA. For the last three aspects which did
not have any seed guidance, we find something
interesting. Seeded models SAS and especially
ME-SAS result in improvements of non-seeded
aspects too. This is because as seeds facilitate
clustering specific and appropriate terms in seeded
aspects, which in turn improves precision on non-
seeded aspects. This phenomenon can be clearly
seen in Table 1. In aspect Staff of ME-LDA, we
find pillow and linens being clustered. This is not a
“flaw” of the model per se, but the point here is
pillow and linens happen to co-occur many times
with other words like maintenance, staff, and
upkeep because “room-service” generally includes
staff members coming and replacing linens and
pillow covers. Although pillow and linens are
related to Staff, strictly speaking they are
semantically incorrect because they do not
represent the very concept “Staff” based on the
seeds (which reflect the user need). Presence of
7 Note that Tables 2 and 3 are different runs of the model. The variations in the
results are due to the random initialization of the Gibbs sampler.
seed sets in SAS and ME-SAS result in pulling
such words as linens and pillow (due to seeds like
beds and cleanliness in the aspect Cleanliness) and
ranking them higher in the aspect Cleanliness (see
Table 1) where they make more sense than Staff.
Lastly, we also note that the improvements in non-
seeded aspects are more pronounced for ME-SAS
than SAS as SAS encounters more switching errors
which counters the improvement gained by seeds.
In summary, the averages over all aspects (Table
3 last row) show that the proposed seeded models
SAS and ME-SAS outperform ME-LDA, DF-LDA
and even DF-LDA-Relaxed considerably.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999241428571429">
This paper studied the issue of using seeds to
discover aspects in an opinion corpus. To our
knowledge, no existing work deals with this
problem. Yet, it is important because in practice
the user often has something in mind to find. The
results obtained in a completely unsupervised
manner may not suit the user’s need. To solve this
problem, we proposed two models SAS and ME-
SAS which take seeds reflecting the user needs to
discover specific aspects. ME-SAS also does not
need any additional help from the user in its Max-
Ent training. Our results showed that both models
outperformed two state-of-the-art existing models
ME-LDA and DF-LDA by large margins.
</bodyText>
<sectionHeader confidence="0.998863" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.856065">
This work is supported in part by National Science
Foundation (NSF) under grant no. IIS-1111092.
</bodyText>
<page confidence="0.997928">
346
</page>
<sectionHeader confidence="0.996394" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999818234693877">
Andrzejewski, D., Zhu, X. and Craven, M. 2009.
Incorporating domain knowledge into topic modeling
via Dirichlet forest priors. Proceedings of
International Conference on Machine Learning
(ICML).
Andrzejewski, D., Zhu, X. and Craven, M. and Recht,
B. 2011. A framework for incorporating general
domain knowledge into latent Dirichlet allocation
using first-order logic. Proceedings of the 22nd
International Joint Conferences on Artificial
Intelligence (IJCAI).
Blair-Goldensohn, S., Hannan, K., McDonald, R.,
Neylon, T., Reis, G. A. and Reynar, J. 2008. Building
a sentiment summarizer for local service reviews.
Proceedings of WWW-2008 workshop on NLP in the
Information Explosion Era.
Blei, D., Ng, A. and Jordan, M. 2003. Latent dirichlet
allocation. The Journal of Machine Learning
Research 3: 993-1022.
Blei D. and McAuliffe, J. 2007. Supervised topic
models. Neural Information Processing Systems
(NIPS).
Branavan, S., Chen, H., Eisenstein J. and Barzilay, R.
2008. Learning document-level semantic properties
from free-text annotations. Proceedings of the
Annual Meeting of the Association for
Computational Linguistics (ACL).
Brody, S. and Elhadad, S. 2010. An Unsupervised
Aspect-Sentiment Model for Online Reviews.
Proceedings of The 2010 Annual Conference of the
North American Chapter of the ACL (NAACL).
Carenini, G., Ng, R. and Zwart, E. 2005. Extracting
knowledge from evaluative text. Proceedings of
Third Intl. Conf. on Knowledge Capture (K-CAP-
05).
Chang, J., Boyd-Graber, J., Wang, C. Gerrish, S. and
Blei, D. 2009. Reading tea leaves: How humans
interpret topic models. In Neural Information
Processing Systems (NIPS).
Choi, Y. and Cardie, C. 2010. Hierarchical sequential
learning for extracting opinions and their attributes.
Proceedings of Annual Meeting of the Association
for Computational (ACL).
Griffiths, T. and Steyvers, M. 2004. Finding scientific
topics. Proceedings of National Academy of Sciences
(PNAS).
Guo, H., Zhu, H., Guo, Z., Zhang, X. and Su, X. 2009.
Product feature categorization with multilevel latent
semantic association. Proceedings of ACM
International Conference on Information and
Knowledge Management (CIKM).
Heinrich, G. 2009. A Generic Approach to Topic
Models. Proceedings of the European Conference on
Machine Learning and Principles and Practice of
Knowledge Discovery in Databases (ECML/PKDD).
Hofmann, T. 1999. Probabilistic latent semantic
indexing. Proceedings of Conference on Uncertainty
in Artificial Intelligence (UAI).
Hu, Y., Boyd-Graber, J. and Satinoff, B. 2011.
Interactive topic modeling. Proceedings of Annual
Meeting of the Association for Computational
Linguistics (ACL), 2011.
Hu, M. and Liu, B. 2004. Mining and summarizing
customer reviews. International Conference on
Knowledge Discovery and Data Mining (ICDM).
Jakob, N. and Gurevych, I. 2010. Extracting Opinion
Targets in a Single-and Cross-Domain Setting with
Conditional Random Fields. Proceedings of
Conference on Empirical Methods in Natural
Language Processing (EMNLP).
Jin, W. and Ho, H. 2009. A novel lexicalized HMM-
based learning framework for web opinion mining.
Proceedings of International Conference on Machine
Learning (ICML).
Jo, Y. and Oh, A. 2011. Aspect and sentiment
unification model for online review analysis. ACM
Conference in Web Search and Data Mining
(WSDM).
Kobayashi, N., Inui, K. and Matsumoto, K. 2007.
Extracting aspect-evaluation and aspect-of relations
in opinion mining. Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural
Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL).
Ku, L., Liang, Y. and Chen, H. 2006. Opinion
extraction, summarization and tracking in news and
blog corpora. Proceedings of AAAI Symposium on
Computational Approaches to Analyzing Weblogs
(AAAI-CAAW&apos;06).
Li, F., Han, C., Huang, M., Zhu, X. Xia, Y., Zhang, S.
and Yu, H. 2010. Structure-aware review mining and
summarization. International Conference on
Computational Linguistics (COLING).
Lin, C. and He, Y. 2009. Joint sentiment/topic model for
sentiment analysis. Proceedings of ACM
International Conference on Information and
Knowledge Management (CIKM).
Liu, B. 2012. Sentiment Analysis and Opinion Mining.
</reference>
<page confidence="0.98326">
347
</page>
<reference confidence="0.999859639175258">
Morgan &amp; Claypool publishers (to appear in June
2012).
Liu, B, M. Hu, and J. Cheng. 2005. Opinion Observer:
Analyzing and comparing opinions on the web.
Proceedings of International Conference on World
Wide Web (WWW).
Lu, Y., Zhai, C. and Sundaresan, N. 2009. Rated aspect
summarization of short comments. Proceedings of
International Conference on World Wide Web
(WWW).
Lu, Y. and Zhai, C. 2008. Opinion Integration Through
Semi-supervised Topic Modeling. Proceedings of the
17th International World Wide Web Conference
(WWW).
Ma, T. and Wan, X. 2010. Opinion target extraction in
Chinese news comments. Proceedings of Coling
2010 Poster Volume (COLING).
Mei, Q., Ling, X., Wondra, M., Su, H. and Zhai, C.
2007. Topic sentiment mixture: modeling facets and
opinions in weblogs. Proceedings of International
Conference on World Wide Web (WWW).
Moghaddam, S. and Ester, M. 2011. ILDA:
interdependent LDA model for learning latent
aspects and their ratings from online product reviews.
Proceedings of the Annual ACM SIGIR International
conference on Research and Development in
Information Retrieval (SIGIR).
Pang, B. and Lee, L. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in
Information Retrieval.
Popescu, A. and Etzioni, O. 2005. Extracting product
features and opinions from reviews. Proceedings of
Conference on Empirical Methods in Natural
Language Processing (EMNLP).
Qiu, G., Liu, B., Bu, J. and Chen, C. 2011. Opinion
Word Expansion and Target Extraction through
Double Propagation. Computational Linguistics.
Ramage, D., Hall, D., Nallapati, R. and Manning, C.
2009. Labeled LDA: a supervised topic model for
credit attribution in multi-labeled corpora.
Proceedings of the Conference on Empirical Methods
in Natural Language Processing (EMNLP).
Sauper, C., Haghighi, A. and Barzilay, R. 2011. Content
models with attitude. Proceedings of the 49th Annual
Meeting of the Association for Computational
Linguistics (ACL).
Somasundaran, S. and Wiebe, J. 2009. Recognizing
stances in online debates, Proceedings of the 47th
Annual Meeting of the ACL and the 4th IJCNLP of
the AFNLP.
Teh, Y., Jordan, M., Beal, M. and Blei, D. 2006.
Hierarchical Dirichlet Processes. In Journal of the
American Statistical Association (JASA).
Titov, I. and McDonald, R. 2008. Modeling online
reviews with multi-grain topic models. Proceedings
of International Conference on World Wide Web
(WWW).
Wallach, H., Mimno, D. and McCallum, A. 2009.
Rethinking LDA: Why priors matter. In Neural
Information Processing Systems (NIPS).
Wang, H., Lu, Y. and Zhai, C. 2010. Latent aspect
rating analysis on review text data: a rating
regression approach. Proceedings of ACM SIGKDD
International Conference on Knowledge Discovery
and Data Mining (KDD).
Wu, Y., Zhang, Q., Huang, X. and Wu, L. 2009. Phrase
dependency parsing for opinion mining. Proceedings
of Conference on Empirical Methods in Natural
Language Processing (EMNLP).
Yi, J., Nasukawa, T., Bunescu, R. and Niblack, W.
2003. Sentiment analyzer: Extracting sentiments
about a given topic using natural language processing
techniques. Proceedings of IEEE International
Conference on Data Mining (ICDM).
Yu, J., Zha, Z. J., Wang, M. and Chua, T. S. 2011.
Aspect ranking: identifying important product
aspects from online consumer reviews. Proceedings
of the 49th Annual Meeting of the Association for
Computational Linguistics, Association for
Computational Linguistics (ACL).
Zhai, Z., Liu, B. Xu, H. and Jia, P. 2010. Grouping
Product Features Using Semi-Supervised Learning
with Soft-Constraints. Proceedings of International
Conference on Computational Linguistics
(COLING).
Zhai, Z., Liu, B. Xu, H. and Jia, P. 2011. Constrained
LDA for Grouping Product Features in Opinion
Mining. Proceedings of Pacific-Asia Conference on
Knowledge Discovery and Data Mining (PAKDD).
Zhao, W., Jiang, J., Yan, Y. and Li, X. 2010. Jointly
modeling aspects and opinions with a MaxEnt-LDA
hybrid. Proceedings of Conference on Empirical
Methods in Natural Language Processing (EMNLP).
Zhuang, L., Jing, F. and Zhu, X. 2006. Movie review
mining and summarization. Proceedings of
International Conference on Information and
Knowledge Management (CIKM).
</reference>
<page confidence="0.998059">
348
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.977978">
<title confidence="0.999631">Aspect Extraction through Semi-Supervised Modeling</title>
<author confidence="0.995542">Arjun Mukherjee Bing Liu</author>
<affiliation confidence="0.999931">Department of Computer Science Department of Computer Science University of Illinois at Chicago University of Illinois at Chicago</affiliation>
<address confidence="0.994826">Chicago, IL 60607, USA Chicago, IL 60607, USA</address>
<email confidence="0.998545">arjun4787@gmail.comliub@cs.uic.edu</email>
<abstract confidence="0.999532625">Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Andrzejewski</author>
<author>X Zhu</author>
<author>M Craven</author>
</authors>
<title>Incorporating domain knowledge into topic modeling via Dirichlet forest priors.</title>
<date>2009</date>
<booktitle>Proceedings of International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="4216" citStr="Andrzejewski et al., 2009" startWordPosition="657" endWordPosition="660">or Computational Linguistics In practical applications, asking users to provide some seeds is easy as they are normally experts in their trades and have a good knowledge what are important in their domains. Our models are related to topic models in general (Blei et al., 2003) and joint models of aspects and sentiments in sentiment analysis in specific (e.g., Zhao et al., 2010). However, these current models are typically unsupervised. None of them can use seeds. With seeds, our models are thus semi-supervised and need a different formulation. Our models are also related to the DFLDA model in (Andrzejewski et al., 2009), which allows the user to set must-link and cannot-link constraints. A must-link means that two terms must be in the same topic (aspect category), and a cannot-link means that two terms cannot be in the same topic. Seeds may be expressed with mustlinks and cannot-links constraints. However, our models are very different from DF-LDA. First of all, we jointly model aspect and sentiment, while DF-LDA is only for topics/aspects. Joint modeling ensures clear separation of aspects from sentiments producing better results. Second, our way of treating seeds is also different from DF-LDA. We discuss t</context>
<context position="8169" citStr="Andrzejewski et al. (2009)" startWordPosition="1289" endWordPosition="1292"> judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/aspects. Blei and McAuliffe (2007) and Ramage et al. (2009) used document label information in a supervised setting. Hu et al. (2011) relied on user feedback during Gibbs sampling iterations. Andrzejewski et al. (2011) incorporated first-order logic with Markov Logic Networks. However, it has a practical limitation for reasonably large corpora since the number of non-trivial groundings can grow to O(N2) where N is the number of unique tokens in the corpus. Andrzejewski et al. (2009) used another approach (DF-LDA) by introducing must-link and cannotlink constraints as Dirichlet Forest priors. Zhai et al. (2011) reported that the model does not scale up 340 Figure 1: Prior structure: (a) Standard ASMs, (b) Two-level tree structured distribution. Graphical models in plate notation: (c) SAS and (d) ME-SAS. u a xa u a wa wa Nd, s Nd, s Sd Sd D D φO a φA Ω a φA Ω a a φO a C C T T T T φA α a room stain bed staff linens service shower pillows walls friendly θ a z ψa a δa αa θ a za ra r a ψa Seeds: {staff, service} {linens, bed, pillows} φA stain walls Ω shower Ω friendly room st</context>
<context position="18582" citStr="Andrzejewski et al., 2009" startWordPosition="3155" endWordPosition="3158">אሼೌෝ,ෝሽ ௫൫∑సభ ఒ൫௫,ೞ,ೕ,௬൯൯ ௫൫∑ ఒ൫௫,ೞ,ೕ,ො൯  ൯ సభ ൯; ݈, ݓ א ܳ ∑ ௫൫∑ ఒ൫௫,ೞ,ೕ,௬൯  אሼೌෝ,ෝሽ సభ where ߣଵ... are the parameters of the learned MaxEnt model corresponding to the ݊ binary feature functions ݂ଵ... of Max-Ent. 4 Experiments This section evaluates the proposed models. Since the focus in this paper is to generate high quality aspects using seeds, we will not evaluate sentiments although both SAS and ME-SAS can also discover sentiments. To compare the performance with our models, we use two existing state-of-the-art models, ME-LDA (Zhao et al. 2010) and DF-LDA (Andrzejewski et al., 2009). As discussed in Section 2, there are two main flavors of aspect and sentiment models. The first flavor does not separate aspect and sentiment, and the second flavor uses a switch to perform the separation. Since our models also perform a switch, it is natural to compare with the latter flavor, which is also more advanced. ME-LDA is the representative model in this flavor. DF-LDA adds constraints to LDA. We use our seeds to generate constraints for DF-LDA. While ME-LDA cannot consider constraints, DF-LDA does not separate sentiments and aspects. Apart from other modeling differences, our mode</context>
<context position="24376" citStr="Andrzejewski et al., 2009" startWordPosition="4039" endWordPosition="4042"> randomly sampled 1000 terms from our corpus appearing at least 20 times and labeled them as aspect terms or sentiment terms, so this labeled data clearly has less noise than our automatically labeled data. For both ME-SAS and ME-LDA we used the corresponding feature vector of each labeled term (in the context of sentences where it occurs) to train the Max-Ent model. As DF-LDA requires must-link and cannot-link constraints, we used our seed sets to generate intra-seed set mustlink and inter-seed set cannot-link constraints. For its hyper-parameters, we used the default values in the package5 (Andrzejewski et al., 2009). Setting the number of topics/aspects in topic models is often tricky as it is difficult to know the 5 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html exact number of topics that a corpus has. While non-parametric Bayesian approaches (Teh et al., 2006) do exist for estimating the number of topics, T, they strongly depend on the hyper-parameters (Heinrich, 2009). As we use fixed hyperparameters, we do not learn T from Bayesian nonparametrics. We used 9 major aspects (T = 9) based on commonsense knowledge of what people usually talk about hotels and some experiments. These are Dining, S</context>
</contexts>
<marker>Andrzejewski, Zhu, Craven, 2009</marker>
<rawString>Andrzejewski, D., Zhu, X. and Craven, M. 2009. Incorporating domain knowledge into topic modeling via Dirichlet forest priors. Proceedings of International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Andrzejewski</author>
<author>X Zhu</author>
<author>M Craven</author>
<author>B Recht</author>
</authors>
<title>A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic.</title>
<date>2011</date>
<booktitle>Proceedings of the 22nd International Joint Conferences on Artificial Intelligence (IJCAI).</booktitle>
<contexts>
<context position="7900" citStr="Andrzejewski et al. (2011)" startWordPosition="1247" endWordPosition="1250">eled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/aspects. Blei and McAuliffe (2007) and Ramage et al. (2009) used document label information in a supervised setting. Hu et al. (2011) relied on user feedback during Gibbs sampling iterations. Andrzejewski et al. (2011) incorporated first-order logic with Markov Logic Networks. However, it has a practical limitation for reasonably large corpora since the number of non-trivial groundings can grow to O(N2) where N is the number of unique tokens in the corpus. Andrzejewski et al. (2009) used another approach (DF-LDA) by introducing must-link and cannotlink constraints as Dirichlet Forest priors. Zhai et al. (2011) reported that the model does not scale up 340 Figure 1: Prior structure: (a) Standard ASMs, (b) Two-level tree structured distribution. Graphical models in plate notation: (c) SAS and (d) ME-SAS. u a </context>
</contexts>
<marker>Andrzejewski, Zhu, Craven, Recht, 2011</marker>
<rawString>Andrzejewski, D., Zhu, X. and Craven, M. and Recht, B. 2011. A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic. Proceedings of the 22nd International Joint Conferences on Artificial Intelligence (IJCAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Blair-Goldensohn</author>
<author>K Hannan</author>
<author>R McDonald</author>
<author>T Neylon</author>
<author>G A Reis</author>
<author>J Reynar</author>
</authors>
<title>Building a sentiment summarizer for local service reviews.</title>
<date>2008</date>
<booktitle>Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era.</booktitle>
<contexts>
<context position="5347" citStr="Blair-Goldensohn et al., 2008" startWordPosition="837" endWordPosition="840">cing better results. Second, our way of treating seeds is also different from DF-LDA. We discuss these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), th</context>
</contexts>
<marker>Blair-Goldensohn, Hannan, McDonald, Neylon, Reis, Reynar, 2008</marker>
<rawString>Blair-Goldensohn, S., Hannan, K., McDonald, R., Neylon, T., Reis, G. A. and Reynar, J. 2008. Building a sentiment summarizer for local service reviews. Proceedings of WWW-2008 workshop on NLP in the Information Explosion Era.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>A Ng</author>
<author>M Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research</journal>
<volume>3</volume>
<pages>993--1022</pages>
<contexts>
<context position="3866" citStr="Blei et al., 2003" startWordPosition="600" endWordPosition="603">ntropy (or Max-Ent for short) priors to help separate aspects and sentiment terms. However, to train Max-Ent, we do not need manually labeled training data (see Section 4). 339 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 339–348, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics In practical applications, asking users to provide some seeds is easy as they are normally experts in their trades and have a good knowledge what are important in their domains. Our models are related to topic models in general (Blei et al., 2003) and joint models of aspects and sentiments in sentiment analysis in specific (e.g., Zhao et al., 2010). However, these current models are typically unsupervised. None of them can use seeds. With seeds, our models are thus semi-supervised and need a different formulation. Our models are also related to the DFLDA model in (Andrzejewski et al., 2009), which allows the user to set must-link and cannot-link constraints. A must-link means that two terms must be in the same topic (aspect category), and a cannot-link means that two terms cannot be in the same topic. Seeds may be expressed with mustli</context>
<context position="6203" citStr="Blei et al., 2003" startWordPosition="986" endWordPosition="989">rdie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentime</context>
<context position="28491" citStr="Blei et al., 2003" startWordPosition="4713" endWordPosition="4716">y are much lower in the ranked order and hence do not show up in the top 10 words in Table 1. As DF-LDA is not meant to perform extraction and to group both aspect and sentiment terms, we relax the errors of DF-LDA due to correct aspect specific sentiments (e.g., friendly, helpful for Staff are correct aspect specific sentiments, but still regard incorrect sentiments like front, comfortable, large as errors) placed in aspect models. We call this model DF-LDA-Relaxed. 4.2 Quantitative Results Topic models are often evaluated quantitatively using perplexity and likelihood on held-out test data (Blei et al., 2003). However, perplexity does not reflect our purpose since our aim is not to predict whether an unseen document is likely to be a review of some particular aspect. Nor are we trying to evaluate how well the unseen review data fits our seeded models. Instead our focus is to evaluate how well our learned aspects perform in clustering specific terms guided by seeds. So we directly evaluate the discovered aspect terms. Note again we do not evaluate sentiment terms as they are not the focus of this paper 6. Since aspects produced by the models are rankings and we do not know the number of correct asp</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>Blei, D., Ng, A. and Jordan, M. 2003. Latent dirichlet allocation. The Journal of Machine Learning Research 3: 993-1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>J McAuliffe</author>
</authors>
<title>Supervised topic models.</title>
<date>2007</date>
<booktitle>Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="7716" citStr="Blei and McAuliffe (2007)" startWordPosition="1218" endWordPosition="1221"> et al., 2010). Zhao et al. (2010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/aspects. Blei and McAuliffe (2007) and Ramage et al. (2009) used document label information in a supervised setting. Hu et al. (2011) relied on user feedback during Gibbs sampling iterations. Andrzejewski et al. (2011) incorporated first-order logic with Markov Logic Networks. However, it has a practical limitation for reasonably large corpora since the number of non-trivial groundings can grow to O(N2) where N is the number of unique tokens in the corpus. Andrzejewski et al. (2009) used another approach (DF-LDA) by introducing must-link and cannotlink constraints as Dirichlet Forest priors. Zhai et al. (2011) reported that th</context>
</contexts>
<marker>Blei, McAuliffe, 2007</marker>
<rawString>Blei D. and McAuliffe, J. 2007. Supervised topic models. Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Branavan</author>
<author>H Chen</author>
<author>J Eisenstein</author>
<author>R Barzilay</author>
</authors>
<title>Learning document-level semantic properties from free-text annotations.</title>
<date>2008</date>
<booktitle>Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="6344" citStr="Branavan et al., 2008" startWordPosition="1006" endWordPosition="1009">age models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms</context>
</contexts>
<marker>Branavan, Chen, Eisenstein, Barzilay, 2008</marker>
<rawString>Branavan, S., Chen, H., Eisenstein J. and Barzilay, R. 2008. Learning document-level semantic properties from free-text annotations. Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brody</author>
<author>S Elhadad</author>
</authors>
<title>An Unsupervised Aspect-Sentiment Model for Online Reviews.</title>
<date>2010</date>
<booktitle>Proceedings of The 2010 Annual Conference of the North American Chapter of the ACL (NAACL).</booktitle>
<contexts>
<context position="6988" citStr="Brody and Elhadad, 2010" startWordPosition="1103" endWordPosition="1106">s (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao et al. (2010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Brody, S. and Elhadad, S. 2010. An Unsupervised Aspect-Sentiment Model for Online Reviews. Proceedings of The 2010 Annual Conference of the North American Chapter of the ACL (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>R Ng</author>
<author>E Zwart</author>
</authors>
<title>Extracting knowledge from evaluative text.</title>
<date>2005</date>
<booktitle>Proceedings of Third Intl. Conf. on Knowledge Capture (K-CAP05).</booktitle>
<contexts>
<context position="5886" citStr="Carenini et al., 2005" startWordPosition="930" endWordPosition="933">004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling atti</context>
</contexts>
<marker>Carenini, Ng, Zwart, 2005</marker>
<rawString>Carenini, G., Ng, R. and Zwart, E. 2005. Extracting knowledge from evaluative text. Proceedings of Third Intl. Conf. on Knowledge Capture (K-CAP05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chang</author>
<author>J Boyd-Graber</author>
<author>C Gerrish Wang</author>
<author>S</author>
<author>D Blei</author>
</authors>
<title>Reading tea leaves: How humans interpret topic models.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="7431" citStr="Chang et al. (2009)" startWordPosition="1176" endWordPosition="1179">i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao et al. (2010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/aspects. Blei and McAuliffe (2007) and Ramage et al. (2009) used document label information in a supervised setting. Hu et al. (2011) relied on user feedback during Gibbs sampling iterations. Andrzejewski et al. (2011) incorporated first-order logic with Markov Logic Networks. However, it has a practical limitation for reasonably large corpora sin</context>
</contexts>
<marker>Chang, Boyd-Graber, Wang, S, Blei, 2009</marker>
<rawString>Chang, J., Boyd-Graber, J., Wang, C. Gerrish, S. and Blei, D. 2009. Reading tea leaves: How humans interpret topic models. In Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>C Cardie</author>
</authors>
<title>Hierarchical sequential learning for extracting opinions and their attributes.</title>
<date>2010</date>
<booktitle>Proceedings of Annual Meeting of the Association for Computational (ACL).</booktitle>
<contexts>
<context position="5595" citStr="Choi and Cardie, 2010" startWordPosition="882" endWordPosition="885">e-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al</context>
</contexts>
<marker>Choi, Cardie, 2010</marker>
<rawString>Choi, Y. and Cardie, C. 2010. Hierarchical sequential learning for extracting opinions and their attributes. Proceedings of Annual Meeting of the Association for Computational (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Griffiths</author>
<author>M Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of National Academy of Sciences (PNAS).</booktitle>
<contexts>
<context position="13288" citStr="Griffiths and Steyvers, 2004" startWordPosition="2207" endWordPosition="2210">on over seeds ߗ௧, ~ ܦ݅ݎሺߛሻ 2. For each (review) document ݀ א ሼ1, ..., ܦሽ: i. Draw ߠௗ ~ ܦ݅ݎሺߙሻ ii. For each sentence ݏ א ሼ1, ... , ܵௗሽ: a) Draw ݖௗ,௦ ~ ܯݑ݈ݐሺߠௗሻ b) Draw ߰ௗ,௦ ~ ܤ݁ݐܽሺߜሻ c) For each term ݓௗ,௦, where ݆ א ሼ1, ..., ܰௗ,௦ሽ: I. Draw ݎௗ,௦, ~ ܤ݁ݎ݊ݑ݈݈݅൫߰ௗ,௦൯, ݎௗ,௦, א ሼܽො, ොሽ II. if ݎௗ,௦, ൌ ො // ݓௗ,௦, is a sentiment Emit ݓௗ,௦, ~ ܯݑ݈ݐሺ߮௭,ೞ ை ሻ else // ݎௗ,௦, ൌ ܽො , ݓௗ,௦, is an aspect A. Draw ݑௗ,௦, ~ ܯݑ݈ݐሺ߮௭,ೞ  ሻ B. if ݑௗ,௦, א ܸ // non-seed term Emit ݓௗ,௦, ൌ ݑௗ,௦, else // ݑௗ,௦, is some seed set index say ݈ௗ,௦, Emit ݓௗ,௦, ~ ߗ௭,ೞ ,,ೞ,ೕ We employ collapsed Gibbs sampling (Griffiths and Steyvers, 2004) for posterior inference. As ݖ and ݎ are at different hierarchical levels, we derive their samplers separately as follows: ܤ൫݊௧,ሾሿ ை  ߚை൯ ൫ݖௗ,௦ ൌ ݐ หܼௗ,௦, ܴௗ,௦, ܹௗ,௦ , ܷௗ,௦ሻ ן ൈ ை ை ܤ ቀ݊௧,ሾሿௗ,௦  ೄ. ሺ,ሾሿ ೆ,ಲା ఉಲሻ ାఈ  ,ೞ ఉಲሻ ൈ ∏ ሺ,,ሾሿ ೄ,ಲ ା ఊሻ , ൈ ୀଵ ሺ,ሾሿ ೆ,ಲ ,ೞା ሺ,,ሾሿ ೄ,ಲ ା்ఈ (1) ,ೞା ఊሻ ,ሺ·ሻ ೄ. ,ೞ൫ݎௗ,௦, ൌ ොหܼௗ,௦, ܴௗ,௦,, ܹௗ,௦, , ܷௗ,௦,, ݖௗ,௦ ൌ ݐ, ݓௗ,௦, ൌ ݓ൯ ן ,ሺ·ሻ ೀ ,ೞ,ೕ ,ೢೀ,ೞ,ೕାఉೀ ା|ڂ ொ |ఉೀ ൈ ,ೞ ಲ ,ೞ,ೕାఋೌା ,ೞ ,ೞ ೀ,ೞ,ೕାఋ್ ೀ ,ೞ,ೕାఋ್ (2) ൫ݎௗ,௦, ൌ ܽොห ... ൯ ן ,,ሺ·ሻ ೄ,ಲ ,ሺ·ሻ ,,ೢ,ೞ,ೕ ାఊ , ೄ,ಲ ,ೞ,ೕ ା|ொ|ఊ ൈ </context>
<context position="15641" citStr="Griffiths and Steyvers, 2004" startWordPosition="2654" endWordPosition="2657">௦ௗ. ݀, ݏ, ݆ denotes counts excluding ݓௗ,௦,.We perform hierarchical sampling. First, an aspect is sampled for each sentence ݖௗ,௦ using Eq. (1). After sampling the aspect, we sample ݎௗ,௦,. The probability of ݓௗ,௦, being an opinion or sentiment term, ሺݎௗ,௦, ൌ ොሻ is given by Eq. (2). However, for ሺݎௗ,௦, ൌ ܽොሻ we have two cases: (a) the observed term ݓ ൌ ݓௗ,௦, א ܳ or (b) does not belong to any seed set, ݈, ݓ א ܳ, i.e., w is an nonseed term. These cases are dealt in Eq. (3). Asymmetric Beta priors: Hyper-parameters α, βO, βA are not very sensitive and the heuristic values suggested in (Griffiths and Steyvers, 2004) usually hold well in practice (Wallach et al. 2009). However, the smoothing hyper-parameter ߜ (Figure 1(c)) is crucial as it governs the aspect or sentiment switch. Essentially, ߰ௗ,௦~ܤ݁ݐܽሺߜߦሻ is the probability of emitting an aspect term2 in ܵ݁݊ݐ௦ௗ with concentration parameter ߜ and base measure  ߦ ൌ ሾߦ,ߦሿ. Without any prior belief, uniform base measures ߦ ൌ ߦ ൌ 0.5 are used resulting in symmetric Beta priors. However, aspects are often more probable than sentiments in a sentence (e.g., “The beds, sheets, and bedding were dirty.”). Thus, it is more principled to employ asymmetric priors</context>
<context position="19690" citStr="Griffiths and Steyvers, 2004" startWordPosition="3337" endWordPosition="3340">ot consider constraints, DF-LDA does not separate sentiments and aspects. Apart from other modeling differences, our models can do both, which enable them to produce much better results. Dataset and Settings: We used hotel reviews from tripadvisor.com. Our corpus consisted of 101,234 reviews and 692,783 sentences. Punctuations, stop words 3, and words appearing less than 5 times in the corpus were removed. For all models, the posterior inference was drawn after 5000 Gibbs iterations with an initial burn-in of 1000 iterations. For SAS and ME-SAS, we set α = 50/T, βA = βO = 0.1 as suggested in (Griffiths and Steyvers, 2004). To make the seeds more effective, we set the seed set worddistribution hyper-parameter γ to be much larger than βA, the hyper-parameter for the distribution over seed sets and aspect terms. This results in higher weights to seeded words which in turn guide the sampler to cluster relevant terms better. A more theoretical approach would involve performing hyper-parameter estimation (Wallach et al., 2009) which may reveal specific properties of the dataset like the estimate of α (indicating how different documents are in terms of their latent semantics), β (suggesting how large the groups of fr</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Griffiths, T. and Steyvers, M. 2004. Finding scientific topics. Proceedings of National Academy of Sciences (PNAS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Guo</author>
<author>H Zhu</author>
<author>Z Guo</author>
<author>X Zhang</author>
<author>X Su</author>
</authors>
<title>Product feature categorization with multilevel latent semantic association.</title>
<date>2009</date>
<booktitle>Proceedings of ACM International Conference on Information and Knowledge Management (CIKM).</booktitle>
<marker>Guo, Zhu, Guo, Zhang, Su, 2009</marker>
<rawString>Guo, H., Zhu, H., Guo, Z., Zhang, X. and Su, X. 2009. Product feature categorization with multilevel latent semantic association. Proceedings of ACM International Conference on Information and Knowledge Management (CIKM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Heinrich</author>
</authors>
<title>A Generic Approach to Topic Models.</title>
<date>2009</date>
<booktitle>Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD).</booktitle>
<contexts>
<context position="9363" citStr="Heinrich, 2009" startWordPosition="1522" endWordPosition="1523">er Ω friendly room staff service bed linens pillows βO a βAa γ βO βA a a a γa (b) (c) (d) λ a when the number of cannot-links go beyond 1000 because the number of maximal cliques Q(r) in a connected component of size |r |in the cannot-link graph is exponential in r. Note that we could still experiment with DF-LDA as our problem size is not so large. We will show in Section 4 that the proposed models outperform it by a large margin. 3 Proposed Seeded Models The standard LDA and existing aspect and sentiment models (ASMs) are mostly governed by the phenomenon called “higher-order cooccurrence” (Heinrich, 2009), i.e., based on how often terms co-occur in different contexts1. This unfortunately results in many “non-specific” terms being pulled and clustered. We employ seed sets to address this issue by “guiding” the model to group semantically related terms in the same aspect thus making the aspect more specific and related to the seeds (which reflect the user needs). For easy presentation, we will use aspect to mean aspect category from now on. We replace the multinomial distribution over words for each aspect (as in ASMs) with a special two-level tree structured distribution. The generative process</context>
<context position="24748" citStr="Heinrich, 2009" startWordPosition="4094" endWordPosition="4095">uires must-link and cannot-link constraints, we used our seed sets to generate intra-seed set mustlink and inter-seed set cannot-link constraints. For its hyper-parameters, we used the default values in the package5 (Andrzejewski et al., 2009). Setting the number of topics/aspects in topic models is often tricky as it is difficult to know the 5 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html exact number of topics that a corpus has. While non-parametric Bayesian approaches (Teh et al., 2006) do exist for estimating the number of topics, T, they strongly depend on the hyper-parameters (Heinrich, 2009). As we use fixed hyperparameters, we do not learn T from Bayesian nonparametrics. We used 9 major aspects (T = 9) based on commonsense knowledge of what people usually talk about hotels and some experiments. These are Dining, Staff, Maintenance, Check In, Cleanliness, Comfort, Amenities, Location and Value for Money (VFM). However, it is important to note that the proposed models are flexible and do not need to have seeds for every aspect/topic. Our experiments simulate the real-life situation where the user may not know all aspects or have no seeds for some aspects. Thus, we provided seeds o</context>
</contexts>
<marker>Heinrich, 2009</marker>
<rawString>Heinrich, G. 2009. A Generic Approach to Topic Models. Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>Proceedings of Conference on Uncertainty in Artificial Intelligence (UAI).</booktitle>
<contexts>
<context position="6175" citStr="Hofmann, 1999" startWordPosition="982" endWordPosition="983">t al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: disc</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Hofmann, T. 1999. Probabilistic latent semantic indexing. Proceedings of Conference on Uncertainty in Artificial Intelligence (UAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Hu</author>
<author>J Boyd-Graber</author>
<author>B Satinoff</author>
</authors>
<title>Interactive topic modeling.</title>
<date>2011</date>
<booktitle>Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="7815" citStr="Hu et al. (2011)" startWordPosition="1235" endWordPosition="1238">ntiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/aspects. Blei and McAuliffe (2007) and Ramage et al. (2009) used document label information in a supervised setting. Hu et al. (2011) relied on user feedback during Gibbs sampling iterations. Andrzejewski et al. (2011) incorporated first-order logic with Markov Logic Networks. However, it has a practical limitation for reasonably large corpora since the number of non-trivial groundings can grow to O(N2) where N is the number of unique tokens in the corpus. Andrzejewski et al. (2009) used another approach (DF-LDA) by introducing must-link and cannotlink constraints as Dirichlet Forest priors. Zhai et al. (2011) reported that the model does not scale up 340 Figure 1: Prior structure: (a) Standard ASMs, (b) Two-level tree stru</context>
</contexts>
<marker>Hu, Boyd-Graber, Satinoff, 2011</marker>
<rawString>Hu, Y., Boyd-Graber, J. and Satinoff, B. 2011. Interactive topic modeling. Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL), 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>International Conference on Knowledge Discovery and Data Mining (ICDM).</booktitle>
<contexts>
<context position="1339" citStr="Hu and Liu, 2004" startWordPosition="192" endWordPosition="195"> extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1 Introduction Aspect-based sentiment analysis is one of the main frameworks for sentiment analysis (Hu and Liu, 2004; Pang and Lee, 2008; Liu, 2012). A key task of the framework is to extract aspects of entities that have been commented in opinion documents. The task consists of two sub-tasks. The first subtask extracts aspect terms from an opinion corpus. The second sub-task clusters synonymous aspect terms into categories where each category represents a single aspect, which we call an aspect category. Existing research has proposed many methods for aspect extraction. They largely fall into two main types. The first type only extracts aspect terms without grouping them into categories (although a subseque</context>
<context position="5268" citStr="Hu and Liu, 2004" startWordPosition="825" endWordPosition="828">modeling ensures clear separation of aspects from sentiments producing better results. Second, our way of treating seeds is also different from DF-LDA. We discuss these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Car</context>
<context position="21027" citStr="Hu and Liu, 2004" startWordPosition="3562" endWordPosition="3565">ood). These are interesting questions and we defer it to our future work. In this work, we found that the setting γ = 250, a larger value compared to βA, produced good results. For SAS, the asymmetric Beta priors were estimated using the method of moments (Section 3.1). We sampled 500 random sentences from the corpus and for each sentence identified the aspects. We thus computed the per-sentence probability of aspect emission (߰ௗ,௦) and used Eq. (4) to compute the final estimates, which give δd = 2.35, δb = 3.44. To learn the Max-Ent parameters λ of ME-SAS, we used the sentiment lexicon 4 of (Hu and Liu, 2004) to automatically generate training data (no manual labeling). We randomly sampled 1000 terms from the corpus which have appeared at least 3 http://jmlr.csail.mit.edu/papers/volume5/lewis04a/a11-smart-stoplist/english.stop 4 http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar ೀ ఉೀ ,ೢ,ೞ,ೕା ೀ ା|ڂ ொ |ఉೀ ൈ ,ೞ,ೕ (6) ,ೢೆ,ಲା ఉಲ ೆ,ಲାሺାሻ ఉಲ ൈ ,ሺ·ሻ 343 Aspect ME-SAS SAS ME-LDA DF-LDA (seeds) Aspect Sentiment Aspect Sentiment Aspect Sentiment Topic Staff attendant friendly attendant friendly staff friendly staff (staff manager attentive waiter nice maintenance nice friendly servic</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Hu, M. and Liu, B. 2004. Mining and summarizing customer reviews. International Conference on Knowledge Discovery and Data Mining (ICDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Jakob</author>
<author>I Gurevych</author>
</authors>
<title>Extracting Opinion Targets in a Single-and Cross-Domain Setting with Conditional Random Fields.</title>
<date>2010</date>
<booktitle>Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="5555" citStr="Jakob and Gurevych, 2010" startWordPosition="874" endWordPosition="877">They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, </context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Jakob, N. and Gurevych, I. 2010. Extracting Opinion Targets in a Single-and Cross-Domain Setting with Conditional Random Fields. Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Jin</author>
<author>H Ho</author>
</authors>
<title>A novel lexicalized HMMbased learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>Proceedings of International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="5529" citStr="Jin and Ho, 2009" startWordPosition="870" endWordPosition="873">of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are b</context>
</contexts>
<marker>Jin, Ho, 2009</marker>
<rawString>Jin, W. and Ho, H. 2009. A novel lexicalized HMMbased learning framework for web opinion mining. Proceedings of International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Jo</author>
<author>A Oh</author>
</authors>
<title>Aspect and sentiment unification model for online review analysis.</title>
<date>2011</date>
<booktitle>ACM Conference in Web Search and Data Mining (WSDM).</booktitle>
<contexts>
<context position="7006" citStr="Jo and Oh, 2011" startWordPosition="1107" endWordPosition="1110">haddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao et al. (2010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this pro</context>
</contexts>
<marker>Jo, Oh, 2011</marker>
<rawString>Jo, Y. and Oh, A. 2011. Aspect and sentiment unification model for online review analysis. ACM Conference in Web Search and Data Mining (WSDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kobayashi</author>
<author>K Inui</author>
<author>K Matsumoto</author>
</authors>
<title>Extracting aspect-evaluation and aspect-of relations in opinion mining.</title>
<date>2007</date>
<booktitle>Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<contexts>
<context position="5619" citStr="Kobayashi et al., 2007" startWordPosition="886" endWordPosition="889">mental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing </context>
</contexts>
<marker>Kobayashi, Inui, Matsumoto, 2007</marker>
<rawString>Kobayashi, N., Inui, K. and Matsumoto, K. 2007. Extracting aspect-evaluation and aspect-of relations in opinion mining. Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ku</author>
<author>Y Liang</author>
<author>H Chen</author>
</authors>
<title>Opinion extraction, summarization and tracking in news and blog corpora.</title>
<date>2006</date>
<booktitle>Proceedings of AAAI Symposium on Computational Approaches to Analyzing Weblogs (AAAI-CAAW&apos;06).</booktitle>
<contexts>
<context position="5364" citStr="Ku et al., 2006" startWordPosition="841" endWordPosition="844">r way of treating seeds is also different from DF-LDA. We discuss these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume tha</context>
</contexts>
<marker>Ku, Liang, Chen, 2006</marker>
<rawString>Ku, L., Liang, Y. and Chen, H. 2006. Opinion extraction, summarization and tracking in news and blog corpora. Proceedings of AAAI Symposium on Computational Approaches to Analyzing Weblogs (AAAI-CAAW&apos;06).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Li</author>
<author>C Han</author>
<author>M Huang</author>
<author>X Xia Zhu</author>
<author>Y Zhang</author>
<author>S</author>
<author>H Yu</author>
</authors>
<title>Structure-aware review mining and summarization.</title>
<date>2010</date>
<booktitle>International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="5572" citStr="Li et al., 2010" startWordPosition="878" endWordPosition="881">h two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 19</context>
</contexts>
<marker>Li, Han, Huang, Zhu, Zhang, S, Yu, 2010</marker>
<rawString>Li, F., Han, C., Huang, M., Zhu, X. Xia, Y., Zhang, S. and Yu, H. 2010. Structure-aware review mining and summarization. International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lin</author>
<author>Y He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>Proceedings of ACM International Conference on Information and Knowledge Management (CIKM).</booktitle>
<contexts>
<context position="6963" citStr="Lin and He, 2009" startWordPosition="1099" endWordPosition="1102">ating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao et al. (2010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seed</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Lin, C. and He, Y. 2009. Joint sentiment/topic model for sentiment analysis. Proceedings of ACM International Conference on Information and Knowledge Management (CIKM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool</publisher>
<note>publishers (to appear in</note>
<contexts>
<context position="1371" citStr="Liu, 2012" startWordPosition="200" endWordPosition="201">to categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1 Introduction Aspect-based sentiment analysis is one of the main frameworks for sentiment analysis (Hu and Liu, 2004; Pang and Lee, 2008; Liu, 2012). A key task of the framework is to extract aspects of entities that have been commented in opinion documents. The task consists of two sub-tasks. The first subtask extracts aspect terms from an opinion corpus. The second sub-task clusters synonymous aspect terms into categories where each category represents a single aspect, which we call an aspect category. Existing research has proposed many methods for aspect extraction. They largely fall into two main types. The first type only extracts aspect terms without grouping them into categories (although a subsequent step may be used for the grou</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Liu, B. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool publishers (to appear in June 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
<author>M Hu</author>
<author>J Cheng</author>
</authors>
<title>Opinion Observer: Analyzing and comparing opinions on the web.</title>
<date>2005</date>
<booktitle>Proceedings of International Conference on World Wide Web (WWW).</booktitle>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Liu, B, M. Hu, and J. Cheng. 2005. Opinion Observer: Analyzing and comparing opinions on the web. Proceedings of International Conference on World Wide Web (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Lu</author>
<author>C Zhai</author>
<author>N Sundaresan</author>
</authors>
<title>Rated aspect summarization of short comments.</title>
<date>2009</date>
<booktitle>Proceedings of International Conference on World Wide Web (WWW).</booktitle>
<contexts>
<context position="6467" citStr="Lu et al., 2009" startWordPosition="1024" endWordPosition="1027">aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g.</context>
</contexts>
<marker>Lu, Zhai, Sundaresan, 2009</marker>
<rawString>Lu, Y., Zhai, C. and Sundaresan, N. 2009. Rated aspect summarization of short comments. Proceedings of International Conference on World Wide Web (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Lu</author>
<author>C Zhai</author>
</authors>
<title>Opinion Integration Through Semi-supervised Topic Modeling.</title>
<date>2008</date>
<booktitle>Proceedings of the 17th International World Wide Web Conference (WWW).</booktitle>
<contexts>
<context position="6537" citStr="Lu and Zhai, 2008" startWordPosition="1036" endWordPosition="1039"> 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao et al. (2010) used Maximu</context>
</contexts>
<marker>Lu, Zhai, 2008</marker>
<rawString>Lu, Y. and Zhai, C. 2008. Opinion Integration Through Semi-supervised Topic Modeling. Proceedings of the 17th International World Wide Web Conference (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Ma</author>
<author>X Wan</author>
</authors>
<title>Opinion target extraction in Chinese news comments.</title>
<date>2010</date>
<booktitle>Proceedings of Coling 2010 Poster Volume (COLING).</booktitle>
<contexts>
<context position="5656" citStr="Ma and Wan (2010)" startWordPosition="894" endWordPosition="897">ls outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and </context>
</contexts>
<marker>Ma, Wan, 2010</marker>
<rawString>Ma, T. and Wan, X. 2010. Opinion target extraction in Chinese news comments. Proceedings of Coling 2010 Poster Volume (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Mei</author>
<author>X Ling</author>
<author>M Wondra</author>
<author>H Su</author>
<author>C Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>Proceedings of International Conference on World Wide Web (WWW).</booktitle>
<contexts>
<context position="7085" citStr="Mei et al., 2007" startWordPosition="1119" endWordPosition="1122">and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao et al. (2010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/asp</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Mei, Q., Ling, X., Wondra, M., Su, H. and Zhai, C. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. Proceedings of International Conference on World Wide Web (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Moghaddam</author>
<author>M Ester</author>
</authors>
<title>ILDA: interdependent LDA model for learning latent aspects and their ratings from online product reviews.</title>
<date>2011</date>
<booktitle>Proceedings of the Annual ACM SIGIR International conference on Research and Development in Information Retrieval (SIGIR).</booktitle>
<contexts>
<context position="6413" citStr="Moghaddam and Ester, 2011" startWordPosition="1016" endWordPosition="1019">ect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and se</context>
</contexts>
<marker>Moghaddam, Ester, 2011</marker>
<rawString>Moghaddam, S. and Ester, M. 2011. ILDA: interdependent LDA model for learning latent aspects and their ratings from online product reviews. Proceedings of the Annual ACM SIGIR International conference on Research and Development in Information Retrieval (SIGIR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval.</title>
<date>2008</date>
<contexts>
<context position="1359" citStr="Pang and Lee, 2008" startWordPosition="196" endWordPosition="199">ters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1 Introduction Aspect-based sentiment analysis is one of the main frameworks for sentiment analysis (Hu and Liu, 2004; Pang and Lee, 2008; Liu, 2012). A key task of the framework is to extract aspects of entities that have been commented in opinion documents. The task consists of two sub-tasks. The first subtask extracts aspect terms from an opinion corpus. The second sub-task clusters synonymous aspect terms into categories where each category represents a single aspect, which we call an aspect category. Existing research has proposed many methods for aspect extraction. They largely fall into two main types. The first type only extracts aspect terms without grouping them into categories (although a subsequent step may be used </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang, B. and Lee, L. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Popescu</author>
<author>O Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="5295" citStr="Popescu and Etzioni, 2005" startWordPosition="829" endWordPosition="832">lear separation of aspects from sentiments producing better results. Second, our way of treating seeds is also different from DF-LDA. We discuss these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Popescu, A. and Etzioni, O. 2005. Extracting product features and opinions from reviews. Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Qiu</author>
<author>B Liu</author>
<author>J Bu</author>
<author>C Chen</author>
</authors>
<title>Opinion Word Expansion and Target Extraction through Double Propagation. Computational Linguistics.</title>
<date>2011</date>
<contexts>
<context position="5430" citStr="Qiu et al., 2011" startWordPosition="853" endWordPosition="856">s these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, to</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Qiu, G., Liu, B., Bu, J. and Chen, C. 2011. Opinion Word Expansion and Target Extraction through Double Propagation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ramage</author>
<author>D Hall</author>
<author>R Nallapati</author>
<author>C Manning</author>
</authors>
<title>Labeled LDA: a supervised topic model for credit attribution in multi-labeled corpora.</title>
<date>2009</date>
<booktitle>Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7741" citStr="Ramage et al. (2009)" startWordPosition="1223" endWordPosition="1226">010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/aspects. Blei and McAuliffe (2007) and Ramage et al. (2009) used document label information in a supervised setting. Hu et al. (2011) relied on user feedback during Gibbs sampling iterations. Andrzejewski et al. (2011) incorporated first-order logic with Markov Logic Networks. However, it has a practical limitation for reasonably large corpora since the number of non-trivial groundings can grow to O(N2) where N is the number of unique tokens in the corpus. Andrzejewski et al. (2009) used another approach (DF-LDA) by introducing must-link and cannotlink constraints as Dirichlet Forest priors. Zhai et al. (2011) reported that the model does not scale up</context>
</contexts>
<marker>Ramage, Hall, Nallapati, Manning, 2009</marker>
<rawString>Ramage, D., Hall, D., Nallapati, R. and Manning, C. 2009. Labeled LDA: a supervised topic model for credit attribution in multi-labeled corpora. Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sauper</author>
<author>A Haghighi</author>
<author>R Barzilay</author>
</authors>
<title>Content models with attitude.</title>
<date>2011</date>
<booktitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="6513" citStr="Sauper et al., 2011" startWordPosition="1031" endWordPosition="1034">et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao e</context>
</contexts>
<marker>Sauper, Haghighi, Barzilay, 2011</marker>
<rawString>Sauper, C., Haghighi, A. and Barzilay, R. 2011. Content models with attitude. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>J Wiebe</author>
</authors>
<title>Recognizing stances in online debates,</title>
<date>2009</date>
<booktitle>Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.</booktitle>
<contexts>
<context position="5411" citStr="Somasundaran and Wiebe, 2009" startWordPosition="849" endWordPosition="852">fferent from DF-LDA. We discuss these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. </context>
</contexts>
<marker>Somasundaran, Wiebe, 2009</marker>
<rawString>Somasundaran, S. and Wiebe, J. 2009. Recognizing stances in online debates, Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Teh</author>
<author>M Jordan</author>
<author>M Beal</author>
<author>D Blei</author>
</authors>
<title>Hierarchical Dirichlet Processes.</title>
<date>2006</date>
<journal>In Journal of the American Statistical Association (JASA).</journal>
<contexts>
<context position="24637" citStr="Teh et al., 2006" startWordPosition="4075" endWordPosition="4078">ctor of each labeled term (in the context of sentences where it occurs) to train the Max-Ent model. As DF-LDA requires must-link and cannot-link constraints, we used our seed sets to generate intra-seed set mustlink and inter-seed set cannot-link constraints. For its hyper-parameters, we used the default values in the package5 (Andrzejewski et al., 2009). Setting the number of topics/aspects in topic models is often tricky as it is difficult to know the 5 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html exact number of topics that a corpus has. While non-parametric Bayesian approaches (Teh et al., 2006) do exist for estimating the number of topics, T, they strongly depend on the hyper-parameters (Heinrich, 2009). As we use fixed hyperparameters, we do not learn T from Bayesian nonparametrics. We used 9 major aspects (T = 9) based on commonsense knowledge of what people usually talk about hotels and some experiments. These are Dining, Staff, Maintenance, Check In, Cleanliness, Comfort, Amenities, Location and Value for Money (VFM). However, it is important to note that the proposed models are flexible and do not need to have seeds for every aspect/topic. Our experiments simulate the real-life</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Teh, Y., Jordan, M., Beal, M. and Blei, D. 2006. Hierarchical Dirichlet Processes. In Journal of the American Statistical Association (JASA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>R McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>Proceedings of International Conference on World Wide Web (WWW).</booktitle>
<contexts>
<context position="6296" citStr="Titov and McDonald, 2008" startWordPosition="999" endWordPosition="1002"> centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspe</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Titov, I. and McDonald, R. 2008. Modeling online reviews with multi-grain topic models. Proceedings of International Conference on World Wide Web (WWW).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wallach</author>
<author>D Mimno</author>
<author>A McCallum</author>
</authors>
<title>Rethinking LDA: Why priors matter.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="15693" citStr="Wallach et al. 2009" startWordPosition="2663" endWordPosition="2666">rchical sampling. First, an aspect is sampled for each sentence ݖௗ,௦ using Eq. (1). After sampling the aspect, we sample ݎௗ,௦,. The probability of ݓௗ,௦, being an opinion or sentiment term, ሺݎௗ,௦, ൌ ොሻ is given by Eq. (2). However, for ሺݎௗ,௦, ൌ ܽොሻ we have two cases: (a) the observed term ݓ ൌ ݓௗ,௦, א ܳ or (b) does not belong to any seed set, ݈, ݓ א ܳ, i.e., w is an nonseed term. These cases are dealt in Eq. (3). Asymmetric Beta priors: Hyper-parameters α, βO, βA are not very sensitive and the heuristic values suggested in (Griffiths and Steyvers, 2004) usually hold well in practice (Wallach et al. 2009). However, the smoothing hyper-parameter ߜ (Figure 1(c)) is crucial as it governs the aspect or sentiment switch. Essentially, ߰ௗ,௦~ܤ݁ݐܽሺߜߦሻ is the probability of emitting an aspect term2 in ܵ݁݊ݐ௦ௗ with concentration parameter ߜ and base measure  ߦ ൌ ሾߦ,ߦሿ. Without any prior belief, uniform base measures ߦ ൌ ߦ ൌ 0.5 are used resulting in symmetric Beta priors. However, aspects are often more probable than sentiments in a sentence (e.g., “The beds, sheets, and bedding were dirty.”). Thus, it is more principled to employ asymmetric priors. Using a labeled set of sentences, ܵௗ, where </context>
<context position="20097" citStr="Wallach et al., 2009" startWordPosition="3401" endWordPosition="3404">ll models, the posterior inference was drawn after 5000 Gibbs iterations with an initial burn-in of 1000 iterations. For SAS and ME-SAS, we set α = 50/T, βA = βO = 0.1 as suggested in (Griffiths and Steyvers, 2004). To make the seeds more effective, we set the seed set worddistribution hyper-parameter γ to be much larger than βA, the hyper-parameter for the distribution over seed sets and aspect terms. This results in higher weights to seeded words which in turn guide the sampler to cluster relevant terms better. A more theoretical approach would involve performing hyper-parameter estimation (Wallach et al., 2009) which may reveal specific properties of the dataset like the estimate of α (indicating how different documents are in terms of their latent semantics), β (suggesting how large the groups of frequently appearing aspect and sentiment terms are) and γ (giving a sense of which and how large groupings of seeds are good). These are interesting questions and we defer it to our future work. In this work, we found that the setting γ = 250, a larger value compared to βA, produced good results. For SAS, the asymmetric Beta priors were estimated using the method of moments (Section 3.1). We sampled 500 r</context>
</contexts>
<marker>Wallach, Mimno, McCallum, 2009</marker>
<rawString>Wallach, H., Mimno, D. and McCallum, A. 2009. Rethinking LDA: Why priors matter. In Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wang</author>
<author>Y Lu</author>
<author>C Zhai</author>
</authors>
<title>Latent aspect rating analysis on review text data: a rating regression approach.</title>
<date>2010</date>
<booktitle>Proceedings of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD).</booktitle>
<contexts>
<context position="6385" citStr="Wang et al., 2010" startWordPosition="1012" endWordPosition="1015">group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2</context>
</contexts>
<marker>Wang, Lu, Zhai, 2010</marker>
<rawString>Wang, H., Lu, Y. and Zhai, C. 2010. Latent aspect rating analysis on review text data: a rating regression approach. Proceedings of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wu</author>
<author>Q Zhang</author>
<author>X Huang</author>
<author>L Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="5381" citStr="Wu et al., 2009" startWordPosition="845" endWordPosition="848"> seeds is also different from DF-LDA. We discuss these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms ha</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Wu, Y., Zhang, Q., Huang, X. and Wu, L. 2009. Phrase dependency parsing for opinion mining. Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Yi</author>
<author>T Nasukawa</author>
<author>R Bunescu</author>
<author>W Niblack</author>
</authors>
<title>Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques.</title>
<date>2003</date>
<booktitle>Proceedings of IEEE International Conference on Data Mining (ICDM).</booktitle>
<contexts>
<context position="5711" citStr="Yi et al., 2003" startWordPosition="903" endWordPosition="906">ted Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting ke</context>
</contexts>
<marker>Yi, Nasukawa, Bunescu, Niblack, 2003</marker>
<rawString>Yi, J., Nasukawa, T., Bunescu, R. and Niblack, W. 2003. Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques. Proceedings of IEEE International Conference on Data Mining (ICDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Yu</author>
<author>Z J Zha</author>
<author>M Wang</author>
<author>T S Chua</author>
</authors>
<title>Aspect ranking: identifying important product aspects from online consumer reviews.</title>
<date>2011</date>
<booktitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="5637" citStr="Yu et al., 2011" startWordPosition="890" endWordPosition="893"> the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include disc</context>
</contexts>
<marker>Yu, Zha, Wang, Chua, 2011</marker>
<rawString>Yu, J., Zha, Z. J., Wang, M. and Chua, T. S. 2011. Aspect ranking: identifying important product aspects from online consumer reviews. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhai</author>
<author>B Xu Liu</author>
<author>H</author>
<author>P Jia</author>
</authors>
<title>Grouping Product Features Using Semi-Supervised Learning with Soft-Constraints.</title>
<date>2010</date>
<booktitle>Proceedings of International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="2397" citStr="Zhai et al., 2010" startWordPosition="359" endWordPosition="362">r aspect extraction. They largely fall into two main types. The first type only extracts aspect terms without grouping them into categories (although a subsequent step may be used for the grouping, see Section 2). The second type uses statistical topic models to extract aspects and group them at the same time in an unsupervised manner. Both approaches are useful. However, in practice, one also encounters another setting, where grouping is not straightforward because for different applications the user may need different groupings to reflect the application needs. This problem was reported in (Zhai et al., 2010), which gave the following example. In car reviews, internal design and external design can be regarded as two separate aspects, but can also be regarded as one aspect, called “design”, based on the level of details that the user wants to study. It is also possible that the same word may be put in different categories based on different needs. However, (Zhai et al., 2010) did not extract aspect terms. It only categorizes a set of given aspect terms. In this work, we propose two novel statistical models to extract and categorize aspect terms automatically given some seeds in the user interested</context>
<context position="5905" citStr="Zhai et al., 2010" startWordPosition="934" endWordPosition="937">i, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al</context>
</contexts>
<marker>Zhai, Liu, H, Jia, 2010</marker>
<rawString>Zhai, Z., Liu, B. Xu, H. and Jia, P. 2010. Grouping Product Features Using Semi-Supervised Learning with Soft-Constraints. Proceedings of International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhai</author>
<author>B Xu Liu</author>
<author>H</author>
<author>P Jia</author>
</authors>
<title>Constrained LDA for Grouping Product Features in Opinion Mining.</title>
<date>2011</date>
<booktitle>Proceedings of Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD).</booktitle>
<contexts>
<context position="5924" citStr="Zhai et al., 2011" startWordPosition="938" endWordPosition="941">al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et al., 2011; Guo et al., 2010), they all assume that aspect terms have been extracted beforehand. In recent years, topic models have been used to perform extraction and grouping at the same time. Existing works are based on two basic models, pLSA (Hofmann, 1999) and LDA (Blei et al., 2003). Some existing works include discovering global and local aspects (Titov and McDonald, 2008), extracting key phrases (Branavan et al., 2008), rating multi-aspects (Wang et al., 2010; Moghaddam and Ester, 2011), summarizing aspects and sentiments (Lu et al., 2009), and modeling attitudes (Sauper et al., 2011). In (Lu an</context>
<context position="8299" citStr="Zhai et al. (2011)" startWordPosition="1308" endWordPosition="1311">/aspects. Blei and McAuliffe (2007) and Ramage et al. (2009) used document label information in a supervised setting. Hu et al. (2011) relied on user feedback during Gibbs sampling iterations. Andrzejewski et al. (2011) incorporated first-order logic with Markov Logic Networks. However, it has a practical limitation for reasonably large corpora since the number of non-trivial groundings can grow to O(N2) where N is the number of unique tokens in the corpus. Andrzejewski et al. (2009) used another approach (DF-LDA) by introducing must-link and cannotlink constraints as Dirichlet Forest priors. Zhai et al. (2011) reported that the model does not scale up 340 Figure 1: Prior structure: (a) Standard ASMs, (b) Two-level tree structured distribution. Graphical models in plate notation: (c) SAS and (d) ME-SAS. u a xa u a wa wa Nd, s Nd, s Sd Sd D D φO a φA Ω a φA Ω a a φO a C C T T T T φA α a room stain bed staff linens service shower pillows walls friendly θ a z ψa a δa αa θ a za ra r a ψa Seeds: {staff, service} {linens, bed, pillows} φA stain walls Ω shower Ω friendly room staff service bed linens pillows βO a βAa γ βO βA a a a γa (b) (c) (d) λ a when the number of cannot-links go beyond 1000 because th</context>
</contexts>
<marker>Zhai, Liu, H, Jia, 2011</marker>
<rawString>Zhai, Z., Liu, B. Xu, H. and Jia, P. 2011. Constrained LDA for Grouping Product Features in Opinion Mining. Proceedings of Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Zhao</author>
<author>J Jiang</author>
<author>Y Yan</author>
<author>X Li</author>
</authors>
<title>Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid.</title>
<date>2010</date>
<booktitle>Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="3969" citStr="Zhao et al., 2010" startWordPosition="617" endWordPosition="620">x-Ent, we do not need manually labeled training data (see Section 4). 339 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 339–348, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics In practical applications, asking users to provide some seeds is easy as they are normally experts in their trades and have a good knowledge what are important in their domains. Our models are related to topic models in general (Blei et al., 2003) and joint models of aspects and sentiments in sentiment analysis in specific (e.g., Zhao et al., 2010). However, these current models are typically unsupervised. None of them can use seeds. With seeds, our models are thus semi-supervised and need a different formulation. Our models are also related to the DFLDA model in (Andrzejewski et al., 2009), which allows the user to set must-link and cannot-link constraints. A must-link means that two terms must be in the same topic (aspect category), and a cannot-link means that two terms cannot be in the same topic. Seeds may be expressed with mustlinks and cannot-links constraints. However, our models are very different from DF-LDA. First of all, we </context>
<context position="7105" citStr="Zhao et al., 2010" startWordPosition="1123" endWordPosition="1126">udes (Sauper et al., 2011). In (Lu and Zhai, 2008), a semi-supervised model was proposed. However, their method is entirely different from ours as they use expert reviews to guide the analysis of user reviews. Aspect and sentiment extraction using topic modeling come in two flavors: discovering aspect words sentiment wise (i.e., discovering positive and negative aspect words and/or sentiments for each aspect without separating aspect and sentiment terms) (Lin and He, 2009; Brody and Elhadad, 2010, Jo and Oh, 2011) and separately discovering both aspects and sentiments (e.g., Mei et al., 2007; Zhao et al., 2010). Zhao et al. (2010) used Maximum-Entropy to train a switch variable to separate aspect and sentiment words. We adopt this method as well but with no use of manually labeled data in training. One problem with these existing models is that many discovered aspects are not understandable/meaningful to users. Chang et al. (2009) stated that one reason is that the objective function of topic models does not always correlate well with human judgments. Our seeded models are designed to overcome this problem. Researchers have tried to generate “meaningful” and “specific” topics/aspects. Blei and McAul</context>
<context position="11953" citStr="Zhao et al., 2010" startWordPosition="1946" endWordPosition="1949">her order cooccurrences with seeds rather than only with standard one level multinomial distribution over words (or terms) alone. 3.1 SAS Model We now present the proposed Seeded Aspect and Sentiment model (SAS). Let ݒଵ... denote the entries in our vocabulary where ܸ is the number of unique non-seed terms. Let there be ܥ seed sets ܳୀଵ... where each seed set ܳ is a group of semantically related terms. Let ߮௧ୀଵ...்  , ߮௧ୀଵ...் ை denote T aspect and aspect specific sentiment models. Also let ߗ௧, denote the aspect specific distribution of seeds in the seed set ܳ. Following the approach of (Zhao et al., 2010), we too assume that a review sentence usually talks about one 341 ۓ ۖ ۔ ۖ ە aspect. A review document ݀ଵ... comprises of ܵௗ sentences and each sentence ݏ א ܵௗ has ܰௗ,௦words. Also, let ܵ݁݊ݐ௦ௗ denote the sentence ݏ of document ݀. To distinguish between aspect and sentiment terms, we introduce an indicator (switch) variable ݎௗ,௦, א ሼܽො, ොሽ for the ݆௧term of ܵ݁݊ݐ௦ௗ, ݓௗ,௦,. Further, let ߰ௗ,௦ denote the distribution of aspects and sentiments in ܵ݁݊ݐ௦ௗ. The generative process of the SAS model (see Figure 1(c)) is given by: 1. For each aspect ݐ א ሼ1, ..., ܶሽ: i. Draw ߮௧ை ~ ܦ݅ݎሺߚைሻ ii. Draw a dis</context>
<context position="18543" citStr="Zhao et al. 2010" startWordPosition="3149" endWordPosition="3152">௫,ೞ,ೕ,ො൯  ൯ సభ ; ݓ א ܳ ∑אሼೌෝ,ෝሽ ௫൫∑సభ ఒ൫௫,ೞ,ೕ,௬൯൯ ௫൫∑ ఒ൫௫,ೞ,ೕ,ො൯  ൯ సభ ൯; ݈, ݓ א ܳ ∑ ௫൫∑ ఒ൫௫,ೞ,ೕ,௬൯  אሼೌෝ,ෝሽ సభ where ߣଵ... are the parameters of the learned MaxEnt model corresponding to the ݊ binary feature functions ݂ଵ... of Max-Ent. 4 Experiments This section evaluates the proposed models. Since the focus in this paper is to generate high quality aspects using seeds, we will not evaluate sentiments although both SAS and ME-SAS can also discover sentiments. To compare the performance with our models, we use two existing state-of-the-art models, ME-LDA (Zhao et al. 2010) and DF-LDA (Andrzejewski et al., 2009). As discussed in Section 2, there are two main flavors of aspect and sentiment models. The first flavor does not separate aspect and sentiment, and the second flavor uses a switch to perform the separation. Since our models also perform a switch, it is natural to compare with the latter flavor, which is also more advanced. ME-LDA is the representative model in this flavor. DF-LDA adds constraints to LDA. We use our seeds to generate constraints for DF-LDA. While ME-LDA cannot consider constraints, DF-LDA does not separate sentiments and aspects. Apart fr</context>
</contexts>
<marker>Zhao, Jiang, Yan, Li, 2010</marker>
<rawString>Zhao, W., Jiang, J., Yan, Y. and Li, X. 2010. Jointly modeling aspects and opinions with a MaxEnt-LDA hybrid. Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Zhuang</author>
<author>F Jing</author>
<author>X Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>Proceedings of International Conference on Information and Knowledge Management (CIKM).</booktitle>
<contexts>
<context position="5316" citStr="Zhuang et al., 2006" startWordPosition="833" endWordPosition="836">from sentiments producing better results. Second, our way of treating seeds is also different from DF-LDA. We discuss these and other related work in Section 2. The proposed models are evaluated using a large number of hotel reviews. They are also compared with two state-of-the-art baselines. Experimental results show that the proposed models outperform the two baselines by large margins. 2 Related Work There are many existing works on aspect extraction. One approach is to find frequent noun terms and possibly with the help of dependency relations (Hu and Liu, 2004; Popescu and Etzioni, 2005; Zhuang et al., 2006; Blair-Goldensohn et al., 2008; Ku et al., 2006; Wu et al., 2009; Somasundaran and Wiebe, 2009; Qiu et al., 2011). Another approach is to use supervised sequence labeling (Liu, Hu and Cheng 2005; Jin and Ho, 2009; Jakob and Gurevych, 2010; Li et al., 2010; Choi and Cardie, 2010; Kobayashi et al., 2007; Yu et al., 2011). Ma and Wan (2010) also exploited centering theory, and (Yi et al., 2003) used language models. However, all these methods do not group extracted aspect terms into categories. Although there are works on grouping aspect terms (Carenini et al., 2005; Zhai et al., 2010; Zhai et a</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Zhuang, L., Jing, F. and Zhu, X. 2006. Movie review mining and summarization. Proceedings of International Conference on Information and Knowledge Management (CIKM).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>