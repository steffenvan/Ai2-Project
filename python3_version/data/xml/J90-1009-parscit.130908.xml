<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000103">
<note confidence="0.425579">
Book Reviews From Syntax to Semantics: Insights from Machine Translation
</note>
<bodyText confidence="0.999275571428572">
generally very thorough, although the chapter on pitch is
unusually skimpy. For some reason, Waibel chooses to
limit his discussion to two sentence tunes—yes-or-no ques-
tions (with a rising pitch contour) and declarative state-
ments (falling pitch contour)—that he feels are relevant to
connected speech recognition. Waibel does not investigate
this in any depth, however; nor does he consider the possible
contribution of pitch to the recognition of polysyllabic
words, which themselves can make up a single intonation
phrase.
The discussion of other prosodic features is much more
satisfying, and I was especially intrigued by the chapter on
stress. Previous researchers on speech recognition and pros-
ody (e.g. Lea 1980) have held that stressed syllables pro-
vide &amp;quot;islands of phonetic reliability&amp;quot; because stress in itself
makes a speech segment more identifiable to human and
machine listeners. Waibel&apos;s results contradict this claim.
His experiments show no significant effect of stress on
recognition accuracies. What makes stressed syllables spe-
cial is their closeness to lexical representation; stressed
syllables have closer agreement between acoustic reality
and abstract representation than unstressed syllables. A
recognizer will therefore have better success at using stress
to find syllables and words than particular phonetic seg-
ments; in Waibel&apos;s implementation, stress (specifically,
stress probabilities) is used for locating word boundaries
and for distinguishing between function and content words.
Such results have important implications for the psycholog-
ical reality of lexical representations and for the place of
cognitive modeling in speech recognition systems. Unfortu-
nately, the effects of Waibel&apos;s experiments are limited by
his vocabulary sample, which contained a large number of
monosyllabic words. I hope Waibel and others will repli-
cate this study with a different and larger set of materials.
I recommend this book as a text and reference. Readers
will benefit from a knowledge of speech basics, but no
special knowledge of synthesis or recognition technology is
necessary. Finally, I wish to recommend this volume espe-
cially to those who are currently looking at ways of improv-
ing a recognizer&apos;s performance through using better-known
tools of computational linguistics, such as morphological
analysis and parsing.
</bodyText>
<sectionHeader confidence="0.98365" genericHeader="abstract">
REFERENCES
</sectionHeader>
<bodyText confidence="0.734517428571429">
Lea, W. A. 1980 Trends in Speech Recognition. Prentice-Hall, Engle-
wood Cliffs, NJ.
Joan Bachenko holds a Ph.D. in linguistics from New York
University. Her research interests include prosody and speech
synthesis, telegraphic sublanguages, and Deaf English. Bachen-
ko&apos;s address is: AT&amp;T Bell Laboratories, 3D462, Murray Hill,
NJ 07974. E-mail:joan-b@allegra.att.com.
</bodyText>
<note confidence="0.824343">
FROM SYNTAX TO SEMANTICS: INSIGHTS FROM
MACHINE TRANSLATION
Erich Steiner, Paul Schmidt, and Cornelia
Zelinsky-Wibbelt (eds.)
</note>
<bodyText confidence="0.800129714285714">
(Institut ftir Angewandte Informationsforschung,
Saarbriicken)
London, U.K.: Pinter Publishers, 1988, vii + 262 pp.
(Communication in artificial intelligence series)
Hardbound, ISBN 0-86187-960-0, £29.50 and Norwood,
NJ: Ablex Publishing Corp, 1988, vii + 262 pp.
Hardbound, ISBN 0-89391-526-2, $48.50
</bodyText>
<equation confidence="0.3468365">
(institutional), $29.50 (personal)
Reviewed by
Harold Somers
UMIST
</equation>
<bodyText confidence="0.978517173076923">
Keen observers of the world of machine translation have
long awaited the first book-length publication on the Com-
mission of the European Communities&apos; MT project EURO-
TRA from the Saarbriicken-based German group; other
readers may have been attracted by this book&apos;s title. Both,
regrettably, risk disappointment.
The former will find this book nothing like the hoped-for
detailed description of the world&apos;s biggest and best-funded
MT project. Not only is the book explicitly &amp;quot;not some
official report on EUROTRA work&amp;quot; (p. 1), but in several
places it contradicts or argues against EUROTRA doctrine
(&amp;quot;. . the concept of transfer developed in this chapter is
the opinion of the author, not necessarily the view underly-
ing the project as a whole&amp;quot;) (p. 161). However, it assumes
in the readership either some prior knowledge of the fine
details of the project and, especially, its formalisms and
jargon, or else access to numerous Commission documents
to which it makes frequent reference (particularly the
&amp;quot;EUROTRA Reference Manual&amp;quot;), even though they are
not in the public domain. A good (or bad) example of this
occurs when we are asked (p. 13) to consult Arnold et al.
1985 (an internal report) for an explanation of the use in
EUROTRA of the term &amp;quot;unification.&amp;quot; What is the reader
to make of this? All we get is a hint that this term might be
being used in a nonstandard way, with no hint as to what it
might mean here, and no reasonable chance of following up
the reference. Similarly, the dual use of the term
&amp;quot;translation&amp;quot; both in its everyday meaning (i.e. between
natural languages) and to describe a relationship between
representations (e.g. p. 21) is very misleading. Other exam-
ples include &amp;quot;euroversal&amp;quot; (e.g. pp. 5, 187), and reference to
&amp;quot;the corpus&amp;quot; (p. 6), though we are not told which corpus, or
of what it is a corpus.
This brings us to the second set of potentially disap-
pointed readers: those expecting to read about syntax and
semantics in an MT system. The recurring theme, inas-
much as there is one, is that a purely syntactic representa-
tion is not suitable for a 72-language-pair transfer MT
system, and so some sort of &amp;quot;semantics&amp;quot; must be used. This
Computational Linguistics Volume 16, Number 1, March 1990 47
Book Reviews From Syntax to Semantics: Insights from Machine Translation
turns out to be a combination of Case Grammar, a classifi-
cation of verbs borrowed from Systemic Grammar, and the
use of syntactic valency frames plus semantic features for
lexical disambiguation. Nothing especially innovative here
then.
Apart from jargon and unobtainable references, other
problems with the book include some disastrous typesetting;
notably, for example, the use of slash, bold slash, backslash,
and vertical bar in one of the formalisms (pp. 120ff), and
the nonuse of superscripts and subscripts from time to time,
as in this example:
</bodyText>
<equation confidence="0.808439">
Xnbar (Cl ... Cm) Xn \- 1 bar (Cm + 1 Cn)
(where each Ci is a maximal projection or a lexical forma-
tive)
</equation>
<bodyText confidence="0.9997266">
I also found the use of lowercase for acronyms irritating
(e.g. &amp;quot;ult,&amp;quot; &amp;quot;scomp&amp;quot;). All of these are problems a good
copyeditor should have ironed out. The book reads for the
most part like a collection of interim progress reports
written for a local audience, and one of its main failings is
the only partial sense of a developing coherent theme or
thread as the book progresses.
The book is divided into an introductory chapter plus
four parts, each of two or three chapters.
Chapter 1 (Haller, Schmidt, Steiner, Teich, and Zelinsky-
Wibbelt) promises &amp;quot;an outline of the EUROTRA project,&amp;quot;
but in fact not enough detail is given. Distracting use of
EUROTRA jargon and reference to articles not in the
public domain, as mentioned above, add to the alienation of
the reader.
Chapter 2 (Schmidt) is the first chapter proper, and is a
description of the treatment of German syntax within the
EUROTRA framework. Given that we are not granted a
sufficient explanation of the formalism, which is not espe-
cially transparent, it is difficult to make much of the
subsequent discussion of how it needs to be improved. The
chapter is patchy: a reasonable discussion of how to treat
German uniformly as a subject-object-verb language using
movement is followed by an incomplete sentence (p. 20):
&amp;quot;As the EUROTRA framework does not allow for transfor-
mations (and for empty elements on ECS the possible
occurrence of constituents has to be regulated by optional-
ity and a-rules (see (23)).&amp;quot; [sic] and then some more
unexplained formalism. Then there is a long discussion of
valency theory, though how this fits in with everything else
is not clarified; and then there is some more formalism (p.
36), which is comprehensible if you know some Prolog and
you assume that the formalism has the same conventions.
Chapter 3 (Steiner, Eckert, Roth, and Winter-Thielen)
discusses the use of semantic relations (SRs) in EURO-
TRA. The background explanation is too brief and vague to
be helpful. The authors should have started by clarifying
the role of SRs and process types and also clarifying the
difference between analyzing SRs as a part of dictionary
coding (done by humans) and the analysis done by the
system. For example, the use of paraphrase tests (pp. 45,
57) is clearly part of the former task. In fact, nowhere in
this chapter are we told how the system correctly assigns
SRs, nor is there any indication of what they will be used
for (cf p. 41). We are given a few examples of problems, but
we are not told anything about general principles (cf p. 78);
for example, is it bad to introduce a new SR? (p. 57) A long
section on tests for distinguishing between complements
and modifiers (pp. 64-70) seems to cover much the same
ground as a previous section (pp. 27-30). In conclusion, it is
difficult to see what they are talking about in this chapter
unless the reader already knows some of the background.
There is no explanation of the different process types, and a
comparison with other similar models (Chafe, Longacre)
would have been appropriate. Also, there is no discussion of
how easy it is to get consistent coding, especially across
languages, nor about how the MT system uses the classifi-
cation (one can guess that it is like the use of SUBCAT
features in GPSG, but one would like reassurance).
The first part of the book closes with a chapter by
Zelinsky-Wibbelt on semantic feature representations of
lexical units. The reader may be alarmed at the thought
that this will be a thinly disguised rehash of Generative
Semantics, but two pages into the chapter we are reassured
that we are talking about the use of features to distinguish
readings, not define meanings. Apart from that, however,
the rest of the chapter is not very clear at all. We discover
(p. 110) that lexical categories can be described by invento-
ries of semantic features, the definitions (or characteriza-
tions) of which are given in terms of syntactic categories,
despite the claim that &amp;quot;there exists no regular relationship
between the semantic principles and the surface structure
of language (p. 107).&amp;quot; The discussion changes abruptly (p.
113) from general principles to definitions of the feature
system. The only indication of how these features were
arrived at is that they &amp;quot;empirically have proved necessary&amp;quot;
(p. 116) and the subsequent mixture of an appalling choice
of formalism (mentioned above), inconsistent use of terms
(e.g. ENT or ENTITY?), garbled explanations, and often
no explanation at all (e.g. what are ind, coll, part, sort,
num, and priv on p. 118?) make the rest of the chapter
fairly hard going.
Part II of the book contains two chapters discussing
semantic relations. The first is a comparison by Steiner of
SRs in EUROTRA and LFG. It is not very clear what the
aim of this chapter is, in fact, or what motivated its
inclusion. To start with, the choice of comparands is not
very good. In LFG (at least in the reference used; namely,
Bresnan 1982—if we can assume that this is what is meant
by &amp;quot;Bresnan 1982b&amp;quot; referred to in the text but absent from
the bibliography), SRs are not properly worked out; for
example, as the author says &amp;quot;it is not obvious what Bres-
nan&apos;s overall set of SRs is&amp;quot; and there are no criteria for
their definition (p. 135). One wonders why some of the
other theories of SRs (case theories, theta-role theories)
ment ioned on page 133 were not chosen for comparison
instead.
The second chapter on SRs is a report by Heid, Rosner,
and Roth on a joint experiment in collaboration with the
Stuttgart group using their SEMSYN generator to pro-
</bodyText>
<page confidence="0.881202">
48 Computational Linguistics Volume 16, Number 1, March 1990
</page>
<note confidence="0.511725">
Book Reviews From Syntax to Semantics: Insights from Machine Translation
</note>
<bodyText confidence="0.995360482014389">
duce German text from representations as described in the
foregoing chapter. In fact, the chapter amounts to a clear
description of the possible syntactic realizations of the SRs,
but it is not really a description of an experiment in text
generation.
Part III of the book has three chapters on transfer. In the
first, Schmidt discusses transfer strategies in general. The
chapter begins with a discussion of why semantic disambig-
uation is necessary in lexical transfer, and makes the
obvious point that there are typically not one-to-one lexical
correspondences in languages. The example given is
schleifien with eight different readings, corresponding vari-
ously to close, shut, close down, lock, lock in, conclude,
and infer. The author then goes on to discuss where lexical
disambiguation might take place: wholly in analysis, wholly
in generation, or partly in both.
Disambiguation wholly in analysis is swiftly dismissed,
though the argument that it &amp;quot;contradicts any idea of
multilinguality&amp;quot; (p. 163) is quite wrong. In fact the oppo-
site is true, since the ideal truly multilingual system would
presumably be an interlingual system, in which disambigu-
ation wholly in analysis would be unavoidable.
Likewise, the dismissal of lexical disambiguation totally
in generation (p. 164ff) is based on the false assumption
that it would imply generating all possible combinations of
lexical alternatives (illustrated by giving 24 &amp;quot;possible&amp;quot;
translations of the sentence Der Rat fafite den Beschlufi
based on the three-way ambiguity of Rat, four possible
translations of fassen, and two of Beschlufi) and then
reducing the choice by hoping &amp;quot;that twenty-three of [them]
will be killed off by rules holding for English&amp;quot; (p. 165).
That may be the way the EUROTRA formalism would
force one to do lexical disambiguation totally in generation,
but the other obvious way to do it would be to enter
generation with unique quasi-English lexical items for each
of the German source words, and then make sure that the
generation grammars had some means of choosing between
the alternatives. This is the obvious strategy in cases in
which there is a genuine generation ambiguity, as where a
single concept in the source language corresponds to multi-
ple concepts in the target language; the well-known exam-
ples of this are know as savoir or connaitre, wall as Wand
or Mauer and so on. I am not advocating disambiguation
wholly in generation, but trying to suggest that Schmidt&apos;s
refutation of it is flawed. For example, paragraph (ii) on
page 166 (which is in any case extremely difficult to
understand) seems to say first that for the person coding the
grammars (or dictionaries?) it does not make any differ-
ence, and that it is better strategically to deliver the infor-
mation in analysis. So is this now an argument for disambig-
uation in analysis after all?
The only alternative, claims Schmidt, is lexical disambig-
uation partly in analysis and partly in generation. That is a
surprise indeed, because there is at least one more alterna-
tive not even considered, which is that disambiguation
might be the job of transfer! As we read on, we find,
however, that this is what Schmidt has in mind after all,
since he next contrasts two versions of the shared disambig-
uation scenario. In one, called &amp;quot;decorated lexical transfer&amp;quot;
or &amp;quot;dlt,&amp;quot; there is a general sematic typing of lexical units of
the source language, while in &amp;quot;undecorated lexical transfer&amp;quot;
or &amp;quot;ult,&amp;quot; semantic information is only invoked as it is
needed. Schmidt attempts to support dlt by arguing against
ult. Ult works like disambiguation totally in generation by
killing off impossible structures; only the generator has to
know about the conditions for choosing between alterna-
tives, so the source language coder does not have to know or
worry about it. So far it looks like an argument for ult, not
against it. But, says Schmidt, how can the source language
coders know that they do not need to worry? Only by
knowing that generation will take care of the problem,
which, we all agree, is unreasonable (analysis and genera-
tion should be modular and mutually independent). Con-
fused? I still am.
I have always assumed that the logical thing to do would
be to disambiguate sometimes in analysis, sometimes in
transfer, and sometimes in generation, depending on the
type of lexical ambiguity (roughly, homograph, translation
ambiguity, or stylistic choice), but in any case there is a
point, not completely brought out by Schmidt, that, in
general, lexical information does not become available as
the translation proceeds, since neither transfer nor genera-
tion can add to what is presumably available from the
beginning. So it is really a question of organizing where
information gets brought into play.
The remainder of Schmidt&apos;s paper reiterates the old idea
that SRs are better for matching frames in transfer than
arbitrarily numbered arguments, and then there is a presen-
tation of how to write transfer rules for various cases of
&amp;quot;structural transfer,&amp;quot; that is, when there is a basic struc-
tural mismatch between two languages. Again, because of
the opacity of the formalism and lack of explanation, this
section is difficult to judge.
In Chapter 8, Eckert and Heid describe an experiment in
which some German verbs are classified on a monolingual
basis according to the system of semantic predicate types
and associated case frames described in Chapter 3. The
same is done independently for the corresponding verbs in
French, and the experiment is to see to what extent correct
translation pairs can be established automatically by match-
ing up the codings. The conclusion the authors draw is that
it works rather well, though to this reader at least, the ratio
of 70 incorrect matches for every 100 correct seems to
suggest that it is not very reliable.
The last chapter in this section appears to be a fairly solid
discussion by Zelinsky-Wibbelt of the treatment of deter-
miners and quantifiers. The chapter is rather impenetrable,
mainly because of the proliferation of terminology, though
perhaps not to the reader who is more familiar with this
particular field. For once there are ample references to the
literature, though again a barely available local working-
paper seems to be a key reference, variously cited for
explanation, fuller details, or exemplification. Also, the
chapter must have been a typesetter&apos;s nightmare with its
bewildering variety of typefaces.
Computational Linguistics Volume 16, Number 1, March 1990 49
Book Reviews Studies in Computer-Aided Lexicology
The last two chapters of the book form Part IV, subtitled
&amp;quot;Explorations.&amp;quot; The first of these comes as something of an
agreeable surprise, and is certainly the best chapter in the
book. The authors, Hauenschild and Busemann, investi-
gate the possibility of adapting GPSG to MT. In particular,
they address the problem of developing a &amp;quot;constructive&amp;quot; (or
constructional) version of the &amp;quot;purely axiomatic&amp;quot; version
found in Gazdar et al. (1985). Here at last is something of
an answer to the very apposite question posed by Kimmo
Kettunen (1986) in this journal.
The second chapter might have been a similar explora-
tion of LFG by Schmidt. Instead, it &amp;quot;tries to give an idea of
how to overcome some weaknesses of [EUROTRA&apos;s] CAT-
formalism . . . by relating it to LFG&amp;quot; (p. 239). The last two
sentences of the book seem to confirm the impression that
perhaps they might have done better just to start with LFG
in the first place:
This chapter was a glimpse at a theory from which a
great deal has been imported into CAT, namely LFG.
However, some of the virtues of the original have been
ignored, above all the most clever LFG mechanism, the
functional uncertainty device. (p. 250)
</bodyText>
<sectionHeader confidence="0.988919" genericHeader="keywords">
REFERENCES
</sectionHeader>
<reference confidence="0.744471333333333">
Bresnan, J. (ed.) 1982 The Mental Representation of Grammatical
Relations. Cambridge, MIT Press, Cambridge, MA.
Gazdar, G.; Klein, E.; Pullum, G. K.; and Sag, I. 1985 Generalized Phrase
Structure Grammar. Basil Blackwell, Oxford.
Kettunen, K. 1986 &amp;quot;Is MT Linguistics?&amp;quot; Computational Linguistics,
12(1), 37-38.
</reference>
<bodyText confidence="0.983321428571429">
Harold Somers, a lecturer at UMIST, is a member of the
machine translation research group there with a special interest in
the relationship between syntax and semantics. Although for-
merly involved in the EUROTRA project, he has not been
associated with that project for three years. Somers&apos;s address is:
Centre for Computational Linguistics, UMIST, P.O. Box 88,
Manchester M60 1QD, U.K. E-mail: hls@ccl.umist.ac.uk
</bodyText>
<sectionHeader confidence="0.962139" genericHeader="introduction">
STUDIES IN COMPUTER-AIDED LEXICOLOGY
</sectionHeader>
<reference confidence="0.678965">
Martin Gellerstam (ed.)
(University of Goteborg)
Stockholm: Almqvist &amp; Wiksell International, 1988,
375pp.(Data Linguistica 18)
Hardbound, ISSN 0347-948X, ISBN 91-22-01258-3,
SEK287.00
Reviewed by
Martha Evens
</reference>
<affiliation confidence="0.582403">
Illinois Institute of Technology
</affiliation>
<bodyText confidence="0.999458222222222">
This volume is a collection of papers in honor of the sixtieth
birthday of Sture Allen, Chairman of the Department of
Computational Linguistics at the University of Gothen-
burg and Permanent Secretary of the Swedish Academy,
written by his students and colleagues. These papers appear
in excellent English but they describe work on Swedish
(although many of the authors represented here have also
worked on problems in English lexicology). The organiza-
tion of the book, in alphabetical order by last name of
author, has the effect of emphasizing the amazing breadth
of Allen&apos;s work, as we move from a paper on applications of
lexical databases in linguistics to a paper on the creation of
such a database, or from a paper on the structure of the
lexicon to a paper on how a computer program can access a
lexical database.
The problem of creating a lexical database from dictio-
nary data is discussed in three papers. Rudolf Rydstedt
gives a preliminary report on the construction of the lexical
database for the Dictionary of the Swedish Academy, a
project headed by Allen himself (comparable to the con-
struction of the new Oxford English Dictionary by the
University of Waterloo and IBM in cooperation with the
Oxford University Press). The paper includes a description
of the languages used for defining the data, the problems of
structuring fixed- and free-format text, and the question of
creating a database that can be distributed in CD-ROM
form. Sture Berg and Kaisa Samuelson exhibit the cooper-
ation between linguist and computer scientist that is such a
happy feature of this book in a description of the production
of a glossary for use in spelling correction; the major
problems are the generation of all inflected forms and the
analysis of the novel compounds that are a common feature
of modern Swedish. Rolf Gavare talks about the problem of
sorting in alphabetical order any collection of &amp;quot;words&amp;quot;
including uppercase letters, numerals, Greek and other
non-Roman characters, and logograms like percent signs
and ampersands.
A number of the papers discuss the structure of the
lexical database and desirable features of the lexical entry.
Staffan Hellberg proposes a novel classification of adjec-
tives. Martin Gellerstam and Maria Toporowska-Gronostaj
both discuss methods of representing the way verbs and
their arguments combine. Bo Ralph looks at semantic
rather than syntactic structures for verbs, concentrating
mainly on taxonomy.
Some lexical databases are created primarily for use by
other computer software; others are intended to be used by
human beings. Anna Sasvall Hein describes the lexical
database used by her parser for Swedish, a unification-
based chart parser designed for such diverse sublanguages
as news agency telegrams, medical texts, and dictionary
definitions. Christian Sjogreen describes a project, also
designed by Allen, to create a commercial dictionary from
a lexical database, complete to the writing of the printer&apos;s
tape. Gudrun Magralsclottir discusses problems of access-
ing the lexicon in the machine translation process. The
advantages of a lexical database as a source for linguistic
research are illustrated by studies of synaesthesia (Asa
Abelin), semantic change (Birgitta Ernby), and loan words
(Kerstin Noren).
Two papers of extraordinary interest span all these cate-
gories. Jerker Jarborg presents a formal structure for the
description of both syntactic and semantic features. Sven-
</bodyText>
<page confidence="0.856037">
50 Computational Linguistics Volume 16, Number 1, March 1990
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.989839">Reviews From to Semantics: from Machine Translation</title>
<abstract confidence="0.999331880952381">generally very thorough, although the chapter on pitch is unusually skimpy. For some reason, Waibel chooses to limit his discussion to two sentence tunes—yes-or-no questions (with a rising pitch contour) and declarative statements (falling pitch contour)—that he feels are relevant to connected speech recognition. Waibel does not investigate this in any depth, however; nor does he consider the possible contribution of pitch to the recognition of polysyllabic words, which themselves can make up a single intonation phrase. The discussion of other prosodic features is much more satisfying, and I was especially intrigued by the chapter on stress. Previous researchers on speech recognition and prosody (e.g. Lea 1980) have held that stressed syllables provide &amp;quot;islands of phonetic reliability&amp;quot; because stress in itself makes a speech segment more identifiable to human and machine listeners. Waibel&apos;s results contradict this claim. His experiments show no significant effect of stress on recognition accuracies. What makes stressed syllables special is their closeness to lexical representation; stressed syllables have closer agreement between acoustic reality and abstract representation than unstressed syllables. A recognizer will therefore have better success at using stress to find syllables and words than particular phonetic segments; in Waibel&apos;s implementation, stress (specifically, stress probabilities) is used for locating word boundaries and for distinguishing between function and content words. Such results have important implications for the psychological reality of lexical representations and for the place of cognitive modeling in speech recognition systems. Unfortunately, the effects of Waibel&apos;s experiments are limited by his vocabulary sample, which contained a large number of monosyllabic words. I hope Waibel and others will replicate this study with a different and larger set of materials. I recommend this book as a text and reference. Readers will benefit from a knowledge of speech basics, but no special knowledge of synthesis or recognition technology is necessary. Finally, I wish to recommend this volume especially to those who are currently looking at ways of improving a recognizer&apos;s performance through using better-known tools of computational linguistics, such as morphological analysis and parsing.</abstract>
<note confidence="0.751828125">REFERENCES W. 1980 in Speech Recognition. Englewood Cliffs, NJ. Bachenko a Ph.D. in linguistics from New York University. Her research interests include prosody and speech synthesis, telegraphic sublanguages, and Deaf English. Bachenko&apos;s address is: AT&amp;T Bell Laboratories, 3D462, Murray Hill, NJ 07974. E-mail:joan-b@allegra.att.com.</note>
<title confidence="0.751828">FROM SYNTAX TO SEMANTICS: INSIGHTS FROM MACHINE TRANSLATION</title>
<author confidence="0.795154">Erich Steiner</author>
<author confidence="0.795154">Paul Schmidt</author>
<author confidence="0.795154">Cornelia</author>
<note confidence="0.9418325">Zelinsky-Wibbelt (eds.) (Institut ftir Angewandte Informationsforschung, Saarbriicken) London, U.K.: Pinter Publishers, 1988, vii + 262 pp. (Communication in artificial intelligence series) Hardbound, ISBN 0-86187-960-0, £29.50 and Norwood, NJ: Ablex Publishing Corp, 1988, vii + 262 pp. Hardbound, ISBN 0-89391-526-2, $48.50 (institutional), $29.50 (personal) Reviewed by</note>
<author confidence="0.552743">Harold Somers</author>
<affiliation confidence="0.309262">UMIST</affiliation>
<abstract confidence="0.990007222222223">Keen observers of the world of machine translation have long awaited the first book-length publication on the Commission of the European Communities&apos; MT project EURO- TRA from the Saarbriicken-based German group; other readers may have been attracted by this book&apos;s title. Both, regrettably, risk disappointment. The former will find this book nothing like the hoped-for detailed description of the world&apos;s biggest and best-funded MT project. Not only is the book explicitly &amp;quot;not some official report on EUROTRA work&amp;quot; (p. 1), but in several places it contradicts or argues against EUROTRA doctrine (&amp;quot;. . the concept of transfer developed in this chapter is the opinion of the author, not necessarily the view underlying the project as a whole&amp;quot;) (p. 161). However, it assumes in the readership either some prior knowledge of the fine details of the project and, especially, its formalisms and jargon, or else access to numerous Commission documents to which it makes frequent reference (particularly the &amp;quot;EUROTRA Reference Manual&amp;quot;), even though they are not in the public domain. A good (or bad) example of this occurs when we are asked (p. 13) to consult Arnold et al. 1985 (an internal report) for an explanation of the use in EUROTRA of the term &amp;quot;unification.&amp;quot; What is the reader to make of this? All we get is a hint that this term might be being used in a nonstandard way, with no hint as to what it might mean here, and no reasonable chance of following up the reference. Similarly, the dual use of the term &amp;quot;translation&amp;quot; both in its everyday meaning (i.e. between natural languages) and to describe a relationship between representations (e.g. p. 21) is very misleading. Other examples include &amp;quot;euroversal&amp;quot; (e.g. pp. 5, 187), and reference to &amp;quot;the corpus&amp;quot; (p. 6), though we are not told which corpus, or of what it is a corpus. This brings us to the second set of potentially disappointed readers: those expecting to read about syntax and semantics in an MT system. The recurring theme, inasmuch as there is one, is that a purely syntactic representation is not suitable for a 72-language-pair transfer MT system, and so some sort of &amp;quot;semantics&amp;quot; must be used. This Computational Linguistics Volume 16, Number 1, March 1990 47 Book Reviews From Syntax to Semantics: Insights from Machine Translation turns out to be a combination of Case Grammar, a classification of verbs borrowed from Systemic Grammar, and the use of syntactic valency frames plus semantic features for lexical disambiguation. Nothing especially innovative here then. Apart from jargon and unobtainable references, other problems with the book include some disastrous typesetting; notably, for example, the use of slash, bold slash, backslash, and vertical bar in one of the formalisms (pp. 120ff), and the nonuse of superscripts and subscripts from time to time, as in this example: Xnbar (Cl ... Cm) Xn \- 1 bar (Cm + 1 Cn) (where each Ci is a maximal projection or a lexical formative) I also found the use of lowercase for acronyms irritating (e.g. &amp;quot;ult,&amp;quot; &amp;quot;scomp&amp;quot;). All of these are problems a good copyeditor should have ironed out. The book reads for the most part like a collection of interim progress reports written for a local audience, and one of its main failings is the only partial sense of a developing coherent theme or thread as the book progresses. The book is divided into an introductory chapter plus four parts, each of two or three chapters. Chapter 1 (Haller, Schmidt, Steiner, Teich, and Zelinsky- Wibbelt) promises &amp;quot;an outline of the EUROTRA project,&amp;quot; but in fact not enough detail is given. Distracting use of EUROTRA jargon and reference to articles not in the public domain, as mentioned above, add to the alienation of the reader. Chapter 2 (Schmidt) is the first chapter proper, and is a description of the treatment of German syntax within the EUROTRA framework. Given that we are not granted a sufficient explanation of the formalism, which is not especially transparent, it is difficult to make much of the subsequent discussion of how it needs to be improved. The chapter is patchy: a reasonable discussion of how to treat German uniformly as a subject-object-verb language using movement is followed by an incomplete sentence (p. 20): &amp;quot;As the EUROTRA framework does not allow for transformations (and for empty elements on ECS the possible occurrence of constituents has to be regulated by optionality and a-rules (see (23)).&amp;quot; [sic] and then some more unexplained formalism. Then there is a long discussion of valency theory, though how this fits in with everything else is not clarified; and then there is some more formalism (p. which is comprehensible know some Prolog you assume that the formalism has the same conventions. Chapter 3 (Steiner, Eckert, Roth, and Winter-Thielen) discusses the use of semantic relations (SRs) in EURO- TRA. The background explanation is too brief and vague to be helpful. The authors should have started by clarifying the role of SRs and process types and also clarifying the difference between analyzing SRs as a part of dictionary coding (done by humans) and the analysis done by the system. For example, the use of paraphrase tests (pp. 45, 57) is clearly part of the former task. In fact, nowhere in this chapter are we told how the system correctly assigns SRs, nor is there any indication of what they will be used for (cf p. 41). We are given a few examples of problems, but we are not told anything about general principles (cf p. 78); for example, is it bad to introduce a new SR? (p. 57) A long section on tests for distinguishing between complements and modifiers (pp. 64-70) seems to cover much the same ground as a previous section (pp. 27-30). In conclusion, it is difficult to see what they are talking about in this chapter unless the reader already knows some of the background. There is no explanation of the different process types, and a comparison with other similar models (Chafe, Longacre) would have been appropriate. Also, there is no discussion of how easy it is to get consistent coding, especially across languages, nor about how the MT system uses the classification (one can guess that it is like the use of SUBCAT features in GPSG, but one would like reassurance). The first part of the book closes with a chapter by Zelinsky-Wibbelt on semantic feature representations of lexical units. The reader may be alarmed at the thought that this will be a thinly disguised rehash of Generative Semantics, but two pages into the chapter we are reassured that we are talking about the use of features to distinguish readings, not define meanings. Apart from that, however, the rest of the chapter is not very clear at all. We discover (p. 110) that lexical categories can be described by inventories of semantic features, the definitions (or characterizations) of which are given in terms of syntactic categories, despite the claim that &amp;quot;there exists no regular relationship between the semantic principles and the surface structure of language (p. 107).&amp;quot; The discussion changes abruptly (p. 113) from general principles to definitions of the feature system. The only indication of how these features were arrived at is that they &amp;quot;empirically have proved necessary&amp;quot; (p. 116) and the subsequent mixture of an appalling choice of formalism (mentioned above), inconsistent use of terms (e.g. ENT or ENTITY?), garbled explanations, and often no explanation at all (e.g. what are ind, coll, part, sort, num, and priv on p. 118?) make the rest of the chapter fairly hard going. Part II of the book contains two chapters discussing semantic relations. The first is a comparison by Steiner of SRs in EUROTRA and LFG. It is not very clear what the aim of this chapter is, in fact, or what motivated its inclusion. To start with, the choice of comparands is not very good. In LFG (at least in the reference used; namely, Bresnan 1982—if we can assume that this is what is meant by &amp;quot;Bresnan 1982b&amp;quot; referred to in the text but absent from the bibliography), SRs are not properly worked out; for example, as the author says &amp;quot;it is not obvious what Bresnan&apos;s overall set of SRs is&amp;quot; and there are no criteria for their definition (p. 135). One wonders why some of the other theories of SRs (case theories, theta-role theories) ment ioned on page 133 were not chosen for comparison instead. The second chapter on SRs is a report by Heid, Rosner, and Roth on a joint experiment in collaboration with the group using their SEMSYN generator to pro- 48 Computational Linguistics Volume 16, Number 1, March 1990 Book Reviews From Syntax to Semantics: Insights from Machine Translation duce German text from representations as described in the foregoing chapter. In fact, the chapter amounts to a clear description of the possible syntactic realizations of the SRs, but it is not really a description of an experiment in text generation. Part III of the book has three chapters on transfer. In the first, Schmidt discusses transfer strategies in general. The begins with a discussion of why semantic disambiguation is necessary in lexical transfer, and makes the obvious point that there are typically not one-to-one lexical correspondences in languages. The example given is eight different readings, corresponding varito shut, close down, lock, lock in, conclude, author then goes on to discuss where lexical disambiguation might take place: wholly in analysis, wholly in generation, or partly in both. Disambiguation wholly in analysis is swiftly dismissed, though the argument that it &amp;quot;contradicts any idea of multilinguality&amp;quot; (p. 163) is quite wrong. In fact the opposite is true, since the ideal truly multilingual system would presumably be an interlingual system, in which disambiguation wholly in analysis would be unavoidable. Likewise, the dismissal of lexical disambiguation totally in generation (p. 164ff) is based on the false assumption that it would imply generating all possible combinations of lexical alternatives (illustrated by giving 24 &amp;quot;possible&amp;quot; of the sentence Rat fafite den Beschlufi on the three-way ambiguity of possible of two of then reducing the choice by hoping &amp;quot;that twenty-three of [them] will be killed off by rules holding for English&amp;quot; (p. 165). That may be the way the EUROTRA formalism would force one to do lexical disambiguation totally in generation, but the other obvious way to do it would be to enter generation with unique quasi-English lexical items for each of the German source words, and then make sure that the generation grammars had some means of choosing between the alternatives. This is the obvious strategy in cases in which there is a genuine generation ambiguity, as where a concept in the source language corresponds to multiple concepts in the target language; the well-known examof this are wall so on. I am not advocating disambiguation wholly in generation, but trying to suggest that Schmidt&apos;s refutation of it is flawed. For example, paragraph (ii) on page 166 (which is in any case extremely difficult to understand) seems to say first that for the person coding the grammars (or dictionaries?) it does not make any difference, and that it is better strategically to deliver the information in analysis. So is this now an argument for disambiguation in analysis after all? The only alternative, claims Schmidt, is lexical disambiguation partly in analysis and partly in generation. That is a surprise indeed, because there is at least one more alternative not even considered, which is that disambiguation might be the job of transfer! As we read on, we find, however, that this is what Schmidt has in mind after all, since he next contrasts two versions of the shared disambiguation scenario. In one, called &amp;quot;decorated lexical transfer&amp;quot; or &amp;quot;dlt,&amp;quot; there is a general sematic typing of lexical units of the source language, while in &amp;quot;undecorated lexical transfer&amp;quot; or &amp;quot;ult,&amp;quot; semantic information is only invoked as it is needed. Schmidt attempts to support dlt by arguing against ult. Ult works like disambiguation totally in generation by killing off impossible structures; only the generator has to about the conditions for choosing between alternatives, so the source language coder does not have to know or worry about it. So far it looks like an argument for ult, not against it. But, says Schmidt, how can the source language coders know that they do not need to worry? Only by knowing that generation will take care of the problem, which, we all agree, is unreasonable (analysis and generation should be modular and mutually independent). Confused? I still am. I have always assumed that the logical thing to do would be to disambiguate sometimes in analysis, sometimes in transfer, and sometimes in generation, depending on the type of lexical ambiguity (roughly, homograph, translation ambiguity, or stylistic choice), but in any case there is a point, not completely brought out by Schmidt, that, in general, lexical information does not become available as the translation proceeds, since neither transfer nor generation can add to what is presumably available from the beginning. So it is really a question of organizing where information gets brought into play. The remainder of Schmidt&apos;s paper reiterates the old idea that SRs are better for matching frames in transfer than arbitrarily numbered arguments, and then there is a presentation of how to write transfer rules for various cases of &amp;quot;structural transfer,&amp;quot; that is, when there is a basic structural mismatch between two languages. Again, because of the opacity of the formalism and lack of explanation, this section is difficult to judge. In Chapter 8, Eckert and Heid describe an experiment in which some German verbs are classified on a monolingual basis according to the system of semantic predicate types and associated case frames described in Chapter 3. The same is done independently for the corresponding verbs in French, and the experiment is to see to what extent correct translation pairs can be established automatically by matching up the codings. The conclusion the authors draw is that it works rather well, though to this reader at least, the ratio of 70 incorrect matches for every 100 correct seems to suggest that it is not very reliable. The last chapter in this section appears to be a fairly solid discussion by Zelinsky-Wibbelt of the treatment of determiners and quantifiers. The chapter is rather impenetrable, mainly because of the proliferation of terminology, though perhaps not to the reader who is more familiar with this particular field. For once there are ample references to the literature, though again a barely available local workingpaper seems to be a key reference, variously cited for explanation, fuller details, or exemplification. Also, the chapter must have been a typesetter&apos;s nightmare with its bewildering variety of typefaces. Computational Linguistics Volume 16, Number 1, March 1990 49 Book Reviews Studies in Computer-Aided Lexicology The last two chapters of the book form Part IV, subtitled &amp;quot;Explorations.&amp;quot; The first of these comes as something of an agreeable surprise, and is certainly the best chapter in the The authors, Hauenschild and Busemann, investigate the possibility of adapting GPSG to MT. In particular, they address the problem of developing a &amp;quot;constructive&amp;quot; (or constructional) version of the &amp;quot;purely axiomatic&amp;quot; version found in Gazdar et al. (1985). Here at last is something of an answer to the very apposite question posed by Kimmo Kettunen (1986) in this journal. second chapter might have been a similar exploration of LFG by Schmidt. Instead, it &amp;quot;tries to give an idea of to overcome some weaknesses of [EUROTRA&apos;s] CATformalism . . . by relating it to LFG&amp;quot; (p. 239). The last two sentences of the book seem to confirm the impression that perhaps they might have done better just to start with LFG in the first place: This chapter was a glimpse at a theory from which a great deal has been imported into CAT, namely LFG. However, some of the virtues of the original have been ignored, above all the most clever LFG mechanism, the functional uncertainty device. (p. 250) REFERENCES</abstract>
<note confidence="0.704122384615385">J. (ed.) 1982 Mental Representation of Grammatical MIT Press, Cambridge, MA. G.; Klein, E.; Pullum, G. K.; and Sag, I. 1985 Phrase Grammar. Blackwell, Oxford. K. 1986 &amp;quot;Is MT Linguistics?&amp;quot; Linguistics, 12(1), 37-38. Somers, lecturer at UMIST, is a member of the machine translation research group there with a special interest in the relationship between syntax and semantics. Although formerly involved in the EUROTRA project, he has not been associated with that project for three years. Somers&apos;s address is: Centre for Computational Linguistics, UMIST, P.O. Box 88, Manchester M60 1QD, U.K. E-mail: hls@ccl.umist.ac.uk</note>
<title confidence="0.713948">STUDIES IN COMPUTER-AIDED LEXICOLOGY</title>
<author confidence="0.927065">Martin Gellerstam</author>
<affiliation confidence="0.934772">(University of Goteborg)</affiliation>
<address confidence="0.50457075">Stockholm: Almqvist &amp; Wiksell International, 1988, 375pp.(Data Linguistica 18) Hardbound, ISSN 0347-948X, ISBN 91-22-01258-3, SEK287.00</address>
<note confidence="0.977392">Reviewed by</note>
<author confidence="0.997794">Martha Evens</author>
<affiliation confidence="0.996067">Illinois Institute of Technology</affiliation>
<abstract confidence="0.992595777777778">This volume is a collection of papers in honor of the sixtieth birthday of Sture Allen, Chairman of the Department of Computational Linguistics at the University of Gothenburg and Permanent Secretary of the Swedish Academy, written by his students and colleagues. These papers appear in excellent English but they describe work on Swedish (although many of the authors represented here have also worked on problems in English lexicology). The organization of the book, in alphabetical order by last name of author, has the effect of emphasizing the amazing breadth of Allen&apos;s work, as we move from a paper on applications of lexical databases in linguistics to a paper on the creation of such a database, or from a paper on the structure of the lexicon to a paper on how a computer program can access a lexical database. The problem of creating a lexical database from dictionary data is discussed in three papers. Rudolf Rydstedt gives a preliminary report on the construction of the lexical for the of the Swedish Academy, project headed by Allen himself (comparable to the conof the new English Dictionary the University of Waterloo and IBM in cooperation with the Oxford University Press). The paper includes a description of the languages used for defining the data, the problems of structuring fixedand free-format text, and the question of creating a database that can be distributed in CD-ROM form. Sture Berg and Kaisa Samuelson exhibit the cooperation between linguist and computer scientist that is such a happy feature of this book in a description of the production of a glossary for use in spelling correction; the major problems are the generation of all inflected forms and the analysis of the novel compounds that are a common feature of modern Swedish. Rolf Gavare talks about the problem of sorting in alphabetical order any collection of &amp;quot;words&amp;quot; including uppercase letters, numerals, Greek and other non-Roman characters, and logograms like percent signs and ampersands. A number of the papers discuss the structure of the lexical database and desirable features of the lexical entry. Staffan Hellberg proposes a novel classification of adjectives. Martin Gellerstam and Maria Toporowska-Gronostaj both discuss methods of representing the way verbs and their arguments combine. Bo Ralph looks at semantic rather than syntactic structures for verbs, concentrating mainly on taxonomy. Some lexical databases are created primarily for use by other computer software; others are intended to be used by human beings. Anna Sasvall Hein describes the lexical used by her parser for Swedish, a unificationbased chart parser designed for such diverse sublanguages as news agency telegrams, medical texts, and dictionary definitions. Christian Sjogreen describes a project, also designed by Allen, to create a commercial dictionary from a lexical database, complete to the writing of the printer&apos;s Gudrun Magralsclottir discusses problems of accessing the lexicon in the machine translation process. The advantages of a lexical database as a source for linguistic research are illustrated by studies of synaesthesia (Asa Abelin), semantic change (Birgitta Ernby), and loan words (Kerstin Noren). Two papers of extraordinary interest span all these categories. Jerker Jarborg presents a formal structure for the of both syntactic and semantic features. Sven-</abstract>
<date confidence="0.399247">50 Computational Linguistics Volume 16, Number 1, March 1990</date>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>The Mental Representation of Grammatical Relations.</title>
<date>1982</date>
<editor>Bresnan, J. (ed.)</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge,</location>
<marker>1982</marker>
<rawString>Bresnan, J. (ed.) 1982 The Mental Representation of Grammatical Relations. Cambridge, MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G K Pullum</author>
<author>I Sag</author>
</authors>
<title>Generalized Phrase Structure Grammar.</title>
<date>1985</date>
<publisher>Basil Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="18907" citStr="Gazdar et al. (1985)" startWordPosition="3066" endWordPosition="3069">en a typesetter&apos;s nightmare with its bewildering variety of typefaces. Computational Linguistics Volume 16, Number 1, March 1990 49 Book Reviews Studies in Computer-Aided Lexicology The last two chapters of the book form Part IV, subtitled &amp;quot;Explorations.&amp;quot; The first of these comes as something of an agreeable surprise, and is certainly the best chapter in the book. The authors, Hauenschild and Busemann, investigate the possibility of adapting GPSG to MT. In particular, they address the problem of developing a &amp;quot;constructive&amp;quot; (or constructional) version of the &amp;quot;purely axiomatic&amp;quot; version found in Gazdar et al. (1985). Here at last is something of an answer to the very apposite question posed by Kimmo Kettunen (1986) in this journal. The second chapter might have been a similar exploration of LFG by Schmidt. Instead, it &amp;quot;tries to give an idea of how to overcome some weaknesses of [EUROTRA&apos;s] CATformalism . . . by relating it to LFG&amp;quot; (p. 239). The last two sentences of the book seem to confirm the impression that perhaps they might have done better just to start with LFG in the first place: This chapter was a glimpse at a theory from which a great deal has been imported into CAT, namely LFG. However, some o</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, G.; Klein, E.; Pullum, G. K.; and Sag, I. 1985 Generalized Phrase Structure Grammar. Basil Blackwell, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kettunen</author>
</authors>
<title>Is MT Linguistics?&amp;quot;</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>1</issue>
<pages>37--38</pages>
<contexts>
<context position="19008" citStr="Kettunen (1986)" startWordPosition="3086" endWordPosition="3087">, Number 1, March 1990 49 Book Reviews Studies in Computer-Aided Lexicology The last two chapters of the book form Part IV, subtitled &amp;quot;Explorations.&amp;quot; The first of these comes as something of an agreeable surprise, and is certainly the best chapter in the book. The authors, Hauenschild and Busemann, investigate the possibility of adapting GPSG to MT. In particular, they address the problem of developing a &amp;quot;constructive&amp;quot; (or constructional) version of the &amp;quot;purely axiomatic&amp;quot; version found in Gazdar et al. (1985). Here at last is something of an answer to the very apposite question posed by Kimmo Kettunen (1986) in this journal. The second chapter might have been a similar exploration of LFG by Schmidt. Instead, it &amp;quot;tries to give an idea of how to overcome some weaknesses of [EUROTRA&apos;s] CATformalism . . . by relating it to LFG&amp;quot; (p. 239). The last two sentences of the book seem to confirm the impression that perhaps they might have done better just to start with LFG in the first place: This chapter was a glimpse at a theory from which a great deal has been imported into CAT, namely LFG. However, some of the virtues of the original have been ignored, above all the most clever LFG mechanism, the functio</context>
</contexts>
<marker>Kettunen, 1986</marker>
<rawString>Kettunen, K. 1986 &amp;quot;Is MT Linguistics?&amp;quot; Computational Linguistics, 12(1), 37-38.</rawString>
</citation>
<citation valid="false">
<journal>(University of Goteborg)</journal>
<editor>Martin Gellerstam (ed.)</editor>
<marker></marker>
<rawString>Martin Gellerstam (ed.) (University of Goteborg)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stockholm</author>
</authors>
<booktitle>Almqvist &amp; Wiksell International, 1988, 375pp.(Data Linguistica</booktitle>
<volume>18</volume>
<marker>Stockholm, </marker>
<rawString>Stockholm: Almqvist &amp; Wiksell International, 1988, 375pp.(Data Linguistica 18)</rawString>
</citation>
<citation valid="false">
<authors>
<author>ISSN Hardbound</author>
</authors>
<title>0347-948X, ISBN 91-22-01258-3, Reviewed by Martha Evens</title>
<marker>Hardbound, </marker>
<rawString>Hardbound, ISSN 0347-948X, ISBN 91-22-01258-3, Reviewed by Martha Evens</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>