<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.061975">
<title confidence="0.997953">
A Best-First Search Algorithm for Generating Referring Expressions
</title>
<author confidence="0.991424">
Helmut Horacek
</author>
<affiliation confidence="0.951883">
Universitat des Saarlandes, FR 6.2 Informatik
</affiliation>
<address confidence="0.961512">
Postfach 151150, D-66041 Saarbdicken, Germany
</address>
<email confidence="0.999387">
email: horacek@cs.uni—sb.de
</email>
<sectionHeader confidence="0.983211" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922846153846">
Existing algorithms for generating referen-
tial descriptions to sets of objects have
serious deficits: while incremental appro-
aches may produce ambiguous and
redundant expressions, exhaustive searches
are computationally expensive. Mediating
between these extreme control regimes, we
propose a best-first searching algorithm for
uniquely identifying sets of objects. We
incorporate linguistically motivated prefer-
ences and several techniques to cut down
the search space. Preliminary results show
the effectiveness of the new algorithm.
</bodyText>
<sectionHeader confidence="0.996299" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956724137931">
A referential description (Donellan 1966) serves
the purpose of letting the addressee identify an
object or a set of objects out of the context set,
the objects assumed to be in the current focus of
attention. The referring expression to be gener-
ated needs to be a distinguishing description, that
is, a description of the intended referent(s), the
target set. Its elements are to be distinguished
from potential distractors (McDonald 1981), the
contrast set, which entails all elements of the
context set except the intended referent(s).
Several algorithms have been developed for
this purpose, differing in terms of computational
efficiency, quality and coverage. For identifying
sets of objects rather than individuals, they typi-
cally suffer from complementary deficits: while
incremental approaches may produce ambiguous,
redundant expressions, exhaustive searches are
computationally expensive. Mediating between
these extreme control regimes, we propose a
best-first search algorithm for uniquely identi-
fying sets of objects, by incorporating lingui-
stically motivated preferences and techniques to
cut down the search space. Preliminary results
show the effectiveness of the new algorithm.
This paper is organized as follows. We review
relevant work in the field and motivate our goals.
Then we describe the new algorithm Finally, we
illustrate its functionality by some examples.
</bodyText>
<sectionHeader confidence="0.623012" genericHeader="introduction">
2 Motivation and Previous Approaches
</sectionHeader>
<bodyText confidence="0.999931375">
Generating referring expressions has been
pursued since the eigthies (Appelt 1985,
Kronfeld 1986, Appelt and Kronfeld 1987).
Later, Dale and Reiter have put considerably
more emphasis on computational efficiency in
the systems EPICURE (Dale 1988), FN (Reiter
1990), and IDAS (Reiter, Dale 1992). Their
algorithms are sensitive to human preferences
(e.g., preferring basic categories (Rosch 1978)),
and efficient in the sense of minimality of the
elements appearing in the resulting referring
expression. They differ, however, in terms of the
precise interpretation of the minimality criterion.
In the mid-nineties, the associated debate of
computational efficiency versus minimality of
the elements appearing in the resulting referring
</bodyText>
<page confidence="0.998954">
103
</page>
<bodyText confidence="0.99999">
expression seemed to be settled in favor of the
incremental approach (Dale and Reiter, 1995) —
motivated by various results of psychological
experiments (see Levelt 1989), certain non-
minimal expressions are tolerated in favor of
adopting the simple and fast strategy of incre-
mentally selecting ambiguity-reducing attributes
from a domain-dependent preference list.
With the extension of the algorithm&apos;s scope to
the identification of sets of objects rather than
individuals (most recently, van Deemter 2002),
the incremental strategy was in some sense put to
the extreme. Since only few attributes typically
apply to all intended referents, boolean combi-
nations of attributes (including negations) are
composed into a distinguishing description. This
is done by successively collecting single attri-
butes, combinations of two attributes, three attri-
butes, and so on, as long as each of them reduces
the set of potential distractors. The a priori
preference for structurally simpler combinations
constitutes a strong commitment. It may prove
unjustified in view of their actual contribution to
exclude potential distractors, as demonstrated by
Gardent (2002) — see the examples with objects
and descriptors as given in Figures 1 and 2. In
the first example, xi and x2 are the intended
referents. An incremental algorithm would select
first the attribute board-member, excluding x6,
then -&apos;treasurer, further excluding x3, and only
then the disjunction president v secretary. That
description could be realized as &amp;quot;a board
member, which is the president or the secretary,
but not the treasurer&amp;quot;, which is highly redundant
compared to &amp;quot;the president or the secretary&amp;quot;. In
the second example, x5, x6, x9, and xio are the
intended referents. After picking white as a
descriptor, the incremental algorithm can choose
from many alternatives for disjunctions of two
attributes. Gardent gives big v cow, Holstein v
vJersey v -&apos;medium as an intermediate
result, potentially verbalized as &amp;quot;the white things
that are big or a cow, a Holstein or not small, and
a Jersey or not medium&amp;quot;. This is still not a distin-
guishing description, since it entails x3 and xi°,
and this verbalization is much inferior to &amp;quot;the
pitbul, the poodle, the Holstein, and the Jersey.&amp;quot;
The latter is generated by the constraint-based
search developed by Gardent, but it takes 1.4 sec,
which is considerable for the small example. In
the best-first procedure, we reduce this search
space, but we also avoid strong commitments.
</bodyText>
<sectionHeader confidence="0.975241" genericHeader="method">
3 The Algorithm at a Glance
</sectionHeader>
<bodyText confidence="0.985257285714286">
Basically, the best-first search algorithm is a
generalization of the incremental version: instead
of successively adding attributes to the full
expression generated so far, all intermediate
results are accessible for this operation. The
&amp;quot;best&amp;quot; among the potential expansion points is
determined according to some measure incorpor-
ating the complexity of partial descriptions
generated so far, the number of potential
distractors still to be excluded, and the comple-
xity of descriptors still unused at each state. The
expansion process is guided by linguistically
motivated preferences (1 and 2, from (Dale,
Reiter 1995), adapted to boolean combinations):
1. First, a boolean combination of category
descriptors is chosen, other descriptors later.
This excludes &amp;quot;mixed&amp;quot; combinations, such as
big v cow. Moreover, category descriptors are
unconditionally included in the expression, so
that not always a minimal description is
obtained (excluding, e.g., &amp;quot;the white things&amp;quot;).
</bodyText>
<table confidence="0.945260894736842">
descriptorebjects xi x2 x3 x4 x5 x6 x7 x8 x9 xio xi]
white
dog
cow
big
small
medium-sized
pitbul
poodle
holstein
jersey
• • • •
descriptors/objects
Xi Xi X3 X4 X5 X6
president
secretary
treasurer
board-member
member
</table>
<figureCaption confidence="0.999611">
Figure 2. Example 2 taken from (Gardent, 2002)
Figure 1. Example 1 taken from (Gardent, 2002)
</figureCaption>
<page confidence="0.988581">
104
</page>
<listItem confidence="0.98424">
2. Descriptors are organized in a taxonomy, to
capture generalizations; the associated redun-
dancies are exploited in the selection process.
3. Descriptor combinations are limited in size.
4. Negations are penalized (1 point), affecting
the ordering of boolean combinations accord-
</listItem>
<bodyText confidence="0.99066725">
ingly. E.g, av b v c precedes —iclv but a
v b precedes (they are scored as equal).
In addition, efficiency in exploring the search
space is greatly supported by two cut-off
techniques, termed as dominance and value cut-
offs. A dominance cut-off is carried out locally
for sibling nodes, when two partial descriptions
exclude the same set of potential distractors, and
the same set of descriptors is still available. Then
the variant which is evaluated worse (in terms of
number of descriptors) is discarded. This step is
justified by the compositionality in mapping
descriptors onto surface expressions, assuming
conflations are not possible. A value cut-off is
carried out globally after a solution has been
found. This is done for the nodes whose score of
the description generated so far, augmented by
the minimal value of the description required for
excluding the remaining potantial distractors,
surpasses the evaluation of the best solution.
</bodyText>
<sectionHeader confidence="0.962732" genericHeader="method">
4 Formalization of the Algorithm
</sectionHeader>
<bodyText confidence="0.999969">
The algorithm operates on a tree of nodes which
are implemented as structured objects, with the
following properties, accessible as functions:
</bodyText>
<listItem confidence="0.999974875">
• State, which is open, closed, final, or cut-off
• Description, a boolean descriptor combination
• Distractors, remaining objects to be excluded
• Score, the quality evaluation of the description
• Assess, the likely evaluation for completion
• Minassess, the possible minimum for Assess
• Successors, pointers to daugther nodes
• Nextprop, boolean combination for successors
</listItem>
<bodyText confidence="0.99992345">
The tree is initialized by a root node with open
state, empty description, all distractors, no
successors, an empty category as Nextprop, and
scores according to the evaluation function used.
When expanding a node, its successor with a
suitable boolean combination of descriptors is
created by the function Create-Successor, which
updates the property Description by accumul-
ation and computes the Distractors and all evalu-
ation properties accordingly. The property Next-
prop is the first non-category atomic descriptor
for successors of the root node. For successors of
interior nodes, it is the descriptor combination
following the one chosen at the mother node.
The generation of boolean combinations is done
by the function Generate-Next. It successively
builds increasingly complex disjunctions of
descriptors and their negation, starting with the
one following Nextprop, until a combination of
limited complexity is found, where:
</bodyText>
<listItem confidence="0.979588">
1. The combination by itself is not redundant
2. It subsumes the target set
3. It further reduces the distractors of the node
4. The reduced set of distractors is not equal to or
a superset of the Distractor property of a
preceding sibling node (dominance cut-oft)
</listItem>
<bodyText confidence="0.990064">
The best-first search is performed by the proce-
dure Search (Figure 3). It maintains the variables
</bodyText>
<table confidence="0.657716925925926">
Procedure Search
Best &lt;— Root
Bestscore 00; Estimate Assess(Best)
1 if State(Best) = Closed
then return failure endif (1)
if State(Best) = Final
then return Description(Best) endif (2)
Descriptors Generate-Next(Best) (3)
if Descriptors = nil
then State(Best) Closed
else Evaluate(Best) (4)
New Create-Successor(Best,Descriptors)
if Distractors(New) = nil then (5)
State(New) Final (6)
if Bestscore &gt; Score(New) then (7)
Bestscore Score(New)
for every node n do
if (State(n) = Open) and (Bestscore
&lt; (Score(n) + Minassess(n))) (8)
then State(n) Cut-off endif (9)
next endif endif endif
for every node a do
if Assess(n) &lt; Estimate
then Estimate (Score(n) + Assess(n))
Best n endif (10)
next
goto Step I
</table>
<figureCaption confidence="0.996127">
Figure 3. Pseudo-code of the algorithm
</figureCaption>
<page confidence="0.995932">
105
</page>
<listItem confidence="0.99976">
• Best, the current node under consideration
• Bestscore, assessing the best solution found
• Estimate, the likely best score of open nodes
</listItem>
<bodyText confidence="0.997985">
The procedure starts with the root node as Best.
It enters a loop with two termination criteria:
</bodyText>
<listItem confidence="0.9997615">
• No more descriptors are available (1)
• A description found is proved to be best (2)
</listItem>
<bodyText confidence="0.999288454545455">
If neither of these is the case, extending Best is
attempted (3). If unsuccessful, Best is closed.
Otherwise, it is re-evaluated, and a successor is
created (4). If the description associated with this
new node excludes all distractors (5), a solution
is found (6). If it is better than previously found
ones (or the first one) (7), the global score is
updated, and all open nodes are tested whether
their score can get better than this score (8). The
state of such a node is set to cut-off, a value cut-
off (9). Finally, a new Best node is chosen (10).
</bodyText>
<sectionHeader confidence="0.994767" genericHeader="method">
5 Preliminary Results
</sectionHeader>
<bodyText confidence="0.999988592592593">
In the implementation, we have elaborated
knowledge bases for the examples in Section 2.
In example 1, only three nodes are generated as
successors of the root node, representing the
descriptions &amp;quot;board member&amp;quot;, &amp;quot;not treasurer&amp;quot;,
and &amp;quot;president or secretary&amp;quot;, the last one being
the optimal solution. These descriptors are also
generated by the incremental algorithm, but as a
single expression rather than as alternatives. In
example 2, seven nodes are generated, four of
them as successors of the root node. They
represent the descriptions &amp;quot;dog or cow&amp;quot;, &amp;quot;dog,
Jersey or Holstein&amp;quot;, &amp;quot;cow, pitbul or poodle&amp;quot;, and
&amp;quot;pitbul, poodle, Jersey or Holstein&amp;quot;, the last one
being the optimal solution. The others are
extended by &amp;quot;big, medium-sized, or small&amp;quot;,
yielding the remaining three nodes. No nodes are
generated for the descriptions &amp;quot;not cow, Jersey
or Holstein&amp;quot;, and &amp;quot;not dog, pitbul or poodle&amp;quot;,
due to dominance cut-offs. The program is
written in CommonLisp, running on an AMD
Athlon processor with 1200 MHz. Computation
times are 11 and 400 msec for the two examples,
which is 7 resp. 3.5 times faster than the exhaust-
ive search in (Gardent 2002). Hence, using the
search restrictions and the representation depen-
dencies cuts down the search space considerably.
</bodyText>
<sectionHeader confidence="0.999143" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999977555555556">
In this paper, we have presented a best-first
search algorithm for producing referring
expressions that identify sets of objects. The
power of the algorithm comes from linguistically
motivated restrictions and preferences, and from
a variety of cut-off techniques. Preliminary
results show improvements in terms of quality
over the incremental algorithm and in terms of
speed when compared to exhaustive searches.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999964948717949">
Appelt, D. 1985. Planning English Referring Expres-
sions. In Artificial Intelligence 26, pp. 1-33.
Appelt, D., and Kronfeld, A. 1987. A Computational
Model of Referring. In Proc. of IJCAI-87, pp.
640-647.
Dale, R. 1988. Generating Referring Expressions in a
Domain of Objects and Processes. PhD Thesis,
Centre for Cognitive Science, University of
Edinburgh.
Dale, R., and Reiter, E. 1995. Computational Inter-
pretations of the Gricean Maxims in the Gener-
ation of Referring Expressions. Cognitive
Science 18, pp. 233-263.
Donellan, K. 1966. Reference and Definite Descrip-
tion. Philosophical Review 75, pp. 281-304.
Gardent, C. 2002. Generating Minimal Definite
Descriptions. In Proc. of ACL-2002, pp. 96-103.
Kronfeld, A. 1986. Donellan&apos;s Distinction and a
Computational Model of Reference. In Proc. of
ACL-86, pp. 186-191.
Levelt, 1989. Speaking: From Intention to Articu-
lation. MIT Press.
McDonald, D. 1981. Natural Language Generation as
a Process of Decision Making under Constraints.
PhD thesis, MIT.
Reiter, E. 1990. Generating Descriptions that Exploit
a User&apos;s Domain Knowledge. In Current Issues
in Natural Language Generation, R. Dale, C.
Mellish, M. Zock (eds.), pp. 257-285.
Reiter, E., and Dale, R. 1992. Generating Definite NP
Referring Expressions. In Proc. of COLING-92.
Rosch, E. 1978. Principles of Categorization. In
Cognition and Categorization, E. Rosch, B.
Lloyd (eds.), pp. 27-48, L. Earlbaum, Hillsdale,
New Jersey.
van Deemter, K. 2002. Generating Referring
Expressions: Boolean Extensions of the Incre-
mental Algorithm. Computational Linguistics,
28(1), pp. 37-52.
</reference>
<page confidence="0.997323">
106
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.954468">
<title confidence="0.999949">A Best-First Search Algorithm for Generating Referring Expressions</title>
<author confidence="0.990768">Helmut Horacek</author>
<affiliation confidence="0.996796">Universitat des Saarlandes, FR 6.2 Informatik</affiliation>
<address confidence="0.995889">Postfach 151150, D-66041 Saarbdicken, Germany</address>
<email confidence="0.997143">horacek@cs.uni—sb.de</email>
<abstract confidence="0.9977365">Existing algorithms for generating referential descriptions to sets of objects have serious deficits: while incremental approaches may produce ambiguous and redundant expressions, exhaustive searches are computationally expensive. Mediating between these extreme control regimes, we propose a best-first searching algorithm for uniquely identifying sets of objects. We incorporate linguistically motivated preferences and several techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Appelt</author>
</authors>
<title>Planning English Referring Expressions.</title>
<date>1985</date>
<journal>In Artificial Intelligence</journal>
<volume>26</volume>
<pages>1--33</pages>
<contexts>
<context position="2267" citStr="Appelt 1985" startWordPosition="315" endWordPosition="316">sive. Mediating between these extreme control regimes, we propose a best-first search algorithm for uniquely identifying sets of objects, by incorporating linguistically motivated preferences and techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm. This paper is organized as follows. We review relevant work in the field and motivate our goals. Then we describe the new algorithm Finally, we illustrate its functionality by some examples. 2 Motivation and Previous Approaches Generating referring expressions has been pursued since the eigthies (Appelt 1985, Kronfeld 1986, Appelt and Kronfeld 1987). Later, Dale and Reiter have put considerably more emphasis on computational efficiency in the systems EPICURE (Dale 1988), FN (Reiter 1990), and IDAS (Reiter, Dale 1992). Their algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimalit</context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>Appelt, D. 1985. Planning English Referring Expressions. In Artificial Intelligence 26, pp. 1-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Appelt</author>
<author>A Kronfeld</author>
</authors>
<title>A Computational Model of Referring.</title>
<date>1987</date>
<booktitle>In Proc. of IJCAI-87,</booktitle>
<pages>640--647</pages>
<contexts>
<context position="2309" citStr="Appelt and Kronfeld 1987" startWordPosition="319" endWordPosition="322">e extreme control regimes, we propose a best-first search algorithm for uniquely identifying sets of objects, by incorporating linguistically motivated preferences and techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm. This paper is organized as follows. We review relevant work in the field and motivate our goals. Then we describe the new algorithm Finally, we illustrate its functionality by some examples. 2 Motivation and Previous Approaches Generating referring expressions has been pursued since the eigthies (Appelt 1985, Kronfeld 1986, Appelt and Kronfeld 1987). Later, Dale and Reiter have put considerably more emphasis on computational efficiency in the systems EPICURE (Dale 1988), FN (Reiter 1990), and IDAS (Reiter, Dale 1992). Their algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimality of the elements appearing in the resulti</context>
</contexts>
<marker>Appelt, Kronfeld, 1987</marker>
<rawString>Appelt, D., and Kronfeld, A. 1987. A Computational Model of Referring. In Proc. of IJCAI-87, pp. 640-647.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>Generating Referring Expressions in a Domain of Objects and Processes.</title>
<date>1988</date>
<tech>PhD Thesis,</tech>
<institution>Centre for Cognitive Science, University of Edinburgh.</institution>
<contexts>
<context position="2432" citStr="Dale 1988" startWordPosition="339" endWordPosition="340">lly motivated preferences and techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm. This paper is organized as follows. We review relevant work in the field and motivate our goals. Then we describe the new algorithm Finally, we illustrate its functionality by some examples. 2 Motivation and Previous Approaches Generating referring expressions has been pursued since the eigthies (Appelt 1985, Kronfeld 1986, Appelt and Kronfeld 1987). Later, Dale and Reiter have put considerably more emphasis on computational efficiency in the systems EPICURE (Dale 1988), FN (Reiter 1990), and IDAS (Reiter, Dale 1992). Their algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimality of the elements appearing in the resulting referring 103 expression seemed to be settled in favor of the incremental approach (Dale and Reiter, 1995) — motivated b</context>
</contexts>
<marker>Dale, 1988</marker>
<rawString>Dale, R. 1988. Generating Referring Expressions in a Domain of Objects and Processes. PhD Thesis, Centre for Cognitive Science, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
<author>E Reiter</author>
</authors>
<date>1995</date>
<journal>Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions. Cognitive Science</journal>
<volume>18</volume>
<pages>233--263</pages>
<contexts>
<context position="3018" citStr="Dale and Reiter, 1995" startWordPosition="422" endWordPosition="425">y in the systems EPICURE (Dale 1988), FN (Reiter 1990), and IDAS (Reiter, Dale 1992). Their algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimality of the elements appearing in the resulting referring 103 expression seemed to be settled in favor of the incremental approach (Dale and Reiter, 1995) — motivated by various results of psychological experiments (see Levelt 1989), certain nonminimal expressions are tolerated in favor of adopting the simple and fast strategy of incrementally selecting ambiguity-reducing attributes from a domain-dependent preference list. With the extension of the algorithm&apos;s scope to the identification of sets of objects rather than individuals (most recently, van Deemter 2002), the incremental strategy was in some sense put to the extreme. Since only few attributes typically apply to all intended referents, boolean combinations of attributes (including negat</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Dale, R., and Reiter, E. 1995. Computational Interpretations of the Gricean Maxims in the Generation of Referring Expressions. Cognitive Science 18, pp. 233-263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Donellan</author>
</authors>
<title>Reference and Definite Description.</title>
<date>1966</date>
<journal>Philosophical Review</journal>
<volume>75</volume>
<pages>281--304</pages>
<contexts>
<context position="803" citStr="Donellan 1966" startWordPosition="100" endWordPosition="101">cs.uni—sb.de Abstract Existing algorithms for generating referential descriptions to sets of objects have serious deficits: while incremental approaches may produce ambiguous and redundant expressions, exhaustive searches are computationally expensive. Mediating between these extreme control regimes, we propose a best-first searching algorithm for uniquely identifying sets of objects. We incorporate linguistically motivated preferences and several techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm. 1 Introduction A referential description (Donellan 1966) serves the purpose of letting the addressee identify an object or a set of objects out of the context set, the objects assumed to be in the current focus of attention. The referring expression to be generated needs to be a distinguishing description, that is, a description of the intended referent(s), the target set. Its elements are to be distinguished from potential distractors (McDonald 1981), the contrast set, which entails all elements of the context set except the intended referent(s). Several algorithms have been developed for this purpose, differing in terms of computational efficienc</context>
</contexts>
<marker>Donellan, 1966</marker>
<rawString>Donellan, K. 1966. Reference and Definite Description. Philosophical Review 75, pp. 281-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gardent</author>
</authors>
<title>Generating Minimal Definite Descriptions.</title>
<date>2002</date>
<booktitle>In Proc. of ACL-2002,</booktitle>
<pages>96--103</pages>
<contexts>
<context position="4082" citStr="Gardent (2002)" startWordPosition="579" endWordPosition="580">ome sense put to the extreme. Since only few attributes typically apply to all intended referents, boolean combinations of attributes (including negations) are composed into a distinguishing description. This is done by successively collecting single attributes, combinations of two attributes, three attributes, and so on, as long as each of them reduces the set of potential distractors. The a priori preference for structurally simpler combinations constitutes a strong commitment. It may prove unjustified in view of their actual contribution to exclude potential distractors, as demonstrated by Gardent (2002) — see the examples with objects and descriptors as given in Figures 1 and 2. In the first example, xi and x2 are the intended referents. An incremental algorithm would select first the attribute board-member, excluding x6, then -&apos;treasurer, further excluding x3, and only then the disjunction president v secretary. That description could be realized as &amp;quot;a board member, which is the president or the secretary, but not the treasurer&amp;quot;, which is highly redundant compared to &amp;quot;the president or the secretary&amp;quot;. In the second example, x5, x6, x9, and xio are the intended referents. After picking white </context>
<context position="6677" citStr="Gardent, 2002" startWordPosition="989" endWordPosition="990">adapted to boolean combinations): 1. First, a boolean combination of category descriptors is chosen, other descriptors later. This excludes &amp;quot;mixed&amp;quot; combinations, such as big v cow. Moreover, category descriptors are unconditionally included in the expression, so that not always a minimal description is obtained (excluding, e.g., &amp;quot;the white things&amp;quot;). descriptorebjects xi x2 x3 x4 x5 x6 x7 x8 x9 xio xi] white dog cow big small medium-sized pitbul poodle holstein jersey • • • • descriptors/objects Xi Xi X3 X4 X5 X6 president secretary treasurer board-member member Figure 2. Example 2 taken from (Gardent, 2002) Figure 1. Example 1 taken from (Gardent, 2002) 104 2. Descriptors are organized in a taxonomy, to capture generalizations; the associated redundancies are exploited in the selection process. 3. Descriptor combinations are limited in size. 4. Negations are penalized (1 point), affecting the ordering of boolean combinations accordingly. E.g, av b v c precedes —iclv but a v b precedes (they are scored as equal). In addition, efficiency in exploring the search space is greatly supported by two cut-off techniques, termed as dominance and value cutoffs. A dominance cut-off is carried out locally fo</context>
</contexts>
<marker>Gardent, 2002</marker>
<rawString>Gardent, C. 2002. Generating Minimal Definite Descriptions. In Proc. of ACL-2002, pp. 96-103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kronfeld</author>
</authors>
<title>Donellan&apos;s Distinction and a Computational Model of Reference.</title>
<date>1986</date>
<booktitle>In Proc. of ACL-86,</booktitle>
<pages>186--191</pages>
<contexts>
<context position="2282" citStr="Kronfeld 1986" startWordPosition="317" endWordPosition="318">ng between these extreme control regimes, we propose a best-first search algorithm for uniquely identifying sets of objects, by incorporating linguistically motivated preferences and techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm. This paper is organized as follows. We review relevant work in the field and motivate our goals. Then we describe the new algorithm Finally, we illustrate its functionality by some examples. 2 Motivation and Previous Approaches Generating referring expressions has been pursued since the eigthies (Appelt 1985, Kronfeld 1986, Appelt and Kronfeld 1987). Later, Dale and Reiter have put considerably more emphasis on computational efficiency in the systems EPICURE (Dale 1988), FN (Reiter 1990), and IDAS (Reiter, Dale 1992). Their algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimality of the elemen</context>
</contexts>
<marker>Kronfeld, 1986</marker>
<rawString>Kronfeld, A. 1986. Donellan&apos;s Distinction and a Computational Model of Reference. In Proc. of ACL-86, pp. 186-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Levelt</author>
</authors>
<title>Speaking: From Intention to Articulation.</title>
<date>1989</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3096" citStr="Levelt 1989" startWordPosition="435" endWordPosition="436">eir algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimality of the elements appearing in the resulting referring 103 expression seemed to be settled in favor of the incremental approach (Dale and Reiter, 1995) — motivated by various results of psychological experiments (see Levelt 1989), certain nonminimal expressions are tolerated in favor of adopting the simple and fast strategy of incrementally selecting ambiguity-reducing attributes from a domain-dependent preference list. With the extension of the algorithm&apos;s scope to the identification of sets of objects rather than individuals (most recently, van Deemter 2002), the incremental strategy was in some sense put to the extreme. Since only few attributes typically apply to all intended referents, boolean combinations of attributes (including negations) are composed into a distinguishing description. This is done by successi</context>
</contexts>
<marker>Levelt, 1989</marker>
<rawString>Levelt, 1989. Speaking: From Intention to Articulation. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McDonald</author>
</authors>
<title>Natural Language Generation as a Process of Decision Making under Constraints.</title>
<date>1981</date>
<tech>PhD thesis,</tech>
<institution>MIT.</institution>
<contexts>
<context position="1202" citStr="McDonald 1981" startWordPosition="166" endWordPosition="167">ate linguistically motivated preferences and several techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm. 1 Introduction A referential description (Donellan 1966) serves the purpose of letting the addressee identify an object or a set of objects out of the context set, the objects assumed to be in the current focus of attention. The referring expression to be generated needs to be a distinguishing description, that is, a description of the intended referent(s), the target set. Its elements are to be distinguished from potential distractors (McDonald 1981), the contrast set, which entails all elements of the context set except the intended referent(s). Several algorithms have been developed for this purpose, differing in terms of computational efficiency, quality and coverage. For identifying sets of objects rather than individuals, they typically suffer from complementary deficits: while incremental approaches may produce ambiguous, redundant expressions, exhaustive searches are computationally expensive. Mediating between these extreme control regimes, we propose a best-first search algorithm for uniquely identifying sets of objects, by incor</context>
</contexts>
<marker>McDonald, 1981</marker>
<rawString>McDonald, D. 1981. Natural Language Generation as a Process of Decision Making under Constraints. PhD thesis, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
</authors>
<title>Generating Descriptions that Exploit a User&apos;s Domain Knowledge.</title>
<date>1990</date>
<booktitle>In Current Issues in Natural Language Generation,</booktitle>
<pages>257--285</pages>
<editor>R. Dale, C. Mellish, M. Zock (eds.),</editor>
<contexts>
<context position="2450" citStr="Reiter 1990" startWordPosition="342" endWordPosition="343">eferences and techniques to cut down the search space. Preliminary results show the effectiveness of the new algorithm. This paper is organized as follows. We review relevant work in the field and motivate our goals. Then we describe the new algorithm Finally, we illustrate its functionality by some examples. 2 Motivation and Previous Approaches Generating referring expressions has been pursued since the eigthies (Appelt 1985, Kronfeld 1986, Appelt and Kronfeld 1987). Later, Dale and Reiter have put considerably more emphasis on computational efficiency in the systems EPICURE (Dale 1988), FN (Reiter 1990), and IDAS (Reiter, Dale 1992). Their algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimality of the elements appearing in the resulting referring 103 expression seemed to be settled in favor of the incremental approach (Dale and Reiter, 1995) — motivated by various results </context>
</contexts>
<marker>Reiter, 1990</marker>
<rawString>Reiter, E. 1990. Generating Descriptions that Exploit a User&apos;s Domain Knowledge. In Current Issues in Natural Language Generation, R. Dale, C. Mellish, M. Zock (eds.), pp. 257-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
<author>R Dale</author>
</authors>
<title>Generating Definite NP Referring Expressions.</title>
<date>1992</date>
<booktitle>In Proc. of COLING-92.</booktitle>
<marker>Reiter, Dale, 1992</marker>
<rawString>Reiter, E., and Dale, R. 1992. Generating Definite NP Referring Expressions. In Proc. of COLING-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Rosch</author>
</authors>
<title>Principles of Categorization.</title>
<date>1978</date>
<booktitle>In Cognition and Categorization,</booktitle>
<pages>27--48</pages>
<editor>E. Rosch, B. Lloyd (eds.),</editor>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="2581" citStr="Rosch 1978" startWordPosition="360" endWordPosition="361">s organized as follows. We review relevant work in the field and motivate our goals. Then we describe the new algorithm Finally, we illustrate its functionality by some examples. 2 Motivation and Previous Approaches Generating referring expressions has been pursued since the eigthies (Appelt 1985, Kronfeld 1986, Appelt and Kronfeld 1987). Later, Dale and Reiter have put considerably more emphasis on computational efficiency in the systems EPICURE (Dale 1988), FN (Reiter 1990), and IDAS (Reiter, Dale 1992). Their algorithms are sensitive to human preferences (e.g., preferring basic categories (Rosch 1978)), and efficient in the sense of minimality of the elements appearing in the resulting referring expression. They differ, however, in terms of the precise interpretation of the minimality criterion. In the mid-nineties, the associated debate of computational efficiency versus minimality of the elements appearing in the resulting referring 103 expression seemed to be settled in favor of the incremental approach (Dale and Reiter, 1995) — motivated by various results of psychological experiments (see Levelt 1989), certain nonminimal expressions are tolerated in favor of adopting the simple and fa</context>
</contexts>
<marker>Rosch, 1978</marker>
<rawString>Rosch, E. 1978. Principles of Categorization. In Cognition and Categorization, E. Rosch, B. Lloyd (eds.), pp. 27-48, L. Earlbaum, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K van Deemter</author>
</authors>
<title>Generating Referring Expressions: Boolean Extensions of the Incremental Algorithm.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>37--52</pages>
<marker>van Deemter, 2002</marker>
<rawString>van Deemter, K. 2002. Generating Referring Expressions: Boolean Extensions of the Incremental Algorithm. Computational Linguistics, 28(1), pp. 37-52.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>