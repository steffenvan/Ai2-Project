<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000047">
<title confidence="0.933033">
Using Cycles and Quasi-Cycles to Disambiguate Dictionary Glosses
</title>
<author confidence="0.820016">
Roberto Navigli
</author>
<note confidence="0.635020666666667">
Dipartimento di Informatica
Sapienza - Universit`a di Roma
Via Salaria, 113 - 00198 Roma Italy
</note>
<email confidence="0.983752">
navigli@di.uniroma1.it
</email>
<sectionHeader confidence="0.993357" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999863071428571">
We present a novel graph-based algo-
rithm for the automated disambiguation
of glosses in lexical knowledge resources.
A dictionary graph is built starting from
senses (vertices) and explicit or implicit
relations in the dictionary (edges). The
approach is based on the identification of
edge sequences which constitute cycles in
the dictionary graph (possibly with one
edge reversed) and relate a source to a
target word sense. Experiments are per-
formed on the disambiguation of ambigu-
ous words in the glosses of WordNet and
two machine-readable dictionaries.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994328349206349">
In the last two decades, we have witnessed an
increasing availability of wide-coverage lexical
knowledge resources in electronic format, most
notably thesauri (such as Roget’s Thesaurus (Ro-
get, 1911), the Macquarie Thesaurus (Bernard,
1986), etc.), machine-readable dictionaries (e.g.,
the Longman Dictionary of Contemporary En-
glish (Proctor, 1978)), computational lexicons
(e.g. WordNet (Fellbaum, 1998)), etc.
The information contained in such resources
comprises (depending on their kind) sense inven-
tories, paradigmatic relations (e.g. fleshn is a kind
of plant tissuen),1 text definitions (e.g. fleshn is
defined as “a soft moist part of a fruit”), usage ex-
amples, and so on.
Unfortunately, not all the semantics are made
explicit within lexical resources. Even Word-
Net, the most widespread computational lexicon
of English, provides explanatory information in
the form of textual glosses, i.e. strings of text
1We denote as wP the ith sense in a reference dictionary
of a word w with part of speech p.
which explain the meaning of concepts in terms
of possibly ambiguous words.
Moreover, while computational lexicons like
WordNet contain semantically explicit informa-
tion such as, among others, hypernymy and
meronymy relations, most thesauri, glossaries, and
machine-readable dictionaries are often just elec-
tronic transcriptions of their paper counterparts.
As a result, for each entry (e.g. a word sense or
thesaurus entry) they mostly provide implicit in-
formation in the form of free text.
The production of semantically richer lexical
resources can help alleviate the knowledge ac-
quisition bottleneck and potentially enable ad-
vanced Natural Language Processing applications
(Cuadros and Rigau, 2006). However, in order to
reduce the high cost of manual annotation (Ed-
monds, 2000), and to avoid the repetition of this
effort for each knowledge resource, this task must
be supported by wide-coverage automated tech-
niques which do not rely on the specific resource
at hand.
In this paper, we aim to make explicit
large quantities of semantic information implic-
itly contained in the glosses of existing wide-
coverage lexical knowledge resources (specifi-
cally, machine-readable dictionaries and computa-
tional lexicons). To this end, we present a method
for Gloss Word Sense Disambiguation (WSD),
called the Cycles and Quasi-Cycles (CQC) algo-
rithm. The algorithm is based on a novel notion
of cycles in the dictionary graph (possibly with
one edge reversed) which support a disambigua-
tion choice. First, a dictionary graph is built from
the input lexical knowledge resource. Next, the
method explicitly disambiguates the information
associated with sense entries (i.e. gloss words)
by associating senses for which the richest sets of
paths can be found in the dictionary graph.
In Section 2, we provide basic definitions,
present the gloss disambiguation algorithm, and il-
</bodyText>
<note confidence="0.923008">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 594–602,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.997839">
594
</page>
<bodyText confidence="0.999850285714286">
lustrate the approach with an example. In Section
3, we present a set of experiments performed on
a variety of lexical knowledge resources, namely
WordNet and two machine-readable dictionaries.
Results are discussed in Section 4, and related
work is presented in Section 5. We give our con-
clusions in Section 6.
</bodyText>
<sectionHeader confidence="0.994496" genericHeader="introduction">
2 Approach
</sectionHeader>
<subsectionHeader confidence="0.738744">
2.1 Definitions
</subsectionHeader>
<bodyText confidence="0.9998254">
Given a dictionary D, we define a dictionary
graph as a directed graph G = (V, E) whose ver-
tices V are the word senses in the sense inventory
of D and whose set of unlabeled edges E is ob-
tained as follows:
</bodyText>
<listItem confidence="0.655251">
i) Initially, E := ∅;
ii) For each sense s ∈ V , and for each lexico-
semantic relation in D connecting sense s to
s0 ∈ V , we perform: E := E ∪ {(s, s0)};
iii) For each sense s ∈ V , let gloss(s) be the set
of content words in its part-of-speech tagged
gloss. Then for each content word w0 in
gloss(s) and for each sense s0 of w0, we
add the corresponding edge to the dictionary
graph, i.e.: E := E ∪ {(s, s0)}.
</listItem>
<bodyText confidence="0.997727565217391">
For instance, consider WordNet as our input
dictionary D. As a result of step (ii), given the se-
mantic relation “sport1n is a hypernym of racing1n”,
the edge (racing1n, sport1n) is added to E (similarly,
an inverse edge is added due to the hyponymy rela-
tion holding between sport1n and racing1n). During
step (iii), the gloss of racing1n “the sport of engag-
ing in contests of speed” is part-of-speech tagged,
obtaining the following set of content words:
{ sportn, engagev, contestn, speedn }. The fol-
lowing edges are then added to E: { (racing1n,
sport1n), (racing1n, sport2n), ... , (racing1n, sport6n),
. . ., (racing1n, speed1n), ... , (racing1n, speed5n) }.
The above steps are performed for all the senses in
V .
We now recall the definition of graph cycle. A
cycle in a graph G is a sequence of edges of G that
forms a path v1 → v2 → · · · → vn (vi ∈ V ) such
that the first vertex of the path corresponds to the
last, i.e. v1 = vn (Cormen et al., 1990, p. 88).
For example, the cycle in Figure 1(a) is given by
the path racing1n → contest1n → race3n → run3 n →
racing1n in the WordNet dictionary graph. In fact
</bodyText>
<figureCaption confidence="0.952186">
Figure 1: An example of cycle (a) and quasi-cycle
(b) in WordNet.
</figureCaption>
<bodyText confidence="0.996476857142857">
contestn occurs in the gloss of racing1n, race3n is a
hyponym of contest1n, and so on.
We further provide the definition of quasi-cycle
as a sequence of edges in which the reversal of
the orientation of a single edge creates a cycle
(Bohman and Thoma, 2000). For instance, the
quasi-cycle in Figure 1(b) is given by the path rac-
ing1n → contest1n → compete1v → race2v ← rac-
ing1n. In fact, the reversal of the edge (racing1n,
race2v) creates a cycle.
Finally, we call a path a (quasi-)cycle if it is ei-
ther a cycle or a quasi-cycle. Further, we say that
a path is (quasi-)cyclic if it forms a (quasi-)cycle
in the graph.
</bodyText>
<subsectionHeader confidence="0.998423">
2.2 The CQC Algorithm
</subsectionHeader>
<bodyText confidence="0.999543588235294">
Given a dictionary graph G = (V, E) built as de-
scribed in the previous section, our objective is
to disambiguate dictionary glosses with the sup-
port of (quasi-)cycles. (Quasi-)cyclic paths are in-
tuitively better than unconstrained paths as each
sense choice s is reinforced by the very fact of s
being reachable from itself through a sequence of
other senses.
Let a(s) be the set of ambiguous words to be
disambiguated in the part-of-speech tagged gloss
of sense s. Given a word w0 ∈ a(s), our aim is
to disambiguate w0 according to the sense inven-
tory of D, i.e. to assign it the right sense chosen
from its set of senses 5enses(w0). To this end, we
propose the use of a graph-based algorithm which
searches the dictionary graph and collects the fol-
lowing kinds of (quasi-)cyclic paths:
</bodyText>
<listItem confidence="0.848033666666667">
i) s → s0 → s1 → · · · → sn−2 → s (cycle)
ii) s → s0 → s1 → · · · → sn−2 ← s
(quasi-cycle)
</listItem>
<figure confidence="0.994443818181818">
(b)
contest1n
(a)
contest1n
racing1n
race3n
run3
n
racing1n
compete1v
race2v
</figure>
<page confidence="0.734238">
595
</page>
<equation confidence="0.496244928571429">
CQC-Algorithm(s, w&apos;)
1 for each sense s&apos; E Senses(w&apos;)
2 CQC(s&apos;) := DFS(s&apos;, s)
3 All CQC := WESenses(w&apos;) CQC(s&apos;)
4 for each sense s&apos; E Senses(w&apos;)
5 score(s&apos;) := 0
6 for each path c E CQC(s&apos;)
7 l := length(c)
1
8 v := �(l)
NumCQC(All CQC,l)
9 score(s&apos;) := score(s&apos;) + v
10 return argmax score(s&apos;)
s&apos;ESenses(w&apos;)
</equation>
<tableCaption confidence="0.801269">
Table 1: The Cycles and Quasi-Cycles (CQC) al-
gorithm in pseudocode.
</tableCaption>
<bodyText confidence="0.996392387096775">
where s is our source sense, s&apos; is a candidate sense
of w&apos; E gloss(s), si is a sense in V , and n is
the length of the path (given by the number of its
edges). We note that both kinds of paths start and
end with the same vertex s, and that we restrict
quasi-cycles to those whose inverted edge departs
from s. To avoid any redundancy, we require that
no vertex is repeated in the path aside from the
start/end vertex (i.e. s =� s&apos; =� si =� sj for any
i, j E {1, ... , n − 2}).
The Cycles and Quasi-Cycles (CQC) algorithm,
reported in pseudo-code in Table 1, takes as input a
source sense s and a target word w&apos; (in our setting2
w&apos; E a(s)). It consists of two main phases.
During steps 1-3, cycles and quasi-cycles are
sought for each sense of w&apos;. This step is per-
formed with a depth-first search (DFS, cf. (Cor-
men et al., 1990, pp. 477–479)) up to a depth
S. To this end, we first define next(s) = {s&apos;&apos; :
(s, s&apos;&apos;) E E}, that is the set of senses which can
be directly reached from sense s. The DFS starts
from a sense s&apos; E Senses(w&apos;), and recursively ex-
plores the senses in next(s&apos;) until sense s or a
sense in next(s) is encountered, obtaining a cy-
cle or a quasi-cycle, respectively. For each sense
s&apos; of w&apos; the DFS returns the full set CQC(s&apos;)
of (quasi-)cyclic paths collected. Note that the
DFS recursively keeps track of previously visited
senses, so as to discard (quasi-)cycles including
the same sense twice. Finally, in step 3, All CQC
is set to store the cycles and quasi-cycles for all
the senses of w&apos;.
2Note that potentially w&apos; can be any word of interest. The
very same algorithm can be applied to determine semantic
similarity or to disambiguate collocations.
The second phase (steps 4-10) computes a score
for each sense s&apos; of w&apos; based on the paths col-
lected for s&apos; during the first phase. Let c be such
a path, and let l be its length, i.e. the number of
edges in the path. Then the contribution of c to the
score of s&apos; is given by a function of its length w(l),
which associates with l a number between 0 and 1.
This contribution is normalized by a factor given
by NumCQC(All CQC, l), which calculates the
overall number of paths of length l. In this work,
we will employ the function w(l) = 1/el, which
weighs a path with the inverse of the exponential
of its length (so as to exponentially decrease the
contribution of longer paths)3. Steps 4-9 are re-
peated for each candidate sense of w&apos;. Finally, step
10 returns the highest-scoring sense of w&apos;.
As a result of the systematic application of
the CQC algorithm to the dictionary graph G =
(V, E) associated with a dictionary D, a graph
G = (V, E) is output, where V is again the sense
inventory of D, and E� C_ E, such that each edge
(s, s&apos;) E E� either represents an unambiguous re-
lation in E (i.e. it was either a lexico-semantic re-
lation in D or a relation between s and a monose-
mous word occurring in its gloss) or is the result
of an execution of the CQC algorithm with input s
and w&apos; E a(s).
</bodyText>
<subsectionHeader confidence="0.999723">
2.3 An Example
</subsectionHeader>
<bodyText confidence="0.9998935">
Consider the following example: WordNet defines
the third sense of fleshn as “a soft moist part of a
fruit”. As a result of part-of-speech tagging, we
obtain:
</bodyText>
<equation confidence="0.947597">
gloss(flesh3n) = {soft,,, moister, part„, fruit,,}
</equation>
<bodyText confidence="0.994571928571429">
Let us assume we aim to disambiguate the noun
fruit. Our call to the CQC algorithm in Table 1 is
then CQC-Algorithm(flesh3n, fruitn).
As a result of the first two steps of the algorithm,
a set of cycles and quasi-cycles for each sense of
fruitn is collected, based on a DFS starting from
the respective senses of our target word (we as-
sume 6 = 5). In Figure 2, we show some of the
(quasi-)cycles collected for senses #1 and #3 of
fruitn, respectively defined as “the ripened repro-
ductive body of a seed plant” and “an amount of
a product” (we neglect sense #2 as the length and
number of its paths is not dissimilar from that of
sense #3).
</bodyText>
<footnote confidence="0.8326555">
3Other weight functions, such as cw(l) = 1 (which weighs
each path independent of its length) proved to perform worse.
</footnote>
<page confidence="0.995821">
596
</page>
<figureCaption confidence="0.924552">
Figure 2: Some cycles and quasi-cycles connect-
ing flesh3n to fruit1n (a), and fruit3n (b).
</figureCaption>
<bodyText confidence="0.999963428571429">
During the second phase of the algorithm, and
for each sense of fruitn, the contribution of each
(quasi-)cycle is calculated (steps 6-9 of the algo-
rithm). For example, for sense fruit1n in Figure
2(a), 5 (quasi-)cycles of length 4 and 2 of length 5
were returned by DFS(fruit1n, flesh3n). Asa result,
the following score is calculated:4
</bodyText>
<equation confidence="0.921629333333333">
score(fruit1n) = 5 1
e4 · NumCQC(all chains,4)
1
= e47+e52
5 2
NumCQC(all chains,5)
= 0.013 + 0.006 = 0.019
whereas for fruit3 n (see Figure 2(b)) we get:
score(fruit3 n) = 2 1
e4 ·NumCQC(all chains,4)
= 2
e4�7 = 0.005
</equation>
<bodyText confidence="0.999326166666667">
where NumCQC�All CQC, l) is the total num-
ber of cycles and quasi-cycles of length l over all
the senses of fruitn (according to Figure 2, this
amounts to 7 paths for l = 4 and 2 paths for l = 5).
Finally, the sense with the highest score (i.e.
fruit1n) is returned.
</bodyText>
<sectionHeader confidence="0.999498" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.8421083">
To test and compare the performance of our al-
gorithm, we performed a set of experiments on a
4Note that, for the sake of simplicity, we are calculating
our scores based on the paths shown in Figure 2. However,
we tried to respect the proportion of paths collected by the
algorithm for the two senses.
variety of resources. First, we summarize the re-
sources (Section 3.1) and algorithms (Section 3.2)
that we adopted. In Section 3.3 we report our ex-
perimental results.
</bodyText>
<subsectionHeader confidence="0.991206">
3.1 Resources
</subsectionHeader>
<bodyText confidence="0.995792">
The following resources were used in our experi-
ments:
</bodyText>
<listItem confidence="0.931914631578947">
• WordNet (Fellbaum, 1998), the most
widespread computational lexicon of En-
glish. It encodes concepts as synsets, and
provides textual glosses and lexico-semantic
relations between synsets. Its latest version
(3.0) contains around 155,000 lemmas, and
over 200,000 word senses;
• Macquarie Concise Dictionary (Yallop,
2006), a machine-readable dictionary of
(Australian) English, which includes around
50,000 lemmas and almost 120,000 word
senses, for which it provides textual glosses
and examples;
• Ragazzini/Biagi Concise (Ragazzini and Bi-
agi, 2006), a bilingual English-Italian dic-
tionary, containing over 90,000 lemmas and
150,000 word senses. The dictionary pro-
vides Italian translations for each English
word sense, and vice versa.
</listItem>
<bodyText confidence="0.9950025">
We used TreeTagger (Schmid, 1997) to part-of-
speech tag the glosses in the three resources.
</bodyText>
<subsectionHeader confidence="0.99421">
3.2 Algorithms
</subsectionHeader>
<bodyText confidence="0.999775">
Hereafter we briefly summarize the algorithms
that we applied in our experiments:
</bodyText>
<listItem confidence="0.980068909090909">
• CQC: we applied the CQC algorithm as de-
scribed in Section 2.2;
• Cycles, which applies the CQC algorithm but
searches for cycles only (i.e. quasi-cycles are
not collected);
• An adaptation of the Lesk algorithm (Lesk,
1986), which, given a source sense s of word
w and a word w&apos; occurring in the gloss of s,
determines the right sense of w&apos; as that which
maximizes the (normalized) overlap between
each sense s&apos; of w&apos; and s:
</listItem>
<figure confidence="0.96834696">
|next*(s) n next*(s&apos;)|
max{next*(s)|, |next*(s&apos;)|}
flesh3n
fruit1n
berry11n
pulpy1a
parenchyma1n
plant tissue1n
lychee1n
custard apple1n
skin2n
flora2n
edible fruit1n
hygrophyte1n
mango2n
moist1a
fruit3n
flesh3n
newspaper4n
production4n
mag1n
2
+ e5 ·
argmax
s&apos;ESenses(w&apos;)
</figure>
<page confidence="0.981299">
597
</page>
<bodyText confidence="0.99983075">
where we define next*(s) = words(s) U
next(s), and words(s) is the set of lexical-
izations of sense s (e.g. the synonyms in the
synset s). When WordNet is our reference re-
source, we employ an extension of the Lesk
algorithm, namely Extended Gloss Overlap
(Banerjee and Pedersen, 2003), which ex-
tends the sense definition with words from
the definitions of related senses (such as hy-
pernyms, hyponyms, etc.). We use the same
set of relations available in the authors’ im-
plementation of the algorithm.
We also compared the performance of the above
algorithms with two standard baselines, namely
the First Sense Baseline (abbreviated as FS BL)
and the Random Baseline (Random BL).
</bodyText>
<subsectionHeader confidence="0.506703">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.999089363636364">
Our experiments concerned the disambiguation of
the gloss words in three datasets, one for each re-
source, namely WordNet, Macquarie Concise, and
Ragazzini/Biagi. In all datasets, given a sense s,
our set a(s) is given by the set of part-of-speech-
tagged ambiguous content words in the gloss of
sense s from our reference dictionary.
WordNet. When using WordNet as a reference
resource, given a sense s whose gloss we aim to
disambiguate, the dictionary graph includes not
only edges connecting s to senses of gloss words
(step (iii) of the graph construction procedure, cf.
Section 2.1), but also those obtained from any of
the WordNet lexico-semantics relations (step (ii)).
For WordNet gloss disambiguation, we em-
ployed the dataset used in the Senseval-3 Gloss
WSD task (Litkowski, 2004), which contains
15,179 content words from 9,257 glosses5. We
compared the performance of CQC, Cycles, Lesk,
and the two baselines. To get full coverage and
high performance, we learned a threshold for each
system below which they recur to the FS heuris-
tic. The threshold and maximum path length were
tuned on a small in-house manually-annotated
dataset of 100 glosses. The results are shown in
Table 2. We also included in the table the perfor-
mance of the best-ranking system in the Senseval-
5Recently, Princeton University released a richer corpus
of disambiguated glosses, namely the “Princeton WordNet
Gloss Corpus” (http://wordnet.princeton.edu).
However, in order to allow for a comparison with the state
of the art (see below), we decided to adopt the Senseval-3
dataset.
</bodyText>
<table confidence="0.999485">
Algorithm Prec./Recall
CQC 64.25
Cycles 63.74
Lesk 51.75
TALP 68.60/68.30
FS BL 55.44
Random BL 26.29
</table>
<tableCaption confidence="0.986348">
Table 2: Gloss WSD performance on WordNet.
</tableCaption>
<figureCaption confidence="0.288641">
3 Gloss WSD task, namely the TALP system
(Castillo et al., 2004).
</figureCaption>
<bodyText confidence="0.996261815789473">
CQC outperforms all other proposed ap-
proaches, obtaining a 64.25% precision and recall.
We note that Cycles also gets high performance,
compared to Lesk and the baselines. Also, com-
pared to CQC, the difference is not statistically
significant. However, we observe that, if we do
not recur to the first sense as a backoff strategy, we
get a much lower recall for Cycles (P = 65.39, R =
26.70 for CQC, P = 72.03, R = 16.39 for Cycles).
CQC performs about 4 points below the TALP
system. As also discussed later, we believe this re-
sult is relevant, given that our approach does not
rely on additional knowledge resources, as TALP
does (though both algorithms recur to the FS back-
off strategy).
Finally, we observe that the FS baseline has
lower performance than in typical all-words dis-
ambiguation settings (usually above 60% accu-
racy). We believe that this is due to the absence
of monosemous words from the test set, and to
the possibly different distribution of senses in the
dataset.
Macquarie Concise. Automatically disam-
biguating glosses in a computational lexicon
such as WordNet is certainly useful. However,
disambiguating a machine-readable dictionary
is an even more ambitious task. In fact, while
computational lexicons typically encode some ex-
plicit semantic relations which can be used as an
aid to the disambiguation task, machine-readable
dictionaries only rarely provide sense-tagged
information (often in the form of references to
other word senses). As a result, in this latter
setting the dictionary graph typically contains
only edges obtained from the gloss words of sense
s (step (iii), Section 2.1).
To experiment with machine-readable dictio-
naries, we employed the Macquarie Concise Dic-
</bodyText>
<page confidence="0.995643">
598
</page>
<table confidence="0.996681333333333">
Algorithm Prec./Recall
CQC 77.13
Cycles 67.63
Lesk 30.16
FS BL 51.48
Random BL 23.28
</table>
<tableCaption confidence="0.9708915">
Table 3: Gloss WSD performance on Macquarie
Concise.
</tableCaption>
<table confidence="0.999133">
Algorithm Prec./Recall
CQC 89.34
Cycles 85.40
Lesk 63.89
FS BL 73.15
Random BL 51.69
</table>
<tableCaption confidence="0.8709495">
Table 4: Gloss WSD performance on Ragazz-
ini/Biagi.
</tableCaption>
<bodyText confidence="0.999954175">
tionary (Yallop, 2006). A dataset was prepared
by randomly selecting 1,000 word senses from
the dictionary and annotating the content words in
their glosses according to the dictionary sense in-
ventory. Overall, 2,678 words were sense tagged.
The results are shown in Table 3. CQC obtains
an accuracy of 77.13% (in case of ties, a random
choice is made, thus leading to the same precision
and recall), Cycles achieves an accuracy of almost
10% less than CQC (the difference is statistically
significant; p &lt; 0.01). The FS baseline, here, is
based on the first sense listed in the Macquarie
sense inventory, which – in contrast to WordNet
– does not depend on the occurrence frequency of
senses in a semantically-annotated corpus. How-
ever, we note that the FS baseline is not very dif-
ferent from that of the WordNet experiment.
We observe that the Lesk performance is very
low on this dataset (around 7 points above the Ran-
dom BL), due to the impossibility of using the
Extended Gloss Overlap approach (semantic rela-
tions are not available in the Macquarie Concise)
and to the low number of matches between source
and target entries.
Ragazzini/Biagi. Finally, we performed an ex-
periment on the Ragazzini/Biagi English-Italian
machine-readable dictionary. In this experiment,
disambiguating a word w&apos; in the gloss of a sense
s from one section (e.g. Italian-English) equals to
selecting a word sense s&apos; of w&apos; listed in the other
section of the dictionary (e.g. English-Italian). For
example, given the English entry race1n, translated
as “corsan, garan”, our objective is to assign the
right Italian sense from the Italian-English section
to corsan and garan.
To apply the CQC algorithm, a simple adapta-
tion is needed, so as to allow (quasi-)cycles to con-
nect word senses from the two distinct sections.
The algorithm must seek cyclic and quasi-cyclic
paths, respectively of the kind:
</bodyText>
<equation confidence="0.8251045">
i) s -* s&apos; -* s1 -* ··· -* sn−2 -* s
ii) s -* s&apos; -* s1 -* ··· -* sn−2 +- s
</equation>
<bodyText confidence="0.999306727272727">
where n is the path length, s and s&apos; are senses re-
spectively from the source (e.g. Italian/English)
and the target (e.g. English/Italian) section of the
dictionary, si is a sense from the target section for
i &lt; k and from the source section for i &gt; k,
for some k such that 0 &lt; k &lt; n − 2. In other
words, the DFS can jump at any time from the tar-
get section to the source section. After the jump,
the depth search continues in the source section, in
the hope to reach s. For example, the following is
a cycle with k = 1:
</bodyText>
<equation confidence="0.85356">
race1n -* corsa2n -* gara2n -* race1n
</equation>
<bodyText confidence="0.999953695652174">
where the edge between corsa2n and gara2n is due
to the occurrence of garan in the gloss of corsa2n
as a domain label for that sense.
To perform this experiment, we randomly se-
lected 250 entries from each section (500 over-
all), including a total number of 1,069 translations
that we manually sense tagged. In Table 4 we re-
port the results of CQC, Cycles and Lesk on this
task. Overall, the figures are higher than in previ-
ous experiments, thanks to a lower average degree
of polysemy of the resource, which also impacts
positively on the FS baseline. However, given a
random baseline of 51.69%, the performance of
CQC, over 89% precision and recall, is signif-
icantly higher. Cycles obtains around 4 points
less than CQC (the difference is statistically sig-
nificant; p &lt; 0.01). The performance of Lesk
(63.89%) is also much higher than in our previ-
ous experiments, thanks to the higher chance of
finding a 1:1 correspondence between the two sec-
tions. However, we observed that this does not al-
ways hold, as also supported by the better results
of CQC.
</bodyText>
<page confidence="0.998649">
599
</page>
<sectionHeader confidence="0.998511" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999928000000001">
The experiments presented in the previous section
are inherently heterogeneous, due to the different
nature of the resources adopted (a computational
lexicon, a monolingual and a bilingual machine-
readable dictionary). Our aim was to show the
flexibility of our approach in tagging gloss words
with senses from the same dictionary.
We show the average polysemy of the three
datasets in Table 5. Notice that none of the
datasets included monosemous items, so our ex-
periments cannot be compared to typical all-words
disambiguation tasks, where monosemous words
are part of the test set.
Given that words in the Macquarie dataset have
a higher average polysemy than in the Word-
Net dataset, one might wonder why disambiguat-
ing glosses from a computational lexicon such as
WordNet is more difficult than performing a sim-
ilar task on a machine-readable dictionary such
as the Macquarie Concise Dictionary, which does
not provide any explicit semantic hint. We be-
lieve there are at least two reasons for this out-
come: the first specifically concerns the Senseval-
3 Gloss WSD dataset, which does not reflect the
distribution of genus-differentiae terms in dictio-
nary glosses: less than 10% of the items were hy-
pernyms, thus making the task harder. As for the
second reason, we believe that the Macquarie Con-
cise provides more clear-cut definitions, thus mak-
ing sense assignments relatively easier.
An analytical comparison of the results of Cy-
cles and CQC show that, especially for machine-
readable dictionaries, employing both cycles and
quasi-cycles is highly beneficial, as additional sup-
port is provided by the latter patterns. Our results
on WordNet prove to be more difficult to analyze,
because of the need of employing the first sense
heuristic to get full coverage. Also, the maximum
path length used for WordNet was different (S = 3
according to our tuning, compared to 6 = 4 for
Macquarie and Ragazzini/Biagi). However, quasi-
cycles are shown to provide over 10% improve-
ment in terms of recall (at the price of a decrease
in precision of 6.6 points).
Further, we note that the performance of the
CQC algorithm dramatically improves as the max-
imum score (i.e. the score which leads to a sense
assignment) increases. As a result, users can tune
the disambiguation performance based on their
specific needs (coverage, precision, etc.). For in-
</bodyText>
<table confidence="0.9902965">
WN Mac R/B
Polysemy 6.68 7.97 3.16
</table>
<tableCaption confidence="0.999417">
Table 5: Average polysemy of the three datasets.
</tableCaption>
<bodyText confidence="0.999348857142857">
stance, WordNet Gloss WSD can perform up to
85.7% precision and 10.1% recall if we require the
score to be &gt; 0.2 and do not use the FS baseline as
a backoff strategy. Similarly, we can reach up to
93.8% prec., 20.0% recall for Macquarie Concise
(score &gt; 0.12) and even 95.2% prec., 70.6% recall
(score &gt; 0.1) for Ragazzini/Biagi.
</bodyText>
<sectionHeader confidence="0.99987" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99893025">
Word Sense Disambiguation is a large research
field (see (Navigli, 2009) for an up-to-date
overview). However, in this paper we focused on
a specific kind of WSD, namely the disambigua-
tion of dictionary definitions. Seminal works on
the topic date back to the late 1970s, with the de-
velopment of models for the identification of tax-
onomies from lexical resources (Litkowski, 1978;
Amsler, 1980). Subsequent works focused on the
identification of genus terms (Chodorow et al.,
1985) and, more in general, on the extraction of
explicit information from machine-readable dic-
tionaries (see, e.g., (Nakamura and Nagao, 1988;
Ide and V´eronis, 1993)). Kozima and Furugori
(1993) provide an approach to the construction
of ambiguous semantic networks from glosses in
the Longman Dictionary of Contemporary English
(LDOCE). In this direction, it is worth citing the
work of Vanderwende (1996) and Richardson et
al. (1998), who describe the construction of Mind-
Net, a lexical knowledge base obtained from the
automated extraction of lexico-semantic informa-
tion from two machine-readable dictionaries. As a
result, weighted relation paths are produced to in-
fer the semantic similarity between pairs of words.
Several heuristics have been presented for the
disambiguation of the genus of a dictionary defini-
tion (Wilks et al., 1996; Rigau et al., 1997). More
recently, a set of heuristic techniques has been pro-
posed to semantically annotate WordNet glosses,
leading to the release of the eXtended WordNet
(Harabagiu et al., 1999; Moldovan and Novischi,
2004). Among the methods, the cross reference
heuristic is the closest technique to our notion of
cycles and quasi-cycles. Given a pair of words w
and w&apos;, this heuristic is based on the occurrence of
</bodyText>
<page confidence="0.98914">
600
</page>
<bodyText confidence="0.999976535714286">
w in the gloss of a sense s&apos; of w&apos; and, vice versa,
of w&apos; in the gloss of a sense s of w. In other words,
a graph cycle s —* s&apos; —* s of length 2 is sought.
Based on the eXtended WordNet, a gloss dis-
ambiguation task was organized at Senseval-3
(Litkowski, 2004). Interestingly, the best perform-
ing systems, namely the TALP system (Castillo et
al., 2004), and SSI (Navigli and Velardi, 2005),
are knowledge-based and rely on rich knowledge
resources: respectively, the Multilingual Central
Repository (Atserias et al., 2004), and a propri-
etary lexical knowledge base.
In contrast, the approach presented in this paper
performs the disambiguation of ambiguous words
by exploiting only the reference dictionary itself.
Furthermore, as we showed in Section 3.3, our
method does not rely on WordNet, and can be ap-
plied to any lexical knowledge resource, including
bilingual dictionaries.
Finally, methods in the literature more focused
on a specific disambiguation task include statisti-
cal methods for the attachment of hyponyms un-
der the most likely hypernym in the WordNet tax-
onomy (Snow et al., 2006), structural approaches
based on semantic clusters and distance met-
rics (Pennacchiotti and Pantel, 2006), supervised
machine learning methods for the disambiguation
of meronymy relations (Girju et al., 2003), etc.
</bodyText>
<sectionHeader confidence="0.999627" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999872142857143">
In this paper we presented a novel approach to dis-
ambiguate the glosses of computational lexicons
and machine-readable dictionaries, with the aim of
alleviating the knowledge acquisition bottleneck.
The method is based on the identification of cy-
cles and quasi-cycles, i.e. circular edge sequences
(possibly with one edge reversed) relating a source
to a target word sense.
The strength of the approach lies in its weakly
supervised nature: (quasi-)cycles rely exclusively
on the structure of the input lexical resources. No
additional resource (such as labeled corpora or ex-
ternal knowledge bases) is required, assuming we
do not resort to the FS baseline. As a result, the
approach can be applied to obtain a semantic net-
work from the disambiguation of virtually any lex-
ical resource available in machine-readable format
for which a sense inventory is provided.
The utility of gloss disambiguation is even
greater in bilingual dictionaries, as idiosyncrasies
such as missing or redundant translations can be
discovered, thus helping lexicographers improve
the resources6. An adaptation similar to that de-
scribed for disambiguating the Ragazzini/Biagi
can be employed for mapping pairs of lexical
resources (e.g. FrameNet (Baker et al., 1998)
to WordNet), thus contributing to the beneficial
knowledge integration process. Following this di-
rection, we are planning to further experiment on
the mapping of FrameNet, VerbNet (Kipper et al.,
2000), and other lexical resources.
The graphs output by the CQC algo-
rithm for our datasets are available from
http://lcl.uniroma1.it/cqc. We
are scheduling the release of a software pack-
age which includes our implementation of the
CQC algorithm and allows its application to any
resource for which a standard interface can be
written.
Finally, starting from the work of Budanitsky
and Hirst (2006), we plan to experiment with the
CQC algorithm when employed as a semantic sim-
ilarity measure, and compare it with the most suc-
cessful existing approaches. Although in this pa-
per we focused on the disambiguation of dictio-
nary glosses, the same approach can be applied for
disambiguating collocations according to a dictio-
nary of choice, thus providing a way to further en-
rich lexical resources with external knowledge.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999158">
The author is grateful to Ken Litkowski and the
anonymous reviewers for their useful comments.
He also wishes to thank Zanichelli and Macquarie
for kindly making their dictionaries available for
research purposes.
</bodyText>
<sectionHeader confidence="0.998615" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998388">
Robert A. Amsler. 1980. The structure of the
Merriam-Webster pocket dictionary, Ph.D. Thesis.
University of Texas, Austin, TX, USA.
Jordi Atserias, Lu´ıs Villarejo, German Rigau, Eneko
Agirre, John Carroll, Bernardo Magnini, and Piek
Vossen. 2004. The meaning multilingual central
repository. In Proceedings of GWC 2004, pages 23–
30, Brno, Czech Republic.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of COLING-ACL 1998, pages 86–90, Montreal,
Canada.
</reference>
<footnote confidence="0.998232">
6This is indeed an ongoing line of research in collabora-
tion with the Zanichelli dictionary publisher.
</footnote>
<page confidence="0.992454">
601
</page>
<reference confidence="0.998037830508475">
Satanjeev Banerjee and Ted Pedersen. 2003. Extended
gloss overlaps as a measure of semantic relatedness.
In Proceedings of IJCAI 2003, pages 805–810, Aca-
pulco, Mexico.
John Bernard, editor. 1986. Macquarie Thesaurus.
Macquarie, Sydney, Australia.
Tom Bohman and Lubos Thoma. 2000. A note on
sparse random graphs and cover graphs. The Elec-
tronic Journal of Combinatorics, 7:1–9.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating wordnet-based measures of semantic dis-
tance. Computational Linguistics, 32(1):13–47.
Mauro Castillo, Francis Real, Jordi Asterias, and Ger-
man Rigau. 2004. The talp systems for dis-
ambiguating wordnet glosses. In Proceedings of
ACL 2004 SENSEVAL-3 Workshop, pages 93–96,
Barcelona, Spain.
Martin Chodorow, Roy Byrd, and George Heidorn.
1985. Extracting semantic hierarchies from a large
on-line dictionary. In Proceedings of ACL 1985,
pages 299–304, Chicago, IL, USA.
Thomas H. Cormen, Charles E. Leiserson, and
Ronald L. Rivest. 1990. Introduction to algorithms.
MIT Press, Cambridge, MA.
Montse Cuadros and German Rigau. 2006. Quality
assessment of large scale knowledge resources. In
Proceedings of EMNLP 2006, pages 534–541, Syd-
ney, Australia.
Philip Edmonds. 2000. Designing a task for
SENSEVAL-2. Technical note.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Database. MIT Press, Cambridge, MA.
Roxana Girju, Adriana Badulescu, and Dan Moldovan.
2003. Learning semantic constraints for the auto-
matic discovery of part-whole relations. In Proceed-
ings of NAACL 2003, pages 1–8, Edmonton, Canada.
Sanda Harabagiu, George Miller, and Dan Moldovan.
1999. Wordnet 2 - a morphologically and se-
mantically enhanced resource. In Proceedings of
SIGLEX-99, pages 1–8, Maryland, USA.
Nancy Ide and Jean V´eronis. 1993. Extracting
knowledge bases from machine-readable dictionar-
ies: Have we wasted our time? In Proceedings
of Workshop on Knowledge Bases and Knowledge
Structures, pages 257–266, Tokyo, Japan.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon. In
Proceedings of AAAI 2000, pages 691–696, Austin,
TX, USA.
Hideki Kozima and Teiji Furugori. 1993. Similarity
between words computed by spreading activation on
an english dictionary. In Proceedings of ACL 1993,
pages 232–239, Utrecht, The Netherlands.
Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: How to tell a
pine cone from an ice cream cone. In Proceedings
of the 51h SIGDOC, pages 24–26, New York, NY.
Kenneth C. Litkowski. 1978. Models of the semantic
structure of dictionaries. American Journal of Com-
putational Linguistics, (81):25–74.
Kenneth C. Litkowski. 2004. Senseval-3 task:
Word-sense disambiguation of wordnet glosses. In
Proceedings of ACL 2004 SENSEVAL-3 Workshop,
pages 13–16, Barcelona, Spain.
Dan Moldovan and Adrian Novischi. 2004. Word
sense disambiguation of wordnet glosses. Computer
Speech &amp; Language, 18:301–317.
Jun-Ichi Nakamura and Makoto Nagao. 1988. Extrac-
tion of semantic information from an ordinary en-
glish dictionary and its evaluation. In Proceedings
of COLING 1988, pages 459–464, Budapest, Hun-
gary.
Roberto Navigli and Paola Velardi. 2005. Structural
semantic interconnections: a knowledge-based ap-
proach to word sense disambiguation. IEEE Trans-
actions of Pattern Analysis and Machine Intelligence
(TPAMI), 27(7):1075–1088.
Roberto Navigli. 2009. Word sense disambiguation: a
survey. ACM Computing Surveys, 41(2):1–69.
Marco Pennacchiotti and Patrick Pantel. 2006. On-
tologizing semantic relations. In Proceedings of
COLING-ACL 2006, pages 793–800, Sydney, Aus-
tralia.
Paul Proctor, editor. 1978. Longman Dictionary of
Contemporary English. Longman Group, UK.
Giuseppe Ragazzini and Adele Biagi, editors. 2006. Il
Ragazzini-Biagi, 41h Edition. Zanichelli, Italy.
Stephen D. Richardson, William B. Dolan, and Lucy
Vanderwende. 1998. Mindnet: acquiring and struc-
turing semantic information from text. In Proceed-
ings of COLING 1998, pages 1098–1102, Montreal,
Quebec, Canada.
German Rigau, Jordi Atserias, and Eneko Agirre.
1997. Combining unsupervised lexical knowledge
methods for word sense disambiguation. In Pro-
ceedings of ACL/EACL 1997, pages 48–55, Madrid,
Spain.
Peter M. Roget. 1911. Roget’s International The-
saurus (111 edition). Cromwell, New York, USA.
Helmut Schmid. 1997. Probabilistic part-of-speech
tagging using decision trees. In Daniel Jones and
Harold Somers, editors, New Methods in Language
Processing, Studies in Computational Linguistics,
pages 154–164. UCL Press, London, UK.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous
evidence. In Proceedings of COLING-ACL 2006,
pages 801–808, Sydney, Australia.
Lucy Vanderwende. 1996. The analysis of noun se-
quences using semantic information extracted from
on-line dictionaries, Ph.D. Thesis. Georgetown
University, Washington, USA.
Yorick Wilks, Brian Slator, and Louise Guthrie, editors.
1996. Electric words: Dictionaries, computers and
meanings. MIT Press, Cambridge, MA.
Colin Yallop, editor. 2006. The Macquarie Concise
Dictionary 41h Edition. Macquarie Library Pty Ltd,
Sydney, Australia.
</reference>
<page confidence="0.99818">
602
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.493017">
<title confidence="0.999992">Using Cycles and Quasi-Cycles to Disambiguate Dictionary Glosses</title>
<author confidence="0.999831">Roberto Navigli</author>
<affiliation confidence="0.932638">Dipartimento di Informatica</affiliation>
<author confidence="0.6222495">Universit`a di_Roma Via Salaria</author>
<email confidence="0.988384">navigli@di.uniroma1.it</email>
<abstract confidence="0.9996104">We present a novel graph-based algorithm for the automated disambiguation of glosses in lexical knowledge resources. A dictionary graph is built starting from senses (vertices) and explicit or implicit relations in the dictionary (edges). The approach is based on the identification of edge sequences which constitute cycles in the dictionary graph (possibly with one edge reversed) and relate a source to a target word sense. Experiments are performed on the disambiguation of ambiguous words in the glosses of WordNet and two machine-readable dictionaries.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert A Amsler</author>
</authors>
<title>The structure of the Merriam-Webster pocket dictionary,</title>
<date>1980</date>
<institution>Ph.D. Thesis. University of Texas,</institution>
<location>Austin, TX, USA.</location>
<contexts>
<context position="26203" citStr="Amsler, 1980" startWordPosition="4501" endWordPosition="4502">e the FS baseline as a backoff strategy. Similarly, we can reach up to 93.8% prec., 20.0% recall for Macquarie Concise (score &gt; 0.12) and even 95.2% prec., 70.6% recall (score &gt; 0.1) for Ragazzini/Biagi. 5 Related Work Word Sense Disambiguation is a large research field (see (Navigli, 2009) for an up-to-date overview). However, in this paper we focused on a specific kind of WSD, namely the disambiguation of dictionary definitions. Seminal works on the topic date back to the late 1970s, with the development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained fro</context>
</contexts>
<marker>Amsler, 1980</marker>
<rawString>Robert A. Amsler. 1980. The structure of the Merriam-Webster pocket dictionary, Ph.D. Thesis. University of Texas, Austin, TX, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
</authors>
<title>Lu´ıs Villarejo, German Rigau, Eneko Agirre,</title>
<date>2004</date>
<booktitle>In Proceedings of GWC 2004,</booktitle>
<pages>23--30</pages>
<location>John</location>
<marker>Atserias, 2004</marker>
<rawString>Jordi Atserias, Lu´ıs Villarejo, German Rigau, Eneko Agirre, John Carroll, Bernardo Magnini, and Piek Vossen. 2004. The meaning multilingual central repository. In Proceedings of GWC 2004, pages 23– 30, Brno, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley framenet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<pages>86--90</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="30124" citStr="Baker et al., 1998" startWordPosition="5115" endWordPosition="5118">do not resort to the FS baseline. As a result, the approach can be applied to obtain a semantic network from the disambiguation of virtually any lexical resource available in machine-readable format for which a sense inventory is provided. The utility of gloss disambiguation is even greater in bilingual dictionaries, as idiosyncrasies such as missing or redundant translations can be discovered, thus helping lexicographers improve the resources6. An adaptation similar to that described for disambiguating the Ragazzini/Biagi can be employed for mapping pairs of lexical resources (e.g. FrameNet (Baker et al., 1998) to WordNet), thus contributing to the beneficial knowledge integration process. Following this direction, we are planning to further experiment on the mapping of FrameNet, VerbNet (Kipper et al., 2000), and other lexical resources. The graphs output by the CQC algorithm for our datasets are available from http://lcl.uniroma1.it/cqc. We are scheduling the release of a software package which includes our implementation of the CQC algorithm and allows its application to any resource for which a standard interface can be written. Finally, starting from the work of Budanitsky and Hirst (2006), we </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley framenet project. In Proceedings of COLING-ACL 1998, pages 86–90, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Extended gloss overlaps as a measure of semantic relatedness.</title>
<date>2003</date>
<booktitle>In Proceedings of IJCAI 2003,</booktitle>
<pages>805--810</pages>
<location>Acapulco, Mexico.</location>
<contexts>
<context position="15290" citStr="Banerjee and Pedersen, 2003" startWordPosition="2665" endWordPosition="2668">ximizes the (normalized) overlap between each sense s&apos; of w&apos; and s: |next*(s) n next*(s&apos;)| max{next*(s)|, |next*(s&apos;)|} flesh3n fruit1n berry11n pulpy1a parenchyma1n plant tissue1n lychee1n custard apple1n skin2n flora2n edible fruit1n hygrophyte1n mango2n moist1a fruit3n flesh3n newspaper4n production4n mag1n 2 + e5 · argmax s&apos;ESenses(w&apos;) 597 where we define next*(s) = words(s) U next(s), and words(s) is the set of lexicalizations of sense s (e.g. the synonyms in the synset s). When WordNet is our reference resource, we employ an extension of the Lesk algorithm, namely Extended Gloss Overlap (Banerjee and Pedersen, 2003), which extends the sense definition with words from the definitions of related senses (such as hypernyms, hyponyms, etc.). We use the same set of relations available in the authors’ implementation of the algorithm. We also compared the performance of the above algorithms with two standard baselines, namely the First Sense Baseline (abbreviated as FS BL) and the Random Baseline (Random BL). 3.3 Results Our experiments concerned the disambiguation of the gloss words in three datasets, one for each resource, namely WordNet, Macquarie Concise, and Ragazzini/Biagi. In all datasets, given a sense s</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2003. Extended gloss overlaps as a measure of semantic relatedness. In Proceedings of IJCAI 2003, pages 805–810, Acapulco, Mexico.</rawString>
</citation>
<citation valid="true">
<title>Macquarie Thesaurus.</title>
<date>1986</date>
<editor>John Bernard, editor.</editor>
<location>Macquarie, Sydney, Australia.</location>
<marker>1986</marker>
<rawString>John Bernard, editor. 1986. Macquarie Thesaurus. Macquarie, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Bohman</author>
<author>Lubos Thoma</author>
</authors>
<title>A note on sparse random graphs and cover graphs.</title>
<date>2000</date>
<journal>The Electronic Journal of Combinatorics,</journal>
<volume>7</volume>
<contexts>
<context position="6236" citStr="Bohman and Thoma, 2000" startWordPosition="1031" endWordPosition="1034">orms a path v1 → v2 → · · · → vn (vi ∈ V ) such that the first vertex of the path corresponds to the last, i.e. v1 = vn (Cormen et al., 1990, p. 88). For example, the cycle in Figure 1(a) is given by the path racing1n → contest1n → race3n → run3 n → racing1n in the WordNet dictionary graph. In fact Figure 1: An example of cycle (a) and quasi-cycle (b) in WordNet. contestn occurs in the gloss of racing1n, race3n is a hyponym of contest1n, and so on. We further provide the definition of quasi-cycle as a sequence of edges in which the reversal of the orientation of a single edge creates a cycle (Bohman and Thoma, 2000). For instance, the quasi-cycle in Figure 1(b) is given by the path racing1n → contest1n → compete1v → race2v ← racing1n. In fact, the reversal of the edge (racing1n, race2v) creates a cycle. Finally, we call a path a (quasi-)cycle if it is either a cycle or a quasi-cycle. Further, we say that a path is (quasi-)cyclic if it forms a (quasi-)cycle in the graph. 2.2 The CQC Algorithm Given a dictionary graph G = (V, E) built as described in the previous section, our objective is to disambiguate dictionary glosses with the support of (quasi-)cycles. (Quasi-)cyclic paths are intuitively better than</context>
</contexts>
<marker>Bohman, Thoma, 2000</marker>
<rawString>Tom Bohman and Lubos Thoma. 2000. A note on sparse random graphs and cover graphs. The Electronic Journal of Combinatorics, 7:1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating wordnet-based measures of semantic distance.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="30719" citStr="Budanitsky and Hirst (2006)" startWordPosition="5207" endWordPosition="5210">g. FrameNet (Baker et al., 1998) to WordNet), thus contributing to the beneficial knowledge integration process. Following this direction, we are planning to further experiment on the mapping of FrameNet, VerbNet (Kipper et al., 2000), and other lexical resources. The graphs output by the CQC algorithm for our datasets are available from http://lcl.uniroma1.it/cqc. We are scheduling the release of a software package which includes our implementation of the CQC algorithm and allows its application to any resource for which a standard interface can be written. Finally, starting from the work of Budanitsky and Hirst (2006), we plan to experiment with the CQC algorithm when employed as a semantic similarity measure, and compare it with the most successful existing approaches. Although in this paper we focused on the disambiguation of dictionary glosses, the same approach can be applied for disambiguating collocations according to a dictionary of choice, thus providing a way to further enrich lexical resources with external knowledge. Acknowledgments The author is grateful to Ken Litkowski and the anonymous reviewers for their useful comments. He also wishes to thank Zanichelli and Macquarie for kindly making the</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating wordnet-based measures of semantic distance. Computational Linguistics, 32(1):13–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Castillo</author>
<author>Francis Real</author>
<author>Jordi Asterias</author>
<author>German Rigau</author>
</authors>
<title>The talp systems for disambiguating wordnet glosses.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL 2004 SENSEVAL-3 Workshop,</booktitle>
<pages>93--96</pages>
<location>Barcelona,</location>
<contexts>
<context position="17471" citStr="Castillo et al., 2004" startWordPosition="3016" endWordPosition="3019">ses. The results are shown in Table 2. We also included in the table the performance of the best-ranking system in the Senseval5Recently, Princeton University released a richer corpus of disambiguated glosses, namely the “Princeton WordNet Gloss Corpus” (http://wordnet.princeton.edu). However, in order to allow for a comparison with the state of the art (see below), we decided to adopt the Senseval-3 dataset. Algorithm Prec./Recall CQC 64.25 Cycles 63.74 Lesk 51.75 TALP 68.60/68.30 FS BL 55.44 Random BL 26.29 Table 2: Gloss WSD performance on WordNet. 3 Gloss WSD task, namely the TALP system (Castillo et al., 2004). CQC outperforms all other proposed approaches, obtaining a 64.25% precision and recall. We note that Cycles also gets high performance, compared to Lesk and the baselines. Also, compared to CQC, the difference is not statistically significant. However, we observe that, if we do not recur to the first sense as a backoff strategy, we get a much lower recall for Cycles (P = 65.39, R = 26.70 for CQC, P = 72.03, R = 16.39 for Cycles). CQC performs about 4 points below the TALP system. As also discussed later, we believe this result is relevant, given that our approach does not rely on additional </context>
<context position="27908" citStr="Castillo et al., 2004" startWordPosition="4780" endWordPosition="4783"> eXtended WordNet (Harabagiu et al., 1999; Moldovan and Novischi, 2004). Among the methods, the cross reference heuristic is the closest technique to our notion of cycles and quasi-cycles. Given a pair of words w and w&apos;, this heuristic is based on the occurrence of 600 w in the gloss of a sense s&apos; of w&apos; and, vice versa, of w&apos; in the gloss of a sense s of w. In other words, a graph cycle s —* s&apos; —* s of length 2 is sought. Based on the eXtended WordNet, a gloss disambiguation task was organized at Senseval-3 (Litkowski, 2004). Interestingly, the best performing systems, namely the TALP system (Castillo et al., 2004), and SSI (Navigli and Velardi, 2005), are knowledge-based and rely on rich knowledge resources: respectively, the Multilingual Central Repository (Atserias et al., 2004), and a proprietary lexical knowledge base. In contrast, the approach presented in this paper performs the disambiguation of ambiguous words by exploiting only the reference dictionary itself. Furthermore, as we showed in Section 3.3, our method does not rely on WordNet, and can be applied to any lexical knowledge resource, including bilingual dictionaries. Finally, methods in the literature more focused on a specific disambig</context>
</contexts>
<marker>Castillo, Real, Asterias, Rigau, 2004</marker>
<rawString>Mauro Castillo, Francis Real, Jordi Asterias, and German Rigau. 2004. The talp systems for disambiguating wordnet glosses. In Proceedings of ACL 2004 SENSEVAL-3 Workshop, pages 93–96, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Chodorow</author>
<author>Roy Byrd</author>
<author>George Heidorn</author>
</authors>
<title>Extracting semantic hierarchies from a large on-line dictionary.</title>
<date>1985</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>299--304</pages>
<location>Chicago, IL, USA.</location>
<contexts>
<context position="26290" citStr="Chodorow et al., 1985" startWordPosition="4512" endWordPosition="4515">rec., 20.0% recall for Macquarie Concise (score &gt; 0.12) and even 95.2% prec., 70.6% recall (score &gt; 0.1) for Ragazzini/Biagi. 5 Related Work Word Sense Disambiguation is a large research field (see (Navigli, 2009) for an up-to-date overview). However, in this paper we focused on a specific kind of WSD, namely the disambiguation of dictionary definitions. Seminal works on the topic date back to the late 1970s, with the development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dic</context>
</contexts>
<marker>Chodorow, Byrd, Heidorn, 1985</marker>
<rawString>Martin Chodorow, Roy Byrd, and George Heidorn. 1985. Extracting semantic hierarchies from a large on-line dictionary. In Proceedings of ACL 1985, pages 299–304, Chicago, IL, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas H Cormen</author>
<author>Charles E Leiserson</author>
<author>Ronald L Rivest</author>
</authors>
<title>Introduction to algorithms.</title>
<date>1990</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5753" citStr="Cormen et al., 1990" startWordPosition="942" endWordPosition="945">he sport of engaging in contests of speed” is part-of-speech tagged, obtaining the following set of content words: { sportn, engagev, contestn, speedn }. The following edges are then added to E: { (racing1n, sport1n), (racing1n, sport2n), ... , (racing1n, sport6n), . . ., (racing1n, speed1n), ... , (racing1n, speed5n) }. The above steps are performed for all the senses in V . We now recall the definition of graph cycle. A cycle in a graph G is a sequence of edges of G that forms a path v1 → v2 → · · · → vn (vi ∈ V ) such that the first vertex of the path corresponds to the last, i.e. v1 = vn (Cormen et al., 1990, p. 88). For example, the cycle in Figure 1(a) is given by the path racing1n → contest1n → race3n → run3 n → racing1n in the WordNet dictionary graph. In fact Figure 1: An example of cycle (a) and quasi-cycle (b) in WordNet. contestn occurs in the gloss of racing1n, race3n is a hyponym of contest1n, and so on. We further provide the definition of quasi-cycle as a sequence of edges in which the reversal of the orientation of a single edge creates a cycle (Bohman and Thoma, 2000). For instance, the quasi-cycle in Figure 1(b) is given by the path racing1n → contest1n → compete1v → race2v ← racin</context>
<context position="8783" citStr="Cormen et al., 1990" startWordPosition="1522" endWordPosition="1526">with the same vertex s, and that we restrict quasi-cycles to those whose inverted edge departs from s. To avoid any redundancy, we require that no vertex is repeated in the path aside from the start/end vertex (i.e. s =� s&apos; =� si =� sj for any i, j E {1, ... , n − 2}). The Cycles and Quasi-Cycles (CQC) algorithm, reported in pseudo-code in Table 1, takes as input a source sense s and a target word w&apos; (in our setting2 w&apos; E a(s)). It consists of two main phases. During steps 1-3, cycles and quasi-cycles are sought for each sense of w&apos;. This step is performed with a depth-first search (DFS, cf. (Cormen et al., 1990, pp. 477–479)) up to a depth S. To this end, we first define next(s) = {s&apos;&apos; : (s, s&apos;&apos;) E E}, that is the set of senses which can be directly reached from sense s. The DFS starts from a sense s&apos; E Senses(w&apos;), and recursively explores the senses in next(s&apos;) until sense s or a sense in next(s) is encountered, obtaining a cycle or a quasi-cycle, respectively. For each sense s&apos; of w&apos; the DFS returns the full set CQC(s&apos;) of (quasi-)cyclic paths collected. Note that the DFS recursively keeps track of previously visited senses, so as to discard (quasi-)cycles including the same sense twice. Finally, </context>
</contexts>
<marker>Cormen, Leiserson, Rivest, 1990</marker>
<rawString>Thomas H. Cormen, Charles E. Leiserson, and Ronald L. Rivest. 1990. Introduction to algorithms. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Montse Cuadros</author>
<author>German Rigau</author>
</authors>
<title>Quality assessment of large scale knowledge resources.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP 2006,</booktitle>
<pages>534--541</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2492" citStr="Cuadros and Rigau, 2006" startWordPosition="363" endWordPosition="366">reover, while computational lexicons like WordNet contain semantically explicit information such as, among others, hypernymy and meronymy relations, most thesauri, glossaries, and machine-readable dictionaries are often just electronic transcriptions of their paper counterparts. As a result, for each entry (e.g. a word sense or thesaurus entry) they mostly provide implicit information in the form of free text. The production of semantically richer lexical resources can help alleviate the knowledge acquisition bottleneck and potentially enable advanced Natural Language Processing applications (Cuadros and Rigau, 2006). However, in order to reduce the high cost of manual annotation (Edmonds, 2000), and to avoid the repetition of this effort for each knowledge resource, this task must be supported by wide-coverage automated techniques which do not rely on the specific resource at hand. In this paper, we aim to make explicit large quantities of semantic information implicitly contained in the glosses of existing widecoverage lexical knowledge resources (specifically, machine-readable dictionaries and computational lexicons). To this end, we present a method for Gloss Word Sense Disambiguation (WSD), called th</context>
</contexts>
<marker>Cuadros, Rigau, 2006</marker>
<rawString>Montse Cuadros and German Rigau. 2006. Quality assessment of large scale knowledge resources. In Proceedings of EMNLP 2006, pages 534–541, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Edmonds</author>
</authors>
<title>Designing a task for SENSEVAL-2.</title>
<date>2000</date>
<tech>Technical note.</tech>
<contexts>
<context position="2572" citStr="Edmonds, 2000" startWordPosition="378" endWordPosition="380">n such as, among others, hypernymy and meronymy relations, most thesauri, glossaries, and machine-readable dictionaries are often just electronic transcriptions of their paper counterparts. As a result, for each entry (e.g. a word sense or thesaurus entry) they mostly provide implicit information in the form of free text. The production of semantically richer lexical resources can help alleviate the knowledge acquisition bottleneck and potentially enable advanced Natural Language Processing applications (Cuadros and Rigau, 2006). However, in order to reduce the high cost of manual annotation (Edmonds, 2000), and to avoid the repetition of this effort for each knowledge resource, this task must be supported by wide-coverage automated techniques which do not rely on the specific resource at hand. In this paper, we aim to make explicit large quantities of semantic information implicitly contained in the glosses of existing widecoverage lexical knowledge resources (specifically, machine-readable dictionaries and computational lexicons). To this end, we present a method for Gloss Word Sense Disambiguation (WSD), called the Cycles and Quasi-Cycles (CQC) algorithm. The algorithm is based on a novel not</context>
</contexts>
<marker>Edmonds, 2000</marker>
<rawString>Philip Edmonds. 2000. Designing a task for SENSEVAL-2. Technical note.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="26722" citStr="(1998)" startWordPosition="4580" endWordPosition="4580">the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics have been presented for the disambiguation of the genus of a dictionary definition (Wilks et al., 1996; Rigau et al., 1997). More recently, a set of heuristic techniques has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtended WordNet (Harabagiu et al.,</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Adriana Badulescu</author>
<author>Dan Moldovan</author>
</authors>
<title>Learning semantic constraints for the automatic discovery of part-whole relations.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL 2003,</booktitle>
<pages>1--8</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="28860" citStr="Girju et al., 2003" startWordPosition="4922" endWordPosition="4925"> reference dictionary itself. Furthermore, as we showed in Section 3.3, our method does not rely on WordNet, and can be applied to any lexical knowledge resource, including bilingual dictionaries. Finally, methods in the literature more focused on a specific disambiguation task include statistical methods for the attachment of hyponyms under the most likely hypernym in the WordNet taxonomy (Snow et al., 2006), structural approaches based on semantic clusters and distance metrics (Pennacchiotti and Pantel, 2006), supervised machine learning methods for the disambiguation of meronymy relations (Girju et al., 2003), etc. 6 Conclusions In this paper we presented a novel approach to disambiguate the glosses of computational lexicons and machine-readable dictionaries, with the aim of alleviating the knowledge acquisition bottleneck. The method is based on the identification of cycles and quasi-cycles, i.e. circular edge sequences (possibly with one edge reversed) relating a source to a target word sense. The strength of the approach lies in its weakly supervised nature: (quasi-)cycles rely exclusively on the structure of the input lexical resources. No additional resource (such as labeled corpora or extern</context>
</contexts>
<marker>Girju, Badulescu, Moldovan, 2003</marker>
<rawString>Roxana Girju, Adriana Badulescu, and Dan Moldovan. 2003. Learning semantic constraints for the automatic discovery of part-whole relations. In Proceedings of NAACL 2003, pages 1–8, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda Harabagiu</author>
<author>George Miller</author>
<author>Dan Moldovan</author>
</authors>
<title>Wordnet 2 - a morphologically and semantically enhanced resource.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGLEX-99,</booktitle>
<pages>1--8</pages>
<location>Maryland, USA.</location>
<contexts>
<context position="27327" citStr="Harabagiu et al., 1999" startWordPosition="4671" endWordPosition="4674">son et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics have been presented for the disambiguation of the genus of a dictionary definition (Wilks et al., 1996; Rigau et al., 1997). More recently, a set of heuristic techniques has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtended WordNet (Harabagiu et al., 1999; Moldovan and Novischi, 2004). Among the methods, the cross reference heuristic is the closest technique to our notion of cycles and quasi-cycles. Given a pair of words w and w&apos;, this heuristic is based on the occurrence of 600 w in the gloss of a sense s&apos; of w&apos; and, vice versa, of w&apos; in the gloss of a sense s of w. In other words, a graph cycle s —* s&apos; —* s of length 2 is sought. Based on the eXtended WordNet, a gloss disambiguation task was organized at Senseval-3 (Litkowski, 2004). Interestingly, the best performing systems, namely the TALP system (Castillo et al., 2004), and SSI (Navigli </context>
</contexts>
<marker>Harabagiu, Miller, Moldovan, 1999</marker>
<rawString>Sanda Harabagiu, George Miller, and Dan Moldovan. 1999. Wordnet 2 - a morphologically and semantically enhanced resource. In Proceedings of SIGLEX-99, pages 1–8, Maryland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Jean V´eronis</author>
</authors>
<title>Extracting knowledge bases from machine-readable dictionaries: Have we wasted our time?</title>
<date>1993</date>
<booktitle>In Proceedings of Workshop on Knowledge Bases and Knowledge Structures,</booktitle>
<pages>257--266</pages>
<location>Tokyo, Japan.</location>
<marker>Ide, V´eronis, 1993</marker>
<rawString>Nancy Ide and Jean V´eronis. 1993. Extracting knowledge bases from machine-readable dictionaries: Have we wasted our time? In Proceedings of Workshop on Knowledge Bases and Knowledge Structures, pages 257–266, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Hoa Trang Dang</author>
<author>Martha Palmer</author>
</authors>
<title>Class-based construction of a verb lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of AAAI 2000,</booktitle>
<pages>691--696</pages>
<location>Austin, TX, USA.</location>
<contexts>
<context position="30326" citStr="Kipper et al., 2000" startWordPosition="5145" endWordPosition="5148">r which a sense inventory is provided. The utility of gloss disambiguation is even greater in bilingual dictionaries, as idiosyncrasies such as missing or redundant translations can be discovered, thus helping lexicographers improve the resources6. An adaptation similar to that described for disambiguating the Ragazzini/Biagi can be employed for mapping pairs of lexical resources (e.g. FrameNet (Baker et al., 1998) to WordNet), thus contributing to the beneficial knowledge integration process. Following this direction, we are planning to further experiment on the mapping of FrameNet, VerbNet (Kipper et al., 2000), and other lexical resources. The graphs output by the CQC algorithm for our datasets are available from http://lcl.uniroma1.it/cqc. We are scheduling the release of a software package which includes our implementation of the CQC algorithm and allows its application to any resource for which a standard interface can be written. Finally, starting from the work of Budanitsky and Hirst (2006), we plan to experiment with the CQC algorithm when employed as a semantic similarity measure, and compare it with the most successful existing approaches. Although in this paper we focused on the disambigua</context>
</contexts>
<marker>Kipper, Dang, Palmer, 2000</marker>
<rawString>Karin Kipper, Hoa Trang Dang, and Martha Palmer. 2000. Class-based construction of a verb lexicon. In Proceedings of AAAI 2000, pages 691–696, Austin, TX, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Kozima</author>
<author>Teiji Furugori</author>
</authors>
<title>Similarity between words computed by spreading activation on an english dictionary.</title>
<date>1993</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>232--239</pages>
<location>Utrecht, The Netherlands.</location>
<contexts>
<context position="26481" citStr="Kozima and Furugori (1993)" startWordPosition="4540" endWordPosition="4543">field (see (Navigli, 2009) for an up-to-date overview). However, in this paper we focused on a specific kind of WSD, namely the disambiguation of dictionary definitions. Seminal works on the topic date back to the late 1970s, with the development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics have been presented for the disambiguation of the genu</context>
</contexts>
<marker>Kozima, Furugori, 1993</marker>
<rawString>Hideki Kozima and Teiji Furugori. 1993. Similarity between words computed by spreading activation on an english dictionary. In Proceedings of ACL 1993, pages 232–239, Utrecht, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the 51h SIGDOC,</booktitle>
<pages>24--26</pages>
<location>New York, NY.</location>
<contexts>
<context position="14528" citStr="Lesk, 1986" startWordPosition="2544" endWordPosition="2545">iagi, 2006), a bilingual English-Italian dictionary, containing over 90,000 lemmas and 150,000 word senses. The dictionary provides Italian translations for each English word sense, and vice versa. We used TreeTagger (Schmid, 1997) to part-ofspeech tag the glosses in the three resources. 3.2 Algorithms Hereafter we briefly summarize the algorithms that we applied in our experiments: • CQC: we applied the CQC algorithm as described in Section 2.2; • Cycles, which applies the CQC algorithm but searches for cycles only (i.e. quasi-cycles are not collected); • An adaptation of the Lesk algorithm (Lesk, 1986), which, given a source sense s of word w and a word w&apos; occurring in the gloss of s, determines the right sense of w&apos; as that which maximizes the (normalized) overlap between each sense s&apos; of w&apos; and s: |next*(s) n next*(s&apos;)| max{next*(s)|, |next*(s&apos;)|} flesh3n fruit1n berry11n pulpy1a parenchyma1n plant tissue1n lychee1n custard apple1n skin2n flora2n edible fruit1n hygrophyte1n mango2n moist1a fruit3n flesh3n newspaper4n production4n mag1n 2 + e5 · argmax s&apos;ESenses(w&apos;) 597 where we define next*(s) = words(s) U next(s), and words(s) is the set of lexicalizations of sense s (e.g. the synonyms i</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 51h SIGDOC, pages 24–26, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth C Litkowski</author>
</authors>
<title>Models of the semantic structure of dictionaries.</title>
<date>1978</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>81--25</pages>
<contexts>
<context position="26188" citStr="Litkowski, 1978" startWordPosition="4499" endWordPosition="4500">0.2 and do not use the FS baseline as a backoff strategy. Similarly, we can reach up to 93.8% prec., 20.0% recall for Macquarie Concise (score &gt; 0.12) and even 95.2% prec., 70.6% recall (score &gt; 0.1) for Ragazzini/Biagi. 5 Related Work Word Sense Disambiguation is a large research field (see (Navigli, 2009) for an up-to-date overview). However, in this paper we focused on a specific kind of WSD, namely the disambiguation of dictionary definitions. Seminal works on the topic date back to the late 1970s, with the development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge ba</context>
</contexts>
<marker>Litkowski, 1978</marker>
<rawString>Kenneth C. Litkowski. 1978. Models of the semantic structure of dictionaries. American Journal of Computational Linguistics, (81):25–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth C Litkowski</author>
</authors>
<title>Senseval-3 task: Word-sense disambiguation of wordnet glosses.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL 2004 SENSEVAL-3 Workshop,</booktitle>
<pages>13--16</pages>
<location>Barcelona,</location>
<contexts>
<context position="16484" citStr="Litkowski, 2004" startWordPosition="2860" endWordPosition="2861">asets, given a sense s, our set a(s) is given by the set of part-of-speechtagged ambiguous content words in the gloss of sense s from our reference dictionary. WordNet. When using WordNet as a reference resource, given a sense s whose gloss we aim to disambiguate, the dictionary graph includes not only edges connecting s to senses of gloss words (step (iii) of the graph construction procedure, cf. Section 2.1), but also those obtained from any of the WordNet lexico-semantics relations (step (ii)). For WordNet gloss disambiguation, we employed the dataset used in the Senseval-3 Gloss WSD task (Litkowski, 2004), which contains 15,179 content words from 9,257 glosses5. We compared the performance of CQC, Cycles, Lesk, and the two baselines. To get full coverage and high performance, we learned a threshold for each system below which they recur to the FS heuristic. The threshold and maximum path length were tuned on a small in-house manually-annotated dataset of 100 glosses. The results are shown in Table 2. We also included in the table the performance of the best-ranking system in the Senseval5Recently, Princeton University released a richer corpus of disambiguated glosses, namely the “Princeton Wor</context>
<context position="27816" citStr="Litkowski, 2004" startWordPosition="4768" endWordPosition="4769"> been proposed to semantically annotate WordNet glosses, leading to the release of the eXtended WordNet (Harabagiu et al., 1999; Moldovan and Novischi, 2004). Among the methods, the cross reference heuristic is the closest technique to our notion of cycles and quasi-cycles. Given a pair of words w and w&apos;, this heuristic is based on the occurrence of 600 w in the gloss of a sense s&apos; of w&apos; and, vice versa, of w&apos; in the gloss of a sense s of w. In other words, a graph cycle s —* s&apos; —* s of length 2 is sought. Based on the eXtended WordNet, a gloss disambiguation task was organized at Senseval-3 (Litkowski, 2004). Interestingly, the best performing systems, namely the TALP system (Castillo et al., 2004), and SSI (Navigli and Velardi, 2005), are knowledge-based and rely on rich knowledge resources: respectively, the Multilingual Central Repository (Atserias et al., 2004), and a proprietary lexical knowledge base. In contrast, the approach presented in this paper performs the disambiguation of ambiguous words by exploiting only the reference dictionary itself. Furthermore, as we showed in Section 3.3, our method does not rely on WordNet, and can be applied to any lexical knowledge resource, including bi</context>
</contexts>
<marker>Litkowski, 2004</marker>
<rawString>Kenneth C. Litkowski. 2004. Senseval-3 task: Word-sense disambiguation of wordnet glosses. In Proceedings of ACL 2004 SENSEVAL-3 Workshop, pages 13–16, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
<author>Adrian Novischi</author>
</authors>
<title>Word sense disambiguation of wordnet glosses.</title>
<date>2004</date>
<journal>Computer Speech &amp; Language,</journal>
<pages>18--301</pages>
<contexts>
<context position="27357" citStr="Moldovan and Novischi, 2004" startWordPosition="4675" endWordPosition="4678">escribe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics have been presented for the disambiguation of the genus of a dictionary definition (Wilks et al., 1996; Rigau et al., 1997). More recently, a set of heuristic techniques has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtended WordNet (Harabagiu et al., 1999; Moldovan and Novischi, 2004). Among the methods, the cross reference heuristic is the closest technique to our notion of cycles and quasi-cycles. Given a pair of words w and w&apos;, this heuristic is based on the occurrence of 600 w in the gloss of a sense s&apos; of w&apos; and, vice versa, of w&apos; in the gloss of a sense s of w. In other words, a graph cycle s —* s&apos; —* s of length 2 is sought. Based on the eXtended WordNet, a gloss disambiguation task was organized at Senseval-3 (Litkowski, 2004). Interestingly, the best performing systems, namely the TALP system (Castillo et al., 2004), and SSI (Navigli and Velardi, 2005), are knowle</context>
</contexts>
<marker>Moldovan, Novischi, 2004</marker>
<rawString>Dan Moldovan and Adrian Novischi. 2004. Word sense disambiguation of wordnet glosses. Computer Speech &amp; Language, 18:301–317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-Ichi Nakamura</author>
<author>Makoto Nagao</author>
</authors>
<title>Extraction of semantic information from an ordinary english dictionary and its evaluation.</title>
<date>1988</date>
<booktitle>In Proceedings of COLING 1988,</booktitle>
<pages>459--464</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="26427" citStr="Nakamura and Nagao, 1988" startWordPosition="4532" endWordPosition="4535"> Work Word Sense Disambiguation is a large research field (see (Navigli, 2009) for an up-to-date overview). However, in this paper we focused on a specific kind of WSD, namely the disambiguation of dictionary definitions. Seminal works on the topic date back to the late 1970s, with the development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics </context>
</contexts>
<marker>Nakamura, Nagao, 1988</marker>
<rawString>Jun-Ichi Nakamura and Makoto Nagao. 1988. Extraction of semantic information from an ordinary english dictionary and its evaluation. In Proceedings of COLING 1988, pages 459–464, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Structural semantic interconnections: a knowledge-based approach to word sense disambiguation.</title>
<date>2005</date>
<journal>IEEE Transactions of Pattern Analysis and Machine Intelligence (TPAMI),</journal>
<volume>27</volume>
<issue>7</issue>
<contexts>
<context position="27945" citStr="Navigli and Velardi, 2005" startWordPosition="4786" endWordPosition="4789">l., 1999; Moldovan and Novischi, 2004). Among the methods, the cross reference heuristic is the closest technique to our notion of cycles and quasi-cycles. Given a pair of words w and w&apos;, this heuristic is based on the occurrence of 600 w in the gloss of a sense s&apos; of w&apos; and, vice versa, of w&apos; in the gloss of a sense s of w. In other words, a graph cycle s —* s&apos; —* s of length 2 is sought. Based on the eXtended WordNet, a gloss disambiguation task was organized at Senseval-3 (Litkowski, 2004). Interestingly, the best performing systems, namely the TALP system (Castillo et al., 2004), and SSI (Navigli and Velardi, 2005), are knowledge-based and rely on rich knowledge resources: respectively, the Multilingual Central Repository (Atserias et al., 2004), and a proprietary lexical knowledge base. In contrast, the approach presented in this paper performs the disambiguation of ambiguous words by exploiting only the reference dictionary itself. Furthermore, as we showed in Section 3.3, our method does not rely on WordNet, and can be applied to any lexical knowledge resource, including bilingual dictionaries. Finally, methods in the literature more focused on a specific disambiguation task include statistical metho</context>
</contexts>
<marker>Navigli, Velardi, 2005</marker>
<rawString>Roberto Navigli and Paola Velardi. 2005. Structural semantic interconnections: a knowledge-based approach to word sense disambiguation. IEEE Transactions of Pattern Analysis and Machine Intelligence (TPAMI), 27(7):1075–1088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: a survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="25881" citStr="Navigli, 2009" startWordPosition="4448" endWordPosition="4449">, users can tune the disambiguation performance based on their specific needs (coverage, precision, etc.). For inWN Mac R/B Polysemy 6.68 7.97 3.16 Table 5: Average polysemy of the three datasets. stance, WordNet Gloss WSD can perform up to 85.7% precision and 10.1% recall if we require the score to be &gt; 0.2 and do not use the FS baseline as a backoff strategy. Similarly, we can reach up to 93.8% prec., 20.0% recall for Macquarie Concise (score &gt; 0.12) and even 95.2% prec., 70.6% recall (score &gt; 0.1) for Ragazzini/Biagi. 5 Related Work Word Sense Disambiguation is a large research field (see (Navigli, 2009) for an up-to-date overview). However, in this paper we focused on a specific kind of WSD, namely the disambiguation of dictionary definitions. Seminal works on the topic date back to the late 1970s, with the development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993)</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: a survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Patrick Pantel</author>
</authors>
<title>Ontologizing semantic relations.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL 2006,</booktitle>
<pages>793--800</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="28757" citStr="Pennacchiotti and Pantel, 2006" startWordPosition="4908" endWordPosition="4911">ontrast, the approach presented in this paper performs the disambiguation of ambiguous words by exploiting only the reference dictionary itself. Furthermore, as we showed in Section 3.3, our method does not rely on WordNet, and can be applied to any lexical knowledge resource, including bilingual dictionaries. Finally, methods in the literature more focused on a specific disambiguation task include statistical methods for the attachment of hyponyms under the most likely hypernym in the WordNet taxonomy (Snow et al., 2006), structural approaches based on semantic clusters and distance metrics (Pennacchiotti and Pantel, 2006), supervised machine learning methods for the disambiguation of meronymy relations (Girju et al., 2003), etc. 6 Conclusions In this paper we presented a novel approach to disambiguate the glosses of computational lexicons and machine-readable dictionaries, with the aim of alleviating the knowledge acquisition bottleneck. The method is based on the identification of cycles and quasi-cycles, i.e. circular edge sequences (possibly with one edge reversed) relating a source to a target word sense. The strength of the approach lies in its weakly supervised nature: (quasi-)cycles rely exclusively on </context>
</contexts>
<marker>Pennacchiotti, Pantel, 2006</marker>
<rawString>Marco Pennacchiotti and Patrick Pantel. 2006. Ontologizing semantic relations. In Proceedings of COLING-ACL 2006, pages 793–800, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<title>Longman Dictionary of Contemporary English.</title>
<date>1978</date>
<editor>Paul Proctor, editor.</editor>
<publisher>Longman Group, UK.</publisher>
<marker>1978</marker>
<rawString>Paul Proctor, editor. 1978. Longman Dictionary of Contemporary English. Longman Group, UK.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>Il Ragazzini-Biagi, 41h Edition.</booktitle>
<editor>Giuseppe Ragazzini and Adele Biagi, editors.</editor>
<location>Zanichelli, Italy.</location>
<contexts>
<context position="30719" citStr="(2006)" startWordPosition="5210" endWordPosition="5210"> al., 1998) to WordNet), thus contributing to the beneficial knowledge integration process. Following this direction, we are planning to further experiment on the mapping of FrameNet, VerbNet (Kipper et al., 2000), and other lexical resources. The graphs output by the CQC algorithm for our datasets are available from http://lcl.uniroma1.it/cqc. We are scheduling the release of a software package which includes our implementation of the CQC algorithm and allows its application to any resource for which a standard interface can be written. Finally, starting from the work of Budanitsky and Hirst (2006), we plan to experiment with the CQC algorithm when employed as a semantic similarity measure, and compare it with the most successful existing approaches. Although in this paper we focused on the disambiguation of dictionary glosses, the same approach can be applied for disambiguating collocations according to a dictionary of choice, thus providing a way to further enrich lexical resources with external knowledge. Acknowledgments The author is grateful to Ken Litkowski and the anonymous reviewers for their useful comments. He also wishes to thank Zanichelli and Macquarie for kindly making the</context>
</contexts>
<marker>2006</marker>
<rawString>Giuseppe Ragazzini and Adele Biagi, editors. 2006. Il Ragazzini-Biagi, 41h Edition. Zanichelli, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen D Richardson</author>
<author>William B Dolan</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Mindnet: acquiring and structuring semantic information from text.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>1098--1102</pages>
<location>Montreal, Quebec, Canada.</location>
<contexts>
<context position="26722" citStr="Richardson et al. (1998)" startWordPosition="4577" endWordPosition="4580">ent of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics have been presented for the disambiguation of the genus of a dictionary definition (Wilks et al., 1996; Rigau et al., 1997). More recently, a set of heuristic techniques has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtended WordNet (Harabagiu et al.,</context>
</contexts>
<marker>Richardson, Dolan, Vanderwende, 1998</marker>
<rawString>Stephen D. Richardson, William B. Dolan, and Lucy Vanderwende. 1998. Mindnet: acquiring and structuring semantic information from text. In Proceedings of COLING 1998, pages 1098–1102, Montreal, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>German Rigau</author>
</authors>
<title>Jordi Atserias, and Eneko Agirre.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL/EACL</booktitle>
<pages>48--55</pages>
<location>Madrid,</location>
<marker>Rigau, 1997</marker>
<rawString>German Rigau, Jordi Atserias, and Eneko Agirre. 1997. Combining unsupervised lexical knowledge methods for word sense disambiguation. In Proceedings of ACL/EACL 1997, pages 48–55, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter M Roget</author>
</authors>
<date>1911</date>
<booktitle>Roget’s International Thesaurus (111 edition).</booktitle>
<location>Cromwell, New York, USA.</location>
<contexts>
<context position="981" citStr="Roget, 1911" startWordPosition="141" endWordPosition="143">nses (vertices) and explicit or implicit relations in the dictionary (edges). The approach is based on the identification of edge sequences which constitute cycles in the dictionary graph (possibly with one edge reversed) and relate a source to a target word sense. Experiments are performed on the disambiguation of ambiguous words in the glosses of WordNet and two machine-readable dictionaries. 1 Introduction In the last two decades, we have witnessed an increasing availability of wide-coverage lexical knowledge resources in electronic format, most notably thesauri (such as Roget’s Thesaurus (Roget, 1911), the Macquarie Thesaurus (Bernard, 1986), etc.), machine-readable dictionaries (e.g., the Longman Dictionary of Contemporary English (Proctor, 1978)), computational lexicons (e.g. WordNet (Fellbaum, 1998)), etc. The information contained in such resources comprises (depending on their kind) sense inventories, paradigmatic relations (e.g. fleshn is a kind of plant tissuen),1 text definitions (e.g. fleshn is defined as “a soft moist part of a fruit”), usage examples, and so on. Unfortunately, not all the semantics are made explicit within lexical resources. Even WordNet, the most widespread com</context>
</contexts>
<marker>Roget, 1911</marker>
<rawString>Peter M. Roget. 1911. Roget’s International Thesaurus (111 edition). Cromwell, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1997</date>
<booktitle>New Methods in Language Processing, Studies in Computational Linguistics,</booktitle>
<pages>154--164</pages>
<editor>In Daniel Jones and Harold Somers, editors,</editor>
<publisher>UCL Press,</publisher>
<location>London, UK.</location>
<contexts>
<context position="14148" citStr="Schmid, 1997" startWordPosition="2481" endWordPosition="2482">tic relations between synsets. Its latest version (3.0) contains around 155,000 lemmas, and over 200,000 word senses; • Macquarie Concise Dictionary (Yallop, 2006), a machine-readable dictionary of (Australian) English, which includes around 50,000 lemmas and almost 120,000 word senses, for which it provides textual glosses and examples; • Ragazzini/Biagi Concise (Ragazzini and Biagi, 2006), a bilingual English-Italian dictionary, containing over 90,000 lemmas and 150,000 word senses. The dictionary provides Italian translations for each English word sense, and vice versa. We used TreeTagger (Schmid, 1997) to part-ofspeech tag the glosses in the three resources. 3.2 Algorithms Hereafter we briefly summarize the algorithms that we applied in our experiments: • CQC: we applied the CQC algorithm as described in Section 2.2; • Cycles, which applies the CQC algorithm but searches for cycles only (i.e. quasi-cycles are not collected); • An adaptation of the Lesk algorithm (Lesk, 1986), which, given a source sense s of word w and a word w&apos; occurring in the gloss of s, determines the right sense of w&apos; as that which maximizes the (normalized) overlap between each sense s&apos; of w&apos; and s: |next*(s) n next*(</context>
</contexts>
<marker>Schmid, 1997</marker>
<rawString>Helmut Schmid. 1997. Probabilistic part-of-speech tagging using decision trees. In Daniel Jones and Harold Somers, editors, New Methods in Language Processing, Studies in Computational Linguistics, pages 154–164. UCL Press, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<pages>801--808</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="28653" citStr="Snow et al., 2006" startWordPosition="4894" endWordPosition="4897"> Central Repository (Atserias et al., 2004), and a proprietary lexical knowledge base. In contrast, the approach presented in this paper performs the disambiguation of ambiguous words by exploiting only the reference dictionary itself. Furthermore, as we showed in Section 3.3, our method does not rely on WordNet, and can be applied to any lexical knowledge resource, including bilingual dictionaries. Finally, methods in the literature more focused on a specific disambiguation task include statistical methods for the attachment of hyponyms under the most likely hypernym in the WordNet taxonomy (Snow et al., 2006), structural approaches based on semantic clusters and distance metrics (Pennacchiotti and Pantel, 2006), supervised machine learning methods for the disambiguation of meronymy relations (Girju et al., 2003), etc. 6 Conclusions In this paper we presented a novel approach to disambiguate the glosses of computational lexicons and machine-readable dictionaries, with the aim of alleviating the knowledge acquisition bottleneck. The method is based on the identification of cycles and quasi-cycles, i.e. circular edge sequences (possibly with one edge reversed) relating a source to a target word sense</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of COLING-ACL 2006, pages 801–808, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucy Vanderwende</author>
</authors>
<title>The analysis of noun sequences using semantic information extracted from on-line dictionaries,</title>
<date>1996</date>
<tech>Ph.D. Thesis.</tech>
<institution>Georgetown University,</institution>
<location>Washington, USA.</location>
<contexts>
<context position="26693" citStr="Vanderwende (1996)" startWordPosition="4574" endWordPosition="4575">970s, with the development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics have been presented for the disambiguation of the genus of a dictionary definition (Wilks et al., 1996; Rigau et al., 1997). More recently, a set of heuristic techniques has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtend</context>
</contexts>
<marker>Vanderwende, 1996</marker>
<rawString>Lucy Vanderwende. 1996. The analysis of noun sequences using semantic information extracted from on-line dictionaries, Ph.D. Thesis. Georgetown University, Washington, USA.</rawString>
</citation>
<citation valid="true">
<title>Electric words: Dictionaries, computers and meanings.</title>
<date>1996</date>
<editor>Yorick Wilks, Brian Slator, and Louise Guthrie, editors.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="26693" citStr="(1996)" startWordPosition="4575" endWordPosition="4575">he development of models for the identification of taxonomies from lexical resources (Litkowski, 1978; Amsler, 1980). Subsequent works focused on the identification of genus terms (Chodorow et al., 1985) and, more in general, on the extraction of explicit information from machine-readable dictionaries (see, e.g., (Nakamura and Nagao, 1988; Ide and V´eronis, 1993)). Kozima and Furugori (1993) provide an approach to the construction of ambiguous semantic networks from glosses in the Longman Dictionary of Contemporary English (LDOCE). In this direction, it is worth citing the work of Vanderwende (1996) and Richardson et al. (1998), who describe the construction of MindNet, a lexical knowledge base obtained from the automated extraction of lexico-semantic information from two machine-readable dictionaries. As a result, weighted relation paths are produced to infer the semantic similarity between pairs of words. Several heuristics have been presented for the disambiguation of the genus of a dictionary definition (Wilks et al., 1996; Rigau et al., 1997). More recently, a set of heuristic techniques has been proposed to semantically annotate WordNet glosses, leading to the release of the eXtend</context>
</contexts>
<marker>1996</marker>
<rawString>Yorick Wilks, Brian Slator, and Louise Guthrie, editors. 1996. Electric words: Dictionaries, computers and meanings. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>The Macquarie Concise Dictionary 41h Edition. Macquarie Library Pty Ltd,</booktitle>
<editor>Colin Yallop, editor.</editor>
<location>Sydney, Australia.</location>
<contexts>
<context position="30719" citStr="(2006)" startWordPosition="5210" endWordPosition="5210"> al., 1998) to WordNet), thus contributing to the beneficial knowledge integration process. Following this direction, we are planning to further experiment on the mapping of FrameNet, VerbNet (Kipper et al., 2000), and other lexical resources. The graphs output by the CQC algorithm for our datasets are available from http://lcl.uniroma1.it/cqc. We are scheduling the release of a software package which includes our implementation of the CQC algorithm and allows its application to any resource for which a standard interface can be written. Finally, starting from the work of Budanitsky and Hirst (2006), we plan to experiment with the CQC algorithm when employed as a semantic similarity measure, and compare it with the most successful existing approaches. Although in this paper we focused on the disambiguation of dictionary glosses, the same approach can be applied for disambiguating collocations according to a dictionary of choice, thus providing a way to further enrich lexical resources with external knowledge. Acknowledgments The author is grateful to Ken Litkowski and the anonymous reviewers for their useful comments. He also wishes to thank Zanichelli and Macquarie for kindly making the</context>
</contexts>
<marker>2006</marker>
<rawString>Colin Yallop, editor. 2006. The Macquarie Concise Dictionary 41h Edition. Macquarie Library Pty Ltd, Sydney, Australia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>