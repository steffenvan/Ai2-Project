<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000377">
<title confidence="0.986677">
Detecting Experiences from Weblogs
</title>
<author confidence="0.996616">
Keun Chan Park, Yoonjae Jeong and Sung Hyon Myaeng
</author>
<affiliation confidence="0.998578">
Department of Computer Science
Korea Advanced Institute of Science and Technology
</affiliation>
<email confidence="0.991488">
{keunchan, hybris, myaeng}@kaist.ac.kr
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999003190476191">
Weblogs are a source of human activity know-
ledge comprising valuable information such as
facts, opinions and personal experiences. In
this paper, we propose a method for mining
personal experiences from a large set of web-
logs. We define experience as knowledge em-
bedded in a collection of activities or events
which an individual or group has actually un-
dergone. Based on an observation that expe-
rience-revealing sentences have a certain lin-
guistic style, we formulate the problem of de-
tecting experience as a classification task us-
ing various features including tense, mood, as-
pect, modality, experiencer, and verb classes.
We also present an activity verb lexicon con-
struction method based on theories of lexical
semantics. Our results demonstrate that the ac-
tivity verb lexicon plays a pivotal role among
selected features in the classification perfor-
mance and shows that our proposed method
outperforms the baseline significantly.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995645652174">
In traditional philosophy, human beings are
known to acquire knowledge mainly by reason-
ing and experience. Reasoning allows us to draw
a conclusion based on evidence, but people tend
to believe it firmly when they experience or ob-
serve it in the physical world. Despite the fact
that direct experiences play a crucial role in mak-
ing a firm decision and solving a problem,
people often resort to indirect experiences by
reading written materials or asking around.
Among many sources people resort to, the Web
has become the largest one for human expe-
riences, especially with the proliferation of web-
logs.
While Web documents contain various types
of information including facts, encyclopedic
knowledge, opinions, and experiences in general,
personal experiences tend to be found in weblogs
more often than other web documents like news
articles, home pages, and scientific papers. As
such, we have begun to see some research efforts
in mining experience-related attributes such as
time, location, topic, and experiencer, and their
relations from weblogs (Inui et al., 2008; Kura-
shima et al., 2009).
Mined experiences can be of practical use in
wide application areas. For example, a collection
of experiences from the people who visited a
resort area would help planning what to do and
how to do things correctly without having to
spend time sifting through a variety of resources
or rely on commercially-oriented sources.
Another example would be a public service de-
partment gleaning information about how a park
is being used at a specific location and time.
Experiences can be recorded around a frame
like “who did what, when, where, and why” al-
though opinions and emotions can be also linked.
Therefore attributes such as location, time, and
activity and their relations must be extracted by
devising a method for selecting experience-
containing sentences based on verbs that have a
particular linguistics case frame or belong to a
“do” class (Kurashima et al., 2009). However,
this kind of method may extract the following
sentences as containing an experience:
</bodyText>
<listItem confidence="0.983844">
[1] If Jason arrives on time, I’ll buy him a drink.
[2] Probably, she will laugh and dance in his funeral.
[3] Can anyone explain what is going on here?
[4] Don’t play soccer on the roads!
</listItem>
<bodyText confidence="0.998928625">
None of the sentences contain actual experiences
because hypotheses, questions, and orders have
not actually happened in the real world. For ex-
perience mining, it is important to ensure a sen-
tence mentions an event or passes a factuality
test to contain experience (Inui et al., 2008).
In this paper, we focus on the problem of de-
tecting experiences from weblogs. We formulate
</bodyText>
<page confidence="0.954457">
1464
</page>
<note confidence="0.9817145">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1464–1472,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<table confidence="0.814281666666667">
Class Examples
State like, know, believe
Activity run, swim, walk
Achievement recognize, realize
Accomplishment paint (a picture),
build (a house)
</table>
<tableCaption confidence="0.999283">
Table 1. Vendler class examples
</tableCaption>
<bodyText confidence="0.998687176470588">
the problem as a classification task using various
linguistic features including tense, mood, aspect,
modality, experiencer, and verb classes.
Based on our observation that experience-
revealing sentences tend to have a certain lin-
guistic style (Jijkoun et al., 2010), we investigate
on the roles of various features. The ability to
detect experience-revealing sentences should be
a precursor for ensuring the quality of extracting
various elements of actual experiences.
Another issue addressed in this paper is au-
tomatic construction of a lexicon for verbs re-
lated to activities and events. While there have
been well-known studies about classifying verbs
based on aspectual features (Vendler, 1967),
thematic roles and selectional restrictions (Fill-
more, 1968; Somers, 1987; Kipper et al., 2008),
valence alternations and intuitions (Levin, 1993)
and conceptual structures (Fillmore and Baker,
2001), we found that none of the existing lexical
resources such as Framenet (Baker et al., 2003)
and Verbnet (Kipper et al., 2008) are sufficient
for identifying experience-revealing verbs. We
introduce a method for constructing an activi-
ty/event verb lexicon based on Vendler’s theory
and statistics obtained by utilizing a web search
engine.
We define experience as knowledge embed-
ded in a collection of activities or events which
an individual or group has actually undergone1. It
can be subjective as in opinions as well as objec-
tive, but our focus in this article lies in objective
knowledge. The following sentences contain ob-
jective experiences:
</bodyText>
<listItem confidence="0.854060375">
[5] I ran with my wife 3 times a week until we
moved to Washington, D.C.
[6] Jane and I hopped on a bus into the city centre.
[7] We went to a restaurant near the central park.
Whereas sentences like the following contain
subjective knowledge:
[8] I like your new style. You’re beautiful!
[9] The food was great, the interior too.
</listItem>
<footnote confidence="0.829174666666667">
Subject knowledge has been studied extensively
for various functions such as identification, po-
1 http://en.wikipedia.org/wiki/Experience_(disambiguation)
</footnote>
<bodyText confidence="0.99864465">
larity detection, and holder extraction under the
names of opinion mining and sentiment analysis
(Pang and Lee, 2008).
In summary, our contribution lies in three as-
pects: 1) conception of experience detection,
which is a precursor for experience mining, and
specific related tasks that can be tackled with a
high performance machine learning based solu-
tion; 2) examination and identification of salient
linguistic features for experience detection; 3) a
novel lexicon construction method with identifi-
cation of key features to be used for verb classi-
fication.
The remainder of the paper is organized as fol-
lows. Section 2 presents our lexicon construction
method with experiments. Section 3 describes
the experience detection method, including expe-
rimental setup, evaluation, and results. In Section
4, we discuss related work, before we close with
conclusion and future work in Section 5.
</bodyText>
<sectionHeader confidence="0.986068" genericHeader="method">
2 Lexicon Construction
</sectionHeader>
<bodyText confidence="0.99997675">
Since our definition of experience is based on
activities and events, it is critical to determine
whether a sentence contains a predicate describ-
ing an activity or an event. To this end, it is quite
conceivable that a lexicon containing activity /
event verbs would play a key role. Given that
our ultimate goal is to extract experiences from a
large amount of weblogs, we opt for increased
coverage by automatically constructing a lexicon
rather than high precision obtainable by manual-
ly crafted lexicon.
Based on the theory of Vendler (1967), we
classify a given verb or a verb phrase into one of
the two categories: activity and state. We consid-
er all the verbs and verb phrases in WordNet
(Fellbaum, 1998) which is the largest electronic
lexical database. In addition to the linguistic
schemata features based on Vendler’s theory, we
used thematic role features and an external
knowledge feature.
</bodyText>
<subsectionHeader confidence="0.982764">
2.1 Background
</subsectionHeader>
<bodyText confidence="0.990931555555556">
Vendler (1967) proposes that verb meanings can
be categorized into four basic classes, states, ac-
tivities, achievements, and accomplishments, de-
pending on interactions between the verbs and
their aspectual and temporal modifiers. Table 1
shows some examples for the classes.
Vendler (1967) and Dowty (1979) introduce
linguistic schemata that serve as evidence for the
classes.
</bodyText>
<page confidence="0.985013">
1465
</page>
<table confidence="0.930592">
Linguistic bs prs prp pts ptp
Schemata
No schema ■ ■ ■ ■ ■
Progressive ■
Force ■
Persuade ■
Stop ■
For ■ ■ ■ ■ ■
Carefully ■ ■ ■ ■ ■
</table>
<tableCaption confidence="0.99279">
Table 2. Query matrix. The “■” indicates that the
</tableCaption>
<bodyText confidence="0.9809727">
query is applied. No Schema indicates that no
schema is applied when the word itself is a query.
bs, prs, prp, pts, ptp correspond to base form,
present simple (3rd person singular), present par-
ticiple, past simple and past participle, respect-
fully.
Below are the six schemata we chose because
they can be tested automatically: progressive,
force, persuade, stop, for, and carefully (An aste-
risk denotes that the statement is awkward).
</bodyText>
<listItem confidence="0.998203">
• States cannot occur in progressive tense:
John is running.
John is liking.*
• States cannot occur as complements of
</listItem>
<bodyText confidence="0.85961175">
force and persuade:
John forced harry to run.
John forced harry to know.*
John persuaded harry to know.*
</bodyText>
<listItem confidence="0.9935765">
• Achievements cannot occur as comple-
ments of stop:
</listItem>
<bodyText confidence="0.755449">
John stopped running.
John stopped realizing.*
</bodyText>
<listItem confidence="0.9999035">
• Achievements cannot occur with time ad-
verbial for:
</listItem>
<bodyText confidence="0.8914235">
John ran for an hour.
John realized for an hour.*
</bodyText>
<listItem confidence="0.999744">
• State and achievement cannot occur with
adverb carefully:
</listItem>
<subsectionHeader confidence="0.8376265">
John runs carefully.
John knows carefully.*
</subsectionHeader>
<bodyText confidence="0.999990277777778">
The schemata are not perfect because verbs can
shift classes due to various contextual factors
such as arguments and senses. However, a verb
certainly has its fundamental class that is its most
natural category at least in its dominant use.
The four classes can further be grouped into
two genuses: a genus of processes going on in
time and the other that refers to non-processes.
Activity and accomplishment belong to the for-
mer whereas state and achievement belong to the
latter. As can be seen in table 1, states are rather
immanent operations and achievements are those
occur in a single moment or operations related to
perception level. On the other hand, activity and
accomplishment are processes (transeunt opera-
tions) in traditional philosophy. We henceforth
call the first genus activity and the latter state.
Our aim is to classify verbs into the two genuses.
</bodyText>
<subsectionHeader confidence="0.982751">
2.2 Features based on Linguistic Schemata
</subsectionHeader>
<bodyText confidence="0.999967511111111">
We developed a relatively simple computational
testing method for the schemata. Assuming that
an awkward expression like, “John is liking
something” won’t occur frequently, for example,
we generated a co-occurrence based test for the
first linguistic schema using the Web as a corpus.
By issuing a search query, ((be OR am OR is OR
was OR were OR been) and ? ing) where ‘?’
represents the verb at hand, to a search engine,
we can get an estimate about how the verb is
likely to belong to state. A test can be generated
for each of the schemata in a similar way.
For completeness, we considered all the verb
forms (i.e., 3rd person singular present, present
participle, simple past, past participle) available.
However, some of the patterns cannot be applied
to some forms. For example, other forms except
the base form cannot come as a complement of
force (e.g., force to runs.*). Therefore, we
created a query matrix which represents all query
patterns we have applied, in table 2.
Based on the query matrix in table 2, we is-
sued queries for all the verbs and verb phrases
from WordNet to a search engine. We used the
Google news archive search for two reasons.
First, since news articles are written rather for-
mally compared to weblogs and other web pages,
the statistics obtained for a test would be more
reliable. Second, Google provides an advanced
option to retrieve snippets containing the query
word. Normally, a snippet is composed of 3~5
sentences.
The basic statistics we consider are hit count,
candidate sentence count and correct sentence
count which we use the notations Hij(w), Sij(w),
and Cij(w), respectfully, where w is a word, i the
linguistic schema and j the verb form from the
query matrix in table 2. Hij(w) was directly ga-
thered from the Google search engine. Sij(w) is
the number of sentences containing the word w
in the search result snippets. Cij(w) is the number
of correct sentences matching the query pattern
among the candidate sentences. For example, the
progressive schema for a verb “build” can re-
trieve the following sentences.
</bodyText>
<page confidence="0.814988">
[10] ..., New-York, is building one of the largest ...
[11] Is building an artifact?
1466
</page>
<bodyText confidence="0.999874071428571">
“Building” in the first example is a progressive
verb, but the one in second is a noun, which does
not satisfy the linguistic schema. For a POS and
grammatical check of a candidate sentence, we
used the Stanford POS tagger (Toutanova et al.,
2003) and Stanford dependency parser (Klein
and Manning, 2003).
For each linguistic schema, we derived three
features: Absolute hit ratio, Relative hit ratio and
Valid ratio for which we use the notations Ai(w),
Ri(w) and Vi(w), respectfully, where w is a word
and i a linguistic schema. The index j for summa-
tions represents the j-th verb form. They are
computed as follows.
</bodyText>
<equation confidence="0.991233666666667">
(w) = ∑j Cij (w)
∑ S w
j ij ( )
</equation>
<bodyText confidence="0.999977">
Absolute hit ratio is computes the extent to
which the target word w occurs with the i-th
schema over all occurrences of the schema. The
denominator is the hit count of wild card “*”
matching any single word with the schema pat-
tern from Google (e.g., H1(*), the progressive
test hit count is 3.82 X 108). Relative hit ratio
computes the extent to which the target word w
occurs with the i-th schema over all occurrences
of the word. The denominator is the sum of all
verb forms. Valid ratio means the fraction of cor-
rect sentences among candidate sentences. The
weight of a linguistic schema increases as the
valid ratio gets high. With the three different
ratios, Ai(w), Ri(w) and Vi(w), for each test, we
can generate a total of 18 features.
</bodyText>
<subsectionHeader confidence="0.996312">
2.3 Features based on case frames
</subsectionHeader>
<bodyText confidence="0.999585363636364">
Since the hit count via Google API sometimes
returns unreliable results (e.g., when the query
becomes too long in case of long verb phrases),
we also consider additional features. While our
initial observation indicated that the existing lex-
ical resources would not be sufficient for our
goal, it occurred to us that the linguistic theory
behind them would be worth exploring as gene-
rating additional features for categorizing verbs
for the two classes. Consider the following ex-
amples:
</bodyText>
<listItem confidence="0.4933355">
[12] John(D) believed(V) the story(O).
[13] John(A) hit(V) him(O) with a bat(I).
</listItem>
<bodyText confidence="0.99987325">
The subject of a state verb is dative (D) as in [12]
whereas the subject for an action verb takes the
agent (A) role. In addition, a verb with the in-
strument (I) role tends to be an action verb. From
these observations, we can use the distribution of
cases (thematic roles) for a verb in a corpus. Ac-
tivity verbs are expected to have high frequency
of agent and instrument roles than state verbs.
Although a verb may have more than one case
frame, it is possible to determine which thematic
roles used more dominantly.
We utilize two major resources of lexical se-
mantics, Verbnet (Kipper et al., 2008) based on
the theory of Levin (1993), and Framenet (Baker
et al., 2003), which is based on Fillmore (1968).
Levin (1993) demonstrated that syntactic alterna-
tions can be the basis for groupings of verbs se-
mantically and accord reasonably well with lin-
guistic intuitions. Verbnet provides 274 verb
classes with 23 thematic roles covering 3,769
verbs based on their alternation behaviors with
thematic roles annotated. Framenet defines 978
semantic frames with 7,124 unique semantic
roles, covering 11,583 words including verbs,
nouns, adverbs, etc.
Using Verbnet alone does not suit our needs
because it has a relatively small number of ex-
ample sentences. Framenet contains a much larg-
er number of examples but the vast number of
semantic roles presents a problem. In order to get
meaningful distributions for a manageable num-
ber of thematic roles, we used Semlink (Loper et
al., 2007) that provides a mapping between Fra-
menet and Verbnet and uses a total of 23 themat-
ic roles of Verbnet for the annotated corpora of
the two resources. By the mapping, we obtained
distributions of the thematic roles for 2,868
unique verbs that exist in both of the resources.
For example, the verb “construct” has high fre-
quencies with agent, material and product roles.
</bodyText>
<subsectionHeader confidence="0.981371">
2.4 Features based on how-to instructions
</subsectionHeader>
<bodyText confidence="0.999857363636363">
Ryu et al. (2010) presented a method for extract-
ing action steps for how-to goals from eHow2 a
website containing a large number of how-to in-
structions. The authors attempted to extract ac-
tions comprising a verb and some ingredients
like an object entity from the documents based
on syntactic patterns and a CRF based model.
Since each extracted action has its probability,
we can use the value as a feature for state / activ-
ity verb classification. However, a verb may ap-
pear in different contexts and can have multiple
</bodyText>
<equation confidence="0.679021076923077">
2 http://www.ehow.com
∑ H w
j ij ( )
( )
w = H ( )
*
i
(w)= ∑jHij(w)
Ai
Ri
(1)
∑jHNoScheme(w)
Vi
</equation>
<page confidence="0.916345">
1467
</page>
<table confidence="0.999830333333333">
Feature ME SVM
Prec. Recall Prec. Recall
All 43 68% 50% 83% 75%
Top 30 72% 52% 83% 75%
Top 20 83% 76% 85% 77%
Top 10 89% 88% 91% 78%
</table>
<tableCaption confidence="0.93229">
Table 3. Classification Performance
</tableCaption>
<table confidence="0.997929333333333">
Class Examples
Activity act, battle, build, carry, chase,
drive, hike, jump, kick, sky
dive, tap dance, walk, ...
State admire, believe, know, like,
love, ...
</table>
<tableCaption confidence="0.999367">
Table 4. Classified Examples
</tableCaption>
<bodyText confidence="0.627906">
probability values. To generate a single value for
a verb, we combine multiple probability values
using the following sigmoid function:
</bodyText>
<equation confidence="0.99661">
1
t
+ e − (2)
t =Ed∈DwPd
</equation>
<bodyText confidence="0.99983675">
Evidence of a word w being an action in eHow is
denoted as E(w) where variable t is the sum of
individual action probability values in Dw the set
of documents from which the word w has been
extracted as an action. The higher probability a
word gets and the more frequent the word has
been extracted as an action, the more evidence
we get.
</bodyText>
<subsectionHeader confidence="0.907539">
2.5 Classification
</subsectionHeader>
<bodyText confidence="0.999983925925926">
For training, we selected 80 seed verbs from
Dowty’s list (1979) which are representative
verbs for each Vendler (1967) class. The selec-
tion was based on the lack of word sense ambi-
guity.
One of our classifiers is based on Maximum
Entropy (ME) models that implement the intui-
tion that the best model will be the one that is
consistent with the set of constraints imposed by
the evidence, but otherwise is as uniform as
possible (Berger et al., 1996). ME models are
widely used in natural language processing tasks
for its flexibility to incorporate a diverse range of
features. The other one is based on Support Vec-
tor Machine (Chang and Lin, 2001) which is the
state-of-the-art algorithm for many classification
tasks. We used RBF kernel with the default set-
tings (Hsu et al., 2009) because it is been known
to show moderate performance using multiple
feature compositions.
The features we considered are a total of 42
real values: 18 from linguistic schemata, 23 the-
matic role distributions, and one from eHow. In
order to examine which features are discrimina-
tive for the classification, we used two well
known feature selection methods, Chi-square and
information gain.
</bodyText>
<sectionHeader confidence="0.592822" genericHeader="method">
2.6 Results
</sectionHeader>
<bodyText confidence="0.999960883720931">
Table 3 shows the classification performance
values for different feature selection methods.
The evaluation was done on the training data
with 10-fold cross validation.
Note that the precision and recall are macro-
averaged values across the two classes, activity
and state. The most discriminative features were
absolute ratio and relative ratio in conjunction
with the force, stop, progressive, and persuade
schemata, the role distribution of experiencer,
and the eHow evidence.
It is noteworthy that eHow evidence and the
distribution of experiencer got into the top 10.
Other thematic roles did not perform well be-
cause of the data sparseness. Only a few roles
(e.g., experience, agent, topic, location) among
the 23 had frequency values other than 0 for
many verbs. Data sparseness affected the linguis-
tic schemata as well. Many of the verbs had zero
hit counts for the for and carefully schemata. It is
also interesting that the validity ratio Vi(w) was
not shown to be a good feature-generating statis-
tic.
We finally trained our model with the top 10
features and classified all WordNet verbs and
verb phrases. For actual construction of the lex-
icon, 11,416 verbs and verb phrases were classi-
fied into the two classes roughly equally. We
randomly sampled 200 items and examined how
accurately the classification was done. A total of
164 items were correctly classified, resulting in
82% accuracy. Some examples from the classifi-
cation are shown in table 4.
A further analysis of the results show that
most of the errors occurred with domain-specific
verbs (e.g., ablactate, alkalify, and transaminate
in chemistry) and multi-word verb phrases (e.g.,
turn a nice dime; keep one’s shoulder to the
wheel). Since many features are computed based
on Web resources, rare verbs cannot be classified
correctly when their hit rations are very low. The
domain-specific words rarely appear in Framenet
or e-how, either.
</bodyText>
<sectionHeader confidence="0.99821" genericHeader="method">
3 Experience Detection
</sectionHeader>
<bodyText confidence="0.999725">
As mentioned earlier, experience-revealing sen-
tences tend to have a certain linguistic style.
</bodyText>
<equation confidence="0.979392333333333">
E (w ) = 1
( )
w
</equation>
<page confidence="0.964227">
1468
</page>
<bodyText confidence="0.999990571428572">
Having converted the problem of experience de-
tection for sentences to a classification task, we
focus on the extent to which various linguistic
features contribute to the performance of the bi-
nary classifier for sentences. We also explain the
experimental setting for evaluation, including the
classifier and the test corpus.
</bodyText>
<subsectionHeader confidence="0.998103">
3.1 Linguistic features
</subsectionHeader>
<bodyText confidence="0.995675315789474">
In addition to the verb class feature available in
the verb lexicon constructed automatically, we
used tense, mood, aspect, modality, and expe-
riencer features.
Verb class: The feature comes directly from
the lexicon since a verb has been classified into a
state or activity verb. The predicate part of the
sentence to be classified for experience is looked
up in the lexicon without sense disambiguation.
Tense: The tense of a sentence is important
since an experience-revealing sentence tends to
use past and present tense. Future tenses are not
experiences in most cases. We use POS tagging
(Toutanova et al., 2003) for tense determination,
but since the Penn tagset provides no future
tenses, they are determined by exploiting modal
verbs such as “will” and future expressions such
“going to”.
Mood: It is one of distinctive forms that are
used to signal the modal status of a sentence. We
consider three mood categories: indicative, im-
perative and subjunctive. We determine the
mood of a sentence by a small set of heuristic
rules using the order of POS occurrences and
punctuation marks.
Aspect: It defines the temporal flow of a verb
in the activity or state. Two categories are used:
progressive and perfective. This feature is deter-
mined by the POS of the predicate in a sentence.
Modality: In linguistics, modals are expres-
sions broadly associated with notions of possibil-
ity. While modality can be classified at a fine
level (e.g., epistemic and deontic), we simply
determine whether or not a sentence includes a
modal marker that is involved in the main predi-
cate of the sentence. In other words, this binary
feature is determined based on the existence of a
model verb like “can”, “shall”, “must”, and “may”
or a phrase like “have to” or “need to”. The de-
pendency parser is used to ensure a modal mark-
er is indeed associated with the main predicate.
Experiencer: A sentence can or cannot be
treated as containing an experience depending on
the subject or experiencer of the verb (note that
this is different from the experiencer role in a
case frame). Consider the following sentences:
[14] The stranger messed up the entire garden.
[15] His presence messed up the whole situation.
The first sentence is considered an experience
since the subject is a person. However, the
second sentence with the same verb is not, be-
cause the subject is a non-animate abstract con-
cept. That is, a non-animate noun can hardly
constitute an experience. In order to make a dis-
tinction, we use the dependency parser and a
named-entity recognizer (Finkel et al., 2005) that
can recognize person pronouns and person names.
</bodyText>
<subsectionHeader confidence="0.996638">
3.2 Classification
</subsectionHeader>
<bodyText confidence="0.999974961538462">
To train our classifier, we first crawled weblogs
from Wordpress3, one of the most popular blog
sites in use today. Worpress provides an interface
to search blog posts with queries. In selecting
experience-containing blog pots, we used loca-
tion names such as Central Park, SOHO, Seoul
and general place names such as airport, subway
station, and restaurant because blog posts with
some places are expected to describe experiences
rather than facts or thoughts.
We crawled 6,000 blog posts. After deleting
non-English and multi-media blog posts for
which we could not obtain any meaningful text
data, the number became 5,326. We randomly
sampled 1,000 sentences4 and asked three anno-
tators to judge whether or not individual sen-
tences are considered containing an experience
based on our definition. For maximum accuracy,
we decided to use only those sentences all the
three annotators agreed, resulting in a total of
568 sentences.
While we tested several classifiers, we chose
to use two different classifiers based on SVM
and Logistic Regression for the final experimen-
tal results because they showed the best perfor-
mance.
</bodyText>
<subsectionHeader confidence="0.930118">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.999877111111111">
For comparison purposes, we take the method of
Kurashima et al. (2005) as our baseline because
the method was used in subsequent studies (Ku-
rashima et al., 2006; Kurashima et al., 2009)
where experience attributes are extracted. We
briefly describe the method and present how we
implemented it.
The method first extracts all verbs and their
dependent phrasal unit from candidate sentences.
</bodyText>
<footnote confidence="0.99575875">
3 http://wordpress.com
4 It was due to the limited human resources, but when we
increased the number at a later stage, the performance in-
crease was almost negligible.
</footnote>
<page confidence="0.964908">
1469
</page>
<table confidence="0.999914909090909">
Feature Logistic SVM
Regression
Prec. Recall Prec. Recall
Baseline 32.0% 55.1% 25.3% 44.4%
Lexicon 77.5% 76.0% 77.5% 76.0%
Tense 75.1% 75.1% 75.1% 75.1%
Mood 75.8% 60.3% 75.8% 60.3%
Aspect 26.7% 51.7% 26.7% 51.7%
Modality 79.8% 70.5% 79.8% 70.5%
Experiencer 54.3% 53.5% 54.3% 53.5%
All included 91.9% 91.7% 91.7% 91.4%
</table>
<tableCaption confidence="0.999213">
Table 5. Experience Detection Performance
</tableCaption>
<bodyText confidence="0.999971871794872">
The candidate goes through three filters before it
is treated as experience-containing sentence.
First, the candidates that do not have an objective
case (Fillmore, 1968) are eliminated because
their definition of experience as “action + object”.
This was done by identifying the object-
indicating particle (case marker) in Japanese.
Next, the candidates belonging to “become” and
“be” statements based on Japanese verb types are
filtered out. Finally, the candidate sentences in-
cluding a verb that indicates a movement are
eliminated because the main interest was to iden-
tify an activity in a place.
Although their definition of experience is
somewhat different from ours (i.e., “action + ob-
ject”), they used the method to generate candi-
date sentences from which various experience
attributes are extracted. From this perspective,
the method functioned like our experience detec-
tion. Put differently, the definition and the me-
thod by which it is determined were much cruder
than the one we are using, which seems close to
our general understanding.5
The three filtering steps were implemented as
follows. We used the dependency parser for ex-
tracting objective cases using the direct object
relation. The second step, however, could not be
applied because there is no grammatical distinc-
tion among “do, be, become” statements in Eng-
lish. We had to alter this step by adopting the
approach of Inui et al. (2008). The authors pro-
pose a lexicon of experience expression by col-
lecting hyponyms from a hierarchically struc-
tured dictionary. We collected all hyponyms of
words “do” and “act”, from WordNet (Fellbaum,
1998). Lastly, we removed all the verbs that are
under the hierarchy of “move” from WordNet.
We not only compared our results with the
baseline in terms of precision and recall but also
</bodyText>
<footnote confidence="0.966285">
5 This is based on our observation that the three annotators
found their task of identifying experience sentences not
difficulty, resulting in a high degree of agreements.
</footnote>
<table confidence="0.9503665">
Feature Logistic SVM
Regression
Prec. Recall Prec. Recall
Baseline 32.0% 55.1% 25.3% 44.4%
-Lexicon 84.6% 84.6% 83.1% 81.2%
-Tense 87.3% 87.1% 86.8% 86.5%
-Mood 89.5% 89.5% 89.3% 89.2%
-Aspect 90.8% 90.5% 89.0% 88.6%
-Modality 89.5% 89.5% 82.8% 82.8%
-Experiencer 91.5% 91.4% 91.1% 90.8%
All included 91.9% 91.7% 91.7% 91.4%
Table 6. Experience Detection Performance
without Individual Features
evaluated individual features for their importance
</table>
<bodyText confidence="0.999520763157895">
in experience detection (classification). The
evaluation was conducted with 10-fold cross va-
lidation. The results are shown in table 5.
The performance, especially precision, of the
baseline is much lower than those of the others.
The method devised for Japanese doesn’t seem
suitable for English. It seems that the linguistic
styles shown in experience expressions are dif-
ferent from each other. In addition, the lexicon
we constructed for the baseline (i.e., using the
WordNet) contains more errors than our activity
lexicon for activity verbs. Some hyponyms of an
activity verb may not be activity verbs. (e.g.,
“appear” is a hyponym of “do”).
There is almost no difference between the Lo-
gistic Regression and SVM classifiers for our
methods although SVM was inferior for the
baseline. The performance for the best case with
all the features included is very promising,
closed to 92% precision and recall. Among the
features, the lexicon, i.e., verb classes, gave the
best result when each is used alone, followed by
modality, tense, and mood. Aspect was the worst
but close to the baseline. This result is very en-
couraging for the automatic lexicon construction
work because the lexicon plays a pivotal role in
the overall performance.
In order to see the effect of including individ-
ual features in the feature set, precision and re-
call were measured after eliminating a particular
feature from the full set. The results are shown in
table 6. Although the absence of the lexicon fea-
ture hurt the performance most badly, still the
performance was reasonably high (roughly 84 %
in precision and recall for the Logistic Regres-
sion case). Similar to table 5, the aspect and ex-
perience features were the least contributors as
the performance drops are almost negligible.
</bodyText>
<page confidence="0.988829">
1470
</page>
<sectionHeader confidence="0.999969" genericHeader="evaluation">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999968979591837">
Experience mining in its entirety is a relatively
new area where various natural language
processing and text mining techniques can play a
significant role. While opinion mining or senti-
ment analysis, which can be considered an im-
portant part of experience mining, has been stu-
died quite extensively (see Pang and Lee’s excel-
lent survey (2008)), another sub-area, factuality
analysis, begins to gain some popularity (Inui et
al., 2008; Saurí, 2008). Very few studies have
focused explicitly on extracting various entities
that constitute experiences (Kurashima et al.,
2009) or detecting experience-containing parts of
text although many NLP research areas such as
named entity recognition and verb classification
are strongly related. The previous work on expe-
rience detection relies on a handcrafted lexicon.
There have been a number of studies for verb
classification (Fillmore, 1968; Vendler, 1967;
Somers, 1982; Levin, 1993; Fillmore and Baker,
2001; Kipper et al., 2008) that are essential for
construction of an activity verb lexicon, which in
turn is important for experience detection. Most
similar to our work was done by Siegel and
McKeown (2000), who attempted to categorize
verbs into state or event classes based on 14 tests
similar to those of Vendler’s. They attempted to
compute co-occurrence statistics from a corpus.
The event class, however, includes activity, ac-
complishment, and achievement. Similarly, Za-
crone and Lenci (2008) attempted to categorize
verbs in Italian into the four Vendler classes us-
ing the Vendler tests by using a tagged corpus.
They focused on existence of arguments such as
subject and object that should co-occur with the
linguistic features in the tests.
The main difference between the previous
work and ours lies in the goal and scope of the
work. Since our work is specifically geared to-
ward domain-independent experience detection,
we attempted to maximize the coverage by using
all the verbs in WordNet, as opposed to the verbs
appearing in a particular domain-specific corpus
(e.g., medicine domain) as done in the previous
work. Another difference is that while we are not
limited to a particular domain, we did not use
extensive human-annotated corpus other than
using the 80 seed verbs and existing lexical re-
sources.
</bodyText>
<sectionHeader confidence="0.997161" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999995526315789">
We defined experience detection as an essential
task for experience mining, which is restated as
determining whether individual sentences con-
tain experience or not. Viewing the task as a
classification problem, we focused on identifica-
tion and examination of various linguistic fea-
tures such as verb class, tense, aspect, mood,
modality, and experience, all of which were
computed automatically. For verb classes, in par-
ticular, we devised a method for classifying all
the verbs and verb phrases in WordNet into the
activity and state classes. The experimental re-
sults show that verb and verb phrase classifica-
tion method is reasonably accurate with 91%
precision and 78% recall with manually con-
structed gold standard consisting of 80 verbs and
82% accuracy for a random sample of all the
WordNet entries. For experience detection, the
performance was very promising, closed to 92%
in precision and recall when all the features were
used. Among the features, the verb classes, or the
lexicon we constructed, contributed the most.
In order to increase the coverage even further
and reduce the errors in lexicon construction, i.e.,
verb classification, caused by data sparseness, we
need to devise a different method, perhaps using
domain specific resources.
Given that experience mining is a relatively
new research area, there are many areas to ex-
plore. In addition to refinements of our work, our
next step is to develop a method for representing
and extracting actual experiences from expe-
rience-revealing sentences. Furthermore, consi-
dering that only 13% of the blog data we
processed contain experiences, an interesting
extension is to apply the methodology to extract
other types of knowledge such as facts, which
are not necessarily experiences.
</bodyText>
<sectionHeader confidence="0.998973" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.992370333333333">
This research was supported by the IT R&amp;D pro-
gram of MKE/KEIT under grant KI001877 [Lo-
cational/Societal Relation-Aware Social Media
Service Technology], and by the MKE (The
Ministry of Knowledge Economy), Korea, under
the ITRC (Information Technology Research
Center) support program supervised by the NIPA
(National IT Industry Promotion Agency) [NI-
PA-2010-C1090-1011-0008].
</bodyText>
<sectionHeader confidence="0.994719" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.996694">
Eiji Aramaki, Yasuhide Miura, Masatsugu Tonoike,
Tomoko Ohkuma, Hiroshi Mashuichi, and Kazuhi-
ko Ohe. 2009. TEXT2TABLE: Medical Text
Summarization System based on Named Entity
</reference>
<page confidence="0.825907">
1471
</page>
<reference confidence="0.999828257731959">
Recognition and Modality Identification. In Pro-
ceedings of the Workshop on BioNLP.
Collin F. Baker, Charles J. Fillmore, and Beau Cronin.
2003. The Structure of the Framenet Database. In-
ternational Journal of Lexicography.
Adam L. Berger, Stephen A. Della Pietra, and Vin-
cent J. Della Pietra. 1996. A Mximum Entropy
Approach to Natural Language Processing. Com-
putational Linguistics.
Chih-Chung Chang and Chih-Jen Lin. 2001.
LIBSVM : a Library for Support Vector Machines.
http://www.csie.ntu.edu.tw/~cjlin/libsvm.
David R. Dowty. 1979. Word meaning and Montague
Grammar. Reidel, Dordrecht.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. MIT Press.
Charles J. Fillmore. 1968. The Case for Case. In Bach
and Harms (Ed.): Universals in Linguistic Theory.
Charles J. Fillmore and Collin F. Baker. 2001. Frame
Semantics for Text Understanding. In Proceedings
of WordNet and Other Lexical Resources Work-
shop, NAACL.
Jenny R. Finkel, Trond Grenager, and Christopher D.
Manning. 2005. Incorporating Non-local Informa-
tion into Information Extraction Systems by Gibbs
Sampling. In Proceedings of ACL.
Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin.
2009. A Practical Guide to Support Vector Classi-
fication. http://www.csie.ntu.edu.tw/~cjlin/libsvm.
Kentaro Inui, Shuya Abe, Kazuo Hara, Hiraku Morita,
Chitose Sao, Megumi Eguchi, Asuka Sumida, Koji
Murakami, and Suguru Matsuyoshi. 2008. Expe-
rience Mining: Building a Large-Scale Database of
Personal Experiences and Opinions from Web
Documents. In Proceedings of the International
Conference on Web Intelligence.
Valentin Jijkoun, Maarten de Rijke, Wouter Weer-
kamp, Paul Ackermans and Gijs Geleijnse. 2010.
Mining User Experiences from Online Forums: An
Exploration. In Proceedings of NAACL HLT Work-
shop on Computational Linguistics in a World of
Social Media.
Karin Kipper, Anna Korhonen, Neville Ryant, and
Martha Palmer. 2008. A Large-scale Classification
of English Verbs. Language Resources and Evalu-
ation Journal.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In Proceedings of ACL.
Takeshi Kurashima, Ko Fujimura, and Hidenori Oku-
da. 2009. Discovering Association Rules on Expe-
riences from Large-Scale Blog Entries. In Proceed-
ings of ECIR.
Takeshi Kurashima, Taro Tezuka, and Katsumi Tana-
ka. 2005. Blog Map of Experiences: Extracting and
Geographically Mapping Visitor Experiences from
Urban Blogs. In Proceedings of WISE.
Takeshi Kurashima, Taro Tezuka, and Katsumi Tana-
ka. 2006. Mining and Visualizing Local Expe-
riences from Blog Entries. In Proceedings of
DEXA.
John Lafferty, Andew McCallum, and Fernando Pe-
reira. 2001. Conditional Random Fields: Probabil-
istic Models for Segmenting and Labeling Se-
quence Data. In Proceedings of ICML.
Beth Levin. 1993. English verb classes and alterna-
tions: A Preliminary investigation. University of
Chicago press.
Edward Loper, Szu-ting Yi, and Martha Palmer. 2007.
Combining Lexical Resources: Mapping Between
PropBank and Verbnet. In Proceedings of the In-
ternational Workshop on Computational Linguis-
tics.
Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis, Foundations and Trends in In-
formation Retrieval.
Jihee Ryu, Yuchul Jung, Kyung-min Kim and Sung H.
Myaeng. 2010. Automatic Extraction of Human
Activity Knowledge from Method-Describing Web
Articles. In Proceedings of the 1st Workshop on Au-
tomated Knowledge Base Construction.
Roser Saurí. 2008. A Factuality Profiler for Eventuali-
ties in Text. PhD thesis, Brandeis University.
Eric V. Siegel and Kathleen R. McKeown. 2000.
Learing Methods to Combine Linguistic Indicators:
Improving Aspectual Classification and Revealing
Linguistic Insights. In Computational Linguistics.
Harold L. Somers. 1987. Valency and Case in Com-
putational Linguistics. Edinburgh University Press.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-Rich Part-
of-Speech Tagging with a Cyclic Dependency
Network. In Proceedings of HLT-NAACL.
Zeno Vendler. 1967. Linguistics in Philosophy. Cor-
nell University Press.
Alessandra Zarcone and Alessandro Lenci. 2008.
Computational Models of Event Type Classifica-
tion in Context. In Proceedings of LREC.
</reference>
<page confidence="0.994125">
1472
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.670331">
<title confidence="0.99996">Detecting Experiences from Weblogs</title>
<author confidence="0.997203">Keun Chan Park</author>
<author confidence="0.997203">Yoonjae Jeong</author>
<author confidence="0.997203">Sung Hyon Myaeng</author>
<affiliation confidence="0.865806">Department of Computer Science Korea Advanced Institute of Science and Technology</affiliation>
<email confidence="0.936577">keunchan@kaist.ac.kr</email>
<email confidence="0.936577">hybris@kaist.ac.kr</email>
<email confidence="0.936577">myaeng@kaist.ac.kr</email>
<abstract confidence="0.999720454545454">Weblogs are a source of human activity knowledge comprising valuable information such as facts, opinions and personal experiences. In this paper, we propose a method for mining personal experiences from a large set of weblogs. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actually undergone. Based on an observation that experience-revealing sentences have a certain linguistic style, we formulate the problem of detecting experience as a classification task using various features including tense, mood, aspect, modality, experiencer, and verb classes. We also present an activity verb lexicon construction method based on theories of lexical semantics. Our results demonstrate that the activity verb lexicon plays a pivotal role among selected features in the classification performance and shows that our proposed method outperforms the baseline significantly.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eiji Aramaki</author>
</authors>
<title>Yasuhide Miura, Masatsugu Tonoike, Tomoko Ohkuma, Hiroshi Mashuichi, and Kazuhiko Ohe.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on BioNLP.</booktitle>
<marker>Aramaki, 2009</marker>
<rawString>Eiji Aramaki, Yasuhide Miura, Masatsugu Tonoike, Tomoko Ohkuma, Hiroshi Mashuichi, and Kazuhiko Ohe. 2009. TEXT2TABLE: Medical Text Summarization System based on Named Entity Recognition and Modality Identification. In Proceedings of the Workshop on BioNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>Beau Cronin</author>
</authors>
<title>The Structure of the Framenet Database.</title>
<date>2003</date>
<journal>International Journal of Lexicography.</journal>
<contexts>
<context position="5162" citStr="Baker et al., 2003" startWordPosition="803" endWordPosition="806">ld be a precursor for ensuring the quality of extracting various elements of actual experiences. Another issue addressed in this paper is automatic construction of a lexicon for verbs related to activities and events. While there have been well-known studies about classifying verbs based on aspectual features (Vendler, 1967), thematic roles and selectional restrictions (Fillmore, 1968; Somers, 1987; Kipper et al., 2008), valence alternations and intuitions (Levin, 1993) and conceptual structures (Fillmore and Baker, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al., 2008) are sufficient for identifying experience-revealing verbs. We introduce a method for constructing an activity/event verb lexicon based on Vendler’s theory and statistics obtained by utilizing a web search engine. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actually undergone1. It can be subjective as in opinions as well as objective, but our focus in this article lies in objective knowledge. The following sentences contain objective experiences: [5] I ran with my wife 3 times a week until</context>
<context position="15299" citStr="Baker et al., 2003" startWordPosition="2504" endWordPosition="2507">whereas the subject for an action verb takes the agent (A) role. In addition, a verb with the instrument (I) role tends to be an action verb. From these observations, we can use the distribution of cases (thematic roles) for a verb in a corpus. Activity verbs are expected to have high frequency of agent and instrument roles than state verbs. Although a verb may have more than one case frame, it is possible to determine which thematic roles used more dominantly. We utilize two major resources of lexical semantics, Verbnet (Kipper et al., 2008) based on the theory of Levin (1993), and Framenet (Baker et al., 2003), which is based on Fillmore (1968). Levin (1993) demonstrated that syntactic alternations can be the basis for groupings of verbs semantically and accord reasonably well with linguistic intuitions. Verbnet provides 274 verb classes with 23 thematic roles covering 3,769 verbs based on their alternation behaviors with thematic roles annotated. Framenet defines 978 semantic frames with 7,124 unique semantic roles, covering 11,583 words including verbs, nouns, adverbs, etc. Using Verbnet alone does not suit our needs because it has a relatively small number of example sentences. Framenet contains</context>
</contexts>
<marker>Baker, Fillmore, Cronin, 2003</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and Beau Cronin. 2003. The Structure of the Framenet Database. International Journal of Lexicography.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A Mximum Entropy Approach to Natural Language Processing. Computational Linguistics.</title>
<date>1996</date>
<contexts>
<context position="18471" citStr="Berger et al., 1996" startWordPosition="3059" endWordPosition="3062">en extracted as an action. The higher probability a word gets and the more frequent the word has been extracted as an action, the more evidence we get. 2.5 Classification For training, we selected 80 seed verbs from Dowty’s list (1979) which are representative verbs for each Vendler (1967) class. The selection was based on the lack of word sense ambiguity. One of our classifiers is based on Maximum Entropy (ME) models that implement the intuition that the best model will be the one that is consistent with the set of constraints imposed by the evidence, but otherwise is as uniform as possible (Berger et al., 1996). ME models are widely used in natural language processing tasks for its flexibility to incorporate a diverse range of features. The other one is based on Support Vector Machine (Chang and Lin, 2001) which is the state-of-the-art algorithm for many classification tasks. We used RBF kernel with the default settings (Hsu et al., 2009) because it is been known to show moderate performance using multiple feature compositions. The features we considered are a total of 42 real values: 18 from linguistic schemata, 23 thematic role distributions, and one from eHow. In order to examine which features a</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra, and Vincent J. Della Pietra. 1996. A Mximum Entropy Approach to Natural Language Processing. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM : a Library for Support Vector Machines.</title>
<date>2001</date>
<note>http://www.csie.ntu.edu.tw/~cjlin/libsvm.</note>
<contexts>
<context position="18670" citStr="Chang and Lin, 2001" startWordPosition="3093" endWordPosition="3096"> seed verbs from Dowty’s list (1979) which are representative verbs for each Vendler (1967) class. The selection was based on the lack of word sense ambiguity. One of our classifiers is based on Maximum Entropy (ME) models that implement the intuition that the best model will be the one that is consistent with the set of constraints imposed by the evidence, but otherwise is as uniform as possible (Berger et al., 1996). ME models are widely used in natural language processing tasks for its flexibility to incorporate a diverse range of features. The other one is based on Support Vector Machine (Chang and Lin, 2001) which is the state-of-the-art algorithm for many classification tasks. We used RBF kernel with the default settings (Hsu et al., 2009) because it is been known to show moderate performance using multiple feature compositions. The features we considered are a total of 42 real values: 18 from linguistic schemata, 23 thematic role distributions, and one from eHow. In order to examine which features are discriminative for the classification, we used two well known feature selection methods, Chi-square and information gain. 2.6 Results Table 3 shows the classification performance values for differ</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2001. LIBSVM : a Library for Support Vector Machines. http://www.csie.ntu.edu.tw/~cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
</authors>
<title>Word meaning and Montague Grammar.</title>
<date>1979</date>
<location>Reidel, Dordrecht.</location>
<contexts>
<context position="8340" citStr="Dowty (1979)" startWordPosition="1306" endWordPosition="1307">egories: activity and state. We consider all the verbs and verb phrases in WordNet (Fellbaum, 1998) which is the largest electronic lexical database. In addition to the linguistic schemata features based on Vendler’s theory, we used thematic role features and an external knowledge feature. 2.1 Background Vendler (1967) proposes that verb meanings can be categorized into four basic classes, states, activities, achievements, and accomplishments, depending on interactions between the verbs and their aspectual and temporal modifiers. Table 1 shows some examples for the classes. Vendler (1967) and Dowty (1979) introduce linguistic schemata that serve as evidence for the classes. 1465 Linguistic bs prs prp pts ptp Schemata No schema ■ ■ ■ ■ ■ Progressive ■ Force ■ Persuade ■ Stop ■ For ■ ■ ■ ■ ■ Carefully ■ ■ ■ ■ ■ Table 2. Query matrix. The “■” indicates that the query is applied. No Schema indicates that no schema is applied when the word itself is a query. bs, prs, prp, pts, ptp correspond to base form, present simple (3rd person singular), present participle, past simple and past participle, respectfully. Below are the six schemata we chose because they can be tested automatically: progressive, </context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>David R. Dowty. 1979. Word meaning and Montague Grammar. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7827" citStr="Fellbaum, 1998" startWordPosition="1231" endWordPosition="1232">ne whether a sentence contains a predicate describing an activity or an event. To this end, it is quite conceivable that a lexicon containing activity / event verbs would play a key role. Given that our ultimate goal is to extract experiences from a large amount of weblogs, we opt for increased coverage by automatically constructing a lexicon rather than high precision obtainable by manually crafted lexicon. Based on the theory of Vendler (1967), we classify a given verb or a verb phrase into one of the two categories: activity and state. We consider all the verbs and verb phrases in WordNet (Fellbaum, 1998) which is the largest electronic lexical database. In addition to the linguistic schemata features based on Vendler’s theory, we used thematic role features and an external knowledge feature. 2.1 Background Vendler (1967) proposes that verb meanings can be categorized into four basic classes, states, activities, achievements, and accomplishments, depending on interactions between the verbs and their aspectual and temporal modifiers. Table 1 shows some examples for the classes. Vendler (1967) and Dowty (1979) introduce linguistic schemata that serve as evidence for the classes. 1465 Linguistic </context>
<context position="27918" citStr="Fellbaum, 1998" startWordPosition="4589" endWordPosition="4590">, which seems close to our general understanding.5 The three filtering steps were implemented as follows. We used the dependency parser for extracting objective cases using the direct object relation. The second step, however, could not be applied because there is no grammatical distinction among “do, be, become” statements in English. We had to alter this step by adopting the approach of Inui et al. (2008). The authors propose a lexicon of experience expression by collecting hyponyms from a hierarchically structured dictionary. We collected all hyponyms of words “do” and “act”, from WordNet (Fellbaum, 1998). Lastly, we removed all the verbs that are under the hierarchy of “move” from WordNet. We not only compared our results with the baseline in terms of precision and recall but also 5 This is based on our observation that the three annotators found their task of identifying experience sentences not difficulty, resulting in a high degree of agreements. Feature Logistic SVM Regression Prec. Recall Prec. Recall Baseline 32.0% 55.1% 25.3% 44.4% -Lexicon 84.6% 84.6% 83.1% 81.2% -Tense 87.3% 87.1% 86.8% 86.5% -Mood 89.5% 89.5% 89.3% 89.2% -Aspect 90.8% 90.5% 89.0% 88.6% -Modality 89.5% 89.5% 82.8% 82</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>The Case for Case. In Bach and Harms (Ed.): Universals in Linguistic Theory.</title>
<date>1968</date>
<contexts>
<context position="4930" citStr="Fillmore, 1968" startWordPosition="769" endWordPosition="771">ed on our observation that experiencerevealing sentences tend to have a certain linguistic style (Jijkoun et al., 2010), we investigate on the roles of various features. The ability to detect experience-revealing sentences should be a precursor for ensuring the quality of extracting various elements of actual experiences. Another issue addressed in this paper is automatic construction of a lexicon for verbs related to activities and events. While there have been well-known studies about classifying verbs based on aspectual features (Vendler, 1967), thematic roles and selectional restrictions (Fillmore, 1968; Somers, 1987; Kipper et al., 2008), valence alternations and intuitions (Levin, 1993) and conceptual structures (Fillmore and Baker, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al., 2008) are sufficient for identifying experience-revealing verbs. We introduce a method for constructing an activity/event verb lexicon based on Vendler’s theory and statistics obtained by utilizing a web search engine. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actu</context>
<context position="15334" citStr="Fillmore (1968)" startWordPosition="2512" endWordPosition="2513">takes the agent (A) role. In addition, a verb with the instrument (I) role tends to be an action verb. From these observations, we can use the distribution of cases (thematic roles) for a verb in a corpus. Activity verbs are expected to have high frequency of agent and instrument roles than state verbs. Although a verb may have more than one case frame, it is possible to determine which thematic roles used more dominantly. We utilize two major resources of lexical semantics, Verbnet (Kipper et al., 2008) based on the theory of Levin (1993), and Framenet (Baker et al., 2003), which is based on Fillmore (1968). Levin (1993) demonstrated that syntactic alternations can be the basis for groupings of verbs semantically and accord reasonably well with linguistic intuitions. Verbnet provides 274 verb classes with 23 thematic roles covering 3,769 verbs based on their alternation behaviors with thematic roles annotated. Framenet defines 978 semantic frames with 7,124 unique semantic roles, covering 11,583 words including verbs, nouns, adverbs, etc. Using Verbnet alone does not suit our needs because it has a relatively small number of example sentences. Framenet contains a much larger number of examples b</context>
<context position="26474" citStr="Fillmore, 1968" startWordPosition="4357" endWordPosition="4358">d the number at a later stage, the performance increase was almost negligible. 1469 Feature Logistic SVM Regression Prec. Recall Prec. Recall Baseline 32.0% 55.1% 25.3% 44.4% Lexicon 77.5% 76.0% 77.5% 76.0% Tense 75.1% 75.1% 75.1% 75.1% Mood 75.8% 60.3% 75.8% 60.3% Aspect 26.7% 51.7% 26.7% 51.7% Modality 79.8% 70.5% 79.8% 70.5% Experiencer 54.3% 53.5% 54.3% 53.5% All included 91.9% 91.7% 91.7% 91.4% Table 5. Experience Detection Performance The candidate goes through three filters before it is treated as experience-containing sentence. First, the candidates that do not have an objective case (Fillmore, 1968) are eliminated because their definition of experience as “action + object”. This was done by identifying the objectindicating particle (case marker) in Japanese. Next, the candidates belonging to “become” and “be” statements based on Japanese verb types are filtered out. Finally, the candidate sentences including a verb that indicates a movement are eliminated because the main interest was to identify an activity in a place. Although their definition of experience is somewhat different from ours (i.e., “action + object”), they used the method to generate candidate sentences from which various</context>
<context position="31393" citStr="Fillmore, 1968" startWordPosition="5139" endWordPosition="5140">n studied quite extensively (see Pang and Lee’s excellent survey (2008)), another sub-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000), who attempted to categorize verbs into state or event classes based on 14 tests similar to those of Vendler’s. They attempted to compute co-occurrence statistics from a corpus. The event class, however, includes activity, accomplishment, and achievement. Similarly, Zacrone and Lenci (2008) attempted to categorize verbs in Ita</context>
</contexts>
<marker>Fillmore, 1968</marker>
<rawString>Charles J. Fillmore. 1968. The Case for Case. In Bach and Harms (Ed.): Universals in Linguistic Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Collin F Baker</author>
</authors>
<title>Frame Semantics for Text Understanding.</title>
<date>2001</date>
<booktitle>In Proceedings of WordNet and Other Lexical Resources Workshop,</booktitle>
<location>NAACL.</location>
<contexts>
<context position="5070" citStr="Fillmore and Baker, 2001" startWordPosition="787" endWordPosition="790">tigate on the roles of various features. The ability to detect experience-revealing sentences should be a precursor for ensuring the quality of extracting various elements of actual experiences. Another issue addressed in this paper is automatic construction of a lexicon for verbs related to activities and events. While there have been well-known studies about classifying verbs based on aspectual features (Vendler, 1967), thematic roles and selectional restrictions (Fillmore, 1968; Somers, 1987; Kipper et al., 2008), valence alternations and intuitions (Levin, 1993) and conceptual structures (Fillmore and Baker, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al., 2008) are sufficient for identifying experience-revealing verbs. We introduce a method for constructing an activity/event verb lexicon based on Vendler’s theory and statistics obtained by utilizing a web search engine. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actually undergone1. It can be subjective as in opinions as well as objective, but our focus in this article lies in objective knowledge. The fo</context>
<context position="31461" citStr="Fillmore and Baker, 2001" startWordPosition="5147" endWordPosition="5150">survey (2008)), another sub-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000), who attempted to categorize verbs into state or event classes based on 14 tests similar to those of Vendler’s. They attempted to compute co-occurrence statistics from a corpus. The event class, however, includes activity, accomplishment, and achievement. Similarly, Zacrone and Lenci (2008) attempted to categorize verbs in Italian into the four Vendler classes using the Vendler tests by using </context>
</contexts>
<marker>Fillmore, Baker, 2001</marker>
<rawString>Charles J. Fillmore and Collin F. Baker. 2001. Frame Semantics for Text Understanding. In Proceedings of WordNet and Other Lexical Resources Workshop, NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Trond Grenager</author>
<author>Christopher D Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="24171" citStr="Finkel et al., 2005" startWordPosition="3994" endWordPosition="3997">epending on the subject or experiencer of the verb (note that this is different from the experiencer role in a case frame). Consider the following sentences: [14] The stranger messed up the entire garden. [15] His presence messed up the whole situation. The first sentence is considered an experience since the subject is a person. However, the second sentence with the same verb is not, because the subject is a non-animate abstract concept. That is, a non-animate noun can hardly constitute an experience. In order to make a distinction, we use the dependency parser and a named-entity recognizer (Finkel et al., 2005) that can recognize person pronouns and person names. 3.2 Classification To train our classifier, we first crawled weblogs from Wordpress3, one of the most popular blog sites in use today. Worpress provides an interface to search blog posts with queries. In selecting experience-containing blog pots, we used location names such as Central Park, SOHO, Seoul and general place names such as airport, subway station, and restaurant because blog posts with some places are expected to describe experiences rather than facts or thoughts. We crawled 6,000 blog posts. After deleting non-English and multi-</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny R. Finkel, Trond Grenager, and Christopher D. Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Wei Hsu</author>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>A Practical Guide to Support Vector Classification.</title>
<date>2009</date>
<note>http://www.csie.ntu.edu.tw/~cjlin/libsvm.</note>
<contexts>
<context position="18805" citStr="Hsu et al., 2009" startWordPosition="3115" endWordPosition="3118">word sense ambiguity. One of our classifiers is based on Maximum Entropy (ME) models that implement the intuition that the best model will be the one that is consistent with the set of constraints imposed by the evidence, but otherwise is as uniform as possible (Berger et al., 1996). ME models are widely used in natural language processing tasks for its flexibility to incorporate a diverse range of features. The other one is based on Support Vector Machine (Chang and Lin, 2001) which is the state-of-the-art algorithm for many classification tasks. We used RBF kernel with the default settings (Hsu et al., 2009) because it is been known to show moderate performance using multiple feature compositions. The features we considered are a total of 42 real values: 18 from linguistic schemata, 23 thematic role distributions, and one from eHow. In order to examine which features are discriminative for the classification, we used two well known feature selection methods, Chi-square and information gain. 2.6 Results Table 3 shows the classification performance values for different feature selection methods. The evaluation was done on the training data with 10-fold cross validation. Note that the precision and </context>
</contexts>
<marker>Hsu, Chang, Lin, 2009</marker>
<rawString>Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin. 2009. A Practical Guide to Support Vector Classification. http://www.csie.ntu.edu.tw/~cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Inui</author>
<author>Shuya Abe</author>
<author>Kazuo Hara</author>
<author>Hiraku Morita</author>
<author>Chitose Sao</author>
<author>Megumi Eguchi</author>
<author>Asuka Sumida</author>
<author>Koji Murakami</author>
<author>Suguru Matsuyoshi</author>
</authors>
<title>Experience Mining: Building a Large-Scale Database of Personal Experiences and Opinions from Web Documents.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Web Intelligence.</booktitle>
<contexts>
<context position="2237" citStr="Inui et al., 2008" startWordPosition="343" endWordPosition="346"> around. Among many sources people resort to, the Web has become the largest one for human experiences, especially with the proliferation of weblogs. While Web documents contain various types of information including facts, encyclopedic knowledge, opinions, and experiences in general, personal experiences tend to be found in weblogs more often than other web documents like news articles, home pages, and scientific papers. As such, we have begun to see some research efforts in mining experience-related attributes such as time, location, topic, and experiencer, and their relations from weblogs (Inui et al., 2008; Kurashima et al., 2009). Mined experiences can be of practical use in wide application areas. For example, a collection of experiences from the people who visited a resort area would help planning what to do and how to do things correctly without having to spend time sifting through a variety of resources or rely on commercially-oriented sources. Another example would be a public service department gleaning information about how a park is being used at a specific location and time. Experiences can be recorded around a frame like “who did what, when, where, and why” although opinions and emot</context>
<context position="3704" citStr="Inui et al., 2008" startWordPosition="590" endWordPosition="593">r belong to a “do” class (Kurashima et al., 2009). However, this kind of method may extract the following sentences as containing an experience: [1] If Jason arrives on time, I’ll buy him a drink. [2] Probably, she will laugh and dance in his funeral. [3] Can anyone explain what is going on here? [4] Don’t play soccer on the roads! None of the sentences contain actual experiences because hypotheses, questions, and orders have not actually happened in the real world. For experience mining, it is important to ensure a sentence mentions an event or passes a factuality test to contain experience (Inui et al., 2008). In this paper, we focus on the problem of detecting experiences from weblogs. We formulate 1464 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1464–1472, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics Class Examples State like, know, believe Activity run, swim, walk Achievement recognize, realize Accomplishment paint (a picture), build (a house) Table 1. Vendler class examples the problem as a classification task using various linguistic features including tense, mood, aspect, modality, experiencer, and verb </context>
<context position="27713" citStr="Inui et al. (2008)" startWordPosition="4555" endWordPosition="4558">s are extracted. From this perspective, the method functioned like our experience detection. Put differently, the definition and the method by which it is determined were much cruder than the one we are using, which seems close to our general understanding.5 The three filtering steps were implemented as follows. We used the dependency parser for extracting objective cases using the direct object relation. The second step, however, could not be applied because there is no grammatical distinction among “do, be, become” statements in English. We had to alter this step by adopting the approach of Inui et al. (2008). The authors propose a lexicon of experience expression by collecting hyponyms from a hierarchically structured dictionary. We collected all hyponyms of words “do” and “act”, from WordNet (Fellbaum, 1998). Lastly, we removed all the verbs that are under the hierarchy of “move” from WordNet. We not only compared our results with the baseline in terms of precision and recall but also 5 This is based on our observation that the three annotators found their task of identifying experience sentences not difficulty, resulting in a high degree of agreements. Feature Logistic SVM Regression Prec. Reca</context>
<context position="30941" citStr="Inui et al., 2008" startWordPosition="5072" endWordPosition="5075"> the Logistic Regression case). Similar to table 5, the aspect and experience features were the least contributors as the performance drops are almost negligible. 1470 4 Related Work Experience mining in its entirety is a relatively new area where various natural language processing and text mining techniques can play a significant role. While opinion mining or sentiment analysis, which can be considered an important part of experience mining, has been studied quite extensively (see Pang and Lee’s excellent survey (2008)), another sub-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb l</context>
</contexts>
<marker>Inui, Abe, Hara, Morita, Sao, Eguchi, Sumida, Murakami, Matsuyoshi, 2008</marker>
<rawString>Kentaro Inui, Shuya Abe, Kazuo Hara, Hiraku Morita, Chitose Sao, Megumi Eguchi, Asuka Sumida, Koji Murakami, and Suguru Matsuyoshi. 2008. Experience Mining: Building a Large-Scale Database of Personal Experiences and Opinions from Web Documents. In Proceedings of the International Conference on Web Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
</authors>
<title>Maarten de Rijke, Wouter Weerkamp, Paul Ackermans and Gijs Geleijnse.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL HLT Workshop on Computational Linguistics in a World of Social Media.</booktitle>
<marker>Jijkoun, 2010</marker>
<rawString>Valentin Jijkoun, Maarten de Rijke, Wouter Weerkamp, Paul Ackermans and Gijs Geleijnse. 2010. Mining User Experiences from Online Forums: An Exploration. In Proceedings of NAACL HLT Workshop on Computational Linguistics in a World of Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Anna Korhonen</author>
<author>Neville Ryant</author>
<author>Martha Palmer</author>
</authors>
<title>A Large-scale Classification of English Verbs. Language Resources and Evaluation Journal.</title>
<date>2008</date>
<contexts>
<context position="4966" citStr="Kipper et al., 2008" startWordPosition="774" endWordPosition="777">eriencerevealing sentences tend to have a certain linguistic style (Jijkoun et al., 2010), we investigate on the roles of various features. The ability to detect experience-revealing sentences should be a precursor for ensuring the quality of extracting various elements of actual experiences. Another issue addressed in this paper is automatic construction of a lexicon for verbs related to activities and events. While there have been well-known studies about classifying verbs based on aspectual features (Vendler, 1967), thematic roles and selectional restrictions (Fillmore, 1968; Somers, 1987; Kipper et al., 2008), valence alternations and intuitions (Levin, 1993) and conceptual structures (Fillmore and Baker, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al., 2008) are sufficient for identifying experience-revealing verbs. We introduce a method for constructing an activity/event verb lexicon based on Vendler’s theory and statistics obtained by utilizing a web search engine. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actually undergone1. It can be subjectiv</context>
<context position="15228" citStr="Kipper et al., 2008" startWordPosition="2491" endWordPosition="2494">(O) with a bat(I). The subject of a state verb is dative (D) as in [12] whereas the subject for an action verb takes the agent (A) role. In addition, a verb with the instrument (I) role tends to be an action verb. From these observations, we can use the distribution of cases (thematic roles) for a verb in a corpus. Activity verbs are expected to have high frequency of agent and instrument roles than state verbs. Although a verb may have more than one case frame, it is possible to determine which thematic roles used more dominantly. We utilize two major resources of lexical semantics, Verbnet (Kipper et al., 2008) based on the theory of Levin (1993), and Framenet (Baker et al., 2003), which is based on Fillmore (1968). Levin (1993) demonstrated that syntactic alternations can be the basis for groupings of verbs semantically and accord reasonably well with linguistic intuitions. Verbnet provides 274 verb classes with 23 thematic roles covering 3,769 verbs based on their alternation behaviors with thematic roles annotated. Framenet defines 978 semantic frames with 7,124 unique semantic roles, covering 11,583 words including verbs, nouns, adverbs, etc. Using Verbnet alone does not suit our needs because i</context>
<context position="31483" citStr="Kipper et al., 2008" startWordPosition="5151" endWordPosition="5154">b-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000), who attempted to categorize verbs into state or event classes based on 14 tests similar to those of Vendler’s. They attempted to compute co-occurrence statistics from a corpus. The event class, however, includes activity, accomplishment, and achievement. Similarly, Zacrone and Lenci (2008) attempted to categorize verbs in Italian into the four Vendler classes using the Vendler tests by using a tagged corpus. They </context>
</contexts>
<marker>Kipper, Korhonen, Ryant, Palmer, 2008</marker>
<rawString>Karin Kipper, Anna Korhonen, Neville Ryant, and Martha Palmer. 2008. A Large-scale Classification of English Verbs. Language Resources and Evaluation Journal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="12935" citStr="Klein and Manning, 2003" startWordPosition="2086" endWordPosition="2089">ord w in the search result snippets. Cij(w) is the number of correct sentences matching the query pattern among the candidate sentences. For example, the progressive schema for a verb “build” can retrieve the following sentences. [10] ..., New-York, is building one of the largest ... [11] Is building an artifact? 1466 “Building” in the first example is a progressive verb, but the one in second is a noun, which does not satisfy the linguistic schema. For a POS and grammatical check of a candidate sentence, we used the Stanford POS tagger (Toutanova et al., 2003) and Stanford dependency parser (Klein and Manning, 2003). For each linguistic schema, we derived three features: Absolute hit ratio, Relative hit ratio and Valid ratio for which we use the notations Ai(w), Ri(w) and Vi(w), respectfully, where w is a word and i a linguistic schema. The index j for summations represents the j-th verb form. They are computed as follows. (w) = ∑j Cij (w) ∑ S w j ij ( ) Absolute hit ratio is computes the extent to which the target word w occurs with the i-th schema over all occurrences of the schema. The denominator is the hit count of wild card “*” matching any single word with the schema pattern from Google (e.g., H1(</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate Unlexicalized Parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Kurashima</author>
<author>Ko Fujimura</author>
<author>Hidenori Okuda</author>
</authors>
<title>Discovering Association Rules on Experiences from Large-Scale Blog Entries.</title>
<date>2009</date>
<booktitle>In Proceedings of ECIR.</booktitle>
<contexts>
<context position="2262" citStr="Kurashima et al., 2009" startWordPosition="347" endWordPosition="351"> sources people resort to, the Web has become the largest one for human experiences, especially with the proliferation of weblogs. While Web documents contain various types of information including facts, encyclopedic knowledge, opinions, and experiences in general, personal experiences tend to be found in weblogs more often than other web documents like news articles, home pages, and scientific papers. As such, we have begun to see some research efforts in mining experience-related attributes such as time, location, topic, and experiencer, and their relations from weblogs (Inui et al., 2008; Kurashima et al., 2009). Mined experiences can be of practical use in wide application areas. For example, a collection of experiences from the people who visited a resort area would help planning what to do and how to do things correctly without having to spend time sifting through a variety of resources or rely on commercially-oriented sources. Another example would be a public service department gleaning information about how a park is being used at a specific location and time. Experiences can be recorded around a frame like “who did what, when, where, and why” although opinions and emotions can be also linked. </context>
<context position="25566" citStr="Kurashima et al., 2009" startWordPosition="4217" endWordPosition="4220">hether or not individual sentences are considered containing an experience based on our definition. For maximum accuracy, we decided to use only those sentences all the three annotators agreed, resulting in a total of 568 sentences. While we tested several classifiers, we chose to use two different classifiers based on SVM and Logistic Regression for the final experimental results because they showed the best performance. 3.3 Results For comparison purposes, we take the method of Kurashima et al. (2005) as our baseline because the method was used in subsequent studies (Kurashima et al., 2006; Kurashima et al., 2009) where experience attributes are extracted. We briefly describe the method and present how we implemented it. The method first extracts all verbs and their dependent phrasal unit from candidate sentences. 3 http://wordpress.com 4 It was due to the limited human resources, but when we increased the number at a later stage, the performance increase was almost negligible. 1469 Feature Logistic SVM Regression Prec. Recall Prec. Recall Baseline 32.0% 55.1% 25.3% 44.4% Lexicon 77.5% 76.0% 77.5% 76.0% Tense 75.1% 75.1% 75.1% 75.1% Mood 75.8% 60.3% 75.8% 60.3% Aspect 26.7% 51.7% 26.7% 51.7% Modality 7</context>
<context position="31081" citStr="Kurashima et al., 2009" startWordPosition="5091" endWordPosition="5094">drops are almost negligible. 1470 4 Related Work Experience mining in its entirety is a relatively new area where various natural language processing and text mining techniques can play a significant role. While opinion mining or sentiment analysis, which can be considered an important part of experience mining, has been studied quite extensively (see Pang and Lee’s excellent survey (2008)), another sub-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000), who attempted t</context>
</contexts>
<marker>Kurashima, Fujimura, Okuda, 2009</marker>
<rawString>Takeshi Kurashima, Ko Fujimura, and Hidenori Okuda. 2009. Discovering Association Rules on Experiences from Large-Scale Blog Entries. In Proceedings of ECIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Kurashima</author>
<author>Taro Tezuka</author>
<author>Katsumi Tanaka</author>
</authors>
<title>Blog Map of Experiences: Extracting and Geographically Mapping Visitor Experiences from Urban Blogs.</title>
<date>2005</date>
<booktitle>In Proceedings of WISE.</booktitle>
<contexts>
<context position="25451" citStr="Kurashima et al. (2005)" startWordPosition="4197" endWordPosition="4200">gful text data, the number became 5,326. We randomly sampled 1,000 sentences4 and asked three annotators to judge whether or not individual sentences are considered containing an experience based on our definition. For maximum accuracy, we decided to use only those sentences all the three annotators agreed, resulting in a total of 568 sentences. While we tested several classifiers, we chose to use two different classifiers based on SVM and Logistic Regression for the final experimental results because they showed the best performance. 3.3 Results For comparison purposes, we take the method of Kurashima et al. (2005) as our baseline because the method was used in subsequent studies (Kurashima et al., 2006; Kurashima et al., 2009) where experience attributes are extracted. We briefly describe the method and present how we implemented it. The method first extracts all verbs and their dependent phrasal unit from candidate sentences. 3 http://wordpress.com 4 It was due to the limited human resources, but when we increased the number at a later stage, the performance increase was almost negligible. 1469 Feature Logistic SVM Regression Prec. Recall Prec. Recall Baseline 32.0% 55.1% 25.3% 44.4% Lexicon 77.5% 76.</context>
</contexts>
<marker>Kurashima, Tezuka, Tanaka, 2005</marker>
<rawString>Takeshi Kurashima, Taro Tezuka, and Katsumi Tanaka. 2005. Blog Map of Experiences: Extracting and Geographically Mapping Visitor Experiences from Urban Blogs. In Proceedings of WISE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Kurashima</author>
<author>Taro Tezuka</author>
<author>Katsumi Tanaka</author>
</authors>
<title>Mining and Visualizing Local Experiences from Blog Entries.</title>
<date>2006</date>
<booktitle>In Proceedings of DEXA.</booktitle>
<contexts>
<context position="25541" citStr="Kurashima et al., 2006" startWordPosition="4212" endWordPosition="4216">ee annotators to judge whether or not individual sentences are considered containing an experience based on our definition. For maximum accuracy, we decided to use only those sentences all the three annotators agreed, resulting in a total of 568 sentences. While we tested several classifiers, we chose to use two different classifiers based on SVM and Logistic Regression for the final experimental results because they showed the best performance. 3.3 Results For comparison purposes, we take the method of Kurashima et al. (2005) as our baseline because the method was used in subsequent studies (Kurashima et al., 2006; Kurashima et al., 2009) where experience attributes are extracted. We briefly describe the method and present how we implemented it. The method first extracts all verbs and their dependent phrasal unit from candidate sentences. 3 http://wordpress.com 4 It was due to the limited human resources, but when we increased the number at a later stage, the performance increase was almost negligible. 1469 Feature Logistic SVM Regression Prec. Recall Prec. Recall Baseline 32.0% 55.1% 25.3% 44.4% Lexicon 77.5% 76.0% 77.5% 76.0% Tense 75.1% 75.1% 75.1% 75.1% Mood 75.8% 60.3% 75.8% 60.3% Aspect 26.7% 51.</context>
</contexts>
<marker>Kurashima, Tezuka, Tanaka, 2006</marker>
<rawString>Takeshi Kurashima, Taro Tezuka, and Katsumi Tanaka. 2006. Mining and Visualizing Local Experiences from Blog Entries. In Proceedings of DEXA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proceedings of ICML.</booktitle>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andew McCallum, and Fernando Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English verb classes and alternations: A Preliminary investigation.</title>
<date>1993</date>
<institution>University of Chicago press.</institution>
<contexts>
<context position="5017" citStr="Levin, 1993" startWordPosition="782" endWordPosition="783">c style (Jijkoun et al., 2010), we investigate on the roles of various features. The ability to detect experience-revealing sentences should be a precursor for ensuring the quality of extracting various elements of actual experiences. Another issue addressed in this paper is automatic construction of a lexicon for verbs related to activities and events. While there have been well-known studies about classifying verbs based on aspectual features (Vendler, 1967), thematic roles and selectional restrictions (Fillmore, 1968; Somers, 1987; Kipper et al., 2008), valence alternations and intuitions (Levin, 1993) and conceptual structures (Fillmore and Baker, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al., 2008) are sufficient for identifying experience-revealing verbs. We introduce a method for constructing an activity/event verb lexicon based on Vendler’s theory and statistics obtained by utilizing a web search engine. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actually undergone1. It can be subjective as in opinions as well as objective, but our focu</context>
<context position="15264" citStr="Levin (1993)" startWordPosition="2500" endWordPosition="2501">rb is dative (D) as in [12] whereas the subject for an action verb takes the agent (A) role. In addition, a verb with the instrument (I) role tends to be an action verb. From these observations, we can use the distribution of cases (thematic roles) for a verb in a corpus. Activity verbs are expected to have high frequency of agent and instrument roles than state verbs. Although a verb may have more than one case frame, it is possible to determine which thematic roles used more dominantly. We utilize two major resources of lexical semantics, Verbnet (Kipper et al., 2008) based on the theory of Levin (1993), and Framenet (Baker et al., 2003), which is based on Fillmore (1968). Levin (1993) demonstrated that syntactic alternations can be the basis for groupings of verbs semantically and accord reasonably well with linguistic intuitions. Verbnet provides 274 verb classes with 23 thematic roles covering 3,769 verbs based on their alternation behaviors with thematic roles annotated. Framenet defines 978 semantic frames with 7,124 unique semantic roles, covering 11,583 words including verbs, nouns, adverbs, etc. Using Verbnet alone does not suit our needs because it has a relatively small number of e</context>
<context position="31435" citStr="Levin, 1993" startWordPosition="5145" endWordPosition="5146">’s excellent survey (2008)), another sub-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000), who attempted to categorize verbs into state or event classes based on 14 tests similar to those of Vendler’s. They attempted to compute co-occurrence statistics from a corpus. The event class, however, includes activity, accomplishment, and achievement. Similarly, Zacrone and Lenci (2008) attempted to categorize verbs in Italian into the four Vendler classes using t</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English verb classes and alternations: A Preliminary investigation. University of Chicago press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Szu-ting Yi</author>
<author>Martha Palmer</author>
</authors>
<title>Combining Lexical Resources: Mapping Between PropBank and Verbnet.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Workshop on Computational Linguistics.</booktitle>
<contexts>
<context position="16111" citStr="Loper et al., 2007" startWordPosition="2633" endWordPosition="2636">ions. Verbnet provides 274 verb classes with 23 thematic roles covering 3,769 verbs based on their alternation behaviors with thematic roles annotated. Framenet defines 978 semantic frames with 7,124 unique semantic roles, covering 11,583 words including verbs, nouns, adverbs, etc. Using Verbnet alone does not suit our needs because it has a relatively small number of example sentences. Framenet contains a much larger number of examples but the vast number of semantic roles presents a problem. In order to get meaningful distributions for a manageable number of thematic roles, we used Semlink (Loper et al., 2007) that provides a mapping between Framenet and Verbnet and uses a total of 23 thematic roles of Verbnet for the annotated corpora of the two resources. By the mapping, we obtained distributions of the thematic roles for 2,868 unique verbs that exist in both of the resources. For example, the verb “construct” has high frequencies with agent, material and product roles. 2.4 Features based on how-to instructions Ryu et al. (2010) presented a method for extracting action steps for how-to goals from eHow2 a website containing a large number of how-to instructions. The authors attempted to extract ac</context>
</contexts>
<marker>Loper, Yi, Palmer, 2007</marker>
<rawString>Edward Loper, Szu-ting Yi, and Martha Palmer. 2007. Combining Lexical Resources: Mapping Between PropBank and Verbnet. In Proceedings of the International Workshop on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis, Foundations and Trends in Information Retrieval.</title>
<date>2008</date>
<contexts>
<context position="6321" citStr="Pang and Lee, 2008" startWordPosition="985" endWordPosition="988">ive experiences: [5] I ran with my wife 3 times a week until we moved to Washington, D.C. [6] Jane and I hopped on a bus into the city centre. [7] We went to a restaurant near the central park. Whereas sentences like the following contain subjective knowledge: [8] I like your new style. You’re beautiful! [9] The food was great, the interior too. Subject knowledge has been studied extensively for various functions such as identification, po1 http://en.wikipedia.org/wiki/Experience_(disambiguation) larity detection, and holder extraction under the names of opinion mining and sentiment analysis (Pang and Lee, 2008). In summary, our contribution lies in three aspects: 1) conception of experience detection, which is a precursor for experience mining, and specific related tasks that can be tackled with a high performance machine learning based solution; 2) examination and identification of salient linguistic features for experience detection; 3) a novel lexicon construction method with identification of key features to be used for verb classification. The remainder of the paper is organized as follows. Section 2 presents our lexicon construction method with experiments. Section 3 describes the experience d</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion Mining and Sentiment Analysis, Foundations and Trends in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jihee Ryu</author>
<author>Yuchul Jung</author>
<author>Kyung-min Kim</author>
<author>Sung H Myaeng</author>
</authors>
<title>Automatic Extraction of Human Activity Knowledge from Method-Describing Web Articles.</title>
<date>2010</date>
<booktitle>In Proceedings of the 1st Workshop on Automated Knowledge Base Construction.</booktitle>
<contexts>
<context position="16540" citStr="Ryu et al. (2010)" startWordPosition="2707" endWordPosition="2710"> examples but the vast number of semantic roles presents a problem. In order to get meaningful distributions for a manageable number of thematic roles, we used Semlink (Loper et al., 2007) that provides a mapping between Framenet and Verbnet and uses a total of 23 thematic roles of Verbnet for the annotated corpora of the two resources. By the mapping, we obtained distributions of the thematic roles for 2,868 unique verbs that exist in both of the resources. For example, the verb “construct” has high frequencies with agent, material and product roles. 2.4 Features based on how-to instructions Ryu et al. (2010) presented a method for extracting action steps for how-to goals from eHow2 a website containing a large number of how-to instructions. The authors attempted to extract actions comprising a verb and some ingredients like an object entity from the documents based on syntactic patterns and a CRF based model. Since each extracted action has its probability, we can use the value as a feature for state / activity verb classification. However, a verb may appear in different contexts and can have multiple 2 http://www.ehow.com ∑ H w j ij ( ) ( ) w = H ( ) * i (w)= ∑jHij(w) Ai Ri (1) ∑jHNoScheme(w) Vi</context>
</contexts>
<marker>Ryu, Jung, Kim, Myaeng, 2010</marker>
<rawString>Jihee Ryu, Yuchul Jung, Kyung-min Kim and Sung H. Myaeng. 2010. Automatic Extraction of Human Activity Knowledge from Method-Describing Web Articles. In Proceedings of the 1st Workshop on Automated Knowledge Base Construction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Saurí</author>
</authors>
<title>A Factuality Profiler for Eventualities in Text.</title>
<date>2008</date>
<tech>PhD thesis,</tech>
<institution>Brandeis University.</institution>
<contexts>
<context position="30955" citStr="Saurí, 2008" startWordPosition="5076" endWordPosition="5077">ssion case). Similar to table 5, the aspect and experience features were the least contributors as the performance drops are almost negligible. 1470 4 Related Work Experience mining in its entirety is a relatively new area where various natural language processing and text mining techniques can play a significant role. While opinion mining or sentiment analysis, which can be considered an important part of experience mining, has been studied quite extensively (see Pang and Lee’s excellent survey (2008)), another sub-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which </context>
</contexts>
<marker>Saurí, 2008</marker>
<rawString>Roser Saurí. 2008. A Factuality Profiler for Eventualities in Text. PhD thesis, Brandeis University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric V Siegel</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Learing Methods to Combine Linguistic Indicators: Improving Aspectual Classification and Revealing Linguistic Insights. In Computational Linguistics.</title>
<date>2000</date>
<contexts>
<context position="31664" citStr="Siegel and McKeown (2000)" startWordPosition="5181" endWordPosition="5184">itute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000), who attempted to categorize verbs into state or event classes based on 14 tests similar to those of Vendler’s. They attempted to compute co-occurrence statistics from a corpus. The event class, however, includes activity, accomplishment, and achievement. Similarly, Zacrone and Lenci (2008) attempted to categorize verbs in Italian into the four Vendler classes using the Vendler tests by using a tagged corpus. They focused on existence of arguments such as subject and object that should co-occur with the linguistic features in the tests. The main difference between the previous work and ours l</context>
</contexts>
<marker>Siegel, McKeown, 2000</marker>
<rawString>Eric V. Siegel and Kathleen R. McKeown. 2000. Learing Methods to Combine Linguistic Indicators: Improving Aspectual Classification and Revealing Linguistic Insights. In Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harold L Somers</author>
</authors>
<title>Valency and Case in Computational Linguistics.</title>
<date>1987</date>
<publisher>Edinburgh University Press.</publisher>
<contexts>
<context position="4944" citStr="Somers, 1987" startWordPosition="772" endWordPosition="773">ation that experiencerevealing sentences tend to have a certain linguistic style (Jijkoun et al., 2010), we investigate on the roles of various features. The ability to detect experience-revealing sentences should be a precursor for ensuring the quality of extracting various elements of actual experiences. Another issue addressed in this paper is automatic construction of a lexicon for verbs related to activities and events. While there have been well-known studies about classifying verbs based on aspectual features (Vendler, 1967), thematic roles and selectional restrictions (Fillmore, 1968; Somers, 1987; Kipper et al., 2008), valence alternations and intuitions (Levin, 1993) and conceptual structures (Fillmore and Baker, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al., 2008) are sufficient for identifying experience-revealing verbs. We introduce a method for constructing an activity/event verb lexicon based on Vendler’s theory and statistics obtained by utilizing a web search engine. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actually undergone</context>
</contexts>
<marker>Somers, 1987</marker>
<rawString>Harold L. Somers. 1987. Valency and Case in Computational Linguistics. Edinburgh University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-Rich Partof-Speech Tagging with a Cyclic Dependency Network.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="12878" citStr="Toutanova et al., 2003" startWordPosition="2078" endWordPosition="2081">gine. Sij(w) is the number of sentences containing the word w in the search result snippets. Cij(w) is the number of correct sentences matching the query pattern among the candidate sentences. For example, the progressive schema for a verb “build” can retrieve the following sentences. [10] ..., New-York, is building one of the largest ... [11] Is building an artifact? 1466 “Building” in the first example is a progressive verb, but the one in second is a noun, which does not satisfy the linguistic schema. For a POS and grammatical check of a candidate sentence, we used the Stanford POS tagger (Toutanova et al., 2003) and Stanford dependency parser (Klein and Manning, 2003). For each linguistic schema, we derived three features: Absolute hit ratio, Relative hit ratio and Valid ratio for which we use the notations Ai(w), Ri(w) and Vi(w), respectfully, where w is a word and i a linguistic schema. The index j for summations represents the j-th verb form. They are computed as follows. (w) = ∑j Cij (w) ∑ S w j ij ( ) Absolute hit ratio is computes the extent to which the target word w occurs with the i-th schema over all occurrences of the schema. The denominator is the hit count of wild card “*” matching any s</context>
<context position="22228" citStr="Toutanova et al., 2003" startWordPosition="3663" endWordPosition="3666">tures In addition to the verb class feature available in the verb lexicon constructed automatically, we used tense, mood, aspect, modality, and experiencer features. Verb class: The feature comes directly from the lexicon since a verb has been classified into a state or activity verb. The predicate part of the sentence to be classified for experience is looked up in the lexicon without sense disambiguation. Tense: The tense of a sentence is important since an experience-revealing sentence tends to use past and present tense. Future tenses are not experiences in most cases. We use POS tagging (Toutanova et al., 2003) for tense determination, but since the Penn tagset provides no future tenses, they are determined by exploiting modal verbs such as “will” and future expressions such “going to”. Mood: It is one of distinctive forms that are used to signal the modal status of a sentence. We consider three mood categories: indicative, imperative and subjunctive. We determine the mood of a sentence by a small set of heuristic rules using the order of POS occurrences and punctuation marks. Aspect: It defines the temporal flow of a verb in the activity or state. Two categories are used: progressive and perfective</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-Rich Partof-Speech Tagging with a Cyclic Dependency Network. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Vendler</author>
</authors>
<title>Linguistics in Philosophy.</title>
<date>1967</date>
<publisher>Cornell University Press.</publisher>
<contexts>
<context position="4869" citStr="Vendler, 1967" startWordPosition="762" endWordPosition="763">e, mood, aspect, modality, experiencer, and verb classes. Based on our observation that experiencerevealing sentences tend to have a certain linguistic style (Jijkoun et al., 2010), we investigate on the roles of various features. The ability to detect experience-revealing sentences should be a precursor for ensuring the quality of extracting various elements of actual experiences. Another issue addressed in this paper is automatic construction of a lexicon for verbs related to activities and events. While there have been well-known studies about classifying verbs based on aspectual features (Vendler, 1967), thematic roles and selectional restrictions (Fillmore, 1968; Somers, 1987; Kipper et al., 2008), valence alternations and intuitions (Levin, 1993) and conceptual structures (Fillmore and Baker, 2001), we found that none of the existing lexical resources such as Framenet (Baker et al., 2003) and Verbnet (Kipper et al., 2008) are sufficient for identifying experience-revealing verbs. We introduce a method for constructing an activity/event verb lexicon based on Vendler’s theory and statistics obtained by utilizing a web search engine. We define experience as knowledge embedded in a collection </context>
<context position="7661" citStr="Vendler (1967)" startWordPosition="1200" endWordPosition="1201"> with conclusion and future work in Section 5. 2 Lexicon Construction Since our definition of experience is based on activities and events, it is critical to determine whether a sentence contains a predicate describing an activity or an event. To this end, it is quite conceivable that a lexicon containing activity / event verbs would play a key role. Given that our ultimate goal is to extract experiences from a large amount of weblogs, we opt for increased coverage by automatically constructing a lexicon rather than high precision obtainable by manually crafted lexicon. Based on the theory of Vendler (1967), we classify a given verb or a verb phrase into one of the two categories: activity and state. We consider all the verbs and verb phrases in WordNet (Fellbaum, 1998) which is the largest electronic lexical database. In addition to the linguistic schemata features based on Vendler’s theory, we used thematic role features and an external knowledge feature. 2.1 Background Vendler (1967) proposes that verb meanings can be categorized into four basic classes, states, activities, achievements, and accomplishments, depending on interactions between the verbs and their aspectual and temporal modifier</context>
<context position="18141" citStr="Vendler (1967)" startWordPosition="3000" endWordPosition="3001">enerate a single value for a verb, we combine multiple probability values using the following sigmoid function: 1 t + e − (2) t =Ed∈DwPd Evidence of a word w being an action in eHow is denoted as E(w) where variable t is the sum of individual action probability values in Dw the set of documents from which the word w has been extracted as an action. The higher probability a word gets and the more frequent the word has been extracted as an action, the more evidence we get. 2.5 Classification For training, we selected 80 seed verbs from Dowty’s list (1979) which are representative verbs for each Vendler (1967) class. The selection was based on the lack of word sense ambiguity. One of our classifiers is based on Maximum Entropy (ME) models that implement the intuition that the best model will be the one that is consistent with the set of constraints imposed by the evidence, but otherwise is as uniform as possible (Berger et al., 1996). ME models are widely used in natural language processing tasks for its flexibility to incorporate a diverse range of features. The other one is based on Support Vector Machine (Chang and Lin, 2001) which is the state-of-the-art algorithm for many classification tasks.</context>
<context position="31408" citStr="Vendler, 1967" startWordPosition="5141" endWordPosition="5142">extensively (see Pang and Lee’s excellent survey (2008)), another sub-area, factuality analysis, begins to gain some popularity (Inui et al., 2008; Saurí, 2008). Very few studies have focused explicitly on extracting various entities that constitute experiences (Kurashima et al., 2009) or detecting experience-containing parts of text although many NLP research areas such as named entity recognition and verb classification are strongly related. The previous work on experience detection relies on a handcrafted lexicon. There have been a number of studies for verb classification (Fillmore, 1968; Vendler, 1967; Somers, 1982; Levin, 1993; Fillmore and Baker, 2001; Kipper et al., 2008) that are essential for construction of an activity verb lexicon, which in turn is important for experience detection. Most similar to our work was done by Siegel and McKeown (2000), who attempted to categorize verbs into state or event classes based on 14 tests similar to those of Vendler’s. They attempted to compute co-occurrence statistics from a corpus. The event class, however, includes activity, accomplishment, and achievement. Similarly, Zacrone and Lenci (2008) attempted to categorize verbs in Italian into the f</context>
</contexts>
<marker>Vendler, 1967</marker>
<rawString>Zeno Vendler. 1967. Linguistics in Philosophy. Cornell University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandra Zarcone</author>
<author>Alessandro Lenci</author>
</authors>
<title>Computational Models of Event Type Classification in Context.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC.</booktitle>
<marker>Zarcone, Lenci, 2008</marker>
<rawString>Alessandra Zarcone and Alessandro Lenci. 2008. Computational Models of Event Type Classification in Context. In Proceedings of LREC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>