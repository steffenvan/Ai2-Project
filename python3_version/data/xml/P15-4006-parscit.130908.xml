<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001428">
<title confidence="0.9960275">
NEED4Tweet: A Twitterbot for Tweets Named Entity Extraction and
Disambiguation
</title>
<author confidence="0.729105">
Mena B. Habib
</author>
<affiliation confidence="0.874680666666667">
Database Chair
University of Twente
Enschede, The Netherlands
</affiliation>
<email confidence="0.996645">
m.b.habib@ewi.utwente.nl
</email>
<sectionHeader confidence="0.993848" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999932368421053">
In this demo paper, we present
NEED4Tweet, a Twitterbot for named en-
tity extraction (NEE) and disambiguation
(NED) for Tweets. The straightforward
application of state-of-the-art extraction
and disambiguation approaches on infor-
mal text widely used in Tweets, typically
results in significantly degraded perfor-
mance due to the lack of formal structure;
the lack of sufficient context required;
and the seldom entities involved. In this
paper, we introduce a novel framework
that copes with the introduced challenges.
We rely on contextual and semantic
features more than syntactic features
which are less informative. We believe
that disambiguation can help to improve
the extraction process. This mimics the
way humans understand language.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999876157894737">
Twitter is an important source for continuously
and instantly updated information. It contains a
large amount of unstructured information about
users, locations, events, etc. Shortness and infor-
mality of Tweets are challenges for Natural Lan-
guage Processing (NLP) tasks. Information Ex-
traction (IE) is the NLP field of research that is
concerned with obtaining structured information
from unstructured text. IE systems attempt to in-
terpret human language text in order to extract in-
formation about different types of events, entities,
or relationships. Named entity extraction (NEE) is
a subtask of IE that aims to locate phrases (men-
tions) in the text that represent names of persons,
organizations, or locations regardless of their type.
Named entity disambiguation (NED) is the task of
determining which concrete person, place, event,
etc. is referred to by a mention. Wikipedia articles
are widely used as an entity’s reference.
</bodyText>
<note confidence="0.661724">
Maurice van Keulen
</note>
<affiliation confidence="0.735540333333333">
Database Chair
University of Twente
Enschede, The Netherlands
</affiliation>
<email confidence="0.936961">
m.vankeulen@utwente.nl
</email>
<bodyText confidence="0.819425">
Challenges: NEE and NED in informal text are
challenging. Here we summarize the challenges of
NEE and NED for Tweets:
</bodyText>
<listItem confidence="0.958705611111111">
• The informal language widely used in Tweets
makes the extraction process more difficult.
Proper capitalization is a key feature that the
state-of-the-art NEE approaches have relied
on. However, this feature gets less atten-
tion from Twitter users when they write their
Tweets.
• The limited length (140 characters) of Tweets
forces the senders to provide dense informa-
tion by using acronyms and informal lan-
guage. This makes both the extraction and
the disambiguation processes more complex.
• The limited coverage of a Knowledge Base
(KB) is another challenge facing NED for
tweets. According to (Lin et al., 2012), 5 mil-
lion out of 15 million mentions on the Web
cannot be linked to Wikipedia. This means
that relying only on a KB for NED leads to
around 33% loss in the disambiguated enti-
ties. This percentage is higher on Twitter be-
cause of its social nature where users also dis-
cuss information about seldom entities.
• The processes of NEE and NED involve
degrees of uncertainty. For example, in
the tweet “history should show that bush jr
should be in jail or at least never should
have been president”, for some NEE systems,
it may be uncertain whether the word ‘jr’
should be part of the mention bush or not.
This motivates us to fundamentally consider
sets of possible alternatives in an early stage
of the extraction and the disambiguation pro-
cesses and do a later filtration instead of mak-
ing hard decisions from the beginning.
• Named entity (NE) representation in KBs
poses another NED challenge. The YAGO
</listItem>
<page confidence="0.997944">
31
</page>
<note confidence="0.69868">
Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 31–36,
Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP
</note>
<bodyText confidence="0.99877404">
KB (Suchanek et al., 2007) uses the
Wikipedia anchor text as a possible mention
representation for named entities. However,
there may be more representations that do
not appear in the Wikipedia anchor text, but
are meant to refer to the entity because of a
spelling mistake or because of a new abbre-
viation for the entity.
In this demo, we introduce NEED4Tweet, a
Twitterbot for a combined system for NEE and
NED in Tweets that uses their interdependency
and mimics how humans exploit it in language
understanding. The system is based on our work
(Habib and van Keulen, 2015). We use a generic
open world approach for NED in Tweets for any
named entity even though it has no Wikipedia ar-
ticle. Mentions are disambiguated by assigning
them to either a Wikipedia article or a home page.
We handle the uncertainty involved in the extrac-
tion process by considering possible alternatives
in an early stage then evaluate these alternatives
later based on disambiguation outcomes. The pro-
posed approach is shown to be robust against the
coverage of KBs and the informality of the used
language.
</bodyText>
<sectionHeader confidence="0.999818" genericHeader="introduction">
2 Related work
</sectionHeader>
<subsectionHeader confidence="0.997248">
2.1 Named Entity Disambiguation
</subsectionHeader>
<bodyText confidence="0.999972083333333">
NED in Web documents is a topic that is well
covered in literature. Recently, researchers have
attempted NED for informal short text such as
Tweets. Most of this research investigate the prob-
lem of entity-oriented disambiguation. Within this
theme, (Spina et al., 2011), (Christoforaki et al.,
2011), (Yerva et al., 2012) and (Delgado et al.,
2012) focus on the task of filtering Tweets con-
taining a given a mention of topic-centric entity,
depending whether the Tweet is actually related to
the entity or not. They develop a set of features
(co-occurrence, Web-based features, collection-
based features) to find keywords for positive and
negative cases.
Similar to our problem discussed in Section 3.2,
is the problem of entity home page finding, which
was part of the TREC Web and entity tracks.
One of the proposed approaches for this task was
(Westerveld et al., 2002). The authors combine
content information with other sources as diverse
as inlinks, URLs and anchors to find an entry page.
Although the TREC problem looks similar to ours,
the Tweets’ short informal nature makes it more
tricky to find an entity reference page.
</bodyText>
<subsectionHeader confidence="0.996705">
2.2 Named Entity Extraction
</subsectionHeader>
<bodyText confidence="0.999945363636364">
Many tools and services have been developed for
the NEE task in web documents written in for-
mal language. In spite of this, few research efforts
studied NEE in Tweets. In (Ritter et al., ), the au-
thors built an NLP pipeline to perform NEE. The
pipeline involves part-of-speech tagging, shallow
parsing, and a novel SVM classifier that predicts
the informativeness of capitalization in a Tweet. It
trains a Conditional Random Fields (CRF) model
with all the aforementioned features for NEE. For
classification, LabeledLDA is applied where entity
types are used as classes. A bag-of-words-based
profile is generated for each entity type, and the
same is done with each extracted mention. Clas-
sification is done based on the comparison of the
two.
The contextual relationship between the micro-
posts is considered by (Jung, 2012). The pa-
per proposes merging the microtexts by discov-
ering contextual relationship between the micro-
texts. A group of microtexts contextually linked
with each other is regarded as a microtext clus-
ter. Once this microtext cluster is obtained, they
expect that the performance of NEE can be better.
The authors provide some suggestions for Contex-
tual closure, Microtext cluster, Semantic closure,
Temporal closure, and Social closure. Those clo-
sures are used by Maximum Entropy for the NER
task.
Similarly, (Li et al., 2012) exploits the gregari-
ous property in the local context derived from the
Twitter stream in an unsupervised manner. The
system first leverages the global context obtained
from Wikipedia and Web N-Gram corpus to par-
tition Tweets into valid segments (phrases) using
a dynamic programming algorithm. Each such
Tweet segment is a candidate NE. Afterwards, a
ranking approach tries to rank segments according
to their probability of being an NE. The highly-
ranked segments have a higher chance of being
true NEs. Each segment is represented as a node
in a graph, and using the Wikipedia and the con-
text of Tweet (adjacent nodes (segments)), a score
is assigned to that segment if it is an NE or not.
</bodyText>
<page confidence="0.98893">
32
</page>
<figure confidence="0.998269454545455">
Extraction
Traditional Approaches For NEE &amp; NED
Disambiguation
Extraction
Phase1: NE Candidates
Generation
Our Approach For NEE &amp; NED
Disambiguation
Extraction
Phase2: NE Candidates
Filtering
</figure>
<figureCaption confidence="0.999887">
Figure 1: Traditional approaches versus our approach for NEE and NED.
</figureCaption>
<sectionHeader confidence="0.908213" genericHeader="method">
3 NEED4Tweet
</sectionHeader>
<bodyText confidence="0.999973833333333">
Although the logical order for a traditional IE
system is to complete the extraction process be-
fore commencing with the disambiguation pro-
cess, we start with an initial extraction-like phase
aiming for high recall (i.e. aiming to find as many
reasonable mention candidates as possible). We
then attempt disambiguation for all the extracted
mentions. Finally we classify extracted mention
candidates into true and false NE using features
(clues) derived from the results of the disambigua-
tion phase such as KB information and entity co-
herency. Figure 1 illustrates our general approach
contrasted with the traditional process.
The potential of this order is that the disam-
biguation step gives extra clues (such as Entity-
Tweet context similarity) about each NE candi-
date. This information can help in the decision
whether the candidate is a true NE or not.
</bodyText>
<subsectionHeader confidence="0.998378">
3.1 Mention Candidates Generation
</subsectionHeader>
<bodyText confidence="0.9974375">
This phase is aiming to find as many reasonable
mention candidates as possible. For this task, we
unionize the output of the following mention can-
didates generation methods:
</bodyText>
<listItem confidence="0.99646725">
• Tweet Segmentation: Tweet text is seg-
mented using the segmentation algorithm de-
scribed in (Li et al., 2012). Each segment is
considered a mention candidate.
• KB Lookup: We scan all possible n-grams of
the Tweet against the mentions-entities table
of YAGO KB. N-grams that matches a YAGO
mention are considered mention candidates.
</listItem>
<subsectionHeader confidence="0.986665">
3.2 Disambiguation
</subsectionHeader>
<bodyText confidence="0.997151428571429">
For NED, we use a generic open world NED
approach where mentions are disambiguated by
assigning them to either a Wikipedia article
(Wikipedia entity) or a home page (non-Wikipedia
entity) (Habib and van Keulen, 2013). The NED
approach is composed of three modules; matcher,
feature extractor, and SVM ranker.
</bodyText>
<listItem confidence="0.982556">
• Matcher: This module is responsible for
</listItem>
<bodyText confidence="0.864412">
finding the possible candidate entities of a
given mention. For this task, we use the
mention-entity table of YAGO KB to get the
possible entities for the given mention. Fur-
thermore, we use the mention as an input
query for the Google API. The top 18 Web
pages retrieved by Google are also consid-
ered candidate entities for that mention.
</bodyText>
<listItem confidence="0.885682722222222">
• Feature Extractor: For each entity page
candidate, we extract a set of context and
URL features. Context features (such as
language model and overlapping terms be-
tween tweet and document) measure the
context similarity between mention context
(the tweet text) and entity candidates’ home
pages. URL features (such as path length and
mention-URL string similarity) measure the
likelihood of the candidate URL being a rep-
resentative of the entity home page. These
features give indicators on how likely the
candidate entity page could be a representa-
tive to the mention.
• SVM Ranker: After extracting the afore-
mentioned set of features, SVM classifier is
used to rank candidate entity pages of a men-
tion. We consider the top ranked page to be
</listItem>
<page confidence="0.998276">
33
</page>
<bodyText confidence="0.9993585">
the entity of the input mention. In this demo,
we use an SVM which is trained on the two
NED datasets presented in (Habib and van
Keulen, 2013).
</bodyText>
<subsectionHeader confidence="0.998761">
3.3 Mention Candidates Filtering
</subsectionHeader>
<bodyText confidence="0.994409142857143">
After generating the mentions candidate list, we
apply our disambiguate approach to disambiguate
each mention candidate. After that, we use another
SVM classifier to predict which mention candi-
dates are true positives and which ones are not. For
each mention candidate, we extract the following
set of features :
</bodyText>
<listItem confidence="0.98911725">
• Shape Features: If the mention candidate is
initially or fully capitalized and if it contains
digits.
• Probabilistic Features:
</listItem>
<bodyText confidence="0.9509258">
– The joint and conditional probability of
the mention candidate obtained from the
Microsoft Web N-Gram service.
– The stickiness of the segment as de-
scribed in (Li et al., 2012).
</bodyText>
<listItem confidence="0.873531181818182">
– The segment frequency over around
5 million tweets1.
• KB Features:
– Whether the segment appears in Word-
Net.
– Whether the segment appears in the
YAGO mention-entity look-up table.
• Disambiguation Features: All the features
described in Section 3.2 derived from the en-
tity page linked to the given mention candi-
date.
</listItem>
<bodyText confidence="0.99940675">
In this demo, we use an SVM which is trained
on four different NEE datasets presented in (Ritter
et al., ), (Basave et al., 2013), (Locke and Martin,
2009), and (Habib and van Keulen, 2012).
</bodyText>
<subsectionHeader confidence="0.950051">
3.4 Final NE Set Generation
</subsectionHeader>
<bodyText confidence="0.999342428571429">
Beside the SVM, we also use a trained CRF model
for NEE. We use the CRF model described in (Zhu
et al., 2014) trained on the four collections men-
tioned in Section 3.3. To train the CRF, Tweet text
is tokenized using a special tweet tokenizer (Gim-
pel et al., 2011) and the following features are ex-
tracted and used for training:
</bodyText>
<footnote confidence="0.954634">
1http://wis.ewi.tudelft.nl/umap2011/ +
TREC 2011 Microblog track collection.
</footnote>
<figure confidence="0.99444375">
(a) Example 1: Tweet for testing both NEE and NED.
(b) Example 2: Tweet for testing NED only.
(d) Results of example 1
(e) Results of example 2
</figure>
<figureCaption confidence="0.999382">
Figure 2: NEED4Tweet Twitterbot
</figureCaption>
<listItem confidence="0.978909285714286">
• The Part of Speech (POS) tag of the token
provided by a special POS tagger designed
for tweets (Gimpel et al., 2011).
• Whether the token’s initial is capitalized.
• Whether the token’s characters are all capi-
talized.
• Whether the token has any capital letters.
</listItem>
<bodyText confidence="0.999782181818182">
We consider the best annotation set for the tweet
given by the CRF model as true positives. To gen-
erate the final NE set, we take the union of the
CRF annotation set (after being disambiguated)
and the SVM results, after removing duplicate and
overlapped extractions. To resolve the overlapped
mentions, we select the mention that appears in
Yago KB. If both mentions appear in Yago or both
don’t, we select the one with the longer length.
The idea behind this combination is that the
SVM and the CRF work in a different way. The
</bodyText>
<listItem confidence="0.889976">
(c) Tweet reply.
</listItem>
<page confidence="0.998019">
34
</page>
<bodyText confidence="0.999470636363636">
former is a distance based classifier that uses nu-
meric features for classification which CRF can
not handle, while the latter is a probabilistic model
that can naturally consider state-to-state depen-
dencies and feature-to-state dependencies. On the
other hand, SVM does not consider such depen-
dencies. The hybrid approach of both makes use
of the strength of each. While the CRF makes
better use of the traditional features like POS and
Capitalization, the SVM makes better use of the
disambiguation (coherency) features.
</bodyText>
<sectionHeader confidence="0.994921" genericHeader="method">
4 Twitterbot
</sectionHeader>
<bodyText confidence="0.999978863636363">
A Twitterbot is a program used to produce au-
tomated posts on the Twitter microblogging ser-
vice. We developed our system as a Twitter-
bot which receives the Tweet, processes it and
sends a reply message contains a link to a page
that shows the generated annotations. We use
Twitter API2 for both receiving the Tweets and
sending the replies. To use NEED4Tweet Twit-
terbot, one should send a Tweet contains either
the mention ‘@UT NEED4Tweet’ or the hashtag
‘#NEED4Tweet’ as shown in Figures 2(a) and 2(b)
respectively. Withing few seconds after sending
the tweet, the sender will get a reply Tweet (see
Figure 2(c)) that includes link to a simple HTML
page contains the generated annotations (see Fig-
ures 2(d) and 2(e)). The page contains a list of
the extracted mentions, their start offset in the
Tweet, and their linked entities. It is also possi-
ble to test only the disambiguation component by
manually coating the mentions required to be dis-
ambiguated using double square brackets ([[]])as
shown in Figure 2(b).
</bodyText>
<sectionHeader confidence="0.993143" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.997666">
5.1 Data sets
</subsectionHeader>
<bodyText confidence="0.999108727272727">
To validate our approach, we use three collections
of tweets. The first two data sets are mainly de-
signed for a NER task. We manually construct the
NED ground truth by linking each NE to only one
appropriate entity page. We give higher priority to
Wikipedia pages. When no Wikipedia page exists
for a mention, we link it to a non-Wikipedia home
page or profile page.
The first data set (Locke collection) is the one
used in (Locke and Martin, 2009). The second
data set (Habib collection) is the one used in
</bodyText>
<footnote confidence="0.950681">
2https://dev.twitter.com/
</footnote>
<table confidence="0.970832666666667">
(a) Locke collection
Pre. Rec. F1
DBpedia Spotlight 0.1004 0.2669 0.1459
Stanford + AIDA 0.5005 0.2940 0.3704
NEED4Tweet 0.5455 0.5640 0.5546
(b) Habib collection
Pre. Rec. F1
DBpedia Spotlight 0.3711 0.5333 0.4377
Stanford + AIDA 0.7263 0.5569 0.6304
NEED4Tweet 0.6861 0.7157 0.7006
(c) #Microposts collection
Pre. Rec. F1
DBpedia Spotlight 0.1873 0.3349 0.2403
Stanford + AIDA 0.5092 0.2795 0.3609
NEED4Tweet 0.5337 0.5343 0.5339
</table>
<tableCaption confidence="0.999943">
Table 1: Combined evaluation of NEE and NED.
</tableCaption>
<bodyText confidence="0.999808933333334">
(Habib and van Keulen, 2012) which is relatively
small in the number of tweets but rich in the num-
ber of NEs. It is composed mainly from tweeted
news about sportsmen, celebrities, politics, etc.
The third data set (#Microposts collection)
is provided by the #Microposts Named Entity
Extraction &amp; Linking (NEEL) Challenge (Cano
Basave et al., 2014). The NEEL Challenge task
required participants to build systems to extract
entity mentions from a tweet and to link the ex-
tracted mentions to DBpedia. Note that this data
set does not contain any non-Wikipedia entities.
We have done the mapping from the YAGO KB to
DBpedia by identifying the Wikipedia page as a
common property for the identical entities.
</bodyText>
<subsectionHeader confidence="0.995643">
5.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999572416666667">
In this experiment, we compare the performance
of NEED4Tweet against two competitors: AIDA3
and DBpedia Spotlight.4 AIDA is a disambigua-
tion system although it uses Stanford NER for
automatic NE extraction. We consider the com-
bination of Stanford NER and the AIDA disam-
biguation system as one competitor to our extrac-
tion and disambiguation system. DBpedia Spot-
light (Mendes et al., 2011) is a tool for automat-
ically annotating mentions of DBpedia resources
in text. We used DBpedia Spotlight through its
Annotate Web Service endpoint. We used the
</bodyText>
<footnote confidence="0.9965335">
3https://d5gate.ag5.mpi-sb.mpg.de/
webaida/
4https://github.com/dbpedia-spotlight/
dbpedia-spotlight/wiki
</footnote>
<page confidence="0.998991">
35
</page>
<bodyText confidence="0.999618833333333">
NESpotter implementation for the extraction con-
figuration. The results in Table 1 show the superi-
ority of NEED4Tweet over DBpedia Spotlight and
the combined Stanford and AIDA system. More
experimental results and analysis can be found in
(Habib and van Keulen, 2015).
</bodyText>
<sectionHeader confidence="0.999172" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999996733333333">
In this demo paper, we present NEED4Tweet, a
Twitterbot for NEE and NED in tweets. The sys-
tem is composed of three phases. The first phase
aims to generate NE candidates with an emphasis
on achieving high recall. The second phase aims
to disambiguate all the candidates generated in the
first phase. For this task, we use a generic non-
entity oriented disambiguation approach. Men-
tions are disambiguated by assigning them to ei-
ther a Wikipedia article or a home page. Finally,
the third phase is to filter the NE candidates using
features derived from disambiguation and other
shape and KB features. The proposed approach
is shown to be robust against the coverage of KBs
and the informality of the used language.
</bodyText>
<sectionHeader confidence="0.99814" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999797688311688">
Amparo Elizabeth Cano Basave, Andrea Varga,
Matthew Rowe, Milan Stankovic, and Aba-Sah
Dadzie. 2013. Making sense of microposts
(#msm2013) concept extraction challenge. In Mak-
ing Sense of Microposts (#MSM2013) Concept Ex-
traction Challenge, pages 1–15.
Amparo Elizabeth Cano Basave, Giuseppe Rizzo, An-
drea Varga, Matthew Rowe, Milan Stankovic, and
Aba-Sah Dadzie. 2014. Making sense of microp-
osts (#microposts2014) named entity extraction &amp;
linking challenge. In Proc. of (#Microposts2014)
Workshop, pages 54–60.
Maria Christoforaki, Ivie Erunse, and Cong Yu. 2011.
Searching social updates for topic-centric entities.
In Proc. of exploreWeb 2011 Workshop, pages 34–
39.
A. D. Delgado, R. Mart’ınez, A. P´erez Garc’ıa-Plaza,
and V. Fresno. 2012. Unsupervised Real-Time com-
pany name disambiguation in twitter. In Proc. of
RAMSS 2012 Workshop, pages 25–28.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: annotation, features, and experiments. In
Proc. of ACL 2011, HLT ’11, pages 42–47.
Mena B. Habib and Maurice van Keulen. 2012. Unsu-
pervised improvement of named entity extraction in
short informal context using disambiguation clues.
In Proc. of SWAIE 2012 Workshop, pages 1–10.
Mena B. Habib and M. van Keulen. 2013. A generic
open world named entity disambiguation approach
for tweets. In Proc. of KDIR 2013, pages 267–276.
Mena B. Habib and Maurice van Keulen. 2015. Twit-
terneed: A hybrid approach for named entity extrac-
tion and disambiguation for tweets. To appear in the
journal of Natural Language Engineering.
Jason J. Jung. 2012. Online named entity recogni-
tion method for microtexts in social networking ser-
vices: A case study of twitter. Expert Syst. Appl.,
39(9):8066–8070.
Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao, An-
witaman Datta, Aixin Sun, and Bu-Sung Lee. 2012.
Twiner: named entity recognition in targeted twitter
stream. In Proc. of SIGIR 2012, pages 721–730.
Thomas Lin, Mausam, and Oren Etzioni. 2012. En-
tity linking at web scale. In Proc. of AKBC-WEKEX
2012 Workshop, pages 84–88.
Brian Locke and James Martin. 2009. Named en-
tity recognition: Adapting to microblogging. Senior
Thesis, University of Colorado.
Pablo N. Mendes, Max Jakob, Andr´es Garc´ıa-Silva,
and Christian Bizer. 2011. Dbpedia spotlight: Shed-
ding light on the web of documents. In Proc. of I-
Semantics 2011, pages 1–8.
A. Ritter, S. Clark, Mausam, and O. Etzioni. Named
entity recognition in tweets: An experimental study.
In Proc. of EMNLP 2011, pages 1524–1534.
Damiano Spina, Enrique Amig´o, and Julio Gonzalo.
2011. Filter keywords and majority class strate-
gies for company name disambiguation in twitter. In
Proc. of CLEF 2011, pages 50–61.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge. In Proc. of WWW 2007, pages 697–706.
Thijs Westerveld, Wessel Kraaij, and Djoerd Hiemstra.
2002. Retrieving web pages using content, links,
urls and anchors. In Tenth Text REtrieval Confer-
ence, TREC 2001, volume SP 500, pages 663–672.
Surender Reddy Yerva, Zolt´an Mikl´os, and Karl
Aberer. 2012. Entity-based classification of twitter
messages. IJCSA, 9(1):88–115.
Zhemin Zhu, Djoerd Hiemstra, and Peter Apers. 2014.
Linear co-occurrence rate networks (l-crns) for se-
quence labeling. In Statistical language and speech
processing, volume 8791 of Lecture notes in com-
puter science, pages 185–196.
</reference>
<page confidence="0.998939">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.497947">
<title confidence="0.974246">NEED4Tweet: A Twitterbot for Tweets Named Entity Extraction Disambiguation</title>
<author confidence="0.761743">B Mena</author>
<affiliation confidence="0.888276666666667">Database University of Enschede, The</affiliation>
<email confidence="0.982893">m.b.habib@ewi.utwente.nl</email>
<abstract confidence="0.9994633">In this demo paper, we present NEED4Tweet, a Twitterbot for named entity extraction (NEE) and disambiguation (NED) for Tweets. The straightforward application of state-of-the-art extraction and disambiguation approaches on informal text widely used in Tweets, typically results in significantly degraded performance due to the lack of formal structure; the lack of sufficient context required; and the seldom entities involved. In this paper, we introduce a novel framework that copes with the introduced challenges. We rely on contextual and semantic features more than syntactic features which are less informative. We believe that disambiguation can help to improve the extraction process. This mimics the way humans understand language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amparo Elizabeth Cano Basave</author>
<author>Andrea Varga</author>
<author>Matthew Rowe</author>
<author>Milan Stankovic</author>
<author>Aba-Sah Dadzie</author>
</authors>
<title>Making sense of microposts (#msm2013) concept extraction challenge. In Making Sense of Microposts (#MSM2013) Concept Extraction Challenge,</title>
<date>2013</date>
<pages>1--15</pages>
<contexts>
<context position="12461" citStr="Basave et al., 2013" startWordPosition="2015" endWordPosition="2018">t and conditional probability of the mention candidate obtained from the Microsoft Web N-Gram service. – The stickiness of the segment as described in (Li et al., 2012). – The segment frequency over around 5 million tweets1. • KB Features: – Whether the segment appears in WordNet. – Whether the segment appears in the YAGO mention-entity look-up table. • Disambiguation Features: All the features described in Section 3.2 derived from the entity page linked to the given mention candidate. In this demo, we use an SVM which is trained on four different NEE datasets presented in (Ritter et al., ), (Basave et al., 2013), (Locke and Martin, 2009), and (Habib and van Keulen, 2012). 3.4 Final NE Set Generation Beside the SVM, we also use a trained CRF model for NEE. We use the CRF model described in (Zhu et al., 2014) trained on the four collections mentioned in Section 3.3. To train the CRF, Tweet text is tokenized using a special tweet tokenizer (Gimpel et al., 2011) and the following features are extracted and used for training: 1http://wis.ewi.tudelft.nl/umap2011/ + TREC 2011 Microblog track collection. (a) Example 1: Tweet for testing both NEE and NED. (b) Example 2: Tweet for testing NED only. (d) Results</context>
</contexts>
<marker>Basave, Varga, Rowe, Stankovic, Dadzie, 2013</marker>
<rawString>Amparo Elizabeth Cano Basave, Andrea Varga, Matthew Rowe, Milan Stankovic, and Aba-Sah Dadzie. 2013. Making sense of microposts (#msm2013) concept extraction challenge. In Making Sense of Microposts (#MSM2013) Concept Extraction Challenge, pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amparo Elizabeth Cano Basave</author>
<author>Giuseppe Rizzo</author>
<author>Andrea Varga</author>
<author>Matthew Rowe</author>
<author>Milan Stankovic</author>
<author>Aba-Sah Dadzie</author>
</authors>
<title>Making sense of microposts (#microposts2014) named entity extraction &amp; linking challenge.</title>
<date>2014</date>
<booktitle>In Proc. of (#Microposts2014) Workshop,</booktitle>
<pages>54--60</pages>
<contexts>
<context position="16882" citStr="Basave et al., 2014" startWordPosition="2759" endWordPosition="2762">333 0.4377 Stanford + AIDA 0.7263 0.5569 0.6304 NEED4Tweet 0.6861 0.7157 0.7006 (c) #Microposts collection Pre. Rec. F1 DBpedia Spotlight 0.1873 0.3349 0.2403 Stanford + AIDA 0.5092 0.2795 0.3609 NEED4Tweet 0.5337 0.5343 0.5339 Table 1: Combined evaluation of NEE and NED. (Habib and van Keulen, 2012) which is relatively small in the number of tweets but rich in the number of NEs. It is composed mainly from tweeted news about sportsmen, celebrities, politics, etc. The third data set (#Microposts collection) is provided by the #Microposts Named Entity Extraction &amp; Linking (NEEL) Challenge (Cano Basave et al., 2014). The NEEL Challenge task required participants to build systems to extract entity mentions from a tweet and to link the extracted mentions to DBpedia. Note that this data set does not contain any non-Wikipedia entities. We have done the mapping from the YAGO KB to DBpedia by identifying the Wikipedia page as a common property for the identical entities. 5.2 Experimental Results In this experiment, we compare the performance of NEED4Tweet against two competitors: AIDA3 and DBpedia Spotlight.4 AIDA is a disambiguation system although it uses Stanford NER for automatic NE extraction. We consider</context>
</contexts>
<marker>Basave, Rizzo, Varga, Rowe, Stankovic, Dadzie, 2014</marker>
<rawString>Amparo Elizabeth Cano Basave, Giuseppe Rizzo, Andrea Varga, Matthew Rowe, Milan Stankovic, and Aba-Sah Dadzie. 2014. Making sense of microposts (#microposts2014) named entity extraction &amp; linking challenge. In Proc. of (#Microposts2014) Workshop, pages 54–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Christoforaki</author>
<author>Ivie Erunse</author>
<author>Cong Yu</author>
</authors>
<title>Searching social updates for topic-centric entities.</title>
<date>2011</date>
<booktitle>In Proc. of exploreWeb 2011 Workshop,</booktitle>
<pages>34--39</pages>
<contexts>
<context position="5180" citStr="Christoforaki et al., 2011" startWordPosition="822" endWordPosition="825">nty involved in the extraction process by considering possible alternatives in an early stage then evaluate these alternatives later based on disambiguation outcomes. The proposed approach is shown to be robust against the coverage of KBs and the informality of the used language. 2 Related work 2.1 Named Entity Disambiguation NED in Web documents is a topic that is well covered in literature. Recently, researchers have attempted NED for informal short text such as Tweets. Most of this research investigate the problem of entity-oriented disambiguation. Within this theme, (Spina et al., 2011), (Christoforaki et al., 2011), (Yerva et al., 2012) and (Delgado et al., 2012) focus on the task of filtering Tweets containing a given a mention of topic-centric entity, depending whether the Tweet is actually related to the entity or not. They develop a set of features (co-occurrence, Web-based features, collectionbased features) to find keywords for positive and negative cases. Similar to our problem discussed in Section 3.2, is the problem of entity home page finding, which was part of the TREC Web and entity tracks. One of the proposed approaches for this task was (Westerveld et al., 2002). The authors combine conten</context>
</contexts>
<marker>Christoforaki, Erunse, Yu, 2011</marker>
<rawString>Maria Christoforaki, Ivie Erunse, and Cong Yu. 2011. Searching social updates for topic-centric entities. In Proc. of exploreWeb 2011 Workshop, pages 34– 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A D Delgado</author>
<author>R Mart’ınez</author>
<author>A P´erez Garc’ıa-Plaza</author>
<author>V Fresno</author>
</authors>
<title>Unsupervised Real-Time company name disambiguation in twitter.</title>
<date>2012</date>
<booktitle>In Proc. of RAMSS 2012 Workshop,</booktitle>
<pages>25--28</pages>
<marker>Delgado, Mart’ınez, Garc’ıa-Plaza, Fresno, 2012</marker>
<rawString>A. D. Delgado, R. Mart’ınez, A. P´erez Garc’ıa-Plaza, and V. Fresno. 2012. Unsupervised Real-Time company name disambiguation in twitter. In Proc. of RAMSS 2012 Workshop, pages 25–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proc. of ACL 2011, HLT ’11,</booktitle>
<pages>42--47</pages>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: annotation, features, and experiments. In Proc. of ACL 2011, HLT ’11, pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mena B Habib</author>
<author>Maurice van Keulen</author>
</authors>
<title>Unsupervised improvement of named entity extraction in short informal context using disambiguation clues.</title>
<date>2012</date>
<booktitle>In Proc. of SWAIE 2012 Workshop,</booktitle>
<pages>1--10</pages>
<marker>Habib, van Keulen, 2012</marker>
<rawString>Mena B. Habib and Maurice van Keulen. 2012. Unsupervised improvement of named entity extraction in short informal context using disambiguation clues. In Proc. of SWAIE 2012 Workshop, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mena B Habib</author>
<author>M van Keulen</author>
</authors>
<title>A generic open world named entity disambiguation approach for tweets.</title>
<date>2013</date>
<booktitle>In Proc. of KDIR</booktitle>
<pages>267--276</pages>
<marker>Habib, van Keulen, 2013</marker>
<rawString>Mena B. Habib and M. van Keulen. 2013. A generic open world named entity disambiguation approach for tweets. In Proc. of KDIR 2013, pages 267–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mena B Habib</author>
<author>Maurice van Keulen</author>
</authors>
<title>Twitterneed: A hybrid approach for named entity extraction and disambiguation for tweets.</title>
<date>2015</date>
<journal>the journal of Natural Language Engineering.</journal>
<note>To appear in</note>
<marker>Habib, van Keulen, 2015</marker>
<rawString>Mena B. Habib and Maurice van Keulen. 2015. Twitterneed: A hybrid approach for named entity extraction and disambiguation for tweets. To appear in the journal of Natural Language Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason J Jung</author>
</authors>
<title>Online named entity recognition method for microtexts in social networking services: A case study of twitter.</title>
<date>2012</date>
<journal>Expert Syst. Appl.,</journal>
<volume>39</volume>
<issue>9</issue>
<contexts>
<context position="6867" citStr="Jung, 2012" startWordPosition="1101" endWordPosition="1102"> pipeline to perform NEE. The pipeline involves part-of-speech tagging, shallow parsing, and a novel SVM classifier that predicts the informativeness of capitalization in a Tweet. It trains a Conditional Random Fields (CRF) model with all the aforementioned features for NEE. For classification, LabeledLDA is applied where entity types are used as classes. A bag-of-words-based profile is generated for each entity type, and the same is done with each extracted mention. Classification is done based on the comparison of the two. The contextual relationship between the microposts is considered by (Jung, 2012). The paper proposes merging the microtexts by discovering contextual relationship between the microtexts. A group of microtexts contextually linked with each other is regarded as a microtext cluster. Once this microtext cluster is obtained, they expect that the performance of NEE can be better. The authors provide some suggestions for Contextual closure, Microtext cluster, Semantic closure, Temporal closure, and Social closure. Those closures are used by Maximum Entropy for the NER task. Similarly, (Li et al., 2012) exploits the gregarious property in the local context derived from the Twitte</context>
</contexts>
<marker>Jung, 2012</marker>
<rawString>Jason J. Jung. 2012. Online named entity recognition method for microtexts in social networking services: A case study of twitter. Expert Syst. Appl., 39(9):8066–8070.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenliang Li</author>
<author>Jianshu Weng</author>
<author>Qi He</author>
<author>Yuxia Yao</author>
<author>Anwitaman Datta</author>
<author>Aixin Sun</author>
<author>Bu-Sung Lee</author>
</authors>
<title>Twiner: named entity recognition in targeted twitter stream.</title>
<date>2012</date>
<booktitle>In Proc. of SIGIR 2012,</booktitle>
<pages>721--730</pages>
<contexts>
<context position="7389" citStr="Li et al., 2012" startWordPosition="1182" endWordPosition="1185">n of the two. The contextual relationship between the microposts is considered by (Jung, 2012). The paper proposes merging the microtexts by discovering contextual relationship between the microtexts. A group of microtexts contextually linked with each other is regarded as a microtext cluster. Once this microtext cluster is obtained, they expect that the performance of NEE can be better. The authors provide some suggestions for Contextual closure, Microtext cluster, Semantic closure, Temporal closure, and Social closure. Those closures are used by Maximum Entropy for the NER task. Similarly, (Li et al., 2012) exploits the gregarious property in the local context derived from the Twitter stream in an unsupervised manner. The system first leverages the global context obtained from Wikipedia and Web N-Gram corpus to partition Tweets into valid segments (phrases) using a dynamic programming algorithm. Each such Tweet segment is a candidate NE. Afterwards, a ranking approach tries to rank segments according to their probability of being an NE. The highlyranked segments have a higher chance of being true NEs. Each segment is represented as a node in a graph, and using the Wikipedia and the context of Tw</context>
<context position="9531" citStr="Li et al., 2012" startWordPosition="1527" endWordPosition="1530">strates our general approach contrasted with the traditional process. The potential of this order is that the disambiguation step gives extra clues (such as EntityTweet context similarity) about each NE candidate. This information can help in the decision whether the candidate is a true NE or not. 3.1 Mention Candidates Generation This phase is aiming to find as many reasonable mention candidates as possible. For this task, we unionize the output of the following mention candidates generation methods: • Tweet Segmentation: Tweet text is segmented using the segmentation algorithm described in (Li et al., 2012). Each segment is considered a mention candidate. • KB Lookup: We scan all possible n-grams of the Tweet against the mentions-entities table of YAGO KB. N-grams that matches a YAGO mention are considered mention candidates. 3.2 Disambiguation For NED, we use a generic open world NED approach where mentions are disambiguated by assigning them to either a Wikipedia article (Wikipedia entity) or a home page (non-Wikipedia entity) (Habib and van Keulen, 2013). The NED approach is composed of three modules; matcher, feature extractor, and SVM ranker. • Matcher: This module is responsible for findin</context>
<context position="12009" citStr="Li et al., 2012" startWordPosition="1936" endWordPosition="1939"> generating the mentions candidate list, we apply our disambiguate approach to disambiguate each mention candidate. After that, we use another SVM classifier to predict which mention candidates are true positives and which ones are not. For each mention candidate, we extract the following set of features : • Shape Features: If the mention candidate is initially or fully capitalized and if it contains digits. • Probabilistic Features: – The joint and conditional probability of the mention candidate obtained from the Microsoft Web N-Gram service. – The stickiness of the segment as described in (Li et al., 2012). – The segment frequency over around 5 million tweets1. • KB Features: – Whether the segment appears in WordNet. – Whether the segment appears in the YAGO mention-entity look-up table. • Disambiguation Features: All the features described in Section 3.2 derived from the entity page linked to the given mention candidate. In this demo, we use an SVM which is trained on four different NEE datasets presented in (Ritter et al., ), (Basave et al., 2013), (Locke and Martin, 2009), and (Habib and van Keulen, 2012). 3.4 Final NE Set Generation Beside the SVM, we also use a trained CRF model for NEE. W</context>
</contexts>
<marker>Li, Weng, He, Yao, Datta, Sun, Lee, 2012</marker>
<rawString>Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao, Anwitaman Datta, Aixin Sun, and Bu-Sung Lee. 2012. Twiner: named entity recognition in targeted twitter stream. In Proc. of SIGIR 2012, pages 721–730.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lin</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Entity linking at web scale.</title>
<date>2012</date>
<booktitle>In Proc. of AKBC-WEKEX 2012 Workshop,</booktitle>
<pages>84--88</pages>
<contexts>
<context position="2716" citStr="Lin et al., 2012" startWordPosition="404" endWordPosition="407"> • The informal language widely used in Tweets makes the extraction process more difficult. Proper capitalization is a key feature that the state-of-the-art NEE approaches have relied on. However, this feature gets less attention from Twitter users when they write their Tweets. • The limited length (140 characters) of Tweets forces the senders to provide dense information by using acronyms and informal language. This makes both the extraction and the disambiguation processes more complex. • The limited coverage of a Knowledge Base (KB) is another challenge facing NED for tweets. According to (Lin et al., 2012), 5 million out of 15 million mentions on the Web cannot be linked to Wikipedia. This means that relying only on a KB for NED leads to around 33% loss in the disambiguated entities. This percentage is higher on Twitter because of its social nature where users also discuss information about seldom entities. • The processes of NEE and NED involve degrees of uncertainty. For example, in the tweet “history should show that bush jr should be in jail or at least never should have been president”, for some NEE systems, it may be uncertain whether the word ‘jr’ should be part of the mention bush or no</context>
</contexts>
<marker>Lin, Mausam, Etzioni, 2012</marker>
<rawString>Thomas Lin, Mausam, and Oren Etzioni. 2012. Entity linking at web scale. In Proc. of AKBC-WEKEX 2012 Workshop, pages 84–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Locke</author>
<author>James Martin</author>
</authors>
<title>Named entity recognition: Adapting to microblogging. Senior Thesis,</title>
<date>2009</date>
<institution>University of Colorado.</institution>
<contexts>
<context position="12487" citStr="Locke and Martin, 2009" startWordPosition="2019" endWordPosition="2022">bility of the mention candidate obtained from the Microsoft Web N-Gram service. – The stickiness of the segment as described in (Li et al., 2012). – The segment frequency over around 5 million tweets1. • KB Features: – Whether the segment appears in WordNet. – Whether the segment appears in the YAGO mention-entity look-up table. • Disambiguation Features: All the features described in Section 3.2 derived from the entity page linked to the given mention candidate. In this demo, we use an SVM which is trained on four different NEE datasets presented in (Ritter et al., ), (Basave et al., 2013), (Locke and Martin, 2009), and (Habib and van Keulen, 2012). 3.4 Final NE Set Generation Beside the SVM, we also use a trained CRF model for NEE. We use the CRF model described in (Zhu et al., 2014) trained on the four collections mentioned in Section 3.3. To train the CRF, Tweet text is tokenized using a special tweet tokenizer (Gimpel et al., 2011) and the following features are extracted and used for training: 1http://wis.ewi.tudelft.nl/umap2011/ + TREC 2011 Microblog track collection. (a) Example 1: Tweet for testing both NEE and NED. (b) Example 2: Tweet for testing NED only. (d) Results of example 1 (e) Results </context>
<context position="15972" citStr="Locke and Martin, 2009" startWordPosition="2619" endWordPosition="2622"> disambiguation component by manually coating the mentions required to be disambiguated using double square brackets ([[]])as shown in Figure 2(b). 5 Evaluation 5.1 Data sets To validate our approach, we use three collections of tweets. The first two data sets are mainly designed for a NER task. We manually construct the NED ground truth by linking each NE to only one appropriate entity page. We give higher priority to Wikipedia pages. When no Wikipedia page exists for a mention, we link it to a non-Wikipedia home page or profile page. The first data set (Locke collection) is the one used in (Locke and Martin, 2009). The second data set (Habib collection) is the one used in 2https://dev.twitter.com/ (a) Locke collection Pre. Rec. F1 DBpedia Spotlight 0.1004 0.2669 0.1459 Stanford + AIDA 0.5005 0.2940 0.3704 NEED4Tweet 0.5455 0.5640 0.5546 (b) Habib collection Pre. Rec. F1 DBpedia Spotlight 0.3711 0.5333 0.4377 Stanford + AIDA 0.7263 0.5569 0.6304 NEED4Tweet 0.6861 0.7157 0.7006 (c) #Microposts collection Pre. Rec. F1 DBpedia Spotlight 0.1873 0.3349 0.2403 Stanford + AIDA 0.5092 0.2795 0.3609 NEED4Tweet 0.5337 0.5343 0.5339 Table 1: Combined evaluation of NEE and NED. (Habib and van Keulen, 2012) which is</context>
</contexts>
<marker>Locke, Martin, 2009</marker>
<rawString>Brian Locke and James Martin. 2009. Named entity recognition: Adapting to microblogging. Senior Thesis, University of Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo N Mendes</author>
<author>Max Jakob</author>
<author>Andr´es Garc´ıa-Silva</author>
<author>Christian Bizer</author>
</authors>
<title>Dbpedia spotlight: Shedding light on the web of documents.</title>
<date>2011</date>
<booktitle>In Proc. of ISemantics</booktitle>
<pages>1--8</pages>
<marker>Mendes, Jakob, Garc´ıa-Silva, Bizer, 2011</marker>
<rawString>Pablo N. Mendes, Max Jakob, Andr´es Garc´ıa-Silva, and Christian Bizer. 2011. Dbpedia spotlight: Shedding light on the web of documents. In Proc. of ISemantics 2011, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ritter</author>
<author>S Clark</author>
<author>Mausam</author>
<author>O Etzioni</author>
</authors>
<title>Named entity recognition in tweets: An experimental study.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP</booktitle>
<pages>1524--1534</pages>
<marker>Ritter, Clark, Mausam, Etzioni, 2011</marker>
<rawString>A. Ritter, S. Clark, Mausam, and O. Etzioni. Named entity recognition in tweets: An experimental study. In Proc. of EMNLP 2011, pages 1524–1534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Damiano Spina</author>
<author>Enrique Amig´o</author>
<author>Julio Gonzalo</author>
</authors>
<title>Filter keywords and majority class strategies for company name disambiguation in twitter.</title>
<date>2011</date>
<booktitle>In Proc. of CLEF</booktitle>
<pages>50--61</pages>
<marker>Spina, Amig´o, Gonzalo, 2011</marker>
<rawString>Damiano Spina, Enrique Amig´o, and Julio Gonzalo. 2011. Filter keywords and majority class strategies for company name disambiguation in twitter. In Proc. of CLEF 2011, pages 50–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In Proc. of WWW</booktitle>
<pages>697--706</pages>
<contexts>
<context position="3772" citStr="Suchanek et al., 2007" startWordPosition="588" endWordPosition="591">uld be in jail or at least never should have been president”, for some NEE systems, it may be uncertain whether the word ‘jr’ should be part of the mention bush or not. This motivates us to fundamentally consider sets of possible alternatives in an early stage of the extraction and the disambiguation processes and do a later filtration instead of making hard decisions from the beginning. • Named entity (NE) representation in KBs poses another NED challenge. The YAGO 31 Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 31–36, Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP KB (Suchanek et al., 2007) uses the Wikipedia anchor text as a possible mention representation for named entities. However, there may be more representations that do not appear in the Wikipedia anchor text, but are meant to refer to the entity because of a spelling mistake or because of a new abbreviation for the entity. In this demo, we introduce NEED4Tweet, a Twitterbot for a combined system for NEE and NED in Tweets that uses their interdependency and mimics how humans exploit it in language understanding. The system is based on our work (Habib and van Keulen, 2015). We use a generic open world approach for NED in T</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proc. of WWW 2007, pages 697–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thijs Westerveld</author>
<author>Wessel Kraaij</author>
<author>Djoerd Hiemstra</author>
</authors>
<title>Retrieving web pages using content, links, urls and anchors.</title>
<date>2002</date>
<booktitle>In Tenth Text REtrieval Conference, TREC</booktitle>
<volume>500</volume>
<pages>663--672</pages>
<contexts>
<context position="5752" citStr="Westerveld et al., 2002" startWordPosition="918" endWordPosition="921">, (Spina et al., 2011), (Christoforaki et al., 2011), (Yerva et al., 2012) and (Delgado et al., 2012) focus on the task of filtering Tweets containing a given a mention of topic-centric entity, depending whether the Tweet is actually related to the entity or not. They develop a set of features (co-occurrence, Web-based features, collectionbased features) to find keywords for positive and negative cases. Similar to our problem discussed in Section 3.2, is the problem of entity home page finding, which was part of the TREC Web and entity tracks. One of the proposed approaches for this task was (Westerveld et al., 2002). The authors combine content information with other sources as diverse as inlinks, URLs and anchors to find an entry page. Although the TREC problem looks similar to ours, the Tweets’ short informal nature makes it more tricky to find an entity reference page. 2.2 Named Entity Extraction Many tools and services have been developed for the NEE task in web documents written in formal language. In spite of this, few research efforts studied NEE in Tweets. In (Ritter et al., ), the authors built an NLP pipeline to perform NEE. The pipeline involves part-of-speech tagging, shallow parsing, and a n</context>
</contexts>
<marker>Westerveld, Kraaij, Hiemstra, 2002</marker>
<rawString>Thijs Westerveld, Wessel Kraaij, and Djoerd Hiemstra. 2002. Retrieving web pages using content, links, urls and anchors. In Tenth Text REtrieval Conference, TREC 2001, volume SP 500, pages 663–672.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Surender Reddy Yerva</author>
<author>Zolt´an Mikl´os</author>
<author>Karl Aberer</author>
</authors>
<title>Entity-based classification of twitter messages.</title>
<date>2012</date>
<journal>IJCSA,</journal>
<volume>9</volume>
<issue>1</issue>
<marker>Yerva, Mikl´os, Aberer, 2012</marker>
<rawString>Surender Reddy Yerva, Zolt´an Mikl´os, and Karl Aberer. 2012. Entity-based classification of twitter messages. IJCSA, 9(1):88–115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhemin Zhu</author>
<author>Djoerd Hiemstra</author>
<author>Peter Apers</author>
</authors>
<title>Linear co-occurrence rate networks (l-crns) for sequence labeling. In Statistical language and speech processing, volume 8791 of Lecture notes in computer science,</title>
<date>2014</date>
<pages>185--196</pages>
<contexts>
<context position="12660" citStr="Zhu et al., 2014" startWordPosition="2053" endWordPosition="2056">und 5 million tweets1. • KB Features: – Whether the segment appears in WordNet. – Whether the segment appears in the YAGO mention-entity look-up table. • Disambiguation Features: All the features described in Section 3.2 derived from the entity page linked to the given mention candidate. In this demo, we use an SVM which is trained on four different NEE datasets presented in (Ritter et al., ), (Basave et al., 2013), (Locke and Martin, 2009), and (Habib and van Keulen, 2012). 3.4 Final NE Set Generation Beside the SVM, we also use a trained CRF model for NEE. We use the CRF model described in (Zhu et al., 2014) trained on the four collections mentioned in Section 3.3. To train the CRF, Tweet text is tokenized using a special tweet tokenizer (Gimpel et al., 2011) and the following features are extracted and used for training: 1http://wis.ewi.tudelft.nl/umap2011/ + TREC 2011 Microblog track collection. (a) Example 1: Tweet for testing both NEE and NED. (b) Example 2: Tweet for testing NED only. (d) Results of example 1 (e) Results of example 2 Figure 2: NEED4Tweet Twitterbot • The Part of Speech (POS) tag of the token provided by a special POS tagger designed for tweets (Gimpel et al., 2011). • Whethe</context>
</contexts>
<marker>Zhu, Hiemstra, Apers, 2014</marker>
<rawString>Zhemin Zhu, Djoerd Hiemstra, and Peter Apers. 2014. Linear co-occurrence rate networks (l-crns) for sequence labeling. In Statistical language and speech processing, volume 8791 of Lecture notes in computer science, pages 185–196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>