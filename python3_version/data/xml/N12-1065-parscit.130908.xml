<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005582">
<title confidence="0.984054">
Identifying Comparable Corpora Using LDA
</title>
<author confidence="0.769246">
Judita Preiss
</author>
<email confidence="0.658604">
j.preiss@sheffield.ac.uk
</email>
<affiliation confidence="0.980085">
Department of Computer Science, University of Sheffield, Regent Court
</affiliation>
<address confidence="0.698392">
211 Portobello, Sheffield, S1 4DP, United Kingdom
</address>
<sectionHeader confidence="0.973061" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999654615384616">
Parallel corpora have applications in many ar-
eas of Natural Language Processing, but are
very expensive to produce. Much information
can be gained from comparable texts, and we
present an algorithm which, given any bod-
ies of text in multiple languages, uses ex-
isting named entity recognition software and
topic detection algorithm to generate pairs of
comparable texts without requiring a paral-
lel corpus training phase. We evaluate the
system’s performance firstly on data from the
online newspaper domain, and secondly on
Wikipedia cross-language links.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995769130434783">
Manual alignment or creation of parallel corpora is
exceedingly expensive, requiring highly skilled an-
notators or professional translators. Methods exist
for aligning parallel corpora, and extracted parallel
segments can be used to, for example, augment ma-
chine translation phrase tables, but the amount of
genuinely parallel data is limited. However, paral-
lel segments can also be extracted from comparable
corpora (a comparable corpus is one which contains
similar texts in more than one language). Compara-
ble documents, if produced with a confidence value,
could also be used to prioritize translation (manual
or automatic) when one is searching for further in-
formation (which may only be available in a foreign
language) to augment information given in an arti-
cle in the source language. We present a technique
to automatically detect comparable corpora in exist-
ing data, and we demonstrate the applicability of our
method to any genre by evaluating on crawled online
newspaper text, as well as Wikipedia articles.
Clearly, texts need to contain some of the same
data in order to be comparable (Harris, 1954), and
we assume:
</bodyText>
<listItem confidence="0.998611666666667">
• To be similar, texts need to share some named
entities, e.g., T´oth et al., (2008).
• Comparable texts need to be on the same topic.
</listItem>
<bodyText confidence="0.995696166666666">
Construction of multilingual topic models usu-
ally requires either parallel data or some number of
aligned documents across multiple languages. Zhao
and Xing (2007) create bilingual topic models from
(at least 25%) of parallel data. Mimno et al., (2009)
start from tuples of equivalent documents to build
models, and then the same distribution over topics
holds in both source and target languages.
While Zhao and Xing (2007) used their topic
models for word alignment from comparable cor-
pora (combined with underlying parallel data), mul-
tilingual topic models are usually applied to data to
automatically detect word translations based on par-
allel data, e.g., Vuli´c et al., (2011) exploit a shared
language independent topic distribution to measure
the similarity between topics pertaining to words.
The novelty of our work is the transformation of a
source language topic model rather than the creation
of a language independent model from parallel data.
Transforming the source language model to the tar-
get language allows the classification of the target
language documents to source language topics. The
translated model is applied to two document collec-
tions to demonstrate its ability to detect comparable
</bodyText>
<page confidence="0.898405">
558
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 558–562,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<bodyText confidence="0.9996626">
corpora. Our system can be applied to any pair of
languages for which there is a dictionary.
Section 2 describes the tools we employ. Sec-
tion 3 contains a description of our system: the
method for employing NE recognition across lan-
guages is presented in Section 3.1, while Section 3.2
outlines our technique for employing LDA across
languages. Our experiments and their results are de-
scribed in Section 4. Section 5 draws our conclu-
sions and indicates avenues for future work.
</bodyText>
<sectionHeader confidence="0.996896" genericHeader="introduction">
2 Tools
</sectionHeader>
<subsectionHeader confidence="0.998665">
2.1 Named entity recognition
</subsectionHeader>
<bodyText confidence="0.993822166666667">
The Stanford named entity recognition (NER) soft-
ware1 (Finkel et al., 2005) is an implementation of
linear chain Conditional Random Field (CRF) se-
quence models, which includes a three class (per-
son, organization, location and other) named entity
recognizer for English.
</bodyText>
<subsectionHeader confidence="0.998103">
2.2 Topic detection
</subsectionHeader>
<bodyText confidence="0.999990071428571">
LDA (Blei et al., 2003) is a generative probabilistic
model where documents are viewed as mixtures over
underlying topics, and each topic is a distribution
over words. Both the document-topic and the topic-
word distributions are assumed to have a Dirichlet
prior. Given a set of documents and a number of
topics, the model returns Bi, the topic distribution
for each document i, and Oik, the word distribution
for topic k. We employ the publicly available imple-
mentation of LDA, JGibbLDA2 (Phan et al., 2008),
which has two main execution methods: parameter
estimation (model building) and inference for new
data (classification of a new document). Both invo-
cations produce the following:
</bodyText>
<sectionHeader confidence="0.67459" genericHeader="method">
Oij: p(wordi|topicj)
Bjk: p(topicj|documentk)
</sectionHeader>
<bodyText confidence="0.999569">
tassign: a deterministic topic-word assignment for
each word in every document
The LDA topic models are created from a ran-
domly selected tenth of the Reuters corpus (Rose
et al., 2002).3
</bodyText>
<footnote confidence="0.9747295">
1http://nlp.stanford.edu/ner/index.shtml
2http://jgibblda.sourceforge.net/
3LDA modeling can abstract a model from a relatively small
corpus and a tenth of the original Reuters corpus is much more
</footnote>
<subsectionHeader confidence="0.993269">
2.3 Indexing
</subsectionHeader>
<bodyText confidence="0.9999842">
To provide quick searching access to the large text
collections, we utilize the high-performance search
engine library Lucene.4 The stemmed and stoplisted
documents are stored along with the frequency of
occurrence of each word within a document.
</bodyText>
<subsectionHeader confidence="0.998523">
2.4 Lemmatization / stemming
</subsectionHeader>
<bodyText confidence="0.99998775">
English text is lemmatized using the lemmatizer
available within RASP5 (Briscoe et al., 2006). Stem-
ming is provided for all the non-English languages
included in our work within Lucene.
</bodyText>
<sectionHeader confidence="0.951512" genericHeader="method">
3 Identifying comparable corpora
</sectionHeader>
<subsectionHeader confidence="0.999042">
3.1 Cross language NER
</subsectionHeader>
<bodyText confidence="0.981060826086957">
NEs extracted from the English text collections are
automatically translated into the target languages us-
ing the BING Translation API6 yielding a single
translation, which is retained. The stemmed, trans-
lated version of each NE in the source text is sought
in the indexed form of the target language document
collection, and the frequency of occurrence of the
NE is returned.
Filtering is applied based on the proportion of
source language document’s NEs found in the target
document (we do not expect all the NEs to be present
in the target language: NEs could be mis-translated,
and not all NEs would necessarily be mentioned
even in a comparable document). The proportions
of all types of NEs required were optimized over a
small manually created set. While we could assign a
weight and not filter documents, this is not believed
to be adequate: e.g., a newspaper article containing
all the source location mentions (and thus having a
high weight), but none of the same people, is likely
to be a news story about the same area but a different
event.
manageable in terms of memory and time requirements.
</bodyText>
<footnote confidence="0.987110571428572">
4http://lucene.apache.org
5http://ilexir.co.uk/applications/rasp/
download
6The translations could also be retrieved from NE mapping
lists, dictionaries (if these are available) or manually translated
– we therefore do not see this step as violating the lack of need
for a parallel corpus.
</footnote>
<page confidence="0.991029">
559
</page>
<subsectionHeader confidence="0.996724">
3.2 Cross language topic identification
</subsectionHeader>
<bodyText confidence="0.999973608695652">
Being non-deterministic, multiple executions of the
LDA algorithm are not guaranteed to (and do not)
give rise to identical topics (even within one lan-
guage). It is therefore not possible to build a topic
model in the source language and the target lan-
guage separately, as there is no clear alignment be-
tween their respective topics. Traditionally, par-
allel corpora are used to generate a language in-
dependent topic-document distribution, from which
polylingual topic models can be created so the un-
derlying topics are shared.
We propose to translate each word from the
source language topic model using the BING API
and substitute the new wordmap thus creating a tar-
get language topic model. While word distributions
are clearly different across languages, and building a
shared topic-document distribution to sample words
from allows words to retain their language specific
distributions, our technique completely avoids the
need for parallel corpora, and merely requires the
translation of the words in the LDA model (which
can be performed using dictionary lookup, or NE
lists instead of the BING API).
</bodyText>
<subsectionHeader confidence="0.999831">
3.3 Selecting comparable corpora
</subsectionHeader>
<bodyText confidence="0.99999625">
Target language candidate documents found to share
sufficient proportions of NEs are classified using the
translated target language LDA model. This yields
Bjk (the probability distribution of topic given doc-
ument) and classifying the original document using
the source language LDA model gives B&apos;jk. The can-
didate documents are ranked according to the cosine
similarity between the two vectors:
</bodyText>
<subsectionHeader confidence="0.329696">
Bjk - Bjk
</subsectionHeader>
<bodyText confidence="0.9352098">
IBjkllllB&apos;jkll
By definition, cosine similarity ranges between -1
and 1. Similarity of 1 indicates two documents with
B = B&apos;, and thus the higher the similarity, the higher
we rank the document.
</bodyText>
<sectionHeader confidence="0.999737" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999958857142857">
We present two evaluations: firstly, we manu-
ally evaluate the comparable documents generated
from online newspaper text in two languages, while
the second evaluation finds comparable articles in
source and target versions of Wikipedia with results
evaluated against the cross-language links present in
Wikipedia.
</bodyText>
<subsectionHeader confidence="0.995792">
4.1 Online newspaper documents
</subsectionHeader>
<bodyText confidence="0.984273114285714">
Simple Google search yields a number of links to
online newspapers in any language, these lists (auto-
matically retrieved) are used to seed a crawler. Doc-
uments from newspaper sites which allow crawling
are retrieved and only well formed HTML docu-
ments are retained,7 and the language of the docu-
ments is verified using a Perl implementation of Lin-
gua::Ident (Dunning, 1994), an n-gram based model
for language identification.8
A single annotator evaluated 10 randomly se-
lected English documents and the comparable doc-
uments returned for them from 40,528 Czech news-
paper articles (total retrieved within a 24 hour pe-
riod). Since there is no current scheme available for
judging comparability, we employed a four category
scale:
Strong: The documents are about the same news
event, in a similar style. (Articles about the
same news event, but elaborating, would be in-
cluded here.)
Medium: The documents are about related news
events.
Weak: The documents refers to similar events.
None: No overlap in topic in the two documents.
Results of the evaluation are presented in Table 1;
the top document is scored for each pair, showing
the high precision of the technique. The 10 English
documents were selected subject to the constraint
that a comparable corpus was retrieved for them: the
imposed constraints on NEs make this a high preci-
sion / low recall technique. Many articles found us-
ing the crawling approach on news sites (rather than
an RSS feed gathering approach) were discussions,
7Note that the crawler is not permitted to leave the domain
of the newspaper.
</bodyText>
<footnote confidence="0.9903074">
8The Lingua::Ident Perl module is available from http:
//search.cpan.org/˜mpiotr/Lingua-Ident-1.
7/Ident.pm. We build the models for the language identi-
fication system from downloaded Wikipedia content for each
language.
</footnote>
<equation confidence="0.491771">
similarity =
</equation>
<page confidence="0.960453">
560
</page>
<table confidence="0.9783895">
Strong Medium Weak None
4 4 1 1
</table>
<tableCaption confidence="0.998221">
Table 1: Results for English-Czech documents
</tableCaption>
<bodyText confidence="0.999917">
for example discussions of strategies in sports, inter-
views with actors, rather than topical news stories.
From a manual inspection of the target language ar-
ticles, many of these articles do not appear to have
comparable equivalents. Also, enforcing a high pro-
portion of NEs shared between the source and target
languages frequently rules out documents which are
subsets of each other (this was also apparent in the
second evaluation).
</bodyText>
<subsectionHeader confidence="0.957814">
4.2 Wikipedia
</subsectionHeader>
<bodyText confidence="0.999980235294118">
Information within Wikipedia is connected across
languages using cross-language links. While the
lists of links are not necessarily complete, and the
articles they link may not contain large parallel seg-
ments, the linked documents should be comparable
(under the definition), and thus provide an empirical
measure of the utility of our method.
The top comparable articles in Czech were gener-
ated for 100 randomly selected English Wikipedia
articles (subject to the constraint that they have
cross-language links). As in our first evaluation, the
system had a low recall (35%), however precision
was 83%. By the design of the experiment, an arti-
cle about the same subject has to exist in both lan-
guages, and therefore the low recall value is surpris-
ing. Rather than a low cosine value, the low recall
is mainly due to the NE filtering step removing the
‘correct’ article from consideration. A brief inspec-
tion of a small number of articles which had been fil-
tered out was performed and substantial differences
between the pages were found – for example, a sig-
nificant portion of the Wikipedia page for Equinox in
English contains descriptions of Equinox commem-
orations all over the world, which are missing in the
Czech version of the Wikipedia article (leading to a
large number of missing NEs). Similar length of ar-
ticles appeared to be a good indicator of both articles
containing similar data, and our system detecting the
two texts to be comparable.
Please note that while the NE filtering step is re-
moving texts from consideration, it is not possible
to compute cosines of the topic vectors of all docu-
ments and thus some candidate selection step is nec-
essary.
</bodyText>
<subsectionHeader confidence="0.980279">
4.3 Baseline
</subsectionHeader>
<bodyText confidence="0.999972666666666">
There are no standard baselines for the task of cre-
ating comparable corpora. It is possible to trans-
late the source language text into the target language
using BING, however, a cosine comparison of the
stemmed, automatically translated document with
all documents in the target language collection is
extremely time consuming. Applying NE filtering,
automatically translating the remaining target lan-
guage candidate texts into the source language us-
ing BING, and ranking according to cosine similar-
ity gives a precision of 69% for the collection dis-
cussed in Section 4.2.
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99997675">
We have presented an LDA based algorithm applica-
ble to large document collections to find comparable
documents across multi-lingual corpora without the
needing to train with parallel data. We show, using
a human judge as well as Wikipedia cross-language
links, that the system achieves high precision in find-
ing comparable documents.
The technique strongly relies on the named en-
tity method selected, and another technique may be
more suitable. A comparison with a bilingual topic
model created from parallel data would also prove
interesting.
</bodyText>
<sectionHeader confidence="0.99764" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999851333333333">
This research was supported by EU grant 248347
on Analysis and Evaluation of Comparable Corpora
for Under-Resourced Areas of Machine Translation
(ACCURAT). My thanks also go to the three review-
ers whose comments strengthened the findings of
this work.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.971763333333333">
Blei, D. M., Ng, A. Y., and Jordan, M. I. (2003). Latent
Dirichlet allocation. Journal of Machine Learning Re-
search, 3:993–1022.
Briscoe, T., Carroll, J., and Watson, R. (2006). The sec-
ond release of the RASP system. In Proceedings of the
COLING/ACL 2006 Interactive Presentation Sessions.
</reference>
<page confidence="0.975258">
561
</page>
<reference confidence="0.999125885714286">
Dunning, T. (1994). Statistical identification of language.
Technical Report CRL MCCS-94-273, Computing Re-
search Lab, New Mexico State University.
Finkel, J. R., Grenager, T., and Manning, C. (2005). In-
corporating non-local information into information ex-
traction systems by Gibbs sampling. In Proceedings of
the 43nd Annual Meeting of the Association for Com-
putational Linguistics, pages 363–370.
Harris, Z. S. (1954). Distributional structure. Word,
10(23):146162.
Mimno, D., Wallach, H. M., Naradowsky, J., Smith,
D. A., and McCallum, A. (2009). Polylingual topic
models. In Proceedings of the Conference on Empir-
ical Methods in Natural Language Processing, page
880889.
Phan, X.-H., Nguyen, L.-M., and Horiguchi, S. (2008).
Learning to classify short and sparse text &amp; web with
hidden topics from large-scale data collections. In
Proceedings of The 17th International World Wide
Web Conference (WWW 2008), pages 91–100.
Rose, T. G., Stevenson, M., and Whitehead, M. (2002).
The Reuters corpus volume 1 - from yesterday’s news
to tomorrow’s language resources. In Proceedings of
the Third International Conference on Language Re-
sources and Evaluation, pages 827–832.
T´oth, K., Farkas, R., and Kocsor, A. (2008). Sentence
alignment of Hungarian-English parallel corpora using
a hybrid algorithm. Acta Cybernetica, pages 463–478.
Vulic, I., Smet, W. D., and Moens, M.-F. (2011). Iden-
tifying word translations from comparable corpora us-
ing latent topic models. In Proceedings of ACL, pages
479–484.
Zhao, B. and Xing, E. P. (2007). HM-BiTAM: Bilingual
topic exploration, word alignment, and translation. In
NIPS.
</reference>
<page confidence="0.997316">
562
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.916472">
<title confidence="0.999484">Identifying Comparable Corpora Using LDA</title>
<author confidence="0.953268">Judita Preiss</author>
<email confidence="0.993764">j.preiss@sheffield.ac.uk</email>
<affiliation confidence="0.99061">Department of Computer Science, University of Sheffield, Regent</affiliation>
<address confidence="0.992312">211 Portobello, Sheffield, S1 4DP, United Kingdom</address>
<abstract confidence="0.998366714285714">Parallel corpora have applications in many areas of Natural Language Processing, but are very expensive to produce. Much information can be gained from comparable texts, and we present an algorithm which, given any bodies of text in multiple languages, uses existing named entity recognition software and topic detection algorithm to generate pairs of comparable texts without requiring a parallel corpus training phase. We evaluate the system’s performance firstly on data from the online newspaper domain, and secondly on Wikipedia cross-language links.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>A Y Ng</author>
<author>M I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="4313" citStr="Blei et al., 2003" startWordPosition="665" endWordPosition="668">recognition across languages is presented in Section 3.1, while Section 3.2 outlines our technique for employing LDA across languages. Our experiments and their results are described in Section 4. Section 5 draws our conclusions and indicates avenues for future work. 2 Tools 2.1 Named entity recognition The Stanford named entity recognition (NER) software1 (Finkel et al., 2005) is an implementation of linear chain Conditional Random Field (CRF) sequence models, which includes a three class (person, organization, location and other) named entity recognizer for English. 2.2 Topic detection LDA (Blei et al., 2003) is a generative probabilistic model where documents are viewed as mixtures over underlying topics, and each topic is a distribution over words. Both the document-topic and the topicword distributions are assumed to have a Dirichlet prior. Given a set of documents and a number of topics, the model returns Bi, the topic distribution for each document i, and Oik, the word distribution for topic k. We employ the publicly available implementation of LDA, JGibbLDA2 (Phan et al., 2008), which has two main execution methods: parameter estimation (model building) and inference for new data (classifica</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>Blei, D. M., Ng, A. Y., and Jordan, M. I. (2003). Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL</booktitle>
<contexts>
<context position="5790" citStr="Briscoe et al., 2006" startWordPosition="887" endWordPosition="890"> the Reuters corpus (Rose et al., 2002).3 1http://nlp.stanford.edu/ner/index.shtml 2http://jgibblda.sourceforge.net/ 3LDA modeling can abstract a model from a relatively small corpus and a tenth of the original Reuters corpus is much more 2.3 Indexing To provide quick searching access to the large text collections, we utilize the high-performance search engine library Lucene.4 The stemmed and stoplisted documents are stored along with the frequency of occurrence of each word within a document. 2.4 Lemmatization / stemming English text is lemmatized using the lemmatizer available within RASP5 (Briscoe et al., 2006). Stemming is provided for all the non-English languages included in our work within Lucene. 3 Identifying comparable corpora 3.1 Cross language NER NEs extracted from the English text collections are automatically translated into the target languages using the BING Translation API6 yielding a single translation, which is retained. The stemmed, translated version of each NE in the source text is sought in the indexed form of the target language document collection, and the frequency of occurrence of the NE is returned. Filtering is applied based on the proportion of source language document’s </context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Briscoe, T., Carroll, J., and Watson, R. (2006). The second release of the RASP system. In Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Statistical identification of language.</title>
<date>1994</date>
<tech>Technical Report CRL MCCS-94-273,</tech>
<institution>Computing Research Lab, New Mexico State University.</institution>
<contexts>
<context position="9851" citStr="Dunning, 1994" startWordPosition="1530" endWordPosition="1531">e newspaper text in two languages, while the second evaluation finds comparable articles in source and target versions of Wikipedia with results evaluated against the cross-language links present in Wikipedia. 4.1 Online newspaper documents Simple Google search yields a number of links to online newspapers in any language, these lists (automatically retrieved) are used to seed a crawler. Documents from newspaper sites which allow crawling are retrieved and only well formed HTML documents are retained,7 and the language of the documents is verified using a Perl implementation of Lingua::Ident (Dunning, 1994), an n-gram based model for language identification.8 A single annotator evaluated 10 randomly selected English documents and the comparable documents returned for them from 40,528 Czech newspaper articles (total retrieved within a 24 hour period). Since there is no current scheme available for judging comparability, we employed a four category scale: Strong: The documents are about the same news event, in a similar style. (Articles about the same news event, but elaborating, would be included here.) Medium: The documents are about related news events. Weak: The documents refers to similar eve</context>
</contexts>
<marker>Dunning, 1994</marker>
<rawString>Dunning, T. (1994). Statistical identification of language. Technical Report CRL MCCS-94-273, Computing Research Lab, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="4075" citStr="Finkel et al., 2005" startWordPosition="628" endWordPosition="631">for Computational Linguistics corpora. Our system can be applied to any pair of languages for which there is a dictionary. Section 2 describes the tools we employ. Section 3 contains a description of our system: the method for employing NE recognition across languages is presented in Section 3.1, while Section 3.2 outlines our technique for employing LDA across languages. Our experiments and their results are described in Section 4. Section 5 draws our conclusions and indicates avenues for future work. 2 Tools 2.1 Named entity recognition The Stanford named entity recognition (NER) software1 (Finkel et al., 2005) is an implementation of linear chain Conditional Random Field (CRF) sequence models, which includes a three class (person, organization, location and other) named entity recognizer for English. 2.2 Topic detection LDA (Blei et al., 2003) is a generative probabilistic model where documents are viewed as mixtures over underlying topics, and each topic is a distribution over words. Both the document-topic and the topicword distributions are assumed to have a Dirichlet prior. Given a set of documents and a number of topics, the model returns Bi, the topic distribution for each document i, and Oik</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Finkel, J. R., Grenager, T., and Manning, C. (2005). Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z S Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1954</date>
<journal>Word,</journal>
<volume>10</volume>
<issue>23</issue>
<contexts>
<context position="1892" citStr="Harris, 1954" startWordPosition="285" endWordPosition="286">. Comparable documents, if produced with a confidence value, could also be used to prioritize translation (manual or automatic) when one is searching for further information (which may only be available in a foreign language) to augment information given in an article in the source language. We present a technique to automatically detect comparable corpora in existing data, and we demonstrate the applicability of our method to any genre by evaluating on crawled online newspaper text, as well as Wikipedia articles. Clearly, texts need to contain some of the same data in order to be comparable (Harris, 1954), and we assume: • To be similar, texts need to share some named entities, e.g., T´oth et al., (2008). • Comparable texts need to be on the same topic. Construction of multilingual topic models usually requires either parallel data or some number of aligned documents across multiple languages. Zhao and Xing (2007) create bilingual topic models from (at least 25%) of parallel data. Mimno et al., (2009) start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages. While Zhao and Xing (2007) used their topic models</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Harris, Z. S. (1954). Distributional structure. Word, 10(23):146162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mimno</author>
<author>H M Wallach</author>
<author>J Naradowsky</author>
<author>D A Smith</author>
<author>A McCallum</author>
</authors>
<title>Polylingual topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>880889</pages>
<contexts>
<context position="2296" citStr="Mimno et al., (2009)" startWordPosition="351" endWordPosition="354">he applicability of our method to any genre by evaluating on crawled online newspaper text, as well as Wikipedia articles. Clearly, texts need to contain some of the same data in order to be comparable (Harris, 1954), and we assume: • To be similar, texts need to share some named entities, e.g., T´oth et al., (2008). • Comparable texts need to be on the same topic. Construction of multilingual topic models usually requires either parallel data or some number of aligned documents across multiple languages. Zhao and Xing (2007) create bilingual topic models from (at least 25%) of parallel data. Mimno et al., (2009) start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages. While Zhao and Xing (2007) used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topic models are usually applied to data to automatically detect word translations based on parallel data, e.g., Vuli´c et al., (2011) exploit a shared language independent topic distribution to measure the similarity between topics pertaining to words. The novelty of our work is the transformation of a </context>
</contexts>
<marker>Mimno, Wallach, Naradowsky, Smith, McCallum, 2009</marker>
<rawString>Mimno, D., Wallach, H. M., Naradowsky, J., Smith, D. A., and McCallum, A. (2009). Polylingual topic models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, page 880889.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X-H Phan</author>
<author>L-M Nguyen</author>
<author>S Horiguchi</author>
</authors>
<title>Learning to classify short and sparse text &amp; web with hidden topics from large-scale data collections.</title>
<date>2008</date>
<booktitle>In Proceedings of The 17th International World Wide Web Conference (WWW</booktitle>
<pages>91--100</pages>
<contexts>
<context position="4797" citStr="Phan et al., 2008" startWordPosition="745" endWordPosition="748">hree class (person, organization, location and other) named entity recognizer for English. 2.2 Topic detection LDA (Blei et al., 2003) is a generative probabilistic model where documents are viewed as mixtures over underlying topics, and each topic is a distribution over words. Both the document-topic and the topicword distributions are assumed to have a Dirichlet prior. Given a set of documents and a number of topics, the model returns Bi, the topic distribution for each document i, and Oik, the word distribution for topic k. We employ the publicly available implementation of LDA, JGibbLDA2 (Phan et al., 2008), which has two main execution methods: parameter estimation (model building) and inference for new data (classification of a new document). Both invocations produce the following: Oij: p(wordi|topicj) Bjk: p(topicj|documentk) tassign: a deterministic topic-word assignment for each word in every document The LDA topic models are created from a randomly selected tenth of the Reuters corpus (Rose et al., 2002).3 1http://nlp.stanford.edu/ner/index.shtml 2http://jgibblda.sourceforge.net/ 3LDA modeling can abstract a model from a relatively small corpus and a tenth of the original Reuters corpus is</context>
</contexts>
<marker>Phan, Nguyen, Horiguchi, 2008</marker>
<rawString>Phan, X.-H., Nguyen, L.-M., and Horiguchi, S. (2008). Learning to classify short and sparse text &amp; web with hidden topics from large-scale data collections. In Proceedings of The 17th International World Wide Web Conference (WWW 2008), pages 91–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T G Rose</author>
<author>M Stevenson</author>
<author>M Whitehead</author>
</authors>
<title>The Reuters corpus volume 1 - from yesterday’s news to tomorrow’s language resources.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation,</booktitle>
<pages>827--832</pages>
<contexts>
<context position="5208" citStr="Rose et al., 2002" startWordPosition="806" endWordPosition="809"> of topics, the model returns Bi, the topic distribution for each document i, and Oik, the word distribution for topic k. We employ the publicly available implementation of LDA, JGibbLDA2 (Phan et al., 2008), which has two main execution methods: parameter estimation (model building) and inference for new data (classification of a new document). Both invocations produce the following: Oij: p(wordi|topicj) Bjk: p(topicj|documentk) tassign: a deterministic topic-word assignment for each word in every document The LDA topic models are created from a randomly selected tenth of the Reuters corpus (Rose et al., 2002).3 1http://nlp.stanford.edu/ner/index.shtml 2http://jgibblda.sourceforge.net/ 3LDA modeling can abstract a model from a relatively small corpus and a tenth of the original Reuters corpus is much more 2.3 Indexing To provide quick searching access to the large text collections, we utilize the high-performance search engine library Lucene.4 The stemmed and stoplisted documents are stored along with the frequency of occurrence of each word within a document. 2.4 Lemmatization / stemming English text is lemmatized using the lemmatizer available within RASP5 (Briscoe et al., 2006). Stemming is prov</context>
</contexts>
<marker>Rose, Stevenson, Whitehead, 2002</marker>
<rawString>Rose, T. G., Stevenson, M., and Whitehead, M. (2002). The Reuters corpus volume 1 - from yesterday’s news to tomorrow’s language resources. In Proceedings of the Third International Conference on Language Resources and Evaluation, pages 827–832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K T´oth</author>
<author>R Farkas</author>
<author>A Kocsor</author>
</authors>
<title>Sentence alignment of Hungarian-English parallel corpora using a hybrid algorithm. Acta Cybernetica,</title>
<date>2008</date>
<pages>463--478</pages>
<marker>T´oth, Farkas, Kocsor, 2008</marker>
<rawString>T´oth, K., Farkas, R., and Kocsor, A. (2008). Sentence alignment of Hungarian-English parallel corpora using a hybrid algorithm. Acta Cybernetica, pages 463–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Vulic</author>
<author>W D Smet</author>
<author>M-F Moens</author>
</authors>
<title>Identifying word translations from comparable corpora using latent topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>479--484</pages>
<marker>Vulic, Smet, Moens, 2011</marker>
<rawString>Vulic, I., Smet, W. D., and Moens, M.-F. (2011). Identifying word translations from comparable corpora using latent topic models. In Proceedings of ACL, pages 479–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Zhao</author>
<author>E P Xing</author>
</authors>
<title>HM-BiTAM: Bilingual topic exploration, word alignment, and translation.</title>
<date>2007</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="2207" citStr="Zhao and Xing (2007)" startWordPosition="336" endWordPosition="339">chnique to automatically detect comparable corpora in existing data, and we demonstrate the applicability of our method to any genre by evaluating on crawled online newspaper text, as well as Wikipedia articles. Clearly, texts need to contain some of the same data in order to be comparable (Harris, 1954), and we assume: • To be similar, texts need to share some named entities, e.g., T´oth et al., (2008). • Comparable texts need to be on the same topic. Construction of multilingual topic models usually requires either parallel data or some number of aligned documents across multiple languages. Zhao and Xing (2007) create bilingual topic models from (at least 25%) of parallel data. Mimno et al., (2009) start from tuples of equivalent documents to build models, and then the same distribution over topics holds in both source and target languages. While Zhao and Xing (2007) used their topic models for word alignment from comparable corpora (combined with underlying parallel data), multilingual topic models are usually applied to data to automatically detect word translations based on parallel data, e.g., Vuli´c et al., (2011) exploit a shared language independent topic distribution to measure the similarit</context>
</contexts>
<marker>Zhao, Xing, 2007</marker>
<rawString>Zhao, B. and Xing, E. P. (2007). HM-BiTAM: Bilingual topic exploration, word alignment, and translation. In NIPS.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>