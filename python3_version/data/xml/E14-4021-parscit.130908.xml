<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020115">
<title confidence="0.998423">
Automatic Selection of Reference Pages in Wikipedia
for Improving Targeted Entities Disambiguation
</title>
<author confidence="0.96848">
Takuya Makino
</author>
<affiliation confidence="0.922815">
Fujitsu Laboratories Ltd.
</affiliation>
<address confidence="0.950523">
4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki, Japan
</address>
<email confidence="0.99936">
makino.takuya@jp.fujitsu.com
</email>
<sectionHeader confidence="0.997392" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99986396">
In Targeted Entity Disambiguation setting,
we take (i) a set of entity names which be-
long to the same domain (target entities),
(ii) candidate mentions of the given enti-
ties which are texts that contain the tar-
get entities as input, and then determine
which ones are true mentions of “target
entity”. For example, given the names of
IT companies, including Apple, we deter-
mine Apple in a mention denotes an IT
company or not. Prior work proposed a
graph based model. This model ranks all
candidate mentions based on scores which
denote the degree of relevancy to target
entities. Furthermore, this graph based
model could utilize reference pages of tar-
get entities. However, human annotators
must select reference pages in advance.
We propose an automatic method that can
select reference pages. We formalize the
selection problem of reference pages as an
Integer Linear Programming problem. We
show that our model works as well as the
prior work that manually selected refer-
ence pages.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999968679245283">
The enterprise is typically interested in customer’s
opinions. One of the methods to analyze cus-
tomer’s opinions is to collect mentions which con-
tain product names. We would get a noisy mention
collection if we use a simple method which ex-
tracts mentions that contain product names, since
the product names may be used as other meanings.
Wang et al. (2012) proposed a new task which
they referred to as Targeted Entity Disambigua-
tion (TED). In this problem setting, we take (i) a
set of entity names which belong to the same do-
main (target entities), (ii) candidate mentions of
the given entities which are texts that contain the
target entity entities as input, and then determine
which ones are true mentions for the target enti-
ties. TED is different from traditional Word Sense
Disambiguation or Entity Linking. Word Sense
Disambiguation can be viewed as a classification
task in which word senses are the classes (Nav-
igli, 2009) and Entity Linking is the task of link-
ing name in Web text with entities in Wikipedia
(Han et al., 2011). The uniqueness of this prob-
lem is that the entities are all in the same domain
(referred to as the target domain) and not necessar-
ily included in a knowledge base such as DBpedia,
Freebase or YAGO.
Wang et al. (2012) realized TED with a graph
based model. In their graph based method, a target
entity in a mention is regarded as a node, and the
weight of an edge is determined according to con-
text similarity, and a prior score of node that is de-
termined according to the unique number of target
entities in the mention. This graph is called as a
mention graph. Using mention graph, the author-
ity of each mention is calculated with Mention-
Rank which is a variant of PageRank (Page et al.,
1999). This authority denotes a score of how likely
this node is in the target domain. In addition, Men-
tionRank could integrate external knowledge such
as Wikipedia. For each target entity, a reference
page is added as a virtual node to the graph. Since
reference pages can be regarded as true mentions,
the prior scores of virtual nodes are higher than
other mentions. This extended method can prop-
agate the score of the virtual node of each entity
to candidate mentions which are likely true. Al-
though the use of reference pages works well, hu-
man annotators must select these reference pages.
In Word Sense Disambiguation and Entity Link-
ing, there are some collective approaches (Hoffart
et al., 2011; Kulkarni et al., 2009). In this pa-
per, we apply this technique to the selection prob-
lem of reference pages for TED. To select refer-
</bodyText>
<page confidence="0.977695">
106
</page>
<note confidence="0.689795">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 106–110,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999877333333333">
ence pages, we collect candidate reference pages
of target entities from Wikipedia in advance. If
the name of a target entity has a disambiguation
page in Wikipedia, we have two or more candi-
date reference pages. Then we formalize the prob-
lem of reference page selection as an Integer Lin-
ear Programming problem. Our model is going to
maximize the summation of similarities between
selected pages under some constraints. Thus, co-
herent pages are selected as reference pages. Our
method does not require any knowledge except for
names of target entities. We give only target enti-
ties as input to select reference pages. Our method
shows competitive accuracy of the prior method
with manually selected reference pages.
</bodyText>
<sectionHeader confidence="0.988848" genericHeader="introduction">
2 Task Definition
</sectionHeader>
<bodyText confidence="0.9958505">
Following previous work, we assume that all oc-
currences of a name in a mention refer to the same
entity (e.g., occurrences of the string “Apple” in a
single mention either all refer to the IT company
or all refer to the fruit) (Wang et al., 2012).
TED is defined as follows.
Definition 1 (Targeted Entity Disambiguation).
Given input of a target entity set E = {ei, ..., en},
a mention set D = {di, ..., dn} and candidate
mentions R = {(ei, dj)|ei ∈ E, dj ∈ D}, out-
put score rij ∈ [0, 1] for every candidate mention
(ei, dj) ∈ R.
</bodyText>
<sectionHeader confidence="0.999959" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999833">
Wang et al. (2012) proposed MentionRank to ad-
dress TED. MentionRank is similar to PageRank.
This model is based on three hypotheses:
</bodyText>
<listItem confidence="0.946899454545455">
1. Context similarity: The true mentions
across all the entities, across all the mentions
will have more similar contexts than the false
mentions of different entities.
2. Co-Mention: If multiple target entities are
co-mentioned in a mention, they are likely to
be true mentions.
3. Interdependency: If one or more men-
tions among the ones with similar context is
deemed likely to be a true mention, they are
all likely to be true mentions.
</listItem>
<bodyText confidence="0.977313666666667">
In a mention graph, a node (ei, dj) denotes an
entity ei in mention dj. The weight of edge be-
tween (ei, dj) and (e′i, d′j) is denoted as wij,i′j′
which is a variable normalized by context similar-
ity µij,i′j′. Context similarities are normalized to
avoid “false-boost” problem. “false-boost” prob-
lem is boosting ranking score of false mentions in
a false mentions group. The normalized weight of
the edge is defined as follows:
</bodyText>
<equation confidence="0.992275">
{ zij if i = i′,
wij,i′j′ =µi′j′,ij
k ViZ + zijk otherwise. (1)
zij = 1 − ∑∑
i′ i UZµi′j′,ij , (2)
Vi
</equation>
<bodyText confidence="0.9999241">
where, U denotes the number of candidate men-
tions that contain ei (i.e. U = |{dj|(ei, dj) ∈
R}|). k denotes the number of all candidate men-
tions (i.e. k = |R|). Co-mention is represented
by a prior score. Wang et al. (2012) defined
prior score 7rij of (ei, dj) as the number of unique
names of target entities occurred in dj.
The final score of each mention is decided by
its prior score estimation as well as the score of
the other correlated mentions.
</bodyText>
<equation confidence="0.9643755">
rij = Apij + (1 − A) ∑ wij,i′j′ri′j′, (4)
i′,j′
</equation>
<bodyText confidence="0.99995225">
where A is the dumping factor. pij denotes prior
score of (ei, dj): pij = 7rij/ ∑i′,j′ 7ri′j′
Although this model works even if only the
names of entities are given as input, we can ex-
tend this model to integrate external knowledge
such as Wikipedia. For example, we can add refer-
ence pages for each entity as virtual nodes. Since
we can assume that the reference page of a tar-
get entity is a true mention with a high confidence,
we assign a high prior score than the other men-
tions. This causes the group of candidate men-
tions which have similar contexts with the refer-
ence pages to get higher scores. One example of
using reference pages is to add a set of reference
pages {ai|1 ≤ i ≤ n} into the mention graph. ai
denotes the reference page of entity ei.
</bodyText>
<sectionHeader confidence="0.99808" genericHeader="method">
4 Proposed Method
</sectionHeader>
<bodyText confidence="0.9985135">
In this section, we propose our approach for auto-
matic selection of reference pages. In the domain
of Word Sense Disambiguation and Entity Link-
ing, some researches proposed the methods which
</bodyText>
<figure confidence="0.541428">
Z=max ∑ ∑ , (3)
i,j i′̸�i j′ µi′j′,ij
Vi
</figure>
<page confidence="0.789037">
107
</page>
<figureCaption confidence="0.8310155">
Figure 1: Article “Apple (disambiguation)” in
Wikipedia
</figureCaption>
<bodyText confidence="0.951510333333333">
are based on coherence between mentions (Hof-
fart et al., 2011; Kulkarni et al., 2009; Han et al.,
2011). Our method does not require any knowl-
edge except for the names of target entities. We
give only target entities as input. Target entities in
Wikipedia have two characteristics.
</bodyText>
<listItem confidence="0.9752008">
• A name of an ambiguous target entity tends
to have a disambiguation page.
• The articles that are in the same domain have
the same categories or contain similar con-
tents.
</listItem>
<bodyText confidence="0.981913318181818">
In Wikipedia, there are disambiguation pages like
Figure 1. “Apple (disambiguation)” contains apple
as a plant, an IT company, a music album, and so
on. To collect candidate reference pages, we use
these disambiguation pages.
Kulkarni et al. (2009) formalized entity linking
as an Integer Linear Programming problem and
then relaxed it as a Linear Programming problem.
They considered a coherence score which takes
higher value if the selected articles have similar
contents. Their framework can be used for entity
linking and word sense disambiguation. In this pa-
per, we use this coherence score to select reference
pages. We show an image of an automatic selec-
tion of reference pages in Figure 2. In Figure 2,
the target entities are Apple, HP and Microsoft.
Although we have only one page for Microsoft,
we have two or more candidate reference pages,
since Apple and HP have disambiguation pages.
Then we need to select reference pages for Ap-
ple and HP. If the name of a target entity is not
in Wikipedia, we have no reference page for that
</bodyText>
<figureCaption confidence="0.7282745">
Figure 2: Automatic selection of reference pages
from disambiguation pages in Wikipedia: selected
pages contains same categories or similar contents
(They are connected by edge).
</figureCaption>
<bodyText confidence="0.999543176470588">
target entity. The goal of this example is to select
“Apple Inc.” for Apple and “Hewlett-Packard” for
HP (Selecting “Microsoft” for Microsoft is triv-
ial). We regard these selected articles as reference
pages for target entities.
We assume that the number of true reference
page ai for target entity ei is one and select one
reference page for each target entity. For each tar-
get entity, we select articles which the have same
categories or similar contents from the set of can-
didate reference pages {cik|1 ≤ k ≤ l} since we
assume that the articles in the same domain have
the same categories or contain similar contents. In
fact, our model is going to maximize the summa-
tion of similarities between selected pages under
some constraints. We formalize this selection as
follows:
</bodyText>
<equation confidence="0.974455666666666">
eik,i′k′xik,i′k′,
yik = 1, (5)
yik ≥ xik,i′k′; ∀i, k, i′, k′, (6)
yi′k′ ≥ xik,i′k′; ∀i, k, i′, k′, (7)
xik,i′k′ ∈ {0, 1}; ∀i, k, i′, k′, (8)
yik ∈ {0,1}; ∀i, k, (9)
</equation>
<bodyText confidence="0.99114675">
eik,i′k′ denotes the weight of the edge between
candidate reference pages cik and ci′k′. xik,i′k′
takes 1 if cik is selected, 0 otherwise. yik takes
1 if the edge between cik and ci′k′ is selected, 0
</bodyText>
<equation confidence="0.953234">
max. E E
i,k i′,k′
�s.t. ∀i,
k
</equation>
<page confidence="0.995643">
108
</page>
<table confidence="0.99737">
n k #cand %Positive
Car 21 1809 21.5 29.9
Magazine 28 2741 17.9 43.5
</table>
<tableCaption confidence="0.9508745">
Table 1: Datasets: n is # of entities, k is # of can-
didate mentions, #cand is average # of candidate
reference pages for each entity and %Positive is %
of true mentions in all candidate mentions
</tableCaption>
<table confidence="0.999541533333333">
n=5 Car Magazine
MentionRank 39.74 61.07
MentionRank+manVN 39.14 70.94†
MentionRank+randomVN 37.85† 65.01
Proposed method 44.21 65.86
n=10
MentionRank 49.23 65.90†
MentionRank+manVN 47.21† 70.85
MentionRank+randomVN 45.13† 68.38
Proposed method 50.84 69.81
n=15
MentionRank 46.50† 65.77†
MentionRank+manVN 44.29 69.38
MentionRank+randomVN 39.21† 67.89
Proposed method 42.77 69.02
</table>
<tableCaption confidence="0.999154">
Table 2: Mean average precision for each dataset
</tableCaption>
<bodyText confidence="0.9937482">
otherwise. Constraint (5) ensures that always one
article is selected for each entity. Constraints (6)
and (7) ensure that when xik,i′k′ = 1, yik and yi′k′.
In this paper, we defined eik,i′k′ as cosine similar-
ity of two vectors of words those weights are tfidf.
</bodyText>
<sectionHeader confidence="0.999164" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99989675">
We used weblogs written in Japanese for experi-
ments. Following the previous work, we created
two datasets: Car and Magazine. A summary of
each dataset is shown in Table 1.
</bodyText>
<listItem confidence="0.9789895">
• Car: Target entities include car names such
as Prius and Harrier.
• Magazine: Target entities include magazine
names such as MORE and LEE.
</listItem>
<bodyText confidence="0.999967657894737">
We randomly selected 5, 10 or 15 entities from
each target entities for 10 times and conducted
experiment for each dataset with parameter A
= 0.15. We conducted significance test using
Wilcoxon signed-rank test. Table 2 lists the
experimental results on these datasets. In Ta-
ble 2, MentionRank+manVN denotes Mention-
Rank with virtual nodes that are selected manually
(Wang et al., 2012). MentionRank+randomVN
denotes MentionRank with virtual nodes that are
selected randomly from candidate reference pages
in Wikipedia. Proposed method denotes the Men-
tionRank with virtual nodes that are selected auto-
matically using ILP. Values with †in Table 2 indi-
cate that there are significant differences between
mean average precision of proposed method and
the others. Five results of proposed methods are
better than those of MentionRank, there are signif-
icant differences on two results. Furthermore, all
the results of proposed method is better than those
of MentionRank+randomVN and there are signif-
icant differences on three results. Four results of
proposed method is worse than those of Mention-
Rank+manVN, however there is a significant dif-
ference on only one of those results. From these
results, we can see that use of reference pages
automatically selected by our method improves
mean average precision. In Magazine, several en-
tities are not ambiguous and we could get true ref-
erence pages easily. Therefore, we think proposed
method did not show any significant differences
compared with MentionRank+randomVN. Also,
in Car, several entities are not ambiguous but these
reference pages belong to domains other than Car
domain. As a result, we think that some results
are worse than MentionRank. For example, entity
“86” which is a kind of car have only one reference
page that belongs to number domain.
</bodyText>
<sectionHeader confidence="0.999541" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999520625">
In this paper, we proposed an automatic selec-
tion method of reference pages for Target En-
tity Disambiguation. Our method that uses au-
tomatically selected reference pages showed bet-
ter performance than MentionRank without ref-
erence pages and competitive mean average pre-
cision with MentionRank with manually selected
reference pages.
Since our framework always selects one refer-
ence page for each target entity even if a reference
page does not exist in Wikipedia or one or more
reference pages exist in Wikipedia, we need to re-
fine our framework in future work. An another im-
provement would be to assign prior scores for vir-
tual nodes according to coherence score between
the other virtual nodes.
</bodyText>
<page confidence="0.998887">
109
</page>
<sectionHeader confidence="0.998316" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999115">
Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective
entity linking in web text: a graph-based method. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Infor-
mation Retrieval, SIGIR ’11, pages 765–774, New
York, NY, USA. ACM.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-
dino, Hagen F¨urstenau, Manfred Pinkal, Marc Span-
iol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011. Robust disambiguation of named
entities in text. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ’11, pages 782–792, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,
and Soumen Chakrabarti. 2009. Collective annota-
tion of Wikipedia entities in web text. In Proceed-
ings of the 15th ACM SIGKDD international con-
ference on Knowledge discovery and data mining,
KDD ’09, pages 457–466, New York, NY, USA.
ACM.
Roberto Navigli. 2009. Word sense disambiguation:
A survey. ACM Comput. Surv., 41(2):10:1–10:69,
February.
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical Report
1999-66, Stanford InfoLab, November.
Chi Wang, Kaushik Chakrabarti, Tao Cheng, and Sura-
jit Chaudhuri. 2012. Targeted disambiguation of
ad-hoc, homogeneous sets of named entities. In
Proceedings of the 21st international conference on
World Wide Web, WWW ’12, pages 719–728, New
York, NY, USA. ACM.
</reference>
<page confidence="0.9984">
110
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.718153">
<title confidence="0.998379">Automatic Selection of Reference Pages in for Improving Targeted Entities Disambiguation</title>
<author confidence="0.777051">Takuya</author>
<affiliation confidence="0.872651">Fujitsu Laboratories</affiliation>
<address confidence="0.927377">4-1-1 Kamikodanaka, Nakahara-ku, Kawasaki,</address>
<email confidence="0.999919">makino.takuya@jp.fujitsu.com</email>
<abstract confidence="0.998641692307692">In Targeted Entity Disambiguation setting, we take (i) a set of entity names which belong to the same domain (target entities), (ii) candidate mentions of the given entities which are texts that contain the target entities as input, and then determine which ones are true mentions of “target entity”. For example, given the names of IT companies, including Apple, we determine Apple in a mention denotes an IT company or not. Prior work proposed a graph based model. This model ranks all candidate mentions based on scores which denote the degree of relevancy to target entities. Furthermore, this graph based model could utilize reference pages of target entities. However, human annotators must select reference pages in advance. We propose an automatic method that can select reference pages. We formalize the selection problem of reference pages as an Integer Linear Programming problem. We show that our model works as well as the prior work that manually selected reference pages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
<author>Jun Zhao</author>
</authors>
<title>Collective entity linking in web text: a graph-based method.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, SIGIR ’11,</booktitle>
<pages>765--774</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Han, Le Sun, Zhao, 2011</marker>
<rawString>Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective entity linking in web text: a graph-based method. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, SIGIR ’11, pages 765–774, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Bilyana Taneva</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>782--792</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 782–792, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sayali Kulkarni</author>
<author>Amit Singh</author>
<author>Ganesh Ramakrishnan</author>
<author>Soumen Chakrabarti</author>
</authors>
<title>Collective annotation of Wikipedia entities in web text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’09,</booktitle>
<pages>457--466</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3682" citStr="Kulkarni et al., 2009" startWordPosition="617" endWordPosition="620">ionRank could integrate external knowledge such as Wikipedia. For each target entity, a reference page is added as a virtual node to the graph. Since reference pages can be regarded as true mentions, the prior scores of virtual nodes are higher than other mentions. This extended method can propagate the score of the virtual node of each entity to candidate mentions which are likely true. Although the use of reference pages works well, human annotators must select these reference pages. In Word Sense Disambiguation and Entity Linking, there are some collective approaches (Hoffart et al., 2011; Kulkarni et al., 2009). In this paper, we apply this technique to the selection problem of reference pages for TED. To select refer106 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 106–110, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics ence pages, we collect candidate reference pages of target entities from Wikipedia in advance. If the name of a target entity has a disambiguation page in Wikipedia, we have two or more candidate reference pages. Then we formalize the problem of reference page selection as an</context>
<context position="8042" citStr="Kulkarni et al., 2009" startWordPosition="1394" endWordPosition="1397">ch have similar contexts with the reference pages to get higher scores. One example of using reference pages is to add a set of reference pages {ai|1 ≤ i ≤ n} into the mention graph. ai denotes the reference page of entity ei. 4 Proposed Method In this section, we propose our approach for automatic selection of reference pages. In the domain of Word Sense Disambiguation and Entity Linking, some researches proposed the methods which Z=max ∑ ∑ , (3) i,j i′̸�i j′ µi′j′,ij Vi 107 Figure 1: Article “Apple (disambiguation)” in Wikipedia are based on coherence between mentions (Hoffart et al., 2011; Kulkarni et al., 2009; Han et al., 2011). Our method does not require any knowledge except for the names of target entities. We give only target entities as input. Target entities in Wikipedia have two characteristics. • A name of an ambiguous target entity tends to have a disambiguation page. • The articles that are in the same domain have the same categories or contain similar contents. In Wikipedia, there are disambiguation pages like Figure 1. “Apple (disambiguation)” contains apple as a plant, an IT company, a music album, and so on. To collect candidate reference pages, we use these disambiguation pages. Kul</context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti. 2009. Collective annotation of Wikipedia entities in web text. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’09, pages 457–466, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Comput. Surv.,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="2160" citStr="Navigli, 2009" startWordPosition="345" endWordPosition="347"> as other meanings. Wang et al. (2012) proposed a new task which they referred to as Targeted Entity Disambiguation (TED). In this problem setting, we take (i) a set of entity names which belong to the same domain (target entities), (ii) candidate mentions of the given entities which are texts that contain the target entity entities as input, and then determine which ones are true mentions for the target entities. TED is different from traditional Word Sense Disambiguation or Entity Linking. Word Sense Disambiguation can be viewed as a classification task in which word senses are the classes (Navigli, 2009) and Entity Linking is the task of linking name in Web text with entities in Wikipedia (Han et al., 2011). The uniqueness of this problem is that the entities are all in the same domain (referred to as the target domain) and not necessarily included in a knowledge base such as DBpedia, Freebase or YAGO. Wang et al. (2012) realized TED with a graph based model. In their graph based method, a target entity in a mention is regarded as a node, and the weight of an edge is determined according to context similarity, and a prior score of node that is determined according to the unique number of targ</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Comput. Surv., 41(2):10:1–10:69, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<tech>Technical Report 1999-66,</tech>
<institution>Stanford InfoLab,</institution>
<contexts>
<context position="2961" citStr="Page et al., 1999" startWordPosition="495" endWordPosition="498">in (referred to as the target domain) and not necessarily included in a knowledge base such as DBpedia, Freebase or YAGO. Wang et al. (2012) realized TED with a graph based model. In their graph based method, a target entity in a mention is regarded as a node, and the weight of an edge is determined according to context similarity, and a prior score of node that is determined according to the unique number of target entities in the mention. This graph is called as a mention graph. Using mention graph, the authority of each mention is calculated with MentionRank which is a variant of PageRank (Page et al., 1999). This authority denotes a score of how likely this node is in the target domain. In addition, MentionRank could integrate external knowledge such as Wikipedia. For each target entity, a reference page is added as a virtual node to the graph. Since reference pages can be regarded as true mentions, the prior scores of virtual nodes are higher than other mentions. This extended method can propagate the score of the virtual node of each entity to candidate mentions which are likely true. Although the use of reference pages works well, human annotators must select these reference pages. In Word Se</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web. Technical Report 1999-66, Stanford InfoLab, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi Wang</author>
<author>Kaushik Chakrabarti</author>
<author>Tao Cheng</author>
<author>Surajit Chaudhuri</author>
</authors>
<title>Targeted disambiguation of ad-hoc, homogeneous sets of named entities.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web, WWW ’12,</booktitle>
<pages>719--728</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1584" citStr="Wang et al. (2012)" startWordPosition="247" endWordPosition="250">se an automatic method that can select reference pages. We formalize the selection problem of reference pages as an Integer Linear Programming problem. We show that our model works as well as the prior work that manually selected reference pages. 1 Introduction The enterprise is typically interested in customer’s opinions. One of the methods to analyze customer’s opinions is to collect mentions which contain product names. We would get a noisy mention collection if we use a simple method which extracts mentions that contain product names, since the product names may be used as other meanings. Wang et al. (2012) proposed a new task which they referred to as Targeted Entity Disambiguation (TED). In this problem setting, we take (i) a set of entity names which belong to the same domain (target entities), (ii) candidate mentions of the given entities which are texts that contain the target entity entities as input, and then determine which ones are true mentions for the target entities. TED is different from traditional Word Sense Disambiguation or Entity Linking. Word Sense Disambiguation can be viewed as a classification task in which word senses are the classes (Navigli, 2009) and Entity Linking is t</context>
<context position="4987" citStr="Wang et al., 2012" startWordPosition="833" endWordPosition="836">milarities between selected pages under some constraints. Thus, coherent pages are selected as reference pages. Our method does not require any knowledge except for names of target entities. We give only target entities as input to select reference pages. Our method shows competitive accuracy of the prior method with manually selected reference pages. 2 Task Definition Following previous work, we assume that all occurrences of a name in a mention refer to the same entity (e.g., occurrences of the string “Apple” in a single mention either all refer to the IT company or all refer to the fruit) (Wang et al., 2012). TED is defined as follows. Definition 1 (Targeted Entity Disambiguation). Given input of a target entity set E = {ei, ..., en}, a mention set D = {di, ..., dn} and candidate mentions R = {(ei, dj)|ei ∈ E, dj ∈ D}, output score rij ∈ [0, 1] for every candidate mention (ei, dj) ∈ R. 3 Related Work Wang et al. (2012) proposed MentionRank to address TED. MentionRank is similar to PageRank. This model is based on three hypotheses: 1. Context similarity: The true mentions across all the entities, across all the mentions will have more similar contexts than the false mentions of different entities.</context>
<context position="6611" citStr="Wang et al. (2012)" startWordPosition="1130" endWordPosition="1133">as wij,i′j′ which is a variable normalized by context similarity µij,i′j′. Context similarities are normalized to avoid “false-boost” problem. “false-boost” problem is boosting ranking score of false mentions in a false mentions group. The normalized weight of the edge is defined as follows: { zij if i = i′, wij,i′j′ =µi′j′,ij k ViZ + zijk otherwise. (1) zij = 1 − ∑∑ i′ i UZµi′j′,ij , (2) Vi where, U denotes the number of candidate mentions that contain ei (i.e. U = |{dj|(ei, dj) ∈ R}|). k denotes the number of all candidate mentions (i.e. k = |R|). Co-mention is represented by a prior score. Wang et al. (2012) defined prior score 7rij of (ei, dj) as the number of unique names of target entities occurred in dj. The final score of each mention is decided by its prior score estimation as well as the score of the other correlated mentions. rij = Apij + (1 − A) ∑ wij,i′j′ri′j′, (4) i′,j′ where A is the dumping factor. pij denotes prior score of (ei, dj): pij = 7rij/ ∑i′,j′ 7ri′j′ Although this model works even if only the names of entities are given as input, we can extend this model to integrate external knowledge such as Wikipedia. For example, we can add reference pages for each entity as virtual nod</context>
<context position="12482" citStr="Wang et al., 2012" startWordPosition="2141" endWordPosition="2144">, we created two datasets: Car and Magazine. A summary of each dataset is shown in Table 1. • Car: Target entities include car names such as Prius and Harrier. • Magazine: Target entities include magazine names such as MORE and LEE. We randomly selected 5, 10 or 15 entities from each target entities for 10 times and conducted experiment for each dataset with parameter A = 0.15. We conducted significance test using Wilcoxon signed-rank test. Table 2 lists the experimental results on these datasets. In Table 2, MentionRank+manVN denotes MentionRank with virtual nodes that are selected manually (Wang et al., 2012). MentionRank+randomVN denotes MentionRank with virtual nodes that are selected randomly from candidate reference pages in Wikipedia. Proposed method denotes the MentionRank with virtual nodes that are selected automatically using ILP. Values with †in Table 2 indicate that there are significant differences between mean average precision of proposed method and the others. Five results of proposed methods are better than those of MentionRank, there are significant differences on two results. Furthermore, all the results of proposed method is better than those of MentionRank+randomVN and there ar</context>
</contexts>
<marker>Wang, Chakrabarti, Cheng, Chaudhuri, 2012</marker>
<rawString>Chi Wang, Kaushik Chakrabarti, Tao Cheng, and Surajit Chaudhuri. 2012. Targeted disambiguation of ad-hoc, homogeneous sets of named entities. In Proceedings of the 21st international conference on World Wide Web, WWW ’12, pages 719–728, New York, NY, USA. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>