<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9975905">
Towards Modular Development
of Typed Unification Grammars
</title>
<author confidence="0.998697">
Yael Sygal*
</author>
<affiliation confidence="0.995741">
University of Haifa
</affiliation>
<author confidence="0.988998">
Shuly Wintner**
</author>
<affiliation confidence="0.99355">
University of Haifa
</affiliation>
<subsubsectionHeader confidence="0.576529">
Development of large-scale grammars for natural languages is a complicated endeavor: Gram-
</subsubsectionHeader>
<bodyText confidence="0.995988388888889">
mars are developed collaboratively by teams of linguists, computational linguists, and computer
scientists, in a process very similar to the development of large-scale software. Grammars are
written in grammatical formalisms that resemble very-high-level programming languages, and
are thus very similar to computer programs. Yet grammar engineering is still in its infancy: Few
grammar development environments support sophisticated modularized grammar development,
in the form of distribution of the grammar development effort, combination of sub-grammars,
separate compilation and automatic linkage, information encapsulation, and so forth.
This work provides preliminary foundations for modular construction of (typed) unification
grammars for natural languages. Much of the information in such formalisms is encoded by
the type signature, and we subsequently address the problem through the distribution of the
signature among the different modules. We define signature modules and provide operators
of module combination. Modules may specify only partial information about the components
of the signature and may communicate through parameters, similarly to function calls in pro-
gramming languages. Our definitions are inspired by methods and techniques of programming
language theory and software engineering and are motivated by the actual needs of grammar
developers, obtained through a careful examination of existing grammars. We show that our def-
initions meet these needs by conforming to a detailed set of desiderata. We demonstrate the utility
of our definitions by providing a modular design of the HPSG grammar of Pollard and Sag.
</bodyText>
<sectionHeader confidence="0.996906" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9990966">
Development of large-scale grammars for natural languages is an active area of research
in human language technology. Such grammars are developed not only for purposes
of theoretical linguistic research, but also for natural language applications such as
machine translation, speech generation, and so on. Wide-coverage grammars are being
developed for various languages (Abeill´e, Candito, and Kinyon 2000; XTAG Research
</bodyText>
<affiliation confidence="0.685124">
* Department of Computer Science, University of Haifa, 31905 Haifa, Israel.
E-mail: yael.sygal®gmail.com.
** Department of Computer Science, University of Haifa, 31905 Haifa, Israel.
</affiliation>
<email confidence="0.61535">
E-mail: shuly®cs.haifa.ac.il.
</email>
<note confidence="0.938230875">
Submission received: 3 June 2009; revised submission received: 21 June 2010; accepted for publication:
14 September 2010.
© 2011 Association for Computational Linguistics
Computational Linguistics Volume 37, Number 1
Group 2001; Oepen et al. 2002; Hinrichs, Meurers, and Wintner 2004; Bender et al. 2005;
King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi,
Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and
XDG (Debusmann, Duchier, and Rossberg 2005).
</note>
<bodyText confidence="0.999858583333333">
Grammar development is a complex enterprise: It is not unusual for a single gram-
mar to be developed by a team including several linguists, computational linguists, and
computer scientists. The scale of grammars is overwhelming—large-scale grammars
can be made up by tens of thousands of line of code (Oepen et al. 2000) and may
include thousands of types (Copestake and Flickinger 2000). Modern grammars are
written in grammatical formalisms that are often reminiscent of very-high-level, declar-
ative (mostly logical) programming languages, and are thus very similar to computer
programs. This raises problems similar to those encountered in large-scale software
development (Erbach and Uszkoreit 1990). Although whereas software engineering
provides adequate solutions for the programmer, grammar engineering is still in its
infancy.
In this work we focus on typed unification grammars (TUG), and their implementa-
tion in grammar-development platforms such as LKB (Copestake 2002), ALE (Carpenter
and Penn 2001), TRALE (Meurers, Penn, and Richter 2002), or Grammix (M¨uller 2007).
Such platforms conceptually view the grammar as a single entity (even when it is
distributed over several files), and provide few provisions for modular grammar de-
velopment, such as mechanisms for defining modules that can interact with each other
through well-defined interfaces, combination of sub-grammars, separate compilation
and automatic linkage of grammars, information encapsulation, and so forth. This is
the main issue that we address in this work.1
We provide a preliminary yet thorough and well-founded solution to the problem
of grammar modularization. We first specify a set of desiderata for a beneficial solu-
tion in Section 1.1, and then survey related work, emphasizing the shortcomings of
existing approaches with respect to these desiderata. Much of the information in typed
unification grammars is encoded in the signature, and hence the key is facilitating a
modularized development of type signatures. In Section 2 we introduce a definition
of signature modules, and show how two signature modules combine and how the
resulting signature module can be extended to a stand-alone type signature. We lift our
definitions from signatures to full grammar modules in Section 3. In Section 4 we use
signature modules and their combination operators to work out a modular design of
the HPSG grammar of Pollard and Sag (1994), demonstrating the utility of signature
modules for the development of linguistically motivated grammars. We then outline
MODALS, an implementation of our solutions which supports modular development
of type signatures in the context of both ALE and TRALE (Section 5). We show in
Section 6 how our solution complies with the desiderata of Section 1.1, and conclude
with directions for future research.
</bodyText>
<subsectionHeader confidence="0.987089">
1.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999624">
The motivation for modular grammar development is straightforward. Like software
development, large-scale grammar development is much simpler when the task can be
cleanly distributed among different developers, provided that well-defined interfaces
govern the interaction among modules. From a theoretical point of view, modularity
</bodyText>
<footnote confidence="0.664285">
1 This article extends and revises Cohen-Sygal and Wintner (2006) and Sygal and Wintner (2008).
</footnote>
<page confidence="0.987859">
30
</page>
<note confidence="0.783972">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<bodyText confidence="0.999290675">
facilitates the definition of cleaner semantics for the underlying formalism and the
construction of correctness proofs. The engineering benefits of modularity in program-
ming languages are summarized by Mitchell (2003, page 235), and are equally valid for
grammar construction:
In an effective design, each module can be designed and tested independently. Two
important goals in modularity are to allow one module to be written with little
knowledge of the code in another module and to allow a module to be redesigned
and re-implemented without modifying other parts of the system.
A suitable notion of modularity should support “reuse of software, abstraction mech-
anisms for information hiding, and import/export relationships” (Brogi et al. 1994,
page 1363). Similarly, Bugliesi, Lamma, and Mello (1994, page 444) state that
[a] modular language should allow rich forms of abstraction, parametrization, and
information hiding; it should ease the development and maintenance of large programs
as well as provide adequate support or reusability and separate and efficient
compilation; it should finally encompass a non-trivial notion of program equivalence
to make it possible to justify the replacement of equivalent components.
In the linguistic literature, however, modularity has a different flavor which has to
do with the way linguistic knowledge is organized, either cognitively (Fodor 1983) or
theoretically (Jackendoff 2002, pages 218–230). Although we do not directly subscribe to
this notion of modularity in this work, it may be the case that an engineering-inspired
definition of modules will facilitate a better understanding of the linguistic notion.
Furthermore, although there is no general agreement among linguists on the exact form
of grammar modularity, a good solution for grammar development must not reflect the
correctness of linguistic theories but rather provide the computational framework for
their implementation.
To consolidate the two notions of modularity, and to devise a solution that is on one
hand inspired by developments in programming languages and on the other useful for
linguists, a clear understanding of the actual needs of grammar developers is crucial. A
first step in this direction was done by Erbach and Uszkoreit (1990). In a similar vein,
we carefully explored two existing grammars: the LINGO grammar matrix (Bender,
Flickinger, and Oepen 2002),2 which is a framework for rapid development of cross-
linguistically consistent grammars; and a grammar of a fragment of modern Hebrew,
focusing on inverted constructions (Melnik 2006). These grammars were chosen since
they are comprehensive enough to reflect the kind of data large-scale grammars encode,
but are not too large to encumber this process.
Inspired by established criteria for modularity in programming languages, and
motivated by our observation of actual grammars, we define the following desiderata
for a beneficial solution for (typed unification) grammar modularization:
Signature focus: Much of the information in typed formalisms is encoded by the signa-
ture. This includes the type hierarchy, the appropriateness specification, and the
</bodyText>
<footnote confidence="0.540466666666667">
2 The LINGO grammar matrix is not a grammar per se, but rather a framework for grammar development
for several languages. We focused on its core grammar and several of the resulting, language-specific
grammars.
</footnote>
<page confidence="0.999393">
31
</page>
<note confidence="0.798865">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.9745383">
type constraints. Hence, modularization must be carried out mainly through the
distribution of the signature between the different modules.3
Partiality: Modules should provide means for specifying partial information about the
components of a grammar: both the grammar itself and the signature over which
it is defined.
Extensibility: Although modules can specify partial information, it must be possible to
deterministically extend a module (which can be the result of the combination of
several modules) into a full grammar.
Consistency: Contradicting information in different modules must be detected when
modules are combined.
Flexibility: The grammar designer should be provided with as much flexibility as
possible. Modules should not be unnecessarily constrained.
(Remote) Reference: A good solution should enable one module to refer to entities
defined in another. Specifically, it should enable the designer of module Mi to use
an entity (e.g., a type or a feature structure) defined in Mj without specifying the
entity explicitly.
Parsimony: When two modules are combined, the resulting module must include all
the information encoded in each of the modules and the information resulting
from the combination operation. Additional information must only be added if it
is essential to render the module well-defined.
Associativity: Module combination must be associative and commutative: The order
in which modules are combined must not affect the result. However, this desider-
atum is not absolute—it is restricted to cases where the combination formulates
a simple union of data. In other cases, associativity and commutativity should be
considered with respect to the benefit the system may enjoy if they are abandoned.
Privacy: Modules should be able to hide (encapsulate) information and render it un-
available to other modules.
The solution we advocate here satisfies all these requirements. It facilitates col-
laborative development of grammars, where several applications of modularity are
conceivable:
</bodyText>
<listItem confidence="0.945397444444445">
• A single large-scale grammar developed by a team.
• Development of parallel grammars for multiple languages under a single
theory, as in Bender et al. (2005), King et al. (2005), or M¨uller (2007). Here,
a core module is common to all grammars, and language-specific
fragments are developed as separate modules.
• A sequence of grammars modeling language development, for example
language acquisition or (historical) language change (Wintner, Lavie, and
MacWhinney 2009). Here, a “new” grammar is obtained from a “previous”
grammar; formal modeling of such operations through module
</listItem>
<bodyText confidence="0.9131555">
composition can shed new light on the linguistic processes that take place
as language develops.
</bodyText>
<footnote confidence="0.92221">
3 We restrict ourselves to standard type signatures (as defined by Carpenter [1992] and Penn [2000]),
ignoring type constraints which are becoming common in practical systems. We defer an extension of our
results to type constraints to future work.
</footnote>
<page confidence="0.991307">
32
</page>
<note confidence="0.909929">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<sectionHeader confidence="0.885965" genericHeader="related work">
1.2 Related Work
</sectionHeader>
<bodyText confidence="0.99230565116279">
1.2.1 Modularity in Programming Languages. Vast literature addresses modularity in pro-
gramming languages, and a comprehensive survey is beyond the scope of this work. As
unification grammars are in many ways very similar to logic programming languages,
our desiderata and solutions are inspired by works in this paradigm.
Modular interfaces of logic programs were first suggested by O’keefe (1985) and
Gaifman and Shapiro (1989). Combination operators that were proved suitable for
Prolog include the algebraic operators ⊕ and ⊗ of Mancarella and Pedreschi (1988);
the union and intersection operators of Brogi et al. (1990); the closure operator of Brogi,
Lamma, and Mello (1993); and the set of four operators (encapsulation, union, inter-
section, and import) defined by Brogi and Turini (1995). For a comprehensive survey,
see Bugliesi, Lamma, and Mello (1994).
The ‘merge’ operator that we present in Section 2.4.2 is closely related to union
operations proposed for logic programming languages. We define no counterpart of
intersection-type operations, although such operations are indeed conceivable. Our
‘attachment’ operation is more in line with Gaifman and Shapiro (1989).
1.2.2 Initial Approaches: Modularized Parsing. Early attempts to address modularity in
linguistic formalisms share a significant disadvantage: The modularization is of the
parsing process rather than the grammar.
Kasper and Krieger (1996) describe a technique for dividing a unification-based
grammar into two components, roughly along the syntax/semantics axis. Their mo-
tivation is efficiency; observing that syntax usually imposes constraints on permissible
structures, and semantics usually mostly adds structure, they propose to parse with the
syntactic constraints first, and apply the semantics later. This is achieved by recursively
deleting the syntactic and semantic information (under their corresponding attributes
in the rules and the lexicon) for the semantic and syntactic parsers, respectively. This
proposal requires that a single grammar be given, from which the two components can
be derived. A more significant disadvantage of this method is that coreferences between
syntax and semantics are lost during this division (because reentrancies that represent
the connection between the syntax and the semantics are removed). Kasper and Krieger
observe that the intersection of the languages generated by the two grammars does not
yield the language of the original grammar.
Zajac and Amtrup (2000) present an implementation of a pipeline-like composition
operator that enables the grammar designer to break a grammar into sub-grammars that
are applied in a sequential manner at run-time. Such an organization is especially useful
for dividing the development process into stages that correspond to morphological
processing, syntax, semantics, and so on. The notion of composition here is such that
sub-grammar Gi+1 operates on the output of sub-grammar Gi; such an organization
might not be suitable for all grammar development frameworks. A similar idea is pro-
posed by Basili, Pazienza, and Zanzotto (2000); it is an approach to parsing that divides
the task into sub-tasks, whereby a module component Pi takes an input sentence at a
given state of analysis Si and augments this information in Si+1 using a knowledge base
Ki. Here, too, it is the processing system, rather than the grammar, which is modularized
in a pipeline fashion.
</bodyText>
<footnote confidence="0.97218425">
1.2.3 Modularity in Typed Unification Grammars. Keselj (2001) presents a modular Head-
driven Phrase Structure Grammar (HPSG), where each module is an ordinary HPSG
grammar, including an ordinary type signature, but each of the sets FEAT, TYPE, and
RULES is divided into two disjoint sets of private and public elements. The public
</footnote>
<page confidence="0.99468">
33
</page>
<note confidence="0.799173">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.998993130434783">
sets consist of those elements that can communicate with elements from corresponding
sets in other modules, and private elements are those that are internal to the module.
Merging two modules is then defined by set union; in particular, the type hierarchies
are merged by unioning the two sets of types and taking the transitive closure of the
union of the two BCPOs (see Definition 2). The success of the merge of two modules
requires that the union of the two BCPOs be a BCPO.
While this work is the first to concretely define signature modules, it provides
a highly insufficient mechanism for supporting modular grammar development: The
requirement that each module include a complete type hierarchy imposes strong lim-
itations on the kind of information that modules can specify. It is virtually impossible
to specify partial information that is consistent with the complete type hierarchy re-
quirement. Furthermore, module composition becomes order-dependent as we show in
Example 8 (Section 2.4.2). Finally, the only channel of interaction between modules is
the names of the types. Our work is similar in spirit to Keselj (2001), but it overcomes
these shortcomings and complies with the desiderata of Section 1.1.
Kaplan, King, and Maxwell (2002) introduce a system designed for building a gram-
mar by both extending and restricting another grammar. An LFG grammar is presented
to the system in a priority-ordered sequence of files containing phrase-structure rules,
lexical entries, abbreviatory macros and templates, feature declarations, and finite-state
transducers for tokenization and morphological analysis. The grammar can include
only one definition of an item of a given type with a particular name (e.g., there can be
only one NP rule, potentially with many alternative expansions), and items in a file with
higher priority override lower priority items of the same type with the same name. The
override convention makes it possible to add, delete, or modify rules. However, when a
rule is modified, the entire rule has to be rewritten, even if the modifications are minor.
Moreover, there is no real concept of modularization in this approach because the only
interaction among files is overriding of information.
King et al. (2005) augment LFG with a makeshift signature to allow modular
development of untyped unification grammars. In addition, they suggest that any de-
velopment team should agree in advance on the feature space. This work emphasizes
the observation that the modularization of the signature is the key for modular devel-
opment of grammars. However, the proposed solution is ad hoc and cannot be taken
seriously as a concept of modularization. In particular, the suggestion for an agreement
on the feature space undermines the essence of modular design.
To support rapid prototyping of deep grammars, Bender and Flickinger (2005)
propose a framework in which the grammar developer can select pre-written grammar
fragments, accounting for common linguistic phenomena that vary across languages
(e.g., word order, yes–no questions, and sentential negation). The developer can spec-
ify how these phenomena are realized in a given language, and a grammar for that
language is automatically generated, implementing that particular realization of the
phenomenon, integrated with a language-independent grammar core. This framework
addresses modularity in the sense that the entire grammar is distributed between sev-
eral fragments that can be combined in different ways, according to the user’s choice.
However, the notion of modularity is rather different here, as modules are pre-written
pieces of code which the grammar designer does not develop and whose interaction he
or she has little control over.
</bodyText>
<footnote confidence="0.709965666666667">
1.2.4 Modularity in Related Formalisms. The previously mentioned works emphasize the
fact that existing approaches to modular grammar development in the area of unifica-
tion grammars are still insufficient. The same problem has also been addressed in some
</footnote>
<page confidence="0.997793">
34
</page>
<subsectionHeader confidence="0.478087">
Sygal and Wintner Modular Typed Unification Grammars
</subsectionHeader>
<bodyText confidence="0.99989392">
other, related, formalisms; we now survey such works and discuss the applicability of
the proposed solutions to the problem of modularity in typed unification grammars.
Wintner (2002) defines the concept of modules for CFGs: The set of nonterminals
is partitioned into three disjoint classes of internal, exported, and imported elements.
The imported elements are those that are supplied to the module by other modules, the
exported elements are those it provides to the outside world, and the internal ones are
local to it. Two modules can be combined only if the set of internal elements of each
module is disjoint from the exported and imported sets of the other module as well as if
the exported sets are disjoint. Then the combination of two modules is done by simple
measures of set union. This is the infrastructure underlying the definition of modular
HPSG discussed earlier (Keselj 2001).
Provisions for modularity have also been discussed in the context of tree-adjoining
grammars (TAG) (Joshi, Levy, and Takahashi 1975). A wide-coverage TAG may contain
hundreds or even thousands of elementary trees, and syntactic structure can be redun-
dantly repeated in many of them (XTAG Research Group 2001; Abeill´e, Candito, and
Kinyon 2000). Consequently, maintenance and extension of such grammars is a complex
task. To address these issues, several high-level formalisms were developed (Vijay-
Shanker 1992; Candito 1996; Duchier and Gardent 1999; Kallmeyer 2001). These for-
malisms take the metagrammar approach, where the basic units are tree descriptions (i.e.,
formulas denoting sets of trees) rather than trees. Tree descriptions are constructed by a
tree logic and combined through conjunction or inheritance; a module in this approach
is merely a tree description, and modules are combined by means of the control logic.
When trees are semantic objects, (i.e., the denotation of tree descriptions), there can be
various ways to refer to nodes in the trees in order to control the possible combination
of grammar modules. Several mechanisms have been suggested to facilitate reference
across modules (Candito 1996; Perrier 2000; Crabb´e and Duchier 2004; Kahane 2006).
The solution that we propose here embraces the idea of moving from concrete
objects (e.g., a concrete type signature) to descriptions thereof; but we take special care
to do so in a way that maintains the associativity of the main grammar combination
operator, in contrast to some earlier approaches (Sygal and Wintner 2009).
Debusmann, Duchier, and Rossberg (2005) introduce Extensible Dependency Gram-
mar (XDG), which is a general framework for dependency grammars that supports
modular grammar design. An XDG grammar consists of dimensions, principles, and a
lexicon; it characterizes a set of well-formed analyses. Each dimension is an attributed
labeled graph, and when a grammar consists of multiple dimensions (e.g., multigraphs),
they share the same set of nodes. A lexicon for a dimension is a set of total assignments
of nodes and labels. The main mechanism XDG uses to control analyses are principles,
that can be either local (imposing a constraint on the possible analysis of a specific
dimension) or multi-dimensional (constraining the analysis of several dimensions
with respect to each other). In XDG, principles are formulated using a type-system
that includes several kinds of elementary types (e.g., nodes, edges, graphs, and even
multigraphs) and complex types that are constructed incrementally over the elementary
types. Then, parameters range over types to formulate parametric principles. A feasible
XDG analysis amounts to a labeled graph in which each dimension is a subgraph,
such that all (parametric) principles are maintained (this may require nodes in differ-
ent subgraphs to be identified). XDG supports modular grammar design where each
dimension graph is a grammar module, and module interaction is governed through
multi-dimensional parametric principles.
This work emphasizes the importance of types as a mechanism for modularity.
Our work shares with XDG the use of graphs as the basic components and the use
</bodyText>
<page confidence="0.996782">
35
</page>
<note confidence="0.296307">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.999938555555556">
of parameters to enforce interaction among modules. In both works, each module
introduces constraints on the type system and interaction among modules through
parameters is used to construct a multigraph in which some of the nodes are identified.
In our approach, however, the type system is part of the grammar specification, and
modules are combined via explicit combination operations. In contrast, in XDG the
type mechanism is used externally, to describe objects, and a general description logic is
used to impose constraints. Another major difference has to do with expressive power:
Whereas unification grammars are Turing-equivalent, XDG is probably mildly context-
sensitive (Debusmann 2006).
The grammar formalism (GF) (Ranta 2007) is a typed functional programming
language designed for multilingual grammars. Ranta introduces a module system for
GF where a module can be either one of three kinds: abstract, concrete, or a resource
module. Each of them reflects the kind of data this module may include. A module of
type abstract includes abstract syntax trees which represent grammatical information,
such as semantic or syntactic data. A module of type concrete includes relations between
trees in the abstract module and relations between strings in the target language.
Communication between modules of these two types is carried out through inheri-
tance hierarchies similarly to object-oriented programs. Resource modules are a means
for code-sharing, independently of the hierarchies. The system of modules supports
development of multilingual grammars through replacement of certain modules with
others. A given grammar can also be extended by adding new modules. Additionally, to
avoid repetition of code with minor variations, GF allows the grammar writer to define
operations which produce new elements.
GF is purposely designed for multilingual grammars which share a core represen-
tation, and individual extensions to different languages are developed independently.
As such, the theoretical framework it provides is tailored for such needs, but is lacking
where general purpose modular applications are considered (see section 1.1 for exam-
ples of such conceivable applications). Mainly, GF forces the developer to pre-decide on
the relations between all modules (through the concrete module and inheritance hierar-
chies), whereas in an ideal solution the interaction between all modules should be left to
the development process. Each module should be able to independently declare its own
interface with other modules; then, when modules combine they may do so in any way
that is consistent with the interfaces of other modules. Furthermore, reference to mutual
elements in GF is carried out only through naming, again resulting in a weak interface
for module interaction. Finally, the operations that the grammar writer can define in GF
are macros, rather than functions, as they are expanded by textual replacement.
</bodyText>
<subsectionHeader confidence="0.705916">
2. Modularization of the Signature
2.1 Typed Signatures
</subsectionHeader>
<bodyText confidence="0.9999658">
We assume familiarity with theories of (typed) unification grammar, as formulated by,
for example, Carpenter (1992) and Penn (2000). The definitions in this section set the
notation and recall basic notions. For a partial function F, ‘F(x)l’ (‘F(x)r’) means that F
is defined (undefined) for the value x; ‘F(x) = F(y)’ means that either F is defined both
for x and for y and assigns them equal values or it is undefined for both.
</bodyText>
<sectionHeader confidence="0.426083" genericHeader="method">
Definition 1
</sectionHeader>
<bodyText confidence="0.8087115">
Given a partially ordered set (P, &lt;), the set of upper bounds of a subset S C_ P is the set
Su = {y E P  |Vx E S x &lt; y}.
</bodyText>
<page confidence="0.992268">
36
</page>
<subsectionHeader confidence="0.467423">
Sygal and Wintner Modular Typed Unification Grammars
</subsectionHeader>
<bodyText confidence="0.9815885">
For a given partially ordered set (P, &lt;), if S C_ P has a least element then it is unique,
and is denoted min(S).
</bodyText>
<figure confidence="0.7117616">
Definition 2
A partially ordered set (P, &lt;) is a bounded complete partial order (BCPO) iff for every
S C_ P such that S&amp;quot; # 0, S&amp;quot; has a least element, called a least upper bound (lub) and
denoted U S.
Definition 3
A type hierarchy is a non-empty, finite, bounded complete partial order (TYPE, C).
Every type hierarchy (TYPE, C) always has a least type (written 1), because the
subset S = 0 of TYPE has the non-empty set of upper bounds, S&amp;quot; = TYPE, which must
have a least element due to bounded completeness.
Definition 4
</figure>
<construct confidence="0.556325333333333">
Let (TYPE, C) be a type hierarchy and let x, y E TYPE. If x C y, then x is a supertype of y
and y is a subtype of x. If x C y, x =� y and there is no z such that x C z C y and z =� x, y
then x is an immediate supertype of y and y is an immediate subtype of x.
</construct>
<bodyText confidence="0.926316">
We follow the definitions of Carpenter (1992) and Penn (2000) in viewing subtypes
as greater than their supertypes (hence the least element 1 and the notion of lub), rather
than the other way round (inducing a glb interpretation), which is sometimes common
in the literature (Copestake 2002).
Definition 5
Given a type hierarchy (TYPE, C) and a finite set of features FEAT, an appropriateness
specification is a partial function, Approp : TYPE x FEAT -4 TYPE such that for every
F E FEAT:
</bodyText>
<listItem confidence="0.8657414">
1. (Feature Introduction) there is a type Intro(F) E TYPE such that:
• Approp(Intro(F),F)J., and
• for every t E TYPE, if Approp(t, F)J., then Intro(F) C t, and
2. (Upward Closure / Right Monotonocy) if Approp(s,F)J. and s C t, then
Approp(t, F)J. and Approp(s, F) C Approp(t, F).
</listItem>
<subsectionHeader confidence="0.511292">
Definition 6
</subsectionHeader>
<bodyText confidence="0.96860075">
A type signature is a structure (TYPE, C, FEAT, Approp), where (TYPE, C) is a type
hierarchy, FEAT is a finite set of features, FEAT and TYPE are disjoint, and Approp is an
appropriateness specification.
Again, note that type constraints are not addressed in this work.
</bodyText>
<page confidence="0.997396">
37
</page>
<figure confidence="0.335299">
Computational Linguistics Volume 37, Number 1
</figure>
<subsectionHeader confidence="0.987431">
2.2 Overview
</subsectionHeader>
<bodyText confidence="0.999944666666667">
We define signature modules (also referred to as modules herein), which are structures
that provide a framework for modular development of type signatures. These structures
follow two guidelines.
</bodyText>
<listItem confidence="0.980778555555556">
1. Signature modules contain partial information about a signature: part of
the subtyping relation (sometimes referred to in the literature as type
subsumption) and part of the appropriateness specification. The key here is
a move from concrete type signatures to descriptions thereof; rather than
specify types, a description is a graph whose nodes denote types and
whose arcs denote elements of the subtyping and appropriateness
relations of signatures.
2. Modules may choose which information to expose to other modules and
how other modules may use the information they encode. The denotation
</listItem>
<bodyText confidence="0.953535444444444">
of nodes is extended by viewing them as parameters: Similarly to
parameters in programming languages, these are entities through which
information can be imported to or exported from other modules. This is
done similarly to the way parametric principles are used by Debusmann,
Duchier, and Rossberg (2005).
We begin by defining the basic structure of signature modules in Section 2.3. We
then introduce (Section 2.4) two combination operators for signature modules which
facilitate interaction and (remote) reference among modules. We end this section by
showing how to extend a signature module into a bona fide type signature (Section 2.5).
</bodyText>
<subsectionHeader confidence="0.998728">
2.3 Signature Modules
</subsectionHeader>
<bodyText confidence="0.999930666666667">
The definition of a signature module is conceptually divided into two levels of in-
formation. The first includes all the genuine information that may be encoded by a
signature, such as subtyping and appropriateness relations, types, and so forth. The
second level includes the parametric casting of nodes. This casting is not part of the core
of a signature, but rather a device that enables advanced module communication. Con-
sequently, we define signature modules in two steps. First, we define partially specified
signatures (PSSs), which are finite directed graphs that encode partial information
about the signature. Then, we extend PSSs to signature modules which are structures,
based on PSSs, that provide also a complete mechanism for module interaction and
(remote) reference.
We assume enumerable, disjoint sets TYPE of types, FEAT of features, and NODES
of nodes, over which signatures are defined.
</bodyText>
<subsectionHeader confidence="0.516245">
Definition 7
</subsectionHeader>
<bodyText confidence="0.9764535">
A partially labeled graph (PLG) over TYPE and FEAT is a finite, directed labeled graph
P = (Q, T, --&lt;, Ap), where:
</bodyText>
<listItem confidence="0.995466">
1. Q C NODES is a finite, nonempty set of nodes.
2. T : Q → TYPE is a partial function, marking some of the nodes with types.
</listItem>
<page confidence="0.991088">
38
</page>
<bodyText confidence="0.382014">
Sygal and Wintner Modular Typed Unification Grammars
</bodyText>
<listItem confidence="0.918923625">
3. �C Q x Q is a relation specifying (immediate) subtyping.
4. Ap C Q x FEAT x Q is a relation specifying appropriateness.
A partially specified signature (PSS) over TYPE and FEAT is a partially labeled graph
P = (Q, T, �, Ap), where:
5. T is one to one.
6. ‘--&lt;’ is antireflexive; its reflexive-transitive closure, denoted ‘�* ’, is
antisymmetric.
7. (Relaxed Upward Closure) for all q1, qi, q2 E Q and F E FEAT, if
</listItem>
<equation confidence="0.998429">
* * q~
(q1, F, q2) E Ap and q1 � q~ 1, then there exists q~ 2 E Q such that q2 � 2 and
(qi,F,q2) E Ap
</equation>
<bodyText confidence="0.972940242424242">
A PSS is a finite, directed graph whose nodes denote types and whose edges denote
the subtyping and appropriateness relations. Nodes can be marked by types through
the function T, but can also be anonymous (unmarked). Anonymous nodes facilitate
reference, in one module, to types that are defined in another module. T is one-to-one
(item 5), because we require that two marked nodes denote different types.
The ‘�’ relation (item 3) specifies an immediate subtyping order over the nodes,
with the intention that this order hold later for the types denoted by nodes. This is why
∗
‘�’ is required to be a partial order (item 6). The type hierarchy of an ordinary type
signature is required to be a BCPO, but current approaches (Copestake 2002) relax this
requirement to allow more flexibility in grammar design. Similarly, the type hierarchy
of PSSs is partially ordered but this order is not necessarily a bounded complete one.
Only after all modules are combined is the resulting subtyping relation extended to
a BCPO (see Section 2.5); any intermediate result can be a general partial order. Relax-
ing the BCPO requirement also helps guarantee the associativity of module combination
(see Example 8).4
Consider now the appropriateness relation. In contrast to type signatures, Ap is not
required to be a function. Rather, it is a relation which may specify several appropriate
nodes for the values of a feature F at a node q (item 4). The intention is that the eventual
value of Approp(T(q), F) be the lub of the types of all those nodes q&apos; such that Ap(q, F, q&apos;).
This relaxation reflects our initial motivation of supporting partiality in modular gram-
mar development, since different modules may specify different appropriate values ac-
cording to their needs and available information. After all modules are combined, all the
specified values are replaced by a single appropriate value, their lub (see Section 2.5). In
this way, each module may specify its own appropriate values without needing to know
the value specification of other modules. We do restrict the Ap relation, however, by a
relaxed version of upward closure (item 7). Finally, the feature introduction condition of
type signatures (Definition 5, item 1) is not enforced by signature modules. This, again,
4 The fact that the subtyping relation is only extended to a BCPO after all modules are combined implies
a lack of incrementality in the system that may be problematic for grammar developers, as modules
cannot be tested and evaluated independently. This situation, however, is not unlike the scenario of
programming languages, where modules can typically be developed and compiled, but not tested,
independently of a complete system.
</bodyText>
<page confidence="0.990997">
39
</page>
<note confidence="0.27924">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.9256325">
results in more flexibility for the grammar designer; the condition can be restored, if it
is desirable, after all modules combine (see Section 2.5).
Example 1
A simple PSS P1 is depicted in Figure 1, where solid arrows represent the ‘�’ (subtyp-
ing) relation and dashed arrows, labeled by features, the Ap relation. P1 stipulates two
subtypes of cat, n and v, with a common subtype, gerund. The feature AGR is appropriate
for all three categories, with distinct (but anonymous) values for Approp(n, AGR) and
Approp(v, AGR). Approp(gerund, AGR) will eventually be the lub of Approp(n, AGR) and
Approp(v, AGR), hence the multiple outgoing AGR arcs from gerund.
Observe that in P1, ‘�’ is not a BCPO, Ap is not a function, and the feature introduc-
tion condition does not hold.
Definition 8
A pre-signature module over TYPE and FEAT is a structure S = (P, Int, Imp, Exp) where
P = (Q, T, --&lt;, Ap) is a PLG and:
</bodyText>
<listItem confidence="0.9994972">
1. Int C Q is a set of internal types
2. Imp C Q is an ordered set of imported parameters
3. Exp C Q is an ordered set of exported parameters
4. Int n Imp = Int n Exp = 0
5. for all q E Q such that q E Int, T(q)j
</listItem>
<bodyText confidence="0.998533222222222">
We refer to elements of (the sequences) Imp and Exp using indices, with the notation
Imp[i], Exp[j], respectively.
A signature module over TYPE and FEAT is a pre-signature module S = (P,Int,
Imp, Exp) in which P is a PSS.
Signature modules extend the denotation of nodes by viewing them as parameters:
Similarly to parameters in programming languages, parameters are entities through
which information can be imported from or exported to other modules. The nodes
of a signature module are distributed among three sets of internal, imported, and
exported nodes. If a node is internal it cannot be imported or exported; but a node
</bodyText>
<figureCaption confidence="0.873411">
Figure 1
</figureCaption>
<bodyText confidence="0.600952">
A partially specified signature, P1.
</bodyText>
<page confidence="0.749396">
40
</page>
<note confidence="0.445319">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<figureCaption confidence="0.977167">
Figure 2
</figureCaption>
<bodyText confidence="0.9974466">
A signature module, S1.
can be simultaneously imported and exported. A node which does not belong to any
of the sets is called external. All nodes denote types, but they differ in the way they
communicate with nodes in other modules. As their name implies, internal nodes are
internal to one module and cannot interact with nodes in other modules. Such nodes
provide a mechanism similar to local variables in programming languages.
Non-internal nodes may interact with the nodes in other modules: Imported nodes
expect to receive information from other modules, while exported nodes provide informa-
tion to other modules. External nodes differ from imported and exported nodes in the
way they may interact with other modules, and provide a mechanism similar to global
variables in programming languages. Because anonymous nodes facilitate reference, in
one module, to information encoded in another module, such nodes cannot be internal.
The imported and exported nodes are ordered in order to control the assignment of
parameters when two modules are combined, as will be shown subsequently.5 In the
examples, the classification of nodes is encoded graphically as follows:
</bodyText>
<sectionHeader confidence="0.537584" genericHeader="method">
Internal Imported Exported External
</sectionHeader>
<subsectionHeader confidence="0.463863">
Example 2
</subsectionHeader>
<bodyText confidence="0.9986638">
Figure 2 depicts a module S1, based on the PSS of Figure 1. S1 = (P1, Int1, Imp1, Exp1),
where P1 is the PSS of Figure 1, Int1 = 0, Imp1 = {q4, q5}, and Exp1 = 0.
Herein, the meta-variable q (with or without subscripts) ranges over nodes, S (with
or without subscripts) – over (pre-)signature modules, P (with or without subscripts)
over PLGs and PSSs, and Q, T, �, Ap (with the same subscripts) over their constituents.
</bodyText>
<subsectionHeader confidence="0.997203">
2.4 Combination Operators for Signature Modules
</subsectionHeader>
<bodyText confidence="0.9990825">
We introduce two operators for combining signature modules. The first operator, merge,
is a symmetric operation which simply combines the information encoded in the two
</bodyText>
<footnote confidence="0.91923175">
5 In fact, Imp and Exp can be general sets, rather than lists, as long as the combination operations can
deterministically map nodes from Exp to nodes of Imp. For simplicity, we limit the discussion to the
familiar case of lists, where matching elements from Exp to Imp is done by the location of the element
on the list, see Definitions 13 and 14.
</footnote>
<page confidence="0.996278">
41
</page>
<note confidence="0.284096">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.999856166666667">
modules. The second operator, attachment, is a non-symmetric operation which uses
the concept of parameters and is inspired by function composition. A signature module
is viewed as a function whose input is a graph with a list of designated imported
nodes and whose output is a graph with a list of designated exported nodes. When
two signature modules are attached, similarly to function composition, the exported
nodes of the second module instantiate the imported parameters of the first module.
Additionally, the information encoded by the second graph is added to the information
encoded by the first one.
The parametric view of modules facilitates interaction between modules in two
channels: by naming or by reference. Through interaction by naming, nodes marked
by the same type are coalesced. Interaction by reference is achieved when the imported
parameters of the calling module are coalesced with the exported nodes of the called
module, respectively. The merge operation allows modules to interact only through
naming, whereas attachment facilitates both ways of interaction.
For both of the operators, we assume that the two signature modules are consistent:
One module does not include types which are internal to the other module and the
two signature modules have no common nodes. If this is not the case, nodes, and in
particular internal nodes, can be renamed without affecting the operation.
</bodyText>
<subsectionHeader confidence="0.314915">
Definition 9
</subsectionHeader>
<bodyText confidence="0.863412">
Let S1 = ((Q1, T1, --&lt;1, Ap1), Int1, Imp1, Exp1), S2 = ((Q2, T2, --&lt;2, Ap2), Int2, Imp2, Exp2) be
two pre-signature modules. S1 and S2 are consistent iff all the following conditions
hold:
</bodyText>
<listItem confidence="0.998036333333333">
1. {T1(q)  |q E Int1} n {T2(q)  |q E Q2 and T2(q)l} = 0
2. {T2(q)  |q E Int2} n {T1(q)  |q E Q1 and T1(q)l} = 0
3. Q1 n Q2 = 0
</listItem>
<bodyText confidence="0.751248166666667">
We begin by introducing the compactness algorithm which is used when two
modules are combined as a mechanism to coalesce corresponding nodes in the two
modules.
2.4.1 Compactness. When two modules are combined, a crucial step in the combination is
the identification of corresponding nodes in the two modules that should be coalesced.
Such pairs of nodes can be either of two kinds:
</bodyText>
<listItem confidence="0.985302545454545">
1. Two typed nodes which are labeled by the same type should be coalesced
(along with their attributes).
2. Two anonymous nodes which are indistinguishable, that is, have
isomorphic environments, should be coalesced. The environment of a
node q is the subgraph that includes all the reachable nodes via any kind
of arc (from q or to q) up to and including a typed node. The intuition is
that if two anonymous nodes have isomorphic environments, then they
cannot be distinguished and therefore should coincide. Two nodes, only
one of which is anonymous, can still be otherwise indistinguishable. Such
nodes will, eventually, be coalesced, but only after all modules are
combined (to ensure the associativity of module combination).
</listItem>
<page confidence="0.986074">
42
</page>
<bodyText confidence="0.86715975">
Sygal and Wintner Modular Typed Unification Grammars
Additionally, during the combination of modules, some arcs may become redun-
dant (such arcs are not prohibited by the definition of a module). Redundant arcs can
be of two kinds:
</bodyText>
<listItem confidence="0.9926836">
1. A subtyping arc (q1, q2) is redundant if it is a member of the transitive
closure of �, where � excludes (q1, q2).
2. An appropriateness arc (q1, F, q2) is redundant if there exists q3 ∈ Q such
∗
that q2 -&lt; q3 and (q1, F, q3) ∈ Ap. (q1, F, q2) is redundant due to the lub
</listItem>
<bodyText confidence="0.985177736842105">
intention of appropriateness arcs: The eventual value of Approp∗(T (q1), F)
will be an upper bound of (at least) both q2 and q3. Because q2 q3,
(q1, F, q2) is redundant.
Redundant arcs encode information that can be inferred from other arcs and therefore
may be removed without affecting the data encoded by the signature module.
While our main interest is in signature modules, the compactness algorithm is
defined over the more general case of pre-signature modules. This more general
notion will be helpful in the definition of module combination. Informally, when a
pre-signature module is compacted, redundant arcs are removed, nodes marked by
the same type are coalesced, and anonymous indistinguishable nodes are identified.
Additionally, the parameters and arities are induced from those of the input pre-
signature module. All parameters may be coalesced with each other, as long as they are
otherwise indistinguishable. If (at least) one of the coalesced nodes is an internal node,
then the result is an internal node. Otherwise, if one of the nodes is imported then
the resulting parameter is imported as well. Similarly, if one of the nodes is exported
then the resulting parameter is exported. Notice that in the case of signature modules,
because T is one to one, an internal node may be coalesced only with other internal
nodes.
The actual definitions of indistinguishability and the compactness algorithm are
mostly technical and are therefore deferred to the Appendix. We do provide two simple
examples to illustrate the general idea.
Example 3
Consider the signature module of Figure 3. (q1, q4) is a redundant subtyping arc be-
cause even without this arc, there is a subtyping path from q1 to q4. (q1, F, q3) is a
redundant appropriateness arc: Eventually the appropriate value of q1 and F should be
the lub of q3 and q5, but since q5 is a subtype of q3, it is sufficient to require that it be at
least q5.
Example 4
Consider S2, the pre-signature module depicted in Figure 4. Note that S2 is not a
signature module (because it includes two nodes labeled by a) and that compactness
is defined over pre-signature modules rather than signature modules as this is the case
for which it will be used during combination. In compact(S2), q1 and q2 are coalesced
because they are both marked by the type a. Additionally, q3 and q6 are coalesced with q4
and q7, respectively, because these are two pairs of anonymous nodes with isomorphic
environments. q5 is not coalesced with q3 and q4 because q5 is typed and q3 and q4 are
not, even though they are otherwise indistinguishable. q8 is not coalesced with q6 and
q7 because they are distinguishable: q8 has a supertype marked by a whereas q6 and q7
have anonymous supertypes.
</bodyText>
<page confidence="0.999331">
43
</page>
<figure confidence="0.925989333333333">
Computational Linguistics Volume 37, Number 1
Figure 3
A signature module with redundant arcs.
</figure>
<figureCaption confidence="0.9008125">
Figure 4
Compactness.
</figureCaption>
<bodyText confidence="0.984461642857143">
2.4.2 Merge. The merge operation combines the information encoded by two signature
modules: Nodes that are marked by the same type are coalesced along with their
attributes. Nodes that are marked by different types cannot be coalesced and must
denote different types. The main complication arises when two anonymous nodes are
considered—such nodes are coalesced only if they are indistinguishable.
The merge of two modules is defined in several stages: First, the two graphs are
unioned (this is a simple pointwise union of the coordinates of the graph, see Defi-
nition 10). Then, the resulting graph is compacted, coalescing nodes marked by the
same type as well as indistinguishable anonymous nodes. However, the resulting graph
does not necessarily maintain the relaxed upward closure condition, and therefore some
modifications are needed. This is done by Ap-Closure (see Definition 11). Finally, the
addition of appropriateness arcs may turn two anonymous distinguishable nodes into
indistinguishable ones and may also add redundant arcs, therefore another compact-
ness step is needed (Definition 12).
</bodyText>
<subsectionHeader confidence="0.400679">
Definition 10
</subsectionHeader>
<bodyText confidence="0.995876">
Let S1 = ((Q1, T1, �1, Ap1), Int1, Imp1, Exp1), S2 = W2, T2, --&lt;2, Ap2�, Int2, Imp2, Exp2) be
two consistent pre-signature modules. The union of S1 and S2, denoted S1 ∪ S2, is the
pre-signature module
</bodyText>
<equation confidence="0.9883465">
S = ((Q1 ∪ Q2, T1 ∪ T2, -1 ∪ -2, Ap1 ∪ Ap2�, Int1 ∪ Int2, Imp1 · Imp2, Exp1 · Exp2)
(where ‘·’ is the concatenation operator).
</equation>
<page confidence="0.832066">
44
</page>
<bodyText confidence="0.352752">
Sygal and Wintner Modular Typed Unification Grammars
</bodyText>
<equation confidence="0.530193">
Definition 11
Let S = ((Q, T, --&lt;, Ap), Int, Imp, Exp) be a pre-signature module. The Ap-Closure of S,
denoted ApCl(S), is the pre-signature module ((Q, T, --&lt;, Ap&apos;), Int, Imp, Exp) where
App = I(q1, F, q2) I q1, q2 E Q
</equation>
<bodyText confidence="0.999711142857143">
and there exists qi E Q such that
qi ∗ --&lt;q1 and (qi,F,q2) E Ap}
Ap-Closure adds to a pre-signature module the required arcs for it to maintain
the relaxed upward closure condition: Arcs are added to create the relations between
elements separated between the two modules and related by mutual elements. Notice
that Ap C Ap&apos; by choosing qi = q1.
Two signature modules can be merged only if the resulting subtyping relation is
indeed a partial order, where the only obstacle can be the antisymmetry of the resulting
relation. The combination of the appropriateness relations, in contrast, cannot cause
the merge operation to fail because any violation of the appropriateness conditions
in signature modules can be deterministically resolved. Note that our specification
language does not support inequations; there is no way to specify that two nodes must
not be identified with each other. Such extensions are indeed possible, but are beyond
the scope of this work.
</bodyText>
<sectionHeader confidence="0.364422" genericHeader="method">
Definition 12
</sectionHeader>
<bodyText confidence="0.87959">
Let S1 = ((Q1, T1, --&lt;1,Ap1), Int1, Imp1,Exp1), S2 = ((Q2,T2,--&lt;2,Ap2),Int2,Imp2,Exp2) be
two consistent signature modules. S1, S2 are mergeable if there are no q1, q2 E Q1 and
q3, q4 E Q2 such that the following hold:
</bodyText>
<equation confidence="0.925491428571429">
1. q1 =� q2 and q3 =� q4
2. T1(q1)1, T1(q2)1, T2(q3)1 and T2(q4)1
3. T1(q1) = T2(q4) and T1(q2) = T2(q3)
� �
4. q1 --&lt;1 q2 and q3 -2 q4
If S1 and S2 are mergeable, then their merge, denoted S1 U S2, is:
compact(ApCl(compact(S1 U S2)))
</equation>
<bodyText confidence="0.999924444444444">
In the merged module, pairs of nodes marked by the same type and pairs of
indistinguishable anonymous nodes are coalesced. An anonymous node cannot be
coalesced with a typed node, even if they are otherwise indistinguishable, because
that would result in a non-associative combination operation. Anonymous nodes are
assigned types only after all modules combine (see Section 2.5.1).
If a node has multiple outgoing Ap-arcs labeled with the same feature, these arcs are
not replaced by a single arc, even if the lub of the target nodes exists in the resulting sig-
nature module. Again, this is done to guarantee the associativity of the merge operation
(see Example 9).
</bodyText>
<page confidence="0.990064">
45
</page>
<figure confidence="0.83034">
Computational Linguistics Volume 37, Number 1
</figure>
<figureCaption confidence="0.545651">
Figure 5
Merge: intermediate steps.
</figureCaption>
<bodyText confidence="0.948621733333333">
Example 5
Let S3 and S4 be the signature modules depicted in Figure 5. S3 U S4 and the intermediate
pre-signature modules are also shown in this figure. First, S3 and S4 are unioned. Then,
in compact(S3 ∪ S4) the two nodes typed by a are coalesced, as are the nodes typed by
c. Notice that this pre-signature module is not a signature module because it does not
maintain the relaxed upward closure condition. To enforce this condition appropriate-
ness arcs are added to yield ApCl(compact(S3 ∪ S4)), but this signature module includes
indistinguishable anonymous nodes and therefore another compactness operation is
required to yield the final result.
Example 6
Figure 6 depicts a naive agreement module, S5. Combined with S1 of Figure 1, S1 U S5 =
S5 U S1 = S6. All dashed arrows are labeled AGR, but these labels are suppressed for
readability.
In what follows, by standard convention, Ap arcs that can be inferred by upward
closure are not depicted.
</bodyText>
<footnote confidence="0.823953">
Figure 6
Merge.
</footnote>
<page confidence="0.996155">
46
</page>
<note confidence="0.689697">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<figureCaption confidence="0.18303">
Example 7
</figureCaption>
<bodyText confidence="0.950529555555556">
Let S7 and S8 be the signature modules depicted in Figure 7. S7 includes general
agreement information and S8 specifies detailed values for several specific properties.
Then, S7 U S8 = S8 U S7 = S9. In this way, the high level organization of the agreement
module is encoded by S7, and S8 provides low level details pertaining to each agreement
feature individually.
The following example motivates our decision to relax the BCPO condition and
defer the conversion of signature modules to BCPOs to a separate resolution stage
(Section 2.5).
Example 8
Let S10, S11, S12 be the signature modules depicted in Figure 8. The merge of S10 with S11
results in a non-BCPO. However, the additional information supplied by S12 resolves
the problem, and S10 U S11 U S12 is bounded complete.
Example 9
Let S13, S14, S15 be the signature modules depicted in Figure 9. In S13 the appropriate
value for a and F is b and in S14 it is c. Hence S13 U S14 states that the appropriate value
for a and F should be lub(b, c). Although in this module there is no such element, in S15
lub(b, c) is determined to be d. In S13 U S14 U S15 the two outgoing arcs from the node
marked by a are not replaced by a single arc whose target is the node marked by d, since
</bodyText>
<figureCaption confidence="0.823842">
Figure 7
Merge.
</figureCaption>
<page confidence="0.910843">
47
</page>
<figure confidence="0.642685">
Computational Linguistics Volume 37, Number 1
Figure 8
BCPO relaxation.
</figure>
<figureCaption confidence="0.991549">
Figure 9
</figureCaption>
<bodyText confidence="0.902079615384615">
Merge of signature modules.
other signature modules may specify that the lub of b and c is some type other than d.
These multiple outgoing arcs are preserved to maintain the associativity of the merge
operation.
Proposition 1
Merge is commutative: For any two signature modules, S1, S2, Let S = S1 U S2 and S&apos; =
S2 U S1 where P, P~ are their underlying PSSs, respectively. Then P = P&apos;. In particular,
either both are defined or both are undefined.
The proof follows immediately from the fact that the merge operation is defined by
set union and equivalence relations which are commutative operations.
Proposition 2
Merge is associative up to isomorphism:6 for all S1, S2, S3, Let S = (S1 (W S2) U S3 and
S&apos; = S1 U (S2 (W S3) where P, P~ are their underlying PSSs, respectively. Then P ∼ P&apos;.
</bodyText>
<footnote confidence="0.5639365">
6 The definition of signature module isomorphism is a simple extension of graph isomorphism; see the
Appendix for more details.
</footnote>
<page confidence="0.993581">
48
</page>
<note confidence="0.498005">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<bodyText confidence="0.968186555555556">
The proof of associativity is similar in spirit to the proof of the associativity of (polar-
ized) forest combination (Sygal and Wintner 2009) and is therefore suppressed.
2.4.3 Attachment. Consider again S1 and S9, the signature modules of Figures 1 and
7, respectively. S1 stipulates two distinct (but anonymous) values for Approp(n, AGR)
and Approp(v, AGR). S9 stipulates two nodes, typed nagr and vagr, with the intention
that these nodes be coalesced with the two anonymous nodes of S1. However, the
‘merge’ operation defined in the previous section cannot achieve this goal, since the two
anonymous nodes in S1 have different attributes from their corresponding typed nodes
in S9. In order to support such a unification of nodes we need to allow a mechanism
that specifically identifies two designated nodes, regardless of their attributes. The
parametric view of nodes facilitates exactly such a mechanism.
The attachment operation is an asymmetric operation, like function composition,
where a signature module, S1, receives as input another signature module, S2. The
information encoded in S2 is added to S1 (as in the merge operation), but additionally,
the exported parameters of S2 are assigned to the imported parameters of S1: Each of
the exported parameters of S2 is forced to coalesce with its corresponding imported
parameter of S1, regardless of the attributes of these two parameters (i.e., whether they
are indistinguishable or not).
</bodyText>
<sectionHeader confidence="0.333457" genericHeader="method">
Definition 13
</sectionHeader>
<bodyText confidence="0.804995333333333">
Let S1= ((Q1, T1, --&lt;1, Ap1), Int1, Imp1, Exp1) and S2= W2, T2, -2, Ap2, ), Int2, Imp2, Exp2)
be two consistent signature modules. S2 can be attached to S1 if the following conditions
hold:
</bodyText>
<listItem confidence="0.746008">
1. |Imp1 |= |Exp2|
2. for all i, 1 ≤ i ≤ |Imp1|, if T1(Imp1[i])↓ and T2(Exp2[i])↓, then
</listItem>
<equation confidence="0.7647424">
T1(Imp1[i]) = T2(Exp2[i])
3. S1 and S2 are mergeable
∗
4. for all i, j, 1 ≤ i ≤ |Imp1 |and 1 ≤ j ≤ |Imp1|, if Imp1[i] � 1 Imp1[j], then
Exp2[j] �2 Exp2[i]
</equation>
<bodyText confidence="0.9995615">
The first condition requires that the number of formal parameters of the calling module
be equal to the number of actual parameters in the called module. The second condition
states that if two typed parameters are attached to each other, they are marked by the
same type. If they are marked by two different types they cannot be coalesced.7 Finally,
the last two conditions guarantee the antisymmetry of the subtyping relation in the
resulting signature module: The third condition requires the two signature modules to
be mergeable. The last condition requires that no subtyping cycles be created by the
attachment of parameters: If q1 is a supertype of qi in S1 and q2 is a supertype of q2 in
S2, then q2 and q2 cannot be both attached to q1 and qi, respectively. Notice that as in the
merge operation, two signature modules can be attached only if the resulting subtyping
</bodyText>
<footnote confidence="0.484626333333333">
7 A variant of attachment can be defined in which if two typed parameters, which are attached to each
other, are marked by two different types, then the type of the exported node overrides the type of the
imported node.
</footnote>
<page confidence="0.994524">
49
</page>
<note confidence="0.481308">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.99427">
relation is indeed a partial order, where the only obstacle can be the antisymmetry of the
resulting relation. The combination of the appropriateness relations, in contrast, cannot
cause the attachment operation to fail because any violation of the appropriateness
conditions in signature modules can be deterministically resolved.8
</bodyText>
<sectionHeader confidence="0.454369" genericHeader="method">
Definition 14
</sectionHeader>
<bodyText confidence="0.999062166666667">
Let S1 = ((Q1, T1, Ap1), Int1, Imp1, Exp1) and S2 =((Q2, T2, --&lt;2, Ap2, ), Int2, Imp2, Exp2)
be two consistent signature modules. If S2 can be attached to S1, then the attachment of
S2 to S1, denoted S1(S2), is: S1(S2) = compact(ApCl(compact(S))), where S = ((Q, T, --&lt;,
Ap), Int, Imp, Exp) is defined as follows: Let ≡ be an equivalence relation over Q1 ∪ Q2
defined by the reflexive and symmetric closure of {(Imp1[i],Exp2[i])  |1 ≤ i ≤ |Imp1|}.
Then:
</bodyText>
<listItem confidence="0.973706">
• Q = {[q]≡  |q ∈ Q1 ∪ Q2}
� T([q]≡) = T1 ∪ T2(q&apos;) there exists q&apos; ∈ [q]≡ such that T1 ∪ T2(q&apos;)↓
↑ otherwise
• �=
{([q1]≡, [q2]≡)  |∃q&apos; 1 ∈ [q1]≡ and ∃q� 2 ∈ [q2]≡ and (q~ 1,q~ 2) ∈�1 ∪ ~2}
• Ap = {([q1]≡,F,[q2]≡)  |∃qi ∈ [q1]≡ and ∃q2 ∈ [q2]≡ and (qi,F,qi) ∈
Ap1 ∪ Ap2}
• Int = {[q]≡  |q ∈ Int1 ∪ Int2}
• Imp = {[q]≡  |q ∈ Imp1}
• Exp = {[q]≡  |q ∈ Exp1}
• the order of Imp and Exp is induced by the order of Imp1 and Exp1,
respectively
</listItem>
<bodyText confidence="0.998783411764706">
When a module S2 is attached to a module S1, all the exported nodes of S2 are first
attached to the imported nodes of S1, respectively, through the equivalence relation,
‘≡’. In this way, for each imported node of S1, all the information encoded by the
corresponding exported node of S2 is added. Notice that each equivalence class of
‘≡’ contains either one or two nodes. In the former case, these nodes are either non-
imported nodes of S1 or non-exported nodes of S2. In the latter, these are pairs of an
imported node of S1 and its corresponding exported node from S2. Hence ‘≡’ is trivially
transitive. Then, similarly to the merge operation, pairs of nodes marked by the same
type and pairs of indistinguishable anonymous nodes are coalesced. In contrast to the
merge operation, in the attachment operation two distinguishable anonymous nodes, as
well as an anonymous node and a typed node, can be coalesced. This is achieved by the
parametric view of nodes and the view of one module as an input to another module.
The imported and exported nodes of the resulting module are the equivalence
classes of the imported and exported nodes of the first module, S1, respectively. The
nodes of S2 which are neither internal nor exported are classified as external nodes in the
resulting module. This asymmetric view of nodes stems from the view of S1 receiving
S2 as input: In this way, S1 may import further information from other modules.
</bodyText>
<footnote confidence="0.792819">
8 Relaxed variants of these conditions are conceivable; for example, one can require |Imp1 |≤ |Exp2 |rather
than |Imp1 |= |Exp2|; or that T1(Imp1[i]) and T2(Exp2[i]) be consistent rather than equal.
</footnote>
<page confidence="0.976392">
50
</page>
<note confidence="0.476139">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<bodyText confidence="0.9509855">
Notice that in the attachment operation internal nodes facilitate no interaction
between modules, external nodes facilitate interaction only through naming, and im-
ported and exported nodes facilitate interaction both through naming and by reference.
Example 10
Consider again S1 and S9, the signature modules of Figures 1 and 7, respectively. Let
S1a and S9a be the signature modules of Figure 10 (these signature modules have the
same underlying graphs as those of S1 and S9, respectively, with different classification
of nodes). Notice that all nodes in both S1a and S9a are non-internal. Let Imp1a = (q4, q5)
and let Exp9a = (p9,p10). S1a(S9a) is depicted in the same figure. Notice how q4,q5 are
coalesced with p9, p10, respectively, even though q4, q5 are anonymous and p9, p10 are
typed and each pair of nodes has different attributes. Such unification of nodes cannot
be achieved with the merge operation.
</bodyText>
<footnote confidence="0.3362955">
Figure 10
Attachment.
</footnote>
<page confidence="0.966894">
51
</page>
<note confidence="0.370541">
Computational Linguistics Volume 37, Number 1
</note>
<subsubsectionHeader confidence="0.411984">
2.4.4 Example: Parametric Lists. Lists and parametric lists are extensively used in typed
</subsubsectionHeader>
<bodyText confidence="0.995951086956522">
unification-based formalisms, for example in HPSG. The mathematical foundations
for parametric lists were established by Penn (2000). As an example of the utility of
signature modules and the attachment operation, we show how they can be used to
construct parametric lists in a straightforward way.
Consider Figure 11. The signature module List depicts a parametric list module. It
receives as input, through the imported node q3, a node which determines the type of
the list members. The entire list can then be used through the exported node q4. Notice
that q2 is an external anonymous node. Although its intended denotation is the type
ne list, it is anonymous in order to be unique for each copy of the list, as will be shown
subsequently. Now, if Phrase is a simple module consisting of one exported node, of type
phrase, then the signature module obtained by List(Phrase) is obtained by coalescing q3,
the imported node of List with the single exported node of Phrase.
Other modules can now use lists of phrases; for example, the module Struct uses
an imported node as the appropriate value for the feature COMP-DTRS. Via attachment,
this node can be instantiated by List(Phrase) as in Struct(List(Phrase)). The single node
of Phrase instantiates the imported node of List, thus determining a list of phrases. The
entire list is then attached to the signature module Struct, where the root of the list
instantiates the imported node typed by phrase list in Struct.
More copies of the list with other list members can be created by different calls to the
module List. Each such call creates a unique copy of the list, potentially with different
types of list elements. Uniqueness is guaranteed by the anonymity of the node q2 of
List: q2 can be coalesced only with anonymous nodes with the exact same attributes,
that is, only with nodes whose appropriate value for the feature FIRST is a node typed
</bodyText>
<figureCaption confidence="0.744096">
Figure 11
</figureCaption>
<bodyText confidence="0.75789">
Implementing parametric lists with signature modules.
</bodyText>
<page confidence="0.988534">
52
</page>
<note confidence="0.442367">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<bodyText confidence="0.996039583333333">
by phrase. If q2 would have been typed by ne list it could be coalesced with any other
node marked by the same type, such as other such nodes from different copies of the
list, resulting in a list whose members have various types. Observe that the uniqueness
of each copy of the list could be achieved also by declaring q2 an internal node, but this
solution prevents other modules from referring to this node, as is reasonably desired. q1
(of List) is typed by elist. Because only one copy of this node is required for all the list
copies, there is no problem with typing this node.
Compared with the parametric type signatures of Penn (2000), our implementation
of parametric lists is simple and general: It falls out directly as one application of
signature modules, whereas the construction of Penn requires dedicated machinery
(parametric subtyping, parametric appropriateness, coherence, etc.) We conjecture that
signature modules can be used to simulate parametric type signatures in the general
case, although we do not have a proof of such a result.
2.4.5 Example: The ‘Addendum’ Operator in LKB. The ‘addendum’ operator9 was added to
the type definition language of LKB (Copestake 2002) in 2005, to allow the grammar
developer to add attributes to an already defined type without the need to repeat
previously defined attributes of that type. The need for such an operation arose as
a consequence of the development of frameworks that generate grammars from pre-
written fragments (e.g., the LINGO grammar matrix, Bender, Flickinger, and Oepen
2002), since editing of framework-source files may lead to errors.
Signature modules trivially support this operator, either by the merge operation (in
which case different attributes of a typed node are gathered from different modules)
or by attachment, where attributes can be assigned to a specific node, even without
specifying its type.
</bodyText>
<subsectionHeader confidence="0.997747">
2.5 Extending Signature Modules to Type Signatures
</subsectionHeader>
<bodyText confidence="0.999135">
Signature modules encode only partial information, and are therefore not required to
conform with all the constraints imposed on ordinary signatures. After modules are
combined, however, the resulting signature module must be extended into a bona fide
signature. For that purpose we use four algorithms, each of which deals with one
property:
</bodyText>
<listItem confidence="0.9588702">
1. Name resolution: This algorithm assigns types to anonymous nodes
(Section 2.5.1).
2. Appropriateness consolidation: This algorithm determinizes Ap, converts
it from a relation to a function and enforces upward closure (Section 2.5.2).
3. Feature introduction completion: This algorithm (whose use is optional)
enforces the feature introduction condition. This is done using the
algorithm of Penn (2000).
4. BCPO completion: This algorithm extends ‘�’ to a BCPO. Again, we use
the algorithm of Penn (2000).
9 See http://depts.washington.edu/uwcl/twiki/bin/view.cgi/Main/TypeAddendum.
</listItem>
<page confidence="0.995559">
53
</page>
<note confidence="0.397628">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.628517333333333">
The input to the resolution algorithm is a signature module and its output is a bona
fide type signature.
Algorithm 1 (Resolve (S))
</bodyText>
<listItem confidence="0.986869666666667">
1. S := NameResolution(S)
2. S := BCPO−Completion(S)
3. S := ApCl(S)
4. S := ApConsolidate(S)
5. S := FeatureIntroductionCompletion(S)
6. S := BCPO−Completion(S)
7. S := ApCl(S)
8. S := ApConsolidate(S)
9. return S
</listItem>
<bodyText confidence="0.983470233333333">
The order in which the four algorithms are executed is crucial for guaranteeing
that the result is indeed a bona fide signature. First, the resolution algorithm assigns
types to anonymous nodes via the name resolution algorithm (stage 1). The BCPO
completion algorithm (stage 2) of Penn (2000) adds types as least upper bounds for sets
of types which have upper bounds but do not have a minimal upper bound. However,
the algorithm does not determine the appropriateness specification of these types. A
natural solution to this problem is to use Ap-Closure (stage 3) but this may lead to a
situation in which the newly added nodes have multiple outgoing Ap-arcs with the
same label. To solve the problem, we execute the BCPO completion algorithm before
the Ap-consolidation algorithm (stage 4), which also preserves bounded completeness.
Now, the feature introduction completion algorithm (stage 5) of Penn assumes that
the subtyping relation is a BCPO and that the appropriateness specification is indeed
a function and hence, it is executed after the BCPO completion and Ap-consolidation
algorithms. However, as Penn observes, this algorithm may disrupt bounded complete-
ness and therefore the result must undergo another BCPO completion and therefore
another Ap-consolidation (stages 6–8).
A signature module is extended to a type signature after all the information from
the different modules have been gathered. Therefore, there is no need to preserve the
classification of nodes and only the underlying PSS is of interest. However, because the
resolution procedure uses the compactness algorithm which is defined over signature
modules, we define the following algorithms over signature modules as well. In cases
where the node classification needs to be adjusted, we simply take the trivial classifica-
tion (i.e., Int = Imp = Exp = ∅).
2.5.1 Name Resolution. During module combination only pairs of indistinguishable
anonymous nodes are coalesced. Two nodes, only one of which is anonymous, can still
be otherwise indistinguishable but they are not coalesced during combination to ensure
the associativity of module combination. The goal of the name resolution procedure is
to assign a type to every anonymous node, by coalescing it with a typed node with an
identical environment, if one exists. If no such node exists, or if there is more than one
such node, the anonymous node is given an arbitrary type.
</bodyText>
<page confidence="0.986716">
54
</page>
<note confidence="0.441556">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<bodyText confidence="0.999796909090909">
The name resolution algorithm iterates as long as there are nodes to coalesce. In each
iteration, for each anonymous node the set of its typed equivalent nodes is computed
(stage 1). Then, using the computation of stage 1, anonymous nodes are coalesced with
their corresponding typed node, if such a node uniquely exists (stage 2.1). Coalescing all
such pairs may result in a signature module that may include indistinguishable anony-
mous nodes and therefore the signature module is compacted (stage 2.2). Compactness
can trigger more pairs that need to be coalesced, and therefore this procedure is repeated
(stage 2.3). When no pairs that need to be coalesced are left, the remaining anonymous
nodes are assigned arbitrary names and the algorithm halts.
We first define NodeCoalesce(S, q, q&apos;): this is a signature module S&apos; that is obtained
from S by coalescing q with q&apos;.
</bodyText>
<equation confidence="0.6315723">
Definition 15
Let S = ((Q, T, --&lt;, Ap), Int, Imp, Exp) be a signature module and let q, q&apos; E Q. Define
NodeCoalesce(S, q, q&apos;) = ((Q1, T1, --&lt;1, Ap1), Int1, Imp1, Exp1) where:
• Q1 = Q\{q}
• T1 = T |Q1
• --&lt;1= {(q1,q2)  |q1 --&lt; q2 and q1,q2 =� q} U {(p,q&apos;)  |p --&lt; q} U {(q&apos;,p)  |q --&lt; p}
• Ap1 = {(q1, F, q2)  |(q1, F, q2) E Ap and q1, q2 =� q} U
{(p,F,q&apos;)  |(p,F,q) E Ap} U {(q&apos;,F,p)  |(q,F,p) E Ap}
•
Int = Imp = Exp = 0
</equation>
<bodyText confidence="0.909284833333333">
The input to the name resolution algorithm is a signature module and its output is a
signature module whose typing function, T, is total. Let S = ((Q, T, --&lt;, Ap), Int, Imp, Exp)
be a signature module, and let NAMES C TYPE be an enumerable set of fresh types from
which arbitrary names can be taken to mark nodes in Q. The following algorithm marks
all the anonymous nodes in S:
Algorithm 2 (NameResolution (S = ((Q, T, --&lt;, Ap), Int, Imp, Exp)))
</bodyText>
<listItem confidence="0.99701375">
1. for all q E Q such that T(q)r, compute Qq = {q&apos; E Q  |T(q&apos;)l and q&apos; is
equivalent to q}.
2. let Q = {q E Q  |T(q)r and |Qq |= 1}. If Q =� 0 then:
2.1. for all q E Q, S := NodeCoalesce(S, q, q&apos;), where Qq = {q&apos;}
2.2. S := compact(S)
2.3. go to (1)
3. Mark remaining anonymous nodes in Q with arbitrary unique types from
NAMES and halt.
</listItem>
<bodyText confidence="0.958322">
For a given anonymous node, the calculation of its typed equivalent nodes is mostly
technical and is therefore suppressed.
</bodyText>
<page confidence="0.987893">
55
</page>
<figure confidence="0.733452">
Computational Linguistics Volume 37, Number 1
Figure 12
Name resolution result for S10.
Example 11
</figure>
<bodyText confidence="0.994507785714286">
Consider the signature module S6 depicted in Figure 6. Executing the name resolution
algorithm on this module results in the signature module of Figure 12 (AGR-labels are
suppressed for readability.) The two anonymous nodes in S6 are coalesced with the
nodes marked nagr and ziagr, as per their attributes. Compare to Figure 1, in particular
how two anonymous nodes in S1 are assigned types from S5 (Figure 6).
2.5.2 Appropriateness Consolidation. For each node q, the set of outgoing appropriateness
arcs with the same label F, {(q,F,q&apos;)}, is replaced by the single arc (q, F,ql), where ql is
marked by the lub of the types of all q&apos;. If no lub exists, a new node is added and is
marked by the lub. The result is an appropriateness relation which is a function, and in
which upward closure is preserved; feature introduction is dealt with separately.
The input to the following procedure is a signature module whose typing func-
tion, T, is total; its output is a signature module whose typing function is total and
whose appropriateness relation is a function that maintains upward closure. Let S =
((Q, T, --&lt;, Ap), Int, Imp, Exp) be a signature module. For each q E Q and F E FEAT, let
</bodyText>
<listItem confidence="0.980143615384615">
• target(q, F) = {q&apos;  |(q, F, q&apos;) E Ap}
• sup(q) = {q&apos; E Q  |q&apos; --&lt; q}
• sub(q) = {q&apos; E Q  |q --&lt; q&apos;}
Algorithm 3 (ApConsolidate (S = ((Q, T, --&lt;, Ap), Int, Imp, Exp)))
1. Set Int := Imp := Exp := 0
2. Find a node q and a feature F for which |target(q, F) |&gt; 1 and for all
q&apos; E Q such that q&apos; --&lt; � q, |target(q&apos;, F) |&lt; 1 (i.e., q is a minimal node with
respect to a topological ordering of Q). If no such pair exists, halt
3. If target(q, F) has a lub, p, then:
(a) for all q&apos; E target(q, F), remove the arc (q, F, q&apos;) from Ap
(b) add the arc (q, F, p) to Ap
(c) for all q&apos; E target(q,F) and for all q&apos;&apos; E sub(q&apos;), if p =� q&apos;&apos; then add the
arc (p, q&apos;&apos;) to --&lt;
</listItem>
<page confidence="0.983191">
56
</page>
<bodyText confidence="0.544691">
Sygal and Wintner Modular Typed Unification Grammars
</bodyText>
<listItem confidence="0.998414444444444">
4. (a) Otherwise, If target(q, F) has no lub, add a new node, p, to Q with:
• sup(p) = target(q,F)
• sub(p) = Uqlctarget(q,F) sub(q&apos;)
(b) Mark p with a fresh type from NAMES
(c) For all q&apos; ∈ target(q, F), remove the arc (q, F, q&apos;) from Ap
(d) Add (q,F,p) to Ap
5. S := ApCl(S)
6. S := compact(S)
7. go to (2)
</listItem>
<bodyText confidence="0.9491105">
The order in which nodes are selected in step 2 of the algorithm is from supertypes
to subtypes. This is done to preserve upward closure. When a set of outgoing appro-
priateness arcs with the same label F, {(q,F,q&apos;)}, is replaced by a single arc (q, F,ql), all
the subtypes of all q&apos; are added as subtypes of ql (stage 3c). This is done to maintain
the upwardly closed intention of appropriateness arcs (see Example 13). Additionally,
ql is added as an appropriate value for F and all the subtypes of q. This is achieved
by the Ap-Closure operation (stage 5). Again, this is done to preserve upward closure.
If a new node is added (stage 3), then its subtypes are inherited from its immediate
supertypes. Its appropriate features and values are also inherited from its immediate
supertypes through the Ap-Closure operation (stage 5). In both stages 3 and 4, a final
step is compaction of the signature module in order to remove redundant arcs.
Example 12
Consider the signature module depicted in Figure 12. Executing the appropriateness
consolidation algorithm on this module results in the module depicted in Figure 13.
</bodyText>
<subsectionHeader confidence="0.605662">
Example 13
</subsectionHeader>
<bodyText confidence="0.996950166666667">
Consider the signature modules depicted in Figure 14. Executing the appropriateness
consolidation algorithm on S16, the two outgoing arcs from a labeled with F are first
replaced by a single outgoing arc to a newly added node, new1, which is the lub of
b and c. During this first iteration, new1 is also added as a supertype of e and f. The
result of these operations is S17. Notice that in S16, the arc (a, F, b) is interpreted as “the
appropriate value of a and F is at least b.” In particular, this value may be e. S17 maintains
</bodyText>
<figureCaption confidence="0.749828">
Figure 13
</figureCaption>
<bodyText confidence="0.136877">
Appropriateness consolidation: result.
</bodyText>
<page confidence="0.951778">
57
</page>
<figure confidence="0.839035">
Computational Linguistics Volume 37, Number 1
</figure>
<figureCaption confidence="0.956262">
Figure 14
</figureCaption>
<bodyText confidence="0.8807912">
Appropriateness consolidation.
this interpretation by means of the subtyping arc that is added from new1 to e. Then, the
two outgoing arcs from d labeled with F (to e and f) are replaced by a single outgoing arc
to a newly added node, new2, which is the lub of e and f. The result of these operations
is S18, which is also the final result.
</bodyText>
<sectionHeader confidence="0.987494" genericHeader="method">
3. Grammar Modules
</sectionHeader>
<bodyText confidence="0.999825">
Before extending signature modules to grammar modules, we first recall basic notions
of typed unification grammars. For the following definitions we assume that a type
signature (TYPE, C, FEAT, Approp) has been specified.
</bodyText>
<equation confidence="0.48255375">
Definition 16
A path is a finite sequence of features, and the set PATHS = FEAT∗ is the collection of
paths. c is the empty path.
Definition 17
</equation>
<bodyText confidence="0.980006">
A typed pre-feature structure (pre-TFS) is a triple (H, ©, &gt;a) where:
</bodyText>
<listItem confidence="0.9640418">
• H C PATHS is a non-empty set of Paths
• © : H -4 TYPE is a total function, assigning a type for all paths
• &gt;aC H x H is a relation specifying reentrancy
A typed feature structure (TFS) is a pre-TFS A = (H, ©, &gt;a) for which the following
requirements hold:
• H is prefix-closed: if πα E H then π E H (where π, α E PATHS)
• A is fusion-closed: if πα E H and π &gt;a π&apos; then π�α E H and πα &gt;a π�α
• &gt;a is an equivalence relation with a finite index (with [&gt;a] the set of its
equivalence classes) including at least the pair (c, c)
• © respects the equivalence: if π1 &gt;a π2 then ©(π1) = ©(π2)
</listItem>
<page confidence="0.99556">
58
</page>
<note confidence="0.605302">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<sectionHeader confidence="0.239014" genericHeader="method">
Definition 18
</sectionHeader>
<bodyText confidence="0.979835555555555">
A TFS A = (H, ©, x) is well-typed iff whenever 7r E H and F E FEAT are such that 7rF E
H, then Approp(©(7r), F)J., and Approp(©(7r), F) C ©(7rF).
A grammar is defined over a concrete type signature and is a structure including a
set of rules (each constructed from a series of TFSs), a lexicon mapping words to sets of
TFSs and a start symbol which is a TFS.
We are now ready to define grammar modules and the way in which they interact.
A grammar module is a structure M = (S, G), where S is a signature module and G is a
grammar. The grammar is defined over the signature module analogously to the way
ordinary grammars are defined over type signatures, albeit with two differences:
</bodyText>
<listItem confidence="0.9957745">
1. TFSS are defined over type signatures, and therefore each path in the TFS
is associated with a type. When TFSS are defined over signature modules
this is not the case, because signature modules may include anonymous
nodes. Therefore, the standard definition of TFSS is modified such that
every path in a TFS is assigned a node in the signature module over which
it is defined, rather than a type.
2. Enforcing all TFSS in the grammar to be well-typed is problematic for
three reasons:
(a) Well-typedness requires that ©(7rF) be an upper bound of all the
(target) nodes which are appropriate for ©(7r) and F. However,
each module may specify only a subset of these nodes. The whole
set of target nodes is known only after all modules combine.
(b) A module may specify several appropriate values for ©(7r) and F,
but it may not specify any upper bound for them.
(c) Well-typedness is not preserved under module combination. The
natural way to preserve well-typedness under module combination
requires addition of nodes and arcs, which would lead to a
non-associative combination.
</listItem>
<bodyText confidence="0.9973335">
To solve these problems, we enforce only a relaxed version of well
typedness. The relaxation is similar to the way upward closure is relaxed:
Whenever ©(7r) = q, ©(7rF) is required to be a subtype of one of the values
q&apos; such that (q, F, q&apos;) E Ap. This relaxation supports the partiality and
associativity requirements of modular grammar development
(Section 1.1). After all modules are combined, the resulting grammar is
extended to maintain well-typedness.
The two combination operators, merge and attachment, are lifted from signature
modules to grammar modules. In both cases, the components of the grammars are
combined using simple set union. This reflects our initial observation (Section 1.1) that
most of the information in typed formalisms is encoded by the signature, and therefore
modularization is carried out mainly through the distribution of the signature between
the different modules; the lifting of the signature combination operation to operations
on full grammar modules is therefore natural and conservative.
</bodyText>
<page confidence="0.993795">
59
</page>
<figure confidence="0.729804">
Computational Linguistics Volume 37, Number 1
</figure>
<figureCaption confidence="0.867309">
Figure 15
The main fragments of the signature.
Figure 16
</figureCaption>
<bodyText confidence="0.97098275">
A signature module, Sign.
Finally, grammar modules are extended to bona fide typed unification grammars
by extending the underlying signature module into an ordinary type signature and
adjusting the grammar accordingly.10
</bodyText>
<sectionHeader confidence="0.892197" genericHeader="method">
4. Modular Construction of the Basic HPSG Signature
</sectionHeader>
<bodyText confidence="0.9999886">
To demonstrate the utility of signature modules for practical grammar engineering we
use signature modules and their combination operators in this section to work out a
modular design of the HPSG grammar of Pollard and Sag (1994). This is a grammar of
English whose signature, covering several aspects of syntax and semantics, is developed
throughout the book. The signature is given (Pollard and Sag 1994, Appendix A1) as one
unit, making it very hard to conceptualize and, therefore, to implement and maintain.
We reverse-engineered this signature, breaking it up into smaller-scale modules that
emphasize fragments of the theory that are more local, and the interactions among such
fragments through ‘merge’ and ‘attachment’.11 Some of the fragments make use of the
signature module List of Figure 11.
</bodyText>
<footnote confidence="0.97915675">
10 In practice, an extra adjustment is required in order to restore well-typedness, but we suppress this
technicality.
11 Of course, other ways to break up the given signature to modules are conceivable. In particular, the
Synsem module of Figure 19 may better be broken into two modules.
</footnote>
<page confidence="0.995584">
60
</page>
<note confidence="0.496999">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<bodyText confidence="0.979372">
We begin with a module defining objects (Figure 15), where the type object is the
most general type. This module defines the main fragments of the signature.
</bodyText>
<figureCaption confidence="0.97575">
Figure 16 defines the module Sign. It consists of the type sign, and its two subtypes
word and phrase. The latter is exported and will be used by other modules, as we
presently show. In addition, two of the appropriate features of sign are lists; note that
the values of PHON and RETRIEVED are imported.
Next, we consider constituent structure, and in particular headed structures, in
Figure 17. Note in particular that the feature COMP-DTRS, defined at head struc, takes
as values a list of phrases; this is an imported type, which is obtained as a result of
several attachment operations (Figure 11).
Figure 18 describes the fragment of the signature rooted by head. This is basically
a specification of the inventory of syntactic categories defined by the theory. Note how
simple it is to add, remove, or revise a category by accessing this fragment only.
Figure 19 provides straight-forward definitions of category and synsem, respectively.
</figureCaption>
<bodyText confidence="0.707188666666667">
As another example, Figure 20 depicts the type hierarchy of nominal objects, which
is completely local (in the sense that it does not interact with other modules, except
at the root). Finally, Figure 21 abstracts over the internal structure of Phonstring and
</bodyText>
<figureCaption confidence="0.64503">
Figure 17
</figureCaption>
<bodyText confidence="0.590069">
Phrase structure.
</bodyText>
<page confidence="0.976942">
61
</page>
<figure confidence="0.744354">
Computational Linguistics Volume 37, Number 1
Figure 18
A signature module, Head.
</figure>
<figureCaption confidence="0.964814">
Figure 19
</figureCaption>
<bodyText confidence="0.950960875">
Signature modules.
Quantifier; these are only representatives of the actual signature modules which define
these fragments.
The full HPSG signature consists of several more fragments that we do not depict
here. With this in mind, the HPSG signature can now be constructed in a modular way
from the fragments defined earlier. The construction is given in Figure 22.
First, we produce two lists of phonestring and quantifier, which are merged into one
module through the operation
</bodyText>
<equation confidence="0.361758">
List(Phonestring) U List(Quantifier)
</equation>
<bodyText confidence="0.9934885">
Then, this module instantiates the two imported nodes phonestring list and quantifier list
in the module Sign through the operation
</bodyText>
<note confidence="0.460172">
Sign(List(Phonestring) (W List(Quantifier))
Notice how the order of the parameters ensures the correct instantiation. Now, in the
second element, List(Sign) both creates a list of phrase (since phrase is an exported
</note>
<page confidence="0.995119">
62
</page>
<figure confidence="0.5667586">
Sygal and Wintner Modular Typed Unification Grammars
Figure 20
A classification of nominal objects.
Figure 21
Parametric signature modules.
</figure>
<figureCaption confidence="0.849195">
Figure 22
</figureCaption>
<bodyText confidence="0.959361076923077">
HPSG signature construction.
node in the module Sign) and unifies the information in the two modules. Similarly,
ConStruc(List(Sign)) unifies the information in the three modules and instantiates the
node phrase list in the module ConStruc. In the same way, List(Synsem) both creates
a list of synsem (since synsem is an exported node in the module Synsem) and unifies
the information in the two modules. Then, Cat(List(Synsem)) unifies the information in
the three modules and instantiates the node synsem list in the module Cat. Finally, all the
information from the different modules is unified through the merge operation. Other
modules can be added, either by merge or by attachment. Additionally, the internal
structure of each module can be locally modified. Such changes become much easier
given the smaller size and theoretical focus of each of the modules.
This modular approach has significant advantages over the monolithic approach
of Pollard and Sag (1994): The signature of Pollard and Sag is hard to conceptualize
</bodyText>
<page confidence="0.997616">
63
</page>
<note confidence="0.592376">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.999785294117647">
because all the information is presented in a single hierarchy. In contrast, looking at
each small fragment (module) separately, it is easier to understand the information
encoded in the module. Contemporary type signatures are in fact much larger; working
with small fragments in such grammars is instrumental for avoiding or tracking errors.
Moreover, grammar maintenance is significantly simplified, because changes can be
done locally, at the level of specific modules. Of course, when a new grammar is devel-
oped from scratch, modularization can be utilized in such a way as to reflect indepen-
dent fragments of the linguistic theory in separate modules.
While the grammar of Pollard and Sag (1994) is not really large-scale, it is large
enough to reflect the kind of knowledge organization exhibited by linguistically moti-
vated grammars, but is at the same time modest enough so that its redesign in a modular
way can be easily comprehended. It is therefore useful as a practical example of how
type signatures can be constructed from smaller, simpler signature modules. Real-world
grammars are not only much larger, they also tend to be more complex, and in particular
express interactions in domains other than the type signature (specifically, as type
constraints and as phrase-structure rules). Extending our solution to such interactions
is feasible, but is beyond the scope of this preliminary work.
</bodyText>
<listItem confidence="0.846374">
5. MODALS: A Platform for Modular Development of Type Signatures
</listItem>
<bodyText confidence="0.7817196">
Two leading implementation platforms are available for the development of typed
unification grammars: The Linguistic Knowledge Building system (LKB) (Copestake
2002) and TRALE (Meurers, Penn, and Richter 2002), an extension of the Attribute
Logic Engine (ALE) (Carpenter and Penn 2001). MODALS (MODular ALE) is a system
that supports modular development of type signatures in both ALE and TRALE. The
main features of the system are:
• The system provides a description language with which signature
modules can be specified. The description language is intuitive and is built
upon the description language of ALE. For example, the description of S1,
the signature module of Figure 2, is shown in Figure 23.
</bodyText>
<listItem confidence="0.9792563">
• Signature modules may be combined using either one of the two
combination operators, merge and attachment, or by a complex
combination involving several operators.
• Signature modules can be resolved to yield bona fide type signatures.
• The system compiles resolved modules into output files using either ALE
or TRALE syntax; these files can be directly manipulated by one of the two
systems.
• Signature modules can be printed using the syntax of the description
language. This feature allows inspection of a signature module that was
created as a result of several combination operators.
</listItem>
<bodyText confidence="0.9900806">
ALE and TRALE share the same underlying core, and are based on data structures
and algorithms that take advantage of type signature properties such as bounded
completeness, upward closure, and feature introduction, none of which can be assumed
when working with a signature module. As a result, our implementation is not a direct
adaption of the existing ALE/TRALE code, but a new system that was developed from
</bodyText>
<page confidence="0.998129">
64
</page>
<note confidence="0.83863">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<figureCaption confidence="0.726955">
Figure 23
MODALE description of S1.
</figureCaption>
<bodyText confidence="0.9931708">
scratch. Extending the algorithms of Penn (2000) from type signatures into signature
modules is left as a direction for future research.
The MODALE system provided us with an opportunity to experimentally evaluate
the time efficiency of module combination. Indeed, the combination and resolution
algorithms are computationally inefficient as they require repeated calculations of graph
isomorphism, a problem which is neither known to be solvable in polynomial time
nor NP-complete.12 However, in the signatures we have experimented with so far, we
encountered no time issues. Furthermore, it is important to note that these calculations
are executed only once, in compile time, and have no impact on the run time of
ALE/TRALE, which is the crucial stage in which efficiency is concerned.
</bodyText>
<sectionHeader confidence="0.962617" genericHeader="method">
6. Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.999908384615384">
We presented a complete definition of typed unification grammar modules and their
interaction. Unlike existing approaches, our solution is formally defined, mathemati-
cally proven, can be easily and efficiently implemented, and conforms to each of the
desiderata listed in Section 1.1, as we now show.
Signature focus: Our solution focuses on the modularization of the signature (Sec-
tion 2), and the extension to grammar modules (Section 3) is natural and conser-
vative. We do restrict ourselves in this work to standard type signatures without
type constraints. We defer the extension of type signatures to include also type
constraints to future work.
Partiality: Our solution provides the grammar developer with means to specify any
piece of information about the signature. A signature module may specify only
partial information about the subtyping and appropriateness relations. Further-
more, the appropriateness relation is not a function as in ordinary signatures, and
</bodyText>
<footnote confidence="0.994384">
12 Garey and Johnson (1979) provide a list of 12 major problems whose complexity status was open at
the time of writing. Recognition of graph isomorphism is one of those, and one of the only two whose
complexity remains unresolved today.
</footnote>
<page confidence="0.997961">
65
</page>
<note confidence="0.591335">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.994551591836735">
the developer may specify several appropriate nodes for the values of a feature
F at a node q. The anonymity of nodes and relaxed upward closure also provide
means for partiality. Another relaxation that supports partiality is not enforcing
feature introduction and the BCPO conditions. Finally, the possibility of distribut-
ing the grammar between several modules and the relaxation of well-typedness
also support this desideratum.
Extensibility: In Section 2.5 we show how a signature module can be deterministically
extended into a bona fide signature.
Consistency: When modules are combined, either by merge or by attachment, the
signature modules are required to be mergeable or attachable, respectively. In
this way, contradicting information in different modules is detected prior to the
combination. Notice that two signature modules can be combined only if the
resulting subtyping relation is indeed a partial order.
Flexibility: The only restrictions we impose on modules are meant to prevent subtyp-
ing cycles.
(Remote) Reference: This requirement is achieved by the parametric view of nodes.
Anonymity of nodes also supports this desideratum.
Parsimony: When two modules are combined, they are first unioned; thus the resulting
module includes all the information encoded in each of the modules. Additional
information is added in a conservative way by compaction and Ap-closure in
order to guarantee that the resulting module is indeed well-defined.
Associativity: We provide two combination operations, merge and attachment. The at-
tachment operation is an asymmetric operation, such as the function application,
and therefore associativity is not germane. The merge operation, which is sym-
metric, is both commutative and associative and therefore conforms with this
desideratum.
Privacy: Privacy is achieved through internal nodes which encode information that
other modules cannot view or refer to.
Modular construction of grammars, and of type signatures in particular, is an
essential requirement for the maintainability and sustainability of large-scale grammars.
We believe that our definition of signature modules, along with the operations of
merge and attachment, provide grammar developers with powerful and flexible tools for
collaborative development of natural language grammars, as demonstrated in Section 4.
Modules provide abstraction; for example, the module List of Figure 11 defines the
structure of a list, abstracting over the type of its elements. In a real-life setting, the
grammar designer must determine how to abstract away certain aspects of the devel-
oped theory, thereby identifying the interaction points between the defined module and
the rest of the grammar. A first step in this direction was done by Bender and Flickinger
(2005); we believe that we provide a more general, flexible, and powerful framework to
achieve the full goal of grammar modularization.
This work can be extended in various ways. First, this work focuses on the modular-
ity of the signature. This is not accidental, and reflects the centrality of the type signature
in typed unification grammars. An extension of signature modules to include also type
constraints is called for and will provide a better, fuller solution to the problem of
grammar modularization. In a different track, we also believe that extra modularization
capabilities can still be provided by means of the grammar itself. This direction is left
for future research.
Although the present work is mainly theoretical, it has important practical implica-
tions. An environment that supports modular construction of large-scale grammars will
</bodyText>
<page confidence="0.904917">
66
</page>
<note confidence="0.474398">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<bodyText confidence="0.999927928571429">
greatly contribute to grammar development and will have a significant impact on prac-
tical implementations of grammatical formalisms. The theoretical basis we presented
in this work was implemented as a system, MODALS, that supports modular develop-
ment of type signatures (Section 5). Once the theoretical basis is extended to include
also type constraints, and they, as well as grammar modules, are fully integrated in a
grammar development system, immediate applications of modularity are conceivable
(see Section 1.1). Furthermore, although there is no general agreement among linguists
on the exact form of modularity in grammar, a good modular interface will provide the
necessary infrastructure for the implementation of different linguistic theories and will
support their comparison in a common platform.
Finally, our proposed mechanisms clearly only fill very few lacunae of existing
grammar development environments, and various other provisions will be needed in
order for grammar engineering to be as well-understood a task as software engineering
now is. We believe that we make a significant step in this crucial journey.
</bodyText>
<sectionHeader confidence="0.964295" genericHeader="method">
Appendix: Compactness
</sectionHeader>
<bodyText confidence="0.9999225">
We provide a formal definition of the compactness algorithm in this section. For an
example of the following two definitions see Example 3.
</bodyText>
<sectionHeader confidence="0.543463" genericHeader="method">
Definition 19
</sectionHeader>
<bodyText confidence="0.993053333333333">
Let S = ((Q, T, �, Ap), Int, Imp, Exp) be a pre-signature module. (q1, q2) ∈ is a redun-
dant subtyping arc if there exist p1, ... , pn ∈ Q, n ≥ 1, such that q1 � p1 � p2 � . . . �
pn � q2.
</bodyText>
<sectionHeader confidence="0.562287" genericHeader="method">
Definition 20
</sectionHeader>
<bodyText confidence="0.999953692307692">
Let P = ((Q, T, �, Ap), Int, Imp, Exp) be a pre-signature module. (q1, F, q2) ∈ Ap is a re-
dundant appropriateness arc if there exists q2 ∈ Q such that q2 ∗q2, q2 =q&apos; 2 and
(q1, F, q&apos;2) ∈ Ap.
The following definitions set the basis for determining whether two nodes are indis-
tinguishable or not. Because signature modules are just a special case of directed, labeled
graphs, we can adapt the well-defined notion of graph isomorphism to pre-signature
modules. Informally, two pre-signature modules are isomorphic when their underlying
PSSs have the same structure; the identities of their nodes may differ without affecting
the structure. In our case, we require also that an anonymous node be mapped only to
an anonymous node and that two typed nodes, mapped to each other, be marked by the
same type. However, the classification of nodes as internal, imported, and/or exported
has no effect on the isomorphism since it is not part of the core of the information
encoded by the signature module.
</bodyText>
<sectionHeader confidence="0.697508" genericHeader="method">
Definition 21
</sectionHeader>
<bodyText confidence="0.99959675">
Two pre-signature modules S1 = ((Q1, T1, �1, Ap1), Int1, Imp1, Exp1), S2 = W2, T2, �2,
Ap2), Int2, Imp2, Exp2) are isomorphic, denoted S1∼S2, if there exists a total, one-to-one
and onto function i (isomorphism) mapping the nodes of S1 to the nodes of S2, such
that all the following hold:
</bodyText>
<listItem confidence="0.996569666666667">
1. for all q ∈ Q1, T1(q) = T2(i(q))
2. for all q, q&apos; ∈ Q1, q �1 q&apos; iff i(q) �2 i(q&apos;)
3. for all q, q&apos; ∈ Q1 and F ∈ FEAT, (q, F, q&apos;) ∈ Ap1 iff (i(q), F, i(q&apos;)) ∈ Ap2
</listItem>
<page confidence="0.996915">
67
</page>
<note confidence="0.562926">
Computational Linguistics Volume 37, Number 1
</note>
<bodyText confidence="0.998529">
The environment of a node q is the set of nodes accessible from q via any sequence
of arcs (subtyping or appropriateness, in any direction), up to and including the first
typed node. The environment of a typed node includes itself only.
</bodyText>
<sectionHeader confidence="0.584178" genericHeader="method">
Definition 22
</sectionHeader>
<bodyText confidence="0.9942925">
Let S = ((Q, T, �, Ap), Int, Imp, Exp) be a pre-signature module. For all q ∈ Q let the
environment of q, denoted env(q), be the smallest set such that:
</bodyText>
<listItem confidence="0.961751333333333">
• q ∈ env(q)
• If q&apos;&apos; ∈ env(q) and T(q&apos;&apos;)↑ and for some q&apos; ∈ Q and F ∈ FEAT, either q&apos; � q&apos;&apos;
or q&apos;&apos; � q&apos; or (q&apos;,F,q&apos;&apos;) ∈ Ap or (q&apos;&apos;, F, q&apos;) ∈ Ap, then q&apos; ∈ env(q)
</listItem>
<sectionHeader confidence="0.62943" genericHeader="method">
Definition 23
</sectionHeader>
<bodyText confidence="0.955011333333333">
Let S = ((Q, T, --&lt;, Ap), Int, Imp, Exp) be a pre-signature module and let Q&apos; ⊆ Q. The
strict restriction of S to Q&apos;, denoted S|strict
Q, , is ((Q&apos;, T2, _2, Ap2�, Int2, Imp2, Exp2), where:
</bodyText>
<listItem confidence="0.996580142857143">
• T2 = TjQ,
• q1 _2 q2 iff q1 -,&lt; q2, q1, q2 ∈ Q&apos; and either T(q1)↑ or T(q2)↑ (or both)
• (q1,F,q2) ∈ Ap2 iff (q1,F,q2) ∈ Ap, q1, q2 ∈ Q&apos; and either T(q1)↑ or T(q2)↑
(or both)
• Int2 = IntjQ&apos;
• Imp2 = ImpjQ,
• Exp2 = ExpjQ,
</listItem>
<bodyText confidence="0.998302333333333">
The strict restriction of a pre-signature module, S, to a set of nodes Q&apos;, is the
subgraph induced by the nodes of Q&apos; without any labeled or unlabeled arcs connecting
two typed nodes in Q&apos;.
</bodyText>
<sectionHeader confidence="0.586071" genericHeader="method">
Definition 24
</sectionHeader>
<bodyText confidence="0.9714145">
Let S = ((Q, T, --&lt;, Ap), Int, Imp, Exp) be a pre-signature module. Two nodes q1, q2 ∈ Q
are indistinguishable, denoted q1 ≈ q2, if S |strict
</bodyText>
<equation confidence="0.993125142857143">
env(q1)∼ S |strict
env(q2) via an isomorphism i such
that i(q1) = q2.
Example 14
Let S1 be the signature module of Figure A1
env(q4) = env(q7) = {q1,q4,q7}, env(q2) = env(q6) = {q1,q2,q6},
env(q5) = {q1,q5,q8} and env(q1) = {q1}
</equation>
<bodyText confidence="0.8055575">
The strict restrictions of S1 to these environments are depicted in Figure A2. q2 ≈ q4 and
q6 ≈ q7, where in both cases the isomorphism is
</bodyText>
<equation confidence="0.9606">
i = {q1 → q1, q2 → q4, q6 → q7}
</equation>
<page confidence="0.997965">
68
</page>
<note confidence="0.666073">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<figureCaption confidence="0.733974">
Figure A1
</figureCaption>
<figure confidence="0.656628">
A signature module with indistinguishable nodes, S1.
</figure>
<figureCaption confidence="0.836691">
Figure A2
</figureCaption>
<subsectionHeader confidence="0.643663">
Strict restriction subgraphs.
</subsectionHeader>
<bodyText confidence="0.920028166666667">
However, q5 is distinguishable from q2 and q4 because T(q8) =� T(q6) and T(q8) =� T(q7).
Notice also that q3 is distinguishable from q2, q4 and q5 because it has no outgoing
appropriateness arcs.
Proposition 3
Let S = ((Q, T, �, Ap), Int, Imp, Exp) be a pre-signature module. Then ‘≈’ is an equiva-
lence relation over Q.
</bodyText>
<sectionHeader confidence="0.591592" genericHeader="method">
Definition 25
</sectionHeader>
<bodyText confidence="0.990243666666667">
A pre-signature module S = ((Q, T, -, Ap), Int, Imp, Exp) is non-redundant if it in-
cludes no redundant subtyping and appropriateness arcs and for all q1, q2 ∈ Q, q1 ≈ q2
implies q1 = q2.
</bodyText>
<sectionHeader confidence="0.676136" genericHeader="method">
Definition 26
</sectionHeader>
<bodyText confidence="0.999836">
Let S = ((Q, T, --&lt;, Ap), Int, Imp, Exp) be a pre-signature module. The coalesced pre-
signature module, denoted coalesce(S), is ((Q1,T1, --&lt;1,Ap1), Int1, Imp1, Exp1) where:
</bodyText>
<listItem confidence="0.998046666666667">
• Q1 = {[q]≈  |q ∈ Q} (Q1 is the set of equivalence classes with respect to ≈)
• T1([q]≈) = T(q&apos;) for some q&apos; ∈ [q]≈
• �1= {([q1]≈,[q2]≈)  |(q1,q2) ∈ms}
</listItem>
<page confidence="0.991236">
69
</page>
<note confidence="0.358705">
Computational Linguistics Volume 37, Number 1
</note>
<listItem confidence="0.948274666666666">
• Ap1 = {([q1]≈,F,[q2]≈)  |(q1,F,q2) ∈ Ap}
• Int1 = {[q]≈  |q ∈ Int}
• Imp1 = {[q]≈  |q ∈ Imp and [q]≈ ∈/ Int}
• Exp1 = {[q]≈  |q ∈ Exp and [q]≈ ∈/ Int}
• the order of Imp1 and Exp1 is induced by the order of Imp and Exp,
respectively, with recurring elements removed
</listItem>
<bodyText confidence="0.9815867">
When a pre-signature module is coalesced, indistinguishable nodes are identified.
Additionally, the parameters and arities are induced from those of the input pre-
signature module. All parameters may be coalesced with each other, as long as they
are otherwise indistinguishable. If (at least) one of the coalesced nodes is an internal
node, then the result is an internal node. Otherwise, if one of the nodes is imported then
the resulting parameter is imported as well. Similarly, if one of the nodes is exported
then the resulting parameter is exported.
The input to the compactness algorithm is a pre-signature module and its output is
a non-redundant signature module which encodes the same information.
Algorithm 4 (compact (S = ((Q, T, --&lt;, Ap), Int, Imp, Exp)))
</bodyText>
<listItem confidence="0.994658181818182">
1. Let S1 = ((Q1, T1, --&lt;1, Ap1), Int1, Imp1, Exp1) be such that:
• Q1 = Q
• T1 = T
• �1= {(q1, q2) ∈� |(q1, q2) is a non-redundant subtyping arc in S}
• Ap1 = {(q1, F, q2) ∈ Ap  |(q1, F, q2) is a non-redundant
appropriateness arc in S}
• Int1 = Int
• Imp1 = Imp
• Exp1 = Exp
2. S&apos; = coalesce(S1)
3. If S&apos; is non-redundant, return S&apos;, otherwise return compact(S&apos;)
</listItem>
<bodyText confidence="0.999819375">
The compactness algorithm iterates as long as the resulting pre-signature module
includes redundant arcs or nodes. In each iteration, all the redundant arcs are first
removed and then all indistinguishable nodes are coalesced. However, the identifica-
tion of nodes can result in redundant arcs or can trigger more nodes to be coalesced.
Therefore, the process is repeated until a non-redundant signature module is obtained.
Notice that the compactness algorithm coalesces pairs of nodes marked by the same
type regardless of their incoming and outgoing arcs. Such pairs of nodes may exist in a
pre-signature module (but not in a signature module).
</bodyText>
<sectionHeader confidence="0.283028" genericHeader="conclusions">
Example 15
</sectionHeader>
<bodyText confidence="0.8398705">
Consider again S1, the signature module of Figure A1. The compacted signature module
of S1 is depicted in Figure A3. Notice that S1 has no redundant arcs to be removed and
</bodyText>
<page confidence="0.989817">
70
</page>
<note confidence="0.787253">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<figureCaption confidence="0.904126">
Figure A3
</figureCaption>
<bodyText confidence="0.776591">
The compacted signature module of S1.
</bodyText>
<figureCaption confidence="0.654981">
Figure A4
</figureCaption>
<bodyText confidence="0.985407333333333">
A compactness example.
that q2 and q6 were coalesced with q4 and q7, respectively. All nodes in compact(S1) are
pairwise distinguishable and no arc is redundant.
</bodyText>
<subsectionHeader confidence="0.527356">
Example 16
</subsectionHeader>
<bodyText confidence="0.905246888888889">
Consider S2, S3, S4, S5, the signature modules depicted in Figure A4. Executing the
compactness algorithm on S2, first the redundant subtyping arc from q1 to q6 is removed,
resulting in S3 which has no redundant arcs. Then, q2 and q3 are coalesced, resulting in
S4. In S4, {q2, q3} ≈ {q4} and {q5} ≈ {q6}, and after coalescing these two pairs, the result
is S5 which is non-redundant.
Proposition 4
The compactness algorithm terminates.
Proposition 5
The compactness algorithm is deterministic: it always produces the same result.
</bodyText>
<equation confidence="0.45410575">
Proposition 6
If S is a signature module then compact(S) is a non-redundant signature module.
Proposition 7
If S is a non-redundant signature module then compact(S) ∼ S.
</equation>
<page confidence="0.989505">
71
</page>
<note confidence="0.643332">
Computational Linguistics Volume 37, Number 1
</note>
<sectionHeader confidence="0.988953" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9319905">
This research was supported by the
Israel Science Foundation (grants 136/01,
137/06). We are grateful to Nurit Melnik
and Gerald Penn for extensive discussions
and constructive feedback, and to the
CL reviewers for detailed, useful
comments. All remaining errors are, of
course, our own.
</bodyText>
<sectionHeader confidence="0.997816" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999365509433962">
Abeill´e, Anne, Marie-H´el`ene Candito,
and Alexandra Kinyon. 2000. FTAG:
developing and maintaining a
wide-coverage grammar for French. In
Erhard Hinrichs, Detmar Meurers, and
Shuly Wintner, editors, Proceedings of the
ESSLLI-2000 Workshop on Linguistic Theory
and Grammar Implementation, pages 21–32.
Basili, R., M. T. Pazienza, and F. M. Zanzotto.
2000. Customizable modular lexicalized
parsing. In Proceedings of the Sixth
International Workshop on Parsing
Technologies (IWPT 2000), pages 41–52,
Trento.
Bender, Emily M., Dan Flickinger, and
Stephan Oepen. 2002. The grammar
matrix: An open-source starter-kit for the
rapid development of cross-linguistically
consistent broad-coverage precision
grammars. In Proceedings of the Workshop
on Grammar Engineering and Evaluation
at the 19th International Conference on
Computational Linguistics, pages 8–14,
Taipei.
Bender, Emily M. and Dan Flickinger. 2005.
Rapid prototyping of scalable grammars:
Towards modularity in extensions to a
language-independent core. In Proceedings
of IJCNLP-05, pages 203–208, Jeju Island.
Bender, Emily M., Dan Flickinger, Fredrik
Fouvry, and Melanie Siegel. 2005. Shared
representation in multilingual grammar
engineering. Research on Language and
Computation, 3:131–138.
Brogi, Antonio, Evelina Lamma, and
Paola Mello. 1993. Composing open logic
programs. Journal of Logic and Computation,
3(4):417–439.
Brogi, Antonio, Paolo Mancarella, Dino
Pedreschi, and Franco Turini.1990.
Composition operators for logic theories.
In J. W. Lloyd, editor, Computational
Logic – Symposium Proceedings,
pages 117–134.
Brogi, Antonio, Paolo Mancarella, Dino
Pedreschi, and Franco Turini.1994.
Modular logic programming. ACM
Transactions on Programming Languages
and Systems, 16(4):1361–1398.
Brogi, Antonio and Franco Turini. 1995. Fully
abstract compositional semantics for an
algebra of logic programs. Theoretical
Computer Science, 149:201–229.
Bugliesi, Michele, Evelina Lamma, and
Paola Mello. 1994. Modularity in logic
programming. Journal of Logic
Programming, 19–20:443–502.
Candito, Marie-H´el`ene. 1996. A
principle-based hierarchical representation
of LTAGs. In COLING-96, pages 194–199,
Copenhagen.
Carpenter, Bob. 1992. The Logic of Typed
Feature Structures. Cambridge Tracts in
Theoretical Computer Science. Cambridge
University Press, Cambridge.
Carpenter, Bob and Gerald Penn. 2001.
ALE—the attribute logic engine: User’s
guide. Technical report, Department of
computer science, University of Toronto
and SpeechWorks Research.
Cohen-Sygal, Yael and Shuly Wintner. 2006.
Partially specified signatures: A vehicle
for grammar modularity. In Proceedings
of the 21st International Conference on
Computational Linguistics and 44th Annual
Meeting of the Association for Computational
Linguistics, pages 145–152, Sydney.
Copestake, Ann. 2002. Implementing typed
feature structures grammars. CSLI
Publications, Stanford, CA.
Copestake, Ann and Dan Flickinger. 2000.
An open-source grammar development
environment and broad-coverage English
grammar using HPSG. In Proceedings
of the Second Conference on Language
Resources and Evaluation (LREC-2000),
pages 591–600.
Crabb´e, Benoit and Denys Duchier. 2004.
Metagrammar redux. In Proceedings of
The International Workshop on Constraint
Solving and Language Processing (CSLP),
pages 32–47.
Dalrymple, Mary. 2001. Lexical Functional
Grammar, volume 34 of Syntax and
Semantics. Academic Press, Oxford.
Debusmann, Ralph. 2006. Extensible
Dependency Grammar: A Modular Grammar
Formalism Based On Multigraph Description.
Ph.D. thesis, University of Saarlandes.
Debusmann, Ralph, Denys Duchier, and
Andreas Rossberg. 2005. Modular
grammar design with typed parametric
principles. In Proceedings of FG-MOL 2005:
The 10th Conference on Formal Grammar and
The 9th Meeting on Mathematics of Language,
pages 113–122.
</reference>
<page confidence="0.968131">
72
</page>
<note confidence="0.583801">
Sygal and Wintner Modular Typed Unification Grammars
</note>
<reference confidence="0.999892949152543">
Duchier, Denys and Claire Gardent. 1999. A
constraint-based treatment of descriptions.
In Third International Workshop on
Computational Semantics (IWCS-3),
pages 71–85.
Erbach, Gregor and Hans Uszkoreit. 1990.
Grammar engineering: Problems and
prospects. CLAUS report 1, University
of the Saarland and German Research
Center for Artificial Intelligence.
Fodor, Jerry. 1983. The Modularity of Mind.
MIT Press, Cambridge, MA.
Gaifman, Haim and Ehud Shapiro. 1989.
Fully abstract compositional semantics
for logic programming. In 16th Annual
ACM Symposium on Principles of Logic
Programming, pages 134–142, Austin, TX.
Garey, Michael R. and David S. Johnson.
1979. Computers and Intractability: A Guide
to the Theory of NP-Completeness. W. H.
Freeman, New York.
Hinrichs, Erhard W., W. Detmar Meurers,
and Shuly Wintner. 2004. Linguistic theory
and grammar implementation. Research on
Language and Computation, 2:155–163.
Jackendoff, Ray. 2002. Foundations of
Language. Oxford University Press, Oxford.
Joshi, Aravind K., Leon S. Levy, and Masako
Takahashi. 1975. Tree adjunct grammars.
Journal of Computer and System Sciences,
10(1):136–163.
Kahane, Sylvain. 2006. Polarized unification
grammars. In Proceedings of the 21st
International Conference on Computational
Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics
(COLING-ACL 2006), pages 137–144,
Sydney.
Kallmeyer, Laura. 2001. Local tree
description grammars. Grammars,
4(2):85–137.
Kaplan, Ronald M., Tracy Holloway King,
and John T. Maxwell. 2002. Adapting
existing grammars: The XLE experience.
In COLING-02 Workshop on Grammar
Engineering and Evaluation, pages 1–7,
Morristown, NJ.
Kasper, Walter and Hans-Ulrich Krieger.
1996. Modularizing codescriptive
grammars for efficient parsing. In
Proceedings of the 16th Conference on
Computational Linguistics, pages 628–633,
Copenhagen.
Keselj, Vlado. 2001. Modular HPSG. In
Proceedings of the 2001 IEEE Systems,
Man, and Cybernetics Conference,
pages 2867–2872, Tucson, AZ.
King, Tracy Holloway, Martin Forst, Jonas
Kuhn, and Miriam Butt. 2005. The feature
space in parallel grammar writing.
Research on Language and Computation,
3:139–163.
Mancarella, Paolo and Dino Pedreschi.
1988. An algebra of logic programs. In
Robert A. Kowalski and Kenneth A.
Bowen, editors, Logic Programming:
Proceedings of the Fifth International
Conference and Symposium,
pages 1006–1023, Cambridge, MA.
Melnik, Nurit. 2006. A constructional
approach to verb-initial constructions in
modern Hebrew. Cognitive Linguistics,
17(2):153–198.
Meurers, W. Detmar, Gerald Penn, and Frank
Richter. 2002. A Web-based instructional
platform for constraint-based grammar
formalisms and parsing. In Proceedings of
the ACL Workshop on Effective Tools and
Methodologies for Teaching NLP and CL,
pages 18–25.
Mitchell, John C. 2003. Concepts in
Programming Languages. Cambridge
University Press, Cambridge.
M¨uller, Stefan. 2007. The Grammix CD
ROM. A software collection for developing
typed feature structure grammars. In
Tracy Holloway King and Emily M.
Bender, editors, Grammar Engineering
across Frameworks 2007, Studies in
Computational Linguistics ONLINE.
CSLI Publications, Stanford, CA,
pages 259–266.
Oepen, Stephan, Dan Flickinger, Hans
Uszkoreit, and Jun-Ichi Tsujii. 2000.
Introduction to this special issue. Natural
Language Engineering, 6(1):1–14.
Oepen, Stephan, Daniel Flickinger, J. Tsujii,
and Hans Uszkoreit, editors. 2002.
Collaborative Language Engineering: A Case
Study in Efficient Grammar-Based Processing.
CSLI Publications, Stanford, CA.
O’Keefe, R. 1985. Towards an algebra for
constructing logic programs. In J. Cohen
and J. Conery, editors, Proceedings of
IEEE Symposium on Logic Programming,
pages 152–160, New York.
Penn, Gerald B. 2000. The Algebraic Structure
of Attributed Type Signatures. Ph.D. thesis,
School of Computer Science, Carnegie
Mellon University, Pittsburgh, PA.
Perrier, Guy. 2000. Interaction grammars.
In Proceedings of the 18th Conference on
Computational Linguistics (COLING 2000),
pages 600–606.
Pollard, Carl and Ivan A. Sag. 1994.
Head-Driven Phrase Structure Grammar.
University of Chicago Press and CSLI
Publications, Stanford, CA.
</reference>
<page confidence="0.960573">
73
</page>
<reference confidence="0.983635459459459">
Computational Linguistics Volume 37, Number 1
Ranta, Aarne. 2007. Modular grammar
engineering in GF. Research on Language
and Computation, 5(2):133–158.
Sygal, Yael and Shuly Wintner. 2008. Type
signature modules. In Philippe de Groote,
editor, Proceedings of FG 2008: The
13th Conference on Formal Grammar,
pages 113–128.
Sygal, Yael and Shuly Wintner. 2009.
Associative grammar combination
operators for tree-based grammars.
Journal of Logic, Language and Information,
18(3):293–316.
Vijay-Shanker, K. 1992. Using descriptions
of trees in a tree adjoining grammar.
Computational Linguistics, 18(4):481–517.
Wintner, Shuly. 2002. Modular context-free
grammars. Grammars, 5(1):41–63.
Wintner, Shuly, Alon Lavie, and Brian
MacWhinney. 2009. Formal grammars
of early language. In Orna Grumberg,
Michael Kaminski, Shmuel Katz, and
Shuly Wintner, editors, Languages:
From Formal to Natural, volume 5533
of Lecture Notes in Computer Science.
Springer Verlag, Berlin and Heidelberg,
pages 204–227.
XTAG Research Group. 2001. A lexicalized
tree adjoining grammar for English.
Technical Report IRCS-01-03, IRCS,
University of Pennsylvania.
Zajac, R´emi and Jan W. Amtrup. 2000.
Modular unification-based parsers.
In Proceedings of the Sixth International
Workshop on Parsing Technologies
(IWPT 2000), pages 278–288, Trento.
</reference>
<page confidence="0.999124">
74
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.592965">
<title confidence="0.8607475">Towards Modular Development of Typed Unification Grammars</title>
<affiliation confidence="0.988705">University of Haifa University of Haifa Development of large-scale grammars for natural languages is a complicated endeavor: Gram-</affiliation>
<abstract confidence="0.986917277777778">mars are developed collaboratively by teams of linguists, computational linguists, and computer scientists, in a process very similar to the development of large-scale software. Grammars are written in grammatical formalisms that resemble very-high-level programming languages, and are thus very similar to computer programs. Yet grammar engineering is still in its infancy: Few grammar development environments support sophisticated modularized grammar development, in the form of distribution of the grammar development effort, combination of sub-grammars, separate compilation and automatic linkage, information encapsulation, and so forth. This work provides preliminary foundations for modular construction of (typed) unification grammars for natural languages. Much of the information in such formalisms is encoded by the type signature, and we subsequently address the problem through the distribution of the among the different modules. We define modules provide operators Modules may specify only partial information about the components of the signature and may communicate through parameters, similarly to function calls in programming languages. Our definitions are inspired by methods and techniques of programming language theory and software engineering and are motivated by the actual needs of grammar developers, obtained through a careful examination of existing grammars. We show that our definitions meet these needs by conforming to a detailed set of desiderata. We demonstrate the utility of our definitions by providing a modular design of the HPSG grammar of Pollard and Sag.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Marie-H´el`ene Candito</author>
<author>Alexandra Kinyon</author>
</authors>
<title>FTAG: developing and maintaining a wide-coverage grammar for French.</title>
<date>2000</date>
<booktitle>Proceedings of the ESSLLI-2000 Workshop on Linguistic Theory and Grammar Implementation,</booktitle>
<pages>21--32</pages>
<editor>In Erhard Hinrichs, Detmar Meurers, and Shuly Wintner, editors,</editor>
<marker>Abeill´e, Candito, Kinyon, 2000</marker>
<rawString>Abeill´e, Anne, Marie-H´el`ene Candito, and Alexandra Kinyon. 2000. FTAG: developing and maintaining a wide-coverage grammar for French. In Erhard Hinrichs, Detmar Meurers, and Shuly Wintner, editors, Proceedings of the ESSLLI-2000 Workshop on Linguistic Theory and Grammar Implementation, pages 21–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>F M Zanzotto</author>
</authors>
<title>Customizable modular lexicalized parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT</booktitle>
<pages>41--52</pages>
<location>Trento.</location>
<marker>Basili, Pazienza, Zanzotto, 2000</marker>
<rawString>Basili, R., M. T. Pazienza, and F. M. Zanzotto. 2000. Customizable modular lexicalized parsing. In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT 2000), pages 41–52, Trento.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>The grammar matrix: An open-source starter-kit for the rapid development of cross-linguistically consistent broad-coverage precision grammars.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Grammar Engineering and Evaluation at the 19th International Conference on Computational Linguistics,</booktitle>
<pages>8--14</pages>
<location>Taipei.</location>
<marker>Bender, Flickinger, Oepen, 2002</marker>
<rawString>Bender, Emily M., Dan Flickinger, and Stephan Oepen. 2002. The grammar matrix: An open-source starter-kit for the rapid development of cross-linguistically consistent broad-coverage precision grammars. In Proceedings of the Workshop on Grammar Engineering and Evaluation at the 19th International Conference on Computational Linguistics, pages 8–14, Taipei.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
</authors>
<title>Rapid prototyping of scalable grammars: Towards modularity in extensions to a language-independent core.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP-05,</booktitle>
<pages>203--208</pages>
<location>Jeju Island.</location>
<contexts>
<context position="19468" citStr="Bender and Flickinger (2005)" startWordPosition="2904" endWordPosition="2907"> et al. (2005) augment LFG with a makeshift signature to allow modular development of untyped unification grammars. In addition, they suggest that any development team should agree in advance on the feature space. This work emphasizes the observation that the modularization of the signature is the key for modular development of grammars. However, the proposed solution is ad hoc and cannot be taken seriously as a concept of modularization. In particular, the suggestion for an agreement on the feature space undermines the essence of modular design. To support rapid prototyping of deep grammars, Bender and Flickinger (2005) propose a framework in which the grammar developer can select pre-written grammar fragments, accounting for common linguistic phenomena that vary across languages (e.g., word order, yes–no questions, and sentential negation). The developer can specify how these phenomena are realized in a given language, and a grammar for that language is automatically generated, implementing that particular realization of the phenomenon, integrated with a language-independent grammar core. This framework addresses modularity in the sense that the entire grammar is distributed between several fragments that c</context>
<context position="92565" citStr="Bender and Flickinger (2005)" startWordPosition="15104" endWordPosition="15107">he operations of merge and attachment, provide grammar developers with powerful and flexible tools for collaborative development of natural language grammars, as demonstrated in Section 4. Modules provide abstraction; for example, the module List of Figure 11 defines the structure of a list, abstracting over the type of its elements. In a real-life setting, the grammar designer must determine how to abstract away certain aspects of the developed theory, thereby identifying the interaction points between the defined module and the rest of the grammar. A first step in this direction was done by Bender and Flickinger (2005); we believe that we provide a more general, flexible, and powerful framework to achieve the full goal of grammar modularization. This work can be extended in various ways. First, this work focuses on the modularity of the signature. This is not accidental, and reflects the centrality of the type signature in typed unification grammars. An extension of signature modules to include also type constraints is called for and will provide a better, fuller solution to the problem of grammar modularization. In a different track, we also believe that extra modularization capabilities can still be provi</context>
</contexts>
<marker>Bender, Flickinger, 2005</marker>
<rawString>Bender, Emily M. and Dan Flickinger. 2005. Rapid prototyping of scalable grammars: Towards modularity in extensions to a language-independent core. In Proceedings of IJCNLP-05, pages 203–208, Jeju Island.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Fredrik Fouvry</author>
<author>Melanie Siegel</author>
</authors>
<title>Shared representation in multilingual grammar engineering.</title>
<date>2005</date>
<booktitle>Research on Language and Computation,</booktitle>
<pages>3--131</pages>
<contexts>
<context position="2816" citStr="Bender et al. 2005" startWordPosition="388" endWordPosition="391">grammars are being developed for various languages (Abeill´e, Candito, and Kinyon 2000; XTAG Research * Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: yael.sygal®gmail.com. ** Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly®cs.haifa.ac.il. Submission received: 3 June 2009; revised submission received: 21 June 2010; accepted for publication: 14 September 2010. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 1 Group 2001; Oepen et al. 2002; Hinrichs, Meurers, and Wintner 2004; Bender et al. 2005; King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi, Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and XDG (Debusmann, Duchier, and Rossberg 2005). Grammar development is a complex enterprise: It is not unusual for a single grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen et al. 2000) and may include thousands of types (Copestake and Flickinger 2</context>
<context position="11947" citStr="Bender et al. (2005)" startWordPosition="1752" endWordPosition="1755">ormulates a simple union of data. In other cases, associativity and commutativity should be considered with respect to the benefit the system may enjoy if they are abandoned. Privacy: Modules should be able to hide (encapsulate) information and render it unavailable to other modules. The solution we advocate here satisfies all these requirements. It facilitates collaborative development of grammars, where several applications of modularity are conceivable: • A single large-scale grammar developed by a team. • Development of parallel grammars for multiple languages under a single theory, as in Bender et al. (2005), King et al. (2005), or M¨uller (2007). Here, a core module is common to all grammars, and language-specific fragments are developed as separate modules. • A sequence of grammars modeling language development, for example language acquisition or (historical) language change (Wintner, Lavie, and MacWhinney 2009). Here, a “new” grammar is obtained from a “previous” grammar; formal modeling of such operations through module composition can shed new light on the linguistic processes that take place as language develops. 3 We restrict ourselves to standard type signatures (as defined by Carpenter </context>
</contexts>
<marker>Bender, Flickinger, Fouvry, Siegel, 2005</marker>
<rawString>Bender, Emily M., Dan Flickinger, Fredrik Fouvry, and Melanie Siegel. 2005. Shared representation in multilingual grammar engineering. Research on Language and Computation, 3:131–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Brogi</author>
<author>Evelina Lamma</author>
<author>Paola Mello</author>
</authors>
<title>Composing open logic programs.</title>
<date>1993</date>
<journal>Journal of Logic and Computation,</journal>
<volume>3</volume>
<issue>4</issue>
<marker>Brogi, Lamma, Mello, 1993</marker>
<rawString>Brogi, Antonio, Evelina Lamma, and Paola Mello. 1993. Composing open logic programs. Journal of Logic and Computation, 3(4):417–439.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Antonio Brogi</author>
<author>Paolo Mancarella</author>
</authors>
<title>Dino Pedreschi, and Franco Turini.1990. Composition operators for logic theories.</title>
<booktitle>Computational Logic – Symposium Proceedings,</booktitle>
<pages>117--134</pages>
<editor>In J. W. Lloyd, editor,</editor>
<marker>Brogi, Mancarella, </marker>
<rawString>Brogi, Antonio, Paolo Mancarella, Dino Pedreschi, and Franco Turini.1990. Composition operators for logic theories. In J. W. Lloyd, editor, Computational Logic – Symposium Proceedings, pages 117–134.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Antonio Brogi</author>
<author>Paolo Mancarella</author>
</authors>
<title>Dino Pedreschi, and Franco Turini.1994. Modular logic programming.</title>
<journal>ACM Transactions on Programming Languages and Systems,</journal>
<volume>16</volume>
<issue>4</issue>
<marker>Brogi, Mancarella, </marker>
<rawString>Brogi, Antonio, Paolo Mancarella, Dino Pedreschi, and Franco Turini.1994. Modular logic programming. ACM Transactions on Programming Languages and Systems, 16(4):1361–1398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Brogi</author>
<author>Franco Turini</author>
</authors>
<title>Fully abstract compositional semantics for an algebra of logic programs.</title>
<date>1995</date>
<journal>Theoretical Computer Science,</journal>
<pages>149--201</pages>
<contexts>
<context position="13587" citStr="Brogi and Turini (1995)" startWordPosition="2000" endWordPosition="2003">ification grammars are in many ways very similar to logic programming languages, our desiderata and solutions are inspired by works in this paradigm. Modular interfaces of logic programs were first suggested by O’keefe (1985) and Gaifman and Shapiro (1989). Combination operators that were proved suitable for Prolog include the algebraic operators ⊕ and ⊗ of Mancarella and Pedreschi (1988); the union and intersection operators of Brogi et al. (1990); the closure operator of Brogi, Lamma, and Mello (1993); and the set of four operators (encapsulation, union, intersection, and import) defined by Brogi and Turini (1995). For a comprehensive survey, see Bugliesi, Lamma, and Mello (1994). The ‘merge’ operator that we present in Section 2.4.2 is closely related to union operations proposed for logic programming languages. We define no counterpart of intersection-type operations, although such operations are indeed conceivable. Our ‘attachment’ operation is more in line with Gaifman and Shapiro (1989). 1.2.2 Initial Approaches: Modularized Parsing. Early attempts to address modularity in linguistic formalisms share a significant disadvantage: The modularization is of the parsing process rather than the grammar. </context>
</contexts>
<marker>Brogi, Turini, 1995</marker>
<rawString>Brogi, Antonio and Franco Turini. 1995. Fully abstract compositional semantics for an algebra of logic programs. Theoretical Computer Science, 149:201–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Bugliesi</author>
<author>Evelina Lamma</author>
<author>Paola Mello</author>
</authors>
<title>Modularity in logic programming.</title>
<date>1994</date>
<journal>Journal of Logic Programming,</journal>
<pages>19--20</pages>
<marker>Bugliesi, Lamma, Mello, 1994</marker>
<rawString>Bugliesi, Michele, Evelina Lamma, and Paola Mello. 1994. Modularity in logic programming. Journal of Logic Programming, 19–20:443–502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-H´el`ene Candito</author>
</authors>
<title>A principle-based hierarchical representation of LTAGs.</title>
<date>1996</date>
<booktitle>In COLING-96,</booktitle>
<pages>194--199</pages>
<location>Copenhagen.</location>
<contexts>
<context position="22070" citStr="Candito 1996" startWordPosition="3304" endWordPosition="3305">frastructure underlying the definition of modular HPSG discussed earlier (Keselj 2001). Provisions for modularity have also been discussed in the context of tree-adjoining grammars (TAG) (Joshi, Levy, and Takahashi 1975). A wide-coverage TAG may contain hundreds or even thousands of elementary trees, and syntactic structure can be redundantly repeated in many of them (XTAG Research Group 2001; Abeill´e, Candito, and Kinyon 2000). Consequently, maintenance and extension of such grammars is a complex task. To address these issues, several high-level formalisms were developed (VijayShanker 1992; Candito 1996; Duchier and Gardent 1999; Kallmeyer 2001). These formalisms take the metagrammar approach, where the basic units are tree descriptions (i.e., formulas denoting sets of trees) rather than trees. Tree descriptions are constructed by a tree logic and combined through conjunction or inheritance; a module in this approach is merely a tree description, and modules are combined by means of the control logic. When trees are semantic objects, (i.e., the denotation of tree descriptions), there can be various ways to refer to nodes in the trees in order to control the possible combination of grammar mo</context>
</contexts>
<marker>Candito, 1996</marker>
<rawString>Candito, Marie-H´el`ene. 1996. A principle-based hierarchical representation of LTAGs. In COLING-96, pages 194–199, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures. Cambridge Tracts in Theoretical Computer Science.</title>
<date>1992</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="27927" citStr="Carpenter (1992)" startWordPosition="4192" endWordPosition="4193">declare its own interface with other modules; then, when modules combine they may do so in any way that is consistent with the interfaces of other modules. Furthermore, reference to mutual elements in GF is carried out only through naming, again resulting in a weak interface for module interaction. Finally, the operations that the grammar writer can define in GF are macros, rather than functions, as they are expanded by textual replacement. 2. Modularization of the Signature 2.1 Typed Signatures We assume familiarity with theories of (typed) unification grammar, as formulated by, for example, Carpenter (1992) and Penn (2000). The definitions in this section set the notation and recall basic notions. For a partial function F, ‘F(x)l’ (‘F(x)r’) means that F is defined (undefined) for the value x; ‘F(x) = F(y)’ means that either F is defined both for x and for y and assigns them equal values or it is undefined for both. Definition 1 Given a partially ordered set (P, &lt;), the set of upper bounds of a subset S C_ P is the set Su = {y E P |Vx E S x &lt; y}. 36 Sygal and Wintner Modular Typed Unification Grammars For a given partially ordered set (P, &lt;), if S C_ P has a least element then it is unique, and i</context>
<context position="29371" citStr="Carpenter (1992)" startWordPosition="4492" endWordPosition="4493"> 3 A type hierarchy is a non-empty, finite, bounded complete partial order (TYPE, C). Every type hierarchy (TYPE, C) always has a least type (written 1), because the subset S = 0 of TYPE has the non-empty set of upper bounds, S&amp;quot; = TYPE, which must have a least element due to bounded completeness. Definition 4 Let (TYPE, C) be a type hierarchy and let x, y E TYPE. If x C y, then x is a supertype of y and y is a subtype of x. If x C y, x =� y and there is no z such that x C z C y and z =� x, y then x is an immediate supertype of y and y is an immediate subtype of x. We follow the definitions of Carpenter (1992) and Penn (2000) in viewing subtypes as greater than their supertypes (hence the least element 1 and the notion of lub), rather than the other way round (inducing a glb interpretation), which is sometimes common in the literature (Copestake 2002). Definition 5 Given a type hierarchy (TYPE, C) and a finite set of features FEAT, an appropriateness specification is a partial function, Approp : TYPE x FEAT -4 TYPE such that for every F E FEAT: 1. (Feature Introduction) there is a type Intro(F) E TYPE such that: • Approp(Intro(F),F)J., and • for every t E TYPE, if Approp(t, F)J., then Intro(F) C t,</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Carpenter, Bob. 1992. The Logic of Typed Feature Structures. Cambridge Tracts in Theoretical Computer Science. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
<author>Gerald Penn</author>
</authors>
<title>ALE—the attribute logic engine: User’s guide.</title>
<date>2001</date>
<tech>Technical report,</tech>
<institution>Department of computer science, University of Toronto and SpeechWorks Research.</institution>
<contexts>
<context position="4045" citStr="Carpenter and Penn 2001" startWordPosition="568" endWordPosition="571"> Modern grammars are written in grammatical formalisms that are often reminiscent of very-high-level, declarative (mostly logical) programming languages, and are thus very similar to computer programs. This raises problems similar to those encountered in large-scale software development (Erbach and Uszkoreit 1990). Although whereas software engineering provides adequate solutions for the programmer, grammar engineering is still in its infancy. In this work we focus on typed unification grammars (TUG), and their implementation in grammar-development platforms such as LKB (Copestake 2002), ALE (Carpenter and Penn 2001), TRALE (Meurers, Penn, and Richter 2002), or Grammix (M¨uller 2007). Such platforms conceptually view the grammar as a single entity (even when it is distributed over several files), and provide few provisions for modular grammar development, such as mechanisms for defining modules that can interact with each other through well-defined interfaces, combination of sub-grammars, separate compilation and automatic linkage of grammars, information encapsulation, and so forth. This is the main issue that we address in this work.1 We provide a preliminary yet thorough and well-founded solution to th</context>
<context position="86193" citStr="Carpenter and Penn 2001" startWordPosition="14125" endWordPosition="14128">to be more complex, and in particular express interactions in domains other than the type signature (specifically, as type constraints and as phrase-structure rules). Extending our solution to such interactions is feasible, but is beyond the scope of this preliminary work. 5. MODALS: A Platform for Modular Development of Type Signatures Two leading implementation platforms are available for the development of typed unification grammars: The Linguistic Knowledge Building system (LKB) (Copestake 2002) and TRALE (Meurers, Penn, and Richter 2002), an extension of the Attribute Logic Engine (ALE) (Carpenter and Penn 2001). MODALS (MODular ALE) is a system that supports modular development of type signatures in both ALE and TRALE. The main features of the system are: • The system provides a description language with which signature modules can be specified. The description language is intuitive and is built upon the description language of ALE. For example, the description of S1, the signature module of Figure 2, is shown in Figure 23. • Signature modules may be combined using either one of the two combination operators, merge and attachment, or by a complex combination involving several operators. • Signature </context>
</contexts>
<marker>Carpenter, Penn, 2001</marker>
<rawString>Carpenter, Bob and Gerald Penn. 2001. ALE—the attribute logic engine: User’s guide. Technical report, Department of computer science, University of Toronto and SpeechWorks Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Cohen-Sygal</author>
<author>Shuly Wintner</author>
</authors>
<title>Partially specified signatures: A vehicle for grammar modularity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>145--152</pages>
<location>Sydney.</location>
<contexts>
<context position="6269" citStr="Cohen-Sygal and Wintner (2006)" startWordPosition="903" endWordPosition="906">lar development of type signatures in the context of both ALE and TRALE (Section 5). We show in Section 6 how our solution complies with the desiderata of Section 1.1, and conclude with directions for future research. 1.1 Motivation The motivation for modular grammar development is straightforward. Like software development, large-scale grammar development is much simpler when the task can be cleanly distributed among different developers, provided that well-defined interfaces govern the interaction among modules. From a theoretical point of view, modularity 1 This article extends and revises Cohen-Sygal and Wintner (2006) and Sygal and Wintner (2008). 30 Sygal and Wintner Modular Typed Unification Grammars facilitates the definition of cleaner semantics for the underlying formalism and the construction of correctness proofs. The engineering benefits of modularity in programming languages are summarized by Mitchell (2003, page 235), and are equally valid for grammar construction: In an effective design, each module can be designed and tested independently. Two important goals in modularity are to allow one module to be written with little knowledge of the code in another module and to allow a module to be redes</context>
</contexts>
<marker>Cohen-Sygal, Wintner, 2006</marker>
<rawString>Cohen-Sygal, Yael and Shuly Wintner. 2006. Partially specified signatures: A vehicle for grammar modularity. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 145–152, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing typed feature structures grammars.</title>
<date>2002</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="4014" citStr="Copestake 2002" startWordPosition="565" endWordPosition="566"> and Flickinger 2000). Modern grammars are written in grammatical formalisms that are often reminiscent of very-high-level, declarative (mostly logical) programming languages, and are thus very similar to computer programs. This raises problems similar to those encountered in large-scale software development (Erbach and Uszkoreit 1990). Although whereas software engineering provides adequate solutions for the programmer, grammar engineering is still in its infancy. In this work we focus on typed unification grammars (TUG), and their implementation in grammar-development platforms such as LKB (Copestake 2002), ALE (Carpenter and Penn 2001), TRALE (Meurers, Penn, and Richter 2002), or Grammix (M¨uller 2007). Such platforms conceptually view the grammar as a single entity (even when it is distributed over several files), and provide few provisions for modular grammar development, such as mechanisms for defining modules that can interact with each other through well-defined interfaces, combination of sub-grammars, separate compilation and automatic linkage of grammars, information encapsulation, and so forth. This is the main issue that we address in this work.1 We provide a preliminary yet thorough </context>
<context position="29617" citStr="Copestake 2002" startWordPosition="4532" endWordPosition="4533"> have a least element due to bounded completeness. Definition 4 Let (TYPE, C) be a type hierarchy and let x, y E TYPE. If x C y, then x is a supertype of y and y is a subtype of x. If x C y, x =� y and there is no z such that x C z C y and z =� x, y then x is an immediate supertype of y and y is an immediate subtype of x. We follow the definitions of Carpenter (1992) and Penn (2000) in viewing subtypes as greater than their supertypes (hence the least element 1 and the notion of lub), rather than the other way round (inducing a glb interpretation), which is sometimes common in the literature (Copestake 2002). Definition 5 Given a type hierarchy (TYPE, C) and a finite set of features FEAT, an appropriateness specification is a partial function, Approp : TYPE x FEAT -4 TYPE such that for every F E FEAT: 1. (Feature Introduction) there is a type Intro(F) E TYPE such that: • Approp(Intro(F),F)J., and • for every t E TYPE, if Approp(t, F)J., then Intro(F) C t, and 2. (Upward Closure / Right Monotonocy) if Approp(s,F)J. and s C t, then Approp(t, F)J. and Approp(s, F) C Approp(t, F). Definition 6 A type signature is a structure (TYPE, C, FEAT, Approp), where (TYPE, C) is a type hierarchy, FEAT is a fini</context>
<context position="34379" citStr="Copestake 2002" startWordPosition="5331" endWordPosition="5332">Nodes can be marked by types through the function T, but can also be anonymous (unmarked). Anonymous nodes facilitate reference, in one module, to types that are defined in another module. T is one-to-one (item 5), because we require that two marked nodes denote different types. The ‘�’ relation (item 3) specifies an immediate subtyping order over the nodes, with the intention that this order hold later for the types denoted by nodes. This is why ∗ ‘�’ is required to be a partial order (item 6). The type hierarchy of an ordinary type signature is required to be a BCPO, but current approaches (Copestake 2002) relax this requirement to allow more flexibility in grammar design. Similarly, the type hierarchy of PSSs is partially ordered but this order is not necessarily a bounded complete one. Only after all modules are combined is the resulting subtyping relation extended to a BCPO (see Section 2.5); any intermediate result can be a general partial order. Relaxing the BCPO requirement also helps guarantee the associativity of module combination (see Example 8).4 Consider now the appropriateness relation. In contrast to type signatures, Ap is not required to be a function. Rather, it is a relation wh</context>
<context position="64246" citStr="Copestake 2002" startWordPosition="10413" endWordPosition="10414">e. Compared with the parametric type signatures of Penn (2000), our implementation of parametric lists is simple and general: It falls out directly as one application of signature modules, whereas the construction of Penn requires dedicated machinery (parametric subtyping, parametric appropriateness, coherence, etc.) We conjecture that signature modules can be used to simulate parametric type signatures in the general case, although we do not have a proof of such a result. 2.4.5 Example: The ‘Addendum’ Operator in LKB. The ‘addendum’ operator9 was added to the type definition language of LKB (Copestake 2002) in 2005, to allow the grammar developer to add attributes to an already defined type without the need to repeat previously defined attributes of that type. The need for such an operation arose as a consequence of the development of frameworks that generate grammars from prewritten fragments (e.g., the LINGO grammar matrix, Bender, Flickinger, and Oepen 2002), since editing of framework-source files may lead to errors. Signature modules trivially support this operator, either by the merge operation (in which case different attributes of a typed node are gathered from different modules) or by a</context>
<context position="86073" citStr="Copestake 2002" startWordPosition="14108" endWordPosition="14109">structed from smaller, simpler signature modules. Real-world grammars are not only much larger, they also tend to be more complex, and in particular express interactions in domains other than the type signature (specifically, as type constraints and as phrase-structure rules). Extending our solution to such interactions is feasible, but is beyond the scope of this preliminary work. 5. MODALS: A Platform for Modular Development of Type Signatures Two leading implementation platforms are available for the development of typed unification grammars: The Linguistic Knowledge Building system (LKB) (Copestake 2002) and TRALE (Meurers, Penn, and Richter 2002), an extension of the Attribute Logic Engine (ALE) (Carpenter and Penn 2001). MODALS (MODular ALE) is a system that supports modular development of type signatures in both ALE and TRALE. The main features of the system are: • The system provides a description language with which signature modules can be specified. The description language is intuitive and is built upon the description language of ALE. For example, the description of S1, the signature module of Figure 2, is shown in Figure 23. • Signature modules may be combined using either one of th</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Copestake, Ann. 2002. Implementing typed feature structures grammars. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>An open-source grammar development environment and broad-coverage English grammar using HPSG.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second Conference on Language Resources and Evaluation (LREC-2000),</booktitle>
<pages>591--600</pages>
<contexts>
<context position="3420" citStr="Copestake and Flickinger 2000" startWordPosition="482" endWordPosition="485">r 2004; Bender et al. 2005; King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi, Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and XDG (Debusmann, Duchier, and Rossberg 2005). Grammar development is a complex enterprise: It is not unusual for a single grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen et al. 2000) and may include thousands of types (Copestake and Flickinger 2000). Modern grammars are written in grammatical formalisms that are often reminiscent of very-high-level, declarative (mostly logical) programming languages, and are thus very similar to computer programs. This raises problems similar to those encountered in large-scale software development (Erbach and Uszkoreit 1990). Although whereas software engineering provides adequate solutions for the programmer, grammar engineering is still in its infancy. In this work we focus on typed unification grammars (TUG), and their implementation in grammar-development platforms such as LKB (Copestake 2002), ALE </context>
</contexts>
<marker>Copestake, Flickinger, 2000</marker>
<rawString>Copestake, Ann and Dan Flickinger. 2000. An open-source grammar development environment and broad-coverage English grammar using HPSG. In Proceedings of the Second Conference on Language Resources and Evaluation (LREC-2000), pages 591–600.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Crabb´e</author>
<author>Denys Duchier</author>
</authors>
<title>Metagrammar redux.</title>
<date>2004</date>
<booktitle>In Proceedings of The International Workshop on Constraint Solving and Language Processing (CSLP),</booktitle>
<pages>32--47</pages>
<marker>Crabb´e, Duchier, 2004</marker>
<rawString>Crabb´e, Benoit and Denys Duchier. 2004. Metagrammar redux. In Proceedings of The International Workshop on Constraint Solving and Language Processing (CSLP), pages 32–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
</authors>
<title>Lexical Functional Grammar,</title>
<date>2001</date>
<volume>34</volume>
<publisher>Academic Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="2954" citStr="Dalrymple 2001" startWordPosition="410" endWordPosition="411">rsity of Haifa, 31905 Haifa, Israel. E-mail: yael.sygal®gmail.com. ** Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly®cs.haifa.ac.il. Submission received: 3 June 2009; revised submission received: 21 June 2010; accepted for publication: 14 September 2010. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 1 Group 2001; Oepen et al. 2002; Hinrichs, Meurers, and Wintner 2004; Bender et al. 2005; King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi, Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and XDG (Debusmann, Duchier, and Rossberg 2005). Grammar development is a complex enterprise: It is not unusual for a single grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen et al. 2000) and may include thousands of types (Copestake and Flickinger 2000). Modern grammars are written in grammatical formalisms that are often reminiscent of very-high-level, declarative (mostly logical) pr</context>
</contexts>
<marker>Dalrymple, 2001</marker>
<rawString>Dalrymple, Mary. 2001. Lexical Functional Grammar, volume 34 of Syntax and Semantics. Academic Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Debusmann</author>
</authors>
<title>Extensible Dependency Grammar: A Modular Grammar Formalism Based On Multigraph Description.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Saarlandes.</institution>
<contexts>
<context position="25515" citStr="Debusmann 2006" startWordPosition="3829" endWordPosition="3830">oduces constraints on the type system and interaction among modules through parameters is used to construct a multigraph in which some of the nodes are identified. In our approach, however, the type system is part of the grammar specification, and modules are combined via explicit combination operations. In contrast, in XDG the type mechanism is used externally, to describe objects, and a general description logic is used to impose constraints. Another major difference has to do with expressive power: Whereas unification grammars are Turing-equivalent, XDG is probably mildly contextsensitive (Debusmann 2006). The grammar formalism (GF) (Ranta 2007) is a typed functional programming language designed for multilingual grammars. Ranta introduces a module system for GF where a module can be either one of three kinds: abstract, concrete, or a resource module. Each of them reflects the kind of data this module may include. A module of type abstract includes abstract syntax trees which represent grammatical information, such as semantic or syntactic data. A module of type concrete includes relations between trees in the abstract module and relations between strings in the target language. Communication </context>
</contexts>
<marker>Debusmann, 2006</marker>
<rawString>Debusmann, Ralph. 2006. Extensible Dependency Grammar: A Modular Grammar Formalism Based On Multigraph Description. Ph.D. thesis, University of Saarlandes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Debusmann</author>
<author>Denys Duchier</author>
<author>Andreas Rossberg</author>
</authors>
<title>Modular grammar design with typed parametric principles.</title>
<date>2005</date>
<booktitle>In Proceedings of FG-MOL 2005: The 10th Conference on Formal Grammar and The 9th Meeting on Mathematics of Language,</booktitle>
<pages>113--122</pages>
<marker>Debusmann, Duchier, Rossberg, 2005</marker>
<rawString>Debusmann, Ralph, Denys Duchier, and Andreas Rossberg. 2005. Modular grammar design with typed parametric principles. In Proceedings of FG-MOL 2005: The 10th Conference on Formal Grammar and The 9th Meeting on Mathematics of Language, pages 113–122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Denys Duchier</author>
<author>Claire Gardent</author>
</authors>
<title>A constraint-based treatment of descriptions.</title>
<date>1999</date>
<booktitle>In Third International Workshop on Computational Semantics (IWCS-3),</booktitle>
<pages>71--85</pages>
<contexts>
<context position="22096" citStr="Duchier and Gardent 1999" startWordPosition="3306" endWordPosition="3309">nderlying the definition of modular HPSG discussed earlier (Keselj 2001). Provisions for modularity have also been discussed in the context of tree-adjoining grammars (TAG) (Joshi, Levy, and Takahashi 1975). A wide-coverage TAG may contain hundreds or even thousands of elementary trees, and syntactic structure can be redundantly repeated in many of them (XTAG Research Group 2001; Abeill´e, Candito, and Kinyon 2000). Consequently, maintenance and extension of such grammars is a complex task. To address these issues, several high-level formalisms were developed (VijayShanker 1992; Candito 1996; Duchier and Gardent 1999; Kallmeyer 2001). These formalisms take the metagrammar approach, where the basic units are tree descriptions (i.e., formulas denoting sets of trees) rather than trees. Tree descriptions are constructed by a tree logic and combined through conjunction or inheritance; a module in this approach is merely a tree description, and modules are combined by means of the control logic. When trees are semantic objects, (i.e., the denotation of tree descriptions), there can be various ways to refer to nodes in the trees in order to control the possible combination of grammar modules. Several mechanisms </context>
</contexts>
<marker>Duchier, Gardent, 1999</marker>
<rawString>Duchier, Denys and Claire Gardent. 1999. A constraint-based treatment of descriptions. In Third International Workshop on Computational Semantics (IWCS-3), pages 71–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Erbach</author>
<author>Hans Uszkoreit</author>
</authors>
<title>Grammar engineering: Problems and prospects.</title>
<date>1990</date>
<tech>CLAUS report 1,</tech>
<institution>University of the Saarland and German Research Center for Artificial Intelligence.</institution>
<contexts>
<context position="3736" citStr="Erbach and Uszkoreit 1990" startWordPosition="524" endWordPosition="527">grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen et al. 2000) and may include thousands of types (Copestake and Flickinger 2000). Modern grammars are written in grammatical formalisms that are often reminiscent of very-high-level, declarative (mostly logical) programming languages, and are thus very similar to computer programs. This raises problems similar to those encountered in large-scale software development (Erbach and Uszkoreit 1990). Although whereas software engineering provides adequate solutions for the programmer, grammar engineering is still in its infancy. In this work we focus on typed unification grammars (TUG), and their implementation in grammar-development platforms such as LKB (Copestake 2002), ALE (Carpenter and Penn 2001), TRALE (Meurers, Penn, and Richter 2002), or Grammix (M¨uller 2007). Such platforms conceptually view the grammar as a single entity (even when it is distributed over several files), and provide few provisions for modular grammar development, such as mechanisms for defining modules that ca</context>
<context position="8627" citStr="Erbach and Uszkoreit (1990)" startWordPosition="1257" endWordPosition="1260">the linguistic notion. Furthermore, although there is no general agreement among linguists on the exact form of grammar modularity, a good solution for grammar development must not reflect the correctness of linguistic theories but rather provide the computational framework for their implementation. To consolidate the two notions of modularity, and to devise a solution that is on one hand inspired by developments in programming languages and on the other useful for linguists, a clear understanding of the actual needs of grammar developers is crucial. A first step in this direction was done by Erbach and Uszkoreit (1990). In a similar vein, we carefully explored two existing grammars: the LINGO grammar matrix (Bender, Flickinger, and Oepen 2002),2 which is a framework for rapid development of crosslinguistically consistent grammars; and a grammar of a fragment of modern Hebrew, focusing on inverted constructions (Melnik 2006). These grammars were chosen since they are comprehensive enough to reflect the kind of data large-scale grammars encode, but are not too large to encumber this process. Inspired by established criteria for modularity in programming languages, and motivated by our observation of actual gr</context>
</contexts>
<marker>Erbach, Uszkoreit, 1990</marker>
<rawString>Erbach, Gregor and Hans Uszkoreit. 1990. Grammar engineering: Problems and prospects. CLAUS report 1, University of the Saarland and German Research Center for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Fodor</author>
</authors>
<title>The Modularity of Mind.</title>
<date>1983</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="7755" citStr="Fodor 1983" startWordPosition="1125" endWordPosition="1126">, and Mello (1994, page 444) state that [a] modular language should allow rich forms of abstraction, parametrization, and information hiding; it should ease the development and maintenance of large programs as well as provide adequate support or reusability and separate and efficient compilation; it should finally encompass a non-trivial notion of program equivalence to make it possible to justify the replacement of equivalent components. In the linguistic literature, however, modularity has a different flavor which has to do with the way linguistic knowledge is organized, either cognitively (Fodor 1983) or theoretically (Jackendoff 2002, pages 218–230). Although we do not directly subscribe to this notion of modularity in this work, it may be the case that an engineering-inspired definition of modules will facilitate a better understanding of the linguistic notion. Furthermore, although there is no general agreement among linguists on the exact form of grammar modularity, a good solution for grammar development must not reflect the correctness of linguistic theories but rather provide the computational framework for their implementation. To consolidate the two notions of modularity, and to d</context>
</contexts>
<marker>Fodor, 1983</marker>
<rawString>Fodor, Jerry. 1983. The Modularity of Mind. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haim Gaifman</author>
<author>Ehud Shapiro</author>
</authors>
<title>Fully abstract compositional semantics for logic programming.</title>
<date>1989</date>
<booktitle>In 16th Annual ACM Symposium on Principles of Logic Programming,</booktitle>
<pages>134--142</pages>
<location>Austin, TX.</location>
<contexts>
<context position="13220" citStr="Gaifman and Shapiro (1989)" startWordPosition="1943" endWordPosition="1946">nts which are becoming common in practical systems. We defer an extension of our results to type constraints to future work. 32 Sygal and Wintner Modular Typed Unification Grammars 1.2 Related Work 1.2.1 Modularity in Programming Languages. Vast literature addresses modularity in programming languages, and a comprehensive survey is beyond the scope of this work. As unification grammars are in many ways very similar to logic programming languages, our desiderata and solutions are inspired by works in this paradigm. Modular interfaces of logic programs were first suggested by O’keefe (1985) and Gaifman and Shapiro (1989). Combination operators that were proved suitable for Prolog include the algebraic operators ⊕ and ⊗ of Mancarella and Pedreschi (1988); the union and intersection operators of Brogi et al. (1990); the closure operator of Brogi, Lamma, and Mello (1993); and the set of four operators (encapsulation, union, intersection, and import) defined by Brogi and Turini (1995). For a comprehensive survey, see Bugliesi, Lamma, and Mello (1994). The ‘merge’ operator that we present in Section 2.4.2 is closely related to union operations proposed for logic programming languages. We define no counterpart of i</context>
</contexts>
<marker>Gaifman, Shapiro, 1989</marker>
<rawString>Gaifman, Haim and Ehud Shapiro. 1989. Fully abstract compositional semantics for logic programming. In 16th Annual ACM Symposium on Principles of Logic Programming, pages 134–142, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Garey</author>
<author>David S Johnson</author>
</authors>
<title>Computers and Intractability: A Guide to the Theory of NP-Completeness.</title>
<date>1979</date>
<location>New York.</location>
<contexts>
<context position="89532" citStr="Garey and Johnson (1979)" startWordPosition="14647" endWordPosition="14650"> (Section 2), and the extension to grammar modules (Section 3) is natural and conservative. We do restrict ourselves in this work to standard type signatures without type constraints. We defer the extension of type signatures to include also type constraints to future work. Partiality: Our solution provides the grammar developer with means to specify any piece of information about the signature. A signature module may specify only partial information about the subtyping and appropriateness relations. Furthermore, the appropriateness relation is not a function as in ordinary signatures, and 12 Garey and Johnson (1979) provide a list of 12 major problems whose complexity status was open at the time of writing. Recognition of graph isomorphism is one of those, and one of the only two whose complexity remains unresolved today. 65 Computational Linguistics Volume 37, Number 1 the developer may specify several appropriate nodes for the values of a feature F at a node q. The anonymity of nodes and relaxed upward closure also provide means for partiality. Another relaxation that supports partiality is not enforcing feature introduction and the BCPO conditions. Finally, the possibility of distributing the grammar </context>
</contexts>
<marker>Garey, Johnson, 1979</marker>
<rawString>Garey, Michael R. and David S. Johnson. 1979. Computers and Intractability: A Guide to the Theory of NP-Completeness. W. H. Freeman, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard W Hinrichs</author>
<author>W Detmar Meurers</author>
<author>Shuly Wintner</author>
</authors>
<title>Linguistic theory and grammar implementation.</title>
<date>2004</date>
<booktitle>Research on Language and Computation,</booktitle>
<pages>2--155</pages>
<marker>Hinrichs, Meurers, Wintner, 2004</marker>
<rawString>Hinrichs, Erhard W., W. Detmar Meurers, and Shuly Wintner. 2004. Linguistic theory and grammar implementation. Research on Language and Computation, 2:155–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>Foundations of Language.</title>
<date>2002</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="7789" citStr="Jackendoff 2002" startWordPosition="1129" endWordPosition="1130">tate that [a] modular language should allow rich forms of abstraction, parametrization, and information hiding; it should ease the development and maintenance of large programs as well as provide adequate support or reusability and separate and efficient compilation; it should finally encompass a non-trivial notion of program equivalence to make it possible to justify the replacement of equivalent components. In the linguistic literature, however, modularity has a different flavor which has to do with the way linguistic knowledge is organized, either cognitively (Fodor 1983) or theoretically (Jackendoff 2002, pages 218–230). Although we do not directly subscribe to this notion of modularity in this work, it may be the case that an engineering-inspired definition of modules will facilitate a better understanding of the linguistic notion. Furthermore, although there is no general agreement among linguists on the exact form of grammar modularity, a good solution for grammar development must not reflect the correctness of linguistic theories but rather provide the computational framework for their implementation. To consolidate the two notions of modularity, and to devise a solution that is on one ha</context>
</contexts>
<marker>Jackendoff, 2002</marker>
<rawString>Jackendoff, Ray. 2002. Foundations of Language. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Leon S Levy</author>
<author>Masako Takahashi</author>
</authors>
<title>Tree adjunct grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>10</volume>
<issue>1</issue>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Joshi, Aravind K., Leon S. Levy, and Masako Takahashi. 1975. Tree adjunct grammars. Journal of Computer and System Sciences, 10(1):136–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvain Kahane</author>
</authors>
<title>Polarized unification grammars.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL</booktitle>
<pages>137--144</pages>
<location>Sydney.</location>
<contexts>
<context position="22822" citStr="Kahane 2006" startWordPosition="3420" endWordPosition="3421">e., formulas denoting sets of trees) rather than trees. Tree descriptions are constructed by a tree logic and combined through conjunction or inheritance; a module in this approach is merely a tree description, and modules are combined by means of the control logic. When trees are semantic objects, (i.e., the denotation of tree descriptions), there can be various ways to refer to nodes in the trees in order to control the possible combination of grammar modules. Several mechanisms have been suggested to facilitate reference across modules (Candito 1996; Perrier 2000; Crabb´e and Duchier 2004; Kahane 2006). The solution that we propose here embraces the idea of moving from concrete objects (e.g., a concrete type signature) to descriptions thereof; but we take special care to do so in a way that maintains the associativity of the main grammar combination operator, in contrast to some earlier approaches (Sygal and Wintner 2009). Debusmann, Duchier, and Rossberg (2005) introduce Extensible Dependency Grammar (XDG), which is a general framework for dependency grammars that supports modular grammar design. An XDG grammar consists of dimensions, principles, and a lexicon; it characterizes a set of we</context>
</contexts>
<marker>Kahane, 2006</marker>
<rawString>Kahane, Sylvain. 2006. Polarized unification grammars. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL 2006), pages 137–144, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Kallmeyer</author>
</authors>
<title>Local tree description grammars.</title>
<date>2001</date>
<journal>Grammars,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="22113" citStr="Kallmeyer 2001" startWordPosition="3310" endWordPosition="3311">f modular HPSG discussed earlier (Keselj 2001). Provisions for modularity have also been discussed in the context of tree-adjoining grammars (TAG) (Joshi, Levy, and Takahashi 1975). A wide-coverage TAG may contain hundreds or even thousands of elementary trees, and syntactic structure can be redundantly repeated in many of them (XTAG Research Group 2001; Abeill´e, Candito, and Kinyon 2000). Consequently, maintenance and extension of such grammars is a complex task. To address these issues, several high-level formalisms were developed (VijayShanker 1992; Candito 1996; Duchier and Gardent 1999; Kallmeyer 2001). These formalisms take the metagrammar approach, where the basic units are tree descriptions (i.e., formulas denoting sets of trees) rather than trees. Tree descriptions are constructed by a tree logic and combined through conjunction or inheritance; a module in this approach is merely a tree description, and modules are combined by means of the control logic. When trees are semantic objects, (i.e., the denotation of tree descriptions), there can be various ways to refer to nodes in the trees in order to control the possible combination of grammar modules. Several mechanisms have been suggest</context>
</contexts>
<marker>Kallmeyer, 2001</marker>
<rawString>Kallmeyer, Laura. 2001. Local tree description grammars. Grammars, 4(2):85–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Tracy Holloway King</author>
<author>John T Maxwell</author>
</authors>
<title>Adapting existing grammars: The XLE experience.</title>
<date>2002</date>
<booktitle>In COLING-02 Workshop on Grammar Engineering and Evaluation,</booktitle>
<pages>1--7</pages>
<location>Morristown, NJ.</location>
<marker>Kaplan, King, Maxwell, 2002</marker>
<rawString>Kaplan, Ronald M., Tracy Holloway King, and John T. Maxwell. 2002. Adapting existing grammars: The XLE experience. In COLING-02 Workshop on Grammar Engineering and Evaluation, pages 1–7, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Kasper</author>
<author>Hans-Ulrich Krieger</author>
</authors>
<title>Modularizing codescriptive grammars for efficient parsing.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th Conference on Computational Linguistics,</booktitle>
<pages>628--633</pages>
<location>Copenhagen.</location>
<contexts>
<context position="14212" citStr="Kasper and Krieger (1996)" startWordPosition="2087" endWordPosition="2090">. For a comprehensive survey, see Bugliesi, Lamma, and Mello (1994). The ‘merge’ operator that we present in Section 2.4.2 is closely related to union operations proposed for logic programming languages. We define no counterpart of intersection-type operations, although such operations are indeed conceivable. Our ‘attachment’ operation is more in line with Gaifman and Shapiro (1989). 1.2.2 Initial Approaches: Modularized Parsing. Early attempts to address modularity in linguistic formalisms share a significant disadvantage: The modularization is of the parsing process rather than the grammar. Kasper and Krieger (1996) describe a technique for dividing a unification-based grammar into two components, roughly along the syntax/semantics axis. Their motivation is efficiency; observing that syntax usually imposes constraints on permissible structures, and semantics usually mostly adds structure, they propose to parse with the syntactic constraints first, and apply the semantics later. This is achieved by recursively deleting the syntactic and semantic information (under their corresponding attributes in the rules and the lexicon) for the semantic and syntactic parsers, respectively. This proposal requires that </context>
</contexts>
<marker>Kasper, Krieger, 1996</marker>
<rawString>Kasper, Walter and Hans-Ulrich Krieger. 1996. Modularizing codescriptive grammars for efficient parsing. In Proceedings of the 16th Conference on Computational Linguistics, pages 628–633, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vlado Keselj</author>
</authors>
<title>Modular HPSG.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 IEEE Systems, Man, and Cybernetics Conference,</booktitle>
<pages>2867--2872</pages>
<location>Tucson, AZ.</location>
<contexts>
<context position="16287" citStr="Keselj (2001)" startWordPosition="2402" endWordPosition="2403"> is such that sub-grammar Gi+1 operates on the output of sub-grammar Gi; such an organization might not be suitable for all grammar development frameworks. A similar idea is proposed by Basili, Pazienza, and Zanzotto (2000); it is an approach to parsing that divides the task into sub-tasks, whereby a module component Pi takes an input sentence at a given state of analysis Si and augments this information in Si+1 using a knowledge base Ki. Here, too, it is the processing system, rather than the grammar, which is modularized in a pipeline fashion. 1.2.3 Modularity in Typed Unification Grammars. Keselj (2001) presents a modular Headdriven Phrase Structure Grammar (HPSG), where each module is an ordinary HPSG grammar, including an ordinary type signature, but each of the sets FEAT, TYPE, and RULES is divided into two disjoint sets of private and public elements. The public 33 Computational Linguistics Volume 37, Number 1 sets consist of those elements that can communicate with elements from corresponding sets in other modules, and private elements are those that are internal to the module. Merging two modules is then defined by set union; in particular, the type hierarchies are merged by unioning t</context>
<context position="17738" citStr="Keselj (2001)" startWordPosition="2636" endWordPosition="2637">y define signature modules, it provides a highly insufficient mechanism for supporting modular grammar development: The requirement that each module include a complete type hierarchy imposes strong limitations on the kind of information that modules can specify. It is virtually impossible to specify partial information that is consistent with the complete type hierarchy requirement. Furthermore, module composition becomes order-dependent as we show in Example 8 (Section 2.4.2). Finally, the only channel of interaction between modules is the names of the types. Our work is similar in spirit to Keselj (2001), but it overcomes these shortcomings and complies with the desiderata of Section 1.1. Kaplan, King, and Maxwell (2002) introduce a system designed for building a grammar by both extending and restricting another grammar. An LFG grammar is presented to the system in a priority-ordered sequence of files containing phrase-structure rules, lexical entries, abbreviatory macros and templates, feature declarations, and finite-state transducers for tokenization and morphological analysis. The grammar can include only one definition of an item of a given type with a particular name (e.g., there can be</context>
<context position="21544" citStr="Keselj 2001" startWordPosition="3227" endWordPosition="3228">classes of internal, exported, and imported elements. The imported elements are those that are supplied to the module by other modules, the exported elements are those it provides to the outside world, and the internal ones are local to it. Two modules can be combined only if the set of internal elements of each module is disjoint from the exported and imported sets of the other module as well as if the exported sets are disjoint. Then the combination of two modules is done by simple measures of set union. This is the infrastructure underlying the definition of modular HPSG discussed earlier (Keselj 2001). Provisions for modularity have also been discussed in the context of tree-adjoining grammars (TAG) (Joshi, Levy, and Takahashi 1975). A wide-coverage TAG may contain hundreds or even thousands of elementary trees, and syntactic structure can be redundantly repeated in many of them (XTAG Research Group 2001; Abeill´e, Candito, and Kinyon 2000). Consequently, maintenance and extension of such grammars is a complex task. To address these issues, several high-level formalisms were developed (VijayShanker 1992; Candito 1996; Duchier and Gardent 1999; Kallmeyer 2001). These formalisms take the met</context>
</contexts>
<marker>Keselj, 2001</marker>
<rawString>Keselj, Vlado. 2001. Modular HPSG. In Proceedings of the 2001 IEEE Systems, Man, and Cybernetics Conference, pages 2867–2872, Tucson, AZ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy Holloway King</author>
<author>Martin Forst</author>
<author>Jonas Kuhn</author>
<author>Miriam Butt</author>
</authors>
<title>The feature space in parallel grammar writing.</title>
<date>2005</date>
<booktitle>Research on Language and Computation,</booktitle>
<pages>3--139</pages>
<contexts>
<context position="2834" citStr="King et al. 2005" startWordPosition="392" endWordPosition="395">eveloped for various languages (Abeill´e, Candito, and Kinyon 2000; XTAG Research * Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: yael.sygal®gmail.com. ** Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly®cs.haifa.ac.il. Submission received: 3 June 2009; revised submission received: 21 June 2010; accepted for publication: 14 September 2010. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 1 Group 2001; Oepen et al. 2002; Hinrichs, Meurers, and Wintner 2004; Bender et al. 2005; King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi, Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and XDG (Debusmann, Duchier, and Rossberg 2005). Grammar development is a complex enterprise: It is not unusual for a single grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen et al. 2000) and may include thousands of types (Copestake and Flickinger 2000). Modern gramm</context>
<context position="11967" citStr="King et al. (2005)" startWordPosition="1756" endWordPosition="1759">on of data. In other cases, associativity and commutativity should be considered with respect to the benefit the system may enjoy if they are abandoned. Privacy: Modules should be able to hide (encapsulate) information and render it unavailable to other modules. The solution we advocate here satisfies all these requirements. It facilitates collaborative development of grammars, where several applications of modularity are conceivable: • A single large-scale grammar developed by a team. • Development of parallel grammars for multiple languages under a single theory, as in Bender et al. (2005), King et al. (2005), or M¨uller (2007). Here, a core module is common to all grammars, and language-specific fragments are developed as separate modules. • A sequence of grammars modeling language development, for example language acquisition or (historical) language change (Wintner, Lavie, and MacWhinney 2009). Here, a “new” grammar is obtained from a “previous” grammar; formal modeling of such operations through module composition can shed new light on the linguistic processes that take place as language develops. 3 We restrict ourselves to standard type signatures (as defined by Carpenter [1992] and Penn [200</context>
<context position="18854" citStr="King et al. (2005)" startWordPosition="2808" endWordPosition="2811"> can include only one definition of an item of a given type with a particular name (e.g., there can be only one NP rule, potentially with many alternative expansions), and items in a file with higher priority override lower priority items of the same type with the same name. The override convention makes it possible to add, delete, or modify rules. However, when a rule is modified, the entire rule has to be rewritten, even if the modifications are minor. Moreover, there is no real concept of modularization in this approach because the only interaction among files is overriding of information. King et al. (2005) augment LFG with a makeshift signature to allow modular development of untyped unification grammars. In addition, they suggest that any development team should agree in advance on the feature space. This work emphasizes the observation that the modularization of the signature is the key for modular development of grammars. However, the proposed solution is ad hoc and cannot be taken seriously as a concept of modularization. In particular, the suggestion for an agreement on the feature space undermines the essence of modular design. To support rapid prototyping of deep grammars, Bender and Fli</context>
</contexts>
<marker>King, Forst, Kuhn, Butt, 2005</marker>
<rawString>King, Tracy Holloway, Martin Forst, Jonas Kuhn, and Miriam Butt. 2005. The feature space in parallel grammar writing. Research on Language and Computation, 3:139–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Mancarella</author>
<author>Dino Pedreschi</author>
</authors>
<title>An algebra of logic programs.</title>
<date>1988</date>
<booktitle>Logic Programming: Proceedings of the Fifth International Conference and Symposium,</booktitle>
<pages>1006--1023</pages>
<editor>In Robert A. Kowalski and Kenneth A. Bowen, editors,</editor>
<location>Cambridge, MA.</location>
<contexts>
<context position="13355" citStr="Mancarella and Pedreschi (1988)" startWordPosition="1963" endWordPosition="1966">gal and Wintner Modular Typed Unification Grammars 1.2 Related Work 1.2.1 Modularity in Programming Languages. Vast literature addresses modularity in programming languages, and a comprehensive survey is beyond the scope of this work. As unification grammars are in many ways very similar to logic programming languages, our desiderata and solutions are inspired by works in this paradigm. Modular interfaces of logic programs were first suggested by O’keefe (1985) and Gaifman and Shapiro (1989). Combination operators that were proved suitable for Prolog include the algebraic operators ⊕ and ⊗ of Mancarella and Pedreschi (1988); the union and intersection operators of Brogi et al. (1990); the closure operator of Brogi, Lamma, and Mello (1993); and the set of four operators (encapsulation, union, intersection, and import) defined by Brogi and Turini (1995). For a comprehensive survey, see Bugliesi, Lamma, and Mello (1994). The ‘merge’ operator that we present in Section 2.4.2 is closely related to union operations proposed for logic programming languages. We define no counterpart of intersection-type operations, although such operations are indeed conceivable. Our ‘attachment’ operation is more in line with Gaifman a</context>
</contexts>
<marker>Mancarella, Pedreschi, 1988</marker>
<rawString>Mancarella, Paolo and Dino Pedreschi. 1988. An algebra of logic programs. In Robert A. Kowalski and Kenneth A. Bowen, editors, Logic Programming: Proceedings of the Fifth International Conference and Symposium, pages 1006–1023, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nurit Melnik</author>
</authors>
<title>A constructional approach to verb-initial constructions in modern Hebrew.</title>
<date>2006</date>
<journal>Cognitive Linguistics,</journal>
<volume>17</volume>
<issue>2</issue>
<contexts>
<context position="8938" citStr="Melnik 2006" startWordPosition="1305" endWordPosition="1306">tions of modularity, and to devise a solution that is on one hand inspired by developments in programming languages and on the other useful for linguists, a clear understanding of the actual needs of grammar developers is crucial. A first step in this direction was done by Erbach and Uszkoreit (1990). In a similar vein, we carefully explored two existing grammars: the LINGO grammar matrix (Bender, Flickinger, and Oepen 2002),2 which is a framework for rapid development of crosslinguistically consistent grammars; and a grammar of a fragment of modern Hebrew, focusing on inverted constructions (Melnik 2006). These grammars were chosen since they are comprehensive enough to reflect the kind of data large-scale grammars encode, but are not too large to encumber this process. Inspired by established criteria for modularity in programming languages, and motivated by our observation of actual grammars, we define the following desiderata for a beneficial solution for (typed unification) grammar modularization: Signature focus: Much of the information in typed formalisms is encoded by the signature. This includes the type hierarchy, the appropriateness specification, and the 2 The LINGO grammar matrix </context>
</contexts>
<marker>Melnik, 2006</marker>
<rawString>Melnik, Nurit. 2006. A constructional approach to verb-initial constructions in modern Hebrew. Cognitive Linguistics, 17(2):153–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Detmar Meurers</author>
<author>Gerald Penn</author>
<author>Frank Richter</author>
</authors>
<title>A Web-based instructional platform for constraint-based grammar formalisms and parsing.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL,</booktitle>
<pages>18--25</pages>
<marker>Meurers, Penn, Richter, 2002</marker>
<rawString>Meurers, W. Detmar, Gerald Penn, and Frank Richter. 2002. A Web-based instructional platform for constraint-based grammar formalisms and parsing. In Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Mitchell</author>
</authors>
<title>Concepts in Programming Languages.</title>
<date>2003</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="6573" citStr="Mitchell (2003" startWordPosition="948" endWordPosition="949">pment, large-scale grammar development is much simpler when the task can be cleanly distributed among different developers, provided that well-defined interfaces govern the interaction among modules. From a theoretical point of view, modularity 1 This article extends and revises Cohen-Sygal and Wintner (2006) and Sygal and Wintner (2008). 30 Sygal and Wintner Modular Typed Unification Grammars facilitates the definition of cleaner semantics for the underlying formalism and the construction of correctness proofs. The engineering benefits of modularity in programming languages are summarized by Mitchell (2003, page 235), and are equally valid for grammar construction: In an effective design, each module can be designed and tested independently. Two important goals in modularity are to allow one module to be written with little knowledge of the code in another module and to allow a module to be redesigned and re-implemented without modifying other parts of the system. A suitable notion of modularity should support “reuse of software, abstraction mechanisms for information hiding, and import/export relationships” (Brogi et al. 1994, page 1363). Similarly, Bugliesi, Lamma, and Mello (1994, page 444) </context>
</contexts>
<marker>Mitchell, 2003</marker>
<rawString>Mitchell, John C. 2003. Concepts in Programming Languages. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan M¨uller</author>
</authors>
<title>The Grammix CD ROM. A software collection for developing typed feature structure grammars.</title>
<date>2007</date>
<booktitle>Grammar Engineering across Frameworks 2007, Studies in Computational Linguistics ONLINE.</booktitle>
<pages>259--266</pages>
<editor>In Tracy Holloway King and Emily M. Bender, editors,</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA,</location>
<marker>M¨uller, 2007</marker>
<rawString>M¨uller, Stefan. 2007. The Grammix CD ROM. A software collection for developing typed feature structure grammars. In Tracy Holloway King and Emily M. Bender, editors, Grammar Engineering across Frameworks 2007, Studies in Computational Linguistics ONLINE. CSLI Publications, Stanford, CA, pages 259–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Dan Flickinger</author>
<author>Hans Uszkoreit</author>
<author>Jun-Ichi Tsujii</author>
</authors>
<title>Introduction to this special issue.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="3353" citStr="Oepen et al. 2000" startWordPosition="472" endWordPosition="475"> 2001; Oepen et al. 2002; Hinrichs, Meurers, and Wintner 2004; Bender et al. 2005; King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi, Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and XDG (Debusmann, Duchier, and Rossberg 2005). Grammar development is a complex enterprise: It is not unusual for a single grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen et al. 2000) and may include thousands of types (Copestake and Flickinger 2000). Modern grammars are written in grammatical formalisms that are often reminiscent of very-high-level, declarative (mostly logical) programming languages, and are thus very similar to computer programs. This raises problems similar to those encountered in large-scale software development (Erbach and Uszkoreit 1990). Although whereas software engineering provides adequate solutions for the programmer, grammar engineering is still in its infancy. In this work we focus on typed unification grammars (TUG), and their implementation </context>
</contexts>
<marker>Oepen, Flickinger, Uszkoreit, Tsujii, 2000</marker>
<rawString>Oepen, Stephan, Dan Flickinger, Hans Uszkoreit, and Jun-Ichi Tsujii. 2000. Introduction to this special issue. Natural Language Engineering, 6(1):1–14.</rawString>
</citation>
<citation valid="true">
<date>2002</date>
<booktitle>Collaborative Language Engineering: A Case Study in Efficient Grammar-Based Processing.</booktitle>
<editor>Oepen, Stephan, Daniel Flickinger, J. Tsujii, and Hans Uszkoreit, editors.</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="17857" citStr="(2002)" startWordPosition="2655" endWordPosition="2655">ement that each module include a complete type hierarchy imposes strong limitations on the kind of information that modules can specify. It is virtually impossible to specify partial information that is consistent with the complete type hierarchy requirement. Furthermore, module composition becomes order-dependent as we show in Example 8 (Section 2.4.2). Finally, the only channel of interaction between modules is the names of the types. Our work is similar in spirit to Keselj (2001), but it overcomes these shortcomings and complies with the desiderata of Section 1.1. Kaplan, King, and Maxwell (2002) introduce a system designed for building a grammar by both extending and restricting another grammar. An LFG grammar is presented to the system in a priority-ordered sequence of files containing phrase-structure rules, lexical entries, abbreviatory macros and templates, feature declarations, and finite-state transducers for tokenization and morphological analysis. The grammar can include only one definition of an item of a given type with a particular name (e.g., there can be only one NP rule, potentially with many alternative expansions), and items in a file with higher priority override low</context>
<context position="20831" citStr="(2002)" startWordPosition="3108" endWordPosition="3108">es of code which the grammar designer does not develop and whose interaction he or she has little control over. 1.2.4 Modularity in Related Formalisms. The previously mentioned works emphasize the fact that existing approaches to modular grammar development in the area of unification grammars are still insufficient. The same problem has also been addressed in some 34 Sygal and Wintner Modular Typed Unification Grammars other, related, formalisms; we now survey such works and discuss the applicability of the proposed solutions to the problem of modularity in typed unification grammars. Wintner (2002) defines the concept of modules for CFGs: The set of nonterminals is partitioned into three disjoint classes of internal, exported, and imported elements. The imported elements are those that are supplied to the module by other modules, the exported elements are those it provides to the outside world, and the internal ones are local to it. Two modules can be combined only if the set of internal elements of each module is disjoint from the exported and imported sets of the other module as well as if the exported sets are disjoint. Then the combination of two modules is done by simple measures o</context>
</contexts>
<marker>2002</marker>
<rawString>Oepen, Stephan, Daniel Flickinger, J. Tsujii, and Hans Uszkoreit, editors. 2002. Collaborative Language Engineering: A Case Study in Efficient Grammar-Based Processing. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R O’Keefe</author>
</authors>
<title>Towards an algebra for constructing logic programs.</title>
<date>1985</date>
<booktitle>Proceedings of IEEE Symposium on Logic Programming,</booktitle>
<pages>152--160</pages>
<editor>In J. Cohen and J. Conery, editors,</editor>
<location>New York.</location>
<marker>O’Keefe, 1985</marker>
<rawString>O’Keefe, R. 1985. Towards an algebra for constructing logic programs. In J. Cohen and J. Conery, editors, Proceedings of IEEE Symposium on Logic Programming, pages 152–160, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald B Penn</author>
</authors>
<title>The Algebraic Structure of Attributed Type Signatures.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Computer Science, Carnegie Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="27943" citStr="Penn (2000)" startWordPosition="4195" endWordPosition="4196">face with other modules; then, when modules combine they may do so in any way that is consistent with the interfaces of other modules. Furthermore, reference to mutual elements in GF is carried out only through naming, again resulting in a weak interface for module interaction. Finally, the operations that the grammar writer can define in GF are macros, rather than functions, as they are expanded by textual replacement. 2. Modularization of the Signature 2.1 Typed Signatures We assume familiarity with theories of (typed) unification grammar, as formulated by, for example, Carpenter (1992) and Penn (2000). The definitions in this section set the notation and recall basic notions. For a partial function F, ‘F(x)l’ (‘F(x)r’) means that F is defined (undefined) for the value x; ‘F(x) = F(y)’ means that either F is defined both for x and for y and assigns them equal values or it is undefined for both. Definition 1 Given a partially ordered set (P, &lt;), the set of upper bounds of a subset S C_ P is the set Su = {y E P |Vx E S x &lt; y}. 36 Sygal and Wintner Modular Typed Unification Grammars For a given partially ordered set (P, &lt;), if S C_ P has a least element then it is unique, and is denoted min(S)</context>
<context position="29387" citStr="Penn (2000)" startWordPosition="4495" endWordPosition="4496">s a non-empty, finite, bounded complete partial order (TYPE, C). Every type hierarchy (TYPE, C) always has a least type (written 1), because the subset S = 0 of TYPE has the non-empty set of upper bounds, S&amp;quot; = TYPE, which must have a least element due to bounded completeness. Definition 4 Let (TYPE, C) be a type hierarchy and let x, y E TYPE. If x C y, then x is a supertype of y and y is a subtype of x. If x C y, x =� y and there is no z such that x C z C y and z =� x, y then x is an immediate supertype of y and y is an immediate subtype of x. We follow the definitions of Carpenter (1992) and Penn (2000) in viewing subtypes as greater than their supertypes (hence the least element 1 and the notion of lub), rather than the other way round (inducing a glb interpretation), which is sometimes common in the literature (Copestake 2002). Definition 5 Given a type hierarchy (TYPE, C) and a finite set of features FEAT, an appropriateness specification is a partial function, Approp : TYPE x FEAT -4 TYPE such that for every F E FEAT: 1. (Feature Introduction) there is a type Intro(F) E TYPE such that: • Approp(Intro(F),F)J., and • for every t E TYPE, if Approp(t, F)J., then Intro(F) C t, and 2. (Upward </context>
<context position="61157" citStr="Penn (2000)" startWordPosition="9894" endWordPosition="9895">Imp1a = (q4, q5) and let Exp9a = (p9,p10). S1a(S9a) is depicted in the same figure. Notice how q4,q5 are coalesced with p9, p10, respectively, even though q4, q5 are anonymous and p9, p10 are typed and each pair of nodes has different attributes. Such unification of nodes cannot be achieved with the merge operation. Figure 10 Attachment. 51 Computational Linguistics Volume 37, Number 1 2.4.4 Example: Parametric Lists. Lists and parametric lists are extensively used in typed unification-based formalisms, for example in HPSG. The mathematical foundations for parametric lists were established by Penn (2000). As an example of the utility of signature modules and the attachment operation, we show how they can be used to construct parametric lists in a straightforward way. Consider Figure 11. The signature module List depicts a parametric list module. It receives as input, through the imported node q3, a node which determines the type of the list members. The entire list can then be used through the exported node q4. Notice that q2 is an external anonymous node. Although its intended denotation is the type ne list, it is anonymous in order to be unique for each copy of the list, as will be shown su</context>
<context position="63693" citStr="Penn (2000)" startWordPosition="10331" endWordPosition="10332"> typed by ne list it could be coalesced with any other node marked by the same type, such as other such nodes from different copies of the list, resulting in a list whose members have various types. Observe that the uniqueness of each copy of the list could be achieved also by declaring q2 an internal node, but this solution prevents other modules from referring to this node, as is reasonably desired. q1 (of List) is typed by elist. Because only one copy of this node is required for all the list copies, there is no problem with typing this node. Compared with the parametric type signatures of Penn (2000), our implementation of parametric lists is simple and general: It falls out directly as one application of signature modules, whereas the construction of Penn requires dedicated machinery (parametric subtyping, parametric appropriateness, coherence, etc.) We conjecture that signature modules can be used to simulate parametric type signatures in the general case, although we do not have a proof of such a result. 2.4.5 Example: The ‘Addendum’ Operator in LKB. The ‘addendum’ operator9 was added to the type definition language of LKB (Copestake 2002) in 2005, to allow the grammar developer to add</context>
<context position="65743" citStr="Penn (2000)" startWordPosition="10638" endWordPosition="10639"> signatures. After modules are combined, however, the resulting signature module must be extended into a bona fide signature. For that purpose we use four algorithms, each of which deals with one property: 1. Name resolution: This algorithm assigns types to anonymous nodes (Section 2.5.1). 2. Appropriateness consolidation: This algorithm determinizes Ap, converts it from a relation to a function and enforces upward closure (Section 2.5.2). 3. Feature introduction completion: This algorithm (whose use is optional) enforces the feature introduction condition. This is done using the algorithm of Penn (2000). 4. BCPO completion: This algorithm extends ‘�’ to a BCPO. Again, we use the algorithm of Penn (2000). 9 See http://depts.washington.edu/uwcl/twiki/bin/view.cgi/Main/TypeAddendum. 53 Computational Linguistics Volume 37, Number 1 The input to the resolution algorithm is a signature module and its output is a bona fide type signature. Algorithm 1 (Resolve (S)) 1. S := NameResolution(S) 2. S := BCPO−Completion(S) 3. S := ApCl(S) 4. S := ApConsolidate(S) 5. S := FeatureIntroductionCompletion(S) 6. S := BCPO−Completion(S) 7. S := ApCl(S) 8. S := ApConsolidate(S) 9. return S The order in which the </context>
<context position="87760" citStr="Penn (2000)" startWordPosition="14380" endWordPosition="14381"> was created as a result of several combination operators. ALE and TRALE share the same underlying core, and are based on data structures and algorithms that take advantage of type signature properties such as bounded completeness, upward closure, and feature introduction, none of which can be assumed when working with a signature module. As a result, our implementation is not a direct adaption of the existing ALE/TRALE code, but a new system that was developed from 64 Sygal and Wintner Modular Typed Unification Grammars Figure 23 MODALE description of S1. scratch. Extending the algorithms of Penn (2000) from type signatures into signature modules is left as a direction for future research. The MODALE system provided us with an opportunity to experimentally evaluate the time efficiency of module combination. Indeed, the combination and resolution algorithms are computationally inefficient as they require repeated calculations of graph isomorphism, a problem which is neither known to be solvable in polynomial time nor NP-complete.12 However, in the signatures we have experimented with so far, we encountered no time issues. Furthermore, it is important to note that these calculations are execut</context>
</contexts>
<marker>Penn, 2000</marker>
<rawString>Penn, Gerald B. 2000. The Algebraic Structure of Attributed Type Signatures. Ph.D. thesis, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy Perrier</author>
</authors>
<title>Interaction grammars.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th Conference on Computational Linguistics (COLING</booktitle>
<pages>600--606</pages>
<contexts>
<context position="22782" citStr="Perrier 2000" startWordPosition="3414" endWordPosition="3415">he basic units are tree descriptions (i.e., formulas denoting sets of trees) rather than trees. Tree descriptions are constructed by a tree logic and combined through conjunction or inheritance; a module in this approach is merely a tree description, and modules are combined by means of the control logic. When trees are semantic objects, (i.e., the denotation of tree descriptions), there can be various ways to refer to nodes in the trees in order to control the possible combination of grammar modules. Several mechanisms have been suggested to facilitate reference across modules (Candito 1996; Perrier 2000; Crabb´e and Duchier 2004; Kahane 2006). The solution that we propose here embraces the idea of moving from concrete objects (e.g., a concrete type signature) to descriptions thereof; but we take special care to do so in a way that maintains the associativity of the main grammar combination operator, in contrast to some earlier approaches (Sygal and Wintner 2009). Debusmann, Duchier, and Rossberg (2005) introduce Extensible Dependency Grammar (XDG), which is a general framework for dependency grammars that supports modular grammar design. An XDG grammar consists of dimensions, principles, and</context>
</contexts>
<marker>Perrier, 2000</marker>
<rawString>Perrier, Guy. 2000. Interaction grammars. In Proceedings of the 18th Conference on Computational Linguistics (COLING 2000), pages 600–606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press and CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="2983" citStr="Pollard and Sag 1994" startWordPosition="413" endWordPosition="416">aifa, Israel. E-mail: yael.sygal®gmail.com. ** Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly®cs.haifa.ac.il. Submission received: 3 June 2009; revised submission received: 21 June 2010; accepted for publication: 14 September 2010. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 1 Group 2001; Oepen et al. 2002; Hinrichs, Meurers, and Wintner 2004; Bender et al. 2005; King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi, Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and XDG (Debusmann, Duchier, and Rossberg 2005). Grammar development is a complex enterprise: It is not unusual for a single grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen et al. 2000) and may include thousands of types (Copestake and Flickinger 2000). Modern grammars are written in grammatical formalisms that are often reminiscent of very-high-level, declarative (mostly logical) programming languages, and are </context>
<context position="5454" citStr="Pollard and Sag (1994)" startWordPosition="787" endWordPosition="790">approaches with respect to these desiderata. Much of the information in typed unification grammars is encoded in the signature, and hence the key is facilitating a modularized development of type signatures. In Section 2 we introduce a definition of signature modules, and show how two signature modules combine and how the resulting signature module can be extended to a stand-alone type signature. We lift our definitions from signatures to full grammar modules in Section 3. In Section 4 we use signature modules and their combination operators to work out a modular design of the HPSG grammar of Pollard and Sag (1994), demonstrating the utility of signature modules for the development of linguistically motivated grammars. We then outline MODALS, an implementation of our solutions which supports modular development of type signatures in the context of both ALE and TRALE (Section 5). We show in Section 6 how our solution complies with the desiderata of Section 1.1, and conclude with directions for future research. 1.1 Motivation The motivation for modular grammar development is straightforward. Like software development, large-scale grammar development is much simpler when the task can be cleanly distributed</context>
<context position="79931" citStr="Pollard and Sag (1994)" startWordPosition="13144" endWordPosition="13147">onservative. 59 Computational Linguistics Volume 37, Number 1 Figure 15 The main fragments of the signature. Figure 16 A signature module, Sign. Finally, grammar modules are extended to bona fide typed unification grammars by extending the underlying signature module into an ordinary type signature and adjusting the grammar accordingly.10 4. Modular Construction of the Basic HPSG Signature To demonstrate the utility of signature modules for practical grammar engineering we use signature modules and their combination operators in this section to work out a modular design of the HPSG grammar of Pollard and Sag (1994). This is a grammar of English whose signature, covering several aspects of syntax and semantics, is developed throughout the book. The signature is given (Pollard and Sag 1994, Appendix A1) as one unit, making it very hard to conceptualize and, therefore, to implement and maintain. We reverse-engineered this signature, breaking it up into smaller-scale modules that emphasize fragments of the theory that are more local, and the interactions among such fragments through ‘merge’ and ‘attachment’.11 Some of the fragments make use of the signature module List of Figure 11. 10 In practice, an extra</context>
<context position="84324" citStr="Pollard and Sag (1994)" startWordPosition="13836" endWordPosition="13839"> Synsem) and unifies the information in the two modules. Then, Cat(List(Synsem)) unifies the information in the three modules and instantiates the node synsem list in the module Cat. Finally, all the information from the different modules is unified through the merge operation. Other modules can be added, either by merge or by attachment. Additionally, the internal structure of each module can be locally modified. Such changes become much easier given the smaller size and theoretical focus of each of the modules. This modular approach has significant advantages over the monolithic approach of Pollard and Sag (1994): The signature of Pollard and Sag is hard to conceptualize 63 Computational Linguistics Volume 37, Number 1 because all the information is presented in a single hierarchy. In contrast, looking at each small fragment (module) separately, it is easier to understand the information encoded in the module. Contemporary type signatures are in fact much larger; working with small fragments in such grammars is instrumental for avoiding or tracking errors. Moreover, grammar maintenance is significantly simplified, because changes can be done locally, at the level of specific modules. Of course, when a</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, Carl and Ivan A. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press and CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>Modular grammar engineering in GF.</title>
<date>2007</date>
<journal>Research on Language and Computation,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="25556" citStr="Ranta 2007" startWordPosition="3835" endWordPosition="3836">eraction among modules through parameters is used to construct a multigraph in which some of the nodes are identified. In our approach, however, the type system is part of the grammar specification, and modules are combined via explicit combination operations. In contrast, in XDG the type mechanism is used externally, to describe objects, and a general description logic is used to impose constraints. Another major difference has to do with expressive power: Whereas unification grammars are Turing-equivalent, XDG is probably mildly contextsensitive (Debusmann 2006). The grammar formalism (GF) (Ranta 2007) is a typed functional programming language designed for multilingual grammars. Ranta introduces a module system for GF where a module can be either one of three kinds: abstract, concrete, or a resource module. Each of them reflects the kind of data this module may include. A module of type abstract includes abstract syntax trees which represent grammatical information, such as semantic or syntactic data. A module of type concrete includes relations between trees in the abstract module and relations between strings in the target language. Communication between modules of these two types is car</context>
</contexts>
<marker>Ranta, 2007</marker>
<rawString>Ranta, Aarne. 2007. Modular grammar engineering in GF. Research on Language and Computation, 5(2):133–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Sygal</author>
<author>Shuly Wintner</author>
</authors>
<title>Type signature modules.</title>
<date>2008</date>
<booktitle>Proceedings of FG 2008: The 13th Conference on Formal Grammar,</booktitle>
<pages>113--128</pages>
<editor>In Philippe de Groote, editor,</editor>
<contexts>
<context position="6298" citStr="Sygal and Wintner (2008)" startWordPosition="908" endWordPosition="911">in the context of both ALE and TRALE (Section 5). We show in Section 6 how our solution complies with the desiderata of Section 1.1, and conclude with directions for future research. 1.1 Motivation The motivation for modular grammar development is straightforward. Like software development, large-scale grammar development is much simpler when the task can be cleanly distributed among different developers, provided that well-defined interfaces govern the interaction among modules. From a theoretical point of view, modularity 1 This article extends and revises Cohen-Sygal and Wintner (2006) and Sygal and Wintner (2008). 30 Sygal and Wintner Modular Typed Unification Grammars facilitates the definition of cleaner semantics for the underlying formalism and the construction of correctness proofs. The engineering benefits of modularity in programming languages are summarized by Mitchell (2003, page 235), and are equally valid for grammar construction: In an effective design, each module can be designed and tested independently. Two important goals in modularity are to allow one module to be written with little knowledge of the code in another module and to allow a module to be redesigned and re-implemented with</context>
</contexts>
<marker>Sygal, Wintner, 2008</marker>
<rawString>Sygal, Yael and Shuly Wintner. 2008. Type signature modules. In Philippe de Groote, editor, Proceedings of FG 2008: The 13th Conference on Formal Grammar, pages 113–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Sygal</author>
<author>Shuly Wintner</author>
</authors>
<title>Associative grammar combination operators for tree-based grammars.</title>
<date>2009</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>18</volume>
<issue>3</issue>
<contexts>
<context position="23148" citStr="Sygal and Wintner 2009" startWordPosition="3471" endWordPosition="3474">tation of tree descriptions), there can be various ways to refer to nodes in the trees in order to control the possible combination of grammar modules. Several mechanisms have been suggested to facilitate reference across modules (Candito 1996; Perrier 2000; Crabb´e and Duchier 2004; Kahane 2006). The solution that we propose here embraces the idea of moving from concrete objects (e.g., a concrete type signature) to descriptions thereof; but we take special care to do so in a way that maintains the associativity of the main grammar combination operator, in contrast to some earlier approaches (Sygal and Wintner 2009). Debusmann, Duchier, and Rossberg (2005) introduce Extensible Dependency Grammar (XDG), which is a general framework for dependency grammars that supports modular grammar design. An XDG grammar consists of dimensions, principles, and a lexicon; it characterizes a set of well-formed analyses. Each dimension is an attributed labeled graph, and when a grammar consists of multiple dimensions (e.g., multigraphs), they share the same set of nodes. A lexicon for a dimension is a set of total assignments of nodes and labels. The main mechanism XDG uses to control analyses are principles, that can be </context>
<context position="54121" citStr="Sygal and Wintner 2009" startWordPosition="8688" endWordPosition="8691">that the merge operation is defined by set union and equivalence relations which are commutative operations. Proposition 2 Merge is associative up to isomorphism:6 for all S1, S2, S3, Let S = (S1 (W S2) U S3 and S&apos; = S1 U (S2 (W S3) where P, P~ are their underlying PSSs, respectively. Then P ∼ P&apos;. 6 The definition of signature module isomorphism is a simple extension of graph isomorphism; see the Appendix for more details. 48 Sygal and Wintner Modular Typed Unification Grammars The proof of associativity is similar in spirit to the proof of the associativity of (polarized) forest combination (Sygal and Wintner 2009) and is therefore suppressed. 2.4.3 Attachment. Consider again S1 and S9, the signature modules of Figures 1 and 7, respectively. S1 stipulates two distinct (but anonymous) values for Approp(n, AGR) and Approp(v, AGR). S9 stipulates two nodes, typed nagr and vagr, with the intention that these nodes be coalesced with the two anonymous nodes of S1. However, the ‘merge’ operation defined in the previous section cannot achieve this goal, since the two anonymous nodes in S1 have different attributes from their corresponding typed nodes in S9. In order to support such a unification of nodes we need</context>
</contexts>
<marker>Sygal, Wintner, 2009</marker>
<rawString>Sygal, Yael and Shuly Wintner. 2009. Associative grammar combination operators for tree-based grammars. Journal of Logic, Language and Information, 18(3):293–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
</authors>
<title>Using descriptions of trees in a tree adjoining grammar.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<marker>Vijay-Shanker, 1992</marker>
<rawString>Vijay-Shanker, K. 1992. Using descriptions of trees in a tree adjoining grammar. Computational Linguistics, 18(4):481–517.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuly Wintner</author>
</authors>
<title>Modular context-free grammars.</title>
<date>2002</date>
<journal>Grammars,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="20831" citStr="Wintner (2002)" startWordPosition="3107" endWordPosition="3108">ten pieces of code which the grammar designer does not develop and whose interaction he or she has little control over. 1.2.4 Modularity in Related Formalisms. The previously mentioned works emphasize the fact that existing approaches to modular grammar development in the area of unification grammars are still insufficient. The same problem has also been addressed in some 34 Sygal and Wintner Modular Typed Unification Grammars other, related, formalisms; we now survey such works and discuss the applicability of the proposed solutions to the problem of modularity in typed unification grammars. Wintner (2002) defines the concept of modules for CFGs: The set of nonterminals is partitioned into three disjoint classes of internal, exported, and imported elements. The imported elements are those that are supplied to the module by other modules, the exported elements are those it provides to the outside world, and the internal ones are local to it. Two modules can be combined only if the set of internal elements of each module is disjoint from the exported and imported sets of the other module as well as if the exported sets are disjoint. Then the combination of two modules is done by simple measures o</context>
</contexts>
<marker>Wintner, 2002</marker>
<rawString>Wintner, Shuly. 2002. Modular context-free grammars. Grammars, 5(1):41–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuly Wintner</author>
<author>Alon Lavie</author>
<author>Brian MacWhinney</author>
</authors>
<title>Formal grammars of early language.</title>
<date>2009</date>
<booktitle>Languages: From Formal to Natural,</booktitle>
<volume>5533</volume>
<pages>204--227</pages>
<editor>In Orna Grumberg, Michael Kaminski, Shmuel Katz, and Shuly Wintner, editors,</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin and Heidelberg,</location>
<marker>Wintner, Lavie, MacWhinney, 2009</marker>
<rawString>Wintner, Shuly, Alon Lavie, and Brian MacWhinney. 2009. Formal grammars of early language. In Orna Grumberg, Michael Kaminski, Shmuel Katz, and Shuly Wintner, editors, Languages: From Formal to Natural, volume 5533 of Lecture Notes in Computer Science. Springer Verlag, Berlin and Heidelberg, pages 204–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>XTAG Research Group</author>
</authors>
<title>A lexicalized tree adjoining grammar for English.</title>
<date>2001</date>
<tech>Technical Report IRCS-01-03,</tech>
<institution>IRCS, University of Pennsylvania.</institution>
<contexts>
<context position="2740" citStr="Group 2001" startWordPosition="377" endWordPosition="378">as machine translation, speech generation, and so on. Wide-coverage grammars are being developed for various languages (Abeill´e, Candito, and Kinyon 2000; XTAG Research * Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: yael.sygal®gmail.com. ** Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly®cs.haifa.ac.il. Submission received: 3 June 2009; revised submission received: 21 June 2010; accepted for publication: 14 September 2010. © 2011 Association for Computational Linguistics Computational Linguistics Volume 37, Number 1 Group 2001; Oepen et al. 2002; Hinrichs, Meurers, and Wintner 2004; Bender et al. 2005; King et al. 2005; M¨uller 2007) in several theoretical frameworks, including TAG (Joshi, Levy, and Takahashi 1975), LFG (Dalrymple 2001), HPSG (Pollard and Sag 1994), and XDG (Debusmann, Duchier, and Rossberg 2005). Grammar development is a complex enterprise: It is not unusual for a single grammar to be developed by a team including several linguists, computational linguists, and computer scientists. The scale of grammars is overwhelming—large-scale grammars can be made up by tens of thousands of line of code (Oepen</context>
<context position="21853" citStr="Group 2001" startWordPosition="3274" endWordPosition="3275">ch module is disjoint from the exported and imported sets of the other module as well as if the exported sets are disjoint. Then the combination of two modules is done by simple measures of set union. This is the infrastructure underlying the definition of modular HPSG discussed earlier (Keselj 2001). Provisions for modularity have also been discussed in the context of tree-adjoining grammars (TAG) (Joshi, Levy, and Takahashi 1975). A wide-coverage TAG may contain hundreds or even thousands of elementary trees, and syntactic structure can be redundantly repeated in many of them (XTAG Research Group 2001; Abeill´e, Candito, and Kinyon 2000). Consequently, maintenance and extension of such grammars is a complex task. To address these issues, several high-level formalisms were developed (VijayShanker 1992; Candito 1996; Duchier and Gardent 1999; Kallmeyer 2001). These formalisms take the metagrammar approach, where the basic units are tree descriptions (i.e., formulas denoting sets of trees) rather than trees. Tree descriptions are constructed by a tree logic and combined through conjunction or inheritance; a module in this approach is merely a tree description, and modules are combined by mean</context>
</contexts>
<marker>Group, 2001</marker>
<rawString>XTAG Research Group. 2001. A lexicalized tree adjoining grammar for English. Technical Report IRCS-01-03, IRCS, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R´emi Zajac</author>
<author>Jan W Amtrup</author>
</authors>
<title>Modular unification-based parsers.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT</booktitle>
<pages>278--288</pages>
<location>Trento.</location>
<contexts>
<context position="15287" citStr="Zajac and Amtrup (2000)" startWordPosition="2243" endWordPosition="2246">nder their corresponding attributes in the rules and the lexicon) for the semantic and syntactic parsers, respectively. This proposal requires that a single grammar be given, from which the two components can be derived. A more significant disadvantage of this method is that coreferences between syntax and semantics are lost during this division (because reentrancies that represent the connection between the syntax and the semantics are removed). Kasper and Krieger observe that the intersection of the languages generated by the two grammars does not yield the language of the original grammar. Zajac and Amtrup (2000) present an implementation of a pipeline-like composition operator that enables the grammar designer to break a grammar into sub-grammars that are applied in a sequential manner at run-time. Such an organization is especially useful for dividing the development process into stages that correspond to morphological processing, syntax, semantics, and so on. The notion of composition here is such that sub-grammar Gi+1 operates on the output of sub-grammar Gi; such an organization might not be suitable for all grammar development frameworks. A similar idea is proposed by Basili, Pazienza, and Zanzo</context>
</contexts>
<marker>Zajac, Amtrup, 2000</marker>
<rawString>Zajac, R´emi and Jan W. Amtrup. 2000. Modular unification-based parsers. In Proceedings of the Sixth International Workshop on Parsing Technologies (IWPT 2000), pages 278–288, Trento.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>