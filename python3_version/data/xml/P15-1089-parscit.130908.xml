<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000028">
<title confidence="0.990636">
Tweet Normalization with Syllables
</title>
<author confidence="0.975393">
Ke Xu
</author>
<affiliation confidence="0.8275045">
School of Software Eng.
Beijing U. of Posts &amp; Telecom.
</affiliation>
<address confidence="0.437716">
Beijing 100876, China
</address>
<email confidence="0.968065">
xxukez2@gmail.com
</email>
<note confidence="0.62498625">
Yunqing Xia
STCA
Microsoft
Beijing 100084, China
</note>
<email confidence="0.975969">
yxia@microsoft.com
</email>
<author confidence="0.96966">
Chin-Hui Lee
</author>
<affiliation confidence="0.9915105">
School of Electr. &amp; Comp. Eng.
Georgia Institute of Technology
</affiliation>
<address confidence="0.924152">
Atlanta, GA 30332-0250, USA
</address>
<email confidence="0.99831">
chl@ece.gatech.edu
</email>
<sectionHeader confidence="0.993874" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999891269230769">
In this paper, we propose a syllable-based
method for tweet normalization to study
the cognitive process of non-standard
word creation in social media. Assuming
that syllable plays a fundamental role in
forming the non-standard tweet words,
we choose syllable as the basic unit and
extend the conventional noisy channel
model by incorporating the syllables to
represent the word-to-word transitions
at both word and syllable levels. The
syllables are used in our method not
only to suggest more candidates, but also
to measure similarity between words.
Novelty of this work is three-fold: First,
to the best of our knowledge, this is an
early attempt to explore syllables in tweet
normalization. Second, our proposed
normalization method relies on unlabeled
samples, making it much easier to adapt
our method to handle non-standard words
in any period of history. And third, we
conduct a series of experiments and prove
that the proposed method is advantageous
over the state-of-art solutions for tweet
normalization.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974730769231">
Due to the casual nature of social media, there
exists a large number of non-standard words in
text expressions which make it substantially dif-
ferent from formal written text. It is reported in
(Liu et al., 2011) that more than 4 million dis-
tinct out-of-vocabulary (OOV) tokens are found
in the Edinburgh Twitter corpus (Petrovic et al.,
2010). This variation poses challenges when
performing natural language processing (NLP)
tasks (Sproat et al., 2001) based on such texts.
Tweet normalization, aiming at converting these
OOV non-standard words into their in-vocabulary
(IV) formal forms, is therefore viewed as a very
important pre-processing task.
Researchers focus their studies in tweet normal-
ization at different levels. A character-level tag-
ging system is used in (Pennell and Liu, 2010) to
solve deletion-based abbreviation. It was further
extended in (Liu et al., 2012) using more charac-
ters instead of Y or N as labels. The character-level
machine translation (MT) approach (Pennell and
Liu, 2011) was modified in (Li and Liu, 2012a)
into character-block. While a string edit distance
method was introduced in (Contractor et al., 2010)
to represent word-level similarity, and this ortho-
graphical feature has been adopted in (Han and
Baldwin, 2011), and (Yang and Eisenstein, 2013).
Challenges are encountered in these different
levels of tweet normalization. In the character-
level sequential labeling systems, features are re-
quired for every character and their combinations,
leading to much more noise into the later reverse
table look-up process (Liu et al., 2012). In the
character-block level MT systems equal number of
blocks and their corresponding phonetic symbols
are required for alignment (Li and Liu, 2012b).
This strict restriction can result in a great difficulty
in training set construction and a loss of useful
information. Finally, word-level normalization
methods cannot properly model how non-standard
words are formed, and some patterns or consisten-
cies within words can be omitted and altered.
We observe the cognitive process that, given
non-standard words like tmr, people tend to first
segment them into syllables like t-m-r. Then
they will find the corresponding standard word
with syllables like to-mor-row. Inspired by
this cognitive observation, we propose a syllable
based tweet normalization method, in which non-
standard words are first segmented into syllables.
Since we cannot predict the writers deterministic
intention in using tmr as a segmentation of tm-r
</bodyText>
<page confidence="0.941089">
920
</page>
<note confidence="0.976953">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 920–928,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999900787878788">
(representing tim-er) or t-m-r (representing
to-mor-row), every possible segmentation for-
m is considered. Then we represent similarity
of standard syllables and non-standard syllables
using an exponential potential function. After
every transition probabilities of standard syllable
and non-standard syllable are assigned, we then
use noisy channel model and Viterbi decoder to
search for the most possible standard candidate in
each tweet sentence.
Our empirical study reveals that syllable is a
proper level for tweet normalization. The syllable
is similar to character-block but it represents pho-
netic features naturally because every word is pro-
nounced with syllables. Our syllable-based tweet
normalization method utilizes effective features of
both character- and word-level: (1) Like character-
level, it can capture more detailed information
about how non-standard words are generated; (2)
Similar to word-level, it reduces a large amount of
noisy candidates. Instead of using domain-specific
resources, our method makes good use of standard
words to extract linguistic features. This makes
our method extendable to new normalization tasks
or domains.
The rest of this paper is organized as follows:
previous work in tweet normalization are reviewed
and discussed in Section 2. Our approach is
presented in Section 3. In Section 4 and Section 5,
we provide implementation details and results.
Then we make some analysis of the results in
Section 6. This work is finally concluded in
Section 7.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9996924">
Non-standard words exhibit different forms and
change rapidly, but people can still figure out
their original standard words. To properly model
this human ability, researchers are studying what
remain unchanged under this dynamic character-
istic. Human normalization of an non-standard
word can be as follows: After realizing the word is
non-standard, people usually first figure out stan-
dard candidate words in various manners. Then
they replace the non-standard words with the stan-
dard candidates in the sentence to check whether
the sentence can carry a meaning. If not, they
switch to a different candidate until a good one is
found. Most normalization methods in existence
follow the same procedure: candidates are first
generated, and then put into the sentence to check
whether a reasonable sentence can be formed.
Differences lie in how the candidates are generated
and weighted. Related work can be classified into
three groups.
</bodyText>
<subsectionHeader confidence="0.997014">
2.1 Orthographical similarity
</subsectionHeader>
<bodyText confidence="0.999987882352941">
Orthographical similarity is built upon the as-
sumption that the non-standard words look like its
standard counterparts, leading to a high Longest
Common Sequence (LCS) and low Edit Distance
(ED). This method is widely used in spell checker,
in which the LCS and ED scores are calculat-
ed for weighting possible candidates. However,
problems are that the correct word cannot always
be the most looked like one. Taking the non-
standard word nite for example, note looks
more likely than the correct form night. To
overcome this problem, an exception dictionary
of strongly-associated word pairs are constructed
in (Gouws et al., 2011). Further, these pairs are
added into a unified log-linear model in (Yang
and Eisenstein, 2013) and Monte Carlo sampling
techniques are used to estimate parameters.
</bodyText>
<subsectionHeader confidence="0.999418">
2.2 Phonetic similarity
</subsectionHeader>
<bodyText confidence="0.999615117647059">
The assumption underlying the phonetic similarity
is that during transition, non-standard words sound
like the standard counterparts, thus the pronunci-
ation of non-standard words can be traced back
to a standard dictionary. The challenge is the
algorithm to annotate pronunciation of the non-
standard words. Double Metaphone algorithm
(Philips, 2000) is used to decode pronunciation
and then to represent phonetic similarity by edit
distance of these transcripts (Han and Baldwin,
2011). IPA symbols are utilized in (Li and Liu,
2012b) to represent sound of words and then word
alignment-based machine translation is applied to
generate possible pronunciation of non-standard
words. And also, phoneme is used in (Liu et al.,
2012) as one kind of features to train their CRF
model.
</bodyText>
<subsectionHeader confidence="0.99953">
2.3 Contextual similarity
</subsectionHeader>
<bodyText confidence="0.999937">
It is accepted that after standard words are trans-
formed into non-standard words, the meaning of a
sentence remains unchanged. So the normalized
standard word must carry a meaning. Most re-
searchers use n-gram language model to normal-
ize a sentence, and several researches use more
contextual information. For example, training
pairs are generated in (Liu et al., 2012) by a
</bodyText>
<page confidence="0.996339">
921
</page>
<bodyText confidence="0.999974705882353">
cosine contextual similarity formula whose items
are defined by TF-IDF scheme. A bipartite graph
is constructed in (Hassan and Menezes, 2013) to
represent tokens (both non-standard and standard
words) and their context. Thus, random walks
on the graph can represent contextual-similarity
between non-standard and standard words. Very
recently, word-embedding (Mikolov et al., 2010;
Mikolov et al., 2013) is utilized in (Li and Liu,
2014) to represent more complex contextual rela-
tionship.
In word-to-word candidate selection, most re-
searches use orthographical similarity and phonet-
ic similarity separately. In the log-linear model
(Yang and Eisenstein, 2013), edit distance is mod-
eled as major feature. In the character- and phone-
based approaches (Li and Liu, 2012b), ortho-
graphical information and phonetic information
were treated separately to generate candidates.
In (Han and Baldwin, 2011), candidates from
lexical edit distance and phonemic edit distance
are merged together. Then an up to 16% increas-
ing recall was reported when adding candidates
from phonetic measure. But improper processing
level makes it difficult to model the two types of
information simultaneously: (1) Single character
can hardly reflect orthographical features of one
word. (2) As fine-grained reasonable restrictions
are lacked, as showed in (Han and Baldwin, 2011),
several times of candidates are included when
adding phonetic candidates and this will bring
much more noise. To combine orthographical
and phonetic measure in a fine-grained level, we
proposed the syllable-level approach.
</bodyText>
<sectionHeader confidence="0.990109" genericHeader="method">
3 Approach
</sectionHeader>
<subsectionHeader confidence="0.99093">
3.1 Framework
</subsectionHeader>
<bodyText confidence="0.999883666666667">
The framework of the proposed tweet normal-
ization method is presented in Figure 1. The
proposed method extends the basic HMM channel
model (Choudhury et al., 2007; Cook and Steven-
son, 2009) into syllable level. And the following
four characteristics are very intersting.
</bodyText>
<listItem confidence="0.651409428571428">
(1) Combination: When reading a sentence,
fast subvocalization will occur in our mind.
In the process, some non-standard words
generated by phonetic substitution are cor-
rectly pronounced and then normalized. And
also, because subvocalization is fast, people
tend to ignore some minor flaws in spelling
</listItem>
<bodyText confidence="0.860002">
intentionally or unintentionally. As this often
occurs in people’s real-life interacting with
these social media language, we believe the
combination of phonetic and orthographical
information is of great significance.
</bodyText>
<listItem confidence="0.99925980952381">
(2) Syllable level: Inspired by Chinese normal-
ization (Xia et al., 2006) using pinyin (pho-
netic transcripts of Chinese), syllable can be
seen as basic unit when processing pronunci-
ation. Different from mono-syllable Chinese
words, English words can be multi-syllable;
this will bring changes in our method that
extra layers of syllables must be put into
consideration. Thus, apart from word-based
noisy-channel model, we extend it into a
syllable-level framework.
(3) Priori knowledge: Priori knowledge is ac-
quired from standard words, meaning that
both standard syllabification and pronunci-
ation can shed some lights to non-standard
words. This assumption makes it possible
to obtain non-standard syllables by standard
syllabification and gain pronunciation of syl-
lables by standard words and rules generated
with them.
(4) General patterns: Social media language
</listItem>
<bodyText confidence="0.8398437">
changes rapidly while labeled data is ex-
pensive thus limited. To effectively solve
the problem, linguistic features instead of
statistical features should be emphasized. We
exploit standard words of their syllables, pro-
nunciation and possible transition pattern-
s and proposed the four-layer HMM-based
model (see Figure 1).
In our method, non-standard words ci are first
segmented into syllables sc(1)
</bodyText>
<equation confidence="0.70725">
i ... sc(k)
</equation>
<bodyText confidence="0.801293714285714">
i , and for
standard syllable sw(j)
i mapping to non-standard
syllable sw(j)
i , we calculate their similarity by
combining the orthographical and phonetic mea-
sures. Standard syllables sw(1)
</bodyText>
<equation confidence="0.573748">
i ... sw(k)
i make
</equation>
<bodyText confidence="0.9993638">
up one standard candidates. Since candidates
are generated and weighted, we can use Viterbi
decoder to perform sentence normalization. Ta-
ble 1 shows some possible candidates for the non-
standard word tmr.
</bodyText>
<subsectionHeader confidence="0.999244">
3.2 Method
</subsectionHeader>
<bodyText confidence="0.9999955">
We extend the noisy channel model to syllable-
level as follows:
</bodyText>
<page confidence="0.959437">
922
</page>
<figure confidence="0.99628025">
Formal
words
Formal word
syllables
Informal word
syllables
Informal
words
</figure>
<figureCaption confidence="0.999973">
Figure 1: Framework of the propose tweet normalization method.
</figureCaption>
<equation confidence="0.981677">
w� = argmax p(w|c)
= argmax p(c|w) x p(w) (1)
= argmax p(~sc |~sw) x p( ~sw),
</equation>
<bodyText confidence="0.99976475">
where w indicates the standard word and c the
non-standard word, and sw and sc represent their
syllabic form, respectively. To simplify the prob-
lem, we restrict the number of standard syllables
equals to the number of non-standard syllables in
our method.
Assuming that syllables are independent of each
other in transforming, we obtain:
</bodyText>
<equation confidence="0.995444333333333">
k
p(~sc |~sw) = H p(scj|swj). (2)
j=1
</equation>
<bodyText confidence="0.976137272727273">
For syllable similarity, we use an exponential
potential function to combine orthographical dis-
tance and phonetic distance. Because pronun-
ciation can be represented using letter-to-phone
transcripts, we can treat string similarity of these
tmr t-mr tm-r t-m-r
tamer ta-mer tim-er to-mor-row
ti-mor tim-ber tri-mes-ter
ti-more ton-er tor-men-tor
tu-mor tem-per ta-ma-ra
. . . . . . . . .
</bodyText>
<tableCaption confidence="0.767177">
Table 1: Standard candidates of tmr in syllable lev-
</tableCaption>
<bodyText confidence="0.969142">
el. The first row gives the different segmentations
and the second row presents the candidates.
transcripts as phonetic similarity. Thus the sylla-
ble similarity can be calculated as follows.
</bodyText>
<equation confidence="0.990202">
p(scj|swj,λ) = Φ(Z(swj)�) (3)
Z(swj) = � Φ(scj, swj) (4)
scj
Φ(sc, sw) = exp(λ(LCS(sc, sw) − ED(sc, sw))
+(1 − λ)(PLCS(sc, sw) − PED(sc, sw)))
(5)
</equation>
<bodyText confidence="0.995556684210527">
Exponential function grows tremendously as its
argument increases, so much more weight can be
assigned if syllables are more similar. The param-
eter λ here is used to empirically adjust relative
contribution of letters and sounds. Longest com-
mon sequence (LCS) and edit distance (ED) are
used to measure orthographical similarity, while
phonetic longest common sequence (PLCS) and
phonetic edit distant (PED) are used to measure
phonetic similarity but based on letter-to-sound
transcripts. The PLCS are defined as basic LCS
but PED here is slightly different.
When performing phonetic similarity calcula-
tion based on syllables, we follow (Xia et al.,
2006) in treating consonant and vowels separate-
ly because transition of consonants can make a
totally different pronunciation. So if consonants
of scj and swj are exactly the same or fit rules
listed in Table 2, PED(scj, swj) equals to edit
</bodyText>
<page confidence="0.988181">
923
</page>
<table confidence="0.619675">
Description Rules Examples
</table>
<listItem confidence="0.9130435">
1. -ng as suffix: g-dropping -n/-ng do-in/do-ing, go-in/go-ing, talk-in/talk-ing, mak-in/mak-ing
2. -ng as suffix: n-dropping -g/-ng tak-ig/tak-ing, likig/lik-ing
3. suffix: z/s equaling -z/-s, -s/-z jamz/james, plz/please
4. suffix: n/m equaling -m/-n, -n/-m in-portant/im-portant, get-tim/get-ting
5. suffix: t/d equaling -t/-d, -d/-t shid/shit, shult/should
6. suffix: t-dropping -/-t jus/just, wha/what, mus/must, ain/ain’t
7. suffix: r-dropping -/-r holla/holler, t-m-r/tomorrow
8. prefix: th-/d- equaling d-/th-, th-/d- de/the, dat/that, dats/that’s, dey/they
</listItem>
<tableCaption confidence="0.993764">
Table 2: The consonant rules.
</tableCaption>
<bodyText confidence="0.999733916666667">
distance of letter-to-phone transcripts, or it will
be assigned infinity to indicate that their pronun-
ciation are so different that this transition can
seldom happen. For example, as consonantal
transition between suffix z and s can always
happen, PED(plz,please) equals string edit
distance of their transcripts. But as consonatal
transition of f and d is rare, phonetic distance
of fly and sky is assigned infinity. Note the
consonant rules in Table 2 are manually defined
in our empirical study, which represent the most
commonly used ones.
</bodyText>
<subsectionHeader confidence="0.980348">
3.3 Parameter
</subsectionHeader>
<bodyText confidence="0.999994">
Parameter in the proposed method is only the
λ in Equation (5), which represents the rela-
tive contribution of orthographical similarity and
phonetic similarity. Because the limited number
of annotated corpus, we have to enumerate the
parameter in {0, 0.1, 0.2, ..., 1} in the experiment
to find the optimal setting.
</bodyText>
<sectionHeader confidence="0.998847" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.999923">
The method described in the previous section are
implemented with the following details.
</bodyText>
<subsectionHeader confidence="0.990903">
4.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.9974165">
Before performing normalization, we need to pro-
cess several types of non-standard words:
</bodyText>
<listItem confidence="0.997296888888889">
• Words containing numbers: People usually
substitute some kind of sounds with number-
s like 4/four, 2/two and 8/eight or
numbers can be replacement of some letters
like 1/i, 4/a. So we replace numbers with
its words or characters and then use them to
generate possible candidates.
• Words with repeating letters: As our
method is syllable-based, repeating letters
</listItem>
<bodyText confidence="0.998756714285714">
for sentiment expressing (like cooool,
(Brody and Diakopoulos, 2011)) can cause
syllabifying failure. For repeating letters, we
reduce it to both two and one to generate
candidate separately. Then the two lists are
merged together to form the whole candidate
list.
</bodyText>
<subsectionHeader confidence="0.930228">
4.2 Letter-to-sound conversion
</subsectionHeader>
<bodyText confidence="0.978132">
Syllable in this work refers to orthographic sylla-
bles. For example, we convert word tomorrow
into to-mor-row. However, when comparing
the syllable of a standard word and that of a non-
standard word, sound (i.e., phones) of the syllables
are considered. Thus letter-to-sound conversion
tools are required.
Several TTS system can perform the task ac-
cording to some linguistic rules, even for non-
standard words. The Double Metaphone algorith-
m used in (Han and Baldwin, 2011) is one of
them. But it uses consonants to encode a word,
which gives less information than we need. In our
method, we use freeTTS (Walker et al., 2002) with
CMU lexicon1 to transform words into APRA-
bet2 symbols. For example, word tomorrow is
transcribed to {T-UW M-AA R-OW} and tmr to
{T M R}.
</bodyText>
<subsectionHeader confidence="0.83541">
4.3 Dictionary preparation
</subsectionHeader>
<listItem confidence="0.933757">
• Dictionary #1: In-vocabulary (IV) words
</listItem>
<bodyText confidence="0.945573142857143">
Following (Yang and Eisenstein, 2013), our
set of IV words is also based on the GNU as-
pell dictionary (v0.60.6). Differently, we use
a collection of 100 million tweets (roughly
the same size of Edinburgh Twitter corpus)
because the Edinburgh Twitter corpus is no
longer available due to Twitter policies. The
</bodyText>
<footnote confidence="0.9999505">
1http://www.speech.cs.cmu.edu/cgi-bin/cmudict
2http://en.wikipedia.org/wiki/Arpabet
</footnote>
<page confidence="0.99743">
924
</page>
<bodyText confidence="0.986106">
final IV dictionary contains 51,948 standard
words.
</bodyText>
<listItem confidence="0.9263765">
• Dictionary #2: Syllables for the standard
words
</listItem>
<bodyText confidence="0.99890275">
Following (Pennell and Liu, 2010), we use
the online dictionary3 to extract syllables
for each standard words. We encountered
same problem when accessing words with
prefixes or suffixes, which are not syllabified
in the same format as the base words on the
website. To address the issue, we simply
regard these prefixes and suffixes as syllables.
</bodyText>
<listItem confidence="0.9647545">
• Dictionary #3: Pronunciation of the sylla-
bles
</listItem>
<bodyText confidence="0.999711166666667">
Using the CMU pronouncing dictionary
(Weide, 1998) and dictionary 2, and knowing
all possible APRAbet symbol for all
consonant characters, we can program to
capture every possible pronunciation of all
syllables in the standard dictionary.
</bodyText>
<subsectionHeader confidence="0.7638435">
4.4 Automatic syllabification of non-standard
words
</subsectionHeader>
<bodyText confidence="0.999892285714286">
Automatic syllabification of non-standard words
is a supervised problem. A straightforward idea
is to train a CRF model on manually labeled
syllables of non-standard words. Unfortunately,
such a corpus is not available and very expensive
to produce.
We assume that both standard and non-standard
forms follow the same syllable rules (i.e., the
cognitive process). Thus we propose to train the
CRF model on the corpus of syllables of standard
words (which is easy to obtain) to construct an
automatic annotation system based on CRF++
(Kudo, 2005). In this work, we extract syllables
of standard words from Dictionary #2 as training
set. Annotations follow (Pennell and Liu, 2010) to
identify boundaries of syllables and in our work,
CRF++ can suggest several candidate solutions,
rather than an optimal segmentation solution for
syllable segmentation of the non-standard words.
In the HMM channel model, the candidate solu-
tions are included as part of the search space.
</bodyText>
<subsectionHeader confidence="0.961642">
4.5 Language model
</subsectionHeader>
<bodyText confidence="0.998457666666667">
Using Tweets from our corpus that contain no
OOV words besides hashtags and username men-
tions (following (Han and Baldwin, 2011)), the
</bodyText>
<footnote confidence="0.889566">
3http://www.dictionary.com
</footnote>
<bodyText confidence="0.999749833333333">
Kneser-Ney smoothed tri-gram language model is
estimated using SRILM toolkit (Stolcke, 2002).
Note that punctuations, hashtags, and username
mentions have some syntactic value (Kaufmann
and Kalita, 2010) to some extent, we replace them
with ’&lt;PUNCT&gt;’, ’&lt;TOPIC&gt;’ and ’&lt;USER&gt;’.
</bodyText>
<sectionHeader confidence="0.99681" genericHeader="method">
5 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.838454">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999618">
We use two labeled twitter datasets in existence to
evaluate our tweet normalization method.
</bodyText>
<listItem confidence="0.9232255">
• LexNorm1.1 contains 549 complete tweets
with 1184 non-standard tokens (558 unique
word type) (Han and Baldwin, 2011).
• LexNorm1.2 is a revised version of LexNor-
m1.1 (Yang and Eisenstein, 2013). Some
inconsistencies and errors in LexNorm1.1 are
corrected and some more non-standard words
are properly recovered.
</listItem>
<bodyText confidence="0.998697">
In both datasets, to-be-normalized non-standard
words are detected manually as well as the corre-
sponding standard words.
</bodyText>
<subsectionHeader confidence="0.999342">
5.2 Evaluation criteria
</subsectionHeader>
<bodyText confidence="0.999955090909091">
Here we use precision, recall and F-score to e-
valuate our method. As normalization methods
on these datasets focused on the labeled non-
standard words (Yang and Eisenstein, 2013), re-
call is the proportion of words requiring normal-
ization which are normalized correctly; precision
is the proportion of normalizations which are cor-
rect. When we perform the tweet normalization
methods, every error is both a false positive and
false negative, so in the task, precision equals to
recall.
</bodyText>
<subsectionHeader confidence="0.998896">
5.3 Sentence level normalization
</subsectionHeader>
<bodyText confidence="0.99515">
We choose the following prior normalization
methods:
</bodyText>
<listItem confidence="0.998754714285714">
• (Liu et al., 2012): the extended character-
level CRF tagging system;
• (Yang and Eisenstein, 2013): log-linear mod-
el using string edit distance and longest com-
mon sequence measures as major features;
• (Hassan and Menezes, 2013): bipartite graph
major exploit contextual similarity;
</listItem>
<page confidence="0.990429">
925
</page>
<table confidence="0.9836125">
Method Dataset Precision Recall F-measure
(Han and Baldwin, 2011) 75.30 75.30 75.30
(Liu et al., 2012) 84.13 78.38 81.15
(Hassan and Menezes, 2013) LexNorm 1.1 85.37 56.4 69.93
(Yang and Eisenstein, 2013) 82.09 82.09 82.09
Syllable-based method 85.30 85.30 85.30
(Yang and Eisenstein, 2013) LexNorm 1.2 82.06 82.06 82.06
Syllable-based method 86.08 86.08 86.08
</table>
<tableCaption confidence="0.999294">
Table 3: Experiment results of the tweet normalization methods.
</tableCaption>
<listItem confidence="0.909869666666667">
• (Han and Baldwin, 2011): the orthography-
phone combined system using lexical edit
distance and phonemic edit distance.
</listItem>
<bodyText confidence="0.999933709677419">
In our method, we set A=0.7 because it is
found best in our experiments (see Figure 2).
The experimental results are presented in Table 3,
which indicate that our method outperforms the
state-of-the-art methods. Details on how to adjust
parameter is given in Section 5.4.
Recall we argue that combination of three simi-
larity is necessary when performing sentence-level
normalization. Apart from contextual similarity
like language model or graphic model, methods
in (Yang and Eisenstein, 2013) or (Hassan and
Menezes, 2013) do not include phonetic measure,
causing loss of important phonetic information.
Though using phoneme, morpheme boundary and
syllable boundary as features (Liu et al., 2012), the
character-level reversed approach will bring much
more noise into the later reversed look-up table,
and also, features of whole word are omitted.
Like (Han and Baldwin, 2011), we also use
lexical measure and phonetic measure. Great
difference between the two approaches is the pro-
cessing level: word level and syllable level. In
their work, average candidates number suffers
times of increase when adding phonetic measure.
This is because when introducing phonemic edit
distance, important pronunciations can be altered
(phonemic edit distance of night-need and
night-kite is equal). Syllable level allows us
to reflect consistencies during transition in a finer-
grained level. Thus the phonetic similarity can be
more precisely modeled.
</bodyText>
<subsectionHeader confidence="0.999809">
5.4 Contributions of phone and orthography
</subsectionHeader>
<bodyText confidence="0.99984925">
In our method, the parameter A in Equation 5 is
used to represent the relatively contributions of
both phonetic and orthographical information. But
as the lack of prior knowledge, we cannot judge
an optimal A. We choose to conduct experiments
varying A = {0, 0.1, ...,1} to find out how this
adjustment can affect performance. The experi-
mental results are presented in Figure 2.
</bodyText>
<figure confidence="0.928294">
0 0.2 0.4 0.6 0.8 1
λ
</figure>
<figureCaption confidence="0.999942">
Figure 2: Contribution of phone and orthography.
</figureCaption>
<bodyText confidence="0.999969909090909">
As shown in Figure 2, when A is set 0 or 1(indi-
cating no contribution of either orthographical or
phonetic in assigning weight to candidates), our
method performs much worse. In our experiment,
when A = 0.7, the models performs best, showing
that orthographical measure makes relatively more
contribution over phonetic measure, but the latter
is indispensable. This justifies the effectiveness of
combining orthographical and phonetic measure,
indicating that human normalization process is
properly modeled.
</bodyText>
<sectionHeader confidence="0.9962" genericHeader="method">
6 Analysis
</sectionHeader>
<subsectionHeader confidence="0.998663">
6.1 Our exceptions
</subsectionHeader>
<bodyText confidence="0.99997725">
Deeper observation of our normalization results
shows that there are several types of exceptions
beyond our consonant-based rules. For example,
thanks fails to be selected as a candidate for the
non-standard word thx because the pronunciation
of thanks contains an N but thx does not.
The same situation happens when we process
stong/strong because of the lacking R. We
</bodyText>
<figure confidence="0.998271636363636">
0.87
0.86
0.85
LexNorm1.1
LexNorm1.2
0.8
F-measure
0.84
0.83
0.82
0.81
</figure>
<page confidence="0.990015">
926
</page>
<bodyText confidence="0.9733745">
believe some more consonant should be exploited
and more precisely described.
</bodyText>
<subsectionHeader confidence="0.892689">
6.2 Non-standard words involving multiple
syllables
</subsectionHeader>
<bodyText confidence="0.999992">
There are one type of transition that we
cannot solve like acc/accelerate and
bio/biology because the mapping is between
single-syllable word and multi-syllable word.
We add possible standard syllable sw(i)
</bodyText>
<sectionHeader confidence="0.905776" genericHeader="method">
0 and
</sectionHeader>
<bodyText confidence="0.990901833333333">
swk+1 to the head and tail of origin syllables,
(i)
but this extended form failed to be assigned high
probability because the string edit distances are
too large. We leave this problem for further
research.
</bodyText>
<subsectionHeader confidence="0.997768">
6.3 Annotation issue
</subsectionHeader>
<bodyText confidence="0.999991">
Though similar, our results of LexNorm1.2 is
better than LexNorm1.1. After scrutinizing, we
notice that several issues in LexNorm1.1 are fixed
in LexNorm1.2. So our results like meh/me
(meaning the non-standard word meh are correct-
ed to me) in LexNorm1.1 is wrong but in LexNor-
m1.2 is right. Even in LexNorm1.2, there exist
some inconsistencies and errors. For example,
our result buyed/bought is wrong for both
datasets, which is actually correct. For another
example, til is normalized to until in some
cases but to till in other cases. We show that the
LexNorm test corpus is still imperfect. We appeal
for systematic efforts to produce a standard dataset
under a widely-accepted guideline.
</bodyText>
<subsectionHeader confidence="0.981837">
6.4 Conventions
</subsectionHeader>
<bodyText confidence="0.999972111111111">
Social media language often contains words that
are culture-specific and widely used in daily life.
Some word like congrats, tv and pic are
included into several dictionaries. We also ob-
served several transitions like atl/atlanta or
wx/weather in the datasets. These kinds of
conventional abbreviations pose great difficulty
to us. Normalization of those conventional non-
standard words still needs further study.
</bodyText>
<sectionHeader confidence="0.998933" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999983928571429">
In this paper, a syllable-based tweet normalization
method is proposed for social media text normal-
ization. Results on publicly available standard
datasets justify our assumption that syllable plays
a fundamental role in social media non-standard
words. Advantage of our proposed method lies
in that syllable is viewed as the basic processing
unit and syllable-level similarity. This accords to
the human cognition in creating and understanding
the social non-standard words. Our method is
domain independent. It is robust on non-standard
words in any period of history. Furthermore, give
the syllable transcription tool, our method can be
easily adapted to a new language.
</bodyText>
<sectionHeader confidence="0.951973" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999899">
This research work was carried out when the
authors worked at Tsinghua University. We
acknowledge the financial support from Natural
Science Foundation of China (NSFC: 61272233,
61373056, 61433018). We thank the anonymous
reviewers for the insightful comments.
</bodyText>
<sectionHeader confidence="0.998743" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998241057142857">
Samuel Brody and Nicholas Diakopoulos. 2011.
Cooooooooooooooollllllllllllll! !!!!!!!!!!!!! using
word lengthening to detect sentiment in microblogs.
In EMNLP, pages 562–570. ACL.
Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh
Mukherjee, Sudeshna Sarkar, and Anupam Basu.
2007. Investigation and modeling of the structure
of texting language. International Journal of
Document Analysis and Recognition (IJDAR), 10(3-
4):157–174.
Danish Contractor, Tanveer A. Faruquie, and L. Venka-
ta Subramaniam. 2010. Unsupervised cleansing of
noisy text. In Chu-Ren Huang and Dan Jurafsky,
editors, COLING (Posters), pages 189–196. Chinese
Information Processing Society of China.
Paul Cook and Suzanne Stevenson. 2009. An
unsupervised model for text message normalization.
In CALC ’09: Proceedings of the Workshop on
Computational Approaches to Linguistic Creativity,
pages 71–78, Morristown, NJ, USA. Association for
Computational Linguistics.
Stephan Gouws, Dirk Hovy, and Donald Metzler.
2011. Unsupervised mining of lexical variants from
noisy text. In Proceedings of the First workshop
on Unsupervised Learning in NLP, pages 82–90.
Association for Computational Linguistics.
Bo Han and Timothy Baldwin. 2011. Lexical
normalisation of short text messages: Makn sens
a #twitter. In Dekang Lin, Yuji Matsumoto, and
Rada Mihalcea, editors, ACL, pages 368–378. The
Association for Computer Linguistics.
Hany Hassan and Arul Menezes. 2013. Social text
normalization using contextual graph random walks.
In ACL (1), pages 1577–1586. The Association for
Computer Linguistics.
</reference>
<page confidence="0.971408">
927
</page>
<reference confidence="0.999819325">
Max Kaufmann and Jugal Kalita. 2010. Syntactic
normalization of Twitter messages. In Interna-
tional conference on natural language processing,
Kharagpur, India.
Taku Kudo. 2005. Crf++: Yet another crf toolkit.
Software available at http://crfpp. sourceforge. net.
Chen Li and Yang Liu. 2012a. Improving text
normalization using character-blocks based models
and system combination. In COLING 2012, 24th
International Conference on Computational Lin-
guistics, Proceedings of the Conference: Technical
Papers, 8-15 December 2012, Mumbai, India, pages
1587–1602.
Chen Li and Yang Liu. 2012b. Normalization of text
messages using character- and phone-based machine
translation approaches. In INTERSPEECH. ISCA.
Chen Li and Yang Liu. 2014. Improving text normal-
ization via unsupervised model and discriminative
reranking. In Proceedings of the 52nd Annual
Meeting of the Association for Computational
Linguistics, ACL 2014, June 22-27, 2014, Baltimore,
MD, USA, Student Research Workshop, pages 86–
93.
Fei Liu, Fuliang Weng, Bingqing Wang, and Yang
Liu. 2011. Insertion, deletion, or substitu-
tion?: normalizing text messages without pre-
categorization nor supervision. In Proceedings
of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies: short papers-Volume 2, pages 71–76.
Association for Computational Linguistics.
Fei Liu, Fuliang Weng, and Xiao Jiang. 2012.
A broad-coverage normalization system for social
media language. In In Proceedings of ACL: Long
Papers-Volume 1, pages 1035–1044. Association for
Computational Linguistics.
Tom´aˇs Mikolov, Martin Karafi´at, Luk Burget, Jan
ernock, and Sanjeev Khudanpur. 2010. Recurrent
neural network based language model. In Inter-
speech, pages 1045–1048.
Tom´aˇs Mikolov, Kai Chen, Greg Corrado, and
Jeffrey Dean. 2013. Efficient estimation of
word representations in vector space. CoRR,
abs/1301.3781.
Deana Pennell and Yang Liu. 2010. Normalization of
text messages for text-to-speech. In ICASSP, pages
4842–4845. IEEE.
Deana Pennell and Yang Liu. 2011. A character-level
machine translation approach for normalization of
sms abbreviations. In IJCNLP, pages 974–982.
S. Petrovic, M. Osborne, and V. Lavrenko. 2010.
The edinburgh twitter corpus. In Proceedings
of the NAACL HLT Workshop on Computational
Linguistics in a World of Social Media, pages 25–
26.
Lawrence Philips. 2000. The double metaphone
search algorithm. C/C++ Users Journal, 18(5),
June.
Richard Sproat, Alan W. Black, Stanley F. Chen,
Shankar Kumar, Mari Ostendorf, and Christopher
Richards. 2001. Normalization of non-standard
words. Computer Speech &amp; Language, 15(3):287–
333.
Andreas Stolcke. 2002. Srilm-an extensible language
modeling toolkit. In Proceedings International
Conference on Spoken Language Processing, pages
257–286, November.
Willie Walker, Paul Lamere, and Philip Kwok. 2002.
Freetts: a performance case study.
Robert L Weide. 1998. The cmu pronouncing
dictionary. URL: http://www. speech. cs. cmu.
edu/cgibin/cmudict.
Yunqing Xia, Kam-Fai Wong, and Wenjie Li. 2006.
A phonetic-based approach to chinese chat text
normalization. In Nicoletta Calzolari, Claire Cardie,
and Pierre Isabelle, editors, ACL. The Association
for Computer Linguistics.
Yi Yang and Jacob Eisenstein. 2013. A log-linear
model for unsupervised text normalization. In
EMNLP, pages 61–72. ACL.
</reference>
<page confidence="0.996999">
928
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.146466">
<title confidence="0.999639">Tweet Normalization with Syllables</title>
<author confidence="0.97852">Ke</author>
<affiliation confidence="0.9470045">School of Software Beijing U. of Posts &amp;</affiliation>
<address confidence="0.8177">Beijing 100876,</address>
<email confidence="0.992803">xxukez2@gmail.com</email>
<affiliation confidence="0.234481">Yunqing</affiliation>
<address confidence="0.811689">Beijing 100084,</address>
<email confidence="0.998877">yxia@microsoft.com</email>
<author confidence="0.991436">Chin-Hui Lee</author>
<affiliation confidence="0.999523">School of Electr. &amp; Comp. Eng. Georgia Institute of Technology</affiliation>
<address confidence="0.999855">Atlanta, GA 30332-0250, USA</address>
<email confidence="0.999744">chl@ece.gatech.edu</email>
<abstract confidence="0.99752162962963">In this paper, we propose a syllable-based method for tweet normalization to study the cognitive process of non-standard word creation in social media. Assuming that syllable plays a fundamental role in forming the non-standard tweet words, we choose syllable as the basic unit and extend the conventional noisy channel model by incorporating the syllables to represent the word-to-word transitions at both word and syllable levels. The syllables are used in our method not only to suggest more candidates, but also to measure similarity between words. Novelty of this work is three-fold: First, to the best of our knowledge, this is an early attempt to explore syllables in tweet normalization. Second, our proposed normalization method relies on unlabeled samples, making it much easier to adapt our method to handle non-standard words in any period of history. And third, we conduct a series of experiments and prove that the proposed method is advantageous over the state-of-art solutions for tweet normalization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Nicholas Diakopoulos</author>
</authors>
<title>Cooooooooooooooollllllllllllll! !!!!!!!!!!!!! using word lengthening to detect sentiment in microblogs.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<pages>562--570</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="17189" citStr="Brody and Diakopoulos, 2011" startWordPosition="2608" endWordPosition="2611">The method described in the previous section are implemented with the following details. 4.1 Preprocessing Before performing normalization, we need to process several types of non-standard words: • Words containing numbers: People usually substitute some kind of sounds with numbers like 4/four, 2/two and 8/eight or numbers can be replacement of some letters like 1/i, 4/a. So we replace numbers with its words or characters and then use them to generate possible candidates. • Words with repeating letters: As our method is syllable-based, repeating letters for sentiment expressing (like cooool, (Brody and Diakopoulos, 2011)) can cause syllabifying failure. For repeating letters, we reduce it to both two and one to generate candidate separately. Then the two lists are merged together to form the whole candidate list. 4.2 Letter-to-sound conversion Syllable in this work refers to orthographic syllables. For example, we convert word tomorrow into to-mor-row. However, when comparing the syllable of a standard word and that of a nonstandard word, sound (i.e., phones) of the syllables are considered. Thus letter-to-sound conversion tools are required. Several TTS system can perform the task according to some linguisti</context>
</contexts>
<marker>Brody, Diakopoulos, 2011</marker>
<rawString>Samuel Brody and Nicholas Diakopoulos. 2011. Cooooooooooooooollllllllllllll! !!!!!!!!!!!!! using word lengthening to detect sentiment in microblogs. In EMNLP, pages 562–570. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monojit Choudhury</author>
<author>Rahul Saraf</author>
<author>Vijit Jain</author>
<author>Animesh Mukherjee</author>
<author>Sudeshna Sarkar</author>
<author>Anupam Basu</author>
</authors>
<title>Investigation and modeling of the structure of texting language.</title>
<date>2007</date>
<journal>International Journal of Document Analysis and Recognition (IJDAR),</journal>
<pages>10--3</pages>
<contexts>
<context position="10384" citStr="Choudhury et al., 2007" startWordPosition="1572" endWordPosition="1575">two types of information simultaneously: (1) Single character can hardly reflect orthographical features of one word. (2) As fine-grained reasonable restrictions are lacked, as showed in (Han and Baldwin, 2011), several times of candidates are included when adding phonetic candidates and this will bring much more noise. To combine orthographical and phonetic measure in a fine-grained level, we proposed the syllable-level approach. 3 Approach 3.1 Framework The framework of the proposed tweet normalization method is presented in Figure 1. The proposed method extends the basic HMM channel model (Choudhury et al., 2007; Cook and Stevenson, 2009) into syllable level. And the following four characteristics are very intersting. (1) Combination: When reading a sentence, fast subvocalization will occur in our mind. In the process, some non-standard words generated by phonetic substitution are correctly pronounced and then normalized. And also, because subvocalization is fast, people tend to ignore some minor flaws in spelling intentionally or unintentionally. As this often occurs in people’s real-life interacting with these social media language, we believe the combination of phonetic and orthographical informat</context>
</contexts>
<marker>Choudhury, Saraf, Jain, Mukherjee, Sarkar, Basu, 2007</marker>
<rawString>Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar, and Anupam Basu. 2007. Investigation and modeling of the structure of texting language. International Journal of Document Analysis and Recognition (IJDAR), 10(3-4):157–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danish Contractor</author>
<author>Tanveer A Faruquie</author>
<author>L Venkata Subramaniam</author>
</authors>
<title>Unsupervised cleansing of noisy text.</title>
<date>2010</date>
<booktitle>In Chu-Ren Huang and</booktitle>
<pages>189--196</pages>
<editor>Dan Jurafsky, editors, COLING (Posters),</editor>
<contexts>
<context position="2515" citStr="Contractor et al., 2010" startWordPosition="382" endWordPosition="385">e OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel sequential labeling systems, features are required for every character and their combinations, leading to much more noise into the later reverse table look-up process (Liu et al., 2012). In the character-block level MT systems equal number of blocks and their corresponding phonetic symbols are required for alignment (Li and Liu, 2012b). This strict res</context>
</contexts>
<marker>Contractor, Faruquie, Subramaniam, 2010</marker>
<rawString>Danish Contractor, Tanveer A. Faruquie, and L. Venkata Subramaniam. 2010. Unsupervised cleansing of noisy text. In Chu-Ren Huang and Dan Jurafsky, editors, COLING (Posters), pages 189–196. Chinese Information Processing Society of China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>An unsupervised model for text message normalization.</title>
<date>2009</date>
<booktitle>In CALC ’09: Proceedings of the Workshop on Computational Approaches to Linguistic Creativity,</booktitle>
<pages>71--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="10411" citStr="Cook and Stevenson, 2009" startWordPosition="1576" endWordPosition="1580"> simultaneously: (1) Single character can hardly reflect orthographical features of one word. (2) As fine-grained reasonable restrictions are lacked, as showed in (Han and Baldwin, 2011), several times of candidates are included when adding phonetic candidates and this will bring much more noise. To combine orthographical and phonetic measure in a fine-grained level, we proposed the syllable-level approach. 3 Approach 3.1 Framework The framework of the proposed tweet normalization method is presented in Figure 1. The proposed method extends the basic HMM channel model (Choudhury et al., 2007; Cook and Stevenson, 2009) into syllable level. And the following four characteristics are very intersting. (1) Combination: When reading a sentence, fast subvocalization will occur in our mind. In the process, some non-standard words generated by phonetic substitution are correctly pronounced and then normalized. And also, because subvocalization is fast, people tend to ignore some minor flaws in spelling intentionally or unintentionally. As this often occurs in people’s real-life interacting with these social media language, we believe the combination of phonetic and orthographical information is of great significanc</context>
</contexts>
<marker>Cook, Stevenson, 2009</marker>
<rawString>Paul Cook and Suzanne Stevenson. 2009. An unsupervised model for text message normalization. In CALC ’09: Proceedings of the Workshop on Computational Approaches to Linguistic Creativity, pages 71–78, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Gouws</author>
<author>Dirk Hovy</author>
<author>Donald Metzler</author>
</authors>
<title>Unsupervised mining of lexical variants from noisy text.</title>
<date>2011</date>
<booktitle>In Proceedings of the First workshop on Unsupervised Learning in NLP,</booktitle>
<pages>82--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7249" citStr="Gouws et al., 2011" startWordPosition="1098" endWordPosition="1101">cal similarity is built upon the assumption that the non-standard words look like its standard counterparts, leading to a high Longest Common Sequence (LCS) and low Edit Distance (ED). This method is widely used in spell checker, in which the LCS and ED scores are calculated for weighting possible candidates. However, problems are that the correct word cannot always be the most looked like one. Taking the nonstandard word nite for example, note looks more likely than the correct form night. To overcome this problem, an exception dictionary of strongly-associated word pairs are constructed in (Gouws et al., 2011). Further, these pairs are added into a unified log-linear model in (Yang and Eisenstein, 2013) and Monte Carlo sampling techniques are used to estimate parameters. 2.2 Phonetic similarity The assumption underlying the phonetic similarity is that during transition, non-standard words sound like the standard counterparts, thus the pronunciation of non-standard words can be traced back to a standard dictionary. The challenge is the algorithm to annotate pronunciation of the nonstandard words. Double Metaphone algorithm (Philips, 2000) is used to decode pronunciation and then to represent phoneti</context>
</contexts>
<marker>Gouws, Hovy, Metzler, 2011</marker>
<rawString>Stephan Gouws, Dirk Hovy, and Donald Metzler. 2011. Unsupervised mining of lexical variants from noisy text. In Proceedings of the First workshop on Unsupervised Learning in NLP, pages 82–90. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: Makn sens a #twitter.</title>
<date>2011</date>
<pages>368--378</pages>
<editor>In Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, ACL,</editor>
<publisher>The Association for Computer Linguistics.</publisher>
<contexts>
<context position="2627" citStr="Han and Baldwin, 2011" startWordPosition="399" endWordPosition="402">rocessing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel sequential labeling systems, features are required for every character and their combinations, leading to much more noise into the later reverse table look-up process (Liu et al., 2012). In the character-block level MT systems equal number of blocks and their corresponding phonetic symbols are required for alignment (Li and Liu, 2012b). This strict restriction can result in a great difficulty in training set construction and a loss of useful information. Finally</context>
<context position="7923" citStr="Han and Baldwin, 2011" startWordPosition="1197" endWordPosition="1200">linear model in (Yang and Eisenstein, 2013) and Monte Carlo sampling techniques are used to estimate parameters. 2.2 Phonetic similarity The assumption underlying the phonetic similarity is that during transition, non-standard words sound like the standard counterparts, thus the pronunciation of non-standard words can be traced back to a standard dictionary. The challenge is the algorithm to annotate pronunciation of the nonstandard words. Double Metaphone algorithm (Philips, 2000) is used to decode pronunciation and then to represent phonetic similarity by edit distance of these transcripts (Han and Baldwin, 2011). IPA symbols are utilized in (Li and Liu, 2012b) to represent sound of words and then word alignment-based machine translation is applied to generate possible pronunciation of non-standard words. And also, phoneme is used in (Liu et al., 2012) as one kind of features to train their CRF model. 2.3 Contextual similarity It is accepted that after standard words are transformed into non-standard words, the meaning of a sentence remains unchanged. So the normalized standard word must carry a meaning. Most researchers use n-gram language model to normalize a sentence, and several researches use mor</context>
<context position="9517" citStr="Han and Baldwin, 2011" startWordPosition="1441" endWordPosition="1444">ual-similarity between non-standard and standard words. Very recently, word-embedding (Mikolov et al., 2010; Mikolov et al., 2013) is utilized in (Li and Liu, 2014) to represent more complex contextual relationship. In word-to-word candidate selection, most researches use orthographical similarity and phonetic similarity separately. In the log-linear model (Yang and Eisenstein, 2013), edit distance is modeled as major feature. In the character- and phonebased approaches (Li and Liu, 2012b), orthographical information and phonetic information were treated separately to generate candidates. In (Han and Baldwin, 2011), candidates from lexical edit distance and phonemic edit distance are merged together. Then an up to 16% increasing recall was reported when adding candidates from phonetic measure. But improper processing level makes it difficult to model the two types of information simultaneously: (1) Single character can hardly reflect orthographical features of one word. (2) As fine-grained reasonable restrictions are lacked, as showed in (Han and Baldwin, 2011), several times of candidates are included when adding phonetic candidates and this will bring much more noise. To combine orthographical and pho</context>
<context position="17888" citStr="Han and Baldwin, 2011" startWordPosition="2719" endWordPosition="2722"> two and one to generate candidate separately. Then the two lists are merged together to form the whole candidate list. 4.2 Letter-to-sound conversion Syllable in this work refers to orthographic syllables. For example, we convert word tomorrow into to-mor-row. However, when comparing the syllable of a standard word and that of a nonstandard word, sound (i.e., phones) of the syllables are considered. Thus letter-to-sound conversion tools are required. Several TTS system can perform the task according to some linguistic rules, even for nonstandard words. The Double Metaphone algorithm used in (Han and Baldwin, 2011) is one of them. But it uses consonants to encode a word, which gives less information than we need. In our method, we use freeTTS (Walker et al., 2002) with CMU lexicon1 to transform words into APRAbet2 symbols. For example, word tomorrow is transcribed to {T-UW M-AA R-OW} and tmr to {T M R}. 4.3 Dictionary preparation • Dictionary #1: In-vocabulary (IV) words Following (Yang and Eisenstein, 2013), our set of IV words is also based on the GNU aspell dictionary (v0.60.6). Differently, we use a collection of 100 million tweets (roughly the same size of Edinburgh Twitter corpus) because the Edin</context>
<context position="20553" citStr="Han and Baldwin, 2011" startWordPosition="3133" endWordPosition="3136">matic annotation system based on CRF++ (Kudo, 2005). In this work, we extract syllables of standard words from Dictionary #2 as training set. Annotations follow (Pennell and Liu, 2010) to identify boundaries of syllables and in our work, CRF++ can suggest several candidate solutions, rather than an optimal segmentation solution for syllable segmentation of the non-standard words. In the HMM channel model, the candidate solutions are included as part of the search space. 4.5 Language model Using Tweets from our corpus that contain no OOV words besides hashtags and username mentions (following (Han and Baldwin, 2011)), the 3http://www.dictionary.com Kneser-Ney smoothed tri-gram language model is estimated using SRILM toolkit (Stolcke, 2002). Note that punctuations, hashtags, and username mentions have some syntactic value (Kaufmann and Kalita, 2010) to some extent, we replace them with ’&lt;PUNCT&gt;’, ’&lt;TOPIC&gt;’ and ’&lt;USER&gt;’. 5 Evaluation 5.1 Datasets We use two labeled twitter datasets in existence to evaluate our tweet normalization method. • LexNorm1.1 contains 549 complete tweets with 1184 non-standard tokens (558 unique word type) (Han and Baldwin, 2011). • LexNorm1.2 is a revised version of LexNorm1.1 (Ya</context>
<context position="22364" citStr="Han and Baldwin, 2011" startWordPosition="3401" endWordPosition="3404">ormalizations which are correct. When we perform the tweet normalization methods, every error is both a false positive and false negative, so in the task, precision equals to recall. 5.3 Sentence level normalization We choose the following prior normalization methods: • (Liu et al., 2012): the extended characterlevel CRF tagging system; • (Yang and Eisenstein, 2013): log-linear model using string edit distance and longest common sequence measures as major features; • (Hassan and Menezes, 2013): bipartite graph major exploit contextual similarity; 925 Method Dataset Precision Recall F-measure (Han and Baldwin, 2011) 75.30 75.30 75.30 (Liu et al., 2012) 84.13 78.38 81.15 (Hassan and Menezes, 2013) LexNorm 1.1 85.37 56.4 69.93 (Yang and Eisenstein, 2013) 82.09 82.09 82.09 Syllable-based method 85.30 85.30 85.30 (Yang and Eisenstein, 2013) LexNorm 1.2 82.06 82.06 82.06 Syllable-based method 86.08 86.08 86.08 Table 3: Experiment results of the tweet normalization methods. • (Han and Baldwin, 2011): the orthographyphone combined system using lexical edit distance and phonemic edit distance. In our method, we set A=0.7 because it is found best in our experiments (see Figure 2). The experimental results are pre</context>
<context position="23721" citStr="Han and Baldwin, 2011" startWordPosition="3607" endWordPosition="3610"> in Section 5.4. Recall we argue that combination of three similarity is necessary when performing sentence-level normalization. Apart from contextual similarity like language model or graphic model, methods in (Yang and Eisenstein, 2013) or (Hassan and Menezes, 2013) do not include phonetic measure, causing loss of important phonetic information. Though using phoneme, morpheme boundary and syllable boundary as features (Liu et al., 2012), the character-level reversed approach will bring much more noise into the later reversed look-up table, and also, features of whole word are omitted. Like (Han and Baldwin, 2011), we also use lexical measure and phonetic measure. Great difference between the two approaches is the processing level: word level and syllable level. In their work, average candidates number suffers times of increase when adding phonetic measure. This is because when introducing phonemic edit distance, important pronunciations can be altered (phonemic edit distance of night-need and night-kite is equal). Syllable level allows us to reflect consistencies during transition in a finergrained level. Thus the phonetic similarity can be more precisely modeled. 5.4 Contributions of phone and orthog</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a #twitter. In Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, ACL, pages 368–378. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hany Hassan</author>
<author>Arul Menezes</author>
</authors>
<title>Social text normalization using contextual graph random walks.</title>
<date>2013</date>
<journal>In ACL</journal>
<volume>1</volume>
<pages>1577--1586</pages>
<institution>The Association for Computer Linguistics.</institution>
<contexts>
<context position="8763" citStr="Hassan and Menezes, 2013" startWordPosition="1332" endWordPosition="1335">is used in (Liu et al., 2012) as one kind of features to train their CRF model. 2.3 Contextual similarity It is accepted that after standard words are transformed into non-standard words, the meaning of a sentence remains unchanged. So the normalized standard word must carry a meaning. Most researchers use n-gram language model to normalize a sentence, and several researches use more contextual information. For example, training pairs are generated in (Liu et al., 2012) by a 921 cosine contextual similarity formula whose items are defined by TF-IDF scheme. A bipartite graph is constructed in (Hassan and Menezes, 2013) to represent tokens (both non-standard and standard words) and their context. Thus, random walks on the graph can represent contextual-similarity between non-standard and standard words. Very recently, word-embedding (Mikolov et al., 2010; Mikolov et al., 2013) is utilized in (Li and Liu, 2014) to represent more complex contextual relationship. In word-to-word candidate selection, most researches use orthographical similarity and phonetic similarity separately. In the log-linear model (Yang and Eisenstein, 2013), edit distance is modeled as major feature. In the character- and phonebased appr</context>
<context position="22240" citStr="Hassan and Menezes, 2013" startWordPosition="3385" endWordPosition="3388">13), recall is the proportion of words requiring normalization which are normalized correctly; precision is the proportion of normalizations which are correct. When we perform the tweet normalization methods, every error is both a false positive and false negative, so in the task, precision equals to recall. 5.3 Sentence level normalization We choose the following prior normalization methods: • (Liu et al., 2012): the extended characterlevel CRF tagging system; • (Yang and Eisenstein, 2013): log-linear model using string edit distance and longest common sequence measures as major features; • (Hassan and Menezes, 2013): bipartite graph major exploit contextual similarity; 925 Method Dataset Precision Recall F-measure (Han and Baldwin, 2011) 75.30 75.30 75.30 (Liu et al., 2012) 84.13 78.38 81.15 (Hassan and Menezes, 2013) LexNorm 1.1 85.37 56.4 69.93 (Yang and Eisenstein, 2013) 82.09 82.09 82.09 Syllable-based method 85.30 85.30 85.30 (Yang and Eisenstein, 2013) LexNorm 1.2 82.06 82.06 82.06 Syllable-based method 86.08 86.08 86.08 Table 3: Experiment results of the tweet normalization methods. • (Han and Baldwin, 2011): the orthographyphone combined system using lexical edit distance and phonemic edit distan</context>
</contexts>
<marker>Hassan, Menezes, 2013</marker>
<rawString>Hany Hassan and Arul Menezes. 2013. Social text normalization using contextual graph random walks. In ACL (1), pages 1577–1586. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Kaufmann</author>
<author>Jugal Kalita</author>
</authors>
<title>Syntactic normalization of Twitter messages.</title>
<date>2010</date>
<booktitle>In International conference on natural language processing,</booktitle>
<location>Kharagpur, India.</location>
<contexts>
<context position="20790" citStr="Kaufmann and Kalita, 2010" startWordPosition="3162" endWordPosition="3165">ork, CRF++ can suggest several candidate solutions, rather than an optimal segmentation solution for syllable segmentation of the non-standard words. In the HMM channel model, the candidate solutions are included as part of the search space. 4.5 Language model Using Tweets from our corpus that contain no OOV words besides hashtags and username mentions (following (Han and Baldwin, 2011)), the 3http://www.dictionary.com Kneser-Ney smoothed tri-gram language model is estimated using SRILM toolkit (Stolcke, 2002). Note that punctuations, hashtags, and username mentions have some syntactic value (Kaufmann and Kalita, 2010) to some extent, we replace them with ’&lt;PUNCT&gt;’, ’&lt;TOPIC&gt;’ and ’&lt;USER&gt;’. 5 Evaluation 5.1 Datasets We use two labeled twitter datasets in existence to evaluate our tweet normalization method. • LexNorm1.1 contains 549 complete tweets with 1184 non-standard tokens (558 unique word type) (Han and Baldwin, 2011). • LexNorm1.2 is a revised version of LexNorm1.1 (Yang and Eisenstein, 2013). Some inconsistencies and errors in LexNorm1.1 are corrected and some more non-standard words are properly recovered. In both datasets, to-be-normalized non-standard words are detected manually as well as the cor</context>
</contexts>
<marker>Kaufmann, Kalita, 2010</marker>
<rawString>Max Kaufmann and Jugal Kalita. 2010. Syntactic normalization of Twitter messages. In International conference on natural language processing, Kharagpur, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
</authors>
<title>Crf++: Yet another crf toolkit. Software available at http://crfpp.</title>
<date>2005</date>
<note>sourceforge. net.</note>
<contexts>
<context position="19982" citStr="Kudo, 2005" startWordPosition="3045" endWordPosition="3046">d dictionary. 4.4 Automatic syllabification of non-standard words Automatic syllabification of non-standard words is a supervised problem. A straightforward idea is to train a CRF model on manually labeled syllables of non-standard words. Unfortunately, such a corpus is not available and very expensive to produce. We assume that both standard and non-standard forms follow the same syllable rules (i.e., the cognitive process). Thus we propose to train the CRF model on the corpus of syllables of standard words (which is easy to obtain) to construct an automatic annotation system based on CRF++ (Kudo, 2005). In this work, we extract syllables of standard words from Dictionary #2 as training set. Annotations follow (Pennell and Liu, 2010) to identify boundaries of syllables and in our work, CRF++ can suggest several candidate solutions, rather than an optimal segmentation solution for syllable segmentation of the non-standard words. In the HMM channel model, the candidate solutions are included as part of the search space. 4.5 Language model Using Tweets from our corpus that contain no OOV words besides hashtags and username mentions (following (Han and Baldwin, 2011)), the 3http://www.dictionary</context>
</contexts>
<marker>Kudo, 2005</marker>
<rawString>Taku Kudo. 2005. Crf++: Yet another crf toolkit. Software available at http://crfpp. sourceforge. net.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Improving text normalization using character-blocks based models and system combination.</title>
<date>2012</date>
<booktitle>In COLING 2012, 24th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers,</booktitle>
<pages>8--15</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="2411" citStr="Li and Liu, 2012" startWordPosition="367" endWordPosition="370"> tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel sequential labeling systems, features are required for every character and their combinations, leading to much more noise into the later reverse table look-up process (Liu et al., 2012). In the character-block level MT systems equal number of blocks </context>
<context position="7970" citStr="Li and Liu, 2012" startWordPosition="1206" endWordPosition="1209"> Carlo sampling techniques are used to estimate parameters. 2.2 Phonetic similarity The assumption underlying the phonetic similarity is that during transition, non-standard words sound like the standard counterparts, thus the pronunciation of non-standard words can be traced back to a standard dictionary. The challenge is the algorithm to annotate pronunciation of the nonstandard words. Double Metaphone algorithm (Philips, 2000) is used to decode pronunciation and then to represent phonetic similarity by edit distance of these transcripts (Han and Baldwin, 2011). IPA symbols are utilized in (Li and Liu, 2012b) to represent sound of words and then word alignment-based machine translation is applied to generate possible pronunciation of non-standard words. And also, phoneme is used in (Liu et al., 2012) as one kind of features to train their CRF model. 2.3 Contextual similarity It is accepted that after standard words are transformed into non-standard words, the meaning of a sentence remains unchanged. So the normalized standard word must carry a meaning. Most researchers use n-gram language model to normalize a sentence, and several researches use more contextual information. For example, training</context>
<context position="9387" citStr="Li and Liu, 2012" startWordPosition="1424" endWordPosition="1427">esent tokens (both non-standard and standard words) and their context. Thus, random walks on the graph can represent contextual-similarity between non-standard and standard words. Very recently, word-embedding (Mikolov et al., 2010; Mikolov et al., 2013) is utilized in (Li and Liu, 2014) to represent more complex contextual relationship. In word-to-word candidate selection, most researches use orthographical similarity and phonetic similarity separately. In the log-linear model (Yang and Eisenstein, 2013), edit distance is modeled as major feature. In the character- and phonebased approaches (Li and Liu, 2012b), orthographical information and phonetic information were treated separately to generate candidates. In (Han and Baldwin, 2011), candidates from lexical edit distance and phonemic edit distance are merged together. Then an up to 16% increasing recall was reported when adding candidates from phonetic measure. But improper processing level makes it difficult to model the two types of information simultaneously: (1) Single character can hardly reflect orthographical features of one word. (2) As fine-grained reasonable restrictions are lacked, as showed in (Han and Baldwin, 2011), several times</context>
</contexts>
<marker>Li, Liu, 2012</marker>
<rawString>Chen Li and Yang Liu. 2012a. Improving text normalization using character-blocks based models and system combination. In COLING 2012, 24th International Conference on Computational Linguistics, Proceedings of the Conference: Technical Papers, 8-15 December 2012, Mumbai, India, pages 1587–1602.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Normalization of text messages using character- and phone-based machine translation approaches.</title>
<date>2012</date>
<booktitle>In INTERSPEECH. ISCA.</booktitle>
<contexts>
<context position="2411" citStr="Li and Liu, 2012" startWordPosition="367" endWordPosition="370"> tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel sequential labeling systems, features are required for every character and their combinations, leading to much more noise into the later reverse table look-up process (Liu et al., 2012). In the character-block level MT systems equal number of blocks </context>
<context position="7970" citStr="Li and Liu, 2012" startWordPosition="1206" endWordPosition="1209"> Carlo sampling techniques are used to estimate parameters. 2.2 Phonetic similarity The assumption underlying the phonetic similarity is that during transition, non-standard words sound like the standard counterparts, thus the pronunciation of non-standard words can be traced back to a standard dictionary. The challenge is the algorithm to annotate pronunciation of the nonstandard words. Double Metaphone algorithm (Philips, 2000) is used to decode pronunciation and then to represent phonetic similarity by edit distance of these transcripts (Han and Baldwin, 2011). IPA symbols are utilized in (Li and Liu, 2012b) to represent sound of words and then word alignment-based machine translation is applied to generate possible pronunciation of non-standard words. And also, phoneme is used in (Liu et al., 2012) as one kind of features to train their CRF model. 2.3 Contextual similarity It is accepted that after standard words are transformed into non-standard words, the meaning of a sentence remains unchanged. So the normalized standard word must carry a meaning. Most researchers use n-gram language model to normalize a sentence, and several researches use more contextual information. For example, training</context>
<context position="9387" citStr="Li and Liu, 2012" startWordPosition="1424" endWordPosition="1427">esent tokens (both non-standard and standard words) and their context. Thus, random walks on the graph can represent contextual-similarity between non-standard and standard words. Very recently, word-embedding (Mikolov et al., 2010; Mikolov et al., 2013) is utilized in (Li and Liu, 2014) to represent more complex contextual relationship. In word-to-word candidate selection, most researches use orthographical similarity and phonetic similarity separately. In the log-linear model (Yang and Eisenstein, 2013), edit distance is modeled as major feature. In the character- and phonebased approaches (Li and Liu, 2012b), orthographical information and phonetic information were treated separately to generate candidates. In (Han and Baldwin, 2011), candidates from lexical edit distance and phonemic edit distance are merged together. Then an up to 16% increasing recall was reported when adding candidates from phonetic measure. But improper processing level makes it difficult to model the two types of information simultaneously: (1) Single character can hardly reflect orthographical features of one word. (2) As fine-grained reasonable restrictions are lacked, as showed in (Han and Baldwin, 2011), several times</context>
</contexts>
<marker>Li, Liu, 2012</marker>
<rawString>Chen Li and Yang Liu. 2012b. Normalization of text messages using character- and phone-based machine translation approaches. In INTERSPEECH. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Improving text normalization via unsupervised model and discriminative reranking.</title>
<date>2014</date>
<journal>Student Research Workshop,</journal>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL</booktitle>
<pages>86--93</pages>
<location>Baltimore, MD, USA,</location>
<contexts>
<context position="9059" citStr="Li and Liu, 2014" startWordPosition="1375" endWordPosition="1378">use n-gram language model to normalize a sentence, and several researches use more contextual information. For example, training pairs are generated in (Liu et al., 2012) by a 921 cosine contextual similarity formula whose items are defined by TF-IDF scheme. A bipartite graph is constructed in (Hassan and Menezes, 2013) to represent tokens (both non-standard and standard words) and their context. Thus, random walks on the graph can represent contextual-similarity between non-standard and standard words. Very recently, word-embedding (Mikolov et al., 2010; Mikolov et al., 2013) is utilized in (Li and Liu, 2014) to represent more complex contextual relationship. In word-to-word candidate selection, most researches use orthographical similarity and phonetic similarity separately. In the log-linear model (Yang and Eisenstein, 2013), edit distance is modeled as major feature. In the character- and phonebased approaches (Li and Liu, 2012b), orthographical information and phonetic information were treated separately to generate candidates. In (Han and Baldwin, 2011), candidates from lexical edit distance and phonemic edit distance are merged together. Then an up to 16% increasing recall was reported when </context>
</contexts>
<marker>Li, Liu, 2014</marker>
<rawString>Chen Li and Yang Liu. 2014. Improving text normalization via unsupervised model and discriminative reranking. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014, June 22-27, 2014, Baltimore, MD, USA, Student Research Workshop, pages 86– 93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Fuliang Weng</author>
<author>Bingqing Wang</author>
<author>Yang Liu</author>
</authors>
<title>Insertion, deletion, or substitution?: normalizing text messages without precategorization nor supervision.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2,</booktitle>
<pages>71--76</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1581" citStr="Liu et al., 2011" startWordPosition="239" endWordPosition="242">is is an early attempt to explore syllables in tweet normalization. Second, our proposed normalization method relies on unlabeled samples, making it much easier to adapt our method to handle non-standard words in any period of history. And third, we conduct a series of experiments and prove that the proposed method is advantageous over the state-of-art solutions for tweet normalization. 1 Introduction Due to the casual nature of social media, there exists a large number of non-standard words in text expressions which make it substantially different from formal written text. It is reported in (Liu et al., 2011) that more than 4 million distinct out-of-vocabulary (OOV) tokens are found in the Edinburgh Twitter corpus (Petrovic et al., 2010). This variation poses challenges when performing natural language processing (NLP) tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletio</context>
</contexts>
<marker>Liu, Weng, Wang, Liu, 2011</marker>
<rawString>Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu. 2011. Insertion, deletion, or substitution?: normalizing text messages without precategorization nor supervision. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 71–76. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Fuliang Weng</author>
<author>Xiao Jiang</author>
</authors>
<title>A broad-coverage normalization system for social media language. In</title>
<date>2012</date>
<booktitle>In Proceedings of ACL: Long Papers-Volume 1,</booktitle>
<pages>1035--1044</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2248" citStr="Liu et al., 2012" startWordPosition="339" endWordPosition="342">ry (OOV) tokens are found in the Edinburgh Twitter corpus (Petrovic et al., 2010). This variation poses challenges when performing natural language processing (NLP) tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel sequential labeling systems, features are required for every character and their combin</context>
<context position="8167" citStr="Liu et al., 2012" startWordPosition="1236" endWordPosition="1239">tandard counterparts, thus the pronunciation of non-standard words can be traced back to a standard dictionary. The challenge is the algorithm to annotate pronunciation of the nonstandard words. Double Metaphone algorithm (Philips, 2000) is used to decode pronunciation and then to represent phonetic similarity by edit distance of these transcripts (Han and Baldwin, 2011). IPA symbols are utilized in (Li and Liu, 2012b) to represent sound of words and then word alignment-based machine translation is applied to generate possible pronunciation of non-standard words. And also, phoneme is used in (Liu et al., 2012) as one kind of features to train their CRF model. 2.3 Contextual similarity It is accepted that after standard words are transformed into non-standard words, the meaning of a sentence remains unchanged. So the normalized standard word must carry a meaning. Most researchers use n-gram language model to normalize a sentence, and several researches use more contextual information. For example, training pairs are generated in (Liu et al., 2012) by a 921 cosine contextual similarity formula whose items are defined by TF-IDF scheme. A bipartite graph is constructed in (Hassan and Menezes, 2013) to </context>
<context position="22031" citStr="Liu et al., 2012" startWordPosition="3352" endWordPosition="3355">s. 5.2 Evaluation criteria Here we use precision, recall and F-score to evaluate our method. As normalization methods on these datasets focused on the labeled nonstandard words (Yang and Eisenstein, 2013), recall is the proportion of words requiring normalization which are normalized correctly; precision is the proportion of normalizations which are correct. When we perform the tweet normalization methods, every error is both a false positive and false negative, so in the task, precision equals to recall. 5.3 Sentence level normalization We choose the following prior normalization methods: • (Liu et al., 2012): the extended characterlevel CRF tagging system; • (Yang and Eisenstein, 2013): log-linear model using string edit distance and longest common sequence measures as major features; • (Hassan and Menezes, 2013): bipartite graph major exploit contextual similarity; 925 Method Dataset Precision Recall F-measure (Han and Baldwin, 2011) 75.30 75.30 75.30 (Liu et al., 2012) 84.13 78.38 81.15 (Hassan and Menezes, 2013) LexNorm 1.1 85.37 56.4 69.93 (Yang and Eisenstein, 2013) 82.09 82.09 82.09 Syllable-based method 85.30 85.30 85.30 (Yang and Eisenstein, 2013) LexNorm 1.2 82.06 82.06 82.06 Syllable-ba</context>
<context position="23541" citStr="Liu et al., 2012" startWordPosition="3579" endWordPosition="3582">ure 2). The experimental results are presented in Table 3, which indicate that our method outperforms the state-of-the-art methods. Details on how to adjust parameter is given in Section 5.4. Recall we argue that combination of three similarity is necessary when performing sentence-level normalization. Apart from contextual similarity like language model or graphic model, methods in (Yang and Eisenstein, 2013) or (Hassan and Menezes, 2013) do not include phonetic measure, causing loss of important phonetic information. Though using phoneme, morpheme boundary and syllable boundary as features (Liu et al., 2012), the character-level reversed approach will bring much more noise into the later reversed look-up table, and also, features of whole word are omitted. Like (Han and Baldwin, 2011), we also use lexical measure and phonetic measure. Great difference between the two approaches is the processing level: word level and syllable level. In their work, average candidates number suffers times of increase when adding phonetic measure. This is because when introducing phonemic edit distance, important pronunciations can be altered (phonemic edit distance of night-need and night-kite is equal). Syllable l</context>
</contexts>
<marker>Liu, Weng, Jiang, 2012</marker>
<rawString>Fei Liu, Fuliang Weng, and Xiao Jiang. 2012. A broad-coverage normalization system for social media language. In In Proceedings of ACL: Long Papers-Volume 1, pages 1035–1044. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom´aˇs Mikolov</author>
<author>Martin Karafi´at</author>
<author>Luk Burget</author>
<author>Jan ernock</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Recurrent neural network based language model.</title>
<date>2010</date>
<booktitle>In Interspeech,</booktitle>
<pages>1045--1048</pages>
<marker>Mikolov, Karafi´at, Burget, ernock, Khudanpur, 2010</marker>
<rawString>Tom´aˇs Mikolov, Martin Karafi´at, Luk Burget, Jan ernock, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Interspeech, pages 1045–1048.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tom´aˇs Mikolov</author>
<author>Kai Chen</author>
</authors>
<location>Greg Corrado, and</location>
<marker>Mikolov, Chen, </marker>
<rawString>Tom´aˇs Mikolov, Kai Chen, Greg Corrado, and</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<location>CoRR, abs/1301.3781.</location>
<marker>Dean, 2013</marker>
<rawString>Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. CoRR, abs/1301.3781.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deana Pennell</author>
<author>Yang Liu</author>
</authors>
<title>Normalization of text messages for text-to-speech.</title>
<date>2010</date>
<booktitle>In ICASSP,</booktitle>
<pages>4842--4845</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="2164" citStr="Pennell and Liu, 2010" startWordPosition="326" endWordPosition="329">t. It is reported in (Liu et al., 2011) that more than 4 million distinct out-of-vocabulary (OOV) tokens are found in the Edinburgh Twitter corpus (Petrovic et al., 2010). This variation poses challenges when performing natural language processing (NLP) tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel seq</context>
<context position="18784" citStr="Pennell and Liu, 2010" startWordPosition="2857" endWordPosition="2860"> and tmr to {T M R}. 4.3 Dictionary preparation • Dictionary #1: In-vocabulary (IV) words Following (Yang and Eisenstein, 2013), our set of IV words is also based on the GNU aspell dictionary (v0.60.6). Differently, we use a collection of 100 million tweets (roughly the same size of Edinburgh Twitter corpus) because the Edinburgh Twitter corpus is no longer available due to Twitter policies. The 1http://www.speech.cs.cmu.edu/cgi-bin/cmudict 2http://en.wikipedia.org/wiki/Arpabet 924 final IV dictionary contains 51,948 standard words. • Dictionary #2: Syllables for the standard words Following (Pennell and Liu, 2010), we use the online dictionary3 to extract syllables for each standard words. We encountered same problem when accessing words with prefixes or suffixes, which are not syllabified in the same format as the base words on the website. To address the issue, we simply regard these prefixes and suffixes as syllables. • Dictionary #3: Pronunciation of the syllables Using the CMU pronouncing dictionary (Weide, 1998) and dictionary 2, and knowing all possible APRAbet symbol for all consonant characters, we can program to capture every possible pronunciation of all syllables in the standard dictionary.</context>
<context position="20115" citStr="Pennell and Liu, 2010" startWordPosition="3064" endWordPosition="3067">ervised problem. A straightforward idea is to train a CRF model on manually labeled syllables of non-standard words. Unfortunately, such a corpus is not available and very expensive to produce. We assume that both standard and non-standard forms follow the same syllable rules (i.e., the cognitive process). Thus we propose to train the CRF model on the corpus of syllables of standard words (which is easy to obtain) to construct an automatic annotation system based on CRF++ (Kudo, 2005). In this work, we extract syllables of standard words from Dictionary #2 as training set. Annotations follow (Pennell and Liu, 2010) to identify boundaries of syllables and in our work, CRF++ can suggest several candidate solutions, rather than an optimal segmentation solution for syllable segmentation of the non-standard words. In the HMM channel model, the candidate solutions are included as part of the search space. 4.5 Language model Using Tweets from our corpus that contain no OOV words besides hashtags and username mentions (following (Han and Baldwin, 2011)), the 3http://www.dictionary.com Kneser-Ney smoothed tri-gram language model is estimated using SRILM toolkit (Stolcke, 2002). Note that punctuations, hashtags, </context>
</contexts>
<marker>Pennell, Liu, 2010</marker>
<rawString>Deana Pennell and Yang Liu. 2010. Normalization of text messages for text-to-speech. In ICASSP, pages 4842–4845. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deana Pennell</author>
<author>Yang Liu</author>
</authors>
<title>A character-level machine translation approach for normalization of sms abbreviations.</title>
<date>2011</date>
<booktitle>In IJCNLP,</booktitle>
<pages>974--982</pages>
<contexts>
<context position="2377" citStr="Pennell and Liu, 2011" startWordPosition="360" endWordPosition="363">orming natural language processing (NLP) tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel sequential labeling systems, features are required for every character and their combinations, leading to much more noise into the later reverse table look-up process (Liu et al., 2012). In the character-block level </context>
</contexts>
<marker>Pennell, Liu, 2011</marker>
<rawString>Deana Pennell and Yang Liu. 2011. A character-level machine translation approach for normalization of sms abbreviations. In IJCNLP, pages 974–982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrovic</author>
<author>M Osborne</author>
<author>V Lavrenko</author>
</authors>
<title>The edinburgh twitter corpus.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT Workshop on Computational Linguistics in a World of Social Media,</booktitle>
<pages>25--26</pages>
<contexts>
<context position="1712" citStr="Petrovic et al., 2010" startWordPosition="260" endWordPosition="263">led samples, making it much easier to adapt our method to handle non-standard words in any period of history. And third, we conduct a series of experiments and prove that the proposed method is advantageous over the state-of-art solutions for tweet normalization. 1 Introduction Due to the casual nature of social media, there exists a large number of non-standard words in text expressions which make it substantially different from formal written text. It is reported in (Liu et al., 2011) that more than 4 million distinct out-of-vocabulary (OOV) tokens are found in the Edinburgh Twitter corpus (Petrovic et al., 2010). This variation poses challenges when performing natural language processing (NLP) tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The characte</context>
</contexts>
<marker>Petrovic, Osborne, Lavrenko, 2010</marker>
<rawString>S. Petrovic, M. Osborne, and V. Lavrenko. 2010. The edinburgh twitter corpus. In Proceedings of the NAACL HLT Workshop on Computational Linguistics in a World of Social Media, pages 25– 26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Philips</author>
</authors>
<title>The double metaphone search algorithm.</title>
<date>2000</date>
<journal>C/C++ Users Journal,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="7787" citStr="Philips, 2000" startWordPosition="1178" endWordPosition="1179">ry of strongly-associated word pairs are constructed in (Gouws et al., 2011). Further, these pairs are added into a unified log-linear model in (Yang and Eisenstein, 2013) and Monte Carlo sampling techniques are used to estimate parameters. 2.2 Phonetic similarity The assumption underlying the phonetic similarity is that during transition, non-standard words sound like the standard counterparts, thus the pronunciation of non-standard words can be traced back to a standard dictionary. The challenge is the algorithm to annotate pronunciation of the nonstandard words. Double Metaphone algorithm (Philips, 2000) is used to decode pronunciation and then to represent phonetic similarity by edit distance of these transcripts (Han and Baldwin, 2011). IPA symbols are utilized in (Li and Liu, 2012b) to represent sound of words and then word alignment-based machine translation is applied to generate possible pronunciation of non-standard words. And also, phoneme is used in (Liu et al., 2012) as one kind of features to train their CRF model. 2.3 Contextual similarity It is accepted that after standard words are transformed into non-standard words, the meaning of a sentence remains unchanged. So the normalize</context>
</contexts>
<marker>Philips, 2000</marker>
<rawString>Lawrence Philips. 2000. The double metaphone search algorithm. C/C++ Users Journal, 18(5), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>Alan W Black</author>
<author>Stanley F Chen</author>
<author>Shankar Kumar</author>
<author>Mari Ostendorf</author>
<author>Christopher Richards</author>
</authors>
<title>Normalization of non-standard words.</title>
<date>2001</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>15</volume>
<issue>3</issue>
<pages>333</pages>
<contexts>
<context position="1823" citStr="Sproat et al., 2001" startWordPosition="275" endWordPosition="278"> third, we conduct a series of experiments and prove that the proposed method is advantageous over the state-of-art solutions for tweet normalization. 1 Introduction Due to the casual nature of social media, there exists a large number of non-standard words in text expressions which make it substantially different from formal written text. It is reported in (Liu et al., 2011) that more than 4 million distinct out-of-vocabulary (OOV) tokens are found in the Edinburgh Twitter corpus (Petrovic et al., 2010). This variation poses challenges when performing natural language processing (NLP) tasks (Sproat et al., 2001) based on such texts. Tweet normalization, aiming at converting these OOV non-standard words into their in-vocabulary (IV) formal forms, is therefore viewed as a very important pre-processing task. Researchers focus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into char</context>
</contexts>
<marker>Sproat, Black, Chen, Kumar, Ostendorf, Richards, 2001</marker>
<rawString>Richard Sproat, Alan W. Black, Stanley F. Chen, Shankar Kumar, Mari Ostendorf, and Christopher Richards. 2001. Normalization of non-standard words. Computer Speech &amp; Language, 15(3):287– 333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings International Conference on Spoken Language Processing,</booktitle>
<pages>257--286</pages>
<contexts>
<context position="20679" citStr="Stolcke, 2002" startWordPosition="3149" endWordPosition="3150">ng set. Annotations follow (Pennell and Liu, 2010) to identify boundaries of syllables and in our work, CRF++ can suggest several candidate solutions, rather than an optimal segmentation solution for syllable segmentation of the non-standard words. In the HMM channel model, the candidate solutions are included as part of the search space. 4.5 Language model Using Tweets from our corpus that contain no OOV words besides hashtags and username mentions (following (Han and Baldwin, 2011)), the 3http://www.dictionary.com Kneser-Ney smoothed tri-gram language model is estimated using SRILM toolkit (Stolcke, 2002). Note that punctuations, hashtags, and username mentions have some syntactic value (Kaufmann and Kalita, 2010) to some extent, we replace them with ’&lt;PUNCT&gt;’, ’&lt;TOPIC&gt;’ and ’&lt;USER&gt;’. 5 Evaluation 5.1 Datasets We use two labeled twitter datasets in existence to evaluate our tweet normalization method. • LexNorm1.1 contains 549 complete tweets with 1184 non-standard tokens (558 unique word type) (Han and Baldwin, 2011). • LexNorm1.2 is a revised version of LexNorm1.1 (Yang and Eisenstein, 2013). Some inconsistencies and errors in LexNorm1.1 are corrected and some more non-standard words are pro</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm-an extensible language modeling toolkit. In Proceedings International Conference on Spoken Language Processing, pages 257–286, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willie Walker</author>
<author>Paul Lamere</author>
<author>Philip Kwok</author>
</authors>
<title>Freetts: a performance case study.</title>
<date>2002</date>
<contexts>
<context position="18040" citStr="Walker et al., 2002" startWordPosition="2748" endWordPosition="2751">lable in this work refers to orthographic syllables. For example, we convert word tomorrow into to-mor-row. However, when comparing the syllable of a standard word and that of a nonstandard word, sound (i.e., phones) of the syllables are considered. Thus letter-to-sound conversion tools are required. Several TTS system can perform the task according to some linguistic rules, even for nonstandard words. The Double Metaphone algorithm used in (Han and Baldwin, 2011) is one of them. But it uses consonants to encode a word, which gives less information than we need. In our method, we use freeTTS (Walker et al., 2002) with CMU lexicon1 to transform words into APRAbet2 symbols. For example, word tomorrow is transcribed to {T-UW M-AA R-OW} and tmr to {T M R}. 4.3 Dictionary preparation • Dictionary #1: In-vocabulary (IV) words Following (Yang and Eisenstein, 2013), our set of IV words is also based on the GNU aspell dictionary (v0.60.6). Differently, we use a collection of 100 million tweets (roughly the same size of Edinburgh Twitter corpus) because the Edinburgh Twitter corpus is no longer available due to Twitter policies. The 1http://www.speech.cs.cmu.edu/cgi-bin/cmudict 2http://en.wikipedia.org/wiki/Arp</context>
</contexts>
<marker>Walker, Lamere, Kwok, 2002</marker>
<rawString>Willie Walker, Paul Lamere, and Philip Kwok. 2002. Freetts: a performance case study.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert L Weide</author>
</authors>
<title>The cmu pronouncing dictionary.</title>
<date>1998</date>
<note>URL: http://www. speech. cs. cmu. edu/cgibin/cmudict.</note>
<contexts>
<context position="19196" citStr="Weide, 1998" startWordPosition="2925" endWordPosition="2926">mu.edu/cgi-bin/cmudict 2http://en.wikipedia.org/wiki/Arpabet 924 final IV dictionary contains 51,948 standard words. • Dictionary #2: Syllables for the standard words Following (Pennell and Liu, 2010), we use the online dictionary3 to extract syllables for each standard words. We encountered same problem when accessing words with prefixes or suffixes, which are not syllabified in the same format as the base words on the website. To address the issue, we simply regard these prefixes and suffixes as syllables. • Dictionary #3: Pronunciation of the syllables Using the CMU pronouncing dictionary (Weide, 1998) and dictionary 2, and knowing all possible APRAbet symbol for all consonant characters, we can program to capture every possible pronunciation of all syllables in the standard dictionary. 4.4 Automatic syllabification of non-standard words Automatic syllabification of non-standard words is a supervised problem. A straightforward idea is to train a CRF model on manually labeled syllables of non-standard words. Unfortunately, such a corpus is not available and very expensive to produce. We assume that both standard and non-standard forms follow the same syllable rules (i.e., the cognitive proce</context>
</contexts>
<marker>Weide, 1998</marker>
<rawString>Robert L Weide. 1998. The cmu pronouncing dictionary. URL: http://www. speech. cs. cmu. edu/cgibin/cmudict.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunqing Xia</author>
<author>Kam-Fai Wong</author>
<author>Wenjie Li</author>
</authors>
<title>A phonetic-based approach to chinese chat text normalization.</title>
<date>2006</date>
<editor>In Nicoletta Calzolari, Claire Cardie, and Pierre Isabelle, editors, ACL.</editor>
<publisher>The Association for Computer Linguistics.</publisher>
<contexts>
<context position="11086" citStr="Xia et al., 2006" startWordPosition="1674" endWordPosition="1677">cs are very intersting. (1) Combination: When reading a sentence, fast subvocalization will occur in our mind. In the process, some non-standard words generated by phonetic substitution are correctly pronounced and then normalized. And also, because subvocalization is fast, people tend to ignore some minor flaws in spelling intentionally or unintentionally. As this often occurs in people’s real-life interacting with these social media language, we believe the combination of phonetic and orthographical information is of great significance. (2) Syllable level: Inspired by Chinese normalization (Xia et al., 2006) using pinyin (phonetic transcripts of Chinese), syllable can be seen as basic unit when processing pronunciation. Different from mono-syllable Chinese words, English words can be multi-syllable; this will bring changes in our method that extra layers of syllables must be put into consideration. Thus, apart from word-based noisy-channel model, we extend it into a syllable-level framework. (3) Priori knowledge: Priori knowledge is acquired from standard words, meaning that both standard syllabification and pronunciation can shed some lights to non-standard words. This assumption makes it possib</context>
<context position="14807" citStr="Xia et al., 2006" startWordPosition="2256" endWordPosition="2259"> as its argument increases, so much more weight can be assigned if syllables are more similar. The parameter λ here is used to empirically adjust relative contribution of letters and sounds. Longest common sequence (LCS) and edit distance (ED) are used to measure orthographical similarity, while phonetic longest common sequence (PLCS) and phonetic edit distant (PED) are used to measure phonetic similarity but based on letter-to-sound transcripts. The PLCS are defined as basic LCS but PED here is slightly different. When performing phonetic similarity calculation based on syllables, we follow (Xia et al., 2006) in treating consonant and vowels separately because transition of consonants can make a totally different pronunciation. So if consonants of scj and swj are exactly the same or fit rules listed in Table 2, PED(scj, swj) equals to edit 923 Description Rules Examples 1. -ng as suffix: g-dropping -n/-ng do-in/do-ing, go-in/go-ing, talk-in/talk-ing, mak-in/mak-ing 2. -ng as suffix: n-dropping -g/-ng tak-ig/tak-ing, likig/lik-ing 3. suffix: z/s equaling -z/-s, -s/-z jamz/james, plz/please 4. suffix: n/m equaling -m/-n, -n/-m in-portant/im-portant, get-tim/get-ting 5. suffix: t/d equaling -t/-d, -d</context>
</contexts>
<marker>Xia, Wong, Li, 2006</marker>
<rawString>Yunqing Xia, Kam-Fai Wong, and Wenjie Li. 2006. A phonetic-based approach to chinese chat text normalization. In Nicoletta Calzolari, Claire Cardie, and Pierre Isabelle, editors, ACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Yang</author>
<author>Jacob Eisenstein</author>
</authors>
<title>A log-linear model for unsupervised text normalization.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>61--72</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2660" citStr="Yang and Eisenstein, 2013" startWordPosition="404" endWordPosition="407">ocus their studies in tweet normalization at different levels. A character-level tagging system is used in (Pennell and Liu, 2010) to solve deletion-based abbreviation. It was further extended in (Liu et al., 2012) using more characters instead of Y or N as labels. The character-level machine translation (MT) approach (Pennell and Liu, 2011) was modified in (Li and Liu, 2012a) into character-block. While a string edit distance method was introduced in (Contractor et al., 2010) to represent word-level similarity, and this orthographical feature has been adopted in (Han and Baldwin, 2011), and (Yang and Eisenstein, 2013). Challenges are encountered in these different levels of tweet normalization. In the characterlevel sequential labeling systems, features are required for every character and their combinations, leading to much more noise into the later reverse table look-up process (Liu et al., 2012). In the character-block level MT systems equal number of blocks and their corresponding phonetic symbols are required for alignment (Li and Liu, 2012b). This strict restriction can result in a great difficulty in training set construction and a loss of useful information. Finally, word-level normalization method</context>
<context position="7344" citStr="Yang and Eisenstein, 2013" startWordPosition="1113" endWordPosition="1116">andard counterparts, leading to a high Longest Common Sequence (LCS) and low Edit Distance (ED). This method is widely used in spell checker, in which the LCS and ED scores are calculated for weighting possible candidates. However, problems are that the correct word cannot always be the most looked like one. Taking the nonstandard word nite for example, note looks more likely than the correct form night. To overcome this problem, an exception dictionary of strongly-associated word pairs are constructed in (Gouws et al., 2011). Further, these pairs are added into a unified log-linear model in (Yang and Eisenstein, 2013) and Monte Carlo sampling techniques are used to estimate parameters. 2.2 Phonetic similarity The assumption underlying the phonetic similarity is that during transition, non-standard words sound like the standard counterparts, thus the pronunciation of non-standard words can be traced back to a standard dictionary. The challenge is the algorithm to annotate pronunciation of the nonstandard words. Double Metaphone algorithm (Philips, 2000) is used to decode pronunciation and then to represent phonetic similarity by edit distance of these transcripts (Han and Baldwin, 2011). IPA symbols are uti</context>
<context position="9281" citStr="Yang and Eisenstein, 2013" startWordPosition="1405" endWordPosition="1408">ula whose items are defined by TF-IDF scheme. A bipartite graph is constructed in (Hassan and Menezes, 2013) to represent tokens (both non-standard and standard words) and their context. Thus, random walks on the graph can represent contextual-similarity between non-standard and standard words. Very recently, word-embedding (Mikolov et al., 2010; Mikolov et al., 2013) is utilized in (Li and Liu, 2014) to represent more complex contextual relationship. In word-to-word candidate selection, most researches use orthographical similarity and phonetic similarity separately. In the log-linear model (Yang and Eisenstein, 2013), edit distance is modeled as major feature. In the character- and phonebased approaches (Li and Liu, 2012b), orthographical information and phonetic information were treated separately to generate candidates. In (Han and Baldwin, 2011), candidates from lexical edit distance and phonemic edit distance are merged together. Then an up to 16% increasing recall was reported when adding candidates from phonetic measure. But improper processing level makes it difficult to model the two types of information simultaneously: (1) Single character can hardly reflect orthographical features of one word. (</context>
<context position="18289" citStr="Yang and Eisenstein, 2013" startWordPosition="2788" endWordPosition="2791">dered. Thus letter-to-sound conversion tools are required. Several TTS system can perform the task according to some linguistic rules, even for nonstandard words. The Double Metaphone algorithm used in (Han and Baldwin, 2011) is one of them. But it uses consonants to encode a word, which gives less information than we need. In our method, we use freeTTS (Walker et al., 2002) with CMU lexicon1 to transform words into APRAbet2 symbols. For example, word tomorrow is transcribed to {T-UW M-AA R-OW} and tmr to {T M R}. 4.3 Dictionary preparation • Dictionary #1: In-vocabulary (IV) words Following (Yang and Eisenstein, 2013), our set of IV words is also based on the GNU aspell dictionary (v0.60.6). Differently, we use a collection of 100 million tweets (roughly the same size of Edinburgh Twitter corpus) because the Edinburgh Twitter corpus is no longer available due to Twitter policies. The 1http://www.speech.cs.cmu.edu/cgi-bin/cmudict 2http://en.wikipedia.org/wiki/Arpabet 924 final IV dictionary contains 51,948 standard words. • Dictionary #2: Syllables for the standard words Following (Pennell and Liu, 2010), we use the online dictionary3 to extract syllables for each standard words. We encountered same problem</context>
<context position="21177" citStr="Yang and Eisenstein, 2013" startWordPosition="3222" endWordPosition="3225">1)), the 3http://www.dictionary.com Kneser-Ney smoothed tri-gram language model is estimated using SRILM toolkit (Stolcke, 2002). Note that punctuations, hashtags, and username mentions have some syntactic value (Kaufmann and Kalita, 2010) to some extent, we replace them with ’&lt;PUNCT&gt;’, ’&lt;TOPIC&gt;’ and ’&lt;USER&gt;’. 5 Evaluation 5.1 Datasets We use two labeled twitter datasets in existence to evaluate our tweet normalization method. • LexNorm1.1 contains 549 complete tweets with 1184 non-standard tokens (558 unique word type) (Han and Baldwin, 2011). • LexNorm1.2 is a revised version of LexNorm1.1 (Yang and Eisenstein, 2013). Some inconsistencies and errors in LexNorm1.1 are corrected and some more non-standard words are properly recovered. In both datasets, to-be-normalized non-standard words are detected manually as well as the corresponding standard words. 5.2 Evaluation criteria Here we use precision, recall and F-score to evaluate our method. As normalization methods on these datasets focused on the labeled nonstandard words (Yang and Eisenstein, 2013), recall is the proportion of words requiring normalization which are normalized correctly; precision is the proportion of normalizations which are correct. Wh</context>
<context position="22503" citStr="Yang and Eisenstein, 2013" startWordPosition="3424" endWordPosition="3427">ve, so in the task, precision equals to recall. 5.3 Sentence level normalization We choose the following prior normalization methods: • (Liu et al., 2012): the extended characterlevel CRF tagging system; • (Yang and Eisenstein, 2013): log-linear model using string edit distance and longest common sequence measures as major features; • (Hassan and Menezes, 2013): bipartite graph major exploit contextual similarity; 925 Method Dataset Precision Recall F-measure (Han and Baldwin, 2011) 75.30 75.30 75.30 (Liu et al., 2012) 84.13 78.38 81.15 (Hassan and Menezes, 2013) LexNorm 1.1 85.37 56.4 69.93 (Yang and Eisenstein, 2013) 82.09 82.09 82.09 Syllable-based method 85.30 85.30 85.30 (Yang and Eisenstein, 2013) LexNorm 1.2 82.06 82.06 82.06 Syllable-based method 86.08 86.08 86.08 Table 3: Experiment results of the tweet normalization methods. • (Han and Baldwin, 2011): the orthographyphone combined system using lexical edit distance and phonemic edit distance. In our method, we set A=0.7 because it is found best in our experiments (see Figure 2). The experimental results are presented in Table 3, which indicate that our method outperforms the state-of-the-art methods. Details on how to adjust parameter is given in </context>
</contexts>
<marker>Yang, Eisenstein, 2013</marker>
<rawString>Yi Yang and Jacob Eisenstein. 2013. A log-linear model for unsupervised text normalization. In EMNLP, pages 61–72. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>