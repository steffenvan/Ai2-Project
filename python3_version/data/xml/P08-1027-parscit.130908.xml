<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001785">
<title confidence="0.9992055">
Classification of Semantic Relationships between Nominals
Using Pattern Clusters
</title>
<author confidence="0.992175">
Dmitry Davidov Ari Rappoport
</author>
<affiliation confidence="0.9996325">
ICNC Institute of Computer Science
Hebrew University of Jerusalem Hebrew University of Jerusalem
</affiliation>
<email confidence="0.99068">
dmitry@alice.nc.huji.ac.il arir@cs.huji.ac.il
</email>
<sectionHeader confidence="0.995506" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999701238095238">
There are many possible different semantic re-
lationships between nominals. Classification
of such relationships is an important and dif-
ficult task (for example, the well known noun
compound classification task is a special case
of this problem). We propose a novel pat-
tern clusters method for nominal relationship
(NR) classification. Pattern clusters are dis-
covered in a large corpus independently of
any particular training set, in an unsupervised
manner. Each of the extracted clusters cor-
responds to some unspecified semantic rela-
tionship. The pattern clusters are then used
to construct features for training and classifi-
cation of specific inter-nominal relationships.
Our NR classification evaluation strictly fol-
lows the ACL SemEval-07 Task 4 datasets and
protocol, obtaining an f-score of 70.6, as op-
posed to 64.8 of the best previous work that
did not use the manually provided WordNet
sense disambiguation tags.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9995315">
Automatic extraction and classification of seman-
tic relationships is a major field of activity, of both
practical and theoretical interest. A prominent type
of semantic relationships is that holding between
nominals1. For example, in noun compounds many
different semantic relationships are encoded by the
same simple form (Girju et al., 2005): ‘dog food’ de-
notes food consumed by dogs, while ‘summer morn-
</bodyText>
<footnote confidence="0.746003666666667">
1Our use of the term ‘nominal’ follows (Girju et al., 2007),
and includes simple nouns, noun compounds and multiword ex-
pressions serving as nouns.
</footnote>
<bodyText confidence="0.999864264705882">
ing’ denotes a morning that happens in the summer.
These two relationships are completely different se-
mantically but are similar syntactically, and distin-
guishing between them could be essential for NLP
applications such as question answering and ma-
chine translation.
Relation classification usually relies on a train-
ing set in the form of tagged data. To improve re-
sults, some systems utilize additional manually con-
structed semantic resources such as WordNet (WN)
(Beamer et al., 2007). However, in many domains
and languages such resources are not available. Fur-
thermore, usage of such resources frequently re-
quires disambiguation and connection of the data to
the resource (word sense disambiguation in the case
of WordNet). Manual disambiguation is unfeasible
in many practical tasks, and an automatic one may
introduce errors and greatly degrade performance. It
thus makes sense to try to minimize the usage of
such resources, and utilize only corpus contexts in
which the relevant words appear.
A leading method for utilizing context informa-
tion for classification and extraction of relationships
is that of patterns (Hearst, 1992; Pantel and Pen-
nacchiotti, 2006). The standard classification pro-
cess is to find in an auxiliary corpus a set of patterns
in which a given training word pair co-appears, and
use pattern-word pair co-appearance statistics as fea-
tures for machine learning algorithms.
In this paper we introduce a novel approach,
based on utilizing pattern clusters that are prepared
separately and independently of the training set. We
do not utilize any manually constructed resource or
any manual tagging of training data beyond the cor-
</bodyText>
<page confidence="0.970323">
227
</page>
<note confidence="0.715398">
Proceedings of ACL-08: HLT, pages 227–235,
</note>
<page confidence="0.537975">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.999918325581395">
rect classification, thus making our method applica-
ble to fully automated tasks and less domain and lan-
guage dependent. Moreover, our pattern clustering
algorithm is fully unsupervised.
Our method is based on the observation that while
each lexical pattern can be highly ambiguous, sev-
eral patterns in conjunction can reliably define and
represent a lexical relationship. Accordingly, we
construct pattern clusters from a large generic cor-
pus, each such cluster potentially representing some
important generic relationship. This step is done
without accessing any training data, anticipating that
most meaningful relationships, including those in a
given classification problem, will be represented by
some of the discovered clusters. We then use the
training set to label some of the clusters, and the la-
beled clusters to assign classes to tested items. One
of the advantages of our method is that it can be used
not only for classification, but also for further anal-
ysis and retrieval of the observed relationships2.
The semantic relationships between the compo-
nents of noun compounds and between nominals in
general are not easy to categorize rigorously. Sev-
eral different relationship hierarchies have been pro-
posed (Nastase and Szpakowicz, 2003; Moldovan et
al., 2004). Some classes, like Container-Contained,
Time-Event and Product-Producer, appear in sev-
eral classification schemes, while classes like Tool-
Object are more vaguely defined and are subdivided
differently. Recently, SemEval-07 Task 4 (Girju et
al., 2007) proposed a benchmark dataset that in-
cludes a subset of 7 widely accepted nominal rela-
tionship (NR) classes, allowing consistent evalua-
tion of different NR classification algorithms. In the
SemEval event, 14 research teams evaluated their al-
gorithms using this benchmark. Some of the teams
have used the manually annotated WN labels pro-
vided with the dataset, and some have not.
We evaluated our algorithm on SemEval-07 Task
4 data, showing superior results over participating
algorithms that did not utilize WordNet disambigua-
tion tags. We also show how pattern clusters can be
used for a completely unsupervised classification of
</bodyText>
<footnote confidence="0.9832798">
2In (Davidov and Rappoport, 2008) we focus on the pat-
tern cluster resource type itself, presenting an evaluation of its
intrinsic quality based on SAT tests. In the present paper we
focus on showing how the resource can be used to improve a
known NLP task.
</footnote>
<bodyText confidence="0.998757857142857">
the test set. Since in this case no training data is
used, this allows the automated discovery of a po-
tentially unbiased classification scheme.
Section 2 discusses related work, Section 3 out-
lines the pattern clustering algorithm, Section 4 de-
tails three classification methods, and Sections 5 and
6 describe the evaluation protocol and results.
</bodyText>
<sectionHeader confidence="0.999724" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999491142857143">
Numerous methods have been devised for classifica-
tion of semantic relationships, among which those
holding between nominals constitute a prominent
category. Major differences between these methods
include available resources, degree of preprocessing,
features used, classification algorithm and the nature
of training/test data.
</bodyText>
<subsectionHeader confidence="0.992457">
2.1 Available Resources
</subsectionHeader>
<bodyText confidence="0.99995196">
Many relation classification algorithms utilize
WordNet. Among the 15 systems presented by
the 14 SemEval teams, some utilized the manually
provided WordNet tags for the dataset pairs (e.g.,
(Beamer et al., 2007)). In all cases, usage of WN
tags improves the results significantly. Some other
systems that avoided using the labels used WN as
a supporting resource for their algorithms (Costello,
2007; Nakov and Hearst, 2007; Kim and Baldwin,
2007). Only three avoided WN altogether (Hen-
drickx et al., 2007; Bedmar et al., 2007; Aramaki
et al., 2006).
Other resources used for relationship discovery
include Wikipedia (Strube and Ponzetto, 2006), the-
sauri or synonym sets (Turney, 2005) and domain-
specific semantic hierarchies like MeSH (Rosario
and Hearst, 2001).
While usage of these resources is beneficial in
many cases, high quality word sense annotation is
not easily available. Besides, lexical resources are
not available for many languages, and their coverage
is limited even for English when applied to some re-
stricted domains. In this paper we do not use any
manually annotated resources apart from the classi-
fication training set.
</bodyText>
<subsectionHeader confidence="0.999698">
2.2 Degree of Preprocessing
</subsectionHeader>
<bodyText confidence="0.915943">
Many relationship classification methods utilize
some language-dependent preprocessing, like deep
or shallow parsing, part of speech tagging and
</bodyText>
<page confidence="0.996378">
228
</page>
<bodyText confidence="0.999719333333333">
named entity annotation (Pantel et al., 2004). While
the obtained features were shown to improve classi-
fication performance, they tend to be language de-
pendent and error-prone when working on unusual
text domains and are also highly computationally in-
tensive when processing large corpora. To make our
approach as language independent and efficient as
possible, we avoided using any such preprocessing
techniques.
</bodyText>
<subsectionHeader confidence="0.999286">
2.3 Classification Features
</subsectionHeader>
<bodyText confidence="0.999993277777778">
A wide variety of features are used by different
algorithms, ranging from simple bag-of-words fre-
quencies to WordNet-based features (Moldovan et
al., 2004). Several studies utilize syntactic features.
Many other works manually develop a set of heuris-
tic features devised with some specific relationship
in mind, like a WordNet-based meronymy feature
(Bedmar et al., 2007) or size-of feature (Aramaki
et al., 2006). However, the most prominent feature
type is based on lexico-syntactic patterns in which
the related words co-appear.
Since (Hearst, 1992), numerous works have used
patterns for discovery and identification of instances
of semantic relationships (e.g., (Girju et al., 2006;
Snow et al., 2006; Banko et al, 2007)). Rosenfeld
and Feldman (2007) discover relationship instances
by clustering entities appearing in similar contexts.
Strategies were developed for discovery of multi-
ple patterns for some specified lexical relationship
(Pantel and Pennacchiotti, 2006) and for unsuper-
vised pattern ranking (Turney, 2006). Davidov et
al. (2007) use pattern clusters to define general rela-
tionships, but these are specific to a given concept.
No study so far has proposed a method to define, dis-
cover and represent general relationships present in
an arbitrary corpus.
In (Davidov and Rappoport, 2008) we present
an approach to extract pattern clusters from an un-
tagged corpus. Each such cluster represents some
unspecified lexical relationship. In this paper, we
use these pattern clusters as the (only) source of ma-
chine learning features for a nominal relationship
classification problem. Unlike the majority of cur-
rent studies, we avoid using any other features that
require some language-specific information or are
devised for specific relationship types.
</bodyText>
<subsectionHeader confidence="0.996388">
2.4 Classification Algorithm
</subsectionHeader>
<bodyText confidence="0.999986416666667">
Various learning algorithms have been used for re-
lation classification. Common choices include vari-
ations of SVM (Girju et al., 2004; Nastase et al.,
2006), decision trees and memory-based learners.
Freely available tools like Weka (Witten and Frank,
1999) allow easy experimentation with common
learning algorithms (Hendrickx et al., 2007). In this
paper we did not focus on a single ML algorithm,
letting algorithm selection be automatically based
on cross-validation results on the training set, as in
(Hendrickx et al., 2007) but using more algorithms
and allowing a more flexible parameter choice.
</bodyText>
<subsectionHeader confidence="0.995768">
2.5 Training Data
</subsectionHeader>
<bodyText confidence="0.9999843125">
As stated above, several categorization schemes for
nominals have been proposed. Nastase and Sz-
pakowicz (2003) proposed a two-level hierarchy
with 5 (30) classes at the top (bottom) levels3. This
hierarchy and a corresponding dataset were used in
(Turney, 2005; Turney, 2006) and (Nastase et al.,
2006) for evaluation of their algorithms. Moldovan
et al. (2004) proposed a different scheme with 35
classes. The most recent dataset has been developed
for SemEval 07 Task 4 (Girju et al., 2007). This
manually annotated dataset includes a representative
rather than exhaustive list of 7 important nominal
relationships. We have used this dataset, strictly fol-
lowing the evaluation protocol. This made it possi-
ble to meaningfully compare our method to state-of-
the-art methods for relation classification.
</bodyText>
<sectionHeader confidence="0.983382" genericHeader="method">
3 Pattern Clustering Algorithm
</sectionHeader>
<bodyText confidence="0.998735071428571">
Our pattern clustering algorithm is designed for the
unsupervised definition and discovery of generic se-
mantic relationships. The algorithm first discovers
and clusters patterns in which a single (‘hook’) word
participates, and then merges the resulting clusters
to form the final structure. In (Davidov and Rap-
poport, 2008) we describe the algorithm at length,
discuss its behavior and parameters in detail, and
evaluate its intrinsic quality. To assist readers of
the present paper, in this section we provide an
overview. Examples of some resulting pattern clus-
ters are given in Section 6. We refer to a pattern
3Actually, there were 50 relationships at the bottom level,
but valid nominal instances were found only for 30.
</bodyText>
<page confidence="0.990775">
229
</page>
<bodyText confidence="0.999990769230769">
contained in our clusters (a pattern type) as a ‘pat-
tern’ and to an occurrence of a pattern in the corpus
(a pattern token) as a ‘pattern instance’.
The algorithm does not rely on any data from the
classification training set, hence we do not need to
repeat its execution for different classification prob-
lems. To calibrate its parameters, we ran it a few
times with varied parameters settings, producing
several different configurations of pattern clusters
with different degrees of noise, coverage and granu-
larity. We then chose the best configuration for our
task automatically without re-running pattern clus-
tering for each specific problem (see Section 5.3).
</bodyText>
<subsectionHeader confidence="0.999795">
3.1 Hook Words and Hook Corpora
</subsectionHeader>
<bodyText confidence="0.999991272727273">
As a first step, we randomly sample a set of hook
words, which will be used in order to discover re-
lationships that generally occur in the corpus. To
avoid selection of ambiguous words or typos, we do
not select words with frequency higher than a pa-
rameter FC and lower than a threshold FB. We also
limit the total number N of hook words. For each
hook word, we now create a hook corpus, the set of
the contexts in which the word appears. Each con-
text is a window containing W words or punctuation
characters before and after the hook word.
</bodyText>
<subsectionHeader confidence="0.999568">
3.2 Pattern Specification
</subsectionHeader>
<bodyText confidence="0.9859155625">
To specify patterns, following (Davidov and Rap-
poport, 2006) we classify words into high-
frequency words (HFWs) and content words (CWs).
A word whose frequency is more (less) than FH
(FC) is considered to be a HFW (CW). Our patterns
have the general form
[Prefix] CW1 [Infix] CW2 [Postfix]
where Prefix, Infix and Postfix contain only HFWs.
We require Prefix and Postfix to be a single HFW,
while Infix can contain any number of HFWs (limit-
ing pattern length by window size). This form may
include patterns like ‘such X as Y and’. At this stage,
the pattern slots can contain only single words; how-
ever, when using the final pattern clusters for nomi-
nal relationship classification, slots can contain mul-
tiword nominals.
</bodyText>
<subsectionHeader confidence="0.9993">
3.3 Discovery of Target Words
</subsectionHeader>
<bodyText confidence="0.998440272727273">
For each of the hook corpora, we now extract all
pattern instances where one CW slot contains the
hook word and the other CW slot contains some
other (‘target’) word. To avoid the selection of com-
mon words as target words, and to avoid targets ap-
pearing in pattern instances that are relatively fixed
multiword expressions, we sort all target words in
a given hook corpus by pointwise mutual informa-
tion between hook and target, and drop patterns ob-
tained from pattern instances containing the lowest
and highest L percent of target words.
</bodyText>
<subsectionHeader confidence="0.95565">
3.4 Pattern Clustering
</subsectionHeader>
<bodyText confidence="0.999412142857143">
We now have for each hook corpus a set of patterns,
together with the target words used for their extrac-
tion, and we want to cluster pattern types. First,
we group in clusters all patterns extracted using the
same target word. Second, we merge clusters that
share more than S percent of their patterns. Some
patterns can appear in more than a single cluster.
Finally, we merge pattern clusters from different
hook corpora, to avoid clusters specific to a single
hook word. During merging, we define and utilize
core patterns and unconfirmed patterns, which are
weighed differently during cluster labeling (see Sec-
tion 4.2). We merge clusters from different hook
corpora using the following algorithm:
</bodyText>
<listItem confidence="0.4553845">
1. Remove all patterns originating from a single hook
corpus only.
2. Mark all patterns of all present clusters as uncon-
firmed.
3. While there exists some cluster C1 from corpus DX
containing only unconfirmed patterns:
(a) Select a cluster with a minimal number of pat-
terns.
(b) For each corpus D different from DX:
i. Scan D for clusters C2 that share at least
S percent of their patterns, and all of their
core patterns, with C1.
ii. Add all patterns of C2 to C1, setting all
shared patterns as core and all others as
unconfirmed.
iii. Remove cluster C2.
(c) If all of C1’s patterns remain unconfirmed re-
move C1.
4. If several clusters have the same set of core patterns
merge them according to rules (i,ii).
</listItem>
<bodyText confidence="0.974935666666667">
At the end of this stage, we have a set of pattern
clusters where for each cluster there are two subsets,
core patterns and unconfirmed patterns.
</bodyText>
<page confidence="0.990071">
230
</page>
<sectionHeader confidence="0.998376" genericHeader="method">
4 Relationship Classification
</sectionHeader>
<bodyText confidence="0.9999195">
Up to this stage we did not access the training set in
any way and we did not use the fact that the target re-
lations are those holding between nominals. Hence,
only a small part of the acquired pattern clusters may
be relevant for a given NR classification task, while
other clusters can represent completely different re-
lationships (e.g., between verbs). We now use the
acquired clusters to learn a model for the given la-
beled training set and to use this model for classifi-
cation of the test set. First we describe how we deal
with data sparseness. Then we propose a HITS mea-
sure used for cluster labeling, and finally we present
three different classification methods that utilize pat-
tern clusters.
</bodyText>
<subsectionHeader confidence="0.997798">
4.1 Enrichment of Provided Data
</subsectionHeader>
<bodyText confidence="0.999916272727273">
Our classification algorithm is based on contexts
of given nominal pairs. Co-appearance of nomi-
nal pairs can be very rare (in fact, some word pairs
in the Task 4 set co-appear only once in Yahoo
web search). Hence we need more contexts where
the given nominals or nominals similar to them co-
appear. This step does not require the training la-
bels (the correct classifications), so we do it for both
training and test pairs. We do it in two stages: ex-
tracting similar nominals, and obtaining more con-
texts.
</bodyText>
<subsectionHeader confidence="0.803807">
4.1.1 Extracting more words
</subsectionHeader>
<bodyText confidence="0.969776575">
For each nominal pair (w1, w2) in a given sentence
5, we use a method similar to (Davidov and Rap-
poport, 2006) to extract words that have a shared
meaning with w1 or w2. We discover such words
by scanning our corpora and querying the web for
symmetric patterns (obtained automatically from the
corpus as in (Davidov and Rappoport, 2006)) that
contain w1 or w2. To avoid getting instances of
w1,2 with a different meaning, we also require that
the second word will appear in the same text para-
graph or the same web page. For example, if we are
given a pair &lt;loans, students&gt; and we see a sen-
tence ‘... loans and scholarships for students and
professionals ...’, we use the symmetric pattern ‘X
and Y’ to add the word scholarships to the group of
loans and to add the word professionals to the group
of students. We do not take words from the sen-
tence ‘In European soccer there are transfers and
loans...’ since its context does not contain the word
students. In cases where there are only several or
zero instances where the two nominals co-appear,
we dismiss the latter rule and scan for each nominal
separately. Note that ‘loans’ can also be a verb, so
usage of a part-of-speech tagger might reduce noise.
If the number of instances for a desired nom-
inal is very low, our algorithm trims the first
words in these nominal and repeats the search (e.g.,
&lt;simulation study, voluminous results&gt; becomes
&lt;study, results&gt;). This step is the only one specific
to English, using the nature of English noun com-
pounds. Our desire in this case is to keep the head
words.
4.1.2 Extracting more contexts using the new
words
To find more instances where nominals similar to
w1 and w2 co-appear in HFW patterns, we construct
web queries using combinations of each nominal’s
group and extract patterns from the search result
snapshots (the two line summary provided by search
engines for each search result).
</bodyText>
<subsectionHeader confidence="0.960569">
4.2 The HITS Measure
</subsectionHeader>
<bodyText confidence="0.999709888888889">
To use clusters for classification we define a HITS
measure similar to that of (Davidov et al., 2007), re-
flecting the affinity of a given nominal pair to a given
cluster. We use the pattern clusters from Section 3
and the additional data collected during the enrich-
ment phase to estimate a HITS value for each cluster
and each pair in the training and test sets. For a given
nominal pair (w1, w2) and cluster C with n core pat-
terns PcoT, and m unconfirmed patterns Punconf,
</bodyText>
<equation confidence="0.927001666666667">
HITS(C, (w1, w2)) _
|{p; (w1, w2) appears in p E PcoT�} |/n+
α x |{p; (w1, w2) appears in p E Punconf} |/m.
</equation>
<bodyText confidence="0.998709375">
In this formula, ‘appears in’ means that the nomi-
nal pair appears in instances of this pattern extracted
from the original corpus or retrieved from the web
at the previous stage. Thus if some pair appears in
most of the patterns of some cluster it receives a high
HITS value for this cluster. α (0..1) is a parameter
that lets us modify the relative weight of core and
unconfirmed patterns.
</bodyText>
<page confidence="0.993258">
231
</page>
<subsectionHeader confidence="0.996467">
4.3 Classification Using Pattern Clusters
</subsectionHeader>
<bodyText confidence="0.9998805">
We present three ways to use pattern clusters for re-
lationship classification.
</bodyText>
<subsectionHeader confidence="0.648349">
4.3.1 Classification by cluster labeling
</subsectionHeader>
<bodyText confidence="0.999958857142857">
One way to train a classifier in our case is to attach
a single relationship label to each cluster during the
training phase, and to assign each unlabeled pair to
some labeled cluster during the test phase. We use
the following normalized HITS measure to label the
involved pattern clusters. Denote by ki the number
of training pairs in class i in training set T. Then
</bodyText>
<equation confidence="0.9944905">
�Label(C) = argmaxi hits(C, p)/ki
pET,Label(p)=i
</equation>
<bodyText confidence="0.989413842105263">
Clusters where the above sum is zero remain un-
labeled. In the test phase we assign to each test pair
p the label of the labeled cluster C that received the
highest HITS(C, p) value. If there are several clus-
ters with a highest HITS value, then the algorithm se-
lects a ‘clarifying’ set of patterns – patterns that are
different in these best clusters. Then it constructs
clarifying web queries that contain the test nomi-
nal pair inside the clarifying patterns. The effect is
to increment the HITS value of the cluster contain-
ing a clarifying pattern if an appropriate pattern in-
stance (including the target nominals) was found on
the web. We start with the most frequent clarifying
pattern and perform additional queries until no clar-
ifying patterns are left or until some labeled cluster
obtains a highest HITS value. If no patterns are left
but there are still several winning clusters, we assign
to the pair the label of the cluster with the largest
number of pattern instances in the corpus.
One advantage of this method is that we get as
a by-product a set of labeled pattern clusters. Ex-
amination of this set can help to distinguish and an-
alyze (by means of patterns) which different rela-
tionships actually exist for each class in the train-
ing set. Furthermore, labeled pattern clusters can be
used for web queries to obtain additional examples
of the same relationship.
4.3.2 Classification by cluster HITS values as
features
In this method we treat the HITS measure for a clus-
ter as a feature for a machine learning classification
algorithm. To do this, we construct feature vectors
from each training pair, where each feature is the
HITS measure corresponding to a single pattern clus-
ter. We prepare test vectors similarly. Once we have
feature vectors, we can use a variety of classifiers
(we used those in Weka) to construct a model and to
evaluate it on the test set.
</bodyText>
<subsectionHeader confidence="0.638428">
4.3.3 Unsupervised clustering
</subsectionHeader>
<bodyText confidence="0.999951555555555">
If we are not given any training set, it is still possi-
ble to separate between different relationship types
by grouping the feature vectors of Section 4.3.2 into
clusters. This can be done by applying k-means or
another clustering algorithm to the feature vectors
described above. This makes the whole approach
completely unsupervised. However, it does not pro-
vide any inherent labeling, making an evaluation dif-
ficult.
</bodyText>
<sectionHeader confidence="0.999137" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999966545454545">
The main problem in a fair evaluation of NR classifi-
cation is that there is no widely accepted list of pos-
sible relationships between nominals. In our eval-
uation we have selected the setup and data from
SemEval-07 Task 4 (Girju et al., 2007). Selecting
this type of dataset allowed us to compare to 6 sub-
mitted state-of-art systems that evaluated on exactly
the same data and to 9 other systems that utilize
additional information (WN labels). We have ap-
plied our three different classification methods on
the given data set.
</bodyText>
<subsectionHeader confidence="0.993376">
5.1 SemEval-07 Task 4 Overview
</subsectionHeader>
<bodyText confidence="0.999861">
Task 4 (Girju et al., 2007) involves classification of
relationships between simple nominals other than
named entities. Seven distinct relationships were
chosen: Cause-Effect, Instrument-Agency, Product-
Producer, Origin-Entity, Theme-Tool, Part-Whole,
and Content-Container. For each relationship, the
provided dataset consists of 140 training and 70 test
examples. Examples were binary tagged as belong-
ing/not belonging to the tested relationship. The vast
majority of negative examples were near-misses, ac-
quired from the web using the same lexico-syntactic
patterns as the positives. Examples appear as sen-
tences with the nominal pair tagged. Nouns in this
pair were manually labeled with their correspond-
ing WordNet 3 labels and the web queries used to
</bodyText>
<page confidence="0.985132">
232
</page>
<bodyText confidence="0.999925875">
obtain the sentences. The 15 submitted systems
were assigned into 4 categories according to whether
they use the WordNet and Query tags (some systems
were assigned to more than a single category, since
they reported experiments in several settings). In our
evaluation we do not utilize WordNet or Query tags,
hence we compare ourselves with the corresponding
group (A), containing 6 systems.
</bodyText>
<subsectionHeader confidence="0.996925">
5.2 Corpus and Web Access
</subsectionHeader>
<bodyText confidence="0.9989414375">
Our algorithm uses two corpora. We estimate fre-
quencies and perform primary search on a local web
corpus containing about 68GB untagged plain text.
This corpus was extracted from the web starting
from open directory links, comprising English web
pages with varied topics and styles (Gabrilovich and
Markovitch, 2005). To enrich the set of given word
pairs and patterns as described in Section 4.1 and
to perform clarifying queries, we utilize the Yahoo
API for web queries. For each query, if the desired
words/patterns were found in a page link’s snapshot,
we do not use the link, otherwise we download the
page from the retrieved link and then extract the re-
quired data. If only several links were found for a
given word pair we perform local crawling to depth
3 in an attempt to discover more instances.
</bodyText>
<subsectionHeader confidence="0.998192">
5.3 Parameters and Learning Algorithm
</subsectionHeader>
<bodyText confidence="0.999979106382979">
Our algorithm utilizes several parameters. Instead
of calibrating them manually, we only provided
a desired range for each, and the final parameter
values were obtained during selection of the best-
performing setup using 10-fold cross-validation on
the training set. For each parameter we have esti-
mated its desired range using the (Nastase and Sz-
pakowicz, 2003) set as a development set. Note that
this set uses an entirely different relationship classi-
fication scheme. We ran the pattern clustering phase
on 128 different sets of parameters, obtaining 128
different clustering schemes with varied granularity,
noise and coverage.
The parameter ranges obtained are: FC (meta-
pattern content word frequency and upper bound for
hook word selection): 100 − 5000 words per million
(wpm); FH (meta-pattern HFW): 10 − 100 wpm;
FB (low word count for hook word filtering): 1− 50
wpm; N (number of hook words): 100 − 1000; W
(window size): 5 or window = sentence; L (tar-
get word mutual information filter): 1/3 − 1/5; 5
(cluster overlap filter for cluster merging): 2/3; α
(core vs. unconfirmed weight for HITS estimation):
0.1 − 0.01; 5 (commonality for cluster merging):
2/3. As designed, each parameter indeed influences
a certain effect. Naturally, the parameters are not
mutually independent. Selecting the best configu-
ration in the cross-validation phase makes the algo-
rithm flexible and less dependent on hard-coded pa-
rameter values.
Selection of learning algorithm and its algorithm-
specific parameters were done as follows. For each
of the 7 classification tasks (one per relationship
type), for each of the 128 pattern clustering schemes,
we prepared a list of most of the compatible al-
gorithms available in Weka, and we automatically
selected the model (a parameter set and an algo-
rithm) which gave the best 10-fold cross-validation
results. The winning algorithms were LWL (Atke-
son et al., 1997), SMO (Platt, 1999), and K* (Cleary
and Trigg, 1995) (there were 7 tasks, and different
algorithms could be selected for each task). We then
used the obtained model to classify the testing set.
This allowed us to avoid fixing parameters that are
best for a specific dataset but not for others. Since
each dataset has only 140 examples, the computa-
tion time of each learning algorithm is negligible.
</bodyText>
<sectionHeader confidence="0.999873" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.998759666666666">
The pattern clustering phase results in 90 to 3000
distinct pattern clusters, depending on the parameter
setup. Manual sampling of these clusters indeed re-
veals that many clusters contain patterns specific to
some apparent lexical relationship. For example, we
have discovered such clusters as: {‘buy Y accessory
for X!’, ‘shipping Yfor X’, ‘Y is available for X’, ‘Y
are available for X’, ‘Y are available forX systems’,
‘Y for X’ } and {‘best X for Y’, ‘X types for Y’, ‘Y
with X’, ‘X is required for Y’, ‘X as required for Y’,
‘Xfor Y’}. Note that some patterns (‘Y for X’) can
appear in many clusters.
We applied the three classification methods de-
scribed in Section 4.3 to Task 4 data. For super-
vised classification we strictly followed the SemEval
datasets and rules. For unsupervised classification
we did not use any training data. Using the k-means
algorithm, we obtained two nearly equal unlabeled
</bodyText>
<page confidence="0.995336">
233
</page>
<table confidence="0.999771">
Method P R F Acc
Unsupervised clustering (4.3.3) 64.5 61.3 62.0 64.5
Cluster Labeling (4.3.1) 65.1 69.0 67.2 68.5
HITS Features (4.3.2) 69.1 70.6 70.6 70.1
Best Task 4 (no WordNet) 66.1 66.7 64.8 66.0
Best Task 4 (with WordNet) 79.7 69.8 72.4 76.3
</table>
<tableCaption confidence="0.96869">
Table 1: Our SemEval-07 Task 4 results.
</tableCaption>
<table confidence="0.999970125">
Relation Type F Acc C
Cause-Effect 69.7 71.4 2
Instrument-Agency 76.5 74.2 1
Product-Producer 76.4 83.8 1
Origin-Entity 65.4 62.6 4
Theme-Tool 59.4 58.7 6
Part-Whole 74.3 70.9 1
Content-Container 72.6 69.2 2
</table>
<tableCaption confidence="0.961639">
Table 2: By-relation Task 4 HITS-based results. C is the
number of clusters with positive labels.
</tableCaption>
<bodyText confidence="0.999486136363636">
clusters containing test samples. For evaluation we
assigned a negative/positive label to these two clus-
ters according to the best alignment with true labels.
Table 1 shows our results, along with the best Task
4 result not using WordNet labels (Costello, 2007).
For reference, the best results overall (Beamer et al.,
2007) are also shown. The table shows precision (P)
recall (R), F-score (F), and Accuracy (Acc) (percent-
age of correctly classified examples).
We can see that while our algorithm is not as good
as the best method that utilizes WordNet tags, results
are superior to all participants who did not use these
tags. We can also see that the unsupervised method
results are above the random baseline (50%). In fact,
our results (f-score 62.0, accuracy 64.5) are better
than the averaged results (58.0, 61.1) of the group
that did not utilize WN tags.
Table 2 shows the HITS-based classification re-
sults (F-score and Accuracy) and the number of pos-
itively labeled clusters (C) for each relation. As ob-
served by participants of Task 4, we can see that dif-
ferent sets vary greatly in difficulty. However, we
also obtain a nice insight as to why this happens –
relations like Theme-Tool seem very ambiguous and
are mapped to several clusters, while relations like
Product-Producer seem to be well-defined by the ob-
tained pattern clusters.
The SemEval dataset does not explicitly mark
items whose correct classification requires analysis
of the context of the whole sentence in which they
appear. Since our algorithm does not utilize test sen-
tence contextual information, we do not expect it to
show exceptional performance on such items. This
is a good topic for future research.
Since the SemEval dataset is of a very spe-
cific nature, we have also applied our classification
framework to the (Nastase and Szpakowicz, 2003)
dataset, which contains 600 pairs labeled with 5
main relationship types. We have used the exact
evaluation procedure described in (Turney, 2006),
achieving a class f-score average of 60.1, as opposed
to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al.,
2006). This shows that our method produces supe-
rior results for rather differing datasets.
</bodyText>
<sectionHeader confidence="0.999042" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999890476190476">
Relationship classification is known to improve
many practical tasks, e.g., textual entailment (Tatu
and Moldovan, 2005). We have presented a novel
framework for relationship classification, based on
pattern clusters prepared as a standalone resource in-
dependently of the training set.
Our method outperforms current state-of-the-art
algorithms that do not utilize WordNet tags on Task
4 of SemEval-07. In practical situations, it would
not be feasible to provide a large amount of such
sense disambiguation tags manually. Our method
also shows competitive performance compared to
the majority of task participants that do utilize WN
tags. Our method can produce labeled pattern clus-
ters, which can be potentially useful for automatic
discovery of additional instances for a given rela-
tionship. We intend to pursue this promising direc-
tion in future work.
Acknowledgement. We would like to thank
the anonymous reviewers, whose comments have
greatly improved the quality of this paper.
</bodyText>
<sectionHeader confidence="0.998971" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9978225">
Aramaki, E., Imai, T., Miyo, K., and Ohe, K., 2007.
UTH: semantic relation classification using physical
sizes. ACL SemEval ’07 Workshop.
Atkeson, C., Moore, A., and Schaal, S., 1997. Lo-
cally weighted learning. Arti�cial Intelligence Review,
11(1–5): 75–113.
</reference>
<page confidence="0.976833">
234
</page>
<reference confidence="0.999750806122448">
Banko, M., Cafarella, M. J., Soderland, S., Broadhead,
M., and Etzioni, O., 2007. Open information extrac-
tion from the Web. IJCAI ’07.
Beamer, B., Bhat, S., Chee, B., Fister, A., Rozovskaya
A., and Gir u, R., 2007. UIUC: A knowledge-rich ap-
proach to identifying semantic relations between nom-
inals. ACL SemEval ’07 Workshop.
Bedmar, I. S., Samy, D., and Martinez, J. L., 2007.
UC3M: Classification of semantic relations between
nominals using sequential minimal optimization. ACL
SemEval ’07 Workshop.
Cleary, J. G. , Trigg, L. E., 1995. K*: An instance-based
learner using and entropic distance measure. ICML
’95.
Costello, F. J., 2007. UCD-FC: Deducing semantic rela-
tions using WordNet senses that occur frequently in a
database of noun-noun compounds. ACL SemEval ’07
Workshop.
Davidov, D., Rappoport, A., 2006. Efficient unsuper-
vised discovery of word categories using symmetric
patterns and high frequency words. COLING-ACL ’06
Davidov D., Rappoport A. and Koppel M., 2007. Fully
unsupervised discovery of concept-specific relation-
ships by Web mining. ACL ’07.
Davidov, D., Rappoport, A., 2008. Unsupervised discov-
ery of generic relationships using pattern clusters and
its evaluation by automatically generated SAT analogy
questions. ACL ’08.
Gabrilovich, E., Markovitch, S., 2005. Feature gener-
ation for text categorization using world knowledge.
IJCAI ’05.
Gir u, R., Giuglea, A., Olteanu, M., Fortu, O., Bolohan,
O., and Moldovan, D., 2004. Support vector ma-
chines applied to the classification of semantic rela-
tions in nominalized noun phrases. HLT/NAACL ’04
Workshop on Computational Lexical Semantics.
Gir u, R., Moldovan, D., Tatu, M., and Antohe, D., 2005.
On the semantics of noun compounds. Computer
Speech and Language, 19(4):479-496.
Gir u, R., Badulescu, A., and Moldovan, D., 2006. Au-
tomatic discovery of part-whole relations. Computa-
tional Linguistics, 32(1).
Gir u, R., Hearst, M., Nakov, P., Nastase, V., Szpakowicz,
S., Turney, P., and Yuret, D., 2007. Task 04: Classi-
fication of semantic relations between nominal at Se-
mEval 2007. 4th Intl. Workshop on Semantic Evalua-
tions (SemEval ’07), in ACL ’07.
Hearst, M., 1992. Automatic acquisition of hyponyms
from large text corpora. COLING ’92
Hendrickx, I., Morante, R., Sporleder, C., and van den
Bosch, A., 2007. Machine learning of semantic rela-
tions with shallow features and almost no data. ACL
SemEval ’07 Workshop.
Kim, S.N., Baldwin, T., 2007. MELB-KB: Nominal
classification as noun compound interpretation. ACL
SemEval ’07 Workshop.
Moldovan, D., Badulescu, A., Tatu, M., Antohe, D., and
Gir u, R., 2004. Models for the semantic classifica-
tion of noun phrases. HLT-NAACL ’04 Workshop on
Computational Lexical Semantics.
Nakov, P., and Hearst, M., 2007. UCB: System descrip-
tion for SemEval Task #4. ACL SemEval ’07 Work-
shop.
Nastase, V., Szpakowicz, S., 2003. Exploring noun-
modifier semantic relations. In Fifth Intl. Workshop
on Computational Semantics (IWCS-5).
Nastase, V., Sayyad-Shirabad, J., Sokolova, M., and Sz-
pakowicz, S., 2006. Learning noun-modifier semantic
relations with corpus-based and WordNet-based fea-
tures. In Proceedings of the 21st National Conference
on Arti�cial Intelligence, Boston, MA.
Pantel, P., Ravichandran, D., and Hovy, E., 2004. To-
wards terascale knowledge acquisition. COLING ’04.
Pantel, P., Pennacchiotti, M., 2006. Espresso: leveraging
generic patterns for automatically harvesting semantic
relations. COLING-ACL ’06.
Platt, J., 1999. Fast training of support vector machines
using sequential minimal optimization. In Scholkopf,
Burges, and Smola, Advances in Kernel Methods –
Support Vector Learning, pp. 185–208. MIT Press.
Rosario, B., Hearst, M., 2001. Classifying the semantic
relations in noun compounds. EMNLP ’01.
Rosenfeld, B., Feldman, R., 2007. Clustering for unsu-
pervised relation identification. CIKM ’07.
Snow, R., Jurafsky, D., Ng, A.Y., 2006. Seman-
tic taxonomy induction from heterogeneous evidence.
COLING-ACL ’06.
Strube, M., Ponzetto, S., 2006. WikiRelate! computing
semantic relatedness using Wikipedia. AAAI ’06.
Tatu, M., Moldovan, D., 2005. A semantic approach to
recognizing textual entailment. HLT/EMNLP ’05.
Turney, P., 2005. Measuring semantic similarity by la-
tent relational analysis. IJCAI ’05.
Turney, P., 2006. Expressing implicit semantic relations
without supervision. COLING-ACL ’06.
Witten, H., Frank, E., 1999. Data Mining: Practical Ma-
chine Learning Tools and Techniques with Java Imple-
mentations. Morgan Kaufman, San Francisco, CA.
</reference>
<page confidence="0.998534">
235
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.963169">
<title confidence="0.9986005">Classification of Semantic Relationships between Nominals Using Pattern Clusters</title>
<author confidence="0.99755">Dmitry Davidov Ari Rappoport</author>
<affiliation confidence="0.9997375">ICNC Institute of Computer Science Hebrew University of Jerusalem Hebrew University of Jerusalem</affiliation>
<email confidence="0.976894">dmitry@alice.nc.huji.ac.ilarir@cs.huji.ac.il</email>
<abstract confidence="0.999571363636364">There are many possible different semantic relationships between nominals. Classification of such relationships is an important and difficult task (for example, the well known noun compound classification task is a special case this problem). We propose a novel patclusters for nominal relationship (NR) classification. Pattern clusters are discovered in a large corpus independently of any particular training set, in an unsupervised manner. Each of the extracted clusters corresponds to some unspecified semantic relationship. The pattern clusters are then used to construct features for training and classification of specific inter-nominal relationships. Our NR classification evaluation strictly follows the ACL SemEval-07 Task 4 datasets and protocol, obtaining an f-score of 70.6, as opposed to 64.8 of the best previous work that did not use the manually provided WordNet sense disambiguation tags.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Aramaki</author>
<author>T Imai</author>
<author>K Miyo</author>
<author>K Ohe</author>
</authors>
<title>UTH: semantic relation classification using physical sizes.</title>
<date>2007</date>
<journal>ACL SemEval</journal>
<volume>07</volume>
<pages>Workshop.</pages>
<marker>Aramaki, Imai, Miyo, Ohe, 2007</marker>
<rawString>Aramaki, E., Imai, T., Miyo, K., and Ohe, K., 2007. UTH: semantic relation classification using physical sizes. ACL SemEval ’07 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Atkeson</author>
<author>A Moore</author>
<author>S Schaal</author>
</authors>
<title>Locally weighted learning.</title>
<date>1997</date>
<journal>Arti�cial Intelligence Review,</journal>
<volume>11</volume>
<issue>1</issue>
<pages>75--113</pages>
<contexts>
<context position="28142" citStr="Atkeson et al., 1997" startWordPosition="4552" endWordPosition="4556">independent. Selecting the best configuration in the cross-validation phase makes the algorithm flexible and less dependent on hard-coded parameter values. Selection of learning algorithm and its algorithmspecific parameters were done as follows. For each of the 7 classification tasks (one per relationship type), for each of the 128 pattern clustering schemes, we prepared a list of most of the compatible algorithms available in Weka, and we automatically selected the model (a parameter set and an algorithm) which gave the best 10-fold cross-validation results. The winning algorithms were LWL (Atkeson et al., 1997), SMO (Platt, 1999), and K* (Cleary and Trigg, 1995) (there were 7 tasks, and different algorithms could be selected for each task). We then used the obtained model to classify the testing set. This allowed us to avoid fixing parameters that are best for a specific dataset but not for others. Since each dataset has only 140 examples, the computation time of each learning algorithm is negligible. 6 Results The pattern clustering phase results in 90 to 3000 distinct pattern clusters, depending on the parameter setup. Manual sampling of these clusters indeed reveals that many clusters contain pat</context>
</contexts>
<marker>Atkeson, Moore, Schaal, 1997</marker>
<rawString>Atkeson, C., Moore, A., and Schaal, S., 1997. Locally weighted learning. Arti�cial Intelligence Review, 11(1–5): 75–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Banko</author>
<author>M J Cafarella</author>
<author>S Soderland</author>
<author>M Broadhead</author>
<author>O Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open information extraction from the Web. IJCAI ’07.</booktitle>
<contexts>
<context position="9152" citStr="Banko et al, 2007" startWordPosition="1384" endWordPosition="1387">o WordNet-based features (Moldovan et al., 2004). Several studies utilize syntactic features. Many other works manually develop a set of heuristic features devised with some specific relationship in mind, like a WordNet-based meronymy feature (Bedmar et al., 2007) or size-of feature (Aramaki et al., 2006). However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No study so far has proposed a method to define, discover and represent general relationships present in an arbitrary corpus. In (Davidov and Rappoport, 2008) we present an app</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Banko, M., Cafarella, M. J., Soderland, S., Broadhead, M., and Etzioni, O., 2007. Open information extraction from the Web. IJCAI ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Beamer</author>
<author>S Bhat</author>
<author>B Chee</author>
<author>A Fister</author>
<author>A Rozovskaya</author>
<author>u Gir</author>
<author>R</author>
</authors>
<title>UIUC: A knowledge-rich approach to identifying semantic relations between nominals.</title>
<date>2007</date>
<journal>ACL SemEval</journal>
<volume>07</volume>
<pages>Workshop.</pages>
<contexts>
<context position="2238" citStr="Beamer et al., 2007" startWordPosition="330" endWordPosition="333">e term ‘nominal’ follows (Girju et al., 2007), and includes simple nouns, noun compounds and multiword expressions serving as nouns. ing’ denotes a morning that happens in the summer. These two relationships are completely different semantically but are similar syntactically, and distinguishing between them could be essential for NLP applications such as question answering and machine translation. Relation classification usually relies on a training set in the form of tagged data. To improve results, some systems utilize additional manually constructed semantic resources such as WordNet (WN) (Beamer et al., 2007). However, in many domains and languages such resources are not available. Furthermore, usage of such resources frequently requires disambiguation and connection of the data to the resource (word sense disambiguation in the case of WordNet). Manual disambiguation is unfeasible in many practical tasks, and an automatic one may introduce errors and greatly degrade performance. It thus makes sense to try to minimize the usage of such resources, and utilize only corpus contexts in which the relevant words appear. A leading method for utilizing context information for classification and extraction </context>
<context position="6877" citStr="Beamer et al., 2007" startWordPosition="1040" endWordPosition="1043">be the evaluation protocol and results. 2 Related Work Numerous methods have been devised for classification of semantic relationships, among which those holding between nominals constitute a prominent category. Major differences between these methods include available resources, degree of preprocessing, features used, classification algorithm and the nature of training/test data. 2.1 Available Resources Many relation classification algorithms utilize WordNet. Among the 15 systems presented by the 14 SemEval teams, some utilized the manually provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in</context>
<context position="30381" citStr="Beamer et al., 2007" startWordPosition="4930" endWordPosition="4933">ype F Acc C Cause-Effect 69.7 71.4 2 Instrument-Agency 76.5 74.2 1 Product-Producer 76.4 83.8 1 Origin-Entity 65.4 62.6 4 Theme-Tool 59.4 58.7 6 Part-Whole 74.3 70.9 1 Content-Container 72.6 69.2 2 Table 2: By-relation Task 4 HITS-based results. C is the number of clusters with positive labels. clusters containing test samples. For evaluation we assigned a negative/positive label to these two clusters according to the best alignment with true labels. Table 1 shows our results, along with the best Task 4 result not using WordNet labels (Costello, 2007). For reference, the best results overall (Beamer et al., 2007) are also shown. The table shows precision (P) recall (R), F-score (F), and Accuracy (Acc) (percentage of correctly classified examples). We can see that while our algorithm is not as good as the best method that utilizes WordNet tags, results are superior to all participants who did not use these tags. We can also see that the unsupervised method results are above the random baseline (50%). In fact, our results (f-score 62.0, accuracy 64.5) are better than the averaged results (58.0, 61.1) of the group that did not utilize WN tags. Table 2 shows the HITS-based classification results (F-score </context>
</contexts>
<marker>Beamer, Bhat, Chee, Fister, Rozovskaya, Gir, R, 2007</marker>
<rawString>Beamer, B., Bhat, S., Chee, B., Fister, A., Rozovskaya A., and Gir u, R., 2007. UIUC: A knowledge-rich approach to identifying semantic relations between nominals. ACL SemEval ’07 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I S Bedmar</author>
<author>D Samy</author>
<author>J L Martinez</author>
</authors>
<title>UC3M: Classification of semantic relations between nominals using sequential minimal optimization.</title>
<date>2007</date>
<journal>ACL SemEval</journal>
<volume>07</volume>
<pages>Workshop.</pages>
<contexts>
<context position="7192" citStr="Bedmar et al., 2007" startWordPosition="1092" endWordPosition="1095">sed, classification algorithm and the nature of training/test data. 2.1 Available Resources Many relation classification algorithms utilize WordNet. Among the 15 systems presented by the 14 SemEval teams, some utilized the manually provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English when applied to some restricted domains. In this paper we do not use any manually annotated resources apart from the classificatio</context>
<context position="8798" citStr="Bedmar et al., 2007" startWordPosition="1330" endWordPosition="1333">nusual text domains and are also highly computationally intensive when processing large corpora. To make our approach as language independent and efficient as possible, we avoided using any such preprocessing techniques. 2.3 Classification Features A wide variety of features are used by different algorithms, ranging from simple bag-of-words frequencies to WordNet-based features (Moldovan et al., 2004). Several studies utilize syntactic features. Many other works manually develop a set of heuristic features devised with some specific relationship in mind, like a WordNet-based meronymy feature (Bedmar et al., 2007) or size-of feature (Aramaki et al., 2006). However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, </context>
</contexts>
<marker>Bedmar, Samy, Martinez, 2007</marker>
<rawString>Bedmar, I. S., Samy, D., and Martinez, J. L., 2007. UC3M: Classification of semantic relations between nominals using sequential minimal optimization. ACL SemEval ’07 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Cleary</author>
</authors>
<title>K*: An instance-based learner using and entropic distance measure.</title>
<date>1995</date>
<journal>ICML</journal>
<volume>95</volume>
<marker>Cleary, 1995</marker>
<rawString>Cleary, J. G. , Trigg, L. E., 1995. K*: An instance-based learner using and entropic distance measure. ICML ’95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Costello</author>
</authors>
<title>UCD-FC: Deducing semantic relations using WordNet senses that occur frequently in a database of noun-noun compounds.</title>
<date>2007</date>
<journal>ACL SemEval</journal>
<volume>07</volume>
<pages>Workshop.</pages>
<contexts>
<context position="7065" citStr="Costello, 2007" startWordPosition="1072" endWordPosition="1073">ominent category. Major differences between these methods include available resources, degree of preprocessing, features used, classification algorithm and the nature of training/test data. 2.1 Available Resources Many relation classification algorithms utilize WordNet. Among the 15 systems presented by the 14 SemEval teams, some utilized the manually provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English whe</context>
<context position="30318" citStr="Costello, 2007" startWordPosition="4922" endWordPosition="4923">.4 76.3 Table 1: Our SemEval-07 Task 4 results. Relation Type F Acc C Cause-Effect 69.7 71.4 2 Instrument-Agency 76.5 74.2 1 Product-Producer 76.4 83.8 1 Origin-Entity 65.4 62.6 4 Theme-Tool 59.4 58.7 6 Part-Whole 74.3 70.9 1 Content-Container 72.6 69.2 2 Table 2: By-relation Task 4 HITS-based results. C is the number of clusters with positive labels. clusters containing test samples. For evaluation we assigned a negative/positive label to these two clusters according to the best alignment with true labels. Table 1 shows our results, along with the best Task 4 result not using WordNet labels (Costello, 2007). For reference, the best results overall (Beamer et al., 2007) are also shown. The table shows precision (P) recall (R), F-score (F), and Accuracy (Acc) (percentage of correctly classified examples). We can see that while our algorithm is not as good as the best method that utilizes WordNet tags, results are superior to all participants who did not use these tags. We can also see that the unsupervised method results are above the random baseline (50%). In fact, our results (f-score 62.0, accuracy 64.5) are better than the averaged results (58.0, 61.1) of the group that did not utilize WN tags</context>
</contexts>
<marker>Costello, 2007</marker>
<rawString>Costello, F. J., 2007. UCD-FC: Deducing semantic relations using WordNet senses that occur frequently in a database of noun-noun compounds. ACL SemEval ’07 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
</authors>
<title>Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="13732" citStr="Davidov and Rappoport, 2006" startWordPosition="2107" endWordPosition="2111"> As a first step, we randomly sample a set of hook words, which will be used in order to discover relationships that generally occur in the corpus. To avoid selection of ambiguous words or typos, we do not select words with frequency higher than a parameter FC and lower than a threshold FB. We also limit the total number N of hook words. For each hook word, we now create a hook corpus, the set of the contexts in which the word appears. Each context is a window containing W words or punctuation characters before and after the hook word. 3.2 Pattern Specification To specify patterns, following (Davidov and Rappoport, 2006) we classify words into highfrequency words (HFWs) and content words (CWs). A word whose frequency is more (less) than FH (FC) is considered to be a HFW (CW). Our patterns have the general form [Prefix] CW1 [Infix] CW2 [Postfix] where Prefix, Infix and Postfix contain only HFWs. We require Prefix and Postfix to be a single HFW, while Infix can contain any number of HFWs (limiting pattern length by window size). This form may include patterns like ‘such X as Y and’. At this stage, the pattern slots can contain only single words; however, when using the final pattern clusters for nominal relatio</context>
<context position="17954" citStr="Davidov and Rappoport, 2006" startWordPosition="2841" endWordPosition="2845">ion algorithm is based on contexts of given nominal pairs. Co-appearance of nominal pairs can be very rare (in fact, some word pairs in the Task 4 set co-appear only once in Yahoo web search). Hence we need more contexts where the given nominals or nominals similar to them coappear. This step does not require the training labels (the correct classifications), so we do it for both training and test pairs. We do it in two stages: extracting similar nominals, and obtaining more contexts. 4.1.1 Extracting more words For each nominal pair (w1, w2) in a given sentence 5, we use a method similar to (Davidov and Rappoport, 2006) to extract words that have a shared meaning with w1 or w2. We discover such words by scanning our corpora and querying the web for symmetric patterns (obtained automatically from the corpus as in (Davidov and Rappoport, 2006)) that contain w1 or w2. To avoid getting instances of w1,2 with a different meaning, we also require that the second word will appear in the same text paragraph or the same web page. For example, if we are given a pair &lt;loans, students&gt; and we see a sentence ‘... loans and scholarships for students and professionals ...’, we use the symmetric pattern ‘X and Y’ to add the</context>
</contexts>
<marker>Davidov, Rappoport, 2006</marker>
<rawString>Davidov, D., Rappoport, A., 2006. Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words. COLING-ACL ’06</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
<author>M Koppel</author>
</authors>
<title>Fully unsupervised discovery of concept-specific relationships by Web mining.</title>
<date>2007</date>
<journal>ACL</journal>
<volume>07</volume>
<contexts>
<context position="9478" citStr="Davidov et al. (2007)" startWordPosition="1428" endWordPosition="1431">st prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No study so far has proposed a method to define, discover and represent general relationships present in an arbitrary corpus. In (Davidov and Rappoport, 2008) we present an approach to extract pattern clusters from an untagged corpus. Each such cluster represents some unspecified lexical relationship. In this paper, we use these pattern clusters as the (only) source of machine learning features for a nominal relationship classification problem. Unlike the majority of current studies, we avoid usin</context>
<context position="19859" citStr="Davidov et al., 2007" startWordPosition="3175" endWordPosition="3178">omes &lt;study, results&gt;). This step is the only one specific to English, using the nature of English noun compounds. Our desire in this case is to keep the head words. 4.1.2 Extracting more contexts using the new words To find more instances where nominals similar to w1 and w2 co-appear in HFW patterns, we construct web queries using combinations of each nominal’s group and extract patterns from the search result snapshots (the two line summary provided by search engines for each search result). 4.2 The HITS Measure To use clusters for classification we define a HITS measure similar to that of (Davidov et al., 2007), reflecting the affinity of a given nominal pair to a given cluster. We use the pattern clusters from Section 3 and the additional data collected during the enrichment phase to estimate a HITS value for each cluster and each pair in the training and test sets. For a given nominal pair (w1, w2) and cluster C with n core patterns PcoT, and m unconfirmed patterns Punconf, HITS(C, (w1, w2)) _ |{p; (w1, w2) appears in p E PcoT�} |/n+ α x |{p; (w1, w2) appears in p E Punconf} |/m. In this formula, ‘appears in’ means that the nominal pair appears in instances of this pattern extracted from the origi</context>
</contexts>
<marker>Davidov, Rappoport, Koppel, 2007</marker>
<rawString>Davidov D., Rappoport A. and Koppel M., 2007. Fully unsupervised discovery of concept-specific relationships by Web mining. ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
</authors>
<title>Unsupervised discovery of generic relationships using pattern clusters and its evaluation by automatically generated SAT analogy questions.</title>
<date>2008</date>
<journal>ACL</journal>
<volume>08</volume>
<contexts>
<context position="5727" citStr="Davidov and Rappoport, 2008" startWordPosition="864" endWordPosition="867">cludes a subset of 7 widely accepted nominal relationship (NR) classes, allowing consistent evaluation of different NR classification algorithms. In the SemEval event, 14 research teams evaluated their algorithms using this benchmark. Some of the teams have used the manually annotated WN labels provided with the dataset, and some have not. We evaluated our algorithm on SemEval-07 Task 4 data, showing superior results over participating algorithms that did not utilize WordNet disambiguation tags. We also show how pattern clusters can be used for a completely unsupervised classification of 2In (Davidov and Rappoport, 2008) we focus on the pattern cluster resource type itself, presenting an evaluation of its intrinsic quality based on SAT tests. In the present paper we focus on showing how the resource can be used to improve a known NLP task. the test set. Since in this case no training data is used, this allows the automated discovery of a potentially unbiased classification scheme. Section 2 discusses related work, Section 3 outlines the pattern clustering algorithm, Section 4 details three classification methods, and Sections 5 and 6 describe the evaluation protocol and results. 2 Related Work Numerous method</context>
<context position="9734" citStr="Davidov and Rappoport, 2008" startWordPosition="1470" endWordPosition="1473">., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No study so far has proposed a method to define, discover and represent general relationships present in an arbitrary corpus. In (Davidov and Rappoport, 2008) we present an approach to extract pattern clusters from an untagged corpus. Each such cluster represents some unspecified lexical relationship. In this paper, we use these pattern clusters as the (only) source of machine learning features for a nominal relationship classification problem. Unlike the majority of current studies, we avoid using any other features that require some language-specific information or are devised for specific relationship types. 2.4 Classification Algorithm Various learning algorithms have been used for relation classification. Common choices include variations of S</context>
<context position="12002" citStr="Davidov and Rappoport, 2008" startWordPosition="1811" endWordPosition="1815">ludes a representative rather than exhaustive list of 7 important nominal relationships. We have used this dataset, strictly following the evaluation protocol. This made it possible to meaningfully compare our method to state-ofthe-art methods for relation classification. 3 Pattern Clustering Algorithm Our pattern clustering algorithm is designed for the unsupervised definition and discovery of generic semantic relationships. The algorithm first discovers and clusters patterns in which a single (‘hook’) word participates, and then merges the resulting clusters to form the final structure. In (Davidov and Rappoport, 2008) we describe the algorithm at length, discuss its behavior and parameters in detail, and evaluate its intrinsic quality. To assist readers of the present paper, in this section we provide an overview. Examples of some resulting pattern clusters are given in Section 6. We refer to a pattern 3Actually, there were 50 relationships at the bottom level, but valid nominal instances were found only for 30. 229 contained in our clusters (a pattern type) as a ‘pattern’ and to an occurrence of a pattern in the corpus (a pattern token) as a ‘pattern instance’. The algorithm does not rely on any data from</context>
</contexts>
<marker>Davidov, Rappoport, 2008</marker>
<rawString>Davidov, D., Rappoport, A., 2008. Unsupervised discovery of generic relationships using pattern clusters and its evaluation by automatically generated SAT analogy questions. ACL ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Feature generation for text categorization using world knowledge.</title>
<date>2005</date>
<journal>IJCAI</journal>
<volume>05</volume>
<contexts>
<context position="25716" citStr="Gabrilovich and Markovitch, 2005" startWordPosition="4155" endWordPosition="4158">hey use the WordNet and Query tags (some systems were assigned to more than a single category, since they reported experiments in several settings). In our evaluation we do not utilize WordNet or Query tags, hence we compare ourselves with the corresponding group (A), containing 6 systems. 5.2 Corpus and Web Access Our algorithm uses two corpora. We estimate frequencies and perform primary search on a local web corpus containing about 68GB untagged plain text. This corpus was extracted from the web starting from open directory links, comprising English web pages with varied topics and styles (Gabrilovich and Markovitch, 2005). To enrich the set of given word pairs and patterns as described in Section 4.1 and to perform clarifying queries, we utilize the Yahoo API for web queries. For each query, if the desired words/patterns were found in a page link’s snapshot, we do not use the link, otherwise we download the page from the retrieved link and then extract the required data. If only several links were found for a given word pair we perform local crawling to depth 3 in an attempt to discover more instances. 5.3 Parameters and Learning Algorithm Our algorithm utilizes several parameters. Instead of calibrating them </context>
</contexts>
<marker>Gabrilovich, Markovitch, 2005</marker>
<rawString>Gabrilovich, E., Markovitch, S., 2005. Feature generation for text categorization using world knowledge. IJCAI ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Giuglea</author>
<author>A Olteanu</author>
<author>M Fortu</author>
<author>O Bolohan</author>
<author>O</author>
<author>D Moldovan</author>
</authors>
<title>Support vector machines applied to the classification of semantic relations in nominalized noun phrases.</title>
<date>2004</date>
<booktitle>HLT/NAACL ’04 Workshop on Computational Lexical Semantics.</booktitle>
<marker>Gir, Giuglea, Olteanu, Fortu, Bolohan, O, Moldovan, 2004</marker>
<rawString>Gir u, R., Giuglea, A., Olteanu, M., Fortu, O., Bolohan, O., and Moldovan, D., 2004. Support vector machines applied to the classification of semantic relations in nominalized noun phrases. HLT/NAACL ’04 Workshop on Computational Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Moldovan</author>
<author>D Tatu</author>
<author>M</author>
<author>D Antohe</author>
</authors>
<title>On the semantics of noun compounds.</title>
<date>2005</date>
<journal>Computer Speech and Language,</journal>
<pages>19--4</pages>
<marker>Gir, Moldovan, Tatu, M, Antohe, 2005</marker>
<rawString>Gir u, R., Moldovan, D., Tatu, M., and Antohe, D., 2005. On the semantics of noun compounds. Computer Speech and Language, 19(4):479-496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Badulescu</author>
<author>A</author>
<author>D Moldovan</author>
</authors>
<title>Automatic discovery of part-whole relations.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<marker>Gir, Badulescu, A, Moldovan, 2006</marker>
<rawString>Gir u, R., Badulescu, A., and Moldovan, D., 2006. Automatic discovery of part-whole relations. Computational Linguistics, 32(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>u Gir</author>
<author>R Hearst</author>
<author>M Nakov</author>
<author>P Nastase</author>
<author>V Szpakowicz</author>
<author>S Turney</author>
<author>P</author>
<author>D Yuret</author>
</authors>
<title>Task 04: Classification of semantic relations between nominal at SemEval</title>
<date>2007</date>
<booktitle>4th Intl. Workshop on Semantic Evaluations (SemEval ’07), in ACL ’07.</booktitle>
<marker>Gir, Hearst, Nakov, Nastase, Szpakowicz, Turney, P, Yuret, 2007</marker>
<rawString>Gir u, R., Hearst, M., Nakov, P., Nastase, V., Szpakowicz, S., Turney, P., and Yuret, D., 2007. Task 04: Classification of semantic relations between nominal at SemEval 2007. 4th Intl. Workshop on Semantic Evaluations (SemEval ’07), in ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<journal>COLING</journal>
<volume>92</volume>
<contexts>
<context position="2888" citStr="Hearst, 1992" startWordPosition="432" endWordPosition="433">es such resources are not available. Furthermore, usage of such resources frequently requires disambiguation and connection of the data to the resource (word sense disambiguation in the case of WordNet). Manual disambiguation is unfeasible in many practical tasks, and an automatic one may introduce errors and greatly degrade performance. It thus makes sense to try to minimize the usage of such resources, and utilize only corpus contexts in which the relevant words appear. A leading method for utilizing context information for classification and extraction of relationships is that of patterns (Hearst, 1992; Pantel and Pennacchiotti, 2006). The standard classification process is to find in an auxiliary corpus a set of patterns in which a given training word pair co-appears, and use pattern-word pair co-appearance statistics as features for machine learning algorithms. In this paper we introduce a novel approach, based on utilizing pattern clusters that are prepared separately and independently of the training set. We do not utilize any manually constructed resource or any manual tagging of training data beyond the cor227 Proceedings of ACL-08: HLT, pages 227–235, Columbus, Ohio, USA, June 2008. </context>
<context position="8979" citStr="Hearst, 1992" startWordPosition="1359" endWordPosition="1360">y such preprocessing techniques. 2.3 Classification Features A wide variety of features are used by different algorithms, ranging from simple bag-of-words frequencies to WordNet-based features (Moldovan et al., 2004). Several studies utilize syntactic features. Many other works manually develop a set of heuristic features devised with some specific relationship in mind, like a WordNet-based meronymy feature (Bedmar et al., 2007) or size-of feature (Aramaki et al., 2006). However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No </context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Hearst, M., 1992. Automatic acquisition of hyponyms from large text corpora. COLING ’92</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Hendrickx</author>
<author>R Morante</author>
<author>C Sporleder</author>
<author>A van den Bosch</author>
</authors>
<title>Machine learning of semantic relations with shallow features and almost no data.</title>
<date>2007</date>
<journal>ACL SemEval</journal>
<volume>07</volume>
<pages>Workshop.</pages>
<marker>Hendrickx, Morante, Sporleder, van den Bosch, 2007</marker>
<rawString>Hendrickx, I., Morante, R., Sporleder, C., and van den Bosch, A., 2007. Machine learning of semantic relations with shallow features and almost no data. ACL SemEval ’07 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Kim</author>
<author>T Baldwin</author>
</authors>
<title>MELB-KB: Nominal classification as noun compound interpretation.</title>
<date>2007</date>
<journal>ACL SemEval</journal>
<volume>07</volume>
<pages>Workshop.</pages>
<contexts>
<context position="7113" citStr="Kim and Baldwin, 2007" startWordPosition="1078" endWordPosition="1081">een these methods include available resources, degree of preprocessing, features used, classification algorithm and the nature of training/test data. 2.1 Available Resources Many relation classification algorithms utilize WordNet. Among the 15 systems presented by the 14 SemEval teams, some utilized the manually provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English when applied to some restricted domains. In this pa</context>
</contexts>
<marker>Kim, Baldwin, 2007</marker>
<rawString>Kim, S.N., Baldwin, T., 2007. MELB-KB: Nominal classification as noun compound interpretation. ACL SemEval ’07 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Moldovan</author>
<author>A Badulescu</author>
<author>M Tatu</author>
<author>D Antohe</author>
<author>u Gir</author>
<author>R</author>
</authors>
<title>Models for the semantic classification of noun phrases.</title>
<date>2004</date>
<booktitle>HLT-NAACL ’04 Workshop on Computational Lexical Semantics.</booktitle>
<contexts>
<context position="4810" citStr="Moldovan et al., 2004" startWordPosition="726" endWordPosition="729">ven classification problem, will be represented by some of the discovered clusters. We then use the training set to label some of the clusters, and the labeled clusters to assign classes to tested items. One of the advantages of our method is that it can be used not only for classification, but also for further analysis and retrieval of the observed relationships2. The semantic relationships between the components of noun compounds and between nominals in general are not easy to categorize rigorously. Several different relationship hierarchies have been proposed (Nastase and Szpakowicz, 2003; Moldovan et al., 2004). Some classes, like Container-Contained, Time-Event and Product-Producer, appear in several classification schemes, while classes like ToolObject are more vaguely defined and are subdivided differently. Recently, SemEval-07 Task 4 (Girju et al., 2007) proposed a benchmark dataset that includes a subset of 7 widely accepted nominal relationship (NR) classes, allowing consistent evaluation of different NR classification algorithms. In the SemEval event, 14 research teams evaluated their algorithms using this benchmark. Some of the teams have used the manually annotated WN labels provided with t</context>
<context position="8582" citStr="Moldovan et al., 2004" startWordPosition="1298" endWordPosition="1301">f speech tagging and 228 named entity annotation (Pantel et al., 2004). While the obtained features were shown to improve classification performance, they tend to be language dependent and error-prone when working on unusual text domains and are also highly computationally intensive when processing large corpora. To make our approach as language independent and efficient as possible, we avoided using any such preprocessing techniques. 2.3 Classification Features A wide variety of features are used by different algorithms, ranging from simple bag-of-words frequencies to WordNet-based features (Moldovan et al., 2004). Several studies utilize syntactic features. Many other works manually develop a set of heuristic features devised with some specific relationship in mind, like a WordNet-based meronymy feature (Bedmar et al., 2007) or size-of feature (Aramaki et al., 2006). However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007</context>
<context position="11206" citStr="Moldovan et al. (2004)" startWordPosition="1693" endWordPosition="1696">id not focus on a single ML algorithm, letting algorithm selection be automatically based on cross-validation results on the training set, as in (Hendrickx et al., 2007) but using more algorithms and allowing a more flexible parameter choice. 2.5 Training Data As stated above, several categorization schemes for nominals have been proposed. Nastase and Szpakowicz (2003) proposed a two-level hierarchy with 5 (30) classes at the top (bottom) levels3. This hierarchy and a corresponding dataset were used in (Turney, 2005; Turney, 2006) and (Nastase et al., 2006) for evaluation of their algorithms. Moldovan et al. (2004) proposed a different scheme with 35 classes. The most recent dataset has been developed for SemEval 07 Task 4 (Girju et al., 2007). This manually annotated dataset includes a representative rather than exhaustive list of 7 important nominal relationships. We have used this dataset, strictly following the evaluation protocol. This made it possible to meaningfully compare our method to state-ofthe-art methods for relation classification. 3 Pattern Clustering Algorithm Our pattern clustering algorithm is designed for the unsupervised definition and discovery of generic semantic relationships. Th</context>
</contexts>
<marker>Moldovan, Badulescu, Tatu, Antohe, Gir, R, 2004</marker>
<rawString>Moldovan, D., Badulescu, A., Tatu, M., Antohe, D., and Gir u, R., 2004. Models for the semantic classification of noun phrases. HLT-NAACL ’04 Workshop on Computational Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Nakov</author>
<author>M Hearst</author>
</authors>
<date>2007</date>
<booktitle>UCB: System description for SemEval Task #4. ACL SemEval ’07 Workshop.</booktitle>
<contexts>
<context position="7089" citStr="Nakov and Hearst, 2007" startWordPosition="1074" endWordPosition="1077">. Major differences between these methods include available resources, degree of preprocessing, features used, classification algorithm and the nature of training/test data. 2.1 Available Resources Many relation classification algorithms utilize WordNet. Among the 15 systems presented by the 14 SemEval teams, some utilized the manually provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English when applied to some restri</context>
</contexts>
<marker>Nakov, Hearst, 2007</marker>
<rawString>Nakov, P., and Hearst, M., 2007. UCB: System description for SemEval Task #4. ACL SemEval ’07 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Nastase</author>
<author>S Szpakowicz</author>
</authors>
<title>Exploring nounmodifier semantic relations.</title>
<date>2003</date>
<booktitle>In Fifth Intl. Workshop on Computational Semantics (IWCS-5).</booktitle>
<contexts>
<context position="4786" citStr="Nastase and Szpakowicz, 2003" startWordPosition="722" endWordPosition="725">ships, including those in a given classification problem, will be represented by some of the discovered clusters. We then use the training set to label some of the clusters, and the labeled clusters to assign classes to tested items. One of the advantages of our method is that it can be used not only for classification, but also for further analysis and retrieval of the observed relationships2. The semantic relationships between the components of noun compounds and between nominals in general are not easy to categorize rigorously. Several different relationship hierarchies have been proposed (Nastase and Szpakowicz, 2003; Moldovan et al., 2004). Some classes, like Container-Contained, Time-Event and Product-Producer, appear in several classification schemes, while classes like ToolObject are more vaguely defined and are subdivided differently. Recently, SemEval-07 Task 4 (Girju et al., 2007) proposed a benchmark dataset that includes a subset of 7 widely accepted nominal relationship (NR) classes, allowing consistent evaluation of different NR classification algorithms. In the SemEval event, 14 research teams evaluated their algorithms using this benchmark. Some of the teams have used the manually annotated W</context>
<context position="10955" citStr="Nastase and Szpakowicz (2003)" startWordPosition="1652" endWordPosition="1656">ons of SVM (Girju et al., 2004; Nastase et al., 2006), decision trees and memory-based learners. Freely available tools like Weka (Witten and Frank, 1999) allow easy experimentation with common learning algorithms (Hendrickx et al., 2007). In this paper we did not focus on a single ML algorithm, letting algorithm selection be automatically based on cross-validation results on the training set, as in (Hendrickx et al., 2007) but using more algorithms and allowing a more flexible parameter choice. 2.5 Training Data As stated above, several categorization schemes for nominals have been proposed. Nastase and Szpakowicz (2003) proposed a two-level hierarchy with 5 (30) classes at the top (bottom) levels3. This hierarchy and a corresponding dataset were used in (Turney, 2005; Turney, 2006) and (Nastase et al., 2006) for evaluation of their algorithms. Moldovan et al. (2004) proposed a different scheme with 35 classes. The most recent dataset has been developed for SemEval 07 Task 4 (Girju et al., 2007). This manually annotated dataset includes a representative rather than exhaustive list of 7 important nominal relationships. We have used this dataset, strictly following the evaluation protocol. This made it possible</context>
<context position="26606" citStr="Nastase and Szpakowicz, 2003" startWordPosition="4304" endWordPosition="4308">ink, otherwise we download the page from the retrieved link and then extract the required data. If only several links were found for a given word pair we perform local crawling to depth 3 in an attempt to discover more instances. 5.3 Parameters and Learning Algorithm Our algorithm utilizes several parameters. Instead of calibrating them manually, we only provided a desired range for each, and the final parameter values were obtained during selection of the bestperforming setup using 10-fold cross-validation on the training set. For each parameter we have estimated its desired range using the (Nastase and Szpakowicz, 2003) set as a development set. Note that this set uses an entirely different relationship classification scheme. We ran the pattern clustering phase on 128 different sets of parameters, obtaining 128 different clustering schemes with varied granularity, noise and coverage. The parameter ranges obtained are: FC (metapattern content word frequency and upper bound for hook word selection): 100 − 5000 words per million (wpm); FH (meta-pattern HFW): 10 − 100 wpm; FB (low word count for hook word filtering): 1− 50 wpm; N (number of hook words): 100 − 1000; W (window size): 5 or window = sentence; L (tar</context>
<context position="31888" citStr="Nastase and Szpakowicz, 2003" startWordPosition="5182" endWordPosition="5185">ry ambiguous and are mapped to several clusters, while relations like Product-Producer seem to be well-defined by the obtained pattern clusters. The SemEval dataset does not explicitly mark items whose correct classification requires analysis of the context of the whole sentence in which they appear. Since our algorithm does not utilize test sentence contextual information, we do not expect it to show exceptional performance on such items. This is a good topic for future research. Since the SemEval dataset is of a very specific nature, we have also applied our classification framework to the (Nastase and Szpakowicz, 2003) dataset, which contains 600 pairs labeled with 5 main relationship types. We have used the exact evaluation procedure described in (Turney, 2006), achieving a class f-score average of 60.1, as opposed to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al., 2006). This shows that our method produces superior results for rather differing datasets. 7 Conclusion Relationship classification is known to improve many practical tasks, e.g., textual entailment (Tatu and Moldovan, 2005). We have presented a novel framework for relationship classification, based on pattern clusters prepared as a standalo</context>
</contexts>
<marker>Nastase, Szpakowicz, 2003</marker>
<rawString>Nastase, V., Szpakowicz, S., 2003. Exploring nounmodifier semantic relations. In Fifth Intl. Workshop on Computational Semantics (IWCS-5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Nastase</author>
<author>J Sayyad-Shirabad</author>
<author>M Sokolova</author>
<author>S Szpakowicz</author>
</authors>
<title>Learning noun-modifier semantic relations with corpus-based and WordNet-based features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Arti�cial Intelligence,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="10379" citStr="Nastase et al., 2006" startWordPosition="1567" endWordPosition="1570">to extract pattern clusters from an untagged corpus. Each such cluster represents some unspecified lexical relationship. In this paper, we use these pattern clusters as the (only) source of machine learning features for a nominal relationship classification problem. Unlike the majority of current studies, we avoid using any other features that require some language-specific information or are devised for specific relationship types. 2.4 Classification Algorithm Various learning algorithms have been used for relation classification. Common choices include variations of SVM (Girju et al., 2004; Nastase et al., 2006), decision trees and memory-based learners. Freely available tools like Weka (Witten and Frank, 1999) allow easy experimentation with common learning algorithms (Hendrickx et al., 2007). In this paper we did not focus on a single ML algorithm, letting algorithm selection be automatically based on cross-validation results on the training set, as in (Hendrickx et al., 2007) but using more algorithms and allowing a more flexible parameter choice. 2.5 Training Data As stated above, several categorization schemes for nominals have been proposed. Nastase and Szpakowicz (2003) proposed a two-level hi</context>
<context position="32150" citStr="Nastase et al., 2006" startWordPosition="5225" endWordPosition="5228"> sentence in which they appear. Since our algorithm does not utilize test sentence contextual information, we do not expect it to show exceptional performance on such items. This is a good topic for future research. Since the SemEval dataset is of a very specific nature, we have also applied our classification framework to the (Nastase and Szpakowicz, 2003) dataset, which contains 600 pairs labeled with 5 main relationship types. We have used the exact evaluation procedure described in (Turney, 2006), achieving a class f-score average of 60.1, as opposed to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al., 2006). This shows that our method produces superior results for rather differing datasets. 7 Conclusion Relationship classification is known to improve many practical tasks, e.g., textual entailment (Tatu and Moldovan, 2005). We have presented a novel framework for relationship classification, based on pattern clusters prepared as a standalone resource independently of the training set. Our method outperforms current state-of-the-art algorithms that do not utilize WordNet tags on Task 4 of SemEval-07. In practical situations, it would not be feasible to provide a large amount of such sense disambig</context>
</contexts>
<marker>Nastase, Sayyad-Shirabad, Sokolova, Szpakowicz, 2006</marker>
<rawString>Nastase, V., Sayyad-Shirabad, J., Sokolova, M., and Szpakowicz, S., 2006. Learning noun-modifier semantic relations with corpus-based and WordNet-based features. In Proceedings of the 21st National Conference on Arti�cial Intelligence, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Ravichandran</author>
<author>E Hovy</author>
</authors>
<title>Towards terascale knowledge acquisition.</title>
<date>2004</date>
<journal>COLING</journal>
<volume>04</volume>
<contexts>
<context position="8030" citStr="Pantel et al., 2004" startWordPosition="1217" endWordPosition="1220"> and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English when applied to some restricted domains. In this paper we do not use any manually annotated resources apart from the classification training set. 2.2 Degree of Preprocessing Many relationship classification methods utilize some language-dependent preprocessing, like deep or shallow parsing, part of speech tagging and 228 named entity annotation (Pantel et al., 2004). While the obtained features were shown to improve classification performance, they tend to be language dependent and error-prone when working on unusual text domains and are also highly computationally intensive when processing large corpora. To make our approach as language independent and efficient as possible, we avoided using any such preprocessing techniques. 2.3 Classification Features A wide variety of features are used by different algorithms, ranging from simple bag-of-words frequencies to WordNet-based features (Moldovan et al., 2004). Several studies utilize syntactic features. Ma</context>
</contexts>
<marker>Pantel, Ravichandran, Hovy, 2004</marker>
<rawString>Pantel, P., Ravichandran, D., and Hovy, E., 2004. Towards terascale knowledge acquisition. COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>M Pennacchiotti</author>
</authors>
<title>Espresso: leveraging generic patterns for automatically harvesting semantic relations.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="2921" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="434" endWordPosition="438">ces are not available. Furthermore, usage of such resources frequently requires disambiguation and connection of the data to the resource (word sense disambiguation in the case of WordNet). Manual disambiguation is unfeasible in many practical tasks, and an automatic one may introduce errors and greatly degrade performance. It thus makes sense to try to minimize the usage of such resources, and utilize only corpus contexts in which the relevant words appear. A leading method for utilizing context information for classification and extraction of relationships is that of patterns (Hearst, 1992; Pantel and Pennacchiotti, 2006). The standard classification process is to find in an auxiliary corpus a set of patterns in which a given training word pair co-appears, and use pattern-word pair co-appearance statistics as features for machine learning algorithms. In this paper we introduce a novel approach, based on utilizing pattern clusters that are prepared separately and independently of the training set. We do not utilize any manually constructed resource or any manual tagging of training data beyond the cor227 Proceedings of ACL-08: HLT, pages 227–235, Columbus, Ohio, USA, June 2008. c�2008 Association for Computatio</context>
<context position="9403" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="1416" endWordPosition="1419">ture (Bedmar et al., 2007) or size-of feature (Aramaki et al., 2006). However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No study so far has proposed a method to define, discover and represent general relationships present in an arbitrary corpus. In (Davidov and Rappoport, 2008) we present an approach to extract pattern clusters from an untagged corpus. Each such cluster represents some unspecified lexical relationship. In this paper, we use these pattern clusters as the (only) source of machine learning features for a nominal relationship cl</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Pantel, P., Pennacchiotti, M., 2006. Espresso: leveraging generic patterns for automatically harvesting semantic relations. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Platt</author>
</authors>
<title>Fast training of support vector machines using sequential minimal optimization.</title>
<date>1999</date>
<booktitle>In Scholkopf, Burges, and Smola, Advances in Kernel Methods – Support Vector Learning,</booktitle>
<pages>185--208</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="28161" citStr="Platt, 1999" startWordPosition="4558" endWordPosition="4559">est configuration in the cross-validation phase makes the algorithm flexible and less dependent on hard-coded parameter values. Selection of learning algorithm and its algorithmspecific parameters were done as follows. For each of the 7 classification tasks (one per relationship type), for each of the 128 pattern clustering schemes, we prepared a list of most of the compatible algorithms available in Weka, and we automatically selected the model (a parameter set and an algorithm) which gave the best 10-fold cross-validation results. The winning algorithms were LWL (Atkeson et al., 1997), SMO (Platt, 1999), and K* (Cleary and Trigg, 1995) (there were 7 tasks, and different algorithms could be selected for each task). We then used the obtained model to classify the testing set. This allowed us to avoid fixing parameters that are best for a specific dataset but not for others. Since each dataset has only 140 examples, the computation time of each learning algorithm is negligible. 6 Results The pattern clustering phase results in 90 to 3000 distinct pattern clusters, depending on the parameter setup. Manual sampling of these clusters indeed reveals that many clusters contain patterns specific to s</context>
</contexts>
<marker>Platt, 1999</marker>
<rawString>Platt, J., 1999. Fast training of support vector machines using sequential minimal optimization. In Scholkopf, Burges, and Smola, Advances in Kernel Methods – Support Vector Learning, pp. 185–208. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Rosario</author>
<author>M Hearst</author>
</authors>
<title>Classifying the semantic relations in noun compounds.</title>
<date>2001</date>
<journal>EMNLP</journal>
<volume>01</volume>
<contexts>
<context position="7428" citStr="Rosario and Hearst, 2001" startWordPosition="1126" endWordPosition="1129">y provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English when applied to some restricted domains. In this paper we do not use any manually annotated resources apart from the classification training set. 2.2 Degree of Preprocessing Many relationship classification methods utilize some language-dependent preprocessing, like deep or shallow parsing, part of speech tagging and 228 named entity annotation (Pantel et al., 200</context>
</contexts>
<marker>Rosario, Hearst, 2001</marker>
<rawString>Rosario, B., Hearst, M., 2001. Classifying the semantic relations in noun compounds. EMNLP ’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Rosenfeld</author>
<author>R Feldman</author>
</authors>
<title>Clustering for unsupervised relation identification.</title>
<date>2007</date>
<journal>CIKM</journal>
<volume>07</volume>
<contexts>
<context position="9183" citStr="Rosenfeld and Feldman (2007)" startWordPosition="1388" endWordPosition="1391">res (Moldovan et al., 2004). Several studies utilize syntactic features. Many other works manually develop a set of heuristic features devised with some specific relationship in mind, like a WordNet-based meronymy feature (Bedmar et al., 2007) or size-of feature (Aramaki et al., 2006). However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No study so far has proposed a method to define, discover and represent general relationships present in an arbitrary corpus. In (Davidov and Rappoport, 2008) we present an approach to extract pattern cluste</context>
</contexts>
<marker>Rosenfeld, Feldman, 2007</marker>
<rawString>Rosenfeld, B., Feldman, R., 2007. Clustering for unsupervised relation identification. CIKM ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>D Jurafsky</author>
<author>A Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogeneous evidence.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="9132" citStr="Snow et al., 2006" startWordPosition="1380" endWordPosition="1383">words frequencies to WordNet-based features (Moldovan et al., 2004). Several studies utilize syntactic features. Many other works manually develop a set of heuristic features devised with some specific relationship in mind, like a WordNet-based meronymy feature (Bedmar et al., 2007) or size-of feature (Aramaki et al., 2006). However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No study so far has proposed a method to define, discover and represent general relationships present in an arbitrary corpus. In (Davidov and Rappoport, 200</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Snow, R., Jurafsky, D., Ng, A.Y., 2006. Semantic taxonomy induction from heterogeneous evidence. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S Ponzetto</author>
</authors>
<title>WikiRelate! computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<journal>AAAI</journal>
<volume>06</volume>
<contexts>
<context position="7310" citStr="Strube and Ponzetto, 2006" startWordPosition="1108" endWordPosition="1111">ification algorithms utilize WordNet. Among the 15 systems presented by the 14 SemEval teams, some utilized the manually provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English when applied to some restricted domains. In this paper we do not use any manually annotated resources apart from the classification training set. 2.2 Degree of Preprocessing Many relationship classification methods utilize some language-dependent p</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Strube, M., Ponzetto, S., 2006. WikiRelate! computing semantic relatedness using Wikipedia. AAAI ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tatu</author>
<author>D Moldovan</author>
</authors>
<title>A semantic approach to recognizing textual entailment.</title>
<date>2005</date>
<journal>HLT/EMNLP</journal>
<volume>05</volume>
<contexts>
<context position="32369" citStr="Tatu and Moldovan, 2005" startWordPosition="5256" endWordPosition="5259">Since the SemEval dataset is of a very specific nature, we have also applied our classification framework to the (Nastase and Szpakowicz, 2003) dataset, which contains 600 pairs labeled with 5 main relationship types. We have used the exact evaluation procedure described in (Turney, 2006), achieving a class f-score average of 60.1, as opposed to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al., 2006). This shows that our method produces superior results for rather differing datasets. 7 Conclusion Relationship classification is known to improve many practical tasks, e.g., textual entailment (Tatu and Moldovan, 2005). We have presented a novel framework for relationship classification, based on pattern clusters prepared as a standalone resource independently of the training set. Our method outperforms current state-of-the-art algorithms that do not utilize WordNet tags on Task 4 of SemEval-07. In practical situations, it would not be feasible to provide a large amount of such sense disambiguation tags manually. Our method also shows competitive performance compared to the majority of task participants that do utilize WN tags. Our method can produce labeled pattern clusters, which can be potentially useful</context>
</contexts>
<marker>Tatu, Moldovan, 2005</marker>
<rawString>Tatu, M., Moldovan, D., 2005. A semantic approach to recognizing textual entailment. HLT/EMNLP ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Measuring semantic similarity by latent relational analysis.</title>
<date>2005</date>
<journal>IJCAI</journal>
<volume>05</volume>
<contexts>
<context position="7351" citStr="Turney, 2005" startWordPosition="1117" endWordPosition="1118">tems presented by the 14 SemEval teams, some utilized the manually provided WordNet tags for the dataset pairs (e.g., (Beamer et al., 2007)). In all cases, usage of WN tags improves the results significantly. Some other systems that avoided using the labels used WN as a supporting resource for their algorithms (Costello, 2007; Nakov and Hearst, 2007; Kim and Baldwin, 2007). Only three avoided WN altogether (Hendrickx et al., 2007; Bedmar et al., 2007; Aramaki et al., 2006). Other resources used for relationship discovery include Wikipedia (Strube and Ponzetto, 2006), thesauri or synonym sets (Turney, 2005) and domainspecific semantic hierarchies like MeSH (Rosario and Hearst, 2001). While usage of these resources is beneficial in many cases, high quality word sense annotation is not easily available. Besides, lexical resources are not available for many languages, and their coverage is limited even for English when applied to some restricted domains. In this paper we do not use any manually annotated resources apart from the classification training set. 2.2 Degree of Preprocessing Many relationship classification methods utilize some language-dependent preprocessing, like deep or shallow parsin</context>
<context position="11105" citStr="Turney, 2005" startWordPosition="1679" endWordPosition="1680">xperimentation with common learning algorithms (Hendrickx et al., 2007). In this paper we did not focus on a single ML algorithm, letting algorithm selection be automatically based on cross-validation results on the training set, as in (Hendrickx et al., 2007) but using more algorithms and allowing a more flexible parameter choice. 2.5 Training Data As stated above, several categorization schemes for nominals have been proposed. Nastase and Szpakowicz (2003) proposed a two-level hierarchy with 5 (30) classes at the top (bottom) levels3. This hierarchy and a corresponding dataset were used in (Turney, 2005; Turney, 2006) and (Nastase et al., 2006) for evaluation of their algorithms. Moldovan et al. (2004) proposed a different scheme with 35 classes. The most recent dataset has been developed for SemEval 07 Task 4 (Girju et al., 2007). This manually annotated dataset includes a representative rather than exhaustive list of 7 important nominal relationships. We have used this dataset, strictly following the evaluation protocol. This made it possible to meaningfully compare our method to state-ofthe-art methods for relation classification. 3 Pattern Clustering Algorithm Our pattern clustering algo</context>
<context position="32115" citStr="Turney, 2005" startWordPosition="5220" endWordPosition="5221">of the context of the whole sentence in which they appear. Since our algorithm does not utilize test sentence contextual information, we do not expect it to show exceptional performance on such items. This is a good topic for future research. Since the SemEval dataset is of a very specific nature, we have also applied our classification framework to the (Nastase and Szpakowicz, 2003) dataset, which contains 600 pairs labeled with 5 main relationship types. We have used the exact evaluation procedure described in (Turney, 2006), achieving a class f-score average of 60.1, as opposed to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al., 2006). This shows that our method produces superior results for rather differing datasets. 7 Conclusion Relationship classification is known to improve many practical tasks, e.g., textual entailment (Tatu and Moldovan, 2005). We have presented a novel framework for relationship classification, based on pattern clusters prepared as a standalone resource independently of the training set. Our method outperforms current state-of-the-art algorithms that do not utilize WordNet tags on Task 4 of SemEval-07. In practical situations, it would not be feasible to provide a </context>
</contexts>
<marker>Turney, 2005</marker>
<rawString>Turney, P., 2005. Measuring semantic similarity by latent relational analysis. IJCAI ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Expressing implicit semantic relations without supervision.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="9455" citStr="Turney, 2006" startWordPosition="1426" endWordPosition="1427">However, the most prominent feature type is based on lexico-syntactic patterns in which the related words co-appear. Since (Hearst, 1992), numerous works have used patterns for discovery and identification of instances of semantic relationships (e.g., (Girju et al., 2006; Snow et al., 2006; Banko et al, 2007)). Rosenfeld and Feldman (2007) discover relationship instances by clustering entities appearing in similar contexts. Strategies were developed for discovery of multiple patterns for some specified lexical relationship (Pantel and Pennacchiotti, 2006) and for unsupervised pattern ranking (Turney, 2006). Davidov et al. (2007) use pattern clusters to define general relationships, but these are specific to a given concept. No study so far has proposed a method to define, discover and represent general relationships present in an arbitrary corpus. In (Davidov and Rappoport, 2008) we present an approach to extract pattern clusters from an untagged corpus. Each such cluster represents some unspecified lexical relationship. In this paper, we use these pattern clusters as the (only) source of machine learning features for a nominal relationship classification problem. Unlike the majority of current</context>
<context position="11120" citStr="Turney, 2006" startWordPosition="1681" endWordPosition="1682"> with common learning algorithms (Hendrickx et al., 2007). In this paper we did not focus on a single ML algorithm, letting algorithm selection be automatically based on cross-validation results on the training set, as in (Hendrickx et al., 2007) but using more algorithms and allowing a more flexible parameter choice. 2.5 Training Data As stated above, several categorization schemes for nominals have been proposed. Nastase and Szpakowicz (2003) proposed a two-level hierarchy with 5 (30) classes at the top (bottom) levels3. This hierarchy and a corresponding dataset were used in (Turney, 2005; Turney, 2006) and (Nastase et al., 2006) for evaluation of their algorithms. Moldovan et al. (2004) proposed a different scheme with 35 classes. The most recent dataset has been developed for SemEval 07 Task 4 (Girju et al., 2007). This manually annotated dataset includes a representative rather than exhaustive list of 7 important nominal relationships. We have used this dataset, strictly following the evaluation protocol. This made it possible to meaningfully compare our method to state-ofthe-art methods for relation classification. 3 Pattern Clustering Algorithm Our pattern clustering algorithm is design</context>
<context position="32034" citStr="Turney, 2006" startWordPosition="5206" endWordPosition="5207">et does not explicitly mark items whose correct classification requires analysis of the context of the whole sentence in which they appear. Since our algorithm does not utilize test sentence contextual information, we do not expect it to show exceptional performance on such items. This is a good topic for future research. Since the SemEval dataset is of a very specific nature, we have also applied our classification framework to the (Nastase and Szpakowicz, 2003) dataset, which contains 600 pairs labeled with 5 main relationship types. We have used the exact evaluation procedure described in (Turney, 2006), achieving a class f-score average of 60.1, as opposed to 54.6 in (Turney, 2005) and 51.2 in (Nastase et al., 2006). This shows that our method produces superior results for rather differing datasets. 7 Conclusion Relationship classification is known to improve many practical tasks, e.g., textual entailment (Tatu and Moldovan, 2005). We have presented a novel framework for relationship classification, based on pattern clusters prepared as a standalone resource independently of the training set. Our method outperforms current state-of-the-art algorithms that do not utilize WordNet tags on Task</context>
</contexts>
<marker>Turney, 2006</marker>
<rawString>Turney, P., 2006. Expressing implicit semantic relations without supervision. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Witten</author>
<author>E Frank</author>
</authors>
<date>1999</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan</publisher>
<location>Kaufman, San Francisco, CA.</location>
<contexts>
<context position="10480" citStr="Witten and Frank, 1999" startWordPosition="1581" endWordPosition="1584">lexical relationship. In this paper, we use these pattern clusters as the (only) source of machine learning features for a nominal relationship classification problem. Unlike the majority of current studies, we avoid using any other features that require some language-specific information or are devised for specific relationship types. 2.4 Classification Algorithm Various learning algorithms have been used for relation classification. Common choices include variations of SVM (Girju et al., 2004; Nastase et al., 2006), decision trees and memory-based learners. Freely available tools like Weka (Witten and Frank, 1999) allow easy experimentation with common learning algorithms (Hendrickx et al., 2007). In this paper we did not focus on a single ML algorithm, letting algorithm selection be automatically based on cross-validation results on the training set, as in (Hendrickx et al., 2007) but using more algorithms and allowing a more flexible parameter choice. 2.5 Training Data As stated above, several categorization schemes for nominals have been proposed. Nastase and Szpakowicz (2003) proposed a two-level hierarchy with 5 (30) classes at the top (bottom) levels3. This hierarchy and a corresponding dataset w</context>
</contexts>
<marker>Witten, Frank, 1999</marker>
<rawString>Witten, H., Frank, E., 1999. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufman, San Francisco, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>