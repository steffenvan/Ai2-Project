<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000118">
<title confidence="0.44588475">
Briefly Noted
Generating Natural Language
Descriptions with Integrated Text and
Examples
</title>
<author confidence="0.387346">
Vibhu 0. Mittal
</author>
<bodyText confidence="0.994374916666667">
(Just Research and Carnegie Mellon Univer-
sity)
Mahwah, NJ: Lawrence Erlbaum Associates,
1999, xxv+260 pp; hardbound, ISBN
0-8058-2414-6, $45.00; paperbound, ISBN
0-8058-2415-4, $22.50
Examples play a crucial role in instruc-
tion manuals, textbooks, and documenta-
tion. If they are carefully chosen they can
show clearly how a new facility or language
can be used, while also supporting concep-
tual understanding. To be effective, examples
should be linked with any textual explana-
tion of a topic, complementing that descrip-
tion.
Language generation techniques have
been used in several prototype documen-
tation systems—e.g., Reiter, Mellish, and
Levine (1995). Documentation can be gener-
ated on-the-fly, tailored to characteristics of
the particular user, using a knowledge base
that can (sometimes) be automatically up-
dated as a system specification is revised.
This provides the possibility of improved
system maintainability and effectiveness. If
such systems are to begin to challenge con-
ventional methods for documentation, then it
is essential that they provide integrated and
well-chosen examples.
This book looks at how examples can be
selected within a system to generate nat-
ural language descriptions. This builds on
the work of the Explainable Expert Systems
project (Swartout, Paris, and Moore 1992)
and many of the examples illustrate a plan
language used in that project. The book is
based on the author&apos;s Ph.D. thesis and in-
cludes an interesting review of work on the
use of examples, taken from several dis-
ciplines, some conclusions and illustrations
from a corpus analysis of instructional texts,
and a detailed description of an implemented
system.
The book highlights many of the issues
that need to be addressed when generating
examples that are based on some underly-
ing specification. A particular contribution
is highlighting that the use (and categoriza-
tion) of examples should depend on any sur-
rounding textual explanation.
Given the range of interesting issues dis-
cussed, the actual system description is a
little disappointing. For example, the rather
general issue of how the presentation of ex-
amples depends on text type is reduced to a
simple expert/novice reader distinction, and
the dependence of examples on the type of
knowledge being conveyed is not addressed.
The system, however, suggests a general di-
rection and approach for integrated exam-
ple generation, and highlights the issues and
problems.
One problem that is highlighted by the
book is the difficulty in generating effective
examples given limitations in the underlying
knowledge representation. The system de-
scribed uses representations of concepts that
are purely syntactic (simply the BNF defini-
tion of allowed constructs). As a result, some
of the examples are a little odd. For example,
a generated example of the use of the LISP
function let is:
</bodyText>
<sectionHeader confidence="0.559571" genericHeader="abstract">
(LET ((ORANGES FISHES))
MEN)
</sectionHeader>
<bodyText confidence="0.9843288">
While syntactically acceptable, it is certainly
rather odd! This highlights a general diffi-
culty in generating effective descriptions—
they can only be as good as your underlying
representation allows.
Overall I found the examples and discus-
sion in the book more interesting than the
details of the actual system, which were occa-
sionally obscured by the effort needed to fol-
low some of the underlying representations.
It is an interesting book to read, and I would
recommend it both to those working on text
planning and those with an interest in the
use of examples.—Alison Cawsey, Heriot-Watt
University
</bodyText>
<sectionHeader confidence="0.70986" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.9285285">
Reiter, Ehud, Christopher Mellish, and John
Levine. 1995. Automatic generation of
technical documentation. Applied Artificial
Intelligence, 9(3):259-287.
Swartout, William R., Cecile L. Paris, and
Johanna D. Moore. 1992. Design for
explainable expert systems. IEEE Expert,
6(3):58-64.
</bodyText>
<page confidence="0.986583">
635
</page>
<figure confidence="0.835256">
Computational Linguistics Volume 25, Number 4
Corpus Linguistics: Investigating
Language Structure and Use
Douglas Biber, Susan Conrad, and Randi
Reppen
</figure>
<bodyText confidence="0.986616094736842">
(Northern Arizona University, Iowa State
University, and Northern Arizona
University)
Cambridge University Press (Cambridge
approaches to linguistics, edited by Jean
Aitchison), 1998, x+300 pp; hardbound,
ISBN 0-521-49622-5, $59.95; paperbound,
ISBN 0-521-49957-7, $19.95
This book provides fairly detailed analyses of
two research questions in corpus linguistics.
The first half discusses how a concordance,
simple counting programs, and a corpus can
be used to identify differences in the rate of
occurrence of a linguistic feature across dif-
ferent registers or conditioned on another lin-
guistic feature. The second, technically more
elaborate, half discusses factor analysis as
a means for combining such counts across
multiple features and arriving at more con-
cise descriptors of differences across regis-
ters. Both questions are rephrased several
times in different forms, involving lexical,
syntactic, or discourse features and contrasts
between speech and written text, between
native and ESL speakers, and across differ-
ent types of scientific writings, to name a few.
In each case, the methodology behind corpus
selection, feature identification, calculation of
the results with a computer, manual editing,
and interpretation of the results is explained
in sufficient detail. There is a collection of
highly readable, if somewhat short, essays on
methodological issues at the end of the book;
these range from corpus design to tagging to
(very briefly) statistical interpretation. There
is also a substantial bibliography on the sub-
ject (up to 1996).
The book appears to be aimed at under-
graduates in linguistics with no experience
of corpus linguistics; even moderately tech-
nical linguistic terms are explained upon first
mention. It will also be useful to those the-
oretical linguists who have managed to re-
main unaware of quantitative methods dur-
ing the past ten years. Each analysis is pre-
sented very clearly, and can be replicated by
the reader (the authors provide an extensive
list of easily accessible corpora and concor-
dancing tools), enhancing the book&apos;s value
for the classroom. The authors make a par-
ticular effort to avoid intimidating the reader
with computer terminology or program list-
ings; not a single line of code appears in the
book.
However, the book&apos;s scope is narrow. The
reader familiar with Biber&apos;s earlier work and
that of his students learns little new—the
methodology is substantially the same as in
Biber &apos;s earlier Variation across Speech and Writ-
ing (1988) and almost all experimental results
have been published before. There is no dis-
cussion of predictive methods or of statisti-
cal models of language, both of which this
reviewer would consider appropriate for a
volume titled &amp;quot;Corpus Linguistics.&amp;quot; Even in
the area that the book does cover, several im-
portant issues receive inadequate treatment.
There is only brief discussion and no detailed
calculations of statistical tests of significance,
so the (presumably inexperienced) reader has
no means of deciding when the corpus and
the feature counts are large enough. Even
though factor analysis is the centerpiece of
the second half of the book, there is no expla-
nation of how the factors and their loadings
might be obtained in practice. These omis-
sions become more apparent because of the
book&apos;s one shortcoming in presentation: al-
though the authors are lucid, they tend to
be repetitive as they detail only superficially
dissimilar studies. The reader tends to search
for nonexistent differences in methodology,
and, after a few sections, is tempted to jump
to the study&apos;s results and summary, which
do make for interesting reading.
This book could be used as part of the
curriculum for an introductory corpus lin-
guistics class, especially for students with a
humanities background. But it will proba-
bly provide only for a portion of a semester,
and will not give by itself a sufficiently well-
rounded perspective in corpus linguistics—
don&apos;t throw out your copy of Mosteller
and Wallace yet.—Vasileios Hatzivassiloglou,
Columbia University
</bodyText>
<sectionHeader confidence="0.846574" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.766696">
Biber, Douglas. 1988. Variation across Speech
and Writing. Cambridge University Press.
</bodyText>
<footnote confidence="0.610671333333333">
Mosteller, Frederick and David L. Wallace.
1984. Applied Bayesian and Classical
Inference: The Case of The Federalist Papers.
(Second edition of Inference and Disputed
Authorship: The Federalist [1964]).
Springer-Verlag, New York.
</footnote>
<page confidence="0.997435">
636
</page>
<bodyText confidence="0.584301">
Briefly Noted
</bodyText>
<subsectionHeader confidence="0.861648">
Lexical Relations
</subsectionHeader>
<bodyText confidence="0.994434416666666">
Jean-Pierre Koenig
(State University of New York at Buffalo)
Stanford: CSLI Publications (Stanford
monographs in linguistics), 1999, x+213pp;
distributed by Cambridge University Press;
hardbound ISBN 1-57586-177-1, $49.95;
paperbound, ISBN 1-57586-178-3, $18.95
&amp;quot;Recent work in syntax has shown that
much of a language&apos;s behavior stems from
the information structure associated with its
words. The thrust of this book is to pro-
vide a model of lexical relations which rec-
onciles the lexicon&apos;s idiosyncratic and pro-
ductive aspects. Building on work in Head-
driven Phrase-Structure Grammar, an organi-
zation of lexical knowledge—called the Type
Underspecified Hierarchical Lexicon—is pro-
posed, through which partial regularities,
medium-size generalization, and truly pro-
ductive processes receive a unified model. Its
basic thesis is that all lexical relations reduce
to categorization (the membership of the two
related lexemes in a common category) and
that category intersection is the only mecha-
nism needed to model lexical processes pro-
vided lexical items can be stored partially
underspecified as to their category member-
ship. Aside from the conceptual simplifica-
tion that results from this move, the book
demonstrates that several empirical and the-
oretical benefits accrue to this architecture;
in particular, many salient properties of mor-
phological processes are shown to reduce to
inherent, formal properties of the organiza-
tion of the lexicon.&amp;quot;—From the publisher&apos;s an-
nouncement
</bodyText>
<subsectionHeader confidence="0.938966666666667">
Semantics and Syntax in Lexical
Functional Grammar:
The Resource Logic Approach
</subsectionHeader>
<bodyText confidence="0.9480395">
Mary Dalrymple (editor)
(Xerox Palo Alto Research Center)
Cambridge, MA: The MIT Press (Language,
speech, and communication series),
x+399 pp; hardbound, ISBN 0-262-04171-5,
$40.00
&amp;quot;A new, deductive approach to the syntax-
semantics interface integrates two mature
and successful lines of research: logical de-
duction for semantic composition and the
Lexical Functional Grammar (LFG) approach
to the analysis of linguistic structure. It is of-
ten referred to as the &apos;glue&apos; approach because
of the role of logic in gluing meanings to-
gether.
&amp;quot;The glue approach has attracted signifi-
cant attention from, among others, logicians
working in the relatively new and active field
of linear logic; linguists interested in a novel
deductive approach to the interface between
syntax and semantics within a nontransfor-
mational, constraint-based syntactic frame-
work; and computational linguists and com-
puter scientists interested in an approach to
semantic composition that is grounded in a
conceptually simple but powerful computa-
tional framework.
&amp;quot;This introduction to and overview of the
new approach is the first book to bring to-
gether the research of the major contributors
to the field.&amp;quot;—From the publisher&apos;s announce-
ment
</bodyText>
<reference confidence="0.947003225806451">
Evaluation of the Linguistic
Performance of Machine
Translation Systems:
Proceedings of the [Workshop at]
Konvens &apos;98 in Bonn
Rita Niibel and Uta Seewald-Heeg
(editors)
(Universitat des Saarlandes and
Universitat Hannover)
St. Augustin, Germany: Gardez! Verlag
(Sprachwissenschaft, Computerlinguistik
und neue Medien, edited by Nico Weber,
volume 2), 1998, 178 pp; paperbound,
ISBN 3-928624-97-0, DM 49.90
The contents of the volume are as follows:
&amp;quot;Linguistically oriented evaluation of ma-
chine translation&amp;quot; by Rita Nilbel and
Uta Seewald-Heeg
&amp;quot;Textsortenspezifische Evaluation maschin-
eller Ubersetzungssysteme am Beispiel
von Instruktionstexten&amp;quot; by Uta
Seewald-Heeg
&amp;quot;Phanomenspezifische Evaluierung von ma-
schinellen Ubersetzungssystemen
am Beispiel von Koordination&amp;quot;
by Rita Niibel
&amp;quot;Komposita im Internet—Obersetzungs-
systeme auf dem Woodway&amp;quot; by Ulrike
Ulrich
&amp;quot;Zur Problematik der maschinellen Ober-
setzung von Nebensatzen zwischen den
</reference>
<page confidence="0.95554">
637
</page>
<note confidence="0.358419">
Computational Linguistics Volume 25, Number 4
</note>
<reference confidence="0.998538166666667">
Sprachen Englisch und Deutsch&amp;quot; by
Stephan Mehl, Britta Heidemann, and
Martin Volk
&amp;quot;Small scale evaluation methods&amp;quot; by
Simone Wagner
&amp;quot;DiET in the context of MT evaluation&amp;quot; by
Judith Klein, Sabine Lehmann, Klaus
Netter, and Tillmann Wegst
&amp;quot;Bewertung von MT-Systemen aus
Benutzersicht: Evaluierung im Projekt
MIROSLAV&amp;quot; by Jutta Marx
&amp;quot;Evaluation problems from a developer&apos;s
point of view&amp;quot; by Kirsten Falkedal
&amp;quot;Evaluation design: The EAGLES frame-
work&amp;quot; by Margaret King
&amp;quot;Linguistic MT evaluation: Assessment and
summary&amp;quot; by Rita Niibel and Uta
Seewald-Heeg
</reference>
<page confidence="0.997284">
638
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.8484035">Briefly Noted Generating Natural Language Descriptions with Integrated Text and Examples</title>
<note confidence="0.907568">0. (Just Research and Carnegie Mellon Univer-</note>
<email confidence="0.728026">sity)</email>
<affiliation confidence="0.798145">Mahwah, NJ: Lawrence Erlbaum Associates,</affiliation>
<address confidence="0.8135385">1999, xxv+260 pp; hardbound, ISBN 0-8058-2414-6, $45.00; paperbound, ISBN</address>
<phone confidence="0.421899">0-8058-2415-4, $22.50</phone>
<abstract confidence="0.998443792682927">Examples play a crucial role in instruction manuals, textbooks, and documentation. If they are carefully chosen they can show clearly how a new facility or language can be used, while also supporting conceptual understanding. To be effective, examples should be linked with any textual explanation of a topic, complementing that description. Language generation techniques have been used in several prototype documentation systems—e.g., Reiter, Mellish, and Levine (1995). Documentation can be generated on-the-fly, tailored to characteristics of the particular user, using a knowledge base that can (sometimes) be automatically updated as a system specification is revised. This provides the possibility of improved system maintainability and effectiveness. If such systems are to begin to challenge conventional methods for documentation, then it is essential that they provide integrated and well-chosen examples. This book looks at how examples can be selected within a system to generate natural language descriptions. This builds on the work of the Explainable Expert Systems project (Swartout, Paris, and Moore 1992) and many of the examples illustrate a plan language used in that project. The book is based on the author&apos;s Ph.D. thesis and includes an interesting review of work on the use of examples, taken from several disciplines, some conclusions and illustrations from a corpus analysis of instructional texts, and a detailed description of an implemented system. The book highlights many of the issues that need to be addressed when generating examples that are based on some underlying specification. A particular contribution is highlighting that the use (and categorization) of examples should depend on any surrounding textual explanation. Given the range of interesting issues discussed, the actual system description is a little disappointing. For example, the rather general issue of how the presentation of examples depends on text type is reduced to a simple expert/novice reader distinction, and the dependence of examples on the type of knowledge being conveyed is not addressed. The system, however, suggests a general direction and approach for integrated example generation, and highlights the issues and problems. One problem that is highlighted by the book is the difficulty in generating effective examples given limitations in the underlying knowledge representation. The system described uses representations of concepts that are purely syntactic (simply the BNF definition of allowed constructs). As a result, some of the examples are a little odd. For example, a generated example of the use of the LISP function let is: (LET ((ORANGES FISHES)) MEN) While syntactically acceptable, it is certainly rather odd! This highlights a general difficulty in generating effective descriptions— they can only be as good as your underlying representation allows. Overall I found the examples and discussion in the book more interesting than the details of the actual system, which were occasionally obscured by the effort needed to follow some of the underlying representations. It is an interesting book to read, and I would recommend it both to those working on text planning and those with an interest in the of examples.—Alison</abstract>
<note confidence="0.5880003">University References Reiter, Ehud, Christopher Mellish, and John Levine. 1995. Automatic generation of documentation. Artificial Swartout, William R., Cecile L. Paris, and Johanna D. Moore. 1992. Design for expert systems. Expert, 635 Computational Linguistics Volume 25, Number 4</note>
<title confidence="0.9325255">Corpus Linguistics: Investigating Language Structure and Use</title>
<author confidence="0.987794">Douglas Biber</author>
<author confidence="0.987794">Susan Conrad</author>
<author confidence="0.987794">Randi</author>
<affiliation confidence="0.80524125">Reppen (Northern Arizona University, Iowa State University, and Northern Arizona University)</affiliation>
<address confidence="0.630189">Cambridge University Press (Cambridge</address>
<note confidence="0.941669">approaches to linguistics, edited by Jean Aitchison), 1998, x+300 pp; hardbound, ISBN 0-521-49622-5, $59.95; paperbound, ISBN 0-521-49957-7, $19.95 This book provides fairly detailed analyses of</note>
<abstract confidence="0.99751919047619">two research questions in corpus linguistics. The first half discusses how a concordance, simple counting programs, and a corpus can be used to identify differences in the rate of occurrence of a linguistic feature across different registers or conditioned on another linguistic feature. The second, technically more elaborate, half discusses factor analysis as a means for combining such counts across multiple features and arriving at more concise descriptors of differences across registers. Both questions are rephrased several times in different forms, involving lexical, syntactic, or discourse features and contrasts between speech and written text, between native and ESL speakers, and across different types of scientific writings, to name a few. In each case, the methodology behind corpus selection, feature identification, calculation of the results with a computer, manual editing, and interpretation of the results is explained in sufficient detail. There is a collection of highly readable, if somewhat short, essays on methodological issues at the end of the book; these range from corpus design to tagging to (very briefly) statistical interpretation. There is also a substantial bibliography on the subject (up to 1996). The book appears to be aimed at undergraduates in linguistics with no experience of corpus linguistics; even moderately technical linguistic terms are explained upon first mention. It will also be useful to those theoretical linguists who have managed to remain unaware of quantitative methods during the past ten years. Each analysis is presented very clearly, and can be replicated by the reader (the authors provide an extensive list of easily accessible corpora and concordancing tools), enhancing the book&apos;s value for the classroom. The authors make a particular effort to avoid intimidating the reader with computer terminology or program listings; not a single line of code appears in the book. However, the book&apos;s scope is narrow. The reader familiar with Biber&apos;s earlier work and that of his students learns little new—the methodology is substantially the same as in &apos;s earlier across Speech and Writand almost all experimental results have been published before. There is no discussion of predictive methods or of statistical models of language, both of which this reviewer would consider appropriate for a volume titled &amp;quot;Corpus Linguistics.&amp;quot; Even in the area that the book does cover, several important issues receive inadequate treatment. There is only brief discussion and no detailed calculations of statistical tests of significance, so the (presumably inexperienced) reader has no means of deciding when the corpus and the feature counts are large enough. Even though factor analysis is the centerpiece of the second half of the book, there is no explanation of how the factors and their loadings might be obtained in practice. These omissions become more apparent because of the book&apos;s one shortcoming in presentation: although the authors are lucid, they tend to be repetitive as they detail only superficially dissimilar studies. The reader tends to search for nonexistent differences in methodology, and, after a few sections, is tempted to jump to the study&apos;s results and summary, which do make for interesting reading. This book could be used as part of the curriculum for an introductory corpus linguistics class, especially for students with a humanities background. But it will probably provide only for a portion of a semester, and will not give by itself a sufficiently wellrounded perspective in corpus linguistics— don&apos;t throw out your copy of Mosteller</abstract>
<author confidence="0.792015">Wallace Hatzivassiloglou</author>
<affiliation confidence="0.99992">Columbia University</affiliation>
<title confidence="0.858803">References</title>
<author confidence="0.898107">across Speech</author>
<affiliation confidence="0.979854">Writing. University Press.</affiliation>
<address confidence="0.768305">Mosteller, Frederick and David L. Wallace.</address>
<note confidence="0.464276666666667">Bayesian and Classical Inference: The Case of The Federalist Papers. edition of and Disputed The Federalist Springer-Verlag, New York. 636</note>
<title confidence="0.9754875">Briefly Noted Lexical Relations</title>
<author confidence="0.977316">Koenig</author>
<affiliation confidence="0.997526">(State University of New York at Buffalo)</affiliation>
<address confidence="0.64054">Stanford: CSLI Publications (Stanford</address>
<note confidence="0.93998875">monographs in linguistics), 1999, x+213pp; distributed by Cambridge University Press; hardbound ISBN 1-57586-177-1, $49.95; paperbound, ISBN 1-57586-178-3, $18.95</note>
<abstract confidence="0.984517931034483">amp;quot;Recent work in syntax has shown that much of a language&apos;s behavior stems from the information structure associated with its words. The thrust of this book is to provide a model of lexical relations which reconciles the lexicon&apos;s idiosyncratic and productive aspects. Building on work in Headdriven Phrase-Structure Grammar, an organization of lexical knowledge—called the Type Underspecified Hierarchical Lexicon—is proposed, through which partial regularities, medium-size generalization, and truly productive processes receive a unified model. Its basic thesis is that all lexical relations reduce to categorization (the membership of the two related lexemes in a common category) and that category intersection is the only mechanism needed to model lexical processes provided lexical items can be stored partially underspecified as to their category membership. Aside from the conceptual simplification that results from this move, the book demonstrates that several empirical and theoretical benefits accrue to this architecture; in particular, many salient properties of morphological processes are shown to reduce to inherent, formal properties of the organizaof the lexicon.&amp;quot;—From publisher&apos;s announcement</abstract>
<title confidence="0.951573666666667">Semantics and Syntax in Lexical Functional Grammar: The Resource Logic Approach</title>
<author confidence="0.99766">Mary Dalrymple</author>
<affiliation confidence="0.994706">(Xerox Palo Alto Research Center)</affiliation>
<address confidence="0.873775">Cambridge, MA: The MIT Press (Language,</address>
<abstract confidence="0.9572645">speech, and communication series), x+399 pp; hardbound, ISBN 0-262-04171-5, $40.00 &amp;quot;A new, deductive approach to the syntaxsemantics interface integrates two mature successful lines of research: logical deduction for semantic composition and the Lexical Functional Grammar (LFG) approach to the analysis of linguistic structure. It is often referred to as the &apos;glue&apos; approach because of the role of logic in gluing meanings together. &amp;quot;The glue approach has attracted significant attention from, among others, logicians working in the relatively new and active field of linear logic; linguists interested in a novel deductive approach to the interface between syntax and semantics within a nontransformational, constraint-based syntactic framework; and computational linguists and computer scientists interested in an approach to semantic composition that is grounded in a conceptually simple but powerful computational framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Evaluation of the Linguistic Performance of Machine Translation Systems:</title>
<booktitle>Proceedings of the [Workshop at] Konvens &apos;98 in</booktitle>
<location>Bonn</location>
<marker></marker>
<rawString>Evaluation of the Linguistic Performance of Machine Translation Systems: Proceedings of the [Workshop at] Konvens &apos;98 in Bonn</rawString>
</citation>
<citation valid="false">
<editor>Rita Niibel and Uta Seewald-Heeg (editors)</editor>
<marker></marker>
<rawString>Rita Niibel and Uta Seewald-Heeg (editors)</rawString>
</citation>
<citation valid="false">
<institution>(Universitat des Saarlandes and Universitat Hannover)</institution>
<marker></marker>
<rawString>(Universitat des Saarlandes and Universitat Hannover)</rawString>
</citation>
<citation valid="false">
<authors>
<author>Augustin</author>
</authors>
<title>Germany: Gardez! Verlag (Sprachwissenschaft, Computerlinguistik und neue Medien, edited by Nico Weber,</title>
<volume>2</volume>
<pages>3--928624</pages>
<marker>Augustin, </marker>
<rawString>St. Augustin, Germany: Gardez! Verlag (Sprachwissenschaft, Computerlinguistik und neue Medien, edited by Nico Weber, volume 2), 1998, 178 pp; paperbound, ISBN 3-928624-97-0, DM 49.90</rawString>
</citation>
<citation valid="false">
<title>The contents of the volume are as follows: &amp;quot;Linguistically oriented evaluation of machine translation&amp;quot; by Rita Nilbel and Uta Seewald-Heeg</title>
<marker></marker>
<rawString>The contents of the volume are as follows: &amp;quot;Linguistically oriented evaluation of machine translation&amp;quot; by Rita Nilbel and Uta Seewald-Heeg</rawString>
</citation>
<citation valid="false">
<title>Textsortenspezifische Evaluation maschineller Ubersetzungssysteme am Beispiel von Instruktionstexten&amp;quot; by Uta Seewald-Heeg</title>
<marker></marker>
<rawString>&amp;quot;Textsortenspezifische Evaluation maschineller Ubersetzungssysteme am Beispiel von Instruktionstexten&amp;quot; by Uta Seewald-Heeg</rawString>
</citation>
<citation valid="false">
<title>Phanomenspezifische Evaluierung von maschinellen Ubersetzungssystemen am Beispiel von Koordination&amp;quot; by Rita Niibel</title>
<marker></marker>
<rawString>&amp;quot;Phanomenspezifische Evaluierung von maschinellen Ubersetzungssystemen am Beispiel von Koordination&amp;quot; by Rita Niibel</rawString>
</citation>
<citation valid="false">
<title>Komposita im Internet—Obersetzungssysteme auf dem Woodway&amp;quot; by Ulrike Ulrich</title>
<marker></marker>
<rawString>&amp;quot;Komposita im Internet—Obersetzungssysteme auf dem Woodway&amp;quot; by Ulrike Ulrich</rawString>
</citation>
<citation valid="false">
<title>Zur Problematik der maschinellen Obersetzung von Nebensatzen zwischen den Sprachen Englisch und Deutsch&amp;quot; by Stephan Mehl,</title>
<location>Britta Heidemann, and Martin Volk</location>
<marker></marker>
<rawString>&amp;quot;Zur Problematik der maschinellen Obersetzung von Nebensatzen zwischen den Sprachen Englisch und Deutsch&amp;quot; by Stephan Mehl, Britta Heidemann, and Martin Volk</rawString>
</citation>
<citation valid="false">
<title>Small scale evaluation methods&amp;quot; by Simone Wagner &amp;quot;DiET in the context of MT evaluation&amp;quot; by Judith Klein,</title>
<location>Sabine Lehmann, Klaus</location>
<marker></marker>
<rawString>&amp;quot;Small scale evaluation methods&amp;quot; by Simone Wagner &amp;quot;DiET in the context of MT evaluation&amp;quot; by Judith Klein, Sabine Lehmann, Klaus</rawString>
</citation>
<citation valid="false">
<authors>
<author>Netter</author>
</authors>
<title>Tillmann Wegst &amp;quot;Bewertung von MT-Systemen aus Benutzersicht: Evaluierung im Projekt MIROSLAV&amp;quot; by Jutta Marx &amp;quot;Evaluation problems from a developer&apos;s point of view&amp;quot; by Kirsten Falkedal &amp;quot;Evaluation design: The EAGLES framework&amp;quot; by Margaret King</title>
<marker>Netter, </marker>
<rawString>Netter, and Tillmann Wegst &amp;quot;Bewertung von MT-Systemen aus Benutzersicht: Evaluierung im Projekt MIROSLAV&amp;quot; by Jutta Marx &amp;quot;Evaluation problems from a developer&apos;s point of view&amp;quot; by Kirsten Falkedal &amp;quot;Evaluation design: The EAGLES framework&amp;quot; by Margaret King</rawString>
</citation>
<citation valid="false">
<authors>
<author>Linguistic MT</author>
</authors>
<title>evaluation: Assessment and summary&amp;quot; by Rita Niibel and Uta Seewald-Heeg</title>
<marker>MT, </marker>
<rawString>&amp;quot;Linguistic MT evaluation: Assessment and summary&amp;quot; by Rita Niibel and Uta Seewald-Heeg</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>