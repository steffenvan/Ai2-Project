<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009029">
<sectionHeader confidence="0.916924" genericHeader="abstract">
AUTOMATED SPEECH RECOGNITION:
A FRAMEWORK FOR RESEARCH
</sectionHeader>
<author confidence="0.456232">
Anne Johnstone
</author>
<affiliation confidence="0.955567">
Department of Artificial Intelligence
Edinburgh University
</affiliation>
<address confidence="0.4850565">
Hope Park Square, Meadow Lane
Edinburgh EHB 9LL. (GB)
</address>
<email confidence="0.381128">
ABSTRACT
</email>
<bodyText confidence="0.999801676470588">
This paper reflects the view that the
decoding of speech, either by computer
systems or people, must to a large extent
be determined by the ways in which the
speaker has encoded the information
necessary for its comprehension. We
therefore place great emphasis on the use
of psycholinguistics as a tool for the
construction of models essential to the
characterisation of the speech
understanding task.
We are primarily concerned with the
interactions between the various levels at
which a fragment of speech can be
described (e.g. acoustic-phonetic,
lexical, syntactic, etc), and the ways in
which the knowledge bases associated with
each of these &amp;quot;levels&amp;quot; contribute towards
a final interpretation of an utterance. We
propose to use the Chart Parser as a
general computational framework for
simulating such interactions, since its
flexibility allows various models to be
implemented and evaluated.
Within this general framework we
discuss problems of information flow and
search strategy in combining evidence
across levels of description and across
time, during the extension of an
hypothesis. We stress the importance of
both psychological and computational
theory in developing a particular control
strategy which could be implemented within
the framework.
</bodyText>
<sectionHeader confidence="0.915804" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.99709680882353">
The decoding of speech, either by
computer systems or people, must to a
large extent be determined by the ways in
which the speaker has encoded the
information necessary for its
comprehension. Such a view is supported by
a large body of experimental evidence
concerning the ways in which various
factors (eg. predictability from context)
affect both the acoustic clarity with
which a speaker pronounces an utterance,
and the strategy the hearer appears to use
in identifying it. The task of the
Gerry Altmann
Department of Linguistics
Edinburgh University
George Square
Edinburgh EBB 9LL. (GB)
doMpdier system is to mimic, though
preferably model, this strategy. In order
to do so, one should presumably draw on
both computational and psychological
theories of process. Such a dual approach
has been shown to be feasible, and indeed
desirable, by research into early visual
processing (eg. Marr 1976) which has shown
that there can come a point when
psychological and computational
descriptions become barely
distinguishable. This analogy with early
visual processing is significant because
central to the development of the vision
research was the notion of &apos;modelling&apos;:
one can argue that a significant
difference between the so-called &apos;4th
Generation&apos; and &apos;5th Generation&apos;
technologies is that with the former ad-
hoc algorithms are applied to often
incomplete and unreliable data, while with
5th Generation systems, algorithms are
devised by first constructing qualitative
models suited to the task domain.
We propose to use psycholinguistics
as a tool for the construction of models
essential to the characterisation of the
speech understanding task. We believe that
this approach is essential to the
development of automated speech
recognition systems, and will also prove
beneficial to psychological models of
human speech processing, the majority of
which are underdetermined from a
computational point of view. Rumelhart and
McClelland have recently adopted a similar
approach to account for the major findings
in the psychological literature on letter
perception. By constructing a detailed
computational model of the processes
involved they were able to give an
alternative description of the recognition
of certain letter strings, which was
supported by subsequent psycholinguistic
experiments. Rumelhart and McClelland
emphasise the point that their results
were not predictable &apos;on paper&apos;, but were
the outcome of considerable
experimentation with the computational
model.
</bodyText>
<page confidence="0.996757">
239
</page>
<bodyText confidence="0.998307380952381">
Requirements of the Computational
Framework
The experience of the ARPA speech
project, which resulted in the design of a
number of speech recognition systems, has
demonstrated that the task of controlling
the interactions between the knowledge
bases which make up the system is at least
as problematic as that of defining the
knowledge bases. Major inadequacies in
the systems developed during the ARPA
project can be attributed to an early
commitment in one or more areas of design
which were not apparent until final
testing and evaluation of the complete
system began. An architecture is
required, therefore, which will permit the
development in parallel and relatively
independently of component knowledge bases
and methods of deploying them
computationally. It should also permit
the evaluation and testing of solutions
with partially specified or simulated
components. This will ensure that the
design of one component will not influence
unduly the design of any other component,
possibly to the detriment of both. In
addition, we should have the ability to
determine the consequences of component
design decisions by testing their
contributions to the overall goals of
speech recognition.
In order to fulfill these
requirements we propose to use the active
chart parser (e.g. Thompson &amp; Ritchie,
1984). This was specifically designed as
a flexible framework for the
implementation (both serial and parallel)
of different rule systems, and the
evaluation of strategies for using these
rule systems. It is described below in
more detail.
</bodyText>
<subsectionHeader confidence="0.668947">
The Computational Model
</subsectionHeader>
<bodyText confidence="0.999144147727272">
The problem in designing optimal
control or search strategies lies in
combining evidence across different levels
of description (e.g. acoustic-phonetic,
morpho-phonemic, syntactic, etc.), and
across time during the extension of a
hypothesis, such that promising
interpretations are given priority and the
right one wins. In this section we shall
consider just a few of the issues
concerning this flow of information.
Automated speech systems, in
particular those implemented during the
ARPA-SUR project, have been forced to
confront the errorfull and ambiguous
nature of speech, and to devise methods of
controlling the very large search space of
partial interpretations generated during
processing. Although the problem was
exacerbated by the poor performance of the
acoustic-phonetic processing used in these
systems, the experimental eviT:1ence
suggests that the solution will not be
found simply by improving techniques for
low-level feature detection. The
situation appears to be analogous to that
of visual processing, where &amp;quot;significant&amp;quot; •
features may be absent. If present, their
significance may also be open to a number
of interpretations.
Combining evidence across different
levels of description requires the
specification of information flow between
these levels. Within the psychological
literature, there is a growing tendency
away from &amp;quot;strong&amp;quot; (or &amp;quot;instructive&amp;quot;)
interactions towards &amp;quot;weak&amp;quot; (or
&amp;quot;selective&amp;quot;) interactions. With the
latter, the only permissible flow of
information involves the filtering out, by
one component, of alternatives produced by
other components (cf. Marslen-Wilson &amp;
Tyler, 1980; Crain &amp; Steedman, 1982;
Altmann &amp; Steedman, forthcoming), so in
hierarchical terms no component determines
what is produced by any other component
beneath it. A strong interaction, on the
other hand, allows one component to
direct, or guide, actively a second
component in the pursuit of a particular
hypothesis. Within the computational
literature, weak interactions are also
argued for on &amp;quot;aesthetic&amp;quot; grounds such as
Marr&apos;s principles of modularity and least
commitment (Marr, 1982).
The strongly interactive
heterarchical and blackboard models
implemented in HWIM and Hearsay II
respectively have been criticised for the
extremely complex control strategies which
they required. Problems arise with the
heterarchical model &amp;quot;because of the
difficulties of generating each of the
separate interfaces and, more importantly,
because of the necessity of specifying the
explicit control scheme.&amp;quot; (Reddy &amp; Erman,
1975). Similar problems arise with
existing blackboard models. Their
information flow allows strong top-down
direction of components, resulting once
again in highly complex control
strategies. Hierarchical models have
other problems, in that they allow too
little interaction between the knowledge
sources: within a strictly hierarchical
system, one cannot &amp;quot;interleave&amp;quot; the
processes associated with each different
level of knowledge, and hence one cannot
allow the very early filtering out by
higher-level components of what might only
be partial analyses at lower levels. This
situation (considered disadvantageous for
reasons of speed and efficiency) arises
because of the lack of any common
workspace over which the separate
components can operate. There is,
however, much to be said for hierarchical
systems in terms of the relative
</bodyText>
<page confidence="0.972402">
240
</page>
<bodyText confidence="0.998791833333333">
simplicity of the control strategies
needed to manage them, a consideration
which is fundamental to the design of any
speech recognition system.
active edge). The knowledge bases define
what extensions are possible, not the
parser.
The model currently being developed
embodies a weak hierarchical interaction,
since this seems most promising on both
psychological and computational grounds.
Unlike existing hierarchical Or
associative models, it uses a uniform
global data structure, a &amp;quot;chart&amp;quot;.
Associated with this structure is the
active chart parser.
The active chart parser consists of
the following:-
</bodyText>
<listItem confidence="0.9357654">
1) A uniform global data structure (the
Chart), represents competing pathways
through a search space, at different
levels of description, and at different
stages of analysis. Complete descriptions
</listItem>
<bodyText confidence="0.977633523364486">
are marked by &amp;quot;inactive&amp;quot; paths, called
edges, spanning temporally defined
portions of the utterance. These inactive
edges have pointers to the lower level
descriptions which support them. Partial
descriptions are marked by &amp;quot;active&amp;quot; edges
which carry representations of the data
needed to complete them. For example, a
syntactic edge, such as a noun phrase, may
span any complete descriptions that
partially support it, such as a determiner
or adjective. In addition, it will carry
a description of the syntactic properties
(e.g. noun) any inactive lexical edge must
have to count both as additional evidence
for this syntactic description and as
justification for its extension or
completion. The type and complexity of
the descriptions are determined by the
rule based knowledge systems used by the
parser, and are not determined by the
parser itself.
2) A multi-level task queueing structure
(the Agenda), which is used to order the
ways in which the descriptions will be
extended, through time and level of
abstraction, and thus to control the size
and direction of the search space. This
ordering on the agenda is controlled by
specifically designed search strategies
which determine the minimum amount of
search compatible with a low rate of error
in description. The power and flexibility
of this approach in tackling complex
system building tasks is well set out in
Bobrow et al. 1976).
3) An algorithm which automatically
schedules additions to the Chart onto the
Agenda for subsequent processing wherever
such extensions are possible. That is to
say, whenever a description which is
complete at some level (an inactive edge)
can be used to extend a partial
description at some higher level (an
To summarize, the chart is used to
represent and extend pathways, through
time and level of abstraction, through a
search space. Within the chart, there are
different types of path corresponding to
different levels of description, each of
which is associated with a particular
knowledge source. To the extent that
knowledge specific rules specify what
counts as constituent pathways at the
different levels of abstraction, a
hierarchical flow in information is
maintained. The weak interaction arises
because alternative pathways at one level
of description can be filtered through
attempts to build pathways at the next
&amp;quot;higher&amp;quot; level. This model differs from
straightforward hierarchical models, but
resembles associative models, in that
knowledge sources contribute to processing
without each source necessarily
corresponding to a distinct stage of
analysis in the processing sequence.
Having sketched the construction of
the search space we must now decide upon a
strategy for exploring that space. Most
current psychological theories appear to
assume strict &amp;quot;left-to-right&amp;quot; processing,
although this requires tackling stretches
of sound immediatedly which are of poor
acoustic quality, and which are relatively
unconstrained by higher level knowledge.
The majority of systems developed during
the ARPA project found it necessary to use
later occurring information to
disambiguate earlier parts of an
utterance. Moreover, there is
psycholinguistic evidence that the
&amp;quot;intelligibility&amp;quot; of a particular stretch
of sound increases with additional
evidence from later &amp;quot;rightward&amp;quot; stretches
of sound (Pollack &amp; Pickett, 1963; Warren
&amp; Warren, 1970). We propose to adopt a
system using a form of left-to-right
analysis which could approximate to the
power of middle-out analysis (used in HWIM
and Hearsay II) but without requiring the
construction of distinct &amp;quot;islands&amp;quot; and
with less computational expense. This
more precise method of using &amp;quot;right-
context effects&amp;quot; depends on the priority
scores assigned to paths. Such scores can
be thought of, for present purposes, as
some measure of &amp;quot;goodness of fit&amp;quot;. The
score on a spanning pathway (that is, a
pathway which spans other pathways
&amp;quot;beneath&amp;quot; it) is determined by the scores
on its constituents, and so is partly
determined by scores towards its right-
hand end. By virtue of affecting the
&amp;quot;spanning score&amp;quot;, a score on one sub-path
can affect the probability that another
sub-path to its left (as well as to its
</bodyText>
<page confidence="0.991825">
241
</page>
<bodyText confidence="0.999972911764706">
right) will finally be chosen as the best
description for the acoustic segment it
represents. We will use psycholinguistic
techniques to interrogate the &amp;quot;expert&amp;quot;
(i.e. statistically reliable experiments
with human listeners), in order to
determine both when such leftwards flowing
information is most often used for the
disambiguation of poor quality areas, and
what sets of paths it will affect. It
will be extremely useful to know whether
people regularly rely on information from
the right to disambiguate preceding
stretches of sound, or whether this
happens only at the beginning of
utterances as the HWIM strategy suggests.
Pollack and Pickett claim that there is no
effect on intelligibility of a word&apos;s
position within a stimulus, but
unfortunately they offer no inferential
statistics to back this claim.
This is only one of the many issues
in speech recognition which are
experimentally addressable. The results of
such experiments are obviously of
relevance to computational systems since
they can indicate where and when sources
of information are most likely to
contribute towards identification of an
utterance. Conversely, the attempt to
build a working model of at least some
parts of the process, will highlight many
areas where further experimental data is
needed.
</bodyText>
<subsectionHeader confidence="0.753907">
Concluding Remark
</subsectionHeader>
<bodyText confidence="0.999981285714286">
We hope that this sketch of part of
the proposed system has given a feel for
the combined approach taken here. It
developed through a re-examination of a
number of issues which arose during the
ARPA speech project, and a reconsideration
of these issues in the light of recent
, computational and psycholinguistic
advances. Given the success of these
recent advancements in the contributing
fields of research, we feel that the time
is right for the evaluation of a speech
recognition system along the lines laid
down here.
</bodyText>
<sectionHeader confidence="0.990918" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999811615384615">
This is a summary of a paper (Johnstone &amp;
Altmann, 1984) written as a result of
discussions held in the University of
Edinburgh School of Epistemics research
workshop on Lexical Access and Speech
Perception. We would like to thank the
members of that workshop, in particular
Dr. Ellen Bard and Dr. Henry Thompson.
The proposals contained therein have been
adopted by the Edinburgh contribution to
the Plessey Consortium&apos;s Alvey Large Scale
Demonstrator Project on Machine Assisted
Speech Transcription.
</bodyText>
<sectionHeader confidence="0.992574" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999497387755102">
Altmann, G.T. &amp; Steedman, M.J.
Forthcoming. The Garden Path in
Context: Reference and the Resolution of
Local Syntactic Ambiguity.
Bard, E.G. &amp; Anderson, A.H. 1983. The
unintelligibility of speech to children.
Journal 21 Child Language 10, 265-292
Crain, S. &amp; Steedman, M.J. 1982. On not
being led up the garden path: the use of
context by the psychological parser. In
(eds.) Dowty, D., Kartunnen, L., &amp;
Zwicky, A. Natural Language Parsing:
psychological, computational, and
theoretical Perspectives. In press.
Johnstone, A.M. &amp; Altmann, G.T. 1984.
Automated Speech Recognition: A
Framework for Research. Department of
Artificial Intelligence, University of
Edinburgh, Research Paper No. 233.
Also appears as Speech Input Project,
University of Edinburgh, Research Report
No. 2.
Marr, D. 1976. Early Processing of
Visual Information. Proc. Roy. Soc.,
275.b
Marslen-Wilson, W.D. &amp; Tyler, L.K. 1980.
The Temporal Structure of Spoken
Language Understanding. Cognition, 8,
1-71
McClelland, J.L &amp; Rumelhart, D.E. 1981.
An Interactive Activation Model of
Context Effects in Letter Perception:
Part I. An Account of Basic Findings.
In Psychological Review, 88, 375-407.
Pollack, I. &amp; Pickett, J.M. 1963. The
intelligibility of excerpts from
Conversation. Language and Speech, 6,
165-171.
Reddy, D.R. &amp; Ermann, L.D. 1975.
Tutorial on System Organisation for
Speech Understanding. In D.R. Reddy
(ed) Speech Recognition, Academic Press.
Rumelhart, D.E. &amp; McClelland, J.L. 1982.
An Interactive Activation Model of
Context Effects in Letter Perception:
Part II. The Contextual Enhancement
Effect. Some Tests and Extensions of
the Model. In Psychological Review, 89,
60-94.
</reference>
<page confidence="0.962656">
242
</page>
<reference confidence="0.999275375">
Thompson, H.S. &amp; Ritchie, G.D. 1984.
Techniques for Parsing Natural Language:
Two Examples. In M. Eisenstadt &amp; T.
O&apos;Shea (eds.) Artificial Intelligence
Skills. Harper &amp; Row.
Warren, R.M. &amp; Warren, R.P. 1970.
Auditory Confusions and Illusions.
Scientific American, 223, 30-36.
</reference>
<page confidence="0.999054">
243
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.202197">
<title confidence="0.997586">AUTOMATED SPEECH RECOGNITION: A FRAMEWORK FOR RESEARCH</title>
<author confidence="0.999503">Anne Johnstone</author>
<affiliation confidence="0.9998955">Department of Artificial Intelligence Edinburgh University</affiliation>
<abstract confidence="0.998339514285714">This paper reflects the view that the decoding of speech, either by computer systems or people, must to a large extent be determined by the ways in which the speaker has encoded the information necessary for its comprehension. We therefore place great emphasis on the use of psycholinguistics as a tool for the construction of models essential to the characterisation of the speech understanding task. We are primarily concerned with the betweenthe various levels at which a fragment of speech can be described (e.g. acoustic-phonetic, lexical, syntactic, etc), and the ways in which the knowledge bases associated with each of these &amp;quot;levels&amp;quot; contribute towards a final interpretation of an utterance. We propose to use the Chart Parser as a general computational framework for simulating such interactions, since its flexibility allows various models to be implemented and evaluated. Within this general framework we discuss problems of information flow and search strategy in combining evidence across levels of description and across time, during the extension of an hypothesis. We stress the importance of both psychological and computational theory in developing a particular control strategy which could be implemented within the framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>G T Altmann</author>
<author>M J Steedman</author>
</authors>
<marker>Altmann, Steedman, </marker>
<rawString>Altmann, G.T. &amp; Steedman, M.J.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Forthcoming</author>
</authors>
<title>The Garden Path in Context: Reference and the Resolution of Local Syntactic Ambiguity.</title>
<marker>Forthcoming, </marker>
<rawString>Forthcoming. The Garden Path in Context: Reference and the Resolution of Local Syntactic Ambiguity.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E G Bard</author>
<author>A H Anderson</author>
</authors>
<title>The unintelligibility of speech to children.</title>
<date>1983</date>
<journal>Journal 21 Child Language</journal>
<volume>10</volume>
<pages>265--292</pages>
<marker>Bard, Anderson, 1983</marker>
<rawString>Bard, E.G. &amp; Anderson, A.H. 1983. The unintelligibility of speech to children. Journal 21 Child Language 10, 265-292</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Crain</author>
<author>M J Steedman</author>
</authors>
<title>On not being led up the garden path: the use of context by the psychological parser.</title>
<date>1982</date>
<editor>In (eds.) Dowty, D., Kartunnen, L., &amp; Zwicky, A. Natural</editor>
<publisher>In press.</publisher>
<contexts>
<context position="7168" citStr="Crain &amp; Steedman, 1982" startWordPosition="1064" endWordPosition="1067"> where &amp;quot;significant&amp;quot; • features may be absent. If present, their significance may also be open to a number of interpretations. Combining evidence across different levels of description requires the specification of information flow between these levels. Within the psychological literature, there is a growing tendency away from &amp;quot;strong&amp;quot; (or &amp;quot;instructive&amp;quot;) interactions towards &amp;quot;weak&amp;quot; (or &amp;quot;selective&amp;quot;) interactions. With the latter, the only permissible flow of information involves the filtering out, by one component, of alternatives produced by other components (cf. Marslen-Wilson &amp; Tyler, 1980; Crain &amp; Steedman, 1982; Altmann &amp; Steedman, forthcoming), so in hierarchical terms no component determines what is produced by any other component beneath it. A strong interaction, on the other hand, allows one component to direct, or guide, actively a second component in the pursuit of a particular hypothesis. Within the computational literature, weak interactions are also argued for on &amp;quot;aesthetic&amp;quot; grounds such as Marr&apos;s principles of modularity and least commitment (Marr, 1982). The strongly interactive heterarchical and blackboard models implemented in HWIM and Hearsay II respectively have been criticised for th</context>
</contexts>
<marker>Crain, Steedman, 1982</marker>
<rawString>Crain, S. &amp; Steedman, M.J. 1982. On not being led up the garden path: the use of context by the psychological parser. In (eds.) Dowty, D., Kartunnen, L., &amp; Zwicky, A. Natural Language Parsing: psychological, computational, and theoretical Perspectives. In press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Johnstone</author>
<author>G T Altmann</author>
</authors>
<title>Automated Speech Recognition: A Framework for Research. Department of Artificial Intelligence,</title>
<date>1984</date>
<location>University of</location>
<marker>Johnstone, Altmann, 1984</marker>
<rawString>Johnstone, A.M. &amp; Altmann, G.T. 1984. Automated Speech Recognition: A Framework for Research. Department of Artificial Intelligence, University of</rawString>
</citation>
<citation valid="false">
<title>Also appears as Speech Input Project,</title>
<tech>Report No. 2.</tech>
<institution>University of Edinburgh, Research</institution>
<marker></marker>
<rawString>Edinburgh, Research Paper No. 233. Also appears as Speech Input Project, University of Edinburgh, Research Report No. 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marr</author>
</authors>
<title>Early Processing of Visual Information.</title>
<date>1976</date>
<booktitle>Proc.</booktitle>
<location>Roy. Soc., 275.b</location>
<contexts>
<context position="2366" citStr="Marr 1976" startWordPosition="359" endWordPosition="360">rious factors (eg. predictability from context) affect both the acoustic clarity with which a speaker pronounces an utterance, and the strategy the hearer appears to use in identifying it. The task of the Gerry Altmann Department of Linguistics Edinburgh University George Square Edinburgh EBB 9LL. (GB) doMpdier system is to mimic, though preferably model, this strategy. In order to do so, one should presumably draw on both computational and psychological theories of process. Such a dual approach has been shown to be feasible, and indeed desirable, by research into early visual processing (eg. Marr 1976) which has shown that there can come a point when psychological and computational descriptions become barely distinguishable. This analogy with early visual processing is significant because central to the development of the vision research was the notion of &apos;modelling&apos;: one can argue that a significant difference between the so-called &apos;4th Generation&apos; and &apos;5th Generation&apos; technologies is that with the former adhoc algorithms are applied to often incomplete and unreliable data, while with 5th Generation systems, algorithms are devised by first constructing qualitative models suited to the task</context>
</contexts>
<marker>Marr, 1976</marker>
<rawString>Marr, D. 1976. Early Processing of Visual Information. Proc. Roy. Soc., 275.b</rawString>
</citation>
<citation valid="true">
<authors>
<author>W D Marslen-Wilson</author>
<author>L K Tyler</author>
</authors>
<date>1980</date>
<journal>The Temporal Structure of Spoken Language Understanding. Cognition,</journal>
<volume>8</volume>
<pages>1--71</pages>
<contexts>
<context position="7144" citStr="Marslen-Wilson &amp; Tyler, 1980" startWordPosition="1060" endWordPosition="1063"> to that of visual processing, where &amp;quot;significant&amp;quot; • features may be absent. If present, their significance may also be open to a number of interpretations. Combining evidence across different levels of description requires the specification of information flow between these levels. Within the psychological literature, there is a growing tendency away from &amp;quot;strong&amp;quot; (or &amp;quot;instructive&amp;quot;) interactions towards &amp;quot;weak&amp;quot; (or &amp;quot;selective&amp;quot;) interactions. With the latter, the only permissible flow of information involves the filtering out, by one component, of alternatives produced by other components (cf. Marslen-Wilson &amp; Tyler, 1980; Crain &amp; Steedman, 1982; Altmann &amp; Steedman, forthcoming), so in hierarchical terms no component determines what is produced by any other component beneath it. A strong interaction, on the other hand, allows one component to direct, or guide, actively a second component in the pursuit of a particular hypothesis. Within the computational literature, weak interactions are also argued for on &amp;quot;aesthetic&amp;quot; grounds such as Marr&apos;s principles of modularity and least commitment (Marr, 1982). The strongly interactive heterarchical and blackboard models implemented in HWIM and Hearsay II respectively hav</context>
</contexts>
<marker>Marslen-Wilson, Tyler, 1980</marker>
<rawString>Marslen-Wilson, W.D. &amp; Tyler, L.K. 1980. The Temporal Structure of Spoken Language Understanding. Cognition, 8, 1-71</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L McClelland</author>
<author>D E Rumelhart</author>
</authors>
<title>An Interactive Activation Model of Context Effects in Letter Perception: Part I. An Account of Basic Findings.</title>
<date>1981</date>
<journal>In Psychological Review,</journal>
<volume>88</volume>
<pages>375--407</pages>
<marker>McClelland, Rumelhart, 1981</marker>
<rawString>McClelland, J.L &amp; Rumelhart, D.E. 1981. An Interactive Activation Model of Context Effects in Letter Perception: Part I. An Account of Basic Findings. In Psychological Review, 88, 375-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Pollack</author>
<author>J M Pickett</author>
</authors>
<title>The intelligibility of excerpts from Conversation.</title>
<date>1963</date>
<journal>Language and Speech,</journal>
<volume>6</volume>
<pages>165--171</pages>
<contexts>
<context position="13025" citStr="Pollack &amp; Pickett, 1963" startWordPosition="1938" endWordPosition="1941">ce. Most current psychological theories appear to assume strict &amp;quot;left-to-right&amp;quot; processing, although this requires tackling stretches of sound immediatedly which are of poor acoustic quality, and which are relatively unconstrained by higher level knowledge. The majority of systems developed during the ARPA project found it necessary to use later occurring information to disambiguate earlier parts of an utterance. Moreover, there is psycholinguistic evidence that the &amp;quot;intelligibility&amp;quot; of a particular stretch of sound increases with additional evidence from later &amp;quot;rightward&amp;quot; stretches of sound (Pollack &amp; Pickett, 1963; Warren &amp; Warren, 1970). We propose to adopt a system using a form of left-to-right analysis which could approximate to the power of middle-out analysis (used in HWIM and Hearsay II) but without requiring the construction of distinct &amp;quot;islands&amp;quot; and with less computational expense. This more precise method of using &amp;quot;rightcontext effects&amp;quot; depends on the priority scores assigned to paths. Such scores can be thought of, for present purposes, as some measure of &amp;quot;goodness of fit&amp;quot;. The score on a spanning pathway (that is, a pathway which spans other pathways &amp;quot;beneath&amp;quot; it) is determined by the scores</context>
</contexts>
<marker>Pollack, Pickett, 1963</marker>
<rawString>Pollack, I. &amp; Pickett, J.M. 1963. The intelligibility of excerpts from Conversation. Language and Speech, 6, 165-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Reddy</author>
<author>L D Ermann</author>
</authors>
<title>Tutorial on System Organisation for Speech Understanding. In D.R. Reddy (ed) Speech Recognition,</title>
<date>1975</date>
<publisher>Academic Press.</publisher>
<marker>Reddy, Ermann, 1975</marker>
<rawString>Reddy, D.R. &amp; Ermann, L.D. 1975. Tutorial on System Organisation for Speech Understanding. In D.R. Reddy (ed) Speech Recognition, Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Rumelhart</author>
<author>J L McClelland</author>
</authors>
<title>An Interactive Activation Model of Context Effects in Letter Perception: Part II. The Contextual Enhancement Effect. Some Tests and Extensions of the Model.</title>
<date>1982</date>
<journal>In Psychological Review,</journal>
<volume>89</volume>
<pages>60--94</pages>
<marker>Rumelhart, McClelland, 1982</marker>
<rawString>Rumelhart, D.E. &amp; McClelland, J.L. 1982. An Interactive Activation Model of Context Effects in Letter Perception: Part II. The Contextual Enhancement Effect. Some Tests and Extensions of the Model. In Psychological Review, 89, 60-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H S Thompson</author>
<author>G D Ritchie</author>
</authors>
<title>Techniques for Parsing Natural Language: Two Examples.</title>
<date>1984</date>
<editor>In M. Eisenstadt &amp; T. O&apos;Shea (eds.) Artificial Intelligence Skills. Harper &amp; Row.</editor>
<contexts>
<context position="5263" citStr="Thompson &amp; Ritchie, 1984" startWordPosition="790" endWordPosition="793">tly of component knowledge bases and methods of deploying them computationally. It should also permit the evaluation and testing of solutions with partially specified or simulated components. This will ensure that the design of one component will not influence unduly the design of any other component, possibly to the detriment of both. In addition, we should have the ability to determine the consequences of component design decisions by testing their contributions to the overall goals of speech recognition. In order to fulfill these requirements we propose to use the active chart parser (e.g. Thompson &amp; Ritchie, 1984). This was specifically designed as a flexible framework for the implementation (both serial and parallel) of different rule systems, and the evaluation of strategies for using these rule systems. It is described below in more detail. The Computational Model The problem in designing optimal control or search strategies lies in combining evidence across different levels of description (e.g. acoustic-phonetic, morpho-phonemic, syntactic, etc.), and across time during the extension of a hypothesis, such that promising interpretations are given priority and the right one wins. In this section we s</context>
</contexts>
<marker>Thompson, Ritchie, 1984</marker>
<rawString>Thompson, H.S. &amp; Ritchie, G.D. 1984. Techniques for Parsing Natural Language: Two Examples. In M. Eisenstadt &amp; T. O&apos;Shea (eds.) Artificial Intelligence Skills. Harper &amp; Row.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Warren</author>
<author>R P Warren</author>
</authors>
<title>Auditory Confusions and Illusions.</title>
<date>1970</date>
<journal>Scientific American,</journal>
<volume>223</volume>
<pages>30--36</pages>
<contexts>
<context position="13049" citStr="Warren &amp; Warren, 1970" startWordPosition="1942" endWordPosition="1945">gical theories appear to assume strict &amp;quot;left-to-right&amp;quot; processing, although this requires tackling stretches of sound immediatedly which are of poor acoustic quality, and which are relatively unconstrained by higher level knowledge. The majority of systems developed during the ARPA project found it necessary to use later occurring information to disambiguate earlier parts of an utterance. Moreover, there is psycholinguistic evidence that the &amp;quot;intelligibility&amp;quot; of a particular stretch of sound increases with additional evidence from later &amp;quot;rightward&amp;quot; stretches of sound (Pollack &amp; Pickett, 1963; Warren &amp; Warren, 1970). We propose to adopt a system using a form of left-to-right analysis which could approximate to the power of middle-out analysis (used in HWIM and Hearsay II) but without requiring the construction of distinct &amp;quot;islands&amp;quot; and with less computational expense. This more precise method of using &amp;quot;rightcontext effects&amp;quot; depends on the priority scores assigned to paths. Such scores can be thought of, for present purposes, as some measure of &amp;quot;goodness of fit&amp;quot;. The score on a spanning pathway (that is, a pathway which spans other pathways &amp;quot;beneath&amp;quot; it) is determined by the scores on its constituents, an</context>
</contexts>
<marker>Warren, Warren, 1970</marker>
<rawString>Warren, R.M. &amp; Warren, R.P. 1970. Auditory Confusions and Illusions. Scientific American, 223, 30-36.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>