<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000416">
<title confidence="0.98948">
Improving Word Alignment with Language Model Based Confidence Scores
</title>
<author confidence="0.998955">
Nguyen Bach, Qin Gao, Stephan Vogel
</author>
<affiliation confidence="0.929755">
InterACT, Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.994897">
{nbach, qing, vogel+}@cs.cmu.edu
</email>
<sectionHeader confidence="0.99561" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999297636363636">
This paper describes the statistical machine trans-
lation systems submitted to the ACL-WMT 2008
shared translation task. Systems were submitted for
two translation directions: English--+Spanish and
Spanish--+English. Using sentence pair confidence
scores estimated with source and target language
models, improvements are observed on the News-
Commentary test sets. Genre-dependent sentence
pair confidence score and integration of sentence
pair confidence score into phrase table are also in-
vestigated.
</bodyText>
<sectionHeader confidence="0.998789" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9995880625">
Word alignment models are a crucial component in sta-
tistical machine translation systems. When estimating
the parameters of the word alignment models, the sen-
tence pair probability is an important factor in the objec-
tive function and is approximated by the empirical prob-
ability. The empirical probability for each sentence pair
is estimated by maximum likelihood estimation over the
training data (Brown et al., 1993). Due to the limitation of
training data, most sentence pairs occur only once, which
makes the empirical probability almost uniform. This is
a rather weak approximation of the true distribution.
In this paper, we investigate the methods of weighting
sentence pairs using language models, and extended the
general weighting method to genre-dependent weight. A
method of integrating the weight directly into the phrase
table is also explored.
</bodyText>
<sectionHeader confidence="0.960369" genericHeader="method">
2 The Baseline Phrase-Based MT System
</sectionHeader>
<bodyText confidence="0.995886">
The ACL-WMT08 organizers provided Europarl and
News-Commentary parallel corpora for English H Span-
ish. Detailed corpus statistics is given in Table 1. Follow-
ing the guidelines of the workshop we built baseline sys-
tems, using the lower-cased Europarl parallel corpus (re-
stricting sentence length to 40 words), GIZA++ (Och and
Ney, 2003), Moses (Koehn et al., 2007), and the SRI LM
toolkit (Stolcke, 2002) to build 5-gram LMs. Since no
News development sets were available we chose News-
Commentary sets as replacements. We used test-2006
(E06) and nc-devtest2007 (NCd) as development sets for
Europarl and News-Commentary; test-2007 (E07) and
nc-test2007 (NCt) as held-out evaluation sets.
</bodyText>
<table confidence="0.971758076923077">
English Spanish
Europarl (E)
sentence pairs 1,258,778
unique sent. pairs 1,235,134
avg. sentence length 27.9 29.0
# words 35.14 M 36.54 M
vocabulary 108.7 K 164.8 K
News-Commentary (NC)
sentence pairs 64,308
unique sent. pairs 64,205
avg. sentence length 24.0 27.4
# words 1.54 M 1.76 M
vocabulary 44.2 K 56.9 K
</table>
<tableCaption confidence="0.9242685">
Table 1: Statistics of English+--*Spanish Europarl and News-
Commentary corpora
</tableCaption>
<bodyText confidence="0.999307428571429">
To improve the baseline performance we trained sys-
tems on all true-cased training data with sentence length
up to 100. We used two language models, a 5-gram LM
build from the Europarl corpus and a 3-gram LM build
from the News-Commentary data. Instead of interpolat-
ing the two language models, we explicitly used them in
the decoder and optimized their weights via minimum-
error-rate (MER) training (Och, 2003). To shorten the
training time, a multi-threaded GIZA++ version was used
to utilize multi-processor servers (Gao and Vogel, 2008).
Other parameters were the same as the baseline sys-
tem. Table 2 shows results in lowercase BLEU (Pap-
ineni et al., 2002) for both the baseline (B) and the im-
proved baseline systems (B5) on development and held-
</bodyText>
<page confidence="0.984459">
151
</page>
<note confidence="0.398115">
Proceedings of the Third Workshop on Statistical Machine Translation, pages 151–154,
</note>
<page confidence="0.471707">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.9892046">
out evaluation sets. We observed significant gains for the
News-Commentary test sets. Our improved baseline sys-
tems obtained a comparable performance with the best
EnglishHSpanish systems in 2007 (Callison-Burch et al.,
2007).
</bodyText>
<table confidence="0.998187833333333">
Pairs Europarl NC
E06 E07 NCd NCt
En→Es B 33.00 32.21 31.84 30.56
B5 33.33 32.25 35.10 34.08
Es→En B 33.08 33.23 31.18 31.34
B5 33.26 33.23 36.06 35.56
</table>
<tableCaption confidence="0.993099">
Table 2: NIST-BLEU scores of baseline and improved baseline
systems experiments on English+-*Spanish
</tableCaption>
<sectionHeader confidence="0.89032" genericHeader="method">
3 Weighting Sentence Pairs
</sectionHeader>
<subsectionHeader confidence="0.995379">
3.1 Problem Definition
</subsectionHeader>
<bodyText confidence="0.999825684210526">
The quality of word alignment is crucial for the perfor-
mance of the machine translation system.
In the well-known so-called IBM word alignment
models (Brown et al., 1993), re-estimating the model pa-
P(ek, fk)
for each sentence pair (ek, fk). During the EM train-
ing, all counts of events, e.g. word pair counts, distortion
model counts, etc., are weighted by P�(ek, fk). For ex-
ample, in IBM Model 1 the lexicon probability of source
word f given target word a is calculated as (Och and Ney,
2003):
To get a more informative P�(ek, fk), we explored
methods of weighting sentence pairs. We investigated
three sets of features: sentence pair confidence (sc),
genre-dependent sentence pair confidence (gdsc) and
phrase alignment confidence (pc) scores. These features
were calculated over an entire training corpus and could
be easily integrated into the phrase-based machine trans-
lation system.
</bodyText>
<subsectionHeader confidence="0.999813">
3.2 Sentence Pair Confidence
</subsectionHeader>
<bodyText confidence="0.999880842105263">
We can hardly compute the joint probability of P(ek, fk)
without knowing the conditional probability P(ek|fk)
which is estimated during the alignment process. There-
fore, to estimate P(ek, fk) before alignment, we make an
assumption that P�(ek, fk) = P(ek)P(fk), which means
the two sides of sentence pair are independent of each
other. P(ek) and P(fk) can be obtained by using lan-
guage models. P(ek) or P(fk), however, can be small
when the sentence is long. Consequently, long sentence
pairs will be assigned low scores and have negligible ef-
fect on the training process. Given limited training data,
ignoring these long sentences may hurt the alignment re-
sult. To compensate this, we normalize the probability by
the sentence length. We propose the following method
to weighting sentence pairs in the corpora. We trained
language models for source and target language, and the
average log likelihood (AVG-LL) of each sentence pair
was calculated by applying the corresponding language
model. For each sentence pair (ek, fk), the AVG-LL
</bodyText>
<equation confidence="0.963053666666667">
G(ek, fk) is
rameters depends on the empirical probability
Pk c(f|e; ek, fk) G(ek) 1
p(f|e) _ (1)  |Pe� ∈ek log P(ek |h)
Pk,f c(f|e; ek, fk)
Xc(f|e; ek, fk) _ P�(ek, fk) X P(a|ek, fk) · (2)
ek,fk a
X S(f, fjk )S(e, ekar )
j
</equation>
<bodyText confidence="0.9995306875">
Therefore, the distribution of P�(ek, fk) will affect the
alignment results. In Eqn. 2, P(ek, fk) determines
how much the alignments of sentence pair (ek, fk) con-
tribute to the model parameters. It will be helpful if
the P�(ek, fk) can approximate the true distribution of
P(ek, fk).
Consider that we are drawing sentence pairs from a
given data source, and each unique sentence pair (ek, fk)
has a probability P(ek, fk) to be observed. If the training
corpora size is infinite, the normalized frequency of each
unique sentence pair will converge to P(ek, fk). In that
case, equally assigning a number to each occurrence of
(ek, fk) and normalizing it will be valid. However, the
assumption is invalid if the data source is finite. As we
can observe in the training corpora, most sentences occur
only one time, and thus P�(ek, fk) will be uniform.
</bodyText>
<equation confidence="0.994144">
G(fk) |fk |Pfkr ∈fk log P(fj  |h) (3)
G(ek, fk) = [G(ek) + G(fk)l/2
</equation>
<bodyText confidence="0.9988995">
where P(ek� |h) and P(fk� |h) are ngram probabilities.
The sentence pair confidence score is then given by:
</bodyText>
<equation confidence="0.955920666666667">
sc(ek, fk)
= exp(G(ek, fk)).
(4)
</equation>
<subsectionHeader confidence="0.997441">
3.3 Genre-Dependent Sentence Pair Confidence
</subsectionHeader>
<bodyText confidence="0.999932">
Genre adaptation is one of the major challenges in statis-
tical machine translation since translation models suffer
from data sparseness (Koehn and Schroeder, 2007). To
overcome these problems previous works have focused
on explicitly modeling topics and on using multiple lan-
guage and translation models. Using a mixture of topic-
dependent Viterbi alignments was proposed in (Civera
and Juan, 2007). Language and translation model adap-
tation to Europarl and News-Commentary have been ex-
plored in (Paulik et al., 2007).
Given the sentence pair weighting method, it is pos-
sible to adopt genre-specific language models into the
</bodyText>
<page confidence="0.967942">
152
</page>
<figure confidence="0.932725678571429">
nce in Weight (NC-EP)
nce in Weight (NC-NE)
nce in Weight (NE-EP)
0.01
0
0.015
Proportion in Corpora
0.005
Data
Commentary
-0.06
0.02 0.04 0.06
-0.04-0.020
0.015
0.01
Proportion in Corpora
0.005
0
0.02 0.04 0.06
-0.04-0.020
0.02
0.015
0.01
Proportion in Corpora
0.005
0
0.02 0.04 0.06
-0.04-0.020
</figure>
<bodyText confidence="0.9833175">
weighting process. The genre-dependent sentence pair
confidence gdsc simulates weighting the training sen-
tences again from different data sources, thus, given
genre g, it can be formulated as:
</bodyText>
<equation confidence="0.999123">
gdsc(ek,fk) = sc(ek,fk1g) (5)
</equation>
<bodyText confidence="0.999871666666667">
where P(eki |h) and P(fkj jh) are estimated by genre-
specific language models.
The score generally represents the likelihood of the
sentence pair to be in a specific genre. Thus, if both sides
of the sentence pair show a high probability according
to the genre-specific language models, alignments in the
pair should be more possible to occur in that particular
domain, and put more weight may contribute to a better
alignment for that genre.
</bodyText>
<subsectionHeader confidence="0.947852">
3.4 Phrase Alignment Confidence
</subsectionHeader>
<bodyText confidence="0.999162875">
So far the confidence scores are used only in the train-
ing of the word alignment models. Tracking from which
sentence pairs each phrase pair was extracted, we can use
the sentence level confidence scores to assign confidence
scores to the phrase pairs. Let S(e, f) denote the set of
sentences pairs from which the phrase pair (e, �f) was ex-
tracted. We calculate then a phrase alignment confidence
score pc as:
</bodyText>
<figure confidence="0.854636454545455">
d EP training corpora
ek fk)ES(
f) log
(e
˜e,˜
k, fk )
f) = exp (
(6)
|S(�e, �f)|
gnment models.
pc(e,
</figure>
<figureCaption confidence="0.580642666666667">
This score is used as an
additional feature of the phrase
pair. The feature weight is estimated in MER training.
</figureCaption>
<table confidence="0.586779444444444">
Uniform NC+EP NC EP
train En→Es 46.76 42.36 42.97 44.47
Es→En 70.18 62.81 62.95 65.86
test NC(En→Es) 53.04 53.44 51.09 55.94
EP(En→Es) 91.13 90.89 91.84 90.77
NC(Es→En) 81.39 81.28 78.23 80.33
EP(Es→En) 126.56 125.96 123.23 122.11
s.
corpus (Figure
</table>
<bodyText confidence="0.833254666666667">
The opposite is true for the EP LM.
When comparing the scores calculated from the NC LM
and the combined NC+EP LM we still see a clear sep-
aration (Figure
No marked difference can be seen
between using the EP LM and the NC+EP LM (Figure
which again is expected, as the NC corpus is very
small compared to the EP corpus.
The next step was to retrain the word alignment mod-
els using sentences weights according to the vari
1a).
1b).
1c),
ous con-
sc
</bodyText>
<sectionHeader confidence="0.994092" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999882909090909">
The first step in validating the proposed approach was
to check if the different language models do assign dif-
ferent weights to the sentence pairs in the training cor-
pora. Using the different language models NC (News-
Commentary), EP (Europarl), NC+EP (both NC and EP)
the genre-specific sentence pair confidence scores were
calculated. Figure 1 shows the distributions of the dif-
ferences in these scores across the two corpora. As ex-
pected, the language model build from the NC corpus as-
signs - on average -higher weights to sentence pairs in the
NC corpus and lower weights to sentence pairs in the EP
</bodyText>
<figure confidence="0.994928736842105">
0.02
Europal
News
Data
(a) Differe
Europal
Data
News
Commentary
Data
-0.06
(b) Differe
Europal
Data
News
Commentary
Data
-0.06
(c) Differe
</figure>
<figureCaption confidence="0.9947715">
Figure 1: Histogram of weight differences genre specific con-
fidence scores on NC an
</figureCaption>
<bodyText confidence="0.999720875">
fidence scores. Table 3 shows training and test set per-
plexities for IBM model 4 for both training directions.
Not only do we see a drop in training set perplexities,
but also in test set perplexities. Using the genre specific
confidence scores leads to lower perplexities on the cor-
responding test set, which means that using the proposed
method does lead to small, but consistent adjustments in
the ali
</bodyText>
<tableCaption confidence="0.9602">
Table 3: IBM model 4 training and test set perplexities using
genre specific sentence pair confidence score
</tableCaption>
<bodyText confidence="0.9967447">
In the final step the specific alignment models were
used to generate various phrase tables, which were then
used in translation experiments. Results are shown in Ta-
ble 4. We report lower-cased Bleu scores. We used nc-
dev2007
as an additional held-out evaluation set.
Bold cells indicate highest scores.
As we can see from the results, improvements are ob-
tained by using sentence pair confidence scores. Us-
ing confidence scores calculated from the EP LM gave
overall the best performance. While we observe only a
small improvement on Europarl sets, improvements on
News-Commentary sets are more pronounced, especially
on held-out evaluation sets NCt and
The exper-
iments do not give evidence that genre-dependent con-
fidence can
(NCt1)
NCt1.
improve over using the general confidence
</bodyText>
<page confidence="0.996268">
153
</page>
<table confidence="0.99980825">
Test Set
E06 E07 NCd NCt NCt1
Es→En
B5 33.26 33.23 36.06 35.56 35.64
NC+EP 33.23 32.29 36.12 35.47 35.97
NC 33.43 33.39 36.14 35.27 35.68
EP 33.36 33.39 36.16 35.63 36.17
En→Es
B5 33.33 32.25 35.10 34.08 34.43
NC+EP 33.23 32.29 35.12 34.56 34.89
NC 33.30 32.27 34.91 34.07 34.29
EP 33.08 32.29 35.05 34.52 35.03
</table>
<tableCaption confidence="0.995359">
Table 4: Translation results (NIST-BLEU) using gdsc with dif-
ferent genre-specific language models for Es+-*En systems
</tableCaption>
<bodyText confidence="0.930336666666667">
score. As the News-Commentary language model was
trained on a very small amount of data further work is
required to study this in more detail.
</bodyText>
<table confidence="0.999648666666667">
Test Set
E06 E07 NCd NCt NCt1
Es→En
B5 33.26 33.23 36.06 35.56 35.64
NC+EP+pc 33.54 33.39 36.07 35.38 35.85
NC+pc 33.17 33.31 35.96 35.74 36.04
EP+pc 33.44 32.87 36.22 35.63 36.09
En→Es
B5 33.33 32.25 35.10 34.08 34.43
NC+EP+pc 33.28 32.45 34.82 33.68 33.86
NC+pc 33.13 32.47 34.01 34.34 34.98
EP+pc 32.97 32.20 34.26 33.99 34.34
</table>
<tableCaption confidence="0.9959025">
Table 5: Translation results (NIST-BLEU) using pc with differ-
ent genre-specific language models for Es+-*En systems
</tableCaption>
<bodyText confidence="0.993811166666667">
Table 5 shows experiments results in NIST-BLEU us-
ing pc score as an additional feature on phrase tables
in EsHEn systems. We observed that across develop-
ment and held-out sets the gains from pc are inconsistent,
therefore our submissions are selected from the B5+EP
system.
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9998107">
In the ACL-WMT 2008, our major innovations are meth-
ods to estimate sentence pair confidence via language
models. We proposed to use source and target language
models to weight the sentence pairs. We developed sen-
tence pair confidence (sc), genre-dependent sentence pair
confidence (gdsc) and phrase alignment confidence (pc)
scores. Our experimental results shown that we had a bet-
ter word alignment and translation performance by using
gdsc. We did not observe consistent improvements by
using phrase pair confidence scores in our systems.
</bodyText>
<sectionHeader confidence="0.997747" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9810415">
This work is in part supported by the US DARPA under the
GALE program. Any opinions, findings, and conclusions or
recommendations expressed in this material are those of the au-
thors and do not necessarily reflect the views of DARPA.
</bodyText>
<sectionHeader confidence="0.998833" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999797795918367">
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra,
and Robert L. Mercer. 1993. The mathematics of statisti-
cal machine translation: Parameter estimation. In Computa-
tional Linguistics, volume 19(2), pages 263–331.
Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,
Christof Monz, and Josh Schroeder. 2007. (Meta-) evalua-
tion of machine translation. In Proc. of the ACL 2007 Second
Workshop on Statistical Machine Translation, Prague, Czech
Republic.
Jorge Civera and Alfons Juan. 2007. Domain adaptation in sta-
tistical translation with mixture modelling. In Proc. of the
ACL 2007 Second Workshop on Statistical Machine Transla-
tion, Prague, Czech Republic.
Qin Gao and Stephan Vogel. 2008. Parallel implementations
of word alignment tool. In Proc. of the ACL 2008 Soft-
ware Engineering, Testing, and Quality Assurance Work-
shop, Columbus, Ohio, USA.
Philipp Koehn and Josh Schroeder. 2007. Experiments in do-
main adaptation for statistical machine translation. In Proc.
of the ACL 2007 Second Workshop on Statistical Machine
Translation, Prague, Czech Republic.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-
Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan,
Wade Shen, Christine Moran, Richard Zens, Chris Dyer, On-
drej Bojar, Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine transla-
tion. In Proc. of the 45th Annual Meeting of the Association
for Computational Linguistics, demo sessions, pages 177–
180, Prague, Czech Republic, June.
Franz J. Och and Hermann Ney. 2003. A systematic compar-
ison of various statistical alignment models. In Computa-
tional Linguistics, volume 1:29, pages 19–51.
Franz Josef Och. 2003. Minimum error rate training in statis-
tical machine translation. In Erhard Hinrichs and Dan Roth,
editors, Proceedings of the 41st Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. 2002. Bleu: a method for automatic evaluation of ma-
chine translation. In Proc. of the 40th Annual Conf. of the
Association for Computational Linguistics (ACL 02), pages
311–318, Philadelphia, PA, July.
Matthias Paulik, Kay Rottmann, Jan Niehues, Silja Hildebrand,
and Stephan Vogel. 2007. The ISL phrase-based mt system
for the 2007 ACL workshop on statistical machine transla-
tion. In In Proc. of the ACL 2007 Second Workshop on Sta-
tistical Machine Translation, Prague, Czech Republic.
Andreas Stolcke. 2002. SRILM – An extensible language mod-
eling toolkit. In Proc. Intl. Conf. on Spoken Language Pro-
cessing, volume 2, pages 901–904, Denver.
</reference>
<page confidence="0.999769">
154
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.539354">
<title confidence="0.999907">Improving Word Alignment with Language Model Based Confidence Scores</title>
<author confidence="0.995654">Nguyen Bach</author>
<author confidence="0.995654">Qin Gao</author>
<author confidence="0.995654">Stephan</author>
<affiliation confidence="0.982934">InterACT, Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.984992">Pittsburgh, PA 15213,</address>
<email confidence="0.737472">qing,</email>
<abstract confidence="0.980266583333333">This paper describes the statistical machine translation systems submitted to the ACL-WMT 2008 shared translation task. Systems were submitted for translation directions: and Using sentence pair confidence scores estimated with source and target language models, improvements are observed on the News- Commentary test sets. Genre-dependent sentence pair confidence score and integration of sentence pair confidence score into phrase table are also investigated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>19</volume>
<issue>2</issue>
<pages>263--331</pages>
<contexts>
<context position="1176" citStr="Brown et al., 1993" startWordPosition="160" endWordPosition="163">s are observed on the NewsCommentary test sets. Genre-dependent sentence pair confidence score and integration of sentence pair confidence score into phrase table are also investigated. 1 Introduction Word alignment models are a crucial component in statistical machine translation systems. When estimating the parameters of the word alignment models, the sentence pair probability is an important factor in the objective function and is approximated by the empirical probability. The empirical probability for each sentence pair is estimated by maximum likelihood estimation over the training data (Brown et al., 1993). Due to the limitation of training data, most sentence pairs occur only once, which makes the empirical probability almost uniform. This is a rather weak approximation of the true distribution. In this paper, we investigate the methods of weighting sentence pairs using language models, and extended the general weighting method to genre-dependent weight. A method of integrating the weight directly into the phrase table is also explored. 2 The Baseline Phrase-Based MT System The ACL-WMT08 organizers provided Europarl and News-Commentary parallel corpora for English H Spanish. Detailed corpus st</context>
<context position="4349" citStr="Brown et al., 1993" startWordPosition="656" endWordPosition="659">ets. Our improved baseline systems obtained a comparable performance with the best EnglishHSpanish systems in 2007 (Callison-Burch et al., 2007). Pairs Europarl NC E06 E07 NCd NCt En→Es B 33.00 32.21 31.84 30.56 B5 33.33 32.25 35.10 34.08 Es→En B 33.08 33.23 31.18 31.34 B5 33.26 33.23 36.06 35.56 Table 2: NIST-BLEU scores of baseline and improved baseline systems experiments on English+-*Spanish 3 Weighting Sentence Pairs 3.1 Problem Definition The quality of word alignment is crucial for the performance of the machine translation system. In the well-known so-called IBM word alignment models (Brown et al., 1993), re-estimating the model paP(ek, fk) for each sentence pair (ek, fk). During the EM training, all counts of events, e.g. word pair counts, distortion model counts, etc., are weighted by P�(ek, fk). For example, in IBM Model 1 the lexicon probability of source word f given target word a is calculated as (Och and Ney, 2003): To get a more informative P�(ek, fk), we explored methods of weighting sentence pairs. We investigated three sets of features: sentence pair confidence (sc), genre-dependent sentence pair confidence (gdsc) and phrase alignment confidence (pc) scores. These features were cal</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. In Computational Linguistics, volume 19(2), pages 263–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>(Meta-) evaluation of machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3874" citStr="Callison-Burch et al., 2007" startWordPosition="579" endWordPosition="582">rs (Gao and Vogel, 2008). Other parameters were the same as the baseline system. Table 2 shows results in lowercase BLEU (Papineni et al., 2002) for both the baseline (B) and the improved baseline systems (B5) on development and held151 Proceedings of the Third Workshop on Statistical Machine Translation, pages 151–154, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics out evaluation sets. We observed significant gains for the News-Commentary test sets. Our improved baseline systems obtained a comparable performance with the best EnglishHSpanish systems in 2007 (Callison-Burch et al., 2007). Pairs Europarl NC E06 E07 NCd NCt En→Es B 33.00 32.21 31.84 30.56 B5 33.33 32.25 35.10 34.08 Es→En B 33.08 33.23 31.18 31.34 B5 33.26 33.23 36.06 35.56 Table 2: NIST-BLEU scores of baseline and improved baseline systems experiments on English+-*Spanish 3 Weighting Sentence Pairs 3.1 Problem Definition The quality of word alignment is crucial for the performance of the machine translation system. In the well-known so-called IBM word alignment models (Brown et al., 1993), re-estimating the model paP(ek, fk) for each sentence pair (ek, fk). During the EM training, all counts of events, e.g. wor</context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2007</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2007. (Meta-) evaluation of machine translation. In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Civera</author>
<author>Alfons Juan</author>
</authors>
<title>Domain adaptation in statistical translation with mixture modelling.</title>
<date>2007</date>
<booktitle>In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="7857" citStr="Civera and Juan, 2007" startWordPosition="1237" endWordPosition="1240"> |h) (3) G(ek, fk) = [G(ek) + G(fk)l/2 where P(ek� |h) and P(fk� |h) are ngram probabilities. The sentence pair confidence score is then given by: sc(ek, fk) = exp(G(ek, fk)). (4) 3.3 Genre-Dependent Sentence Pair Confidence Genre adaptation is one of the major challenges in statistical machine translation since translation models suffer from data sparseness (Koehn and Schroeder, 2007). To overcome these problems previous works have focused on explicitly modeling topics and on using multiple language and translation models. Using a mixture of topicdependent Viterbi alignments was proposed in (Civera and Juan, 2007). Language and translation model adaptation to Europarl and News-Commentary have been explored in (Paulik et al., 2007). Given the sentence pair weighting method, it is possible to adopt genre-specific language models into the 152 nce in Weight (NC-EP) nce in Weight (NC-NE) nce in Weight (NE-EP) 0.01 0 0.015 Proportion in Corpora 0.005 Data Commentary -0.06 0.02 0.04 0.06 -0.04-0.020 0.015 0.01 Proportion in Corpora 0.005 0 0.02 0.04 0.06 -0.04-0.020 0.02 0.015 0.01 Proportion in Corpora 0.005 0 0.02 0.04 0.06 -0.04-0.020 weighting process. The genre-dependent sentence pair confidence gdsc sim</context>
</contexts>
<marker>Civera, Juan, 2007</marker>
<rawString>Jorge Civera and Alfons Juan. 2007. Domain adaptation in statistical translation with mixture modelling. In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Proc. of the ACL 2008 Software Engineering, Testing, and Quality Assurance Workshop,</booktitle>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="3270" citStr="Gao and Vogel, 2008" startWordPosition="487" endWordPosition="490">9 K Table 1: Statistics of English+--*Spanish Europarl and NewsCommentary corpora To improve the baseline performance we trained systems on all true-cased training data with sentence length up to 100. We used two language models, a 5-gram LM build from the Europarl corpus and a 3-gram LM build from the News-Commentary data. Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimumerror-rate (MER) training (Och, 2003). To shorten the training time, a multi-threaded GIZA++ version was used to utilize multi-processor servers (Gao and Vogel, 2008). Other parameters were the same as the baseline system. Table 2 shows results in lowercase BLEU (Papineni et al., 2002) for both the baseline (B) and the improved baseline systems (B5) on development and held151 Proceedings of the Third Workshop on Statistical Machine Translation, pages 151–154, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics out evaluation sets. We observed significant gains for the News-Commentary test sets. Our improved baseline systems obtained a comparable performance with the best EnglishHSpanish systems in 2007 (Callison-Burch et al., 2</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Proc. of the ACL 2008 Software Engineering, Testing, and Quality Assurance Workshop, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="7623" citStr="Koehn and Schroeder, 2007" startWordPosition="1201" endWordPosition="1204">ormalizing it will be valid. However, the assumption is invalid if the data source is finite. As we can observe in the training corpora, most sentences occur only one time, and thus P�(ek, fk) will be uniform. G(fk) |fk |Pfkr ∈fk log P(fj |h) (3) G(ek, fk) = [G(ek) + G(fk)l/2 where P(ek� |h) and P(fk� |h) are ngram probabilities. The sentence pair confidence score is then given by: sc(ek, fk) = exp(G(ek, fk)). (4) 3.3 Genre-Dependent Sentence Pair Confidence Genre adaptation is one of the major challenges in statistical machine translation since translation models suffer from data sparseness (Koehn and Schroeder, 2007). To overcome these problems previous works have focused on explicitly modeling topics and on using multiple language and translation models. Using a mixture of topicdependent Viterbi alignments was proposed in (Civera and Juan, 2007). Language and translation model adaptation to Europarl and News-Commentary have been explored in (Paulik et al., 2007). Given the sentence pair weighting method, it is possible to adopt genre-specific language models into the 152 nce in Weight (NC-EP) nce in Weight (NC-NE) nce in Weight (NE-EP) 0.01 0 0.015 Proportion in Corpora 0.005 Data Commentary -0.06 0.02 0</context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris CallisonBurch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of the 45th Annual Meeting of the Association for Computational Linguistics, demo sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2018" citStr="Koehn et al., 2007" startWordPosition="290" endWordPosition="293">e the methods of weighting sentence pairs using language models, and extended the general weighting method to genre-dependent weight. A method of integrating the weight directly into the phrase table is also explored. 2 The Baseline Phrase-Based MT System The ACL-WMT08 organizers provided Europarl and News-Commentary parallel corpora for English H Spanish. Detailed corpus statistics is given in Table 1. Following the guidelines of the workshop we built baseline systems, using the lower-cased Europarl parallel corpus (restricting sentence length to 40 words), GIZA++ (Och and Ney, 2003), Moses (Koehn et al., 2007), and the SRI LM toolkit (Stolcke, 2002) to build 5-gram LMs. Since no News development sets were available we chose NewsCommentary sets as replacements. We used test-2006 (E06) and nc-devtest2007 (NCd) as development sets for Europarl and News-Commentary; test-2007 (E07) and nc-test2007 (NCt) as held-out evaluation sets. English Spanish Europarl (E) sentence pairs 1,258,778 unique sent. pairs 1,235,134 avg. sentence length 27.9 29.0 # words 35.14 M 36.54 M vocabulary 108.7 K 164.8 K News-Commentary (NC) sentence pairs 64,308 unique sent. pairs 64,205 avg. sentence length 24.0 27.4 # words 1.5</context>
</contexts>
<marker>Koehn, Hoang, Birch, CallisonBurch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris CallisonBurch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. of the 45th Annual Meeting of the Association for Computational Linguistics, demo sessions, pages 177– 180, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<contexts>
<context position="1990" citStr="Och and Ney, 2003" startWordPosition="285" endWordPosition="288">n this paper, we investigate the methods of weighting sentence pairs using language models, and extended the general weighting method to genre-dependent weight. A method of integrating the weight directly into the phrase table is also explored. 2 The Baseline Phrase-Based MT System The ACL-WMT08 organizers provided Europarl and News-Commentary parallel corpora for English H Spanish. Detailed corpus statistics is given in Table 1. Following the guidelines of the workshop we built baseline systems, using the lower-cased Europarl parallel corpus (restricting sentence length to 40 words), GIZA++ (Och and Ney, 2003), Moses (Koehn et al., 2007), and the SRI LM toolkit (Stolcke, 2002) to build 5-gram LMs. Since no News development sets were available we chose NewsCommentary sets as replacements. We used test-2006 (E06) and nc-devtest2007 (NCd) as development sets for Europarl and News-Commentary; test-2007 (E07) and nc-test2007 (NCt) as held-out evaluation sets. English Spanish Europarl (E) sentence pairs 1,258,778 unique sent. pairs 1,235,134 avg. sentence length 27.9 29.0 # words 35.14 M 36.54 M vocabulary 108.7 K 164.8 K News-Commentary (NC) sentence pairs 64,308 unique sent. pairs 64,205 avg. sentence </context>
<context position="4673" citStr="Och and Ney, 2003" startWordPosition="715" endWordPosition="718">f baseline and improved baseline systems experiments on English+-*Spanish 3 Weighting Sentence Pairs 3.1 Problem Definition The quality of word alignment is crucial for the performance of the machine translation system. In the well-known so-called IBM word alignment models (Brown et al., 1993), re-estimating the model paP(ek, fk) for each sentence pair (ek, fk). During the EM training, all counts of events, e.g. word pair counts, distortion model counts, etc., are weighted by P�(ek, fk). For example, in IBM Model 1 the lexicon probability of source word f given target word a is calculated as (Och and Ney, 2003): To get a more informative P�(ek, fk), we explored methods of weighting sentence pairs. We investigated three sets of features: sentence pair confidence (sc), genre-dependent sentence pair confidence (gdsc) and phrase alignment confidence (pc) scores. These features were calculated over an entire training corpus and could be easily integrated into the phrase-based machine translation system. 3.2 Sentence Pair Confidence We can hardly compute the joint probability of P(ek, fk) without knowing the conditional probability P(ek|fk) which is estimated during the alignment process. Therefore, to es</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. In Computational Linguistics, volume 1:29, pages 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<editor>In Erhard Hinrichs and Dan Roth, editors,</editor>
<contexts>
<context position="3141" citStr="Och, 2003" startWordPosition="470" endWordPosition="471">tence pairs 64,308 unique sent. pairs 64,205 avg. sentence length 24.0 27.4 # words 1.54 M 1.76 M vocabulary 44.2 K 56.9 K Table 1: Statistics of English+--*Spanish Europarl and NewsCommentary corpora To improve the baseline performance we trained systems on all true-cased training data with sentence length up to 100. We used two language models, a 5-gram LM build from the Europarl corpus and a 3-gram LM build from the News-Commentary data. Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimumerror-rate (MER) training (Och, 2003). To shorten the training time, a multi-threaded GIZA++ version was used to utilize multi-processor servers (Gao and Vogel, 2008). Other parameters were the same as the baseline system. Table 2 shows results in lowercase BLEU (Papineni et al., 2002) for both the baseline (B) and the improved baseline systems (B5) on development and held151 Proceedings of the Third Workshop on Statistical Machine Translation, pages 151–154, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics out evaluation sets. We observed significant gains for the News-Commentary test sets. Our im</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Erhard Hinrichs and Dan Roth, editors, Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Conf. of the Association for Computational Linguistics (ACL 02),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="3390" citStr="Papineni et al., 2002" startWordPosition="508" endWordPosition="512">we trained systems on all true-cased training data with sentence length up to 100. We used two language models, a 5-gram LM build from the Europarl corpus and a 3-gram LM build from the News-Commentary data. Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimumerror-rate (MER) training (Och, 2003). To shorten the training time, a multi-threaded GIZA++ version was used to utilize multi-processor servers (Gao and Vogel, 2008). Other parameters were the same as the baseline system. Table 2 shows results in lowercase BLEU (Papineni et al., 2002) for both the baseline (B) and the improved baseline systems (B5) on development and held151 Proceedings of the Third Workshop on Statistical Machine Translation, pages 151–154, Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics out evaluation sets. We observed significant gains for the News-Commentary test sets. Our improved baseline systems obtained a comparable performance with the best EnglishHSpanish systems in 2007 (Callison-Burch et al., 2007). Pairs Europarl NC E06 E07 NCd NCt En→Es B 33.00 32.21 31.84 30.56 B5 33.33 32.25 35.10 34.08 Es→En B 33.08 33.23 3</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proc. of the 40th Annual Conf. of the Association for Computational Linguistics (ACL 02), pages 311–318, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Paulik</author>
<author>Kay Rottmann</author>
<author>Jan Niehues</author>
<author>Silja Hildebrand</author>
<author>Stephan Vogel</author>
</authors>
<title>The ISL phrase-based mt system for the</title>
<date>2007</date>
<booktitle>In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="7976" citStr="Paulik et al., 2007" startWordPosition="1256" endWordPosition="1259">e score is then given by: sc(ek, fk) = exp(G(ek, fk)). (4) 3.3 Genre-Dependent Sentence Pair Confidence Genre adaptation is one of the major challenges in statistical machine translation since translation models suffer from data sparseness (Koehn and Schroeder, 2007). To overcome these problems previous works have focused on explicitly modeling topics and on using multiple language and translation models. Using a mixture of topicdependent Viterbi alignments was proposed in (Civera and Juan, 2007). Language and translation model adaptation to Europarl and News-Commentary have been explored in (Paulik et al., 2007). Given the sentence pair weighting method, it is possible to adopt genre-specific language models into the 152 nce in Weight (NC-EP) nce in Weight (NC-NE) nce in Weight (NE-EP) 0.01 0 0.015 Proportion in Corpora 0.005 Data Commentary -0.06 0.02 0.04 0.06 -0.04-0.020 0.015 0.01 Proportion in Corpora 0.005 0 0.02 0.04 0.06 -0.04-0.020 0.02 0.015 0.01 Proportion in Corpora 0.005 0 0.02 0.04 0.06 -0.04-0.020 weighting process. The genre-dependent sentence pair confidence gdsc simulates weighting the training sentences again from different data sources, thus, given genre g, it can be formulated as</context>
</contexts>
<marker>Paulik, Rottmann, Niehues, Hildebrand, Vogel, 2007</marker>
<rawString>Matthias Paulik, Kay Rottmann, Jan Niehues, Silja Hildebrand, and Stephan Vogel. 2007. The ISL phrase-based mt system for the 2007 ACL workshop on statistical machine translation. In In Proc. of the ACL 2007 Second Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – An extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. Intl. Conf. on Spoken Language Processing,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver.</location>
<contexts>
<context position="2058" citStr="Stolcke, 2002" startWordPosition="299" endWordPosition="300">ng language models, and extended the general weighting method to genre-dependent weight. A method of integrating the weight directly into the phrase table is also explored. 2 The Baseline Phrase-Based MT System The ACL-WMT08 organizers provided Europarl and News-Commentary parallel corpora for English H Spanish. Detailed corpus statistics is given in Table 1. Following the guidelines of the workshop we built baseline systems, using the lower-cased Europarl parallel corpus (restricting sentence length to 40 words), GIZA++ (Och and Ney, 2003), Moses (Koehn et al., 2007), and the SRI LM toolkit (Stolcke, 2002) to build 5-gram LMs. Since no News development sets were available we chose NewsCommentary sets as replacements. We used test-2006 (E06) and nc-devtest2007 (NCd) as development sets for Europarl and News-Commentary; test-2007 (E07) and nc-test2007 (NCt) as held-out evaluation sets. English Spanish Europarl (E) sentence pairs 1,258,778 unique sent. pairs 1,235,134 avg. sentence length 27.9 29.0 # words 35.14 M 36.54 M vocabulary 108.7 K 164.8 K News-Commentary (NC) sentence pairs 64,308 unique sent. pairs 64,205 avg. sentence length 24.0 27.4 # words 1.54 M 1.76 M vocabulary 44.2 K 56.9 K Tabl</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – An extensible language modeling toolkit. In Proc. Intl. Conf. on Spoken Language Processing, volume 2, pages 901–904, Denver.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>