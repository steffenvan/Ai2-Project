<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016223">
<title confidence="0.9966465">
Analysis and System Combination of Phrase- and N-gram-based
Statistical Machine Translation Systems
</title>
<author confidence="0.8121055">
Marta R. Costa-juss`a1, Josep M. Crego1, David Vilar2
Jos´e A. R. Fonollosa1, Jos´e B. Mari˜no1 and Hermann Ney2
</author>
<affiliation confidence="0.691965">
&apos;TALP Research Center (UPC), Barcelona 08034, Spain
</affiliation>
<email confidence="0.98479">
{mruiz,jmcrego,adrian,canton}@gps.tsc.upc.edu
</email>
<affiliation confidence="0.802693">
2RWTH Aachen University, Aachen D-52056, Germany
</affiliation>
<email confidence="0.996706">
{vilar,ney}@i6.informatik.rwth-aachen.de
</email>
<sectionHeader confidence="0.997355" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999545833333333">
In the framework of the Tc-STAR project,
we analyze and propose a combination of
two Statistical Machine Translation sys-
tems: a phrase-based and an N-gram-based
one. The exhaustive analysis includes a
comparison of the translation models in
terms of efficiency (number of translation
units used in the search and computational
time) and an examination of the errors in
each system’s output. Additionally, we
combine both systems, showing accuracy
improvements.
</bodyText>
<sectionHeader confidence="0.99951" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99819123255814">
Statistical machine translation (SMT) has evolved
from the initial word-based translation models to
more advanced models that take the context sur-
rounding the words into account. The so-called
phrase-based and N-gram-based models are two ex-
amples of these approaches (Zens and Ney, 2004;
Marino et al., 2006).
In current state-of-the-art SMT systems, the
phrase-based or the N-gram-based models are usu-
ally the main features in a log-linear framework, rem-
iniscent of the maximum entropy modeling approach.
Two basic issues differentiate the N-gram-based
system from the phrase-based one: the training data
is sequentially segmented into bilingual units; and
the probability of these units is estimated as a bilin-
gual N-gram language model. In the phrase-based
model, no monotonicity restriction is imposed on the
segmentation and the probabilities are normally es-
timated simply by relative frequencies.
This paper extends the analysis of both systems
performed in (Crego et al., 2005a) by additionally
performing a manual error analysis of both systems,
which were the ones used by UPC and RWTH in the
last Tc-STAR evaluation.
Furthermore, we will propose a way to combine
both systems in order to improve the quality of trans-
lations.
Experiments combining several kinds of MT sys-
tems have been presented in (Matusov et al., 2006),
based only on the single best output of each system.
Recently, a more straightforward approach of both
systems has been performed in (Costa-jussa et al.,
2006) which simply selects, for each sentence, one of
the provided hypotheses.
This paper is organized as follows. In section 2,
we briefly describe the phrase and the N-gram-based
baseline systems. In the next section we present the
evaluation framework. In Section 4 we report a struc-
tural comparison performed for both systems and, af-
terwards, in Section 5, we analyze the errors of both
systems. Finally, in the last two sections we rescore
and combine both systems, and the obtained results
are discussed.
</bodyText>
<sectionHeader confidence="0.962806" genericHeader="method">
2 Baseline Systems
</sectionHeader>
<subsectionHeader confidence="0.976179">
2.1 Phrase-based System
</subsectionHeader>
<bodyText confidence="0.999881">
The basic idea of phrase-based translation is to seg-
ment the given source sentence into units (here called
phrases), then translate each phrase and finally com-
pose the target sentence from these phrase transla-
tions.
In order to train these phrase-based models, an
alignment between the source and target training
sentences is found by using the standard IBM mod-
els in both directions (source-to-target and target-
to-source) and combining the two obtained align-
ments. Given this alignment an extraction of con-
tiguous phrases is carried out, specifically we extract
all phrases that fulfill the following restrictions: all
source (target) words within the phrase are aligned
only to target (source) words within the phrase.
The probability of these phrases is normally esti-
mated by relative frequencies, normally in both di-
rections, which are then combined in a log-linear way.
</bodyText>
<page confidence="0.982768">
137
</page>
<note confidence="0.522308">
Proceedings of NAACL HLT 2007, Companion Volume, pages 137–140,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.996631">
2.2 N-gram-based System
</subsectionHeader>
<bodyText confidence="0.999369">
In contrast with standard phrase-based approaches,
the N-gram translation model uses tuples as bilin-
gual units whose probabilities are estimated as an
N-gram language model (Marino et al., 2006). This
model approximates the joint probability between
the source and target languages by using N-grams.
Given a word alignment, tuples define a unique
and monotonic segmentation of each bilingual sen-
tence, building up a much smaller set of units
than with phrases and allowing N-gram estimation
to account for the history of the translation pro-
cess (Marino et al., 2006).
</bodyText>
<subsectionHeader confidence="0.999336">
2.3 Feature functions
</subsectionHeader>
<bodyText confidence="0.999564833333333">
Both baseline systems are combined in a log-linear
way with several additional feature functions: a tar-
get language model, a forward and a backward lex-
icon model and a word bonus are common features
for both systems. The phrase-based system also in-
troduces a phrase bonus model.
</bodyText>
<sectionHeader confidence="0.997873" genericHeader="method">
3 Evaluation framework
</sectionHeader>
<bodyText confidence="0.999666176470588">
The translation models presented so far were the ones
used by UPC and RWTH in the second evaluation
campaign of the Tc-STAR project. The goal of this
project is to build a speech-to-speech translation sys-
tem that can deal with real life data.
The corpus consists of the official version of the
speeches held in the European Parliament Plenary
Sessions (EPPS), as available on the web page of the
European Parliament. Table 1 shows some statistics.
The following tools have been used for building
both systems: Word alignments were computed us-
ing GIZA++ (Och, 2003), language models were es-
timated using the SRILM toolkit (Stolcke, 2002), de-
coding was carried out by the free available MARIE
decoder (Crego et al., 2005b) and the optimization
was performed through an in-house implementation
of the simplex method (Nelder and Mead, 1965).
</bodyText>
<table confidence="0.997551125">
Spanish English
Train Sentences 1.2M
Words 32M 31M
Vocabulary 159K 111K
Dev Sentences 1122 699
Words 26K 21K
Test Sentences 1117 894
Words 26K 26K
</table>
<tableCaption confidence="0.99986">
Table 1: Statistics of the EPPS Corpora.
</tableCaption>
<sectionHeader confidence="0.956716" genericHeader="method">
4 Structural comparison
</sectionHeader>
<bodyText confidence="0.936802818181818">
Both approaches aim at improving accuracy by in-
cluding word context in the model. However, the
implementation of the models are quite different and
may produce variations in several aspects.
Table 2 shows the effect on decoding time intro-
duced through different settings of the beam size.
Additionally, the number of available translation
units is shown, corresponding to number of avail-
able phrases for the phrase-based system and 1gram,
2gram and 3gram entries for the N-gram-based sys-
tem. Results are computed on the development set.
</bodyText>
<table confidence="0.999857615384615">
Task Beam Time(s) Units
50 2,677
es—&gt;en 10 852 537k
5 311
50 2,689
en—&gt;es 10 903 594k
5 329
50 1,264
es—&gt;en 10 281 104k 288k 145k
5 138
50 1,508
en—&gt;es 10 302 118k 355k 178k
5 155
</table>
<tableCaption confidence="0.9633535">
Table 2: Impact on efficiency of the beam size in PB
(top) and NB system (bottom).
</tableCaption>
<bodyText confidence="0.999301565217391">
As it can be seen, the number of translation units
is similar in both tasks for both systems (537k —
537k for Spanish to English and 594k — 651k for
English to Spanish) while the time consumed in de-
coding is clearly higher for the phrase-based system.
This can be explained by the fact that in the phrase-
based approach, the same translation can be hypoth-
esized following several segmentations of the input
sentence, as phrases appear (and are collected) from
multiple segmentations of the training sentence pairs.
In other words, the search graph seems to be over-
populated under the phrase-based approach.
Table 3 shows the effect on translation accuracy
regarding the size of the beam in the search. Results
are computed on the test set for the phrase-based
and N-gram-based systems.
Results of the N-gram-based system show that de-
creasing the beam size produces a clear reduction
of the accuracy results. The phrase-based system
shows that accuracy results remain very similar un-
der the different settings. The reason is found on
how translation models are used in the search. In
the phrase-based approach, every partial hypothesis
</bodyText>
<page confidence="0.981721">
138
</page>
<table confidence="0.999876538461538">
Task Beam BLEU NIST mWER
50 51.90 10.53 37.54
es-&gt;en 10 51.93 10.54 37.49
5 51.87 10.55 37.47
50 47.75 9.94 41.20
en-&gt;es 10 47.77 9.96 41.09
5 47.86 10.00 40.74
50 51.63 10.46 37.88
es-&gt;en 10 51.50 10.45 37.83
5 51.39 10.45 37.85
50 47.73 10.08 40.50
en-&gt;es 10 46.82 9.97 41.04
5 45.59 9.83 41.04
</table>
<tableCaption confidence="0.958369">
Table 3: Impact on accuracy of the beam size in PB
(top) and NB system (bottom).
</tableCaption>
<bodyText confidence="0.995106888888889">
is scored uncontextualized, hence, a single score is
used for a given partial hypothesis (phrase). In the
N-gram-based approach, the model is intrinsically
contextualized, which means that each partial hy-
pothesis (tuple) depends on the preceding sequence
of tuples. Thus, if a bad sequence of tuples (bad
scored) is composed of a good initial sequence (well
scored), it is placed on top of the first stacks (beam)
and may cause the pruning of the rest of hypotheses.
</bodyText>
<sectionHeader confidence="0.996357" genericHeader="method">
5 Error analysis
</sectionHeader>
<bodyText confidence="0.999968476190476">
In order to better asses the quality and the differ-
ences between the two systems, a human error anal-
ysis was carried out. The guidelines for this error
analysis can be found in (Vilar et al., 2006). We
randomly selected 100 sentences, which were evalu-
ated by bilingual judges.
This analysis reveals that both systems produce
the same kind of errors in general. However some dif-
ferences were identified. For the English to Spanish
direction the greatest problem is the correct genera-
tion of the right tense for verbs, with around 20% of
all translation errors being of this kind. Reordering
also poses an important problem for both phrase and
N-gram-based systems, with 18% or 15% (respec-
tively) of the errors falling into this category. Miss-
ing words is also an important problem. However,
most of them (approximately two thirds for both sys-
tems) are filler words (i.e. words which do not con-
vey meaning), that is, the meaning of the sentence
is preserved. The most remarkable difference when
comparing both systems is that the N-gram based
system produces a relatively large amount of extra
words (approximately 10%), while for the phrase-
based system, this is only a minor problem (2% of
the errors). In contrast the phrase-based system has
more problems with incorrect translations, that is
words for which a human can find a correspondence
in the source text, but the translation is incorrect.
Similar conclusions can be drawn for the inverse di-
rection. The verb generating problem is not so acute
in this translation direction due to the much simpli-
fied morphology of English. An important problem
is the generation of the right preposition.
The N-gram based system seems to be able to pro-
duce more accurate translations (reflected by a lower
percentage of translation errors). However, it gener-
ates too many additional (and incorrect words) in
the process. The phrase-based system, in contrast,
counteracts this effect by producing a more direct
correspondence with the words present in the source
sentence at the cost of sometimes not being able to
find the exact translation.
</bodyText>
<sectionHeader confidence="0.963773" genericHeader="method">
6 System Rescoring and
Combination
</sectionHeader>
<bodyText confidence="0.999634666666667">
Integration of both output translations in the search
procedure is a complex task. Translation units of
both models are quite different and generation his-
tories pose severe implementation difficulties. We
propose a method for combining the two systems at
the level of N-best lists.
Some features that are useful for SMT are too com-
plex for including them directly in the search pro-
cess. A clear example are the features that require
the entire target sentence to be evaluated, as this is
not compatible with the pruning and recombination
procedures that are necessary for keeping the target
sentence generation process manageable. A possible
solution for this problem is to apply sentence level
re-ranking by using N-best lists.
</bodyText>
<subsectionHeader confidence="0.999691">
6.1 Rescoring Criteria
</subsectionHeader>
<bodyText confidence="0.9546806">
The aim of the rescoring procedure is to choose the
best translation candidate out of a given set of N
possible translations. In our approach this transla-
tion candidates are produced independently by both
of the systems and then combined by a simple con-
catenation&apos;. In order for the hypothesis to have a
comparable set of scores, we perform an additional
“cross-rescoring&amp;quot; of the lists.
Given an N-best list of the phrase-based (N-gram-
based) system, we compute the cost of each target
sentence of this N-best list for the N-gram-based
(phrase-based) system. However this computation
is not possible in all cases. Table 4 shows the per-
centage of target sentences that the N-gram-based
&apos;With removal of duplicates.
</bodyText>
<page confidence="0.994184">
139
</page>
<bodyText confidence="0.998771">
(phrase-based) system is able to produce given an N-
best list of target sentences computed by the phrase-
based (N-gram-based) system. This percentage is
calculated on the development set.
The vocabulary of phrases is bigger than the vo-
cabulary of tuples, due to the fact that phrases are
extracted from multiple segmentations of the train-
ing sentence pairs. Hence, the number of sentences
reproduced by the N-gram-based system is smaller
than the number of sentences reproduced by the
phrase-based system. Whenever a sentence can not
be reproduced by a given system, the cost of the
worst sentence in the N-best list is assigned to it.
</bodyText>
<table confidence="0.965536666666667">
Task N-best % NB % PB
es-&gt;en 1000 37.5 57.5
en-&gt;es 1000 37.2 48.6
</table>
<tableCaption confidence="0.998985">
Table 4: Sentences (%) produced by each system.
</tableCaption>
<subsectionHeader confidence="0.647439">
6.2 Results
</subsectionHeader>
<bodyText confidence="0.997924285714286">
Table 5 shows results of the rescoring and system
combination experiments on the test set. The first
two rows include results of systems non-rescored and
PB (NB) rescored by NB (PB). The third row corre-
sponds to the system combination. Here, PB (NB)
rescored by NB (PB) are simply merged and ranked
by rescored score.
</bodyText>
<table confidence="0.9853818">
System N-best BLEU NIST mWER
Spanish-to-English
PB 1 51.90 10.54 37.50
PB 1000 52.55 10.61 37.12
NB 1 51.63 10.46 37.88
NB 1000 52.25 10.55 37.43
PB+NB 2 51.77 10.49 37.68
PB+NB 2000 52.31 10.56 37.32
English-to-Spanish
PB 1 47.75 9.94 41.2
PB 1000 48.46 10.13 39.98
NB 1 47.73 10.09 40.50
NB 1000 48.33 10.15 40.13
PB+NB 2 48.26 10.05 40.61
PB+NB 2000 48.54 10.16 40.00
</table>
<tableCaption confidence="0.999527">
Table 5: Rescoring and system combination results.
</tableCaption>
<sectionHeader confidence="0.999568" genericHeader="conclusions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999981315789474">
The structural comparison has shown on the one
hand that the N-gram-based system outperforms
the phrase-based in terms of search time efficiency
by avoiding the overpopulation problem presented
in the phrase-based approach. On the other hand
the phrase-based system shows a better performance
when decoding under a highly constrained search.
A detailed error analysis has also been carried out
in order to better determine the differences in per-
formance of both systems. The N-gram based sys-
tem produced more accurate translations, but also a
larger amount of extra (incorrect) words when com-
pare to the phrase-based translation system.
In section 6 we have presented a system combina-
tion method using a rescoring feature for each SMT
system, i.e. the N-gram-based feature for the phrase-
based system and vice-versa. For both systems, con-
sidering the feature of the opposite system leads to
an improvement of BLEU score.
</bodyText>
<sectionHeader confidence="0.999679" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998484891891892">
M.R. Costa-jussa, J.M. Crego, A. de Gispert,
P. Lambert, M. Khalilov J.A.R. Fonollosa, J.B.
Marino, and R. Banchs. 2006. Talp phrase-based
statistical machine translation and talp system
combination the iwslt 2006. IWSLT06.
J. M. Crego, M. R. Costa-jussa, J. Marino, and J. A.
Fonollosa. 2005a. N-gram-based versus phrase-
based statistical machine translation. IWSLT05,
October.
J.M. Crego, J. Marino, and A. de Gispert. 2005b.
An Ngram-based statistical machine translation
decoder. ICSLP05, April.
J.B. Marino, R.E. Banchs, J.M. Crego, A. de Gis-
pert, P. Lambert, J.A.R. Fonollosa, and M.R.
Costa-jussa. 2006. N-gram based machine trans-
lation. Computational Linguistics, 32(4):527–549.
E. Matusov, N. Ueffing, and H. Ney. 2006. Com-
puting consensus translation from multiple ma-
chine translation systems using enhanced hypothe-
ses alignment. EACL06, pages 33–40.
J.A. Nelder and R. Mead. 1965. A simplex method
for function minimization. The Computer Journal,
7:308–313.
F.J. Och. 2003. Giza++ software. http://www-
i6.informatik.rwth-aachen.de/˜och/ soft-
ware/giza++.html.
A. Stolcke. 2002. Srilm - an extensible language
modeling toolkit. Proc. of the 7th Int. Conf. on
Spoken Language Processing, ICSLP&apos;02, Septem-
ber.
David Vilar, Jia Xu, Luis Fernando D&apos;Haro, and
Hermann Ney. 2006. Error Analysis of Machine
Translation Output. In LREC06, pages 697–702,
Genoa, Italy, May.
Richard Zens and Hermann Ney. 2004. Improve-
ments in phrase-based statistical machine transla-
tion. In HLT04, pages 257–264, Boston, MA, May.
</reference>
<page confidence="0.997533">
140
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.748692">
<title confidence="0.996419">and System Combination of Phraseand Statistical Machine Translation Systems</title>
<author confidence="0.988802">R Josep M David A R Jos´e B</author>
<note confidence="0.836886">Research Center (UPC), Barcelona 08034, Aachen University, Aachen D-52056,</note>
<abstract confidence="0.995476307692308">the framework of the we analyze and propose a combination of two Statistical Machine Translation sysa phrase-based and an one. The exhaustive analysis includes a comparison of the translation models in terms of efficiency (number of translation units used in the search and computational time) and an examination of the errors in each system’s output. Additionally, we combine both systems, showing accuracy improvements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M R Costa-jussa</author>
<author>J M Crego</author>
<author>A de Gispert</author>
<author>P Lambert</author>
<author>M Khalilov J A R Fonollosa</author>
<author>J B Marino</author>
<author>R Banchs</author>
</authors>
<title>Talp phrase-based statistical machine translation and talp system combination the iwslt</title>
<date>2006</date>
<pages>06</pages>
<marker>Costa-jussa, Crego, de Gispert, Lambert, Fonollosa, Marino, Banchs, 2006</marker>
<rawString>M.R. Costa-jussa, J.M. Crego, A. de Gispert, P. Lambert, M. Khalilov J.A.R. Fonollosa, J.B. Marino, and R. Banchs. 2006. Talp phrase-based statistical machine translation and talp system combination the iwslt 2006. IWSLT06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Crego</author>
<author>M R Costa-jussa</author>
<author>J Marino</author>
<author>J A Fonollosa</author>
</authors>
<title>N-gram-based versus phrasebased statistical machine translation.</title>
<date>2005</date>
<tech>IWSLT05,</tech>
<contexts>
<context position="1869" citStr="Crego et al., 2005" startWordPosition="261" endWordPosition="264">ed or the N-gram-based models are usually the main features in a log-linear framework, reminiscent of the maximum entropy modeling approach. Two basic issues differentiate the N-gram-based system from the phrase-based one: the training data is sequentially segmented into bilingual units; and the probability of these units is estimated as a bilingual N-gram language model. In the phrase-based model, no monotonicity restriction is imposed on the segmentation and the probabilities are normally estimated simply by relative frequencies. This paper extends the analysis of both systems performed in (Crego et al., 2005a) by additionally performing a manual error analysis of both systems, which were the ones used by UPC and RWTH in the last Tc-STAR evaluation. Furthermore, we will propose a way to combine both systems in order to improve the quality of translations. Experiments combining several kinds of MT systems have been presented in (Matusov et al., 2006), based only on the single best output of each system. Recently, a more straightforward approach of both systems has been performed in (Costa-jussa et al., 2006) which simply selects, for each sentence, one of the provided hypotheses. This paper is orga</context>
<context position="5579" citStr="Crego et al., 2005" startWordPosition="858" endWordPosition="861">campaign of the Tc-STAR project. The goal of this project is to build a speech-to-speech translation system that can deal with real life data. The corpus consists of the official version of the speeches held in the European Parliament Plenary Sessions (EPPS), as available on the web page of the European Parliament. Table 1 shows some statistics. The following tools have been used for building both systems: Word alignments were computed using GIZA++ (Och, 2003), language models were estimated using the SRILM toolkit (Stolcke, 2002), decoding was carried out by the free available MARIE decoder (Crego et al., 2005b) and the optimization was performed through an in-house implementation of the simplex method (Nelder and Mead, 1965). Spanish English Train Sentences 1.2M Words 32M 31M Vocabulary 159K 111K Dev Sentences 1122 699 Words 26K 21K Test Sentences 1117 894 Words 26K 26K Table 1: Statistics of the EPPS Corpora. 4 Structural comparison Both approaches aim at improving accuracy by including word context in the model. However, the implementation of the models are quite different and may produce variations in several aspects. Table 2 shows the effect on decoding time introduced through different settin</context>
</contexts>
<marker>Crego, Costa-jussa, Marino, Fonollosa, 2005</marker>
<rawString>J. M. Crego, M. R. Costa-jussa, J. Marino, and J. A. Fonollosa. 2005a. N-gram-based versus phrasebased statistical machine translation. IWSLT05, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Crego</author>
<author>J Marino</author>
<author>A de Gispert</author>
</authors>
<title>An Ngram-based statistical machine translation decoder.</title>
<date>2005</date>
<tech>ICSLP05,</tech>
<marker>Crego, Marino, de Gispert, 2005</marker>
<rawString>J.M. Crego, J. Marino, and A. de Gispert. 2005b. An Ngram-based statistical machine translation decoder. ICSLP05, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Marino</author>
<author>R E Banchs</author>
<author>J M Crego</author>
<author>A de Gispert</author>
<author>P Lambert</author>
<author>J A R Fonollosa</author>
<author>M R Costa-jussa</author>
</authors>
<title>N-gram based machine translation.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>4</issue>
<marker>Marino, Banchs, Crego, de Gispert, Lambert, Fonollosa, Costa-jussa, 2006</marker>
<rawString>J.B. Marino, R.E. Banchs, J.M. Crego, A. de Gispert, P. Lambert, J.A.R. Fonollosa, and M.R. Costa-jussa. 2006. N-gram based machine translation. Computational Linguistics, 32(4):527–549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Matusov</author>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment. EACL06,</title>
<date>2006</date>
<pages>33--40</pages>
<contexts>
<context position="2216" citStr="Matusov et al., 2006" startWordPosition="320" endWordPosition="323">lingual N-gram language model. In the phrase-based model, no monotonicity restriction is imposed on the segmentation and the probabilities are normally estimated simply by relative frequencies. This paper extends the analysis of both systems performed in (Crego et al., 2005a) by additionally performing a manual error analysis of both systems, which were the ones used by UPC and RWTH in the last Tc-STAR evaluation. Furthermore, we will propose a way to combine both systems in order to improve the quality of translations. Experiments combining several kinds of MT systems have been presented in (Matusov et al., 2006), based only on the single best output of each system. Recently, a more straightforward approach of both systems has been performed in (Costa-jussa et al., 2006) which simply selects, for each sentence, one of the provided hypotheses. This paper is organized as follows. In section 2, we briefly describe the phrase and the N-gram-based baseline systems. In the next section we present the evaluation framework. In Section 4 we report a structural comparison performed for both systems and, afterwards, in Section 5, we analyze the errors of both systems. Finally, in the last two sections we rescore</context>
</contexts>
<marker>Matusov, Ueffing, Ney, 2006</marker>
<rawString>E. Matusov, N. Ueffing, and H. Ney. 2006. Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment. EACL06, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Nelder</author>
<author>R Mead</author>
</authors>
<title>A simplex method for function minimization.</title>
<date>1965</date>
<journal>The Computer Journal,</journal>
<pages>7--308</pages>
<contexts>
<context position="5697" citStr="Nelder and Mead, 1965" startWordPosition="875" endWordPosition="878">an deal with real life data. The corpus consists of the official version of the speeches held in the European Parliament Plenary Sessions (EPPS), as available on the web page of the European Parliament. Table 1 shows some statistics. The following tools have been used for building both systems: Word alignments were computed using GIZA++ (Och, 2003), language models were estimated using the SRILM toolkit (Stolcke, 2002), decoding was carried out by the free available MARIE decoder (Crego et al., 2005b) and the optimization was performed through an in-house implementation of the simplex method (Nelder and Mead, 1965). Spanish English Train Sentences 1.2M Words 32M 31M Vocabulary 159K 111K Dev Sentences 1122 699 Words 26K 21K Test Sentences 1117 894 Words 26K 26K Table 1: Statistics of the EPPS Corpora. 4 Structural comparison Both approaches aim at improving accuracy by including word context in the model. However, the implementation of the models are quite different and may produce variations in several aspects. Table 2 shows the effect on decoding time introduced through different settings of the beam size. Additionally, the number of available translation units is shown, corresponding to number of avai</context>
</contexts>
<marker>Nelder, Mead, 1965</marker>
<rawString>J.A. Nelder and R. Mead. 1965. A simplex method for function minimization. The Computer Journal, 7:308–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<date>2003</date>
<note>Giza++ software. http://wwwi6.informatik.rwth-aachen.de/˜och/ software/giza++.html.</note>
<contexts>
<context position="5425" citStr="Och, 2003" startWordPosition="834" endWordPosition="835"> a phrase bonus model. 3 Evaluation framework The translation models presented so far were the ones used by UPC and RWTH in the second evaluation campaign of the Tc-STAR project. The goal of this project is to build a speech-to-speech translation system that can deal with real life data. The corpus consists of the official version of the speeches held in the European Parliament Plenary Sessions (EPPS), as available on the web page of the European Parliament. Table 1 shows some statistics. The following tools have been used for building both systems: Word alignments were computed using GIZA++ (Och, 2003), language models were estimated using the SRILM toolkit (Stolcke, 2002), decoding was carried out by the free available MARIE decoder (Crego et al., 2005b) and the optimization was performed through an in-house implementation of the simplex method (Nelder and Mead, 1965). Spanish English Train Sentences 1.2M Words 32M 31M Vocabulary 159K 111K Dev Sentences 1122 699 Words 26K 21K Test Sentences 1117 894 Words 26K 26K Table 1: Statistics of the EPPS Corpora. 4 Structural comparison Both approaches aim at improving accuracy by including word context in the model. However, the implementation of t</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F.J. Och. 2003. Giza++ software. http://wwwi6.informatik.rwth-aachen.de/˜och/ software/giza++.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>Srilm - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP&apos;02,</booktitle>
<contexts>
<context position="5497" citStr="Stolcke, 2002" startWordPosition="845" endWordPosition="846"> presented so far were the ones used by UPC and RWTH in the second evaluation campaign of the Tc-STAR project. The goal of this project is to build a speech-to-speech translation system that can deal with real life data. The corpus consists of the official version of the speeches held in the European Parliament Plenary Sessions (EPPS), as available on the web page of the European Parliament. Table 1 shows some statistics. The following tools have been used for building both systems: Word alignments were computed using GIZA++ (Och, 2003), language models were estimated using the SRILM toolkit (Stolcke, 2002), decoding was carried out by the free available MARIE decoder (Crego et al., 2005b) and the optimization was performed through an in-house implementation of the simplex method (Nelder and Mead, 1965). Spanish English Train Sentences 1.2M Words 32M 31M Vocabulary 159K 111K Dev Sentences 1122 699 Words 26K 21K Test Sentences 1117 894 Words 26K 26K Table 1: Statistics of the EPPS Corpora. 4 Structural comparison Both approaches aim at improving accuracy by including word context in the model. However, the implementation of the models are quite different and may produce variations in several aspe</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. Srilm - an extensible language modeling toolkit. Proc. of the 7th Int. Conf. on Spoken Language Processing, ICSLP&apos;02, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vilar</author>
<author>Jia Xu</author>
<author>Luis Fernando D&apos;Haro</author>
<author>Hermann Ney</author>
</authors>
<title>Error Analysis of Machine Translation Output. In</title>
<date>2006</date>
<booktitle>LREC06,</booktitle>
<pages>697--702</pages>
<location>Genoa, Italy,</location>
<contexts>
<context position="8908" citStr="Vilar et al., 2006" startWordPosition="1430" endWordPosition="1433">a given partial hypothesis (phrase). In the N-gram-based approach, the model is intrinsically contextualized, which means that each partial hypothesis (tuple) depends on the preceding sequence of tuples. Thus, if a bad sequence of tuples (bad scored) is composed of a good initial sequence (well scored), it is placed on top of the first stacks (beam) and may cause the pruning of the rest of hypotheses. 5 Error analysis In order to better asses the quality and the differences between the two systems, a human error analysis was carried out. The guidelines for this error analysis can be found in (Vilar et al., 2006). We randomly selected 100 sentences, which were evaluated by bilingual judges. This analysis reveals that both systems produce the same kind of errors in general. However some differences were identified. For the English to Spanish direction the greatest problem is the correct generation of the right tense for verbs, with around 20% of all translation errors being of this kind. Reordering also poses an important problem for both phrase and N-gram-based systems, with 18% or 15% (respectively) of the errors falling into this category. Missing words is also an important problem. However, most of</context>
</contexts>
<marker>Vilar, Xu, D&apos;Haro, Ney, 2006</marker>
<rawString>David Vilar, Jia Xu, Luis Fernando D&apos;Haro, and Hermann Ney. 2006. Error Analysis of Machine Translation Output. In LREC06, pages 697–702, Genoa, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Improvements in phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT04,</booktitle>
<pages>257--264</pages>
<location>Boston, MA,</location>
<contexts>
<context position="1172" citStr="Zens and Ney, 2004" startWordPosition="156" endWordPosition="159"> an N-gram-based one. The exhaustive analysis includes a comparison of the translation models in terms of efficiency (number of translation units used in the search and computational time) and an examination of the errors in each system’s output. Additionally, we combine both systems, showing accuracy improvements. 1 Introduction Statistical machine translation (SMT) has evolved from the initial word-based translation models to more advanced models that take the context surrounding the words into account. The so-called phrase-based and N-gram-based models are two examples of these approaches (Zens and Ney, 2004; Marino et al., 2006). In current state-of-the-art SMT systems, the phrase-based or the N-gram-based models are usually the main features in a log-linear framework, reminiscent of the maximum entropy modeling approach. Two basic issues differentiate the N-gram-based system from the phrase-based one: the training data is sequentially segmented into bilingual units; and the probability of these units is estimated as a bilingual N-gram language model. In the phrase-based model, no monotonicity restriction is imposed on the segmentation and the probabilities are normally estimated simply by relat</context>
</contexts>
<marker>Zens, Ney, 2004</marker>
<rawString>Richard Zens and Hermann Ney. 2004. Improvements in phrase-based statistical machine translation. In HLT04, pages 257–264, Boston, MA, May.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>