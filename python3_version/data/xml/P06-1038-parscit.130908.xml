<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001190">
<title confidence="0.9991665">
Efficient Unsupervised Discovery of Word Categories
Using Symmetric Patterns and High Frequency Words
</title>
<author confidence="0.945051">
Dmitry Davidov
</author>
<affiliation confidence="0.735622">
ICNC
The Hebrew University
Jerusalem 91904, Israel
</affiliation>
<email confidence="0.992873">
dmitry@alice.nc.huji.ac.il
</email>
<author confidence="0.992313">
Ari Rappoport
</author>
<affiliation confidence="0.818934666666667">
Institute of Computer Science
The Hebrew University
Jerusalem 91904, Israel
</affiliation>
<email confidence="0.92131">
www.cs.huji.ac.il/∼arir
</email>
<sectionHeader confidence="0.992388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999865">
We present a novel approach for discov-
ering word categories, sets of words shar-
ing a significant aspect of their mean-
ing. We utilize meta-patterns of high-
frequency words and content words in or-
der to discover pattern candidates. Sym-
metric patterns are then identified using
graph-based measures, and word cate-
gories are created based on graph clique
sets. Our method is the first pattern-based
method that requires no corpus annota-
tion or manually provided seed patterns
or words. We evaluate our algorithm on
very large corpora in two languages, us-
ing both human judgments and WordNet-
based evaluation. Our fully unsupervised
results are superior to previous work that
used a POS tagged corpus, and computa-
tion time for huge corpora are orders of
magnitude faster than previously reported.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994425">
Lexical resources are crucial in most NLP tasks
and are extensively used by people. Manual com-
pilation of lexical resources is labor intensive, er-
ror prone, and susceptible to arbitrary human deci-
sions. Hence there is a need for automatic author-
ing that would be as unsupervised and language-
independent as possible.
An important type of lexical resource is that
given by grouping words into categories. In gen-
eral, the notion of a category is a fundamental one
in cognitive psychology (Matlin, 2005). A lexi-
cal category is a set of words that share a signif-
icant aspect of their meaning, e.g., sets of words
denoting vehicles, types of food, tool names, etc.
A word can obviously belong to more than a single
category. We will use ‘category’ instead of ‘lexi-
cal category’ for brevity&apos;.
Grouping of words into categories is useful in it-
self (e.g., for the construction of thesauri), and can
serve as the starting point in many applications,
such as ontology construction and enhancement,
discovery of verb subcategorization frames, etc.
Our goal in this paper is a fully unsupervised
discovery of categories from large unannotated
text corpora. We aim for categories containing sin-
gle words (multi-word lexical items will be dealt
with in future papers.) Our approach is based on
patterns, and utilizes the following stages:
</bodyText>
<listItem confidence="0.949219307692308">
1. Discovery of a set of pattern candidates that
might be useful for induction of lexical re-
lationships. We do this in a fully unsuper-
vised manner, using meta-patterns comprised
of high frequency words and content words.
2. Identification of pattern candidates that give
rise to symmetric lexical relationships. This
is done using simple measures in a word re-
lationship graph.
3. Usage of a novel graph clique-set algorithm
in order to generate categories from informa-
tion on the co-occurrence of content words in
the symmetric patterns.
</listItem>
<bodyText confidence="0.999863">
We performed a thorough evaluation on two En-
glish corpora (the BNC and a 68GB web corpus)
and on a 33GB Russian corpus, and a sanity-check
test on smaller Danish, Irish and Portuguese cor-
pora. Evaluations were done using both human
</bodyText>
<footnote confidence="0.875813333333333">
&apos;Some people use the term ‘concept’. We adhere to the
cognitive psychology terminology, in which ‘concept’ refers
to the mental representation of a category (Matlin, 2005).
</footnote>
<page confidence="0.93223">
297
</page>
<note confidence="0.55332">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 297–304,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999934625">
judgments and WordNet in a setting quite simi-
lar to that done (for the BNC) in previous work.
Our unsupervised results are superior to previous
work that used a POS tagged corpus, are less lan-
guage dependent, and are very efficient computa-
tionally2.
Patterns are a common approach in lexical ac-
quisition. Our approach is novel in several as-
pects: (1) we discover patterns in a fully unsu-
pervised manner, as opposed to using a manually
prepared pattern set, pattern seed or words seeds;
(2) our pattern discovery requires no annotation of
the input corpus, as opposed to requiring POS tag-
ging or partial or full parsing; (3) we discover gen-
eral symmetric patterns, as opposed to using a few
hard-coded ones such as ‘x and y’; (4) the clique-
set graph algorithm in stage 3 is novel. In addition,
we demonstrated the relatively language indepen-
dent nature of our approach by evaluating on very
large corpora in two languages3.
Section 2 surveys previous work. Section 3 de-
scribes pattern discovery, and Section 4 describes
the formation of categories. Evaluation is pre-
sented in Section 5, and a discussion in Section 6.
</bodyText>
<sectionHeader confidence="0.990549" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.980174523809524">
Much work has been done on lexical acquisition
of all sorts. The three main distinguishing axes are
(1) the type of corpus annotation and other human
input used; (2) the type of lexical relationship tar-
geted; and (3) the basic algorithmic approach. The
two main approaches are pattern-based discovery
and clustering of context feature vectors.
Many of the papers cited below aim at the con-
struction of hyponym (is-a) hierarchies. Note that
they can also be viewed as algorithms for category
discovery, because a subtree in such a hierarchy
defines a lexical category.
A first major algorithmic approach is to repre-
sent word contexts as vectors in some space and
use similarity measures and automatic clustering
in that space (Curran and Moens, 2002). Pereira
(1993) and Lin (1998) use syntactic features in the
vector definition. (Pantel and Lin, 2002) improves
on the latter by clustering by committee. Cara-
ballo (1999) uses conjunction and appositive an-
notations in the vector representation.
</bodyText>
<footnote confidence="0.9685612">
2We did not compare against methods that use richer syn-
tactic information, both because they are supervised and be-
cause they are much more computationally demanding.
3We are not aware of any multilingual evaluation previ-
ously reported on the task.
</footnote>
<bodyText confidence="0.999772019607843">
The only previous works addressing our prob-
lem and not requiring any syntactic annotation are
those that decompose a lexically-defined matrix
(by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deer-
wester et al, 1990). Such matrix decomposition
is computationally heavy and has not been proven
to scale well when the number of words assigned
to categories grows.
Agglomerative clustering (e.g., (Brown et al,
1992; Li, 1996)) can produce hierarchical word
categories from an unannotated corpus. However,
we are not aware of work in this direction that has
been evaluated with good results on lexical cate-
gory acquisition. The technique is also quite de-
manding computationally.
The second main algorithmic approach is to
use lexico-syntactic patterns. Patterns have been
shown to produce more accurate results than fea-
ture vectors, at a lower computational cost on large
corpora (Pantel et al, 2004). Hearst (1992) uses a
manually prepared set of initial lexical patterns in
order to discover hierarchical categories, and uti-
lizes those categories in order to automatically dis-
cover additional patterns.
(Berland and Charniak, 1999) use hand crafted
patterns to discover part-of (meronymy) relation-
ships, and (Chklovski and Pantel, 2004) discover
various interesting relations between verbs. Both
use information obtained by parsing. (Pantel et al,
2004) reduce the depth of the linguistic data used
but still requires POS tagging.
Many papers directly target specific applica-
tions, and build lexical resources as a side effect.
Named Entity Recognition can be viewed as an in-
stance of our problem where the desired categories
contain words that are names of entities of a par-
ticular kind, as done in (Freitag, 2004) using co-
clustering. Many Information Extraction papers
discover relationships between words using syn-
tactic patterns (Riloff and Jones, 1999).
(Widdows and Dorow, 2002; Dorow et al, 2005)
discover categories using two hard-coded symmet-
ric patterns, and are thus the closest to us. They
also introduce an elegant graph representation that
we adopted. They report good results. However,
they require POS tagging of the corpus, use only
two hard-coded patterns (‘x and y’, ‘x or y’), deal
only with nouns, and require non-trivial computa-
tions on the graph.
A third, less common, approach uses set-
theoretic inference, for example (Cimiano et al,
</bodyText>
<page confidence="0.99561">
298
</page>
<bodyText confidence="0.99951">
2005). Again, that paper uses syntactic informa-
tion.
In summary, no previous work has combined
the accuracy, scalability and performance advan-
tages of patterns with the fully unsupervised,
unannotated nature possible with clustering ap-
proaches. This severely limits the applicability
of previous work on the huge corpora available at
present.
</bodyText>
<sectionHeader confidence="0.931856" genericHeader="method">
3 Discovery of Patterns
</sectionHeader>
<bodyText confidence="0.9999254">
Our first step is the discovery of patterns that are
useful for lexical category acquisition. We use two
main stages: discovery of pattern candidates, and
identification of the symmetric patterns among the
candidates.
</bodyText>
<subsectionHeader confidence="0.992292">
3.1 Pattern Candidates
</subsectionHeader>
<bodyText confidence="0.999703448275862">
An examination of the patterns found useful in
previous work shows that they contain one or more
very frequent word, such as ‘and’, ‘is’, etc. Our
approach towards unsupervised pattern induction
is to find such words and utilize them.
We define a high frequency word (HFW) as a
word appearing more than TH times per million
words, and a content word (CW) as a word appear-
ing less than TC times per a million words4.
Now define a meta-pattern as any sequence of
HFWs and CWs. In this paper we require that
meta-patterns obey the following constraints: (1)
at most 4 words; (2) exactly two content words; (3)
no two consecutive CWs. The rationale is to see
what can be achieved using relatively short pat-
terns and where the discovered categories contain
single words only. We will relax these constraints
in future papers. Our meta-patterns here are thus
of four types: CHC, CHCH, CHHC, and HCHC.
In order to focus on patterns that are more likely
to provide high quality categories, we removed
patterns that appear in the corpus less than TP
times per million words. Since we can ensure that
the number of HFWs is bounded, the total number
of pattern candidates is bounded as well. Hence,
this stage can be computed in time linear in the
size of the corpus (assuming the corpus has been
already pre-processed to allow direct access to a
word by its index.)
</bodyText>
<footnote confidence="0.584524">
4Considerations for the selection of thresholds are dis-
cussed in Section 5.
</footnote>
<subsectionHeader confidence="0.998978">
3.2 Symmetric Patterns
</subsectionHeader>
<bodyText confidence="0.999933">
Many of the pattern candidates discovered in the
previous stage are not usable. In order to find a us-
able subset, we focus on the symmetric patterns.
Our rationale is that two content-bearing words
that appear in a symmetric pattern are likely to
be semantically similar in some sense. This sim-
ple observation turns out to be very powerful, as
shown by our results. We will eventually combine
data from several patterns and from different cor-
pus windows (Section 4.)
For identifying symmetric patterns, we use a
version of the graph representation of (Widdows
and Dorow, 2002). We first define the single-
pattern graph G(P) as follows. Nodes corre-
spond to content words, and there is a directed arc
A(x, y) from node x to node y iff (1) the words x
and y both appear in an instance of the pattern P
as its two CWs; and (2) x precedes y in P. Denote
by Nodes(G), Arcs(G) the nodes and arcs in a
graph G, respectively.
We now compute three measures on G(P) and
combine them for all pattern candidates to filter
asymmetric ones. The first measure (M1) counts
the proportion of words that can appear in both
slots of the pattern, out of the total number of
words. The reasoning here is that if a pattern al-
lows a large percentage of words to participate in
both slots, its chances of being a symmetric pat-
tern are greater:
</bodyText>
<equation confidence="0.9419155">
M1��|{x|∃yA(x, y) ∧ ∃zA(z, x)}|
|Nodes(G(P))|
</equation>
<bodyText confidence="0.99969675">
M1 filters well patterns that connect words hav-
ing different parts of speech. However, it may
fail to filter patterns that contain multiple levels
of asymmetric relationships. For example, in the
pattern ‘x belongs to y’, we may find a word B
on both sides (‘A belongs to B’, ‘B belongs to C’)
while the pattern is still asymmetric.
In order to detect symmetric relationships in a
finer manner, for the second and third measures
we define 5ymG(P), the symmetric subgraph of
G(P), containing only the bidirectional arcs and
nodes of G(P):
</bodyText>
<equation confidence="0.83177">
5ymG(P) _ {{x}, {(x, y)}|A(x, y) ∧ A(y, x)}
</equation>
<bodyText confidence="0.999917">
The second and third measures count the pro-
portion of the number of symmetric nodes and
edges in G(P), respectively:
</bodyText>
<equation confidence="0.9220714">
M2 ��|Nodes(5ymG(P))|
|Nodes(G(P))|
299
M3 |Ares(5ymG(P))|
|Ares(G(P))|
</equation>
<bodyText confidence="0.999807">
All three measures yield values in [0, 1], and
in all three a higher value indicates more symme-
try. M2 and M3 are obviously correlated, but they
capture different aspects of a pattern’s nature: M3
is informative for highly interconnected but small
word categories (e.g., month names), while M2 is
useful for larger categories that are more loosely
connected in the corpus.
We use the three measures as follows. For each
measure, we prepare a sorted list of all candidate
patterns. We remove patterns that are not in the
top ZT (we use 100, see Section 5) in any of the
three lists, and patterns that are in the bottom ZB
in at least one of the lists. The remaining patterns
constitute our final list of symmetric patterns.
We do not rank the final list, since the category
discovery algorithm of the next section does not
need such a ranking. Defining and utilizing such a
ranking is a subject for future work.
A sparse matrix representation of each graph
can be computed in time linear in the size of the in-
put corpus, since (1) the number of patterns |P |is
bounded, (2) vocabulary size |V  |(the total number
of graph nodes) is much smaller than corpus size,
and (3) the average node degree is much smaller
than |V  |(in practice, with the thresholds used, it
is a small constant.)
</bodyText>
<sectionHeader confidence="0.978795" genericHeader="method">
4 Discovery of Categories
</sectionHeader>
<bodyText confidence="0.999838333333333">
After the end of the previous stage we have a set
of symmetric patterns. We now use them in order
to discover categories. In this section we describe
the graph clique-set method for generating initial
categories, and category pruning techniques for in-
creased quality.
</bodyText>
<subsectionHeader confidence="0.993867">
4.1 The Clique-Set Method
</subsectionHeader>
<bodyText confidence="0.9992008">
Our approach to category discovery is based on
connectivity structures in the all-pattern word rela-
tionship graph G, resulting from merging all of the
single-pattern graphs into a single unified graph.
The graph G can be built in time O(|V  |x |P |x
AverageDegree(G(P))) = O(|V |) (we use V
rather than Nodes(G) for brevity.)
When building G, no special treatment is done
when one pattern is contained within another. For
example, any pattern of the form CHC is contained
in a pattern of the form HCHC (‘x and y’, ‘both x
and y’.) The shared part yields exactly the same
subgraph. This policy could be changed for a dis-
covery of finer relationships.
The main observation on G is that words that
are highly interconnected are good candidates to
form a category. This is the same general obser-
vation exploited by (Widdows and Dorow, 2002),
who try to find graph regions that are more con-
nected internally than externally.
We use a different algorithm. We find all strong
n-cliques (subgraphs containing n nodes that are
all bidirectionally interconnected.) A clique Q de-
fines a category that contains the nodes in Q plus
all of the nodes that are (1) at least unidirectionally
connected to all nodes in Q, and (2) bidirectionally
connected to at least one node in Q.
In practice we use 2-cliques. The strongly con-
nected cliques are the bidirectional arcs in G and
their nodes. For each such arc A, a category is gen-
erated that contains the nodes of all triangles that
contain A and at least one additional bidirectional
arc. For example, suppose the corpus contains the
text fragments ‘book and newspaper’, ‘newspaper
and book’, ‘book and note’, ‘note and book’ and
‘note and newspaper’. In this case the three words
are assigned to a category.
Note that a pair of nodes connected by a sym-
metric arc can appear in more than a single cate-
gory. For example, suppose a graph G containing
five nodes and seven arcs that define exactly three
strongly connected triangles, ABC, ABD, ACE.
The arc (A, B) yields a category {A, B, C, D},
and the arc (A, C) yields a category {A, C, B, E}.
Nodes A and C appear in both categories. Cate-
gory merging is described below.
This stage requires an O(1) computation for
each bidirectional arc of each node, so its com-
plexity is O(|V  |x AverageDegree(G))
O(|V |).
</bodyText>
<subsectionHeader confidence="0.922457">
4.2 Enhancing Category Quality: Category
Merging and Corpus Windowing
</subsectionHeader>
<bodyText confidence="0.993485272727273">
In order to cover as many words as possible, we
use the smallest clique, a single symmetric arc.
This creates redundant categories. We enhance the
quality of the categories by merging them and by
windowing on the corpus.
We use two simple merge heuristics. First,
if two categories are identical we treat them as
one. Second, given two categories Q, R, we merge
them iff there’s more than a 50% overlap between
them: (|Q n R |&gt; |Q|/2) n (|Q n R |&gt; |R|/2).
=
</bodyText>
<page confidence="0.982993">
300
</page>
<bodyText confidence="0.999909730769231">
This could be added to the clique-set stage, but the
phrasing above is simpler to explain and imple-
ment.
In order to increase category quality and re-
move categories that are too context-specific, we
use a simple corpus windowing technique. In-
stead of running the algorithm of this section on
the whole corpus, we divide the corpus into win-
dows of equal size (see Section 5 for size deter-
mination) and perform the category discovery al-
gorithm of this section on each window indepen-
dently. Merging is also performed in each win-
dow separately. We now have a set of categories
for each window. For the final set, we select only
those categories that appear in at least two of the
windows. This technique reduces noise at the po-
tential cost of lowering coverage. However, the
numbers of categories discovered and words they
contain is still very large (see Section 5), so win-
dowing achieves higher precision without hurting
coverage in practice.
The complexity of the merge stage is O(|V |)
times the average number of categories per word
times the average number of words per category.
The latter two are small in practice, so complexity
amounts to O(|V |).
</bodyText>
<sectionHeader confidence="0.997797" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999865">
Lexical acquisition algorithms are notoriously
hard to evaluate. We have attempted to be as
thorough as possible, using several languages and
both automatic and human evaluation. In the auto-
matic part, we followed as closely as possible the
methodology and data used in previous work, so
that meaningful comparisons could be made.
</bodyText>
<subsectionHeader confidence="0.993099">
5.1 Languages and Corpora
</subsectionHeader>
<bodyText confidence="0.999966571428571">
We performed in-depth evaluation on two lan-
guages, English and Russian, using three cor-
pora, two for English and one for Russian. The
first English corpus is the BNC, containing about
100M words. The second English corpus, Dmoz
(Gabrilovich and Markovitch, 2005), is a web cor-
pus obtained by crawling and cleaning the URLs
in the Open Directory Project (dmoz.org), result-
ing in 68GB containing about 8.2G words from
50M web pages.
The Russian corpus was assembled from many
web sites and carefully filtered for duplicates, to
yield 33GB and 4G words. It is a varied corpus
comprising literature, technical texts, news, news-
groups, etc.
As a preliminary sanity-check test we also ap-
plied our method to smaller corpora in Danish,
Irish and Portuguese, and noted some substantial
similarities in the discovered patterns. For exam-
ple, in all 5 languages the pattern corresponding to
‘x and y’ was among the 50 selected.
</bodyText>
<subsectionHeader confidence="0.999765">
5.2 Thresholds, Statistics and Examples
</subsectionHeader>
<bodyText confidence="0.999647592592592">
The thresholds TH, TC, TP, ZT, ZB, were deter-
mined by memory size considerations: we com-
puted thresholds that would give us the maximal
number of words, while enabling the pattern ac-
cess table to reside in main memory. The resulting
numbers are 100, 50,20, 100, 100.
Corpus window size was determined by starting
from a very small window size, defining at ran-
dom a single window of that size, running the al-
gorithm, and iterating this process with increased
window sizes until reaching a desired vocabulary
category participation percentage (i.e., x% of the
different words in the corpus assigned into cate-
gories. We used 5%.) This process has only a
negligible effect on running times, because each
iteration is run only on a single window, not on
the whole corpus.
The table below gives some statistics. V is the
total number of different words in the corpus. W
is the number of words belonging to at least one
of our categories. C is the number of categories
(after merging and windowing.) A5 is the aver-
age category size. Running times are in minutes
on a 2.53Ghz Pentium 4 XP machine with 1GB
memory. Note how small they are, when com-
pared to (Pantel et al, 2004), which took 4 days
for a smaller corpus using the same CPU.
</bodyText>
<table confidence="0.82609425">
V W C AS Time
Dmoz 16M 330K 142K 12.8 93m
BNC 337K 25K 9.6K 10.2 6.8m
Russian 10M 235K 115K 11.6 60m
</table>
<bodyText confidence="0.999289">
Among the patterns discovered are the ubiqui-
tous ‘x and y’, ‘x or y’ and many patterns con-
taining them. Additional patterns include ‘from x
to y’, ‘x and/or y’ (punctuation is treated here as
white space), ‘x and a y’, and ‘neither x nor y’.
We discover categories of different parts of
speech. Among the noun ones, there are many
whose precision is 100%: 37 countries, 18 lan-
guages, 51 chemical elements, 62 animals, 28
types of meat, 19 fruits, 32 university names, etc.
A nice verb category example is {dive, snorkel,
swim, float, surf, sail, canoe, kayak, paddle, tube,
drift}. A nice adjective example is {amazing,
</bodyText>
<page confidence="0.998104">
301
</page>
<construct confidence="0.55712">
awesome, fascinating, inspiring, inspirational, ex-
citing, fantastic, breathtaking, gorgeous.}
</construct>
<subsectionHeader confidence="0.990793">
5.3 Human Judgment Evaluation
</subsectionHeader>
<bodyText confidence="0.999886714285715">
The purpose of the human evaluation was dual: to
assess the quality of the discovered categories in
terms of precision, and to compare with those ob-
tained by a baseline clustering algorithm.
For the baseline, we implemented k-means as
follows. We have removed stopwords from the
corpus, and then used as features the words which
appear before or after the target word. In the calcu-
lation of feature values and inter-vector distances,
and in the removal of less informative features, we
have strictly followed (Pantel and Lin, 2002). We
ran the algorithm 10 times using k = 500 with
randomly selected centroids, producing 5000 clus-
ters. We then merged the resulting clusters us-
ing the same 50% overlap criterion as in our algo-
rithm. The result included 3090, 2116, and 3206
clusters for Dmoz, BNC and Russian respectively.
We used 8 subjects for evaluation of the English
categories and 15 subjects for evaluation of the
Russian ones. In order to assess the subjects’ re-
liability, we also included random categories (see
below.)
The experiment contained two parts. In Part
I, subjects were given 40 triplets of words and
were asked to rank them using the following scale:
(1) the words definitely share a significant part
of their meaning; (2) the words have a shared
meaning but only in some context; (3) the words
have a shared meaning only under a very un-
usual context/situation; (4) the words do not share
any meaning; (5) I am not familiar enough with
some/all of the words.
The 40 triplets were obtained as follows. 20 of
our categories were selected at random from the
non-overlapping categories we have discovered,
and three words were selected from each of these
at random. 10 triplets were selected in the same
manner from the categories produced by k-means,
and 10 triplets were generated by random selec-
tion of content words from the same window in
the corpus.
In Part II, subjects were given the full categories
of the triplets that were graded as 1 or 2 in Part I
(that is, the full ‘good’ categories in terms of shar-
ing of meaning.) They were asked to grade the
categories from 1 (worst) to 10 (best) according to
how much the full category had met the expecta-
tions they had when seeing only the triplet.
Results are given in Table 1. The first line gives
the average percentage of triplets that were given
scores of 1 or 2 (that is, ‘significant shared mean-
ing’.) The 2nd line gives the average score of
a triplet (1 is best.) In these lines scores of 5
were not counted. The 3rd line gives the average
score given to a full category (10 is best.) Inter-
evaluator Kappa between scores 1,2 and 3,4 was
0.56, 0.67 and 0.72 for Dmoz, BNC and Russian
respectively.
Our algorithm clearly outperforms k-means,
which outperforms random. We believe that the
Russian results are better because the percentage
of native speakers among our subjects for Russian
was larger than that for English.
</bodyText>
<subsectionHeader confidence="0.960824">
5.4 WordNet-Based Evaluation
</subsectionHeader>
<bodyText confidence="0.999976612903226">
The major guideline in this part of the evalua-
tion was to compare our results with previous
work having a similar goal (Widdows and Dorow,
2002). We have followed their methodology as
best as we could, using the same WordNet (WN)
categories and the same corpus (BNC) in addition
to the Dmoz and Russian corporal.
The evaluation method is as follows. We took
the exact 10 WN subsets referred to as ‘subjects’
in (Widdows and Dorow, 2002), and removed all
multi-word items. We now selected at random 10
pairs of words from each subject. For each pair,
we found the largest of our discovered categories
containing it (if there isn’t one, we pick another
pair. This is valid because our Recall is obviously
not even close to 100%, so if we did not pick an-
other pair we would seriously harm the validity of
the evaluation.) The various morphological forms
of the same word were treated as one during the
evaluation.
The only difference from the (Widdows and
Dorow, 2002) experiment is the usage of pairs
rather than single words. We did this in order to
disambiguate our categories. This was not needed
in (Widdows and Dorow, 2002) because they had
directly accessed the word graph, which may be
an advantage in some applications.
The Russian evaluation posed a bit of a prob-
lem because the Russian WordNet is not readily
available and its coverage is rather small. Fortu-
nately, the subject list is such that WordNet words
</bodyText>
<footnote confidence="0.990291">
5(Widdows and Dorow, 2002) also reports results for an
LSA-based clustering algorithm that are vastly inferior to the
pattern-based ones.
</footnote>
<page confidence="0.989616">
302
</page>
<table confidence="0.9964008">
Dmoz BNC Russian
us k-means random us k-means random us k-means random
avg ‘shared meaning’ (%) 80.53 18.25 1.43 86.87 8.52 0.00 95.00 18.96 7.33
avg triplet score (1-4) 1.74 3.34 3.88 1.56 3.61 3.94 1.34 3.32 3.76
avg category score (1-10) 9.27 4.00 1.8 9.31 4.50 0.00 8.50 4.66 3.32
</table>
<tableCaption confidence="0.7476715">
Table 1: Results of evaluation by human judgment of three data sets (ours, that obtained by k-means, and
random categories) on the three corpora. See text for detailed explanations.
</tableCaption>
<bodyText confidence="0.996195483870967">
could be translated unambiguously to Russian and
words in our discovered categories could be trans-
lated unambiguously into English. This was the
methodology taken.
For each found category C containing N words,
we computed the following (see Table 2): (1) Pre-
cision: the number of words present in both C and
WN divided by N; (2) Precision*: the number of
correct words divided by N. Correct words are ei-
ther words that appear in the WN subtree, or words
whose entry in the American Heritage Dictionary
or the Britannica directly defines them as belong-
ing to the given class (e.g., ‘keyboard’ is defined
as ‘a piano’; ‘mitt’ is defined by ‘a type of glove’.)
This was done in order to overcome the relative
poorness of WordNet; (3) Recall: the number of
words present in both C and WN divided by the
number of (single) words in WN; (4) The num-
ber of correctly discovered words (New) that are
not in WN. The Table also shows the number of
WN words (:WN), in order to get a feeling by how
much WN could be improved here. For each sub-
ject, we show the average over the 10 randomly
selected pairs.
Table 2 also shows the average of each measure
over the subjects, and the two precision measures
when computed on the total set of WN words. The
(uncorrected) precision is the only metric given in
(Widdows and Dorow, 2002), who reported 82%
(for the BNC.) Our method gives 90.47% for this
metric on the same corpus.
</bodyText>
<subsectionHeader confidence="0.891229">
5.5 Summary
</subsectionHeader>
<bodyText confidence="0.999978111111111">
Our human-evaluated and WordNet-based results
are better than the baseline and previous work re-
spectively. Both are also of good standalone qual-
ity. Clearly, evaluation methodology for lexical
acquisition tasks should be improved, which is an
interesting research direction in itself.
Examining our categories at random, we found
a nice example that shows how difficult it is to
evaluate the task and how useful automatic cate-
gory discovery can be, as opposed to manual def-
inition. Consider the following category, discov-
ered in the Dmoz corpus: {nightcrawlers, chicken,
shrimp, liver, leeches}. We did not know why
these words were grouped together; if asked in an
evaluation, we would give the category a very low
score. However, after some web search, we found
that this is a ‘fish bait’ category, especially suitable
for catfish.
</bodyText>
<sectionHeader confidence="0.999856" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999944647058823">
We have presented a novel method for pattern-
based discovery of lexical semantic categories.
It is the first pattern-based lexical acquisition
method that is fully unsupervised, requiring no
corpus annotation or manually provided patterns
or words. Pattern candidates are discovered us-
ing meta-patterns of high frequency and content
words, and symmetric patterns are discovered us-
ing simple graph-theoretic measures. Categories
are generated using a novel graph clique-set algo-
rithm. The only other fully unsupervised lexical
category acquisition approach is based on decom-
position of a matrix defined by context feature vec-
tors, and it has not been shown to scale well yet.
Our algorithm was evaluated using both human
judgment and automatic comparisons with Word-
Net, and results were superior to previous work
(although it used a POS tagged corpus) and more
efficient computationally. Our algorithm is also
easy to implement.
Computational efficiency and specifically lack
of annotation are important criteria, because they
allow usage of huge corpora, which are presently
becoming available and growing in size.
There are many directions to pursue in the fu-
ture: (1) support multi-word lexical items; (2) in-
crease category quality by improved merge algo-
rithms; (3) discover various relationships (e.g., hy-
ponymy) between the discovered categories; (4)
discover finer inter-word relationships, such as
verb selection preferences; (5) study various prop-
erties of discovered patterns in a detailed manner;
and (6) adapt the algorithm to morphologically
rich languages.
</bodyText>
<page confidence="0.997151">
303
</page>
<table confidence="0.9040496">
Subject Prec. Prec.* Rec. New:WN
Dmoz
instruments 79.25 89.34 34.54 7.2:163
vehicles 80.17 86.84 18.35 6.3:407
academic 78.78 89.32 30.83 15.5:396
body parts 73.85 79.29 5.95 9.1:1491
foodstuff 83.94 90.51 28.41 26.3:1209
clothes 83.41 89.43 10.65 4.5:539
tools 83.99 89.91 21.69 4.3:219
places 76.96 84.45 25.82 6.3:232
crimes 76.32 86.99 31.86 4.7:102
diseases 81.33 88.99 19.58 6.8:332
set avg 79.80 87.51 22.77 9.1:509
all words 79.32 86.94
BNC
instruments 92.68 95.43 9.51 0.6:163
vehicles 94.16 95.23 3.81 0.2:407
academic 93.45 96.10 12.02 0.6:396
body parts 96.38 97.60 0.97 0.3:1491
foodstuff 93.76 94.36 3.60 0.6:1209
cloths 93.49 94.90 4.04 0.3:539
tools 96.84 97.24 6.67 0.1:219
places 87.88 97.25 6.42 1.5:232
crimes 83.79 91.99 19.61 2.6:102
diseases 95.16 97.14 5.54 0.5:332
set avg 92.76 95.72 7.22 0.73:509
all words 90.47 93.80
Russian
instruments 82.46 89.09 25.28 3.4:163
vehicles 83.16 89.58 16.31 5.1:407
academic 87.27 92.92 15.71 4.9:396
body parts 81.42 89.68 3.94 8.3:1491
foodstuff 80.34 89.23 13.41 24.3:1209
clothes 82.47 87.75 15.94 5.1:539
tools 79.69 86.98 21.14 3.7:219
places 82.25 90.20 33.66 8.5:232
crimes 84.77 93.26 34.22 3.3:102
diseases 80.11 87.70 20.69 7.7:332
set avg 82.39 89.64 20.03 7.43:509
all words 80.67 89.17
</table>
<tableCaption confidence="0.832414">
Table 2: WordNet evaluation. Note the BNC ‘all
</tableCaption>
<bodyText confidence="0.9716647">
words’ precision of 90.47%. This metric was re-
ported to be 82% in (Widdows and Dorow, 2002).
It should be noted that our algorithm can be
viewed as one for automatic discovery of word
senses, because it allows a word to participate in
more than a single category. When merged prop-
erly, the different categories containing a word can
be viewed as the set of its senses. We are planning
an evaluation according to this measure after im-
proving the merge stage.
</bodyText>
<sectionHeader confidence="0.999466" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998068">
Matthew Berland and Eugene Charniak, 1999. Finding
parts in very large corpora. ACL ’99.
Peter Brown, Vincent Della Pietra, Peter deSouza,
Jenifer Lai, Robert Mercer, 1992. Class-based n-
gram models for natural language. Comp. Linguis-
tics, 18(4):468–479.
Sharon Caraballo, 1999. Automatic construction of a
hypernym-labeled noun hierarchy from text. ACL
’99.
Timothy Chklovski, Patrick Pantel, 2004. VerbOcean:
mining the web for fine-grained semantic verb rela-
tions. EMNLP ’04.
Philipp Cimiano, Andreas Hotho, Steffen Staab, 2005.
Learning concept hierarchies from text corpora us-
ing formal concept analysis. J. of Artificial Intelli-
gence Research, 24:305–339.
James Curran, Marc Moens, 2002. Improvements in
automatic thesaurus extraction. ACL Workshop on
Unsupervised Lexical Acquisition, 2002.
Scott Deerwester, Susan Dumais, George Furnas,
Thomas Landauer, Richard Harshman, 1990. Index-
ing by latent semantic analysis. J. of the American
Society for Info. Science, 41(6):391–407.
Beate Dorow, Dominic Widdows, Katarina Ling, Jean-
Pierre Eckmann, Danilo Sergi, Elisha Moses, 2005.
Using curvature and Markov clustering in graphs for
lexical acquisition and word sense discrimination.
MEANING ’05.
Dayne Freitag, 2004. Trained named entity recognition
using distributional clusters. EMNLP ’04.
Evgeniy Gabrilovich, Shaul Markovitch, 2005. Fea-
ture generation for text categorization using world
knowledge. IJCAI ’05.
Marti Hearst, 1992. Automatic acquisition of hy-
ponyms from large text corpora. COLING ’92.
Hang Li, Naoki Abe, 1996. Clustering words with the
MDL principle. COLING ’96.
Dekang Lin, 1998. Automatic retrieval and clustering
of similar words. COLING ’98.
Margaret Matlin, 2005. Cognition, 6th edition. John
Wiley &amp; Sons.
Patrick Pantel, Dekang Lin, 2002. Discovering word
senses from text. SIGKDD ’02.
Patrick Pantel, Deepak Ravichandran, Eduard Hovy,
2004. Towards terascale knowledge acquisition.
COLING ’04.
Fernando Pereira, Naftali Tishby, Lillian Lee, 1993.
Distributional clustering of English words. ACL ’93.
Ellen Riloff, Rosie Jones, 1999. Learning dictionaries
for information extraction by multi-level bootstrap-
ping. AAAI ’99.
Hinrich Sch¨utze, 1998. Automatic word sense discrim-
ination. Comp. Linguistics, 24(1):97–123.
Dominic Widdows, Beate Dorow, 2002. A graph model
for unsupervised Lexical acquisition. COLING ’02.
</reference>
<page confidence="0.999327">
304
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.848895">
<title confidence="0.9993855">Efficient Unsupervised Discovery of Word Categories Using Symmetric Patterns and High Frequency Words</title>
<author confidence="0.874504">Dmitry Davidov</author>
<affiliation confidence="0.9846315">ICNC The Hebrew University</affiliation>
<address confidence="0.999918">Jerusalem 91904, Israel</address>
<email confidence="0.999042">dmitry@alice.nc.huji.ac.il</email>
<author confidence="0.996572">Ari Rappoport</author>
<affiliation confidence="0.9998985">Institute of Computer Science The Hebrew University</affiliation>
<address confidence="0.999481">Jerusalem 91904, Israel</address>
<abstract confidence="0.999390523809524">We present a novel approach for discovering word categories, sets of words sharing a significant aspect of their meaning. We utilize meta-patterns of highfrequency words and content words in order to discover pattern candidates. Symmetric patterns are then identified using graph-based measures, and word categories are created based on graph clique sets. Our method is the first pattern-based method that requires no corpus annotation or manually provided seed patterns or words. We evaluate our algorithm on very large corpora in two languages, using both human judgments and WordNetbased evaluation. Our fully unsupervised results are superior to previous work that used a POS tagged corpus, and computation time for huge corpora are orders of magnitude faster than previously reported.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Matthew Berland</author>
<author>Eugene Charniak</author>
</authors>
<title>Finding parts in very large corpora.</title>
<date>1999</date>
<journal>ACL</journal>
<volume>99</volume>
<contexts>
<context position="7087" citStr="Berland and Charniak, 1999" startWordPosition="1132" endWordPosition="1135">we are not aware of work in this direction that has been evaluated with good results on lexical category acquisition. The technique is also quite demanding computationally. The second main algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al, 2004). Hearst (1992) uses a manually prepared set of initial lexical patterns in order to discover hierarchical categories, and utilizes those categories in order to automatically discover additional patterns. (Berland and Charniak, 1999) use hand crafted patterns to discover part-of (meronymy) relationships, and (Chklovski and Pantel, 2004) discover various interesting relations between verbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of our problem where the desired categories contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using cocluster</context>
</contexts>
<marker>Berland, Charniak, 1999</marker>
<rawString>Matthew Berland and Eugene Charniak, 1999. Finding parts in very large corpora. ACL ’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Brown</author>
<author>Vincent Della Pietra</author>
<author>Peter deSouza</author>
<author>Jenifer Lai</author>
<author>Robert Mercer</author>
</authors>
<title>Class-based ngram models for natural language.</title>
<date>1992</date>
<journal>Comp. Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="6369" citStr="Brown et al, 1992" startWordPosition="1022" endWordPosition="1025">ds that use richer syntactic information, both because they are supervised and because they are much more computationally demanding. 3We are not aware of any multilingual evaluation previously reported on the task. The only previous works addressing our problem and not requiring any syntactic annotation are those that decompose a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al, 1990). Such matrix decomposition is computationally heavy and has not been proven to scale well when the number of words assigned to categories grows. Agglomerative clustering (e.g., (Brown et al, 1992; Li, 1996)) can produce hierarchical word categories from an unannotated corpus. However, we are not aware of work in this direction that has been evaluated with good results on lexical category acquisition. The technique is also quite demanding computationally. The second main algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al, 2004). Hearst (1992) uses a manually prepared set of initial lexical patterns in order to discover hierarchical categori</context>
</contexts>
<marker>Brown, Pietra, deSouza, Lai, Mercer, 1992</marker>
<rawString>Peter Brown, Vincent Della Pietra, Peter deSouza, Jenifer Lai, Robert Mercer, 1992. Class-based ngram models for natural language. Comp. Linguistics, 18(4):468–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Caraballo</author>
</authors>
<title>Automatic construction of a hypernym-labeled noun hierarchy from text.</title>
<date>1999</date>
<journal>ACL</journal>
<volume>99</volume>
<contexts>
<context position="5644" citStr="Caraballo (1999)" startWordPosition="910" endWordPosition="912"> clustering of context feature vectors. Many of the papers cited below aim at the construction of hyponym (is-a) hierarchies. Note that they can also be viewed as algorithms for category discovery, because a subtree in such a hierarchy defines a lexical category. A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002). Pereira (1993) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. 2We did not compare against methods that use richer syntactic information, both because they are supervised and because they are much more computationally demanding. 3We are not aware of any multilingual evaluation previously reported on the task. The only previous works addressing our problem and not requiring any syntactic annotation are those that decompose a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al, 1990). Such matrix decomposition is computationally heavy and has not been p</context>
</contexts>
<marker>Caraballo, 1999</marker>
<rawString>Sharon Caraballo, 1999. Automatic construction of a hypernym-labeled noun hierarchy from text. ACL ’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>VerbOcean: mining the web for fine-grained semantic verb relations.</title>
<date>2004</date>
<journal>EMNLP</journal>
<volume>04</volume>
<contexts>
<context position="7192" citStr="Chklovski and Pantel, 2004" startWordPosition="1147" endWordPosition="1150">acquisition. The technique is also quite demanding computationally. The second main algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al, 2004). Hearst (1992) uses a manually prepared set of initial lexical patterns in order to discover hierarchical categories, and utilizes those categories in order to automatically discover additional patterns. (Berland and Charniak, 1999) use hand crafted patterns to discover part-of (meronymy) relationships, and (Chklovski and Pantel, 2004) discover various interesting relations between verbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of our problem where the desired categories contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using coclustering. Many Information Extraction papers discover relationships between words using syntactic patterns (Ri</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Timothy Chklovski, Patrick Pantel, 2004. VerbOcean: mining the web for fine-grained semantic verb relations. EMNLP ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Cimiano</author>
<author>Andreas Hotho</author>
<author>Steffen Staab</author>
</authors>
<title>Learning concept hierarchies from text corpora using formal concept analysis.</title>
<date>2005</date>
<journal>J. of Artificial Intelligence Research,</journal>
<pages>24--305</pages>
<marker>Cimiano, Hotho, Staab, 2005</marker>
<rawString>Philipp Cimiano, Andreas Hotho, Steffen Staab, 2005. Learning concept hierarchies from text corpora using formal concept analysis. J. of Artificial Intelligence Research, 24:305–339.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
<author>Marc Moens</author>
</authors>
<title>Improvements in automatic thesaurus extraction.</title>
<date>2002</date>
<booktitle>ACL Workshop on Unsupervised Lexical Acquisition,</booktitle>
<contexts>
<context position="5473" citStr="Curran and Moens, 2002" startWordPosition="882" endWordPosition="885">otation and other human input used; (2) the type of lexical relationship targeted; and (3) the basic algorithmic approach. The two main approaches are pattern-based discovery and clustering of context feature vectors. Many of the papers cited below aim at the construction of hyponym (is-a) hierarchies. Note that they can also be viewed as algorithms for category discovery, because a subtree in such a hierarchy defines a lexical category. A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002). Pereira (1993) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. 2We did not compare against methods that use richer syntactic information, both because they are supervised and because they are much more computationally demanding. 3We are not aware of any multilingual evaluation previously reported on the task. The only previous works addressing our problem and not requiring any syntactic annotation are those that d</context>
</contexts>
<marker>Curran, Moens, 2002</marker>
<rawString>James Curran, Marc Moens, 2002. Improvements in automatic thesaurus extraction. ACL Workshop on Unsupervised Lexical Acquisition, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan Dumais</author>
<author>George Furnas</author>
<author>Thomas Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>J. of the American Society for Info. Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="6173" citStr="Deerwester et al, 1990" startWordPosition="991" endWordPosition="995">on. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. 2We did not compare against methods that use richer syntactic information, both because they are supervised and because they are much more computationally demanding. 3We are not aware of any multilingual evaluation previously reported on the task. The only previous works addressing our problem and not requiring any syntactic annotation are those that decompose a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al, 1990). Such matrix decomposition is computationally heavy and has not been proven to scale well when the number of words assigned to categories grows. Agglomerative clustering (e.g., (Brown et al, 1992; Li, 1996)) can produce hierarchical word categories from an unannotated corpus. However, we are not aware of work in this direction that has been evaluated with good results on lexical category acquisition. The technique is also quite demanding computationally. The second main algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than fea</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan Dumais, George Furnas, Thomas Landauer, Richard Harshman, 1990. Indexing by latent semantic analysis. J. of the American Society for Info. Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beate Dorow</author>
<author>Dominic Widdows</author>
<author>Katarina Ling</author>
<author>JeanPierre Eckmann</author>
<author>Danilo Sergi</author>
<author>Elisha Moses</author>
</authors>
<title>Using curvature and Markov clustering in graphs for lexical acquisition and word sense discrimination.</title>
<date>2005</date>
<journal>MEANING</journal>
<volume>05</volume>
<contexts>
<context position="7859" citStr="Dorow et al, 2005" startWordPosition="1252" endWordPosition="1255">erbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of our problem where the desired categories contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using coclustering. Many Information Extraction papers discover relationships between words using syntactic patterns (Riloff and Jones, 1999). (Widdows and Dorow, 2002; Dorow et al, 2005) discover categories using two hard-coded symmetric patterns, and are thus the closest to us. They also introduce an elegant graph representation that we adopted. They report good results. However, they require POS tagging of the corpus, use only two hard-coded patterns (‘x and y’, ‘x or y’), deal only with nouns, and require non-trivial computations on the graph. A third, less common, approach uses settheoretic inference, for example (Cimiano et al, 298 2005). Again, that paper uses syntactic information. In summary, no previous work has combined the accuracy, scalability and performance adva</context>
</contexts>
<marker>Dorow, Widdows, Ling, Eckmann, Sergi, Moses, 2005</marker>
<rawString>Beate Dorow, Dominic Widdows, Katarina Ling, JeanPierre Eckmann, Danilo Sergi, Elisha Moses, 2005. Using curvature and Markov clustering in graphs for lexical acquisition and word sense discrimination. MEANING ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
</authors>
<title>Trained named entity recognition using distributional clusters.</title>
<date>2004</date>
<journal>EMNLP</journal>
<volume>04</volume>
<contexts>
<context position="7671" citStr="Freitag, 2004" startWordPosition="1227" endWordPosition="1228">. (Berland and Charniak, 1999) use hand crafted patterns to discover part-of (meronymy) relationships, and (Chklovski and Pantel, 2004) discover various interesting relations between verbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of our problem where the desired categories contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using coclustering. Many Information Extraction papers discover relationships between words using syntactic patterns (Riloff and Jones, 1999). (Widdows and Dorow, 2002; Dorow et al, 2005) discover categories using two hard-coded symmetric patterns, and are thus the closest to us. They also introduce an elegant graph representation that we adopted. They report good results. However, they require POS tagging of the corpus, use only two hard-coded patterns (‘x and y’, ‘x or y’), deal only with nouns, and require non-trivial computations on the graph. A third, less common, approach uses settheore</context>
</contexts>
<marker>Freitag, 2004</marker>
<rawString>Dayne Freitag, 2004. Trained named entity recognition using distributional clusters. EMNLP ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Feature generation for text categorization using world knowledge.</title>
<date>2005</date>
<journal>IJCAI</journal>
<volume>05</volume>
<contexts>
<context position="18729" citStr="Gabrilovich and Markovitch, 2005" startWordPosition="3127" endWordPosition="3130"> 5 Evaluation Lexical acquisition algorithms are notoriously hard to evaluate. We have attempted to be as thorough as possible, using several languages and both automatic and human evaluation. In the automatic part, we followed as closely as possible the methodology and data used in previous work, so that meaningful comparisons could be made. 5.1 Languages and Corpora We performed in-depth evaluation on two languages, English and Russian, using three corpora, two for English and one for Russian. The first English corpus is the BNC, containing about 100M words. The second English corpus, Dmoz (Gabrilovich and Markovitch, 2005), is a web corpus obtained by crawling and cleaning the URLs in the Open Directory Project (dmoz.org), resulting in 68GB containing about 8.2G words from 50M web pages. The Russian corpus was assembled from many web sites and carefully filtered for duplicates, to yield 33GB and 4G words. It is a varied corpus comprising literature, technical texts, news, newsgroups, etc. As a preliminary sanity-check test we also applied our method to smaller corpora in Danish, Irish and Portuguese, and noted some substantial similarities in the discovered patterns. For example, in all 5 languages the pattern </context>
</contexts>
<marker>Gabrilovich, Markovitch, 2005</marker>
<rawString>Evgeniy Gabrilovich, Shaul Markovitch, 2005. Feature generation for text categorization using world knowledge. IJCAI ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<journal>COLING</journal>
<volume>92</volume>
<contexts>
<context position="6869" citStr="Hearst (1992)" startWordPosition="1102" endWordPosition="1103">le well when the number of words assigned to categories grows. Agglomerative clustering (e.g., (Brown et al, 1992; Li, 1996)) can produce hierarchical word categories from an unannotated corpus. However, we are not aware of work in this direction that has been evaluated with good results on lexical category acquisition. The technique is also quite demanding computationally. The second main algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al, 2004). Hearst (1992) uses a manually prepared set of initial lexical patterns in order to discover hierarchical categories, and utilizes those categories in order to automatically discover additional patterns. (Berland and Charniak, 1999) use hand crafted patterns to discover part-of (meronymy) relationships, and (Chklovski and Pantel, 2004) discover various interesting relations between verbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as </context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst, 1992. Automatic acquisition of hyponyms from large text corpora. COLING ’92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Clustering words with the MDL principle.</title>
<date>1996</date>
<journal>COLING</journal>
<volume>96</volume>
<marker>Li, Abe, 1996</marker>
<rawString>Hang Li, Naoki Abe, 1996. Clustering words with the MDL principle. COLING ’96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<journal>COLING</journal>
<volume>98</volume>
<contexts>
<context position="5504" citStr="Lin (1998)" startWordPosition="889" endWordPosition="890">type of lexical relationship targeted; and (3) the basic algorithmic approach. The two main approaches are pattern-based discovery and clustering of context feature vectors. Many of the papers cited below aim at the construction of hyponym (is-a) hierarchies. Note that they can also be viewed as algorithms for category discovery, because a subtree in such a hierarchy defines a lexical category. A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002). Pereira (1993) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. 2We did not compare against methods that use richer syntactic information, both because they are supervised and because they are much more computationally demanding. 3We are not aware of any multilingual evaluation previously reported on the task. The only previous works addressing our problem and not requiring any syntactic annotation are those that decompose a lexically-defined ma</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin, 1998. Automatic retrieval and clustering of similar words. COLING ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Matlin</author>
</authors>
<title>Cognition, 6th edition.</title>
<date>2005</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="1622" citStr="Matlin, 2005" startWordPosition="249" endWordPosition="250">us, and computation time for huge corpora are orders of magnitude faster than previously reported. 1 Introduction Lexical resources are crucial in most NLP tasks and are extensively used by people. Manual compilation of lexical resources is labor intensive, error prone, and susceptible to arbitrary human decisions. Hence there is a need for automatic authoring that would be as unsupervised and languageindependent as possible. An important type of lexical resource is that given by grouping words into categories. In general, the notion of a category is a fundamental one in cognitive psychology (Matlin, 2005). A lexical category is a set of words that share a significant aspect of their meaning, e.g., sets of words denoting vehicles, types of food, tool names, etc. A word can obviously belong to more than a single category. We will use ‘category’ instead of ‘lexical category’ for brevity&apos;. Grouping of words into categories is useful in itself (e.g., for the construction of thesauri), and can serve as the starting point in many applications, such as ontology construction and enhancement, discovery of verb subcategorization frames, etc. Our goal in this paper is a fully unsupervised discovery of cat</context>
<context position="3388" citStr="Matlin, 2005" startWordPosition="539" endWordPosition="540">ng simple measures in a word relationship graph. 3. Usage of a novel graph clique-set algorithm in order to generate categories from information on the co-occurrence of content words in the symmetric patterns. We performed a thorough evaluation on two English corpora (the BNC and a 68GB web corpus) and on a 33GB Russian corpus, and a sanity-check test on smaller Danish, Irish and Portuguese corpora. Evaluations were done using both human &apos;Some people use the term ‘concept’. We adhere to the cognitive psychology terminology, in which ‘concept’ refers to the mental representation of a category (Matlin, 2005). 297 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 297–304, Sydney, July 2006. c�2006 Association for Computational Linguistics judgments and WordNet in a setting quite similar to that done (for the BNC) in previous work. Our unsupervised results are superior to previous work that used a POS tagged corpus, are less language dependent, and are very efficient computationally2. Patterns are a common approach in lexical acquisition. Our approach is novel in several aspects: (1) we discover patterns in a fully unsupervised m</context>
</contexts>
<marker>Matlin, 2005</marker>
<rawString>Margaret Matlin, 2005. Cognition, 6th edition. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<journal>SIGKDD</journal>
<volume>02</volume>
<contexts>
<context position="5576" citStr="Pantel and Lin, 2002" startWordPosition="898" endWordPosition="901">rithmic approach. The two main approaches are pattern-based discovery and clustering of context feature vectors. Many of the papers cited below aim at the construction of hyponym (is-a) hierarchies. Note that they can also be viewed as algorithms for category discovery, because a subtree in such a hierarchy defines a lexical category. A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002). Pereira (1993) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. 2We did not compare against methods that use richer syntactic information, both because they are supervised and because they are much more computationally demanding. 3We are not aware of any multilingual evaluation previously reported on the task. The only previous works addressing our problem and not requiring any syntactic annotation are those that decompose a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al, 1990). S</context>
<context position="22032" citStr="Pantel and Lin, 2002" startWordPosition="3694" endWordPosition="3697">nspirational, exciting, fantastic, breathtaking, gorgeous.} 5.3 Human Judgment Evaluation The purpose of the human evaluation was dual: to assess the quality of the discovered categories in terms of precision, and to compare with those obtained by a baseline clustering algorithm. For the baseline, we implemented k-means as follows. We have removed stopwords from the corpus, and then used as features the words which appear before or after the target word. In the calculation of feature values and inter-vector distances, and in the removal of less informative features, we have strictly followed (Pantel and Lin, 2002). We ran the algorithm 10 times using k = 500 with randomly selected centroids, producing 5000 clusters. We then merged the resulting clusters using the same 50% overlap criterion as in our algorithm. The result included 3090, 2116, and 3206 clusters for Dmoz, BNC and Russian respectively. We used 8 subjects for evaluation of the English categories and 15 subjects for evaluation of the Russian ones. In order to assess the subjects’ reliability, we also included random categories (see below.) The experiment contained two parts. In Part I, subjects were given 40 triplets of words and were asked </context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel, Dekang Lin, 2002. Discovering word senses from text. SIGKDD ’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Deepak Ravichandran, Eduard Hovy,</title>
<date>2004</date>
<journal>COLING</journal>
<volume>04</volume>
<contexts>
<context position="7192" citStr="Pantel, 2004" startWordPosition="1149" endWordPosition="1150">he technique is also quite demanding computationally. The second main algorithmic approach is to use lexico-syntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al, 2004). Hearst (1992) uses a manually prepared set of initial lexical patterns in order to discover hierarchical categories, and utilizes those categories in order to automatically discover additional patterns. (Berland and Charniak, 1999) use hand crafted patterns to discover part-of (meronymy) relationships, and (Chklovski and Pantel, 2004) discover various interesting relations between verbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of our problem where the desired categories contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using coclustering. Many Information Extraction papers discover relationships between words using syntactic patterns (Ri</context>
</contexts>
<marker>Pantel, 2004</marker>
<rawString>Patrick Pantel, Deepak Ravichandran, Eduard Hovy, 2004. Towards terascale knowledge acquisition. COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<journal>ACL</journal>
<volume>93</volume>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, Lillian Lee, 1993. Distributional clustering of English words. ACL ’93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<journal>AAAI</journal>
<volume>99</volume>
<contexts>
<context position="7813" citStr="Riloff and Jones, 1999" startWordPosition="1244" endWordPosition="1247">4) discover various interesting relations between verbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of our problem where the desired categories contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using coclustering. Many Information Extraction papers discover relationships between words using syntactic patterns (Riloff and Jones, 1999). (Widdows and Dorow, 2002; Dorow et al, 2005) discover categories using two hard-coded symmetric patterns, and are thus the closest to us. They also introduce an elegant graph representation that we adopted. They report good results. However, they require POS tagging of the corpus, use only two hard-coded patterns (‘x and y’, ‘x or y’), deal only with nouns, and require non-trivial computations on the graph. A third, less common, approach uses settheoretic inference, for example (Cimiano et al, 298 2005). Again, that paper uses syntactic information. In summary, no previous work has combined </context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff, Rosie Jones, 1999. Learning dictionaries for information extraction by multi-level bootstrapping. AAAI ’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic word sense discrimination.</title>
<date>1998</date>
<journal>Comp. Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze, 1998. Automatic word sense discrimination. Comp. Linguistics, 24(1):97–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
</authors>
<title>A graph model for unsupervised Lexical acquisition.</title>
<date>2002</date>
<journal>COLING</journal>
<volume>02</volume>
<contexts>
<context position="7839" citStr="Widdows and Dorow, 2002" startWordPosition="1248" endWordPosition="1251">sting relations between verbs. Both use information obtained by parsing. (Pantel et al, 2004) reduce the depth of the linguistic data used but still requires POS tagging. Many papers directly target specific applications, and build lexical resources as a side effect. Named Entity Recognition can be viewed as an instance of our problem where the desired categories contain words that are names of entities of a particular kind, as done in (Freitag, 2004) using coclustering. Many Information Extraction papers discover relationships between words using syntactic patterns (Riloff and Jones, 1999). (Widdows and Dorow, 2002; Dorow et al, 2005) discover categories using two hard-coded symmetric patterns, and are thus the closest to us. They also introduce an elegant graph representation that we adopted. They report good results. However, they require POS tagging of the corpus, use only two hard-coded patterns (‘x and y’, ‘x or y’), deal only with nouns, and require non-trivial computations on the graph. A third, less common, approach uses settheoretic inference, for example (Cimiano et al, 298 2005). Again, that paper uses syntactic information. In summary, no previous work has combined the accuracy, scalability </context>
<context position="10957" citStr="Widdows and Dorow, 2002" startWordPosition="1768" endWordPosition="1771"> discussed in Section 5. 3.2 Symmetric Patterns Many of the pattern candidates discovered in the previous stage are not usable. In order to find a usable subset, we focus on the symmetric patterns. Our rationale is that two content-bearing words that appear in a symmetric pattern are likely to be semantically similar in some sense. This simple observation turns out to be very powerful, as shown by our results. We will eventually combine data from several patterns and from different corpus windows (Section 4.) For identifying symmetric patterns, we use a version of the graph representation of (Widdows and Dorow, 2002). We first define the singlepattern graph G(P) as follows. Nodes correspond to content words, and there is a directed arc A(x, y) from node x to node y iff (1) the words x and y both appear in an instance of the pattern P as its two CWs; and (2) x precedes y in P. Denote by Nodes(G), Arcs(G) the nodes and arcs in a graph G, respectively. We now compute three measures on G(P) and combine them for all pattern candidates to filter asymmetric ones. The first measure (M1) counts the proportion of words that can appear in both slots of the pattern, out of the total number of words. The reasoning her</context>
<context position="14954" citStr="Widdows and Dorow, 2002" startWordPosition="2473" endWordPosition="2476"> G can be built in time O(|V |x |P |x AverageDegree(G(P))) = O(|V |) (we use V rather than Nodes(G) for brevity.) When building G, no special treatment is done when one pattern is contained within another. For example, any pattern of the form CHC is contained in a pattern of the form HCHC (‘x and y’, ‘both x and y’.) The shared part yields exactly the same subgraph. This policy could be changed for a discovery of finer relationships. The main observation on G is that words that are highly interconnected are good candidates to form a category. This is the same general observation exploited by (Widdows and Dorow, 2002), who try to find graph regions that are more connected internally than externally. We use a different algorithm. We find all strong n-cliques (subgraphs containing n nodes that are all bidirectionally interconnected.) A clique Q defines a category that contains the nodes in Q plus all of the nodes that are (1) at least unidirectionally connected to all nodes in Q, and (2) bidirectionally connected to at least one node in Q. In practice we use 2-cliques. The strongly connected cliques are the bidirectional arcs in G and their nodes. For each such arc A, a category is generated that contains th</context>
<context position="24572" citStr="Widdows and Dorow, 2002" startWordPosition="4139" endWordPosition="4142">ese lines scores of 5 were not counted. The 3rd line gives the average score given to a full category (10 is best.) Interevaluator Kappa between scores 1,2 and 3,4 was 0.56, 0.67 and 0.72 for Dmoz, BNC and Russian respectively. Our algorithm clearly outperforms k-means, which outperforms random. We believe that the Russian results are better because the percentage of native speakers among our subjects for Russian was larger than that for English. 5.4 WordNet-Based Evaluation The major guideline in this part of the evaluation was to compare our results with previous work having a similar goal (Widdows and Dorow, 2002). We have followed their methodology as best as we could, using the same WordNet (WN) categories and the same corpus (BNC) in addition to the Dmoz and Russian corporal. The evaluation method is as follows. We took the exact 10 WN subsets referred to as ‘subjects’ in (Widdows and Dorow, 2002), and removed all multi-word items. We now selected at random 10 pairs of words from each subject. For each pair, we found the largest of our discovered categories containing it (if there isn’t one, we pick another pair. This is valid because our Recall is obviously not even close to 100%, so if we did not </context>
<context position="25872" citStr="Widdows and Dorow, 2002" startWordPosition="4365" endWordPosition="4368">he various morphological forms of the same word were treated as one during the evaluation. The only difference from the (Widdows and Dorow, 2002) experiment is the usage of pairs rather than single words. We did this in order to disambiguate our categories. This was not needed in (Widdows and Dorow, 2002) because they had directly accessed the word graph, which may be an advantage in some applications. The Russian evaluation posed a bit of a problem because the Russian WordNet is not readily available and its coverage is rather small. Fortunately, the subject list is such that WordNet words 5(Widdows and Dorow, 2002) also reports results for an LSA-based clustering algorithm that are vastly inferior to the pattern-based ones. 302 Dmoz BNC Russian us k-means random us k-means random us k-means random avg ‘shared meaning’ (%) 80.53 18.25 1.43 86.87 8.52 0.00 95.00 18.96 7.33 avg triplet score (1-4) 1.74 3.34 3.88 1.56 3.61 3.94 1.34 3.32 3.76 avg category score (1-10) 9.27 4.00 1.8 9.31 4.50 0.00 8.50 4.66 3.32 Table 1: Results of evaluation by human judgment of three data sets (ours, that obtained by k-means, and random categories) on the three corpora. See text for detailed explanations. could be translat</context>
<context position="27770" citStr="Widdows and Dorow, 2002" startWordPosition="4700" endWordPosition="4703">e the relative poorness of WordNet; (3) Recall: the number of words present in both C and WN divided by the number of (single) words in WN; (4) The number of correctly discovered words (New) that are not in WN. The Table also shows the number of WN words (:WN), in order to get a feeling by how much WN could be improved here. For each subject, we show the average over the 10 randomly selected pairs. Table 2 also shows the average of each measure over the subjects, and the two precision measures when computed on the total set of WN words. The (uncorrected) precision is the only metric given in (Widdows and Dorow, 2002), who reported 82% (for the BNC.) Our method gives 90.47% for this metric on the same corpus. 5.5 Summary Our human-evaluated and WordNet-based results are better than the baseline and previous work respectively. Both are also of good standalone quality. Clearly, evaluation methodology for lexical acquisition tasks should be improved, which is an interesting research direction in itself. Examining our categories at random, we found a nice example that shows how difficult it is to evaluate the task and how useful automatic category discovery can be, as opposed to manual definition. Consider the</context>
</contexts>
<marker>Widdows, Dorow, 2002</marker>
<rawString>Dominic Widdows, Beate Dorow, 2002. A graph model for unsupervised Lexical acquisition. COLING ’02.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>