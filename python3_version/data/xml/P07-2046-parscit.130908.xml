<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007082">
<title confidence="0.9176845">
Boosting Statistical Machine Translation by Lemmatization and Linear
Interpolation
</title>
<author confidence="0.99825">
Ruiqiang Zhang1,2 and Eiichiro Sumita1,2
</author>
<affiliation confidence="0.998811">
1National Institute of Information and Communications Technology
</affiliation>
<address confidence="0.8195725">
2ATR Spoken Language Communication Research Laboratories
2-2-2 Hikaridai, Seiika-cho, Soraku-gun, Kyoto, 619-0288, Japan
</address>
<email confidence="0.999154">
fruiqiang.zhang,eiichiro.sumital@atr.jp
</email>
<sectionHeader confidence="0.997388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999699555555556">
Data sparseness is one of the factors that de-
grade statistical machine translation (SMT).
Existing work has shown that using morpho-
syntactic information is an effective solu-
tion to data sparseness. However, fewer ef-
forts have been made for Chinese-to-English
SMT with using English morpho-syntactic
analysis. We found that while English is
a language with less inflection, using En-
glish lemmas in training can significantly
improve the quality of word alignment that
leads to yield better translation performance.
We carried out comprehensive experiments
on multiple training data of varied sizes to
prove this. We also proposed a new effec-
tive linear interpolation method to integrate
multiple homologous features of translation
models.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999928117647059">
Raw parallel data need to be preprocessed in the
modern phrase-based SMT before they are aligned
by alignment algorithms, one of which is the well-
known tool, GIZA++ (Och and Ney, 2003), for
training IBM models (1-4). Morphological analy-
sis (MA) is used in data preprocessing, by which the
surface words of the raw data are converted into a
new format. This new format can be lemmas, stems,
parts-of-speech and morphemes or mixes of these.
One benefit of using MA is to ease data sparseness
that can reduce the translation quality significantly,
especially for tasks with small amounts of training
data.
Some published work has shown that apply-
ing morphological analysis improved the quality of
SMT (Lee, 2004; Goldwater and McClosky, 2005).
We found that all this earlier work involved exper-
iments conducted on translations from highly in-
flected languages, such as Czech, Arabic, and Span-
ish, to English. These researchers also provided de-
tailed descriptions of the effects of foreign language
morpho-syntactic analysis but presented no specific
results to show the effect of English morphologi-
cal analysis. To the best of our knowledge, there
have been no papers related to English morpholog-
ical analysis for Chinese-to-English (CE) transla-
tions even though the CE translation has been the
main track for many evaluation campaigns includ-
ing NIST MT, IWSLT and TC-STAR, where only
simple tokenization or lower-case capitalization has
been applied to English preprocessing. One possi-
ble reason why English morphological analysis has
been neglected may be that English is less inflected
to the extent that MA may not be effective. How-
ever, we found this assumption should not be taken-
for-granted.
We studied what effect English lemmatization had
on CE translation. Lemmatization is shallow mor-
phological analysis, which uses a lexical entry to re-
place inflected words. For example, the three words,
doing, did and done, are replaced by one word, do.
They are all mapped to the same Chinese transla-
tions. As a result, it eases the problem with sparse
data, and retains word meanings unchanged. It is
not impossible to improve word alignment by using
English lemmatization.
We determined what effect lemmatization had in
experiments using data from the BTEC (Paul, 2006)
CSTAR track. We collected a relatively large cor-
pus of more than 678,000 sentences. We conducted
comprehensive evaluations and used multiple trans-
</bodyText>
<page confidence="0.979291">
181
</page>
<bodyText confidence="0.97402825">
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 181–184,
Prague, June 2007. c�2007 Association for Computational Linguistics
lation metrics to evaluate the results. We found that distance-based distortion model. The weighting pa-
our approach of using lemmatization improved both rameters of these features were optimized in terms
the word alignment and the quality of SMT with of BLEU by the approach of minimum error rate
a small amounts of training data, and, while much training (Och, 2003).
work indicates that MA is useless in training large The data for training and test are from the
amounts of data (Lee, 2004), our intensive exper- IWSLT06 CSTAR track that uses the Basic Travel
iments proved that the chance to get a better MT Expression Corpus (BTEC). The BTEC corpus are
quality using lemmatization is higher than that with- relatively larger corpus for travel domain. We use
out it for large amounts of training data. 678,748 Chinese/English parallel sentences as the
On the basis of successful use of lemmatization training data in the experiments. The number of
translation, we propose a new linear interpolation words are about 3.9M and 4.4M for Chinese and En-
method by which we integrate the homologous fea- glish respectively. The number of unique words for
tures of translation models of the lemmatization and English is 28,709 before lemmatization and 24,635
non-lemmatization system. We found the integrated after lemmatization. A 15%-20% reduction in vo-
model improved all the components’ performance in cabulary is obtained by the lemmatization. The test
the translation. data are the one used in IWSLT06 evaluation. It
2 Moses training for system with contains 500 Chinese sentences. The test data of
lemmatization and without IWSLT05 are the development data for tuning the
We used Moses to carry out the expriments. Moses weighting parameters. Multiple references are used
is the state of the art decoder for SMT. It is an ex- for computing the automatic metrics.
tension of Pharaoh (Koehn et al., 2003), and sup- 3 Experiments
ports factor training and decoding. Our idea can 3.1 Regular test
be easily implemented by Moses. We feed Moses The purpose of the regular tests is to find what ef-
English words with two factors: surface word and fect lemmatization has as the amount of training
lemma. The only difference in training with lemma- data increases. We used the data from the IWSLT06
tization from that without is the alignment factor. CSTAR track. We started with 50,000 (50 K) of
The former uses Chinese surface words and English data, and gradually added more training data from
lemmas as the alignment factor, but the latter uses a 678 K corpus to this. We applied the methods
Chinese surface words and English surface words. in Section 2 to train the non-lemmatized translation
Therefore, the lemmatized English is only used in and lemmatized translation systems. The results are
word alignment. All the other options of Moses are listed in Table 1. We use the alignment error rate
same for both the lemmatization translation and non- (AER) to measure the alignment performance, and
lemmatization translation. the two popular automatic metric, BLEU1 and ME-
We use the tool created by (Minnen et al., 2001) to TEOR2 to evaluate the translations. To measure the
complete the morphological analysis of English. We word alignment, we manually aligned 100 parallel
had to make an English part-of-speech (POS) tag- sentences from the BTEC as the reference file. We
ger that is compatible with the CLAWS-5 tagset to use the “sure” links and the “possible” links to de-
use this tool. We use our in-house tagset and En- note the alignments. As shown in Table 1, we found
glish tagged corpus to train a statistical POS tagger our approach improved word alignment uniformly
by using the maximum entropy principle. Our tagset from small amounts to large amounts of training
contains over 200 POS tags, most of which are con- data. The maximal AER reduction is up to 27.4%
sistent to the CLAWS-5. The tagger achieved 93.7% for the 600K. However, we found some mixed trans-
accuracy for our test set. lation results in terms of BLEU. The lemmatized
We use the default features defined by Pharaoh
in the phrase-based log-linear models i.e., a target
language model, five translation models, and one
</bodyText>
<table confidence="0.9322535">
182
1http://domino.watson.ibm.com/library/CyberDig.nsf (key-
word=RC22176)
2http://www.cs.cmu.edu/—alavie/METEOR
</table>
<tableCaption confidence="0.931436">
Table 1: Translation results as increasing amount of training
</tableCaption>
<table confidence="0.981397857142857">
data in IWSLT06 CSTAR track
System AER BLEU METEOR
50K nonlem 0.217 0.158 0.427
lemma 0.199 0.167 0.431
100K nonlem 0.178 0.182 0.457
lemma 0.177 0.188 0.463
300K nonlem 0.150 0.223 0.501
lemma 0.132 0.217 0.505
400K nonlem 0.136 0.231 0.509
lemma 0.102 0.224 0.507
500K nonlem 0.119 0.235 0.519
lemma 0.104 0.241 0.522
600K nonlem 0.095 0.238 0.535
lemma 0.069 0.248 0.536
</table>
<tableCaption confidence="0.98202">
Table 2: Statistical significance test in terms of BLEU:
sys1=non-lemma, sys2=lemma
</tableCaption>
<table confidence="0.995744714285714">
Data size Diff(sys1-sys2)
50K -0.092 [-0.0176,-0.0012]
100K -0.006 [-0.0155,0.0039]
300K 0.0057 [-0.0046,0.0161]
400K 0.0074 [-0.0023,0.0174]
500K -0.0054 [-0.0139,0.0035]
600K -0.0103 [-0.0201,-0.0006]
</table>
<bodyText confidence="0.994373166666667">
translations did not outperform the non-lemmatized
ones uniformly. They did for small amounts of data,
i.e., 50 K and 100 K, and for large amounts, 500 K
and 600 K. However, they failed for 300 K and 400
K.
The translations were under the statistical signif-
icance test by using the bootStrap scripts3. The re-
sults giving the medians and confidence intervals are
shown in Table 2, where the numbers indicate the
median, the lower and higher boundary at 95% con-
fidence interval. we found the lemma systems were
confidently better than the nonlem systems for the
50K and 600K, but didn’t for other data sizes.
This experiments proved that our proposed ap-
proach improved the qualities of word alignments
that lead to the translation improvement for the 50K,
100K, 500K and 600K. In particular, our results
revealed large amounts of data of 500 K and 600
</bodyText>
<footnote confidence="0.7439115">
3http://projectile.is.cs.cmu.edu/research/public/tools/bootStrap
/tutorial.htm
</footnote>
<tableCaption confidence="0.971913">
Table 3: Competitive scores (BLEU) for non-lemmatization and
lemmatization using randomly extracted corpora
</tableCaption>
<table confidence="0.810146666666667">
System 100K 300K 400K 600K total
lemma 10/11 5.5/11 6.5/11 5/7 27/40
nonlem 1/11 5.5/11 4.5/11 2/7 13/40
</table>
<bodyText confidence="0.990988375">
K was improved by the lemmatization while it has
been found impossible in most published results.
However, data of 300 K and 400 K worsen trans-
lations achieved by the lemmatization4. In what fol-
lows, we discuss a method of random sampling of
creating multiple corpora of varied sizes to see ro-
bustness of our approach and re-investigate the re-
sults of the 300K and 400K.
</bodyText>
<subsectionHeader confidence="0.998315">
3.2 Random sampling test
</subsectionHeader>
<bodyText confidence="0.999692592592593">
In this section, we use a method of random extrac-
tion to generate new multiple training data for each
corpus of one definite size. The new data are ex-
tracted from the whole corpus of 678 K randomly.
We generate ten new corpora for 100 K, 300 K,
and 400 K data and six new corpora for the 678 K
data. Thus, we create eleven and seven corpora of
varied sizes if the corpora in the last experiments
are counted. We use the same method as in Sec-
tion 2 for each generated corpus to construct sys-
tems to compare non-lemmatization and lemmati-
zation. The systems are evaluated again using the
same test data. The results are listed in Table 3
and Figure 1. Table 3 shows the “scoreboard” of
non-lemmatized and lemmatized results in terms of
BLEU. If its score for the lemma system is higher
than that for the nonlem system, the former earns
one point; if equal, each earns 0.5; otherwise, the
nonlem earns one point. As we can see from the ta-
ble, the results for the lemma system are better than
those for the nonlem system for the 100K in 10 of
the total 11 corpora. Of the total 40 random corpora,
the lemma systems outperform the nonlem systems
in 27 times.
By analyzing the results from Tables 1 and 3, we
can arrive at some conclusions. The lemma systems
outperform the nonlem for training corpora less than
</bodyText>
<footnote confidence="0.996248333333333">
4while the results was not confident by statistical signifi-
cance test, the medians of 300K and 400K were lowered by
the lemmatization
</footnote>
<page confidence="0.993912">
183
</page>
<table confidence="0.7970505">
0.241
0.232
0.223
0.214
</table>
<tableCaption confidence="0.907571">
Table 4: Effect of linear interpolation
</tableCaption>
<figure confidence="0.903709357142857">
lemma nonlemma interpolation
open track 0.1938 0.1993 0.2054
L-600K
NL-400K
L-400K
NL-300K
L-300K
BLEU
0.25
NL-600K
the three other features: phrase inverse probability,
lexical probability, and lexical inverse probability.
NL-100K We tested this integration using the open track of
L-100K
</figure>
<figureCaption confidence="0.575811666666667">
IWSLT 2006, a small task track. The BLEU scores
are shown in Table 4. An improvement over both of
the systems were observed.
</figureCaption>
<figure confidence="0.999514125">
0.205
0.196
0.187
0.178
0.169
0.16
1 2 3 4 5 6 7 8 9 10 11
Number of randomly extracted corpora
</figure>
<figureCaption confidence="0.999944">
Figure 1: Bleu scores for randomly extracted corpora
</figureCaption>
<bodyText confidence="0.9980278">
100 K. The BLEU score favors the lemma system
overwhelmingly for this size. When the amount of
training data is increased up to 600 K, the lemma
still beat the nonlem system in most tests while the
number of success by the nonlem system increases.
This random test, as a complement to the last ex-
periment, reveals that the lemma either performs the
same or better than the nonlem system for training
data of any size. Therefore, the lemma system is
slightly better than the nonlem in general.
Figure 1 illustrates the BLEU scores for the
“lemma(L)” and “nonlem(NL)” systems for ran-
domly extracted corpora. A higher number of points
is obtained by the lemma system than the nonlem for
each corpus.
</bodyText>
<sectionHeader confidence="0.821946" genericHeader="method">
4 Effect of linear interpolation of features
</sectionHeader>
<bodyText confidence="0.9999638">
We generated translation models for lemmatization
translation and non-lemmatization translation. We
found some features of the translation models could
be added linearly. For example, phrase translation
model p(e|f) can be calculated as,
</bodyText>
<equation confidence="0.990074">
p(e|f) = α1pl(e|f) + α2pnl(e|f)
</equation>
<bodyText confidence="0.999986625">
where pl(e|f) and pnl(e |f) is the phrase translation
models corresponding to the lemmatization system
and non-lemma system. α1 + α2 = 1. αs can be
obtained by maximizing likelihood or BLEU scores
of a development data. But we used the same val-
ues for all the α. p(e|f) is the phrase translation
model after linear interpolation. Besides the phrase
translation model, we used this approach to integrate
</bodyText>
<sectionHeader confidence="0.999721" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999931">
We proposed a new approach of using lemmatiza-
tion and linear interpolation of homologous features
in SMT. The principal idea is to use lemmatized En-
glish for the word alignment. Our approach was
proved effective for the BTEC Chinese to English
translation. It is significant in particular that we
have target language, English, as the lemmatized ob-
ject because it is less usual in SMT. Nevertheless,
we found our approach significantly improved word
alignment and qualities of translations.
</bodyText>
<sectionHeader confidence="0.999457" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999853954545455">
Sharon Goldwater and David McClosky. 2005. Im-
proving statistical MT through morphological analy-
sis. In Proceedings of HLT/EMNLP, pages 676–683,
Vancouver, British Columbia, Canada, October.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In HLT-NAACL
2003: Main Proceedings, pages 127–133.
Young-Suk Lee. 2004. Morphological analysis for statis-
tical machine translation. In HLT-NAACL 2004: Short
Papers, pages 57–60, Boston, Massachusetts, USA.
Guido Minnen, John Carroll, and Darren Pearce. 2001.
Applied morphological processing of english. Natural
Language Engineering, 7(3):207–223.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In ACL 2003, pages
160–167.
Michael Paul. 2006. Overview of the IWSLT 2006 Eval-
uation Campaign. In Proc. of the IWSLT, pages 1–15,
Kyoto, Japan.
</reference>
<page confidence="0.998705">
184
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.497012">
<title confidence="0.7523275">Boosting Statistical Machine Translation by Lemmatization and Linear Interpolation</title>
<affiliation confidence="0.990724">Institute of Information and Communications Technology Spoken Language Communication Research Laboratories</affiliation>
<address confidence="0.971415">2-2-2 Hikaridai, Seiika-cho, Soraku-gun, Kyoto, 619-0288, Japan</address>
<abstract confidence="0.997926684210526">Data sparseness is one of the factors that degrade statistical machine translation (SMT). Existing work has shown that using morphosyntactic information is an effective solution to data sparseness. However, fewer efforts have been made for Chinese-to-English SMT with using English morpho-syntactic analysis. We found that while English is a language with less inflection, using English lemmas in training can significantly improve the quality of word alignment that leads to yield better translation performance. We carried out comprehensive experiments on multiple training data of varied sizes to prove this. We also proposed a new effective linear interpolation method to integrate multiple homologous features of translation models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>David McClosky</author>
</authors>
<title>Improving statistical MT through morphological analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP,</booktitle>
<pages>676--683</pages>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="1851" citStr="Goldwater and McClosky, 2005" startWordPosition="267" endWordPosition="270">algorithms, one of which is the wellknown tool, GIZA++ (Och and Ney, 2003), for training IBM models (1-4). Morphological analysis (MA) is used in data preprocessing, by which the surface words of the raw data are converted into a new format. This new format can be lemmas, stems, parts-of-speech and morphemes or mixes of these. One benefit of using MA is to ease data sparseness that can reduce the translation quality significantly, especially for tasks with small amounts of training data. Some published work has shown that applying morphological analysis improved the quality of SMT (Lee, 2004; Goldwater and McClosky, 2005). We found that all this earlier work involved experiments conducted on translations from highly inflected languages, such as Czech, Arabic, and Spanish, to English. These researchers also provided detailed descriptions of the effects of foreign language morpho-syntactic analysis but presented no specific results to show the effect of English morphological analysis. To the best of our knowledge, there have been no papers related to English morphological analysis for Chinese-to-English (CE) translations even though the CE translation has been the main track for many evaluation campaigns includi</context>
</contexts>
<marker>Goldwater, McClosky, 2005</marker>
<rawString>Sharon Goldwater and David McClosky. 2005. Improving statistical MT through morphological analysis. In Proceedings of HLT/EMNLP, pages 676–683, Vancouver, British Columbia, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In HLT-NAACL 2003: Main Proceedings,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="5568" citStr="Koehn et al., 2003" startWordPosition="861" endWordPosition="864">ound the integrated after lemmatization. A 15%-20% reduction in vomodel improved all the components’ performance in cabulary is obtained by the lemmatization. The test the translation. data are the one used in IWSLT06 evaluation. It 2 Moses training for system with contains 500 Chinese sentences. The test data of lemmatization and without IWSLT05 are the development data for tuning the We used Moses to carry out the expriments. Moses weighting parameters. Multiple references are used is the state of the art decoder for SMT. It is an ex- for computing the automatic metrics. tension of Pharaoh (Koehn et al., 2003), and sup- 3 Experiments ports factor training and decoding. Our idea can 3.1 Regular test be easily implemented by Moses. We feed Moses The purpose of the regular tests is to find what efEnglish words with two factors: surface word and fect lemmatization has as the amount of training lemma. The only difference in training with lemma- data increases. We used the data from the IWSLT06 tization from that without is the alignment factor. CSTAR track. We started with 50,000 (50 K) of The former uses Chinese surface words and English data, and gradually added more training data from lemmas as the a</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In HLT-NAACL 2003: Main Proceedings, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
</authors>
<title>Morphological analysis for statistical machine translation.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Short Papers,</booktitle>
<pages>57--60</pages>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="1820" citStr="Lee, 2004" startWordPosition="265" endWordPosition="266"> alignment algorithms, one of which is the wellknown tool, GIZA++ (Och and Ney, 2003), for training IBM models (1-4). Morphological analysis (MA) is used in data preprocessing, by which the surface words of the raw data are converted into a new format. This new format can be lemmas, stems, parts-of-speech and morphemes or mixes of these. One benefit of using MA is to ease data sparseness that can reduce the translation quality significantly, especially for tasks with small amounts of training data. Some published work has shown that applying morphological analysis improved the quality of SMT (Lee, 2004; Goldwater and McClosky, 2005). We found that all this earlier work involved experiments conducted on translations from highly inflected languages, such as Czech, Arabic, and Spanish, to English. These researchers also provided detailed descriptions of the effects of foreign language morpho-syntactic analysis but presented no specific results to show the effect of English morphological analysis. To the best of our knowledge, there have been no papers related to English morphological analysis for Chinese-to-English (CE) translations even though the CE translation has been the main track for ma</context>
<context position="4158" citStr="Lee, 2004" startWordPosition="637" endWordPosition="638">ACL 2007 Demo and Poster Sessions, pages 181–184, Prague, June 2007. c�2007 Association for Computational Linguistics lation metrics to evaluate the results. We found that distance-based distortion model. The weighting paour approach of using lemmatization improved both rameters of these features were optimized in terms the word alignment and the quality of SMT with of BLEU by the approach of minimum error rate a small amounts of training data, and, while much training (Och, 2003). work indicates that MA is useless in training large The data for training and test are from the amounts of data (Lee, 2004), our intensive exper- IWSLT06 CSTAR track that uses the Basic Travel iments proved that the chance to get a better MT Expression Corpus (BTEC). The BTEC corpus are quality using lemmatization is higher than that with- relatively larger corpus for travel domain. We use out it for large amounts of training data. 678,748 Chinese/English parallel sentences as the On the basis of successful use of lemmatization training data in the experiments. The number of translation, we propose a new linear interpolation words are about 3.9M and 4.4M for Chinese and Enmethod by which we integrate the homologou</context>
</contexts>
<marker>Lee, 2004</marker>
<rawString>Young-Suk Lee. 2004. Morphological analysis for statistical machine translation. In HLT-NAACL 2004: Short Papers, pages 57–60, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Applied morphological processing of english.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="6780" citStr="Minnen et al., 2001" startWordPosition="1064" endWordPosition="1067">as the alignment factor, but the latter uses a 678 K corpus to this. We applied the methods Chinese surface words and English surface words. in Section 2 to train the non-lemmatized translation Therefore, the lemmatized English is only used in and lemmatized translation systems. The results are word alignment. All the other options of Moses are listed in Table 1. We use the alignment error rate same for both the lemmatization translation and non- (AER) to measure the alignment performance, and lemmatization translation. the two popular automatic metric, BLEU1 and MEWe use the tool created by (Minnen et al., 2001) to TEOR2 to evaluate the translations. To measure the complete the morphological analysis of English. We word alignment, we manually aligned 100 parallel had to make an English part-of-speech (POS) tag- sentences from the BTEC as the reference file. We ger that is compatible with the CLAWS-5 tagset to use the “sure” links and the “possible” links to deuse this tool. We use our in-house tagset and En- note the alignments. As shown in Table 1, we found glish tagged corpus to train a statistical POS tagger our approach improved word alignment uniformly by using the maximum entropy principle. Our</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2001. Applied morphological processing of english. Natural Language Engineering, 7(3):207–223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="1296" citStr="Och and Ney, 2003" startWordPosition="177" endWordPosition="180">hat while English is a language with less inflection, using English lemmas in training can significantly improve the quality of word alignment that leads to yield better translation performance. We carried out comprehensive experiments on multiple training data of varied sizes to prove this. We also proposed a new effective linear interpolation method to integrate multiple homologous features of translation models. 1 Introduction Raw parallel data need to be preprocessed in the modern phrase-based SMT before they are aligned by alignment algorithms, one of which is the wellknown tool, GIZA++ (Och and Ney, 2003), for training IBM models (1-4). Morphological analysis (MA) is used in data preprocessing, by which the surface words of the raw data are converted into a new format. This new format can be lemmas, stems, parts-of-speech and morphemes or mixes of these. One benefit of using MA is to ease data sparseness that can reduce the translation quality significantly, especially for tasks with small amounts of training data. Some published work has shown that applying morphological analysis improved the quality of SMT (Lee, 2004; Goldwater and McClosky, 2005). We found that all this earlier work involve</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL</booktitle>
<pages>160--167</pages>
<contexts>
<context position="4033" citStr="Och, 2003" startWordPosition="614" endWordPosition="615"> corpus of more than 678,000 sentences. We conducted comprehensive evaluations and used multiple trans181 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 181–184, Prague, June 2007. c�2007 Association for Computational Linguistics lation metrics to evaluate the results. We found that distance-based distortion model. The weighting paour approach of using lemmatization improved both rameters of these features were optimized in terms the word alignment and the quality of SMT with of BLEU by the approach of minimum error rate a small amounts of training data, and, while much training (Och, 2003). work indicates that MA is useless in training large The data for training and test are from the amounts of data (Lee, 2004), our intensive exper- IWSLT06 CSTAR track that uses the Basic Travel iments proved that the chance to get a better MT Expression Corpus (BTEC). The BTEC corpus are quality using lemmatization is higher than that with- relatively larger corpus for travel domain. We use out it for large amounts of training data. 678,748 Chinese/English parallel sentences as the On the basis of successful use of lemmatization training data in the experiments. The number of translation, we </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In ACL 2003, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Paul</author>
</authors>
<title>Overview of the IWSLT</title>
<date>2006</date>
<booktitle>In Proc. of the IWSLT,</booktitle>
<pages>1--15</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="3378" citStr="Paul, 2006" startWordPosition="512" endWordPosition="513">umption should not be takenfor-granted. We studied what effect English lemmatization had on CE translation. Lemmatization is shallow morphological analysis, which uses a lexical entry to replace inflected words. For example, the three words, doing, did and done, are replaced by one word, do. They are all mapped to the same Chinese translations. As a result, it eases the problem with sparse data, and retains word meanings unchanged. It is not impossible to improve word alignment by using English lemmatization. We determined what effect lemmatization had in experiments using data from the BTEC (Paul, 2006) CSTAR track. We collected a relatively large corpus of more than 678,000 sentences. We conducted comprehensive evaluations and used multiple trans181 Proceedings of the ACL 2007 Demo and Poster Sessions, pages 181–184, Prague, June 2007. c�2007 Association for Computational Linguistics lation metrics to evaluate the results. We found that distance-based distortion model. The weighting paour approach of using lemmatization improved both rameters of these features were optimized in terms the word alignment and the quality of SMT with of BLEU by the approach of minimum error rate a small amounts</context>
</contexts>
<marker>Paul, 2006</marker>
<rawString>Michael Paul. 2006. Overview of the IWSLT 2006 Evaluation Campaign. In Proc. of the IWSLT, pages 1–15, Kyoto, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>