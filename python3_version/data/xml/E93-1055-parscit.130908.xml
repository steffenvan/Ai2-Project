<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.182527">
<title confidence="0.968269">
Lexical Choice Criteria in Language Generation
</title>
<author confidence="0.996088">
Manfred Stede
</author>
<affiliation confidence="0.993344">
Department of Computer Science
University of Toronto
</affiliation>
<bodyText confidence="0.5955855">
Toronto M5S 1A4, Canada
mstedeacs.toronto.edu
</bodyText>
<sectionHeader confidence="0.994968" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999915053571429">
In natural language generation (NLG), a semantic
representation of some kind — possibly enriched with
pragmatic attributes — is successively transformed
into one or more linguistic utterances. No matter
what particular architecture is chosen to organize
this process, one of the crucial decisions to be made
is lexicalization: selecting words that adequately ex-
press the content that is to be communicated and,
if represented, the intentions and attitudes of the
speaker. Nirenburg and Nirenburg [1988] give this
example to illustrate the lexical choice problem: If
we want to express the meaning &amp;quot;a person whose
sex is male and whose age is between 13 and 15
years&amp;quot;, then candidate realizations include: boy, kid,
teenager, youth, child, young man, schoolboy, ado-
lescent, man. The criteria influencing such choices
remain largely in the dark, however.
As it happens, the problem of lexical choice has
not been a particularly popular one in NLG. For
instance, Marcus [1987] complained that most gen-
erators don&apos;t really choose words at all; McDonald
[1991], amongst others, lamented that lexical choice
has attracted only very little attention in the research
community. Implemented generators tend to provide
a one-to-one mapping from semantic units to lexical
items, and their producers occasionally acknowledge
this as a shortcoming (e.g., [Novak, 1991, p. 666]);
thereby the task of lexical choice becomes a non-
issue. For many applications, this is indeed a feasible
scheme, because the sub-language under considera-
tion can be sufficiently restricted such that a direct
mapping from content to words does not present a
drawback — the generator is implicitly tailored to-
wards the type of situation (or register) in which it
operates. But in general, with an eye on more ex-
pressive and versatile generators, this state of affairs
calls for improvement.
Why is lexical choice difficult? Unlike many other
decisions in generation (e.g., whether to express an
attribute of an object as a relative clause or an ad-
jective) the choice of a word very often carries impli-
catures that can change the overall message signifi-
cantly — if in some sentence the word boy is replaced
with one of the alternatives above, the meaning shifts
considerably. Also, often there are quite a few sim-
ilar lexical options available to a speaker, whereas
the number of possible syntactic sentence construc-
tions is more limited. To solve the choice problem,
first of all the differences between similar words have
to be represented in the lexicon, and the criteria for
choosing among them have to be established. In the
following, I give a tentative list of choice criteria,
classify them into constraints and preferences, and
outline a (partly implemented) model of lexicaliza-
tion that can be incorporated into language genera-
tors.
</bodyText>
<sectionHeader confidence="0.966594" genericHeader="method">
2 Word Choice Criteria
</sectionHeader>
<bodyText confidence="0.998937790697674">
Only few contributions have been made towards
establishing word choice criteria in NLG.1 Hovy&apos;s
[1988] generator PAULINE selected lexical items ac-
cording to pragmatic aspects of the situation (rhetor-
ical goals of the speaker giving rise to stylistic goals,
which in turn lead to certain lexical choices). Also
looking at the pragmatic level, Elhadad [1991] ex-
amined the influence of a speaker&apos;s argumentative
intent on the choice of adjectives. Wanner and Bate-
man [1990] viewed lexical choice from a situation-
dependent perspective: the various aspects of the
message to be expressed by the generator can have
different degrees of salience, which may give rise
to certain thematizations and also influence lexical
choice. Reiter [1990] demonstrated the importance
of basic-level categories (as used by Rosch [19781) for
generation, overriding the popular heuristic of always
choosing the most specific word available.
Generally speaking, the point of &amp;quot;interesting&amp;quot; lan-
guage generation (that is, more than merely map-
ping semantic elements one-to-one onto words) is to
tailor the output to the situation at hand, where &apos;sit-
uation&apos; is to be taken in the widest sense, including
the regional setting, the topic of the discourse, the
social relationships between discourse participants,
etc. There is, however, no straightforward one-to-
one mapping from linguistic features to the param-
eters that characterize a situation, as, for example,
stylisticians point out [Crystal and Davy, 1969]. Var-
ious levels of description are needed to account for
the complex relationships between the intentions of
the speaker and the variety of situational parameters,
which together determine the (higher-level) rhetori-
cal means for accomplishing the speaker&apos;s goal(s) and
then on lower levels their stylistic realizations.
Here we are interested in the descriptional level
of lexis: we want to identify linguistic features that
&apos;Considerable work has been done on the construc-
tion of referring expressions, but this is just one specific
sub-problem of lexical choice, and moreover a context-
sensitive one. In this paper, we restrict ourselves to
choice criteria that apply independently of the linguis-
tic context.
</bodyText>
<page confidence="0.998725">
454
</page>
<bodyText confidence="0.99983230952381">
serve as a basis for choosing a particular lexical item
from a set of synonyms. Not all these features are
equally interesting, however; as Crystal and Davy
[1969] noted, the relation between situational fea-
tures and linguistic features is on a scale from to-
tal predictability to considerable freedom of choice.
Among the less interesting dimensions are dialect
and genre (sub-languages pertaining to particular do-
mains, for example legal language or sports talk),
because they tend to merely fix a subset of the vo-
cabulary instead of allowing for variation: the fact
that what Americans call a lightning rod is a light-
ning conductor in British English does not imply a
meaningful (in particular, not a goal-directed) choice
for a speaker; one rarely switches to some dialect for
a particular purpose. More interesting is the degree
of semantic specificity of lexical items. An example
from Cruse [1986]: see is a general term for hav-
ing a visual experience, but there is a wide range
of more specific verbs that convey additional mean-
ing; for instance, watch is used when one pays atten-
tion to a changing or a potentially changing visual
stimulus, whereas look at implies that the stimulus is
static. Such subtle semantic distinctions demand a
fine-grained knowledge representation if a generator
is expected to make these choices [DiMarco et a/.,
1993].
An important factor in lexical choice are collo-
cational constraints stating that certain words can
co-occur whereas others cannot. For instance, we
find rancid butter, putrid fish, and addled eggs, but
no alternative combination, although the adjectives
mean very much the same thing.2 Collocations hold
among lexemes, as opposed to underlying semantic
concepts, and hence have to be represented as lexical
relations. They create the problem that individual
lexical choices for parts of the semantic representa-
tion may not be independent: roughly speaking, the
choice of word x for concept a can enforce the choice
of word y for concept b.
Finally, a highly influential, though not yet very
well-understood, factor in lexical choice is style.
</bodyText>
<sectionHeader confidence="0.965642" genericHeader="method">
3 Lexical Style
</sectionHeader>
<bodyText confidence="0.999575109589041">
The notion of style is most commonly associated with
literary theory, but that perspective is not suitable
for our purposes here. Style has also been inves-
tigated from a linguistic perspective (e.g., Sanders
[1973]), and recently a computational treatment has
been proposed by DiMarco and Hirst [1993]. What,
then, is style? Like Sanders, we view it broadly as
the choice between the various ways of expressing
the same message. Linguists interested in style, as,
for instance, Crystal and Davy [1969], have analyzed
the relationships between situational parameters (in
&apos;In NLG, collocation knowledge has been employed
by, inter alin, Smadja and McKeown [1991] and Iordan-
skaja, Kittredge and Polguere [1991].
particular, different genres) and stylistic choice, and
work in artificial intelligence has added the impor-
tant aspect of (indirectly) linking linguistic choices
to the intentions of a speaker [Hovy, 1988]. Clearly,
the difficult part of the definition given above is to
draw the line between message and style: what parts
of an utterance are to be attributed to its invariant
content, and what belongs to the chosen mode of
expressing that content?
In order to approach this question for the level
of lexis, hence to investigate lexical style, it helps
to turn the question &amp;quot;What criteria do we employ
for word choice?&amp;quot; around and to start by analyz-
ing what different words the language provides to
say roughly the same thing, for example with the
help of thesauri. By contrastively comparing simi-
lar words, their differences can be pinned down, and
appropriate features can be chosen to characterize
them. A second resource besides the thesaurus are
guidebooks on &amp;quot;how to write&amp;quot; (especially in foreign-
language teaching), which occasionally attempt to
explain differences between similar words or propose
categories of words with a certain &amp;quot;colour&amp;quot; (cf. [Di-
Marco et al., 1993]). One problem here is to deter-
mine when different suggested categories are in fact
the same (e.g., what one text calls a &apos;vivid&apos; word is
labelled &apos;concrete&apos; in another).
An investigation of lexical style should therefore
look for sufficiently general features: those that can
be found again and again when analyzing differ-
ent sets of synonymous words. It is important to
separate stylistic features from semantic ones, cf.
the choice criterion of semantic specificity mentioned
above. The whole range of phenomena that have
been labelled as associative meaning (or as one as-
pect under the even more fuzzy heading connotation)
has to be excluded from this search for features. For
example, the different overtones of the largely syn-
onymous words smile, grin (showing teeth), simper
(silly, affected), smirk (conceit, self-satisfaction) do
not qualify as recurring stylistic features. Similarly,
a sentence like Be a man, my son! alludes to aspects
of meaning that are clearly beyond the standard &apos;def-
inition&apos; of man (human being of male sex) but again
should not be classified as stylistic. And as a final
illustration, lexical style should not be put in charge
to explain the anomaly in The lady held a white lily
in her delicate fist, which from a &apos;purely&apos; semantic
viewpoint should be all right (with fist being defined
as closed hand).
Stylistic features can be isolated by carefully com-
paring words within a set of synonyms, from which a
generator is supposed to make a lexical choice. Once
a feature has been selected, the words can be ranked
on a corresponding numerical scale; the experiments
so far have shown that a range from 0 to 3 is sufficient
to represent the differences. Several features, how-
ever, have an &apos;opposite end&apos; and a neutral position
in the middle; here, the scale is —3...3.
</bodyText>
<page confidence="0.995569">
455
</page>
<bodyText confidence="0.999881235294118">
Ranking words is best being done by construct-
ing a &amp;quot;minimal&amp;quot; context for a paradigm of synonyms
so that the semantic influence exerted by the sur-
rounding words is as small as possible (e.g.: They
destroyed/annihilated/ruined/razed/. . . the building).
Words can hardly be compared with no context at
all — when informants are asked to rate words on a
particular scale, they typically respond with a ques-
tion like &amp;quot;In what sentence?&amp;quot; immediately. If, on the
other hand, the context is too specific, i.e., semanti-
cally loaded, it becomes more difficult to get access
to the inherent qualities of the particular word in
question.
These are the stylistic features that have been de-
termined by investigating various guides on good
writing and by analyzing a dozen synonym-sets that
were compiled from thesauri:
</bodyText>
<listItem confidence="0.980032">
• FORMALITY: —3...3
</listItem>
<bodyText confidence="0.9858525">
This is the only stylistic dimension that lin-
guists have thoroughly investigated and that is
well-known to dictionary users. Words can be
rated on a scale from &apos;very formal&apos; via &apos;collo-
quial&apos; to &apos;vulgar&apos; or something similar (e.g., mo-
tion picture-movie-flick).
</bodyText>
<listItem confidence="0.981738">
• EUPHEMISM: 0...3
</listItem>
<bodyText confidence="0.998630571428571">
The euphemism is used in order to avoid the
&amp;quot;real&amp;quot; word in certain social situations. They
are frequently found when the topic is strongly
connected to emotions (death, for example) or
social taboos (in a washroom, the indicated ac-
tivity is merely a secondary function of the in-
stallation).
</bodyText>
<listItem confidence="0.997145">
• SLANT: —3. . .3
</listItem>
<bodyText confidence="0.99905775">
A speaker can convey a high or low opinion
on the subject by using a slanted word: a
favourable or a pejorative one. Often this in-
volves metaphor: a word is used that in fact
denotes a different concept, for example when
an extremely disliked person is called a rat. But
the distinction can also be found within sets of
synonyms, e.g., gentleman vs. jerk.
</bodyText>
<listItem confidence="0.961705">
• ARCHAIC ...TRENDY: —3...3
</listItem>
<bodyText confidence="0.9997646">
The archaic word is sometimes called &apos;obsolete&apos;,
but it is not: old words can be exhumed on pur-
pose to achieve specific effects, for example by
calling the pharmacist apothecary. This stylis-
tic dimension holds not only for content words:
albeit is the archaic variant of even though. At
the opposite end is the trendy word that has
only recently been coined to denote some mod-
ern concept or to replace an existent word that
is worn out.
</bodyText>
<listItem confidence="0.978591">
• FLORIDITY: —3...3
</listItem>
<bodyText confidence="0.999767357142857">
This is one of the dimensions suggested by Hovy
[1988]. A more flowery expression for consider
is entertain the thought. At the opposite end
of the scale is the trite word. Floridity is occa-
sionally identified with high formality, but the
two should be distinguished: The flowery word
is used when the speaker wants to sound im-
pressively &amp;quot;bookish&amp;quot;, whereas the formal word
is &amp;quot;very correct&amp;quot;. Thus, the trite house can be
called habitation to add sophistication, but that
would not be merely &apos;formal&apos;. Another reason
for keeping the two distinct is the opposite end
of the scale: a non-flowery word is not the same
as a slang term.
</bodyText>
<listItem confidence="0.997998">
• ABSTRACTNESS: —3... 3
</listItem>
<bodyText confidence="0.999508272727273">
Writing-guidebooks often recommend to replace
the abstract with the concrete word that evokes
a more vivid mental image in the hearer. But
what most examples found in the literature re-
ally do is to recommend semantically more spe-
cific words (e.g., replace to fly with to float or
to glide), which add traits of meaning and are
therefore not always interchangeable; thus the
choice is not merely stylistic. A more suitable
example is to characterize an unemployed person
(abstract) as out of work (concrete).
</bodyText>
<listItem confidence="0.991404">
• FORCE: 0...3
</listItem>
<bodyText confidence="0.975306137931034">
Some words are more forceful, or &amp;quot;stronger&amp;quot;
than others, for instance destroy vs. annihilate,
or big vs. monstrous.
There is an interesting relationship (that should
be investigated more thoroughly) between these fea-
tures and the notion of core vocabulary as it is known
in applied linguistics. Carter [1987] characterizes
core words as having the following properties: they
often have clear antonyms (big—small); they have a
wide collocational range (fat cheque, fat salary but
*corpulent cheque, *chubby salary); they often serve
to define other words in the same lexical set (to beam
= to smile happily, to smirk = to smile knowingly);
they do not indicate the genre of discourse to which
they belong; they do not carry marked connotations
or associations. This last criterion, the connotational
neutrality of core words could be measured using
our stylistic features, with the hypothesis being that
core words tend to assume the value 0 on the scales.
However, the coreness of a word is not only a mat-
ter of style, but also of semantic specificity: Carter
notes that they are often superordinates, and this
is also the reason for their role in defining similar
words, which are, of course, semantically more spe-
cific. It seems that the notion of core words corre-
sponds with basic-level categories, which have been
employed in NLG by Reiter [1990], but which had
originated not in linguistics but in cognitive psychol-
ogy [Rosch, 19781.
</bodyText>
<sectionHeader confidence="0.979438" genericHeader="method">
4 Towards a Model for Lexicalization
</sectionHeader>
<bodyText confidence="0.999563">
When the input to the generator is some sort of a
semantic net (and possibly additional pragmatic pa-
rameters), lexical items are sought that express all
the parts of that net and that can be combined into a
grammatical sentence. The hard constraint on which
</bodyText>
<page confidence="0.998256">
456
</page>
<bodyText confidence="0.999990520833334">
(content) words can participate in the sentence is
that they have the right meaning, i.e., they correctly
express some aspect of the semantic specification.
The second constraint is that collocations are not to
be violated, to avoid the production of a phrase like
addled butter. The other factors mentioned above en-
ter the game as preferences, because their complete
achievement cannot be guaranteed — if we want to
speak &apos;formally&apos;, we can try to find particularly for-
mal words for the concepts to be expressed; but if
the dictionary does not offer any, we have to be con-
tent with more &apos;standard&apos; words, at least for some of
the concepts underlying the sentence. We can max-
imize the achievement of lexical-stylistic goals, but
not strive to fully achieve them.
To arrive at this kind of elaborate lexical choice, I
first employ a lexical option finder (following ideas
by Miezitis [19881) that scans the input semantic
net and produces all the lexical items that are se-
mantically (or truth-conditionally) appropriate for
expressing parts of the net. If the set of options con-
tains more than one item for the same sub-net, these
items can differ either semantically (be more or less
specific) or connotationally (have different stylistic
features associated with them).
The second task is to choose from this pool a set
of lexical items that together express the complete
net, respect collocational constraints (if any are in-
volved), and are maximal under a preference func-
tion that determines the degree of appropriateness
of items in terms of their stylistic and other conno-
tational features. Finally, the choice process has to
be integrated with the other decisions to be made in
generation (sentence scope and structure, theme con-
trol, use of conjunctions and cue words, etc.), such
that syntactic constraints are respected.
Two parts of the overall system have been realized
so far. First, a lexical option finder was built with
LOOM, a KL-ONE dialect. Lexical items correspond
to configurations of concepts and roles (not just to
single concepts, as it is usually done in generation),
and the option finder determines the set of all items
that can cover a part of the input proposition (repre-
sented as LOOM instances). Using inheritance, the
most specific as well as the appropriate more general
items are retrieved (e.g., if the event in the proposi-
tion is darning a sock, the items darn, mend, fix are
produced for expressing the action).
</bodyText>
<sectionHeader confidence="0.996451" genericHeader="method">
5 Stylistic Lexical Choice in
PENMAN
</sectionHeader>
<bodyText confidence="0.99997114893617">
At the &apos;front end&apos; of the overall system, a lexical
choice process based on the stylistic features listed
in section 3 has been implemented using the PEN-
MAN sentence generator [Penman-Group, 19891.
Its systemic-functional grammar has been extended
with systems that determine the desired stylistic
&amp;quot;colour&amp;quot; and, with the help of a distance metric (see
below), determine the most appropriate lexical items
that fit the target specification.
Figure 1 shows a sample run of the system, where
the :lexstyle keyword is in charge of the variation;
its filler (here, slang or newspaper) is being trans-
lated into a configuration of values for the stylistic
features. This is handled by the standard mech-
anism in PENMAN that associates keyword-fillers
with answers to inquiries posed by the grammatical
systems. In the example, the keyword governs the
selection from the synonym-sets for evict, destroy,
and building (stored in Penman&apos;s lexicon with their
stylistic features). The chosen transformation of the
:lexstyle filler into feature values is merely a first
step towards providing a link from low-level features
to more abstract parameters; a thorough specifica-
tion of these parameters and their correspondence
with lexical features has not been done yet.
More specifically, for every stylistic dimension one
system is in charge to determine its numeric target
value (on the scale —3 to 3). Therefore, the par-
ticular :lexstyle filler translates into a set of fea-
ture/value pairs. When all the value-inquiries have
been made, the subsequent system in the grammar
looks up the words associated with the concept to be
expressed and determines the one that best matches
the desired feature/value-specification. For every
word, the distance metric adds the squares of the
differences between the target feature value (tf ) and
the value found in the lexical entry (wf ) for each of
the n features: an._1(tfi — wfi )2
The fine-tuning of the distance-metric is subject to
experimentation; in the version shown, the motiva-
tion for taking the square of the difference is to, for
example, favour a word that differs in two dimen-
sions by one point over another one that differs in
one dimension by two points (they would otherwise
be equivalent). The word with the lowest total dif-
ference is chosen; in case of conflict, a random choice
is made.
</bodyText>
<sectionHeader confidence="0.97882" genericHeader="conclusions">
6 Summary and Future Work
</sectionHeader>
<bodyText confidence="0.999937764705883">
An important task in language generation is to
choose the words that most adequately fit into the ut-
terance situation and serve to express the intentions
of the speaker. I have listed a number of criteria for
lexical choice and then explored stylistic dimensions
in more detail: Arguing in favour of a &apos;data-driven&apos;
approach, sets of synonyms have been extracted from
thesauri and dictionaries; comparing them led to a
proposed set of features that can discriminate syn-
onyms on stylistic grounds. The features chosen in
the implementation have been selected solely on the
basis of the author&apos;s intuitions (albeit using a sys-
tematic method) — clearly, these findings have to be
validated through psychological experiments (asking
subjects to compare words and rate them on appro-
priate scales). Also, it needs to be explored in more
detail whether different parts of speech should be
</bodyText>
<page confidence="0.991386">
457
</page>
<figure confidence="0.76341725">
(say-spl 1(rr / rst-sequence
:domain (d / EVICT :actor (p / PERSON :name tom)
:actee (t / TENANT :determiner the :number plural)
:tense past :lexstyle slang)
:range (e / DESTROY :actor p
:actee (b / BUILDING :determiner the)
:tense past :lexstyle slang)))
&amp;quot;Tom threw the tenants out, then he pulverized the shed.&amp;quot;
(say-spl (rr / rst-sequence
&lt; same as above &gt;
:tense past :lexstyle newspaper)))
&amp;quot;Tom evicted the tenants, then he tore the building down.&amp;quot;
</figure>
<figureCaption confidence="0.99957">
Figure 1: Sample run of style-enhanced PENMAN
</figureCaption>
<bodyText confidence="0.999783064516129">
characterized by different feature sets.
An overall model of lexicalization in the generation
process has been sketched that first determines all
candidate lexical items for expressing parts of a mes-
sage (including all synonyms and less-specific items),
and a preferential choice process is supposed to make
the selections. The front-end of this system has been
implemented by extending the PENMAN sentence
generator so that it can choose words on the basis of
a distance function that compares the feature/value
pairs of lexical entries (of synonyms) with a target
specification. This target specification has so far only
been postulated as corresponding to various stereo-
typical genres, the name of which is a part of the
input specification to PENMAN. In future work, the
stylistic features need to be linked more systemati-
cally to rhetorical goals of the speaker and to param-
eters characterizing the utterance situation. One of
the tasks here is to determine which features should
be valid for the whole text to be generated (e.g., for-
mality), or only for single sentences, or only for single
constituents (e.g., slant).
Besides, ultimately the work on lexical style has
to be integrated with efforts on syntactic style [Di-
Marco and Hirst, 1993]. Other criteria for lexical
choice, like those mentioned in section two, have to
be incorporated into the choice process. And finally,
it has to be examined how lexical decisions interact
with the other decisions to be made in the gener-
ation process (sentence scope and structure, theme
control, use of conjunctions and cue words, etc.).
</bodyText>
<sectionHeader confidence="0.996514" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998066">
Financial support from the Natural Sciences and En-
gineering Research Council of Canada and the Infor-
mation Technology Research Centre of Ontario is ac-
knowledged. Part of the work reported in this paper
originated during a visit to the Information Sciences
Institute (ISI) at the University of Southern Califor-
nia; thanks to Eduard Hovy for hospitality and in-
spiration. For helpful comments on earlier versions
of this paper, I thank Graeme Hirst and two anony-
mous reviewers.
</bodyText>
<sectionHeader confidence="0.998945" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999779285714286">
[Carter, 19871 Ronald Carter. Vocabulary: Applied
Linguistic Perspectives. Allen &amp; Unwin, London,
1987.
[Cruse, 1986] D. Alan Cruse. Lexical Semantics.
Cambridge University Press, 1986.
[Crystal and Davy, 19691 David Crystal and Derek
Davy. Investigating English Style. Edward Arnold,
London, 1969.
[DiMarco and Hirst, 1993] Chrysanne DiMarco and
Graeme Hirst. A Computational Theory of Goal-
Directed Style in Syntax. Computational Linguis-
tics, 19(??), 1993. Forthcoming.
[DiMarco et al., 1993] Chrysanne DiMarco, Graeme
Hirst, and Manfred Stede. The Semantic and
Stylistic Differentiation of Synonyms and Near-
Synonyms. In Working Notes of the AAAI Spring
Symposium on Building Lexicons for Machine
Translation. Stanford University, 1993. Forthcom-
ing.
[Elhadad, 1991] Michael Elhadad. Generating Ad-
jectives to Express the Speaker&apos;s Argumentative
Intent. In Proceedings of the Fifth National Con-
ference on Artificial Intelligence (AAAI-91), pages
98-104, 1991.
[Hovy, 1988] Eduard H. Hovy. Generating Natural
Language Under Pragmatic Constraints. Lawrence
Erlbaum, Hillsdale, NJ, 1988.
[Iordanskaja et al., 1991]
Lidija Iordanskaja, Richard Kittredge, and Alain
Polguere. Lexical Selection and Paraphrase in a
Meaning-Text Generation Model. In C. L. Paris,
W. R. Swartout, and W. C. Mann, editors, Natu-
ral Language Generation in Artificial Intelligence
and Computational Linguistics, chapter 11, pages
293-312. Kluwer, Dordrecht, 1991.
</reference>
<page confidence="0.982932">
458
</page>
<reference confidence="0.999612">
[Marcus, 1987] Mitchell Marcus. Generation Sys-
tems Should Choose Their Words. In Yorick
Wilks, editor, Theoretical Issues in Natural Lan-
guage Processing, pages 211-214. New Mexico
State University, Las Cruces, 1987.
[McDonald, 1991] David D. McDonald. On the
Place of Words in the Generation Process. In C. L.
Paris, W. R. Swartout, and W. C. Mann, editors,
Natural Language Generation in Artificial Intelli-
gence and Computational Linguistics, pages 227-
248. Kluwer, Dordrecht, 1991.
[Miezitis, 1988] Mara Anita Miezitis. Generating
Lexical Options by Matching in a Knowledge
Base. Technical Report CSRI-217, University of
Toronto, 1988.
[Nirenburg and Nirenburg, 1988] Sergei Nirenburg
and Irene Nirenburg. A Framework for Lexical Se-
lection in Natural Language Generation. In Pro-
ceedings of the 12th International Conference on
Computational Linguistics (COLING-88), pages
471-475, Budapest, 1988.
[Novak, 1991] Hans-Joachim Novak. Integrating a
Generation Component into a Natural Language
Understanding System. In 0. Herzog and C. R.
Rollinger, editors, Tezt Understanding in LILOG,
pages 659-669. Springer, Berlin/Heidelberg, 1991.
[Penman-Group, 1989] Penman-Group. The Pen-
man Documentation. Unpublished documentation
for the Penman system, 1989.
[Reiter, 1990] Ehud Reiter. Generating Descriptions
that Exploit a User&apos;s Domain Knowledge. In
It. Dale, C. Mellish, and M. Zock, editors, Current
Research in Natural Language Generation. Aca-
demic Press, 1990.
[Roach, 1978] Eleanor Rosch. Principles of Catego-
rization. In E. Rosch and B. Lloyd, editors, Cogni-
tion and Categorization. Lawrence Erlbaum, Hills-
dale, NJ, 1978.
[Sanders, 1973] Willy Sanders. Linguistische Stilthe-
orie. Vandenhoeck Sz Ruprecht, GOttingen, 1973.
[Smadja and McKeown, 1991] Frank Smadja and
Kathleen R. McKeown. Using Collocations for
Language Generation. Computational Intelligence,
7:229-239,1991.
[Wanner and Bateman, 1990]
Leo Wanner and John A. Bateman. A Colloca-
tional Based Approach to Salience-Sensitive Lex-
ical Selection. In Proceedings of the Fifth Inter-
national Natural Language Generation Workshop,
pages 31-38, Dawson, PA, 1990.
</reference>
<page confidence="0.999114">
459
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.985069">
<title confidence="0.999877">Lexical Choice Criteria in Language Generation</title>
<author confidence="0.99971">Manfred Stede</author>
<affiliation confidence="0.9999765">Department of Computer Science University of Toronto</affiliation>
<address confidence="0.989566">Toronto M5S 1A4, Canada</address>
<email confidence="0.995833">mstedeacs.toronto.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Vocabulary: Applied Linguistic Perspectives.</title>
<date>1987</date>
<publisher>Allen &amp; Unwin,</publisher>
<location>London,</location>
<contexts>
<context position="1148" citStr="[1987]" startWordPosition="174" endWordPosition="174">the content that is to be communicated and, if represented, the intentions and attitudes of the speaker. Nirenburg and Nirenburg [1988] give this example to illustrate the lexical choice problem: If we want to express the meaning &amp;quot;a person whose sex is male and whose age is between 13 and 15 years&amp;quot;, then candidate realizations include: boy, kid, teenager, youth, child, young man, schoolboy, adolescent, man. The criteria influencing such choices remain largely in the dark, however. As it happens, the problem of lexical choice has not been a particularly popular one in NLG. For instance, Marcus [1987] complained that most generators don&apos;t really choose words at all; McDonald [1991], amongst others, lamented that lexical choice has attracted only very little attention in the research community. Implemented generators tend to provide a one-to-one mapping from semantic units to lexical items, and their producers occasionally acknowledge this as a shortcoming (e.g., [Novak, 1991, p. 666]); thereby the task of lexical choice becomes a nonissue. For many applications, this is indeed a feasible scheme, because the sub-language under consideration can be sufficiently restricted such that a direct </context>
<context position="14748" citStr="[1987]" startWordPosition="2383" endWordPosition="2383"> specific words (e.g., replace to fly with to float or to glide), which add traits of meaning and are therefore not always interchangeable; thus the choice is not merely stylistic. A more suitable example is to characterize an unemployed person (abstract) as out of work (concrete). • FORCE: 0...3 Some words are more forceful, or &amp;quot;stronger&amp;quot; than others, for instance destroy vs. annihilate, or big vs. monstrous. There is an interesting relationship (that should be investigated more thoroughly) between these features and the notion of core vocabulary as it is known in applied linguistics. Carter [1987] characterizes core words as having the following properties: they often have clear antonyms (big—small); they have a wide collocational range (fat cheque, fat salary but *corpulent cheque, *chubby salary); they often serve to define other words in the same lexical set (to beam = to smile happily, to smirk = to smile knowingly); they do not indicate the genre of discourse to which they belong; they do not carry marked connotations or associations. This last criterion, the connotational neutrality of core words could be measured using our stylistic features, with the hypothesis being that core </context>
</contexts>
<marker>1987</marker>
<rawString> [Carter, 19871 Ronald Carter. Vocabulary: Applied Linguistic Perspectives. Allen &amp; Unwin, London, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Alan Cruse</author>
</authors>
<title>Lexical Semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press,</publisher>
<location>London,</location>
<marker>[Cruse, 1986]</marker>
<rawString>D. Alan Cruse. Lexical Semantics. Cambridge University Press, 1986. [Crystal and Davy, 19691 David Crystal and Derek Davy. Investigating English Style. Edward Arnold, London, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chrysanne DiMarco</author>
<author>Graeme Hirst</author>
</authors>
<date>1993</date>
<journal>A Computational Theory of GoalDirected Style in Syntax. Computational Linguistics,</journal>
<volume>19</volume>
<publisher>Forthcoming.</publisher>
<marker>[DiMarco and Hirst, 1993]</marker>
<rawString>Chrysanne DiMarco and Graeme Hirst. A Computational Theory of GoalDirected Style in Syntax. Computational Linguistics, 19(??), 1993. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chrysanne DiMarco</author>
<author>Graeme Hirst</author>
<author>Manfred Stede</author>
</authors>
<title>The Semantic and Stylistic Differentiation of Synonyms and NearSynonyms.</title>
<date>1993</date>
<booktitle>In Working Notes of the AAAI Spring Symposium on Building Lexicons for Machine</booktitle>
<publisher>Forthcoming.</publisher>
<institution>Translation. Stanford University,</institution>
<marker>[DiMarco et al., 1993]</marker>
<rawString>Chrysanne DiMarco, Graeme Hirst, and Manfred Stede. The Semantic and Stylistic Differentiation of Synonyms and NearSynonyms. In Working Notes of the AAAI Spring Symposium on Building Lexicons for Machine Translation. Stanford University, 1993. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
</authors>
<title>Generating Adjectives to Express the Speaker&apos;s Argumentative Intent.</title>
<date>1991</date>
<booktitle>In Proceedings of the Fifth National Conference on Artificial Intelligence (AAAI-91),</booktitle>
<pages>98--104</pages>
<marker>[Elhadad, 1991]</marker>
<rawString>Michael Elhadad. Generating Adjectives to Express the Speaker&apos;s Argumentative Intent. In Proceedings of the Fifth National Conference on Artificial Intelligence (AAAI-91), pages 98-104, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
</authors>
<title>Generating Natural Language Under Pragmatic Constraints. Lawrence Erlbaum,</title>
<date>1988</date>
<location>Hillsdale, NJ,</location>
<marker>[Hovy, 1988]</marker>
<rawString>Eduard H. Hovy. Generating Natural Language Under Pragmatic Constraints. Lawrence Erlbaum, Hillsdale, NJ, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lidija Iordanskaja</author>
<author>Richard Kittredge</author>
<author>Alain Polguere</author>
</authors>
<title>Lexical Selection and Paraphrase in a Meaning-Text Generation Model.</title>
<date>1991</date>
<booktitle>Natural Language Generation in Artificial Intelligence and Computational Linguistics, chapter 11,</booktitle>
<pages>293--312</pages>
<editor>In C. L. Paris, W. R. Swartout, and W. C. Mann, editors,</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht,</location>
<marker>[Iordanskaja et al., 1991]</marker>
<rawString> Lidija Iordanskaja, Richard Kittredge, and Alain Polguere. Lexical Selection and Paraphrase in a Meaning-Text Generation Model. In C. L. Paris, W. R. Swartout, and W. C. Mann, editors, Natural Language Generation in Artificial Intelligence and Computational Linguistics, chapter 11, pages 293-312. Kluwer, Dordrecht, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
</authors>
<title>Generation Systems Should Choose Their Words.</title>
<date>1987</date>
<booktitle>Theoretical Issues in Natural Language Processing,</booktitle>
<pages>211--214</pages>
<editor>In Yorick Wilks, editor,</editor>
<institution>New Mexico State University, Las Cruces,</institution>
<marker>[Marcus, 1987]</marker>
<rawString>Mitchell Marcus. Generation Systems Should Choose Their Words. In Yorick Wilks, editor, Theoretical Issues in Natural Language Processing, pages 211-214. New Mexico State University, Las Cruces, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D McDonald</author>
</authors>
<title>On the Place of Words in the Generation Process. In</title>
<date>1991</date>
<booktitle>Natural Language Generation in Artificial Intelligence and Computational Linguistics,</booktitle>
<pages>227--248</pages>
<editor>C. L. Paris, W. R. Swartout, and W. C. Mann, editors,</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht,</location>
<marker>[McDonald, 1991]</marker>
<rawString>David D. McDonald. On the Place of Words in the Generation Process. In C. L. Paris, W. R. Swartout, and W. C. Mann, editors, Natural Language Generation in Artificial Intelligence and Computational Linguistics, pages 227-248. Kluwer, Dordrecht, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mara Anita</author>
</authors>
<title>Miezitis. Generating Lexical Options by Matching in a Knowledge Base.</title>
<date>1988</date>
<tech>Technical Report CSRI-217,</tech>
<institution>University of Toronto,</institution>
<marker>[Miezitis, 1988]</marker>
<rawString>Mara Anita Miezitis. Generating Lexical Options by Matching in a Knowledge Base. Technical Report CSRI-217, University of Toronto, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
<author>Irene Nirenburg</author>
</authors>
<title>A Framework for Lexical Selection in Natural Language Generation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics (COLING-88),</booktitle>
<pages>471--475</pages>
<location>Budapest,</location>
<marker>[Nirenburg and Nirenburg, 1988]</marker>
<rawString>Sergei Nirenburg and Irene Nirenburg. A Framework for Lexical Selection in Natural Language Generation. In Proceedings of the 12th International Conference on Computational Linguistics (COLING-88), pages 471-475, Budapest, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Joachim Novak</author>
</authors>
<title>Integrating a Generation Component into a Natural Language Understanding System. In 0. Herzog</title>
<date>1991</date>
<booktitle>Tezt Understanding in LILOG,</booktitle>
<pages>659--669</pages>
<editor>and C. R. Rollinger, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin/Heidelberg,</location>
<marker>[Novak, 1991]</marker>
<rawString>Hans-Joachim Novak. Integrating a Generation Component into a Natural Language Understanding System. In 0. Herzog and C. R. Rollinger, editors, Tezt Understanding in LILOG, pages 659-669. Springer, Berlin/Heidelberg, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Penman-Group</author>
</authors>
<title>The Penman Documentation. Unpublished documentation for the Penman system,</title>
<date>1989</date>
<marker>[Penman-Group, 1989]</marker>
<rawString>Penman-Group. The Penman Documentation. Unpublished documentation for the Penman system, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>Generating Descriptions that Exploit a User&apos;s Domain Knowledge.</title>
<date>1990</date>
<booktitle>Current Research in Natural Language Generation.</booktitle>
<editor>In It. Dale, C. Mellish, and M. Zock, editors,</editor>
<publisher>Academic Press,</publisher>
<marker>[Reiter, 1990]</marker>
<rawString>Ehud Reiter. Generating Descriptions that Exploit a User&apos;s Domain Knowledge. In It. Dale, C. Mellish, and M. Zock, editors, Current Research in Natural Language Generation. Academic Press, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleanor Rosch</author>
</authors>
<title>Principles of Categorization. In</title>
<date>1978</date>
<booktitle>Cognition and Categorization. Lawrence Erlbaum,</booktitle>
<editor>E. Rosch and B. Lloyd, editors,</editor>
<location>Hillsdale, NJ,</location>
<marker>[Roach, 1978]</marker>
<rawString>Eleanor Rosch. Principles of Categorization. In E. Rosch and B. Lloyd, editors, Cognition and Categorization. Lawrence Erlbaum, Hillsdale, NJ, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willy Sanders</author>
</authors>
<title>Linguistische Stiltheorie. Vandenhoeck Sz Ruprecht, GOttingen,</title>
<date>1973</date>
<marker>[Sanders, 1973]</marker>
<rawString>Willy Sanders. Linguistische Stiltheorie. Vandenhoeck Sz Ruprecht, GOttingen, 1973.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Frank Smadja</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Using Collocations for Language Generation.</title>
<journal>Computational Intelligence,</journal>
<pages>7--229</pages>
<marker>[Smadja and McKeown, 1991]</marker>
<rawString>Frank Smadja and Kathleen R. McKeown. Using Collocations for Language Generation. Computational Intelligence, 7:229-239,1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Wanner</author>
<author>John A Bateman</author>
</authors>
<title>A Collocational Based Approach to Salience-Sensitive Lexical Selection.</title>
<date>1990</date>
<booktitle>In Proceedings of the Fifth International Natural Language Generation Workshop,</booktitle>
<pages>31--38</pages>
<location>Dawson, PA,</location>
<marker>[Wanner and Bateman, 1990]</marker>
<rawString> Leo Wanner and John A. Bateman. A Collocational Based Approach to Salience-Sensitive Lexical Selection. In Proceedings of the Fifth International Natural Language Generation Workshop, pages 31-38, Dawson, PA, 1990.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>