<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.998372">
In-domain Relation Discovery with Meta-constraints
via Posterior Regularization
</title>
<author confidence="0.998353">
Harr Chen, Edward Benson, Tahira Naseem, and Regina Barzilay
</author>
<affiliation confidence="0.9987505">
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<email confidence="0.988812">
{harr, eob, tahira, regina} @csail.mit.edu
</email>
<sectionHeader confidence="0.995514" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999938809523809">
We present a novel approach to discovering re-
lations and their instantiations from a collec-
tion of documents in a single domain. Our
approach learns relation types by exploiting
meta-constraints that characterize the general
qualities of a good relation in any domain.
These constraints state that instances of a
single relation should exhibit regularities at
multiple levels of linguistic structure, includ-
ing lexicography, syntax, and document-level
context. We capture these regularities via the
structure of our probabilistic model as well
as a set of declaratively-specified constraints
enforced during posterior inference. Across
two domains our approach successfully recov-
ers hidden relation structure, comparable to
or outperforming previous state-of-the-art ap-
proaches. Furthermore, we find that a small
set of constraints is applicable across the do-
mains, and that using domain-specific con-
straints can further improve performance. 1
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99972425">
In this paper, we introduce a novel approach for the
unsupervised learning of relations and their instan-
tiations from a set of in-domain documents. Given
a collection of news articles about earthquakes, for
example, our method discovers relations such as the
earthquake’s location and resulting damage, and ex-
tracts phrases representing the relations’ instantia-
tions. Clusters of similar in-domain documents are
</bodyText>
<footnote confidence="0.9988445">
1The source code for this work is available at:
http://groups.csail.mit.edu/rbg/code/relation extraction/
</footnote>
<bodyText confidence="0.908594625">
A strong earthquake rocked the Philippine island of Min-
doro early Tuesday, [destroying]ind [some homes]arg ...
A strong earthquake hit the China-Burma border early
Wednesday ... The official Xinhua News Agency said
[some houses]arg were [damaged]ind ...
A strong earthquake with a preliminary magnitude of 6.6
shook northwestern Greece on Saturday, ... [destroying]ind
[hundreds of old houses]arg ...
</bodyText>
<figureCaption confidence="0.996029333333333">
Figure 1: Excerpts from newswire articles about earth-
quakes. The indicator and argument words for the dam-
age relation are highlighted.
</figureCaption>
<bodyText confidence="0.999881391304348">
increasingly available in forms such as Wikipedia ar-
ticle categories, financial reports, and biographies.
In contrast to previous work, our approach learns
from domain-independent meta-constraints on rela-
tion expression, rather than supervision specific to
particular relations and their instances. In particular,
we leverage the linguistic intuition that documents
in a single domain exhibit regularities in how they
express their relations. These regularities occur both
in the relations’ lexical and syntactic realizations as
well as at the level of document structure. For in-
stance, consider the damage relation excerpted from
earthquake articles in Figure 1. Lexically, we ob-
serve similar words in the instances and their con-
texts, such as “destroying” and “houses.” Syntacti-
cally, in two instances the relation instantiation is the
dependency child of the word “destroying.” On the
discourse level, these instances appear toward the
beginning of their respective documents. In general,
valid relations in many domains are characterized by
these coherence properties.
We capture these regularities using a Bayesian
model where the underlying relations are repre-
</bodyText>
<page confidence="0.951478">
530
</page>
<note confidence="0.9793145">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 530–540,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999942291666667">
sented as latent variables. The model takes as in-
put a constituent-parsed corpus and explains how the
constituents arise from the latent variables. Each re-
lation instantiation is encoded by the variables as
a relation-evoking indicator word (e.g., “destroy-
ing”) and corresponding argument constituent (e.g.,
“some homes”).2 Our approach capitalizes on rela-
tion regularity in two ways. First, the model’s gen-
erative process encourages coherence in the local
features and placement of relation instances. Sec-
ond, we apply posterior regularization (Grac¸a et
al., 2007) during inference to enforce higher-level
declarative constraints, such as requiring indicators
and arguments to be syntactically linked.
We evaluate our approach on two domains pre-
viously studied for high-level document structure
analysis, news articles about earthquakes and finan-
cial markets. Our results demonstrate that we can
successfully identify domain-relevant relations. We
also study the importance and effectiveness of the
declaratively-specified constraints. In particular, we
find that a small set of declarative constraints are
effective across domains, while additional domain-
specific constraints yield further benefits.
</bodyText>
<sectionHeader confidence="0.999771" genericHeader="introduction">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.521593">
Extraction with Reduced Supervision Recent
</subsectionHeader>
<bodyText confidence="0.999806235294118">
research in information extraction has taken large
steps toward reducing the need for labeled data. Ex-
amples include using bootstrapping to amplify small
seed sets of example outputs (Agichtein and Gra-
vano, 2000; Yangarber et al., 2000; Bunescu and
Mooney, 2007; Zhu et al., 2009), leveraging ex-
isting databases that overlap with the text (Mintz
et al., 2009; Yao et al., 2010), and learning gen-
eral domain-independent knowledge bases by ex-
ploiting redundancies in large web and news cor-
pora (Hasegawa et al., 2004; Shinyama and Sekine,
2006; Banko et al., 2007; Yates and Etzioni, 2009).
Our approach is distinct in both the supervision
and data we operate over. First, in contrast to boot-
strapping and database matching approaches, we
learn from meta-qualities, such as low variability in
syntactic patterns, that characterize a good relation.
</bodyText>
<tableCaption confidence="0.472648666666667">
2We do not use the word “argument” in the syntactic sense—
a relation’s argument may or may not be the syntactic depen-
dency argument of its indicator.
</tableCaption>
<bodyText confidence="0.999950897435898">
We hypothesize that these properties hold across re-
lations in different domains. Second, in contrast to
work that builds general relation databases from het-
erogeneous corpora, our focus is on learning the re-
lations salient in a single domain. Our setup is more
germane to specialized domains expressing informa-
tion not broadly available on the web.
Earlier work in unsupervised information extrac-
tion has also leveraged meta-knowledge indepen-
dent of specific relation types, such as declaratively-
specified syntactic patterns (Riloff, 1996), frequent
dependency subtree patterns (Sudo et al., 2003), and
automatic clusterings of syntactic patterns (Lin and
Pantel, 2001; Zhang et al., 2005) and contexts (Chen
et al., 2005; Rosenfeld and Feldman, 2007). Our ap-
proach incorporates a broader range of constraints
and balances constraints with underlying patterns
learned from the data, thereby requiring more so-
phisticated machinery for modeling and inference.
Extraction with Constraints Previous work has
recognized the appeal of applying declarative con-
straints to extraction. In a supervised setting, Roth
and Yih (2004) induce relations by using linear pro-
gramming to impose global declarative constraints
on the output from a set of classifiers trained on lo-
cal features. Chang et al. (2007) propose an objec-
tive function for semi-supervised extraction that bal-
ances likelihood of labeled instances and constraint
violation on unlabeled instances. Recent work has
also explored how certain kinds of supervision can
be formulated as constraints on model posteriors.
Such constraints are not declarative, but instead
based on annotations of words’ majority relation la-
bels (Mann and McCallum, 2008) and pre-existing
databases with the desired output schema (Bellare
and McCallum, 2009). In contrast to previous work,
our approach explores a different class of constraints
that does not rely on supervision that is specific to
particular relation types and their instances.
</bodyText>
<sectionHeader confidence="0.994893" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999869">
Our work performs in-domain relation discovery by
leveraging regularities in relation expression at the
lexical, syntactic, and discourse levels. These regu-
larities are captured via two components: a proba-
bilistic model that explains how documents are gen-
erated from latent relation variables and a technique
</bodyText>
<page confidence="0.998293">
531
</page>
<figureCaption confidence="0.8718318">
Figure 2: Words w and constituents x of syntactic parses
are represented with indicator features Oi and argument
features 0a respectively. A single relation instantiation is
a pair of indicator w and argument x; we filter w to be
nouns and verbs and x to be noun phrases and adjectives.
</figureCaption>
<bodyText confidence="0.999985">
for biasing inference to adhere to declaratively-
specified constraints on relation expression. This
section describes the generative process, while Sec-
tions 4 and 5 discuss declarative constraints.
</bodyText>
<subsectionHeader confidence="0.999218">
3.1 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.9998872">
Our input is a corpus of constituent-parsed docu-
ments and a number K of relation types. The output
is K clusters of semantically related relation instan-
tiations. We represent these instantiations as a pair
of indicator word and argument sequence from the
same sentence. The indicator’s role is to anchor a
relation and identify its type. We only allow nouns
or verbs to be indicators. For instance, in the earth-
quake domain a likely indicator for damage would
be “destroyed.” The argument is the actual rela-
tion value, e.g., “some homes,” and corresponds to
a noun phrase or adjective.3
Along with the document parse trees, we utilize
a set of features Oi(w) and oa(x) describing each
potential indicator word w and argument constituent
x, respectively. An example feature representation
is shown in Figure 2. These features can encode
words, part-of-speech tags, context, and so on. Indi-
cator and argument feature definitions need not be
the same (e.g., has number is important for argu-
</bodyText>
<footnote confidence="0.8553">
3In this paper we focus on unary relations; binary relations
can be modeled with extensions of the hidden variables and con-
straints.
</footnote>
<bodyText confidence="0.654018">
ments but irrelevant for indicators).4
</bodyText>
<subsectionHeader confidence="0.896735">
3.2 Generative Process
</subsectionHeader>
<bodyText confidence="0.978521545454546">
Our model associates each relation type k with a set
offeature distributions Bk and a location distribution
Ak. Each instantiation’s indicator and argument, and
its position within a document, are drawn from these
distributions. By sharing distributions within each
relation, the model places high probability mass on
clusters of instantiations that are coherent in features
and position. Furthermore, we allow at most one in-
stantiation per document and relation, so as to target
relations that are relevant to the entire document.
There are three steps to the generative process.
First, we draw feature and location distributions for
each relation. Second, an instantiation is selected
for every pair of document d and relation k. Third,
the indicator features of each word and argument
features of each constituent are generated based on
the relation parameters and instantiations. Figure 3
presents a reference for the generative process.
Generating Relation Parameters Each relation k
is associated with four feature distribution param-
eter vectors: Bik for indicator words, Bbi kfor non-
indicator words, Ba k for argument constituents, and
Bba
k for non-argument constituents. Each of these is
a set of multinomial parameters per feature drawn
from a symmetric Dirichlet prior. A likely indica-
tor word should have features that are highly proba-
ble according to Bik, and likewise for arguments and
Bak. Parameters Bbi
k and Bba
k represent background dis-
tributions for non-relation words and constituents,
similar in spirit to other uses of background distri-
butions that filter out irrelevant words (Che, 2006).5
By drawing each instance from these distributions,
we encourage the relation to be coherent in local lex-
ical and syntactic properties.
Each relation type k is also associated with a pa-
rameter vector Ak over document segments drawn
from a symmetric Dirichlet prior. Documents are
divided into L equal-length segments; Ak states how
likely relation k is for each segment, with one null
outcome for the relation not occurring in the doc-
ument. Because Ak is shared within a relation, its
</bodyText>
<footnote confidence="0.78269725">
4We consider only categorical features here, though the ex-
tension to continuous or ordinal features is straightforward.
5We use separate background distributions for each relation
to make inference more tractable.
</footnote>
<bodyText confidence="0.979884833333333">
is_verb 0 1 0
earthquake 1 0 0
hit 0 1 0
has_proper 0 0 1
has_number 0 0 0
depth 1 3 2
</bodyText>
<page confidence="0.864393">
532
</page>
<bodyText confidence="0.934754">
For each relation type k:
</bodyText>
<listItem confidence="0.980713545454546">
• For each indicator feature φi draw feature distri-
butions θik,φi, θbik,φi — Dir(θ0)
• For each argument feature φa draw feature dis-
tributions θak,φa, θba
k,φa — Dir(θ0)
• Draw location distribution λk — Dir(λ0)
For each relation type k and document d:
• Select document segment sd,k — Mult(λk)
• Select sentence zd,k uniformly from segment
sd,k, and indicator id,k and argument ad,k uni-
formly from sentence zd,k
</listItem>
<figure confidence="0.889618111111111">
For each word w in every document d:
• Draw each indicator feature φi(w) —
Mult ( z FIk= 1 θk,φi), where θk,φi is θik
if id,k = w and θbik,φi otherwise
For each constituent x in every document d:
• Draw each argument feature φa(x) —
Mult ( z FIk= 1 θk,φa), where θk,φa is θa k,φa
if ad,k = x and θba
k,φa otherwise
</figure>
<figureCaption confidence="0.9984385">
Figure 3: The generative process for model parameters
and features. In the above Dir and Mult refer respectively
to the Dirichlet distribution and multinomial distribution.
Fixed hyperparameters are subscripted with zero.
</figureCaption>
<bodyText confidence="0.999217">
instances will tend to occur in the same relative po-
sitions across documents. The model can learn, for
example, that a particular relation typically occurs in
the first quarter of a document (if L = 4).
Generating Relation Instantiations For every rela-
tion type k and document d, we first choose which
portion of the document (if any) contains the instan-
tiation by drawing a document segment sd,k from
λk. Our model only draws one instantiation per pair
of k and d, so each discovered instantiation within a
document is a separate relation. We then choose the
specific sentence zd,k uniformly from within the seg-
ment, and the indicator word id,k and argument con-
stituent ad,k uniformly from within that sentence.
Generating Text Finally, we draw the feature val-
ues. We make a Naive Bayes assumption between
features, drawing each independently conditioned
on relation structure. For a word w, we want all re-
lations to be able to influence its generation. Toward
this end, we compute the element-wise product of
feature parameters across relations k = 1, ... , K,
using indicator parameters θi k if relation k selected
w as an indicator word (if id,k = w) and background
parameters θbi
k otherwise. The result is then normal-
ized to form a valid multinomial that produces word
w’s features. Constituents are drawn similarly from
every relations’ argument distributions.
</bodyText>
<sectionHeader confidence="0.992508" genericHeader="method">
4 Inference with Constraints
</sectionHeader>
<bodyText confidence="0.999985214285714">
The model presented above leverages relation reg-
ularities in local features and document placement.
However, it is unable to specify global syntactic
preferences about relation expression, such as indi-
cators and arguments being in the same clause. An-
other issue with this model is that different relations
could overlap in their indicators and arguments.6
To overcome these obstacles, we apply declara-
tive constraints by imposing inequality constraints
on expectations of the posterior during inference
using posterior regularization (Grac¸a et al., 2007).
In this section we present the technical details
of the approach; Section 5 explains the specific
linguistically-motivated constraints we consider.
</bodyText>
<subsectionHeader confidence="0.995042">
4.1 Inference with Posterior Regularization
</subsectionHeader>
<bodyText confidence="0.879205571428571">
We first review how posterior regularization impacts
the variational inference procedure in general. Let
θ, z, and x denote the parameters, hidden struc-
ture, and observations of an arbitrary model. We
are interested in estimating the posterior distribution
p(θ, z  |x) by finding a distribution q(θ, z) E 2 that
is minimal in KL-divergence to the true posterior:
</bodyText>
<equation confidence="0.93192">
KL(qf(B, z) 11 p(θ, z  |x))
= J q(θ, z) log pq(θ, z)) dθdz + log p(x). (1)
</equation>
<bodyText confidence="0.999401571428571">
For tractability, variational inference typically
makes a mean-field assumption that restricts the set
2 to distributions where θ and z are independent,
i.e., q(θ, z) = q(θ)q(z). We then optimize equa-
tion 1 by coordinate-wise descent on q(θ) and q(z).
To incorporate constraints into inference, we fur-
ther restrict 2 to distributions that satisfy a given
</bodyText>
<footnote confidence="0.994763666666667">
6In fact, a true maximum a posteriori estimate of the model
parameters would find the same most salient relation over and
over again for every k, rather than finding K different relations.
</footnote>
<page confidence="0.997113">
533
</page>
<bodyText confidence="0.999605076923077">
set of inequality constraints, each of the form
Eq[f(z)] G b. Here, f(z) is a deterministic func-
tion of z and b is a user-specified threshold. Inequal-
ities in the opposite direction simply require negat-
ing f(z) and b. For example, we could apply a syn-
tactic constraint of the form Eq[f(z)] &gt; b, where
f(z) counts the number of indicator/argument pairs
that are syntactically connected in a pre-specified
manner (e.g., the indicator and argument modify the
same verb), and b is a fixed threshold.
Given a set C of constraints with functions fc(z)
and thresholds bc, the updates for q(θ) and q(z) from
equation 1 are as follows:
</bodyText>
<equation confidence="0.952422">
q(θ) = argmin KL (q(θ) II q0(θ)), (2)
q(θ)
where q0(θ) a exp Eq(z)[log p(θ, z, x)], and
q(z) = argmin KL (q(z) II q0(z))
q(z)
s.t. Eq(z)[fc(z)] G bc, Vc E C, (3)
</equation>
<bodyText confidence="0.986440806451613">
where q0(z) a exp Eq(θ)[log p(θ, z, x)]. Equation 2
is not affected by the posterior constraints and is up-
dated by setting q(θ) to q0(θ). We solve equation 3
in its dual form (Grac¸a et al., 2007):
With the box constraints of equation 4, a numerical
optimization procedure such as L-BFGS-B (Byrd
et al., 1995) can be used to find optimal dual pa-
rameters κ∗. The original q(z) is then updated to
q0(z) exp(− Ec∈C κ∗cfc(z)) and renormalized.
that we do not factorize the distribution of z, i, and
a for a single document and relation, instead repre-
senting their joint distribution with a single set of
variational parameters ˆc. This is tractable because a
single relation occurs only once per document, re-
ducing the joint search space of z, i, and a. The
factors in equation 5 are updated one at a time while
holding the other factors fixed.
Updating θˆ Due to the Naive Bayes assumption
between features, each feature’s q(θ) distributions
can be updated separately. However, the product
between feature parameters of different relations in-
troduces a nonconjugacy in the model, precluding
a closed form update. Instead we numerically opti-
mize equation 1 with respect to each ˆθ, similarly to
previous work (Boyd-Graber and Blei, 2008). For
instance, ˆθi k,φ of relation k and feature φ is updated
by finding the gradient of equation 1 with respect to
ˆθik,φ and applying L-BFGS. Parameters ˆθbi, ˆθa, and
ˆθba are updated analogously.
Updating λˆ This update follows the standard
closed form for Dirichlet parameters:
</bodyText>
<equation confidence="0.997775">
ˆλk,` = λ0 + Eq(z,a,i)[C`(z, a, i)], (6)
</equation>
<bodyText confidence="0.9854095">
where C` counts the number of times z falls into seg-
ment ` of a document.
Updating cˆ Parameters cˆ are updated by first com-
puting an unconstrained update q0(z, a, i; ˆc0):
</bodyText>
<equation confidence="0.704656142857143">
ˆc0 d,k,(z,a,i) a exp IEq(λk)[log p(z, a, i  |λk)]
+ Eq(θik)[log p(i  |θik)] + � Eq(θbik )[log p(w  |θbi
k )]
w6=i
argmin � �κcbc + log q0(z)e− EcEC κcfc(z)
κ c∈C z
s.t. κc &gt; 0, Vc E C. (4)
</equation>
<table confidence="0.804099">
4.2 Updates for our Model � �
Our model uses this mean-field factorization: + Eq(θak)[log p(a  |θak)] + Eq(θbak )[log p(x  |θba
</table>
<equation confidence="0.929136357142857">
x6=a k )] �
ˆλk)q(θik; ˆθik)q(θbi
k ; ˆθbi
k )q(θa k; ˆθa k)q(θba
k ; ˆθba
k
)
=
q(λk;
K
rl
k=1
q(θ, λ, z, a, i)
rlX q(zd,k, ad,k, id,k; ˆcd,k) (5)
</equation>
<bodyText confidence="0.969267727272727">
d
In the above, λˆ and θˆ are Dirichlet distribution pa-
rameters, and cˆ are multinomial parameters. Note
We then perform the minimization on the dual in
equation 4 under the provided constraints to derive a
final update to the constrained ˆc.
Simplifying Approximation The update for θˆ re-
quires numerical optimization due to the nonconju-
gacy introduced by the point-wise product in fea-
ture generation. If instead we have every relation
type separately generate a copy of the corpus, the θˆ
</bodyText>
<page confidence="0.985277">
534
</page>
<table confidence="0.9992854">
Quantity f(z, a, i) &lt; or &gt; b
Syntax dk Counts i, a of relation k that match a pattern (see text) &gt; 0.8D
Prevalence dk Counts instantiations of relation k &gt; 0.8D
Separation (ind) dw Counts times w selected as i &lt; 2
Separation (arg) dw Counts times w selected as part of a &lt; 1
</table>
<tableCaption confidence="0.9889815">
Table 1: Each constraint takes the form E9[f(z, a, i)] &lt; b or E9[f(z, a, i)] &gt; b; D denotes the number of corpus
documents, dk means one constraint per relation type, and dw means one constraint per token in the corpus.
</tableCaption>
<bodyText confidence="0.99883475">
updates becomes closed-form expressions similar to
equation 6. This approximation yields similar pa-
rameter estimates as the true updates while vastly
improving speed, so we use it in our experiments.
</bodyText>
<sectionHeader confidence="0.99809" genericHeader="method">
5 Declarative Constraints
</sectionHeader>
<bodyText confidence="0.935133764705882">
We now have the machinery to incorporate a va-
riety of declarative constraints during inference.
The classes of domain-independent constraints we
study are summarized in Table 1. For the propor-
tion constraints we arbitrarily select a threshold of
80% without any tuning, in the spirit of building a
domain-independent approach.
Syntax As previous work has observed, most rela-
tions are expressed using a limited number of com-
mon syntactic patterns (Riloff, 1996; Banko and Et-
zioni, 2008). Our syntactic constraint captures this
insight by requiring that a certain proportion of the
induced instantiations for each relation match one of
these syntactic patterns:
• The indicator is a verb and the argument’s
headword is either the child or grandchild of
the indicator word in the dependency tree.
</bodyText>
<listItem confidence="0.75141575">
• The indicator is a noun and the argument is a
modifier or complement.
• The indicator is a noun in a verb’s subject and
the argument is in the corresponding object.
</listItem>
<bodyText confidence="0.985461818181818">
Prevalence For a relation to be domain-relevant, it
should occur in numerous documents across the cor-
pus, so we institute a constraint on the number of
times a relation is instantiated. Note that the effect
of this constraint could also be achieved by tuning
the prior probability of a relation not occurring in a
document. However, this prior would need to be ad-
justed every time the number of documents or fea-
ture selection changes; using a constraint is an ap-
pealing alternative that is portable across domains.
Separation The separation constraint encourages
diversity in the discovered relation types by restrict-
ing the number of times a single word can serve as
either an indicator or part of the argument of a re-
lation instance. Specifically, we require that every
token of the corpus occurs at most once as a word
in a relation’s argument in expectation. On the other
hand, a single word can sometimes be evocative of
multiple relations (e.g., “occurred” signals both date
and time in “occurred on Friday at 3pm”). Thus, we
allow each word to serve as an indicator more than
once, arbitrarily fixing the limit at two.
</bodyText>
<sectionHeader confidence="0.999222" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<bodyText confidence="0.997663764705882">
Datasets and Metrics We evaluate on two datasets,
financial market reports and newswire articles about
earthquakes, previously used in work on high-level
content analysis (Barzilay and Lee, 2004; Lap-
ata, 2006). Finance articles chronicle daily mar-
ket movements of currencies and stock indexes, and
earthquake articles document specific earthquakes.
Constituent parses are obtained automatically us-
ing the Stanford parser (Klein and Manning, 2003)
and then converted to dependency parses using the
PennConvertor tool (Johansson and Nugues, 2007).
We manually annotated relations for both corpora,
selecting relation types that occurred frequently in
each domain. We found 15 types for finance and
9 for earthquake. Corpus statistics are summarized
below, and example relation types are shown in Ta-
ble 2.
</bodyText>
<table confidence="0.990448666666667">
Docs Sent/Doc Tok/Doc Vocab
Finance 100 12.1 262.9 2918
Earthquake 200 9.3 210.3 3155
</table>
<bodyText confidence="0.999520285714286">
In our task, annotation conventions for desired
output relations can greatly impact token-level per-
formance, and the model cannot learn to fit a par-
ticular convention by looking at example data. For
example, earthquakes times are frequently reported
in both local and GMT, and either may be arbitrar-
ily chosen as correct. Moreover, the baseline we
</bodyText>
<page confidence="0.996546">
535
</page>
<table confidence="0.999449">
Finance Bond 104.58 yen, 98.37 yen
Dollar Change up 0.52 yen, down 0.01 yen
Tokyo Index Change down 5.38 points or 0.41 percent, up 0.16 points, insignificant in percentage terms
Earthquake Damage about 10000 homes, some buildings, no information
Epicenter Patuca about 185 miles (300 kilometers) south of Quito, 110 kilometers (65 miles)
from shore under the surface of the Flores sea in the Indonesian archipelago
Magnitude 5.7, 6, magnitude-4
</table>
<tableCaption confidence="0.999032">
Table 2: Example relation types identified in the finance and earthquake datasets with example instance arguments.
</tableCaption>
<bodyText confidence="0.999612539473684">
compare against produces lambda calculus formulas
rather than spans of text as output, so a token-level
comparison requires transforming its output.
For these reasons, we evaluate on both sentence-
level and token-level precision, recall, and F-score.
Precision is measured by mapping every induced re-
lation cluster to its closest gold relation and comput-
ing the proportion of predicted sentences or words
that are correct. Conversely, for recall we map ev-
ery gold relation to its closest predicted relation and
find the proportion of gold sentences or words that
are predicted. This mapping technique is based on
the many-to-one scheme used for evaluating unsu-
pervised part-of-speech induction (Johnson, 2007).
Note that sentence-level scores are always at least as
high as token-level scores, since it is possible to se-
lect a sentence correctly but none of its true relation
tokens while the opposite is not possible.
Domain-specific Constraints On top of the cross-
domain constraints from Section 5, we study
whether imposing basic domain-specific constraints
can be beneficial. The finance dataset is heav-
ily quantitative, so we consider applying a single
domain-specific constraint stating that most rela-
tion arguments should include a number. Likewise,
earthquake articles are typically written with a ma-
jority of the relevant information toward the begin-
ning of the document, so its domain-specific con-
straint is that most relations should occur in the
first two sentences of a document. Note that these
domain-specific constraints are not specific to in-
dividual relations or instances, but rather encode a
preference across all relation types. In both cases,
we again use an 80% threshold without tuning.
Features For indicators, we use the word, part of
speech, and word stem. For arguments, we use the
word, syntactic constituent label, the head word of
the parent constituent, and the dependency label of
the argument to its parent.
Baselines We compare against three alternative un-
supervised approaches. Note that the first two only
identify relation-bearing sentences, not the specific
words that participate in the relation.
Clustering (CLUTO): A straightforward way of
identifying sentences bearing the same relation is
to simply cluster them. We implement a cluster-
ing baseline using the CLUTO toolkit with word and
part-of-speech features. As with our model, we set
the number of clusters K to the true number of rela-
tion types.
Mallows Topic Model (MTM): Another technique
for grouping similar sentences is the Mallows-based
topic model of Chen et al. (2009). The datasets we
consider here exhibit high-level regularities in con-
tent organization, so we expect that a topic model
with global constraints could identify plausible clus-
ters of relation-bearing sentences. Again, K is set to
the true number of relation types.
Unsupervised Semantic Parsing (USP): Our fi-
nal unsupervised comparison is to USP, an unsuper-
vised deep semantic parser introduced by Poon and
Domingos (2009). USP induces a lambda calculus
representation of an entire corpus and was shown to
be competitive with open information extraction ap-
proaches (Lin and Pantel, 2001; Banko et al., 2007).
We give USP the required Stanford dependency for-
mat as input (de Marneffe and Manning, 2008). We
find that the results are sensitive to the cluster granu-
larity prior, so we tune this parameter and report the
best-performing runs.
We recognize that USP targets a different out-
put representation than ours: a hierarchical semantic
structure over the entirety of a dependency-parsed
text. In contrast, we focus on discovering a limited
number K of domain-relevant relations expressed as
constituent phrases. Despite these differences, both
</bodyText>
<page confidence="0.995883">
536
</page>
<bodyText confidence="0.99997737037037">
methods ultimately aim to capture domain-specific
relations expressed with varying verbalizations, and
both operate over in-domain input corpora supple-
mented with syntactic information. For these rea-
sons, USP provides a clear and valuable point of
comparison. For this comparison, we transform
USP’s lambda calculus formulas to relation spans as
follows. First, we group lambda forms by a combi-
nation of core form, argument form, and the parent’s
core form.7 We then filter to the K relations that
appear in the most documents. For token-level eval-
uation we take the dependency tree fragment corre-
sponding to the lambda form. For example, in the
sentence “a strong earthquake rocked the Philippines
island of Mindoro early Tuesday,” USP learns that
the word “Tuesday” has a core form corresponding
to words {Tuesday, Wednesday, Saturday}, a parent
form corresponding to words {shook, rock, hit, jolt},
and an argument form of TMOD; all phrases with
this same combination are grouped as a relation.
Training Regimes and Hyperparameters For each
run of our model we perform three random restarts
to convergence and select the posterior with lowest
final free energy. We fix K to the true number of
annotated relation types for both our model and USP
and L (the number of document segments) to five.
Dirichlet hyperparameters are set to 0.1.
</bodyText>
<sectionHeader confidence="0.99976" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.999891">
Table 3’s first two sections present the results of our
main evaluation. For earthquake, the far more diffi-
cult domain, our base model with only the domain-
independent constraints strongly outperforms all
three baselines across both metrics. For finance,
the CLUTO and USP baselines achieve performance
comparable to or slightly better than our base model.
Our approach, however, has the advantage of provid-
ing a formalism for seamlessly incorporating addi-
tional arbitrary domain-specific constraints. When
we add such constraints (denoted as model+DSC),
we achieve consistently higher performance than all
baselines across both datasets and metrics, demon-
strating that this approach provides a simple and ef-
fective framework for injecting domain knowledge
into relation discovery.
</bodyText>
<footnote confidence="0.956535">
7This grouping mechanism yields better results than only
grouping by core form.
</footnote>
<bodyText confidence="0.999924377777778">
The first two baselines correspond to a setup
where the number of sentence clusters K is set to
the true number of relation types. This has the effect
of lowering precision because each sentence must be
assigned a cluster. To mitigate this impact, we exper-
imented with using K + N clusters, with N ranging
from 1 to 30. In each case, we then keep only the K
largest clusters. For the earthquake dataset, increas-
ing N improves performance until some point, after
which performance degrades. However, the best F-
Score corresponding to the optimal number of clus-
ters is 42.2, still far below our model’s 66.0 F-score.
For the finance domain, increasing the number of
clusters hurts performance.
Our results show a large gap in F-score between
the sentence and token-level evaluations for both the
USP baseline and our model. A qualitative analysis
of the results indicates that our model often picks up
on regularities that are difficult to distinguish with-
out relation-specific supervision. For earthquake, a
location may be annotated as “the Philippine island
of Mindoro” while we predict just the word “Min-
doro.” For finance, an index change can be anno-
tated as “30 points, or 0.8 percent,” while our model
identifies “30 points” and “0.8 percent” as separate
relations. In practice, these outputs are all plausi-
ble discoveries, and a practitioner desiring specific
outputs could impose additional constraints to guide
relation discovery toward them.
The Impact of Constraints To understand the im-
pact of the declarative constraints, we perform an
ablation analysis on the constraint sets. We con-
sider removing the constraints on syntactic patterns
(no-syn) and the constraints disallowing relations to
overlap (no-sep) from the full domain-independent
model.8 We also try a version with hard syntac-
tic constraints (hard-syn), which requires that every
extraction match one of the three syntactic patterns
specified by the syntactic constraint.
Table 3’s bottom section presents the results of
this evaluation. The model’s performance degrades
when either of the two constraint sets are removed,
demonstrating that the constraints are in fact benefi-
cial for relation discovery. Additionally, in the hard-
syn case, performance drops dramatically for finance
</bodyText>
<footnote confidence="0.980963">
8Prevalence constraints are always enforced, as otherwise
the prior on not instantiating a relation would need to be tuned.
</footnote>
<page confidence="0.977829">
537
</page>
<table confidence="0.999812090909091">
Finance Earthquake
Sentence-level Token-level Sentence-level Token-level
Prec Rec F1 Prec Rec F1 Prec Rec F1 Prec Rec F1
Model 82.1 59.7 69.2 42.2 23.9 30.5 54.2 68.1 60.4 20.2 16.8 18.3
Model+DSC 87.3 81.6 84.4 51.8 30.0 38.0 66.4 65.6 66.0 22.6 23.1 22.8
CLUTO 56.3 92.7 70.0 — — — 19.8 58.0 29.5 — — —
MTM 40.4 99.3 57.5 — — — 18.6 74.6 29.7 — — —
USP 91.3 66.1 76.7 28.5 32.6 30.4 61.2 43.5 50.8 9.9 32.3 15.1
No-sep 97.8 35.4 52.0 86.1 8.7 15.9 42.2 21.9 28.8 16.1 4.6 7.1
No-syn 83.3 46.1 59.3 20.8 9.9 13.4 53.8 60.9 57.1 14.0 13.8 13.9
Hard-syn 47.7 39.0 42.9 11.6 7.0 8.7 55.0 66.2 60.1 20.1 17.3 18.6
</table>
<tableCaption confidence="0.9945885">
Table 3: Top section: our model, with and without domain-specific constraints (DSC). Middle section: The three
baselines. Bottom section: ablation analysis of constraint sets for our model. For all scores, higher is better.
</tableCaption>
<bodyText confidence="0.999956234042553">
while remaining almost unchanged for earthquake.
This suggests that formulating constraints as soft in-
equalities on posterior expectations gives our model
the flexibility to accommodate both the underlying
signal in the data and the declarative constraints.
Comparison against Supervised CRF Our final
set of experiments compares a semi-supervised ver-
sion of our model against a conditional random field
(CRF) model. The CRF model was trained using
the same features as our model’s argument features.
To incorporate training examples in our model, we
simply treat annotated relation instances as observed
variables. For both the baselines and our model,
we experiment with using up to 10 annotated docu-
ments. At each of those levels of supervision, we av-
erage results over 10 randomly drawn training sets.
At the sentence level, our model compares very
favorably to the supervised CRF. For finance, it takes
at least 10 annotated documents (corresponding to
roughly 130 annotated relation instances) for the
CRF to match the semi-supervised model’s perfor-
mance. For earthquake, using even 10 annotated
documents (about 71 relation instances) is not suf-
ficient to match our model’s performance.
At the token level, the supervised CRF base-
line is far more competitive. Using a single la-
beled document (13 relation instances) yields su-
perior performance to either of our model variants
for finance, while four labeled documents (29 re-
lation instances) do the same for earthquake. This
result is not surprising—our model makes strong
domain-independent assumptions about how under-
lying patterns of regularities in the text connect to
relation expression. Without domain-specific super-
vision such assumptions are necessary, but they can
prevent the model from fully utilizing available la-
beled instances. Moreover, being able to annotate
even a single document requires a broad understand-
ing of every relation type germane to the domain,
which can be infeasible when there are many unfa-
miliar, complex domains to process.
In light of our strong sentence-level performance,
this suggests a possible human-assisted application:
use our model to identify promising relation-bearing
sentences in a new domain, then have a human an-
notate those sentences for use by a supervised ap-
proach to achieve optimal token-level extraction.
</bodyText>
<sectionHeader confidence="0.998945" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999939777777778">
This paper has presented a constraint-based ap-
proach to in-domain relation discovery. We have
shown that a generative model augmented with
declarative constraints on the model posterior can
successfully identify domain-relevant relations and
their instantiations. Furthermore, we found that a
single set of constraints can be used across divergent
domains, and that tailoring constraints specific to a
domain can yield further performance benefits.
</bodyText>
<sectionHeader confidence="0.994951" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999542818181818">
The authors gratefully acknowledge the support
of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air
Force Research Laboratory (AFRL) prime contract
no. FA8750-09-C-0172. Any opinions, findings,
and conclusion or recommendations expressed in
this material are those of the authors and do not nec-
essarily reflect the view of the DARPA, AFRL, or
the US government. Thanks also to Hoifung Poon
and the members of the MIT NLP group for their
suggestions and comments.
</bodyText>
<page confidence="0.996766">
538
</page>
<sectionHeader confidence="0.995856" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99986475">
Eugene Agichtein and Luis Gravano. 2000. Snowball:
Extracting relations from large plain-text collections.
In Proceedings of DL.
Michele Banko and Oren Etzioni. 2008. The tradeoffs
between open and traditional relation extraction. In
Proceedings of ACL.
Michele Banko, Michael J. Cafarella, Stephen Soderland,
Matt Broadhead, and Oren Etzioni. 2007. Open in-
formation extraction from the web. In Proceedings of
IJCAI.
Regina Barzilay and Lillian Lee. 2004. Catching the
drift: Probabilistic content models, with applications
to generation and summarization. In Proceedings of
HLT/NAACL.
Kedar Bellare and Andrew McCallum. 2009. Gen-
eralized expectation criteria for bootstrapping extrac-
tors using record-text alignment. In Proceedings of
EMNLP.
Jordan Boyd-Graber and David M. Blei. 2008. Syntactic
topic models. In Advances in NIPS.
Razvan C. Bunescu and Raymond J. Mooney. 2007.
Learning to extract relations from the web using mini-
mal supervision. In Proceedings ofACL.
Richard H. Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou
Zhu. 1995. A limited memory algorithm for bound
constrained optimization. SIAM Journal on Scientific
Computing, 16(5):1190–1208.
Ming-Wei Chang, Lev Ratinov, and Dan Roth.
2007. Guiding semi-supervision with constraint-
driven learning. In Proceedings of ACL.
2006. Modeling general and specific aspects of docu-
ments with a probabilistic topic model. In Advances
in NIPS.
Jinxiu Chen, Dong-Hong Ji, Chew Lim Tan, and Zheng-
Yu Niu. 2005. Automatic relation extraction with
model order selection and discriminative label identi-
fication. In Proceedings of IJCNLP.
Harr Chen, S.R.K. Branavan, Regina Barzilay, and
David R. Karger. 2009. Content modeling using la-
tent permutations. Journal of Artificial Intelligence
Research, 36:129–163.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The stanford typed dependencies repre-
sentation. In Proceedings of the COLING Workshop
on Cross-framework and Cross-domain Parser Evalu-
ation.
Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007.
Expectation maximization and posterior constraints.
In Advances in NIPS.
Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.
2004. Discovering relations among named entities
from large corpora. In Proceedings of ACL.
Richard Johansson and Pierre Nugues. 2007. Extended
constituent-to-dependency conversion for english. In
Proceedings of NODALIDA.
Mark Johnson. 2007. Why doesn’t EM find good HMM
POS-taggers? In Proceedings of EMNLP.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proceedings of ACL.
Mirella Lapata. 2006. Automatic evaluation of informa-
tion ordering: Kendall’s tau. Computational Linguis-
tics, 32(4):471–484.
Dekang Lin and Patrick Pantel. 2001. DIRT - discov-
ery of inference rules from text. In Proceedings of
SIGKDD.
Gideon S. Mann and Andrew McCallum. 2008. General-
ized expectation criteria for semi-supervised learning
of conditional random fields. In Proceedings of ACL.
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of ACL/IJCNLP.
Hoifung Poon and Pedro Domingos. 2009. Unsuper-
vised semantic parsing. In Proceedings of EMNLP.
Ellen Riloff. 1996. Automatically generating extraction
patterns from untagged texts. In Proceedings of AAAI.
Benjamin Rosenfeld and Ronen Feldman. 2007. Clus-
tering for unsupervised relation identification. In Pro-
ceedings of CIKM.
Dan Roth and Wen-tau Yih. 2004. A linear programming
formulation for global inference in natural language
tasks. In Proceedings of CoNLL.
Yusuke Shinyama and Satoshi Sekine. 2006. Preemp-
tive information extraction using unrestricted relation
discovery. In Proceedings of HLT/NAACL.
Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman.
2003. An improved extraction pattern representation
model for automatic IE pattern acquisition. In Pro-
ceedings of ACL.
Roman Yangarber, Ralph Grishman, Pasi Tapanainen,
and Silja Huttunen. 2000. Automatic acquisition of
domain knowledge for information extraction. In Pro-
ceedings of COLING.
Limin Yao, Sebastian Riedel, and Andrew McCallum.
2010. Cross-document relation extraction without la-
belled data. In Proceedings of EMNLP.
Alexander Yates and Oren Etzioni. 2009. Unsupervised
methods for determining object and relation synonyms
on the web. Journal ofArtificial Intelligence Research,
34:255–296.
Min Zhang, Jian Su, Danmei Wang, Guodong Zhou, and
Chew Lim Tan. 2005. Discovering relations between
named entities from a large raw corpus using tree
similarity-based clustering. In Proceedings of IJC-
NLP.
</reference>
<page confidence="0.986117">
539
</page>
<reference confidence="0.898974">
Jun Zhu, Zaiqing Nie, Xiaojing Liu, Bo Zhang, and Ji-
Rong Wen. 2009. StatSnowball: a statistical approach
to extracting entity relationships. In Proceedings of
WWW.
</reference>
<page confidence="0.996674">
540
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.832439">
<title confidence="0.9939835">In-domain Relation Discovery with via Posterior Regularization</title>
<author confidence="0.995573">Edward Benson Chen</author>
<author confidence="0.995573">Tahira Naseem</author>
<affiliation confidence="0.971887">Computer Science and Artificial Intelligence Massachusetts Institute of</affiliation>
<email confidence="0.926703">eob,tahira,</email>
<abstract confidence="0.998408318181818">We present a novel approach to discovering relations and their instantiations from a collection of documents in a single domain. Our approach learns relation types by exploiting characterize the general qualities of a good relation in any domain. These constraints state that instances of a single relation should exhibit regularities at multiple levels of linguistic structure, including lexicography, syntax, and document-level context. We capture these regularities via the structure of our probabilistic model as well as a set of declaratively-specified constraints enforced during posterior inference. Across two domains our approach successfully recovers hidden relation structure, comparable to or outperforming previous state-of-the-art approaches. Furthermore, we find that a small set of constraints is applicable across the domains, and that using domain-specific concan further improve performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: Extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>In Proceedings of DL.</booktitle>
<contexts>
<context position="5131" citStr="Agichtein and Gravano, 2000" startWordPosition="719" endWordPosition="723">nancial markets. Our results demonstrate that we can successfully identify domain-relevant relations. We also study the importance and effectiveness of the declaratively-specified constraints. In particular, we find that a small set of declarative constraints are effective across domains, while additional domainspecific constraints yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, </context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and Luis Gravano. 2000. Snowball: Extracting relations from large plain-text collections. In Proceedings of DL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
</authors>
<title>The tradeoffs between open and traditional relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="21094" citStr="Banko and Etzioni, 2008" startWordPosition="3356" endWordPosition="3360">s similar parameter estimates as the true updates while vastly improving speed, so we use it in our experiments. 5 Declarative Constraints We now have the machinery to incorporate a variety of declarative constraints during inference. The classes of domain-independent constraints we study are summarized in Table 1. For the proportion constraints we arbitrarily select a threshold of 80% without any tuning, in the spirit of building a domain-independent approach. Syntax As previous work has observed, most relations are expressed using a limited number of common syntactic patterns (Riloff, 1996; Banko and Etzioni, 2008). Our syntactic constraint captures this insight by requiring that a certain proportion of the induced instantiations for each relation match one of these syntactic patterns: • The indicator is a verb and the argument’s headword is either the child or grandchild of the indicator word in the dependency tree. • The indicator is a noun and the argument is a modifier or complement. • The indicator is a noun in a verb’s subject and the argument is in the corresponding object. Prevalence For a relation to be domain-relevant, it should occur in numerous documents across the corpus, so we institute a </context>
</contexts>
<marker>Banko, Etzioni, 2008</marker>
<rawString>Michele Banko and Oren Etzioni. 2008. The tradeoffs between open and traditional relation extraction. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<contexts>
<context position="5481" citStr="Banko et al., 2007" startWordPosition="779" endWordPosition="782"> Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use the word “argument” in the syntactic sense— a relation’s argument may or may not be the syntactic dependency argument of its indicator. We hypothesize that these properties hold across relations in different domains. Second, in contrast to work that builds general relation databases from heterogeneo</context>
<context position="27698" citStr="Banko et al., 2007" startWordPosition="4406" endWordPosition="4409">et al. (2009). The datasets we consider here exhibit high-level regularities in content organization, so we expect that a topic model with global constraints could identify plausible clusters of relation-bearing sentences. Again, K is set to the true number of relation types. Unsupervised Semantic Parsing (USP): Our final unsupervised comparison is to USP, an unsupervised deep semantic parser introduced by Poon and Domingos (2009). USP induces a lambda calculus representation of an entire corpus and was shown to be competitive with open information extraction approaches (Lin and Pantel, 2001; Banko et al., 2007). We give USP the required Stanford dependency format as input (de Marneffe and Manning, 2008). We find that the results are sensitive to the cluster granularity prior, so we tune this parameter and report the best-performing runs. We recognize that USP targets a different output representation than ours: a hierarchical semantic structure over the entirety of a dependency-parsed text. In contrast, we focus on discovering a limited number K of domain-relevant relations expressed as constituent phrases. Despite these differences, both 536 methods ultimately aim to capture domain-specific relatio</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In Proceedings of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<contexts>
<context position="22911" citStr="Barzilay and Lee, 2004" startWordPosition="3662" endWordPosition="3665">lation instance. Specifically, we require that every token of the corpus occurs at most once as a word in a relation’s argument in expectation. On the other hand, a single word can sometimes be evocative of multiple relations (e.g., “occurred” signals both date and time in “occurred on Friday at 3pm”). Thus, we allow each word to serve as an indicator more than once, arbitrarily fixing the limit at two. 6 Experimental Setup Datasets and Metrics We evaluate on two datasets, financial market reports and newswire articles about earthquakes, previously used in work on high-level content analysis (Barzilay and Lee, 2004; Lapata, 2006). Finance articles chronicle daily market movements of currencies and stock indexes, and earthquake articles document specific earthquakes. Constituent parses are obtained automatically using the Stanford parser (Klein and Manning, 2003) and then converted to dependency parses using the PennConvertor tool (Johansson and Nugues, 2007). We manually annotated relations for both corpora, selecting relation types that occurred frequently in each domain. We found 15 types for finance and 9 for earthquake. Corpus statistics are summarized below, and example relation types are shown in </context>
</contexts>
<marker>Barzilay, Lee, 2004</marker>
<rawString>Regina Barzilay and Lillian Lee. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kedar Bellare</author>
<author>Andrew McCallum</author>
</authors>
<title>Generalized expectation criteria for bootstrapping extractors using record-text alignment.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="7703" citStr="Bellare and McCallum, 2009" startWordPosition="1115" endWordPosition="1118">ramming to impose global declarative constraints on the output from a set of classifiers trained on local features. Chang et al. (2007) propose an objective function for semi-supervised extraction that balances likelihood of labeled instances and constraint violation on unlabeled instances. Recent work has also explored how certain kinds of supervision can be formulated as constraints on model posteriors. Such constraints are not declarative, but instead based on annotations of words’ majority relation labels (Mann and McCallum, 2008) and pre-existing databases with the desired output schema (Bellare and McCallum, 2009). In contrast to previous work, our approach explores a different class of constraints that does not rely on supervision that is specific to particular relation types and their instances. 3 Model Our work performs in-domain relation discovery by leveraging regularities in relation expression at the lexical, syntactic, and discourse levels. These regularities are captured via two components: a probabilistic model that explains how documents are generated from latent relation variables and a technique 531 Figure 2: Words w and constituents x of syntactic parses are represented with indicator fea</context>
</contexts>
<marker>Bellare, McCallum, 2009</marker>
<rawString>Kedar Bellare and Andrew McCallum. 2009. Generalized expectation criteria for bootstrapping extractors using record-text alignment. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordan Boyd-Graber</author>
<author>David M Blei</author>
</authors>
<title>Syntactic topic models.</title>
<date>2008</date>
<booktitle>In Advances in NIPS.</booktitle>
<contexts>
<context position="18434" citStr="Boyd-Graber and Blei, 2008" startWordPosition="2880" endWordPosition="2883">ional parameters ˆc. This is tractable because a single relation occurs only once per document, reducing the joint search space of z, i, and a. The factors in equation 5 are updated one at a time while holding the other factors fixed. Updating θˆ Due to the Naive Bayes assumption between features, each feature’s q(θ) distributions can be updated separately. However, the product between feature parameters of different relations introduces a nonconjugacy in the model, precluding a closed form update. Instead we numerically optimize equation 1 with respect to each ˆθ, similarly to previous work (Boyd-Graber and Blei, 2008). For instance, ˆθi k,φ of relation k and feature φ is updated by finding the gradient of equation 1 with respect to ˆθik,φ and applying L-BFGS. Parameters ˆθbi, ˆθa, and ˆθba are updated analogously. Updating λˆ This update follows the standard closed form for Dirichlet parameters: ˆλk,` = λ0 + Eq(z,a,i)[C`(z, a, i)], (6) where C` counts the number of times z falls into segment ` of a document. Updating cˆ Parameters cˆ are updated by first computing an unconstrained update q0(z, a, i; ˆc0): ˆc0 d,k,(z,a,i) a exp IEq(λk)[log p(z, a, i |λk)] + Eq(θik)[log p(i |θik)] + � Eq(θbik )[log p(w |θbi </context>
</contexts>
<marker>Boyd-Graber, Blei, 2008</marker>
<rawString>Jordan Boyd-Graber and David M. Blei. 2008. Syntactic topic models. In Advances in NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to extract relations from the web using minimal supervision.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="5181" citStr="Bunescu and Mooney, 2007" startWordPosition="728" endWordPosition="731">successfully identify domain-relevant relations. We also study the importance and effectiveness of the declaratively-specified constraints. In particular, we find that a small set of declarative constraints are effective across domains, while additional domainspecific constraints yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use </context>
</contexts>
<marker>Bunescu, Mooney, 2007</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2007. Learning to extract relations from the web using minimal supervision. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard H Byrd</author>
<author>Peihuang Lu</author>
<author>Jorge Nocedal</author>
<author>Ciyou Zhu</author>
</authors>
<title>A limited memory algorithm for bound constrained optimization.</title>
<date>1995</date>
<journal>SIAM Journal on Scientific Computing,</journal>
<volume>16</volume>
<issue>5</issue>
<contexts>
<context position="17510" citStr="Byrd et al., 1995" startWordPosition="2726" endWordPosition="2729">ixed threshold. Given a set C of constraints with functions fc(z) and thresholds bc, the updates for q(θ) and q(z) from equation 1 are as follows: q(θ) = argmin KL (q(θ) II q0(θ)), (2) q(θ) where q0(θ) a exp Eq(z)[log p(θ, z, x)], and q(z) = argmin KL (q(z) II q0(z)) q(z) s.t. Eq(z)[fc(z)] G bc, Vc E C, (3) where q0(z) a exp Eq(θ)[log p(θ, z, x)]. Equation 2 is not affected by the posterior constraints and is updated by setting q(θ) to q0(θ). We solve equation 3 in its dual form (Grac¸a et al., 2007): With the box constraints of equation 4, a numerical optimization procedure such as L-BFGS-B (Byrd et al., 1995) can be used to find optimal dual parameters κ∗. The original q(z) is then updated to q0(z) exp(− Ec∈C κ∗cfc(z)) and renormalized. that we do not factorize the distribution of z, i, and a for a single document and relation, instead representing their joint distribution with a single set of variational parameters ˆc. This is tractable because a single relation occurs only once per document, reducing the joint search space of z, i, and a. The factors in equation 5 are updated one at a time while holding the other factors fixed. Updating θˆ Due to the Naive Bayes assumption between features, each</context>
</contexts>
<marker>Byrd, Lu, Nocedal, Zhu, 1995</marker>
<rawString>Richard H. Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. 1995. A limited memory algorithm for bound constrained optimization. SIAM Journal on Scientific Computing, 16(5):1190–1208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Guiding semi-supervision with constraintdriven learning.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="7211" citStr="Chang et al. (2007)" startWordPosition="1044" endWordPosition="1047"> et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative constraints on the output from a set of classifiers trained on local features. Chang et al. (2007) propose an objective function for semi-supervised extraction that balances likelihood of labeled instances and constraint violation on unlabeled instances. Recent work has also explored how certain kinds of supervision can be formulated as constraints on model posteriors. Such constraints are not declarative, but instead based on annotations of words’ majority relation labels (Mann and McCallum, 2008) and pre-existing databases with the desired output schema (Bellare and McCallum, 2009). In contrast to previous work, our approach explores a different class of constraints that does not rely on</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraintdriven learning. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<title>Modeling general and specific aspects of documents with a probabilistic topic model.</title>
<date>2006</date>
<booktitle>In Advances in NIPS.</booktitle>
<marker>2006</marker>
<rawString>2006. Modeling general and specific aspects of documents with a probabilistic topic model. In Advances in NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxiu Chen</author>
<author>Dong-Hong Ji</author>
<author>Chew Lim Tan</author>
<author>ZhengYu Niu</author>
</authors>
<title>Automatic relation extraction with model order selection and discriminative label identification.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP.</booktitle>
<contexts>
<context position="6638" citStr="Chen et al., 2005" startWordPosition="958" endWordPosition="961">work that builds general relation databases from heterogeneous corpora, our focus is on learning the relations salient in a single domain. Our setup is more germane to specialized domains expressing information not broadly available on the web. Earlier work in unsupervised information extraction has also leveraged meta-knowledge independent of specific relation types, such as declarativelyspecified syntactic patterns (Riloff, 1996), frequent dependency subtree patterns (Sudo et al., 2003), and automatic clusterings of syntactic patterns (Lin and Pantel, 2001; Zhang et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative constraints on the output from a set of classifiers trained on local features. Chang et al. (2007) propose an objective funct</context>
</contexts>
<marker>Chen, Ji, Tan, Niu, 2005</marker>
<rawString>Jinxiu Chen, Dong-Hong Ji, Chew Lim Tan, and ZhengYu Niu. 2005. Automatic relation extraction with model order selection and discriminative label identification. In Proceedings of IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harr Chen</author>
<author>S R K Branavan</author>
<author>Regina Barzilay</author>
<author>David R Karger</author>
</authors>
<title>Content modeling using latent permutations.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>36--129</pages>
<contexts>
<context position="27092" citStr="Chen et al. (2009)" startWordPosition="4311" endWordPosition="4314">ompare against three alternative unsupervised approaches. Note that the first two only identify relation-bearing sentences, not the specific words that participate in the relation. Clustering (CLUTO): A straightforward way of identifying sentences bearing the same relation is to simply cluster them. We implement a clustering baseline using the CLUTO toolkit with word and part-of-speech features. As with our model, we set the number of clusters K to the true number of relation types. Mallows Topic Model (MTM): Another technique for grouping similar sentences is the Mallows-based topic model of Chen et al. (2009). The datasets we consider here exhibit high-level regularities in content organization, so we expect that a topic model with global constraints could identify plausible clusters of relation-bearing sentences. Again, K is set to the true number of relation types. Unsupervised Semantic Parsing (USP): Our final unsupervised comparison is to USP, an unsupervised deep semantic parser introduced by Poon and Domingos (2009). USP induces a lambda calculus representation of an entire corpus and was shown to be competitive with open information extraction approaches (Lin and Pantel, 2001; Banko et al.,</context>
</contexts>
<marker>Chen, Branavan, Barzilay, Karger, 2009</marker>
<rawString>Harr Chen, S.R.K. Branavan, Regina Barzilay, and David R. Karger. 2009. Content modeling using latent permutations. Journal of Artificial Intelligence Research, 36:129–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The stanford typed dependencies representation.</title>
<date>2008</date>
<booktitle>In Proceedings of the COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.</booktitle>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The stanford typed dependencies representation. In Proceedings of the COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Grac¸a</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2007</date>
<booktitle>In Advances in NIPS.</booktitle>
<marker>Grac¸a, Ganchev, Taskar, 2007</marker>
<rawString>Jo˜ao Grac¸a, Kuzman Ganchev, and Ben Taskar. 2007. Expectation maximization and posterior constraints. In Advances in NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Hasegawa</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>Discovering relations among named entities from large corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5434" citStr="Hasegawa et al., 2004" startWordPosition="771" endWordPosition="774">mainspecific constraints yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use the word “argument” in the syntactic sense— a relation’s argument may or may not be the syntactic dependency argument of its indicator. We hypothesize that these properties hold across relations in different domains. Second, in contrast to work that bui</context>
</contexts>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman. 2004. Discovering relations among named entities from large corpora. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Extended constituent-to-dependency conversion for english.</title>
<date>2007</date>
<booktitle>In Proceedings of NODALIDA.</booktitle>
<contexts>
<context position="23261" citStr="Johansson and Nugues, 2007" startWordPosition="3711" endWordPosition="3714">ndicator more than once, arbitrarily fixing the limit at two. 6 Experimental Setup Datasets and Metrics We evaluate on two datasets, financial market reports and newswire articles about earthquakes, previously used in work on high-level content analysis (Barzilay and Lee, 2004; Lapata, 2006). Finance articles chronicle daily market movements of currencies and stock indexes, and earthquake articles document specific earthquakes. Constituent parses are obtained automatically using the Stanford parser (Klein and Manning, 2003) and then converted to dependency parses using the PennConvertor tool (Johansson and Nugues, 2007). We manually annotated relations for both corpora, selecting relation types that occurred frequently in each domain. We found 15 types for finance and 9 for earthquake. Corpus statistics are summarized below, and example relation types are shown in Table 2. Docs Sent/Doc Tok/Doc Vocab Finance 100 12.1 262.9 2918 Earthquake 200 9.3 210.3 3155 In our task, annotation conventions for desired output relations can greatly impact token-level performance, and the model cannot learn to fit a particular convention by looking at example data. For example, earthquakes times are frequently reported in bo</context>
</contexts>
<marker>Johansson, Nugues, 2007</marker>
<rawString>Richard Johansson and Pierre Nugues. 2007. Extended constituent-to-dependency conversion for english. In Proceedings of NODALIDA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Why doesn’t EM find good HMM POS-taggers?</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="25227" citStr="Johnson, 2007" startWordPosition="4019" endWordPosition="4020">ken-level comparison requires transforming its output. For these reasons, we evaluate on both sentencelevel and token-level precision, recall, and F-score. Precision is measured by mapping every induced relation cluster to its closest gold relation and computing the proportion of predicted sentences or words that are correct. Conversely, for recall we map every gold relation to its closest predicted relation and find the proportion of gold sentences or words that are predicted. This mapping technique is based on the many-to-one scheme used for evaluating unsupervised part-of-speech induction (Johnson, 2007). Note that sentence-level scores are always at least as high as token-level scores, since it is possible to select a sentence correctly but none of its true relation tokens while the opposite is not possible. Domain-specific Constraints On top of the crossdomain constraints from Section 5, we study whether imposing basic domain-specific constraints can be beneficial. The finance dataset is heavily quantitative, so we consider applying a single domain-specific constraint stating that most relation arguments should include a number. Likewise, earthquake articles are typically written with a maj</context>
</contexts>
<marker>Johnson, 2007</marker>
<rawString>Mark Johnson. 2007. Why doesn’t EM find good HMM POS-taggers? In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="23163" citStr="Klein and Manning, 2003" startWordPosition="3697" endWordPosition="3700">s both date and time in “occurred on Friday at 3pm”). Thus, we allow each word to serve as an indicator more than once, arbitrarily fixing the limit at two. 6 Experimental Setup Datasets and Metrics We evaluate on two datasets, financial market reports and newswire articles about earthquakes, previously used in work on high-level content analysis (Barzilay and Lee, 2004; Lapata, 2006). Finance articles chronicle daily market movements of currencies and stock indexes, and earthquake articles document specific earthquakes. Constituent parses are obtained automatically using the Stanford parser (Klein and Manning, 2003) and then converted to dependency parses using the PennConvertor tool (Johansson and Nugues, 2007). We manually annotated relations for both corpora, selecting relation types that occurred frequently in each domain. We found 15 types for finance and 9 for earthquake. Corpus statistics are summarized below, and example relation types are shown in Table 2. Docs Sent/Doc Tok/Doc Vocab Finance 100 12.1 262.9 2918 Earthquake 200 9.3 210.3 3155 In our task, annotation conventions for desired output relations can greatly impact token-level performance, and the model cannot learn to fit a particular c</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Automatic evaluation of information ordering: Kendall’s tau.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>4</issue>
<contexts>
<context position="22926" citStr="Lapata, 2006" startWordPosition="3666" endWordPosition="3668">cally, we require that every token of the corpus occurs at most once as a word in a relation’s argument in expectation. On the other hand, a single word can sometimes be evocative of multiple relations (e.g., “occurred” signals both date and time in “occurred on Friday at 3pm”). Thus, we allow each word to serve as an indicator more than once, arbitrarily fixing the limit at two. 6 Experimental Setup Datasets and Metrics We evaluate on two datasets, financial market reports and newswire articles about earthquakes, previously used in work on high-level content analysis (Barzilay and Lee, 2004; Lapata, 2006). Finance articles chronicle daily market movements of currencies and stock indexes, and earthquake articles document specific earthquakes. Constituent parses are obtained automatically using the Stanford parser (Klein and Manning, 2003) and then converted to dependency parses using the PennConvertor tool (Johansson and Nugues, 2007). We manually annotated relations for both corpora, selecting relation types that occurred frequently in each domain. We found 15 types for finance and 9 for earthquake. Corpus statistics are summarized below, and example relation types are shown in Table 2. Docs S</context>
</contexts>
<marker>Lapata, 2006</marker>
<rawString>Mirella Lapata. 2006. Automatic evaluation of information ordering: Kendall’s tau. Computational Linguistics, 32(4):471–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT - discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGKDD.</booktitle>
<contexts>
<context position="6585" citStr="Lin and Pantel, 2001" startWordPosition="948" endWordPosition="951"> relations in different domains. Second, in contrast to work that builds general relation databases from heterogeneous corpora, our focus is on learning the relations salient in a single domain. Our setup is more germane to specialized domains expressing information not broadly available on the web. Earlier work in unsupervised information extraction has also leveraged meta-knowledge independent of specific relation types, such as declarativelyspecified syntactic patterns (Riloff, 1996), frequent dependency subtree patterns (Sudo et al., 2003), and automatic clusterings of syntactic patterns (Lin and Pantel, 2001; Zhang et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative constraints on the output from a set of classifiers trained on local fea</context>
<context position="27677" citStr="Lin and Pantel, 2001" startWordPosition="4402" endWordPosition="4405">d topic model of Chen et al. (2009). The datasets we consider here exhibit high-level regularities in content organization, so we expect that a topic model with global constraints could identify plausible clusters of relation-bearing sentences. Again, K is set to the true number of relation types. Unsupervised Semantic Parsing (USP): Our final unsupervised comparison is to USP, an unsupervised deep semantic parser introduced by Poon and Domingos (2009). USP induces a lambda calculus representation of an entire corpus and was shown to be competitive with open information extraction approaches (Lin and Pantel, 2001; Banko et al., 2007). We give USP the required Stanford dependency format as input (de Marneffe and Manning, 2008). We find that the results are sensitive to the cluster granularity prior, so we tune this parameter and report the best-performing runs. We recognize that USP targets a different output representation than ours: a hierarchical semantic structure over the entirety of a dependency-parsed text. In contrast, we focus on discovering a limited number K of domain-relevant relations expressed as constituent phrases. Despite these differences, both 536 methods ultimately aim to capture do</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT - discovery of inference rules from text. In Proceedings of SIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning of conditional random fields.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="7616" citStr="Mann and McCallum, 2008" startWordPosition="1103" endWordPosition="1106">. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative constraints on the output from a set of classifiers trained on local features. Chang et al. (2007) propose an objective function for semi-supervised extraction that balances likelihood of labeled instances and constraint violation on unlabeled instances. Recent work has also explored how certain kinds of supervision can be formulated as constraints on model posteriors. Such constraints are not declarative, but instead based on annotations of words’ majority relation labels (Mann and McCallum, 2008) and pre-existing databases with the desired output schema (Bellare and McCallum, 2009). In contrast to previous work, our approach explores a different class of constraints that does not rely on supervision that is specific to particular relation types and their instances. 3 Model Our work performs in-domain relation discovery by leveraging regularities in relation expression at the lexical, syntactic, and discourse levels. These regularities are captured via two components: a probabilistic model that explains how documents are generated from latent relation variables and a technique 531 Figu</context>
</contexts>
<marker>Mann, McCallum, 2008</marker>
<rawString>Gideon S. Mann and Andrew McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL/IJCNLP.</booktitle>
<contexts>
<context position="5278" citStr="Mintz et al., 2009" startWordPosition="745" endWordPosition="748">declaratively-specified constraints. In particular, we find that a small set of declarative constraints are effective across domains, while additional domainspecific constraints yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use the word “argument” in the syntactic sense— a relation’s argument may or may not be the syntactic</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of ACL/IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="27513" citStr="Poon and Domingos (2009)" startWordPosition="4376" endWordPosition="4379">l, we set the number of clusters K to the true number of relation types. Mallows Topic Model (MTM): Another technique for grouping similar sentences is the Mallows-based topic model of Chen et al. (2009). The datasets we consider here exhibit high-level regularities in content organization, so we expect that a topic model with global constraints could identify plausible clusters of relation-bearing sentences. Again, K is set to the true number of relation types. Unsupervised Semantic Parsing (USP): Our final unsupervised comparison is to USP, an unsupervised deep semantic parser introduced by Poon and Domingos (2009). USP induces a lambda calculus representation of an entire corpus and was shown to be competitive with open information extraction approaches (Lin and Pantel, 2001; Banko et al., 2007). We give USP the required Stanford dependency format as input (de Marneffe and Manning, 2008). We find that the results are sensitive to the cluster granularity prior, so we tune this parameter and report the best-performing runs. We recognize that USP targets a different output representation than ours: a hierarchical semantic structure over the entirety of a dependency-parsed text. In contrast, we focus on di</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2009. Unsupervised semantic parsing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically generating extraction patterns from untagged texts.</title>
<date>1996</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="6456" citStr="Riloff, 1996" startWordPosition="932" endWordPosition="933">ent may or may not be the syntactic dependency argument of its indicator. We hypothesize that these properties hold across relations in different domains. Second, in contrast to work that builds general relation databases from heterogeneous corpora, our focus is on learning the relations salient in a single domain. Our setup is more germane to specialized domains expressing information not broadly available on the web. Earlier work in unsupervised information extraction has also leveraged meta-knowledge independent of specific relation types, such as declarativelyspecified syntactic patterns (Riloff, 1996), frequent dependency subtree patterns (Sudo et al., 2003), and automatic clusterings of syntactic patterns (Lin and Pantel, 2001; Zhang et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations </context>
<context position="21068" citStr="Riloff, 1996" startWordPosition="3354" endWordPosition="3355">ximation yields similar parameter estimates as the true updates while vastly improving speed, so we use it in our experiments. 5 Declarative Constraints We now have the machinery to incorporate a variety of declarative constraints during inference. The classes of domain-independent constraints we study are summarized in Table 1. For the proportion constraints we arbitrarily select a threshold of 80% without any tuning, in the spirit of building a domain-independent approach. Syntax As previous work has observed, most relations are expressed using a limited number of common syntactic patterns (Riloff, 1996; Banko and Etzioni, 2008). Our syntactic constraint captures this insight by requiring that a certain proportion of the induced instantiations for each relation match one of these syntactic patterns: • The indicator is a verb and the argument’s headword is either the child or grandchild of the indicator word in the dependency tree. • The indicator is a noun and the argument is a modifier or complement. • The indicator is a noun in a verb’s subject and the argument is in the corresponding object. Prevalence For a relation to be domain-relevant, it should occur in numerous documents across the </context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. Automatically generating extraction patterns from untagged texts. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Rosenfeld</author>
<author>Ronen Feldman</author>
</authors>
<title>Clustering for unsupervised relation identification.</title>
<date>2007</date>
<booktitle>In Proceedings of CIKM.</booktitle>
<contexts>
<context position="6668" citStr="Rosenfeld and Feldman, 2007" startWordPosition="962" endWordPosition="965">neral relation databases from heterogeneous corpora, our focus is on learning the relations salient in a single domain. Our setup is more germane to specialized domains expressing information not broadly available on the web. Earlier work in unsupervised information extraction has also leveraged meta-knowledge independent of specific relation types, such as declarativelyspecified syntactic patterns (Riloff, 1996), frequent dependency subtree patterns (Sudo et al., 2003), and automatic clusterings of syntactic patterns (Lin and Pantel, 2001; Zhang et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative constraints on the output from a set of classifiers trained on local features. Chang et al. (2007) propose an objective function for semi-supervised extrac</context>
</contexts>
<marker>Rosenfeld, Feldman, 2007</marker>
<rawString>Benjamin Rosenfeld and Ronen Feldman. 2007. Clustering for unsupervised relation identification. In Proceedings of CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="7038" citStr="Roth and Yih (2004)" startWordPosition="1015" endWordPosition="1018">ied syntactic patterns (Riloff, 1996), frequent dependency subtree patterns (Sudo et al., 2003), and automatic clusterings of syntactic patterns (Lin and Pantel, 2001; Zhang et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative constraints on the output from a set of classifiers trained on local features. Chang et al. (2007) propose an objective function for semi-supervised extraction that balances likelihood of labeled instances and constraint violation on unlabeled instances. Recent work has also explored how certain kinds of supervision can be formulated as constraints on model posteriors. Such constraints are not declarative, but instead based on annotations of words’ majority relation labels (Mann and McCallum, 2008) and pre-existing data</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>Dan Roth and Wen-tau Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Preemptive information extraction using unrestricted relation discovery.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<contexts>
<context position="5461" citStr="Shinyama and Sekine, 2006" startWordPosition="775" endWordPosition="778">s yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use the word “argument” in the syntactic sense— a relation’s argument may or may not be the syntactic dependency argument of its indicator. We hypothesize that these properties hold across relations in different domains. Second, in contrast to work that builds general relation databa</context>
</contexts>
<marker>Shinyama, Sekine, 2006</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive information extraction using unrestricted relation discovery. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoshi Sudo</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>An improved extraction pattern representation model for automatic IE pattern acquisition.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="6514" citStr="Sudo et al., 2003" startWordPosition="938" endWordPosition="941">nt of its indicator. We hypothesize that these properties hold across relations in different domains. Second, in contrast to work that builds general relation databases from heterogeneous corpora, our focus is on learning the relations salient in a single domain. Our setup is more germane to specialized domains expressing information not broadly available on the web. Earlier work in unsupervised information extraction has also leveraged meta-knowledge independent of specific relation types, such as declarativelyspecified syntactic patterns (Riloff, 1996), frequent dependency subtree patterns (Sudo et al., 2003), and automatic clusterings of syntactic patterns (Lin and Pantel, 2001; Zhang et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative c</context>
</contexts>
<marker>Sudo, Sekine, Grishman, 2003</marker>
<rawString>Kiyoshi Sudo, Satoshi Sekine, and Ralph Grishman. 2003. An improved extraction pattern representation model for automatic IE pattern acquisition. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Ralph Grishman</author>
<author>Pasi Tapanainen</author>
<author>Silja Huttunen</author>
</authors>
<title>Automatic acquisition of domain knowledge for information extraction.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="5155" citStr="Yangarber et al., 2000" startWordPosition="724" endWordPosition="727">demonstrate that we can successfully identify domain-relevant relations. We also study the importance and effectiveness of the declaratively-specified constraints. In particular, we find that a small set of declarative constraints are effective across domains, while additional domainspecific constraints yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good</context>
</contexts>
<marker>Yangarber, Grishman, Tapanainen, Huttunen, 2000</marker>
<rawString>Roman Yangarber, Ralph Grishman, Pasi Tapanainen, and Silja Huttunen. 2000. Automatic acquisition of domain knowledge for information extraction. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Cross-document relation extraction without labelled data.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="5297" citStr="Yao et al., 2010" startWordPosition="749" endWordPosition="752">ied constraints. In particular, we find that a small set of declarative constraints are effective across domains, while additional domainspecific constraints yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use the word “argument” in the syntactic sense— a relation’s argument may or may not be the syntactic dependency argumen</context>
</contexts>
<marker>Yao, Riedel, McCallum, 2010</marker>
<rawString>Limin Yao, Sebastian Riedel, and Andrew McCallum. 2010. Cross-document relation extraction without labelled data. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Oren Etzioni</author>
</authors>
<title>Unsupervised methods for determining object and relation synonyms on the web.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>34--255</pages>
<contexts>
<context position="5507" citStr="Yates and Etzioni, 2009" startWordPosition="783" endWordPosition="786">tion with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use the word “argument” in the syntactic sense— a relation’s argument may or may not be the syntactic dependency argument of its indicator. We hypothesize that these properties hold across relations in different domains. Second, in contrast to work that builds general relation databases from heterogeneous corpora, our focus is o</context>
</contexts>
<marker>Yates, Etzioni, 2009</marker>
<rawString>Alexander Yates and Oren Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal ofArtificial Intelligence Research, 34:255–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jian Su</author>
<author>Danmei Wang</author>
<author>Guodong Zhou</author>
<author>Chew Lim Tan</author>
</authors>
<title>Discovering relations between named entities from a large raw corpus using tree similarity-based clustering.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP.</booktitle>
<contexts>
<context position="6606" citStr="Zhang et al., 2005" startWordPosition="952" endWordPosition="955">t domains. Second, in contrast to work that builds general relation databases from heterogeneous corpora, our focus is on learning the relations salient in a single domain. Our setup is more germane to specialized domains expressing information not broadly available on the web. Earlier work in unsupervised information extraction has also leveraged meta-knowledge independent of specific relation types, such as declarativelyspecified syntactic patterns (Riloff, 1996), frequent dependency subtree patterns (Sudo et al., 2003), and automatic clusterings of syntactic patterns (Lin and Pantel, 2001; Zhang et al., 2005) and contexts (Chen et al., 2005; Rosenfeld and Feldman, 2007). Our approach incorporates a broader range of constraints and balances constraints with underlying patterns learned from the data, thereby requiring more sophisticated machinery for modeling and inference. Extraction with Constraints Previous work has recognized the appeal of applying declarative constraints to extraction. In a supervised setting, Roth and Yih (2004) induce relations by using linear programming to impose global declarative constraints on the output from a set of classifiers trained on local features. Chang et al. (</context>
</contexts>
<marker>Zhang, Su, Wang, Zhou, Tan, 2005</marker>
<rawString>Min Zhang, Jian Su, Danmei Wang, Guodong Zhou, and Chew Lim Tan. 2005. Discovering relations between named entities from a large raw corpus using tree similarity-based clustering. In Proceedings of IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Zaiqing Nie</author>
<author>Xiaojing Liu</author>
<author>Bo Zhang</author>
<author>JiRong Wen</author>
</authors>
<title>StatSnowball: a statistical approach to extracting entity relationships.</title>
<date>2009</date>
<booktitle>In Proceedings of WWW.</booktitle>
<contexts>
<context position="5200" citStr="Zhu et al., 2009" startWordPosition="732" endWordPosition="735">in-relevant relations. We also study the importance and effectiveness of the declaratively-specified constraints. In particular, we find that a small set of declarative constraints are effective across domains, while additional domainspecific constraints yield further benefits. 2 Related Work Extraction with Reduced Supervision Recent research in information extraction has taken large steps toward reducing the need for labeled data. Examples include using bootstrapping to amplify small seed sets of example outputs (Agichtein and Gravano, 2000; Yangarber et al., 2000; Bunescu and Mooney, 2007; Zhu et al., 2009), leveraging existing databases that overlap with the text (Mintz et al., 2009; Yao et al., 2010), and learning general domain-independent knowledge bases by exploiting redundancies in large web and news corpora (Hasegawa et al., 2004; Shinyama and Sekine, 2006; Banko et al., 2007; Yates and Etzioni, 2009). Our approach is distinct in both the supervision and data we operate over. First, in contrast to bootstrapping and database matching approaches, we learn from meta-qualities, such as low variability in syntactic patterns, that characterize a good relation. 2We do not use the word “argument”</context>
</contexts>
<marker>Zhu, Nie, Liu, Zhang, Wen, 2009</marker>
<rawString>Jun Zhu, Zaiqing Nie, Xiaojing Liu, Bo Zhang, and JiRong Wen. 2009. StatSnowball: a statistical approach to extracting entity relationships. In Proceedings of WWW.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>