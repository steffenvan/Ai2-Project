<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003846">
<title confidence="0.99054">
Improving Syntactic Coordination Resolution Using Language Modeling
</title>
<author confidence="0.995485">
Philip V. Ogren
</author>
<affiliation confidence="0.9985945">
Center for Computational Pharmacology
University of Colorado Denver
</affiliation>
<address confidence="0.9897145">
12801 E. 17th Ave
Aurora, CO 80045, USA
</address>
<email confidence="0.998561">
philip@ogren.info
</email>
<sectionHeader confidence="0.995649" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998987555555556">
Determining the correct structure of coordi-
nating conjunctions and the syntactic con-
stituents that they coordinate is a difficult task.
This subtask of syntactic parsing is explored
here for biomedical scientific literature. In
particular, the intuition that sentences contain-
ing coordinating conjunctions can often be
rephrased as two or more smaller sentences
derived from the coordination structure is ex-
ploited. Generating candidate sentences cor-
responding to different possible coordination
structures and comparing them with a lan-
guage model is employed to help determine
which coordination structure is best. This
strategy is used to augment a simple baseline
system for coordination resolution which out-
performs both the baseline system and a con-
stituent parser on the same task.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996758416666667">
For this work, coordination resolution (CR) refers to
the task of automatically identifying the correct co-
ordination structure of coordinating conjunctions. In
this study the conjunctions and and or and the con-
juncts they coordinate are examined. CR is an im-
portant subtask of syntactic parsing in the biomed-
ical domain because many information extraction
tasks require correct syntactic structures to perform
well, in particular coordination structures. For ex-
ample, (Cohen et al., 2009) showed that using a con-
stituent parser trained on biomedical data to provide
coordination structures to a high-precision protein-
protein interaction recognition system resulted in
1
a significant performance boost from an overall F-
measure of 24.7 to 27.6. Coordination structures are
the source of a disproportionate number of parsing
errors for both constituent parsers (Clegg and Shep-
herd, 2007) and dependency parsers (Nivre and Mc-
Donald, 2008).
CR is difficult for a variety of reasons related to
the linguistic complexity of the phenomenon. There
are a number of measurable characteristics of coor-
dination structures that support this claim including
the following: constituent types of conjuncts, num-
ber of words per conjunct, number of conjuncts per
conjunction, and the number of conjunctions that are
nested inside the conjunct of another conjunction,
among others. Each of these metrics reveal wide
variability of coordination structures. For example,
roughly half of all conjuncts consist of one or two
words while the other half consist of three or more
words including 15% of all conjuncts that have ten
or more words. There is also an increased preva-
lence of coordinating conjunctions in biomedical lit-
erature when compared with newswire text. Table 1
lists three corpora in the biomedical domain that are
annotated with deep syntactic structures; CRAFT
(described below), GENIA (Tateisi et al., 2005), and
Penn BIOIE (Bies et al., 2005). The number of co-
ordinating conjunctions they contain as a percentage
of the number of total tokens in each corpus are com-
pared with the Penn Treebank corpus (Marcus et al.,
1994). The salient result from this table is that there
are 50% more conjunctions in biomedical scientific
text than in newswire text. It is also interesting to
note that 15.4% of conjunctions in the biomedical
corpora are nested inside a conjunct of another con-
</bodyText>
<subsectionHeader confidence="0.2338815">
Proceedings of the NAACL HLT 2010 Student Research Workshop, pages 1–6,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.677386">
junction as compared with 10.9% for newswire.
</bodyText>
<tableCaption confidence="0.938783">
Table 1: Biomedical corpora that provide coordination
structures compared with the Penn Treebank corpus.
</tableCaption>
<table confidence="0.998903833333333">
Corpus Tokens Conjunctions
CRAFT 246,008 7,115 2.89%
GENIA 490,970 14,854 3.03%
BIOIE 188,341 5,036 2.67%
subtotal 925,319 27,005 2.92%
PTB 1,173,766 22,888 1.95%
</table>
<bodyText confidence="0.991804888888889">
The Colorado Richly Annotated Full-Text
(CRAFT) Corpus being developed at the Univer-
sity of Colorado Denver was used for this work.
Currently, the corpus consists of 97 full-text open-
access scientific articles that have been annotated by
the Mouse Genome Institute1 with concepts from
the Gene Ontology2 and Mammalian Phenotype
Ontology3. Thirty-six of the articles have been
annotated with deep syntactic structures similar
to that of the Penn Treebank corpus described in
(Marcus et al., 1994). As this is a work in progress,
eight of the articles have been set aside for a final
holdout evaluation and results for these articles
are not reported here. In addition to the standard
treebank annotation, the NML tag discussed in
(Bies et al., 2005) and (Vadas and Curran, 2007)
which marks nominal subconstituents which do
not observe the right-branching structure common
to many (but not all) noun phrases is annotated.
This is of particular importance for coordinated
noun phrases because it provides an unambiguous
representation of the correct coordination structure.
The coordination instances in the CRAFT data
were converted to simplified coordination structures
consisting of conjunctions and their conjuncts using
a script that cleanly translates the vast majority of
coordination structures.
</bodyText>
<sectionHeader confidence="0.999778" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9950275">
There are two main approaches to CR. The first ap-
proach considers CR as a task in its own right where
</bodyText>
<footnote confidence="0.96837425">
1http://www.informatics.jax.org/
2http://geneontology.org/
3http://www.informatics.jax.org/
searches/MP_form.shtml
</footnote>
<bodyText confidence="0.999969479166667">
the solutions are built specifically to perform CR.
Often the task is narrowly defined, e.g. only coor-
dinations of the pattern noun-1 conjunction noun-2
noun-3 are considered, and relies on small training
and testing data sets. Generally, such research ef-
forts do not attempt to compare their results with
previous results other than in the broadest and most-
qualified way. Studies by (Chantree et al., 2005),
(Nakov and Hearst, 2005), and (Resnik, 1999) are
representative examples of such work. A study by
(Shimbo and Hara, 2007) performed CR on sen-
tences from the GENIA corpus containing one in-
stance of the word “and” coordinating noun phrases.
They used a sequence alignment algorithm modified
for CR drawing on the intuition that conjuncts have
similar syntactic constructs. In each of these studies,
promising results were achieved by careful applica-
tion of their respective approaches. However, each
study is limited in important respects because they
narrowly constrain the problem, use limited train-
ing data, and make certain unrealistic assumptions
in their experimental setup that make general appli-
cation of their solutions problematic. For example,
in the study by (Shimbo and Hara, 2007) they chose
only sentences that have one instance of “and” be-
cause their algorithm does not handle nested con-
junctions. Additionally, they assume an oracle that
provides the system with only sentences that contain
coordinated noun phrases.
The work most similar to this study was done by
(Hara et al., 2009) in that they define the CR task
essentially the same as is done here. Their approach
involves a grammar tailored for coordination struc-
tures that is coupled with a sequence alignment al-
gorithm that uses perceptrons for learning feature
weights of an edit graph. The evaluation metric they
use is slightly less strict than the metric used for
this study in that they require identification of the
left boundary of the left-most conjunct and the right
boundary of the right-most conjunct to be counted
correct. Two other important differences are that
the evaluation data comes from the GENIA corpus
and they use gold-standard part-of-speech tags for
the input data. Regardless of these relatively minor
differences, their performance of 61.5 F-measure far
outperforms what is reported below and experiments
that are directly comparable to their work will be
performed.
</bodyText>
<page confidence="0.711792">
2
</page>
<bodyText confidence="0.998764266666666">
The second main approach considers CR within correct conjunct boundary will have a higher proba-
the broader task of syntactic parsing. Any syntac- bility than the other candidate sentences. One prob-
tic parser that generates constituents or dependen- lem with this approach is that the candidate sen-
cies must necessarily perform CR to perform well. tences are different lengths. This has a large and
Typically, a syntactic parser will have a single, cen- undesirable (for this task) impact on the probability
tral algorithm that is used to determine all con- calculation. A simple and effective way to normal-
stituents or dependencies. However, this does not ize for sentence length is by adding4 the probability
preclude parsers from giving special attention to CR of the candidate conjunct (also computed by using
by adding CR-specific rules and features. For exam- the language model) to the probability of the candi-
ple, (Nilsson et al., 2006) show that for dependency date sentence. The probability of each candidate is
parsing it is useful to transform dependency struc- calculated using this simple metric and then rank or-
tures that make conjunctions the head of their con- dered. Because the number of candidate conjuncts
juncts into structures in which coordination depen- varies from one sentence to the next (as determined
dencies are chained. (Charniak and Johnson, 2005) by the token index of the conjunction) it is useful to
discusses a constituent-based parser that adds two translate the rank into a percentile. The rank per-
features to the learning model that directly address centile of the candidate conjuncts will be applied to
coordination. The first measures parallelism in the the task of CR as described below. However, it is
labels of the conjunct constituents and their children informative to directly evaluate how good the rank
and the second measures the lengths of the conjunct percentile scores of the correct conjuncts are.
constituents. The work done by (Hogan, 2007) fo- To build a language model a corpus of more than
cuses directly on coordination of noun phrases in 80,000 full-text open-access scientific articles were
the context of the Collins parser (Collins, 2003) by obtained from PubMed Central5. The articles are
building a right conjunct using features from the al- provided in a simple XML format which was parsed
ready built left conjunct. to produce plain text documents using only sections
3 Using a Language Model of the articles containing contentful prose (i.e. by
Consider the following sentence: excluding sections such as e.g. acknowledgments
Tyr mutation results in increased IOP and and references.) The plain text documents were
altered diurnal changes. automatically sentence segmented, tokenized, and
By exploiting the coordination structure we can part-of-speech tagged resulting in nearly 13 million
rephrase this sentence as two separate sentences: sentences and over 250 million tagged words. A lan-
</bodyText>
<listItem confidence="0.667627">
• Tyr mutation results in increased IOP. guage model was then built using this data with the
• Tyr mutation results in altered diurnal changes. SRILM toolkit described in (Stolcke, 2002). De-
</listItem>
<bodyText confidence="0.9918426">
Using this simple rewrite strategy a candidate sen- fault options were used for creating the language
tence for each possible conjunct can be composed. model except that the order of the model was set to
For this sentence there are six possible left conjuncts four and the “-tagged” option was used. Thus, a 4-
corresponding to each word to the left of the con- gram model with Good-Turing discounting and Katz
junction. For example, the candidate conjunct cor- backoff for smoothing was built.
responding to the third word is results in increased For each token to the left of a conjunction a candi-
IOP and the corresponding sentence rewrite is Tyr date conjunct/sentence pair is derived, its probabil-
mutation altered diurnal changes. The resulting ity calculated, and a rank percentile score is assigned
candidate sentences can be compared by calculat- to it relative to the other candidates. Because mul-
ing a sentence probability using a language model. tiple conjuncts can appear on the left-hand-side of
</bodyText>
<table confidence="0.760145166666667">
Ideally, the candidate sentence corresponding to the the conjunction, the left border of the leftmost con-
3 junct is considered here. The same is done for tokens
4logprobs are used here
5http://www.ncbi.nlm.nih.gov/pmc/about/
ftp.html. The corpus was downloaded in September of
2008.
</table>
<figureCaption confidence="0.9993344">
Figure 1: The first column can be read as “The correct
conjunct candidate had the highest rank percentile 32.1%
of the time.” The second column can be read as “The
correct conjunct candidate had a rank percentile of 90%
or greater 17.6% of the time.” The columns add to one.
</figureCaption>
<bodyText confidence="0.999989075">
be exact. That is, for conjunct level evaluation a
conjunct generated by the system must have exactly
the same extent (i.e. character offsets) as the con-
junct in the gold-standard data in addition to be-
ing attached to the same conjunction. Similarly, at
the conjunction level a true positive requires that a
coordination structure generated by the system has
the same number of conjuncts each with extents ex-
actly the same as the corresponding conjunct in the
gold-standard coordination structure. Where 10-fold
cross-validation is performed, training is performed
on roughly 90% of the data and testing on the re-
maining 10% with the results micro-averaged. Here,
the folds are split at the document level to avoid the
unfair advantage of training and testing on different
sections of the same document.
on the right-hand-side of the conjunction. Figure 1
shows a histogram of the rank percentile scores for
the correct left conjunct. The height of the bars cor-
respond to the percentage of the total number of con-
junctions in which the correct candidate was ranked
within the percentile range. Thus, the columns add
to one and generalizations can be made by adding
the columns together. For example, 66.7% of the
conjunctions (by adding the first three columns) fall
above the eightieth percentile. The overall average
rank percentage for all of the left-hand-side con-
juncts was 81.1%. The median number of candi-
dates on the left-hand-side is 17 (i.e. the median to-
ken index of the conjunction is 17). Similar results
were obtained for the right-hand-side data but were
withheld for space considerations. The overall av-
erage rank percentage for right-hand-side conjuncts
was 82.2%. This slightly better result is likely due
to the smaller median number of candidates on the
right-hand-side of 12 (i.e. the median token index
of the conjunction is 12 from the end of the sen-
tence.) These data suggest that the rank percentile of
the candidate conjuncts calculated in this way could
be an effective feature to use for CR.
</bodyText>
<sectionHeader confidence="0.988584" genericHeader="conclusions">
4 Coordination Resolution
</sectionHeader>
<bodyText confidence="0.99520075">
Table 2 reports the performance of two CR systems
that are described below. Results are reported as F-
Measure at both the conjunct and conjunction lev-
els where a true positive requires all boundaries to
</bodyText>
<tableCaption confidence="0.9565115">
Table 2: Coordination resolution results at the conjunct
and conjunction levels as F-Measure.
</tableCaption>
<table confidence="0.5700888">
Conjunct Conjunction
OpenNLP + PTB 55.46 36.56
OpenNLP + CRAFT 58.87 39.50
baseline 59.75 40.99
baseline + LM 64.64 46.40
</table>
<bodyText confidence="0.9997565">
The first system performs CR within the broader
task of syntactic parsing. Here the constituent parser
from the OpenNLP project6 is applied. This parser
was chosen because of its availability and ease of
use for both training and execution. It has also
been shown by (Buyko et al., 2006) to perform well
on biomedical data. The output of the parser is
processed by the same conversion script described
above. The parser was trained and evaluated on
both the Penn Treebank and CRAFT corpora. For
the latter, 10-fold cross-validation was performed.
Preliminary experiments that attempted to add ad-
ditional training data from the GENIA and Penn
BIOIE corpora proved to be slightly detrimental to
performance in both cases. Table 2 shows that CR
improves at the conjunction level by nearly three
points (from 36.56 to 39.50) by simply training on
biomedical data rather than using a model trained
on newswire.
The second system that performs CR as a separate
</bodyText>
<footnote confidence="0.96766">
6http://opennlp.sf.net
</footnote>
<page confidence="0.99415">
4
</page>
<bodyText confidence="0.9945806">
task by using token-level classification to determine annotator agreement on the CR task, 500 sentences
conjunct boundaries is introduced and evaluated. In containing either the word “and” or “or” were ran-
brief, each token to the left of a conjunction is clas- domly chosen from the 13 million sentence corpus
sified as being either a left-hand border of a conjunct described in Section 3 and annotated with coordi-
for that conjunction or not. Similarly, tokens to the nation structures by two individuals, the author and
right of a conjunction are classified as either a right- another computer scientist with background in biol-
hand border of a conjunct or not. From these token- ogy. Our positive specific agreement8 was 91.93 and
level classifications and some simple assumptions 83.88 at the conjunct and conjunction level, respec-
about the right-hand and left-hand borders of left tively, for 732 conjunctions. This represents a dra-
and right conjuncts, respectively,7 a complete coor- matic gulf between system and human performance
dination structure can be constructed. The classifier on this task but also suggests that large improve-
used was SVMlight described in (Joachims, 1999) ments for automated CR should be expected.
using a linear kernel. The baseline system uses a 5 Future Work
number of shallow lexical features (many common
to named entity recognition systems) including part-
of-speech tags, word and character n-grams, the dis-
tance between the focus token and the conjunction,
and word-level features such as whether the token
is a number or contains a hyphen. A more detailed
description of the baseline system is avoided here as
this remains a major focus of current and future re-
search efforts and the final system will likely change
considerably. Table 2 shows the results of 10-fold
cross-validation for the baseline system. This sim-
ple baseline system performs at 40.99 F-measure at
the conjunction level which is modestly better than
the syntactic parser trained on CRAFT.
The baseline system as described above was aug-
mented using the language modeling approach de-
scribed in Section 3 by adding a simple feature to
each token being classified whose value is the rank
percentile of the probability of the corresponding
conjunct candidate. Again, 10-fold cross-validation
was performed. Table 2 shows that this augmented
baseline system performs at 46.40 F-measure at the
conjunction level which out-performs the baseline
system and the CRAFT-trained parser by 5.4 and 6.9
points, respectively. This increase in performance
demonstrates that a language model can be effec-
tively purposed for CR.
While the use of a language model to improve CR
results is promising, the results in Table 2 also speak
to how difficult this task is for machines to perform.
In contrast, the task is comparatively easy for hu-
mans to perform consistently. To calculate inter-
There is much that can be done to move this work
forward. Creating comparable results to the study
discussed in Section 2 by (Hara et al., 2009) is a top
priority. As alluded to earlier, there is much that can
be done to improve the baseline system. For exam-
ple, constraining coordination structures to not over-
lap except where one is completely nested within
the conjunct of another should be enforced as par-
tially overlapping coordination structures never oc-
cur in the training data. Similarly, a conjunction that
appears inside parentheses should have a coordina-
tion structure that is completely contained inside the
parentheses. Thorough error analysis should also
be performed. For example, it would be interesting
to characterize the conjuncts that have a low rank
percentile for their calculated probability. Also, it
would be useful to measure performance across a
number of metrics such as phrase type of the con-
juncts, length of conjuncts, whether a coordination
structure is nested inside another, etc. Demonstrat-
ing that CR can improve syntactic parsing perfor-
mance and improve the performance of an informa-
tion extraction system would give this work greater
significance.
Conclusion
This work has demonstrated that a language model
can be used to improve performance of a simple CR
system. This is due to the high rank percentile of the
probability of the correct conjunct compared with
other possible conjuncts.
7For example, the left-hand border of the conjunct to the
right of a conjunction will always be the first word following
the conjunction.
8This measure is directly comparable with F-measure.
5
</bodyText>
<sectionHeader confidence="0.986734" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999734059405941">
Ann Bies, Seth Kulick, and Mark Mandel. 2005. Parallel
entity and treebank annotation. In CorpusAnno ’05:
Proceedings of the Workshop on Frontiers in Corpus
Annotations II, pages 21–28, Morristown, NJ, USA.
Association for Computational Linguistics.
Ekaterina Buyko, Joachim Wermter, Michael Poprat, and
Udo Hahn. 2006. Automatically adapting an NLP
core engine to the biology domain. In Proceedings
of the Joint BioLINK-Bio-Ontologies Meeting. A Joint
Meeting of the ISMB Special Interest Group on Bio-
Ontologies and the BioLINK Special Interest Group on
Text Data M ining in Association with ISMB, pages
65–68. Citeseer.
Francis Chantree, Adam Kilgarriff, Anne De Roeck, and
Alistair Willis. 2005. Disambiguating coordinations
using word distribution information. Proceedings of
RANLP2005.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL’05),
pages 173–180, Ann Arbor, Michigan, June. Associa-
tion for Computational Linguistics.
Andrew Clegg and Adrian Shepherd. 2007. Bench-
marking natural-language parsers for biological appli-
cations using dependency graphs. BMC Bioinformat-
ics, 8(1):24.
Kevin B. Cohen, Karin Verspoor, Helen L. Johnson,
Chris Roeder, Philip V. Ogren, William A. Baumgart-
ner Jr, Elizabeth White, Hannah Tipney, and Lawrence
Hunter. 2009. High-precision biological event extrac-
tion with a concept recognizer. In Proceedings of the
Workshop on BioNLP: Shared Task, pages 50–58. As-
sociation for Computational Linguistics.
Michael Collins. 2003. Head-driven statistical models
for natural language parsing. Computational linguis-
tics, 29(4):589–637.
Kazuo Hara, Masashi Shimbo, Hideharu Okuma, and
Yuji Matsumoto. 2009. Coordinate structure analysis
with global structural constraints and alignment-based
local features. In ACL-IJCNLP ’09: Proceedings of
the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Volume
2, pages 967–975, Morristown, NJ, USA. Association
for Computational Linguistics.
Deirdre Hogan. 2007. Coordinate noun phrase disam-
biguation in a generative parsing model. In Proceed-
ings of the 45th Annual Meeting of the Association
of Computational Linguistics, pages 680–687, Prague,
Czech Republic, June. Association for Computational
Linguistics.
Thorsten Joachims. 1999. Making large scale SVM
learning practical.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated cor-
pus of English: The Penn Treebank. Computational
linguistics, 19(2):313–330.
Preslav Nakov and Marti Hearst. 2005. Using the web as
an implicit training set: Application to structural ambi-
guity resolution. In Proceedings of Human Language
Technology Conference and Conference on Empirical
Methods in Natural Language Processing, pages 835–
842, Vancouver, British Columbia, Canada, October.
Association for Computational Linguistics.
Jens Nilsson, Joakim Nivre, and Johan Hall. 2006.
Graph transformations in data-driven dependency
parsing. In Proceedings of the 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the Association for Computational Linguis-
tics, pages 257–264, Sydney, Australia, July. Associa-
tion for Computational Linguistics.
Joakim Nivre and Ryan McDonald. 2008. Integrating
graph-based and transition-based dependency parsers.
In Proceedings of ACL-08: HLT, pages 950–958,
Columbus, Ohio, June. Association for Computational
Linguistics.
Philip Resnik. 1999. Semantic similarity in a Taxonomy:
An Information-Based Measure and its Application to
Problems of Ambiguity in Natural Language. Journal
of Artificial Intelligence, 11(11):95–130.
Masashi Shimbo and Kazuo Hara. 2007. A discrim-
inative learning model for coordinate conjunctions.
In Proceedings of the 2007 Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), pages 610–619.
Andreas Stolcke. 2002. SRILM-an extensible language
modeling toolkit. In Seventh International Conference
on Spoken Language Processing, volume 3. Citeseer.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Ju-
nichi Tsujii. 2005. Syntax Annotation for the GE-
NIA corpus. In Second International Joint Conference
on Natural Language Processing (IJCNLP05), pages
222–227.
David Vadas and James Curran. 2007. Adding noun
phrase structure to the penn treebank. In Proceed-
ings of the 45th Annual Meeting of the Association
of Computational Linguistics, pages 240–247, Prague,
Czech Republic, June. Association for Computational
Linguistics.
</reference>
<page confidence="0.998755">
6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.929728">
<title confidence="0.999985">Improving Syntactic Coordination Resolution Using Language Modeling</title>
<author confidence="0.999854">V Philip</author>
<affiliation confidence="0.99938">Center for Computational University of Colorado</affiliation>
<address confidence="0.98839">12801 E. 17th Aurora, CO 80045,</address>
<email confidence="0.98924">philip@ogren.info</email>
<abstract confidence="0.997695">Determining the correct structure of coordinating conjunctions and the syntactic constituents that they coordinate is a difficult task. This subtask of syntactic parsing is explored here for biomedical scientific literature. In particular, the intuition that sentences containing coordinating conjunctions can often be rephrased as two or more smaller sentences derived from the coordination structure is exploited. Generating candidate sentences corresponding to different possible coordination structures and comparing them with a language model is employed to help determine which coordination structure is best. This strategy is used to augment a simple baseline system for coordination resolution which outperforms both the baseline system and a constituent parser on the same task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Seth Kulick</author>
<author>Mark Mandel</author>
</authors>
<title>Parallel entity and treebank annotation.</title>
<date>2005</date>
<booktitle>In CorpusAnno ’05: Proceedings of the Workshop on Frontiers in Corpus Annotations II,</booktitle>
<pages>21--28</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2961" citStr="Bies et al., 2005" startWordPosition="444" endWordPosition="447">nct of another conjunction, among others. Each of these metrics reveal wide variability of coordination structures. For example, roughly half of all conjuncts consist of one or two words while the other half consist of three or more words including 15% of all conjuncts that have ten or more words. There is also an increased prevalence of coordinating conjunctions in biomedical literature when compared with newswire text. Table 1 lists three corpora in the biomedical domain that are annotated with deep syntactic structures; CRAFT (described below), GENIA (Tateisi et al., 2005), and Penn BIOIE (Bies et al., 2005). The number of coordinating conjunctions they contain as a percentage of the number of total tokens in each corpus are compared with the Penn Treebank corpus (Marcus et al., 1994). The salient result from this table is that there are 50% more conjunctions in biomedical scientific text than in newswire text. It is also interesting to note that 15.4% of conjunctions in the biomedical corpora are nested inside a conjunct of another conProceedings of the NAACL HLT 2010 Student Research Workshop, pages 1–6, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics juncti</context>
<context position="4617" citStr="Bies et al., 2005" startWordPosition="705" endWordPosition="708">. Currently, the corpus consists of 97 full-text openaccess scientific articles that have been annotated by the Mouse Genome Institute1 with concepts from the Gene Ontology2 and Mammalian Phenotype Ontology3. Thirty-six of the articles have been annotated with deep syntactic structures similar to that of the Penn Treebank corpus described in (Marcus et al., 1994). As this is a work in progress, eight of the articles have been set aside for a final holdout evaluation and results for these articles are not reported here. In addition to the standard treebank annotation, the NML tag discussed in (Bies et al., 2005) and (Vadas and Curran, 2007) which marks nominal subconstituents which do not observe the right-branching structure common to many (but not all) noun phrases is annotated. This is of particular importance for coordinated noun phrases because it provides an unambiguous representation of the correct coordination structure. The coordination instances in the CRAFT data were converted to simplified coordination structures consisting of conjunctions and their conjuncts using a script that cleanly translates the vast majority of coordination structures. 2 Related Work There are two main approaches t</context>
</contexts>
<marker>Bies, Kulick, Mandel, 2005</marker>
<rawString>Ann Bies, Seth Kulick, and Mark Mandel. 2005. Parallel entity and treebank annotation. In CorpusAnno ’05: Proceedings of the Workshop on Frontiers in Corpus Annotations II, pages 21–28, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Buyko</author>
<author>Joachim Wermter</author>
<author>Michael Poprat</author>
<author>Udo Hahn</author>
</authors>
<title>Automatically adapting an NLP core engine to the biology domain.</title>
<date>2006</date>
<booktitle>In Proceedings of the Joint BioLINK-Bio-Ontologies Meeting. A Joint Meeting of the ISMB Special Interest Group on BioOntologies and the BioLINK Special Interest Group on Text Data M ining in Association with ISMB,</booktitle>
<pages>65--68</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="15247" citStr="Buyko et al., 2006" startWordPosition="2396" endWordPosition="2399">e reported as FMeasure at both the conjunct and conjunction levels where a true positive requires all boundaries to Table 2: Coordination resolution results at the conjunct and conjunction levels as F-Measure. Conjunct Conjunction OpenNLP + PTB 55.46 36.56 OpenNLP + CRAFT 58.87 39.50 baseline 59.75 40.99 baseline + LM 64.64 46.40 The first system performs CR within the broader task of syntactic parsing. Here the constituent parser from the OpenNLP project6 is applied. This parser was chosen because of its availability and ease of use for both training and execution. It has also been shown by (Buyko et al., 2006) to perform well on biomedical data. The output of the parser is processed by the same conversion script described above. The parser was trained and evaluated on both the Penn Treebank and CRAFT corpora. For the latter, 10-fold cross-validation was performed. Preliminary experiments that attempted to add additional training data from the GENIA and Penn BIOIE corpora proved to be slightly detrimental to performance in both cases. Table 2 shows that CR improves at the conjunction level by nearly three points (from 36.56 to 39.50) by simply training on biomedical data rather than using a model tr</context>
</contexts>
<marker>Buyko, Wermter, Poprat, Hahn, 2006</marker>
<rawString>Ekaterina Buyko, Joachim Wermter, Michael Poprat, and Udo Hahn. 2006. Automatically adapting an NLP core engine to the biology domain. In Proceedings of the Joint BioLINK-Bio-Ontologies Meeting. A Joint Meeting of the ISMB Special Interest Group on BioOntologies and the BioLINK Special Interest Group on Text Data M ining in Association with ISMB, pages 65–68. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Chantree</author>
<author>Adam Kilgarriff</author>
<author>Anne De Roeck</author>
<author>Alistair Willis</author>
</authors>
<title>Disambiguating coordinations using word distribution information.</title>
<date>2005</date>
<booktitle>Proceedings of RANLP2005.</booktitle>
<marker>Chantree, Kilgarriff, De Roeck, Willis, 2005</marker>
<rawString>Francis Chantree, Adam Kilgarriff, Anne De Roeck, and Alistair Willis. 2005. Disambiguating coordinations using word distribution information. Proceedings of RANLP2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-tofine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="9161" citStr="Charniak and Johnson, 2005" startWordPosition="1409" endWordPosition="1412">tion to CR of the candidate conjunct (also computed by using by adding CR-specific rules and features. For exam- the language model) to the probability of the candiple, (Nilsson et al., 2006) show that for dependency date sentence. The probability of each candidate is parsing it is useful to transform dependency struc- calculated using this simple metric and then rank ortures that make conjunctions the head of their con- dered. Because the number of candidate conjuncts juncts into structures in which coordination depen- varies from one sentence to the next (as determined dencies are chained. (Charniak and Johnson, 2005) by the token index of the conjunction) it is useful to discusses a constituent-based parser that adds two translate the rank into a percentile. The rank perfeatures to the learning model that directly address centile of the candidate conjuncts will be applied to coordination. The first measures parallelism in the the task of CR as described below. However, it is labels of the conjunct constituents and their children informative to directly evaluate how good the rank and the second measures the lengths of the conjunct percentile scores of the correct conjuncts are. constituents. The work done </context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 173–180, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Clegg</author>
<author>Adrian Shepherd</author>
</authors>
<title>Benchmarking natural-language parsers for biological applications using dependency graphs.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="1907" citStr="Clegg and Shepherd, 2007" startWordPosition="276" endWordPosition="280">rtant subtask of syntactic parsing in the biomedical domain because many information extraction tasks require correct syntactic structures to perform well, in particular coordination structures. For example, (Cohen et al., 2009) showed that using a constituent parser trained on biomedical data to provide coordination structures to a high-precision proteinprotein interaction recognition system resulted in 1 a significant performance boost from an overall Fmeasure of 24.7 to 27.6. Coordination structures are the source of a disproportionate number of parsing errors for both constituent parsers (Clegg and Shepherd, 2007) and dependency parsers (Nivre and McDonald, 2008). CR is difficult for a variety of reasons related to the linguistic complexity of the phenomenon. There are a number of measurable characteristics of coordination structures that support this claim including the following: constituent types of conjuncts, number of words per conjunct, number of conjuncts per conjunction, and the number of conjunctions that are nested inside the conjunct of another conjunction, among others. Each of these metrics reveal wide variability of coordination structures. For example, roughly half of all conjuncts consi</context>
</contexts>
<marker>Clegg, Shepherd, 2007</marker>
<rawString>Andrew Clegg and Adrian Shepherd. 2007. Benchmarking natural-language parsers for biological applications using dependency graphs. BMC Bioinformatics, 8(1):24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin B Cohen</author>
<author>Karin Verspoor</author>
<author>Helen L Johnson</author>
<author>Chris Roeder</author>
<author>Philip V Ogren</author>
<author>William A Baumgartner Jr</author>
<author>Elizabeth White</author>
<author>Hannah Tipney</author>
<author>Lawrence Hunter</author>
</authors>
<title>High-precision biological event extraction with a concept recognizer.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on BioNLP: Shared Task,</booktitle>
<pages>50--58</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1510" citStr="Cohen et al., 2009" startWordPosition="217" endWordPosition="220">m for coordination resolution which outperforms both the baseline system and a constituent parser on the same task. 1 Introduction For this work, coordination resolution (CR) refers to the task of automatically identifying the correct coordination structure of coordinating conjunctions. In this study the conjunctions and and or and the conjuncts they coordinate are examined. CR is an important subtask of syntactic parsing in the biomedical domain because many information extraction tasks require correct syntactic structures to perform well, in particular coordination structures. For example, (Cohen et al., 2009) showed that using a constituent parser trained on biomedical data to provide coordination structures to a high-precision proteinprotein interaction recognition system resulted in 1 a significant performance boost from an overall Fmeasure of 24.7 to 27.6. Coordination structures are the source of a disproportionate number of parsing errors for both constituent parsers (Clegg and Shepherd, 2007) and dependency parsers (Nivre and McDonald, 2008). CR is difficult for a variety of reasons related to the linguistic complexity of the phenomenon. There are a number of measurable characteristics of co</context>
</contexts>
<marker>Cohen, Verspoor, Johnson, Roeder, Ogren, Jr, White, Tipney, Hunter, 2009</marker>
<rawString>Kevin B. Cohen, Karin Verspoor, Helen L. Johnson, Chris Roeder, Philip V. Ogren, William A. Baumgartner Jr, Elizabeth White, Hannah Tipney, and Lawrence Hunter. 2009. High-precision biological event extraction with a concept recognizer. In Proceedings of the Workshop on BioNLP: Shared Task, pages 50–58. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<booktitle>Computational linguistics,</booktitle>
<pages>29--4</pages>
<contexts>
<context position="9983" citStr="Collins, 2003" startWordPosition="1544" endWordPosition="1545">s centile of the candidate conjuncts will be applied to coordination. The first measures parallelism in the the task of CR as described below. However, it is labels of the conjunct constituents and their children informative to directly evaluate how good the rank and the second measures the lengths of the conjunct percentile scores of the correct conjuncts are. constituents. The work done by (Hogan, 2007) fo- To build a language model a corpus of more than cuses directly on coordination of noun phrases in 80,000 full-text open-access scientific articles were the context of the Collins parser (Collins, 2003) by obtained from PubMed Central5. The articles are building a right conjunct using features from the al- provided in a simple XML format which was parsed ready built left conjunct. to produce plain text documents using only sections 3 Using a Language Model of the articles containing contentful prose (i.e. by Consider the following sentence: excluding sections such as e.g. acknowledgments Tyr mutation results in increased IOP and and references.) The plain text documents were altered diurnal changes. automatically sentence segmented, tokenized, and By exploiting the coordination structure we </context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Michael Collins. 2003. Head-driven statistical models for natural language parsing. Computational linguistics, 29(4):589–637.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kazuo Hara</author>
<author>Masashi Shimbo</author>
<author>Hideharu Okuma</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Coordinate structure analysis with global structural constraints and alignment-based local features. In</title>
<date>2009</date>
<booktitle>ACL-IJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>2</volume>
<pages>967--975</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6911" citStr="Hara et al., 2009" startWordPosition="1050" endWordPosition="1053">s. However, each study is limited in important respects because they narrowly constrain the problem, use limited training data, and make certain unrealistic assumptions in their experimental setup that make general application of their solutions problematic. For example, in the study by (Shimbo and Hara, 2007) they chose only sentences that have one instance of “and” because their algorithm does not handle nested conjunctions. Additionally, they assume an oracle that provides the system with only sentences that contain coordinated noun phrases. The work most similar to this study was done by (Hara et al., 2009) in that they define the CR task essentially the same as is done here. Their approach involves a grammar tailored for coordination structures that is coupled with a sequence alignment algorithm that uses perceptrons for learning feature weights of an edit graph. The evaluation metric they use is slightly less strict than the metric used for this study in that they require identification of the left boundary of the left-most conjunct and the right boundary of the right-most conjunct to be counted correct. Two other important differences are that the evaluation data comes from the GENIA corpus a</context>
<context position="18960" citStr="Hara et al., 2009" startWordPosition="2994" endWordPosition="2997">ction level which out-performs the baseline system and the CRAFT-trained parser by 5.4 and 6.9 points, respectively. This increase in performance demonstrates that a language model can be effectively purposed for CR. While the use of a language model to improve CR results is promising, the results in Table 2 also speak to how difficult this task is for machines to perform. In contrast, the task is comparatively easy for humans to perform consistently. To calculate interThere is much that can be done to move this work forward. Creating comparable results to the study discussed in Section 2 by (Hara et al., 2009) is a top priority. As alluded to earlier, there is much that can be done to improve the baseline system. For example, constraining coordination structures to not overlap except where one is completely nested within the conjunct of another should be enforced as partially overlapping coordination structures never occur in the training data. Similarly, a conjunction that appears inside parentheses should have a coordination structure that is completely contained inside the parentheses. Thorough error analysis should also be performed. For example, it would be interesting to characterize the conj</context>
</contexts>
<marker>Hara, Shimbo, Okuma, Matsumoto, 2009</marker>
<rawString>Kazuo Hara, Masashi Shimbo, Hideharu Okuma, and Yuji Matsumoto. 2009. Coordinate structure analysis with global structural constraints and alignment-based local features. In ACL-IJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2, pages 967–975, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deirdre Hogan</author>
</authors>
<title>Coordinate noun phrase disambiguation in a generative parsing model.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>680--687</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="9777" citStr="Hogan, 2007" startWordPosition="1511" endWordPosition="1512">the token index of the conjunction) it is useful to discusses a constituent-based parser that adds two translate the rank into a percentile. The rank perfeatures to the learning model that directly address centile of the candidate conjuncts will be applied to coordination. The first measures parallelism in the the task of CR as described below. However, it is labels of the conjunct constituents and their children informative to directly evaluate how good the rank and the second measures the lengths of the conjunct percentile scores of the correct conjuncts are. constituents. The work done by (Hogan, 2007) fo- To build a language model a corpus of more than cuses directly on coordination of noun phrases in 80,000 full-text open-access scientific articles were the context of the Collins parser (Collins, 2003) by obtained from PubMed Central5. The articles are building a right conjunct using features from the al- provided in a simple XML format which was parsed ready built left conjunct. to produce plain text documents using only sections 3 Using a Language Model of the articles containing contentful prose (i.e. by Consider the following sentence: excluding sections such as e.g. acknowledgments T</context>
</contexts>
<marker>Hogan, 2007</marker>
<rawString>Deirdre Hogan. 2007. Coordinate noun phrase disambiguation in a generative parsing model. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 680–687, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large scale SVM learning practical.</title>
<date>1999</date>
<contexts>
<context position="17126" citStr="Joachims, 1999" startWordPosition="2696" endWordPosition="2697">right- another computer scientist with background in biolhand border of a conjunct or not. From these token- ogy. Our positive specific agreement8 was 91.93 and level classifications and some simple assumptions 83.88 at the conjunct and conjunction level, respecabout the right-hand and left-hand borders of left tively, for 732 conjunctions. This represents a draand right conjuncts, respectively,7 a complete coor- matic gulf between system and human performance dination structure can be constructed. The classifier on this task but also suggests that large improveused was SVMlight described in (Joachims, 1999) ments for automated CR should be expected. using a linear kernel. The baseline system uses a 5 Future Work number of shallow lexical features (many common to named entity recognition systems) including partof-speech tags, word and character n-grams, the distance between the focus token and the conjunction, and word-level features such as whether the token is a number or contains a hyphen. A more detailed description of the baseline system is avoided here as this remains a major focus of current and future research efforts and the final system will likely change considerably. Table 2 shows the</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large scale SVM learning practical.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational linguistics,</title>
<date>1994</date>
<contexts>
<context position="3141" citStr="Marcus et al., 1994" startWordPosition="476" endWordPosition="479">wo words while the other half consist of three or more words including 15% of all conjuncts that have ten or more words. There is also an increased prevalence of coordinating conjunctions in biomedical literature when compared with newswire text. Table 1 lists three corpora in the biomedical domain that are annotated with deep syntactic structures; CRAFT (described below), GENIA (Tateisi et al., 2005), and Penn BIOIE (Bies et al., 2005). The number of coordinating conjunctions they contain as a percentage of the number of total tokens in each corpus are compared with the Penn Treebank corpus (Marcus et al., 1994). The salient result from this table is that there are 50% more conjunctions in biomedical scientific text than in newswire text. It is also interesting to note that 15.4% of conjunctions in the biomedical corpora are nested inside a conjunct of another conProceedings of the NAACL HLT 2010 Student Research Workshop, pages 1–6, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics junction as compared with 10.9% for newswire. Table 1: Biomedical corpora that provide coordination structures compared with the Penn Treebank corpus. Corpus Tokens Conjunctions CRAFT 24</context>
<context position="4364" citStr="Marcus et al., 1994" startWordPosition="660" endWordPosition="663">08 7,115 2.89% GENIA 490,970 14,854 3.03% BIOIE 188,341 5,036 2.67% subtotal 925,319 27,005 2.92% PTB 1,173,766 22,888 1.95% The Colorado Richly Annotated Full-Text (CRAFT) Corpus being developed at the University of Colorado Denver was used for this work. Currently, the corpus consists of 97 full-text openaccess scientific articles that have been annotated by the Mouse Genome Institute1 with concepts from the Gene Ontology2 and Mammalian Phenotype Ontology3. Thirty-six of the articles have been annotated with deep syntactic structures similar to that of the Penn Treebank corpus described in (Marcus et al., 1994). As this is a work in progress, eight of the articles have been set aside for a final holdout evaluation and results for these articles are not reported here. In addition to the standard treebank annotation, the NML tag discussed in (Bies et al., 2005) and (Vadas and Curran, 2007) which marks nominal subconstituents which do not observe the right-branching structure common to many (but not all) noun phrases is annotated. This is of particular importance for coordinated noun phrases because it provides an unambiguous representation of the correct coordination structure. The coordination instan</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of English: The Penn Treebank. Computational linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Marti Hearst</author>
</authors>
<title>Using the web as an implicit training set: Application to structural ambiguity resolution.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>835--842</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="5836" citStr="Nakov and Hearst, 2005" startWordPosition="880" endWordPosition="883">es to CR. The first approach considers CR as a task in its own right where 1http://www.informatics.jax.org/ 2http://geneontology.org/ 3http://www.informatics.jax.org/ searches/MP_form.shtml the solutions are built specifically to perform CR. Often the task is narrowly defined, e.g. only coordinations of the pattern noun-1 conjunction noun-2 noun-3 are considered, and relies on small training and testing data sets. Generally, such research efforts do not attempt to compare their results with previous results other than in the broadest and mostqualified way. Studies by (Chantree et al., 2005), (Nakov and Hearst, 2005), and (Resnik, 1999) are representative examples of such work. A study by (Shimbo and Hara, 2007) performed CR on sentences from the GENIA corpus containing one instance of the word “and” coordinating noun phrases. They used a sequence alignment algorithm modified for CR drawing on the intuition that conjuncts have similar syntactic constructs. In each of these studies, promising results were achieved by careful application of their respective approaches. However, each study is limited in important respects because they narrowly constrain the problem, use limited training data, and make certai</context>
</contexts>
<marker>Nakov, Hearst, 2005</marker>
<rawString>Preslav Nakov and Marti Hearst. 2005. Using the web as an implicit training set: Application to structural ambiguity resolution. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 835– 842, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
</authors>
<title>Graph transformations in data-driven dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>257--264</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="8725" citStr="Nilsson et al., 2006" startWordPosition="1341" endWordPosition="1344">form CR to perform well. tences are different lengths. This has a large and Typically, a syntactic parser will have a single, cen- undesirable (for this task) impact on the probability tral algorithm that is used to determine all con- calculation. A simple and effective way to normalstituents or dependencies. However, this does not ize for sentence length is by adding4 the probability preclude parsers from giving special attention to CR of the candidate conjunct (also computed by using by adding CR-specific rules and features. For exam- the language model) to the probability of the candiple, (Nilsson et al., 2006) show that for dependency date sentence. The probability of each candidate is parsing it is useful to transform dependency struc- calculated using this simple metric and then rank ortures that make conjunctions the head of their con- dered. Because the number of candidate conjuncts juncts into structures in which coordination depen- varies from one sentence to the next (as determined dencies are chained. (Charniak and Johnson, 2005) by the token index of the conjunction) it is useful to discusses a constituent-based parser that adds two translate the rank into a percentile. The rank perfeature</context>
</contexts>
<marker>Nilsson, Nivre, Hall, 2006</marker>
<rawString>Jens Nilsson, Joakim Nivre, and Johan Hall. 2006. Graph transformations in data-driven dependency parsing. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 257–264, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graph-based and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>950--958</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="1957" citStr="Nivre and McDonald, 2008" startWordPosition="284" endWordPosition="288">al domain because many information extraction tasks require correct syntactic structures to perform well, in particular coordination structures. For example, (Cohen et al., 2009) showed that using a constituent parser trained on biomedical data to provide coordination structures to a high-precision proteinprotein interaction recognition system resulted in 1 a significant performance boost from an overall Fmeasure of 24.7 to 27.6. Coordination structures are the source of a disproportionate number of parsing errors for both constituent parsers (Clegg and Shepherd, 2007) and dependency parsers (Nivre and McDonald, 2008). CR is difficult for a variety of reasons related to the linguistic complexity of the phenomenon. There are a number of measurable characteristics of coordination structures that support this claim including the following: constituent types of conjuncts, number of words per conjunct, number of conjuncts per conjunction, and the number of conjunctions that are nested inside the conjunct of another conjunction, among others. Each of these metrics reveal wide variability of coordination structures. For example, roughly half of all conjuncts consist of one or two words while the other half consis</context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proceedings of ACL-08: HLT, pages 950–958, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language.</title>
<date>1999</date>
<journal>Journal of Artificial Intelligence,</journal>
<volume>11</volume>
<issue>11</issue>
<contexts>
<context position="5856" citStr="Resnik, 1999" startWordPosition="885" endWordPosition="886">onsiders CR as a task in its own right where 1http://www.informatics.jax.org/ 2http://geneontology.org/ 3http://www.informatics.jax.org/ searches/MP_form.shtml the solutions are built specifically to perform CR. Often the task is narrowly defined, e.g. only coordinations of the pattern noun-1 conjunction noun-2 noun-3 are considered, and relies on small training and testing data sets. Generally, such research efforts do not attempt to compare their results with previous results other than in the broadest and mostqualified way. Studies by (Chantree et al., 2005), (Nakov and Hearst, 2005), and (Resnik, 1999) are representative examples of such work. A study by (Shimbo and Hara, 2007) performed CR on sentences from the GENIA corpus containing one instance of the word “and” coordinating noun phrases. They used a sequence alignment algorithm modified for CR drawing on the intuition that conjuncts have similar syntactic constructs. In each of these studies, promising results were achieved by careful application of their respective approaches. However, each study is limited in important respects because they narrowly constrain the problem, use limited training data, and make certain unrealistic assump</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Semantic similarity in a Taxonomy: An Information-Based Measure and its Application to Problems of Ambiguity in Natural Language. Journal of Artificial Intelligence, 11(11):95–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masashi Shimbo</author>
<author>Kazuo Hara</author>
</authors>
<title>A discriminative learning model for coordinate conjunctions.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>610--619</pages>
<contexts>
<context position="5933" citStr="Shimbo and Hara, 2007" startWordPosition="896" endWordPosition="899">.jax.org/ 2http://geneontology.org/ 3http://www.informatics.jax.org/ searches/MP_form.shtml the solutions are built specifically to perform CR. Often the task is narrowly defined, e.g. only coordinations of the pattern noun-1 conjunction noun-2 noun-3 are considered, and relies on small training and testing data sets. Generally, such research efforts do not attempt to compare their results with previous results other than in the broadest and mostqualified way. Studies by (Chantree et al., 2005), (Nakov and Hearst, 2005), and (Resnik, 1999) are representative examples of such work. A study by (Shimbo and Hara, 2007) performed CR on sentences from the GENIA corpus containing one instance of the word “and” coordinating noun phrases. They used a sequence alignment algorithm modified for CR drawing on the intuition that conjuncts have similar syntactic constructs. In each of these studies, promising results were achieved by careful application of their respective approaches. However, each study is limited in important respects because they narrowly constrain the problem, use limited training data, and make certain unrealistic assumptions in their experimental setup that make general application of their solu</context>
</contexts>
<marker>Shimbo, Hara, 2007</marker>
<rawString>Masashi Shimbo and Kazuo Hara. 2007. A discriminative learning model for coordinate conjunctions. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 610–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Seventh International Conference on Spoken Language Processing,</booktitle>
<volume>3</volume>
<publisher>Citeseer.</publisher>
<contexts>
<context position="10926" citStr="Stolcke, 2002" startWordPosition="1688" endWordPosition="1689">owing sentence: excluding sections such as e.g. acknowledgments Tyr mutation results in increased IOP and and references.) The plain text documents were altered diurnal changes. automatically sentence segmented, tokenized, and By exploiting the coordination structure we can part-of-speech tagged resulting in nearly 13 million rephrase this sentence as two separate sentences: sentences and over 250 million tagged words. A lan• Tyr mutation results in increased IOP. guage model was then built using this data with the • Tyr mutation results in altered diurnal changes. SRILM toolkit described in (Stolcke, 2002). DeUsing this simple rewrite strategy a candidate sen- fault options were used for creating the language tence for each possible conjunct can be composed. model except that the order of the model was set to For this sentence there are six possible left conjuncts four and the “-tagged” option was used. Thus, a 4- corresponding to each word to the left of the con- gram model with Good-Turing discounting and Katz junction. For example, the candidate conjunct cor- backoff for smoothing was built. responding to the third word is results in increased For each token to the left of a conjunction a ca</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM-an extensible language modeling toolkit. In Seventh International Conference on Spoken Language Processing, volume 3. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuka Tateisi</author>
<author>Akane Yakushiji</author>
<author>Tomoko Ohta</author>
<author>Junichi Tsujii</author>
</authors>
<title>Syntax Annotation for the GENIA corpus.</title>
<date>2005</date>
<booktitle>In Second International Joint Conference on Natural Language Processing (IJCNLP05),</booktitle>
<pages>222--227</pages>
<contexts>
<context position="2925" citStr="Tateisi et al., 2005" startWordPosition="437" endWordPosition="440">ctions that are nested inside the conjunct of another conjunction, among others. Each of these metrics reveal wide variability of coordination structures. For example, roughly half of all conjuncts consist of one or two words while the other half consist of three or more words including 15% of all conjuncts that have ten or more words. There is also an increased prevalence of coordinating conjunctions in biomedical literature when compared with newswire text. Table 1 lists three corpora in the biomedical domain that are annotated with deep syntactic structures; CRAFT (described below), GENIA (Tateisi et al., 2005), and Penn BIOIE (Bies et al., 2005). The number of coordinating conjunctions they contain as a percentage of the number of total tokens in each corpus are compared with the Penn Treebank corpus (Marcus et al., 1994). The salient result from this table is that there are 50% more conjunctions in biomedical scientific text than in newswire text. It is also interesting to note that 15.4% of conjunctions in the biomedical corpora are nested inside a conjunct of another conProceedings of the NAACL HLT 2010 Student Research Workshop, pages 1–6, Los Angeles, California, June 2010. c�2010 Association </context>
</contexts>
<marker>Tateisi, Yakushiji, Ohta, Tsujii, 2005</marker>
<rawString>Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Junichi Tsujii. 2005. Syntax Annotation for the GENIA corpus. In Second International Joint Conference on Natural Language Processing (IJCNLP05), pages 222–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vadas</author>
<author>James Curran</author>
</authors>
<title>Adding noun phrase structure to the penn treebank.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>240--247</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="4646" citStr="Vadas and Curran, 2007" startWordPosition="710" endWordPosition="713">consists of 97 full-text openaccess scientific articles that have been annotated by the Mouse Genome Institute1 with concepts from the Gene Ontology2 and Mammalian Phenotype Ontology3. Thirty-six of the articles have been annotated with deep syntactic structures similar to that of the Penn Treebank corpus described in (Marcus et al., 1994). As this is a work in progress, eight of the articles have been set aside for a final holdout evaluation and results for these articles are not reported here. In addition to the standard treebank annotation, the NML tag discussed in (Bies et al., 2005) and (Vadas and Curran, 2007) which marks nominal subconstituents which do not observe the right-branching structure common to many (but not all) noun phrases is annotated. This is of particular importance for coordinated noun phrases because it provides an unambiguous representation of the correct coordination structure. The coordination instances in the CRAFT data were converted to simplified coordination structures consisting of conjunctions and their conjuncts using a script that cleanly translates the vast majority of coordination structures. 2 Related Work There are two main approaches to CR. The first approach cons</context>
</contexts>
<marker>Vadas, Curran, 2007</marker>
<rawString>David Vadas and James Curran. 2007. Adding noun phrase structure to the penn treebank. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 240–247, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>