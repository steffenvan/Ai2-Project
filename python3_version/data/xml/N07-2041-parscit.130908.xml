<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.044636">
<title confidence="0.9987125">
Simultaneous Identification of Biomedical Named-Entity and
Functional Relations Using Statistical Parsing Techniques �
</title>
<author confidence="0.996684">
Zhongmin Shi and Anoop Sarkar and Fred Popowich
</author>
<affiliation confidence="0.9784435">
School of Computing Science
Simon Fraser University
</affiliation>
<email confidence="0.965556">
{zshi1,anoop,popowich}@cs.sfu.ca
</email>
<sectionHeader confidence="0.993173" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999168588235294">
In this paper we propose a statistical pars-
ing technique that simultaneously iden-
tifies biomedical named-entities (NEs)
and extracts subcellular localization re-
lations for bacterial proteins from the
text in MEDLINE articles. We build
a parser that derives both syntactic and
domain-dependent semantic information
and achieves an F-score of 48.4% for the
relation extraction task. We then propose
a semi-supervised approach that incor-
porates noisy automatically labeled data
to improve the F-score of our parser to
83.2%. Our key contributions are: learn-
ing from noisy data, and building an an-
notated corpus that can benefit relation ex-
traction research.
</bodyText>
<sectionHeader confidence="0.998978" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9981516">
Relation extraction from text is a step beyond
Named-Entity Recognition (NER) and generally de-
mands adequate domain knowledge to build rela-
tions among domain-specific concepts. A Biomedi-
cal Functional Relation (relation for short) states in-
teractions among biomedical substances. In this pa-
per we focus on one such relation: Bacterial Protein
Localization (BPL), and introduce our approach for
identifying BPLs from MEDLINE1 articles.
BPL is a key functional characteristic of pro-
teins. It is essential to the understanding of the func-
tion of different proteins and the discovery of suit-
able drugs, vaccines and diagnostic targets. We are
collaborating with researchers in molecular biology
with the goal of automatically extracting BPLs from
</bodyText>
<footnote confidence="0.990907">
*This research was partially supported by NSERC, Canada.
1MEDLINE is a bibliographic database of biomedical
scientific articles at National Library of Medcine (NLM,
http://www.nlm.nih.gov/).
</footnote>
<bodyText confidence="0.9997415">
text with BioNLP techniques, to expand their pro-
tein localization database, namely PSORTdb2(Rey
et al., 2005). Specifically, the task is to produce as
output the relation tuple BPL(BACTERIUM, PRO-
TEIN, LOCATION) along with source sentence and
document references. The task is new to BioNLP
in terms of the specific biomedical relation being
sought. Therefore, we have to build annotated cor-
pus from scratch and we are unable to use existing
BioNLP shared task resources in our experiments.
In this paper we extract from the text of biomedical
articles a relation among: a LOCATION (one of the
possible locations shown in Figure 1 for Gram+ and
Gram- bacteria); a particular BACTERIUM, e.g. E.
Coli, and a PROTEIN name, e.g. OprF.
(Nair and Rost, 2002) used the text taken from
Swiss-Prot annotations of proteins, and trained a
subcellular classifier on this data. (Hoglund et al.,
2006) predicted subcellular localizations using an
SVM trained on both text and protein sequence data,
by assigning each protein name a vector based on
terms co-occurring with the localization name for
each organism. (Lu and Hunter, 2005) applied a hi-
erarchical architecture of SVMs to predict subcel-
lular localization by incorporating a semantic hier-
archy of localization classes modeled with biolog-
ical processing pathways. These approaches either
ignore the actual location information in their pre-
dicted localization relations, or only focus on a small
portion of eukaryotic proteins. The performance of
these approaches are not comparable due to different
tasks and datasets.
</bodyText>
<sectionHeader confidence="0.955486" genericHeader="method">
2 System Outline
</sectionHeader>
<bodyText confidence="0.9976256">
During our system’s preprocessing phase, sentences
are automatically annotated with both syntactic in-
formation and domain-specific semantic informa-
tion. Syntactic annotations are provided by a statis-
tical parser (Charniak and Johnson, 2005). Domain-
</bodyText>
<footnote confidence="0.972444">
2http://db.psort.org.
</footnote>
<page confidence="0.939857">
161
</page>
<note confidence="0.477522">
Proceedings of NAACL HLT 2007, Companion Volume, pages 161–164,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<figure confidence="0.989828515151515">
Gram+ Gram-
PROTEIN_R/JJ
PROTEIN_R/NNP
-LRB-
NNP
-RRB-
ORGANISM_R/NNP ORGANISM_R/NNP
periplasm
cytoplasm cytoplasm
cell wall
cytoplasmic
membrane
secreted
inner
membrane
outer
membrane
PO_LNK/NP
PO_PTR/PP PO_PTR/PP
IN
PO_PTR/NP
DT PO_PTR/NP PRN NN
NP
-RRB-
-LRB-
gene
The PROTEIN_R/NP
of ORGANISM_R/NP
Figure 2: An example of parsing results
phospholipase
C
PLC
Pseudomonas aeruginosa
</figure>
<figureCaption confidence="0.9878855">
Figure 1: Illustration of possible locations of pro-
teins with respect to the bacterial cell structure.
</figureCaption>
<bodyText confidence="0.982386545454546">
specific semantic information includes annotations
on PROTEIN, BACTERIUM and LOCATION NEs
by dictionary lookups from UMLS3, NCBI Taxon-
omy4 and SwissProt5, and two automatic Bio-NE
recognizers: MMTx6 and Lingpipe7.
We propose the use of a parser that simultane-
ously identifies NEs and extracts the BPL relations
from each sentence. We define NEs to be Relevant
to each other only if they are arguments of a BPL re-
lation, otherwise they are defined to be Irrelevant.
A sentence may contain multiple PROTEIN (LO-
CATION or ORGANISM) NEs, e.g., there are two
PROTEIN NEs in the sentence below but only one,
OmpA, is relevant. Our system aims to identify the
correct BPL relation among all possible BPL tuples
(candidate relations) in the sentence by only recog-
nizing relevant NEs. Each input sentence is assumed
to have at least one BPL relation.
Nine of 10 monoclonal antibodies mapped within the carboxy-
terminal region of [PROTEIN OprF] that is homologous to
the [ORGANISM Escherichia coli] [LOCATION outer membrane]
protein [PROTEIN OmpA].
</bodyText>
<sectionHeader confidence="0.782222" genericHeader="method">
3 Statistical Syntactic and Semantic Parser
</sectionHeader>
<bodyText confidence="0.999979">
Similar to the approach in (Miller et al., 2000) and
(Kulick et al., 2004), our parser integrates both syn-
tactic and semantic annotations into a single annota-
tion as shown in Figure 2. A lexicalized statistical
parser (Bikel, 2004) is applied to the parsing task.
The parse tree is decorated with two types of seman-
</bodyText>
<footnote confidence="0.9994758">
3http://www.nlm.nih.gov/research/umls/
4http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=Taxonomy
5http://www.ebi.ac.uk/swissprot/
6MetaMap Transfer, http://mmtx.nlm.nih.gov/
7http://www.alias-i.com/
</footnote>
<listItem confidence="0.973345333333333">
tic annotations:
1) Annotations on relevant PROTEIN, BAC-
TERIUM and LOCATION NEs. Tags are PRO-
TEIN R, BACTERIUM R and LOCATION R respec-
tively.
2) Annotations on paths between relevant NEs. The
lower-most node that spans both NEs is tagged as
LNK and all nodes along the path to the NEs are
tagged as PTR.
</listItem>
<bodyText confidence="0.999350315789474">
Binary relations are apparently much easier to
represent on the parse tree, therefore we split the
BPL ternary relation into two binary relations: BP
(BACTERIUM and PROTEIN) and PL (PROTEIN
and LOCATION). After capturing BP and PL rela-
tions, we will predict BPL as a fusion of BP and PL,
see §4.1. In contrast to the global inference done us-
ing our generative model, heavily pipelined discrim-
inative approaches usually have problems with error
propagation. A more serious problem in a pipelined
system when using syntactic parses for relation ex-
traction is the alignment between the named enti-
ties produced by a separate system and the syntac-
tic parses produced by the statistical parser. This
alignment issue is non-trivial and we could not pro-
duce a pipelined system that dealt with this issue
satisfactorily for our dataset. As a result, we did
not directly compare our generative approach to a
pipelined strategy.
</bodyText>
<sectionHeader confidence="0.962946" genericHeader="method">
4 Experiment Settings and Evaluations
</sectionHeader>
<bodyText confidence="0.999889125">
The training and test sets are derived from a small
expert-curated corpus. Table 1 lists numbers of sen-
tences and relevant NEs in each BP/PL/BPL set.
Since the parsing results include both NE and path
tags (note that we do not use any external NER sys-
tem), there are two metrics to produce and evalu-
ate PL or BP relations: Name-only and Name-path
metrics. The name-only metric only measures Rel-
</bodyText>
<page confidence="0.994091">
162
</page>
<table confidence="0.999069666666667">
PL BP BPL
Training set 289 / 605 258 / 595 352 / 852
Test set 44 / 134 28 / 127 62 / 182
</table>
<tableCaption confidence="0.9193515">
Table 1: Sizes of training and test sets (number of
sentences / number of relevant NEs)
</tableCaption>
<bodyText confidence="0.998972578947368">
evant PROTEIN, BACTERIUM and LOCATION
NEs (see Section 2). It does not take path annota-
tions into account. The name-only metric is mea-
sured in terms of Precision, Recall and F-score, in
which True Positive (TP) is the number of correctly
identified NEs, False Positive (FP) is the number of
incorrectly identified NEs and False Negative (FN)
is the number of correct NEs that are not identified.
The name-path measures nodes being annotated
as LNK, PTR or R along the path between NEs
on the parse tree, therefore it represents confidence
of NEs being arguments of the relation. The name-
path metric is a macro-average measure, which is
the average performance of all sentences in data set.
In measurement of the name-path metric, TP is the
number of correctly annotated nodes on the path be-
tween relevant NEs. FP is the number of incor-
rectly annotated nodes on the path and FN is the
number of correct nodes that are not identified.
</bodyText>
<subsectionHeader confidence="0.998117">
4.1 Fusion of BP and PL
</subsectionHeader>
<bodyText confidence="0.999991615384615">
The BPL relation can be predicted by a fusion of
BP and PL once they are extracted. Specifically, a
BP and a PL that are extracted from the same sen-
tence are merged into a BPL. The predicted BPL
relations are then evaluated by the same name-only
and name-path metrics as for binary relations. In the
name-path metric, nodes on both PL and BP paths
are counted. Note that we do not need a common
protein NER to merge the BP and PL relations. E.g.,
for name-only evaluation, assume true BPL(B1, P1,
L1): if we predict BP(B1, ) and PL(P1, L2), then
TP=2 due to B1, P1; FP=1 due to L2; and FN=1
due to P1.
</bodyText>
<sectionHeader confidence="0.938447" genericHeader="evaluation">
5 NER and BPL Extraction
</sectionHeader>
<bodyText confidence="0.999722235294118">
Baseline: An intuitive method for relation extrac-
tion would assume that any sentence containing
PROTEIN, ORGANISM and LOCATION NEs has
the relation. We employ this method as a baseline
system, in which NEs are identified by the auto-
matic NE recognizers and dictionary lookups as in-
troduced in §2. The system is evaluated against the
test set in Table 1. Results in Table 2 show low pre-
cision for PROTEIN NER and the name-path metric.
Extraction using Supervised Parsing: We first ex-
periment a fully supervised approach by training the
parser on the BP/PL training set and evaluate on the
test set (see Table 1). The name-only and name-path
evaluation results in Table 2 show poor syntactic
parsing annotation quality and low recall on PRO-
TEIN NER. The major reason of these problems is
the lack of training data.
</bodyText>
<subsectionHeader confidence="0.695401">
Extraction using Semi-supervised Parsing: Ex-
</subsectionHeader>
<bodyText confidence="0.999985485714285">
periments with purely supervised learning show that
our generative model requires a large curated set
to minimize the sparse data problem, but domain-
specific annotated corpora are always rare and ex-
pensive. However, there is a huge source of unla-
beled MEDLINE articles available that may meet
our needs, by assuming that any sentence contain-
ing BACTERIUM, PROTEIN and LOCATION NEs
has the BPL relation. We then choose such sentences
from a subset of the MEDLINE database as the
training data. These sentences, after being parsed
and BPL relations inserted, are in fact the very noisy
data when used to train the parser, since the assumed
relations do not necessarily exist. The reason this
noisy data works at all is probably because we can
learn a preference for structural relations between
entities that are close to each other in the sentence,
and thus distinguish between competing relations in
the same sentence. In future work, we hope to ex-
plore explicit bootstrapping from the labeled data to
improve the quality of the noisy data.
Two experiments were carried out corresponding
to choices of the training set: 1) noisy data only, 2)
noisy data and curated training data. Evaluation re-
sults given in Table 2.
Evaluation results on the name-only metric show
that, compared to supervised parsing, our semi-
supervised method dramatically improves recall for
NER. For instance, recall for PROTEIN NER in-
creases from 25.0% to 81.3%; recall on BAC-
TERIUM and LOCATION NERs increases about
30%. As for the name-path metric, the over-
all F-score is much higher than our fully super-
vised method increasing from 39.9% to 74.5%. It
shows that the inclusion of curated data in the semi-
</bodyText>
<page confidence="0.995618">
163
</page>
<table confidence="0.999969733333333">
Method Measure Name-only Evaluation (%) Name-Path Evaluation (%)
PL BP BPL PL BP BPL
PROT LOC PROT BACT
P 42.3 78.6 41.9 81.3 40.7 27.1 38.9 31.0
Baseline R 92.5 97.3 87.8 97.4 90.9 56.5 69.0 60.7
F 58.0 87.0 56.7 88.6 56.2 36.6 49.8 41.0
Supervised P 66.7 87.5 66.7 72.7 76.9 45.9 41.2 43.9
(training data R 25.0 56.0 10.5 47.1 35.3 36.7 36.3 36.5
only) F 36.4 68.3 18.2 57.1 48.4 40.8 38.6 39.9
Semi-supervised P 66.7 95.5 70.6 94.1 80.8 76.2 83.5 79.3
(noisy data R 84.2 80.8 80.0 84.2 81.8 67.8 72.4 67.0
only) F 74.4 87.5 75.0 88.9 81.3 71.7 77.5 74.2
Semi-supervised P 73.9 95.5 76.5 94.1 84.8 77.0 81.1 78.7
(noisy data + R 81.0 80.8 81.3 84.2 81.7 68.5 73.7 70.7
training data) F 77.3 87.5 78.8 88.9 83.2 72.5 77.2 74.5
</table>
<tableCaption confidence="0.935505">
Table 2: Name-only and name-path evaluation results. PROTEIN, LOCATION and BACTERIUM are
PROT, LOC and BACT for short. The training data is the subset of curated data in Table 1.
</tableCaption>
<bodyText confidence="0.999080272727273">
supervised method does not improve performance
much. Precision of PROTEIN NER increases 6.5%
on average, while F-score of overall BPL extraction
increases only slightly. We experimented with train-
ing the semi-supervised method using noisy data
alone, and testing on the entire curated set, i.e., 333
and 286 sentences for BP and PL extractions respec-
tively. Note that we do not directly train from the
training set in this method, so it is still “unseen” data
for this model. The F-scores of path-only and path-
name metrics are 75.5% and 67.1% respectively.
</bodyText>
<sectionHeader confidence="0.998763" genericHeader="conclusions">
6 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.9991568125">
In this paper we introduced a statistical parsing-
based method to extract biomedical relations from
MEDLINE articles. We made use of a large un-
labeled data set to train our relation extraction
model. Experiments show that the semi-supervised
method significantly outperforms the fully super-
vised method with F-score increasing from 48.4%
to 83.2%. We have implemented a discriminative
model (Liu et al., 2007) which takes as input the ex-
amples with gold named entities and identifies BPL
relations on them. In future work, we plan to let the
discriminative model take the output of our parser
and refine our current results further. We also plan
to train a graphical model based on all extracted BP,
PL and BPL relations to infer relations from multi-
ple sentences and documents.
</bodyText>
<sectionHeader confidence="0.999117" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708233333333">
D. Bikel. 2004. A distributional analysis of a lexicalized statis-
tical parsing model. In Proc. of EMNLP ’04, pages 182–189.
E. Charniak and M. Johnson. 2005. Coarse-to-fine n-best pars-
ing and maxent discriminative reranking. In Proc. of ACL
’5, pages 173–180.
A. Hoglund, T. Blum, S. Brady, P. Donnes, J. Miguel,
M. Rocheford, O. Kohlbacher, and H. Shatkay. 2006. Sig-
nificantly improved prediction of subcellular localization by
integrating text and protein sequence data. In Proc. of PSB
’6, volume 11, pages 16–27.
S. Kulick, A. Bies, M. Libeman, M. Mandel, R. McDonald,
M. Palmer, A. Schein, and L. Ungar. 2004. Integrated an-
notation for biomedical information extraction. In Proc. of
HLT/NAACL ’04, pages 61–68, Boston, May.
Y. Liu, Z. Shi, and A. Sarkar. 2007. Exploiting rich syntactic
information for relation extraction from biomedical articles.
In NAACL-HLT ’07, poster track, Rochester, NY, April.
Z. Lu and L. Hunter. 2005. Go molecular function terms are
predictive of subcellular localization. In Proc. of PSB ’05,
volume 10, pages 151–161.
S. Miller, H. Fox, L. Ramshaw, and R. Weischedel. 2000. A
novel use of statistical parsing to extract information from
text. In Proc. of NAACL ’06, pages 226–233.
R. Nair and B. Rost. 2002. Inferring subcellular localization
through automated lexical analysis. In Bioinformatics, vol-
ume 18, pages 78–86.
S. Rey, M. Acab, J. Gardy, M. Laird, K. deFays, C. Lam-
bert, and F. Brinkman. 2005. Psortdb: A database of sub-
cellular localizations for bacteria. Nucleic Acids Research,
33(D):164–168.
</reference>
<page confidence="0.998519">
164
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.876517">
<title confidence="0.9990265">Simultaneous Identification of Biomedical Named-Entity Relations Using Statistical Parsing Techniques</title>
<author confidence="0.999929">Shi Sarkar</author>
<affiliation confidence="0.974575">School of Computing Simon Fraser University</affiliation>
<abstract confidence="0.995687333333333">In this paper we propose a statistical parsing technique that simultaneously identifies biomedical named-entities (NEs) and extracts subcellular localization relations for bacterial proteins from the text in MEDLINE articles. We build a parser that derives both syntactic and domain-dependent semantic information achieves an F-score of the relation extraction task. We then propose a semi-supervised approach that incorporates noisy automatically labeled data to improve the F-score of our parser to Our key contributions are: learning from noisy data, and building an annotated corpus that can benefit relation extraction research.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bikel</author>
</authors>
<title>A distributional analysis of a lexicalized statistical parsing model.</title>
<date>2004</date>
<booktitle>In Proc. of EMNLP ’04,</booktitle>
<pages>182--189</pages>
<contexts>
<context position="5647" citStr="Bikel, 2004" startWordPosition="844" endWordPosition="845">es (candidate relations) in the sentence by only recognizing relevant NEs. Each input sentence is assumed to have at least one BPL relation. Nine of 10 monoclonal antibodies mapped within the carboxyterminal region of [PROTEIN OprF] that is homologous to the [ORGANISM Escherichia coli] [LOCATION outer membrane] protein [PROTEIN OmpA]. 3 Statistical Syntactic and Semantic Parser Similar to the approach in (Miller et al., 2000) and (Kulick et al., 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2. A lexicalized statistical parser (Bikel, 2004) is applied to the parsing task. The parse tree is decorated with two types of seman3http://www.nlm.nih.gov/research/umls/ 4http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=Taxonomy 5http://www.ebi.ac.uk/swissprot/ 6MetaMap Transfer, http://mmtx.nlm.nih.gov/ 7http://www.alias-i.com/ tic annotations: 1) Annotations on relevant PROTEIN, BACTERIUM and LOCATION NEs. Tags are PROTEIN R, BACTERIUM R and LOCATION R respectively. 2) Annotations on paths between relevant NEs. The lower-most node that spans both NEs is tagged as LNK and all nodes along the path to the NEs are tagged as PTR. Binary relat</context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>D. Bikel. 2004. A distributional analysis of a lexicalized statistical parsing model. In Proc. of EMNLP ’04, pages 182–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Coarse-to-fine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proc. of ACL ’5,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="3683" citStr="Charniak and Johnson, 2005" startWordPosition="543" endWordPosition="546">ization by incorporating a semantic hierarchy of localization classes modeled with biological processing pathways. These approaches either ignore the actual location information in their predicted localization relations, or only focus on a small portion of eukaryotic proteins. The performance of these approaches are not comparable due to different tasks and datasets. 2 System Outline During our system’s preprocessing phase, sentences are automatically annotated with both syntactic information and domain-specific semantic information. Syntactic annotations are provided by a statistical parser (Charniak and Johnson, 2005). Domain2http://db.psort.org. 161 Proceedings of NAACL HLT 2007, Companion Volume, pages 161–164, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics Gram+ GramPROTEIN_R/JJ PROTEIN_R/NNP -LRBNNP -RRBORGANISM_R/NNP ORGANISM_R/NNP periplasm cytoplasm cytoplasm cell wall cytoplasmic membrane secreted inner membrane outer membrane PO_LNK/NP PO_PTR/PP PO_PTR/PP IN PO_PTR/NP DT PO_PTR/NP PRN NN NP -RRB-LRBgene The PROTEIN_R/NP of ORGANISM_R/NP Figure 2: An example of parsing results phospholipase C PLC Pseudomonas aeruginosa Figure 1: Illustration of possible locations of pro</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>E. Charniak and M. Johnson. 2005. Coarse-to-fine n-best parsing and maxent discriminative reranking. In Proc. of ACL ’5, pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hoglund</author>
<author>T Blum</author>
<author>S Brady</author>
<author>P Donnes</author>
<author>J Miguel</author>
<author>M Rocheford</author>
<author>O Kohlbacher</author>
<author>H Shatkay</author>
</authors>
<title>Significantly improved prediction of subcellular localization by integrating text and protein sequence data.</title>
<date>2006</date>
<booktitle>In Proc. of PSB ’6,</booktitle>
<volume>11</volume>
<pages>16--27</pages>
<contexts>
<context position="2750" citStr="Hoglund et al., 2006" startWordPosition="407" endWordPosition="410">he task is new to BioNLP in terms of the specific biomedical relation being sought. Therefore, we have to build annotated corpus from scratch and we are unable to use existing BioNLP shared task resources in our experiments. In this paper we extract from the text of biomedical articles a relation among: a LOCATION (one of the possible locations shown in Figure 1 for Gram+ and Gram- bacteria); a particular BACTERIUM, e.g. E. Coli, and a PROTEIN name, e.g. OprF. (Nair and Rost, 2002) used the text taken from Swiss-Prot annotations of proteins, and trained a subcellular classifier on this data. (Hoglund et al., 2006) predicted subcellular localizations using an SVM trained on both text and protein sequence data, by assigning each protein name a vector based on terms co-occurring with the localization name for each organism. (Lu and Hunter, 2005) applied a hierarchical architecture of SVMs to predict subcellular localization by incorporating a semantic hierarchy of localization classes modeled with biological processing pathways. These approaches either ignore the actual location information in their predicted localization relations, or only focus on a small portion of eukaryotic proteins. The performance </context>
</contexts>
<marker>Hoglund, Blum, Brady, Donnes, Miguel, Rocheford, Kohlbacher, Shatkay, 2006</marker>
<rawString>A. Hoglund, T. Blum, S. Brady, P. Donnes, J. Miguel, M. Rocheford, O. Kohlbacher, and H. Shatkay. 2006. Significantly improved prediction of subcellular localization by integrating text and protein sequence data. In Proc. of PSB ’6, volume 11, pages 16–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kulick</author>
<author>A Bies</author>
<author>M Libeman</author>
<author>M Mandel</author>
<author>R McDonald</author>
<author>M Palmer</author>
<author>A Schein</author>
<author>L Ungar</author>
</authors>
<title>Integrated annotation for biomedical information extraction.</title>
<date>2004</date>
<booktitle>In Proc. of HLT/NAACL ’04,</booktitle>
<pages>61--68</pages>
<location>Boston,</location>
<contexts>
<context position="5490" citStr="Kulick et al., 2004" startWordPosition="817" endWordPosition="820">g., there are two PROTEIN NEs in the sentence below but only one, OmpA, is relevant. Our system aims to identify the correct BPL relation among all possible BPL tuples (candidate relations) in the sentence by only recognizing relevant NEs. Each input sentence is assumed to have at least one BPL relation. Nine of 10 monoclonal antibodies mapped within the carboxyterminal region of [PROTEIN OprF] that is homologous to the [ORGANISM Escherichia coli] [LOCATION outer membrane] protein [PROTEIN OmpA]. 3 Statistical Syntactic and Semantic Parser Similar to the approach in (Miller et al., 2000) and (Kulick et al., 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2. A lexicalized statistical parser (Bikel, 2004) is applied to the parsing task. The parse tree is decorated with two types of seman3http://www.nlm.nih.gov/research/umls/ 4http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=Taxonomy 5http://www.ebi.ac.uk/swissprot/ 6MetaMap Transfer, http://mmtx.nlm.nih.gov/ 7http://www.alias-i.com/ tic annotations: 1) Annotations on relevant PROTEIN, BACTERIUM and LOCATION NEs. Tags are PROTEIN R, BACTERIUM R and LOCATION R respectively. 2) Annotations on</context>
</contexts>
<marker>Kulick, Bies, Libeman, Mandel, McDonald, Palmer, Schein, Ungar, 2004</marker>
<rawString>S. Kulick, A. Bies, M. Libeman, M. Mandel, R. McDonald, M. Palmer, A. Schein, and L. Ungar. 2004. Integrated annotation for biomedical information extraction. In Proc. of HLT/NAACL ’04, pages 61–68, Boston, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Liu</author>
<author>Z Shi</author>
<author>A Sarkar</author>
</authors>
<title>Exploiting rich syntactic information for relation extraction from biomedical articles.</title>
<date>2007</date>
<booktitle>In NAACL-HLT ’07, poster track,</booktitle>
<location>Rochester, NY,</location>
<marker>Liu, Shi, Sarkar, 2007</marker>
<rawString>Y. Liu, Z. Shi, and A. Sarkar. 2007. Exploiting rich syntactic information for relation extraction from biomedical articles. In NAACL-HLT ’07, poster track, Rochester, NY, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Lu</author>
<author>L Hunter</author>
</authors>
<title>Go molecular function terms are predictive of subcellular localization.</title>
<date>2005</date>
<booktitle>In Proc. of PSB ’05,</booktitle>
<volume>10</volume>
<pages>151--161</pages>
<contexts>
<context position="2983" citStr="Lu and Hunter, 2005" startWordPosition="443" endWordPosition="446">aper we extract from the text of biomedical articles a relation among: a LOCATION (one of the possible locations shown in Figure 1 for Gram+ and Gram- bacteria); a particular BACTERIUM, e.g. E. Coli, and a PROTEIN name, e.g. OprF. (Nair and Rost, 2002) used the text taken from Swiss-Prot annotations of proteins, and trained a subcellular classifier on this data. (Hoglund et al., 2006) predicted subcellular localizations using an SVM trained on both text and protein sequence data, by assigning each protein name a vector based on terms co-occurring with the localization name for each organism. (Lu and Hunter, 2005) applied a hierarchical architecture of SVMs to predict subcellular localization by incorporating a semantic hierarchy of localization classes modeled with biological processing pathways. These approaches either ignore the actual location information in their predicted localization relations, or only focus on a small portion of eukaryotic proteins. The performance of these approaches are not comparable due to different tasks and datasets. 2 System Outline During our system’s preprocessing phase, sentences are automatically annotated with both syntactic information and domain-specific semantic </context>
</contexts>
<marker>Lu, Hunter, 2005</marker>
<rawString>Z. Lu and L. Hunter. 2005. Go molecular function terms are predictive of subcellular localization. In Proc. of PSB ’05, volume 10, pages 151–161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miller</author>
<author>H Fox</author>
<author>L Ramshaw</author>
<author>R Weischedel</author>
</authors>
<title>A novel use of statistical parsing to extract information from text.</title>
<date>2000</date>
<booktitle>In Proc. of NAACL ’06,</booktitle>
<pages>226--233</pages>
<contexts>
<context position="5464" citStr="Miller et al., 2000" startWordPosition="812" endWordPosition="815">ATION or ORGANISM) NEs, e.g., there are two PROTEIN NEs in the sentence below but only one, OmpA, is relevant. Our system aims to identify the correct BPL relation among all possible BPL tuples (candidate relations) in the sentence by only recognizing relevant NEs. Each input sentence is assumed to have at least one BPL relation. Nine of 10 monoclonal antibodies mapped within the carboxyterminal region of [PROTEIN OprF] that is homologous to the [ORGANISM Escherichia coli] [LOCATION outer membrane] protein [PROTEIN OmpA]. 3 Statistical Syntactic and Semantic Parser Similar to the approach in (Miller et al., 2000) and (Kulick et al., 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2. A lexicalized statistical parser (Bikel, 2004) is applied to the parsing task. The parse tree is decorated with two types of seman3http://www.nlm.nih.gov/research/umls/ 4http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=Taxonomy 5http://www.ebi.ac.uk/swissprot/ 6MetaMap Transfer, http://mmtx.nlm.nih.gov/ 7http://www.alias-i.com/ tic annotations: 1) Annotations on relevant PROTEIN, BACTERIUM and LOCATION NEs. Tags are PROTEIN R, BACTERIUM R and LOCATION R respe</context>
</contexts>
<marker>Miller, Fox, Ramshaw, Weischedel, 2000</marker>
<rawString>S. Miller, H. Fox, L. Ramshaw, and R. Weischedel. 2000. A novel use of statistical parsing to extract information from text. In Proc. of NAACL ’06, pages 226–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Nair</author>
<author>B Rost</author>
</authors>
<title>Inferring subcellular localization through automated lexical analysis.</title>
<date>2002</date>
<journal>In Bioinformatics,</journal>
<volume>18</volume>
<pages>78--86</pages>
<contexts>
<context position="2615" citStr="Nair and Rost, 2002" startWordPosition="386" endWordPosition="389">ask is to produce as output the relation tuple BPL(BACTERIUM, PROTEIN, LOCATION) along with source sentence and document references. The task is new to BioNLP in terms of the specific biomedical relation being sought. Therefore, we have to build annotated corpus from scratch and we are unable to use existing BioNLP shared task resources in our experiments. In this paper we extract from the text of biomedical articles a relation among: a LOCATION (one of the possible locations shown in Figure 1 for Gram+ and Gram- bacteria); a particular BACTERIUM, e.g. E. Coli, and a PROTEIN name, e.g. OprF. (Nair and Rost, 2002) used the text taken from Swiss-Prot annotations of proteins, and trained a subcellular classifier on this data. (Hoglund et al., 2006) predicted subcellular localizations using an SVM trained on both text and protein sequence data, by assigning each protein name a vector based on terms co-occurring with the localization name for each organism. (Lu and Hunter, 2005) applied a hierarchical architecture of SVMs to predict subcellular localization by incorporating a semantic hierarchy of localization classes modeled with biological processing pathways. These approaches either ignore the actual lo</context>
</contexts>
<marker>Nair, Rost, 2002</marker>
<rawString>R. Nair and B. Rost. 2002. Inferring subcellular localization through automated lexical analysis. In Bioinformatics, volume 18, pages 78–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Rey</author>
<author>M Acab</author>
<author>J Gardy</author>
<author>M Laird</author>
<author>K deFays</author>
<author>C Lambert</author>
<author>F Brinkman</author>
</authors>
<title>Psortdb: A database of subcellular localizations for bacteria. Nucleic Acids Research,</title>
<date>2005</date>
<contexts>
<context position="1974" citStr="Rey et al., 2005" startWordPosition="279" endWordPosition="282">rticles. BPL is a key functional characteristic of proteins. It is essential to the understanding of the function of different proteins and the discovery of suitable drugs, vaccines and diagnostic targets. We are collaborating with researchers in molecular biology with the goal of automatically extracting BPLs from *This research was partially supported by NSERC, Canada. 1MEDLINE is a bibliographic database of biomedical scientific articles at National Library of Medcine (NLM, http://www.nlm.nih.gov/). text with BioNLP techniques, to expand their protein localization database, namely PSORTdb2(Rey et al., 2005). Specifically, the task is to produce as output the relation tuple BPL(BACTERIUM, PROTEIN, LOCATION) along with source sentence and document references. The task is new to BioNLP in terms of the specific biomedical relation being sought. Therefore, we have to build annotated corpus from scratch and we are unable to use existing BioNLP shared task resources in our experiments. In this paper we extract from the text of biomedical articles a relation among: a LOCATION (one of the possible locations shown in Figure 1 for Gram+ and Gram- bacteria); a particular BACTERIUM, e.g. E. Coli, and a PROTE</context>
</contexts>
<marker>Rey, Acab, Gardy, Laird, deFays, Lambert, Brinkman, 2005</marker>
<rawString>S. Rey, M. Acab, J. Gardy, M. Laird, K. deFays, C. Lambert, and F. Brinkman. 2005. Psortdb: A database of subcellular localizations for bacteria. Nucleic Acids Research, 33(D):164–168.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>