<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.986423">
Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure
</title>
<author confidence="0.857508">
Oscar T¨ackstr¨om* Ryan McDonald Jakob Uszkoreit
</author>
<affiliation confidence="0.7329">
SICS / Uppsala University Google Google
Kista / Uppsala, Sweden New York, NY Mountain View, CA
</affiliation>
<email confidence="0.96053">
oscar@sics.se ryanmcd@google.com uszkoreit@google.com
</email>
<sectionHeader confidence="0.993126" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998865380952381">
It has been established that incorporating word
cluster features derived from large unlabeled
corpora can significantly improve prediction of
linguistic structure. While previous work has
focused primarily on English, we extend these
results to other languages along two dimen-
sions. First, we show that these results hold
true for a number of languages across families.
Second, and more interestingly, we provide an
algorithm for inducing cross-lingual clusters
and we show that features derived from these
clusters significantly improve the accuracy of
cross-lingual structure prediction. Specifically,
we show that by augmenting direct-transfer sys-
tems with cross-lingual cluster features, the rel-
ative error of delexicalized dependency parsers,
trained on English treebanks and transferred
to foreign languages, can be reduced by up to
13%. When applying the same method to di-
rect transfer of named-entity recognizers, we
observe relative improvements of up to 26%.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98824376923077">
The ability to predict the linguistic structure of sen-
tences or documents is central to the field of nat-
ural language processing (NLP). Structures such as
named-entity tag sequences (Bikel et al., 1999) or sen-
timent relations (Pang and Lee, 2008) are inherently
useful in data mining, information retrieval and other
user-facing technologies. More fundamental struc-
tures such as part-of-speech tag sequences (Ratna-
parkhi, 1996) or syntactic parse trees (Collins, 1997;
K¨ubler et al., 2009), on the other hand, comprise the
core linguistic analysis for many important down-
stream tasks such as machine translation (Chiang,
* The majority of this work was performed while the author
was an intern at Google, New York, NY.
2005; Collins et al., 2005). Currently, supervised
data-driven methods dominate the literature on lin-
guistic structure prediction (Smith, 2011). Regret-
tably, the majority of studies on these methods have
focused on evaluations specific to English, since it is
the language with the most annotated resources. No-
table exceptions include the CoNLL shared tasks
(Tjong Kim Sang, 2002; Tjong Kim Sang and
De Meulder, 2003; Buchholz and Marsi, 2006; Nivre
et al., 2007) and subsequent studies on this data, as
well as a number of focused studies on one or two
specific languages, as discussed by Bender (2011).
While annotated resources for parsing and several
other tasks are available in a number of languages, we
cannot expect to have access to labeled resources for
all tasks in all languages. This fact has given rise to
a large body of research on unsupervised (Klein and
Manning, 2004), semi-supervised (Koo et al., 2008)
and transfer (Hwa et al., 2005) systems for prediction
of linguistic structure. These methods all attempt to
benefit from the plethora of unlabeled monolingual
and/or cross-lingual data that has become available
in the digital age. Unsupervised methods are ap-
pealing in that they are often inherently language
independent. This is borne out by the many recent
studies on unsupervised parsing that include evalu-
ations covering a number of languages (Cohen and
Smith, 2009; Gillenwater et al., 2010; Naseem et al.,
2010; Spitkovsky et al., 2011). However, the perfor-
mance for most languages is still well below that of
supervised systems and recent work has established
that the performance is also below simple methods
of linguistic transfer (McDonald et al., 2011).
In this study we focus on semi-supervised and
linguistic-transfer methods for multilingual structure
prediction. In particular, we pursue two lines of re-
search around the use of word cluster features in
discriminative models for structure prediction:
</bodyText>
<page confidence="0.977363">
477
</page>
<note confidence="0.495987">
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</note>
<listItem confidence="0.605425">
1. Monolingual word cluster features induced from
large corpora of text for semi-supervised learn-
ing (SSL) of linguistic structure. Previous stud-
ies on this approach have typically focused only
on a small set of languages and tasks (Freitag,
2004; Miller et al., 2004; Koo et al., 2008;
Turian et al., 2010; Faruqui and Pad´o, 2010; Haf-
fari et al., 2011; Tratz and Hovy, 2011). Here
we show that this method is robust across 13 lan-
</listItem>
<bodyText confidence="0.9886988">
guages for dependency parsing and 4 languages
for named-entity recognition (NER). This is the
first study with such a broad view on this subject,
in terms of language diversity.
2. Cross-lingual word cluster features for transfer-
ring linguistic structure from English to other
languages. We develop an algorithm that gener-
ates cross-lingual word clusters; that is clusters
of words that are consistent across languages.
This is achieved by means of a probabilistic
model over large amounts of monolingual data
in two languages, coupled with parallel data
through which cross-lingual word-cluster con-
straints are enforced. We show that by augment-
ing the delexicalized direct transfer system of
McDonald et al. (2011) with cross-lingual clus-
ter features, we are able to reduce its error by
up to 13% relative. Further, we show that by ap-
plying the same method to direct-transfer NER,
we achieve a relative error reduction of 26%.
In line with much previous work on word clusters
for tasks such as dependency parsing and NER, for
which local syntactic and semantic constraints are
of importance, we induce word clusters by means of
a probabilistic class-based language model (Brown
et al., 1992; Clark, 2003). However, rather than the
more commonly used model of Brown et al. (1992),
we use the predictive class bigram model introduced
by Uszkoreit and Brants (2008). The two models
are very similar, but whereas the former takes class-
to-class transitions into account, the latter directly
models word-to-class transitions. By ignoring class-
to-class transitions, an approximate maximum likeli-
hood clustering can be found efficiently with the dis-
tributed exchange algorithm (Uszkoreit and Brants,
2008). This is a useful property, as we later develop
an algorithm for inducing cross-lingual word clusters
that calls this monolingual algorithm as a subroutine.
More formally, let C : V H 1, ... , K be a (hard)
clustering function that maps each word type from the
vocabulary, V, to one of K cluster identities. With the
model of Uszkoreit and Brants (2008), the likelihood
of a sequence of word tokens, w = (wi)mi=1, with
wi E V U {S}, where S is a designated start-of-
segment symbol, factors as
</bodyText>
<equation confidence="0.994780666666667">
m
L(w; C) = P(wi|C(wi))P(C(wi)|wi−1) . (1)
i=1
</equation>
<bodyText confidence="0.85646175">
Compare this to the model of Brown et al. (1992):
By incorporating cross-lingual cluster features in a m
linguistic transfer system, we are for the first time L&apos;(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) .
combining SSL and cross-lingual transfer. i=1
</bodyText>
<sectionHeader confidence="0.952021" genericHeader="introduction">
2 Monolingual Word Cluster Features
</sectionHeader>
<bodyText confidence="0.990236269230769">
Word cluster features have been shown to be use-
ful in various tasks in natural language processing,
including syntactic dependency parsing (Koo et al.,
2008; Haffari et al., 2011; Tratz and Hovy, 2011),
syntactic chunking (Turian et al., 2010), and NER
(Freitag, 2004; Miller et al., 2004; Turian et al., 2010;
Faruqui and Pad´o, 2010). Intuitively, the reason for
the effectiveness of cluster features lie in their abil-
ity to aggregate local distributional information from
large unlabeled corpora, which aid in conquering data
sparsity in supervised training regimes as well as in
mitigating cross-domain generalization issues.
While the use of class-to-class transitions can lead
to more compact models, which is often useful for
conquering data sparsity, when clustering large data
sets we can get reliable statistics directly on the word-
to-class transitions (Uszkoreit and Brants, 2008).
In addition to the clustering model that we make
use of in this study, a number of additional word
clustering and embedding variants have been pro-
posed. For example, Turian et al. (2010) assessed
the effectiveness of the word embedding techniques
of Collobert and Weston (2008) and Mnih and Hin-
ton (2007) along with the word clustering technique
of Brown et al. (1992) for syntactic chunking and
NER. Recently, Dhillon et al. (2011) proposed a word
</bodyText>
<page confidence="0.997746">
478
</page>
<table confidence="0.9582559">
Single words S0c{p}, N0c{p}, N1c{p}, N2c{p}
Word pairs S0c{p}N0c{p}, S0pcN0p, S0pN0pc,
S0wN0c, S0cN0w, N0cN1c, N1cN2c
Word triples N0cN1cN2c, S0cN0cN1c, S0hcS0cN0c,
S0cS0lcN0c, S0cS0rcN0c, S0cN0cN0lc
Distance S0cd, N0cd, S0cN0cd
Valency S0cvl, S0cvr, N0cS0vl
Unigrams S0hc, S0lc, S0rc, N0lc
Third-order S0h2c, S0l2c, S0r2c, N0l2c
Label set S0cS0ll, S0cS0rl, N0cN0ll, N0cN0rl
</table>
<tableCaption confidence="0.849712">
Table 1: Additional cluster-based parser features. Si and
Ni: the ith tokens in the stack and buffer. p: the part-of-
</tableCaption>
<figureCaption confidence="0.6366785">
speech tag, c: the cluster. v: the valence of the left (l) or
right (r) set of children. l: the label of the token under
consideration. d: distance between the words on the top of
the stack and buffer. Sih, Sir and Sil: the head, right-most
modifier and left-most modifier of the token at the top of
the stack. Gx{y} expands to Gxy and Gx.
</figureCaption>
<bodyText confidence="0.999394333333333">
embedding method based on canonical correlation
analysis that provides state-of-the art results for word-
based SSL for English NER. As an alternative to clus-
tering words, Lin and Wu (2009) proposed a phrase
clustering approach that obtained the state-of-the-art
result for English NER.
</bodyText>
<sectionHeader confidence="0.986312" genericHeader="method">
3 Monolingual Cluster Experiments
</sectionHeader>
<bodyText confidence="0.9998635">
Before moving on to the multilingual setting, we
conduct a set of monolingual experiments where we
evaluate the use of the monolingual word clusters
just described as features for dependency parsing and
NER. In the parsing experiments, we study the fol-
lowing thirteen languages:1 Danish (DA), German
(DE), Greek (EL), English (EN), Spanish (ES), French
(FR), Italian (IT), Korean (KO), Dutch (NL), Portugese
(PT), Russian (RU), Swedish (SV) and Chinese (ZH)
– representing the Chinese, Germanic, Hellenic, Ro-
mance, Slavic, Altaic and Korean genera. In the NER
experiments, we study three Germanic languages:
German (DE), English (EN) and Dutch (NL); and one
Romance language: Spanish (ES).
Details of the labeled and unlabeled data sets used
are given in Appendix A. For all experiments we
fixed the number of clusters to 256 as this performed
well on held-out data. Furthermore, we only clus-
tered the 1 million most frequent word types in each
language for both efficiency and sparsity reasons. For
</bodyText>
<footnote confidence="0.984438">
1The particular choice of languages was made purely based
on data availability and institution licensing.
</footnote>
<equation confidence="0.973788142857143">
Word &amp; bias w−1,0,1, w−1:0, w0:1, w−1:1, b
Pre-/suffix w:1,: 2,,3,:4,:5, w=5:,−4:,−3:,−2:,−1:
Orthography Hyp−1,0,1, Cap−1,0,1, Cap−1:0,
Cap0:1, Cap−1:1
PoS p−1,0,1, p−1:0, p0:1, p−1:1, p−2:1, p−1:2
Cluster c−1,0,1, c−1:0, c0:1, c−1:1, c−2:1, c−1:2
Transition →/p−1,0,1,→/c−1,0,1,→/Cap−1,0,1,→/b
</equation>
<tableCaption confidence="0.943948571428571">
Table 2: NER features. Hyp: Word contains hyphen. Cap:
First letter is capitalized. -/f - Transition from previous
to current label conjoined with feature f. w:j: j-character
prefix of w. w−j:: j-character suffix of w. fi: Feature f
at relative position i. fi,j: Union of features at positions i
and j. fi:j: Conjoined feature sequence between relative
positions i and j (inclusive). b: Bias.
</tableCaption>
<bodyText confidence="0.9912735">
languages in which our unlabeled data did not have
at least 1 million types, we considered all types.
</bodyText>
<subsectionHeader confidence="0.996168">
3.1 Cluster Augmented Feature Models
</subsectionHeader>
<bodyText confidence="0.999898633333333">
All of the parsing experiments reported in this study
are based on the transition-based dependency parsing
paradigm (Nivre, 2008). For all languages and set-
tings, we use an arc-eager decoding strategy, with a
beam of eight hypotheses, and perform ten epochs of
the averaged structured perceptron algorithm (Zhang
and Clark, 2008). We extend the state-of-the-art fea-
ture model recently introduced by Zhang and Nivre
(2011) by adding an additional word cluster based
feature template for each word based template. Ad-
ditionally, we add templates where one or more part-
of-speech feature is replaced with the corresponding
cluster feature. The resulting set of additional fea-
ture templates are shown in Table 1. The expanded
feature model includes all of the feature templates de-
fined by Zhang and Nivre (2011), which we also use
as the baseline model, whereas Table 1 only shows
our new templates due to space limitations.
For all NER experiments, we use a sequential first-
order conditional random field (CRF) with a unit
variance Normal prior, trained with L-BFGS until
c-convergence (c = 0.0001, typically obtained after
less than 400 iterations). The feature model used
for the NER tagger is shown in Table 2. These are
similar to the features used by Turian et al. (2010),
with the main difference that we do not use any long
range features and that we add templates that conjoin
adjacent clusters and adjacent tags as well as tem-
plates that conjoin label transitions with tags, clusters
and capitalization features.
</bodyText>
<page confidence="0.997232">
479
</page>
<table confidence="0.837902">
DA DE EL EN ES FR IT KO NL PT RU SV ZH AVG
NO CLUSTERS 84.3 88.9 76.1 90.3 82.8 85.7 81.4 82.0 77.2 86.9 83.5 84.7 74.9 83.0
CLUSTERS 85.8 89.5 77.3 90.7 83.6 85.7 82.2 83.6 77.8 87.6 86.0 86.5 75.5 84.0
</table>
<tableCaption confidence="0.96782">
Table 3: Supervised parsing results measured with labeled attachment score (LAS) on the test set. All results are
statistically significant at p &lt; 0.05, except FR and NL.
</tableCaption>
<table confidence="0.988564666666667">
DE EN ES NL AVG
NO CLUSTERS 65.4 89.2 75.0 75.7 76.3
CLUSTERS 74.8 91.8 81.1 84.2 83.0
I DEVELOPMENT SET I TEST SET
NO CLUSTERS 69.1 83.5 78.9 79.6 77.8
CLUSTERS 74.4 87.8 82.0 85.7 82.5
</table>
<tableCaption confidence="0.988354">
Table 4: Supervised NER results measured with Fl-score
on the CoNLL 2002/2003 development and test sets.
</tableCaption>
<subsectionHeader confidence="0.892747">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999995063829787">
The results of the parsing experiments, measured
with labeled accuracy score (LAS) on all sentence
lengths, excluding punctuation, are shown in Table 3.
The baselines are all comparable to the state-of-the-
art. On average, the addition of word cluster features
yields a 6% relative reduction in error and upwards
of 15% (for RU). All languages improve except FR,
which sees neither an increase nor a decrease in LAS.
We observe an average absolute increase in LAS
of approximately 1%, which is inline with previous
observations (Koo et al., 2008). It is perhaps not
surprising that RU sees a large gain as it is a highly
inflected language, making observations of lexical
features far more sparse. Some languages, e.g., FR,
NL, and ZH see much smaller gains. One likely cul-
prit is a divergence between the tokenization schemes
used in the treebank and in our unlabeled data, which
for Indo-European languages is closely related to the
Penn Treebank tokenization. For example, the NL
treebank contains many multi-word tokens that are
typically broken apart by our automatic tokenizer.
The NER results, in terms of F1 measure, are listed
in Table 4. Introducing word cluster features for
NER reduces relative errors on the test set by 21%
(39% on the development set) on average. Broken
down per language, reductions on the test set vary
from substantial for NL (30%) and EN (26%), down
to more modest for DE (17%) and ES (12%). The
addition of cluster features most markedly improve
recognition of the PER category, with an average error
reduction on the test set of 44%, while the reductions
for ORG (19%), LOC (17%) and MISC (10%) are more
modest, but still significant. Although our results
are below the best reported results for EN and DE
(Lin and Wu, 2009; Faruqui and Pad´o, 2010), the
relative improvements of adding word clusters are
inline with previous results on NER for EN (Miller
et al., 2004; Turian et al., 2010), who report error
reductions of approximately 25% from adding word
cluster features. Slightly higher reductions where
achieved for DE by Faruqui and Pad´o (2010), who
report a reduction of 22%. Note that we did not tune
hyper-parameters of the supervised learning methods
and of the clustering method, such as the number
of clusters (Turian et al., 2010; Faruqui and Pad´o,
2010), and that we did not apply any heuristic for data
cleaning such as that used by Turian et al. (2010).
</bodyText>
<sectionHeader confidence="0.98872" genericHeader="method">
4 Cross-lingual Word Cluster Features
</sectionHeader>
<bodyText confidence="0.999645421052632">
All results of the previous section rely on the avail-
ability of large quantities of language specific anno-
tations for each task. Cross-lingual transfer methods
and unsupervised methods have recently been shown
to hold promise as a way to at least partially sidestep
the demand for labeled data. Unsupervised methods
attempt to infer linguistic structure without using any
annotated data (Klein and Manning, 2004) or possi-
bly by using a set of linguistically motivated rules
(Naseem et al., 2010) or a linguistically informed
model structure (Berg-Kirkpatrick and Klein, 2010).
The aim of transfer methods is instead to use knowl-
edge induced from labeled resources in one or more
source languages to construct systems for target lan-
guages in which no or few such resources are avail-
able (Hwa et al., 2005). Currently, the performance
of even the most simple direct transfer systems far
exceeds that of unsupervised systems (Cohen et al.,
2011; McDonald et al., 2011; Søgaard, 2011).
</bodyText>
<page confidence="0.99625">
480
</page>
<figureCaption confidence="0.990345666666667">
Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering model.
Top-right: Samples of some of the induced cross-lingual word clusters. Bottom-left: Delexicalized cluster-augmented
source (EN) treebank for training transfer parser. Bottom-right: Parsing of target (ES) sentence using the transfer parser.
</figureCaption>
<subsectionHeader confidence="0.994536">
4.1 Direct Transfer of Discriminative Models
</subsectionHeader>
<bodyText confidence="0.999991897435898">
Our starting point is the delexicalized direct transfer
method proposed by McDonald et al. (2011) based on
work by Zeman and Resnik (2008). This method was
shown to outperform a number of state-of-the-art un-
supervised and transfer-based baselines. The method
is simple; for a given training set, the learner ignores
all lexical identities and only observes features over
other characteristics, e.g., part-of-speech tags, ortho-
graphic features, direction of syntactic attachment,
etc. The learner builds a model from an annotated
source language data set, after which the model is
used to directly make target language predictions.
There are three basic assumptions that drive this ap-
proach. First, that high-level tasks, such as syntactic
parsing, can be learned reliably using coarse-grained
statistics, such as part-of-speech tags, in place of
fine-grained statistics such as lexical word identities.
Second, that the parameters of features over coarse-
grained statistics are in some sense language inde-
pendent, e.g., a feature that indicates that adjectives
modify their closest noun is useful in all languages.
Third, that these coarse-grained statistics are robustly
available across languages. The approach proposed
by McDonald et al. (2011) relies on these three as-
sumptions. Specifically, by replacing fine-grained
language specific part-of-speech tags with universal
part-of-speech tags, generated with the method de-
scribed by Das and Petrov (2011), a universal parser
is achieved that can be applied to any language for
which universal part-of-speech tags are available.
Below, we extend this approach to universal pars-
ing by adding cross-lingual word cluster features. A
cross-lingual word clustering is a clustering of words
in two languages, in which the clusters correspond to
some meaningful cross-lingual property. For exam-
ple, prepositions from both languages should be in
the same cluster, proper names from both languages
in another cluster and so on. By adding features de-
fined over these clusters, we can, to some degree,
</bodyText>
<page confidence="0.994903">
481
</page>
<bodyText confidence="0.999987388888889">
re-lexicalize the delexicalized models, while main-
taining the “universality” of the features. This ap-
proach is outlined in Figure 1. Assuming that we
have an algorithm for generating cross-lingual word
clusters (see Section 4.2), we can augment the delex-
icalized parsing algorithm to use these word cluster
features at training and testing time.
In order to further motivate the proposed approach,
consider the accuracy of the supervised English
parser. A parser with lexical, part-of-speech and
cluster features achieves 90.7% LAS (see Table 3). If
we remove all lexical and cluster features, the same
parser achieves 83.1%. However, if we add back just
the cluster features, the accuracy jumps back up to
89.5%, which is only 1.2% below the full system.
Thus, if we can accurately learn cross-lingual clus-
ters, there is hope of regaining some of the accuracy
lost due to the delexicalization process.
</bodyText>
<subsectionHeader confidence="0.957045">
4.2 Inducing Cross-lingual Word Clusters
</subsectionHeader>
<bodyText confidence="0.99997">
Our first method for inducing cross-lingual clusters
has two stages. First, it clusters a source language
(S) as in the monolingual case, and then projects
these clusters to a target language (T), using word
alignments. Given two aligned word sequences
</bodyText>
<equation confidence="0.9886225">
wS = �wS�mS
i�� and wT = �wT�� i, let AT|S be a
</equation>
<bodyText confidence="0.960615216216216">
set of scored alignments from the source language to
the target language, where (wTj , wSaj, sj,aj) ∈ AT |S
is an alignment from the ajth source word to the jth
target word, with score sj,aj ≥ δ.2 We use the short-
hand j ∈ AT |S to denote those target words wTj that
are aligned to some source word wSaj. Provided a
clustering CS, we assign the target word t ∈ VT to
the cluster with which it is most often aligned:
where [·� is the indicator function. We refer to the
cross-lingual clusters induced in this way as PRO-
JECTED CLUSTERS.
This simple projection approach has two potential
drawbacks. First, it only provides a clustering of
those target language words that occur in the word
2In our case, the alignment score corresponds to the condi-
tional alignment probability p(wTj |wSa� ). All E-alignments are
ignored and we use S = 0.95 throughout.
aligned data, which is typically smaller than our
monolingual data sets. Second, the mapped cluster-
ing may not necessarily correspond to an acceptable
target language clustering in terms of monolingual
likelihood. In order to tackle these issues, we pro-
pose the following more complex model. First, to
find clusterings that are good according to both the
source and target language, and to make use of more
unlabeled data, we model word sequences in each lan-
guage by the monolingual language model with like-
lihood function defined by equation (1). Denote these
likelihood functions respectively by LS(wS; CS) and
LT (wT; CT), where we have overloaded notation so
that the word sequences denoted by wS and wT in-
clude much more plentiful non-aligned data when
taken as an argument of the monolingual likelihood
functions. Second, we couple the clusterings defined
by these individual models, by introducing additional
factors based on word alignments, as proposed by
Och (1999):
</bodyText>
<equation confidence="0.998563333333333">
LT|S(wT;AT|S,CT,CS) =
Y p(wTj |CT (wTj ))p(CT (wTj )|CS(wSaj)) .
jEAT|S
</equation>
<bodyText confidence="0.993957833333333">
and the symmetric LS|T(wS; AS|T, CS, CT). Note
that the simple projection defined by equation (2)
correspond to a hard assignment variant of this prob-
abilistic formulation when the source clustering is
fixed. Combining all four factors results in the joint
monolingual and cross-lingual objective function
</bodyText>
<equation confidence="0.953474">
LS,T(wS, wT; AT|S,AS|T, CS, CT) =
LS(...) · LT (...) · LT|S(...) · LS|T (...) . (3)
</equation>
<bodyText confidence="0.999973461538461">
The intuition of this approach is that the clusterings
CS and CT are forced to jointly explain the source
and target data, treating the word alignments as a
form of soft constraints. We approximately optimize
(3) with the alternating procedure in Algorithm 1, in
which we iteratively maximize LS and LT , keeping
the other factors fixed. In this way we can generate
cross-lingual clusterings using all the monolingual
data while forcing the clusterings to obey the word
alignment constraints. We refer to the clusters in-
duced with this method as X-LINGUAL CLUSTERS.
In practice we found that each unconstrained
monolingual run of the exchange algorithm (lines
</bodyText>
<equation confidence="0.999343857142857">
X
k
h i
sj,aj CS(wS aj) = k , (2)
CT (t) = argmax
jEAT|S
s.t. wT j=t
</equation>
<page confidence="0.978835">
482
</page>
<table confidence="0.330615333333333">
Algorithm 1 Cross-lingual clustering.
Randomly initialize source/target clusterings CS and CT.
for = 1 ... N do
</table>
<listItem confidence="0.956718">
1. Find �CS Pz� argmaxCS LS(wS; CS). (†)
2. Project �CS to CT using equation (2).
- keep cluster of non-projected words in CT fixed.
3. Find CT Pz� argmaxcT LT (wT ; CT ). (†)
4. Project CT to CS using equation (2).
- keep cluster of non-projected words in CS fixed.
</listItem>
<subsectionHeader confidence="0.848307">
end for
</subsectionHeader>
<bodyText confidence="0.999248">
† Optimized via the exchange algorithm keeping the cluster
of projected words fixed and only clustering additional words
not in the projection.
1 and 3) moves the clustering too far from those that
obey the word alignment constraints, which causes
the procedure to fail to converge. However, we found
that fixing the clustering of the words that are as-
signed clusters in the projection stages (lines 2 and
4) and only clustering the remaining words works
well in practice. Furthermore, we found that iterating
the procedure has little effect on performance and set
N = 1 for all subsequent experiments.
</bodyText>
<sectionHeader confidence="0.998558" genericHeader="method">
5 Cross-lingual Experiments
</sectionHeader>
<bodyText confidence="0.999640408163265">
In our first set of experiments on using cross-lingual
cluster features, we evaluate direct transfer of our
EN parser, trained on Stanford style dependencies
(De Marneffe et al., 2006), to the the ten non-EN
Indo-European languages listed in Section 3. We ex-
clude KO and ZH as initial experiments proved direct
transfer a poor technique when transferring parsers
between such diverse languages. We study the impact
of using cross-lingual cluster features by comparing
the strong delexicalized baseline model of McDon-
ald et al. (2011), which only has features derived
from universal part-of-speech tags, projected from
English with the method of Das and Petrov (2011), to
the same model when adding features derived from
cross-lingual clusters. In both cases the feature mod-
els are the same as those used in Section 3.1, except
that they are delexicalized by removing all lexical
word-identity features. We evaluate both the PRO-
JECTED CLUSTERS and the X-LINGUAL CLUSTERS.
For these experiments we train the perceptron
for only five epochs in order to prevent over-fitting,
which is an acute problem due to the divergence be-
tween the training and testing data sets in this setting.
Furthermore, in accordance to standard practices we
only evaluate unlabeled attachment score (UAS) due
to the fact that each treebank uses a different – possi-
bly non-overlapping – label set.
In our second set of experiments, we evaluate di-
rect transfer of a NER system trained on EN to DE,
ES and NL. We use the same feature models as in
the monolingual case, with the exception that we use
universal part-of-speech tags for all languages and
we remove the capitalization feature when transfer-
ring from EN to DE. Capitalization is both a prevalent
and highly predictive feature of named-entities in EN,
while in DE, capitalization is even more prevalent, but
has very low predictive power. Interestingly, while
delexicalization has shown to be important for di-
rect transfer of dependency-parsers (McDonald et al.,
2011), we noticed in preliminary experiments that
it substantially degrades performance for NER. We
hypothesize that this is because word features are pre-
dictive of common proper names and that these are
often translated directly across languages, at least in
the case of newswire text. As for the transfer parser,
when training the source NER model, we regularize
the model more heavily by setting Q = 0.1.
Appendix A contains the details of the training,
testing, unlabeled and parallel/aligned data sets.
</bodyText>
<sectionHeader confidence="0.642915" genericHeader="method">
5.1 Results
</sectionHeader>
<bodyText confidence="0.99997080952381">
Table 5 lists the results of the transfer experiments
for dependency parsing. The baseline results are
comparable to those in McDonald et al. (2011) and
thus also significantly outperform the results of re-
cent unsupervised approaches (Berg-Kirkpatrick and
Klein, 2010; Naseem et al., 2010). Importantly, cross-
lingual cluster features are helpful across the board
and give a relative error reduction ranging from 3%
for DA to 13% for PT, with an average reduction of
6%, in terms of unlabeled attachment score (UAS).
This shows the utility of cross-lingual cluster fea-
tures for syntactic transfer. However, X-LINGUAL
CLUSTERS provides roughly the same performance
as PROJECTED CLUSTERS suggesting that even sim-
ple methods of cross-lingual clustering are sufficient
for direct transfer dependency parsing.
We would like to stress that these results are likely
to be under-estimating the parsers’ actual ability to
predict Stanford-style dependencies in the target lan-
guages. This is because the target language anno-
tations that we use for evaluation differ from the
</bodyText>
<page confidence="0.998173">
483
</page>
<table confidence="0.936204625">
DA DE EL ES FR IT NL PT RU SV AVG
NO CLUSTERS 36.7 48.9 59.5 60.2 70.0 64.6 52.8 66.8 29.7 55.4 54.5
PROJECTED CLUSTERS 38.9 50.3 61.1 62.6 71.6 68.6 54.5 70.7 32.9 57.0 56.8
X-LINGUAL CLUSTERS 38.7 50.7 63.0 62.9 72.1 68.8 54.3 71.0 34.4 56.9 57.3
I ALL DEPENDENCY RELATIONS I ONLY SUBJECT/OBJECT RELATIONS
NO CLUSTERS 44.6 56.7 67.2 60.7 77.4 64.6 59.5 53.3 29.3 57.3 57.1
PROJECTED CLUSTERS 49.8 57.1 72.2 65.9 80.4 70.5 67.0 62.6 34.6 65.0 62.5
X-LINGUAL CLUSTERS 49.2 59.0 72.5 65.9 80.9 72.7 65.7 62.5 37.2 64.4 63.0
</table>
<tableCaption confidence="0.977869">
Table 5: Direct transfer dependency parsing from English. Results measured by unlabeled attachment score (UAS).
ONLY SUBJECT/OBJECT RELATIONS – UAS measured only over words marked as subject/object in the evaluation data.
</tableCaption>
<bodyText confidence="0.999917333333333">
Stanford dependency annotation. Some of these dif-
ferences are warranted in that certain target language
phenomena are better captured by the native annota-
tion. However, differences such as choice of lexical
versus functional head are more arbitrary.
To highlight this point we run two additional ex-
periments. First, we had linguists, who were also
fluent speakers of German, re-annotate the DE test set
so that unlabeled arcs are consistent with Stanford-
style dependencies. Using this data, NO CLUSTERS
obtains 60.0% UAS, PROJECTED CLUSTERS 63.6%
and X-LINGUAL CLUSTERS 64.4%. When compared
to the scores on the original data set (48.9%, 50.3%
and 50.7%, respectively) we can see that not only is
the baseline system doing much better, but that the
improvements from cross-lingual clustering are much
more pronounced. Next, we investigated the accuracy
of subject and object dependencies, as these are often
annotated in similar ways across treebanks, typically
modifying the main verb of the sentence. The bottom
half of Table 5 gives the scores when restricted to
such dependencies in the gold data. We measure the
percentage of modifiers in subject and object depen-
dencies that modify the correct word. Indeed, here
we see the difference in performance become clearer,
with the cross-lingual cluster model reducing errors
by 14% relative to the non-cross-lingual model and
upwards of 22% relative for IT.
We now turn to the results of the transfer experi-
ments for NER, listed in Table 6. While the perfor-
mance of the transfer systems is very poor when no
word clusters are used, adding cross-lingual word
clusters give substantial improvements across all lan-
guages. The simple PROJECTED CLUSTERS work
well, but the X-LINGUAL CLUSTERS provide even
larger improvements. On average the latter reduce
</bodyText>
<table confidence="0.9942435">
DE ES NL AVG
NO CLUSTERS 25.4 49.5 49.9 41.6
PROJECTED CLUSTERS 39.1 62.1 61.8 54.4
X-LINGUAL CLUSTERS 43.1 62.8 64.7 56.9
I DEVELOPMENT SET I TEST SET
NO CLUSTERS 23.5 45.6 48.4 39.1
PROJECTED CLUSTERS 35.2 59.1 56.4 50.2
X-LINGUAL CLUSTERS 40.4 59.3 58.4 52.7
</table>
<tableCaption confidence="0.99655">
Table 6: Direct transfer NER results (from English) mea-
sured with average Fl-score on the CoNLL 2002/2003
development and test sets.
</tableCaption>
<bodyText confidence="0.999383083333333">
errors on the test set by 22% in terms of FI and up
to 26% for ES. We also measure how well the di-
rect transfer NER systems are able to detect entity
boundaries (ignoring the entity categories). Here, on
average, the best clusters provide a 24% relative error
reduction on the test set (75.8 vs. 68.1 FI).
To our knowledge there are no comparable results
on transfer learning of NER systems. Based on the
results of this first attempt at this scenario, we believe
that transfer learning by multilingual word clusters
could be developed into a practical way to construct
NER systems for resource poor languages.
</bodyText>
<sectionHeader confidence="0.995035" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999894375">
In the first part of this study, we showed that word
clusters induced from a simple class-based language
model can be used to significantly improve on state-
of-the-art supervised dependency parsing and NER
for a wide range of languages and even across lan-
guage families. Although the improvements vary
between languages, the addition of word cluster fea-
tures never has a negative impact on performance.
</bodyText>
<page confidence="0.99786">
484
</page>
<bodyText confidence="0.999985935483871">
This result has important practical consequences as
it allows practitioners to simply plug in word clus-
ter features into their current feature models. Given
previous work on word clusters for various linguistic
structure prediction tasks, these results are not too
surprising. However, to our knowledge this is the first
study to apply the same type of word cluster features
across languages and tasks.
In the second part, we provided two simple meth-
ods for inducing cross-lingual word clusters. The first
method works by projecting word clusters, induced
from monolingual data, from a source language to
a target language directly via word alignments. The
second method, on the other hand, makes use of
monolingual data in both the source and the target
language, together with word alignments that act as
constraints on the joint clustering. We then showed
that by using these cross-lingual word clusters, we
can significantly improve on direct transfer of dis-
criminative models for both parsing and NER. As
in the monolingual case, both types of cross-lingual
word cluster features yield improvements across the
board, with the more complex method providing a
significantly larger improvement for NER. Although
the performance of transfer systems is still substan-
tially below that of supervised systems, this research
provides one step towards bridging this gap. Further,
we believe that it opens up an avenue for future work
on multilingual clustering methods, cross-lingual fea-
ture projection and domain adaptation for direct trans-
fer of linguistic structure.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999946666666667">
We thank John DeNero for help with creating the
word alignments; Reut Tsarfaty and Joakim Nivre for
rewarding discussions on evaluation; Slav Petrov and
Kuzman Ganchev for discussions on cross-lingual
clustering; and the anonymous reviewers, along with
Joakim Nivre, for valuable comments that helped
improve the paper. The first author is grateful for the
financial support of the Swedish National Graduate
School of Language Technology (GSLT).
</bodyText>
<sectionHeader confidence="0.875438" genericHeader="method">
A Data Sets
</sectionHeader>
<bodyText confidence="0.99998785106383">
In the parsing experiments, we use the following data
sets. For DA, DE, EL, ES, IT, NL, PT and SV, we
use the predefined training and evaluation data sets
from the CoNLL 2006/2007 data sets (Buchholz and
Marsi, 2006; Nivre et al., 2007). For EN we use
sections 02-21, 22, and 23 of the Penn WSJ Tree-
bank (Marcus et al., 1993) for training, development
and evaluation. For FR we used the French Treebank
(Abeill´e and Barrier, 2004) with splits defined in Can-
dito et al. (2010). For KO we use the Sejong Korean
Treebank (Han et al., 2002) randomly splitting the
data into 80% training, 10% development and 10%
evaluation. For RU we use the SynTagRus Treebank
(Boguslavsky et al., 2000; Apresjan et al., 2006) ran-
domly splitting the data into 80% training, 10% devel-
opment and 10% evaluation. For ZH we use the Penn
Chinese Treebank v6 (Xue et al., 2005) using the
proposed data splits from the documentation. Both
EN and ZH were converted to dependencies using
v1.6.8 of the Stanford Converter (De Marneffe et al.,
2006). FR was converted using the procedure defined
in Candito et al. (2010). RU and KO are native depen-
dency treebanks. For the CoNLL data sets we use
the part-of-speech tags provided with the data. For
all other data sets, we train a part-of-speech tagger
on the training data in order to tag the development
and evaluation data.
For the NER experiments we use the training, de-
velopment and evaluation data sets from the CoNLL
2002/2003 shared tasks (Tjong Kim Sang, 2002;
Tjong Kim Sang and De Meulder, 2003) for all
four languages (DE, EN, ES and NL). The data set
for each language consists of newswire text anno-
tated with four entity categories: Location (LOC),
Miscellaneous (MISC), Organization (ORG) and Per-
son (PER). We use the part-of-speech tags supplied
with the data, except for ES where we instead use
universal part-of-speech tags (Petrov et al., 2011).
Unlabeled data for training the monolingual cluster
models was extracted from one year of newswire ar-
ticles from multiple sources from a news aggregation
website. This consists of 0.8 billion (DA) to 121.6 bil-
lion (EN) tokens per language. All word alignments
for the cross-lingual clusterings were produced with
the dual decomposition aligner described by DeNero
and Macherey (2011) using 10.5 million (DA) to 12.1
million (FR) sentences of aligned web data.
</bodyText>
<page confidence="0.99884">
485
</page>
<sectionHeader confidence="0.987734" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997876805825242">
Anne Abeill´e and Nicolas Barrier. 2004. Enriching a
french treebank. In Proceedings of LREC.
Juri Apresjan, Igor Boguslavsky, Boris Iomdin, Leonid
Iomdin, Andrei Sannikov, and Victor Sizov. 2006. A
syntactically and semantically tagged corpus of russian:
State of the art and prospects. In Proceedings of LREC.
Emily M. Bender. 2011. On achieving and evaluating
language-independence in NLP. Linguistic Issues in
Language Technology, 6(3):1–26.
Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phyloge-
netic grammar induction. In Proceedings of ACL.
Daniel M. Bikel, Richard Schwartz, and Ralph M.
Weischedel. 1999. An algorithm that learns what’s
in a name. Machine Learning, 34(1):211–231.
Igor Boguslavsky, Svetlana Grigorieva, Nikolai Grigoriev,
Leonid Kreidlin, and Nadezhda Frid. 2000. Depen-
dency treebank for Russian: Concept, tools, types of
information. In Proceedings of COLING.
Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vin-
cent J. Della Pietra, and Jenifer C. Lai. 1992. Class-
based n-gram models of natural language. Computa-
tional Linguistics, 18:467–479.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of CoNLL.
Marie Candito, Benoit Crabb´e, and Pascal Denis. 2010.
Statistical french dependency parsing: treebank conver-
sion and first results. In Proceedings of LREC.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
ACL.
Alexander Clark. 2003. Combining distributional and
morphological information for part of speech induction.
In Proceedings of EACL.
Shay B. Cohen and Noah A. Smith. 2009. Shared lo-
gistic normal distributions for soft parameter tying in
unsupervised grammar induction. In Proceedings of
NAACL.
Shay B. Cohen, Dipanjan Das, and Noah A. Smith. 2011.
Unsupervised structure prediction with non-parallel
multilingual guidance. In Proceedings of EMNLP.
Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a.
2005. Clause restructuring for statistical machine trans-
lation. In Proceedings of ACL.
Michael Collins. 1997. Three generative, lexicalised
models for statistical parsing. In Proceedings of ACL.
Ronan Collobert and Jason Weston. 2008. A unified ar-
chitecture for natural language processing: deep neural
networks with multitask learning. In Proceedings of
ICML.
Dipanjan Das and Slav Petrov. 2011. Unsupervised part-
of-speech tagging with bilingual graph-based projec-
tions. In Proceedings of ACL-HLT.
Marie-Catherine De Marneffe, Bill MacCartney, and
Chris D. Manning. 2006. Generating typed depen-
dency parses from phrase structure parses. In Proceed-
ings of LREC.
John DeNero and Klaus Macherey. 2011. Model-based
aligner combination using dual decomposition. In Pro-
ceedings of ACL-HLT.
Paramveer Dhillon, Dean Foster, and Lyle Dean. 2011.
Multi-view learning of word embeddings via cca. In
Proceedings of NIPS.
Manaal Faruqui and Sebastian Pad´o. 2010. Training
and evaluating a german named entity recognizer with
semantic generalization. In Proceedings of KONVENS.
Dayne Freitag. 2004. Trained named entity recogni-
tion using distributional clusters. In Proceedings of
EMNLP.
Jennifer Gillenwater, Kuzman Ganchev, Jo˜ao Grac¸a, Fer-
nando Pereira, and Ben Taskar. 2010. Sparsity in
dependency grammar induction. In Proceedings of
ACL.
Gholamreza Haffari, Marzieh Razavi, and Anoop Sarkar.
2011. An ensemble model that combines syntactic
and semantic clustering for discriminative dependency
parsing. In Proceedings of ACL.
Chung-hye Han, Na-Rare Han, Eon-Suk Ko, and Martha
Palmer. 2002. Development and evaluation of a korean
treebank and its application to nlp. In Proceedings of
LREC.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Natural Language Engineering, 11(03):311–325.
Dan Klein and Chris D. Manning. 2004. Corpus-based
induction of syntactic structure: models of dependency
and constituency. In Proceedings of ACL.
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
Simple semi-supervised dependency parsing. In Pro-
ceedings of ACL-HLT.
Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009.
Dependency parsing. Morgan &amp; Claypool Publishers.
Dekang Lin and Xiaoyun Wu. 2009. Phrase clustering
for discriminative learning. In Proceedings of ACL-
IJCNLP, pages 1030–1038.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-
rice Santorini. 1993. Building a large annotated corpus
of English: the Penn treebank. Computational Linguis-
tics, 19(2):313–330.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of EMNLP.
</reference>
<page confidence="0.988471">
486
</page>
<reference confidence="0.999833803030303">
Scott Miller, Jethran Guinness, and Alex Zamanian. 2004.
Name tagging with word clusters and discriminative
training. In Proceedings of HLT-NAACL.
Andriy Mnih and Geoffrey Hinton. 2007. Three new
graphical models for statistical language modelling. In
Proceedings of ICML.
Tahira Naseem, Harr Chen, Regina Barzilay, and Mark
Johnson. 2010. Using universal linguistic knowl-
edge to guide grammar induction. In Proceedings of
EMNLP.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDon-
ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007. The CoNLL 2007 shared task on dependency
parsing. In Proceedings of EMNLP-CoNLL.
Joakim Nivre. 2008. Algorithms for deterministic incre-
mental dependency parsing. Computational Linguis-
tics, 34(4):513–553.
Franz Josef Och. 1999. An efficient method for determin-
ing bilingual word classes. In Proceedings of EACL.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Now Publishers Inc.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A
universal part-of-speech tagset. In ArXiv:1104.2086.
Adwait Ratnaparkhi. 1996. A maximum entropy model
for part-of-speech tagging. In Proceedings of EMNLP.
Noah A. Smith. 2011. Linguistic Structure Prediction.
Morgan &amp; Claypool Publishers.
Anders Søgaard. 2011. Data point selection for cross-
language adaptation of dependency parsers. In Pro-
ceedings of ACL.
Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Juraf-
sky. 2011. Lateen EM: Unsupervised training with
multiple objectives, applied to dependency grammar
induction. In Proceedings of EMNLP.
Erik F. Tjong Kim Sang and Fien De Meulder. 2003.
Introduction to the conll-2003 shared task: Language-
independent named entity recognition. In Proceedings
of CoNLL.
Erik F. Tjong Kim Sang. 2002. Introduction to the conll-
2002 shared task: Language-independent named entity
recognition. In Proceedings of CoNLL.
Stephen Tratz and Eduard Hovy. 2011. A fast, effec-
tive, non-projective, semantically-enriched parser. In
Proceedings of EMNLP.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceedings
of ACL.
Jakob Uszkoreit and Thorsten Brants. 2008. Distributed
word clustering for large scale class-based language
modeling in machine translation. In Proceedings of
ACL-HLT.
Naiwen Xue, Fei Xia, Fu-dong Chiou, and Marta Palmer.
2005. The penn chinese treebank: Phrase structure
annotation of a large corpus. Natural Language Engi-
neering, 11(02):207–238.
Daniel Zeman and Philip Resnik. 2008. Cross-language
parser adaptation between related languages. In IJC-
NLP Workshop: NLP for Less Privileged Languages.
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings
of EMNLP.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of ACL-HLT.
</reference>
<page confidence="0.998395">
487
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.311871">
<title confidence="0.997168">Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure</title>
<author confidence="0.94845">McDonald Jakob Uszkoreit</author>
<affiliation confidence="0.376749">SICS / Uppsala University Google Google</affiliation>
<address confidence="0.370083">Kista / Uppsala, Sweden New York, NY Mountain View, CA</address>
<email confidence="0.973119">oscar@sics.seryanmcd@google.comuszkoreit@google.com</email>
<abstract confidence="0.998933272727273">It has been established that incorporating word cluster features derived from large unlabeled corpora can significantly improve prediction of linguistic structure. While previous work has focused primarily on English, we extend these results to other languages along two dimensions. First, we show that these results hold true for a number of languages across families. Second, and more interestingly, we provide an algorithm for inducing cross-lingual clusters and we show that features derived from these clusters significantly improve the accuracy of cross-lingual structure prediction. Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%. When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
<author>Nicolas Barrier</author>
</authors>
<title>Enriching a french treebank.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC.</booktitle>
<marker>Abeill´e, Barrier, 2004</marker>
<rawString>Anne Abeill´e and Nicolas Barrier. 2004. Enriching a french treebank. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Apresjan</author>
<author>Igor Boguslavsky</author>
<author>Boris Iomdin</author>
<author>Leonid Iomdin</author>
<author>Andrei Sannikov</author>
<author>Victor Sizov</author>
</authors>
<title>A syntactically and semantically tagged corpus of russian: State of the art and prospects.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="35192" citStr="Apresjan et al., 2006" startWordPosition="5649" endWordPosition="5652">L, PT and SV, we use the predefined training and evaluation data sets from the CoNLL 2006/2007 data sets (Buchholz and Marsi, 2006; Nivre et al., 2007). For EN we use sections 02-21, 22, and 23 of the Penn WSJ Treebank (Marcus et al., 1993) for training, development and evaluation. For FR we used the French Treebank (Abeill´e and Barrier, 2004) with splits defined in Candito et al. (2010). For KO we use the Sejong Korean Treebank (Han et al., 2002) randomly splitting the data into 80% training, 10% development and 10% evaluation. For RU we use the SynTagRus Treebank (Boguslavsky et al., 2000; Apresjan et al., 2006) randomly splitting the data into 80% training, 10% development and 10% evaluation. For ZH we use the Penn Chinese Treebank v6 (Xue et al., 2005) using the proposed data splits from the documentation. Both EN and ZH were converted to dependencies using v1.6.8 of the Stanford Converter (De Marneffe et al., 2006). FR was converted using the procedure defined in Candito et al. (2010). RU and KO are native dependency treebanks. For the CoNLL data sets we use the part-of-speech tags provided with the data. For all other data sets, we train a part-of-speech tagger on the training data in order to ta</context>
</contexts>
<marker>Apresjan, Boguslavsky, Iomdin, Iomdin, Sannikov, Sizov, 2006</marker>
<rawString>Juri Apresjan, Igor Boguslavsky, Boris Iomdin, Leonid Iomdin, Andrei Sannikov, and Victor Sizov. 2006. A syntactically and semantically tagged corpus of russian: State of the art and prospects. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily M Bender</author>
</authors>
<title>On achieving and evaluating language-independence in NLP.</title>
<date>2011</date>
<journal>Linguistic Issues in Language Technology,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="2586" citStr="Bender (2011)" startWordPosition="387" endWordPosition="388">York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate the literature on linguistic structure prediction (Smith, 2011). Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources. Notable exceptions include the CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011). While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages. This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they </context>
</contexts>
<marker>Bender, 2011</marker>
<rawString>Emily M. Bender. 2011. On achieving and evaluating language-independence in NLP. Linguistic Issues in Language Technology, 6(3):1–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Phylogenetic grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="16754" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="2670" endWordPosition="2673">rian et al. (2010). 4 Cross-lingual Word Cluster Features All results of the previous section rely on the availability of large quantities of language specific annotations for each task. Cross-lingual transfer methods and unsupervised methods have recently been shown to hold promise as a way to at least partially sidestep the demand for labeled data. Unsupervised methods attempt to infer linguistic structure without using any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010). The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005). Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering model. Top-right: Samples of some of the induced cross-lingual word clusters. Bott</context>
<context position="27675" citStr="Berg-Kirkpatrick and Klein, 2010" startWordPosition="4431" endWordPosition="4434">ictive of common proper names and that these are often translated directly across languages, at least in the case of newswire text. As for the transfer parser, when training the source NER model, we regularize the model more heavily by setting Q = 0.1. Appendix A contains the details of the training, testing, unlabeled and parallel/aligned data sets. 5.1 Results Table 5 lists the results of the transfer experiments for dependency parsing. The baseline results are comparable to those in McDonald et al. (2011) and thus also significantly outperform the results of recent unsupervised approaches (Berg-Kirkpatrick and Klein, 2010; Naseem et al., 2010). Importantly, crosslingual cluster features are helpful across the board and give a relative error reduction ranging from 3% for DA to 13% for PT, with an average reduction of 6%, in terms of unlabeled attachment score (UAS). This shows the utility of cross-lingual cluster features for syntactic transfer. However, X-LINGUAL CLUSTERS provides roughly the same performance as PROJECTED CLUSTERS suggesting that even simple methods of cross-lingual clustering are sufficient for direct transfer dependency parsing. We would like to stress that these results are likely to be und</context>
</contexts>
<marker>Berg-Kirkpatrick, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick and Dan Klein. 2010. Phylogenetic grammar induction. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
<author>Richard Schwartz</author>
<author>Ralph M Weischedel</author>
</authors>
<title>An algorithm that learns what’s in a name.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="1465" citStr="Bikel et al., 1999" startWordPosition="207" endWordPosition="210"> structure prediction. Specifically, we show that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%. When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%. 1 Introduction The ability to predict the linguistic structure of sentences or documents is central to the field of natural language processing (NLP). Structures such as named-entity tag sequences (Bikel et al., 1999) or sentiment relations (Pang and Lee, 2008) are inherently useful in data mining, information retrieval and other user-facing technologies. More fundamental structures such as part-of-speech tag sequences (Ratnaparkhi, 1996) or syntactic parse trees (Collins, 1997; K¨ubler et al., 2009), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate th</context>
</contexts>
<marker>Bikel, Schwartz, Weischedel, 1999</marker>
<rawString>Daniel M. Bikel, Richard Schwartz, and Ralph M. Weischedel. 1999. An algorithm that learns what’s in a name. Machine Learning, 34(1):211–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Boguslavsky</author>
<author>Svetlana Grigorieva</author>
<author>Nikolai Grigoriev</author>
<author>Leonid Kreidlin</author>
<author>Nadezhda Frid</author>
</authors>
<title>Dependency treebank for Russian: Concept, tools, types of information.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="35168" citStr="Boguslavsky et al., 2000" startWordPosition="5645" endWordPosition="5648"> For DA, DE, EL, ES, IT, NL, PT and SV, we use the predefined training and evaluation data sets from the CoNLL 2006/2007 data sets (Buchholz and Marsi, 2006; Nivre et al., 2007). For EN we use sections 02-21, 22, and 23 of the Penn WSJ Treebank (Marcus et al., 1993) for training, development and evaluation. For FR we used the French Treebank (Abeill´e and Barrier, 2004) with splits defined in Candito et al. (2010). For KO we use the Sejong Korean Treebank (Han et al., 2002) randomly splitting the data into 80% training, 10% development and 10% evaluation. For RU we use the SynTagRus Treebank (Boguslavsky et al., 2000; Apresjan et al., 2006) randomly splitting the data into 80% training, 10% development and 10% evaluation. For ZH we use the Penn Chinese Treebank v6 (Xue et al., 2005) using the proposed data splits from the documentation. Both EN and ZH were converted to dependencies using v1.6.8 of the Stanford Converter (De Marneffe et al., 2006). FR was converted using the procedure defined in Candito et al. (2010). RU and KO are native dependency treebanks. For the CoNLL data sets we use the part-of-speech tags provided with the data. For all other data sets, we train a part-of-speech tagger on the trai</context>
</contexts>
<marker>Boguslavsky, Grigorieva, Grigoriev, Kreidlin, Frid, 2000</marker>
<rawString>Igor Boguslavsky, Svetlana Grigorieva, Nikolai Grigoriev, Leonid Kreidlin, and Nadezhda Frid. 2000. Dependency treebank for Russian: Concept, tools, types of information. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V deSouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Classbased n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--467</pages>
<contexts>
<context position="5773" citStr="Brown et al., 1992" startWordPosition="889" endWordPosition="892">s-lingual word-cluster constraints are enforced. We show that by augmenting the delexicalized direct transfer system of McDonald et al. (2011) with cross-lingual cluster features, we are able to reduce its error by up to 13% relative. Further, we show that by applying the same method to direct-transfer NER, we achieve a relative error reduction of 26%. In line with much previous work on word clusters for tasks such as dependency parsing and NER, for which local syntactic and semantic constraints are of importance, we induce word clusters by means of a probabilistic class-based language model (Brown et al., 1992; Clark, 2003). However, rather than the more commonly used model of Brown et al. (1992), we use the predictive class bigram model introduced by Uszkoreit and Brants (2008). The two models are very similar, but whereas the former takes classto-class transitions into account, the latter directly models word-to-class transitions. By ignoring classto-class transitions, an approximate maximum likelihood clustering can be found efficiently with the distributed exchange algorithm (Uszkoreit and Brants, 2008). This is a useful property, as we later develop an algorithm for inducing cross-lingual word</context>
<context position="8363" citStr="Brown et al. (1992)" startWordPosition="1304" endWordPosition="1307">e of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Uszkoreit and Brants, 2008). In addition to the clustering model that we make use of in this study, a number of additional word clustering and embedding variants have been proposed. For example, Turian et al. (2010) assessed the effectiveness of the word embedding techniques of Collobert and Weston (2008) and Mnih and Hinton (2007) along with the word clustering technique of Brown et al. (1992) for syntactic chunking and NER. Recently, Dhillon et al. (2011) proposed a word 478 Single words S0c{p}, N0c{p}, N1c{p}, N2c{p} Word pairs S0c{p}N0c{p}, S0pcN0p, S0pN0pc, S0wN0c, S0cN0w, N0cN1c, N1cN2c Word triples N0cN1cN2c, S0cN0cN1c, S0hcS0cN0c, S0cS0lcN0c, S0cS0rcN0c, S0cN0cN0lc Distance S0cd, N0cd, S0cN0cd Valency S0cvl, S0cvr, N0cS0vl Unigrams S0hc, S0lc, S0rc, N0lc Third-order S0h2c, S0l2c, S0r2c, N0l2c Label set S0cS0ll, S0cS0rl, N0cN0ll, N0cN0rl Table 1: Additional cluster-based parser features. Si and Ni: the ith tokens in the stack and buffer. p: the part-ofspeech tag, c: the clust</context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Classbased n-gram models of natural language. Computational Linguistics, 18:467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="2425" citStr="Buchholz and Marsi, 2006" startWordPosition="356" endWordPosition="359">c analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate the literature on linguistic structure prediction (Smith, 2011). Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources. Notable exceptions include the CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011). While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages. This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit fr</context>
<context position="34700" citStr="Buchholz and Marsi, 2006" startWordPosition="5562" endWordPosition="5565">ord alignments; Reut Tsarfaty and Joakim Nivre for rewarding discussions on evaluation; Slav Petrov and Kuzman Ganchev for discussions on cross-lingual clustering; and the anonymous reviewers, along with Joakim Nivre, for valuable comments that helped improve the paper. The first author is grateful for the financial support of the Swedish National Graduate School of Language Technology (GSLT). A Data Sets In the parsing experiments, we use the following data sets. For DA, DE, EL, ES, IT, NL, PT and SV, we use the predefined training and evaluation data sets from the CoNLL 2006/2007 data sets (Buchholz and Marsi, 2006; Nivre et al., 2007). For EN we use sections 02-21, 22, and 23 of the Penn WSJ Treebank (Marcus et al., 1993) for training, development and evaluation. For FR we used the French Treebank (Abeill´e and Barrier, 2004) with splits defined in Candito et al. (2010). For KO we use the Sejong Korean Treebank (Han et al., 2002) randomly splitting the data into 80% training, 10% development and 10% evaluation. For RU we use the SynTagRus Treebank (Boguslavsky et al., 2000; Apresjan et al., 2006) randomly splitting the data into 80% training, 10% development and 10% evaluation. For ZH we use the Penn C</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabb´e</author>
<author>Pascal Denis</author>
</authors>
<title>Statistical french dependency parsing: treebank conversion and first results.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC.</booktitle>
<marker>Candito, Crabb´e, Denis, 2010</marker>
<rawString>Marie Candito, Benoit Crabb´e, and Pascal Denis. 2010. Statistical french dependency parsing: treebank conversion and first results. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Clark</author>
</authors>
<title>Combining distributional and morphological information for part of speech induction.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="5787" citStr="Clark, 2003" startWordPosition="893" endWordPosition="894">er constraints are enforced. We show that by augmenting the delexicalized direct transfer system of McDonald et al. (2011) with cross-lingual cluster features, we are able to reduce its error by up to 13% relative. Further, we show that by applying the same method to direct-transfer NER, we achieve a relative error reduction of 26%. In line with much previous work on word clusters for tasks such as dependency parsing and NER, for which local syntactic and semantic constraints are of importance, we induce word clusters by means of a probabilistic class-based language model (Brown et al., 1992; Clark, 2003). However, rather than the more commonly used model of Brown et al. (1992), we use the predictive class bigram model introduced by Uszkoreit and Brants (2008). The two models are very similar, but whereas the former takes classto-class transitions into account, the latter directly models word-to-class transitions. By ignoring classto-class transitions, an approximate maximum likelihood clustering can be found efficiently with the distributed exchange algorithm (Uszkoreit and Brants, 2008). This is a useful property, as we later develop an algorithm for inducing cross-lingual word clusters that</context>
</contexts>
<marker>Clark, 2003</marker>
<rawString>Alexander Clark. 2003. Combining distributional and morphological information for part of speech induction. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="3376" citStr="Cohen and Smith, 2009" startWordPosition="511" endWordPosition="514">s in all languages. This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they are often inherently language independent. This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011). However, the performance for most languages is still well below that of supervised systems and recent work has established that the performance is also below simple methods of linguistic transfer (McDonald et al., 2011). In this study we focus on semi-supervised and linguistic-transfer methods for multilingual structure prediction. In particular, we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of </context>
</contexts>
<marker>Cohen, Smith, 2009</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2009. Shared logistic normal distributions for soft parameter tying in unsupervised grammar induction. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Unsupervised structure prediction with non-parallel multilingual guidance.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="17120" citStr="Cohen et al., 2011" startWordPosition="2733" endWordPosition="2736"> to infer linguistic structure without using any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010). The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005). Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering model. Top-right: Samples of some of the induced cross-lingual word clusters. Bottom-left: Delexicalized cluster-augmented source (EN) treebank for training transfer parser. Bottom-right: Parsing of target (ES) sentence using the transfer parser. 4.1 Direct Transfer of Discriminative Models Our starting point is the delexicalized direct transfer method proposed by McDonald et al. (2011) based on work by Zeman and Resnik (2008). This method was </context>
</contexts>
<marker>Cohen, Das, Smith, 2011</marker>
<rawString>Shay B. Cohen, Dipanjan Das, and Noah A. Smith. 2011. Unsupervised structure prediction with non-parallel multilingual guidance. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kuˇcerov´a</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Collins, Koehn, Kuˇcerov´a, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a. 2005. Clause restructuring for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1730" citStr="Collins, 1997" startWordPosition="247" endWordPosition="248"> 13%. When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%. 1 Introduction The ability to predict the linguistic structure of sentences or documents is central to the field of natural language processing (NLP). Structures such as named-entity tag sequences (Bikel et al., 1999) or sentiment relations (Pang and Lee, 2008) are inherently useful in data mining, information retrieval and other user-facing technologies. More fundamental structures such as part-of-speech tag sequences (Ratnaparkhi, 1996) or syntactic parse trees (Collins, 1997; K¨ubler et al., 2009), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate the literature on linguistic structure prediction (Smith, 2011). Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources. Notable exceptions include the CoNLL sh</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="8272" citStr="Collobert and Weston (2008)" startWordPosition="1287" endWordPosition="1290">pervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Uszkoreit and Brants, 2008). In addition to the clustering model that we make use of in this study, a number of additional word clustering and embedding variants have been proposed. For example, Turian et al. (2010) assessed the effectiveness of the word embedding techniques of Collobert and Weston (2008) and Mnih and Hinton (2007) along with the word clustering technique of Brown et al. (1992) for syntactic chunking and NER. Recently, Dhillon et al. (2011) proposed a word 478 Single words S0c{p}, N0c{p}, N1c{p}, N2c{p} Word pairs S0c{p}N0c{p}, S0pcN0p, S0pN0pc, S0wN0c, S0cN0w, N0cN1c, N1cN2c Word triples N0cN1cN2c, S0cN0cN1c, S0hcS0cN0c, S0cS0lcN0c, S0cS0rcN0c, S0cN0cN0lc Distance S0cd, N0cd, S0cN0cd Valency S0cvl, S0cvr, N0cS0vl Unigrams S0hc, S0lc, S0rc, N0lc Third-order S0h2c, S0l2c, S0r2c, N0l2c Label set S0cS0ll, S0cS0rl, N0cN0ll, N0cN0rl Table 1: Additional cluster-based parser features</context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: deep neural networks with multitask learning. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised partof-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="19020" citStr="Das and Petrov (2011)" startWordPosition="3004" endWordPosition="3007">n place of fine-grained statistics such as lexical word identities. Second, that the parameters of features over coarsegrained statistics are in some sense language independent, e.g., a feature that indicates that adjectives modify their closest noun is useful in all languages. Third, that these coarse-grained statistics are robustly available across languages. The approach proposed by McDonald et al. (2011) relies on these three assumptions. Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features. A cross-lingual word clustering is a clustering of words in two languages, in which the clusters correspond to some meaningful cross-lingual property. For example, prepositions from both languages should be in the same cluster, proper names from both languages in another cluster and so on. By adding features defined over these clusters, we can, to some degree, 481 re-lexical</context>
<context position="25560" citStr="Das and Petrov (2011)" startWordPosition="4090" endWordPosition="4093">s-lingual cluster features, we evaluate direct transfer of our EN parser, trained on Stanford style dependencies (De Marneffe et al., 2006), to the the ten non-EN Indo-European languages listed in Section 3. We exclude KO and ZH as initial experiments proved direct transfer a poor technique when transferring parsers between such diverse languages. We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al. (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters. In both cases the feature models are the same as those used in Section 3.1, except that they are delexicalized by removing all lexical word-identity features. We evaluate both the PROJECTED CLUSTERS and the X-LINGUAL CLUSTERS. For these experiments we train the perceptron for only five epochs in order to prevent over-fitting, which is an acute problem due to the divergence between the training and testing data sets in this setting. Furthermore, in accordance to standard practices we only evaluate unlabeled attachment</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised partof-speech tagging with bilingual graph-based projections. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Chris D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC.</booktitle>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, and Chris D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Klaus Macherey</author>
</authors>
<title>Model-based aligner combination using dual decomposition.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<marker>DeNero, Macherey, 2011</marker>
<rawString>John DeNero and Klaus Macherey. 2011. Model-based aligner combination using dual decomposition. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paramveer Dhillon</author>
<author>Dean Foster</author>
<author>Lyle Dean</author>
</authors>
<title>Multi-view learning of word embeddings via cca.</title>
<date>2011</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="8427" citStr="Dhillon et al. (2011)" startWordPosition="1314" endWordPosition="1317">s, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Uszkoreit and Brants, 2008). In addition to the clustering model that we make use of in this study, a number of additional word clustering and embedding variants have been proposed. For example, Turian et al. (2010) assessed the effectiveness of the word embedding techniques of Collobert and Weston (2008) and Mnih and Hinton (2007) along with the word clustering technique of Brown et al. (1992) for syntactic chunking and NER. Recently, Dhillon et al. (2011) proposed a word 478 Single words S0c{p}, N0c{p}, N1c{p}, N2c{p} Word pairs S0c{p}N0c{p}, S0pcN0p, S0pN0pc, S0wN0c, S0cN0w, N0cN1c, N1cN2c Word triples N0cN1cN2c, S0cN0cN1c, S0hcS0cN0c, S0cS0lcN0c, S0cS0rcN0c, S0cN0cN0lc Distance S0cd, N0cd, S0cN0cd Valency S0cvl, S0cvr, N0cS0vl Unigrams S0hc, S0lc, S0rc, N0lc Third-order S0h2c, S0l2c, S0r2c, N0l2c Label set S0cS0ll, S0cS0rl, N0cN0ll, N0cN0rl Table 1: Additional cluster-based parser features. Si and Ni: the ith tokens in the stack and buffer. p: the part-ofspeech tag, c: the cluster. v: the valence of the left (l) or right (r) set of children.</context>
</contexts>
<marker>Dhillon, Foster, Dean, 2011</marker>
<rawString>Paramveer Dhillon, Dean Foster, and Lyle Dean. 2011. Multi-view learning of word embeddings via cca. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaal Faruqui</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Training and evaluating a german named entity recognizer with semantic generalization.</title>
<date>2010</date>
<booktitle>In Proceedings of KONVENS.</booktitle>
<marker>Faruqui, Pad´o, 2010</marker>
<rawString>Manaal Faruqui and Sebastian Pad´o. 2010. Training and evaluating a german named entity recognizer with semantic generalization. In Proceedings of KONVENS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dayne Freitag</author>
</authors>
<title>Trained named entity recognition using distributional clusters.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="4397" citStr="Freitag, 2004" startWordPosition="664" endWordPosition="665"> In particular, we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics 1. Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguistic structure. Previous studies on this approach have typically focused only on a small set of languages and tasks (Freitag, 2004; Miller et al., 2004; Koo et al., 2008; Turian et al., 2010; Faruqui and Pad´o, 2010; Haffari et al., 2011; Tratz and Hovy, 2011). Here we show that this method is robust across 13 languages for dependency parsing and 4 languages for named-entity recognition (NER). This is the first study with such a broad view on this subject, in terms of language diversity. 2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages. We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across langua</context>
<context position="7369" citStr="Freitag, 2004" startWordPosition="1150" endWordPosition="1151">mbol, factors as m L(w; C) = P(wi|C(wi))P(C(wi)|wi−1) . (1) i=1 Compare this to the model of Brown et al. (1992): By incorporating cross-lingual cluster features in a m linguistic transfer system, we are for the first time L&apos;(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) . combining SSL and cross-lingual transfer. i=1 2 Monolingual Word Cluster Features Word cluster features have been shown to be useful in various tasks in natural language processing, including syntactic dependency parsing (Koo et al., 2008; Haffari et al., 2011; Tratz and Hovy, 2011), syntactic chunking (Turian et al., 2010), and NER (Freitag, 2004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010). Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Usz</context>
</contexts>
<marker>Freitag, 2004</marker>
<rawString>Dayne Freitag. 2004. Trained named entity recognition using distributional clusters. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Gillenwater</author>
<author>Kuzman Ganchev</author>
<author>Jo˜ao Grac¸a</author>
<author>Fernando Pereira</author>
<author>Ben Taskar</author>
</authors>
<title>Sparsity in dependency grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<marker>Gillenwater, Ganchev, Grac¸a, Pereira, Taskar, 2010</marker>
<rawString>Jennifer Gillenwater, Kuzman Ganchev, Jo˜ao Grac¸a, Fernando Pereira, and Ben Taskar. 2010. Sparsity in dependency grammar induction. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gholamreza Haffari</author>
<author>Marzieh Razavi</author>
<author>Anoop Sarkar</author>
</authors>
<title>An ensemble model that combines syntactic and semantic clustering for discriminative dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="4504" citStr="Haffari et al., 2011" startWordPosition="682" endWordPosition="686">ative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics 1. Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguistic structure. Previous studies on this approach have typically focused only on a small set of languages and tasks (Freitag, 2004; Miller et al., 2004; Koo et al., 2008; Turian et al., 2010; Faruqui and Pad´o, 2010; Haffari et al., 2011; Tratz and Hovy, 2011). Here we show that this method is robust across 13 languages for dependency parsing and 4 languages for named-entity recognition (NER). This is the first study with such a broad view on this subject, in terms of language diversity. 2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages. We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages. This is achieved by means of a probabilistic model over large amounts of monolingual data in two langu</context>
<context position="7280" citStr="Haffari et al., 2011" startWordPosition="1134" endWordPosition="1137">ence of word tokens, w = (wi)mi=1, with wi E V U {S}, where S is a designated start-ofsegment symbol, factors as m L(w; C) = P(wi|C(wi))P(C(wi)|wi−1) . (1) i=1 Compare this to the model of Brown et al. (1992): By incorporating cross-lingual cluster features in a m linguistic transfer system, we are for the first time L&apos;(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) . combining SSL and cross-lingual transfer. i=1 2 Monolingual Word Cluster Features Word cluster features have been shown to be useful in various tasks in natural language processing, including syntactic dependency parsing (Koo et al., 2008; Haffari et al., 2011; Tratz and Hovy, 2011), syntactic chunking (Turian et al., 2010), and NER (Freitag, 2004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010). Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering lar</context>
</contexts>
<marker>Haffari, Razavi, Sarkar, 2011</marker>
<rawString>Gholamreza Haffari, Marzieh Razavi, and Anoop Sarkar. 2011. An ensemble model that combines syntactic and semantic clustering for discriminative dependency parsing. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung-hye Han</author>
<author>Na-Rare Han</author>
<author>Eon-Suk Ko</author>
<author>Martha Palmer</author>
</authors>
<title>Development and evaluation of a korean treebank and its application to nlp.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC.</booktitle>
<contexts>
<context position="35022" citStr="Han et al., 2002" startWordPosition="5622" endWordPosition="5625">the Swedish National Graduate School of Language Technology (GSLT). A Data Sets In the parsing experiments, we use the following data sets. For DA, DE, EL, ES, IT, NL, PT and SV, we use the predefined training and evaluation data sets from the CoNLL 2006/2007 data sets (Buchholz and Marsi, 2006; Nivre et al., 2007). For EN we use sections 02-21, 22, and 23 of the Penn WSJ Treebank (Marcus et al., 1993) for training, development and evaluation. For FR we used the French Treebank (Abeill´e and Barrier, 2004) with splits defined in Candito et al. (2010). For KO we use the Sejong Korean Treebank (Han et al., 2002) randomly splitting the data into 80% training, 10% development and 10% evaluation. For RU we use the SynTagRus Treebank (Boguslavsky et al., 2000; Apresjan et al., 2006) randomly splitting the data into 80% training, 10% development and 10% evaluation. For ZH we use the Penn Chinese Treebank v6 (Xue et al., 2005) using the proposed data splits from the documentation. Both EN and ZH were converted to dependencies using v1.6.8 of the Stanford Converter (De Marneffe et al., 2006). FR was converted using the procedure defined in Candito et al. (2010). RU and KO are native dependency treebanks. Fo</context>
</contexts>
<marker>Han, Han, Ko, Palmer, 2002</marker>
<rawString>Chung-hye Han, Na-Rare Han, Eon-Suk Ko, and Martha Palmer. 2002. Development and evaluation of a korean treebank and its application to nlp. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>03</issue>
<contexts>
<context position="2937" citStr="Hwa et al., 2005" startWordPosition="444" endWordPosition="447">e CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011). While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages. This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they are often inherently language independent. This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011). However, the performance for most languages is still well below that of supervised sys</context>
<context position="16983" citStr="Hwa et al., 2005" startWordPosition="2712" endWordPosition="2715">ve recently been shown to hold promise as a way to at least partially sidestep the demand for labeled data. Unsupervised methods attempt to infer linguistic structure without using any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010). The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005). Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering model. Top-right: Samples of some of the induced cross-lingual word clusters. Bottom-left: Delexicalized cluster-augmented source (EN) treebank for training transfer parser. Bottom-right: Parsing of target (ES) sentence using the transfer parser. 4.1 Direct Transfer of Discriminative Models Our starting point </context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11(03):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Chris D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2869" citStr="Klein and Manning, 2004" startWordPosition="433" endWordPosition="436">e language with the most annotated resources. Notable exceptions include the CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011). While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages. This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they are often inherently language independent. This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011). However, the perfo</context>
<context position="16591" citStr="Klein and Manning, 2004" startWordPosition="2645" endWordPosition="2648">s the number of clusters (Turian et al., 2010; Faruqui and Pad´o, 2010), and that we did not apply any heuristic for data cleaning such as that used by Turian et al. (2010). 4 Cross-lingual Word Cluster Features All results of the previous section rely on the availability of large quantities of language specific annotations for each task. Cross-lingual transfer methods and unsupervised methods have recently been shown to hold promise as a way to at least partially sidestep the demand for labeled data. Unsupervised methods attempt to infer linguistic structure without using any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010). The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005). Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual wo</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Chris D. Manning. 2004. Corpus-based induction of syntactic structure: models of dependency and constituency. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="2905" citStr="Koo et al., 2008" startWordPosition="438" endWordPosition="441">s. Notable exceptions include the CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011). While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages. This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they are often inherently language independent. This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011). However, the performance for most languages is still w</context>
<context position="4436" citStr="Koo et al., 2008" startWordPosition="670" endWordPosition="673">of research around the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics 1. Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguistic structure. Previous studies on this approach have typically focused only on a small set of languages and tasks (Freitag, 2004; Miller et al., 2004; Koo et al., 2008; Turian et al., 2010; Faruqui and Pad´o, 2010; Haffari et al., 2011; Tratz and Hovy, 2011). Here we show that this method is robust across 13 languages for dependency parsing and 4 languages for named-entity recognition (NER). This is the first study with such a broad view on this subject, in terms of language diversity. 2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages. We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages. This is achieved by means of a pro</context>
<context position="7258" citStr="Koo et al., 2008" startWordPosition="1130" endWordPosition="1133">kelihood of a sequence of word tokens, w = (wi)mi=1, with wi E V U {S}, where S is a designated start-ofsegment symbol, factors as m L(w; C) = P(wi|C(wi))P(C(wi)|wi−1) . (1) i=1 Compare this to the model of Brown et al. (1992): By incorporating cross-lingual cluster features in a m linguistic transfer system, we are for the first time L&apos;(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) . combining SSL and cross-lingual transfer. i=1 2 Monolingual Word Cluster Features Word cluster features have been shown to be useful in various tasks in natural language processing, including syntactic dependency parsing (Koo et al., 2008; Haffari et al., 2011; Tratz and Hovy, 2011), syntactic chunking (Turian et al., 2010), and NER (Freitag, 2004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010). Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsit</context>
<context position="14277" citStr="Koo et al., 2008" startWordPosition="2259" endWordPosition="2262"> Fl-score on the CoNLL 2002/2003 development and test sets. 3.2 Results The results of the parsing experiments, measured with labeled accuracy score (LAS) on all sentence lengths, excluding punctuation, are shown in Table 3. The baselines are all comparable to the state-of-theart. On average, the addition of word cluster features yields a 6% relative reduction in error and upwards of 15% (for RU). All languages improve except FR, which sees neither an increase nor a decrease in LAS. We observe an average absolute increase in LAS of approximately 1%, which is inline with previous observations (Koo et al., 2008). It is perhaps not surprising that RU sees a large gain as it is a highly inflected language, making observations of lexical features far more sparse. Some languages, e.g., FR, NL, and ZH see much smaller gains. One likely culprit is a divergence between the tokenization schemes used in the treebank and in our unlabeled data, which for Indo-European languages is closely related to the Penn Treebank tokenization. For example, the NL treebank contains many multi-word tokens that are typically broken apart by our automatic tokenizer. The NER results, in terms of F1 measure, are listed in Table 4</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency parsing.</title>
<date>2009</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009. Dependency parsing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Xiaoyun Wu</author>
</authors>
<title>Phrase clustering for discriminative learning.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLIJCNLP,</booktitle>
<pages>1030--1038</pages>
<contexts>
<context position="9466" citStr="Lin and Wu (2009)" startWordPosition="1480" endWordPosition="1483">r-based parser features. Si and Ni: the ith tokens in the stack and buffer. p: the part-ofspeech tag, c: the cluster. v: the valence of the left (l) or right (r) set of children. l: the label of the token under consideration. d: distance between the words on the top of the stack and buffer. Sih, Sir and Sil: the head, right-most modifier and left-most modifier of the token at the top of the stack. Gx{y} expands to Gxy and Gx. embedding method based on canonical correlation analysis that provides state-of-the art results for wordbased SSL for English NER. As an alternative to clustering words, Lin and Wu (2009) proposed a phrase clustering approach that obtained the state-of-the-art result for English NER. 3 Monolingual Cluster Experiments Before moving on to the multilingual setting, we conduct a set of monolingual experiments where we evaluate the use of the monolingual word clusters just described as features for dependency parsing and NER. In the parsing experiments, we study the following thirteen languages:1 Danish (DA), German (DE), Greek (EL), English (EN), Spanish (ES), French (FR), Italian (IT), Korean (KO), Dutch (NL), Portugese (PT), Russian (RU), Swedish (SV) and Chinese (ZH) – represen</context>
<context position="15491" citStr="Lin and Wu, 2009" startWordPosition="2467" endWordPosition="2470"> 4. Introducing word cluster features for NER reduces relative errors on the test set by 21% (39% on the development set) on average. Broken down per language, reductions on the test set vary from substantial for NL (30%) and EN (26%), down to more modest for DE (17%) and ES (12%). The addition of cluster features most markedly improve recognition of the PER category, with an average error reduction on the test set of 44%, while the reductions for ORG (19%), LOC (17%) and MISC (10%) are more modest, but still significant. Although our results are below the best reported results for EN and DE (Lin and Wu, 2009; Faruqui and Pad´o, 2010), the relative improvements of adding word clusters are inline with previous results on NER for EN (Miller et al., 2004; Turian et al., 2010), who report error reductions of approximately 25% from adding word cluster features. Slightly higher reductions where achieved for DE by Faruqui and Pad´o (2010), who report a reduction of 22%. Note that we did not tune hyper-parameters of the supervised learning methods and of the clustering method, such as the number of clusters (Turian et al., 2010; Faruqui and Pad´o, 2010), and that we did not apply any heuristic for data cl</context>
</contexts>
<marker>Lin, Wu, 2009</marker>
<rawString>Dekang Lin and Xiaoyun Wu. 2009. Phrase clustering for discriminative learning. In Proceedings of ACLIJCNLP, pages 1030–1038.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of English: the Penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="34810" citStr="Marcus et al., 1993" startWordPosition="5585" endWordPosition="5588">chev for discussions on cross-lingual clustering; and the anonymous reviewers, along with Joakim Nivre, for valuable comments that helped improve the paper. The first author is grateful for the financial support of the Swedish National Graduate School of Language Technology (GSLT). A Data Sets In the parsing experiments, we use the following data sets. For DA, DE, EL, ES, IT, NL, PT and SV, we use the predefined training and evaluation data sets from the CoNLL 2006/2007 data sets (Buchholz and Marsi, 2006; Nivre et al., 2007). For EN we use sections 02-21, 22, and 23 of the Penn WSJ Treebank (Marcus et al., 1993) for training, development and evaluation. For FR we used the French Treebank (Abeill´e and Barrier, 2004) with splits defined in Candito et al. (2010). For KO we use the Sejong Korean Treebank (Han et al., 2002) randomly splitting the data into 80% training, 10% development and 10% evaluation. For RU we use the SynTagRus Treebank (Boguslavsky et al., 2000; Apresjan et al., 2006) randomly splitting the data into 80% training, 10% development and 10% evaluation. For ZH we use the Penn Chinese Treebank v6 (Xue et al., 2005) using the proposed data splits from the documentation. Both EN and ZH we</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of English: the Penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="3670" citStr="McDonald et al., 2011" startWordPosition="558" endWordPosition="561">beled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they are often inherently language independent. This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011). However, the performance for most languages is still well below that of supervised systems and recent work has established that the performance is also below simple methods of linguistic transfer (McDonald et al., 2011). In this study we focus on semi-supervised and linguistic-transfer methods for multilingual structure prediction. In particular, we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics 1. Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguisti</context>
<context position="5297" citStr="McDonald et al. (2011)" startWordPosition="808" endWordPosition="811"> first study with such a broad view on this subject, in terms of language diversity. 2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages. We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages. This is achieved by means of a probabilistic model over large amounts of monolingual data in two languages, coupled with parallel data through which cross-lingual word-cluster constraints are enforced. We show that by augmenting the delexicalized direct transfer system of McDonald et al. (2011) with cross-lingual cluster features, we are able to reduce its error by up to 13% relative. Further, we show that by applying the same method to direct-transfer NER, we achieve a relative error reduction of 26%. In line with much previous work on word clusters for tasks such as dependency parsing and NER, for which local syntactic and semantic constraints are of importance, we induce word clusters by means of a probabilistic class-based language model (Brown et al., 1992; Clark, 2003). However, rather than the more commonly used model of Brown et al. (1992), we use the predictive class bigram</context>
<context position="17143" citStr="McDonald et al., 2011" startWordPosition="2737" endWordPosition="2740"> structure without using any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010). The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005). Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering model. Top-right: Samples of some of the induced cross-lingual word clusters. Bottom-left: Delexicalized cluster-augmented source (EN) treebank for training transfer parser. Bottom-right: Parsing of target (ES) sentence using the transfer parser. 4.1 Direct Transfer of Discriminative Models Our starting point is the delexicalized direct transfer method proposed by McDonald et al. (2011) based on work by Zeman and Resnik (2008). This method was shown to outperform a n</context>
<context position="18810" citStr="McDonald et al. (2011)" startWordPosition="2975" endWordPosition="2978">tions. There are three basic assumptions that drive this approach. First, that high-level tasks, such as syntactic parsing, can be learned reliably using coarse-grained statistics, such as part-of-speech tags, in place of fine-grained statistics such as lexical word identities. Second, that the parameters of features over coarsegrained statistics are in some sense language independent, e.g., a feature that indicates that adjectives modify their closest noun is useful in all languages. Third, that these coarse-grained statistics are robustly available across languages. The approach proposed by McDonald et al. (2011) relies on these three assumptions. Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features. A cross-lingual word clustering is a clustering of words in two languages, in which the clusters correspond to some meaningful cross-lingual property. For example, pre</context>
<context position="25427" citStr="McDonald et al. (2011)" startWordPosition="4069" endWordPosition="4073">on performance and set N = 1 for all subsequent experiments. 5 Cross-lingual Experiments In our first set of experiments on using cross-lingual cluster features, we evaluate direct transfer of our EN parser, trained on Stanford style dependencies (De Marneffe et al., 2006), to the the ten non-EN Indo-European languages listed in Section 3. We exclude KO and ZH as initial experiments proved direct transfer a poor technique when transferring parsers between such diverse languages. We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al. (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters. In both cases the feature models are the same as those used in Section 3.1, except that they are delexicalized by removing all lexical word-identity features. We evaluate both the PROJECTED CLUSTERS and the X-LINGUAL CLUSTERS. For these experiments we train the perceptron for only five epochs in order to prevent over-fitting, which is an acute problem due to the divergence between the t</context>
<context position="26893" citStr="McDonald et al., 2011" startWordPosition="4309" endWordPosition="4312"> second set of experiments, we evaluate direct transfer of a NER system trained on EN to DE, ES and NL. We use the same feature models as in the monolingual case, with the exception that we use universal part-of-speech tags for all languages and we remove the capitalization feature when transferring from EN to DE. Capitalization is both a prevalent and highly predictive feature of named-entities in EN, while in DE, capitalization is even more prevalent, but has very low predictive power. Interestingly, while delexicalization has shown to be important for direct transfer of dependency-parsers (McDonald et al., 2011), we noticed in preliminary experiments that it substantially degrades performance for NER. We hypothesize that this is because word features are predictive of common proper names and that these are often translated directly across languages, at least in the case of newswire text. As for the transfer parser, when training the source NER model, we regularize the model more heavily by setting Q = 0.1. Appendix A contains the details of the training, testing, unlabeled and parallel/aligned data sets. 5.1 Results Table 5 lists the results of the transfer experiments for dependency parsing. The bas</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Jethran Guinness</author>
<author>Alex Zamanian</author>
</authors>
<title>Name tagging with word clusters and discriminative training.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL.</booktitle>
<contexts>
<context position="4418" citStr="Miller et al., 2004" startWordPosition="666" endWordPosition="669"> we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics 1. Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguistic structure. Previous studies on this approach have typically focused only on a small set of languages and tasks (Freitag, 2004; Miller et al., 2004; Koo et al., 2008; Turian et al., 2010; Faruqui and Pad´o, 2010; Haffari et al., 2011; Tratz and Hovy, 2011). Here we show that this method is robust across 13 languages for dependency parsing and 4 languages for named-entity recognition (NER). This is the first study with such a broad view on this subject, in terms of language diversity. 2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages. We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages. This is achieved</context>
<context position="7390" citStr="Miller et al., 2004" startWordPosition="1152" endWordPosition="1155">s m L(w; C) = P(wi|C(wi))P(C(wi)|wi−1) . (1) i=1 Compare this to the model of Brown et al. (1992): By incorporating cross-lingual cluster features in a m linguistic transfer system, we are for the first time L&apos;(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) . combining SSL and cross-lingual transfer. i=1 2 Monolingual Word Cluster Features Word cluster features have been shown to be useful in various tasks in natural language processing, including syntactic dependency parsing (Koo et al., 2008; Haffari et al., 2011; Tratz and Hovy, 2011), syntactic chunking (Turian et al., 2010), and NER (Freitag, 2004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010). Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Uszkoreit and Brants, 20</context>
<context position="15636" citStr="Miller et al., 2004" startWordPosition="2491" endWordPosition="2494">own per language, reductions on the test set vary from substantial for NL (30%) and EN (26%), down to more modest for DE (17%) and ES (12%). The addition of cluster features most markedly improve recognition of the PER category, with an average error reduction on the test set of 44%, while the reductions for ORG (19%), LOC (17%) and MISC (10%) are more modest, but still significant. Although our results are below the best reported results for EN and DE (Lin and Wu, 2009; Faruqui and Pad´o, 2010), the relative improvements of adding word clusters are inline with previous results on NER for EN (Miller et al., 2004; Turian et al., 2010), who report error reductions of approximately 25% from adding word cluster features. Slightly higher reductions where achieved for DE by Faruqui and Pad´o (2010), who report a reduction of 22%. Note that we did not tune hyper-parameters of the supervised learning methods and of the clustering method, such as the number of clusters (Turian et al., 2010; Faruqui and Pad´o, 2010), and that we did not apply any heuristic for data cleaning such as that used by Turian et al. (2010). 4 Cross-lingual Word Cluster Features All results of the previous section rely on the availabil</context>
</contexts>
<marker>Miller, Guinness, Zamanian, 2004</marker>
<rawString>Scott Miller, Jethran Guinness, and Alex Zamanian. 2004. Name tagging with word clusters and discriminative training. In Proceedings of HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andriy Mnih</author>
<author>Geoffrey Hinton</author>
</authors>
<title>Three new graphical models for statistical language modelling.</title>
<date>2007</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="8299" citStr="Mnih and Hinton (2007)" startWordPosition="1292" endWordPosition="1296">l as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Uszkoreit and Brants, 2008). In addition to the clustering model that we make use of in this study, a number of additional word clustering and embedding variants have been proposed. For example, Turian et al. (2010) assessed the effectiveness of the word embedding techniques of Collobert and Weston (2008) and Mnih and Hinton (2007) along with the word clustering technique of Brown et al. (1992) for syntactic chunking and NER. Recently, Dhillon et al. (2011) proposed a word 478 Single words S0c{p}, N0c{p}, N1c{p}, N2c{p} Word pairs S0c{p}N0c{p}, S0pcN0p, S0pN0pc, S0wN0c, S0cN0w, N0cN1c, N1cN2c Word triples N0cN1cN2c, S0cN0cN1c, S0hcS0cN0c, S0cS0lcN0c, S0cS0rcN0c, S0cN0cN0lc Distance S0cd, N0cd, S0cN0cd Valency S0cvl, S0cvr, N0cS0vl Unigrams S0hc, S0lc, S0rc, N0lc Third-order S0h2c, S0l2c, S0r2c, N0l2c Label set S0cS0ll, S0cS0rl, N0cN0ll, N0cN0rl Table 1: Additional cluster-based parser features. Si and Ni: the ith tokens</context>
</contexts>
<marker>Mnih, Hinton, 2007</marker>
<rawString>Andriy Mnih and Geoffrey Hinton. 2007. Three new graphical models for statistical language modelling. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Harr Chen</author>
<author>Regina Barzilay</author>
<author>Mark Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="3423" citStr="Naseem et al., 2010" startWordPosition="519" endWordPosition="522"> large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they are often inherently language independent. This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011). However, the performance for most languages is still well below that of supervised systems and recent work has established that the performance is also below simple methods of linguistic transfer (McDonald et al., 2011). In this study we focus on semi-supervised and linguistic-transfer methods for multilingual structure prediction. In particular, we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: </context>
<context position="16674" citStr="Naseem et al., 2010" startWordPosition="2660" endWordPosition="2663">d not apply any heuristic for data cleaning such as that used by Turian et al. (2010). 4 Cross-lingual Word Cluster Features All results of the previous section rely on the availability of large quantities of language specific annotations for each task. Cross-lingual transfer methods and unsupervised methods have recently been shown to hold promise as a way to at least partially sidestep the demand for labeled data. Unsupervised methods attempt to infer linguistic structure without using any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010). The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005). Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering mo</context>
<context position="27697" citStr="Naseem et al., 2010" startWordPosition="4435" endWordPosition="4438">that these are often translated directly across languages, at least in the case of newswire text. As for the transfer parser, when training the source NER model, we regularize the model more heavily by setting Q = 0.1. Appendix A contains the details of the training, testing, unlabeled and parallel/aligned data sets. 5.1 Results Table 5 lists the results of the transfer experiments for dependency parsing. The baseline results are comparable to those in McDonald et al. (2011) and thus also significantly outperform the results of recent unsupervised approaches (Berg-Kirkpatrick and Klein, 2010; Naseem et al., 2010). Importantly, crosslingual cluster features are helpful across the board and give a relative error reduction ranging from 3% for DA to 13% for PT, with an average reduction of 6%, in terms of unlabeled attachment score (UAS). This shows the utility of cross-lingual cluster features for syntactic transfer. However, X-LINGUAL CLUSTERS provides roughly the same performance as PROJECTED CLUSTERS suggesting that even simple methods of cross-lingual clustering are sufficient for direct transfer dependency parsing. We would like to stress that these results are likely to be under-estimating the pars</context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="11661" citStr="Nivre, 2008" startWordPosition="1814" endWordPosition="1815"> Cap: First letter is capitalized. -/f - Transition from previous to current label conjoined with feature f. w:j: j-character prefix of w. w−j:: j-character suffix of w. fi: Feature f at relative position i. fi,j: Union of features at positions i and j. fi:j: Conjoined feature sequence between relative positions i and j (inclusive). b: Bias. languages in which our unlabeled data did not have at least 1 million types, we considered all types. 3.1 Cluster Augmented Feature Models All of the parsing experiments reported in this study are based on the transition-based dependency parsing paradigm (Nivre, 2008). For all languages and settings, we use an arc-eager decoding strategy, with a beam of eight hypotheses, and perform ten epochs of the averaged structured perceptron algorithm (Zhang and Clark, 2008). We extend the state-of-the-art feature model recently introduced by Zhang and Nivre (2011) by adding an additional word cluster based feature template for each word based template. Additionally, we add templates where one or more partof-speech feature is replaced with the corresponding cluster feature. The resulting set of additional feature templates are shown in Table 1. The expanded feature m</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>An efficient method for determining bilingual word classes.</title>
<date>1999</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="22679" citStr="Och (1999)" startWordPosition="3612" endWordPosition="3613"> target language, and to make use of more unlabeled data, we model word sequences in each language by the monolingual language model with likelihood function defined by equation (1). Denote these likelihood functions respectively by LS(wS; CS) and LT (wT; CT), where we have overloaded notation so that the word sequences denoted by wS and wT include much more plentiful non-aligned data when taken as an argument of the monolingual likelihood functions. Second, we couple the clusterings defined by these individual models, by introducing additional factors based on word alignments, as proposed by Och (1999): LT|S(wT;AT|S,CT,CS) = Y p(wTj |CT (wTj ))p(CT (wTj )|CS(wSaj)) . jEAT|S and the symmetric LS|T(wS; AS|T, CS, CT). Note that the simple projection defined by equation (2) correspond to a hard assignment variant of this probabilistic formulation when the source clustering is fixed. Combining all four factors results in the joint monolingual and cross-lingual objective function LS,T(wS, wT; AT|S,AS|T, CS, CT) = LS(...) · LT (...) · LT|S(...) · LS|T (...) . (3) The intuition of this approach is that the clusterings CS and CT are forced to jointly explain the source and target data, treating the </context>
</contexts>
<marker>Och, 1999</marker>
<rawString>Franz Josef Och. 1999. An efficient method for determining bilingual word classes. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<publisher>Now Publishers Inc.</publisher>
<contexts>
<context position="1509" citStr="Pang and Lee, 2008" startWordPosition="215" endWordPosition="218"> that by augmenting direct-transfer systems with cross-lingual cluster features, the relative error of delexicalized dependency parsers, trained on English treebanks and transferred to foreign languages, can be reduced by up to 13%. When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%. 1 Introduction The ability to predict the linguistic structure of sentences or documents is central to the field of natural language processing (NLP). Structures such as named-entity tag sequences (Bikel et al., 1999) or sentiment relations (Pang and Lee, 2008) are inherently useful in data mining, information retrieval and other user-facing technologies. More fundamental structures such as part-of-speech tag sequences (Ratnaparkhi, 1996) or syntactic parse trees (Collins, 1997; K¨ubler et al., 2009), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate the literature on linguistic structure predict</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Now Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2011</date>
<booktitle>In ArXiv:1104.2086.</booktitle>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A universal part-of-speech tagset. In ArXiv:1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="1690" citStr="Ratnaparkhi, 1996" startWordPosition="240" endWordPosition="242">to foreign languages, can be reduced by up to 13%. When applying the same method to direct transfer of named-entity recognizers, we observe relative improvements of up to 26%. 1 Introduction The ability to predict the linguistic structure of sentences or documents is central to the field of natural language processing (NLP). Structures such as named-entity tag sequences (Bikel et al., 1999) or sentiment relations (Pang and Lee, 2008) are inherently useful in data mining, information retrieval and other user-facing technologies. More fundamental structures such as part-of-speech tag sequences (Ratnaparkhi, 1996) or syntactic parse trees (Collins, 1997; K¨ubler et al., 2009), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate the literature on linguistic structure prediction (Smith, 2011). Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources.</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
</authors>
<title>Linguistic Structure Prediction.</title>
<date>2011</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="2126" citStr="Smith, 2011" startWordPosition="309" endWordPosition="310">inherently useful in data mining, information retrieval and other user-facing technologies. More fundamental structures such as part-of-speech tag sequences (Ratnaparkhi, 1996) or syntactic parse trees (Collins, 1997; K¨ubler et al., 2009), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate the literature on linguistic structure prediction (Smith, 2011). Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources. Notable exceptions include the CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011). While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to l</context>
</contexts>
<marker>Smith, 2011</marker>
<rawString>Noah A. Smith. 2011. Linguistic Structure Prediction. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
</authors>
<title>Data point selection for crosslanguage adaptation of dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="17159" citStr="Søgaard, 2011" startWordPosition="2741" endWordPosition="2742">g any annotated data (Klein and Manning, 2004) or possibly by using a set of linguistically motivated rules (Naseem et al., 2010) or a linguistically informed model structure (Berg-Kirkpatrick and Klein, 2010). The aim of transfer methods is instead to use knowledge induced from labeled resources in one or more source languages to construct systems for target languages in which no or few such resources are available (Hwa et al., 2005). Currently, the performance of even the most simple direct transfer systems far exceeds that of unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering model. Top-right: Samples of some of the induced cross-lingual word clusters. Bottom-left: Delexicalized cluster-augmented source (EN) treebank for training transfer parser. Bottom-right: Parsing of target (ES) sentence using the transfer parser. 4.1 Direct Transfer of Discriminative Models Our starting point is the delexicalized direct transfer method proposed by McDonald et al. (2011) based on work by Zeman and Resnik (2008). This method was shown to outperform a number of state-o</context>
</contexts>
<marker>Søgaard, 2011</marker>
<rawString>Anders Søgaard. 2011. Data point selection for crosslanguage adaptation of dependency parsers. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin I Spitkovsky</author>
<author>Hiyan Alshawi</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Lateen EM: Unsupervised training with multiple objectives, applied to dependency grammar induction.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="3449" citStr="Spitkovsky et al., 2011" startWordPosition="523" endWordPosition="526">ch on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction of linguistic structure. These methods all attempt to benefit from the plethora of unlabeled monolingual and/or cross-lingual data that has become available in the digital age. Unsupervised methods are appealing in that they are often inherently language independent. This is borne out by the many recent studies on unsupervised parsing that include evaluations covering a number of languages (Cohen and Smith, 2009; Gillenwater et al., 2010; Naseem et al., 2010; Spitkovsky et al., 2011). However, the performance for most languages is still well below that of supervised systems and recent work has established that the performance is also below simple methods of linguistic transfer (McDonald et al., 2011). In this study we focus on semi-supervised and linguistic-transfer methods for multilingual structure prediction. In particular, we pursue two lines of research around the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologie</context>
</contexts>
<marker>Spitkovsky, Alshawi, Jurafsky, 2011</marker>
<rawString>Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Jurafsky. 2011. Lateen EM: Unsupervised training with multiple objectives, applied to dependency grammar induction. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Erik</author>
</authors>
<title>Tjong Kim Sang and Fien De Meulder.</title>
<date>2003</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<marker>Erik, 2003</marker>
<rawString>Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the conll-2003 shared task: Languageindependent named entity recognition. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
</authors>
<title>Introduction to the conll2002 shared task: Language-independent named entity recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of CoNLL.</booktitle>
<contexts>
<context position="2362" citStr="Sang, 2002" startWordPosition="347" endWordPosition="348">), on the other hand, comprise the core linguistic analysis for many important downstream tasks such as machine translation (Chiang, * The majority of this work was performed while the author was an intern at Google, New York, NY. 2005; Collins et al., 2005). Currently, supervised data-driven methods dominate the literature on linguistic structure prediction (Smith, 2011). Regrettably, the majority of studies on these methods have focused on evaluations specific to English, since it is the language with the most annotated resources. Notable exceptions include the CoNLL shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003; Buchholz and Marsi, 2006; Nivre et al., 2007) and subsequent studies on this data, as well as a number of focused studies on one or two specific languages, as discussed by Bender (2011). While annotated resources for parsing and several other tasks are available in a number of languages, we cannot expect to have access to labeled resources for all tasks in all languages. This fact has given rise to a large body of research on unsupervised (Klein and Manning, 2004), semi-supervised (Koo et al., 2008) and transfer (Hwa et al., 2005) systems for prediction o</context>
<context position="35972" citStr="Sang, 2002" startWordPosition="5786" endWordPosition="5787">splits from the documentation. Both EN and ZH were converted to dependencies using v1.6.8 of the Stanford Converter (De Marneffe et al., 2006). FR was converted using the procedure defined in Candito et al. (2010). RU and KO are native dependency treebanks. For the CoNLL data sets we use the part-of-speech tags provided with the data. For all other data sets, we train a part-of-speech tagger on the training data in order to tag the development and evaluation data. For the NER experiments we use the training, development and evaluation data sets from the CoNLL 2002/2003 shared tasks (Tjong Kim Sang, 2002; Tjong Kim Sang and De Meulder, 2003) for all four languages (DE, EN, ES and NL). The data set for each language consists of newswire text annotated with four entity categories: Location (LOC), Miscellaneous (MISC), Organization (ORG) and Person (PER). We use the part-of-speech tags supplied with the data, except for ES where we instead use universal part-of-speech tags (Petrov et al., 2011). Unlabeled data for training the monolingual cluster models was extracted from one year of newswire articles from multiple sources from a news aggregation website. This consists of 0.8 billion (DA) to 121</context>
</contexts>
<marker>Sang, 2002</marker>
<rawString>Erik F. Tjong Kim Sang. 2002. Introduction to the conll2002 shared task: Language-independent named entity recognition. In Proceedings of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Tratz</author>
<author>Eduard Hovy</author>
</authors>
<title>A fast, effective, non-projective, semantically-enriched parser.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="4527" citStr="Tratz and Hovy, 2011" startWordPosition="687" endWordPosition="690">ture prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics 1. Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguistic structure. Previous studies on this approach have typically focused only on a small set of languages and tasks (Freitag, 2004; Miller et al., 2004; Koo et al., 2008; Turian et al., 2010; Faruqui and Pad´o, 2010; Haffari et al., 2011; Tratz and Hovy, 2011). Here we show that this method is robust across 13 languages for dependency parsing and 4 languages for named-entity recognition (NER). This is the first study with such a broad view on this subject, in terms of language diversity. 2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages. We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages. This is achieved by means of a probabilistic model over large amounts of monolingual data in two languages, coupled with para</context>
<context position="7303" citStr="Tratz and Hovy, 2011" startWordPosition="1138" endWordPosition="1141"> = (wi)mi=1, with wi E V U {S}, where S is a designated start-ofsegment symbol, factors as m L(w; C) = P(wi|C(wi))P(C(wi)|wi−1) . (1) i=1 Compare this to the model of Brown et al. (1992): By incorporating cross-lingual cluster features in a m linguistic transfer system, we are for the first time L&apos;(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) . combining SSL and cross-lingual transfer. i=1 2 Monolingual Word Cluster Features Word cluster features have been shown to be useful in various tasks in natural language processing, including syntactic dependency parsing (Koo et al., 2008; Haffari et al., 2011; Tratz and Hovy, 2011), syntactic chunking (Turian et al., 2010), and NER (Freitag, 2004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010). Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get</context>
</contexts>
<marker>Tratz, Hovy, 2011</marker>
<rawString>Stephen Tratz and Eduard Hovy. 2011. A fast, effective, non-projective, semantically-enriched parser. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev-Arie Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="4457" citStr="Turian et al., 2010" startWordPosition="674" endWordPosition="677"> the use of word cluster features in discriminative models for structure prediction: 477 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 477–487, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics 1. Monolingual word cluster features induced from large corpora of text for semi-supervised learning (SSL) of linguistic structure. Previous studies on this approach have typically focused only on a small set of languages and tasks (Freitag, 2004; Miller et al., 2004; Koo et al., 2008; Turian et al., 2010; Faruqui and Pad´o, 2010; Haffari et al., 2011; Tratz and Hovy, 2011). Here we show that this method is robust across 13 languages for dependency parsing and 4 languages for named-entity recognition (NER). This is the first study with such a broad view on this subject, in terms of language diversity. 2. Cross-lingual word cluster features for transferring linguistic structure from English to other languages. We develop an algorithm that generates cross-lingual word clusters; that is clusters of words that are consistent across languages. This is achieved by means of a probabilistic model over</context>
<context position="7345" citStr="Turian et al., 2010" startWordPosition="1144" endWordPosition="1147">a designated start-ofsegment symbol, factors as m L(w; C) = P(wi|C(wi))P(C(wi)|wi−1) . (1) i=1 Compare this to the model of Brown et al. (1992): By incorporating cross-lingual cluster features in a m linguistic transfer system, we are for the first time L&apos;(w; C) = P(wi|C(wi))P(C(wi)|C(wi−1)) . combining SSL and cross-lingual transfer. i=1 2 Monolingual Word Cluster Features Word cluster features have been shown to be useful in various tasks in natural language processing, including syntactic dependency parsing (Koo et al., 2008; Haffari et al., 2011; Tratz and Hovy, 2011), syntactic chunking (Turian et al., 2010), and NER (Freitag, 2004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010). Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordt</context>
<context position="12803" citStr="Turian et al. (2010)" startWordPosition="2001" endWordPosition="2004">t of additional feature templates are shown in Table 1. The expanded feature model includes all of the feature templates defined by Zhang and Nivre (2011), which we also use as the baseline model, whereas Table 1 only shows our new templates due to space limitations. For all NER experiments, we use a sequential firstorder conditional random field (CRF) with a unit variance Normal prior, trained with L-BFGS until c-convergence (c = 0.0001, typically obtained after less than 400 iterations). The feature model used for the NER tagger is shown in Table 2. These are similar to the features used by Turian et al. (2010), with the main difference that we do not use any long range features and that we add templates that conjoin adjacent clusters and adjacent tags as well as templates that conjoin label transitions with tags, clusters and capitalization features. 479 DA DE EL EN ES FR IT KO NL PT RU SV ZH AVG NO CLUSTERS 84.3 88.9 76.1 90.3 82.8 85.7 81.4 82.0 77.2 86.9 83.5 84.7 74.9 83.0 CLUSTERS 85.8 89.5 77.3 90.7 83.6 85.7 82.2 83.6 77.8 87.6 86.0 86.5 75.5 84.0 Table 3: Supervised parsing results measured with labeled attachment score (LAS) on the test set. All results are statistically significant at p &lt;</context>
<context position="15658" citStr="Turian et al., 2010" startWordPosition="2495" endWordPosition="2498">uctions on the test set vary from substantial for NL (30%) and EN (26%), down to more modest for DE (17%) and ES (12%). The addition of cluster features most markedly improve recognition of the PER category, with an average error reduction on the test set of 44%, while the reductions for ORG (19%), LOC (17%) and MISC (10%) are more modest, but still significant. Although our results are below the best reported results for EN and DE (Lin and Wu, 2009; Faruqui and Pad´o, 2010), the relative improvements of adding word clusters are inline with previous results on NER for EN (Miller et al., 2004; Turian et al., 2010), who report error reductions of approximately 25% from adding word cluster features. Slightly higher reductions where achieved for DE by Faruqui and Pad´o (2010), who report a reduction of 22%. Note that we did not tune hyper-parameters of the supervised learning methods and of the clustering method, such as the number of clusters (Turian et al., 2010; Faruqui and Pad´o, 2010), and that we did not apply any heuristic for data cleaning such as that used by Turian et al. (2010). 4 Cross-lingual Word Cluster Features All results of the previous section rely on the availability of large quantitie</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Uszkoreit</author>
<author>Thorsten Brants</author>
</authors>
<title>Distributed word clustering for large scale class-based language modeling in machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="5945" citStr="Uszkoreit and Brants (2008)" startWordPosition="917" endWordPosition="920">luster features, we are able to reduce its error by up to 13% relative. Further, we show that by applying the same method to direct-transfer NER, we achieve a relative error reduction of 26%. In line with much previous work on word clusters for tasks such as dependency parsing and NER, for which local syntactic and semantic constraints are of importance, we induce word clusters by means of a probabilistic class-based language model (Brown et al., 1992; Clark, 2003). However, rather than the more commonly used model of Brown et al. (1992), we use the predictive class bigram model introduced by Uszkoreit and Brants (2008). The two models are very similar, but whereas the former takes classto-class transitions into account, the latter directly models word-to-class transitions. By ignoring classto-class transitions, an approximate maximum likelihood clustering can be found efficiently with the distributed exchange algorithm (Uszkoreit and Brants, 2008). This is a useful property, as we later develop an algorithm for inducing cross-lingual word clusters that calls this monolingual algorithm as a subroutine. More formally, let C : V H 1, ... , K be a (hard) clustering function that maps each word type from the voc</context>
<context position="7993" citStr="Uszkoreit and Brants, 2008" startWordPosition="1241" endWordPosition="1244">004; Miller et al., 2004; Turian et al., 2010; Faruqui and Pad´o, 2010). Intuitively, the reason for the effectiveness of cluster features lie in their ability to aggregate local distributional information from large unlabeled corpora, which aid in conquering data sparsity in supervised training regimes as well as in mitigating cross-domain generalization issues. While the use of class-to-class transitions can lead to more compact models, which is often useful for conquering data sparsity, when clustering large data sets we can get reliable statistics directly on the wordto-class transitions (Uszkoreit and Brants, 2008). In addition to the clustering model that we make use of in this study, a number of additional word clustering and embedding variants have been proposed. For example, Turian et al. (2010) assessed the effectiveness of the word embedding techniques of Collobert and Weston (2008) and Mnih and Hinton (2007) along with the word clustering technique of Brown et al. (1992) for syntactic chunking and NER. Recently, Dhillon et al. (2011) proposed a word 478 Single words S0c{p}, N0c{p}, N1c{p}, N2c{p} Word pairs S0c{p}N0c{p}, S0pcN0p, S0pN0pc, S0wN0c, S0cN0w, N0cN1c, N1cN2c Word triples N0cN1cN2c, S0c</context>
</contexts>
<marker>Uszkoreit, Brants, 2008</marker>
<rawString>Jakob Uszkoreit and Thorsten Brants. 2008. Distributed word clustering for large scale class-based language modeling in machine translation. In Proceedings of ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naiwen Xue</author>
<author>Fei Xia</author>
<author>Fu-dong Chiou</author>
<author>Marta Palmer</author>
</authors>
<title>The penn chinese treebank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>02</issue>
<contexts>
<context position="35337" citStr="Xue et al., 2005" startWordPosition="5676" endWordPosition="5679">). For EN we use sections 02-21, 22, and 23 of the Penn WSJ Treebank (Marcus et al., 1993) for training, development and evaluation. For FR we used the French Treebank (Abeill´e and Barrier, 2004) with splits defined in Candito et al. (2010). For KO we use the Sejong Korean Treebank (Han et al., 2002) randomly splitting the data into 80% training, 10% development and 10% evaluation. For RU we use the SynTagRus Treebank (Boguslavsky et al., 2000; Apresjan et al., 2006) randomly splitting the data into 80% training, 10% development and 10% evaluation. For ZH we use the Penn Chinese Treebank v6 (Xue et al., 2005) using the proposed data splits from the documentation. Both EN and ZH were converted to dependencies using v1.6.8 of the Stanford Converter (De Marneffe et al., 2006). FR was converted using the procedure defined in Candito et al. (2010). RU and KO are native dependency treebanks. For the CoNLL data sets we use the part-of-speech tags provided with the data. For all other data sets, we train a part-of-speech tagger on the training data in order to tag the development and evaluation data. For the NER experiments we use the training, development and evaluation data sets from the CoNLL 2002/2003</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Naiwen Xue, Fei Xia, Fu-dong Chiou, and Marta Palmer. 2005. The penn chinese treebank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(02):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>Cross-language parser adaptation between related languages.</title>
<date>2008</date>
<booktitle>In IJCNLP Workshop: NLP for Less Privileged Languages.</booktitle>
<contexts>
<context position="17702" citStr="Zeman and Resnik (2008)" startWordPosition="2813" endWordPosition="2816"> unsupervised systems (Cohen et al., 2011; McDonald et al., 2011; Søgaard, 2011). 480 Figure 1: Cross-lingual word cluster features for parsing. Top-left: Cross-lingual (EN-ES) word clustering model. Top-right: Samples of some of the induced cross-lingual word clusters. Bottom-left: Delexicalized cluster-augmented source (EN) treebank for training transfer parser. Bottom-right: Parsing of target (ES) sentence using the transfer parser. 4.1 Direct Transfer of Discriminative Models Our starting point is the delexicalized direct transfer method proposed by McDonald et al. (2011) based on work by Zeman and Resnik (2008). This method was shown to outperform a number of state-of-the-art unsupervised and transfer-based baselines. The method is simple; for a given training set, the learner ignores all lexical identities and only observes features over other characteristics, e.g., part-of-speech tags, orthographic features, direction of syntactic attachment, etc. The learner builds a model from an annotated source language data set, after which the model is used to directly make target language predictions. There are three basic assumptions that drive this approach. First, that high-level tasks, such as syntactic</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. Cross-language parser adaptation between related languages. In IJCNLP Workshop: NLP for Less Privileged Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="11861" citStr="Zhang and Clark, 2008" startWordPosition="1844" endWordPosition="1847">ative position i. fi,j: Union of features at positions i and j. fi:j: Conjoined feature sequence between relative positions i and j (inclusive). b: Bias. languages in which our unlabeled data did not have at least 1 million types, we considered all types. 3.1 Cluster Augmented Feature Models All of the parsing experiments reported in this study are based on the transition-based dependency parsing paradigm (Nivre, 2008). For all languages and settings, we use an arc-eager decoding strategy, with a beam of eight hypotheses, and perform ten epochs of the averaged structured perceptron algorithm (Zhang and Clark, 2008). We extend the state-of-the-art feature model recently introduced by Zhang and Nivre (2011) by adding an additional word cluster based feature template for each word based template. Additionally, we add templates where one or more partof-speech feature is replaced with the corresponding cluster feature. The resulting set of additional feature templates are shown in Table 1. The expanded feature model includes all of the feature templates defined by Zhang and Nivre (2011), which we also use as the baseline model, whereas Table 1 only shows our new templates due to space limitations. For all NE</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT.</booktitle>
<contexts>
<context position="11953" citStr="Zhang and Nivre (2011)" startWordPosition="1858" endWordPosition="1861">ence between relative positions i and j (inclusive). b: Bias. languages in which our unlabeled data did not have at least 1 million types, we considered all types. 3.1 Cluster Augmented Feature Models All of the parsing experiments reported in this study are based on the transition-based dependency parsing paradigm (Nivre, 2008). For all languages and settings, we use an arc-eager decoding strategy, with a beam of eight hypotheses, and perform ten epochs of the averaged structured perceptron algorithm (Zhang and Clark, 2008). We extend the state-of-the-art feature model recently introduced by Zhang and Nivre (2011) by adding an additional word cluster based feature template for each word based template. Additionally, we add templates where one or more partof-speech feature is replaced with the corresponding cluster feature. The resulting set of additional feature templates are shown in Table 1. The expanded feature model includes all of the feature templates defined by Zhang and Nivre (2011), which we also use as the baseline model, whereas Table 1 only shows our new templates due to space limitations. For all NER experiments, we use a sequential firstorder conditional random field (CRF) with a unit var</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceedings of ACL-HLT.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>