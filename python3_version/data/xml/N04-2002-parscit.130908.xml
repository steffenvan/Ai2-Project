<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9822125">
Identifying Chemical Names in Biomedical Text:
An Investigation of the Substring Co-occurrence Based Approaches
</title>
<author confidence="0.997126">
Alexander Vasserman
</author>
<affiliation confidence="0.997897333333333">
Department of Computer and
Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.797479">
Philadelphia, PA 19104
</address>
<email confidence="0.998553">
avasserm@seas.upenn.edu
</email>
<sectionHeader confidence="0.996658" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999940615384616">
We investigate various strategies for finding
chemicals in biomedical text using substring
co-occurrence information. The goal is to
build a system from readily available data
with minimal human involvement. Our
models are trained from a dictionary of
chemical names and general biomedical text.
We investigated several strategies including
Naïve Bayes classifiers and several types of
N-gram models. We introduced a new way of
interpolating N-grams that does not require
tuning any parameters. We also found the
task to be similar to Language Identification.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999952011764706">
Chemical names recognition is one of the first tasks
needed for building an information extraction system in
the biomedical domain. Chemicals, especially organic
chemicals, are one of the main agents in many processes
and relationships such a system would need to find. In
this work, we investigate a number of approaches to the
problem of chemical names identification. We focus on
approaches that use string internal information for
classification, those based on the character co-
occurrence statistics within the strings that we would
like to classify. We would also like not to spend much
time and effort to do manual annotation, and hence use
readily publicly available data for training all the
models. Because of that, we would be satisfied with
only moderate results. In the course of this
investigation, we have found that N-gram methods work
best given these restrictions on the models.
Work has been done on a related task of named
entity recognition (Bikel et al., 1999, Riloff, 1996,
Cucerzan, 1999, and others). The aim of the named
entity task is usually set to find names of people,
organizations, and some other similar entities in text.
Adding features based on the internal substring patterns
has been found useful by Cucerzan et al., 1999. For
finding chemicals, internal substring patterns are even
more important source of information. Many substrings
of chemical names are very characteristic. For example,
seeing &amp;quot;methyl&amp;quot; as a substring of a word is a strong
indicator of a chemical name. The systematic chemical
names are constructed from substrings like that, but
even the generic names follow certain conventions, and
have many characteristic substrings.
In this work, character co-occurrence patterns are
extracted from available lists of chemicals that have
been compiled for other purposes. We built models
based on the difference between strings occurring in
chemical names and strings that occur in other words.
The use of only string internal information prevents us
from disambiguating different word senses, but we
accept this source of errors as a minor one.
Classification based solely on string internal
information makes the chemical names recognition task
similar to language identification. In the language
identification task, these patterns are used to detect
strings from a different language embedded into text.
Because chemicals are so different, we can view them
as a different language, and borrow some of the
Language Identification techniques. Danning, 1994 was
able to achieve good results using character N-gram
models on language identification even on short strings
(20 symbols long). This suggests that his approach
might be successful in chemical names identification
setting.
N-gram based methods were previously used for
chemicals recognition. Wilbur et al., 1999 used all
substrings of a fixed length N, but they combined the
training counts in a Bayesian framework, ignoring non-
independence of overlapping substring. They claimed
good performance for their data, but this approach
showed significantly lower performance than
alternatives on our data. See the results section for
more details. The difference is that their data is
carefully constructed to contain only chemicals and
chemicals of all types in the test data, i.e. their training
and testing data is in a very close correspondence.
We on the other hand tried to use readily available
chemical lists without putting much manual labor into
their construction. Most of our training data comes
from a single source - National Cancer Institute website
- and hence represents only a very specific domain of
chemicals, while testing data is coming from a random
sample from MEDLINE. In addition, these lists were
designed for use by human, and hence contain many
comments and descriptions that are not easily separable
for the chemical names themselves. Several attempts on
cleaning these out have been made. Most aggressive
attempts deleted about half the text from the list. While
deleting many useful names, this improved the results
significantly.
While we found that N-grams worked best amoung
the approaches we have tried, other approaches are also
possible. We did not explore the possibility of using
substring as features to a generic classification
algorithm, such as, for example, support vector
machines (Burges, 1998).
</bodyText>
<sectionHeader confidence="0.898574" genericHeader="introduction">
2 Available Data
</sectionHeader>
<bodyText confidence="0.999975068181818">
In order to train a statistical model for recognizing
chemicals a list of about 240 thousands entries have
been download from National Cancer Institute website
(freely available at dtp.nci.nih.gov). Entries are unique
names of about 45 thousands unique chemicals. Each
entry includes a name of a chemical possibly followed
by alternative references and some comments. This
additional information had to be deleted in order to
compute statistics from chemical names only. While
there were no clean separators between chemical names
and the additional materials, several patterns were
designed to clean up the list. Applying those patterns
shrunk each entry on average by half. This cleaning
step has not produced perfect results in both leaving
some unusable material in and deleting some useful
strings, yet it improved the performance of all methods
dramatically. Cleaning the list by hand might have
produced better results, but it would require more
expertise and take a lot of time and would contradict the
goal of building the system from readily available data.
We used text from MEDLINE abstracts to model
general biomedical language. These were available as a
part of the MEDLINE database of bibliographical
records for papers in biomedical domain. Records that
had non-empty abstracts have been extracted. From
those &apos;title&apos; and &apos;abstract&apos; fields were taken and cleaned
off from remaining XML tags.
Both the list of chemical names (LCN) and the text
corpus obtained from the MED LINE database (MED)
were tokenized by splitting on the white spaces. White
space tokenization was used over other possible
approaches, as the problem of tokenization is very hard
for chemical names, because they contain a lot of
internal punctuation. We also wanted to avoid splitting
chemical names into tokens that are too small, as they
would contain very little internal information to work
with. The counts of occurrences of tokens in LCN and
MD were used in all experiments to build models of
chemical names and general biomedical text.
In addition, 15 abstracts containing chemical names
were selected from the parts of MEDLINE corpus not
used for the creation of the above list. These abstracts
have been annotated by hand and used as development
and test sets.
</bodyText>
<sectionHeader confidence="0.9973495" genericHeader="method">
3 Classification Using Substring
Importance Criteria
</sectionHeader>
<subsectionHeader confidence="0.999901">
3.1 Classification Approach
</subsectionHeader>
<bodyText confidence="0.99762672972973">
Most obvious approach to this problem is to try to
match the chemicals in the list against the text and label
only the matches, i.e. chemicals that are known from the
list. This approach is similar to the memory-based
baseline described by Palmer et al., 1997, where instead
of using precompiled list they memorized all the entries
that occurred in a training text.
A natural extension of matching is a decision list.
Each classification rule in the list checks if a substring is
present in a token. Matching can be viewed as just an
extreme of this approach, where the strings selected into
the decision list are the complete tokens from the LCN
(including token boundary information). Using other
substrings increases recall, as non-exact matches are
detected, and it also improves precision, as it decreases
the number of error coming from noise in LCN.
While decision list performs better than matching, its
performance is still unsatisfactory. Selecting only
highly indicative substrings results in high precision, but
very low recall. Lowering the thresholds and taking
more substrings decreases the precision without
improving the recall much until the precision gets very
low.
The decision list approach makes each decision
based on a single substring. This forces us to select
only substrings that are extreemly rare outside the
chemical names. This in turn results in extremely low
recall. An alternative would be to combine the
information from multiple substrings into a single
decision using Naive Bayes framework. This would
keep precision from dropping as dramatically when we
increase the number of strings used in classification.
We would like to estimate the probability of a token
being a part of a chemical name given the token (string)
p(c|s) . Representing each string as a set of its substrings
we need to estimate p(c|s1...sn). Using Bayes Rule, we
get
</bodyText>
<equation confidence="0.993271333333333">
p(si|c)log(p(si|c) / p(si )) &gt; t (6)
where t is some threshold value. Notice that this
p(c|s1...sn) = p(s1...sn |c)p(c)/p(s1...sn) (1)
</equation>
<bodyText confidence="0.962206666666667">
Assuming independence of substrings s1...sn and
conditional independence of substrings s1...sn given c,
we can rewrite:
</bodyText>
<equation confidence="0.992056833333333">
n n
∏ p(s  |c)/ p(s
∏
i
i 1
= i
</equation>
<bodyText confidence="0.9999315">
Now notice that for most applications we would like
to be able to vary precision/recall tradeoff by setting
some threshold t and classifying each string s as a
chemical only if
</bodyText>
<equation confidence="0.874151777777778">
n n
p c s p(c) p(s  |c)/ p(s ) t
(  |) = ∏ ∏ &gt; (3)
i i
i 1
= i 1
=
or
or
</equation>
<bodyText confidence="0.997866071428571">
is equal to zero. In this case, this
selection criterion cannot be computed, yet some of the
most valuable strings could have
equal to zero.
Therefore, we need to smooth probabilities of the
strings to avoid zero values. One possibility is to
include all strings
such that
and
where
is some new threshold needed to avoid
selecting very rare strings. It would be nice though not
to introduce an additional parameter. An alternative
would be to reassign probabilities to all substrings an
</bodyText>
<equation confidence="0.895079571428571">
p(si|c)
p(si)
p(si)
si,
p(si)=0
p(si|c)&gt;t&apos;,
t&apos;&lt;t
</equation>
<bodyText confidence="0.99256575">
d
keep the selection criterion the same. It could be done,
for example, using Good-Turing smoothing (Good
1953).
</bodyText>
<equation confidence="0.692677818181818">
p(c|s ...s
1 n
) p(c)p(s ...s |c)/p(s ...s )
= 1 n 1 n
p(c)
i ) (2)
1
n n
∏ p(si |c)11p(si) &gt; t / p(c) = t&apos;(4)
i 1 i 1
=
</equation>
<bodyText confidence="0.99984575">
This allows us to avoid estimation of p(c)
(estimating p(c) is hard without any labeled text). We
can estimate p(si|c) and p(si) from the LCN and MED
respectively as
</bodyText>
<equation confidence="0.575737">
p(si) =#(tokens containg si)/# (tokens) (5)
</equation>
<bodyText confidence="0.9821957">
substring
of s to use to represent s. We would like
to select
of non-overlapping substrings to make the
independence assumption more grounded (while it is
clear that even non-overlapping substrings are not
independent, assuming independence of overlapping
substrings clearly causes major problems). In order to
do this we need some measure of usefulness of
substrings. We would like to select substrings that are
both informative and reliable as features, i.e. the
substrings fraction of which in LCN is different from
the fraction of them in MED an
{si}
a set
d which occur often
enough in LCN. Once this measure is defined, we can
use dynamic programming algorithm similar to Viterbi
decoding to select the set of non-overlapping substrings
with maximum value.
is significantly different from f(c). We test the
significan
f(c|s)
ce by assuming that f(c) is a good estimate for
the prior probability of a token being a chemical p(c),
and trying to reject the null hypothesis, that actual
probability of chemicals among tokens that contain s is
also p(c). If the number of tokens containing s is n(s)
and the number of chemicals containing s is c(s), then
the selection criterion becomes
</bodyText>
<equation confidence="0.982977">
c(s) − n(s) f (c)
n s f c f
( ) ( )( 1−
</equation>
<bodyText confidence="0.999810571428571">
This formula is obtained by viewing occurrences of s
as Bernoulli trials with probability p(c) of the
occurrence being a chemical and probability (1-p(c)) of
the occurrence being non-chemical. Distribution
obtained by n(s) such trials can be approximated with
the normal distribution with mean n(s)p(c) and variance
n(s)p(c)(1-p(c)).
</bodyText>
<sectionHeader confidence="0.995787" genericHeader="method">
4 Classification Using N-gram Models
</sectionHeader>
<subsectionHeader confidence="0.99998">
3.2 Substring Selection
</subsectionHeader>
<bodyText confidence="0.982539">
For this approach, we need to decide what set of
</bodyText>
<subsectionHeader confidence="0.657463">
Kullback-Leibler divergence based measure
</subsectionHeader>
<bodyText confidence="0.9718255">
If we view the substring frequencies as a distribution,
we can ask the question which substrings account for
the biggest contribution to
divergence
(Cover et al, 1991) between distribution given by LCN
and that given by MED. From this view it is reasonable
to take
Kullback-Leibler
p(si|c)*log(p(si|c)/p(si)) as a measure of value of
a substring. Therefore, the selection criterion would be
measure combines frequency of a substring in chemicals
and the difference between frequencies of occurrences
of the substring in chemicals and non-chemicals.
A problem with this approach arises when either
</bodyText>
<subsectionHeader confidence="0.93685">
Selection by significance testing
</subsectionHeader>
<bodyText confidence="0.9729264">
A different way of viewing this is to say that we want to
select all the substrings in which we are confident. It
can be observed that tokens might contain certain
substrings that are strong indicators of them being
chemicals. Useful substrings are the ones that predict
significantly different from the prior probability of
being a chemical. I.e. if the frequency of chemicals
among all tokens is f(c), then s is a useful substring if
the frequency of chemicals among tokens containing s
We can estimate probability of a string given class
(chemical or non-chemical) as the probability of letters
of the string based on a
history
finite
.
</bodyText>
<equation confidence="0.995966">
( ))
c
&gt;1. 65 =z .9 5 (7)
</equation>
<bodyText confidence="0.999910666666667">
where S is the string to be classified and si are the
letters of S.
The N-gram approach has been a successful
modeling technique in many other applications. It has a
number of advantages over the Bayesian approach. In
this framework we can use information from all
substrings of a token, and not only sets of non-
overlapping ones. There is no (incorrect) independence
assumption, so we get a more sound probability model.
As a practical issue, there has been a lot of work done
on smoothing techniques for N-gram models (Chen et
al., 1998), so it is easier to use them.
</bodyText>
<subsectionHeader confidence="0.518845">
4.1 Investigating Usefulness of Different N-gram
Lengths
</subsectionHeader>
<bodyText confidence="0.9999518">
As the first task in investigating N-gram models, we
investigated usefulness of N-grams of different length.
For each n, we constructed a model based on the
substrings of this length only using Laplacian
smoothing to avoid zero probability.
</bodyText>
<equation confidence="0.998975333333333">
p(si  |si−1..S0, 0
(9)
p(si  |si−1..S0
</equation>
<bodyText confidence="0.999991533333333">
where N is the length of the N-grams, nii-N+1 and ncii-N+1
are the number of occurrences of N-gram sisi-1...si-N-1 in
MEDLINE and chemical list respectively, d is the
smoothing parameter, and B is the number of different
N-grams of length N.
The smoothing parameter was tuned for each n
individually using the development data (hand
annotated MEDLINE abstracts). The results of these
experiments showed that 3-grams and 4-grams are most
useful. While poor performance by longer N-grams was
somewhat surprising, results indicated that overtraining
might be an issue for longer N-grams, as the model they
produce models the training data more precisely. While
unexpected, the result is similar to the conclusion in
Dunning &apos;94 for language identification task.
</bodyText>
<subsectionHeader confidence="0.799755">
4.2 Interpolated N-gram Models
</subsectionHeader>
<bodyText confidence="0.9999125">
In many different tasks that use N-gram models,
interpolated or back-off models have been proven
useful. The idea here is to use shorter N-grams for
smoothing longer ones.
</bodyText>
<equation confidence="0.916661">
(10)
</equation>
<bodyText confidence="0.999873894736842">
where lj&apos;s are the interpolation coefficients, m and mc
are the total number of letters in MEDLINE and
chemical list respectively. lj can generally depend on
si-1...si-N+1, with the only constraint that all l j
coefficients sum up to one. One of the main question
for interpolated models is learning the values for l&apos;s.
Estimating N different l&apos;s for each context si-1...si-N+1 is
a hard learning task by itself that requires a lot of
development data. There are two fundamentally
different ways for dealing with this problem. Often
grouping different coefficients together and providing
single value for each group, or imposing some other
constraints on the coefficients is used to decrease the
number of parameters. The other approach is providing
a theory for values of l&apos;s without tuning them on the
development data (This is similar in spirit to Minimal
Description Length approach). We have investigated
several different possibilities in both of these two
approaches.
</bodyText>
<equation confidence="0.977664333333333">
(11)
+ lN
lN
</equation>
<bodyText confidence="0.99996525">
This form states more explicitly that each N-gram
model is smoothed by all lower models. An extreme of
the grouping approach is then to make all lj&apos;s equal,
and tune this single parameter on the development data.
</bodyText>
<subsectionHeader confidence="0.6664065">
4.4 Computing Interpolation Coefficients:
Context Independent Coefficients
</subsectionHeader>
<bodyText confidence="0.999384">
Relaxing this constraint and going back to the original
form of equation (10), we can make all lj&apos;s independent
of their context, so we get only N parameters to tune.
When N is small, this can be done even with relatively
</bodyText>
<equation confidence="0.959236585714285">
−
1
n
i
i
1
+
n
4.3 Computing Interpolation Coefficients: Fixed
Coefficients
Equation (10) can be rewritten in a slightly different
form:
(si  |si
1 ... s0)≈(1 − lN−1
p
i
n
i
−
1
+
)
N
i
1
i
d
+
−
≈
nc
N+
i −1
nci−N+1 +dB
+
d
−
≈
ni−1
−N +1 +dB
i
)
n
i
N+
1
)
p(si  |si−1 ... s0
n
i
i
−
N+
1
i
+li−N+2 + +
...
N−1 i−1
n.
−
n
a
N
≈
lN
i
−
1
n
N+
i
−
1
l1
2
+
ni
i
m
i
n
i
−
+
2
1
−
+
N
i
lN
−
)
(
2
i
n
−
+
2
N
1
−
⎛ n i i
n ⎞ ⎞
i − 1 i
⎜ . . . (1 )
⎛ −
⎜ l + l ⎟ ⎟
2 1 −⎝ ⎝ni 1 1 m
i − 1 ⎠ ⎠
i
i
−
2
+
N
nc
i
−
i
−
1
nc
i
i
nc
mc
p
p
c)
(c)
(S
p
(c|S) = AS
∏
i
∏
i
(si  |si−1 ... s0, c)
</equation>
<figure confidence="0.573435478260869">
p
.s0
)
p
)
(c
1
. .
−
p(si|si
1
)
(|
si si
s c
0 ,
. . .
(8)
i
)
1
−
1
+ lN
lN
i
−
+
−
1
nc
N
p
≈
i
nc
−
i
1
+
N
2
+
N
+ +
... l 1
</figure>
<bodyText confidence="0.999825307692308">
small development set. We can do this by exploring all
possible settings of these parameters in an N
dimensional grid with small increment. For larger N we
have to introduce an additional constraint that l j&apos;s
should lie on some function of j with a smaller number
of parameters. We have used a quadratic function (2
parameters, as one of them is fixed by the constraint that
all lj&apos;s have to sum up to 1). Using higher order of the
function gives more flexibility, but introduces more
parameters, which would require more development
data to tune well. The quadratic function seems to be a
good trade off that provides enough flexibility, but does
not introduce too many parameters.
</bodyText>
<sectionHeader confidence="0.547798" genericHeader="method">
4.5 Computing Interpolation Coefficients:
Confidence Based Coefficients
</sectionHeader>
<bodyText confidence="0.999996470588235">
The intuition for using interpolated models is that higher
level N-grams give more information when they are
reliable, but lower level N-grams are usually more
reliable, as they normally occur more frequently. We
can formalize this intuition by computing the
confidence of higher level N-grams and weight them
proportionally. We are trying to estimate p(si|si-1...si-
N+1) with the ratio nii-N+1/ni-1i-N+1. We can say that our
observation in the training data was generated by ni-1i-
N+1 Bernoulli trials with outcomes either si or any other
letter. We consider si to be a positive outcome and any
other letter would be a negative outcome. Given this
model we have nii-N+1 positive outcomes in ni-1 i-N+1
Bernoulli trials with probability of positive outcome
p(si|si-1...si-N+1). This means that the estimate given by
nii-N+1/ni-1 i-N+1 has the confidence interval of binomial
distribution approximated by normal given by
</bodyText>
<equation confidence="0.942500666666667">
3 2
z c z
2 4
+
a a
I = 2c (c + za 2 ) (12)
</equation>
<bodyText confidence="0.998284333333333">
where c = ni-1i-N+1.
Since the true probability is within I of the estimate,
the lower level models should not change the estimate
given by the highest-level model by more than I. This
means that lN-1 in the equation (11) should be equal to
I. By recursing the argument we get
</bodyText>
<equation confidence="0.985604714285714">
3 2 2 4
c j za +c j za
l = =
I (13)
j j 2 (
c c z
+ 2 )
</equation>
<bodyText confidence="0.867432">
j j a
where cj = ni-1i-j+2 for j &gt; 1, and c1 = m.
</bodyText>
<sectionHeader confidence="0.994077" genericHeader="evaluation">
5 Evaluation and Results
</sectionHeader>
<bodyText confidence="0.999447076923077">
We performed cross validation experiments on 15 hand-
annotated MEDLINE abstracts described in section
&amp;quot;Available Data&amp;quot;. Experiments were done by holding
out each abstract, tuning model parameters on 14
remaining abstracts, and testing on the held out one.
Fifteen such experiments were performed. The results
of these experiments were combined by taking weighed
geometric mean of precision results at each recall level.
The results were weighted according to the number of
positive examples in each file to ensure equal
contribution from each example. Figure 1 shows the
resulting precision/recall curves.
As we can see, the N-gram approaches perform
better than the other ones. The interpolated model with
quadratic coefficients needs a lot of development data,
so it does not produce good results in our case. Simple
Laplacian smoothing needs less development data and
produces much better results. The model with
confidence based coefficients works best. The graph
also shows the model introduced by Wilbur et al., 1999.
It does not perform nearly as well on our data, even
though it produces very good results on clean data they
have used. This (as well as some experiments we
performed that have not been included into this work)
suggests that quality of the training data has very strong
effect on the model results.
</bodyText>
<sectionHeader confidence="0.997944" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999616125">
We have investigated a number of different approaches
to chemical identification using string internal
information. We used readily available training data,
and a small amount of human annotated text that was
used primarily for testing. We were able to achieve
good performance on general biomedical text taken
from MEDLINE abstracts. N-gram models showed the
best performance. The specific details of parameter
</bodyText>
<sectionHeader confidence="0.349077" genericHeader="acknowledgments">
Recall
</sectionHeader>
<figureCaption confidence="0.894249">
Fig. 1. Precision/Recall curves for Naïve
Bayes and N-gram based models
</figureCaption>
<page confidence="0.997978">
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
0.45
0.50
0.55
0.60
0.65
0.70
0.75
0.80
0.85
0.90
0.95
1.00
</page>
<figure confidence="0.990221647058823">
Precision
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Naive Bayes
Wilbur et al
Laplacian Smoothing
Quadratic Coefficients
Confidence-Based Coefficients
c
</figure>
<bodyText confidence="0.999958025641026">
tuning for these models produced small variations in the
results. We have also introduced a method for
computing interpolated N-gram model parameters
without any tuning on development data. The results
produced by this method were slightly better than those
of other approaches. We believe this approach
performed better because only one parameter - the
length of N-grams - needed to be tuned on the
development data. This is a big advantage when little
development data is available. In general, we
discovered many similarities with previous work on
language identification, which suggests that other
techniques introduced for language identification may
carry over well into chemicals identification.
As a short term goal we would like to determine N-
gram interpolation coeficients by usefulness of the
corresponding context for discrimination. This would
incorporate the same techinque as we used for Naive
Bayes system, hopefully combining the advantage of
both approaches
There are other alternatives for learning a
classification rule. Recently using support vector
machines (Burges 1998) have been a popular approach.
More traditionally decision trees (Breiman et al, 1984)
have been used for simmilar tasks. It would be
interesting to try these aproaches for our task and
compare them with Naive Bayes and N-gram
approaches discussed here.
One limitation of the current system is that it does
not find the boundaries of chemicals, but only classifies
predetermind tokens as being part of a chemical name
or not. The system can be improved by removing prior
tokenization requirment, and attempting to identify
chemical name boundaries based on the learned
information.
In this work we explored just one dimention of
possible features usefull for finding chemical names.
We intent to incorporate other types of features
including context based features with this work.
</bodyText>
<sectionHeader confidence="0.998387" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999680538461538">
T. Dunning. 1994. &amp;quot;Statistical identification of
language&amp;quot;. Technical Report MCCS 94-273, New
Mexico State University.
S. F. Chen and J. Goodman. 1998. “An Empirical
Study of Smoothing Techniques for Language
Modeling,” TR-10-98, Computer Science Group,
Harvard Univ., 1998.
W. John Wilbur, George F. Hazard, Jr., Guy Divita,
James G. Mork, Alan R. Aronson, Allen C. Browne.
1999. &amp;quot;Analysis of Biomedical Text for Chemical
Names: A Comparison of Three Methods&amp;quot;.
Proceedings of AMIA Symposium 1999:181-5.
Daniel M. Bikel, Richard Schwartz and Ralph M.
Weischedel. 1999. &amp;quot;An Algorithm that Learns
What&apos;s in a Name&amp;quot;, Machine Learning
Ellen Riloff. 1996. &amp;quot;Automatically Generating
Extraction Patterns from Untagged Text&amp;quot;,
Proceedings of the Thirteenth National Conference
on Artificial Intelligence (AAAI-96), pp. 1044-1049
Silviu Cucerzan, David Yarowsky. 1999. &amp;quot;Language
Independent Named Entity Recognition Combining
Morphological and Contextual Evidence&amp;quot;.
Proceedings of 1999 Joint SIGDAT conference on
EMNLP and VLC, University of Maryland, MD.
D. D. Palmer, D. S. Day. 1997. &amp;quot;A Statistical Profile of
Named Entity Task&amp;quot;. Proceedings of Fifth ACL
Conference for Applied Natural Language Processing
(ANLP-97), Washington D.C.
I. Good. 1953. &amp;quot;The population frequencies of species
and the estimation of population parameters&amp;quot;.
Biometrika, v. 40, pp. 237-264
C.J.C. Burges, 1998. &amp;quot;A Tutorial on Support Vector
Machines for Pattern Recognition,&amp;quot; Data Mining and
Knowledge Discovery, 2(2), pp. 955-974
T. Cover and J. Thomas, 1991. “Elements of
Information Theory”, Wiley, New York.
L. Breiman, J.H. Friedman, R.A. Olshen, and C.J.
Stone, 1984. &amp;quot;Classification and Regression Trees,&amp;quot;
Chapman &amp; Hall, New York.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.704378">
<title confidence="0.999826">Identifying Chemical Names in Biomedical Text: An Investigation of the Substring Co-occurrence Based Approaches</title>
<author confidence="0.997484">Alexander</author>
<affiliation confidence="0.998698">Department of Computer Information University of</affiliation>
<address confidence="0.798919">Philadelphia, PA</address>
<email confidence="0.999125">avasserm@seas.upenn.edu</email>
<abstract confidence="0.991628285714286">We investigate various strategies for finding chemicals in biomedical text using substring co-occurrence information. The goal is to build a system from readily available data with minimal human involvement. Our models are trained from a dictionary of chemical names and general biomedical text. We investigated several strategies including Naïve Bayes classifiers and several types of N-gram models. We introduced a new way of interpolating N-grams that does not require tuning any parameters. We also found the task to be similar to Language Identification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Statistical identification of language&amp;quot;.</title>
<date>1994</date>
<tech>Technical Report MCCS 94-273,</tech>
<institution>New Mexico State University.</institution>
<marker>Dunning, 1994</marker>
<rawString>T. Dunning. 1994. &amp;quot;Statistical identification of language&amp;quot;. Technical Report MCCS 94-273, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Chen</author>
<author>J Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Techniques for Language Modeling,”</title>
<date>1998</date>
<tech>TR-10-98,</tech>
<institution>Computer Science Group, Harvard Univ.,</institution>
<marker>Chen, Goodman, 1998</marker>
<rawString>S. F. Chen and J. Goodman. 1998. “An Empirical Study of Smoothing Techniques for Language Modeling,” TR-10-98, Computer Science Group, Harvard Univ., 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W John Wilbur</author>
<author>George F Hazard</author>
<author>Guy Divita</author>
<author>James G Mork</author>
<author>Alan R Aronson</author>
<author>Allen C Browne</author>
</authors>
<title>Analysis of Biomedical Text for Chemical Names: A Comparison of Three Methods&amp;quot;.</title>
<date>1999</date>
<booktitle>Proceedings of AMIA Symposium</booktitle>
<pages>1999--181</pages>
<contexts>
<context position="3657" citStr="Wilbur et al., 1999" startWordPosition="549" endWordPosition="552">r to language identification. In the language identification task, these patterns are used to detect strings from a different language embedded into text. Because chemicals are so different, we can view them as a different language, and borrow some of the Language Identification techniques. Danning, 1994 was able to achieve good results using character N-gram models on language identification even on short strings (20 symbols long). This suggests that his approach might be successful in chemical names identification setting. N-gram based methods were previously used for chemicals recognition. Wilbur et al., 1999 used all substrings of a fixed length N, but they combined the training counts in a Bayesian framework, ignoring nonindependence of overlapping substring. They claimed good performance for their data, but this approach showed significantly lower performance than alternatives on our data. See the results section for more details. The difference is that their data is carefully constructed to contain only chemicals and chemicals of all types in the test data, i.e. their training and testing data is in a very close correspondence. We on the other hand tried to use readily available chemical lists</context>
<context position="21174" citStr="Wilbur et al., 1999" startWordPosition="3591" endWordPosition="3594">ch recall level. The results were weighted according to the number of positive examples in each file to ensure equal contribution from each example. Figure 1 shows the resulting precision/recall curves. As we can see, the N-gram approaches perform better than the other ones. The interpolated model with quadratic coefficients needs a lot of development data, so it does not produce good results in our case. Simple Laplacian smoothing needs less development data and produces much better results. The model with confidence based coefficients works best. The graph also shows the model introduced by Wilbur et al., 1999. It does not perform nearly as well on our data, even though it produces very good results on clean data they have used. This (as well as some experiments we performed that have not been included into this work) suggests that quality of the training data has very strong effect on the model results. 6 Conclusions and Future Work We have investigated a number of different approaches to chemical identification using string internal information. We used readily available training data, and a small amount of human annotated text that was used primarily for testing. We were able to achieve good per</context>
</contexts>
<marker>Wilbur, Hazard, Divita, Mork, Aronson, Browne, 1999</marker>
<rawString>W. John Wilbur, George F. Hazard, Jr., Guy Divita, James G. Mork, Alan R. Aronson, Allen C. Browne. 1999. &amp;quot;Analysis of Biomedical Text for Chemical Names: A Comparison of Three Methods&amp;quot;. Proceedings of AMIA Symposium 1999:181-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
<author>Richard Schwartz</author>
<author>Ralph M Weischedel</author>
</authors>
<title>An Algorithm that Learns What&apos;s in a Name&amp;quot;,</title>
<date>1999</date>
<journal>Machine Learning</journal>
<contexts>
<context position="1817" citStr="Bikel et al., 1999" startWordPosition="271" endWordPosition="274">ication. We focus on approaches that use string internal information for classification, those based on the character cooccurrence statistics within the strings that we would like to classify. We would also like not to spend much time and effort to do manual annotation, and hence use readily publicly available data for training all the models. Because of that, we would be satisfied with only moderate results. In the course of this investigation, we have found that N-gram methods work best given these restrictions on the models. Work has been done on a related task of named entity recognition (Bikel et al., 1999, Riloff, 1996, Cucerzan, 1999, and others). The aim of the named entity task is usually set to find names of people, organizations, and some other similar entities in text. Adding features based on the internal substring patterns has been found useful by Cucerzan et al., 1999. For finding chemicals, internal substring patterns are even more important source of information. Many substrings of chemical names are very characteristic. For example, seeing &amp;quot;methyl&amp;quot; as a substring of a word is a strong indicator of a chemical name. The systematic chemical names are constructed from substrings like t</context>
</contexts>
<marker>Bikel, Schwartz, Weischedel, 1999</marker>
<rawString>Daniel M. Bikel, Richard Schwartz and Ralph M. Weischedel. 1999. &amp;quot;An Algorithm that Learns What&apos;s in a Name&amp;quot;, Machine Learning</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically Generating Extraction Patterns from Untagged Text&amp;quot;,</title>
<date>1996</date>
<booktitle>Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96),</booktitle>
<pages>1044--1049</pages>
<contexts>
<context position="1831" citStr="Riloff, 1996" startWordPosition="275" endWordPosition="276"> approaches that use string internal information for classification, those based on the character cooccurrence statistics within the strings that we would like to classify. We would also like not to spend much time and effort to do manual annotation, and hence use readily publicly available data for training all the models. Because of that, we would be satisfied with only moderate results. In the course of this investigation, we have found that N-gram methods work best given these restrictions on the models. Work has been done on a related task of named entity recognition (Bikel et al., 1999, Riloff, 1996, Cucerzan, 1999, and others). The aim of the named entity task is usually set to find names of people, organizations, and some other similar entities in text. Adding features based on the internal substring patterns has been found useful by Cucerzan et al., 1999. For finding chemicals, internal substring patterns are even more important source of information. Many substrings of chemical names are very characteristic. For example, seeing &amp;quot;methyl&amp;quot; as a substring of a word is a strong indicator of a chemical name. The systematic chemical names are constructed from substrings like that, but even </context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. &amp;quot;Automatically Generating Extraction Patterns from Untagged Text&amp;quot;, Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), pp. 1044-1049</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
<author>David Yarowsky</author>
</authors>
<title>Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence&amp;quot;.</title>
<date>1999</date>
<booktitle>Proceedings of 1999 Joint SIGDAT conference on EMNLP and VLC,</booktitle>
<institution>University of Maryland, MD.</institution>
<marker>Cucerzan, Yarowsky, 1999</marker>
<rawString>Silviu Cucerzan, David Yarowsky. 1999. &amp;quot;Language Independent Named Entity Recognition Combining Morphological and Contextual Evidence&amp;quot;. Proceedings of 1999 Joint SIGDAT conference on EMNLP and VLC, University of Maryland, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Palmer</author>
<author>D S Day</author>
</authors>
<title>A Statistical Profile of Named Entity Task&amp;quot;.</title>
<date>1997</date>
<booktitle>Proceedings of Fifth ACL Conference for Applied Natural Language Processing (ANLP-97),</booktitle>
<location>Washington D.C.</location>
<marker>Palmer, Day, 1997</marker>
<rawString>D. D. Palmer, D. S. Day. 1997. &amp;quot;A Statistical Profile of Named Entity Task&amp;quot;. Proceedings of Fifth ACL Conference for Applied Natural Language Processing (ANLP-97), Washington D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Good</author>
</authors>
<title>The population frequencies of species and the estimation of population parameters&amp;quot;.</title>
<date>1953</date>
<journal>Biometrika,</journal>
<volume>40</volume>
<pages>237--264</pages>
<contexts>
<context position="10598" citStr="Good 1953" startWordPosition="1684" endWordPosition="1685">selection criterion cannot be computed, yet some of the most valuable strings could have equal to zero. Therefore, we need to smooth probabilities of the strings to avoid zero values. One possibility is to include all strings such that and where is some new threshold needed to avoid selecting very rare strings. It would be nice though not to introduce an additional parameter. An alternative would be to reassign probabilities to all substrings an p(si|c) p(si) p(si) si, p(si)=0 p(si|c)&gt;t&apos;, t&apos;&lt;t d keep the selection criterion the same. It could be done, for example, using Good-Turing smoothing (Good 1953). p(c|s ...s 1 n ) p(c)p(s ...s |c)/p(s ...s ) = 1 n 1 n p(c) i ) (2) 1 n n ∏ p(si |c)11p(si) &gt; t / p(c) = t&apos;(4) i 1 i 1 = This allows us to avoid estimation of p(c) (estimating p(c) is hard without any labeled text). We can estimate p(si|c) and p(si) from the LCN and MED respectively as p(si) =#(tokens containg si)/# (tokens) (5) substring of s to use to represent s. We would like to select of non-overlapping substrings to make the independence assumption more grounded (while it is clear that even non-overlapping substrings are not independent, assuming independence of overlapping substrings </context>
</contexts>
<marker>Good, 1953</marker>
<rawString>I. Good. 1953. &amp;quot;The population frequencies of species and the estimation of population parameters&amp;quot;. Biometrika, v. 40, pp. 237-264</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J C Burges</author>
</authors>
<title>A Tutorial on Support Vector Machines for Pattern Recognition,&amp;quot;</title>
<date>1998</date>
<journal>Data Mining and Knowledge Discovery,</journal>
<volume>2</volume>
<issue>2</issue>
<pages>955--974</pages>
<contexts>
<context position="5182" citStr="Burges, 1998" startWordPosition="792" endWordPosition="793">gned for use by human, and hence contain many comments and descriptions that are not easily separable for the chemical names themselves. Several attempts on cleaning these out have been made. Most aggressive attempts deleted about half the text from the list. While deleting many useful names, this improved the results significantly. While we found that N-grams worked best amoung the approaches we have tried, other approaches are also possible. We did not explore the possibility of using substring as features to a generic classification algorithm, such as, for example, support vector machines (Burges, 1998). 2 Available Data In order to train a statistical model for recognizing chemicals a list of about 240 thousands entries have been download from National Cancer Institute website (freely available at dtp.nci.nih.gov). Entries are unique names of about 45 thousands unique chemicals. Each entry includes a name of a chemical possibly followed by alternative references and some comments. This additional information had to be deleted in order to compute statistics from chemical names only. While there were no clean separators between chemical names and the additional materials, several patterns wer</context>
<context position="23337" citStr="Burges 1998" startWordPosition="3931" endWordPosition="3932">le. In general, we discovered many similarities with previous work on language identification, which suggests that other techniques introduced for language identification may carry over well into chemicals identification. As a short term goal we would like to determine Ngram interpolation coeficients by usefulness of the corresponding context for discrimination. This would incorporate the same techinque as we used for Naive Bayes system, hopefully combining the advantage of both approaches There are other alternatives for learning a classification rule. Recently using support vector machines (Burges 1998) have been a popular approach. More traditionally decision trees (Breiman et al, 1984) have been used for simmilar tasks. It would be interesting to try these aproaches for our task and compare them with Naive Bayes and N-gram approaches discussed here. One limitation of the current system is that it does not find the boundaries of chemicals, but only classifies predetermind tokens as being part of a chemical name or not. The system can be improved by removing prior tokenization requirment, and attempting to identify chemical name boundaries based on the learned information. In this work we ex</context>
</contexts>
<marker>Burges, 1998</marker>
<rawString>C.J.C. Burges, 1998. &amp;quot;A Tutorial on Support Vector Machines for Pattern Recognition,&amp;quot; Data Mining and Knowledge Discovery, 2(2), pp. 955-974</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cover</author>
<author>J Thomas</author>
</authors>
<title>Elements of Information Theory”,</title>
<date>1991</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<marker>Cover, Thomas, 1991</marker>
<rawString>T. Cover and J. Thomas, 1991. “Elements of Information Theory”, Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Breiman</author>
<author>J H Friedman</author>
<author>R A Olshen</author>
<author>C J Stone</author>
</authors>
<title>Classification and Regression Trees,&amp;quot;</title>
<date>1984</date>
<publisher>Chapman &amp; Hall,</publisher>
<location>New York.</location>
<contexts>
<context position="23423" citStr="Breiman et al, 1984" startWordPosition="3942" endWordPosition="3945"> identification, which suggests that other techniques introduced for language identification may carry over well into chemicals identification. As a short term goal we would like to determine Ngram interpolation coeficients by usefulness of the corresponding context for discrimination. This would incorporate the same techinque as we used for Naive Bayes system, hopefully combining the advantage of both approaches There are other alternatives for learning a classification rule. Recently using support vector machines (Burges 1998) have been a popular approach. More traditionally decision trees (Breiman et al, 1984) have been used for simmilar tasks. It would be interesting to try these aproaches for our task and compare them with Naive Bayes and N-gram approaches discussed here. One limitation of the current system is that it does not find the boundaries of chemicals, but only classifies predetermind tokens as being part of a chemical name or not. The system can be improved by removing prior tokenization requirment, and attempting to identify chemical name boundaries based on the learned information. In this work we explored just one dimention of possible features usefull for finding chemical names. We </context>
</contexts>
<marker>Breiman, Friedman, Olshen, Stone, 1984</marker>
<rawString>L. Breiman, J.H. Friedman, R.A. Olshen, and C.J. Stone, 1984. &amp;quot;Classification and Regression Trees,&amp;quot; Chapman &amp; Hall, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>