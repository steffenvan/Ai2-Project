<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000971">
<title confidence="0.970419">
Getting More from Morphology in Multilingual Dependency Parsing
</title>
<author confidence="0.996888">
Matt Hohensee and Emily M. Bender
</author>
<affiliation confidence="0.9955015">
University of Washington
Department of Linguistics
</affiliation>
<address confidence="0.9727265">
Box 354340
Seattle WA 98195-4340, USA
</address>
<email confidence="0.998839">
{hohensee, ebender}@uw.edu
</email>
<sectionHeader confidence="0.995631" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999696">
We propose a linguistically motivated set of
features to capture morphological agreement
and add them to the MSTParser dependency
parser. Compared to the built-in morphologi-
cal feature set, ours is both much smaller and
more accurate across a sample of 20 morpho-
logically annotated treebanks. We find in-
creases in accuracy of up to 5.3% absolute.
While some of this results from the feature set
capturing information unrelated to morphol-
ogy, there is still significant improvement, up
to 4.6% absolute, due to the agreement model.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972461538462">
Most data-driven dependency parsers are meant to
be language-independent. They do not use any
information that is specific to the language being
parsed, and they often rely heavily on n-grams, or
sequences of words and POS tags, to make parsing
decisions. However, designing a parser without in-
corporating any specific linguistic details does not
guarantee its language-independence; even linguis-
tically naive systems can involve design decisions
which in fact bias the system towards languages with
certain properties (Bender, 2011).
It is often taken for granted that using linguistic
information necessarily makes a system language-
dependent. But it is possible to design a linguisti-
cally intelligent parser without tuning it to a specific
language, by modeling at a high level phenomena
which appear cross-linguistically. Such a system is
still language-independent; it does not require any
knowledge or modeling of specific languages, but
it does use linguistic knowledge to make the most
of the available data. We present modifications to
an existing system, MSTParser (McDonald et al.,
2006), to incorporate a very simple model of mor-
phological agreement. These modifications improve
parsing performance across a variety of languages
by making better use of morphological annotations.
</bodyText>
<sectionHeader confidence="0.821919" genericHeader="introduction">
2 Background and related work
</sectionHeader>
<subsectionHeader confidence="0.99041">
2.1 Morphological marking of agreement
</subsectionHeader>
<bodyText confidence="0.999971521739131">
Most languages show some morphological agree-
ment via inflected noun, adjective, verb, and deter-
miner forms, although the degree to which this hap-
pens varies. At one end of the spectrum are analytic,
or “morphologically impoverished”, languages. An
extreme example is Chinese, which shows no inflec-
tion at all; words do not take different forms de-
pending on features such as person or gender. En-
glish has some inflection, but is relatively morpho-
logically poor.
At the other end are synthetic or “morphologi-
cally rich” languages such as Czech, which has, inter
alia, four genders and seven cases. In synthetic lan-
guages, words which are syntactically related in cer-
tain ways must agree: e.g., subject-verb agreement
for gender or determiner-noun agreement for case
(Corbett, 2006). Words participating in agreement
may be marked explicitly for the property in ques-
tion (via affixing or other morphological changes),
or may possess it inherently (with no specific affix
encoding the property). Treebanks are often anno-
tated to reflect some or all of these properties; the
level of detail depends on the annotation guidelines.
</bodyText>
<page confidence="0.990231">
315
</page>
<bodyText confidence="0.783336164835165">
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 315–326,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
zahraniˇcn´ı investice rostou MSTParser is a data-driven, graph-based parser
foreign investment grow which creates a model from training data by learn-
.F.PL.NOM .F.3RD.PL.NOM .3RD.PL.PRES ing weights for arc-level features. The feature set in-
cludes combinations of the word and POS tag of the
parent and child of each dependency arc; POS tags
of words between the parent and child; and POS tags
of the parent and child along with those of the pre-
ceding and following words. A similar feature set is
conjoined with arc labels in order to perform label-
ing, and an optional set of “second-order” features
includes analogous information about siblings.
Morphological features for an arc are generated
by iterating over each pair in the cross product of
the parent and child tokens’ lists of attributes. For
every such pair, thirteen groups of four features each
are generated. The thirteen groups represent combi-
nations of the head and child word forms/lemmas
and attributes. Each group contains subgroups dis-
tinguished by whether they use word forms or lem-
mas and by whether or not they encode the direc-
tion and distance of the dependency. These features
are summarized in Table 2. At run time, MSTParser
finds the highest-scoring parse for each sentence ac-
cording to the learned feature weights.
Decoding can be performed in projective or non-
projective mode, depending on the type of trees de-
sired. Projective trees are those in which every con-
stituent (head plus all dependents) forms a complete
subtree; non-projective parsing lacks this limitation.
2.3 Related work
The organizers of the CoNLL 2007 shared task
noted that languages with free word order and high
morphological complexity are the most difficult for
dependency parsing (Nivre et al., 2007). Most of the
participants took language-independent approaches
toward leveraging this complexity into better perfor-
mance: generating machine learning features based
on each item in a token’s list of morphological at-
tributes (Nivre et al., 2006b; Carreras et al., 2006);
using the entire list as an atomic feature (Chang et
al., 2006; Titov and Henderson, 2007); or generat-
ing features based on each pair of attributes in the
cross-product of the lists of a potential head and de-
pendent (McDonald et al., 2006; Nakagawa, 2007).
Language-specific uses of morphological infor-
mation have included using it to disambiguate func-
tion words (Bick, 2006) or to pick out finite verbs
foreign investments grow
foreign investment grow
.3RD.PL .PL
Table 1: Sentence in Czech (Hajiˇc, 1998) and English
A sample sentence in English and Czech (Table 1)
demonstrates this contrast. In Czech, the adjective
and noun agree for gender, number, and case, and
the noun and verb agree for person and number. In
the English version, only the noun and verb agree.
Agreement can be very useful for data-driven de-
pendency parsing. A statistical parser can learn from
training data that, for example, a third-person singu-
lar noun is a likely dependent of a verb marked as
third-person singular. Similarly, it can learn that a
determiner showing genitive case and a noun show-
ing dative case are often not syntactically related.
It is often assumed that morphological complex-
ity correlates with degree of variation in word order.
This is because synthetic languages use inflection to
mark the roles of constituents, while analytic lan-
guages generally assign these roles to specific phrase
structural locations. Siewierska (1998) investigated
this empirically and found that it holds to a certain
extent: the absence of agreement and/or case mark-
ing predicts rigid word order, though their presence
is not particularly predictive of flexible word order.
Many parsers rely on word order to establish de-
pendencies, so they often perform best on languages
with more rigid word order. Making use of mor-
phological agreement could compensate for greater
variation in word order and help to bring parsing per-
formance on flexible-word-order languages up to par
with that on rigid-word-order languages.
2.2 MSTParser
The CoNLL-X (Buchholz and Marsi, 2006) and
CoNLL 2007 (Nivre et al., 2007) shared tasks fo-
cused on multilingual dependency parsing. Each
system was trained on treebanks in a variety of lan-
guages and predicted dependency arcs and labels for
POS-tagged data. The best performers in 2006 were
MSTParser (McDonald et al., 2006), which we use
here, and MaltParser (Nivre et al., 2006a).
</bodyText>
<page confidence="0.419731">
316
</page>
<figure confidence="0.996630615384615">
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;dpAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;hdAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;hdAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;hdAtt&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;hdAtt&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;)
&lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;{dpForm|dpLemma}&gt;&lt;hdAtt&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;)
</figure>
<tableCaption confidence="0.995077666666667">
Table 2: Original MSTParser feature templates. hdForm and dpForm are the head and dependent word forms;
hdLemma and dpLemma are the lemmas. hdAtt and dpAtt are the morphological attributes; hdIdx and dpIdx
are their indices. dir+dist is a string encoding the direction and length of the arc. Each line represents one feature.
</tableCaption>
<figure confidence="0.506606">
&lt;attr&gt;_agrees,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
Unlabeled &lt;attr&gt;_disagrees,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
head_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
dep_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
&lt;attr&gt;_agrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
Labeled &lt;attr&gt;_disagrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
head_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
dep_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt;
</figure>
<tableCaption confidence="0.99147">
Table 3: Agreement feature templates. headPOS and depPOS are the head and dependent coarse POS tags.
</tableCaption>
<bodyText confidence="0.999432682926829">
(Carreras et al., 2006). Schiehlen and Spranger
(2007) used language-specific rules to add detail to
other features, such as fine-grained POS tags or lem-
mas. Attardi et al. (2007) modeled agreement ex-
plicitly, generating a morphological agreement fea-
ture whenever two tokens possess the same value
for the same linguistic attribute. The authors note
accuracy improvements of up to 0.5% for Italian
and 0.8% for Catalan using a transition-based parser.
A similar approach was used by Goldberg and El-
hadad (2010), who improved the accuracy of their
transition-based Hebrew parser by adding features
for gender and number agreement in noun phrases.
The potential of morphological information to im-
prove parsing performance has been documented in
numerous experiments using MaltParser and with
various morphological attributes as machine learn-
ing features, on several morphologically rich lan-
guages, including: Russian (Nivre et al., 2008);
Swedish (Øvrelid and Nivre, 2007); Bangla, Tel-
ugu, and Hindi (Nivre, 2009); Turkish (Eryiˇgit et
al., 2008); and Basque (Bengoetxea and Gojenola,
2010). These experiments, however, did not include
any higher-level features such as agreement.
Goldberg and Elhadad (2009) found that using
morphological features increased the accuracy of
MSTParser on Hebrew only when the morpholog-
ical annotations were gold-standard; automatic an-
notations decreased accuracy, although MaltParser
showed improvement with both gold and automatic
annotations. The accuracy of MaltParser on Arabic
was improved by different types of morphological
features depending on whether gold or automatic an-
notations were used (Marton et al., 2010).
As far as we can tell, no language-independent
approaches to utilizing morphological data thus far
have taken advantage of agreement specifically. We
take a linguistically informed approach, maintain-
ing language-independence, by explicitly modeling
agreement between head and dependent morphol-
ogy.
</bodyText>
<sectionHeader confidence="0.999763" genericHeader="method">
3 Methodology
</sectionHeader>
<subsectionHeader confidence="0.999954">
3.1 Modifications to parser
</subsectionHeader>
<bodyText confidence="0.999633666666667">
Our approach builds on the observation that there
are two kinds of information marked in morphol-
ogy: symmetric, recorded on both head and depen-
</bodyText>
<page confidence="0.998726">
317
</page>
<tableCaption confidence="0.999382">
Table 4: Sample sentence (Hajiˇc, 1998) and agreement features generated
</tableCaption>
<figure confidence="0.99201075">
ID TOKEN CPOS MORPH HEAD REL
Gloss
1 VznikajiVERB num=PL|per=3 0 ROOT
2 zbyteˇcn´e ADJ num=PL|gen=I|case=NOM 3 ATR
3 konflikty NOUN num=PL|gen=I|case=NOM 1 SBJ
arise.3RD.PL
unnecessary.PL.INAN.NOM
conflicts.PL.INAN.NOM
num_agrees,head=NOUN,dep=ADJ num_agrees,head=VERB,dep=NOUN
num_agrees&amp;label=ATR,head=NOUN,dep=ADJ num_agrees&amp;label=SBJ,head=VERB,dep=NOUN
gen_agrees,head=NOUN,dep=ADJ head_per=3,head=VERB,dep=NOUN
gen_agrees&amp;label=ATR,head=NOUN,dep=ADJ head_per=3&amp;label=SBJ,head=VERB,dep=NOUN
case_agrees,head=NOUN,dep=ADJ dep_gen=I,head=VERB,dep=NOUN
case_agrees&amp;label=ATR,head=NOUN,dep=ADJ dep_gen=I&amp;label=SBJ,head=VERB,dep=NOUN
dep_case=NOM,head=VERB,dep=NOUN
dep_case=NOM&amp;label=SBJ,head=VERB,dep=NOUN
</figure>
<bodyText confidence="0.999734032786886">
dent, and asymmetric, marked on only one or the
other. Symmetric information provides a natural,
effectively non-lossy type of back-off that parsers
can take advantage of; all that matters is whether
the information on the head and dependent match.1
Furthermore, we don’t need to know ahead of time
which types of morphological information are sym-
metric. This is extracted from the annotations.
In order to take advantage of this property of nat-
ural language, we devised a set of features which
model agreement. These allow the learner to op-
erate at a higher level, using agreement itself as a
feature rather than having to discover agreement and
forming generalizations about whether tokens which
agree (or disagree) in various ways are related. Since
agreement appears cross-linguistically, such features
are applicable to a diverse set of languages.
Since MSTParser breaks down every parse into a
set of arcs, our features are defined at the arc level.
Each arc is a head and dependent pair, and each of
those tokens has a list of morphological features in
the normalized form attribute=value. We com-
pare these lists and add, for every attribute which
is present in both, either an agreement or a disagree-
ment feature, depending on whether the head and de-
pendent have the same value for that attribute. This
feature encapsulates the attribute, but not the value,
as well as the coarse POS tags of the head and the
dependent. If an attribute is present in only one of
1If an attribute is marked on both head and dependent and
the value matches, the specific value should not affect the prob-
ability or possibility of the dependency relationship. If the same
attribute is marked on both elements but is independent (not a
matter of agreement) we risk losing information, but we hypoth-
esize that such information is unlikely to be very predictive.
the lists, we add a feature encapsulating whether the
token is the head or the dependent, the single mor-
phological feature (attribute and value), and the two
coarse POS tags. We also generate both types of fea-
tures conjoined with the arc label. Like the original
feature set, we include only first-order morphologi-
cal features. See Table 3 for a summary. A sample
sentence in a simplified CoNLL format and the fea-
tures it would trigger are shown in Table 4.2
We hypothesize that these agreement features will
function as a type of back-off, allowing the parser
to extract more information from the morphological
marking. For instance, they can capture case agree-
ment between a determiner and noun. We expect
that this would lead to higher parsing accuracy, espe-
cially when training on smaller datasets, where mor-
phological data might be sparse.
We made a slight modification to the parser so that
underscores used in the treebanks to indicate the ab-
sence of morphological annotation for a token were
not themselves treated as morphological informa-
tion. This was necessary to ensure that all feature
configurations performed identically on treebanks
with no morphological information. Depending on
the treebank, this increased or decreased the perfor-
mance of the system slightly (by less than 0.5%).
</bodyText>
<subsectionHeader confidence="0.999919">
3.2 Data collection and preparation
</subsectionHeader>
<bodyText confidence="0.99974675">
We gathered a range of dependency treebanks, rep-
resenting as many language families as possible (Ta-
ble 5). Many of these used the CoNLL shared task
treebank format, so we adopted it as well, and con-
</bodyText>
<footnote confidence="0.93588">
2A more complete description of the system, as well as
source code, can be found in (Hohensee, 2012).
</footnote>
<page confidence="0.989621">
318
</page>
<table confidence="0.994263166666666">
Language ISO Treebank Num. Ref. Avg. Reference
sents. size atts.
Hindi-Urdu hin HUTB 3,855 2,800 3.6 (Bhatt et al., 2009)
Hungarian hun Szeged DTB 92,176 9,000 3.3 (Vincze et al., 2010)
Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998)
Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011)
Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006)
Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003)
Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003)
Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002)
Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006)
Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004)
Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009)
Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010)
German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999)
Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003)
Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007)
Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004)
Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000)
Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002)
Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011)
English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993)
Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005)
*Acquired as part of NLTK (Bird et al., 2009)
</table>
<tableCaption confidence="0.9928375">
Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of
morphological attributes per token, and reference for each treebank used, ordered by average number of attributes.
</tableCaption>
<bodyText confidence="0.999070047619048">
verted the other treebanks to the same. It includes
for each token: position in the sentence; the token
itself; a lemma (not present in all datasets); a coarse
POS tag; a fine POS tag; a list of morphological fea-
tures; the token’s head; and the label for the depen-
dency relation to that head.3 We retained all punctu-
ation and other tokens in the treebanks.
The POS tagsets used in the treebanks varied
widely. We normalized the coarse tags to the univer-
sal twelve-tag set suggested by Petrov et al. (2011),
in order to ensure that every treebank had coarse tags
for use in the agreement features, and to make the
features easier to interpret. It is unlikely that infor-
mation was lost in this process: for treebanks with
one set of tags, information was added, and for those
with two, the universal tags aligned closely with the
coarse tags already in the data.
Two of the treebanks we used included no mor-
phological information. We included the Penn Chi-
nese Treebank as a representative of analytic lan-
guages.4 We also included part of the (English) Penn
</bodyText>
<footnote confidence="0.888823">
3The original format also included two more fields, projec-
tive head and label; neither is used by MSTParser.
4Dependency trees were generated from the Penn Chinese
</footnote>
<bodyText confidence="0.999915045454545">
Treebank, converted to dependency trees. For this
data we generated morphological annotations based
on fine POS tags, consisting of person and number
information for nouns and verbs, and person, num-
ber, and case information for pronouns. The German
NEGRA corpus includes detailed morphological an-
notations for about 3,400 sentences (of 20,600), and
we used only that portion.
Note that the amount of morphological informa-
tion present in any given treebank is a function of the
morphological properties of the language as well as
the annotation guidelines: annotations do not nec-
essarily encode all of the morphological informa-
tion which is actually marked in a language. Fur-
thermore, the presence of a morphological feature
does not imply that it participates in an agreement
relationship; it merely encodes some piece of mor-
phological information about the token. Finally, an-
notation guidelines vary as to whether they provide
for the explicit marking of morphological proper-
ties which are inherent to a lemma (e.g., gender on
nouns) and not marked by separate affixes.
</bodyText>
<footnote confidence="0.6484675">
Treebank using the Penn2Malt converter: http://w3.msi.
vxu.se/˜nivre/research/Penn2Malt.html.
</footnote>
<page confidence="0.997744">
319
</page>
<bodyText confidence="0.999596230769231">
We normalized all morphological annotations to
the form attribute=value (e.g., case=NOM). For
treebanks that provided values only, this involved
adding attribute names, obtained from the annota-
tion guidelines. The attributes person, number, gen-
der, and case appeared often; also included in some
data were verb tense, adjective degree, and pronoun
type (e.g., personal, possessive, or reflexive). We
normalized all features in the data, regardless of
whether they participate in any agreement relations.
Many of the treebanks include data from multiple
domains; to minimize the effects of this, we random-
ized the order of sentences in each treebank.
</bodyText>
<subsectionHeader confidence="0.988731">
3.3 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999932866666667">
All experiments were performed using 5-fold cross-
validation. Reported accuracies, run times, and fea-
ture counts are averages over all five folds. We
ran experiments on multiple cross-validation dataset
sizes in order to assess the performance of our model
when trained on different amounts of data. For each
treebank, we report results on a “reference size”:
9,000 sentences or the largest size available (for tree-
banks of less than 9,000 sentences).
For evaluation, we used the module built into
MSTParser. We focused on the unlabeled accu-
racy score (percentage of tokens with correctly as-
signed heads, ignoring labels). We also looked at
labeled accuracies, but found they displayed trends
very similar, if not identical, to the unlabeled scores.
</bodyText>
<sectionHeader confidence="0.999964" genericHeader="method">
4 Results
</sectionHeader>
<bodyText confidence="0.999975">
We ran the system on each treebank at all dataset
sizes in projective and non-projective modes, using
no morphological features. For each language, sub-
sequent tests used the algorithm which performed
better (or non-projective in the case of a tie).
</bodyText>
<subsectionHeader confidence="0.996275">
4.1 Overall results
</subsectionHeader>
<bodyText confidence="0.999935191489362">
We ran the parser on each treebank with each of
four feature configurations: one with no morpho-
logical features (no-morph); one with the original
morphological features (orig; Table 2); one using
the agreement features (agr; Table 3); and one us-
ing both feature sets (agr+orig).
Table 6 displays the unlabeled accuracy, run time,
and feature counts when parsing each treebank using
each feature configuration at the reference size, with
the highest accuracy highlighted. Excluding Chi-
nese, agr generated the best performance in all but
two cases, outperforming orig by margins ranging
from 0.8% (Arabic) to 5.3% (Latin) absolute. In the
other cases, agr+orig outperformed agr slightly.
In all cases, the total number of machine learning
features was approximately the same for no-morph
and agr, and for orig and agr+orig, because
the number of morphological features generated by
orig is very large compared to the number gener-
ated by agr. Performance was noticeably faster for
the two smaller feature configurations.
Figure 1 shows the error reduction of orig, agr,
and agr+orig relative to no-morph, at the refer-
ence size. Despite its relative lack of morphological
inflection, English shows a fairly high error reduc-
tion, because parsing performance on English was
already high. Similarly, error reduction on some of
the morphologically rich languages is lower because
baseline performance was low. Calculating the cor-
relation coefficient (Pearson’s r) between average
morphological attributes per token and error reduc-
tion gives r = 0.608 for orig, r = 0.560 for agr,
and r = 0.428 for agr+orig, with p &lt; 0.01 for
the first two and p &lt; 0.10 for the last, indicating
moderate correlations for all feature sets.
The strength of these correlations depends on sev-
eral factors. Languages differ in what information is
marked morphologically, and in number of agree-
ment relationships. Annotation schemes vary in
what morphological information they encode, and in
how relevant that information is to agreement. Some
morphologically complex languages have rigid word
order, leading to better performance with no mor-
phological features at all, and limiting the amount
of improvement that is possible. Finally, it is pos-
sible that a stronger correlation is obscured by other
effects due to feature set design, as we will find later.
</bodyText>
<subsectionHeader confidence="0.993596">
4.2 Performance vs. dataset size
</subsectionHeader>
<bodyText confidence="0.999671142857143">
Figures 2 presents unlabeled accuracy when parsing
Czech with the orig and agr configurations. Im-
provement with agr is roughly uniform across all
dataset sizes; this was the general trend for all tree-
banks. This is somewhat unexpected; we had pre-
dicted that the agreement features would be more
helpful at smaller dataset sizes.
</bodyText>
<page confidence="0.994092">
320
</page>
<table confidence="0.99986752173913">
Lang. no-morph orig agr agr+orig
UAC time feats UAC Otime Ofeats UAC Otime Ofeats UAC Otime Ofeats
hin 90.0 1.4k 1.6m 92.0 116% 893% 93.8 50% 1% 93.0 144% 893%
hun 87.9 4.6k 5.3m 88.7 201% 687% 90.3 10% 0% 89.9 159% 687%
ces 80.9 3.3k 4.8m 81.6 71% 454% 85.5 27% 0% 84.5 114% 454%
tam 79.0 0.1k 0.5m 79.7 237% 329% 82.1 64% 1% 81.1 279% 330%
slv 80.8 0.8k 1.0m 80.4 103% 352% 81.9 21% 1% 80.8 129% 353%
dan 87.7 2.0k 1.6m 88.4 71% 256% 89.3 24% 0% 89.3 86% 256%
lat 61.7 1.8k 1.6m 65.0 54% 306% 70.3 91% 0% 68.6 119% 306%
nld 88.2 2.0k 3.6m 89.0 83% 270% 90.5 16% 0% 90.3 98% 270%
eus 78.7 0.7k 1.7m 80.2 80% 229% 82.3 10% 0% 82.3 78% 230%
bul 89.9 1.7k 2.6m 90.1 60% 221% 93.0 14% 0% 92.5 54% 222%
grc 74.9 8.6k 3.8m 76.9 36% 314% 80.7 45% 0% 79.5 70% 314%
deu 90.0 0.9k 1.3m 90.8 33% 189% 92.0 1% 0% 91.7 50% 186%
fin 73.3 0.7k 2.4m 76.3 74% 244% 79.1 23% 1% 78.7 84% 245%
tur 80.2 1.2k 2.1m 81.5 13% 178% 81.6 −2% 0% 81.7 29% 178%
cat 81.8 3.0k 2.5m 81.9 2% 142% 84.9 -9% 0% 84.0 −2% 143%
ara 78.0 3.2k 2.0m 78.1 65% 94% 78.9 23% 0% 78.7 20% 94%
ita 88.3 4.2k 1.8m 88.9 −3% 59% 90.2 9% 0% 90.3 6% 59%
por 88.1 6.4k 5.0m 88.1 18% 46% 89.0 −3% 0% 88.9 27% 46%
heb 87.4 4.3k 3.1m 87.4 −18% 31% 89.2 −16% 0% 89.1 −5% 31%
eng 88.1 5.2k 3.1m 88.0 5% 7% 90.6 3% 0% 90.6 −9% 8%
cmn 82.4 7.5k 6.0m 82.4 37% 0% 82.4 16% 0% 82.4 23% 0%
</table>
<tableCaption confidence="0.953302">
Table 6: Unlabeled accuracy, run time in seconds, and number of features for all treebanks and feature configurations.
Run time and number of features for orig, agr, and agr+orig are given as percent change relative to no-morph
</tableCaption>
<subsectionHeader confidence="0.995946">
4.3 Gold vs. automatic tags
</subsectionHeader>
<bodyText confidence="0.999918666666667">
The Hebrew treebank includes both automatically
generated and gold standard POS and morphological
annotations. In order to test how sensitive the agree-
ment features are to automatically predicted mor-
phological information, tests were run on both ver-
sions at the reference size. These results are not di-
rectly comparable to those of Goldberg and Elhadad
(2009), because of the parser modifications, POS tag
normalization, and cross-validation described ear-
lier. Comparing results qualitatively, we find less
sensitivity to the automatic tags overall, and that the
orig features improve accuracy even when using
automatic tags.
Results appear in Table 7. Using the automatic
data affects all feature sets negatively by 2.1% to
2.9%. Since the no-morph parser was affected the
most, it appears that this decrease is due largely
to errors in the POS tags, rather than the morpho-
logical annotations. The orig features compensate
for this slightly (0.2%), and the agr features more
(0.8%); this indicates that including even automatic
morphological information can compensate for in-
correct POS tags, and that the agr feature configu-
ration is the most robust when given predicted tags.
</bodyText>
<table confidence="0.791890166666667">
Feature Acc. on Acc. on Difference
configuration gold data auto data
no-morph 87.4 84.5 −2.9
orig 87.4 84.7 −2.7
agr 89.3 87.2 −2.1
agr+orig 89.1 86.9 −2.2
</table>
<tableCaption confidence="0.994666">
Table 7: Unlabeled accuracy on Hebrew dataset, with
gold and automatic POS and morphological annotations
</tableCaption>
<subsectionHeader confidence="0.994838">
4.4 PPL feature
</subsectionHeader>
<bodyText confidence="0.9999846">
Examining the feature weights from the first cross-
validation fold when running the agr feature config-
uration on the Czech dataset indicated that 323 of the
1,000 highest-weighted features are agreement fea-
tures. Of these, 79 are symmetric (“agrees” or “dis-
agrees”) agr features, and 244 asymmetric. This
was unexpected, as the symmetric features would
seem to be more useful, and it suggested that the la-
beled asymmetric agr features might be important
for reasons other than their modeling of morpholog-
ical information. Careful analysis of the MSTParser
feature set revealed that it does not include a fea-
ture which incorporates head POS, dependent POS,
and dependency label. We hypothesized that the la-
beled asymmetric agr features were highly ranked
</bodyText>
<page confidence="0.998265">
321
</page>
<figureCaption confidence="0.999974">
Figure 1: Error reduction relative to no-morph vs. language
Figure 2: Unlabeled accuracy vs. num. sentences, Czech
</figureCaption>
<bodyText confidence="0.999969242424242">
because they capture these three arc features, not be-
cause they include with morphological information.
To test this, we added a single feature template
to MSTParser which encapsulates head POS, de-
pendent POS, and dependency label (the POS-POS-
label, or PPL, feature). Running a subsequent ex-
periment on the Czech data and looking at feature
weights from the same cross-validation fold, 278 of
the 1,000 highest-weighted features were PPL fea-
tures, and 187 were asymmetric agr features. This
indicated that the improvement seen with agr fea-
tures was indeed due partly to their inclusion of fea-
tures combining label and head and dependent POS.
All feature configurations were run on all tree-
banks with the PPL feature included; results appear
in Table 8. Performance increases from orig to
agr are generally smaller, with a maximum of 4.6%
absolute. This is seen especially on languages with
less morphological information, such as English and
Hebrew; this indicates that for those languages, most
of the previous improvement was due not to agree-
ment modeling, but to the PPL effect.
Calculating Pearson’s r between morphological
features per token and the new error reduction data
gives a stronger correlation coefficient of 0.748 for
agr, with p &lt; 0.01, demonstrating that improve-
ment due solely to agreement modeling correlates
strongly with quantity of morphological informa-
tion. The earlier error reduction data were likely
polluted by improvement due to capturing the PPL
information. Correlation for the other feature con-
figurations is still moderate (0.506 with p &lt; 0.02
for orig and 0.621 with p &lt; 0.01 for agr+orig).
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="method">
5 Future work
</sectionHeader>
<bodyText confidence="0.99942275">
In future work, we plan to experiment with more
careful normalization of treebanks. For instance,
if an adjective can agree with either a masculine
or a feminine noun, annotating it with both gen=M
</bodyText>
<page confidence="0.993751">
322
</page>
<table confidence="0.999921695652174">
Lang. no-morph orig agr agr+orig
UAC time feats UAC Atime Afeats UAC Atime Afeats UAC Atime Afeats
hin 90.0 1.4k 1.6 92.0 116% 893% 93.8 50% 1% 93.0 144% 893%
hun 87.9 4.6k 5.3 88.7 201% 687% 90.3 10% 0% 89.9 159% 687%
ces 80.9 3.3k 4.8 81.6 71% 454% 85.5 27% 0% 84.5 114% 454%
tam 79.0 0.1k 0.5 79.7 237% 329% 82.1 64% 1% 81.1 279% 330%
slv 80.8 0.8k 1.0 80.4 102% 352% 81.8 21% 0% 80.8 129% 353%
dan 87.8 2.0k 1.6 88.4 71% 256% 89.3 24% 0% 89.3 86% 256%
lat 61.7 1.8k 1.6 65.0 54% 306% 70.3 91% 0% 68.6 119% 306%
nld 88.2 2.0k 3.6 89.0 83% 270% 90.5 16% 0% 90.3 98% 270%
eus 78.7 0.7k 1.7 80.2 80% 229% 82.3 10% 0% 82.3 78% 230%
bul 89.9 1.7k 2.6 90.2 60% 221% 93.0 14% 0% 92.5 54% 222%
grc 74.9 8.6k 3.8 77.0 36% 314% 80.7 45% 0% 79.5 70% 314%
deu 90.0 0.9k 1.3 90.8 33% 189% 92.0 1% 0% 91.7 50% 186%
fin 73.3 0.7k 2.4 76.3 74% 244% 79.1 23% 0% 78.7 84% 245%
tur 80.2 1.2k 2.1 81.5 13% 178% 81.6 -2% 0% 81.7 29% 178%
cat 81.8 3.0k 2.5 81.9 1% 142% 84.9 -9% 0% 84.0 -2% 143%
ara 77.6 5.4k 1.8 77.7 20% 100% 78.2 -8% 0% 78.0 4% 100%
ita 88.4 4.2k 1.8 88.9 -2% 59% 90.2 9% 0% 90.3 6% 59%
por 88.1 6.4k 5.0 88.2 18% 46% 89.0 -3% 0% 88.9 27% 46%
heb 87.4 4.3k 3.1 87.4 -18% 31% 89.2 -16% 0% 89.1 -5% 31%
eng 88.1 5.2k 3.1 88.0 5% 7% 90.6 3% 0% 90.6 -9% 7%
cmn 82.4 7.5k 6.0 82.4 37% 0% 82.4 16% 0% 82.4 23% 0%
</table>
<tableCaption confidence="0.841933">
Table 8: Unlabeled accuracy, run time in seconds, and number of features with PPL feature included. Run time and
number of features for orig, agr, and agr+orig are given as percent change relative to no-morph.
</tableCaption>
<bodyText confidence="0.999942214285714">
and gen=F (rather than gen=X) would ensure that
agreement with a noun of either gender would be
captured by our features. Furthermore, we may ex-
periment with filtering morphological information
based on part-of-speech, on attribute, or on whether
the attribute participates in any agreement relation-
ships. We also intend to perform feature selection on
the original feature set, and investigate the impor-
tance of labeled morphological features, which are
included in agr but not in orig. Finally, we plan to
develop metrics to measure the degree of word or-
der flexibility in a treebank, in order to explore the
extent to which it correlates with the degree of im-
provement achieved by our system.
</bodyText>
<sectionHeader confidence="0.996774" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999932777777778">
We developed a simple, language-independent
model of agreement to better leverage morphologi-
cal data in dependency parsing. Testing on treebanks
containing varying amounts of morphological infor-
mation resulted in substantial improvements in pars-
ing accuracy while reducing feature counts and run
times significantly. Although originally intended to
compensate for lower accuracy on morphologically
rich languages, the model improved performance on
all treebanks with any morphological information.
We acknowledge that because our model was
tested on treebanks which differ widely in annota-
tion guidelines, variables such as the amount of mor-
phological information included and the treatment
of non-projective parses and coordination could af-
fect parsing performance. We did not delve into
these factors. However, we believe this is part of the
strength of the approach: we were able to achieve
performance gains without any detailed knowledge
of the languages and treebanks used.
We hope these results will encourage similarly
linguistically motivated design in future systems.
This case study provides strong evidence that in-
corporating linguistic knowledge into NLP systems
does not preclude language independence, and in-
deed may enhance it, by leveling performance across
typologically differing languages.
</bodyText>
<sectionHeader confidence="0.99171" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9996788">
We would like to thank everyone who assisted us in
gathering treebanks, particularly Maite Oronoz and
her colleagues at the University of the Basque Coun-
try and Yoav Goldberg, as well as three anonymous
reviewers for their comments.
</bodyText>
<page confidence="0.998848">
323
</page>
<sectionHeader confidence="0.990367" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995869257142857">
I. Aduriz, M.J. Aranzabe, J.M. Arriola, A. Atutxa, A.D.
de Ilarraza, A. Garmendia, and M. Oronoz. 2003.
Construction of a Basque dependency treebank. In
Proc. of the Second Workshop on Treebanks and Lin-
guistic Theories (TLT 2003), pages 201–204.
S. Afonso, E. Bick, R. Haber, and D. Santos. 2002.
Floresta Sint´a(c)tica: A treebank for Portuguese. In
Proc. of the Third International Conference on Lan-
guage Resources and Evaluation (LREC 2002), page
1698.
G. Attardi, F. DellOrletta, M. Simi, A. Chanev, and
M. Ciaramita. 2007. Multilingual dependency pars-
ing and domain adaptation using DeSR. In Proc. of the
2007 Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL 2007), pages
1112–1118.
D. Bamman and G. Crane. 2006. The design and use
of a Latin dependency treebank. In Proc. of the Fifth
International Workshop on Treebanks and Linguistic
Theories (TLT 2006), pages 67–78.
D. Bamman, F. Mambrini, and G. Crane. 2009. An own-
ership model of annotation: The Ancient Greek De-
pendency Treebank. In Proc. of the Eighth Interna-
tional Workshop on Treebanks and Linguistic Theories
(TLT8), pages 5–15.
E.M. Bender. 2011. On achieving and evaluating
language-independence in NLP. Linguistic Issues in
Language Technology: Special Issue on Interaction of
Linguistics and Computational Linguistics, 6(3):1–26.
K. Bengoetxea and K. Gojenola. 2010. Application of
different techniques to dependency parsing of Basque.
In Proc. of the First Workshop on Statistical Parsing
of Morphologically Rich Languages (SPMRL 2010),
pages 31–39. Association for Computational Linguis-
tics.
R. Bhatt, B. Narasimhan, M. Palmer, O. Rambow, D.M.
Sharma, and F. Xia. 2009. A multi-representational
and multi-layered treebank for Hindi/Urdu. In Proc. of
the Third Linguistic Annotation Workshop (LAW III),
pages 186–189. Association for Computational Lin-
guistics.
E. Bick. 2006. LingPars, a linguistically inspired,
language-independent machine learner for depen-
dency treebanks. In Proc. of the Tenth Conference on
Computational Natural Language Learning (CoNLL-
X), pages 171–175. Association for Computational
Linguistics.
S. Bird, E. Klein, and E. Loper. 2009. Natural Language
Processing with Python. O’Reilly Media.
C. Bosco, V. Lombardo, D. Vassallo, and L. Lesmo.
2000. Building a treebank for Italian: a data-driven
annotation schema. In Proc. of the Second Interna-
tional Conference on Language Resources and Evalu-
ation (LREC 2000), pages 99–106.
T. Brants, W. Skut, and H. Uszkoreit. 1999. Syntactic
annotation of a German newspaper corpus. Treebanks:
Building and using parsed corpora, 20:73.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
the Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X), pages 149–164. Associa-
tion for Computational Linguistics.
X. Carreras, M. Surdeanu, and L. Marquez. 2006. Pro-
jective dependency parsing with perceptron. In Proc.
of the Tenth Conference on Computational Natural
Language Learning (CoNLL-X), pages 181–185. As-
sociation for Computational Linguistics.
M.W. Chang, Q. Do, and D. Roth. 2006. A pipeline
model for bottom-up dependency parsing. In Proc. of
the Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X), pages 186–190. Associa-
tion for Computational Linguistics.
G.G. Corbett. 2006. Agreement. Cambridge University
Press.
S. Dz&amp;quot;eroski, T. Erjavec, N. Ledinek, P. Pajas,
Z. &amp;quot;Zabokrtsky, and A. &amp;quot;Zele. 2006. Towards a Slovene
dependency treebank. In Proc. of the Fifth Interna-
tional Conference on Language Resources and Evalu-
ation (LREC 2006).
G. Eryi&amp;quot;git, J. Nivre, and K. Oflazer. 2008. Depen-
dency parsing of Turkish. Computational Linguistics,
34(3):357–389.
Y. Goldberg and M. Elhadad. 2009. Hebrew de-
pendency parsing: Initial results. In Proc. of the
11th International Conference on Parsing Technolo-
gies (IWPT’09), pages 129–133. Association for Com-
putational Linguistics.
Y. Goldberg and M. Elhadad. 2010. Easy-first depen-
dency parsing of Modern Hebrew. In Proc. of the First
Workshop on Statistical Parsing of Morphologically
Rich Languages (SPMRL 2010), pages 103–107. As-
sociation for Computational Linguistics.
Yoav Goldberg. 2011. Automatic Syntactic Processing of
Modern Hebrew. Ph.D. thesis, Ben Gurion University.
J. Hajic, O. Smrz, P. Zem´anek, J. &amp;quot;Snaidauf, and E. Be&amp;quot;ska.
2004. Prague Arabic dependency treebank: Develop-
ment in data and tools. In Proc. of the NEMLAR Inter-
national Conference on Arabic Language Resources
and Tools, pages 110–117.
Jan Haji&amp;quot;c. 1998. Building a syntactically annotated
corpus: The Prague Dependency Treebank. In Eva
Haji&amp;quot;cov´a, editor, Issues of Valency and Meaning:
Studies in Honor of Jarmila Panevov´a, pages 12–19.
Prague Karolinum, Charles University Press.
</reference>
<page confidence="0.995477">
324
</page>
<reference confidence="0.99974391588785">
Katri Haverinen, Timo Viljanen, Veronika Laippala,
Samuel Kohonen, Filip Ginter, and Tapio Salakoski.
2010. Treebanking Finnish. In Proc. of the Ninth
International Workshop on Treebanks and Linguistic
Theories (TLT9, volume 9, pages 79–90.
M. Hohensee. 2012. It’s only morpho-logical: Model-
ing agreement in cross-linguistic dependency parsing.
Master’s thesis, University of Washington.
M.T. Kromann. 2003. The Danish Dependency Tree-
bank and the DTAG treebank tool. In Proc. of the Sec-
ond Workshop on Treebanks and Linguistic Theories
(TLT 2003), pages 217–220.
M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini.
1993. Building a large annotated corpus of En-
glish: The Penn Treebank. Computational Linguistics,
19(2):313–330.
M.A. Martı, M. Taul´e, L. M´arquez, and M. Bertran.
2007. CESS-ECE: A multilingual and multilevel an-
notated corpus.
Y. Marton, N. Habash, and O. Rambow. 2010. Improv-
ing Arabic dependency parsing with lexical and inflec-
tional morphological features. In Proc. of the First
Workshop on Statistical Parsing of Morphologically
Rich Languages (SPMRL 2010), pages 13–21. Asso-
ciation for Computational Linguistics.
R. McDonald, K. Lerman, and F. Pereira. 2006. Multi-
lingual dependency analysis with a two-stage discrim-
inative parser. In Proc. of the Tenth Conference on
Computational Natural Language Learning (CoNLL-
X), pages 216–220. Association for Computational
Linguistics.
T. Nakagawa. 2007. Multilingual dependency pars-
ing using global features. In Proc. of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL 2007), pages 952–
956.
J. Nivre, J. Hall, and J. Nilsson. 2006a. Maltparser: A
data-driven parser-generator for dependency parsing.
In Proc. of the Fifth International Conference on Lan-
guage Resources and Evaluation (LREC 2006), vol-
ume 6, pages 2216–2219.
J. Nivre, J. Hall, J. Nilsson, G. Eryiˇgit, and S. Mari-
nov. 2006b. Labeled pseudo-projective dependency
parsing with support vector machines. In Proc. of
the Tenth Conference on Computational Natural Lan-
guage Learning (CoNLL-X), pages 221–225. Associa-
tion for Computational Linguistics.
J. Nivre, J. Hall, S. Kabler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. CoNLL 2007 shared
task on dependency parsing. In Proc. of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL 2007). Association
for Computational Linguistics.
J. Nivre, I.M. Boguslavsky, and L.L. Iomdin. 2008. Pars-
ing the SynTagRus treebank of Russian. In Proc. of the
22nd International Conference on Computational Lin-
guistics (COLING 2008), volume 1, pages 641–648.
Association for Computational Linguistics.
J. Nivre. 2009. Parsing Indian languages with Malt-
Parser. In Proc. of the Seventh International Confer-
ence on Natural Language Processing (ICON 2009)
NLP Tools Contest, pages 12–18.
K. Oflazer, B. Say, D.Z. Hakkani-Tar, and G. Tar. 2003.
Building a Turkish treebank. Text, Speech, and Lan-
guage Technology, pages 261–277.
L. Øvrelid and J. Nivre. 2007. When word order and
part-of-speech tags are not enough–Swedish depen-
dency parsing with rich linguistic features. In Proc. of
the International Conference on Recent Advances in
Natural Language Processing (RANLP), pages 447–
451.
S. Petrov, D. Das, and R. McDonald. 2011. A
universal part-of-speech tagset. Arxiv preprint
ArXiv:1104.2086.
Loganathan Ramasamy and Zdenˇek ˇZabokrtsk´y. 2011.
Tamil dependency parsing: Results using rule based
and corpus based approaches. In Proc. of the 12th
International Conference on Intelligent Text Process-
ing and Computational Linguistics (CICLING 2011),
volume 1, pages 82–95, Berlin, Heidelberg. Springer-
Verlag.
M. Schiehlen and K. Spranger. 2007. Global learn-
ing of labelled dependency trees. In Proc. of the
2007 Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL 2007), pages
1156–1160.
Anna Siewierska. 1998. Variation in major constituent
order: A global and a European perspective. In
Anna Siewierska, editor, Constituent Order in the
Languages of Europe, pages 475–551. Mouton De
Gruyter.
K. Simov, P. Osenova, A. Simov, and M. Kouylekov.
2004. Design and implementation of the Bulgar-
ian HPSG-based treebank. Research on Language &amp;
Computation, 2(4):495–522.
I. Titov and J. Henderson. 2007. Fast and robust mul-
tilingual dependency parsing with a generative latent
variable model. In Proc. of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL 2007), pages 947–951.
L. Van der Beek, G. Bouma, R. Malouf, and G. Van No-
ord. 2002. The Alpino dependency treebank. Lan-
guage and Computers, 45(1):8–22.
</reference>
<page confidence="0.987103">
325
</page>
<reference confidence="0.999320125">
V. Vincze, D. Szauter, A. Alm´asi, G. M´ora, Z. Alexin,
and J. Csirik. 2010. Hungarian dependency treebank.
In Proc. of the Seventh Conference on Language Re-
sources and Evaluation (LREC 2010).
N. Xue, F. Xia, F.D. Chiou, and M. Palmer. 2005. The
Penn Chinese Treebank: Phrase structure annotation
of a large corpus. Natural Language Engineering,
11(2):207–238.
</reference>
<page confidence="0.999113">
326
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.789629">
<title confidence="0.999947">Getting More from Morphology in Multilingual Dependency Parsing</title>
<author confidence="0.999495">Matt Hohensee</author>
<author confidence="0.999495">M Emily</author>
<affiliation confidence="0.9983425">University of Department of</affiliation>
<address confidence="0.909179">Box Seattle WA 98195-4340,</address>
<abstract confidence="0.996945076923077">We propose a linguistically motivated set of features to capture morphological agreement and add them to the MSTParser dependency parser. Compared to the built-in morphological feature set, ours is both much smaller and more accurate across a sample of 20 morphologically annotated treebanks. We find increases in accuracy of up to 5.3% absolute. While some of this results from the feature set capturing information unrelated to morphology, there is still significant improvement, up to 4.6% absolute, due to the agreement model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>M J Aranzabe</author>
<author>J M Arriola</author>
<author>A Atutxa</author>
<author>A D de Ilarraza</author>
<author>A Garmendia</author>
<author>M Oronoz</author>
</authors>
<title>Construction of a Basque dependency treebank.</title>
<date>2003</date>
<booktitle>In Proc. of the Second Workshop on Treebanks and Linguistic Theories (TLT</booktitle>
<pages>201--204</pages>
<marker>Aduriz, Aranzabe, Arriola, Atutxa, de Ilarraza, Garmendia, Oronoz, 2003</marker>
<rawString>I. Aduriz, M.J. Aranzabe, J.M. Arriola, A. Atutxa, A.D. de Ilarraza, A. Garmendia, and M. Oronoz. 2003. Construction of a Basque dependency treebank. In Proc. of the Second Workshop on Treebanks and Linguistic Theories (TLT 2003), pages 201–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Afonso</author>
<author>E Bick</author>
<author>R Haber</author>
<author>D Santos</author>
</authors>
<title>Floresta Sint´a(c)tica: A treebank for Portuguese.</title>
<date>2002</date>
<booktitle>In Proc. of the Third International Conference on Language Resources and Evaluation (LREC 2002),</booktitle>
<pages>1698</pages>
<contexts>
<context position="16971" citStr="Afonso et al., 2002" startWordPosition="2464" endWordPosition="2467"> (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of morphological attributes per token, and reference for each treebank used, ordered by average number of attributes. verted the other treebanks to the same. It includes for each token: position in the sentence; the token itself; a lemma (not present in all datasets);</context>
</contexts>
<marker>Afonso, Bick, Haber, Santos, 2002</marker>
<rawString>S. Afonso, E. Bick, R. Haber, and D. Santos. 2002. Floresta Sint´a(c)tica: A treebank for Portuguese. In Proc. of the Third International Conference on Language Resources and Evaluation (LREC 2002), page 1698.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Attardi</author>
<author>F DellOrletta</author>
<author>M Simi</author>
<author>A Chanev</author>
<author>M Ciaramita</author>
</authors>
<title>Multilingual dependency parsing and domain adaptation using DeSR.</title>
<date>2007</date>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>1112--1118</pages>
<contexts>
<context position="9626" citStr="Attardi et al. (2007)" startWordPosition="1353" endWordPosition="1356">depPOS&gt; head_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; dep_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; &lt;attr&gt;_agrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Labeled &lt;attr&gt;_disagrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; head_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; dep_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Table 3: Agreement feature templates. headPOS and depPOS are the head and dependent coarse POS tags. (Carreras et al., 2006). Schiehlen and Spranger (2007) used language-specific rules to add detail to other features, such as fine-grained POS tags or lemmas. Attardi et al. (2007) modeled agreement explicitly, generating a morphological agreement feature whenever two tokens possess the same value for the same linguistic attribute. The authors note accuracy improvements of up to 0.5% for Italian and 0.8% for Catalan using a transition-based parser. A similar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agreement in noun phrases. The potential of morphological information to improve parsing performance has been documented in numerous experiments using MaltParse</context>
</contexts>
<marker>Attardi, DellOrletta, Simi, Chanev, Ciaramita, 2007</marker>
<rawString>G. Attardi, F. DellOrletta, M. Simi, A. Chanev, and M. Ciaramita. 2007. Multilingual dependency parsing and domain adaptation using DeSR. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 1112–1118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bamman</author>
<author>G Crane</author>
</authors>
<title>The design and use of a Latin dependency treebank.</title>
<date>2006</date>
<booktitle>In Proc. of the Fifth International Workshop on Treebanks and Linguistic Theories (TLT</booktitle>
<pages>67--78</pages>
<contexts>
<context position="16434" citStr="Bamman and Crane, 2006" startWordPosition="2372" endWordPosition="2375">code, can be found in (Hohensee, 2012). 318 Language ISO Treebank Num. Ref. Avg. Reference sents. size atts. Hindi-Urdu hin HUTB 3,855 2,800 3.6 (Bhatt et al., 2009) Hungarian hun Szeged DTB 92,176 9,000 3.3 (Vincze et al., 2010) Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) Eng</context>
</contexts>
<marker>Bamman, Crane, 2006</marker>
<rawString>D. Bamman and G. Crane. 2006. The design and use of a Latin dependency treebank. In Proc. of the Fifth International Workshop on Treebanks and Linguistic Theories (TLT 2006), pages 67–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bamman</author>
<author>F Mambrini</author>
<author>G Crane</author>
</authors>
<title>An ownership model of annotation: The Ancient Greek Dependency Treebank.</title>
<date>2009</date>
<booktitle>In Proc. of the Eighth International Workshop on Treebanks and Linguistic Theories (TLT8),</booktitle>
<pages>5--15</pages>
<contexts>
<context position="16562" citStr="Bamman et al., 2009" startWordPosition="2393" endWordPosition="2396">855 2,800 3.6 (Bhatt et al., 2009) Hungarian hun Szeged DTB 92,176 9,000 3.3 (Vincze et al., 2010) Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as </context>
</contexts>
<marker>Bamman, Mambrini, Crane, 2009</marker>
<rawString>D. Bamman, F. Mambrini, and G. Crane. 2009. An ownership model of annotation: The Ancient Greek Dependency Treebank. In Proc. of the Eighth International Workshop on Treebanks and Linguistic Theories (TLT8), pages 5–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Bender</author>
</authors>
<title>On achieving and evaluating language-independence in NLP.</title>
<date>2011</date>
<booktitle>Linguistic Issues in Language Technology: Special Issue on Interaction of Linguistics and Computational Linguistics,</booktitle>
<pages>6--3</pages>
<contexts>
<context position="1302" citStr="Bender, 2011" startWordPosition="193" endWordPosition="194">nt improvement, up to 4.6% absolute, due to the agreement model. 1 Introduction Most data-driven dependency parsers are meant to be language-independent. They do not use any information that is specific to the language being parsed, and they often rely heavily on n-grams, or sequences of words and POS tags, to make parsing decisions. However, designing a parser without incorporating any specific linguistic details does not guarantee its language-independence; even linguistically naive systems can involve design decisions which in fact bias the system towards languages with certain properties (Bender, 2011). It is often taken for granted that using linguistic information necessarily makes a system languagedependent. But it is possible to design a linguistically intelligent parser without tuning it to a specific language, by modeling at a high level phenomena which appear cross-linguistically. Such a system is still language-independent; it does not require any knowledge or modeling of specific languages, but it does use linguistic knowledge to make the most of the available data. We present modifications to an existing system, MSTParser (McDonald et al., 2006), to incorporate a very simple model</context>
</contexts>
<marker>Bender, 2011</marker>
<rawString>E.M. Bender. 2011. On achieving and evaluating language-independence in NLP. Linguistic Issues in Language Technology: Special Issue on Interaction of Linguistics and Computational Linguistics, 6(3):1–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bengoetxea</author>
<author>K Gojenola</author>
</authors>
<title>Application of different techniques to dependency parsing of Basque.</title>
<date>2010</date>
<booktitle>In Proc. of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010),</booktitle>
<pages>31--39</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10535" citStr="Bengoetxea and Gojenola, 2010" startWordPosition="1488" endWordPosition="1491">lar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agreement in noun phrases. The potential of morphological information to improve parsing performance has been documented in numerous experiments using MaltParser and with various morphological attributes as machine learning features, on several morphologically rich languages, including: Russian (Nivre et al., 2008); Swedish (Øvrelid and Nivre, 2007); Bangla, Telugu, and Hindi (Nivre, 2009); Turkish (Eryiˇgit et al., 2008); and Basque (Bengoetxea and Gojenola, 2010). These experiments, however, did not include any higher-level features such as agreement. Goldberg and Elhadad (2009) found that using morphological features increased the accuracy of MSTParser on Hebrew only when the morphological annotations were gold-standard; automatic annotations decreased accuracy, although MaltParser showed improvement with both gold and automatic annotations. The accuracy of MaltParser on Arabic was improved by different types of morphological features depending on whether gold or automatic annotations were used (Marton et al., 2010). As far as we can tell, no languag</context>
</contexts>
<marker>Bengoetxea, Gojenola, 2010</marker>
<rawString>K. Bengoetxea and K. Gojenola. 2010. Application of different techniques to dependency parsing of Basque. In Proc. of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), pages 31–39. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bhatt</author>
<author>B Narasimhan</author>
<author>M Palmer</author>
<author>O Rambow</author>
<author>D M Sharma</author>
<author>F Xia</author>
</authors>
<title>A multi-representational and multi-layered treebank for Hindi/Urdu.</title>
<date>2009</date>
<booktitle>In Proc. of the Third Linguistic Annotation Workshop (LAW III),</booktitle>
<pages>186--189</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15976" citStr="Bhatt et al., 2009" startWordPosition="2291" endWordPosition="2294">eebanks with no morphological information. Depending on the treebank, this increased or decreased the performance of the system slightly (by less than 0.5%). 3.2 Data collection and preparation We gathered a range of dependency treebanks, representing as many language families as possible (Table 5). Many of these used the CoNLL shared task treebank format, so we adopted it as well, and con2A more complete description of the system, as well as source code, can be found in (Hohensee, 2012). 318 Language ISO Treebank Num. Ref. Avg. Reference sents. size atts. Hindi-Urdu hin HUTB 3,855 2,800 3.6 (Bhatt et al., 2009) Hungarian hun Szeged DTB 92,176 9,000 3.3 (Vincze et al., 2010) Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin T</context>
</contexts>
<marker>Bhatt, Narasimhan, Palmer, Rambow, Sharma, Xia, 2009</marker>
<rawString>R. Bhatt, B. Narasimhan, M. Palmer, O. Rambow, D.M. Sharma, and F. Xia. 2009. A multi-representational and multi-layered treebank for Hindi/Urdu. In Proc. of the Third Linguistic Annotation Workshop (LAW III), pages 186–189. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bick</author>
</authors>
<title>LingPars, a linguistically inspired, language-independent machine learner for dependency treebanks.</title>
<date>2006</date>
<booktitle>In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLLX),</booktitle>
<pages>171--175</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5880" citStr="Bick, 2006" startWordPosition="910" endWordPosition="911">guage-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using it to disambiguate function words (Bick, 2006) or to pick out finite verbs foreign investments grow foreign investment grow .3RD.PL .PL Table 1: Sentence in Czech (Hajiˇc, 1998) and English A sample sentence in English and Czech (Table 1) demonstrates this contrast. In Czech, the adjective and noun agree for gender, number, and case, and the noun and verb agree for person and number. In the English version, only the noun and verb agree. Agreement can be very useful for data-driven dependency parsing. A statistical parser can learn from training data that, for example, a third-person singular noun is a likely dependent of a verb marked as </context>
</contexts>
<marker>Bick, 2006</marker>
<rawString>E. Bick. 2006. LingPars, a linguistically inspired, language-independent machine learner for dependency treebanks. In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLLX), pages 171–175. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>E Klein</author>
<author>E Loper</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python. O’Reilly Media.</booktitle>
<contexts>
<context position="17194" citStr="Bird et al., 2009" startWordPosition="2503" endWordPosition="2506">urku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of morphological attributes per token, and reference for each treebank used, ordered by average number of attributes. verted the other treebanks to the same. It includes for each token: position in the sentence; the token itself; a lemma (not present in all datasets); a coarse POS tag; a fine POS tag; a list of morphological features; the token’s head; and the label for the dependency relation to that head.3 We retained all punctuation and other tokens in the treebanks. The POS tagsets </context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>S. Bird, E. Klein, and E. Loper. 2009. Natural Language Processing with Python. O’Reilly Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bosco</author>
<author>V Lombardo</author>
<author>D Vassallo</author>
<author>L Lesmo</author>
</authors>
<title>Building a treebank for Italian: a data-driven annotation schema.</title>
<date>2000</date>
<booktitle>In Proc. of the Second International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>99--106</pages>
<contexts>
<context position="16909" citStr="Bosco et al., 2000" startWordPosition="2454" endWordPosition="2457">0 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of morphological attributes per token, and reference for each treebank used, ordered by average number of attributes. verted the other treebanks to the same. It includes for each token: position in the sent</context>
</contexts>
<marker>Bosco, Lombardo, Vassallo, Lesmo, 2000</marker>
<rawString>C. Bosco, V. Lombardo, D. Vassallo, and L. Lesmo. 2000. Building a treebank for Italian: a data-driven annotation schema. In Proc. of the Second International Conference on Language Resources and Evaluation (LREC 2000), pages 99–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>W Skut</author>
<author>H Uszkoreit</author>
</authors>
<title>Syntactic annotation of a German newspaper corpus. Treebanks: Building and using parsed corpora,</title>
<date>1999</date>
<contexts>
<context position="16676" citStr="Brants et al., 1999" startWordPosition="2413" endWordPosition="2416">.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, refe</context>
</contexts>
<marker>Brants, Skut, Uszkoreit, 1999</marker>
<rawString>T. Brants, W. Skut, and H. Uszkoreit. 1999. Syntactic annotation of a German newspaper corpus. Treebanks: Building and using parsed corpora, 20:73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7551" citStr="Buchholz and Marsi, 2006" startWordPosition="1175" endWordPosition="1178">a (1998) investigated this empirically and found that it holds to a certain extent: the absence of agreement and/or case marking predicts rigid word order, though their presence is not particularly predictive of flexible word order. Many parsers rely on word order to establish dependencies, so they often perform best on languages with more rigid word order. Making use of morphological agreement could compensate for greater variation in word order and help to bring parsing performance on flexible-word-order languages up to par with that on rigid-word-order languages. 2.2 MSTParser The CoNLL-X (Buchholz and Marsi, 2006) and CoNLL 2007 (Nivre et al., 2007) shared tasks focused on multilingual dependency parsing. Each system was trained on treebanks in a variety of languages and predicted dependency arcs and labels for POS-tagged data. The best performers in 2006 were MSTParser (McDonald et al., 2006), which we use here, and MaltParser (Nivre et al., 2006a). 316 &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdF</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 149–164. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>M Surdeanu</author>
<author>L Marquez</author>
</authors>
<title>Projective dependency parsing with perceptron.</title>
<date>2006</date>
<booktitle>In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>181--185</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5503" citStr="Carreras et al., 2006" startWordPosition="846" endWordPosition="849">ective trees are those in which every constituent (head plus all dependents) forms a complete subtree; non-projective parsing lacks this limitation. 2.3 Related work The organizers of the CoNLL 2007 shared task noted that languages with free word order and high morphological complexity are the most difficult for dependency parsing (Nivre et al., 2007). Most of the participants took language-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using it to disambiguate function words (Bick, 2006) or to pick out finite verbs foreign investments grow foreign investment grow .3RD.PL .PL Table 1: Sentence in Czech (Hajiˇc, 1998) and English A sample sentence in English and Czech (Table 1) demonstrates this contrast. In</context>
<context position="9470" citStr="Carreras et al., 2006" startWordPosition="1328" endWordPosition="1331"> direction and length of the arc. Each line represents one feature. &lt;attr&gt;_agrees,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Unlabeled &lt;attr&gt;_disagrees,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; head_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; dep_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; &lt;attr&gt;_agrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Labeled &lt;attr&gt;_disagrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; head_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; dep_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Table 3: Agreement feature templates. headPOS and depPOS are the head and dependent coarse POS tags. (Carreras et al., 2006). Schiehlen and Spranger (2007) used language-specific rules to add detail to other features, such as fine-grained POS tags or lemmas. Attardi et al. (2007) modeled agreement explicitly, generating a morphological agreement feature whenever two tokens possess the same value for the same linguistic attribute. The authors note accuracy improvements of up to 0.5% for Italian and 0.8% for Catalan using a transition-based parser. A similar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agre</context>
</contexts>
<marker>Carreras, Surdeanu, Marquez, 2006</marker>
<rawString>X. Carreras, M. Surdeanu, and L. Marquez. 2006. Projective dependency parsing with perceptron. In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 181–185. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Chang</author>
<author>Q Do</author>
<author>D Roth</author>
</authors>
<title>A pipeline model for bottom-up dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>186--190</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5567" citStr="Chang et al., 2006" startWordPosition="858" endWordPosition="861">endents) forms a complete subtree; non-projective parsing lacks this limitation. 2.3 Related work The organizers of the CoNLL 2007 shared task noted that languages with free word order and high morphological complexity are the most difficult for dependency parsing (Nivre et al., 2007). Most of the participants took language-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using it to disambiguate function words (Bick, 2006) or to pick out finite verbs foreign investments grow foreign investment grow .3RD.PL .PL Table 1: Sentence in Czech (Hajiˇc, 1998) and English A sample sentence in English and Czech (Table 1) demonstrates this contrast. In Czech, the adjective and noun agree for gender, number, and cas</context>
</contexts>
<marker>Chang, Do, Roth, 2006</marker>
<rawString>M.W. Chang, Q. Do, and D. Roth. 2006. A pipeline model for bottom-up dependency parsing. In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 186–190. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G G Corbett</author>
</authors>
<date>2006</date>
<publisher>Agreement. Cambridge University Press.</publisher>
<contexts>
<context position="2908" citStr="Corbett, 2006" startWordPosition="442" endWordPosition="443">end of the spectrum are analytic, or “morphologically impoverished”, languages. An extreme example is Chinese, which shows no inflection at all; words do not take different forms depending on features such as person or gender. English has some inflection, but is relatively morphologically poor. At the other end are synthetic or “morphologically rich” languages such as Czech, which has, inter alia, four genders and seven cases. In synthetic languages, words which are syntactically related in certain ways must agree: e.g., subject-verb agreement for gender or determiner-noun agreement for case (Corbett, 2006). Words participating in agreement may be marked explicitly for the property in question (via affixing or other morphological changes), or may possess it inherently (with no specific affix encoding the property). Treebanks are often annotated to reflect some or all of these properties; the level of detail depends on the annotation guidelines. 315 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 315–326, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics zahraniˇcn´ı investice rost</context>
</contexts>
<marker>Corbett, 2006</marker>
<rawString>G.G. Corbett. 2006. Agreement. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dzeroski</author>
<author>T Erjavec</author>
<author>N Ledinek</author>
<author>P Pajas</author>
<author>Z Zabokrtsky</author>
<author>A Zele</author>
</authors>
<title>Towards a Slovene dependency treebank.</title>
<date>2006</date>
<booktitle>In Proc. of the Fifth International Conference on Language Resources and Evaluation (LREC</booktitle>
<marker>Dzeroski, Erjavec, Ledinek, Pajas, Zabokrtsky, Zele, 2006</marker>
<rawString>S. Dz&amp;quot;eroski, T. Erjavec, N. Ledinek, P. Pajas, Z. &amp;quot;Zabokrtsky, and A. &amp;quot;Zele. 2006. Towards a Slovene dependency treebank. In Proc. of the Fifth International Conference on Language Resources and Evaluation (LREC 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Eryigit</author>
<author>J Nivre</author>
<author>K Oflazer</author>
</authors>
<title>Dependency parsing of Turkish.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<marker>Eryigit, Nivre, Oflazer, 2008</marker>
<rawString>G. Eryi&amp;quot;git, J. Nivre, and K. Oflazer. 2008. Dependency parsing of Turkish. Computational Linguistics, 34(3):357–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Goldberg</author>
<author>M Elhadad</author>
</authors>
<title>Hebrew dependency parsing: Initial results.</title>
<date>2009</date>
<booktitle>In Proc. of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>129--133</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10653" citStr="Goldberg and Elhadad (2009)" startWordPosition="1504" endWordPosition="1507">y adding features for gender and number agreement in noun phrases. The potential of morphological information to improve parsing performance has been documented in numerous experiments using MaltParser and with various morphological attributes as machine learning features, on several morphologically rich languages, including: Russian (Nivre et al., 2008); Swedish (Øvrelid and Nivre, 2007); Bangla, Telugu, and Hindi (Nivre, 2009); Turkish (Eryiˇgit et al., 2008); and Basque (Bengoetxea and Gojenola, 2010). These experiments, however, did not include any higher-level features such as agreement. Goldberg and Elhadad (2009) found that using morphological features increased the accuracy of MSTParser on Hebrew only when the morphological annotations were gold-standard; automatic annotations decreased accuracy, although MaltParser showed improvement with both gold and automatic annotations. The accuracy of MaltParser on Arabic was improved by different types of morphological features depending on whether gold or automatic annotations were used (Marton et al., 2010). As far as we can tell, no language-independent approaches to utilizing morphological data thus far have taken advantage of agreement specifically. We t</context>
<context position="26146" citStr="Goldberg and Elhadad (2009)" startWordPosition="4006" endWordPosition="4009">82.4 23% 0% Table 6: Unlabeled accuracy, run time in seconds, and number of features for all treebanks and feature configurations. Run time and number of features for orig, agr, and agr+orig are given as percent change relative to no-morph 4.3 Gold vs. automatic tags The Hebrew treebank includes both automatically generated and gold standard POS and morphological annotations. In order to test how sensitive the agreement features are to automatically predicted morphological information, tests were run on both versions at the reference size. These results are not directly comparable to those of Goldberg and Elhadad (2009), because of the parser modifications, POS tag normalization, and cross-validation described earlier. Comparing results qualitatively, we find less sensitivity to the automatic tags overall, and that the orig features improve accuracy even when using automatic tags. Results appear in Table 7. Using the automatic data affects all feature sets negatively by 2.1% to 2.9%. Since the no-morph parser was affected the most, it appears that this decrease is due largely to errors in the POS tags, rather than the morphological annotations. The orig features compensate for this slightly (0.2%), and the a</context>
</contexts>
<marker>Goldberg, Elhadad, 2009</marker>
<rawString>Y. Goldberg and M. Elhadad. 2009. Hebrew dependency parsing: Initial results. In Proc. of the 11th International Conference on Parsing Technologies (IWPT’09), pages 129–133. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Goldberg</author>
<author>M Elhadad</author>
</authors>
<title>Easy-first dependency parsing of Modern Hebrew.</title>
<date>2010</date>
<booktitle>In Proc. of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010),</booktitle>
<pages>103--107</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9957" citStr="Goldberg and Elhadad (2010)" startWordPosition="1404" endWordPosition="1408">S&gt;,dep=&lt;depPOS&gt; Table 3: Agreement feature templates. headPOS and depPOS are the head and dependent coarse POS tags. (Carreras et al., 2006). Schiehlen and Spranger (2007) used language-specific rules to add detail to other features, such as fine-grained POS tags or lemmas. Attardi et al. (2007) modeled agreement explicitly, generating a morphological agreement feature whenever two tokens possess the same value for the same linguistic attribute. The authors note accuracy improvements of up to 0.5% for Italian and 0.8% for Catalan using a transition-based parser. A similar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agreement in noun phrases. The potential of morphological information to improve parsing performance has been documented in numerous experiments using MaltParser and with various morphological attributes as machine learning features, on several morphologically rich languages, including: Russian (Nivre et al., 2008); Swedish (Øvrelid and Nivre, 2007); Bangla, Telugu, and Hindi (Nivre, 2009); Turkish (Eryiˇgit et al., 2008); and Basque (Bengoetxea and Gojenola, 2010). These experiments, h</context>
</contexts>
<marker>Goldberg, Elhadad, 2010</marker>
<rawString>Y. Goldberg and M. Elhadad. 2010. Easy-first dependency parsing of Modern Hebrew. In Proc. of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), pages 103–107. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
</authors>
<title>Automatic Syntactic Processing of Modern Hebrew.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>Ben Gurion University.</institution>
<contexts>
<context position="17030" citStr="Goldberg, 2011" startWordPosition="2475" endWordPosition="2476">an and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of morphological attributes per token, and reference for each treebank used, ordered by average number of attributes. verted the other treebanks to the same. It includes for each token: position in the sentence; the token itself; a lemma (not present in all datasets); a coarse POS tag; a fine POS tag; a list of morphological </context>
</contexts>
<marker>Goldberg, 2011</marker>
<rawString>Yoav Goldberg. 2011. Automatic Syntactic Processing of Modern Hebrew. Ph.D. thesis, Ben Gurion University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajic</author>
<author>O Smrz</author>
<author>P Zem´anek</author>
<author>J Snaidauf</author>
<author>E Beska</author>
</authors>
<title>Prague Arabic dependency treebank: Development in data and tools.</title>
<date>2004</date>
<booktitle>In Proc. of the NEMLAR International Conference on Arabic Language Resources and Tools,</booktitle>
<pages>110--117</pages>
<marker>Hajic, Smrz, Zem´anek, Snaidauf, Beska, 2004</marker>
<rawString>J. Hajic, O. Smrz, P. Zem´anek, J. &amp;quot;Snaidauf, and E. Be&amp;quot;ska. 2004. Prague Arabic dependency treebank: Development in data and tools. In Proc. of the NEMLAR International Conference on Arabic Language Resources and Tools, pages 110–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajic</author>
</authors>
<title>Building a syntactically annotated corpus: The Prague Dependency Treebank.</title>
<date>1998</date>
<booktitle>Issues of Valency and Meaning: Studies in Honor of Jarmila Panevov´a,</booktitle>
<pages>12--19</pages>
<editor>In Eva Haji&amp;quot;cov´a, editor,</editor>
<publisher>Charles University Press.</publisher>
<marker>Hajic, 1998</marker>
<rawString>Jan Haji&amp;quot;c. 1998. Building a syntactically annotated corpus: The Prague Dependency Treebank. In Eva Haji&amp;quot;cov´a, editor, Issues of Valency and Meaning: Studies in Honor of Jarmila Panevov´a, pages 12–19. Prague Karolinum, Charles University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katri Haverinen</author>
<author>Timo Viljanen</author>
<author>Veronika Laippala</author>
<author>Samuel Kohonen</author>
<author>Filip Ginter</author>
<author>Tapio Salakoski</author>
</authors>
<title>Treebanking Finnish.</title>
<date>2010</date>
<booktitle>In Proc. of the Ninth International Workshop on Treebanks and Linguistic Theories (TLT9,</booktitle>
<volume>9</volume>
<pages>79--90</pages>
<contexts>
<context position="16621" citStr="Haverinen et al., 2010" startWordPosition="2403" endWordPosition="2406">DTB 92,176 9,000 3.3 (Vincze et al., 2010) Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639</context>
</contexts>
<marker>Haverinen, Viljanen, Laippala, Kohonen, Ginter, Salakoski, 2010</marker>
<rawString>Katri Haverinen, Timo Viljanen, Veronika Laippala, Samuel Kohonen, Filip Ginter, and Tapio Salakoski. 2010. Treebanking Finnish. In Proc. of the Ninth International Workshop on Treebanks and Linguistic Theories (TLT9, volume 9, pages 79–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hohensee</author>
</authors>
<title>It’s only morpho-logical: Modeling agreement in cross-linguistic dependency parsing. Master’s thesis,</title>
<date>2012</date>
<institution>University of Washington.</institution>
<contexts>
<context position="15849" citStr="Hohensee, 2012" startWordPosition="2272" endWordPosition="2273">ated as morphological information. This was necessary to ensure that all feature configurations performed identically on treebanks with no morphological information. Depending on the treebank, this increased or decreased the performance of the system slightly (by less than 0.5%). 3.2 Data collection and preparation We gathered a range of dependency treebanks, representing as many language families as possible (Table 5). Many of these used the CoNLL shared task treebank format, so we adopted it as well, and con2A more complete description of the system, as well as source code, can be found in (Hohensee, 2012). 318 Language ISO Treebank Num. Ref. Avg. Reference sents. size atts. Hindi-Urdu hin HUTB 3,855 2,800 3.6 (Bhatt et al., 2009) Hungarian hun Szeged DTB 92,176 9,000 3.3 (Vincze et al., 2010) Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul </context>
</contexts>
<marker>Hohensee, 2012</marker>
<rawString>M. Hohensee. 2012. It’s only morpho-logical: Modeling agreement in cross-linguistic dependency parsing. Master’s thesis, University of Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Kromann</author>
</authors>
<title>The Danish Dependency Treebank and the DTAG treebank tool.</title>
<date>2003</date>
<booktitle>In Proc. of the Second Workshop on Treebanks and Linguistic Theories (TLT</booktitle>
<pages>217--220</pages>
<contexts>
<context position="16263" citStr="Kromann, 2003" startWordPosition="2342" endWordPosition="2343">able 5). Many of these used the CoNLL shared task treebank format, so we adopted it as well, and con2A more complete description of the system, as well as source code, can be found in (Hohensee, 2012). 318 Language ISO Treebank Num. Ref. Avg. Reference sents. size atts. Hindi-Urdu hin HUTB 3,855 2,800 3.6 (Bhatt et al., 2009) Hungarian hun Szeged DTB 92,176 9,000 3.3 (Vincze et al., 2010) Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italia</context>
</contexts>
<marker>Kromann, 2003</marker>
<rawString>M.T. Kromann. 2003. The Danish Dependency Treebank and the DTAG treebank tool. In Proc. of the Second Workshop on Treebanks and Linguistic Theories (TLT 2003), pages 217–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>M A Marcinkiewicz</author>
<author>B Santorini</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="17087" citStr="Marcus et al., 1993" startWordPosition="2483" endWordPosition="2486"> 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of morphological attributes per token, and reference for each treebank used, ordered by average number of attributes. verted the other treebanks to the same. It includes for each token: position in the sentence; the token itself; a lemma (not present in all datasets); a coarse POS tag; a fine POS tag; a list of morphological features; the token’s head; and the label for the depende</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Martı</author>
<author>M Taul´e</author>
<author>L M´arquez</author>
<author>M Bertran</author>
</authors>
<title>CESS-ECE: A multilingual and multilevel annotated corpus.</title>
<date>2007</date>
<marker>Martı, Taul´e, M´arquez, Bertran, 2007</marker>
<rawString>M.A. Martı, M. Taul´e, L. M´arquez, and M. Bertran. 2007. CESS-ECE: A multilingual and multilevel annotated corpus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Marton</author>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>Improving Arabic dependency parsing with lexical and inflectional morphological features.</title>
<date>2010</date>
<booktitle>In Proc. of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010),</booktitle>
<pages>13--21</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11100" citStr="Marton et al., 2010" startWordPosition="1567" endWordPosition="1570"> al., 2008); and Basque (Bengoetxea and Gojenola, 2010). These experiments, however, did not include any higher-level features such as agreement. Goldberg and Elhadad (2009) found that using morphological features increased the accuracy of MSTParser on Hebrew only when the morphological annotations were gold-standard; automatic annotations decreased accuracy, although MaltParser showed improvement with both gold and automatic annotations. The accuracy of MaltParser on Arabic was improved by different types of morphological features depending on whether gold or automatic annotations were used (Marton et al., 2010). As far as we can tell, no language-independent approaches to utilizing morphological data thus far have taken advantage of agreement specifically. We take a linguistically informed approach, maintaining language-independence, by explicitly modeling agreement between head and dependent morphology. 3 Methodology 3.1 Modifications to parser Our approach builds on the observation that there are two kinds of information marked in morphology: symmetric, recorded on both head and depen317 Table 4: Sample sentence (Hajiˇc, 1998) and agreement features generated ID TOKEN CPOS MORPH HEAD REL Gloss 1 V</context>
</contexts>
<marker>Marton, Habash, Rambow, 2010</marker>
<rawString>Y. Marton, N. Habash, and O. Rambow. 2010. Improving Arabic dependency parsing with lexical and inflectional morphological features. In Proc. of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), pages 13–21. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Lerman</author>
<author>F Pereira</author>
</authors>
<title>Multilingual dependency analysis with a two-stage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLLX),</booktitle>
<pages>216--220</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1866" citStr="McDonald et al., 2006" startWordPosition="278" endWordPosition="281">m towards languages with certain properties (Bender, 2011). It is often taken for granted that using linguistic information necessarily makes a system languagedependent. But it is possible to design a linguistically intelligent parser without tuning it to a specific language, by modeling at a high level phenomena which appear cross-linguistically. Such a system is still language-independent; it does not require any knowledge or modeling of specific languages, but it does use linguistic knowledge to make the most of the available data. We present modifications to an existing system, MSTParser (McDonald et al., 2006), to incorporate a very simple model of morphological agreement. These modifications improve parsing performance across a variety of languages by making better use of morphological annotations. 2 Background and related work 2.1 Morphological marking of agreement Most languages show some morphological agreement via inflected noun, adjective, verb, and determiner forms, although the degree to which this happens varies. At one end of the spectrum are analytic, or “morphologically impoverished”, languages. An extreme example is Chinese, which shows no inflection at all; words do not take different</context>
<context position="5743" citStr="McDonald et al., 2006" startWordPosition="889" endWordPosition="892"> word order and high morphological complexity are the most difficult for dependency parsing (Nivre et al., 2007). Most of the participants took language-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using it to disambiguate function words (Bick, 2006) or to pick out finite verbs foreign investments grow foreign investment grow .3RD.PL .PL Table 1: Sentence in Czech (Hajiˇc, 1998) and English A sample sentence in English and Czech (Table 1) demonstrates this contrast. In Czech, the adjective and noun agree for gender, number, and case, and the noun and verb agree for person and number. In the English version, only the noun and verb agree. Agreement can be very useful for data-driven dependency parsing. A s</context>
<context position="7836" citStr="McDonald et al., 2006" startWordPosition="1222" endWordPosition="1225">es, so they often perform best on languages with more rigid word order. Making use of morphological agreement could compensate for greater variation in word order and help to bring parsing performance on flexible-word-order languages up to par with that on rigid-word-order languages. 2.2 MSTParser The CoNLL-X (Buchholz and Marsi, 2006) and CoNLL 2007 (Nivre et al., 2007) shared tasks focused on multilingual dependency parsing. Each system was trained on treebanks in a variety of languages and predicted dependency arcs and labels for POS-tagged data. The best performers in 2006 were MSTParser (McDonald et al., 2006), which we use here, and MaltParser (Nivre et al., 2006a). 316 &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;hdAtt&gt;&lt;dpAtt</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>R. McDonald, K. Lerman, and F. Pereira. 2006. Multilingual dependency analysis with a two-stage discriminative parser. In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLLX), pages 216–220. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nakagawa</author>
</authors>
<title>Multilingual dependency parsing using global features.</title>
<date>2007</date>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>952--956</pages>
<contexts>
<context position="5760" citStr="Nakagawa, 2007" startWordPosition="893" endWordPosition="894">rphological complexity are the most difficult for dependency parsing (Nivre et al., 2007). Most of the participants took language-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using it to disambiguate function words (Bick, 2006) or to pick out finite verbs foreign investments grow foreign investment grow .3RD.PL .PL Table 1: Sentence in Czech (Hajiˇc, 1998) and English A sample sentence in English and Czech (Table 1) demonstrates this contrast. In Czech, the adjective and noun agree for gender, number, and case, and the noun and verb agree for person and number. In the English version, only the noun and verb agree. Agreement can be very useful for data-driven dependency parsing. A statistical parser</context>
</contexts>
<marker>Nakagawa, 2007</marker>
<rawString>T. Nakagawa. 2007. Multilingual dependency parsing using global features. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 952– 956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>J Nilsson</author>
</authors>
<title>Maltparser: A data-driven parser-generator for dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of the Fifth International Conference on Language Resources and Evaluation (LREC</booktitle>
<volume>6</volume>
<pages>2216--2219</pages>
<contexts>
<context position="5478" citStr="Nivre et al., 2006" startWordPosition="842" endWordPosition="845">f trees desired. Projective trees are those in which every constituent (head plus all dependents) forms a complete subtree; non-projective parsing lacks this limitation. 2.3 Related work The organizers of the CoNLL 2007 shared task noted that languages with free word order and high morphological complexity are the most difficult for dependency parsing (Nivre et al., 2007). Most of the participants took language-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using it to disambiguate function words (Bick, 2006) or to pick out finite verbs foreign investments grow foreign investment grow .3RD.PL .PL Table 1: Sentence in Czech (Hajiˇc, 1998) and English A sample sentence in English and Czech (Table 1) demon</context>
<context position="7891" citStr="Nivre et al., 2006" startWordPosition="1232" endWordPosition="1235"> word order. Making use of morphological agreement could compensate for greater variation in word order and help to bring parsing performance on flexible-word-order languages up to par with that on rigid-word-order languages. 2.2 MSTParser The CoNLL-X (Buchholz and Marsi, 2006) and CoNLL 2007 (Nivre et al., 2007) shared tasks focused on multilingual dependency parsing. Each system was trained on treebanks in a variety of languages and predicted dependency arcs and labels for POS-tagged data. The best performers in 2006 were MSTParser (McDonald et al., 2006), which we use here, and MaltParser (Nivre et al., 2006a). 316 &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;hdAtt&gt;&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;&lt;hdAtt&gt;</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2006</marker>
<rawString>J. Nivre, J. Hall, and J. Nilsson. 2006a. Maltparser: A data-driven parser-generator for dependency parsing. In Proc. of the Fifth International Conference on Language Resources and Evaluation (LREC 2006), volume 6, pages 2216–2219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>J Nilsson</author>
<author>G Eryiˇgit</author>
<author>S Marinov</author>
</authors>
<title>Labeled pseudo-projective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>221--225</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Nivre, Hall, Nilsson, Eryiˇgit, Marinov, 2006</marker>
<rawString>J. Nivre, J. Hall, J. Nilsson, G. Eryiˇgit, and S. Marinov. 2006b. Labeled pseudo-projective dependency parsing with support vector machines. In Proc. of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 221–225. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S Kabler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>CoNLL</journal>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007). Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5234" citStr="Nivre et al., 2007" startWordPosition="807" endWordPosition="810">. These features are summarized in Table 2. At run time, MSTParser finds the highest-scoring parse for each sentence according to the learned feature weights. Decoding can be performed in projective or nonprojective mode, depending on the type of trees desired. Projective trees are those in which every constituent (head plus all dependents) forms a complete subtree; non-projective parsing lacks this limitation. 2.3 Related work The organizers of the CoNLL 2007 shared task noted that languages with free word order and high morphological complexity are the most difficult for dependency parsing (Nivre et al., 2007). Most of the participants took language-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using </context>
<context position="7587" citStr="Nivre et al., 2007" startWordPosition="1182" endWordPosition="1185"> found that it holds to a certain extent: the absence of agreement and/or case marking predicts rigid word order, though their presence is not particularly predictive of flexible word order. Many parsers rely on word order to establish dependencies, so they often perform best on languages with more rigid word order. Making use of morphological agreement could compensate for greater variation in word order and help to bring parsing performance on flexible-word-order languages up to par with that on rigid-word-order languages. 2.2 MSTParser The CoNLL-X (Buchholz and Marsi, 2006) and CoNLL 2007 (Nivre et al., 2007) shared tasks focused on multilingual dependency parsing. Each system was trained on treebanks in a variety of languages and predicted dependency arcs and labels for POS-tagged data. The best performers in 2006 were MSTParser (McDonald et al., 2006), which we use here, and MaltParser (Nivre et al., 2006a). 316 &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;dpAtt&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;{dpForm|dpLemma}&gt;(&lt;dir+dist&gt;) &lt;hdIdx&gt;*&lt;dpIdx&gt;=&lt;{hdForm|hdLemma}&gt;&lt;hdAtt&gt;(&lt;dir+dist&gt;) &lt;hd</context>
</contexts>
<marker>Nivre, Hall, Kabler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. Kabler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. CoNLL 2007 shared task on dependency parsing. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>I M Boguslavsky</author>
<author>L L Iomdin</author>
</authors>
<title>Parsing the SynTagRus treebank of Russian.</title>
<date>2008</date>
<booktitle>In Proc. of the 22nd International Conference on Computational Linguistics (COLING</booktitle>
<volume>1</volume>
<pages>641--648</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10382" citStr="Nivre et al., 2008" startWordPosition="1465" endWordPosition="1468">istic attribute. The authors note accuracy improvements of up to 0.5% for Italian and 0.8% for Catalan using a transition-based parser. A similar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agreement in noun phrases. The potential of morphological information to improve parsing performance has been documented in numerous experiments using MaltParser and with various morphological attributes as machine learning features, on several morphologically rich languages, including: Russian (Nivre et al., 2008); Swedish (Øvrelid and Nivre, 2007); Bangla, Telugu, and Hindi (Nivre, 2009); Turkish (Eryiˇgit et al., 2008); and Basque (Bengoetxea and Gojenola, 2010). These experiments, however, did not include any higher-level features such as agreement. Goldberg and Elhadad (2009) found that using morphological features increased the accuracy of MSTParser on Hebrew only when the morphological annotations were gold-standard; automatic annotations decreased accuracy, although MaltParser showed improvement with both gold and automatic annotations. The accuracy of MaltParser on Arabic was improved by differ</context>
</contexts>
<marker>Nivre, Boguslavsky, Iomdin, 2008</marker>
<rawString>J. Nivre, I.M. Boguslavsky, and L.L. Iomdin. 2008. Parsing the SynTagRus treebank of Russian. In Proc. of the 22nd International Conference on Computational Linguistics (COLING 2008), volume 1, pages 641–648. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
</authors>
<title>Parsing Indian languages with MaltParser.</title>
<date>2009</date>
<booktitle>In Proc. of the Seventh International Conference on Natural Language Processing (ICON 2009) NLP Tools Contest,</booktitle>
<pages>12--18</pages>
<contexts>
<context position="10458" citStr="Nivre, 2009" startWordPosition="1479" endWordPosition="1480">nd 0.8% for Catalan using a transition-based parser. A similar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agreement in noun phrases. The potential of morphological information to improve parsing performance has been documented in numerous experiments using MaltParser and with various morphological attributes as machine learning features, on several morphologically rich languages, including: Russian (Nivre et al., 2008); Swedish (Øvrelid and Nivre, 2007); Bangla, Telugu, and Hindi (Nivre, 2009); Turkish (Eryiˇgit et al., 2008); and Basque (Bengoetxea and Gojenola, 2010). These experiments, however, did not include any higher-level features such as agreement. Goldberg and Elhadad (2009) found that using morphological features increased the accuracy of MSTParser on Hebrew only when the morphological annotations were gold-standard; automatic annotations decreased accuracy, although MaltParser showed improvement with both gold and automatic annotations. The accuracy of MaltParser on Arabic was improved by different types of morphological features depending on whether gold or automatic a</context>
</contexts>
<marker>Nivre, 2009</marker>
<rawString>J. Nivre. 2009. Parsing Indian languages with MaltParser. In Proc. of the Seventh International Conference on Natural Language Processing (ICON 2009) NLP Tools Contest, pages 12–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Oflazer</author>
<author>B Say</author>
<author>D Z Hakkani-Tar</author>
<author>G Tar</author>
</authors>
<date>2003</date>
<booktitle>Building a Turkish treebank. Text, Speech, and Language Technology,</booktitle>
<pages>261--277</pages>
<contexts>
<context position="16740" citStr="Oflazer et al., 2003" startWordPosition="2423" endWordPosition="2426">00 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of morphological attributes per token</context>
</contexts>
<marker>Oflazer, Say, Hakkani-Tar, Tar, 2003</marker>
<rawString>K. Oflazer, B. Say, D.Z. Hakkani-Tar, and G. Tar. 2003. Building a Turkish treebank. Text, Speech, and Language Technology, pages 261–277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Øvrelid</author>
<author>J Nivre</author>
</authors>
<title>When word order and part-of-speech tags are not enough–Swedish dependency parsing with rich linguistic features.</title>
<date>2007</date>
<booktitle>In Proc. of the International Conference on Recent Advances in Natural Language Processing (RANLP),</booktitle>
<pages>447--451</pages>
<contexts>
<context position="10417" citStr="Øvrelid and Nivre, 2007" startWordPosition="1470" endWordPosition="1473">ote accuracy improvements of up to 0.5% for Italian and 0.8% for Catalan using a transition-based parser. A similar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agreement in noun phrases. The potential of morphological information to improve parsing performance has been documented in numerous experiments using MaltParser and with various morphological attributes as machine learning features, on several morphologically rich languages, including: Russian (Nivre et al., 2008); Swedish (Øvrelid and Nivre, 2007); Bangla, Telugu, and Hindi (Nivre, 2009); Turkish (Eryiˇgit et al., 2008); and Basque (Bengoetxea and Gojenola, 2010). These experiments, however, did not include any higher-level features such as agreement. Goldberg and Elhadad (2009) found that using morphological features increased the accuracy of MSTParser on Hebrew only when the morphological annotations were gold-standard; automatic annotations decreased accuracy, although MaltParser showed improvement with both gold and automatic annotations. The accuracy of MaltParser on Arabic was improved by different types of morphological features</context>
</contexts>
<marker>Øvrelid, Nivre, 2007</marker>
<rawString>L. Øvrelid and J. Nivre. 2007. When word order and part-of-speech tags are not enough–Swedish dependency parsing with rich linguistic features. In Proc. of the International Conference on Recent Advances in Natural Language Processing (RANLP), pages 447– 451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-of-speech tagset. Arxiv preprint ArXiv:1104.2086.</title>
<date>2011</date>
<contexts>
<context position="17926" citStr="Petrov et al. (2011)" startWordPosition="2627" endWordPosition="2630">morphological attributes per token, and reference for each treebank used, ordered by average number of attributes. verted the other treebanks to the same. It includes for each token: position in the sentence; the token itself; a lemma (not present in all datasets); a coarse POS tag; a fine POS tag; a list of morphological features; the token’s head; and the label for the dependency relation to that head.3 We retained all punctuation and other tokens in the treebanks. The POS tagsets used in the treebanks varied widely. We normalized the coarse tags to the universal twelve-tag set suggested by Petrov et al. (2011), in order to ensure that every treebank had coarse tags for use in the agreement features, and to make the features easier to interpret. It is unlikely that information was lost in this process: for treebanks with one set of tags, information was added, and for those with two, the universal tags aligned closely with the coarse tags already in the data. Two of the treebanks we used included no morphological information. We included the Penn Chinese Treebank as a representative of analytic languages.4 We also included part of the (English) Penn 3The original format also included two more fields</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2011. A universal part-of-speech tagset. Arxiv preprint ArXiv:1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loganathan Ramasamy</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
</authors>
<title>Tamil dependency parsing: Results using rule based and corpus based approaches.</title>
<date>2011</date>
<booktitle>In Proc. of the 12th International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2011),</booktitle>
<volume>1</volume>
<pages>82--95</pages>
<publisher>SpringerVerlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Ramasamy, ˇZabokrtsk´y, 2011</marker>
<rawString>Loganathan Ramasamy and Zdenˇek ˇZabokrtsk´y. 2011. Tamil dependency parsing: Results using rule based and corpus based approaches. In Proc. of the 12th International Conference on Intelligent Text Processing and Computational Linguistics (CICLING 2011), volume 1, pages 82–95, Berlin, Heidelberg. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Schiehlen</author>
<author>K Spranger</author>
</authors>
<title>Global learning of labelled dependency trees.</title>
<date>2007</date>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>1156--1160</pages>
<contexts>
<context position="9501" citStr="Schiehlen and Spranger (2007)" startWordPosition="1332" endWordPosition="1335"> the arc. Each line represents one feature. &lt;attr&gt;_agrees,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Unlabeled &lt;attr&gt;_disagrees,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; head_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; dep_&lt;attr=value&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; &lt;attr&gt;_agrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Labeled &lt;attr&gt;_disagrees&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; head_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; dep_&lt;attr=value&gt;&amp;label=&lt;label&gt;,head=&lt;headPOS&gt;,dep=&lt;depPOS&gt; Table 3: Agreement feature templates. headPOS and depPOS are the head and dependent coarse POS tags. (Carreras et al., 2006). Schiehlen and Spranger (2007) used language-specific rules to add detail to other features, such as fine-grained POS tags or lemmas. Attardi et al. (2007) modeled agreement explicitly, generating a morphological agreement feature whenever two tokens possess the same value for the same linguistic attribute. The authors note accuracy improvements of up to 0.5% for Italian and 0.8% for Catalan using a transition-based parser. A similar approach was used by Goldberg and Elhadad (2010), who improved the accuracy of their transition-based Hebrew parser by adding features for gender and number agreement in noun phrases. The pote</context>
</contexts>
<marker>Schiehlen, Spranger, 2007</marker>
<rawString>M. Schiehlen and K. Spranger. 2007. Global learning of labelled dependency trees. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 1156–1160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Siewierska</author>
</authors>
<title>Variation in major constituent order: A global and a European perspective.</title>
<date>1998</date>
<booktitle>In Anna Siewierska, editor, Constituent Order in the Languages of Europe,</booktitle>
<pages>475--551</pages>
<institution>Mouton De Gruyter.</institution>
<contexts>
<context position="6934" citStr="Siewierska (1998)" startWordPosition="1080" endWordPosition="1081">en dependency parsing. A statistical parser can learn from training data that, for example, a third-person singular noun is a likely dependent of a verb marked as third-person singular. Similarly, it can learn that a determiner showing genitive case and a noun showing dative case are often not syntactically related. It is often assumed that morphological complexity correlates with degree of variation in word order. This is because synthetic languages use inflection to mark the roles of constituents, while analytic languages generally assign these roles to specific phrase structural locations. Siewierska (1998) investigated this empirically and found that it holds to a certain extent: the absence of agreement and/or case marking predicts rigid word order, though their presence is not particularly predictive of flexible word order. Many parsers rely on word order to establish dependencies, so they often perform best on languages with more rigid word order. Making use of morphological agreement could compensate for greater variation in word order and help to bring parsing performance on flexible-word-order languages up to par with that on rigid-word-order languages. 2.2 MSTParser The CoNLL-X (Buchholz</context>
</contexts>
<marker>Siewierska, 1998</marker>
<rawString>Anna Siewierska. 1998. Variation in major constituent order: A global and a European perspective. In Anna Siewierska, editor, Constituent Order in the Languages of Europe, pages 475–551. Mouton De Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Simov</author>
<author>P Osenova</author>
<author>A Simov</author>
<author>M Kouylekov</author>
</authors>
<title>Design and implementation of the Bulgarian HPSG-based treebank.</title>
<date>2004</date>
<journal>Research on Language &amp; Computation,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="16498" citStr="Simov et al., 2004" startWordPosition="2382" endWordPosition="2385">m. Ref. Avg. Reference sents. size atts. Hindi-Urdu hin HUTB 3,855 2,800 3.6 (Bhatt et al., 2009) Hungarian hun Szeged DTB 92,176 9,000 3.3 (Vincze et al., 2010) Czech ces PDT 1.0 73,068 9,000 2.8 (Hajiˇc, 1998) Tamil tam TamilTB v0.1 600 600 2.8 (Ramasamy and ˇZabokrtsk´y, 2011) Slovene slv SDT 1,998 1,500 2.6 (Dˇzeroski et al., 2006) Danish dan DDT 5,512 5,500 2.4 (Kromann, 2003) Basque eus 3LB* 3,175 2,800 2.4 (Aduriz et al., 2003) Dutch nld Alpino 13,735 9,000 2.4 (Van der Beek et al., 2002) Latin lat LDT 3,423 2,800 2.4 (Bamman and Crane, 2006) Bulgarian bul BulTreeBank 13,221 9,000 2.1 (Simov et al., 2004) Greek (ancient) grc AGDT 21,104 9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cm</context>
</contexts>
<marker>Simov, Osenova, Simov, Kouylekov, 2004</marker>
<rawString>K. Simov, P. Osenova, A. Simov, and M. Kouylekov. 2004. Design and implementation of the Bulgarian HPSG-based treebank. Research on Language &amp; Computation, 2(4):495–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>J Henderson</author>
</authors>
<title>Fast and robust multilingual dependency parsing with a generative latent variable model.</title>
<date>2007</date>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>947--951</pages>
<contexts>
<context position="5595" citStr="Titov and Henderson, 2007" startWordPosition="862" endWordPosition="865">plete subtree; non-projective parsing lacks this limitation. 2.3 Related work The organizers of the CoNLL 2007 shared task noted that languages with free word order and high morphological complexity are the most difficult for dependency parsing (Nivre et al., 2007). Most of the participants took language-independent approaches toward leveraging this complexity into better performance: generating machine learning features based on each item in a token’s list of morphological attributes (Nivre et al., 2006b; Carreras et al., 2006); using the entire list as an atomic feature (Chang et al., 2006; Titov and Henderson, 2007); or generating features based on each pair of attributes in the cross-product of the lists of a potential head and dependent (McDonald et al., 2006; Nakagawa, 2007). Language-specific uses of morphological information have included using it to disambiguate function words (Bick, 2006) or to pick out finite verbs foreign investments grow foreign investment grow .3RD.PL .PL Table 1: Sentence in Czech (Hajiˇc, 1998) and English A sample sentence in English and Czech (Table 1) demonstrates this contrast. In Czech, the adjective and noun agree for gender, number, and case, and the noun and verb agr</context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>I. Titov and J. Henderson. 2007. Fast and robust multilingual dependency parsing with a generative latent variable model. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 947–951.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Van der Beek</author>
<author>G Bouma</author>
<author>R Malouf</author>
<author>G Van Noord</author>
</authors>
<title>The Alpino dependency treebank.</title>
<date>2002</date>
<journal>Language and Computers,</journal>
<volume>45</volume>
<issue>1</issue>
<marker>Van der Beek, Bouma, Malouf, Van Noord, 2002</marker>
<rawString>L. Van der Beek, G. Bouma, R. Malouf, and G. Van Noord. 2002. The Alpino dependency treebank. Language and Computers, 45(1):8–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vincze</author>
<author>D Szauter</author>
<author>A Alm´asi</author>
<author>G M´ora</author>
<author>Z Alexin</author>
<author>J Csirik</author>
</authors>
<title>Hungarian dependency treebank.</title>
<date>2010</date>
<booktitle>In Proc. of the Seventh Conference on Language Resources and Evaluation (LREC</booktitle>
<marker>Vincze, Szauter, Alm´asi, M´ora, Alexin, Csirik, 2010</marker>
<rawString>V. Vincze, D. Szauter, A. Alm´asi, G. M´ora, Z. Alexin, and J. Csirik. 2010. Hungarian dependency treebank. In Proc. of the Seventh Conference on Language Resources and Evaluation (LREC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
<author>F Xia</author>
<author>F D Chiou</author>
<author>M Palmer</author>
</authors>
<title>The Penn Chinese Treebank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="17148" citStr="Xue et al., 2005" startWordPosition="2494" endWordPosition="2497">9,000 2.1 (Bamman et al., 2009) Finnish fin Turku 4,307 2,800 2.0 (Haverinen et al., 2010) German deu NEGRA 3,427 2,800 2.0 (Brants et al., 1999) Turkish tur METU-Sabanci 5,620 5,500 1.6 (Oflazer et al., 2003) Catalan cat CESS-ECE* 3,512 2,800 1.5 (Martı et al., 2007) Arabic ara PADT 1.0 2,367 2,300 1.2 (Hajic et al., 2004) Italian ita TUT 2,858 2,800 1.1 (Bosco et al., 2000) Portuguese por Floresta 9,359 9,000 1.0 (Afonso et al., 2002) Hebrew (modern) heb DepTB 6,214 5,500 0.9 (Goldberg, 2011) English eng Penn* 49,208 9,000 0.4 (Marcus et al., 1993) Chinese cmn Penn Chinese 28,035 9,000 0.0 (Xue et al., 2005) *Acquired as part of NLTK (Bird et al., 2009) Table 5: Language, ISO 639-2 code, treebank name, total number of sentences, reference size, average number of morphological attributes per token, and reference for each treebank used, ordered by average number of attributes. verted the other treebanks to the same. It includes for each token: position in the sentence; the token itself; a lemma (not present in all datasets); a coarse POS tag; a fine POS tag; a list of morphological features; the token’s head; and the label for the dependency relation to that head.3 We retained all punctuation and o</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>N. Xue, F. Xia, F.D. Chiou, and M. Palmer. 2005. The Penn Chinese Treebank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>