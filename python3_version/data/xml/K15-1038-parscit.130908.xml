<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013351">
<title confidence="0.990306">
Reading behavior predicts syntactic categories
</title>
<author confidence="0.994706">
Maria Barrett and Anders Søgaard
</author>
<affiliation confidence="0.997746">
University of Copenhagen
</affiliation>
<address confidence="0.91616">
Njalsgade 140
DK-2300 Copenhagen S
</address>
<email confidence="0.998463">
{dtq912,soegaard}@hum.ku.dk
</email>
<sectionHeader confidence="0.993873" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999882105263158">
It is well-known that readers are less likely
to fixate their gaze on closed class syn-
tactic categories such as prepositions and
pronouns. This paper investigates to what
extent the syntactic category of a word in
context can be predicted from gaze fea-
tures obtained using eye-tracking equip-
ment. If syntax can be reliably predicted
from eye movements of readers, it can
speed up linguistic annotation substan-
tially, since reading is considerably faster
than doing linguistic annotation by hand.
Our results show that gaze features do dis-
criminate between most pairs of syntactic
categories, and we show how we can use
this to annotate words with part of speech
across domains, when tag dictionaries en-
able us to narrow down the set of potential
categories.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999763162162162">
Eye movements during reading is a well-
established proxy for cognitive processing, and it
is well-known that readers are more likely to fixate
on words from open syntactic categories (verbs,
nouns, adjectives) than on closed category items
like prepositions and conjunctions (Rayner, 1998;
Nilsson and Nivre, 2009). Generally, readers seem
to be most likely to fixate and re-fixate on nouns
(Furtner et al., 2009). If reading behavior is af-
fected by syntactic category, maybe reading be-
havior can, conversely, also tell us about the syn-
tax of words in context.
This paper investigates to what extent gaze data
can be used to predict syntactic categories. We
show that gaze data can effectively be used to dis-
criminate between a wide range of part of speech
(POS) pairs, and gaze data can therefore be used to
significantly improve type-constrained POS tag-
gers. This is potentially useful, since eye-tracking
data becomes more and more readily available
with the emergence of eye trackers in mainstream
consumer products (San Agustin et al., 2010).
With the development of robust eye-tracking in
laptops, it is easy to imagine digital text providers
storing gaze data, which could then be used to im-
prove automated analysis of their publications.
Contributions We are, to the best of our knowl-
edge, the first to study reading behavior of syntac-
tically annotated, natural text across domains, and
how gaze correlates with a complete set of syntac-
tic categories. We use logistic regression to show
that gaze features discriminate between POS pairs,
even across domains. We then show how gaze fea-
tures can improve a cross-domain supervised POS
tagger. We show that gaze-based predictions are
robust, not only across domains, but also across
subjects.
</bodyText>
<sectionHeader confidence="0.997081" genericHeader="introduction">
2 Experiment
</sectionHeader>
<bodyText confidence="0.999595083333333">
In our experiment, 10 subjects read syntactically
annotated sentences from five domains.
Data The data consists of 250 sentences: 50
sentences (min. 3 tokens, max. 120 characters),
randomly sampled from each of five different,
manually annotated corpora: Wall Street Jour-
nal articles (WSJ), Wall Street Journal headlines
(HDL), emails (MAI), weblogs (WBL), and Twit-
ter (TWI). WSJ and HDL syntactically annotated
sentences come from the OntoNotes 4.0 release of
the English Penn Treebank.1 The MAI and WBL
sections come from the English Web Treebank.2
</bodyText>
<footnote confidence="0.562639">
1catalog.ldc.upenn.edu/LDC2011T03
2catalog.ldc.upenn.edu/LDC2012T13
</footnote>
<page confidence="0.975802">
345
</page>
<note confidence="0.8968835">
Proceedings of the 19th Conference on Computational Language Learning, pages 345–349,
Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.983473">
Figure 1: Fixation probability boxplots across five
domains
</figureCaption>
<bodyText confidence="0.999939873417722">
The TWI data comes from the work of Foster et
al. (2011). We mapped the gold labels to the 12
Universal POS (Petrov et al., 2011), but discarded
the category X due to data sparsity.
Experimental design The 250 items were read
by all 10 participants, but participants read the
items in one of five randomized orders. Neither
the source domain for the sentence, nor the POS
tags were revealed to the participant at any time.
One sentence was presented at a time in black on a
light gray background. Font face was Verdana and
font size was 25 pixels. Sentences were centered
vertically, and all sentences could fit into one line.
All sentences were preceded by a fixation cross.
The experiment was self-paced. To switch to a
new sentence and to ensure that the sentence was
actually processed by the participant, participants
rated the immediate interest towards the sentence
on a scale from 1-6 by pressing the corresponding
number on the numeric keypad. Participants were
instructed to read and continue to the next sentence
as quickly as possible. The actual experiment was
preceded by 25 practice sentences to familiarize
the participant with the experimental setup.
Our apparatus was a Tobii X120 eye tracker
with a 15” monitor. Sampling rate was 120 Hz
binocular. Participants were seated on a chair ap-
proximately 65 cm from the display. We recruited
10 participants (7 male, mean age 31.30 ±4.74))
from campus. All were native English speakers.
Their vision was normal or corrected to normal,
and none were diagnosed with dyslexia. All were
skilled readers. Minimum educational level was
an ongoing MA. Each session lasted around 40
minutes. One participant had no fixations on a few
sentences. We believe that erroneous key strokes
caused the participant to skip a few sentences.
Features There are many different features for
exploring cognitive load during reading (Rayner,
1998). We extracted a broad selection of cognitive
effort features from the raw eye-tracking data in
order to determine which are more fit for the task.
The features are inspired by Saloj¨arvi et al. (2003),
who used a similarly exploratory approach. We
wanted to cover both oculomotor features, such as
fixations on previous and subsequent words, and
measures relating to early (e.g. first fixation du-
ration) and late processing (e.g. regression desti-
nations / departure points and total fixation time).
We also included reading speed and reading depth
features, such as fixation probability and total fix-
ation time per word. In total, we have 32 gaze
features, where some are highly correlated (such
as number of fixations on a word and total fixation
time per sentence).
Dundee Corpus The main weakness of the exper-
iment is the small dataset. As future work, we
plan to replicate the experiment with a $99 eye
tracker for subjects to use at home. This will
make it easy to collect thousands of sentences,
leading to more robust gaze-based POS models.
Here, instead, we include an experiment with the
Dundee corpus (Kennedy and Pynte, 2005). The
Dundee corpus is a widely used dataset in re-
search on reading and consists of gaze data for
10 subjects reading 20 newswire articles (about
51,000 words). We extracted the same word-based
features as above, except probability for 1st and
2nd fixation, and sentence-level features (in the
Dundee corpus, subjects are exposed to multiple
sentences per screen window), and used them as
features in our POS tagging experiments (§3).
Learning experiments In our experiments, we
used type-constrained logistic regression with
L2-regularization and type-constrained (averaged)
structured perceptron (Collins, 2002; T¨ackstr¨om
et al., 2013). In all experiments, unless otherwise
stated, we trained our models on four domains and
evaluated on the fifth to avoid over-fitting to the
</bodyText>
<figure confidence="0.999488073684211">
.
ADJ
ADP
ADV
CONJ
DET
NOUN
NUM
PRON
PRT
VERB
TWI Fixation probability. n = 610
.
ADJ
ADP
ADV
CONJ
DET
NOUN
NUM
PRON
PRT
VERB
MAI Fixation probability. n = 575
.
ADJ
ADP
ADV
CONJ
DET
NOUN
NUM
PRON
PRT
VERB
.
ADJ
ADP
ADV
CONJ
DET
NOUN
NUM
PRON
PRT
VERB
WBL Fixation probability. n = 716
1.0
0.8
0.6
0.4
0.2
0.0
probability
probability
HDL Fixation probability. n = 461
1.0
WSJ Fixation probability. n = 858
1.0
0.8
0.8
0.6
0.6
0.4
0.4
probability
0.2
0.2
0.0
0.0
probability
0.8
0.6
0.4
0.2
0.0
1.0
probability
0.8
0.6
0.4
0.2
0.0
1.0
.
ADJ
ADP
ADV
CONJ
DET
NOUN
NUM
PRON
PRT
VERB
</figure>
<page confidence="0.858907">
346
</page>
<figureCaption confidence="0.9694395">
Figure 3: Error reduction of logistic regression
over a majority baseline. All domains
</figureCaption>
<bodyText confidence="0.99649434">
fixation probabilities across the 11 parts of speech.
While the overall pattern is similar across the five
domains (open category items are more likely to
be fixated), we see domain differences. For ex-
ample, pronouns are more likely to be fixated in
headlines. The explanation could lie in the dif-
ferent distributions of function words and content
words. It is established and unchallenged that
function words are fixated on about 35% of the
time and content words are fixated on about 85%
of the time (Rayner and Duffy, 1988). In our data,
these numbers vary among the domains according
to frequency of that word class, see Figure 2. Fig-
ure 2a shows that there is a strong linear correla-
tion between content word frequency and content
word fixation probability among the different do-
mains: Pearson’s p = 0.909. From Figure 2b,
there is a negative correlation between function
word frequency and function word fixation proba-
bility: Pearson’s p = −0.702.
Predictive gaze features To investigate which
gaze features were more predictive of part of
speech, we used stability selection (Meinshausen
and B¨uhlmann, 2010) with logistic regression
classification on all binary POS classifications.
Fixation probability was the most informative fea-
ture, but also whether the words around the word
is fixated is important along with number of fixa-
tions. In our binary discrimination and POS tag-
ging experiments, using L2-regularization or av-
eraging with all features was superior (on Twitter
data) to using stability selection for feature selec-
tion. We also asked a psycholinguist to select a
small set of relatively independent gaze features fit
for the task (first fixation duration, fixation proba-
bility and re-read probability), but again, using all
features with L2-regularization led to better per-
formance on the Twitter data.
Binary discrimination First, we trained L2-
regularized logistic regression models to discrim-
inate between all pairs of POS tags only using
gaze features. In other words, for example we
selected all words annotated as NOUN or VERB,
and trained a logistic regression model to discrim-
inate between the two in a five-fold cross valida-
tion setup. We report error reduction ai —baseline
baseline
in Figure 3.
POS tagging We also tried evaluating our gaze
features directly in a supervised POS tagger.4 We
</bodyText>
<footnote confidence="0.957972">
4https://github.com/coastalcph/
rungsted
</footnote>
<figure confidence="0.987382855072464">
100
89
92 94 94 85 61 80 94 76 72
27 8 52 22 -11 -5 22 15 -4
10 -1 65 26 36 10 -3 4
32 5 56 37 2 16
28
32 22 49 26
4 4
19 5 67 42
50
0 0 5
2
2
1 13
0 -2
7
.
DET
CONJ
PRON
ADP
PRT
NUM
ADV
ADJ
VERB
NOUN
90
80
70
60
50
40
30
20
10
0
Rank Feature % of votes
Fixation prob
Previous word fixated binary
Next word fixated binary
nFixations
First fixation duration on every word
Previous fixation duration
Mean fixation duration per word
Re-read prob
Next fixation duration
Total fixation duration per word
19.0
13.7
13.2
12.2
9.1
7.0
6.6
5.7
2.0
2.0
0
1
2
3
4
5
6
7
8
9
</figure>
<figureCaption confidence="0.320971666666667">
Table 1: 10 most used features by stability selec-
tion from logistic regression classification of all
POS pairs on all domains, 5-fold cross validation.
</figureCaption>
<figure confidence="0.996372071428571">
0.50 0.55 0.60 0.65
Frequency
(a) Content words
0.15 0.20 0.250.30
Frequency
(b) Function words
0.78 HDL
HDL
0.50
MAI
TWI
WBL
WSJ
MAI
TWI
WBL
WSJ
0.76
Fix. prob.
Fix. prob.
0.48
0.74
0.46
0.72
0.70
0.44
0.68
0.42
</figure>
<figureCaption confidence="0.6892435">
Figure 2: Scatter plot of frequency and fixation
probability for content words (NOUN, VERB,
ADJ, NUM) and function words (PRON, CONJ,
ADP, DET, PRT)
</figureCaption>
<bodyText confidence="0.894421">
characteristics of a specific domain. Our tag dic-
tionary is from Wiktionary3 and covers 95% of all
tokens.
</bodyText>
<sectionHeader confidence="0.995478" genericHeader="background">
3 Results
</sectionHeader>
<bodyText confidence="0.994098666666667">
Domain differences Our first observation is that
the gaze characteristics differ slightly across do-
mains, but more across POS. Figure 1 presents the
</bodyText>
<figure confidence="0.801918333333333">
3https://code.google.com/p/
wikily-supervised-pos-tagger/downloads/
list
</figure>
<page confidence="0.976971">
347
</page>
<table confidence="0.999044857142857">
SP +GAZE +DGAZE +FREQLEN +DGAZE+FREQLEN
HDL 0.807 0.822 0.822 0.826 0.843
MAI 0.791 0.831 0.834 0.795 0.831
TWI 0.771 0.787 0.800 0.772 0.793
WBL 0.836 0.854 0.858 0.850 0.861
WSJ 0.831 0.837 0.838 0.831 0.859
Macro-av 0.807 0.826 0.830 0.815 0.837
</table>
<tableCaption confidence="0.9826655">
Table 2: POS tagging results on different test sets using 200 out-of-domain sentences for training.
DGAZE is using gaze features from Dundee. Best result for each row in bold face
</tableCaption>
<bodyText confidence="0.997096578947368">
trained a type-constrained (averaged) perceptron
model with drop-out and a standard feature model
(from Owoputi et al. (2013)) augmented with the
above gaze features. The POS tagger was trained
on a very small seed of data (200 sentences), doing
20 passes over the data, and evaluated on out-of-
domain test data; training on four domains, testing
on one. For the gaze features, instead of using to-
ken gaze features, we first built a lexicon with av-
erage word type statistics from the training data.
We normalize the gaze matrix by dividing with
its standard deviation. This is the normalizer in
Turian et al. (2010) with σ = 1.0. We condition
on the gaze features of the current word, only. We
compare performance using gaze features to us-
ing only word frequency, estimating from the (un-
labeled) English Web Treebank corpus, and word
length (FREQLEN).
The first three columns in Table 2 show, that
gaze features help POS tagging, at least when
trained on very small seeds of data. Error reduc-
tion using gaze features from the Dundee corpus
(DGAZE) is 12%. We know that gaze features cor-
relate with word frequency and word length, but
using these features directly leads to much smaller
performance gains. Concatenating the two fea-
tures sets leads to the best performance, with an
error reduction of 16%.
In follow-up experiments, we observe that aver-
aging over 10 subjects when collecting gaze fea-
tures does not seem as important as we expected.
Tagging accuracies on raw (non-averaged) data are
only about 1% lower. Finally, we also tried run-
ning logistic regression experiments across sub-
jects rather than domains. Here, tagging accura-
cies were again comparable to our set-up, suggest-
ing that gaze features are also robust across sub-
jects.
</bodyText>
<sectionHeader confidence="0.999969" genericHeader="related work">
4 Related work
</sectionHeader>
<bodyText confidence="0.999660538461538">
Matthies and Søgaard (2013) present results that
suggest that individual variation among (academ-
ically trained) subjects’ reading behavior was not
a greater source of error than variation within sub-
jects, showing that it is possible to predict fixations
across readers. Our work relates to such work,
studying the robustness of reading models across
domains and readers, but it also relates in spirit to
research on using weak supervision in NLP, e.g.,
work on using HTML markup to improve depen-
dency parsers (Spitkovsky, 2013) or using click-
through data to improve POS taggers (Ganchev et
al., 2012).
</bodyText>
<sectionHeader confidence="0.999483" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999715">
We have shown that it is possible to use gaze
features to discriminate between many POS pairs
across domains, even with only a small dataset and
a small set of subjects. We also showed that gaze
features can improve the performance of a POS
tagger trained on small seeds of data.
</bodyText>
<sectionHeader confidence="0.999274" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999882533333333">
Michael Collins. 2002. Discriminative training meth-
ods for Hidden Markov Models. In EMNLP.
Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,
Josef Le Roux, Joakim Nivre, Deirde Hogan, and
Josef van Genabith. 2011. From news to comments:
Resources and benchmarks for parsing the language
of Web 2.0. In IJCNLP.
Marco R Furtner, John F Rauthmann, and Pierre
Sachse. 2009. Nomen est omen: Investigating the
dominance of nouns in word comprehension with
eye movement analyses. Advances in Cognitive Psy-
chology, 5:91.
Kuzman Ganchev, Keith Hall, Ryan McDonald, and
Slav Petrov. 2012. Using search-logs to improve
query tagging. In ACL.
</reference>
<page confidence="0.982109">
348
</page>
<reference confidence="0.99981182">
Alan Kennedy and Jo¨el Pynte. 2005. Parafoveal-on-
foveal effects in normal reading. Vision research,
45(2):153–168.
Franz Matthies and Anders Søgaard. 2013. With
blinkers on: Robust prediction of eye movements
across readers. In EMNLP, Seattle, Washington,
USA.
Nicolai Meinshausen and Peter B¨uhlmann. 2010.
Stability selection. Journal of the Royal Statis-
tical Society: Series B (Statistical Methodology),
72(4):417–473.
Matthias Nilsson and Joakim Nivre. 2009. Learning
where to look: Modeling eye movements in reading.
In CoNLL.
Olutobi Owoputi, Brendan O’Connor, Chris Dyer,
Kevin Gimpel, Nathan Schneider, and Noah A
Smith. 2013. Improved part-of-speech tagging for
online conversational text with word clusters. In
NAACL.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011.
A universal part-of-speech tagset. arXiv preprint
arXiv:1104.2086.
K.; Rayner and S. A. Duffy. 1988. On-line compre-
hension processes and eye movements in reading.
In G. E. MacKinnon M. Daneman and T. G. Waller,
editors, Reading research: Advances in theory and
practice, pages 13–66. Academic Press, New York.
Keith Rayner. 1998. Eye movements in reading and
information processing: 20 years of research. Psy-
chological bulletin, 124(3):372.
Jarkko Saloj¨arvi, Ilpo Kojo, Jaana Simola, and Samuel
Kaski. 2003. Can relevance be inferred from eye
movements in information retrieval. In Proceedings
of WSOM, volume 3, pages 261–266.
Javier San Agustin, Henrik Skovsgaard, Emilie Mol-
lenbach, Maria Barret, Martin Tall, Dan Witzner
Hansen, and John Paulin Hansen. 2010. Evalua-
tion of a low-cost open-source gaze tracker. In Pro-
ceedings of the 2010 Symposium on Eye-Tracking
Research &amp; Applications, pages 77–80. ACM.
Valentin Ilyich Spitkovsky. 2013. Grammar Induction
and Parsing with Dependency-and-Boundary Mod-
els. Ph.D. thesis, STANFORD UNIVERSITY.
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013. Token and
type constraints for cross-lingual part-of-speech tag-
ging. TACL, 1:1–12.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In ACL.
</reference>
<page confidence="0.999255">
349
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.587329">
<title confidence="0.998885">Reading behavior predicts syntactic categories</title>
<author confidence="0.999067">Maria Barrett</author>
<author confidence="0.999067">Anders</author>
<affiliation confidence="0.8210375">University of Njalsgade</affiliation>
<address confidence="0.774585">DK-2300 Copenhagen</address>
<abstract confidence="0.9982183">It is well-known that readers are less likely to fixate their gaze on closed class syntactic categories such as prepositions and pronouns. This paper investigates to what extent the syntactic category of a word in context can be predicted from gaze features obtained using eye-tracking equipment. If syntax can be reliably predicted from eye movements of readers, it can speed up linguistic annotation substantially, since reading is considerably faster than doing linguistic annotation by hand. Our results show that gaze features do discriminate between most pairs of syntactic categories, and we show how we can use this to annotate words with part of speech across domains, when tag dictionaries enable us to narrow down the set of potential categories.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for Hidden Markov Models.</title>
<date>2002</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="7196" citStr="Collins, 2002" startWordPosition="1135" endWordPosition="1136">). The Dundee corpus is a widely used dataset in research on reading and consists of gaze data for 10 subjects reading 20 newswire articles (about 51,000 words). We extracted the same word-based features as above, except probability for 1st and 2nd fixation, and sentence-level features (in the Dundee corpus, subjects are exposed to multiple sentences per screen window), and used them as features in our POS tagging experiments (§3). Learning experiments In our experiments, we used type-constrained logistic regression with L2-regularization and type-constrained (averaged) structured perceptron (Collins, 2002; T¨ackstr¨om et al., 2013). In all experiments, unless otherwise stated, we trained our models on four domains and evaluated on the fifth to avoid over-fitting to the . ADJ ADP ADV CONJ DET NOUN NUM PRON PRT VERB TWI Fixation probability. n = 610 . ADJ ADP ADV CONJ DET NOUN NUM PRON PRT VERB MAI Fixation probability. n = 575 . ADJ ADP ADV CONJ DET NOUN NUM PRON PRT VERB . ADJ ADP ADV CONJ DET NOUN NUM PRON PRT VERB WBL Fixation probability. n = 716 1.0 0.8 0.6 0.4 0.2 0.0 probability probability HDL Fixation probability. n = 461 1.0 WSJ Fixation probability. n = 858 1.0 0.8 0.8 0.6 0.6 0.4 0.</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for Hidden Markov Models. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Foster</author>
<author>Ozlem Cetinoglu</author>
<author>Joachim Wagner</author>
<author>Josef Le Roux</author>
<author>Joakim Nivre</author>
<author>Deirde Hogan</author>
<author>Josef van Genabith</author>
</authors>
<title>From news to comments: Resources and benchmarks for parsing the language of Web 2.0.</title>
<date>2011</date>
<booktitle>In IJCNLP.</booktitle>
<marker>Foster, Cetinoglu, Wagner, Le Roux, Nivre, Hogan, van Genabith, 2011</marker>
<rawString>Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner, Josef Le Roux, Joakim Nivre, Deirde Hogan, and Josef van Genabith. 2011. From news to comments: Resources and benchmarks for parsing the language of Web 2.0. In IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco R Furtner</author>
<author>John F Rauthmann</author>
<author>Pierre Sachse</author>
</authors>
<title>Nomen est omen: Investigating the dominance of nouns in word comprehension with eye movement analyses.</title>
<date>2009</date>
<booktitle>Advances in Cognitive Psychology,</booktitle>
<pages>5--91</pages>
<contexts>
<context position="1362" citStr="Furtner et al., 2009" startWordPosition="207" endWordPosition="210">rs of syntactic categories, and we show how we can use this to annotate words with part of speech across domains, when tag dictionaries enable us to narrow down the set of potential categories. 1 Introduction Eye movements during reading is a wellestablished proxy for cognitive processing, and it is well-known that readers are more likely to fixate on words from open syntactic categories (verbs, nouns, adjectives) than on closed category items like prepositions and conjunctions (Rayner, 1998; Nilsson and Nivre, 2009). Generally, readers seem to be most likely to fixate and re-fixate on nouns (Furtner et al., 2009). If reading behavior is affected by syntactic category, maybe reading behavior can, conversely, also tell us about the syntax of words in context. This paper investigates to what extent gaze data can be used to predict syntactic categories. We show that gaze data can effectively be used to discriminate between a wide range of part of speech (POS) pairs, and gaze data can therefore be used to significantly improve type-constrained POS taggers. This is potentially useful, since eye-tracking data becomes more and more readily available with the emergence of eye trackers in mainstream consumer pr</context>
</contexts>
<marker>Furtner, Rauthmann, Sachse, 2009</marker>
<rawString>Marco R Furtner, John F Rauthmann, and Pierre Sachse. 2009. Nomen est omen: Investigating the dominance of nouns in word comprehension with eye movement analyses. Advances in Cognitive Psychology, 5:91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Keith Hall</author>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
</authors>
<title>Using search-logs to improve query tagging.</title>
<date>2012</date>
<booktitle>In ACL.</booktitle>
<marker>Ganchev, Hall, McDonald, Petrov, 2012</marker>
<rawString>Kuzman Ganchev, Keith Hall, Ryan McDonald, and Slav Petrov. 2012. Using search-logs to improve query tagging. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Kennedy</author>
<author>Jo¨el Pynte</author>
</authors>
<title>Parafoveal-onfoveal effects in normal reading.</title>
<date>2005</date>
<booktitle>Vision research,</booktitle>
<pages>45--2</pages>
<marker>Kennedy, Jo¨el Pynte, 2005</marker>
<rawString>Alan Kennedy and Jo¨el Pynte. 2005. Parafoveal-onfoveal effects in normal reading. Vision research, 45(2):153–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Matthies</author>
<author>Anders Søgaard</author>
</authors>
<title>With blinkers on: Robust prediction of eye movements across readers. In EMNLP,</title>
<date>2013</date>
<location>Seattle, Washington, USA.</location>
<contexts>
<context position="14032" citStr="Matthies and Søgaard (2013)" startWordPosition="2313" endWordPosition="2316">rectly leads to much smaller performance gains. Concatenating the two features sets leads to the best performance, with an error reduction of 16%. In follow-up experiments, we observe that averaging over 10 subjects when collecting gaze features does not seem as important as we expected. Tagging accuracies on raw (non-averaged) data are only about 1% lower. Finally, we also tried running logistic regression experiments across subjects rather than domains. Here, tagging accuracies were again comparable to our set-up, suggesting that gaze features are also robust across subjects. 4 Related work Matthies and Søgaard (2013) present results that suggest that individual variation among (academically trained) subjects’ reading behavior was not a greater source of error than variation within subjects, showing that it is possible to predict fixations across readers. Our work relates to such work, studying the robustness of reading models across domains and readers, but it also relates in spirit to research on using weak supervision in NLP, e.g., work on using HTML markup to improve dependency parsers (Spitkovsky, 2013) or using clickthrough data to improve POS taggers (Ganchev et al., 2012). 5 Conclusions We have sho</context>
</contexts>
<marker>Matthies, Søgaard, 2013</marker>
<rawString>Franz Matthies and Anders Søgaard. 2013. With blinkers on: Robust prediction of eye movements across readers. In EMNLP, Seattle, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolai Meinshausen</author>
<author>Peter B¨uhlmann</author>
</authors>
<title>Stability selection.</title>
<date>2010</date>
<journal>Journal of the Royal Statistical Society: Series B (Statistical Methodology),</journal>
<volume>72</volume>
<issue>4</issue>
<marker>Meinshausen, B¨uhlmann, 2010</marker>
<rawString>Nicolai Meinshausen and Peter B¨uhlmann. 2010. Stability selection. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 72(4):417–473.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Nilsson</author>
<author>Joakim Nivre</author>
</authors>
<title>Learning where to look: Modeling eye movements in reading.</title>
<date>2009</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="1263" citStr="Nilsson and Nivre, 2009" startWordPosition="190" endWordPosition="193">ng linguistic annotation by hand. Our results show that gaze features do discriminate between most pairs of syntactic categories, and we show how we can use this to annotate words with part of speech across domains, when tag dictionaries enable us to narrow down the set of potential categories. 1 Introduction Eye movements during reading is a wellestablished proxy for cognitive processing, and it is well-known that readers are more likely to fixate on words from open syntactic categories (verbs, nouns, adjectives) than on closed category items like prepositions and conjunctions (Rayner, 1998; Nilsson and Nivre, 2009). Generally, readers seem to be most likely to fixate and re-fixate on nouns (Furtner et al., 2009). If reading behavior is affected by syntactic category, maybe reading behavior can, conversely, also tell us about the syntax of words in context. This paper investigates to what extent gaze data can be used to predict syntactic categories. We show that gaze data can effectively be used to discriminate between a wide range of part of speech (POS) pairs, and gaze data can therefore be used to significantly improve type-constrained POS taggers. This is potentially useful, since eye-tracking data b</context>
</contexts>
<marker>Nilsson, Nivre, 2009</marker>
<rawString>Matthias Nilsson and Joakim Nivre. 2009. Learning where to look: Modeling eye movements in reading. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olutobi Owoputi</author>
<author>Brendan O’Connor</author>
<author>Chris Dyer</author>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Improved part-of-speech tagging for online conversational text with word clusters.</title>
<date>2013</date>
<booktitle>In NAACL.</booktitle>
<marker>Owoputi, O’Connor, Dyer, Gimpel, Schneider, Smith, 2013</marker>
<rawString>Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, Nathan Schneider, and Noah A Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset. arXiv preprint arXiv:1104.2086.</title>
<date>2011</date>
<contexts>
<context position="3690" citStr="Petrov et al., 2011" startWordPosition="569" endWordPosition="572">Twitter (TWI). WSJ and HDL syntactically annotated sentences come from the OntoNotes 4.0 release of the English Penn Treebank.1 The MAI and WBL sections come from the English Web Treebank.2 1catalog.ldc.upenn.edu/LDC2011T03 2catalog.ldc.upenn.edu/LDC2012T13 345 Proceedings of the 19th Conference on Computational Language Learning, pages 345–349, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics Figure 1: Fixation probability boxplots across five domains The TWI data comes from the work of Foster et al. (2011). We mapped the gold labels to the 12 Universal POS (Petrov et al., 2011), but discarded the category X due to data sparsity. Experimental design The 250 items were read by all 10 participants, but participants read the items in one of five randomized orders. Neither the source domain for the sentence, nor the POS tags were revealed to the participant at any time. One sentence was presented at a time in black on a light gray background. Font face was Verdana and font size was 25 pixels. Sentences were centered vertically, and all sentences could fit into one line. All sentences were preceded by a fixation cross. The experiment was self-paced. To switch to a new sen</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A universal part-of-speech tagset. arXiv preprint arXiv:1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Rayner</author>
<author>S A Duffy</author>
</authors>
<title>On-line comprehension processes and eye movements in reading.</title>
<date>1988</date>
<booktitle>Reading research: Advances in theory and practice,</booktitle>
<pages>13--66</pages>
<editor>In G. E. MacKinnon M. Daneman and T. G. Waller, editors,</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="8561" citStr="Rayner and Duffy, 1988" startWordPosition="1383" endWordPosition="1386"> VERB 346 Figure 3: Error reduction of logistic regression over a majority baseline. All domains fixation probabilities across the 11 parts of speech. While the overall pattern is similar across the five domains (open category items are more likely to be fixated), we see domain differences. For example, pronouns are more likely to be fixated in headlines. The explanation could lie in the different distributions of function words and content words. It is established and unchallenged that function words are fixated on about 35% of the time and content words are fixated on about 85% of the time (Rayner and Duffy, 1988). In our data, these numbers vary among the domains according to frequency of that word class, see Figure 2. Figure 2a shows that there is a strong linear correlation between content word frequency and content word fixation probability among the different domains: Pearson’s p = 0.909. From Figure 2b, there is a negative correlation between function word frequency and function word fixation probability: Pearson’s p = −0.702. Predictive gaze features To investigate which gaze features were more predictive of part of speech, we used stability selection (Meinshausen and B¨uhlmann, 2010) with logis</context>
</contexts>
<marker>Rayner, Duffy, 1988</marker>
<rawString>K.; Rayner and S. A. Duffy. 1988. On-line comprehension processes and eye movements in reading. In G. E. MacKinnon M. Daneman and T. G. Waller, editors, Reading research: Advances in theory and practice, pages 13–66. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Rayner</author>
</authors>
<title>Eye movements in reading and information processing: 20 years of research.</title>
<date>1998</date>
<journal>Psychological bulletin,</journal>
<pages>124--3</pages>
<contexts>
<context position="1237" citStr="Rayner, 1998" startWordPosition="188" endWordPosition="189">aster than doing linguistic annotation by hand. Our results show that gaze features do discriminate between most pairs of syntactic categories, and we show how we can use this to annotate words with part of speech across domains, when tag dictionaries enable us to narrow down the set of potential categories. 1 Introduction Eye movements during reading is a wellestablished proxy for cognitive processing, and it is well-known that readers are more likely to fixate on words from open syntactic categories (verbs, nouns, adjectives) than on closed category items like prepositions and conjunctions (Rayner, 1998; Nilsson and Nivre, 2009). Generally, readers seem to be most likely to fixate and re-fixate on nouns (Furtner et al., 2009). If reading behavior is affected by syntactic category, maybe reading behavior can, conversely, also tell us about the syntax of words in context. This paper investigates to what extent gaze data can be used to predict syntactic categories. We show that gaze data can effectively be used to discriminate between a wide range of part of speech (POS) pairs, and gaze data can therefore be used to significantly improve type-constrained POS taggers. This is potentially useful,</context>
<context position="5447" citStr="Rayner, 1998" startWordPosition="857" endWordPosition="858">ipants were seated on a chair approximately 65 cm from the display. We recruited 10 participants (7 male, mean age 31.30 ±4.74)) from campus. All were native English speakers. Their vision was normal or corrected to normal, and none were diagnosed with dyslexia. All were skilled readers. Minimum educational level was an ongoing MA. Each session lasted around 40 minutes. One participant had no fixations on a few sentences. We believe that erroneous key strokes caused the participant to skip a few sentences. Features There are many different features for exploring cognitive load during reading (Rayner, 1998). We extracted a broad selection of cognitive effort features from the raw eye-tracking data in order to determine which are more fit for the task. The features are inspired by Saloj¨arvi et al. (2003), who used a similarly exploratory approach. We wanted to cover both oculomotor features, such as fixations on previous and subsequent words, and measures relating to early (e.g. first fixation duration) and late processing (e.g. regression destinations / departure points and total fixation time). We also included reading speed and reading depth features, such as fixation probability and total fi</context>
</contexts>
<marker>Rayner, 1998</marker>
<rawString>Keith Rayner. 1998. Eye movements in reading and information processing: 20 years of research. Psychological bulletin, 124(3):372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jarkko Saloj¨arvi</author>
<author>Ilpo Kojo</author>
<author>Jaana Simola</author>
<author>Samuel Kaski</author>
</authors>
<title>Can relevance be inferred from eye movements in information retrieval.</title>
<date>2003</date>
<booktitle>In Proceedings of WSOM,</booktitle>
<volume>3</volume>
<pages>261--266</pages>
<marker>Saloj¨arvi, Kojo, Simola, Kaski, 2003</marker>
<rawString>Jarkko Saloj¨arvi, Ilpo Kojo, Jaana Simola, and Samuel Kaski. 2003. Can relevance be inferred from eye movements in information retrieval. In Proceedings of WSOM, volume 3, pages 261–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javier San Agustin</author>
<author>Henrik Skovsgaard</author>
<author>Emilie Mollenbach</author>
<author>Maria Barret</author>
<author>Martin Tall</author>
<author>Dan Witzner Hansen</author>
<author>John Paulin Hansen</author>
</authors>
<title>Evaluation of a low-cost open-source gaze tracker.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Symposium on Eye-Tracking Research &amp; Applications,</booktitle>
<pages>77--80</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1995" citStr="Agustin et al., 2010" startWordPosition="312" endWordPosition="315"> behavior is affected by syntactic category, maybe reading behavior can, conversely, also tell us about the syntax of words in context. This paper investigates to what extent gaze data can be used to predict syntactic categories. We show that gaze data can effectively be used to discriminate between a wide range of part of speech (POS) pairs, and gaze data can therefore be used to significantly improve type-constrained POS taggers. This is potentially useful, since eye-tracking data becomes more and more readily available with the emergence of eye trackers in mainstream consumer products (San Agustin et al., 2010). With the development of robust eye-tracking in laptops, it is easy to imagine digital text providers storing gaze data, which could then be used to improve automated analysis of their publications. Contributions We are, to the best of our knowledge, the first to study reading behavior of syntactically annotated, natural text across domains, and how gaze correlates with a complete set of syntactic categories. We use logistic regression to show that gaze features discriminate between POS pairs, even across domains. We then show how gaze features can improve a cross-domain supervised POS tagger</context>
</contexts>
<marker>Agustin, Skovsgaard, Mollenbach, Barret, Tall, Hansen, Hansen, 2010</marker>
<rawString>Javier San Agustin, Henrik Skovsgaard, Emilie Mollenbach, Maria Barret, Martin Tall, Dan Witzner Hansen, and John Paulin Hansen. 2010. Evaluation of a low-cost open-source gaze tracker. In Proceedings of the 2010 Symposium on Eye-Tracking Research &amp; Applications, pages 77–80. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Ilyich Spitkovsky</author>
</authors>
<title>Grammar Induction and Parsing with Dependency-and-Boundary Models.</title>
<date>2013</date>
<tech>Ph.D. thesis,</tech>
<institution>STANFORD UNIVERSITY.</institution>
<marker>Spitkovsky, 2013</marker>
<rawString>Valentin Ilyich Spitkovsky. 2013. Grammar Induction and Parsing with Dependency-and-Boundary Models. Ph.D. thesis, STANFORD UNIVERSITY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<tech>TACL,</tech>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tagging. TACL, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="12863" citStr="Turian et al. (2010)" startWordPosition="2117" endWordPosition="2120"> face trained a type-constrained (averaged) perceptron model with drop-out and a standard feature model (from Owoputi et al. (2013)) augmented with the above gaze features. The POS tagger was trained on a very small seed of data (200 sentences), doing 20 passes over the data, and evaluated on out-ofdomain test data; training on four domains, testing on one. For the gaze features, instead of using token gaze features, we first built a lexicon with average word type statistics from the training data. We normalize the gaze matrix by dividing with its standard deviation. This is the normalizer in Turian et al. (2010) with σ = 1.0. We condition on the gaze features of the current word, only. We compare performance using gaze features to using only word frequency, estimating from the (unlabeled) English Web Treebank corpus, and word length (FREQLEN). The first three columns in Table 2 show, that gaze features help POS tagging, at least when trained on very small seeds of data. Error reduction using gaze features from the Dundee corpus (DGAZE) is 12%. We know that gaze features correlate with word frequency and word length, but using these features directly leads to much smaller performance gains. Concatenat</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>