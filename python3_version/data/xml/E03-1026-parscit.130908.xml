<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000205">
<title confidence="0.995183">
Combining Clues for Word Alignment
</title>
<author confidence="0.998099">
Jorg Tiedemann
</author>
<affiliation confidence="0.99911">
Department of Linguistics
Uppsala University
</affiliation>
<address confidence="0.9841775">
Box 527
SE-751 20 Uppsala, Sweden
</address>
<email confidence="0.99792">
joerg@stp.ling.uu.se
</email>
<sectionHeader confidence="0.995617" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999948526315789">
In this paper, a word alignment ap-
proach is presented which is based on
a combination of clues. Word align-
ment clues indicate associations be-
tween words and phrases. They can
be based on features such as frequency,
part-of-speech, phrase type, and the ac-
tual wordform strings. Clues can be
found by calculating similarity mea-
sures or learned from word aligned data.
The clue alignment approach, which is
proposed in this paper, makes it possi-
ble to combine association clues taking
different kinds of linguistic information
into account. It allows a dynamic to-
kenization into token units of varying
size. The approach has been applied
to an English/Swedish parallel text with
promising results.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.990489307692308">
Parallel corpora carry a huge amount of bilingual
lexical information. Word alignment approaches
focus on the automatic identification of translation
relations in translated texts. Alignments are usu-
ally represented as a set of links between words
and phrases of source and target language seg-
ments. An alignment can be complete, i.e. all
items in both segments have been linked to cor-
responding items in the other language, or incom-
plete, otherwise. Alignments may include &amp;quot;null
links&amp;quot; which can be modeled as links to an &amp;quot;empty
element&amp;quot;.
In word alignment, we have to
</bodyText>
<listItem confidence="0.987142111111111">
• find an appropriate model M for the align-
ment of source and target language texts
(modeling)
• estimate parameters of the model M, e.g.
from empirical data (parameter estimation)
• find the optimal alignment of words and
phrases for a given translation according to
the model M and its parameters (alignment
recovery).
</listItem>
<bodyText confidence="0.999685761904762">
Modeling the relations between lexical units of
translated texts is not a trivial task due to the di-
versity of natural languages. There are generally
two approaches, the estimation approach which is
used in, e.g., statistical machine translation, and
the association approach which is used in, e.g.,
automatic extraction of bilingual terminology. In
the estimation approach, alignment parameters are
modeled as hidden parameters in a statistical trans-
lation model (Och and Ney, 2000). Association
approaches base the alignment on similarity mea-
sures and association tests such as Dice scores
(Smadj a et al., 1996; Tiedemann, 1999), t-scores
(Ahrenberg et al., 1998) log-likelihood measures
(Tufis and Barbu, 2002), and longest common sub-
sequence ratios (Melamed, 1995).
One of the main difficulties in all alignment
strategies is the identification of appropriate units
in the source and the target language to be aligned.
This task is hard even for human experts as can be
seen in the detailed guidelines which are required
</bodyText>
<page confidence="0.998233">
339
</page>
<bodyText confidence="0.999911742424243">
for manual alignments (Merkel, 1999; Melamed,
1998). Many translation relations involve multi-
word units such as phrasal compounds, idiomatic
expressions, and complex terms. Syntactic shifts
can also require the consideration of a context
larger than a single word. Some items are not
translated at all. Splitting source and target
language texts into appropriate units for align-
ment (henceforth: tokenization) is often not pos-
sible without considering the translation relations.
In other words, initial tokenization borders may
change when the translation relations are investi-
gated. Human aligners frequently expand token
units when aligning sentences manually depend-
ing on the context (Ahrenberg et al., 2002). Pre-
vious approaches use either iterative procedures to
re-estimate alignment parameters (Smadja et al.,
1996; Melamed, 1997; Vogel et al., 2000) or pre-
processing steps for the identification of token N-
grams (Ahrenberg et al., 1998; Tiedemann, 1999).
In our approach, we combine simple techniques
for prior tokenization with dynamic techniques
during the alignment phase.
The second problem of traditional word align-
ment approaches is the fact that parameter estima-
tions are usually based on plain text items only.
Linguistic data, which could be used to identify
associations between lexical items are often ig-
nored. Linguistic tools such as part-of-speech tag-
gers, (shallow) parsers, named-entity recognizers
become more and more robust and available for
more languages. Linguistic information includ-
ing contextual features could be used to improve
alignment strategies.
The third problem, alignment recovery, is a
search problem. Using the alignment model and
its parameters, we have to find the optimal align-
ment for a given pair of source and target lan-
guage segments. In (Hiemstra, 1998), the author
points out that a sentence pair with a maximum
of n token units in both sentences has n! possible
alignments in a simple directed alignment model
with a fixed tokenization. Furthermore, a search
strategy becomes very complex if we allow dy-
n am i c tokeni zati on borders (overlapping N- gram s,
inclusions), which leads us not only to a larger
number of possible combinations but also to the
problem of comparing alignments with variable
length (number of links)
The clue alignment approach, which we pro-
pose here, addresses the three problems which
were mentioned above. The approach allows the
combination of association measures for any fea-
tures of translation units of varying size. Overlap-
ping units are allowed as well as inclusions. As-
sociation scores are organized in a clue matrix and
we present a simple approach for approximating
the optimal alignment.
Section 2 describes the clue alignment model
and ways of estimating parameters from associ-
ation scores. Section 3 introduces the alignment
approach which is based on word alignment clues.
Section 4 gives examples of learning clues from
previous alignments. Section 5 summarizes align-
ment experiments and, finally, section 6 contains
conclusions and a discussion.
</bodyText>
<sectionHeader confidence="0.967841" genericHeader="method">
2 Word Alignment Clues
</sectionHeader>
<subsectionHeader confidence="0.956318">
2.1 Motivation
</subsectionHeader>
<bodyText confidence="0.960420740740741">
The following English/Swedish sentence pair has
been taken from the PLUG corpus (Sagvall Hein,
1999):
The corridors are jumping with them.
Korridorerna myllrar av dem.
The task for an aligner is now to find all the
links between the lexical items in English and the
lexical items in Swedish. The natural way of doing
this for a human is to use various kinds of infor-
mation, clues. Even without knowing either of
the two languages, a human aligner would find a
strong similarity between corridors and korridor-
ema which leads to the conclusion of a possible
relation between these two words. Similarly, a
relation could be seen between them and dem.1
In a second step, the aligner might use fre-
quency counts of words in both languages and co-
occurrence frequencies for some interesting word
pairs.
source freq target freq co-occ. Dice
corridors 3 korridorerna 2 2 0.8
with 518 dem 188 39 0.110
with 518 av 988 169 0.224
them 193 dem 188 170 0.892
them 193 av 988 71 0.120
10f course, the aligner should be aware of the possibilities
of false friends especially among short words.
</bodyText>
<page confidence="0.996541">
340
</page>
<bodyText confidence="0.998725875">
The frequency table above gives the aligner an
additional clue for an association between corri-
dors and korridorema and also some ideas about
the relation between them and dem but not much
about the remaining words.
Finally, the aligner might apply off-the-shelf
part-of-speech taggers and shallow syntactic ana-
lyzers.
</bodyText>
<equation confidence="0.918947714285714">
NP VP NP
DT NNS VBP VBG IN PRP
The corridors are jumping with them
Korridorerna myllrar as dem
NCUPN@DS V@IPAS SPS PF@OPO@S
NP VC NP
PP
</equation>
<bodyText confidence="0.998232456521739">
The aligner might look up the descriptions of
the English tag set and finds out that NNS is the
label for a plural noun, VBP and VBG are labels
of verbs in the present tense, IN labels a prepo-
sition, and PRP a personal pronoun. Similarly,
(s)he looks for the Swedish tags and finds out
that NCUPN@DS describes a definite noun in plu-
ral form and nominative case, V@IPAS describes
an active verb in the present tense, SPS labels a
preposition, and PF@OPO@S describes a definite
pronoun object in plural form. This gives the
aligner additional clues about possible links (S)he
might expect relations between active verbs in the
present tense rather than between verbs and nouns.
Finding out that Swedish nouns can bear the fea-
ture of definiteness gives the aligner another clue
about the translation of the definite article in the
English sentence.
Finally, the aligner looks at the output of the
shallow parser and gets additional clues for align-
ing the two sentences. For example, the two En-
glish verbs build a verb phrase (VP) which is most
likely to be linked to the only &amp;quot;verb cluster&amp;quot; (VC)
in the Swedish sentence. The personal pronoun in
the English sentence is used as a noun phrase (NP)
similar to the pronoun in the Swedish sentence.
Putting all the clues together, the aligner comes
up with the following alignment without actually
having to know the two languages:
the corridors korridorerna
are jumping myllrar
with av
them dem
However, looking at the sentence pair again,
a second aligner with knowledge of both lan-
guages might realize that the verbs myllrar (En-
glish: swarm) and jumping do not really corre-
spond to each other in isolation and that the ex-
pressions are rather idiomatic in both languages.
Therefore, the second aligner might decide to link
the whole expression &amp;quot;are jumping with&amp;quot; to the
Swedish translation of &amp;quot;myllrar av&amp;quot;.
This kind of disagreement between human
aligners is quite normal and demonstrates quite
well the problems which have to be handled by
automatic alignment approaches.
</bodyText>
<subsectionHeader confidence="0.990167">
2.2 Definitions
</subsectionHeader>
<bodyText confidence="0.997256777777778">
Now, we would like to use a similar strategy as
described in the previous section for an automatic
alignment process. In our approach, we use the
following definitions:
Word alignment clue: A word alignment clue
C, t) is a probability which indicates an
association between two lexical items s and
tin parallel texts.
Lexical item: A lexical item is a set of words
with associated features attached to it (word
position may be a feature).
A clue is called static if its value is constant for
a given pair of features of lexical items, otherwise
it is called dynamic Furthermore, clues can be
declarative, i.e. pre-defined feature correspon-
dences, or estimated, i.e. from association scores
or from training data. Generally, a clue is defined
as a weighted association A between s and t:
</bodyText>
<equation confidence="0.492597">
Ci(s, t) = P(a,) = t)
</equation>
<bodyText confidence="0.951712">
The value of w, is used to normalize and weight
the association score A.
Alignment clues can be estimated from associ-
ation measures given empirical data. Examples of
such measures are given below:
2P(s,t)
Co-occurrence: ADice(s, t) = p(s)+P(t)
(the Dice coefficient)
String similarity: ALCSR(S,t) = LCSR(S,t)
(the longest common subsequence ratio)
Other clues can be estimated from word aligned
training data:
</bodyText>
<page confidence="0.854612">
341
</page>
<equation confidence="0.988163">
Ci(8,t) = wi * P(ftlfs) wi f rferge(qf(819f)t)
</equation>
<bodyText confidence="0.999599272727273">
f, and ft are sets of features of s and t, respec-
tively. They may include features such as part-of-
speech, phrase categories, word positions, and/or
any other kind of contextual features.
Clues can also be pre-defined. For example,
machine-readable dictionary can be used as a col-
lection of declarative clues. Each translation from
the dictionary is an alignment clue for the cor-
responding word pairs. The likelihood of each
translation alternative can be weighted, e.g., by
frequency (if available).
</bodyText>
<subsectionHeader confidence="0.997189">
2.3 Clue Combinations
</subsectionHeader>
<bodyText confidence="0.993110052631579">
So far, word alignment clues are simply sets of
weighted association scores. The key task is to
combine available clues in order to find inter-
lingual links. Clues are defined as probabilities of
associations. In order to combine all indications
which are given by single clues C, (s, t) = P(ai)
we define the overall clue Cat/ (s,t) for a given
pair of lexical items as the disjunction of all in-
dications:
Cau(s7 t) = P(aall) = P(ai U a2 U U a,„)
Note that clues are not mutually exclusive. For
example, an association based on co-occurrence
measures can be found together with an associa-
tion based on string similarity measures. Using the
addition rule for probabilities we get the following
formula for a disjunction of two clues:
P(ai U a2) = P(ai) P(a2) — P(ai n a2)
For simplicity, we assume that clues are inde-
pendent of each other.
</bodyText>
<equation confidence="0.858251">
P(ai n a2) = P(ai)P(a2)
</equation>
<bodyText confidence="0.999699">
This is a crucial assumption and has to be consid-
ered when designing clue patterns.
</bodyText>
<subsectionHeader confidence="0.996284">
2.4 Overlaps, Inclusions and the Clue Matrix
</subsectionHeader>
<bodyText confidence="0.999987962962963">
Word alignment clues may refer to any set of
words from the source and target language seg-
ment according to the definitions in section 2.2.
Therefore, clues can refer to sets of words which
overlap with other sets of words to which another
clue refers. Such overlaps and inclusions make
it impossible to combine the corresponding clues
directly with the formulas which were given in the
previous section. In order to enable clue combi-
nations even for overlapping units, we define the
following property of word alignment clues:
A clue indicates an association between all its
member token pairs.
This property makes it possible to combine
alignment clues by distributing the clue indication
from complex structures to single word pairs. In
this way, dynamic tokenization can be used for
both, source and target language sentences and
combined association scores (the total clue value)
can be calculated for each pair of single tokens.
Now, sentence pairs can be represented in a
two-dimensional matrix with one source language
word per row and one target language word per
column. The cells inside the matrix can be filled
with the combined clue values for the correspond-
ing word pairs. Henceforth, this matrix will be
referred to as a clue matrix.
</bodyText>
<subsectionHeader confidence="0.864617">
2.5 Example
</subsectionHeader>
<bodyText confidence="0.998815285714286">
Consider the following English/Swedish sentence
pair:
Then hand baggage is opened.
Sedan eppnas handbagaget.
Assume that the alignment program found the
following alignment clues which are based on
string similarity and co-occurrence statistics:2
</bodyText>
<figure confidence="0.608807818181818">
co-occurrence (DICE)
then sedan
is opened oppnas
is opened sedan oppnas
opened oppnas
baggage handbagaget
string similarity (LCSR)
hand baggage handbagaget
opened oppnas
then sedan
hand sedan
</figure>
<bodyText confidence="0.999331714285714">
The alignment clues contain only three multi-
word units. However, even these few units cause
several overlaps. For example, the English string
&amp;quot;hand baggage&amp;quot; from the set of string similarity
clues overlaps with the string &amp;quot;baggage&amp;quot;. The
clue for the pair &amp;quot;is opened&amp;quot; and &amp;quot;sedan Oppnas&amp;quot;
overlaps with six other clues. However, using our
</bodyText>
<footnote confidence="0.612835">
2Note that clues do not have to be correct! Alignment
clues give hints for a possible relation between words and
phrases. They can even be misleading, but hopefully, the
indication of combined clues will lead to correct links.
</footnote>
<figure confidence="0.997940444444444">
0.38
0.65
0.2
0.5
0.45
0.83
0.33
0.4
0.4
</figure>
<page confidence="0.91562">
342
</page>
<table confidence="0.916149">
definitions of alignment clues, we can easily con- value in the matrix. Set the corresponding
struct the following clue matrix:
sedan oppnas handbagaget
then 0.628 0 0
hand 0.4 0 0.83
baggage 0 0 0.9065
is 0.2 0.72 0
opened 0.2 0.86 0
</table>
<bodyText confidence="0.985739769230769">
The matrix is simply filled with all values of
combined clues for each word pair. For ex-
ample, the total clue value for the word pair
s =&amp;quot;baggage&amp;quot; and t =&amp;quot;handbagaget&amp;quot; is calcu-
lated as follows:
Cau (s, t) = 0.45+0.83 — 0.45*0.83 = 0.9065
All other values are computed in the same way.
Looking at the matrix, we can find clear relations
between certain words such as [hand,baggage]
and handbagaget. However, between other word
pairs such as is and sedan we find only low asso-
ciations which conflict with others and therefore,
they can be dismissed in the alignment process.
</bodyText>
<sectionHeader confidence="0.995968" genericHeader="method">
3 Clue Alignment
</sectionHeader>
<bodyText confidence="0.999951681818182">
Word alignment clues as described above can be
used to model the relations between words of
translated texts. Parameters of this model can be
collected in a clue matrix as introduced in section
2.4. The final task is now to recover the actual
alignment of words and phrases from the text us-
ing the parameters in the clue matrix. This can
be formulated as a search task in which one tries
to find the optimal alignment using possible links
between words and phrases.
It is important for our purposes to allow mul-
tiple links from each word (source and target) to
corresponding words in the other language in or-
der to obtain phrasal links We say that a word-
to-word link overlaps with another one if both of
them refer to either the same source or the same
target language word. Sets of overlapping links
form link clusters.
Phrasal links cause alignments with varying
numbers of linked items which have to be com-
pared. We use the following dynamic procedure
in order to approach an optimal alignment:
</bodyText>
<listItem confidence="0.5816394">
1. Find the best link in the clue matrix, i.e. find
the word-to-word relation with the highest
value in the matrix to zero.
2. Check for overlaps: If the link overlaps with
other links from more than one accepted link
</listItem>
<bodyText confidence="0.986131">
cluster continue with 1. If the link over-
laps with another accepted link but the non-
overlapping tokens are not next to each other
in the text continue with 1.
</bodyText>
<listItem confidence="0.99660425">
3. Add the link to the set of accepted link clus-
ters and continue with 1 until no more links
are found (or the best link is below a certain
threshold)
</listItem>
<bodyText confidence="0.999971625">
The algorithm is very simple and may miss the
optimal alignment. However, it is a very efficient
way of extracting links according to their asso-
ciation clues. Experiments, which are presented
further down, show promising results. The crucial
point of the algorithm is the attachment of links
to existing link clusters. The algorithm restricts
clusters to pairs of contiguous word sequences in
order to reduce the number of malformed phrases
in extracted links. A better way would be to use
proper language models to do this job. Another
possibility is to use the syntactic structures from
a (shallow) parser as prior knowledge. A simple
modification of the algorithm above would be to
accept overlapping links only if they do not cross
phrase borders according to the syntactic analysis.
</bodyText>
<sectionHeader confidence="0.992319" genericHeader="method">
4 Bootstrapping Clue Alignment
</sectionHeader>
<bodyText confidence="0.999932294117647">
In section 2.2, we pointed out that clues can be
estimated from aligned training material. This al-
lows us to infer new clues from previous links by
estimating conditional probabilities. For this, we
assume that previous links are correct and can be
used for probability estimations. This is not true
in general. However, we hope to find additional
links with sufficient accuracy from these clues. In
other words, we expect clues, which have been
found via &amp;quot;self-learning&amp;quot; techniques to increase
the recall with an acceptable increase of noise.
Previous links point to the context from which
they originated. Therefore, we can access any pair
of features which is available for the context as
well as for the linked items themselves. In this
way, clue probabilities can be based on any combi-
nation of features of linked items and their context.
</bodyText>
<page confidence="0.998371">
343
</page>
<bodyText confidence="0.972240822222223">
A simple example is to use part-of-speech
(POS) tags as a feature of lexical items. Using
this feature, we can estimate the probabilities of
source language items with certain POS-tags to be
linked to target language items with certain other
POS-tags.
Consider the following example: An En-
glish/Swedish bitext has been aligned with some
basic clue patterns using the clue alignment ap-
proach. Now, we assume that pairs of POS labels
can give us additional clues about possible links
A new clue is, e.g., a conditional probability of a
sequence of POS labels of linked items given the
POS labels of the items they were linked to.
Applying learned clues (such as the POS clue
from above) on their own would probably be mis-
leading in many cases. However, they add valu-
able information in combination with others. In
our experiments, we applied the following feature
patterns for learning clues:
POS full: Label sequences as described above.
POS coarse: Label sequences as in POS full but
with a reduced tag set for Swedish (done by
simply cutting the label after two characters)
Phrase: Phrase type labels which have been pro-
duced by (shallow) parsers
Position: The position of the translations in the
target language segment relative to the po-
sition of the original in the source language
segment.3
The following matrix was produced for the sen-
tence pair from section 2.1 using all the learned
alignment clues from above.4
Korri dorern a myl lrar av dem
The 0.54 0.02 0.17 0.33
corridors 0.82 0.07 0.06 0.06
are 0.17 0.46 0.15 0.14
jumping 0.27 0.73 0.11 0.11
with 0 0 0.63 0.09
them 0 0 0.12 0.61
&apos;The position clue is more of a weight than a clue. It
favors common position distances of links by giving them a
higher value. This somehow assumes that translations are
more likely to be found close to each other than far away in
terms of word position.
</bodyText>
<footnote confidence="0.937552">
4Each clue has been normalized with a uniform weight of
0.5 except for the position clue which was weighted with a
value of 0.1.
</footnote>
<bodyText confidence="0.994920666666667">
The numbers in bold refer to the link clusters
which would have been extracted using the clue
alignment procedure from section 3.
</bodyText>
<sectionHeader confidence="0.94788" genericHeader="method">
5 Clue Alignment Experiments
</sectionHeader>
<subsectionHeader confidence="0.918467">
5.1 The Setup
</subsectionHeader>
<bodyText confidence="0.9902665">
We applied the &amp;quot;clue aligner&amp;quot; to one of our parallel
corpora from the PLUG project (Sagvall Hein,
1999), a novel by Saul Bellow &amp;quot;To Jerusalem and
back: a personal account&amp;quot; with about 170,000
words in English and Swedish.
The English portion of the corpus has been
tagged automatically with POS tags by the En-
glish maximum entropy tagger in the open-source
software package Grok (Baldridge, 2002). The
same package was used for shallow parsing of the
English sentences.
The Swedish portion was tagged by the Ngram-
based TnT-tagger (Brants, 2000) which was
trained for Swedish on the SUC corpus (Megyesi,
2001). Furthermore, we used a rule-based ana-
lyzer for syntactic parsing (Megyesi, 2002).
Our basic alignment applies two association
clues: the Dice coefficient and the longest com-
mon subsequence ratio (LCSR). Both clues have
been weighted uniformly with a value of 0.5. The
threshold for the Dice coefficient has been set to
0.3 and the minimal co-occurrence frequency to 2.
The threshold of LCSR scores has been set to 0.4
and the minimal token length to 3 characters.5
We certainly wanted to test the ability of finding
phrasal links Therefore, both association clues
have been calculated for pairs of multi-word units
(MWUs). MWUs may overlap with others or may
be included in other MWUs. We used two dif-
ferent approaches in order to select appropriate
MWUs:
N-grams: word bigrams and trigrams + simple
language filters (stop word lists) to find com-
mon phrase borders.
Chunks phrases which have been marked by a
shallow parser for English and a rule-based
parser for Swedish.
Both sets of MWUs can also be combined.
</bodyText>
<footnote confidence="0.810721">
5Weights and threshold have been chosen intuitively.
</footnote>
<page confidence="0.997721">
344
</page>
<bodyText confidence="0.999922363636364">
Furthermore, we were interested in the ability
of the algorithm of learning new clues from pre-
viously aligned links as discussed in 4. We ap-
plied all the clue patterns which where introduced
at the end of section 4: POS full, POS coarse,
Phrase, Position. POS clues have been normalized
with a weight of 0.5. Relative position and phrase
type labels bear much less information about spe-
cific words and phrases than POS tags, therefore,
a lower weight of 0.1 was chosen for these two
clues.
</bodyText>
<subsectionHeader confidence="0.993803">
5.2 The results
</subsectionHeader>
<bodyText confidence="0.999798083333333">
For the evaluation, we used an existing gold stan-
dard which was produced within the PLUG project
(Ahrenberg et al., 1999). The gold standard
consists of 500 randomly sampled items which
have been aligned manually according to detailed
guidelines (Merkel, 1999). Results are measured
using fine-grained metrics for precision and re-
call (Ahrenberg et al., 2000) and a balanced F-
measure.
The following table summarizes the results of
some alignment experiments using different sets
of clues (all values in %):6
</bodyText>
<table confidence="0.973573285714286">
adding clues precision recall F
basic 79.737 41.695 54.757
+ POS full 74.311 49.554 59.458
+ POS coarse 69.854 57.279 62.945
+ phrase 78.289 45.122 57.249
+ position 81.939 44.703 57.847
+ all 74.749 63.730 68.801
</table>
<bodyText confidence="0.999628933333333">
The values in the table above show a clear im-
provement, mainly in recall, of the results when
additional clues have been applied. The impact
of POS clues follows intuitive expectations. A
smaller tagset makes the clues more general and
the recall value is increased while the precision
drops significantly. However, the position clue
changed the result beyond all expectations. Not
only did recall go up significantly, even the pre-
cision was increased. This proves that relations
between word positions are important in aligning
Swedish and English. Position distance weights
(implicitly implemented as a position clue) seem
to improve the choice between competing link al-
ternatives. The effect of similar clues on less re-
</bodyText>
<footnote confidence="0.970885">
6The values refer to experiments with the &amp;quot;chunk&amp;quot; ap-
proach for MWU selection.
</footnote>
<bodyText confidence="0.990696333333333">
lated languages is necessary in order to evaluate
their general quality.
The impact of the MWU approach was investi-
gated as well. The following table compares re-
sults of the two different approaches as well as the
combined approach.
</bodyText>
<table confidence="0.856761">
MWU approach precision recall F
N-grams 74.462 62.539 67.981
chunks 74.749 63.730 68.801
N-grams + chunks 70.894 61.115 65.642
</table>
<bodyText confidence="0.9995844">
The &amp;quot;chunk&amp;quot; approach is best in all categories.
The lower values for precision for the other two
approaches could be expected. However, the low
recall value for the combined approach is a sur-
prise.
</bodyText>
<sectionHeader confidence="0.999747" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999923903225806">
In this paper, a word alignment approach has been
introduced which is based on a combination of
association clues. The algorithm supports a dy-
namic tokenization of parallel texts which enables
the alignment system to combine relations of over-
lapping pairs of lexical items (words and phrases).
Alignment clues can be estimated from com-
mon association criteria such as co-occurrence
statistics and string similarity measures. Clues
can also be learned from pre-aligned training data.
It has been demonstrated how self-learning tech-
niques can be used for learning additional align-
ment clues from previous alignments. Clues are
defined as probabilities which indicate an associ-
ation between lexical items according to some of
their features. This definition is very flexible as
features can represent any kind of information that
is available for each item and its context. An im-
portant advantage of the clue alignment algorithm
is the possibility of combining association scores.
In this way, any number of clues can be included
in the alignment process.
The alignment experiments, which were pre-
sented in this paper, demonstrate the combination
of two basic clue types (based on co-occurrence
and string similarity) with four additional clue
types (based on POS labels, chunk labels, and rela-
tive word positions) which were learned during the
alignment process. The alignment experiments on
a parallel English/Swedish corpus showed signifi-
cant improvements of the results when additional
</bodyText>
<page confidence="0.996907">
345
</page>
<bodyText confidence="0.9994355">
clues were added to the basic settings.
The clue alignment approach is very flexible
and can easily be adapted to a new domain, lan-
guage pair, and a different set of clues. Clue pat-
terns can be defined depending on the information
which is available (POS tags, phrase types, seman-
tic tags, named entity markup, dictionaries etc.).
However, clue patterns have to be designed care-
fully as they can be misleading. Word alignment
is a real-life problem: We are looking for links in
the complex world of parallel corpora and we need
good clues in order to find them.
</bodyText>
<sectionHeader confidence="0.998501" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999836511627907">
Lars Ahrenberg, Magnus Merkel, and Mikael Anders-
son. 1998. A simple hybrid aligner for generating
lexical correspondences in parallel texts. In Pro-
ceedings of the 36th Annual Meeting of the Associa-
tion for Computational Linguistics and the 17th In-
ternational Conference on Computational Linguis-
tics, pages 29-35, Montreal, Canada.
Lars Ahrenberg, Magnus Merkel, Anna Sfigvall Hein,
and Jorg Tiedemann. 1999. Evaluation of LWA and
UWA. Technical Report 15, Department of Linguis-
tics, University of Uppsala.
Lars Ahrenberg, Magnus Merkel, Anna Sagvall Hein,
and Jorg Tiedemann. 2000. Evaluation of word
alignment systems. In Proceedings of the 2nd In-
ternational Conference on Language Resources and
Evaluation, LREC-2000. European Language Re-
sources Association.
Lars Ahrenberg, Magnus Merkel, and Mikael Anders-
son. 2002. A system for incremental and interactive
word linking. In Proceedings from The Third In-
ternational Conference on Language Resources and
Evaluation (LREC-2002), pages 485-490, Las Pal-
mas, Spain.
Jason Baldridge. 2002. GROK - an open
source natural language processing library.
http://grok.sourceforge.net/.
Thorsten Brants. 2000. TnT - a statistical part-of-
speech tagger. In Proceedings of the Sixth Applied
Natural Language Processing Conference ANLP-
2000, Seattle, Washington.
Djoerd Hiemstra. 1998. Multilingual domain mod-
eling in Twenty-One: Automatic creation of a bi-
directional translation lexicon from a parallel cor-
pus. In Peter-Arno Coppen, Hans van Halteren,
and Lisanne Teunissen, editors, Proceedings of the
eighth CLIN meeting, pages 41-58.
Beata Megyesi. 2001. Comparing data-driven learning
algorithms for POS tagging of swedish. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP 2001), pages
151-158, Carnegie Mellon University, Pittsburgh,
PA, USA.
Beata Megyesi. 2002. Shallow parsing with POS
taggers and linguistic features. Journal of Machine
Learning Research: Special Issue on Shallow Pars-
ing, (2):639-668.
I. Dan Melamed. 1995. Automatic evaluation and uni-
form filter cascades for inducing N-best translation
lexicons. In Proceedings of the 3rd Workshop on
Very Large Corpora, Boston/Massachusetts.
I. Dan Melamed. 1997. Automatic discovery of non-
compositional compounds in parallel data. In Pro-
ceedings of the 2nd Conference on Empirical Meth-
ods in Natural Language Processing, Providence.
I. Dan Melamed. 1998. Annotation style guide for the
Blinker project, version 1.0. IRCS Technical Report
98-06, University of Pennsylvania, Philadelphia.
Magnus Merkel. 1999. Annotation style guide for the
PLUG link annotator. Technical report, Linkoping
University, Linkoping.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the Association for Compu-
tational Linguistics, pages 440-447.
Anna Sagvall HeM. 1999. The PLUG Project: Parallel
corpora in Linkoping, Uppsala, and Goteborg: Aims
and achievements. Technical Report 16, Department
of Linguistics, University of Uppsala.
Frank Smadja, Kathleen R. McKeown, and Vasileios
Hatzivassiloglou. 1996. Translating collocations for
bilingual lexicons: A statistical approach. Compu-
tational Linguistics, 22(1), pages 1-38.
Jorg Tiedemann. 1999. Word alignment - step by
step. In Proceedings of the 12th Nordic Conference
on Computational Linguistics NODALIDA99, pages
216-227, University of Trondheim, Norway.
Dan Tufis and Ana-Maria Barbu. 2002. Lexical to-
ken alignment: Experiments, results and applica-
tions. In Proceedings from The Third International
Conference on Language Resources and Evaluation
(LREC-2002), pages 458-465, Las Palmas, Spain.
Stephan Vogel, Franz Josef Och, Christoph Tillmann,
Sonja Niel3en, Hassan Sawaf, and Hermann Ney,
2000. Verbmobil: Foundations of Speech-to-Speech
Translation, chapter Statistical Methods for Ma-
chine Translation. Springer Verlag, Berlin.
</reference>
<page confidence="0.999102">
346
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.975181">
<title confidence="0.99974">Combining Clues for Word Alignment</title>
<author confidence="0.99966">Jorg Tiedemann</author>
<affiliation confidence="0.999977">Department of Linguistics Uppsala University</affiliation>
<address confidence="0.994608">Box 527 SE-751 20 Uppsala, Sweden</address>
<email confidence="0.991271">joerg@stp.ling.uu.se</email>
<abstract confidence="0.99972565">In this paper, a word alignment approach is presented which is based on a combination of clues. Word alignment clues indicate associations between words and phrases. They can be based on features such as frequency, part-of-speech, phrase type, and the actual wordform strings. Clues can be found by calculating similarity measures or learned from word aligned data. alignment which is proposed in this paper, makes it possible to combine association clues taking different kinds of linguistic information into account. It allows a dynamic tokenization into token units of varying size. The approach has been applied to an English/Swedish parallel text with promising results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lars Ahrenberg</author>
<author>Magnus Merkel</author>
<author>Mikael Andersson</author>
</authors>
<title>A simple hybrid aligner for generating lexical correspondences in parallel texts.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics,</booktitle>
<pages>29--35</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2426" citStr="Ahrenberg et al., 1998" startWordPosition="377" endWordPosition="380">s of translated texts is not a trivial task due to the diversity of natural languages. There are generally two approaches, the estimation approach which is used in, e.g., statistical machine translation, and the association approach which is used in, e.g., automatic extraction of bilingual terminology. In the estimation approach, alignment parameters are modeled as hidden parameters in a statistical translation model (Och and Ney, 2000). Association approaches base the alignment on similarity measures and association tests such as Dice scores (Smadj a et al., 1996; Tiedemann, 1999), t-scores (Ahrenberg et al., 1998) log-likelihood measures (Tufis and Barbu, 2002), and longest common subsequence ratios (Melamed, 1995). One of the main difficulties in all alignment strategies is the identification of appropriate units in the source and the target language to be aligned. This task is hard even for human experts as can be seen in the detailed guidelines which are required 339 for manual alignments (Merkel, 1999; Melamed, 1998). Many translation relations involve multiword units such as phrasal compounds, idiomatic expressions, and complex terms. Syntactic shifts can also require the consideration of a contex</context>
<context position="3733" citStr="Ahrenberg et al., 1998" startWordPosition="575" endWordPosition="578">nd target language texts into appropriate units for alignment (henceforth: tokenization) is often not possible without considering the translation relations. In other words, initial tokenization borders may change when the translation relations are investigated. Human aligners frequently expand token units when aligning sentences manually depending on the context (Ahrenberg et al., 2002). Previous approaches use either iterative procedures to re-estimate alignment parameters (Smadja et al., 1996; Melamed, 1997; Vogel et al., 2000) or preprocessing steps for the identification of token Ngrams (Ahrenberg et al., 1998; Tiedemann, 1999). In our approach, we combine simple techniques for prior tokenization with dynamic techniques during the alignment phase. The second problem of traditional word alignment approaches is the fact that parameter estimations are usually based on plain text items only. Linguistic data, which could be used to identify associations between lexical items are often ignored. Linguistic tools such as part-of-speech taggers, (shallow) parsers, named-entity recognizers become more and more robust and available for more languages. Linguistic information including contextual features could</context>
</contexts>
<marker>Ahrenberg, Merkel, Andersson, 1998</marker>
<rawString>Lars Ahrenberg, Magnus Merkel, and Mikael Andersson. 1998. A simple hybrid aligner for generating lexical correspondences in parallel texts. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics, pages 29-35, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Ahrenberg</author>
<author>Magnus Merkel</author>
<author>Anna Sfigvall Hein</author>
<author>Jorg Tiedemann</author>
</authors>
<title>Evaluation of LWA and UWA.</title>
<date>1999</date>
<tech>Technical Report 15,</tech>
<institution>Department of Linguistics, University of Uppsala.</institution>
<contexts>
<context position="23011" citStr="Ahrenberg et al., 1999" startWordPosition="3824" endWordPosition="3827">hermore, we were interested in the ability of the algorithm of learning new clues from previously aligned links as discussed in 4. We applied all the clue patterns which where introduced at the end of section 4: POS full, POS coarse, Phrase, Position. POS clues have been normalized with a weight of 0.5. Relative position and phrase type labels bear much less information about specific words and phrases than POS tags, therefore, a lower weight of 0.1 was chosen for these two clues. 5.2 The results For the evaluation, we used an existing gold standard which was produced within the PLUG project (Ahrenberg et al., 1999). The gold standard consists of 500 randomly sampled items which have been aligned manually according to detailed guidelines (Merkel, 1999). Results are measured using fine-grained metrics for precision and recall (Ahrenberg et al., 2000) and a balanced Fmeasure. The following table summarizes the results of some alignment experiments using different sets of clues (all values in %):6 adding clues precision recall F basic 79.737 41.695 54.757 + POS full 74.311 49.554 59.458 + POS coarse 69.854 57.279 62.945 + phrase 78.289 45.122 57.249 + position 81.939 44.703 57.847 + all 74.749 63.730 68.801</context>
</contexts>
<marker>Ahrenberg, Merkel, Hein, Tiedemann, 1999</marker>
<rawString>Lars Ahrenberg, Magnus Merkel, Anna Sfigvall Hein, and Jorg Tiedemann. 1999. Evaluation of LWA and UWA. Technical Report 15, Department of Linguistics, University of Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Ahrenberg</author>
<author>Magnus Merkel</author>
<author>Anna Sagvall Hein</author>
<author>Jorg Tiedemann</author>
</authors>
<title>Evaluation of word alignment systems.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation, LREC-2000. European Language Resources Association.</booktitle>
<contexts>
<context position="23249" citStr="Ahrenberg et al., 2000" startWordPosition="3859" endWordPosition="3862">se, Position. POS clues have been normalized with a weight of 0.5. Relative position and phrase type labels bear much less information about specific words and phrases than POS tags, therefore, a lower weight of 0.1 was chosen for these two clues. 5.2 The results For the evaluation, we used an existing gold standard which was produced within the PLUG project (Ahrenberg et al., 1999). The gold standard consists of 500 randomly sampled items which have been aligned manually according to detailed guidelines (Merkel, 1999). Results are measured using fine-grained metrics for precision and recall (Ahrenberg et al., 2000) and a balanced Fmeasure. The following table summarizes the results of some alignment experiments using different sets of clues (all values in %):6 adding clues precision recall F basic 79.737 41.695 54.757 + POS full 74.311 49.554 59.458 + POS coarse 69.854 57.279 62.945 + phrase 78.289 45.122 57.249 + position 81.939 44.703 57.847 + all 74.749 63.730 68.801 The values in the table above show a clear improvement, mainly in recall, of the results when additional clues have been applied. The impact of POS clues follows intuitive expectations. A smaller tagset makes the clues more general and t</context>
</contexts>
<marker>Ahrenberg, Merkel, Hein, Tiedemann, 2000</marker>
<rawString>Lars Ahrenberg, Magnus Merkel, Anna Sagvall Hein, and Jorg Tiedemann. 2000. Evaluation of word alignment systems. In Proceedings of the 2nd International Conference on Language Resources and Evaluation, LREC-2000. European Language Resources Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Ahrenberg</author>
<author>Magnus Merkel</author>
<author>Mikael Andersson</author>
</authors>
<title>A system for incremental and interactive word linking.</title>
<date>2002</date>
<booktitle>In Proceedings from The Third International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<pages>485--490</pages>
<location>Las Palmas,</location>
<contexts>
<context position="3501" citStr="Ahrenberg et al., 2002" startWordPosition="539" endWordPosition="542">multiword units such as phrasal compounds, idiomatic expressions, and complex terms. Syntactic shifts can also require the consideration of a context larger than a single word. Some items are not translated at all. Splitting source and target language texts into appropriate units for alignment (henceforth: tokenization) is often not possible without considering the translation relations. In other words, initial tokenization borders may change when the translation relations are investigated. Human aligners frequently expand token units when aligning sentences manually depending on the context (Ahrenberg et al., 2002). Previous approaches use either iterative procedures to re-estimate alignment parameters (Smadja et al., 1996; Melamed, 1997; Vogel et al., 2000) or preprocessing steps for the identification of token Ngrams (Ahrenberg et al., 1998; Tiedemann, 1999). In our approach, we combine simple techniques for prior tokenization with dynamic techniques during the alignment phase. The second problem of traditional word alignment approaches is the fact that parameter estimations are usually based on plain text items only. Linguistic data, which could be used to identify associations between lexical items </context>
</contexts>
<marker>Ahrenberg, Merkel, Andersson, 2002</marker>
<rawString>Lars Ahrenberg, Magnus Merkel, and Mikael Andersson. 2002. A system for incremental and interactive word linking. In Proceedings from The Third International Conference on Language Resources and Evaluation (LREC-2002), pages 485-490, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Baldridge</author>
</authors>
<title>GROK - an open source natural language processing library.</title>
<date>2002</date>
<note>http://grok.sourceforge.net/.</note>
<contexts>
<context position="21100" citStr="Baldridge, 2002" startWordPosition="3504" endWordPosition="3505">on clue which was weighted with a value of 0.1. The numbers in bold refer to the link clusters which would have been extracted using the clue alignment procedure from section 3. 5 Clue Alignment Experiments 5.1 The Setup We applied the &amp;quot;clue aligner&amp;quot; to one of our parallel corpora from the PLUG project (Sagvall Hein, 1999), a novel by Saul Bellow &amp;quot;To Jerusalem and back: a personal account&amp;quot; with about 170,000 words in English and Swedish. The English portion of the corpus has been tagged automatically with POS tags by the English maximum entropy tagger in the open-source software package Grok (Baldridge, 2002). The same package was used for shallow parsing of the English sentences. The Swedish portion was tagged by the Ngrambased TnT-tagger (Brants, 2000) which was trained for Swedish on the SUC corpus (Megyesi, 2001). Furthermore, we used a rule-based analyzer for syntactic parsing (Megyesi, 2002). Our basic alignment applies two association clues: the Dice coefficient and the longest common subsequence ratio (LCSR). Both clues have been weighted uniformly with a value of 0.5. The threshold for the Dice coefficient has been set to 0.3 and the minimal co-occurrence frequency to 2. The threshold of </context>
</contexts>
<marker>Baldridge, 2002</marker>
<rawString>Jason Baldridge. 2002. GROK - an open source natural language processing library. http://grok.sourceforge.net/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT - a statistical part-ofspeech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Applied Natural Language Processing Conference ANLP2000,</booktitle>
<location>Seattle, Washington.</location>
<contexts>
<context position="21248" citStr="Brants, 2000" startWordPosition="3528" endWordPosition="3529"> procedure from section 3. 5 Clue Alignment Experiments 5.1 The Setup We applied the &amp;quot;clue aligner&amp;quot; to one of our parallel corpora from the PLUG project (Sagvall Hein, 1999), a novel by Saul Bellow &amp;quot;To Jerusalem and back: a personal account&amp;quot; with about 170,000 words in English and Swedish. The English portion of the corpus has been tagged automatically with POS tags by the English maximum entropy tagger in the open-source software package Grok (Baldridge, 2002). The same package was used for shallow parsing of the English sentences. The Swedish portion was tagged by the Ngrambased TnT-tagger (Brants, 2000) which was trained for Swedish on the SUC corpus (Megyesi, 2001). Furthermore, we used a rule-based analyzer for syntactic parsing (Megyesi, 2002). Our basic alignment applies two association clues: the Dice coefficient and the longest common subsequence ratio (LCSR). Both clues have been weighted uniformly with a value of 0.5. The threshold for the Dice coefficient has been set to 0.3 and the minimal co-occurrence frequency to 2. The threshold of LCSR scores has been set to 0.4 and the minimal token length to 3 characters.5 We certainly wanted to test the ability of finding phrasal links Ther</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. TnT - a statistical part-ofspeech tagger. In Proceedings of the Sixth Applied Natural Language Processing Conference ANLP2000, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djoerd Hiemstra</author>
</authors>
<title>Multilingual domain modeling in Twenty-One: Automatic creation of a bidirectional translation lexicon from a parallel corpus.</title>
<date>1998</date>
<booktitle>In Peter-Arno Coppen, Hans van Halteren, and Lisanne Teunissen, editors, Proceedings of the eighth CLIN meeting,</booktitle>
<pages>41--58</pages>
<contexts>
<context position="4595" citStr="Hiemstra, 1998" startWordPosition="708" endWordPosition="709">ally based on plain text items only. Linguistic data, which could be used to identify associations between lexical items are often ignored. Linguistic tools such as part-of-speech taggers, (shallow) parsers, named-entity recognizers become more and more robust and available for more languages. Linguistic information including contextual features could be used to improve alignment strategies. The third problem, alignment recovery, is a search problem. Using the alignment model and its parameters, we have to find the optimal alignment for a given pair of source and target language segments. In (Hiemstra, 1998), the author points out that a sentence pair with a maximum of n token units in both sentences has n! possible alignments in a simple directed alignment model with a fixed tokenization. Furthermore, a search strategy becomes very complex if we allow dyn am i c tokeni zati on borders (overlapping N- gram s, inclusions), which leads us not only to a larger number of possible combinations but also to the problem of comparing alignments with variable length (number of links) The clue alignment approach, which we propose here, addresses the three problems which were mentioned above. The approach al</context>
</contexts>
<marker>Hiemstra, 1998</marker>
<rawString>Djoerd Hiemstra. 1998. Multilingual domain modeling in Twenty-One: Automatic creation of a bidirectional translation lexicon from a parallel corpus. In Peter-Arno Coppen, Hans van Halteren, and Lisanne Teunissen, editors, Proceedings of the eighth CLIN meeting, pages 41-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Megyesi</author>
</authors>
<title>Comparing data-driven learning algorithms for POS tagging of swedish.</title>
<date>2001</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>151--158</pages>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA, USA.</location>
<contexts>
<context position="21312" citStr="Megyesi, 2001" startWordPosition="3539" endWordPosition="3540"> Setup We applied the &amp;quot;clue aligner&amp;quot; to one of our parallel corpora from the PLUG project (Sagvall Hein, 1999), a novel by Saul Bellow &amp;quot;To Jerusalem and back: a personal account&amp;quot; with about 170,000 words in English and Swedish. The English portion of the corpus has been tagged automatically with POS tags by the English maximum entropy tagger in the open-source software package Grok (Baldridge, 2002). The same package was used for shallow parsing of the English sentences. The Swedish portion was tagged by the Ngrambased TnT-tagger (Brants, 2000) which was trained for Swedish on the SUC corpus (Megyesi, 2001). Furthermore, we used a rule-based analyzer for syntactic parsing (Megyesi, 2002). Our basic alignment applies two association clues: the Dice coefficient and the longest common subsequence ratio (LCSR). Both clues have been weighted uniformly with a value of 0.5. The threshold for the Dice coefficient has been set to 0.3 and the minimal co-occurrence frequency to 2. The threshold of LCSR scores has been set to 0.4 and the minimal token length to 3 characters.5 We certainly wanted to test the ability of finding phrasal links Therefore, both association clues have been calculated for pairs of </context>
</contexts>
<marker>Megyesi, 2001</marker>
<rawString>Beata Megyesi. 2001. Comparing data-driven learning algorithms for POS tagging of swedish. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2001), pages 151-158, Carnegie Mellon University, Pittsburgh, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Megyesi</author>
</authors>
<title>Shallow parsing with POS taggers and linguistic features.</title>
<date>2002</date>
<journal>Journal of Machine Learning Research: Special Issue on Shallow Parsing,</journal>
<pages>2--639</pages>
<contexts>
<context position="21394" citStr="Megyesi, 2002" startWordPosition="3551" endWordPosition="3552">project (Sagvall Hein, 1999), a novel by Saul Bellow &amp;quot;To Jerusalem and back: a personal account&amp;quot; with about 170,000 words in English and Swedish. The English portion of the corpus has been tagged automatically with POS tags by the English maximum entropy tagger in the open-source software package Grok (Baldridge, 2002). The same package was used for shallow parsing of the English sentences. The Swedish portion was tagged by the Ngrambased TnT-tagger (Brants, 2000) which was trained for Swedish on the SUC corpus (Megyesi, 2001). Furthermore, we used a rule-based analyzer for syntactic parsing (Megyesi, 2002). Our basic alignment applies two association clues: the Dice coefficient and the longest common subsequence ratio (LCSR). Both clues have been weighted uniformly with a value of 0.5. The threshold for the Dice coefficient has been set to 0.3 and the minimal co-occurrence frequency to 2. The threshold of LCSR scores has been set to 0.4 and the minimal token length to 3 characters.5 We certainly wanted to test the ability of finding phrasal links Therefore, both association clues have been calculated for pairs of multi-word units (MWUs). MWUs may overlap with others or may be included in other </context>
</contexts>
<marker>Megyesi, 2002</marker>
<rawString>Beata Megyesi. 2002. Shallow parsing with POS taggers and linguistic features. Journal of Machine Learning Research: Special Issue on Shallow Parsing, (2):639-668.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic evaluation and uniform filter cascades for inducing N-best translation lexicons.</title>
<date>1995</date>
<booktitle>In Proceedings of the 3rd Workshop on Very Large Corpora,</booktitle>
<location>Boston/Massachusetts.</location>
<contexts>
<context position="2529" citStr="Melamed, 1995" startWordPosition="393" endWordPosition="394">pproaches, the estimation approach which is used in, e.g., statistical machine translation, and the association approach which is used in, e.g., automatic extraction of bilingual terminology. In the estimation approach, alignment parameters are modeled as hidden parameters in a statistical translation model (Och and Ney, 2000). Association approaches base the alignment on similarity measures and association tests such as Dice scores (Smadj a et al., 1996; Tiedemann, 1999), t-scores (Ahrenberg et al., 1998) log-likelihood measures (Tufis and Barbu, 2002), and longest common subsequence ratios (Melamed, 1995). One of the main difficulties in all alignment strategies is the identification of appropriate units in the source and the target language to be aligned. This task is hard even for human experts as can be seen in the detailed guidelines which are required 339 for manual alignments (Merkel, 1999; Melamed, 1998). Many translation relations involve multiword units such as phrasal compounds, idiomatic expressions, and complex terms. Syntactic shifts can also require the consideration of a context larger than a single word. Some items are not translated at all. Splitting source and target language</context>
</contexts>
<marker>Melamed, 1995</marker>
<rawString>I. Dan Melamed. 1995. Automatic evaluation and uniform filter cascades for inducing N-best translation lexicons. In Proceedings of the 3rd Workshop on Very Large Corpora, Boston/Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Automatic discovery of noncompositional compounds in parallel data.</title>
<date>1997</date>
<booktitle>In Proceedings of the 2nd Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Providence.</location>
<contexts>
<context position="3626" citStr="Melamed, 1997" startWordPosition="558" endWordPosition="559">n of a context larger than a single word. Some items are not translated at all. Splitting source and target language texts into appropriate units for alignment (henceforth: tokenization) is often not possible without considering the translation relations. In other words, initial tokenization borders may change when the translation relations are investigated. Human aligners frequently expand token units when aligning sentences manually depending on the context (Ahrenberg et al., 2002). Previous approaches use either iterative procedures to re-estimate alignment parameters (Smadja et al., 1996; Melamed, 1997; Vogel et al., 2000) or preprocessing steps for the identification of token Ngrams (Ahrenberg et al., 1998; Tiedemann, 1999). In our approach, we combine simple techniques for prior tokenization with dynamic techniques during the alignment phase. The second problem of traditional word alignment approaches is the fact that parameter estimations are usually based on plain text items only. Linguistic data, which could be used to identify associations between lexical items are often ignored. Linguistic tools such as part-of-speech taggers, (shallow) parsers, named-entity recognizers become more a</context>
</contexts>
<marker>Melamed, 1997</marker>
<rawString>I. Dan Melamed. 1997. Automatic discovery of noncompositional compounds in parallel data. In Proceedings of the 2nd Conference on Empirical Methods in Natural Language Processing, Providence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Annotation style guide for the Blinker project, version 1.0. IRCS</title>
<date>1998</date>
<tech>Technical Report 98-06,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia.</location>
<contexts>
<context position="2841" citStr="Melamed, 1998" startWordPosition="445" endWordPosition="446">h and Ney, 2000). Association approaches base the alignment on similarity measures and association tests such as Dice scores (Smadj a et al., 1996; Tiedemann, 1999), t-scores (Ahrenberg et al., 1998) log-likelihood measures (Tufis and Barbu, 2002), and longest common subsequence ratios (Melamed, 1995). One of the main difficulties in all alignment strategies is the identification of appropriate units in the source and the target language to be aligned. This task is hard even for human experts as can be seen in the detailed guidelines which are required 339 for manual alignments (Merkel, 1999; Melamed, 1998). Many translation relations involve multiword units such as phrasal compounds, idiomatic expressions, and complex terms. Syntactic shifts can also require the consideration of a context larger than a single word. Some items are not translated at all. Splitting source and target language texts into appropriate units for alignment (henceforth: tokenization) is often not possible without considering the translation relations. In other words, initial tokenization borders may change when the translation relations are investigated. Human aligners frequently expand token units when aligning sentence</context>
</contexts>
<marker>Melamed, 1998</marker>
<rawString>I. Dan Melamed. 1998. Annotation style guide for the Blinker project, version 1.0. IRCS Technical Report 98-06, University of Pennsylvania, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Magnus Merkel</author>
</authors>
<title>Annotation style guide for the PLUG link annotator.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>Linkoping University, Linkoping.</institution>
<contexts>
<context position="2825" citStr="Merkel, 1999" startWordPosition="443" endWordPosition="444">tion model (Och and Ney, 2000). Association approaches base the alignment on similarity measures and association tests such as Dice scores (Smadj a et al., 1996; Tiedemann, 1999), t-scores (Ahrenberg et al., 1998) log-likelihood measures (Tufis and Barbu, 2002), and longest common subsequence ratios (Melamed, 1995). One of the main difficulties in all alignment strategies is the identification of appropriate units in the source and the target language to be aligned. This task is hard even for human experts as can be seen in the detailed guidelines which are required 339 for manual alignments (Merkel, 1999; Melamed, 1998). Many translation relations involve multiword units such as phrasal compounds, idiomatic expressions, and complex terms. Syntactic shifts can also require the consideration of a context larger than a single word. Some items are not translated at all. Splitting source and target language texts into appropriate units for alignment (henceforth: tokenization) is often not possible without considering the translation relations. In other words, initial tokenization borders may change when the translation relations are investigated. Human aligners frequently expand token units when a</context>
<context position="23150" citStr="Merkel, 1999" startWordPosition="3846" endWordPosition="3847"> clue patterns which where introduced at the end of section 4: POS full, POS coarse, Phrase, Position. POS clues have been normalized with a weight of 0.5. Relative position and phrase type labels bear much less information about specific words and phrases than POS tags, therefore, a lower weight of 0.1 was chosen for these two clues. 5.2 The results For the evaluation, we used an existing gold standard which was produced within the PLUG project (Ahrenberg et al., 1999). The gold standard consists of 500 randomly sampled items which have been aligned manually according to detailed guidelines (Merkel, 1999). Results are measured using fine-grained metrics for precision and recall (Ahrenberg et al., 2000) and a balanced Fmeasure. The following table summarizes the results of some alignment experiments using different sets of clues (all values in %):6 adding clues precision recall F basic 79.737 41.695 54.757 + POS full 74.311 49.554 59.458 + POS coarse 69.854 57.279 62.945 + phrase 78.289 45.122 57.249 + position 81.939 44.703 57.847 + all 74.749 63.730 68.801 The values in the table above show a clear improvement, mainly in recall, of the results when additional clues have been applied. The impa</context>
</contexts>
<marker>Merkel, 1999</marker>
<rawString>Magnus Merkel. 1999. Annotation style guide for the PLUG link annotator. Technical report, Linkoping University, Linkoping.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="2243" citStr="Och and Ney, 2000" startWordPosition="349" endWordPosition="352">d the optimal alignment of words and phrases for a given translation according to the model M and its parameters (alignment recovery). Modeling the relations between lexical units of translated texts is not a trivial task due to the diversity of natural languages. There are generally two approaches, the estimation approach which is used in, e.g., statistical machine translation, and the association approach which is used in, e.g., automatic extraction of bilingual terminology. In the estimation approach, alignment parameters are modeled as hidden parameters in a statistical translation model (Och and Ney, 2000). Association approaches base the alignment on similarity measures and association tests such as Dice scores (Smadj a et al., 1996; Tiedemann, 1999), t-scores (Ahrenberg et al., 1998) log-likelihood measures (Tufis and Barbu, 2002), and longest common subsequence ratios (Melamed, 1995). One of the main difficulties in all alignment strategies is the identification of appropriate units in the source and the target language to be aligned. This task is hard even for human experts as can be seen in the detailed guidelines which are required 339 for manual alignments (Merkel, 1999; Melamed, 1998). </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Sagvall HeM</author>
</authors>
<title>The PLUG Project: Parallel corpora in Linkoping, Uppsala, and Goteborg: Aims and achievements.</title>
<date>1999</date>
<tech>Technical Report 16,</tech>
<institution>Department of Linguistics, University of Uppsala.</institution>
<marker>HeM, 1999</marker>
<rawString>Anna Sagvall HeM. 1999. The PLUG Project: Parallel corpora in Linkoping, Uppsala, and Goteborg: Aims and achievements. Technical Report 16, Department of Linguistics, University of Uppsala.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
<author>Kathleen R McKeown</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>1--38</pages>
<contexts>
<context position="3611" citStr="Smadja et al., 1996" startWordPosition="554" endWordPosition="557">uire the consideration of a context larger than a single word. Some items are not translated at all. Splitting source and target language texts into appropriate units for alignment (henceforth: tokenization) is often not possible without considering the translation relations. In other words, initial tokenization borders may change when the translation relations are investigated. Human aligners frequently expand token units when aligning sentences manually depending on the context (Ahrenberg et al., 2002). Previous approaches use either iterative procedures to re-estimate alignment parameters (Smadja et al., 1996; Melamed, 1997; Vogel et al., 2000) or preprocessing steps for the identification of token Ngrams (Ahrenberg et al., 1998; Tiedemann, 1999). In our approach, we combine simple techniques for prior tokenization with dynamic techniques during the alignment phase. The second problem of traditional word alignment approaches is the fact that parameter estimations are usually based on plain text items only. Linguistic data, which could be used to identify associations between lexical items are often ignored. Linguistic tools such as part-of-speech taggers, (shallow) parsers, named-entity recognizer</context>
</contexts>
<marker>Smadja, McKeown, Hatzivassiloglou, 1996</marker>
<rawString>Frank Smadja, Kathleen R. McKeown, and Vasileios Hatzivassiloglou. 1996. Translating collocations for bilingual lexicons: A statistical approach. Computational Linguistics, 22(1), pages 1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorg Tiedemann</author>
</authors>
<title>Word alignment - step by step.</title>
<date>1999</date>
<booktitle>In Proceedings of the 12th Nordic Conference on Computational Linguistics NODALIDA99,</booktitle>
<pages>216--227</pages>
<institution>University of Trondheim,</institution>
<contexts>
<context position="2391" citStr="Tiedemann, 1999" startWordPosition="374" endWordPosition="375">lations between lexical units of translated texts is not a trivial task due to the diversity of natural languages. There are generally two approaches, the estimation approach which is used in, e.g., statistical machine translation, and the association approach which is used in, e.g., automatic extraction of bilingual terminology. In the estimation approach, alignment parameters are modeled as hidden parameters in a statistical translation model (Och and Ney, 2000). Association approaches base the alignment on similarity measures and association tests such as Dice scores (Smadj a et al., 1996; Tiedemann, 1999), t-scores (Ahrenberg et al., 1998) log-likelihood measures (Tufis and Barbu, 2002), and longest common subsequence ratios (Melamed, 1995). One of the main difficulties in all alignment strategies is the identification of appropriate units in the source and the target language to be aligned. This task is hard even for human experts as can be seen in the detailed guidelines which are required 339 for manual alignments (Merkel, 1999; Melamed, 1998). Many translation relations involve multiword units such as phrasal compounds, idiomatic expressions, and complex terms. Syntactic shifts can also re</context>
<context position="3751" citStr="Tiedemann, 1999" startWordPosition="579" endWordPosition="580"> into appropriate units for alignment (henceforth: tokenization) is often not possible without considering the translation relations. In other words, initial tokenization borders may change when the translation relations are investigated. Human aligners frequently expand token units when aligning sentences manually depending on the context (Ahrenberg et al., 2002). Previous approaches use either iterative procedures to re-estimate alignment parameters (Smadja et al., 1996; Melamed, 1997; Vogel et al., 2000) or preprocessing steps for the identification of token Ngrams (Ahrenberg et al., 1998; Tiedemann, 1999). In our approach, we combine simple techniques for prior tokenization with dynamic techniques during the alignment phase. The second problem of traditional word alignment approaches is the fact that parameter estimations are usually based on plain text items only. Linguistic data, which could be used to identify associations between lexical items are often ignored. Linguistic tools such as part-of-speech taggers, (shallow) parsers, named-entity recognizers become more and more robust and available for more languages. Linguistic information including contextual features could be used to improv</context>
</contexts>
<marker>Tiedemann, 1999</marker>
<rawString>Jorg Tiedemann. 1999. Word alignment - step by step. In Proceedings of the 12th Nordic Conference on Computational Linguistics NODALIDA99, pages 216-227, University of Trondheim, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tufis</author>
<author>Ana-Maria Barbu</author>
</authors>
<title>Lexical token alignment: Experiments, results and applications.</title>
<date>2002</date>
<booktitle>In Proceedings from The Third International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<pages>458--465</pages>
<location>Las Palmas,</location>
<contexts>
<context position="2474" citStr="Tufis and Barbu, 2002" startWordPosition="383" endWordPosition="386">o the diversity of natural languages. There are generally two approaches, the estimation approach which is used in, e.g., statistical machine translation, and the association approach which is used in, e.g., automatic extraction of bilingual terminology. In the estimation approach, alignment parameters are modeled as hidden parameters in a statistical translation model (Och and Ney, 2000). Association approaches base the alignment on similarity measures and association tests such as Dice scores (Smadj a et al., 1996; Tiedemann, 1999), t-scores (Ahrenberg et al., 1998) log-likelihood measures (Tufis and Barbu, 2002), and longest common subsequence ratios (Melamed, 1995). One of the main difficulties in all alignment strategies is the identification of appropriate units in the source and the target language to be aligned. This task is hard even for human experts as can be seen in the detailed guidelines which are required 339 for manual alignments (Merkel, 1999; Melamed, 1998). Many translation relations involve multiword units such as phrasal compounds, idiomatic expressions, and complex terms. Syntactic shifts can also require the consideration of a context larger than a single word. Some items are not </context>
</contexts>
<marker>Tufis, Barbu, 2002</marker>
<rawString>Dan Tufis and Ana-Maria Barbu. 2002. Lexical token alignment: Experiments, results and applications. In Proceedings from The Third International Conference on Language Resources and Evaluation (LREC-2002), pages 458-465, Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Franz Josef Och</author>
<author>Christoph Tillmann</author>
<author>Sonja Niel3en</author>
<author>Hassan Sawaf</author>
<author>Hermann Ney</author>
</authors>
<title>Verbmobil: Foundations of Speech-to-Speech Translation, chapter Statistical Methods for Machine Translation.</title>
<date>2000</date>
<publisher>Springer Verlag,</publisher>
<location>Berlin.</location>
<marker>Vogel, Och, Tillmann, Niel3en, Sawaf, Ney, 2000</marker>
<rawString>Stephan Vogel, Franz Josef Och, Christoph Tillmann, Sonja Niel3en, Hassan Sawaf, and Hermann Ney, 2000. Verbmobil: Foundations of Speech-to-Speech Translation, chapter Statistical Methods for Machine Translation. Springer Verlag, Berlin.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>