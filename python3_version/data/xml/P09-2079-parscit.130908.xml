<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.153778">
<title confidence="0.99054">
Generalizing Dependency Features for Opinion Mining
</title>
<author confidence="0.962166">
Mahesh Joshi&apos; and Carolyn Penstein-Ros´e&apos;,2
</author>
<affiliation confidence="0.981118666666667">
&apos;Language Technologies Institute
2Human-Computer Interaction Institute
Carnegie Mellon University, Pittsburgh, PA, USA
</affiliation>
<email confidence="0.999392">
{maheshj,cprose}@cs.cmu.edu
</email>
<sectionHeader confidence="0.997397" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998898833333333">
We explore how features based on syntac-
tic dependency relations can be utilized to
improve performance on opinion mining.
Using a transformation of dependency re-
lation triples, we convert them into “com-
posite back-off features” that generalize
better than the regular lexicalized depen-
dency relation features. Experiments com-
paring our approach with several other ap-
proaches that generalize dependency fea-
tures or ngrams demonstrate the utility of
composite back-off features.
</bodyText>
<sectionHeader confidence="0.999389" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999944818181818">
Online product reviews are a crucial source of
opinions about a product, coming from the peo-
ple who have experienced it first-hand. However,
the task of a potential buyer is complicated by the
sheer number of reviews posted online for a prod-
uct of his/her interest. Opinion mining, or sen-
timent analysis (Pang and Lee, 2008) in product
reviews, in part, aims at automatically processing
a large number of such product reviews to identify
opinionated statements, and to classify them into
having either a positive or negative polarity.
One of the most popular techniques used for
opinion mining is that of supervised machine
learning, for which, many different lexical, syntac-
tic and knowledge-based feature representations
have been explored in the literature (Dave et al.,
2003; Gamon, 2004; Matsumoto et al., 2005; Ng
et al., 2006). However, the use of syntactic fea-
tures for opinion mining has achieved varied re-
sults. In our work, we show that by altering
syntactic dependency relation triples in a partic-
ular way (namely, “backing off” only the head
word in a dependency relation to its part-of-speech
tag), they generalize better and yield a significant
improvement on the task of identifying opinions
from product reviews. In effect, this work demon-
strates a better way to utilize syntactic dependency
relations for opinion mining.
In the remainder of the paper, we first discuss
related work. We then motivate our approach and
describe the composite back-off features, followed
by experimental results, discussion and future di-
rections for our work.
</bodyText>
<sectionHeader confidence="0.999918" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999929870967742">
The use of syntactic or deep linguistic features for
opinion mining has yielded mixed results in the lit-
erature so far. On the positive side, Gamon (2004)
found that the use of deep linguistic features ex-
tracted from phrase structure trees (which include
syntactic dependency relations) yield significant
improvements on the task of predicting satisfac-
tion ratings in customer feedback data. Mat-
sumoto et al. (2005) show that when using fre-
quently occurring sub-trees obtained from depen-
dency relation parse trees as features for machine
learning, significant improvement in performance
is obtained on the task of classifying movie re-
views as having positive or negative polarity. Fi-
nally, Wilson et al. (2004) use several different
features extracted from dependency parse trees to
improve performance on the task of predicting the
strength of opinion phrases.
On the flip side, Dave et al. (2003) found
that for the task of polarity prediction, adding
adjective-noun dependency relationships as fea-
tures does not provide any benefit over a sim-
ple bag-of-words based feature space. Ng et al.
(2006) proposed that rather than focusing on just
adjective-noun relationships, the subject-verb and
verb-object relationships should also be consid-
ered for polarity classification. However, they ob-
served that the addition of these dependency re-
lationships does not improve performance over a
feature space that includes unigrams, bigrams and
trigrams.
</bodyText>
<page confidence="0.993609">
313
</page>
<note confidence="0.92602">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 313–316,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999920625">
One difference that seems to separate the suc-
cesses from the failures is that of using the en-
tire set of dependency relations obtained from a
dependency parser and allowing the learning al-
gorithm to generalize, rather than picking a small
subset of dependency relations manually. How-
ever, in such a situation, one critical issue might be
the sparseness of the very specific linguistic fea-
tures, which may cause the classifier learned from
such features to not generalize. Features based on
dependency relations provide a nice way to enable
generalization to the right extent through utiliza-
tion of their structural aspect. In the next section,
we motivate this idea in the context of our task,
from a linguistic as well as machine learning per-
spective.
</bodyText>
<sectionHeader confidence="0.982073" genericHeader="method">
3 Identifying Opinionated Sentences
</sectionHeader>
<bodyText confidence="0.999986736842105">
We focus on the problem of automatically identi-
fying whether a sentence in a product review con-
tains an opinion about the product or one of its
features. We use the definition of this task as for-
mulated by Hu and Liu (2004) on Amazon.com
and CNet.com product reviews for five different
products. Their definition of an opinion sentence
is reproduced here verbatim: “If a sentence con-
tains one or more product features and one or
more opinion words, then the sentence is called an
opinion sentence.” Any other sentence in a review
that does not fit the above definition of an opinion
sentence is considered as a non-opinion sentence.
In general, these can be expected to be verifiable
statements or facts such as product specifications
and so on.
Before motivating the use of dependency rela-
tions as features for our task, a brief overview
about dependency relations follows.
</bodyText>
<subsectionHeader confidence="0.998581">
3.1 Dependency Relations
</subsectionHeader>
<bodyText confidence="0.9999462">
The dependency parse for a given sentence is es-
sentially a set of triplets or triples, each of which is
composed of a grammatical relation and the pair of
words from the sentence among which the gram-
matical relation holds ({reli, wj, wkb where reli
is the dependency relation among words wj and
wk). The set of dependency relations is specific
to a given parser – we use the Stanford parser1 for
computing dependency relations. The word wj is
usually referred to as the head word in the depen-
</bodyText>
<footnote confidence="0.8041355">
1http://nlp.stanford.edu/software/
lex-parser.shtml
</footnote>
<bodyText confidence="0.9934145">
dency triple, and the word wk is usually referred
to as the modifier word.
One straightforward way to use depen-
dency relations as features for machine
learning is to generate features of the form
RELATION HEAD MODIFIER and use them in a
standard bag-of-words type binary or frequency-
based representation. The indices of the head and
modifier words are dropped for the obvious reason
that one does not expect them to generalize across
sentences. We refer to such features as lexicalized
dependency relation features.
</bodyText>
<subsectionHeader confidence="0.989791">
3.2 Motivation for our Approach
</subsectionHeader>
<bodyText confidence="0.9949455">
Consider the following examples (these are made-
up examples for the purpose of keeping the dis-
cussion succinct, but still capture the essence of
our approach):
</bodyText>
<listItem confidence="0.623852666666667">
(i) This is a great camera!
(ii) Despite its few negligible flaws, this really
great mp3 player won my vote.
</listItem>
<bodyText confidence="0.9991998">
Both of these sentences have an adjectival mod-
ifier (amod) relationship, the first one having
amod camera great) and the second one hav-
ing amod player great). Although both of
these features are good indicators of opinion sen-
tences and are closely related, any machine learn-
ing algorithm that treats these features indepen-
dently will not be able to generalize their rela-
tionship to the opinion class. Also, any new test
sentence that contains a noun different from either
“camera” or “player” (for instance in the review
of a different electronic product), but is participat-
ing in a similar relationship, will not receive any
importance in favor of the opinion class – the ma-
chine learning algorithm may not have even seen
it in the training data.
Now consider the case where we “back off”
the head word in each of the above features to its
part-of-speech tag. This leads to a single feature:
amod NN great. This has two advantages: first,
the learning algorithm can now learn a weight for a
more general feature that has stronger evidence of
association with the opinion class, and second, any
new test sentence that contains an unseen noun in a
similar relationship with the adjective “great” will
receive some weight in favor of the opinion class.
This “back off” operation is a generalization of
the regular lexicalized dependency relations men-
tioned above. In the next section we describe all
such generalizations that we experimented with.
</bodyText>
<page confidence="0.998085">
314
</page>
<sectionHeader confidence="0.999559" genericHeader="method">
4 Methodology
</sectionHeader>
<bodyText confidence="0.999585857142857">
Composite Back-off Features: The idea behind
our composite back-off features is to create more
generalizable, but not overly general back-off fea-
tures by backing off to the part-of-speech (POS)
tag of either the head word or the modifier word
(but not both at once, as in Gamon (2004) and Wil-
son et al. (2004)) – hence the description “compos-
ite,” as there is a lexical part to the feature, coming
from one word, and a POS tag coming from the
other word, along with the dependency relation it-
self.
The two types of composite back-off features
that we create from lexicalized dependency triples
are as follows:
</bodyText>
<listItem confidence="0.986536714285714">
(i) h-bo: Here we use features of the form
{reli, POSj, wk} where the head word is replaced
by its POS tag, but the modifier word is retained.
(ii) m-bo: Here we use features of the form
{reli, wj, POSk}, where the modifier word is re-
placed by its POS tag, but the head word is re-
tained.
</listItem>
<bodyText confidence="0.999715615384616">
Our hypothesis is that the h-bo features will
perform better than purely lexicalized dependency
relations for reasons mentioned in Section 3.2
above. Although m-bo features also generalize
the lexicalized dependency features, in a relation
such as an adjectival modifier (discussed in Sec-
tion 3.2 above), the head noun is a better candi-
date to back-off for enabling generalization across
different products, rather than the modifier adjec-
tive. For this reason, we do not expect their per-
formance to be comparable to h-bo features.
We compare our composite back-off features
with other similar ways of generalizing depen-
dency relations and lexical ngrams that have been
tried in previous work. We describe these below.
Full Back-off Features: Both Gamon (2004)
and Wilson et al. (2004) utilize features based on
the following version of dependency relationships:
{reli, POSj, POSk}, where they “back off” both
the head word and the modifier word to their re-
spective POS tags (POSj and POSk). We refer
to this as hm-bo.
NGram Back-off Features: Similar to Mc-
Donald et al. (2007), we utilize backed-off ver-
sions of lexical bigrams and trigrams, where all
possible combinations of the words in the ngram
are replaced by their POS tags, creating features
such as wj POSk, POSj wk, POSj POSk for
each lexical bigram and similarly for trigrams. We
refer to these as bi-bo and tri-bo features respec-
tively.
In addition to these back-off approaches, we
also use regular lexical bigrams (bi), lexical tri-
grams (tri), POS bigrams (POS-bi), POS trigrams
(POS-tri) and lexicalized dependency relations
(lexdep) as features. While testing all of our fea-
ture sets, we evaluate each of them individually by
adding them to the basic set of unigram (uni) fea-
tures.
</bodyText>
<sectionHeader confidence="0.998083" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.8893935">
Details of our experiments and results follow.
5.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999764875">
We use the extended version of the Amazon.com /
CNet.com product reviews dataset released by Hu
and Liu (2004), available from their web page2.
We use a randomly chosen subset consisting of
2,200 review sentences (200 sentences each for
11 different products)3. The distribution is 1,053
(47.86%) opinion sentences and 1,147 (52.14%)
non-opinion sentences.
</bodyText>
<subsectionHeader confidence="0.999383">
5.2 Machine Learning Parameters
</subsectionHeader>
<bodyText confidence="0.999978571428572">
We have used the Support Vector Machine (SVM)
learner (Shawe-Taylor and Cristianini, 2000) from
the MinorThird Toolkit (Cohen, 2004), along with
the x-squared feature selection procedure, where
we reject features if their x-squared score is not
significant at the 0.05 level. For SVM, we use
the default linear kernel with all other parameters
also set to defaults. We perform 11-fold cross-
validation, where each test fold contains all the
sentences for one of the 11 products, and the sen-
tences for the remaining ten products are in the
corresponding training fold. Our results are re-
ported in terms of average accuracy and Cohen’s
kappa values across the 11 folds.
</bodyText>
<subsectionHeader confidence="0.8673">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.999890285714286">
Table 1 shows the full set of results from our ex-
periments. Our results are comparable to those re-
ported by Hu and Liu (2004) on the same task;
as well as those by Arora et al. (2009) on a sim-
ilar task of identifying qualified vs. bald claims
in product reviews. On the accuracy metric, the
composite features with the head word backed off
</bodyText>
<footnote confidence="0.999414">
2http://www.cs.uic.edu/˜liub/FBS/
sentiment-analysis.html
3http://www.cs.cmu.edu/˜maheshj/
datasets/acl09short.html
</footnote>
<page confidence="0.994334">
315
</page>
<table confidence="0.999592083333333">
Features Accuracy Kappa
uni .652 (±.048) .295 (±.049)
uni+bi .657 (±.066) .304 (±.089)
uni+bi-bo .650 (±.056) .299 (±.079)
uni+tri .655 (±.062) .306 (±.077)
uni+tri-bo .647 (±.051) .287 (±.075)
uni+POS-bi .676 (±.057) .349 (±.083)
uni+POS-tri .661 (±.050) .317 (±.064)
uni+lezdep .639 (±.055) .268 (±.079)
uni+hm-bo .670 (±.046) .336 (±.065)
uni+h-bo .679 (±.063) .351 (±.097)
uni+m-bo .657 (±.056) .308 (±.063)
</table>
<tableCaption confidence="0.999817">
Table 1: Shown are the average accuracy and Co-
</tableCaption>
<bodyText confidence="0.987167666666667">
hen’s kappa across 11 folds. Bold indicates statis-
tically significant improvements (p &lt; 0.05, two-
tailed pairwise T-test) over the (uni) baseline.
are the only ones that achieve a statistically signif-
icant improvement over the uni baseline. On the
kappa metric, using POS bigrams also achieves
a statistically significant improvement, as do the
composite h-bo features. None of the other back-
off strategies achieve a statistically significant im-
provement over uni, although numerically hm-bo
comes quite close to h-bo. Evaluation of these
two types of features by themselves (without un-
igrams) shows that h-bo are significantly better
than hm-bo at p &lt; 0.10 level. Regular lexical-
ized dependency relation features perform worse
than unigrams alone. These results thus demon-
strate that composite back-off features based on
dependency relations, where only the head word is
backed off to its POS tag present a useful alterna-
tive to encoding dependency relations as features
for opinion mining.
</bodyText>
<sectionHeader confidence="0.998906" genericHeader="conclusions">
6 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.999910166666667">
We have shown that for opinion mining in prod-
uct review data, a feature representation based on
a simple transformation (“backing off” the head
word in a dependency relation to its POS tag) of
syntactic dependency relations captures more gen-
eralizable and useful patterns in data than purely
lexicalized dependency relations, yielding a statis-
tically significant improvement.
The next steps that we are currently working
on include applying this approach to polarity clas-
sification. Also, the aspect of generalizing fea-
tures across different products is closely related
to fully supervised domain adaptation (Daum´e III,
2007), and we plan to combine our approach with
the idea from Daum´e III (2007) to gain insights
into whether the composite back-off features ex-
hibit different behavior in domain-general versus
domain-specific feature sub-spaces.
</bodyText>
<sectionHeader confidence="0.998675" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9664485">
This research is supported by National Science
Foundation grant IIS-0803482.
</bodyText>
<sectionHeader confidence="0.99858" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999856142857143">
Shilpa Arora, Mahesh Joshi, and Carolyn Ros´e. 2009.
Identifying Types of Claims in Online Customer Re-
views. In Proceedings ofNAACL 2009.
William Cohen. 2004. Minorthird: Methods for Iden-
tifying Names and Ontological Relations in Text us-
ing Heuristics for Inducing Regularities from Data.
Hal Daum´e III. 2007. Frustratingly Easy Domain
Adaptation. In Proceedings ofACL 2007.
Kushal Dave, Steve Lawrence, and David Pennock.
2003. Mining the Peanut Gallery: Opinion Ex-
traction and Semantic Classification of Product Re-
views. In Proceedings of WWW 2003.
Michael Gamon. 2004. Sentiment Classification on
Customer Feedback Data: Noisy Data, Large Fea-
ture Vectors, and the Role of Linguistic Analysis. In
Proceedings of COLING 2004.
Minqing Hu and Bing Liu. 2004. Mining and Summa-
rizing Customer Reviews. In Proceedings of ACM
SIGKDD 2004.
Shotaro Matsumoto, Hiroya Takamura, and Manabu
Okumura. 2005. Sentiment Classification Using
Word Sub-sequences and Dependency Sub-trees. In
Proceedings of the 9th PAKDD.
Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike
Wells, and Jeff Reynar. 2007. Structured Models for
Fine-to-Coarse Sentiment Analysis. In Proceedings
ofACL 2007.
Vincent Ng, Sajib Dasgupta, and S. M. Niaz Arifin.
2006. Examining the Role of Linguistic Knowledge
Sources in the Automatic Identification and Classi-
fication of Reviews. In Proceedings of the COL-
ING/ACL 2006.
Bo Pang and Lillian Lee. 2008. Opinion Mining and
Sentiment Analysis. Foundations and Trends in In-
formation Retrieval, 2(1–2).
John Shawe-Taylor and Nello Cristianini. 2000.
Support Vector Machines and Other Kernel-based
Learning Methods. Cambridge University Press.
Theresa Wilson, Janyce Wiebe, and Rebecca Hwa.
2004. Just How Mad Are You? Finding Strong
and Weak Opinion Clauses. In Proceedings ofAAAI
2004.
</reference>
<page confidence="0.999278">
316
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.865311">
<title confidence="0.995123">Generalizing Dependency Features for Opinion Mining</title>
<affiliation confidence="0.963403">Technologies Institute Interaction Institute</affiliation>
<address confidence="0.942277">Carnegie Mellon University, Pittsburgh, PA, USA</address>
<abstract confidence="0.999387">We explore how features based on syntactic dependency relations can be utilized to improve performance on opinion mining. Using a transformation of dependency relation triples, we convert them into “composite back-off features” that generalize better than the regular lexicalized dependency relation features. Experiments comparing our approach with several other approaches that generalize dependency features or ngrams demonstrate the utility of composite back-off features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shilpa Arora</author>
<author>Mahesh Joshi</author>
<author>Carolyn Ros´e</author>
</authors>
<title>Identifying Types of Claims in Online Customer Reviews.</title>
<date>2009</date>
<booktitle>In Proceedings ofNAACL</booktitle>
<marker>Arora, Joshi, Ros´e, 2009</marker>
<rawString>Shilpa Arora, Mahesh Joshi, and Carolyn Ros´e. 2009. Identifying Types of Claims in Online Customer Reviews. In Proceedings ofNAACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Cohen</author>
</authors>
<title>Minorthird: Methods for Identifying Names and Ontological Relations in Text using Heuristics for Inducing Regularities from Data.</title>
<date>2004</date>
<contexts>
<context position="11661" citStr="Cohen, 2004" startWordPosition="1881" endWordPosition="1882">ures. 5 Experiments and Results Details of our experiments and results follow. 5.1 Dataset We use the extended version of the Amazon.com / CNet.com product reviews dataset released by Hu and Liu (2004), available from their web page2. We use a randomly chosen subset consisting of 2,200 review sentences (200 sentences each for 11 different products)3. The distribution is 1,053 (47.86%) opinion sentences and 1,147 (52.14%) non-opinion sentences. 5.2 Machine Learning Parameters We have used the Support Vector Machine (SVM) learner (Shawe-Taylor and Cristianini, 2000) from the MinorThird Toolkit (Cohen, 2004), along with the x-squared feature selection procedure, where we reject features if their x-squared score is not significant at the 0.05 level. For SVM, we use the default linear kernel with all other parameters also set to defaults. We perform 11-fold crossvalidation, where each test fold contains all the sentences for one of the 11 products, and the sentences for the remaining ten products are in the corresponding training fold. Our results are reported in terms of average accuracy and Cohen’s kappa values across the 11 folds. 5.3 Results Table 1 shows the full set of results from our experi</context>
</contexts>
<marker>Cohen, 2004</marker>
<rawString>William Cohen. 2004. Minorthird: Methods for Identifying Names and Ontological Relations in Text using Heuristics for Inducing Regularities from Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Frustratingly Easy Domain Adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL</booktitle>
<marker>Daum´e, 2007</marker>
<rawString>Hal Daum´e III. 2007. Frustratingly Easy Domain Adaptation. In Proceedings ofACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David Pennock</author>
</authors>
<title>Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews.</title>
<date>2003</date>
<booktitle>In Proceedings of WWW</booktitle>
<contexts>
<context position="1522" citStr="Dave et al., 2003" startWordPosition="218" endWordPosition="221">ial buyer is complicated by the sheer number of reviews posted online for a product of his/her interest. Opinion mining, or sentiment analysis (Pang and Lee, 2008) in product reviews, in part, aims at automatically processing a large number of such product reviews to identify opinionated statements, and to classify them into having either a positive or negative polarity. One of the most popular techniques used for opinion mining is that of supervised machine learning, for which, many different lexical, syntactic and knowledge-based feature representations have been explored in the literature (Dave et al., 2003; Gamon, 2004; Matsumoto et al., 2005; Ng et al., 2006). However, the use of syntactic features for opinion mining has achieved varied results. In our work, we show that by altering syntactic dependency relation triples in a particular way (namely, “backing off” only the head word in a dependency relation to its part-of-speech tag), they generalize better and yield a significant improvement on the task of identifying opinions from product reviews. In effect, this work demonstrates a better way to utilize syntactic dependency relations for opinion mining. In the remainder of the paper, we first</context>
<context position="3215" citStr="Dave et al. (2003)" startWordPosition="488" endWordPosition="491">tions) yield significant improvements on the task of predicting satisfaction ratings in customer feedback data. Matsumoto et al. (2005) show that when using frequently occurring sub-trees obtained from dependency relation parse trees as features for machine learning, significant improvement in performance is obtained on the task of classifying movie reviews as having positive or negative polarity. Finally, Wilson et al. (2004) use several different features extracted from dependency parse trees to improve performance on the task of predicting the strength of opinion phrases. On the flip side, Dave et al. (2003) found that for the task of polarity prediction, adding adjective-noun dependency relationships as features does not provide any benefit over a simple bag-of-words based feature space. Ng et al. (2006) proposed that rather than focusing on just adjective-noun relationships, the subject-verb and verb-object relationships should also be considered for polarity classification. However, they observed that the addition of these dependency relationships does not improve performance over a feature space that includes unigrams, bigrams and trigrams. 313 Proceedings of the ACL-IJCNLP 2009 Conference Sh</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David Pennock. 2003. Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews. In Proceedings of WWW 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
</authors>
<title>Sentiment Classification on Customer Feedback Data: Noisy Data, Large Feature Vectors, and the Role of Linguistic Analysis.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="1535" citStr="Gamon, 2004" startWordPosition="222" endWordPosition="223">cated by the sheer number of reviews posted online for a product of his/her interest. Opinion mining, or sentiment analysis (Pang and Lee, 2008) in product reviews, in part, aims at automatically processing a large number of such product reviews to identify opinionated statements, and to classify them into having either a positive or negative polarity. One of the most popular techniques used for opinion mining is that of supervised machine learning, for which, many different lexical, syntactic and knowledge-based feature representations have been explored in the literature (Dave et al., 2003; Gamon, 2004; Matsumoto et al., 2005; Ng et al., 2006). However, the use of syntactic features for opinion mining has achieved varied results. In our work, we show that by altering syntactic dependency relation triples in a particular way (namely, “backing off” only the head word in a dependency relation to its part-of-speech tag), they generalize better and yield a significant improvement on the task of identifying opinions from product reviews. In effect, this work demonstrates a better way to utilize syntactic dependency relations for opinion mining. In the remainder of the paper, we first discuss rela</context>
<context position="8694" citStr="Gamon (2004)" startWordPosition="1391" endWordPosition="1392"> noun in a similar relationship with the adjective “great” will receive some weight in favor of the opinion class. This “back off” operation is a generalization of the regular lexicalized dependency relations mentioned above. In the next section we describe all such generalizations that we experimented with. 314 4 Methodology Composite Back-off Features: The idea behind our composite back-off features is to create more generalizable, but not overly general back-off features by backing off to the part-of-speech (POS) tag of either the head word or the modifier word (but not both at once, as in Gamon (2004) and Wilson et al. (2004)) – hence the description “composite,” as there is a lexical part to the feature, coming from one word, and a POS tag coming from the other word, along with the dependency relation itself. The two types of composite back-off features that we create from lexicalized dependency triples are as follows: (i) h-bo: Here we use features of the form {reli, POSj, wk} where the head word is replaced by its POS tag, but the modifier word is retained. (ii) m-bo: Here we use features of the form {reli, wj, POSk}, where the modifier word is replaced by its POS tag, but the head word</context>
<context position="10067" citStr="Gamon (2004)" startWordPosition="1625" endWordPosition="1626">e. Although m-bo features also generalize the lexicalized dependency features, in a relation such as an adjectival modifier (discussed in Section 3.2 above), the head noun is a better candidate to back-off for enabling generalization across different products, rather than the modifier adjective. For this reason, we do not expect their performance to be comparable to h-bo features. We compare our composite back-off features with other similar ways of generalizing dependency relations and lexical ngrams that have been tried in previous work. We describe these below. Full Back-off Features: Both Gamon (2004) and Wilson et al. (2004) utilize features based on the following version of dependency relationships: {reli, POSj, POSk}, where they “back off” both the head word and the modifier word to their respective POS tags (POSj and POSk). We refer to this as hm-bo. NGram Back-off Features: Similar to McDonald et al. (2007), we utilize backed-off versions of lexical bigrams and trigrams, where all possible combinations of the words in the ngram are replaced by their POS tags, creating features such as wj POSk, POSj wk, POSj POSk for each lexical bigram and similarly for trigrams. We refer to these as </context>
</contexts>
<marker>Gamon, 2004</marker>
<rawString>Michael Gamon. 2004. Sentiment Classification on Customer Feedback Data: Noisy Data, Large Feature Vectors, and the Role of Linguistic Analysis. In Proceedings of COLING 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and Summarizing Customer Reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of ACM SIGKDD</booktitle>
<contexts>
<context position="4909" citStr="Hu and Liu (2004)" startWordPosition="760" endWordPosition="763">which may cause the classifier learned from such features to not generalize. Features based on dependency relations provide a nice way to enable generalization to the right extent through utilization of their structural aspect. In the next section, we motivate this idea in the context of our task, from a linguistic as well as machine learning perspective. 3 Identifying Opinionated Sentences We focus on the problem of automatically identifying whether a sentence in a product review contains an opinion about the product or one of its features. We use the definition of this task as formulated by Hu and Liu (2004) on Amazon.com and CNet.com product reviews for five different products. Their definition of an opinion sentence is reproduced here verbatim: “If a sentence contains one or more product features and one or more opinion words, then the sentence is called an opinion sentence.” Any other sentence in a review that does not fit the above definition of an opinion sentence is considered as a non-opinion sentence. In general, these can be expected to be verifiable statements or facts such as product specifications and so on. Before motivating the use of dependency relations as features for our task, a</context>
<context position="11250" citStr="Hu and Liu (2004)" startWordPosition="1821" endWordPosition="1824">or trigrams. We refer to these as bi-bo and tri-bo features respectively. In addition to these back-off approaches, we also use regular lexical bigrams (bi), lexical trigrams (tri), POS bigrams (POS-bi), POS trigrams (POS-tri) and lexicalized dependency relations (lexdep) as features. While testing all of our feature sets, we evaluate each of them individually by adding them to the basic set of unigram (uni) features. 5 Experiments and Results Details of our experiments and results follow. 5.1 Dataset We use the extended version of the Amazon.com / CNet.com product reviews dataset released by Hu and Liu (2004), available from their web page2. We use a randomly chosen subset consisting of 2,200 review sentences (200 sentences each for 11 different products)3. The distribution is 1,053 (47.86%) opinion sentences and 1,147 (52.14%) non-opinion sentences. 5.2 Machine Learning Parameters We have used the Support Vector Machine (SVM) learner (Shawe-Taylor and Cristianini, 2000) from the MinorThird Toolkit (Cohen, 2004), along with the x-squared feature selection procedure, where we reject features if their x-squared score is not significant at the 0.05 level. For SVM, we use the default linear kernel wit</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. In Proceedings of ACM SIGKDD 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shotaro Matsumoto</author>
<author>Hiroya Takamura</author>
<author>Manabu Okumura</author>
</authors>
<title>Sentiment Classification Using Word Sub-sequences and Dependency Sub-trees.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th PAKDD.</booktitle>
<contexts>
<context position="1559" citStr="Matsumoto et al., 2005" startWordPosition="224" endWordPosition="227">sheer number of reviews posted online for a product of his/her interest. Opinion mining, or sentiment analysis (Pang and Lee, 2008) in product reviews, in part, aims at automatically processing a large number of such product reviews to identify opinionated statements, and to classify them into having either a positive or negative polarity. One of the most popular techniques used for opinion mining is that of supervised machine learning, for which, many different lexical, syntactic and knowledge-based feature representations have been explored in the literature (Dave et al., 2003; Gamon, 2004; Matsumoto et al., 2005; Ng et al., 2006). However, the use of syntactic features for opinion mining has achieved varied results. In our work, we show that by altering syntactic dependency relation triples in a particular way (namely, “backing off” only the head word in a dependency relation to its part-of-speech tag), they generalize better and yield a significant improvement on the task of identifying opinions from product reviews. In effect, this work demonstrates a better way to utilize syntactic dependency relations for opinion mining. In the remainder of the paper, we first discuss related work. We then motiva</context>
</contexts>
<marker>Matsumoto, Takamura, Okumura, 2005</marker>
<rawString>Shotaro Matsumoto, Hiroya Takamura, and Manabu Okumura. 2005. Sentiment Classification Using Word Sub-sequences and Dependency Sub-trees. In Proceedings of the 9th PAKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kerry Hannan</author>
<author>Tyler Neylon</author>
<author>Mike Wells</author>
<author>Jeff Reynar</author>
</authors>
<title>Structured Models for Fine-to-Coarse Sentiment Analysis.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="10384" citStr="McDonald et al. (2007)" startWordPosition="1677" endWordPosition="1681">eason, we do not expect their performance to be comparable to h-bo features. We compare our composite back-off features with other similar ways of generalizing dependency relations and lexical ngrams that have been tried in previous work. We describe these below. Full Back-off Features: Both Gamon (2004) and Wilson et al. (2004) utilize features based on the following version of dependency relationships: {reli, POSj, POSk}, where they “back off” both the head word and the modifier word to their respective POS tags (POSj and POSk). We refer to this as hm-bo. NGram Back-off Features: Similar to McDonald et al. (2007), we utilize backed-off versions of lexical bigrams and trigrams, where all possible combinations of the words in the ngram are replaced by their POS tags, creating features such as wj POSk, POSj wk, POSj POSk for each lexical bigram and similarly for trigrams. We refer to these as bi-bo and tri-bo features respectively. In addition to these back-off approaches, we also use regular lexical bigrams (bi), lexical trigrams (tri), POS bigrams (POS-bi), POS trigrams (POS-tri) and lexicalized dependency relations (lexdep) as features. While testing all of our feature sets, we evaluate each of them i</context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike Wells, and Jeff Reynar. 2007. Structured Models for Fine-to-Coarse Sentiment Analysis. In Proceedings ofACL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
<author>Sajib Dasgupta</author>
<author>S M Niaz Arifin</author>
</authors>
<title>Examining the Role of Linguistic Knowledge Sources in the Automatic Identification and Classification of Reviews.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL</booktitle>
<contexts>
<context position="1577" citStr="Ng et al., 2006" startWordPosition="228" endWordPosition="231">posted online for a product of his/her interest. Opinion mining, or sentiment analysis (Pang and Lee, 2008) in product reviews, in part, aims at automatically processing a large number of such product reviews to identify opinionated statements, and to classify them into having either a positive or negative polarity. One of the most popular techniques used for opinion mining is that of supervised machine learning, for which, many different lexical, syntactic and knowledge-based feature representations have been explored in the literature (Dave et al., 2003; Gamon, 2004; Matsumoto et al., 2005; Ng et al., 2006). However, the use of syntactic features for opinion mining has achieved varied results. In our work, we show that by altering syntactic dependency relation triples in a particular way (namely, “backing off” only the head word in a dependency relation to its part-of-speech tag), they generalize better and yield a significant improvement on the task of identifying opinions from product reviews. In effect, this work demonstrates a better way to utilize syntactic dependency relations for opinion mining. In the remainder of the paper, we first discuss related work. We then motivate our approach an</context>
<context position="3416" citStr="Ng et al. (2006)" startWordPosition="520" endWordPosition="523">ependency relation parse trees as features for machine learning, significant improvement in performance is obtained on the task of classifying movie reviews as having positive or negative polarity. Finally, Wilson et al. (2004) use several different features extracted from dependency parse trees to improve performance on the task of predicting the strength of opinion phrases. On the flip side, Dave et al. (2003) found that for the task of polarity prediction, adding adjective-noun dependency relationships as features does not provide any benefit over a simple bag-of-words based feature space. Ng et al. (2006) proposed that rather than focusing on just adjective-noun relationships, the subject-verb and verb-object relationships should also be considered for polarity classification. However, they observed that the addition of these dependency relationships does not improve performance over a feature space that includes unigrams, bigrams and trigrams. 313 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 313–316, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP One difference that seems to separate the successes from the failures is that of using the entire set of dependency rel</context>
</contexts>
<marker>Ng, Dasgupta, Arifin, 2006</marker>
<rawString>Vincent Ng, Sajib Dasgupta, and S. M. Niaz Arifin. 2006. Examining the Role of Linguistic Knowledge Sources in the Automatic Identification and Classification of Reviews. In Proceedings of the COLING/ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="1068" citStr="Pang and Lee, 2008" startWordPosition="149" endWordPosition="152"> “composite back-off features” that generalize better than the regular lexicalized dependency relation features. Experiments comparing our approach with several other approaches that generalize dependency features or ngrams demonstrate the utility of composite back-off features. 1 Introduction Online product reviews are a crucial source of opinions about a product, coming from the people who have experienced it first-hand. However, the task of a potential buyer is complicated by the sheer number of reviews posted online for a product of his/her interest. Opinion mining, or sentiment analysis (Pang and Lee, 2008) in product reviews, in part, aims at automatically processing a large number of such product reviews to identify opinionated statements, and to classify them into having either a positive or negative polarity. One of the most popular techniques used for opinion mining is that of supervised machine learning, for which, many different lexical, syntactic and knowledge-based feature representations have been explored in the literature (Dave et al., 2003; Gamon, 2004; Matsumoto et al., 2005; Ng et al., 2006). However, the use of syntactic features for opinion mining has achieved varied results. In</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval, 2(1–2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Support Vector Machines and Other Kernel-based Learning Methods.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="11619" citStr="Shawe-Taylor and Cristianini, 2000" startWordPosition="1873" endWordPosition="1876">ndividually by adding them to the basic set of unigram (uni) features. 5 Experiments and Results Details of our experiments and results follow. 5.1 Dataset We use the extended version of the Amazon.com / CNet.com product reviews dataset released by Hu and Liu (2004), available from their web page2. We use a randomly chosen subset consisting of 2,200 review sentences (200 sentences each for 11 different products)3. The distribution is 1,053 (47.86%) opinion sentences and 1,147 (52.14%) non-opinion sentences. 5.2 Machine Learning Parameters We have used the Support Vector Machine (SVM) learner (Shawe-Taylor and Cristianini, 2000) from the MinorThird Toolkit (Cohen, 2004), along with the x-squared feature selection procedure, where we reject features if their x-squared score is not significant at the 0.05 level. For SVM, we use the default linear kernel with all other parameters also set to defaults. We perform 11-fold crossvalidation, where each test fold contains all the sentences for one of the 11 products, and the sentences for the remaining ten products are in the corresponding training fold. Our results are reported in terms of average accuracy and Cohen’s kappa values across the 11 folds. 5.3 Results Table 1 sho</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2000</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2000. Support Vector Machines and Other Kernel-based Learning Methods. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Rebecca Hwa</author>
</authors>
<title>Just How Mad Are You? Finding Strong and Weak Opinion Clauses.</title>
<date>2004</date>
<booktitle>In Proceedings ofAAAI</booktitle>
<contexts>
<context position="3027" citStr="Wilson et al. (2004)" startWordPosition="458" endWordPosition="461">lts in the literature so far. On the positive side, Gamon (2004) found that the use of deep linguistic features extracted from phrase structure trees (which include syntactic dependency relations) yield significant improvements on the task of predicting satisfaction ratings in customer feedback data. Matsumoto et al. (2005) show that when using frequently occurring sub-trees obtained from dependency relation parse trees as features for machine learning, significant improvement in performance is obtained on the task of classifying movie reviews as having positive or negative polarity. Finally, Wilson et al. (2004) use several different features extracted from dependency parse trees to improve performance on the task of predicting the strength of opinion phrases. On the flip side, Dave et al. (2003) found that for the task of polarity prediction, adding adjective-noun dependency relationships as features does not provide any benefit over a simple bag-of-words based feature space. Ng et al. (2006) proposed that rather than focusing on just adjective-noun relationships, the subject-verb and verb-object relationships should also be considered for polarity classification. However, they observed that the add</context>
<context position="8719" citStr="Wilson et al. (2004)" startWordPosition="1394" endWordPosition="1398">r relationship with the adjective “great” will receive some weight in favor of the opinion class. This “back off” operation is a generalization of the regular lexicalized dependency relations mentioned above. In the next section we describe all such generalizations that we experimented with. 314 4 Methodology Composite Back-off Features: The idea behind our composite back-off features is to create more generalizable, but not overly general back-off features by backing off to the part-of-speech (POS) tag of either the head word or the modifier word (but not both at once, as in Gamon (2004) and Wilson et al. (2004)) – hence the description “composite,” as there is a lexical part to the feature, coming from one word, and a POS tag coming from the other word, along with the dependency relation itself. The two types of composite back-off features that we create from lexicalized dependency triples are as follows: (i) h-bo: Here we use features of the form {reli, POSj, wk} where the head word is replaced by its POS tag, but the modifier word is retained. (ii) m-bo: Here we use features of the form {reli, wj, POSk}, where the modifier word is replaced by its POS tag, but the head word is retained. Our hypothe</context>
<context position="10092" citStr="Wilson et al. (2004)" startWordPosition="1628" endWordPosition="1631">features also generalize the lexicalized dependency features, in a relation such as an adjectival modifier (discussed in Section 3.2 above), the head noun is a better candidate to back-off for enabling generalization across different products, rather than the modifier adjective. For this reason, we do not expect their performance to be comparable to h-bo features. We compare our composite back-off features with other similar ways of generalizing dependency relations and lexical ngrams that have been tried in previous work. We describe these below. Full Back-off Features: Both Gamon (2004) and Wilson et al. (2004) utilize features based on the following version of dependency relationships: {reli, POSj, POSk}, where they “back off” both the head word and the modifier word to their respective POS tags (POSj and POSk). We refer to this as hm-bo. NGram Back-off Features: Similar to McDonald et al. (2007), we utilize backed-off versions of lexical bigrams and trigrams, where all possible combinations of the words in the ngram are replaced by their POS tags, creating features such as wj POSk, POSj wk, POSj POSk for each lexical bigram and similarly for trigrams. We refer to these as bi-bo and tri-bo features</context>
</contexts>
<marker>Wilson, Wiebe, Hwa, 2004</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Rebecca Hwa. 2004. Just How Mad Are You? Finding Strong and Weak Opinion Clauses. In Proceedings ofAAAI 2004.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>