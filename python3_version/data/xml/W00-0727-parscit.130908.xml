<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000675">
<note confidence="0.814216">
In: Proceedings of CoNLL-2000 and LLL-2000, pages 133-135, Lisbon, Portugal, 2000.
</note>
<title confidence="0.985586">
Learning Syntactic Structures with XML
</title>
<author confidence="0.901789">
Herve Dejean
</author>
<affiliation confidence="0.640196">
Seminar fiir Sprachwissenschaft
</affiliation>
<address confidence="0.323828">
Universitat Tiibingen
</address>
<email confidence="0.51131">
dejeanOsfs.nphil.uni-tuebingen.de
</email>
<sectionHeader confidence="0.994169" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999872875">
We present the result of a symbolic machine
learning system for the CoNLL-2000 shared
task. This system, ALLiS, is based on theory
refinement. In this paper we want to show that
XML format not only offers a good framework
to annotate texts, but also provides a good for-.
malism and tools in order to learn (syntactic)
structures.
</bodyText>
<sectionHeader confidence="0.968015" genericHeader="keywords">
2 ALLiS
</sectionHeader>
<bodyText confidence="0.999468581818182">
ALLiS (Architecture for Learning Linguistic
Structure) (Deleon, 2000a), (Deleon, 2000b) is a
symbolic machine learning system. The learn-
ing system is based on theory refinement. It
tries to refine (to improve) an existing imperfect
grammar using operators such as contextualisa-
tion and lexicalisation (Section 4). ALLiS sepa-
rates the task of the generation of rules and the
task of the use of these rules (task of parsing).
First symbolic rules are learned and saved using
an own formalism, and in a second time, these
rules are converted into a proper formalism used
by a specific rule-based parser. The rules gen-
erated by ALLiS contain enough contextual in-
formation so that their conversions into other
formalisms is possible (Deleon, 2000b).
We present here the three tools we tested in
order to parse texts.
CASS : the CASS system (Abney, 1996) pro-
vides a very fast parser which uses Regular Ex-
pression Grammar. The inconvenient of this
system is twofold: first CASS only handles tags.
Some pre- and post-processings are needed.
Second, it is impossible to use contextual infor-
mation. Using CASS, it is thus difficult to im-
plement rules generated by the two refinement
operators used in ALLiS: contextualisation (in-
troduction of contexts) and lexicalisation (use
of the word level).
XFST : the Xerox finite State Tool (Kart-
tunen et al., 1997) offers a rich finite state for-
malism (operator of contextualisation, replace
operator). If the formalism is powerful enough,
the main problem with XFST is the number
of transducers generated by ALLiS. For each
context and each word occurring in the rules
learned by ALLiS corresponds a transducer.
The size of the final Regular Expression Gram-
mar is quite big and the compilation and pro-
cessing time keeps low. A phase of optimisation
would be required.
LT TTT : the last tool tried, LT TTT
(Grover et al., 1999), is a text tokenisation sys-
tem and toolset. One of the tools, fsgmatch
reads a grammar (also written in XML format)
which is used to annotate/parse XML texts. Us-
ing XML properties, the grammar has easily ac-
cess to all the levels of the document (word, tag,
phrase, and higher structures). The manipula-
tion/annotation of several structures (as in the
CoNLL-2000 shared task) is very easy. LT TTT
is a good trade-off between the rapidity of CASS
and the rich formalism of XFST.
We now explain how the LT TTT is used dur-
ing the learning and the parsing task.
</bodyText>
<sectionHeader confidence="0.915873" genericHeader="introduction">
3 Data and Learning Algorithm
</sectionHeader>
<bodyText confidence="0.9998677">
The training corpus is an XML document where
each structure is marked up (Table 1). Train-
ing corpus can contain other structures or in-
formation. Using XML tools, we can choose
which information we want to use. The DTD
used by ALLiS (Table 2) describes a document
composed of words (W) which compose phrases
(PHR), and a sequence of phrases composes a
sentence (S). This DTD should be updated in
order to take into account intermediate levels
</bodyText>
<page confidence="0.992349">
133
</page>
<figure confidence="0.999669166666667">
&lt;S&gt;
&lt;PHR C=&apos;NP&apos;&gt;
&lt;W C=&apos;NNP&apos;&gt;Mr.&lt;/W&gt;
&lt;W C=&apos;NNP&apos;&gt;Percival&lt;/W&gt;
&lt;/PHR&gt;
&lt;PHR C=&apos;VP&gt;
&lt;W C=&apos;VBD&apos;&gt;declined&lt;/W&gt;
&lt;W C=&apos;T0&apos;&gt;to&lt;/W&gt;
&lt;W C=&apos;VB&apos;&gt;comment&lt;/W&gt;
&lt;/PHR&gt;
&lt;W C=&apos;.&apos;&gt;.&lt;/W&gt;
&lt;/S&gt;
</figure>
<tableCaption confidence="0.954079">
Table 1: Example of training corpus.
</tableCaption>
<figure confidence="0.7375846">
&lt;!ELEMENT DOCS (#PCDATA I TEXT)* &gt;
&lt;!ELEMENT TEXT (SIPHRIW)+ &gt;
&lt;!ELEMENT (PHR W) + &gt;
&lt;!ELEMENT PHR (W) + &gt;
&lt;!ATTLIST PHR C CDATA &amp;quot; &amp;quot; &gt;
&lt;!ELEMENT W (#PCDATA) &gt;
&lt;!ATTLIST W C CDATA
S CDATA
BK CDATA
CAT CDATA &amp;quot; &amp;quot; &gt;
</figure>
<tableCaption confidence="0.985942">
Table 2: DTD used for the training corpus.
</tableCaption>
<bodyText confidence="0.999410863636364">
between the phrase and the sentence.
The learning method consists of finding con-
texts in which an element (tag or word) can
be associated to a specific category with high
confidence. Some elements do not need con-
texts and are themselves confident. In the case
an element requires contexts, these contexts
are computed by the use of queries which ex-
amine training corpus. XML Path Language
provides an easy way of addressing nodes of
an XML document. For example, the query
/TEXT/S/PHR [C= &apos;NP &apos;11W determines elements
W directly under an entity PHR with the
attribute C,&apos;NP&apos;, under the entities S and
TEXT. A query returns the indicated items one
by one until the set denoted by the query is ex-
hausted. The above query returns all the ele-
ments occurring in a phrase marked NP.
The next section provides some examples of
queries used during the learning task. (Grover
et al., 1999) describes the syntax of the LT XML
query language.
</bodyText>
<sectionHeader confidence="0.466225" genericHeader="method">
4 Examples of LT XML Queries
</sectionHeader>
<bodyText confidence="0.970920535714286">
The default category of a tag is given by the
ration between its number of occurrences in the
structure we want to recognise and the number
of occurrences in the training corpus. The two
following queries compute this ration for the tag
VBG and the NP structure:
*/ (PHR [C= &apos; &apos;] /W [C= &apos; VBG &apos;])
. */W [C= &apos; VBG &apos;]
The first query can be read as follows: element
W with the attribute C=&apos;VBG&apos; occurring in an
entity PHR with the attribute C=&apos;NP &apos; , this last
structure occurring anywhere in the document.
The second query counts all the occurrences of
the entity W with the attribute C= &apos;VBG&apos; any-
where in the document. If the ration is higher
than a threshold 0, then the tag is considered
as belonging to the structure. If not, we have
to use operators of specialisation.
The principle consists of enriching the query
so that the ratio 0 is higher than a given thresh-
old. Contextualisation introduces left and/or
right elements in the query. Lexicalisation uses
the word value and not only the tag. Since
the tag VBG is not reliable (it mainly occurs
in an VP structure), we have to look for larger
contexts. The following query returns the list
of the elements W occurring on the left of an
element W [C= &apos;VBG&apos;] in the same phrase NP
</bodyText>
<equation confidence="0.972922">
(PHR [C= &apos; NP &apos;] ).
PHR[C=&apos;NP&apos;] /(W! ,W[C=&apos;VBG&apos;])
</equation>
<bodyText confidence="0.998890166666667">
The tag DT is one the elements of this list. We
now try to find negative examples. The second
query looks for all the occurrences of the entity
W [C=&apos;VBG&apos;] which occur outside the NP struc-
ture in the same context: a tag DT occurring
before the tag VBG.
</bodyText>
<equation confidence="0.712269">
PHR[C=&apos;NP &apos;] /W[C=&apos;DT&apos;] ,W[C=&apos;VBG&apos;])
</equation>
<bodyText confidence="0.998184888888889">
Using the result of these two queries, a new ratio
is computed to determine whether the category
of VBG is reliable in this context (the answer
is affirmative). For some tags, the ratio still
remains below the threshold.
The last query shows that we can also have
access to the word itself: it looks for the word
operating tagged VBG inside a phrase cate-
gorised as NP:
</bodyText>
<page confidence="0.986194">
134
</page>
<note confidence="0.340121">
PHR [C= &apos; NP &apos; ] /W [C= &apos; VBG &apos; ] /#= &apos; operat ing &apos;
</note>
<bodyText confidence="0.999733">
Contexts in which the word occurs outside the
structure are also built, and the ratio is com-
puted in the same was as above.
</bodyText>
<sectionHeader confidence="0.433088" genericHeader="method">
5 Parsing with fsgmatch
</sectionHeader>
<bodyText confidence="0.997844625">
Once rules are learned, they are converted into
the formalism of the parser. Table 3 provides
an example of rules used by fsgmatch (Grover
et al., 1999). The rule consists of adding the
attributes CAT=&apos;AL&apos; S=&apos;NP&apos; (left adjunct of a
Noun Phrase(NP)) to each word with the at-
tribute C=&apos; VBG &apos; which occurs after a word with
the attribute C= &apos;DT &apos; .
</bodyText>
<figure confidence="0.748604166666667">
&lt;RULE name=&amp;quot;AL&amp;quot; targ_sg=&amp;quot;0[CAT=&apos;AL&apos;
&lt;REL match=&amp;quot;W[C=&apos;DT&apos;
m_mod=&apos;TEST1
S=&apos;NP&apos;]&amp;quot;&gt; &lt;/REL&gt;
&lt;REL match=&amp;quot;W[C=&apos;VBG&apos;]&amp;quot;&gt;&lt;/REL&gt;
&lt;/RULE&gt;
</figure>
<tableCaption confidence="0.806995">
Table 3: An example of fsgmatch rule.
</tableCaption>
<table confidence="0.477484888888889">
&lt;PHR C=&apos;PP&apos;&gt;
&lt;W CAT=&apos;N&apos; C=&apos;IN&apos;&gt;Under&lt;/W&gt;
&lt;/PHR&gt;
&lt;PHR C=&apos;NP&apos;&gt;
&lt;W S=&apos;NP&apos; BK=&apos;L&apos; CAT=&apos;AL&apos; C=&apos;DT&apos;&gt;the&lt;/W&gt;
&lt;W S=&apos;NP&apos; CAT=&apos;AL&apos; C=&apos;VBG&apos;&gt;existing&lt;/W&gt;
&lt;W S= &apos;NP&apos; CAT=&apos;N&apos; C=&apos;NN&apos;&gt;contract&lt;/W&gt;
&lt;/PHR&gt;
&lt;W C=&apos;,&apos;&gt;,&lt;/W&gt;
</table>
<tableCaption confidence="0.968908">
Table 4: Example of output.
</tableCaption>
<bodyText confidence="0.999160444444445">
For each structure, words are marked up with
their categories, and then a rule inserts an en-
tity PHR with an attribute C which corresponds
to the name of the structure. The entity PHR
is inserted by a rule which recognises sequences
of entities W corresponding to a structure. Ta-
ble 4 shows an output where two phrases were
added: a prepositional one (&lt;PHR C=&apos;PP&apos;&gt;),
and a noun phrase (&lt;PHR C=&apos;NP&apos;&gt;).
</bodyText>
<sectionHeader confidence="0.981529" genericHeader="conclusions">
6 Ordering Structures
</sectionHeader>
<bodyText confidence="0.9520855">
The different structures are learned sequen-
tially. If, in principle, the order used for learning
</bodyText>
<table confidence="0.999905916666667">
test data precision recall Fo=1
ADJP 74.26% 68.49% 71.26
ADVP 72.10% 80.25% 75.96
CONJP 100.00% 55.56% 71.43
INTJ 100.00% 50.00% 66.67
LST 0.00% 0.00% 0.00
NP 92.38% 92.71% 92.54
PP 95.57% 97.86% 96.70
PRT 81.43% 53.77% 64.77
SBAR 90.47% 76.26% 82.76
VP 92.48% 92.92% 92.70
all 91.87% 92.31% 92.09
</table>
<tableCaption confidence="0.998818">
Table 5: ALLiS results
</tableCaption>
<bodyText confidence="0.999769684210526">
structures is not important, the practice shows
that it is better to begin with structures which
contain other structures. Once a structure is
learned, it is not taken into account during the
learning of the next structures. This avoids
generating of complementary contexts already
learned at the preceding level. For instance,
ALLiS first learns NP structure. Once categori-
sation rules for the tag VBG are learned, ALLiS
does not take into account VBG occurring in a
NP when it learns following structures. At the
VP level, it is thus useless of learn contexts in
which VBG does not occur in a VP (cases which
mainly correspond to occurrences of VBG in
NP). The parsing phase has of course to use the
same learning order. The (partial) order used
is: NP, VP, ADJP, ADVP, PP, PRT, CONJP,
SBAR, INTJ, LST. Table 5 shows evaluation of
ALLiS for the CoNLL-2000 shared task.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9957035">
Steven Abney. 1996. Partial parsing via finite-state
cascades. In Proceedings of the ESSLLI &apos;96 Ro-
bust Parsing Workshop.
Herve Dejean. 2000a. Theory refinement and natu-
ral language learning. In COLING &apos;2000.
Herve Dejean. 2000b. A Symbolic system for natu-
ral language learning. In CONLL&apos;2000.
Claire Grover, Andrei Mikheev, and
Colin Matheson, 1999. LT TTT ver-
sion 1.0: Text Tokenisation Software.
http://www.ltg.ed.ac.uk/softwareittt/.
Lauri Karttunen, Tamas Gag, and André Kempe.
1997. Xerox finite-state tool. Technical report,
Xerox Research Centre Europe, Grenoble.
</reference>
<page confidence="0.998692">
135
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.270317">
<note confidence="0.968026">of CoNLL-2000 and LLL-2000, 133-135, Lisbon, Portugal, 2000.</note>
<title confidence="0.8624635">Learning Syntactic Structures with XML Herve</title>
<author confidence="0.589224">Seminar fiir</author>
<intro confidence="0.693848">Universitat</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Partial parsing via finite-state cascades.</title>
<date>1996</date>
<booktitle>In Proceedings of the ESSLLI &apos;96 Robust Parsing Workshop.</booktitle>
<contexts>
<context position="1425" citStr="Abney, 1996" startWordPosition="222" endWordPosition="223">mar using operators such as contextualisation and lexicalisation (Section 4). ALLiS separates the task of the generation of rules and the task of the use of these rules (task of parsing). First symbolic rules are learned and saved using an own formalism, and in a second time, these rules are converted into a proper formalism used by a specific rule-based parser. The rules generated by ALLiS contain enough contextual information so that their conversions into other formalisms is possible (Deleon, 2000b). We present here the three tools we tested in order to parse texts. CASS : the CASS system (Abney, 1996) provides a very fast parser which uses Regular Expression Grammar. The inconvenient of this system is twofold: first CASS only handles tags. Some pre- and post-processings are needed. Second, it is impossible to use contextual information. Using CASS, it is thus difficult to implement rules generated by the two refinement operators used in ALLiS: contextualisation (introduction of contexts) and lexicalisation (use of the word level). XFST : the Xerox finite State Tool (Karttunen et al., 1997) offers a rich finite state formalism (operator of contextualisation, replace operator). If the formal</context>
</contexts>
<marker>Abney, 1996</marker>
<rawString>Steven Abney. 1996. Partial parsing via finite-state cascades. In Proceedings of the ESSLLI &apos;96 Robust Parsing Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herve Dejean</author>
</authors>
<title>Theory refinement and natural language learning.</title>
<date>2000</date>
<booktitle>In COLING &apos;2000.</booktitle>
<marker>Dejean, 2000</marker>
<rawString>Herve Dejean. 2000a. Theory refinement and natural language learning. In COLING &apos;2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herve Dejean</author>
</authors>
<title>A Symbolic system for natural language learning.</title>
<date>2000</date>
<booktitle>In CONLL&apos;2000.</booktitle>
<marker>Dejean, 2000</marker>
<rawString>Herve Dejean. 2000b. A Symbolic system for natural language learning. In CONLL&apos;2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Andrei Mikheev</author>
<author>Colin Matheson</author>
</authors>
<date>1999</date>
<booktitle>LT TTT version 1.0: Text Tokenisation Software. http://www.ltg.ed.ac.uk/softwareittt/.</booktitle>
<contexts>
<context position="2436" citStr="Grover et al., 1999" startWordPosition="390" endWordPosition="393">ts) and lexicalisation (use of the word level). XFST : the Xerox finite State Tool (Karttunen et al., 1997) offers a rich finite state formalism (operator of contextualisation, replace operator). If the formalism is powerful enough, the main problem with XFST is the number of transducers generated by ALLiS. For each context and each word occurring in the rules learned by ALLiS corresponds a transducer. The size of the final Regular Expression Grammar is quite big and the compilation and processing time keeps low. A phase of optimisation would be required. LT TTT : the last tool tried, LT TTT (Grover et al., 1999), is a text tokenisation system and toolset. One of the tools, fsgmatch reads a grammar (also written in XML format) which is used to annotate/parse XML texts. Using XML properties, the grammar has easily access to all the levels of the document (word, tag, phrase, and higher structures). The manipulation/annotation of several structures (as in the CoNLL-2000 shared task) is very easy. LT TTT is a good trade-off between the rapidity of CASS and the rich formalism of XFST. We now explain how the LT TTT is used during the learning and the parsing task. 3 Data and Learning Algorithm The training </context>
<context position="4810" citStr="Grover et al., 1999" startWordPosition="804" endWordPosition="807">an element requires contexts, these contexts are computed by the use of queries which examine training corpus. XML Path Language provides an easy way of addressing nodes of an XML document. For example, the query /TEXT/S/PHR [C= &apos;NP &apos;11W determines elements W directly under an entity PHR with the attribute C,&apos;NP&apos;, under the entities S and TEXT. A query returns the indicated items one by one until the set denoted by the query is exhausted. The above query returns all the elements occurring in a phrase marked NP. The next section provides some examples of queries used during the learning task. (Grover et al., 1999) describes the syntax of the LT XML query language. 4 Examples of LT XML Queries The default category of a tag is given by the ration between its number of occurrences in the structure we want to recognise and the number of occurrences in the training corpus. The two following queries compute this ration for the tag VBG and the NP structure: */ (PHR [C= &apos; &apos;] /W [C= &apos; VBG &apos;]) . */W [C= &apos; VBG &apos;] The first query can be read as follows: element W with the attribute C=&apos;VBG&apos; occurring in an entity PHR with the attribute C=&apos;NP &apos; , this last structure occurring anywhere in the document. The second que</context>
<context position="7193" citStr="Grover et al., 1999" startWordPosition="1250" endWordPosition="1253"> reliable in this context (the answer is affirmative). For some tags, the ratio still remains below the threshold. The last query shows that we can also have access to the word itself: it looks for the word operating tagged VBG inside a phrase categorised as NP: 134 PHR [C= &apos; NP &apos; ] /W [C= &apos; VBG &apos; ] /#= &apos; operat ing &apos; Contexts in which the word occurs outside the structure are also built, and the ratio is computed in the same was as above. 5 Parsing with fsgmatch Once rules are learned, they are converted into the formalism of the parser. Table 3 provides an example of rules used by fsgmatch (Grover et al., 1999). The rule consists of adding the attributes CAT=&apos;AL&apos; S=&apos;NP&apos; (left adjunct of a Noun Phrase(NP)) to each word with the attribute C=&apos; VBG &apos; which occurs after a word with the attribute C= &apos;DT &apos; . &lt;RULE name=&amp;quot;AL&amp;quot; targ_sg=&amp;quot;0[CAT=&apos;AL&apos; &lt;REL match=&amp;quot;W[C=&apos;DT&apos; m_mod=&apos;TEST1 S=&apos;NP&apos;]&amp;quot;&gt; &lt;/REL&gt; &lt;REL match=&amp;quot;W[C=&apos;VBG&apos;]&amp;quot;&gt;&lt;/REL&gt; &lt;/RULE&gt; Table 3: An example of fsgmatch rule. &lt;PHR C=&apos;PP&apos;&gt; &lt;W CAT=&apos;N&apos; C=&apos;IN&apos;&gt;Under&lt;/W&gt; &lt;/PHR&gt; &lt;PHR C=&apos;NP&apos;&gt; &lt;W S=&apos;NP&apos; BK=&apos;L&apos; CAT=&apos;AL&apos; C=&apos;DT&apos;&gt;the&lt;/W&gt; &lt;W S=&apos;NP&apos; CAT=&apos;AL&apos; C=&apos;VBG&apos;&gt;existing&lt;/W&gt; &lt;W S= &apos;NP&apos; CAT=&apos;N&apos; C=&apos;NN&apos;&gt;contract&lt;/W&gt; &lt;/PHR&gt; &lt;W C=&apos;,&apos;&gt;,&lt;/W&gt; Table 4: Example of output. For each s</context>
</contexts>
<marker>Grover, Mikheev, Matheson, 1999</marker>
<rawString>Claire Grover, Andrei Mikheev, and Colin Matheson, 1999. LT TTT version 1.0: Text Tokenisation Software. http://www.ltg.ed.ac.uk/softwareittt/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Tamas Gag</author>
<author>André Kempe</author>
</authors>
<title>Xerox finite-state tool.</title>
<date>1997</date>
<tech>Technical report,</tech>
<institution>Xerox Research Centre Europe,</institution>
<location>Grenoble.</location>
<contexts>
<context position="1923" citStr="Karttunen et al., 1997" startWordPosition="301" endWordPosition="305">ible (Deleon, 2000b). We present here the three tools we tested in order to parse texts. CASS : the CASS system (Abney, 1996) provides a very fast parser which uses Regular Expression Grammar. The inconvenient of this system is twofold: first CASS only handles tags. Some pre- and post-processings are needed. Second, it is impossible to use contextual information. Using CASS, it is thus difficult to implement rules generated by the two refinement operators used in ALLiS: contextualisation (introduction of contexts) and lexicalisation (use of the word level). XFST : the Xerox finite State Tool (Karttunen et al., 1997) offers a rich finite state formalism (operator of contextualisation, replace operator). If the formalism is powerful enough, the main problem with XFST is the number of transducers generated by ALLiS. For each context and each word occurring in the rules learned by ALLiS corresponds a transducer. The size of the final Regular Expression Grammar is quite big and the compilation and processing time keeps low. A phase of optimisation would be required. LT TTT : the last tool tried, LT TTT (Grover et al., 1999), is a text tokenisation system and toolset. One of the tools, fsgmatch reads a grammar</context>
</contexts>
<marker>Karttunen, Gag, Kempe, 1997</marker>
<rawString>Lauri Karttunen, Tamas Gag, and André Kempe. 1997. Xerox finite-state tool. Technical report, Xerox Research Centre Europe, Grenoble.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>