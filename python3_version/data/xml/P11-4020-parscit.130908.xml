<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001725">
<title confidence="0.988861">
SciSumm: A Multi-Document Summarization System for Scientific Articles
</title>
<author confidence="0.969914">
Nitin Agarwal Kiran Gvr
</author>
<affiliation confidence="0.9622245">
Language Technologies Institute Language Technologies Resource Center
Carnegie Mellon University IIIT-Hyderabad, India
</affiliation>
<email confidence="0.968078">
nitina@cs.cmu.edu kiran gvr@students.iiit.ac.in
</email>
<author confidence="0.996998">
Ravi Shankar Reddy Carolyn Penstein Ros´e
</author>
<affiliation confidence="0.746491">
Language Technologies Resource Center Language Technologies Institute
IIIT-Hyderabad, India Carnegie Mellon University
</affiliation>
<email confidence="0.992174">
krs reddy@students.iiit.ac.in cprose@cs.cmu.edu
</email>
<sectionHeader confidence="0.995461" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999474913043478">
In this demo, we present SciSumm, an inter-
active multi-document summarization system
for scientific articles. The document collec-
tion to be summarized is a list of papers cited
together within the same source article, oth-
erwise known as a co-citation. At the heart
of the approach is a topic based clustering of
fragments extracted from each article based on
queries generated from the context surround-
ing the co-cited list of papers. This analy-
sis enables the generation of an overview of
common themes from the co-cited papers that
relate to the context in which the co-citation
was found. SciSumm is currently built over
the 2008 ACL Anthology, however the gen-
eralizable nature of the summarization tech-
niques and the extensible architecture makes it
possible to use the system with other corpora
where a citation network is available. Evalu-
ation results on the same corpus demonstrate
that our system performs better than an exist-
ing widely used multi-document summariza-
tion system (MEAD).
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963857142857">
We present an interactive multi-document summa-
rization system called SciSumm that summarizes
document collections that are composed of lists of
papers cited together within the same source arti-
cle, otherwise known as a co-citation. The inter-
active nature of the summarization approach makes
this demo session ideal for its presentation.
When users interact with SciSumm, they request
summaries in context as they read, and that context
determines the focus of the summary generated for
a set of related scientific articles. This behaviour is
different from some other non-interactive summa-
rization systems that might appear as a black box
and might not tailor the result to the specific infor-
mation needs of the users in context. SciSumm cap-
tures a user’s contextual needs when a user clicks on
a co-citation. Using the context of the co-citation in
the source article, we generate a query that allows
us to create a summary in a query-oriented fash-
ion. The extracted portions of the co-cited articles
are then assembled into clusters that represent the
main themes of the articles that relate to the context
in which they were cited. Our evaluation demon-
strates that SciSumm achieves higher quality sum-
maries than a state-of-the-art multidocument sum-
marization system (Radev, 2004).
The rest of the paper is organized as follows. We
first describe the design goals for SciSumm in 2 to
motivate the need for the system and its usefulness.
The end-to-end summarization pipeline has been de-
scribed in Section 3. Section 4 presents an evalua-
tion of summaries generated from the system. We
present an overview of relevant literature in Section
5. We end the paper with conclusions and some in-
teresting further research directions in Section 6.
</bodyText>
<sectionHeader confidence="0.98919" genericHeader="method">
2 Design Goals
</sectionHeader>
<bodyText confidence="0.999972666666667">
Consider that as a researcher reads a scientific arti-
cle, she/he encounters numerous citations, most of
them citing the foundational and seminal work that
is important in that scientific domain. The text sur-
rounding these citations is a valuable resource as
it allows the author to make a statement about her
</bodyText>
<page confidence="0.983528">
115
</page>
<note confidence="0.315686">
Proceedings of the ACL-HLT 2011 System Demonstrations, pages 115–120,
Portland, Oregon, USA, 21 June 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.969029911764706">
viewpoint towards the cited articles. However, to re-
searchers who are new to the field, or sometimes just
as a side-effect of not being completely up-to-date
with related work in a domain, these citations may
pose a challenge to readers. A system that could
generate a small summary of the collection of cited
articles that is constructed specifically to relate to
the claims made by the author citing them would be
incredibly useful. It would also help the researcher
determine if the cited work is relevant for her own
research.
As an example of such a co-citation consider the
following citation sentence:
Various machine learning approaches have been
proposed for chunking (Ramshaw and Marcus,
1995; Tjong Kim Sang, 2000a; Tjong Kim Sang et
al. , 2000; Tjong Kim Sang, 2000b; Sassano and
Utsuro, 2000; van Halteren, 2000).
Now imagine the reader trying to determine about
widely used machine learning approaches for noun
phrase chunking. He would probably be required
to go through these cited papers to understand what
is similar and different in the variety of chunking
approaches. Instead of going through these individ-
ual papers, it would be quicker if the user could get
the summary of the topics in all those papers that
talk about the usage of machine learning methods
in chunking. SciSumm aims to automatically dis-
cover these points of comparison between the co-
cited papers by taking into consideration the con-
textual needs of a user. When the user clicks on a
co-citation in context, the system uses the text sur-
rounding that co-citation as evidence of the informa-
tion need.
</bodyText>
<sectionHeader confidence="0.975636" genericHeader="method">
3 System Overview
</sectionHeader>
<bodyText confidence="0.9998045">
A high level overview of our system’s architecture
is presented in Figure 1. The system provides a web
based interface for viewing and summarizing re-
search articles in the ACL Anthology corpus, 2008.
The summarization proceeds in three main stages as
follows:
</bodyText>
<listItem confidence="0.942821722222222">
• A user may retrieve a collection of articles
of interest by entering a query. SciSumm re-
sponds by returning a list of relevant articles,
including the title and a snippet based sum-
mary. For this SciSumm uses standard retrieval
from a Lucene index.
• A user can use the title, snippet summary and
author information to find an article of inter-
est. The actual article is rendered in HTML af-
ter the user clicks on one of the search results.
The co-citations in the article are highlighted in
bold and italics to mark them as points of inter-
est for the user.
• If a user clicks on one, SciSumm responds by
generating a query from the local context of the
co-citation. That query is then used to select
relevant portions of the co-cited articles, which
are then used to generate the summary.
</listItem>
<bodyText confidence="0.999902736842105">
An example of a summary for a particular topic is
displayed in Figure 2. This figure shows one of
the clusters generated for the citation sentence “Var-
ious machine learning approaches have been pro-
posed for chunking (Ramshaw and Marcus, 1995;
Tjong Kim Sang, 2000a; Tjong Kim Sang et al. ,
2000; Tjong Kim Sang, 2000b; Sassano and Utsuro,
2000; van Halteren, 2000)”. The cluster has a la-
bel Chunk, Tag, Word and contains fragments from
two of the papers discussing this topic. A ranked
list of such clusters is generated, which allows for
swift navigation between topics of interest for a user
(Figure 3). This summary is tremendously useful as
it informs the user of the different perspectives of
co-cited authors towards a shared problem (in this
case ”Chunking”). More specifically, it informs the
user as to how different or similar approaches are
that were used for this research problem (which is
”Chunking”).
</bodyText>
<subsectionHeader confidence="0.999241">
3.1 System Description
</subsectionHeader>
<bodyText confidence="0.999282090909091">
SciSumm has four primary modules that are central
to the functionality of the system, as displayed in
Figure 1. First, the Text Tiling module takes care
of obtaining tiles of text relevant to the citation con-
text. Next, the clustering module is used to generate
labelled clusters using the text tiles extracted from
the co-cited papers. The clusters are ordered accord-
ing to relevance with respect to the generated query.
This is accomplished by the Ranking Module.
In the following sections, we discuss each of the
main modules in detail.
</bodyText>
<page confidence="0.99723">
116
</page>
<figureCaption confidence="0.999515">
Figure 1: SciSumm summarization pipeline
</figureCaption>
<subsectionHeader confidence="0.995976">
3.2 Texttiling
</subsectionHeader>
<bodyText confidence="0.9999436875">
The Text Tiling module uses the TextTiling algo-
rithm (Hearst, 1997) for segmenting the text of each
article. We have used text tiles as the basic unit
for our summary since individual sentences are too
short to stand on their own. This happens as a side-
effect of the length of scientific articles. Sentences
picked from different parts of several articles assem-
bled together would make an incoherent summary.
Once computed, text tiles are used to expand on the
content viewed within the context associated with a
co-citation. The intuition is that an embedded co-
citation in a text tile is connected with the topic dis-
tribution of its context. Thus, we can use a computa-
tion of similarity between tiles and the context of the
co-citation to rank clusters generated using Frequent
Term based text clustering.
</bodyText>
<subsectionHeader confidence="0.999155">
3.3 Frequent Term Based Clustering
</subsectionHeader>
<bodyText confidence="0.999946333333333">
The clustering module employs Frequent Term
Based Clustering (Beil et al., 2002). For each co-
citation, we use this clustering technique to cluster
all the of the extracted text tiles generated by seg-
menting each of the co-cited papers. We settled on
this clustering approach for the following reasons:
</bodyText>
<listItem confidence="0.925765818181818">
• Text tile contents coming from different papers
constitute a sparse vector space, and thus the
centroid based approaches would not work very
well for integrating content across papers.
• Frequent Term based clustering is extremely
fast in execution time as well as and relatively
efficient in terms of space requirements.
• A frequent term set is generated for each clus-
ter, which gives a comprehensible description
that can be used to label the cluster.
Frequent Term Based text clustering uses a group
</listItem>
<bodyText confidence="0.972714333333334">
of frequently co-occurring terms called a frequent
term set. We use a measure of entropy to rank these
frequent term sets. Frequent term sets provide a
clean clustering that is determined by specifying the
number of overlapping documents containing more
than one frequent term set. The algorithm uses the
first k term sets if all the documents in the document
collection are clustered. To discover all the possi-
ble candidates for clustering, i.e., term sets, we used
the Apriori algorithm (Agrawal et al., 1994), which
identifies the sets of terms that are both relatively
frequent and highly correlated with one another.
</bodyText>
<subsectionHeader confidence="0.984721">
3.4 Cluster Ranking
</subsectionHeader>
<bodyText confidence="0.9999675">
The ranking module uses cosine similarity between
the query and the centroid of each cluster to rank all
the clusters generated by the clustering module. The
context of a co-citation is restricted to the text of the
segment in which the co-citation is found. In this
way we attempt to leverage the expert knowledge of
the author as it is encoded in the local context of the
co-citation.
</bodyText>
<sectionHeader confidence="0.99919" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9997945">
We have taken great care in the design of the evalu-
ation for the SciSumm summarization system. In a
</bodyText>
<page confidence="0.996933">
117
</page>
<figureCaption confidence="0.998719">
Figure 2: Example of a summary generated by our system. We can see that the clusters are cross cutting across
different papers, thus giving the user a multi-document summary.
</figureCaption>
<bodyText confidence="0.9999515">
typical evaluation of a multi-document summariza-
tion system, gold standard summaries are created by
hand and then compared against fixed length gen-
erated summaries. It was necessary to prepare our
own evaluation corpus, consisting of gold standard
summaries created for a randomly selected set of co-
citations because such an evaluation corpus does not
exist for this task.
</bodyText>
<subsectionHeader confidence="0.98199">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999986181818182">
An important target user population for multi-
document summarization of scientific articles is
graduate students. Hence to get a measure of how
well the summarization system is performing, we
asked 2 graduate students who have been working
in the computational linguistics community to create
gold standard summaries of a fixed length (8 sen-
tences — 200 words) for 10 randomly selected co-
citations. We obtained two different gold standard
summaries for each co-citation (i.e., 20 gold stan-
dard summaries total). Our evaluation is designed
to measure the quality of the content selection. In
future work, we will evaluate the usability of the
SciSumm system using a task based evaluation.
In the absence of any other multi-document sum-
marization system in the domain of scientific ar-
ticle summarization, we used a widely used and
freely available multi-document summarization sys-
tem called MEAD (Radev, 2004) as our baseline.
MEAD uses centroid based summarization to cre-
ate informative clusters of topics. We use the de-
fault configuration of MEAD in which MEAD uses
length, position and centroid for ranking each sen-
tence. We did not use query focussed summarization
with MEAD. We evaluate its performance with the
same gold standard summaries we use to evaluate
SciSumm. For generating a summary from our sys-
tem we used sentences from the tiles that are clus-
tered in the top ranked cluster. Once all of the ex-
tracts included in that entire cluster are exhausted,
we move on to the next highly ranked cluster. In this
way we prepare a summary comprising of 8 highly
relevant sentences.
</bodyText>
<sectionHeader confidence="0.620843" genericHeader="method">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999949631578947">
For measuring performance of the two summariza-
tion systems (SciSumm and MEAD), we compute
the ROUGE metric based on the 2 * 10 gold standard
summaries that were manually created. ROUGE has
been traditionally used to compute the performance
based on the N-gram overlap (ROUGE-N) between
the summaries generated by the system and the tar-
get gold standard summaries. For our evaluation
we used two different versions of the ROUGE met-
ric, namely ROUGE-1 and ROUGE-2, which corre-
spond to measures of the unigram and bigram over-
lap respectively. We computed four metrics in order
to get a complete picture of how SciSumm performs
in relation to the baseline, namely ROUGE-1 F-
measure, ROUGE-1 Recall, ROUGE-2 F-measure,
and ROUGE-2 Recall.
From the results presented in Figure 4 and 5, we
can see that our system performs well on average in
comparison to the baseline. Especially important is
</bodyText>
<page confidence="0.996861">
118
</page>
<figureCaption confidence="0.899749">
Figure 3: Clusters generated in response to a user click on the co-citation. The list of clusters in the left pane gives a
bird-eye view of the topics which are present in the co-cited papers
</figureCaption>
<tableCaption confidence="0.8262025">
Table 1: Average ROUGE results. * represents improve-
ment significant at p &lt; .05, † at p &lt; .01.
</tableCaption>
<table confidence="0.999698714285714">
Metric MEAD SciSumm
ROUGE-1 F-measure 0.3680 0.5123 †
ROUGE-1 Recall 0.4168 0.5018
ROUGE-1 Precision 0.3424 0.5349 †
ROUGE-2 F-measure 0.1598 0.3303 *
ROUGE-2 Recall 0.1786 0.3227 *
ROUGE-2 Precision 0.1481 0.3450 †
</table>
<bodyText confidence="0.999778071428571">
the performance of the system on recall measures,
which shows the most dramatic advantage over the
baseline. To measure the statistical significance of
this result, we carried out a Student T-Test, the re-
sults of which are presented in the results section
in Table 1. It is apparent from the p-values gener-
ated by T-Test that our system performs significantly
better than MEAD on three of the metrics on which
both the systems were evaluated using (p &lt; 0.05)
as the criterion for statistical significance. This sup-
ports the view that summaries perceived as higher in
value are generated using a query focused technique,
where the query is generated automatically from the
context of the co-citation.
</bodyText>
<sectionHeader confidence="0.99588" genericHeader="method">
5 Previous Work
</sectionHeader>
<bodyText confidence="0.999985235294118">
Surprisingly, not many approaches to the problem of
summarization of scientific articles have been pro-
posed in the past. Qazvinian et al. (2008) present
a summarization approach that can be seen as the
converse of what we are working to achieve. Rather
than summarizing multiple papers cited in the same
source article, they summarize different viewpoints
expressed towards the same paper from different pa-
pers that cite it. Nanba et al. (1999) argue in their
work that a co-citation frequently implies a consis-
tent viewpoint towards the cited articles. Another
approach that uses bibliographic coupling has been
used for gathering different viewpoints from which
to summarize a document (Kaplan et al., 2008). In
our work we make use of this insight by generating
a query to focus our multi-document summary from
the text closest to the citation.
</bodyText>
<sectionHeader confidence="0.997976" genericHeader="method">
6 Conclusion And Future Work
</sectionHeader>
<bodyText confidence="0.99997384">
In this demo, we present SciSumm, which is an in-
teractive multi-document summarization system for
scientific articles. Our evaluation shows that the
SciSumm approach to content selection outperforms
another widely used multi-document summarization
system for this summarization task.
Our long term goal is to expand the capabilities
of SciSumm to generate literature surveys of larger
document collections from less focused queries.
This more challenging task would require more con-
trol over filtering and ranking in order to avoid gen-
erating summaries that lack focus. To this end, a
future improvement that we plan to use is a vari-
ant on MMR (Maximum Marginal Relevance) (Car-
bonell et al., 1998), which can be used to optimize
the diversity of selected text tiles as well as the rel-
evance based ordering of clusters, i.e., so that more
diverse sets of extracts from the co-cited articles will
be placed at the ready fingertips of users.
Another important direction is to refine the inter-
action design through task-based user studies. As
we collect more feedback from students and re-
searchers through this process, we will used the in-
sights gained to achieve a more robust and effective
implementation.
</bodyText>
<page confidence="0.998119">
119
</page>
<figureCaption confidence="0.999209">
Figure 4: ROUGE-1 Recall Figure 5: ROUGE-2 Recall
</figureCaption>
<sectionHeader confidence="0.993092" genericHeader="conclusions">
7 Acknowledgements
</sectionHeader>
<copyright confidence="0.556965">
This research was supported in part by NSF grant
EEC-064848 and ONR grant N00014-10-1-0277.
</copyright>
<sectionHeader confidence="0.998764" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998933294117647">
Agrawal R. and Srikant R. 1994. Fast Algorithm for
Mining Association Rules In Proceedings of the 20th
VLDB Conference Santiago, Chile, 1994
Baxendale, P. 1958. Machine-made index for technical
literature - an experiment. IBM Journal of Research
and Development
Beil F., Ester M. and Xu X 2002. Frequent-Term based
Text Clustering In Proceedings of SIGKDD ’02 Ed-
monton, Alberta, Canada
Carbonell J. and Goldstein J. 1998. The Use of MMR,
Diversity-Based Reranking for Reordering Documents
and Producing Summaries In Research and Develop-
ment in Information Retrieval, pages 335–336
Councill I. G. , Giles C. L. and Kan M. 2008. ParsCit:
An open-source CRF reference string parsing pack-
age INTERNATIONAL LANGUAGE RESOURCES
AND EVALUATION European Language Resources
Association
Edmundson, H.P. 1969. New methods in automatic ex-
tracting. Journal of ACM.
Hearst M.A. 1997 TextTiling: Segmenting text into
multi-paragraph subtopic passages In proceedings of
LREC 2004, Lisbon, Portugal, May 2004
Joseph M. T. and Radev D. R. 2007. Citation analysis,
centrality, and the ACL Anthology
Kupiec J. , Pedersen J. , Chen F. 1995. A training doc-
ument summarizer. In Proceedings SIGIR ’95, pages
68-73, New York, NY, USA. 28(1):114–133.
Luhn, H. P. 1958. IBM Journal of Research Develop-
ment.
Mani I. , Bloedorn E. 1997. Multi-Document Summa-
rization by graph search and matching In AAAI/IAAI,
pages 622-628. [15, 16].
Nanba H. , Okumura M. 1999. Towards Multi-paper
Summarization Using Reference Information In Pro-
ceedings of IJCAI-99, pages 926–931 .
Paice CD. 1990. Constructing Literature Abstracts by
Computer: Techniques and Prospects Information
Processing and Management Vol. 26, No.1, pp, 171-
186, 1990
Qazvinian V. , Radev D.R 2008. Scientific Paper
summarization using Citation Summary Networks In
Proceedings of the 22nd International Conference on
Computational Linguistics, pages 689–696 Manch-
ester, August 2008
Radev D. R . , Jing H. and Budzikowska M. 2000.
Centroid-based summarization of multiple documents:
sentence extraction, utility based evaluation, and user
studies In NAACL-ANLP 2000 Workshop on Auto-
matic summarization, pages 21-30, Morristown, NJ,
USA. [12, 16, 17].
Radev, Dragomir. 2004. MEAD - a platform for mul-
tidocument multilingual text summarization. In pro-
ceedings of LREC 2004, Lisbon, Portugal, May 2004.
Teufel S. , Moens M. 2002. Summarizing Scientific
Articles - Experiments with Relevance and Rhetorical
Status In Journal of Computational Linguistics, MIT
Press.
Hal Daume III , Marcu D. 2006. Bayesian query-
focussed summarization. In Proceedings of the Con-
ference of the Association for Computational Linguis-
tics, ACL.
Eisenstein J , Barzilay R. 2008. Bayesian unsupervised
topic segmentation In EMNLP-SIGDAT.
Barzilay R , Lee L. 2004. Catching the drift: Probabilis-
tic content models, with applications to generation and
summarization In Proceedings of 3rd Asian Semantic
Web Conference (ASWC 2008), pp.182-188,.
</reference>
<bodyText confidence="0.68598925">
Kaplan D , Tokunaga T. 2008. Sighting citation sights:
A collective-intelligence approach for automatic sum-
marization of research papers using C-sites In HLT-
NAACL.
</bodyText>
<page confidence="0.994209">
120
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.507302">
<title confidence="0.999886">SciSumm: A Multi-Document Summarization System for Scientific Articles</title>
<author confidence="0.985947">Nitin Agarwal Kiran Gvr</author>
<affiliation confidence="0.9762065">Language Technologies Institute Language Technologies Resource Center Carnegie Mellon University IIIT-Hyderabad, India</affiliation>
<email confidence="0.643961">nitina@cs.cmu.edukirangvr@students.iiit.ac.in</email>
<author confidence="0.998154">Ravi Shankar Reddy Carolyn Penstein Ros´e</author>
<affiliation confidence="0.9589355">Language Technologies Resource Center Language Technologies Institute IIIT-Hyderabad, India Carnegie Mellon University</affiliation>
<email confidence="0.950932">krsreddy@students.iiit.ac.incprose@cs.cmu.edu</email>
<abstract confidence="0.998488166666667">In this demo, we present SciSumm, an interactive multi-document summarization system for scientific articles. The document collection to be summarized is a list of papers cited together within the same source article, otherwise known as a co-citation. At the heart of the approach is a topic based clustering of fragments extracted from each article based on queries generated from the context surrounding the co-cited list of papers. This analysis enables the generation of an overview of common themes from the co-cited papers that relate to the context in which the co-citation was found. SciSumm is currently built over the 2008 ACL Anthology, however the generalizable nature of the summarization techniques and the extensible architecture makes it possible to use the system with other corpora where a citation network is available. Evaluation results on the same corpus demonstrate that our system performs better than an existing widely used multi-document summarization system (MEAD).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Agrawal</author>
<author>R Srikant</author>
</authors>
<title>Fast Algorithm for Mining Association Rules</title>
<date>1994</date>
<booktitle>In Proceedings of the 20th VLDB Conference</booktitle>
<location>Santiago, Chile,</location>
<marker>Agrawal, Srikant, 1994</marker>
<rawString>Agrawal R. and Srikant R. 1994. Fast Algorithm for Mining Association Rules In Proceedings of the 20th VLDB Conference Santiago, Chile, 1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Baxendale</author>
</authors>
<title>Machine-made index for technical literature - an experiment.</title>
<date>1958</date>
<journal>IBM Journal of Research and Development</journal>
<marker>Baxendale, 1958</marker>
<rawString>Baxendale, P. 1958. Machine-made index for technical literature - an experiment. IBM Journal of Research and Development</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Beil</author>
<author>M Ester</author>
<author>X Xu</author>
</authors>
<title>Frequent-Term based Text Clustering</title>
<date>2002</date>
<booktitle>In Proceedings of SIGKDD ’02</booktitle>
<location>Edmonton, Alberta, Canada</location>
<contexts>
<context position="8829" citStr="Beil et al., 2002" startWordPosition="1430" endWordPosition="1433">ces picked from different parts of several articles assembled together would make an incoherent summary. Once computed, text tiles are used to expand on the content viewed within the context associated with a co-citation. The intuition is that an embedded cocitation in a text tile is connected with the topic distribution of its context. Thus, we can use a computation of similarity between tiles and the context of the co-citation to rank clusters generated using Frequent Term based text clustering. 3.3 Frequent Term Based Clustering The clustering module employs Frequent Term Based Clustering (Beil et al., 2002). For each cocitation, we use this clustering technique to cluster all the of the extracted text tiles generated by segmenting each of the co-cited papers. We settled on this clustering approach for the following reasons: • Text tile contents coming from different papers constitute a sparse vector space, and thus the centroid based approaches would not work very well for integrating content across papers. • Frequent Term based clustering is extremely fast in execution time as well as and relatively efficient in terms of space requirements. • A frequent term set is generated for each cluster, w</context>
</contexts>
<marker>Beil, Ester, Xu, 2002</marker>
<rawString>Beil F., Ester M. and Xu X 2002. Frequent-Term based Text Clustering In Proceedings of SIGKDD ’02 Edmonton, Alberta, Canada</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carbonell</author>
<author>J Goldstein</author>
</authors>
<title>The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries</title>
<date>1998</date>
<booktitle>In Research and Development in Information Retrieval,</booktitle>
<pages>335--336</pages>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Carbonell J. and Goldstein J. 1998. The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries In Research and Development in Information Retrieval, pages 335–336</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Giles</author>
<author>M Kan</author>
</authors>
<title>ParsCit: An open-source CRF reference string parsing package</title>
<date>2008</date>
<journal>INTERNATIONAL LANGUAGE RESOURCES AND EVALUATION European Language Resources Association</journal>
<marker>Giles, Kan, 2008</marker>
<rawString>Councill I. G. , Giles C. L. and Kan M. 2008. ParsCit: An open-source CRF reference string parsing package INTERNATIONAL LANGUAGE RESOURCES AND EVALUATION European Language Resources Association</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Edmundson</author>
</authors>
<title>New methods in automatic extracting.</title>
<date>1969</date>
<journal>Journal of ACM.</journal>
<marker>Edmundson, 1969</marker>
<rawString>Edmundson, H.P. 1969. New methods in automatic extracting. Journal of ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>TextTiling: Segmenting text into multi-paragraph subtopic passages</title>
<date>1997</date>
<booktitle>In proceedings of LREC 2004,</booktitle>
<location>Lisbon, Portugal,</location>
<contexts>
<context position="7974" citStr="Hearst, 1997" startWordPosition="1289" endWordPosition="1290">he functionality of the system, as displayed in Figure 1. First, the Text Tiling module takes care of obtaining tiles of text relevant to the citation context. Next, the clustering module is used to generate labelled clusters using the text tiles extracted from the co-cited papers. The clusters are ordered according to relevance with respect to the generated query. This is accomplished by the Ranking Module. In the following sections, we discuss each of the main modules in detail. 116 Figure 1: SciSumm summarization pipeline 3.2 Texttiling The Text Tiling module uses the TextTiling algorithm (Hearst, 1997) for segmenting the text of each article. We have used text tiles as the basic unit for our summary since individual sentences are too short to stand on their own. This happens as a sideeffect of the length of scientific articles. Sentences picked from different parts of several articles assembled together would make an incoherent summary. Once computed, text tiles are used to expand on the content viewed within the context associated with a co-citation. The intuition is that an embedded cocitation in a text tile is connected with the topic distribution of its context. Thus, we can use a compu</context>
</contexts>
<marker>Hearst, 1997</marker>
<rawString>Hearst M.A. 1997 TextTiling: Segmenting text into multi-paragraph subtopic passages In proceedings of LREC 2004, Lisbon, Portugal, May 2004</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Joseph</author>
<author>D R Radev</author>
</authors>
<title>Citation analysis, centrality,</title>
<date>2007</date>
<journal>and the ACL Anthology</journal>
<marker>Joseph, Radev, 2007</marker>
<rawString>Joseph M. T. and Radev D. R. 2007. Citation analysis, centrality, and the ACL Anthology</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pedersen</author>
</authors>
<title>A training document summarizer.</title>
<date>1995</date>
<booktitle>In Proceedings SIGIR ’95,</booktitle>
<pages>68--73</pages>
<location>New York, NY, USA.</location>
<marker>Pedersen, 1995</marker>
<rawString>Kupiec J. , Pedersen J. , Chen F. 1995. A training document summarizer. In Proceedings SIGIR ’95, pages 68-73, New York, NY, USA. 28(1):114–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Luhn</author>
</authors>
<date>1958</date>
<journal>IBM Journal of Research Development.</journal>
<marker>Luhn, 1958</marker>
<rawString>Luhn, H. P. 1958. IBM Journal of Research Development.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
</authors>
<title>Multi-Document Summarization by graph search and matching In</title>
<date>1997</date>
<booktitle>AAAI/IAAI,</booktitle>
<pages>622--628</pages>
<marker>Mani, 1997</marker>
<rawString>Mani I. , Bloedorn E. 1997. Multi-Document Summarization by graph search and matching In AAAI/IAAI, pages 622-628. [15, 16].</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Nanba</author>
</authors>
<title>Towards Multi-paper Summarization Using Reference Information</title>
<date>1999</date>
<booktitle>In Proceedings of IJCAI-99,</booktitle>
<pages>926--931</pages>
<marker>Nanba, 1999</marker>
<rawString>Nanba H. , Okumura M. 1999. Towards Multi-paper Summarization Using Reference Information In Proceedings of IJCAI-99, pages 926–931 .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paice CD</author>
</authors>
<title>Constructing Literature Abstracts by Computer:</title>
<date>1990</date>
<booktitle>Techniques and Prospects Information Processing and Management Vol. 26, No.1,</booktitle>
<pages>171--186</pages>
<marker>CD, 1990</marker>
<rawString>Paice CD. 1990. Constructing Literature Abstracts by Computer: Techniques and Prospects Information Processing and Management Vol. 26, No.1, pp, 171-186, 1990</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Qazvinian</author>
</authors>
<title>Scientific Paper summarization using Citation Summary Networks</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>689--696</pages>
<location>Manchester,</location>
<marker>Qazvinian, 2008</marker>
<rawString>Qazvinian V. , Radev D.R 2008. Scientific Paper summarization using Citation Summary Networks In Proceedings of the 22nd International Conference on Computational Linguistics, pages 689–696 Manchester, August 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Jing</author>
<author>M Budzikowska</author>
</authors>
<title>Centroid-based summarization of multiple documents: sentence extraction, utility based evaluation, and user studies</title>
<date>2000</date>
<booktitle>In NAACL-ANLP 2000 Workshop on Automatic summarization,</booktitle>
<volume>12</volume>
<pages>21--30</pages>
<location>Morristown, NJ, USA.</location>
<marker>Jing, Budzikowska, 2000</marker>
<rawString>Radev D. R . , Jing H. and Budzikowska M. 2000. Centroid-based summarization of multiple documents: sentence extraction, utility based evaluation, and user studies In NAACL-ANLP 2000 Workshop on Automatic summarization, pages 21-30, Morristown, NJ, USA. [12, 16, 17].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir Radev</author>
</authors>
<title>MEAD - a platform for multidocument multilingual text summarization.</title>
<date>2004</date>
<booktitle>In proceedings of LREC 2004,</booktitle>
<location>Lisbon, Portugal,</location>
<contexts>
<context position="2771" citStr="Radev, 2004" startWordPosition="415" endWordPosition="416"> to the specific information needs of the users in context. SciSumm captures a user’s contextual needs when a user clicks on a co-citation. Using the context of the co-citation in the source article, we generate a query that allows us to create a summary in a query-oriented fashion. The extracted portions of the co-cited articles are then assembled into clusters that represent the main themes of the articles that relate to the context in which they were cited. Our evaluation demonstrates that SciSumm achieves higher quality summaries than a state-of-the-art multidocument summarization system (Radev, 2004). The rest of the paper is organized as follows. We first describe the design goals for SciSumm in 2 to motivate the need for the system and its usefulness. The end-to-end summarization pipeline has been described in Section 3. Section 4 presents an evaluation of summaries generated from the system. We present an overview of relevant literature in Section 5. We end the paper with conclusions and some interesting further research directions in Section 6. 2 Design Goals Consider that as a researcher reads a scientific article, she/he encounters numerous citations, most of them citing the foundat</context>
<context position="12180" citStr="Radev, 2004" startWordPosition="1979" endWordPosition="1980">ld standard summaries of a fixed length (8 sentences — 200 words) for 10 randomly selected cocitations. We obtained two different gold standard summaries for each co-citation (i.e., 20 gold standard summaries total). Our evaluation is designed to measure the quality of the content selection. In future work, we will evaluate the usability of the SciSumm system using a task based evaluation. In the absence of any other multi-document summarization system in the domain of scientific article summarization, we used a widely used and freely available multi-document summarization system called MEAD (Radev, 2004) as our baseline. MEAD uses centroid based summarization to create informative clusters of topics. We use the default configuration of MEAD in which MEAD uses length, position and centroid for ranking each sentence. We did not use query focussed summarization with MEAD. We evaluate its performance with the same gold standard summaries we use to evaluate SciSumm. For generating a summary from our system we used sentences from the tiles that are clustered in the top ranked cluster. Once all of the extracts included in that entire cluster are exhausted, we move on to the next highly ranked cluste</context>
</contexts>
<marker>Radev, 2004</marker>
<rawString>Radev, Dragomir. 2004. MEAD - a platform for multidocument multilingual text summarization. In proceedings of LREC 2004, Lisbon, Portugal, May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Teufel</author>
</authors>
<title>Summarizing Scientific Articles - Experiments with Relevance and Rhetorical Status In</title>
<date>2002</date>
<journal>Journal of Computational Linguistics,</journal>
<publisher>MIT Press.</publisher>
<marker>Teufel, 2002</marker>
<rawString>Teufel S. , Moens M. 2002. Summarizing Scientific Articles - Experiments with Relevance and Rhetorical Status In Journal of Computational Linguistics, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daume</author>
</authors>
<title>Bayesian queryfocussed summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics, ACL.</booktitle>
<marker>Daume, 2006</marker>
<rawString>Hal Daume III , Marcu D. 2006. Bayesian queryfocussed summarization. In Proceedings of the Conference of the Association for Computational Linguistics, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisenstein</author>
</authors>
<title>Bayesian unsupervised topic segmentation</title>
<date>2008</date>
<booktitle>In EMNLP-SIGDAT.</booktitle>
<marker>Eisenstein, 2008</marker>
<rawString>Eisenstein J , Barzilay R. 2008. Bayesian unsupervised topic segmentation In EMNLP-SIGDAT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
</authors>
<title>Catching the drift: Probabilistic content models, with applications to generation and summarization</title>
<date>2004</date>
<booktitle>In Proceedings of 3rd Asian Semantic Web Conference (ASWC</booktitle>
<pages>182--188</pages>
<marker>Barzilay, 2004</marker>
<rawString>Barzilay R , Lee L. 2004. Catching the drift: Probabilistic content models, with applications to generation and summarization In Proceedings of 3rd Asian Semantic Web Conference (ASWC 2008), pp.182-188,.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>