<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.90923">
The FINITE STRING Abstracts of Current Literature
</note>
<title confidence="0.718337">
Abstracts of Current Literature
A Fuzzy-Set-Theoretic Approach to the
</title>
<affiliation confidence="0.844930571428571">
Compositionality of Meaning: Propo-
sitions, Dispositions and Canonical
Forms
Lotfi A. Zadeh
Division of Computer Science
ERL, College of Engineering
University of California
</affiliation>
<address confidence="0.4907265">
Berkeley, CA 94720
Memorandum No. UCBIERL M83124
</address>
<bodyText confidence="0.999943557692308">
This is the manual for the Pro Gram grammar development system
(written in Prolog) intended for use by linguists and computational
linguists developing grammars for significant fragments of natural
languages. The system incorporates all aspects of the Generalized
Phrase Structure Grammar framework, including features, metarules,
ID/LP rule format, Kleene star rule feature instantiation principles,
schemata, and so on. Among other things, the user can &amp;quot;direct&amp;quot;
parsing interactively in order to explore particular analyses.
Although natural language (NL) querying of data bases (DBs) has been
an active research area for many years, and at least one commercial
system is available that supports natural language database query, little
effort has been expended in support of natural language database
update. Thus, end-users of data bases must alternate between easy-to-
use natural language query systems and harder-to-use format database
update systems.
Salveter and Maier have shown that, because NL DB update is a
fundamentally different problem than query, it is not possible to
naturally extend natural language query systems to also support up-
date. A data base is an attempt to abstract information about the real
world. A state of the data base is meant to represent a state of a
portion of the real world. To interpret values of the data objects in
the data base as statements about the real world, we must be able to
connect the values in the data base with various entities and relation-
ships in the data base. A semantic data description indicates a set of
real world states (RWS), a database definition gives a set of allowable
database states (DBS). The correspondence between the semantic
description and the database definition induces connections between
database states and real world states.
In its traditional interpretation, Frege&apos;s principle of compositionality is
not sufficiently flexible to have a wide applicability to natural lan-
guages. In a fuzzy-set-theoretic setting which is outlined in this paper,
Frege&apos;s principle is modified and broadened by allowing the meaning
of a proposition, p, to be composed not from the meaning of the
constituents of p but, more generally, from the meaning of a collection
of fuzzy relations which form a so-called explanatory data base that is
associated with p. More specficially, through the application of test-
score semantics, the meaning of p is represented as a procedure which
tests, scores and aggregates the elastic constraints which are implicit
in p. The employment of fuzzy sets in this semantics allows p to con-
tain fuzzy predicates such as tall, kind, much richer, etc.,; fuzzy quan-
tifiers such as most, several, few, usually, etc.; and other types of
semantic entities which cannot be dealt with within the framework of
classical logic.
The approach described in the paper suggests a way of representing
the meaning of dispositions, e.g., Overeating causes obesity, Icy roads
are slippery, Young men like young women, etc. Specifically, by view-
ing a disposition, d, as a proposition with implicit fuzzy quantifiers,
the problem of representing the meaning of d may be decomposed into
(a) restoring the suppressed fuzzy quantifiers and/or fuzzifying the
nonfuzzy quantifiers in the body of d; and (b) representing the mean-
ing of the resulting dispositional proposition through the use of test-
score semantics.
</bodyText>
<table confidence="0.817081529411765">
The ProGram Manual
Roger Evans, Gerald Gazdar
Cognitive Studies Programme
Arts E, University of Sussex
Brighton, BN1 9QN, U.K.
Cognitive Science Research Paper
CSRP 035, April 1984, 106 pages
(Address requests to Judith Dennison.)
Natural Language Database Update
Sharon Salveter
Computer Science Department
College of Liberal Arts
Boston University
Boston, MA 02215
Technical Report No. 841001
Computational Linguistics, Volume 10, Number 1 January-March 1984 43
The FINITE STRING Abstracts of Current Literature
</table>
<bodyText confidence="0.992291333333333">
To place in evidence the logical structure of p and, at the same time
provide a high-level description o the composition process, p may be
expressed in the canonical form &amp;quot;X is F&amp;quot;, where X = (X1 ..., Xn) is an
implicit n-ary variable which is constrained by p and F is a fuzzy
n-ary relation which may be interpreted as an elastic constraint on X.
This canonical form and the meaning-composition process for proposi-
sitions and dispositions are Illustrated by several examples among
which is the proposition p = Over the past few years Naomi earned far
more than most of her close friends.
</bodyText>
<figure confidence="0.977967230769231">
Test-Score Semantics for Natural Lan-
guages and Meaning Representation
via PRUF
Lotfi A. Zadeh
see page 43
In Rieger, B., Ed., Empire&amp; Semantics I.
Brockmeyer, Bochum, 1981.
A Computational Approach to Fuzzy
Quantifiers in Natural Languages
Lotfi A. Zadeh
see page 43
Comp. &amp; Maths. with App/s.
9(1): 149-184 (1983).
</figure>
<bodyText confidence="0.997805108695652">
In a sharp departure from the conventional approaches to the
problem of meaning representation in natural languages, test-score
semantics is based on the premise that almost everything that relates to
natural languages is a matter of degree. Thus, in test-score semantics,
predicates, propositions and other types of linguistic entities are treat-
ed as collections of elastic constraints on a set of objects or relations
in a universe of discourse. Viewed in this perspective, the meaning of
a linguistic entity may be defined by (a) identifying the constraints
which are implicit or explicit in the entity in question; (b) describing
the tests that must be performed to ascertain the degree to which each
constraint is satisfied; and (c) specifying the manner in which the
degrees in question or, equivalently, the partial test scores are to be
aggregated to yield an overall test score. In general, the overall test
score is a vector whose components are numbers in the unit interval or
possibility/probability distributions over this interval.
The first step in the representation of the meaning of a given propo-
sition involves the construction of a relational data base in which the
meaning of constituent relations and their attributes is assumed to be
known. The choice of the data base affects the explanatory effective-
ness of the translation process and is governed by the knowledge
profile of the intended user of the translation. The test procedure —
which is regarded as the representation of the meaning of the proposi-
tion — acts on the data base and returns an overall test score which is
interpreted as the compatibility of p with the data base.
Test-score semantics is sufficiently general to allow the translation of
almost any proposition in a natural language. However, the price of
generality is the difficulty of writing a program which could represent
the meaning of a given proposition without recourse to human assist-
ance.
The generic term fuzzy quantifier is employed in this paper to denote
the collection of quantifiers in natural languages whose representative
elements are: several, most, much, not many, very many, not very many,
few, quite a few, large number, small number, close to five, approximate-
ly ten, frequently, etc. In our approach, such quantifiers are treated as
fuzzy numbers which may be manipulated through the use of fuzzy
arithmetic and, more generally, fuzzy logic.
A concept which plays an essential role in the treatment of fuzzy
quantifiers is that of the cardinality of a fuzzy set. Through the use
of this concept, the meaning of a proposition containing one or more
fuzzy quantifiers may be represented as a system of elastic constraints
whose domain is a collection of fuzzy relations in a relational data
base. This representation, then, provides a basis for inference from
premises which contain fuzzy quantifiers. For example, from the
propositions &amp;quot;Most U&apos;s are A&apos;s&amp;quot; and &amp;quot;Most A&apos;s are B&apos;s&amp;quot;, it follows
that &amp;quot;Most2 U&apos;s are B&apos;s&amp;quot;, where most2 is the fuzzy product of the
fuzzy proportion most with itself.
</bodyText>
<page confidence="0.985859">
44 Computational Linguistics, Volume 10, Number 1 January-March 1984
</page>
<note confidence="0.596948">
The FINITE STRING Abstracts of Current Literature
</note>
<bodyText confidence="0.9982934">
The computational approach to fuzzy quantifiers which is described
in this paper may be viewed as a derivative of fuzzy logic and test-
score semantics. In this semantics, the meaning of a semantic entity is
represented as a procedure which tests, scores, and aggregates the
elastic constraints which are induced by the entity in question.
</bodyText>
<figure confidence="0.833528714285714">
The Role of Fuzzy Logic in the Man-
agement of Uncertainty in Expert
Systems
Lotti A. Zadeh
see page 43
Fuzzy Sets and Systems 11,1983:
199-227.
</figure>
<bodyText confidence="0.995081479166666">
Management of uncertainty is an intrinsically important issue in the
design of expert systems because much of the information in the
knowledge base of a typical expert system is imprecise, incomplete or
not totally reliable.
In the existing expert systems, uncertainty is dealt with through a
combination of predicate logic and probability-based methods. A
serious shortcoming of these methods is that they are not capable of
coming to grips with the pervasive fuzziness of information in the
knowledge base, and, as a result, are mostly ad hoc in nature. An
alternative approach to the management of uncertainty which is sug-
gested in this paper is based on the use of fuzzy logic, which is the
logic underlying approximate or, equivalently, fuzzy reasoning. A
feature of fuzzy logic which is of particular importance to the manage-
ment of uncertainty in expert systems is that it provides a systematic
framework for dealing with fuzzy quantifiers, e.g., most, many, few, not
very many, almost all, infrequently, about 0.8, etc. In this way, fuzzy
logic subsumes both predicate logic and probability theory, and makes
it possible to deal with different types of uncertainty within a single
conceptual framework.
In fuzzy logic, the deduction of a conclusion from a set of premises is
reduced, in general, to the solution of a nonlinear program through the
application of projection and extension principles. This approach to
deduction leads to various basic syllogisms which may be used as rules
of combination of evidence in expert systems. Among syllogisms of
this type which are discussed in this paper are the intersection/project
syllogism, the generalized modus ponens, the consequent conjunction
syllogism, and the major-premise reversibility rule.
It is suggested that communication between humans — as well as be-
tween humans and machines — may be made more precise by the
employment of a meaning representation language PRUF which is
based on the concept of a possibility distribution. A brief exposition
of PRUF is presented, and its application to precisiation of meaning is
illustrated by a number of examples.
The theory outlined in this paper is based on the idea that what is
commonly called commonsense knowledge may be viewed as a collec-
tion of dispositions, that is, propositions with implied fuzzy quantifiers.
Typical examples of dispositions are: Icy roads are slippery, Tall men
are not very agile, Overeating causes obesity, Bob loves women, What is
rare is expensive, etc. It is understood that, upon restoration of fuzzy
quantifiers, a disposition is converted into a proposition with explicit
fuzzy quantifiers, e.g., Tall men are not very agile -4. Most tall men
are not very agile.
Since traditional logical systems provide no methods for representing
the meaning of propositions containing fuzzy quantifiers, such systems
are unsuitable for dealing with commonsense knowledge. It is suggest-
ed in this paper that an appropriate computational framework for
dealing with commonsense knowledge is provided by fuzzy logic,
which, as its name implies, is the logic underlying fuzzy (or approxi-
</bodyText>
<table confidence="0.9806358125">
Precisiation of Meaning via Transla-
tion into PRUF
Lofti A. Zadeh
see page 43
In Vaina, L. and Hintikka, J., Eds.,
Cognitive Constraints on Communication
D. Reidel, 1984: 373-401.
A Theory of Commonsense
Knowledge
Lotfi A. Zadeh
see page 43
In Skala, H.J.; Termini, S.; and Trillas,
E., Eds., Aspects of Vagueness.
D. Reidel, 1984: 257-296.
Computational Linguistics, Volume 10, Number 1 January-March 1984 45
The FINITE STRING Abstracts of Current Literature
</table>
<bodyText confidence="0.666360375">
mate) reasoning. Such a framework, with an emphasis on the repre-
sentation of dispositions, is outlined and illustrated with examples.
The following reports are available from
Computer Laboratory
University of Cambridge
Corn Exchange Street
Cambridge CB2 3QG, England
Prices are as indicated; add postage: surface — theses £0.65, others £0.40; air — theses £5.00, others £1.50.
</bodyText>
<subsectionHeader confidence="0.5063635">
Compound Noun Interpretation
Problems
</subsectionHeader>
<figure confidence="0.49155875">
K. Sparck Jones
Technical Report No. 45, July 1983,
16pp., £0.50
Automatic Summarising of English
Texts
J.I. Tait
Technical Report No. 47, December 1982,
137pp., £2.50.
</figure>
<title confidence="0.387641">
A Mechanism for the Accumulation
</title>
<subsectionHeader confidence="0.685301666666667">
and Application of Context in Text
Processing
H. Alshawi
</subsectionHeader>
<subsubsectionHeader confidence="0.655803">
Technical Report No. 48, 17pp. £0.50.
</subsubsectionHeader>
<bodyText confidence="0.999983837209302">
This paper was prepared for the SERC/CREST Course on Computer
Speech Processing, Cambridge, England, July 1983. It discusses the
problems of compound noun interpretation in the context of automatic
language processing. Given that compound processing implies identi-
fying the senses of the words involved, determining their bracketing,
and establishing their underlying semantic relations, the paper illus-
trates the need, even in comparatively favourable cases, for inference
using pragmatic information. This has consequences for language
processor architectures and, even more, for speech processors.
The thesis describes a computer program called Scrabble which can
summarise short English texts. It uses large bodies of predictions
about the likely contents of texts about particular topics to identify the
commonplace material in an input text. Pre-specified summary tem-
plates, each associated with a different topic, are used to condense the
commonplace material in the input. Filled-in summary templates are
then used to form a framework into which unexpected material in the
input may be fitted, allowing unexpected material to appear in output
summary texts in an essentially unreduced form. The system&apos;s sum-
maries are in English.
The program is based on technology not dissimilar to a script applier.
However, Scrabble represents a significant advance over previous
script-based summarising systems. It is much less likely to produce
misleading summaries of an input text than some previous systems, and
can operate with less information about the subject domain of the
input than others.
These improvements are achieved by the use of three main novel
ideas. First, the system incorporates a new method for identifying the
topic or topics of an input text. Second, it allows a section of text to
have more than one topic at a time, or at least a composite topic
which may best be dealt with by the computer program simultaneously
applying to the text predictions associated with more than one simple
topic. Third, Scrabble incorporates new mechanisms for the incorpora-
tion of unexpected material in the input into its output summary texts.
The incorporation of such material in the output summary is motivated
by the view that it is precisely unexpected material which is likely to
form the most salient matter in the input text.
The performance of the system is illustrated by means of a number
of example input texts and their corresponding Scrabble summaries.
The paper describes a mechanism for the representation and applica-
tion of context information for automatic natural language processing
systems. Context information is gathered gradually during the reading
of the text, and the mechanism gives a way of combining the effect of
several different types of context factors. Context factors can be
</bodyText>
<page confidence="0.974544">
46 Computational Linguistics, Volume 10, Number 1 January-March 1984
</page>
<note confidence="0.527791">
The FINITE STRING Abstracts of Current Literature
</note>
<bodyText confidence="0.999829833333333">
managed independently, while still allowing efficient access to entities
in focus. The mechanism is claimed to be more general than the global
focus mechanism used by Grosz for discourse understanding. Context
affects the interpretation process by choosing the results, and restrict-
ing the processing, of a number of important language interpretation
operations, including lexical disambiguation and reference resolution.
The types of context factors that have been implemented in an exper-
imental system are described, and examples of the application of
context are given.
Following are the titles and abstracts of reports and memos recently published by the Research Unit for
Information Science and Artificial Intelligence at the University of Hamburg. Single copies of papers still in print
are available, free of charge. Please write
</bodyText>
<figure confidence="0.649096076923077">
Ms. Angela Carstensen
Reseach Unit for Information Science and Artificial Intelligence
University of Hamburg
Mittelweg 179
D-2000 Hamburg 13, WEST GERMANY
Surface Transformation during the
Generation of Written German Sen-
tences
Stephan Busemann
Report ANS-23. In Neumann, B., Ed.,
GWAI-83. 7th German Workshop in
Artificial Intelligence.
Dassel, September 1983: 90-99.
</figure>
<subsectionHeader confidence="0.9984505">
The Real Estate Agent — Modeling
Users by Uncertain Reasoning
Katharine Monk,
Claus-Rainer Rollinger
</subsectionHeader>
<bodyText confidence="0.960933">
Report No. ANS-24. In Neuman, B., Ed.,
GWAI-83: 158-168.
</bodyText>
<subsectionHeader confidence="0.96486775">
User Modelling and Profiles of Inter-
est in Artificial Intelligence Dialog
Systems
Katharina Monk
</subsectionHeader>
<bodyText confidence="0.945384965517241">
Report No. ANS-25. To appear in
This paper gives an overview of the modular and adaptable system
SUTRA for surface transformations. The system generates written
German sentences from an intermediate structure consisting solely of
data based on knowledge which was already required for an earlier
stage of the generation process. SUTRA may thus be employed in any
generation system for the German language which produces such
intermediate structures. SUTRA works in two steps. During the syn-
tactical stage, several processes transform the intermediate structure
into a linear string, thereby generating discontinuous verb constituents,
arranging sentence components using separate ordering rules, mapping
deep cases onto surface cases, and extracting further morpho-
syntactical properties from the intermediate structure (e.g., number)
and the word lexicon of the generation system (e.g., gender). During
the morphological stage, the terminal word forms are generated from
the linear string using classification schemas for the different inflec-
tional paradigms of German word stems. SUTRA is currently employed
in the generation component of the natural language dialogue system
HAM-ANS.
Two topics are treated in this article. Firstly, a user model patterned
after the stereotype approach is presented. This model surpasses
Rich&apos;s model with respect to its greater flexibility in the construction
of user profiles and its treatment of positive and negative arguments.
Secondly, an inference machine is presented. This machine treats
uncertain knowledge in the form of evidence for and against the accu-
racy of a proposition. Truth values are replaced by the concept of a
two-dimensional evidence space. The consequences of the concept,
particularly with regard to verification, are discussed. The connection
between these two topics is established by implementation of the user
model on the inference machine.
In this paper the necessity for user modeling is demonstrated for three
types of systems: information retrieval systems, tutor systems, and
natural language systems. Three facets of user modeling — familiarity
with system use, expertise in a domain, and profile of interests — are
distinguished. Techniques for building up user profiles and utilizing
Computational Linguistics, Volume 10, Number 1 January-March 1984 47
The FINITE STRING Abstracts of Current Literature
Report on a Lecture and Fact-Finding
Tour in the USA in Late Summer 1983
Thomas Christaller,
Wolfgang Hoeppner
Memo No. ANS-19, October 1983.
them to govern system behavior are described. With regard to natural
language systems, our work on user modeling for HAM-ANS is present-
ed in some detail.
The first part of this study presents the manual transporting of the Al
language FUZZY from UCI-LISP to Franz Lisp. The problems encoun-
tered in this process and their solution are taken up in the second part,
dealing with the evaluation of different transporting procedures for
LISP-programs. The best procedures are based on production rule
systems. These must, however, offer the capability of interacting
with the user in doubtful cases.
This paper investigates the integration of an automatic spelling-
correction component in an AI-system. First the basic requirements
for such a correction procedure are presented. The major part of the
paper consists of a critical examination of different correction meth-
ods, which formed the basis for the automatic spelling-correction
component integrated in HAM-ANS.
</bodyText>
<figure confidence="0.97445184375">
Rollinger, C.-R., Ed., Probleme
des (Text-) Verstehens Aneatze
der Kunstlichen Intelligenz. (Sprache
and Information). Tlibingen, 1984
A Study of LISP-Program-Transpor-
tation
Thomas Christaller
Memo No. ANS-17, July 1983.
Considerations for Automatic Spelling
Correction in an Al System
Michael Fliegner
Memo No. GEN-18, September 1983.
I I
CCA
BBN
• • MIT
Boston
University of
Pennsylvania
Phi/ade/phi
49
Washington
AAAI-83
New Brunswick
Rutgers University
San Francisco
Stanford University
SRI
Hewlett Packard
Berkeley
Dynamic Storage Allocation Strategy
for UCI-LISP
</figure>
<figureCaption confidence="0.3631185">
Rolf Dannenberg, Bernhard Nebel
Memo No. ANS-20, November 1983.
</figureCaption>
<bodyText confidence="0.8866515">
Approaches to a Semantic Represen-
tation for Natural Language Access
to a Relational Data Base.
Henning Bergmann,
Annedore Paeseler
Memo No. ANS-21, December 1983.
After criticizing the current strategy of memory reallocation in
UCI-LISP, we discuss several alternative possibilities for realizing
dynamic strategies under the TOPS10 operating system. The imple-
mentation of the chosen method, which is from the users&apos; point of
view almost as convenient as memory management in INTERLISP, is
described and the user interface is documented.
Natural language access systems to formatted mass data administered
by DBMSs (data base management systems) have been available for a
number of years. The inadequacy of these systems is, for the most
part, a result of an insufficient representation of knowledge about the
interfaced DBMS and the domain of discourse modeled by the stored
data. Taking a specific relational data base as a point of departure, we
first discuss preliminary considerations for the representation of this
knowledge. Next we describe the design of such a representation and
its implementation in the frame-oriented AI-langauge FRL. The char-
acteristics of our approach are: organization of knowledge in a gener-
alization hierarchy, the use of deep-case frames and the attachment of
procedures for the generation of database queries.
</bodyText>
<page confidence="0.872886">
48 Computational Linguistics, Volume 10, Number 1 January-March 1984
</page>
<table confidence="0.983928928571428">
The FINITE STRING Abstracts of Current Literature
The following abstracts are from Proceedings of the First Conference of the European Chapter of the Association for
Computational Linguistics, available for $15 a copy from
Donald E. Walker, ACL
Bell Communications Research
445 South Street
Morristown, NJ 07960 USA
Abstract Control Structures and the
Semantics of Quantifers
Steven Cushing
Computer Science Department
St. Anselm College
Manchester, NH 03102
Proc. EACL 1983, pp. 1-8
</table>
<bodyText confidence="0.9998638">
Intuitively, a quantifier is any word or phrase that expresses a meaning
that answers one of the questions &amp;quot;How many?&amp;quot; or &amp;quot;How much?&amp;quot;
Typical English examples include all, no, many, few, some but not
many, all but at most a very few, wherever, whoever, whoever there is, and
also, it can be argued, only, also, and the. In this paper we review an
empirically motivated analysis of such meanings and draw out its
computational significance. For purposes of illustration, we focus our
attention on the meanings expressed by the English words whatever and
some, commonly represented, respectively, by the symbols &amp;quot;V&amp;quot; and
&amp;quot;3&amp;quot;, but most of what we say will generalize to the other meanings of
this class.
In Section 1, we review the notion of satisfaction in a model, through
which logical formulas are customarily imbued implicitly with meaning.
In Section 2, we discuss quantifier relativization, a notion that be-
comes important for meanings other than V and 3. In Section 3, we
use these two notions to characterize quantifier meanings as structured
functions of a certain sort. In Section 4, we discuss the computational
significance of that analysis. In Section 5, we elaborate on this signifi-
cance by outlining a notion of abstract control structure that the
analysis instantiates.
Commonly used grammars that describe natural languages (e.g., ATN,
Metamorphonic Grammars) can hardly be applied in describing highly
inflectional languages. So I propose a grammar called the grammar
with natural context, which takes into consideration properties of
highly inflectional languages (e.g., Polish) as well as structural lan-
guages (e.g., English). I introduce its normal form.
We present in this article, as part of an aspectual operation system, a
generation system of iterative expressions using a set of operators
called iterative operators. In order to execute the iterative operations
efficiently, we have classified previously propositions denoting a single
occurrence of a single event into three groups. The definition of a
single event is given recursively. The classification has been carried
out especially in consideration of the durative/non-durative character
of the denoted events and also in consideration of existence/non-
existence of a culmination point (or a boundary) in the events. The
operations concerned with iteration have either the effect of giving a
boundary to an event (in the case of a non-bounded event) or of
extending an event through repetitions. The operators concerned are:
N,F — direct iterative operators; I,G — boundary giving operators; I —
extending operator. There are direct and indirect operations: the
direct ones change a non-repetitious proposition into a repetitious one
directly, whereas the indirect ones change it indirectly. The indirect
iteration is indicated with E. The scope of each operator is not
uniquely definable, though the mutual relation of the operators can
be given more or less explicitly.
</bodyText>
<table confidence="0.97529312244898">
L&apos;idee de Grammaire avec le Contexte
Nature!
Leszek Haduch
Institute of Informatics
Technical University of Lodz
Lodz, ul.Piotrkowska 220, Poland
Proc. EACL 1983, pp. 9-13
Iterative Operations
Sae Yamada
Notre Dame Seishin University
Ifuku-Cho 2-16-9
700 Okayama, Japan
Proc. EACL 1983, pp. 14-20
Computational Linguistics, Volume 10, Number 1 January-March 1984 49
The FINITE STRING Abstracts of Current Literature
Structure of Sentence and Inferencing
in Question Answering
Eva Hajieovd, Petr Sgall
Faculty of Mathematics and Physics
Charles University
Malostransk6 n. 25
118 00 Praha 1 Czechoslovakia
Proc. EACL 1983, pp. 21-25
A Phonological Processor for Italian
Rodolfo Delmonte
Centro Linguistico Interfacolta
Universi-th degli Studi di Venezia
Ca&apos; Garzoni-Moro - S. Marco 3417
Proc. EACL 1983, pp. 26-34
An Expert System for the Production
of Phoneme Strings from Unmarked
English Text using Machine-Induced
Rules
Alberto Maria Segre
Coordinated Science Laboratory
Bruce Arne Sherwood
Computer-Based Education Research
Laboratory
Wayne B. Dickerson
English as a Second Language
University of Illinois at Urbana-Champaign
Urbana, IL 61801
Proc. EACL 1983, pp. 35-42
Vocal Interface for a Man-Machine
Dialog
Dominique Beroule
LIMSI (CNRS)
B.P. 30
91406 Orsay CEDEX France
</table>
<subsubsectionHeader confidence="0.447065">
Proc. EACL 1983, pp. 43-48
</subsubsectionHeader>
<bodyText confidence="0.999949711538462">
In the present paper we characterize in more detail some of the aspects
of a question answering system using as its starting point the underly-
ing structure of sentences (which with some approaches can be identi-
fied with the level of meaning or of logical form). First of all, the
criteria are described that are used to identify the elementary units of
underlying structure and the operations conjoining them into complex
units (Section 1), then the main types of units and operations resulting
from an empirical investigation on the basis of the criteria are regis-
tered (Section 2), and finally the rules of inference, accounting for the
relevant aspects of the relationship between linguistic and cognitive
structures are illustrated (Section 3).
A computer program for the automatic translation of any text of
Italian into naturally fluent synthetic speech is presented. The pro-
gram, or Phonological Processor (hence FP) maps into prosodic struc-
tures the phonological rules of Italian. Structural information is pro-
vided by such hierarchical prosodic constituents as Syllable (S), Metri-
cal Foot (MF), Phonological Word (PW), Intonational Group (IG).
Onto these structures, phonological rules are applied such as the
&amp;quot;letter-to-sound&amp;quot; rules, automatic word stress rules, internal stress
hierarchy rules indicating secondary stress, external sandhi rules,
phonological focus assignment rules, logical focus assignment rules.
The FP constitutes also a model to simulate the reading process aloud,
and the psycholinguistics and cognitive aspects related will be dis-
cussed in the computational model of the FP. At present, Logical
Focus assignment rules and the computational model are work in
progress still to be implemented in the FP. Recorded samples of
automatically produced synthetic speech will be presented at the
conference to illustrate the functioning of the rules.
The speech synthesis group at the Computer-Based Education Re-
search Laboratory (CERL) of the University of Illinois at Urbana-
Champaign is developing a diphone speech synthesis system based on
pitch-adaptive short-time Fourier transforms. This system accepts the
phonemic specification of an utterance along with pitch, time and
amplitude warping functions in order to produce high quality speech
output from stored diphone templates.
This paper describes the operation of a program which operates as a
front end for the diphone speech synthesis system. The UTTER (for
&amp;quot;Unmarked Text Transcription by Expert Rule&amp;quot;) system maps English
text onto a phoneme string, which is then used as an input to the
diphone speech synthesis system. The program is a two-tiered Expert
System which operates first on the word level and then on the (vowel
or consonant) cluster level. The system&apos;s knowledge about pronuncia-
tion is organized in two decision trees automatically generated by an
induction algorithm on a dynamically specified &amp;quot;training set&amp;quot; of exam-.
ples.
We describe a dialog-handling module used as an interface between a
vocal terminal and a task-oriented device (for instance, a robot manip-
ulating blocks). This module has been specially designed to be im-
planted on a single board using a microprocessor, and inserted into the
vocal terminal which already comprises a speech recognition board and
a synthesis board. The entire vocal system is at present capable of
conducting a real time spoken dialog with its user.
</bodyText>
<page confidence="0.850679">
50 Computational Linguistics, Volume 10, Number 1 January-March 1984
</page>
<figure confidence="0.720600633333333">
The FINITE STRING Abstracts of Current Literature
Knowledge Engineering Approach to
Morphological Analysis
Harri Jappinen, Aarno Lehtola,
Esa Nelimarkka, Matti Ylilammi
Helsinki University of Technology
Helsinki, Finland
Proc. EACL 1983, pp. 49-51
A PROLOG Implementation of Lexical
Functional Grammar as a Base for a
Natural Language Processing System
Werner Frey, Uwe Reyle
Department of Linguistics
University of Stuttgart
West Germany
Proc. EACL 1983, pp. 52-57
Extended Access to the Left Context
in an ATN Parser
Irina Prodanof, Giacomo Ferrari
Istituto di Linguistica Computazionale
Via della Faggiola 32
1-56100 Pisa, Italy
Proc. EACL 1983, pp. 58-65
An Experiment with Heuristic Parsing
of Swedish
Benny Brodda
Institute of Linguistics
University of Stockholm
S-106 91 Stockholm SWEDEN
Proc. EACL 1983, pp. 66-73
</figure>
<subsectionHeader confidence="0.4109835">
Towards the Semantics of Sentence
Adverbials
</subsectionHeader>
<footnote confidence="0.445435">
Eva Koktova
9. kv6tna 1576
</footnote>
<bodyText confidence="0.999520865384616">
Finnish is a highly inflectional language. A verb can have over ten
thousand different surface forms — nominals slightly fewer. Conse-
quently, a morphological analyzer is an important component of a
system aiming at &amp;quot;understanding&amp;quot; Finnish. This paper briefly de-
scribes our rule-based heuristic analyzer for Finnish nominal and verb
forms. Our tests have shown it to be quite efficient: the analysis of a
Finnish word in a running text takes an average of 15 ms of DEC 20
CPU time.
The aim of this paper is to present parts of our system, which is to
construct a data base out of a narrative natural language text. We
think the parts are of interest on their own. The paper consists of
three sections: (I) We give a detailed description of the PROLOG
implementation of the parser, which is based on the theory of lexical
functional grammar. (II) For the semantic representation of texts we
use the Discourse Representation Theory developed by Hans Kamp.
(III) Finally we sketch how the parser formalism can be augmented to
yield as output discourse representation structures.
Some Italian sentences related to linguistic phenomena largely known
and recently discussed by many computational linguists are discussed
in the framework of ATN. They offer certain difficulties which seem
to suggest a substantial revision of the ATN formalism. The theoretical
assumptions and an experimental implementation of such a revision are
presented together with examples. Many related theoretical points,
such as some psycholinguistic implications and the relationship be-
tween deterministic and non-deterministic hypothesis are also briefly
discussed.
Heuristic parsing is the art of doing parsing in a haphazard and seem-
ingly careless manner but in such a way that the outcome is still
&amp;quot;good&amp;quot;, at least from a statistical point of view, or, hopefully, even
from a more absolute point of view. The idea is to find strategic
shortcuts derived from guesses about the structure of a sentence based
on scanty observations of linguistic units in the sentence. If the guess
comes out right, much parsing time can be saved; and if it does not,
many subobservations may still be valid for revised guesses. In the
(very preliminary) experiment reported here, the main idea is to make
use of (combinations of) surface phenomena as much as possible as
the base for the prediction of the structure as a whole. In the parser
to be developed along the lines sketched in this report, the main stress
is put on arriving at independently working, parallel recognition proce-
dures.
The work reported here is aimed both at simulating certain aspects of
human language perception and at arriving at effective algorithms for
actual parsing of running text. There is, indeed, a great need for fast
such algorithms, e.g. for the analysis of the literally millions of words
of running text that already today comprise the data bases in various
large information retrieval systems, and which can be expected to
expand several orders of magnitude both in importance and in size in
the foreseeable future.
In the present paper we argue that the so-called sentence adverbials
(typically, adverbs like probably, admittedly, ...) should be generated, in
the framework of Functional Generative Description, by means of a
special deep case — Complementation of Attitude (CA) on grounds of
</bodyText>
<table confidence="0.3478235">
Computational Linguistics, Volume 10, Number 1 January-March 1984 51
The FINITE STRING Abstracts of Current Literature
39001 Tabor, Czechoslovakia
Proc. EACL 1983, pp. 74-80
</table>
<tableCaption confidence="0.235794">
Dealing with Conjunctions in a Ma-
chine Translation Environment
</tableCaption>
<figure confidence="0.657429809523809">
Xiuming Huang
Institute of Linguistics
Chinese Academy of Social Sciences
Beijing, China
Proc. EACL 1983, pp. 81-85
Fallible Rationalism and Machine
Translation
Geoffrey Sampson
Linguistics &amp; Modern English Language
University of Lancaster
Lancaster LA1-4YT, G.B.
Proc. EACL 1983, pp. 86-89
The Generation of Term Definitions
from an Online Terminological
Thesaurus
John McNaught
Centre for Computational Lingustics
UMIST
P.O. Box 88
Manchester, UK
Proc. EACL 1983, pp. 90-95
</figure>
<subsectionHeader confidence="0.689805">
Relating Syntax and Semantics: The
Syntactico-semantic Lexicon of the
System VIE-LANG
Ingeborg Steinacker,
Ernst Buchberger
Medical Cybernetics
</subsectionHeader>
<affiliation confidence="0.754908">
University of Vienna, Austria
</affiliation>
<subsubsectionHeader confidence="0.605622">
Proc. EACL 1983, pp. 96-100
</subsubsectionHeader>
<bodyText confidence="0.999794773584906">
their special behaviour in the topic-focus articulation (TFA) of a sen-
tence. From the viewpoint of the translation of CA expressions (and
also of the multiple occurrence thereof inside a sentence) into a calcu-
lus of intensional logic, it should be noted that the TFA properties of
CA expressions are directly correlated to the scope properties thereof.
Our approach, which is stated in terms of a linguistic theory, serves as
a basis for an algorithm of analysis of CA for purposes of a system of
man-machine communication without a pre-arranged data base.
A set of rules, named CSDC (Conjunction Scope Determination Con-
straints), is suggested for attacking the conjunct scope problem, the
major issue in the automatic processing of conjunctions which has been
raising great difficulty for natural language processing systems. Gram-
mars embodying the CSDC are incorporated into an existing ATN
parser, and are tested successfully against a wide group of &amp;quot;and&amp;quot;
conjunctive sentences, which are of three types: clausal coordination,
phrasal coordination, and gapping. With phrasal coordination, the
structure with two NPs coordinated by &amp;quot;and&amp;quot; has been given the most
attention.
It is hoped that an ATN parser capable of dealing with a large variety
of conjunctions in an efficient way will finally emerge from the pre-
sented work.
Approaches to MT have been heavily influenced by changing trends in
the philosophy of language and mind Because of the artificial hiatus
which followed the publication of the ALPAC Report, MT research in
the 1970s and early 1980s has had to catch up with major develop-
ments that have occurred in linguistic and philosophical thinking;
currently, MT seems.to be uncritically loyal to a paradigm of thought
about language which is rapidly losing most of its adherents in depart-
ments of linguistics and philosophy. I argue, both in theoretical terms
and by reference to empirical research on a particular translation
problem, that the Popperian &amp;quot;falliable rationalist&amp;quot; view of mental
processes which is winning acceptance as a more sophisticated alter-
native to Chomskyan &amp;quot;deterministic rationalism&amp;quot; should lead MT re-
searchers to redefine their goals and to adopt certain currently-
neglected techniques in trying to achieve those goals.
A new type of machine dictionary is described, which uses terminologi-
cal relations to build up a semantic network representing the terms of
a particular subject field, through interaction with the user. These
relations are then used to dynamically generate outline definitions of
terms in online query mode. The definitions produced are precise,
consistent and informative, and allow the user to situate a query term
in the local conceptual environment. The simple definitions based on
terminological relations are supplemented by information contained in
facets and modifiers, which allow the user to capture different views of
the data.
This paper describes the structure and evaluation of the syntactico-
semantic lexicon (SSL) of the German Natural Language Understand-
ing System VIE-LANG. VIE-LANG uses an SI-Net as internal repre-
sentation. The SSL contains the rules according to which the mapping
between net-structures and surface structures of a sentence is carried
out. This information is structured in such a way that it can be evalu-
ated from two sides. The parser interprets it as production-rules that
control the analysis. Syntactic and semantic features of the input
</bodyText>
<page confidence="0.963996">
52 Computational Linguistics, Volume 10, Number 1 January-March 1984
</page>
<note confidence="0.831433">
The FINITE STRING Abstracts of Current Literature
</note>
<bodyText confidence="0.9977684">
sentence are evaluated and individuals are created in the semantic net.
The generator uses the same rules to express selected net-structures in
adequate natural language expressions. It is shown how both processes
can make effective use of SSL. The different possibilities for evalu-
ating the SSL are explained and illustrated by examples.
</bodyText>
<table confidence="0.7813037">
An Island Parsing Interpreter for the
Full Augmented Transition Network
Formalism
John A. Carroll
University of Cambridge Computer
Laboratory
Corn Exchange Street
Cambridge CB2 30G England
Proc. EACL 1983, pp. 101-105
WEDNESDAY: Parsing Flexible Word
Order Languages
Oliviero Stock, Cristiano Castel-
franchi, Domenico Parisi
Istituto di Psicologia
del Consiglio Nazionale delle Ricerche
Via dei Monti Tiburtini 509, 00157 Roma
Proc. EACL 1983, pp. 106-110
How to Parse Gaps in Spoken
Utterances
G. Goerz, C. Beckstein
</table>
<footnote confidence="0.59273775">
Univ. Erlangen-Nuernberg, RRZE
Martensstr. 1
D-8520 Erlangen, W. Germany
Proc. EACL 1983, pp. 111-113
</footnote>
<subsectionHeader confidence="0.546388666666667">
A Flexible Natural Language Parser
Based on a Two-Level Representation
of Syntax
</subsectionHeader>
<bodyText confidence="0.991717617021277">
Island parsing is a powerful technique for parsing with Augmented
Transition Networks (ATNs) which was developed and successfully
applied in the HWIM speech understanding project. The HWIM appli-
cation grammar did not, however, exploit Woods&apos; original full ATN
specification. This paper describes an island parsing interpreter based
on HWIM but containing substantial and important extensions to
enable it to interpret any grammar which conforms to that full specifi-
cation of 1970. The most important contributions have been to elimi-
nate the need for prior specification of scope clauses, to provide more
power by implementing LIFTR and SENDR actions within the island
parsing framework, and to improve the efficiency of the techniques
used to merge together partially-built islands within the utterance.
This paper also presents some observations about island parsing,
based on the use of the parser described, and some suggestions for
future directions for island parsing research.
A parser for &amp;quot;flexible&amp;quot; word order languages must be substantially
data driven. In our view syntax has two distinct roles in this connec-
tion: (i) to give impulses for assembling cognitive representations, (ii)
to structure the space of search for fillers. WEDNESDAY is an inter-
preter for a language describing the lexicon and operating on natural
language sentences. The system operates from left to right, interpret-
ing the various words comprising the sentence one at a time. The
basic ideas of the approach are the following:
a) To introduce into the lexicon linguistic knowledge that in other
systems is in a centralized module. The lexicon therefore carries not
only morphological data and semantic descriptions. Syntactic knowl-
edge, partly of a procedural kind, also is distributed throughout it.
b) To build progressively a cognitive representation of the sentence
in the form of a semantic network, in a global space, accessible from
all levels of the analysis.
c) To introduce procedures invoked by the words themselves for
syntactic memory management. Simply stated, these procedures decide
on the opening, closing, and maintaining of search spaces; they use
detailed constraints and take into account the active expectations.
WEDNESDAY is implemented in MAGMA-LISP, with a stress on the
non-deterministic mechanism.
We describe GLP, a chart parser that will be used as a SYNTAX mod-
ule of the Erlangen Speech Understanding System. GLP realizes an
agenda-based multiprocessing scheme, which allows us to apply easily
various parsing strategies in a transparent way. We discuss which
features have been incorporated into the parser in order to process
speech data, in particular the ability to perform direction independent
island parsing, to handle gaps in the utterance and its hypothesis
scoring scheme.
In this paper we present a parser which allows us to make explicit the
interconnections between syntax and semantics, to analyze the sen-
tences in a quasi-deterministic fashion and, in many cases, to identify
</bodyText>
<table confidence="0.756192866666667">
Computational Linguistics, Volume 10, Number 1 January-March 1984 53
The FINITE STRING Abstracts of Current Literature
Leonardo Lesmo, Pietro Torasso
Istituto di Scienze dell-Informazione
Universa di Torino
C.so Massimo D&apos;Azeglio 42
10125 TORINO - ITALY
Proc. EACL 1983, pp. 114-121
An Approach to Natural Language in
the SI-Nets Paradigm
Amedeo Cappelli, Lorenzo Moretti
Istituto di Linguistica Computazionale,
CNR
Via della Faggiola, 32
56100 Pisa - Italy
</table>
<reference confidence="0.799347736842105">
Proc. EACL 1983, pp. 122-128
An Experiment on Synthesis of Rus-
sian Parametric Constructions
I.S. Kononenko, E.L. Pershina
Al Laboratory, Computing Center
Siberian Branch of the USSSR Ac. Sci.
Novosibirsk 630090, USSR
Proc. EACL 1983, pp. 129-132
Learning Translation Skills with a
Knowledge-Based Tutor: French-
Italian Conjunctions in Context
Stefano A. Cerni
Dipartimento di lnformatica
Marie-France Merger
Dipartimento di Lingue e Letterature
Romanze
Universifa di Pisa
56100 Pisa, Italy
Proc. EACL 1983, pp. 133-138
</reference>
<bodyText confidence="0.999697549019608">
the roles of the various constituents even if the sentence is ill-formed.
The main feature of the approach on which the parser is based com-
prises a two-level representation of the syntactic knowledge: a first set
of rules emits hypotheses about the constituents of the sentence and
their functional role and another set of rules verifies whether a hypoth-
esis satisfies the constraints about the well-formedness of sentences.
However, the application of the second set of rules is delayed until the
semantic knowledge confirms the acceptability of the hypothesis. If
the semantics reject it, a new hypothesis is obtained by applying a
simple and relatively inexpensive &amp;quot;natural&amp;quot; modification; a set of these
modifications is predefined and only when none of them is applicable
is a real backup performed: in most cases this situation corresponds
to a case where people would normally garden path.
This article deals with the interpretation of conceptual operations
underlying the communicative use of natural language (NL) within the
Structured Inheritance Network (SI-Nets) paradigm. The operations
are reduced to functions of a formal language, thus changing the level
of abstraction of the operations on SI-Nets In this sense, operations
on SI-Nets are not merely isomorphic to single epistemological objects,
but can be viewed as a simulation of processes on a different level,
that pertaining to the conceptual system of NL. For this purpose, we
have designed a version of KL-ONE which represents the epistemologi-
cal level, while the new experimental language, KL-Conc, represents
the conceptual level. KL-Conc would seem to be a more natural
and intuitive way of interacting with SI-Nets.
The paper describes an experimental model of syntactic structure
generation starting from the limited fragment of semantics that deals
with the quantitative values of object parameters. To present the
input information the basic semantic units of four types are proposed:
&amp;quot;object&amp;quot;, &amp;quot;parameter&amp;quot;, &amp;quot;function&amp;quot; and &amp;quot;constant&amp;quot;. For the syntactic
structure representation, the system of syntactic components is used
that combines the properties of the dependency and constituent sys-
tems: the syntactic components corresponding to word forms and
exocentric constituents are introduced and two basic subordinate
relations (&amp;quot;actant&amp;quot; and &amp;quot;attributive&amp;quot;) are claimed to be necessary.
Special attention has been devoted to problems of complex correspon-
dence between the semantic units and lexical-syntactic means. In the
process of synthesis such sections of the model as the lexicon, the
syntactic structure generation rules, the set of syntactic restrictions
and morphological operators are utilized to generate the considerable
enough subset of Russian parametric constructions.
This paper describes an &amp;quot;intelligent&amp;quot; tutor of foreign language con-
cepts and skills based upon state-of-the-art research in Intelligent
Teaching Systems and Computational Linguistics.
The tutor is part of a large R&amp;D project in ITS which resulted in a
system (called DART) for the design and development of intelligent
teaching dialogues on PLATO and in a program (called ELISA) for
teaching foreign language conjunctions in context. ELISA was able to
teach a few conjunctions in English, Dutch and Italian. The research
reported here extends ELISA to a complete set of conjunctions in
Italian and French.
</bodyText>
<page confidence="0.914729">
54 Computational Linguistics, Volume 10, Number 1 January-March 1984
</page>
<table confidence="0.515809307692308">
The FINITE STRING Abstracts of Current Literature
Towards Better Understanding Of
Anaphora
Barbara Dunin-Keplicz
Institute of Informatics
Warsaw University
P.O. Box 1210
00-901 Warszawa, Poland
Proc. EACL 1983, pp. 139-143
Rules for Pronominalization
Franz Guenthner, Hubert Lehmann
IBM Deutschland GmbH
Heidelberg Science Center
Tiergartenstr. 15
D-6900 Heidelberg, FRG
Proc. EACL 1983, pp. 144-151
Local and Global Structures in Dis-
course Understanding
M. Koit, S. Litvak, H. Oim,
T. Roosmaa, M. Saluveer
Artificial Intelligence Laboratory
Tartu State University
202400 Tartu, Estonian S.S.R, U.S.S.R.
Proc. EACL 1983, pp. 152-154
Systemic Grammar in Computation:
The Nigel Case
</table>
<reference confidence="0.894028">
Christian M.I.M. Matthiessen
USC/Information Sciences Institute
4676 Admiralty Way
Marina del Rey, CA 90292
Proc. EACL 1983, pp. 155-164
Inquiry Semantics: A Functional Se-
mantics of Natural Language Grammar
William C. Mann
USC/Information Sciences Institute
4676 Admiralty Way
</reference>
<bodyText confidence="0.992942920792079">
This paper represents a syntactical method of interpreting pronouns in
Polish. Using the surface structure of the sentence as well as gram-
matical and inflexional information accessible during syntactic analysis,
an area of reference is marked out for each personal and possessive
pronoun. This area consists of a few internal areas inside the current
sentence and an external area, i.e., the part of the text preceding it. In
order to determine that area of reference, several syntactic sentence-
level restrictions on anaphora interpretation are formulated.
Next, when looking at the area of the pronoun&apos;s reference, all NPs
which number-gender agree with the pronoun can be selected, and this
way the set of surface referents of each pronoun can be created. It can
be used as data for further semantic analysis.
Rigorous interpretation of pronouns is possible when syntax, seman-
tics, and pragmatics of a discourse can be reasonably controlled.
Interaction with a data base provides such an environment. In the
framework of the User Specialty Languages system and Discourse
Representation Theory, we formulate strict and preferential rules for
pronominalization and outline a procedure to find proper assignments
of referents to pronouns.
We are interested in the nature of content structures in terms of which
it would be possible to account for reasoning processes in understand-
ing natural language texts. One of the most crucial problems here at
the present time is: how and by which mechanisms these reasoning
processes are controlled and directed. As the emphasis in the design
of discourse understanding systems so far has been on the problems of
knowledge organization and representation, we are only beginning to
guess what the corresponding processing mechanisms are and how they
function, although an increasing number of papers has been devoted to
these problems as well. There are studies of the relation of under-
standing to such types of knowledge processing as problem solving and
planning. Various types of content units and structures needed to
account for knowledge processing have been proposed in the general
context of modeling discourse understanding. We ourselves have
discussed an approach to knowledge units and processing mechanisms
in questions, as a part of a computer system which understands stories
of a certain kind, as well as on a more theoretical level.
Computational linguistics needs grammars for several different tasks
such as comprehension of text, machine translation, and text genera-
tion. Clearly, any approach to grammar has potentially something to
offer computational linguistics, say for parsing or text generation (and,
by the same token, there is a potential benefit from an application
within computational linguistics for each approach). However, it is
equally clear that some approaches have much more to offer than
others. Here I take a look at Systemic Linguistics in the service of
computational linguistics tasks, concentrating on a large computational
systemic grammar for text generation (Nigel) that is currently being
developed.
Programming a computer to operate to a significant degree as an
author is a challenging research task. The creation of fluent multipara-
graph text is a complex process because knowledge must be expressed
in linguistic forms at several levels of organization, including para-
graphs, sentences and words, each of which involves its own kinds of
Computational Linguistics, Volume 10, Number 1 January-March 1984 55
The FINITE STRING Abstracts of Current Literature
Marina del Rey, CA 90292
Proc. EACL 1983, pp. 165-174
complexity. Accommodating this natural complexity is a difficult
design problem. To solve it we must separate the various relevant
kinds of knowledge into nearly independent collections, factoring the
problem.
Inquiry semantics is a new factoring of the text generation problems.
It is novel in that it provides a distinct semantic for the grammar,
independent of world knowledge, discourse knowledge, text plans and
the lexicon, but appropriately linked to each. It has been implemented
as part of the Nigel text generation grammar of English.
This paper characterizes inquiry semantics, shows how it factors text
generation, and describes its exemplification in Nigel. The resulting
description of inquiries for English has three dimensions: the varieties
of operations on information, the varieties of information operated
upon, and the subject matter of the operations. The definition frame-
work for inquiries involves both traditional and nontraditional linguis-
tic abstractions, spanning the knowledge to be represented and the
plans required for presenting it.
In this paper a system which understands and conceptualizes scene
descriptions in natural language is presented. Specifically, the follow-
ing components of the system are described: the syntactic analyzer,
based on a Procedural Systemic Grammar; the semantic analyzer
relying on the Conceptual Dependency Theory; and the dictionary.
In the project &amp;quot;Procedural Dialogue Models&amp;quot; being carried on at the
University of Bielefeld, we have developed an incremental multi-level
parsing formalism to reconstruct task-oriented dialogues. A major
difficulty we have had to overcome is that the dialogues are real ones
with numerous ungrammatical utterances. The approach we have
devised to cope with this problem is reported here.
This paper addresses the problem of generating communicatively
adequate extended responses in the absence of specific knowledge
concerning the intensions of the questioner. We formulate and justify
a heuristic for the selection of optional deep case slots not contained in
the question as candidates for the additional information contained in
an extended response. It is shown that, in a visually present domain of
discourse, case role filling for the construction of an extended response
can be regarded as a side effect of the visual search necessary to
answer a question containing a locomotion verb. This paper describes
the various representation constructions used in the German language
dialog system HAM-ANS for dealing with the semantics of locomotion
verbs and illustrates their use in generating extended responses. In
particular, we outline the structure of the geometrical scene descrip-
tion, the representation of events in a logic-oriented semantic repre-
sentation language, the case-frame lexicon and the representation of
the referential semantics based on the Flavor system. The emphasis is
on a detailed presentation of the application of object-oriented pro-
</bodyText>
<figure confidence="0.982882914285714">
Natural Language Input for Scene
Generation
Giovanni Adorni, Mauro DiManzo
Istituto di Elettrotechnica, U. of Genoa
Viale F.Causa 13
16145 Genoa, Italy
Giacomo Ferrari
Istituto di Linguistica Computazionale,
CNR
Via della Faggiola
56100 Pisa, Italy
Proc. EACL 1983, pp. 175-182
A Multilevel Approach to Handle Non-
standard Input
Manfred Gehrke
Linguistics and Literature
University of Bielefeld
P.O. Box 8640
D-4800 Bielefeld 1
Proc. EACL 1983, pp. 183-187
Case Role Filling as a Side Effect of
Visual Search
Heinz Marbur ger
Research Unit for Information Science
and Artificial Intelligence
University of Hamburg
Mittelweg 179
D-2000 Hamburg 13, F.R. Germany
Wolfgang Wahlster
FB10 - Angewandte Mathematik und
lnformatik
University of Saarbrucken
Im Stadtwald
D-6600 Saarbrucken 11, F.R. Germany
Proc. EACL 1983, pp. 188-195
</figure>
<page confidence="0.798836">
56 Computational Linguistics, Volume 10, Number 1 January-March 1984
</page>
<note confidence="0.542934">
The FINITE STRING Abstracts of Current Literature
</note>
<bodyText confidence="0.679465">
gramming methods for coping with the semantics of locomotion verbs.
The process of generating an extended response is illustrated by an
extensively annotated trace.
</bodyText>
<reference confidence="0.981116222222222">
Natural Language Information Re-
trieval System Dialog
L. Bolc, K. Kochut, A. Lesniewski,
T. Strzalkowski
Warsaw University
Institute of Informatics
PKin, pok.850
00-901 Warszawa, Poland
Proc. EACL 1983, pp. 196-203
</reference>
<bodyText confidence="0.998490833333333">
The presented paper contains a description of an experimental version
of the natural language information retrieval system DIALOG. The
system is destined for use in the field of medicine. Its main purpose is
to ensure access to information to physicians in a conversational
manner. The use of the system does not require programming ability
from its user.
</bodyText>
<page confidence="0.282052">
Computational Linguistics, Volume 10, Number 1 January-March 1984 57
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9337205">The FINITE STRING Abstracts of Current Literature Abstracts of Current Literature A Fuzzy-Set-Theoretic Approach to the of Meaning: Propositions, Dispositions and Canonical Forms</title>
<author confidence="0.999854">Lotfi A Zadeh</author>
<affiliation confidence="0.999441">Division of Computer Science ERL, College of Engineering University of California</affiliation>
<address confidence="0.7308015">Berkeley, CA 94720 Memorandum No. UCBIERL M83124</address>
<abstract confidence="0.999835903846154">is the manual for the Gram development system (written in Prolog) intended for use by linguists and computational linguists developing grammars for significant fragments of natural languages. The system incorporates all aspects of the Generalized Phrase Structure Grammar framework, including features, metarules, ID/LP rule format, Kleene star rule feature instantiation principles, schemata, and so on. Among other things, the user can &amp;quot;direct&amp;quot; parsing interactively in order to explore particular analyses. natural language (NL) querying of data bases been an active research area for many years, and at least one commercial system is available that supports natural language database query, little effort has been expended in support of natural language database end-users of data bases must alternate between easy-touse natural language query systems and harder-to-use format database update systems. Salveter and Maier have shown that, because NL DB update is a fundamentally different problem than query, it is not possible to naturally extend natural language query systems to also support update. A data base is an attempt to abstract information about the real world. A state of the data base is meant to represent a state of a portion of the real world. To interpret values of the data objects in the data base as statements about the real world, we must be able to connect the values in the data base with various entities and relationships in the data base. A semantic data description indicates a set of world states database definition gives a set of allowable database states (DBS). The correspondence between the semantic description and the database definition induces connections between database states and real world states. In its traditional interpretation, Frege&apos;s principle of compositionality is not sufficiently flexible to have a wide applicability to natural languages. In a fuzzy-set-theoretic setting which is outlined in this paper, Frege&apos;s principle is modified and broadened by allowing the meaning a proposition, be composed not from the meaning of the of more generally, from the meaning of a collection fuzzy relations which form a so-called data base is with specficially, through the application of testsemantics, the meaning of represented as a procedure which tests, scores and aggregates the elastic constraints which are implicit employment of fuzzy sets in this semantics allows confuzzy predicates such as kind, much richer, fuzzy quansuch as several, few, usually, and other types of semantic entities which cannot be dealt with within the framework of classical logic. The approach described in the paper suggests a way of representing meaning of dispositions, e.g., causes obesity, Icy roads slippery, Young men like young women, Specifically, by viewa disposition, a proposition with implicit fuzzy quantifiers, problem of representing the meaning of be decomposed into (a) restoring the suppressed fuzzy quantifiers and/or fuzzifying the quantifiers in the body of (b) representing the meaning of the resulting dispositional proposition through the use of testscore semantics.</abstract>
<title confidence="0.956065">The ProGram Manual</title>
<author confidence="0.975056">Roger Evans</author>
<author confidence="0.975056">Gerald Gazdar</author>
<affiliation confidence="0.770881">Cognitive Studies Programme Arts E, University of Sussex</affiliation>
<address confidence="0.836778">Brighton, BN1 9QN, U.K.</address>
<note confidence="0.929066666666667">Cognitive Science Research Paper CSRP 035, April 1984, 106 pages (Address requests to Judith Dennison.)</note>
<title confidence="0.919195">Natural Language Database Update</title>
<author confidence="0.997346">Sharon Salveter</author>
<affiliation confidence="0.999603666666667">Computer Science Department College of Liberal Arts Boston University</affiliation>
<address confidence="0.999872">Boston, MA 02215</address>
<pubnum confidence="0.985121">Technical Report No. 841001</pubnum>
<date confidence="0.42139">Linguistics, Volume 10, Number 1 January-March 1984</date>
<title confidence="0.770773">The FINITE STRING Abstracts of Current Literature</title>
<abstract confidence="0.990842">in evidence the logical structure of at the same time a high-level description o the composition process, be in the canonical form is F&amp;quot;, = ..., an n-ary variable which is constrained by a fuzzy relation which may be interpreted as an elastic constraint on This canonical form and the meaning-composition process for proposisitions and dispositions are Illustrated by several examples among is the proposition = Over the past few years Naomi earned far more than most of her close friends.</abstract>
<title confidence="0.919282">Test-Score Semantics for Natural Languages and Meaning Representation</title>
<author confidence="0.993533">Lotfi A Zadeh</author>
<note confidence="0.759032333333333">see page 43 Rieger, B., Ed., Semantics I. Brockmeyer, Bochum, 1981.</note>
<title confidence="0.9848575">A Computational Approach to Fuzzy Quantifiers in Natural Languages</title>
<author confidence="0.988529">Lotfi A Zadeh</author>
<abstract confidence="0.990525910714286">see page 43 with App/s. 9(1): 149-184 (1983). In a sharp departure from the conventional approaches to the problem of meaning representation in natural languages, test-score semantics is based on the premise that almost everything that relates to natural languages is a matter of degree. Thus, in test-score semantics, predicates, propositions and other types of linguistic entities are treated as collections of elastic constraints on a set of objects or relations in a universe of discourse. Viewed in this perspective, the meaning of a linguistic entity may be defined by (a) identifying the constraints which are implicit or explicit in the entity in question; (b) describing the tests that must be performed to ascertain the degree to which each constraint is satisfied; and (c) specifying the manner in which the degrees in question or, equivalently, the partial test scores are to be aggregated to yield an overall test score. In general, the overall test score is a vector whose components are numbers in the unit interval or possibility/probability distributions over this interval. The first step in the representation of the meaning of a given proposition involves the construction of a relational data base in which the meaning of constituent relations and their attributes is assumed to be known. The choice of the data base affects the explanatory effectiveness of the translation process and is governed by the knowledge profile of the intended user of the translation. The test procedure — which is regarded as the representation of the meaning of the proposition — acts on the data base and returns an overall test score which is interpreted as the compatibility of p with the data base. Test-score semantics is sufficiently general to allow the translation of almost any proposition in a natural language. However, the price of generality is the difficulty of writing a program which could represent the meaning of a given proposition without recourse to human assistance. generic term quantifier employed in this paper to denote the collection of quantifiers in natural languages whose representative are: most, much, not many, very many, not very many, few, quite a few, large number, small number, close to five, approximateten, frequently, In our approach, such quantifiers are treated as fuzzy numbers which may be manipulated through the use of fuzzy arithmetic and, more generally, fuzzy logic. A concept which plays an essential role in the treatment of fuzzy is that of the cardinality of a fuzzy set. use of this concept, the meaning of a proposition containing one or more fuzzy quantifiers may be represented as a system of elastic constraints whose domain is a collection of fuzzy relations in a relational data base. This representation, then, provides a basis for inference from premises which contain fuzzy quantifiers. For example, from the propositions &amp;quot;Most U&apos;s are A&apos;s&amp;quot; and &amp;quot;Most A&apos;s are B&apos;s&amp;quot;, it follows U&apos;s are B&apos;s&amp;quot;, where is the fuzzy product of the proportion itself. Linguistics, Volume 10, Number 1 January-March 1984 The FINITE STRING Abstracts of Current Literature The computational approach to fuzzy quantifiers which is described in this paper may be viewed as a derivative of fuzzy logic and testscore semantics. In this semantics, the meaning of a semantic entity is represented as a procedure which tests, scores, and aggregates the elastic constraints which are induced by the entity in question.</abstract>
<title confidence="0.857305333333333">The Role of Fuzzy Logic in the Management of Uncertainty in Expert Systems</title>
<author confidence="0.989007">Lotti A Zadeh</author>
<abstract confidence="0.971986461538462">see page 43 Sets and Systems 199-227. Management of uncertainty is an intrinsically important issue in the design of expert systems because much of the information in the knowledge base of a typical expert system is imprecise, incomplete or not totally reliable. In the existing expert systems, uncertainty is dealt with through a combination of predicate logic and probability-based methods. A serious shortcoming of these methods is that they are not capable of coming to grips with the pervasive fuzziness of information in the knowledge base, and, as a result, are mostly ad hoc in nature. An alternative approach to the management of uncertainty which is suggested in this paper is based on the use of fuzzy logic, which is the logic underlying approximate or, equivalently, fuzzy reasoning. A feature of fuzzy logic which is of particular importance to the management of uncertainty in expert systems is that it provides a systematic for dealing with fuzzy quantifiers, e.g., many, few, not many, almost all, infrequently, about 0.8, In this way, fuzzy logic subsumes both predicate logic and probability theory, and makes it possible to deal with different types of uncertainty within a single conceptual framework. In fuzzy logic, the deduction of a conclusion from a set of premises is reduced, in general, to the solution of a nonlinear program through the application of projection and extension principles. This approach to deduction leads to various basic syllogisms which may be used as rules of combination of evidence in expert systems. Among syllogisms of this type which are discussed in this paper are the intersection/project syllogism, the generalized modus ponens, the consequent conjunction syllogism, and the major-premise reversibility rule. It is suggested that communication between humans — as well as between humans and machines — may be made more precise by the of a meaning representation language is based on the concept of a possibility distribution. A brief exposition of PRUF is presented, and its application to precisiation of meaning is illustrated by a number of examples. The theory outlined in this paper is based on the idea that what is called knowledge be viewed as a collecof is, propositions with implied fuzzy quantifiers. examples of dispositions are: roads are slippery, Tall men are not very agile, Overeating causes obesity, Bob loves women, What is is expensive, It is understood that, upon restoration of fuzzy quantifiers, a disposition is converted into a proposition with explicit quantifiers, e.g., men are not very agile -4. Most tall men are not very agile. Since traditional logical systems provide no methods for representing the meaning of propositions containing fuzzy quantifiers, such systems are unsuitable for dealing with commonsense knowledge. It is suggested in this paper that an appropriate computational framework for with commonsense knowledge is provided by logic, as its name implies, is the logic underlying fuzzy (or approxi- Precisiation of Meaning via Transla-</abstract>
<email confidence="0.315464">into</email>
<author confidence="0.743136">Lofti A Zadeh</author>
<note confidence="0.59412225">see page 43 In Vaina, L. and Hintikka, J., Eds., Cognitive Constraints on Communication 1984: 373-401.</note>
<title confidence="0.8397705">A Theory of Commonsense Knowledge</title>
<author confidence="0.953137">Lotfi A Zadeh</author>
<note confidence="0.5933514">see page 43 In Skala, H.J.; Termini, S.; and Trillas, Eds., of Vagueness. 1984: 257-296. Linguistics, Volume 10, Number 1 January-March 45</note>
<title confidence="0.741286">The FINITE STRING Abstracts of Current Literature</title>
<abstract confidence="0.887280333333333">mate) reasoning. Such a framework, with an emphasis on the representation of dispositions, is outlined and illustrated with examples. The following reports are available from</abstract>
<affiliation confidence="0.840641333333333">Computer Laboratory University of Cambridge Corn Exchange Street</affiliation>
<address confidence="0.993948">Cambridge CB2 3QG, England</address>
<note confidence="0.922151">Prices are as indicated; add postage: surface — theses £0.65, others £0.40; air — theses £5.00, others £1.50.</note>
<title confidence="0.9919855">Compound Noun Interpretation Problems</title>
<author confidence="0.930045">K Sparck Jones</author>
<pubnum confidence="0.666757">Technical Report No. 45, July 1983,</pubnum>
<title confidence="0.989149">Automatic Summarising of English Texts</title>
<author confidence="0.998969">J I Tait</author>
<pubnum confidence="0.563357">Technical Report No. 47, December 1982,</pubnum>
<address confidence="0.582401">137pp., £2.50.</address>
<title confidence="0.997719333333333">A Mechanism for the Accumulation and Application of Context in Text Processing</title>
<author confidence="0.955108">H Alshawi</author>
<note confidence="0.807273666666667">Report No. 48, 17pp. This paper was prepared for the SERC/CREST Course on Computer Speech Processing, Cambridge, England, July 1983. It discusses the</note>
<abstract confidence="0.998546461538462">problems of compound noun interpretation in the context of automatic language processing. Given that compound processing implies identifying the senses of the words involved, determining their bracketing, and establishing their underlying semantic relations, the paper illustrates the need, even in comparatively favourable cases, for inference using pragmatic information. This has consequences for language processor architectures and, even more, for speech processors. The thesis describes a computer program called Scrabble which can summarise short English texts. It uses large bodies of predictions about the likely contents of texts about particular topics to identify the commonplace material in an input text. Pre-specified summary templates, each associated with a different topic, are used to condense the commonplace material in the input. Filled-in summary templates are then used to form a framework into which unexpected material in the input may be fitted, allowing unexpected material to appear in output summary texts in an essentially unreduced form. The system&apos;s summaries are in English. The program is based on technology not dissimilar to a script applier. However, Scrabble represents a significant advance over previous script-based summarising systems. It is much less likely to produce misleading summaries of an input text than some previous systems, and can operate with less information about the subject domain of the input than others. These improvements are achieved by the use of three main novel ideas. First, the system incorporates a new method for identifying the topic or topics of an input text. Second, it allows a section of text to have more than one topic at a time, or at least a composite topic which may best be dealt with by the computer program simultaneously applying to the text predictions associated with more than one simple topic. Third, Scrabble incorporates new mechanisms for the incorporation of unexpected material in the input into its output summary texts. The incorporation of such material in the output summary is motivated by the view that it is precisely unexpected material which is likely to form the most salient matter in the input text. The performance of the system is illustrated by means of a number of example input texts and their corresponding Scrabble summaries. The paper describes a mechanism for the representation and application of context information for automatic natural language processing systems. Context information is gathered gradually during the reading of the text, and the mechanism gives a way of combining the effect of several different types of context factors. Context factors can be Linguistics, Volume 10, Number 1 January-March 1984 The FINITE STRING Abstracts of Current Literature managed independently, while still allowing efficient access to entities in focus. The mechanism is claimed to be more general than the global focus mechanism used by Grosz for discourse understanding. Context affects the interpretation process by choosing the results, and restricting the processing, of a number of important language interpretation operations, including lexical disambiguation and reference resolution. The types of context factors that have been implemented in an experimental system are described, and examples of the application of context are given.</abstract>
<title confidence="0.772584333333333">Following are the titles and abstracts of reports and memos recently published by the Research Unit for Information Science and Artificial Intelligence at the University of Hamburg. Single copies of papers still in print are available, free of charge. Please write</title>
<author confidence="0.997857">Angela Carstensen</author>
<affiliation confidence="0.983006">Reseach Unit for Information Science and Artificial Intelligence University of Hamburg</affiliation>
<address confidence="0.9945725">Mittelweg 179 D-2000 Hamburg 13, WEST GERMANY</address>
<title confidence="0.925157666666667">Surface Transformation during the Generation of Written German Sentences</title>
<author confidence="0.997719">Stephan Busemann</author>
<note confidence="0.9250665">ANS-23. Neumann, B., Ed., GWAI-83. 7th German Workshop in Artificial Intelligence. Dassel, September 1983: 90-99.</note>
<title confidence="0.917482">The Real Estate Agent — Modeling Users by Uncertain Reasoning</title>
<author confidence="0.487396">ANS- Neuman</author>
<author confidence="0.487396">B Ed</author>
<affiliation confidence="0.282097">User Modelling and Profiles of Inter-</affiliation>
<title confidence="0.987834">Intelligence Dialog Systems</title>
<author confidence="0.998077">Katharina Monk</author>
<abstract confidence="0.9851405">No. ANS-25. appear in This paper gives an overview of the modular and adaptable system SUTRA for surface transformations. The system generates written German sentences from an intermediate structure consisting solely of data based on knowledge which was already required for an earlier of the generation process. thus be employed in any generation system for the German language which produces such intermediate structures. SUTRA works in two steps. During the syntactical stage, several processes transform the intermediate structure into a linear string, thereby generating discontinuous verb constituents, arranging sentence components using separate ordering rules, mapping deep cases onto surface cases, and extracting further morphosyntactical properties from the intermediate structure (e.g., number) and the word lexicon of the generation system (e.g., gender). During the morphological stage, the terminal word forms are generated from the linear string using classification schemas for the different inflectional paradigms of German word stems. SUTRA is currently employed in the generation component of the natural language dialogue system HAM-ANS. topics treated in this article. Firstly, a user model patterned after the stereotype approach is presented. This model surpasses Rich&apos;s model with respect to its greater flexibility in the construction of user profiles and its treatment of positive and negative arguments. Secondly, an inference machine is presented. This machine treats uncertain knowledge in the form of evidence for and against the accuracy of a proposition. Truth values are replaced by the concept of a two-dimensional evidence space. The consequences of the concept, particularly with regard to verification, are discussed. The connection between these two topics is established by implementation of the user model on the inference machine. In this paper the necessity for user modeling is demonstrated for three types of systems: information retrieval systems, tutor systems, and natural language systems. Three facets of user modeling — familiarity with system use, expertise in a domain, and profile of interests — are distinguished. Techniques for building up user profiles and utilizing Computational Linguistics, Volume 10, Number 1 January-March 1984 47</abstract>
<title confidence="0.9860045">The FINITE STRING Abstracts of Current Literature Report on a Lecture and Fact-Finding</title>
<author confidence="0.802815">Tour in the USA in Late Summer Thomas Christaller</author>
<author confidence="0.802815">Wolfgang Hoeppner</author>
<abstract confidence="0.986951">Memo No. ANS-19, October 1983. them to govern system behavior are described. With regard to natural language systems, our work on user modeling for HAM-ANS is presented in some detail. The first part of this study presents the manual transporting of the Al language FUZZY from UCI-LISP to Franz Lisp. The problems encountered in this process and their solution are taken up in the second part, dealing with the evaluation of different transporting procedures for LISP-programs. The best procedures are based on production rule systems. These must, however, offer the capability of interacting with the user in doubtful cases. This paper investigates the integration of an automatic spellingcorrection component in an AI-system. First the basic requirements for such a correction procedure are presented. The major part of the paper consists of a critical examination of different correction methods, which formed the basis for the automatic spelling-correction component integrated in HAM-ANS.</abstract>
<address confidence="0.398374">C.-R., Ed.,</address>
<date confidence="0.524111">Information). 1984</date>
<title confidence="0.938862">A Study of LISP-Program-Transportation</title>
<author confidence="0.921648">Thomas Christaller</author>
<note confidence="0.635551">Memo No. ANS-17, July 1983.</note>
<title confidence="0.9923585">Considerations for Automatic Spelling Correction in an Al System</title>
<author confidence="0.998405">Michael Fliegner</author>
<note confidence="0.529143">Memo No. GEN-18, September 1983.</note>
<title confidence="0.389680666666667">CCA BBN •</title>
<author confidence="0.311815">Boston</author>
<affiliation confidence="0.996585">University of</affiliation>
<address confidence="0.821381">Pennsylvania</address>
<email confidence="0.453154">Phi/ade/phi</email>
<address confidence="0.604009666666667">49 Washington AAAI-83</address>
<affiliation confidence="0.735447857142857">New Brunswick Rutgers University San Francisco Stanford University SRI Hewlett Packard Berkeley</affiliation>
<title confidence="0.978992">Dynamic Storage Allocation Strategy for UCI-LISP</title>
<author confidence="0.991389">Rolf Dannenberg</author>
<author confidence="0.991389">Bernhard Nebel</author>
<note confidence="0.386572625">Memo No. ANS-20, November 1983. Approaches to a Semantic Representation for Natural Language Access to a Relational Data Base. Henning Bergmann, Annedore Paeseler Memo No. ANS-21, December 1983. After criticizing the current strategy of memory reallocation in</note>
<abstract confidence="0.999115235294118">UCI-LISP, we discuss several alternative possibilities for realizing dynamic strategies under the TOPS10 operating system. The implementation of the chosen method, which is from the users&apos; point of almost as convenient as memory management in described and the user interface is documented. Natural language access systems to formatted mass data administered base management systems) have been available for a number of years. The inadequacy of these systems is, for the most part, a result of an insufficient representation of knowledge about the interfaced DBMS and the domain of discourse modeled by the stored data. Taking a specific relational data base as a point of departure, we first discuss preliminary considerations for the representation of this knowledge. Next we describe the design of such a representation and its implementation in the frame-oriented AI-langauge FRL. The characteristics of our approach are: organization of knowledge in a generalization hierarchy, the use of deep-case frames and the attachment of procedures for the generation of database queries.</abstract>
<note confidence="0.594667">Linguistics, Volume 10, Number 1 January-March 1984</note>
<title confidence="0.963606333333333">The FINITE STRING Abstracts of Current Literature following abstracts are from of the First Conference of the European Chapter of the Association for Linguistics, for $15 a copy from</title>
<author confidence="0.991272">Donald E Walker</author>
<author confidence="0.991272">ACL</author>
<affiliation confidence="0.999537">Bell Communications Research</affiliation>
<address confidence="0.9974685">445 South Street Morristown, NJ 07960 USA</address>
<title confidence="0.5963175">Abstract Control Structures and the Semantics of Quantifers</title>
<author confidence="0.992227">Steven Cushing</author>
<affiliation confidence="0.8479455">Computer Science Department St. Anselm College</affiliation>
<address confidence="0.998342">Manchester, NH 03102</address>
<abstract confidence="0.991021021739131">Proc. EACL 1983, pp. 1-8 a any word or phrase that expresses a meaning that answers one of the questions &amp;quot;How many?&amp;quot; or &amp;quot;How much?&amp;quot; English examples include no, many, few, some but not all but at most a very few, wherever, whoever, whoever there is, it can be argued, also, this paper we review an empirically motivated analysis of such meanings and draw out its computational significance. For purposes of illustration, we focus our on the meanings expressed by the English words represented, respectively, by the symbols most of what we say will generalize to the other meanings of this class. In Section 1, we review the notion of satisfaction in a model, through which logical formulas are customarily imbued implicitly with meaning. In Section 2, we discuss quantifier relativization, a notion that beimportant for meanings other than Section 3, we use these two notions to characterize quantifier meanings as structured functions of a certain sort. In Section 4, we discuss the computational significance of that analysis. In Section 5, we elaborate on this significance by outlining a notion of abstract control structure that the analysis instantiates. used grammars that describe natural languages (e.g., Metamorphonic Grammars) can hardly be applied in describing highly inflectional languages. So I propose a grammar called the grammar with natural context, which takes into consideration properties of highly inflectional languages (e.g., Polish) as well as structural languages (e.g., English). I introduce its normal form. We present in this article, as part of an aspectual operation system, a generation system of iterative expressions using a set of operators called iterative operators. In order to execute the iterative operations efficiently, we have classified previously propositions denoting a single occurrence of a single event into three groups. The definition of a single event is given recursively. The classification has been carried out especially in consideration of the durative/non-durative character of the denoted events and also in consideration of existence/nonexistence of a culmination point (or a boundary) in the events. The operations concerned with iteration have either the effect of giving a boundary to an event (in the case of a non-bounded event) or of extending an event through repetitions. The operators concerned are: N,F — direct iterative operators; I,G — boundary giving operators; I — extending operator. There are direct and indirect operations: the direct ones change a non-repetitious proposition into a repetitious one directly, whereas the indirect ones change it indirectly. The indirect iteration is indicated with E. The scope of each operator is not uniquely definable, though the mutual relation of the operators can be given more or less explicitly.</abstract>
<title confidence="0.734283">L&apos;idee de Grammaire avec le Contexte Nature!</title>
<author confidence="0.807499">Leszek Haduch</author>
<affiliation confidence="0.99892">Institute of Informatics Technical University of Lodz</affiliation>
<address confidence="0.927818">Lodz, ul.Piotrkowska 220, Poland</address>
<note confidence="0.884582">Proc. EACL 1983, pp. 9-13</note>
<title confidence="0.988555">Iterative Operations</title>
<author confidence="0.986983">Sae Yamada</author>
<affiliation confidence="0.99967">Notre Dame Seishin University</affiliation>
<address confidence="0.9869065">Ifuku-Cho 2-16-9 700 Okayama, Japan</address>
<note confidence="0.942656">Proc. EACL 1983, pp. 14-20 Linguistics, Volume 10, Number 1 January-March 1984</note>
<title confidence="0.996893666666667">The FINITE STRING Abstracts of Current Literature Structure of Sentence and Inferencing in Question Answering</title>
<author confidence="0.999205">Eva Hajieovd</author>
<author confidence="0.999205">Petr Sgall</author>
<affiliation confidence="0.996123">Faculty of Mathematics and Physics Charles University</affiliation>
<address confidence="0.850572">Malostransk6 n. 25 118 00 Praha 1 Czechoslovakia</address>
<note confidence="0.804118">Proc. EACL 1983, pp. 21-25</note>
<title confidence="0.997961">A Phonological Processor for Italian</title>
<author confidence="0.9997">Rodolfo Delmonte</author>
<affiliation confidence="0.872372">Centro Linguistico Interfacolta degli Studi di Venezia</affiliation>
<address confidence="0.834309">Ca&apos; Garzoni-Moro - S. Marco 3417</address>
<note confidence="0.845022">Proc. EACL 1983, pp. 26-34</note>
<title confidence="0.989571">An Expert System for the Production of Phoneme Strings from Unmarked English Text using Machine-Induced Rules</title>
<author confidence="0.999849">Alberto Maria Segre</author>
<affiliation confidence="0.999335">Coordinated Science Laboratory</affiliation>
<author confidence="0.772705">Bruce Arne Sherwood</author>
<affiliation confidence="0.990596">Computer-Based Education Research Laboratory</affiliation>
<author confidence="0.581141">Wayne B Dickerson</author>
<affiliation confidence="0.922316">English as a Second Language University of Illinois at Urbana-Champaign</affiliation>
<address confidence="0.839626">Urbana, IL 61801</address>
<note confidence="0.746495">Proc. EACL 1983, pp. 35-42</note>
<title confidence="0.958808">Vocal Interface for a Man-Machine Dialog</title>
<author confidence="0.996417">Dominique Beroule</author>
<affiliation confidence="0.868413">LIMSI (CNRS)</affiliation>
<address confidence="0.9816765">B.P. 30 91406 Orsay CEDEX France</address>
<abstract confidence="0.977819566037736">Proc. EACL 1983, pp. 43-48 In the present paper we characterize in more detail some of the aspects of a question answering system using as its starting point the underlying structure of sentences (which with some approaches can be identified with the level of meaning or of logical form). First of all, the criteria are described that are used to identify the elementary units of underlying structure and the operations conjoining them into complex units (Section 1), then the main types of units and operations resulting from an empirical investigation on the basis of the criteria are registered (Section 2), and finally the rules of inference, accounting for the relevant aspects of the relationship between linguistic and cognitive structures are illustrated (Section 3). computer for the automatic translation of any text of Italian into naturally fluent synthetic speech is presented. The proor Phonological Processor (hence into prosodic structures the phonological rules of Italian. Structural information is provided by such hierarchical prosodic constituents as Syllable (S), Metri- Foot Word Intonational Group (IG). Onto these structures, phonological rules are applied such as the rules, word stress rules, internal stress hierarchy rules indicating secondary stress, external sandhi rules, phonological focus assignment rules, logical focus assignment rules. The FP constitutes also a model to simulate the reading process aloud, and the psycholinguistics and cognitive aspects related will be disin the computational model of the At present, Logical assignment and the computational model are work in still to be implemented in the samples of automatically produced synthetic speech will be presented at the conference to illustrate the functioning of the rules. The speech synthesis group at the Computer-Based Education Re- Laboratory of the University of Illinois at Urbana- Champaign is developing a diphone speech synthesis system based on pitch-adaptive short-time Fourier transforms. This system accepts the phonemic specification of an utterance along with pitch, time and amplitude warping functions in order to produce high quality speech output from stored diphone templates. This paper describes the operation of a program which operates as a end for the diphone speech synthesis system. The &amp;quot;Unmarked Text Transcription by Expert Rule&amp;quot;) system maps English text onto a phoneme string, which is then used as an input to the diphone speech synthesis system. The program is a two-tiered Expert System which operates first on the word level and then on the (vowel or consonant) cluster level. The system&apos;s knowledge about pronunciation is organized in two decision trees automatically generated by an induction algorithm on a dynamically specified &amp;quot;training set&amp;quot; of exam-. ples. We describe a dialog-handling module used as an interface between a vocal terminal and a task-oriented device (for instance, a robot manipulating blocks). This module has been specially designed to be implanted on a single board using a microprocessor, and inserted into the vocal terminal which already comprises a speech recognition board and a synthesis board. The entire vocal system is at present capable of conducting a real time spoken dialog with its user.</abstract>
<note confidence="0.547095">Linguistics, Volume 10, Number 1 January-March 1984</note>
<title confidence="0.995349333333333">The FINITE STRING Abstracts of Current Literature Knowledge Engineering Approach to Morphological Analysis</title>
<author confidence="0.762168">Harri Jappinen</author>
<author confidence="0.762168">Aarno Lehtola</author>
<author confidence="0.762168">Esa Nelimarkka</author>
<author confidence="0.762168">Matti Ylilammi</author>
<affiliation confidence="0.999975">Helsinki University of Technology</affiliation>
<address confidence="0.997571">Helsinki, Finland</address>
<note confidence="0.714527">Proc. EACL 1983, pp. 49-51</note>
<title confidence="0.959691">A PROLOG Implementation of Lexical Functional Grammar as a Base for a Natural Language Processing System</title>
<author confidence="0.999313">Werner Frey</author>
<author confidence="0.999313">Uwe Reyle</author>
<affiliation confidence="0.999634">Department of Linguistics University of Stuttgart</affiliation>
<address confidence="0.848962">West Germany</address>
<note confidence="0.882374">Proc. EACL 1983, pp. 52-57 Extended Access to the Left Context</note>
<title confidence="0.64633">in an ATN Parser</title>
<author confidence="0.970443">Irina Prodanof</author>
<author confidence="0.970443">Giacomo Ferrari</author>
<affiliation confidence="0.965526">Istituto di Linguistica Computazionale</affiliation>
<address confidence="0.9168945">Via della Faggiola 32 1-56100 Pisa, Italy</address>
<note confidence="0.63596">Proc. EACL 1983, pp. 58-65</note>
<title confidence="0.9955045">An Experiment with Heuristic Parsing of Swedish</title>
<author confidence="0.99987">Benny Brodda</author>
<affiliation confidence="0.9998135">Institute of Linguistics University of Stockholm</affiliation>
<address confidence="0.946609">S-106 91 Stockholm SWEDEN</address>
<note confidence="0.785936">Proc. EACL 1983, pp. 66-73</note>
<title confidence="0.867233">Towards the Semantics of Sentence Adverbials</title>
<author confidence="0.991894">Eva Koktova</author>
<abstract confidence="0.991673796296296">9. kv6tna 1576 Finnish is a highly inflectional language. A verb can have over ten thousand different surface forms — nominals slightly fewer. Consequently, a morphological analyzer is an important component of a system aiming at &amp;quot;understanding&amp;quot; Finnish. This paper briefly describes our rule-based heuristic analyzer for Finnish nominal and verb forms. Our tests have shown it to be quite efficient: the analysis of a word in a running text takes an average of 15 ms of DEC CPU time. The aim of this paper is to present parts of our system, which is to construct a data base out of a narrative natural language text. We think the parts are of interest on their own. The paper consists of sections: (I) We give a detailed description of the implementation of the parser, which is based on the theory of lexical functional grammar. (II) For the semantic representation of texts we use the Discourse Representation Theory developed by Hans Kamp. (III) Finally we sketch how the parser formalism can be augmented to yield as output discourse representation structures. Some Italian sentences related to linguistic phenomena largely known and recently discussed by many computational linguists are discussed in the framework of ATN. They offer certain difficulties which seem to suggest a substantial revision of the ATN formalism. The theoretical assumptions and an experimental implementation of such a revision are presented together with examples. Many related theoretical points, such as some psycholinguistic implications and the relationship between deterministic and non-deterministic hypothesis are also briefly discussed. Heuristic parsing is the art of doing parsing in a haphazard and seemingly careless manner but in such a way that the outcome is still &amp;quot;good&amp;quot;, at least from a statistical point of view, or, hopefully, even from a more absolute point of view. The idea is to find strategic shortcuts derived from guesses about the structure of a sentence based on scanty observations of linguistic units in the sentence. If the guess comes out right, much parsing time can be saved; and if it does not, many subobservations may still be valid for revised guesses. In the (very preliminary) experiment reported here, the main idea is to make use of (combinations of) surface phenomena as much as possible as the base for the prediction of the structure as a whole. In the parser to be developed along the lines sketched in this report, the main stress is put on arriving at independently working, parallel recognition procedures. The work reported here is aimed both at simulating certain aspects of human language perception and at arriving at effective algorithms for actual parsing of running text. There is, indeed, a great need for fast such algorithms, e.g. for the analysis of the literally millions of words of running text that already today comprise the data bases in various large information retrieval systems, and which can be expected to expand several orders of magnitude both in importance and in size in the foreseeable future. In the present paper we argue that the so-called sentence adverbials adverbs like admittedly, ...) be generated, in the framework of Functional Generative Description, by means of a deep case — Complementation of Attitude grounds of Linguistics, Volume 10, Number 1 January-March 51</abstract>
<affiliation confidence="0.377755">The FINITE STRING Abstracts of Current Literature</affiliation>
<address confidence="0.839261">39001 Tabor, Czechoslovakia</address>
<note confidence="0.806521">Proc. EACL 1983, pp. 74-80 Dealing with Conjunctions in a Ma-</note>
<title confidence="0.94237">chine Translation Environment</title>
<author confidence="0.973726">Xiuming Huang</author>
<affiliation confidence="0.9864875">Institute of Linguistics Chinese Academy of Social Sciences</affiliation>
<address confidence="0.981627">Beijing, China</address>
<note confidence="0.885376">Proc. EACL 1983, pp. 81-85</note>
<title confidence="0.9978585">Fallible Rationalism and Machine Translation</title>
<author confidence="0.999488">Geoffrey Sampson</author>
<affiliation confidence="0.928792">Linguistics &amp; Modern English Language University of Lancaster</affiliation>
<address confidence="0.785022">Lancaster LA1-4YT, G.B.</address>
<note confidence="0.924363">Proc. EACL 1983, pp. 86-89</note>
<title confidence="0.981120333333333">The Generation of Term Definitions from an Online Terminological Thesaurus</title>
<author confidence="0.999526">John McNaught</author>
<affiliation confidence="0.8573595">Centre for Computational Lingustics UMIST</affiliation>
<address confidence="0.9797905">P.O. Box 88 Manchester, UK</address>
<note confidence="0.913286">Proc. EACL 1983, pp. 90-95</note>
<title confidence="0.986963666666667">Relating Syntax and Semantics: The Syntactico-semantic Lexicon of the System VIE-LANG</title>
<author confidence="0.977899">Ingeborg Steinacker</author>
<author confidence="0.977899">Ernst Buchberger</author>
<affiliation confidence="0.952868">Medical Cybernetics University of Vienna, Austria</affiliation>
<abstract confidence="0.991839704918033">Proc. EACL 1983, pp. 96-100 their special behaviour in the topic-focus articulation (TFA) of a sentence. From the viewpoint of the translation of CA expressions (and also of the multiple occurrence thereof inside a sentence) into a calculus of intensional logic, it should be noted that the TFA properties of CA expressions are directly correlated to the scope properties thereof. Our approach, which is stated in terms of a linguistic theory, serves as a basis for an algorithm of analysis of CA for purposes of a system of man-machine communication without a pre-arranged data base. A set of rules, named CSDC (Conjunction Scope Determination Constraints), is suggested for attacking the conjunct scope problem, the major issue in the automatic processing of conjunctions which has been raising great difficulty for natural language processing systems. Grammars embodying the CSDC are incorporated into an existing ATN parser, and are tested successfully against a wide group of &amp;quot;and&amp;quot; conjunctive sentences, which are of three types: clausal coordination, phrasal coordination, and gapping. With phrasal coordination, the structure with two NPs coordinated by &amp;quot;and&amp;quot; has been given the most attention. It is hoped that an ATN parser capable of dealing with a large variety of conjunctions in an efficient way will finally emerge from the presented work. Approaches to MT have been heavily influenced by changing trends in the philosophy of language and mind Because of the artificial hiatus which followed the publication of the ALPAC Report, MT research in the 1970s and early 1980s has had to catch up with major developments that have occurred in linguistic and philosophical thinking; currently, MT seems.to be uncritically loyal to a paradigm of thought about language which is rapidly losing most of its adherents in departments of linguistics and philosophy. I argue, both in theoretical terms and by reference to empirical research on a particular translation problem, that the Popperian &amp;quot;falliable rationalist&amp;quot; view of mental processes which is winning acceptance as a more sophisticated alternative to Chomskyan &amp;quot;deterministic rationalism&amp;quot; should lead MT researchers to redefine their goals and to adopt certain currentlyneglected techniques in trying to achieve those goals. A new type of machine dictionary is described, which uses terminological relations to build up a semantic network representing the terms of a particular subject field, through interaction with the user. These relations are then used to dynamically generate outline definitions of terms in online query mode. The definitions produced are precise, consistent and informative, and allow the user to situate a query term in the local conceptual environment. The simple definitions based on terminological relations are supplemented by information contained in facets and modifiers, which allow the user to capture different views of the data. This paper describes the structure and evaluation of the syntacticosemantic lexicon (SSL) of the German Natural Language Understanding System VIE-LANG. VIE-LANG uses an SI-Net as internal representation. The SSL contains the rules according to which the mapping between net-structures and surface structures of a sentence is carried out. This information is structured in such a way that it can be evaluated from two sides. The parser interprets it as production-rules that control the analysis. Syntactic and semantic features of the input Linguistics, Volume 10, Number 1 January-March 1984 The FINITE STRING Abstracts of Current Literature sentence are evaluated and individuals are created in the semantic net. The generator uses the same rules to express selected net-structures in adequate natural language expressions. It is shown how both processes can make effective use of SSL. The different possibilities for evaluating the SSL are explained and illustrated by examples.</abstract>
<title confidence="0.958691666666667">An Island Parsing Interpreter for the Full Augmented Transition Network Formalism</title>
<author confidence="0.999309">John A Carroll</author>
<affiliation confidence="0.903995666666667">University of Cambridge Computer Laboratory Corn Exchange Street</affiliation>
<address confidence="0.995061">Cambridge CB2 30G England</address>
<note confidence="0.74214">Proc. EACL 1983, pp. 101-105</note>
<title confidence="0.99491">WEDNESDAY: Parsing Flexible Word Order Languages</title>
<author confidence="0.7428545">Oliviero Stock</author>
<author confidence="0.7428545">Cristiano Castelfranchi</author>
<author confidence="0.7428545">Domenico Parisi Istituto di_Psicologia del Consiglio Nazionale delle Ricerche</author>
<note confidence="0.9074835">Via dei Monti Tiburtini 509, 00157 Roma Proc. EACL 1983, pp. 106-110</note>
<title confidence="0.8945215">How to Parse Gaps in Spoken Utterances</title>
<author confidence="0.863877">G Goerz</author>
<author confidence="0.863877">C Beckstein</author>
<affiliation confidence="0.611569">Univ. Erlangen-Nuernberg, RRZE</affiliation>
<address confidence="0.754807">Martensstr. 1 D-8520 Erlangen, W. Germany</address>
<phone confidence="0.333765">Proc. EACL 1983, pp. 111-113</phone>
<title confidence="0.901108666666667">A Flexible Natural Language Parser Based on a Two-Level Representation of Syntax</title>
<abstract confidence="0.97246075">Island parsing is a powerful technique for parsing with Augmented Transition Networks (ATNs) which was developed and successfully applied in the HWIM speech understanding project. The HWIM application grammar did not, however, exploit Woods&apos; original full ATN specification. This paper describes an island parsing interpreter based on HWIM but containing substantial and important extensions to enable it to interpret any grammar which conforms to that full specification of 1970. The most important contributions have been to eliminate the need for prior specification of scope clauses, to provide more power by implementing LIFTR and SENDR actions within the island parsing framework, and to improve the efficiency of the techniques used to merge together partially-built islands within the utterance. This paper also presents some observations about island parsing, based on the use of the parser described, and some suggestions for future directions for island parsing research. A parser for &amp;quot;flexible&amp;quot; word order languages must be substantially data driven. In our view syntax has two distinct roles in this connection: (i) to give impulses for assembling cognitive representations, (ii) to structure the space of search for fillers. WEDNESDAY is an interpreter for a language describing the lexicon and operating on natural language sentences. The system operates from left to right, interpreting the various words comprising the sentence one at a time. The basic ideas of the approach are the following: a) To introduce into the lexicon linguistic knowledge that in other systems is in a centralized module. The lexicon therefore carries not only morphological data and semantic descriptions. Syntactic knowledge, partly of a procedural kind, also is distributed throughout it. b) To build progressively a cognitive representation of the sentence in the form of a semantic network, in a global space, accessible from all levels of the analysis. c) To introduce procedures invoked by the words themselves for syntactic memory management. Simply stated, these procedures decide on the opening, closing, and maintaining of search spaces; they use detailed constraints and take into account the active expectations. WEDNESDAY is implemented in MAGMA-LISP, with a stress on the non-deterministic mechanism. We describe GLP, a chart parser that will be used as a SYNTAX module of the Erlangen Speech Understanding System. GLP realizes an agenda-based multiprocessing scheme, which allows us to apply easily various parsing strategies in a transparent way. We discuss which features have been incorporated into the parser in order to process speech data, in particular the ability to perform direction independent island parsing, to handle gaps in the utterance and its hypothesis scoring scheme. In this paper we present a parser which allows us to make explicit the interconnections between syntax and semantics, to analyze the sentences in a quasi-deterministic fashion and, in many cases, to identify Linguistics, Volume 10, Number 1 January-March 1984</abstract>
<title confidence="0.996335">The FINITE STRING Abstracts of Current Literature</title>
<author confidence="0.999638">Leonardo Lesmo</author>
<author confidence="0.999638">Pietro Torasso</author>
<affiliation confidence="0.9928815">Istituto di Scienze dell-Informazione Universa di Torino</affiliation>
<address confidence="0.991709">C.so Massimo D&apos;Azeglio 42 10125 TORINO - ITALY</address>
<note confidence="0.667301">Proc. EACL 1983, pp. 114-121</note>
<title confidence="0.8599945">An Approach to Natural Language in the SI-Nets Paradigm</title>
<author confidence="0.996117">Amedeo Cappelli</author>
<author confidence="0.996117">Lorenzo Moretti</author>
<affiliation confidence="0.9321035">Istituto di Linguistica Computazionale, CNR</affiliation>
<address confidence="0.991972">Via della Faggiola, 32 56100 Pisa - Italy</address>
<note confidence="0.635163">Proc. EACL 1983, pp. 122-128</note>
<title confidence="0.9886405">An Experiment on Synthesis of Russian Parametric Constructions</title>
<author confidence="0.993882">I S Kononenko</author>
<author confidence="0.993882">E L Pershina</author>
<affiliation confidence="0.97549">Al Laboratory, Computing Center</affiliation>
<note confidence="0.624266666666667">Siberian Branch of the USSSR Ac. Sci. Novosibirsk 630090, USSR Proc. EACL 1983, pp. 129-132</note>
<title confidence="0.997399">Learning Translation Skills with a Knowledge-Based Tutor: French- Italian Conjunctions in Context</title>
<author confidence="0.999936">Stefano A Cerni</author>
<affiliation confidence="0.9207332">Dipartimento di lnformatica Merger Dipartimento di Lingue e Letterature Romanze Universifa di Pisa</affiliation>
<address confidence="0.999873">56100 Pisa, Italy</address>
<abstract confidence="0.984791346153845">Proc. EACL 1983, pp. 133-138 the roles of the various constituents even if the sentence is ill-formed. The main feature of the approach on which the parser is based comprises a two-level representation of the syntactic knowledge: a first set of rules emits hypotheses about the constituents of the sentence and their functional role and another set of rules verifies whether a hypothesis satisfies the constraints about the well-formedness of sentences. However, the application of the second set of rules is delayed until the semantic knowledge confirms the acceptability of the hypothesis. If the semantics reject it, a new hypothesis is obtained by applying a simple and relatively inexpensive &amp;quot;natural&amp;quot; modification; a set of these modifications is predefined and only when none of them is applicable is a real backup performed: in most cases this situation corresponds to a case where people would normally garden path. This article deals with the interpretation of conceptual operations underlying the communicative use of natural language (NL) within the Structured Inheritance Network (SI-Nets) paradigm. The operations are reduced to functions of a formal language, thus changing the level of abstraction of the operations on SI-Nets In this sense, operations on SI-Nets are not merely isomorphic to single epistemological objects, but can be viewed as a simulation of processes on a different level, that pertaining to the conceptual system of NL. For this purpose, we have designed a version of KL-ONE which represents the epistemological level, while the new experimental language, KL-Conc, represents the conceptual level. KL-Conc would seem to be a more natural and intuitive way of interacting with SI-Nets. The paper describes an experimental model of syntactic structure generation starting from the limited fragment of semantics that deals with the quantitative values of object parameters. To present the input information the basic semantic units of four types are proposed: &amp;quot;object&amp;quot;, &amp;quot;parameter&amp;quot;, &amp;quot;function&amp;quot; and &amp;quot;constant&amp;quot;. For the syntactic structure representation, the system of syntactic components is used that combines the properties of the dependency and constituent systems: the syntactic components corresponding to word forms and exocentric constituents are introduced and two basic subordinate relations (&amp;quot;actant&amp;quot; and &amp;quot;attributive&amp;quot;) are claimed to be necessary. Special attention has been devoted to problems of complex correspondence between the semantic units and lexical-syntactic means. In the process of synthesis such sections of the model as the lexicon, the syntactic structure generation rules, the set of syntactic restrictions and morphological operators are utilized to generate the considerable enough subset of Russian parametric constructions. This paper describes an &amp;quot;intelligent&amp;quot; tutor of foreign language concepts and skills based upon state-of-the-art research in Intelligent Teaching Systems and Computational Linguistics. tutor is part of a large in which resulted in a system (called DART) for the design and development of intelligent teaching dialogues on PLATO and in a program (called ELISA) for teaching foreign language conjunctions in context. ELISA was able to teach a few conjunctions in English, Dutch and Italian. The research reported here extends ELISA to a complete set of conjunctions in Italian and French.</abstract>
<note confidence="0.484221">Linguistics, Volume 10, Number 1 January-March 1984</note>
<title confidence="0.983941">The FINITE STRING Abstracts of Current Literature Towards Better Understanding Of Anaphora</title>
<author confidence="0.998176">Barbara Dunin-Keplicz</author>
<affiliation confidence="0.999467">Institute of Informatics Warsaw University</affiliation>
<address confidence="0.9842635">P.O. Box 1210 00-901 Warszawa, Poland</address>
<note confidence="0.877414">Proc. EACL 1983, pp. 139-143</note>
<title confidence="0.998095">Rules for Pronominalization</title>
<author confidence="0.999949">Franz Guenthner</author>
<author confidence="0.999949">Hubert Lehmann</author>
<affiliation confidence="0.9914035">GmbH Heidelberg Science Center</affiliation>
<address confidence="0.9360505">Tiergartenstr. 15 D-6900 Heidelberg, FRG</address>
<note confidence="0.826273">Proc. EACL 1983, pp. 144-151</note>
<title confidence="0.988122">and Global Structures in Discourse Understanding</title>
<author confidence="0.994425">M Koit</author>
<author confidence="0.994425">S Litvak</author>
<author confidence="0.994425">H Oim</author>
<author confidence="0.994425">T Roosmaa</author>
<author confidence="0.994425">M Saluveer</author>
<affiliation confidence="0.999782">Artificial Intelligence Laboratory Tartu State University</affiliation>
<address confidence="0.998383">202400 Tartu, Estonian S.S.R, U.S.S.R.</address>
<note confidence="0.93318">Proc. EACL 1983, pp. 152-154</note>
<title confidence="0.807126">Systemic Grammar in Computation: The Nigel Case</title>
<author confidence="0.99985">Christian M I M Matthiessen</author>
<affiliation confidence="0.999849">USC/Information Sciences Institute</affiliation>
<address confidence="0.999016">4676 Admiralty Way Marina del Rey, CA 90292</address>
<note confidence="0.94344">Proc. EACL 1983, pp. 155-164</note>
<title confidence="0.71218">Inquiry Semantics: A Functional Semantics of Natural Language Grammar</title>
<author confidence="0.999255">William C Mann</author>
<affiliation confidence="0.999873">USC/Information Sciences Institute</affiliation>
<address confidence="0.995559">4676 Admiralty Way</address>
<abstract confidence="0.981283056603774">This paper represents a syntactical method of interpreting pronouns in Polish. Using the surface structure of the sentence as well as grammatical and inflexional information accessible during syntactic analysis, of reference marked out for each personal and possessive This area consists of a few areas the current and an area, the part of the text preceding it. In order to determine that area of reference, several syntactic sentencelevel restrictions on anaphora interpretation are formulated. Next, when looking at the area of the pronoun&apos;s reference, all NPs which number-gender agree with the pronoun can be selected, and this the set of referents each pronoun can be created. It can be used as data for further semantic analysis. Rigorous interpretation of pronouns is possible when syntax, semantics, and pragmatics of a discourse can be reasonably controlled. Interaction with a data base provides such an environment. In the framework of the User Specialty Languages system and Discourse Representation Theory, we formulate strict and preferential rules for pronominalization and outline a procedure to find proper assignments of referents to pronouns. We are interested in the nature of content structures in terms of which it would be possible to account for reasoning processes in understanding natural language texts. One of the most crucial problems here at the present time is: how and by which mechanisms these reasoning processes are controlled and directed. As the emphasis in the design of discourse understanding systems so far has been on the problems of knowledge organization and representation, we are only beginning to guess what the corresponding processing mechanisms are and how they function, although an increasing number of papers has been devoted to these problems as well. There are studies of the relation of understanding to such types of knowledge processing as problem solving and planning. Various types of content units and structures needed to account for knowledge processing have been proposed in the general context of modeling discourse understanding. We ourselves have discussed an approach to knowledge units and processing mechanisms in questions, as a part of a computer system which understands stories of a certain kind, as well as on a more theoretical level. Computational linguistics needs grammars for several different tasks such as comprehension of text, machine translation, and text generation. Clearly, any approach to grammar has potentially something to offer computational linguistics, say for parsing or text generation (and, by the same token, there is a potential benefit from an application within computational linguistics for each approach). However, it is equally clear that some approaches have much more to offer than others. Here I take a look at Systemic Linguistics in the service of computational linguistics tasks, concentrating on a large computational systemic grammar for text generation (Nigel) that is currently being developed. Programming a computer to operate to a significant degree as an author is a challenging research task. The creation of fluent multiparagraph text is a complex process because knowledge must be expressed in linguistic forms at several levels of organization, including paragraphs, sentences and words, each of which involves its own kinds of Linguistics, Volume 10, Number 1 January-March 1984</abstract>
<title confidence="0.748583">The FINITE STRING Abstracts of Current Literature</title>
<address confidence="0.973417">Marina del Rey, CA 90292</address>
<note confidence="0.558914">Proc. EACL 1983, pp. 165-174</note>
<abstract confidence="0.999345933333333">complexity. Accommodating this natural complexity is a difficult design problem. To solve it we must separate the various relevant kinds of knowledge into nearly independent collections, factoring the problem. Inquiry semantics is a new factoring of the text generation problems. It is novel in that it provides a distinct semantic for the grammar, independent of world knowledge, discourse knowledge, text plans and the lexicon, but appropriately linked to each. It has been implemented as part of the Nigel text generation grammar of English. This paper characterizes inquiry semantics, shows how it factors text generation, and describes its exemplification in Nigel. The resulting description of inquiries for English has three dimensions: the varieties of operations on information, the varieties of information operated upon, and the subject matter of the operations. The definition framework for inquiries involves both traditional and nontraditional linguistic abstractions, spanning the knowledge to be represented and the plans required for presenting it. In this paper a system which understands and conceptualizes scene descriptions in natural language is presented. Specifically, the following components of the system are described: the syntactic analyzer, based on a Procedural Systemic Grammar; the semantic analyzer relying on the Conceptual Dependency Theory; and the dictionary. In the project &amp;quot;Procedural Dialogue Models&amp;quot; being carried on at the University of Bielefeld, we have developed an incremental multi-level parsing formalism to reconstruct task-oriented dialogues. A major difficulty we have had to overcome is that the dialogues are real ones with numerous ungrammatical utterances. The approach we have devised to cope with this problem is reported here. This paper addresses the problem of generating communicatively adequate extended responses in the absence of specific knowledge concerning the intensions of the questioner. We formulate and justify a heuristic for the selection of optional deep case slots not contained in the question as candidates for the additional information contained in an extended response. It is shown that, in a visually present domain of discourse, case role filling for the construction of an extended response can be regarded as a side effect of the visual search necessary to answer a question containing a locomotion verb. This paper describes the various representation constructions used in the German language system dealing with the semantics of locomotion verbs and illustrates their use in generating extended responses. In particular, we outline the structure of the geometrical scene description, the representation of events in a logic-oriented semantic representation language, the case-frame lexicon and the representation of the referential semantics based on the Flavor system. The emphasis is a detailed presentation of the application of object-oriented pro-</abstract>
<title confidence="0.995969">Natural Language Input for Scene Generation</title>
<author confidence="0.99825">Giovanni Adorni</author>
<author confidence="0.99825">Mauro DiManzo</author>
<affiliation confidence="0.999085">Istituto di Elettrotechnica, U. of Genoa</affiliation>
<address confidence="0.955014">Viale F.Causa 13 16145 Genoa, Italy</address>
<author confidence="0.999948">Giacomo Ferrari</author>
<affiliation confidence="0.777622">Istituto di Linguistica Computazionale, CNR Via della Faggiola</affiliation>
<address confidence="0.993125">56100 Pisa, Italy</address>
<note confidence="0.658823">Proc. EACL 1983, pp. 175-182</note>
<title confidence="0.98733">Multilevel Approach to Handle Nonstandard Input</title>
<author confidence="0.999133">Manfred Gehrke</author>
<affiliation confidence="0.952648">Linguistics and Literature University of Bielefeld</affiliation>
<address confidence="0.998829">P.O. Box 8640</address>
<note confidence="0.678717">D-4800 Bielefeld 1 Proc. EACL 1983, pp. 183-187</note>
<title confidence="0.5299435">Case Role Filling as a Side Effect of Visual Search</title>
<author confidence="0.907891">Heinz Marbur ger</author>
<affiliation confidence="0.982257333333333">Research Unit for Information Science and Artificial Intelligence University of Hamburg</affiliation>
<address confidence="0.9910175">Mittelweg 179 D-2000 Hamburg 13, F.R. Germany</address>
<author confidence="0.5954">Wolfgang Wahlster</author>
<affiliation confidence="0.418209">Mathematik und</affiliation>
<email confidence="0.491522">lnformatik</email>
<affiliation confidence="0.742972">University of Saarbrucken Im Stadtwald</affiliation>
<address confidence="0.820731">D-6600 Saarbrucken 11, F.R. Germany</address>
<note confidence="0.7959485">Proc. EACL 1983, pp. 188-195 Linguistics, Volume 10, Number 1 January-March 1984</note>
<title confidence="0.649993">The FINITE STRING Abstracts of Current Literature</title>
<abstract confidence="0.956571333333333">gramming methods for coping with the semantics of locomotion verbs. The process of generating an extended response is illustrated by an extensively annotated trace.</abstract>
<title confidence="0.8113925">Natural Language Information Retrieval System Dialog</title>
<author confidence="0.995634">L Bolc</author>
<author confidence="0.995634">K Kochut</author>
<author confidence="0.995634">A Lesniewski</author>
<author confidence="0.995634">T Strzalkowski</author>
<affiliation confidence="0.9991865">Warsaw University Institute of Informatics</affiliation>
<address confidence="0.9665645">PKin, pok.850 00-901 Warszawa, Poland</address>
<note confidence="0.524824">Proc. EACL 1983, pp. 196-203</note>
<abstract confidence="0.965306333333333">The presented paper contains a description of an experimental version the natural language information retrieval system system is destined for use in the field of medicine. Its main purpose is to ensure access to information to physicians in a conversational manner. The use of the system does not require programming ability from its user.</abstract>
<intro confidence="0.782873">Computational Linguistics, Volume 10, Number 1 January-March 1984 57</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>EACL</author>
</authors>
<date>1983</date>
<pages>122--128</pages>
<contexts>
<context position="23491" citStr="EACL 1983" startWordPosition="3623" endWordPosition="3624"> attachment of procedures for the generation of database queries. 48 Computational Linguistics, Volume 10, Number 1 January-March 1984 The FINITE STRING Abstracts of Current Literature The following abstracts are from Proceedings of the First Conference of the European Chapter of the Association for Computational Linguistics, available for $15 a copy from Donald E. Walker, ACL Bell Communications Research 445 South Street Morristown, NJ 07960 USA Abstract Control Structures and the Semantics of Quantifers Steven Cushing Computer Science Department St. Anselm College Manchester, NH 03102 Proc. EACL 1983, pp. 1-8 Intuitively, a quantifier is any word or phrase that expresses a meaning that answers one of the questions &amp;quot;How many?&amp;quot; or &amp;quot;How much?&amp;quot; Typical English examples include all, no, many, few, some but not many, all but at most a very few, wherever, whoever, whoever there is, and also, it can be argued, only, also, and the. In this paper we review an empirically motivated analysis of such meanings and draw out its computational significance. For purposes of illustration, we focus our attention on the meanings expressed by the English words whatever and some, commonly represented, respectiv</context>
<context position="26615" citStr="EACL 1983" startWordPosition="4110" endWordPosition="4111"> N,F — direct iterative operators; I,G — boundary giving operators; I — extending operator. There are direct and indirect operations: the direct ones change a non-repetitious proposition into a repetitious one directly, whereas the indirect ones change it indirectly. The indirect iteration is indicated with E. The scope of each operator is not uniquely definable, though the mutual relation of the operators can be given more or less explicitly. L&apos;idee de Grammaire avec le Contexte Nature! Leszek Haduch Institute of Informatics Technical University of Lodz Lodz, ul.Piotrkowska 220, Poland Proc. EACL 1983, pp. 9-13 Iterative Operations Sae Yamada Notre Dame Seishin University Ifuku-Cho 2-16-9 700 Okayama, Japan Proc. EACL 1983, pp. 14-20 Computational Linguistics, Volume 10, Number 1 January-March 1984 49 The FINITE STRING Abstracts of Current Literature Structure of Sentence and Inferencing in Question Answering Eva Hajieovd, Petr Sgall Faculty of Mathematics and Physics Charles University Malostransk6 n. 25 118 00 Praha 1 Czechoslovakia Proc. EACL 1983, pp. 21-25 A Phonological Processor for Italian Rodolfo Delmonte Centro Linguistico Interfacolta Universi-th degli Studi di Venezia Ca&apos; Garzo</context>
<context position="31457" citStr="EACL 1983" startWordPosition="4838" endWordPosition="4839">odule has been specially designed to be implanted on a single board using a microprocessor, and inserted into the vocal terminal which already comprises a speech recognition board and a synthesis board. The entire vocal system is at present capable of conducting a real time spoken dialog with its user. 50 Computational Linguistics, Volume 10, Number 1 January-March 1984 The FINITE STRING Abstracts of Current Literature Knowledge Engineering Approach to Morphological Analysis Harri Jappinen, Aarno Lehtola, Esa Nelimarkka, Matti Ylilammi Helsinki University of Technology Helsinki, Finland Proc. EACL 1983, pp. 49-51 A PROLOG Implementation of Lexical Functional Grammar as a Base for a Natural Language Processing System Werner Frey, Uwe Reyle Department of Linguistics University of Stuttgart West Germany Proc. EACL 1983, pp. 52-57 Extended Access to the Left Context in an ATN Parser Irina Prodanof, Giacomo Ferrari Istituto di Linguistica Computazionale Via della Faggiola 32 1-56100 Pisa, Italy Proc. EACL 1983, pp. 58-65 An Experiment with Heuristic Parsing of Swedish Benny Brodda Institute of Linguistics University of Stockholm S-106 91 Stockholm SWEDEN Proc. EACL 1983, pp. 66-73 Towards the Se</context>
<context position="35618" citStr="EACL 1983" startWordPosition="5502" endWordPosition="5503">n various large information retrieval systems, and which can be expected to expand several orders of magnitude both in importance and in size in the foreseeable future. In the present paper we argue that the so-called sentence adverbials (typically, adverbs like probably, admittedly, ...) should be generated, in the framework of Functional Generative Description, by means of a special deep case — Complementation of Attitude (CA) on grounds of Computational Linguistics, Volume 10, Number 1 January-March 1984 51 The FINITE STRING Abstracts of Current Literature 39001 Tabor, Czechoslovakia Proc. EACL 1983, pp. 74-80 Dealing with Conjunctions in a Machine Translation Environment Xiuming Huang Institute of Linguistics Chinese Academy of Social Sciences Beijing, China Proc. EACL 1983, pp. 81-85 Fallible Rationalism and Machine Translation Geoffrey Sampson Linguistics &amp; Modern English Language University of Lancaster Lancaster LA1-4YT, G.B. Proc. EACL 1983, pp. 86-89 The Generation of Term Definitions from an Online Terminological Thesaurus John McNaught Centre for Computational Lingustics UMIST P.O. Box 88 Manchester, UK Proc. EACL 1983, pp. 90-95 Relating Syntax and Semantics: The Syntactico-sem</context>
<context position="40472" citStr="EACL 1983" startWordPosition="6241" endWordPosition="6242">uary-March 1984 The FINITE STRING Abstracts of Current Literature sentence are evaluated and individuals are created in the semantic net. The generator uses the same rules to express selected net-structures in adequate natural language expressions. It is shown how both processes can make effective use of SSL. The different possibilities for evaluating the SSL are explained and illustrated by examples. An Island Parsing Interpreter for the Full Augmented Transition Network Formalism John A. Carroll University of Cambridge Computer Laboratory Corn Exchange Street Cambridge CB2 30G England Proc. EACL 1983, pp. 101-105 WEDNESDAY: Parsing Flexible Word Order Languages Oliviero Stock, Cristiano Castelfranchi, Domenico Parisi Istituto di Psicologia del Consiglio Nazionale delle Ricerche Via dei Monti Tiburtini 509, 00157 Roma Proc. EACL 1983, pp. 106-110 How to Parse Gaps in Spoken Utterances G. Goerz, C. Beckstein Univ. Erlangen-Nuernberg, RRZE Martensstr. 1 D-8520 Erlangen, W. Germany Proc. EACL 1983, pp. 111-113 A Flexible Natural Language Parser Based on a Two-Level Representation of Syntax Island parsing is a powerful technique for parsing with Augmented Transition Networks (ATNs) which was d</context>
</contexts>
<marker>EACL, 1983</marker>
<rawString>Proc. EACL 1983, pp. 122-128</rawString>
</citation>
<citation valid="true">
<authors>
<author>I S Kononenko</author>
<author>E L</author>
</authors>
<title>An Experiment on Synthesis of Russian Parametric Constructions</title>
<date>1983</date>
<booktitle>Pershina Al Laboratory, Computing Center Siberian Branch of the USSSR Ac. Sci. Novosibirsk 630090, USSR Proc. EACL</booktitle>
<pages>129--132</pages>
<marker>Kononenko, L, 1983</marker>
<rawString>An Experiment on Synthesis of Russian Parametric Constructions I.S. Kononenko, E.L. Pershina Al Laboratory, Computing Center Siberian Branch of the USSSR Ac. Sci. Novosibirsk 630090, USSR Proc. EACL 1983, pp. 129-132</rawString>
</citation>
<citation valid="false">
<title>Learning Translation Skills with a Knowledge-Based Tutor: FrenchItalian Conjunctions in Context Stefano A. Cerni Dipartimento di lnformatica Marie-France Merger</title>
<marker></marker>
<rawString>Learning Translation Skills with a Knowledge-Based Tutor: FrenchItalian Conjunctions in Context Stefano A. Cerni Dipartimento di lnformatica Marie-France Merger</rawString>
</citation>
<citation valid="false">
<booktitle>Dipartimento di Lingue e Letterature Romanze</booktitle>
<marker></marker>
<rawString>Dipartimento di Lingue e Letterature Romanze</rawString>
</citation>
<citation valid="true">
<title>Universifa di Pisa 56100 Pisa, Italy</title>
<date>1983</date>
<booktitle>Proc. EACL</booktitle>
<pages>133--138</pages>
<contexts>
<context position="5142" citStr="(1983)" startWordPosition="805" endWordPosition="805"> may be interpreted as an elastic constraint on X. This canonical form and the meaning-composition process for proposisitions and dispositions are Illustrated by several examples among which is the proposition p = Over the past few years Naomi earned far more than most of her close friends. Test-Score Semantics for Natural Languages and Meaning Representation via PRUF Lotfi A. Zadeh see page 43 In Rieger, B., Ed., Empire&amp; Semantics I. Brockmeyer, Bochum, 1981. A Computational Approach to Fuzzy Quantifiers in Natural Languages Lotfi A. Zadeh see page 43 Comp. &amp; Maths. with App/s. 9(1): 149-184 (1983). In a sharp departure from the conventional approaches to the problem of meaning representation in natural languages, test-score semantics is based on the premise that almost everything that relates to natural languages is a matter of degree. Thus, in test-score semantics, predicates, propositions and other types of linguistic entities are treated as collections of elastic constraints on a set of objects or relations in a universe of discourse. Viewed in this perspective, the meaning of a linguistic entity may be defined by (a) identifying the constraints which are implicit or explicit in the</context>
</contexts>
<marker>1983</marker>
<rawString>Universifa di Pisa 56100 Pisa, Italy Proc. EACL 1983, pp. 133-138</rawString>
</citation>
<citation valid="false">
<authors>
<author>M I M Christian</author>
</authors>
<booktitle>Matthiessen USC/Information Sciences Institute 4676 Admiralty Way</booktitle>
<marker>Christian, </marker>
<rawString>Christian M.I.M. Matthiessen USC/Information Sciences Institute 4676 Admiralty Way</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina del Rey</author>
</authors>
<date>1983</date>
<booktitle>CA 90292 Proc. EACL</booktitle>
<pages>155--164</pages>
<marker>Rey, 1983</marker>
<rawString>Marina del Rey, CA 90292 Proc. EACL 1983, pp. 155-164</rawString>
</citation>
<citation valid="false">
<title>Inquiry Semantics: A Functional Semantics of Natural Language Grammar William C.</title>
<booktitle>Mann USC/Information Sciences Institute 4676 Admiralty Way</booktitle>
<marker></marker>
<rawString>Inquiry Semantics: A Functional Semantics of Natural Language Grammar William C. Mann USC/Information Sciences Institute 4676 Admiralty Way</rawString>
</citation>
<citation valid="false">
<authors>
<author>L Bolc</author>
<author>K Kochut</author>
<author>A Lesniewski</author>
<author>T</author>
</authors>
<title>Natural Language Information Retrieval System Dialog</title>
<publisher>Strzalkowski</publisher>
<marker>Bolc, Kochut, Lesniewski, T, </marker>
<rawString>Natural Language Information Retrieval System Dialog L. Bolc, K. Kochut, A. Lesniewski, T. Strzalkowski</rawString>
</citation>
<citation valid="true">
<date>1983</date>
<booktitle>Proc. EACL</booktitle>
<pages>850--00</pages>
<institution>Warsaw University Institute of Informatics PKin,</institution>
<location>Warszawa, Poland</location>
<contexts>
<context position="5142" citStr="(1983)" startWordPosition="805" endWordPosition="805"> may be interpreted as an elastic constraint on X. This canonical form and the meaning-composition process for proposisitions and dispositions are Illustrated by several examples among which is the proposition p = Over the past few years Naomi earned far more than most of her close friends. Test-Score Semantics for Natural Languages and Meaning Representation via PRUF Lotfi A. Zadeh see page 43 In Rieger, B., Ed., Empire&amp; Semantics I. Brockmeyer, Bochum, 1981. A Computational Approach to Fuzzy Quantifiers in Natural Languages Lotfi A. Zadeh see page 43 Comp. &amp; Maths. with App/s. 9(1): 149-184 (1983). In a sharp departure from the conventional approaches to the problem of meaning representation in natural languages, test-score semantics is based on the premise that almost everything that relates to natural languages is a matter of degree. Thus, in test-score semantics, predicates, propositions and other types of linguistic entities are treated as collections of elastic constraints on a set of objects or relations in a universe of discourse. Viewed in this perspective, the meaning of a linguistic entity may be defined by (a) identifying the constraints which are implicit or explicit in the</context>
</contexts>
<marker>1983</marker>
<rawString>Warsaw University Institute of Informatics PKin, pok.850 00-901 Warszawa, Poland Proc. EACL 1983, pp. 196-203</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>