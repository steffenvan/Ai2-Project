<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993818">
Joint Graphical Models for Date Selection in Timeline Summarization
</title>
<author confidence="0.96177">
Giang Tran
</author>
<affiliation confidence="0.7495925">
L3S Research Center
Leibniz-University Hannover
</affiliation>
<email confidence="0.872365">
gtran@l3s.de
</email>
<author confidence="0.470025">
Eelco Herder
</author>
<affiliation confidence="0.383152">
L3S Research Center
Leibniz-University Hannover
</affiliation>
<email confidence="0.763469">
herder@l3s.de
</email>
<author confidence="0.952647">
Katja Markert
</author>
<affiliation confidence="0.97249625">
L3S Research Center
Leibniz-University Hannover
and School of Computing
University of Leeds
</affiliation>
<email confidence="0.993885">
markert@l3s.de
</email>
<sectionHeader confidence="0.993795" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99964235">
Automatic timeline summarization (TLS)
generates precise, dated overviews over
(often prolonged) events, such as wars or
economic crises. One subtask of TLS se-
lects the most important dates for an event
within a certain time frame. Date selec-
tion has up to now been handled via su-
pervised machine learning approaches that
estimate the importance of each date sepa-
rately, using features such as the frequency
of date mentions in news corpora. This ap-
proach neglects interactions between dif-
ferent dates that occur due to connections
between subevents. We therefore suggest
a joint graphical model for date selection.
Even unsupervised versions of this model
perform as well as supervised state-of-the-
art approaches. With parameter tuning on
training data, it outperforms prior super-
vised models by a considerable margin.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99974">
Major events (such as the Egypt revolution starting
in 2011) often last over a long period of time and
have impact for a considerable time afterwards. In
order to find out what happened when during such
an event, time-related queries to search engines are
often insufficient as traditional IR does not handle
time-related queries well (Foley and Allan, 2015).
To provide readers with comprehensive overviews
of long events, many news outlets employ time-
line summaries: a timeline summary is a list of
selected dates with a few sentences describing the
most important events on each date. An example
can be seen in Table 1. Timelines allow the reader
to gain a quick overview over a complex event and
to answer questions such as: How and when did
the event start? What were the main consequences
of the initial events? What happened to the main
protagonists in the event? In addition, timelines
are frequent means in education (such as history
teaching) so that their generation is relevant for
education as well as journalism.
</bodyText>
<equation confidence="0.501843">
(a1) 2011-01-25
</equation>
<bodyText confidence="0.565122666666667">
Egyptians hold nationwide demonstrations against the au-
thoritarian rule of Hosni Mubarak, who has led the country
for nearly three decades.
</bodyText>
<figure confidence="0.8437488125">
(a2) 2011-01-26
A large security force moves into Cairo’s Tahrir Square
(a3) 2011-01-28
Protesters burn down the ruling party’s headquarters, and
the military is deployed.
(a4) 2011-02-11
Mubarak steps down and turns power over to the military.
(a5) 2011-03-19
In the first post Mubarak vote, Egyptians cast ballots on
constitutional amendments ..., including scheduling the
first parliamentary and presidential elections
(a8) 2012-04-20
The presidential campaign officially begins.
(a10) 2012-06-24
Election officials declare Morsi the winner
(a26) 2013-07-03
</figure>
<figureCaption confidence="0.474941833333333">
Egypt’s military chief says Morsi has been replaced by Adly
Mansour, the chief justice of constitutional court.
Table 1: A timeline about the Egypt revolution published by
the Associated Press (AP). We leave out intermediate dates
due to space constraints. The whole timeline includes 30
dates between 2011-01-25 and 2013-07-07.
</figureCaption>
<bodyText confidence="0.999824583333333">
Though convenient for the reader, the manual
creation of a timeline can take a long time even
for experts. For example, the creator of the start-
up Timeline says that it initially took a multi-
person team a full work day to create a single
timeline.1 Therefore, automatic timeline summa-
rization (TLS) has emerged as an NLP task in the
past few years (Tran et al., 2013a; Kessler et al.,
2012; Nguyen et al., 2014; Yan et al., 2011b; Yan
et al., 2011a; Wang et al., 2012; Tran et al., 2013b;
Tran et al., 2015). TLS has been divided into two
subtasks: (i) ranking the dates between beginning
</bodyText>
<footnote confidence="0.68788425">
1http://www.niemanlab.org/2015/02/
timeline-is-providing-historical-
context-to-the-news-but-is-there-a-
business-model-to-support-it/.
</footnote>
<page confidence="0.921654">
1598
</page>
<note confidence="0.976021333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1598–1607,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.993329206349207">
and end of the timeline in order of importance, to
achieve date selection and (ii) generating a good
daily summary for each of the selected dates. In
this paper, we tackle the first task. Date selection
is challenging, as normally only a small set of the
available dates is chosen for inclusion in the time-
line (see Table 1). Date selection may be partially
subjective: different journalists might include dif-
ferent dates.2
Existing approaches to date selection (Kessler
et al., 2012; Tran et al., 2013a) use supervised ma-
chine learning, where each date receives a score
for ranking the dates. Features used (such as fre-
quency of date mention) are extracted from a cor-
pus of event-related newspaper articles. Though
the features are well-explored, the models score
each date independently of other dates.
In contrast, we argue that interaction between
dates should be taken into account. Timeline
summaries tend to include “substories” in which
the majority of selected dates are part of a chain
of events that share major actors or demonstrate
cause-effect. Table 1 shows at least two such
chains: the (a1-4-5) chain of protests leading to
Mubarak’s resignation and the necessity of new
elections, as well as the similar (a8-10-26) chain
on Mursi. These chains can also be observed in the
corresponding news articles. For example, some
background articles on Mubarak’s step-down will
likely explain the reasons behind it. However, ex-
tracting such causal information can be difficult,
as demonstrated by the still low results for dis-
course relation extraction (Lin et al., 2014; Braud
and Denis, 2014). Instead, we use date reference
graphs, which model which date refers to which
other date. In our example, articles published on
Mubarak’s resignation date might refer to the date
when the protest started. Although weaker than
direct causal links, these links are easy to extract
and we will show that they are very useful. In ad-
dition, references from important dates (such as
Mubarak’s resignation date) should be weighted
higher than other references. This is akin to IR
models such as PageRank, which weigh links from
popular pages higher than links from less popular
pages.
The main contributions of this work are: (i)
we leverage interaction between dates via date ref-
erence graphs as a basis for date selection in TLS
2Note that the date selection task uses dates as proxies for
important events on that date.
(ii) we provide a novel random walk model on this
graph that incorporates both topical importance of
referring sentences as well as frequency and tem-
poral distance of references. We propose both un-
supervised as well as supervised versions of this
model.
We show that the proposed date selection
approach outperforms previous approaches with
evaluations on four real-life, long-term news
events. We also discuss variations in timeline con-
struction over different events, as well as by dif-
ferent journalists.
</bodyText>
<sectionHeader confidence="0.999724" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9998282">
Timeline summarization is a special case of multi-
document summarization (MDS). As TLS orga-
nizes events by date, timelines can be generated
by MDS systems (such as (Radev et al., 2004b;
Radev et al., 2004a; McKeown et al., 2003; Erkan
and Radev, 2004; Metzler and Kanungo, 2008;
Hong and Nenkova, 2014) by applying their sum-
marization techniques on news articles for every
individual date to create corresponding daily sum-
maries. However, manually written timelines nor-
mally only include a small number of dates; in
addition, the temporal component imposes con-
straints on sentence selection for timeline sum-
marization, such as the preference for little over-
lap between sentences selected for different dates
(Yan et al., 2011b).
Many studies specific to timeline summariza-
tion, such as (Swan and Allan, 2000; Allan et al.,
2001; Chieu and Lee, 2004; Yan et al., 2011b;
Tran et al., 2015), focus on the extraction of salient
sentences or headlines for generating the textual
content of timelines. They assume either that the
dates are given in advance or they use simple mea-
sures such as burstiness (Chieu and Lee, 2004;
Yan et al., 2011b) for date selection, where bursti-
ness relies on the number of date mentions.
Prior approaches dedicated specifically to date
selection are Tran et al. (2013a) and Kessler et
al. (2012).3 They use supervised machine learn-
ing methods that score dates independently of
each other. Features are extracted from a cor-
pus of event-related newspaper articles, including
frequency-based features (such as how often the
date is referred to in the corpus), temporal distance
features (such as how long into the future a date
</bodyText>
<footnote confidence="0.9882045">
3Kessler et al. (2012) is also used in Nguyen et al. (2014)’s
system.
</footnote>
<page confidence="0.998372">
1599
</page>
<bodyText confidence="0.999846625">
keeps being referred to) and topical features (such
as whether the date mention is associated with the
most significant keywords of the event). We, how-
ever, score dates jointly, making use of interac-
tions between dates in a graphical model. This
improves substantially over prior approaches. We
also propose unsupervised variations that perform
competitively to prior supervised models.
</bodyText>
<sectionHeader confidence="0.886492" genericHeader="method">
3 Problem Definition and Approach
</sectionHeader>
<bodyText confidence="0.999807">
Similar to Kessler et al. (2012) and Tran et al.
(2013a), we use the day as the timeline time unit
(so, for example, we exclude hourly timelines).
</bodyText>
<subsectionHeader confidence="0.997621">
3.1 Problem Definition
</subsectionHeader>
<bodyText confidence="0.999942888888889">
Given a main event and a time window [t1, t2]
within the event duration, our task is to select the
top k dates (d1, d2, ..., dk) E [t1, t2], when the
most important (sub)events occurred. Therefore,
timelines of variable length can be constructed.
Like (Kessler et al., 2012; Tran et al., 2013a), we
also assume that we have a corpus C, consisting
of news articles about the main event. This corpus
gives evidence about the dates in [t1, t2].
</bodyText>
<subsectionHeader confidence="0.999768">
3.2 Proposed Approach
</subsectionHeader>
<bodyText confidence="0.979829185185185">
We build a date reference graph, which is a fully
directed graph G = (V, £), where V is the set of
dates mentioned in any text in corpus C, including
publication dates. The edges £ = {e(di, dj)} in-
dicate that at least one text published on di refers
to the date dj.
We represent each such link as
a multi-value tuple e(di, dj) =
(Mij, freq(di, dj), Itemporal(di, dj), Itopical(di, dj))
to integrate different measures of date importance.
The first value, Mij = 1 N expresses the prior
stochastic transitional probability between 2
dates where N = |V|. The others express the
strength of the connection between di and dj
modelled by the following aspects: frequency
(freq), temporal influence (Itemporal) and topical
influence (Itopical). We also suggest different
combinations of these parameters.
Then we introduce a random walk model that
uses these perspectives to rank the collection of
dates.
Frequency of References. When a date dj is re-
ferred to from either a past or future news article
(published on di), it is likely involved in the events
that are reported in that article. An example pub-
lished on Mubarak’s resignation date and referring
back to the protest start can be seen below:
</bodyText>
<listItem confidence="0.909203">
(1) On January 25, an uprising of Egyptians erupted calling
for Mubaraks resignation as president. Protests contin-
ued to grow ... (CBS Detroit, 2011-02-11)
</listItem>
<bodyText confidence="0.998693285714286">
We hypothesize that the more frequent such
references are, the stronger this involvement is.
Hence, we compute freq(di, dj) as the number
of references to dj from news articles published
on di. While prior work (Kessler et al., 2012)
uses aggregate frequency of references to dj over
the whole corpus as a feature, they do not handle
the interaction between dates and can therefore not
score dates jointly.
Topical Influence. In Example 1 above, the ref-
erence sentence mentions only major actors in the
Egypt crisis (Mubarak, Egyptians) as well as only
major subevents (uprising, protests). This makes
for a link between 2011-02-11 (publication date)
and 2011-01-25 (referred date) that is relevant to
the main event and emphasises the importance of
the referred date. In contrast, Example 2 also talks
about less salient entities in context of the Egypt
revolution and makes for a less topical link be-
tween 2011-02-02 (publication date) and 2011-01-
25 (referred date).
</bodyText>
<listItem confidence="0.628243333333333">
(2) Mr Ghonim is Google’s head of marketing for Mid-
dle East and North Africa and was in Egypt when the
protests started on Jan 25 (DailyMail, 2011-02-02).
</listItem>
<bodyText confidence="0.9999366875">
We quantify the topical influence between dates
as follows: Let Si,j = {sij} be the set of sen-
tences that are published in di and refer to dj. We
are interested in how relevant this connection is to
the overall news event, looking at the content in
Si,j. To do so, we represent the overall content
of the news collection by a set of keywords Q =
{q1, q2,..., qn}, which are computed via TextRank
(Mihalcea and Tarau, 2004).4 We compute a rel-
evance score for each sentence sij in Si,j by the
famous Okapi BM25 function (Robertson et al.,
1994), which ranks a sentence more topical if it
contains more as well as more of the most salient
collection keywords Q.5 We compute topical in-
fluence (Itopical) as either the maximum value or
the sum value of the relevance scores of all sij.
</bodyText>
<equation confidence="0.85225525">
Imax topical(di, dj) = max
sij ESi→j
�Ifreq∗topical(di, dj) =
sij ESi→j
</equation>
<footnote confidence="0.963802333333333">
4We set n=20 in practice.
5We use the standard BM25 parameter settings k1 = 1.2
and b = 0.75
</footnote>
<equation confidence="0.985666">
BM25(sij,Q) (3)
BM25(sij, Q) (4)
</equation>
<page confidence="0.772294">
1600
</page>
<bodyText confidence="0.997890076923077">
Intuitively, Ifreq∗topical(di, dj) is proportional
to the size of Si→j as well as to the relevance
scores of its sentences whereas Imax topical(di, dj)
does not consider reference frequency at all.
When dj is not mentioned by any articles pub-
lished on di, the value of the topical influence is
equal to zero.
Temporal Influence. The longer ago an event
happened the more likely it is to have been for-
gotten. Only very important events are referred to
over long time frames. We therefore hypothesise
that a date dj is more influential (for another date
di) if di mentions dj and the temporal distance
between the two dates is high. Overall, dj gath-
ers importance with several long-term references.
Ex. 5 showcases an example:
(5) Military generals took over power from Mubarak when
he stepped down on February 11 last year. (Daily Mail,
2012-01-25).
We define the temporal influence of an existing
edge Itemporal(di, dj) as either the absolute value
of temporal distance between the two dates or by
the product of the temporal distance with the num-
ber of references freq(di, dj). In the second com-
putation, the temporal influence between two dates
increases when di references dj more than once.
</bodyText>
<equation confidence="0.994477">
I|temporal|(di, dj) = Δt = |di − dj |(6)
Ifreq*temporal(di, dj) = freq(di, dj) · |di − dj |(7)
</equation>
<bodyText confidence="0.956474545454545">
When dj is not mentioned by any articles pub-
lished on di, the temporal influence is set as zero.
Random Walk Model for Date Ranking. A
random walk on a given graph is a Markov pro-
cess, where each node represents a state and a
walk transiting from one state to another state is
based on a transition probability matrix. One well-
known random walk algorithm is PageRank (Page
et al., 1999), which models web surfer behavior to
determine the importance of web pages with the
following formula:
</bodyText>
<equation confidence="0.9915565">
xt(j) = α � Mijxt_1(i) + (1 − α)vj, (8)
iEL−3
</equation>
<bodyText confidence="0.999951571428571">
where Mij is the stochastic transition probability
from page pi to pj, xt(j) is the importance score
of page pj at step t, α is a damping factor that
controls how often the walker jumps to an arbi-
trary node, vj is the initial probabilistic impor-
tance score (generally set to 1/N, where N is the
number of nodes in the graph), and L−i is the set
of incoming links of page pi. When t is iterated
enough, the importance score vector reaches a sta-
tionary distribution that can be used for ranking
pages.
The traditional PageRank process in Eq. 8 cap-
tures only the observed linking characteristics of
nodes but ignores other sources of information
which can be indicators for their importance.
We extend the model by introducing an
influence-based random walk model (IRW) that
allows the random walker to take into account
multiple sources of information and perform vot-
ing more effectively. The random walk process we
propose can be defined by the following formula:
</bodyText>
<equation confidence="0.9971425">
xt(j) = α � Z(i, j) · Mij · xt_1(i) + (1 − α)vj (9)
iEL−3
</equation>
<bodyText confidence="0.999907176470588">
where I(i, j) is the normalized influence factor
that indicates how influential the edge di → dj is
in the global context of the event. The normaliza-
tion is done by scaling the range of value from [0,
1]. M is the stochastic transitional matrix. In our
case, I(i, j) can be just the value of freq(di, dj),
Itopical(di, dj) , Itemporal(di, dj) alone or a lin-
ear combination of them. Note that, (I · M) in
most case is not stochastic and must not be trans-
formed into a stochastic transitional matrix, as the
transformation will collapse the global context of
I. IRW is different to PageRank on weighted
graph, weighted or personalized PageRank and
their variations e.g, (Xing and Ghorbani, 2004;
Haveliwala, 2002), among others. In particu-
lar, weighted PageRank integrates influence scores
into the stochastic transitional matrix. Thus, the
random walker contributes the voting impact of a
node X to its neighbor with an influence score nor-
malized by the sum of scores on all outgoing con-
nections. That process leverages how good this
connection is in the sub-graph (G*) which consists
of X and its outgoing neighbors. In contrast, our
proposed model uses the non-normalized value of
the influence score to leverage how good this con-
nection is on the entire graph instead of G*. To
give an example, if date X1 mentions only X2 with
a raw temporal distance score of 20 and X3 men-
tions only X4 with a score of 100, then in weighted
Page Rank both would be normalized to a weight
one, losing the information that X4 is mentioned
after a much longer time period than X2. The pro-
cess for combination in our model is defined as the
following:
</bodyText>
<page confidence="0.933593">
1601
</page>
<bodyText confidence="0.924026">
where W1(i, j) = is
</bodyText>
<figure confidence="0.606893">
maxuv Itopical(du,dv)
Itopical(di,dj)
the normalized value for topical influence, and
W2(i, j) = Itemporal(di,dj) is the normalized
maxuv Itemporal (du,dv)
</figure>
<bodyText confidence="0.998397947368421">
value for temporal influence.6
Here, the hyper-parameter 0 &lt; w &lt; 1 controls
the proportion of the topical influence from di to
dj. When w = 0, no topical influence is taken
into account. No temporal influence is considered
when w = 1. Intuitively, at every step, the random
walker can follow the outgoing nodes and either
carry topical influence (the first part) or temporal
influence (the second part) to contribute to the rank
of the outgoing nodes. Otherwise, it teleports to an
arbitrary node with probability (1 − α).
Convergence Property. Starting from Eq. 10,
we now show that the IRW model converges to a
stationary distribution.
Let A and A&apos; be the matrix with elements
W1(i, j) and W2(ij) respectively, with any edge
(di, dj), I be the n x n identity matrix, and v be
the transpose of 1 x n uniform stochastic vector.
M denotes the transitional matrix for G.
</bodyText>
<equation confidence="0.983401947368421">
(wMT A+ (1− w)MTA&apos;))
Proposition 1. (I −α
is invertible for all M, A, A&apos;, α, w.
Proof. Let P = wMT A+ (1 − w)MT A0, we need to prove
that I−αP is invertible. Equivalently, we prove its transpose
I − αPT is invertible, which can be proved by showing that
(I − αPT )y = 0 only has the trivial solution y = 0.
(I − αPT )y = 0
y = αPT y
Xyi = α Pjiyj
j
X= α ((ωW1(i, j) + (1 − ω)W2(i, j))Mijyj).
j
Let u = arg maxj yj. When i == u, Eq. 11 infers,
Xyu &lt; α ((ωW1(u, j) + (1 − ω)W2(u, j))Mujyu).
j
Xyu &lt; αyu ((ωW1(u, j) + (1 − ω)W2(u, j))Muj
j
yu(1 − α.Pu) &lt; 0.
</equation>
<bodyText confidence="0.928095">
where Fu = Ej((wW1(u, j) + (1 − w)W2(u, j))Muj.
Clearly, Fu ≤ 1 because W1(u, j) ≤ 1 and W2(u, j) ≤ 1
</bodyText>
<footnote confidence="0.983369">
6In the case of linear combinations we incorporate fre-
quency into topical or temporal influence as described above.
</footnote>
<construct confidence="0.49622525">
and Ej Muj = 1. Since α &lt; 1 and Fu ≤ 1, (1− αFu) &gt; 0.
Therefore yu ≤ 0. Similarly, let v = arg minj yj we have
that yv ≥ 0. As yv ≤ yu, this implies yu = yv = 0 to satisfy
all inequalities. Consequently, yi = 0 for all i, or y = 0.
</construct>
<equation confidence="0.961328730769231">
Thus, I − αPT invertible. Equivalently,(I − α(wMT A +
(1 − w)MT A0)) is invertible.
Proposition 2. The iteration in Eq. 9 converges to
(1 − α)(I − α(wMTA + (1 − w)MTA&apos;))−1v.
Proof. We can re-write Eq. 9 in matrix form:
xt = αPxt−1 + (1 − α)v
= (αP)tx0 + (1 − α)( Xt (αP)i−1)v (13)
i=1
We will show that lim
t→∞ xt = (1 − α)(I − αP)−1v.
X(αP)tij = X X
i i k
X
(αP)t−1
kj
i
(αP)t−1 (14)
kj α(.Pk)
(αP)t−1
kj α
&lt; (α)t
Here, Fk = Ei((wW1(k, i)+(1−w)W2(k, i))Mki ≤ 1
(proof similarly to Proposition 1
Because α &lt; 1, this column sum converges to zero when
t → ∞. We then derive lim (αP)tx0 = 0. When t → ∞,
t→∞
</equation>
<bodyText confidence="0.64929">
given Proposition 1 and Neumann series, Eq. 13 becomes:
</bodyText>
<equation confidence="0.9937535">
xt = (αP)tx0 + (1 − α)(I − αP)−1v
xt = (1−α)(I−αP)−1v. Convergence proved.
</equation>
<sectionHeader confidence="0.999775" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999789">
4.1 Ground Truth and Data Preprocessing
</subsectionHeader>
<bodyText confidence="0.9999779">
Kessler et al. (2012) use 91 timelines from AFP
as ground truth along with the AFP news corpus
for feature extraction. However, their dataset is
not publically available. In addition, although they
consider a wide spread of events, each event is
only represented by a single timeline from a sin-
gle source, making that method somewhat vul-
nerable to journalism bias (as discussed by them-
selves in their paper). The data collected by us
previously (Tran et al., 2013a) is publically avail-
able at http://l3s.de/˜gtran/timeline/ and
has since been extended by us (Tran et al., 2015).
Similar to Kessler et al. (2012), it contains ground
truth timelines as well as a corpus of news articles
covering each event. The dataset is suitable for our
purpose because of the following reasons: (1) it is
a heterogeneous dataset which contains news arti-
cles and expert timeline summaries from different
news agencies. Thus, it is more likely to avoid
the issue of bias. Also, each event is represented
</bodyText>
<equation confidence="0.988054470588235">
�xt(j) = αw W1(i, j) · Mij · xt−1(i)
i∈L−j
+ α(1 − w) � W2(i, j) · Mij · xt−1(i) (10)
i∈L−j
+ (1 − α)vj
(αP )ik(αP )t−1
kj
X=
k
X=
k
X
&lt;
k
(αP)ik
hence, lim
t→∞
</equation>
<page confidence="0.943443">
1602
</page>
<bodyText confidence="0.999765714285714">
by more than one timeline; (2) it covers long-term
stories that have been happening since 2011, mak-
ing the date selection problem non trivial for any
system.
Timelines. The groundtruth contains 21 time-
lines for 4 main events (Egypt Revolution, Libya
War, Syria War, Yemen Crisis), created by profes-
sional journalists. Table 2 shows statistics about
the timelines. Only a small number of all pos-
sible dates in a time range is included in at least
one timeline (for example, only 122 dates among
a possible 918 dates for the Egypt Revolution).
News Corpus. The news articles have been col-
lected from 24 well-known news outlets by query-
ing Google with the event name together with
the outlets’ sitename and time range specification.
The crawl time range starts from the first of the
month of the earliest event in any timeline (for ex-
ample, 2011-01-01 for the Egypt revolution) and
ends at crawl date. The top-ranked 300 news ar-
ticles from each news site were collected, if still
available. The article creation date is parsed from
the answers returned by Google. The corpus con-
tains 15,534 news articles. Its statistics are sum-
marised in Table 3. The overlap between time-
line date ranges and news corpus date ranges is
only partial: on the one hand, the corpora have
many articles published after the timelines end; on
the other hand, sometimes the corpus has no ar-
ticles published near the beginning of the time-
line (Syria War). The distribution of document
frequency leans towards the end date of the news
collection. The reason could be that most search
engines rank recent documents higher than those
published longer ago.
</bodyText>
<table confidence="0.9995504">
Story Time Range #News
Egypt 2011/01/11 - 2013/11/10 3869
Libya 2011/02/16 - 2013/07/18 3994
Syria 2011/11/17 - 2013/07/26 4071
Yemen 2011/01/15 - 2013/07/25 3600
</table>
<tableCaption confidence="0.999867">
Table 3: Overview of the news corpus
</tableCaption>
<bodyText confidence="0.999239">
Preprocessing. Accurate date extraction includ-
ing both implicit (like last Friday) and explicit
(like 11 Feb ) temporal expressions is vital to
our approach as well as for competitor systems.
We use the Heideltime state-of-the art toolkit
(Str¨otgen and Gertz, 2010) for this task.
</bodyText>
<subsectionHeader confidence="0.96578">
4.2 Experimental settings
</subsectionHeader>
<bodyText confidence="0.984172611111111">
As can be seen from Table 2, different timelines
for the same event can contain varying dates, due
to different ranges timelines might cover but also
due to selection preferences by individual writers.
Therefore, we consider the union of all timelines
for an event. The set of input dates for ranking are
all dates from the start t1 and end t2 of the union
of timelines.7 We call that input time range TRe,
depending on main event e.
We consider two evaluation settings:
relaxed setting: A date from TRe selected by
an algorithm is counted as correct if it is included
in the union of timelines, therefore in at least one
individual timeline.
strict setting: A date from TRe selected by an
algorithm is counted as correct if it is included in
at least two individual timelines.
The first setting is the one used in previous work
such as (Kessler et al., 2012; Tran et al., 2013a).
It is also the only one that can be used if only one
timeline per event is considered as in Kessler et
al. (2012). We therefore include it for compari-
son purposes. However, we think it is better to
consider several timelines as it allows us to con-
sider agreement between timeline writers. If more
than one writer agrees on a date being important
we have more evidence that a system should find
that date. Finding dates that only a single writer
includes is less important and could even be due
to bias or system overfitting. Therefore, our sec-
ond setting is preferable as it emphasizes highly
important dates selected by multiple journalists.
Each system selects the top k dates during the
input time range. We evaluate the systems by
Mean Average Precision at k (MAP@k) for k =
5, 10, 15, 20 over all four events.
</bodyText>
<subsectionHeader confidence="0.995066">
4.3 Systems.
</subsectionHeader>
<bodyText confidence="0.999820076923077">
Baseline. We use three unsupervised baselines.
The baseline Document Frequency ranks dates ac-
cording to the number of news articles published
on that date. Our assumption is that on a date
where one or more important events happened,
there would be a spread of information over dif-
ferent news agencies in the world. Therefore, this
date has more news articles published. This base-
line is related to the burstiness date selection used
by Yan et al. (2011b).
The baseline MaxLength ranks dates by the
maximum article length of all articles published on
that date. Our hypothesis is that important events
</bodyText>
<footnote confidence="0.9378245">
7Prior work also uses start and end date of timelines for
delimiting input (Kessler et al., 2012; Tran et al., 2013a).
</footnote>
<page confidence="0.794866">
1603
</page>
<table confidence="0.9532082">
Story #TL #atLeastOnce #atLeastTwice avgL maxL minL Time Range #dates
Egypt 4 122 18 36 57 24 2011/01/01 - 2013/07/07 918
Libya 7 118 56 34 62 22 2011/02/14 - 2011/11/22 281
Syria 5 106 17 60 26 13 2011/03/15 - 2013/07/06 844
Yemen 5 81 26 24 42 10 2011/01/22 - 2012/02/27 401
</table>
<tableCaption confidence="0.5773825">
Number of timelines (#TL), number of dates occurring in at least one timeline (#atLeastOnce), number of dates that appear
in at least 2 timelines, average (avgL), max (maxL) and min (minL) length of timelines; the Time Range of the union of
timelines and all potential dates (#dates) within the time range.
Table 2: Overview of groundtruth timelines
</tableCaption>
<bodyText confidence="0.996363098591549">
often receive more attention from writers, leading
to longer articles.
Date Frequency ranks a date d by the total num-
ber of sentences referring to d that are not pub-
lished on d. This is a simple measure of d’s influ-
ence without joint scoring of dates or integration
of temporal distance or topic.
Competitors. We reimplement Kessler et al.
(2012)’s model. It first detects all sentences with
date references and filters out certain types of sen-
tences according to linguistic features (such as
presence of modality as this can put the factual-
ity of the event into question). Then, the impor-
tance score of a date is determined by the prod-
uct of the Lucene score of referring sentences and
an ML-predicted score that takes into account date
reference frequencies, temporal distance of date
references and topical importance of referring sen-
tences. To use the same setting as for our systems,
we use the list of keywords extracted by TextRank
(Mihalcea and Tarau, 2004) to formulate a topic
query for the Lucene index.
We reimplement Tran et al. (2013a) who use a
supervised ML approach based on a more detailed
consideration of date reference frequencies.
Both Kessler et al. (2012) and Tran et al.
(2013a) are retrained and tested via 4-fold cross-
validation on events. In addition, we noted that
the two supervised systems could profit from the
fact that for certain dates in TRe no published
news articles exist in the news collection and that
they are therefore a priori unlikely to be relevant.
We therefore also run those systems with a stricter
input time range, which intersects TRe with the
dates that are the publication date of at least one
article in the news collection. We indicate these
systems as Kessler et al. (2012) (Pub) and Tran et
al. (2013a) (Pub).
Our Approach. Our system builds graphs with
all dates referenced in the news corpus for an event
as nodes. We select the top k highest ranked nodes
that also fall within TRe. We measure the perfor-
mance with different strategies for the Influence
factor Z. We use the following five unsupervised
strategies, where we just set the damping factor α
to 0.85 as suggested by Page et al. (1999).8
IRWfreq only uses the frequency aspect. This
corresponds to a joint modelling version of the
Date Frequency baseline.
IRWmaxtopical uses topical influence, disre-
garding frequency aspect in its computation.
IRWfreq∗topical uses topical influence, incor-
porating the frequency aspect in its computation.
IRW|temporal |uses temporal influence, disre-
garding the frequency aspect.
IRWfreq∗temporal uses temporal influence in-
corporating the frequency aspect.
Furthermore, we are interested in combining
topical and temporal influence (with or without
frequency aspects). Here, our model is parame-
terized by w which controls the impact of topi-
cal influence vs. temporal influence. This param-
eter is tuned on the training set via 4-fold cross-
validation and, therefore, the next two models
have a small element of supervision.
IRWmax topical+freq∗temporal combines topical
and temporal influence, integrating the frequency
aspect into temporal influence.
IRWfreq∗topical+|temporal |combines topical
and temporal influence, integrating the frequency
aspect into topical influence.
</bodyText>
<subsectionHeader confidence="0.999845">
4.4 Analysis of date reference graphs
</subsectionHeader>
<bodyText confidence="0.863252789473684">
Table 4 shows an analysis of the four date refer-
ence graphs. In this Table, #sent provides the total
number of sentences from all news articles while
#hasRef shows the number of sentences that re-
fer to a date (around 15%), suggesting a sustain-
able part of data can be helpful for the interaction-
based approach. The number of nodes shows the
unique dates that are involved in a date reference
link. The number of edges is equivalent to the
number of date reference links (di, dj) that in-
dicate that there exist sentences published on di
but referring to dj. toStrict and toRelaxed is the
8We could make these models supervised by tuning the
damping factor via cross-validation. However, we found it
encouraging that we were able to achieve competitive results
without tuning — similar to links between web pages in the
traditional PageRank algorithm, links between dates seem to
embody strong relations, making the same damping factor
suitable.
</bodyText>
<page confidence="0.974127">
1604
</page>
<table confidence="0.9997922">
#sent #hasRef(%) #nodes #Edges toStrict reachStrict toRelaxed reachRelaxed
Egypt 143,096 26,428 (18.5) 939 2784 15.55% 100.00% 35.99% 89.34%
Libya 140,753 22,166 (15.7) 971 1797 33.78% 98.21% 56.98% 99.15%
Syria 162,305 26,992 (16.6) 812 1555 7.14% 88.24% 31.00% 73.58%
Yemen 140,156 21,606 (15.4) 1106 1608 18.28% 100.00% 37.00% 100.00%
</table>
<tableCaption confidence="0.999901">
Table 4: Interaction-based analysis on experimental news collections
</tableCaption>
<bodyText confidence="0.999973">
proportion of the edges that link to groundtruth
dates in the strict setting and relaxed setting.
Those edges cover almost all the groundtruth dates
(i.e, reachStrict and reachRelaxed), i.e almost all
groundtruth dates are indeed referenced at least
once in our corpus.
</bodyText>
<sectionHeader confidence="0.770784" genericHeader="evaluation">
4.5 Results
</sectionHeader>
<bodyText confidence="0.999981918918919">
Table 5 shows the average performance of differ-
ent systems over our four events. Several general
observations stand out. First, we notice that the
scores wrt. relaxed setting of all systems are higher
than those wrt. strict setting. That is expected, as
in relaxed setting, a selected date has a higher like-
lihood to be one of the milestones in the timeline
of at least one expert. Second, simple baselines
such as Document Frequency and MaxLength per-
form reasonably well in the relaxed-setting. That
confirms our assumptions that important dates of-
ten possess more published news articles and are
likely to have at least one article of substantial
length. However, these baselines are not enough
to distinguish highly important dates (which are
selected by more than one journalist) as shown by
their performance in the strict setting (around 0.3
MAP@k only).
Using Date Frequency leads to a substan-
tial performance improvement in the strict set-
ting comapred to the publication-based baselines.
Therefore, highly important dates are more likely
to be kept mentioning in the future and that sup-
ports our research direction to better leverage date
interaction for ranking date importance. This
is further confirmed by the performance of the
IRWfreq system which is the joint modelling ver-
sion of the DateFrequency baseline and outper-
foms the baseline without inclusion of any further
information such as topical salience. It can even
compete with prior supervised competitors when
their input time range is not modified.
Our supervised competitors (Kessler et al.,
2012; Tran et al., 2013a) perform overall well and
both profit from modifying their input time range
as suggested in the Pub versions. However, the un-
supervised versions of our system IRWmaxtopical
and IRWfreq∗topical perform very comparably to
the supervised competitors in the strict and relaxed
setting, respectively.
The last two lines of Table 5 show the re-
sults of our proposed method when using a lin-
ear combination of the different influence fac-
tors, and the hyperparameter w having been tuned
on the training set. IRWmax topical+freq∗temporal
shows the result of our system with w = 0.2 and
IRWfreq∗topical+|temporal |with w = 0.1 These
systems outperform the state-of-the-art systems
clearly in the strict setting and for most measures
in the relaxed setting.
Stability. We also investigated the stability of
the performance of different systems by look-
ing into their results on each event. Table 6
presents the performance of our best system
IRWmax topical+freq∗temporal and its best super-
vised competitors Tran et al. (2013a) (Pub) and
Kessler et al. (2012) (Pub). All systems perform
worse on the Syria story although our dropoff is
less than the one of prior systems.
We speculate that the competitor systems are
more sensitive to the amount of available pub-
lished content on a target date than ours. In partic-
ular, Tran et al. (2013a) use the frequency of pub-
lished dates and sentences as one of their features,
and Kessler et al. (2012) rely on the returned re-
sults from Lucene index which tends towards sub-
stories from the publication periods. Different to
others, the time range for the Syria news collection
does not include the time range for the Syria time-
lines fully or almost fully (see Tables 2 and 3). We
therefore are not as dependent on an exact match
between timeline dates and news collection dates
and can use news articles from later dates more
effectively.
</bodyText>
<sectionHeader confidence="0.994852" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999">
This paper addresses the problem of date selec-
tion for timeline summarization. Our approach
leverages the interactions between dates via a joint
model based on a date reference graph, improving
on individual scoring of dates.
We capture the interactions between dates from
the number of cross-references between dates, and
</bodyText>
<page confidence="0.957272">
1605
</page>
<table confidence="0.999909875">
System strict setting relaxed-setting
MAP@5 MAP@10 MAP@15 MAP@20 MAP@5 MAP@10 MAP@15 MAP@20
Document Frequency 0.312 0.303 0.299 0.299 0.509 0.550 0.564 0.560
MaxLength 0.349 0.335 0.311 0.287 0.647 0.594 0.566 0.533
Date Frequency 0.555 0.498 0.457 0.427 0.597 0.626 0.625 0.613
(Kessler et al., 2012) 0.567 0.546 0.519 0.491 0.790 0.740 0.723 0.704
(Kessler et al., 2012) (Pub) 0.701 0.620 0.571 0.524 0.912 0.807 0.759 0.731
(Tran et al., 2013a) 0.668 0.565 0.522 0.488 0.740 0.717 0.700 0.673
(Tran et al., 2013a) (Pub) 0.710 0.601 0.551 0.506 0.792 0.771 0.746 0.716
IRWfreq 0.646 0.535 0.471 0.431 0.861 0.770 0.711 0.687
IRWmax topical 0.763 0.647 0.564 0.510 0.887 0.794 0.724 0.685
IRWfreq∗topical 0.737 0.576 0.498 0.448 0.945 0.836 0.762 0.709
IRW|temporal |0.724 0.587 0.522 0.484 0.699 0.597 0.570 0.564
IRWfreq∗temporal 0.724 0.588 0.527 0.486 0.712 0.622 0.581 0.559
IRWmax topical+freq∗temporal 0.879 0.760 0.658 0.587 0.897 0.842 0.775 0.730
IRWfreq∗topical+|temporal |0.818 0.677 0.596 0.536 0.928 0.866 0.801 0.745
</table>
<tableCaption confidence="0.989476">
Table 5: Average MAP@k scores of different systems on 4 news collections
</tableCaption>
<table confidence="0.9997946875">
Egypt Libya Syria Yemen Acknowledgments
IRWmax topical+freq∗temporal
MAP@5 0.960 1.000 0.713 0.843
MAP@10 0.738 0.969 0.598 0.735 The work was partially funded by the Eu-
MAP@15 0.600 0.854 0.503 0.676
MAP@20 0.520 0.776 0.433 0.619 ropean Commission for the FP7 project
Kessler et al. (2012) (Pub) EUMSSI (611057) and the ERC Advanced
MAP@5 0.703 0.843 0.257 1.000
MAP@10 0.566 0.759 0.203 0.952 Grant ALEXANDRIA (339233).
MAP@15 0.507 0.697 0.187 0.894
MAP@20 0.450 0.659 0.171 0.816
Tran et al. (2013a) (Pub)
MAP@5 0.960 0.910 0.257 0.713 References
MAP@10 0.803 0.836 0.224 0.541
MAP@15 0.665 0.799 0.227 0.514
MAP@20 0.569 0.758 0.212 0.484 James Allan, Rahul Gupta, and Vikas Khandelwal.
</table>
<tableCaption confidence="0.998717">
Table 6: Stability of our systems vs. competitors
</tableCaption>
<bodyText confidence="0.987555083333333">
their temporal and topical influences. We present a
novel random walk model that incorporates these
perspectives into connectivity-based computation.
Experimental results on four news events that span
a long time period show that the proposed models
outperform state-of-the art approaches. Even un-
supervised versions of the model perform on a par
with previous supervised methods. We also draw
attention to the necessity to take personal bias into
account, which leads to differences between man-
ually created timelines for the same event — we
encourage future work to always consider several
timelines per event in the way that other NLP work
uses several annotators to create ground truth.
In future work, we will consider a wider range
of events and event types. This will also lead
to considering timelines where the day as unit of
granularity might not be appropriate or where the
unit of granularity might be varying across the
timeline. We will also explore in depth the effect
of size and type of news corpus on resulting time-
lines, research further into the issue of human dis-
agreement in timeline creation and explore human
evaluation of timeline summarization.
</bodyText>
<reference confidence="0.997643379310345">
2001. Temporal summaries of new topics. In Pro-
ceedings of SIGIR’01, pages 10–18.
Chlo´e Braud and Pascal Denis. 2014. Combin-
ing natural and artificial examples to improve im-
plicit discourse relation identification. In COL-
ING 2014: Technical Papers. Dublin, Ireland, pages
1694–1705.
Hai Leong Chieu and Yoong Keok Lee. 2004. Query
based event extraction along a timeline. In Proceed-
ings of SIGIR’04, pages 425–432.
G¨unes Erkan and Dragomir R. Radev. 2004. Lexrank:
graph-based lexical centrality as salience in text
summarization. J. Artif. Int. Res., 22(1):457–479.
John Foley and James Allan. 2015. Retrieving time
from scanned books. In Advances in Information
Retrieval, pages 221–232. Springer.
Taher H. Haveliwala. 2002. Topic-sensitive pagerank.
In WWW, pages 517–526.
Kai Hong and Ani Nenkova. 2014. Improving
the estimation of word importance for news multi-
document summarization. In Proceedings of EACL
2014, pages 712–721.
Remy Kessler, Xavier Tannier, Caroline Hag`ege,
V´eronique Moriceau, and Andr´e Bittar. 2012. Find-
ing salient dates for building thematic timelines. In
Proceedings ofACL.
Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2014.
A pdtb-styled end-to-end discourse parser. Natural
Language Engineering, 20(2):151–184.
</reference>
<page confidence="0.806436">
1606
</page>
<reference confidence="0.997894764705882">
Kathleen McKeown, Regina Barzilay, John Chen,
David K. Elson, David Kirk Evans, Judith Klavans,
Ani Nenkova, Barry Schiffman, and Sergey Sigel-
man. 2003. Columbia’s newsblaster: New features
and future directions. In HLT-NAACL.
Donald Metzler and Tapas Kanungo. 2008. Ma-
chine learned sentence selection strategies for query-
biased summarization. In Proceedings of the 2008
ACM SIGIR LR4IR Workshop.
Rada Mihalcea and Paul Tarau. 2004. Textrank:
Bringing order into text. In EMNLP, pages 404–
411.
Kiem-Hieu Nguyen, Xavier Tannier, and V´eronique
Moriceau. 2014. Ranking multidocument event de-
scriptions for building thematic timelines. In COL-
ING 2014, pages 1208–1217.
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical report,
Stanford InfoLab, November. Previous number =
SIDL-WP-1999-0120.
Dragomir R. Radev, Timothy Allison, Sasha Blair-
Goldensohn, John Blitzer, Arda Celebi, Stanko
Dimitrov, Elliott Drbek, Ali Hakim, Wai Lam,
Danyu Liu, Jahna Otterbacher, Hong Qi, Horacio
Saggion, Simone Teufel, Michael Topper, Adam
Winkel, and Zhu Zhang. 2004a. Mead - a platform
for multidocument multilingual text summarization.
In Proceedings of LREC’04.
Dragomir R. Radev, Hongyan Jing, Magorzata Sty, and
Daniel Tam. 2004b. Centroid-based summarization
of multiple documents. pages 919–938.
Stephen E. Robertson, Steve Walker, Susan Jones,
Micheline Hancock-Beaulieu, and Mike Gatford.
1994. Okapi at trec-3. In TREC.
Jannik Str¨otgen and Michael Gertz. 2010. Heideltime:
High quality rule-based extraction and normaliza-
tion of temporal expressions. In Proceedings of the
SemEval ’10 Workshop, pages 321–324.
Russell C. Swan and James Allan. 2000. Timemine:
visualizing automatically constructed timelines. In
SIGIR, page 393.
Binh Giang Tran, Mohammad Alrifai, and Dat
Quoc Nguyen. 2013a. Predicting relevant news
events for timeline summaries. In WWW’2013.
Giang Binh Tran, Tuan A. Tran, Nam-Khanh Tran,
Mohammad Alrifai, and Nattiya Kanhabua. 2013b.
Leveraging learning to rank in an optimization
framework for timeline summarization. In SIGIR
2013 Workshop TAIA.
Giang Tran, Mohammad Alrifai, and Eelco Herder.
2015. Timeline summarization from relevent head-
lines. In Proceedings of ECIR’2015.
Dingding Wang, Tao Li, and Mitsunori Ogihara. 2012.
Generating pictorial storylines via minimum-weight
connected dominating set approximation in multi-
view graphs. In Proceedings ofAAAI’2012.
Wenpu Xing and Ali A. Ghorbani. 2004. Weighted
pagerank algorithm. In CNSR, pages 305–314.
Rui Yan, Jian-Yun Nie, and Xiaoming Li. 2011a. Sum-
marize what you are interested in: An optimization
framework for interactive personalized summariza-
tion. In Proceedings of EMNLP’11.
Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,
Xiaoming Li, and Yan Zhang. 2011b. Evolution-
ary timeline summarization: a balanced optimiza-
tion framework via iterative substitution. In Pro-
ceedings of SIGIR’11, pages 745–754.
</reference>
<page confidence="0.993388">
1607
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.047409">
<title confidence="0.997584">Joint Graphical Models for Date Selection in Timeline Summarization</title>
<author confidence="0.96734">Giang</author>
<affiliation confidence="0.9232515">L3S Research Leibniz-University</affiliation>
<email confidence="0.839499">gtran@l3s.de</email>
<affiliation confidence="0.626423333333333">Eelco L3S Research Leibniz-University</affiliation>
<email confidence="0.803385">herder@l3s.de</email>
<author confidence="0.333174">Katja</author>
<affiliation confidence="0.95341275">L3S Research Leibniz-University and School of University of</affiliation>
<email confidence="0.811473">markert@l3s.de</email>
<abstract confidence="0.997372571428571">Automatic timeline summarization (TLS) generates precise, dated overviews over (often prolonged) events, such as wars or economic crises. One subtask of TLS selects the most important dates for an event within a certain time frame. Date selection has up to now been handled via supervised machine learning approaches that estimate the importance of each date separately, using features such as the frequency of date mentions in news corpora. This approach neglects interactions between different dates that occur due to connections between subevents. We therefore suggest a joint graphical model for date selection. Even unsupervised versions of this model perform as well as supervised state-of-theart approaches. With parameter tuning on training data, it outperforms prior supervised models by a considerable margin.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Temporal summaries of new topics.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGIR’01,</booktitle>
<pages>10--18</pages>
<marker>2001</marker>
<rawString>2001. Temporal summaries of new topics. In Proceedings of SIGIR’01, pages 10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chlo´e Braud</author>
<author>Pascal Denis</author>
</authors>
<title>Combining natural and artificial examples to improve implicit discourse relation identification.</title>
<date>2014</date>
<booktitle>In COLING 2014: Technical Papers.</booktitle>
<pages>1694--1705</pages>
<location>Dublin, Ireland,</location>
<contexts>
<context position="5843" citStr="Braud and Denis, 2014" startWordPosition="896" endWordPosition="899"> part of a chain of events that share major actors or demonstrate cause-effect. Table 1 shows at least two such chains: the (a1-4-5) chain of protests leading to Mubarak’s resignation and the necessity of new elections, as well as the similar (a8-10-26) chain on Mursi. These chains can also be observed in the corresponding news articles. For example, some background articles on Mubarak’s step-down will likely explain the reasons behind it. However, extracting such causal information can be difficult, as demonstrated by the still low results for discourse relation extraction (Lin et al., 2014; Braud and Denis, 2014). Instead, we use date reference graphs, which model which date refers to which other date. In our example, articles published on Mubarak’s resignation date might refer to the date when the protest started. Although weaker than direct causal links, these links are easy to extract and we will show that they are very useful. In addition, references from important dates (such as Mubarak’s resignation date) should be weighted higher than other references. This is akin to IR models such as PageRank, which weigh links from popular pages higher than links from less popular pages. The main contributio</context>
</contexts>
<marker>Braud, Denis, 2014</marker>
<rawString>Chlo´e Braud and Pascal Denis. 2014. Combining natural and artificial examples to improve implicit discourse relation identification. In COLING 2014: Technical Papers. Dublin, Ireland, pages 1694–1705.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Leong Chieu</author>
<author>Yoong Keok Lee</author>
</authors>
<title>Query based event extraction along a timeline.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGIR’04,</booktitle>
<pages>425--432</pages>
<contexts>
<context position="8030" citStr="Chieu and Lee, 2004" startWordPosition="1252" endWordPosition="1255">Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et al., 2015), focus on the extraction of salient sentences or headlines for generating the textual content of timelines. They assume either that the dates are given in advance or they use simple measures such as burstiness (Chieu and Lee, 2004; Yan et al., 2011b) for date selection, where burstiness relies on the number of date mentions. Prior approaches dedicated specifically to date selection are Tran et al. (2013a) and Kessler et al. (2012).3 They use supervised machine learning methods that score dates independently of each other. Features are extracted from a co</context>
</contexts>
<marker>Chieu, Lee, 2004</marker>
<rawString>Hai Leong Chieu and Yoong Keok Lee. 2004. Query based event extraction along a timeline. In Proceedings of SIGIR’04, pages 425–432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>Lexrank: graph-based lexical centrality as salience in text summarization.</title>
<date>2004</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="7432" citStr="Erkan and Radev, 2004" startWordPosition="1158" endWordPosition="1161">oral distance of references. We propose both unsupervised as well as supervised versions of this model. We show that the proposed date selection approach outperforms previous approaches with evaluations on four real-life, long-term news events. We also discuss variations in timeline construction over different events, as well as by different journalists. 2 Related Work Timeline summarization is a special case of multidocument summarization (MDS). As TLS organizes events by date, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; </context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes Erkan and Dragomir R. Radev. 2004. Lexrank: graph-based lexical centrality as salience in text summarization. J. Artif. Int. Res., 22(1):457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Foley</author>
<author>James Allan</author>
</authors>
<title>Retrieving time from scanned books.</title>
<date>2015</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<pages>221--232</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1538" citStr="Foley and Allan, 2015" startWordPosition="226" endWordPosition="229"> a joint graphical model for date selection. Even unsupervised versions of this model perform as well as supervised state-of-theart approaches. With parameter tuning on training data, it outperforms prior supervised models by a considerable margin. 1 Introduction Major events (such as the Egypt revolution starting in 2011) often last over a long period of time and have impact for a considerable time afterwards. In order to find out what happened when during such an event, time-related queries to search engines are often insufficient as traditional IR does not handle time-related queries well (Foley and Allan, 2015). To provide readers with comprehensive overviews of long events, many news outlets employ timeline summaries: a timeline summary is a list of selected dates with a few sentences describing the most important events on each date. An example can be seen in Table 1. Timelines allow the reader to gain a quick overview over a complex event and to answer questions such as: How and when did the event start? What were the main consequences of the initial events? What happened to the main protagonists in the event? In addition, timelines are frequent means in education (such as history teaching) so th</context>
</contexts>
<marker>Foley, Allan, 2015</marker>
<rawString>John Foley and James Allan. 2015. Retrieving time from scanned books. In Advances in Information Retrieval, pages 221–232. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taher H Haveliwala</author>
</authors>
<title>Topic-sensitive pagerank.</title>
<date>2002</date>
<booktitle>In WWW,</booktitle>
<pages>517--526</pages>
<contexts>
<context position="16983" citStr="Haveliwala, 2002" startWordPosition="2800" endWordPosition="2801">dj is in the global context of the event. The normalization is done by scaling the range of value from [0, 1]. M is the stochastic transitional matrix. In our case, I(i, j) can be just the value of freq(di, dj), Itopical(di, dj) , Itemporal(di, dj) alone or a linear combination of them. Note that, (I · M) in most case is not stochastic and must not be transformed into a stochastic transitional matrix, as the transformation will collapse the global context of I. IRW is different to PageRank on weighted graph, weighted or personalized PageRank and their variations e.g, (Xing and Ghorbani, 2004; Haveliwala, 2002), among others. In particular, weighted PageRank integrates influence scores into the stochastic transitional matrix. Thus, the random walker contributes the voting impact of a node X to its neighbor with an influence score normalized by the sum of scores on all outgoing connections. That process leverages how good this connection is in the sub-graph (G*) which consists of X and its outgoing neighbors. In contrast, our proposed model uses the non-normalized value of the influence score to leverage how good this connection is on the entire graph instead of G*. To give an example, if date X1 men</context>
</contexts>
<marker>Haveliwala, 2002</marker>
<rawString>Taher H. Haveliwala. 2002. Topic-sensitive pagerank. In WWW, pages 517–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Hong</author>
<author>Ani Nenkova</author>
</authors>
<title>Improving the estimation of word importance for news multidocument summarization.</title>
<date>2014</date>
<booktitle>In Proceedings of EACL 2014,</booktitle>
<pages>712--721</pages>
<contexts>
<context position="7484" citStr="Hong and Nenkova, 2014" startWordPosition="1166" endWordPosition="1169">ervised as well as supervised versions of this model. We show that the proposed date selection approach outperforms previous approaches with evaluations on four real-life, long-term news events. We also discuss variations in timeline construction over different events, as well as by different journalists. 2 Related Work Timeline summarization is a special case of multidocument summarization (MDS). As TLS organizes events by date, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et al., 2015), focus on the </context>
</contexts>
<marker>Hong, Nenkova, 2014</marker>
<rawString>Kai Hong and Ani Nenkova. 2014. Improving the estimation of word importance for news multidocument summarization. In Proceedings of EACL 2014, pages 712–721.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remy Kessler</author>
<author>Xavier Tannier</author>
<author>Caroline Hag`ege</author>
<author>V´eronique Moriceau</author>
<author>Andr´e Bittar</author>
</authors>
<title>Finding salient dates for building thematic timelines.</title>
<date>2012</date>
<booktitle>In Proceedings ofACL.</booktitle>
<marker>Kessler, Tannier, Hag`ege, Moriceau, Bittar, 2012</marker>
<rawString>Remy Kessler, Xavier Tannier, Caroline Hag`ege, V´eronique Moriceau, and Andr´e Bittar. 2012. Finding salient dates for building thematic timelines. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ziheng Lin</author>
<author>Hwee Tou Ng</author>
<author>Min-Yen Kan</author>
</authors>
<title>A pdtb-styled end-to-end discourse parser.</title>
<date>2014</date>
<journal>Natural Language Engineering,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="5819" citStr="Lin et al., 2014" startWordPosition="892" endWordPosition="895">selected dates are part of a chain of events that share major actors or demonstrate cause-effect. Table 1 shows at least two such chains: the (a1-4-5) chain of protests leading to Mubarak’s resignation and the necessity of new elections, as well as the similar (a8-10-26) chain on Mursi. These chains can also be observed in the corresponding news articles. For example, some background articles on Mubarak’s step-down will likely explain the reasons behind it. However, extracting such causal information can be difficult, as demonstrated by the still low results for discourse relation extraction (Lin et al., 2014; Braud and Denis, 2014). Instead, we use date reference graphs, which model which date refers to which other date. In our example, articles published on Mubarak’s resignation date might refer to the date when the protest started. Although weaker than direct causal links, these links are easy to extract and we will show that they are very useful. In addition, references from important dates (such as Mubarak’s resignation date) should be weighted higher than other references. This is akin to IR models such as PageRank, which weigh links from popular pages higher than links from less popular pag</context>
</contexts>
<marker>Lin, Ng, Kan, 2014</marker>
<rawString>Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2014. A pdtb-styled end-to-end discourse parser. Natural Language Engineering, 20(2):151–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
<author>Regina Barzilay</author>
<author>John Chen</author>
<author>David K Elson</author>
<author>David Kirk Evans</author>
<author>Judith Klavans</author>
<author>Ani Nenkova</author>
<author>Barry Schiffman</author>
<author>Sergey Sigelman</author>
</authors>
<title>Columbia’s newsblaster: New features and future directions.</title>
<date>2003</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="7409" citStr="McKeown et al., 2003" startWordPosition="1154" endWordPosition="1157"> as frequency and temporal distance of references. We propose both unsupervised as well as supervised versions of this model. We show that the proposed date selection approach outperforms previous approaches with evaluations on four real-life, long-term news events. We also discuss variations in timeline construction over different events, as well as by different journalists. 2 Related Work Timeline summarization is a special case of multidocument summarization (MDS). As TLS organizes events by date, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001</context>
</contexts>
<marker>McKeown, Barzilay, Chen, Elson, Evans, Klavans, Nenkova, Schiffman, Sigelman, 2003</marker>
<rawString>Kathleen McKeown, Regina Barzilay, John Chen, David K. Elson, David Kirk Evans, Judith Klavans, Ani Nenkova, Barry Schiffman, and Sergey Sigelman. 2003. Columbia’s newsblaster: New features and future directions. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
<author>Tapas Kanungo</author>
</authors>
<title>Machine learned sentence selection strategies for querybiased summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM SIGIR LR4IR Workshop.</booktitle>
<contexts>
<context position="7459" citStr="Metzler and Kanungo, 2008" startWordPosition="1162" endWordPosition="1165">nces. We propose both unsupervised as well as supervised versions of this model. We show that the proposed date selection approach outperforms previous approaches with evaluations on four real-life, long-term news events. We also discuss variations in timeline construction over different events, as well as by different journalists. 2 Related Work Timeline summarization is a special case of multidocument summarization (MDS). As TLS organizes events by date, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et </context>
</contexts>
<marker>Metzler, Kanungo, 2008</marker>
<rawString>Donald Metzler and Tapas Kanungo. 2008. Machine learned sentence selection strategies for querybiased summarization. In Proceedings of the 2008 ACM SIGIR LR4IR Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>Textrank: Bringing order into text.</title>
<date>2004</date>
<booktitle>In EMNLP,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="12863" citStr="Mihalcea and Tarau, 2004" startWordPosition="2068" endWordPosition="2071">lication date) and 2011-01- 25 (referred date). (2) Mr Ghonim is Google’s head of marketing for Middle East and North Africa and was in Egypt when the protests started on Jan 25 (DailyMail, 2011-02-02). We quantify the topical influence between dates as follows: Let Si,j = {sij} be the set of sentences that are published in di and refer to dj. We are interested in how relevant this connection is to the overall news event, looking at the content in Si,j. To do so, we represent the overall content of the news collection by a set of keywords Q = {q1, q2,..., qn}, which are computed via TextRank (Mihalcea and Tarau, 2004).4 We compute a relevance score for each sentence sij in Si,j by the famous Okapi BM25 function (Robertson et al., 1994), which ranks a sentence more topical if it contains more as well as more of the most salient collection keywords Q.5 We compute topical influence (Itopical) as either the maximum value or the sum value of the relevance scores of all sij. Imax topical(di, dj) = max sij ESi→j �Ifreq∗topical(di, dj) = sij ESi→j 4We set n=20 in practice. 5We use the standard BM25 parameter settings k1 = 1.2 and b = 0.75 BM25(sij,Q) (3) BM25(sij, Q) (4) 1600 Intuitively, Ifreq∗topical(di, dj) is </context>
<context position="28065" citStr="Mihalcea and Tarau, 2004" startWordPosition="4805" endWordPosition="4808">(2012)’s model. It first detects all sentences with date references and filters out certain types of sentences according to linguistic features (such as presence of modality as this can put the factuality of the event into question). Then, the importance score of a date is determined by the product of the Lucene score of referring sentences and an ML-predicted score that takes into account date reference frequencies, temporal distance of date references and topical importance of referring sentences. To use the same setting as for our systems, we use the list of keywords extracted by TextRank (Mihalcea and Tarau, 2004) to formulate a topic query for the Lucene index. We reimplement Tran et al. (2013a) who use a supervised ML approach based on a more detailed consideration of date reference frequencies. Both Kessler et al. (2012) and Tran et al. (2013a) are retrained and tested via 4-fold crossvalidation on events. In addition, we noted that the two supervised systems could profit from the fact that for certain dates in TRe no published news articles exist in the news collection and that they are therefore a priori unlikely to be relevant. We therefore also run those systems with a stricter input time range,</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. Textrank: Bringing order into text. In EMNLP, pages 404– 411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiem-Hieu Nguyen</author>
<author>Xavier Tannier</author>
<author>V´eronique Moriceau</author>
</authors>
<title>Ranking multidocument event descriptions for building thematic timelines.</title>
<date>2014</date>
<booktitle>In COLING 2014,</booktitle>
<pages>1208--1217</pages>
<contexts>
<context position="3663" citStr="Nguyen et al., 2014" startWordPosition="564" endWordPosition="567"> A timeline about the Egypt revolution published by the Associated Press (AP). We leave out intermediate dates due to space constraints. The whole timeline includes 30 dates between 2011-01-25 and 2013-07-07. Though convenient for the reader, the manual creation of a timeline can take a long time even for experts. For example, the creator of the startup Timeline says that it initially took a multiperson team a full work day to create a single timeline.1 Therefore, automatic timeline summarization (TLS) has emerged as an NLP task in the past few years (Tran et al., 2013a; Kessler et al., 2012; Nguyen et al., 2014; Yan et al., 2011b; Yan et al., 2011a; Wang et al., 2012; Tran et al., 2013b; Tran et al., 2015). TLS has been divided into two subtasks: (i) ranking the dates between beginning 1http://www.niemanlab.org/2015/02/ timeline-is-providing-historicalcontext-to-the-news-but-is-there-abusiness-model-to-support-it/. 1598 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1598–1607, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and end of the timeli</context>
<context position="8893" citStr="Nguyen et al. (2014)" startWordPosition="1397" endWordPosition="1400">tiness (Chieu and Lee, 2004; Yan et al., 2011b) for date selection, where burstiness relies on the number of date mentions. Prior approaches dedicated specifically to date selection are Tran et al. (2013a) and Kessler et al. (2012).3 They use supervised machine learning methods that score dates independently of each other. Features are extracted from a corpus of event-related newspaper articles, including frequency-based features (such as how often the date is referred to in the corpus), temporal distance features (such as how long into the future a date 3Kessler et al. (2012) is also used in Nguyen et al. (2014)’s system. 1599 keeps being referred to) and topical features (such as whether the date mention is associated with the most significant keywords of the event). We, however, score dates jointly, making use of interactions between dates in a graphical model. This improves substantially over prior approaches. We also propose unsupervised variations that perform competitively to prior supervised models. 3 Problem Definition and Approach Similar to Kessler et al. (2012) and Tran et al. (2013a), we use the day as the timeline time unit (so, for example, we exclude hourly timelines). 3.1 Problem Defi</context>
</contexts>
<marker>Nguyen, Tannier, Moriceau, 2014</marker>
<rawString>Kiem-Hieu Nguyen, Xavier Tannier, and V´eronique Moriceau. 2014. Ranking multidocument event descriptions for building thematic timelines. In COLING 2014, pages 1208–1217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<booktitle>Previous number =</booktitle>
<tech>Technical report, Stanford InfoLab,</tech>
<pages>1999--0120</pages>
<contexts>
<context position="15101" citStr="Page et al., 1999" startWordPosition="2463" endWordPosition="2466">rences freq(di, dj). In the second computation, the temporal influence between two dates increases when di references dj more than once. I|temporal|(di, dj) = Δt = |di − dj |(6) Ifreq*temporal(di, dj) = freq(di, dj) · |di − dj |(7) When dj is not mentioned by any articles published on di, the temporal influence is set as zero. Random Walk Model for Date Ranking. A random walk on a given graph is a Markov process, where each node represents a state and a walk transiting from one state to another state is based on a transition probability matrix. One wellknown random walk algorithm is PageRank (Page et al., 1999), which models web surfer behavior to determine the importance of web pages with the following formula: xt(j) = α � Mijxt_1(i) + (1 − α)vj, (8) iEL−3 where Mij is the stochastic transition probability from page pi to pj, xt(j) is the importance score of page pj at step t, α is a damping factor that controls how often the walker jumps to an arbitrary node, vj is the initial probabilistic importance score (generally set to 1/N, where N is the number of nodes in the graph), and L−i is the set of incoming links of page pi. When t is iterated enough, the importance score vector reaches a stationary</context>
<context position="29256" citStr="Page et al. (1999)" startWordPosition="5013" endWordPosition="5016"> stricter input time range, which intersects TRe with the dates that are the publication date of at least one article in the news collection. We indicate these systems as Kessler et al. (2012) (Pub) and Tran et al. (2013a) (Pub). Our Approach. Our system builds graphs with all dates referenced in the news corpus for an event as nodes. We select the top k highest ranked nodes that also fall within TRe. We measure the performance with different strategies for the Influence factor Z. We use the following five unsupervised strategies, where we just set the damping factor α to 0.85 as suggested by Page et al. (1999).8 IRWfreq only uses the frequency aspect. This corresponds to a joint modelling version of the Date Frequency baseline. IRWmaxtopical uses topical influence, disregarding frequency aspect in its computation. IRWfreq∗topical uses topical influence, incorporating the frequency aspect in its computation. IRW|temporal |uses temporal influence, disregarding the frequency aspect. IRWfreq∗temporal uses temporal influence incorporating the frequency aspect. Furthermore, we are interested in combining topical and temporal influence (with or without frequency aspects). Here, our model is parameterized </context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web. Technical report, Stanford InfoLab, November. Previous number = SIDL-WP-1999-0120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Timothy Allison</author>
<author>Sasha BlairGoldensohn</author>
<author>John Blitzer</author>
<author>Arda Celebi</author>
<author>Stanko Dimitrov</author>
<author>Elliott Drbek</author>
<author>Ali Hakim</author>
</authors>
<title>Mead - a platform for multidocument multilingual text summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC’04.</booktitle>
<location>Wai Lam, Danyu Liu, Jahna Otterbacher, Hong Qi, Horacio Saggion, Simone Teufel, Michael Topper, Adam</location>
<contexts>
<context position="7365" citStr="Radev et al., 2004" startWordPosition="1146" endWordPosition="1149"> importance of referring sentences as well as frequency and temporal distance of references. We propose both unsupervised as well as supervised versions of this model. We show that the proposed date selection approach outperforms previous approaches with evaluations on four real-life, long-term news events. We also discuss variations in timeline construction over different events, as well as by different journalists. 2 Related Work Timeline summarization is a special case of multidocument summarization (MDS). As TLS organizes events by date, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such </context>
</contexts>
<marker>Radev, Allison, BlairGoldensohn, Blitzer, Celebi, Dimitrov, Drbek, Hakim, 2004</marker>
<rawString>Dragomir R. Radev, Timothy Allison, Sasha BlairGoldensohn, John Blitzer, Arda Celebi, Stanko Dimitrov, Elliott Drbek, Ali Hakim, Wai Lam, Danyu Liu, Jahna Otterbacher, Hong Qi, Horacio Saggion, Simone Teufel, Michael Topper, Adam Winkel, and Zhu Zhang. 2004a. Mead - a platform for multidocument multilingual text summarization. In Proceedings of LREC’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Hongyan Jing</author>
<author>Magorzata Sty</author>
<author>Daniel Tam</author>
</authors>
<title>Centroid-based summarization of multiple documents.</title>
<date>2004</date>
<pages>919--938</pages>
<contexts>
<context position="7365" citStr="Radev et al., 2004" startWordPosition="1146" endWordPosition="1149"> importance of referring sentences as well as frequency and temporal distance of references. We propose both unsupervised as well as supervised versions of this model. We show that the proposed date selection approach outperforms previous approaches with evaluations on four real-life, long-term news events. We also discuss variations in timeline construction over different events, as well as by different journalists. 2 Related Work Timeline summarization is a special case of multidocument summarization (MDS). As TLS organizes events by date, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such </context>
</contexts>
<marker>Radev, Jing, Sty, Tam, 2004</marker>
<rawString>Dragomir R. Radev, Hongyan Jing, Magorzata Sty, and Daniel Tam. 2004b. Centroid-based summarization of multiple documents. pages 919–938.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen E Robertson</author>
<author>Steve Walker</author>
<author>Susan Jones</author>
<author>Micheline Hancock-Beaulieu</author>
<author>Mike Gatford</author>
</authors>
<title>Okapi at trec-3. In TREC.</title>
<date>1994</date>
<contexts>
<context position="12983" citStr="Robertson et al., 1994" startWordPosition="2090" endWordPosition="2093">ca and was in Egypt when the protests started on Jan 25 (DailyMail, 2011-02-02). We quantify the topical influence between dates as follows: Let Si,j = {sij} be the set of sentences that are published in di and refer to dj. We are interested in how relevant this connection is to the overall news event, looking at the content in Si,j. To do so, we represent the overall content of the news collection by a set of keywords Q = {q1, q2,..., qn}, which are computed via TextRank (Mihalcea and Tarau, 2004).4 We compute a relevance score for each sentence sij in Si,j by the famous Okapi BM25 function (Robertson et al., 1994), which ranks a sentence more topical if it contains more as well as more of the most salient collection keywords Q.5 We compute topical influence (Itopical) as either the maximum value or the sum value of the relevance scores of all sij. Imax topical(di, dj) = max sij ESi→j �Ifreq∗topical(di, dj) = sij ESi→j 4We set n=20 in practice. 5We use the standard BM25 parameter settings k1 = 1.2 and b = 0.75 BM25(sij,Q) (3) BM25(sij, Q) (4) 1600 Intuitively, Ifreq∗topical(di, dj) is proportional to the size of Si→j as well as to the relevance scores of its sentences whereas Imax topical(di, dj) does n</context>
</contexts>
<marker>Robertson, Walker, Jones, Hancock-Beaulieu, Gatford, 1994</marker>
<rawString>Stephen E. Robertson, Steve Walker, Susan Jones, Micheline Hancock-Beaulieu, and Mike Gatford. 1994. Okapi at trec-3. In TREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jannik Str¨otgen</author>
<author>Michael Gertz</author>
</authors>
<title>Heideltime: High quality rule-based extraction and normalization of temporal expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the SemEval ’10 Workshop,</booktitle>
<pages>321--324</pages>
<marker>Str¨otgen, Gertz, 2010</marker>
<rawString>Jannik Str¨otgen and Michael Gertz. 2010. Heideltime: High quality rule-based extraction and normalization of temporal expressions. In Proceedings of the SemEval ’10 Workshop, pages 321–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Russell C Swan</author>
<author>James Allan</author>
</authors>
<title>Timemine: visualizing automatically constructed timelines.</title>
<date>2000</date>
<booktitle>In SIGIR,</booktitle>
<pages>393</pages>
<contexts>
<context position="7989" citStr="Swan and Allan, 2000" startWordPosition="1244" endWordPosition="1247">adev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et al., 2015), focus on the extraction of salient sentences or headlines for generating the textual content of timelines. They assume either that the dates are given in advance or they use simple measures such as burstiness (Chieu and Lee, 2004; Yan et al., 2011b) for date selection, where burstiness relies on the number of date mentions. Prior approaches dedicated specifically to date selection are Tran et al. (2013a) and Kessler et al. (2012).3 They use supervised machine learning methods that score dates independently of eac</context>
</contexts>
<marker>Swan, Allan, 2000</marker>
<rawString>Russell C. Swan and James Allan. 2000. Timemine: visualizing automatically constructed timelines. In SIGIR, page 393.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Binh Giang Tran</author>
</authors>
<title>Mohammad Alrifai, and Dat Quoc Nguyen. 2013a. Predicting relevant news events for timeline summaries.</title>
<booktitle>In WWW’2013.</booktitle>
<marker>Tran, </marker>
<rawString>Binh Giang Tran, Mohammad Alrifai, and Dat Quoc Nguyen. 2013a. Predicting relevant news events for timeline summaries. In WWW’2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giang Binh Tran</author>
<author>Tuan A Tran</author>
<author>Nam-Khanh Tran</author>
<author>Mohammad Alrifai</author>
<author>Nattiya Kanhabua</author>
</authors>
<title>Leveraging learning to rank in an optimization framework for timeline summarization.</title>
<date>2013</date>
<booktitle>In SIGIR 2013 Workshop TAIA.</booktitle>
<contexts>
<context position="3619" citStr="Tran et al., 2013" startWordPosition="556" endWordPosition="559"> justice of constitutional court. Table 1: A timeline about the Egypt revolution published by the Associated Press (AP). We leave out intermediate dates due to space constraints. The whole timeline includes 30 dates between 2011-01-25 and 2013-07-07. Though convenient for the reader, the manual creation of a timeline can take a long time even for experts. For example, the creator of the startup Timeline says that it initially took a multiperson team a full work day to create a single timeline.1 Therefore, automatic timeline summarization (TLS) has emerged as an NLP task in the past few years (Tran et al., 2013a; Kessler et al., 2012; Nguyen et al., 2014; Yan et al., 2011b; Yan et al., 2011a; Wang et al., 2012; Tran et al., 2013b; Tran et al., 2015). TLS has been divided into two subtasks: (i) ranking the dates between beginning 1http://www.niemanlab.org/2015/02/ timeline-is-providing-historicalcontext-to-the-news-but-is-there-abusiness-model-to-support-it/. 1598 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1598–1607, Beijing, China, July 26-31, 2015. c�2015 Association for Com</context>
<context position="8476" citStr="Tran et al. (2013" startWordPosition="1328" endWordPosition="1331">s selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et al., 2015), focus on the extraction of salient sentences or headlines for generating the textual content of timelines. They assume either that the dates are given in advance or they use simple measures such as burstiness (Chieu and Lee, 2004; Yan et al., 2011b) for date selection, where burstiness relies on the number of date mentions. Prior approaches dedicated specifically to date selection are Tran et al. (2013a) and Kessler et al. (2012).3 They use supervised machine learning methods that score dates independently of each other. Features are extracted from a corpus of event-related newspaper articles, including frequency-based features (such as how often the date is referred to in the corpus), temporal distance features (such as how long into the future a date 3Kessler et al. (2012) is also used in Nguyen et al. (2014)’s system. 1599 keeps being referred to) and topical features (such as whether the date mention is associated with the most significant keywords of the event). We, however, score date</context>
<context position="9792" citStr="Tran et al., 2013" startWordPosition="1545" endWordPosition="1548">ly over prior approaches. We also propose unsupervised variations that perform competitively to prior supervised models. 3 Problem Definition and Approach Similar to Kessler et al. (2012) and Tran et al. (2013a), we use the day as the timeline time unit (so, for example, we exclude hourly timelines). 3.1 Problem Definition Given a main event and a time window [t1, t2] within the event duration, our task is to select the top k dates (d1, d2, ..., dk) E [t1, t2], when the most important (sub)events occurred. Therefore, timelines of variable length can be constructed. Like (Kessler et al., 2012; Tran et al., 2013a), we also assume that we have a corpus C, consisting of news articles about the main event. This corpus gives evidence about the dates in [t1, t2]. 3.2 Proposed Approach We build a date reference graph, which is a fully directed graph G = (V, £), where V is the set of dates mentioned in any text in corpus C, including publication dates. The edges £ = {e(di, dj)} indicate that at least one text published on di refers to the date dj. We represent each such link as a multi-value tuple e(di, dj) = (Mij, freq(di, dj), Itemporal(di, dj), Itopical(di, dj)) to integrate different measures of date im</context>
<context position="21215" citStr="Tran et al., 2013" startWordPosition="3617" endWordPosition="3620"> series, Eq. 13 becomes: xt = (αP)tx0 + (1 − α)(I − αP)−1v xt = (1−α)(I−αP)−1v. Convergence proved. 4 Experiments 4.1 Ground Truth and Data Preprocessing Kessler et al. (2012) use 91 timelines from AFP as ground truth along with the AFP news corpus for feature extraction. However, their dataset is not publically available. In addition, although they consider a wide spread of events, each event is only represented by a single timeline from a single source, making that method somewhat vulnerable to journalism bias (as discussed by themselves in their paper). The data collected by us previously (Tran et al., 2013a) is publically available at http://l3s.de/˜gtran/timeline/ and has since been extended by us (Tran et al., 2015). Similar to Kessler et al. (2012), it contains ground truth timelines as well as a corpus of news articles covering each event. The dataset is suitable for our purpose because of the following reasons: (1) it is a heterogeneous dataset which contains news articles and expert timeline summaries from different news agencies. Thus, it is more likely to avoid the issue of bias. Also, each event is represented �xt(j) = αw W1(i, j) · Mij · xt−1(i) i∈L−j + α(1 − w) � W2(i, j) · Mij · xt−</context>
<context position="24915" citStr="Tran et al., 2013" startWordPosition="4258" endWordPosition="4261">vent. The set of input dates for ranking are all dates from the start t1 and end t2 of the union of timelines.7 We call that input time range TRe, depending on main event e. We consider two evaluation settings: relaxed setting: A date from TRe selected by an algorithm is counted as correct if it is included in the union of timelines, therefore in at least one individual timeline. strict setting: A date from TRe selected by an algorithm is counted as correct if it is included in at least two individual timelines. The first setting is the one used in previous work such as (Kessler et al., 2012; Tran et al., 2013a). It is also the only one that can be used if only one timeline per event is considered as in Kessler et al. (2012). We therefore include it for comparison purposes. However, we think it is better to consider several timelines as it allows us to consider agreement between timeline writers. If more than one writer agrees on a date being important we have more evidence that a system should find that date. Finding dates that only a single writer includes is less important and could even be due to bias or system overfitting. Therefore, our second setting is preferable as it emphasizes highly imp</context>
<context position="26464" citStr="Tran et al., 2013" startWordPosition="4528" endWordPosition="4531"> to the number of news articles published on that date. Our assumption is that on a date where one or more important events happened, there would be a spread of information over different news agencies in the world. Therefore, this date has more news articles published. This baseline is related to the burstiness date selection used by Yan et al. (2011b). The baseline MaxLength ranks dates by the maximum article length of all articles published on that date. Our hypothesis is that important events 7Prior work also uses start and end date of timelines for delimiting input (Kessler et al., 2012; Tran et al., 2013a). 1603 Story #TL #atLeastOnce #atLeastTwice avgL maxL minL Time Range #dates Egypt 4 122 18 36 57 24 2011/01/01 - 2013/07/07 918 Libya 7 118 56 34 62 22 2011/02/14 - 2011/11/22 281 Syria 5 106 17 60 26 13 2011/03/15 - 2013/07/06 844 Yemen 5 81 26 24 42 10 2011/01/22 - 2012/02/27 401 Number of timelines (#TL), number of dates occurring in at least one timeline (#atLeastOnce), number of dates that appear in at least 2 timelines, average (avgL), max (maxL) and min (minL) length of timelines; the Time Range of the union of timelines and all potential dates (#dates) within the time range. Table 2</context>
<context position="28147" citStr="Tran et al. (2013" startWordPosition="4820" endWordPosition="4823">n types of sentences according to linguistic features (such as presence of modality as this can put the factuality of the event into question). Then, the importance score of a date is determined by the product of the Lucene score of referring sentences and an ML-predicted score that takes into account date reference frequencies, temporal distance of date references and topical importance of referring sentences. To use the same setting as for our systems, we use the list of keywords extracted by TextRank (Mihalcea and Tarau, 2004) to formulate a topic query for the Lucene index. We reimplement Tran et al. (2013a) who use a supervised ML approach based on a more detailed consideration of date reference frequencies. Both Kessler et al. (2012) and Tran et al. (2013a) are retrained and tested via 4-fold crossvalidation on events. In addition, we noted that the two supervised systems could profit from the fact that for certain dates in TRe no published news articles exist in the news collection and that they are therefore a priori unlikely to be relevant. We therefore also run those systems with a stricter input time range, which intersects TRe with the dates that are the publication date of at least one</context>
<context position="33592" citStr="Tran et al., 2013" startWordPosition="5680" endWordPosition="5683">lication-based baselines. Therefore, highly important dates are more likely to be kept mentioning in the future and that supports our research direction to better leverage date interaction for ranking date importance. This is further confirmed by the performance of the IRWfreq system which is the joint modelling version of the DateFrequency baseline and outperfoms the baseline without inclusion of any further information such as topical salience. It can even compete with prior supervised competitors when their input time range is not modified. Our supervised competitors (Kessler et al., 2012; Tran et al., 2013a) perform overall well and both profit from modifying their input time range as suggested in the Pub versions. However, the unsupervised versions of our system IRWmaxtopical and IRWfreq∗topical perform very comparably to the supervised competitors in the strict and relaxed setting, respectively. The last two lines of Table 5 show the results of our proposed method when using a linear combination of the different influence factors, and the hyperparameter w having been tuned on the training set. IRWmax topical+freq∗temporal shows the result of our system with w = 0.2 and IRWfreq∗topical+|tempor</context>
<context position="34916" citStr="Tran et al. (2013" startWordPosition="5896" endWordPosition="5899">r most measures in the relaxed setting. Stability. We also investigated the stability of the performance of different systems by looking into their results on each event. Table 6 presents the performance of our best system IRWmax topical+freq∗temporal and its best supervised competitors Tran et al. (2013a) (Pub) and Kessler et al. (2012) (Pub). All systems perform worse on the Syria story although our dropoff is less than the one of prior systems. We speculate that the competitor systems are more sensitive to the amount of available published content on a target date than ours. In particular, Tran et al. (2013a) use the frequency of published dates and sentences as one of their features, and Kessler et al. (2012) rely on the returned results from Lucene index which tends towards substories from the publication periods. Different to others, the time range for the Syria news collection does not include the time range for the Syria timelines fully or almost fully (see Tables 2 and 3). We therefore are not as dependent on an exact match between timeline dates and news collection dates and can use news articles from later dates more effectively. 5 Conclusion and Future Work This paper addresses the prob</context>
<context position="36261" citStr="Tran et al., 2013" startWordPosition="6116" endWordPosition="6119">on a date reference graph, improving on individual scoring of dates. We capture the interactions between dates from the number of cross-references between dates, and 1605 System strict setting relaxed-setting MAP@5 MAP@10 MAP@15 MAP@20 MAP@5 MAP@10 MAP@15 MAP@20 Document Frequency 0.312 0.303 0.299 0.299 0.509 0.550 0.564 0.560 MaxLength 0.349 0.335 0.311 0.287 0.647 0.594 0.566 0.533 Date Frequency 0.555 0.498 0.457 0.427 0.597 0.626 0.625 0.613 (Kessler et al., 2012) 0.567 0.546 0.519 0.491 0.790 0.740 0.723 0.704 (Kessler et al., 2012) (Pub) 0.701 0.620 0.571 0.524 0.912 0.807 0.759 0.731 (Tran et al., 2013a) 0.668 0.565 0.522 0.488 0.740 0.717 0.700 0.673 (Tran et al., 2013a) (Pub) 0.710 0.601 0.551 0.506 0.792 0.771 0.746 0.716 IRWfreq 0.646 0.535 0.471 0.431 0.861 0.770 0.711 0.687 IRWmax topical 0.763 0.647 0.564 0.510 0.887 0.794 0.724 0.685 IRWfreq∗topical 0.737 0.576 0.498 0.448 0.945 0.836 0.762 0.709 IRW|temporal |0.724 0.587 0.522 0.484 0.699 0.597 0.570 0.564 IRWfreq∗temporal 0.724 0.588 0.527 0.486 0.712 0.622 0.581 0.559 IRWmax topical+freq∗temporal 0.879 0.760 0.658 0.587 0.897 0.842 0.775 0.730 IRWfreq∗topical+|temporal |0.818 0.677 0.596 0.536 0.928 0.866 0.801 0.745 Table 5: Ave</context>
</contexts>
<marker>Tran, Tran, Tran, Alrifai, Kanhabua, 2013</marker>
<rawString>Giang Binh Tran, Tuan A. Tran, Nam-Khanh Tran, Mohammad Alrifai, and Nattiya Kanhabua. 2013b. Leveraging learning to rank in an optimization framework for timeline summarization. In SIGIR 2013 Workshop TAIA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giang Tran</author>
<author>Mohammad Alrifai</author>
<author>Eelco Herder</author>
</authors>
<title>Timeline summarization from relevent headlines.</title>
<date>2015</date>
<booktitle>In Proceedings of ECIR’2015.</booktitle>
<contexts>
<context position="3760" citStr="Tran et al., 2015" startWordPosition="584" endWordPosition="587">ediate dates due to space constraints. The whole timeline includes 30 dates between 2011-01-25 and 2013-07-07. Though convenient for the reader, the manual creation of a timeline can take a long time even for experts. For example, the creator of the startup Timeline says that it initially took a multiperson team a full work day to create a single timeline.1 Therefore, automatic timeline summarization (TLS) has emerged as an NLP task in the past few years (Tran et al., 2013a; Kessler et al., 2012; Nguyen et al., 2014; Yan et al., 2011b; Yan et al., 2011a; Wang et al., 2012; Tran et al., 2013b; Tran et al., 2015). TLS has been divided into two subtasks: (i) ranking the dates between beginning 1http://www.niemanlab.org/2015/02/ timeline-is-providing-historicalcontext-to-the-news-but-is-there-abusiness-model-to-support-it/. 1598 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1598–1607, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and end of the timeline in order of importance, to achieve date selection and (ii) generating a good daily summary for</context>
<context position="8069" citStr="Tran et al., 2015" startWordPosition="1260" endWordPosition="1263">go, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et al., 2015), focus on the extraction of salient sentences or headlines for generating the textual content of timelines. They assume either that the dates are given in advance or they use simple measures such as burstiness (Chieu and Lee, 2004; Yan et al., 2011b) for date selection, where burstiness relies on the number of date mentions. Prior approaches dedicated specifically to date selection are Tran et al. (2013a) and Kessler et al. (2012).3 They use supervised machine learning methods that score dates independently of each other. Features are extracted from a corpus of event-related newspaper article</context>
<context position="21329" citStr="Tran et al., 2015" startWordPosition="3634" endWordPosition="3637"> 4.1 Ground Truth and Data Preprocessing Kessler et al. (2012) use 91 timelines from AFP as ground truth along with the AFP news corpus for feature extraction. However, their dataset is not publically available. In addition, although they consider a wide spread of events, each event is only represented by a single timeline from a single source, making that method somewhat vulnerable to journalism bias (as discussed by themselves in their paper). The data collected by us previously (Tran et al., 2013a) is publically available at http://l3s.de/˜gtran/timeline/ and has since been extended by us (Tran et al., 2015). Similar to Kessler et al. (2012), it contains ground truth timelines as well as a corpus of news articles covering each event. The dataset is suitable for our purpose because of the following reasons: (1) it is a heterogeneous dataset which contains news articles and expert timeline summaries from different news agencies. Thus, it is more likely to avoid the issue of bias. Also, each event is represented �xt(j) = αw W1(i, j) · Mij · xt−1(i) i∈L−j + α(1 − w) � W2(i, j) · Mij · xt−1(i) (10) i∈L−j + (1 − α)vj (αP )ik(αP )t−1 kj X= k X= k X &lt; k (αP)ik hence, lim t→∞ 1602 by more than one timelin</context>
</contexts>
<marker>Tran, Alrifai, Herder, 2015</marker>
<rawString>Giang Tran, Mohammad Alrifai, and Eelco Herder. 2015. Timeline summarization from relevent headlines. In Proceedings of ECIR’2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dingding Wang</author>
<author>Tao Li</author>
<author>Mitsunori Ogihara</author>
</authors>
<title>Generating pictorial storylines via minimum-weight connected dominating set approximation in multiview graphs.</title>
<date>2012</date>
<booktitle>In Proceedings ofAAAI’2012.</booktitle>
<contexts>
<context position="3720" citStr="Wang et al., 2012" startWordPosition="576" endWordPosition="579">ociated Press (AP). We leave out intermediate dates due to space constraints. The whole timeline includes 30 dates between 2011-01-25 and 2013-07-07. Though convenient for the reader, the manual creation of a timeline can take a long time even for experts. For example, the creator of the startup Timeline says that it initially took a multiperson team a full work day to create a single timeline.1 Therefore, automatic timeline summarization (TLS) has emerged as an NLP task in the past few years (Tran et al., 2013a; Kessler et al., 2012; Nguyen et al., 2014; Yan et al., 2011b; Yan et al., 2011a; Wang et al., 2012; Tran et al., 2013b; Tran et al., 2015). TLS has been divided into two subtasks: (i) ranking the dates between beginning 1http://www.niemanlab.org/2015/02/ timeline-is-providing-historicalcontext-to-the-news-but-is-there-abusiness-model-to-support-it/. 1598 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1598–1607, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and end of the timeline in order of importance, to achieve date selection and </context>
</contexts>
<marker>Wang, Li, Ogihara, 2012</marker>
<rawString>Dingding Wang, Tao Li, and Mitsunori Ogihara. 2012. Generating pictorial storylines via minimum-weight connected dominating set approximation in multiview graphs. In Proceedings ofAAAI’2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenpu Xing</author>
<author>Ali A Ghorbani</author>
</authors>
<title>Weighted pagerank algorithm.</title>
<date>2004</date>
<booktitle>In CNSR,</booktitle>
<pages>305--314</pages>
<contexts>
<context position="16964" citStr="Xing and Ghorbani, 2004" startWordPosition="2796" endWordPosition="2799">nfluential the edge di → dj is in the global context of the event. The normalization is done by scaling the range of value from [0, 1]. M is the stochastic transitional matrix. In our case, I(i, j) can be just the value of freq(di, dj), Itopical(di, dj) , Itemporal(di, dj) alone or a linear combination of them. Note that, (I · M) in most case is not stochastic and must not be transformed into a stochastic transitional matrix, as the transformation will collapse the global context of I. IRW is different to PageRank on weighted graph, weighted or personalized PageRank and their variations e.g, (Xing and Ghorbani, 2004; Haveliwala, 2002), among others. In particular, weighted PageRank integrates influence scores into the stochastic transitional matrix. Thus, the random walker contributes the voting impact of a node X to its neighbor with an influence score normalized by the sum of scores on all outgoing connections. That process leverages how good this connection is in the sub-graph (G*) which consists of X and its outgoing neighbors. In contrast, our proposed model uses the non-normalized value of the influence score to leverage how good this connection is on the entire graph instead of G*. To give an exam</context>
</contexts>
<marker>Xing, Ghorbani, 2004</marker>
<rawString>Wenpu Xing and Ali A. Ghorbani. 2004. Weighted pagerank algorithm. In CNSR, pages 305–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Jian-Yun Nie</author>
<author>Xiaoming Li</author>
</authors>
<title>Summarize what you are interested in: An optimization framework for interactive personalized summarization.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP’11.</booktitle>
<contexts>
<context position="3681" citStr="Yan et al., 2011" startWordPosition="568" endWordPosition="571"> Egypt revolution published by the Associated Press (AP). We leave out intermediate dates due to space constraints. The whole timeline includes 30 dates between 2011-01-25 and 2013-07-07. Though convenient for the reader, the manual creation of a timeline can take a long time even for experts. For example, the creator of the startup Timeline says that it initially took a multiperson team a full work day to create a single timeline.1 Therefore, automatic timeline summarization (TLS) has emerged as an NLP task in the past few years (Tran et al., 2013a; Kessler et al., 2012; Nguyen et al., 2014; Yan et al., 2011b; Yan et al., 2011a; Wang et al., 2012; Tran et al., 2013b; Tran et al., 2015). TLS has been divided into two subtasks: (i) ranking the dates between beginning 1http://www.niemanlab.org/2015/02/ timeline-is-providing-historicalcontext-to-the-news-but-is-there-abusiness-model-to-support-it/. 1598 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1598–1607, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and end of the timeline in order of imp</context>
<context position="7907" citStr="Yan et al., 2011" startWordPosition="1231" endWordPosition="1234">te, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et al., 2015), focus on the extraction of salient sentences or headlines for generating the textual content of timelines. They assume either that the dates are given in advance or they use simple measures such as burstiness (Chieu and Lee, 2004; Yan et al., 2011b) for date selection, where burstiness relies on the number of date mentions. Prior approaches dedicated specifically to date selection are Tran et al. (2013a) and Kessler et al. (2012).3 </context>
<context position="26200" citStr="Yan et al. (2011" startWordPosition="4484" endWordPosition="4487">e top k dates during the input time range. We evaluate the systems by Mean Average Precision at k (MAP@k) for k = 5, 10, 15, 20 over all four events. 4.3 Systems. Baseline. We use three unsupervised baselines. The baseline Document Frequency ranks dates according to the number of news articles published on that date. Our assumption is that on a date where one or more important events happened, there would be a spread of information over different news agencies in the world. Therefore, this date has more news articles published. This baseline is related to the burstiness date selection used by Yan et al. (2011b). The baseline MaxLength ranks dates by the maximum article length of all articles published on that date. Our hypothesis is that important events 7Prior work also uses start and end date of timelines for delimiting input (Kessler et al., 2012; Tran et al., 2013a). 1603 Story #TL #atLeastOnce #atLeastTwice avgL maxL minL Time Range #dates Egypt 4 122 18 36 57 24 2011/01/01 - 2013/07/07 918 Libya 7 118 56 34 62 22 2011/02/14 - 2011/11/22 281 Syria 5 106 17 60 26 13 2011/03/15 - 2013/07/06 844 Yemen 5 81 26 24 42 10 2011/01/22 - 2012/02/27 401 Number of timelines (#TL), number of dates occurri</context>
</contexts>
<marker>Yan, Nie, Li, 2011</marker>
<rawString>Rui Yan, Jian-Yun Nie, and Xiaoming Li. 2011a. Summarize what you are interested in: An optimization framework for interactive personalized summarization. In Proceedings of EMNLP’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Xiaojun Wan</author>
<author>Jahna Otterbacher</author>
<author>Liang Kong</author>
<author>Xiaoming Li</author>
<author>Yan Zhang</author>
</authors>
<title>Evolutionary timeline summarization: a balanced optimization framework via iterative substitution.</title>
<date>2011</date>
<booktitle>In Proceedings of SIGIR’11,</booktitle>
<pages>745--754</pages>
<contexts>
<context position="3681" citStr="Yan et al., 2011" startWordPosition="568" endWordPosition="571"> Egypt revolution published by the Associated Press (AP). We leave out intermediate dates due to space constraints. The whole timeline includes 30 dates between 2011-01-25 and 2013-07-07. Though convenient for the reader, the manual creation of a timeline can take a long time even for experts. For example, the creator of the startup Timeline says that it initially took a multiperson team a full work day to create a single timeline.1 Therefore, automatic timeline summarization (TLS) has emerged as an NLP task in the past few years (Tran et al., 2013a; Kessler et al., 2012; Nguyen et al., 2014; Yan et al., 2011b; Yan et al., 2011a; Wang et al., 2012; Tran et al., 2013b; Tran et al., 2015). TLS has been divided into two subtasks: (i) ranking the dates between beginning 1http://www.niemanlab.org/2015/02/ timeline-is-providing-historicalcontext-to-the-news-but-is-there-abusiness-model-to-support-it/. 1598 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1598–1607, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics and end of the timeline in order of imp</context>
<context position="7907" citStr="Yan et al., 2011" startWordPosition="1231" endWordPosition="1234">te, timelines can be generated by MDS systems (such as (Radev et al., 2004b; Radev et al., 2004a; McKeown et al., 2003; Erkan and Radev, 2004; Metzler and Kanungo, 2008; Hong and Nenkova, 2014) by applying their summarization techniques on news articles for every individual date to create corresponding daily summaries. However, manually written timelines normally only include a small number of dates; in addition, the temporal component imposes constraints on sentence selection for timeline summarization, such as the preference for little overlap between sentences selected for different dates (Yan et al., 2011b). Many studies specific to timeline summarization, such as (Swan and Allan, 2000; Allan et al., 2001; Chieu and Lee, 2004; Yan et al., 2011b; Tran et al., 2015), focus on the extraction of salient sentences or headlines for generating the textual content of timelines. They assume either that the dates are given in advance or they use simple measures such as burstiness (Chieu and Lee, 2004; Yan et al., 2011b) for date selection, where burstiness relies on the number of date mentions. Prior approaches dedicated specifically to date selection are Tran et al. (2013a) and Kessler et al. (2012).3 </context>
<context position="26200" citStr="Yan et al. (2011" startWordPosition="4484" endWordPosition="4487">e top k dates during the input time range. We evaluate the systems by Mean Average Precision at k (MAP@k) for k = 5, 10, 15, 20 over all four events. 4.3 Systems. Baseline. We use three unsupervised baselines. The baseline Document Frequency ranks dates according to the number of news articles published on that date. Our assumption is that on a date where one or more important events happened, there would be a spread of information over different news agencies in the world. Therefore, this date has more news articles published. This baseline is related to the burstiness date selection used by Yan et al. (2011b). The baseline MaxLength ranks dates by the maximum article length of all articles published on that date. Our hypothesis is that important events 7Prior work also uses start and end date of timelines for delimiting input (Kessler et al., 2012; Tran et al., 2013a). 1603 Story #TL #atLeastOnce #atLeastTwice avgL maxL minL Time Range #dates Egypt 4 122 18 36 57 24 2011/01/01 - 2013/07/07 918 Libya 7 118 56 34 62 22 2011/02/14 - 2011/11/22 281 Syria 5 106 17 60 26 13 2011/03/15 - 2013/07/06 844 Yemen 5 81 26 24 42 10 2011/01/22 - 2012/02/27 401 Number of timelines (#TL), number of dates occurri</context>
</contexts>
<marker>Yan, Wan, Otterbacher, Kong, Li, Zhang, 2011</marker>
<rawString>Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong, Xiaoming Li, and Yan Zhang. 2011b. Evolutionary timeline summarization: a balanced optimization framework via iterative substitution. In Proceedings of SIGIR’11, pages 745–754.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>