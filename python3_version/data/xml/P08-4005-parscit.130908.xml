<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.239156">
<title confidence="0.987934">
Interactive ASR Error Correction for Touchscreen Devices
</title>
<author confidence="0.993549">
David Huggins-Daines
</author>
<affiliation confidence="0.875100666666667">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998423">
dhuggins@cs.cmu.edu
</email>
<author confidence="0.975732">
Alexander I. Rudnicky
</author>
<affiliation confidence="0.871193333333333">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998785">
air@cs.cmu.edu
</email>
<sectionHeader confidence="0.993898" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999920545454545">
We will demonstrate a novel graphical inter-
face for correcting search errors in the out-
put of a speech recognizer. This interface
allows the user to visualize the word lattice
by “pulling apart” regions of the hypothesis
to reveal a cloud of words simlar to the “tag
clouds” popular in many Web applications.
This interface is potentially useful for dicta-
tion on portable touchscreen devices such as
the Nokia N800 and other mobile Internet de-
vices.
</bodyText>
<sectionHeader confidence="0.997656" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999921611111111">
For most people, dictating continuous speech is con-
siderably faster than entering text using a keyboard
or other manual input device. This is particularly
true on mobile devices which typically have no hard-
ware keyboard whatsoever, a 12-digit keypad, or at
best a miniaturized keyboard unsuitable for touch
typing.
However, the effective speed of text input using
speech is significantly reduced by the fact that even
the best speech recognition systems make errors.
After accounting for error correction, the effective
number of words per minute attainable with speech
recognition drops to within the range attainable by
an average typist (Moore, 2004). Moreover, on a
mobile phone with predictive text entry, it has been
shown that isolated word dictation is actually slower
than using a 12-digit keypad for typing SMS mes-
sages (Karpov et al., 2006).
</bodyText>
<sectionHeader confidence="0.99285" genericHeader="introduction">
2 Description
</sectionHeader>
<bodyText confidence="0.999861">
It has been shown that multimodal error correction
methods are much more effective than using speech
</bodyText>
<page confidence="0.950257">
17
</page>
<bodyText confidence="0.999640333333333">
alone (Lewis, 1999). Mobile devices are increas-
ingly being equipped with touchscreens which lend
themselves to gesture-based interaction methods.
Therefore, we propose an interactive method of
visualizing and browsing the word lattice using ges-
tures in order to correct speech recognition errors.
The user is presented with the decoding result in a
large font, either in a window on the desktop, or in a
full-screen presentation on a touchscreen device. If
the utterance is too long to fit on the screen, the user
can scroll left and right using touch gestures. The
initial interface is shown in Figure 1.
</bodyText>
<figureCaption confidence="0.99691">
Figure 1: Initial hypothesis view
</figureCaption>
<bodyText confidence="0.999964818181818">
Where there is an error, the user can “pull apart”
the result using a touch stroke (or a multitouch ges-
ture where supported), revealing a “cloud” of hy-
pothesis words at that point in the utterance, as
shown in Figure 2.
It is also possible to expand the time interval over
which the cloud is calculated by dragging sideways,
resulting in a view like that in Figure 3. The user
can then select zero or more words to add to the hy-
pothesis string in place of the errorful text which was
“exploded”, as shown in Figure 4.
</bodyText>
<note confidence="0.8557505">
Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 17–19,
Columbus, June 2008. c�2008 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9999825">
Figure 2: Expanded word view
Figure 3: Word cloud expanded in time
</figureCaption>
<bodyText confidence="0.999938571428572">
The word cloud is constructed by finding all
words active within a time interval whose log poste-
rior probability falls within range of the most prob-
able word. Word posterior probabilities are cal-
culated using the forward-backward algorithm de-
scribed in (Wessel et al., 1998). Specifically, given a
word lattice in the form of a directed acyclic graph,
whose nodes represent unique starting points t in
time, and whose edges represent the acoustic likeli-
hoods of word hypotheses wt s spanning a given time
interval (s, t), we can calculate the forward variable
αt(w), which represents the joint probability of all
word sequences ending in wt s and the acoustic ob-
servations up to time t, as:
</bodyText>
<equation confidence="0.9913775">
�αt(w) = P(Os1,wts) = P(w|v)P(wts)αs(v)
vgEprev(w)
</equation>
<bodyText confidence="0.9960696">
Here, P(w|v) is the bigram probability of (v, w)
obtained from the language model and P(wts) is the
acoustic likelihood of the word model w given the
observed speech from time s to t, as approximated
by the Viterbi path score.
</bodyText>
<figureCaption confidence="0.99859">
Figure 4: Selecting replacement words
</figureCaption>
<bodyText confidence="0.9996692">
Likewise, we can compute the backward variable
Qt(w), which represents the conditional probabil-
ity of all word sequences beginning in wt s and the
acoustic observations from time t + 1 to the end of
the utterance, given wts:
</bodyText>
<equation confidence="0.9917995">
Qt(w) = P(OTt |wts) = � P(v|w)P(ve t )Qe(v)
vt Esucc(w)
</equation>
<bodyText confidence="0.944325">
The posterior probability P(wt s|OT1 ) can then be
obtained by multiplication and normalization:
</bodyText>
<equation confidence="0.9872462">
1 )
P(wt s|OT 1 ) = P(wt s, OT
P(OT1 )
αt(w)Qt(w)
P(OT1 )
</equation>
<bodyText confidence="0.997278785714286">
This algorithm has a straightforward extension to
trigram language models which has been omitted
here for simplicity.
This interface is inspired by the web browser
zooming interface used on the Apple iPhone (Ap-
ple, Inc., 2008), as well as the Speech Dasher
lattice correction tool (Vertanen, 2004). We feel
that it is potentially useful not only for auto-
matic speech recognition, but also for machine
translation and any other situation in which
a lattice representation of a possibly errorful
hypothesis is available. A video of this in-
terface in Ogg Theora format1 can be viewed at
http://www.cs.cmu.edu/˜dhuggins/touchcorrect.ogg.
</bodyText>
<footnote confidence="0.9997615">
1For Mac OS X: http://xiph.org/quicktime/download.html
For Windows: http://www.illiminable.com/ogg/downloads.html
</footnote>
<page confidence="0.998683">
18
</page>
<sectionHeader confidence="0.959652" genericHeader="method">
3 Script Outline
</sectionHeader>
<bodyText confidence="0.9998821">
For our demonstration, we will have available
a poster describing the interaction method being
demonstrated. We will begin by describing the mo-
tivation for this work, followed by a “silent” demo
of the correction method itself, using pre-recorded
audio. We will then demonstrate live speech input
and correction using our own voices. The audience
will then be invited to test the interaction method on
a touchscreen device (either a handheld computer or
a tablet PC).
</bodyText>
<sectionHeader confidence="0.999591" genericHeader="conclusions">
4 Requirements
</sectionHeader>
<bodyText confidence="0.9999302">
To present this demo, we will be bringing two Nokia
Internet Tablets as well as a laptop and possibly a
Tablet PC. We have no requirements from the con-
ference organizers aside from a suitable number of
power outlets, a table, and a poster board.
</bodyText>
<sectionHeader confidence="0.994728" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999735">
We wish to thank Nokia for donating an N800 Inter-
net Tablet used to develop this software.
</bodyText>
<sectionHeader confidence="0.99796" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998605">
E. Karpov, I. Kiss, J. Lepp¨anen, J. Olsen, D. Oria, S.
Sivadas and J. Tian 2006. Short Message Sys-
tem dictation on Series 60 mobile phones. Work-
shop on Speech in Mobile and Pervasive Environ-
ments (SiMPE) in Conjunction with MobileHCI 2006.
Helsinki, Finland.
Keith Vertanen 2004. Efficient Computer Interfaces
Using Continuous Gestures, Language Models, and
Speech. M.Phil Thesis, University of Cambridge,
Cambridge, UK.
Apple, Inc. 2008. iPhone: Zoom-
ing In to Enlarge Part of a Webpage.
http://docs.info.apple.com/article.html?artnum=305899
Roger K. Moore 2004. Modelling Data Entry Rates for
ASR and Alternative Input Methods. Proceedings of
Interspeech 2004. Jeju, Korea.
James R. Lewis 1999. Effect of Error Correction Strat-
egy on Speech Dictation Throughput Proceedings of
the Human Factors and Ergonomics Society 43rd An-
nual Meeting.
Frank Wessel, Klaus Macherey, Ralf Schl¨uter 1998. Us-
ing Word Probabilities as Confidence Measures. Pro-
ceedings of ICASSP 1998.
</reference>
<page confidence="0.999333">
19
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.716967">
<title confidence="0.999989">Interactive ASR Error Correction for Touchscreen Devices</title>
<author confidence="0.999201">David Huggins-Daines</author>
<affiliation confidence="0.9943985">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.99895">Pittsburgh, PA 15213, USA</address>
<email confidence="0.999797">dhuggins@cs.cmu.edu</email>
<author confidence="0.999818">Alexander I Rudnicky</author>
<affiliation confidence="0.9986125">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.998144">Pittsburgh, PA 15213, USA</address>
<email confidence="0.999691">air@cs.cmu.edu</email>
<abstract confidence="0.969119583333333">We will demonstrate a novel graphical interface for correcting search errors in the output of a speech recognizer. This interface allows the user to visualize the word lattice by “pulling apart” regions of the hypothesis to reveal a cloud of words simlar to the “tag clouds” popular in many Web applications. This interface is potentially useful for dictation on portable touchscreen devices such as the Nokia N800 and other mobile Internet devices.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Karpov</author>
<author>I Kiss</author>
<author>J Lepp¨anen</author>
<author>J Olsen</author>
<author>D Oria</author>
<author>S Sivadas</author>
<author>J Tian</author>
</authors>
<date>2006</date>
<booktitle>Short Message System dictation on Series 60 mobile phones. Workshop on Speech in Mobile and Pervasive Environments (SiMPE) in Conjunction with MobileHCI</booktitle>
<location>Helsinki, Finland.</location>
<marker>Karpov, Kiss, Lepp¨anen, Olsen, Oria, Sivadas, Tian, 2006</marker>
<rawString>E. Karpov, I. Kiss, J. Lepp¨anen, J. Olsen, D. Oria, S. Sivadas and J. Tian 2006. Short Message System dictation on Series 60 mobile phones. Workshop on Speech in Mobile and Pervasive Environments (SiMPE) in Conjunction with MobileHCI 2006. Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Vertanen</author>
</authors>
<title>Efficient Computer Interfaces Using Continuous Gestures, Language Models, and Speech. M.Phil Thesis,</title>
<date>2004</date>
<institution>University of Cambridge,</institution>
<location>Cambridge, UK.</location>
<contexts>
<context position="4862" citStr="Vertanen, 2004" startWordPosition="793" endWordPosition="794">es beginning in wt s and the acoustic observations from time t + 1 to the end of the utterance, given wts: Qt(w) = P(OTt |wts) = � P(v|w)P(ve t )Qe(v) vt Esucc(w) The posterior probability P(wt s|OT1 ) can then be obtained by multiplication and normalization: 1 ) P(wt s|OT 1 ) = P(wt s, OT P(OT1 ) αt(w)Qt(w) P(OT1 ) This algorithm has a straightforward extension to trigram language models which has been omitted here for simplicity. This interface is inspired by the web browser zooming interface used on the Apple iPhone (Apple, Inc., 2008), as well as the Speech Dasher lattice correction tool (Vertanen, 2004). We feel that it is potentially useful not only for automatic speech recognition, but also for machine translation and any other situation in which a lattice representation of a possibly errorful hypothesis is available. A video of this interface in Ogg Theora format1 can be viewed at http://www.cs.cmu.edu/˜dhuggins/touchcorrect.ogg. 1For Mac OS X: http://xiph.org/quicktime/download.html For Windows: http://www.illiminable.com/ogg/downloads.html 18 3 Script Outline For our demonstration, we will have available a poster describing the interaction method being demonstrated. We will begin by des</context>
</contexts>
<marker>Vertanen, 2004</marker>
<rawString>Keith Vertanen 2004. Efficient Computer Interfaces Using Continuous Gestures, Language Models, and Speech. M.Phil Thesis, University of Cambridge, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inc Apple</author>
</authors>
<title>iPhone: Zooming In to Enlarge Part of a Webpage.</title>
<date>2008</date>
<note>http://docs.info.apple.com/article.html?artnum=305899</note>
<marker>Apple, 2008</marker>
<rawString>Apple, Inc. 2008. iPhone: Zooming In to Enlarge Part of a Webpage. http://docs.info.apple.com/article.html?artnum=305899</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger K Moore</author>
</authors>
<title>Modelling Data Entry Rates for ASR and Alternative Input Methods.</title>
<date>2004</date>
<booktitle>Proceedings of Interspeech</booktitle>
<location>Jeju,</location>
<contexts>
<context position="1432" citStr="Moore, 2004" startWordPosition="212" endWordPosition="213">ech is considerably faster than entering text using a keyboard or other manual input device. This is particularly true on mobile devices which typically have no hardware keyboard whatsoever, a 12-digit keypad, or at best a miniaturized keyboard unsuitable for touch typing. However, the effective speed of text input using speech is significantly reduced by the fact that even the best speech recognition systems make errors. After accounting for error correction, the effective number of words per minute attainable with speech recognition drops to within the range attainable by an average typist (Moore, 2004). Moreover, on a mobile phone with predictive text entry, it has been shown that isolated word dictation is actually slower than using a 12-digit keypad for typing SMS messages (Karpov et al., 2006). 2 Description It has been shown that multimodal error correction methods are much more effective than using speech 17 alone (Lewis, 1999). Mobile devices are increasingly being equipped with touchscreens which lend themselves to gesture-based interaction methods. Therefore, we propose an interactive method of visualizing and browsing the word lattice using gestures in order to correct speech recog</context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Roger K. Moore 2004. Modelling Data Entry Rates for ASR and Alternative Input Methods. Proceedings of Interspeech 2004. Jeju, Korea.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R James</author>
</authors>
<title>Lewis 1999. Effect of Error Correction Strategy on Speech Dictation Throughput</title>
<booktitle>Proceedings of the Human Factors and Ergonomics Society 43rd Annual Meeting.</booktitle>
<marker>James, </marker>
<rawString>James R. Lewis 1999. Effect of Error Correction Strategy on Speech Dictation Throughput Proceedings of the Human Factors and Ergonomics Society 43rd Annual Meeting.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Wessel</author>
<author>Klaus Macherey</author>
<author>Ralf Schl¨uter</author>
</authors>
<title>Using Word Probabilities as Confidence Measures.</title>
<date>1998</date>
<booktitle>Proceedings of ICASSP</booktitle>
<marker>Wessel, Macherey, Schl¨uter, 1998</marker>
<rawString>Frank Wessel, Klaus Macherey, Ralf Schl¨uter 1998. Using Word Probabilities as Confidence Measures. Proceedings of ICASSP 1998.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>