<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.063856">
<title confidence="0.973433">
Distributed dialogue management in a blackboard architecture
</title>
<author confidence="0.993801">
Antti Kerminen Kristiina Jokinen
</author>
<affiliation confidence="0.994455">
University of Art and Design Helsinki University of Helsinki*
</affiliation>
<email confidence="0.98143">
fakerminel@uiah.fi fkristiina.jokinenj@helsinki.fi
</email>
<sectionHeader confidence="0.997136" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999644">
This paper describes a distributed dia-
logue management scheme for speech-
based information seeking dialogue.
The dialogue management is distributed
to several components, supported by a
general blackboard-type architecture for
speech systems. By breaking down the
dialogue management, we can achieve
more general solutions and support so-
phisticated decision making algorithms.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994955983050848">
The main questions in dialogue system design are:
&amp;quot;what should the system do?&amp;quot; and &amp;quot;how should
the system do what it is meant to do?&amp;quot; The an-
swer is affected by the task complexity and the
desired dialogue functionalities, and also by the
architectural design: there is a wide variety of dia-
logue models that describe processing of the di-
alogue information on the conceptual level, but
there is also a need for generic development plat-
forms that would support experimenting with var-
ious architectures and techniques, and would also
allow easy extensibility to new functionalities re-
quired by new tasks and applications.
As described e.g. in Bernsen et al. (1998), the
logical structure of dialogue management contains
input analysis (speech recognition and linguistic
analysis), dialogue handling, and output genera-
tion (natural language generation and speech syn-
thesis). Consequently, spoken dialogue systems
have pi pel i ned architectures where the decision
The research was done while the author was working at
the University of Art and Design Helsinki.
making is based on the logical order of the in-
formation flow, and dialogue handling is imple-
mented as a single dialogue management compo-
nent with the task of making decisions of what the
system should do next in a particular context.
Three different ways for handling interaction
can be distinguished, based on the modelling tech-
niques used for task and dialogue information.
The most straightforward way is to use scripts
that combine the two types of information under
the same plan. Scripts define actions at each dia-
logue point and can be best used in simple control-
ling tasks, such as banking and financial services,
which require only limited dialogue capabilities
that do not go beyond the actual task requirements.
Scripts can be written using scripting languages
like VoiceXML (VoiceXML Forum, 2003), and
including subroutines, it is possible to produce
fairly complicated dialogues that contain embed-
ded subdialogues. However, the tight coupling
of task and dialogue knowledge does not support
natural interaction, and the writing of scripts can
be rather time-consuming since all possible action
patterns must be explicitly enlisted and described.
Also user actions which do not exactly match the
responses that the system prompts presuppose, are
problematic: elaborate error-handling subroutines
are required for each particular case.
A more flexible approach is to separate the do-
main and dialogue information, and to use forms
or frames which define the knowledge necessary
to complete the underlying task. The dialogue is
thus driven by the information needed, and the in-
teraction appears more natural as the actions can
be executed in various orders which are more suit-
able for individual users (cf. e.g. the question-
under-discussion approach implemented in (Lars-
</bodyText>
<page confidence="0.997668">
53
</page>
<bodyText confidence="0.999801541666667">
son et al., 2001)). For instance, tasks like hotel
reservations and flight information providing ser-
vices contain pieces of knowledge which can be
communicated in various orders and combinations
between the partners, and thus they do not eas-
ily lend themselves to any fixed dialogue mod-
elling. The form also provides a dialogue con-
text in which the actions can be interpreted and
planned so as to allow more varied system utter-
ances. Early dialogue research concerned plan-
based and BDI-systems (e.g. (Cohen et al., 1990;
Jennings, 1993), and references therein), and also
emphasized the separation of static task knowl-
edge from the processing knowledge, although
the mechanisms for both knowledge representa-
tion and reasoning were usually too heavy and
complicated for practical dialogue systems.
To enable truly natural interaction, it is neces-
sary to equip the system with knowledge about
the task and application as well as with dialogue
capabilities. The aim of conversational dialogue
management is to improve human-computer inter-
action by taking human conversational capabilities
into account (both verbal and non-verbal commu-
nication) and by building models for their com-
putational treatment. It also calls for the devel-
opment in computational technology, and various
statistical and machine-learning techniques have
been applied to model conversational phenomena.
Research has focussed on modelling such issues
as the speakers&apos;s intentions (dialogue acts), topic
tracking, response planning, cooperation (ground-
ing), and spoken language errors, but more re-
search is still needed to reach a better understand-
ing of the mechanisms behind conversational phe-
nomena, as well as to evaluate which parts of dia-
logue management will benefit most from the re-
sults obtained through the new models. On the
other hand, conversational dialogue management
can be operationalised by dividing the interaction
task into different processing tasks and actions
which can be implemented as separate independet
procedurs of the whole system, operate asynchro-
niously, and combine to produce the desired func-
tionality.
Agent-based architectures have thus been intro-
duced with the main benefit being that of flexibil-
ity in regard to functioning of the system compo-
nents (Seneff et al., 1999; Rudnicky et al., 1999;
Baylock et al., 2002; Jokinen et al., 2002). While
not necessary being committed to conversational
dialogue management, agent-based architectures
support simultaneous processing of dialogue in-
formation by allowing asynchronicity, which pro-
vides freedom from a tight pipeline processing and
also speeds up the system as e.g. input analy-
sis and output generation can function simultane-
ously. In practice, however, agent-based archi-
tectures usually have general control mechanisms
that constrain the components to follow the logical
structure of the information flow.
In this paper, we discuss these aspects and
present a system with distributed dialogue man-
agement, where decision making does not mani-
fest itself as a single block, but is distributed over
the whole system. We also suggest that this kind of
dialogue management provides a useful basis for
building prototypes and experimenting with learn-
ing techniques presupposed by the more demand-
ing dialogue tasks of conversational dialogue man-
agement. In concrete terms, the distribute dialogue
management refers to
</bodyText>
<listItem confidence="0.979368714285714">
• interleaving input and output processing with
dialogue management
• specifying task management as a separate
level of information processing
• introducing special dialogue agents and eval-
uators as the tools to implement dialogue
management.
</listItem>
<bodyText confidence="0.9999445">
The paper is organised as follows. Section 2
gives a short overview of the Jaspis framework that
the Interact system is built on. Section 3 presents
the concept of distributed dialogue management,
and its implementation in our system. Section 4
motivates distributed dialogue management from
the perspective of learning and adaptivity. Finally,
section 5 provides summary and discussion.
</bodyText>
<sectionHeader confidence="0.946346" genericHeader="method">
2 Jaspis framework
</sectionHeader>
<bodyText confidence="0.9998975">
The Interact system is built on top of the Jaspis
framework developed by Turunen and Hakulinen
(2001). Jaspis is a general blackboard-type ar-
chitecture for speech-based applications. The two
</bodyText>
<page confidence="0.996974">
54
</page>
<bodyText confidence="0.998697833333333">
key features of the architecture are the shared in-
formation storage, and the concept of managers,
agents and evaluators. The overall architecture, as
demostrated in our system, is depicted in Figure 1.
Jaspis can be called an agent-based architecture
but the naming of system components can be a
little confusing. Especially &amp;quot;agent&amp;quot; in Jaspis is
somewhat different from the usual meaning of an
autonomous, intelligent agent: it refers to the ac-
tions available for a manager. Table 1 gives rough
correspondents of Jaspis components and tradi-
tional terms of agent architectures.
</bodyText>
<tableCaption confidence="0.679553">
Table 1: Correspondence of names in Jaspis and
traditional agent architectures.
</tableCaption>
<bodyText confidence="0.991646419354839">
All information in Jaspis is stored in the Infor-
mation Storage, which is accessible by all compo-
nents in the system. Thus, any component can use
any information in the system. For example, the
dialogue history is accessible by all components
and is used e.g. by input agents to analyze the in-
put at the discourse level.
The shared information storage in Jaspis com-
pares to the hub or facilitator of some common
agent-based architectures, like the CMU Com-
municator (Rudnicky et al., 1999), GALAXY-II
(Seneff et al., 1999), and TRAINS (Baylock et
al., 2002). However, the CMU Communicator,
GALAXY-II, and TRAINS allow asynchronous
execution of all system components, while in
Jaspis the only place for asynchronicity is the
Communication Manager, which can handle mul-
tiple parallel requests for input/output devices.
The other managers cannot run asynchronously
but they follow the logical order of informa-
tion flow. The lack of parallel manager execu-
tion makes it difficult to implement grounding or
barge-in functionality. On the other hand, within
each manager the agents operate independently to
the extend of producing scores for how well their
functioning fits in a particular system state.
The concept of managers, agents and evaluators
is explained in more detail in the following three
sections. More information about implementing
dialogue management in the Jaspis framework can
be found in (Turunen and Hakulinen, 2001).
</bodyText>
<subsectionHeader confidence="0.972423">
2.1 Managers
</subsectionHeader>
<bodyText confidence="0.9999675">
Jaspis has three main managers by default: the
Communication Manager, the Dialogue Manager,
and the Presentation Manager. The Communi-
cation Manager gives a high level abstraction of
input/output devices and handles communication
between the user and the computer. The Dialogue
Manager decides the next system action, and the
Presentation Manager realizes the semantic rep-
resentation of the next system turn as a text and
passes it to the output device (speech synthesis,
screen). The program flow is controlled by the
Interaction Manager, which gives the turn to the
managers in a round-robin manner. The managers
themselves are responsible for determining if they
are capable of doing something in the present sit-
uation.
</bodyText>
<subsectionHeader confidence="0.995096">
2.2 Agents
</subsectionHeader>
<bodyText confidence="0.9995902">
As already explained, agents in Jaspis are not
agents in the sense that they would be autonomous
or intelligent. Rather, they represent the actions
available for a manager. Every agent knows how
well it is suited for the current situation.
</bodyText>
<subsectionHeader confidence="0.987228">
2.3 Evaluators
</subsectionHeader>
<bodyText confidence="0.9999958">
The evaluators choose the best agent to handle the
manager&apos;s turn in the program flow. Coordination
of the evaluation process is done by the managers.
The evaluators evaluate agents by giving a score
for each agent. The score can be based on the
agent&apos;s own opinion, or the evaluator can evalu-
ate agents with its own criteria. Scores from all
evaluators are multiplied and this forms the total
score for the agent. The agent with a highest score
is selected as the action of the manager.
</bodyText>
<subsectionHeader confidence="0.962786">
2.4 Devices
</subsectionHeader>
<bodyText confidence="0.99987225">
Devices are high level abstractions of concrete in-
put/output devices. Below this abstract level there
are clients, servers, and engines implementing the
actual functionality of the device.
</bodyText>
<figure confidence="0.989786714285714">
Jaspis
Agent architecture
manager
evaluator
agent
agent
action
55
Interaction Manager
Presentation Manager
Presentation Evaluators
Presentation Agents
Dialogue Manager
Dialgoue Evaluators
Dialogue Agents
Communication Manager
Input Evaluators
Input Agents
Devices
Access information
Shared Information Storage
</figure>
<figureCaption confidence="0.999997">
Figure 1: The Jaspis architecture as demonstrated in the Interact system.
</figureCaption>
<bodyText confidence="0.999977857142857">
An example of a device would be the speech
recognizer. The application interacts with an ab-
stract device, and the implementation consists of
an client, a server, and an engine for a particular
speech recognizer. The Interact system has multi-
modal input/output capabilities and it also accepts
text and touch-screen input and video output.
</bodyText>
<sectionHeader confidence="0.999216" genericHeader="method">
3 Distributed dialogue management
</sectionHeader>
<bodyText confidence="0.99993062962963">
We have built a timetable service as the Inter-
act demonstration system. The system is capa-
ble of answering questions about connections be-
tween two places, arrival and departure times, and
arrival and departure places. The system supp-
ports mixed-initiative dialogues: by default the
user has the initiative, but the system enters mixed-
initiative mode if the user fails communicate his
goals to the system. The general overview of the
demostration system is given in (Jokinen et al.,
2002).
Unlike the traditional approaches, the dialogue
management components are distributed across
various managers. The discourse and dialogue
level analysis is implemented in the Communica-
tion Manager which has a set of input agents and
input evaluators to analyze inputs. Input agents
in the Communication Manager differ from the
agents in the other managers in that they repre-
sent different levels of input analysis. Input agents
are executed in order, and input evaluators decide
when the analysis in complete. The generation
of system responses is implemented as presenta-
tion agents in the Presentation Manager. The Task
Manager takes care of the task related information,
while the decision of what to say next is made in
the Dialogue Manager.
</bodyText>
<subsectionHeader confidence="0.959097">
3.1 Constructive Dialogue Model
</subsectionHeader>
<bodyText confidence="0.99999195">
Our dialogue model follows the Constructive Di-
algue Model (Jokinen, 1996), based on the com-
municative principles of rational and coordinated
interaction (Allwood, 1997; Allwood et al., 2000).
The speakers act by exchanging new informa-
tion and constructing a shared context in which
to achieve the underlying goal (in our case this is
to provide information from a database, but it can
also be a general interactional goal such as &amp;quot;keep
the channel open&amp;quot;). The speakers are engaged in
a cooperative activity and their actions are con-
strained by communicative obligations. The em-
phasis on the principles of ideal co-operation dis-
tinguishes our approach from the related work
in multiagent systems such as (Gmytrasiewicz
and Durfee, 2001) which deals with rationality in
decision-theoretic framework, and views commu-
nication as a decision process whereby the agent
selects acts with the highest expected utility. Al-
though acting may be selected on the basis of cost
</bodyText>
<page confidence="0.984964">
56
</page>
<bodyText confidence="0.997835782608696">
and benefit, communication brings in such aspects
as trust, obligations and social commitments, the
influence of which in dialogue decisions may be
difficult to model solely in these terms in practise.
The speakers continue their interaction, and
proceed by taking turns to specify, clarify and
elaborate the information exchanged as long as the
goal is valid, i.e. not yet achieved or abandoned.
Each action results in a new dialogue state which
is characterized by the agent&apos;s perception of the
context: the Dialogue Act Dact, New Informa-
tion NewInfo and the Topic Top of the last utter-
ance, the unfulfilled task goals TGoals, expecta-
tions, Expect are related to communicative obli-
gations, and used to constrain possible interpre-
tations of the next act, and the last speaker. The
system&apos;s internal states are thus reduced to a com-
bination of these categories, all of which form an
independent source of information for the system
to decide on the next move (Figure 2). The state
description also contains reinforcement values that
provide information of the goodness of the state in
the given context.
</bodyText>
<figureCaption confidence="0.784528333333333">
Figure 2: Dialogue states for the user utterance
and system action, together with dialogue-level
agents involved in producing various information.
</figureCaption>
<subsectionHeader confidence="0.981652">
3.2 Concepts
</subsectionHeader>
<bodyText confidence="0.999987272727273">
The dialogue management operates on a concept-
level representation of a user utterance (Figure 2).
The conceptual representation includes the dia-
logue act and the semantic content of the ut-
terance. The semantic content is a set of con-
cepts. Each concept is marked as either Topic or
NewInfo, depending on its status with respect to
the discourse context. NewInfo concepts encode
the information that is asked or presented to the
user, while the Topic concepts encode information
already available in the context.
</bodyText>
<subsectionHeader confidence="0.998746">
3.3 Input analysis
</subsectionHeader>
<bodyText confidence="0.999992">
The basic semantic content of the user&apos;s utterance
is given by the parser. Because the parser only
looks at the current utterance, it cannot provide in-
formation about ellipses or anaphoric references.
However, the discourse-level input agents com-
plete the semantic analysis of the parser by taking
into account the dialogue history. There are three
input agents in the discourse-level analysis: ellip-
sis resolution, anaphora resolution, and dialogue
act classification. The current system uses a sub-
set of the dialogue acts described in (Jokinen et
al., 2001) which presents dialogue act classifica-
tion based on machine-learning techniques.
In addition there are agents for merging inputs
from different input modalities and updating the
dialogue history in the information storage.
</bodyText>
<subsectionHeader confidence="0.928612">
3.4 Task management
</subsectionHeader>
<bodyText confidence="0.999992181818182">
The task management is separate and has its own
manager. The tasks of the Task Manager are to
make sure that the user has given all required in-
formation to complete a database query, execute
the complete query, and transfer the information
for further processing.
Because of the fairly simple application do-
main, task specific knowledge is represented as a
form with a slot for each concept the system is ca-
pable of talking about. The Dialogue Manager and
Task Manager communicate with each other via
this particular task-form. If the form is filled in so
that a database query can be performed, the Task
Manager returns the form with all the appropriate
parameters filled in, and the Dialogue Manager de-
cides on the Topic/NewInfo status of the concepts
corresponding to the parameters and their values
with respect to the dialogue situation.
The Task Manager consists of three task agents.
The main agent or the DatabaseAgent takes care of
the normal access to the database. The two addi-
tional agents deal with special situations concern-
</bodyText>
<figure confidence="0.984926269230769">
Speaker
= system
Speaker
= user
Dact
Topic
NewInfo
TGoals
Dialogue • Dact
Model
rio tion
• Topic
Anaphora
resolution NewInfo
TGoals
Task
Agent
Task
Agent
Agents
System
action
Dialogue Agents
state
Expect
Expect
</figure>
<page confidence="0.995105">
57
</page>
<bodyText confidence="0.999303909090909">
ing the execution of a database query. The Cur-
sorAgent moves the cursor between pre-fetched
database items (e.g. when the user has asked
next/previous departure time), and the PlaceAgent
ensures that place names in the form are correct
and existent in order for a successful query to be
executed. The motivation for these two special
agents is to keep the main DatabaseAgent sim-
ple: by implementing special checks as separate
agents, the logic of the different tasks and subtasks
becomes clear.
</bodyText>
<subsectionHeader confidence="0.969103">
3.5 Dialogue management
</subsectionHeader>
<bodyText confidence="0.997151161290322">
In our implementation, dialogue management
proper concerns decision making of what to do
next, i.e. the selection of the system&apos;s next di-
alogue act. All possible dialogue acts for the
system are implemented as dialogue agents, de-
scribed shortly in the following list:
Open Give the opening prompt.
ReOpen Start the dialogue all over again.
Close Close the dialogue.
Help Give a help message to the user.
Repeat Repeat the previous system&apos;s turn.
ReqRepeat Ask the user to repeat the last utter-
ance.
ReqRephrase Ask the user to rephrase the last ut-
terance.
Ask Ask a question from the user.
Inform Give information to the user.
Confirm Ask confirmation from the user.
Note that many — or all — of the agents can be
made domain independent. For example, Repeat
simply reproduces the system&apos;s previous turn from
the dialogue history, and requires no application
specific information. Also, these kinds of dialogue
acts are commonly found in most of the dialogue
systems for database access.
The agent selection is done by heuristic rules,
implemented so that each agent can tell itself how
well it is suited to the current dialogue state. Eval-
uation is done by a single evaluator, CanHandleE-
valuator, which passes all responsibility to agents&apos;
own opinion (Figure 3).
</bodyText>
<figure confidence="0.834268666666667">
How good
are you?
Information Storage
</figure>
<figureCaption confidence="0.9888635">
Figure 3: The Dialogue Manager with heuristic
agent selection.
</figureCaption>
<bodyText confidence="0.9998148">
The dialogue manager produces the dialgoue
act and the semantic content of the system&apos;s next
turn. The presentation manager is responsible for
realizing the intented act as text and passing it to
the speech synthesizer.
</bodyText>
<sectionHeader confidence="0.921342" genericHeader="method">
4 Learning and adaptivity
</sectionHeader>
<bodyText confidence="0.999377809523809">
In this section we outline how the distributed dia-
logue management scheme supports learning and
adaptivity in dialogue systems.
Agent selection by managers in the Jaspis
framework compares to action selection by agents
in the research area of autonomous agents (Maes,
1994). By defining agents (in Jaspis) as dialogue
acts and applying machine learning methods for
agent evaluation and selection, it is possible to
learn dialogue management strategies and sup-
port learning and adaptive dialogue systems at the
system-level architecture.
Agent selection with a machine learning algo-
rithm can be implemented with a single evaluator.
Now the agents themselves are passive and the de-
cision is made by the evaluator. Figure 4 takes
reinforcement learning (RL) as an example. The
notion of dialogue states and agents as we have de-
fined them translates directly to the states and ac-
tions in reinforcement learning (Sutton and Barto,
1998). The same state representation that was used
</bodyText>
<figure confidence="0.998176875">
Dialogue Manager
CanHandleEvaluator
Open Confirm
Close Inform
Ask
What&apos;s the
dialogue
state?
</figure>
<page confidence="0.997771">
58
</page>
<bodyText confidence="0.9996635">
in the heuristic decision making by agents can
be used by the evaluator that implements the Q-
estimate in RL-algorithm, and agents can be seen
as actions from which to choose from.
</bodyText>
<figure confidence="0.984520375">
Dialogue Manager
QEstimateEvaluator
Pick the
best agent
What&apos;s the
dialogue
state?
Information Storage ./
</figure>
<figureCaption confidence="0.970027">
Figure 4: The Dialogue Manager with agent selec-
tion based on reinforcement learning.
</figureCaption>
<bodyText confidence="0.99984037037037">
When the agent selection algorithm is imple-
mented as an evaluator, it can be reused in an-
other application and in a different domain, pro-
vided that the dialogue state can be represented in
a uniform way. This is indeed often the case: for
example Litman et al. (2000) apply RL for the se-
lection of dialogue strategy and use variables such
as the (index of the) attribute in focus, the con-
fidence value of the attribute, and the number of
times that the attribute value has been asked for,
which are generally applicable for different kinds
of form-based dialogue systems.
As the Jaspis framework supports agent selec-
tion by combining several evaluators, one can take
advantage of multiple machine learning methods
and design a sophisticated decision making algo-
rithm. This can be done by implementing each
machine learning algorithm in an evaluator and
combining them with e.g. majority voting.
Reinforcement learning has been used in pre-
vious work to learn dialogue strategies (Litman
et al., 2000; Walker, 2000; Scheffler and Young,
2002). The choice of RL is natural: training ex-
amples for supervised learning methods are hard
to get, and the reward given most naturally at end
of the dialogue must be propagated back to earlier
utterances in the dialogue history.
</bodyText>
<sectionHeader confidence="0.872841" genericHeader="conclusions">
5 Summary and discussion
</sectionHeader>
<bodyText confidence="0.999992279069768">
We have introduced a distributed dialogue man-
agement scheme, and shown how it can sup-
port software reuse and the application of ma-
chine learning in the selection of dialogue strat-
egy. Building an application partly from existing
configurable components allows us to shorten de-
velopment times and to concentrate on more chal-
lenging aspects of dialogue management. On the
other hand, the logical structure of dialogue pro-
cessing also poses the question of task decompo-
sition: what are the smallest parametrised actions
that are needed for composing various tasks, and
which can thus be used as reusable agents? Fur-
ther research is needed to provide insight to this
question.
One also has to note that a common represen-
tation scheme for task and dialogue knowledge is
a prerequisite for developing general components
for a blackboard architecture. We have adopted
the Annotation Graph (AG) framework (Bird and
Liberman, 1999) for the basis of our representa-
tion of dialogue knowledge. Although the primary
target for the AG framework is the annotation of a
speech signal with linguistic features by hand, it is
a general and flexible model for multiple levels of
information attached to a timeline.
The task knowledge in our system is repre-
sented with an XML-representation designed es-
pecially for the current application. Without any
standards for task knowledge representation one
can only hope to build a general enough represen-
tation that is applicable to various domains. The
recent intrest in ontologies and semantic web, as
well as building general knowledge bases on the
basis of existing classifications, can be seen as a
step towards a solution to this kind of portability
problems.
The Interact demonstration system that imple-
ments distributed dialogue management as de-
scribed in this paper, will be demonstrated in the
workshop. The system can be used with a speech
interface, a multimodal interface with a touch-
screen, or with a text interface.
</bodyText>
<figure confidence="0.943370666666667">
Open Confirm
Close Inform
Ask
</figure>
<page confidence="0.993219">
59
</page>
<sectionHeader confidence="0.988863" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999936571428571">
This research has been carried out in the context
of USIX Interact project, a collaboration project
between four Finnish universities, and funded by
the National Technology Agency, the leading IT
companies Fujitsu Invia oyj, Sonera oyj, Lingsoft
oy, and Gurusoft oy, as well as the Finnish Assosi-
ation for the Deaf and Arla Institute.
</bodyText>
<sectionHeader confidence="0.997746" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999884602272728">
J. Allwood, D. Traum, and K. Jokinen. 2000. Cooper-
ation, dialogue and ethics. International Journal of
Human-Computer Studies, 53(6):871-914.
J. Allwood. 1997. Dialog as collective thinking. In
P. Pylkkanen, P. Pylkko, and A. Hautamaki, editors,
Brain, Mind and Physics. IOS Press, Amsterdam.
N. Baylock, J. Allen, and G. Ferguson. 2002. Syn-
chronization in an asynchronous agent-based archi-
tecture for dialogue systems. In K. Jokinen and
S. McRoy, editors, Proceedings of the 3rd SIGDial
workshop on Discourse and Dialogue, pages 1-10,
Philadelphia, USA.
N.O. Bernsen, H. Dybkjaer, and L. Dybkjaer. 1998.
Designing Interactive Speech Systems. From First
Ideas to User Testing. Springer Verlag, London.
S. Bird and M. Liberman. 1999. A formal framework
for linguistic annotation. Technical Report MS-CIS-
99-01, Philadelphia, Pennsylvania.
P.R. Cohen, J. Morgan, and M. Pollack, editors. 1990.
Intentions in Communication. MIT Press, Cam-
bridge, Massachusettes.
P. Gmytrasiewicz and E. Durfee. 2001. Ratio-
nal communication in multi-agent environments.
Autonomous Agents and Multi-Agent Systems,
4(3):233-272.
N.R. Jennings. 1993. Specifi cation and implementa-
tion of a belief-desire-joint-intention architecture for
collaborative problem solving. International Jour-
nal of Intelligent and Coopeartive Information Sys-
tems, 2(3):289-318.
K. Jokinen, T. Hurtig, K. Hynna, K. Kanto, A. Ker-
minen, and M. Kaipainen. 2001. Self-organizing
dialogue management. In H. Isahara and Q. Ma, ed-
itors, NLPRS2001 Proceedings of the 2nd Workshop
on Natural Language Processing and Neural Net-
works, pages 77-84, Tokyo, Japan.
K. Jokinen, A. Kerminen, M. Kaipainen, T. Jauhi-
ainen, G. Wilcock, M. Turunen, J. Hakulinen, J. Ku-
usisto, and K. Lagus. 2002. Adaptive dialogue sys-
tems - interaction with Interact. In K. Jokinen and
S. McRoy, editors, Proceedings of the 3rd SIGDial
workshop on Discourse and Dialogue, pages 64-73,
Philadelphia, USA.
K. Jokinen. 1996. Goal formulation based on com-
municative principles. In Proceedings of the 16th
COLING, pages 598-603.
S. Larsson, R. Cooper, and S. Ericsson. 2001.
menu2dialog. In K. Jokinen, editor, Proceedings of
the 2nd Workshop on Knowledge and Reasoning in
Practical Dialogue Systems, LICAI-2001, pages 41-
45, San Diego.
D. Litman, M. Kearns, S. Singh, and M. Walker. 2000.
Automatic optimization of dialogue management.
In Proceedings of COLING 2000.
P. Maes. 1994. Modeling adaptive autonomous agents.
Artificial Life, I, (1&amp;2)(9).
A.I. Rudnicky, E. Thayer, P. Constantinides, C. Tchou,
R. Shern, K. Lenzo, W. Xu, and A. Oh. 1999. Creat-
ing natural dialogs in the Carnegie Mellon Commu-
nicator system. In Proceedings of the 6th European
Conference on Speech Communication and Technol-
ogy (Eurospeech-99), pages 1531-1534, Budapest,
Hungary.
K. Scheffbr and S. Young. 2002. Automatic learning
of dialogue strategy using dialogue simulation and
reinforcement learning. In Proceedings of Human
Language Technology, pages 12-18, San Diego.
S. Seneff, R. Lau, and J. Polifroni. 1999. Organiza-
tion, communication, and control in the GALAXY-
II conversational system. In Proceedings of the
6th European Conference on Speech Communica-
tion and Technology (Eurospeech-99), pages 1271-
1274, Budapest, Hungary.
R. Sutton and A. Barto. 1998. Reinforcement Learn-
ing: An Introduction. MIT Press, Cambridge, Mas-
sach usettes .
M. Turunen and J. Hakulinen. 2001. Agent-based
adaptive interaction and dialogue management ar-
chitecture for speech applications. In Text, Speech
and Dialogue. Proceedings of the Fourth Interna-
tional Conference TSD-2001, pages 357-364.
The VoiceXML Forum. 2003. Voice eXtensi-
ble Markup Language VoiceXML, Version 1.00.
http://www.voicexml.org.
M. Walker. 2000. An application of reinforcement
learning to dialogue strategy selection in a spoken
dialogue system for email. Journal of Artificial In-
telligence Research, 12:387-416.
</reference>
<page confidence="0.998411">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.902600">
<title confidence="0.973018">Distributed dialogue management in a blackboard architecture</title>
<author confidence="0.999937">Antti Kerminen Kristiina Jokinen</author>
<affiliation confidence="0.999907">University of Art and Design Helsinki University of Helsinki*</affiliation>
<email confidence="0.953938">fakerminel@uiah.fifkristiina.jokinenj@helsinki.fi</email>
<abstract confidence="0.997481272727273">This paper describes a distributed dialogue management scheme for speechbased information seeking dialogue. The dialogue management is distributed to several components, supported by a general blackboard-type architecture for speech systems. By breaking down the dialogue management, we can achieve more general solutions and support sophisticated decision making algorithms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allwood</author>
<author>D Traum</author>
<author>K Jokinen</author>
</authors>
<title>Cooperation, dialogue and ethics.</title>
<date>2000</date>
<journal>International Journal of Human-Computer Studies,</journal>
<pages>53--6</pages>
<contexts>
<context position="13648" citStr="Allwood et al., 2000" startWordPosition="2091" endWordPosition="2094"> managers in that they represent different levels of input analysis. Input agents are executed in order, and input evaluators decide when the analysis in complete. The generation of system responses is implemented as presentation agents in the Presentation Manager. The Task Manager takes care of the task related information, while the decision of what to say next is made in the Dialogue Manager. 3.1 Constructive Dialogue Model Our dialogue model follows the Constructive Dialgue Model (Jokinen, 1996), based on the communicative principles of rational and coordinated interaction (Allwood, 1997; Allwood et al., 2000). The speakers act by exchanging new information and constructing a shared context in which to achieve the underlying goal (in our case this is to provide information from a database, but it can also be a general interactional goal such as &amp;quot;keep the channel open&amp;quot;). The speakers are engaged in a cooperative activity and their actions are constrained by communicative obligations. The emphasis on the principles of ideal co-operation distinguishes our approach from the related work in multiagent systems such as (Gmytrasiewicz and Durfee, 2001) which deals with rationality in decision-theoretic fra</context>
</contexts>
<marker>Allwood, Traum, Jokinen, 2000</marker>
<rawString>J. Allwood, D. Traum, and K. Jokinen. 2000. Cooperation, dialogue and ethics. International Journal of Human-Computer Studies, 53(6):871-914.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Allwood</author>
</authors>
<title>Dialog as collective thinking.</title>
<date>1997</date>
<editor>In P. Pylkkanen, P. Pylkko, and A. Hautamaki, editors, Brain, Mind and Physics.</editor>
<publisher>IOS Press,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="13625" citStr="Allwood, 1997" startWordPosition="2089" endWordPosition="2090">ts in the other managers in that they represent different levels of input analysis. Input agents are executed in order, and input evaluators decide when the analysis in complete. The generation of system responses is implemented as presentation agents in the Presentation Manager. The Task Manager takes care of the task related information, while the decision of what to say next is made in the Dialogue Manager. 3.1 Constructive Dialogue Model Our dialogue model follows the Constructive Dialgue Model (Jokinen, 1996), based on the communicative principles of rational and coordinated interaction (Allwood, 1997; Allwood et al., 2000). The speakers act by exchanging new information and constructing a shared context in which to achieve the underlying goal (in our case this is to provide information from a database, but it can also be a general interactional goal such as &amp;quot;keep the channel open&amp;quot;). The speakers are engaged in a cooperative activity and their actions are constrained by communicative obligations. The emphasis on the principles of ideal co-operation distinguishes our approach from the related work in multiagent systems such as (Gmytrasiewicz and Durfee, 2001) which deals with rationality in</context>
</contexts>
<marker>Allwood, 1997</marker>
<rawString>J. Allwood. 1997. Dialog as collective thinking. In P. Pylkkanen, P. Pylkko, and A. Hautamaki, editors, Brain, Mind and Physics. IOS Press, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Baylock</author>
<author>J Allen</author>
<author>G Ferguson</author>
</authors>
<title>Synchronization in an asynchronous agent-based architecture for dialogue systems.</title>
<date>2002</date>
<booktitle>Proceedings of the 3rd SIGDial workshop on Discourse and Dialogue,</booktitle>
<pages>1--10</pages>
<editor>In K. Jokinen and S. McRoy, editors,</editor>
<location>Philadelphia, USA.</location>
<contexts>
<context position="5765" citStr="Baylock et al., 2002" startWordPosition="877" endWordPosition="880">parts of dialogue management will benefit most from the results obtained through the new models. On the other hand, conversational dialogue management can be operationalised by dividing the interaction task into different processing tasks and actions which can be implemented as separate independet procedurs of the whole system, operate asynchroniously, and combine to produce the desired functionality. Agent-based architectures have thus been introduced with the main benefit being that of flexibility in regard to functioning of the system components (Seneff et al., 1999; Rudnicky et al., 1999; Baylock et al., 2002; Jokinen et al., 2002). While not necessary being committed to conversational dialogue management, agent-based architectures support simultaneous processing of dialogue information by allowing asynchronicity, which provides freedom from a tight pipeline processing and also speeds up the system as e.g. input analysis and output generation can function simultaneously. In practice, however, agent-based architectures usually have general control mechanisms that constrain the components to follow the logical structure of the information flow. In this paper, we discuss these aspects and present a s</context>
<context position="8870" citStr="Baylock et al., 2002" startWordPosition="1355" endWordPosition="1358">spondence of names in Jaspis and traditional agent architectures. All information in Jaspis is stored in the Information Storage, which is accessible by all components in the system. Thus, any component can use any information in the system. For example, the dialogue history is accessible by all components and is used e.g. by input agents to analyze the input at the discourse level. The shared information storage in Jaspis compares to the hub or facilitator of some common agent-based architectures, like the CMU Communicator (Rudnicky et al., 1999), GALAXY-II (Seneff et al., 1999), and TRAINS (Baylock et al., 2002). However, the CMU Communicator, GALAXY-II, and TRAINS allow asynchronous execution of all system components, while in Jaspis the only place for asynchronicity is the Communication Manager, which can handle multiple parallel requests for input/output devices. The other managers cannot run asynchronously but they follow the logical order of information flow. The lack of parallel manager execution makes it difficult to implement grounding or barge-in functionality. On the other hand, within each manager the agents operate independently to the extend of producing scores for how well their functio</context>
</contexts>
<marker>Baylock, Allen, Ferguson, 2002</marker>
<rawString>N. Baylock, J. Allen, and G. Ferguson. 2002. Synchronization in an asynchronous agent-based architecture for dialogue systems. In K. Jokinen and S. McRoy, editors, Proceedings of the 3rd SIGDial workshop on Discourse and Dialogue, pages 1-10, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N O Bernsen</author>
<author>H Dybkjaer</author>
<author>L Dybkjaer</author>
</authors>
<title>Designing Interactive Speech Systems. From First Ideas to User Testing.</title>
<date>1998</date>
<publisher>Springer Verlag,</publisher>
<location>London.</location>
<contexts>
<context position="1268" citStr="Bernsen et al. (1998)" startWordPosition="183" endWordPosition="186">sign are: &amp;quot;what should the system do?&amp;quot; and &amp;quot;how should the system do what it is meant to do?&amp;quot; The answer is affected by the task complexity and the desired dialogue functionalities, and also by the architectural design: there is a wide variety of dialogue models that describe processing of the dialogue information on the conceptual level, but there is also a need for generic development platforms that would support experimenting with various architectures and techniques, and would also allow easy extensibility to new functionalities required by new tasks and applications. As described e.g. in Bernsen et al. (1998), the logical structure of dialogue management contains input analysis (speech recognition and linguistic analysis), dialogue handling, and output generation (natural language generation and speech synthesis). Consequently, spoken dialogue systems have pi pel i ned architectures where the decision The research was done while the author was working at the University of Art and Design Helsinki. making is based on the logical order of the information flow, and dialogue handling is implemented as a single dialogue management component with the task of making decisions of what the system should do </context>
</contexts>
<marker>Bernsen, Dybkjaer, Dybkjaer, 1998</marker>
<rawString>N.O. Bernsen, H. Dybkjaer, and L. Dybkjaer. 1998. Designing Interactive Speech Systems. From First Ideas to User Testing. Springer Verlag, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
<author>M Liberman</author>
</authors>
<title>A formal framework for linguistic annotation.</title>
<date>1999</date>
<tech>Technical Report MS-CIS99-01,</tech>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="24064" citStr="Bird and Liberman, 1999" startWordPosition="3775" endWordPosition="3778"> concentrate on more challenging aspects of dialogue management. On the other hand, the logical structure of dialogue processing also poses the question of task decomposition: what are the smallest parametrised actions that are needed for composing various tasks, and which can thus be used as reusable agents? Further research is needed to provide insight to this question. One also has to note that a common representation scheme for task and dialogue knowledge is a prerequisite for developing general components for a blackboard architecture. We have adopted the Annotation Graph (AG) framework (Bird and Liberman, 1999) for the basis of our representation of dialogue knowledge. Although the primary target for the AG framework is the annotation of a speech signal with linguistic features by hand, it is a general and flexible model for multiple levels of information attached to a timeline. The task knowledge in our system is represented with an XML-representation designed especially for the current application. Without any standards for task knowledge representation one can only hope to build a general enough representation that is applicable to various domains. The recent intrest in ontologies and semantic we</context>
</contexts>
<marker>Bird, Liberman, 1999</marker>
<rawString>S. Bird and M. Liberman. 1999. A formal framework for linguistic annotation. Technical Report MS-CIS99-01, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<date>1990</date>
<booktitle>Intentions in Communication.</booktitle>
<editor>P.R. Cohen, J. Morgan, and M. Pollack, editors.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusettes.</location>
<marker>1990</marker>
<rawString>P.R. Cohen, J. Morgan, and M. Pollack, editors. 1990. Intentions in Communication. MIT Press, Cambridge, Massachusettes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Gmytrasiewicz</author>
<author>E Durfee</author>
</authors>
<title>Rational communication in multi-agent environments. Autonomous Agents and Multi-Agent Systems,</title>
<date>2001</date>
<pages>4--3</pages>
<contexts>
<context position="14193" citStr="Gmytrasiewicz and Durfee, 2001" startWordPosition="2180" endWordPosition="2183">inciples of rational and coordinated interaction (Allwood, 1997; Allwood et al., 2000). The speakers act by exchanging new information and constructing a shared context in which to achieve the underlying goal (in our case this is to provide information from a database, but it can also be a general interactional goal such as &amp;quot;keep the channel open&amp;quot;). The speakers are engaged in a cooperative activity and their actions are constrained by communicative obligations. The emphasis on the principles of ideal co-operation distinguishes our approach from the related work in multiagent systems such as (Gmytrasiewicz and Durfee, 2001) which deals with rationality in decision-theoretic framework, and views communication as a decision process whereby the agent selects acts with the highest expected utility. Although acting may be selected on the basis of cost 56 and benefit, communication brings in such aspects as trust, obligations and social commitments, the influence of which in dialogue decisions may be difficult to model solely in these terms in practise. The speakers continue their interaction, and proceed by taking turns to specify, clarify and elaborate the information exchanged as long as the goal is valid, i.e. not</context>
</contexts>
<marker>Gmytrasiewicz, Durfee, 2001</marker>
<rawString>P. Gmytrasiewicz and E. Durfee. 2001. Rational communication in multi-agent environments. Autonomous Agents and Multi-Agent Systems, 4(3):233-272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N R Jennings</author>
</authors>
<title>Specifi cation and implementation of a belief-desire-joint-intention architecture for collaborative problem solving.</title>
<date>1993</date>
<journal>International Journal of Intelligent and Coopeartive Information Systems,</journal>
<pages>2--3</pages>
<contexts>
<context position="3982" citStr="Jennings, 1993" startWordPosition="611" endWordPosition="612">l users (cf. e.g. the questionunder-discussion approach implemented in (Lars53 son et al., 2001)). For instance, tasks like hotel reservations and flight information providing services contain pieces of knowledge which can be communicated in various orders and combinations between the partners, and thus they do not easily lend themselves to any fixed dialogue modelling. The form also provides a dialogue context in which the actions can be interpreted and planned so as to allow more varied system utterances. Early dialogue research concerned planbased and BDI-systems (e.g. (Cohen et al., 1990; Jennings, 1993), and references therein), and also emphasized the separation of static task knowledge from the processing knowledge, although the mechanisms for both knowledge representation and reasoning were usually too heavy and complicated for practical dialogue systems. To enable truly natural interaction, it is necessary to equip the system with knowledge about the task and application as well as with dialogue capabilities. The aim of conversational dialogue management is to improve human-computer interaction by taking human conversational capabilities into account (both verbal and non-verbal communica</context>
</contexts>
<marker>Jennings, 1993</marker>
<rawString>N.R. Jennings. 1993. Specifi cation and implementation of a belief-desire-joint-intention architecture for collaborative problem solving. International Journal of Intelligent and Coopeartive Information Systems, 2(3):289-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Jokinen</author>
<author>T Hurtig</author>
<author>K Hynna</author>
<author>K Kanto</author>
<author>A Kerminen</author>
<author>M Kaipainen</author>
</authors>
<title>Self-organizing dialogue management.</title>
<date>2001</date>
<booktitle>NLPRS2001 Proceedings of the 2nd Workshop on Natural Language Processing and Neural Networks,</booktitle>
<pages>77--84</pages>
<editor>In H. Isahara and Q. Ma, editors,</editor>
<location>Tokyo, Japan.</location>
<contexts>
<context position="16778" citStr="Jokinen et al., 2001" startWordPosition="2592" endWordPosition="2595">ormation already available in the context. 3.3 Input analysis The basic semantic content of the user&apos;s utterance is given by the parser. Because the parser only looks at the current utterance, it cannot provide information about ellipses or anaphoric references. However, the discourse-level input agents complete the semantic analysis of the parser by taking into account the dialogue history. There are three input agents in the discourse-level analysis: ellipsis resolution, anaphora resolution, and dialogue act classification. The current system uses a subset of the dialogue acts described in (Jokinen et al., 2001) which presents dialogue act classification based on machine-learning techniques. In addition there are agents for merging inputs from different input modalities and updating the dialogue history in the information storage. 3.4 Task management The task management is separate and has its own manager. The tasks of the Task Manager are to make sure that the user has given all required information to complete a database query, execute the complete query, and transfer the information for further processing. Because of the fairly simple application domain, task specific knowledge is represented as a</context>
</contexts>
<marker>Jokinen, Hurtig, Hynna, Kanto, Kerminen, Kaipainen, 2001</marker>
<rawString>K. Jokinen, T. Hurtig, K. Hynna, K. Kanto, A. Kerminen, and M. Kaipainen. 2001. Self-organizing dialogue management. In H. Isahara and Q. Ma, editors, NLPRS2001 Proceedings of the 2nd Workshop on Natural Language Processing and Neural Networks, pages 77-84, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Jokinen</author>
<author>A Kerminen</author>
<author>M Kaipainen</author>
<author>T Jauhiainen</author>
<author>G Wilcock</author>
<author>M Turunen</author>
<author>J Hakulinen</author>
<author>J Kuusisto</author>
<author>K Lagus</author>
</authors>
<title>Adaptive dialogue systems - interaction with Interact. In</title>
<date>2002</date>
<booktitle>Proceedings of the 3rd SIGDial workshop on Discourse and Dialogue,</booktitle>
<pages>64--73</pages>
<editor>K. Jokinen and S. McRoy, editors,</editor>
<location>Philadelphia, USA.</location>
<contexts>
<context position="5788" citStr="Jokinen et al., 2002" startWordPosition="881" endWordPosition="884">gement will benefit most from the results obtained through the new models. On the other hand, conversational dialogue management can be operationalised by dividing the interaction task into different processing tasks and actions which can be implemented as separate independet procedurs of the whole system, operate asynchroniously, and combine to produce the desired functionality. Agent-based architectures have thus been introduced with the main benefit being that of flexibility in regard to functioning of the system components (Seneff et al., 1999; Rudnicky et al., 1999; Baylock et al., 2002; Jokinen et al., 2002). While not necessary being committed to conversational dialogue management, agent-based architectures support simultaneous processing of dialogue information by allowing asynchronicity, which provides freedom from a tight pipeline processing and also speeds up the system as e.g. input analysis and output generation can function simultaneously. In practice, however, agent-based architectures usually have general control mechanisms that constrain the components to follow the logical structure of the information flow. In this paper, we discuss these aspects and present a system with distributed </context>
<context position="12679" citStr="Jokinen et al., 2002" startWordPosition="1942" endWordPosition="1945">timodal input/output capabilities and it also accepts text and touch-screen input and video output. 3 Distributed dialogue management We have built a timetable service as the Interact demonstration system. The system is capable of answering questions about connections between two places, arrival and departure times, and arrival and departure places. The system suppports mixed-initiative dialogues: by default the user has the initiative, but the system enters mixedinitiative mode if the user fails communicate his goals to the system. The general overview of the demostration system is given in (Jokinen et al., 2002). Unlike the traditional approaches, the dialogue management components are distributed across various managers. The discourse and dialogue level analysis is implemented in the Communication Manager which has a set of input agents and input evaluators to analyze inputs. Input agents in the Communication Manager differ from the agents in the other managers in that they represent different levels of input analysis. Input agents are executed in order, and input evaluators decide when the analysis in complete. The generation of system responses is implemented as presentation agents in the Presenta</context>
</contexts>
<marker>Jokinen, Kerminen, Kaipainen, Jauhiainen, Wilcock, Turunen, Hakulinen, Kuusisto, Lagus, 2002</marker>
<rawString>K. Jokinen, A. Kerminen, M. Kaipainen, T. Jauhiainen, G. Wilcock, M. Turunen, J. Hakulinen, J. Kuusisto, and K. Lagus. 2002. Adaptive dialogue systems - interaction with Interact. In K. Jokinen and S. McRoy, editors, Proceedings of the 3rd SIGDial workshop on Discourse and Dialogue, pages 64-73, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Jokinen</author>
</authors>
<title>Goal formulation based on communicative principles.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th COLING,</booktitle>
<pages>598--603</pages>
<contexts>
<context position="13531" citStr="Jokinen, 1996" startWordPosition="2076" endWordPosition="2077">ut evaluators to analyze inputs. Input agents in the Communication Manager differ from the agents in the other managers in that they represent different levels of input analysis. Input agents are executed in order, and input evaluators decide when the analysis in complete. The generation of system responses is implemented as presentation agents in the Presentation Manager. The Task Manager takes care of the task related information, while the decision of what to say next is made in the Dialogue Manager. 3.1 Constructive Dialogue Model Our dialogue model follows the Constructive Dialgue Model (Jokinen, 1996), based on the communicative principles of rational and coordinated interaction (Allwood, 1997; Allwood et al., 2000). The speakers act by exchanging new information and constructing a shared context in which to achieve the underlying goal (in our case this is to provide information from a database, but it can also be a general interactional goal such as &amp;quot;keep the channel open&amp;quot;). The speakers are engaged in a cooperative activity and their actions are constrained by communicative obligations. The emphasis on the principles of ideal co-operation distinguishes our approach from the related work </context>
</contexts>
<marker>Jokinen, 1996</marker>
<rawString>K. Jokinen. 1996. Goal formulation based on communicative principles. In Proceedings of the 16th COLING, pages 598-603.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
<author>R Cooper</author>
<author>S Ericsson</author>
</authors>
<date>2001</date>
<booktitle>Proceedings of the 2nd Workshop on Knowledge and Reasoning in Practical Dialogue Systems, LICAI-2001,</booktitle>
<pages>41--45</pages>
<editor>menu2dialog. In K. Jokinen, editor,</editor>
<location>San Diego.</location>
<marker>Larsson, Cooper, Ericsson, 2001</marker>
<rawString>S. Larsson, R. Cooper, and S. Ericsson. 2001. menu2dialog. In K. Jokinen, editor, Proceedings of the 2nd Workshop on Knowledge and Reasoning in Practical Dialogue Systems, LICAI-2001, pages 41-45, San Diego.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>M Kearns</author>
<author>S Singh</author>
<author>M Walker</author>
</authors>
<title>Automatic optimization of dialogue management.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="22116" citStr="Litman et al. (2000)" startWordPosition="3459" endWordPosition="3462">ecision making by agents can be used by the evaluator that implements the Qestimate in RL-algorithm, and agents can be seen as actions from which to choose from. Dialogue Manager QEstimateEvaluator Pick the best agent What&apos;s the dialogue state? Information Storage ./ Figure 4: The Dialogue Manager with agent selection based on reinforcement learning. When the agent selection algorithm is implemented as an evaluator, it can be reused in another application and in a different domain, provided that the dialogue state can be represented in a uniform way. This is indeed often the case: for example Litman et al. (2000) apply RL for the selection of dialogue strategy and use variables such as the (index of the) attribute in focus, the confidence value of the attribute, and the number of times that the attribute value has been asked for, which are generally applicable for different kinds of form-based dialogue systems. As the Jaspis framework supports agent selection by combining several evaluators, one can take advantage of multiple machine learning methods and design a sophisticated decision making algorithm. This can be done by implementing each machine learning algorithm in an evaluator and combining them</context>
</contexts>
<marker>Litman, Kearns, Singh, Walker, 2000</marker>
<rawString>D. Litman, M. Kearns, S. Singh, and M. Walker. 2000. Automatic optimization of dialogue management. In Proceedings of COLING 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Maes</author>
</authors>
<title>Modeling adaptive autonomous agents.</title>
<date>1994</date>
<journal>Artificial Life, I,</journal>
<contexts>
<context position="20678" citStr="Maes, 1994" startWordPosition="3228" endWordPosition="3229">are you? Information Storage Figure 3: The Dialogue Manager with heuristic agent selection. The dialogue manager produces the dialgoue act and the semantic content of the system&apos;s next turn. The presentation manager is responsible for realizing the intented act as text and passing it to the speech synthesizer. 4 Learning and adaptivity In this section we outline how the distributed dialogue management scheme supports learning and adaptivity in dialogue systems. Agent selection by managers in the Jaspis framework compares to action selection by agents in the research area of autonomous agents (Maes, 1994). By defining agents (in Jaspis) as dialogue acts and applying machine learning methods for agent evaluation and selection, it is possible to learn dialogue management strategies and support learning and adaptive dialogue systems at the system-level architecture. Agent selection with a machine learning algorithm can be implemented with a single evaluator. Now the agents themselves are passive and the decision is made by the evaluator. Figure 4 takes reinforcement learning (RL) as an example. The notion of dialogue states and agents as we have defined them translates directly to the states and </context>
</contexts>
<marker>Maes, 1994</marker>
<rawString>P. Maes. 1994. Modeling adaptive autonomous agents. Artificial Life, I, (1&amp;2)(9).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A I Rudnicky</author>
<author>E Thayer</author>
<author>P Constantinides</author>
<author>C Tchou</author>
<author>R Shern</author>
<author>K Lenzo</author>
<author>W Xu</author>
<author>A Oh</author>
</authors>
<title>Creating natural dialogs in the Carnegie Mellon Communicator system.</title>
<date>1999</date>
<booktitle>In Proceedings of the 6th European Conference on Speech Communication and Technology (Eurospeech-99),</booktitle>
<pages>1531--1534</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="5743" citStr="Rudnicky et al., 1999" startWordPosition="873" endWordPosition="876">l as to evaluate which parts of dialogue management will benefit most from the results obtained through the new models. On the other hand, conversational dialogue management can be operationalised by dividing the interaction task into different processing tasks and actions which can be implemented as separate independet procedurs of the whole system, operate asynchroniously, and combine to produce the desired functionality. Agent-based architectures have thus been introduced with the main benefit being that of flexibility in regard to functioning of the system components (Seneff et al., 1999; Rudnicky et al., 1999; Baylock et al., 2002; Jokinen et al., 2002). While not necessary being committed to conversational dialogue management, agent-based architectures support simultaneous processing of dialogue information by allowing asynchronicity, which provides freedom from a tight pipeline processing and also speeds up the system as e.g. input analysis and output generation can function simultaneously. In practice, however, agent-based architectures usually have general control mechanisms that constrain the components to follow the logical structure of the information flow. In this paper, we discuss these a</context>
<context position="8802" citStr="Rudnicky et al., 1999" startWordPosition="1344" endWordPosition="1347">mponents and traditional terms of agent architectures. Table 1: Correspondence of names in Jaspis and traditional agent architectures. All information in Jaspis is stored in the Information Storage, which is accessible by all components in the system. Thus, any component can use any information in the system. For example, the dialogue history is accessible by all components and is used e.g. by input agents to analyze the input at the discourse level. The shared information storage in Jaspis compares to the hub or facilitator of some common agent-based architectures, like the CMU Communicator (Rudnicky et al., 1999), GALAXY-II (Seneff et al., 1999), and TRAINS (Baylock et al., 2002). However, the CMU Communicator, GALAXY-II, and TRAINS allow asynchronous execution of all system components, while in Jaspis the only place for asynchronicity is the Communication Manager, which can handle multiple parallel requests for input/output devices. The other managers cannot run asynchronously but they follow the logical order of information flow. The lack of parallel manager execution makes it difficult to implement grounding or barge-in functionality. On the other hand, within each manager the agents operate indepe</context>
</contexts>
<marker>Rudnicky, Thayer, Constantinides, Tchou, Shern, Lenzo, Xu, Oh, 1999</marker>
<rawString>A.I. Rudnicky, E. Thayer, P. Constantinides, C. Tchou, R. Shern, K. Lenzo, W. Xu, and A. Oh. 1999. Creating natural dialogs in the Carnegie Mellon Communicator system. In Proceedings of the 6th European Conference on Speech Communication and Technology (Eurospeech-99), pages 1531-1534, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Scheffbr</author>
<author>S Young</author>
</authors>
<title>Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning.</title>
<date>2002</date>
<booktitle>In Proceedings of Human Language Technology,</booktitle>
<pages>12--18</pages>
<location>San Diego.</location>
<marker>Scheffbr, Young, 2002</marker>
<rawString>K. Scheffbr and S. Young. 2002. Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning. In Proceedings of Human Language Technology, pages 12-18, San Diego.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Seneff</author>
<author>R Lau</author>
<author>J Polifroni</author>
</authors>
<title>Organization, communication, and control in the GALAXYII conversational system.</title>
<date>1999</date>
<booktitle>In Proceedings of the 6th European Conference on Speech Communication and Technology (Eurospeech-99),</booktitle>
<pages>1271--1274</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="5720" citStr="Seneff et al., 1999" startWordPosition="869" endWordPosition="872">nal phenomena, as well as to evaluate which parts of dialogue management will benefit most from the results obtained through the new models. On the other hand, conversational dialogue management can be operationalised by dividing the interaction task into different processing tasks and actions which can be implemented as separate independet procedurs of the whole system, operate asynchroniously, and combine to produce the desired functionality. Agent-based architectures have thus been introduced with the main benefit being that of flexibility in regard to functioning of the system components (Seneff et al., 1999; Rudnicky et al., 1999; Baylock et al., 2002; Jokinen et al., 2002). While not necessary being committed to conversational dialogue management, agent-based architectures support simultaneous processing of dialogue information by allowing asynchronicity, which provides freedom from a tight pipeline processing and also speeds up the system as e.g. input analysis and output generation can function simultaneously. In practice, however, agent-based architectures usually have general control mechanisms that constrain the components to follow the logical structure of the information flow. In this pa</context>
<context position="8835" citStr="Seneff et al., 1999" startWordPosition="1349" endWordPosition="1352">gent architectures. Table 1: Correspondence of names in Jaspis and traditional agent architectures. All information in Jaspis is stored in the Information Storage, which is accessible by all components in the system. Thus, any component can use any information in the system. For example, the dialogue history is accessible by all components and is used e.g. by input agents to analyze the input at the discourse level. The shared information storage in Jaspis compares to the hub or facilitator of some common agent-based architectures, like the CMU Communicator (Rudnicky et al., 1999), GALAXY-II (Seneff et al., 1999), and TRAINS (Baylock et al., 2002). However, the CMU Communicator, GALAXY-II, and TRAINS allow asynchronous execution of all system components, while in Jaspis the only place for asynchronicity is the Communication Manager, which can handle multiple parallel requests for input/output devices. The other managers cannot run asynchronously but they follow the logical order of information flow. The lack of parallel manager execution makes it difficult to implement grounding or barge-in functionality. On the other hand, within each manager the agents operate independently to the extend of producin</context>
</contexts>
<marker>Seneff, Lau, Polifroni, 1999</marker>
<rawString>S. Seneff, R. Lau, and J. Polifroni. 1999. Organization, communication, and control in the GALAXYII conversational system. In Proceedings of the 6th European Conference on Speech Communication and Technology (Eurospeech-99), pages 1271-1274, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sutton</author>
<author>A Barto</author>
</authors>
<title>Reinforcement Learning: An Introduction.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massach</location>
<note>usettes .</note>
<contexts>
<context position="21336" citStr="Sutton and Barto, 1998" startWordPosition="3331" endWordPosition="3334"> dialogue acts and applying machine learning methods for agent evaluation and selection, it is possible to learn dialogue management strategies and support learning and adaptive dialogue systems at the system-level architecture. Agent selection with a machine learning algorithm can be implemented with a single evaluator. Now the agents themselves are passive and the decision is made by the evaluator. Figure 4 takes reinforcement learning (RL) as an example. The notion of dialogue states and agents as we have defined them translates directly to the states and actions in reinforcement learning (Sutton and Barto, 1998). The same state representation that was used Dialogue Manager CanHandleEvaluator Open Confirm Close Inform Ask What&apos;s the dialogue state? 58 in the heuristic decision making by agents can be used by the evaluator that implements the Qestimate in RL-algorithm, and agents can be seen as actions from which to choose from. Dialogue Manager QEstimateEvaluator Pick the best agent What&apos;s the dialogue state? Information Storage ./ Figure 4: The Dialogue Manager with agent selection based on reinforcement learning. When the agent selection algorithm is implemented as an evaluator, it can be reused in </context>
</contexts>
<marker>Sutton, Barto, 1998</marker>
<rawString>R. Sutton and A. Barto. 1998. Reinforcement Learning: An Introduction. MIT Press, Cambridge, Massach usettes .</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Turunen</author>
<author>J Hakulinen</author>
</authors>
<title>Agent-based adaptive interaction and dialogue management architecture for speech applications.</title>
<date>2001</date>
<booktitle>In Text, Speech and Dialogue. Proceedings of the Fourth International Conference TSD-2001,</booktitle>
<pages>357--364</pages>
<contexts>
<context position="7565" citStr="Turunen and Hakulinen (2001)" startWordPosition="1145" endWordPosition="1148">ormation processing • introducing special dialogue agents and evaluators as the tools to implement dialogue management. The paper is organised as follows. Section 2 gives a short overview of the Jaspis framework that the Interact system is built on. Section 3 presents the concept of distributed dialogue management, and its implementation in our system. Section 4 motivates distributed dialogue management from the perspective of learning and adaptivity. Finally, section 5 provides summary and discussion. 2 Jaspis framework The Interact system is built on top of the Jaspis framework developed by Turunen and Hakulinen (2001). Jaspis is a general blackboard-type architecture for speech-based applications. The two 54 key features of the architecture are the shared information storage, and the concept of managers, agents and evaluators. The overall architecture, as demostrated in our system, is depicted in Figure 1. Jaspis can be called an agent-based architecture but the naming of system components can be a little confusing. Especially &amp;quot;agent&amp;quot; in Jaspis is somewhat different from the usual meaning of an autonomous, intelligent agent: it refers to the actions available for a manager. Table 1 gives rough corresponden</context>
<context position="9743" citStr="Turunen and Hakulinen, 2001" startWordPosition="1486" endWordPosition="1489">utput devices. The other managers cannot run asynchronously but they follow the logical order of information flow. The lack of parallel manager execution makes it difficult to implement grounding or barge-in functionality. On the other hand, within each manager the agents operate independently to the extend of producing scores for how well their functioning fits in a particular system state. The concept of managers, agents and evaluators is explained in more detail in the following three sections. More information about implementing dialogue management in the Jaspis framework can be found in (Turunen and Hakulinen, 2001). 2.1 Managers Jaspis has three main managers by default: the Communication Manager, the Dialogue Manager, and the Presentation Manager. The Communication Manager gives a high level abstraction of input/output devices and handles communication between the user and the computer. The Dialogue Manager decides the next system action, and the Presentation Manager realizes the semantic representation of the next system turn as a text and passes it to the output device (speech synthesis, screen). The program flow is controlled by the Interaction Manager, which gives the turn to the managers in a roun</context>
</contexts>
<marker>Turunen, Hakulinen, 2001</marker>
<rawString>M. Turunen and J. Hakulinen. 2001. Agent-based adaptive interaction and dialogue management architecture for speech applications. In Text, Speech and Dialogue. Proceedings of the Fourth International Conference TSD-2001, pages 357-364.</rawString>
</citation>
<citation valid="true">
<title>The VoiceXML Forum.</title>
<date>2003</date>
<note>http://www.voicexml.org.</note>
<marker>2003</marker>
<rawString>The VoiceXML Forum. 2003. Voice eXtensible Markup Language VoiceXML, Version 1.00. http://www.voicexml.org.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
</authors>
<title>An application of reinforcement learning to dialogue strategy selection in a spoken dialogue system for email.</title>
<date>2000</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>12--387</pages>
<contexts>
<context position="22861" citStr="Walker, 2000" startWordPosition="3581" endWordPosition="3582">e of the attribute, and the number of times that the attribute value has been asked for, which are generally applicable for different kinds of form-based dialogue systems. As the Jaspis framework supports agent selection by combining several evaluators, one can take advantage of multiple machine learning methods and design a sophisticated decision making algorithm. This can be done by implementing each machine learning algorithm in an evaluator and combining them with e.g. majority voting. Reinforcement learning has been used in previous work to learn dialogue strategies (Litman et al., 2000; Walker, 2000; Scheffler and Young, 2002). The choice of RL is natural: training examples for supervised learning methods are hard to get, and the reward given most naturally at end of the dialogue must be propagated back to earlier utterances in the dialogue history. 5 Summary and discussion We have introduced a distributed dialogue management scheme, and shown how it can support software reuse and the application of machine learning in the selection of dialogue strategy. Building an application partly from existing configurable components allows us to shorten development times and to concentrate on more </context>
</contexts>
<marker>Walker, 2000</marker>
<rawString>M. Walker. 2000. An application of reinforcement learning to dialogue strategy selection in a spoken dialogue system for email. Journal of Artificial Intelligence Research, 12:387-416.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>