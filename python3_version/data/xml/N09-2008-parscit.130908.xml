<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010434">
<title confidence="0.983707">
Large-scale Computation of Distributional Similarities for Queries
</title>
<author confidence="0.97554">
Enrique Alfonseca Keith Hall
</author>
<affiliation confidence="0.8663715">
Google Research Google Research
Zurich, Switzerland Zurich, Switzerland
</affiliation>
<email confidence="0.987738">
ealfonseca@google.com kbhall@google.com
</email>
<author confidence="0.997368">
Silvana Hartmann
</author>
<affiliation confidence="0.999176">
University of Stuttgart
</affiliation>
<address confidence="0.544515">
Stuttgart, Germany
</address>
<email confidence="0.996543">
silvana.hartmann@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.995597" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99989325">
We present a large-scale, data-driven approach
to computing distributional similarity scores
for queries. We contrast this to recent web-
based techniques which either require the off-
line computation of complete phrase vectors,
or an expensive on-line interaction with a
search engine interface. Independent of the
computational advantages of our approach, we
show empirically that our technique is more
effective at ranking query alternatives that the
computationally more expensive technique of
using the results from a web search engine.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999541529411765">
Measuring the semantic similarity between queries
or, more generally, between pairs of very short texts,
is increasingly receiving attention due to its many
applications. An accurate metric of query simi-
larities is useful for query expansion, to improve
recall in Information Retrieval systems; for query
suggestion, to propose to the user related queries
that might help reach the desired information more
quickly; and for sponsored search, where advertisers
bid for keywords that may be different but semanti-
cally equivalent to user queries.
In this paper, we study the problem of measuring
similarity between queries using corpus-based unsu-
pervised methods. Given a query q, we would like
to rank all other queries according to their similarity
to q. The proposed approach compares favorably to
a state-of-the-art unsupervised system.
</bodyText>
<page confidence="0.992059">
29
</page>
<sectionHeader confidence="0.999807" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.997741285714286">
Distributional similarity methods model the similar-
ity or relatedness of words using a metric defined
over the set of contexts in which the words appear
(Firth, 1957). One of the most common representa-
tions for contexts is the vector space model (Salton
et al., 1975). This is the basic idea of approaches
such as (Grefenstette, 1992; Bordag, 2008; Lin,
1998; Riloff and Shepherd, 1997), with some varia-
tions; e.g., whether syntactic information is used ex-
plicitly, or which weight function is applied. Most of
the existing work has focused on similarity between
single words or syntactically-correct multiword ex-
pressions. In this work, we adapt these techniques
to calculate similarity metrics between pairs of com-
plete queries, which may or may not be syntactically
correct.
Other approaches for query similarity use sta-
tistical translation models (Riezler et al., 2008),
analysing search engine logs (Jones et al., 2006),
looking for different anchor texts pointing to the
same pages (Kraft and Zien, 2004), or replacing
query words with other words that have the high-
est pointwise mutual information (Terra and Clarke,
2004).
Sahami and Helman (Sahami and Heilman, 2006)
define a web kernel function for semantic similarity
based on the snippets of the search results returned
by the queries. The algorithm used is the following:
</bodyText>
<listItem confidence="0.98498">
(a) Issue a query x to a search engine and collect
the set of n snippets returned by the search engine;
(b) Compute the tf·idf vector vi for each document
snippet di; (c) Truncate each vector to include its m
</listItem>
<subsubsectionHeader confidence="0.781143">
Proceedings of NAACL HLT 2009: Short Papers, pages 29–32,
</subsubsectionHeader>
<bodyText confidence="0.964283083333333">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
highest weighted terms; (d) Construct the centroid
of the L2-normalized vectors vi; (e) Calculate the
similarity of two queries as the dot product of their
L2-normalized vectors, i.e. as the cosine of both
vectors.
This work was followed up by Yih and Meek (Yih
and Meek, 2007), who combine the web kernel with
other simple metrics of similarity between word vec-
tors (Dice Coefficient, Jaccard Coefficient, Overlap,
Cosine, KL Divergence) in a machine learning sys-
tem to provide a ranking of similar queries.
</bodyText>
<sectionHeader confidence="0.992888" genericHeader="method">
3 Proposed method
</sectionHeader>
<bodyText confidence="0.999928666666667">
Using a search engine to collect snippets (Sahami
and Heilman, 2006; Yih and Meek, 2007; Yih and
Meek, 2008) takes advantage of all the optimizations
performed by the retrieval engine (spelling correc-
tion, relevance scores, etc.), but it has several disad-
vantages: first, it is not repeatable, as the code un-
derlying search engines is in a constant state of flux;
secondly, it is usually very expensive to issue a large
number of search requests; sometimes the APIs pro-
vided limit the number of requests. In this section,
we describe a method which overcomes these draw-
backs. The distributional methods we propose for
calculating similarities between words and multi-
word expressions profit from the use of a large Web-
based corpus.
The contextual vectors for a query can be col-
lected by identifying the contexts in which the query
appears. Queries such as [buy a book] and [buy
some books] are supposed to appear close to simi-
lar context words in a bag-of-words model, and they
should have a high similarity. However, there are
two reasons why this would yield poor results:
First, as the length of the queries grows, the prob-
ability of finding exact queries in the corpus shrinks
quickly. As an example, when issuing the queries
[Lindsay Lohan pets] and [Britney Spears pets] to
Google enclosed in double quotes, we obtain only
6 and 760 results, respectively. These are too few
occurrences in order to collect meaningful statistics
about the contexts of the queries.
Secondly, many user queries are simply a concate-
nation of keywords with weak or no underlying syn-
tax. Therefore, even if they are popular queries, they
may not appear as such in well-formed text found
in web documents. For example, queries like [hol-
lywood dvd cheap], enclosed in double quotes, re-
trieve less than 10 results. Longer queries, such as
[hotel cheap new york fares], are still meaningful,
but do not appear frequently in web documents.
In order to use of distributional similarities in the
query setting, we propose the following method.
Given a query of interest p = [w1, w2, ..., wn]:
</bodyText>
<listItem confidence="0.939392583333333">
1. For each word wi collect all words that appear
close to wi in the web corpus (i.e., a bag-fo-
words models). Empirically we have chosen
all the words whose distance to wi is less or
equal to 3. This gives us a vector of context
words and frequencies for each of the words in
the query, vz = (fi1, fi2,..., fi|V |), where IVI is
the size of the corpus vocabulary.
2. Represent the query p with a vector of words,
and the weight associated to each word is the
geometric mean of the frequencies for the word
in the original vectors:
</listItem>
<bodyText confidence="0.902214538461539">
}&apos; n 0 In |Y }&apos; 1/111 n C In |1/111 n
.I &apos;Ll� , @i=1 YZ/ I..., i=1 Y V / 1
AC
3. Apply the X2 test as a weighting function test to
measure whether the query and the contextual
feature are conditionally independent.
4. Given two queries, use the cosine between their
vectors to calculate their similarity.
The motivations for this approach are: the geo-
metric mean is a way to approximate a boolean AND
operation between the vectors, while at the same
time keeping track of the magnitude of the frequen-
cies. Therefore, if two queries only differ on a very
general word, e.g. [books] and either [buy books]
or [some books], the vector associated to the general
words (buy or some in the example) will have non-
zero values for most of the contextual features, be-
cause they are not topically constrained; and the vec-
tors for the queries will have similar sets of features
with non-zero values. Equally relevant, terms that
are closely related will appear in the proximity of a
similar set of words and will have similar vectors.
For example, if the two queries are Sir Arthur Co-
nan Doyle books and Sir Arthur Conan Doyle nov-
els, given that the vectors for books and novels are
expected to have similar features, these two queries
</bodyText>
<figure confidence="0.967013166666667">
0
B @
~qv =
0
Y|n|
@i=1
</figure>
<page confidence="0.96016">
30
</page>
<table confidence="0.998702777777778">
Contextual word acid fast bacteria Query
acidogenicity 11 6 4 6.41506
auramin 2 5 2 2.71441
bacillae 3 10 4 4.93242
carbolfuchsin 1 28 2 8.24257
dehydrogena 5 3 3 3.55689
diphtheroid 5 9 92 16.05709
fuchsine 42 3 4 7.95811
glycosilation 3 2 3 2.62074
</table>
<tableCaption confidence="0.999931">
Table 1: Example of context words for the query [acid fast bacteria].
</tableCaption>
<bodyText confidence="0.999539">
will receive a high similarity score.
On the other hand, this combination also helps in
reducing word ambiguity. Consider the query bank
account; the bag-of-words vector for bank will con-
tain words related to the various senses of the word,
but when combining it to account only the terms that
belong to the financial domain and are shared be-
tween the two vectors will be included in the final
query vector.
Finally, we note that the geometric mean provides
a clean way to encode the pair-wise similarities of
the individual words of the phrase. One can inter-
pret the cosine similarity metric as the magnitude of
the vector constructed by the scalar product of the
individual vectors. Our approach scales this up by
taking the scalar product of the vectors for all words
in the phrase and then scaling them by the number of
words (i.e., the geometric mean). Instead of comput-
ing the magnitude of this vector, we use it to com-
pute similarities for the entire phrase.
As an example of the proposed procedure, Table 1
shows a random sample of the contextual features
collected for the words in the query [acid fast bac-
teria], and how the query’s vector is generated by
using the geometric mean of the frequencies of the
features in the vectors for the query words.
</bodyText>
<sectionHeader confidence="0.995189" genericHeader="evaluation">
4 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.974294">
4.1 Experimental settings
</subsectionHeader>
<bodyText confidence="0.999344875">
To collect the contextual features for words and
phrases, we have used a corpus of hundreds of mil-
lions of documents crawled from the Web in August
2008. An HTML parser is used to extract text and
non-English documents are discarded. After pro-
cess, the remaining corpus contains hundreds of bil-
lions of words.
As a source of keywords, we have used the top
</bodyText>
<table confidence="0.985791">
0 1 2 3 4
0 280 95 14 1 0
1 108 86 65 4 0
2 11 47 83 16 0
3 1 2 17 45 2
4 0 0 1 1 2
</table>
<tableCaption confidence="0.9943725">
Table 2: Confusion matrix for the pairs in the goldstandard. Rows
represent first rater scores, and columns second rater scores.
</tableCaption>
<bodyText confidence="0.999974179487179">
one and a half million English queries sent to the
Google search engine after being fully anonymized.
We have calculated the pairwise similarity between
all queries, which would potentially return 2.25 tril-
lion similarity scores, but in practice returns a much
smaller number as many pairs have non-overlapping
contexts.
As a baseline, we have used a new implementa-
tion of the Web Kernel similarity (Sahami and Heil-
man, 2006). The parameters are set the same as re-
ported in the paper with the exception of the snip-
pet size; in their study, the size was limited to 1,000
characters and in our system, the normal snippet re-
turned by Google is used (around 160 characters).
In order to evaluate our system, we prepared a
goldstandard set of query similarities. We have ran-
domly sampled 65 queries from our full dataset, and
obtained the top 20 suggestions from both the Sa-
hami system and the distributional similarities sys-
tem. Two human raters have rated the original query
and the union of the sets of suggestions, using the
same 5-point Likert scale that Sahami used. Table 2
shows the confusion matrix of scores between the
two raters. Most of the disagreements are between
the scores 0 and 1, which means that probably it was
not clear enough whether the queries were unrelated
or only slightly related. It is also noteworthy that
in this case, very few rewritten queries were clas-
sified as being better than the original, which also
suggests to us that probably we could remove the
topmost score from the classifications scale.
We have evaluated inter-judge agreement in the
following two ways: first, using the weighted Kappa
score, which has a value of 0.7111. Second, by
grouping the pairs judged as irrelevant or slightly
relevant (scores 0 and 1) as a class containing nega-
tive examples, and the pairs judged as very relevant,
equal or better (scores 2 through 4) as a class con-
taining positive examples. Using this two-class clas-
</bodyText>
<page confidence="0.999521">
31
</page>
<table confidence="0.99990375">
Method Prec@1 Prec@3 Prec@5 mAP AUC
Web Kernel 0.39 0.35 0.32 0.49 0.22
Unigrams 0.47 0.53 0.47 0.57 0.26
N-grams 0.70 0.57 0.52 0.71 0.54
</table>
<tableCaption confidence="0.985528">
Table 3: Results. mAP is mean average precision, and AUC is the
area under the precision/recall curve.
</tableCaption>
<bodyText confidence="0.986748166666667">
sification, Cohen’s Kappa score becomes 0.6171.
Both scores indicates substantial agreement amongst
the raters.
The data set thus collected is a ranked list of sug-
gestions for each query1, and can be used to evaluate
any other suggestion-ranking system.
</bodyText>
<subsectionHeader confidence="0.883395">
4.2 Experiments and results
</subsectionHeader>
<bodyText confidence="0.9999963">
As an evolution of the distributional similarities
approach, we also implemented a second version
where the queries are chunked into phrases. The
motivation for the second version is that, in some
queries, like [new york cheap hotel], it makes sense
to handle new york as a single phrase with a sin-
gle associated context vector collected from the web
corpus. The list of valid n-grams is collected by
combining several metrics, e.g. whether Wikipedia
contains an entry with that name, or whether they
appear quoted in query logs. The queries are then
chunked greedily always preferring the longer n-
gram from our list.
Table 3 shows the results of trying both systems
on the same set of queries. The original system is
the one called Unigrams, and the one that chunks
the queries is the one called N-grams. The distri-
butional similarity approaches outperform the web-
based kernel on all the metrics, and chunking queries
shows a good improvement over using unigrams.
</bodyText>
<sectionHeader confidence="0.999442" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999980666666667">
This paper extends the vector-space model of dis-
tributional similarities to query-to-query similarities
by combining different vectors using the geometric
mean. We show that using n-grams to chunk the
queries improves the results significantly. This out-
performs the web-based kernel method, a state-of-
the-art unsupervised query-to-query similarity tech-
nique, which is particularly relevant as the corpus-
based method does not benefit automatically from
</bodyText>
<footnote confidence="0.605354">
1We plan to make it available to the research community.
</footnote>
<note confidence="0.537265">
search engine features.
</note>
<sectionHeader confidence="0.853811" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998578961538461">
S. Bordag. 2008. A Comparison of Co-occurrence and
Similarity Measures as Simulations of Context. Lec-
ture Notes in Computer Science, 4919:52.
J.R. Firth. 1957. A synopsis of linguistic theory 1930-
1955. Studies in Linguistic Analysis, pages 1–32.
G. Grefenstette. 1992. Use of syntactic context to pro-
duce term association lists for text retrieval. In Pro-
ceedings of the 15th annual international ACM SI-
GIR conference on Research and development in infor-
mation retrieval, pages 89–97. ACM New York, NY,
USA.
R. Jones, B. Rey, O. Madani, and W. Greiner. 2006. Gen-
erating query substitutions. In Proceedings of the 15th
international conference on World Wide Web, pages
387–396. ACM New York, NY, USA.
Reiner Kraft and Jason Zien. 2004. Mining anchor text
for query refinement. In WWW ’04: Proceedings of
the 13th international conference on World Wide Web,
pages 666–674, New York, NY, USA. ACM.
D. Lin. 1998. Extracting Collocations from Text Cor-
pora. In First Workshop on Computational Terminol-
ogy, pages 57–63.
Stefan Riezler, Yi Liu, and Alexander Vasserman.
2008. Translating Queries into Snippets for Improved
Query Expansion. In Proceedings of the 22nd In-
ternational Conference on Computational Linguistics
(COLING’08).
E. Riloff and J. Shepherd. 1997. A corpus-based ap-
proach for building semantic lexicons. In Proceed-
ings of the Second Conference on Empirical Methods
in Natural Language Processing, pages 117–124. As-
sociation for Computational Linguistics.
M. Sahami and T.D. Heilman. 2006. A web-based ker-
nel function for measuring the similarity of short text
snippets. In Proceedings of the 15th international con-
ference on World Wide Web, pages 377–386.
G. Salton, A. Wong, and CS Yang. 1975. A vector space
model for automatic indexing. Communications of the
ACM, 18(11):613–620.
Egidio Terra and Charles L.A. Clarke. 2004. Scoring
missing terms in information retrieval tasks. In CIKM
’04: Proceedings of the thirteenth ACM international
conference on Information and knowledge manage-
ment, pages 50–58, New York, NY, USA. ACM.
W. Yih and C. Meek. 2007. Improving Similarity Mea-
sures for Short Segments of Text. In Proceedings of
the Natural Conference on Artificial Intelligence, vol-
ume 2, page 1489. Menlo Park, CA; Cambridge, MA;
London; AAAI Press; MIT Press; 1999.
W. Yih and C. Meek. 2008. Consistent Phrase Relevance
Measures. Data Mining and Audience Intelligence for
Advertising (ADKDD 2008), page 37.
</reference>
<page confidence="0.999288">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.595361">
<title confidence="0.999983">Large-scale Computation of Distributional Similarities for Queries</title>
<author confidence="0.998911">Enrique Alfonseca Keith Hall</author>
<affiliation confidence="0.998829">Google Research Google Research</affiliation>
<address confidence="0.902544">Zurich, Switzerland Zurich, Switzerland</address>
<email confidence="0.998217">ealfonseca@google.comkbhall@google.com</email>
<author confidence="0.945868">Silvana</author>
<affiliation confidence="0.999412">University of</affiliation>
<address confidence="0.701302">Stuttgart,</address>
<email confidence="0.998439">silvana.hartmann@ims.uni-stuttgart.de</email>
<abstract confidence="0.999921615384615">We present a large-scale, data-driven approach to computing distributional similarity scores for queries. We contrast this to recent webbased techniques which either require the offline computation of complete phrase vectors, or an expensive on-line interaction with a search engine interface. Independent of the computational advantages of our approach, we show empirically that our technique is more effective at ranking query alternatives that the computationally more expensive technique of using the results from a web search engine.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bordag</author>
</authors>
<title>A Comparison of Co-occurrence and Similarity Measures as Simulations of Context.</title>
<date>2008</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>4919--52</pages>
<contexts>
<context position="2072" citStr="Bordag, 2008" startWordPosition="297" endWordPosition="298">g similarity between queries using corpus-based unsupervised methods. Given a query q, we would like to rank all other queries according to their similarity to q. The proposed approach compares favorably to a state-of-the-art unsupervised system. 29 2 Related work Distributional similarity methods model the similarity or relatedness of words using a metric defined over the set of contexts in which the words appear (Firth, 1957). One of the most common representations for contexts is the vector space model (Salton et al., 1975). This is the basic idea of approaches such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different</context>
</contexts>
<marker>Bordag, 2008</marker>
<rawString>S. Bordag. 2008. A Comparison of Co-occurrence and Similarity Measures as Simulations of Context. Lecture Notes in Computer Science, 4919:52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Firth</author>
</authors>
<title>A synopsis of linguistic theory 1930-1955. Studies in Linguistic Analysis,</title>
<date>1957</date>
<pages>1--32</pages>
<contexts>
<context position="1891" citStr="Firth, 1957" startWordPosition="266" endWordPosition="267">ckly; and for sponsored search, where advertisers bid for keywords that may be different but semantically equivalent to user queries. In this paper, we study the problem of measuring similarity between queries using corpus-based unsupervised methods. Given a query q, we would like to rank all other queries according to their similarity to q. The proposed approach compares favorably to a state-of-the-art unsupervised system. 29 2 Related work Distributional similarity methods model the similarity or relatedness of words using a metric defined over the set of contexts in which the words appear (Firth, 1957). One of the most common representations for contexts is the vector space model (Salton et al., 1975). This is the basic idea of approaches such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactical</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>J.R. Firth. 1957. A synopsis of linguistic theory 1930-1955. Studies in Linguistic Analysis, pages 1–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
</authors>
<title>Use of syntactic context to produce term association lists for text retrieval.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>89--97</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2058" citStr="Grefenstette, 1992" startWordPosition="295" endWordPosition="296"> problem of measuring similarity between queries using corpus-based unsupervised methods. Given a query q, we would like to rank all other queries according to their similarity to q. The proposed approach compares favorably to a state-of-the-art unsupervised system. 29 2 Related work Distributional similarity methods model the similarity or relatedness of words using a metric defined over the set of contexts in which the words appear (Firth, 1957). One of the most common representations for contexts is the vector space model (Salton et al., 1975). This is the basic idea of approaches such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking</context>
</contexts>
<marker>Grefenstette, 1992</marker>
<rawString>G. Grefenstette. 1992. Use of syntactic context to produce term association lists for text retrieval. In Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval, pages 89–97. ACM New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jones</author>
<author>B Rey</author>
<author>O Madani</author>
<author>W Greiner</author>
</authors>
<title>Generating query substitutions.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th international conference on World Wide Web,</booktitle>
<pages>387--396</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2649" citStr="Jones et al., 2006" startWordPosition="383" endWordPosition="386"> such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different anchor texts pointing to the same pages (Kraft and Zien, 2004), or replacing query words with other words that have the highest pointwise mutual information (Terra and Clarke, 2004). Sahami and Helman (Sahami and Heilman, 2006) define a web kernel function for semantic similarity based on the snippets of the search results returned by the queries. The algorithm used is the following: (a) Issue a query x to a search engine and collect the set of n snippets returned by the search engine; (b) Compute the tf·idf vector vi for each document snippet di; (c) Truncate each vect</context>
</contexts>
<marker>Jones, Rey, Madani, Greiner, 2006</marker>
<rawString>R. Jones, B. Rey, O. Madani, and W. Greiner. 2006. Generating query substitutions. In Proceedings of the 15th international conference on World Wide Web, pages 387–396. ACM New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reiner Kraft</author>
<author>Jason Zien</author>
</authors>
<title>Mining anchor text for query refinement.</title>
<date>2004</date>
<booktitle>In WWW ’04: Proceedings of the 13th international conference on World Wide Web,</booktitle>
<pages>666--674</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2735" citStr="Kraft and Zien, 2004" startWordPosition="397" endWordPosition="400">ith some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different anchor texts pointing to the same pages (Kraft and Zien, 2004), or replacing query words with other words that have the highest pointwise mutual information (Terra and Clarke, 2004). Sahami and Helman (Sahami and Heilman, 2006) define a web kernel function for semantic similarity based on the snippets of the search results returned by the queries. The algorithm used is the following: (a) Issue a query x to a search engine and collect the set of n snippets returned by the search engine; (b) Compute the tf·idf vector vi for each document snippet di; (c) Truncate each vector to include its m Proceedings of NAACL HLT 2009: Short Papers, pages 29–32, Boulder,</context>
</contexts>
<marker>Kraft, Zien, 2004</marker>
<rawString>Reiner Kraft and Jason Zien. 2004. Mining anchor text for query refinement. In WWW ’04: Proceedings of the 13th international conference on World Wide Web, pages 666–674, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Extracting Collocations from Text Corpora.</title>
<date>1998</date>
<booktitle>In First Workshop on Computational Terminology,</booktitle>
<pages>57--63</pages>
<contexts>
<context position="2083" citStr="Lin, 1998" startWordPosition="299" endWordPosition="300">etween queries using corpus-based unsupervised methods. Given a query q, we would like to rank all other queries according to their similarity to q. The proposed approach compares favorably to a state-of-the-art unsupervised system. 29 2 Related work Distributional similarity methods model the similarity or relatedness of words using a metric defined over the set of contexts in which the words appear (Firth, 1957). One of the most common representations for contexts is the vector space model (Salton et al., 1975). This is the basic idea of approaches such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different anchor tex</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Extracting Collocations from Text Corpora. In First Workshop on Computational Terminology, pages 57–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Yi Liu</author>
<author>Alexander Vasserman</author>
</authors>
<title>Translating Queries into Snippets for Improved Query Expansion.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING’08).</booktitle>
<contexts>
<context position="2598" citStr="Riezler et al., 2008" startWordPosition="375" endWordPosition="378">n et al., 1975). This is the basic idea of approaches such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different anchor texts pointing to the same pages (Kraft and Zien, 2004), or replacing query words with other words that have the highest pointwise mutual information (Terra and Clarke, 2004). Sahami and Helman (Sahami and Heilman, 2006) define a web kernel function for semantic similarity based on the snippets of the search results returned by the queries. The algorithm used is the following: (a) Issue a query x to a search engine and collect the set of n snippets returned by the search engine; (b) Compute the tf·idf vector vi f</context>
</contexts>
<marker>Riezler, Liu, Vasserman, 2008</marker>
<rawString>Stefan Riezler, Yi Liu, and Alexander Vasserman. 2008. Translating Queries into Snippets for Improved Query Expansion. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Shepherd</author>
</authors>
<title>A corpus-based approach for building semantic lexicons.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>117--124</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2111" citStr="Riloff and Shepherd, 1997" startWordPosition="301" endWordPosition="304">ies using corpus-based unsupervised methods. Given a query q, we would like to rank all other queries according to their similarity to q. The proposed approach compares favorably to a state-of-the-art unsupervised system. 29 2 Related work Distributional similarity methods model the similarity or relatedness of words using a metric defined over the set of contexts in which the words appear (Firth, 1957). One of the most common representations for contexts is the vector space model (Salton et al., 1975). This is the basic idea of approaches such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different anchor texts pointing to the same page</context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>E. Riloff and J. Shepherd. 1997. A corpus-based approach for building semantic lexicons. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pages 117–124. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahami</author>
<author>T D Heilman</author>
</authors>
<title>A web-based kernel function for measuring the similarity of short text snippets.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th international conference on World Wide Web,</booktitle>
<pages>377--386</pages>
<contexts>
<context position="2900" citStr="Sahami and Heilman, 2006" startWordPosition="423" endWordPosition="426">rity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different anchor texts pointing to the same pages (Kraft and Zien, 2004), or replacing query words with other words that have the highest pointwise mutual information (Terra and Clarke, 2004). Sahami and Helman (Sahami and Heilman, 2006) define a web kernel function for semantic similarity based on the snippets of the search results returned by the queries. The algorithm used is the following: (a) Issue a query x to a search engine and collect the set of n snippets returned by the search engine; (b) Compute the tf·idf vector vi for each document snippet di; (c) Truncate each vector to include its m Proceedings of NAACL HLT 2009: Short Papers, pages 29–32, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics highest weighted terms; (d) Construct the centroid of the L2-normalized vectors vi; (e) Calcul</context>
<context position="10412" citStr="Sahami and Heilman, 2006" startWordPosition="1752" endWordPosition="1756">80 95 14 1 0 1 108 86 65 4 0 2 11 47 83 16 0 3 1 2 17 45 2 4 0 0 1 1 2 Table 2: Confusion matrix for the pairs in the goldstandard. Rows represent first rater scores, and columns second rater scores. one and a half million English queries sent to the Google search engine after being fully anonymized. We have calculated the pairwise similarity between all queries, which would potentially return 2.25 trillion similarity scores, but in practice returns a much smaller number as many pairs have non-overlapping contexts. As a baseline, we have used a new implementation of the Web Kernel similarity (Sahami and Heilman, 2006). The parameters are set the same as reported in the paper with the exception of the snippet size; in their study, the size was limited to 1,000 characters and in our system, the normal snippet returned by Google is used (around 160 characters). In order to evaluate our system, we prepared a goldstandard set of query similarities. We have randomly sampled 65 queries from our full dataset, and obtained the top 20 suggestions from both the Sahami system and the distributional similarities system. Two human raters have rated the original query and the union of the sets of suggestions, using the s</context>
</contexts>
<marker>Sahami, Heilman, 2006</marker>
<rawString>M. Sahami and T.D. Heilman. 2006. A web-based kernel function for measuring the similarity of short text snippets. In Proceedings of the 15th international conference on World Wide Web, pages 377–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>A Wong</author>
<author>CS Yang</author>
</authors>
<title>A vector space model for automatic indexing.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<contexts>
<context position="1992" citStr="Salton et al., 1975" startWordPosition="282" endWordPosition="285">semantically equivalent to user queries. In this paper, we study the problem of measuring similarity between queries using corpus-based unsupervised methods. Given a query q, we would like to rank all other queries according to their similarity to q. The proposed approach compares favorably to a state-of-the-art unsupervised system. 29 2 Related work Distributional similarity methods model the similarity or relatedness of words using a metric defined over the set of contexts in which the words appear (Firth, 1957). One of the most common representations for contexts is the vector space model (Salton et al., 1975). This is the basic idea of approaches such as (Grefenstette, 1992; Bordag, 2008; Lin, 1998; Riloff and Shepherd, 1997), with some variations; e.g., whether syntactic information is used explicitly, or which weight function is applied. Most of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al.,</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>G. Salton, A. Wong, and CS Yang. 1975. A vector space model for automatic indexing. Communications of the ACM, 18(11):613–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Egidio Terra</author>
<author>Charles L A Clarke</author>
</authors>
<title>Scoring missing terms in information retrieval tasks.</title>
<date>2004</date>
<booktitle>In CIKM ’04: Proceedings of the thirteenth ACM international conference on Information and knowledge management,</booktitle>
<pages>50--58</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2854" citStr="Terra and Clarke, 2004" startWordPosition="416" endWordPosition="419">t of the existing work has focused on similarity between single words or syntactically-correct multiword expressions. In this work, we adapt these techniques to calculate similarity metrics between pairs of complete queries, which may or may not be syntactically correct. Other approaches for query similarity use statistical translation models (Riezler et al., 2008), analysing search engine logs (Jones et al., 2006), looking for different anchor texts pointing to the same pages (Kraft and Zien, 2004), or replacing query words with other words that have the highest pointwise mutual information (Terra and Clarke, 2004). Sahami and Helman (Sahami and Heilman, 2006) define a web kernel function for semantic similarity based on the snippets of the search results returned by the queries. The algorithm used is the following: (a) Issue a query x to a search engine and collect the set of n snippets returned by the search engine; (b) Compute the tf·idf vector vi for each document snippet di; (c) Truncate each vector to include its m Proceedings of NAACL HLT 2009: Short Papers, pages 29–32, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics highest weighted terms; (d) Construct the centro</context>
</contexts>
<marker>Terra, Clarke, 2004</marker>
<rawString>Egidio Terra and Charles L.A. Clarke. 2004. Scoring missing terms in information retrieval tasks. In CIKM ’04: Proceedings of the thirteenth ACM international conference on Information and knowledge management, pages 50–58, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Yih</author>
<author>C Meek</author>
</authors>
<title>Improving Similarity Measures for Short Segments of Text.</title>
<date>2007</date>
<booktitle>In Proceedings of the Natural Conference on Artificial Intelligence,</booktitle>
<volume>2</volume>
<pages>1489</pages>
<publisher>AAAI Press; MIT Press;</publisher>
<location>Menlo Park, CA; Cambridge, MA; London;</location>
<contexts>
<context position="3683" citStr="Yih and Meek, 2007" startWordPosition="554" endWordPosition="557">Issue a query x to a search engine and collect the set of n snippets returned by the search engine; (b) Compute the tf·idf vector vi for each document snippet di; (c) Truncate each vector to include its m Proceedings of NAACL HLT 2009: Short Papers, pages 29–32, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics highest weighted terms; (d) Construct the centroid of the L2-normalized vectors vi; (e) Calculate the similarity of two queries as the dot product of their L2-normalized vectors, i.e. as the cosine of both vectors. This work was followed up by Yih and Meek (Yih and Meek, 2007), who combine the web kernel with other simple metrics of similarity between word vectors (Dice Coefficient, Jaccard Coefficient, Overlap, Cosine, KL Divergence) in a machine learning system to provide a ranking of similar queries. 3 Proposed method Using a search engine to collect snippets (Sahami and Heilman, 2006; Yih and Meek, 2007; Yih and Meek, 2008) takes advantage of all the optimizations performed by the retrieval engine (spelling correction, relevance scores, etc.), but it has several disadvantages: first, it is not repeatable, as the code underlying search engines is in a constant s</context>
</contexts>
<marker>Yih, Meek, 2007</marker>
<rawString>W. Yih and C. Meek. 2007. Improving Similarity Measures for Short Segments of Text. In Proceedings of the Natural Conference on Artificial Intelligence, volume 2, page 1489. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Yih</author>
<author>C Meek</author>
</authors>
<title>Consistent Phrase Relevance Measures. Data Mining and Audience Intelligence for Advertising (ADKDD</title>
<date>2008</date>
<pages>37</pages>
<contexts>
<context position="4041" citStr="Yih and Meek, 2008" startWordPosition="612" endWordPosition="615"> terms; (d) Construct the centroid of the L2-normalized vectors vi; (e) Calculate the similarity of two queries as the dot product of their L2-normalized vectors, i.e. as the cosine of both vectors. This work was followed up by Yih and Meek (Yih and Meek, 2007), who combine the web kernel with other simple metrics of similarity between word vectors (Dice Coefficient, Jaccard Coefficient, Overlap, Cosine, KL Divergence) in a machine learning system to provide a ranking of similar queries. 3 Proposed method Using a search engine to collect snippets (Sahami and Heilman, 2006; Yih and Meek, 2007; Yih and Meek, 2008) takes advantage of all the optimizations performed by the retrieval engine (spelling correction, relevance scores, etc.), but it has several disadvantages: first, it is not repeatable, as the code underlying search engines is in a constant state of flux; secondly, it is usually very expensive to issue a large number of search requests; sometimes the APIs provided limit the number of requests. In this section, we describe a method which overcomes these drawbacks. The distributional methods we propose for calculating similarities between words and multiword expressions profit from the use of a </context>
</contexts>
<marker>Yih, Meek, 2008</marker>
<rawString>W. Yih and C. Meek. 2008. Consistent Phrase Relevance Measures. Data Mining and Audience Intelligence for Advertising (ADKDD 2008), page 37.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>