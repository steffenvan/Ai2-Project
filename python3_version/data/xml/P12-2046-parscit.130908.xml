<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.032050">
<title confidence="0.977939">
Coupling Label Propagation and Constraints for Temporal Fact Extraction
</title>
<author confidence="0.974707">
Yafang Wang, Maximilian Dylla, Marc Spaniol and Gerhard Weikum
</author>
<affiliation confidence="0.824017">
Max Planck Institute for Informatics, Saarbr¨ucken, Germany
</affiliation>
<email confidence="0.438344">
{ywang|mdylla|mspaniol|weikum}@mpi-inf.mpg.de
</email>
<sectionHeader confidence="0.976751" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999854666666667">
The Web and digitized text sources contain
a wealth of information about named entities
such as politicians, actors, companies, or cul-
tural landmarks. Extracting this information
has enabled the automated construction of large
knowledge bases, containing hundred millions
of binary relationships or attribute values about
these named entities. However, in reality most
knowledge is transient, i.e. changes over time,
requiring a temporal dimension in fact extrac-
tion. In this paper we develop a methodology
that combines label propagation with constraint
reasoning for temporal fact extraction. Label
propagation aggressively gathers fact candi-
dates, and an Integer Linear Program is used
to clean out false hypotheses that violate tem-
poral constraints. Our method is able to im-
prove on recall while keeping up with preci-
sion, which we demonstrate by experiments
with biography-style Wikipedia pages and a
large corpus of news articles.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994075918918919">
In recent years, automated fact extraction from Web
contents has seen significant progress with the emer-
gence of freely available knowledge bases, such as
DBpedia (Auer et al., 2007), YAGO (Suchanek et
al., 2007), TextRunner (Etzioni et al., 2008), or
ReadTheWeb (Carlson et al., 2010a). These knowl-
edge bases are constantly growing and contain cur-
rently (by example of DBpedia) several million enti-
ties and half a billion facts about them. This wealth
of data allows to satisfy the information needs of
advanced Internet users by raising queries from key-
words to entities. This enables queries like “Who is
married to Prince Charles?” or “Who are the team-
mates of Lionel Messi at FC Barcelona?”.
However, factual knowledge is highly ephemeral:
Royals get married and divorced, politicians hold
positions only for a limited time and soccer players
transfer from one club to another. Consequently,
knowledge bases should be able to support more
sophisticated temporal queries at entity-level, such
as “Who have been the spouses of Prince Charles
before 2000?” or “Who are the teammates of Lionel
Messi at FC Barcelona in the season 2011/2012?”.
In order to achieve this goal, the next big step is to
distill temporal knowledge from the Web.
Extracting temporal facts is a complex and time-
consuming endeavor. There are “conservative” strate-
gies that aim at high precision, but they tend to suffer
from low recall. On the contrary, there are “aggres-
sive” approaches that target at high recall, but fre-
quently suffer from low precision. To this end, we
introduce a method that allows us to gain maximum
benefit from both “worlds” by “aggressively” gath-
ering fact candidates and subsequently “cleaning-up”
the incorrect ones. The salient properties of our ap-
proach and the novel contributions of this paper are
the following:
</bodyText>
<listItem confidence="0.994750888888889">
• A temporal fact extraction strategy that is able
to efficiently gather thousands of fact candidates
based on a handful of seed facts.
• An ILP solver incorporating constraints on tem-
poral relations among events (e.g., marriage of
a person must be non-overlapping in time).
• Experiments on real world news and Wikipedia
articles showing that we gain recall while keep-
ing up with precision.
</listItem>
<sectionHeader confidence="0.999294" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.995422666666667">
Recently, there have been several approaches that
aim at the extraction of temporal facts for the auto-
mated construction of large knowledge bases, but
</bodyText>
<page confidence="0.982093">
233
</page>
<note confidence="0.6829255">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 233–237,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999927833333333">
time-aware fact extraction is still in its infancy. An
approach toward fact extraction based on coupled
semi-supervised learning for information extraction
(IE) is NELL (Carlson et al., 2010b). However, it
does neither incorporate constraints nor temporal-
ity. TIE (Ling and Weld, 2010) binds time-points
of events described in sentences, but does not dis-
ambiguate entities or combine observations to facts.
A pattern-based approach for temporal fact extrac-
tion is PRAVDA (Wang et al., 2011), which utilizes
label propagation as a semi-supervised learning strat-
egy, but does not incorporate constraints. Similarly,
TOB is an approach of extracting temporal business-
related facts from free text, which requires deep pars-
ing and does not apply constraints as well (Zhang et
al., 2008). In contrast, CoTS (Talukdar et al., 2012)
introduces a constraint-based approach of coupled
semi-supervised learning for IE, however not focus-
ing on the extraction part. Building on TimeML
(Pustejovsky et al., 2003) several works (Verhagen et
al., 2005; Mani et al., 2006; Chambers and Jurafsky,
2008; Verhagen et al., 2009; Yoshikawa et al., 2009)
identify temporal relationships in free text, but don’t
focus on fact extraction.
</bodyText>
<sectionHeader confidence="0.997621" genericHeader="method">
3 Framework
</sectionHeader>
<bodyText confidence="0.99924275">
Facts and Observations. We aim to extract factual
knowledge transient over time from free text. More
specifically, we assume time T = [0,T�... ] to
be a finite sequence of time-points with yearly
granularity. Furthermore, a fact consists of a
relation with two typed arguments and a time-
interval defining its validity. For instance, we write
worksForClub(Beckham, RMadrid)@[2003, 2008)
to express that Beckham played for Real Madrid
from 2003 to 2007. Since sentences containing a
fact and its full time-interval are sparse, we consider
three kinds of textual observations for each relation,
namely begin, during, and end. “Beckham signed
for Real Madrid from Manchester United in 2003.”
includes both the begin observation of Beckham be-
ing with Real Madrid as well as the end observation
of working for Manchester. A positive seed fact is a
valid fact of a relation, while a negative seed fact is
incorrect (e.g., for relation worksForClub, a positive
seed fact is worksForClub(Beckham, RMadrid),
while worksForClub(Beckham, BMunich) is a
negative seed fact).
Framework. As depicted in Figure 1, our framework
is composed of four stages, where the first collects
candidate sentences, the second mines patterns from
the candidates sentences, the third extracts temporal
facts from the sentences utilizing the patterns and the
last removes noisy facts by enforcing constraints.
Preprocessing. We retrieve all sentences from the
corpus comprising at least two entities and a temporal
expression, where we use YAGO for entity recogni-
tion and disambiguation (cf. (Hoffart et al., 2011)).
</bodyText>
<figureCaption confidence="0.999514">
Figure 1: System Overview
</figureCaption>
<bodyText confidence="0.998925266666667">
Pattern Analysis. A pattern is a n-gram based fea-
ture vector. It is generated by replacing entities
by their types, keeping only stemmed nouns, verbs
converted to present tense and the last preposition.
For example, considering “Beckham signed for Real
Madrid from Manchester United in 2003.” the cor-
responding pattern for the end occurrence is “sign
for CLUB from”. We quantify the strength of each
pattern by investigating how frequent the pattern oc-
curs with seed facts of a particular relation and how
infrequent it appears with negative seed facts.
Fact Candidate Gathering. Entity pairs that co-
occur with patterns whose strength is above a mini-
mum threshold become fact candidates and are fed
into the next stage of label propagation.
</bodyText>
<sectionHeader confidence="0.995172" genericHeader="method">
4 T-Fact Extraction
</sectionHeader>
<bodyText confidence="0.9998135">
Building on (Wang et al., 2011) we utilize Label
Propagation (Talukdar and Crammer, 2009) to deter-
mine the relation and observation type expressed by
each pattern.
Graph. We create a graph G = (VFOVP, £) having
one vertex v E VF for each fact candidate observed
in the text and one vertex v E VP for each pattern.
Edges between VF and VP are introduced whenever a
fact candidate appeared with a pattern. Their weight
is derived from the co-occurrence frequency. Edges
</bodyText>
<page confidence="0.986242">
234
</page>
<bodyText confidence="0.999695727272727">
among VP nodes have weights derived from the n-
gram overlap of the patterns.
Labels. Moreover, we use one label for each observa-
tion type (begin, during, and end) of each relation and
a dummy label representing the unknown relation.
Objective Function. Let Y ∈ R|V|×|Labels |de-
note the graph’s initial label assignment, and Yb ∈
R|V|×|Labels |stand for the estimated labels of all ver-
tices, Sl encode the seed’s weights on its diagonal,
and R∗l contain zeroes except for the dummy label’s
column. Then, the objective function is:
</bodyText>
<equation confidence="0.978077333333333">
&amp;quot; #
(Y*` − bY*`)T S`(Yb*` − Y*`) 1
+µ1bY T*`LbY*` + µ2kY*` − R*` k2 ( )
</equation>
<bodyText confidence="0.979348333333333">
ensures that the estimated labels approximate the
Here, the first term (Y∗t − bY∗t)T St(Y∗t − bY∗t)
initial labels. The labeling of neighboring vertices
bYT ∗tLbY∗t, where L refers to the
is smoothed by µ1
Laplacian matrix. The last term is a L2 regularizer.
</bodyText>
<sectionHeader confidence="0.907535" genericHeader="method">
5 Cleaning of Fact Candidates
</sectionHeader>
<bodyText confidence="0.999960538461538">
To prune noisy t-facts, we compute a consistent sub-
set of t-facts with respect to temporal constraints (e.g.
joining a sports club takes place before leaving a
sports club) by an Integer Linear Program (ILP).
Variables. We introduce a variable xr ∈ {0, 1} for
each t-fact candidate r ∈ R, where 1 means the can-
didate is valid. Two variables xf,b, xf,e ∈ [0, T.a�]
denote begin (b) and end (e) of time-interval of a fact
f ∈ F. Note, that many t-fact candidates refer to the
same fact f, since they share their entity pairs.
Objective Function. The objective function intends
to maximize the number of valid raw t-facts, where
wr is a weight obtained from the previous stage:
</bodyText>
<equation confidence="0.9302815">
Xmax wr · xr
rER
</equation>
<bodyText confidence="0.99494">
Intra-Fact Constraints. xf,b and xf,e encode a
proper time-interval by adding the constraint:
</bodyText>
<equation confidence="0.55462">
∀f ∈ F xf,b &lt; xf,e
</equation>
<bodyText confidence="0.999957">
Considering only a single relation, we assume the
sets Rb, Rd, and Re to comprise its t-fact candidates
with respect to the begin, during, and end observa-
tions. Then, we introduce the constraints
</bodyText>
<equation confidence="0.97373">
∀l ∈ {b, e}, r ∈ Rl tl · xr ≤ xf,l (2)
∀l ∈ {b, e}, r ∈ Rl xf,l ≤ tl · xr + (1 − xr)Tmax (3)
∀r ∈ Rd xf,b ≤ tb · xr + (1 − xr)Tmax (4)
∀r ∈ Rd te · xr ≤ xf,e (5)
</equation>
<bodyText confidence="0.998549045454546">
where f has the same entity pair as r and tb, te are
begin and end of r’s time-interval. Whenever xr is
set to 1 for begin or end t-fact candidates, Eq. (2)
and Eq. (3) set the value of xf,b or xf,e to tb or te,
respectively. For each during t-fact candidate with
xr = 1, Eq. (4) and Eq. (5) enforce xf,b ≤ tb and
te ≤ xf,e.
Inter-Fact Constraints. Since we can refer to a fact
f’s time interval by xf,b and xf,e and the connectives
of Boolean Logic can be encoded in ILPs (Karp,
1972), we can use all temporal constraints expressible
by Allen’s Interval Algebra (Allen, 1983) to specify
inter-fact constraints. For example, we leverage this
by prohibiting marriages of a single person from
overlapping in time.
Previous Work. In comparison to (Talukdar et al.,
2012), our ILP encoding is time-scale invariant. That
is, for the same data, if the granularity of T is
changed from months to seconds, for example, the
size of the ILP is not affected. Furthermore, because
we allow all relations of Allen’s Interval Algebra, we
support a richer class of temporal constraints.
</bodyText>
<sectionHeader confidence="0.999505" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999957368421053">
Corpus. Experiments are conducted in the soccer
and the celebrity domain by considering the works-
ForClub and isMarriedTo relation, respectively. For
each person in the “FIFA 100 list” and “Forbes 100
list” we retrieve their Wikipedia article. In addition,
we obtained about 80,000 documents for the soccer
domain and 370,000 documents for the celebrity do-
main from BBC, The Telegraph, Times Online and
ESPN by querying Google’s News Archive Search1
in the time window from 1990-2011. All hyperpa-
rameters are tuned on a separate data-set.
Seeds. For each relation we manually select the 10
positive and negative fact candidates with highest
occurrence frequencies in the corpus as seeds.
Evaluation. We evaluate precision by randomly sam-
pling 50 (isMarriedTo) and 100 (worksForClub) facts
for each observation type and manually evaluating
them against the text documents. All experimental
data is available for download from our website2.
</bodyText>
<subsectionHeader confidence="0.980014">
6.1 Pipeline vs. Joint Model
</subsectionHeader>
<bodyText confidence="0.998685">
Setting. In this experiment we compare the perfor-
mance of the pipeline being stages 3 and 4 in Figure
</bodyText>
<footnote confidence="0.9705535">
1news.google.com/archivesearch
2www.mpi-inf.mpg.de/yago-naga/pravda/
</footnote>
<equation confidence="0.84306375">
X
bY) =
`
L(
</equation>
<page confidence="0.99443">
235
</page>
<bodyText confidence="0.9959815">
1 and a joint model in form of an ILP solving the
t-fact extraction and noise cleaning at the same time.
Hence, the joint model resembles (Roth and Yih,
2004) extended by Section 5’s temporal constraints.
</bodyText>
<table confidence="0.999776285714286">
Relation Observation Label Propagation ILP for T-Fact Extraction
Precision # Obs. Precision # Obs.
worksForClub begin 80% 2537 81% 2426 Without Noise Cleaning
during 78% 2826 86% 1153
end 65% 440 50% 550
isMarried7o begin 52% 195 28% 232
during 76% 92 6% 466
end 62% 50 2% 551
worksForClub begin 85% 2469 87% 2076 With Noise Cleaning
during 85% 2761 79% 1434
end 74% 403 72% 275
isMarried7o begin 64% 177 74% 67
during 79% 89 88% 61
end 70% 47 71% 28
</table>
<tableCaption confidence="0.999912">
Table 1: Pipeline vs. Joint Model
</tableCaption>
<bodyText confidence="0.999949222222222">
Results. Table 1 shows the results on the pipeline
model (lower-left), joint model (lower-right), label-
propagation w/o noise cleaning (upper-left), and ILP
for t-fact extraction w/o noise cleaning (upper-right).
Analysis. Regarding the upper part of Table 1 the
pattern-based extraction works very well for works-
ForClub, however it fails on isMarriedTo. The reason
is, that the types of worksForClub distinguish the
patterns well from other relations. In contrast, isMar-
riedTo’s patterns interfere with other person-person
relations making constraints a decisive asset. When
comparing the joint model and the pipeline model,
the former sacrifices recall in order to keep up with
the latter’s precision level. That is because the joint
model’s ILP decides with binary variables on which
patterns to accept. In contrast, label propagation ad-
dresses the inherent uncertainty by providing label
assignments with confidence numbers.
</bodyText>
<subsectionHeader confidence="0.999733">
6.2 Increasing Recall
</subsectionHeader>
<bodyText confidence="0.97084196">
Setting. In a second experiment, we move the t-fact
extraction stage away from high precision towards
higher recall, where the successive noise cleaning
stage attempts to restore the precision level.
Results. The columns of Table 2 show results for
different values of µ1 of Eq. (1). From left to right,
we used µ1 = e−1, 0.6, 0.8 for worksForClub and
µ1 = e−2, e−1 ,0.6 for isMarriedTo. The table’s up-
per part reports on the output of stage 3, whereas the
lower part covers the facts returned by noise cleaning.
Analysis. For the conservative setting label propa-
gation produces high precision facts with only few
inconsistencies, so the noise cleaning stage has no
effect, i.e. no pruning takes place. This is the set-
ting usual pattern-based approaches without cleaning
stage are working in. In contrast, for the standard set-
ting (coinciding with Table 1’s left column) stage 3
yields less precision, but higher recall. Since there are
more inconsistencies in this setup, the noise cleaning
stage accomplishes precision gains compensating for
the losses in the previous stage. In the relaxed setting
precision drops too low, so the noise cleaning stage is
unable to figure out the truly correct facts. In general,
the effects on worksForClub are weaker, since in this
relation the constraints are less influential.
</bodyText>
<table confidence="0.999661928571428">
Conservative Standard Relaxed
Prec. # Obs. Prec. # Obs. Prec. # Obs.
worksForClub begin 83% 2443 80% 2537 80% 2608 Without Noise Cleaning
during 81% 2523 78% 2826 76% 2928
end 77% 377 65% 440 62% 501
isMarried7o begin 72% 112 52% 195 44% 269
during 90% 63 76% 92 52% 187
end 67% 37 62% 50 36% 116
worksForClub begin 83% 2389 85% 2469 84% 2536 With Noise Cleaning
during 88% 2474 85% 2761 75% 2861
end 79% 349 72% 403 70% 463
isMarried7o begin 72% 111 64% 177 46% 239
during 90% 62 79% 89 54% 177
end 69% 36 68% 47 38% 110
</table>
<tableCaption confidence="0.998903">
Table 2: Increasing Recall.
</tableCaption>
<sectionHeader confidence="0.983507" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.996739444444445">
In this paper we have developed a method that com-
bines label propagation with constraint reasoning
for temporal fact extraction. Our experiments have
shown that best results can be achieved by applying
“aggressive” label propagation with a subsequent ILP
for “clean-up”. By coupling both approaches we
achieve both high(er) precision and high(er) recall.
Thus, our method efficiently extracts high quality
temporal facts at large scale.
</bodyText>
<page confidence="0.997014">
236
</page>
<sectionHeader confidence="0.996528" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9995188">
This work is supported by the 7th Framework IST
programme of the European Union through the fo-
cused research project (STREP) on Longitudinal An-
alytics of Web Archive data (LAWA) under contract
no. 258105.
</bodyText>
<sectionHeader confidence="0.998526" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99983968367347">
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Commun. ACM, 26(11):832–843,
November.
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, and Zachary Ives. 2007. Dbpedia: A nu-
cleus for a web of open data. In In 6th Intl Semantic
Web Conference, Busan, Korea, pages 11–15. Springer.
Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr
Settles, Estevam R. Hruschka Jr., and Tom M. Mitchell.
2010a. Toward an architecture for never-ending lan-
guage learning. In AAAI, pages 1306–1313.
Andrew Carlson, Justin Betteridge, Richard C. Wang, Es-
tevam R. Hruschka Jr., and Tom M. Mitchell. 2010b.
Coupled semi-supervised learning for information ex-
traction. In Proceedings of the Third ACM Interna-
tional Conference on Web Search and Data Mining
(WSDM 2010).
Nathanael Chambers and Daniel Jurafsky. 2008. Jointly
combining implicit constraints improves temporal or-
dering. In EMNLP, pages 698–706.
Oren Etzioni, Michele Banko, Stephen Soderland, and
Daniel S. Weld. 2008. Open information extraction
from the web. Commun. ACM, 51(12):68–74, Decem-
ber.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino,
Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Ste-
fan Thater, and Gerhard Weikum. 2011. Robust disam-
biguation of named entities in text. In Proc. of EMNLP
2011: Conference on Empirical Methods in Natural
Language Processing, Edinburgh, Scotland, UK, July
2731, pages 782–792.
Richard M. Karp. 1972. Reducibility among combinato-
rial problems. In Complexity of Computer Computa-
tions, pages 85–103.
Xiao Ling and Daniel S. Weld. 2010. Temporal infor-
mation extraction. In Proceedings of the AAAI 2010
Conference, pages 1385 – 1390, Atlanta, Georgia, USA,
July 11-15. Association for the Advancement of Artifi-
cial Intelligence.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine learning
of temporal relations. In In ACL-06, pages 17–18.
James Pustejovsky, Jos´e M. Casta˜no, Robert Ingria, Roser
Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham
Katz, and Dragomir R. Radev. 2003. TimeML: Robust
specification of event and temporal expressions in text.
In New Directions in Question Answering, pages 28–
34.
Dan Roth and Wen-Tau Yih, 2004. A Linear Programming
Formulation for Global Inference in Natural Language
Tasks, pages 1–8.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowledge.
In WWW ’07: Proceedings of the 16th International
Conference on World Wide Web, pages 697–706, New
York, NY, USA. ACM.
Partha Pratim Talukdar and Koby Crammer. 2009. New
regularized algorithms for transductive learning. In
Proceedings of the European Conference on Machine
Learning and Knowledge Discovery in Databases: Part
II, ECML PKDD ’09, pages 442–457, Berlin, Heidel-
berg. Springer-Verlag.
Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell.
2012. Coupled temporal scoping of relational facts.
In Proceedings of the Fifth ACM International Confer-
ence on Web Search and Data Mining (WSDM), Seattle,
Washington, USA, February. Association for Comput-
ing Machinery.
Marc Verhagen, Inderjeet Mani, Roser Sauri, Robert Knip-
pen, Seok Bae Jang, Jessica Littman, Anna Rumshisky,
John Phillips, and James Pustejovsky. 2005. Automat-
ing temporal annotation with TARSQI. In ACL ’05:
Proceedings of the ACL 2005 on Interactive poster and
demonstration sessions, pages 81–84, Morristown, NJ,
USA. Association for Computational Linguistics.
Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark
Hepple, Jessica Moszkowicz, and James Pustejovsky.
2009. The tempeval challenge: identifying temporal
relations in text. Language Resources and Evaluation,
43:161–179.
Yafang Wang, Bin Yang, Lizhen Qu, Marc Spaniol, and
Gerhard Weikum. 2011. Harvesting facts from textual
web sources by constrained label propagation. In Pro-
ceedings of the 20th ACM international conference on
Information and knowledge management, CIKM ’11,
pages 837–846, New York, NY, USA. ACM.
Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-
hara, and Yuji Matsumoto. 2009. Jointly identifying
temporal relations with markov logic. In Proceedings
of the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Volume 1
- Volume 1, ACL ’09, pages 405–413, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Qi Zhang, Fabian Suchanek, and Gerhard Weikum. 2008.
TOB: Timely ontologies for business relations. In 11th
International Workshop on Web and Databases 2008
(WebDB 2008), Vancouver, Canada. ACM.
</reference>
<page confidence="0.997377">
237
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.556116">
<title confidence="0.781246">Coupling Label Propagation and Constraints for Temporal Fact Extraction Yafang Wang, Maximilian Dylla, Marc Spaniol and Gerhard</title>
<author confidence="0.988999">Max Planck Institute for Informatics</author>
<author confidence="0.988999">Saarbr¨ucken</author>
<abstract confidence="0.999631454545455">The Web and digitized text sources contain a wealth of information about named entities such as politicians, actors, companies, or cultural landmarks. Extracting this information has enabled the automated construction of large knowledge bases, containing hundred millions of binary relationships or attribute values about these named entities. However, in reality most knowledge is transient, i.e. changes over time, requiring a temporal dimension in fact extraction. In this paper we develop a methodology that combines label propagation with constraint reasoning for temporal fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Commun. ACM,</journal>
<volume>26</volume>
<issue>11</issue>
<contexts>
<context position="10477" citStr="Allen, 1983" startWordPosition="1723" endWordPosition="1724">Tmax (4) ∀r ∈ Rd te · xr ≤ xf,e (5) where f has the same entity pair as r and tb, te are begin and end of r’s time-interval. Whenever xr is set to 1 for begin or end t-fact candidates, Eq. (2) and Eq. (3) set the value of xf,b or xf,e to tb or te, respectively. For each during t-fact candidate with xr = 1, Eq. (4) and Eq. (5) enforce xf,b ≤ tb and te ≤ xf,e. Inter-Fact Constraints. Since we can refer to a fact f’s time interval by xf,b and xf,e and the connectives of Boolean Logic can be encoded in ILPs (Karp, 1972), we can use all temporal constraints expressible by Allen’s Interval Algebra (Allen, 1983) to specify inter-fact constraints. For example, we leverage this by prohibiting marriages of a single person from overlapping in time. Previous Work. In comparison to (Talukdar et al., 2012), our ILP encoding is time-scale invariant. That is, for the same data, if the granularity of T is changed from months to seconds, for example, the size of the ILP is not affected. Furthermore, because we allow all relations of Allen’s Interval Algebra, we support a richer class of temporal constraints. 6 Experiments Corpus. Experiments are conducted in the soccer and the celebrity domain by considering th</context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>James F. Allen. 1983. Maintaining knowledge about temporal intervals. Commun. ACM, 26(11):832–843, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: A nucleus for a web of open data. In</title>
<date>2007</date>
<booktitle>In 6th Intl Semantic Web Conference, Busan, Korea,</booktitle>
<pages>11--15</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1384" citStr="Auer et al., 2007" startWordPosition="194" endWordPosition="197">ines label propagation with constraint reasoning for temporal fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles. 1 Introduction In recent years, automated fact extraction from Web contents has seen significant progress with the emergence of freely available knowledge bases, such as DBpedia (Auer et al., 2007), YAGO (Suchanek et al., 2007), TextRunner (Etzioni et al., 2008), or ReadTheWeb (Carlson et al., 2010a). These knowledge bases are constantly growing and contain currently (by example of DBpedia) several million entities and half a billion facts about them. This wealth of data allows to satisfy the information needs of advanced Internet users by raising queries from keywords to entities. This enables queries like “Who is married to Prince Charles?” or “Who are the teammates of Lionel Messi at FC Barcelona?”. However, factual knowledge is highly ephemeral: Royals get married and divorced, poli</context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. In In 6th Intl Semantic Web Conference, Busan, Korea, pages 11–15. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Bryan Kisiel</author>
<author>Burr Settles</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Toward an architecture for never-ending language learning.</title>
<date>2010</date>
<booktitle>In AAAI,</booktitle>
<pages>1306--1313</pages>
<contexts>
<context position="1486" citStr="Carlson et al., 2010" startWordPosition="210" endWordPosition="213">ressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles. 1 Introduction In recent years, automated fact extraction from Web contents has seen significant progress with the emergence of freely available knowledge bases, such as DBpedia (Auer et al., 2007), YAGO (Suchanek et al., 2007), TextRunner (Etzioni et al., 2008), or ReadTheWeb (Carlson et al., 2010a). These knowledge bases are constantly growing and contain currently (by example of DBpedia) several million entities and half a billion facts about them. This wealth of data allows to satisfy the information needs of advanced Internet users by raising queries from keywords to entities. This enables queries like “Who is married to Prince Charles?” or “Who are the teammates of Lionel Messi at FC Barcelona?”. However, factual knowledge is highly ephemeral: Royals get married and divorced, politicians hold positions only for a limited time and soccer players transfer from one club to another. C</context>
<context position="3969" citStr="Carlson et al., 2010" startWordPosition="608" endWordPosition="611">cles showing that we gain recall while keeping up with precision. 2 Related Work Recently, there have been several approaches that aim at the extraction of temporal facts for the automated construction of large knowledge bases, but 233 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 233–237, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics time-aware fact extraction is still in its infancy. An approach toward fact extraction based on coupled semi-supervised learning for information extraction (IE) is NELL (Carlson et al., 2010b). However, it does neither incorporate constraints nor temporality. TIE (Ling and Weld, 2010) binds time-points of events described in sentences, but does not disambiguate entities or combine observations to facts. A pattern-based approach for temporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In cont</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka Jr., and Tom M. Mitchell. 2010a. Toward an architecture for never-ending language learning. In AAAI, pages 1306–1313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Richard C Wang</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Coupled semi-supervised learning for information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the Third ACM International Conference on Web Search and Data Mining (WSDM</booktitle>
<contexts>
<context position="1486" citStr="Carlson et al., 2010" startWordPosition="210" endWordPosition="213">ressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles. 1 Introduction In recent years, automated fact extraction from Web contents has seen significant progress with the emergence of freely available knowledge bases, such as DBpedia (Auer et al., 2007), YAGO (Suchanek et al., 2007), TextRunner (Etzioni et al., 2008), or ReadTheWeb (Carlson et al., 2010a). These knowledge bases are constantly growing and contain currently (by example of DBpedia) several million entities and half a billion facts about them. This wealth of data allows to satisfy the information needs of advanced Internet users by raising queries from keywords to entities. This enables queries like “Who is married to Prince Charles?” or “Who are the teammates of Lionel Messi at FC Barcelona?”. However, factual knowledge is highly ephemeral: Royals get married and divorced, politicians hold positions only for a limited time and soccer players transfer from one club to another. C</context>
<context position="3969" citStr="Carlson et al., 2010" startWordPosition="608" endWordPosition="611">cles showing that we gain recall while keeping up with precision. 2 Related Work Recently, there have been several approaches that aim at the extraction of temporal facts for the automated construction of large knowledge bases, but 233 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 233–237, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics time-aware fact extraction is still in its infancy. An approach toward fact extraction based on coupled semi-supervised learning for information extraction (IE) is NELL (Carlson et al., 2010b). However, it does neither incorporate constraints nor temporality. TIE (Ling and Weld, 2010) binds time-points of events described in sentences, but does not disambiguate entities or combine observations to facts. A pattern-based approach for temporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In cont</context>
</contexts>
<marker>Carlson, Betteridge, Wang, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Richard C. Wang, Estevam R. Hruschka Jr., and Tom M. Mitchell. 2010b. Coupled semi-supervised learning for information extraction. In Proceedings of the Third ACM International Conference on Web Search and Data Mining (WSDM 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Jointly combining implicit constraints improves temporal ordering.</title>
<date>2008</date>
<booktitle>In EMNLP,</booktitle>
<pages>698--706</pages>
<contexts>
<context position="4862" citStr="Chambers and Jurafsky, 2008" startWordPosition="745" endWordPosition="748">tion is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verhagen et al., 2009; Yoshikawa et al., 2009) identify temporal relationships in free text, but don’t focus on fact extraction. 3 Framework Facts and Observations. We aim to extract factual knowledge transient over time from free text. More specifically, we assume time T = [0,T�... ] to be a finite sequence of time-points with yearly granularity. Furthermore, a fact consists of a relation with two typed arguments and a timeinterval defining its validity. For instance, we write worksForClub(Beckham, RMadrid)@[2003, 2008) to express that Beckham played for Real Madrid from 2003 to 2007. Since</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Daniel Jurafsky. 2008. Jointly combining implicit constraints improves temporal ordering. In EMNLP, pages 698–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michele Banko</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2008</date>
<journal>Commun. ACM,</journal>
<volume>51</volume>
<issue>12</issue>
<contexts>
<context position="1449" citStr="Etzioni et al., 2008" startWordPosition="204" endWordPosition="207">fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles. 1 Introduction In recent years, automated fact extraction from Web contents has seen significant progress with the emergence of freely available knowledge bases, such as DBpedia (Auer et al., 2007), YAGO (Suchanek et al., 2007), TextRunner (Etzioni et al., 2008), or ReadTheWeb (Carlson et al., 2010a). These knowledge bases are constantly growing and contain currently (by example of DBpedia) several million entities and half a billion facts about them. This wealth of data allows to satisfy the information needs of advanced Internet users by raising queries from keywords to entities. This enables queries like “Who is married to Prince Charles?” or “Who are the teammates of Lionel Messi at FC Barcelona?”. However, factual knowledge is highly ephemeral: Royals get married and divorced, politicians hold positions only for a limited time and soccer players</context>
</contexts>
<marker>Etzioni, Banko, Soderland, Weld, 2008</marker>
<rawString>Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S. Weld. 2008. Open information extraction from the web. Commun. ACM, 51(12):68–74, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP 2011: Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>782--792</pages>
<location>Edinburgh, Scotland, UK,</location>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Stefan Thater, and Gerhard Weikum. 2011. Robust disambiguation of named entities in text. In Proc. of EMNLP 2011: Conference on Empirical Methods in Natural Language Processing, Edinburgh, Scotland, UK, July 2731, pages 782–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard M Karp</author>
</authors>
<title>Reducibility among combinatorial problems.</title>
<date>1972</date>
<journal>In Complexity of Computer Computations,</journal>
<pages>85--103</pages>
<contexts>
<context position="10386" citStr="Karp, 1972" startWordPosition="1710" endWordPosition="1711">2) ∀l ∈ {b, e}, r ∈ Rl xf,l ≤ tl · xr + (1 − xr)Tmax (3) ∀r ∈ Rd xf,b ≤ tb · xr + (1 − xr)Tmax (4) ∀r ∈ Rd te · xr ≤ xf,e (5) where f has the same entity pair as r and tb, te are begin and end of r’s time-interval. Whenever xr is set to 1 for begin or end t-fact candidates, Eq. (2) and Eq. (3) set the value of xf,b or xf,e to tb or te, respectively. For each during t-fact candidate with xr = 1, Eq. (4) and Eq. (5) enforce xf,b ≤ tb and te ≤ xf,e. Inter-Fact Constraints. Since we can refer to a fact f’s time interval by xf,b and xf,e and the connectives of Boolean Logic can be encoded in ILPs (Karp, 1972), we can use all temporal constraints expressible by Allen’s Interval Algebra (Allen, 1983) to specify inter-fact constraints. For example, we leverage this by prohibiting marriages of a single person from overlapping in time. Previous Work. In comparison to (Talukdar et al., 2012), our ILP encoding is time-scale invariant. That is, for the same data, if the granularity of T is changed from months to seconds, for example, the size of the ILP is not affected. Furthermore, because we allow all relations of Allen’s Interval Algebra, we support a richer class of temporal constraints. 6 Experiments</context>
</contexts>
<marker>Karp, 1972</marker>
<rawString>Richard M. Karp. 1972. Reducibility among combinatorial problems. In Complexity of Computer Computations, pages 85–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Temporal information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the AAAI 2010 Conference,</booktitle>
<pages>1385--1390</pages>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="4064" citStr="Ling and Weld, 2010" startWordPosition="622" endWordPosition="625">e have been several approaches that aim at the extraction of temporal facts for the automated construction of large knowledge bases, but 233 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 233–237, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics time-aware fact extraction is still in its infancy. An approach toward fact extraction based on coupled semi-supervised learning for information extraction (IE) is NELL (Carlson et al., 2010b). However, it does neither incorporate constraints nor temporality. TIE (Ling and Weld, 2010) binds time-points of events described in sentences, but does not disambiguate entities or combine observations to facts. A pattern-based approach for temporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-super</context>
</contexts>
<marker>Ling, Weld, 2010</marker>
<rawString>Xiao Ling and Daniel S. Weld. 2010. Temporal information extraction. In Proceedings of the AAAI 2010 Conference, pages 1385 – 1390, Atlanta, Georgia, USA, July 11-15. Association for the Advancement of Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Marc Verhagen</author>
<author>Ben Wellner</author>
<author>Chong Min Lee</author>
<author>James Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>In In ACL-06,</booktitle>
<pages>17--18</pages>
<contexts>
<context position="4833" citStr="Mani et al., 2006" startWordPosition="741" endWordPosition="744">emporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verhagen et al., 2009; Yoshikawa et al., 2009) identify temporal relationships in free text, but don’t focus on fact extraction. 3 Framework Facts and Observations. We aim to extract factual knowledge transient over time from free text. More specifically, we assume time T = [0,T�... ] to be a finite sequence of time-points with yearly granularity. Furthermore, a fact consists of a relation with two typed arguments and a timeinterval defining its validity. For instance, we write worksForClub(Beckham, RMadrid)@[2003, 2008) to express that Beckham played for Real Ma</context>
</contexts>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine learning of temporal relations. In In ACL-06, pages 17–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e M Casta˜no</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert J Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
<author>Dragomir R Radev</author>
</authors>
<title>TimeML: Robust specification of event and temporal expressions in text.</title>
<date>2003</date>
<booktitle>In New Directions in Question Answering,</booktitle>
<pages>28--34</pages>
<marker>Pustejovsky, Casta˜no, Ingria, Sauri, Gaizauskas, Setzer, Katz, Radev, 2003</marker>
<rawString>James Pustejovsky, Jos´e M. Casta˜no, Robert Ingria, Roser Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham Katz, and Dragomir R. Radev. 2003. TimeML: Robust specification of event and temporal expressions in text. In New Directions in Question Answering, pages 28– 34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-Tau Yih</author>
</authors>
<title>A Linear Programming Formulation for Global Inference in Natural Language Tasks,</title>
<date>2004</date>
<pages>1--8</pages>
<contexts>
<context position="12300" citStr="Roth and Yih, 2004" startWordPosition="2009" endWordPosition="2012">ion. We evaluate precision by randomly sampling 50 (isMarriedTo) and 100 (worksForClub) facts for each observation type and manually evaluating them against the text documents. All experimental data is available for download from our website2. 6.1 Pipeline vs. Joint Model Setting. In this experiment we compare the performance of the pipeline being stages 3 and 4 in Figure 1news.google.com/archivesearch 2www.mpi-inf.mpg.de/yago-naga/pravda/ X bY) = ` L( 235 1 and a joint model in form of an ILP solving the t-fact extraction and noise cleaning at the same time. Hence, the joint model resembles (Roth and Yih, 2004) extended by Section 5’s temporal constraints. Relation Observation Label Propagation ILP for T-Fact Extraction Precision # Obs. Precision # Obs. worksForClub begin 80% 2537 81% 2426 Without Noise Cleaning during 78% 2826 86% 1153 end 65% 440 50% 550 isMarried7o begin 52% 195 28% 232 during 76% 92 6% 466 end 62% 50 2% 551 worksForClub begin 85% 2469 87% 2076 With Noise Cleaning during 85% 2761 79% 1434 end 74% 403 72% 275 isMarried7o begin 64% 177 74% 67 during 79% 89 88% 61 end 70% 47 71% 28 Table 1: Pipeline vs. Joint Model Results. Table 1 shows the results on the pipeline model (lower-left</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>Dan Roth and Wen-Tau Yih, 2004. A Linear Programming Formulation for Global Inference in Natural Language Tasks, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In WWW ’07: Proceedings of the 16th International Conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1414" citStr="Suchanek et al., 2007" startWordPosition="199" endWordPosition="202">h constraint reasoning for temporal fact extraction. Label propagation aggressively gathers fact candidates, and an Integer Linear Program is used to clean out false hypotheses that violate temporal constraints. Our method is able to improve on recall while keeping up with precision, which we demonstrate by experiments with biography-style Wikipedia pages and a large corpus of news articles. 1 Introduction In recent years, automated fact extraction from Web contents has seen significant progress with the emergence of freely available knowledge bases, such as DBpedia (Auer et al., 2007), YAGO (Suchanek et al., 2007), TextRunner (Etzioni et al., 2008), or ReadTheWeb (Carlson et al., 2010a). These knowledge bases are constantly growing and contain currently (by example of DBpedia) several million entities and half a billion facts about them. This wealth of data allows to satisfy the information needs of advanced Internet users by raising queries from keywords to entities. This enables queries like “Who is married to Prince Charles?” or “Who are the teammates of Lionel Messi at FC Barcelona?”. However, factual knowledge is highly ephemeral: Royals get married and divorced, politicians hold positions only fo</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In WWW ’07: Proceedings of the 16th International Conference on World Wide Web, pages 697–706, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Koby Crammer</author>
</authors>
<title>New regularized algorithms for transductive learning.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II, ECML PKDD ’09,</booktitle>
<pages>442--457</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="7465" citStr="Talukdar and Crammer, 2009" startWordPosition="1154" endWordPosition="1157">ring “Beckham signed for Real Madrid from Manchester United in 2003.” the corresponding pattern for the end occurrence is “sign for CLUB from”. We quantify the strength of each pattern by investigating how frequent the pattern occurs with seed facts of a particular relation and how infrequent it appears with negative seed facts. Fact Candidate Gathering. Entity pairs that cooccur with patterns whose strength is above a minimum threshold become fact candidates and are fed into the next stage of label propagation. 4 T-Fact Extraction Building on (Wang et al., 2011) we utilize Label Propagation (Talukdar and Crammer, 2009) to determine the relation and observation type expressed by each pattern. Graph. We create a graph G = (VFOVP, £) having one vertex v E VF for each fact candidate observed in the text and one vertex v E VP for each pattern. Edges between VF and VP are introduced whenever a fact candidate appeared with a pattern. Their weight is derived from the co-occurrence frequency. Edges 234 among VP nodes have weights derived from the ngram overlap of the patterns. Labels. Moreover, we use one label for each observation type (begin, during, and end) of each relation and a dummy label representing the unk</context>
</contexts>
<marker>Talukdar, Crammer, 2009</marker>
<rawString>Partha Pratim Talukdar and Koby Crammer. 2009. New regularized algorithms for transductive learning. In Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II, ECML PKDD ’09, pages 442–457, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Derry Wijaya</author>
<author>Tom Mitchell</author>
</authors>
<title>Coupled temporal scoping of relational facts.</title>
<date>2012</date>
<booktitle>In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining (WSDM),</booktitle>
<publisher>Association for Computing Machinery.</publisher>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="4603" citStr="Talukdar et al., 2012" startWordPosition="706" endWordPosition="709"> it does neither incorporate constraints nor temporality. TIE (Ling and Weld, 2010) binds time-points of events described in sentences, but does not disambiguate entities or combine observations to facts. A pattern-based approach for temporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verhagen et al., 2009; Yoshikawa et al., 2009) identify temporal relationships in free text, but don’t focus on fact extraction. 3 Framework Facts and Observations. We aim to extract factual knowledge transient over time from free text. More specifically, we assume time T = [0,T�... ] to be a finite sequence of time-points with yearly gr</context>
<context position="10668" citStr="Talukdar et al., 2012" startWordPosition="1750" endWordPosition="1753">es, Eq. (2) and Eq. (3) set the value of xf,b or xf,e to tb or te, respectively. For each during t-fact candidate with xr = 1, Eq. (4) and Eq. (5) enforce xf,b ≤ tb and te ≤ xf,e. Inter-Fact Constraints. Since we can refer to a fact f’s time interval by xf,b and xf,e and the connectives of Boolean Logic can be encoded in ILPs (Karp, 1972), we can use all temporal constraints expressible by Allen’s Interval Algebra (Allen, 1983) to specify inter-fact constraints. For example, we leverage this by prohibiting marriages of a single person from overlapping in time. Previous Work. In comparison to (Talukdar et al., 2012), our ILP encoding is time-scale invariant. That is, for the same data, if the granularity of T is changed from months to seconds, for example, the size of the ILP is not affected. Furthermore, because we allow all relations of Allen’s Interval Algebra, we support a richer class of temporal constraints. 6 Experiments Corpus. Experiments are conducted in the soccer and the celebrity domain by considering the worksForClub and isMarriedTo relation, respectively. For each person in the “FIFA 100 list” and “Forbes 100 list” we retrieve their Wikipedia article. In addition, we obtained about 80,000 </context>
</contexts>
<marker>Talukdar, Wijaya, Mitchell, 2012</marker>
<rawString>Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell. 2012. Coupled temporal scoping of relational facts. In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining (WSDM), Seattle, Washington, USA, February. Association for Computing Machinery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Inderjeet Mani</author>
<author>Roser Sauri</author>
<author>Robert Knippen</author>
<author>Seok Bae Jang</author>
<author>Jessica Littman</author>
<author>Anna Rumshisky</author>
<author>John Phillips</author>
<author>James Pustejovsky</author>
</authors>
<title>Automating temporal annotation with TARSQI.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the ACL</booktitle>
<pages>81--84</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4814" citStr="Verhagen et al., 2005" startWordPosition="737" endWordPosition="740">rn-based approach for temporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verhagen et al., 2009; Yoshikawa et al., 2009) identify temporal relationships in free text, but don’t focus on fact extraction. 3 Framework Facts and Observations. We aim to extract factual knowledge transient over time from free text. More specifically, we assume time T = [0,T�... ] to be a finite sequence of time-points with yearly granularity. Furthermore, a fact consists of a relation with two typed arguments and a timeinterval defining its validity. For instance, we write worksForClub(Beckham, RMadrid)@[2003, 2008) to express that Beckham</context>
</contexts>
<marker>Verhagen, Mani, Sauri, Knippen, Jang, Littman, Rumshisky, Phillips, Pustejovsky, 2005</marker>
<rawString>Marc Verhagen, Inderjeet Mani, Roser Sauri, Robert Knippen, Seok Bae Jang, Jessica Littman, Anna Rumshisky, John Phillips, and James Pustejovsky. 2005. Automating temporal annotation with TARSQI. In ACL ’05: Proceedings of the ACL 2005 on Interactive poster and demonstration sessions, pages 81–84, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Jessica Moszkowicz</author>
<author>James Pustejovsky</author>
</authors>
<title>The tempeval challenge: identifying temporal relations in text. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--161</pages>
<contexts>
<context position="4885" citStr="Verhagen et al., 2009" startWordPosition="749" endWordPosition="752">2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verhagen et al., 2009; Yoshikawa et al., 2009) identify temporal relationships in free text, but don’t focus on fact extraction. 3 Framework Facts and Observations. We aim to extract factual knowledge transient over time from free text. More specifically, we assume time T = [0,T�... ] to be a finite sequence of time-points with yearly granularity. Furthermore, a fact consists of a relation with two typed arguments and a timeinterval defining its validity. For instance, we write worksForClub(Beckham, RMadrid)@[2003, 2008) to express that Beckham played for Real Madrid from 2003 to 2007. Since sentences containing a</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Moszkowicz, Pustejovsky, 2009</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Jessica Moszkowicz, and James Pustejovsky. 2009. The tempeval challenge: identifying temporal relations in text. Language Resources and Evaluation, 43:161–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yafang Wang</author>
<author>Bin Yang</author>
<author>Lizhen Qu</author>
<author>Marc Spaniol</author>
<author>Gerhard Weikum</author>
</authors>
<title>Harvesting facts from textual web sources by constrained label propagation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11,</booktitle>
<pages>837--846</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4269" citStr="Wang et al., 2011" startWordPosition="654" endWordPosition="657">utational Linguistics, pages 233–237, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics time-aware fact extraction is still in its infancy. An approach toward fact extraction based on coupled semi-supervised learning for information extraction (IE) is NELL (Carlson et al., 2010b). However, it does neither incorporate constraints nor temporality. TIE (Ling and Weld, 2010) binds time-points of events described in sentences, but does not disambiguate entities or combine observations to facts. A pattern-based approach for temporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verha</context>
<context position="7407" citStr="Wang et al., 2011" startWordPosition="1146" endWordPosition="1149">se and the last preposition. For example, considering “Beckham signed for Real Madrid from Manchester United in 2003.” the corresponding pattern for the end occurrence is “sign for CLUB from”. We quantify the strength of each pattern by investigating how frequent the pattern occurs with seed facts of a particular relation and how infrequent it appears with negative seed facts. Fact Candidate Gathering. Entity pairs that cooccur with patterns whose strength is above a minimum threshold become fact candidates and are fed into the next stage of label propagation. 4 T-Fact Extraction Building on (Wang et al., 2011) we utilize Label Propagation (Talukdar and Crammer, 2009) to determine the relation and observation type expressed by each pattern. Graph. We create a graph G = (VFOVP, £) having one vertex v E VF for each fact candidate observed in the text and one vertex v E VP for each pattern. Edges between VF and VP are introduced whenever a fact candidate appeared with a pattern. Their weight is derived from the co-occurrence frequency. Edges 234 among VP nodes have weights derived from the ngram overlap of the patterns. Labels. Moreover, we use one label for each observation type (begin, during, and en</context>
</contexts>
<marker>Wang, Yang, Qu, Spaniol, Weikum, 2011</marker>
<rawString>Yafang Wang, Bin Yang, Lizhen Qu, Marc Spaniol, and Gerhard Weikum. 2011. Harvesting facts from textual web sources by constrained label propagation. In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11, pages 837–846, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Katsumasa Yoshikawa</author>
<author>Sebastian Riedel</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Jointly identifying temporal relations with markov logic.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09,</booktitle>
<pages>405--413</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4910" citStr="Yoshikawa et al., 2009" startWordPosition="753" endWordPosition="756">abel propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verhagen et al., 2009; Yoshikawa et al., 2009) identify temporal relationships in free text, but don’t focus on fact extraction. 3 Framework Facts and Observations. We aim to extract factual knowledge transient over time from free text. More specifically, we assume time T = [0,T�... ] to be a finite sequence of time-points with yearly granularity. Furthermore, a fact consists of a relation with two typed arguments and a timeinterval defining its validity. For instance, we write worksForClub(Beckham, RMadrid)@[2003, 2008) to express that Beckham played for Real Madrid from 2003 to 2007. Since sentences containing a fact and its full time-i</context>
</contexts>
<marker>Yoshikawa, Riedel, Asahara, Matsumoto, 2009</marker>
<rawString>Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asahara, and Yuji Matsumoto. 2009. Jointly identifying temporal relations with markov logic. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09, pages 405–413, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Zhang</author>
<author>Fabian Suchanek</author>
<author>Gerhard Weikum</author>
</authors>
<title>TOB: Timely ontologies for business relations.</title>
<date>2008</date>
<booktitle>In 11th International Workshop on Web and Databases</booktitle>
<publisher>ACM.</publisher>
<location>Vancouver, Canada.</location>
<contexts>
<context position="4560" citStr="Zhang et al., 2008" startWordPosition="699" endWordPosition="702">s NELL (Carlson et al., 2010b). However, it does neither incorporate constraints nor temporality. TIE (Ling and Weld, 2010) binds time-points of events described in sentences, but does not disambiguate entities or combine observations to facts. A pattern-based approach for temporal fact extraction is PRAVDA (Wang et al., 2011), which utilizes label propagation as a semi-supervised learning strategy, but does not incorporate constraints. Similarly, TOB is an approach of extracting temporal businessrelated facts from free text, which requires deep parsing and does not apply constraints as well (Zhang et al., 2008). In contrast, CoTS (Talukdar et al., 2012) introduces a constraint-based approach of coupled semi-supervised learning for IE, however not focusing on the extraction part. Building on TimeML (Pustejovsky et al., 2003) several works (Verhagen et al., 2005; Mani et al., 2006; Chambers and Jurafsky, 2008; Verhagen et al., 2009; Yoshikawa et al., 2009) identify temporal relationships in free text, but don’t focus on fact extraction. 3 Framework Facts and Observations. We aim to extract factual knowledge transient over time from free text. More specifically, we assume time T = [0,T�... ] to be a fi</context>
</contexts>
<marker>Zhang, Suchanek, Weikum, 2008</marker>
<rawString>Qi Zhang, Fabian Suchanek, and Gerhard Weikum. 2008. TOB: Timely ontologies for business relations. In 11th International Workshop on Web and Databases 2008 (WebDB 2008), Vancouver, Canada. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>