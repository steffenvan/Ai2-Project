<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001006">
<title confidence="0.999612">
Japanese Dependency Parsing Using Co-occurrence Information and a
Combination of Case Elements
</title>
<author confidence="0.996266">
Takeshi Abekawa Manabu Okumura
</author>
<affiliation confidence="0.9984215">
Graduate School of Education Precision and Intelligence Laboratory
University of Tokyo Tokyo Institute of Technology
</affiliation>
<email confidence="0.99867">
abekawa@p.u-tokyo.ac.jp oku@pi.titech.ac.jp
</email>
<sectionHeader confidence="0.99389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999918368421053">
In this paper, we present a method that
improves Japanese dependency parsing by
using large-scale statistical information. It
takes into account two kinds of informa-
tion not considered in previous statistical
(machine learning based) parsing meth-
ods: information about dependency rela-
tions among the case elements of a verb,
and information about co-occurrence re-
lations between a verb and its case ele-
ment. This information can be collected
from the results of automatic dependency
parsing of large-scale corpora. The results
of an experiment in which our method was
used to rerank the results obtained using an
existing machine learning based parsing
method showed that our method can im-
prove the accuracy of the results obtained
using the existing method.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964385964912">
Dependency parsing is a basic technology for pro-
cessing Japanese and has been the subject of much
research. The Japanese dependency structure is
usually represented by the relationship between
phrasal units called bunsetsu, each of which con-
sists of one or more content words that may be
followed by any number of function words. The
dependency between two bunsetsus is direct from
a dependent to its head.
Manually written rules have usually been used
to determine which bunsetsu another bunsetsu
tends to modify, but this method poses problems in
terms of the coverage and consistency of the rules.
The recent availability of larger-scale corpora an-
notated with dependency information has thus re-
sulted in more work on statistical dependency
analysis technologies that use machine learning al-
gorithms (Kudo and Matsumoto, 2002; Sassano,
2004; Uchimoto et al., 1999; Uchimoto et al.,
2000).
Work on statistical Japanese dependency analy-
sis has usually assumed that all the dependency re-
lations in a sentence are independent of each other,
and has considered the bunsetsus in a sentence in-
dependently when judging whether or not a pair
of bunsetsus is in a dependency relation. In judg-
ing which bunsetsu a bunsetsu modifies, this type
of work has used as features the information of
two bunsetsus, such as the head words of the two
bunsetsus, and the morphemes at the ends of the
bunsetsus (Uchimoto et al., 1999). It is necessary,
however, to also consider features for the contex-
tual information of the two bunsetsus. One such
feature is the constraint that two case elements
with the same case do not modify a verb.
Statistical Japanese dependency analysis takes
into account syntactic information but tends not to
take into account lexical information, such as co-
occurrence between a case element and a verb.
The recent availability of more corpora has en-
abled much information about dependency rela-
tions to be obtained by using a Japanese depen-
dency analyzer such as KNP (Kurohashi and Na-
gao, 1994) or CaboCha (Kudo and Matsumoto,
2002). Although this information is less accu-
rate than manually annotated information, these
automatic analyzers provide a large amount of
co-occurrence information as well as information
about combinations of multiple cases that tend to
modify a verb.
In this paper, we present a method for improv-
ing the accuracy of Japanese dependency analy-
sis by representing the lexical information of co-
occurrence and dependency relations of multiple
cases as statistical models. We also show the re-
sults of experiments demonstrating the effective-
ness of our method.
</bodyText>
<page confidence="0.985764">
833
</page>
<note confidence="0.900323">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 833–840,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<figure confidence="0.623914666666667">
Keisatsu-de hitori-de umibe-de arui-teiru syonen-wo hogo-shita
(The police/subj) (alone) (on the beach) (was walking) (boy/obj) (had custody)
(The police had custody of the boy who was walking alone on the beach.)
</figure>
<figureCaption confidence="0.999917">
Figure 1: Example of a Japanese sentence, bunsetsu and dependencies
</figureCaption>
<sectionHeader confidence="0.891104" genericHeader="method">
2 Parsing Japanese
</sectionHeader>
<bodyText confidence="0.997265">
The Japanese language is basically an SOV lan-
guage, but word order is relatively free. In English
the syntactic function of each word is represented
by word order, while in Japanese it is represented
by postpositions. For example, one or more post-
positions following a noun play a role similar to
the declension of nouns in German, which indi-
cates grammatical case.
The syntax of a Japanese sentence is analyzed
by using segments, called bunsetsu, that usually
contain one or more content words like a noun,
verb, or adjective, and zero or more function
words like a particle (case marker) or verb/noun
suffix. By defining a bunsetsu in this manner, we
can analyze a sentence in a way similar to that used
when analyzing the grammatical roles of words in
inflected languages like German.
Japanese dependencies have the following char-
acteristics:
</bodyText>
<listItem confidence="0.9999348">
• Each bunsetsu except the rightmost one has
only one head.
• Each head bunsetsu is always placed to the
right of (i.e. after) its modifier.
• Dependencies do not cross one another.
</listItem>
<bodyText confidence="0.980959411764706">
Statistical Japanese dependency analyzers
(Kudo and Matsumoto, 2005; Kudo and Mat-
sumoto, 2002; Sassano, 2004; Uchimoto et al.,
1999; Uchimoto et al., 2000) automatically learn
the likelihood of dependencies from a tagged
corpus and calculate the best dependencies for an
input sentence. These likelihoods are learned by
considering the features of bunsetsus such as their
character strings, parts of speech, and inflection
types, as well as information between bunsetsus
such as punctuation and the distance between
bunsetsus. The weight of given features is learned
from a training corpus by calculating the weights
from the frequencies of the features in the training
data.
3 Japanese dependency analysis taking
account of co-occurrence information
and a combination of multiple cases
One constraint in Japanese is that multiple nouns
of the same case do not modify a verb. Previ-
ous work on Japanese dependency analysis has as-
sumed that all the dependency relations are inde-
pendent of one another. It is therefore necessary
to also consider such a constraint as a feature for
contextual information. Uchimoto et al., for ex-
ample, used as such a feature whether a particu-
lar type of bunsetsu is between two bunsetsus in a
dependency relation (Uchimoto et al., 1999), and
Sassano used information about what is just be-
fore and after the modifying bunsetsu and modi-
fyee bunsetsu (Sassano, 2004).
In the artificial example shown in Figure 1, it
is natural to consider that “keisatsu-de” will mod-
ify “hogo-shita”. Statistical Japanese dependency
analyzers (Uchimoto et al., 2000; Kudo and Mat-
sumoto, 2002), however, will output the result
where “keisatsu-de” modifies “arui-teiru”. This is
because in sentences without internal punctuation
a noun tends to modify the nearest verb, and these
analyzers do not take into account a combination
of multiple cases.
Another kind of information useful in depen-
dency analysis is the co-occurrence of a noun and
a verb, which indicates to what degree the noun
tends to modify the verb. In the above example,
the possible modifyees of “keisatsu-de” are “arui-
teiru” and “hogo-shita”. Taking into account in-
formation about the co-occurrence of “keisatsu-
de” and “arui-teiru” and of “keisatsu-de” and
“hogo-shita” makes it obvious that “keisatsu-de”
is more likely to modify “hogo-shita”.
</bodyText>
<page confidence="0.997203">
834
</page>
<bodyText confidence="0.999936">
In summary, we think that statistical Japanese
dependency analysis needs to take into account
at least two more kinds of information: the de-
pendency relation between multiple cases where
multiple nouns of the same case do not modify a
verb, and the co-occurrence of nouns and verbs.
One way to use such information in statistical de-
pendency analysis is to directly use it as features.
However, Kehler et al. pointed out that this does
not make the analysis more accurate (Kehler et al.,
2004). This paper therefore presents a model that
uses the co-occurrence information separately and
reranks the analysis candidates generated by the
existing machine learning model.
</bodyText>
<sectionHeader confidence="0.993922" genericHeader="method">
4 Our proposed model
</sectionHeader>
<bodyText confidence="0.956784739130435">
We first introduce the notation for the explanation
of the dependency structure T:
m(T) : the number of verbs in T
vz(T) : the i-th verb in T
cz(T) : the number of case elements that mod-
ify the i-th verb in T
esz(T) : the set of case elements that modify the
i-th verb in T
rsz(T) : the set of particles in the set of case el-
ements that modify the i-th verb in T
nsz(T) : the set of nouns in the set of case ele-
ments that modify the i-th verb in T
rz,j(T) : the j-th particle that modifies the i-th
verb in T
nz,j(T) : the j-th noun that modifies the i-th verb
in T
We defined case element as a pair of a noun
and following particles. For the dependency
structure we assume the conditional probability
P(esz(T)|vz(T)) that the set of case elements
esz(T) depends on the vz(T), and assume the set
of case elements esz(T) is composed of the set of
noun nsz(T) and particles rsz(T).
</bodyText>
<equation confidence="0.995654153846154">
P(esz(T)|vz(T))d�f = P(rsz(T),nsz(T)|vz(T)) (1)
= P(rsz(T)|vz(T)) ×
P(nsz(T)|rsz(T),vz(T)) (2)
&apos; P(rsz(T)|vz(T)) ×
ci(T)
∏
P(nz,j(T)|rsz(T),vz(T)) (3)
j=1
&apos; P(rsz(T)|vz(T)) ×
ci(T)
∏
P(nz,j(T)|rz,j(T),vz(T)) (4)
j=1
</equation>
<bodyText confidence="0.999861545454545">
In the transformation from Equation (2) to Equa-
tion (3), we assume that the set of noun nsz(T) is
independent of the verb vz(T). And in the trans-
formation from Equation (3) to Equation (4), we
assume that the noun nz,j(T) is dependent on only
its following particle rz,j(T).
Now we assume the dependency structure T of
the whole sentence is composed of only the depen-
dency relation between case elements and verbs,
and propose the sentence probability defined by
Equation (5).
</bodyText>
<equation confidence="0.999897">
P(rsz(T)|vz(T)) ×
P(nz,j(T)|rz,j(T),vz(T)) (5)
</equation>
<bodyText confidence="0.990519125">
We call P (rsz(T)|vz(T)) the co-occurrence prob-
ability of the particle set and the verb, and we
call P(nz,j(T)|rz,j(T), vz(T)) the co-occurrence
probability of the case element set and the verb.
In the actual dependency analysis, we try to se-
lect the dependency structure Tˆ that maximizes
the Equation (5) from the possible parses T for the
inputted sentence:
</bodyText>
<equation confidence="0.9987225">
P(rsz(T)|vz(T)) ×
ci(T)
∏ P(nz,j(T)|rz,j(T), vz(T)). (6)
j=1
</equation>
<bodyText confidence="0.999987272727273">
The proposed model is inspired by the semantic
role labeling method (Gildea and Jurafsky, 2002),
which uses the frame element group in place of the
particle set.
It differs from the previous parsing models in
that we take into account the dependency relations
among particles in the set of case elements that
modify a verb. This information can constrain the
combination of particles (cases) among bunsetsus
that modify a verb. Assuming the independence
among particles, we can rewrite Equation (5) as
</bodyText>
<equation confidence="0.911128">
P(nz,j(T),rz,j(T)|vz(T)). (7)
</equation>
<subsectionHeader confidence="0.993993">
4.1 Syntactic property of a verb
</subsectionHeader>
<bodyText confidence="0.999931333333333">
In Japanese, the “ha” case that indicates a topic
tends to modify the main verb in a sentence and
tends not to modify a verb in a relative clause. The
</bodyText>
<equation confidence="0.947350214285714">
P(T) = m(T)
∏
z=1
ci(T)
∏
j=1
Tˆ = argmax
T
m(T)
∏
z=1
P(T) = m(T) ci(T)
∏ ∏
z=1 j=1
</equation>
<page confidence="0.991864">
835
</page>
<table confidence="0.979686833333333">
verb: ‘aru-ku’ verb: ‘hogo-suru’ particle set
case elements particle set case elements
a keisatsu-de umibe-de hitori-de { de,de,de } syonen-wo {wo}
b umibe-de hitori-de {de,de} keisatsu-de syonen-wo {de,wo}
c hitori-de {de} keisatsu-de umibe-de syonen-wo {de,de,wo}
d {none} keisatsu-de umibe-de hitori-de syonen-wo { de,de,de,wo }
</table>
<tableCaption confidence="0.999596">
Table 1: Analytical process of the example sentence
</tableCaption>
<bodyText confidence="0.997588714285714">
co-occurrence probability of the particle set there-
fore tends to be different for verbs with different
syntactic properties.
Like (Shirai, 1998), to take into account the re-
liance of the co-occurrence probability of the par-
ticle set on the syntactic property of a verb, instead
of using P(rsi(T)|vi(T)) in Equation (5), we use
P(rsi(T)|syni(T), vi(T)), where syni(T) is the
syntactic property of the i-th verb in T and takes
one of the following three values:
‘verb’ when v modifies another verb
‘noun’ when v modifies a noun
‘main’ when v modifies nothing (when it is at the
end of the sentence, and is the main verb)
</bodyText>
<subsectionHeader confidence="0.993957">
4.2 Illustration of model application
</subsectionHeader>
<bodyText confidence="0.999989476190476">
Here, we illustrate the process of applying our pro-
posed model to the example sentence in Figure 1,
for which there are four possible combinations of
dependency relations. The bunsetsu combinations
and corresponding sets of particles are listed in Ta-
ble 1. In the analytical process, we calculate for
all the combinations the co-occurrence probability
of the case element set (bunsetsu set) and the co-
occurrence probability of the particle set, and we
select the Tˆ that maximizes the probability.
Some of the co-occurrence probabilities of the
particle sets for the verbs “aru-ku” and “hogo-
suru” in the sentence are listed in Table 2. How to
estimate these probabilities is described in section
5.3. Basically, the larger the number of particles,
the lower the probability is. As you can see in the
comparison between {de, wo} and {de, de}, the
probability becomes lower when multiple same
cases are included. Therefore, the probability can
reflect the constraint that multiple case elements
of the same particle tend not to modify a verb.
</bodyText>
<sectionHeader confidence="0.999673" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999634">
We evaluated the effectiveness of our model ex-
perimentally. Since our model treats only the de-
</bodyText>
<table confidence="0.998621769230769">
rsi P(rsi|noun, v1) P(rsiImain,v2)
v1 = “aru-ku” v2 = “hogo-suru”
{none} 0.29 0.35
{wo} 0.30 0.24
{ga} 0.056 0.072
{ni} 0.040 0.041
{de} 0.032 0.033
{ha} 0.035 0.041
{de, wo} 0.022 0.018
{de, de} 0.00038 0.00038
{de, de, wo} 0.00022 0.00018
{de, de, de} 0.0000019 0.0000018
{de, de, de, wo} 0.00000085 0.00000070
</table>
<tableCaption confidence="0.971246">
Table 2: Example of the co-occurrence probabili-
ties of particle sets
</tableCaption>
<bodyText confidence="0.999810285714286">
pendency relations between a noun and a verb, we
cannot determine all the dependency relations in
a sentence. We therefore use one of the currently
available dependency analyzers to generate an or-
dered list of n-best possible parses for the sentence
and then use our proposed model to rerank them
and select the best parse.
</bodyText>
<subsectionHeader confidence="0.991308">
5.1 Dependency analyzer for outputting
</subsectionHeader>
<bodyText confidence="0.9696647">
n-best parses
We generated the n-best parses by using the “pos-
terior context model” (Uchimoto et al., 2000). The
features we used were those in (Uchimoto et al.,
1999) and their combinations. We also added our
original features and their combinations, with ref-
erence to (Sassano, 2004; Kudo and Matsumoto,
2002), but we removed the features that had a fre-
quency of less than 30 in our training data. The
total number of features is thus 105,608.
</bodyText>
<subsectionHeader confidence="0.99727">
5.2 Reranking method
</subsectionHeader>
<bodyText confidence="0.9939065">
Because our model considers only the dependency
relations between a noun and a verb, and thus
cannot determine all the dependency relations in
a sentence, we restricted the possible parses for
</bodyText>
<page confidence="0.993337">
836
</page>
<bodyText confidence="0.999783818181818">
reranking as illustrated in Figure 2. The possi-
ble parses for reranking were the first-ranked parse
and those of the next-best parses in which the
verb to modify was different from that in the first-
ranked one. For example, parses 1 and 3 in Figure
2 are the only candidates for reranking. In our ex-
periments, n is set to 50.
The score we used for reranking the parses was
the product of the probability of the posterior con-
text model and the probability of our proposed
model:
</bodyText>
<equation confidence="0.827311">
score = Pcontext(T)α X P(T), (8)
</equation>
<bodyText confidence="0.999599666666667">
where Pcontext(T) is the probability of the poste-
rior context model. The α here is a parameter with
which we can adjust the balance of the two proba-
bilities, and is fixed to the best value by consider-
ing development data (different from the training
data)1.
</bodyText>
<figureCaption confidence="0.999528">
Figure 2: Selection of possible parses for reranking
</figureCaption>
<bodyText confidence="0.967224653846154">
Many methods for reranking the parsing of En-
glish sentences have been proposed (Charniak and
Johnson, 2005; Collins and Koo, 2005; Hender-
son and Titov, 2005), all of which are discrimina-
tive methods which learn the difference between
the best parse and next-best parses. While our
reranking model using generation probability is
quite simple, we can easily verify our hypothesis
that the two proposed probabilities have an effect
on improving the parsing accuracy. We can also
verify that the parsing accuracy improves by using
imprecise information obtained from an automati-
cally parsed corpus.
Klein and Manning proposed a generative
model in which syntactic (PCFG) and semantic
(lexical dependency) structures are scored with
separate models (Klein and Manning, 2002), but
1In our experiments, α is set to 2.0 using development
data.
they do not take into account the combination of
dependencies. Shirai et al. also proposed a statis-
tical model of Japanese language which integrates
lexical association statistics with syntactic prefer-
ence (Shirai et al., 1998). Our proposed model dif-
fers from their method in that it explicitly uses the
combination of multiple cases.
</bodyText>
<subsectionHeader confidence="0.999725">
5.3 Estimation of co-occurrence probability
</subsectionHeader>
<bodyText confidence="0.999957272727273">
We estimated the co-occurrence probability of the
particle set and the co-occurrence probability of
the case element set used in our model by analyz-
ing a large-scale corpus. We collected a 30-year
newspaper corpus2, applied the morphological an-
alyzer JUMAN (Kurohashi and Nagao, 1998b),
and then applied the dependency analyzer with
a posterior context model3. To ensure that we
collected reliable co-occurrence information, we
removed the information for the bunsetsus with
punctuation4.
</bodyText>
<listItem confidence="0.430074833333333">
Like (Torisawa, 2001), we estimated the co-
occurrence probability P((n, r, v)) of the case
element set (noun n, particle r, and verb v)
by using probabilistic latent semantic indexing
(PLSI) (Hofmann, 1999)5. If (n, r, v) is the
co-occurrence of n and (r, v), we can calculate
</listItem>
<equation confidence="0.915783666666667">
P((n, r, v)) by using the following equation:
∑P((n,r,v)) = P(n|z)P((r,v)|z)P(z), (9)
z∈Z
</equation>
<bodyText confidence="0.998752090909091">
where z indicates a latent semantic class of co-
occurrence (hidden class). Probabilistic parame-
ters P(n|z), P((r, v)|z), and P(z) in Equation (9)
can be estimated by using the EM algorithm. In
our experiments, the dimension of the hidden class
z was set to 300. As a result, the collected (n, r, v)
total 102,581,924 pairs. The number of n and v is
57,315 and 15,098, respectively.
The particles for which the co-occurrence prob-
ability was estimated were the set of case particles,
the “ha” case particle, and a class of “fukujoshi”
</bodyText>
<footnote confidence="0.99333425">
213 years’ worth of articles from the Mainichi Shimbun,
14 years’ worth from the Yomiuri Shimbun, and 3 years’
worth from the Asahi Shimbun.
3We used the following package for calculation of
Maximum Entropy:
http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.
4The result of dependency analysis with a posterior con-
text model for the Kyodai Corpus showed that the accuracy
for the bunsetsu without punctuation is 90.6%, while the ac-
curacy is only 76.4% for those with punctuation.
5We used the following package for calculation of PLSI:
http://chasen.org/˜taku/software/plsi/.
</footnote>
<figure confidence="0.991274">
Candidate 1
Candidate 2
Candidate 3
Candidate 4
Candidate
: Case element : Verb
Reranking
Candidate
</figure>
<page confidence="0.984945">
837
</page>
<table confidence="0.99975">
Bunsetsu accuracy Sentence accuracy
Whole data Context model 90.95% (73,390/80,695) 54.40% (5,052/9,287)
Our model 91.21% (73,603/80,695) 55.17% (5,124/9,287)
Only for reranked sentences Context model 90.72% (68,971/76,026) 48,33% (3,813/7,889)
Our model 91.00% (69,184/76,026) 49.25% (3,885/7,889)
Only for case elements Context model 91.80% (28,849/31,427) –
Our model 92.47% (29,062/31,427) –
</table>
<tableCaption confidence="0.999767">
Table 3: Accuracy before/after reranking
</tableCaption>
<bodyText confidence="0.999951133333334">
particles. Therefore, the total number of particles
was 10.
We also estimated the co-occurrence probability
of the particle set P (rs|syn, v) by using PLSI. We
regarded the triple (rs, syn, v) (the co-occurrence
of particle set rs, verb v, and the syntactic prop-
erty syn) as the co-occurrence of rs and (syn, v).
The dimension of the hidden class was 100. The
total number of (rs, syn, v) pairs was 1,016,508,
v was 18,423, and rs was 1,490. The particle set
should be treated not as a non-ordered set but as
an occurrence ordered set. However, we think cor-
rect probability estimation using an occurrence or-
dered set is difficult, because it gives rise to an ex-
plosion in the number of combination,
</bodyText>
<subsectionHeader confidence="0.988941">
5.4 Experimental environment
</subsectionHeader>
<bodyText confidence="0.9999905">
The evaluation data we used was Kyodai Cor-
pus 3.0, a corpus manually annotated with depen-
dency relations (Kurohashi and Nagao, 1998a).
The statistics of the data are as follows:
</bodyText>
<listItem confidence="0.9998248">
• Training data: 24,263 sentences, 234,474
bunsetsus
• Development data: 4,833 sentences, 47,580
bunsetsus
• Test data: 9,287 sentences, 89,982 bunsetsus
</listItem>
<bodyText confidence="0.999639857142857">
The test data contained 31,427 case elements, and
28,801 verbs.
The evaluation measures we used were bunsetsu
accuracy (the percentage of bunsetsu for which the
correct modifyee was identified) and sentence ac-
curacy (the percentage of sentences for which the
correct dependency structure was identified).
</bodyText>
<subsectionHeader confidence="0.9916075">
5.5 Experimental results
5.5.1 Evaluation of our model
</subsectionHeader>
<bodyText confidence="0.9965815">
Our first experiment evaluated the effectiveness
of reranking with our proposed model. Bunsetsu
</bodyText>
<table confidence="0.99743475">
Our reranking model
correct incorrect
Context model correct 73,119 271
incorrect 484 6,821
</table>
<tableCaption confidence="0.848499">
Table 4: 2 x 2 contingency table of the number of
correct bunsetsu (posterior context model x our
model)
</tableCaption>
<bodyText confidence="0.999949384615385">
and sentence accuracies before and after rerank-
ing, for the entire set of test data as well as for
only those sentences whose parse was actually
reranked, are listed in Table 3.
The results showed that the accuracy could be
improved by using our proposed model to rerank
the results obtained with the posterior context
model. McNemar testing showed that the null hy-
pothesis that there is no difference between the ac-
curacy of the results obtained with the posterior
context model and those obtained with our model
could be rejected with a p value &lt; 0.01. The
difference in accuracy is therefore significant.
</bodyText>
<subsectionHeader confidence="0.828163">
5.5.2 Comparing variant models
</subsectionHeader>
<bodyText confidence="0.9997895">
We next experimentally compare the following
variations of the proposed model:
</bodyText>
<listItem confidence="0.99712775">
(a) one in which the case element set is assumed
to be independent [Equation (7)]
(b) one using the co-occurrence probability of
the particle set, P (rs|syn, v), in our model
(c) one using only the co-occurrence probability
of the case element, P(n|r, v), in our model
(d) one not taking into account the syntactic
property of a verb (i,e. a model in which
the co-occurrence probability is defined as
P(r|v), without the syntactic property syn)
(e) one in which the co-occurrence probability of
the case element, P(n|r, v), is simply added
</listItem>
<page confidence="0.99385">
838
</page>
<table confidence="0.994365">
Bunsetsu accuracy
Bunsetsu Sentence
accuracy accuracy
Context model 90.95% 54.40%
Our model 91.21% 55.17%
model (a) 91.12% 54.90%
model (b) 91.10% 54.69%
model (c) 91.11% 54.91%
model (d) 91.15% 54.82%
model (e) 90.96% 54.33%
model (f) 89.50% 48.33%
Kudo et al 2005 91.37% 56.00%
</table>
<tableCaption confidence="0.999923">
Table 5: Comparison of various models
</tableCaption>
<bodyText confidence="0.996295541666667">
to a feature set used in the posterior context
model
(f) one using only our proposed probabilities
without the probability of the posterior con-
text model
The accuracies obtained with each of these
models are listed in Table 5, from which we can
conclude that it is effective to take into account the
dependency between case elements because model
(a) is less accurate than our model.
Since the accuracy of model (d) is comparable
to that of our model, we can conclude that the con-
sideration of the syntactic property of a verb does
not necessarily improve dependency analysis.
The accuracy of model (e), which uses the co-
occurrence probability of the case element set as
features in the posterior context model, is compa-
rable to that of the posterior context model. This
result is similar to the one obtained by (Kehler et
al., 2004), where the task was anaphora resolution.
Although we think the co-occurrence probability
is useful information for dependency analysis, this
result shows that simply adding it as a feature does
not improve the accuracy.
</bodyText>
<subsectionHeader confidence="0.875625">
5.5.3 Changing the amount of training data
</subsectionHeader>
<bodyText confidence="0.999436">
Changing the size of the training data set, we
investigated whether the degree of accuracy im-
provement due to reranking depends on the accu-
racy of the existing dependency analyzer.
Figure 3 shows that the accuracy improvement
is constant even if the accuracy of the dependency
analyzer is varied.
</bodyText>
<sectionHeader confidence="0.528999" genericHeader="evaluation">
5.6 Discussion
</sectionHeader>
<bodyText confidence="0.9972645">
The score used in reranking is the product of the
probability of the posterior context model and the
</bodyText>
<figure confidence="0.9671885">
4000 6000 8000 10000 12000 14000 16000 18000 20000 22000 24000 26000
No. of training sentences
</figure>
<figureCaption confidence="0.99365">
Figure 3: Bunsetsu accuracy when the size of the
training data is changed
</figureCaption>
<bodyText confidence="0.999955361111111">
probability of our proposed model. The results in
Table 5 show that the parsing accuracy of model
(f), which uses only the probabilities obtained with
our proposed model, is quite low. We think the
reason for this is that our two co-occurrence prob-
abilities cannot take account of syntactic proper-
ties, such as punctuation and the distance between
two bunsetsus, which improve dependency analy-
sis.
Furthermore, when the sentence has multiple
verbs and case elements, the constraint of our pro-
posed model tends to distribute case elements to
each verb equally. To investigate such bias, we
calculated the variance of the number of case ele-
ments per verb.
Table 6 shows that the variance for our proposed
model (Equation [5]) is the lowest, and this model
distributes case elements to each verb equally. The
variance of the posterior context model is higher
than that of the test data, probably because the
syntactic constraint in this model affects parsing
too much. Therefore the variance of the reranking
model (Equation [8]), which is the combination
of our proposed model and the posterior context
model, is close to that of the test data.
The best parse which uses this data set is (Kudo
and Matsumoto, 2005), and their parsing accuracy
is 91.37%. The features and the parsing method
used by their model are almost equal to the poste-
rior context model, but they use a different method
of probability estimation. If their model could
generate n-best parsing and attach some kind of
score to each parse tree, we would combine their
model in place of the posterior context model.
At the stage of incorporating the proposed ap-
proach to a parser, the consistency with other pos-
</bodyText>
<figure confidence="0.995192384615385">
0.914
0.912
0.91
0.908
0.906
0.904
0.902
0.9
0.898
0.896
0.894
posterior context model
proposed model
</figure>
<page confidence="0.987159">
839
</page>
<table confidence="0.966012">
variance (σ2) context model test data Equation [8] Equation [5]
0.724 0.702 0.696 0.666
*The average number of elements per verb is 1.078.
</table>
<tableCaption confidence="0.999256">
Table 6: The variance of the number of elements per verb
</tableCaption>
<bodyText confidence="0.995791">
sible methods that deal with other relations should
be taken into account. This will be one of our fu-
ture tasks.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999997818181818">
We presented a method of improving Japanese de-
pendency parsing by using large-scale statistical
information. Our method takes into account two
types of information, not considered in previous
statistical (machine learning based) parsing meth-
ods. One is information about the dependency re-
lations among the case elements of a verb, and the
other is information about co-occurrence relations
between a verb and its case element. Experimen-
tal results showed that our method can improve the
accuracy of the existing method.
</bodyText>
<sectionHeader confidence="0.999103" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999700565789474">
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and maxent discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing of the ACL, pages 173–180.
Michael Collins and Terry Koo. 2005. Discriminative
reranking for natural language parsing. Computa-
tional Linguistics, 31(1):25–69.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245–288.
James Henderson and Ivan Titov. 2005. Data-defined
kernels for parse reranking derived from probabilis-
tic models. In Proceedings of the 43rd Annual Meet-
ing of the ACL, pages 181–188.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of the 22nd Annual Inter-
national SIGIR Conference on Research and Devel-
opment in Information Retrieval, pages 50–57.
Andrew Kehler, Douglas Appelt, Lara Taylor, and
Aleksandr Simma. 2004. The (non)utility of
predicate-argument frequencies for pronoun inter-
pretation. In Proceedings of the HLT/NAACL 2004,
pages 289–296.
Dan Klein and Christopher D. Manning. 2002. Fast
exact inference with a factored model for natural
language parsing. In Advances in Neural Informa-
tion Processing Systems 15 (NIPS 2002), pages 3–
10.
Taku Kudo and Yuji Matsumoto. 2002. Japanese
dependency analysis using cascaded chunking. In
CoNLL 2002: Proceedings of the 6th Conference on
Natural Language Learning 2002 (COLING 2002
Post-Conference Workshops), pages 63–69.
Taku Kudo and Yuji Matsumoto. 2005. Japanese de-
pendency parsing using relative preference of depen-
dency. Transactions of Information Processing So-
ciety of Japan, 46(4):1082–1092. (in Japanese).
Sadao Kurohashi and Makoto Nagao. 1994. Kn parser:
Japanese dependency/case structure analyzer. In
Proceedings of the Workshop on Sharable Natural
Language Resources, pages 48–55.
Sadao Kurohashi and Makoto Nagao. 1998a. Building
a Japanese parsed corpus while improving the pars-
ing system. In Proceedings of the 1st International
Conference on Language Resources and Evaluation,
pages 719–724.
Sadao Kurohashi and Makoto Nagao. 1998b. Japanese
Morphological Analysis System JUMAN version
3.5. Department of Informatics, Kyoto University.
(in Japanese).
Manabu Sassano. 2004. Linear-time dependency anal-
ysis for Japanese. In Proceedings of the COLING
2004, pages 8–14.
Kiyoaki Shirai, Kentaro Inui, Takenobu Tokunaga, and
Hozumi Tanaka. 1998. An empirical evaluation on
statistical parsing of Japanese sentences using lexi-
cal association statistics. In Proceedings of the 3rd
Conference on EMNLP, pages 80–87.
Kiyoaki Shirai. 1998. The integrated natural language
processing using statistical information. Technical
Report TR98–0004, Department of Computer Sci-
ence, Tokyo Institute of Technology. (in Japanese).
Kentaro Torisawa. 2001. An unsupervised method for
canonicalization of Japanese postpositions. In Pro-
ceedings of the 6th Natural Language Processing
Pacific Rim Symposium (NLPRS), pages 211–218.
Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isa-
hara. 1999. Japanese dependency structure analy-
sis based on maximum entropy models. Transac-
tions of Information Processing Society of Japan,
40(9):3397–3407. (in Japanese).
Kiyotaka Uchimoto, Masaki Murata, Satoshi Sekine,
and Hitoshi Isahara. 2000. Dependency model
using posterior context. In Proceedings of the
Sixth International Workshop on Parsing Technol-
ogy (IWPT2000), pages 321–322.
</reference>
<page confidence="0.997655">
840
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.532141">
<title confidence="0.9986735">Japanese Dependency Parsing Using Co-occurrence Information and a Combination of Case Elements</title>
<author confidence="0.998254">Takeshi Abekawa Manabu Okumura</author>
<affiliation confidence="0.9999545">Graduate School of Education Precision and Intelligence Laboratory University of Tokyo Tokyo Institute of Technology</affiliation>
<email confidence="0.536257">abekawa@p.u-tokyo.ac.jpoku@pi.titech.ac.jp</email>
<abstract confidence="0.9998255">In this paper, we present a method that improves Japanese dependency parsing by using large-scale statistical information. It takes into account two kinds of information not considered in previous statistical (machine learning based) parsing methods: information about dependency relations among the case elements of a verb, and information about co-occurrence relations between a verb and its case element. This information can be collected from the results of automatic dependency parsing of large-scale corpora. The results of an experiment in which our method was used to rerank the results obtained using an existing machine learning based parsing method showed that our method can improve the accuracy of the results obtained using the existing method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="15580" citStr="Charniak and Johnson, 2005" startWordPosition="2541" endWordPosition="2544">iments, n is set to 50. The score we used for reranking the parses was the product of the probability of the posterior context model and the probability of our proposed model: score = Pcontext(T)α X P(T), (8) where Pcontext(T) is the probability of the posterior context model. The α here is a parameter with which we can adjust the balance of the two probabilities, and is fixed to the best value by considering development data (different from the training data)1. Figure 2: Selection of possible parses for reranking Many methods for reranking the parsing of English sentences have been proposed (Charniak and Johnson, 2005; Collins and Koo, 2005; Henderson and Titov, 2005), all of which are discriminative methods which learn the difference between the best parse and next-best parses. While our reranking model using generation probability is quite simple, we can easily verify our hypothesis that the two proposed probabilities have an effect on improving the parsing accuracy. We can also verify that the parsing accuracy improves by using imprecise information obtained from an automatically parsed corpus. Klein and Manning proposed a generative model in which syntactic (PCFG) and semantic (lexical dependency) stru</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting of the ACL, pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="15603" citStr="Collins and Koo, 2005" startWordPosition="2545" endWordPosition="2548">score we used for reranking the parses was the product of the probability of the posterior context model and the probability of our proposed model: score = Pcontext(T)α X P(T), (8) where Pcontext(T) is the probability of the posterior context model. The α here is a parameter with which we can adjust the balance of the two probabilities, and is fixed to the best value by considering development data (different from the training data)1. Figure 2: Selection of possible parses for reranking Many methods for reranking the parsing of English sentences have been proposed (Charniak and Johnson, 2005; Collins and Koo, 2005; Henderson and Titov, 2005), all of which are discriminative methods which learn the difference between the best parse and next-best parses. While our reranking model using generation probability is quite simple, we can easily verify our hypothesis that the two proposed probabilities have an effect on improving the parsing accuracy. We can also verify that the parsing accuracy improves by using imprecise information obtained from an automatically parsed corpus. Klein and Manning proposed a generative model in which syntactic (PCFG) and semantic (lexical dependency) structures are scored with </context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Michael Collins and Terry Koo. 2005. Discriminative reranking for natural language parsing. Computational Linguistics, 31(1):25–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="10344" citStr="Gildea and Jurafsky, 2002" startWordPosition="1662" endWordPosition="1665">and propose the sentence probability defined by Equation (5). P(rsz(T)|vz(T)) × P(nz,j(T)|rz,j(T),vz(T)) (5) We call P (rsz(T)|vz(T)) the co-occurrence probability of the particle set and the verb, and we call P(nz,j(T)|rz,j(T), vz(T)) the co-occurrence probability of the case element set and the verb. In the actual dependency analysis, we try to select the dependency structure Tˆ that maximizes the Equation (5) from the possible parses T for the inputted sentence: P(rsz(T)|vz(T)) × ci(T) ∏ P(nz,j(T)|rz,j(T), vz(T)). (6) j=1 The proposed model is inspired by the semantic role labeling method (Gildea and Jurafsky, 2002), which uses the frame element group in place of the particle set. It differs from the previous parsing models in that we take into account the dependency relations among particles in the set of case elements that modify a verb. This information can constrain the combination of particles (cases) among bunsetsus that modify a verb. Assuming the independence among particles, we can rewrite Equation (5) as P(nz,j(T),rz,j(T)|vz(T)). (7) 4.1 Syntactic property of a verb In Japanese, the “ha” case that indicates a topic tends to modify the main verb in a sentence and tends not to modify a verb in a </context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Henderson</author>
<author>Ivan Titov</author>
</authors>
<title>Data-defined kernels for parse reranking derived from probabilistic models.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>181--188</pages>
<contexts>
<context position="15631" citStr="Henderson and Titov, 2005" startWordPosition="2549" endWordPosition="2553">king the parses was the product of the probability of the posterior context model and the probability of our proposed model: score = Pcontext(T)α X P(T), (8) where Pcontext(T) is the probability of the posterior context model. The α here is a parameter with which we can adjust the balance of the two probabilities, and is fixed to the best value by considering development data (different from the training data)1. Figure 2: Selection of possible parses for reranking Many methods for reranking the parsing of English sentences have been proposed (Charniak and Johnson, 2005; Collins and Koo, 2005; Henderson and Titov, 2005), all of which are discriminative methods which learn the difference between the best parse and next-best parses. While our reranking model using generation probability is quite simple, we can easily verify our hypothesis that the two proposed probabilities have an effect on improving the parsing accuracy. We can also verify that the parsing accuracy improves by using imprecise information obtained from an automatically parsed corpus. Klein and Manning proposed a generative model in which syntactic (PCFG) and semantic (lexical dependency) structures are scored with separate models (Klein and M</context>
</contexts>
<marker>Henderson, Titov, 2005</marker>
<rawString>James Henderson and Ivan Titov. 2005. Data-defined kernels for parse reranking derived from probabilistic models. In Proceedings of the 43rd Annual Meeting of the ACL, pages 181–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd Annual International SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>50--57</pages>
<contexts>
<context position="17385" citStr="Hofmann, 1999" startWordPosition="2819" endWordPosition="2820">ence probability of the case element set used in our model by analyzing a large-scale corpus. We collected a 30-year newspaper corpus2, applied the morphological analyzer JUMAN (Kurohashi and Nagao, 1998b), and then applied the dependency analyzer with a posterior context model3. To ensure that we collected reliable co-occurrence information, we removed the information for the bunsetsus with punctuation4. Like (Torisawa, 2001), we estimated the cooccurrence probability P((n, r, v)) of the case element set (noun n, particle r, and verb v) by using probabilistic latent semantic indexing (PLSI) (Hofmann, 1999)5. If (n, r, v) is the co-occurrence of n and (r, v), we can calculate P((n, r, v)) by using the following equation: ∑P((n,r,v)) = P(n|z)P((r,v)|z)P(z), (9) z∈Z where z indicates a latent semantic class of cooccurrence (hidden class). Probabilistic parameters P(n|z), P((r, v)|z), and P(z) in Equation (9) can be estimated by using the EM algorithm. In our experiments, the dimension of the hidden class z was set to 300. As a result, the collected (n, r, v) total 102,581,924 pairs. The number of n and v is 57,315 and 15,098, respectively. The particles for which the co-occurrence probability was </context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of the 22nd Annual International SIGIR Conference on Research and Development in Information Retrieval, pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kehler</author>
<author>Douglas Appelt</author>
<author>Lara Taylor</author>
<author>Aleksandr Simma</author>
</authors>
<title>The (non)utility of predicate-argument frequencies for pronoun interpretation.</title>
<date>2004</date>
<booktitle>In Proceedings of the HLT/NAACL</booktitle>
<pages>289--296</pages>
<contexts>
<context position="8009" citStr="Kehler et al., 2004" startWordPosition="1267" endWordPosition="1270">rui-teiru” and of “keisatsu-de” and “hogo-shita” makes it obvious that “keisatsu-de” is more likely to modify “hogo-shita”. 834 In summary, we think that statistical Japanese dependency analysis needs to take into account at least two more kinds of information: the dependency relation between multiple cases where multiple nouns of the same case do not modify a verb, and the co-occurrence of nouns and verbs. One way to use such information in statistical dependency analysis is to directly use it as features. However, Kehler et al. pointed out that this does not make the analysis more accurate (Kehler et al., 2004). This paper therefore presents a model that uses the co-occurrence information separately and reranks the analysis candidates generated by the existing machine learning model. 4 Our proposed model We first introduce the notation for the explanation of the dependency structure T: m(T) : the number of verbs in T vz(T) : the i-th verb in T cz(T) : the number of case elements that modify the i-th verb in T esz(T) : the set of case elements that modify the i-th verb in T rsz(T) : the set of particles in the set of case elements that modify the i-th verb in T nsz(T) : the set of nouns in the set of</context>
<context position="23329" citStr="Kehler et al., 2004" startWordPosition="3773" endWordPosition="3776">d in Table 5, from which we can conclude that it is effective to take into account the dependency between case elements because model (a) is less accurate than our model. Since the accuracy of model (d) is comparable to that of our model, we can conclude that the consideration of the syntactic property of a verb does not necessarily improve dependency analysis. The accuracy of model (e), which uses the cooccurrence probability of the case element set as features in the posterior context model, is comparable to that of the posterior context model. This result is similar to the one obtained by (Kehler et al., 2004), where the task was anaphora resolution. Although we think the co-occurrence probability is useful information for dependency analysis, this result shows that simply adding it as a feature does not improve the accuracy. 5.5.3 Changing the amount of training data Changing the size of the training data set, we investigated whether the degree of accuracy improvement due to reranking depends on the accuracy of the existing dependency analyzer. Figure 3 shows that the accuracy improvement is constant even if the accuracy of the dependency analyzer is varied. 5.6 Discussion The score used in rerank</context>
</contexts>
<marker>Kehler, Appelt, Taylor, Simma, 2004</marker>
<rawString>Andrew Kehler, Douglas Appelt, Lara Taylor, and Aleksandr Simma. 2004. The (non)utility of predicate-argument frequencies for pronoun interpretation. In Proceedings of the HLT/NAACL 2004, pages 289–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Fast exact inference with a factored model for natural language parsing.</title>
<date>2002</date>
<booktitle>In Advances in Neural Information Processing Systems 15 (NIPS 2002),</booktitle>
<pages>3--10</pages>
<contexts>
<context position="16244" citStr="Klein and Manning, 2002" startWordPosition="2642" endWordPosition="2645">itov, 2005), all of which are discriminative methods which learn the difference between the best parse and next-best parses. While our reranking model using generation probability is quite simple, we can easily verify our hypothesis that the two proposed probabilities have an effect on improving the parsing accuracy. We can also verify that the parsing accuracy improves by using imprecise information obtained from an automatically parsed corpus. Klein and Manning proposed a generative model in which syntactic (PCFG) and semantic (lexical dependency) structures are scored with separate models (Klein and Manning, 2002), but 1In our experiments, α is set to 2.0 using development data. they do not take into account the combination of dependencies. Shirai et al. also proposed a statistical model of Japanese language which integrates lexical association statistics with syntactic preference (Shirai et al., 1998). Our proposed model differs from their method in that it explicitly uses the combination of multiple cases. 5.3 Estimation of co-occurrence probability We estimated the co-occurrence probability of the particle set and the co-occurrence probability of the case element set used in our model by analyzing a</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher D. Manning. 2002. Fast exact inference with a factored model for natural language parsing. In Advances in Neural Information Processing Systems 15 (NIPS 2002), pages 3– 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese dependency analysis using cascaded chunking.</title>
<date>2002</date>
<booktitle>In CoNLL 2002: Proceedings of the 6th Conference on Natural Language Learning</booktitle>
<pages>63--69</pages>
<contexts>
<context position="1898" citStr="Kudo and Matsumoto, 2002" startWordPosition="282" endWordPosition="285">ts called bunsetsu, each of which consists of one or more content words that may be followed by any number of function words. The dependency between two bunsetsus is direct from a dependent to its head. Manually written rules have usually been used to determine which bunsetsu another bunsetsu tends to modify, but this method poses problems in terms of the coverage and consistency of the rules. The recent availability of larger-scale corpora annotated with dependency information has thus resulted in more work on statistical dependency analysis technologies that use machine learning algorithms (Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000). Work on statistical Japanese dependency analysis has usually assumed that all the dependency relations in a sentence are independent of each other, and has considered the bunsetsus in a sentence independently when judging whether or not a pair of bunsetsus is in a dependency relation. In judging which bunsetsu a bunsetsu modifies, this type of work has used as features the information of two bunsetsus, such as the head words of the two bunsetsus, and the morphemes at the ends of the bunsetsus (Uchimoto et al., 1999). It is necessa</context>
<context position="5285" citStr="Kudo and Matsumoto, 2002" startWordPosition="829" endWordPosition="833">ke a noun, verb, or adjective, and zero or more function words like a particle (case marker) or verb/noun suffix. By defining a bunsetsu in this manner, we can analyze a sentence in a way similar to that used when analyzing the grammatical roles of words in inflected languages like German. Japanese dependencies have the following characteristics: • Each bunsetsu except the rightmost one has only one head. • Each head bunsetsu is always placed to the right of (i.e. after) its modifier. • Dependencies do not cross one another. Statistical Japanese dependency analyzers (Kudo and Matsumoto, 2005; Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000) automatically learn the likelihood of dependencies from a tagged corpus and calculate the best dependencies for an input sentence. These likelihoods are learned by considering the features of bunsetsus such as their character strings, parts of speech, and inflection types, as well as information between bunsetsus such as punctuation and the distance between bunsetsus. The weight of given features is learned from a training corpus by calculating the weights from the frequencies of the features in the training data. 3 Japanese depend</context>
<context position="6794" citStr="Kudo and Matsumoto, 2002" startWordPosition="1070" endWordPosition="1074">endent of one another. It is therefore necessary to also consider such a constraint as a feature for contextual information. Uchimoto et al., for example, used as such a feature whether a particular type of bunsetsu is between two bunsetsus in a dependency relation (Uchimoto et al., 1999), and Sassano used information about what is just before and after the modifying bunsetsu and modifyee bunsetsu (Sassano, 2004). In the artificial example shown in Figure 1, it is natural to consider that “keisatsu-de” will modify “hogo-shita”. Statistical Japanese dependency analyzers (Uchimoto et al., 2000; Kudo and Matsumoto, 2002), however, will output the result where “keisatsu-de” modifies “arui-teiru”. This is because in sentences without internal punctuation a noun tends to modify the nearest verb, and these analyzers do not take into account a combination of multiple cases. Another kind of information useful in dependency analysis is the co-occurrence of a noun and a verb, which indicates to what degree the noun tends to modify the verb. In the above example, the possible modifyees of “keisatsu-de” are “aruiteiru” and “hogo-shita”. Taking into account information about the co-occurrence of “keisatsude” and “arui-t</context>
<context position="14300" citStr="Kudo and Matsumoto, 2002" startWordPosition="2315" endWordPosition="2318">cannot determine all the dependency relations in a sentence. We therefore use one of the currently available dependency analyzers to generate an ordered list of n-best possible parses for the sentence and then use our proposed model to rerank them and select the best parse. 5.1 Dependency analyzer for outputting n-best parses We generated the n-best parses by using the “posterior context model” (Uchimoto et al., 2000). The features we used were those in (Uchimoto et al., 1999) and their combinations. We also added our original features and their combinations, with reference to (Sassano, 2004; Kudo and Matsumoto, 2002), but we removed the features that had a frequency of less than 30 in our training data. The total number of features is thus 105,608. 5.2 Reranking method Because our model considers only the dependency relations between a noun and a verb, and thus cannot determine all the dependency relations in a sentence, we restricted the possible parses for 836 reranking as illustrated in Figure 2. The possible parses for reranking were the first-ranked parse and those of the next-best parses in which the verb to modify was different from that in the firstranked one. For example, parses 1 and 3 in Figure</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In CoNLL 2002: Proceedings of the 6th Conference on Natural Language Learning 2002 (COLING 2002 Post-Conference Workshops), pages 63–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese dependency parsing using relative preference of dependency.</title>
<date>2005</date>
<journal>Transactions of Information Processing Society of Japan,</journal>
<volume>46</volume>
<issue>4</issue>
<note>(in Japanese).</note>
<contexts>
<context position="5259" citStr="Kudo and Matsumoto, 2005" startWordPosition="825" endWordPosition="828">e or more content words like a noun, verb, or adjective, and zero or more function words like a particle (case marker) or verb/noun suffix. By defining a bunsetsu in this manner, we can analyze a sentence in a way similar to that used when analyzing the grammatical roles of words in inflected languages like German. Japanese dependencies have the following characteristics: • Each bunsetsu except the rightmost one has only one head. • Each head bunsetsu is always placed to the right of (i.e. after) its modifier. • Dependencies do not cross one another. Statistical Japanese dependency analyzers (Kudo and Matsumoto, 2005; Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000) automatically learn the likelihood of dependencies from a tagged corpus and calculate the best dependencies for an input sentence. These likelihoods are learned by considering the features of bunsetsus such as their character strings, parts of speech, and inflection types, as well as information between bunsetsus such as punctuation and the distance between bunsetsus. The weight of given features is learned from a training corpus by calculating the weights from the frequencies of the features in the traini</context>
<context position="25387" citStr="Kudo and Matsumoto, 2005" startWordPosition="4114" endWordPosition="4117">e calculated the variance of the number of case elements per verb. Table 6 shows that the variance for our proposed model (Equation [5]) is the lowest, and this model distributes case elements to each verb equally. The variance of the posterior context model is higher than that of the test data, probably because the syntactic constraint in this model affects parsing too much. Therefore the variance of the reranking model (Equation [8]), which is the combination of our proposed model and the posterior context model, is close to that of the test data. The best parse which uses this data set is (Kudo and Matsumoto, 2005), and their parsing accuracy is 91.37%. The features and the parsing method used by their model are almost equal to the posterior context model, but they use a different method of probability estimation. If their model could generate n-best parsing and attach some kind of score to each parse tree, we would combine their model in place of the posterior context model. At the stage of incorporating the proposed approach to a parser, the consistency with other pos0.914 0.912 0.91 0.908 0.906 0.904 0.902 0.9 0.898 0.896 0.894 posterior context model proposed model 839 variance (σ2) context model te</context>
</contexts>
<marker>Kudo, Matsumoto, 2005</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2005. Japanese dependency parsing using relative preference of dependency. Transactions of Information Processing Society of Japan, 46(4):1082–1092. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>Kn parser: Japanese dependency/case structure analyzer.</title>
<date>1994</date>
<booktitle>In Proceedings of the Workshop on Sharable Natural Language Resources,</booktitle>
<pages>48--55</pages>
<contexts>
<context position="3073" citStr="Kurohashi and Nagao, 1994" startWordPosition="480" endWordPosition="484">he bunsetsus (Uchimoto et al., 1999). It is necessary, however, to also consider features for the contextual information of the two bunsetsus. One such feature is the constraint that two case elements with the same case do not modify a verb. Statistical Japanese dependency analysis takes into account syntactic information but tends not to take into account lexical information, such as cooccurrence between a case element and a verb. The recent availability of more corpora has enabled much information about dependency relations to be obtained by using a Japanese dependency analyzer such as KNP (Kurohashi and Nagao, 1994) or CaboCha (Kudo and Matsumoto, 2002). Although this information is less accurate than manually annotated information, these automatic analyzers provide a large amount of co-occurrence information as well as information about combinations of multiple cases that tend to modify a verb. In this paper, we present a method for improving the accuracy of Japanese dependency analysis by representing the lexical information of cooccurrence and dependency relations of multiple cases as statistical models. We also show the results of experiments demonstrating the effectiveness of our method. 833 Proceed</context>
</contexts>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1994. Kn parser: Japanese dependency/case structure analyzer. In Proceedings of the Workshop on Sharable Natural Language Resources, pages 48–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>Building a Japanese parsed corpus while improving the parsing system.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1st International Conference on Language Resources and Evaluation,</booktitle>
<pages>719--724</pages>
<contexts>
<context position="16974" citStr="Kurohashi and Nagao, 1998" startWordPosition="2756" endWordPosition="2759">ination of dependencies. Shirai et al. also proposed a statistical model of Japanese language which integrates lexical association statistics with syntactic preference (Shirai et al., 1998). Our proposed model differs from their method in that it explicitly uses the combination of multiple cases. 5.3 Estimation of co-occurrence probability We estimated the co-occurrence probability of the particle set and the co-occurrence probability of the case element set used in our model by analyzing a large-scale corpus. We collected a 30-year newspaper corpus2, applied the morphological analyzer JUMAN (Kurohashi and Nagao, 1998b), and then applied the dependency analyzer with a posterior context model3. To ensure that we collected reliable co-occurrence information, we removed the information for the bunsetsus with punctuation4. Like (Torisawa, 2001), we estimated the cooccurrence probability P((n, r, v)) of the case element set (noun n, particle r, and verb v) by using probabilistic latent semantic indexing (PLSI) (Hofmann, 1999)5. If (n, r, v) is the co-occurrence of n and (r, v), we can calculate P((n, r, v)) by using the following equation: ∑P((n,r,v)) = P(n|z)P((r,v)|z)P(z), (9) z∈Z where z indicates a latent s</context>
<context position="20063" citStr="Kurohashi and Nagao, 1998" startWordPosition="3239" endWordPosition="3242">rb v, and the syntactic property syn) as the co-occurrence of rs and (syn, v). The dimension of the hidden class was 100. The total number of (rs, syn, v) pairs was 1,016,508, v was 18,423, and rs was 1,490. The particle set should be treated not as a non-ordered set but as an occurrence ordered set. However, we think correct probability estimation using an occurrence ordered set is difficult, because it gives rise to an explosion in the number of combination, 5.4 Experimental environment The evaluation data we used was Kyodai Corpus 3.0, a corpus manually annotated with dependency relations (Kurohashi and Nagao, 1998a). The statistics of the data are as follows: • Training data: 24,263 sentences, 234,474 bunsetsus • Development data: 4,833 sentences, 47,580 bunsetsus • Test data: 9,287 sentences, 89,982 bunsetsus The test data contained 31,427 case elements, and 28,801 verbs. The evaluation measures we used were bunsetsu accuracy (the percentage of bunsetsu for which the correct modifyee was identified) and sentence accuracy (the percentage of sentences for which the correct dependency structure was identified). 5.5 Experimental results 5.5.1 Evaluation of our model Our first experiment evaluated the effe</context>
</contexts>
<marker>Kurohashi, Nagao, 1998</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1998a. Building a Japanese parsed corpus while improving the parsing system. In Proceedings of the 1st International Conference on Language Resources and Evaluation, pages 719–724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<date>1998</date>
<booktitle>Japanese Morphological Analysis System JUMAN version 3.5.</booktitle>
<institution>Department of Informatics, Kyoto University.</institution>
<note>(in Japanese).</note>
<contexts>
<context position="16974" citStr="Kurohashi and Nagao, 1998" startWordPosition="2756" endWordPosition="2759">ination of dependencies. Shirai et al. also proposed a statistical model of Japanese language which integrates lexical association statistics with syntactic preference (Shirai et al., 1998). Our proposed model differs from their method in that it explicitly uses the combination of multiple cases. 5.3 Estimation of co-occurrence probability We estimated the co-occurrence probability of the particle set and the co-occurrence probability of the case element set used in our model by analyzing a large-scale corpus. We collected a 30-year newspaper corpus2, applied the morphological analyzer JUMAN (Kurohashi and Nagao, 1998b), and then applied the dependency analyzer with a posterior context model3. To ensure that we collected reliable co-occurrence information, we removed the information for the bunsetsus with punctuation4. Like (Torisawa, 2001), we estimated the cooccurrence probability P((n, r, v)) of the case element set (noun n, particle r, and verb v) by using probabilistic latent semantic indexing (PLSI) (Hofmann, 1999)5. If (n, r, v) is the co-occurrence of n and (r, v), we can calculate P((n, r, v)) by using the following equation: ∑P((n,r,v)) = P(n|z)P((r,v)|z)P(z), (9) z∈Z where z indicates a latent s</context>
<context position="20063" citStr="Kurohashi and Nagao, 1998" startWordPosition="3239" endWordPosition="3242">rb v, and the syntactic property syn) as the co-occurrence of rs and (syn, v). The dimension of the hidden class was 100. The total number of (rs, syn, v) pairs was 1,016,508, v was 18,423, and rs was 1,490. The particle set should be treated not as a non-ordered set but as an occurrence ordered set. However, we think correct probability estimation using an occurrence ordered set is difficult, because it gives rise to an explosion in the number of combination, 5.4 Experimental environment The evaluation data we used was Kyodai Corpus 3.0, a corpus manually annotated with dependency relations (Kurohashi and Nagao, 1998a). The statistics of the data are as follows: • Training data: 24,263 sentences, 234,474 bunsetsus • Development data: 4,833 sentences, 47,580 bunsetsus • Test data: 9,287 sentences, 89,982 bunsetsus The test data contained 31,427 case elements, and 28,801 verbs. The evaluation measures we used were bunsetsu accuracy (the percentage of bunsetsu for which the correct modifyee was identified) and sentence accuracy (the percentage of sentences for which the correct dependency structure was identified). 5.5 Experimental results 5.5.1 Evaluation of our model Our first experiment evaluated the effe</context>
</contexts>
<marker>Kurohashi, Nagao, 1998</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 1998b. Japanese Morphological Analysis System JUMAN version 3.5. Department of Informatics, Kyoto University. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manabu Sassano</author>
</authors>
<title>Linear-time dependency analysis for Japanese.</title>
<date>2004</date>
<booktitle>In Proceedings of the COLING</booktitle>
<pages>8--14</pages>
<contexts>
<context position="1913" citStr="Sassano, 2004" startWordPosition="286" endWordPosition="287">f which consists of one or more content words that may be followed by any number of function words. The dependency between two bunsetsus is direct from a dependent to its head. Manually written rules have usually been used to determine which bunsetsu another bunsetsu tends to modify, but this method poses problems in terms of the coverage and consistency of the rules. The recent availability of larger-scale corpora annotated with dependency information has thus resulted in more work on statistical dependency analysis technologies that use machine learning algorithms (Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000). Work on statistical Japanese dependency analysis has usually assumed that all the dependency relations in a sentence are independent of each other, and has considered the bunsetsus in a sentence independently when judging whether or not a pair of bunsetsus is in a dependency relation. In judging which bunsetsu a bunsetsu modifies, this type of work has used as features the information of two bunsetsus, such as the head words of the two bunsetsus, and the morphemes at the ends of the bunsetsus (Uchimoto et al., 1999). It is necessary, however, to</context>
<context position="5300" citStr="Sassano, 2004" startWordPosition="834" endWordPosition="835">ive, and zero or more function words like a particle (case marker) or verb/noun suffix. By defining a bunsetsu in this manner, we can analyze a sentence in a way similar to that used when analyzing the grammatical roles of words in inflected languages like German. Japanese dependencies have the following characteristics: • Each bunsetsu except the rightmost one has only one head. • Each head bunsetsu is always placed to the right of (i.e. after) its modifier. • Dependencies do not cross one another. Statistical Japanese dependency analyzers (Kudo and Matsumoto, 2005; Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000) automatically learn the likelihood of dependencies from a tagged corpus and calculate the best dependencies for an input sentence. These likelihoods are learned by considering the features of bunsetsus such as their character strings, parts of speech, and inflection types, as well as information between bunsetsus such as punctuation and the distance between bunsetsus. The weight of given features is learned from a training corpus by calculating the weights from the frequencies of the features in the training data. 3 Japanese dependency analysis t</context>
<context position="6585" citStr="Sassano, 2004" startWordPosition="1041" endWordPosition="1042">e cases One constraint in Japanese is that multiple nouns of the same case do not modify a verb. Previous work on Japanese dependency analysis has assumed that all the dependency relations are independent of one another. It is therefore necessary to also consider such a constraint as a feature for contextual information. Uchimoto et al., for example, used as such a feature whether a particular type of bunsetsu is between two bunsetsus in a dependency relation (Uchimoto et al., 1999), and Sassano used information about what is just before and after the modifying bunsetsu and modifyee bunsetsu (Sassano, 2004). In the artificial example shown in Figure 1, it is natural to consider that “keisatsu-de” will modify “hogo-shita”. Statistical Japanese dependency analyzers (Uchimoto et al., 2000; Kudo and Matsumoto, 2002), however, will output the result where “keisatsu-de” modifies “arui-teiru”. This is because in sentences without internal punctuation a noun tends to modify the nearest verb, and these analyzers do not take into account a combination of multiple cases. Another kind of information useful in dependency analysis is the co-occurrence of a noun and a verb, which indicates to what degree the n</context>
<context position="14273" citStr="Sassano, 2004" startWordPosition="2313" endWordPosition="2314">and a verb, we cannot determine all the dependency relations in a sentence. We therefore use one of the currently available dependency analyzers to generate an ordered list of n-best possible parses for the sentence and then use our proposed model to rerank them and select the best parse. 5.1 Dependency analyzer for outputting n-best parses We generated the n-best parses by using the “posterior context model” (Uchimoto et al., 2000). The features we used were those in (Uchimoto et al., 1999) and their combinations. We also added our original features and their combinations, with reference to (Sassano, 2004; Kudo and Matsumoto, 2002), but we removed the features that had a frequency of less than 30 in our training data. The total number of features is thus 105,608. 5.2 Reranking method Because our model considers only the dependency relations between a noun and a verb, and thus cannot determine all the dependency relations in a sentence, we restricted the possible parses for 836 reranking as illustrated in Figure 2. The possible parses for reranking were the first-ranked parse and those of the next-best parses in which the verb to modify was different from that in the firstranked one. For exampl</context>
</contexts>
<marker>Sassano, 2004</marker>
<rawString>Manabu Sassano. 2004. Linear-time dependency analysis for Japanese. In Proceedings of the COLING 2004, pages 8–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoaki Shirai</author>
<author>Kentaro Inui</author>
<author>Takenobu Tokunaga</author>
<author>Hozumi Tanaka</author>
</authors>
<title>An empirical evaluation on statistical parsing of Japanese sentences using lexical association statistics.</title>
<date>1998</date>
<booktitle>In Proceedings of the 3rd Conference on EMNLP,</booktitle>
<pages>80--87</pages>
<contexts>
<context position="16538" citStr="Shirai et al., 1998" startWordPosition="2689" endWordPosition="2692">he parsing accuracy. We can also verify that the parsing accuracy improves by using imprecise information obtained from an automatically parsed corpus. Klein and Manning proposed a generative model in which syntactic (PCFG) and semantic (lexical dependency) structures are scored with separate models (Klein and Manning, 2002), but 1In our experiments, α is set to 2.0 using development data. they do not take into account the combination of dependencies. Shirai et al. also proposed a statistical model of Japanese language which integrates lexical association statistics with syntactic preference (Shirai et al., 1998). Our proposed model differs from their method in that it explicitly uses the combination of multiple cases. 5.3 Estimation of co-occurrence probability We estimated the co-occurrence probability of the particle set and the co-occurrence probability of the case element set used in our model by analyzing a large-scale corpus. We collected a 30-year newspaper corpus2, applied the morphological analyzer JUMAN (Kurohashi and Nagao, 1998b), and then applied the dependency analyzer with a posterior context model3. To ensure that we collected reliable co-occurrence information, we removed the informa</context>
</contexts>
<marker>Shirai, Inui, Tokunaga, Tanaka, 1998</marker>
<rawString>Kiyoaki Shirai, Kentaro Inui, Takenobu Tokunaga, and Hozumi Tanaka. 1998. An empirical evaluation on statistical parsing of Japanese sentences using lexical association statistics. In Proceedings of the 3rd Conference on EMNLP, pages 80–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoaki Shirai</author>
</authors>
<title>The integrated natural language processing using statistical information.</title>
<date>1998</date>
<tech>Technical Report TR98–0004,</tech>
<institution>Department of Computer Science, Tokyo Institute of Technology.</institution>
<note>(in Japanese).</note>
<contexts>
<context position="11582" citStr="Shirai, 1998" startWordPosition="1865" endWordPosition="1866"> = m(T) ∏ z=1 ci(T) ∏ j=1 Tˆ = argmax T m(T) ∏ z=1 P(T) = m(T) ci(T) ∏ ∏ z=1 j=1 835 verb: ‘aru-ku’ verb: ‘hogo-suru’ particle set case elements particle set case elements a keisatsu-de umibe-de hitori-de { de,de,de } syonen-wo {wo} b umibe-de hitori-de {de,de} keisatsu-de syonen-wo {de,wo} c hitori-de {de} keisatsu-de umibe-de syonen-wo {de,de,wo} d {none} keisatsu-de umibe-de hitori-de syonen-wo { de,de,de,wo } Table 1: Analytical process of the example sentence co-occurrence probability of the particle set therefore tends to be different for verbs with different syntactic properties. Like (Shirai, 1998), to take into account the reliance of the co-occurrence probability of the particle set on the syntactic property of a verb, instead of using P(rsi(T)|vi(T)) in Equation (5), we use P(rsi(T)|syni(T), vi(T)), where syni(T) is the syntactic property of the i-th verb in T and takes one of the following three values: ‘verb’ when v modifies another verb ‘noun’ when v modifies a noun ‘main’ when v modifies nothing (when it is at the end of the sentence, and is the main verb) 4.2 Illustration of model application Here, we illustrate the process of applying our proposed model to the example sentence </context>
</contexts>
<marker>Shirai, 1998</marker>
<rawString>Kiyoaki Shirai. 1998. The integrated natural language processing using statistical information. Technical Report TR98–0004, Department of Computer Science, Tokyo Institute of Technology. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kentaro Torisawa</author>
</authors>
<title>An unsupervised method for canonicalization of Japanese postpositions.</title>
<date>2001</date>
<booktitle>In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium (NLPRS),</booktitle>
<pages>211--218</pages>
<contexts>
<context position="17201" citStr="Torisawa, 2001" startWordPosition="2789" endWordPosition="2790">n that it explicitly uses the combination of multiple cases. 5.3 Estimation of co-occurrence probability We estimated the co-occurrence probability of the particle set and the co-occurrence probability of the case element set used in our model by analyzing a large-scale corpus. We collected a 30-year newspaper corpus2, applied the morphological analyzer JUMAN (Kurohashi and Nagao, 1998b), and then applied the dependency analyzer with a posterior context model3. To ensure that we collected reliable co-occurrence information, we removed the information for the bunsetsus with punctuation4. Like (Torisawa, 2001), we estimated the cooccurrence probability P((n, r, v)) of the case element set (noun n, particle r, and verb v) by using probabilistic latent semantic indexing (PLSI) (Hofmann, 1999)5. If (n, r, v) is the co-occurrence of n and (r, v), we can calculate P((n, r, v)) by using the following equation: ∑P((n,r,v)) = P(n|z)P((r,v)|z)P(z), (9) z∈Z where z indicates a latent semantic class of cooccurrence (hidden class). Probabilistic parameters P(n|z), P((r, v)|z), and P(z) in Equation (9) can be estimated by using the EM algorithm. In our experiments, the dimension of the hidden class z was set to</context>
</contexts>
<marker>Torisawa, 2001</marker>
<rawString>Kentaro Torisawa. 2001. An unsupervised method for canonicalization of Japanese postpositions. In Proceedings of the 6th Natural Language Processing Pacific Rim Symposium (NLPRS), pages 211–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyotaka Uchimoto</author>
<author>Satoshi Sekine</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Japanese dependency structure analysis based on maximum entropy models.</title>
<date>1999</date>
<journal>Transactions of Information Processing Society of Japan,</journal>
<volume>40</volume>
<issue>9</issue>
<note>(in Japanese).</note>
<contexts>
<context position="1936" citStr="Uchimoto et al., 1999" startWordPosition="288" endWordPosition="291">s of one or more content words that may be followed by any number of function words. The dependency between two bunsetsus is direct from a dependent to its head. Manually written rules have usually been used to determine which bunsetsu another bunsetsu tends to modify, but this method poses problems in terms of the coverage and consistency of the rules. The recent availability of larger-scale corpora annotated with dependency information has thus resulted in more work on statistical dependency analysis technologies that use machine learning algorithms (Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000). Work on statistical Japanese dependency analysis has usually assumed that all the dependency relations in a sentence are independent of each other, and has considered the bunsetsus in a sentence independently when judging whether or not a pair of bunsetsus is in a dependency relation. In judging which bunsetsu a bunsetsu modifies, this type of work has used as features the information of two bunsetsus, such as the head words of the two bunsetsus, and the morphemes at the ends of the bunsetsus (Uchimoto et al., 1999). It is necessary, however, to also consider features</context>
<context position="5323" citStr="Uchimoto et al., 1999" startWordPosition="836" endWordPosition="839">r more function words like a particle (case marker) or verb/noun suffix. By defining a bunsetsu in this manner, we can analyze a sentence in a way similar to that used when analyzing the grammatical roles of words in inflected languages like German. Japanese dependencies have the following characteristics: • Each bunsetsu except the rightmost one has only one head. • Each head bunsetsu is always placed to the right of (i.e. after) its modifier. • Dependencies do not cross one another. Statistical Japanese dependency analyzers (Kudo and Matsumoto, 2005; Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000) automatically learn the likelihood of dependencies from a tagged corpus and calculate the best dependencies for an input sentence. These likelihoods are learned by considering the features of bunsetsus such as their character strings, parts of speech, and inflection types, as well as information between bunsetsus such as punctuation and the distance between bunsetsus. The weight of given features is learned from a training corpus by calculating the weights from the frequencies of the features in the training data. 3 Japanese dependency analysis taking account of co-occ</context>
<context position="14156" citStr="Uchimoto et al., 1999" startWordPosition="2293" endWordPosition="2296"> 0.00000085 0.00000070 Table 2: Example of the co-occurrence probabilities of particle sets pendency relations between a noun and a verb, we cannot determine all the dependency relations in a sentence. We therefore use one of the currently available dependency analyzers to generate an ordered list of n-best possible parses for the sentence and then use our proposed model to rerank them and select the best parse. 5.1 Dependency analyzer for outputting n-best parses We generated the n-best parses by using the “posterior context model” (Uchimoto et al., 2000). The features we used were those in (Uchimoto et al., 1999) and their combinations. We also added our original features and their combinations, with reference to (Sassano, 2004; Kudo and Matsumoto, 2002), but we removed the features that had a frequency of less than 30 in our training data. The total number of features is thus 105,608. 5.2 Reranking method Because our model considers only the dependency relations between a noun and a verb, and thus cannot determine all the dependency relations in a sentence, we restricted the possible parses for 836 reranking as illustrated in Figure 2. The possible parses for reranking were the first-ranked parse and</context>
</contexts>
<marker>Uchimoto, Sekine, Isahara, 1999</marker>
<rawString>Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isahara. 1999. Japanese dependency structure analysis based on maximum entropy models. Transactions of Information Processing Society of Japan, 40(9):3397–3407. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyotaka Uchimoto</author>
<author>Masaki Murata</author>
<author>Satoshi Sekine</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Dependency model using posterior context.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Workshop on Parsing Technology (IWPT2000),</booktitle>
<pages>321--322</pages>
<contexts>
<context position="1960" citStr="Uchimoto et al., 2000" startWordPosition="292" endWordPosition="295">t words that may be followed by any number of function words. The dependency between two bunsetsus is direct from a dependent to its head. Manually written rules have usually been used to determine which bunsetsu another bunsetsu tends to modify, but this method poses problems in terms of the coverage and consistency of the rules. The recent availability of larger-scale corpora annotated with dependency information has thus resulted in more work on statistical dependency analysis technologies that use machine learning algorithms (Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000). Work on statistical Japanese dependency analysis has usually assumed that all the dependency relations in a sentence are independent of each other, and has considered the bunsetsus in a sentence independently when judging whether or not a pair of bunsetsus is in a dependency relation. In judging which bunsetsu a bunsetsu modifies, this type of work has used as features the information of two bunsetsus, such as the head words of the two bunsetsus, and the morphemes at the ends of the bunsetsus (Uchimoto et al., 1999). It is necessary, however, to also consider features for the contextual info</context>
<context position="5347" citStr="Uchimoto et al., 2000" startWordPosition="840" endWordPosition="843">ike a particle (case marker) or verb/noun suffix. By defining a bunsetsu in this manner, we can analyze a sentence in a way similar to that used when analyzing the grammatical roles of words in inflected languages like German. Japanese dependencies have the following characteristics: • Each bunsetsu except the rightmost one has only one head. • Each head bunsetsu is always placed to the right of (i.e. after) its modifier. • Dependencies do not cross one another. Statistical Japanese dependency analyzers (Kudo and Matsumoto, 2005; Kudo and Matsumoto, 2002; Sassano, 2004; Uchimoto et al., 1999; Uchimoto et al., 2000) automatically learn the likelihood of dependencies from a tagged corpus and calculate the best dependencies for an input sentence. These likelihoods are learned by considering the features of bunsetsus such as their character strings, parts of speech, and inflection types, as well as information between bunsetsus such as punctuation and the distance between bunsetsus. The weight of given features is learned from a training corpus by calculating the weights from the frequencies of the features in the training data. 3 Japanese dependency analysis taking account of co-occurrence information and </context>
<context position="6767" citStr="Uchimoto et al., 2000" startWordPosition="1066" endWordPosition="1069">ncy relations are independent of one another. It is therefore necessary to also consider such a constraint as a feature for contextual information. Uchimoto et al., for example, used as such a feature whether a particular type of bunsetsu is between two bunsetsus in a dependency relation (Uchimoto et al., 1999), and Sassano used information about what is just before and after the modifying bunsetsu and modifyee bunsetsu (Sassano, 2004). In the artificial example shown in Figure 1, it is natural to consider that “keisatsu-de” will modify “hogo-shita”. Statistical Japanese dependency analyzers (Uchimoto et al., 2000; Kudo and Matsumoto, 2002), however, will output the result where “keisatsu-de” modifies “arui-teiru”. This is because in sentences without internal punctuation a noun tends to modify the nearest verb, and these analyzers do not take into account a combination of multiple cases. Another kind of information useful in dependency analysis is the co-occurrence of a noun and a verb, which indicates to what degree the noun tends to modify the verb. In the above example, the possible modifyees of “keisatsu-de” are “aruiteiru” and “hogo-shita”. Taking into account information about the co-occurrence </context>
<context position="14096" citStr="Uchimoto et al., 2000" startWordPosition="2282" endWordPosition="2285">22 0.00018 {de, de, de} 0.0000019 0.0000018 {de, de, de, wo} 0.00000085 0.00000070 Table 2: Example of the co-occurrence probabilities of particle sets pendency relations between a noun and a verb, we cannot determine all the dependency relations in a sentence. We therefore use one of the currently available dependency analyzers to generate an ordered list of n-best possible parses for the sentence and then use our proposed model to rerank them and select the best parse. 5.1 Dependency analyzer for outputting n-best parses We generated the n-best parses by using the “posterior context model” (Uchimoto et al., 2000). The features we used were those in (Uchimoto et al., 1999) and their combinations. We also added our original features and their combinations, with reference to (Sassano, 2004; Kudo and Matsumoto, 2002), but we removed the features that had a frequency of less than 30 in our training data. The total number of features is thus 105,608. 5.2 Reranking method Because our model considers only the dependency relations between a noun and a verb, and thus cannot determine all the dependency relations in a sentence, we restricted the possible parses for 836 reranking as illustrated in Figure 2. The p</context>
</contexts>
<marker>Uchimoto, Murata, Sekine, Isahara, 2000</marker>
<rawString>Kiyotaka Uchimoto, Masaki Murata, Satoshi Sekine, and Hitoshi Isahara. 2000. Dependency model using posterior context. In Proceedings of the Sixth International Workshop on Parsing Technology (IWPT2000), pages 321–322.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>