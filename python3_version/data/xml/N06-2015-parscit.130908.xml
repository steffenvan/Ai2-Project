<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.090892">
<note confidence="0.755247333333333">
OntoNotes: The 90% Solution
Eduard Hovy Mitchell Marcus Martha Palmer Lance Ramshaw Ralph Weischedel
USC/ICI Comp &amp; Info Science ICS and Linguistics BBN Technologies BBN Technologies
4676 Admiralty U. of Pennsylvania U. of Colorado 10 Moulton St. 10 Moulton St.
Marina d. R., CA Philadelphia, PA Boulder, CO Cambridge, MA Cambridge, MA
hovy mitch martha.palmer lance.ramshaw weischedel
</note>
<email confidence="0.595059">
@isi.edu @cis.upenn.edu @colorado.edu @bbn.com @bbn.com
</email>
<sectionHeader confidence="0.803661" genericHeader="abstract">
Abstract*
</sectionHeader>
<bodyText confidence="0.9998995">
We describe the OntoNotes methodology and its
result, a large multilingual richly-annotated corpus
constructed at 90% interannotator agreement. An
initial portion (300K words of English newswire
and 250K words of Chinese newswire) will be
made available to the community during 2007.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999934111111111">
Many natural language processing applications
could benefit from a richer model of text meaning
than the bag-of-words and n-gram models that cur-
rently predominate. Until now, however, no such
model has been identified that can be annotated
dependably and rapidly. We have developed a
methodology for producing such a corpus at 90%
inter-annotator agreement, and will release com-
pleted segments beginning in early 2007.
The OntoNotes project focuses on a domain in-
dependent representation of literal meaning that
includes predicate structure, word sense, ontology
linking, and coreference. Pilot studies have shown
that these can all be annotated rapidly and with
better than 90% consistency. Once a substantial
and accurate training corpus is available, trained
algorithms can be developed to predict these struc-
tures in new documents.
</bodyText>
<footnote confidence="0.966116">
* This work was supported under the GALE program of the
Defense Advanced Research Projects Agency, Contract No.
HR0011-06-C-0022.
</footnote>
<bodyText confidence="0.9999405">
This process begins with parse (TreeBank) and
propositional (PropBank) structures, which provide
normalization over predicates and their arguments.
Word sense ambiguities are then resolved, with
each word sense also linked to the appropriate
node in the Omega ontology. Coreference is also
annotated, allowing the entity mentions that are
propositional arguments to be resolved in context.
Annotation will cover multiple languages (Eng-
lish, Chinese, and Arabic) and multiple genres
(newswire, broadcast news, news groups, weblogs,
etc.), to create a resource that is broadly applicable.
</bodyText>
<sectionHeader confidence="0.971058" genericHeader="introduction">
2 Treebanking
</sectionHeader>
<bodyText confidence="0.999525421052632">
The Penn Treebank (Marcus et al., 1993) is anno-
tated with information to make predicate-argument
structure easy to decode, including function tags
and markers of “empty” categories that represent
displaced constituents. To expedite later stages of
annotation, we have developed a parsing system
(Gabbard et al., 2006) that recovers both of these
latter annotations, the first we know of. A first-
stage parser matches the Collins (2003) parser on
which it is based on the Parseval metric, while si-
multaneously achieving near state-of-the-art per-
formance on recovering function tags (F-measure
89.0). A second stage, a seven stage pipeline of
maximum entropy learners and voted perceptrons,
achieves state-of-the-art performance (F-measure
74.7) on the recovery of empty categories by com-
bining a linguistically-informed architecture and a
rich feature set with the power of modern machine
learning methods.
</bodyText>
<page confidence="0.986239">
57
</page>
<note confidence="0.9417825">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 57–60,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.98661" genericHeader="method">
3 PropBanking
</sectionHeader>
<bodyText confidence="0.999746071428572">
The Penn Proposition Bank, funded by ACE
(DOD), focuses on the argument structure of verbs,
and provides a corpus annotated with semantic
roles, including participants traditionally viewed as
arguments and adjuncts. The 1M word Penn Tree-
bank II Wall Street Journal corpus has been suc-
cessfully annotated with semantic argument
structures for verbs and is now available via the
Penn Linguistic Data Consortium as PropBank I
(Palmer et al., 2005). Links from the argument
labels in the Frames Files to FrameNet frame ele-
ments and VerbNet thematic roles are being added.
This style of annotation has also been successfully
applied to other genres and languages.
</bodyText>
<sectionHeader confidence="0.983048" genericHeader="method">
4 Word Sense
</sectionHeader>
<bodyText confidence="0.999942764705883">
Word sense ambiguity is a continuing major ob-
stacle to accurate information extraction, summari-
zation and machine translation. The subtle fine-
grained sense distinctions in WordNet have not
lent themselves to high agreement between human
annotators or high automatic tagging performance.
Building on results in grouping fine-grained
WordNet senses into more coarse-grained senses
that led to improved inter-annotator agreement
(ITA) and system performance (Palmer et al.,
2004; Palmer et al., 2006), we have developed a
process for rapid sense inventory creation and an-
notation that includes critical links between the
grouped word senses and the Omega ontology
(Philpot et al., 2005; see Section 5 below).
This process is based on recognizing that sense
distinctions can be represented by linguists in an
hierarchical structure, similar to a decision tree,
that is rooted in very coarse-grained distinctions
which become increasingly fine-grained until
reaching WordNet senses at the leaves. Sets of
senses under specific nodes of the tree are grouped
together into single entries, along with the syntac-
tic and semantic criteria for their groupings, to be
presented to the annotators.
As shown in Figure 1, a 50-sentence sample of
instances is annotated and immediately checked for
inter-annotator agreement. ITA scores below 90%
lead to a revision and clarification of the groupings
by the linguist. It is only after the groupings have
passed the ITA hurdle that each individual group is
linked to a conceptual node in the ontology. In ad-
dition to higher accuracy, we find at least a three-
fold increase in annotator productivity.
</bodyText>
<figure confidence="0.693348">
OK
</figure>
<figureCaption confidence="0.999893">
Figure 1. Annotation Procedure
</figureCaption>
<bodyText confidence="0.999855">
As part of OntoNotes we are annotating the
most frequent noun and verb senses in a 300K
subset of the PropBank, and will have this data
available for release in early 2007.
</bodyText>
<subsectionHeader confidence="0.979535">
4.1 Verbs
</subsectionHeader>
<bodyText confidence="0.99560625">
Our initial goal is to annotate the 700 most fre-
quently occurring verbs in our data, which are
typically also the most polysemous; so far 300
verbs have been grouped and 150 double anno-
tated. Subcategorization frames and semantic
classes of arguments play major roles in determin-
ing the groupings, as illustrated by the grouping for
the 22 WN 2.1 senses for drive in Figure 2. In ad-
</bodyText>
<table confidence="0.957072190476191">
Save for full
annotation
word
Sense partitioning, creating definitions,
commentary, etc. (2 or 3 people)
not OK
Adjudication (1 person)
Check against ontology (1 person)
Annotate test (2 people)
Results: agreement
not OK and confusion matrix
GI: operating or traveling via a vehi- WN1: “Can you drive a truck?”, WN2: “drive to school,”, WN3: “drive her to
cle school,”, WN12: “this truck drives well,” WN13: “he drives a taxi,”,WN14: “The car
NP (Agent) drive NP, NP drive PP drove around the corner,”, WN:16: “drive the turnpike to work,”
G2: force to a position or stance WN4: “He drives me mad.,” WN6: “drive back the invaders,” WN7: “She finally
NP drive NP/PP/infinitival drove him to change jobs,” WN8: “drive a nail,” WN15: “drive the herd,” WN22:
“drive the game.”
G3: to exert energy on behalf of WN5: “Her passion drives her,” WN10: “He is driving away at his thesis.”
something NP drive NP/infinitival
G4: cause object to move rapidly by WN9: “drive the ball into the outfield ,” WN17 “drive a golf ball,” WN18 “drive a
striking it NP drive NP ball”
</table>
<figureCaption confidence="0.993821">
Figure 2. A Portion of the Grouping of WordNet Senses for &amp;quot;drive”
</figureCaption>
<page confidence="0.988941">
58
</page>
<bodyText confidence="0.99988">
dition to improved annotator productivity and ac-
curacy, we predict a corresponding improvement
in word sense disambiguation performance. Train-
ing on this new data, Chen and Palmer (2005) re-
port 86.3% accuracy for verbs using a smoothed
maximum entropy model and rich linguistic fea-
tures, which is 10% higher than their earlier, state-
of-the art performance on ungrouped, fine-grained
senses.
</bodyText>
<subsectionHeader confidence="0.911519">
4.2 Nouns
</subsectionHeader>
<bodyText confidence="0.999933">
We follow a similar procedure for the annotation
of nouns. The same individual who groups Word-
Net verb senses also creates noun senses, starting
with WordNet and other dictionaries. We aim to
double-annotate the 1100 most frequent polyse-
mous nouns in the initial corpus by the end of
2006, while maximizing overlap with the sentences
containing annotated verbs.
Certain nouns carry predicate structure; these
include nominalizations (whose structure obvi-
ously is derived from their verbal form) and vari-
ous types of relational nouns (like father,
President, and believer, that express relations be-
tween entities, often stated using of). We have
identified a limited set of these whose structural
relations can be semi-automatically annotated with
high accuracy.
</bodyText>
<sectionHeader confidence="0.998607" genericHeader="method">
5 Ontology
</sectionHeader>
<bodyText confidence="0.999750451612903">
In standard dictionaries, the senses for each word
are simply listed. In order to allow access to addi-
tional useful information, such as subsumption,
property inheritance, predicate frames from other
sources, links to instances, and so on, our goal is to
link the senses to an ontology. This requires de-
composing the hierarchical structure into subtrees
which can then be inserted at the appropriate con-
ceptual node in the ontology.
The OntoNotes terms are represented in the
110,000-node Omega ontology (Philpot et al.,
2005), under continued construction and extension
at ISI. Omega, which has been used for MT,
summarization, and database alignment, has been
assembled semi-automatically by merging a vari-
ety of sources, including Princeton’s WordNet,
New Mexico State University’s Mikrokosmos, and
a variety of Upper Models, including DOLCE
(Gangemi et al., 2002), SUMO (Niles and Pease,
2001), and ISI’s Upper Model, which are in the
process of being reconciled. The verb frames from
PropBank, FrameNet, WordNet, and Lexical Con-
ceptual Structures (Dorr and Habash, 2001) have
all been included and cross-linked.
In work planned for later this year, verb and
noun sense groupings will be manually inserted
into Omega, replacing the current (primarily
WordNet-derived) contents. For example, of the
verb groups for drive in the table above, G1 and
G4 will be placed into the area of “controlled mo-
tion”, while G2 will then sort with “attitudes”.
</bodyText>
<sectionHeader confidence="0.996955" genericHeader="method">
6 Coreference
</sectionHeader>
<bodyText confidence="0.999952">
The coreference annotation in OntoNotes connects
coreferring instances of specific referring expres-
sions, meaning primarily NPs that introduce or
access a discourse entity. For example, “Elco In-
dustries, Inc.”, “the Rockford, Ill. Maker of fasten-
ers”, and “it” could all corefer. (Non-specific
references like “officials” in “Later, officials re-
ported...” are not included, since coreference for
them is frequently unclear.) In addition, proper
premodifiers and verb phrases can be marked when
coreferent with an NP, such as linking, “when the
company withdrew from the bidding” to “the with-
drawal of New England Electric”.
Unlike the coreference task as defined in the
ACE program, attributives are not generally
marked. For example, the “veterinarian” NP would
not be marked in “Baxter Black is a large animal
veterinarian”. Adjectival modifiers like “Ameri-
can” in “the American embassy” are also not sub-
ject to coreference.
Appositives are annotated as a special kind of
coreference, so that later processing will be able to
supply and interpret the implicit copula link.
All of the coreference annotation is being dou-
bly annotated and adjudicated. In our initial Eng-
lish batch, the average agreement scores between
each annotator and the adjudicated results were
91.8% for normal coreference and 94.2% for ap-
positives.
</bodyText>
<sectionHeader confidence="0.996891" genericHeader="conclusions">
7 Related and Future Work
</sectionHeader>
<bodyText confidence="0.9978986">
PropBank I (Palmer et al., 2005), developed at
UPenn, captures predicate argument structure for
verbs; NomBank provides predicate argument
structure for nominalizations and other noun predi-
cates (Meyers et al., 2004). PropBank II annota-
</bodyText>
<page confidence="0.99738">
59
</page>
<bodyText confidence="0.9999345">
tion (eventuality ID’s, coarse-grained sense tags,
nominal coreference and selected discourse con-
nectives) is being applied to a small (100K) paral-
lel Chinese/English corpus (Babko-Malaya et al.,
2004). The OntoNotes representation extends
these annotations, and allows eventual inclusion of
additional shallow semantic representations for
other phenomena, including temporal and spatial
relations, numerical expressions, deixis, etc. One
of the principal aims of OntoNotes is to enable
automated semantic analysis. The best current al-
gorithm for semantic role labeling for PropBank
style annotation (Pradhan et al., 2005) achieves an
F-measure of 81.0 using an SVM. OntoNotes will
provide a large amount of new training data for
similar efforts.
Existing work in the same realm falls into two
classes: the development of resources for specific
phenomena or the annotation of corpora. An ex-
ample of the former is Berkeley’s FrameNet pro-
ject (Baker et al., 1998), which produces rich
semantic frames, annotating a set of examples for
each predicator (including verbs, nouns and adjec-
tives), and describing the network of relations
among the semantic frames. An example of the
latter type is the Salsa project (Burchardt et al.,
2004), which produced a German lexicon based on
the FrameNet semantic frames and annotated a
large German newswire corpus. A second exam-
ple, the Prague Dependency Treebank (Hajic et al.,
2001), has annotated a large Czech corpus with
several levels of (tectogrammatical) representation,
including parts of speech, syntax, and topic/focus
information structure. Finally, the IL-Annotation
project (Reeder et al., 2004) focused on the repre-
sentations required to support a series of increas-
ingly semantic phenomena across seven languages
(Arabic, Hindi, English, Spanish, Korean, Japanese
and French). In intent and in many details,
OntoNotes is compatible with all these efforts,
which may one day all participate in a larger multi-
lingual corpus integration effort.
</bodyText>
<sectionHeader confidence="0.999001" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999928254237288">
O. Babko-Malaya, M. Palmer, N. Xue, A. Joshi, and S. Ku-
lick. 2004. Proposition Bank II: Delving Deeper, Frontiers
in Corpus Annotation, Workshop, HLT/NAACL
C. F. Baker, C. J. Fillmore, and J. B. Lowe. 1998. The Berke-
ley FrameNet Project. In Proceedings of COLING/ACL,
pages 86-90.
J. Chen and M. Palmer. 2005. Towards Robust High Per-
formance Word Sense Disambiguation of English Verbs
Using Rich Linguistic Features. In Proceedings of
IJCNLP2005, pp. 933-944.
B. Dorr and N. Habash. 2001. Lexical Conceptual Structure
Lexicons. In Calzolari et al. ISLE-IST-1999-10647-WP2-
WP3, Survey of Major Approaches Towards Bilin-
gual/Multilingual Lexicons.
A. Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado, and M.
Pinkal. 2006. Consistency and Coverage: Challenges for
exhaustive semantic annotation. In Proceedings of DGfS-
06.
C. Fellbaum (ed.). 1998. WordNet: An On-line Lexical Data-
base and Some of its Applications. MIT Press.
R. Gabbard, M. Marcus, and S. Kulick. Fully Parsing the Penn
Treebank. In Proceedings of HLT/NAACL 2006.
A. Gangemi, N. Guarino, C. Masolo, A. Oltramari, and L.
Schneider. 2002. Sweetening Ontologies with DOLCE. In
Proceedings of EKAW pp. 166-181.
J. Hajic, B. Vidová-Hladká, and P. Pajas. 2001: The Prague
Dependency Treebank: Annotation Structure and Support.
Proceeding of the IRCS Workshop on Linguistic Data-
bases, pp. 105–114.
M. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993.
Building a Large Annotated Corpus of English: The Penn
Treebank. Computational Linguistics 19: 313-330.
A. Meyers, R. Reeves, C Macleod, R. Szekely, V. Zielinska,
B. Young, and R. Grishman. 2004. The NomBank Project:
An Interim Report. Frontiers in Corpus Annotation, Work-
shop in conjunction with HLT/NAACL.
I. Niles and A. Pease. 2001. Towards a Standard Upper On-
tology. Proceedings of the International Conference on
Formal Ontology in Information Systems (FOIS-2001).
M. Palmer, O. Babko-Malaya, and H. T. Dang. 2004. Differ-
ent Sense Granularities for Different Applications, 2nd
Workshop on Scalable Natural Language Understanding
Systems, at HLT/NAACL-04,
M. Palmer, H. Dang and C. Fellbaum. 2006. Making Fine-
grained and Coarse-grained Sense Distinctions, Both
Manually and Automatically, Journal of Natural Language
Engineering, to appear.
M. Palmer, D. Gildea, and P. Kingsbury. 2005. The Proposi-
tion Bank: A Corpus Annotated with Semantic Roles,
Computational Linguistics, 31(1).
A. Philpot, E.. Hovy, and P. Pantel. 2005. The Omega Ontol-
ogy. Proceedings of the ONTOLEX Workshop at IJCNLP
S. Pradhan, W. Ward, K. Hacioglu, J. Martin, D. Jurafsky.
2005. Semantic Role Labeling Using Different Syntactic
Views. Proceedings of the ACL.
F. Reeder, B. Dorr, D. Farwell, N. Habash, S. Helmreich, E.H.
Hovy, L. Levin, T. Mitamura, K. Miller, O. Rambow, A.
Siddharthan. 2004. Interlingual Annotation for MT Devel-
opment. Proceedings of AMTA.
</reference>
<page confidence="0.998414">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.601332">
<title confidence="0.999392">OntoNotes: The 90% Solution</title>
<author confidence="0.999679">Eduard Hovy Mitchell Marcus Martha Palmer Lance Ramshaw Ralph Weischedel</author>
<affiliation confidence="0.985905">USC/ICI Comp &amp; Info Science ICS and Linguistics BBN Technologies BBN Technologies</affiliation>
<address confidence="0.8449315">4676 Admiralty U. of Pennsylvania U. of Colorado 10 Moulton St. 10 Moulton St. Marina d. R., CA Philadelphia, PA Boulder, CO Cambridge, MA Cambridge, MA</address>
<abstract confidence="0.97442225">hovy mitch martha.palmer lance.ramshaw weischedel @isi.edu @cis.upenn.edu @colorado.edu @bbn.com @bbn.com We describe the OntoNotes methodology and its result, a large multilingual richly-annotated corpus constructed at 90% interannotator agreement. An initial portion (300K words of English newswire and 250K words of Chinese newswire) will be made available to the community during 2007.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>O Babko-Malaya</author>
<author>M Palmer</author>
<author>N Xue</author>
<author>A Joshi</author>
<author>S Kulick</author>
</authors>
<title>Proposition Bank II: Delving Deeper, Frontiers in Corpus Annotation,</title>
<date>2004</date>
<location>Workshop, HLT/NAACL</location>
<contexts>
<context position="11879" citStr="Babko-Malaya et al., 2004" startWordPosition="1840" endWordPosition="1843">ial English batch, the average agreement scores between each annotator and the adjudicated results were 91.8% for normal coreference and 94.2% for appositives. 7 Related and Future Work PropBank I (Palmer et al., 2005), developed at UPenn, captures predicate argument structure for verbs; NomBank provides predicate argument structure for nominalizations and other noun predicates (Meyers et al., 2004). PropBank II annota59 tion (eventuality ID’s, coarse-grained sense tags, nominal coreference and selected discourse connectives) is being applied to a small (100K) parallel Chinese/English corpus (Babko-Malaya et al., 2004). The OntoNotes representation extends these annotations, and allows eventual inclusion of additional shallow semantic representations for other phenomena, including temporal and spatial relations, numerical expressions, deixis, etc. One of the principal aims of OntoNotes is to enable automated semantic analysis. The best current algorithm for semantic role labeling for PropBank style annotation (Pradhan et al., 2005) achieves an F-measure of 81.0 using an SVM. OntoNotes will provide a large amount of new training data for similar efforts. Existing work in the same realm falls into two classes</context>
</contexts>
<marker>Babko-Malaya, Palmer, Xue, Joshi, Kulick, 2004</marker>
<rawString>O. Babko-Malaya, M. Palmer, N. Xue, A. Joshi, and S. Kulick. 2004. Proposition Bank II: Delving Deeper, Frontiers in Corpus Annotation, Workshop, HLT/NAACL</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Baker</author>
<author>C J Fillmore</author>
<author>J B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING/ACL,</booktitle>
<pages>86--90</pages>
<contexts>
<context position="12639" citStr="Baker et al., 1998" startWordPosition="1955" endWordPosition="1958">her phenomena, including temporal and spatial relations, numerical expressions, deixis, etc. One of the principal aims of OntoNotes is to enable automated semantic analysis. The best current algorithm for semantic role labeling for PropBank style annotation (Pradhan et al., 2005) achieves an F-measure of 81.0 using an SVM. OntoNotes will provide a large amount of new training data for similar efforts. Existing work in the same realm falls into two classes: the development of resources for specific phenomena or the annotation of corpora. An example of the former is Berkeley’s FrameNet project (Baker et al., 1998), which produces rich semantic frames, annotating a set of examples for each predicator (including verbs, nouns and adjectives), and describing the network of relations among the semantic frames. An example of the latter type is the Salsa project (Burchardt et al., 2004), which produced a German lexicon based on the FrameNet semantic frames and annotated a large German newswire corpus. A second example, the Prague Dependency Treebank (Hajic et al., 2001), has annotated a large Czech corpus with several levels of (tectogrammatical) representation, including parts of speech, syntax, and topic/fo</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>C. F. Baker, C. J. Fillmore, and J. B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of COLING/ACL, pages 86-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chen</author>
<author>M Palmer</author>
</authors>
<title>Towards Robust High Performance Word Sense Disambiguation of English Verbs Using Rich Linguistic Features.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP2005,</booktitle>
<pages>933--944</pages>
<contexts>
<context position="7639" citStr="Chen and Palmer (2005)" startWordPosition="1186" endWordPosition="1189">ge jobs,” WN8: “drive a nail,” WN15: “drive the herd,” WN22: “drive the game.” G3: to exert energy on behalf of WN5: “Her passion drives her,” WN10: “He is driving away at his thesis.” something NP drive NP/infinitival G4: cause object to move rapidly by WN9: “drive the ball into the outfield ,” WN17 “drive a golf ball,” WN18 “drive a striking it NP drive NP ball” Figure 2. A Portion of the Grouping of WordNet Senses for &amp;quot;drive” 58 dition to improved annotator productivity and accuracy, we predict a corresponding improvement in word sense disambiguation performance. Training on this new data, Chen and Palmer (2005) report 86.3% accuracy for verbs using a smoothed maximum entropy model and rich linguistic features, which is 10% higher than their earlier, stateof-the art performance on ungrouped, fine-grained senses. 4.2 Nouns We follow a similar procedure for the annotation of nouns. The same individual who groups WordNet verb senses also creates noun senses, starting with WordNet and other dictionaries. We aim to double-annotate the 1100 most frequent polysemous nouns in the initial corpus by the end of 2006, while maximizing overlap with the sentences containing annotated verbs. Certain nouns carry pre</context>
</contexts>
<marker>Chen, Palmer, 2005</marker>
<rawString>J. Chen and M. Palmer. 2005. Towards Robust High Performance Word Sense Disambiguation of English Verbs Using Rich Linguistic Features. In Proceedings of IJCNLP2005, pp. 933-944.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorr</author>
<author>N Habash</author>
</authors>
<title>Lexical Conceptual Structure Lexicons. In Calzolari et al. ISLE-IST-1999-10647-WP2-WP3, Survey of Major Approaches Towards Bilingual/Multilingual Lexicons.</title>
<date>2001</date>
<contexts>
<context position="9702" citStr="Dorr and Habash, 2001" startWordPosition="1504" endWordPosition="1507">are represented in the 110,000-node Omega ontology (Philpot et al., 2005), under continued construction and extension at ISI. Omega, which has been used for MT, summarization, and database alignment, has been assembled semi-automatically by merging a variety of sources, including Princeton’s WordNet, New Mexico State University’s Mikrokosmos, and a variety of Upper Models, including DOLCE (Gangemi et al., 2002), SUMO (Niles and Pease, 2001), and ISI’s Upper Model, which are in the process of being reconciled. The verb frames from PropBank, FrameNet, WordNet, and Lexical Conceptual Structures (Dorr and Habash, 2001) have all been included and cross-linked. In work planned for later this year, verb and noun sense groupings will be manually inserted into Omega, replacing the current (primarily WordNet-derived) contents. For example, of the verb groups for drive in the table above, G1 and G4 will be placed into the area of “controlled motion”, while G2 will then sort with “attitudes”. 6 Coreference The coreference annotation in OntoNotes connects coreferring instances of specific referring expressions, meaning primarily NPs that introduce or access a discourse entity. For example, “Elco Industries, Inc.”, “</context>
</contexts>
<marker>Dorr, Habash, 2001</marker>
<rawString>B. Dorr and N. Habash. 2001. Lexical Conceptual Structure Lexicons. In Calzolari et al. ISLE-IST-1999-10647-WP2-WP3, Survey of Major Approaches Towards Bilingual/Multilingual Lexicons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Burchardt</author>
<author>K Erk</author>
<author>A Frank</author>
<author>A Kowalski</author>
<author>S Pado</author>
<author>M Pinkal</author>
</authors>
<title>Consistency and Coverage: Challenges for exhaustive semantic annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of DGfS06.</booktitle>
<marker>Burchardt, Erk, Frank, Kowalski, Pado, Pinkal, 2006</marker>
<rawString>A. Burchardt, K. Erk, A. Frank, A. Kowalski, S. Pado, and M. Pinkal. 2006. Consistency and Coverage: Challenges for exhaustive semantic annotation. In Proceedings of DGfS06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An On-line Lexical Database and Some of its Applications.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum (ed.). 1998. WordNet: An On-line Lexical Database and Some of its Applications. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gabbard</author>
<author>M Marcus</author>
<author>S Kulick</author>
</authors>
<title>Fully Parsing the Penn Treebank.</title>
<date>2006</date>
<booktitle>In Proceedings of HLT/NAACL</booktitle>
<contexts>
<context position="2635" citStr="Gabbard et al., 2006" startWordPosition="379" endWordPosition="382">ed, allowing the entity mentions that are propositional arguments to be resolved in context. Annotation will cover multiple languages (English, Chinese, and Arabic) and multiple genres (newswire, broadcast news, news groups, weblogs, etc.), to create a resource that is broadly applicable. 2 Treebanking The Penn Treebank (Marcus et al., 1993) is annotated with information to make predicate-argument structure easy to decode, including function tags and markers of “empty” categories that represent displaced constituents. To expedite later stages of annotation, we have developed a parsing system (Gabbard et al., 2006) that recovers both of these latter annotations, the first we know of. A firststage parser matches the Collins (2003) parser on which it is based on the Parseval metric, while simultaneously achieving near state-of-the-art performance on recovering function tags (F-measure 89.0). A second stage, a seven stage pipeline of maximum entropy learners and voted perceptrons, achieves state-of-the-art performance (F-measure 74.7) on the recovery of empty categories by combining a linguistically-informed architecture and a rich feature set with the power of modern machine learning methods. 57 Proceedin</context>
</contexts>
<marker>Gabbard, Marcus, Kulick, 2006</marker>
<rawString>R. Gabbard, M. Marcus, and S. Kulick. Fully Parsing the Penn Treebank. In Proceedings of HLT/NAACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gangemi</author>
<author>N Guarino</author>
<author>C Masolo</author>
<author>A Oltramari</author>
<author>L Schneider</author>
</authors>
<title>Sweetening Ontologies with DOLCE.</title>
<date>2002</date>
<booktitle>In Proceedings of EKAW</booktitle>
<pages>166--181</pages>
<contexts>
<context position="9494" citStr="Gangemi et al., 2002" startWordPosition="1471" endWordPosition="1474">al is to link the senses to an ontology. This requires decomposing the hierarchical structure into subtrees which can then be inserted at the appropriate conceptual node in the ontology. The OntoNotes terms are represented in the 110,000-node Omega ontology (Philpot et al., 2005), under continued construction and extension at ISI. Omega, which has been used for MT, summarization, and database alignment, has been assembled semi-automatically by merging a variety of sources, including Princeton’s WordNet, New Mexico State University’s Mikrokosmos, and a variety of Upper Models, including DOLCE (Gangemi et al., 2002), SUMO (Niles and Pease, 2001), and ISI’s Upper Model, which are in the process of being reconciled. The verb frames from PropBank, FrameNet, WordNet, and Lexical Conceptual Structures (Dorr and Habash, 2001) have all been included and cross-linked. In work planned for later this year, verb and noun sense groupings will be manually inserted into Omega, replacing the current (primarily WordNet-derived) contents. For example, of the verb groups for drive in the table above, G1 and G4 will be placed into the area of “controlled motion”, while G2 will then sort with “attitudes”. 6 Coreference The </context>
</contexts>
<marker>Gangemi, Guarino, Masolo, Oltramari, Schneider, 2002</marker>
<rawString>A. Gangemi, N. Guarino, C. Masolo, A. Oltramari, and L. Schneider. 2002. Sweetening Ontologies with DOLCE. In Proceedings of EKAW pp. 166-181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajic</author>
<author>B Vidová-Hladká</author>
<author>P Pajas</author>
</authors>
<title>The Prague Dependency Treebank: Annotation Structure and Support.</title>
<date>2001</date>
<booktitle>Proceeding of the IRCS Workshop on Linguistic Databases,</booktitle>
<pages>105--114</pages>
<marker>Hajic, Vidová-Hladká, Pajas, 2001</marker>
<rawString>J. Hajic, B. Vidová-Hladká, and P. Pajas. 2001: The Prague Dependency Treebank: Annotation Structure and Support. Proceeding of the IRCS Workshop on Linguistic Databases, pp. 105–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<pages>313--330</pages>
<contexts>
<context position="2357" citStr="Marcus et al., 1993" startWordPosition="339" endWordPosition="342">with parse (TreeBank) and propositional (PropBank) structures, which provide normalization over predicates and their arguments. Word sense ambiguities are then resolved, with each word sense also linked to the appropriate node in the Omega ontology. Coreference is also annotated, allowing the entity mentions that are propositional arguments to be resolved in context. Annotation will cover multiple languages (English, Chinese, and Arabic) and multiple genres (newswire, broadcast news, news groups, weblogs, etc.), to create a resource that is broadly applicable. 2 Treebanking The Penn Treebank (Marcus et al., 1993) is annotated with information to make predicate-argument structure easy to decode, including function tags and markers of “empty” categories that represent displaced constituents. To expedite later stages of annotation, we have developed a parsing system (Gabbard et al., 2006) that recovers both of these latter annotations, the first we know of. A firststage parser matches the Collins (2003) parser on which it is based on the Parseval metric, while simultaneously achieving near state-of-the-art performance on recovering function tags (F-measure 89.0). A second stage, a seven stage pipeline of</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics 19: 313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
<author>R Reeves</author>
<author>C Macleod</author>
<author>R Szekely</author>
<author>V Zielinska</author>
<author>B Young</author>
<author>R Grishman</author>
</authors>
<title>The NomBank Project: An Interim Report. Frontiers in Corpus Annotation, Workshop in conjunction with HLT/NAACL.</title>
<date>2004</date>
<contexts>
<context position="11655" citStr="Meyers et al., 2004" startWordPosition="1808" endWordPosition="1811">notated as a special kind of coreference, so that later processing will be able to supply and interpret the implicit copula link. All of the coreference annotation is being doubly annotated and adjudicated. In our initial English batch, the average agreement scores between each annotator and the adjudicated results were 91.8% for normal coreference and 94.2% for appositives. 7 Related and Future Work PropBank I (Palmer et al., 2005), developed at UPenn, captures predicate argument structure for verbs; NomBank provides predicate argument structure for nominalizations and other noun predicates (Meyers et al., 2004). PropBank II annota59 tion (eventuality ID’s, coarse-grained sense tags, nominal coreference and selected discourse connectives) is being applied to a small (100K) parallel Chinese/English corpus (Babko-Malaya et al., 2004). The OntoNotes representation extends these annotations, and allows eventual inclusion of additional shallow semantic representations for other phenomena, including temporal and spatial relations, numerical expressions, deixis, etc. One of the principal aims of OntoNotes is to enable automated semantic analysis. The best current algorithm for semantic role labeling for Pro</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>A. Meyers, R. Reeves, C Macleod, R. Szekely, V. Zielinska, B. Young, and R. Grishman. 2004. The NomBank Project: An Interim Report. Frontiers in Corpus Annotation, Workshop in conjunction with HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Niles</author>
<author>A Pease</author>
</authors>
<title>Towards a Standard Upper Ontology.</title>
<date>2001</date>
<booktitle>Proceedings of the International Conference on Formal Ontology in Information Systems (FOIS-2001).</booktitle>
<contexts>
<context position="9524" citStr="Niles and Pease, 2001" startWordPosition="1476" endWordPosition="1479">n ontology. This requires decomposing the hierarchical structure into subtrees which can then be inserted at the appropriate conceptual node in the ontology. The OntoNotes terms are represented in the 110,000-node Omega ontology (Philpot et al., 2005), under continued construction and extension at ISI. Omega, which has been used for MT, summarization, and database alignment, has been assembled semi-automatically by merging a variety of sources, including Princeton’s WordNet, New Mexico State University’s Mikrokosmos, and a variety of Upper Models, including DOLCE (Gangemi et al., 2002), SUMO (Niles and Pease, 2001), and ISI’s Upper Model, which are in the process of being reconciled. The verb frames from PropBank, FrameNet, WordNet, and Lexical Conceptual Structures (Dorr and Habash, 2001) have all been included and cross-linked. In work planned for later this year, verb and noun sense groupings will be manually inserted into Omega, replacing the current (primarily WordNet-derived) contents. For example, of the verb groups for drive in the table above, G1 and G4 will be placed into the area of “controlled motion”, while G2 will then sort with “attitudes”. 6 Coreference The coreference annotation in Onto</context>
</contexts>
<marker>Niles, Pease, 2001</marker>
<rawString>I. Niles and A. Pease. 2001. Towards a Standard Upper Ontology. Proceedings of the International Conference on Formal Ontology in Information Systems (FOIS-2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>O Babko-Malaya</author>
<author>H T Dang</author>
</authors>
<date>2004</date>
<booktitle>Different Sense Granularities for Different Applications, 2nd Workshop on Scalable Natural Language Understanding Systems, at HLT/NAACL-04,</booktitle>
<contexts>
<context position="4568" citStr="Palmer et al., 2004" startWordPosition="671" endWordPosition="674">VerbNet thematic roles are being added. This style of annotation has also been successfully applied to other genres and languages. 4 Word Sense Word sense ambiguity is a continuing major obstacle to accurate information extraction, summarization and machine translation. The subtle finegrained sense distinctions in WordNet have not lent themselves to high agreement between human annotators or high automatic tagging performance. Building on results in grouping fine-grained WordNet senses into more coarse-grained senses that led to improved inter-annotator agreement (ITA) and system performance (Palmer et al., 2004; Palmer et al., 2006), we have developed a process for rapid sense inventory creation and annotation that includes critical links between the grouped word senses and the Omega ontology (Philpot et al., 2005; see Section 5 below). This process is based on recognizing that sense distinctions can be represented by linguists in an hierarchical structure, similar to a decision tree, that is rooted in very coarse-grained distinctions which become increasingly fine-grained until reaching WordNet senses at the leaves. Sets of senses under specific nodes of the tree are grouped together into single en</context>
</contexts>
<marker>Palmer, Babko-Malaya, Dang, 2004</marker>
<rawString>M. Palmer, O. Babko-Malaya, and H. T. Dang. 2004. Different Sense Granularities for Different Applications, 2nd Workshop on Scalable Natural Language Understanding Systems, at HLT/NAACL-04,</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>H Dang</author>
<author>C Fellbaum</author>
</authors>
<title>Making Finegrained and Coarse-grained Sense Distinctions,</title>
<date>2006</date>
<journal>Both Manually and Automatically, Journal of Natural Language Engineering,</journal>
<note>to appear.</note>
<contexts>
<context position="4590" citStr="Palmer et al., 2006" startWordPosition="675" endWordPosition="678">s are being added. This style of annotation has also been successfully applied to other genres and languages. 4 Word Sense Word sense ambiguity is a continuing major obstacle to accurate information extraction, summarization and machine translation. The subtle finegrained sense distinctions in WordNet have not lent themselves to high agreement between human annotators or high automatic tagging performance. Building on results in grouping fine-grained WordNet senses into more coarse-grained senses that led to improved inter-annotator agreement (ITA) and system performance (Palmer et al., 2004; Palmer et al., 2006), we have developed a process for rapid sense inventory creation and annotation that includes critical links between the grouped word senses and the Omega ontology (Philpot et al., 2005; see Section 5 below). This process is based on recognizing that sense distinctions can be represented by linguists in an hierarchical structure, similar to a decision tree, that is rooted in very coarse-grained distinctions which become increasingly fine-grained until reaching WordNet senses at the leaves. Sets of senses under specific nodes of the tree are grouped together into single entries, along with the </context>
</contexts>
<marker>Palmer, Dang, Fellbaum, 2006</marker>
<rawString>M. Palmer, H. Dang and C. Fellbaum. 2006. Making Finegrained and Coarse-grained Sense Distinctions, Both Manually and Automatically, Journal of Natural Language Engineering, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>P Kingsbury</author>
</authors>
<title>The Proposition Bank: A Corpus Annotated with Semantic Roles,</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="3865" citStr="Palmer et al., 2005" startWordPosition="566" endWordPosition="569">Human Language Technology Conference of the North American Chapter of the ACL, pages 57–60, New York, June 2006. c�2006 Association for Computational Linguistics 3 PropBanking The Penn Proposition Bank, funded by ACE (DOD), focuses on the argument structure of verbs, and provides a corpus annotated with semantic roles, including participants traditionally viewed as arguments and adjuncts. The 1M word Penn Treebank II Wall Street Journal corpus has been successfully annotated with semantic argument structures for verbs and is now available via the Penn Linguistic Data Consortium as PropBank I (Palmer et al., 2005). Links from the argument labels in the Frames Files to FrameNet frame elements and VerbNet thematic roles are being added. This style of annotation has also been successfully applied to other genres and languages. 4 Word Sense Word sense ambiguity is a continuing major obstacle to accurate information extraction, summarization and machine translation. The subtle finegrained sense distinctions in WordNet have not lent themselves to high agreement between human annotators or high automatic tagging performance. Building on results in grouping fine-grained WordNet senses into more coarse-grained </context>
<context position="11471" citStr="Palmer et al., 2005" startWordPosition="1783" endWordPosition="1786">d not be marked in “Baxter Black is a large animal veterinarian”. Adjectival modifiers like “American” in “the American embassy” are also not subject to coreference. Appositives are annotated as a special kind of coreference, so that later processing will be able to supply and interpret the implicit copula link. All of the coreference annotation is being doubly annotated and adjudicated. In our initial English batch, the average agreement scores between each annotator and the adjudicated results were 91.8% for normal coreference and 94.2% for appositives. 7 Related and Future Work PropBank I (Palmer et al., 2005), developed at UPenn, captures predicate argument structure for verbs; NomBank provides predicate argument structure for nominalizations and other noun predicates (Meyers et al., 2004). PropBank II annota59 tion (eventuality ID’s, coarse-grained sense tags, nominal coreference and selected discourse connectives) is being applied to a small (100K) parallel Chinese/English corpus (Babko-Malaya et al., 2004). The OntoNotes representation extends these annotations, and allows eventual inclusion of additional shallow semantic representations for other phenomena, including temporal and spatial relat</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>M. Palmer, D. Gildea, and P. Kingsbury. 2005. The Proposition Bank: A Corpus Annotated with Semantic Roles, Computational Linguistics, 31(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Philpot</author>
<author>E Hovy</author>
<author>P Pantel</author>
</authors>
<title>The Omega Ontology.</title>
<date>2005</date>
<booktitle>Proceedings of the ONTOLEX Workshop at IJCNLP</booktitle>
<contexts>
<context position="4775" citStr="Philpot et al., 2005" startWordPosition="705" endWordPosition="708">e information extraction, summarization and machine translation. The subtle finegrained sense distinctions in WordNet have not lent themselves to high agreement between human annotators or high automatic tagging performance. Building on results in grouping fine-grained WordNet senses into more coarse-grained senses that led to improved inter-annotator agreement (ITA) and system performance (Palmer et al., 2004; Palmer et al., 2006), we have developed a process for rapid sense inventory creation and annotation that includes critical links between the grouped word senses and the Omega ontology (Philpot et al., 2005; see Section 5 below). This process is based on recognizing that sense distinctions can be represented by linguists in an hierarchical structure, similar to a decision tree, that is rooted in very coarse-grained distinctions which become increasingly fine-grained until reaching WordNet senses at the leaves. Sets of senses under specific nodes of the tree are grouped together into single entries, along with the syntactic and semantic criteria for their groupings, to be presented to the annotators. As shown in Figure 1, a 50-sentence sample of instances is annotated and immediately checked for </context>
<context position="9153" citStr="Philpot et al., 2005" startWordPosition="1422" endWordPosition="1425"> whose structural relations can be semi-automatically annotated with high accuracy. 5 Ontology In standard dictionaries, the senses for each word are simply listed. In order to allow access to additional useful information, such as subsumption, property inheritance, predicate frames from other sources, links to instances, and so on, our goal is to link the senses to an ontology. This requires decomposing the hierarchical structure into subtrees which can then be inserted at the appropriate conceptual node in the ontology. The OntoNotes terms are represented in the 110,000-node Omega ontology (Philpot et al., 2005), under continued construction and extension at ISI. Omega, which has been used for MT, summarization, and database alignment, has been assembled semi-automatically by merging a variety of sources, including Princeton’s WordNet, New Mexico State University’s Mikrokosmos, and a variety of Upper Models, including DOLCE (Gangemi et al., 2002), SUMO (Niles and Pease, 2001), and ISI’s Upper Model, which are in the process of being reconciled. The verb frames from PropBank, FrameNet, WordNet, and Lexical Conceptual Structures (Dorr and Habash, 2001) have all been included and cross-linked. In work p</context>
</contexts>
<marker>Philpot, Hovy, Pantel, 2005</marker>
<rawString>A. Philpot, E.. Hovy, and P. Pantel. 2005. The Omega Ontology. Proceedings of the ONTOLEX Workshop at IJCNLP S. Pradhan, W. Ward, K. Hacioglu, J. Martin, D. Jurafsky. 2005. Semantic Role Labeling Using Different Syntactic Views. Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Reeder</author>
<author>B Dorr</author>
<author>D Farwell</author>
<author>N Habash</author>
<author>S Helmreich</author>
<author>E H Hovy</author>
<author>L Levin</author>
<author>T Mitamura</author>
<author>K Miller</author>
<author>O Rambow</author>
<author>A Siddharthan</author>
</authors>
<title>Interlingual Annotation for MT Development.</title>
<date>2004</date>
<booktitle>Proceedings of AMTA.</booktitle>
<marker>Reeder, Dorr, Farwell, Habash, Helmreich, Hovy, Levin, Mitamura, Miller, Rambow, Siddharthan, 2004</marker>
<rawString>F. Reeder, B. Dorr, D. Farwell, N. Habash, S. Helmreich, E.H. Hovy, L. Levin, T. Mitamura, K. Miller, O. Rambow, A. Siddharthan. 2004. Interlingual Annotation for MT Development. Proceedings of AMTA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>