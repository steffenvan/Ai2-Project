<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008039">
<title confidence="0.922177">
Temporal Evaluation
</title>
<author confidence="0.990233">
Naushad UzZaman and James F. Allen
</author>
<affiliation confidence="0.9962145">
Computer Science Department
University of Rochester
</affiliation>
<address confidence="0.853195">
Rochester, NY, USA
</address>
<email confidence="0.999505">
{naushad, james}@cs.rochester.edu
</email>
<sectionHeader confidence="0.993961" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998577909090909">
In this paper we propose a new method for
evaluating systems that extract temporal
information from text. It uses temporal
closure1 to reward relations that are
equivalent but distinct. Our metric
measures the overall performance of
systems with a single score, making
comparison between different systems
straightforward. Our approach is easy to
implement, intuitive, accurate, scalable and
computationally inexpensive.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.936862069767442">
The recent emergence of language processing
applications like question answering, information
extraction, and document summarization has
motivated the need for temporally-aware systems.
This, along with the availability of the temporal
annotation scheme TimeML (Pustejovsky et al.,
2003), a temporally annotated corpus, TimeBank
(Pustejovsky et al., 2003) and the temporal
evaluation challenges TempEval-1 (Verhagen et
al., 2007) and TempEval-2 (Pustejovsky and
Verhagen, 2010), has led to an explosion of
research on temporal information processing (TIP).
Prior evaluation methods (TempEval-1, 2) for
different TIP subtasks have borrowed precision
and recall measures from the information retrieval
community. This has two problems: First, systems
express temporal relations in different, yet
equivalent, ways. Consider a scenario where the
1 Temporal closure is a reasoning mechanism that derives new
implied temporal relations, i.e. makes implicit temporal
relations explicit. For example, if we know A before B, B
before C, then using temporal closure we can derive A before
C. Allen (1983) demonstrates the closure table for 13 Allen
interval relations.
reference annotation contains e1&lt;e2 and e2&lt;e3 and
the system identifies the relation e1&lt;e3. The
traditional evaluation metric will fail to identify
e1&lt;e3 as a correct relation, which is a logical
consequence of the reference annotation. Second,
traditional evaluations tell us how well a system
performs in a particular task, but not the overall
performance. For example, in TempEval-2 there
were 6 subtasks (event extraction, temporal
expression extraction and 4 subtasks on identifying
temporal relations). Thus, different systems
perform best is different subtasks, but we can’t
compare overall performance of systems.
We use temporal closure to identify equivalent
temporal relations and produce a single score that
measures the temporal awareness of each system.
We use Timegraph (Miller and Schubert, 1990) for
computing temporal closure, which makes our
system scalable and computationally inexpensive.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999958578947369">
To calculate the inter-annotator agreement between
annotators in the temporal annotation task, some
researchers have used semantic matching to reward
distinct but equivalent temporal relations. Such
techniques can equally well be applied to system
evaluation.
Setzer et al. (2003) use temporal closure to
reward equivalent but distinct relations. Consider
the example in Figure 1 (due to Tannier and
Muller, 2008). Consider graph K as the reference
annotation graph, and S1, S2 and S3 as outputs of
different systems. The bold edges are the extracted
relations and the dotted edges are derived. The
traditional matching approach will fail to verify
B&lt;D is a correct relation in S2, since there is no
explicit edge between B and D in reference
annotation (K). But a metric using temporal
closure would create all implicit edges and be able
to reward B&lt;D edge in S2.
</bodyText>
<page confidence="0.98512">
351
</page>
<note confidence="0.892773">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 351–356,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999928">
Figure 1: Examples of temporal graphs and relations
</figureCaption>
<bodyText confidence="0.999939846153846">
Setzer et al.’s approach works for this particular
case, but as pointed by Tannier and Muller (2008),
it gives the same importance to all relations,
whereas some relations are not as crucial as others.
For example, with K again as the reference
annotation, S2 and S3 both identify two correct
relations, so both should have a 100% precision,
but in terms of recall, S3 identified 2 explicit
relations and S2 identified one explicit and one
implicit relation. With Setzer at al.’s technique,
both S2 and S3 will get the same score, which is not
accurate. Tannier and Muller handle this problem
by finding the core2 relations. For recall, they
consider the reference core relations found in the
system core relations and for precision they
consider the system core relations found in the
reference core relations. They noted that core
relations do not contain all information provided
by closed graphs. Hence their measure is only an
approximation of what should be assessed.
Consider the previous example again. If we are
evaluating graph S2, they will fail to verify that
B&lt;D is a correct edge.
We have shown that both of these existing
evaluation mechanism reward relations based on
semantic matching, but still fail in specific cases.
</bodyText>
<sectionHeader confidence="0.989129" genericHeader="method">
3 Temporal Evaluation
</sectionHeader>
<bodyText confidence="0.992511307692308">
We also use temporal closure to reward equivalent
but distinct relations. However, we do not compare
against the temporal closure of reference
annotation and system output, like Setzer et al., but
2 For relation RA, B between A and B, derivations are RA, C, RB,
C, RA, D, RB, D. If the intersection of all these derived relations
equals RA, B, it means that RA, B is not a core relation, since it
can be obtained by composing some other relations.
Otherwise, the relation is a core, since removing it tends to
loss of information.
we use the temporal closure to verify if a temporal
relation can be derived or not. Our precision and
recall is defined as:
</bodyText>
<construct confidence="0.986793">
Precision = (# of system temporal relations that can be
verified from reference annotation temporal closure
graph / # of temporal relations in system output)
Recall = (# of reference annotation temporal relations
that can be verified from system output’s temporal
closure graph / # of temporal relations in reference
annotation)
</construct>
<bodyText confidence="0.999888952380953">
The harmonic mean of precision and recall, i.e.
fscore, will give an evaluation of the temporal
awareness of the system.
As an example, consider again the examples in
Figure 1, with K as reference annotation. S1 and S3
clearly have 100% precision, and S2 also gets
100% precision, since the B&lt;D edge can be
verified through the temporal closure graph of K.
Note, our recall measure doesn’t reward the B&lt;D
edge of S2, but it is counted for precision. S1 and S3
both get a recall of 2/3, since 2 edges can be
verified in the reference temporal closure graph.
This scheme is similar to the MUC-6 scoring for
coreference (Vilain et al., 1995). Their scoring
estimated the minimal number of missing links
necessary to complete co-reference chain in order
to make it match the human annotation. Here in
both S1 and S3, we are missing one edge to match
with the reference annotation; hence 2/3 is the
appropriate score. Precision, recall and fscore for
all these system output are shown in Table 1.
</bodyText>
<table confidence="0.99836725">
System Precision Recall Fscore
S1 2/2=1 2/3=0.66 0.8
S2 2/2=1 1/3=0.33 0.5
S3 2/2=1 2/3=0.66 0.8
</table>
<tableCaption confidence="0.989462">
Table 1: Precision, recall and fscore for systems in
</tableCaption>
<figureCaption confidence="0.708288">
Figure 1 according to our evaluation metric
</figureCaption>
<sectionHeader confidence="0.997404" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.8477414">
Our proposed approach is easy to implement with
an existing temporal closure implementation. We
preferred Timegraph (Miller and Schubert, 1990)
over Allen’s interval closure algorithm (Allen,
1983) because Timegraph has been shown to be
more scalable3 to larger problems (Yampratoom
3 Allen’s temporal closure takes O(n2) space for n intervals,
whereas Timegraph takes O(n+e) space, where n is the
number of time points3 and e is the number of relations
between them. In terms of closure computation, without
</bodyText>
<page confidence="0.993076">
352
</page>
<bodyText confidence="0.992358114285715">
and Allen, 1993). Furthermore, the additional
expressive power of interval disjunction in Allen
(1983) does not appear to play a significant role in
temporal extractions from text.
A Timegraph G = (T, E) is an acyclic directed
graph in which T is the set of vertices (nodes) and
E is the set of edges (links). It is partitioned into
chains, which are defined as sets of points in a
linear order. Links between points in the same
chain are in-chain links and links between points in
different chains are cross-chain links. Each point
has a numeric pseudo-time, which is arbitrary
except that it maintains the ordering relationship
between the points on the same chain. Chain and
pseudo-time information are calculated when the
point is first entered into the Timegraph.
Determining relationship between any two points
in the same chain can be done in constant time
simply by comparing the pseudo-times, rather than
following the in-chain links. On the other hand,
relationship between points in different chains can
be found with a search in cross-chain links, which
is dependent on the number of edges (i.e. number
of chains and number of cross-chain links). A
metagraph keeps track of the cross-chain links
effectively by maintaining a metanode for each
chain, and using a cross-chain links between
metanodes. More details about Timegraph can be
found in Miller and Schubert (1990) and Taugher
(1983).
Timegraph only supports simple point relations
(&lt;, =, ≤), but we need to evaluate systems based on
TimeML, which is based on interval algebra.
However, single (i.e., non-disjunctive) interval
relations can be easily converted to point
relations4.
For efficiency, we want to minimize the number
of chains constructed by Timegraph, since with
more chains our search in Timegraph will take
more time. If we arbitrarily choose TimeML
TLINKs (temporal links) and add them we will
create some extra chains. To avoid this, we start
with a node and traverse through its neighbors in a
systematic fashion trying to add in chain order.
disjunction Allen’s algorithm computes in O(n2), whereas
Timegraph takes O(n+e) time, n and e are same as before.
4 Interval relation between two intervals X and Y is
represented with points x1, x2, y1 and y2, where x1 and y1 are
start points and x2 and y2 are end points of X and Y.
Temporal relations between interval X and Y is represented
with point relation between x1,y1; x1,y2; x2,y1 and x2,y2.
This approach decreases number of nodes+edges
by 2.3% in complete TimeBank corpus, which
eventually affects searching in Timegraph.
Next addition is to optimize Timegraph
construction. For each relation we have to make
sure all constraints are met. The easiest and best
way to approach this is to consider all relations
together. For example, for interval relation X
includes Y, the point relation constraints are:
x1&lt;y1, x1&lt;y2, x2&gt;y1, x2&gt;y2, x1&lt;x2 and y1&lt;y2.
We want to consider all constraints together as, x1
&lt; y1 &lt; y2 &lt; x2 and add all together in the
Timegraph. In Table 2, we show TimeML relations
and equivalent Allen’s relation5, then equivalent
representation in point algebra and finally point
algebra represented as a chain, which makes
adding relations in Timegraph much easier with
fewer chains. These additions make Timegraph
more effective for TimeML corpus.
</bodyText>
<table confidence="0.993384333333333">
TimeML Allen Equivalent in Point
relations relations Point Algebra Algebra
represented
as a chain
Before Before x1&lt;y1, x1&lt;y2, x1 &lt; x2 &lt;
x2&lt;y1, x2&lt;y2 y1 &lt; y2
After After x1&gt;y1, x1&gt;y2, y1 &lt; y2 &lt; x1
x2&gt;y1, x2&gt;y2 &lt; x2
IBefore Meet x1&lt;y1, x1&lt;y2, x1 &lt; x2 = y1
x2=y1, x2&lt;y2 &lt; y2
IAfter MetBy x1&gt;y1, x1=y2, y1 &lt; y2 = x1
x2&gt;y1, x2&gt;y2 &lt; x2
Begins Start x1=y1, x1&lt;y2, x1 = y1 &lt; x2
x2&gt;y1, x2&lt;y2 &lt; y2
BegunBy StartedBy x1=y1, x1&lt;y2, x1 = y1 &lt; y2
x2&gt;y1, x2&gt;y2 &lt; x2
Ends Finish x1&gt;y1, x1&lt;y2, y1 &lt; x1 &lt; x2
x2&gt;y1, x2=y2 = y2
EndedBy FinishedBy x1&lt;y1, x1&lt;y2, x1 &lt; y1 &lt; y2
x2&gt;y1, x2=y2 = x2
IsIncluded, During x1&gt;y1, x1&lt;y2, y1 &lt; x1 &lt; x2
During x2&gt;y1, x2&lt;y2 &lt; y2
Includes Contains x1&lt;y1, x1&lt;y2, x1 &lt; y1 &lt; y2
x2&gt;y1, x2&gt;y2 &lt; x2
Identity &amp; Equality x1=y1, x1&lt;y2, x1 = y1 &lt; x2
Simultaneous x2&gt;y1, x2=y2 = y2
(=)
</table>
<tableCaption confidence="0.998704">
Table 2: Interval algebra and equivalent point algebra
</tableCaption>
<footnote confidence="0.9001985">
5 We couldn’t find equivalent of Overlaps and OverlappedBy
from Allen’s interval algebra in TimeML relations.
</footnote>
<page confidence="0.998799">
353
</page>
<sectionHeader confidence="0.995507" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.919904277777778">
Our proposed evaluation metric has some very
good properties, which makes it very suitable as a
standard metric. This section presents a few
empirical tests to show the usefulness of our
metric.
Our precision and recall goes with the same
spirit with traditional precision and recall, as a
result, performance decreases with the decrease of
information. Specifically,
i. if we remove relations from the reference
annotation and then compare that against the full
reference annotation, then recall decreases linearly.
Shown in Figure 2.
Figure 2: For 5 TimeBank documents, the graph shows
performance drops linearly in recall by removing
temporal relations one by one.
ii. if we introduce noise by adding new relations,
then precision decreases linearly (Figure 3).
</bodyText>
<figureCaption confidence="0.978681">
Figure 3: For 5 TimeBank documents, the graph shows
performance drops linearly in precision by adding new
(wrong) temporal relations one by one.
</figureCaption>
<bodyText confidence="0.924934666666667">
iii. if we introduce noise by changing existing
relations then fscore decreases linearly (Figure 4).
Figure 4: For 5 TimeBank documents, the graph shows
performance drops linearly in fscore by changing
temporal relations one by one.
iv. if we remove temporal entities (such as
events or temporal expressions), performance
decreases more for entities that are temporally
related to more entities. This means, if the system
fails to extract important temporal entities then the
performance will decrease more (Figure 5).
Figure 5: For 5 TimeBank documents, performance
drop in recall by removing temporal entities.
Temporal entities related with a maximum
number of entities are removed first. It is evident
from the graph that performance decreased more
for removing important entities (first few entities).
These properties explain that our final fscore
captures how well a system extracts events,
temporal expressions and temporal relations.
Therefore this single score captures all the scores
of six subtasks in TempEval-2, making it very
convenient and straightforward to compare
different systems.
Our implementation using Timegraph is also
scalable. We ran our Timegraph construction
algorithm on the complete TimeBank corpus and
found that Timegraph construction time increases
linearly with the increase of number of nodes and
edges (= # of cross-chain links and # of chains)
(Figure 6).
The largest document, with 235 temporal
relations (around 900 nodes+edges in Timegraph)
</bodyText>
<page confidence="0.997081">
354
</page>
<figureCaption confidence="0.905062142857143">
only takes 0.22 seconds in a laptop computer with
4GB RAM and 2.26 GHz Core 2 Duo processor.
Figure 8: Number of relation against time (in seconds)
for all documents of TimeBank corpus.
Figure 6: Number of nodes+edges (# of cross-chain
links + # of chains) against time (in seconds) for
Timegraph construction of all TimeBank documents.
</figureCaption>
<bodyText confidence="0.997820333333333">
We also confirmed that the number of nodes +
edges in Timegraph also increases linearly with
number of temporal relations in TimeBank
documents. , i.e. our Timegraph construction time
correlates with the # of relations in TimeBank
documents (Figure 7).
</bodyText>
<figureCaption confidence="0.926460333333333">
Figure 7: Number of temporal relations in all TimeBank
documents against the number of nodes and edges in
Timegraph of those documents
</figureCaption>
<bodyText confidence="0.9998776">
Searching in Timegraph, which we need for
temporal evaluation, also depends on number of
nodes and edges, hence number of TimeBank
relations. We ran a temporal evaluation on
TimeBank corpus using the same document as
system output. The operation included creating two
Timegraphs and searching in the Timegraph. As
expected, the searching time also increases linearly
against the number of relations and is
computationally inexpensive (Figure 8).
</bodyText>
<sectionHeader confidence="0.999174" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999464">
We proposed a temporal evaluation that considers
semantically similar but distinct temporal relations
and consequently gives a single score, which could
be used for identifying the temporal awareness of a
system. Our approach is easy to implement,
intuitive and accurate. We implemented it using
Timegraph for handling temporal closure in
TimeML derived corpora, which makes our
implementation scalable and computationally
inexpensive.
</bodyText>
<sectionHeader confidence="0.998191" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995651904761905">
James F. Allen. 1983. Maintaining knowledge
about temporal intervals. Communications of the
ACM 26, 832-843.
S. Miller and L. Schubert. 1990. Time revisited.
Computational Intelligence 6, 108-118.
J. Pustejovsky, P. Hanks, R. Sauri, A. See, R.
Gaizauskas, A. Setzer, D. Radev, B. Sundheim,
D. Day, L. Ferro and M. Lazo. 2003. The
TIMEBANK corpus. Proceedings of the Corpus
Linguistics, 647–656.
James Pustejovsky, Jos M. Castao, Robert Ingria,
Roser Sauri, Robert J. Gaizauskas, Andrea
Setzer, Graham Katz and Dragomir R. Radev.
2003. TimeML: Robust Specication of Event
and Temporal Expressions in Text. .
Proceedings of the New Directions in Question
Answering.
James Pustejovsky and Marc Verhagen. 2010.
SemEval-2010 task 13: evaluating events, time
expressions, and temporal relations (TempEval-
2). Proceedings of the Workshop on Semantic
</reference>
<page confidence="0.985469">
355
</page>
<reference confidence="0.999477451612903">
Evaluations: Recent Achievements and Future
Directions.
A Setzer, R Gaizauskas and M Hepple. 2003.
Using semantic inferences for temporal
annotation comparison. Proceedings of the
Fourth International Workshop on Inference in
Computational Semantics (ICOS-4), 25-26.
X Tannier and P Muller. 2008. Evaluation Metrics
for Automatic Temporal Annotation of Texts.
Proceedings of the Proceedings of the Sixth
International Language Resources and
Evaluation (LREC&apos;08).
J. Taugher. 1983. An efficient representation for
time information. Department of Computer
Science. Edmonton, Canada: University of
Alberta.
Marc Verhagen, Robert Gaizauskas, Frank
Schilder, Mark Hepple, Graham Katz and James
Pustejovsky. 2007. SemEval-2007 Task 15:
TempEval Temporal Relation Identification.
Proceedings of the 4th International Workshop
on Semantic Evaluations (SemEval 2007).
Marc Vilain, John Burger, John Aberdeen, Dennis
Connolly and Lynette Hirschman. 1995. A
model-theoretic coreference scoring scheme.
Proceedings of the MUC6 ’95: Proceedings of
the 6th conference on Message understanding.
Ed Yampratoom and James F. Allen. 1993.
Performance of Temporal Reasoning Systems.
TRAINS Technical Note 93-1. Rochester, NY:
University of Rochester.
</reference>
<page confidence="0.999001">
356
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.940968">
<title confidence="0.998694">Temporal Evaluation</title>
<author confidence="0.968458">Naushad UzZaman</author>
<author confidence="0.968458">F James</author>
<affiliation confidence="0.999796">Computer Science University of</affiliation>
<address confidence="0.999848">Rochester, NY, USA</address>
<email confidence="0.9999">naushad@cs.rochester.edu</email>
<email confidence="0.9999">james@cs.rochester.edu</email>
<abstract confidence="0.997671666666667">In this paper we propose a new method for evaluating systems that extract temporal information from text. It uses temporal to reward relations that are equivalent but distinct. Our metric measures the overall performance of systems with a single score, making comparison between different systems straightforward. Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Communications of the ACM</journal>
<volume>26</volume>
<pages>832--843</pages>
<contexts>
<context position="1699" citStr="Allen (1983)" startWordPosition="234" endWordPosition="235"> led to an explosion of research on temporal information processing (TIP). Prior evaluation methods (TempEval-1, 2) for different TIP subtasks have borrowed precision and recall measures from the information retrieval community. This has two problems: First, systems express temporal relations in different, yet equivalent, ways. Consider a scenario where the 1 Temporal closure is a reasoning mechanism that derives new implied temporal relations, i.e. makes implicit temporal relations explicit. For example, if we know A before B, B before C, then using temporal closure we can derive A before C. Allen (1983) demonstrates the closure table for 13 Allen interval relations. reference annotation contains e1&lt;e2 and e2&lt;e3 and the system identifies the relation e1&lt;e3. The traditional evaluation metric will fail to identify e1&lt;e3 as a correct relation, which is a logical consequence of the reference annotation. Second, traditional evaluations tell us how well a system performs in a particular task, but not the overall performance. For example, in TempEval-2 there were 6 subtasks (event extraction, temporal expression extraction and 4 subtasks on identifying temporal relations). Thus, different systems pe</context>
<context position="7454" citStr="Allen, 1983" startWordPosition="1162" endWordPosition="1163"> Here in both S1 and S3, we are missing one edge to match with the reference annotation; hence 2/3 is the appropriate score. Precision, recall and fscore for all these system output are shown in Table 1. System Precision Recall Fscore S1 2/2=1 2/3=0.66 0.8 S2 2/2=1 1/3=0.33 0.5 S3 2/2=1 2/3=0.66 0.8 Table 1: Precision, recall and fscore for systems in Figure 1 according to our evaluation metric 4 Implementation Our proposed approach is easy to implement with an existing temporal closure implementation. We preferred Timegraph (Miller and Schubert, 1990) over Allen’s interval closure algorithm (Allen, 1983) because Timegraph has been shown to be more scalable3 to larger problems (Yampratoom 3 Allen’s temporal closure takes O(n2) space for n intervals, whereas Timegraph takes O(n+e) space, where n is the number of time points3 and e is the number of relations between them. In terms of closure computation, without 352 and Allen, 1993). Furthermore, the additional expressive power of interval disjunction in Allen (1983) does not appear to play a significant role in temporal extractions from text. A Timegraph G = (T, E) is an acyclic directed graph in which T is the set of vertices (nodes) and E is </context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>James F. Allen. 1983. Maintaining knowledge about temporal intervals. Communications of the ACM 26, 832-843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miller</author>
<author>L Schubert</author>
</authors>
<title>Time revisited.</title>
<date>1990</date>
<journal>Computational Intelligence</journal>
<volume>6</volume>
<pages>108--118</pages>
<contexts>
<context position="2576" citStr="Miller and Schubert, 1990" startWordPosition="360" endWordPosition="363">a logical consequence of the reference annotation. Second, traditional evaluations tell us how well a system performs in a particular task, but not the overall performance. For example, in TempEval-2 there were 6 subtasks (event extraction, temporal expression extraction and 4 subtasks on identifying temporal relations). Thus, different systems perform best is different subtasks, but we can’t compare overall performance of systems. We use temporal closure to identify equivalent temporal relations and produce a single score that measures the temporal awareness of each system. We use Timegraph (Miller and Schubert, 1990) for computing temporal closure, which makes our system scalable and computationally inexpensive. 2 Related Work To calculate the inter-annotator agreement between annotators in the temporal annotation task, some researchers have used semantic matching to reward distinct but equivalent temporal relations. Such techniques can equally well be applied to system evaluation. Setzer et al. (2003) use temporal closure to reward equivalent but distinct relations. Consider the example in Figure 1 (due to Tannier and Muller, 2008). Consider graph K as the reference annotation graph, and S1, S2 and S3 as</context>
<context position="7400" citStr="Miller and Schubert, 1990" startWordPosition="1153" endWordPosition="1156">e co-reference chain in order to make it match the human annotation. Here in both S1 and S3, we are missing one edge to match with the reference annotation; hence 2/3 is the appropriate score. Precision, recall and fscore for all these system output are shown in Table 1. System Precision Recall Fscore S1 2/2=1 2/3=0.66 0.8 S2 2/2=1 1/3=0.33 0.5 S3 2/2=1 2/3=0.66 0.8 Table 1: Precision, recall and fscore for systems in Figure 1 according to our evaluation metric 4 Implementation Our proposed approach is easy to implement with an existing temporal closure implementation. We preferred Timegraph (Miller and Schubert, 1990) over Allen’s interval closure algorithm (Allen, 1983) because Timegraph has been shown to be more scalable3 to larger problems (Yampratoom 3 Allen’s temporal closure takes O(n2) space for n intervals, whereas Timegraph takes O(n+e) space, where n is the number of time points3 and e is the number of relations between them. In terms of closure computation, without 352 and Allen, 1993). Furthermore, the additional expressive power of interval disjunction in Allen (1983) does not appear to play a significant role in temporal extractions from text. A Timegraph G = (T, E) is an acyclic directed gra</context>
<context position="9152" citStr="Miller and Schubert (1990)" startWordPosition="1439" endWordPosition="1442">e Timegraph. Determining relationship between any two points in the same chain can be done in constant time simply by comparing the pseudo-times, rather than following the in-chain links. On the other hand, relationship between points in different chains can be found with a search in cross-chain links, which is dependent on the number of edges (i.e. number of chains and number of cross-chain links). A metagraph keeps track of the cross-chain links effectively by maintaining a metanode for each chain, and using a cross-chain links between metanodes. More details about Timegraph can be found in Miller and Schubert (1990) and Taugher (1983). Timegraph only supports simple point relations (&lt;, =, ≤), but we need to evaluate systems based on TimeML, which is based on interval algebra. However, single (i.e., non-disjunctive) interval relations can be easily converted to point relations4. For efficiency, we want to minimize the number of chains constructed by Timegraph, since with more chains our search in Timegraph will take more time. If we arbitrarily choose TimeML TLINKs (temporal links) and add them we will create some extra chains. To avoid this, we start with a node and traverse through its neighbors in a sy</context>
</contexts>
<marker>Miller, Schubert, 1990</marker>
<rawString>S. Miller and L. Schubert. 1990. Time revisited. Computational Intelligence 6, 108-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>P Hanks</author>
<author>R Sauri</author>
<author>A See</author>
<author>R Gaizauskas</author>
<author>A Setzer</author>
<author>D Radev</author>
<author>B Sundheim</author>
<author>D Day</author>
<author>L Ferro</author>
<author>M Lazo</author>
</authors>
<date>2003</date>
<booktitle>The TIMEBANK corpus. Proceedings of the Corpus Linguistics,</booktitle>
<pages>647--656</pages>
<contexts>
<context position="892" citStr="Pustejovsky et al., 2003" startWordPosition="114" endWordPosition="117">m text. It uses temporal closure1 to reward relations that are equivalent but distinct. Our metric measures the overall performance of systems with a single score, making comparison between different systems straightforward. Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive. 1 Introduction The recent emergence of language processing applications like question answering, information extraction, and document summarization has motivated the need for temporally-aware systems. This, along with the availability of the temporal annotation scheme TimeML (Pustejovsky et al., 2003), a temporally annotated corpus, TimeBank (Pustejovsky et al., 2003) and the temporal evaluation challenges TempEval-1 (Verhagen et al., 2007) and TempEval-2 (Pustejovsky and Verhagen, 2010), has led to an explosion of research on temporal information processing (TIP). Prior evaluation methods (TempEval-1, 2) for different TIP subtasks have borrowed precision and recall measures from the information retrieval community. This has two problems: First, systems express temporal relations in different, yet equivalent, ways. Consider a scenario where the 1 Temporal closure is a reasoning mechanism t</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, Lazo, 2003</marker>
<rawString>J. Pustejovsky, P. Hanks, R. Sauri, A. See, R. Gaizauskas, A. Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro and M. Lazo. 2003. The TIMEBANK corpus. Proceedings of the Corpus Linguistics, 647–656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos M Castao</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert J Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
<author>Dragomir R Radev</author>
</authors>
<date>2003</date>
<booktitle>TimeML: Robust Specication of Event and Temporal Expressions in Text. . Proceedings of the New Directions in Question Answering.</booktitle>
<contexts>
<context position="892" citStr="Pustejovsky et al., 2003" startWordPosition="114" endWordPosition="117">m text. It uses temporal closure1 to reward relations that are equivalent but distinct. Our metric measures the overall performance of systems with a single score, making comparison between different systems straightforward. Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive. 1 Introduction The recent emergence of language processing applications like question answering, information extraction, and document summarization has motivated the need for temporally-aware systems. This, along with the availability of the temporal annotation scheme TimeML (Pustejovsky et al., 2003), a temporally annotated corpus, TimeBank (Pustejovsky et al., 2003) and the temporal evaluation challenges TempEval-1 (Verhagen et al., 2007) and TempEval-2 (Pustejovsky and Verhagen, 2010), has led to an explosion of research on temporal information processing (TIP). Prior evaluation methods (TempEval-1, 2) for different TIP subtasks have borrowed precision and recall measures from the information retrieval community. This has two problems: First, systems express temporal relations in different, yet equivalent, ways. Consider a scenario where the 1 Temporal closure is a reasoning mechanism t</context>
</contexts>
<marker>Pustejovsky, Castao, Ingria, Sauri, Gaizauskas, Setzer, Katz, Radev, 2003</marker>
<rawString>James Pustejovsky, Jos M. Castao, Robert Ingria, Roser Sauri, Robert J. Gaizauskas, Andrea Setzer, Graham Katz and Dragomir R. Radev. 2003. TimeML: Robust Specication of Event and Temporal Expressions in Text. . Proceedings of the New Directions in Question Answering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Marc Verhagen</author>
</authors>
<title>SemEval-2010 task 13: evaluating events, time expressions, and temporal relations</title>
<date>2010</date>
<booktitle>(TempEval2). Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions.</booktitle>
<contexts>
<context position="1082" citStr="Pustejovsky and Verhagen, 2010" startWordPosition="139" endWordPosition="142">tween different systems straightforward. Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive. 1 Introduction The recent emergence of language processing applications like question answering, information extraction, and document summarization has motivated the need for temporally-aware systems. This, along with the availability of the temporal annotation scheme TimeML (Pustejovsky et al., 2003), a temporally annotated corpus, TimeBank (Pustejovsky et al., 2003) and the temporal evaluation challenges TempEval-1 (Verhagen et al., 2007) and TempEval-2 (Pustejovsky and Verhagen, 2010), has led to an explosion of research on temporal information processing (TIP). Prior evaluation methods (TempEval-1, 2) for different TIP subtasks have borrowed precision and recall measures from the information retrieval community. This has two problems: First, systems express temporal relations in different, yet equivalent, ways. Consider a scenario where the 1 Temporal closure is a reasoning mechanism that derives new implied temporal relations, i.e. makes implicit temporal relations explicit. For example, if we know A before B, B before C, then using temporal closure we can derive A befor</context>
</contexts>
<marker>Pustejovsky, Verhagen, 2010</marker>
<rawString>James Pustejovsky and Marc Verhagen. 2010. SemEval-2010 task 13: evaluating events, time expressions, and temporal relations (TempEval2). Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Setzer</author>
<author>R Gaizauskas</author>
<author>M Hepple</author>
</authors>
<title>Using semantic inferences for temporal annotation comparison.</title>
<date>2003</date>
<booktitle>Proceedings of the Fourth International Workshop on Inference in Computational Semantics (ICOS-4),</booktitle>
<pages>25--26</pages>
<contexts>
<context position="2969" citStr="Setzer et al. (2003)" startWordPosition="414" endWordPosition="417">pare overall performance of systems. We use temporal closure to identify equivalent temporal relations and produce a single score that measures the temporal awareness of each system. We use Timegraph (Miller and Schubert, 1990) for computing temporal closure, which makes our system scalable and computationally inexpensive. 2 Related Work To calculate the inter-annotator agreement between annotators in the temporal annotation task, some researchers have used semantic matching to reward distinct but equivalent temporal relations. Such techniques can equally well be applied to system evaluation. Setzer et al. (2003) use temporal closure to reward equivalent but distinct relations. Consider the example in Figure 1 (due to Tannier and Muller, 2008). Consider graph K as the reference annotation graph, and S1, S2 and S3 as outputs of different systems. The bold edges are the extracted relations and the dotted edges are derived. The traditional matching approach will fail to verify B&lt;D is a correct relation in S2, since there is no explicit edge between B and D in reference annotation (K). But a metric using temporal closure would create all implicit edges and be able to reward B&lt;D edge in S2. 351 Proceedings</context>
</contexts>
<marker>Setzer, Gaizauskas, Hepple, 2003</marker>
<rawString>A Setzer, R Gaizauskas and M Hepple. 2003. Using semantic inferences for temporal annotation comparison. Proceedings of the Fourth International Workshop on Inference in Computational Semantics (ICOS-4), 25-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Tannier</author>
<author>P Muller</author>
</authors>
<title>Evaluation Metrics for Automatic Temporal Annotation of Texts.</title>
<date>2008</date>
<booktitle>Proceedings of the Proceedings of the Sixth International Language Resources and Evaluation (LREC&apos;08).</booktitle>
<contexts>
<context position="3102" citStr="Tannier and Muller, 2008" startWordPosition="435" endWordPosition="438">e that measures the temporal awareness of each system. We use Timegraph (Miller and Schubert, 1990) for computing temporal closure, which makes our system scalable and computationally inexpensive. 2 Related Work To calculate the inter-annotator agreement between annotators in the temporal annotation task, some researchers have used semantic matching to reward distinct but equivalent temporal relations. Such techniques can equally well be applied to system evaluation. Setzer et al. (2003) use temporal closure to reward equivalent but distinct relations. Consider the example in Figure 1 (due to Tannier and Muller, 2008). Consider graph K as the reference annotation graph, and S1, S2 and S3 as outputs of different systems. The bold edges are the extracted relations and the dotted edges are derived. The traditional matching approach will fail to verify B&lt;D is a correct relation in S2, since there is no explicit edge between B and D in reference annotation (K). But a metric using temporal closure would create all implicit edges and be able to reward B&lt;D edge in S2. 351 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 351–356, Portland, Oregon, June 19-24</context>
</contexts>
<marker>Tannier, Muller, 2008</marker>
<rawString>X Tannier and P Muller. 2008. Evaluation Metrics for Automatic Temporal Annotation of Texts. Proceedings of the Proceedings of the Sixth International Language Resources and Evaluation (LREC&apos;08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Taugher</author>
</authors>
<title>An efficient representation for time information.</title>
<date>1983</date>
<institution>Department of Computer Science. Edmonton, Canada: University of Alberta.</institution>
<contexts>
<context position="9171" citStr="Taugher (1983)" startWordPosition="1444" endWordPosition="1445">onship between any two points in the same chain can be done in constant time simply by comparing the pseudo-times, rather than following the in-chain links. On the other hand, relationship between points in different chains can be found with a search in cross-chain links, which is dependent on the number of edges (i.e. number of chains and number of cross-chain links). A metagraph keeps track of the cross-chain links effectively by maintaining a metanode for each chain, and using a cross-chain links between metanodes. More details about Timegraph can be found in Miller and Schubert (1990) and Taugher (1983). Timegraph only supports simple point relations (&lt;, =, ≤), but we need to evaluate systems based on TimeML, which is based on interval algebra. However, single (i.e., non-disjunctive) interval relations can be easily converted to point relations4. For efficiency, we want to minimize the number of chains constructed by Timegraph, since with more chains our search in Timegraph will take more time. If we arbitrarily choose TimeML TLINKs (temporal links) and add them we will create some extra chains. To avoid this, we start with a node and traverse through its neighbors in a systematic fashion tr</context>
</contexts>
<marker>Taugher, 1983</marker>
<rawString>J. Taugher. 1983. An efficient representation for time information. Department of Computer Science. Edmonton, Canada: University of Alberta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<date>2007</date>
<booktitle>SemEval-2007 Task 15: TempEval Temporal Relation Identification. Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval</booktitle>
<contexts>
<context position="1034" citStr="Verhagen et al., 2007" startWordPosition="133" endWordPosition="136">th a single score, making comparison between different systems straightforward. Our approach is easy to implement, intuitive, accurate, scalable and computationally inexpensive. 1 Introduction The recent emergence of language processing applications like question answering, information extraction, and document summarization has motivated the need for temporally-aware systems. This, along with the availability of the temporal annotation scheme TimeML (Pustejovsky et al., 2003), a temporally annotated corpus, TimeBank (Pustejovsky et al., 2003) and the temporal evaluation challenges TempEval-1 (Verhagen et al., 2007) and TempEval-2 (Pustejovsky and Verhagen, 2010), has led to an explosion of research on temporal information processing (TIP). Prior evaluation methods (TempEval-1, 2) for different TIP subtasks have borrowed precision and recall measures from the information retrieval community. This has two problems: First, systems express temporal relations in different, yet equivalent, ways. Consider a scenario where the 1 Temporal closure is a reasoning mechanism that derives new implied temporal relations, i.e. makes implicit temporal relations explicit. For example, if we know A before B, B before C, t</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz and James Pustejovsky. 2007. SemEval-2007 Task 15: TempEval Temporal Relation Identification. Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Vilain</author>
<author>John Burger</author>
<author>John Aberdeen</author>
<author>Dennis Connolly</author>
<author>Lynette Hirschman</author>
</authors>
<title>A model-theoretic coreference scoring scheme.</title>
<date>1995</date>
<booktitle>Proceedings of the MUC6 ’95: Proceedings of the 6th conference on Message understanding.</booktitle>
<contexts>
<context position="6692" citStr="Vilain et al., 1995" startWordPosition="1039" endWordPosition="1042">of precision and recall, i.e. fscore, will give an evaluation of the temporal awareness of the system. As an example, consider again the examples in Figure 1, with K as reference annotation. S1 and S3 clearly have 100% precision, and S2 also gets 100% precision, since the B&lt;D edge can be verified through the temporal closure graph of K. Note, our recall measure doesn’t reward the B&lt;D edge of S2, but it is counted for precision. S1 and S3 both get a recall of 2/3, since 2 edges can be verified in the reference temporal closure graph. This scheme is similar to the MUC-6 scoring for coreference (Vilain et al., 1995). Their scoring estimated the minimal number of missing links necessary to complete co-reference chain in order to make it match the human annotation. Here in both S1 and S3, we are missing one edge to match with the reference annotation; hence 2/3 is the appropriate score. Precision, recall and fscore for all these system output are shown in Table 1. System Precision Recall Fscore S1 2/2=1 2/3=0.66 0.8 S2 2/2=1 1/3=0.33 0.5 S3 2/2=1 2/3=0.66 0.8 Table 1: Precision, recall and fscore for systems in Figure 1 according to our evaluation metric 4 Implementation Our proposed approach is easy to im</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Marc Vilain, John Burger, John Aberdeen, Dennis Connolly and Lynette Hirschman. 1995. A model-theoretic coreference scoring scheme. Proceedings of the MUC6 ’95: Proceedings of the 6th conference on Message understanding.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ed Yampratoom</author>
<author>James F Allen</author>
</authors>
<title>Performance of Temporal Reasoning Systems.</title>
<date>1993</date>
<booktitle>TRAINS Technical Note 93-1.</booktitle>
<institution>University of Rochester.</institution>
<location>Rochester, NY:</location>
<marker>Yampratoom, Allen, 1993</marker>
<rawString>Ed Yampratoom and James F. Allen. 1993. Performance of Temporal Reasoning Systems. TRAINS Technical Note 93-1. Rochester, NY: University of Rochester.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>