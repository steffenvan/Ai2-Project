<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001239">
<note confidence="0.95207">
Proceedings of the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), Philadelphia, July 2002, pp. 144-151.
</note>
<title confidence="0.997199">
Pronunciation Modeling for Improved Spelling Correction
</title>
<author confidence="0.748563">
Kristina Toutanova Robert C. Moore
</author>
<affiliation confidence="0.596646333333333">
Computer Science Department Microsoft Research
Stanford University One Microsoft Way
Stanford, CA 94305 USA Redmond, WA 98052 USA
</affiliation>
<sectionHeader confidence="0.989919" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999122">
This paper presents a method for incor-
porating word pronunciation information
in a noisy channel model for spelling cor-
rection. The proposed method builds an
explicit error model for word pronuncia-
tions. By modeling pronunciation simi-
larities between words we achieve a sub-
stantial performance improvement over
the previous best performing models for
spelling correction.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999453914285714">
Spelling errors are generally grouped into two
classes (Kuckich, 1992) — typographic and cogni-
tive. Cognitive errors occur when the writer does
not know how to spell a word. In these cases the
misspelling often has the same pronunciation as the
correct word ( for example writing latex as latecks).
Typographic errors are mostly errors related to the
keyboard; e.g., substitution or transposition of two
letters because their keys are close on the keyboard.
Damerau (1964) found that 80% of misspelled
words that are non-word errors are the result of a sin-
gle insertion, deletion, substitution or transposition
of letters. Many of the early algorithms for spelling
correction are based on the assumption that the cor-
rect word differs from the misspelling by exactly
one of these operations (M. D. Kernigan and Gale,
1990; Church and Gale, 1991; Mayes and F. Dam-
erau, 1991).
By estimating probabilities or weights for the
different edit operations and conditioning on the
left and right context for insertions and deletions
and allowing multiple edit operations, high spelling
correction accuracy has been achieved. At ACL
2000, Brill and Moore (2000) introduced a new error
model, allowing generic string-to-string edits. This
model reduced the error rate of the best previous
model by nearly 50%. It proved advantageous to
model substitutions of up to 5-letter sequences (e.g
ent being mistyped as ant, ph as f, al as le, etc.) This
model deals with phonetic errors significantly better
than previous models since it allows a much larger
context size.
However this model makes residual errors, many
of which have to do with word pronunciation. For
example, the following are triples of misspelling,
correct word and (incorrect) guess that the Brill and
Moore model made:
edelvise edelweiss advise
bouncie bouncy bounce
latecks latex lacks
In this work we take the approach of modeling
phonetic errors explicitly by building a separate er-
ror model for phonetic errors. More specifically,
we build two different error models using the Brill
and Moore learning algorithm. One of them is a
letter-based model which is exactly the Brill and
Moore model trained on a similar dataset. The other
is a phone-sequence-to-phone-sequence error model
trained on the same data as the first model, but using
the pronunciations of the correct words and the es-
timated pronunciations of the misspellings to learn
phone-sequence-to-phone-sequence edits and esti-
mate their probabilities. At classification time, N-
best list predictions of the two models are combined
using a log linear model.
A requirement for our model is the availability of
a letter-to-phone model that can generate pronunci-
ations for misspellings. We build a letter-to-phone
model automatically from a dictionary.
The rest of the paper is structured as follows:
Section 2 describes the Brill and Moore model and
briefly describes how we use it to build our er-
ror models. Section 3 presents our letter-to-phone
model, which is the result of a series of improve-
ments on a previously proposed N-gram letter-to-
phone model (Fisher, 1999). Section 4 describes the
training and test phases of our algorithm in more de-
tail and reports on experiments comparing the new
model to the Brill and Moore model. Section 6 con-
tains conclusions and ideas for future work.
</bodyText>
<sectionHeader confidence="0.802478" genericHeader="introduction">
2 Brill and Moore Noisy Channel Spelling
Correction Model
</sectionHeader>
<bodyText confidence="0.9998737">
Many statistical spelling correction methods can be
viewed as instances of the noisy channel model. The
misspelling of a word is viewed as the result of cor-
ruption of the intended word as it passes through a
noisy communications channel.
The task of spelling correction is a task of finding,
for a misspelling w, a correct word r 2 D, where
D is a given dictionary and r is the most probable
word to have been garbled into w. Equivalently, the
problem is to find a word r for which
</bodyText>
<equation confidence="0.9992505">
P(r)P(wjr)
P(rjw) = P(w)
</equation>
<bodyText confidence="0.999524625">
is maximized. Since the denominator is constant,
this is the same as maximizing P (r)P (wjr). In the
terminology of noisy channel modeling, the distribu-
tion P(r) is referred to as the source model, and the
distribution P (wjr) is the error or channel model.
Typically, spelling correction models are not used
for identifying misspelled words, only for propos-
ing corrections for words that are not found in a
dictionary. Notice, however, that the noisy chan-
nel model offers the possibility of correcting mis-
spellings without a dictionary, as long as sufficient
data is available to estimate the source model fac-
tors. For example, if r = Osama bin Laden and
w = Ossama bin Laden, the model will predict that
the correct spelling r is more likely than the incor-
rect spelling w, provided that
</bodyText>
<equation confidence="0.995583">
P(w) &lt;
P (r)
</equation>
<bodyText confidence="0.999805404255319">
where P (wjr)IP (wjw) would be approximately the
odds of doubling the s in Osama. We do not pursue
this, here, however.
Brill and Moore (2000) present an improved er-
ror model for noisy channel spelling correction that
goes beyond single insertions, deletions, substitu-
tions, and transpositions. The model has a set of pa-
rameters P(a ! ,) for letter sequences of lengths
up to 5. An extension they presented has refined pa-
rameters P(a ! ,jPSN) which also depend on
the position of the substitution in the source word.
According to this model, the misspelling is gener-
ated by the correct word as follows: First, a person
picks a partition of the correct word and then types
each partition independently, possibly making some
errors. The probability for the generation of the mis-
spelling will then be the product of the substitution
probabilities for each of the parts in the partition.
For example, if a person chooses to type the word
bouncy and picks the partition boun cy, the proba-
bility that she mistypes this word as boun cie will
be P(boun ! boun)P(cie ! cy). The probability
P(wjr) is estimated as the maximum over all parti-
tions of r of the probability that w is generated from
r given that partition.
We use this method to build an error model for
letter strings and a separate error model for phone
sequences. Two models are learned; one model LTR
(standing for “letter”) has a set of substitution prob-
abilities P(a ! ,) where a and , are character
strings, and another model PH (for “phone”) has a
set of substitution probabilities P(a ! ,) where a
and , are phone sequences.
We learn these two models on the same data set
of misspellings and correct words. For LTR, we use
the training data as is and run the Brill and Moore
training algorithm over it to learn the parameters of
LTR. For PH, we convert the misspelling/correct-
word pairs into pairs of pronunciations of the mis-
spelling and the correct word, and run the Brill and
Moore training algorithm over that.
For PH, we need word pronunciations for the cor-
rect words and the misspellings. As the misspellings
are certainly not in the dictionary we need a letter-
to-phone converter that generates possible pronun-
ciations for them. The next section describes our
letter-to-phone model.
</bodyText>
<equation confidence="0.6622105">
P(wjr)
P(wjw)
</equation>
<table confidence="0.995756">
NETtalk MS Speech
Set Words Set Words
Training 14,876 Training 106,650
Test 4,964 Test 30,003
</table>
<tableCaption confidence="0.999563">
Table 1: Text-to-phone conversion data
</tableCaption>
<sectionHeader confidence="0.998563" genericHeader="method">
3 Letter-to-Phone Model
</sectionHeader>
<bodyText confidence="0.999987885714286">
There has been a lot of research on machine learn-
ing methods for letter-to-phone conversion. High
accuracy is achieved, for example, by using neural
networks (Sejnowski and Rosenberg, 1987), deci-
sion trees (Jiang et al., 1997), and N-grams (Fisher,
1999). We use a modified version of the method pro-
posed by Fisher, incorporating several extensions re-
sulting in substantial gains in performance. In this
section we first describe how we do alignment at
the phone level, then describe Fisher’s model, and fi-
nally present our extensions and the resulting letter-
to-phone conversion accuracy.
The machine learning algorithms for converting
text to phones usually start off with training data
in the form of a set of examples, consisting of let-
ters in context and their corresponding phones (clas-
sifications). Pronunciation dictionaries are the ma-
jor source of training data for these algorithms, but
they do not contain information for correspondences
between letters and phones directly; they have cor-
respondences between sequences of letters and se-
quences of phones.
A first step before running a machine learning
algorithm on a dictionary is, therefore, alignment
between individual letters and phones. The align-
ment algorithm is dependent on the phone set used.
We experimented with two dictionaries, the NETtalk
dataset and the Microsoft Speech dictionary. Statis-
tics about them and how we split them into training
and test sets are shown in Table 1. The NETtalk
dataset contains information for phone level align-
ment and we used it to test our algorithm for auto-
matic alignment. The Microsoft Speech dictionary
is not aligned at the phone level but it is much big-
ger and is the dictionary we used for learning our
final letter-to-phone model.
The NETtalk dictionary has been designed so that
each letter correspond to at most one phone, so a
word is always longer, or of the same length as, its
pronunciation. The alignment algorithm has to de-
cide which of the letters correspond to phones and
which ones correspond to nothing (i.e., are silent).
For example, the entry in NETtalk (when we remove
the empties, which contain information for phone
level alignment) for the word able is ABLE e b L.
The correct alignment is A/e B/b L/L E/–, where – de-
notes the empty phone. In the Microsoft Speech dic-
tionary, on the other hand, each letter can naturally
correspond to 0, 1, or 2 phones. For example, the en-
try in that dictionary for able is ABLE ey b ax l. The
correct alignment is A/ey B/b L/ax&amp;l E/–. If we also
allowed two letters as a group to correspond to two
phones as a group, the correct alignment might be
A/ey B/b LE/ax&amp;l, but that would make it harder for
the machine learning algorithm.
Our alignment algorithm is an implementa-
tion of hard EM (Viterbi training) that starts off
with heuristically estimated initial parameters for
P (phonesIletter) and, at each iteration, finds the
most likely alignment for each word given the pa-
rameters and then re-estimates the parameters col-
lecting counts from the obtained alignments. Here
phones ranges over sequences of 0 (empty), 1,
and 2 phones for the Microsoft Speech dictionary
and 0 or 1 phones for NETtalk. The parameters
P (phonesIletter) were initialized by amethod sim-
ilar to the one proposed in (Daelemans and van den
Bosch, 1996). Word frequencies were not taken into
consideration here as the dictionary contains no fre-
quency information.
</bodyText>
<subsectionHeader confidence="0.987784">
3.1 Initial Letter-to-Phone Model
</subsectionHeader>
<bodyText confidence="0.99996">
The method we started with was the N-gram model
of Fisher (1999). From training data, it learns rules
that predict the pronunciation of a letter based on m
letters of left and n letters of right context. The rules
are of the following form:
</bodyText>
<equation confidence="0.627046">
[Lm.T.Rn —� ph1 p1 ph2 p2 . . .]
</equation>
<bodyText confidence="0.998772863636364">
Here Lm stands for a sequence of m letters to the
left of T and Rn is a sequence of n letters to the
right. The number of letters in the context to the left
and right varies. We used from 0 to 4 letters on each
side. For example, two rules learned for the letter B
were: [AB.B.OT —� — 1.0] and [B —� b .96 — .04],
meaning that in the first context the letter B is silent
with probability 1.0, and in the second it is pro-
nounced as b with probability .96 and is silent with
probability .04.
Training this model consists of collecting counts
for the contexts that appear in the data with the se-
lected window size to the left and right. We col-
lected counts for all configurations Lm.T.Rn for
m E {0, 1, 2, 3, 41, n E {0, 1, 2, 3, 41 that occurred
in the data. The model is applied by choosing for
each letter T the most probable translation as pre-
dicted by the most specific rule for the context of
occurrence of the letter. For example, if we want
to find how to pronounce the second b in abbot we
would chose the empty phone because the first rule
mentioned above is more specific than the second.
</bodyText>
<subsectionHeader confidence="0.987192">
3.2 Extensions
</subsectionHeader>
<bodyText confidence="0.999928666666667">
We implemented five extensions to the initial model
which together decreased the error rate of the letter-
to-phone model by around 20%. These are:
</bodyText>
<listItem confidence="0.999157125">
• Combination of the predictions of several ap-
plicable rules by linear interpolation
• Rescoring of N-best proposed pronunciations
for a word using a trigram phone sequence lan-
guage model
• Explicit distinction between middle of word
versus start or end
• Rescoring of N-best proposed pronunciations
</listItem>
<bodyText confidence="0.948331117647059">
for a word using a fourgram vowel sequence
language model
The performance figures reported by Fisher
(1999) are significantly higher than our figures us-
ing the basic model, which is probably due to the
cleaner data used in their experiments and the dif-
ferences in phoneset size.
The extensions we implemented are inspired
largely by the work on letter-to-phone conversion
using decision trees (Jiang et al., 1997). The last
extension, rescoring based on vowel fourgams, has
not been proposed previously. We tested the algo-
rithms on the NETtalk and Microsoft Speech dic-
tionaries, by splitting them into training and test
sets in proportion 80%/20% training-set to test-set
size. We trained the letter-to-phone models using
the training splits and tested on the test splits. We
</bodyText>
<table confidence="0.9997289">
Model Phone Acc Word Acc
Initial 88.83% 53.28%
Interpolation 90.55% 59.04%
of contexts
Distinction 91.09% 60.81%
of middle
Phonetic 91.38% 62.95%
trigram
Vowel 91.46% 63.63%
fourgram
</table>
<tableCaption confidence="0.998338">
Table 2: Letter-to-phone accuracies
</tableCaption>
<bodyText confidence="0.999975102040817">
are reporting accuracy figures only on the NETtalk
dataset since this dataset has been used extensively
in building letter-to-phone models, and because
phone accuracy is hard to determine for the non-
phonetically-aligned Microsoft Speech dictionary.
For our spelling correction algorithm we use a letter-
to-phone model learned from the Microsoft Speech
dictionary, however.
The results for phone accuracy and word accuracy
of the initial model and extensions are shown in Ta-
ble 2. The phone accuracy is the percentage cor-
rect of all phones proposed (excluding the empties)
and the word accuracy is the percentage of words
for which pronunciations were guessed without any
error.
For our data we noticed that the most specific
rule that matches is often not a sufficiently good
predictor. By linearly interpolating the probabili-
ties given by the five most specific matching rules
we decreased the word error rate by 14.3%. The
weights for the individual rules in the top five were
set to be equal. It seems reasonable to combine the
predictions from several rules especially because the
choice of which rule is more specific of two is arbi-
trary when neither is a substring of the other. For
example, of the two rules with contexts A.B. and
.B.B, where the first has 0 right context and the
second has 0 left letter context, one heuristic is to
choose the latter as more specific since right context
seems more valuable than left (Fisher, 1999). How-
ever this choice may not always be the best and it
proves useful to combine predictions from several
rules. In Table 2 the row labeled “Interpolation of
contexts” refers to this extension of the basic model.
Adding a symbol for interior of word produced a
gain in accuracy. Prior to adding this feature, we
had features for beginning and end of word. Explic-
itly modeling interior proved helpful and further de-
creased our error rate by 4.3%. The results after this
improvement are shown in the third row of Table 2.
After linearly combining the predictions from the
top matching rules we have a probability distribu-
tion over phones for each letter. It has been shown
that modeling the probability of sequences of phones
can greatly reduce the error (Jiang et al., 1997). We
learned a trigram phone sequence model and used
it to re-score the N-best predictions from the basic
model. We computed the score for a sequence of
phones given a sequence of letters, as follows:
</bodyText>
<equation confidence="0.9972216">
Score(p1;p2; ::: ;pnjl1;l2 ::: ln) _
log 11 P (pijl1; l2 ::: ln) +
i=1...n
a log 11 P(pijpi-1; pi-2) (1)
i=1...n
</equation>
<bodyText confidence="0.9999468">
Here the probabilities P (pijl1; l2 ::: ln) are the
distributions over phones that we obtain for each let-
ter from combination of the matching rules. The
weight a for the phone sequence model was esti-
mated from a held-out set by a linear search. This
model further improved our performance and the re-
sults it achieves are in the fourth row of Table 2.
The final improvement is adding a term from a
vowel fourgram language model to equation 1 with
a weight ,Q. The term is the log probability of the
sequence of vowels in the word according to a four-
gram model over vowel sequences learned from the
data. The final accuracy we achieve is shown in
the fifth row of the same table. As a comparison,
the best accuracy achieved by Jiang et al. (1997)
on NETalk using a similar proportion of training
and test set sizes was 65:8%. Their system uses
more sources of information, such as phones in the
left context as features in the decision tree. They
also achieve a large performance gain by combining
multiple decision trees trained on separate portions
of the training data. The accuracy of our letter-to-
phone model is comparable to state of the art sys-
tems. Further improvements in this component may
lead to higher spelling correction accuracy.
</bodyText>
<subsectionHeader confidence="0.5075565">
4 Combining Pronunciation and
Letter-Based Models
</subsectionHeader>
<bodyText confidence="0.999951961538461">
Our combined error model gives the probability
PCMB(wjr) where w is the misspelling and r is a
word in the dictionary. The spelling correction algo-
rithm selects for a misspelling w the word r in the
dictionary for which the product P (r)PCMB(wjr)
is maximized. In our experiments we used a uniform
source language model over the words in the dictio-
nary. Therefore our spelling correction algorithm se-
lects the word r that maximizes PCMB(wjr). Brill
and Moore (2000) showed that adding a source lan-
guage model increases the accuracy significantly.
They also showed that the addition of a language
model does not obviate the need for a good error
model and that improvements in the error model lead
to significant improvements in the full noisy channel
model.
We build two separate error models, LTR and
PH (standing for “letter” model and “phone”
model). The letter-based model estimates a prob-
ability distribution PLTR(wjr) over words, and
the phone-based model estimates a distribution
PPH(pron wjpron r) over pronunciations. Using
the PH model and the letter-to-phone model, we de-
rive a distribution PPHL(wjr) in a way to be made
precise shortly. We combine the two models to esti-
mate scores as follows:
</bodyText>
<equation confidence="0.997046666666667">
SCMB(wjr) _
log PLTR(wjr) +
A log PPHL(wjr)
</equation>
<bodyText confidence="0.707765666666667">
The r that maximizes this score will also maxi-
mize the probability PCMB(wjr). The probabilities
PPHL(wjr) are computed as follows:
</bodyText>
<equation confidence="0.9839718">
PPHL(wjr)
_ P(pron r;wjr)
pron r
_ P(pron rjr) x
pron r P(wjpron r; r)
</equation>
<bodyText confidence="0.995035666666667">
This equation is approximated by the expression
for PPHL shown in Figure 1 after several simplify-
ing assumptions. The probabilities P(pron rjr) are
</bodyText>
<figure confidence="0.75682725">
PPHL(wjr) lz:� 1 ( PPH(pron wjpron r) �
pron r max )
pron wP(pron wjw)
num pron r
</figure>
<figureCaption confidence="0.999485">
Figure 1: Equation for approximation of PPHL
</figureCaption>
<bodyText confidence="0.993513777777778">
taken to be equal for all possible pronunciations of r
in the dictionary. Next we assume independence of
the misspelling from the right word given the pro-
nunciation of the right word i.e. P (wjr, pron r) =
P(wjpron r). By inversion of the conditional prob-
ability this is equal to P(pron rjw) multiplied by
P(w)IP(pron r). Since we do not model these
marginal probabilities, we drop the latter factor.
Next the probability P(pron rjw) is expressed as
</bodyText>
<equation confidence="0.5137475">
� P(pron w,pron rjw)
pron w
</equation>
<bodyText confidence="0.956241692307692">
which is approximated by the maximum term in the
sum. After the following decomposition:
P(pron w, pron rjw)
= P(pron wjw)xP(pron rjw,pron w)
ti P(pron wjw)xP(pron rjpron w)
where the second part represents a final indepen-
dence assumption, we get the expression in Figure 1.
The probabilities P(pron wjw) are given by the
letter-to-phone model. In the following subsections,
we first describe how we train and apply the individ-
ual error models, and then we show performance re-
sults for the combined model compared to the letter-
based error model.
</bodyText>
<subsectionHeader confidence="0.988124">
4.1 Training Individual Error Models
</subsectionHeader>
<bodyText confidence="0.999883851851852">
The error model LTR was trained exactly as de-
scribed originally by Brill and Moore (2000). Given
a training set of pairs fw2, r2g the algorithm es-
timates a set of rewrite probabilities p(a ! ,Q)
which are the basis for computing probabilities
PLTR(wjr).
The parameters of the PH model
PPH(pron wjpron r) are obtained by training
a phone-sequence-to-phone-sequence error model
starting from the same training set of pairs fw2, r2g
of misspelling and correct word as for the LTR
model. We convert this set to a set of pronunciations
of misspellings and pronunciations of correct
words in the following way: For each training
sample fw2, r2g we generate m training samples
of corresponding pronunciations where m is the
number of pronunciations of the correct word r2
in our dictionary. Each of those m samples is the
most probable pronunciation of w2 according to
our letter-to-phone model paired with one of the
possible pronunciations of r2. Using this training
set, we run the algorithm of Brill and Moore to es-
timate a set of substitution probabilities a ! , for
sequences of phones to sequences of phones. The
probability PPH(pron wjpron r) is then computed
as a product of the substitution probabilities in the
most probable alignment, as Brill and Moore did.
</bodyText>
<sectionHeader confidence="0.829597" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999968869565218">
We tested our system and compared it to the Brill
and Moore model on a dataset of around 10, 000
pairs of misspellings and corresponding correct
words, split into training and test sets. The ex-
act data sizes are 7, 385 word pairs in the training
set and 1, 812 word pairs in the test set. This set
is slightly different from the dataset used in Brill
and Moore’s experiments because we removed from
the original dataset the pairs for which we did not
have the correct word in the pronunciation dictio-
nary. Both models LTR and PH were trained on the
same training set. The interpolation weight that the
combined model CMB uses is also set on the train-
ing set to maximize the classification accuracy.
At test time we do not search through all possible
words r in the dictionary to find the one maximizing
SeoreCMB(wjr). Rather, we compute the combi-
nation score only for candidate words r that are in
the top N according to the PLTR(wjr) or are in the
top N according to PPH(pron wjpron r) for any
of the pronunciations of r from the dictionary and
any of the pronunciations for w that were proposed
by the letter-to-phone model. The letter-to-phone
</bodyText>
<table confidence="0.999551333333333">
Model 1-Best 2-Best 3-Best 4-Best
LTR 94.21% 98.18% 98.90 % 99.06%
PH 86.36% 93.65% 95.69 % 96.63%
CMB 95.58% 98.90% 99.34% 99.50%
Error 23.8% 39.6% 40% 46.8%
Reduction
</table>
<tableCaption confidence="0.986626">
Table 3: Spelling Correction Accuracy Results
</tableCaption>
<table confidence="0.951008333333333">
Misspelling Correct LTR Guess
bouncie bouncy bounce
edelvise edelweiss advise
grissel gristle grizzle
latecks latex lacks
neut newt nut
rench wrench ranch
saing saying sang
stail stale stall
</table>
<bodyText confidence="0.999911137931034">
model returned for each w the 3 most probable pro-
nunciations only. Our performance was better when
we considered the top 3 pronunciations of w rather
than a single most likely hypothesis. That is prob-
ably due to the fact that the 3-best accuracy of the
letter-to-phone model is significantly higher than its
1-best accuracy.
Table 3 shows the spelling correction accuracy
when using the model LTR, PH, or both in com-
bination. The table shows N-best accuracy results.
The N-best accuracy figures represent the percent
test cases for which the correct word was in the top
N words proposed by the model. We chose the con-
text size of 3 for the LTR model as this context size
maximized test set accuracy. Larger context sizes
neither helped nor hurt accuracy.
As we can see from the table, the phone-based
model alone produces respectable accuracy results
considering that it is only dealing with word pronun-
ciations. The error reduction of the combined model
compared to the letters-only model is substantial:
for 1-Best, the error reduction is over 23%; for 2-
Best, 3-Best, and 4-Best it is even higher, reaching
over 46% for 4-Best.
As an example of the influence of pronuncia-
tion modeling, in Table 4 we list some misspelling-
correct word pairs where the LTR model made
an incorrect guess and the combined model CMB
guessed accurately.
</bodyText>
<sectionHeader confidence="0.999521" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999442714285714">
We have presented a method for using word pro-
nunciation information to improve spelling correc-
tion accuracy. The proposed method substantially
reduces the error rate of the previous best spelling
correction model.
A subject of future research is looking for a bet-
ter way to combine the two error models or building
</bodyText>
<tableCaption confidence="0.953791">
Table 4: Examples of Corrected Errors
</tableCaption>
<bodyText confidence="0.998398333333333">
a single model that can recognize whether there is
a phonetic or typographic error. Another interest-
ing task is exploring the potential of our model in
different settings such as the Web, e-mail, or as a
specialized model for non-native English speakers
of particular origin.
</bodyText>
<sectionHeader confidence="0.99945" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999613676470588">
E. Brill and R. C. Moore. 2000. An improved error
model for noisy channel spelling correction. In Proc.
of the 38th Annual Meeting of the ACL, pages 286–
293.
K. Church and W. Gale. 1991. Probability scoring for
spelling correction. In Statistics and Computing, vol-
ume 1, pages 93–103.
W. Daelemans and A. van den Bosch. 1996. Language-
independent data-oriented grapheme-to-phoneme con-
version. In Progress in Speech Synthesis, pages 77–90.
F. J. Damerau. 1964. A technique for computer detection
and correction of spelling errors. In Communications
of the ACM, volume 7(3), pages 171–176.
W. M. Fisher. 1999. A statistical text-to-phone function
using ngrams and rules. In Proc. of the IEEE Inter-
national Conference on Acoustics, Speech and Signal
Processing, pages 649–652.
L. Jiang, H.W. Hon, and X. Huang. 1997. Improvements
on a trainable letter-to-sound converter. In Proceed-
ings of the 5th European Conference on Speech Com-
munication and Technology.
K. Kuckich. 1992. Techniques for automatically correct-
ing words in text. In ACM Computing Surveys, volume
24(4), pages 377–439.
W. Church M. D. Kernigan and W. A. Gale. 1990. A
spelling correction program based on a noisy channel
model. In Proc. of COLING-90, volume II, pages 205–
211.
F. Mayes and et al. F. Damerau. 1991. Conext based
spelling correction. In Information Processing and
Management, volume 27(5), pages 517–522.
T. J. Sejnowski and C. R. Rosenberg. 1987. Parallel net-
works that learn to pronounce english text. In Complex
Systems, pages 145–168.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.930047">
<note confidence="0.9981325">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, July 2002, pp. 144-151.</note>
<title confidence="0.999096">Pronunciation Modeling for Improved Spelling Correction</title>
<author confidence="0.999682">Kristina Toutanova Robert C Moore</author>
<affiliation confidence="0.984718">Computer Science Department Microsoft Research Stanford University One Microsoft Way</affiliation>
<address confidence="0.997856">Stanford, CA 94305 USA Redmond, WA 98052 USA</address>
<abstract confidence="0.996873818181818">This paper presents a method for incorporating word pronunciation information in a noisy channel model for spelling correction. The proposed method builds an explicit error model for word pronunciations. By modeling pronunciation similarities between words we achieve a substantial performance improvement over the previous best performing models for spelling correction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>R C Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>In Proc. of the 38th Annual Meeting of the ACL,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="1900" citStr="Brill and Moore (2000)" startWordPosition="286" endWordPosition="289">rors are the result of a single insertion, deletion, substitution or transposition of letters. Many of the early algorithms for spelling correction are based on the assumption that the correct word differs from the misspelling by exactly one of these operations (M. D. Kernigan and Gale, 1990; Church and Gale, 1991; Mayes and F. Damerau, 1991). By estimating probabilities or weights for the different edit operations and conditioning on the left and right context for insertions and deletions and allowing multiple edit operations, high spelling correction accuracy has been achieved. At ACL 2000, Brill and Moore (2000) introduced a new error model, allowing generic string-to-string edits. This model reduced the error rate of the best previous model by nearly 50%. It proved advantageous to model substitutions of up to 5-letter sequences (e.g ent being mistyped as ant, ph as f, al as le, etc.) This model deals with phonetic errors significantly better than previous models since it allows a much larger context size. However this model makes residual errors, many of which have to do with word pronunciation. For example, the following are triples of misspelling, correct word and (incorrect) guess that the Brill </context>
<context position="5564" citStr="Brill and Moore (2000)" startWordPosition="904" endWordPosition="907">ng misspelled words, only for proposing corrections for words that are not found in a dictionary. Notice, however, that the noisy channel model offers the possibility of correcting misspellings without a dictionary, as long as sufficient data is available to estimate the source model factors. For example, if r = Osama bin Laden and w = Ossama bin Laden, the model will predict that the correct spelling r is more likely than the incorrect spelling w, provided that P(w) &lt; P (r) where P (wjr)IP (wjw) would be approximately the odds of doubling the s in Osama. We do not pursue this, here, however. Brill and Moore (2000) present an improved error model for noisy channel spelling correction that goes beyond single insertions, deletions, substitutions, and transpositions. The model has a set of parameters P(a ! ,) for letter sequences of lengths up to 5. An extension they presented has refined parameters P(a ! ,jPSN) which also depend on the position of the substitution in the source word. According to this model, the misspelling is generated by the correct word as follows: First, a person picks a partition of the correct word and then types each partition independently, possibly making some errors. The probabi</context>
<context position="18395" citStr="Brill and Moore (2000)" startWordPosition="3106" endWordPosition="3109">f the art systems. Further improvements in this component may lead to higher spelling correction accuracy. 4 Combining Pronunciation and Letter-Based Models Our combined error model gives the probability PCMB(wjr) where w is the misspelling and r is a word in the dictionary. The spelling correction algorithm selects for a misspelling w the word r in the dictionary for which the product P (r)PCMB(wjr) is maximized. In our experiments we used a uniform source language model over the words in the dictionary. Therefore our spelling correction algorithm selects the word r that maximizes PCMB(wjr). Brill and Moore (2000) showed that adding a source language model increases the accuracy significantly. They also showed that the addition of a language model does not obviate the need for a good error model and that improvements in the error model lead to significant improvements in the full noisy channel model. We build two separate error models, LTR and PH (standing for “letter” model and “phone” model). The letter-based model estimates a probability distribution PLTR(wjr) over words, and the phone-based model estimates a distribution PPH(pron wjpron r) over pronunciations. Using the PH model and the letter-to-p</context>
<context position="20807" citStr="Brill and Moore (2000)" startWordPosition="3513" endWordPosition="3516">um. After the following decomposition: P(pron w, pron rjw) = P(pron wjw)xP(pron rjw,pron w) ti P(pron wjw)xP(pron rjpron w) where the second part represents a final independence assumption, we get the expression in Figure 1. The probabilities P(pron wjw) are given by the letter-to-phone model. In the following subsections, we first describe how we train and apply the individual error models, and then we show performance results for the combined model compared to the letterbased error model. 4.1 Training Individual Error Models The error model LTR was trained exactly as described originally by Brill and Moore (2000). Given a training set of pairs fw2, r2g the algorithm estimates a set of rewrite probabilities p(a ! ,Q) which are the basis for computing probabilities PLTR(wjr). The parameters of the PH model PPH(pron wjpron r) are obtained by training a phone-sequence-to-phone-sequence error model starting from the same training set of pairs fw2, r2g of misspelling and correct word as for the LTR model. We convert this set to a set of pronunciations of misspellings and pronunciations of correct words in the following way: For each training sample fw2, r2g we generate m training samples of corresponding pr</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>E. Brill and R. C. Moore. 2000. An improved error model for noisy channel spelling correction. In Proc. of the 38th Annual Meeting of the ACL, pages 286– 293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
</authors>
<title>Probability scoring for spelling correction.</title>
<date>1991</date>
<booktitle>In Statistics and Computing,</booktitle>
<volume>1</volume>
<pages>93--103</pages>
<contexts>
<context position="1593" citStr="Church and Gale, 1991" startWordPosition="239" endWordPosition="242">e pronunciation as the correct word ( for example writing latex as latecks). Typographic errors are mostly errors related to the keyboard; e.g., substitution or transposition of two letters because their keys are close on the keyboard. Damerau (1964) found that 80% of misspelled words that are non-word errors are the result of a single insertion, deletion, substitution or transposition of letters. Many of the early algorithms for spelling correction are based on the assumption that the correct word differs from the misspelling by exactly one of these operations (M. D. Kernigan and Gale, 1990; Church and Gale, 1991; Mayes and F. Damerau, 1991). By estimating probabilities or weights for the different edit operations and conditioning on the left and right context for insertions and deletions and allowing multiple edit operations, high spelling correction accuracy has been achieved. At ACL 2000, Brill and Moore (2000) introduced a new error model, allowing generic string-to-string edits. This model reduced the error rate of the best previous model by nearly 50%. It proved advantageous to model substitutions of up to 5-letter sequences (e.g ent being mistyped as ant, ph as f, al as le, etc.) This model dea</context>
</contexts>
<marker>Church, Gale, 1991</marker>
<rawString>K. Church and W. Gale. 1991. Probability scoring for spelling correction. In Statistics and Computing, volume 1, pages 93–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>A van den Bosch</author>
</authors>
<title>Languageindependent data-oriented grapheme-to-phoneme conversion.</title>
<date>1996</date>
<booktitle>In Progress in Speech Synthesis,</booktitle>
<pages>77--90</pages>
<marker>Daelemans, van den Bosch, 1996</marker>
<rawString>W. Daelemans and A. van den Bosch. 1996. Languageindependent data-oriented grapheme-to-phoneme conversion. In Progress in Speech Synthesis, pages 77–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Damerau</author>
</authors>
<title>A technique for computer detection and correction of spelling errors.</title>
<date>1964</date>
<journal>In Communications of the ACM,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>171--176</pages>
<contexts>
<context position="1222" citStr="Damerau (1964)" startWordPosition="179" endWordPosition="180">tween words we achieve a substantial performance improvement over the previous best performing models for spelling correction. 1 Introduction Spelling errors are generally grouped into two classes (Kuckich, 1992) — typographic and cognitive. Cognitive errors occur when the writer does not know how to spell a word. In these cases the misspelling often has the same pronunciation as the correct word ( for example writing latex as latecks). Typographic errors are mostly errors related to the keyboard; e.g., substitution or transposition of two letters because their keys are close on the keyboard. Damerau (1964) found that 80% of misspelled words that are non-word errors are the result of a single insertion, deletion, substitution or transposition of letters. Many of the early algorithms for spelling correction are based on the assumption that the correct word differs from the misspelling by exactly one of these operations (M. D. Kernigan and Gale, 1990; Church and Gale, 1991; Mayes and F. Damerau, 1991). By estimating probabilities or weights for the different edit operations and conditioning on the left and right context for insertions and deletions and allowing multiple edit operations, high spell</context>
</contexts>
<marker>Damerau, 1964</marker>
<rawString>F. J. Damerau. 1964. A technique for computer detection and correction of spelling errors. In Communications of the ACM, volume 7(3), pages 171–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W M Fisher</author>
</authors>
<title>A statistical text-to-phone function using ngrams and rules.</title>
<date>1999</date>
<booktitle>In Proc. of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<pages>649--652</pages>
<contexts>
<context position="3833" citStr="Fisher, 1999" startWordPosition="598" endWordPosition="599">t classification time, Nbest list predictions of the two models are combined using a log linear model. A requirement for our model is the availability of a letter-to-phone model that can generate pronunciations for misspellings. We build a letter-to-phone model automatically from a dictionary. The rest of the paper is structured as follows: Section 2 describes the Brill and Moore model and briefly describes how we use it to build our error models. Section 3 presents our letter-to-phone model, which is the result of a series of improvements on a previously proposed N-gram letter-tophone model (Fisher, 1999). Section 4 describes the training and test phases of our algorithm in more detail and reports on experiments comparing the new model to the Brill and Moore model. Section 6 contains conclusions and ideas for future work. 2 Brill and Moore Noisy Channel Spelling Correction Model Many statistical spelling correction methods can be viewed as instances of the noisy channel model. The misspelling of a word is viewed as the result of corruption of the intended word as it passes through a noisy communications channel. The task of spelling correction is a task of finding, for a misspelling w, a corre</context>
<context position="8097" citStr="Fisher, 1999" startWordPosition="1339" endWordPosition="1340"> misspellings are certainly not in the dictionary we need a letterto-phone converter that generates possible pronunciations for them. The next section describes our letter-to-phone model. P(wjr) P(wjw) NETtalk MS Speech Set Words Set Words Training 14,876 Training 106,650 Test 4,964 Test 30,003 Table 1: Text-to-phone conversion data 3 Letter-to-Phone Model There has been a lot of research on machine learning methods for letter-to-phone conversion. High accuracy is achieved, for example, by using neural networks (Sejnowski and Rosenberg, 1987), decision trees (Jiang et al., 1997), and N-grams (Fisher, 1999). We use a modified version of the method proposed by Fisher, incorporating several extensions resulting in substantial gains in performance. In this section we first describe how we do alignment at the phone level, then describe Fisher’s model, and finally present our extensions and the resulting letterto-phone conversion accuracy. The machine learning algorithms for converting text to phones usually start off with training data in the form of a set of examples, consisting of letters in context and their corresponding phones (classifications). Pronunciation dictionaries are the major source o</context>
<context position="11347" citStr="Fisher (1999)" startWordPosition="1884" endWordPosition="1885">the most likely alignment for each word given the parameters and then re-estimates the parameters collecting counts from the obtained alignments. Here phones ranges over sequences of 0 (empty), 1, and 2 phones for the Microsoft Speech dictionary and 0 or 1 phones for NETtalk. The parameters P (phonesIletter) were initialized by amethod similar to the one proposed in (Daelemans and van den Bosch, 1996). Word frequencies were not taken into consideration here as the dictionary contains no frequency information. 3.1 Initial Letter-to-Phone Model The method we started with was the N-gram model of Fisher (1999). From training data, it learns rules that predict the pronunciation of a letter based on m letters of left and n letters of right context. The rules are of the following form: [Lm.T.Rn —� ph1 p1 ph2 p2 . . .] Here Lm stands for a sequence of m letters to the left of T and Rn is a sequence of n letters to the right. The number of letters in the context to the left and right varies. We used from 0 to 4 letters on each side. For example, two rules learned for the letter B were: [AB.B.OT —� — 1.0] and [B —� b .96 — .04], meaning that in the first context the letter B is silent with probability 1.</context>
<context position="13222" citStr="Fisher (1999)" startWordPosition="2234" endWordPosition="2235">oned above is more specific than the second. 3.2 Extensions We implemented five extensions to the initial model which together decreased the error rate of the letterto-phone model by around 20%. These are: • Combination of the predictions of several applicable rules by linear interpolation • Rescoring of N-best proposed pronunciations for a word using a trigram phone sequence language model • Explicit distinction between middle of word versus start or end • Rescoring of N-best proposed pronunciations for a word using a fourgram vowel sequence language model The performance figures reported by Fisher (1999) are significantly higher than our figures using the basic model, which is probably due to the cleaner data used in their experiments and the differences in phoneset size. The extensions we implemented are inspired largely by the work on letter-to-phone conversion using decision trees (Jiang et al., 1997). The last extension, rescoring based on vowel fourgams, has not been proposed previously. We tested the algorithms on the NETtalk and Microsoft Speech dictionaries, by splitting them into training and test sets in proportion 80%/20% training-set to test-set size. We trained the letter-to-phon</context>
<context position="15550" citStr="Fisher, 1999" startWordPosition="2611" endWordPosition="2612">es given by the five most specific matching rules we decreased the word error rate by 14.3%. The weights for the individual rules in the top five were set to be equal. It seems reasonable to combine the predictions from several rules especially because the choice of which rule is more specific of two is arbitrary when neither is a substring of the other. For example, of the two rules with contexts A.B. and .B.B, where the first has 0 right context and the second has 0 left letter context, one heuristic is to choose the latter as more specific since right context seems more valuable than left (Fisher, 1999). However this choice may not always be the best and it proves useful to combine predictions from several rules. In Table 2 the row labeled “Interpolation of contexts” refers to this extension of the basic model. Adding a symbol for interior of word produced a gain in accuracy. Prior to adding this feature, we had features for beginning and end of word. Explicitly modeling interior proved helpful and further decreased our error rate by 4.3%. The results after this improvement are shown in the third row of Table 2. After linearly combining the predictions from the top matching rules we have a p</context>
</contexts>
<marker>Fisher, 1999</marker>
<rawString>W. M. Fisher. 1999. A statistical text-to-phone function using ngrams and rules. In Proc. of the IEEE International Conference on Acoustics, Speech and Signal Processing, pages 649–652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Jiang</author>
<author>H W Hon</author>
<author>X Huang</author>
</authors>
<title>Improvements on a trainable letter-to-sound converter.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th European Conference on Speech Communication and Technology.</booktitle>
<contexts>
<context position="8069" citStr="Jiang et al., 1997" startWordPosition="1333" endWordPosition="1336">words and the misspellings. As the misspellings are certainly not in the dictionary we need a letterto-phone converter that generates possible pronunciations for them. The next section describes our letter-to-phone model. P(wjr) P(wjw) NETtalk MS Speech Set Words Set Words Training 14,876 Training 106,650 Test 4,964 Test 30,003 Table 1: Text-to-phone conversion data 3 Letter-to-Phone Model There has been a lot of research on machine learning methods for letter-to-phone conversion. High accuracy is achieved, for example, by using neural networks (Sejnowski and Rosenberg, 1987), decision trees (Jiang et al., 1997), and N-grams (Fisher, 1999). We use a modified version of the method proposed by Fisher, incorporating several extensions resulting in substantial gains in performance. In this section we first describe how we do alignment at the phone level, then describe Fisher’s model, and finally present our extensions and the resulting letterto-phone conversion accuracy. The machine learning algorithms for converting text to phones usually start off with training data in the form of a set of examples, consisting of letters in context and their corresponding phones (classifications). Pronunciation diction</context>
<context position="13528" citStr="Jiang et al., 1997" startWordPosition="2282" endWordPosition="2285">ng of N-best proposed pronunciations for a word using a trigram phone sequence language model • Explicit distinction between middle of word versus start or end • Rescoring of N-best proposed pronunciations for a word using a fourgram vowel sequence language model The performance figures reported by Fisher (1999) are significantly higher than our figures using the basic model, which is probably due to the cleaner data used in their experiments and the differences in phoneset size. The extensions we implemented are inspired largely by the work on letter-to-phone conversion using decision trees (Jiang et al., 1997). The last extension, rescoring based on vowel fourgams, has not been proposed previously. We tested the algorithms on the NETtalk and Microsoft Speech dictionaries, by splitting them into training and test sets in proportion 80%/20% training-set to test-set size. We trained the letter-to-phone models using the training splits and tested on the test splits. We Model Phone Acc Word Acc Initial 88.83% 53.28% Interpolation 90.55% 59.04% of contexts Distinction 91.09% 60.81% of middle Phonetic 91.38% 62.95% trigram Vowel 91.46% 63.63% fourgram Table 2: Letter-to-phone accuracies are reporting accu</context>
<context position="16323" citStr="Jiang et al., 1997" startWordPosition="2743" endWordPosition="2746"> of contexts” refers to this extension of the basic model. Adding a symbol for interior of word produced a gain in accuracy. Prior to adding this feature, we had features for beginning and end of word. Explicitly modeling interior proved helpful and further decreased our error rate by 4.3%. The results after this improvement are shown in the third row of Table 2. After linearly combining the predictions from the top matching rules we have a probability distribution over phones for each letter. It has been shown that modeling the probability of sequences of phones can greatly reduce the error (Jiang et al., 1997). We learned a trigram phone sequence model and used it to re-score the N-best predictions from the basic model. We computed the score for a sequence of phones given a sequence of letters, as follows: Score(p1;p2; ::: ;pnjl1;l2 ::: ln) _ log 11 P (pijl1; l2 ::: ln) + i=1...n a log 11 P(pijpi-1; pi-2) (1) i=1...n Here the probabilities P (pijl1; l2 ::: ln) are the distributions over phones that we obtain for each letter from combination of the matching rules. The weight a for the phone sequence model was estimated from a held-out set by a linear search. This model further improved our performan</context>
</contexts>
<marker>Jiang, Hon, Huang, 1997</marker>
<rawString>L. Jiang, H.W. Hon, and X. Huang. 1997. Improvements on a trainable letter-to-sound converter. In Proceedings of the 5th European Conference on Speech Communication and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kuckich</author>
</authors>
<title>Techniques for automatically correcting words in text.</title>
<date>1992</date>
<journal>In ACM Computing Surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<pages>377--439</pages>
<contexts>
<context position="820" citStr="Kuckich, 1992" startWordPosition="113" endWordPosition="114">a Robert C. Moore Computer Science Department Microsoft Research Stanford University One Microsoft Way Stanford, CA 94305 USA Redmond, WA 98052 USA Abstract This paper presents a method for incorporating word pronunciation information in a noisy channel model for spelling correction. The proposed method builds an explicit error model for word pronunciations. By modeling pronunciation similarities between words we achieve a substantial performance improvement over the previous best performing models for spelling correction. 1 Introduction Spelling errors are generally grouped into two classes (Kuckich, 1992) — typographic and cognitive. Cognitive errors occur when the writer does not know how to spell a word. In these cases the misspelling often has the same pronunciation as the correct word ( for example writing latex as latecks). Typographic errors are mostly errors related to the keyboard; e.g., substitution or transposition of two letters because their keys are close on the keyboard. Damerau (1964) found that 80% of misspelled words that are non-word errors are the result of a single insertion, deletion, substitution or transposition of letters. Many of the early algorithms for spelling corre</context>
</contexts>
<marker>Kuckich, 1992</marker>
<rawString>K. Kuckich. 1992. Techniques for automatically correcting words in text. In ACM Computing Surveys, volume 24(4), pages 377–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Church M D Kernigan</author>
<author>W A Gale</author>
</authors>
<title>A spelling correction program based on a noisy channel model.</title>
<date>1990</date>
<booktitle>In Proc. of COLING-90,</booktitle>
<volume>volume II,</volume>
<pages>205--211</pages>
<contexts>
<context position="1570" citStr="Kernigan and Gale, 1990" startWordPosition="235" endWordPosition="238">pelling often has the same pronunciation as the correct word ( for example writing latex as latecks). Typographic errors are mostly errors related to the keyboard; e.g., substitution or transposition of two letters because their keys are close on the keyboard. Damerau (1964) found that 80% of misspelled words that are non-word errors are the result of a single insertion, deletion, substitution or transposition of letters. Many of the early algorithms for spelling correction are based on the assumption that the correct word differs from the misspelling by exactly one of these operations (M. D. Kernigan and Gale, 1990; Church and Gale, 1991; Mayes and F. Damerau, 1991). By estimating probabilities or weights for the different edit operations and conditioning on the left and right context for insertions and deletions and allowing multiple edit operations, high spelling correction accuracy has been achieved. At ACL 2000, Brill and Moore (2000) introduced a new error model, allowing generic string-to-string edits. This model reduced the error rate of the best previous model by nearly 50%. It proved advantageous to model substitutions of up to 5-letter sequences (e.g ent being mistyped as ant, ph as f, al as l</context>
</contexts>
<marker>Kernigan, Gale, 1990</marker>
<rawString>W. Church M. D. Kernigan and W. A. Gale. 1990. A spelling correction program based on a noisy channel model. In Proc. of COLING-90, volume II, pages 205– 211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mayes</author>
</authors>
<title>Conext based spelling correction.</title>
<date>1991</date>
<booktitle>In Information Processing and Management,</booktitle>
<volume>27</volume>
<issue>5</issue>
<pages>517--522</pages>
<marker>Mayes, 1991</marker>
<rawString>F. Mayes and et al. F. Damerau. 1991. Conext based spelling correction. In Information Processing and Management, volume 27(5), pages 517–522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T J Sejnowski</author>
<author>C R Rosenberg</author>
</authors>
<title>Parallel networks that learn to pronounce english text.</title>
<date>1987</date>
<booktitle>In Complex Systems,</booktitle>
<pages>145--168</pages>
<contexts>
<context position="8032" citStr="Sejnowski and Rosenberg, 1987" startWordPosition="1326" endWordPosition="1329">PH, we need word pronunciations for the correct words and the misspellings. As the misspellings are certainly not in the dictionary we need a letterto-phone converter that generates possible pronunciations for them. The next section describes our letter-to-phone model. P(wjr) P(wjw) NETtalk MS Speech Set Words Set Words Training 14,876 Training 106,650 Test 4,964 Test 30,003 Table 1: Text-to-phone conversion data 3 Letter-to-Phone Model There has been a lot of research on machine learning methods for letter-to-phone conversion. High accuracy is achieved, for example, by using neural networks (Sejnowski and Rosenberg, 1987), decision trees (Jiang et al., 1997), and N-grams (Fisher, 1999). We use a modified version of the method proposed by Fisher, incorporating several extensions resulting in substantial gains in performance. In this section we first describe how we do alignment at the phone level, then describe Fisher’s model, and finally present our extensions and the resulting letterto-phone conversion accuracy. The machine learning algorithms for converting text to phones usually start off with training data in the form of a set of examples, consisting of letters in context and their corresponding phones (cl</context>
</contexts>
<marker>Sejnowski, Rosenberg, 1987</marker>
<rawString>T. J. Sejnowski and C. R. Rosenberg. 1987. Parallel networks that learn to pronounce english text. In Complex Systems, pages 145–168.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>