<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.986172">
Can Nominal Expressions Achieve Multiple Goals?: An
Empirical Study
</title>
<author confidence="0.898858">
Pamela W. Jordan
</author>
<affiliation confidence="0.936594">
Intelligent Systems Program
University of Pittsburgh
</affiliation>
<address confidence="0.724203">
Pittsburgh PA 15260 *
</address>
<email confidence="0.999009">
jordan@isp.pitt.edu
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999964739130435">
While previous work suggests that
multiple goals can be addressed by a
nominal expression, there is no sys-
tematic work describing what goals
in addition to identification might
be relevant and how speakers can
use nominal expressions to achieve
them. In this paper, we first hy-
pothesize a number of communica-
tive goals that could be addressed by
nominal expressions in task-oriented
dialogues. We then describe the in-
tentional influences model for nom-
inal expression generation that at-
tempts to simultaneously address
the identification goal and these ad-
ditional goals with a single nominal
expression. Our evaluation results
show that the intentional influences
model fits the nominal expressions
in the COCONUT corpus as well as
previous accounts that focus solely
on the identification goal.
</bodyText>
<sectionHeader confidence="0.999029" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999557875">
Previous work on nominal expression gener-
ation has mainly focused on the use of nom-
inal expressions to achieve a speaker&apos;s goal
to identify an object in the discourse con-
text (Dale and Reiter, 1995; Passonneau,
1995). While other work suggests that it
should be possible for a nominal expression
to contribute to the satisfaction of additional
</bodyText>
<footnote confidence="0.725571">
This work was partially funded by NSF grant IRI-
9314961 at the University of Pittsburgh, and a Mellon
Predoctoral Fellowship
</footnote>
<bodyText confidence="0.987062">
goals (Appelt, 1985; Pollack, 1991; Stone and
Webber, 1998), there is no systematic work
describing what these goals might be and
how speakers can use nominal expressions to
achieve them. For example, consider the dia-
logue contribution in (1) in a context in which
the color of the table is not necessary to IDEN-
TIFY the discourse entity under discussion,
but where the color of the item could be in-
ferred to be MOTIVATION for the proposal.&apos;
(I) Let&apos;s use my table. It is red.
A plausible hypothesis is that the alterna-
tive utterance in (2) could also support the
MOTIVATION inference, and that the nominal
expression my red table could thus simultane-
ously achieve the two goals of identifying the
object under discussion and supporting the
MOTIVATION inference.
(2) Let&apos;s use my red table.
We hypothesized that in addition to the
conversational inference of MOTIVATION that
a speaker might also attempt to achieve other
task-relevant inferences via the generation of
nominal expressions.
In order to test this hypothesis further,
we first specified a number of specific com-
municative goals that we believe can be
addressed by nominal expressions in task-
oriented dialogues. We then implemented two
models of nominal expression generation. The
first model was the INCREMENTAL MODEL of
Dale and Reiter (1995), which implements a
strategy for satisfying the identification goal.
</bodyText>
<footnote confidence="0.9523405">
1-For example, a possible context is one in which
the speaker only has one table, and the speaker and
hearer are trying for one color in a room, and have
already agreed upon other red furniture.
</footnote>
<bodyText confidence="0.999931818181818">
The second model we call the intentional in-
fluences model; this model of nominal ex-
pression generation attempts to simultane-
ously achieve the identification goal and to
cue other task-related inferences with a sin-
gle nominal expression. We then evaluated
these two models using 13 of the dialogues
from the COCONUT corpus of task-oriented di-
alogues (Di Eugenio et al., 1998). This sub-
set of dialogues contains 166 non-pronominal
discourse anaphoric expressions which we call
REDESCRIPTIONS (e.g. my table and my red
table in (1) and (2)). Our results show that
the intentional influences model fits the re-
descriptions in the corpus as well as previous
accounts which focus solely on the identifi-
cation goal. To test the validity of the set
of inferences we considered in the intentional
influences model, we also compared it to a
model that addresses the identification goal
but also includes additional mutually known
attributes at random. We found that the
inference set we considered was significantly
better than random.
Section 2 describes the COCONUT corpus,
the task that the conversants were attempting
to achieve, the conversational inferences rel-
evant to the task, and our hypotheses about
the way these conversational inferences could
provide additional influences on the speaker&apos;s
generation of nominal expressions. Section 3
explains how we tested our hypotheses and
section 4 presents our results.
</bodyText>
<sectionHeader confidence="0.9857235" genericHeader="method">
2 Potential Influences on
Redescriptions
</sectionHeader>
<bodyText confidence="0.972903344827586">
The COCONUT corpus consists of 24
computer-mediated dialogues in which
two people collaborate on a simple design
task, buying furniture for two rooms of a
house. The participants&apos; main goal is to
negotiate the purchases; the items of highest
priority are a sofa for the living room and
a table and four chairs for the dining room.
The participants also have specific secondary
goals which further constrain the problem
solving task. Participants are instructed to
try to meet as many of these goals as possible,
and are motivated to do so by associating
points with satisfied goals. The secondary
goals are: 1) use one color attribute value
for all items within a room, 2) buy as much
furniture as you can, 3) spend all your money.
The participants are equals and must agree
on the final plan for furnishing the house.
We hypothesized that many of the task-
related inferences that the participants must
make in this domain to (1) efficiently come
to an agreement, and (2) do well on the task,
could potentially be cued by the nominal ex-
pressions describing the items of furniture
used to solve the task.2
Persuasion Hypothesis: The first task-
related inference that we consider is the MO-
TIVATION inference exemplified in examples
</bodyText>
<listItem confidence="0.8781935">
(1) and (2). Previous research suggests
that discourse relations such as motivation
</listItem>
<bodyText confidence="0.850571666666667">
can influence the content and form of utter-
ances (Mann and Thompson, 1987; McKe-
own, 1985; Moser and Moore, 1995). It seems
plausible that the speaker can cue these same
inferences via nominal redescriptions. For ex-
ample, in (3)3 one can infer from O&apos;s last ut-
terance and the redescription mine for 150
that his motivation for proposing his rug is
its better price.
</bodyText>
<listItem confidence="0.846066333333333">
(3) U: i have a blue rug for 250. that would leave
us with 50 or any other options you may
have for us.
</listItem>
<bodyText confidence="0.79010125">
0: ok lets take the blue rug for 250, my rug
would not match which is yellow for 150.
U: we don&apos;t have to match...
0: well then lets use mine for 150.
</bodyText>
<sectionHeader confidence="0.769016" genericHeader="method">
PERSUASION HYPOTHESIS: Proper-
</sectionHeader>
<bodyText confidence="0.99767675">
ties that are relevant to getting the
hearer to agree with the speaker&apos;s
proposed action may be expressed in
the context of a goal to propose that
action.
21n this respect our hypotheses are similar to those
of Walker (1993) and Johnstone (1994), who hypoth-
esized that speakers in task-oriented dialogues would
restate information that was already in the common
ground for the purpose of cuing particular task-related
or conversational inferences.
3A11 of the COCONUT excerpts appear verbatim
except that we italicize redescriptions and due to space
limitations we omit parts of turns when they are un-
related to the point of the example. We indicate omis-
sions with &lt;...&gt;.
</bodyText>
<subsubsectionHeader confidence="0.545758">
Constraint Changes Hypothesis: The
</subsubsectionHeader>
<bodyText confidence="0.999895259259259">
second type of task-related inference is mo-
tivated by the observation that participants
in task-oriented dialogues appear to be able
to coordinate on the relaxation of particular
task constraints without needing to discuss
it. For example, the participants may de-
cide it is impossible to achieve the optional
task goal of matching furniture colors within
a room. In the COCONUT dialogues, in 38%
of the cases where optional goals were aban-
doned, the participants appeared to agree to
abandon the goal without explicit discussion.4
Our hypothesis is that this inference can also
be cued by the content of a nominal expres-
sion when that expression realizes properties
of a domain object that are not needed to
identify which object is under discussion. For
example, in (4) A specifies both the color and
price for both the sofa and the lamp even
though the price attributes alone would ad-
equately identify each item. By specifying
the color, one can easily infer that the color
match constraint has been dropped in the pro-
posal. A has eliminated having to explicitly
communicate this information (Walker, 1993)
and reduced the risk of the hearer missing the
inference (Carletta, 1992).
</bodyText>
<listItem confidence="0.709764666666667">
(4) S: &lt;...&gt; if we do that i have 400 blue sofa
and a 350 yellow sofa, and i have a 250
blue floor lamp or a 150 yellow rug. &lt;...&gt;
</listItem>
<bodyText confidence="0.949385785714286">
A: &lt;...&gt; so now we have 600 left for the living
room. if we get your 350 yellow sofa and
your 250 blue floor lamp, that sounds good
to me because I don&apos;t have anything better
in my inventory.
DOMAIN CONSTRAINT CHANGES HY-
POTHESIS: Properties related to
constraint changes are expressed in
a context where the change is to be
inferred by the hearer.
Commitment Hypothesis: The next
two types of inference are based on the idea
that if a speaker repeats an utterance and pro-
vides no new information, this can show that
</bodyText>
<footnote confidence="0.9601295">
4In (3) there is some explicit discussion about the
color match goal.
</footnote>
<bodyText confidence="0.997849454545454">
a stage of the interaction is complete (Whit-
taker and Stenton, 1988; Jordan and Di Eu-
genio, 1997). Repeating properties for a re-
cently evoked item could show that the cur-
rent stage has just been completed while do-
ing so for an older item could indicate that a
higher level subproblem has been completed.
In (5), S&apos;s second utterance appears to end a
stage in the interaction, in this case the end of
the agreement process for a select sofa action
(Di Eugenio et al., 2000).
</bodyText>
<figure confidence="0.538584">
(5) S: &lt;...&gt; I have a $300 yellow sofa &lt;...&gt;
G: My sofa&apos;s are more expensive so buy your
$300 yellow sofa. Also &lt;...&gt;
S: &lt;...&gt; / will go ahead and buy the $300
yellow sofa.
</figure>
<bodyText confidence="0.874409571428571">
COMMITMENT HYPOTHESIS: In the
context of a commitment to a pro-
posal, all the properties expressed in
the proposal will be repeated.
Summarization Hypothesis: The sec-
ond case in which a higher level subproblem
was completed is illustrated by the summary
in (6). Note that D summarizes both living
room (as requested) and dining room items.
Summaries differ from commitments in that
they are delayed redescriptions. The action
associated with the object was completed and
the participants had moved on to a new part
of the task.
</bodyText>
<listItem confidence="0.986517333333333">
(6) G: I got the rug. What do you have in the
living room and what are the prices of the
items
</listItem>
<bodyText confidence="0.541038333333333">
D: the green sofa in the living room 350. din-
ing room &gt; 3 yellow chairs 75 each, 1
high-table yellow, 1 yellow rug
</bodyText>
<sectionHeader confidence="0.731303" genericHeader="method">
SUMMARIZATION HYPOTHESIS: In
</sectionHeader>
<bodyText confidence="0.998225714285714">
the context of a previously com-
pleted problem or subproblem, all
the mutually known properties for
an item will be repeated.
Verification Hypothesis: The final type
of inference we considered is when a speaker
repeats an utterance to show that it was un-
derstood (Clark and Schaefer, 1989; Brennan,
1990; Walker, 1992; Walker, 1993). In the
COCONUT corpus, the hearer sometimes re-
peats the description in the turn immediately
following. For example, in (5) G repeats S&apos;s
description of the sofa, although the sofa was
introduced by S. We claim that this type of
redescription could help verify that the prop-
erty information was correctly understood.
VERIFICATION HYPOTHESIS: In the
context of a newly introduced en-
tity, all the properties expressed will
be repeated by the hearer in his/her
next turn.
</bodyText>
<sectionHeader confidence="0.997912" genericHeader="conclusions">
3 Experimental Approach
</sectionHeader>
<bodyText confidence="0.999980960784314">
To verify our hypotheses about what could
influence attribute selection, we undertook
a two part corpus investigation. First, we
did correlational studies on the corpus to
get guidance on which of the hypotheses we
should examine more closely. Our correla-
tional studies showed that the contexts and
attribute selections indicated in our hypothe-
ses positively correlated for all but Verifica-
tion and Summarization (Jordan, 2000a).
In the second part of our investigation,
which is the subject of this paper, we ana-
lyzed how well computer simulated selections
for the COCONUT corpus matched human
selections. We reasoned that if our hypothe-
ses were valid then a selection strategy that
incorporates them should match the selec-
tions made by humans at least as well as an
identification-only selection strategy. We an-
ticipated that the degree of match could be
similar since there may be many allowable
ways to express a description for identification
purposes and the selections intended to cue
the inferences could intersect some of these
allowable ways. However, if the hypotheses
were invalid then the resulting descriptions
should only match the corpus as well as iden-
tificationally adequate descriptions that have
some random attributes included. For exam-
ple, if my table is identificationally adequate
then it might also randomly include any of
the remaining mutually known attributes as
well (e.g. my red table, my $250 table).
We simulated selections for the COCONUT
dialogues by using annotations about the dis-
course entities to be described and the con-
texts in which they appeared as input to
the selection strategies we wished to test.
We used existing annotations that were pre-
viously developed and tested for the CO-
CONUT project as described in (Di Eugenio
et al., 2000) as well as ones developed specif-
ically for this research (Jordan, 2000b).5
One type of annotation feature we used to
identify some of the contexts indicated in our
hypotheses, were those that defined elements
of the agreement process described in (Di Eu-
genio et al., 2000). First we will present high-
level definitions of these agreement process el-
ements and then we will explain how we used
these definitions to identify the contexts.
</bodyText>
<listItem confidence="0.933110933333333">
• propose: The speaker offers the item and
unconditionally commits to using it and
the offer makes the mutual solution state
determinate.
• partner decidable option: The speaker
offers an item and conditionally commits
to using it but the offer leaves the mutual
solution state indeterminate.
• unconditional commit: The speaker in-
dicates his unconditional commitment to
using the item
• unendorsed option: The speaker offers
an item but does not show any commit-
ment to using it when the mutual solu-
tion state is already determinate.
</listItem>
<bodyText confidence="0.992410542857143">
The context for the Summarization hypoth-
esis is the most restrictive. An agreement
must have been reached for an annotated ac-
tion without the action being readdressed be-
tween the agreement and the Summarization.
The achievement of an agreement state is ap-
proximated when either 1) a propose or part-
ner decidable option was the last state for the
action and it happened more than two turns
ago or 2) an unconditional commit was the
last state and it happened two or more turns
ago. In the first case, the agreement must
5A11 of the annotations features were found to have
good intercoder reliability.
be inferred and in the other the agreement is
more explicit.
The Commitment context exists when a
commitment is to be made and either 1) there
is a previous proposal or unconditional com-
mitment for the action involving the entity in
the immediately previous turn and no other
unrelated entities have been discussed for the
action in the interim or 2) a speaker indi-
cated unconditional commitment in his pre-
vious turn. This definition reflects commit-
ment patterns described in (Di Eugenio et al.,
2000).
The Persuasion context exists when a pro-
posal is to be made and alternate solutions
exist and there is a contrast between the col-
ors or prices that make the proposed item
clearly a better choice. Given the analysis
of the agreement process in (Di Eugenio et
al., 2000), we identify proposals by looking
for either a propose utterance, or an uncondi-
tional commitment utterance where the pre-
vious state for an annotated action is an unen-
dorsed option or a partner decidable option.
The alternatives are approximated by accu-
mulating a list of the items evoked for each
annotated action up until a propose or un-
conditional commitment occurs.
Once we have identified proposals and al-
ternative solutions, next we check for con-
trasts to the alternative solutions and the
partial solution. For color we compare the
color of the proposed item to those items al-
ready selected for the room and the alternate
items. If the proposed item matches the color
of items already selected for the room while
none of the alternates do, then a Persuasion
context exists. For prices there are two pos-
sibilities that depend on whether or not the
end of the problem solving effort is nearing.
An item may be a better choice 1) when the
price of the proposed item is greater than that
of each alternate (i.e. it may be helping to
spend out the budget) or 2) when the price
of the proposed item is less than that of each
alternate (i.e. the cheaper item may be pre-
ferred since it leaves some money for other
purchases).
The remaining contexts are easier to rec-
ognize. The Verification context exists when
an item was initially described in the immedi-
ately previous turn. The Domain constraint
change context exists whenever an implicit
constraint change is directly annotated.
We used the human generated descriptions
in the COCONUT corpus to evaluate the de-
scriptions created by the selection strategies
we wished to test. To compare the perfor-
mance of a selection strategy to that of hu-
mans, we used a measure of the degree of
match between the human&apos;s and the strat-
egy&apos;s selection of attributes for the same dis-
course entity in the same dialogue context.
Inclusion and exclusion of an attribute both
count in the degree of match. A perfect match
means that the strategy chose to include or
exclude the same attributes as the human did
for a particular entity. The measure, X/N,
ranges between 0 and 1 inclusive, where X
is the number of attribute inclusions and ex-
clusions that agree with the human descrip-
tion and N is the number of attributes that
could be expressed for an entity. This re-
sponse variable is called match in the experi-
ments that follow. After doing an analysis of
variance (Mat, 1998) on the results of exper-
iments where we varied the selection strat-
egy, we used multiple pairwise comparisons
(MCA) (Hsu, 1996) 6 to locate where signif-
icant performance differences between strate-
gies existed.7 We display the results of the
multiple comparisons as 95% confidence inter-
vals, (e.g. as in Figure 3), which are always
of the form:
(estimate)±(critical point) x (standard er-
ror of estimate)
The critical point in the above calculation
depends on the multiple comparison method
used (e.g. Tukey, Dunnett, LSD). We chose
the method that created the smallest critical
point and this is indicated in each figure. 8
</bodyText>
<footnote confidence="0.993722142857143">
6We used S-plus&apos; multicomp function to perform
the multiple comparisons (Mat, 1998).
7MCA is a standard statistical procedure for pair-
wise comparisons. It adjusts the ANOVA confidence
intervals for error propagation (Hsu, 1996; Cohen,
1995).
85-plus&apos; multicomp function can optionally con-
</footnote>
<table confidence="0.66488152">
(
)
−Summ − Summ
+
−0.018 −0.014 −0.010 −0.006 −0.002 0.0
individual 95 % confidence limits, LSD method
response variable: match
(
)
Verif − Verif
+
0.0 0.002 0.004 0.006 0.008 0.010 0.012 0.014 0.016
individual 95 % confidence limits, LSD method
response variable: match
(
(
( )
)
)
INC − RINF
INC − IINF
RINF − IINF
−0.16 −0.12 −0.08 −0.04 0.0 0.04 0.08 0.12
simultaneous 95 % confidence limits, Tukey method
response variable: match
</table>
<bodyText confidence="0.9997952">
represented in the IINF selection strategy to
see which cases are critical for ensuring an in-
ference is made. However, to test these goals
individually we need to collect more instances
of redescriptions.
</bodyText>
<sectionHeader confidence="0.997744" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999689369565217">
Douglas E. Appelt. 1985. Planning English
Sentences. Cambridge University Press, Cam-
bridge, U.K.
Susan E. Brennan. 1990. Seeking and Providing
Evidence for Mutual Understanding. Ph.D. the-
sis, Stanford University Psychology Dept. Un-
published Manuscript.
Jean C. Carletta. 1992. Risk Taking and Recov-
ery in Task-Oriented Dialogue. Ph.D. thesis,
Edinburgh University.
Herbert H. Clark and Edward F. Schaefer. 1989.
Contributing to discourse. Cognitive Science,
13:259-294.
Paul R. Cohen. 1995. Empirical Methods for Ar-
tificial Intelligence. MIT Press, Boston.
Robert Dale and Ehud Reiter. 1995. Computa-
tional interpretations of the Gricean maxims in
the generation of referring expressions. Cogni-
tive Science, 19(2):233-263, Apr-June.
Barbara Di Eugenio, Pamela W. Jordan, Jo-
hanna D. Moore, and Richmond H. Thomason.
1998. An empirical investigation of collabora-
tive dialogues. In ACL-COLING98, Proceed-
ings of the Thirty-sixth Conference of the As-
sociation for Computational Linguistics, Mon-
treal, Canada, August.
Barbara Di Eugenio, Pamela W. Jordan, Rich-
mond H. Thomason, and Johanna D. Moore.
2000. The agreement process: An empiri-
cal investigation of human-human computer-
mediated collaborative dialogues. To Appear
in International Journal of Human-Computer
Studies.
Jason C. Hsu. 1996. Multiple Comparisons: The-
ory and Methods. Chapman and Hall, London.
Barbara Johnstone. 1994. Repetition in dis-
course: A dialogue. In Barbara Johnstone,
editor, Repetition in Discourse: Interdisci-
plinary Perspectives, Volume I, volume XLVII
of Advances in Discourse Processes, chapter 1.
Ablex.
Pamela W. Jordan and Barbara Di Eugenio. 1997.
Control and initiative in collaborative problem
solving dialogues. In Computational Models for
Mixed Initiative Interaction. Papers from the
1997 AAAI Spring Symposium. Technical Re-
port 55-97-04, pages 81-84. The AAAI Press.
Pamela W. Jordan. 2000a. Influences on attribute
selection in redescriptions: A corpus study. In
Proceedings of CogSci2000, August.
Pamela W. Jordan. 2000b. Intentional Influences
on Object Redescriptions in Dialogue: Evidence
from an Empirical Study. Ph.D. thesis, Intel-
ligent Systems Program, University of Pitts-
burgh.
W.C. Mann and S.A. Thompson. 1987. Rhetor-
ical Structure Theory: A Framework for the
Analysis of Texts. Technical Report RS-87-190,
USC/Information Sciences Institute.
MathSoft, Inc., Seattle, Washington, 1998. S-Plus
5 for Unix Guide to Statistics, September.
Kathleen R. McKeown. 1985. Text Generation.
Using Discourse Strategies and Focus Con-
straints to Generate Natural Language Text.
Cambridge University Press.
Megan Moser and Johanna D. Moore. 1995. In-
vestigating cue placement and selection in tu-
torial discourse. In Proceedings of 33rd Annual
Meeting of the Association for Computational
Linguistics, pages 130-135.
Rebecca J. Passonneau. 1995. Integrating
Gricean and attentional constraints. In Pro-
ceedings of IJCAI 95.
Martha E. Pollack. 1991. Overloading intentions
for efficient practical reasoning. Nofts, 25:513 -
536.
Matthew Stone and Bonnie Webber. 1998. Tex-
tual economy through close coupling of syntax
and semantics. In Proceedings of 1998 Interna-
tional Workshop on Natural Language Genera-
tion, Niagra-on-the-Lake, Canada.
Marilyn A. Walker. 1992. Redundancy in col-
laborative dialogue. In Fourteenth Interna-
tional Conference on Computational Linguis-
tics, pages 345-351.
Marilyn A. Walker. 1993. Informational Redun-
dancy and Resource Bounds in Dialogue. Ph.D.
thesis, University of Pennsylvania, December.
Steve Whittaker and Phil Stenton. 1988. Cues
and control in expert client dialogues. In Proc.
26th Annual Meeting of the ACL, Association
of Computational Linguistics, pages 123-130.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.425188">
<title confidence="0.9654385">Can Nominal Expressions Achieve Multiple Goals?: An Empirical Study</title>
<author confidence="0.999935">Pamela W Jordan</author>
<affiliation confidence="0.997517">Intelligent Systems Program University of Pittsburgh</affiliation>
<address confidence="0.812441">Pittsburgh PA 15260 *</address>
<email confidence="0.999492">jordan@isp.pitt.edu</email>
<abstract confidence="0.999755260869565">While previous work suggests that multiple goals can be addressed by a nominal expression, there is no systematic work describing what goals in addition to identification might be relevant and how speakers can use nominal expressions to achieve them. In this paper, we first hypothesize a number of communicative goals that could be addressed by nominal expressions in task-oriented We then describe the infor nominal expression generation that attempts to simultaneously address and these additional goals with a single nominal expression. Our evaluation results that the influences model fits the nominal expressions in the COCONUT corpus as well as previous accounts that focus solely</abstract>
<intro confidence="0.56578">the</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
</authors>
<title>Planning English Sentences.</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, U.K.</location>
<contexts>
<context position="1486" citStr="Appelt, 1985" startWordPosition="228" endWordPosition="229"> expressions in the COCONUT corpus as well as previous accounts that focus solely on the identification goal. 1 Introduction Previous work on nominal expression generation has mainly focused on the use of nominal expressions to achieve a speaker&apos;s goal to identify an object in the discourse context (Dale and Reiter, 1995; Passonneau, 1995). While other work suggests that it should be possible for a nominal expression to contribute to the satisfaction of additional This work was partially funded by NSF grant IRI9314961 at the University of Pittsburgh, and a Mellon Predoctoral Fellowship goals (Appelt, 1985; Pollack, 1991; Stone and Webber, 1998), there is no systematic work describing what these goals might be and how speakers can use nominal expressions to achieve them. For example, consider the dialogue contribution in (1) in a context in which the color of the table is not necessary to IDENTIFY the discourse entity under discussion, but where the color of the item could be inferred to be MOTIVATION for the proposal.&apos; (I) Let&apos;s use my table. It is red. A plausible hypothesis is that the alternative utterance in (2) could also support the MOTIVATION inference, and that the nominal expression m</context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>Douglas E. Appelt. 1985. Planning English Sentences. Cambridge University Press, Cambridge, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
</authors>
<title>Seeking and Providing Evidence for Mutual Understanding.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University Psychology Dept. Unpublished Manuscript.</institution>
<contexts>
<context position="10775" citStr="Brennan, 1990" startWordPosition="1811" endWordPosition="1812"> completed and the participants had moved on to a new part of the task. (6) G: I got the rug. What do you have in the living room and what are the prices of the items D: the green sofa in the living room 350. dining room &gt; 3 yellow chairs 75 each, 1 high-table yellow, 1 yellow rug SUMMARIZATION HYPOTHESIS: In the context of a previously completed problem or subproblem, all the mutually known properties for an item will be repeated. Verification Hypothesis: The final type of inference we considered is when a speaker repeats an utterance to show that it was understood (Clark and Schaefer, 1989; Brennan, 1990; Walker, 1992; Walker, 1993). In the COCONUT corpus, the hearer sometimes repeats the description in the turn immediately following. For example, in (5) G repeats S&apos;s description of the sofa, although the sofa was introduced by S. We claim that this type of redescription could help verify that the property information was correctly understood. VERIFICATION HYPOTHESIS: In the context of a newly introduced entity, all the properties expressed will be repeated by the hearer in his/her next turn. 3 Experimental Approach To verify our hypotheses about what could influence attribute selection, we u</context>
</contexts>
<marker>Brennan, 1990</marker>
<rawString>Susan E. Brennan. 1990. Seeking and Providing Evidence for Mutual Understanding. Ph.D. thesis, Stanford University Psychology Dept. Unpublished Manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean C Carletta</author>
</authors>
<title>Risk Taking and Recovery in Task-Oriented Dialogue.</title>
<date>1992</date>
<tech>Ph.D. thesis,</tech>
<institution>Edinburgh University.</institution>
<contexts>
<context position="8341" citStr="Carletta, 1992" startWordPosition="1365" endWordPosition="1366">e can also be cued by the content of a nominal expression when that expression realizes properties of a domain object that are not needed to identify which object is under discussion. For example, in (4) A specifies both the color and price for both the sofa and the lamp even though the price attributes alone would adequately identify each item. By specifying the color, one can easily infer that the color match constraint has been dropped in the proposal. A has eliminated having to explicitly communicate this information (Walker, 1993) and reduced the risk of the hearer missing the inference (Carletta, 1992). (4) S: &lt;...&gt; if we do that i have 400 blue sofa and a 350 yellow sofa, and i have a 250 blue floor lamp or a 150 yellow rug. &lt;...&gt; A: &lt;...&gt; so now we have 600 left for the living room. if we get your 350 yellow sofa and your 250 blue floor lamp, that sounds good to me because I don&apos;t have anything better in my inventory. DOMAIN CONSTRAINT CHANGES HYPOTHESIS: Properties related to constraint changes are expressed in a context where the change is to be inferred by the hearer. Commitment Hypothesis: The next two types of inference are based on the idea that if a speaker repeats an utterance and</context>
</contexts>
<marker>Carletta, 1992</marker>
<rawString>Jean C. Carletta. 1992. Risk Taking and Recovery in Task-Oriented Dialogue. Ph.D. thesis, Edinburgh University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
<author>Edward F Schaefer</author>
</authors>
<title>Contributing to discourse.</title>
<date>1989</date>
<journal>Cognitive Science,</journal>
<pages>13--259</pages>
<contexts>
<context position="10760" citStr="Clark and Schaefer, 1989" startWordPosition="1807" endWordPosition="1810">ciated with the object was completed and the participants had moved on to a new part of the task. (6) G: I got the rug. What do you have in the living room and what are the prices of the items D: the green sofa in the living room 350. dining room &gt; 3 yellow chairs 75 each, 1 high-table yellow, 1 yellow rug SUMMARIZATION HYPOTHESIS: In the context of a previously completed problem or subproblem, all the mutually known properties for an item will be repeated. Verification Hypothesis: The final type of inference we considered is when a speaker repeats an utterance to show that it was understood (Clark and Schaefer, 1989; Brennan, 1990; Walker, 1992; Walker, 1993). In the COCONUT corpus, the hearer sometimes repeats the description in the turn immediately following. For example, in (5) G repeats S&apos;s description of the sofa, although the sofa was introduced by S. We claim that this type of redescription could help verify that the property information was correctly understood. VERIFICATION HYPOTHESIS: In the context of a newly introduced entity, all the properties expressed will be repeated by the hearer in his/her next turn. 3 Experimental Approach To verify our hypotheses about what could influence attribute </context>
</contexts>
<marker>Clark, Schaefer, 1989</marker>
<rawString>Herbert H. Clark and Edward F. Schaefer. 1989. Contributing to discourse. Cognitive Science, 13:259-294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul R Cohen</author>
</authors>
<title>Empirical Methods for Artificial Intelligence.</title>
<date>1995</date>
<publisher>MIT Press,</publisher>
<location>Boston.</location>
<contexts>
<context position="18691" citStr="Cohen, 1995" startWordPosition="3137" endWordPosition="3138">omparisons as 95% confidence intervals, (e.g. as in Figure 3), which are always of the form: (estimate)±(critical point) x (standard error of estimate) The critical point in the above calculation depends on the multiple comparison method used (e.g. Tukey, Dunnett, LSD). We chose the method that created the smallest critical point and this is indicated in each figure. 8 6We used S-plus&apos; multicomp function to perform the multiple comparisons (Mat, 1998). 7MCA is a standard statistical procedure for pairwise comparisons. It adjusts the ANOVA confidence intervals for error propagation (Hsu, 1996; Cohen, 1995). 85-plus&apos; multicomp function can optionally con( ) −Summ − Summ + −0.018 −0.014 −0.010 −0.006 −0.002 0.0 individual 95 % confidence limits, LSD method response variable: match ( ) Verif − Verif + 0.0 0.002 0.004 0.006 0.008 0.010 0.012 0.014 0.016 individual 95 % confidence limits, LSD method response variable: match ( ( ( ) ) ) INC − RINF INC − IINF RINF − IINF −0.16 −0.12 −0.08 −0.04 0.0 0.04 0.08 0.12 simultaneous 95 % confidence limits, Tukey method response variable: match represented in the IINF selection strategy to see which cases are critical for ensuring an inference is made. Howeve</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>Paul R. Cohen. 1995. Empirical Methods for Artificial Intelligence. MIT Press, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
<author>Ehud Reiter</author>
</authors>
<title>Computational interpretations of the Gricean maxims in the generation of referring expressions.</title>
<date>1995</date>
<journal>Cognitive Science,</journal>
<pages>19--2</pages>
<location>Apr-June.</location>
<contexts>
<context position="1196" citStr="Dale and Reiter, 1995" startWordPosition="181" endWordPosition="184">logues. We then describe the intentional influences model for nominal expression generation that attempts to simultaneously address the identification goal and these additional goals with a single nominal expression. Our evaluation results show that the intentional influences model fits the nominal expressions in the COCONUT corpus as well as previous accounts that focus solely on the identification goal. 1 Introduction Previous work on nominal expression generation has mainly focused on the use of nominal expressions to achieve a speaker&apos;s goal to identify an object in the discourse context (Dale and Reiter, 1995; Passonneau, 1995). While other work suggests that it should be possible for a nominal expression to contribute to the satisfaction of additional This work was partially funded by NSF grant IRI9314961 at the University of Pittsburgh, and a Mellon Predoctoral Fellowship goals (Appelt, 1985; Pollack, 1991; Stone and Webber, 1998), there is no systematic work describing what these goals might be and how speakers can use nominal expressions to achieve them. For example, consider the dialogue contribution in (1) in a context in which the color of the table is not necessary to IDENTIFY the discours</context>
<context position="2773" citStr="Dale and Reiter (1995)" startWordPosition="437" endWordPosition="440">entifying the object under discussion and supporting the MOTIVATION inference. (2) Let&apos;s use my red table. We hypothesized that in addition to the conversational inference of MOTIVATION that a speaker might also attempt to achieve other task-relevant inferences via the generation of nominal expressions. In order to test this hypothesis further, we first specified a number of specific communicative goals that we believe can be addressed by nominal expressions in taskoriented dialogues. We then implemented two models of nominal expression generation. The first model was the INCREMENTAL MODEL of Dale and Reiter (1995), which implements a strategy for satisfying the identification goal. 1-For example, a possible context is one in which the speaker only has one table, and the speaker and hearer are trying for one color in a room, and have already agreed upon other red furniture. The second model we call the intentional influences model; this model of nominal expression generation attempts to simultaneously achieve the identification goal and to cue other task-related inferences with a single nominal expression. We then evaluated these two models using 13 of the dialogues from the COCONUT corpus of task-orien</context>
</contexts>
<marker>Dale, Reiter, 1995</marker>
<rawString>Robert Dale and Ehud Reiter. 1995. Computational interpretations of the Gricean maxims in the generation of referring expressions. Cognitive Science, 19(2):233-263, Apr-June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Pamela W Jordan</author>
<author>Johanna D Moore</author>
<author>Richmond H Thomason</author>
</authors>
<title>An empirical investigation of collaborative dialogues.</title>
<date>1998</date>
<booktitle>In ACL-COLING98, Proceedings of the Thirty-sixth Conference of the Association for Computational Linguistics,</booktitle>
<location>Montreal, Canada,</location>
<marker>Di Eugenio, Jordan, Moore, Thomason, 1998</marker>
<rawString>Barbara Di Eugenio, Pamela W. Jordan, Johanna D. Moore, and Richmond H. Thomason. 1998. An empirical investigation of collaborative dialogues. In ACL-COLING98, Proceedings of the Thirty-sixth Conference of the Association for Computational Linguistics, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Pamela W Jordan</author>
<author>Richmond H Thomason</author>
<author>Johanna D Moore</author>
</authors>
<title>The agreement process: An empirical investigation of human-human computermediated collaborative dialogues. To Appear in</title>
<date>2000</date>
<journal>International Journal of Human-Computer Studies.</journal>
<marker>Di Eugenio, Jordan, Thomason, Moore, 2000</marker>
<rawString>Barbara Di Eugenio, Pamela W. Jordan, Richmond H. Thomason, and Johanna D. Moore. 2000. The agreement process: An empirical investigation of human-human computermediated collaborative dialogues. To Appear in International Journal of Human-Computer Studies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason C Hsu</author>
</authors>
<title>Multiple Comparisons: Theory and Methods.</title>
<date>1996</date>
<publisher>Chapman and Hall,</publisher>
<location>London.</location>
<contexts>
<context position="17955" citStr="Hsu, 1996" startWordPosition="3022" endWordPosition="3023">e of match. A perfect match means that the strategy chose to include or exclude the same attributes as the human did for a particular entity. The measure, X/N, ranges between 0 and 1 inclusive, where X is the number of attribute inclusions and exclusions that agree with the human description and N is the number of attributes that could be expressed for an entity. This response variable is called match in the experiments that follow. After doing an analysis of variance (Mat, 1998) on the results of experiments where we varied the selection strategy, we used multiple pairwise comparisons (MCA) (Hsu, 1996) 6 to locate where significant performance differences between strategies existed.7 We display the results of the multiple comparisons as 95% confidence intervals, (e.g. as in Figure 3), which are always of the form: (estimate)±(critical point) x (standard error of estimate) The critical point in the above calculation depends on the multiple comparison method used (e.g. Tukey, Dunnett, LSD). We chose the method that created the smallest critical point and this is indicated in each figure. 8 6We used S-plus&apos; multicomp function to perform the multiple comparisons (Mat, 1998). 7MCA is a standard </context>
</contexts>
<marker>Hsu, 1996</marker>
<rawString>Jason C. Hsu. 1996. Multiple Comparisons: Theory and Methods. Chapman and Hall, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Johnstone</author>
</authors>
<title>Repetition in discourse: A dialogue.</title>
<date>1994</date>
<booktitle>Repetition in Discourse: Interdisciplinary Perspectives, Volume I, volume XLVII of Advances in Discourse Processes, chapter 1. Ablex.</booktitle>
<editor>In Barbara Johnstone, editor,</editor>
<contexts>
<context position="6697" citStr="Johnstone (1994)" startWordPosition="1099" endWordPosition="1100">escription mine for 150 that his motivation for proposing his rug is its better price. (3) U: i have a blue rug for 250. that would leave us with 50 or any other options you may have for us. 0: ok lets take the blue rug for 250, my rug would not match which is yellow for 150. U: we don&apos;t have to match... 0: well then lets use mine for 150. PERSUASION HYPOTHESIS: Properties that are relevant to getting the hearer to agree with the speaker&apos;s proposed action may be expressed in the context of a goal to propose that action. 21n this respect our hypotheses are similar to those of Walker (1993) and Johnstone (1994), who hypothesized that speakers in task-oriented dialogues would restate information that was already in the common ground for the purpose of cuing particular task-related or conversational inferences. 3A11 of the COCONUT excerpts appear verbatim except that we italicize redescriptions and due to space limitations we omit parts of turns when they are unrelated to the point of the example. We indicate omissions with &lt;...&gt;. Constraint Changes Hypothesis: The second type of task-related inference is motivated by the observation that participants in task-oriented dialogues appear to be able to co</context>
</contexts>
<marker>Johnstone, 1994</marker>
<rawString>Barbara Johnstone. 1994. Repetition in discourse: A dialogue. In Barbara Johnstone, editor, Repetition in Discourse: Interdisciplinary Perspectives, Volume I, volume XLVII of Advances in Discourse Processes, chapter 1. Ablex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
<author>Barbara Di Eugenio</author>
</authors>
<title>Control and initiative in collaborative problem solving dialogues.</title>
<date>1997</date>
<booktitle>In Computational Models for Mixed Initiative Interaction. Papers from the</booktitle>
<tech>Technical Report 55-97-04,</tech>
<pages>81--84</pages>
<publisher>The AAAI Press.</publisher>
<marker>Jordan, Di Eugenio, 1997</marker>
<rawString>Pamela W. Jordan and Barbara Di Eugenio. 1997. Control and initiative in collaborative problem solving dialogues. In Computational Models for Mixed Initiative Interaction. Papers from the 1997 AAAI Spring Symposium. Technical Report 55-97-04, pages 81-84. The AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
</authors>
<title>Influences on attribute selection in redescriptions: A corpus study.</title>
<date>2000</date>
<booktitle>In Proceedings of CogSci2000,</booktitle>
<contexts>
<context position="11724" citStr="Jordan, 2000" startWordPosition="1960" endWordPosition="1961">derstood. VERIFICATION HYPOTHESIS: In the context of a newly introduced entity, all the properties expressed will be repeated by the hearer in his/her next turn. 3 Experimental Approach To verify our hypotheses about what could influence attribute selection, we undertook a two part corpus investigation. First, we did correlational studies on the corpus to get guidance on which of the hypotheses we should examine more closely. Our correlational studies showed that the contexts and attribute selections indicated in our hypotheses positively correlated for all but Verification and Summarization (Jordan, 2000a). In the second part of our investigation, which is the subject of this paper, we analyzed how well computer simulated selections for the COCONUT corpus matched human selections. We reasoned that if our hypotheses were valid then a selection strategy that incorporates them should match the selections made by humans at least as well as an identification-only selection strategy. We anticipated that the degree of match could be similar since there may be many allowable ways to express a description for identification purposes and the selections intended to cue the inferences could intersect som</context>
<context position="13149" citStr="Jordan, 2000" startWordPosition="2193" endWordPosition="2194">included. For example, if my table is identificationally adequate then it might also randomly include any of the remaining mutually known attributes as well (e.g. my red table, my $250 table). We simulated selections for the COCONUT dialogues by using annotations about the discourse entities to be described and the contexts in which they appeared as input to the selection strategies we wished to test. We used existing annotations that were previously developed and tested for the COCONUT project as described in (Di Eugenio et al., 2000) as well as ones developed specifically for this research (Jordan, 2000b).5 One type of annotation feature we used to identify some of the contexts indicated in our hypotheses, were those that defined elements of the agreement process described in (Di Eugenio et al., 2000). First we will present highlevel definitions of these agreement process elements and then we will explain how we used these definitions to identify the contexts. • propose: The speaker offers the item and unconditionally commits to using it and the offer makes the mutual solution state determinate. • partner decidable option: The speaker offers an item and conditionally commits to using it but </context>
</contexts>
<marker>Jordan, 2000</marker>
<rawString>Pamela W. Jordan. 2000a. Influences on attribute selection in redescriptions: A corpus study. In Proceedings of CogSci2000, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
</authors>
<title>Intentional Influences on Object Redescriptions in Dialogue: Evidence from an Empirical Study.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>Intelligent Systems Program, University of Pittsburgh.</institution>
<contexts>
<context position="11724" citStr="Jordan, 2000" startWordPosition="1960" endWordPosition="1961">derstood. VERIFICATION HYPOTHESIS: In the context of a newly introduced entity, all the properties expressed will be repeated by the hearer in his/her next turn. 3 Experimental Approach To verify our hypotheses about what could influence attribute selection, we undertook a two part corpus investigation. First, we did correlational studies on the corpus to get guidance on which of the hypotheses we should examine more closely. Our correlational studies showed that the contexts and attribute selections indicated in our hypotheses positively correlated for all but Verification and Summarization (Jordan, 2000a). In the second part of our investigation, which is the subject of this paper, we analyzed how well computer simulated selections for the COCONUT corpus matched human selections. We reasoned that if our hypotheses were valid then a selection strategy that incorporates them should match the selections made by humans at least as well as an identification-only selection strategy. We anticipated that the degree of match could be similar since there may be many allowable ways to express a description for identification purposes and the selections intended to cue the inferences could intersect som</context>
<context position="13149" citStr="Jordan, 2000" startWordPosition="2193" endWordPosition="2194">included. For example, if my table is identificationally adequate then it might also randomly include any of the remaining mutually known attributes as well (e.g. my red table, my $250 table). We simulated selections for the COCONUT dialogues by using annotations about the discourse entities to be described and the contexts in which they appeared as input to the selection strategies we wished to test. We used existing annotations that were previously developed and tested for the COCONUT project as described in (Di Eugenio et al., 2000) as well as ones developed specifically for this research (Jordan, 2000b).5 One type of annotation feature we used to identify some of the contexts indicated in our hypotheses, were those that defined elements of the agreement process described in (Di Eugenio et al., 2000). First we will present highlevel definitions of these agreement process elements and then we will explain how we used these definitions to identify the contexts. • propose: The speaker offers the item and unconditionally commits to using it and the offer makes the mutual solution state determinate. • partner decidable option: The speaker offers an item and conditionally commits to using it but </context>
</contexts>
<marker>Jordan, 2000</marker>
<rawString>Pamela W. Jordan. 2000b. Intentional Influences on Object Redescriptions in Dialogue: Evidence from an Empirical Study. Ph.D. thesis, Intelligent Systems Program, University of Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: A Framework for the Analysis of Texts.</title>
<date>1987</date>
<tech>Technical Report RS-87-190,</tech>
<institution>USC/Information Sciences Institute.</institution>
<contexts>
<context position="5876" citStr="Mann and Thompson, 1987" startWordPosition="943" endWordPosition="946">d must agree on the final plan for furnishing the house. We hypothesized that many of the taskrelated inferences that the participants must make in this domain to (1) efficiently come to an agreement, and (2) do well on the task, could potentially be cued by the nominal expressions describing the items of furniture used to solve the task.2 Persuasion Hypothesis: The first taskrelated inference that we consider is the MOTIVATION inference exemplified in examples (1) and (2). Previous research suggests that discourse relations such as motivation can influence the content and form of utterances (Mann and Thompson, 1987; McKeown, 1985; Moser and Moore, 1995). It seems plausible that the speaker can cue these same inferences via nominal redescriptions. For example, in (3)3 one can infer from O&apos;s last utterance and the redescription mine for 150 that his motivation for proposing his rug is its better price. (3) U: i have a blue rug for 250. that would leave us with 50 or any other options you may have for us. 0: ok lets take the blue rug for 250, my rug would not match which is yellow for 150. U: we don&apos;t have to match... 0: well then lets use mine for 150. PERSUASION HYPOTHESIS: Properties that are relevant t</context>
</contexts>
<marker>Mann, Thompson, 1987</marker>
<rawString>W.C. Mann and S.A. Thompson. 1987. Rhetorical Structure Theory: A Framework for the Analysis of Texts. Technical Report RS-87-190, USC/Information Sciences Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inc MathSoft</author>
</authors>
<title>S-Plus 5 for Unix Guide to Statistics,</title>
<date>1998</date>
<location>Seattle, Washington,</location>
<marker>MathSoft, 1998</marker>
<rawString>MathSoft, Inc., Seattle, Washington, 1998. S-Plus 5 for Unix Guide to Statistics, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Text Generation. Using Discourse Strategies and Focus Constraints to Generate Natural Language Text.</title>
<date>1985</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5891" citStr="McKeown, 1985" startWordPosition="947" endWordPosition="949"> plan for furnishing the house. We hypothesized that many of the taskrelated inferences that the participants must make in this domain to (1) efficiently come to an agreement, and (2) do well on the task, could potentially be cued by the nominal expressions describing the items of furniture used to solve the task.2 Persuasion Hypothesis: The first taskrelated inference that we consider is the MOTIVATION inference exemplified in examples (1) and (2). Previous research suggests that discourse relations such as motivation can influence the content and form of utterances (Mann and Thompson, 1987; McKeown, 1985; Moser and Moore, 1995). It seems plausible that the speaker can cue these same inferences via nominal redescriptions. For example, in (3)3 one can infer from O&apos;s last utterance and the redescription mine for 150 that his motivation for proposing his rug is its better price. (3) U: i have a blue rug for 250. that would leave us with 50 or any other options you may have for us. 0: ok lets take the blue rug for 250, my rug would not match which is yellow for 150. U: we don&apos;t have to match... 0: well then lets use mine for 150. PERSUASION HYPOTHESIS: Properties that are relevant to getting the h</context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>Kathleen R. McKeown. 1985. Text Generation. Using Discourse Strategies and Focus Constraints to Generate Natural Language Text. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megan Moser</author>
<author>Johanna D Moore</author>
</authors>
<title>Investigating cue placement and selection in tutorial discourse.</title>
<date>1995</date>
<booktitle>In Proceedings of 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>130--135</pages>
<contexts>
<context position="5915" citStr="Moser and Moore, 1995" startWordPosition="950" endWordPosition="953">shing the house. We hypothesized that many of the taskrelated inferences that the participants must make in this domain to (1) efficiently come to an agreement, and (2) do well on the task, could potentially be cued by the nominal expressions describing the items of furniture used to solve the task.2 Persuasion Hypothesis: The first taskrelated inference that we consider is the MOTIVATION inference exemplified in examples (1) and (2). Previous research suggests that discourse relations such as motivation can influence the content and form of utterances (Mann and Thompson, 1987; McKeown, 1985; Moser and Moore, 1995). It seems plausible that the speaker can cue these same inferences via nominal redescriptions. For example, in (3)3 one can infer from O&apos;s last utterance and the redescription mine for 150 that his motivation for proposing his rug is its better price. (3) U: i have a blue rug for 250. that would leave us with 50 or any other options you may have for us. 0: ok lets take the blue rug for 250, my rug would not match which is yellow for 150. U: we don&apos;t have to match... 0: well then lets use mine for 150. PERSUASION HYPOTHESIS: Properties that are relevant to getting the hearer to agree with the </context>
</contexts>
<marker>Moser, Moore, 1995</marker>
<rawString>Megan Moser and Johanna D. Moore. 1995. Investigating cue placement and selection in tutorial discourse. In Proceedings of 33rd Annual Meeting of the Association for Computational Linguistics, pages 130-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca J Passonneau</author>
</authors>
<title>Integrating Gricean and attentional constraints.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI 95.</booktitle>
<contexts>
<context position="1215" citStr="Passonneau, 1995" startWordPosition="185" endWordPosition="186">e the intentional influences model for nominal expression generation that attempts to simultaneously address the identification goal and these additional goals with a single nominal expression. Our evaluation results show that the intentional influences model fits the nominal expressions in the COCONUT corpus as well as previous accounts that focus solely on the identification goal. 1 Introduction Previous work on nominal expression generation has mainly focused on the use of nominal expressions to achieve a speaker&apos;s goal to identify an object in the discourse context (Dale and Reiter, 1995; Passonneau, 1995). While other work suggests that it should be possible for a nominal expression to contribute to the satisfaction of additional This work was partially funded by NSF grant IRI9314961 at the University of Pittsburgh, and a Mellon Predoctoral Fellowship goals (Appelt, 1985; Pollack, 1991; Stone and Webber, 1998), there is no systematic work describing what these goals might be and how speakers can use nominal expressions to achieve them. For example, consider the dialogue contribution in (1) in a context in which the color of the table is not necessary to IDENTIFY the discourse entity under disc</context>
</contexts>
<marker>Passonneau, 1995</marker>
<rawString>Rebecca J. Passonneau. 1995. Integrating Gricean and attentional constraints. In Proceedings of IJCAI 95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha E Pollack</author>
</authors>
<title>Overloading intentions for efficient practical reasoning.</title>
<date>1991</date>
<journal>Nofts,</journal>
<volume>25</volume>
<pages>536</pages>
<contexts>
<context position="1501" citStr="Pollack, 1991" startWordPosition="230" endWordPosition="231">n the COCONUT corpus as well as previous accounts that focus solely on the identification goal. 1 Introduction Previous work on nominal expression generation has mainly focused on the use of nominal expressions to achieve a speaker&apos;s goal to identify an object in the discourse context (Dale and Reiter, 1995; Passonneau, 1995). While other work suggests that it should be possible for a nominal expression to contribute to the satisfaction of additional This work was partially funded by NSF grant IRI9314961 at the University of Pittsburgh, and a Mellon Predoctoral Fellowship goals (Appelt, 1985; Pollack, 1991; Stone and Webber, 1998), there is no systematic work describing what these goals might be and how speakers can use nominal expressions to achieve them. For example, consider the dialogue contribution in (1) in a context in which the color of the table is not necessary to IDENTIFY the discourse entity under discussion, but where the color of the item could be inferred to be MOTIVATION for the proposal.&apos; (I) Let&apos;s use my table. It is red. A plausible hypothesis is that the alternative utterance in (2) could also support the MOTIVATION inference, and that the nominal expression my red table cou</context>
</contexts>
<marker>Pollack, 1991</marker>
<rawString>Martha E. Pollack. 1991. Overloading intentions for efficient practical reasoning. Nofts, 25:513 -536.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stone</author>
<author>Bonnie Webber</author>
</authors>
<title>Textual economy through close coupling of syntax and semantics.</title>
<date>1998</date>
<booktitle>In Proceedings of 1998 International Workshop on Natural Language Generation,</booktitle>
<location>Niagra-on-the-Lake, Canada.</location>
<contexts>
<context position="1526" citStr="Stone and Webber, 1998" startWordPosition="232" endWordPosition="235">orpus as well as previous accounts that focus solely on the identification goal. 1 Introduction Previous work on nominal expression generation has mainly focused on the use of nominal expressions to achieve a speaker&apos;s goal to identify an object in the discourse context (Dale and Reiter, 1995; Passonneau, 1995). While other work suggests that it should be possible for a nominal expression to contribute to the satisfaction of additional This work was partially funded by NSF grant IRI9314961 at the University of Pittsburgh, and a Mellon Predoctoral Fellowship goals (Appelt, 1985; Pollack, 1991; Stone and Webber, 1998), there is no systematic work describing what these goals might be and how speakers can use nominal expressions to achieve them. For example, consider the dialogue contribution in (1) in a context in which the color of the table is not necessary to IDENTIFY the discourse entity under discussion, but where the color of the item could be inferred to be MOTIVATION for the proposal.&apos; (I) Let&apos;s use my table. It is red. A plausible hypothesis is that the alternative utterance in (2) could also support the MOTIVATION inference, and that the nominal expression my red table could thus simultaneously ac</context>
</contexts>
<marker>Stone, Webber, 1998</marker>
<rawString>Matthew Stone and Bonnie Webber. 1998. Textual economy through close coupling of syntax and semantics. In Proceedings of 1998 International Workshop on Natural Language Generation, Niagra-on-the-Lake, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Redundancy in collaborative dialogue.</title>
<date>1992</date>
<booktitle>In Fourteenth International Conference on Computational Linguistics,</booktitle>
<pages>345--351</pages>
<contexts>
<context position="10789" citStr="Walker, 1992" startWordPosition="1813" endWordPosition="1814">the participants had moved on to a new part of the task. (6) G: I got the rug. What do you have in the living room and what are the prices of the items D: the green sofa in the living room 350. dining room &gt; 3 yellow chairs 75 each, 1 high-table yellow, 1 yellow rug SUMMARIZATION HYPOTHESIS: In the context of a previously completed problem or subproblem, all the mutually known properties for an item will be repeated. Verification Hypothesis: The final type of inference we considered is when a speaker repeats an utterance to show that it was understood (Clark and Schaefer, 1989; Brennan, 1990; Walker, 1992; Walker, 1993). In the COCONUT corpus, the hearer sometimes repeats the description in the turn immediately following. For example, in (5) G repeats S&apos;s description of the sofa, although the sofa was introduced by S. We claim that this type of redescription could help verify that the property information was correctly understood. VERIFICATION HYPOTHESIS: In the context of a newly introduced entity, all the properties expressed will be repeated by the hearer in his/her next turn. 3 Experimental Approach To verify our hypotheses about what could influence attribute selection, we undertook a two</context>
</contexts>
<marker>Walker, 1992</marker>
<rawString>Marilyn A. Walker. 1992. Redundancy in collaborative dialogue. In Fourteenth International Conference on Computational Linguistics, pages 345-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Informational Redundancy and Resource Bounds in Dialogue.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<contexts>
<context position="6676" citStr="Walker (1993)" startWordPosition="1096" endWordPosition="1097">erance and the redescription mine for 150 that his motivation for proposing his rug is its better price. (3) U: i have a blue rug for 250. that would leave us with 50 or any other options you may have for us. 0: ok lets take the blue rug for 250, my rug would not match which is yellow for 150. U: we don&apos;t have to match... 0: well then lets use mine for 150. PERSUASION HYPOTHESIS: Properties that are relevant to getting the hearer to agree with the speaker&apos;s proposed action may be expressed in the context of a goal to propose that action. 21n this respect our hypotheses are similar to those of Walker (1993) and Johnstone (1994), who hypothesized that speakers in task-oriented dialogues would restate information that was already in the common ground for the purpose of cuing particular task-related or conversational inferences. 3A11 of the COCONUT excerpts appear verbatim except that we italicize redescriptions and due to space limitations we omit parts of turns when they are unrelated to the point of the example. We indicate omissions with &lt;...&gt;. Constraint Changes Hypothesis: The second type of task-related inference is motivated by the observation that participants in task-oriented dialogues ap</context>
<context position="8267" citStr="Walker, 1993" startWordPosition="1353" endWordPosition="1354"> goal without explicit discussion.4 Our hypothesis is that this inference can also be cued by the content of a nominal expression when that expression realizes properties of a domain object that are not needed to identify which object is under discussion. For example, in (4) A specifies both the color and price for both the sofa and the lamp even though the price attributes alone would adequately identify each item. By specifying the color, one can easily infer that the color match constraint has been dropped in the proposal. A has eliminated having to explicitly communicate this information (Walker, 1993) and reduced the risk of the hearer missing the inference (Carletta, 1992). (4) S: &lt;...&gt; if we do that i have 400 blue sofa and a 350 yellow sofa, and i have a 250 blue floor lamp or a 150 yellow rug. &lt;...&gt; A: &lt;...&gt; so now we have 600 left for the living room. if we get your 350 yellow sofa and your 250 blue floor lamp, that sounds good to me because I don&apos;t have anything better in my inventory. DOMAIN CONSTRAINT CHANGES HYPOTHESIS: Properties related to constraint changes are expressed in a context where the change is to be inferred by the hearer. Commitment Hypothesis: The next two types of </context>
<context position="10804" citStr="Walker, 1993" startWordPosition="1815" endWordPosition="1816">ts had moved on to a new part of the task. (6) G: I got the rug. What do you have in the living room and what are the prices of the items D: the green sofa in the living room 350. dining room &gt; 3 yellow chairs 75 each, 1 high-table yellow, 1 yellow rug SUMMARIZATION HYPOTHESIS: In the context of a previously completed problem or subproblem, all the mutually known properties for an item will be repeated. Verification Hypothesis: The final type of inference we considered is when a speaker repeats an utterance to show that it was understood (Clark and Schaefer, 1989; Brennan, 1990; Walker, 1992; Walker, 1993). In the COCONUT corpus, the hearer sometimes repeats the description in the turn immediately following. For example, in (5) G repeats S&apos;s description of the sofa, although the sofa was introduced by S. We claim that this type of redescription could help verify that the property information was correctly understood. VERIFICATION HYPOTHESIS: In the context of a newly introduced entity, all the properties expressed will be repeated by the hearer in his/her next turn. 3 Experimental Approach To verify our hypotheses about what could influence attribute selection, we undertook a two part corpus in</context>
</contexts>
<marker>Walker, 1993</marker>
<rawString>Marilyn A. Walker. 1993. Informational Redundancy and Resource Bounds in Dialogue. Ph.D. thesis, University of Pennsylvania, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Whittaker</author>
<author>Phil Stenton</author>
</authors>
<title>Cues and control in expert client dialogues.</title>
<date>1988</date>
<booktitle>In Proc. 26th Annual Meeting of the ACL, Association of Computational Linguistics,</booktitle>
<pages>123--130</pages>
<contexts>
<context position="9127" citStr="Whittaker and Stenton, 1988" startWordPosition="1511" endWordPosition="1515">0 left for the living room. if we get your 350 yellow sofa and your 250 blue floor lamp, that sounds good to me because I don&apos;t have anything better in my inventory. DOMAIN CONSTRAINT CHANGES HYPOTHESIS: Properties related to constraint changes are expressed in a context where the change is to be inferred by the hearer. Commitment Hypothesis: The next two types of inference are based on the idea that if a speaker repeats an utterance and provides no new information, this can show that 4In (3) there is some explicit discussion about the color match goal. a stage of the interaction is complete (Whittaker and Stenton, 1988; Jordan and Di Eugenio, 1997). Repeating properties for a recently evoked item could show that the current stage has just been completed while doing so for an older item could indicate that a higher level subproblem has been completed. In (5), S&apos;s second utterance appears to end a stage in the interaction, in this case the end of the agreement process for a select sofa action (Di Eugenio et al., 2000). (5) S: &lt;...&gt; I have a $300 yellow sofa &lt;...&gt; G: My sofa&apos;s are more expensive so buy your $300 yellow sofa. Also &lt;...&gt; S: &lt;...&gt; / will go ahead and buy the $300 yellow sofa. COMMITMENT HYPOTHESI</context>
</contexts>
<marker>Whittaker, Stenton, 1988</marker>
<rawString>Steve Whittaker and Phil Stenton. 1988. Cues and control in expert client dialogues. In Proc. 26th Annual Meeting of the ACL, Association of Computational Linguistics, pages 123-130.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>