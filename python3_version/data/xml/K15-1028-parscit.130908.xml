<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.986228">
Temporal Information Extraction from Korean Texts
</title>
<author confidence="0.998272">
Young-Seob Jeong, Zae Myung Kim, Hyun-Woo Do, Chae-Gyun Lim, and Ho-Jin Choi
</author>
<affiliation confidence="0.9983765">
School of Computing
Korea Advanced Institute of Science and Technology
</affiliation>
<address confidence="0.979747">
291 Daehak-ro, Yuseong-gu, Daejeon 305-701, South Korea
</address>
<email confidence="0.998906">
{pinode,zaemyung,realstorm103,rayote,hojinc}@kaist.ac.kr
</email>
<sectionHeader confidence="0.997385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999974066666667">
As documents tend to contain temporal
information, extracting such information
is attracting much research interests re-
cently. In this paper, we propose a hybrid
method that combines machine-learning
models and hand-crafted rules for the task
of extracting temporal information from
unstructured Korean texts. We address
Korean-specific research issues and pro-
pose a new probabilistic model to generate
complementary features. The performance
of our approach is demonstrated by exper-
iments on the TempEval-2 dataset, and the
Korean TimeBank dataset which we built
for this study.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975634615385">
Due to the increasing number of unstructured
documents available on the Web and from other
sources, developing techniques that automatically
extract knowledge from the documents has been
of paramount importance. Among many aspects
of extracting knowledge from documents, the ex-
traction of temporal information is recently draw-
ing much attention, since the documents usually
incorporate temporal information that is useful
for further applications such as Information Re-
trieval (IR) and Question Answering (QA) sys-
tems. Given a simple question, “who was the pres-
ident of the U.S. 8 years ago?”, for example, a
QA system may have a difficulty in finding the
right answer without the correct temporal informa-
tion about when the question is posed and what ‘8
years ago’ refers to.
There have been many studies for temporal in-
formation extraction, but most of them are appli-
cable only to their target languages. The main rea-
son for this limitation is that some parts of tem-
poral information are difficult to predict without
the use of language-specific processing. For ex-
ample, the normalized value ‘1983-03-08’ can be
represented by ‘March 8, 1983’ in English, while
it can be represented by ‘1983A¢� 8 in Ko-
rean. The order of date representation in Korean is
usually different from that of English, and the digit
expression in Korean is more complex than that of
English. This implies that it is necessary to inves-
tigate language-specific difficulties for developing
a method to extract temporal information.
In this paper, we propose a method for tem-
poral information extraction from Korean texts.
The contributions of this paper are as follows:
we (1) show how the Korean-specific issues (e.g.,
morpheme-level tagging, various ways of digit ex-
pression, uses of lunar calendar, and so on) are ad-
dressed, (2) propose a hybrid method that com-
bines a set of hand-crafted rules and machine-
learning models, (3) propose a data-driven proba-
bilistic model to generate complementary features,
and (4) create a new dataset, the Korean Time-
Bank, that consists of more than 3,700 manually
annotated sentences.
The rest of the paper is organized as follows.
Section 2 describes the background of the re-
search. Section 3 presents the details of the pro-
posed method, the Korean TimeBank dataset, and
how we apply the probabilistic model for generat-
ing features. Section 4 shows experimental results,
and Section 5 concludes the paper.
</bodyText>
<sectionHeader confidence="0.995967" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.991856444444444">
TempEval is a series of shared tasks for temporal
information extraction (Verhagen et al., 2009; Ver-
hagen et al., 2010; UzZaman et al., 2013). There
have been many studies related to the shared tasks
(Chambers et al., 2007; Yoshikawa et al., 2009;
UzZaman and Allen, 2010; Ling and Weld, 2010;
Mirroshandel and Ghassem-Sani, 2012; Bethard,
2013b), which are based on the Time Mark-up
Language (TimeML) (Pustejovsky et al., 2003).
</bodyText>
<page confidence="0.976425">
279
</page>
<note confidence="0.9799695">
Proceedings of the 19th Conference on Computational Language Learning, pages 279–288,
Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.99893490425532">
The shared tasks can be summarized into three ex-
traction tasks: (1) extraction of timex3 tags, (2) ex-
traction of event and makeinstance tags, and (3)
extraction of tlink tags. The timex3 tag is asso-
ciated with expressions of temporal information
such as ‘May 1973’ and ‘today’. The event tag
and makeinstance tag represent some eventual ex-
pressions which can be related to temporal infor-
mation. The makeinstance tag is an instance of
the event tag. For example, the sentence, “I go
to school on Mondays and Tuesdays”, contains
one event tag on ‘go’ and two makeinstance tags
as the action ‘go’ occurs twice on Mondays and
Tuesdays. The tlink tag represents a linkage be-
tween two tags. The tlink can be a linkage between
two timex3 tags (TT tlink), two makeinstance tags
(MM tlink), a timex3 tag and a makeinstance tag
(TM tlink), or Document Creation Time and a
makeinstance tag (DM tlink). Note that the tlink
takes makeinstance tags as arguments, but not the
event tags, as the event tags are merely templates
for them. For the above sentence, there will be two
TM tlinks: go-Tuesdays and go-Mondays. The TT
tlink is assumed to be easy to extract, so TempEval
does not incorporate the TT tlink into the task of
extracting tlink tags.
Among many related studies, there are sev-
eral leading ones. HeidelTime is proposed for
extraction of timex3 tags (Strotgen and Gertz,
2010). It strongly depends on hand-crafted rules,
and showed the best performance in TempEval-
2. Llorens et al. (2010) proposed TIPSem for
all of the three extraction tasks. It employs Con-
ditional Random Fields (CRF) (Lafferty et al.,
2001) for capturing patterns of texts, and defines
a set of hand-crafted rules for determining sev-
eral attributes of the tags. ClearTK is another work
proposed for all three extraction tasks (Bethard,
2013a); it utilizes machine-learning models such
as Support Vector Machines (SVM) (Boser et al.,
1992; Cortes and Vapnik, 1995) and Logistic Re-
gressions (LR), and shows the best performance in
TempEval-3.
Although the existing approaches show good re-
sults, most of them are applicable only to their
target languages. The first reason is that there
are several attributes which are difficult to pre-
dict without the use of language-specific process-
ing. For instance, the attribute value of timex3
tag has a normalized form of time (e.g., 1999-
04-12) following ISO-8601. This is not accurately
predictable by relying solely on data-driven ap-
proaches. The second reason is that they depend
on some language-specific resources (e.g., Word-
Net) or tools. Unless the same quality of resources
or tools is achieved for other languages, the exist-
ing works would not be available to the other lan-
guages. To alleviate this limitation, a language in-
dependent parser for extracting timex3 tags is pro-
posed (Angeli and Uszkoreit, 2013). Its portability
is demonstrated by experiments with TempEval-
2 dataset of six languages: English, Spanish, Ital-
ian, Chinese, Korean, and French. However, the
performance in English and Spanish datasets are
about twice as high as the other languages, since
the method highly depends on the feature defi-
nition and language-specific preprocessing (e.g.,
morphological analysis). This implies that it is
necessary to address language-specific difficulties
in order to achieve high performance.
Korean language has many subtle rules and ex-
ceptions on word spacing. Korean is an aggluti-
native language, where verbs are formed by at-
taching various endings to the stem. There are
usually multiple morphemes for each token, and
empty elements appear very often because sub-
jects and objects are dropped to avoid duplication.
Temporal expressions often take the lunar calendar
representation as a tradition. Moreover, the same
temporal information can have various forms due
to a complex system of digit expression. For in-
stance, a digit 30 can be represented as ‘30’, ‘��
[sam-sib]’, or ‘A]K[seo-run]’. Most of these is-
sues stem from the Chinese language, as a large
number of Chinese words and letters have become
an integral part of Korean vocabulary due to his-
torical contact. All these issues hinder the perfor-
mance of the existing approaches when applied to
Korean documents.
In this paper, we show how these issues are ad-
dressed in our Korean-specific hybrid method. To
the best of our knowledge, this is the first Korean-
specific study which addresses all of the three ex-
traction tasks.
</bodyText>
<sectionHeader confidence="0.991571" genericHeader="method">
3 Proposed Method
</sectionHeader>
<subsectionHeader confidence="0.997461">
3.1 Korean TimeBank
</subsectionHeader>
<bodyText confidence="0.9995884">
Although there is a Korean dataset provided by
TempEval-2, we chose not to use it because it is
small in size and has many annotation errors. In
TempEval-2 Korean dataset, there are missing val-
ues of timex3 tags, and multiple tags that must be
</bodyText>
<page confidence="0.997319">
280
</page>
<figureCaption confidence="0.9131275">
Figure 1: Example of extent representation by to-
ken indices and letter indices.
</figureCaption>
<bodyText confidence="0.998833863636364">
merged into one. Please refer to the examples in
the 11th sentence of the 2nd training document
of the TempEval-2 Korean dataset. Thus, we con-
structed a new dataset called Korean TimeBank.
The new dataset is based on TimeML but with
several differences. The tags of the new dataset
are represented using a stand-off scheme, keep-
ing the original sentences unharmed. As there are
often multiple morphemes within each token in
Korean, the tags are annotated in letter-level. The
letter-level annotation allows multiple annotations
to appear within a single token. This also makes
the dataset independent of morphological analy-
sis, so it is not required to update the dataset when
the morphological analyzer is updated. To enable
the letter-level annotation, we introduce several at-
tributes for timex3 tag and event tag: text, begin,
end, e begin, and e end. The attributes e begin and
e end indicate token indices, while begin and end
indicate letter indices of the extent. The attribute
text contains the string of the extent. For example,
the sentence, “I work today” in Fig. 1, contains one
timex3 tag whose text is ‘today’, where e begin=2,
e end=2, begin=0, and end=4.
Since temporal expressions following the lunar
calendar representation appear often in Korean,
we add an attribute calendar. The value of the cal-
endar can be LUNAR or other types of calendar,
and its default value is GREGORIAN when it is
not explicitly clarified. We also add two values for
the attribute mod of timex3 tag: START OR MID
and MID OR END, as these expressions appear
often in Korean. For example, ‘_ILW&amp;quot;L-[cho-joong-
ban]’ represents beginning or middle phase of a
period, and ‘W��[joong-hoo-ban]’ represents
middle or ending phase of a period.
The source of the Korean TimeBank includes
Wikipedia documents and hundreds of manually
generated question-answer pairs. The domains of
the Wikipedia documents are personage, music,
university, and history. The documents are anno-
tated by two trained annotators and a supervisor,
all majoring in computer science. The annotated
tags of each document is saved in an XML file.
</bodyText>
<figureCaption confidence="0.9741025">
Figure 2: Overall process of temporal information
extraction from Korean texts.
</figureCaption>
<subsectionHeader confidence="0.9601905">
3.2 Temporal Information Extraction from
Korean Texts
</subsectionHeader>
<bodyText confidence="0.997049125">
Our proposed method addresses all of the three
tasks: (1) extraction of timex3 tags, (2) extraction
of event and makeinstance tags, and (3) extraction
of tlink tags. The proposed method also extracts
additional attributes of timex3 tag, such as freq, be-
ginPoint, endPoint, mod, and calendar. The over-
all process is depicted in Fig. 2, where the solid
line represents training process and the dotted line
represents testing process. The Korean analyzer
at the center of the figure takes Korean texts as
an input and generates several raw features as an
output, such as results of morphological analysis,
Part-Of-Speech (POS) tags, Named-Entity (NE)
tags, and results of dependency parsing (Lim et
al., 2006). The number of possible POS tags is
45, which follows the definition of Sejong Tree-
bank1. The number of possible NE tags is 178,
where each of them belongs to one of 15 super NE
tags.
The generated raw features are used to define a
set of features for machine-learning models and a
set of hand-crafted rules. The rules are designed by
examining the training dataset and the errors that
the proposed method generates with the valida-
tion dataset. We employ several machine-learning
methods that have shown the best performance
in the TempEval shared tasks, such as Maximum
Entropy Model (MEM), Support Vector Machine
(SVM), Conditional Random Fields (CRF), and
Logistic Regression (LR).
Fig. 2 introduces Temporal Information Extrac-
tor (TIE) which consists of four sub-extractors:
</bodyText>
<footnote confidence="0.914211">
1Korean Language Institute, http://www.sejong.or.kr
</footnote>
<page confidence="0.996534">
281
</page>
<bodyText confidence="0.999964052631579">
timex3 extractor, event extractor, makeinstance ex-
tractor, and tlink extractor. The timex3 extrac-
tor and the event extractor work independently,
and the makeinstance extractor uses the predicted
event tags. The tlink extractor makes use of the
predicted makeinstance tags and predicted timex3
tags. Thus, the performance of timex3 extractor
and event extractor will strongly influence the per-
formance of makeinstance extractor and tlink ex-
tractor. These four sub-extractors as a whole give
predicted tags as an output, where the tags are rep-
resented in morpheme-level. The extent converter
at the center of the figure changes the morpheme-
level tags into letter-level and vice versa by check-
ing ASCII values of each letter and each mor-
pheme. In training process, the annotated tags of
Korean TimeBank are converted into morpheme-
level through the extent converter, and used to train
the TIE.
</bodyText>
<subsubsectionHeader confidence="0.452707">
3.2.1 Timex3 extractor
</subsubsectionHeader>
<bodyText confidence="0.999775064516129">
The goal of timex3 extractor is to predict whether
each morpheme belongs to the extent of a timex3
tag or not, and finds appropriate attributes of the
tag. There are five types of timex3 tag: DATE,
TIME, DURATION, SET, and NONE. The NONE
represents that the corresponding morpheme does
not belong to the extent of a timex3 tag, and
the other four types follow the same definition
of TimeML. This is essentially a morpheme-level
classification over 5 classes.
We basically take two approaches: a set of 100
hand-crafted rules and machine-learning models.
Examples of the rules for extent and type are listed
in Table 1. In the second rule of the table, the first
condition is satisfied when the sequence of two
morphemes is a digit followed by a morpheme ‘�
[wol]’(month), ‘°j[il]’(day), or ‘Uoo]’(week).
The various ways of digit expressions are also con-
sidered. The second condition is satisfied when the
morpheme next to the extent is ‘bll[eh]’(at) or ‘u}
r+[ma-da]’(every) followed by ‘121[beon]’(times)
or ‘A[hoi]’(times), and there must be no other
tags between the two morphemes. If these two
conditions are satisfied, then the sequence of mor-
phemes becomes the extent of timex3 tag whose
type is SET. If one of the rules is satisfied, then
the remaining rules are skipped for the target mor-
pheme.
We compare two machine-learning models,
CRF and MEM, for timex3 tag by experiments. We
defined a set of features based on the raw features
</bodyText>
<tableCaption confidence="0.974266">
Table 1: Examples of the rules for extent and type
</tableCaption>
<table confidence="0.925877833333333">
of timex3 tags.
Type Conditions
DATE Extent=(digit, )
SET Extent=(digit,-W∨°j∨T),
Next morps=
(oil∨u}r+,no other tags,121∨A)
</table>
<tableCaption confidence="0.8857">
Table 2: Examples of the rules for value of timex3
tag.
</tableCaption>
<figure confidence="0.980717222222222">
Operations Conditions
Month=digit Context updated
Type=DATE∨TIME
Surrounding morps=
c
(digit,-)
Year=context Type=DATE∨TIME
Surrounding morps=
(��∨�121�)
</figure>
<bodyText confidence="0.999762766666667">
obtained from the Korean analyzer. The defined
features include morphemes, POS tags, NE tags,
morpheme-level features of dependency parsing,
given a particular window size. The morpheme-
level features of dependency parsing are generated
by following approaches in Sang and Buchholz
(2000).
To predict other attributes of each predicted
timex3 tag, we also define sets of rules: 112 rules
for value, 7 rules for beginPoint/endPoint, 9 rules
for freq, 10 rules for mod, and 1 rule for calen-
dar. Especially, the rules for value and freq take
a temporal context into account. For instance, the
sentence “We go there tomorrow”, makes it hard
to predict value of ‘tomorrow’ without considering
the temporal context. We assume that the temporal
context of each sentence depends on the previous
sentence. For each document, the temporal con-
text is initialized with Document Creation Time
(DCT), and the context is updated when a normal-
ized value appears in a certain condition.
Examples of the rules are described in Table 2.
If the first rule in the table is satisfied, then the
month of value is changed to the corresponding
digit and the temporal context is updated.
As there can be multiple clues for determining
value within an extent, all of the rules are checked
for each timex3 tag. To avoid overwriting value by
multiple satisfied rules, the rules are listed in as-
cending order of temporal unit. That is, the rules
</bodyText>
<page confidence="0.983885">
282
</page>
<bodyText confidence="0.999825625">
for seconds or minutes are listed before the rules
for hours or days. This allows value to be changed
from smaller temporal unit to bigger unit, thereby
avoiding overwriting wrong value. The rules for
different attributes are listed in separate files, and
are written in a systematic way similar to regular
expressions. Such format enables rules to be easily
manipulated.
</bodyText>
<subsectionHeader confidence="0.690642">
3.2.2 Event extractor
</subsectionHeader>
<bodyText confidence="0.999916454545455">
The goal of event extractor is to predict whether
each morpheme belongs to the extent of an event
tag or not, and finds appropriate class of the tag.
There are 7 classes of event tag: OCCURRENCE,
PERCEPTION, REPORTING, STATE, I STATE,
I ACTION, and NONE. The NONE represents
that the corresponding morpheme does not be-
long to the extent, and the other classes follow
the same definition of TimeML. Similar to the
timex3 extractor, we take two approaches: a set of
26 rules and machine-learning models (e.g., CRF
and MEM), based on the set of features used in the
timex3 extractor.
There are several verbs that often appear within
the extents of event tags, although they do not
carry any meaning. For example, in the sen-
tence, “�� o-&apos;�r� a}�”(I study), the verb ‘a}
[ha]’(do) has no meaning while the noun ‘��
[gong-bu]’(study) has eventual meaning. We de-
fine a set of such verbal morphemes (e.g., ‘41
a}[wi-ha]’(for), and ‘tea}[tong-ha]’(through)), to
avoid generating meaningless event tags.
</bodyText>
<subsectionHeader confidence="0.822987">
3.2.3 Makeinstance extractor
</subsectionHeader>
<bodyText confidence="0.9999902">
The goal of makeinstance extractor is to generate
at least one makeinstance tag for each event tag,
and find appropriate attributes. As we observed
that there is only one makeinstance tag for each
event tag in most cases, the makeinstance extractor
simply generates one makeinstance tag for each
event tag. For the attribute POS, we simply take
the POS tags obtained from the Korean analyzer.
We define a set of 5 rules for the attribute tense,
and 2 rules for the attribute polarity.
</bodyText>
<subsectionHeader confidence="0.684913">
3.2.4 Tlink extractor
</subsectionHeader>
<bodyText confidence="0.994735166666667">
The goal of tlink extractor is to make a linkage be-
tween two tags, and find appropriate types of the
links. For each pair of tags, it determines whether
there must be a linkage between them, and finds
the most appropriate relType. There are 11 rel-
Types: BEFORE, AFTER, INCLUDES, DUR-
</bodyText>
<tableCaption confidence="0.994202">
Table 3: Features in the two kinds of classifiers.
</tableCaption>
<table confidence="0.98044985">
Features for TM tlink
Surrounding morphemes of the argument tags
Linear order of the argument tags
Attribute type of timex3 tag
Attribute class of event tag
Attribute polarity of makeinstance tag
Attribute tense of makeinstance tag
Whether tlink tag is non-consuming tag or not
Does timex3 tag exist between argument tags?
Does event tag exist between argument tags?
Is event tag an objective of other event tag
in dependency tree?
Features for MM tlink
Surrounding morphemes of event tags
Linear order of event tags
Attribute class of event tags
Attribute polarity of makeinstance tags
Attribute tense of makeinstance tags
Does timex3 tag exist between event tags?
Does event tag exist between event tags?
</table>
<bodyText confidence="0.996437857142857">
ING, DURING INV, SIMULTANEOUS, IDEN-
TITY, BEGINS, ENDS, OVERLAP, and NONE.
The NONE represents that there is no linkage be-
tween the two argument tags, and the OVERLAP
means that the temporal intervals of two tags are
overlapping. The other relTypes follow the same
definition of TimeML. Thus, it is essentially a
classification over 11 classes for each pair of two
argument tags.
The tlink extractor generates intra-sentence
tlinks and inter-sentence tlinks. For the intra-
sentence tlinks, we take two approaches: a set of
19 rules and machine-learning models (e.g., SVM
and LR). Among the four kinds of tlinks (e.g.,
TT tlink, TM tlink, MM tlink, and DM tlink), our
tlink extractor generates the first three kinds of
tlinks. The reason for excluding DM tlink is that
we maintain the temporal context initialized with
DCT in the timex3 extractor, so it is not necessary
to generate DM tlinks. The TT tlinks are extracted
by comparing normalized values of two timex3
tags. Two models are independently trained for
predicting TM tlinks and MM tlinks, respectively.
We tried many possible combinations of features
to reach better performance, and obtained sets of
features as described in Table 3.
Given a pair of two makeinstance tags, it is
straight forward to derive relType when the two
</bodyText>
<page confidence="0.991694">
283
</page>
<bodyText confidence="0.926410375">
event tags are linked with timex3 tags. Thus, firstly
we predict TT tlinks, and thereafter predict TM
tlinks and MM tlinks. For the inter-sentence tlinks,
we generate MM tlinks between adjacent sen-
tences when there is a particular expression at
the beginning of a sentence, such as ‘a T[geu-
hoo]’(afterward), ‘a ;�A[geu-jeon]’(beforehand),
or ‘a �&amp;[geu-da-eum]’(thereafter).
</bodyText>
<subsectionHeader confidence="0.955046">
3.3 Online LIFE
</subsectionHeader>
<bodyText confidence="0.999918268292683">
As the performance of the Korean analyzer is not
stable, we need complementary features to make
better classifiers. Jeong and Choi (2015) proposed
Language Independent Feature Extractor (LIFE)
which generates a pair of class label and topic la-
bel for each Letter-Sequence (LS), where LS rep-
resents frequently appeared letter sequence. The
class labels can be used as syntactic features, while
the topic labels can be used as semantic features.
The concept of LS makes it language indepen-
dent, so it is basically applicable to any language.
This is especially helpful to some languages that
have no stable feature extractors. Korean is one of
such languages, so we employ the LIFE to gener-
ate complementary features.
The temporal information extractor must work
online because it usually takes a stream of docu-
ments as an input. However, as the LIFE is origi-
nally designed to work offline, we propose an ex-
tended version of the LIFE, namely, Online LIFE
(O-LIFE), whose parameters are estimated incre-
mentally. When we design O-LIFE, the LS con-
cept of LIFE becomes a problem because the LS
dictionary changes. For example, if the LS dictio-
nary has only one LS goes and a new token go
comes in, then the LS dictionary may contain go
and es. Note that the LS goes does not exist in
the new dictionary. This issue is addressed by our
proposed algorithm which basically distributes the
values of previously estimated parameters to new
prior parameters of overlapping LSs. For the above
example, φk,‘goes0 will be distributed to βk,‘go0 and
βk,‘es0, where k is a topic index.
The formal algorithm of O-LIFE is shown in Al-
gorithm 1, where C is the number of classes and T
is the number of topics. Sstream is the number of
streams, and Ss is s-th stream of Ds documents.
The four parameters a, bt, g and bc are default val-
ues of the priors α, β, γ and δ. The three threshold
parameters t1, t2, and t3 are used to generate LS
dictionary.
</bodyText>
<figure confidence="0.923563848484848">
Algorithm 1 Online LIFE
23: end for
24: end for
25: end if
28: initilize
and
to zeros
29: initilize class/topic assignments
B
=
1U
D
t
,
αsd=a,1≤d≤Ds
γsc=g,1≤c≤C
φs,ηs,πs,
θs
[φs,ηs,πs,θs]=
ParameterEstimation(Ss,αs,βs,γs,δs)
st
Bs−
φts
s
s−1c,1≤c≤C
1≤t≤T
34: end for
The LS dictionary of O-LIFE is updated as it
reads data. That is,
an
|Dicprev|≤|Diccur|
d
is the pre-
</figure>
<figureCaption confidence="0.222321">
vious dictionary and
</figureCaption>
<bodyText confidence="0.94411575">
is the current dictio-
nary. To handle this change in dictionary, the two
parameters (e.g.,
are updated by four steps,
based on an assumption that every unique LS wi
of the previous dictionary should contribute to the
new dictionary as much as possible. Firstly, as de-
scribed in 8th line of the algorithm, the two pa-
rameters are initialized with default values. Sec-
ondly, if a particular LS wi of the previous dic-
tioanry exists in the new dictionary, then the two
parameters increase by
</bodyText>
<page confidence="0.155376">
an
</page>
<figure confidence="0.884641275">
Dicprev⊆6Diccur,whereDicprev
Diccur
β,δ)
Bs−1
t,wiwp
d Ds−1
c,wiwp, re-
1: INPUT: a;bt;g;bc;wp;Ss;t1;t2;t3
2: for s=1 to Sstream do
3: Dics = DictionaryGenerator(t1,t2,t3)
4: if s=1 then
5: βst =bt, 1≤t≤T
6: δsc=bc, 1≤c≤C
7: else
8: βst,w=bt, w ∈ Dics
9: δsc,w=bc, w ∈ Dics
10: for each item wi ∈ Dics−1 do
11: if wi ∈ Dics then
12: βs t,wi+=Bs−1
t,wiwp, 1≤t≤T
13: δs c,wi+=Ds−1
c,wiwp, 1≤c≤C
14: end if
15: for each w0i ∈ Dics do
16: βs i+=Bs−1
t,wiwp, 1≤t≤T
t,w0 17: δs i+=Ds−1
c,wiwp, 1≤c≤C
c,w0
18: end for
19: for each w00
i ∈ Dics do
20: r=|woverlap|/|wi|
21: βs i +=Bs−1
t,wirwp, 1≤t≤T
t,w00
δs
i +=Ds−1
c,wirwp, 1≤c≤C
c,w00
</figure>
<page confidence="0.996215">
284
</page>
<tableCaption confidence="0.775225333333333">
Table 4: The statistics of Korean TimeBank, where
the digits represent the number of corresponding
items.
</tableCaption>
<table confidence="0.919354625">
Training Validation Test
documents 536 131 173
sentences 2357 466 879
timex3 1245 253 494
event 6594 1145 2609
makeinstance 6615 1155 2613
tlink 1295 374 674
spectively. Bs−1
</table>
<bodyText confidence="0.965059521739131">
t denotes an evolutionary matrix
whose columns are LS-topic distribution Os−1
t ,
and Ds−1
c means an evolutionary matrix whose
columns are LS-class distribution ηs−1
t . By multi-
plying them with the weight vector wp, the contri-
bution in initializing priors is determined for each
time slice. We call this value, the weighted con-
tribution. Thirdly, for every w0 i which contains wi,
the two parameters increase by the weighted con-
tribution. Lastly, for every w00
i which overlaps with
wi, the two parameters increase by r times of the
weighted contribution, where woverlap is the over-
lapping part.
The class labels and topic labels are converted
to morpheme-level features by concatenating la-
bels of LSs overlapping with a given morpheme.
We call these features as LIFE features, and these
are used to train machine-learning models, to-
gether with the features based on the raw features.
</bodyText>
<sectionHeader confidence="0.99956" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999956333333333">
The Korean TimeBank is divided into a training
dataset, a validation dataset, and a test dataset. The
statistics of the dataset are described in Table 4. As
shown in the table, only one makeinstance tag ex-
ists for each event tag in most cases, which follows
the assumption of makeinstance extractor.
</bodyText>
<subsectionHeader confidence="0.994313">
4.1 Timex3 prediction
</subsectionHeader>
<bodyText confidence="0.997220714285714">
For the extent and type prediction, only the exactly
predicted extents and types are regarded as correct,
and the results are summarized in Table 5, where
MEM is trained only with the features generated
from raw features, and MEML is trained with both
of the features and LIFE features. We employ the
CRF++ library2 and MEM toolkit3. The optimal
</bodyText>
<footnote confidence="0.9998485">
2http://crfpp.googlecode.com/svn/trunk/doc/index.html
3http://homepages.inf.ed.ac.uk/lzhang10/maxent toolkit
</footnote>
<bodyText confidence="0.999961274509804">
parameter settings are found by a grid search with
the validation set. The optimal setting for CRF is
as follows: L1-regularization, c=0.6, and f=1. The
MEM shows its best performance without Gaus-
sian prior smoothing. Both models give generally
better performance when window size is 2. The
parameter setting for O-LIFE is as follows: a=0.1,
bt=0.1, g=0.1, bc=0.1, wp=(1), C=10, T=10,
t1=0.4, t2=0.4, t3=0.7, and the number of iter-
ations for estimation is 1000.
As shown in the table, CRF gives generally bet-
ter performance than MEM and rules. We tried
a combination of the rules and machine-learning
models, and the combination led to an increase in
the performance. For example, the combination of
CRF and rules gives better performance than us-
ing only CRF. This can be explained that there
are some patterns that the machine-learning mod-
els could not capture, so the combination with the
rules can deal with the patterns. Note that using the
LIFE features dramatically increases the perfor-
mance. We believe that this is due to the raw fea-
tures of Korean (e.g., POS tagger) being unstable.
The LIFE features complement these unstable fea-
tures by capturing syntactic/semantic patterns that
are inherent in the given documents. Furthermore,
we observed that the combination of the rules
and machine-learning models trained with LIFE
features does not contribute to the performance.
This implies that using LIFE features allows the
machine-learning models to capture the patterns
that could not be captured by the machine-learning
models without LIFE features. The CRFL is dis-
covered to be the best, and the other remaining at-
tributes are predicted using the rules. The perfor-
mance is measured in a sequential manner, so the
performance generally decreases from the top to
bottom of the table.
Another experiments of timex3 prediction us-
ing TempEval-2 Korean dataset are conducted to
compare with the existing method of Angeli and
Uszkoreit (2013). The existing method makes use
of a latent parse conveying a language-flexible
representation of time, and extract features over
both the parse and associated temporal semantics.
The results of comparison are shown in Table 6,
where our method uses CRFL for type and rules
for value. For a fair comparison, both methods are
trained and tested using only TempEval-2 Korean
dataset. As mentioned before, TempEval-2 Korean
dataset contained errors, so we corrected them and
</bodyText>
<page confidence="0.999067">
285
</page>
<tableCaption confidence="0.81949725">
Table 5: Timex3 prediction results, where P repre-
sents precision, R means recall, F represents F1
score, points represent beginPoint/endPoint, and
cal represents calendar.
</tableCaption>
<table confidence="0.9999145">
Attri- Performances
butes
Comb P R F
Rules 74.79 70.95 72.82
MEM 31.79 25.1 28.05
extent CRF 80.34 65.42 72.11
MEM,Rules 70.61 70.75 70.68
CRF,Rules 73.05 72.33 72.69
MEML 33.51 41.34 37.02
CRFL 81.15 72.33 76.49
Rules 72.71 68.97 70.79
MEM 30.26 23.89 26.7
type CRF 78.88 64.23 70.81
MEM,Rules 68.64 68.77 68.71
CRF,Rules 71.06 70.36 70.7
MEML 31.88 39.16 35.15
CRFL 75.83 67.59 71.47
value Rules 71.18 63.44 67.08
points Rules 71.18 63.44 67.08
freq Rules 71.18 63.44 67.08
mod Rules 70.07 62.45 66.04
cal Rules 70.07 62.45 66.04
</table>
<tableCaption confidence="0.855934">
Table 7: Event prediction results.
</tableCaption>
<table confidence="0.999872705882353">
Attri- Performances
butes
Comb P R F
Rules 75.62 44.0 55.63
MEM 33.22 15.07 20.73
extent CRF 45.33 35.72 39.96
MEM,Rules 43.57 47.15 45.29
CRF,Rules 72.67 64.32 68.24
MEML 37.49 56.34 45.02
CRFL 86.49 78.5 82.3
Rules 63.97 37.22 47.06
MEM 31.11 14.12 19.41
class CRF 34.63 27.29 30.53
MEM,Rules 36.91 39.94 38.37
CRF,Rules 61.15 54.12 57.42
MEML 34.74 51.46 41.48
CRFL 78.63 71.37 74.82
</table>
<tableCaption confidence="0.820321">
Table 8: Makeinstance prediction results.
</tableCaption>
<table confidence="0.9995586">
Attri- Performances
butes P R F
eventID 86.28 78.19 82.03
polarity 93.59 73.17 82.13
tense 71.03 51.97 60.02
</table>
<tableCaption confidence="0.976056">
Table 6: Results of timex3 prediction with
TempEval-2 Korean dataset, where the digits rep-
resent accuracy.
</tableCaption>
<table confidence="0.864525666666667">
Attributes Angeli’s method Our method
type 82.0 100.0
value 42.0 100.0
</table>
<bodyText confidence="0.986904">
used for this experiment. As shown in the table,
our method gives much better accuracy than the
existing method.
</bodyText>
<subsectionHeader confidence="0.990039">
4.2 Event prediction
</subsectionHeader>
<bodyText confidence="0.998675142857143">
The results of event prediction are summarized in
Table 7, which are similar to the results of timex3
prediction. By a grid search, the optimal param-
eter settings are found to be the same as that of
the timex3 extractor. Employing the LIFE features
again increases the performance, and the CRFL is
discovered to be the best.
</bodyText>
<subsectionHeader confidence="0.99885">
4.3 Makeinstance prediction
</subsectionHeader>
<bodyText confidence="0.9999772">
All the attributes of makeinstance tag are predicted
through hand-crafted rules. The performance is
summarized in Table 8. The measurement of the
attribute POS is excluded because we simply take
the results of the Korean analyzer.
</bodyText>
<subsectionHeader confidence="0.997638">
4.4 Tlink prediction
</subsectionHeader>
<bodyText confidence="0.999920866666667">
By performing a grid search with the validation
set, we found that Support Vector Machine (SVM)
of C-SVC type with Radial Basis Function (RBF)
gives the best performance when Γ of kernel func-
tion is 1/number of features. It is also found that
the L1-regularized Logistic Regression (LR) with
C=1 gives the best performance. We observed that
both models give better performance when a win-
dow size is 1.
There are two cases of tlink prediction: (1) tlink
prediction given correct other tags, and (2) tlink
prediction given predicted other tags. The results
of the first case are summarized in Table 9, where
the performance is measured in a sequential man-
ner. As shown in the table, we tried a combina-
</bodyText>
<page confidence="0.998374">
286
</page>
<tableCaption confidence="0.972367">
Table 9: Tlink prediction results given correct
timex3, event, and makeinstance tags.
</tableCaption>
<table confidence="0.999804769230769">
Attri- Performances
butes
Comb P R F
SVM 63.84 16.72 26.49
LR 20.02 63.91 30.49
link- Rules 39.11 59.76 47.28
age SVM,Rules 39.04 61.69 47.82
LR,Rules 21.13 77.22 33.19
SVM 63.84 16.72 26.49
LR 19.18 61.24 29.22
rel- Rules 37.27 56.95 45.06
Type SVM,Rules 37.27 58.88 45.64
LR,Rules 20.2 73.82 31.72
</table>
<tableCaption confidence="0.9698195">
Table 10: Tlink prediction results of the combina-
tion of SVM and rules, given timex3, event, and
makeinstance tags which are predicted using LIFE
features.
</tableCaption>
<table confidence="0.99396325">
Attributes Performances
P R F
linkage 34.39 38.46 36.31
relType 32.94 36.83 34.77
</table>
<bodyText confidence="0.998649041666666">
tion of the rules and machine-learning models,
and the combination of SVM and rules performed
the best. Note that we do not use the LIFE fea-
tures for tlink prediction because we observed that
the LIFE features do not contribute to the perfor-
mance for tlink prediction. We believe that this is
because the LIFE features represent only the syn-
tactic/semantic patterns of the given terms, but not
arbitrary relations between the terms.
The results of the second case are obtained us-
ing the best combination, and are shown in Ta-
ble 10. Note that the tlink tags are predicted with-
out the LIFE features, while the other tags (e.g.,
timex3, event, makeinstance) are obtained using
the LIFE features. To measure the impact of the
LIFE features, we also conduct the experiment of
the second case given the predicted tags without
using the LIFE features, and the results are shown
in Table 11. As shown in Table 10 and Table 11,
using the LIFE features increases the F1 score
about 6 percents.
Table 11: Tlink prediction results of the combina-
tion of SVM and rules, given the tags predicted
without using the LIFE features.
</bodyText>
<table confidence="0.99680525">
Attributes Performances
P R F
linkage 25.41 36.69 30.02
relType 24.18 34.91 28.57
</table>
<sectionHeader confidence="0.998619" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999980882352941">
We introduced a new method for extracting tem-
poral information from unstructured Korean texts.
Korean language has a complex grammar, so there
were many research issues to address prior to
achieving our goal. We presented such issues and
our solutions to them. Experimental results il-
lustrated the effectiveness of our method, espe-
cially when we adopted the extended probabilis-
tical model, Online LIFE (O-LIFE), to gener-
ate complementary features for training machine-
learning models. In addition, as there were no suf-
ficient data for this study, we have manually con-
structed the Korean TimeBank consisting of more
than 3,700 annotated sentences. We will extend
our study to interact with Knowledge-Base for
achieving better prediction of temporal informa-
tion.
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999446">
This work was supported by ICT R&amp;D program
of MSIP/IITP. [R0101-15-0062, Development of
Knowledge Evolutionary WiseQA Platform Tech-
nology for Human Knowledge Augmented Ser-
vices] Many thanks to my family (HoYoun, Youn-
Seo), and my parents.
</bodyText>
<page confidence="0.994135">
287
</page>
<sectionHeader confidence="0.99833" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999813598039215">
Gabor Angeli and Jakob Uszkoreit. 2013. Language-
independent discriminative parsing of temporal ex-
pressions. In Proceedings of the 51th Annual Meet-
ing of the Association for Computational Linguis-
tics, Sofia, Bulgaria.
Steven Bethard. 2013a. Cleartk-timeml: A minimalist
approach to tempeval 2013. In Proceedings of the
Seventh International Workshop on Semantic Evalu-
ation, pages 10–14, Atlanta, Georgia, USA.
Steven Bethard. 2013b. A synchronous context free
grammar for time normalization. In Proceedings
of the Conference on Empirical Methods in Natu-
ral Language Processing, pages 821–826, Seattle,
USA.
Bernhard E. Boser, Isabelle M. Guyon, and Vladimir N.
Vapnik. 1992. A training algorithm for optimal
margin classifiers. In Proceedings of the fifth An-
nual Workshop on Computational Learning Theory,
pages 144–152, Pittsburgh, PA, USA.
Nathanael Chambers, Shan Wang, and Dan Juraf-
sky. 2007. Classifying temporal relations between
events. In Proceedings of the 45th Annual Meeting
of the ACL on Interactive Poster and Demonstration
Sessions, pages 173–176, Prague, Czech Republic.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Machine Learning, 20(3):273–
297.
Young-Seob Jeong and Ho-Jin Choi. 2015. Language
independent feature extractor. In Proceedings of the
Twenty-Ninth AAAI Conference on Artificial Intelli-
gence, pages 4170–4171, Texas, USA.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth In-
ternational Conference on Machine Learning, pages
282–289, Williamstown, USA.
Soojong Lim, ChangKi Lee, Jeong Hur, and Myoung-
Gil Jang. 2006. Syntax analysis of enumera-
tion type and parallel type using maximum en-
tropy model. In Proceedings of the Korea Human-
Computer Interaction Conference, pages 1240–
1245.
Xiao Ling and Daniel S. Weld. 2010. Temporal in-
formation extraction. In Proceedings of the Twenty-
Fourth AAAI Conference on Artificial Intelligence,
Atlanta, Georgia, USA.
Hector Llorens, Estela Saquete, and Borja Navarro.
2010. Tipsem (english and spanish): Evaluating crfs
and semantic roles in tempeval-2. In Proceedings of
the Fifth International Workshop on Semantic Eval-
uation, pages 284–291, Uppsala, Sweden.
Seyed Abolghasem Mirroshandel and Gholamreza
Ghassem-Sani. 2012. Towards unsupervised learn-
ing of temporal relations between events. Journal of
Artificial Intelligence Research, 45(1):125–163.
James Pustejovsky, Jose Castano, Robert Ingria, Roser
Sauri, Robert Gaizauskas, Andrea Setzer, and Gra-
ham Katz. 2003. Timeml: Robust specification of
event and temporal expressions in text. In New Di-
rections in Question Answering, pages 28–34, Stan-
ford, USA.
Erik F. Tjong Kim Sang and Sabine Buchholz. 2000.
Introduction to the conll-2000 shared task: chunk-
ing. In Proceedings of the 2nd workshop on Learn-
ing language in logic and the 4th conference on
Computational natural language learning, pages
127–132, Lisbon, Portugal.
Jannik Strotgen and Michael Gertz. 2010. Heideltime:
High quality rule-based extraction and normaliza-
tion of temporal expressions. In Proceedings of the
Fifth International Workshop on Semantic Evalua-
tion, pages 321–324, Uppsala, Sweden.
Naushad UzZaman and James Allen. 2010. Event
and temporal expression extraction from raw text:
First step towards a temporally aware system. Inter-
national Journal of Semantic Computing, 4(4):487–
508.
Naushad UzZaman, Hector Llorens, Leon Derczyn-
ski, Marc Verhagen, James Allen, and James Puste-
jovsky. 2013. Semeval-2013 task 1: Tempeval-3:
Evaluating time expressions, events, and temporal
relations. In Proceedings of the Seventh Interna-
tional Workshop on Semantic Evaluation, pages 1–9,
Atlanta, Georgia, USA.
Marc Verhagen, Robert J. Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James
Pustejovsky. 2009. The tempeval challenge: Iden-
tifying temporal relations in text. Language Re-
sources and Evaluation, 43(2):161–179.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 task 13:
Tempeval-2. In Proceedings of the Fifth Interna-
tional Workshop on Semantic Evaluation, pages 57–
62, Uppsala, Sweden.
Katsumasa Yoshikawa, Sebastian Riedel, Masayuki
Asahara, and Yuji Matsumoto. 2009. Jointly identi-
fying temporal relations with markov logic. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP, pages 405–413, Suntec, Singapore.
</reference>
<page confidence="0.997113">
288
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.636856">
<title confidence="0.998366">Temporal Information Extraction from Korean Texts</title>
<author confidence="0.982091">Young-Seob Jeong</author>
<author confidence="0.982091">Zae Myung Kim</author>
<author confidence="0.982091">Hyun-Woo Do</author>
<author confidence="0.982091">Chae-Gyun Lim</author>
<author confidence="0.982091">Ho-Jin</author>
<affiliation confidence="0.9166735">School of Korea Advanced Institute of Science and</affiliation>
<address confidence="0.670293">291 Daehak-ro, Yuseong-gu, Daejeon 305-701, South</address>
<abstract confidence="0.9963875">As documents tend to contain temporal information, extracting such information is attracting much research interests recently. In this paper, we propose a hybrid method that combines machine-learning models and hand-crafted rules for the task of extracting temporal information from unstructured Korean texts. We address Korean-specific research issues and propose a new probabilistic model to generate complementary features. The performance of our approach is demonstrated by experiments on the TempEval-2 dataset, and the Korean TimeBank dataset which we built for this study.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Languageindependent discriminative parsing of temporal expressions.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="6775" citStr="Angeli and Uszkoreit, 2013" startWordPosition="1075" endWordPosition="1078">predict without the use of language-specific processing. For instance, the attribute value of timex3 tag has a normalized form of time (e.g., 1999- 04-12) following ISO-8601. This is not accurately predictable by relying solely on data-driven approaches. The second reason is that they depend on some language-specific resources (e.g., WordNet) or tools. Unless the same quality of resources or tools is achieved for other languages, the existing works would not be available to the other languages. To alleviate this limitation, a language independent parser for extracting timex3 tags is proposed (Angeli and Uszkoreit, 2013). Its portability is demonstrated by experiments with TempEval2 dataset of six languages: English, Spanish, Italian, Chinese, Korean, and French. However, the performance in English and Spanish datasets are about twice as high as the other languages, since the method highly depends on the feature definition and language-specific preprocessing (e.g., morphological analysis). This implies that it is necessary to address language-specific difficulties in order to achieve high performance. Korean language has many subtle rules and exceptions on word spacing. Korean is an agglutinative language, wh</context>
<context position="28652" citStr="Angeli and Uszkoreit (2013)" startWordPosition="4662" endWordPosition="4665">ned with LIFE features does not contribute to the performance. This implies that using LIFE features allows the machine-learning models to capture the patterns that could not be captured by the machine-learning models without LIFE features. The CRFL is discovered to be the best, and the other remaining attributes are predicted using the rules. The performance is measured in a sequential manner, so the performance generally decreases from the top to bottom of the table. Another experiments of timex3 prediction using TempEval-2 Korean dataset are conducted to compare with the existing method of Angeli and Uszkoreit (2013). The existing method makes use of a latent parse conveying a language-flexible representation of time, and extract features over both the parse and associated temporal semantics. The results of comparison are shown in Table 6, where our method uses CRFL for type and rules for value. For a fair comparison, both methods are trained and tested using only TempEval-2 Korean dataset. As mentioned before, TempEval-2 Korean dataset contained errors, so we corrected them and 285 Table 5: Timex3 prediction results, where P represents precision, R means recall, F represents F1 score, points represent be</context>
</contexts>
<marker>Angeli, Uszkoreit, 2013</marker>
<rawString>Gabor Angeli and Jakob Uszkoreit. 2013. Languageindependent discriminative parsing of temporal expressions. In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
</authors>
<title>Cleartk-timeml: A minimalist approach to tempeval 2013.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventh International Workshop on Semantic Evaluation,</booktitle>
<pages>10--14</pages>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="3690" citStr="Bethard, 2013" startWordPosition="572" endWordPosition="573"> the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressions of temporal information such as ‘May 1973’ and ‘today’. The event tag and makeinstance tag represent some eventual expr</context>
<context position="5758" citStr="Bethard, 2013" startWordPosition="914" endWordPosition="915">into the task of extracting tlink tags. Among many related studies, there are several leading ones. HeidelTime is proposed for extraction of timex3 tags (Strotgen and Gertz, 2010). It strongly depends on hand-crafted rules, and showed the best performance in TempEval2. Llorens et al. (2010) proposed TIPSem for all of the three extraction tasks. It employs Conditional Random Fields (CRF) (Lafferty et al., 2001) for capturing patterns of texts, and defines a set of hand-crafted rules for determining several attributes of the tags. ClearTK is another work proposed for all three extraction tasks (Bethard, 2013a); it utilizes machine-learning models such as Support Vector Machines (SVM) (Boser et al., 1992; Cortes and Vapnik, 1995) and Logistic Regressions (LR), and shows the best performance in TempEval-3. Although the existing approaches show good results, most of them are applicable only to their target languages. The first reason is that there are several attributes which are difficult to predict without the use of language-specific processing. For instance, the attribute value of timex3 tag has a normalized form of time (e.g., 1999- 04-12) following ISO-8601. This is not accurately predictable </context>
</contexts>
<marker>Bethard, 2013</marker>
<rawString>Steven Bethard. 2013a. Cleartk-timeml: A minimalist approach to tempeval 2013. In Proceedings of the Seventh International Workshop on Semantic Evaluation, pages 10–14, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
</authors>
<title>A synchronous context free grammar for time normalization.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>821--826</pages>
<location>Seattle, USA.</location>
<contexts>
<context position="3690" citStr="Bethard, 2013" startWordPosition="572" endWordPosition="573"> the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressions of temporal information such as ‘May 1973’ and ‘today’. The event tag and makeinstance tag represent some eventual expr</context>
<context position="5758" citStr="Bethard, 2013" startWordPosition="914" endWordPosition="915">into the task of extracting tlink tags. Among many related studies, there are several leading ones. HeidelTime is proposed for extraction of timex3 tags (Strotgen and Gertz, 2010). It strongly depends on hand-crafted rules, and showed the best performance in TempEval2. Llorens et al. (2010) proposed TIPSem for all of the three extraction tasks. It employs Conditional Random Fields (CRF) (Lafferty et al., 2001) for capturing patterns of texts, and defines a set of hand-crafted rules for determining several attributes of the tags. ClearTK is another work proposed for all three extraction tasks (Bethard, 2013a); it utilizes machine-learning models such as Support Vector Machines (SVM) (Boser et al., 1992; Cortes and Vapnik, 1995) and Logistic Regressions (LR), and shows the best performance in TempEval-3. Although the existing approaches show good results, most of them are applicable only to their target languages. The first reason is that there are several attributes which are difficult to predict without the use of language-specific processing. For instance, the attribute value of timex3 tag has a normalized form of time (e.g., 1999- 04-12) following ISO-8601. This is not accurately predictable </context>
</contexts>
<marker>Bethard, 2013</marker>
<rawString>Steven Bethard. 2013b. A synchronous context free grammar for time normalization. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 821–826, Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard E Boser</author>
<author>Isabelle M Guyon</author>
<author>Vladimir N Vapnik</author>
</authors>
<title>A training algorithm for optimal margin classifiers.</title>
<date>1992</date>
<booktitle>In Proceedings of the fifth Annual Workshop on Computational Learning Theory,</booktitle>
<pages>144--152</pages>
<location>Pittsburgh, PA, USA.</location>
<contexts>
<context position="5855" citStr="Boser et al., 1992" startWordPosition="926" endWordPosition="929">g ones. HeidelTime is proposed for extraction of timex3 tags (Strotgen and Gertz, 2010). It strongly depends on hand-crafted rules, and showed the best performance in TempEval2. Llorens et al. (2010) proposed TIPSem for all of the three extraction tasks. It employs Conditional Random Fields (CRF) (Lafferty et al., 2001) for capturing patterns of texts, and defines a set of hand-crafted rules for determining several attributes of the tags. ClearTK is another work proposed for all three extraction tasks (Bethard, 2013a); it utilizes machine-learning models such as Support Vector Machines (SVM) (Boser et al., 1992; Cortes and Vapnik, 1995) and Logistic Regressions (LR), and shows the best performance in TempEval-3. Although the existing approaches show good results, most of them are applicable only to their target languages. The first reason is that there are several attributes which are difficult to predict without the use of language-specific processing. For instance, the attribute value of timex3 tag has a normalized form of time (e.g., 1999- 04-12) following ISO-8601. This is not accurately predictable by relying solely on data-driven approaches. The second reason is that they depend on some langua</context>
</contexts>
<marker>Boser, Guyon, Vapnik, 1992</marker>
<rawString>Bernhard E. Boser, Isabelle M. Guyon, and Vladimir N. Vapnik. 1992. A training algorithm for optimal margin classifiers. In Proceedings of the fifth Annual Workshop on Computational Learning Theory, pages 144–152, Pittsburgh, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Shan Wang</author>
<author>Dan Jurafsky</author>
</authors>
<title>Classifying temporal relations between events.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>173--176</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3568" citStr="Chambers et al., 2007" startWordPosition="552" endWordPosition="555"> that consists of more than 3,700 manually annotated sentences. The rest of the paper is organized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressio</context>
</contexts>
<marker>Chambers, Wang, Jurafsky, 2007</marker>
<rawString>Nathanael Chambers, Shan Wang, and Dan Jurafsky. 2007. Classifying temporal relations between events. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 173–176, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Supportvector networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<volume>20</volume>
<issue>3</issue>
<pages>297</pages>
<contexts>
<context position="5881" citStr="Cortes and Vapnik, 1995" startWordPosition="930" endWordPosition="933">s proposed for extraction of timex3 tags (Strotgen and Gertz, 2010). It strongly depends on hand-crafted rules, and showed the best performance in TempEval2. Llorens et al. (2010) proposed TIPSem for all of the three extraction tasks. It employs Conditional Random Fields (CRF) (Lafferty et al., 2001) for capturing patterns of texts, and defines a set of hand-crafted rules for determining several attributes of the tags. ClearTK is another work proposed for all three extraction tasks (Bethard, 2013a); it utilizes machine-learning models such as Support Vector Machines (SVM) (Boser et al., 1992; Cortes and Vapnik, 1995) and Logistic Regressions (LR), and shows the best performance in TempEval-3. Although the existing approaches show good results, most of them are applicable only to their target languages. The first reason is that there are several attributes which are difficult to predict without the use of language-specific processing. For instance, the attribute value of timex3 tag has a normalized form of time (e.g., 1999- 04-12) following ISO-8601. This is not accurately predictable by relying solely on data-driven approaches. The second reason is that they depend on some language-specific resources (e.g</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Supportvector networks. Machine Learning, 20(3):273– 297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Seob Jeong</author>
<author>Ho-Jin Choi</author>
</authors>
<title>Language independent feature extractor.</title>
<date>2015</date>
<booktitle>In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence,</booktitle>
<pages>4170--4171</pages>
<location>Texas, USA.</location>
<contexts>
<context position="21445" citStr="Jeong and Choi (2015)" startWordPosition="3452" endWordPosition="3455">en a pair of two makeinstance tags, it is straight forward to derive relType when the two 283 event tags are linked with timex3 tags. Thus, firstly we predict TT tlinks, and thereafter predict TM tlinks and MM tlinks. For the inter-sentence tlinks, we generate MM tlinks between adjacent sentences when there is a particular expression at the beginning of a sentence, such as ‘a T[geuhoo]’(afterward), ‘a ;�A[geu-jeon]’(beforehand), or ‘a �&amp;[geu-da-eum]’(thereafter). 3.3 Online LIFE As the performance of the Korean analyzer is not stable, we need complementary features to make better classifiers. Jeong and Choi (2015) proposed Language Independent Feature Extractor (LIFE) which generates a pair of class label and topic label for each Letter-Sequence (LS), where LS represents frequently appeared letter sequence. The class labels can be used as syntactic features, while the topic labels can be used as semantic features. The concept of LS makes it language independent, so it is basically applicable to any language. This is especially helpful to some languages that have no stable feature extractors. Korean is one of such languages, so we employ the LIFE to generate complementary features. The temporal informat</context>
</contexts>
<marker>Jeong, Choi, 2015</marker>
<rawString>Young-Seob Jeong and Ho-Jin Choi. 2015. Language independent feature extractor. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, pages 4170–4171, Texas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<location>Williamstown, USA.</location>
<contexts>
<context position="5558" citStr="Lafferty et al., 2001" startWordPosition="880" endWordPosition="883">ags are merely templates for them. For the above sentence, there will be two TM tlinks: go-Tuesdays and go-Mondays. The TT tlink is assumed to be easy to extract, so TempEval does not incorporate the TT tlink into the task of extracting tlink tags. Among many related studies, there are several leading ones. HeidelTime is proposed for extraction of timex3 tags (Strotgen and Gertz, 2010). It strongly depends on hand-crafted rules, and showed the best performance in TempEval2. Llorens et al. (2010) proposed TIPSem for all of the three extraction tasks. It employs Conditional Random Fields (CRF) (Lafferty et al., 2001) for capturing patterns of texts, and defines a set of hand-crafted rules for determining several attributes of the tags. ClearTK is another work proposed for all three extraction tasks (Bethard, 2013a); it utilizes machine-learning models such as Support Vector Machines (SVM) (Boser et al., 1992; Cortes and Vapnik, 1995) and Logistic Regressions (LR), and shows the best performance in TempEval-3. Although the existing approaches show good results, most of them are applicable only to their target languages. The first reason is that there are several attributes which are difficult to predict wi</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, pages 282–289, Williamstown, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soojong Lim</author>
<author>ChangKi Lee</author>
<author>Jeong Hur</author>
<author>MyoungGil Jang</author>
</authors>
<title>Syntax analysis of enumeration type and parallel type using maximum entropy model.</title>
<date>2006</date>
<booktitle>In Proceedings of the Korea HumanComputer Interaction Conference,</booktitle>
<pages>1240--1245</pages>
<contexts>
<context position="11667" citStr="Lim et al., 2006" startWordPosition="1865" endWordPosition="1868">extraction of event and makeinstance tags, and (3) extraction of tlink tags. The proposed method also extracts additional attributes of timex3 tag, such as freq, beginPoint, endPoint, mod, and calendar. The overall process is depicted in Fig. 2, where the solid line represents training process and the dotted line represents testing process. The Korean analyzer at the center of the figure takes Korean texts as an input and generates several raw features as an output, such as results of morphological analysis, Part-Of-Speech (POS) tags, Named-Entity (NE) tags, and results of dependency parsing (Lim et al., 2006). The number of possible POS tags is 45, which follows the definition of Sejong Treebank1. The number of possible NE tags is 178, where each of them belongs to one of 15 super NE tags. The generated raw features are used to define a set of features for machine-learning models and a set of hand-crafted rules. The rules are designed by examining the training dataset and the errors that the proposed method generates with the validation dataset. We employ several machine-learning methods that have shown the best performance in the TempEval shared tasks, such as Maximum Entropy Model (MEM), Support</context>
</contexts>
<marker>Lim, Lee, Hur, Jang, 2006</marker>
<rawString>Soojong Lim, ChangKi Lee, Jeong Hur, and MyoungGil Jang. 2006. Syntax analysis of enumeration type and parallel type using maximum entropy model. In Proceedings of the Korea HumanComputer Interaction Conference, pages 1240– 1245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Temporal information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the TwentyFourth AAAI Conference on Artificial Intelligence,</booktitle>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="3638" citStr="Ling and Weld, 2010" startWordPosition="564" endWordPosition="567"> of the paper is organized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressions of temporal information such as ‘May 1973’ and ‘today’. The event t</context>
</contexts>
<marker>Ling, Weld, 2010</marker>
<rawString>Xiao Ling and Daniel S. Weld. 2010. Temporal information extraction. In Proceedings of the TwentyFourth AAAI Conference on Artificial Intelligence, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Estela Saquete</author>
<author>Borja Navarro</author>
</authors>
<title>Tipsem (english and spanish): Evaluating crfs and semantic roles in tempeval-2.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fifth International Workshop on Semantic Evaluation,</booktitle>
<pages>284--291</pages>
<location>Uppsala,</location>
<contexts>
<context position="5436" citStr="Llorens et al. (2010)" startWordPosition="860" endWordPosition="863">instance tag (DM tlink). Note that the tlink takes makeinstance tags as arguments, but not the event tags, as the event tags are merely templates for them. For the above sentence, there will be two TM tlinks: go-Tuesdays and go-Mondays. The TT tlink is assumed to be easy to extract, so TempEval does not incorporate the TT tlink into the task of extracting tlink tags. Among many related studies, there are several leading ones. HeidelTime is proposed for extraction of timex3 tags (Strotgen and Gertz, 2010). It strongly depends on hand-crafted rules, and showed the best performance in TempEval2. Llorens et al. (2010) proposed TIPSem for all of the three extraction tasks. It employs Conditional Random Fields (CRF) (Lafferty et al., 2001) for capturing patterns of texts, and defines a set of hand-crafted rules for determining several attributes of the tags. ClearTK is another work proposed for all three extraction tasks (Bethard, 2013a); it utilizes machine-learning models such as Support Vector Machines (SVM) (Boser et al., 1992; Cortes and Vapnik, 1995) and Logistic Regressions (LR), and shows the best performance in TempEval-3. Although the existing approaches show good results, most of them are applicab</context>
</contexts>
<marker>Llorens, Saquete, Navarro, 2010</marker>
<rawString>Hector Llorens, Estela Saquete, and Borja Navarro. 2010. Tipsem (english and spanish): Evaluating crfs and semantic roles in tempeval-2. In Proceedings of the Fifth International Workshop on Semantic Evaluation, pages 284–291, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seyed Abolghasem Mirroshandel</author>
<author>Gholamreza Ghassem-Sani</author>
</authors>
<title>Towards unsupervised learning of temporal relations between events.</title>
<date>2012</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="3675" citStr="Mirroshandel and Ghassem-Sani, 2012" startWordPosition="568" endWordPosition="571">nized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressions of temporal information such as ‘May 1973’ and ‘today’. The event tag and makeinstance tag represent som</context>
</contexts>
<marker>Mirroshandel, Ghassem-Sani, 2012</marker>
<rawString>Seyed Abolghasem Mirroshandel and Gholamreza Ghassem-Sani. 2012. Towards unsupervised learning of temporal relations between events. Journal of Artificial Intelligence Research, 45(1):125–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jose Castano</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
</authors>
<title>Timeml: Robust specification of event and temporal expressions in text.</title>
<date>2003</date>
<booktitle>In New Directions in Question Answering,</booktitle>
<pages>28--34</pages>
<location>Stanford, USA.</location>
<contexts>
<context position="3774" citStr="Pustejovsky et al., 2003" startWordPosition="583" endWordPosition="586">roposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressions of temporal information such as ‘May 1973’ and ‘today’. The event tag and makeinstance tag represent some eventual expressions which can be related to temporal information. The makeinstance tag is an ins</context>
</contexts>
<marker>Pustejovsky, Castano, Ingria, Sauri, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>James Pustejovsky, Jose Castano, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003. Timeml: Robust specification of event and temporal expressions in text. In New Directions in Question Answering, pages 28–34, Stanford, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the conll-2000 shared task: chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning,</booktitle>
<pages>127--132</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="15532" citStr="Sang and Buchholz (2000)" startWordPosition="2473" endWordPosition="2476">e of timex3 tags. Type Conditions DATE Extent=(digit, ) SET Extent=(digit,-W∨°j∨T), Next morps= (oil∨u}r+,no other tags,121∨A) Table 2: Examples of the rules for value of timex3 tag. Operations Conditions Month=digit Context updated Type=DATE∨TIME Surrounding morps= c (digit,-) Year=context Type=DATE∨TIME Surrounding morps= (��∨�121�) obtained from the Korean analyzer. The defined features include morphemes, POS tags, NE tags, morpheme-level features of dependency parsing, given a particular window size. The morphemelevel features of dependency parsing are generated by following approaches in Sang and Buchholz (2000). To predict other attributes of each predicted timex3 tag, we also define sets of rules: 112 rules for value, 7 rules for beginPoint/endPoint, 9 rules for freq, 10 rules for mod, and 1 rule for calendar. Especially, the rules for value and freq take a temporal context into account. For instance, the sentence “We go there tomorrow”, makes it hard to predict value of ‘tomorrow’ without considering the temporal context. We assume that the temporal context of each sentence depends on the previous sentence. For each document, the temporal context is initialized with Document Creation Time (DCT), a</context>
</contexts>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the conll-2000 shared task: chunking. In Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning, pages 127–132, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jannik Strotgen</author>
<author>Michael Gertz</author>
</authors>
<title>Heideltime: High quality rule-based extraction and normalization of temporal expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fifth International Workshop on Semantic Evaluation,</booktitle>
<pages>321--324</pages>
<location>Uppsala,</location>
<contexts>
<context position="5324" citStr="Strotgen and Gertz, 2010" startWordPosition="842" endWordPosition="845">o makeinstance tags (MM tlink), a timex3 tag and a makeinstance tag (TM tlink), or Document Creation Time and a makeinstance tag (DM tlink). Note that the tlink takes makeinstance tags as arguments, but not the event tags, as the event tags are merely templates for them. For the above sentence, there will be two TM tlinks: go-Tuesdays and go-Mondays. The TT tlink is assumed to be easy to extract, so TempEval does not incorporate the TT tlink into the task of extracting tlink tags. Among many related studies, there are several leading ones. HeidelTime is proposed for extraction of timex3 tags (Strotgen and Gertz, 2010). It strongly depends on hand-crafted rules, and showed the best performance in TempEval2. Llorens et al. (2010) proposed TIPSem for all of the three extraction tasks. It employs Conditional Random Fields (CRF) (Lafferty et al., 2001) for capturing patterns of texts, and defines a set of hand-crafted rules for determining several attributes of the tags. ClearTK is another work proposed for all three extraction tasks (Bethard, 2013a); it utilizes machine-learning models such as Support Vector Machines (SVM) (Boser et al., 1992; Cortes and Vapnik, 1995) and Logistic Regressions (LR), and shows t</context>
</contexts>
<marker>Strotgen, Gertz, 2010</marker>
<rawString>Jannik Strotgen and Michael Gertz. 2010. Heideltime: High quality rule-based extraction and normalization of temporal expressions. In Proceedings of the Fifth International Workshop on Semantic Evaluation, pages 321–324, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>James Allen</author>
</authors>
<title>Event and temporal expression extraction from raw text: First step towards a temporally aware system.</title>
<date>2010</date>
<journal>International Journal of Semantic Computing,</journal>
<volume>4</volume>
<issue>4</issue>
<pages>508</pages>
<contexts>
<context position="3617" citStr="UzZaman and Allen, 2010" startWordPosition="560" endWordPosition="563">tated sentences. The rest of the paper is organized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressions of temporal information such as ‘May 1973’ and</context>
</contexts>
<marker>UzZaman, Allen, 2010</marker>
<rawString>Naushad UzZaman and James Allen. 2010. Event and temporal expression extraction from raw text: First step towards a temporally aware system. International Journal of Semantic Computing, 4(4):487– 508.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>Hector Llorens</author>
<author>Leon Derczynski</author>
<author>Marc Verhagen</author>
<author>James Allen</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventh International Workshop on Semantic Evaluation,</booktitle>
<pages>1--9</pages>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="3487" citStr="UzZaman et al., 2013" startWordPosition="538" endWordPosition="541">nerate complementary features, and (4) create a new dataset, the Korean TimeBank, that consists of more than 3,700 manually annotated sentences. The rest of the paper is organized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance ta</context>
</contexts>
<marker>UzZaman, Llorens, Derczynski, Verhagen, Allen, Pustejovsky, 2013</marker>
<rawString>Naushad UzZaman, Hector Llorens, Leon Derczynski, Marc Verhagen, James Allen, and James Pustejovsky. 2013. Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations. In Proceedings of the Seventh International Workshop on Semantic Evaluation, pages 1–9, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert J Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Jessica Moszkowicz</author>
<author>James Pustejovsky</author>
</authors>
<title>The tempeval challenge: Identifying temporal relations in text.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="3441" citStr="Verhagen et al., 2009" startWordPosition="529" endWordPosition="532">ropose a data-driven probabilistic model to generate complementary features, and (4) create a new dataset, the Korean TimeBank, that consists of more than 3,700 manually annotated sentences. The rest of the paper is organized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tag</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Moszkowicz, Pustejovsky, 2009</marker>
<rawString>Marc Verhagen, Robert J. Gaizauskas, Frank Schilder, Mark Hepple, Jessica Moszkowicz, and James Pustejovsky. 2009. The tempeval challenge: Identifying temporal relations in text. Language Resources and Evaluation, 43(2):161–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>Semeval-2010 task 13: Tempeval-2. In Proceedings of the Fifth International Workshop on Semantic Evaluation,</booktitle>
<pages>57--62</pages>
<location>Uppsala,</location>
<contexts>
<context position="3464" citStr="Verhagen et al., 2010" startWordPosition="533" endWordPosition="537">obabilistic model to generate complementary features, and (4) create a new dataset, the Korean TimeBank, that consists of more than 3,700 manually annotated sentences. The rest of the paper is organized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of ev</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. Semeval-2010 task 13: Tempeval-2. In Proceedings of the Fifth International Workshop on Semantic Evaluation, pages 57– 62, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsumasa Yoshikawa</author>
<author>Sebastian Riedel</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Jointly identifying temporal relations with markov logic.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>405--413</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="3592" citStr="Yoshikawa et al., 2009" startWordPosition="556" endWordPosition="559">than 3,700 manually annotated sentences. The rest of the paper is organized as follows. Section 2 describes the background of the research. Section 3 presents the details of the proposed method, the Korean TimeBank dataset, and how we apply the probabilistic model for generating features. Section 4 shows experimental results, and Section 5 concludes the paper. 2 Background TempEval is a series of shared tasks for temporal information extraction (Verhagen et al., 2009; Verhagen et al., 2010; UzZaman et al., 2013). There have been many studies related to the shared tasks (Chambers et al., 2007; Yoshikawa et al., 2009; UzZaman and Allen, 2010; Ling and Weld, 2010; Mirroshandel and Ghassem-Sani, 2012; Bethard, 2013b), which are based on the Time Mark-up Language (TimeML) (Pustejovsky et al., 2003). 279 Proceedings of the 19th Conference on Computational Language Learning, pages 279–288, Beijing, China, July 30-31, 2015. c�2015 Association for Computational Linguistics The shared tasks can be summarized into three extraction tasks: (1) extraction of timex3 tags, (2) extraction of event and makeinstance tags, and (3) extraction of tlink tags. The timex3 tag is associated with expressions of temporal informati</context>
</contexts>
<marker>Yoshikawa, Riedel, Asahara, Matsumoto, 2009</marker>
<rawString>Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asahara, and Yuji Matsumoto. 2009. Jointly identifying temporal relations with markov logic. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 405–413, Suntec, Singapore.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>