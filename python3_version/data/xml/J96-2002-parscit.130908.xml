<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992894">
DATR: A Language for Lexical Knowledge
Representation
</title>
<author confidence="0.999831">
Roger Evans* Gerald Gazdar
</author>
<affiliation confidence="0.999053">
University of Brighton University of Sussex
</affiliation>
<bodyText confidence="0.996294615384615">
Much recent research on the design of natural language lexicons has made use of nonmonotonic
inheritance networks as originally developed for general knowledge representation purposes in
Artificial Intelligence. DAT R is a simple, spartan language for defining nonmonotonic inher-
itance networks with path/value equations, one that has been designed specifically for lexical
knowledge representation. In keeping with its intendedly minimalist character, it lacks many
of the constructs embodied either in general-purpose knowledge representation languages or in
contemporary grammar formalisms. The present paper shows that the language is nonetheless
sufficiently expressive to represent concisely the structure of lexical information at a variety of
levels of linguistic analysis. The paper provides an informal example-based introduction to DAT R
and to techniques for its use, including finite-state transduction, the encoding of DAGs and lexical
rules, and the representation of ambiguity and alternation. Sample analyses of phenomena such
as inflectional syncretism and verbal subcategorization are given that show how the language can
be used to squeeze out redundancy from lexical descriptions.
</bodyText>
<sectionHeader confidence="0.991856" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999847857142857">
Irregular lexemes are standardly regular in some respect. Most are just like regular
lexemes except that they deviate in one or two characteristics. What is needed is a
natural way of saying &amp;quot;this lexeme is regular except for this property.&amp;quot; One obvious
approach is to use nonmonotonicity and inheritance machinery to capture such lexical
irregularity (and subregularity), and much recent research into the design of represen-
tation languages for natural language lexicons has thus made use of nonmonotonic
inheritance networks (or &amp;quot;semantic nets&amp;quot;) as originally developed for more general
representation purposes in Artificial Intelligence. Daelemans, De Smedt, and Gazdar
(1992) provide a rationale for, and an introduction to, this body of research and we will
not rehearse the content of that paper here, nor review the work cited there.1 DAT R
is a rather spartan nonmonotonic language for defining inheritance networks with
path/value equations. In keeping with its intendedly minimalist character, it lacks
many of the constructs embodied either in general-purpose knowledge representation
languages or in contemporary grammar formalisms. But the present paper seeks to
</bodyText>
<footnote confidence="0.8452119">
* Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail:
Roger.Evans@itri.brighton.ac.uk
t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail:
Gerald.Gazdar@cogs.sussex.ac.uk
1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring
together much recent work on the application of inheritance networks to lexical description. Other
relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995),
Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre,
and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992),
Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993).
</footnote>
<note confidence="0.810394">
© 1996 Association for Computational Linguistics
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.999963161290322">
show that the language is nonetheless sufficiently expressive to represent concisely
the structure of lexical information at a variety of levels of language description.
The development of DATR has been guided by a number of concerns, which we
summarize here. Our objective has been a language that (i) has an explicit theory of
inference, (ii) has an explicit declarative semantics, (iii) can be readily and efficiently
implemented, (iv) has the necessary expressive power to encode the lexical entries
presupposed by work in the unification grammar tradition, and (v) can express all the
evident generalizations and subgeneralizations about such entries. Our first publica-
tions on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference
(i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2
With respect to (iii), the core inference engine for DATR can be coded in a page
of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen
different implementations of the language, some of which have been used with large
DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a,
1994; Cahill and Evans 1990). We will comment further on implementation matters in
Section 5, below. However, the main purpose of the present paper is to exhibit the use
of DATR for lexical description (iv) and the way it makes it relatively easy to capture
lexical generalizations and subregularities at a variety of analytic levels (v). We will
pursue (iv) and (v) in the context of an informal example-based introduction to the
language and to techniques for its use, and we will make frequent reference to the
DATR-based lexical work that has been done since 1989.
The paper is organized as follows: Section 2 uses an analysis of English verbal
morphology to provide an informal introduction to DATR. Section 3 describes the
language more precisely: its syntax, inferential and default mechanisms, and the use
of abbreviatory variables. Section 4 describes a wide variety of DATR techniques, in-
cluding case constructs and parameters, Boolean logic, finite-state transduction, lists
and DAGs, lexical rules, and ways to encode ambiguity and alternation. Section 5
explores more technical issues relating to the language, including functionality and
consistency, multiple-inheritance, modes of use, and existing implementations. Sec-
tion 6 makes some closing observations. Finally, an appendix to the paper replies to
the points made in the critical literature on DATR.
</bodyText>
<sectionHeader confidence="0.941943" genericHeader="method">
2. DATR by Example
</sectionHeader>
<bodyText confidence="0.999157833333333">
We begin our presentation of DATR with a partial analysis of morphology in the
English verbal system. In DATR, information is organized as a network of nodes,
where a node is essentially just a collection of closely related information. In the
context of lexical description, a node typically corresponds to a word, a lexeme, or
a class of lexemes. For example, we might have a node describing an abstract verb,
another for the subcase of a transitive verb, another for the lexeme love, and still more
for the individual words that are instances of this lexeme (love, loves, loved, loving, etc.).
Each node has associated with it a set of path/value pairs, where a path is a sequence
of atoms (which are primitive objects), and a value is an atom or a sequence of atoms.
We will sometimes refer to atoms in paths as attributes.
For example, a node describing the present participle form of the verb love (and
called perhaps Wordi) might contain the path/value pairs shown in Table 1. The paths
</bodyText>
<footnote confidence="0.502409">
2 Note, however, that the definitions in the 1989 papers are not given in sufficient generality to cover
DATR equations with more than one (non-atomic) descriptor on the right hand side. Keller (1995)
effectively replaces our 1989 presentation of a semantics for DATR and his treatment is general enough
to cover descriptor sequences.
</footnote>
<page confidence="0.993191">
168
</page>
<note confidence="0.870372">
Evans and Gazdar Lexical Knowledge Representation
</note>
<tableCaption confidence="0.811870333333333">
Table 1
Path/value pairs for present participle of love.
Path Value
</tableCaption>
<bodyText confidence="0.969866363636363">
syn cat verb
syn type main
syn form present participle
mor form love ing
in this example all happen to contain two attributes, and the first attribute can be
thought of as distinguishing syntactic and morphological types of information. The
values indicate appropriate linguistic settings for the paths for a present participle
form of love. Thus, its syntactic category is verb, its syntactic type is main (i.e., it is
a main verb, not an auxiliary), its syntactic form is present participle (a two-atom
sequence), its morphological form is love ing (another two-atom sequence). In DATR
this can be written as:3
</bodyText>
<figure confidence="0.44189">
Wordl:
&lt;syn cat&gt; = verb
&lt;syn type&gt; = main
&lt;syn form&gt; = present participle
&lt;mor form&gt; = love ing.
</figure>
<bodyText confidence="0.941509125">
Here, angle brackets (&lt;• • •&gt;) delimit paths. Note that values can be atomic or they can
consist of sequences of atoms, as the two last lines of the example illustrate.4 As a
first approximation, nodes can be thought of as denoting partial functions from paths
(sequences of atoms) to values (sequences of atoms).5
In itself, this tiny fragment of DATR is not persuasive, apparently allowing only
for the specification of words by simple listing of path/value statements for each one.
It seems that if we wished to describe the passive form of love we would have to write:
Word2:
&lt;syn cat&gt; = verb
&lt;syn type&gt; = main
&lt;syn form&gt; = passive participle
&lt;mor form&gt; = love ed.
This does not seem very helpful: the whole point of a lexical description language is to
capture generalizations and avoid the kind of duplication evident in the specification
of Wordl and Word2. And indeed, we shall shortly introduce an inheritance mechanism
that allows us to do just that. But there is one sense in which this listing approach
</bodyText>
<footnote confidence="0.99393025">
3 The syntax of DATR, like its name and its minimalist philosophy, owes more than a little to that of the
unification grammar language PATR (Shieber 1986). With hindsight this may have been a bad design
decision since similarity of syntax tends to imply a similarity of semantics. And, as we shall see in
Section 4.7 below, and elsewhere, there is a subtle but important semantic difference.
4 Node names and atoms are distinct, but essentially arbitrary, classes of tokens in DATR. In this paper
we shall distinguish them by a simple case convention—node names start with an uppercase letter,
atoms do not.
5 This is an approximation since it ignores the role of global contexts, see Section 5.1, below.
</footnote>
<page confidence="0.991769">
169
</page>
<note confidence="0.872408">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.980974547619048">
is exactly what we want: it represents the actual information we generally wish to
access from the description. So in a sense, we do want all the above statements to
be present in our description; what we want to avoid is repeated specification of the
common elements.
This problem is overcome in DAT R in the following way: such exhaustively listed
path/value statements are indeed present in a description, but typically only implic-
itly present. Their presence is a logical consequence of a second set of statements,
which have the concise, generalization-capturing properties we expect. To make the
distinction sharp, we call the first type of statement extensional and the second type
definitional. Syntactically, the distinction is made with the equality operator: for ex-
tensional statements (as above), we use =, while for definitional statements we use ==.
And, although our first example of DAT R consisted entirely of extensional statements,
almost all the remaining examples will be definitional. The semantics of the DAT R
language binds the two together in a declarative fashion, allowing us to concentrate
on concise definitions of the network structure from which the extensional &amp;quot;results&amp;quot;
can be read off.
Our first step towards a more concise account of Wordl and Word2 is simply to
change the extensional statements to definitional ones:
Wordl: = = verb
&lt;syn cat&gt; = = main
&lt;syn type&gt; = = present participle
&lt;syn form&gt; = love ing.
&lt;mor form&gt; = = verb
Word2: = main
&lt;syn cat&gt; = passive participle
&lt;syn type&gt; = = love ed.
&lt;syn form&gt;
&lt;mor form&gt;
This is possible because DAT R respects the unsurprising condition that if at some
node a value is specifically defined for a path with a definitional statement, then the
corresponding extensional statement also holds. So the statements we previously made
concerning Wordl and Word2 remain true, but now only implicitly true.
Although this change does not itself make the description more concise, it allows
us to introduce other ways of describing values in definitional statements, in addition
to simply specifying them. Such value descriptors will include inheritance specifica-
tions that allow us to gather together the properties that Wordl and Word2 have solely
by virtue of being verbs. We start by introducing a VERB node:
VERB:
&lt;syn cat&gt; == verb
&lt;syn type&gt; == main.
and then redefine Wordl and Word2 to inherit their verb properties from it. A direct
encoding for this is as follows:
</bodyText>
<footnote confidence="0.50631025">
Wordl:
&lt;syn cat&gt; == VERB:&lt;syn cat&gt;
&lt;syn type&gt; == VERB:&lt;syn type&gt;
&lt;syn form&gt; == present participle
</footnote>
<page confidence="0.985725">
170
</page>
<table confidence="0.859073285714286">
Evans and Gazdar Lexical Knowledge Representation
&lt;mor form&gt; = love ing.
Word2: == VERB:&lt;syn cat&gt;
&lt;syn cat&gt; == VERB:&lt;syn type&gt;
&lt;syn type&gt; == passive participle
&lt;syn form&gt; = = love ed.
&lt;mor form&gt;
</table>
<bodyText confidence="0.997928">
In these revised definitions the right-hand side of the &lt;syn cat&gt; statement is not a
direct value specification, but instead an inheritance descriptor. This is the simplest
form of DATR inheritance: it just specifies a new node and path from which to obtain
the required value. It can be glossed roughly as &amp;quot;the value associated with &lt;syn
cat &gt; at Wordl is the same as the value associated with &lt;syn cat&gt; at VERB.&amp;quot; Thus
from VERB: &lt;syn cat&gt; == verb it now follows that Wordl : &lt;syn cat&gt; == verb.6
However, this modification to our analysis seems to make it less concise, rather
than more. It can be improved in two ways. The first is really just a syntactic trick: if
the path on the right-hand side is the same as the path on the left-hand side, it can be
omitted. So we can replace VERB: &lt;syn type&gt;, in the example above, with just VERB.
We can also extend this abbreviation strategy to cover cases like the following, where
the path on the right-hand side is different but the node is the same:
</bodyText>
<figure confidence="0.563190285714286">
Come:
&lt;mor root&gt; == come
&lt;mor past participle&gt; == Come:&lt;mor root&gt;.
In this case we can simply omit the node:
Come:
&lt;mor root&gt; == come
&lt;mor past participle&gt; == &lt;mor root&gt;.
</figure>
<bodyText confidence="0.999940666666667">
The other improvement introduces one of the most important features of DAT R—
specification by default. Recall that paths are sequences of attributes. If we understand
paths to start at their left-hand end, we can construct a notion of path extension: a
path P2 extends a path P1 if and only if all the attributes of P1 occur in the same
order at the left-hand end of P2 (so &lt;al a2 a3&gt; extends &lt;&gt;, &lt;al&gt;, &lt;al a2&gt;, and
&lt;al a2 a3&gt;, but not &lt;a2&gt;, &lt;al a3&gt;, etc.). If we now consider the (finite) set of
paths occurring in definitional statements associated with some node, that set will not
include all possible paths (of which there are infinitely many). So the question arises
of what we can say about paths for which there is no specific definition. For some path
P1 not defined at node N, there are two cases to consider: either P1 is the extension
of some path defined at N or it is not. The latter case is easiest—there is simply no
definition for P1 at N (hence N can be a partial function, as already noted above). But
in the former case, where P1 extends some P2 which is defined at N, P1 assumes a
definition &amp;quot;by default.&amp;quot; If P2 is the only path defined at N which P1 extends, then P1
takes its definition from the definition of P2. If P1 extends several paths defined at
N, it takes its definition from the most specific (i.e., the longest) of the paths that it
extends.
In the present example, this mode of default specification can be applied as follows:
</bodyText>
<page confidence="0.81013">
6 And hence also the extensional version, Wordl :&lt;syn cat&gt; = verb.
171
</page>
<figure confidence="0.4791362">
Computational Linguistics Volume 22, Number 2
We have two statements at Wordl that (after applying the abbreviation introduced
above) both inherit from VERB:
Word1:
&lt;syn cat&gt; == VERB
&lt;syn type&gt; == VERB.
Because they have a common leading subpath &lt;syn&gt;, we can collapse them into a
single statement about &lt;syn&gt; alone:
Wordl:
&lt;syn&gt; == VERB.
</figure>
<bodyText confidence="0.9653568">
If this were the entire definition of Wordl, the default mechanism would ensure that
all extensions of &lt;syn&gt; (including the two that concern us here) would be given the
same definition—inheritance from VERB. But in our example, of course, there are other
statements concerning Word1. If we add these back in, the complete definition looks
like this:
</bodyText>
<figure confidence="0.610562">
Wordl:
&lt;syn&gt; == VERB
</figure>
<figureCaption confidence="0.489534">
&lt;syn form&gt; == present participle
&lt;mor form&gt; == love ing.
</figureCaption>
<bodyText confidence="0.92802368">
The paths &lt;syn type&gt; and &lt;syn cat&gt; (and also many others, such as &lt;syn cat
foo&gt;, &lt;syn baz&gt;) obtain their definitions from &lt;syn&gt; using the default mechanism
just introduced, and so inherit from VERB. The path &lt;syn form&gt;, being explicitly de-
fined, is exempt from this default behavior, and so retains its value definition, present
participle; any extensions of &lt;syn form&gt; obtain their definitions from &lt;syn form&gt;
rather than &lt;syn&gt; (since it is a more specific leading subpath), and so will have the
value present participle also.
The net effect of this definition for Wordl can be glossed as &amp;quot;Word1 stipulates its
morphological form to be love ing and inherits values for its syntactic features from
VERB, except for &lt;syn form&gt;, which is present participle.&amp;quot; More generally, this
mechanism allows us to define nodes differentially: by inheritance from default spec-
ifications, augmented by any nondefault settings associated with the node at hand. In
fact, the Wordl example can take this default inheritance one step further, by inheriting
everything (not just &lt;syn&gt;) from VERB, except for the specifically mentioned values:
Word1:
== VERB
&lt;syn form&gt; == present participle
&lt;mor form&gt; == love ing.
Here the empty path &lt;&gt; is a leading subpath of every path, and so acts as a &amp;quot;catch
all&amp;quot;—any path for which no more specific definition at Word1 exists will inherit from
VERB. Inheritance via the empty path is ubiquitous in real DATR lexicons but it should
be remembered that the empty path has no special formal status in the language.
In this way, Word1 and Word2 can both inherit their general verbal properties from
VERB. Of course, these two particular forms have more in common than simply being
verbs—they are both instances of the same verb: love. By introducing an abstract Love
</bodyText>
<page confidence="0.98851">
172
</page>
<note confidence="0.724656">
Evans and Gazdar Lexical Knowledge Representation
</note>
<bodyText confidence="0.994215">
lexeme, we can provide a site for properties shared by all forms of love (in this simple
example, just its morphological root and the fact that it is a verb).
</bodyText>
<figure confidence="0.9549116">
VERB:
&lt;syn cat) == verb
&lt;syn type&gt;
Love:
&lt;&gt; == VERB
&lt;mor root&gt;
Word1:
&lt;&gt; == Love
&lt;syn form&gt;
&lt;mor form&gt;
Word2:
&lt;&gt; == Love
&lt;syn form&gt;
&lt;mor form&gt;
= main.
love.
present participle
&lt;mor root&gt; ing.
passive participle
&lt;mor root&gt; ed.
</figure>
<bodyText confidence="0.96543455">
So now Word1 inherits from Love rather than VERB (but Love inherits from VERB, so the
latter&apos;s definitions are still present at Word1). However, instead of explicitly including
the atom love in the morphological form, the value definition includes the descriptor
&lt;mor root&gt;. This descriptor is equivalent to Wordl : &lt;mor root&gt; and, since &lt;mor
root &gt; is not defined at Wordl, the empty path definition applies, causing it to inherit
from Love: &lt;mor root&gt;, and thereby return the expected value, love. Notice here that
each element of a value can be defined entirely independently of the others; for &lt;mor
form&gt; we now have an inheritance descriptor for the first element and a simple value
for the second.
Our toy fragment is beginning to look somewhat more respectable: a single node
for abstract verbs, a node for each abstract verb lexeme, and then individual nodes
for each morphological form of each verb; but there is still more that can be done.
Our focus on a single lexeme has meant that one class of redundancy has remained
hidden. The line
&lt;mor form&gt; == &lt;mor root&gt; ing
will occur in every present participle form of every verb, yet it is a completely generic
statement that can be applied to all English present participle verb forms. Can we not
replace it with a single statement in the VERB node? Using the mechanisms we have
seen so far, the answer is no. The statement would have to be (i), which is equivalent
to (ii), whereas the effect we want is (iii):
</bodyText>
<listItem confidence="0.975002333333333">
(i) VERB:&lt;mor form&gt; == &lt;mor root&gt; ing
(ii) VERB:&lt;mor form&gt; == VERB:&lt;mor root&gt; ing
(iii) VERB:&lt;mor form&gt; == Word1:&lt;mor root&gt; ing
</listItem>
<bodyText confidence="0.964662">
Using (i) or (ii), we would end up with the same morphological root for every verb (or
more likely no value at all, since it is hard to imagine what value VERB: &lt;mor root &gt;
might plausibly be given), rather than a different one for each. And of course, we
cannot simply use (iii) as it is, since it only applies to the particular word described
by Word1, namely loving.
</bodyText>
<page confidence="0.995691">
173
</page>
<note confidence="0.422721">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.9997369">
The problem is that the inheritance mechanism we have been using is local, in the
sense that it can only be used to inherit either from a specifically named node (and/or
path), or relative to the local context of the node (and/or path) at which it is defined.
What we need is a way of specifying inheritance relative to the the original node/path
specification whose value we are trying to determine, rather than the one we have
reached by following inheritance links. We shall refer to this original specification as
the query we are attempting to evaluate, and the node and path associated with this
query as the global context.&apos; Global inheritance, that is, inheritance relative to the
global context, is indicated in DATR by using quoted (&amp;quot;...&amp;quot;) descriptors, and we can
use it to extend our definition of VERB as follows:
</bodyText>
<equation confidence="0.71668725">
VERB:
&lt;syn cat&gt; == verb
&lt;syn type&gt; == main
&lt;mor form&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; ing.
</equation>
<bodyText confidence="0.9998505">
Here we have added a definition for &lt;mor form&gt; that contains the quoted path &amp;quot; &lt;mor
root &gt;&amp;quot;. Roughly speaking, this is to be interpreted as &amp;quot;inherit the value of &lt;mor
root&gt; from the node originally queried.&amp;quot; With this extra definition, we no longer
need a &lt;mor form&gt; definition in Wordl, so it becomes:
</bodyText>
<equation confidence="0.893778333333333">
Wordl:
&lt;&gt; == Love
&lt;syn form&gt; == present participle.
</equation>
<bodyText confidence="0.999863125">
To see how this global inheritance works, consider the query Wordl : &lt;mor form&gt;.
Since &lt;mor form&gt; is not defined at Wordl, it will inherit from VERB via Love. This
specifies inheritance of &lt;mor root &gt; from the query node, which in this case is Wordl.
The path &lt;mor root&gt; is not defined at Wordl but inherits the value love from Love.
Finally, the definition of &lt;mor form&gt; at VERB adds an explicit ing, resulting in a value
of love ing for Wordl : &lt;mor form&gt;. Had we begun evaluation at, say, a daughter
of the lexeme Eat, we would have been directed from VERB: &lt;mor form&gt; back to the
original daughter of Eat to determine its &lt;mor root&gt;, which would be inherited from
Eat itself; we would have ended up with the value eat ing.
The analysis is now almost the way we would like it to be. Unfortunately, by
moving &lt;mor form&gt; from Wordl to VERB, we have introduced a new problem: we
have specified the present participle as the (default) value of &lt;mor form&gt; for all
verbs. Clearly, if we want to specify other forms at the same level of generality, then
&lt;mor form&gt; is currently misnamed: it should be &lt;mor present participle&gt;, so
that we can add &lt;mor past participle&gt;, &lt;nor present tense&gt;, etc. If we make
this change, then the VERB node will look like this:
</bodyText>
<construct confidence="0.4181388">
VERB:
&lt;syn cat&gt; == verb
&lt;syn type&gt; == main
&lt;mor past&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; ed
&lt;mor passive&gt; == &amp;quot;&lt;mor past&gt;&amp;quot;
</construct>
<footnote confidence="0.9458025">
7 Strictly speaking, the query node and path form just the initial global context, since as we shall see in
Section 3.2.2 below, the global context can change during inheritance processing.
</footnote>
<page confidence="0.99409">
174
</page>
<figure confidence="0.39643825">
Evans and Gazdar Lexical Knowledge Representation
&lt;mor present&gt; == &amp;quot;&lt;mor root&gt;&amp;quot;
&lt;mor present participle&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; ing
&lt;mor present tense sing three&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; s.
</figure>
<bodyText confidence="0.99460496">
In adding these new specifications, we have added a little extra structure as well. The
passive form is asserted to be the same as the past form—the use of global inheritance
here ensures that irregular or subregular past forms result in irregular or subregular
passive forms, as we shall see shortly. The paths introduced for the present forms
illustrate another use of default definitions. We assume that the morphology of present
tense forms is specified with paths of five attributes, the fourth specifying number, the
fifth, person. Here we define default present morphology to be simply the root, and
this generalizes to all the longer forms, except the present participle and the third
person singular.
For Love, given these changes, the following extensional statements hold, inter
alia:
Love:
&lt;syn
&lt;syn
&lt;mor
&lt;mor
&lt;mor
&lt;mor
&lt;mor
&lt;mor
&lt;mor
&lt;mor
&lt;mor
&lt;mor
&lt;mor
</bodyText>
<equation confidence="0.9991235">
cat&gt; = verb
type&gt; = main
</equation>
<bodyText confidence="0.988436724137931">
present tense sing one&gt; = love
present tense sing two&gt; = love
present tense sing three&gt; = love
present tense plur&gt; = love
present participle&gt; = love ing
past tense sing one&gt; = love ed
past tense sing two&gt; = love ed
past tense sing three&gt; = love ed
past tense plur&gt; = love ed
past participle&gt; = love ed
passive participle&gt; = love ed.
There remains one last problem in the definitions of Wordl and Word2. The mor-
phological form of Wordl is now given by &lt;mor present participle&gt;. Similarly,
Word2&apos;s morphological form is given by &lt;mor passive participle&gt;. There is no
longer a unique path representing morphological form. This can be corrected by the
addition of a single statement to VERB:
VERB:
&lt;mor form&gt; == &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot;.
This statement employs a DATR construct, the evaluable path, which we have not
encountered before. The right-hand side consists of a (global) path specification, one
of whose component attributes is itself a descriptor that must be evaluated before
the outer path can be. The effect of the above statement is to say that &lt;mor form&gt;
globally inherits from the path given by the atom mor followed by the global value of
&lt;syn form&gt;. For Wordl, &lt;syn form&gt; is present participle, so &lt;mor form&gt; inher-
its from &lt;mor present participle&gt;. But for Word2, &lt;mor form&gt; inherits from &lt;mor
passive participle&gt;. Effectively, &lt;syn f orm&gt; is being used here as a parameter
to control which specific form should be considered the morphological form. Evalu-
able paths may themselves be global (as in our example) or local, and their evaluable
components may also involve global or local reference.
</bodyText>
<page confidence="0.992633">
175
</page>
<figure confidence="0.9849892">
Computational Linguistics Volume 22, Number 2
Our analysis now looks like this:
VERB:
&lt;syn cat&gt; == verb
&lt;syn type&gt; == main
&lt;mor form&gt; == &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot;
&lt;mor past&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; ed
&lt;mor passive&gt; == &amp;quot;&lt;mor past&gt;&amp;quot;
&lt;mor present&gt; == &amp;quot;&lt;mor root&gt;&amp;quot;
&lt;mor present participle&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; ing
&lt;mor present tense sing three&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; s.
Love:
&lt;&gt; == VERB
&lt;mor root&gt; == love.
Wordl:
== Love
&lt;syn form&gt; == present participle.
Word2:
== Love
&lt;syn form&gt; == passive participle.
</figure>
<bodyText confidence="0.999355545454545">
The entire analysis is somewhat larger than the original, but it encodes all the past and
present tense forms as well as all three participial forms. More importantly, almost all
the information is in the VERB node and is common to many verb lexemes.8 Indeed,
the other nodes are as small as they reasonably could be: Love simply states that it
is a verb with morphological root love, and Wordl simply states that it is a present
participle instance of Love.
Of course, Love is a completely regular verb; but DAT R&apos;s capacity for definition by
default allows subregular and irregular lexemes to be concisely represented also. As
an example, consider the class of verbs which take -en as their past participle ending:
hew, mow, saw, sew, etc.&apos; We can represent this subregularity with a new verbal node
that defaults to VERB, but overrides just the past participle morphology:
</bodyText>
<equation confidence="0.988969857142857">
EN_VERB:
&lt;&gt; == VERB
&lt;mor past participle&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; en.
Relevant individual verb lexemes then inherit from this node instead of directly from
VERB:
Mow:
&lt;&gt; == EN_VERB
</equation>
<footnote confidence="0.855586">
8 Linguistically, the analysis is still not abstract enough since it fails to encode the morphotactic
generalization that, by default, an inflected English word consists of a root optionally followed by a
suffix. Such generalizations are easy enough to state in DATR but would entail more elaboration of our
running example than its expository purpose requires.
9 Our orthographic representations in this paper presuppose some basic spelling rules, thus love ed is
spelt loved, love ing is spelt loving and mow en is spelt mown. If we had chosen to represent roots and
suffixes as letter sequences rather than as atoms, then it would have been possible to implement the
necessary spelling rules in a finite-state transducer written in DATR itself. See, for example, that
presented in Section 4.3, below.
</footnote>
<page confidence="0.989631">
176
</page>
<equation confidence="0.8798238">
Evans and Gazdar Lexical Knowledge Representation
&lt;mor root&gt; == mow.
Sew:
&lt;&gt; == EN_VERB
&lt;mor root&gt; == sew.
</equation>
<bodyText confidence="0.999477666666667">
As noted above, the passive forms of these subregular verbs will be correct now
as well, because of the use of a global cross-reference to the past participle form in the
VERB node. For example, the definition of the passive form of sew is:
</bodyText>
<equation confidence="0.651812">
Word3:
&lt;&gt; == Sew
&lt;syn form&gt; == passive participle.
</equation>
<bodyText confidence="0.9985346">
If we seek to establish the &lt;mor f orm&gt; of Word3, we are sent up the hierarchy of
nodes, first to Sew, then to EN_VERB, and then to VERB. Here we encounter &amp;quot; &lt;mor &amp;quot; &lt;syn
f orm&gt;&amp;quot; &gt;&amp;quot;, which resolves to &amp;quot; &lt;mor passive part iciple&gt;&amp;quot; in virtue of the embed-
ded global reference to &lt;syn form&gt; at Word3. This means we now have to establish
the value of &lt;mor passive participle&gt; at Word3. Again, we ascend the hierarchy to
VERB and find ourselves referred to the global descriptor &amp;quot; &lt;mor past part iciple&gt;&amp;quot;.
This takes us back to Word3, from where we again climb, first to Sew, then to EN_VERB.
Here, &lt;mor past part iciple&gt; is given as the sequence &amp;quot; &lt;mor root &gt; &amp;quot; en. This leads
us to look for the &lt;mor root&gt; of Word3, which we find at Sew, giving the result we
seek:
</bodyText>
<equation confidence="0.4398115">
Word3:
&lt;mor form&gt; = sew en.
</equation>
<bodyText confidence="0.8395175">
Irregularity can be treated as just the limiting case of subregularity, so, for example,
the morphology of Do can be specified as follows:I°
</bodyText>
<equation confidence="0.6792114">
Do:
&lt;&gt; == VERB
&lt;mor root&gt; == do
&lt;mor past&gt; == did
&lt;mor past participle&gt; == done
&lt;mor present tense sing three&gt; does.
Likewise, the morphology of Be can be specified as follows:11
Be:
&lt;&gt; == EN_VERB
&lt;mor root&gt; == be
</equation>
<bodyText confidence="0.450169666666667">
10 Orthographically, the form does could simply be treated as regular (from do s). However, we have
chosen to stipulate it here since, although the spelling appears regular, the phonology is not, so in a
lexicon that defined phonological forms it would need to be stipulated.
</bodyText>
<footnote confidence="0.755261666666667">
11 In their default unification reconstruction of this DATR analysis of English verbal inflection, Bouma and
Nerbonne (1994, 48) invoke &amp;quot;a feature -SG3 to cover all agreement values other than third person
singular&amp;quot; in order &amp;quot;to avoid redundancy,&amp;quot; but they do not explain how they would then account for
the first person singular present tense form of be without reintroducing the redundancy that they are
seeking to avoid. Moreover, the use of this purely morphological feature leads them to introduce a set
of lexical rules in order to map the relevant information across from the (different) syntactic features.
</footnote>
<page confidence="0.974377">
177
</page>
<figure confidence="0.695682428571429">
Computational Linguistics Volume 22, Number 2
&lt;mor present tense sing one&gt; == am
&lt;mor present tense sing three&gt; == is
&lt;mor present tense plur&gt; == are
&lt;mor past tense sing one&gt; == &lt;mor past tense sing three&gt;
&lt;mor past tense sing three&gt; == was
&lt;mor past tense plur&gt; == were.
</figure>
<bodyText confidence="0.999218">
In this section, we have moved from simple attribute/value listings to a compact,
generalization-capturing representation for a fragment of English verbal morphology.
In so doing, we have seen examples of most of the important ingredients of DATR:
local and global descriptors, definition by default, and evaluable paths.
</bodyText>
<sectionHeader confidence="0.989555" genericHeader="method">
3. The DATR Language
</sectionHeader>
<subsectionHeader confidence="0.999924">
3.1 Syntax
</subsectionHeader>
<bodyText confidence="0.937986461538461">
A DATR description consists of a sequence of sentences corresponding semantically to
a set of statements. Sentences are built up out of a small set of basic expression types,
which themselves are built up out of sequences of lexical tokens, which we take to be
primitive.
In the previous section, we referred to individual lines in DATR definitions as state-
ments. Syntactically, however, a DATR description consists of a sequence of sentences,
where each sentence starts with a node name and ends with a period, and contains
one or more path equations relating to that node, each corresponding to a statement
in DATR. This distinction between sentences and statements is primarily for notational
convenience (it would be cumbersome to require repetition of the node name for each
statement) and statements are the primary unit of specification in DATR. For the pur-
poses of this section, where we need to be particularly clear about this distinction, we
shall call a sentence containing just a single statement a simple sentence.
</bodyText>
<subsubsectionHeader confidence="0.317351">
3.1.1 Lexical Tokens. The syntax of DATR distinguishes four classes of lexical token:
</subsubsectionHeader>
<bodyText confidence="0.569938">
nodes, atoms, variables, and reserved symbols. The complete list of reserved symbols
is as follows:
</bodyText>
<equation confidence="0.821639">
&amp;quot; &lt; &gt; = == % #
</equation>
<bodyText confidence="0.999382272727273">
We have already seen the use of the first seven of these. Single quotes can be used
to form atoms that would otherwise be ill-formed as such; % is used for end-of-line
comments, following the Prolog convention; # is used to introduce declarations and
other compiler directives.&apos;
The other classes, nodes, atoms, and variables, must be distinct, and distinct from
the reserved symbols, but are otherwise arbitrary.13 For this discussion, we have al-
ready adopted the convention that both nodes and atoms are simple words, with nodes
starting with uppercase letters. We extend this convention to variables, discussed more
fully in Section 3.4 below, which we require to start with the character $. And we take
white space (spaces, new lines, tabs, etc.) to delimit lexical tokens but otherwise to be
insignificant.
</bodyText>
<page confidence="0.918212">
12 Aside from their use in Section 3.4, we will completely ignore such directives in this paper.
13 Formally, we require them to be finite classes, but this is not of great significance here.
178
</page>
<bodyText confidence="0.251521">
Evans and Gazdar Lexical Knowledge Representation
</bodyText>
<listItem confidence="0.99332025">
3.1.2 Right-hand-side Expressions. The expressions that may appear as the right-hand
sides of DATR equations are sequences of zero or more descriptors.&apos; Descriptors are
defined recursively, and come in seven kinds. The simplest descriptor is just an atom
or variable:
</listItem>
<bodyText confidence="0.893382333333333">
atomi
$var 1
Then there are three kinds of local inheritance descriptor: a node, an (evalu-
able) path, and a node/path pair. Nodes are primitive tokens, paths are descriptor
sequences (defined below) enclosed in angle brackets and node/path pairs consist of
a node and a path, separated by a colon:
</bodyText>
<equation confidence="0.976397666666667">
Nodel
&lt;descl desc2 desc3 ...&gt;
Nodel:&lt;descl desc2 desc3 ...&gt;
</equation>
<bodyText confidence="0.9924705">
Finally there are three kinds of global inheritance descriptor, which are quoted
variants of the three local types just described:
</bodyText>
<equation confidence="0.974425666666667">
&amp;quot;Node 1&amp;quot;
&amp;quot;&lt;descl desc2 desc3 ...&gt;&amp;quot;
&amp;quot;Nodel:&lt;descl desc2 desc3 ...&gt;&amp;quot;
</equation>
<bodyText confidence="0.999759666666667">
A descriptor sequence is a (possibly empty) sequence of descriptors. The recur-
sive definition of evaluable paths in terms of descriptor sequences allows arbitrarily
complex expressions to be constructed, such as:15
</bodyText>
<equation confidence="0.84029">
&amp;quot;Nodel:&lt;&amp;quot;&lt;atoml&gt;&amp;quot; Node2:&lt;atom2&gt;&gt;&amp;quot;
&amp;quot;&lt;&amp;quot;&lt;&amp;quot;&lt;Nodel:&lt;atoml atom2&gt; atom3&gt;&amp;quot; Node2 &amp;quot;&lt;atom4 atom5&gt;&amp;quot; &lt;&gt; &gt;&amp;quot;&gt;&amp;quot;
</equation>
<bodyText confidence="0.993273666666667">
But the value sequences determined by such definitions are flat: they have no struc-
ture beyond the simple sequence and in particular do not reflect the structure of the
descriptors that define them.
We shall sometimes refer to descriptor sequences containing only atoms as simple
values, and similarly, (unquoted) path expressions containing only atoms as simple
paths.
</bodyText>
<subsubsectionHeader confidence="0.382707">
3.1.3 Sentences. DATR sentences represent the statements that make up a description.
</subsubsectionHeader>
<bodyText confidence="0.995917666666667">
As we have already seen, there are two basic statement types, extensional and defini-
tional, and these correspond directly to simple extensional and definitional sentences,
which are made up from the components introduced in the preceding section.
</bodyText>
<footnote confidence="0.766741222222222">
14 DATR makes a distinction between a path not having a value (i.e., being undefined) and a path having
the empty sequence as a value:
NUM:
&lt;two&gt; ==
&lt;one&gt; == one.
In this example, NUM: &lt;one&gt; has the value one, NUM: &lt;two&gt; has the empty sequence as its value, and
NUM: &lt;three&gt; is simply undefined.
15 A descriptor containing an evaluable path may include nested descriptors that are either local or global.
Our use of the local/global terminology always refers to the outermost descriptor of an expression.
</footnote>
<page confidence="0.987632">
179
</page>
<note confidence="0.265142">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.748382545454545">
Simple extensional sentences take the form
Node:Path = Ext.
where Node is a node, Path is a simple path, and Ext is a simple value. Extensional
sentences derivable from the examples given in Section 2 include:
Do:&lt;mor past participle&gt; = done.
Mow:&lt;mor past tense sing one&gt; = mow ed.
Love:&lt;mor present tense sing three&gt; = love s.
Simple definitional sentences take the form
Node:Path == Def.
where Node and Path are as above and Def is an arbitrary descriptor sequence. Defi-
nitional sentences already seen in Section 2 include:
</bodyText>
<equation confidence="0.436080333333333">
Do:&lt;mor past&gt; == did.
VERB:&lt;mor form&gt; == &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot;.
EN_VERB:&lt;mor past participle&gt; == &amp;quot;&lt;mor root&gt;&amp;quot; en.
</equation>
<bodyText confidence="0.996648">
Each of these sentences corresponds directly to a DATR statement. However we extend
the notion of a sentence to include an abbreviatory convention for sets of statements
relating to a single node. The following single sentence:
</bodyText>
<equation confidence="0.9967552">
Node:
Pathl == Defl
Path2 == Def2
...
PathN == Def N.
abbreviates (and is entirely equivalent to):
Node:Pathl == Def 1.
Node:Path2 == Def 2.
...
Node:PathN == Def N.
</equation>
<bodyText confidence="0.999871571428572">
Extensional statements, and combinations of definitional and extensional statements,
may be similarly abbreviated, and the examples used throughout this paper make
extensive use of this convention. Such compound sentences correspond to a number
of individual (and entirely independent) DATR statements.
Finally, it is worth reiterating that DATR descriptions correspond to sets of state-
ments: the order of sentences, or of definitions within a compound sentence, is imma-
terial to the relationships described.
</bodyText>
<subsectionHeader confidence="0.997689">
3.2 Inheritance in DATR
</subsectionHeader>
<bodyText confidence="0.812076">
DATR descriptions associate values with node/path pairs. This is achieved in one of
three ways: a value is explicitly stated, or it is explicitly inherited, or it is implicitly
</bodyText>
<page confidence="0.925168">
180
</page>
<bodyText confidence="0.935773285714286">
Evans and Gazdar Lexical Knowledge Representation
specified (stated or inherited) via the default mechanism. We have already seen how
values are explicitly stated; in this and the following subsections, we continue our
exposition by providing an informal account of the semantics of specification via in-
heritance or by default. The present subsection is only concerned with explicit (i.e.,
nondefault) inheritance. Section 3.3 deals with implicit specification via DATR&apos;s default
mechanism.
</bodyText>
<subsubsectionHeader confidence="0.779883">
3.2.1 Local Inheritance. The simplest type of inheritance in DATR is the specification
</subsubsectionHeader>
<bodyText confidence="0.995375333333333">
of a value by local inheritance. Such specifications may provide a new node, a new
path, or a new node and path to inherit from. An example definition for the lexeme
Come illustrates all three of these types:
</bodyText>
<equation confidence="0.957485833333333">
Come:
&lt;&gt; == VERB
&lt;mor root&gt; == come
&lt;mor past&gt; == came
&lt;mor past participle&gt; == &lt;mor root&gt;
&lt;syn&gt; == INTRANSITIVE:&lt;&gt;.
</equation>
<bodyText confidence="0.999962227272727">
Here the empty path inherits from VERB so the value of Come: &lt;&gt; is equated to
that of VERB: &lt;&gt;. And the past participle inherits from the root: Come: &lt;mor past
part iciple&gt; is equated to Come : &lt;mor root&gt; (i.e., come). In both these inheritances,
only one node or path was specified: the other was taken to be the same as that found
on the left-hand side of the statement (&lt;&gt; and Come respectively). The third type of
local inheritance is illustrated by the final statement, in which both node and path
are specified: the syntax of Come is equated with the empty path at INTRANSITIVE, an
abstract node defining the syntax of intransitive verbs.&apos;
There is a natural procedural interpretation of this kind of inheritance, in which
the value associated with the definitional expression is determined by &amp;quot;following&amp;quot; the
inheritance specification and looking for the value at the new site. So given a DATR
description (i.e., a set of definitional statements) and an initial node/path query, we
look for the node and path as the left-hand side of a definitional statement. If the
definitional statement for this pair provides a local descriptor, then we follow it, by
changing one or both of node or path, and then repeat the process with the resulting
node/path pair. We continue until some node/path pair specifies an explicit value. In
the case of multiple expressions on the right-hand side of a statement, we pursue each
of them entirely independently of the others. This operation is local in the sense that
each step is carried out without reference to any context wider than the immediate
definitional statement at hand.
Declaratively speaking, local descriptors simply express equality constraints be-
tween definitional values for node/path pairs. The statement:
</bodyText>
<equation confidence="0.914861666666667">
Nodel:Pathl == Node2:Path2.
16 Bear in mind that the following are not synonymous
Come : &lt;syn&gt; == INTRANSITIVE: &lt;&gt; .
Come : &lt;syn&gt; == INTRANSITIVE.
since the latter is equivalent to
Come : &lt;syn&gt; == INTRANSITIVE: &lt;syn&gt; .
</equation>
<page confidence="0.967195">
181
</page>
<note confidence="0.399364">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.990305925">
can be read approximately as &amp;quot;if the value for Node2 :Path2 is defined, then the value
of Node 1 : Path 1 is defined and equal to it.&amp;quot; There are several points to notice here.
First, if Node2:Path2 is not defined, then Node1 :Pathl is unconstrained, so this is
a weak directional equality constraint. However, in practice this has no useful con-
sequences, due to interactions with the default mechanism (see Section 5.1 below).
Second, &amp;quot;defined&amp;quot; here means &amp;quot;defined by a definitional statement,&amp;quot; that is, a &amp;quot;==&amp;quot;
statement: local inheritance operates entirely with definitional statements, implicitly
introducing new ones for Node1:Path1 on the basis of those defined for Node2:Path2.
Finally, as we shall discuss more fully in the next subsection, &amp;quot;value&amp;quot; here technically
covers both simple values and global inheritance descriptors.
3.2.2 Global Inheritance. Like local inheritance, global inheritance comes in three
types: node, path, and node/path pair. However, when either the node or the path
is omitted from a global inheritance descriptor, rather than using the node or path of
the left-hand side of the statement that contains it (the local context of the definition),
the values of a global context are used instead. This behavior is perhaps also more
easily introduced procedurally rather than declaratively. As we saw above, we can
think of local inheritance in terms of following descriptors starting from the query.
The local context is initially set to the node and path specified in the query. When
a local descriptor is encountered, any missing node or path components are filled in
from the local context, and then control passes to the new context created (that is, we
look at the definition associated with the new node/path pair). In doing this, the local
context also changes to be the new context. Global inheritance operates in exactly the
same way: the global context is initially set to the node and path specified in the query.
It is not altered when local inheritance descriptors are followed (it &amp;quot;remembers&amp;quot; where
we started from), but when a global descriptor is encountered, it is the global context
that is used to fill in any missing node or path components in the descriptor, and
hence to decide where to pass control to. In addition, both global and local contexts
are updated to the new settings. So global inheritance can be seen as essentially the
same mechanism as local inheritance, but layered on top of it—following global links
alters the local context too, but not vice versa.
For example, when a global path is specified, it effectively returns control to the
current global node (often the original query node) but with the newly given path.
Thus in Section 2, above, we saw that the node VERB defines the default morphology
of present forms using global inheritance from the path for the morphological root:
VERB:&lt;mor present&gt; == &amp;quot;&lt;mor root&gt;&amp;quot;.
The node from which inheritance occurs is that stored in the global context: a query of
Love: &lt;mor present &gt; will result in inheritance from Love: &lt;mor root&gt; (via VERB: &lt;mor
pr e sent &gt;), while a query of Do : &lt;mor present&gt; will inherit from Do : &lt;mor root&gt;.
Similarly, a quoted node form accesses the globally stored path value, as in the
following example:
</bodyText>
<equation confidence="0.888921727272727">
Declensionl:
&lt;vocative&gt; == -a
&lt;accusative&gt; == -am.
Declension2:
&lt;vocative&gt; == &amp;quot;Declensionl&amp;quot;
&lt;accusative&gt; == -um.
Declension3:
182
Evans and Gazdar Lexical Knowledge Representation
&lt;vocative&gt; == -e
&lt;accusative&gt; == Declension2:&lt;vocative&gt;.
</equation>
<bodyText confidence="0.999992785714286">
Here, the value of Declension3 : &lt;accusative&gt; inherits from Declension2: &lt;voca-
t ive&gt; and then from De clens oni : &lt;ac cus at ive&gt;, using the global path (in this case
the query path), rather than the local path (&lt;vocat ive&gt;) to fill out the specification.
The resulting value is -am and not -a as it would have been if the descriptor in
Declension2 had been local, rather than global.
We observed above that when inheritance through a global descriptor occurs, the
global context is altered to reflect the new node/path pair. Thus after Love : &lt;mor
present&gt; has inherited through &amp;quot;VERB: &lt;mor root &gt;&amp;quot;, the global path will be &lt;mor
root&gt; rather than &lt;mor present&gt;. When we consider quoted node/path pairs, it
turns out that this is the only property that makes them useful. Since a quoted
node/path pair completely respecifies both node and path, its immediate inheritance
characteristics are the same as the unquoted node/path pair. However, because it
also alters the global context, its effect on any subsequent global descriptors (in the
evaluation of the same query) will be different:
</bodyText>
<equation confidence="0.911542777777778">
Declensionl:
&lt;vocative&gt; == &amp;quot;&lt;nominative&gt;&amp;quot;
&lt;nominative&gt; == -a.
Declension2:
&lt;vocative&gt; == Declensionl
&lt;nominative&gt; == -u.
Declension3:
&lt;nominative&gt; ==
&lt;accusative&gt; == &amp;quot;Declension2:&lt;vocative&gt;&amp;quot;.
</equation>
<bodyText confidence="0.999984130434782">
In this example, the value of Declension3: &lt;accusative&gt; inherits from Declension2:
&lt;vocative&gt; and then from Declensionl : &lt;vocative&gt; and then from Declension2:
&lt;nominative&gt; (because the global node has changed from Declension3 to Declen-
sion2) giving a value of -u and not as it would have been if the descriptor in
Declension3 had been local, rather than global.
There are a number of ways of understanding this global inheritance mechanism.
The description we have given above amounts to a &amp;quot;global memory&amp;quot; model, in which
a DATR query evaluator is a machine equipped with two memories: one containing
the current local node and path, and another containing the current global node and
path. Both are initialized to the query node and path, and the machine operates by
repeatedly examining the definition associated with the current local settings. Local
descriptors alter just the local memory, while global descriptors alter both the local
and global settings.
This model is the basis of at least one implementation of DATR but it is not, of
course, declarative. Nevertheless, the notion of global inheritance does have a declar-
ative reading, very similar to local inheritance but, as we have already suggested,
layered on top of it. Recall that local inheritance establishes a network of weak equal-
ity relationships among node/path pairs, and these equalities are used to distribute
values across this network. Formally speaking, the local inheritance network controls
the distribution not only of simple values, but also of global descriptors, as we men-
tioned above. That is, to local inheritance, values and global descriptors are one and
the same, and are inherited through the network. Indeed, this is the intuitive warrant
for the use of the quote notation: the quotes turn an inheritance descriptor into a (kind
</bodyText>
<page confidence="0.989978">
183
</page>
<note confidence="0.400668">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.992891666666667">
of) value. Consequently, global descriptors are also distributed through the local inher-
itance network, and so are implicitly present at many node/path pairs in addition to
those they are explicitly defined for. In fact, a global descriptor is implicitly present at
every node/path pair that could ever occur as the global context for evaluation of the
descriptor at its original, explicitly defined location. This means that once distributed
in this way, the global descriptors form a network of weak equality relationships just
as the local descriptors do, and distribute the simple values (alone) in the same way.
To see this interpretation in action, we consider an alternative analysis of the past
participle form of Come. The essential elements of the analysis are as follows:
</bodyText>
<figure confidence="0.556635222222222">
BARE_VERB:
&lt;mor past participle&gt; == &amp;quot;&lt;mor root&gt;&amp;quot;.
Come:
&lt;mor root&gt; == come
&lt;mor past participle&gt; == BARE_VERB.
Local inheritance from BARE_VERB to Come implicitly defines the following statement
(in addition to the above):
Come:
&lt;mor past participle&gt; == &amp;quot;&lt;mor root&gt;&amp;quot;.
</figure>
<bodyText confidence="0.957509807692308">
Because we have now brought the global inheritance descriptor to the node corre-
sponding to the global context for its interpretation, global inheritance can now oper-
ate entirely locally—the required global node is the local node, Come, producing the
desired result:
Come:
&lt;mor past participle&gt; = come.
Notice that, in this last example, the final statement was extensional, not def-
initional. So far in this paper we have almost entirely ignored the distinction we
established between definitional and extensional statements, but with this declarative
reading of global inheritance we can do so no longer. Local inheritance uses definitional
inheritance statements to distribute simple values and global descriptors. The simple-
valued definitional statements thereby defined map directly to extensional statements,
and global inheritance uses the global inheritance statements (now distributed), to fur-
ther distribute these extensional statements about simple values. The statements must
be of a formally distinct type, to prevent local inheritance descriptors from distribut-
ing them still further. In practice, however, we need not be too concerned about the
distinction: descriptions are written as definitional statements, queries are read off as
extensional statements.&amp;quot;
The declarative interpretation of global inheritance suggests an alternative proce-
dural characterization to the one already discussed, which we outline here. Starting
from a query, local descriptors alone are used to determine either a value or a global
descriptor associated with the queried node/path pair. If the result is a global descrip-
tor, this is used to construct a new query, which is evaluated in the same way. The
17 However, in principle, there is nothing to stop an extensional statement from being specified as part of
a DATR description directly. Such a statement would respect global inheritance but not local
inheritance, and might be useful to achieve some exotic effect.
</bodyText>
<page confidence="0.969671">
184
</page>
<bodyText confidence="0.973998722222222">
Evans and Gazdar Lexical Knowledge Representation
process repeats until a value is returned. The difference between this and the earlier
model is one of perspective: When a global descriptor is encountered, one can either
bring the global context to the current evaluation context (first model), or take the
new descriptor back to the global context and continue from there (second model).
The significance of the latter approach is that it reduces both kinds of inheritance to
a single basic operation with a straightforward declarative interpretation. Thus we
see that DATR contains two instances of essentially the same declarative inheritance
mechanism. The first, local inheritance, is always specified explicitly, while the second,
global inheritance, is specified implicitly in terms of the first.
Extending these inheritance mechanisms to the more complex DATR expressions is
straightforward. Descriptors nested within definitional expressions are treated indepen-
dently—as though each was the entire value definition rather than just an item in a
sequence. In particular, global descriptors that alter the global context in one nested
definition have no effect on any others. Each descriptor in a definitional sequence or
evaluable path is evaluated from the same global state. In the case of global evaluable
paths, once the subexpressions have been evaluated, the expression containing the
resultant path is also evaluated from the same global state.
</bodyText>
<subsectionHeader confidence="0.999519">
3.3 Definition by Default
</subsectionHeader>
<bodyText confidence="0.999628111111111">
The other major component of DATR is definition by default. This mechanism allows
a DATR definitional statement to be applicable not only for the path specified in its
left-hand side, but also for any rightward extension of that path for which no more
specific definitional statement exists. In effect, this &amp;quot;fills in the gaps&amp;quot; between paths
defined at a node, on the basis that an undefined path takes its definition from the
path that best approximates it without being more specific.&apos; Of course, to be effective,
this &amp;quot;filling in&amp;quot; has to take place before the operation of the inheritance mechanisms
described in the previous section.
Consider for example, the definition of Do we gave above.
</bodyText>
<equation confidence="0.833056">
Do:
&lt;&gt; == VERB
</equation>
<bodyText confidence="0.708718333333333">
&lt;mor root&gt; == do
&lt;mor past&gt; == did
&lt;mor past participle&gt; == done
&lt;mor present tense sing three&gt; == does.
Filling in the gaps between these definitions, we can see that many paths will be
implicitly defined only by the empty path specification. Examples include:
</bodyText>
<equation confidence="0.529308166666667">
Do:
&lt;mor&gt; == VERB
&lt;syn&gt; == VERB
&lt;mor present&gt; == VERB
&lt;syn cat&gt; == VERB
&lt;syn type&gt; == VERB
</equation>
<bodyText confidence="0.425803">
&lt;mor present tense sing one&gt; == VERB.
If there had been no definition for &lt;&gt;, then none of these example paths would have
</bodyText>
<page confidence="0.8095735">
18 For formal discussion of the semantics of the DATR default mechanism, see Keller (1995).
185
</page>
<note confidence="0.390389">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.98318962962963">
been defined at all, since there would have been no leading subpath with a definition.
Note how &lt;mor&gt; itself takes its definition from &lt;&gt;, since all the explicitly defined
&lt;mor ...&gt; specifications have at least one further attribute.
The definition for &lt;mor past&gt; overrides default definition from &lt;&gt; and in turn
provides a definition for longer paths. However, &lt;mor past participle&gt; blocks de-
fault definition from &lt;mor past&gt;. Thus the following arise:19
Do: &lt;mor past tense&gt; == did
&lt;mor past tense plur&gt; == did
&lt;mor past tense sing three&gt; == did
&lt;mor past participle plur&gt; == done
&lt;mor past participle sing one&gt; == done
Similarly all the &lt;mor present &gt; forms inherit from VERB except for the explicitly cited
&lt;mor present tense sing three&gt;.
Definition by default introduces new DATR sentences, each of whose left-hand-
side paths is an extension of the left-hand-side paths of some explicit sentence. This
path extension carries over to any paths occurring on the right-hand side as well. For
example, the sentence:
VERB:
&lt;mor present tense&gt; == &amp;quot;&lt;mor root&gt;&amp;quot;
&lt;mor form&gt; == &lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;.
gives rise to the following, inter alia:
VERB:
&lt;mor
&lt;mor
&lt;mor
&lt;mor
present tense
present tense
form present&gt;
form passive&gt;
sing&gt; =
plur&gt; =
== &lt;mor
== &lt;mor
&amp;quot;&lt;mor root sing&gt;&amp;quot;
&amp;quot;&lt;mor root plur&gt;&amp;quot;
&amp;quot;&lt;syn form present&gt;&amp;quot; present&gt;
&amp;quot;&lt;syn form passive&gt;&amp;quot; passive&gt;.
This extension occurs for all paths in the right-hand side, whether they are quoted or
unquoted and/or nested in descriptor sequences or evaluable paths.
The intent of this path extension is to allow descriptors to provide not simply a
single definition for a path but a whole set of definitions for extensions to that path,
without losing path information. In some cases this can lead to gratuitous extensions to
paths—path attributes specifying detail beyond any of the specifications in the overall
description. However, this does not generally cause problems since such gratuitously
detailed paths, being unspecified, will always take their value from the most specific
path that is specified; effectively, gratuitous detail is ignored.2° Indeed, DATR&apos;s ap-
proach to default information always implies an infinite number of unwritten DATR
statements, with paths of arbitrary length.
19 The past participle extensions here are purely for the sake of the formal example—they have no role to
play in the morphological description of English (but cf. French, where past participles inflect for
gender and number).
20 Thus, for example, the path &lt;mor &apos;Dior acc&gt; is a gratuitous extension of the path &lt;mor plur&gt; for
English common nouns, since the latter are not differentiated for case.
</bodyText>
<page confidence="0.978847">
186
</page>
<bodyText confidence="0.370355">
Evans and Gazdar Lexical Knowledge Representation
</bodyText>
<subsectionHeader confidence="0.983092">
3.4 Abbreviatory Variables
</subsectionHeader>
<bodyText confidence="0.999954">
The default mechanism of DATR provides for generalization across sets of atoms by
means of path extension, and is the preferred mechanism to use in the majority of
cases. However, to transduce atoms in the path domain to atoms in the value domain
(see Section 4.3, below), it is extremely convenient to use abbreviatory variables over
finite sets of atoms. This is achieved by declaring DATR variables whose use constitutes
a kind of macro: they can always be eliminated by replacing the equations in which
they occur with larger sets of equations that spell out each value of the variables.
Conventionally, variable names begin with the $ character and are declared in one of
the following three ways:
</bodyText>
<listItem confidence="0.9912">
# vars $Varl: Rangel Range2
# vars $Var2: Rangel Range2 - RangeA RangeB .
# vars $Var3.
</listItem>
<bodyText confidence="0.9987454">
Here, the first case declares a variable $Varl that ranges over the values Rangel ,
Range2 ..., where each RangeN is either an atom or a variable name; the second case
declares $Var2 to range over the same range, but excluding values in RangeA RangeB
...; and the third declares $Var3 to range over the full (finite) set of atoms in the
language.21 For example:
</bodyText>
<listItem confidence="0.830636545454546">
# vars netters: abcdef ghijklmno P q rstuvwxy z.
# vars $vowels: aeio u.
• vars $consonants: $letters - $vowels.
# vars $not_z: $letters - z.
# vars $odd: 1 3 5 7 9.
• vars $even: 0 2 6 4 8.
# vars $digit: $odd $even.
Caution has to be exercised in the use of DATR variables for two reasons. One is
that their use makes it hard to spot multiple conflicting definitions:
# vars $vowel: aeio u.
DIPTHONG:
</listItem>
<equation confidence="0.905512">
&lt;e&gt; == e i &lt;&gt;
&lt;$vowel&gt; == $vowel e &lt;&gt;.
</equation>
<bodyText confidence="0.903924125">
Here, &lt;e&gt; appears on the left hand side of two conflicting definitions. Exactly what
happens to such an improper description in practice depends on the implementation,
and usages of this kind can be the source of hard-to-locate bugs (see also Section 5.1,
below).
The other reason is that one can fall into the trap of using variables to express
generalizations that would be better expressed using the path extension mechanism.
Here is a very blatant example:
# vars $number: singular plural.
</bodyText>
<footnote confidence="0.5925235">
21 Undeclared variables are similarly assumed to range over the full set of atoms. Some implementations
may also include implicit definitions of more restricted variables, such as $integer.
</footnote>
<page confidence="0.827105">
187
</page>
<table confidence="0.8938721">
Computational Linguistics Volume 22, Number 2
NOUNX:
&lt;third $number&gt; == &lt;second $number&gt;.
This would almost certainly be better expressed as:
NOUNX:
&lt;third&gt; == &lt;second&gt;.
The following example is a variant on the same theme:
# vars $number: singular plural.
NOUNY:
&lt;$number third&gt; == &lt;$number second&gt;.
</table>
<bodyText confidence="0.9320695">
which suggests not a real need for the use of DATR variables, but rather an inappro-
priate choice of attribute order in the design of the description.
</bodyText>
<sectionHeader confidence="0.959314" genericHeader="method">
4. DATR Techniques
</sectionHeader>
<bodyText confidence="0.999948">
The DATR fragments introduced above illustrate the basic descriptive resources pro-
vided by the language. We now present some further examples, showing how these
basic components combine to provide a powerful representation tool.
</bodyText>
<subsectionHeader confidence="0.999939">
4.1 Case Constructs and Parameters
</subsectionHeader>
<bodyText confidence="0.9999482">
Evaluable paths allow the value of one path to be determined by the value of another.
More generally, the values of an arbitrary number of descriptors can be invoked as pa-
rameters in an evaluable path, and thus determine the value of a particular node/path
pair. The familiar case construct of procedural programming languages is readily im-
plemented, as the following example describing English plural suffixes shows:
</bodyText>
<equation confidence="0.825799714285714">
NOUN:
&lt;plural&gt; == &lt;case of &amp;quot;&lt;origin&gt;&amp;quot;&gt;
&lt;case of latin masculine&gt; == -i
&lt;case of latin neuter&gt; == -a
&lt;case of&gt; == -s
&lt;origin&gt; == norman.
Cat:
&lt;&gt; == NOUN.
Datum:
&lt;&gt; == NOUN
&lt;origin&gt; == latin neuter.
Alumnus:
&lt;&gt; == NOUN
&lt;origin&gt; == latin masculine.
</equation>
<bodyText confidence="0.7411005">
Here the value of the &lt;origin&gt; attribute of a noun (denoting its etymological source)
is used to determine the value of its &lt;plural&gt; suffix. Thus we can derive the following
</bodyText>
<page confidence="0.965356">
188
</page>
<figure confidence="0.83474725">
Evans and Gazdar Lexical Knowledge Representation
extensional statements:
Cat:
&lt;plural&gt; = -s.
Datum:
&lt;plural&gt; = -a.
Alumnus:
&lt;plural&gt; =
</figure>
<bodyText confidence="0.740914454545455">
We do not need to invoke an attribute called case to get this technique to work.
For example, in Section 2, we gave the following definition of &lt;mor form&gt; in terms
of &lt;syn form&gt;:
VERB:
&lt;mor form&gt; == &lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;.
Here the feature &lt;syn form&gt; returns a value (such as passive participle or present
tense sing three) that becomes part of the path through which &lt;mor form&gt; inherits.
This means that nodes for surface word forms need only state their parent lexeme and
&lt;syn form&gt; feature in order for their &lt;mor form&gt; to be fully described.&apos; So, as we
saw in Section 2 above, the passive participle form of sew is fully described by the
node definition for Word3.
</bodyText>
<table confidence="0.973926">
Word3:
&lt;&gt; == Sew
&lt;syn form&gt; == passive participle.
For finite forms, we could use a similar technique. From this:
Word4:
&lt;&gt; == Sew
&lt;syn form&gt; == present sing third.
we would want to be able to infer this:
Word4:
&lt;mor form&gt; = sew s
</table>
<bodyText confidence="0.8909201">
However, the components of &lt;syn form&gt;, present, sing, third are themselves values
of features we probably want to represent independently. One way to achieve this is
to define a value for &lt;syn form&gt; which is itself parameterized from the values of
these other features. And the appropriate place to do this is in the VERB node, thus:
VERB:
&lt;syn form&gt; == &amp;quot;&lt;syn tense&gt;&amp;quot; &amp;quot;&lt;syn number&gt;&amp;quot; &amp;quot;&lt;syn person&gt;&amp;quot;.
This says that the default value for the syntactic form of a verb is a finite form, but
exactly which finite form depends on the settings of three other paths, &lt;syn tense&gt;,
22 More generally, evaluable paths provide structured inheritance in the sense of Daelemans and De
Smedt (1994, 161-468).
</bodyText>
<page confidence="0.941222">
189
</page>
<table confidence="0.755309">
Computational Linguistics Volume 22, Number 2
&lt;syn number&gt;, and &lt;syn person&gt;. Now we can express Word4 as:
Word4:
&lt;&gt; == Sew
&lt;syn tense&gt; == present
&lt;syn number&gt; == sing
&lt;syn person&gt; == third.
</table>
<bodyText confidence="0.9508935">
This approach has the advantage that the attribute ordering used in the &lt;mor &gt;
paths is handled internally: the leaf nodes need not know or care about it.&apos;
</bodyText>
<subsectionHeader confidence="0.995619">
4.2 Boolean Logic
</subsectionHeader>
<bodyText confidence="0.9900185">
We can, if we wish, use parameters in evaluable paths that resolve to true or false.
We can then define standard truth tables over DATR paths:
</bodyText>
<figure confidence="0.578053375">
Boolean:
&lt;&gt; == false
&lt;or&gt; == true
&lt;if&gt; == true
&lt;not false&gt; == true
&lt;and true true&gt; == true
&lt;if true false&gt; == false
&lt;or false false&gt; == false.
</figure>
<bodyText confidence="0.999835538461538">
This node defines the standard truth tables for all the familiar operators and connec-
tives of the propositional calculus expressed in Polish order rather than infix order.&apos;
Notice, in particular, how the DATR default mechanism completes most of the truth
table rows without explicit listing. The definability of the propositional calculus may
appear, at first sight, to be a curiosity, one which has no relevance to real-life lexical
representation. But that is not so. Consider a hypothetical language in which personal
proper names have one of two genders, masculine or feminine. Instead of the gender
being wholly determined by the sex of the referent, the gender is determined partly
by sex and partly by the phonology. Examples of this general type are quite common
in the world&apos;s languages. In our hypothetical example, the proper name will have
feminine gender either if it ends in a consonant and denotes a female or if it ends in
a stop consonant but does not denote a female. We can encode this situation in DATR
as follows:&amp;quot;
</bodyText>
<equation confidence="0.886107666666667">
Personal_name:
&lt;&gt; == Boolean
&lt;ends_in_consonant&gt; == &amp;quot;&lt;ends_in_stop&gt;&amp;quot;
</equation>
<bodyText confidence="0.767687777777778">
23 Word3 remains unchanged, overriding the definition of &lt;syn f orm&gt; and so not requiring these
additional features to be defined at all.
24 We can, of course, use the same technique to define many-valued logics if we wish.
25 For example, Fraser and Corbett (1995) use DATR to capture a range of
phonology/morphology/semantics interdependencies in Russian. And Brown and Hippisley (1994) do
the same for a Russian segmental phonology/prosody/morphology interdependency. But one can find
such interdependencies in English also: see Ostler and Atkins (1992, 96-98).
26 Note that complex expressions require path embedding. Thus, for example, the well-formed negation
of a conditional is &lt;not &lt;if ...&gt;&gt; rather than &lt;not if ...&gt;.
</bodyText>
<page confidence="0.93903">
190
</page>
<figure confidence="0.546387421052631">
Evans and Gazdar Lexical Knowledge Representation
&lt;gender_is_feminine&gt; ==
&lt;or &lt;and &amp;quot;&lt;female_referent&gt;&amp;quot; &amp;quot;&lt;ends_in_consonant&gt;&amp;quot;&gt;
&lt;and &lt;not &amp;quot;&lt;female_referent&gt;&amp;quot;&gt; &amp;quot;&lt;ends_in_stop&gt;&amp;quot;&gt;&gt;.
We can then list some example lexical entries for personal proper names:2&apos;
Taruz:
&lt;&gt; == Personal_name
&lt;female_referent&gt; == true
&lt;ends_in_consonant&gt; == true.
Turat:
&lt;&gt; == Personal_name
&lt;female_referent&gt; == true
&lt;ends_in_stop&gt; == true.
Tarud:
&lt;&gt; == Personal_name
&lt;ends_in_stop&gt; == true.
Turas:
&lt;&gt; == Personal_name
&lt;ends_in_consonant&gt; == true.
</figure>
<bodyText confidence="0.984313857142857">
Note that both Turas and Tarud turn out not to denote females, given the general
false default in Boolean.&apos; The genders of all four names can now be obtained as
theorems:
Taruz: &lt;gender_is_feminine&gt; = true.
Turat: &lt;gender_is_feminine&gt; = true.
Tarud: &lt;gender_is_feminine&gt; = true.
Turas: &lt;gender_is_feminine&gt; = false.
</bodyText>
<subsectionHeader confidence="0.997757">
4.3 Finite-state Transduction
</subsectionHeader>
<bodyText confidence="0.994178571428572">
Perhaps surprisingly, DATR turns out to be an excellent language for defining finite-
state transducers (FSTs).&apos; A path can be used as the input tape and a value as the
output tape (recall that the DATR default mechanism means that extensions to left-
hand-side paths are automatically carried over as extensions to right-hand-side paths,
as discussed in Section 3.3, above). Nodes can be used for states, or else states can be
encoded in attributes that are prefixed to the current input path. Here, for example, is
a very simple DATR FST that will transduce a path such as &lt;subj 1 sg futr obj 2
27 For the sake of simplicity, we have assumed that the truth values of &lt;ends_in_consonant&gt; and
&lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name
means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the
phonology of the words in DATR also, then these predicates could be defined on the basis of the
feature composition of the stem-final segment. As a number of researchers have shown, the highly
defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of
representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991;
</bodyText>
<footnote confidence="0.69965025">
Reinhard 1990; Reinhard and Gibbon 1991).
28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when
&lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false,
or conversely.
</footnote>
<page confidence="0.801231666666667">
29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description
language.
191
</page>
<table confidence="0.950621">
Computational Linguistics Volume 22, Number 2
sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos;
Si: 1 sg&gt; == ni S2:&lt;&gt;
&lt;subj 2 sg&gt; == u S2:&lt;&gt;
&lt;subj 3 sg&gt; =1= a 52:&lt;&gt;
&lt;subj 1 pl&gt; == tu S2:&lt;&gt;
&lt;subj 2 pl&gt; == m S2:&lt;&gt;
&lt;subj 3 pl&gt; == wa S2:&lt;&gt;.
&lt;subj
</table>
<equation confidence="0.799292444444444">
&lt;past&gt; == li 53:&lt;&gt;
&lt;futr&gt; == ta S3:&lt;&gt;.
&lt;obj 1 sg&gt; == ni S4:&lt;&gt;
&lt;obj 2 sg&gt; == ku S4:&lt;&gt;
&lt;obj 3 sg&gt; == m S4:&lt;&gt;
&lt;obj 1 pl&gt; == tu 54:&lt;&gt;
&lt;obj 2 pl&gt; == wa 54:&lt;&gt;
&lt;obj 3 pl&gt; == wa 54:&lt;&gt;.
&lt;like&gt; == penda.
</equation>
<bodyText confidence="0.9999765">
Although the example is trivial, the technique is both powerful and useful. Gibbon
(1990), for example, has made notably effective use of it in his treatments of African
tone systems.&apos; Much of the computational phonology and morphology of the last
decade and a half has depended on FSTs (Kaplan and Kay 1994). Potential lexical
applications come readily to mind—for example, the orthographic spelling rules for
English suffixation (such as sky/skies). We give below a small fragment of such an FST
in which + is used as a morpheme boundary marker. Note the role of DATR variables
in giving concise expression to the rules:
</bodyText>
<listItem confidence="0.637752">
# vars $abc:abcdefghijklmnopqrstuvwxyz.
# vars $vow: ae io u.
</listItem>
<equation confidence="0.846202">
SPELL:
&lt;&gt; ==
&lt;+&gt; == &lt;&gt;
&lt;$abc&gt; == $abc &lt;&gt;
&lt;e + $vow&gt; == $vow &lt;&gt;.
</equation>
<bodyText confidence="0.923563">
These axioms then give rise to theorems such as these:
</bodyText>
<figure confidence="0.981532">
SPELL:
&lt;1 o v e&gt; =love
&lt;1 o v e + s&gt; =loves
&lt;love+ed&gt; =loved
&lt;love+er&gt; =lover
&lt;love+ly&gt; =lovely
</figure>
<footnote confidence="0.690769333333333">
30 For clarity, this FST does not exploit default inheritance to capture the 50% overlap between the subject
and object pronoun paradigms. See Gazdar (1992) for a version that does.
31 And see McFetridge and Villavicencio (1995) for a less exotic application.
</footnote>
<page confidence="0.937632">
192
</page>
<figure confidence="0.857913666666667">
Evans and Gazdar Lexical Knowledge Representation
&lt;love+ing&gt; =loving
&lt;love+able&gt; lovable.=
</figure>
<subsectionHeader confidence="0.974293">
4.4 Representing Lists
</subsectionHeader>
<bodyText confidence="0.987578666666666">
DATR&apos;s foundation in path/value specifications means that many of the representa-
tional idioms of unification formalisms transfer fairly directly. A good example is the
use of first and rest attributes to represent list-structured features, such as syntactic
arguments and subcategorized complements. The following definitions could be used
to extend our verb fragment by introducing the path &lt;syn args&gt;, which determines
a list of syntactic argument specifications:
</bodyText>
<table confidence="0.456921222222222">
NIL:
&lt;&gt; == nil
&lt;rest&gt; == UNDEF
&lt;first&gt; == UNDEF.
VERB:
&lt;syn cat&gt; == verb
&lt;syn args first syn cat&gt; == np
&lt;syn args first syn case&gt; == nominative
&lt;syn args rest&gt; == NIL:&lt;&gt;.
</table>
<bodyText confidence="0.998762625">
Here extensions of &lt;syn args first&gt; specify properties of the first syntactic argu-
ment, while extensions of &lt;syn args rest&gt; specify the others (as a first/rest list).
UNDEF is the name of a node that is not defined in the fragment, thus ensuring that
&lt;syn args rest first&gt;, &lt;syn args rest rest&gt;, and so forth, are all undefined.
The fragment above provides a default specification for &lt;syn args&gt; for verbs con-
sisting of just one argument, the subject NP. Subclasses of verb may, of course, override
any part of this default; for instance, transitive verbs add a second syntactic argument
for their direct object:
</bodyText>
<table confidence="0.861351722222222">
TR_VERB:
&lt;&gt; == VERB
&lt;syn args rest first syn cat&gt; == np
&lt;syn args rest first syn case&gt; == accusative
&lt;syn args rest rest&gt; == NIL:&lt;&gt;.
The description can be improved by using a separate node, NP_ARG, to represent the
(default) properties of noun-phrase arguments:
NP_ARG:
&lt;first syn cat&gt; == np
&lt;first syn case&gt; == accusative
&lt;rest&gt; == NIL:&lt;&gt;.
VERB:
&lt;syn cat&gt; == v
&lt;syn args&gt; == NP_ARG:&lt;&gt;
&lt;syn args first syn case&gt; == nominative.
TR_VERB:
&lt;&gt; == VERB
&lt;syn args rest&gt; == NP_ARG:&lt;&gt;.
</table>
<page confidence="0.884396">
193
</page>
<note confidence="0.552095">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.985082636363636">
TR_VERB accepts the NP_ARG default unconditionally for the direct object argument,
but VERB overrides the default case for its subject argument. The effect of the empty
path (&lt;&gt;) specification in the NP_ARG inheritances is to &amp;quot;strip off&amp;quot; the leading subpath
from the path whose value is inherited. The default mechanism adds the same path
extension to both sides, giving rise to statements such as the following:
VERB:&lt;syn args first syn cat&gt; == NP_ARG:&lt;first syn cat&gt;.
TR_VERB:&lt;syn args rest first syn cat&gt; == NP_ARG:&lt;first syn cat&gt;.
TR_VERB:&lt;syn args rest first syn case&gt; == NP_ARG:&lt;first syn case&gt;.
Three-element argument lists, such as that needed for ditransitive verbs, are con-
structed in the obvious way (where PP_ARG is assumed to be like NP_ARG but for prepo-
sitional phrase complements):
</bodyText>
<table confidence="0.43148">
DI_VERB:
== TR_VERB
&lt;syn args rest rest&gt; == PP_ARG:&lt;&gt;.
</table>
<subsectionHeader confidence="0.996983">
4.5 Lexical Rules
</subsectionHeader>
<bodyText confidence="0.797659258064516">
A lexical representation language must be able to express the relations that are now
widely thought to be in the domain of lexical rules.&apos; Canonically, such rules deal
with the phenomena that used to be described by the &amp;quot;cyclic rules&amp;quot; of late 1960s
transformational grammar. Characteristically, they pertain to rather specific classes of
lexical items (e.g., transitive verbs, or tensed auxiliary verbs) and they are subject to
exceptions of various kinds.&apos; It is these characteristics that have led many linguists to
consign them to the lexicon. They usually involve a difference in argument structure
and this is sometimes accompanied by a morphological difference. The combination
of evaluable paths with a standard encoding of argument lists make it rather easy to
define lexical rules in DATR.34
Here, by way of illustration, is a partial analysis of verbs that implements a lexical
rule for the syntax of the (agentless) passive construction:&apos;
VERB: past&gt; = = &amp;quot;&lt;mor root&gt;&amp;quot; ed
&lt;mor form&gt; = = &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot;
&lt;mor cat&gt; == verb
&lt;syn sub c at &gt; == &amp;quot;&lt;syn args&gt;&amp;quot;
&lt;syn
32 See Carpenter (1991; 1992) and Ritchie et al. (1992, 93-111) for thorough discussion and exemplification
of lexical rules in several different grammatical frameworks. More generally, Briscoe and Copestake
(1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the
very same lexical rule mechanism can be invoked for both sense extensions and morphological
processes.
33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the
lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazdar,
and Weir (1995) report the use of DATR to formulate a lexical rule for Wh-questions in LTAG, inter alia.
34 Evaluable paths are not essential in this domain: thus Kilgarriff (1993) does not employ them in his
DATR analysis of verbal alternations in the context of an H PSG lexicon, although he does use the
standard encoding of argument lists.
35 Since our purpose here is expository, we have deliberately kept the analysis to a minimum. Dealing
with the semantics of passive, for example, involves more of the same, rather than any issue of
principle.
</bodyText>
<page confidence="0.987739">
194
</page>
<figure confidence="0.511363928571429">
Evans and Gazdar Lexical Knowledge Representation
&lt;syn args&gt; == NP_ARG:&lt;&gt;
&lt;syn args first syn case&gt; == nominative.
PASSIVE_VERB:
&lt;&gt; == VERB
&lt;mor passive&gt; == &amp;quot;&lt;mor past&gt;&amp;quot;
&lt;syn subcat rest&gt; == &amp;quot;&lt;syn args rest rest&gt;&amp;quot;.
TR_VERB:
&lt;syn args rest&gt; == NP_ARG:&lt;&gt;
&lt;&gt; == &lt;&lt;mood &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&gt;
&lt;mood&gt; == active
&lt;mood passive&gt; == passive
&lt;active&gt; == VERB:&lt;&gt;
&lt;passive&gt; == PASSIVE_VERB:&lt;&gt;.
</figure>
<bodyText confidence="0.999504952380952">
This example introduces several new techniques. Firstly, in TR_VERB we have a double
parametrization on &lt;syn form&gt;: the value of &lt;syn form&gt; is evaluated and used to
create a &lt;mood&gt; path; the value returned by this path is then used to route the in-
heritance. This allows us to employ the default mechanism to make the default mood
active (for arbitrary &lt;syn form&gt; values other than those that begin with the atom
passive), and thus just pick out &lt;syn form&gt; passive (and its extensions) for verbs
in the passive mood. Secondly, &lt;active&gt; and &lt;passive&gt; path prefixes are provided
for the explicit purpose of controlling the inheritance route. Thirdly, the example pre-
supposes a distinction between the syntactic arguments list (&lt;syn args&gt;) associated
with a lexeme and the subcategorization frame list (&lt;syn subcat&gt;) associated with a
particular syntactic form of a lexeme. If the mood of the form is active (and the TR_VERB
node says that anything that is not passive is active), then the subcategorization frame
is the same as the argument list. But if the mood of the form is passive, then the part
of the subcategorization frame that deals with objects and complements is stripped of
its first item—i.e., its direct object. By default, this dependency of subcategorization
frame on mood will be inherited by all the descendants of TR_VERB, whether these be
instances of simple transitive verb lexemes or nodes defining specific types of tran-
sitive verbs (ditransitives, object-plus-infinitive verbs, bet-class verbs, etc.) and their
descendants. Thus, if we assume, for example, that the lexeme Donate is an instance
of DI_VERB as defined above, and that Word5 and Word6 are inflected tokens of Donate,
then we will be able to derive the following theorems:
</bodyText>
<table confidence="0.988498533333333">
Word5:
&lt;mor form&gt; = donate ed
&lt;syn form&gt; = past tense
&lt;syn subcat first syn cat&gt; = np
&lt;syn subcat first syn case&gt; = nominative
&lt;syn subcat rest first syn cat&gt; = np
&lt;syn subcat rest first syn case&gt; = accusative
&lt;syn subcat rest rest first syn cat&gt; = pp
&lt;syn subcat rest rest first syn pform&gt; = to
&lt;syn subcat rest rest rest&gt; = nil.
Word6:
&lt;mor form&gt; = donate ed
&lt;syn form&gt; = passive participle
&lt;syn subcat first syn cat&gt; = np
&lt;syn subcat first syn case&gt; = nominative
</table>
<page confidence="0.948801">
195
</page>
<note confidence="0.567911">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.9808026">
&lt;syn subcat rest first syn cat&gt; = pp
&lt;syn subcat rest first syn pform&gt; = to
&lt;syn subcat rest rest&gt; = nil.
Finally, notice that the equation that specifies passive morphology appears on the
PASSIVE_VERB node. This ensures that passive morphology is undefined for verbs not
syntactically passive.
The techniques used in this rather simple treatment of passive can be readily
adapted for use in encoding other lexical rules and for grammatical frameworks other
than that implicit in the PAT Rish syntax we have adopted in our example. Thus, Evans,
Gazdar, and Weir (1995) formulate various lexical rules for LTAG (see note 33). These
techniques can also be readily adapted for use in the semantic domain and used, for
example, to implement the distinction between fixed and projective inheritance of
lexical semantic information proposed by Pustejovsky (1991, 433-437).
It is advantageous to express lexical rules in the same formal language as is used
to express the lexical hierarchy, since lexical rules themselves may well exhibit exactly
the kinds of defaulty relations, one to another, that lexical classes do.&apos; Thus a lexical
rule for direct Wh-questions may be a variant of that for indirect Wh-questions: similar,
sharing components, but not identical. With a suitable degree of abstraction, achieved
by parameterization of the components, lexical rules can be reified in a language like
DATR, allowing one to inherit from another.
</bodyText>
<subsectionHeader confidence="0.999918">
4.6 Representing Ambiguity and Alternation
</subsectionHeader>
<bodyText confidence="0.979881375">
DATR is a language that allows the lexicon writer to define sets of partial functions
from sequences of atoms to sequences of atoms. That is actually all that it allows
the lexicon writer to do. Because DATR deals in functions, it does not embody any
notion of disjunction or any possibility of multiple values being associated with a
single node/path pair. It might seem, at first glance, that such a language would be
quite inappropriate to a domain such as the lexicon, where ambiguities are common.
In practice, however, this turns out not to be the case. Consider the homonymy of
bank:
</bodyText>
<equation confidence="0.908317875">
Bankl:
&lt;&gt; == NOUN
&lt;mor root&gt; == bank
&lt;sem gloss&gt; == side of river.
Bank2:
&lt;&gt; == NOUN
&lt;mor root&gt; == bank
&lt;sem gloss&gt; == financial institution.
</equation>
<bodyText confidence="0.9898875">
This is simply the traditional analysis of homonymy, encoded in DATR: there are two
entirely distinct lexemes, with unrelated meanings, that happen both to be nouns and
to have indistinguishable morphological roots.
Or consider the polysemy of cherry:37
</bodyText>
<page confidence="0.916073">
36 Cf. Krieger (1994, 279) who notes some other advantages.
</page>
<bodyText confidence="0.85172375">
37 The example is due to Kilgarriff (1995) who shows that the kind of polysemy exhibited by cherry
applies generally to fruit trees and can thus be specified at a higher node in the lexical network,
removing the need for stipulation (as in our example) at the Cherry node, the Apple node, and so on.
Kilgarriff and Gazdar (1995) also present an extended example showing how DATR can be used to
</bodyText>
<page confidence="0.990649">
196
</page>
<figure confidence="0.891751">
Evans and Gazdar Lexical Knowledge Representation
Cherry:
&lt;&gt; == NOUN
&lt;mor root&gt; == cherry
</figure>
<figureCaption confidence="0.804055333333333">
&lt;sem gloss 1&gt; == sweet red berry with pip
&lt;sem gloss 2&gt; == tree bearing &lt;sem gloss 1&gt;
&lt;sem gloss 3&gt; == wood from &lt;sem gloss 2&gt;.
</figureCaption>
<bodyText confidence="0.994979444444444">
Again, this is a rather traditional analysis. There are (at least) three distinct but related
senses.&apos; They are not freely interchangeable alternative values for a single attribute
or path. Instead, DATR allows their relatedness of meaning to be captured by using
the definition of one in the definition of another.
A very few words in English have alternative morphological forms for the same
syntactic specification. An example noted by Fraser and Hudson (1990, 62) is the plural
of hoof which, for many English speakers, can appear as both hoofs and hooves.&apos; DATR
does not permit a theorem set such as the following to be derived from a consistent
description:
</bodyText>
<figure confidence="0.927097210526316">
Word7:
&lt;syn number&gt; = plural
&lt;mor form&gt; = hoof s
&lt;mor form&gt; = hoove s.
But it is quite straightforward to define a description that will lead to the following
theorem set:
Word7:
&lt;syn number&gt; = plural
&lt;mor form&gt; = hoof s
&lt;mor form alternant&gt; = hoove s.
Or something like this:
Word7:
&lt;syn number&gt; = plural
&lt;mor forms&gt; = hoof s I hoove s
Or this:
Word7:
&lt;syn number&gt; = plural
&lt;mor forms&gt; = { hoof s , hoove s I.
Of course, as far as DATR is concerned { hoof s , hoove s } is just a sequence
</figure>
<footnote confidence="0.749337">
encode the regular and subregular polysemy associated with the crop, fiber, yarn, fabric, and garment
senses of words like cotton and silk. See also Copestake and Briscoe (1995) for related work on regular
and subregular polysemy.
38 For perspicuity, we provide these in DATR-augmented English here. But in a serious treatment they
could just as well be given in a DATR-encoding of the lambda calculus, as used in Cahill and Evans
(1990), for example.
</footnote>
<page confidence="0.797453">
39 See also the dreamt/dreamed verb class discussed by Russell et al. (1992, 330-331).
197
</page>
<note confidence="0.620215">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.9986925">
of seven atoms. It is up to some component external to DATR that makes use of such
complex values to interpret it as a two-member set of alternative forms. Likewise, if
we have some good reason for wanting to put together the various senses of cherry
into a value returned by a single path, then we can write something like this:
</bodyText>
<figure confidence="0.690451888888889">
Cherry:
&lt;sem glosses&gt; == { &lt;sem gloss 1&gt; , &lt;sem gloss 2&gt; , &lt;sem gloss 3&gt; }.
which will then provide this theorem:
Cherry:
&lt;sem glosses&gt; = { sweet red berry with pip ,
tree bearing sweet red berry with pip ,
wood from tree bearing sweet red berry with pip }.
Also relevant here are the various techniques for reducing lexical disjunction dis-
cussed in Pulman (forthcoming).
</figure>
<subsectionHeader confidence="0.997861">
4.7 Encoding DAGs
</subsectionHeader>
<bodyText confidence="0.999825666666667">
As a feature-based formalism with a syntax modeled on PATR, it would be reasonable
to expect that DATR can be used to describe directed acyclic graphs (DAGs) in a
PATR-like fashion. Consider an example such as the following:
</bodyText>
<equation confidence="0.5659495">
DAG1:
&lt;vp agr&gt; == &lt;v agr&gt;
&lt;v agr per&gt; == 3
&lt;vp agr gen&gt; == masc.
</equation>
<bodyText confidence="0.981230833333333">
This looks like simple re-entrancy, from which we would expect to be able to infer:
DAG1:
&lt;vp agr per&gt; = 3.
And, indeed, this turns out to be valid. But matters are not as simple as the example
makes them appear: if DAG1 was really the DAG it purports to be, then we would also
expect to be able to infer:
</bodyText>
<equation confidence="0.8229055">
DAG1:
&lt;v agr gen&gt; = masc.
</equation>
<bodyText confidence="0.8687145">
This, however, is not valid; in fact, &lt;v agr gen&gt; is undefined. It might be tempting to
conclude from this that the equality operator in DATR is very different from the corre-
sponding operator in PATR, but this would be to misunderstand what has happened
in this example. In fact, the semantics of the statement
DAG1:
&lt;vp agr&gt; == &lt;v agr&gt;.
taken in isolation is very similar to the semantics of the corresponding PATR statement:
both assert equality of values associated with the two paths. The DATR statement is
</bodyText>
<page confidence="0.990301">
198
</page>
<note confidence="0.424444">
Evans and Gazdar Lexical Knowledge Representation
</note>
<bodyText confidence="0.99886975">
slightly weaker in that it allows the left-hand side to be defined when the right-hand
side is undefined, but, even in DATR, if both sides are defined they must be the same,
so in principle, the value of the left-hand side does semantically constrain the value
of the right-hand side. However, in a DATR description, specifying explicit values for
extensions of the left-hand side of such an equality constraint overrides its effect, and
thus does not influence the values on its right-hand side.
Another difference lies in the fact that DATR subpaths and superpaths can have
values of their own:
</bodyText>
<equation confidence="0.815602555555555">
DAG2:
&lt;v agr&gt; == sing
&lt;v agr per&gt; == 3.
From this little description we can derive the following statements, inter alia:
DAG2:
&lt;v agr&gt; = sing
&lt;v agr num&gt; = sing
&lt;v agr per&gt; = 3
&lt;v agr per num&gt; = 3.
</equation>
<bodyText confidence="0.999576">
From the perspective of a standard untyped DAG-encoding language like PATR, this
is strange. In PATR, if &lt;v agr per&gt; has value 3, then neither &lt;v agr&gt; nor &lt;v agr
per num&gt; can have (atomic) values.
As these examples clearly show, DATR descriptions do not map trivially into (sets
of) standard DAGs (although neither are they entirely dissimilar); but that does not
mean that DATR descriptions cannot describe standard DAGs. Indeed, there are a va-
riety of ways in which this can be done. An especially simple approach is possible
when the DAGs one is interested in are all built out of a set of paths whose identity is
known in advance (Kilbury, Naerger, and Renz 1991). In this case, we can use DATR
paths as DAG paths, more or less directly:
</bodyText>
<equation confidence="0.831173076923077">
PRONOUN2:
&lt;referent&gt; == &apos;&lt;&amp;quot;NP&apos; referent &apos;&gt;&apos;.
She2:
&lt;&gt; == PRONOUN2
&lt;case&gt; == nominative
&lt;person&gt; == third
&lt;number&gt; == singular.
From this description, we can derive the following theorems:
She2:
&lt;case&gt; = nominative
&lt;person&gt; = third
&lt;number&gt; = singular
&lt;referent&gt; = &lt; NP referent &gt;
</equation>
<bodyText confidence="0.650255">
We can also derive the following un-DAG-like consequences, of course:
She2:
</bodyText>
<page confidence="0.971115">
199
</page>
<note confidence="0.46803">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.91147875">
&lt;case person&gt; = nominative
&lt;person number&gt; = third
&lt;referent referent referent&gt; = &lt; NP referent &gt;.
But these nonsensical theorems will be of no concern to a DAT R-invoking NLP system
that is able to specify in advance which paths are of interest for DAG-construction
and to ignore all the rest.&amp;quot;
A more sophisticated approach uses DATR itself to construct a DAG description
(in the notation of your choice) as a value:4&apos;
</bodyText>
<equation confidence="0.981370578947368">
IDEM:
&lt;&gt; ==
&lt;$atom&gt; == $atom &lt;&gt;.
PATH:
&lt;&gt; == &apos;&lt;&apos; IDEM &apos;&gt;&apos;.
LHS_EQ:
&lt;&gt; == PATH &apos;=&apos;.
LHS_EQ_RHS:
&lt;&gt; == LHS_EQ
PRONOUN1:
&lt;dag&gt; == [ LHS_EQ_RHS:&lt;case&gt;
LHS_EQ_RHS:&lt;person&gt;
LHS_EQ_RHS:&lt;number&gt;
LHS_EQ:&lt;referent&gt; PATH:&lt;&apos;NP&apos; referent&gt; ]
She1:
&lt;&gt; == PRONOUN1
&lt;case&gt; == nominative
&lt;person&gt; == third
&lt;number&gt; == singular.
</equation>
<bodyText confidence="0.471354">
From this description, we can derive the following theorem:
She1:
</bodyText>
<listItem confidence="0.756592">
&lt;dag&gt; = [ &lt; case &gt; = nominative
&lt; person &gt; = third
&lt; number &gt; = singular
&lt; referent &gt; = &lt; NP referent &gt; ].
</listItem>
<bodyText confidence="0.99981875">
The sequence of atoms on the right-hand side of this equation is just a sequence of
atoms as far as DATR is concerned. But a grammar or a parser that expects to see
DAGs represented as they are here can interpret the DATR values as easily as it can
the contents of a file.&apos;
</bodyText>
<footnote confidence="0.991836111111111">
40 In this connection, see the discussion of &amp;quot;closure definitions&amp;quot; in Andry et al. (1992, 259-261).
41 This approach is due to recent unpublished work by Jim Kilbury. He has shown that the same DATR
theorems can have their values realized as conventional attribute-value matrix representations, Prolog
terms, or expressions of a feature logic, simply by changing the fine detail of the transducer employed.
42 Indeed, it will be interpreting the contents of a file if DATR has been used to define a lexicon that has
subsequently been compiled out, rather than being accessed directly by components of the NLP system
(see Section 5.3, below). We are not, of course, claiming that textual representations will standardly
provide the optimal interface between an implementation of DATR and the larger NLP system in
which it is embedded (cf., e.g., Duda and Gebhardi 1994).
</footnote>
<page confidence="0.989421">
200
</page>
<bodyText confidence="0.35029">
Evans and Gazdar Lexical Knowledge Representation
</bodyText>
<sectionHeader confidence="0.893698" genericHeader="method">
5. Technical Issues
</sectionHeader>
<bodyText confidence="0.9998815">
In this section we briefly discuss a number of technical issues, relating both to DATR
as a formal language, and also to practical aspects of DATR in use.
</bodyText>
<subsectionHeader confidence="0.996512">
5.1 Functionality
</subsectionHeader>
<bodyText confidence="0.999374">
Most DATR descriptions consist only of definitional statements, and include at most
one statement for each node/path pair. In this section we examine the significance of
this observation from a formal perspective. As noted in Section 2, DATR nodes can be
thought of semantically as denoting partial functions from paths (sequences of atoms)
to values (sequences of atoms).&apos; Generalizing this view in the obvious way, whole
DATR descriptions can be thought of as denoting functions from nodes to (partial)
functions from paths to values. This semantic notion induces a notion of consistency
for DATR descriptions: we say that a DATR description is consistent if and only if it
has a coherent interpretation as a function; that is, if the extensional sentences defined
(explicitly or implicitly) for each node constitute a (partial) function from paths to
values.
The syntax of DATR does not itself prevent one from writing down inconsistent
descriptions:
</bodyText>
<equation confidence="0.350561666666667">
VERB:
&lt;syn cat&gt; == verb
&lt;syn cat&gt; == noun.
</equation>
<bodyText confidence="0.99989094117647">
However, such descriptions are of no utility and it would be desirable to find a me-
chanical way of eliminating them. In pursuit of this, we can define a syntactic notion
of functionality over DATR descriptions as follows:
A DATR description is functional if and only if (i) it contains only
definitional statements and (ii) those statements constitute a (partial)
function from node/path pairs to descriptor sequences.
The significance of this syntactic notion arises from the following property:44
Every functional DATR description is consistent.
To understand why this is, note first that the default extension process preserves func-
tionality since it only adds definitional statements about new node/path pairs not
already present in the original description. Local inheritance derives new statements
associated with a node/path pair, but at most one of these defines a value or global
inheritance descriptor (since local inheritance ceases at that point). Thus although the
local inheritance makes the description become syntactically nonfunctional, the spec-
ification of values or global descriptors remains functional. The value specifications
map directly to extensional statements, while the global inheritance descriptors oper-
ate just as the local ones, adding at most one further value statement for each global
</bodyText>
<footnote confidence="0.4771354">
43 We continue to oversimplify matters here. As Keller (1995) points out, the meaning of a node depends
on the global context, and a node thus really denotes a function from global contexts to partial
functions from paths to values. Though important, this point is tangential to the issue addressed here.
44 For simplicity here, we consider only the case of descriptor sequences of length one—the general case
involves complications not relevant to the main point.
</footnote>
<page confidence="0.990454">
201
</page>
<note confidence="0.69857">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.96342575">
inheritance statement, so that ultimately the consistency of the set of (extensional)
value statements is assured.
This theorem cannot be strengthened to a biconditional, however, since consistent
but nonfunctional DATR descriptions exist, as in the following examples:
</bodyText>
<figure confidence="0.985099090909091">
NONFUNC1:
&lt;a&gt; == UNDEF
&lt;a&gt; == 1.
NONFUNC2:
&lt;a&gt; == &lt;b&gt;
&lt;a&gt; == 1
&lt;b&gt; == 1.
NONFUNC3:
&lt;a&gt; == &lt;b&gt;
&lt;b&gt; == &lt;a&gt;
&lt;a&gt; == 1.
</figure>
<bodyText confidence="0.999821842105263">
In NONFUNC1, UNDEF is a node with no associated definitions, so the first statement
imposes no constraint on the value of &lt;a&gt;; in NONFUNC2, two definitions for &lt;a&gt; are
provided, which happen to define the same value; in NONFUNC3, we establish a mutual
dependence between &lt;a&gt; and &lt;b&gt;, and then define a value for one (either) of them.
However, we have not encountered any examples of nonfunctional but consistent de-
scriptions that are not better expressed by a straightforward functional counterpart.&apos;
Indeed, we suspect (but have no proof) that every consistent DATR description is exten-
sionally equivalent to (that is, defines the same extensional sentences as) a functional
one.
In the light of these considerations, we assume here, and elsewhere, that func-
tionality is a reasonable restriction to place on DATR descriptions.&amp;quot; The advantage of
this is that to check the functionality of a DATR description, and hence guarantee its
consistency, is completely trivial. In other words, we can substitute a straightforward
syntactic constraint on descriptions for the less tractable notion of semantic consis-
tency, apparently without significant loss of expressive power. Among other things,
this means that implementations of DATR can either treat apparent violations of func-
tionality as syntactic errors and require the user to eliminate them, or (more commonly
in existing implementations) treat them as intentional corrections and silently erase
earlier statements for the node and path for which a violation has been detected.
</bodyText>
<subsectionHeader confidence="0.999506">
5.2 Multiple Inheritance
</subsectionHeader>
<bodyText confidence="0.9988694">
Multiple inheritance, in inheritance network terminology, describes any situation
where a node in an inheritance network inherits information from more than one
other node in the network. Wherever this phenomenon occurs there is the potential
for conflicting inheritance, i.e., when the information inherited from one node is in-
consistent with that inherited from another. Because of this, the handling of multiple
</bodyText>
<footnote confidence="0.916413333333333">
45 NONFUNC3 perhaps comes closest, but adding statements about extensions of either &lt;a&gt; or &lt;b&gt;
quickly breaks the illusion that the two are in some sense &amp;quot;unified.&amp;quot;
46 This only applies to original source descriptions: as we mentioned above, the formal inference
mechanisms that implement inheritance necessarily add statements to make a description
nonfunctional, but since these can always be automatically determined, they need never appear
explicitly in source descriptions.
</footnote>
<page confidence="0.990666">
202
</page>
<note confidence="0.523394">
Evans and Gazdar Lexical Knowledge Representation
</note>
<bodyText confidence="0.999348090909091">
inheritance is an issue central to the design of any formalism for representing inheri-
tance networks.
For the formalism to be coherent, it must provide a way of avoiding or resolving
any conflict that might arise. This might be by banning multiple inheritance altogether,
restricting it so that conflicts are avoided, providing some mechanism for conflict
resolution as part of the formalism itself, or providing the user of the formalism with
the means to specify how the conflict should be resolved. Putting aside considerations
of functionality for the moment, we see that, in DATR, both the second and third of
these options are employed. The &amp;quot;longest-defined-subpath-wins&amp;quot; principle amounts
to conflict resolution built into the formalism; however, it does not deal with every
case. Definitions such as:
</bodyText>
<equation confidence="0.985246333333333">
Node3:
&lt;&gt; == Nodel
&lt;&gt; == Node2.
</equation>
<bodyText confidence="0.999385666666667">
may result in unresolvable conflicts. Such conflicts could, of course, just be ruled out
by appealing to their inconsistency, which, following a logical tradition, is grounds for
ruling the description to be &amp;quot;improper.&amp;quot;
Touretzky (1986, 70ff) provides a formal description of a number of properties
that an inheritance network may have, and discusses their significance with respect to
the problem of multiple inheritance. Tree-structured networks, as their name suggests,
allow any node to inherit from at most one other node, so multiple inheritance conflicts
cannot arise. Orthogonal networks allow a node to inherit from more than one other
node, but the properties it inherits from each must be disjoint, so that again, no conflict
can possibly arise.
The basic descriptive features of DATR allow the specification of simple orthogonal
networks similar to Touretzky&apos;s. For example, if we write:
</bodyText>
<figure confidence="0.91943025">
&lt;a&gt; == true.
&lt;b&gt; == false.
&lt;a&gt; == A
&lt;b&gt; == B.
</figure>
<bodyText confidence="0.9983925">
then we are specifying a network of three nodes (A B, and C), and two &amp;quot;predicates&amp;quot;
(Boolean-valued attributes coded as DATR paths &lt;a&gt; and &lt;6&gt;), with C inheriting a
value for &lt;a&gt; from A, and for &lt;b&gt; from B. The network is orthogonal, since &lt;a&gt; and
&lt;b&gt; represent distinct (sets of) predicates.
Orthogonal multiple inheritance (OMI) is a desirable property of lexical repre-
sentation systems. Consider an analysis in which we put the common properties of
verbs at a VERB node and the (disjoint) common properties of words that take noun
phrase complements at an NP_ARG node. A transitive verb (TR_VERB) is both a verb
and a word that takes an NP complement, thus it should inherit from both VERB and
NP_ARG in this analysis. In DATR, this might be expressed as follows:
</bodyText>
<footnote confidence="0.707961">
VERB:
&lt;cat&gt; == verb.
NP_ARG:
</footnote>
<page confidence="0.995146">
203
</page>
<figure confidence="0.696762666666667">
Computational Linguistics Volume 22, Number 2
&lt;arg cat&gt; == np
&lt;arg case&gt; == acc.
TR_VERB:
&lt;cat&gt; == VERB
&lt;arg&gt; == NP_ARG.
</figure>
<bodyText confidence="0.995211419354839">
Here TR_VERB inherits from both VERB and NP_ARG but the path prefixes cat and arg
ensure that the inheritance is orthogonal and that no conflict (e.g., in respect of &lt;cat&gt;
values) can arise.
More generally, OMI is invaluable for partitioning the various different, and largely
independent, aspects of lexical description conventionally associated with such initial
path prefixes as Om (phonology), mor (morphology), syn (syntax), and sem (semantics).
In the English verbal system, for example, most morphological subregularities (such as
having a past participle form in -en) operate entirely independently of most syntactic
subregularities (such as having a ditransitive subcategorization frame). Within the se-
mantic domain, Pustejovsky and Boguraev (1993, 214) introduce the expression typed
inheritance for OMI and argue for its advantages in connection with the consistent
assembly of the different facets of meaning associated with a lexical item.
The above examples of OMI are in fact instances of a more general phenomenon
in DATR. We have already noted that the combination of the longest-defined-subpath-
wins and logical consistency are the basis of DATR&apos;s support for coherent multiple in-
heritance. It turns out that functionality (which of course implies consistency) ensures
orthogonality so that OMI falls out as the most normal, natural mode of definition
using DATR.
Finally, we note that a number of recent lexical theories have invoked a form of
inheritance in which multiple parents with overlapping domains are specified, and
a priority ordering imposed to resolve potential inheritance conflicts (e.g., Flickinger
1987; Russell et al. 1992). In this prioritized multiple inheritance (PMI), precedence
is given to nodes that come earlier in the ordering, so that the inherited value for a
property comes from the first parent node in the ordering that defines that property,
regardless of whether other later nodes also define it (possibly differently).
Surprisingly perhaps, DATR&apos;s version of OMI can be used to reconstruct PMI
without making syntactic and semantic additions to the language. In fact, we have
described elsewhere no fewer than three different techniques for capturing PMI in
DATR (Evans, Gazdar, and Moser 1993). But DATR was primarily designed to facilitate
OMI analyses of natural language lexicons and we do not believe that PMI treatments
of the lexicon offer significant analytical or descriptive advantages.
</bodyText>
<subsectionHeader confidence="0.999981">
5.3 Modes of Use
</subsectionHeader>
<bodyText confidence="0.99972375">
Lexicons can either be developed by hand or, in principle at least, they can be induced
from relevant data. Once created, lexicons are used for language understanding, lan-
guage generation, or both. Lexicons that are in use also have to be maintained. At
present, implementations of lexical representation systems are typically specialized to
one or two of these tasks. A language for lexical knowledge representation is merely
one component of a lexical representation system, of course, but its design may well
have implications for the tasks noted above. A language that coded everything into
bit strings might be fully adequate for, say, the induction and generation tasks, but
would probably not facilitate manual lexicon maintenance.
From a more formal point of view, Barg (1994) provides the useful tabular concep-
tualization shown in Table 2, below, of the inferential tasks that may be associated with
a lexical representation language like DATR. Consider the English verbal morphology
</bodyText>
<page confidence="0.996106">
204
</page>
<table confidence="0.9804716">
Evans and Gazdar Lexical Knowledge Representation
Theory Query Value
Conventional inference given given unknown
Reverse query given unknown given
Theory induction unknown given given
</table>
<tableCaption confidence="0.7413285">
Table 2
Possible inference tasks (adapted from Barg 1994).
</tableCaption>
<bodyText confidence="0.999876948717949">
facts that provided our running example in Section 2, above. The conventional infer-
ence task presupposes that we have a description (such as that given in that section)
and a query (such as Love: &lt;mor past part ic iple&gt;): the task is to infer the appropri-
ate value for this query, namely love ed. This task is crucial to lexicon development
and maintenance, since it provides lexicon developers with the means to check the
empirical adequacy of their analyses. It is also a task that is likely to figure in the
on-line use of the lexicon in a language-processing system, once the relevant lexical
entry (i.e., the relevant DATR node) has been determined, to recover information as-
sociated with the entry, and it is the task that does the compilation in systems that
use a partially or fully compiled-out off-line lexicon (as in Andry et al. 1992).
The reverse query task again presupposes that we have a description available
to us, but instead of starting with a known query, we start instead with a known
value love ed, say, and the task is to infer what queries would lead to that value
(Love: &lt;mor past participle&gt;, Love: &lt;mor past tense sing one&gt;, etc.).47 The ability
to perform this kind of inference may also be useful in lexicon development and
maintenance. However, its most obvious application is to &amp;quot;bootstrap&amp;quot; lexical access
in language-processing systems that make direct use of an on-line lexicon: given a
surface form (in analysis) or a semantic form (in generation), we need to identify a
lexical entry associated with that form by reverse query, and then access other lexical
information associated with the entry by conventional inference. Langer (1994) gives
an inference algorithm, based on the familiar chart data structure, for reverse querying
DATR lexicons; and Gibbon (1993) describes EDQL (Extended DATR Query Language)
which permits quantification into components of multisentence DATR queries.
The final task is that of theory induction. Here one starts with a set of known
query-value pairs (Love: &lt;mor past participle&gt; = love ed., Love: &lt;mor pres tense
sing three&gt; = love s., etc.) and the task is to induce a description that has those pairs
as theorems under the application of conventional inference. In a world in which all
the relevant data was already clearly set out in descriptive linguistic work, an al-
gorithm that efficiently achieved this kind of induction would be the philosopher&apos;s
stone to the construction of computational lexicons. In the real world, such an al-
gorithm would still be useful for domains like morphology (where the quality and
clarity of extant descriptive linguistic work is very high), for bootstrapping lexical
descriptions for subsequent manual development by humans, for updating lexicons
in the light of newly encountered lexical information, and for converting one kind
of lexicon into a completely different kind of lexicon by inducing the latter from the
output of the former. The automatic induction of (symbolic) lexicons from data is a
very new research area in computational linguistics: Kilbury (1993), Kilbury, Naerger,
and Renz (1994), Light (1994), and Light, Reinhard, and Boyle-Hinrichs (1993) have
proposed a variety of incremental algorithms that take a partial lexical hierarchy and
</bodyText>
<footnote confidence="0.969585">
47 An alternative formulation is to start with a known value and path, and the task is to infer the
appropriate nodes.
</footnote>
<page confidence="0.991345">
205
</page>
<note confidence="0.714552">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.996970428571429">
elaborate it as necessary in the light of successively presented data sets, while Barg
(1994) has presented a non-incremental algorithm that induces full DATR hierarchies
from suitable data sets.
Since DATR is no more than a language, it does not itself dictate how a DATR
lexicon is to be used. As it turns out, different researchers have used it very differently.
Andry et al. (1992), in the context of a speech recognition task involving the parsing of
&amp;quot;extremely large lattices of lexical hypotheses&amp;quot; (p. 248), opted for off-line compilation
of their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which was
encoded with bit-vectors for speed and compactness. At the other extreme, Duda
and Gebhardi (1994) present an interface between a PATR-based parser and a DATR
lexicon where the former is dynamically linked to the latter and able to query it freely,
in both conventional and reverse modes, without restriction. Gibbon (1993) presents an
implementation of a very flexible query language, EDQL, which allows quantification
over any constituents of (possibly complex) DATR queries.
</bodyText>
<subsectionHeader confidence="0.997866">
5.4 Implementations
</subsectionHeader>
<bodyText confidence="0.999879333333333">
As already noted, the inferential core of DATR is extremely simple to implement. We
know of the existence of approximately a dozen different implementations of the lan-
guage but there may well be others that we do not know of. The best known, and
most widely available are our own (Brighton/Sussex), which is written in Prolog and
runs on most Unix platforms, Gibbon&apos;s (Bielefeld) DDATR Scheme and NODE Sicstus
Prolog implementations, and Kilbury&apos;s (Duesseldorf) QDATR Prolog implementation,
which runs (in compiled form) on PCs and on Sicstus Prolog under Unix. All of these
are freely available on request, as is an extensive archive of over one hundred example
fragments, some of which illustrate formal techniques and others of which are appli-
cations of DATR to the lexical phonology, morphology, syntax, or semantics of a wide
variety of different languages.&apos; Other interesting implementations that we are familiar
with include the experimental reverse query implementation by Langer (Osnabrueck),
Duda and Gebhardi&apos;s (Berlin) implementation that is dynamically linked to PATR, and
Barg&apos;s (Duesseldorf) implementation of a system that induces DATR descriptions from
extensional data sets.
</bodyText>
<subsectionHeader confidence="0.686994">
6. Concluding Remarks
</subsectionHeader>
<bodyText confidence="0.99993825">
Our title for this paper is to be taken literally—DATR is a language for lexical knowledge
representation. It is a kind of programming language, not a theoretical framework for
the lexicon (in the way that, say, H PSG is a theoretical framework for syntax). Clearly,
the language is well suited to lexical frameworks that embrace, or are consistent with,
nonmonotonicity and inheritance of properties through networks of nodes. But those
two dispositions hardly constitute a restrictive notion of suitability in the context
of contemporary NLP work, nor are they absolute requirements: it is, for example,
entirely possible to write useful DATR fragments that never override inherited values
(and so are monotonic) or that define isolated nodes with no inheritance.
It is true, of course, that our examples, in this paper and elsewhere, reflect a
particular set of assumptions about how NLP lexicons can be best organized. But,
apart from the utility of inheritance and nonmonotonicity, we have been careful not
</bodyText>
<footnote confidence="0.950533">
48 Anonymous FTP to ftp.cogs.sussex.ac.uk and directory /pub/nlp/DATR provides access to various
DATR implementations, the example archive, and some relevant papers and documentation.
</footnote>
<page confidence="0.994921">
206
</page>
<note confidence="0.52279">
Evans and Gazdar Lexical Knowledge Representation
</note>
<bodyText confidence="0.9719101875">
to build those assumptions into the DATR language itself. There is, for example, no
built-in assumption that lexicons should be lexeme-based rather than, say, word- or
morpheme-based.
Unlike some other NLP inheritance languages, DATR is not intended to provide
the facilities of a particular syntactic formalism. Rather, it is intended to be a lexical for-
malism that can be used with any syntactic representation that can be encoded in terms
of attributes and values. Thus, at the time of writing, we know of nontrivial DATR
lexicons written for G PSG, LTAG, PATR, Unification Categorial Grammar, and Word
Grammar. Equally, the use of DATR does not commit one, in advance, to adopting any
particular set of theoretical assumptions with respect to phonology, morphology, or
semantics. In phonology, for example, the language allows one to write transducers
that map strings of atomic phonemes to strings of atomic phones. But it also allows
one to encode full-blown feature- and syllable-tree-based prosodic analyses.
Unlike the formalisms typically proposed by linguists, DATR does not attempt to
embody in its design any substantive and restrictive universal claims about the lex-
icons of natural language. That does not distinguish it from most NLP formalisms,
of course. However, we have also sought to ensure that its design does not embody
features that would restrict its use to a single language (English, say) or to a particular
class of closely related languages (the Romance class, say). The available evidence sug-
gests that we have succeeded in the latter aim since, at the time of writing, nontrivial
DATR fragments of the lexicons of Arabic, Arapesh, Czech, English, French, German,
Gikuyu, Italian, Latin, Polish, Portuguese, Russian, and Spanish have been developed.
There are also smaller indicative fragments for Baoule, Dakota, Dan, Dutch, Japanese,
Nyanja, Sanskrit, Serbo-Croat, Swahili, and Tem.
Unlike most other languages proposed for lexical knowledge representation, DATR
is not intended to be restricted in the levels of linguistic description to which it can sen-
sibly be applied. It is designed to be equally applicable at phonological, orthographic,
morphological, syntactic, and semantic levels of description; but it is not intended
to replace existing approaches to those levels. Rather, we envisage descriptions of
different levels according to different theoretical frameworks being implementable in
DATR: thus an NLP group might decide, for example, to build a lexicon with DRT-style
semantic representations, H PSG-style syntactic representations, &amp;quot;item &amp; arrangement&amp;quot;-
style morphological representations and a KIMMO-style orthographic component, im-
plementing all of these, including the H PSG lexical rules, in DATR. DATR itself does
not mandate any of the choices in this example, but equally, nor does it allow such
choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as
to the theoretical frameworks in which the description is to be conducted: there is no
&amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example,
Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX the-
ory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press)
use DATR to implement their Network Morphology framework, and Gazdar (1992)
shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped
into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of
assembly language for constructing (or reconstructing) higher-level theories of lexical
representation.
49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of
polytheoretic lexicons. For example, one that would allow either categorial or HPSG-style
subcategorization specifications to be derived, depending on the setting of a parameter.
</bodyText>
<page confidence="0.988813">
207
</page>
<note confidence="0.5844675">
Computational Linguistics Volume 22, Number 2
APPENDIX: The Critical Literature on DATR Reviewed
</note>
<bodyText confidence="0.9840178125">
Since DATR has been in the public domain for the last half-dozen years and been
widely used in Europe during that period (by the standards of lexical knowledge rep-
resentation languages), it is not surprising that it has attracted some critical attention
from others working in the field. In this appendix, we consider and respond to the
critical material that has been published: Domenig and ten Hacken (1992), Bouma and
Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and
van der Linden (1992). Langer and Gibbon (1992) also respond to the last three pa-
pers in the context of a thorough general review of appropriate evaluation criteria for
lexical knowledge representation formalisms. We are indebted to their discussion.
Domenig and ten Hacken (1992) base part of their critique of DATR on an id-
iosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology.
This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for
morphological processing—even though, as they note &amp;quot;DATR is strictly speaking not
an FMP&amp;quot; (p. 8) and &amp;quot;is not specifically geared to morphological processing&amp;quot; (p. 15). As
they point out, dealing with the choice morphologically leads to undermotivated in-
flectional subclasses, obscures the role of phonology in the choice of form, and misses
the morphophonological generalization that unites nouns and verbs in respect of the
choice. But their critique is based on the assumption that they have identified &amp;quot;the
most natural way to express [the choice] in DATR&amp;quot; (p. 17). Given the well-known facts
of this phenomenon,&apos; their analysis seems to us to be about as unnatural as it could
be. Depending on the nature and purpose of one&apos;s lexicon, it would be much more
natural to deal with the choice orthographically with a DAT R-coded FST of the kind
discussed in Section 4.3, above, or morphophonologically using the kind of phonolog-
ical representation adopted by Reinhard and Gibbon (1991), for example.
Domenig and ten Hacken actually cite this latter paper in connection with Ger-
man umlaut and suggest that the -s/-es alternation might be handled in the same way.
However, they go on to claim, quite incorrectly, that &amp;quot;morphophonological generaliza-
tions can actually not be expressed as such&amp;quot; in DATR because &amp;quot;they are represented as
properties of the individual lexemes&amp;quot; (pp. 23-24). This claim appears to be based on
a false assumption that DATR nodes are somehow restricted to the description of lex-
emes. This is an odd assumption to make given that the Reinhard and Gibbon paper
postulates nodes for vowels, syllables, stems, stem types, prefixes, plural inflection,
and syntactic categories, as well as lexemes. But then they dismiss the analysis given
in that paper as &amp;quot;incomprehensible&amp;quot; (p. 24).
A related straw man appears in their discussion of how alternation within a mor-
phological paradigm might be represented in DATR (p. 22). They once again postulate
an analysis that proliferates nodes beyond necessity and fail to spot the possibility of
path domain or value domain analyses such as those sketched in Section 4.6, above.
They go on to offer a &amp;quot;slightly speculative&amp;quot; evaluation of ways in which DATR might
be able to represent word formation, concluding that they &amp;quot;do not see any possibility
of representing the rules involved in word formation&amp;quot; (p. 22). This conclusion again
appears to be based on their assumption that DATR nodes are somehow restricted
to the description of lexemes. But DATR, of course, knows nothing about lexemes,
affixes, vowels, words, lexical rules, or whatever. These are higher-level notions that
the analyst may choose to represent in a wide variety of ways.
50 The orthographic alternation applies to the third person singular present tense forms of verbs and the
plural forms of nouns. The choice between the altemants is wholly governed by the phonology of the
verb or noun stem.
</bodyText>
<page confidence="0.983145">
208
</page>
<note confidence="0.485354">
Evans and Gazdar Lexical Knowledge Representation
</note>
<bodyText confidence="0.9999506">
Finally, Domenig and ten Hacken contend that lexical inheritance formalisms (and
thus DATR) are unusable for the purpose for which they were designed because the
humans who have to work with them for lexicon development cannot keep track of
all the interactions. They provide no evidence for this assertion and the widespread
adoption, development, and use of a variety of large inheritance lexicons in working
NLP systems over the last few years make the assertion seem somewhat implausible.
They conclude that their evaluation of DATR has been &amp;quot;unfair&amp;quot; (p. 29) because they
failed to consider the language in its natural environment. We agree that their eval-
uation is unfair, but ascribe the cause to the ways in which they attempted to apply
DATR to their chosen tasks.&apos;
Daelemans and van der Linden (1992) review a number of approaches to lexi-
cal knowledge representation, including DATR, with respect to their notational ade-
quacy and expressivity. They argue that adequate approaches will allow (i) recursive
path formation; (ii) multiple inheritance, preferably orthogonal multiple inheritance;
(iii) nonmonotonic inheritance; and require (iv) that irregular items take precedence
over regular ones without explicit coding (p. 61). Since, as we have seen, and as Langer
and Gibbon (1992) note, DATR has all four of these properties, one might expect it to
emerge from their review with at least a low alpha grade—but in fact they find fault
with it on a number of grounds.
The first of these is the use of double quotes to mark global inheritance in the
concrete syntax of DATR. They claim that global inheritance is the normal kind of
inheritance in DATR and should thus not be marked in any special way, while (un-
quoted) local inheritance is exceptional and should therefore have a special notation
(like quotes) associated with it (p. 63).52 The small example they give lends some plau-
sibility to their claim. However, the claim is nonetheless misleading. Quoted paths (the
only instances of global inheritance to be found in their example fragment) are indeed
ubiquitous at the highest nodes of existing DATR fragments, but unquoted nodes, un-
quoted paths, and unquoted node/path pairs all also occur very frequently in existing
DATR fragments, while quoted nodes and quoted node/path pairs are hardly found
at all. In some common applications of DATR, such as FSTs, no use at all may be made
of global inheritance.
Their second objection is to the way path extension in DATR permits the derivation
of theorems that have no interpretation in the domain being modeled (p. 63). Thus,
for example, a description that had (a) as a (sensible) theorem might also have (b) as
one of an infinity of (silly) theorems:
</bodyText>
<figure confidence="0.5457295">
(a) Parrot : &lt;mor plur&gt; = parrot s.
(b) Parrot:&lt;mor plur past perfect&gt; = parrot s.
</figure>
<bodyText confidence="0.9997145">
The issue here is that while DATR encourages abstraction away from the most specific
level of detail wherever possible, it does not itself provide a built-in mechanism for
stating what that most specific level is. Our position is that this is part of the lexical
metatheory, rather than the lexical description itself. It needs to be known by anyone
(or any system) wishing to access the lexicon properly, and it may be practically useful
to constrain access by checking for the well-formedness of queries according to such
a metatheory—this could be done quite straightforwardly in DATR as an adjunct to
the main lexicon if desired. This notion, however, is external to, and independent of,
</bodyText>
<page confidence="0.765588">
51 For another critical discussion of the same Domenig and ten Hacken material, see Russell (1993).
52 One of our referees comments that &amp;quot;the issue ... appears to be rather scholastic.&amp;quot; We agree.
209
</page>
<note confidence="0.690812">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.999959386363637">
the lexical description itself: the range of sensible queries only weakly constrains the
manner in which their values are defined.
Their third objection concerns multiple inheritance. They draw attention to the
fact that DATR&apos;s normal mode of multiple inheritance is orthogonal and complain
that prioritized multiple inheritance can only be expressed with additional DATR code
(p. 63). However, we agree with their earlier comment &amp;quot;that orthogonal multiple de-
fault inheritance is at this stage the best solution for conflicts&amp;quot; (p. 61) and can see
no computational linguistic motivation for equipping DATR with a further primitive
inheritance mechanism.&amp;quot;
Their fourth objection consists of the claim that &amp;quot;it is not possible in DATR to have
complex structured objects as values&amp;quot; (p. 64). In one sense this is true, since DATR val-
ues are simply sequences of atoms. But although true, it does not provide support for
a sound objection. DATR can construct those sequences of atoms on the basis of a com-
plex recursive description, and the atom sequences themselves can represent complex
recursive objects so far as NLP system components outside the lexicon are concerned.
The sequences of atoms that DATR provides as values constitute an interface for the
lexicon that is entirely neutral with respect to the representational requirements of
external components. For what is intended to be a general-purpose lexical knowledge
representation language, not tied to any particular conceptions of linguistic structure
or NLP formalism, this neutrality seems to us to be a feature, not a bug.
In a fifth objection, they note correctly that the semantics of paths in DATR and
PATR is different but then go on to claim that DATR paths &amp;quot;could be better described
as atomic attributes&amp;quot; that &amp;quot;do not correspond with a recursive structure&amp;quot; and whose
&amp;quot;only function is to support prefix matching&amp;quot; (p. 64). None of these latter claims
are true. If DATR paths were atomic attributes then our Section 4.3, on finite-state
transducers, could not have been written; DATR paths are the same as PATR paths as
far as recursive structure is concerned; and, as we have seen throughout this paper,
DATR paths have many functions in addition to prefix matching.
In a final set of comments, they briefly raise various issues connected with the
integration of DATR lexicons with unification-based grammar (p. 64). We have dealt
with these issues in earlier parts of the present paper and will not rehearse them here.&apos;
Krieger and Nerbonne (1993) claim that &amp;quot;the basic insight of DATR&amp;quot; lies in its
use in characterizing &amp;quot;the inflectional variants of a lexeme as alternative (disjunctive)
realisations&amp;quot; (p. 135). This claim confuses the basic insight of a very traditional ap-
proach to inflectional morphology with the application of DATR in implementing that
approach. Elsewhere they note that &amp;quot;the fundamental idea in our characterisation is
due to the work in DATR, in which paradigms are treated as alternative further speci-
fications of abstract lexemes&amp;quot; (p. 104). Unfortunately, their own implementation of this
fundamental idea turns out to be significantly less satisfactory than that provided in
the DATR analysis to which they refer. In order to reconstruct paradigms in their fea-
ture language, they invoke distributed disjunctions (fixed-length term expressions).&amp;quot;
The descriptive problem with this approach, as they admit, is that &amp;quot;there is no way
to note that a single form in a paradigm is exceptional without respecifying the en-
tire paradigm—the disjunction must be respecified as a whole ... there is no way to
</bodyText>
<footnote confidence="0.913404166666667">
53 But see Daelemans and De Smedt (1994) for articulation of the methodological principle that underlies
the third objection.
54 The issues are also discussed in detail by Langer and Gibbon (1992).
55 Langer and Gibbon (1992) argue, at some length, that it is formally inappropriate to add distributed
disjunction to a typed feature structure language of the kind otherwise assumed by Krieger and
Nerbonne.
</footnote>
<page confidence="0.994807">
210
</page>
<note confidence="0.491136">
Evans and Gazdar Lexical Knowledge Representation
</note>
<bodyText confidence="0.999906288888889">
identify a particular alternation within the distributed disjunction&amp;quot; (p. 107). Anyone
familiar with the way inflection works in Romance languages will immediately see that
this is a very serious weakness. In Latin, for example, there are many individual words
and small subclasses of words that deviate from a major declension or conjugation in
just one or two parts of the paradigm. Under Krieger and Nerbonne&apos;s approach every
such case will require one to &amp;quot;respecify the entire paradigmatic disjunction&amp;quot; (p. 107).
This is exactly the kind of redundancy that the introduction of defaults is meant to
eliminate.56
At the root of Krieger and Nerbonne&apos;s (1993) critique of DATR is a complaint that
it fails to provide all the resources of a modern, fully equipped unification grammar
formalism (p. 90-91). From our perspective, this is a bit like criticizing STANDARD ML
on the grounds that it lacks the functionality provided in ADA. Thus, for example,
they complain that disjunction is missing from DATR and that nobody seems to be
trying to add it to the language (p. 110). They cite their own &amp;quot;extensive employment
of [distributed] disjunction&amp;quot; (p. 110) as evidence for its utility in lexical description,
apparently forgetting that their use of distributed disjunction to describe inflection
was motivated by a desire to reconstruct a treatment of inflection that they had seen
implemented in DATR. They provide no motivation for adding distributed disjunction
to DAT R&apos;s (rather small) list of available descriptive resources because that list of
resources already allows better analyses of the phenomena they discuss than does
their version of distributed disjunction, as noted above.
They also object to the fact that use of a DATR lexicon will require an &amp;quot;interface&amp;quot;
(p. 110) between the lexicon and a feature-based parser. But, as we have seen in Sec-
tion 4.7, above, such an interface will normally be trivial and required in any case
(since Krieger and Nerbonne&apos;s parser must be able to access and read files that con-
tain text descriptions of feature structures). As it is, they seem happy to countenance
an interface to a separate two-level morphophonemic processor (p. 103, n. 9) whereas,
in DATR, the morphophonemics can be done entirely in the lexicon if one wishes.
From remarks they make on pages 109 and 111 of their paper, Krieger and Ner-
bonne appear to believe that it is impossible to implement a particular inflectional
analysis of the passive in Latin in DATR. They do not provide much of an argument,
but what they do say suggests that the simple treatment of passive given in Section
4.5, above, is likewise impossible. This may be because they regard their own inter-
pretation of lexical rules as &amp;quot;novel&amp;quot; (p. 113), although examples of that interpretation
of lexical rules appear in earlier DATR work that they cite.
Many of the points made in Nerbonne (1992) are repeated from the more accessi-
ble Krieger and Nerbonne (1993)57 and we have considered them in our discussion of
the latter. Some of the points from the 1992 and 1993 papers resurface in Bouma and
Nerbonne (1994). Nerbonne appears to misconstrue Evans, Gazdar, and Moser (1993)
as an attempt to augment DATR with re-entrancy and goes on to suggest that DATR is
somehow forced to maintain that &amp;quot;all linguistic generalizations tend to follow the lines
of morphological form&amp;quot; (p. 47) when, in fact, the attribute ordering used in a DATR
treatment of morphology is entirely independent of the use and ordering of those same
attributes elsewhere in the lexicon (see the discussion at the end of Section 4.1, above).
Like Daelemans and van der Linden (1992), he makes some pessimistic comments
</bodyText>
<footnote confidence="0.9863594">
56 Krieger and Nerbonne are not forced to use distributed disjunction to describe inflectional paradigms.
Their very well-equipped feature description language provides alternative analytical resources. What
puzzles us is why they chose to use distributed disjunction for this purpose. Bouma and Nerbonne
(1994) propose using lists of specified phonological forms instead.
57 Although the joint 1993 paper has a later publication date, it appears to have been written first.
</footnote>
<page confidence="0.99105">
211
</page>
<note confidence="0.69011">
Computational Linguistics Volume 22, Number 2
</note>
<bodyText confidence="0.998991916666667">
about the integration of a DATR lexicon with feature-based grammars. Some of these
are effectively dealt with elsewhere in this paper, but two of them need to be noted
here. He asserts that if a rich feature formalism is encoded in DATR then &amp;quot;distinctions
must be lost.&amp;quot; It is not clear from the context exactly which distinctions he has in mind
or what the basis for the claim is, but the expressions of all existing feature formalisms
can be represented by sequences of atoms (and thus by DATR values) and all existing
lexicons for feature-based NLP systems use such representations. We therefore find
the claim deeply implausible. He also asserts that the fact that an atom may mean
one thing in the semantics of DATR and something quite different in the semantics
of a feature formalism will lead to &amp;quot;massive redundancy&amp;quot; (p. 47) in lexical specifica-
tions (the phrase gets repeated in Bouma and Nerbonne 1994). Again, no argument in
support of this conclusion is offered. And we cannot see how semantic overloading
of atoms gives rise, of itself, to any kind of redundancy.&apos; Indeed, those who design
programming languages normally introduce semantic overloading in order to achieve
economy of expression.
Finally, Bouma and Nerbonne (1994, 47) comment that &amp;quot;in spite of Kilgarriff&apos;s
(1993) interesting work on modelling some derivational relations in the pure inher-
itance machinery of DATR, we know of no work attempting to model potentially
recursive derivational relations, and we remain sceptical about relying on inheritance
alone for this.&amp;quot; We are not sure what they mean by &amp;quot;the pure inheritance machinery
of DATR&amp;quot; or why they think that someone attempting an analysis of recursive deriva-
tion in DATR would want to do so using &amp;quot;pure inheritance&amp;quot; alone. Here is a trivial
(and linguistically rather pointless) DATR analysis of the more complex of their two
examples:
</bodyText>
<figure confidence="0.9501917">
Word:
&lt;v&gt; == &amp;quot;&lt;&gt;&amp;quot;
&lt;a from n&gt; == &lt;n&gt; + al
&lt;v from a&gt; == &lt;a&gt; + ize
&lt;n from v&gt; == &lt;v&gt; + tion.
Institute:
&lt;&gt; == Word
&lt;root&gt; == institute.
From this description we can derive theorems like these:
Institute:
&lt;root&gt; = institute
&lt;n from v root&gt; = institute + tion
&lt;a from n from v root&gt; =
institute + tion + al
&lt;v from a from n from v root&gt; =
institute + tion + al + ize
&lt;n from v from a from n from v root&gt; =
institute + tion + al + ize + tion.
Note the recursive reintroduction of the -tion suffix in the last theorem shown.
58 Sacks (1973) makes interesting reading in this connection.
</figure>
<page confidence="0.976639">
212
</page>
<note confidence="0.678192">
Evans and Gazdar Lexical Knowledge Representation
</note>
<sectionHeader confidence="0.911565" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.976706428571429">
We are grateful to the four Computational
Linguistics referees for their criticisms and
suggestions; to Lynne Cahill, Dafydd
Gibbon, Jim Kilbury and David Weir for
their comments on an earlier draft of the
paper; and to Walter Daelemans and John
Nerbonne for their comments on the first
draft of the appendix. We thank Petra Barg,
Lynne Cahill, Norman Fraser, Dafydd
Gibbon, Elizabeth Jenkins, Jim Kilbury,
Lionel Moser, and Ingrid Renz for their
role(s) in the development of the DATR
language and the coding techniques
discussed above; Fernando Pereira for early
critical comments that led directly to the
introduction of evaluable paths into the
language; and Bill Keller and David Weir
for much relevant recent interaction. This
research was supported by various grants to
the authors from ESRC (UK) and
SERC/EPSRC (UK).
</bodyText>
<sectionHeader confidence="0.957199" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999432741935483">
Andry, Francois, Norman Fraser, Scott
McGlashan, Simon Thornton, and Nick
Youd. 1992 Making DATR work for
speech: Lexicon compilation in SUNDIAL.
Computational Linguistics 18:245-267.
Barg, Petra. 1994. Automatic acquisition of
DATR theories from observations.
Theories des Lexicons: Arbeiten des
Sonderforschungsbereichs 282,
Heinrich-Heine University of Duesseldorf.
Bleiching, Doris. 1992. Prosodisches Wissen
in Lexicon. In G. Goerz, editor,
Proceedings of KONVENS-92, Berlin:
Springer-Verlag, pages 59-68.
Bleiching, Doris. 1994. Integration von
Morphophonologie und Prosodie in emn
hierarchisches Lexicon. In Harald Trost,
editor, Proceedings of KONVENS-94, pages
32-41, Vienna: Oesterreichische
Gesellschaft fuer Artificial Intelligence.
Bouma, Gosse. 1993. Nonmonotonicity and
Categorial Unification Grammar.
Proefschrift, Rijksuniversiteit Groningen.
Bouma, Gosse and John Nerbonne. 1994.
Lexicons for feature-based systems. In
Harald Trost, editor, Proceedings of
KONVENS-94, pages 42-51, Vienna:
Oesterreichische Gesellschaft fuer
Artificial Intelligence.
Briscoe, Ted and Ann Copestake. 1991.
Sense extensions as lexical rules. In
D. Fass, E. Hinkelman &amp; J. Martin,
editors. Computational approaches to
Non-Literal Language, Proceedings of the
IJCAI Workshop, pages 12-20, Sydney.
Briscoe, Ted, Ann Copestake, and Alex
Lascarides. 1995. Blocking. In Patrick
Saint-Dizier &amp; Evelyne Viegas, editors.
Computational Lexical Semantics.
Cambridge: Cambridge University Press,
pages 272-302.
Briscoe, Ted, Valeria de Paiva, and Ann
Copestake, editors. 1993. Inheritance,
Defaults, and the Lexicon, Cambridge:
Cambridge University Press.
Brown, Dunstan and Andrew Hippisley.
1994. Conflict in Russian genitive plural
assignment: A solution represented in
DATR. Journal of Slavic Linguistics,
2(1):48-76.
Cahill, Lynne. 1993a. Some reflections on
the conversion of the TIC lexicon into
DATR. In Ted Briscoe, Valeria de Paiva,
and Ann Copestake, editors. Inheritance,
Defaults, and the Lexicon. Cambridge:
Cambridge University Press, pages 47-57.
Cahill, Lynne. 1993b. Morphonology in the
lexicon. Sixth Conference of the European
Chapter of the Association for Computational
Linguistics, pages 87-96.
Cahill, Lynne. 1994. An inheritance-based
lexicon for message understanding
systems. Fourth ACL Conference on Applied
Natural Language Processing, pages
211-212.
Cahill, Lynne and Roger Evans. 1990. An
application of DATR: The TIC lexicon. In
Proceedings of the 9th European Conference on
Artificial Intelligence, pages 120-125,
Stockholm.
Calder, Jo. 1994. Feature-value logics: Some
limits on the role of defaults. In
C. J. Rupp, M. A. Rosner, &amp; R. L. Johnson,
editors. Constraints, Language and
Computation. London: Academic Press,
pages 205-222.
Carpenter, Bob. 1991. The generative power
of categorial grammars and head-driven
phrase structure grammars with lexical
rules. Computational Linguistics 17:301-313.
Carpenter, Bob. 1992. Categorial grammars,
lexical rules, and the English predicative.
In Robert Levine, editor. Formal Grammar:
Theory and Implementation. New York:
Oxford University Press, pages 168-242.
Copestake, Ann. 1992. The representation of
lexical semantic information. Ph.D.
dissertation, University of Sussex,
Cognitive Science Research Paper CSRP 280.
Copestake, Ann and Ted Briscoe. 1992.
Lexical operations in a unification based
framework. In James Pustejovsky &amp;
Sabine Bergler, editors. Lexical Semantics
</reference>
<page confidence="0.978205">
213
</page>
<note confidence="0.346802">
Computational Linguistics Volume 22, Number 2
</note>
<reference confidence="0.999679680327869">
and Knowledge Representation. Berlin:
Springer-Verlag, pages 101-119.
Copestake, Ann and Ted Briscoe. 1995.
Regular polysemy and semi-productive
sense extension. Journal of Semantics
12:15-67.
Corbett, Greville and Norman Fraser. 1993.
Network Morphology: A DATR account
of Russian nominal inflection. Journal of
Linguistics 29:113-142.
Daelemans, Walter. 1994. Review of
Inheritance, Defaults, and the Lexicon, by Ted
Briscoe, Valeria de Paiva &amp; Ann
Copestake, editors. Computational
Linguistics 20(4):661-664.
Daelemans, Walter and Koenraad De Smedt.
1994. Inheritance in an object-oriented
representation of linguistic categories.
International Journal of Human-Computer
Studies 41(1/2):149-177.
Daelemans, Walter, Koenraad De Smedt,
and Gerald Gazdar. 1992. Inheritance in
natural language processing.
Computational Linguistics 18(2):205-218.
Daelemans, Walter and Gerald Gazdar,
editors. 1992. Computational Linguistics
18(2) and 18(3), special issues on
inheritance.
Daelemans, Walter and Erik-Jan van der
Linden. 1992. Evaluation of lexical
representation formalisms. In Jan van
Eijck &amp; Wilfried Meyer, editors.
Computational Linguistics in the Netherlands:
Papers from the Second CLIN Meeting, pages
54-67, Utrecht: OTS.
Domenig, Marc and Pius ten Hacken. 1992.
Word Manager: A System for Morphological
Dictionaries. Hidesheim: Georg Olms
Verlag.
Duda, Markus and Gunter Gebhardi. 1994.
DUTR-A DATR-PATR interface
formalism. In Harald Trost, editor.
Proceedings of KONVENS-94, pages
411-414, Vienna: Oesterreichische
Gesellschaft fuer Artificial Intelligence.
Evans, Roger and Gerald Gazdar. 1989a.
Inference in DATR. Fourth Conference of the
European Chapter of the Association for
Computational Linguistics, pages 66-71.
Evans, Roger and Gerald Gazdar. 1989b.
The semantics of DATR. In Anthony G.
Cohn, editor. Proceedings of the Seventh
Conference of the Society for the Study of
Artificial Intelligence and Simulation of
Behaviour, pages 79-87, London:
Pitman/Morgan Kaufmann.
Evans, Roger, Gerald Gazdar, and Lionel
Moser. 1993. Prioritised multiple
inheritance in DATR. In Ted Briscoe,
Valeria de Paiva, and Ann Copestake,
editors. Inheritance, Defaults, and the
Lexicon. Cambridge: Cambridge
University Press, pages 38-46.
Evans, Roger, Gerald Gazdar, and David
Weir. 1995. Encoding lexicalized tree
adjoining grammars with a nonmonotonic
inheritance hierarchy. 33rd Annual Meeting
of the Association for Computational
Linguistics, pages 77-84.
Flickinger, Daniel P. 1987. Lexical Rules in the
Hierarchical Lexicon. Ph.D. dissertation,
Stanford University.
Fraser, Norman and Greville Corbett. 1995.
Gender, animacy, and declensional class
assignment: A unified account for
Russian. In Geert Booij &amp; Jaap van Marle,
editors. Year Book of Morphology 1994.
Dordrecht: Kluwer, pages 123-150.
Fraser, Norman and Greville Corbett. In
press. Gender assignment in Arapesh: A
Network Morphology analysis. Lingua.
Fraser, Norman and Richard Hudson. 1990.
Word Grammar: An inheritance-based
theory of language. In Walter Daelemans
&amp; Gerald Gazdar, editors. Proceedings of
the Workshop on Inheritance in Natural
Language Processing, pages 58-64, Tilburg:
Institute for Language Technology.
Gazdar, Gerald. 1992. Paradigm function
morphology in DATR. In Lynne Cahill &amp;
Richard Coates, editors. Sussex Papers in
General and Computational Linguistics.
Brighton, University of Sussex, Cognitive
Science Research Paper CSRP 239, pages
43-53.
Gibbon, Dafydd. 1990. Prosodic association
by template inheritance. In Walter
Daelemans &amp; Gerald Gazdar, editors.
Proceedings of the Workshop on Inheritance in
Natural Language Processing, pages 65-81,
Tilburg: Institute for Language
Technology.
Gibbon, Dafydd. 1992. ILEX: A linguistic
approach to computational lexica. In
Ursula Klenk, editor. Computatio Linguae:
Aufsaze zur algorithmischen und
quantitativen Analyse der Sprache (Zeitschrift
fur Dialektologie und Linguistik, Beiheft 73),
Stuttgart: Franz Steiner Verlag, pages
32-53.
Gibbon, Dafydd. 1993. Generalized DATR
for flexible lexical access: PROLOG
specification. Bielefeld: Verbmobil Report 2.
Gibbon, Dafydd and Doris Bleiching. 1991.
An ILEX model for German compound
stress in DATR. Proceedings of the
FOR WISS-ASL Workshop on Prosody in
Man-Machine Communication, pages 1-6.
Ide, Nancy, Jacques Le Maitre, and Jean
Veronis. 1994. Outline of a model for
lexical databases. In Antonio Zampolli,
Nicoletta Calzolari, and Martha Palmer,
</reference>
<page confidence="0.971091">
214
</page>
<note confidence="0.350353">
Evans and Gazdar Lexical Knowledge Representation
</note>
<reference confidence="0.999707819672131">
editors. Current Issues in Computational
Linguistics: In Honour of Don Walker. Pisa:
Kluwer, pages 283-320.
Kaplan, Ronald M. and Martin Kay. 1994.
Regular models of phonological rule
systems. Computational Linguistics
20(3):331-378.
Keller, William. 1995. DATR theories and
DATR models. 33rd Annual Meeting of the
Association for Computational Linguistics,
pages 55-62.
Kilbury, James. 1993. Strict inheritance and
the taxonomy of lexical types in DATR.
Unpublished manuscript, University of
Duesseldorf.
Kilbury, James, Petra [Barg] Naerger, and
Ingrid Renz. 1991. DATR as a lexical
component for PATR. Fifth Conference of the
European Chapter of the Association for
Computational Linguistics, pages 137-142.
Kilbury, James, Petra [Bargj Naerger; and
Ingrid Renz. 1994. Simulation
lexicalischen Erwerbs. In Sascha W. Felix,
Christopher Habel, and Gert Rickheit
Kognitive Linguistik: Repraesentation und
Prozesse. Opladen: Westdeutscher Verlag,
pages 251-271.
Kilgarriff, Adam. 1993. Inheriting verb
alternations. Sixth Conference of the
European Chapter of the Association for
Computational Linguistics, pages 213-221.
Kilgarriff, Adam. 1995. Inheriting polysemy.
In Patrick Saint-Dizier &amp; Evelyne Viegas,
editors. Computational Lexical Semantics.
Cambridge: Cambridge University Press.
Kilgarriff, Adam and Gerald Gazdar. 1995.
Polysemous relations. In F. R. Palmer,
editor. Grammar and Meaning: Essays in
Honour of Sir John Lyons. Cambridge:
Cambridge University Press, pages 1-25.
Krieger, Hans-Ulrich. 1994. Derivation
without lexical rules. In C. J. Rupp,
M. A. Rosner, and R. L. Johnson, editors.
Constraints, Language and Computation.
London: Academic Press, pages 277-313.
Krieger, Hans-Ulrich and John Nerbonne.
1993. Feature-based inheritance networks
for computational lexicons. In Ted
Briscoe, Valeria de Paiva, and Arm
Copestake, editors. Inheritance, Defaults,
and the Lexicon. Cambridge: Cambridge
University Press, pages 90-136.
Krieger, Hans-Ulrich, Hannes Pirker, and
John Nerbonne. 1993. Feature-based
allomorphy. 31st Annual Meeting of the
Association for Computational Linguistics,
pages 140-147.
Langer, Hagen. 1994. Reverse queries in
DATR. COLING-94, pages 1089-1095.
Langer, Hagen and Dafydd Gibbon. 1992.
DATR as a graph representation language
for ILEX speech oriented lexica. Technical
Report ASL-TR-43-92/UBI, University of
Bielefeld.
Lascarides, Alex, Nicholas Asher, Ted
Briscoe, and Ann Copestake.
Forthcoming. Order independent and
persistent typed default unification.
Linguistics &amp; Philosophy 19(1):1-89.
Light, Marc. 1994. Classification in
feature-based default inheritance
hierarchies. In Harald Trost, editor.
Proceedings of KONVENS-94, pages
220-229, Vienna: Oesterreichische
Gesellschaft fuer Artificial Intelligence.
Light, Marc, Sabine Reinhard, and Marie
Boyle-Hinrichs. 1993. INSYST: An
automatic inserter system for hierarchical
lexica. Sixth Conference of the European
Chapter of the Association for Computational
Linguistics, page 471.
McFetridge, Paul and Aline Villavicencio.
1995. A hierarchical description of the
Portuguese verb. Proceedings of the XIIth
Brazilian Symposium on Artificial
Intelligence, pages 302-311.
Mellish, Chris and Ehud Reiter. 1993. Using
classification as a programming language.
IJCAI-93, pages 696-701.
Mitamura, Teruko and Eric H. Nyberg III.
1992. Hierarchical lexical structure and
interpretive mapping in machine
translation. COLING-92 Vol. IV, pages
1254-1258.
Nerbonne, John. 1992. Feature-based
lexicons-an example and a comparison
to DATR. In Dorothee Reimann, editor.
Beit rage des ASL-Lexicon-Workshops.
Wandtlitz, pages 36-49.
Ostler, Nicholas and B. T. S. Atkins. 1992.
Predictable meaning shift: Some linguistic
properties of lexical implication rules. In
James Pustejovsky &amp; Sabine Bergler,
editors. Lexical Semantics and Knowledge
Representation. Berlin: Springer-Verlag,
pages 87-100.
Penn, Gerald and Richmond Thomason.
1994. Default finite state machines and
finite state phonology. Computational
Phonology: Proceedings of the 1st Meeting of
the ACL Special Interest Group in
Computational Phonology, pages 33-42.
Pulman, Stephen G. Forthcoming.
Unification encodings of grammatical
notations. To appear in Computational
Linguistics.
Pustejovsky, James. 1991. The generative
lexicon. Computational Linguistics
17(4):409-441.
Pustejovsky, James and Branimir Boguraev.
1993. Lexical knowledge representation
and natural language processing. Artificial
</reference>
<page confidence="0.973195">
215
</page>
<note confidence="0.313858">
Computational Linguistics Volume 22, Number 2
</note>
<reference confidence="0.996651618181818">
Intelligence 63(1-2):193-223.
Reinhard, Sabine. 1990.
Verarbeitungsprobleme nichtlinearer
Morphologien: Umlautbeschreibung in
einem hierarchischen Lexikon. In
Burghard Rieger &amp; Burkhard Schaeder
Lexikon und Lexikographie. Hildesheim:
Olms Verlag, 45-61.
Reinhard, Sabine and Dafydd Gibbon. 1991.
Prosodic inheritance and morphological
generalisations. Fifth Conference of the
European Chapter of the Association for
Computational Linguistics, pages 131-136.
Reiter, Ehud and Chris Mellish. 1992. Using
classification to generate text. 30th Annual
Meeting of the Association for Computational
Linguistics, pages 265-272.
Ritchie, Graeme D., Graham J. Russell, Alan
W. Black, and Stephen G. Pulman. 1992.
Computational Morphology. Cambridge,
MA: MIT Press.
Russell, Graham. 1993. Review of Word
Manager: A System for Morphological
Dictionaries, by Marc Domenig &amp; Pius ten
Hacken. Computational Linguistics
19(4):699-700.
Russell, Graham, Afzal Ballim, John Carroll,
and Susan Warwick-Armstrong. 1992. A
practical approach to multiple default
inheritance for unification-based lexicons.
Computational Linguistics 183:311-337.
Sacks, Harvey. 1973. On some puns with
some intimations. In Roger W. Shuy,
editor. Report of the 23rd Annual Roundtable
Meeting on Linguistics and Language Studies.
Washington D.C.: Georgetown University
Press, pages 135-144.
Shieber, Stuart M. 1986. An Introduction to
Unification Approaches to Grammar.
Stanford: CSLI/Chicago University Press.
Stump, Greg. 1992. On the theoretical status
of position class restrictions on
inflectional affixes. In Geert Booij &amp; Jaap
van Marie, editors. Year Book of Morphology
1991. Dordrecht: Kluwer, pages 211-241.
Touretzky, David S. 1986. The Mathematics of
Inheritance Systems. London/Los Altos:
Pitman/ Morgan Kaufmann.
Young, Mark A. 1992. Nonmonotonic sorts
for feature structures. AAAI-92, pages
596-601.
Young, Mark A. and Bill Rounds. 1993. A
logical semantics for nonmonotonic sorts.
Proceedings of the 31st Annual Meeting of the
ACL, pages 209-215.
</reference>
<page confidence="0.999144">
216
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.496037">
<title confidence="0.9992225">Language for Lexical Knowledge Representation</title>
<author confidence="0.999841">Roger Evans Gerald Gazdar</author>
<affiliation confidence="0.997453">University of Brighton University of Sussex</affiliation>
<abstract confidence="0.930277">Much recent research on the design of natural language lexicons has made use of nonmonotonic inheritance networks as originally developed for general knowledge representation purposes in Intelligence. R a simple, spartan language for defining nonmonotonic inheritance networks with path/value equations, one that has been designed specifically for lexical knowledge representation. In keeping with its intendedly minimalist character, it lacks many of the constructs embodied either in general-purpose knowledge representation languages or in contemporary grammar formalisms. The present paper shows that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Francois Andry</author>
<author>Norman Fraser</author>
<author>Scott McGlashan</author>
<author>Simon Thornton</author>
<author>Nick Youd</author>
</authors>
<title>Making DATR work for speech: Lexicon compilation in SUNDIAL.</title>
<date>1992</date>
<journal>Computational Linguistics</journal>
<pages>18--245</pages>
<contexts>
<context position="4631" citStr="Andry et al. 1992" startWordPosition="677" endWordPosition="680">tradition, and (v) can express all the evident generalizations and subgeneralizations about such entries. Our first publications on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference (i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2 With respect to (iii), the core inference engine for DATR can be coded in a page of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen different implementations of the language, some of which have been used with large DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a, 1994; Cahill and Evans 1990). We will comment further on implementation matters in Section 5, below. However, the main purpose of the present paper is to exhibit the use of DATR for lexical description (iv) and the way it makes it relatively easy to capture lexical generalizations and subregularities at a variety of analytic levels (v). We will pursue (iv) and (v) in the context of an informal example-based introduction to the language and to techniques for its use, and we will make frequent reference to the DATR-based lexical work that has been done since 1989. The paper is or</context>
<context position="85715" citStr="Andry et al. (1992" startWordPosition="14207" endWordPosition="14210"> She1: &lt;&gt; == PRONOUN1 &lt;case&gt; == nominative &lt;person&gt; == third &lt;number&gt; == singular. From this description, we can derive the following theorem: She1: &lt;dag&gt; = [ &lt; case &gt; = nominative &lt; person &gt; = third &lt; number &gt; = singular &lt; referent &gt; = &lt; NP referent &gt; ]. The sequence of atoms on the right-hand side of this equation is just a sequence of atoms as far as DATR is concerned. But a grammar or a parser that expects to see DAGs represented as they are here can interpret the DATR values as easily as it can the contents of a file.&apos; 40 In this connection, see the discussion of &amp;quot;closure definitions&amp;quot; in Andry et al. (1992, 259-261). 41 This approach is due to recent unpublished work by Jim Kilbury. He has shown that the same DATR theorems can have their values realized as conventional attribute-value matrix representations, Prolog terms, or expressions of a feature logic, simply by changing the fine detail of the transducer employed. 42 Indeed, it will be interpreting the contents of a file if DATR has been used to define a lexicon that has subsequently been compiled out, rather than being accessed directly by components of the NLP system (see Section 5.3, below). We are not, of course, claiming that textual r</context>
<context position="99724" citStr="Andry et al. 1992" startWordPosition="16408" endWordPosition="16411">sk is to infer the appropriate value for this query, namely love ed. This task is crucial to lexicon development and maintenance, since it provides lexicon developers with the means to check the empirical adequacy of their analyses. It is also a task that is likely to figure in the on-line use of the lexicon in a language-processing system, once the relevant lexical entry (i.e., the relevant DATR node) has been determined, to recover information associated with the entry, and it is the task that does the compilation in systems that use a partially or fully compiled-out off-line lexicon (as in Andry et al. 1992). The reverse query task again presupposes that we have a description available to us, but instead of starting with a known query, we start instead with a known value love ed, say, and the task is to infer what queries would lead to that value (Love: &lt;mor past participle&gt;, Love: &lt;mor past tense sing one&gt;, etc.).47 The ability to perform this kind of inference may also be useful in lexicon development and maintenance. However, its most obvious application is to &amp;quot;bootstrap&amp;quot; lexical access in language-processing systems that make direct use of an on-line lexicon: given a surface form (in analysis</context>
<context position="102699" citStr="Andry et al. (1992)" startWordPosition="16885" endWordPosition="16888">incremental algorithms that take a partial lexical hierarchy and 47 An alternative formulation is to start with a known value and path, and the task is to infer the appropriate nodes. 205 Computational Linguistics Volume 22, Number 2 elaborate it as necessary in the light of successively presented data sets, while Barg (1994) has presented a non-incremental algorithm that induces full DATR hierarchies from suitable data sets. Since DATR is no more than a language, it does not itself dictate how a DATR lexicon is to be used. As it turns out, different researchers have used it very differently. Andry et al. (1992), in the context of a speech recognition task involving the parsing of &amp;quot;extremely large lattices of lexical hypotheses&amp;quot; (p. 248), opted for off-line compilation of their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which was encoded with bit-vectors for speed and compactness. At the other extreme, Duda and Gebhardi (1994) present an interface between a PATR-based parser and a DATR lexicon where the former is dynamically linked to the latter and able to query it freely, in both conventional and reverse modes, without restriction. Gibbon (1993) presents an implementation of a </context>
</contexts>
<marker>Andry, Fraser, McGlashan, Thornton, Youd, 1992</marker>
<rawString>Andry, Francois, Norman Fraser, Scott McGlashan, Simon Thornton, and Nick Youd. 1992 Making DATR work for speech: Lexicon compilation in SUNDIAL. Computational Linguistics 18:245-267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petra Barg</author>
</authors>
<title>Automatic acquisition of DATR theories from observations.</title>
<date>1994</date>
<booktitle>Theories des Lexicons: Arbeiten des Sonderforschungsbereichs 282,</booktitle>
<institution>Heinrich-Heine University of Duesseldorf.</institution>
<contexts>
<context position="98423" citStr="Barg (1994)" startWordPosition="16198" endWordPosition="16199">age generation, or both. Lexicons that are in use also have to be maintained. At present, implementations of lexical representation systems are typically specialized to one or two of these tasks. A language for lexical knowledge representation is merely one component of a lexical representation system, of course, but its design may well have implications for the tasks noted above. A language that coded everything into bit strings might be fully adequate for, say, the induction and generation tasks, but would probably not facilitate manual lexicon maintenance. From a more formal point of view, Barg (1994) provides the useful tabular conceptualization shown in Table 2, below, of the inferential tasks that may be associated with a lexical representation language like DATR. Consider the English verbal morphology 204 Evans and Gazdar Lexical Knowledge Representation Theory Query Value Conventional inference given given unknown Reverse query given unknown given Theory induction unknown given given Table 2 Possible inference tasks (adapted from Barg 1994). facts that provided our running example in Section 2, above. The conventional inference task presupposes that we have a description (such as that</context>
<context position="102407" citStr="Barg (1994)" startWordPosition="16837" endWordPosition="16838">rom the output of the former. The automatic induction of (symbolic) lexicons from data is a very new research area in computational linguistics: Kilbury (1993), Kilbury, Naerger, and Renz (1994), Light (1994), and Light, Reinhard, and Boyle-Hinrichs (1993) have proposed a variety of incremental algorithms that take a partial lexical hierarchy and 47 An alternative formulation is to start with a known value and path, and the task is to infer the appropriate nodes. 205 Computational Linguistics Volume 22, Number 2 elaborate it as necessary in the light of successively presented data sets, while Barg (1994) has presented a non-incremental algorithm that induces full DATR hierarchies from suitable data sets. Since DATR is no more than a language, it does not itself dictate how a DATR lexicon is to be used. As it turns out, different researchers have used it very differently. Andry et al. (1992), in the context of a speech recognition task involving the parsing of &amp;quot;extremely large lattices of lexical hypotheses&amp;quot; (p. 248), opted for off-line compilation of their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which was encoded with bit-vectors for speed and compactness. At the other</context>
</contexts>
<marker>Barg, 1994</marker>
<rawString>Barg, Petra. 1994. Automatic acquisition of DATR theories from observations. Theories des Lexicons: Arbeiten des Sonderforschungsbereichs 282, Heinrich-Heine University of Duesseldorf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doris Bleiching</author>
</authors>
<title>Prosodisches Wissen in Lexicon.</title>
<date>1992</date>
<booktitle>Proceedings of KONVENS-92,</booktitle>
<pages>59--68</pages>
<editor>In G. Goerz, editor,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin:</location>
<contexts>
<context position="65998" citStr="Bleiching 1992" startWordPosition="10852" endWordPosition="10853"> obj 2 27 For the sake of simplicity, we have assumed that the truth values of &lt;ends_in_consonant&gt; and &lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the phonology of the words in DATR also, then these predicates could be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; </context>
</contexts>
<marker>Bleiching, 1992</marker>
<rawString>Bleiching, Doris. 1992. Prosodisches Wissen in Lexicon. In G. Goerz, editor, Proceedings of KONVENS-92, Berlin: Springer-Verlag, pages 59-68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doris Bleiching</author>
</authors>
<title>Integration von Morphophonologie und Prosodie in emn hierarchisches Lexicon.</title>
<date>1994</date>
<booktitle>Proceedings of KONVENS-94,</booktitle>
<pages>32--41</pages>
<editor>In Harald Trost, editor,</editor>
<location>Vienna:</location>
<marker>Bleiching, 1994</marker>
<rawString>Bleiching, Doris. 1994. Integration von Morphophonologie und Prosodie in emn hierarchisches Lexicon. In Harald Trost, editor, Proceedings of KONVENS-94, pages 32-41, Vienna: Oesterreichische Gesellschaft fuer Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
</authors>
<title>Nonmonotonicity and Categorial Unification Grammar. Proefschrift,</title>
<date>1993</date>
<location>Rijksuniversiteit Groningen.</location>
<contexts>
<context position="3028" citStr="Bouma (1993)" startWordPosition="426" endWordPosition="427">owledge representation languages or in contemporary grammar formalisms. But the present paper seeks to * Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail: Roger.Evans@itri.brighton.ac.uk t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language descript</context>
</contexts>
<marker>Bouma, 1993</marker>
<rawString>Bouma, Gosse. 1993. Nonmonotonicity and Categorial Unification Grammar. Proefschrift, Rijksuniversiteit Groningen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
<author>John Nerbonne</author>
</authors>
<title>Lexicons for feature-based systems.</title>
<date>1994</date>
<booktitle>Proceedings of KONVENS-94,</booktitle>
<pages>42--51</pages>
<editor>In Harald Trost, editor,</editor>
<location>Vienna:</location>
<contexts>
<context position="30185" citStr="Bouma and Nerbonne (1994" startWordPosition="5069" endWordPosition="5072">follows:I° Do: &lt;&gt; == VERB &lt;mor root&gt; == do &lt;mor past&gt; == did &lt;mor past participle&gt; == done &lt;mor present tense sing three&gt; does. Likewise, the morphology of Be can be specified as follows:11 Be: &lt;&gt; == EN_VERB &lt;mor root&gt; == be 10 Orthographically, the form does could simply be treated as regular (from do s). However, we have chosen to stipulate it here since, although the spelling appears regular, the phonology is not, so in a lexicon that defined phonological forms it would need to be stipulated. 11 In their default unification reconstruction of this DATR analysis of English verbal inflection, Bouma and Nerbonne (1994, 48) invoke &amp;quot;a feature -SG3 to cover all agreement values other than third person singular&amp;quot; in order &amp;quot;to avoid redundancy,&amp;quot; but they do not explain how they would then account for the first person singular present tense form of be without reintroducing the redundancy that they are seeking to avoid. Moreover, the use of this purely morphological feature leads them to introduce a set of lexical rules in order to map the relevant information across from the (different) syntactic features. 177 Computational Linguistics Volume 22, Number 2 &lt;mor present tense sing one&gt; == am &lt;mor present tense sing</context>
<context position="110336" citStr="Bouma and Nerbonne (1994)" startWordPosition="18051" endWordPosition="18054">ubcategorization specifications to be derived, depending on the setting of a parameter. 207 Computational Linguistics Volume 22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has been in the public domain for the last half-dozen years and been widely used in Europe during that period (by the standards of lexical knowledge representation languages), it is not surprising that it has attracted some critical attention from others working in the field. In this appendix, we consider and respond to the critical material that has been published: Domenig and ten Hacken (1992), Bouma and Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and van der Linden (1992). Langer and Gibbon (1992) also respond to the last three papers in the context of a thorough general review of appropriate evaluation criteria for lexical knowledge representation formalisms. We are indebted to their discussion. Domenig and ten Hacken (1992) base part of their critique of DATR on an idiosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology. This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for morphological processing—even though, a</context>
<context position="124768" citStr="Bouma and Nerbonne (1994)" startWordPosition="20398" endWordPosition="20401">n DATR. They do not provide much of an argument, but what they do say suggests that the simple treatment of passive given in Section 4.5, above, is likewise impossible. This may be because they regard their own interpretation of lexical rules as &amp;quot;novel&amp;quot; (p. 113), although examples of that interpretation of lexical rules appear in earlier DATR work that they cite. Many of the points made in Nerbonne (1992) are repeated from the more accessible Krieger and Nerbonne (1993)57 and we have considered them in our discussion of the latter. Some of the points from the 1992 and 1993 papers resurface in Bouma and Nerbonne (1994). Nerbonne appears to misconstrue Evans, Gazdar, and Moser (1993) as an attempt to augment DATR with re-entrancy and goes on to suggest that DATR is somehow forced to maintain that &amp;quot;all linguistic generalizations tend to follow the lines of morphological form&amp;quot; (p. 47) when, in fact, the attribute ordering used in a DATR treatment of morphology is entirely independent of the use and ordering of those same attributes elsewhere in the lexicon (see the discussion at the end of Section 4.1, above). Like Daelemans and van der Linden (1992), he makes some pessimistic comments 56 Krieger and Nerbonne </context>
<context position="126781" citStr="Bouma and Nerbonne 1994" startWordPosition="20724" endWordPosition="20727">rom the context exactly which distinctions he has in mind or what the basis for the claim is, but the expressions of all existing feature formalisms can be represented by sequences of atoms (and thus by DATR values) and all existing lexicons for feature-based NLP systems use such representations. We therefore find the claim deeply implausible. He also asserts that the fact that an atom may mean one thing in the semantics of DATR and something quite different in the semantics of a feature formalism will lead to &amp;quot;massive redundancy&amp;quot; (p. 47) in lexical specifications (the phrase gets repeated in Bouma and Nerbonne 1994). Again, no argument in support of this conclusion is offered. And we cannot see how semantic overloading of atoms gives rise, of itself, to any kind of redundancy.&apos; Indeed, those who design programming languages normally introduce semantic overloading in order to achieve economy of expression. Finally, Bouma and Nerbonne (1994, 47) comment that &amp;quot;in spite of Kilgarriff&apos;s (1993) interesting work on modelling some derivational relations in the pure inheritance machinery of DATR, we know of no work attempting to model potentially recursive derivational relations, and we remain sceptical about rel</context>
</contexts>
<marker>Bouma, Nerbonne, 1994</marker>
<rawString>Bouma, Gosse and John Nerbonne. 1994. Lexicons for feature-based systems. In Harald Trost, editor, Proceedings of KONVENS-94, pages 42-51, Vienna: Oesterreichische Gesellschaft fuer Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>Ann Copestake</author>
</authors>
<title>Sense extensions as lexical rules. In</title>
<date>1991</date>
<booktitle>Computational approaches to Non-Literal Language, Proceedings of the IJCAI Workshop,</booktitle>
<pages>12--20</pages>
<editor>D. Fass, E. Hinkelman &amp; J. Martin, editors.</editor>
<location>Sydney.</location>
<contexts>
<context position="72095" citStr="Briscoe and Copestake (1991)" startWordPosition="11870" endWordPosition="11873">ference. The combination of evaluable paths with a standard encoding of argument lists make it rather easy to define lexical rules in DATR.34 Here, by way of illustration, is a partial analysis of verbs that implements a lexical rule for the syntax of the (agentless) passive construction:&apos; VERB: past&gt; = = &amp;quot;&lt;mor root&gt;&amp;quot; ed &lt;mor form&gt; = = &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot; &lt;mor cat&gt; == verb &lt;syn sub c at &gt; == &amp;quot;&lt;syn args&gt;&amp;quot; &lt;syn 32 See Carpenter (1991; 1992) and Ritchie et al. (1992, 93-111) for thorough discussion and exemplification of lexical rules in several different grammatical frameworks. More generally, Briscoe and Copestake (1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the very same lexical rule mechanism can be invoked for both sense extensions and morphological processes. 33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazdar, and Weir (1995) report the use of DATR to formulate a lexical rule for Wh-questions in LTAG, inter alia. 34 Evaluable paths are not essential in this domain: thus Kilgarriff (1993) does no</context>
</contexts>
<marker>Briscoe, Copestake, 1991</marker>
<rawString>Briscoe, Ted and Ann Copestake. 1991. Sense extensions as lexical rules. In D. Fass, E. Hinkelman &amp; J. Martin, editors. Computational approaches to Non-Literal Language, Proceedings of the IJCAI Workshop, pages 12-20, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
</authors>
<title>Ann Copestake, and Alex Lascarides.</title>
<date>1995</date>
<booktitle>Computational Lexical Semantics. Cambridge:</booktitle>
<pages>272--302</pages>
<editor>Blocking. In Patrick Saint-Dizier &amp; Evelyne Viegas, editors.</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="80187" citStr="Briscoe (1995)" startWordPosition="13232" endWordPosition="13233"> form&gt; = hoove s. But it is quite straightforward to define a description that will lead to the following theorem set: Word7: &lt;syn number&gt; = plural &lt;mor form&gt; = hoof s &lt;mor form alternant&gt; = hoove s. Or something like this: Word7: &lt;syn number&gt; = plural &lt;mor forms&gt; = hoof s I hoove s Or this: Word7: &lt;syn number&gt; = plural &lt;mor forms&gt; = { hoof s , hoove s I. Of course, as far as DATR is concerned { hoof s , hoove s } is just a sequence encode the regular and subregular polysemy associated with the crop, fiber, yarn, fabric, and garment senses of words like cotton and silk. See also Copestake and Briscoe (1995) for related work on regular and subregular polysemy. 38 For perspicuity, we provide these in DATR-augmented English here. But in a serious treatment they could just as well be given in a DATR-encoding of the lambda calculus, as used in Cahill and Evans (1990), for example. 39 See also the dreamt/dreamed verb class discussed by Russell et al. (1992, 330-331). 197 Computational Linguistics Volume 22, Number 2 of seven atoms. It is up to some component external to DATR that makes use of such complex values to interpret it as a two-member set of alternative forms. Likewise, if we have some good r</context>
</contexts>
<marker>Briscoe, 1995</marker>
<rawString>Briscoe, Ted, Ann Copestake, and Alex Lascarides. 1995. Blocking. In Patrick Saint-Dizier &amp; Evelyne Viegas, editors. Computational Lexical Semantics. Cambridge: Cambridge University Press, pages 272-302.</rawString>
</citation>
<citation valid="true">
<date>1993</date>
<booktitle>Inheritance, Defaults, and the Lexicon,</booktitle>
<editor>Briscoe, Ted, Valeria de Paiva, and Ann Copestake, editors.</editor>
<publisher>Cambridge University Press.</publisher>
<location>Cambridge:</location>
<contexts>
<context position="2843" citStr="(1993)" startWordPosition="400" endWordPosition="400">defining inheritance networks with path/value equations. In keeping with its intendedly minimalist character, it lacks many of the constructs embodied either in general-purpose knowledge representation languages or in contemporary grammar formalisms. But the present paper seeks to * Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail: Roger.Evans@itri.brighton.ac.uk t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics </context>
<context position="66345" citStr="(1993)" startWordPosition="10906" endWordPosition="10906">uld be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1 pl&gt; == tu S2:&lt;&gt; &lt;subj 2 pl&gt; == m S2:&lt;&gt; &lt;subj 3 pl&gt; == wa S2:&lt;&gt;. &lt;subj &lt;past&gt; == li 53:&lt;&gt; &lt;futr&gt; == ta S3:&lt;&gt;. &lt;obj 1 sg&gt; == ni S4:&lt;&gt; &lt;obj 2 sg&gt; == ku S4:&lt;&gt; &lt;obj 3 sg&gt; == m S4:&lt;&gt; &lt;obj 1 pl&gt; == tu 54:&lt;&gt; &lt;obj 2 pl&gt; == wa 54:&lt;&gt; &lt;obj 3 pl&gt; == wa 54:&lt;&gt;. &lt;like&gt; == penda. Although the example is trivial, the technique is both powerful</context>
<context position="72687" citStr="(1993)" startWordPosition="11964" endWordPosition="11964">pestake (1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the very same lexical rule mechanism can be invoked for both sense extensions and morphological processes. 33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazdar, and Weir (1995) report the use of DATR to formulate a lexical rule for Wh-questions in LTAG, inter alia. 34 Evaluable paths are not essential in this domain: thus Kilgarriff (1993) does not employ them in his DATR analysis of verbal alternations in the context of an H PSG lexicon, although he does use the standard encoding of argument lists. 35 Since our purpose here is expository, we have deliberately kept the analysis to a minimum. Dealing with the semantics of passive, for example, involves more of the same, rather than any issue of principle. 194 Evans and Gazdar Lexical Knowledge Representation &lt;syn args&gt; == NP_ARG:&lt;&gt; &lt;syn args first syn case&gt; == nominative. PASSIVE_VERB: &lt;&gt; == VERB &lt;mor passive&gt; == &amp;quot;&lt;mor past&gt;&amp;quot; &lt;syn subcat rest&gt; == &amp;quot;&lt;syn args rest rest&gt;&amp;quot;. TR_VERB:</context>
<context position="95934" citStr="(1993, 214)" startWordPosition="15809" endWordPosition="15810"> in respect of &lt;cat&gt; values) can arise. More generally, OMI is invaluable for partitioning the various different, and largely independent, aspects of lexical description conventionally associated with such initial path prefixes as Om (phonology), mor (morphology), syn (syntax), and sem (semantics). In the English verbal system, for example, most morphological subregularities (such as having a past participle form in -en) operate entirely independently of most syntactic subregularities (such as having a ditransitive subcategorization frame). Within the semantic domain, Pustejovsky and Boguraev (1993, 214) introduce the expression typed inheritance for OMI and argue for its advantages in connection with the consistent assembly of the different facets of meaning associated with a lexical item. The above examples of OMI are in fact instances of a more general phenomenon in DATR. We have already noted that the combination of the longest-defined-subpathwins and logical consistency are the basis of DATR&apos;s support for coherent multiple inheritance. It turns out that functionality (which of course implies consistency) ensures orthogonality so that OMI falls out as the most normal, natural mode of defi</context>
<context position="100678" citStr="(1993)" startWordPosition="16565" endWordPosition="16565"> of inference may also be useful in lexicon development and maintenance. However, its most obvious application is to &amp;quot;bootstrap&amp;quot; lexical access in language-processing systems that make direct use of an on-line lexicon: given a surface form (in analysis) or a semantic form (in generation), we need to identify a lexical entry associated with that form by reverse query, and then access other lexical information associated with the entry by conventional inference. Langer (1994) gives an inference algorithm, based on the familiar chart data structure, for reverse querying DATR lexicons; and Gibbon (1993) describes EDQL (Extended DATR Query Language) which permits quantification into components of multisentence DATR queries. The final task is that of theory induction. Here one starts with a set of known query-value pairs (Love: &lt;mor past participle&gt; = love ed., Love: &lt;mor pres tense sing three&gt; = love s., etc.) and the task is to induce a description that has those pairs as theorems under the application of conventional inference. In a world in which all the relevant data was already clearly set out in descriptive linguistic work, an algorithm that efficiently achieved this kind of induction w</context>
<context position="101955" citStr="(1993)" startWordPosition="16767" endWordPosition="16767">xicons. In the real world, such an algorithm would still be useful for domains like morphology (where the quality and clarity of extant descriptive linguistic work is very high), for bootstrapping lexical descriptions for subsequent manual development by humans, for updating lexicons in the light of newly encountered lexical information, and for converting one kind of lexicon into a completely different kind of lexicon by inducing the latter from the output of the former. The automatic induction of (symbolic) lexicons from data is a very new research area in computational linguistics: Kilbury (1993), Kilbury, Naerger, and Renz (1994), Light (1994), and Light, Reinhard, and Boyle-Hinrichs (1993) have proposed a variety of incremental algorithms that take a partial lexical hierarchy and 47 An alternative formulation is to start with a known value and path, and the task is to infer the appropriate nodes. 205 Computational Linguistics Volume 22, Number 2 elaborate it as necessary in the light of successively presented data sets, while Barg (1994) has presented a non-incremental algorithm that induces full DATR hierarchies from suitable data sets. Since DATR is no more than a language, it doe</context>
<context position="103266" citStr="(1993)" startWordPosition="16978" endWordPosition="16978">t very differently. Andry et al. (1992), in the context of a speech recognition task involving the parsing of &amp;quot;extremely large lattices of lexical hypotheses&amp;quot; (p. 248), opted for off-line compilation of their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which was encoded with bit-vectors for speed and compactness. At the other extreme, Duda and Gebhardi (1994) present an interface between a PATR-based parser and a DATR lexicon where the former is dynamically linked to the latter and able to query it freely, in both conventional and reverse modes, without restriction. Gibbon (1993) presents an implementation of a very flexible query language, EDQL, which allows quantification over any constituents of (possibly complex) DATR queries. 5.4 Implementations As already noted, the inferential core of DATR is extremely simple to implement. We know of the existence of approximately a dozen different implementations of the language but there may well be others that we do not know of. The best known, and most widely available are our own (Brighton/Sussex), which is written in Prolog and runs on most Unix platforms, Gibbon&apos;s (Bielefeld) DDATR Scheme and NODE Sicstus Prolog implemen</context>
<context position="109146" citStr="(1993)" startWordPosition="17874" endWordPosition="17874">tions and a KIMMO-style orthographic component, implementing all of these, including the H PSG lexical rules, in DATR. DATR itself does not mandate any of the choices in this example, but equally, nor does it allow such choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as to the theoretical frameworks in which the description is to be conducted: there is no &amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example, Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX theory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press) use DATR to implement their Network Morphology framework, and Gazdar (1992) shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of assembly language for constructing (or reconstructing) higher-level theories of lexical representation. 49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of polytheoretic lexicons. For example, one that would allow either categorial or HPSG-style subcategorization specifications to </context>
<context position="110382" citStr="(1993)" startWordPosition="18060" endWordPosition="18060">etting of a parameter. 207 Computational Linguistics Volume 22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has been in the public domain for the last half-dozen years and been widely used in Europe during that period (by the standards of lexical knowledge representation languages), it is not surprising that it has attracted some critical attention from others working in the field. In this appendix, we consider and respond to the critical material that has been published: Domenig and ten Hacken (1992), Bouma and Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and van der Linden (1992). Langer and Gibbon (1992) also respond to the last three papers in the context of a thorough general review of appropriate evaluation criteria for lexical knowledge representation formalisms. We are indebted to their discussion. Domenig and ten Hacken (1992) base part of their critique of DATR on an idiosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology. This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for morphological processing—even though, as they note &amp;quot;DATR is strictly speaking not an </context>
<context position="117467" citStr="(1993)" startWordPosition="19219" endWordPosition="19219"> that most specific level is. Our position is that this is part of the lexical metatheory, rather than the lexical description itself. It needs to be known by anyone (or any system) wishing to access the lexicon properly, and it may be practically useful to constrain access by checking for the well-formedness of queries according to such a metatheory—this could be done quite straightforwardly in DATR as an adjunct to the main lexicon if desired. This notion, however, is external to, and independent of, 51 For another critical discussion of the same Domenig and ten Hacken material, see Russell (1993). 52 One of our referees comments that &amp;quot;the issue ... appears to be rather scholastic.&amp;quot; We agree. 209 Computational Linguistics Volume 22, Number 2 the lexical description itself: the range of sensible queries only weakly constrains the manner in which their values are defined. Their third objection concerns multiple inheritance. They draw attention to the fact that DATR&apos;s normal mode of multiple inheritance is orthogonal and complain that prioritized multiple inheritance can only be expressed with additional DATR code (p. 63). However, we agree with their earlier comment &amp;quot;that orthogonal mult</context>
</contexts>
<marker>1993</marker>
<rawString>Briscoe, Ted, Valeria de Paiva, and Ann Copestake, editors. 1993. Inheritance, Defaults, and the Lexicon, Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dunstan Brown</author>
<author>Andrew Hippisley</author>
</authors>
<title>Conflict in Russian genitive plural assignment: A solution represented in DATR.</title>
<date>1994</date>
<journal>Journal of Slavic Linguistics,</journal>
<pages>2--1</pages>
<marker>Brown, Hippisley, 1994</marker>
<rawString>Brown, Dunstan and Andrew Hippisley. 1994. Conflict in Russian genitive plural assignment: A solution represented in DATR. Journal of Slavic Linguistics, 2(1):48-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cahill</author>
</authors>
<title>Some reflections on the conversion of the TIC lexicon into DATR.</title>
<date>1993</date>
<pages>47--57</pages>
<editor>In Ted Briscoe, Valeria de Paiva, and Ann Copestake, editors. Inheritance, Defaults, and</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="4644" citStr="Cahill 1993" startWordPosition="681" endWordPosition="682">can express all the evident generalizations and subgeneralizations about such entries. Our first publications on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference (i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2 With respect to (iii), the core inference engine for DATR can be coded in a page of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen different implementations of the language, some of which have been used with large DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a, 1994; Cahill and Evans 1990). We will comment further on implementation matters in Section 5, below. However, the main purpose of the present paper is to exhibit the use of DATR for lexical description (iv) and the way it makes it relatively easy to capture lexical generalizations and subregularities at a variety of analytic levels (v). We will pursue (iv) and (v) in the context of an informal example-based introduction to the language and to techniques for its use, and we will make frequent reference to the DATR-based lexical work that has been done since 1989. The paper is organized as fo</context>
<context position="66017" citStr="Cahill 1993" startWordPosition="10855" endWordPosition="10856"> of simplicity, we have assumed that the truth values of &lt;ends_in_consonant&gt; and &lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the phonology of the words in DATR also, then these predicates could be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1</context>
</contexts>
<marker>Cahill, 1993</marker>
<rawString>Cahill, Lynne. 1993a. Some reflections on the conversion of the TIC lexicon into DATR. In Ted Briscoe, Valeria de Paiva, and Ann Copestake, editors. Inheritance, Defaults, and the Lexicon. Cambridge: Cambridge University Press, pages 47-57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cahill</author>
</authors>
<date>1993</date>
<booktitle>Morphonology in the lexicon. Sixth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>87--96</pages>
<contexts>
<context position="4644" citStr="Cahill 1993" startWordPosition="681" endWordPosition="682">can express all the evident generalizations and subgeneralizations about such entries. Our first publications on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference (i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2 With respect to (iii), the core inference engine for DATR can be coded in a page of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen different implementations of the language, some of which have been used with large DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a, 1994; Cahill and Evans 1990). We will comment further on implementation matters in Section 5, below. However, the main purpose of the present paper is to exhibit the use of DATR for lexical description (iv) and the way it makes it relatively easy to capture lexical generalizations and subregularities at a variety of analytic levels (v). We will pursue (iv) and (v) in the context of an informal example-based introduction to the language and to techniques for its use, and we will make frequent reference to the DATR-based lexical work that has been done since 1989. The paper is organized as fo</context>
<context position="66017" citStr="Cahill 1993" startWordPosition="10855" endWordPosition="10856"> of simplicity, we have assumed that the truth values of &lt;ends_in_consonant&gt; and &lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the phonology of the words in DATR also, then these predicates could be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1</context>
</contexts>
<marker>Cahill, 1993</marker>
<rawString>Cahill, Lynne. 1993b. Morphonology in the lexicon. Sixth Conference of the European Chapter of the Association for Computational Linguistics, pages 87-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cahill</author>
</authors>
<title>An inheritance-based lexicon for message understanding systems.</title>
<date>1994</date>
<booktitle>Fourth ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>211--212</pages>
<marker>Cahill, 1994</marker>
<rawString>Cahill, Lynne. 1994. An inheritance-based lexicon for message understanding systems. Fourth ACL Conference on Applied Natural Language Processing, pages 211-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cahill</author>
<author>Roger Evans</author>
</authors>
<title>An application of DATR: The TIC lexicon.</title>
<date>1990</date>
<booktitle>In Proceedings of the 9th European Conference on Artificial Intelligence,</booktitle>
<pages>120--125</pages>
<location>Stockholm.</location>
<contexts>
<context position="4675" citStr="Cahill and Evans 1990" startWordPosition="684" endWordPosition="687">evident generalizations and subgeneralizations about such entries. Our first publications on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference (i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2 With respect to (iii), the core inference engine for DATR can be coded in a page of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen different implementations of the language, some of which have been used with large DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a, 1994; Cahill and Evans 1990). We will comment further on implementation matters in Section 5, below. However, the main purpose of the present paper is to exhibit the use of DATR for lexical description (iv) and the way it makes it relatively easy to capture lexical generalizations and subregularities at a variety of analytic levels (v). We will pursue (iv) and (v) in the context of an informal example-based introduction to the language and to techniques for its use, and we will make frequent reference to the DATR-based lexical work that has been done since 1989. The paper is organized as follows: Section 2 uses an analys</context>
<context position="80447" citStr="Cahill and Evans (1990)" startWordPosition="13274" endWordPosition="13277">l &lt;mor forms&gt; = hoof s I hoove s Or this: Word7: &lt;syn number&gt; = plural &lt;mor forms&gt; = { hoof s , hoove s I. Of course, as far as DATR is concerned { hoof s , hoove s } is just a sequence encode the regular and subregular polysemy associated with the crop, fiber, yarn, fabric, and garment senses of words like cotton and silk. See also Copestake and Briscoe (1995) for related work on regular and subregular polysemy. 38 For perspicuity, we provide these in DATR-augmented English here. But in a serious treatment they could just as well be given in a DATR-encoding of the lambda calculus, as used in Cahill and Evans (1990), for example. 39 See also the dreamt/dreamed verb class discussed by Russell et al. (1992, 330-331). 197 Computational Linguistics Volume 22, Number 2 of seven atoms. It is up to some component external to DATR that makes use of such complex values to interpret it as a two-member set of alternative forms. Likewise, if we have some good reason for wanting to put together the various senses of cherry into a value returned by a single path, then we can write something like this: Cherry: &lt;sem glosses&gt; == { &lt;sem gloss 1&gt; , &lt;sem gloss 2&gt; , &lt;sem gloss 3&gt; }. which will then provide this theorem: Cher</context>
</contexts>
<marker>Cahill, Evans, 1990</marker>
<rawString>Cahill, Lynne and Roger Evans. 1990. An application of DATR: The TIC lexicon. In Proceedings of the 9th European Conference on Artificial Intelligence, pages 120-125, Stockholm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo Calder</author>
</authors>
<title>Feature-value logics: Some limits on the role of defaults. In</title>
<date>1994</date>
<booktitle>Constraints, Language and Computation.</booktitle>
<pages>205--222</pages>
<editor>C. J. Rupp, M. A. Rosner, &amp; R. L. Johnson, editors.</editor>
<publisher>Academic Press,</publisher>
<location>London:</location>
<contexts>
<context position="3086" citStr="Calder (1994)" startWordPosition="433" endWordPosition="434">ar formalisms. But the present paper seeks to * Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail: Roger.Evans@itri.brighton.ac.uk t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number o</context>
</contexts>
<marker>Calder, 1994</marker>
<rawString>Calder, Jo. 1994. Feature-value logics: Some limits on the role of defaults. In C. J. Rupp, M. A. Rosner, &amp; R. L. Johnson, editors. Constraints, Language and Computation. London: Academic Press, pages 205-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The generative power of categorial grammars and head-driven phrase structure grammars with lexical rules.</title>
<date>1991</date>
<journal>Computational Linguistics</journal>
<pages>17--301</pages>
<contexts>
<context position="71903" citStr="Carpenter (1991" startWordPosition="11846" endWordPosition="11847">stics that have led many linguists to consign them to the lexicon. They usually involve a difference in argument structure and this is sometimes accompanied by a morphological difference. The combination of evaluable paths with a standard encoding of argument lists make it rather easy to define lexical rules in DATR.34 Here, by way of illustration, is a partial analysis of verbs that implements a lexical rule for the syntax of the (agentless) passive construction:&apos; VERB: past&gt; = = &amp;quot;&lt;mor root&gt;&amp;quot; ed &lt;mor form&gt; = = &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot; &lt;mor cat&gt; == verb &lt;syn sub c at &gt; == &amp;quot;&lt;syn args&gt;&amp;quot; &lt;syn 32 See Carpenter (1991; 1992) and Ritchie et al. (1992, 93-111) for thorough discussion and exemplification of lexical rules in several different grammatical frameworks. More generally, Briscoe and Copestake (1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the very same lexical rule mechanism can be invoked for both sense extensions and morphological processes. 33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazd</context>
</contexts>
<marker>Carpenter, 1991</marker>
<rawString>Carpenter, Bob. 1991. The generative power of categorial grammars and head-driven phrase structure grammars with lexical rules. Computational Linguistics 17:301-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Categorial grammars, lexical rules, and the English predicative.</title>
<date>1992</date>
<booktitle>Formal Grammar: Theory and Implementation.</booktitle>
<pages>168--242</pages>
<editor>In Robert Levine, editor.</editor>
<publisher>University Press,</publisher>
<location>New York: Oxford</location>
<marker>Carpenter, 1992</marker>
<rawString>Carpenter, Bob. 1992. Categorial grammars, lexical rules, and the English predicative. In Robert Levine, editor. Formal Grammar: Theory and Implementation. New York: Oxford University Press, pages 168-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>The representation of lexical semantic information.</title>
<date>1992</date>
<journal>Cognitive Science Research Paper CSRP</journal>
<pages>280</pages>
<institution>University of Sussex,</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="3104" citStr="Copestake (1992)" startWordPosition="435" endWordPosition="436">But the present paper seeks to * Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail: Roger.Evans@itri.brighton.ac.uk t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which </context>
</contexts>
<marker>Copestake, 1992</marker>
<rawString>Copestake, Ann. 1992. The representation of lexical semantic information. Ph.D. dissertation, University of Sussex, Cognitive Science Research Paper CSRP 280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Ted Briscoe</author>
</authors>
<title>Lexical operations in a unification based framework.</title>
<date>1992</date>
<booktitle>Lexical Semantics and Knowledge Representation.</booktitle>
<pages>101--119</pages>
<editor>In James Pustejovsky &amp; Sabine Bergler, editors.</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin:</location>
<contexts>
<context position="72128" citStr="Copestake and Briscoe (1992)" startWordPosition="11875" endWordPosition="11878">able paths with a standard encoding of argument lists make it rather easy to define lexical rules in DATR.34 Here, by way of illustration, is a partial analysis of verbs that implements a lexical rule for the syntax of the (agentless) passive construction:&apos; VERB: past&gt; = = &amp;quot;&lt;mor root&gt;&amp;quot; ed &lt;mor form&gt; = = &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot; &lt;mor cat&gt; == verb &lt;syn sub c at &gt; == &amp;quot;&lt;syn args&gt;&amp;quot; &lt;syn 32 See Carpenter (1991; 1992) and Ritchie et al. (1992, 93-111) for thorough discussion and exemplification of lexical rules in several different grammatical frameworks. More generally, Briscoe and Copestake (1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the very same lexical rule mechanism can be invoked for both sense extensions and morphological processes. 33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazdar, and Weir (1995) report the use of DATR to formulate a lexical rule for Wh-questions in LTAG, inter alia. 34 Evaluable paths are not essential in this domain: thus Kilgarriff (1993) does not employ them in his DATR analysi</context>
</contexts>
<marker>Copestake, Briscoe, 1992</marker>
<rawString>Copestake, Ann and Ted Briscoe. 1992. Lexical operations in a unification based framework. In James Pustejovsky &amp; Sabine Bergler, editors. Lexical Semantics and Knowledge Representation. Berlin: Springer-Verlag, pages 101-119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Ted Briscoe</author>
</authors>
<title>Regular polysemy and semi-productive sense extension.</title>
<date>1995</date>
<journal>Journal of Semantics</journal>
<pages>12--15</pages>
<contexts>
<context position="80187" citStr="Copestake and Briscoe (1995)" startWordPosition="13230" endWordPosition="13233"> = hoof s &lt;mor form&gt; = hoove s. But it is quite straightforward to define a description that will lead to the following theorem set: Word7: &lt;syn number&gt; = plural &lt;mor form&gt; = hoof s &lt;mor form alternant&gt; = hoove s. Or something like this: Word7: &lt;syn number&gt; = plural &lt;mor forms&gt; = hoof s I hoove s Or this: Word7: &lt;syn number&gt; = plural &lt;mor forms&gt; = { hoof s , hoove s I. Of course, as far as DATR is concerned { hoof s , hoove s } is just a sequence encode the regular and subregular polysemy associated with the crop, fiber, yarn, fabric, and garment senses of words like cotton and silk. See also Copestake and Briscoe (1995) for related work on regular and subregular polysemy. 38 For perspicuity, we provide these in DATR-augmented English here. But in a serious treatment they could just as well be given in a DATR-encoding of the lambda calculus, as used in Cahill and Evans (1990), for example. 39 See also the dreamt/dreamed verb class discussed by Russell et al. (1992, 330-331). 197 Computational Linguistics Volume 22, Number 2 of seven atoms. It is up to some component external to DATR that makes use of such complex values to interpret it as a two-member set of alternative forms. Likewise, if we have some good r</context>
</contexts>
<marker>Copestake, Briscoe, 1995</marker>
<rawString>Copestake, Ann and Ted Briscoe. 1995. Regular polysemy and semi-productive sense extension. Journal of Semantics 12:15-67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greville Corbett</author>
<author>Norman Fraser</author>
</authors>
<title>Network Morphology: A DATR account of Russian nominal inflection.</title>
<date>1993</date>
<journal>Journal of Linguistics</journal>
<pages>29--113</pages>
<contexts>
<context position="109146" citStr="Corbett and Fraser (1993)" startWordPosition="17871" endWordPosition="17874">ological representations and a KIMMO-style orthographic component, implementing all of these, including the H PSG lexical rules, in DATR. DATR itself does not mandate any of the choices in this example, but equally, nor does it allow such choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as to the theoretical frameworks in which the description is to be conducted: there is no &amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example, Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX theory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press) use DATR to implement their Network Morphology framework, and Gazdar (1992) shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of assembly language for constructing (or reconstructing) higher-level theories of lexical representation. 49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of polytheoretic lexicons. For example, one that would allow either categorial or HPSG-style subcategorization specifications to </context>
</contexts>
<marker>Corbett, Fraser, 1993</marker>
<rawString>Corbett, Greville and Norman Fraser. 1993. Network Morphology: A DATR account of Russian nominal inflection. Journal of Linguistics 29:113-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
</authors>
<title>Review of Inheritance, Defaults, and the Lexicon,</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<pages>20--4</pages>
<editor>by Ted Briscoe, Valeria de Paiva &amp; Ann Copestake, editors.</editor>
<contexts>
<context position="3122" citStr="Daelemans (1994)" startWordPosition="437" endWordPosition="438">per seeks to * Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail: Roger.Evans@itri.brighton.ac.uk t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here.</context>
</contexts>
<marker>Daelemans, 1994</marker>
<rawString>Daelemans, Walter. 1994. Review of Inheritance, Defaults, and the Lexicon, by Ted Briscoe, Valeria de Paiva &amp; Ann Copestake, editors. Computational Linguistics 20(4):661-664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Koenraad De Smedt</author>
</authors>
<title>Inheritance in an object-oriented representation of linguistic categories.</title>
<date>1994</date>
<journal>International Journal of Human-Computer Studies</journal>
<pages>41--1</pages>
<marker>Daelemans, De Smedt, 1994</marker>
<rawString>Daelemans, Walter and Koenraad De Smedt. 1994. Inheritance in an object-oriented representation of linguistic categories. International Journal of Human-Computer Studies 41(1/2):149-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Koenraad De Smedt</author>
<author>Gerald Gazdar</author>
</authors>
<date>1992</date>
<booktitle>Inheritance in natural language processing. Computational Linguistics</booktitle>
<pages>18--2</pages>
<marker>Daelemans, De Smedt, Gazdar, 1992</marker>
<rawString>Daelemans, Walter, Koenraad De Smedt, and Gerald Gazdar. 1992. Inheritance in natural language processing. Computational Linguistics 18(2):205-218.</rawString>
</citation>
<citation valid="true">
<date>1992</date>
<journal>Computational Linguistics</journal>
<volume>18</volume>
<issue>2</issue>
<editor>Daelemans, Walter and Gerald Gazdar, editors.</editor>
<note>special issues on inheritance.</note>
<contexts>
<context position="2022" citStr="(1992)" startWordPosition="285" endWordPosition="285">ike regular lexemes except that they deviate in one or two characteristics. What is needed is a natural way of saying &amp;quot;this lexeme is regular except for this property.&amp;quot; One obvious approach is to use nonmonotonicity and inheritance machinery to capture such lexical irregularity (and subregularity), and much recent research into the design of representation languages for natural language lexicons has thus made use of nonmonotonic inheritance networks (or &amp;quot;semantic nets&amp;quot;) as originally developed for more general representation purposes in Artificial Intelligence. Daelemans, De Smedt, and Gazdar (1992) provide a rationale for, and an introduction to, this body of research and we will not rehearse the content of that paper here, nor review the work cited there.1 DAT R is a rather spartan nonmonotonic language for defining inheritance networks with path/value equations. In keeping with its intendedly minimalist character, it lacks many of the constructs embodied either in general-purpose knowledge representation languages or in contemporary grammar formalisms. But the present paper seeks to * Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail: Rog</context>
<context position="3270" citStr="(1992)" startWordPosition="461" endWordPosition="461"> Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily an</context>
<context position="67938" citStr="(1992)" startWordPosition="11203" endWordPosition="11203">. We give below a small fragment of such an FST in which + is used as a morpheme boundary marker. Note the role of DATR variables in giving concise expression to the rules: # vars $abc:abcdefghijklmnopqrstuvwxyz. # vars $vow: ae io u. SPELL: &lt;&gt; == &lt;+&gt; == &lt;&gt; &lt;$abc&gt; == $abc &lt;&gt; &lt;e + $vow&gt; == $vow &lt;&gt;. These axioms then give rise to theorems such as these: SPELL: &lt;1 o v e&gt; =love &lt;1 o v e + s&gt; =loves &lt;love+ed&gt; =loved &lt;love+er&gt; =lover &lt;love+ly&gt; =lovely 30 For clarity, this FST does not exploit default inheritance to capture the 50% overlap between the subject and object pronoun paradigms. See Gazdar (1992) for a version that does. 31 And see McFetridge and Villavicencio (1995) for a less exotic application. 192 Evans and Gazdar Lexical Knowledge Representation &lt;love+ing&gt; =loving &lt;love+able&gt; lovable.= 4.4 Representing Lists DATR&apos;s foundation in path/value specifications means that many of the representational idioms of unification formalisms transfer fairly directly. A good example is the use of first and rest attributes to represent list-structured features, such as syntactic arguments and subcategorized complements. The following definitions could be used to extend our verb fragment by introdu</context>
<context position="71910" citStr="(1991; 1992)" startWordPosition="11847" endWordPosition="11848"> have led many linguists to consign them to the lexicon. They usually involve a difference in argument structure and this is sometimes accompanied by a morphological difference. The combination of evaluable paths with a standard encoding of argument lists make it rather easy to define lexical rules in DATR.34 Here, by way of illustration, is a partial analysis of verbs that implements a lexical rule for the syntax of the (agentless) passive construction:&apos; VERB: past&gt; = = &amp;quot;&lt;mor root&gt;&amp;quot; ed &lt;mor form&gt; = = &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot; &lt;mor cat&gt; == verb &lt;syn sub c at &gt; == &amp;quot;&lt;syn args&gt;&amp;quot; &lt;syn 32 See Carpenter (1991; 1992) and Ritchie et al. (1992, 93-111) for thorough discussion and exemplification of lexical rules in several different grammatical frameworks. More generally, Briscoe and Copestake (1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the very same lexical rule mechanism can be invoked for both sense extensions and morphological processes. 33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazdar, and</context>
<context position="102699" citStr="(1992)" startWordPosition="16888" endWordPosition="16888">lgorithms that take a partial lexical hierarchy and 47 An alternative formulation is to start with a known value and path, and the task is to infer the appropriate nodes. 205 Computational Linguistics Volume 22, Number 2 elaborate it as necessary in the light of successively presented data sets, while Barg (1994) has presented a non-incremental algorithm that induces full DATR hierarchies from suitable data sets. Since DATR is no more than a language, it does not itself dictate how a DATR lexicon is to be used. As it turns out, different researchers have used it very differently. Andry et al. (1992), in the context of a speech recognition task involving the parsing of &amp;quot;extremely large lattices of lexical hypotheses&amp;quot; (p. 248), opted for off-line compilation of their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which was encoded with bit-vectors for speed and compactness. At the other extreme, Duda and Gebhardi (1994) present an interface between a PATR-based parser and a DATR lexicon where the former is dynamically linked to the latter and able to query it freely, in both conventional and reverse modes, without restriction. Gibbon (1993) presents an implementation of a </context>
<context position="109026" citStr="(1992)" startWordPosition="17854" endWordPosition="17854">le semantic representations, H PSG-style syntactic representations, &amp;quot;item &amp; arrangement&amp;quot;- style morphological representations and a KIMMO-style orthographic component, implementing all of these, including the H PSG lexical rules, in DATR. DATR itself does not mandate any of the choices in this example, but equally, nor does it allow such choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as to the theoretical frameworks in which the description is to be conducted: there is no &amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example, Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX theory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press) use DATR to implement their Network Morphology framework, and Gazdar (1992) shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of assembly language for constructing (or reconstructing) higher-level theories of lexical representation. 49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of polyth</context>
<context position="110309" citStr="(1992)" startWordPosition="18050" endWordPosition="18050">-style subcategorization specifications to be derived, depending on the setting of a parameter. 207 Computational Linguistics Volume 22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has been in the public domain for the last half-dozen years and been widely used in Europe during that period (by the standards of lexical knowledge representation languages), it is not surprising that it has attracted some critical attention from others working in the field. In this appendix, we consider and respond to the critical material that has been published: Domenig and ten Hacken (1992), Bouma and Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and van der Linden (1992). Langer and Gibbon (1992) also respond to the last three papers in the context of a thorough general review of appropriate evaluation criteria for lexical knowledge representation formalisms. We are indebted to their discussion. Domenig and ten Hacken (1992) base part of their critique of DATR on an idiosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology. This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for morphologica</context>
<context position="114685" citStr="(1992)" startWordPosition="18759" endWordPosition="18759">icon development cannot keep track of all the interactions. They provide no evidence for this assertion and the widespread adoption, development, and use of a variety of large inheritance lexicons in working NLP systems over the last few years make the assertion seem somewhat implausible. They conclude that their evaluation of DATR has been &amp;quot;unfair&amp;quot; (p. 29) because they failed to consider the language in its natural environment. We agree that their evaluation is unfair, but ascribe the cause to the ways in which they attempted to apply DATR to their chosen tasks.&apos; Daelemans and van der Linden (1992) review a number of approaches to lexical knowledge representation, including DATR, with respect to their notational adequacy and expressivity. They argue that adequate approaches will allow (i) recursive path formation; (ii) multiple inheritance, preferably orthogonal multiple inheritance; (iii) nonmonotonic inheritance; and require (iv) that irregular items take precedence over regular ones without explicit coding (p. 61). Since, as we have seen, and as Langer and Gibbon (1992) note, DATR has all four of these properties, one might expect it to emerge from their review with at least a low al</context>
<context position="121403" citStr="(1992)" startWordPosition="19849" endWordPosition="19849">lysis to which they refer. In order to reconstruct paradigms in their feature language, they invoke distributed disjunctions (fixed-length term expressions).&amp;quot; The descriptive problem with this approach, as they admit, is that &amp;quot;there is no way to note that a single form in a paradigm is exceptional without respecifying the entire paradigm—the disjunction must be respecified as a whole ... there is no way to 53 But see Daelemans and De Smedt (1994) for articulation of the methodological principle that underlies the third objection. 54 The issues are also discussed in detail by Langer and Gibbon (1992). 55 Langer and Gibbon (1992) argue, at some length, that it is formally inappropriate to add distributed disjunction to a typed feature structure language of the kind otherwise assumed by Krieger and Nerbonne. 210 Evans and Gazdar Lexical Knowledge Representation identify a particular alternation within the distributed disjunction&amp;quot; (p. 107). Anyone familiar with the way inflection works in Romance languages will immediately see that this is a very serious weakness. In Latin, for example, there are many individual words and small subclasses of words that deviate from a major declension or conj</context>
<context position="124551" citStr="(1992)" startWordPosition="20363" endWordPosition="20363">es. From remarks they make on pages 109 and 111 of their paper, Krieger and Nerbonne appear to believe that it is impossible to implement a particular inflectional analysis of the passive in Latin in DATR. They do not provide much of an argument, but what they do say suggests that the simple treatment of passive given in Section 4.5, above, is likewise impossible. This may be because they regard their own interpretation of lexical rules as &amp;quot;novel&amp;quot; (p. 113), although examples of that interpretation of lexical rules appear in earlier DATR work that they cite. Many of the points made in Nerbonne (1992) are repeated from the more accessible Krieger and Nerbonne (1993)57 and we have considered them in our discussion of the latter. Some of the points from the 1992 and 1993 papers resurface in Bouma and Nerbonne (1994). Nerbonne appears to misconstrue Evans, Gazdar, and Moser (1993) as an attempt to augment DATR with re-entrancy and goes on to suggest that DATR is somehow forced to maintain that &amp;quot;all linguistic generalizations tend to follow the lines of morphological form&amp;quot; (p. 47) when, in fact, the attribute ordering used in a DATR treatment of morphology is entirely independent of the use an</context>
</contexts>
<marker>1992</marker>
<rawString>Daelemans, Walter and Gerald Gazdar, editors. 1992. Computational Linguistics 18(2) and 18(3), special issues on inheritance.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Erik-Jan van der Linden</author>
</authors>
<title>Evaluation of lexical representation formalisms.</title>
<date>1992</date>
<booktitle>Computational Linguistics in the Netherlands: Papers from the Second CLIN Meeting,</booktitle>
<pages>54--67</pages>
<editor>In Jan van Eijck &amp; Wilfried Meyer, editors.</editor>
<publisher>OTS.</publisher>
<location>Utrecht:</location>
<marker>Daelemans, van der Linden, 1992</marker>
<rawString>Daelemans, Walter and Erik-Jan van der Linden. 1992. Evaluation of lexical representation formalisms. In Jan van Eijck &amp; Wilfried Meyer, editors. Computational Linguistics in the Netherlands: Papers from the Second CLIN Meeting, pages 54-67, Utrecht: OTS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Domenig</author>
<author>Pius ten Hacken</author>
</authors>
<title>Word Manager: A System for Morphological Dictionaries. Hidesheim: Georg Olms Verlag.</title>
<date>1992</date>
<marker>Domenig, Hacken, 1992</marker>
<rawString>Domenig, Marc and Pius ten Hacken. 1992. Word Manager: A System for Morphological Dictionaries. Hidesheim: Georg Olms Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Duda</author>
<author>Gunter Gebhardi</author>
</authors>
<title>DUTR-A DATR-PATR interface formalism.</title>
<date>1994</date>
<booktitle>Proceedings of KONVENS-94,</booktitle>
<pages>411--414</pages>
<editor>In Harald Trost, editor.</editor>
<location>Vienna:</location>
<contexts>
<context position="86495" citStr="Duda and Gebhardi 1994" startWordPosition="14333" endWordPosition="14336">ventional attribute-value matrix representations, Prolog terms, or expressions of a feature logic, simply by changing the fine detail of the transducer employed. 42 Indeed, it will be interpreting the contents of a file if DATR has been used to define a lexicon that has subsequently been compiled out, rather than being accessed directly by components of the NLP system (see Section 5.3, below). We are not, of course, claiming that textual representations will standardly provide the optimal interface between an implementation of DATR and the larger NLP system in which it is embedded (cf., e.g., Duda and Gebhardi 1994). 200 Evans and Gazdar Lexical Knowledge Representation 5. Technical Issues In this section we briefly discuss a number of technical issues, relating both to DATR as a formal language, and also to practical aspects of DATR in use. 5.1 Functionality Most DATR descriptions consist only of definitional statements, and include at most one statement for each node/path pair. In this section we examine the significance of this observation from a formal perspective. As noted in Section 2, DATR nodes can be thought of semantically as denoting partial functions from paths (sequences of atoms) to values </context>
<context position="103041" citStr="Duda and Gebhardi (1994)" startWordPosition="16939" endWordPosition="16942">nted a non-incremental algorithm that induces full DATR hierarchies from suitable data sets. Since DATR is no more than a language, it does not itself dictate how a DATR lexicon is to be used. As it turns out, different researchers have used it very differently. Andry et al. (1992), in the context of a speech recognition task involving the parsing of &amp;quot;extremely large lattices of lexical hypotheses&amp;quot; (p. 248), opted for off-line compilation of their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which was encoded with bit-vectors for speed and compactness. At the other extreme, Duda and Gebhardi (1994) present an interface between a PATR-based parser and a DATR lexicon where the former is dynamically linked to the latter and able to query it freely, in both conventional and reverse modes, without restriction. Gibbon (1993) presents an implementation of a very flexible query language, EDQL, which allows quantification over any constituents of (possibly complex) DATR queries. 5.4 Implementations As already noted, the inferential core of DATR is extremely simple to implement. We know of the existence of approximately a dozen different implementations of the language but there may well be other</context>
</contexts>
<marker>Duda, Gebhardi, 1994</marker>
<rawString>Duda, Markus and Gunter Gebhardi. 1994. DUTR-A DATR-PATR interface formalism. In Harald Trost, editor. Proceedings of KONVENS-94, pages 411-414, Vienna: Oesterreichische Gesellschaft fuer Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
</authors>
<date>1989</date>
<booktitle>Inference in DATR. Fourth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>66--71</pages>
<contexts>
<context position="4173" citStr="Evans and Gazdar 1989" startWordPosition="594" endWordPosition="597">structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily and efficiently implemented, (iv) has the necessary expressive power to encode the lexical entries presupposed by work in the unification grammar tradition, and (v) can express all the evident generalizations and subgeneralizations about such entries. Our first publications on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference (i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2 With respect to (iii), the core inference engine for DATR can be coded in a page of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen different implementations of the language, some of which have been used with large DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a, 1994; Cahill and Evans 1990). We will comment further on implementation matters in Section 5, below. However, the main purpose</context>
</contexts>
<marker>Evans, Gazdar, 1989</marker>
<rawString>Evans, Roger and Gerald Gazdar. 1989a. Inference in DATR. Fourth Conference of the European Chapter of the Association for Computational Linguistics, pages 66-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
</authors>
<title>The semantics of DATR.</title>
<date>1989</date>
<booktitle>Proceedings of the Seventh Conference of the Society for the Study of Artificial Intelligence and Simulation of Behaviour,</booktitle>
<pages>79--87</pages>
<editor>In Anthony G. Cohn, editor.</editor>
<publisher>Pitman/Morgan Kaufmann.</publisher>
<location>London:</location>
<contexts>
<context position="4173" citStr="Evans and Gazdar 1989" startWordPosition="594" endWordPosition="597">structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily and efficiently implemented, (iv) has the necessary expressive power to encode the lexical entries presupposed by work in the unification grammar tradition, and (v) can express all the evident generalizations and subgeneralizations about such entries. Our first publications on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference (i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2 With respect to (iii), the core inference engine for DATR can be coded in a page of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen different implementations of the language, some of which have been used with large DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a, 1994; Cahill and Evans 1990). We will comment further on implementation matters in Section 5, below. However, the main purpose</context>
</contexts>
<marker>Evans, Gazdar, 1989</marker>
<rawString>Evans, Roger and Gerald Gazdar. 1989b. The semantics of DATR. In Anthony G. Cohn, editor. Proceedings of the Seventh Conference of the Society for the Study of Artificial Intelligence and Simulation of Behaviour, pages 79-87, London: Pitman/Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
<author>Lionel Moser</author>
</authors>
<title>Prioritised multiple inheritance</title>
<date>1993</date>
<pages>38--46</pages>
<editor>in DATR. In Ted Briscoe, Valeria de Paiva, and Ann Copestake, editors. Inheritance, Defaults, and</editor>
<publisher>Cambridge University Press,</publisher>
<marker>Evans, Gazdar, Moser, 1993</marker>
<rawString>Evans, Roger, Gerald Gazdar, and Lionel Moser. 1993. Prioritised multiple inheritance in DATR. In Ted Briscoe, Valeria de Paiva, and Ann Copestake, editors. Inheritance, Defaults, and the Lexicon. Cambridge: Cambridge University Press, pages 38-46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
<author>David Weir</author>
</authors>
<title>Encoding lexicalized tree adjoining grammars with a nonmonotonic inheritance hierarchy. 33rd Annual Meeting of the Association for Computational Linguistics,</title>
<date>1995</date>
<pages>77--84</pages>
<marker>Evans, Gazdar, Weir, 1995</marker>
<rawString>Evans, Roger, Gerald Gazdar, and David Weir. 1995. Encoding lexicalized tree adjoining grammars with a nonmonotonic inheritance hierarchy. 33rd Annual Meeting of the Association for Computational Linguistics, pages 77-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel P Flickinger</author>
</authors>
<date>1987</date>
<booktitle>Lexical Rules in the Hierarchical Lexicon. Ph.D. dissertation,</booktitle>
<institution>Stanford University.</institution>
<contexts>
<context position="96809" citStr="Flickinger 1987" startWordPosition="15944" endWordPosition="15945">nomenon in DATR. We have already noted that the combination of the longest-defined-subpathwins and logical consistency are the basis of DATR&apos;s support for coherent multiple inheritance. It turns out that functionality (which of course implies consistency) ensures orthogonality so that OMI falls out as the most normal, natural mode of definition using DATR. Finally, we note that a number of recent lexical theories have invoked a form of inheritance in which multiple parents with overlapping domains are specified, and a priority ordering imposed to resolve potential inheritance conflicts (e.g., Flickinger 1987; Russell et al. 1992). In this prioritized multiple inheritance (PMI), precedence is given to nodes that come earlier in the ordering, so that the inherited value for a property comes from the first parent node in the ordering that defines that property, regardless of whether other later nodes also define it (possibly differently). Surprisingly perhaps, DATR&apos;s version of OMI can be used to reconstruct PMI without making syntactic and semantic additions to the language. In fact, we have described elsewhere no fewer than three different techniques for capturing PMI in DATR (Evans, Gazdar, and M</context>
</contexts>
<marker>Flickinger, 1987</marker>
<rawString>Flickinger, Daniel P. 1987. Lexical Rules in the Hierarchical Lexicon. Ph.D. dissertation, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman Fraser</author>
<author>Greville Corbett</author>
</authors>
<title>Gender, animacy, and declensional class assignment: A unified account for Russian.</title>
<date>1995</date>
<booktitle>In Geert Booij &amp; Jaap</booktitle>
<pages>123--150</pages>
<editor>van Marle, editors.</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="63468" citStr="Fraser and Corbett (1995)" startWordPosition="10476" endWordPosition="10479">ral type are quite common in the world&apos;s languages. In our hypothetical example, the proper name will have feminine gender either if it ends in a consonant and denotes a female or if it ends in a stop consonant but does not denote a female. We can encode this situation in DATR as follows:&amp;quot; Personal_name: &lt;&gt; == Boolean &lt;ends_in_consonant&gt; == &amp;quot;&lt;ends_in_stop&gt;&amp;quot; 23 Word3 remains unchanged, overriding the definition of &lt;syn f orm&gt; and so not requiring these additional features to be defined at all. 24 We can, of course, use the same technique to define many-valued logics if we wish. 25 For example, Fraser and Corbett (1995) use DATR to capture a range of phonology/morphology/semantics interdependencies in Russian. And Brown and Hippisley (1994) do the same for a Russian segmental phonology/prosody/morphology interdependency. But one can find such interdependencies in English also: see Ostler and Atkins (1992, 96-98). 26 Note that complex expressions require path embedding. Thus, for example, the well-formed negation of a conditional is &lt;not &lt;if ...&gt;&gt; rather than &lt;not if ...&gt;. 190 Evans and Gazdar Lexical Knowledge Representation &lt;gender_is_feminine&gt; == &lt;or &lt;and &amp;quot;&lt;female_referent&gt;&amp;quot; &amp;quot;&lt;ends_in_consonant&gt;&amp;quot;&gt; &lt;and &lt;no</context>
</contexts>
<marker>Fraser, Corbett, 1995</marker>
<rawString>Fraser, Norman and Greville Corbett. 1995. Gender, animacy, and declensional class assignment: A unified account for Russian. In Geert Booij &amp; Jaap van Marle, editors. Year Book of Morphology 1994. Dordrecht: Kluwer, pages 123-150.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Norman Fraser</author>
<author>Greville Corbett</author>
</authors>
<title>In press. Gender assignment in Arapesh: A Network Morphology analysis.</title>
<journal>Lingua.</journal>
<marker>Fraser, Corbett, </marker>
<rawString>Fraser, Norman and Greville Corbett. In press. Gender assignment in Arapesh: A Network Morphology analysis. Lingua.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman Fraser</author>
<author>Richard Hudson</author>
</authors>
<title>Word Grammar: An inheritance-based theory of language.</title>
<date>1990</date>
<booktitle>Proceedings of the Workshop on Inheritance in Natural Language Processing,</booktitle>
<pages>58--64</pages>
<editor>In Walter Daelemans &amp; Gerald Gazdar, editors.</editor>
<institution>Institute for Language Technology.</institution>
<location>Tilburg:</location>
<contexts>
<context position="79318" citStr="Fraser and Hudson (1990" startWordPosition="13065" endWordPosition="13068"> &lt;&gt; == NOUN &lt;mor root&gt; == cherry &lt;sem gloss 1&gt; == sweet red berry with pip &lt;sem gloss 2&gt; == tree bearing &lt;sem gloss 1&gt; &lt;sem gloss 3&gt; == wood from &lt;sem gloss 2&gt;. Again, this is a rather traditional analysis. There are (at least) three distinct but related senses.&apos; They are not freely interchangeable alternative values for a single attribute or path. Instead, DATR allows their relatedness of meaning to be captured by using the definition of one in the definition of another. A very few words in English have alternative morphological forms for the same syntactic specification. An example noted by Fraser and Hudson (1990, 62) is the plural of hoof which, for many English speakers, can appear as both hoofs and hooves.&apos; DATR does not permit a theorem set such as the following to be derived from a consistent description: Word7: &lt;syn number&gt; = plural &lt;mor form&gt; = hoof s &lt;mor form&gt; = hoove s. But it is quite straightforward to define a description that will lead to the following theorem set: Word7: &lt;syn number&gt; = plural &lt;mor form&gt; = hoof s &lt;mor form alternant&gt; = hoove s. Or something like this: Word7: &lt;syn number&gt; = plural &lt;mor forms&gt; = hoof s I hoove s Or this: Word7: &lt;syn number&gt; = plural &lt;mor forms&gt; = { hoof s </context>
</contexts>
<marker>Fraser, Hudson, 1990</marker>
<rawString>Fraser, Norman and Richard Hudson. 1990. Word Grammar: An inheritance-based theory of language. In Walter Daelemans &amp; Gerald Gazdar, editors. Proceedings of the Workshop on Inheritance in Natural Language Processing, pages 58-64, Tilburg: Institute for Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
</authors>
<title>Paradigm function morphology in DATR.</title>
<date>1992</date>
<booktitle>Sussex Papers in General and Computational Linguistics. Brighton, University of Sussex, Cognitive Science Research Paper CSRP 239,</booktitle>
<pages>43--53</pages>
<editor>In Lynne Cahill &amp; Richard Coates, editors.</editor>
<contexts>
<context position="2022" citStr="Gazdar (1992)" startWordPosition="284" endWordPosition="285"> just like regular lexemes except that they deviate in one or two characteristics. What is needed is a natural way of saying &amp;quot;this lexeme is regular except for this property.&amp;quot; One obvious approach is to use nonmonotonicity and inheritance machinery to capture such lexical irregularity (and subregularity), and much recent research into the design of representation languages for natural language lexicons has thus made use of nonmonotonic inheritance networks (or &amp;quot;semantic nets&amp;quot;) as originally developed for more general representation purposes in Artificial Intelligence. Daelemans, De Smedt, and Gazdar (1992) provide a rationale for, and an introduction to, this body of research and we will not rehearse the content of that paper here, nor review the work cited there.1 DAT R is a rather spartan nonmonotonic language for defining inheritance networks with path/value equations. In keeping with its intendedly minimalist character, it lacks many of the constructs embodied either in general-purpose knowledge representation languages or in contemporary grammar formalisms. But the present paper seeks to * Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail: Rog</context>
<context position="67938" citStr="Gazdar (1992)" startWordPosition="11202" endWordPosition="11203">/skies). We give below a small fragment of such an FST in which + is used as a morpheme boundary marker. Note the role of DATR variables in giving concise expression to the rules: # vars $abc:abcdefghijklmnopqrstuvwxyz. # vars $vow: ae io u. SPELL: &lt;&gt; == &lt;+&gt; == &lt;&gt; &lt;$abc&gt; == $abc &lt;&gt; &lt;e + $vow&gt; == $vow &lt;&gt;. These axioms then give rise to theorems such as these: SPELL: &lt;1 o v e&gt; =love &lt;1 o v e + s&gt; =loves &lt;love+ed&gt; =loved &lt;love+er&gt; =lover &lt;love+ly&gt; =lovely 30 For clarity, this FST does not exploit default inheritance to capture the 50% overlap between the subject and object pronoun paradigms. See Gazdar (1992) for a version that does. 31 And see McFetridge and Villavicencio (1995) for a less exotic application. 192 Evans and Gazdar Lexical Knowledge Representation &lt;love+ing&gt; =loving &lt;love+able&gt; lovable.= 4.4 Representing Lists DATR&apos;s foundation in path/value specifications means that many of the representational idioms of unification formalisms transfer fairly directly. A good example is the use of first and rest attributes to represent list-structured features, such as syntactic arguments and subcategorized complements. The following definitions could be used to extend our verb fragment by introdu</context>
<context position="109256" citStr="Gazdar (1992)" startWordPosition="17890" endWordPosition="17891">rules, in DATR. DATR itself does not mandate any of the choices in this example, but equally, nor does it allow such choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as to the theoretical frameworks in which the description is to be conducted: there is no &amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example, Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX theory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press) use DATR to implement their Network Morphology framework, and Gazdar (1992) shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of assembly language for constructing (or reconstructing) higher-level theories of lexical representation. 49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of polytheoretic lexicons. For example, one that would allow either categorial or HPSG-style subcategorization specifications to be derived, depending on the setting of a parameter. 207 Computational Linguistics Volume 22, Number 2 APPENDI</context>
</contexts>
<marker>Gazdar, 1992</marker>
<rawString>Gazdar, Gerald. 1992. Paradigm function morphology in DATR. In Lynne Cahill &amp; Richard Coates, editors. Sussex Papers in General and Computational Linguistics. Brighton, University of Sussex, Cognitive Science Research Paper CSRP 239, pages 43-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dafydd Gibbon</author>
</authors>
<title>Prosodic association by template inheritance.</title>
<date>1990</date>
<booktitle>Proceedings of the Workshop on Inheritance in Natural Language Processing,</booktitle>
<pages>65--81</pages>
<editor>In Walter Daelemans &amp; Gerald Gazdar, editors.</editor>
<institution>Institute for Language Technology.</institution>
<location>Tilburg:</location>
<contexts>
<context position="66031" citStr="Gibbon 1990" startWordPosition="10857" endWordPosition="10858">, we have assumed that the truth values of &lt;ends_in_consonant&gt; and &lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the phonology of the words in DATR also, then these predicates could be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1 pl&gt; == tu S2:</context>
</contexts>
<marker>Gibbon, 1990</marker>
<rawString>Gibbon, Dafydd. 1990. Prosodic association by template inheritance. In Walter Daelemans &amp; Gerald Gazdar, editors. Proceedings of the Workshop on Inheritance in Natural Language Processing, pages 65-81, Tilburg: Institute for Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dafydd Gibbon</author>
</authors>
<title>ILEX: A linguistic approach to computational lexica.</title>
<date>1992</date>
<booktitle>Computatio Linguae: Aufsaze zur algorithmischen und quantitativen Analyse der Sprache (Zeitschrift fur Dialektologie und Linguistik, Beiheft 73),</booktitle>
<pages>32--53</pages>
<editor>In Ursula Klenk, editor.</editor>
<publisher>Franz Steiner Verlag,</publisher>
<location>Stuttgart:</location>
<contexts>
<context position="109026" citStr="Gibbon (1992)" startWordPosition="17853" endWordPosition="17854">DRT-style semantic representations, H PSG-style syntactic representations, &amp;quot;item &amp; arrangement&amp;quot;- style morphological representations and a KIMMO-style orthographic component, implementing all of these, including the H PSG lexical rules, in DATR. DATR itself does not mandate any of the choices in this example, but equally, nor does it allow such choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as to the theoretical frameworks in which the description is to be conducted: there is no &amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example, Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX theory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press) use DATR to implement their Network Morphology framework, and Gazdar (1992) shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of assembly language for constructing (or reconstructing) higher-level theories of lexical representation. 49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of polyth</context>
<context position="110449" citStr="Gibbon (1992)" startWordPosition="18070" endWordPosition="18071">22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has been in the public domain for the last half-dozen years and been widely used in Europe during that period (by the standards of lexical knowledge representation languages), it is not surprising that it has attracted some critical attention from others working in the field. In this appendix, we consider and respond to the critical material that has been published: Domenig and ten Hacken (1992), Bouma and Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and van der Linden (1992). Langer and Gibbon (1992) also respond to the last three papers in the context of a thorough general review of appropriate evaluation criteria for lexical knowledge representation formalisms. We are indebted to their discussion. Domenig and ten Hacken (1992) base part of their critique of DATR on an idiosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology. This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for morphological processing—even though, as they note &amp;quot;DATR is strictly speaking not an FMP&amp;quot; (p. 8) and &amp;quot;is not specifically geared to morphological proces</context>
<context position="115169" citStr="Gibbon (1992)" startWordPosition="18827" endWordPosition="18828">t ascribe the cause to the ways in which they attempted to apply DATR to their chosen tasks.&apos; Daelemans and van der Linden (1992) review a number of approaches to lexical knowledge representation, including DATR, with respect to their notational adequacy and expressivity. They argue that adequate approaches will allow (i) recursive path formation; (ii) multiple inheritance, preferably orthogonal multiple inheritance; (iii) nonmonotonic inheritance; and require (iv) that irregular items take precedence over regular ones without explicit coding (p. 61). Since, as we have seen, and as Langer and Gibbon (1992) note, DATR has all four of these properties, one might expect it to emerge from their review with at least a low alpha grade—but in fact they find fault with it on a number of grounds. The first of these is the use of double quotes to mark global inheritance in the concrete syntax of DATR. They claim that global inheritance is the normal kind of inheritance in DATR and should thus not be marked in any special way, while (unquoted) local inheritance is exceptional and should therefore have a special notation (like quotes) associated with it (p. 63).52 The small example they give lends some pla</context>
<context position="121403" citStr="Gibbon (1992)" startWordPosition="19848" endWordPosition="19849">ATR analysis to which they refer. In order to reconstruct paradigms in their feature language, they invoke distributed disjunctions (fixed-length term expressions).&amp;quot; The descriptive problem with this approach, as they admit, is that &amp;quot;there is no way to note that a single form in a paradigm is exceptional without respecifying the entire paradigm—the disjunction must be respecified as a whole ... there is no way to 53 But see Daelemans and De Smedt (1994) for articulation of the methodological principle that underlies the third objection. 54 The issues are also discussed in detail by Langer and Gibbon (1992). 55 Langer and Gibbon (1992) argue, at some length, that it is formally inappropriate to add distributed disjunction to a typed feature structure language of the kind otherwise assumed by Krieger and Nerbonne. 210 Evans and Gazdar Lexical Knowledge Representation identify a particular alternation within the distributed disjunction&amp;quot; (p. 107). Anyone familiar with the way inflection works in Romance languages will immediately see that this is a very serious weakness. In Latin, for example, there are many individual words and small subclasses of words that deviate from a major declension or conj</context>
</contexts>
<marker>Gibbon, 1992</marker>
<rawString>Gibbon, Dafydd. 1992. ILEX: A linguistic approach to computational lexica. In Ursula Klenk, editor. Computatio Linguae: Aufsaze zur algorithmischen und quantitativen Analyse der Sprache (Zeitschrift fur Dialektologie und Linguistik, Beiheft 73), Stuttgart: Franz Steiner Verlag, pages 32-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dafydd Gibbon</author>
</authors>
<title>Generalized DATR for flexible lexical access: PROLOG specification.</title>
<date>1993</date>
<tech>Bielefeld: Verbmobil Report 2.</tech>
<contexts>
<context position="4426" citStr="Gibbon 1993" startWordPosition="641" endWordPosition="642">explicit declarative semantics, (iii) can be readily and efficiently implemented, (iv) has the necessary expressive power to encode the lexical entries presupposed by work in the unification grammar tradition, and (v) can express all the evident generalizations and subgeneralizations about such entries. Our first publications on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference (i) and a formal semantics (ii) for DATR and we will not recapitulate that material here.2 With respect to (iii), the core inference engine for DATR can be coded in a page of Prolog (see, e.g., Gibbon 1993, 50). At the time of writing, we know of a dozen different implementations of the language, some of which have been used with large DATR lexicons in the context of big NLP systems (e.g., Andry et al. 1992; Cahill 1993a, 1994; Cahill and Evans 1990). We will comment further on implementation matters in Section 5, below. However, the main purpose of the present paper is to exhibit the use of DATR for lexical description (iv) and the way it makes it relatively easy to capture lexical generalizations and subregularities at a variety of analytic levels (v). We will pursue (iv) and (v) in the conte</context>
<context position="100678" citStr="Gibbon (1993)" startWordPosition="16564" endWordPosition="16565">is kind of inference may also be useful in lexicon development and maintenance. However, its most obvious application is to &amp;quot;bootstrap&amp;quot; lexical access in language-processing systems that make direct use of an on-line lexicon: given a surface form (in analysis) or a semantic form (in generation), we need to identify a lexical entry associated with that form by reverse query, and then access other lexical information associated with the entry by conventional inference. Langer (1994) gives an inference algorithm, based on the familiar chart data structure, for reverse querying DATR lexicons; and Gibbon (1993) describes EDQL (Extended DATR Query Language) which permits quantification into components of multisentence DATR queries. The final task is that of theory induction. Here one starts with a set of known query-value pairs (Love: &lt;mor past participle&gt; = love ed., Love: &lt;mor pres tense sing three&gt; = love s., etc.) and the task is to induce a description that has those pairs as theorems under the application of conventional inference. In a world in which all the relevant data was already clearly set out in descriptive linguistic work, an algorithm that efficiently achieved this kind of induction w</context>
<context position="103266" citStr="Gibbon (1993)" startWordPosition="16977" endWordPosition="16978"> used it very differently. Andry et al. (1992), in the context of a speech recognition task involving the parsing of &amp;quot;extremely large lattices of lexical hypotheses&amp;quot; (p. 248), opted for off-line compilation of their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which was encoded with bit-vectors for speed and compactness. At the other extreme, Duda and Gebhardi (1994) present an interface between a PATR-based parser and a DATR lexicon where the former is dynamically linked to the latter and able to query it freely, in both conventional and reverse modes, without restriction. Gibbon (1993) presents an implementation of a very flexible query language, EDQL, which allows quantification over any constituents of (possibly complex) DATR queries. 5.4 Implementations As already noted, the inferential core of DATR is extremely simple to implement. We know of the existence of approximately a dozen different implementations of the language but there may well be others that we do not know of. The best known, and most widely available are our own (Brighton/Sussex), which is written in Prolog and runs on most Unix platforms, Gibbon&apos;s (Bielefeld) DDATR Scheme and NODE Sicstus Prolog implemen</context>
</contexts>
<marker>Gibbon, 1993</marker>
<rawString>Gibbon, Dafydd. 1993. Generalized DATR for flexible lexical access: PROLOG specification. Bielefeld: Verbmobil Report 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dafydd Gibbon</author>
<author>Doris Bleiching</author>
</authors>
<title>An ILEX model for German compound stress in DATR.</title>
<date>1991</date>
<booktitle>Proceedings of the FOR WISS-ASL Workshop on Prosody in Man-Machine Communication,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="66064" citStr="Gibbon and Bleiching 1991" startWordPosition="10860" endWordPosition="10863">hat the truth values of &lt;ends_in_consonant&gt; and &lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the phonology of the words in DATR also, then these predicates could be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1 pl&gt; == tu S2:&lt;&gt; &lt;subj 2 pl&gt; == m S2:&lt;&gt; &lt;subj 3</context>
</contexts>
<marker>Gibbon, Bleiching, 1991</marker>
<rawString>Gibbon, Dafydd and Doris Bleiching. 1991. An ILEX model for German compound stress in DATR. Proceedings of the FOR WISS-ASL Workshop on Prosody in Man-Machine Communication, pages 1-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Jacques Le Maitre</author>
<author>Jean Veronis</author>
</authors>
<title>Outline of a model for lexical databases. In Antonio Zampolli, Nicoletta Calzolari,</title>
<date>1994</date>
<location>and Martha Palmer,</location>
<marker>Ide, Le Maitre, Veronis, 1994</marker>
<rawString>Ide, Nancy, Jacques Le Maitre, and Jean Veronis. 1994. Outline of a model for lexical databases. In Antonio Zampolli, Nicoletta Calzolari, and Martha Palmer,</rawString>
</citation>
<citation valid="false">
<booktitle>Current Issues in Computational Linguistics: In Honour of Don</booktitle>
<pages>283--320</pages>
<editor>editors.</editor>
<publisher>Kluwer,</publisher>
<location>Walker. Pisa:</location>
<marker></marker>
<rawString>editors. Current Issues in Computational Linguistics: In Honour of Don Walker. Pisa: Kluwer, pages 283-320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<pages>20--3</pages>
<contexts>
<context position="67190" citStr="Kaplan and Kay 1994" startWordPosition="11070" endWordPosition="11073"> sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1 pl&gt; == tu S2:&lt;&gt; &lt;subj 2 pl&gt; == m S2:&lt;&gt; &lt;subj 3 pl&gt; == wa S2:&lt;&gt;. &lt;subj &lt;past&gt; == li 53:&lt;&gt; &lt;futr&gt; == ta S3:&lt;&gt;. &lt;obj 1 sg&gt; == ni S4:&lt;&gt; &lt;obj 2 sg&gt; == ku S4:&lt;&gt; &lt;obj 3 sg&gt; == m S4:&lt;&gt; &lt;obj 1 pl&gt; == tu 54:&lt;&gt; &lt;obj 2 pl&gt; == wa 54:&lt;&gt; &lt;obj 3 pl&gt; == wa 54:&lt;&gt;. &lt;like&gt; == penda. Although the example is trivial, the technique is both powerful and useful. Gibbon (1990), for example, has made notably effective use of it in his treatments of African tone systems.&apos; Much of the computational phonology and morphology of the last decade and a half has depended on FSTs (Kaplan and Kay 1994). Potential lexical applications come readily to mind—for example, the orthographic spelling rules for English suffixation (such as sky/skies). We give below a small fragment of such an FST in which + is used as a morpheme boundary marker. Note the role of DATR variables in giving concise expression to the rules: # vars $abc:abcdefghijklmnopqrstuvwxyz. # vars $vow: ae io u. SPELL: &lt;&gt; == &lt;+&gt; == &lt;&gt; &lt;$abc&gt; == $abc &lt;&gt; &lt;e + $vow&gt; == $vow &lt;&gt;. These axioms then give rise to theorems such as these: SPELL: &lt;1 o v e&gt; =love &lt;1 o v e + s&gt; =loves &lt;love+ed&gt; =loved &lt;love+er&gt; =lover &lt;love+ly&gt; =lovely 30 For c</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Kaplan, Ronald M. and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics 20(3):331-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Keller</author>
</authors>
<date>1995</date>
<booktitle>DATR theories and DATR models. 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>55--62</pages>
<contexts>
<context position="7231" citStr="Keller (1995)" startWordPosition="1104" endWordPosition="1105"> loving, etc.). Each node has associated with it a set of path/value pairs, where a path is a sequence of atoms (which are primitive objects), and a value is an atom or a sequence of atoms. We will sometimes refer to atoms in paths as attributes. For example, a node describing the present participle form of the verb love (and called perhaps Wordi) might contain the path/value pairs shown in Table 1. The paths 2 Note, however, that the definitions in the 1989 papers are not given in sufficient generality to cover DATR equations with more than one (non-atomic) descriptor on the right hand side. Keller (1995) effectively replaces our 1989 presentation of a semantics for DATR and his treatment is general enough to cover descriptor sequences. 168 Evans and Gazdar Lexical Knowledge Representation Table 1 Path/value pairs for present participle of love. Path Value syn cat verb syn type main syn form present participle mor form love ing in this example all happen to contain two attributes, and the first attribute can be thought of as distinguishing syntactic and morphological types of information. The values indicate appropriate linguistic settings for the paths for a present participle form of love. T</context>
<context position="53097" citStr="Keller (1995)" startWordPosition="8734" endWordPosition="8735"> definition of Do we gave above. Do: &lt;&gt; == VERB &lt;mor root&gt; == do &lt;mor past&gt; == did &lt;mor past participle&gt; == done &lt;mor present tense sing three&gt; == does. Filling in the gaps between these definitions, we can see that many paths will be implicitly defined only by the empty path specification. Examples include: Do: &lt;mor&gt; == VERB &lt;syn&gt; == VERB &lt;mor present&gt; == VERB &lt;syn cat&gt; == VERB &lt;syn type&gt; == VERB &lt;mor present tense sing one&gt; == VERB. If there had been no definition for &lt;&gt;, then none of these example paths would have 18 For formal discussion of the semantics of the DATR default mechanism, see Keller (1995). 185 Computational Linguistics Volume 22, Number 2 been defined at all, since there would have been no leading subpath with a definition. Note how &lt;mor&gt; itself takes its definition from &lt;&gt;, since all the explicitly defined &lt;mor ...&gt; specifications have at least one further attribute. The definition for &lt;mor past&gt; overrides default definition from &lt;&gt; and in turn provides a definition for longer paths. However, &lt;mor past participle&gt; blocks default definition from &lt;mor past&gt;. Thus the following arise:19 Do: &lt;mor past tense&gt; == did &lt;mor past tense plur&gt; == did &lt;mor past tense sing three&gt; == did &lt;</context>
<context position="89123" citStr="Keller (1995)" startWordPosition="14741" endWordPosition="14742">inheritance derives new statements associated with a node/path pair, but at most one of these defines a value or global inheritance descriptor (since local inheritance ceases at that point). Thus although the local inheritance makes the description become syntactically nonfunctional, the specification of values or global descriptors remains functional. The value specifications map directly to extensional statements, while the global inheritance descriptors operate just as the local ones, adding at most one further value statement for each global 43 We continue to oversimplify matters here. As Keller (1995) points out, the meaning of a node depends on the global context, and a node thus really denotes a function from global contexts to partial functions from paths to values. Though important, this point is tangential to the issue addressed here. 44 For simplicity here, we consider only the case of descriptor sequences of length one—the general case involves complications not relevant to the main point. 201 Computational Linguistics Volume 22, Number 2 inheritance statement, so that ultimately the consistency of the set of (extensional) value statements is assured. This theorem cannot be strength</context>
</contexts>
<marker>Keller, 1995</marker>
<rawString>Keller, William. 1995. DATR theories and DATR models. 33rd Annual Meeting of the Association for Computational Linguistics, pages 55-62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Kilbury</author>
</authors>
<title>Strict inheritance and the taxonomy of lexical types in DATR.</title>
<date>1993</date>
<institution>University of Duesseldorf.</institution>
<note>Unpublished manuscript,</note>
<contexts>
<context position="101955" citStr="Kilbury (1993)" startWordPosition="16766" endWordPosition="16767">ional lexicons. In the real world, such an algorithm would still be useful for domains like morphology (where the quality and clarity of extant descriptive linguistic work is very high), for bootstrapping lexical descriptions for subsequent manual development by humans, for updating lexicons in the light of newly encountered lexical information, and for converting one kind of lexicon into a completely different kind of lexicon by inducing the latter from the output of the former. The automatic induction of (symbolic) lexicons from data is a very new research area in computational linguistics: Kilbury (1993), Kilbury, Naerger, and Renz (1994), Light (1994), and Light, Reinhard, and Boyle-Hinrichs (1993) have proposed a variety of incremental algorithms that take a partial lexical hierarchy and 47 An alternative formulation is to start with a known value and path, and the task is to infer the appropriate nodes. 205 Computational Linguistics Volume 22, Number 2 elaborate it as necessary in the light of successively presented data sets, while Barg (1994) has presented a non-incremental algorithm that induces full DATR hierarchies from suitable data sets. Since DATR is no more than a language, it doe</context>
</contexts>
<marker>Kilbury, 1993</marker>
<rawString>Kilbury, James. 1993. Strict inheritance and the taxonomy of lexical types in DATR. Unpublished manuscript, University of Duesseldorf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Kilbury</author>
<author>Petra Naerger</author>
<author>Ingrid Renz</author>
</authors>
<title>DATR as a lexical component for PATR.</title>
<date>1991</date>
<booktitle>Fifth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>137--142</pages>
<marker>Kilbury, Naerger, Renz, 1991</marker>
<rawString>Kilbury, James, Petra [Barg] Naerger, and Ingrid Renz. 1991. DATR as a lexical component for PATR. Fifth Conference of the European Chapter of the Association for Computational Linguistics, pages 137-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Kilbury</author>
<author>Petra</author>
</authors>
<title>Simulation lexicalischen Erwerbs. In</title>
<date>1994</date>
<pages>251--271</pages>
<publisher>Westdeutscher Verlag,</publisher>
<marker>Kilbury, Petra, 1994</marker>
<rawString>Kilbury, James, Petra [Bargj Naerger; and Ingrid Renz. 1994. Simulation lexicalischen Erwerbs. In Sascha W. Felix, Christopher Habel, and Gert Rickheit Kognitive Linguistik: Repraesentation und Prozesse. Opladen: Westdeutscher Verlag, pages 251-271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Inheriting verb alternations.</title>
<date>1993</date>
<booktitle>Sixth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>213--221</pages>
<contexts>
<context position="72687" citStr="Kilgarriff (1993)" startWordPosition="11963" endWordPosition="11964">scoe and Copestake (1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the very same lexical rule mechanism can be invoked for both sense extensions and morphological processes. 33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazdar, and Weir (1995) report the use of DATR to formulate a lexical rule for Wh-questions in LTAG, inter alia. 34 Evaluable paths are not essential in this domain: thus Kilgarriff (1993) does not employ them in his DATR analysis of verbal alternations in the context of an H PSG lexicon, although he does use the standard encoding of argument lists. 35 Since our purpose here is expository, we have deliberately kept the analysis to a minimum. Dealing with the semantics of passive, for example, involves more of the same, rather than any issue of principle. 194 Evans and Gazdar Lexical Knowledge Representation &lt;syn args&gt; == NP_ARG:&lt;&gt; &lt;syn args first syn case&gt; == nominative. PASSIVE_VERB: &lt;&gt; == VERB &lt;mor passive&gt; == &amp;quot;&lt;mor past&gt;&amp;quot; &lt;syn subcat rest&gt; == &amp;quot;&lt;syn args rest rest&gt;&amp;quot;. TR_VERB:</context>
</contexts>
<marker>Kilgarriff, 1993</marker>
<rawString>Kilgarriff, Adam. 1993. Inheriting verb alternations. Sixth Conference of the European Chapter of the Association for Computational Linguistics, pages 213-221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Inheriting polysemy.</title>
<date>1995</date>
<booktitle>Computational Lexical Semantics. Cambridge:</booktitle>
<editor>In Patrick Saint-Dizier &amp; Evelyne Viegas, editors.</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="78282" citStr="Kilgarriff (1995)" startWordPosition="12889" endWordPosition="12890"> where ambiguities are common. In practice, however, this turns out not to be the case. Consider the homonymy of bank: Bankl: &lt;&gt; == NOUN &lt;mor root&gt; == bank &lt;sem gloss&gt; == side of river. Bank2: &lt;&gt; == NOUN &lt;mor root&gt; == bank &lt;sem gloss&gt; == financial institution. This is simply the traditional analysis of homonymy, encoded in DATR: there are two entirely distinct lexemes, with unrelated meanings, that happen both to be nouns and to have indistinguishable morphological roots. Or consider the polysemy of cherry:37 36 Cf. Krieger (1994, 279) who notes some other advantages. 37 The example is due to Kilgarriff (1995) who shows that the kind of polysemy exhibited by cherry applies generally to fruit trees and can thus be specified at a higher node in the lexical network, removing the need for stipulation (as in our example) at the Cherry node, the Apple node, and so on. Kilgarriff and Gazdar (1995) also present an extended example showing how DATR can be used to 196 Evans and Gazdar Lexical Knowledge Representation Cherry: &lt;&gt; == NOUN &lt;mor root&gt; == cherry &lt;sem gloss 1&gt; == sweet red berry with pip &lt;sem gloss 2&gt; == tree bearing &lt;sem gloss 1&gt; &lt;sem gloss 3&gt; == wood from &lt;sem gloss 2&gt;. Again, this is a rather tr</context>
</contexts>
<marker>Kilgarriff, 1995</marker>
<rawString>Kilgarriff, Adam. 1995. Inheriting polysemy. In Patrick Saint-Dizier &amp; Evelyne Viegas, editors. Computational Lexical Semantics. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>Gerald Gazdar</author>
</authors>
<title>Polysemous relations.</title>
<date>1995</date>
<booktitle>Grammar and Meaning: Essays in Honour of Sir John Lyons. Cambridge:</booktitle>
<pages>1--25</pages>
<editor>In F. R. Palmer, editor.</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="78568" citStr="Kilgarriff and Gazdar (1995)" startWordPosition="12938" endWordPosition="12941"> the traditional analysis of homonymy, encoded in DATR: there are two entirely distinct lexemes, with unrelated meanings, that happen both to be nouns and to have indistinguishable morphological roots. Or consider the polysemy of cherry:37 36 Cf. Krieger (1994, 279) who notes some other advantages. 37 The example is due to Kilgarriff (1995) who shows that the kind of polysemy exhibited by cherry applies generally to fruit trees and can thus be specified at a higher node in the lexical network, removing the need for stipulation (as in our example) at the Cherry node, the Apple node, and so on. Kilgarriff and Gazdar (1995) also present an extended example showing how DATR can be used to 196 Evans and Gazdar Lexical Knowledge Representation Cherry: &lt;&gt; == NOUN &lt;mor root&gt; == cherry &lt;sem gloss 1&gt; == sweet red berry with pip &lt;sem gloss 2&gt; == tree bearing &lt;sem gloss 1&gt; &lt;sem gloss 3&gt; == wood from &lt;sem gloss 2&gt;. Again, this is a rather traditional analysis. There are (at least) three distinct but related senses.&apos; They are not freely interchangeable alternative values for a single attribute or path. Instead, DATR allows their relatedness of meaning to be captured by using the definition of one in the definition of anoth</context>
</contexts>
<marker>Kilgarriff, Gazdar, 1995</marker>
<rawString>Kilgarriff, Adam and Gerald Gazdar. 1995. Polysemous relations. In F. R. Palmer, editor. Grammar and Meaning: Essays in Honour of Sir John Lyons. Cambridge: Cambridge University Press, pages 1-25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Ulrich Krieger</author>
</authors>
<title>Derivation without lexical rules. In</title>
<date>1994</date>
<booktitle>Constraints, Language and Computation.</booktitle>
<pages>277--313</pages>
<editor>C. J. Rupp, M. A. Rosner, and R. L. Johnson, editors.</editor>
<publisher>Academic Press,</publisher>
<location>London:</location>
<contexts>
<context position="78200" citStr="Krieger (1994" startWordPosition="12875" endWordPosition="12876"> such a language would be quite inappropriate to a domain such as the lexicon, where ambiguities are common. In practice, however, this turns out not to be the case. Consider the homonymy of bank: Bankl: &lt;&gt; == NOUN &lt;mor root&gt; == bank &lt;sem gloss&gt; == side of river. Bank2: &lt;&gt; == NOUN &lt;mor root&gt; == bank &lt;sem gloss&gt; == financial institution. This is simply the traditional analysis of homonymy, encoded in DATR: there are two entirely distinct lexemes, with unrelated meanings, that happen both to be nouns and to have indistinguishable morphological roots. Or consider the polysemy of cherry:37 36 Cf. Krieger (1994, 279) who notes some other advantages. 37 The example is due to Kilgarriff (1995) who shows that the kind of polysemy exhibited by cherry applies generally to fruit trees and can thus be specified at a higher node in the lexical network, removing the need for stipulation (as in our example) at the Cherry node, the Apple node, and so on. Kilgarriff and Gazdar (1995) also present an extended example showing how DATR can be used to 196 Evans and Gazdar Lexical Knowledge Representation Cherry: &lt;&gt; == NOUN &lt;mor root&gt; == cherry &lt;sem gloss 1&gt; == sweet red berry with pip &lt;sem gloss 2&gt; == tree bearing </context>
</contexts>
<marker>Krieger, 1994</marker>
<rawString>Krieger, Hans-Ulrich. 1994. Derivation without lexical rules. In C. J. Rupp, M. A. Rosner, and R. L. Johnson, editors. Constraints, Language and Computation. London: Academic Press, pages 277-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Ulrich Krieger</author>
<author>John Nerbonne</author>
</authors>
<title>Feature-based inheritance networks for computational lexicons.</title>
<date>1993</date>
<pages>90--136</pages>
<editor>In Ted Briscoe, Valeria de Paiva, and Arm Copestake, editors. Inheritance, Defaults, and</editor>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="110382" citStr="Krieger and Nerbonne (1993)" startWordPosition="18057" endWordPosition="18060">d, depending on the setting of a parameter. 207 Computational Linguistics Volume 22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has been in the public domain for the last half-dozen years and been widely used in Europe during that period (by the standards of lexical knowledge representation languages), it is not surprising that it has attracted some critical attention from others working in the field. In this appendix, we consider and respond to the critical material that has been published: Domenig and ten Hacken (1992), Bouma and Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and van der Linden (1992). Langer and Gibbon (1992) also respond to the last three papers in the context of a thorough general review of appropriate evaluation criteria for lexical knowledge representation formalisms. We are indebted to their discussion. Domenig and ten Hacken (1992) base part of their critique of DATR on an idiosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology. This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for morphological processing—even though, as they note &amp;quot;DATR is strictly speaking not an </context>
<context position="120129" citStr="Krieger and Nerbonne (1993)" startWordPosition="19645" endWordPosition="19648">. None of these latter claims are true. If DATR paths were atomic attributes then our Section 4.3, on finite-state transducers, could not have been written; DATR paths are the same as PATR paths as far as recursive structure is concerned; and, as we have seen throughout this paper, DATR paths have many functions in addition to prefix matching. In a final set of comments, they briefly raise various issues connected with the integration of DATR lexicons with unification-based grammar (p. 64). We have dealt with these issues in earlier parts of the present paper and will not rehearse them here.&apos; Krieger and Nerbonne (1993) claim that &amp;quot;the basic insight of DATR&amp;quot; lies in its use in characterizing &amp;quot;the inflectional variants of a lexeme as alternative (disjunctive) realisations&amp;quot; (p. 135). This claim confuses the basic insight of a very traditional approach to inflectional morphology with the application of DATR in implementing that approach. Elsewhere they note that &amp;quot;the fundamental idea in our characterisation is due to the work in DATR, in which paradigms are treated as alternative further specifications of abstract lexemes&amp;quot; (p. 104). Unfortunately, their own implementation of this fundamental idea turns out to b</context>
<context position="124617" citStr="Krieger and Nerbonne (1993)" startWordPosition="20371" endWordPosition="20374">11 of their paper, Krieger and Nerbonne appear to believe that it is impossible to implement a particular inflectional analysis of the passive in Latin in DATR. They do not provide much of an argument, but what they do say suggests that the simple treatment of passive given in Section 4.5, above, is likewise impossible. This may be because they regard their own interpretation of lexical rules as &amp;quot;novel&amp;quot; (p. 113), although examples of that interpretation of lexical rules appear in earlier DATR work that they cite. Many of the points made in Nerbonne (1992) are repeated from the more accessible Krieger and Nerbonne (1993)57 and we have considered them in our discussion of the latter. Some of the points from the 1992 and 1993 papers resurface in Bouma and Nerbonne (1994). Nerbonne appears to misconstrue Evans, Gazdar, and Moser (1993) as an attempt to augment DATR with re-entrancy and goes on to suggest that DATR is somehow forced to maintain that &amp;quot;all linguistic generalizations tend to follow the lines of morphological form&amp;quot; (p. 47) when, in fact, the attribute ordering used in a DATR treatment of morphology is entirely independent of the use and ordering of those same attributes elsewhere in the lexicon (see </context>
</contexts>
<marker>Krieger, Nerbonne, 1993</marker>
<rawString>Krieger, Hans-Ulrich and John Nerbonne. 1993. Feature-based inheritance networks for computational lexicons. In Ted Briscoe, Valeria de Paiva, and Arm Copestake, editors. Inheritance, Defaults, and the Lexicon. Cambridge: Cambridge University Press, pages 90-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Ulrich Krieger</author>
<author>Hannes Pirker</author>
<author>John Nerbonne</author>
</authors>
<title>Feature-based allomorphy.</title>
<date>1993</date>
<booktitle>31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>140--147</pages>
<marker>Krieger, Pirker, Nerbonne, 1993</marker>
<rawString>Krieger, Hans-Ulrich, Hannes Pirker, and John Nerbonne. 1993. Feature-based allomorphy. 31st Annual Meeting of the Association for Computational Linguistics, pages 140-147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagen Langer</author>
</authors>
<date>1994</date>
<booktitle>Reverse queries in DATR. COLING-94,</booktitle>
<pages>1089--1095</pages>
<contexts>
<context position="100550" citStr="Langer (1994)" startWordPosition="16545" endWordPosition="16546">eries would lead to that value (Love: &lt;mor past participle&gt;, Love: &lt;mor past tense sing one&gt;, etc.).47 The ability to perform this kind of inference may also be useful in lexicon development and maintenance. However, its most obvious application is to &amp;quot;bootstrap&amp;quot; lexical access in language-processing systems that make direct use of an on-line lexicon: given a surface form (in analysis) or a semantic form (in generation), we need to identify a lexical entry associated with that form by reverse query, and then access other lexical information associated with the entry by conventional inference. Langer (1994) gives an inference algorithm, based on the familiar chart data structure, for reverse querying DATR lexicons; and Gibbon (1993) describes EDQL (Extended DATR Query Language) which permits quantification into components of multisentence DATR queries. The final task is that of theory induction. Here one starts with a set of known query-value pairs (Love: &lt;mor past participle&gt; = love ed., Love: &lt;mor pres tense sing three&gt; = love s., etc.) and the task is to induce a description that has those pairs as theorems under the application of conventional inference. In a world in which all the relevant </context>
</contexts>
<marker>Langer, 1994</marker>
<rawString>Langer, Hagen. 1994. Reverse queries in DATR. COLING-94, pages 1089-1095.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagen Langer</author>
<author>Dafydd Gibbon</author>
</authors>
<title>DATR as a graph representation language for ILEX speech oriented lexica.</title>
<date>1992</date>
<tech>Technical Report ASL-TR-43-92/UBI,</tech>
<institution>University of Bielefeld.</institution>
<contexts>
<context position="109055" citStr="Langer and Gibbon (1992)" startWordPosition="17856" endWordPosition="17859"> representations, H PSG-style syntactic representations, &amp;quot;item &amp; arrangement&amp;quot;- style morphological representations and a KIMMO-style orthographic component, implementing all of these, including the H PSG lexical rules, in DATR. DATR itself does not mandate any of the choices in this example, but equally, nor does it allow such choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as to the theoretical frameworks in which the description is to be conducted: there is no &amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example, Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX theory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press) use DATR to implement their Network Morphology framework, and Gazdar (1992) shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of assembly language for constructing (or reconstructing) higher-level theories of lexical representation. 49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of polytheoretic lexicons. For example</context>
<context position="110449" citStr="Langer and Gibbon (1992)" startWordPosition="18068" endWordPosition="18071">ics Volume 22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has been in the public domain for the last half-dozen years and been widely used in Europe during that period (by the standards of lexical knowledge representation languages), it is not surprising that it has attracted some critical attention from others working in the field. In this appendix, we consider and respond to the critical material that has been published: Domenig and ten Hacken (1992), Bouma and Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and van der Linden (1992). Langer and Gibbon (1992) also respond to the last three papers in the context of a thorough general review of appropriate evaluation criteria for lexical knowledge representation formalisms. We are indebted to their discussion. Domenig and ten Hacken (1992) base part of their critique of DATR on an idiosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology. This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for morphological processing—even though, as they note &amp;quot;DATR is strictly speaking not an FMP&amp;quot; (p. 8) and &amp;quot;is not specifically geared to morphological proces</context>
<context position="115169" citStr="Langer and Gibbon (1992)" startWordPosition="18825" endWordPosition="18828"> unfair, but ascribe the cause to the ways in which they attempted to apply DATR to their chosen tasks.&apos; Daelemans and van der Linden (1992) review a number of approaches to lexical knowledge representation, including DATR, with respect to their notational adequacy and expressivity. They argue that adequate approaches will allow (i) recursive path formation; (ii) multiple inheritance, preferably orthogonal multiple inheritance; (iii) nonmonotonic inheritance; and require (iv) that irregular items take precedence over regular ones without explicit coding (p. 61). Since, as we have seen, and as Langer and Gibbon (1992) note, DATR has all four of these properties, one might expect it to emerge from their review with at least a low alpha grade—but in fact they find fault with it on a number of grounds. The first of these is the use of double quotes to mark global inheritance in the concrete syntax of DATR. They claim that global inheritance is the normal kind of inheritance in DATR and should thus not be marked in any special way, while (unquoted) local inheritance is exceptional and should therefore have a special notation (like quotes) associated with it (p. 63).52 The small example they give lends some pla</context>
<context position="121403" citStr="Langer and Gibbon (1992)" startWordPosition="19846" endWordPosition="19849">ed in the DATR analysis to which they refer. In order to reconstruct paradigms in their feature language, they invoke distributed disjunctions (fixed-length term expressions).&amp;quot; The descriptive problem with this approach, as they admit, is that &amp;quot;there is no way to note that a single form in a paradigm is exceptional without respecifying the entire paradigm—the disjunction must be respecified as a whole ... there is no way to 53 But see Daelemans and De Smedt (1994) for articulation of the methodological principle that underlies the third objection. 54 The issues are also discussed in detail by Langer and Gibbon (1992). 55 Langer and Gibbon (1992) argue, at some length, that it is formally inappropriate to add distributed disjunction to a typed feature structure language of the kind otherwise assumed by Krieger and Nerbonne. 210 Evans and Gazdar Lexical Knowledge Representation identify a particular alternation within the distributed disjunction&amp;quot; (p. 107). Anyone familiar with the way inflection works in Romance languages will immediately see that this is a very serious weakness. In Latin, for example, there are many individual words and small subclasses of words that deviate from a major declension or conj</context>
</contexts>
<marker>Langer, Gibbon, 1992</marker>
<rawString>Langer, Hagen and Dafydd Gibbon. 1992. DATR as a graph representation language for ILEX speech oriented lexica. Technical Report ASL-TR-43-92/UBI, University of Bielefeld.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Forthcoming</author>
</authors>
<title>Order independent and persistent typed default unification.</title>
<journal>Linguistics &amp; Philosophy</journal>
<pages>19--1</pages>
<marker>Forthcoming, </marker>
<rawString>Lascarides, Alex, Nicholas Asher, Ted Briscoe, and Ann Copestake. Forthcoming. Order independent and persistent typed default unification. Linguistics &amp; Philosophy 19(1):1-89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Light</author>
</authors>
<title>Classification in feature-based default inheritance hierarchies.</title>
<date>1994</date>
<booktitle>Proceedings of KONVENS-94,</booktitle>
<pages>220--229</pages>
<editor>In Harald Trost, editor.</editor>
<location>Vienna:</location>
<contexts>
<context position="102004" citStr="Light (1994)" startWordPosition="16773" endWordPosition="16774">m would still be useful for domains like morphology (where the quality and clarity of extant descriptive linguistic work is very high), for bootstrapping lexical descriptions for subsequent manual development by humans, for updating lexicons in the light of newly encountered lexical information, and for converting one kind of lexicon into a completely different kind of lexicon by inducing the latter from the output of the former. The automatic induction of (symbolic) lexicons from data is a very new research area in computational linguistics: Kilbury (1993), Kilbury, Naerger, and Renz (1994), Light (1994), and Light, Reinhard, and Boyle-Hinrichs (1993) have proposed a variety of incremental algorithms that take a partial lexical hierarchy and 47 An alternative formulation is to start with a known value and path, and the task is to infer the appropriate nodes. 205 Computational Linguistics Volume 22, Number 2 elaborate it as necessary in the light of successively presented data sets, while Barg (1994) has presented a non-incremental algorithm that induces full DATR hierarchies from suitable data sets. Since DATR is no more than a language, it does not itself dictate how a DATR lexicon is to be </context>
</contexts>
<marker>Light, 1994</marker>
<rawString>Light, Marc. 1994. Classification in feature-based default inheritance hierarchies. In Harald Trost, editor. Proceedings of KONVENS-94, pages 220-229, Vienna: Oesterreichische Gesellschaft fuer Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Light</author>
<author>Sabine Reinhard</author>
<author>Marie Boyle-Hinrichs</author>
</authors>
<title>INSYST: An automatic inserter system for hierarchical lexica.</title>
<date>1993</date>
<booktitle>Sixth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>471</pages>
<marker>Light, Reinhard, Boyle-Hinrichs, 1993</marker>
<rawString>Light, Marc, Sabine Reinhard, and Marie Boyle-Hinrichs. 1993. INSYST: An automatic inserter system for hierarchical lexica. Sixth Conference of the European Chapter of the Association for Computational Linguistics, page 471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McFetridge</author>
<author>Aline Villavicencio</author>
</authors>
<title>A hierarchical description of the Portuguese verb.</title>
<date>1995</date>
<booktitle>Proceedings of the XIIth Brazilian Symposium on Artificial Intelligence,</booktitle>
<pages>302--311</pages>
<contexts>
<context position="68010" citStr="McFetridge and Villavicencio (1995)" startWordPosition="11212" endWordPosition="11215"> FST in which + is used as a morpheme boundary marker. Note the role of DATR variables in giving concise expression to the rules: # vars $abc:abcdefghijklmnopqrstuvwxyz. # vars $vow: ae io u. SPELL: &lt;&gt; == &lt;+&gt; == &lt;&gt; &lt;$abc&gt; == $abc &lt;&gt; &lt;e + $vow&gt; == $vow &lt;&gt;. These axioms then give rise to theorems such as these: SPELL: &lt;1 o v e&gt; =love &lt;1 o v e + s&gt; =loves &lt;love+ed&gt; =loved &lt;love+er&gt; =lover &lt;love+ly&gt; =lovely 30 For clarity, this FST does not exploit default inheritance to capture the 50% overlap between the subject and object pronoun paradigms. See Gazdar (1992) for a version that does. 31 And see McFetridge and Villavicencio (1995) for a less exotic application. 192 Evans and Gazdar Lexical Knowledge Representation &lt;love+ing&gt; =loving &lt;love+able&gt; lovable.= 4.4 Representing Lists DATR&apos;s foundation in path/value specifications means that many of the representational idioms of unification formalisms transfer fairly directly. A good example is the use of first and rest attributes to represent list-structured features, such as syntactic arguments and subcategorized complements. The following definitions could be used to extend our verb fragment by introducing the path &lt;syn args&gt;, which determines a list of syntactic argument </context>
</contexts>
<marker>McFetridge, Villavicencio, 1995</marker>
<rawString>McFetridge, Paul and Aline Villavicencio. 1995. A hierarchical description of the Portuguese verb. Proceedings of the XIIth Brazilian Symposium on Artificial Intelligence, pages 302-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Mellish</author>
<author>Ehud Reiter</author>
</authors>
<title>Using classification as a programming language. IJCAI-93,</title>
<date>1993</date>
<pages>696--701</pages>
<contexts>
<context position="3242" citStr="Mellish and Reiter (1993)" startWordPosition="454" endWordPosition="457">: Roger.Evans@itri.brighton.ac.uk t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semant</context>
</contexts>
<marker>Mellish, Reiter, 1993</marker>
<rawString>Mellish, Chris and Ehud Reiter. 1993. Using classification as a programming language. IJCAI-93, pages 696-701.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teruko Mitamura</author>
<author>Eric H Nyberg</author>
</authors>
<title>Hierarchical lexical structure and interpretive mapping in machine translation.</title>
<date>1992</date>
<booktitle>COLING-92 Vol. IV,</booktitle>
<pages>1254--1258</pages>
<contexts>
<context position="3270" citStr="Mitamura and Nyberg (1992)" startWordPosition="458" endWordPosition="461">.ac.uk t Cognitive &amp; Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily an</context>
</contexts>
<marker>Mitamura, Nyberg, 1992</marker>
<rawString>Mitamura, Teruko and Eric H. Nyberg III. 1992. Hierarchical lexical structure and interpretive mapping in machine translation. COLING-92 Vol. IV, pages 1254-1258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
</authors>
<title>Feature-based lexicons-an example and a comparison to DATR.</title>
<date>1992</date>
<booktitle>Beit rage des ASL-Lexicon-Workshops. Wandtlitz,</booktitle>
<pages>36--49</pages>
<editor>In Dorothee Reimann, editor.</editor>
<contexts>
<context position="110353" citStr="Nerbonne (1992)" startWordPosition="18055" endWordPosition="18056">ions to be derived, depending on the setting of a parameter. 207 Computational Linguistics Volume 22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has been in the public domain for the last half-dozen years and been widely used in Europe during that period (by the standards of lexical knowledge representation languages), it is not surprising that it has attracted some critical attention from others working in the field. In this appendix, we consider and respond to the critical material that has been published: Domenig and ten Hacken (1992), Bouma and Nerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans and van der Linden (1992). Langer and Gibbon (1992) also respond to the last three papers in the context of a thorough general review of appropriate evaluation criteria for lexical knowledge representation formalisms. We are indebted to their discussion. Domenig and ten Hacken (1992) base part of their critique of DATR on an idiosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology. This may be because they are considering DATR as a candidate &amp;quot;FMP&amp;quot;—formalism for morphological processing—even though, as they note &amp;quot;DATR</context>
<context position="124551" citStr="Nerbonne (1992)" startWordPosition="20362" endWordPosition="20363"> one wishes. From remarks they make on pages 109 and 111 of their paper, Krieger and Nerbonne appear to believe that it is impossible to implement a particular inflectional analysis of the passive in Latin in DATR. They do not provide much of an argument, but what they do say suggests that the simple treatment of passive given in Section 4.5, above, is likewise impossible. This may be because they regard their own interpretation of lexical rules as &amp;quot;novel&amp;quot; (p. 113), although examples of that interpretation of lexical rules appear in earlier DATR work that they cite. Many of the points made in Nerbonne (1992) are repeated from the more accessible Krieger and Nerbonne (1993)57 and we have considered them in our discussion of the latter. Some of the points from the 1992 and 1993 papers resurface in Bouma and Nerbonne (1994). Nerbonne appears to misconstrue Evans, Gazdar, and Moser (1993) as an attempt to augment DATR with re-entrancy and goes on to suggest that DATR is somehow forced to maintain that &amp;quot;all linguistic generalizations tend to follow the lines of morphological form&amp;quot; (p. 47) when, in fact, the attribute ordering used in a DATR treatment of morphology is entirely independent of the use an</context>
</contexts>
<marker>Nerbonne, 1992</marker>
<rawString>Nerbonne, John. 1992. Feature-based lexicons-an example and a comparison to DATR. In Dorothee Reimann, editor. Beit rage des ASL-Lexicon-Workshops. Wandtlitz, pages 36-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Ostler</author>
<author>B T S Atkins</author>
</authors>
<title>Predictable meaning shift: Some linguistic properties of lexical implication rules.</title>
<date>1992</date>
<booktitle>Lexical Semantics and Knowledge Representation.</booktitle>
<pages>87--100</pages>
<editor>In James Pustejovsky &amp; Sabine Bergler, editors.</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin:</location>
<contexts>
<context position="63758" citStr="Ostler and Atkins (1992" startWordPosition="10515" endWordPosition="10518">ersonal_name: &lt;&gt; == Boolean &lt;ends_in_consonant&gt; == &amp;quot;&lt;ends_in_stop&gt;&amp;quot; 23 Word3 remains unchanged, overriding the definition of &lt;syn f orm&gt; and so not requiring these additional features to be defined at all. 24 We can, of course, use the same technique to define many-valued logics if we wish. 25 For example, Fraser and Corbett (1995) use DATR to capture a range of phonology/morphology/semantics interdependencies in Russian. And Brown and Hippisley (1994) do the same for a Russian segmental phonology/prosody/morphology interdependency. But one can find such interdependencies in English also: see Ostler and Atkins (1992, 96-98). 26 Note that complex expressions require path embedding. Thus, for example, the well-formed negation of a conditional is &lt;not &lt;if ...&gt;&gt; rather than &lt;not if ...&gt;. 190 Evans and Gazdar Lexical Knowledge Representation &lt;gender_is_feminine&gt; == &lt;or &lt;and &amp;quot;&lt;female_referent&gt;&amp;quot; &amp;quot;&lt;ends_in_consonant&gt;&amp;quot;&gt; &lt;and &lt;not &amp;quot;&lt;female_referent&gt;&amp;quot;&gt; &amp;quot;&lt;ends_in_stop&gt;&amp;quot;&gt;&gt;. We can then list some example lexical entries for personal proper names:2&apos; Taruz: &lt;&gt; == Personal_name &lt;female_referent&gt; == true &lt;ends_in_consonant&gt; == true. Turat: &lt;&gt; == Personal_name &lt;female_referent&gt; == true &lt;ends_in_stop&gt; == true. Tarud: &lt;&gt; == </context>
</contexts>
<marker>Ostler, Atkins, 1992</marker>
<rawString>Ostler, Nicholas and B. T. S. Atkins. 1992. Predictable meaning shift: Some linguistic properties of lexical implication rules. In James Pustejovsky &amp; Sabine Bergler, editors. Lexical Semantics and Knowledge Representation. Berlin: Springer-Verlag, pages 87-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Penn</author>
<author>Richmond Thomason</author>
</authors>
<title>Default finite state machines and finite state phonology. Computational Phonology:</title>
<date>1994</date>
<booktitle>Proceedings of the 1st Meeting of the ACL Special Interest Group in Computational Phonology,</booktitle>
<pages>33--42</pages>
<contexts>
<context position="3296" citStr="Penn and Thomason (1994)" startWordPosition="462" endWordPosition="465">ng Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily and efficiently implemented,</context>
</contexts>
<marker>Penn, Thomason, 1994</marker>
<rawString>Penn, Gerald and Richmond Thomason. 1994. Default finite state machines and finite state phonology. Computational Phonology: Proceedings of the 1st Meeting of the ACL Special Interest Group in Computational Phonology, pages 33-42.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stephen G Forthcoming Pulman</author>
</authors>
<title>Unification encodings of grammatical notations.</title>
<note>To appear in Computational Linguistics.</note>
<marker>Pulman, </marker>
<rawString>Pulman, Stephen G. Forthcoming. Unification encodings of grammatical notations. To appear in Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The generative lexicon.</title>
<date>1991</date>
<journal>Computational Linguistics</journal>
<pages>17--4</pages>
<contexts>
<context position="76567" citStr="Pustejovsky (1991" startWordPosition="12608" endWordPosition="12609">hology is undefined for verbs not syntactically passive. The techniques used in this rather simple treatment of passive can be readily adapted for use in encoding other lexical rules and for grammatical frameworks other than that implicit in the PAT Rish syntax we have adopted in our example. Thus, Evans, Gazdar, and Weir (1995) formulate various lexical rules for LTAG (see note 33). These techniques can also be readily adapted for use in the semantic domain and used, for example, to implement the distinction between fixed and projective inheritance of lexical semantic information proposed by Pustejovsky (1991, 433-437). It is advantageous to express lexical rules in the same formal language as is used to express the lexical hierarchy, since lexical rules themselves may well exhibit exactly the kinds of defaulty relations, one to another, that lexical classes do.&apos; Thus a lexical rule for direct Wh-questions may be a variant of that for indirect Wh-questions: similar, sharing components, but not identical. With a suitable degree of abstraction, achieved by parameterization of the components, lexical rules can be reified in a language like DATR, allowing one to inherit from another. 4.6 Representing </context>
</contexts>
<marker>Pustejovsky, 1991</marker>
<rawString>Pustejovsky, James. 1991. The generative lexicon. Computational Linguistics 17(4):409-441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Branimir Boguraev</author>
</authors>
<title>Lexical knowledge representation and natural language processing.</title>
<date>1993</date>
<journal>Artificial Intelligence</journal>
<pages>63--1</pages>
<contexts>
<context position="95928" citStr="Pustejovsky and Boguraev (1993" startWordPosition="15806" endWordPosition="15809">d that no conflict (e.g., in respect of &lt;cat&gt; values) can arise. More generally, OMI is invaluable for partitioning the various different, and largely independent, aspects of lexical description conventionally associated with such initial path prefixes as Om (phonology), mor (morphology), syn (syntax), and sem (semantics). In the English verbal system, for example, most morphological subregularities (such as having a past participle form in -en) operate entirely independently of most syntactic subregularities (such as having a ditransitive subcategorization frame). Within the semantic domain, Pustejovsky and Boguraev (1993, 214) introduce the expression typed inheritance for OMI and argue for its advantages in connection with the consistent assembly of the different facets of meaning associated with a lexical item. The above examples of OMI are in fact instances of a more general phenomenon in DATR. We have already noted that the combination of the longest-defined-subpathwins and logical consistency are the basis of DATR&apos;s support for coherent multiple inheritance. It turns out that functionality (which of course implies consistency) ensures orthogonality so that OMI falls out as the most normal, natural mode o</context>
</contexts>
<marker>Pustejovsky, Boguraev, 1993</marker>
<rawString>Pustejovsky, James and Branimir Boguraev. 1993. Lexical knowledge representation and natural language processing. Artificial Intelligence 63(1-2):193-223.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Reinhard</author>
</authors>
<title>Verarbeitungsprobleme nichtlinearer Morphologien: Umlautbeschreibung in einem hierarchischen Lexikon.</title>
<date>1990</date>
<booktitle>In Burghard Rieger &amp; Burkhard Schaeder Lexikon und Lexikographie.</booktitle>
<pages>45--61</pages>
<publisher>Olms Verlag,</publisher>
<location>Hildesheim:</location>
<contexts>
<context position="66079" citStr="Reinhard 1990" startWordPosition="10864" endWordPosition="10865">ds_in_consonant&gt; and &lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the phonology of the words in DATR also, then these predicates could be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1 pl&gt; == tu S2:&lt;&gt; &lt;subj 2 pl&gt; == m S2:&lt;&gt; &lt;subj 3 pl&gt; == wa S2:&lt;</context>
</contexts>
<marker>Reinhard, 1990</marker>
<rawString>Reinhard, Sabine. 1990. Verarbeitungsprobleme nichtlinearer Morphologien: Umlautbeschreibung in einem hierarchischen Lexikon. In Burghard Rieger &amp; Burkhard Schaeder Lexikon und Lexikographie. Hildesheim: Olms Verlag, 45-61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Reinhard</author>
<author>Dafydd Gibbon</author>
</authors>
<title>Prosodic inheritance and morphological generalisations.</title>
<date>1991</date>
<booktitle>Fifth Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>131--136</pages>
<contexts>
<context position="66106" citStr="Reinhard and Gibbon 1991" startWordPosition="10866" endWordPosition="10869">&gt; and &lt;ends_in_stop&gt; are just stipulated in the entries, and indeed the second definition in Personal_name means that &lt;ends_in_stop&gt; implies &lt;ends_in_consonant&gt;. But if the entries represented the phonology of the words in DATR also, then these predicates could be defined on the basis of the feature composition of the stem-final segment. As a number of researchers have shown, the highly defaulty character of lexical phonology and morphophonology makes DATR a very suitable medium of representation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991; Reinhard 1990; Reinhard and Gibbon 1991). 28 It is straightforward to add extra DATR code so as to derive &lt;gender&gt; = feminine when &lt;gender_is_feminine&gt; is true and &lt;gender&gt; = masculine when &lt;gender_is_feminine&gt; is false, or conversely. 29 Cf. Krieger, Pirker, and Nerbonne (1993), who reconstruct finite-state automata in a feature description language. 191 Computational Linguistics Volume 22, Number 2 sg like&gt; into the value ni ta ku penda (Swahili for I will like you):&apos; Si: 1 sg&gt; == ni S2:&lt;&gt; &lt;subj 2 sg&gt; == u S2:&lt;&gt; &lt;subj 3 sg&gt; =1= a 52:&lt;&gt; &lt;subj 1 pl&gt; == tu S2:&lt;&gt; &lt;subj 2 pl&gt; == m S2:&lt;&gt; &lt;subj 3 pl&gt; == wa S2:&lt;&gt;. &lt;subj &lt;past&gt; == li 53:&lt;&gt;</context>
<context position="111881" citStr="Reinhard and Gibbon (1991)" startWordPosition="18300" endWordPosition="18303">ical generalization that unites nouns and verbs in respect of the choice. But their critique is based on the assumption that they have identified &amp;quot;the most natural way to express [the choice] in DATR&amp;quot; (p. 17). Given the well-known facts of this phenomenon,&apos; their analysis seems to us to be about as unnatural as it could be. Depending on the nature and purpose of one&apos;s lexicon, it would be much more natural to deal with the choice orthographically with a DAT R-coded FST of the kind discussed in Section 4.3, above, or morphophonologically using the kind of phonological representation adopted by Reinhard and Gibbon (1991), for example. Domenig and ten Hacken actually cite this latter paper in connection with German umlaut and suggest that the -s/-es alternation might be handled in the same way. However, they go on to claim, quite incorrectly, that &amp;quot;morphophonological generalizations can actually not be expressed as such&amp;quot; in DATR because &amp;quot;they are represented as properties of the individual lexemes&amp;quot; (pp. 23-24). This claim appears to be based on a false assumption that DATR nodes are somehow restricted to the description of lexemes. This is an odd assumption to make given that the Reinhard and Gibbon paper post</context>
</contexts>
<marker>Reinhard, Gibbon, 1991</marker>
<rawString>Reinhard, Sabine and Dafydd Gibbon. 1991. Prosodic inheritance and morphological generalisations. Fifth Conference of the European Chapter of the Association for Computational Linguistics, pages 131-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Chris Mellish</author>
</authors>
<title>Using classification to generate text.</title>
<date>1992</date>
<booktitle>30th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>265--272</pages>
<contexts>
<context position="3323" citStr="Reiter and Mellish (1992)" startWordPosition="466" endWordPosition="469"> Sussex, Brighton BN1 9QH, U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily and efficiently implemented, (iv) has the necessary exp</context>
</contexts>
<marker>Reiter, Mellish, 1992</marker>
<rawString>Reiter, Ehud and Chris Mellish. 1992. Using classification to generate text. 30th Annual Meeting of the Association for Computational Linguistics, pages 265-272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme D Ritchie</author>
<author>Graham J Russell</author>
<author>Alan W Black</author>
<author>Stephen G Pulman</author>
</authors>
<title>Computational Morphology.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="71935" citStr="Ritchie et al. (1992" startWordPosition="11850" endWordPosition="11853">nguists to consign them to the lexicon. They usually involve a difference in argument structure and this is sometimes accompanied by a morphological difference. The combination of evaluable paths with a standard encoding of argument lists make it rather easy to define lexical rules in DATR.34 Here, by way of illustration, is a partial analysis of verbs that implements a lexical rule for the syntax of the (agentless) passive construction:&apos; VERB: past&gt; = = &amp;quot;&lt;mor root&gt;&amp;quot; ed &lt;mor form&gt; = = &amp;quot;&lt;mor &amp;quot;&lt;syn form&gt;&amp;quot;&gt;&amp;quot; &lt;mor cat&gt; == verb &lt;syn sub c at &gt; == &amp;quot;&lt;syn args&gt;&amp;quot; &lt;syn 32 See Carpenter (1991; 1992) and Ritchie et al. (1992, 93-111) for thorough discussion and exemplification of lexical rules in several different grammatical frameworks. More generally, Briscoe and Copestake (1991) and Copestake and Briscoe (1992) argue that, in the context of a default inheritance lexicon, the very same lexical rule mechanism can be invoked for both sense extensions and morphological processes. 33 Radically lexicalist frameworks, which lack any construction-specific grammatical rules outside the lexicon, do not restrict the use of lexical rules to &amp;quot;cyclic&amp;quot; phenomena. Thus, for example, Evans, Gazdar, and Weir (1995) report the u</context>
</contexts>
<marker>Ritchie, Russell, Black, Pulman, 1992</marker>
<rawString>Ritchie, Graeme D., Graham J. Russell, Alan W. Black, and Stephen G. Pulman. 1992. Computational Morphology. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Russell</author>
</authors>
<title>Review of Word Manager: A System for Morphological Dictionaries,</title>
<date>1993</date>
<booktitle>by Marc Domenig &amp; Pius ten Hacken. Computational Linguistics</booktitle>
<pages>19--4</pages>
<contexts>
<context position="117467" citStr="Russell (1993)" startWordPosition="19218" endWordPosition="19219">ing what that most specific level is. Our position is that this is part of the lexical metatheory, rather than the lexical description itself. It needs to be known by anyone (or any system) wishing to access the lexicon properly, and it may be practically useful to constrain access by checking for the well-formedness of queries according to such a metatheory—this could be done quite straightforwardly in DATR as an adjunct to the main lexicon if desired. This notion, however, is external to, and independent of, 51 For another critical discussion of the same Domenig and ten Hacken material, see Russell (1993). 52 One of our referees comments that &amp;quot;the issue ... appears to be rather scholastic.&amp;quot; We agree. 209 Computational Linguistics Volume 22, Number 2 the lexical description itself: the range of sensible queries only weakly constrains the manner in which their values are defined. Their third objection concerns multiple inheritance. They draw attention to the fact that DATR&apos;s normal mode of multiple inheritance is orthogonal and complain that prioritized multiple inheritance can only be expressed with additional DATR code (p. 63). However, we agree with their earlier comment &amp;quot;that orthogonal mult</context>
</contexts>
<marker>Russell, 1993</marker>
<rawString>Russell, Graham. 1993. Review of Word Manager: A System for Morphological Dictionaries, by Marc Domenig &amp; Pius ten Hacken. Computational Linguistics 19(4):699-700.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Russell</author>
<author>Afzal Ballim</author>
<author>John Carroll</author>
<author>Susan Warwick-Armstrong</author>
</authors>
<title>A practical approach to multiple default inheritance for unification-based lexicons.</title>
<date>1992</date>
<journal>Computational Linguistics</journal>
<pages>183--311</pages>
<contexts>
<context position="80537" citStr="Russell et al. (1992" startWordPosition="13289" endWordPosition="13292"> , hoove s I. Of course, as far as DATR is concerned { hoof s , hoove s } is just a sequence encode the regular and subregular polysemy associated with the crop, fiber, yarn, fabric, and garment senses of words like cotton and silk. See also Copestake and Briscoe (1995) for related work on regular and subregular polysemy. 38 For perspicuity, we provide these in DATR-augmented English here. But in a serious treatment they could just as well be given in a DATR-encoding of the lambda calculus, as used in Cahill and Evans (1990), for example. 39 See also the dreamt/dreamed verb class discussed by Russell et al. (1992, 330-331). 197 Computational Linguistics Volume 22, Number 2 of seven atoms. It is up to some component external to DATR that makes use of such complex values to interpret it as a two-member set of alternative forms. Likewise, if we have some good reason for wanting to put together the various senses of cherry into a value returned by a single path, then we can write something like this: Cherry: &lt;sem glosses&gt; == { &lt;sem gloss 1&gt; , &lt;sem gloss 2&gt; , &lt;sem gloss 3&gt; }. which will then provide this theorem: Cherry: &lt;sem glosses&gt; = { sweet red berry with pip , tree bearing sweet red berry with pip , w</context>
<context position="96831" citStr="Russell et al. 1992" startWordPosition="15946" endWordPosition="15949">We have already noted that the combination of the longest-defined-subpathwins and logical consistency are the basis of DATR&apos;s support for coherent multiple inheritance. It turns out that functionality (which of course implies consistency) ensures orthogonality so that OMI falls out as the most normal, natural mode of definition using DATR. Finally, we note that a number of recent lexical theories have invoked a form of inheritance in which multiple parents with overlapping domains are specified, and a priority ordering imposed to resolve potential inheritance conflicts (e.g., Flickinger 1987; Russell et al. 1992). In this prioritized multiple inheritance (PMI), precedence is given to nodes that come earlier in the ordering, so that the inherited value for a property comes from the first parent node in the ordering that defines that property, regardless of whether other later nodes also define it (possibly differently). Surprisingly perhaps, DATR&apos;s version of OMI can be used to reconstruct PMI without making syntactic and semantic additions to the language. In fact, we have described elsewhere no fewer than three different techniques for capturing PMI in DATR (Evans, Gazdar, and Moser 1993). But DATR w</context>
</contexts>
<marker>Russell, Ballim, Carroll, Warwick-Armstrong, 1992</marker>
<rawString>Russell, Graham, Afzal Ballim, John Carroll, and Susan Warwick-Armstrong. 1992. A practical approach to multiple default inheritance for unification-based lexicons. Computational Linguistics 183:311-337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey Sacks</author>
</authors>
<title>On some puns with some intimations.</title>
<date>1973</date>
<booktitle>Report of the 23rd Annual Roundtable Meeting on Linguistics and Language Studies. Washington D.C.:</booktitle>
<pages>135--144</pages>
<editor>In Roger W. Shuy, editor.</editor>
<publisher>Georgetown University Press,</publisher>
<contexts>
<context position="128278" citStr="Sacks (1973)" startWordPosition="20995" endWordPosition="20996">ly rather pointless) DATR analysis of the more complex of their two examples: Word: &lt;v&gt; == &amp;quot;&lt;&gt;&amp;quot; &lt;a from n&gt; == &lt;n&gt; + al &lt;v from a&gt; == &lt;a&gt; + ize &lt;n from v&gt; == &lt;v&gt; + tion. Institute: &lt;&gt; == Word &lt;root&gt; == institute. From this description we can derive theorems like these: Institute: &lt;root&gt; = institute &lt;n from v root&gt; = institute + tion &lt;a from n from v root&gt; = institute + tion + al &lt;v from a from n from v root&gt; = institute + tion + al + ize &lt;n from v from a from n from v root&gt; = institute + tion + al + ize + tion. Note the recursive reintroduction of the -tion suffix in the last theorem shown. 58 Sacks (1973) makes interesting reading in this connection. 212 Evans and Gazdar Lexical Knowledge Representation Acknowledgments We are grateful to the four Computational Linguistics referees for their criticisms and suggestions; to Lynne Cahill, Dafydd Gibbon, Jim Kilbury and David Weir for their comments on an earlier draft of the paper; and to Walter Daelemans and John Nerbonne for their comments on the first draft of the appendix. We thank Petra Barg, Lynne Cahill, Norman Fraser, Dafydd Gibbon, Elizabeth Jenkins, Jim Kilbury, Lionel Moser, and Ingrid Renz for their role(s) in the development of the DA</context>
</contexts>
<marker>Sacks, 1973</marker>
<rawString>Sacks, Harvey. 1973. On some puns with some intimations. In Roger W. Shuy, editor. Report of the 23rd Annual Roundtable Meeting on Linguistics and Language Studies. Washington D.C.: Georgetown University Press, pages 135-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to Unification Approaches to Grammar. Stanford: CSLI/Chicago</title>
<date>1986</date>
<publisher>University Press.</publisher>
<contexts>
<context position="9367" citStr="Shieber 1986" startWordPosition="1464" endWordPosition="1465">d have to write: Word2: &lt;syn cat&gt; = verb &lt;syn type&gt; = main &lt;syn form&gt; = passive participle &lt;mor form&gt; = love ed. This does not seem very helpful: the whole point of a lexical description language is to capture generalizations and avoid the kind of duplication evident in the specification of Wordl and Word2. And indeed, we shall shortly introduce an inheritance mechanism that allows us to do just that. But there is one sense in which this listing approach 3 The syntax of DATR, like its name and its minimalist philosophy, owes more than a little to that of the unification grammar language PATR (Shieber 1986). With hindsight this may have been a bad design decision since similarity of syntax tends to imply a similarity of semantics. And, as we shall see in Section 4.7 below, and elsewhere, there is a subtle but important semantic difference. 4 Node names and atoms are distinct, but essentially arbitrary, classes of tokens in DATR. In this paper we shall distinguish them by a simple case convention—node names start with an uppercase letter, atoms do not. 5 This is an approximation since it ignores the role of global contexts, see Section 5.1, below. 169 Computational Linguistics Volume 22, Number 2</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart M. 1986. An Introduction to Unification Approaches to Grammar. Stanford: CSLI/Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Stump</author>
</authors>
<title>On the theoretical status of position class restrictions on inflectional affixes.</title>
<date>1992</date>
<booktitle>In Geert Booij &amp; Jaap</booktitle>
<pages>211--241</pages>
<editor>van Marie, editors.</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="109317" citStr="Stump 1992" startWordPosition="17898" endWordPosition="17899"> in this example, but equally, nor does it allow such choices to be avoided.&apos; DATR cannot be (sensibly) used without a prior decision as to the theoretical frameworks in which the description is to be conducted: there is no &amp;quot;default&amp;quot; framework for describing morphological facts in DATR. Thus, for example, Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX theory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press) use DATR to implement their Network Morphology framework, and Gazdar (1992) shows how Paradigm Function Morphology analyses (Stump 1992) can be mapped into DATR. Indeed, it would not be entirely misleading to think of DATR as a kind of assembly language for constructing (or reconstructing) higher-level theories of lexical representation. 49 However, DATR&apos;s framework-agnosticism may make it a plausible candidate for the construction of polytheoretic lexicons. For example, one that would allow either categorial or HPSG-style subcategorization specifications to be derived, depending on the setting of a parameter. 207 Computational Linguistics Volume 22, Number 2 APPENDIX: The Critical Literature on DATR Reviewed Since DATR has be</context>
</contexts>
<marker>Stump, 1992</marker>
<rawString>Stump, Greg. 1992. On the theoretical status of position class restrictions on inflectional affixes. In Geert Booij &amp; Jaap van Marie, editors. Year Book of Morphology 1991. Dordrecht: Kluwer, pages 211-241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David S Touretzky</author>
</authors>
<title>The Mathematics of Inheritance Systems. London/Los Altos:</title>
<date>1986</date>
<publisher>Pitman/ Morgan Kaufmann.</publisher>
<contexts>
<context position="93541" citStr="Touretzky (1986" startWordPosition="15424" endWordPosition="15425">ify how the conflict should be resolved. Putting aside considerations of functionality for the moment, we see that, in DATR, both the second and third of these options are employed. The &amp;quot;longest-defined-subpath-wins&amp;quot; principle amounts to conflict resolution built into the formalism; however, it does not deal with every case. Definitions such as: Node3: &lt;&gt; == Nodel &lt;&gt; == Node2. may result in unresolvable conflicts. Such conflicts could, of course, just be ruled out by appealing to their inconsistency, which, following a logical tradition, is grounds for ruling the description to be &amp;quot;improper.&amp;quot; Touretzky (1986, 70ff) provides a formal description of a number of properties that an inheritance network may have, and discusses their significance with respect to the problem of multiple inheritance. Tree-structured networks, as their name suggests, allow any node to inherit from at most one other node, so multiple inheritance conflicts cannot arise. Orthogonal networks allow a node to inherit from more than one other node, but the properties it inherits from each must be disjoint, so that again, no conflict can possibly arise. The basic descriptive features of DATR allow the specification of simple ortho</context>
</contexts>
<marker>Touretzky, 1986</marker>
<rawString>Touretzky, David S. 1986. The Mathematics of Inheritance Systems. London/Los Altos: Pitman/ Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Young</author>
</authors>
<title>Nonmonotonic sorts for feature structures. AAAI-92,</title>
<date>1992</date>
<pages>596--601</pages>
<contexts>
<context position="3337" citStr="Young (1992)" startWordPosition="470" endWordPosition="471">U.K. E-mail: Gerald.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily and efficiently implemented, (iv) has the necessary expressive power </context>
</contexts>
<marker>Young, 1992</marker>
<rawString>Young, Mark A. 1992. Nonmonotonic sorts for feature structures. AAAI-92, pages 596-601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Young</author>
<author>Bill Rounds</author>
</authors>
<title>A logical semantics for nonmonotonic sorts.</title>
<date>1993</date>
<booktitle>Proceedings of the 31st Annual Meeting of the ACL,</booktitle>
<pages>209--215</pages>
<contexts>
<context position="3366" citStr="Young and Rounds (1993)" startWordPosition="473" endWordPosition="476">d.Gazdar@cogs.sussex.ac.uk 1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bring together much recent work on the application of inheritance networks to lexical description. Other relevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995), Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre, and Veronis (1994), Lascarides et al. (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992), Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993). © 1996 Association for Computational Linguistics Computational Linguistics Volume 22, Number 2 show that the language is nonetheless sufficiently expressive to represent concisely the structure of lexical information at a variety of levels of language description. The development of DATR has been guided by a number of concerns, which we summarize here. Our objective has been a language that (i) has an explicit theory of inference, (ii) has an explicit declarative semantics, (iii) can be readily and efficiently implemented, (iv) has the necessary expressive power to encode the lexical entries</context>
</contexts>
<marker>Young, Rounds, 1993</marker>
<rawString>Young, Mark A. and Bill Rounds. 1993. A logical semantics for nonmonotonic sorts. Proceedings of the 31st Annual Meeting of the ACL, pages 209-215.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>