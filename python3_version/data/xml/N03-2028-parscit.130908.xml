<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.047079">
<title confidence="0.923255">
LM Studies on Filled Pauses in Spontaneous Medical Dictation
</title>
<author confidence="0.922763">
Jochen Peters
</author>
<affiliation confidence="0.865369">
Philips Research Laboratories, Weisshausstrasse 2, D-52066 Aachen
</affiliation>
<email confidence="0.989246">
jochen.peters@philips.com
</email>
<sectionHeader confidence="0.993709" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999986411764706">
We investigate the optimal LM treatment of
abundant filled pauses (FP) in spontaneous
monologues of a professional dictation task.
Questions addressed here are (1) how to deal
with FP in the LM history and (2) to which ex-
tent can the LM distinguish between positions
with high and low FP likelihood. Our results
differ partly from observations reported on di-
alogues. Discarding FP from all LM histories
clearly improves the performance. Local per-
plexities, entropies and word rankings at po-
sitions following FP suggest that most FP in-
dicate hesitations rather than restarts. Proper
prediction of FP allows to distinguish FP from
word positions by a doubled FP probability.
Recognition experiments confirm the improve-
ments found in our perplexity studies.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999978346938776">
Speech disfluencies are characteristic for spontaneous
speech. Different disfluency types can be distinguished:
Filled pauses (FP) such as ‘UH’ or ‘UM’, restarts or re-
pairs, and repetitions. It is widely accepted that disflu-
encies considerably degrade the performance of speech
recognition due to unexpected word sequences and due
to the acoustic confusability of FP with short function
words.
Most publications investigate different types of disflu-
encies in spontaneous dialogues. This paper, instead, re-
ports analyses on spontaneous dictation of medical re-
ports, i.e. on spontaneous monologues. Our studies focus
on FP which are clearly dominant in our data (8% fre-
quency) and which appear to be mainly associated with
hesitations. As opposed to dialogues, FP are never used
here to prevent interruptions by the dialogue partner as
the speaker is searching for some formulation.
Central questions for language modeling are the op-
timal prediction of FP and its treatment in the LM his-
tory. Discarding FP from the history should be helpful if
the sentence is continued after the interruption. For com-
plete restarts, however, preceding words may be mislead-
ing and a conditioning on FP may be better. On Switch-
board, (Stolcke and Shriberg, 1996) found that words
following FP are better predicted if FP is not discarded
from the history. This was attributed to the tendency of
FP to appear at sentence boundaries where the word con-
text from the preceding sentence appears to be harmful.
Measurements after sentence-internal FP only, however,
showed a local perplexity reduction for FP-cleaned histo-
ries by 20–30%. This was expected since most sentences
are continued after the FP. These observations were con-
firmed by (Siu and Ostendorf, 1996) for sentence-internal
FP but the local perplexity reduction due to skipping FP
was much smaller. Interestingly, there, local trigram per-
plexities after FP are about 40% worse than bigram per-
plexities, no matter whether FP was discarded from the
history or not. For a How May I Help You task, (Rose and
Riccardi, 1999) report an improved LM prediction if FP
is explicitly used for the conditioning of following words.
This paper is organized as follows: Section 2 describes
the dictation task and our corpora. Section 3 lists three
basic approaches to treat FP in trigram LMs. Section 4
discusses various perplexity comparisons, especially fo-
cussing on the question how to treat FP in the LM history.
An extra study is concerned with LM uncertainties after
FP. Finally, we analyze how well our LMs can discrimi-
nate FP from word positions. Section 5 summarizes our
results and cites related speech recognition experiments.
</bodyText>
<sectionHeader confidence="0.986739" genericHeader="introduction">
2 Corpora
</sectionHeader>
<bodyText confidence="0.997683551724138">
Our experiments are based on about 1.4 Mio. words of
real-life dictated medical reports from various US hospi-
tals which are partitioned into a Train, Dev, and Eval set
(Table 1). The dictation style is fully spontaneous with
repairs, repetitions, partial words, and – most frequent –
filled pauses. Manual transciptions of these data include
the annotation of FP. However, tags to distinguish be-
tween FP associated with hesitations, repairs, and restarts
are missing. Here, as opposed to Switchboard, most FP
are sentence-internal (ca. 70–80%).
A large background corpus provides formatted, i.e.
non-spontaneous reports which are mapped to the 60 k
word list of our recognition system. To train LMs includ-
ing FP this ‘Report’ corpus was stochastically enriched
with FP. Considering single or sequential FP/s as hid-
den events in the reports we randomly inserted them with
their a-posteriori probabilities in the given word contexts.
These probabilities are estimated using a bigram from the
spontaneous training data. A similar approach was men-
tioned without details in (Gauvain et al., 1997). They
report increasing error rates if too many FP are inserted
by this method into the LM training data. This might be
explained by the following observation: Adding FP in a
context-dependent fashion diminishes the number of ob-
served bi- and trigrams since words typically preceding
or following FP “loose individual contexts” if many FP
are inserted. For our Report corpus, the number of dis-
tinct uni- + bi- + trigrams drops from 107 M (without FP)
to 98 M (after FP enrichment).
</bodyText>
<table confidence="0.999819">
Corpus Spont # words FP rate OOV rate
Train yes 1314 k 8.2 % 0.45 %
Dev yes 81 k 6.3 % 0.23 %
Eval yes 53 k 7.0 % 0.30 %
Report no 1071 M 7.9 % 0.31 %
</table>
<tableCaption confidence="0.6797">
Table 1: Characteristics of text corpora including FP.
(The high OOV rate on Train is due to an extension of
this data set after fixing our 60 k word list.)
</tableCaption>
<sectionHeader confidence="0.971512" genericHeader="method">
3 Language models
</sectionHeader>
<bodyText confidence="0.8649885">
Mapping all filled pauses to a unique symbol FP we com-
pare three LM approaches:
</bodyText>
<listItem confidence="0.868156125">
1. We treat FP as a regular word which is predicted by
the LM and which conditions following words.
2. We use the LM for both words and FP but discard
all FP from the conditioning histories.
3. We use a fixed, context-independent probability for
FP of 0.08 (FP unigram). Here, words are predicted
with a FP-free LM skipping FP in the history (as in
approach 2.). Normalization is achieved by a scal-
</listItem>
<bodyText confidence="0.997157388888889">
ing of word probabilities with (1 − pfix(FP)). This
simplistic approach relieves us from the need of FP-
tagged corpora, but we clearly loose the discrimina-
tive prediction of FP.
Approaches 1. and 2. use count statistics with FP. As
discussed above, the inclusion of FP “destroys” some
possible word transitions. To exploit the knowledge
about possible FP-cleaned transitions we successfully
tested merged counts. Here, the sets of observed M-
Grams in the corpus with and without FP are joined and
counts of common M-Grams are added. (Doubled counts
use modified discounting and the reduced FP-rate is com-
pensated using marginal adaptation (Kneser et al., 1997).)
All reported results are obtained with linearly interpo-
lated models from the spontaneous Train and the non-
spontaneous Report corpus. (For trigrams, perplexities
of these two component LMs are 95% and 19% above
the perplexity of the interpolated LM.)
</bodyText>
<sectionHeader confidence="0.996984" genericHeader="evaluation">
4 Experimental results
</sectionHeader>
<bodyText confidence="0.998469926829268">
The three approaches are evaluated in terms of the overall
perplexity (PP) and local values: PPFP and PPword are
measured at FP and word positions only, and PPafter ∗
are measured immediately thereafter.
The results in Table 2 show that discarding FP from the
history clearly improves the performance (2. versus 1.).
The overall PP is reduced by 4–5%. Big reductions by
30–40% are found at positions immediately following FP.
This, and the improvements as we go from bi- to trigrams
(which are contrary to (Siu and Ostendorf, 1996)), indi-
cates that sentences are – on average – continued after FP.
Using merged counts further improves our LMs. Gains
are (almost) additive to those from FP-skipping. Espe-
cially, PPafter FP decreases by another 10% for approach
2. which shows that the “recovered” FP-free M-Grams
are indeed valuable if we use FP-free histories.
A comparison of PPafter FP and PPafter word confirms
the common knowledge that word prediction after FP is
pretty hard. Even the unigram perplexity is almost 50%
higher for words following FP than for words follow-
ing fluent contexts. This supports (Shriberg and Stolcke,
1996) where the reduced predictability after FP is partly
attributed to the chosen words in those positions.
For trigrams, the discrepancy between PPafter FP and
PPafter word is much larger. Asking “how unexpected is
a word in a given context ?” we evaluated the entropy
H(hi) = −Ew pLM(w  |hi) · log pLM(w  |hi) and the
rank Ri of wi following hi in the distribution pLM(*  |hi).
Both quantities were averaged over histories hi ending on
FP or on words.1 Note that eHme8II represents a perplex-
ity for the case that words following each history are dis-
tributed according to pLM(*  |h). An actually measured
PP above eHme8II indicates a bias in the corpus towards
words with low pLM(w  |h). The results from Table 3
show almost no such bias after words. After FP, however,
following words are clearly biased to low probabilities
within the trigram distributions. Also, the mean ranks are
considerably higher after FP than after words.
Together, these findings support our impression that FP
often represents a hesitation where the speaker is search-
ing for a less common word or formulation.
</bodyText>
<tableCaption confidence="0.543418">
1(Shriberg and Stolcke, 1996) report increasing entropies at
FP versus word positions. Our studies confirm these results.
Table 2: Perplexities and error bars (95% confidence) on the Dev set for linearly interpolated LMs.
</tableCaption>
<table confidence="0.999731583333333">
LM range Appr. Counts PPoverall PPFP PPword PPafter FP PPafter word
size: 81 k 5 k 76 k 5 k 76 k
Unigram 1. = 2. with FP 786.5 f 14.0 12.4 f 0.0 1042.2 f 17.9 1136.8 f 85.7 767.1 f 14.0
3. FP-free 786.4 f 14.0 12.5 f 0.0 1041.7 f 17.9 1136.3 f 85.6 767.0 f 14.0
Bigram with FP 115.6 f 2.4 11.0 f 0.2 135.7 f 3.0 957.5 f 76.0 100.2 f 2.2
with FP 112.0 f 2.4 11.1 f 0.2 131.0 f 2.9 579.3 f 50.6 100.2 f 2.2
FP-free 110.9 f 2.3 12.5 f 0.0 128.6 f 2.8 503.5 f 42.6 100.1 f 2.1
Trigram 1. with FP 61.4 f 1.4 10.4 f 0.2 69.3 f 1.6 605.9 f 49.9 52.6 f 1.2
merged 60.3 f 1.3 9.8 f 0.2 68.2 f 1.6 646.3 f 53.2 51.4 f 1.1
with FP 59.2 f 1.3 10.9 f 0.2 66.4 f 1.5 427.2 f 39.8 51.8 f 1.2
2. merged 57.5 f 1.2 11.4 f 0.2 64.2 f 1.5 383.6 f 34.5 50.5 f 1.1
3. FP-free 57.9 f 1.2 12.5 f 0.0 64.3 f 1.5 367.0 f 33.0 51.1 f 1.1
</table>
<tableCaption confidence="0.989137">
Table 3: Measured PP versus eHmean and mean rank after
histories ending on FP or on word (using pruned LMs).
</tableCaption>
<table confidence="0.997795666666667">
Range Appr. PP Rmean after
eHmean after
FP word FP word
Uni 1. = 2. 1.6 1.1 1301 881
Tri 2.6 1.2 1050 336
5.1 1.2 719 335
</table>
<bodyText confidence="0.998836888888889">
Recall that approach 3. cannot discriminate between
positions with an increased or reduced FP probability. To
evaluate the discrimination for approaches 1. and 2. we
calculated p(FPI h) instead of p(w I h) at each position
in the corpus. The crucial result is that the mean FP prob-
ability is reduced by 48% and 45% (approach 1. and 2.)
at word as compared to FP positions. This is an important
feature of these LMs since small FP probabilities reduce
confusions of proper words with FP.
</bodyText>
<sectionHeader confidence="0.998698" genericHeader="conclusions">
5 Summary
</sectionHeader>
<bodyText confidence="0.9993155">
Concerning the question how to best predict words next
to FP we get the following results for our spontaneous
dictation task: Discarding FP from the LM histories re-
duces PPoverall by 4% and PPafter FP by 30%. (The
latter reduction is bigger than in (Stolcke and Shriberg,
1996). Note that our measurements include positions af-
ter sentence-initial FP which suffer from the FP-removal.)
Count merging with FP-free M-Grams gives an additional
reduction of PPoverall by 3% and of PPafter FP by 10%.
Comparisons of local perplexities and studies of en-
tropies and word rankings indicate that FP often repre-
sents a hesitation as speakers are searching for a less com-
mon word or formulation which is hard to predict.
At positions following FP, trigrams outperform bi-
grams. This together with gains from discarded FP sug-
gests that FP rarely represent sentence breaks or restarts.
We presented a new analysis of the LM’s power to dis-
criminate between FP and word positions. Predicting FP
with a trigram allows to lower the FP probability at word
positions by almost 50%. This is an important feature to
reduce confusions of words with FP.
Speech recognition experiments are published in
(Schramm et al., 2003). Using merged counts and dis-
carding FP from the LM history reduces the error rate on
Eval by 2.2% (relative) while PP is reduced by 7%.
Acknowledgements: I would like to thank Xavier
Aubert and Hauke Schramm for their contribution of
speech recognition experiments.
</bodyText>
<sectionHeader confidence="0.999095" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999622954545455">
J.L. Gauvain, G. Adda, L. Lamel, M. Adda-Decker.
1997. Transcribing Broadcast News: The LIMSI
Nov96 Hub4 System. Proc. DARPA Speech Recog-
nition Workshop.
R. Kneser, J. Peters, D. Klakow. 1997. Language
model adaptation using dynamic marginals. Proc. EU-
ROSPEECH, 4:1971–1974.
R.C. Rose, G. Riccardi. 1999. Modeling disfluency and
background events in ASR for a natural language un-
derstanding task. Proc. ICASSP, 1:341–344.
H. Schramm, X. L. Aubert, C. Meyer, J. Peters. 2003.
Filled-pause modeling for medical transcriptions. To
appear at IEEE Workshop an Spontaneous Speech Pro-
cessing and Recognition.
E. Shriberg, A. Stolcke. 1996. Word predictability af-
ter hesitations: a corpus-based study. Proc. ICSLP,
3:1868 -1871.
M. Siu, M. Ostendorf. 1996. Modeling disfluencies in
conversational speech. Proc. ICSLP, 1:386–389.
A. Stolcke, E. Shriberg. 1996. Statistical language mod-
eling for speech disfluencies. Proc. ICASSP, 1:405–
408.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.173586">
<title confidence="0.8031535">LM Studies on Filled Pauses in Spontaneous Medical Dictation Jochen Peters</title>
<note confidence="0.321016">Philips Research Laboratories, Weisshausstrasse 2, D-52066</note>
<email confidence="0.999191">jochen.peters@philips.com</email>
<abstract confidence="0.995049833333333">We investigate the optimal LM treatment of abundant filled pauses (FP) in spontaneous a professional dictation task. Questions addressed here are (1) how to deal with FP in the LM history and (2) to which extent can the LM distinguish between positions with high and low FP likelihood. Our results partly from observations reported on di- Discarding FP from all LM histories clearly improves the performance. Local perplexities, entropies and word rankings at positions following FP suggest that most FP indicate hesitations rather than restarts. Proper prediction of FP allows to distinguish FP from word positions by a doubled FP probability. Recognition experiments confirm the improvements found in our perplexity studies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J L Gauvain</author>
<author>G Adda</author>
<author>L Lamel</author>
<author>M Adda-Decker</author>
</authors>
<title>Transcribing Broadcast News:</title>
<date>1997</date>
<booktitle>The LIMSI Nov96 Hub4 System. Proc. DARPA Speech Recognition Workshop.</booktitle>
<contexts>
<context position="4710" citStr="Gauvain et al., 1997" startWordPosition="739" endWordPosition="742">re, as opposed to Switchboard, most FP are sentence-internal (ca. 70–80%). A large background corpus provides formatted, i.e. non-spontaneous reports which are mapped to the 60 k word list of our recognition system. To train LMs including FP this ‘Report’ corpus was stochastically enriched with FP. Considering single or sequential FP/s as hidden events in the reports we randomly inserted them with their a-posteriori probabilities in the given word contexts. These probabilities are estimated using a bigram from the spontaneous training data. A similar approach was mentioned without details in (Gauvain et al., 1997). They report increasing error rates if too many FP are inserted by this method into the LM training data. This might be explained by the following observation: Adding FP in a context-dependent fashion diminishes the number of observed bi- and trigrams since words typically preceding or following FP “loose individual contexts” if many FP are inserted. For our Report corpus, the number of distinct uni- + bi- + trigrams drops from 107 M (without FP) to 98 M (after FP enrichment). Corpus Spont # words FP rate OOV rate Train yes 1314 k 8.2 % 0.45 % Dev yes 81 k 6.3 % 0.23 % Eval yes 53 k 7.0 % 0.3</context>
</contexts>
<marker>Gauvain, Adda, Lamel, Adda-Decker, 1997</marker>
<rawString>J.L. Gauvain, G. Adda, L. Lamel, M. Adda-Decker. 1997. Transcribing Broadcast News: The LIMSI Nov96 Hub4 System. Proc. DARPA Speech Recognition Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kneser</author>
<author>J Peters</author>
<author>D Klakow</author>
</authors>
<title>Language model adaptation using dynamic marginals.</title>
<date>1997</date>
<booktitle>Proc. EUROSPEECH,</booktitle>
<pages>4--1971</pages>
<contexts>
<context position="6655" citStr="Kneser et al., 1997" startWordPosition="1089" endWordPosition="1092">ix(FP)). This simplistic approach relieves us from the need of FPtagged corpora, but we clearly loose the discriminative prediction of FP. Approaches 1. and 2. use count statistics with FP. As discussed above, the inclusion of FP “destroys” some possible word transitions. To exploit the knowledge about possible FP-cleaned transitions we successfully tested merged counts. Here, the sets of observed MGrams in the corpus with and without FP are joined and counts of common M-Grams are added. (Doubled counts use modified discounting and the reduced FP-rate is compensated using marginal adaptation (Kneser et al., 1997).) All reported results are obtained with linearly interpolated models from the spontaneous Train and the nonspontaneous Report corpus. (For trigrams, perplexities of these two component LMs are 95% and 19% above the perplexity of the interpolated LM.) 4 Experimental results The three approaches are evaluated in terms of the overall perplexity (PP) and local values: PPFP and PPword are measured at FP and word positions only, and PPafter ∗ are measured immediately thereafter. The results in Table 2 show that discarding FP from the history clearly improves the performance (2. versus 1.). The ove</context>
</contexts>
<marker>Kneser, Peters, Klakow, 1997</marker>
<rawString>R. Kneser, J. Peters, D. Klakow. 1997. Language model adaptation using dynamic marginals. Proc. EUROSPEECH, 4:1971–1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Rose</author>
<author>G Riccardi</author>
</authors>
<title>Modeling disfluency and background events in ASR for a natural language understanding task.</title>
<date>1999</date>
<booktitle>Proc. ICASSP,</booktitle>
<pages>1--341</pages>
<contexts>
<context position="3005" citStr="Rose and Riccardi, 1999" startWordPosition="468" endWordPosition="471">rom the preceding sentence appears to be harmful. Measurements after sentence-internal FP only, however, showed a local perplexity reduction for FP-cleaned histories by 20–30%. This was expected since most sentences are continued after the FP. These observations were confirmed by (Siu and Ostendorf, 1996) for sentence-internal FP but the local perplexity reduction due to skipping FP was much smaller. Interestingly, there, local trigram perplexities after FP are about 40% worse than bigram perplexities, no matter whether FP was discarded from the history or not. For a How May I Help You task, (Rose and Riccardi, 1999) report an improved LM prediction if FP is explicitly used for the conditioning of following words. This paper is organized as follows: Section 2 describes the dictation task and our corpora. Section 3 lists three basic approaches to treat FP in trigram LMs. Section 4 discusses various perplexity comparisons, especially focussing on the question how to treat FP in the LM history. An extra study is concerned with LM uncertainties after FP. Finally, we analyze how well our LMs can discriminate FP from word positions. Section 5 summarizes our results and cites related speech recognition experimen</context>
</contexts>
<marker>Rose, Riccardi, 1999</marker>
<rawString>R.C. Rose, G. Riccardi. 1999. Modeling disfluency and background events in ASR for a natural language understanding task. Proc. ICASSP, 1:341–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schramm</author>
<author>X L Aubert</author>
<author>C Meyer</author>
<author>J Peters</author>
</authors>
<title>Filled-pause modeling for medical transcriptions. To appear at IEEE Workshop an Spontaneous Speech Processing and Recognition.</title>
<date>2003</date>
<marker>Schramm, Aubert, Meyer, Peters, 2003</marker>
<rawString>H. Schramm, X. L. Aubert, C. Meyer, J. Peters. 2003. Filled-pause modeling for medical transcriptions. To appear at IEEE Workshop an Spontaneous Speech Processing and Recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shriberg</author>
<author>A Stolcke</author>
</authors>
<title>Word predictability after hesitations: a corpus-based study.</title>
<date>1996</date>
<booktitle>Proc. ICSLP,</booktitle>
<volume>3</volume>
<pages>1871</pages>
<contexts>
<context position="8068" citStr="Shriberg and Stolcke, 1996" startWordPosition="1318" endWordPosition="1321"> and Ostendorf, 1996)), indicates that sentences are – on average – continued after FP. Using merged counts further improves our LMs. Gains are (almost) additive to those from FP-skipping. Especially, PPafter FP decreases by another 10% for approach 2. which shows that the “recovered” FP-free M-Grams are indeed valuable if we use FP-free histories. A comparison of PPafter FP and PPafter word confirms the common knowledge that word prediction after FP is pretty hard. Even the unigram perplexity is almost 50% higher for words following FP than for words following fluent contexts. This supports (Shriberg and Stolcke, 1996) where the reduced predictability after FP is partly attributed to the chosen words in those positions. For trigrams, the discrepancy between PPafter FP and PPafter word is much larger. Asking “how unexpected is a word in a given context ?” we evaluated the entropy H(hi) = −Ew pLM(w |hi) · log pLM(w |hi) and the rank Ri of wi following hi in the distribution pLM(* |hi). Both quantities were averaged over histories hi ending on FP or on words.1 Note that eHme8II represents a perplexity for the case that words following each history are distributed according to pLM(* |h). An actually measured PP</context>
</contexts>
<marker>Shriberg, Stolcke, 1996</marker>
<rawString>E. Shriberg, A. Stolcke. 1996. Word predictability after hesitations: a corpus-based study. Proc. ICSLP, 3:1868 -1871.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Siu</author>
<author>M Ostendorf</author>
</authors>
<title>Modeling disfluencies in conversational speech.</title>
<date>1996</date>
<booktitle>Proc. ICSLP,</booktitle>
<pages>1--386</pages>
<contexts>
<context position="2687" citStr="Siu and Ostendorf, 1996" startWordPosition="414" endWordPosition="417">owever, preceding words may be misleading and a conditioning on FP may be better. On Switchboard, (Stolcke and Shriberg, 1996) found that words following FP are better predicted if FP is not discarded from the history. This was attributed to the tendency of FP to appear at sentence boundaries where the word context from the preceding sentence appears to be harmful. Measurements after sentence-internal FP only, however, showed a local perplexity reduction for FP-cleaned histories by 20–30%. This was expected since most sentences are continued after the FP. These observations were confirmed by (Siu and Ostendorf, 1996) for sentence-internal FP but the local perplexity reduction due to skipping FP was much smaller. Interestingly, there, local trigram perplexities after FP are about 40% worse than bigram perplexities, no matter whether FP was discarded from the history or not. For a How May I Help You task, (Rose and Riccardi, 1999) report an improved LM prediction if FP is explicitly used for the conditioning of following words. This paper is organized as follows: Section 2 describes the dictation task and our corpora. Section 3 lists three basic approaches to treat FP in trigram LMs. Section 4 discusses var</context>
<context position="7462" citStr="Siu and Ostendorf, 1996" startWordPosition="1220" endWordPosition="1223">ent LMs are 95% and 19% above the perplexity of the interpolated LM.) 4 Experimental results The three approaches are evaluated in terms of the overall perplexity (PP) and local values: PPFP and PPword are measured at FP and word positions only, and PPafter ∗ are measured immediately thereafter. The results in Table 2 show that discarding FP from the history clearly improves the performance (2. versus 1.). The overall PP is reduced by 4–5%. Big reductions by 30–40% are found at positions immediately following FP. This, and the improvements as we go from bi- to trigrams (which are contrary to (Siu and Ostendorf, 1996)), indicates that sentences are – on average – continued after FP. Using merged counts further improves our LMs. Gains are (almost) additive to those from FP-skipping. Especially, PPafter FP decreases by another 10% for approach 2. which shows that the “recovered” FP-free M-Grams are indeed valuable if we use FP-free histories. A comparison of PPafter FP and PPafter word confirms the common knowledge that word prediction after FP is pretty hard. Even the unigram perplexity is almost 50% higher for words following FP than for words following fluent contexts. This supports (Shriberg and Stolcke,</context>
</contexts>
<marker>Siu, Ostendorf, 1996</marker>
<rawString>M. Siu, M. Ostendorf. 1996. Modeling disfluencies in conversational speech. Proc. ICSLP, 1:386–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>E Shriberg</author>
</authors>
<title>Statistical language modeling for speech disfluencies.</title>
<date>1996</date>
<booktitle>Proc. ICASSP,</booktitle>
<pages>1--405</pages>
<contexts>
<context position="2189" citStr="Stolcke and Shriberg, 1996" startWordPosition="334" endWordPosition="337">n FP which are clearly dominant in our data (8% frequency) and which appear to be mainly associated with hesitations. As opposed to dialogues, FP are never used here to prevent interruptions by the dialogue partner as the speaker is searching for some formulation. Central questions for language modeling are the optimal prediction of FP and its treatment in the LM history. Discarding FP from the history should be helpful if the sentence is continued after the interruption. For complete restarts, however, preceding words may be misleading and a conditioning on FP may be better. On Switchboard, (Stolcke and Shriberg, 1996) found that words following FP are better predicted if FP is not discarded from the history. This was attributed to the tendency of FP to appear at sentence boundaries where the word context from the preceding sentence appears to be harmful. Measurements after sentence-internal FP only, however, showed a local perplexity reduction for FP-cleaned histories by 20–30%. This was expected since most sentences are continued after the FP. These observations were confirmed by (Siu and Ostendorf, 1996) for sentence-internal FP but the local perplexity reduction due to skipping FP was much smaller. Inte</context>
<context position="11187" citStr="Stolcke and Shriberg, 1996" startWordPosition="1914" endWordPosition="1917">aches 1. and 2. we calculated p(FPI h) instead of p(w I h) at each position in the corpus. The crucial result is that the mean FP probability is reduced by 48% and 45% (approach 1. and 2.) at word as compared to FP positions. This is an important feature of these LMs since small FP probabilities reduce confusions of proper words with FP. 5 Summary Concerning the question how to best predict words next to FP we get the following results for our spontaneous dictation task: Discarding FP from the LM histories reduces PPoverall by 4% and PPafter FP by 30%. (The latter reduction is bigger than in (Stolcke and Shriberg, 1996). Note that our measurements include positions after sentence-initial FP which suffer from the FP-removal.) Count merging with FP-free M-Grams gives an additional reduction of PPoverall by 3% and of PPafter FP by 10%. Comparisons of local perplexities and studies of entropies and word rankings indicate that FP often represents a hesitation as speakers are searching for a less common word or formulation which is hard to predict. At positions following FP, trigrams outperform bigrams. This together with gains from discarded FP suggests that FP rarely represent sentence breaks or restarts. We pre</context>
</contexts>
<marker>Stolcke, Shriberg, 1996</marker>
<rawString>A. Stolcke, E. Shriberg. 1996. Statistical language modeling for speech disfluencies. Proc. ICASSP, 1:405– 408.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>