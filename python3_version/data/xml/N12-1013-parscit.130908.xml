<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000675">
<title confidence="0.982243">
Minimum-Risk Training of Approximate CRF-Based NLP Systems
</title>
<author confidence="0.936361">
Veselin Stoyanov and Jason Eisner
</author>
<affiliation confidence="0.778972">
HLTCOE and Center for Language and Speech Processing
Johns Hopkins University
</affiliation>
<address confidence="0.876349">
Baltimore, MD 21218
</address>
<email confidence="0.9946">
Ives, jason}@cs.jhu.edu
</email>
<sectionHeader confidence="0.994508" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.981586823529412">
Conditional Random Fields (CRFs) are a pop-
ular formalism for structured prediction in
NLP. It is well known how to train CRFs with
certain topologies that admit exact inference,
such as linear-chain CRFs. Some NLP phe-
nomena, however, suggest CRFs with more
complex topologies. Should such models be
used, considering that they make exact infer-
ence intractable? Stoyanov et al. (2011) re-
cently argued for training parameters to min-
imize the task-specific loss of whatever ap-
proximate inference and decoding methods
will be used at test time. We apply their
method to three NLP problems, showing that
(i) using more complex CRFs leads to im-
proved performance, and that (ii) minimum-
risk training learns more accurate models.
</bodyText>
<sectionHeader confidence="0.998904" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99862968">
Conditional Random Fields (CRFs) (Lafferty et al.,
2001) are often used to model dependencies among
linguistic variables. CRF-based models have im-
proved the state of the art in a number of natural
language processing (NLP) tasks ranging from part-
of-speech tagging to information extraction and sen-
timent analysis (Lafferty et al., 2001; Peng and Mc-
Callum, 2006; Choi et al., 2005).
Robust and theoretically sound training proce-
dures have been developed for CRFs when the
model can be used with exact inference and de-
coding.1 However, some NLP problems seem to
1“Inference” typically refers to computing posterior
marginal or max-marginal probability distributions of output
random variables, given some evidence. “Decoding” derives
a single structured output from the results of inference.
call for higher-treewidth graphical models in which
exact inference is expensive or intractable. These
“loopy” CRFs have cyclic connections among the
output and/or latent variables. Alas, standard learn-
ing procedures assume exact inference: they do not
compensate for approximations that will be used at
test time, and can go surprisingly awry if approxi-
mate inference is used at training time (Kulesza and
Pereira, 2008).
While NLP research has been consistently evolv-
ing toward more richly structured models, one may
hesitate to add dependencies to a graphical model if
there is a danger that this will end up hurting per-
formance through approximations. In this paper we
illustrate how to address this problem, even for ex-
tremely interconnected models in which every pair
of output variables is connected.
Wainwright (2006) showed that if approximate in-
ference will be used at test time, it may be beneficial
to use a learning procedure that does not converge to
the true model but to one that performs well under
the approximations. Stoyanov et al. (2011) argue for
minimizing a certain non-convex training objective,
namely the empirical risk of the entire system com-
prising the CRF together with whatever approximate
inference and decoding procedures will be used at
test time. They regard this entire system as sim-
ply a complex decision rule, analogous to a neu-
ral network, and show how to use back-propagation
to tune its parameters to locally minimize the em-
pirical risk (i.e., the average task-specific loss on
training data). Stoyanov et al. (2011) show that
on certain synthetic-data problems, this frequentist
training regimen significantly reduced test-data loss
</bodyText>
<page confidence="0.645241666666667">
120
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 120–130,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<bodyText confidence="0.999975032258065">
compared to approximate maximum likelihood esti-
mation (MLE). However, this method has not been
evaluated on real-world problems until now.
We will refer to the Stoyanov et al. (2011) ap-
proach as “ERMA”—Empirical Risk Minimization
under Approximations. ERMA is attractive for NLP
because the freedom to use arbitrarily structured
graphical models makes it possible to include latent
linguistic variables, predict complex structures such
as parses (Smith and Eisner, 2008), and do collec-
tive prediction in relational domains (Ji and Grish-
man, 2011; Benson et al., 2011; Dreyer and Eis-
ner, 2009). In training, ERMA considers not only
the approximation method but also the task-specific
loss function. This means that ERMA is careful to
use the additional variables and dependencies only
in ways that help training set performance. (Overfit-
ting on the enlarged parameter set should be avoided
through regularization.)
We have developed a simple syntax for specify-
ing CRFs with complex structures, and a software
package (available from http://www.clsp.
jhu.edu/˜ves/software.html) that allows
ERMA training of these CRFs for several popular
loss functions (e.g., accuracy, mean-squared error,
F-measure). In this paper, we use these tools to re-
visit three previously studied NLP applications that
can be modeled naturally with approximate CRFs
(we will use approximate CRFs to refer to CRF-
based systems that are used with approximations in
inference or decoding). We show that (i) natural lan-
guage can be modeled more effectively with CRFs
that are not restricted to a linear structure and (ii)
that ERMA training represents an improvement over
previous learning methods.
The first application, predicting congressional
votes, has not been previously modeled with CRFs.
By using a more principled probabilistic approach,
we are able to improve the state-of-the-art accuracy
from 71.2% to 78.2% when training to maximize the
approximate log-likelihood of the training data. By
switching to ERMA training, we improve this result
further to 85.1%.
The second application, information extraction
from seminar announcements, has been modeled
previously with skip-chain CRFs (Sutton and Mc-
Callum, 2005; Finkel et al., 2005). The skip-chain
CRF introduces loops and requires approximate in-
ference, which motivates minimum risk training.
Our results show that ERMA training improves F-
measures from 89.5 to 90.9 (compared to 87.1 for
the model without skip-chains).
Finally, for our third application, we perform col-
lective multi-label text classification. We follow pre-
vious work (Ghamrawi and McCallum, 2005; Finley
and Joachims, 2008) and use a fully connected CRF
to model all pairwise dependencies between labels.
We observe similar trends for this task: switching
from a maximum entropy model that does not model
label dependencies to a loopy CRF leads to an im-
provement in F-measure from 81.6 to 84.0, and us-
ing ERMA leads to additional improvement (84.7).
</bodyText>
<sectionHeader confidence="0.997296" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<subsectionHeader confidence="0.99816">
2.1 Conditional Random Fields
</subsectionHeader>
<bodyText confidence="0.999551">
A conditional random field (CRF) is an undirected
graphical model defined by a tuple (X, Y, F, f, θ).
</bodyText>
<equation confidence="0.697244666666667">
X = (X1, X2, ...) is a set of random variables and
Y = (Y1, Y2, . . .) is a set of output random vari-
ables.2 We use x = (x1, x2,...), to denote a possi-
</equation>
<bodyText confidence="0.989849941176471">
ble assignment of values to X, and similarly for y,
with xy denoting the joint assignment. Each α ∈ F
is a subset of the random variables, α ⊆ X ∪ Y,
and we write xyα to denote the restriction of xy to
α. Finally, for each α ∈ F, the CRF specifies a
function ~fα that extracts a feature vector ∈ Rd from
the restricted assignment xyα. We define the over-
~fα(xyα) ∈ Rd.
where θ~ ∈ Rd is a global weight vector (to be
learned). This is a log-linear model; the denomina-
tor (traditionally denoted Zx) sums over all possible
output assignments to normalize the distribution.
Provided that all probabilities needed at training
or test time are conditioned on an observation of the
form X = x, CRFs can include arbitrary overlap-
ping features of the input without having to explic-
itly model input feature dependencies.
</bodyText>
<footnote confidence="0.767194333333333">
2Stoyanov et al. (2011) distinguished some of the Y vari-
ables as latent (i.e., unsupervised and ignored by the loss func-
tion). We omit this possibility, to simplify the notation.
</footnote>
<bodyText confidence="0.897068">
The model defines conditional probabilities
</bodyText>
<equation confidence="0.9764634">
exp
pθ(y|x) =
Ey, exp
θ~·
~f(x, y)
θ~·
(1)
~f(x, y&apos;)
all feature vector
~f(x, y) = EαEF
</equation>
<page confidence="0.992798">
121
</page>
<subsectionHeader confidence="0.9503">
2.2 Inference in CRFs
</subsectionHeader>
<bodyText confidence="0.999793380952381">
Inference in general CRFs is intractable (Koller and
Friedman, 2009). Nevertheless, there exist several
approximate algorithms that have theoretical moti-
vation and tend to exhibit good performance in prac-
tice. Those include variational methods such as
loopy belief propagation (BP) (Murphy et al., 1999)
and mean-field, as well as Markov Chain Monte
Carlo methods.
ERMA training is applicable to any approxima-
tion that corresponds to a differentiable function,
even if the function has no simple closed form but is
computed by an iterative update algorithm. In this
paper we select BP, which is exact when the fac-
tor graph is a tree, such as a linear-chain CRF, but
whose results can be somewhat distorted by loops
in the factor graph, as in our settings. BP computes
beliefs about the marginal distribution of each ran-
dom variable using iterative updates. We standardly
approximate the posterior CRF marginals given the
input observations by running BP over a CRF that
enforces those observations.
</bodyText>
<subsectionHeader confidence="0.998254">
2.3 Decoding
</subsectionHeader>
<bodyText confidence="0.999958375">
Conditional random fields are models of probabil-
ity. A decoder is a procedure for converting these
probabilities into system outputs. Given x, the de-
coder would ideally choose y to minimize the loss
`(y, y∗), where ` compares a candidate assignment
y to the true assignment y∗. But of course we do not
know the truth at test time. Instead we can average
over possible values y0 of the truth:
</bodyText>
<equation confidence="0.977689">
p(y0  |x) - `(y, y0) (2)
</equation>
<bodyText confidence="0.99998195">
This is the minimum Bayes risk (MBR) principle
from statistical decision theory: choose y to mini-
mize the expected loss (i.e., the risk) according to
the CRF’s posterior beliefs given x.
In the NLP literature, CRFs are often decoded by
choosing y to be the maximum posterior probabil-
ity assignment (e.g., Sha and Pereira (2003), Sutton
et al. (2007)). This is the MBR procedure for the
0-1 loss function that simply tests whether y = y∗.
For other loss functions, however, the corresponding
MBR procedure is preferable. For some loss func-
tions it is tractable given the posterior marginals of
p, while in other cases approximations are needed.
In our experiments we use MBR decoding (or a
tractable approximation) but substitute the approx-
imate posterior marginals of p as computed by BP.
For example, if the loss of y is the number of incor-
rectly recovered output variables, MBR says to sep-
arately pick the most probable value for each output
variable, according to its (approximate) marginal.
</bodyText>
<sectionHeader confidence="0.992707" genericHeader="method">
3 Minimum-Risk CRF Training
</sectionHeader>
<bodyText confidence="0.999449285714286">
This section briefly describes the ERMA training al-
gorithm from Stoyanov et al. (2011) and compares it
to related structured learning methods. We assume
a standard ML setting, with a set of training inputs
xi and corresponding correct outputs yi∗. All the
methods below are regularized in practice, but we
omit mention of regularizers for simplicity.
</bodyText>
<subsectionHeader confidence="0.986199">
3.1 Related Structured Learning Methods
</subsectionHeader>
<bodyText confidence="0.999515333333333">
When inference and decoding can be performed ex-
actly, the CRF parameters θ~ are often trained by
maximum likelihood estimation (MLE):
</bodyText>
<equation confidence="0.991642">
argmax log pθ(yi∗  |xi) (3)
θ i
</equation>
<bodyText confidence="0.999952608695652">
The gradient of each summand log pθ(yi∗  |xi)
can be computed by performing inference in two set-
tings, one with xi, yi∗ observed and one with only
the conditioning events xi observed. The gradient
emerges as the difference between the feature ex-
pectations in the two cases. If exact inference is
intractable, one can compute approximate feature
expectations by loopy BP. Computing the approx-
imate gradient in this way, and training the CRF
with some gradient-based optimization method, has
been shown to work relatively well in practice (Vish-
wanathan et al., 2006; Sutton and McCallum, 2005).
The above method takes into account neither the
loss function that will be used for evaluation, nor
the approximate algorithms that have been selected
for inference and decoding at test time. Other struc-
ture learning methods do consider loss, though it is
not obvious how to make them consider approxima-
tions. Those include maximum margin (Taskar et
al., 2003; Finley and Joachims, 2008) and softmax-
margin (Gimpel and Smith, 2010). The idea of
margin-based methods is to choose weights θ~ so that
the correct alternative yi∗ always gets a better score
</bodyText>
<equation confidence="0.525474">
argmin
Y
</equation>
<page confidence="0.971491">
122
</page>
<bodyText confidence="0.9989334">
than each possible alternative yi E Y. The loss is
incorporated in these methods by requiring the mar-
gin (~θ · ~f(xi, yi*) − θ~ · ~f(xi, yi)) ? `(yi, yi*), with
penalized slack in these constraints. The softmax-
margin method uses a different criterion—it resem-
bles MLE but modifies the denominator of (1) to
Zx = Ey,,, exp(~θ · ~f(x, y&apos;) + `(y&apos;, y*)).
In our experiments we compare against MLE
training (which is common) and softmax-margin,
which incorporates loss and which Gimpel and
Smith (2010) show is either better or competitive
when compared to other margin methods on an NLP
task. We adapt these methods to the loopy case in
the obvious way, by replacing exact inference with
loopy BP and keeping everything else the same.
</bodyText>
<subsectionHeader confidence="0.998267">
3.2 Minimum-Risk Training
</subsectionHeader>
<bodyText confidence="0.9999125">
We wish to consider the approximate inference and
decoding algorithms and the loss function that will
be used during testing. Thus, we want θ to minimize
the expected loss under the true data distribution P:
</bodyText>
<equation confidence="0.485886">
argmin
θ Exy—P [`(δθ(x), y)] (4)
</equation>
<bodyText confidence="0.999920802816901">
where δθ is the decision rule (parameterized by θ),
which decodes the results of inference under pθ.
In practice, we do not know the true data distri-
bution, but we can do empirical risk minimization
(ERM), instead averaging the loss over our sample
of (xi, yi) pairs. ERM for structured prediction was
first introduced in the speech community (Bahl et
al., 1988) and later used in NLP (Och, 2003; Kakade
et al., 2002; Suzuki et al., 2006; Li and Eisner, 2009,
etc.). Previous applications of risk minimization as-
sume exact inference, having defined the hypothe-
sis space by a precomputed n-best list, lattice, or
packed forest over which exact inference is possible.
The ERMA approach (Stoyanov et al., 2011)
works with approximate inference and computes ex-
act gradients of the output loss (or a differentiable
surrogate) in the context of the approximate infer-
ence and decoding algorithms. To determine the gra-
dient of `(δθ(xi), yi) with respect to θ, the method
relies on automatic differentiation in the reverse
mode (Griewank and Corliss, 1991), a general tech-
nique for sensitivity analysis in computations. The
intuition behind automatic differentiation is that the
entire computation is a sequence of elementary dif-
ferentiable operations. For each elementary opera-
tion, given that we know the input and result values,
and the partial derivative of the loss with respect to
the result, we can compute the partial derivative of
the loss with respect to the inputs to the step. Dif-
ferentiating the whole complicated computation can
be carried out in backward pass in this step-by-step
manner as long as we record intermediate results
during the computation of the function (the forward
pass). At the end, we accumulate the partials of the
loss with respect to each parameter θi.
ERMA is similar to back-propagation used in re-
current neural networks, which involve cyclic up-
dates like those in belief propagation (Williams and
Zipser, 1989). It considers an “unrolled” version of
the forward pass, in which “snapshots” of a vari-
able at times t and t + 1 are treated as distinct vari-
ables, with one perhaps influencing the other. The
forward pass computes `(δθ(xi), yi) by performing
approximate inference, then decoding, then evalu-
ation. These steps convert (xi, θ) —* marginals —*
decision —* loss. The backward pass rewinds the en-
tire computation, differentiating each phase in term.
The total time required by this algorithm is roughly
twice the time of the forward pass, so its complexity
is comparable to approximate inference.
In this paper, we do not advocate any particular
test-time inference or decoding procedures. It is rea-
sonable to experiment with several choices that may
produce faster or more accurate systems. We sim-
ply recommend doing ERMA training to match each
selected test-time condition. Stoyanov et al. (2011)
specifically showed how to train a system that will
use sum-product BP for inference at test time (un-
like margin-based methods). This may be advanta-
geous for some tasks because it marginalizes over la-
tent variables. However, it is popular and sometimes
faster to do 1-best decoding, so we also include ex-
periments where the test-time system returns a 1-
best value of y (or an approximation to this if the
CRF is loopy), based on max-product BP inference.
Although 1-best systems are not differentiable func-
tions, we can approach their behavior during ERM
training by annealing the training objective (Smith
and Eisner, 2006). In the annealed case we evaluate
(4) and its gradient under sum-product BP, except
that we perform inference under p(θ/T) instead of pθ.
</bodyText>
<page confidence="0.995282">
123
</page>
<bodyText confidence="0.99993525">
We gradually reduce the temperature T E R from 1
to 0 as training proceeds, which turns sum-product
inference into max-product by moving all the prob-
ability mass toward the highest-scoring assignment.
</bodyText>
<sectionHeader confidence="0.777736" genericHeader="method">
4 Modeling Natural Language with CRFs
</sectionHeader>
<bodyText confidence="0.999982615384615">
This section describes three NLP problems that can
be naturally modeled with approximate CRFs. The
first problem, modeling congressional votes, has not
been previously modeled with a CRF. We show that
by switching to the principled CRF framework we
can learn models that are much more accurate when
evaluated on test data, though using the same (or less
expressive) features as previous work. The other
two problems, information extraction from semi-
structured text and collective multi-label classifica-
tion, have been modeled with loopy CRFs before.
For all three models, we show that ERMA training
results in better test set performance.3
</bodyText>
<subsectionHeader confidence="0.999122">
4.1 Modeling Congressional Votes
</subsectionHeader>
<bodyText confidence="0.996583878378378">
The Congressional Vote (ConVote) corpus was cre-
ated by Thomas et al. (2006) to study whether votes
of U.S. congressional representatives can be pre-
dicted from the speeches they gave when debating
a bill. The corpus consists of transcripts of con-
gressional floor debates split into speech segments.
Each speech segment is labeled with the represen-
tative who is speaking and the recorded vote of that
representative on the bill. We aim to predict a high
percentage of the recorded votes correctly.
Speakers often reference one another (e.g., “I
thank the gentleman from Utah”), to indicate agree-
ment or disagreement. The ConVote corpus manu-
ally annotates each phrase such as “the gentleman
from Utah” with the representative that it denotes.
Thomas et al. (2006) show that classification us-
ing the agreement/disagreement information in the
local context of such references, together with the
rest of the language in the speeches, can lead to sig-
nificant improvement over using either of these two
3We also experimented with a fourth application, joint POS
tagging and shallow parsing (Sutton et al., 2007) and observed
the same overall trend (i.e., minimum risk training improved
performance significantly). We do not include those experi-
ments, however, because we were unable to make our baseline
results replicate (Sutton et al., 2007).
sources of information in isolation. The original ap-
proach of Thomas et al. (2006) is based on training
two Support Vector Machine (SVM) classifiers—
one for classifying speeches as supporting/opposing
the legislation and another for classifying references
as agreement/disagreement. Both classifiers rely on
bag-of-word (unigram) features of the document and
the context surrounding the link respectively. The
scores produced by the two SVMs are used to weight
a global graph whose vertices are the representa-
tives; then the min-cut algorithm is applied to par-
tition the vertices into “yea” and “nay” voters.
While the approach of Thomas et al. (2006)
leads to significant improvement over using the first
SVM alone, it does not admit a probabilistic in-
terpretation and the two classifiers are not trained
jointly. We also remark that the min-cut technique
would not generalize beyond binary random vari-
ables (yea/nay).
We observe that congressional votes together with
references between speakers can be naturally mod-
eled with a CRF. Figure 1 depicts the CRF con-
structed for one of the debates in the development
part of the ConVote corpus. It contains a random
variable for each representative’s vote. In addition,
each speech is an observed input random variable:
it is connected by a factor to its speaker’s vote and
encourages it to be “yea” or “nay” according to fea-
tures of the text of the speech. Finally, each ref-
erence in each speech is an observed input random
variable connected by a factor to two votes—those
of the speaker and the referent—which it encourages
to agree or disagree according to features of the text
surrounding the reference. Just as in (Thomas et al.,
2006), the score of a global assignment to all votes is
defined by considering both kinds of factors. How-
ever, unlike min-cut, CRF inference finds a proba-
bility distribution over assignments, not just a sin-
gle best assignment. This fact allows us to train the
two kinds of factors jointly (on the set of training
debates where the votes are known) to predict the
correct votes accurately (as defined by accuracy).
As Figure 1 shows, the reference factors introduce
arbitrary loops, making exact inference intractable
and thus motivating ERMA. Our experiments de-
scribed in section 5.2 show that switching to a CRF
model (keeping the same features) leads to a sizable
improvement over the previous state of the art—
</bodyText>
<page confidence="0.972868">
124
</page>
<figure confidence="0.9997931875">
O
S
S
S
... ...
S
S
O
Who:
Prof.
Klaus
Sutner
... ...
Prof.
Sutner
will
</figure>
<figureCaption confidence="0.970806888888889">
Figure 1: An example of a debate structure from the Con-
Vote corpus. Each black square node represents a factor
and is connected to the variables in that factor, shown
as round nodes. Unshaded variables correspond to the
representatives’ votes and depict the output variables that
we learn to jointly predict. Shaded variables correspond
to the observed input data— the text of all speeches of a
representative (in dark gray) or all local contexts of refer-
ences between two representatives (in light gray).
</figureCaption>
<bodyText confidence="0.999877">
and that ERMA further significantly improves per-
formance, particularly when it properly trains with
the same inference algorithm (max-product vs. sum-
product) to be used at test time.
Baseline. As an exact baseline, we compare
against the results of Thomas et al. (2006). Their
test-time Min-Cut algorithm is exact in this case: bi-
nary variables and a two-way classification.
</bodyText>
<subsectionHeader confidence="0.9606425">
4.2 Information Extraction from
Semi-Structured Text
</subsectionHeader>
<bodyText confidence="0.999891846153846">
We utilize the CMU seminar announcement corpus
of Freitag (2000) consisting of emails with seminar
announcements. The task is to extract four fields that
describe each seminar: speaker, location, start time
and end time. The corpus annotates the document
with all mentions of these four fields.
Sequential CRFs have been used successfully for
semi-structured information extraction (Sutton and
McCallum, 2005; Finkel et al., 2005). However,
they cannot model non-local dependencies in the
data. For example, in the seminar announcements
corpus, if “Sutner” is mentioned once in an email
in a context that identifies him as a speaker, it is
</bodyText>
<figureCaption confidence="0.9938035">
Figure 2: Skip-chain CRF for semi-structured informa-
tion extraction.
</figureCaption>
<bodyText confidence="0.972912">
likely that other occurrences of “Sutner” in the same
email should be marked as speaker. Hence Finkel et
al. (2005) and Sutton and McCallum (2005) propose
adding non-local edges to a sequential CRF to repre-
sent soft consistency constraints. The model, called
a “skip-chain CRF” and shown in Figure 2, contains
a factor linking each pair of capitalized words with
the same lexical form. The skip-chain CRF model
exhibits better empirical performance than its se-
quential counterpart (Sutton and McCallum, 2005;
Finkel et al., 2005).
The non-local skip links make exact inference
intractable. To train the full model, Finkel et al.
(2005) estimate the parameters of a sequential CRF
and then manually select values for the weights of
the non-local edges. At test time, they use Gibbs
sampling to perform inference. Sutton and McCal-
lum (2005) use max-product loopy belief propaga-
tion for test-time inference, and compare a train-
ing procedure that uses a piecewise approximation
of the partition function against using sum-product
loopy belief propagation to compute output variable
marginals. They find that the two training regimens
perform similarly on the overall task. All of these
training procedures try to approximately maximize
conditional likelihood, whereas we will aim to mini-
mize the empirical loss of the approximate inference
and decoding procedures.
Baseline. As an exact (non-loopy) baseline, we
train a model without the skip chains. We give two
baseline numbers in Table 1—for training the exact
CRF with MLE and with ERM. The ERM setting re-
sulted in a statistically significant improvement even
in the exact case, thanks to the use of the loss func-
tion at training time.
</bodyText>
<subsectionHeader confidence="0.986731">
4.3 Multi-Label Classification
</subsectionHeader>
<bodyText confidence="0.998576666666667">
Multi-label classification is the problem of assign-
ing multiple labels to a document. For example, a
news article can be about both “Libya” and “civil
</bodyText>
<page confidence="0.997319">
125
</page>
<bodyText confidence="0.9994916">
war.” The most straightforward approach to multi-
label classification employs a binary classifier for
each class separately. However, previous work has
shown that incorporating information about label de-
pendencies can lead to improvement in performance
(Elisseeff and Weston, 2001; Ghamrawi and McCal-
lum, 2005; Finley and Joachims, 2008).
For this task we follow Ghamrawi and McCallum
(2005) and Finley and Joachims (2008) and model
the label interactions by constructing a fully con-
nected CRF between the output labels. That is, for
every document, we construct a CRF that contains
a binary random variable for each label (indicating
that the corresponding label is on/off for the doc-
ument) and one binary edge for every unique pair
of labels. This architecture can represent dependen-
cies between labels, but leads to a setting in which
the output variables form one massive clique. The
resulting intractability of inference (and decoding)
motivates the use of ERMA training.
Baseline. We train a model without any of the
pairwise edges (i.e., a separate logistic regression
model for each class). We report the single best
baseline number, since MLE and ERM training re-
sulted in statistically indistinguishable results.
</bodyText>
<sectionHeader confidence="0.999842" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999477">
5.1 Learning Methodology
</subsectionHeader>
<bodyText confidence="0.999978984615385">
For all experiments we split the data into
train/development/test sets using the standard splits
when available. We tune optimization algorithm pa-
rameters (initial learning rate, batch size and meta-
parameters A and p for stochastic meta descent) on
the training set based on training objective conver-
gence rates. We tune the regularization parameter
Q (below) on development data when available, oth-
erwise we use a default value of 0.1—performance
was generally robust for small changes in the value
of Q. All statistical significance testing is performed
using paired permutation tests (Good, 2000).
Gradient-based Optimization. Gradient infor-
mation from the back-propagation procedure can be
used in a local optimization method to minimize em-
pirical loss. In this paper we use stochastic meta
descent (SMD) (Schraudolph, 1999). SMD is a
second-order method that requires vector-Hessian
products. For computing those, we do not need to
maintain the full Hessian matrix. Instead, we apply
more automatic differentiation magic—this time in
the forward mode. Computing the vector-Hessian
product and utilizing it in SMD does not add to the
asymptotic runtime, it requires about twice as many
arithmetic operations, and leads to much faster con-
vergence of the learner in our experience. See Stoy-
anov et al. (2011) for details.
Since the empirical risk objective could overfit
the training data, we add an L2 regularizer Q Ej 02 j
that prefers parameter values close to 0. This im-
proves generalization, like the margin constraints in
margin-based methods.
Training Procedure Stoyanov et al. (2011) ob-
served that the minimum-risk objective tends to be
highly non-convex in practice. The usual approx-
imate log likelihood training objective appeared to
be smoother over the parameter space, but exhibited
global maxima at parameter values that were rela-
tively good, but sub-optimal for other loss functions.
Mean-squared error (MSE) also gave a smoother ob-
jective than other loss functions. These observations
motivated Stoyanov et al. (2011) to use a contin-
uation method. They optimized approximate log-
likelihood for a few iterations to get to a good part of
the parameter space, then switched to using the hy-
brid loss function Af(y, y&apos;)+(1−A)fMSE(y, y&apos;). The
coefficient A changed gradually from 0 to 1 during
training, which morphs from optimizing a smoother
loss to optimizing the desired bumpy test loss. We
follow the same procedure.
Experiments in this paper use two evaluation met-
rics: percentage accuracy and F-measure. For both
of these losses we decode by selecting the most
probable value under the marginal distribution of
each random variable. This is an exact MBR de-
code for accuracy but an approximate one for the
F-measure; our ERMA training will try to compen-
sate for this approximate decoder. This decoding
procedure is not differentiable due to the use of the
argmax function. To make the decoder differen-
tiable, we replace argmax with a stochastic (soft-
max) version during training, averaging loss over all
possible values v in proportion to their exponenti-
ated probability p(yz = v  |x)&apos;/Tdecode. This de-
coder loses smoothness and approaches an argmax
</bodyText>
<page confidence="0.993275">
126
</page>
<figure confidence="0.960567461538461">
Problem
Loss function
Non-loopy Baseline
Congressional Vote
Accuracy
71.2
Semi-structured IE
Token-wise F-score
86.2 (87.1)
Multi-label class.
F-score
81.6
Loopy CRF models INFERENCE:
</figure>
<table confidence="0.989990142857143">
TRAINING: maxprod sumprod maxprod sumprod maxprod sumprod
MLE 78.2 78.2 89.0 89.5 84.2 84.0
Softmax-margin 79.0 79.0 90.1 90.2 84.3 83.8
85.1 90.9 84.5
Min-risk (maxprod) 80.1 90.7 84.4
84.5 90.9 84.6
Min-risk (sumprod) 83.6 90.3 84.7
</table>
<tableCaption confidence="0.987567333333333">
Table 1: Results. The top of the table lists the loss function used for each problem and the score for the best exact
baseline. The bottom lists results for the full models used with loopy BP. Models are tested with either sum-product
BP (sumprod) or max-product BP (maxprod) and trained with MLE or the minimum risk criterion. Min-risk training
runs are either annealed (maxprod), which matches max-product test, or not (sumprod), which matches sum-product
test; grey cells in the table indicate matched training and test settings. In each column, we boldface the best result as
well as all results that are not significantly worse (paired permutation test, p &lt; 0.05).
</tableCaption>
<bodyText confidence="0.9997838">
decoder as Tdecode decreases toward 0. For simplic-
ity, our experiments just use a single fixed value of
0.1 for Tdecode. Annealing the decoder slowly did not
lead to significant differences in early experiments
on development data.
</bodyText>
<subsectionHeader confidence="0.9357">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999930729166667">
Table 1 lists results of our evaluation. For all three
of our problems, using approximate CRFs results
in statistically significant improvement over the ex-
act baselines, for any of the training procedures.
But among the training procedures for approximate
CRFs, our ERMA procedure—minimizing empiri-
cal risk with the training setting matched to the test
setting—improves over the two baselines, namely
MLE and softmax-margin. MLE and softmax-
margin training were statistically indistinguishable
in our experiments with the exception of semi-
structured IE. ERMA’s improvements over them are
statistically significant at the p &lt; .05 level for the
Congressional Vote and Semi-Structured IE prob-
lems and at the p &lt; .1 level for the Multi-label clas-
sification problem (comparing each matched min-
risk setting shown in a gray cell in Table 1 vs. MLE).
When minimizing risk, we also observe that
matching training and test-time procedures can re-
sult in improved performance in one of the three
problems, Congressional Vote. For this problem, the
matched training condition performs better than the
alternatives (accuracy of 85.1 vs. 83.6 for the an-
nealed max-product testing and 84.5 vs 80.1 for the
sum-product setting), significant at p &lt; .01). We
observe the same effect for semi-structured IE when
testing using max-product inference. For the other
remaining three problem setting training with either
minimal risk training regiment.
Finally, we hypothesized that sum-product infer-
ence may produce more accurate results in certain
cases as it allows more information about differ-
ent parts of the model to be exchanged. How-
ever, our results show that for these three problems,
sum-product and max-product inference yield statis-
tically indistinguishable results. This may be be-
cause the particular CRFs we used included no la-
tent variables (in constrast to the synthetic CRFs
in Stoyanov et al. (2011)). As expected, we found
that max-product BP converges in fewer iterations—
sum-product BP required as many as twice the num-
ber of iterations for some of the runs.
Results in this paper represent a new state-of-the-
art for the first two of the problems, Congressional
Vote and Semi-structured IE. For Multi-Label classi-
fication, comparing against the SVM-based method
of Finley and Joachims (2008) goes beyond the
scope of this paper.
</bodyText>
<sectionHeader confidence="0.999701" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9231996">
Minimum-risk training has been used in speech
recognition (Bahl et al., 1988), machine translation
(Och, 2003), and energy-based models generally
(LeCun et al., 2006). In graphical models, methods
have been proposed to directly minimize loss in tree-
</bodyText>
<page confidence="0.991881">
127
</page>
<bodyText confidence="0.978975857142857">
shaped or linear chain MRFs and CRFs (Kakade et
al., 2002; Suzuki et al., 2006; Gross et al., 2007).
All of the above focus on exact inference. Our
approach can be seen as generalizing these methods
to arbitrary graph structures, arbitrary loss functions
and approximate inference.
Lacoste-Julien et al. (2011) also consider the ef-
fects of approximate inference on loss. However,
they assume the parameters are given, and modify
the approximate inference algorithm at test time to
consider the loss function.
Using empirical risk minimization to train graph-
ical models was independently proposed by Domke
(2010; 2011). Just as in our own paper (Stoy-
anov et al., 2011), Domke took a decision-theoretic
stance and proposed ERM as a way of calibrating
the graphical model for use with approximate infer-
ence, or for use with data that do not quite match the
modeling assumptions.4
In particular, (Domke, 2011) is similar to (Stoy-
anov et al., 2011) in using ERMA to train model pa-
rameters to be used with “truncated” inference that
will be run for only a fixed number of iterations. For
a common pixel-labeling benchmark in computer vi-
sion, Domke (2011) shows that this procedure im-
proves training time by orders of magnitude, and
slightly improves accuracy if the same number of
message-passing iterations is used at test time.
Stoyanov and Eisner (2011) extend the ERMA
objective function by adding an explicit runtime
term. This allows them to tune model parameters
and stopping criteria to learn models that obtain a
given speed-accuracy tradeoff. Their approach im-
proves this hybrid objective over a range of coeffi-
cients when compared to the traditional way of in-
ducing sparse structures through Li regularization.
Eisner and Daum´e III (2011) propose the same lin-
ear combination of speed and accuracy as a rein-
forcement learning objective. In general, our pro-
posed ERMA setting resembles the reinforcement
learning problem of trying to directly learn a policy
that minimizes loss or maximizes reward.
We have been concerned with the fact that ERMA
training objectives may suffer from local optima and
non-differentiability. Stoyanov et al. (2011) studied
4However, he is less focused than we are on matching train-
ing conditions to test conditions (by including the decoder and
task loss in the ERMA objective).
several such settings, graphed the difficult objective,
and identified some practical workarounds that are
used in the present paper. Although these methods
have enabled us to get strong results by reducing the
empirical risk, we suspect that ERMA training ob-
jectives will benefit from more sophisticated opti-
mization methods. This is true even when the ap-
proximate inference itself is restricted to be some-
thing as simple as a convex minimization. While
that simplified setting can make it slightly more con-
venient to compute the gradient of the inference re-
sult with respect to the parameters (Domke, 2008;
Domke, 2012), there is still no guarantee that follow-
ing that gradient will minimize the empirical risk.
Convex inference does not imply convex training.
</bodyText>
<sectionHeader confidence="0.999573" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999975454545455">
Motivated by the recently proposed method of Stoy-
anov et al. (2011) for minimum-risk training of
CRF-based systems, we revisited three NLP do-
mains that can naturally be modeled with approx-
imate CRF-based systems. These include appli-
cations that have not been modeled with CRFs
before (the ConVote corpus), as well as applica-
tions that have been modeled with loopy CRFs
trained to minimize the approximate log-likelihood
(semi-structured information extraction and collec-
tive multi-label classification). We show that (i)
the NLP models are improved by moving to richer
CRFs that require approximate inference, and (ii)
empirical performance is always significantly im-
proved by training to reduce the loss that would be
achieved by approximate inference, even compared
to another state-of-the-art training method (softmax-
margin) that also considers loss and uses approxi-
mate inference. The general software package that
implements the algorithms in this paper is avail-
able at http://www.clsp.jhu.edu/˜ves/
software.html.
</bodyText>
<sectionHeader confidence="0.998432" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.86569575">
This material is based upon work supported by the
National Science Foundation under Grant #0937060
to the Computing Research Association for the
CIFellows Project.
</bodyText>
<page confidence="0.997367">
128
</page>
<sectionHeader confidence="0.990107" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999854461538461">
L. Bahl, P. Brown, P. de Souza, and R. Mercer. 1988.
A new algorithm for the estimation of hidden Markov
model parameters. In Proceedings of ICASSP, pages
493–496.
E. Benson, A. Haghighi, and R. Barzilay. 2011. Event
discovery in social media feeds. In Proceedings of
ACL-HLT, pages 389–398.
Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan. 2005.
Identifying sources of opinions with conditional ran-
dom fields and extraction patterns. In Proceedings of
HLT/EMNLP, pages 355–362.
J. Domke. 2008. Learning convex inference of
marginals. In Proceedings of UAI.
J. Domke. 2010. Implicit differentiation by perturba-
tion. In Advances in Neural Information Processing
Systems, pages 523–531.
J. Domke. 2011. Parameter learning with truncated
message-passing. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition
(CVPR).
J. Domke. 2012. Generic methods for optimization-
based modeling. In Proceedings of AISTATS.
M. Dreyer and J. Eisner. 2009. Graphical models over
multiple strings. In Proceedings of EMNLP, pages
101–110.
J. Eisner and Hal Daum´e III. 2011. Learning speed-
accuracy tradeoffs in nondeterministic inference al-
gorithms. In COST: NIPS 2011 Workshop on Com-
putational Trade-offs in Statistical Learning, Sierra
Nevada, Spain, December.
A. Elisseeff and J. Weston. 2001. Kernel methods for
multi-labelled classification and categorical regression
problems. In Advances in Neural Information Pro-
cessing Systems, pages 681–687.
J.R. Finkel, T. Grenager, and C. Manning. 2005. In-
corporating non-local information into information ex-
traction systems by Gibbs sampling. In Proceedings of
ACL, pages 363–370.
T. Finley and T. Joachims. 2008. Training structural
SVMs when exact inference is intractable. In Proceed-
ings of ICML, pages 304–311.
D. Freitag. 2000. Machine learning for information
extraction in informal domains. Machine learning,
39(2).
N. Ghamrawi and A. McCallum. 2005. Collective multi-
label classification. In Proceedings of CIKM, pages
195–200.
K. Gimpel and N.A. Smith. 2010. Softmax-margin
CRFs: Training log-linear models with cost functions.
In Proceedings of ACL, pages 733–736.
P. I. Good. 2000. Permutation Tests. Springer.
A. Griewank and G. Corliss, editors. 1991. Automatic
Differentiation of Algorithms. SIAM, Philadelphia.
S. Gross, O. Russakovsky, C. Do, and S. Batzoglou.
2007. Training conditional random fields for maxi-
mum labelwise accuracy. Advances in Neural Infor-
mation Processing Systems, 19:529.
H. Ji and R. Grishman. 2011. Knowledge base popula-
tion: Successful approaches and challenges. In Pro-
ceedings of ACL-HLT, pages 1148–1158.
S. Kakade, Y.W. Teh, and S. Roweis. 2002. An alternate
objective function for Markovian fields. In Proceed-
ings of ICML, pages 275–282.
D. Koller and N. Friedman. 2009. Probabilistic Graph-
ical Models: Principles and Techniques. The MIT
Press.
A. Kulesza and F. Pereira. 2008. Structured learning
with approximate inference. In Advances in Neural
Information Processing Systems, pages 785–792.
S. Lacoste-Julien, F. Huszr, and Z. Ghahramani.
2011. Approximate inference for the loss-calibrated
Bayesian. In Proceedings of AISTATS.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proceedings
of ICML, pages 282–289.
Y. LeCun, S. Chopra, R. Hadsell, M.A. Ranzato, and F.-
J. Huang. 2006. A tutorial on energy-based learning.
In G. Bakir, T. Hofman, B. Schlkopf, A. Smola, and
B. Taskar, editors, Predicting Structured Data. MIT
Press.
Z. Li and J. Eisner. 2009. First- and second-order
expectation semirings with applications to minimum-
risk training on translation forests. In Proceedings of
EMNLP, pages 40–51.
K. P. Murphy, Y. Weiss, and M. I. Jordan. 1999. Loopy
belief propagation for approximate inference: An em-
pirical study. In Proceedings of UAI.
F. Och. 2003. Minimum error rate training in statisti-
cal machine translation. In Proceedings ofACL, pages
160–167.
F. Peng and A. McCallum. 2006. Information extraction
from research papers using conditional random fields.
Information Processing &amp; Management, 42(4):963–
979.
N.N. Schraudolph. 1999. Local gain adaptation in
stochastic gradient descent. In Proceedings of ANN,
pages 569–574.
F. Sha and F. Pereira. 2003. Shallow parsing with con-
ditional random fields. In Proceedings of ACL/HLT,
pages 134–141.
D.A. Smith and J. Eisner. 2006. Minimum risk annealing
for training log-linear models. In Proceedings of the
COLING/ACL, pages 787–794.
</reference>
<page confidence="0.98337">
129
</page>
<reference confidence="0.999912975609756">
D. Smith and J. Eisner. 2008. Dependency parsing by
belief propagation. In Proceedings of EMNLP, pages
145–156.
V. Stoyanov and J. Eisner. 2011. Learning cost-aware,
loss-aware approximate inference policies for proba-
bilistic graphical models. In COST: NIPS 2011 Work-
shop on Computational Trade-offs in Statistical Learn-
ing, Sierra Nevada, Spain, December.
V. Stoyanov, A. Ropson, and J. Eisner. 2011. Empirical
risk minimization of graphical model parameters given
approximate inference, decoding, and model structure.
In Proceedings of AISTATS.
C. Sutton and A. McCallum. 2005. Piecewise training
of undirected models. In Proceedings of UAI, pages
568–575.
C. Sutton, A. McCallum, and K. Rohanimanesh. 2007.
Dynamic conditional random fields: Factorized proba-
bilistic models for labeling and segmenting sequence
data. The Journal of Machine Learning Research,
8:693–723.
J. Suzuki, E. McDermott, and H. Isozaki. 2006. Train-
ing conditional random fields with multivariate eval-
uation measures. In Proceedings of COLING/ACL,
pages 217–224.
B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin
Markov networks. Proceedings of NIPS, pages 25–32.
M. Thomas, B. Pang, and L. Lee. 2006. Get out the vote:
Determining support or opposition from congressional
floor-debate transcripts. In Proceedings of EMNLP,
pages 327–335.
S. Vishwanathan, N. Schraudolph, M. Schmidt, and
K. Murphy. 2006. Accelerated training of conditional
random fields with stochastic gradient methods. In
Proceedings of ICML, pages 969–976.
M. Wainwright. 2006. Estimating the “wrong” graphi-
cal model: Benefits in the computation-limited setting.
Journal of Machine Learning Research, 7:1829–1859,
September.
R.J. Williams and D. Zipser. 1989. A learning algo-
rithm for continually running fully recurrent neural
networks. Neural Computation, 1(2):270–280.
</reference>
<page confidence="0.997617">
130
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.527995">
<title confidence="0.917750333333333">Minimum-Risk Training of Approximate CRF-Based NLP Systems Stoyanov HLTCOE and Center for Language and Speech</title>
<author confidence="0.726783">Johns Hopkins</author>
<address confidence="0.800695">Baltimore, MD</address>
<abstract confidence="0.999014333333333">Conditional Random Fields (CRFs) are a popular formalism for structured prediction in NLP. It is well known how to train CRFs with certain topologies that admit exact inference, such as linear-chain CRFs. Some NLP phenomena, however, suggest CRFs with more complex topologies. Should such models be used, considering that they make exact inference intractable? Stoyanov et al. (2011) recently argued for training parameters to minthe task-specific loss of whatever apand decoding methods will be used at test time. We apply their method to three NLP problems, showing that (i) using more complex CRFs leads to improved performance, and that (ii) minimumrisk training learns more accurate models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Bahl</author>
<author>P Brown</author>
<author>P de Souza</author>
<author>R Mercer</author>
</authors>
<title>A new algorithm for the estimation of hidden Markov model parameters.</title>
<date>1988</date>
<booktitle>In Proceedings of ICASSP,</booktitle>
<pages>493--496</pages>
<marker>Bahl, Brown, de Souza, Mercer, 1988</marker>
<rawString>L. Bahl, P. Brown, P. de Souza, and R. Mercer. 1988. A new algorithm for the estimation of hidden Markov model parameters. In Proceedings of ICASSP, pages 493–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Benson</author>
<author>A Haghighi</author>
<author>R Barzilay</author>
</authors>
<title>Event discovery in social media feeds.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<pages>389--398</pages>
<contexts>
<context position="4221" citStr="Benson et al., 2011" startWordPosition="645" endWordPosition="648">12. c�2012 Association for Computational Linguistics compared to approximate maximum likelihood estimation (MLE). However, this method has not been evaluated on real-world problems until now. We will refer to the Stoyanov et al. (2011) approach as “ERMA”—Empirical Risk Minimization under Approximations. ERMA is attractive for NLP because the freedom to use arbitrarily structured graphical models makes it possible to include latent linguistic variables, predict complex structures such as parses (Smith and Eisner, 2008), and do collective prediction in relational domains (Ji and Grishman, 2011; Benson et al., 2011; Dreyer and Eisner, 2009). In training, ERMA considers not only the approximation method but also the task-specific loss function. This means that ERMA is careful to use the additional variables and dependencies only in ways that help training set performance. (Overfitting on the enlarged parameter set should be avoided through regularization.) We have developed a simple syntax for specifying CRFs with complex structures, and a software package (available from http://www.clsp. jhu.edu/˜ves/software.html) that allows ERMA training of these CRFs for several popular loss functions (e.g., accurac</context>
</contexts>
<marker>Benson, Haghighi, Barzilay, 2011</marker>
<rawString>E. Benson, A. Haghighi, and R. Barzilay. 2011. Event discovery in social media feeds. In Proceedings of ACL-HLT, pages 389–398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>C Cardie</author>
<author>E Riloff</author>
<author>S Patwardhan</author>
</authors>
<title>Identifying sources of opinions with conditional random fields and extraction patterns.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP,</booktitle>
<pages>355--362</pages>
<contexts>
<context position="1341" citStr="Choi et al., 2005" startWordPosition="205" endWordPosition="208">coding methods will be used at test time. We apply their method to three NLP problems, showing that (i) using more complex CRFs leads to improved performance, and that (ii) minimumrisk training learns more accurate models. 1 Introduction Conditional Random Fields (CRFs) (Lafferty et al., 2001) are often used to model dependencies among linguistic variables. CRF-based models have improved the state of the art in a number of natural language processing (NLP) tasks ranging from partof-speech tagging to information extraction and sentiment analysis (Lafferty et al., 2001; Peng and McCallum, 2006; Choi et al., 2005). Robust and theoretically sound training procedures have been developed for CRFs when the model can be used with exact inference and decoding.1 However, some NLP problems seem to 1“Inference” typically refers to computing posterior marginal or max-marginal probability distributions of output random variables, given some evidence. “Decoding” derives a single structured output from the results of inference. call for higher-treewidth graphical models in which exact inference is expensive or intractable. These “loopy” CRFs have cyclic connections among the output and/or latent variables. Alas, st</context>
</contexts>
<marker>Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan. 2005. Identifying sources of opinions with conditional random fields and extraction patterns. In Proceedings of HLT/EMNLP, pages 355–362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Domke</author>
</authors>
<title>Learning convex inference of marginals.</title>
<date>2008</date>
<booktitle>In Proceedings of UAI.</booktitle>
<contexts>
<context position="36333" citStr="Domke, 2008" startWordPosition="5840" endWordPosition="5841">e). several such settings, graphed the difficult objective, and identified some practical workarounds that are used in the present paper. Although these methods have enabled us to get strong results by reducing the empirical risk, we suspect that ERMA training objectives will benefit from more sophisticated optimization methods. This is true even when the approximate inference itself is restricted to be something as simple as a convex minimization. While that simplified setting can make it slightly more convenient to compute the gradient of the inference result with respect to the parameters (Domke, 2008; Domke, 2012), there is still no guarantee that following that gradient will minimize the empirical risk. Convex inference does not imply convex training. 7 Conclusions Motivated by the recently proposed method of Stoyanov et al. (2011) for minimum-risk training of CRF-based systems, we revisited three NLP domains that can naturally be modeled with approximate CRF-based systems. These include applications that have not been modeled with CRFs before (the ConVote corpus), as well as applications that have been modeled with loopy CRFs trained to minimize the approximate log-likelihood (semi-stru</context>
</contexts>
<marker>Domke, 2008</marker>
<rawString>J. Domke. 2008. Learning convex inference of marginals. In Proceedings of UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Domke</author>
</authors>
<title>Implicit differentiation by perturbation.</title>
<date>2010</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>523--531</pages>
<contexts>
<context position="34023" citStr="Domke (2010" startWordPosition="5462" endWordPosition="5463"> shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Using empirical risk minimization to train graphical models was independently proposed by Domke (2010; 2011). Just as in our own paper (Stoyanov et al., 2011), Domke took a decision-theoretic stance and proposed ERM as a way of calibrating the graphical model for use with approximate inference, or for use with data that do not quite match the modeling assumptions.4 In particular, (Domke, 2011) is similar to (Stoyanov et al., 2011) in using ERMA to train model parameters to be used with “truncated” inference that will be run for only a fixed number of iterations. For a common pixel-labeling benchmark in computer vision, Domke (2011) shows that this procedure improves training time by orders of</context>
</contexts>
<marker>Domke, 2010</marker>
<rawString>J. Domke. 2010. Implicit differentiation by perturbation. In Advances in Neural Information Processing Systems, pages 523–531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Domke</author>
</authors>
<title>Parameter learning with truncated message-passing.</title>
<date>2011</date>
<booktitle>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</booktitle>
<contexts>
<context position="34318" citStr="Domke, 2011" startWordPosition="5513" endWordPosition="5514">ien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Using empirical risk minimization to train graphical models was independently proposed by Domke (2010; 2011). Just as in our own paper (Stoyanov et al., 2011), Domke took a decision-theoretic stance and proposed ERM as a way of calibrating the graphical model for use with approximate inference, or for use with data that do not quite match the modeling assumptions.4 In particular, (Domke, 2011) is similar to (Stoyanov et al., 2011) in using ERMA to train model parameters to be used with “truncated” inference that will be run for only a fixed number of iterations. For a common pixel-labeling benchmark in computer vision, Domke (2011) shows that this procedure improves training time by orders of magnitude, and slightly improves accuracy if the same number of message-passing iterations is used at test time. Stoyanov and Eisner (2011) extend the ERMA objective function by adding an explicit runtime term. This allows them to tune model parameters and stopping criteria to learn models tha</context>
</contexts>
<marker>Domke, 2011</marker>
<rawString>J. Domke. 2011. Parameter learning with truncated message-passing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Domke</author>
</authors>
<title>Generic methods for optimizationbased modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of AISTATS.</booktitle>
<contexts>
<context position="36347" citStr="Domke, 2012" startWordPosition="5842" endWordPosition="5843">uch settings, graphed the difficult objective, and identified some practical workarounds that are used in the present paper. Although these methods have enabled us to get strong results by reducing the empirical risk, we suspect that ERMA training objectives will benefit from more sophisticated optimization methods. This is true even when the approximate inference itself is restricted to be something as simple as a convex minimization. While that simplified setting can make it slightly more convenient to compute the gradient of the inference result with respect to the parameters (Domke, 2008; Domke, 2012), there is still no guarantee that following that gradient will minimize the empirical risk. Convex inference does not imply convex training. 7 Conclusions Motivated by the recently proposed method of Stoyanov et al. (2011) for minimum-risk training of CRF-based systems, we revisited three NLP domains that can naturally be modeled with approximate CRF-based systems. These include applications that have not been modeled with CRFs before (the ConVote corpus), as well as applications that have been modeled with loopy CRFs trained to minimize the approximate log-likelihood (semi-structured informa</context>
</contexts>
<marker>Domke, 2012</marker>
<rawString>J. Domke. 2012. Generic methods for optimizationbased modeling. In Proceedings of AISTATS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dreyer</author>
<author>J Eisner</author>
</authors>
<title>Graphical models over multiple strings.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>101--110</pages>
<contexts>
<context position="4247" citStr="Dreyer and Eisner, 2009" startWordPosition="649" endWordPosition="653">n for Computational Linguistics compared to approximate maximum likelihood estimation (MLE). However, this method has not been evaluated on real-world problems until now. We will refer to the Stoyanov et al. (2011) approach as “ERMA”—Empirical Risk Minimization under Approximations. ERMA is attractive for NLP because the freedom to use arbitrarily structured graphical models makes it possible to include latent linguistic variables, predict complex structures such as parses (Smith and Eisner, 2008), and do collective prediction in relational domains (Ji and Grishman, 2011; Benson et al., 2011; Dreyer and Eisner, 2009). In training, ERMA considers not only the approximation method but also the task-specific loss function. This means that ERMA is careful to use the additional variables and dependencies only in ways that help training set performance. (Overfitting on the enlarged parameter set should be avoided through regularization.) We have developed a simple syntax for specifying CRFs with complex structures, and a software package (available from http://www.clsp. jhu.edu/˜ves/software.html) that allows ERMA training of these CRFs for several popular loss functions (e.g., accuracy, mean-squared error, F-m</context>
</contexts>
<marker>Dreyer, Eisner, 2009</marker>
<rawString>M. Dreyer and J. Eisner. 2009. Graphical models over multiple strings. In Proceedings of EMNLP, pages 101–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
<author>Hal Daum´e</author>
</authors>
<title>Learning speedaccuracy tradeoffs in nondeterministic inference algorithms.</title>
<date>2011</date>
<booktitle>In COST: NIPS 2011 Workshop on Computational Trade-offs in Statistical Learning,</booktitle>
<location>Sierra Nevada, Spain,</location>
<marker>Eisner, Daum´e, 2011</marker>
<rawString>J. Eisner and Hal Daum´e III. 2011. Learning speedaccuracy tradeoffs in nondeterministic inference algorithms. In COST: NIPS 2011 Workshop on Computational Trade-offs in Statistical Learning, Sierra Nevada, Spain, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Elisseeff</author>
<author>J Weston</author>
</authors>
<title>Kernel methods for multi-labelled classification and categorical regression problems.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>681--687</pages>
<contexts>
<context position="25335" citStr="Elisseeff and Weston, 2001" startWordPosition="4090" endWordPosition="4093">d with ERM. The ERM setting resulted in a statistically significant improvement even in the exact case, thanks to the use of the loss function at training time. 4.3 Multi-Label Classification Multi-label classification is the problem of assigning multiple labels to a document. For example, a news article can be about both “Libya” and “civil 125 war.” The most straightforward approach to multilabel classification employs a binary classifier for each class separately. However, previous work has shown that incorporating information about label dependencies can lead to improvement in performance (Elisseeff and Weston, 2001; Ghamrawi and McCallum, 2005; Finley and Joachims, 2008). For this task we follow Ghamrawi and McCallum (2005) and Finley and Joachims (2008) and model the label interactions by constructing a fully connected CRF between the output labels. That is, for every document, we construct a CRF that contains a binary random variable for each label (indicating that the corresponding label is on/off for the document) and one binary edge for every unique pair of labels. This architecture can represent dependencies between labels, but leads to a setting in which the output variables form one massive cliq</context>
</contexts>
<marker>Elisseeff, Weston, 2001</marker>
<rawString>A. Elisseeff and J. Weston. 2001. Kernel methods for multi-labelled classification and categorical regression problems. In Advances in Neural Information Processing Systems, pages 681–687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Finkel</author>
<author>T Grenager</author>
<author>C Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="5868" citStr="Finkel et al., 2005" startWordPosition="892" endWordPosition="895">at ERMA training represents an improvement over previous learning methods. The first application, predicting congressional votes, has not been previously modeled with CRFs. By using a more principled probabilistic approach, we are able to improve the state-of-the-art accuracy from 71.2% to 78.2% when training to maximize the approximate log-likelihood of the training data. By switching to ERMA training, we improve this result further to 85.1%. The second application, information extraction from seminar announcements, has been modeled previously with skip-chain CRFs (Sutton and McCallum, 2005; Finkel et al., 2005). The skip-chain CRF introduces loops and requires approximate inference, which motivates minimum risk training. Our results show that ERMA training improves Fmeasures from 89.5 to 90.9 (compared to 87.1 for the model without skip-chains). Finally, for our third application, we perform collective multi-label text classification. We follow previous work (Ghamrawi and McCallum, 2005; Finley and Joachims, 2008) and use a fully connected CRF to model all pairwise dependencies between labels. We observe similar trends for this task: switching from a maximum entropy model that does not model label d</context>
<context position="22905" citStr="Finkel et al., 2005" startWordPosition="3708" endWordPosition="3711">results of Thomas et al. (2006). Their test-time Min-Cut algorithm is exact in this case: binary variables and a two-way classification. 4.2 Information Extraction from Semi-Structured Text We utilize the CMU seminar announcement corpus of Freitag (2000) consisting of emails with seminar announcements. The task is to extract four fields that describe each seminar: speaker, location, start time and end time. The corpus annotates the document with all mentions of these four fields. Sequential CRFs have been used successfully for semi-structured information extraction (Sutton and McCallum, 2005; Finkel et al., 2005). However, they cannot model non-local dependencies in the data. For example, in the seminar announcements corpus, if “Sutner” is mentioned once in an email in a context that identifies him as a speaker, it is Figure 2: Skip-chain CRF for semi-structured information extraction. likely that other occurrences of “Sutner” in the same email should be marked as speaker. Hence Finkel et al. (2005) and Sutton and McCallum (2005) propose adding non-local edges to a sequential CRF to represent soft consistency constraints. The model, called a “skip-chain CRF” and shown in Figure 2, contains a factor li</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>J.R. Finkel, T. Grenager, and C. Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of ACL, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Finley</author>
<author>T Joachims</author>
</authors>
<title>Training structural SVMs when exact inference is intractable.</title>
<date>2008</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>304--311</pages>
<contexts>
<context position="6279" citStr="Finley and Joachims, 2008" startWordPosition="953" endWordPosition="956">, we improve this result further to 85.1%. The second application, information extraction from seminar announcements, has been modeled previously with skip-chain CRFs (Sutton and McCallum, 2005; Finkel et al., 2005). The skip-chain CRF introduces loops and requires approximate inference, which motivates minimum risk training. Our results show that ERMA training improves Fmeasures from 89.5 to 90.9 (compared to 87.1 for the model without skip-chains). Finally, for our third application, we perform collective multi-label text classification. We follow previous work (Ghamrawi and McCallum, 2005; Finley and Joachims, 2008) and use a fully connected CRF to model all pairwise dependencies between labels. We observe similar trends for this task: switching from a maximum entropy model that does not model label dependencies to a loopy CRF leads to an improvement in F-measure from 81.6 to 84.0, and using ERMA leads to additional improvement (84.7). 2 Preliminaries 2.1 Conditional Random Fields A conditional random field (CRF) is an undirected graphical model defined by a tuple (X, Y, F, f, θ). X = (X1, X2, ...) is a set of random variables and Y = (Y1, Y2, . . .) is a set of output random variables.2 We use x = (x1, </context>
<context position="12038" citStr="Finley and Joachims, 2008" startWordPosition="1935" endWordPosition="1938">ons by loopy BP. Computing the approximate gradient in this way, and training the CRF with some gradient-based optimization method, has been shown to work relatively well in practice (Vishwanathan et al., 2006; Sutton and McCallum, 2005). The above method takes into account neither the loss function that will be used for evaluation, nor the approximate algorithms that have been selected for inference and decoding at test time. Other structure learning methods do consider loss, though it is not obvious how to make them consider approximations. Those include maximum margin (Taskar et al., 2003; Finley and Joachims, 2008) and softmaxmargin (Gimpel and Smith, 2010). The idea of margin-based methods is to choose weights θ~ so that the correct alternative yi∗ always gets a better score argmin Y 122 than each possible alternative yi E Y. The loss is incorporated in these methods by requiring the margin (~θ · ~f(xi, yi*) − θ~ · ~f(xi, yi)) ? `(yi, yi*), with penalized slack in these constraints. The softmaxmargin method uses a different criterion—it resembles MLE but modifies the denominator of (1) to Zx = Ey,,, exp(~θ · ~f(x, y&apos;) + `(y&apos;, y*)). In our experiments we compare against MLE training (which is common) an</context>
<context position="25392" citStr="Finley and Joachims, 2008" startWordPosition="4099" endWordPosition="4102">ignificant improvement even in the exact case, thanks to the use of the loss function at training time. 4.3 Multi-Label Classification Multi-label classification is the problem of assigning multiple labels to a document. For example, a news article can be about both “Libya” and “civil 125 war.” The most straightforward approach to multilabel classification employs a binary classifier for each class separately. However, previous work has shown that incorporating information about label dependencies can lead to improvement in performance (Elisseeff and Weston, 2001; Ghamrawi and McCallum, 2005; Finley and Joachims, 2008). For this task we follow Ghamrawi and McCallum (2005) and Finley and Joachims (2008) and model the label interactions by constructing a fully connected CRF between the output labels. That is, for every document, we construct a CRF that contains a binary random variable for each label (indicating that the corresponding label is on/off for the document) and one binary edge for every unique pair of labels. This architecture can represent dependencies between labels, but leads to a setting in which the output variables form one massive clique. The resulting intractability of inference (and decodi</context>
<context position="33107" citStr="Finley and Joachims (2008)" startWordPosition="5316" endWordPosition="5319">blems, sum-product and max-product inference yield statistically indistinguishable results. This may be because the particular CRFs we used included no latent variables (in constrast to the synthetic CRFs in Stoyanov et al. (2011)). As expected, we found that max-product BP converges in fewer iterations— sum-product BP required as many as twice the number of iterations for some of the runs. Results in this paper represent a new state-of-theart for the first two of the problems, Congressional Vote and Semi-structured IE. For Multi-Label classification, comparing against the SVM-based method of Finley and Joachims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCun et al., 2006). In graphical models, methods have been proposed to directly minimize loss in tree127 shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Juli</context>
</contexts>
<marker>Finley, Joachims, 2008</marker>
<rawString>T. Finley and T. Joachims. 2008. Training structural SVMs when exact inference is intractable. In Proceedings of ICML, pages 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Freitag</author>
</authors>
<title>Machine learning for information extraction in informal domains.</title>
<date>2000</date>
<booktitle>Machine learning,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="22539" citStr="Freitag (2000)" startWordPosition="3656" endWordPosition="3657">eches of a representative (in dark gray) or all local contexts of references between two representatives (in light gray). and that ERMA further significantly improves performance, particularly when it properly trains with the same inference algorithm (max-product vs. sumproduct) to be used at test time. Baseline. As an exact baseline, we compare against the results of Thomas et al. (2006). Their test-time Min-Cut algorithm is exact in this case: binary variables and a two-way classification. 4.2 Information Extraction from Semi-Structured Text We utilize the CMU seminar announcement corpus of Freitag (2000) consisting of emails with seminar announcements. The task is to extract four fields that describe each seminar: speaker, location, start time and end time. The corpus annotates the document with all mentions of these four fields. Sequential CRFs have been used successfully for semi-structured information extraction (Sutton and McCallum, 2005; Finkel et al., 2005). However, they cannot model non-local dependencies in the data. For example, in the seminar announcements corpus, if “Sutner” is mentioned once in an email in a context that identifies him as a speaker, it is Figure 2: Skip-chain CRF</context>
</contexts>
<marker>Freitag, 2000</marker>
<rawString>D. Freitag. 2000. Machine learning for information extraction in informal domains. Machine learning, 39(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ghamrawi</author>
<author>A McCallum</author>
</authors>
<title>Collective multilabel classification.</title>
<date>2005</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>195--200</pages>
<contexts>
<context position="6251" citStr="Ghamrawi and McCallum, 2005" startWordPosition="949" endWordPosition="952">By switching to ERMA training, we improve this result further to 85.1%. The second application, information extraction from seminar announcements, has been modeled previously with skip-chain CRFs (Sutton and McCallum, 2005; Finkel et al., 2005). The skip-chain CRF introduces loops and requires approximate inference, which motivates minimum risk training. Our results show that ERMA training improves Fmeasures from 89.5 to 90.9 (compared to 87.1 for the model without skip-chains). Finally, for our third application, we perform collective multi-label text classification. We follow previous work (Ghamrawi and McCallum, 2005; Finley and Joachims, 2008) and use a fully connected CRF to model all pairwise dependencies between labels. We observe similar trends for this task: switching from a maximum entropy model that does not model label dependencies to a loopy CRF leads to an improvement in F-measure from 81.6 to 84.0, and using ERMA leads to additional improvement (84.7). 2 Preliminaries 2.1 Conditional Random Fields A conditional random field (CRF) is an undirected graphical model defined by a tuple (X, Y, F, f, θ). X = (X1, X2, ...) is a set of random variables and Y = (Y1, Y2, . . .) is a set of output random </context>
<context position="25364" citStr="Ghamrawi and McCallum, 2005" startWordPosition="4094" endWordPosition="4098">resulted in a statistically significant improvement even in the exact case, thanks to the use of the loss function at training time. 4.3 Multi-Label Classification Multi-label classification is the problem of assigning multiple labels to a document. For example, a news article can be about both “Libya” and “civil 125 war.” The most straightforward approach to multilabel classification employs a binary classifier for each class separately. However, previous work has shown that incorporating information about label dependencies can lead to improvement in performance (Elisseeff and Weston, 2001; Ghamrawi and McCallum, 2005; Finley and Joachims, 2008). For this task we follow Ghamrawi and McCallum (2005) and Finley and Joachims (2008) and model the label interactions by constructing a fully connected CRF between the output labels. That is, for every document, we construct a CRF that contains a binary random variable for each label (indicating that the corresponding label is on/off for the document) and one binary edge for every unique pair of labels. This architecture can represent dependencies between labels, but leads to a setting in which the output variables form one massive clique. The resulting intractabil</context>
</contexts>
<marker>Ghamrawi, McCallum, 2005</marker>
<rawString>N. Ghamrawi and A. McCallum. 2005. Collective multilabel classification. In Proceedings of CIKM, pages 195–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Gimpel</author>
<author>N A Smith</author>
</authors>
<title>Softmax-margin CRFs: Training log-linear models with cost functions.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>733--736</pages>
<contexts>
<context position="12081" citStr="Gimpel and Smith, 2010" startWordPosition="1942" endWordPosition="1945">dient in this way, and training the CRF with some gradient-based optimization method, has been shown to work relatively well in practice (Vishwanathan et al., 2006; Sutton and McCallum, 2005). The above method takes into account neither the loss function that will be used for evaluation, nor the approximate algorithms that have been selected for inference and decoding at test time. Other structure learning methods do consider loss, though it is not obvious how to make them consider approximations. Those include maximum margin (Taskar et al., 2003; Finley and Joachims, 2008) and softmaxmargin (Gimpel and Smith, 2010). The idea of margin-based methods is to choose weights θ~ so that the correct alternative yi∗ always gets a better score argmin Y 122 than each possible alternative yi E Y. The loss is incorporated in these methods by requiring the margin (~θ · ~f(xi, yi*) − θ~ · ~f(xi, yi)) ? `(yi, yi*), with penalized slack in these constraints. The softmaxmargin method uses a different criterion—it resembles MLE but modifies the denominator of (1) to Zx = Ey,,, exp(~θ · ~f(x, y&apos;) + `(y&apos;, y*)). In our experiments we compare against MLE training (which is common) and softmax-margin, which incorporates loss a</context>
</contexts>
<marker>Gimpel, Smith, 2010</marker>
<rawString>K. Gimpel and N.A. Smith. 2010. Softmax-margin CRFs: Training log-linear models with cost functions. In Proceedings of ACL, pages 733–736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P I Good</author>
</authors>
<title>Permutation Tests.</title>
<date>2000</date>
<editor>A. Griewank and G. Corliss, editors.</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="26915" citStr="Good, 2000" startWordPosition="4340" endWordPosition="4341">Methodology For all experiments we split the data into train/development/test sets using the standard splits when available. We tune optimization algorithm parameters (initial learning rate, batch size and metaparameters A and p for stochastic meta descent) on the training set based on training objective convergence rates. We tune the regularization parameter Q (below) on development data when available, otherwise we use a default value of 0.1—performance was generally robust for small changes in the value of Q. All statistical significance testing is performed using paired permutation tests (Good, 2000). Gradient-based Optimization. Gradient information from the back-propagation procedure can be used in a local optimization method to minimize empirical loss. In this paper we use stochastic meta descent (SMD) (Schraudolph, 1999). SMD is a second-order method that requires vector-Hessian products. For computing those, we do not need to maintain the full Hessian matrix. Instead, we apply more automatic differentiation magic—this time in the forward mode. Computing the vector-Hessian product and utilizing it in SMD does not add to the asymptotic runtime, it requires about twice as many arithmeti</context>
</contexts>
<marker>Good, 2000</marker>
<rawString>P. I. Good. 2000. Permutation Tests. Springer. A. Griewank and G. Corliss, editors. 1991. Automatic Differentiation of Algorithms. SIAM, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gross</author>
<author>O Russakovsky</author>
<author>C Do</author>
<author>S Batzoglou</author>
</authors>
<title>Training conditional random fields for maximum labelwise accuracy.</title>
<date>2007</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<pages>19--529</pages>
<contexts>
<context position="33512" citStr="Gross et al., 2007" startWordPosition="5383" endWordPosition="5386">per represent a new state-of-theart for the first two of the problems, Congressional Vote and Semi-structured IE. For Multi-Label classification, comparing against the SVM-based method of Finley and Joachims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCun et al., 2006). In graphical models, methods have been proposed to directly minimize loss in tree127 shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Using empirical risk minimization to train graphical models was independently proposed by Domke (2010; 2011). Just as in our own paper (Stoyanov et al., 2011), Domke took a decision-theoreti</context>
</contexts>
<marker>Gross, Russakovsky, Do, Batzoglou, 2007</marker>
<rawString>S. Gross, O. Russakovsky, C. Do, and S. Batzoglou. 2007. Training conditional random fields for maximum labelwise accuracy. Advances in Neural Information Processing Systems, 19:529.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ji</author>
<author>R Grishman</author>
</authors>
<title>Knowledge base population: Successful approaches and challenges.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<pages>1148--1158</pages>
<contexts>
<context position="4200" citStr="Ji and Grishman, 2011" startWordPosition="640" endWordPosition="644">l, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics compared to approximate maximum likelihood estimation (MLE). However, this method has not been evaluated on real-world problems until now. We will refer to the Stoyanov et al. (2011) approach as “ERMA”—Empirical Risk Minimization under Approximations. ERMA is attractive for NLP because the freedom to use arbitrarily structured graphical models makes it possible to include latent linguistic variables, predict complex structures such as parses (Smith and Eisner, 2008), and do collective prediction in relational domains (Ji and Grishman, 2011; Benson et al., 2011; Dreyer and Eisner, 2009). In training, ERMA considers not only the approximation method but also the task-specific loss function. This means that ERMA is careful to use the additional variables and dependencies only in ways that help training set performance. (Overfitting on the enlarged parameter set should be avoided through regularization.) We have developed a simple syntax for specifying CRFs with complex structures, and a software package (available from http://www.clsp. jhu.edu/˜ves/software.html) that allows ERMA training of these CRFs for several popular loss fun</context>
</contexts>
<marker>Ji, Grishman, 2011</marker>
<rawString>H. Ji and R. Grishman. 2011. Knowledge base population: Successful approaches and challenges. In Proceedings of ACL-HLT, pages 1148–1158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kakade</author>
<author>Y W Teh</author>
<author>S Roweis</author>
</authors>
<title>An alternate objective function for Markovian fields.</title>
<date>2002</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>275--282</pages>
<contexts>
<context position="13630" citStr="Kakade et al., 2002" startWordPosition="2211" endWordPosition="2214">ference and decoding algorithms and the loss function that will be used during testing. Thus, we want θ to minimize the expected loss under the true data distribution P: argmin θ Exy—P [`(δθ(x), y)] (4) where δθ is the decision rule (parameterized by θ), which decodes the results of inference under pθ. In practice, we do not know the true data distribution, but we can do empirical risk minimization (ERM), instead averaging the loss over our sample of (xi, yi) pairs. ERM for structured prediction was first introduced in the speech community (Bahl et al., 1988) and later used in NLP (Och, 2003; Kakade et al., 2002; Suzuki et al., 2006; Li and Eisner, 2009, etc.). Previous applications of risk minimization assume exact inference, having defined the hypothesis space by a precomputed n-best list, lattice, or packed forest over which exact inference is possible. The ERMA approach (Stoyanov et al., 2011) works with approximate inference and computes exact gradients of the output loss (or a differentiable surrogate) in the context of the approximate inference and decoding algorithms. To determine the gradient of `(δθ(xi), yi) with respect to θ, the method relies on automatic differentiation in the reverse mo</context>
<context position="33470" citStr="Kakade et al., 2002" startWordPosition="5375" endWordPosition="5378">s for some of the runs. Results in this paper represent a new state-of-theart for the first two of the problems, Congressional Vote and Semi-structured IE. For Multi-Label classification, comparing against the SVM-based method of Finley and Joachims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCun et al., 2006). In graphical models, methods have been proposed to directly minimize loss in tree127 shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Using empirical risk minimization to train graphical models was independently proposed by Domke (2010; 2011). Just as in our own paper (Stoyanov et </context>
</contexts>
<marker>Kakade, Teh, Roweis, 2002</marker>
<rawString>S. Kakade, Y.W. Teh, and S. Roweis. 2002. An alternate objective function for Markovian fields. In Proceedings of ICML, pages 275–282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Koller</author>
<author>N Friedman</author>
</authors>
<title>Probabilistic Graphical Models: Principles and Techniques.</title>
<date>2009</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="8120" citStr="Koller and Friedman, 2009" startWordPosition="1288" endWordPosition="1291">obabilities needed at training or test time are conditioned on an observation of the form X = x, CRFs can include arbitrary overlapping features of the input without having to explicitly model input feature dependencies. 2Stoyanov et al. (2011) distinguished some of the Y variables as latent (i.e., unsupervised and ignored by the loss function). We omit this possibility, to simplify the notation. The model defines conditional probabilities exp pθ(y|x) = Ey, exp θ~· ~f(x, y) θ~· (1) ~f(x, y&apos;) all feature vector ~f(x, y) = EαEF 121 2.2 Inference in CRFs Inference in general CRFs is intractable (Koller and Friedman, 2009). Nevertheless, there exist several approximate algorithms that have theoretical motivation and tend to exhibit good performance in practice. Those include variational methods such as loopy belief propagation (BP) (Murphy et al., 1999) and mean-field, as well as Markov Chain Monte Carlo methods. ERMA training is applicable to any approximation that corresponds to a differentiable function, even if the function has no simple closed form but is computed by an iterative update algorithm. In this paper we select BP, which is exact when the factor graph is a tree, such as a linear-chain CRF, but wh</context>
</contexts>
<marker>Koller, Friedman, 2009</marker>
<rawString>D. Koller and N. Friedman. 2009. Probabilistic Graphical Models: Principles and Techniques. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kulesza</author>
<author>F Pereira</author>
</authors>
<title>Structured learning with approximate inference.</title>
<date>2008</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>785--792</pages>
<contexts>
<context position="2172" citStr="Kulesza and Pereira, 2008" startWordPosition="328" endWordPosition="331">fers to computing posterior marginal or max-marginal probability distributions of output random variables, given some evidence. “Decoding” derives a single structured output from the results of inference. call for higher-treewidth graphical models in which exact inference is expensive or intractable. These “loopy” CRFs have cyclic connections among the output and/or latent variables. Alas, standard learning procedures assume exact inference: they do not compensate for approximations that will be used at test time, and can go surprisingly awry if approximate inference is used at training time (Kulesza and Pereira, 2008). While NLP research has been consistently evolving toward more richly structured models, one may hesitate to add dependencies to a graphical model if there is a danger that this will end up hurting performance through approximations. In this paper we illustrate how to address this problem, even for extremely interconnected models in which every pair of output variables is connected. Wainwright (2006) showed that if approximate inference will be used at test time, it may be beneficial to use a learning procedure that does not converge to the true model but to one that performs well under the a</context>
</contexts>
<marker>Kulesza, Pereira, 2008</marker>
<rawString>A. Kulesza and F. Pereira. 2008. Structured learning with approximate inference. In Advances in Neural Information Processing Systems, pages 785–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lacoste-Julien</author>
<author>F Huszr</author>
<author>Z Ghahramani</author>
</authors>
<title>Approximate inference for the loss-calibrated Bayesian.</title>
<date>2011</date>
<booktitle>In Proceedings of AISTATS.</booktitle>
<contexts>
<context position="33723" citStr="Lacoste-Julien et al. (2011)" startWordPosition="5414" endWordPosition="5417">chims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCun et al., 2006). In graphical models, methods have been proposed to directly minimize loss in tree127 shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Using empirical risk minimization to train graphical models was independently proposed by Domke (2010; 2011). Just as in our own paper (Stoyanov et al., 2011), Domke took a decision-theoretic stance and proposed ERM as a way of calibrating the graphical model for use with approximate inference, or for use with data that do not quite match the modeling assumptions.4 In particular, (Domke, 2011) is s</context>
</contexts>
<marker>Lacoste-Julien, Huszr, Ghahramani, 2011</marker>
<rawString>S. Lacoste-Julien, F. Huszr, and Z. Ghahramani. 2011. Approximate inference for the loss-calibrated Bayesian. In Proceedings of AISTATS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="1017" citStr="Lafferty et al., 2001" startWordPosition="152" endWordPosition="155">rence, such as linear-chain CRFs. Some NLP phenomena, however, suggest CRFs with more complex topologies. Should such models be used, considering that they make exact inference intractable? Stoyanov et al. (2011) recently argued for training parameters to minimize the task-specific loss of whatever approximate inference and decoding methods will be used at test time. We apply their method to three NLP problems, showing that (i) using more complex CRFs leads to improved performance, and that (ii) minimumrisk training learns more accurate models. 1 Introduction Conditional Random Fields (CRFs) (Lafferty et al., 2001) are often used to model dependencies among linguistic variables. CRF-based models have improved the state of the art in a number of natural language processing (NLP) tasks ranging from partof-speech tagging to information extraction and sentiment analysis (Lafferty et al., 2001; Peng and McCallum, 2006; Choi et al., 2005). Robust and theoretically sound training procedures have been developed for CRFs when the model can be used with exact inference and decoding.1 However, some NLP problems seem to 1“Inference” typically refers to computing posterior marginal or max-marginal probability distri</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of ICML, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y LeCun</author>
<author>S Chopra</author>
<author>R Hadsell</author>
<author>M A Ranzato</author>
<author>F-J Huang</author>
</authors>
<title>A tutorial on energy-based learning.</title>
<date>2006</date>
<editor>In G. Bakir, T. Hofman, B. Schlkopf, A. Smola, and B. Taskar, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="33326" citStr="LeCun et al., 2006" startWordPosition="5350" endWordPosition="5353">011)). As expected, we found that max-product BP converges in fewer iterations— sum-product BP required as many as twice the number of iterations for some of the runs. Results in this paper represent a new state-of-theart for the first two of the problems, Congressional Vote and Semi-structured IE. For Multi-Label classification, comparing against the SVM-based method of Finley and Joachims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCun et al., 2006). In graphical models, methods have been proposed to directly minimize loss in tree127 shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Usin</context>
</contexts>
<marker>LeCun, Chopra, Hadsell, Ranzato, Huang, 2006</marker>
<rawString>Y. LeCun, S. Chopra, R. Hadsell, M.A. Ranzato, and F.-J. Huang. 2006. A tutorial on energy-based learning. In G. Bakir, T. Hofman, B. Schlkopf, A. Smola, and B. Taskar, editors, Predicting Structured Data. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Li</author>
<author>J Eisner</author>
</authors>
<title>First- and second-order expectation semirings with applications to minimumrisk training on translation forests.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>40--51</pages>
<contexts>
<context position="13672" citStr="Li and Eisner, 2009" startWordPosition="2219" endWordPosition="2222">ss function that will be used during testing. Thus, we want θ to minimize the expected loss under the true data distribution P: argmin θ Exy—P [`(δθ(x), y)] (4) where δθ is the decision rule (parameterized by θ), which decodes the results of inference under pθ. In practice, we do not know the true data distribution, but we can do empirical risk minimization (ERM), instead averaging the loss over our sample of (xi, yi) pairs. ERM for structured prediction was first introduced in the speech community (Bahl et al., 1988) and later used in NLP (Och, 2003; Kakade et al., 2002; Suzuki et al., 2006; Li and Eisner, 2009, etc.). Previous applications of risk minimization assume exact inference, having defined the hypothesis space by a precomputed n-best list, lattice, or packed forest over which exact inference is possible. The ERMA approach (Stoyanov et al., 2011) works with approximate inference and computes exact gradients of the output loss (or a differentiable surrogate) in the context of the approximate inference and decoding algorithms. To determine the gradient of `(δθ(xi), yi) with respect to θ, the method relies on automatic differentiation in the reverse mode (Griewank and Corliss, 1991), a general</context>
</contexts>
<marker>Li, Eisner, 2009</marker>
<rawString>Z. Li and J. Eisner. 2009. First- and second-order expectation semirings with applications to minimumrisk training on translation forests. In Proceedings of EMNLP, pages 40–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K P Murphy</author>
<author>Y Weiss</author>
<author>M I Jordan</author>
</authors>
<title>Loopy belief propagation for approximate inference: An empirical study.</title>
<date>1999</date>
<booktitle>In Proceedings of UAI.</booktitle>
<contexts>
<context position="8355" citStr="Murphy et al., 1999" startWordPosition="1322" endWordPosition="1325">11) distinguished some of the Y variables as latent (i.e., unsupervised and ignored by the loss function). We omit this possibility, to simplify the notation. The model defines conditional probabilities exp pθ(y|x) = Ey, exp θ~· ~f(x, y) θ~· (1) ~f(x, y&apos;) all feature vector ~f(x, y) = EαEF 121 2.2 Inference in CRFs Inference in general CRFs is intractable (Koller and Friedman, 2009). Nevertheless, there exist several approximate algorithms that have theoretical motivation and tend to exhibit good performance in practice. Those include variational methods such as loopy belief propagation (BP) (Murphy et al., 1999) and mean-field, as well as Markov Chain Monte Carlo methods. ERMA training is applicable to any approximation that corresponds to a differentiable function, even if the function has no simple closed form but is computed by an iterative update algorithm. In this paper we select BP, which is exact when the factor graph is a tree, such as a linear-chain CRF, but whose results can be somewhat distorted by loops in the factor graph, as in our settings. BP computes beliefs about the marginal distribution of each random variable using iterative updates. We standardly approximate the posterior CRF ma</context>
</contexts>
<marker>Murphy, Weiss, Jordan, 1999</marker>
<rawString>K. P. Murphy, Y. Weiss, and M. I. Jordan. 1999. Loopy belief propagation for approximate inference: An empirical study. In Proceedings of UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="13609" citStr="Och, 2003" startWordPosition="2209" endWordPosition="2210">roximate inference and decoding algorithms and the loss function that will be used during testing. Thus, we want θ to minimize the expected loss under the true data distribution P: argmin θ Exy—P [`(δθ(x), y)] (4) where δθ is the decision rule (parameterized by θ), which decodes the results of inference under pθ. In practice, we do not know the true data distribution, but we can do empirical risk minimization (ERM), instead averaging the loss over our sample of (xi, yi) pairs. ERM for structured prediction was first introduced in the speech community (Bahl et al., 1988) and later used in NLP (Och, 2003; Kakade et al., 2002; Suzuki et al., 2006; Li and Eisner, 2009, etc.). Previous applications of risk minimization assume exact inference, having defined the hypothesis space by a precomputed n-best list, lattice, or packed forest over which exact inference is possible. The ERMA approach (Stoyanov et al., 2011) works with approximate inference and computes exact gradients of the output loss (or a differentiable surrogate) in the context of the approximate inference and decoding algorithms. To determine the gradient of `(δθ(xi), yi) with respect to θ, the method relies on automatic differentiat</context>
<context position="33270" citStr="Och, 2003" startWordPosition="5344" endWordPosition="5345">ast to the synthetic CRFs in Stoyanov et al. (2011)). As expected, we found that max-product BP converges in fewer iterations— sum-product BP required as many as twice the number of iterations for some of the runs. Results in this paper represent a new state-of-theart for the first two of the problems, Congressional Vote and Semi-structured IE. For Multi-Label classification, comparing against the SVM-based method of Finley and Joachims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCun et al., 2006). In graphical models, methods have been proposed to directly minimize loss in tree127 shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference al</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings ofACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Peng</author>
<author>A McCallum</author>
</authors>
<title>Information extraction from research papers using conditional random fields.</title>
<date>2006</date>
<journal>Information Processing &amp; Management,</journal>
<volume>42</volume>
<issue>4</issue>
<pages>979</pages>
<contexts>
<context position="1321" citStr="Peng and McCallum, 2006" startWordPosition="200" endWordPosition="204">roximate inference and decoding methods will be used at test time. We apply their method to three NLP problems, showing that (i) using more complex CRFs leads to improved performance, and that (ii) minimumrisk training learns more accurate models. 1 Introduction Conditional Random Fields (CRFs) (Lafferty et al., 2001) are often used to model dependencies among linguistic variables. CRF-based models have improved the state of the art in a number of natural language processing (NLP) tasks ranging from partof-speech tagging to information extraction and sentiment analysis (Lafferty et al., 2001; Peng and McCallum, 2006; Choi et al., 2005). Robust and theoretically sound training procedures have been developed for CRFs when the model can be used with exact inference and decoding.1 However, some NLP problems seem to 1“Inference” typically refers to computing posterior marginal or max-marginal probability distributions of output random variables, given some evidence. “Decoding” derives a single structured output from the results of inference. call for higher-treewidth graphical models in which exact inference is expensive or intractable. These “loopy” CRFs have cyclic connections among the output and/or latent</context>
</contexts>
<marker>Peng, McCallum, 2006</marker>
<rawString>F. Peng and A. McCallum. 2006. Information extraction from research papers using conditional random fields. Information Processing &amp; Management, 42(4):963– 979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N N Schraudolph</author>
</authors>
<title>Local gain adaptation in stochastic gradient descent.</title>
<date>1999</date>
<booktitle>In Proceedings of ANN,</booktitle>
<pages>569--574</pages>
<contexts>
<context position="27144" citStr="Schraudolph, 1999" startWordPosition="4373" endWordPosition="4374"> and p for stochastic meta descent) on the training set based on training objective convergence rates. We tune the regularization parameter Q (below) on development data when available, otherwise we use a default value of 0.1—performance was generally robust for small changes in the value of Q. All statistical significance testing is performed using paired permutation tests (Good, 2000). Gradient-based Optimization. Gradient information from the back-propagation procedure can be used in a local optimization method to minimize empirical loss. In this paper we use stochastic meta descent (SMD) (Schraudolph, 1999). SMD is a second-order method that requires vector-Hessian products. For computing those, we do not need to maintain the full Hessian matrix. Instead, we apply more automatic differentiation magic—this time in the forward mode. Computing the vector-Hessian product and utilizing it in SMD does not add to the asymptotic runtime, it requires about twice as many arithmetic operations, and leads to much faster convergence of the learner in our experience. See Stoyanov et al. (2011) for details. Since the empirical risk objective could overfit the training data, we add an L2 regularizer Q Ej 02 j t</context>
</contexts>
<marker>Schraudolph, 1999</marker>
<rawString>N.N. Schraudolph. 1999. Local gain adaptation in stochastic gradient descent. In Proceedings of ANN, pages 569–574.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sha</author>
<author>F Pereira</author>
</authors>
<title>Shallow parsing with conditional random fields.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL/HLT,</booktitle>
<pages>134--141</pages>
<contexts>
<context position="9807" citStr="Sha and Pereira (2003)" startWordPosition="1571" endWordPosition="1574">tem outputs. Given x, the decoder would ideally choose y to minimize the loss `(y, y∗), where ` compares a candidate assignment y to the true assignment y∗. But of course we do not know the truth at test time. Instead we can average over possible values y0 of the truth: p(y0 |x) - `(y, y0) (2) This is the minimum Bayes risk (MBR) principle from statistical decision theory: choose y to minimize the expected loss (i.e., the risk) according to the CRF’s posterior beliefs given x. In the NLP literature, CRFs are often decoded by choosing y to be the maximum posterior probability assignment (e.g., Sha and Pereira (2003), Sutton et al. (2007)). This is the MBR procedure for the 0-1 loss function that simply tests whether y = y∗. For other loss functions, however, the corresponding MBR procedure is preferable. For some loss functions it is tractable given the posterior marginals of p, while in other cases approximations are needed. In our experiments we use MBR decoding (or a tractable approximation) but substitute the approximate posterior marginals of p as computed by BP. For example, if the loss of y is the number of incorrectly recovered output variables, MBR says to separately pick the most probable value</context>
</contexts>
<marker>Sha, Pereira, 2003</marker>
<rawString>F. Sha and F. Pereira. 2003. Shallow parsing with conditional random fields. In Proceedings of ACL/HLT, pages 134–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Smith</author>
<author>J Eisner</author>
</authors>
<title>Minimum risk annealing for training log-linear models.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL,</booktitle>
<pages>787--794</pages>
<contexts>
<context position="16675" citStr="Smith and Eisner, 2006" startWordPosition="2705" endWordPosition="2708">ecifically showed how to train a system that will use sum-product BP for inference at test time (unlike margin-based methods). This may be advantageous for some tasks because it marginalizes over latent variables. However, it is popular and sometimes faster to do 1-best decoding, so we also include experiments where the test-time system returns a 1- best value of y (or an approximation to this if the CRF is loopy), based on max-product BP inference. Although 1-best systems are not differentiable functions, we can approach their behavior during ERM training by annealing the training objective (Smith and Eisner, 2006). In the annealed case we evaluate (4) and its gradient under sum-product BP, except that we perform inference under p(θ/T) instead of pθ. 123 We gradually reduce the temperature T E R from 1 to 0 as training proceeds, which turns sum-product inference into max-product by moving all the probability mass toward the highest-scoring assignment. 4 Modeling Natural Language with CRFs This section describes three NLP problems that can be naturally modeled with approximate CRFs. The first problem, modeling congressional votes, has not been previously modeled with a CRF. We show that by switching to t</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>D.A. Smith and J. Eisner. 2006. Minimum risk annealing for training log-linear models. In Proceedings of the COLING/ACL, pages 787–794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Smith</author>
<author>J Eisner</author>
</authors>
<title>Dependency parsing by belief propagation.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>145--156</pages>
<contexts>
<context position="4125" citStr="Smith and Eisner, 2008" startWordPosition="628" endWordPosition="631">mputational Linguistics: Human Language Technologies, pages 120–130, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics compared to approximate maximum likelihood estimation (MLE). However, this method has not been evaluated on real-world problems until now. We will refer to the Stoyanov et al. (2011) approach as “ERMA”—Empirical Risk Minimization under Approximations. ERMA is attractive for NLP because the freedom to use arbitrarily structured graphical models makes it possible to include latent linguistic variables, predict complex structures such as parses (Smith and Eisner, 2008), and do collective prediction in relational domains (Ji and Grishman, 2011; Benson et al., 2011; Dreyer and Eisner, 2009). In training, ERMA considers not only the approximation method but also the task-specific loss function. This means that ERMA is careful to use the additional variables and dependencies only in ways that help training set performance. (Overfitting on the enlarged parameter set should be avoided through regularization.) We have developed a simple syntax for specifying CRFs with complex structures, and a software package (available from http://www.clsp. jhu.edu/˜ves/software</context>
</contexts>
<marker>Smith, Eisner, 2008</marker>
<rawString>D. Smith and J. Eisner. 2008. Dependency parsing by belief propagation. In Proceedings of EMNLP, pages 145–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Stoyanov</author>
<author>J Eisner</author>
</authors>
<title>Learning cost-aware, loss-aware approximate inference policies for probabilistic graphical models.</title>
<date>2011</date>
<booktitle>In COST: NIPS 2011 Workshop on Computational Trade-offs in Statistical Learning,</booktitle>
<location>Sierra Nevada, Spain,</location>
<contexts>
<context position="34763" citStr="Stoyanov and Eisner (2011)" startWordPosition="5587" endWordPosition="5590"> as a way of calibrating the graphical model for use with approximate inference, or for use with data that do not quite match the modeling assumptions.4 In particular, (Domke, 2011) is similar to (Stoyanov et al., 2011) in using ERMA to train model parameters to be used with “truncated” inference that will be run for only a fixed number of iterations. For a common pixel-labeling benchmark in computer vision, Domke (2011) shows that this procedure improves training time by orders of magnitude, and slightly improves accuracy if the same number of message-passing iterations is used at test time. Stoyanov and Eisner (2011) extend the ERMA objective function by adding an explicit runtime term. This allows them to tune model parameters and stopping criteria to learn models that obtain a given speed-accuracy tradeoff. Their approach improves this hybrid objective over a range of coefficients when compared to the traditional way of inducing sparse structures through Li regularization. Eisner and Daum´e III (2011) propose the same linear combination of speed and accuracy as a reinforcement learning objective. In general, our proposed ERMA setting resembles the reinforcement learning problem of trying to directly lea</context>
</contexts>
<marker>Stoyanov, Eisner, 2011</marker>
<rawString>V. Stoyanov and J. Eisner. 2011. Learning cost-aware, loss-aware approximate inference policies for probabilistic graphical models. In COST: NIPS 2011 Workshop on Computational Trade-offs in Statistical Learning, Sierra Nevada, Spain, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Stoyanov</author>
<author>A Ropson</author>
<author>J Eisner</author>
</authors>
<title>Empirical risk minimization of graphical model parameters given approximate inference, decoding, and model structure.</title>
<date>2011</date>
<booktitle>In Proceedings of AISTATS.</booktitle>
<contexts>
<context position="2809" citStr="Stoyanov et al. (2011)" startWordPosition="435" endWordPosition="438">earch has been consistently evolving toward more richly structured models, one may hesitate to add dependencies to a graphical model if there is a danger that this will end up hurting performance through approximations. In this paper we illustrate how to address this problem, even for extremely interconnected models in which every pair of output variables is connected. Wainwright (2006) showed that if approximate inference will be used at test time, it may be beneficial to use a learning procedure that does not converge to the true model but to one that performs well under the approximations. Stoyanov et al. (2011) argue for minimizing a certain non-convex training objective, namely the empirical risk of the entire system comprising the CRF together with whatever approximate inference and decoding procedures will be used at test time. They regard this entire system as simply a complex decision rule, analogous to a neural network, and show how to use back-propagation to tune its parameters to locally minimize the empirical risk (i.e., the average task-specific loss on training data). Stoyanov et al. (2011) show that on certain synthetic-data problems, this frequentist training regimen significantly reduc</context>
<context position="7738" citStr="Stoyanov et al. (2011)" startWordPosition="1223" endWordPosition="1226">y, for each α ∈ F, the CRF specifies a function ~fα that extracts a feature vector ∈ Rd from the restricted assignment xyα. We define the over~fα(xyα) ∈ Rd. where θ~ ∈ Rd is a global weight vector (to be learned). This is a log-linear model; the denominator (traditionally denoted Zx) sums over all possible output assignments to normalize the distribution. Provided that all probabilities needed at training or test time are conditioned on an observation of the form X = x, CRFs can include arbitrary overlapping features of the input without having to explicitly model input feature dependencies. 2Stoyanov et al. (2011) distinguished some of the Y variables as latent (i.e., unsupervised and ignored by the loss function). We omit this possibility, to simplify the notation. The model defines conditional probabilities exp pθ(y|x) = Ey, exp θ~· ~f(x, y) θ~· (1) ~f(x, y&apos;) all feature vector ~f(x, y) = EαEF 121 2.2 Inference in CRFs Inference in general CRFs is intractable (Koller and Friedman, 2009). Nevertheless, there exist several approximate algorithms that have theoretical motivation and tend to exhibit good performance in practice. Those include variational methods such as loopy belief propagation (BP) (Mur</context>
<context position="10589" citStr="Stoyanov et al. (2011)" startWordPosition="1701" endWordPosition="1704">ing MBR procedure is preferable. For some loss functions it is tractable given the posterior marginals of p, while in other cases approximations are needed. In our experiments we use MBR decoding (or a tractable approximation) but substitute the approximate posterior marginals of p as computed by BP. For example, if the loss of y is the number of incorrectly recovered output variables, MBR says to separately pick the most probable value for each output variable, according to its (approximate) marginal. 3 Minimum-Risk CRF Training This section briefly describes the ERMA training algorithm from Stoyanov et al. (2011) and compares it to related structured learning methods. We assume a standard ML setting, with a set of training inputs xi and corresponding correct outputs yi∗. All the methods below are regularized in practice, but we omit mention of regularizers for simplicity. 3.1 Related Structured Learning Methods When inference and decoding can be performed exactly, the CRF parameters θ~ are often trained by maximum likelihood estimation (MLE): argmax log pθ(yi∗ |xi) (3) θ i The gradient of each summand log pθ(yi∗ |xi) can be computed by performing inference in two settings, one with xi, yi∗ observed an</context>
<context position="13921" citStr="Stoyanov et al., 2011" startWordPosition="2257" endWordPosition="2260">rence under pθ. In practice, we do not know the true data distribution, but we can do empirical risk minimization (ERM), instead averaging the loss over our sample of (xi, yi) pairs. ERM for structured prediction was first introduced in the speech community (Bahl et al., 1988) and later used in NLP (Och, 2003; Kakade et al., 2002; Suzuki et al., 2006; Li and Eisner, 2009, etc.). Previous applications of risk minimization assume exact inference, having defined the hypothesis space by a precomputed n-best list, lattice, or packed forest over which exact inference is possible. The ERMA approach (Stoyanov et al., 2011) works with approximate inference and computes exact gradients of the output loss (or a differentiable surrogate) in the context of the approximate inference and decoding algorithms. To determine the gradient of `(δθ(xi), yi) with respect to θ, the method relies on automatic differentiation in the reverse mode (Griewank and Corliss, 1991), a general technique for sensitivity analysis in computations. The intuition behind automatic differentiation is that the entire computation is a sequence of elementary differentiable operations. For each elementary operation, given that we know the input and</context>
<context position="16049" citStr="Stoyanov et al. (2011)" startWordPosition="2601" endWordPosition="2604">ecoding, then evaluation. These steps convert (xi, θ) —* marginals —* decision —* loss. The backward pass rewinds the entire computation, differentiating each phase in term. The total time required by this algorithm is roughly twice the time of the forward pass, so its complexity is comparable to approximate inference. In this paper, we do not advocate any particular test-time inference or decoding procedures. It is reasonable to experiment with several choices that may produce faster or more accurate systems. We simply recommend doing ERMA training to match each selected test-time condition. Stoyanov et al. (2011) specifically showed how to train a system that will use sum-product BP for inference at test time (unlike margin-based methods). This may be advantageous for some tasks because it marginalizes over latent variables. However, it is popular and sometimes faster to do 1-best decoding, so we also include experiments where the test-time system returns a 1- best value of y (or an approximation to this if the CRF is loopy), based on max-product BP inference. Although 1-best systems are not differentiable functions, we can approach their behavior during ERM training by annealing the training objectiv</context>
<context position="27626" citStr="Stoyanov et al. (2011)" startWordPosition="4447" endWordPosition="4451">an be used in a local optimization method to minimize empirical loss. In this paper we use stochastic meta descent (SMD) (Schraudolph, 1999). SMD is a second-order method that requires vector-Hessian products. For computing those, we do not need to maintain the full Hessian matrix. Instead, we apply more automatic differentiation magic—this time in the forward mode. Computing the vector-Hessian product and utilizing it in SMD does not add to the asymptotic runtime, it requires about twice as many arithmetic operations, and leads to much faster convergence of the learner in our experience. See Stoyanov et al. (2011) for details. Since the empirical risk objective could overfit the training data, we add an L2 regularizer Q Ej 02 j that prefers parameter values close to 0. This improves generalization, like the margin constraints in margin-based methods. Training Procedure Stoyanov et al. (2011) observed that the minimum-risk objective tends to be highly non-convex in practice. The usual approximate log likelihood training objective appeared to be smoother over the parameter space, but exhibited global maxima at parameter values that were relatively good, but sub-optimal for other loss functions. Mean-squa</context>
<context position="32711" citStr="Stoyanov et al. (2011)" startWordPosition="5253" endWordPosition="5256">i-structured IE when testing using max-product inference. For the other remaining three problem setting training with either minimal risk training regiment. Finally, we hypothesized that sum-product inference may produce more accurate results in certain cases as it allows more information about different parts of the model to be exchanged. However, our results show that for these three problems, sum-product and max-product inference yield statistically indistinguishable results. This may be because the particular CRFs we used included no latent variables (in constrast to the synthetic CRFs in Stoyanov et al. (2011)). As expected, we found that max-product BP converges in fewer iterations— sum-product BP required as many as twice the number of iterations for some of the runs. Results in this paper represent a new state-of-theart for the first two of the problems, Congressional Vote and Semi-structured IE. For Multi-Label classification, comparing against the SVM-based method of Finley and Joachims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCu</context>
<context position="34080" citStr="Stoyanov et al., 2011" startWordPosition="5471" endWordPosition="5475">et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Using empirical risk minimization to train graphical models was independently proposed by Domke (2010; 2011). Just as in our own paper (Stoyanov et al., 2011), Domke took a decision-theoretic stance and proposed ERM as a way of calibrating the graphical model for use with approximate inference, or for use with data that do not quite match the modeling assumptions.4 In particular, (Domke, 2011) is similar to (Stoyanov et al., 2011) in using ERMA to train model parameters to be used with “truncated” inference that will be run for only a fixed number of iterations. For a common pixel-labeling benchmark in computer vision, Domke (2011) shows that this procedure improves training time by orders of magnitude, and slightly improves accuracy if the same nu</context>
<context position="35561" citStr="Stoyanov et al. (2011)" startWordPosition="5712" endWordPosition="5715">d-accuracy tradeoff. Their approach improves this hybrid objective over a range of coefficients when compared to the traditional way of inducing sparse structures through Li regularization. Eisner and Daum´e III (2011) propose the same linear combination of speed and accuracy as a reinforcement learning objective. In general, our proposed ERMA setting resembles the reinforcement learning problem of trying to directly learn a policy that minimizes loss or maximizes reward. We have been concerned with the fact that ERMA training objectives may suffer from local optima and non-differentiability. Stoyanov et al. (2011) studied 4However, he is less focused than we are on matching training conditions to test conditions (by including the decoder and task loss in the ERMA objective). several such settings, graphed the difficult objective, and identified some practical workarounds that are used in the present paper. Although these methods have enabled us to get strong results by reducing the empirical risk, we suspect that ERMA training objectives will benefit from more sophisticated optimization methods. This is true even when the approximate inference itself is restricted to be something as simple as a convex </context>
</contexts>
<marker>Stoyanov, Ropson, Eisner, 2011</marker>
<rawString>V. Stoyanov, A. Ropson, and J. Eisner. 2011. Empirical risk minimization of graphical model parameters given approximate inference, decoding, and model structure. In Proceedings of AISTATS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sutton</author>
<author>A McCallum</author>
</authors>
<title>Piecewise training of undirected models.</title>
<date>2005</date>
<booktitle>In Proceedings of UAI,</booktitle>
<pages>568--575</pages>
<contexts>
<context position="5846" citStr="Sutton and McCallum, 2005" startWordPosition="887" endWordPosition="891">inear structure and (ii) that ERMA training represents an improvement over previous learning methods. The first application, predicting congressional votes, has not been previously modeled with CRFs. By using a more principled probabilistic approach, we are able to improve the state-of-the-art accuracy from 71.2% to 78.2% when training to maximize the approximate log-likelihood of the training data. By switching to ERMA training, we improve this result further to 85.1%. The second application, information extraction from seminar announcements, has been modeled previously with skip-chain CRFs (Sutton and McCallum, 2005; Finkel et al., 2005). The skip-chain CRF introduces loops and requires approximate inference, which motivates minimum risk training. Our results show that ERMA training improves Fmeasures from 89.5 to 90.9 (compared to 87.1 for the model without skip-chains). Finally, for our third application, we perform collective multi-label text classification. We follow previous work (Ghamrawi and McCallum, 2005; Finley and Joachims, 2008) and use a fully connected CRF to model all pairwise dependencies between labels. We observe similar trends for this task: switching from a maximum entropy model that </context>
<context position="11649" citStr="Sutton and McCallum, 2005" startWordPosition="1872" endWordPosition="1875">LE): argmax log pθ(yi∗ |xi) (3) θ i The gradient of each summand log pθ(yi∗ |xi) can be computed by performing inference in two settings, one with xi, yi∗ observed and one with only the conditioning events xi observed. The gradient emerges as the difference between the feature expectations in the two cases. If exact inference is intractable, one can compute approximate feature expectations by loopy BP. Computing the approximate gradient in this way, and training the CRF with some gradient-based optimization method, has been shown to work relatively well in practice (Vishwanathan et al., 2006; Sutton and McCallum, 2005). The above method takes into account neither the loss function that will be used for evaluation, nor the approximate algorithms that have been selected for inference and decoding at test time. Other structure learning methods do consider loss, though it is not obvious how to make them consider approximations. Those include maximum margin (Taskar et al., 2003; Finley and Joachims, 2008) and softmaxmargin (Gimpel and Smith, 2010). The idea of margin-based methods is to choose weights θ~ so that the correct alternative yi∗ always gets a better score argmin Y 122 than each possible alternative yi</context>
<context position="22883" citStr="Sutton and McCallum, 2005" startWordPosition="3704" endWordPosition="3707">ne, we compare against the results of Thomas et al. (2006). Their test-time Min-Cut algorithm is exact in this case: binary variables and a two-way classification. 4.2 Information Extraction from Semi-Structured Text We utilize the CMU seminar announcement corpus of Freitag (2000) consisting of emails with seminar announcements. The task is to extract four fields that describe each seminar: speaker, location, start time and end time. The corpus annotates the document with all mentions of these four fields. Sequential CRFs have been used successfully for semi-structured information extraction (Sutton and McCallum, 2005; Finkel et al., 2005). However, they cannot model non-local dependencies in the data. For example, in the seminar announcements corpus, if “Sutner” is mentioned once in an email in a context that identifies him as a speaker, it is Figure 2: Skip-chain CRF for semi-structured information extraction. likely that other occurrences of “Sutner” in the same email should be marked as speaker. Hence Finkel et al. (2005) and Sutton and McCallum (2005) propose adding non-local edges to a sequential CRF to represent soft consistency constraints. The model, called a “skip-chain CRF” and shown in Figure 2</context>
</contexts>
<marker>Sutton, McCallum, 2005</marker>
<rawString>C. Sutton and A. McCallum. 2005. Piecewise training of undirected models. In Proceedings of UAI, pages 568–575.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sutton</author>
<author>A McCallum</author>
<author>K Rohanimanesh</author>
</authors>
<title>Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data.</title>
<date>2007</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>8--693</pages>
<contexts>
<context position="9829" citStr="Sutton et al. (2007)" startWordPosition="1575" endWordPosition="1578">e decoder would ideally choose y to minimize the loss `(y, y∗), where ` compares a candidate assignment y to the true assignment y∗. But of course we do not know the truth at test time. Instead we can average over possible values y0 of the truth: p(y0 |x) - `(y, y0) (2) This is the minimum Bayes risk (MBR) principle from statistical decision theory: choose y to minimize the expected loss (i.e., the risk) according to the CRF’s posterior beliefs given x. In the NLP literature, CRFs are often decoded by choosing y to be the maximum posterior probability assignment (e.g., Sha and Pereira (2003), Sutton et al. (2007)). This is the MBR procedure for the 0-1 loss function that simply tests whether y = y∗. For other loss functions, however, the corresponding MBR procedure is preferable. For some loss functions it is tractable given the posterior marginals of p, while in other cases approximations are needed. In our experiments we use MBR decoding (or a tractable approximation) but substitute the approximate posterior marginals of p as computed by BP. For example, if the loss of y is the number of incorrectly recovered output variables, MBR says to separately pick the most probable value for each output varia</context>
<context position="18833" citStr="Sutton et al., 2007" startWordPosition="3049" endWordPosition="3052">s correctly. Speakers often reference one another (e.g., “I thank the gentleman from Utah”), to indicate agreement or disagreement. The ConVote corpus manually annotates each phrase such as “the gentleman from Utah” with the representative that it denotes. Thomas et al. (2006) show that classification using the agreement/disagreement information in the local context of such references, together with the rest of the language in the speeches, can lead to significant improvement over using either of these two 3We also experimented with a fourth application, joint POS tagging and shallow parsing (Sutton et al., 2007) and observed the same overall trend (i.e., minimum risk training improved performance significantly). We do not include those experiments, however, because we were unable to make our baseline results replicate (Sutton et al., 2007). sources of information in isolation. The original approach of Thomas et al. (2006) is based on training two Support Vector Machine (SVM) classifiers— one for classifying speeches as supporting/opposing the legislation and another for classifying references as agreement/disagreement. Both classifiers rely on bag-of-word (unigram) features of the document and the co</context>
</contexts>
<marker>Sutton, McCallum, Rohanimanesh, 2007</marker>
<rawString>C. Sutton, A. McCallum, and K. Rohanimanesh. 2007. Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data. The Journal of Machine Learning Research, 8:693–723.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Suzuki</author>
<author>E McDermott</author>
<author>H Isozaki</author>
</authors>
<title>Training conditional random fields with multivariate evaluation measures.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL,</booktitle>
<pages>217--224</pages>
<contexts>
<context position="13651" citStr="Suzuki et al., 2006" startWordPosition="2215" endWordPosition="2218">algorithms and the loss function that will be used during testing. Thus, we want θ to minimize the expected loss under the true data distribution P: argmin θ Exy—P [`(δθ(x), y)] (4) where δθ is the decision rule (parameterized by θ), which decodes the results of inference under pθ. In practice, we do not know the true data distribution, but we can do empirical risk minimization (ERM), instead averaging the loss over our sample of (xi, yi) pairs. ERM for structured prediction was first introduced in the speech community (Bahl et al., 1988) and later used in NLP (Och, 2003; Kakade et al., 2002; Suzuki et al., 2006; Li and Eisner, 2009, etc.). Previous applications of risk minimization assume exact inference, having defined the hypothesis space by a precomputed n-best list, lattice, or packed forest over which exact inference is possible. The ERMA approach (Stoyanov et al., 2011) works with approximate inference and computes exact gradients of the output loss (or a differentiable surrogate) in the context of the approximate inference and decoding algorithms. To determine the gradient of `(δθ(xi), yi) with respect to θ, the method relies on automatic differentiation in the reverse mode (Griewank and Corl</context>
<context position="33491" citStr="Suzuki et al., 2006" startWordPosition="5379" endWordPosition="5382">s. Results in this paper represent a new state-of-theart for the first two of the problems, Congressional Vote and Semi-structured IE. For Multi-Label classification, comparing against the SVM-based method of Finley and Joachims (2008) goes beyond the scope of this paper. 6 Related Work Minimum-risk training has been used in speech recognition (Bahl et al., 1988), machine translation (Och, 2003), and energy-based models generally (LeCun et al., 2006). In graphical models, methods have been proposed to directly minimize loss in tree127 shaped or linear chain MRFs and CRFs (Kakade et al., 2002; Suzuki et al., 2006; Gross et al., 2007). All of the above focus on exact inference. Our approach can be seen as generalizing these methods to arbitrary graph structures, arbitrary loss functions and approximate inference. Lacoste-Julien et al. (2011) also consider the effects of approximate inference on loss. However, they assume the parameters are given, and modify the approximate inference algorithm at test time to consider the loss function. Using empirical risk minimization to train graphical models was independently proposed by Domke (2010; 2011). Just as in our own paper (Stoyanov et al., 2011), Domke too</context>
</contexts>
<marker>Suzuki, McDermott, Isozaki, 2006</marker>
<rawString>J. Suzuki, E. McDermott, and H. Isozaki. 2006. Training conditional random fields with multivariate evaluation measures. In Proceedings of COLING/ACL, pages 217–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Taskar</author>
<author>C Guestrin</author>
<author>D Koller</author>
</authors>
<title>Max-margin Markov networks.</title>
<date>2003</date>
<booktitle>Proceedings of NIPS,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="12010" citStr="Taskar et al., 2003" startWordPosition="1931" endWordPosition="1934">ate feature expectations by loopy BP. Computing the approximate gradient in this way, and training the CRF with some gradient-based optimization method, has been shown to work relatively well in practice (Vishwanathan et al., 2006; Sutton and McCallum, 2005). The above method takes into account neither the loss function that will be used for evaluation, nor the approximate algorithms that have been selected for inference and decoding at test time. Other structure learning methods do consider loss, though it is not obvious how to make them consider approximations. Those include maximum margin (Taskar et al., 2003; Finley and Joachims, 2008) and softmaxmargin (Gimpel and Smith, 2010). The idea of margin-based methods is to choose weights θ~ so that the correct alternative yi∗ always gets a better score argmin Y 122 than each possible alternative yi E Y. The loss is incorporated in these methods by requiring the margin (~θ · ~f(xi, yi*) − θ~ · ~f(xi, yi)) ? `(yi, yi*), with penalized slack in these constraints. The softmaxmargin method uses a different criterion—it resembles MLE but modifies the denominator of (1) to Zx = Ey,,, exp(~θ · ~f(x, y&apos;) + `(y&apos;, y*)). In our experiments we compare against MLE t</context>
</contexts>
<marker>Taskar, Guestrin, Koller, 2003</marker>
<rawString>B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin Markov networks. Proceedings of NIPS, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thomas</author>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Get out the vote: Determining support or opposition from congressional floor-debate transcripts.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>327--335</pages>
<contexts>
<context position="17805" citStr="Thomas et al. (2006)" startWordPosition="2884" endWordPosition="2887">essional votes, has not been previously modeled with a CRF. We show that by switching to the principled CRF framework we can learn models that are much more accurate when evaluated on test data, though using the same (or less expressive) features as previous work. The other two problems, information extraction from semistructured text and collective multi-label classification, have been modeled with loopy CRFs before. For all three models, we show that ERMA training results in better test set performance.3 4.1 Modeling Congressional Votes The Congressional Vote (ConVote) corpus was created by Thomas et al. (2006) to study whether votes of U.S. congressional representatives can be predicted from the speeches they gave when debating a bill. The corpus consists of transcripts of congressional floor debates split into speech segments. Each speech segment is labeled with the representative who is speaking and the recorded vote of that representative on the bill. We aim to predict a high percentage of the recorded votes correctly. Speakers often reference one another (e.g., “I thank the gentleman from Utah”), to indicate agreement or disagreement. The ConVote corpus manually annotates each phrase such as “t</context>
<context position="19149" citStr="Thomas et al. (2006)" startWordPosition="3098" endWordPosition="3101">eement/disagreement information in the local context of such references, together with the rest of the language in the speeches, can lead to significant improvement over using either of these two 3We also experimented with a fourth application, joint POS tagging and shallow parsing (Sutton et al., 2007) and observed the same overall trend (i.e., minimum risk training improved performance significantly). We do not include those experiments, however, because we were unable to make our baseline results replicate (Sutton et al., 2007). sources of information in isolation. The original approach of Thomas et al. (2006) is based on training two Support Vector Machine (SVM) classifiers— one for classifying speeches as supporting/opposing the legislation and another for classifying references as agreement/disagreement. Both classifiers rely on bag-of-word (unigram) features of the document and the context surrounding the link respectively. The scores produced by the two SVMs are used to weight a global graph whose vertices are the representatives; then the min-cut algorithm is applied to partition the vertices into “yea” and “nay” voters. While the approach of Thomas et al. (2006) leads to significant improvem</context>
<context position="20756" citStr="Thomas et al., 2006" startWordPosition="3359" endWordPosition="3362">ted for one of the debates in the development part of the ConVote corpus. It contains a random variable for each representative’s vote. In addition, each speech is an observed input random variable: it is connected by a factor to its speaker’s vote and encourages it to be “yea” or “nay” according to features of the text of the speech. Finally, each reference in each speech is an observed input random variable connected by a factor to two votes—those of the speaker and the referent—which it encourages to agree or disagree according to features of the text surrounding the reference. Just as in (Thomas et al., 2006), the score of a global assignment to all votes is defined by considering both kinds of factors. However, unlike min-cut, CRF inference finds a probability distribution over assignments, not just a single best assignment. This fact allows us to train the two kinds of factors jointly (on the set of training debates where the votes are known) to predict the correct votes accurately (as defined by accuracy). As Figure 1 shows, the reference factors introduce arbitrary loops, making exact inference intractable and thus motivating ERMA. Our experiments described in section 5.2 show that switching t</context>
<context position="22316" citStr="Thomas et al. (2006)" startWordPosition="3622" endWordPosition="3625">ctor, shown as round nodes. Unshaded variables correspond to the representatives’ votes and depict the output variables that we learn to jointly predict. Shaded variables correspond to the observed input data— the text of all speeches of a representative (in dark gray) or all local contexts of references between two representatives (in light gray). and that ERMA further significantly improves performance, particularly when it properly trains with the same inference algorithm (max-product vs. sumproduct) to be used at test time. Baseline. As an exact baseline, we compare against the results of Thomas et al. (2006). Their test-time Min-Cut algorithm is exact in this case: binary variables and a two-way classification. 4.2 Information Extraction from Semi-Structured Text We utilize the CMU seminar announcement corpus of Freitag (2000) consisting of emails with seminar announcements. The task is to extract four fields that describe each seminar: speaker, location, start time and end time. The corpus annotates the document with all mentions of these four fields. Sequential CRFs have been used successfully for semi-structured information extraction (Sutton and McCallum, 2005; Finkel et al., 2005). However, </context>
</contexts>
<marker>Thomas, Pang, Lee, 2006</marker>
<rawString>M. Thomas, B. Pang, and L. Lee. 2006. Get out the vote: Determining support or opposition from congressional floor-debate transcripts. In Proceedings of EMNLP, pages 327–335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vishwanathan</author>
<author>N Schraudolph</author>
<author>M Schmidt</author>
<author>K Murphy</author>
</authors>
<title>Accelerated training of conditional random fields with stochastic gradient methods.</title>
<date>2006</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>969--976</pages>
<contexts>
<context position="11621" citStr="Vishwanathan et al., 2006" startWordPosition="1867" endWordPosition="1871">um likelihood estimation (MLE): argmax log pθ(yi∗ |xi) (3) θ i The gradient of each summand log pθ(yi∗ |xi) can be computed by performing inference in two settings, one with xi, yi∗ observed and one with only the conditioning events xi observed. The gradient emerges as the difference between the feature expectations in the two cases. If exact inference is intractable, one can compute approximate feature expectations by loopy BP. Computing the approximate gradient in this way, and training the CRF with some gradient-based optimization method, has been shown to work relatively well in practice (Vishwanathan et al., 2006; Sutton and McCallum, 2005). The above method takes into account neither the loss function that will be used for evaluation, nor the approximate algorithms that have been selected for inference and decoding at test time. Other structure learning methods do consider loss, though it is not obvious how to make them consider approximations. Those include maximum margin (Taskar et al., 2003; Finley and Joachims, 2008) and softmaxmargin (Gimpel and Smith, 2010). The idea of margin-based methods is to choose weights θ~ so that the correct alternative yi∗ always gets a better score argmin Y 122 than </context>
</contexts>
<marker>Vishwanathan, Schraudolph, Schmidt, Murphy, 2006</marker>
<rawString>S. Vishwanathan, N. Schraudolph, M. Schmidt, and K. Murphy. 2006. Accelerated training of conditional random fields with stochastic gradient methods. In Proceedings of ICML, pages 969–976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wainwright</author>
</authors>
<title>Estimating the “wrong” graphical model: Benefits in the computation-limited setting.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--1829</pages>
<contexts>
<context position="2576" citStr="Wainwright (2006)" startWordPosition="395" endWordPosition="396">ocedures assume exact inference: they do not compensate for approximations that will be used at test time, and can go surprisingly awry if approximate inference is used at training time (Kulesza and Pereira, 2008). While NLP research has been consistently evolving toward more richly structured models, one may hesitate to add dependencies to a graphical model if there is a danger that this will end up hurting performance through approximations. In this paper we illustrate how to address this problem, even for extremely interconnected models in which every pair of output variables is connected. Wainwright (2006) showed that if approximate inference will be used at test time, it may be beneficial to use a learning procedure that does not converge to the true model but to one that performs well under the approximations. Stoyanov et al. (2011) argue for minimizing a certain non-convex training objective, namely the empirical risk of the entire system comprising the CRF together with whatever approximate inference and decoding procedures will be used at test time. They regard this entire system as simply a complex decision rule, analogous to a neural network, and show how to use back-propagation to tune </context>
</contexts>
<marker>Wainwright, 2006</marker>
<rawString>M. Wainwright. 2006. Estimating the “wrong” graphical model: Benefits in the computation-limited setting. Journal of Machine Learning Research, 7:1829–1859, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Williams</author>
<author>D Zipser</author>
</authors>
<title>A learning algorithm for continually running fully recurrent neural networks.</title>
<date>1989</date>
<journal>Neural Computation,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="15155" citStr="Williams and Zipser, 1989" startWordPosition="2455" endWordPosition="2458">values, and the partial derivative of the loss with respect to the result, we can compute the partial derivative of the loss with respect to the inputs to the step. Differentiating the whole complicated computation can be carried out in backward pass in this step-by-step manner as long as we record intermediate results during the computation of the function (the forward pass). At the end, we accumulate the partials of the loss with respect to each parameter θi. ERMA is similar to back-propagation used in recurrent neural networks, which involve cyclic updates like those in belief propagation (Williams and Zipser, 1989). It considers an “unrolled” version of the forward pass, in which “snapshots” of a variable at times t and t + 1 are treated as distinct variables, with one perhaps influencing the other. The forward pass computes `(δθ(xi), yi) by performing approximate inference, then decoding, then evaluation. These steps convert (xi, θ) —* marginals —* decision —* loss. The backward pass rewinds the entire computation, differentiating each phase in term. The total time required by this algorithm is roughly twice the time of the forward pass, so its complexity is comparable to approximate inference. In this</context>
</contexts>
<marker>Williams, Zipser, 1989</marker>
<rawString>R.J. Williams and D. Zipser. 1989. A learning algorithm for continually running fully recurrent neural networks. Neural Computation, 1(2):270–280.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>