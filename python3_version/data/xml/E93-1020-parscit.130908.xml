<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9873135">
A Computational Treatment of
Sentence-Final &apos;then&apos;
</title>
<author confidence="0.947593">
Sheila Glasbey
</author>
<affiliation confidence="0.99635">
Centre for Cognitive Science
Edinburgh University
</affiliation>
<sectionHeader confidence="0.6533635" genericHeader="abstract">
2 Buccleuch Place
Edinburgh EH8 9LW
UK
Abstract
</sectionHeader>
<bodyText confidence="0.999956888888889">
We describe a computational system which
parses discourses consisting of sequences of
simple sentences. These contain a range
of temporal constructions, including time
adverbials, progressive aspect and various
aspectual classes. In particular, the gram-
mar generates the required readings, accor-
ding to the theoretical analysis of (Glasbey,
forthcoming), for sentence-final &apos;then&apos;.
</bodyText>
<sectionHeader confidence="0.97731" genericHeader="method">
1 Sentence-final &apos;then&apos;
</sectionHeader>
<bodyText confidence="0.941008290322581">
It is possible to follow:
(la) Emily climbed Ben Nevis in July.
with
(lb) Fiona climbed Snowdon then.
This is interpreted to mean that each climb took
place at some time within the July in question. No-
tice, however, that if we remove &apos;in July&apos; from (la)
to give:
(lc) Emily climbed Ben Nevis.
the sequence (1c4b) becomes harder to interpret and
sounds rather odd.1 The difference is, of course, that
we have removed &apos;in July&apos; and there is no longer an
explicit reference to a &amp;quot;time&amp;quot;. We will call such an
explicitly mentioned time an explicit temporal re-
ferent (ETR). Thus, sentence-final &apos;then&apos; appears,
&apos;We are not concerned here with the rather marginal
reading, available to some speakers, where what is con-
veyed by (1c,lb) is that Fiona&apos;s climb follows Emily&apos;s.
This corresponds to the &amp;quot;updating&amp;quot; reading normally as-
sociated with sentence-initial &apos;then&apos;.
on the basis of this and other examples, to require
explicit mention of a time. Being able to infer a
time from the description of an event is clearly not
enough. We would expect to be able to infer readily
from (1c) that there was a time at which Emily&apos;s
climb took place. However, it appears that we can-
not use sentence-final &apos;then&apos; here to refer back to such
an inferred time.
In order to make sense of the sequence (1c,lb)
without the ETR., it seems we have to be able to see
the two events as connected in some way. Consider:
</bodyText>
<listItem confidence="0.9972356">
(1c) Emily climbed Ben Nevis.
(1d) She achieved her ambition then.
which sounds fine, and:
(2a) The children went to Wales.
(2b) Fiona climbed Snowdon then.
</listItem>
<bodyText confidence="0.9631405">
which is also perfectly acceptable. Note that in both
these cases the second event is readily seen as connec-
ted to the first—by the kind of discourse relation that
has often been called elaboration.2
</bodyText>
<listItem confidence="0.968278666666667">
Now consider:
(3a) John went to France.
(3b) Bill Clinton became president then.
</listItem>
<bodyText confidence="0.879867333333333">
This sequence sounds odd, presumably because it is
difficult to see any connection between the events
described in (3a) and (3b). Consider also:
</bodyText>
<listItem confidence="0.890032333333333">
(4a) John took the children to Aviemore.
(4b) Mary wrote her paper then.
which sounds odd if we do not know who Mary is,
</listItem>
<bodyText confidence="0.418469">
2See, for example, (Mann and Thompson, 1987).
</bodyText>
<page confidence="0.997463">
158
</page>
<bodyText confidence="0.999245888888889">
but sounds fine if we are told that John and Mary
are the parents and John took the children off to
Aviemore to give Mary peace and quiet to write her
paper. In other words, the sequence is acceptable if
we can envisage a connection between the events.
On the basis of these examples, it appears that
sentence-final &apos;then&apos; either requires an ETR, or there
must be some kind of connection, such as an elabo-
ration relation, between the two events.
The picture is still incomplete, however. The ex-
amples considered so far have been accomplish-
ments or achievements.3 If the second sentence
of the sequence is a lexical stative or a progressive4,
sentence-final &apos;then&apos; becomes acceptable even when
the first sentence contains no ETR and there is no
obvious connection between the eventualities.5
For example, (1c,le) and (1c,10 are both perfectly
acceptable.
</bodyText>
<listItem confidence="0.566301">
(lc) Emily climbed Ben Nevis.
(le) Fiona was a girl then.
(10 Fiona was climbing Snowdon then.
</listItem>
<bodyText confidence="0.98297535">
A detailed analysis of such sequences, which was
carried out in (Glasbey, forthcoming) and (Glasbey,
msl), reveals the importance of the notion of di-
scourse backgrounding. Provided that the se-
quence can be interpreted in such a way that the se-
cond eventuality is presented as backgrounded with
respect to the first, sentence-final &apos;then&apos; is acceptable
and the sequence (1c,le), for example, conveys that
Emily&apos;s climb is temporally included in the state of
Fiona&apos;s being a girl. A similar notion in the litera-
ture is that of the temporal overlap often conveyed
when a stative (or progressive) follows a non-stative;
see, for example, (Hinrichs, 1986). We will show in
Section 2 how the notion of discourse backgrounding
can be formalized in our theoretical framework.
We have seen, too, that sentence-final &apos;then&apos;, in the
absence of an ETR, is acceptable in cases where the
second eventuality can be seen as an elaboration of
the first. This means that we have so far identified
three uses of sentence-final &apos;then&apos;:
</bodyText>
<listItem confidence="0.973978333333334">
1. The ETR use.
2. The elaboration use.
3. The background use.
</listItem>
<bodyText confidence="0.965135142857143">
It would simplify matters if we could group (2) and
(3) together—perhaps by saying that backgrounding
is another way of expressing a connection between
two events.
In our formal analysis, to be described shortly,
which uses the situation theory/discourse represen-
tation theory (ST/DRT) framework of (Barwise and
</bodyText>
<footnote confidence="0.7485824">
3We use the terminology of (Vendler, 1967).
4 Or an iterative state or habitual state, using the ter-
minology of (Moens, 1987).
5We use this term to include events and states, as in
(Bach, 1986).
</footnote>
<bodyText confidence="0.9997947">
Cooper, forthcoming), we model eventualities as si-
tuations. We express the connection between even-
tualities by means of the situation-theoretic relation
part-of (or 1), from (Barwise, 1989). Part-of is
a relation6 which holds between situations. In or-
der for sentence-final &apos;then&apos; to be acceptable in the
absence of an ETR, the second eventuality must be
part-of the first. This intuitively covers the elabora-
tion case, in that it makes sense to think, for exam-
ple, of Fiona&apos;s climbing Snowdon as being part of the
children&apos;s trip to Wales in (2a,2b). But how does it
work in the backgrounding case? We will explain in
Section 2, when we have introduced some notation,
how the part-of analysis can be used to cover this
case too.
If we take the part-of analysis to cover both the
backgrounding and elaboration cases, we can now
say that there are two distinct uses of sentence-final
&apos;then&apos;. The first involves reference back to a pre-
viously introduced ETR and is only possible if such
an explicit referent is present. The second does not
refer to an explicit time, but rather conveys that the
second eventuality is part-of the first. This may be
the case if the second sentence is stative or progres-
sive. Of course, progressives have often been ana-
lysed as stative in the literature (for example, by
Vlach (1981)). Part of the motivation given for the
progressive-as-stative analysis concerns facts about
temporal overlap and updating. We prefer to say
that an event described in the progressive is interpre-
ted as backgrounded with respect to a previous (non-
progressive) event in the discourse.7 We thus keep
separate the notions of stativity and backgrounding,
which enables us to explore the relationship between
the two concepts.8 We adopt Smith&apos;s two-component
theory of aspect (Smith, 1991) and regard progres-
sive aspect as conveying an internal perspective or
viewpoint on the described event.
The part-of relation between eventualities may
also hold if the second eventuality can be read as
an elaboration of the first. Of course, world know-
ledge will often be required to decide this. Part-of is
therefore a relation between two eventualities which.
covers both the background and the elaboration
discourse relations.
Thus we see that sentence-final &apos;then&apos; can, if con-
ditions are right, give rise to two readings. This
is shown in sequences where the conditions for ETR.
&apos;then&apos; and those for part-of &apos;then&apos; are both fulfilled.
For example:
</bodyText>
<footnote confidence="0.930533444444445">
8In our formal treatment we will in fact treat 4 as a
type, but this is a technical detail. We will continue to
refer to the &apos;4 relation&apos; rather than the &apos;&lt;I type&apos;, as the
former conveys a clearer meaning.
7Actually there are cases where a progressive does
not convey backgrounding, but we will not discuss them
here. They involve &apos;at the same time&apos; and are discussed
in (Glasbey, msl).
&apos;See (Glasbey, msl, Glasbey, ms2) for details.
</footnote>
<page confidence="0.995731">
159
</page>
<listItem confidence="0.904117833333333">
(1a) Emily climbed Ben Nevis in July.
(1f) Fiona was climbing Snowdon then.
(1a,1f) can either mean that Fiona&apos;s climb took
place in July, or that it temporally included Emily&apos;s
climb. World knowledge or context may sometimes
favour one reading or the other.
</listItem>
<bodyText confidence="0.999671583333333">
This analysis of sentence-final &apos;then&apos; has impor-
tant consequences for theories of temporal reference.
It shows that, whatever theoretical framework is em-
ployed, it is necessary to distinguish in some way
between temporal discourse referents which are in-
troduced into the discourse via explicit mention of
a time, and those which are introduced via the in-
ference of a time from the mention of an event or
state. We explain below a means of making this di-
stinction in an ST/DRT framework, and describe a
computational implementation which embodies the
distinction.9
</bodyText>
<sectionHeader confidence="0.978455" genericHeader="method">
2 Grammar and Implementation
</sectionHeader>
<bodyText confidence="0.999908892857143">
The fragment contains sequences of sentences of a
type similar to the ones given in Section 1. It inclu-
des sentence-final &apos;then&apos;, together with other tempo-
ral adverbials such as for-adverbials, frame adverbi-
als (e.g, &apos;in July&apos;) and completive in-adverbials (e.g.,
&apos;in two hours&apos;). Sentence-initial &apos;then&apos; and sentence-
final &apos;at the time&apos; and &apos;at the same time&apos; are also
included, although we do not discuss their analysis
here. There is a range of verbs, transitive and intran-
sitive, with various aspectual characteristics, and a
range of noun types including count nouns, mass no-
uns, bare plurals, definite and indefinite NPs. Pro-
gressives are also included. We are thus concerned
not merely with the analysis of &apos;then&apos; but with mat-
ters of aspectual composition/modification and the
distribution of temporal adverbials. Space does not
permit us to describe the full system in detail. We
will concentrate here on those parts of it that are
particularly relevant to the analysis of &apos;then&apos;.
As the system is concerned with temporal matters,
we have not built into it a treatment of pronominal
anaphora. However, it is designed in such a way,
as will shortly become clear, that it could be exten-
ded without undue difficulty to include pronoun ana-
phora, using a treatment based on that in (Johnson
and Klein, 1986).
The system parses sequences of sentences and pro-
duces representations for the required readings for
</bodyText>
<footnote confidence="0.532515875">
9We discuss in (Glasbey, msl) how &apos;at the time&apos; be-
haves similarly to the part-of&apos; use of &apos;then&apos; (but conveys
only backgrounding and not elaboration), while &apos;at the
same time&apos; appears to be acceptable in cases where the
second eventuality is not a part of the first, i.e., where it
can be seen as forming a distinct or separate event. These
are also included in the implemented grammar, but their
treatment is not described here.
</footnote>
<bodyText confidence="0.999811">
sentence-final &apos;then&apos;. It is based on a situation-
theoretic grammar developed in (Cooper, 1991) and
its computational implementation ProSit (Cooper,
msl). ProSit is a definite clause grammar (DCG)
with features. It parses single sentences and con-
structs syntactic and semantic representations ex-
pressed in situation-theoretic terms. We have ex-
tended it firstly to deal with sentences containing a
range of tense and aspect constructions which were
not present in Cooper&apos;s original fragment, and se-
condly to allow the processing of discourse. To en-
able us to do the former, we have built aspectual
composition into the grammar using a theoretical
approach based upon (Krifka, 1991) and described
below. In order to process discourse, we have em-
ployed the technique known as &apos;threading&apos;, used by
Johnson and Klein (1986), whereby discourse refe-
rents are carried from left to right among the consti-
tuents of a sentence, and from one sentence to the
next.
</bodyText>
<subsectionHeader confidence="0.756538">
Extended Kamp Notation
</subsectionHeader>
<bodyText confidence="0.989575757575758">
The grammar is expressed in a combined
DRT/situation theoretic formalism, employing the
Extended Kamp Notation (EKN) developed in (Bar-
wise and Cooper, forthcoming). These authors use a
box notation for situation-theoretic objects such as
infons, situations and propositions, based upon the
graphical notation of DRT (Kamp and Reyle, forth-
coming). However, in EKN the boxes directly repre-
sent semantic objects, in contrast to DRT where the
discourse representation structures (DRSs) are ex-
pressions of a language which require interpretation
in a model. Nevertheless, EKN boxes look rather
like DRSs. One important difference, however, is
that EKN boxes may contain situations.
In situation theory, infons (which can be thought
of as items of information or &amp;quot;possible facts&amp;quot;) are
supported by situations, which are parts of the world
as individuated by agents. An infon consists of
a relationl° with its argument roles filled by ob-
jects which may be individuals, parameters or other
situation-theoretic objects. Propositions in EKN in-
clude objects of the form:
climb(X,Y)
which is the proposition that a situation S supports
an infon climb (X,Y ).11 Situation-theoretic objects
may have restrictions imposed on them. A proposi-
tion with restrictions is shown in Figure 1.
The box in Figure 1 denotes an object only if the
restrictions are true, i.e., in the above case, if X is
°Relations are primitives in situation theory.
&amp;quot;S, X and Y are parameters, denoted by capital letters
in situation theory. A parameter is a partially-specified
object.
</bodyText>
<page confidence="0.816154">
160
</page>
<figure confidence="0.862439">
climb(X,Y) named(X,`Emily&apos;)
named(Y,`Ben Nevis&apos;)
</figure>
<figureCaption confidence="0.989064">
Figure 1: An EKN restricted proposition.
</figureCaption>
<figure confidence="0.981186833333333">
Fl —&gt; 5, r2 -4 X, r3 -4 Y, r4 —* R
S
climb(X,Y)
R
named(X,`Emily&apos;)
named(Y,`Ben Nevis&apos;)
</figure>
<figureCaption confidence="0.998848">
Figure 2: An EKN proposition abstract or &apos;type.
</figureCaption>
<bodyText confidence="0.999908772727273">
anchored to an individual named &apos;Emily&apos; and Y to an
individual named &apos;Ben Nevis&apos;. R is the resource si-
tuation supporting information about the naming of
individuals.12 A proposition containing parameters
is known as a parametric proposition. It is possible
to abstract (simultaneously) over one or more para-
meters of a parametric proposition to give a type of
the form shown in Figure 2.
Once a parameter has been abstracted over, it ef-
fectively &amp;quot;disappears&amp;quot; and is no longer present in the
type. What remains is the &amp;quot;role&amp;quot; corresponding to
the abstracted parameter. These roles may be index-
ed however we choose (for example, by the natural
numbers, by r1 to rfi as above, or by utterance situa-
tions as in (Cooper, 1991)).
Cooper (ms2), in the development of situation-
theoretic DRT (STDRT), sees a DRS as equivalent
to the situation-theoretic type obtained by abstrac-
ting over the parameters of a proposition. The roles
of such a type are equivalent to DRT discourse refe-
rents, and the infons correspond to the conditions of
the &amp;quot;main&amp;quot; situation.13
</bodyText>
<subsectionHeader confidence="0.643245">
Processing of Sentences
</subsectionHeader>
<bodyText confidence="0.999083333333333">
The system parses both individual sentences and se-
quences of sentences forming a discourse. For a sen-
tence such as:
</bodyText>
<listItem confidence="0.530598">
(1c) Emily climbed Ben Nevis.
</listItem>
<bodyText confidence="0.9713795">
it produces a syntactic parse tree, together with a
semantic representation in the form of a DRS/type
as shown in Figure 3. The DRS/type is shown in
slightly simplified form here. It will also contain in-
</bodyText>
<footnote confidence="0.771442">
&apos;See (Cooper, forthcoming) for further explanation.
150f course there are no precise DRT equivalents of the
situation and the restrictions.
</footnote>
<table confidence="0.972470875">
ri -4 S, r2 —&gt; X, rs -4 Y, r4 -4 R, r5 —* T
S
climb(X,Y)
R
named(X,&apos;Emily&apos;)
named(Y,&apos;Ben Nevis&apos;)
S
occ-time(S,T)
</table>
<figureCaption confidence="0.966539">
Figure 3: DRS/type for (1c).
</figureCaption>
<bodyText confidence="0.959614926829268">
formation about aspectual class etc., as discussed be-
low.
Parsing of an individual sentence takes place
in a top-down14, left-to-right manner, causing a
DRS/type like the one in Figure 3 to be gradually
built up. The lexical entry for a verb introduces a
&amp;quot;skeletal&amp;quot; (partially instantiated) type, and further
information is added to this by the remaining con-
stituents as parsing proceeds.
Although there is no explicit mention of a &amp;quot;time&amp;quot;
in (lc), the representation for this sentence (Fi-
gure 3) contains a parameter T corresponding to
what we call the the &amp;quot;occurrence time&amp;quot; of the eventu-
ality. This is the total temporal extent of the even-
tuality. Although inclusion of the occurrence time
is not strictly necessary in the representation for a
single sentence with no ETR, it will be needed when
we come to process discourse. We will see shortly
that stative verbs do not introduce occurrence-times
into the representations, whereas non-stative ones
do, unless they are presented with progressive as-
pect.
Now compare the representation produced for the
sentence:
(la) Emily climbed Ben Nevis in July.
In this case, the system produces the DRS/type&apos;
shown in Figure 4.
Here we have a second temporal parameter T&apos;, cor-
responding to to the explicit temporal referent &apos;July&apos;.
Note that the role corresponding to this parameter
is indexed by &apos;pr&apos;. This indicates that this time refe-
rent, unlike the one corresponding to T, is phonolo-
gically realised in the utterance. This distinction will
be important when we come to process &apos;then&apos;. Here
we are exploiting the possibility afforded by situation
theory of being able to include information about the
utterance in our semantic representations.15
&amp;quot;However, top-down processing is not essential to the
grammar, and a left-corner parser or chart parser could
be used instead.
&apos;5We have not taken the trouble here to mark non-
</bodyText>
<page confidence="0.933682">
161
</page>
<table confidence="0.9814825">
ri .-+ S, r2 -+ X, r3 -&gt; Y, r.1 -&gt; R, r5 -) T, jr6,pr] T&apos;
S
climb(X,Y)
R
named(X,`Emily&apos;)
named(Y,&apos;Ben Nevis&apos;)
named(T&apos;,`July&apos;)
S
T CT&apos;
occ-time(S,T)
</table>
<figureCaption confidence="0.686267">
Figure 4: DRS/type for (la),
</figureCaption>
<figure confidence="0.428545">
The box:
T C T&apos;
</figure>
<figureCaption confidence="0.4997758">
is another kind of EKN proposition—one that does
not involve a situation. It expresses the information
that T and T&apos; are of type C, where this is a type
of two times such that the second includes or equals
the first.
</figureCaption>
<subsectionHeader confidence="0.721405">
Processing of Discourse
</subsectionHeader>
<bodyText confidence="0.977275375">
Now let us consider the semantic representation for
a discourse. This consists of a proposition which is
the conjunction of the propositions introduced by the
individual sentences. Abstraction is carried out over
the conjoined proposition as a whole, giving a list of
discourse referents/roles for the discourse processed
up to a given point.
Thus for (1a,1g):
</bodyText>
<listItem confidence="0.810338375">
(1a) Emily climbed Ben Nevis in July.
(1g) Fiona climbed Snowdon.
we get the representation shown in Figure 5.16
Now let us consider the processing of discourse se-
quences containing sentence-final &apos;then&apos;. Consider
(1a,lb):
(la) Emily climbed Ben Nevis in July.
(lb) Fiona climbed Snowdon then.
</listItem>
<bodyText confidence="0.989463530612245">
The system parses (la), followed by (lb) as far as
&apos;then&apos;. At this point in processing, the representa-
tion built so far is that of Figure 5. The processing
temporal discourse referents as phonologically realised,
as this is not relevant to the analysis of `then&apos;—but it
could of course be done.
&apos;The representation for (1a4g) will also contain in-
formation about possible discourse relations between the
two eventualities. We do not describe this feature of the
system here except where it is relevant to &apos;then&apos;.
of &apos;then&apos; causes the rules for ETR &apos;then&apos; and part-
of &apos;then&apos; to be invoked in turn. The rule for ETR.
&apos;then&apos; causes the system to &amp;quot;look for&amp;quot; a temporal re-
ferent indexed &apos;pr&apos; in the list of discourse referents
introduced by the processing of the discourse up to
this point. This list of discourse referents is threaded
from one sentence to the next (and from NP to VP
within a sentence). In fact, what is threaded is not
just the discourse referents but the overall DRS/type
from the processing of the discourse up to this point.
The threading is achieved at discourse level by means
of the top-level rule of the grammar:
dis(dis(SBar, Dis)),In, Out) --&gt;
sbar(SBar,Type,...,In,Med),
dis(Dis,Med,Out).
The first argument to the predicate `dis&apos; is respon-
sible for building the tree structure associated with
the parse. The second and third arguments, the Pro-
log variables &apos;In&apos; and &apos;Out&apos;, enable threading of dis-
course referents from the sentence just parsed to the
remaining discourse. The input &apos;In&apos; to the proces-
sing of sbar consists of the overall DRS/type built
up from processing the discourse up to this point.
This includes a list of discourse referents generated
so far. The grammar rules at sbar level and below
cause the overall DRS/type to be updated to give a
new type &apos;Med&apos;, which is the input DRS/type to the
processing of the remainder of the discourse. The
&apos;Type&apos; argument of sbar is the DRS/type obtained
from parsing that individual sentence. The other ar-
guments to sbar are not relevant to this discussion
and have thus been omitted.
Thus, at a given point in processing of discourse,
the system can look for a temporal referent indexed
&apos;pr&apos;. Looking at Figure 5, we see that an appropriate
temporal referent indexed &apos;pr&apos; is present. The rule
for ETR &apos;then&apos; therefore succeeds, and a proposition
is introduced to the effect that T2 is temporally in-
cluded in T&apos;, i.e.
</bodyText>
<page confidence="0.992698">
162
</page>
<figureCaption confidence="0.7276565">
ri -4 SI, r2 X r3 Y, 1•4 -4 R1, r6 -4 T1, r6 -4 S2, T7 U, r8 V, 1&apos;9 -4 R2, rio T2, rii —&gt; T&apos;
Figure 5: Slightly simplified representation for (1a4g) and for (1a,lb) at the point of processing &apos;then&apos;.
</figureCaption>
<figure confidence="0.992079833333333">
Si
climb(X,Y)
named(X,&apos;Emily&apos;)
named(Y,&apos;Ben Nevis&apos;)
named(T&apos;,`July&apos;)
occ-time(SI,Ti)
S2
climb(U,V)
R2
named(U,&apos;Daniel&apos;)
named(V,&apos;Snowdon&apos;)
occ-time(S2, T2)
</figure>
<page confidence="0.897114">
163
</page>
<equation confidence="0.392107">
T2 C T&apos;
</equation>
<bodyText confidence="0.999865129032258">
This proposition is added to the restrictions of the
lower box of Figure 5, to give the completed repre-
sentation for (1a,lb), which is not shown here for
reasons of space. If there had been no such temporal
referent marked &apos;pr&apos; present, the rule for ETR &apos;then&apos;
would have failed.
Now consider the part-of reading for &apos;then&apos;.
We saw earlier that this requires an appro-
priate discourse relation between the two described
eventualities—one of either backgrounding or ela-
boration. Testing for whether an elaboration re-
lation is possible requires world knowledge, and we
have not attempted to build any of this into the sy-
stem, although there appears to be no reason why
this could not be done. The system in its present
form therefore checks only for the background in-
stance of the part-of relation.
Backgrounding is possible if the second eventua-
lity is either a state or if it is presented with pro-
gressive viewpoint. This means that, in order to
test for backgrounding, the representations for indi-
vidual sentences must contain information about the
aspectual properties of the described eventualities—
for example, whether an eventuality is a state or a
non-state (event), and whether it is presented with
simple aspect (external viewpoint) or progressive as-
pect (internal viewpoint). It is widely known that
the aspectual properties of a described eventuality
depend on certain properties of the verb17 and also
on other elements such as the referents of NP argu-
ments. For example, the event described by:
</bodyText>
<listItem confidence="0.76691225">
(5) Daniel climbed a mountain.
is a Vendler accomplishment. Alternatively, we may
characterise it in Krifka&apos;s terms as having the pro-
perty +Q (quantized) or —CUM (non-cumulative),
which are equivalent to the lack of a natural end-
point or culmination. However, the event described
by:
(6) Daniel climbed mountains.
</listItem>
<bodyText confidence="0.993391172413793">
is a Vendler activity, and in Krifka&apos;s terms has the
property —Q/+CUM. Here we see what Krifka de-
scribes as a &amp;quot;mapping&amp;quot; from the properties of the NP
object&apos; to the properties of the event. The referent
of &apos;a mountain&apos; is +Q, and so is the event of (5). The
referent of &apos;mountains&apos; is —Q, and so is the event of
(6). Such mapping from the properties of the object
to the properties of the event only occurs for certain
verbs, however—those where what Krifka calls the
&amp;quot;E.g. &apos;basic aspectual type&apos; in Moens&apos; terms (Moens,
1987) and semantic features in both Verkuyl&apos;s (1989) and
Krifka&apos;s (1991) accounts.
18More strictly the &amp;quot;patient&amp;quot;, as it is thematic roles
and not grammatical roles that are important here.
&amp;quot;thematic relation&amp;quot; between the object and the event
has an appropriate property. One such property that
enables this mapping is what he calls gradual pati-
ent. In such cases, there is an intuitive relationship
between the &amp;quot;progress&amp;quot; of the object and the pro-
gress of the event. For example, in an eating event,
the object is gradually consumed, and in a writing
event, the object is gradually created. Both &apos;eat&apos; and
&apos;write&apos;, as well as &apos;climb&apos; thus have thematic relati-
ons with the property gradual patient. Driving
events do not, on the other hand, exhibit this corre-
spondence between the progress of the event and the
progress of the object. Thus the thematic relation
between object and event for &apos;drive&apos; does not have
the gradual patient property, which explains why:
</bodyText>
<listItem confidence="0.842945">
(7) John drove the car.
</listItem>
<bodyText confidence="0.976515428571428">
is +CUM/—Q even though &apos;the car&apos; is —CUM/+Q.19
In our EKN account we encode Krifka&apos;s properties
of thematic relations as types of situations and in-
dividuals. For example, the lexical entry for &apos;climb&apos;
includes the following information:
climb(X,Y) 8, Y I
GRAD-PAT
The grammar rules then make reference to this in-
formation. For example, the rule:
vbar( ....) --&gt; v( ) , np( )
contains a procedure which evaluates the Q-value of
the predicate (vbar) according to the following algo-
rithm:
If: The thematic relation between S and Y is of type
GRAD-PAT
Then: Set the Q-value of the predicate (vbar) to be
the same as that of Y
Otherwise: Set the Q-value of the predicate to —Q.
The Q-value of the agent2° also affects that of the
described eventuality. For example, the eventuality
described by:
</bodyText>
<listItem confidence="0.832031333333333">
(8) Emily climbed the mountain.
is +Q, whereas that described by:
(9) People climbed the mountain.
is —Q. In (9), the —Q value of the agent is transferred
to the event. In order to deal with such examples,
the rule
</listItem>
<equation confidence="0.545219">
s(...) --&gt; np(...), vp(...)
</equation>
<footnote confidence="0.997847">
18A. well-known test for the property +CUM/ —Q of
predicates is the ability to combine with a for-adverbial.
20Corresponding to the grammatical subject in these
active sentences.
</footnote>
<page confidence="0.989018">
164
</page>
<table confidence="0.894939857142857">
ri .- S, r2 -&gt; X, r3 -4 R
S
girl(X)
R
named(X,Tional
S
STATE
</table>
<figureCaption confidence="0.991389">
Figure 6: Representation for (le) at the point of pro-
cessing &apos;then&apos;.
</figureCaption>
<bodyText confidence="0.9830804">
contains a similar algorithm to the one in the vbar
rule.
Thus the representation constructed by parsing a
sentence includes information about the aspectual
properties of the described eventuality. These in-
clude the features +/-STATE and +/-Q as already
described, together with +/-PROG depending on
whether or not progressive aspect is present, and
+/-PUNCT which distinguishes punctual and non-
punctual events (corresponding to the difference bet-
ween achievements and accomplishments).
Let us now consider the representation from the
processing of:
(le) Fiona was a girl then.
up to the point where &apos;then&apos; is reached. This is given
(in slightly simplified form) in Figure 6.
Now suppose we are processing (1c,le):
(lc) Emily climbed Ben Nevis.
(le) Fiona was a girl then.
The rule for part-of &apos;then&apos; requires that the se-
cond eventuality is either a state or it is described
with progressive viewpoint. The former is true in
this case, so the conditions for part-of &apos;then&apos; are
satisfied. The representation obtained for (1c,le) is
shown in Figure 7.
</bodyText>
<subsectionHeader confidence="0.955589">
The semantics of `part-of&apos;
</subsectionHeader>
<bodyText confidence="0.999984363636364">
What exactly does it mean for the part-of (1) re-
lation to hold between two eventualities? The idea
is that if S2 &lt;I S1, then any infon which is suppor-
ted by S2 is also supported by Si. In other words,
S2 adds further information to Si, causing it to be
more fully specified. Here we exploit the partiality
of situation theory. Situations may be only parti-
ally specified: if we say that Si supports a, this does
not tell us anything about what other information
Si does or does not support. It is thus possible for
a later utterance to add further information about
Si and thereby specify it more fully. If the first ut-
terance tells us that Si supports the infon a, and the
second tells us that S2 supports the infon r and also
that S2 &lt;I Si, then we know that Si supports both
cr and r. This is straightforward enough for the ela-
boration case. We need to consider carefully what it
means in a backgrounding case such as (1a,le).
According to our theoretical analysis, if an even-
tuality is backgrounded then it does not introduce
an occurrence-time of its own. Instead, the backgro-
unded eventuality is of the same duration as that of
the preceding event—it &amp;quot;takes on&amp;quot; the time of that
event.21 Thus, in the representation of (1c,le) in Fi-
gure 7, the backgrounded S2 has the same temporal
extent as the event Si. This amounts to claiming
that (le) describes only the part of the state that
coincides with the preceding event. Of course we
know that the state of Fiona&apos;s being a girl began
before and continues after Emily&apos;s climb—there is a
relationship of temporal inclusion between the &amp;quot;to-
tal duration&amp;quot; of the state and the event. But we are
saying that those parts of the state that are before
and after the event are not described but are infer-
red from our world knowledge about the duration of
such states.
Stative verbs are &amp;quot;natural backgrounders&amp;quot; in that
they describe eventualities without making reference
to the beginning and end points of the eventuality.
They naturally describe a situation which can rea-
dily be seen as a temporal &amp;quot;slice&amp;quot; of a more prolon-
ged situation. For this reason, in the lexical entries
for stative verbs in our grammar, there is no men-
tion of the occurrence-time of the state. Progressives
usually behave in a similar way. When an event de-
scribed with progressive viewpoint follows one with
simple (perfective) viewpoint, the relation between
them is normally one of backgrounding. The effect of
progressive viewpoint is to present the event from an
internal perspective. An event described with inter-
nal perspective is no longer temporally bounded—it
does not have an occurrence-time of its own. Instead,
its duration is that of the preceding event, just as in
the stative case.
If we define two instances of the part-of relation:
</bodyText>
<listItem confidence="0.961513333333333">
• 4 bg for the backgrounding case
• &lt;I el for the elaboration case
we can thus say:
</listItem>
<note confidence="0.408829">
S2 &lt;I bg S1 T2 = Ti
</note>
<bodyText confidence="0.864699875">
where T1 , T2 are the temporal durations of Si and
S2 respectively. And:
S2 4 ei Si 4 T2 C Ti
Thus, for the general .4 relation:
S2 4 Si —+ T2 C T1
&apos;Evidence for this comes from an analysis of &apos;at the
time&apos; and &apos;at the same time&apos;. See (Glasbey, ms2) for
details.
</bodyText>
<page confidence="0.997252">
165
</page>
<figureCaption confidence="0.999353">
Figure 7: Representation for (1c, le).
</figureCaption>
<figure confidence="0.993892583333333">
ri SI, r2 X, r3 Y, r4 —&gt; R1, r5 -3 T1, r6 -+ S2 U, r8 -4 R2
Si
climb(X,Y)
R1
named(X,&apos;Emily&apos;)
named(Y,`Ben Nevis&apos;)
occ-time(Si ,
52
STATE
S2 4 Si
named(U,Tional
girl(U)
</figure>
<bodyText confidence="0.844212222222222">
Finally, let us consider (la, if):
(la) Emily climbed Ben Nevis in July.
(1f) Fiona was climbing Snowdon then.
In this case, an ETR is present and the second sen-
tence has progressive aspect. This means that the
conditions for both ETR &apos;then&apos; and part-of &apos;then&apos;
are met.Our grammar will thus cause two represen-
tations to be generated for (1a,lf), corresponding to
the two readings that we identified in Section 1.
</bodyText>
<sectionHeader confidence="0.999225" genericHeader="method">
3 General remarks
</sectionHeader>
<subsectionHeader confidence="0.995721">
3.1 Further Developments
</subsectionHeader>
<bodyText confidence="0.999993285714286">
The system parses sequences of any length, keeping
track of all the discourse referents/roles introduced
so far. Thus, as it stands at present, it will find a
temporal referent for &apos;then&apos;, irrespective of how far
back in the discourse that referent was introduced.
It may be desirable to refine this in some way—for
example, to disallow anaphoric reference to an ETR
that is more than a certain &amp;quot;distance&amp;quot; back in the
discourse. Also, the system at present finds only
the most recently introduce temporal referent. This
could easily be modified—for example, in order to
allow it to produce a set of alternatives. However, it
appears that we would need to take discourse struc-
ture into account here.
</bodyText>
<subsectionHeader confidence="0.49266">
3.2 Relation to other accounts of temporal
</subsectionHeader>
<bodyText confidence="0.986496074074074">
reference
It is important to consider how our analysis fits with
other work on temporal reference in discourse, and
how readily our treatment of &apos;then&apos; could be incorpo-
rated into these accounts. Kamp and Reyle (forth-
coming) present a DRT fragment which deals with
temporal reference but does not include &apos;then&apos;. In
(Glasbey, forthcoming) and (Glasbey, 1992) we pre-
sent a modification of Kamp and Reyle&apos;s fragment
which incorporates our analysis of &apos;then&apos;. We make
the necessary distinction between what we call &amp;quot;ex-
plicit&amp;quot; and &amp;quot;inferred&amp;quot; times by allowing a temporal
referent to be introduced only when an explicit tem-
poral referent is present. If there is no ETR, only an
event referent may be introduced. This enables us to
produce the correct readings for &apos;then&apos;. We consider
the ST/DRT account given in the present paper to
be preferable, however, in that situation theory al-
lows us to express information about the utterance
in a way that traditional DRT does not. This enables
us to make precisely the distinction we need between
whether or not a particular referent was phonologi-
cally realised in the utterance.
Lascarides and Asher (1991) present an account of
temporal reference where discourse relations between
eventualities are deduced by means of defeasible rea-
soning. Their account is expressed in a version of
</bodyText>
<page confidence="0.995437">
166
</page>
<bodyText confidence="0.99977">
DRT and preliminary investigations suggest that it
could be extended to include &apos;then&apos; in a similar way
to the Kamp and Reyle fragment.
</bodyText>
<sectionHeader confidence="0.998873" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999983833333333">
We have developed a computational grammar which
parses discourse consisting of sequences of simple
sentences containing a range of tense and aspect con-
structions. In particular, it generates the required
readings for sentence-final &apos;then&apos;. We have also in-
dicated how our analysis of &apos;then&apos; could be incorpo-
rated into some existing DRT accounts of temporal
reference. The system appears to be capable of va-
rious refinements involving more detailed theories of
discourse structure, and as such may provide a basis
for development of more extensive systems for dis-
course analysis.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999364">
I would like to thank Robin Cooper, Max Cresswell,
Elisabet Engdahl, Martin Mellor and Marc Moens
for helpful advice and comments on this work.
</bodyText>
<sectionHeader confidence="0.999053" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999814860465116">
[Bach, 1986] Emmon Bach. The algebra of events.
Linguistics and Philosophy, 9:5-16, 1986.
[Barwise, 1989] Jon Barwise. The Situation in Logic.
CSLI, Stanford, California, 1989.
[Barwise and Cooper, forthcoming] Jon Barwise
and Robin Cooper. Extended Kamp Notation:
a graphical notation for situation theory. In P.
Aczel, D. Israel, Y. Katagiri and S. Peters (eds.)
Situation Theory and its Applications, Vol. 3.
CSLI, Stanford, California, 1993.
[Cooper, 1991] Robin Cooper. Three lectures on si-
tuation theoretic grammar. In Natural Language
Processing. Proceedings of 2nd Advanced School
in Artificial Intelligence, Guarda, Portugal, Oc-
tober 8-12, 1990. In series: Lecture Notes in
Artificial Intelligence, Miguel Filgueiras (ed.).
Springer Verlag, Berlin, London, 1991.
[Cooper, forthcoming] Robin Cooper. Generalized
quantifiers and resource situations. In P. Ac-
zel, D. Israel, Y. Katagiri and S. Peters (eds.)
Situation Theory and its Applications, Vol. 3.
CSLI, Stanford, California, 1993.
[Cooper, msl] Robin Cooper. Introduction to Situa-
tion Semantics. Edinburgh University, Depart-
ment of AT and Centre for Cognitive Science. In
preparation.
[Cooper, ms2] Robin Cooper. Situation theoretic di-
scourse representation theory. Centre for Cogni-
tive Science and Human Communication Rese-
arch Centre, Edinburgh University, 1992. In pre-
paration.
[Glasbey, 1992] Sheila Glasbey. Sentence-final
&apos;then&apos;: a formal analysis. Edinburgh Research
Papers in Cognitive Science, Centre for Cogni-
tive Science, Edinburgh University, 1992.
[Glasbey, forthcoming] Sheila Glasbey. Events and
times: the semantics of &apos;then&apos;. To appear in a
forthcoming issue of Natural Language Seman-
tics, 1993.
[Glasbey, rnsl] Sheila Glasbey. Event Structure in
Natural Language Discourse. PhD thesis, Edin-
burgh University. In preparation.
[Glasbey, ms2] Sheila Glasbey. A formal analysis of
&apos;the X&apos; and &apos;the same X&apos; in discourse. Centre
for Cognitive Science, Edinburgh University. In
preparation.
[Hinrichs, 1986] Erhard Hinrichs. Temporal ana-
phora in discourses of English. Linguistics and
Philosophy, 9:63-82, 1986.
[Johnson and Klein, 1986] Mark Johnson and Ewan
Klein. Discourse, anaphora and parsing. In Pro-
ceedings of the 11th COLING, 669-675, 1986.
[Kamp and Reyle, forthcoming] Hans Kamp and
Uwe Reyle. From Discourse to Logic. Kluwer
Academic Publishers, Dordrecht, 1993.
[Krifka, 1991] Manfred Krifka. Thematic relations
as links between nominal reference and tem-
poral constitution. In Ivan Sag and Anna Sa-
bolcsi (eds.), Lexical Matters, Chicago Univer-
sity Press, 1991.
[Lascarides and Asher, 1991] Alex Lascarides and
Nicholas Asher. Discourse relations and com-
monsense entailment. In Hans Kamp (ed.), De-
fault Logics for Linguistic Analysis, Dyana De-
liverable R2.5B, 1991.
[Mann and Thompson, 1987] W.C. Mann and S.A.
Thompson. Rhetorical Structure Theory: A
theory of text organization. Technical Report
RR/87/190, Information Sciences Institute, Ma-
rina del Rey, California, 1987.
[Moens, 1987] Marc Moens. Tense, Aspect and Tem-
poral Reference. Unpublished Ph.D. thesis,
Edinburgh University, 1987.
[Smith, 1991] Carlota Smith. The Parameter of As-
pect. Kluwer Academic Publishers, Dordrecht,
1991.
[Vendler, 1967] Zeno Vendler. Verbs and times. In
Linguistics in Philosophy, Chapter 4, pages 97-
121. Cornell University Press, Ithaca, NY, 1967.
[Verkuyl, 1989] Henk Verkuyl. Aspectual classes and
aspectual composition. Linguistics and Philoso-
phy, 12:39-94, 1989.
[Vlach, 1981] Frank Vlach. The semantics of the
progressive. In P. Tedeschi and A. Zaenen (eds.),
Syntax and Semantics, Vol.14: Tense and As-
pect. Academic Press, New York, 1981.
</reference>
<page confidence="0.997762">
167
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000070">
<title confidence="0.9527925">A Computational Treatment of Sentence-Final &apos;then&apos;</title>
<author confidence="0.997557">Sheila Glasbey</author>
<affiliation confidence="0.851723666666667">Centre for Cognitive Science Edinburgh University 2 Buccleuch Place</affiliation>
<address confidence="0.758068">Edinburgh EH8 9LW UK</address>
<abstract confidence="0.989105511904764">We describe a computational system which parses discourses consisting of sequences of simple sentences. These contain a range of temporal constructions, including time adverbials, progressive aspect and various aspectual classes. In particular, the grammar generates the required readings, according to the theoretical analysis of (Glasbey, forthcoming), for sentence-final &apos;then&apos;. 1 Sentence-final &apos;then&apos; It is possible to follow: (la) Emily climbed Ben Nevis in July. with (lb) Fiona climbed Snowdon then. This is interpreted to mean that each climb took place at some time within the July in question. Notice, however, that if we remove &apos;in July&apos; from (la) to give: (lc) Emily climbed Ben Nevis. the sequence (1c4b) becomes harder to interpret and rather The difference is, of course, that we have removed &apos;in July&apos; and there is no longer an explicit reference to a &amp;quot;time&amp;quot;. We will call such an explicitly mentioned time an explicit temporal referent (ETR). Thus, sentence-final &apos;then&apos; appears, are not here with the rather marginal reading, available to some speakers, where what is conveyed by (1c,lb) is that Fiona&apos;s climb follows Emily&apos;s. This corresponds to the &amp;quot;updating&amp;quot; reading normally associated with sentence-initial &apos;then&apos;. the basis this and other examples, to require explicit mention of a time. Being able to infer a time from the description of an event is clearly not enough. We would expect to be able to infer readily from (1c) that there was a time at which Emily&apos;s climb took place. However, it appears that we cannot use sentence-final &apos;then&apos; here to refer back to such an inferred time. In order to make sense of the sequence (1c,lb) the seems we have to be able to see the two events as connected in some way. Consider: (1c) Emily climbed Ben Nevis. (1d) She achieved her ambition then. which sounds fine, and: (2a) The children went to Wales. (2b) Fiona climbed Snowdon then. which is also perfectly acceptable. Note that in both these cases the second event is readily seen as connected to the first—by the kind of discourse relation that often been called Now consider: (3a) John went to France. (3b) Bill Clinton became president then. This sequence sounds odd, presumably because it is difficult to see any connection between the events described in (3a) and (3b). Consider also: (4a) John took the children to Aviemore. (4b) Mary wrote her paper then. which sounds odd if we do not know who Mary is, for example, (Mann and Thompson, 1987). 158 but sounds fine if we are told that John and Mary are the parents and John took the children off to Aviemore to give Mary peace and quiet to write her paper. In other words, the sequence is acceptable if we can envisage a connection between the events. On the basis of these examples, it appears that &apos;then&apos; either requires an there must be some kind of connection, such as an elaboration relation, between the two events. The picture is still incomplete, however. The exconsidered so far have been accomplish- If the second sentence the sequence is a lexical stative or a sentence-final &apos;then&apos; becomes acceptable even when first sentence contains no there is no connection between the For example, (1c,le) and (1c,10 are both perfectly acceptable. (lc) Emily climbed Ben Nevis. (le) Fiona was a girl then. Fiona was climbing then. detailed analysis such sequences, which out in (Glasbey, and (Glasbey, the importance of the notion of dibackgrounding. Provided the sequence can be interpreted in such a way that the second eventuality is presented as backgrounded with respect to the first, sentence-final &apos;then&apos; is acceptable and the sequence (1c,le), for example, conveys that Emily&apos;s climb is temporally included in the state of Fiona&apos;s being a girl. A similar notion in the literature is that of the temporal overlap often conveyed when a stative (or progressive) follows a non-stative; see, for example, (Hinrichs, 1986). We will show in Section 2 how the notion of discourse backgrounding can be formalized in our theoretical framework. We have seen, too, that sentence-final &apos;then&apos;, in the of an is in cases the second eventuality can be seen as an elaboration of the first. This means that we have so far identified three uses of sentence-final &apos;then&apos;: The 2. The elaboration use. 3. The background use. It would simplify matters if we could group (2) and (3) together—perhaps by saying that backgrounding is another way of expressing a connection between two events. In our formal analysis, to be described shortly, which uses the situation theory/discourse representation theory (ST/DRT) framework of (Barwise and use the terminology of (Vendler, 1967). 4Or an iterative state or habitual state, using the terminology of (Moens, 1987). term to include events and states, as in (Bach, 1986). Cooper, forthcoming), we model eventualities as siexpress the connection between evenby of the situation-theoretic relation (or 1), from (Barwise, 1989). which holds between In or- &apos;then&apos; to be acceptable in the of an second eventuality must be part-of the first. This intuitively covers the elaborathat it makes sense to think, for example, of Fiona&apos;s climbing Snowdon as being part of the children&apos;s trip to Wales in (2a,2b). But how does it work in the backgrounding case? We will explain in when we have introduced some notation, the analysis can be used to cover this case too. we take part-of analysis to cover both the and elaboration can say that there are two distinct uses of sentence-final The first involves reference back a preintroduced is only possible if such an explicit referent is present. The second does not refer to an explicit time, but rather conveys that the eventuality is first. This may be the case if the second sentence is stative or progressive. Of course, progressives have often been analysed as stative in the literature (for example, by Vlach (1981)). Part of the motivation given for the progressive-as-stative analysis concerns facts about temporal overlap and updating. We prefer to say that an event described in the progressive is interpreted as backgrounded with respect to a previous (nonevent in the We thus keep separate the notions of stativity and backgrounding, which enables us to explore the relationship between two We adopt Smith&apos;s two-component theory of aspect (Smith, 1991) and regard progressive aspect as conveying an internal perspective or viewpoint on the described event. between eventualities may also hold if the second eventuality can be read as an elaboration of the first. Of course, world knowwill often be required to decide this. a relation between two eventualities both the the discourse relations. we sentence-final &apos;then&apos; can, if conditions are right, give rise to two readings. This shown in sequences where the conditions for and those are both fulfilled. For example: our treatment we will in fact treat 4 as a is a technical detail. We will continue to refer to the &apos;4 relation&apos; rather than the &apos;&lt;I type&apos;, as the former conveys a clearer meaning. there are cases where a progressive does not convey backgrounding, but we will not discuss them here. They involve &apos;at the same time&apos; and are discussed in (Glasbey, msl). &apos;See (Glasbey, msl, Glasbey, ms2) for details. 159 (1a) Emily climbed Ben Nevis in July. (1f) Fiona was climbing Snowdon then. (1a,1f) can either mean that Fiona&apos;s climb took place in July, or that it temporally included Emily&apos;s climb. World knowledge or context may sometimes favour one reading or the other. This analysis of sentence-final &apos;then&apos; has important consequences for theories of temporal reference. It shows that, whatever theoretical framework is employed, it is necessary to distinguish in some way between temporal discourse referents which are introduced into the discourse via explicit mention of a time, and those which are introduced via the inference of a time from the mention of an event or state. We explain below a means of making this distinction in an ST/DRT framework, and describe a computational implementation which embodies the 2 Grammar and Implementation The fragment contains sequences of sentences of a type similar to the ones given in Section 1. It includes sentence-final &apos;then&apos;, together with other temporal adverbials such as for-adverbials, frame adverbials (e.g, &apos;in July&apos;) and completive in-adverbials (e.g., &apos;in two hours&apos;). Sentence-initial &apos;then&apos; and sentencefinal &apos;at the time&apos; and &apos;at the same time&apos; are also included, although we do not discuss their analysis here. There is a range of verbs, transitive and intransitive, with various aspectual characteristics, and a range of noun types including count nouns, mass nouns, bare plurals, definite and indefinite NPs. Progressives are also included. We are thus concerned not merely with the analysis of &apos;then&apos; but with matters of aspectual composition/modification and the distribution of temporal adverbials. Space does not permit us to describe the full system in detail. We will concentrate here on those parts of it that are particularly relevant to the analysis of &apos;then&apos;. As the system is concerned with temporal matters, we have not built into it a treatment of pronominal anaphora. However, it is designed in such a way, as will shortly become clear, that it could be extended without undue difficulty to include pronoun anaphora, using a treatment based on that in (Johnson and Klein, 1986). The system parses sequences of sentences and produces representations for the required readings for in (Glasbey, msl) how &apos;at the time&apos; behaves similarly to the part-of&apos; use of &apos;then&apos; (but conveys only backgrounding and not elaboration), while &apos;at the same time&apos; appears to be acceptable in cases where the second eventuality is not a part of the first, i.e., where it can be seen as forming a distinct or separate event. These are also included in the implemented grammar, but their treatment is not described here. sentence-final &apos;then&apos;. It is based on a situationtheoretic grammar developed in (Cooper, 1991) and its computational implementation ProSit (Cooper, msl). ProSit is a definite clause grammar (DCG) with features. It parses single sentences and constructs syntactic and semantic representations expressed in situation-theoretic terms. We have extended it firstly to deal with sentences containing a range of tense and aspect constructions which were not present in Cooper&apos;s original fragment, and secondly to allow the processing of discourse. To enable us to do the former, we have built aspectual composition into the grammar using a theoretical approach based upon (Krifka, 1991) and described below. In order to process discourse, we have employed the technique known as &apos;threading&apos;, used by Johnson and Klein (1986), whereby discourse referents are carried from left to right among the constituents of a sentence, and from one sentence to the next. Extended Kamp Notation The grammar is expressed in a combined DRT/situation theoretic formalism, employing the Extended Kamp Notation (EKN) developed in (Barwise and Cooper, forthcoming). These authors use a box notation for situation-theoretic objects such as infons, situations and propositions, based upon the graphical notation of DRT (Kamp and Reyle, forthcoming). However, in EKN the boxes directly represent semantic objects, in contrast to DRT where the discourse representation structures (DRSs) are expressions of a language which require interpretation in a model. Nevertheless, EKN boxes look rather like DRSs. One important difference, however, is that EKN boxes may contain situations. In situation theory, infons (which can be thought of as items of information or &amp;quot;possible facts&amp;quot;) are supported by situations, which are parts of the world as individuated by agents. An infon consists of a relationl° with its argument roles filled by objects which may be individuals, parameters or other situation-theoretic objects. Propositions in EKN include objects of the form: climb(X,Y) is the proposition that a situation infon climb (X,Y Situation-theoretic objects may have restrictions imposed on them. A proposition with restrictions is shown in Figure 1. The box in Figure 1 denotes an object only if the restrictions are true, i.e., in the above case, if X is are primitives in theory. &amp;quot;S, X and Y are parameters, denoted by capital letters in situation theory. A parameter is a partially-specified object. 160 climb(X,Y) named(X,`Emily&apos;) named(Y,`Ben Nevis&apos;) Figure 1: An EKN restricted proposition. —&gt; 5, r2 r3 r4 —* R S climb(X,Y) R named(X,`Emily&apos;) named(Y,`Ben Nevis&apos;) Figure 2: An EKN proposition abstract or &apos;type. anchored to an individual named &apos;Emily&apos; and Y to an individual named &apos;Ben Nevis&apos;. R is the resource situation supporting information about the naming of A proposition containing parameters is known as a parametric proposition. It is possible to abstract (simultaneously) over one or more parameters of a parametric proposition to give a type of the form shown in Figure 2. Once a parameter has been abstracted over, it effectively &amp;quot;disappears&amp;quot; and is no longer present in the type. What remains is the &amp;quot;role&amp;quot; corresponding to the abstracted parameter. These roles may be indexed however we choose (for example, by the natural by r1 to as above, or by utterance situations as in (Cooper, 1991)). Cooper (ms2), in the development of situationtheoretic DRT (STDRT), sees a DRS as equivalent to the situation-theoretic type obtained by abstracting over the parameters of a proposition. The roles of such a type are equivalent to DRT discourse referents, and the infons correspond to the conditions of &amp;quot;main&amp;quot; Processing of Sentences The system parses both individual sentences and sequences of sentences forming a discourse. For a sentence such as: (1c) Emily climbed Ben Nevis. it produces a syntactic parse tree, together with a semantic representation in the form of a DRS/type as shown in Figure 3. The DRS/type is shown in simplified form here. It will also contain in- &apos;See (Cooper, forthcoming) for further explanation. course there are no precise DRT equivalents of the situation and the restrictions. -4 S, r2 —&gt; X, rs -4 Y, r4 -4 R, r5 —* T S climb(X,Y) R named(X,&apos;Emily&apos;) named(Y,&apos;Ben Nevis&apos;) S occ-time(S,T) Figure 3: DRS/type for (1c). about aspectual etc., as discussed below. Parsing of an individual sentence takes place a left-to-right manner, causing a DRS/type like the one in Figure 3 to be gradually built up. The lexical entry for a verb introduces a &amp;quot;skeletal&amp;quot; (partially instantiated) type, and further information is added to this by the remaining constituents as parsing proceeds. Although there is no explicit mention of a &amp;quot;time&amp;quot; in (lc), the representation for this sentence (Figure 3) contains a parameter T corresponding to what we call the the &amp;quot;occurrence time&amp;quot; of the eventuality. This is the total temporal extent of the eventuality. Although inclusion of the occurrence time is not strictly necessary in the representation for a sentence with no it needed when come to process discourse. We will that stative verbs do not introduce occurrence-times into the representations, whereas non-stative ones do, unless they are presented with progressive aspect. Now compare the representation produced for the sentence: (la) Emily climbed Ben Nevis in July. In this case, the system produces the DRS/type&apos; shown in Figure 4. Here we have a second temporal parameter T&apos;, corresponding to to the explicit temporal referent &apos;July&apos;. Note that the role corresponding to this parameter is indexed by &apos;pr&apos;. This indicates that this time referent, unlike the one corresponding to T, is phonologically realised in the utterance. This distinction will be important when we come to process &apos;then&apos;. Here we are exploiting the possibility afforded by situation theory of being able to include information about the in our semantic &amp;quot;However, top-down processing is not essential to the grammar, and a left-corner parser or chart parser could be used instead. have not taken the trouble here to mark non- 161 S, r2 X, r3 r.1 -&gt; R, r5 -) jr6,pr] S climb(X,Y) R named(X,`Emily&apos;) named(Y,&apos;Ben Nevis&apos;) named(T&apos;,`July&apos;) S T CT&apos; occ-time(S,T) Figure 4: DRS/type for (la), The box: T C T&apos; is another kind of EKN proposition—one that does not involve a situation. It expresses the information that T and T&apos; are of type C, where this is a type of two times such that the second includes or equals the first. Processing of Discourse let consider the semantic representation for a discourse. This consists of a proposition which is the conjunction of the propositions introduced by the individual sentences. Abstraction is carried out over the conjoined proposition as a whole, giving a list of discourse referents/roles for the discourse processed up to a given point. Thus for (1a,1g): (1a) Emily climbed Ben Nevis in July. (1g) Fiona climbed Snowdon. get the representation shown in Figure Now let us consider the processing of discourse sequences containing sentence-final &apos;then&apos;. Consider (1a,lb): (la) Emily climbed Ben Nevis in July. (lb) Fiona climbed Snowdon then. The system parses (la), followed by (lb) as far as &apos;then&apos;. At this point in processing, the representabuilt so far is that of Figure processing referents as phonologically realised, as this is not relevant to the analysis of `then&apos;—but it could of course be done. &apos;The representation for (1a4g) will also contain information about possible discourse relations between the two eventualities. We do not describe this feature of the system here except where it is relevant to &apos;then&apos;. &apos;then&apos; causes the rules for and part- &apos;then&apos; to be invoked in turn. The rule for &apos;then&apos; causes the system to &amp;quot;look for&amp;quot; a temporal referent indexed &apos;pr&apos; in the list of discourse referents introduced by the processing of the discourse up to this point. This list of discourse referents is threaded from one sentence to the next (and from NP to VP within a sentence). In fact, what is threaded is not just the discourse referents but the overall DRS/type from the processing of the discourse up to this point. The threading is achieved at discourse level by means of the top-level rule of the grammar: dis(dis(SBar, Dis)),In, Out) --&gt; sbar(SBar,Type,...,In,Med), dis(Dis,Med,Out). The first argument to the predicate `dis&apos; is responsible for building the tree structure associated with parse. The second and third arguments, Prolog variables &apos;In&apos; and &apos;Out&apos;, enable threading of discourse referents from the sentence just parsed to the remaining discourse. The input &apos;In&apos; to the processing of sbar consists of the overall DRS/type built up from processing the discourse up to this point. This includes a list of discourse referents generated so far. The grammar rules at sbar level and below cause the overall DRS/type to be updated to give a new type &apos;Med&apos;, which is the input DRS/type to the processing of the remainder of the discourse. The &apos;Type&apos; argument of sbar is the DRS/type obtained from parsing that individual sentence. The other arguments to sbar are not relevant to this discussion and have thus been omitted. Thus, at a given point in processing of discourse, the system can look for a temporal referent indexed Looking at Figure we that an appropriate temporal referent indexed &apos;pr&apos; is present. The rule therefore succeeds, and a proposition introduced to the effect that temporally included in T&apos;, i.e. 162 r2 X r3 Y, -4 R1, r6 S2, T7 U, V, -4 R2, —&gt; T&apos; Figure 5: Slightly simplified representation for (1a4g) and for (1a,lb) at the point of processing &apos;then&apos;. Si climb(X,Y) named(X,&apos;Emily&apos;) named(Y,&apos;Ben Nevis&apos;) named(T&apos;,`July&apos;) occ-time(SI,Ti) S2 climb(U,V) R2 named(U,&apos;Daniel&apos;) named(V,&apos;Snowdon&apos;) 163 T&apos; This proposition is added to the restrictions of the lower box of Figure 5, to give the completed representation for (1a,lb), which is not shown here for reasons of space. If there had been no such temporal marked &apos;pr&apos; present, the rule for would have failed. consider the for &apos;then&apos;. We saw earlier that this requires an appropriate discourse relation between the two described of either elafor whether an elaboration relation is possible requires world knowledge, and we have not attempted to build any of this into the system, although there appears to be no reason why this could not be done. The system in its present therefore checks only for the inpart-of Backgrounding is possible if the second eventuality is either a state or if it is presented with progressive viewpoint. This means that, in order to test for backgrounding, the representations for individual sentences must contain information about the aspectual properties of the described eventualities— for example, whether an eventuality is a state or a non-state (event), and whether it is presented with simple aspect (external viewpoint) or progressive aspect (internal viewpoint). It is widely known that the aspectual properties of a described eventuality on certain properties of the and also on other elements such as the referents of NP arguments. For example, the event described by: (5) Daniel climbed a mountain. is a Vendler accomplishment. Alternatively, we may it in terms as having property +Q (quantized) or —CUM (non-cumulative), which are equivalent to the lack of a natural endpoint or culmination. However, the event described by: (6) Daniel climbed mountains. is a Vendler activity, and in Krifka&apos;s terms has the property —Q/+CUM. Here we see what Krifka describes as a &amp;quot;mapping&amp;quot; from the properties of the NP object&apos; to the properties of the event. The referent of &apos;a mountain&apos; is +Q, and so is the event of (5). The referent of &apos;mountains&apos; is —Q, and so is the event of (6). Such mapping from the properties of the object to the properties of the event only occurs for certain verbs, however—those where what Krifka calls the aspectual type&apos; in Moens&apos; terms (Moens, 1987) and semantic features in both Verkuyl&apos;s (1989) and Krifka&apos;s (1991) accounts. strictly the &amp;quot;patient&amp;quot;, as it is thematic roles and not grammatical roles that are important here. &amp;quot;thematic relation&amp;quot; between the object and the event has an appropriate property. One such property that this mapping is what he calls patisuch cases, there is an intuitive relationship between the &amp;quot;progress&amp;quot; of the object and the progress of the event. For example, in an eating event, the object is gradually consumed, and in a writing event, the object is gradually created. Both &apos;eat&apos; and &apos;write&apos;, as well as &apos;climb&apos; thus have thematic relatiwith the property patient. do the other hand, exhibit this correspondence between the progress of the event and the progress of the object. Thus the thematic relation between object and event for &apos;drive&apos; does not have patient which explains why: (7) John drove the car. +CUM/—Q even though &apos;the car&apos; is In our EKN account we encode Krifka&apos;s properties thematic relations as types of and individuals. For example, the lexical entry for &apos;climb&apos; includes the following information: climb(X,Y) 8,Y GRAD-PAT The grammar rules then make reference to this information. For example, the rule: ....) --&gt; v( ) , ) a procedure evaluates the Q-value of predicate (vbar) according the following algorithm: thematic relation between S Y is of type GRAD-PAT the Q-value of the (vbar) to be the same as that of Y Otherwise: Set the Q-value of the predicate to —Q. Q-value of the also affects that of the described eventuality. For example, the eventuality described by: (8) Emily climbed the mountain. whereas that described by: (9) People climbed the mountain. is —Q. In (9), the —Q value of the agent is transferred to the event. In order to deal with such examples, the rule s(...) --&gt; np(...), vp(...) well-known test for the property +CUM/ predicates is the ability to combine with a for-adverbial. to the grammatical subject in these active sentences. 164 .- S, r2 -&gt; X, r3 -4 R S girl(X) R named(X,Tional S STATE Figure 6: Representation for (le) at the point of processing &apos;then&apos;. contains a similar algorithm to the one in the vbar rule. Thus the representation constructed by parsing a sentence includes information about the aspectual properties of the described eventuality. These include the features +/-STATE and +/-Q as already described, together with +/-PROG depending on whether or not progressive aspect is present, and +/-PUNCT which distinguishes punctual and nonpunctual events (corresponding to the difference between achievements and accomplishments). Let us now consider the representation from the processing of: (le) Fiona was a girl then. up to the point where &apos;then&apos; is reached. This is given (in slightly simplified form) in Figure 6. Now suppose we are processing (1c,le): (lc) Emily climbed Ben Nevis. (le) Fiona was a girl then. The rule for part-of &apos;then&apos; requires that the second eventuality is either a state or it is described with progressive viewpoint. The former is true in this case, so the conditions for part-of &apos;then&apos; are satisfied. The representation obtained for (1c,le) is shown in Figure 7. The semantics of `part-of&apos; What exactly does it mean for the part-of (1) relation to hold between two eventualities? The idea that if &lt;I S1, any is supporby also supported by Si. In other words, further information to Si, causing it to be more fully specified. Here we exploit the partiality of situation theory. Situations may be only partispecified: if we say that supports does not tell us anything about what other information does or does not support. It is thus possible for a later utterance to add further information about Si and thereby specify it more fully. If the first uttells us that Si supports the infon the tells us that the infon r and also S2 &lt;I then we know that Si supports both r. This is straightforward enough for the elaboration case. We need to consider carefully what it means in a backgrounding case such as (1a,le). According to our theoretical analysis, if an eventuality is backgrounded then it does not introduce an occurrence-time of its own. Instead, the backgrounded eventuality is of the same duration as that of the preceding event—it &amp;quot;takes on&amp;quot; the time of that Thus, in the representation of (1c,le) in Fi- 7, the backgrounded the temporal extent as the event Si. This amounts to claiming that (le) describes only the part of the state that coincides with the preceding event. Of course we know that the state of Fiona&apos;s being a girl began before and continues after Emily&apos;s climb—there is a relationship of temporal inclusion between the &amp;quot;total duration&amp;quot; of the state and the event. But we are saying that those parts of the state that are before and after the event are not described but are inferred from our world knowledge about the duration of such states. Stative verbs are &amp;quot;natural backgrounders&amp;quot; in that they describe eventualities without making reference to the beginning and end points of the eventuality. They naturally describe a situation which can readily be seen as a temporal &amp;quot;slice&amp;quot; of a more prolonged situation. For this reason, in the lexical entries for stative verbs in our grammar, there is no mention of the occurrence-time of the state. Progressives usually behave in a similar way. When an event described with progressive viewpoint follows one with simple (perfective) viewpoint, the relation between them is normally one of backgrounding. The effect of progressive viewpoint is to present the event from an internal perspective. An event described with internal perspective is no longer temporally bounded—it does not have an occurrence-time of its own. Instead, its duration is that of the preceding event, just as in the stative case. we define two instances of the 4 for the backgrounding case &lt;I for the elaboration case we can thus say:</abstract>
<note confidence="0.783587">lt;I S1 T2 = Ti , are the temporal durations of Si and And: ei 4 C Ti Thus, for the general .4 relation: Si C T1 for comes from an analysis of &apos;at the time&apos; and &apos;at the same time&apos;. See (Glasbey, ms2) for details. 165 Figure 7: Representation for (1c, le). SI, X, r3 Y, r4 R1, T1, -+ r8</note>
<abstract confidence="0.992045076923077">climb(X,Y) named(X,&apos;Emily&apos;) occ-time(Si , 52 STATE 4 named(U,Tional girl(U) Finally, let us consider (la, if): (la) Emily climbed Ben Nevis in July. (1f) Fiona was climbing Snowdon then. this case, an present and the second sentence has progressive aspect. This means that the for both part-of &apos;then&apos; are met.Our grammar will thus cause two representations to be generated for (1a,lf), corresponding to the two readings that we identified in Section 1. 3 General remarks 3.1 Further Developments The system parses sequences of any length, keeping track of all the discourse referents/roles introduced so far. Thus, as it stands at present, it will find a temporal referent for &apos;then&apos;, irrespective of how far back in the discourse that referent was introduced. It may be desirable to refine this in some way—for to disallow anaphoric reference to an that is more than a certain &amp;quot;distance&amp;quot; back in the discourse. Also, the system at present finds only the most recently introduce temporal referent. This could easily be modified—for example, in order to allow it to produce a set of alternatives. However, it appears that we would need to take discourse structure into account here. 3.2 Relation to other accounts of temporal reference It is important to consider how our analysis fits with other work on temporal reference in discourse, and how readily our treatment of &apos;then&apos; could be incorporated into these accounts. Kamp and Reyle (forthcoming) present a DRT fragment which deals with temporal reference but does not include &apos;then&apos;. In (Glasbey, forthcoming) and (Glasbey, 1992) we present a modification of Kamp and Reyle&apos;s fragment which incorporates our analysis of &apos;then&apos;. We make the necessary distinction between what we call &amp;quot;explicit&amp;quot; and &amp;quot;inferred&amp;quot; times by allowing a temporal referent to be introduced only when an explicit temreferent is present. If there is no an event referent may be introduced. This enables us to produce the correct readings for &apos;then&apos;. We consider the ST/DRT account given in the present paper to be preferable, however, in that situation theory allows us to express information about the utterance in a way that traditional DRT does not. This enables us to make precisely the distinction we need between whether or not a particular referent was phonologically realised in the utterance. Lascarides and Asher (1991) present an account of temporal reference where discourse relations between eventualities are deduced by means of defeasible reasoning. Their account is expressed in a version of 166 DRT and preliminary investigations suggest that it could be extended to include &apos;then&apos; in a similar way to the Kamp and Reyle fragment. 4 Conclusion We have developed a computational grammar which parses discourse consisting of sequences of simple sentences containing a range of tense and aspect constructions. In particular, it generates the required readings for sentence-final &apos;then&apos;. We have also indicated how our analysis of &apos;then&apos; could be incorporated into some existing DRT accounts of temporal reference. The system appears to be capable of various refinements involving more detailed theories of discourse structure, and as such may provide a basis for development of more extensive systems for discourse analysis.</abstract>
<note confidence="0.911320222222222">Acknowledgments I would like to thank Robin Cooper, Max Cresswell, Elisabet Engdahl, Martin Mellor and Marc Moens for helpful advice and comments on this work. References [Bach, 1986] Emmon Bach. The algebra of events. 1986. 1989] Jon Barwise. Situation in Logic. CSLI, Stanford, California, 1989.</note>
<title confidence="0.818172">[Barwise and Cooper, forthcoming] Jon Barwise</title>
<author confidence="0.834416">Extended Kamp Notation</author>
<note confidence="0.969957">a graphical notation for situation theory. In P. Aczel, D. Israel, Y. Katagiri and S. Peters (eds.) Situation Theory and its Applications, Vol. 3. CSLI, Stanford, California, 1993. [Cooper, 1991] Robin Cooper. Three lectures on sitheoretic grammar. In Language of 2nd Advanced School in Artificial Intelligence, Guarda, Portugal, October 8-12, 1990. In series: Lecture Notes in Artificial Intelligence, Miguel Filgueiras (ed.). Springer Verlag, Berlin, London, 1991. [Cooper, forthcoming] Robin Cooper. Generalized quantifiers and resource situations. In P. Aczel, D. Israel, Y. Katagiri and S. Peters (eds.) Situation Theory and its Applications, Vol. 3. CSLI, Stanford, California, 1993.</note>
<title confidence="0.355438">msl] Robin Cooper. to Situa-</title>
<affiliation confidence="0.8182135">Semantics. University, Department of AT and Centre for Cognitive Science. In</affiliation>
<abstract confidence="0.8440835">preparation. [Cooper, ms2] Robin Cooper. Situation theoretic discourse representation theory. Centre for Cognitive Science and Human Communication Research Centre, Edinburgh University, 1992. In preparation. [Glasbey, 1992] Sheila Glasbey. Sentence-final &apos;then&apos;: a formal analysis. Edinburgh Research Papers in Cognitive Science, Centre for Cognitive Science, Edinburgh University, 1992. [Glasbey, forthcoming] Sheila Glasbey. Events and times: the semantics of &apos;then&apos;. To appear in a issue of Language Semanrnsl] Sheila Glasbey. Structure in Language Discourse. thesis, Edinburgh University. In preparation. [Glasbey, ms2] Sheila Glasbey. A formal analysis of &apos;the X&apos; and &apos;the same X&apos; in discourse. Centre for Cognitive Science, Edinburgh University. In preparation.</abstract>
<note confidence="0.959871853658537">[Hinrichs, 1986] Erhard Hinrichs. Temporal anain discourses of English. and 1986. [Johnson and Klein, 1986] Mark Johnson and Ewan Discourse, anaphora and parsing. In Proof the 11th COLING, 1986. [Kamp and Reyle, forthcoming] Hans Kamp and Reyle. Discourse to Logic. Academic Publishers, Dordrecht, 1993. [Krifka, 1991] Manfred Krifka. Thematic relations as links between nominal reference and temporal constitution. In Ivan Sag and Anna Sa- (eds.), Matters, University Press, 1991. [Lascarides and Asher, 1991] Alex Lascarides and Nicholas Asher. Discourse relations and comentailment. In Hans Kamp (ed.), De- Logics for Linguistic Analysis, Deliverable R2.5B, 1991. [Mann and Thompson, 1987] W.C. Mann and S.A. Thompson. Rhetorical Structure Theory: A theory of text organization. Technical Report RR/87/190, Information Sciences Institute, Marina del Rey, California, 1987. 1987] Marc Moens. Aspect and Tem- Reference. Ph.D. thesis, Edinburgh University, 1987. 1991] Carlota Smith. Parameter of As- Academic Publishers, Dordrecht, 1991. [Vendler, 1967] Zeno Vendler. Verbs and times. In in Philosophy, 4, pages 97- 121. Cornell University Press, Ithaca, NY, 1967. [Verkuyl, 1989] Henk Verkuyl. Aspectual classes and composition. and Philoso- 1989. [Vlach, 1981] Frank Vlach. The semantics of the progressive. In P. Tedeschi and A. Zaenen (eds.), Syntax and Semantics, Vol.14: Tense and As- Press, New York, 1981. 167</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Emmon Bach</author>
</authors>
<title>The algebra of events.</title>
<date>1986</date>
<journal>Linguistics and Philosophy,</journal>
<pages>9--5</pages>
<marker>[Bach, 1986]</marker>
<rawString>Emmon Bach. The algebra of events. Linguistics and Philosophy, 9:5-16, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Barwise</author>
</authors>
<title>The Situation in Logic.</title>
<date>1989</date>
<location>CSLI, Stanford, California,</location>
<marker>[Barwise, 1989]</marker>
<rawString>Jon Barwise. The Situation in Logic. CSLI, Stanford, California, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Barwise</author>
<author>Robin Cooper</author>
</authors>
<title>Extended Kamp Notation: a graphical notation for situation theory.</title>
<date>1993</date>
<booktitle>Situation Theory and its Applications,</booktitle>
<volume>3</volume>
<editor>In P. Aczel, D. Israel, Y. Katagiri and S. Peters (eds.)</editor>
<location>California,</location>
<marker>[Barwise and Cooper, forthcoming]</marker>
<rawString>Jon Barwise and Robin Cooper. Extended Kamp Notation: a graphical notation for situation theory. In P. Aczel, D. Israel, Y. Katagiri and S. Peters (eds.) Situation Theory and its Applications, Vol. 3. CSLI, Stanford, California, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Three lectures on situation theoretic grammar.</title>
<date>1990</date>
<booktitle>In Natural Language Processing. Proceedings of 2nd Advanced School in Artificial Intelligence,</booktitle>
<editor>(ed.).</editor>
<publisher>Springer Verlag,</publisher>
<location>Guarda, Portugal,</location>
<marker>[Cooper, 1991]</marker>
<rawString>Robin Cooper. Three lectures on situation theoretic grammar. In Natural Language Processing. Proceedings of 2nd Advanced School in Artificial Intelligence, Guarda, Portugal, October 8-12, 1990. In series: Lecture Notes in Artificial Intelligence, Miguel Filgueiras (ed.). Springer Verlag, Berlin, London, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Generalized quantifiers and resource situations.</title>
<date>1993</date>
<booktitle>Situation Theory and its Applications,</booktitle>
<volume>3</volume>
<editor>In P. Aczel, D. Israel, Y. Katagiri and S. Peters (eds.)</editor>
<location>California,</location>
<marker>[Cooper, forthcoming]</marker>
<rawString>Robin Cooper. Generalized quantifiers and resource situations. In P. Aczel, D. Israel, Y. Katagiri and S. Peters (eds.) Situation Theory and its Applications, Vol. 3. CSLI, Stanford, California, 1993.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Introduction to Situation Semantics.</title>
<institution>Edinburgh University, Department of AT and Centre for Cognitive Science. In preparation.</institution>
<marker>[Cooper, msl]</marker>
<rawString>Robin Cooper. Introduction to Situation Semantics. Edinburgh University, Department of AT and Centre for Cognitive Science. In preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Situation theoretic discourse representation theory.</title>
<date>1992</date>
<institution>Centre for Cognitive Science and Human Communication Research Centre, Edinburgh University,</institution>
<note>In preparation.</note>
<marker>[Cooper, ms2]</marker>
<rawString>Robin Cooper. Situation theoretic discourse representation theory. Centre for Cognitive Science and Human Communication Research Centre, Edinburgh University, 1992. In preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheila Glasbey</author>
</authors>
<title>Sentence-final &apos;then&apos;: a formal analysis. Edinburgh Research Papers in Cognitive Science,</title>
<date>1992</date>
<institution>Centre for Cognitive Science, Edinburgh University,</institution>
<marker>[Glasbey, 1992]</marker>
<rawString>Sheila Glasbey. Sentence-final &apos;then&apos;: a formal analysis. Edinburgh Research Papers in Cognitive Science, Centre for Cognitive Science, Edinburgh University, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheila Glasbey</author>
</authors>
<title>Events and times: the semantics of &apos;then&apos;. To appear in a forthcoming issue of Natural Language Semantics,</title>
<date>1993</date>
<marker>[Glasbey, forthcoming]</marker>
<rawString>Sheila Glasbey. Events and times: the semantics of &apos;then&apos;. To appear in a forthcoming issue of Natural Language Semantics, 1993.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sheila Glasbey</author>
</authors>
<title>Event Structure in Natural Language Discourse.</title>
<tech>PhD thesis,</tech>
<institution>Edinburgh University. In preparation.</institution>
<marker>[Glasbey, rnsl]</marker>
<rawString>Sheila Glasbey. Event Structure in Natural Language Discourse. PhD thesis, Edinburgh University. In preparation.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sheila Glasbey</author>
</authors>
<title>A formal analysis of &apos;the X&apos; and &apos;the same X&apos; in discourse.</title>
<institution>Centre for Cognitive Science, Edinburgh University. In preparation.</institution>
<marker>[Glasbey, ms2]</marker>
<rawString>Sheila Glasbey. A formal analysis of &apos;the X&apos; and &apos;the same X&apos; in discourse. Centre for Cognitive Science, Edinburgh University. In preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erhard Hinrichs</author>
</authors>
<title>Temporal anaphora in discourses of English.</title>
<date>1986</date>
<journal>Linguistics and Philosophy,</journal>
<pages>9--63</pages>
<marker>[Hinrichs, 1986]</marker>
<rawString>Erhard Hinrichs. Temporal anaphora in discourses of English. Linguistics and Philosophy, 9:63-82, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Ewan Klein</author>
</authors>
<title>Discourse, anaphora and parsing.</title>
<date>1986</date>
<booktitle>In Proceedings of the 11th COLING,</booktitle>
<pages>669--675</pages>
<marker>[Johnson and Klein, 1986]</marker>
<rawString>Mark Johnson and Ewan Klein. Discourse, anaphora and parsing. In Proceedings of the 11th COLING, 669-675, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic.</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht,</location>
<marker>[Kamp and Reyle, forthcoming]</marker>
<rawString>Hans Kamp and Uwe Reyle. From Discourse to Logic. Kluwer Academic Publishers, Dordrecht, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Krifka</author>
</authors>
<title>Thematic relations as links between nominal reference and temporal constitution.</title>
<date>1991</date>
<booktitle>In Ivan Sag and Anna Sabolcsi (eds.), Lexical Matters,</booktitle>
<publisher>Chicago University Press,</publisher>
<marker>[Krifka, 1991]</marker>
<rawString>Manfred Krifka. Thematic relations as links between nominal reference and temporal constitution. In Ivan Sag and Anna Sabolcsi (eds.), Lexical Matters, Chicago University Press, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Lascarides</author>
<author>Nicholas Asher</author>
</authors>
<title>Discourse relations and commonsense entailment.</title>
<date>1991</date>
<booktitle>Default Logics for Linguistic Analysis, Dyana Deliverable R2.5B,</booktitle>
<editor>In Hans Kamp (ed.),</editor>
<marker>[Lascarides and Asher, 1991]</marker>
<rawString>Alex Lascarides and Nicholas Asher. Discourse relations and commonsense entailment. In Hans Kamp (ed.), Default Logics for Linguistic Analysis, Dyana Deliverable R2.5B, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: A theory of text organization.</title>
<date>1987</date>
<tech>Technical Report RR/87/190,</tech>
<institution>Information Sciences Institute, Marina del Rey,</institution>
<location>California,</location>
<marker>[Mann and Thompson, 1987]</marker>
<rawString>W.C. Mann and S.A. Thompson. Rhetorical Structure Theory: A theory of text organization. Technical Report RR/87/190, Information Sciences Institute, Marina del Rey, California, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Moens</author>
</authors>
<title>Tense, Aspect and Temporal Reference. Unpublished Ph.D. thesis,</title>
<date>1987</date>
<institution>Edinburgh University,</institution>
<marker>[Moens, 1987]</marker>
<rawString>Marc Moens. Tense, Aspect and Temporal Reference. Unpublished Ph.D. thesis, Edinburgh University, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlota Smith</author>
</authors>
<title>The Parameter of Aspect.</title>
<date>1991</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht,</location>
<marker>[Smith, 1991]</marker>
<rawString>Carlota Smith. The Parameter of Aspect. Kluwer Academic Publishers, Dordrecht, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeno Vendler</author>
</authors>
<title>Verbs and times.</title>
<date>1967</date>
<booktitle>In Linguistics in Philosophy, Chapter 4,</booktitle>
<pages>97--121</pages>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, NY,</location>
<marker>[Vendler, 1967]</marker>
<rawString>Zeno Vendler. Verbs and times. In Linguistics in Philosophy, Chapter 4, pages 97-121. Cornell University Press, Ithaca, NY, 1967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henk Verkuyl</author>
</authors>
<title>Aspectual classes and aspectual composition.</title>
<date>1989</date>
<journal>Linguistics and Philosophy,</journal>
<pages>12--39</pages>
<marker>[Verkuyl, 1989]</marker>
<rawString>Henk Verkuyl. Aspectual classes and aspectual composition. Linguistics and Philosophy, 12:39-94, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Vlach</author>
</authors>
<title>The semantics of the progressive.</title>
<date>1981</date>
<booktitle>Syntax and Semantics, Vol.14: Tense and Aspect.</booktitle>
<editor>In P. Tedeschi and A. Zaenen (eds.),</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>[Vlach, 1981]</marker>
<rawString>Frank Vlach. The semantics of the progressive. In P. Tedeschi and A. Zaenen (eds.), Syntax and Semantics, Vol.14: Tense and Aspect. Academic Press, New York, 1981.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>