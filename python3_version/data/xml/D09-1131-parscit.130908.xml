<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.996485">
Using Morphological and Syntactic Structures
for Chinese Opinion Analysis
</title>
<author confidence="0.998915">
Lun-Wei Ku Ting-Hao Huang Hsin-Hsi Chen
</author>
<affiliation confidence="0.995546">
Department of Computer Science and Information Engineering
National Taiwan University
</affiliation>
<address confidence="0.989811">
No. 1, Sec. 4, Roosevelt Road, Taipei, 10617 Taiwan
</address>
<email confidence="0.999561">
{lwku,thhuang}@nlg.csie.ntu.edu.tw;hhchen@ntu.edu.tw
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999958105263158">
This paper employs morphological struc-
tures and relations between sentence seg-
ments for opinion analysis on words and
sentences. Chinese words are classified
into eight morphological types by two
proposed classifiers, CRF classifier and
SVM classifier. Experiments show that
the injection of morphological information
improves the performance of the word po-
larity detection. To utilize syntactic struc-
tures, we annotate structural trios to repre-
sent relations between sentence segments.
Experiments show that considering struc-
tural trios is useful for sentence opinion
analysis. The best f-score achieves 0.77
for opinion word extraction, 0.62 for opin-
ion word polarity detection, 0.80 for opin-
ion sentence extraction, and 0.54 for opin-
ion sentence polarity detection.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99954194117647">
Sentiment analysis has attracted much attention
in recent years because a large scale of subjective
information is disseminated through various plat-
forms on the web. Sentiment information can be
applied to a wide variety of fields, including
product recommendation, review summarization,
public polling, and so on.
Opinion dictionaries are important resources
for identifying subjective information. Several
approaches were proposed to collect such re-
sources. Wiebe (2000) learned subjective adjec-
tives from corpora. Takamura et al. (2005) ex-
tracted semantic orientations of words. Ku et al.
(2007) measured sentiment degrees of Chinese
words by averaging the sentiment scores of the
composing characters. When the opinion words
are available, the polarities of sentences and
documents can be determined by them. Riloff
and Wiebe (2003) learned the extraction patterns
for subjective expressions. Kim and Hovy (2004)
found the polarity of subjective expressions.
Pang et al. (2002) and Dave et al. (2003) ex-
plored various techniques at document level.
Morphological information has been widely
used in classifying words, telling the meanings,
and doing other in-depth analysis (Tzeng and
Chen, 2002). However, morphological informa-
tion was seldom applied either in Chinese opin-
ion extraction, or in solving the coverage prob-
lem of opinion dictionary. Instead of bag-of-
characters approach (Ku et al., 2007), this paper
employs morphological structures of words to
extract opinion words.
Relations between sentence segments are also
defined by linguistics in the Chinese language.
These are similar to morphological structures
between Chinese characters. Based on parsing
trees of sentences, we identify these relations and
utilize them for opinion analysis on sentences.
As the experimental corpus, some researchers
managed to generate annotated materials and
gold standards under many constraints. Ku set a
standard for generating final answers from anno-
tations of multiple annotators (Ku et al., 2007),
and Somasundaran annotated discourse informa-
tion from meeting dialogs to train a sentiment
model (Somasundaran et al., 2007). For multi-
lingual issues, researchers concerned mainly
about the applicability of corpus and algorithms
from the native language to foreign languages
(Banea et al., 2008; Bautin et al., 2008).
</bodyText>
<footnote confidence="0.7535685">
Several opinion analysis systems have been
developed so far. OASYS (Cesarano et al., 2007)
and CopeOpi (Ku et al., 2007) allow users input
their queries and select preferred data sources,
</footnote>
<page confidence="0.796546">
1260
</page>
<note confidence="0.996615">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1260–1269,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9999251875">
and then track opinions in a time zone. For both
systems, extracting opinions is the main focus,
while holders and targets are identified implicitly
when retrieving relevant documents. Carenini’s
team proposed a graphical user interface for
evaluative texts (2006), in which color blocks
were used to present the evaluations for compo-
nents of products. Fair News Reader, a Japanese
news Web system, incorporates sentiment infor-
mation insensibly in an interesting way (Kawai
et al., 2007). It provides readers “balanced” re-
ports by analyzing the sentiment in news articles
which readers have read, and suggests them new
articles according to the analysis results. It leads
the application of opinion analysis to the direc-
tion of personalization.
</bodyText>
<sectionHeader confidence="0.990435" genericHeader="method">
2 Chinese Morphological Structures
</sectionHeader>
<bodyText confidence="0.99994388">
In the Chinese language, a word is composed of
one or more Chinese characters, and its meaning
can be interpreted in terms of its composite char-
acters. The morphological structures of Chinese
words are formulated by three major processes in
linguistics: compounding, affixation, and conver-
sion. Compounding is a complex word-
formation process. In most cases, two or more
morphemes together are formed as a lexical item
by this process. Affixation is a morphological
process, by which grammatical or lexical infor-
mation is added to a base form. By the conver-
sion process, a word is changed from one part of
speech into another without the addition or dele-
tion of any morphemes.
Compounding is the most productive way to
construct a Chinese word. Mostly, a Chinese
character itself carries meanings, so that a mor-
pheme can function as a character and has its
own part of speech. In some cases, a Chinese
morpheme may carry no specific meaning and
just makes a word more readable. Cheng and
Tian (1992) divided Chinese words into five
morphological types based on the relations be-
tween the morphemes in compounding words.
</bodyText>
<listItem confidence="0.927725">
(1) Parallel Type: Two morphemes play coordi-
nate roles in a word. For example, the mor-
phemes “財” (money) and “富” (wealth) are par-
allel in the word “財富” (money-wealth).
(2) Substantive-Modifier Type: A modified
morpheme follows a modifying morpheme. For
example, the morpheme “哭” (cry) is modified
by “痛” (bitterly) in the word ”痛哭” (bitterly-
cry).
(3) Subjective-Predicate Type: One morpheme
is an expresser and the other one is described.
The structure is like a subject-verb sentence con-
densed in one word. For example, the morpheme
“心” (heart) is a subject of the predicate “疼”
(hurt) in the word “心疼” (heart-hurt).
(4) Verb-Object Type: The first morpheme is
usually a verb which governs the second one,
making this word similar to a verb followed by
its object. For example, the morpheme “控”
(control) serves as the object of the verb “失”
(lose) in the word ”失控” (lose-control).
(5) Verb-Complement Type: The first mor-
pheme is usually a verb but sometimes can be an
adjective, and the second morpheme explains the
first one from different aspects. For example, the
morpheme “清” (clearly) expresses the aspects of
the action “看” (look).
</listItem>
<bodyText confidence="0.999657181818182">
Chinese words constructed by affixation proc-
ess can be one of the two cases – say, morpheme
and morpheme, or morpheme and non-morpheme.
In the case of morpheme and morpheme, the af-
fixation word belongs to one of the above 5 types
if the prefix and the suffix are neither negations
nor confirmations. Types 6 and 7 defined below
represent the affixation words whose prefix or
suffix is a negation or a confirmation. The af-
fixation words whose prefix or suffix characters
are not morphemes are classified into type 8.
</bodyText>
<listItem confidence="0.9960105">
(6) Negation Type: There is at least one nega-
tion character in words of this type. For example,
the prefix “無” (no) is the negation morpheme in
the word ”無法” (no-method).
(7) Confirmation Type: There is at least one
confirmation character in words of this type. For
example, the prefix “有” (do) is a confirmation
in the word “有賴” (do-depend on).
(8) Others: Those words that do not belong to
the above seven types are assigned to this type,
such as words whose meanings are not a function
of their composite characters, words whose com-
posite characters are not morphemes, such as “姪
子” (nephew-suffix) and “薄荷” (peppermint).
</listItem>
<sectionHeader confidence="0.97463" genericHeader="method">
3 Opinion Scores of Chinese Words
</sectionHeader>
<bodyText confidence="0.999746833333333">
The bag-of-characters approach proposed by Ku
et al. (2007) considers the observation probabili-
ties of characters in Chinese opinion words. It
calculates the observation probabilities of char-
acters from a set of seeds first, then dynamically
enlarges the set and adjusts their probabilities. In
</bodyText>
<page confidence="0.982819">
1261
</page>
<bodyText confidence="0.999457">
this approach, the opinion score of a word is de-
termined by the combination of the observation
probabilities of its composite characters defined
by Formulas (1) and (2).
</bodyText>
<equation confidence="0.9836865">
n
f C, pos / f C
( ) ( i
∑
</equation>
<bodyText confidence="0.999547571428571">
word is negative, else it is positive. For example,
the word “rX” (bitterly cry) is composed of
“r” (bitterly, negative) and “X” (cry, negative).
Negative characters make this word negative and
its opinion strength, i.e., the absolute value of the
score, is decided by the first character for the
degree of crying.
</bodyText>
<equation confidence="0.971268615384615">
P(C, pos) = i=1 n m
f (C, pos)/∑f
+ ∑
( ) ( ) (
C , pos f C, neg / f C
i i
(1)
, neg)
)
,pos
i =1 i=1
m
, neg)
</equation>
<figure confidence="0.957052104166667">
f
(Ci
if ( ( ) 0 and ( ) 0) then
S C ≠ S C ≠
1
(C, neg)/∑f
if
( ( )
S C 1
&gt; 0 and ( )
S C 2
( )
C1
(2)
f
-
=
, neg)
(Ci
1 ×
else ( )
S C C
1 2
( )
C 1
S
P(C, neg) = ni=1 m
(C, pos) /∑f (Ci, pos)+ f (C, neg)/∑f
i = 1 i = 1
&gt; 0) then ( )
S C C S
=
1 2
S(C)= P(C, pos) − N(C,neg) (3) else ( ) ( ) (C2)
S C C S C S
= +
1 2 1
(6)
1
S C C C
( ... )
1 2 ∑=
= S C i
( ) (4)
l
li
l
1
</figure>
<bodyText confidence="0.999940291666667">
where C is an arbitrary Chinese character, f(C,
polarity) counts the observed frequency of C in a
set of Chinese words whose opinion polarity is
positive (pos) or negative (neg); P(C, pos) and
P(C, neg) denote the observation probabilities of
C as a positive and a negative character, and n
and m denote total number of unique characters
in positive and negative words. The difference
of P(C, pos) and P(C, neg) in Formula (3) de-
termines the sentiment score of character C, de-
noted by S(C). Formula (4) computes the opin-
ion score of a word of l characters C1C2...Cl by
averaging their scores.
Instead of counting the weights as in the bag-
of-characters approaches, we consider the word
structures and propose a scoring function for
each morphological type. According to the Fre-
quency Dictionary of Modern Chinese, 96.5% of
Chinese words are unigrams and bigrams (Chen,
et al., 1997). In the following functions, S(C1C2)
computes the opinion scores of words with char-
acters C1 and C2. SIGN(s) returns -1 if polarity
degree s is smaller than 0, i.e., negative, and re-
turns 1 when positive.
</bodyText>
<listItem confidence="0.996852">
(1) Parallel Type: Since the two composite
characters of a word of this type are homogene-
ous, the opinion score is the average score of two
characters’ opinion scores.
</listItem>
<equation confidence="0.982616">
S C S C
( ) ( )
+
1 2
S C C
( )= (5)
1 2 2
</equation>
<listItem confidence="0.901766727272727">
(2) Substantive-Modifier Type: The first mor-
pheme of a word of this type modifies the second
one, so that its opinion weight comes from the
absolute opinion score of the first character,
while the opinion polarity is determined by the
occurrence of negative opinion characters. If at
least one negative opinion character appears, the
(3) Subjective-Predicate Type: The first mor-
pheme of a word of this type is a subject and the
second morpheme is the action it performs, so
that the action decides the opinion score of the
</listItem>
<bodyText confidence="0.995156375">
word. If the action is not an opinion or it is neu-
tral, the subject determines the opinion score of
this word. For example, the word “JaM” (mud-
slide, negative) is composed of “Ja” (mountain,
non-opinion) and “M” (collapse, negative). Its
opinion score depends only on the second char-
acter “M” (collapse) since the first character is a
subject and usually bears no opinions.
</bodyText>
<equation confidence="0.8103474">
if (S(C2) ≠ 0) then S(C1C2) = S(C2) (7)
else ( ) ( )
S C C S C
=
1 2 1
</equation>
<bodyText confidence="0.987786315789474">
(4) Verb-Object Type: The first morpheme of
words of this type acts upon the second mor-
pheme. The effect depends not only on the ac-
tion but on the target. The weight is determined
by the action, but the polarity is the multiplica-
tion of the signs of the two morphemes. For ex-
ample, the word “iffA-” (to go away for the
summer, positive) is composed of “iff” (hide,
negative) and “A-” (hot summer, negative). Its
strength depends on the strength of “iff” (hide)
and polarity is positive from the multiplication of
two negatives.
(5) Verb-Complement Type: The scoring func-
tion for words of this type is defined the same as
that of a Subjective-Predicate type in Formula
(7). The complement morpheme is the deciding
factor of the opinion score. For example, the
word “ ” (raise, positive) is composed of
“�” (carry or lift, non-opinion) and “it” (high,
</bodyText>
<figure confidence="0.961348380952381">
≠ S C ≠
( ( ) 0 and ( )
S C
1 2
if
0)
= ) + S(C2)
else S C C S C
( ) (
1 2 1
then ( )
S C C
1 2
× SIGN S C SIGN S C
( ( )) × ( ( ))
1 2
(8)
=
S C
( )
1
</figure>
<page confidence="0.985956">
1262
</page>
<bodyText confidence="0.9990079">
positive). The complement morpheme “ 高 ”
(high) describes the resulting state of the verb
morpheme “提” (raise), so both strength and po-
larity depend on the morpheme “高” (high).
(6) Negation Type: A negative character speci-
fied in a predefined set NC has a negation effect
on the opinion score of the other character. The
strength depends on the modified morpheme
while the polarity of the word is the negation of
the polarity of the modified morpheme.
</bodyText>
<equation confidence="0.8986935">
then S(C1C2 )=(−1)xS(C2) (9)
= (−1)xS(C1)
</equation>
<listItem confidence="0.898556090909091">
(7) Confirmation Type: A positive character
specified in a predefined set PC ensures that the
opinion score of a word only comes from the
other character. Therefore, the opinion score of
this word is determined by the modified mor-
pheme.
if (C1e PC) thenS(C1C2)=S(C2) elseS(C1C2)=S(C1) (10)
(8) Others: Since words of this type contain no
clear cues for their morphological structures, we
postulate that both characters have the same con-
tribution, and adopt Formula (5).
</listItem>
<sectionHeader confidence="0.9737" genericHeader="method">
4 Identification of Morphological Types
</sectionHeader>
<bodyText confidence="0.999987722222222">
To compute the opinion score of a word accord-
ing to formulae in Section 3, we must know its
morphological type from the morphological
structure, i.e., the parts of speech of the compos-
ite morphemes. Currently, part of speech tag-
ging is performed at the word level rather than
the morpheme level, and morpheme-tagging cor-
pus is not available. We consider an on-line
Chinese dictionary, Dictionary of Chinese Words
by Ministry of Education, Taiwan (MOEDCW),
as a corpus, and compute the statistics of each
morpheme in it.
Two classifiers, CRF classifier and SVM clas-
sifier are proposed to recognize morphological
types (1)-(5). Morphological types (6) to (8) are
determined by rules such as whether two com-
posite characters are morphemes; whether there
are confirmation/negation morphemes; and so on.
</bodyText>
<subsectionHeader confidence="0.875836">
4.1 MOEDCW Corpus
</subsectionHeader>
<bodyText confidence="0.998434958333333">
MOEDCW corpus provides possible parts of
speech for each morpheme by treating it as a uni-
gram word, and possible senses under each part
of speech. In each entry, there are a sense defini-
tion and some example words. Figures 1 and 2
show the specifications of two morphemes “冒”
and “汗”. The morpheme “冒” has three parts
of speech (verb, adverb and noun) and includes 3,
1, and 1 senses. There are 3, 3, and 2 example
words listed under the three verb senses.
We can find the correct parts of speech of the
composite characters of a word when it is an ex-
ample word in the dictionary. However, not all
words are listed in the corpus. Consider the
word “冒汗” (sweat, verb). Figure 1 shows that
“冒汗” (sweat) is an example word listed under
the verb sense of the character “冒” (perspire),
thus the character “冒” (perspire) in the word “冒
汗” (sweat) functions as a verb. However, “冒
汗” (sweat) is not an example for the character
“汗” (sweat). Figure 2 show that there are two
possible parts of speech, noun and verb, for the
character “汗” (sweat). We then show how to
identify its function in the word “冒汗”.
</bodyText>
<figureCaption confidence="0.471624111111111">
Goes out from the button to the top or
from inside to outside. For example,
1 fume, smoking, and sweat. 由下往上或
往外透出、發散。如: 「冒煙」 、
「冒氣」、「冒汗」。
verb Burst into or regardless of. For example,
take risk, to offend, and offense. 衝
2 犯 、 不 顧 。 如 : 「 冒 險 」 、 「 冒
犯」、「衝冒」。...
3 Fake or on the pretext of. For example,
personate and to pretend to be. 假稱、
假託。如:「冒名」、「假冒」。
Crude or rash. For example, offensively
ad- 1 and advance rashly. 鹵 莽 、 莽 撞 。
verb
如:「冒犯」、「冒進」。
noun 1 Family name. 姓。
Figure 1: Specification of “冒” in MOEDCW
</figureCaption>
<bodyText confidence="0.858170142857143">
noun 1 Sweat. For example, cold sweat, night
sweat, sweatiness, and to drip with
sweat. 由動物皮膚的毛細孔所排泄出
的液體。如:「冷汗」、「盜汗」、
「汗流浹背」、「揮汗如雨」。...
2 Family name 姓。
verb 1 To sweat 流汗、使出汗。
</bodyText>
<figureCaption confidence="0.996703">
Figure 2: Specification of “汗” in MOEDCW
</figureCaption>
<equation confidence="0.9675935">
T C, POS = NumberOfSe nses C,POS
( ) ( ) (11)
</equation>
<bodyText confidence="0.7819035">
The number of possible meanings one charac-
ter can bear when it functions as a certain part of
</bodyText>
<figure confidence="0.72815075">
if (C1 e NC)
else ( )
S C C
1 2
</figure>
<page confidence="0.828954">
1263
</page>
<bodyText confidence="0.9919864">
speech is employed to estimate how often this
part of speech is used. The function T(C, POS)
shown in Formula (11) defines the score of a
character C functioning as a particular part of
speech POS. Here, POS may be noun (N), adjec-
tive (ADJ), verb (V), adverb (ADV), auxiliary
(AUX), conjunction (CONJ), pronoun (PRON),
preposition (PREP), and interjection (INT). In
Figure 2, T(汗&lt;sweat&gt;, N) = 2 and T(汗&lt;sweat&gt;,
V) = 1.
</bodyText>
<subsectionHeader confidence="0.498019">
4.2 Features for Classifiers
</subsectionHeader>
<bodyText confidence="0.999736533333333">
Features for training SVM and CRF classifiers
include the pronunciation and the tone of the
word, parts of speech of the first and the second
characters of training words, and the position
information of the composite characters. The
tone of the word is acquired from MOEDCW.
The parts of speech are estimated by Formula
(11). f(C, POS, k, start/end) counts the number
of k-grams (k=2, 3, 4). In Figures 1 and 2, f(冒,
V, 2, start)=6, f(冒, V, 2, end)= 2, f(冒, ADV, 2,
start) = 2, and f(冒, ADV, 2, end)=0. This ex-
ample shows that when the character “冒” func-
tions as a verb or an adverb, it serves as the start-
ing character more often than the ending charac-
ter.
</bodyText>
<subsectionHeader confidence="0.985814">
4.3 CRF and SVM Classifier
</subsectionHeader>
<bodyText confidence="0.999952434782609">
CRF and SVM are both common used algorithms
for building classifiers (Lafferty et al., 2001).
We adopted CRF++1 and libSVM (Chang and
Lin, 2001) to develop our classifiers. The fea-
tures for training our CRF and SVM classifiers
include the input word W, the tone of W, the first
and the second characters C1 and C2, T(C1, POS),
T(C2, POS), f(C1, POS, k, start), f(C1, POS, k,
end), f(C2, POS, k, start), and f(C2, POS, k, end).
POS denotes one of nine parts of speech in
MOEDCW, and k equals to 2, 3 or 4.
Using SVM is straightforward. To classify a
word into one of the morphological structure
types, we construct the word&apos;s feature vector and
input the vector into SVM. When using CRF, a
different approach is taken. When predicting the
classes of two successive instances, CRF takes
the predicted class of the first instance into ac-
count when predicting the second instance&apos;s class.
Here is how we exploit this capability. In a nut-
shell, we perform classification at the character
level instead of the word level. Let W be a word
composed of the two characters C1 and C2. Let v
</bodyText>
<footnote confidence="0.801342">
1 http://crfpp.sourceforge.net/
</footnote>
<bodyText confidence="0.999742742857143">
be the feature vector of W. Let t be the morpho-
logical structure type of W. We define C1&apos;s fea-
ture vector to be composed of the features in v
which are related to C1, e.g., T(C1, verb). Simi-
larly, C2&apos;s feature vector is composed of the fea-
tures in v which are related to C2. C1&apos;s class and
C2&apos;s class are defined as t_1 and t_2, respectively.
Since t has five possible values, there are 10
character classes.
To determine a word W&apos;s morphological struc-
ture type, we first apply CRF on W&apos;s constituent
characters C1 and C2&apos;s feature vectors. For C1,
CRF will return a set of probabilities P(C1,t_q),
where q ∈ {1, 2}, indicating the likelihood of C1
being an instance of class t_q. Similarly, a set of
probabilities P(C2,t_q) is returned for C2. W&apos;s
morphological structure type is defined as the
value of t which maximizes the product of
P(C1,t_1) and P(C2,t_2).
Though CRF is mostly used for sequential la-
beling, the idea of using CRF is to tail this classi-
fication questions into a labeling question in or-
der to utilizing the position information of char-
acters. As mentioned, if a word W of two char-
acters C1C2 is of type 1, CRF will label C1 1_1
(type1_1st char) and C2 1_2 (type1_2nd char).
The labeling of each character considers both the
previous character&apos;s features and the next charac-
ter&apos;s features. That is, if the current character is
the first character, its previous character is an
empty character (which is used for segmenting
sequences in CRF); if the current character is the
second character, its next character is an empty
character. Hence the position information will be
considered by CRF.
</bodyText>
<sectionHeader confidence="0.998136" genericHeader="method">
5 Experiments and Discussion
</sectionHeader>
<bodyText confidence="0.9999356">
Experiments verify whether the morphological
types benefit opinion polarity detection on words.
The relation between the performance of mor-
phological classifiers and opinion polarity detec-
tion is discussed.
</bodyText>
<subsectionHeader confidence="0.967253">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9999521">
To compare the bag-of-characters approach (Ku
et al., 2007) with our morphological structure
approach, we adopt the same evaluation data set
containing 836 words. To evaluate the perform-
ance of our two morphological classifiers, we
prepare two sets of words, including the testing
set of 836 words for word-level opinion predic-
tion (abbreviated as OP), and a set of 8,186
words selected from words in MOEDCW corpus
and news documents except those can be classi-
</bodyText>
<page confidence="0.987586">
1264
</page>
<bodyText confidence="0.999159647058824">
fied by patterns (abbreviated as TRAIN set), all
with their morphological types annotated. Table
1 lists the distributions of morphological types in
OP and TRAIN sets.
The polarity of words is predicted by their
opinion scores ranging between -1 to 1. We set a
positive threshold. Those words with scores
above it are considered as positive while those
below this threshold multiplied by (-1) are re-
garded as negative. The words with non-zero
scores falling between the positive and negative
thresholds are neutral. Fifty grids from 0 to 0.5
are searched for the best threshold. Since the
opinion extraction at word level concerns only
word structure, no retraining for the best thresh-
old is need when domain shifts, which is a supe-
riority of our method.
</bodyText>
<subsectionHeader confidence="0.9971835">
5.2 Morphological Type Classification and
Polarity Detection
</subsectionHeader>
<bodyText confidence="0.999753871794872">
The performances of CRF and SVM classifiers
on each morphological type are listed in Table 2.
We perform four-fold cross validation on the
TRAIN set. Results show that CRF classifier
achieves better performance than SVM classifier
in this task. The accuracy of CRF classifier
(0.70) is 8% higher than that of SVM classifier
(0.62). Note those type 8 words which could be
extracted by rules are excluded from classifica-
tion experiment. The remaining type 8 words are
usually proper names. It is difficult for both
classifiers to identify such words.
Table 3 further shows the performance of po-
larity prediction using morphological types de-
termined by CRF classifier and SVM classifier.
The performance of polarity detection is evalu-
ated by the f-score defined in Formula (12).
The f-scores of polarity detection using CRF
classified types and SVM classified types are
0.5806 and 0.5938, respectively. Both of them
outperform baseline’s f-score 0.5455, i.e., the
bag-of-characters approach (Ku et al., 2007).
Experiments show that adopting morphological
types annotated by two classifiers for polarity
prediction has little difference. In other words,
CRF and SVM classifiers have an 8% f-score
difference in their best performance of classifica-
tion, while the performance gap in word polarity
prediction using morphological types provided
by these two classifiers is around 1.3% only
(0.5806 vs. 0.5938). The reason may be that we
define scoring functions of each morphological
type in a straightforward way. If they are not the
best scoring functions, the benefit of considering
the morphological type information could be re-
stricted. Nevertheless, experimental results show
that morphological type information is useful for
word polarity detection (with p-value less than
0.05).
</bodyText>
<equation confidence="0.7843771">
P = correct(opinion) ∩ correct(polarity) ,
proposed (opinion )
R = correct(opinion) ∩ correct(polarity) ,
)
(opinion
gold
f − score = 2 P R .
⋅ ⋅
P+R
(12)
</equation>
<table confidence="0.927643">
set/type 1 2 3 4 5 6 7 8
TRAIN 26.15 44.97 1.64 15.14 9.22 0 0 2.88
OP 45.8 24.4 1.3 7.9 8.0 2.3 0.5 9.8
</table>
<tableCaption confidence="0.99867">
Table 1: The Percentage of distribution for morphological types in TRAIN and OP sets
</tableCaption>
<table confidence="0.999909666666667">
MorphoType 1 2 3 4 5 8 Accuracy
CRF 0.63 0.78 0.41 0.66 0.78 0.17 0.70
SVM 0.49 0.73 0.22 0.52 0.55 0 0.62
</table>
<tableCaption confidence="0.999781">
Table 2: The f-score of CRF and SVM classifiers
</tableCaption>
<bodyText confidence="0.999935125">
We further examine how well our polarity de-
tection method works in combination with a
word sentiment dictionary. We use the NTUSD2
word sentiment dictionary. If a word appears in
NTUSD, then the word&apos;s polarity is the one
specified in NTUSD. If a word does not appear
in NTUSD, then the word&apos;s polarity is deter-
mined using our morphological type method.
</bodyText>
<footnote confidence="0.619519">
2 http://nlg18.csie.ntu.edu.tw:8080/opinion/
</footnote>
<bodyText confidence="0.997314285714286">
After introducing a sentiment dictionary
NTUSD3, CRF and SVM classifiers both achieve
the f-score 0.77 for opinion word extraction, and
achieve f-scores 0.61 and 0.62 for polarity detec-
tion, respectively. Note that if only NTUSD is
used to extract opinion words by string matching,
the f-score is only 0.44.
</bodyText>
<footnote confidence="0.929962">
3 http://nlg18.csie.ntu.edu.tw:8080/opinion/
</footnote>
<page confidence="0.927117">
1265
</page>
<table confidence="0.99972325">
Polarity f-score Without NTUSD With NTUSD
Ku 0.5455 0.5789
CRF type 0.5806 0.6100
SVM type 0.5938 0.6246
</table>
<tableCaption confidence="0.999979">
Table 3: Prediction with Morphological Types
</tableCaption>
<bodyText confidence="0.999959333333333">
We further analyze the improvement of polar-
ity prediction for each morphological type. We
find that the f-scores of polarity prediction of all
morphological types are improved in different
degrees, and among them the performance of
type 2 words are improved the most. We have
shown that our method can assign an opinion
score to an arbitrary word without any word
thesauri by considering its morphological infor-
mation. Moreover, since the Substantive-
Modifier (type 2) is the most common way to
form a new word in the Chinese language
(Cheng and Tian, 1992), the result presents the
strength of our method in solving the coverage
problem.
</bodyText>
<sectionHeader confidence="0.736075" genericHeader="method">
6 Syntactic Structure for Chinese Opin-
</sectionHeader>
<subsectionHeader confidence="0.853198">
ion Analysis
</subsectionHeader>
<bodyText confidence="0.999922153846154">
As mentioned, the relations introduced in Section
2 exist not only within words, but also between
sentence segments. Relations between sentence
segments are represented by structural trios here-
after and will be introduced in next section. We
have already shown that morphological types are
useful when extracting opinion words and would
like to further testify whether structural trios also
benefit the opinion analysis on sentences. We
annotate these relations manually, propose a
method to identify these relations, and compare
results of experimental settings using structural
trios with those not using structural trios.
</bodyText>
<subsectionHeader confidence="0.99937">
6.1 Structural Trio
</subsectionHeader>
<bodyText confidence="0.999957555555556">
Each node in a parsing tree dominates a word
string in a sentence. Linguistics have shown that
there are also five relations between sentence
segments: Parallel, Substantive-Modifier, Sub-
jective-Predicate, Verb-Object, and Verb-
Complement, same as morphological types (1) to
(5). Because parsing trees have hierarchical
structures, we define a structural trio to represent
a relation between two nodes as follows:
</bodyText>
<listItem confidence="0.9899314">
(1) A structure trio contains two children
nodes which bear a relation.
(2) A structure trio contains one head node
which is the nearest common parent of two
children nodes in (1).
</listItem>
<figureCaption confidence="0.9994">
Figure 3: Example of structural trios
</figureCaption>
<bodyText confidence="0.999148454545455">
Figure 3 shows an example of a structure trio.
It is a part of a parsing tree containing words “取
得” (obtain), “可喜” (happy), “成果” (results).
Two structural trios are shown in this example.
The lower one contains two children nodes “可
喜” (happy) and “成果” (results), and is labeled
as Substantive-Modifier (S-M (2)) in their near-
est common parent node, while the upper one
contains two children nodes “取得” (obtain) and
“可喜成果” (happy results), and is labeled as
Verb-Object (V-O (4)).
</bodyText>
<subsectionHeader confidence="0.997063">
6.2 Experimental Corpus
</subsectionHeader>
<bodyText confidence="0.999966409090909">
To experiment with structural trios, we need the
parsing trees of all experimental sentences. For
this purpose, we adopted Chinese Treebank 5.14
as the experimental materials. Chinese Treebank
contains raw Chinese news documents together
with their segmented, part of speech tagged, and
parsed versions. The parsed documents are
adopted in experiments utilizing structural trios,
and the part of speech tagged documents are used
in experiments not utilizing structural trios.
In Chinese Treebank, a unique ID is labeled
on each sentence. For each sentence, we had
three annotators label their opinions and then we
generate the gold standard following NTCIR 5
MOAT protocol (Seki et al., 2008). We also
annotated structure trios in Chinese Treebank. A
total of 17,159 sentences are obtained after drop-
ping some faulty sentences such as empty sen-
tences and sentences composed of more than one
parsing tree. The statistics of opinion sentences
and structural trios in the constructed experimen-
tal materials are shown in Table 4 and Table 5.
</bodyText>
<footnote confidence="0.999305333333333">
4 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2005T01
5 http://research.nii.ac.jp/ntcir/index-en.html
</footnote>
<page confidence="0.930834">
1266
</page>
<table confidence="0.9994925">
Opinion Non-Opinion
Positive Neutral Negative 7,528
# 6,380 1,537 1,714
9,631
% 66.24 15.96 17.80 43.87
56.13
</table>
<tableCaption confidence="0.988811">
Table 4: Statistics of opinion sentences
</tableCaption>
<table confidence="0.999862571428571">
Trio Type Number Percentage %
2 18,483 36.85
3 13,687 27.29
4 15,970 31.84
5 965 1.92
Others 1,054 2.10
Total 50,159 100.00
</table>
<tableCaption confidence="0.999447">
Table 5: Statistics of structural trios
</tableCaption>
<subsectionHeader confidence="0.996658">
6.3 Experiment Setup
</subsectionHeader>
<bodyText confidence="0.999969931034483">
The aim of our experiments is to know how
opinion analysis approach performs when mor-
phological and syntactic structures are incorpo-
rated. They are compared with the bag-of-
character and bag-of-word approaches. We im-
plemented the bag-of-word approach proposed
by Ku et al. (2007) to show its performance on
Chinese Treebank. In their approach, the opin-
ion scores of words are summed to generate the
opinion scores of sentences, and the negation
words will negate the closest opinion words.
Based on this approach, we further consider
structural trios to experiment whether syntactic
structures of sentences are beneficial for opinion
analysis. Because the scoring functions may not
be straight forward as those we have adopted for
opinion word extraction, we did not design scor-
ing functions for utilizing all types of structural
trios. Instead, we emphasize their original opin-
ion scores by multiplying a variable alpha to see
whether these structures are important. In this
paper, alpha equals five.
We have shown that word morphological
structures benefit the word opinion extraction.
When we experiment on sentences, we also in-
corporate the word morphological structures to
see whether they are also useful for opinion
analysis on sentences. Five experimental set-
tings are listed as below:
</bodyText>
<listItem confidence="0.604118">
(1) bag[w]-bag[s]: structural information is
</listItem>
<bodyText confidence="0.978693545454545">
not considered for both words and sen-
tences. The bag-of-character approach
is used to calculate the opinion scores of
words, and the bag-of-word approach
sentences.
(2) struc[w]-bag[s]: morphological struc-
tures are utilized to calculate word opin-
ion scores, but structural trios are not
considered. The bag-of-word approach
is used to calculate the opinion scores of
sentences.
</bodyText>
<listItem confidence="0.989637222222222">
(3) bag[w]-struc[s]: structural trios are con-
sidered for calculating sentence opinion
scores, while the bag-of-character ap-
proach is used to calculate the opinion
scores of words.
(4) struc[w]-(m)struc[s]: both word mor-
phological structures and manually la-
beled structural trios are adopted.
(5) struc[w]-struc[s]: both morphological
</listItem>
<bodyText confidence="0.9742284">
structure of words and system labeled
structural trios are adopted.
As we have shown that NTUSD is beneficial
to the opinion analysis at word level, it is used as
described in section 5.2 by default.
Our system adopted CRF algorithm to label
structural trios for setting (5). The content string
and the part of speech of the current node, its
parent node, its offspring nodes in the next three
generations, together with the depth of the cur-
rent node in the Chinese Treebank, are used as
the features for each node in CRF. The co-
occurrence of the current node and all its siblings
are defined in CRF’s template file. CRF will
label whether the current node is the first child or
the second child of a certain relation in a struc-
tural trio, or it is not part of any structural trios.
A four-fold experiment is performed for the
learning and testing of this labeling process by
CRF.
</bodyText>
<subsectionHeader confidence="0.5515">
6.4 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.9999553">
Table 6 shows the statistics of manually labeled
structural trios in Chinese Treebank and identifi-
cation performance of CRF. Table 7 shows the
performance of five experiment settings de-
scribed in Section 6.3. The experiment results
show that the morphological structures of words
do not have a large contribution for opinion sen-
tence analysis (setting 1 vs. setting 2; setting 3 vs.
setting 4). However, considering the structural
trios improve the performance.
</bodyText>
<page confidence="0.967307">
1267
</page>
<table confidence="0.999746571428571">
Trio Type Number Percentage f-Score
2 18,483 36.85% 0.4883
3 13,687 27.29% 0.4944
4 15,970 31.84% 0.6360
5 965 1.92% 0.2034
Others 1,054 2.10%
Total 50159 100%
</table>
<tableCaption confidence="0.949851">
Table 6: Statistics and Results of Identifying
Structural Trios
</tableCaption>
<table confidence="0.999700571428571">
Setting Word Sentence f-Score f-Score
[w] [s] (opinion) (polarity)
1 bag bag 0.7073 0.4988
2 struc bag 0.7162 0.5117
3 bag struc 0.8000 0.5361
4 struc (m)struc 0.7922 0.5297
5 struc struc 0.7993 0.5187
</table>
<tableCaption confidence="0.976772">
Table 7: Results of Opinion Extraction
on Chinese Treebank
</tableCaption>
<bodyText confidence="0.999986821428572">
By summarizing the experimental results in
Section 5 and this section, we can conclude that
considering the word morphological structures
benefits the opinion polarity detection, but in the
current approach its assistance to words does not
propagate to sentences. Considering the syntac-
tic structures, however, do help in opinion analy-
sis both for the opinion sentence extraction and
the polarity detection. The performance of opin-
ion extraction boosts to an f-score 0.80 and the
performance of polarity detection an f-score 0.54.
However, the utilization of structure trios
needs the parsing tree of sentences as the prior
knowledge. Hence these two kinds of structural
information may be suitable for different applica-
tions: structural trios for well written sentences
such as those in the news articles, while the mor-
phological structures for casually written sen-
tences such as those appear in SMS messages or
articles with limit length on the Web.
Because there are no opinion experiments per-
formed on Chinese Treebank, we mention the
performance of Ku’s approach (setting (1)) for
opinion sentence extraction, f-score 0.6846, in
NTCIR-7 MOAT task, on news articles, as a re-
sult for comparison. Their approach was ranked
the second in this task, and the best team
achieved an f-score 0.7453.
</bodyText>
<sectionHeader confidence="0.997928" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999982351351351">
This paper considers morphological and syntac-
tic structures in analyzing Chinese opinion words
and sentences. For morphological structures,
eight Chinese morphological types are defined.
CRF classifier and SVM classifier for morpho-
logical type classification are proposed. Experi-
ments show that CRF classifier achieves the best
accuracy 0.70 in type classification, which is 8%
better than SVM classifier. We further show that
word morphological structures benefit the opin-
ion word extraction significantly. With the help
of the sentiment dictionary NTUSD, the f-score
of opinion word extraction achieves 0.77 and the
f-score of the word polarity detection achieves
0.62 when the word morphological types are
provided by the SVM classifier. They are com-
parably better than bag-of-character approach
and the dictionary based approach.
We defined structural trios to represent the re-
lations between sentence segments and also ex-
tract these relations using CRF algorithm. Re-
sults show that considering structural trios bene-
fits the opinion analysis on sentences. An f-
score 0.80 for opinion extraction and an f-score
0.54 for polarity detection are achieved, which is
a great improvement.
The opinion scoring functions for morphologi-
cal types and structural trios are critical for polar-
ity detection, and scoring functions for words
determine the scoring functions for sentences.
Now we define these functions intuitively based
on linguistic rules, but learning methods like re-
gression will be investigated in the future. Ex-
amining the interaction of cues from word and
sentence levels on the opinion sentence extrac-
tion and the opinion polarity detection is our next
goal.
</bodyText>
<sectionHeader confidence="0.987753" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.740709">
Research of this paper was partially supported by Na-
tional Science Council, Taiwan, under the contract
NSC95-2221-E-002-265-MY3.
</bodyText>
<sectionHeader confidence="0.993466" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999612785714286">
Banea, C., Mihalcea, R., Wiebe, J. and Hassan, S.
2008. Multilingual Subjectivity Analysis Using
Machine Translation. In Proceedings of Empirical
Methods in Natural Language Processing (EMNLP
2008).
Bautin, M., Vijayarenu, L. and Skiena, S. 2008. Inter-
national sentiment analysis for news and blogs. In
Proceedings of the International Conference on
Weblogs and Social Media (ICWSM).
Carenini, G., Ng, R. T. and Pauls, A. 2006. Interactive
Multimedia Summaries of Evaluative Text. In Pro-
ceedings of the 11th International Conference on
Intelligent User Interfaces (pp. 124-131), Sydney,
Australia.
</reference>
<page confidence="0.791664">
1268
</page>
<reference confidence="0.999817565217392">
Cesarano, C., Picariello, A., Reforgiato, D. and
Subrahmanian, V.S. 2007. The OASYS 2.0 Opin-
ion Analysis System. Demo in Proceedings of In-
ternational Conference on Weblogs and Social
Media (pp. 313-314), Boulder, CO USA.
Chang, Chih-Chung and Lin, Chih-Jen. 2001.
LIBSVM: a library for support vector machines,
http://www.csie.ntu.edu.tw/~cjlin/libsvm
Chen, A., Xu, L., Gey, F.C. and Meggs, J. 1997. Chi-
nese Text Retrieval without Using a Dictionary.
ACM SIGIR Forum, Volume 31, Issue SI (pp. 42-
49).
Cheng, X.-H. and Tian, X.-L. 1992. Modern Chinese.
Bookman Books Ltd.
Dave, K., Lawrence, S., and Pennock, D.M. 2003.
Mining the Peanut Gallery: Opinion Extraction
and Semantic Classification of Product Reviews.
In Proc. of the 12th International WWW Confer-
ence (pp. 519-528).
Kawai, Y., Kumamoto, T. and Tanaka, K. 2007. Fair
News Reader: Recommending news articles with
different sentiments based on user preference. In
Proceedings of Knowledge-Based Intelligent In-
formation and Engineering Systems (KES), No.
4692 in Lecture Notes in Computer Science (pp.
612–622).
Kim, S.-M. and Hovy, E. 2004. Determining the Sen-
timent of Opinions. In Proc. of the 20th ICCL (pp.
1367-1373).
Ku, L.-W. and Chen, H.-H. 2007. Mining Opinions
from the Web: Beyond Relevance Retrieval. Jour-
nal of American Society for Information Science
and Technology, Special Issue on Mining Web Re-
sources for Enhancing Information Retrieval,
58(12), 1838-1850.
Lafferty, J., McCallum, A. and Pereira, F. 2001. Con-
ditional Random Fields: Probabilistic Models for
Segmenting and Labeling Sequence Data, In Proc.
of ICML (pp.282-289).
Pang, B., Lee, L. and Vaithyanathan, S. 2002. Thumbs
up? Sentiment Classification Using Machine
Learning Techniques. In Proc. of the 2002 Confer-
ence on EMNLP (pp. 79-86).
Riloff, E. and Wiebe, J. 2003. Learning Extraction
Patterns for Subjective Expressions. In Proc. of the
2003 Conference on EMNLP (pp. 105-112).
Seki, Y., Evans, D. K., Ku, L.-W., Sun, L., Chen, H.-H.
and Kando, N. 2008. Overview of Multilingual
Opinion Analysis Task at NTCIR-7. In Proceed-
ings of the 7th NTCIR Workshop Meeting on
Evaluation of Information Access Technologies:
Information Retrieval, Question Answering, and
Cross-Lingual Information Access.
Somasundaran, S., Ruppenhofer, J. and Wiebe, J.
2007. Detecting arguing and sentiment in meetings.
Proceedings of the SIGdial Workshop on Dis-
course and Dialogue, 2007.8.6
Takamura, H., Inui, T. and Okumura, M. 2005. Ex-
tracting Semantic Orientations of Words Using
Spin Model. In Proc. of the 43rd Annual Meeting
of the ACL (pp. 133-140).
Tzeng, H. and Chen, K.-J. 2002. Design of Chinese
Morphological Analyzer. In Proc. of the 1st
SIGHAN Workshop on Chinese Language Process-
ing, vol.18, 1-7.
Wiebe, J. 2000. Learning Subjective Adjectives from
Corpora. In Proc. of the 17th National Conference
on AAAI and Twelfth Conference on IAAI (pp. 735-
740).
</reference>
<page confidence="0.994922">
1269
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.914540">
<title confidence="0.9998025">Using Morphological and Syntactic for Chinese Opinion Analysis</title>
<author confidence="0.999632">Lun-Wei Ku Ting-Hao Huang Hsin-Hsi Chen</author>
<affiliation confidence="0.998077">Department of Computer Science and Information National Taiwan</affiliation>
<address confidence="0.997105">No. 1, Sec. 4, Roosevelt Road, Taipei, 10617</address>
<email confidence="0.968276">lwku@nlg.csie.ntu.edu.tw;hhchen@ntu.edu.tw</email>
<email confidence="0.968276">thhuang@nlg.csie.ntu.edu.tw;hhchen@ntu.edu.tw</email>
<abstract confidence="0.9973469">This paper employs morphological structures and relations between sentence segments for opinion analysis on words and sentences. Chinese words are classified into eight morphological types by two proposed classifiers, CRF classifier and SVM classifier. Experiments show that the injection of morphological information improves the performance of the word polarity detection. To utilize syntactic structures, we annotate structural trios to represent relations between sentence segments. Experiments show that considering structural trios is useful for sentence opinion analysis. The best f-score achieves 0.77 for opinion word extraction, 0.62 for opinion word polarity detection, 0.80 for opinion sentence extraction, and 0.54 for opinion sentence polarity detection.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Banea</author>
<author>R Mihalcea</author>
<author>J Wiebe</author>
<author>S Hassan</author>
</authors>
<title>Multilingual Subjectivity Analysis Using Machine Translation.</title>
<date>2008</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="3396" citStr="Banea et al., 2008" startWordPosition="483" endWordPosition="486">entences, we identify these relations and utilize them for opinion analysis on sentences. As the experimental corpus, some researchers managed to generate annotated materials and gold standards under many constraints. Ku set a standard for generating final answers from annotations of multiple annotators (Ku et al., 2007), and Somasundaran annotated discourse information from meeting dialogs to train a sentiment model (Somasundaran et al., 2007). For multilingual issues, researchers concerned mainly about the applicability of corpus and algorithms from the native language to foreign languages (Banea et al., 2008; Bautin et al., 2008). Several opinion analysis systems have been developed so far. OASYS (Cesarano et al., 2007) and CopeOpi (Ku et al., 2007) allow users input their queries and select preferred data sources, 1260 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1260–1269, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP and then track opinions in a time zone. For both systems, extracting opinions is the main focus, while holders and targets are identified implicitly when retrieving relevant documents. Carenini’s team proposed a graphical user in</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, Hassan, 2008</marker>
<rawString>Banea, C., Mihalcea, R., Wiebe, J. and Hassan, S. 2008. Multilingual Subjectivity Analysis Using Machine Translation. In Proceedings of Empirical Methods in Natural Language Processing (EMNLP 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bautin</author>
<author>L Vijayarenu</author>
<author>S Skiena</author>
</authors>
<title>International sentiment analysis for news and blogs.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</booktitle>
<contexts>
<context position="3418" citStr="Bautin et al., 2008" startWordPosition="487" endWordPosition="490">y these relations and utilize them for opinion analysis on sentences. As the experimental corpus, some researchers managed to generate annotated materials and gold standards under many constraints. Ku set a standard for generating final answers from annotations of multiple annotators (Ku et al., 2007), and Somasundaran annotated discourse information from meeting dialogs to train a sentiment model (Somasundaran et al., 2007). For multilingual issues, researchers concerned mainly about the applicability of corpus and algorithms from the native language to foreign languages (Banea et al., 2008; Bautin et al., 2008). Several opinion analysis systems have been developed so far. OASYS (Cesarano et al., 2007) and CopeOpi (Ku et al., 2007) allow users input their queries and select preferred data sources, 1260 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1260–1269, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP and then track opinions in a time zone. For both systems, extracting opinions is the main focus, while holders and targets are identified implicitly when retrieving relevant documents. Carenini’s team proposed a graphical user interface for evaluative</context>
</contexts>
<marker>Bautin, Vijayarenu, Skiena, 2008</marker>
<rawString>Bautin, M., Vijayarenu, L. and Skiena, S. 2008. International sentiment analysis for news and blogs. In Proceedings of the International Conference on Weblogs and Social Media (ICWSM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>R T Ng</author>
<author>A Pauls</author>
</authors>
<title>Interactive Multimedia Summaries of Evaluative Text.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th International Conference on Intelligent User Interfaces</booktitle>
<pages>124--131</pages>
<location>Sydney, Australia.</location>
<marker>Carenini, Ng, Pauls, 2006</marker>
<rawString>Carenini, G., Ng, R. T. and Pauls, A. 2006. Interactive Multimedia Summaries of Evaluative Text. In Proceedings of the 11th International Conference on Intelligent User Interfaces (pp. 124-131), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cesarano</author>
<author>A Picariello</author>
<author>D Reforgiato</author>
<author>V S Subrahmanian</author>
</authors>
<title>The OASYS 2.0 Opinion Analysis System. Demo in</title>
<date>2007</date>
<booktitle>Proceedings of International Conference on Weblogs and Social Media</booktitle>
<pages>313--314</pages>
<location>Boulder, CO USA.</location>
<contexts>
<context position="3510" citStr="Cesarano et al., 2007" startWordPosition="501" endWordPosition="504">corpus, some researchers managed to generate annotated materials and gold standards under many constraints. Ku set a standard for generating final answers from annotations of multiple annotators (Ku et al., 2007), and Somasundaran annotated discourse information from meeting dialogs to train a sentiment model (Somasundaran et al., 2007). For multilingual issues, researchers concerned mainly about the applicability of corpus and algorithms from the native language to foreign languages (Banea et al., 2008; Bautin et al., 2008). Several opinion analysis systems have been developed so far. OASYS (Cesarano et al., 2007) and CopeOpi (Ku et al., 2007) allow users input their queries and select preferred data sources, 1260 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1260–1269, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP and then track opinions in a time zone. For both systems, extracting opinions is the main focus, while holders and targets are identified implicitly when retrieving relevant documents. Carenini’s team proposed a graphical user interface for evaluative texts (2006), in which color blocks were used to present the evaluations for components of </context>
</contexts>
<marker>Cesarano, Picariello, Reforgiato, Subrahmanian, 2007</marker>
<rawString>Cesarano, C., Picariello, A., Reforgiato, D. and Subrahmanian, V.S. 2007. The OASYS 2.0 Opinion Analysis System. Demo in Proceedings of International Conference on Weblogs and Social Media (pp. 313-314), Boulder, CO USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines,</title>
<date>2001</date>
<location>http://www.csie.ntu.edu.tw/~cjlin/libsvm</location>
<contexts>
<context position="17664" citStr="Chang and Lin, 2001" startWordPosition="3087" endWordPosition="3090">mposite characters. The tone of the word is acquired from MOEDCW. The parts of speech are estimated by Formula (11). f(C, POS, k, start/end) counts the number of k-grams (k=2, 3, 4). In Figures 1 and 2, f(冒, V, 2, start)=6, f(冒, V, 2, end)= 2, f(冒, ADV, 2, start) = 2, and f(冒, ADV, 2, end)=0. This example shows that when the character “冒” functions as a verb or an adverb, it serves as the starting character more often than the ending character. 4.3 CRF and SVM Classifier CRF and SVM are both common used algorithms for building classifiers (Lafferty et al., 2001). We adopted CRF++1 and libSVM (Chang and Lin, 2001) to develop our classifiers. The features for training our CRF and SVM classifiers include the input word W, the tone of W, the first and the second characters C1 and C2, T(C1, POS), T(C2, POS), f(C1, POS, k, start), f(C1, POS, k, end), f(C2, POS, k, start), and f(C2, POS, k, end). POS denotes one of nine parts of speech in MOEDCW, and k equals to 2, 3 or 4. Using SVM is straightforward. To classify a word into one of the morphological structure types, we construct the word&apos;s feature vector and input the vector into SVM. When using CRF, a different approach is taken. When predicting the classe</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chang, Chih-Chung and Lin, Chih-Jen. 2001. LIBSVM: a library for support vector machines, http://www.csie.ntu.edu.tw/~cjlin/libsvm</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Chen</author>
<author>L Xu</author>
<author>F C Gey</author>
<author>J Meggs</author>
</authors>
<title>Chinese Text Retrieval without Using a Dictionary.</title>
<date>1997</date>
<booktitle>ACM SIGIR Forum, Volume 31, Issue SI</booktitle>
<pages>42--49</pages>
<contexts>
<context position="10159" citStr="Chen, et al., 1997" startWordPosition="1704" endWordPosition="1707"> a negative character, and n and m denote total number of unique characters in positive and negative words. The difference of P(C, pos) and P(C, neg) in Formula (3) determines the sentiment score of character C, denoted by S(C). Formula (4) computes the opinion score of a word of l characters C1C2...Cl by averaging their scores. Instead of counting the weights as in the bagof-characters approaches, we consider the word structures and propose a scoring function for each morphological type. According to the Frequency Dictionary of Modern Chinese, 96.5% of Chinese words are unigrams and bigrams (Chen, et al., 1997). In the following functions, S(C1C2) computes the opinion scores of words with characters C1 and C2. SIGN(s) returns -1 if polarity degree s is smaller than 0, i.e., negative, and returns 1 when positive. (1) Parallel Type: Since the two composite characters of a word of this type are homogeneous, the opinion score is the average score of two characters’ opinion scores. S C S C ( ) ( ) + 1 2 S C C ( )= (5) 1 2 2 (2) Substantive-Modifier Type: The first morpheme of a word of this type modifies the second one, so that its opinion weight comes from the absolute opinion score of the first charact</context>
</contexts>
<marker>Chen, Xu, Gey, Meggs, 1997</marker>
<rawString>Chen, A., Xu, L., Gey, F.C. and Meggs, J. 1997. Chinese Text Retrieval without Using a Dictionary. ACM SIGIR Forum, Volume 31, Issue SI (pp. 42-49).</rawString>
</citation>
<citation valid="true">
<authors>
<author>X-H Cheng</author>
<author>X-L Tian</author>
</authors>
<title>Modern Chinese.</title>
<date>1992</date>
<publisher>Bookman Books Ltd.</publisher>
<contexts>
<context position="5545" citStr="Cheng and Tian (1992)" startWordPosition="829" endWordPosition="832">es together are formed as a lexical item by this process. Affixation is a morphological process, by which grammatical or lexical information is added to a base form. By the conversion process, a word is changed from one part of speech into another without the addition or deletion of any morphemes. Compounding is the most productive way to construct a Chinese word. Mostly, a Chinese character itself carries meanings, so that a morpheme can function as a character and has its own part of speech. In some cases, a Chinese morpheme may carry no specific meaning and just makes a word more readable. Cheng and Tian (1992) divided Chinese words into five morphological types based on the relations between the morphemes in compounding words. (1) Parallel Type: Two morphemes play coordinate roles in a word. For example, the morphemes “財” (money) and “富” (wealth) are parallel in the word “財富” (money-wealth). (2) Substantive-Modifier Type: A modified morpheme follows a modifying morpheme. For example, the morpheme “哭” (cry) is modified by “痛” (bitterly) in the word ”痛哭” (bitterlycry). (3) Subjective-Predicate Type: One morpheme is an expresser and the other one is described. The structure is like a subject-verb sent</context>
<context position="25527" citStr="Cheng and Tian, 1992" startWordPosition="4396" endWordPosition="4399"> type 0.5938 0.6246 Table 3: Prediction with Morphological Types We further analyze the improvement of polarity prediction for each morphological type. We find that the f-scores of polarity prediction of all morphological types are improved in different degrees, and among them the performance of type 2 words are improved the most. We have shown that our method can assign an opinion score to an arbitrary word without any word thesauri by considering its morphological information. Moreover, since the SubstantiveModifier (type 2) is the most common way to form a new word in the Chinese language (Cheng and Tian, 1992), the result presents the strength of our method in solving the coverage problem. 6 Syntactic Structure for Chinese Opinion Analysis As mentioned, the relations introduced in Section 2 exist not only within words, but also between sentence segments. Relations between sentence segments are represented by structural trios hereafter and will be introduced in next section. We have already shown that morphological types are useful when extracting opinion words and would like to further testify whether structural trios also benefit the opinion analysis on sentences. We annotate these relations manua</context>
</contexts>
<marker>Cheng, Tian, 1992</marker>
<rawString>Cheng, X.-H. and Tian, X.-L. 1992. Modern Chinese. Bookman Books Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Dave</author>
<author>S Lawrence</author>
<author>D M Pennock</author>
</authors>
<title>Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews.</title>
<date>2003</date>
<booktitle>In Proc. of the 12th International WWW Conference</booktitle>
<pages>519--528</pages>
<contexts>
<context position="2102" citStr="Dave et al. (2003)" startWordPosition="294" endWordPosition="297"> information. Several approaches were proposed to collect such resources. Wiebe (2000) learned subjective adjectives from corpora. Takamura et al. (2005) extracted semantic orientations of words. Ku et al. (2007) measured sentiment degrees of Chinese words by averaging the sentiment scores of the composing characters. When the opinion words are available, the polarities of sentences and documents can be determined by them. Riloff and Wiebe (2003) learned the extraction patterns for subjective expressions. Kim and Hovy (2004) found the polarity of subjective expressions. Pang et al. (2002) and Dave et al. (2003) explored various techniques at document level. Morphological information has been widely used in classifying words, telling the meanings, and doing other in-depth analysis (Tzeng and Chen, 2002). However, morphological information was seldom applied either in Chinese opinion extraction, or in solving the coverage problem of opinion dictionary. Instead of bag-ofcharacters approach (Ku et al., 2007), this paper employs morphological structures of words to extract opinion words. Relations between sentence segments are also defined by linguistics in the Chinese language. These are similar to morp</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Dave, K., Lawrence, S., and Pennock, D.M. 2003. Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews. In Proc. of the 12th International WWW Conference (pp. 519-528).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Kawai</author>
<author>T Kumamoto</author>
<author>K Tanaka</author>
</authors>
<title>Fair News Reader: Recommending news articles with different sentiments based on user preference.</title>
<date>2007</date>
<booktitle>In Proceedings of Knowledge-Based Intelligent Information and Engineering Systems (KES), No. 4692 in Lecture Notes in Computer Science</booktitle>
<pages>612--622</pages>
<contexts>
<context position="4254" citStr="Kawai et al., 2007" startWordPosition="615" endWordPosition="618">9 Conference on Empirical Methods in Natural Language Processing, pages 1260–1269, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP and then track opinions in a time zone. For both systems, extracting opinions is the main focus, while holders and targets are identified implicitly when retrieving relevant documents. Carenini’s team proposed a graphical user interface for evaluative texts (2006), in which color blocks were used to present the evaluations for components of products. Fair News Reader, a Japanese news Web system, incorporates sentiment information insensibly in an interesting way (Kawai et al., 2007). It provides readers “balanced” reports by analyzing the sentiment in news articles which readers have read, and suggests them new articles according to the analysis results. It leads the application of opinion analysis to the direction of personalization. 2 Chinese Morphological Structures In the Chinese language, a word is composed of one or more Chinese characters, and its meaning can be interpreted in terms of its composite characters. The morphological structures of Chinese words are formulated by three major processes in linguistics: compounding, affixation, and conversion. Compounding </context>
</contexts>
<marker>Kawai, Kumamoto, Tanaka, 2007</marker>
<rawString>Kawai, Y., Kumamoto, T. and Tanaka, K. 2007. Fair News Reader: Recommending news articles with different sentiments based on user preference. In Proceedings of Knowledge-Based Intelligent Information and Engineering Systems (KES), No. 4692 in Lecture Notes in Computer Science (pp. 612–622).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-M Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the Sentiment of Opinions.</title>
<date>2004</date>
<booktitle>In Proc. of the 20th ICCL</booktitle>
<pages>1367--1373</pages>
<contexts>
<context position="2014" citStr="Kim and Hovy (2004)" startWordPosition="279" endWordPosition="282">lling, and so on. Opinion dictionaries are important resources for identifying subjective information. Several approaches were proposed to collect such resources. Wiebe (2000) learned subjective adjectives from corpora. Takamura et al. (2005) extracted semantic orientations of words. Ku et al. (2007) measured sentiment degrees of Chinese words by averaging the sentiment scores of the composing characters. When the opinion words are available, the polarities of sentences and documents can be determined by them. Riloff and Wiebe (2003) learned the extraction patterns for subjective expressions. Kim and Hovy (2004) found the polarity of subjective expressions. Pang et al. (2002) and Dave et al. (2003) explored various techniques at document level. Morphological information has been widely used in classifying words, telling the meanings, and doing other in-depth analysis (Tzeng and Chen, 2002). However, morphological information was seldom applied either in Chinese opinion extraction, or in solving the coverage problem of opinion dictionary. Instead of bag-ofcharacters approach (Ku et al., 2007), this paper employs morphological structures of words to extract opinion words. Relations between sentence seg</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Kim, S.-M. and Hovy, E. 2004. Determining the Sentiment of Opinions. In Proc. of the 20th ICCL (pp. 1367-1373).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L-W Ku</author>
<author>H-H Chen</author>
</authors>
<title>Mining Opinions from the Web: Beyond Relevance Retrieval.</title>
<date>2007</date>
<journal>Journal of American Society for Information Science and Technology, Special Issue on Mining Web Resources for Enhancing Information Retrieval,</journal>
<volume>58</volume>
<issue>12</issue>
<pages>1838--1850</pages>
<marker>Ku, Chen, 2007</marker>
<rawString>Ku, L.-W. and Chen, H.-H. 2007. Mining Opinions from the Web: Beyond Relevance Retrieval. Journal of American Society for Information Science and Technology, Special Issue on Mining Web Resources for Enhancing Information Retrieval, 58(12), 1838-1850.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data,</title>
<date>2001</date>
<booktitle>In Proc. of ICML</booktitle>
<pages>282--289</pages>
<contexts>
<context position="17612" citStr="Lafferty et al., 2001" startWordPosition="3078" endWordPosition="3081">training words, and the position information of the composite characters. The tone of the word is acquired from MOEDCW. The parts of speech are estimated by Formula (11). f(C, POS, k, start/end) counts the number of k-grams (k=2, 3, 4). In Figures 1 and 2, f(冒, V, 2, start)=6, f(冒, V, 2, end)= 2, f(冒, ADV, 2, start) = 2, and f(冒, ADV, 2, end)=0. This example shows that when the character “冒” functions as a verb or an adverb, it serves as the starting character more often than the ending character. 4.3 CRF and SVM Classifier CRF and SVM are both common used algorithms for building classifiers (Lafferty et al., 2001). We adopted CRF++1 and libSVM (Chang and Lin, 2001) to develop our classifiers. The features for training our CRF and SVM classifiers include the input word W, the tone of W, the first and the second characters C1 and C2, T(C1, POS), T(C2, POS), f(C1, POS, k, start), f(C1, POS, k, end), f(C2, POS, k, start), and f(C2, POS, k, end). POS denotes one of nine parts of speech in MOEDCW, and k equals to 2, 3 or 4. Using SVM is straightforward. To classify a word into one of the morphological structure types, we construct the word&apos;s feature vector and input the vector into SVM. When using CRF, a dif</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A. and Pereira, F. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data, In Proc. of ICML (pp.282-289).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification Using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>In Proc. of the 2002 Conference on EMNLP</booktitle>
<pages>79--86</pages>
<contexts>
<context position="2079" citStr="Pang et al. (2002)" startWordPosition="289" endWordPosition="292"> identifying subjective information. Several approaches were proposed to collect such resources. Wiebe (2000) learned subjective adjectives from corpora. Takamura et al. (2005) extracted semantic orientations of words. Ku et al. (2007) measured sentiment degrees of Chinese words by averaging the sentiment scores of the composing characters. When the opinion words are available, the polarities of sentences and documents can be determined by them. Riloff and Wiebe (2003) learned the extraction patterns for subjective expressions. Kim and Hovy (2004) found the polarity of subjective expressions. Pang et al. (2002) and Dave et al. (2003) explored various techniques at document level. Morphological information has been widely used in classifying words, telling the meanings, and doing other in-depth analysis (Tzeng and Chen, 2002). However, morphological information was seldom applied either in Chinese opinion extraction, or in solving the coverage problem of opinion dictionary. Instead of bag-ofcharacters approach (Ku et al., 2007), this paper employs morphological structures of words to extract opinion words. Relations between sentence segments are also defined by linguistics in the Chinese language. Th</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Pang, B., Lee, L. and Vaithyanathan, S. 2002. Thumbs up? Sentiment Classification Using Machine Learning Techniques. In Proc. of the 2002 Conference on EMNLP (pp. 79-86).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
</authors>
<title>Learning Extraction Patterns for Subjective Expressions.</title>
<date>2003</date>
<booktitle>In Proc. of the 2003 Conference on EMNLP</booktitle>
<pages>105--112</pages>
<contexts>
<context position="1934" citStr="Riloff and Wiebe (2003)" startWordPosition="268" endWordPosition="271">variety of fields, including product recommendation, review summarization, public polling, and so on. Opinion dictionaries are important resources for identifying subjective information. Several approaches were proposed to collect such resources. Wiebe (2000) learned subjective adjectives from corpora. Takamura et al. (2005) extracted semantic orientations of words. Ku et al. (2007) measured sentiment degrees of Chinese words by averaging the sentiment scores of the composing characters. When the opinion words are available, the polarities of sentences and documents can be determined by them. Riloff and Wiebe (2003) learned the extraction patterns for subjective expressions. Kim and Hovy (2004) found the polarity of subjective expressions. Pang et al. (2002) and Dave et al. (2003) explored various techniques at document level. Morphological information has been widely used in classifying words, telling the meanings, and doing other in-depth analysis (Tzeng and Chen, 2002). However, morphological information was seldom applied either in Chinese opinion extraction, or in solving the coverage problem of opinion dictionary. Instead of bag-ofcharacters approach (Ku et al., 2007), this paper employs morphologi</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Riloff, E. and Wiebe, J. 2003. Learning Extraction Patterns for Subjective Expressions. In Proc. of the 2003 Conference on EMNLP (pp. 105-112).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Seki</author>
<author>D K Evans</author>
<author>L-W Ku</author>
<author>L Sun</author>
<author>H-H Chen</author>
<author>N Kando</author>
</authors>
<title>Overview of Multilingual Opinion Analysis Task at NTCIR-7.</title>
<date>2008</date>
<booktitle>In Proceedings of the 7th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering, and Cross-Lingual Information Access.</booktitle>
<contexts>
<context position="28135" citStr="Seki et al., 2008" startWordPosition="4801" endWordPosition="4804">rimental sentences. For this purpose, we adopted Chinese Treebank 5.14 as the experimental materials. Chinese Treebank contains raw Chinese news documents together with their segmented, part of speech tagged, and parsed versions. The parsed documents are adopted in experiments utilizing structural trios, and the part of speech tagged documents are used in experiments not utilizing structural trios. In Chinese Treebank, a unique ID is labeled on each sentence. For each sentence, we had three annotators label their opinions and then we generate the gold standard following NTCIR 5 MOAT protocol (Seki et al., 2008). We also annotated structure trios in Chinese Treebank. A total of 17,159 sentences are obtained after dropping some faulty sentences such as empty sentences and sentences composed of more than one parsing tree. The statistics of opinion sentences and structural trios in the constructed experimental materials are shown in Table 4 and Table 5. 4 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp? catalogId=LDC2005T01 5 http://research.nii.ac.jp/ntcir/index-en.html 1266 Opinion Non-Opinion Positive Neutral Negative 7,528 # 6,380 1,537 1,714 9,631 % 66.24 15.96 17.80 43.87 56.13 Table 4: Statisti</context>
</contexts>
<marker>Seki, Evans, Ku, Sun, Chen, Kando, 2008</marker>
<rawString>Seki, Y., Evans, D. K., Ku, L.-W., Sun, L., Chen, H.-H. and Kando, N. 2008. Overview of Multilingual Opinion Analysis Task at NTCIR-7. In Proceedings of the 7th NTCIR Workshop Meeting on Evaluation of Information Access Technologies: Information Retrieval, Question Answering, and Cross-Lingual Information Access.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>J Ruppenhofer</author>
<author>J Wiebe</author>
</authors>
<title>Detecting arguing and sentiment in meetings.</title>
<date>2007</date>
<booktitle>Proceedings of the SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>2007--8</pages>
<contexts>
<context position="3226" citStr="Somasundaran et al., 2007" startWordPosition="458" endWordPosition="461">n sentence segments are also defined by linguistics in the Chinese language. These are similar to morphological structures between Chinese characters. Based on parsing trees of sentences, we identify these relations and utilize them for opinion analysis on sentences. As the experimental corpus, some researchers managed to generate annotated materials and gold standards under many constraints. Ku set a standard for generating final answers from annotations of multiple annotators (Ku et al., 2007), and Somasundaran annotated discourse information from meeting dialogs to train a sentiment model (Somasundaran et al., 2007). For multilingual issues, researchers concerned mainly about the applicability of corpus and algorithms from the native language to foreign languages (Banea et al., 2008; Bautin et al., 2008). Several opinion analysis systems have been developed so far. OASYS (Cesarano et al., 2007) and CopeOpi (Ku et al., 2007) allow users input their queries and select preferred data sources, 1260 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1260–1269, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP and then track opinions in a time zone. For both systems, e</context>
</contexts>
<marker>Somasundaran, Ruppenhofer, Wiebe, 2007</marker>
<rawString>Somasundaran, S., Ruppenhofer, J. and Wiebe, J. 2007. Detecting arguing and sentiment in meetings. Proceedings of the SIGdial Workshop on Discourse and Dialogue, 2007.8.6</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Takamura</author>
<author>T Inui</author>
<author>M Okumura</author>
</authors>
<title>Extracting Semantic Orientations of Words Using Spin Model.</title>
<date>2005</date>
<booktitle>In Proc. of the 43rd Annual Meeting of the ACL</booktitle>
<pages>133--140</pages>
<contexts>
<context position="1637" citStr="Takamura et al. (2005)" startWordPosition="222" endWordPosition="225">tence extraction, and 0.54 for opinion sentence polarity detection. 1 Introduction Sentiment analysis has attracted much attention in recent years because a large scale of subjective information is disseminated through various platforms on the web. Sentiment information can be applied to a wide variety of fields, including product recommendation, review summarization, public polling, and so on. Opinion dictionaries are important resources for identifying subjective information. Several approaches were proposed to collect such resources. Wiebe (2000) learned subjective adjectives from corpora. Takamura et al. (2005) extracted semantic orientations of words. Ku et al. (2007) measured sentiment degrees of Chinese words by averaging the sentiment scores of the composing characters. When the opinion words are available, the polarities of sentences and documents can be determined by them. Riloff and Wiebe (2003) learned the extraction patterns for subjective expressions. Kim and Hovy (2004) found the polarity of subjective expressions. Pang et al. (2002) and Dave et al. (2003) explored various techniques at document level. Morphological information has been widely used in classifying words, telling the meanin</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Takamura, H., Inui, T. and Okumura, M. 2005. Extracting Semantic Orientations of Words Using Spin Model. In Proc. of the 43rd Annual Meeting of the ACL (pp. 133-140).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tzeng</author>
<author>K-J Chen</author>
</authors>
<title>Design of Chinese Morphological Analyzer.</title>
<date>2002</date>
<booktitle>In Proc. of the 1st SIGHAN Workshop on Chinese Language Processing,</booktitle>
<volume>18</volume>
<pages>1--7</pages>
<contexts>
<context position="2297" citStr="Tzeng and Chen, 2002" startWordPosition="322" endWordPosition="325">ds. Ku et al. (2007) measured sentiment degrees of Chinese words by averaging the sentiment scores of the composing characters. When the opinion words are available, the polarities of sentences and documents can be determined by them. Riloff and Wiebe (2003) learned the extraction patterns for subjective expressions. Kim and Hovy (2004) found the polarity of subjective expressions. Pang et al. (2002) and Dave et al. (2003) explored various techniques at document level. Morphological information has been widely used in classifying words, telling the meanings, and doing other in-depth analysis (Tzeng and Chen, 2002). However, morphological information was seldom applied either in Chinese opinion extraction, or in solving the coverage problem of opinion dictionary. Instead of bag-ofcharacters approach (Ku et al., 2007), this paper employs morphological structures of words to extract opinion words. Relations between sentence segments are also defined by linguistics in the Chinese language. These are similar to morphological structures between Chinese characters. Based on parsing trees of sentences, we identify these relations and utilize them for opinion analysis on sentences. As the experimental corpus, s</context>
</contexts>
<marker>Tzeng, Chen, 2002</marker>
<rawString>Tzeng, H. and Chen, K.-J. 2002. Design of Chinese Morphological Analyzer. In Proc. of the 1st SIGHAN Workshop on Chinese Language Processing, vol.18, 1-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
</authors>
<title>Learning Subjective Adjectives from Corpora.</title>
<date>2000</date>
<booktitle>In Proc. of the 17th National Conference on AAAI and Twelfth Conference on IAAI</booktitle>
<pages>735--740</pages>
<contexts>
<context position="1570" citStr="Wiebe (2000)" startWordPosition="214" endWordPosition="215">for opinion word polarity detection, 0.80 for opinion sentence extraction, and 0.54 for opinion sentence polarity detection. 1 Introduction Sentiment analysis has attracted much attention in recent years because a large scale of subjective information is disseminated through various platforms on the web. Sentiment information can be applied to a wide variety of fields, including product recommendation, review summarization, public polling, and so on. Opinion dictionaries are important resources for identifying subjective information. Several approaches were proposed to collect such resources. Wiebe (2000) learned subjective adjectives from corpora. Takamura et al. (2005) extracted semantic orientations of words. Ku et al. (2007) measured sentiment degrees of Chinese words by averaging the sentiment scores of the composing characters. When the opinion words are available, the polarities of sentences and documents can be determined by them. Riloff and Wiebe (2003) learned the extraction patterns for subjective expressions. Kim and Hovy (2004) found the polarity of subjective expressions. Pang et al. (2002) and Dave et al. (2003) explored various techniques at document level. Morphological inform</context>
</contexts>
<marker>Wiebe, 2000</marker>
<rawString>Wiebe, J. 2000. Learning Subjective Adjectives from Corpora. In Proc. of the 17th National Conference on AAAI and Twelfth Conference on IAAI (pp. 735-740).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>