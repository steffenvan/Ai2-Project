<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000063">
<title confidence="0.996046">
Fine-grained Genre Classification using Structural Learning Algorithms
</title>
<author confidence="0.999008">
Zhili Wu Katja Markert Serge Sharoff
</author>
<affiliation confidence="0.9935925">
Centre for Translation Studies School of Computing Centre for Translation Studies
University of Leeds, UK University of Leeds, UK University of Leeds, UK
</affiliation>
<email confidence="0.984512">
z.wu@leeds.ac.uk scskm@leeds.ac.uk s.sharoff@leeds.ac.uk
</email>
<sectionHeader confidence="0.997232" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999895">
Prior use of machine learning in genre
classification used a list of labels as clas-
sification categories. However, genre
classes are often organised into hierar-
chies, e.g., covering the subgenres of fic-
tion. In this paper we present a method
of using the hierarchy of labels to improve
the classification accuracy. As a testbed
for this approach we use the Brown Cor-
pus as well as a range of other corpora, in-
cluding the BNC, HGC and Syracuse. The
results are not encouraging: apart from the
Brown corpus, the improvements of our
structural classifier over the flat one are
not statistically significant. We discuss the
relation between structural learning per-
formance and the visual and distributional
balance of the label hierarchy, suggesting
that only balanced hierarchies might profit
from structural learning.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999888879310345">
Automatic genre identification (AGI) can be
traced to the mid-1990s (Karlgren and Cutting,
1994; Kessler et al., 1997), but this research be-
came much more active in recent years, partly be-
cause of the explosive growth of the Web, and
partly because of the importance of making genre
distinctions in NLP applications. In Information
Retrieval, given the large number of web pages on
any given topic, it is often difficult for the users
to find relevant pages that are in the right genre
(Vidulin et al., 2007). As for other applications,
the accuracy of many tasks, such as machine trans-
lation, POS tagging (Giesbrecht and Evert, 2009)
or identification of discourse relations (Webber,
2009) relies of defining the language model suit-
able for the genre of a given text. For example,
the accuracy of POS tagging reaching 96.9% on
newspaper texts drops down to 85.7% on forums
(Giesbrecht and Evert, 2009), i.e., every seventh
word in forums is tagged incorrectly.
This interest in genres resulted in a prolifer-
ation of studies on corpus development of web
genres and comparison of methods for AGI. The
two corpora commonly used for this task are KI-
04 (Meyer zu Eissen and Stein, 2004) and San-
tinis (Santini, 2007). The best results reported for
these corpora (with 10-fold cross-validation) reach
84.1% on KI-04 and 96.5% accuracy on Santinis
(Kanaris and Stamatatos, 2009). In our research
(Sharoff et al., 2010) we produced even better re-
sults on these two benchmarks (85.8% and 97.1%,
respectively). However, this impressive accuracy
is not realistic in vivo, i.e., in classifying web
pages retrieved as a result of actual queries. One
reason comes from the limited number of genres
present in these two collections (eight genres in
KI-04 and seven in Santinis). As an example, only
front pages of online newspapers are listed in San-
tinis, but not actual newspaper articles, so once an
article is retrieved, it cannot be assigned to any
class at all. Another reason why the high accu-
racy is not useful concerns the limited number of
sources in each collection, e.g., all FAQs in Santi-
nis come from either a website with FAQs on hur-
ricanes or another one with tax advice. In the end,
a classifier built for FAQs on this training data re-
lies on a high topic-genre correlation in this par-
ticular collection and fails to spot any other FAQs.
There are other corpora, which are more diverse
in the range of their genres, such as the fifteen
genres of the Brown Corpus (Kuˇcera and Fran-
cis, 1967) or the seventy genres of the BNC (Lee,
2001), but because of the number of genres in
them and the diversity of documents within each
genre, the accuracy of prior work on these collec-
tions is much less impressive. For example, Karl-
gren and Cutting (1994) using linear discriminant
analysis achieve an accuracy of 52% without us-
</bodyText>
<page confidence="0.979216">
749
</page>
<note confidence="0.9434755">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 749–759,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999808857142857">
ing cross-validation (the entire Brown Corpus was
used as both the test set and training set), with the
accuracy improving to 65% when the 15 genres
are collapsed into 10, and to 73% with only 4 gen-
res (Figure 1). This result suggests the importance
of the hierarchy of genres. Firstly, making a deci-
sion on higher levels might be easier than on lower
levels (fiction or non-fiction rather than science
fiction or mystery). Secondly, we might be able
to improve the accuracy on lower levels, by taking
into account the relevant position of each node in
the hierarchy (distinguishing between reportage
or editorial becomes easier when we know they
are safely under the category of press).
</bodyText>
<figureCaption confidence="0.999091">
Figure 1: Hierarchy of Brown corpus.
</figureCaption>
<bodyText confidence="0.999987045454546">
This paper explores a way of using information on
the hierarchy of labels for improving fine-grained
genre classification. To the best of our knowl-
edge, this is the first work presenting structural
genre classification and distance measures for gen-
res. In Section 2 we present a structural reformula-
tion of Support Vector Machines (SVMs) that can
take similarities between different genres into ac-
count. This formulation necessitates the develop-
ment of distance measures between different gen-
res in a hierarchy, of which we present three dif-
ferent types in Section 3, along with possible esti-
mation procedures for these distances. We present
experiments with these novel structural SVMs and
distance measures on three different corpora in
Section 4. Our experiments show that structural
SVMs can outperform the non-structural standard.
However, the improvement is only statistically sig-
nificant on the Brown corpus. In Section 5 we
investigate potential reasons for this, including
the (im)balance of different genre hierarchies and
problems with our distance measures.
</bodyText>
<sectionHeader confidence="0.980712" genericHeader="method">
2 Structural SVMs
</sectionHeader>
<bodyText confidence="0.999980636363637">
Discriminative methods are often used for clas-
sification, with SVMs being a well-performing
method in many tasks (Boser et al., 1992;
Joachims, 1999). Linear SVMs on a flat list of
labels achieve high efficiency and accuracy in text
classification when compared to nonlinear SVMs
or other state-of-the-art methods. As for structural
output learning, a few SVM-based objective func-
tions have been proposed, including margin for-
mulation for hierarchical learning (Dekel et al.,
2004) or general structural learning (Joachims
et al., 2009; Tsochantaridis et al., 2005). But many
implementations are not publicly available, and
their scalability to real-life text classification tasks
is unknown. Also they have not been applied to
genre classification.
Our formulation can be taken as a special in-
stance of the structural learning framework in
(Tsochantaridis et al., 2005). However, they con-
centrate on more complicated label structures as
for sequence alignment or parsing. They proposed
two formulations, slack-rescaling and margin-
rescaling, claiming that margin-rescaling has two
disadvantages. First, it potentially gives signifi-
cant weight to output values that might not be eas-
ily confused with the target values, because every
increase in the loss increases the required margin.
However, they did not provide empirical evidence
for this claim. Second, margin rescaling is not
necessarily invariant to the scaling of the distance
matrix. We still used margin-rescaling because it
allows us to use the sequential dual method for
large-scale implementation (Keerthi et al., 2008),
which is not applicable to the slack-rescaling for-
mulation. For web page classification we will
need fast processing. In addition, we performed
model calibration to address the second disadvan-
tage (distance matrix invariance).
Let x be a document and wm a weight vector
associated with the genre class m in a corpus with
k genres at the most fine-grained level. The pre-
dicted class is the class achieving the maximum
inner product between x and the weight vector for
the class, denoted as,
</bodyText>
<equation confidence="0.832231666666667">
wmx,Vm. (1)
arg max
m
</equation>
<page confidence="0.981015">
750
</page>
<bodyText confidence="0.9998182">
Accurate prediction requires that when a docu-
ment vector is multiplied with the weight vector
associated with its own class, the resulting inner
product should be larger than its inner products
with a weight vector for any other genre class m.
This helps us to define criteria for weight vectors.
Let xi be the i−th training document, and yi its
genre label. For its weight vector wyo the inner
product wTy�xi should be larger than all other prod-
ucts wTmxi, that is,
</bodyText>
<equation confidence="0.869208">
wTy�xi − wT mxi ≥ 0, ∀m. (2)
</equation>
<bodyText confidence="0.9999796">
To strengthen the constraints, the zero value on the
right hand side of the inequality for the flat SVM
can be replaced by a positive value, corresponding
to a distance measure h(yi, m) between two genre
classes, leading to the following constraint:
</bodyText>
<equation confidence="0.830859">
wTy�xi − wT mxi ≥ h(yi, m), ∀m. (3)
</equation>
<bodyText confidence="0.9999446">
To allow feasible models, in real scenarios such
constraints can be violated, but the degree of vio-
lation is expected to be small. For each document,
the maximum violation in the k constraints is of
interest, as given by the following loss term:
</bodyText>
<equation confidence="0.999441">
Lossi = max
m {h(yi, m) − wTy�xi + wT mxi}. (4)
</equation>
<bodyText confidence="0.994777555555556">
Adding up all loss terms over all training docu-
ments, and further introducing a term to penalize
large values in the weight vectors, we have the
following objective function (C is a user-specified
nonnegative parameter).
Efficient methods can be derived by borrowing the
sequential dual methods in (Keerthi et al., 2008)
or other optimization techniques (Crammer and
Singer, 2002).
</bodyText>
<sectionHeader confidence="0.993688" genericHeader="method">
3 Genre Distance Measures
</sectionHeader>
<bodyText confidence="0.999507777777778">
The structural SVM (Section 2) requires a dis-
tance measure h between two genres. We can
derive such distance measures from the genre
hierarchy in a way similar to word similarity
measures that were invented for lexical hierar-
chies such as WordNet (see (Pedersen et al.,
2007) for an overview). In the following,
we will first shortly summarise path-based and
information-based measures for similarity. How-
ever, information-based measures are based on
the information content of a node in a hierarchy.
Whereas the information content of a word or con-
cept in a lexical hierarchy has been well-defined
(Resnik, 1995), it is less clear how to estimate
the information content of a genre label. We will
therefore discuss several different ways of estimat-
ing information content of nodes in a genre hierar-
chy.
</bodyText>
<subsectionHeader confidence="0.998453">
3.1 Distance Measures based on Path Length
</subsectionHeader>
<bodyText confidence="0.893032">
If genre labels are organised into a tree (Figure 1),
one of the simplest ways to measure distance be-
tween two genre labels (= tree nodes) is path
length (h(a, b)plen):
</bodyText>
<equation confidence="0.9114">
f(a, LC5(a, b)) + f(b, LC5(a, b)), (6)
</equation>
<bodyText confidence="0.96379125">
where a and b are two nodes in the tree,
LC5(a, b) is their Least Common Subsumer, and
f(a, LC5(a, b)) is the number of levels passed
through when traversing from a to the ancestral
node LC5(a, b). In other words, the distance
counts the number of edges traversed from nodes a
to b in the tree. For example, the distance between
Learned and Misc in Figure 1 would be 3.
As an alternative, the maximum path length
h(a, b)pmax to their least common subsumer can
be used to reduce the range of possible values:
max{f(a, LC5(a, b)), f(b, LC5(a, b))}. (7)
The Leacock &amp; Chodorow similarity measure
(Leacock and Chodorow, 1998) normalizes the
path length measure (6) by the maximum number
of nodes D when traversing down from the root.
</bodyText>
<equation confidence="0.794174">
s(a, b)plsk = −log((h(a, b)plen + 1)/2D). (8)
</equation>
<bodyText confidence="0.6842105">
To convert it into a distance measure, we can
invert it h(a, b)plsk = 1/s(a, b)plsk.
Other path-length based measures include the
Wu &amp; Palmer Similarity (Wu and Palmer, 1994).
</bodyText>
<construct confidence="0.809824666666667">
2f(R, LC5(a, b))
s(a, b)pwupal = (9)
( f (R, a) + f (R, b))
</construct>
<bodyText confidence="0.996700166666667">
where R describes the hierarchy’s root node. Here
similarity is proportional to the shared path from
the root to the least common subsumer of two
nodes. Since the Wu &amp; Palmer similarity is always
between [0 1), we can convert it into a distance
measure by h(a, b)pwupal = 1 − s(a, b
</bodyText>
<equation confidence="0.989686375">
T
wmwm + C
Lossi. (5)
min � 1 k
m,i 2 m=1
� p
i=1
)pwupal.
</equation>
<page confidence="0.986292">
751
</page>
<subsectionHeader confidence="0.973805">
3.2 Distance Measures based on Information
Content
</subsectionHeader>
<bodyText confidence="0.9997753125">
Path-based distance measures work relatively well
on balanced hierarchies such as the one in Figure 1
but fail to treat hierarchies with different levels
of granularity well. For lexical hierarchies, as a
result, several distance measures based on infor-
mation content have been suggested where the in-
formation content of a concept c in a hierarchy is
measured by (Resnik, 1995)
The frequency freq of a concept c is the sum of
the frequency of the node c itself and the frequen-
cies of all its subnodes. Since the root may be a
dummy concept, its frequency is simply the sum
of the frequencies of all its subnodes. The simi-
larity between two nodes can then be defined as
the information content of their least common sub-
sumer:
</bodyText>
<equation confidence="0.730275">
s(a, b)resk = IC(LCS(a, b)). (11)
</equation>
<bodyText confidence="0.95680875">
If two nodes just share the root as their subsumer,
their similarity will be zero. To convert 11 into a
distance measure, it is possible to add a constant 1
to it before inverting it, as given by
h(a, b)resk = 1/(s(a, b)resk + 1). (12)
Several other similarity measures have been pro-
posed based on the Resnik similarity such as the
one by (Lin, 1998):
</bodyText>
<equation confidence="0.990017">
2IC(LCS(a, b))
s(a, b)lin = IC(a) + IC(b) .(13)
</equation>
<bodyText confidence="0.9905095">
Again to avoid the effect of zero similarity when
defining the Lin’s distance we use:
</bodyText>
<equation confidence="0.96156525">
h(a, b)lin = 1/(s(a, b)lin + 1). (14)
(Jiang and Conrath, 1997) directly define Jiang’s
distance (h(a, b)pg):
IC(a) + IC(b) − 2IC(LCS(a, b)). (15)
</equation>
<subsubsectionHeader confidence="0.424449">
3.2.1 Information Content of Genre Labels
</subsubsectionHeader>
<bodyText confidence="0.998534955555555">
The notion of information content of a genre is not
straightforward. We use two ways of measuring
the frequency freq of a genre, depending on its
interpretation.
Genre Frequency based on Document Occur-
rence. We can interpret the “frequency” of a
genre node simply as the number of all documents
belonging to that genre (including any of its sub-
genres). Unfortunately, there are no estimates for
genre frequencies on, for example, a representa-
tive sample of web documents. Therefore, we ap-
proximate genre frequencies from the document
frequencies (dfs) in the training sets used in clas-
sification. Note that (i) for balanced class distribu-
tions this information will not be helpful and (ii)
that this is a relatively poor substitute for an esti-
mation on an independent, representative corpus.
Genre Frequency based on Genre Labels. We
can also use the labels/names of the genre nodes
as the unit of frequency estimation. Then, the
frequency of a genre node is the occurrence fre-
quency of its label in a corpus plus the occurrence
frequencies of the labels of all its subnodes. Note
that there is no direct correspondence between this
measure and the document frequency of a genre:
measuring the number of times the potential genre
label poem occurs in a corpus is not in any way
equivalent to the number of poems in that corpus.
However, the measure is still structurally aware
as frequencies of labels of subnodes are included,
i.e. a higher level genre label will have higher
frequency (and lower information content) than a
lower level genre label.1
For label frequency estimation, we manually
expand any label abbreviations (such as &amp;quot;newsp&amp;quot;
for BNC genre labels), delete stop words and func-
tion words and then use two search methods. For
the search method word we simply search the fre-
quency of the genre label in a corpus, using three
different corpora (the BNC, Brown and Google
web search). As for the BNC and Brown cor-
pus some labels are very rarely mentioned, we for
these two corpora use also a search method gram
where all character 5-grams within the genre label
are searched for and their frequencies aggregated.
</bodyText>
<subsectionHeader confidence="0.985392">
3.3 Terminology
</subsectionHeader>
<bodyText confidence="0.993885444444444">
Algorithms are prefixed by the kind of distance
measure they employ — IC for Information con-
tent and p for path-based). If the measure is infor-
1Obviously when using this measure we rely on genre la-
bels which are meaningful in the sense that lower level labels
were chosen to be more specific and therefore probably rarer
terms in a corpus. The measure could not possibly be use-
ful on a genre hierarchy that would give random names to its
genres such as genre 1.
</bodyText>
<equation confidence="0.9935485">
IC(c) = −log( freq(c)
f req(root)). (10)
</equation>
<page confidence="0.979559">
752
</page>
<bodyText confidence="0.9999714">
mation content based the specific measure is men-
tioned next, such as lin. The way for measuring
genre frequency is indicated last with df for mea-
suring via document frequency and word/gram
when measured via frequency of genre labels. If
frequencies of genre labels are used, the corpus
for counting the occurrence of genre labels is also
indicated via brown, bnc or the Web as estimated
by Google hit counts gg. Standard non-structural
SVMs are indicated by flat.
</bodyText>
<sectionHeader confidence="0.999095" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.94548">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999967">
We use four genre-annotated corpora for genre
classification: the Brown Corpus (Kuˇcera and
Francis, 1967), BNC (Lee, 2001), HGC (Stubbe
and Ringlstetter, 2007) and Syracuse (Crowston
et al., 2009). They have a wide variety of genre
labels (from 15 in the Brown corpus to 32 genres
in HGC to 70 in the BNC to 292 in Syracuse), and
different types of hierarchies.
</bodyText>
<subsectionHeader confidence="0.955359">
4.2 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.999957652173913">
We use standard classification accuracy (Acc) on
the most fine-grained level of target categories in
the genre hierarchy.
In addition, given a structural distance H, mis-
classifications can be weighted based on the dis-
tance measure. This allows us to penalize incor-
rect predictions which are further away in the hi-
erarchy (such as between government documents
and westerns) more than &amp;quot;close&amp;quot; mismatches (such
as between science fiction and westerns). For-
mally, given the classification confusion matrix M
then each Mab for a =� b contains the number
of class a documents that are misclassified into
class b. To achieve proper normalization in giv-
ing weights to misclassified entries, we can redis-
tribute a total weight k − 1 to each row of H pro-
portionally to its values, where k is the number
of genres. That is, given g the row summation
of H, we define a weight matrix Q by normal-
izing the rows of H in a way given by Qab =
(k − 1)hab/ga, a =� b. We further assign a unit
value to the diagonal of Q. Then it is possible to
construct a structurally-aware measure (S-Acc):
</bodyText>
<equation confidence="0.8438045">
�S-Acc = �Maa/ MabQab. (16)
a a,b
</equation>
<subsectionHeader confidence="0.982747">
4.3 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999934611111111">
We compare structural SVMs using all path-based
and information-content based measures (see also
Section 3.3). As a baseline we use the accuracy
achieved by a standard &amp;quot;flat&amp;quot; SVM.
We use 10-fold (randomised) cross validation
throughout. In each fold, for each genre class 10%
of documents are used for testing. For the re-
maining 90%, a portion of 10% are sampled for
parameter tuning, leaving 80% for training. In
each round the validation set is used to help de-
termine the best C associated with Equation (5)
based on the validation accuracy from the candi-
date list 0.0001, 0.0005, 0.001, 0.005, 0.01,
0.05, 0.1, 0.5, 1. Note via this experiment setup,
all methods are tuned to their best performance.
For any algorithm comparison, we use a McNe-
mar test with the significance level of 5% as rec-
ommended by (Dietterich, 1998).
</bodyText>
<subsectionHeader confidence="0.745088">
4.4 Features
</subsectionHeader>
<bodyText confidence="0.9999882">
The features used for genre classification are char-
acter 4-grams for all algorithms, i.e. each docu-
ment is represented by a binary vector indicating
the existence of each character 4-gram. We used
character n-grams because they are very easy to
extract, language-independent (no need to rely on
parsing or even stemming), and they are known
to have the best performance in genre classifica-
tion tasks (Kanaris and Stamatatos, 2009; Sharoff
et al., 2010).
</bodyText>
<subsectionHeader confidence="0.971842">
4.5 Brown Corpus Results
</subsectionHeader>
<bodyText confidence="0.993396764705882">
The Brown Corpus has 500 documents and is or-
ganized in a hierarchy with a depth of 3. It
contains 15 end-level genres. In one experiment
in (Karlgren and Cutting, 1994) the subgenres un-
der fiction are grouped together, leading to 10 gen-
res to classify.
Results on 10-genre Brown Corpus. A stan-
dard flat SVM achieves an accuracy of 64.4%
whereas the best structural SVM based on Lin’s
information content distance measure (IC-lin-
word-bnc) achieves 68.8% accuracy, significantly
better at the 1% level. The result is also signif-
icantly better than prior work on the Brown cor-
pus in (Karlgren and Cutting, 1994) (who use the
whole corpus as test as well as training data). Ta-
ble 1 summarizes the best performing measures
that all outperform the flat SVM at the 1% level.
</bodyText>
<page confidence="0.999045">
753
</page>
<tableCaption confidence="0.99841">
Table 1: Brown 10-genre Classification Results.
</tableCaption>
<table confidence="0.899765833333333">
Method Accuracy
Karlgren and Cutting, 1994 65 (Training)
Flat SVM 64.40
SSVM(IC-lin-word-bnc) 68.80
SSVM(IC-lin-word-br) 68.60
SSVM(IC-lin-gram-br) 67.80
</table>
<bodyText confidence="0.966828285714286">
Figure 2 provides the box plots of accuracy scores.
The dashed boxes indicate that the distance mea-
sures perform significantly worse than the best
performing IC-lin-word-bnc at the bottom. The
solid boxes indicate the corresponding measures
are statistically comparable to the IC-lin-word-bnc
in terms of the mean accuracy they can achieve.
</bodyText>
<figure confidence="0.7354062">
IC−jng−word−gg
IC−jng−gram−br
IC−jng−gram−bnc
flat
IC−jng−word−bnc
IC−jng−word−br
pmax
plsk
IC−lin−word−gg
IC−resk−word−br
IC−resk−gram−bnc
IC−lin−df
IC−resk−gram−br
IC−lin−gram−bnc
IC−resk−df
plen
IC−resk−word−gg
IC−resk−word−bnc
IC−lin−gram−br
pwupal
IC−jng−df
IC−lin−word−br
IC−lin−word−bnc
50 55 60 65 70 75 80
Accuracy
</figure>
<figureCaption confidence="0.999619">
Figure 2: Accuracy on Brown Corpus (10 genres).
</figureCaption>
<bodyText confidence="0.998359925925926">
Results on 15-genre Brown Corpus. We per-
form experiments on all 15 genres on the end level
of the Brown corpus. The increase of genre classes
leads to reduced classification performance. In our
experiment, the flat SVM achieves an accuracy of
52.40%, and the structural SVM using path length
measure achieves 55.40%, a difference significant
at the 5% level. The structural SVMs using infor-
mation content measures IC-lin-gram-bnc and IC-
resk-word-br also perform equally well. In addi-
tion, we improve on the training accuracy of 52%
reported in (Karlgren and Cutting, 1994).
We are also interested in structural accuracy (S-
Acc) to see whether the structural SVMs make
fewer &amp;quot;big&amp;quot; mistakes. Table 2 shows a cross com-
parison of structural accuracy. Each row shows
how accurate the corresponding method is un-
der the structural accuracy criteria given in the
column. The ’no-struct’ column corresponds to
vanilla accuracy. It is natural to expect each di-
agonal entry of the numeric table to be the high-
est, since the respective method is optimised for
its own structural distance. However, in our case,
Lin’s information content measure and the plen
measure perform well under any structural ac-
curacy evaluation measure and outperform flat
SVMs.
</bodyText>
<subsectionHeader confidence="0.981514">
4.6 Other Corpora
</subsectionHeader>
<bodyText confidence="0.999949909090909">
In spite of the promising results on the Brown
Corpus, structural SVMs on other corpora (BNC,
HGC, Syracuse) did not show considerable im-
provement.
HGC contains 1330 documents divided into 32
approximately equally frequent classes. Its hierar-
chy has just two levels. Standard accuracy for the
best performing structural methods on HGC is just
the same as for flat SVM (69.1%), with marginally
better structural accuracy (for example, 71.39 vs.
71.04%, using a path-length based structural ac-
curacy). The BNC corpus contains 70 genres and
4053 documents. The number of documents per
class ranges from 2 to 501. The accuracy of SSVM
is also just comparable to flat SVM (73.6%). The
Syracuse corpus is a recently developed large col-
lection of 3027 annotated webpages divided into
292 genres (Crowston et al., 2009). Focusing only
on genres containing 15 or more examples, we ar-
rived at a corpus of 2293 samples and 52 genres.
Accuracy for flat (53.3%) and structural SVMs
(53.7%) are again comparable.
</bodyText>
<sectionHeader confidence="0.999629" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9983952">
Given that structural learning can help in topical
classification tasks (Tsochantaridis et al., 2005;
Dekel et al., 2004), the lack of success on genres
is surprising. We now discuss potential reasons for
this lack of success.
</bodyText>
<subsectionHeader confidence="0.999054">
5.1 Tree Depth and Balance
</subsectionHeader>
<bodyText confidence="0.999945888888889">
Our best results were achieved on the Brown cor-
pus, whose genre tree has at least three attractive
properties. Firstly, it has a depth greater than 2,
i.e. several levels are distinguished. Secondly,
it seems visually balanced: branches from root
to leaves (or terminals) are of pretty much equal
length; branching factors are similar, for exam-
ple ranging between 2 and 6 for the last level of
branching. Thirdly, the number of examples at
</bodyText>
<page confidence="0.999428">
754
</page>
<tableCaption confidence="0.994363">
Table 2: Structural Accuracy on Brown 15-genre Classification.
</tableCaption>
<bodyText confidence="0.992084363636364">
Method no-struct (=typical accuracy) IC-lin-gram-bnc plen IC-resk-word-br IC-jng-word-gg
flat 52.40 55.34 60.60 58.91 52.19
IC-lin-gram-bnc 55.00 58.15 63.59 61.83 53.85
plen 55.40 58.74 64.51 62.61 54.27
IC-resk-word-br 55.00 58.24 63.96 62.08 54.08
IC-jng-word-gg 46.00 49.00 54.89 53.01 52.58
each leaf node is roughly comparable (distribu-
tional balance).
The other hierarchies violate these properties to
a large extent. Thus, the genres in HGC are al-
most represented by a flat list with just one extra
level over 32 categories. Similarly, the vast ma-
jority of genres in the Syracuse corpus are also
organised in two levels only. Such flat hierar-
chies do not offer much scope to improve over a
completely flat list. There are considerably more
levels in the BNC for some branches, e.g., writ-
ten/national/broadsheet/arts, but many other gen-
res are still only specified to the second level of
its hierarchy, e.g., written/adverts. In addition, the
BNC is also distributionally imbalanced, i.e. the
number of documents per class varies from 2 to
501 documents.
To test our hypothesis, we tried to skew the
Brown genre tree in two ways. First, we kept the
tree relatively balanced visually and distribution-
ally but flattened it by removing the second layer
Press, Misc, Non-Fiction, Fiction from the hierar-
chy, leaving a tree with only two layers. Second,
we skewed the visual and distributional balance of
the tree by collapsing its three leaf-level genres un-
der Press, and the two under non-fiction, leading to
12 genres to classify (cf. Figure 1).
</bodyText>
<figure confidence="0.93567412">
IC−jng−word−gg
IC−jng−word−bnc
IC−jng−word−br
IC−jng−gram−br
IC−jng−gram−bnc
IC−lin−word−gg
pmax
IC−resk−gram−br
plsk
IC−resk−df
flat
IC−jng−df
IC−lin−gram−br
IC−lin−word−bnc
IC−lin−df
IC−resk−word−gg
IC−lin−word−br
pwupal
plen
IC−lin−gram−bnc
IC−resk−word−br
IC−resk−gram−bnc
IC−resk−word−bnc
30 35 40 45 50 55 60 65 70
Accuracy
</figure>
<figureCaption confidence="0.9955155">
Figure 3: Accuracy on flattened Brown Corpus (15
genres).
</figureCaption>
<figure confidence="0.7101028">
IC−jng−word−gg
IC−jng−word−bnc
IC−jng−word−br
IC−jng−gram−bnc
IC−lin−word−gg
IC−resk−word−gg
IC−jng−df
IC−jng−gram−br
IC−lin−gram−bnc
IC−lin−df
IC−lin−word−br
flat
IC−lin−gram−br
plsk
IC−resk−word−bnc
plen
pwupal
IC−lin−word−bnc
IC−resk−df
IC−resk−gram−br
pmax
IC−resk−gram−bnc
IC−resk−word−br
35 40 45 50 55 60 65 70 75
Accuracy
</figure>
<figureCaption confidence="0.9768175">
Figure 4: Accuracy on skewed Brown Corpus (12
genres).
</figureCaption>
<bodyText confidence="0.99999148">
As expected, the structural methods on either
skewed or flattened hierarchies are not signifi-
cantly better than the flat SVM. For the flattened
hierarchy of 15 leaf genres the maximal accuracy
is 54.2% vs. 52.4% for the flat SVM (Figure 3), a
non-significant improvement. Similarly, the max-
imal accuracy on the skewed 12-genre hierarchy
is 58.2% vs. 56% (see also Figure 4), again a not
significant improvement.
To measure the degree of balance of a tree,
we introduce two tree balance scores based on
entropy. First, for both measures we extend all
branches to the maximum depth of the tree. Then
level by level we calculate an entropy score, ei-
ther according to how many tree nodes at the next
level belong to a node at this level (denoted as
vb: visual balance), or according to how many
end level documents belong to a node at this level
(denoted as db: distribution balance). To make
trees with different numbers of internal nodes
and leaves more comparable, the entropy score
at each level is normalized by the maximal en-
tropy achieved by a tree with uniform distribution
of nodes/documents, which is simply −log(1/N),
where N denotes the number of nodes at the corre-
</bodyText>
<page confidence="0.996573">
755
</page>
<bodyText confidence="0.999971155555556">
sponding level. Finally, the entropy scores for all
levels are averaged. It can be shown that any per-
fect N-ary tree will have the largest visual balance
score of 1. If in addition its nodes at each level
contain the same number of documents, the distri-
bution balance score will reach the maximum, too.
Table 3 shows the balance scores for all the cor-
pora we use. The first two rows for the Brown cor-
pus have both large visual balance and distribution
balance scores. As shown earlier, for those two se-
tups the structural SVMs perform better than the
flat approach. In contrast, for the tree hierarchies
of Brown that we deformed or flattened, and also
BNC and Syracuse, either or both of the two bal-
ance scores tend to be lower, and no improvement
has been obtained over the flat approach. This
may indicate that a further exploration of the rela-
tion between tree balance and the performance of
structural SVMs is warranted. However, high vi-
sual balance and distribution scores do not neces-
sarily imply high performance of structural SVMs,
as very flat trees are also visually very balanced.
As an example, HGC has a high visual balance
score due to a shallow hierarchy and a high distri-
butional balance score due to a roughly equal num-
ber of documents contained in each genre. How-
ever, HGC did not benefit from structural learning
as it is also a very shallow hierarchy; therefore we
think that a third variable depth also needs to be
taken into account.
A similar observation on the importance of
well-balanced hierarchies comes from a recent
Pascal challenge on large scale hierarchical text
classification,2 which shows that some flat ap-
proaches perform competitively in topic classifi-
cation with imbalanced hierarchies. However, the
participants do not explore explicitly the relation
between tree balance and performance.
Other methods for measuring tree balance
(some of which are related to ours) are used in
the field of phylogenetic research (Shao and Sokal,
1990) but they are only applicable to visual bal-
ance. In addition, the methods they used often
provide conflicting results on which trees are con-
sidered as balanced (Shao and Sokal, 1990).
</bodyText>
<subsectionHeader confidence="0.999826">
5.2 Distance Measures
</subsectionHeader>
<bodyText confidence="0.999680666666667">
We also scrutinise our distance measures as these
are crucial for the structural approach. We no-
tice that simple path length based measures per-
</bodyText>
<footnote confidence="0.874542">
2http://lshtc.iit.demokritos.gr/
</footnote>
<tableCaption confidence="0.99209">
Table 3: Tree Balance Scores
</tableCaption>
<table confidence="0.999696125">
Corpus depth vb db
Brown (10 genres) 3 0.9115 0.9024
Brown (15 genres) 3 0.9186 0.9083
Brown (15, flattened) 2 0.9855 0.8742
Brown (12, skewed) 3 0.8747 0.8947
HGC (32) 2 0.9562 0.9570
BNC (70) 4 0.9536 0.8039
Syracuse (52) 3 0.9404 0.8634
</table>
<bodyText confidence="0.999638846153846">
form well overall; again for the Brown corpus
this is probably due to its balanced hierarchy
which makes path length appropriate. There are
other probable reasons why information content
based measures do not perform better than path-
length based ones. When measured via docu-
ment frequency in a corpus we do not have suffi-
ciently large, representative genre-annotated cor-
pora to hand. When measured via genre label
frequency, we run into at least two problems.
Firstly, as mentioned in Section 3.2.1 genre la-
bel frequency does not have to correspond to class
frequency of documents. Secondly, the labels
used are often abbreviations (e.g. W_institut_doc,
W_newsp_brdsht_nat_social in BNC Corpus),
underspecified (other, misc, unclassified) or a col-
lection of phrases (e.g. belles letters, etc. in
Brown). This made search for frequency very ap-
proximate and also loosens the link between label
and content.
We investigated in more depth how well the dif-
ferent distance measures are aligned. We adapt
the alignment measure between kernels (Cristian-
ini et al., 2002), to investigate how close the dis-
tance matrices are. For two distance matrices H1
and H2, their alignment A(H1, H2) is defined as:
</bodyText>
<equation confidence="0.877656">
&lt; H1, H2 &gt;F
(17)
/&lt;H H &gt; &lt; H2 H &gt; &apos;
y 1� 1 F, � 2 F
</equation>
<bodyText confidence="0.999979583333333">
where &lt; H1, H2 &gt;F= �ki,j H1(gi,gj)H2(gi,gj)
which is the total sum of the entry-wise products
between the two distance matrices. Figure 5 shows
several distance matrices on the (original) 15 genre
Brown corpus. The plen matrix has clear blocks
for the super genres press, informative, imagina-
tive, etc. The IC-lin-gram-bnc matrix refines dis-
tances in the blocks, due to the introduction of in-
formation content. It keeps an alignment score that
is over 0.99 (the maximum is 1.00) toward the plen
matrix, and still has visible block patterns. How-
ever, the IC-jng-word-bnc significantly adjusts the
</bodyText>
<page confidence="0.994799">
756
</page>
<bodyText confidence="0.999277875">
distance entries, has a much lower alignment score
with the plen matrix, and doesn’t reveal appar-
ent blocks. This partially explains the bad perfor-
mance of the Jiang distance measure on the Brown
corpus (see Section 4). The diagrams also show
the high closeness between the best performing IC
measure and the simple path length based mea-
sure.
</bodyText>
<figureCaption confidence="0.799662">
Figure 5: Distance Matrices on Brown. Values in
bracket is the alignment with the plen matrix
</figureCaption>
<bodyText confidence="0.999992818181818">
An alternative to structural distance measures
would be distance measures between the gen-
res based on pairwise cosine similarities between
them. To assess this, we aggregated all character
4-gram training vectors of each genre and calcu-
lated standard cosine similarities. Note that these
similarities are based on the documents only and
do not make use of the Brown hierarchy at all. Af-
ter converting the similarities to distance, we plug
the distance matrix into our structural SVM. How-
ever, accuracy on the Brown corpus (15 genres)
was almost the same as for a flat SVM. Inspecting
the distance matrix visually, we determined that
the cosine similarity could clearly distinguish be-
tween Fiction and Non-Fiction texts but not be-
tween any other genres. This also indicates that
the genre structural hierarchy clearly gives infor-
mation not present in the simple character 4-gram
features we use. For a more detailed discussion
of the problems of the currently prevalently used
character n-grams as features for genre classifica-
tion, we refer the reader to (Sharoff et al., 2010).
</bodyText>
<sectionHeader confidence="0.999709" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999924103448276">
In this paper, we have evaluated structural learn-
ing approaches to genre classification using sev-
eral different genre distance measures. Although
we were able to improve on non-structural ap-
proaches for the Brown corpus, we found it hard to
improve over flat SVMs on other corpora. As po-
tential reasons for this negative result, we suggest
that current genre hierarchies are either not of suf-
ficient depth or are visually or distributionally im-
balanced. We think further investigation into the
relationship between hierarchy balance and struc-
tural learning is warranted. Further investigation
is also needed into the appropriateness of n-gram
features for genre identification as well as good
measures of genre distance.
In the future, an important task would be the re-
finement or unsupervised generation of new hier-
archies, using information theoretic or data-driven
approaches. For a full assessment of hierarchical
learning for genre classification, the field of genre
studies needs a testbed similar to the Reuters or 20
Newsgroups datasets used in topic-based IR with a
balanced genre hierarchy and a representative cor-
pus of reliably annotated webpages.
With regard to algorithms, we are also inter-
ested in other formulations for structural SVMs
and their large-scale implementation as well as the
combination of different distance measures, for
example in ensemble learning.
</bodyText>
<sectionHeader confidence="0.997364" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999824">
We would like to thank the authors of each corpus
collection, who invested a lot of effort into produc-
ing them. We are also grateful to Google Inc. for
supporting this research via their Google Research
Awards programme.
</bodyText>
<sectionHeader confidence="0.972424" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.922650769230769">
Boser, B. E., Guyon, I. M., and Vapnik, V. N.
(1992). A training algorithm for optimal mar-
gin classifiers. In COLT ’92: Proceedings of
the fifth annual workshop on Computational
learning theory, pages 144–152, New York,
NY, USA. ACM.
Crammer, K. and Singer, Y. (2002). On the algo-
rithmic implementation of multiclass kernel-
based vector machines. J. Mach. Learn. Res.,
2:265–292.
Cristianini, N., Shawe-Taylor, J., and Kandola, J.
(2002). On kernel target alignment. In Pro-
ceedings of the Neural Information Process-
</bodyText>
<figure confidence="0.99841375">
plen IC−lin−gram−bnc (0.98376)
Informative Imaginative Informative Imaginative
plsk (0.96061) IC−jng−word−bnc (0.92993)
nonfiction
Press
Misc
Press
Misc
nonfiction
Informative Imaginative Informative Imaginative
Press
Misc
nonfiction
nonfiction
Press
Misc
</figure>
<page confidence="0.9621">
757
</page>
<reference confidence="0.99498808988764">
ing Systems, NIPS’01, pages 367–373. MIT
Press.
Crowston, K., Kwasnik, B., and Rubleske, J.
(2009). Problems in the use-centered de-
velopment of a taxonomy of web genres.
In Mehler, A., Sharoff, S., and Santini,
M., editors, Genres on the Web: Com-
putational Models and Empirical Studies.
Springer, Berlin/New York.
Dekel, O., Keshet, J., and Singer, Y. (2004).
Large margin hierarchical classification. In
ICML ’04: Proceedings of the twenty-first in-
ternational conference on Machine learning,
page 27, New York, NY, USA. ACM.
Dietterich, T. G. (1998). Approximate statistical
tests for comparing supervised classification
learning algorithms. Neural Computation,
10:1895–1923.
Giesbrecht, E. and Evert, S. (2009). Part-of-
Speech (POS) Tagging - a solved task? An
evaluation of POS taggers for the Web as
corpus. In Proceedings of the Fifth Web
as Corpus Workshop (WAC5), pages 27–35,
Donostia-San Sebastián.
Jiang, J. J. and Conrath, D. W. (1997). Semantic
similarity based on corpus statistics and lexi-
cal taxonomy. CoRR, cmp-lg/9709008.
Joachims, T. (1999). Making large-scale SVM
learning practical. In Schölkopf, B., Burges,
C., and Smola, A., editors, Advances in
Kernel Methods – Support Vector Learning,
pages 41–56. MIT Press.
Joachims, T., Finley, T., and Yu, C.-N. (2009).
Cutting-plane training of structural svms.
Machine Learning, 77(1):27–59.
Kanaris, I. and Stamatatos, E. (2009). Learning to
recognize webpage genres. Information Pro-
cessing and Management, 45:499–512.
Karlgren, J. and Cutting, D. (1994). Recogniz-
ing text genres with simple metrics using dis-
criminant analysis. In Proc. of the 15th. Inter-
national Conference on Computational Lin-
guistics (COLING 94), pages 1071 – 1075,
Kyoto, Japan.
Keerthi, S. S., Sundararajan, S., Chang, K.-W.,
Hsieh, C.-J., and Lin, C.-J. (2008). A se-
quential dual method for large scale multi-
class linear svms. In KDD ’08: Proceeding of
the 14th ACM SIGKDD international confer-
ence on Knowledge discovery and data min-
ing, pages 408–416, New York, NY, USA.
ACM.
Kessler, B., Nunberg, G., and Schütze, H. (1997).
Automatic detection of text genre. In Pro-
ceedings of the 35th ACL/8th EACL, pages
32–38.
Kuˇcera, H. and Francis, W. N. (1967). Computa-
tional analysis of present-day American En-
glish. Brown University Press, Providence.
Leacock, C. and Chodorow, M. (1998). Combin-
ing local context and WordNet similarity for
word sense identification, pages 305–332. In
C. Fellbaum (Ed.), MIT Press.
Lee, D. (2001). Genres, registers, text types, do-
mains, and styles: clarifying the concepts
and navigating a path through the BNC jun-
gle. Language Learning and Technology,
5(3):37–72.
Lin, D. (1998). An information-theoretic defini-
tion of similarity. In ICML ’98: Proceed-
ings of the Fifteenth International Confer-
ence on Machine Learning, pages 296–304,
San Francisco, CA, USA. Morgan Kaufmann
Publishers Inc.
Meyer zu Eissen, S. and Stein, B. (2004). Genre
classification of web pages. In Proceedings
of the 27th German Conference on Artificial
Intelligence, Ulm, Germany.
Pedersen, T., Pakhomov, S. V. S., Patwardhan, S.,
and Chute, C. G. (2007). Measures of seman-
tic similarity and relatedness in the biomed-
ical domain. J. of Biomedical Informatics,
40(3):288–299.
Resnik, P. (1995). Using information content to
evaluate semantic similarity in a taxonomy.
In IJCAI’95: Proceedings of the 14th inter-
national joint conference on Artificial intel-
ligence, pages 448–453, San Francisco, CA,
USA. Morgan Kaufmann Publishers Inc.
</reference>
<page confidence="0.97794">
758
</page>
<reference confidence="0.94576625">
Santini, M. (2007). Automatic Identification of
Genre in Web Pages. PhD thesis, University
of Brighton.
Shao, K.-T. and Sokal, R. R. (1990). Tree balance.
Systematic Zoology, 39(3):266–276.
Sharoff, S., Wu, Z., and Markert, K. (2010). The
Web library of Babel: evaluating genre col-
lections. In Proc. of the Seventh Language
Resources and Evaluation Conference, LREC
2010, Malta.
Stubbe, A. and Ringlstetter, C. (2007). Recogniz-
ing genres. In Santini, M. and Sharoff, S.,
editors, Proc. Towards a Reference Corpus of
Web Genres.
Tsochantaridis, I., Joachims, T., Hofmann, T., and
Altun, Y. (2005). Large margin methods
for structured and interdependent output vari-
ables. J. Mach. Learn. Res., 6:1453–1484.
Vidulin, V., Luštrek, M., and Gams, M. (2007).
Using genres to improve search engines. In
Proc. Towards Genre-Enabled Search En-
gines: The Impact of NLP. RANLP-07.
Webber, B. (2009). Genre distinctions for dis-
course in the Penn TreeBank. In Proc the
47th Annual Meeting of the ACL, pages 674–
682.
Wu, Z. and Palmer, M. (1994). Verbs seman-
tics and lexical selection. In Proceedings of
the 32nd annual meeting on Association for
Computational Linguistics, pages 133–138,
Morristown, NJ, USA. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.998641">
759
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.791657">
<title confidence="0.999722">Fine-grained Genre Classification using Structural Learning Algorithms</title>
<author confidence="0.999434">Zhili Wu Katja Markert Serge Sharoff</author>
<affiliation confidence="0.9550645">Centre for Translation Studies School of Computing Centre for Translation Studies University of Leeds, UK University of Leeds, UK University of Leeds, UK</affiliation>
<email confidence="0.89206">z.wu@leeds.ac.ukscskm@leeds.ac.uks.sharoff@leeds.ac.uk</email>
<abstract confidence="0.999061476190476">Prior use of machine learning in genre classification used a list of labels as classification categories. However, genre classes are often organised into hierarchies, e.g., covering the subgenres of fiction. In this paper we present a method of using the hierarchy of labels to improve the classification accuracy. As a testbed for this approach we use the Brown Corpus as well as a range of other corpora, including the BNC, HGC and Syracuse. The results are not encouraging: apart from the Brown corpus, the improvements of our structural classifier over the flat one are not statistically significant. We discuss the relation between structural learning performance and the visual and distributional balance of the label hierarchy, suggesting that only balanced hierarchies might profit from structural learning.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>ing Systems</author>
</authors>
<volume>01</volume>
<pages>367--373</pages>
<publisher>MIT Press.</publisher>
<marker>Systems, </marker>
<rawString>ing Systems, NIPS’01, pages 367–373. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crowston</author>
<author>B Kwasnik</author>
<author>J Rubleske</author>
</authors>
<title>Problems in the use-centered development of a taxonomy of web genres.</title>
<date>2009</date>
<booktitle>Genres on the Web: Computational Models and Empirical Studies.</booktitle>
<editor>In Mehler, A., Sharoff, S., and Santini, M., editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin/New York.</location>
<contexts>
<context position="16798" citStr="Crowston et al., 2009" startWordPosition="2810" endWordPosition="2813">as lin. The way for measuring genre frequency is indicated last with df for measuring via document frequency and word/gram when measured via frequency of genre labels. If frequencies of genre labels are used, the corpus for counting the occurrence of genre labels is also indicated via brown, bnc or the Web as estimated by Google hit counts gg. Standard non-structural SVMs are indicated by flat. 4 Experiments 4.1 Datasets We use four genre-annotated corpora for genre classification: the Brown Corpus (Kuˇcera and Francis, 1967), BNC (Lee, 2001), HGC (Stubbe and Ringlstetter, 2007) and Syracuse (Crowston et al., 2009). They have a wide variety of genre labels (from 15 in the Brown corpus to 32 genres in HGC to 70 in the BNC to 292 in Syracuse), and different types of hierarchies. 4.2 Evaluation Measures We use standard classification accuracy (Acc) on the most fine-grained level of target categories in the genre hierarchy. In addition, given a structural distance H, misclassifications can be weighted based on the distance measure. This allows us to penalize incorrect predictions which are further away in the hierarchy (such as between government documents and westerns) more than &amp;quot;close&amp;quot; mismatches (such as</context>
<context position="23194" citStr="Crowston et al., 2009" startWordPosition="3851" endWordPosition="3854">32 approximately equally frequent classes. Its hierarchy has just two levels. Standard accuracy for the best performing structural methods on HGC is just the same as for flat SVM (69.1%), with marginally better structural accuracy (for example, 71.39 vs. 71.04%, using a path-length based structural accuracy). The BNC corpus contains 70 genres and 4053 documents. The number of documents per class ranges from 2 to 501. The accuracy of SSVM is also just comparable to flat SVM (73.6%). The Syracuse corpus is a recently developed large collection of 3027 annotated webpages divided into 292 genres (Crowston et al., 2009). Focusing only on genres containing 15 or more examples, we arrived at a corpus of 2293 samples and 52 genres. Accuracy for flat (53.3%) and structural SVMs (53.7%) are again comparable. 5 Discussion Given that structural learning can help in topical classification tasks (Tsochantaridis et al., 2005; Dekel et al., 2004), the lack of success on genres is surprising. We now discuss potential reasons for this lack of success. 5.1 Tree Depth and Balance Our best results were achieved on the Brown corpus, whose genre tree has at least three attractive properties. Firstly, it has a depth greater th</context>
</contexts>
<marker>Crowston, Kwasnik, Rubleske, 2009</marker>
<rawString>Crowston, K., Kwasnik, B., and Rubleske, J. (2009). Problems in the use-centered development of a taxonomy of web genres. In Mehler, A., Sharoff, S., and Santini, M., editors, Genres on the Web: Computational Models and Empirical Studies. Springer, Berlin/New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Dekel</author>
<author>J Keshet</author>
<author>Y Singer</author>
</authors>
<title>Large margin hierarchical classification.</title>
<date>2004</date>
<booktitle>In ICML ’04: Proceedings of the twenty-first international conference on Machine learning,</booktitle>
<pages>27</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6462" citStr="Dekel et al., 2004" startWordPosition="1039" endWordPosition="1042">ial reasons for this, including the (im)balance of different genre hierarchies and problems with our distance measures. 2 Structural SVMs Discriminative methods are often used for classification, with SVMs being a well-performing method in many tasks (Boser et al., 1992; Joachims, 1999). Linear SVMs on a flat list of labels achieve high efficiency and accuracy in text classification when compared to nonlinear SVMs or other state-of-the-art methods. As for structural output learning, a few SVM-based objective functions have been proposed, including margin formulation for hierarchical learning (Dekel et al., 2004) or general structural learning (Joachims et al., 2009; Tsochantaridis et al., 2005). But many implementations are not publicly available, and their scalability to real-life text classification tasks is unknown. Also they have not been applied to genre classification. Our formulation can be taken as a special instance of the structural learning framework in (Tsochantaridis et al., 2005). However, they concentrate on more complicated label structures as for sequence alignment or parsing. They proposed two formulations, slack-rescaling and marginrescaling, claiming that margin-rescaling has two </context>
<context position="23516" citStr="Dekel et al., 2004" startWordPosition="3903" endWordPosition="3906"> contains 70 genres and 4053 documents. The number of documents per class ranges from 2 to 501. The accuracy of SSVM is also just comparable to flat SVM (73.6%). The Syracuse corpus is a recently developed large collection of 3027 annotated webpages divided into 292 genres (Crowston et al., 2009). Focusing only on genres containing 15 or more examples, we arrived at a corpus of 2293 samples and 52 genres. Accuracy for flat (53.3%) and structural SVMs (53.7%) are again comparable. 5 Discussion Given that structural learning can help in topical classification tasks (Tsochantaridis et al., 2005; Dekel et al., 2004), the lack of success on genres is surprising. We now discuss potential reasons for this lack of success. 5.1 Tree Depth and Balance Our best results were achieved on the Brown corpus, whose genre tree has at least three attractive properties. Firstly, it has a depth greater than 2, i.e. several levels are distinguished. Secondly, it seems visually balanced: branches from root to leaves (or terminals) are of pretty much equal length; branching factors are similar, for example ranging between 2 and 6 for the last level of branching. Thirdly, the number of examples at 754 Table 2: Structural Acc</context>
</contexts>
<marker>Dekel, Keshet, Singer, 2004</marker>
<rawString>Dekel, O., Keshet, J., and Singer, Y. (2004). Large margin hierarchical classification. In ICML ’04: Proceedings of the twenty-first international conference on Machine learning, page 27, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T G Dietterich</author>
</authors>
<title>Approximate statistical tests for comparing supervised classification learning algorithms.</title>
<date>1998</date>
<journal>Neural Computation,</journal>
<pages>10--1895</pages>
<contexts>
<context position="18943" citStr="Dietterich, 1998" startWordPosition="3190" endWordPosition="3191">cross validation throughout. In each fold, for each genre class 10% of documents are used for testing. For the remaining 90%, a portion of 10% are sampled for parameter tuning, leaving 80% for training. In each round the validation set is used to help determine the best C associated with Equation (5) based on the validation accuracy from the candidate list 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1. Note via this experiment setup, all methods are tuned to their best performance. For any algorithm comparison, we use a McNemar test with the significance level of 5% as recommended by (Dietterich, 1998). 4.4 Features The features used for genre classification are character 4-grams for all algorithms, i.e. each document is represented by a binary vector indicating the existence of each character 4-gram. We used character n-grams because they are very easy to extract, language-independent (no need to rely on parsing or even stemming), and they are known to have the best performance in genre classification tasks (Kanaris and Stamatatos, 2009; Sharoff et al., 2010). 4.5 Brown Corpus Results The Brown Corpus has 500 documents and is organized in a hierarchy with a depth of 3. It contains 15 end-l</context>
</contexts>
<marker>Dietterich, 1998</marker>
<rawString>Dietterich, T. G. (1998). Approximate statistical tests for comparing supervised classification learning algorithms. Neural Computation, 10:1895–1923.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Giesbrecht</author>
<author>S Evert</author>
</authors>
<title>Part-ofSpeech (POS) Tagging - a solved task? An evaluation of POS taggers for the Web as corpus.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fifth Web as Corpus Workshop (WAC5),</booktitle>
<pages>27--35</pages>
<institution>Donostia-San Sebastián.</institution>
<contexts>
<context position="1793" citStr="Giesbrecht and Evert, 2009" startWordPosition="276" endWordPosition="279">ic genre identification (AGI) can be traced to the mid-1990s (Karlgren and Cutting, 1994; Kessler et al., 1997), but this research became much more active in recent years, partly because of the explosive growth of the Web, and partly because of the importance of making genre distinctions in NLP applications. In Information Retrieval, given the large number of web pages on any given topic, it is often difficult for the users to find relevant pages that are in the right genre (Vidulin et al., 2007). As for other applications, the accuracy of many tasks, such as machine translation, POS tagging (Giesbrecht and Evert, 2009) or identification of discourse relations (Webber, 2009) relies of defining the language model suitable for the genre of a given text. For example, the accuracy of POS tagging reaching 96.9% on newspaper texts drops down to 85.7% on forums (Giesbrecht and Evert, 2009), i.e., every seventh word in forums is tagged incorrectly. This interest in genres resulted in a proliferation of studies on corpus development of web genres and comparison of methods for AGI. The two corpora commonly used for this task are KI04 (Meyer zu Eissen and Stein, 2004) and Santinis (Santini, 2007). The best results repo</context>
</contexts>
<marker>Giesbrecht, Evert, 2009</marker>
<rawString>Giesbrecht, E. and Evert, S. (2009). Part-ofSpeech (POS) Tagging - a solved task? An evaluation of POS taggers for the Web as corpus. In Proceedings of the Fifth Web as Corpus Workshop (WAC5), pages 27–35, Donostia-San Sebastián.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Jiang</author>
<author>D W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<location>CoRR, cmp-lg/9709008.</location>
<contexts>
<context position="13336" citStr="Jiang and Conrath, 1997" startWordPosition="2226" endWordPosition="2229"> content of their least common subsumer: s(a, b)resk = IC(LCS(a, b)). (11) If two nodes just share the root as their subsumer, their similarity will be zero. To convert 11 into a distance measure, it is possible to add a constant 1 to it before inverting it, as given by h(a, b)resk = 1/(s(a, b)resk + 1). (12) Several other similarity measures have been proposed based on the Resnik similarity such as the one by (Lin, 1998): 2IC(LCS(a, b)) s(a, b)lin = IC(a) + IC(b) .(13) Again to avoid the effect of zero similarity when defining the Lin’s distance we use: h(a, b)lin = 1/(s(a, b)lin + 1). (14) (Jiang and Conrath, 1997) directly define Jiang’s distance (h(a, b)pg): IC(a) + IC(b) − 2IC(LCS(a, b)). (15) 3.2.1 Information Content of Genre Labels The notion of information content of a genre is not straightforward. We use two ways of measuring the frequency freq of a genre, depending on its interpretation. Genre Frequency based on Document Occurrence. We can interpret the “frequency” of a genre node simply as the number of all documents belonging to that genre (including any of its subgenres). Unfortunately, there are no estimates for genre frequencies on, for example, a representative sample of web documents. Th</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jiang, J. J. and Conrath, D. W. (1997). Semantic similarity based on corpus statistics and lexical taxonomy. CoRR, cmp-lg/9709008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods – Support Vector Learning,</booktitle>
<pages>41--56</pages>
<editor>In Schölkopf, B., Burges, C., and Smola, A., editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6130" citStr="Joachims, 1999" startWordPosition="991" endWordPosition="992">stances. We present experiments with these novel structural SVMs and distance measures on three different corpora in Section 4. Our experiments show that structural SVMs can outperform the non-structural standard. However, the improvement is only statistically significant on the Brown corpus. In Section 5 we investigate potential reasons for this, including the (im)balance of different genre hierarchies and problems with our distance measures. 2 Structural SVMs Discriminative methods are often used for classification, with SVMs being a well-performing method in many tasks (Boser et al., 1992; Joachims, 1999). Linear SVMs on a flat list of labels achieve high efficiency and accuracy in text classification when compared to nonlinear SVMs or other state-of-the-art methods. As for structural output learning, a few SVM-based objective functions have been proposed, including margin formulation for hierarchical learning (Dekel et al., 2004) or general structural learning (Joachims et al., 2009; Tsochantaridis et al., 2005). But many implementations are not publicly available, and their scalability to real-life text classification tasks is unknown. Also they have not been applied to genre classification.</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Joachims, T. (1999). Making large-scale SVM learning practical. In Schölkopf, B., Burges, C., and Smola, A., editors, Advances in Kernel Methods – Support Vector Learning, pages 41–56. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
<author>T Finley</author>
<author>C-N Yu</author>
</authors>
<title>Cutting-plane training of structural svms.</title>
<date>2009</date>
<booktitle>Machine Learning,</booktitle>
<volume>77</volume>
<issue>1</issue>
<contexts>
<context position="6516" citStr="Joachims et al., 2009" startWordPosition="1047" endWordPosition="1050">ifferent genre hierarchies and problems with our distance measures. 2 Structural SVMs Discriminative methods are often used for classification, with SVMs being a well-performing method in many tasks (Boser et al., 1992; Joachims, 1999). Linear SVMs on a flat list of labels achieve high efficiency and accuracy in text classification when compared to nonlinear SVMs or other state-of-the-art methods. As for structural output learning, a few SVM-based objective functions have been proposed, including margin formulation for hierarchical learning (Dekel et al., 2004) or general structural learning (Joachims et al., 2009; Tsochantaridis et al., 2005). But many implementations are not publicly available, and their scalability to real-life text classification tasks is unknown. Also they have not been applied to genre classification. Our formulation can be taken as a special instance of the structural learning framework in (Tsochantaridis et al., 2005). However, they concentrate on more complicated label structures as for sequence alignment or parsing. They proposed two formulations, slack-rescaling and marginrescaling, claiming that margin-rescaling has two disadvantages. First, it potentially gives significant</context>
</contexts>
<marker>Joachims, Finley, Yu, 2009</marker>
<rawString>Joachims, T., Finley, T., and Yu, C.-N. (2009). Cutting-plane training of structural svms. Machine Learning, 77(1):27–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Kanaris</author>
<author>E Stamatatos</author>
</authors>
<title>Learning to recognize webpage genres.</title>
<date>2009</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>45--499</pages>
<contexts>
<context position="2530" citStr="Kanaris and Stamatatos, 2009" startWordPosition="397" endWordPosition="400">the genre of a given text. For example, the accuracy of POS tagging reaching 96.9% on newspaper texts drops down to 85.7% on forums (Giesbrecht and Evert, 2009), i.e., every seventh word in forums is tagged incorrectly. This interest in genres resulted in a proliferation of studies on corpus development of web genres and comparison of methods for AGI. The two corpora commonly used for this task are KI04 (Meyer zu Eissen and Stein, 2004) and Santinis (Santini, 2007). The best results reported for these corpora (with 10-fold cross-validation) reach 84.1% on KI-04 and 96.5% accuracy on Santinis (Kanaris and Stamatatos, 2009). In our research (Sharoff et al., 2010) we produced even better results on these two benchmarks (85.8% and 97.1%, respectively). However, this impressive accuracy is not realistic in vivo, i.e., in classifying web pages retrieved as a result of actual queries. One reason comes from the limited number of genres present in these two collections (eight genres in KI-04 and seven in Santinis). As an example, only front pages of online newspapers are listed in Santinis, but not actual newspaper articles, so once an article is retrieved, it cannot be assigned to any class at all. Another reason why </context>
<context position="19387" citStr="Kanaris and Stamatatos, 2009" startWordPosition="3259" endWordPosition="3262">iment setup, all methods are tuned to their best performance. For any algorithm comparison, we use a McNemar test with the significance level of 5% as recommended by (Dietterich, 1998). 4.4 Features The features used for genre classification are character 4-grams for all algorithms, i.e. each document is represented by a binary vector indicating the existence of each character 4-gram. We used character n-grams because they are very easy to extract, language-independent (no need to rely on parsing or even stemming), and they are known to have the best performance in genre classification tasks (Kanaris and Stamatatos, 2009; Sharoff et al., 2010). 4.5 Brown Corpus Results The Brown Corpus has 500 documents and is organized in a hierarchy with a depth of 3. It contains 15 end-level genres. In one experiment in (Karlgren and Cutting, 1994) the subgenres under fiction are grouped together, leading to 10 genres to classify. Results on 10-genre Brown Corpus. A standard flat SVM achieves an accuracy of 64.4% whereas the best structural SVM based on Lin’s information content distance measure (IC-linword-bnc) achieves 68.8% accuracy, significantly better at the 1% level. The result is also significantly better than prio</context>
</contexts>
<marker>Kanaris, Stamatatos, 2009</marker>
<rawString>Kanaris, I. and Stamatatos, E. (2009). Learning to recognize webpage genres. Information Processing and Management, 45:499–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Karlgren</author>
<author>D Cutting</author>
</authors>
<title>Recognizing text genres with simple metrics using discriminant analysis.</title>
<date>1994</date>
<booktitle>In Proc. of the 15th. International Conference on Computational Linguistics (COLING 94),</booktitle>
<pages>1071--1075</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="1254" citStr="Karlgren and Cutting, 1994" startWordPosition="183" endWordPosition="186">tion accuracy. As a testbed for this approach we use the Brown Corpus as well as a range of other corpora, including the BNC, HGC and Syracuse. The results are not encouraging: apart from the Brown corpus, the improvements of our structural classifier over the flat one are not statistically significant. We discuss the relation between structural learning performance and the visual and distributional balance of the label hierarchy, suggesting that only balanced hierarchies might profit from structural learning. 1 Introduction Automatic genre identification (AGI) can be traced to the mid-1990s (Karlgren and Cutting, 1994; Kessler et al., 1997), but this research became much more active in recent years, partly because of the explosive growth of the Web, and partly because of the importance of making genre distinctions in NLP applications. In Information Retrieval, given the large number of web pages on any given topic, it is often difficult for the users to find relevant pages that are in the right genre (Vidulin et al., 2007). As for other applications, the accuracy of many tasks, such as machine translation, POS tagging (Giesbrecht and Evert, 2009) or identification of discourse relations (Webber, 2009) reli</context>
<context position="3904" citStr="Karlgren and Cutting (1994)" startWordPosition="640" endWordPosition="644">th FAQs on hurricanes or another one with tax advice. In the end, a classifier built for FAQs on this training data relies on a high topic-genre correlation in this particular collection and fails to spot any other FAQs. There are other corpora, which are more diverse in the range of their genres, such as the fifteen genres of the Brown Corpus (Kuˇcera and Francis, 1967) or the seventy genres of the BNC (Lee, 2001), but because of the number of genres in them and the diversity of documents within each genre, the accuracy of prior work on these collections is much less impressive. For example, Karlgren and Cutting (1994) using linear discriminant analysis achieve an accuracy of 52% without us749 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 749–759, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics ing cross-validation (the entire Brown Corpus was used as both the test set and training set), with the accuracy improving to 65% when the 15 genres are collapsed into 10, and to 73% with only 4 genres (Figure 1). This result suggests the importance of the hierarchy of genres. Firstly, making a decision on higher levels might be easie</context>
<context position="19605" citStr="Karlgren and Cutting, 1994" startWordPosition="3298" endWordPosition="3301">r genre classification are character 4-grams for all algorithms, i.e. each document is represented by a binary vector indicating the existence of each character 4-gram. We used character n-grams because they are very easy to extract, language-independent (no need to rely on parsing or even stemming), and they are known to have the best performance in genre classification tasks (Kanaris and Stamatatos, 2009; Sharoff et al., 2010). 4.5 Brown Corpus Results The Brown Corpus has 500 documents and is organized in a hierarchy with a depth of 3. It contains 15 end-level genres. In one experiment in (Karlgren and Cutting, 1994) the subgenres under fiction are grouped together, leading to 10 genres to classify. Results on 10-genre Brown Corpus. A standard flat SVM achieves an accuracy of 64.4% whereas the best structural SVM based on Lin’s information content distance measure (IC-linword-bnc) achieves 68.8% accuracy, significantly better at the 1% level. The result is also significantly better than prior work on the Brown corpus in (Karlgren and Cutting, 1994) (who use the whole corpus as test as well as training data). Table 1 summarizes the best performing measures that all outperform the flat SVM at the 1% level. </context>
<context position="21696" citStr="Karlgren and Cutting, 1994" startWordPosition="3607" endWordPosition="3610">curacy Figure 2: Accuracy on Brown Corpus (10 genres). Results on 15-genre Brown Corpus. We perform experiments on all 15 genres on the end level of the Brown corpus. The increase of genre classes leads to reduced classification performance. In our experiment, the flat SVM achieves an accuracy of 52.40%, and the structural SVM using path length measure achieves 55.40%, a difference significant at the 5% level. The structural SVMs using information content measures IC-lin-gram-bnc and ICresk-word-br also perform equally well. In addition, we improve on the training accuracy of 52% reported in (Karlgren and Cutting, 1994). We are also interested in structural accuracy (SAcc) to see whether the structural SVMs make fewer &amp;quot;big&amp;quot; mistakes. Table 2 shows a cross comparison of structural accuracy. Each row shows how accurate the corresponding method is under the structural accuracy criteria given in the column. The ’no-struct’ column corresponds to vanilla accuracy. It is natural to expect each diagonal entry of the numeric table to be the highest, since the respective method is optimised for its own structural distance. However, in our case, Lin’s information content measure and the plen measure perform well under </context>
</contexts>
<marker>Karlgren, Cutting, 1994</marker>
<rawString>Karlgren, J. and Cutting, D. (1994). Recognizing text genres with simple metrics using discriminant analysis. In Proc. of the 15th. International Conference on Computational Linguistics (COLING 94), pages 1071 – 1075, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S S Keerthi</author>
<author>S Sundararajan</author>
<author>K-W Chang</author>
<author>C-J Hsieh</author>
<author>C-J Lin</author>
</authors>
<title>A sequential dual method for large scale multiclass linear svms.</title>
<date>2008</date>
<booktitle>In KDD ’08: Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>408--416</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7562" citStr="Keerthi et al., 2008" startWordPosition="1202" endWordPosition="1205"> or parsing. They proposed two formulations, slack-rescaling and marginrescaling, claiming that margin-rescaling has two disadvantages. First, it potentially gives significant weight to output values that might not be easily confused with the target values, because every increase in the loss increases the required margin. However, they did not provide empirical evidence for this claim. Second, margin rescaling is not necessarily invariant to the scaling of the distance matrix. We still used margin-rescaling because it allows us to use the sequential dual method for large-scale implementation (Keerthi et al., 2008), which is not applicable to the slack-rescaling formulation. For web page classification we will need fast processing. In addition, we performed model calibration to address the second disadvantage (distance matrix invariance). Let x be a document and wm a weight vector associated with the genre class m in a corpus with k genres at the most fine-grained level. The predicted class is the class achieving the maximum inner product between x and the weight vector for the class, denoted as, wmx,Vm. (1) arg max m 750 Accurate prediction requires that when a document vector is multiplied with the we</context>
<context position="9476" citStr="Keerthi et al., 2008" startWordPosition="1538" endWordPosition="1541">m. (3) To allow feasible models, in real scenarios such constraints can be violated, but the degree of violation is expected to be small. For each document, the maximum violation in the k constraints is of interest, as given by the following loss term: Lossi = max m {h(yi, m) − wTy�xi + wT mxi}. (4) Adding up all loss terms over all training documents, and further introducing a term to penalize large values in the weight vectors, we have the following objective function (C is a user-specified nonnegative parameter). Efficient methods can be derived by borrowing the sequential dual methods in (Keerthi et al., 2008) or other optimization techniques (Crammer and Singer, 2002). 3 Genre Distance Measures The structural SVM (Section 2) requires a distance measure h between two genres. We can derive such distance measures from the genre hierarchy in a way similar to word similarity measures that were invented for lexical hierarchies such as WordNet (see (Pedersen et al., 2007) for an overview). In the following, we will first shortly summarise path-based and information-based measures for similarity. However, information-based measures are based on the information content of a node in a hierarchy. Whereas the</context>
</contexts>
<marker>Keerthi, Sundararajan, Chang, Hsieh, Lin, 2008</marker>
<rawString>Keerthi, S. S., Sundararajan, S., Chang, K.-W., Hsieh, C.-J., and Lin, C.-J. (2008). A sequential dual method for large scale multiclass linear svms. In KDD ’08: Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 408–416, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kessler</author>
<author>G Nunberg</author>
<author>H Schütze</author>
</authors>
<title>Automatic detection of text genre.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th ACL/8th EACL,</booktitle>
<pages>32--38</pages>
<contexts>
<context position="1277" citStr="Kessler et al., 1997" startWordPosition="187" endWordPosition="190">for this approach we use the Brown Corpus as well as a range of other corpora, including the BNC, HGC and Syracuse. The results are not encouraging: apart from the Brown corpus, the improvements of our structural classifier over the flat one are not statistically significant. We discuss the relation between structural learning performance and the visual and distributional balance of the label hierarchy, suggesting that only balanced hierarchies might profit from structural learning. 1 Introduction Automatic genre identification (AGI) can be traced to the mid-1990s (Karlgren and Cutting, 1994; Kessler et al., 1997), but this research became much more active in recent years, partly because of the explosive growth of the Web, and partly because of the importance of making genre distinctions in NLP applications. In Information Retrieval, given the large number of web pages on any given topic, it is often difficult for the users to find relevant pages that are in the right genre (Vidulin et al., 2007). As for other applications, the accuracy of many tasks, such as machine translation, POS tagging (Giesbrecht and Evert, 2009) or identification of discourse relations (Webber, 2009) relies of defining the lang</context>
</contexts>
<marker>Kessler, Nunberg, Schütze, 1997</marker>
<rawString>Kessler, B., Nunberg, G., and Schütze, H. (1997). Automatic detection of text genre. In Proceedings of the 35th ACL/8th EACL, pages 32–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kuˇcera</author>
<author>W N Francis</author>
</authors>
<title>Computational analysis of present-day American English.</title>
<date>1967</date>
<publisher>Brown University Press,</publisher>
<location>Providence.</location>
<marker>Kuˇcera, Francis, 1967</marker>
<rawString>Kuˇcera, H. and Francis, W. N. (1967). Computational analysis of present-day American English. Brown University Press, Providence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification,</title>
<date>1998</date>
<pages>305--332</pages>
<editor>In C. Fellbaum (Ed.),</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="11240" citStr="Leacock and Chodorow, 1998" startWordPosition="1840" endWordPosition="1843">, (6) where a and b are two nodes in the tree, LC5(a, b) is their Least Common Subsumer, and f(a, LC5(a, b)) is the number of levels passed through when traversing from a to the ancestral node LC5(a, b). In other words, the distance counts the number of edges traversed from nodes a to b in the tree. For example, the distance between Learned and Misc in Figure 1 would be 3. As an alternative, the maximum path length h(a, b)pmax to their least common subsumer can be used to reduce the range of possible values: max{f(a, LC5(a, b)), f(b, LC5(a, b))}. (7) The Leacock &amp; Chodorow similarity measure (Leacock and Chodorow, 1998) normalizes the path length measure (6) by the maximum number of nodes D when traversing down from the root. s(a, b)plsk = −log((h(a, b)plen + 1)/2D). (8) To convert it into a distance measure, we can invert it h(a, b)plsk = 1/s(a, b)plsk. Other path-length based measures include the Wu &amp; Palmer Similarity (Wu and Palmer, 1994). 2f(R, LC5(a, b)) s(a, b)pwupal = (9) ( f (R, a) + f (R, b)) where R describes the hierarchy’s root node. Here similarity is proportional to the shared path from the root to the least common subsumer of two nodes. Since the Wu &amp; Palmer similarity is always between [0 1)</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Leacock, C. and Chodorow, M. (1998). Combining local context and WordNet similarity for word sense identification, pages 305–332. In C. Fellbaum (Ed.), MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lee</author>
</authors>
<title>Genres, registers, text types, domains, and styles: clarifying the concepts and navigating a path through the BNC jungle.</title>
<date>2001</date>
<journal>Language Learning and Technology,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="3695" citStr="Lee, 2001" startWordPosition="606" endWordPosition="607">gned to any class at all. Another reason why the high accuracy is not useful concerns the limited number of sources in each collection, e.g., all FAQs in Santinis come from either a website with FAQs on hurricanes or another one with tax advice. In the end, a classifier built for FAQs on this training data relies on a high topic-genre correlation in this particular collection and fails to spot any other FAQs. There are other corpora, which are more diverse in the range of their genres, such as the fifteen genres of the Brown Corpus (Kuˇcera and Francis, 1967) or the seventy genres of the BNC (Lee, 2001), but because of the number of genres in them and the diversity of documents within each genre, the accuracy of prior work on these collections is much less impressive. For example, Karlgren and Cutting (1994) using linear discriminant analysis achieve an accuracy of 52% without us749 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 749–759, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics ing cross-validation (the entire Brown Corpus was used as both the test set and training set), with the accuracy improving to 6</context>
<context position="16724" citStr="Lee, 2001" startWordPosition="2801" endWordPosition="2802">on content based the specific measure is mentioned next, such as lin. The way for measuring genre frequency is indicated last with df for measuring via document frequency and word/gram when measured via frequency of genre labels. If frequencies of genre labels are used, the corpus for counting the occurrence of genre labels is also indicated via brown, bnc or the Web as estimated by Google hit counts gg. Standard non-structural SVMs are indicated by flat. 4 Experiments 4.1 Datasets We use four genre-annotated corpora for genre classification: the Brown Corpus (Kuˇcera and Francis, 1967), BNC (Lee, 2001), HGC (Stubbe and Ringlstetter, 2007) and Syracuse (Crowston et al., 2009). They have a wide variety of genre labels (from 15 in the Brown corpus to 32 genres in HGC to 70 in the BNC to 292 in Syracuse), and different types of hierarchies. 4.2 Evaluation Measures We use standard classification accuracy (Acc) on the most fine-grained level of target categories in the genre hierarchy. In addition, given a structural distance H, misclassifications can be weighted based on the distance measure. This allows us to penalize incorrect predictions which are further away in the hierarchy (such as betwee</context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>Lee, D. (2001). Genres, registers, text types, domains, and styles: clarifying the concepts and navigating a path through the BNC jungle. Language Learning and Technology, 5(3):37–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In ICML ’98: Proceedings of the Fifteenth International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="13137" citStr="Lin, 1998" startWordPosition="2192" endWordPosition="2193">s. Since the root may be a dummy concept, its frequency is simply the sum of the frequencies of all its subnodes. The similarity between two nodes can then be defined as the information content of their least common subsumer: s(a, b)resk = IC(LCS(a, b)). (11) If two nodes just share the root as their subsumer, their similarity will be zero. To convert 11 into a distance measure, it is possible to add a constant 1 to it before inverting it, as given by h(a, b)resk = 1/(s(a, b)resk + 1). (12) Several other similarity measures have been proposed based on the Resnik similarity such as the one by (Lin, 1998): 2IC(LCS(a, b)) s(a, b)lin = IC(a) + IC(b) .(13) Again to avoid the effect of zero similarity when defining the Lin’s distance we use: h(a, b)lin = 1/(s(a, b)lin + 1). (14) (Jiang and Conrath, 1997) directly define Jiang’s distance (h(a, b)pg): IC(a) + IC(b) − 2IC(LCS(a, b)). (15) 3.2.1 Information Content of Genre Labels The notion of information content of a genre is not straightforward. We use two ways of measuring the frequency freq of a genre, depending on its interpretation. Genre Frequency based on Document Occurrence. We can interpret the “frequency” of a genre node simply as the numb</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Lin, D. (1998). An information-theoretic definition of similarity. In ICML ’98: Proceedings of the Fifteenth International Conference on Machine Learning, pages 296–304, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Meyer zu Eissen</author>
<author>S</author>
<author>B Stein</author>
</authors>
<title>Genre classification of web pages.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th German Conference on Artificial Intelligence,</booktitle>
<location>Ulm, Germany.</location>
<marker>Eissen, S, Stein, 2004</marker>
<rawString>Meyer zu Eissen, S. and Stein, B. (2004). Genre classification of web pages. In Proceedings of the 27th German Conference on Artificial Intelligence, Ulm, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S V S Pakhomov</author>
<author>S Patwardhan</author>
<author>C G Chute</author>
</authors>
<title>Measures of semantic similarity and relatedness in the biomedical domain.</title>
<date>2007</date>
<journal>J. of Biomedical Informatics,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="9839" citStr="Pedersen et al., 2007" startWordPosition="1597" endWordPosition="1600">ther introducing a term to penalize large values in the weight vectors, we have the following objective function (C is a user-specified nonnegative parameter). Efficient methods can be derived by borrowing the sequential dual methods in (Keerthi et al., 2008) or other optimization techniques (Crammer and Singer, 2002). 3 Genre Distance Measures The structural SVM (Section 2) requires a distance measure h between two genres. We can derive such distance measures from the genre hierarchy in a way similar to word similarity measures that were invented for lexical hierarchies such as WordNet (see (Pedersen et al., 2007) for an overview). In the following, we will first shortly summarise path-based and information-based measures for similarity. However, information-based measures are based on the information content of a node in a hierarchy. Whereas the information content of a word or concept in a lexical hierarchy has been well-defined (Resnik, 1995), it is less clear how to estimate the information content of a genre label. We will therefore discuss several different ways of estimating information content of nodes in a genre hierarchy. 3.1 Distance Measures based on Path Length If genre labels are organise</context>
</contexts>
<marker>Pedersen, Pakhomov, Patwardhan, Chute, 2007</marker>
<rawString>Pedersen, T., Pakhomov, S. V. S., Patwardhan, S., and Chute, C. G. (2007). Measures of semantic similarity and relatedness in the biomedical domain. J. of Biomedical Informatics, 40(3):288–299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In IJCAI’95: Proceedings of the 14th international joint conference on Artificial intelligence,</booktitle>
<pages>448--453</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="10177" citStr="Resnik, 1995" startWordPosition="1651" endWordPosition="1652">The structural SVM (Section 2) requires a distance measure h between two genres. We can derive such distance measures from the genre hierarchy in a way similar to word similarity measures that were invented for lexical hierarchies such as WordNet (see (Pedersen et al., 2007) for an overview). In the following, we will first shortly summarise path-based and information-based measures for similarity. However, information-based measures are based on the information content of a node in a hierarchy. Whereas the information content of a word or concept in a lexical hierarchy has been well-defined (Resnik, 1995), it is less clear how to estimate the information content of a genre label. We will therefore discuss several different ways of estimating information content of nodes in a genre hierarchy. 3.1 Distance Measures based on Path Length If genre labels are organised into a tree (Figure 1), one of the simplest ways to measure distance between two genre labels (= tree nodes) is path length (h(a, b)plen): f(a, LC5(a, b)) + f(b, LC5(a, b)), (6) where a and b are two nodes in the tree, LC5(a, b) is their Least Common Subsumer, and f(a, LC5(a, b)) is the number of levels passed through when traversing </context>
<context position="12405" citStr="Resnik, 1995" startWordPosition="2053" endWordPosition="2054">e Wu &amp; Palmer similarity is always between [0 1), we can convert it into a distance measure by h(a, b)pwupal = 1 − s(a, b T wmwm + C Lossi. (5) min � 1 k m,i 2 m=1 � p i=1 )pwupal. 751 3.2 Distance Measures based on Information Content Path-based distance measures work relatively well on balanced hierarchies such as the one in Figure 1 but fail to treat hierarchies with different levels of granularity well. For lexical hierarchies, as a result, several distance measures based on information content have been suggested where the information content of a concept c in a hierarchy is measured by (Resnik, 1995) The frequency freq of a concept c is the sum of the frequency of the node c itself and the frequencies of all its subnodes. Since the root may be a dummy concept, its frequency is simply the sum of the frequencies of all its subnodes. The similarity between two nodes can then be defined as the information content of their least common subsumer: s(a, b)resk = IC(LCS(a, b)). (11) If two nodes just share the root as their subsumer, their similarity will be zero. To convert 11 into a distance measure, it is possible to add a constant 1 to it before inverting it, as given by h(a, b)resk = 1/(s(a, </context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, P. (1995). Using information content to evaluate semantic similarity in a taxonomy. In IJCAI’95: Proceedings of the 14th international joint conference on Artificial intelligence, pages 448–453, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Santini</author>
</authors>
<title>Automatic Identification of Genre in Web Pages.</title>
<date>2007</date>
<tech>PhD thesis,</tech>
<institution>University of Brighton.</institution>
<contexts>
<context position="2370" citStr="Santini, 2007" startWordPosition="376" endWordPosition="377"> tagging (Giesbrecht and Evert, 2009) or identification of discourse relations (Webber, 2009) relies of defining the language model suitable for the genre of a given text. For example, the accuracy of POS tagging reaching 96.9% on newspaper texts drops down to 85.7% on forums (Giesbrecht and Evert, 2009), i.e., every seventh word in forums is tagged incorrectly. This interest in genres resulted in a proliferation of studies on corpus development of web genres and comparison of methods for AGI. The two corpora commonly used for this task are KI04 (Meyer zu Eissen and Stein, 2004) and Santinis (Santini, 2007). The best results reported for these corpora (with 10-fold cross-validation) reach 84.1% on KI-04 and 96.5% accuracy on Santinis (Kanaris and Stamatatos, 2009). In our research (Sharoff et al., 2010) we produced even better results on these two benchmarks (85.8% and 97.1%, respectively). However, this impressive accuracy is not realistic in vivo, i.e., in classifying web pages retrieved as a result of actual queries. One reason comes from the limited number of genres present in these two collections (eight genres in KI-04 and seven in Santinis). As an example, only front pages of online newsp</context>
</contexts>
<marker>Santini, 2007</marker>
<rawString>Santini, M. (2007). Automatic Identification of Genre in Web Pages. PhD thesis, University of Brighton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-T Shao</author>
<author>R R Sokal</author>
</authors>
<title>Tree balance.</title>
<date>1990</date>
<journal>Systematic Zoology,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="29632" citStr="Shao and Sokal, 1990" startWordPosition="4879" endWordPosition="4882">shallow hierarchy; therefore we think that a third variable depth also needs to be taken into account. A similar observation on the importance of well-balanced hierarchies comes from a recent Pascal challenge on large scale hierarchical text classification,2 which shows that some flat approaches perform competitively in topic classification with imbalanced hierarchies. However, the participants do not explore explicitly the relation between tree balance and performance. Other methods for measuring tree balance (some of which are related to ours) are used in the field of phylogenetic research (Shao and Sokal, 1990) but they are only applicable to visual balance. In addition, the methods they used often provide conflicting results on which trees are considered as balanced (Shao and Sokal, 1990). 5.2 Distance Measures We also scrutinise our distance measures as these are crucial for the structural approach. We notice that simple path length based measures per2http://lshtc.iit.demokritos.gr/ Table 3: Tree Balance Scores Corpus depth vb db Brown (10 genres) 3 0.9115 0.9024 Brown (15 genres) 3 0.9186 0.9083 Brown (15, flattened) 2 0.9855 0.8742 Brown (12, skewed) 3 0.8747 0.8947 HGC (32) 2 0.9562 0.9570 BNC </context>
</contexts>
<marker>Shao, Sokal, 1990</marker>
<rawString>Shao, K.-T. and Sokal, R. R. (1990). Tree balance. Systematic Zoology, 39(3):266–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sharoff</author>
<author>Z Wu</author>
<author>K Markert</author>
</authors>
<title>The Web library of Babel: evaluating genre collections.</title>
<date>2010</date>
<booktitle>In Proc. of the Seventh Language Resources and Evaluation Conference, LREC</booktitle>
<contexts>
<context position="2570" citStr="Sharoff et al., 2010" startWordPosition="404" endWordPosition="407">racy of POS tagging reaching 96.9% on newspaper texts drops down to 85.7% on forums (Giesbrecht and Evert, 2009), i.e., every seventh word in forums is tagged incorrectly. This interest in genres resulted in a proliferation of studies on corpus development of web genres and comparison of methods for AGI. The two corpora commonly used for this task are KI04 (Meyer zu Eissen and Stein, 2004) and Santinis (Santini, 2007). The best results reported for these corpora (with 10-fold cross-validation) reach 84.1% on KI-04 and 96.5% accuracy on Santinis (Kanaris and Stamatatos, 2009). In our research (Sharoff et al., 2010) we produced even better results on these two benchmarks (85.8% and 97.1%, respectively). However, this impressive accuracy is not realistic in vivo, i.e., in classifying web pages retrieved as a result of actual queries. One reason comes from the limited number of genres present in these two collections (eight genres in KI-04 and seven in Santinis). As an example, only front pages of online newspapers are listed in Santinis, but not actual newspaper articles, so once an article is retrieved, it cannot be assigned to any class at all. Another reason why the high accuracy is not useful concerns</context>
<context position="19410" citStr="Sharoff et al., 2010" startWordPosition="3263" endWordPosition="3266">uned to their best performance. For any algorithm comparison, we use a McNemar test with the significance level of 5% as recommended by (Dietterich, 1998). 4.4 Features The features used for genre classification are character 4-grams for all algorithms, i.e. each document is represented by a binary vector indicating the existence of each character 4-gram. We used character n-grams because they are very easy to extract, language-independent (no need to rely on parsing or even stemming), and they are known to have the best performance in genre classification tasks (Kanaris and Stamatatos, 2009; Sharoff et al., 2010). 4.5 Brown Corpus Results The Brown Corpus has 500 documents and is organized in a hierarchy with a depth of 3. It contains 15 end-level genres. In one experiment in (Karlgren and Cutting, 1994) the subgenres under fiction are grouped together, leading to 10 genres to classify. Results on 10-genre Brown Corpus. A standard flat SVM achieves an accuracy of 64.4% whereas the best structural SVM based on Lin’s information content distance measure (IC-linword-bnc) achieves 68.8% accuracy, significantly better at the 1% level. The result is also significantly better than prior work on the Brown cor</context>
<context position="33643" citStr="Sharoff et al., 2010" startWordPosition="5541" endWordPosition="5544">ix into our structural SVM. However, accuracy on the Brown corpus (15 genres) was almost the same as for a flat SVM. Inspecting the distance matrix visually, we determined that the cosine similarity could clearly distinguish between Fiction and Non-Fiction texts but not between any other genres. This also indicates that the genre structural hierarchy clearly gives information not present in the simple character 4-gram features we use. For a more detailed discussion of the problems of the currently prevalently used character n-grams as features for genre classification, we refer the reader to (Sharoff et al., 2010). 6 Conclusions In this paper, we have evaluated structural learning approaches to genre classification using several different genre distance measures. Although we were able to improve on non-structural approaches for the Brown corpus, we found it hard to improve over flat SVMs on other corpora. As potential reasons for this negative result, we suggest that current genre hierarchies are either not of sufficient depth or are visually or distributionally imbalanced. We think further investigation into the relationship between hierarchy balance and structural learning is warranted. Further inves</context>
</contexts>
<marker>Sharoff, Wu, Markert, 2010</marker>
<rawString>Sharoff, S., Wu, Z., and Markert, K. (2010). The Web library of Babel: evaluating genre collections. In Proc. of the Seventh Language Resources and Evaluation Conference, LREC 2010, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stubbe</author>
<author>C Ringlstetter</author>
</authors>
<title>Recognizing genres.</title>
<date>2007</date>
<booktitle>Proc. Towards a Reference Corpus of Web Genres.</booktitle>
<editor>In Santini, M. and Sharoff, S., editors,</editor>
<contexts>
<context position="16761" citStr="Stubbe and Ringlstetter, 2007" startWordPosition="2804" endWordPosition="2807">the specific measure is mentioned next, such as lin. The way for measuring genre frequency is indicated last with df for measuring via document frequency and word/gram when measured via frequency of genre labels. If frequencies of genre labels are used, the corpus for counting the occurrence of genre labels is also indicated via brown, bnc or the Web as estimated by Google hit counts gg. Standard non-structural SVMs are indicated by flat. 4 Experiments 4.1 Datasets We use four genre-annotated corpora for genre classification: the Brown Corpus (Kuˇcera and Francis, 1967), BNC (Lee, 2001), HGC (Stubbe and Ringlstetter, 2007) and Syracuse (Crowston et al., 2009). They have a wide variety of genre labels (from 15 in the Brown corpus to 32 genres in HGC to 70 in the BNC to 292 in Syracuse), and different types of hierarchies. 4.2 Evaluation Measures We use standard classification accuracy (Acc) on the most fine-grained level of target categories in the genre hierarchy. In addition, given a structural distance H, misclassifications can be weighted based on the distance measure. This allows us to penalize incorrect predictions which are further away in the hierarchy (such as between government documents and westerns) </context>
</contexts>
<marker>Stubbe, Ringlstetter, 2007</marker>
<rawString>Stubbe, A. and Ringlstetter, C. (2007). Recognizing genres. In Santini, M. and Sharoff, S., editors, Proc. Towards a Reference Corpus of Web Genres.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Tsochantaridis</author>
<author>T Joachims</author>
<author>T Hofmann</author>
<author>Y Altun</author>
</authors>
<title>Large margin methods for structured and interdependent output variables.</title>
<date>2005</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>6--1453</pages>
<contexts>
<context position="6546" citStr="Tsochantaridis et al., 2005" startWordPosition="1051" endWordPosition="1054">ies and problems with our distance measures. 2 Structural SVMs Discriminative methods are often used for classification, with SVMs being a well-performing method in many tasks (Boser et al., 1992; Joachims, 1999). Linear SVMs on a flat list of labels achieve high efficiency and accuracy in text classification when compared to nonlinear SVMs or other state-of-the-art methods. As for structural output learning, a few SVM-based objective functions have been proposed, including margin formulation for hierarchical learning (Dekel et al., 2004) or general structural learning (Joachims et al., 2009; Tsochantaridis et al., 2005). But many implementations are not publicly available, and their scalability to real-life text classification tasks is unknown. Also they have not been applied to genre classification. Our formulation can be taken as a special instance of the structural learning framework in (Tsochantaridis et al., 2005). However, they concentrate on more complicated label structures as for sequence alignment or parsing. They proposed two formulations, slack-rescaling and marginrescaling, claiming that margin-rescaling has two disadvantages. First, it potentially gives significant weight to output values that </context>
<context position="23495" citStr="Tsochantaridis et al., 2005" startWordPosition="3899" endWordPosition="3902">ral accuracy). The BNC corpus contains 70 genres and 4053 documents. The number of documents per class ranges from 2 to 501. The accuracy of SSVM is also just comparable to flat SVM (73.6%). The Syracuse corpus is a recently developed large collection of 3027 annotated webpages divided into 292 genres (Crowston et al., 2009). Focusing only on genres containing 15 or more examples, we arrived at a corpus of 2293 samples and 52 genres. Accuracy for flat (53.3%) and structural SVMs (53.7%) are again comparable. 5 Discussion Given that structural learning can help in topical classification tasks (Tsochantaridis et al., 2005; Dekel et al., 2004), the lack of success on genres is surprising. We now discuss potential reasons for this lack of success. 5.1 Tree Depth and Balance Our best results were achieved on the Brown corpus, whose genre tree has at least three attractive properties. Firstly, it has a depth greater than 2, i.e. several levels are distinguished. Secondly, it seems visually balanced: branches from root to leaves (or terminals) are of pretty much equal length; branching factors are similar, for example ranging between 2 and 6 for the last level of branching. Thirdly, the number of examples at 754 Ta</context>
</contexts>
<marker>Tsochantaridis, Joachims, Hofmann, Altun, 2005</marker>
<rawString>Tsochantaridis, I., Joachims, T., Hofmann, T., and Altun, Y. (2005). Large margin methods for structured and interdependent output variables. J. Mach. Learn. Res., 6:1453–1484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vidulin</author>
<author>M Luštrek</author>
<author>M Gams</author>
</authors>
<title>Using genres to improve search engines.</title>
<date>2007</date>
<booktitle>In Proc. Towards Genre-Enabled Search Engines: The Impact of NLP. RANLP-07.</booktitle>
<contexts>
<context position="1667" citStr="Vidulin et al., 2007" startWordPosition="256" endWordPosition="259">label hierarchy, suggesting that only balanced hierarchies might profit from structural learning. 1 Introduction Automatic genre identification (AGI) can be traced to the mid-1990s (Karlgren and Cutting, 1994; Kessler et al., 1997), but this research became much more active in recent years, partly because of the explosive growth of the Web, and partly because of the importance of making genre distinctions in NLP applications. In Information Retrieval, given the large number of web pages on any given topic, it is often difficult for the users to find relevant pages that are in the right genre (Vidulin et al., 2007). As for other applications, the accuracy of many tasks, such as machine translation, POS tagging (Giesbrecht and Evert, 2009) or identification of discourse relations (Webber, 2009) relies of defining the language model suitable for the genre of a given text. For example, the accuracy of POS tagging reaching 96.9% on newspaper texts drops down to 85.7% on forums (Giesbrecht and Evert, 2009), i.e., every seventh word in forums is tagged incorrectly. This interest in genres resulted in a proliferation of studies on corpus development of web genres and comparison of methods for AGI. The two corp</context>
</contexts>
<marker>Vidulin, Luštrek, Gams, 2007</marker>
<rawString>Vidulin, V., Luštrek, M., and Gams, M. (2007). Using genres to improve search engines. In Proc. Towards Genre-Enabled Search Engines: The Impact of NLP. RANLP-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
</authors>
<title>Genre distinctions for discourse in the Penn TreeBank. In</title>
<date>2009</date>
<booktitle>Proc the 47th Annual Meeting of the ACL,</booktitle>
<pages>674--682</pages>
<contexts>
<context position="1849" citStr="Webber, 2009" startWordPosition="285" endWordPosition="286"> and Cutting, 1994; Kessler et al., 1997), but this research became much more active in recent years, partly because of the explosive growth of the Web, and partly because of the importance of making genre distinctions in NLP applications. In Information Retrieval, given the large number of web pages on any given topic, it is often difficult for the users to find relevant pages that are in the right genre (Vidulin et al., 2007). As for other applications, the accuracy of many tasks, such as machine translation, POS tagging (Giesbrecht and Evert, 2009) or identification of discourse relations (Webber, 2009) relies of defining the language model suitable for the genre of a given text. For example, the accuracy of POS tagging reaching 96.9% on newspaper texts drops down to 85.7% on forums (Giesbrecht and Evert, 2009), i.e., every seventh word in forums is tagged incorrectly. This interest in genres resulted in a proliferation of studies on corpus development of web genres and comparison of methods for AGI. The two corpora commonly used for this task are KI04 (Meyer zu Eissen and Stein, 2004) and Santinis (Santini, 2007). The best results reported for these corpora (with 10-fold cross-validation) r</context>
</contexts>
<marker>Webber, 2009</marker>
<rawString>Webber, B. (2009). Genre distinctions for discourse in the Penn TreeBank. In Proc the 47th Annual Meeting of the ACL, pages 674– 682.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="11569" citStr="Wu and Palmer, 1994" startWordPosition="1897" endWordPosition="1900">earned and Misc in Figure 1 would be 3. As an alternative, the maximum path length h(a, b)pmax to their least common subsumer can be used to reduce the range of possible values: max{f(a, LC5(a, b)), f(b, LC5(a, b))}. (7) The Leacock &amp; Chodorow similarity measure (Leacock and Chodorow, 1998) normalizes the path length measure (6) by the maximum number of nodes D when traversing down from the root. s(a, b)plsk = −log((h(a, b)plen + 1)/2D). (8) To convert it into a distance measure, we can invert it h(a, b)plsk = 1/s(a, b)plsk. Other path-length based measures include the Wu &amp; Palmer Similarity (Wu and Palmer, 1994). 2f(R, LC5(a, b)) s(a, b)pwupal = (9) ( f (R, a) + f (R, b)) where R describes the hierarchy’s root node. Here similarity is proportional to the shared path from the root to the least common subsumer of two nodes. Since the Wu &amp; Palmer similarity is always between [0 1), we can convert it into a distance measure by h(a, b)pwupal = 1 − s(a, b T wmwm + C Lossi. (5) min � 1 k m,i 2 m=1 � p i=1 )pwupal. 751 3.2 Distance Measures based on Information Content Path-based distance measures work relatively well on balanced hierarchies such as the one in Figure 1 but fail to treat hierarchies with diff</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Wu, Z. and Palmer, M. (1994). Verbs semantics and lexical selection. In Proceedings of the 32nd annual meeting on Association for Computational Linguistics, pages 133–138, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>