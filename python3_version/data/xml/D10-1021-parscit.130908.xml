<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.99657">
Improving Gender Classification of Blog Authors
</title>
<author confidence="0.998898">
Arjun Mukherjee Bing Liu
</author>
<affiliation confidence="0.9991815">
Department of Computer Science
University of Illinois at Chicago
</affiliation>
<address confidence="0.738149">
851 South Morgan Street
Chicago, IL 60607, USA
</address>
<email confidence="0.995059">
amukherj@cs.uic.edu
</email>
<affiliation confidence="0.998579">
Department of Computer Science
University of Illinois at Chicago
</affiliation>
<address confidence="0.739718">
851 South Morgan Street
Chicago, IL 60607, USA
</address>
<email confidence="0.998609">
liub@cs.uic.edu
</email>
<sectionHeader confidence="0.997386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999620263157895">
The problem of automatically classifying the
gender of a blog author has important appli-
cations in many commercial domains. Exist-
ing systems mainly use features such as
words, word classes, and POS (part-of-
speech) n-grams, for classification learning.
In this paper, we propose two new techniques
to improve the current result. The first tech-
nique introduces a new class of features
which are variable length POS sequence pat-
terns mined from the training data using a se-
quence pattern mining algorithm. The second
technique is a new feature selection method
which is based on an ensemble of several fea-
ture selection criteria and approaches. Empir-
ical evaluation using a real-life blog data set
shows that these two techniques improve the
classification accuracy of the current state-of-
the-art methods significantly.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999983098039216">
Weblogs, commonly known as blogs, refer to on-
line personal diaries which generally contain in-
formal writings. With the rapid growth of blogs,
their value as an important source of information
is increasing. A large amount of research work
has been devoted to blogs in the natural language
processing (NLP) and other communities. There
are also many commercial companies that exploit
information in blogs to provide value-added ser-
vices, e.g., blog search, blog topic tracking, and
sentiment analysis of people’s opinions on prod-
ucts and services. Gender classification of blog
authors is one such study, which also has many
commercial applications. For example, it can help
the user find what topics or products are most
talked about by males and females, and what
products and services are liked or disliked by men
and women. Knowing this information is crucial
for market intelligence because the information
can be exploited in targeted advertising and also
product development.
In the past few years, several authors have stu-
died the problem of gender classification in the
natural language processing and linguistic com-
munities. However, most existing works deal with
formal writings, e.g., essays of people, the Reuters
news corpus and the British National Corpus
(BNC). Blog posts differ from such text in many
ways. For instance, blog posts are typically short
and unstructured, and consist of mostly informal
sentences, which can contain spurious information
and are full of grammar errors, abbreviations,
slang words and phrases, and wrong spellings.
Due to these reasons, gender classification of blog
posts is a harder problem than gender classifica-
tion of traditional formal text.
Recent work has also attempted gender classi-
fication of blog authors using features such as
content words, dictionary based content analysis
results, POS (part-of-speech) tags and feature se-
lection along with a supervised learning algorithm
(Schler et al., 2006; Argamon et al., 2007; Yan
and Yan, 2006). This paper improves these exist-
ing methods by proposing two novel techniques.
The first technique adds a new class of pattern
based features to learning, which are not used in
any existing work. The patterns are frequent se-
quences of POS tags which can capture complex
stylistic characteristics of male and female au-
thors. We note that these patterns are very differ-
ent from the traditional n-grams because the
</bodyText>
<page confidence="0.968131">
207
</page>
<note confidence="0.8185165">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 207–217,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.99922756">
patterns are of variable lengths and need to satisfy
some criteria in order for them to represent signif-
icant regularities. We will discuss them in detail
in Section 3.5.
The second technique is a new feature selec-
tion algorithm which uses an ensemble of feature
selection criteria and methods. It is well known
that each individual feature selection criterion and
method can be biased and tends to favor certain
types of features. A combination of them should
be able to capture the most useful or discrimina-
tive features.
Our experimental results based on a real life
blog data set collected from a large number of
blog hosting sites show that the two new tech-
niques enable classification algorithms to signifi-
cantly improve the accuracy of the current state-
of-the-art techniques (Argamon et al., 2007;
Schler et al., 2006; Yan and Yan, 2006). We also
compare with two publicly available systems,
Gender Genie (BookBlog, 2007) and Gender
Guesser (Krawetz, 2006). Both systems imple-
mented variations of the method given in (Arga-
mon et al., 2003). Here, the improvement of our
techniques is even greater.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999977157894737">
There have been several recent papers on gender
classification of blogs (e.g., Schler et al., 2006,
Argamon et al., 2007; Yan and Yan, 2006; Now-
son et al., 2005). These systems use func-
tion/content words, POS tag features, word classes
(Schler et al., 2006), content word classes (Arga-
mon et al., 2007), results of dictionary based con-
tent analysis, POS unigram (Yan and Yan, 2006),
and personality types (Nowson et al., 2005) to
capture stylistic behavior of authors’ writings for
classifying gender. (Koppel et al. 2002) also used
POS n-grams together with content words on the
British National Corpus (BNC). (Houvardas and
Stamatatos, 2006) even applied character (rather
than word or tag) n-grams to capture stylistic fea-
tures for authorship classification of news articles
in Reuters.
However, these works use only one or a subset
of the classes of features. None of them uses all
features for classification learning. Given the
complexity of blog posts, it makes sense to apply
all classes of features jointly in order to classify
genders. Moreover, having many feature classes is
very useful as they provide features with varied
granularities and diversities. However, this also
results in a huge number of features and many of
them are redundant and may obscure classifica-
tion. Feature selection is thus needed. Following
the idea, this paper proposes a new ensemble fea-
ture selection method which is capable of extract-
ing good features from different feature classes
using multiple criteria.
We also note some less relevant literature. For
example, (Tannen, 1990) deals with gender differ-
ences in “conversational style” and in “formal
written essays”, and (Gefen and Straub, 1997)
reports differences in perception of males and fe-
males in the use of emails.
Our new POS pattern features are related to
POS n-grams used in (Koppel et al., 2002; Arga-
mon et al., 2007), which considered POS 3-grams,
2-grams and unigrams as features. As shown in
(Baayen et. al. 1996), POS n-grams are very ef-
fective in capturing the fine-grained stylistic and
heavier syntactic information. In this work, we go
further by finding POS sequence patterns. As dis-
cussed in the introduction, our patterns are entire-
ly different from POS n-grams. First of all, they
are of variable lengths depending on whatever
lengths can catch the regularities. They also need
to satisfy some constraints to ensure that they tru-
ly represent some significant regularity of male or
female writings. Furthermore, our POS sequence
patterns can take care of n-grams and capture ad-
ditional sequence regularities. These automatical-
ly mined pattern features are thus more
discriminating for classification.
</bodyText>
<sectionHeader confidence="0.892385" genericHeader="method">
3 Feature Engineering and Mining
</sectionHeader>
<bodyText confidence="0.999952">
There are different classes of features that have
been experimented for gender classification, e.g.,
F-measure, stylistic features, gender preferential
features, factor analysis and word classes (Now-
son et al., 2005; Schler et al., 2006; Corney et al.,
2002; Argamon et al., 2007). We use all these ex-
isting features and also propose a new class of
features that are POS sequence patterns, which
replace existing POS n-grams. Also, as mentioned
before, using all feature classes gives us features
with varied granularities. Upon extracting all
these classes of features, a new ensemble feature
selection (EFS) algorithm is proposed to select a
subset of good or discriminative features.
</bodyText>
<page confidence="0.996973">
208
</page>
<bodyText confidence="0.999980375">
since we mine all POS sequence patterns and use
them as features, most discriminative POS n-
grams are already covered. In Section 5, we will
also show that POS n-grams do not perform as
well as our POS sequence patterns.
Below, we first introduce the existing features,
and then present the proposed class of new pattern
based features and how to discover them.
</bodyText>
<subsectionHeader confidence="0.992396">
3.1 F-measure
</subsectionHeader>
<bodyText confidence="0.999935">
The F-measure feature was originally proposed in
(Heylighen and Dewaele, 2002) and has been used
in (Nowson et al., 2005) with good results. Note
that F-measure here is not the F-score or F-
measure used in text classification or information
retrieval for measuring the classification or re-
trieval effectiveness (or accuracy).
F-measure explores the notion of implicitness
of text and is a unitary measure of text’s relative
contextuality (implicitness), as opposed to its
formality (explicitness). Contextuality and formal-
ity can be captured by certain parts of speech. A
lower score of F-measure indicates contextuality,
marked by greater relative use of pronouns, verbs,
adverbs, and interjections; a higher score of F-
measure indicates formality, represented by great-
er use of nouns, adjectives, prepositions, and ar-
ticles. F-measure is defined based on the
frequency of the POS usage in a text (freq.x below
means the frequency of the part-of-speech x):
</bodyText>
<equation confidence="0.999413666666667">
F = 0.5 * [(freq.noun + freq.adj + freq.prep +
freq.art) – (freq.pron + freq.verb +
freq.adv + freq.int) + 100]
</equation>
<bodyText confidence="0.998033111111111">
(Heylighen and Dewaele, 2002) applied the F-
measure to a corpus with known author genders
and found a distinct difference between the sexes.
Females scored lower preferring a more contex-
tual style while males scored higher preferring a
more formal style. F-measure values for male and
female writings reported in (Nowson et al., 2005)
also demonstrated a similar trend. In our work, we
also use F-measure as one of the features.
</bodyText>
<subsectionHeader confidence="0.999681">
3.2 Stylistic Features
</subsectionHeader>
<bodyText confidence="0.999815333333333">
These are features which capture people’s writing
styles. The style of writing is typically captured
by three types of features: part of speech, words,
and in the blog context, words such as lol, hmm,
and smiley that appear with high frequency. In this
work, we use words and blog words as stylistic
features. Part of speech features are mined using
our POS sequence pattern mining algorithm. POS
n-grams can also be used as features. However,
</bodyText>
<subsectionHeader confidence="0.996222">
3.3 Gender Preferential Features
</subsectionHeader>
<bodyText confidence="0.999865681818182">
Gender preferential features consist of a set of
signals that has been used in an email gender clas-
sification task (Corney et al., 2002). These fea-
tures come from various studies that have been
undertaken on the issue of gender and language
use (Schiffman, 2002). It was suggested by these
studies and also various other works that women’s
language makes more frequent use of emotionally
intensive adverbs and adjectives like “so”, “terri-
bly”, “awfully”, “dreadfully” and women’s lan-
guage is more punctuated. On the other hand,
men’s conversational patterns express “indepen-
dence” (Corney et al., 2002). In brief, the lan-
guage expressed by males is more proactive at
solving problems while the language used by fe-
males is more reactive to the contribution of oth-
ers - agreeing, understanding and supporting. We
used the gender preferential features listed in Ta-
ble 1, which indicate adjectives and adverbs based
on the presence of suffixes and apologies as used
in (Corney et al., 2002). The feature value as-
signment will be discussed in Section 5.
</bodyText>
<tableCaption confidence="0.812916727272727">
f1 words ending with able
f2 words ending with al
f3 words ending with ful
f4 words ending with ible
f5 words ending with ic
f6 words ending with ive
f7 words ending with less
f8 words ending with ly
f9 words ending with ous
f10 sorry words
Table 1: Gender preferential features
</tableCaption>
<subsectionHeader confidence="0.999116">
3.4 Factor Analysis and Word Classes
</subsectionHeader>
<bodyText confidence="0.99980875">
Factor or word factor analysis refers to the process
of finding groups of similar words that tend to
occur in similar documents. This process is re-
ferred to as meaning extraction in (Chung and
Pennebaker, 2007). Word lists for twenty factors,
along with suggested labels/headings (for refer-
ence) were used as features in (Argamon et al.,
2007). Here we list some of those features (word
</bodyText>
<page confidence="0.99784">
209
</page>
<bodyText confidence="0.977368074074074">
classes) in Table 2. For the detailed list of such
word classes, the reader is referred to (Argamon et
al., 2007). We also used these word classes as fea-
tures in our work. In addition, we added three
more new word classes implying positive, nega-
tive and emotional connotations and used them as
features in our experiments. These are listed in
Table 3.
Factor Words
Conversa-new, know, people, think, person, tell, feel, friends, talk,
tion talking, mean, ask, understand, feelings, care,
thinking, friend, relationship, realize, question, an-
swer, saying
Home woke, home, sleep, today, eat, tired, wake, watch,
watched, dinner, ate, bed, day, house, tv, early, bor-
ing, yesterday, watching, sit
Family years, family, mother, children, father, kids, parents,
old, year, child, son, married, sister, dad, brother,
moved, age, young, months, three, wife, living, col-
lege, four, high, five, died, six, baby, boy, spend,
Christmas
Food / food, eating, weight, lunch, water, hair, life, white,
Clothes wearing, color, ice, red, fat, body, black, clothes,
hot, drink, wear, blue, minutes, shirt, green, coffee,
total, store, shopping
Romance forget, forever, remember, gone, true, face, spent,
times, love, cry, hurt, wish, loved
</bodyText>
<tableCaption confidence="0.980872">
Table 2: Words in factors
</tableCaption>
<bodyText confidence="0.999679137931035">
Positive absolutely, abundance, ace, active, admirable, adore,
agree, amazing, appealing, attraction, bargain, beam-
ing, beautiful, best, better, boost, breakthrough, breeze,
brilliant, brimming, charming, clean, clear, colorful,
compliment, confidence, cool, courteous, cuddly, daz-
zling, delicious, delightful, dynamic, easy, ecstatic,
efficient, enhance, enjoy, enormous, excellent, exotic,
expert, exquisite, flair, free, generous, genius, great,
graceful, heavenly, ideal, immaculate, impressive, in-
credible, inspire, luxurious, outstanding, royal, speed,
splendid, spectacular, superb, sweet, sure, supreme,
terrific, treat, treasure, ultra, unbeatable, ultimate,
unique, wow, zest
Negative wrong, stupid, bad, evil, dumb, foolish, grotesque,
harm, fear, horrible, idiot, lame, mean, poor, heinous,
hideous, deficient, petty, awful, hopeless, fool, risk,
immoral, risky, spoil, spoiled, malign, vicious, wicked,
fright, ugly, atrocious, moron, hate, spiteful, meager,
malicious, lacking
Emotion aggressive, alienated, angry, annoyed, anxious, careful,
cautious, confused, curious, depressed, determined,
disappointed, discouraged, disgusted, ecstatic, embar-
rassed, enthusiastic, envious, excited, exhausted,
frightened, frustrated, guilty, happy, helpless, hopeful,
hostile, humiliated, hurt, hysterical, innocent, interest-
ed, jealous, lonely, mischievous, miserable, optimistic,
paranoid, peaceful, proud, puzzled, regretful, relieved,
sad, satisfied, shocked, shy, sorry, surprised, suspi-
cious, thoughtful, undecided, withdrawn
</bodyText>
<tableCaption confidence="0.987755">
Table 3: Words implying positive, negative and emo-
tional connotations
</tableCaption>
<subsectionHeader confidence="0.677451">
3.5 Proposed POS Sequence Pattern Fea-
tures
</subsectionHeader>
<bodyText confidence="0.999978212121212">
We now present the proposed POS sequence pat-
tern features and the mining algorithm. This re-
sults in a new feature class. A POS sequence
pattern is a sequence of consecutive POS tags that
satisfy some constraints (discussed below). We
used (Tsuruoka and Tsujii, 2005) as our POS tag-
ger.
As shown in (Baayen et. al., 1996), POS n-
grams are good at capturing the heavy stylistic
and syntactic information. Instead of using all
such n-grams, we want to discover all those pat-
terns that represent true regularities, and we also
want to have flexible lengths (not fixed lengths as
in n-grams). POS sequence patterns serve these
purposes. Its mining algorithm mines all such pat-
terns that satisfy the user-specified minimum sup-
port (minsup) and minimum adherence
(minadherence) thresholds or constraints. These
thresholds ensure that the mined patterns represent
significant regularities.
The main idea of the algorithm is to perform a
level-wise search for such patterns, which are
POS sequences with minsup and minadherence.
The support of a pattern is simply the proportion
of documents that contain the pattern. If a pattern
appears too few times, it is probably spurious. A
sequence is called a frequent sequence if it satis-
fies minsup. The adherence of a pattern is meas-
ured using the symmetrical conditional
probability (SCP) given in (Silva et al., 1999).
The SCP of a sequence with two elements |xy |is
the product of the conditional probability of each
given the other,
</bodyText>
<equation confidence="0.979459">
SCP x y = P x y P y x =
( , ) (  |) (  |)
</equation>
<bodyText confidence="0.998952142857143">
Given a consecutive sequence of POS tags
|x1...xn|, called a POS sequence of length n, a dis-
persion point defines two subparts of the se-
quence. A sequence of length n contains n-1
possible dispersion points. The SCP of the se-
quence |x1...xn |given the dispersion point (denoted
by *) |x1...xn-1*xn |is:
</bodyText>
<equation confidence="0.998955">
SCP x x x
(( ... ), )
1 n− 1 n
</equation>
<bodyText confidence="0.966577">
The SCP measure can be extended so that all
possible dispersion points are accounted for.
</bodyText>
<equation confidence="0.991532181818182">
2
P x y
( , )
P ( ) ( )
x P y
2
)
P(x1 ...xn
=
1) P( xn)
P(x1 ...xn
</equation>
<page confidence="0.987376">
210
</page>
<bodyText confidence="0.8098808">
Hence the fairSCP of the sequence |x1...xn |is giv-
en by:
fairSCP measures the adherence strength of POS
tags in a sequence. The higher the fairSCP value,
the more dominant is the sequence. Our POS se-
quence pattern mining algorithm is given below.
Input: Corpus D = {d  |d is a document containing a
sequence of POS tags}, Tagset T = {t  |t is a POS
tag}, and the user specified minimum support (min-
sup) and minimum adherence (minadherence).
Output: All POS sequence patterns (stored in SP)
mined from D that satisfy minsup and minadhe-
rence.
Algorithm mine-POS-pats(D, T, minsup, minadhe-
rence)
</bodyText>
<listItem confidence="0.994516166666667">
1. C1 +- count each t (e T) in D;
2. F1 +- {f  |f c C1 , f .count / n &gt; minsup}; // n = |D|
3. SP1 +- F1;
4. for (k = 2; k :5 MAX-length; k++)
5. Ck = candidate-gen(Fk-1);
6. for each document d c D
7. for each candidate POS sequence c c Ck
8. if (c is contained in d)
9. c.count++;
10. endfor
11. endfor
12. Fk +- {c c Ck  |c.count / n &gt; minsup};
13 SPk +- {f c Fk  |fairSCP(f) &gt; minadherence}
14. endfor
15. return SP +- I I SPk ;
k
Function candidate-gen(Fk-1)
1. Ck +- ∅;
2. for each POS n-gram c c Fk-1
3. for each t c T
4. c′ +- addsuffix(c, t); // adds tag t to c as suffix
5. add c′ to Ck ;
6. endfor
7. endfor
</listItem>
<bodyText confidence="0.999118785714286">
We now briefly explain the mine-POS-pats algo-
rithm. The algorithm is based on level-wise
search. It generates all POS patterns by making
multiple passes over data. In the first pass, it
counts the support of individual POS tags and de-
termines which of them have minsup (line 2).
Multiple occurrences of a tag in a document are
counted only once. Those in F1 are called length 1
frequent sequences. All length 1 sequence patterns
are stored in SP1. Since adherence is not defined
for a single element, we have SP1 = F1 (line 3). In
each subsequent pass k until MAX-length (which
is the maximum length limit of the mined pat-
terns), there are three steps:
</bodyText>
<listItem confidence="0.999415125">
1. Using Fk-1 (frequent sequences found in the (k-
1) pass) as a set of seeds, the algorithm applies
candidate-gen() to generate all possibly fre-
quent POS k-sequences (sequences of length k)
(line 5). Those infrequent sequences (which are
not in Fk-1) are discarded as adding more POS
tags will not make them frequent based on the
downward closure property in (Agrawal and
Srikant, 1994).
2. D is then scanned to compute the actual sup-
port count of each candidate in Ck (lines 6-11).
3. At the end of each scan, it determines which
candidate sequences have minsup and minad-
herence (lines 12 - 13). We compute Fk and SPk
separately because adherence does not have the
downward closure property as the support.
</listItem>
<bodyText confidence="0.997872869565217">
Finally, the algorithm returns the set of all se-
quence patterns (line 15) that meet the minsup and
minadherence thresholds.
The candidate-gen() function generates all pos-
sibly frequent k-sequences by adding each POS
tag t to c as suffix. c is a k-1-sequence in Fk-1.
In our experiments, we used MAX-length = 7,
minsup = 30%, and minadherence = 20% to mine
all POS sequence patterns. All the mined patterns
are used as features.
Finally, it is worthwhile to note that mine-
POS-pat is very similar to the well-known GSP
algorithm (Srikant and Agrawal, 1996). Likewise,
it has linear scale up with data size. If needed, one
can use MapReduce (Dean and Ghemawat, 2004)
with suitable modifications in mine-POS-pats to
speed things up by distributing to multiple ma-
chines for large corpora. Moreover, mining is a
part of preprocessing of the algorithm and its
complexity does not affect the final prediction, as
it will be later shown that for model building and
prediction, standard machine learning methods are
used.
</bodyText>
<sectionHeader confidence="0.995558" genericHeader="method">
4 Ensemble Feature Selection
</sectionHeader>
<bodyText confidence="0.999335">
Since all classes of features discussed in Section 3
are useful, we want to employ all of them. This
results in a huge number of features. Many of
</bodyText>
<equation confidence="0.9901235">
1
−
n
fairSCP(x1 ... xn) = n − 1
1
L
2
)
P(x1 ... xn
)
)P(xi+1 ...xn
P(x1 ... xi
i
=1
</equation>
<page confidence="0.990984">
211
</page>
<bodyText confidence="0.999975192307692">
them are redundant and even harmful. Feature
selection thus becomes important. There are two
common approaches to feature selection: the filter
and the wrapper approaches (Blum and Langley,
1997; Kohavi and John, 1997). In the filter ap-
proach, features are first ranked based on a feature
selection criterion such as information gain, chi-
square (x2) test, and mutual information. A set of
top ranked features are selected. On the contrary,
the wrapper model chooses features and adds to
the current feature pool based on whether the new
features improve the classification accuracy.
Both these approaches have drawbacks. While
the wrapper approach becomes very time consum-
ing and impractical when the number of features
is large as each feature is tested by building a new
classifier. The filter approach often uses only one
feature selection criterion (e.g., information gain,
chi-square, or mutual information). Due to the
bias of each criterion, using only a single one may
result in missing out some good features which
can rank high based on another criterion. In this
work, we developed a novel feature selection me-
thod that uses multiple criteria, and combines both
the wrapper and the filter approaches. Our method
is called ensemble feature selection (EFS).
</bodyText>
<subsectionHeader confidence="0.928621">
4.1 EFS Algorithm
</subsectionHeader>
<bodyText confidence="0.999462954545455">
EFS takes the best of both worlds. It first uses a
number of feature selection criteria to rank the
features following the filter model. Upon ranking,
the algorithm generates some candidate feature
subsets which are used to find the final feature set
based on classification accuracy using the wrapper
model. Since our framework generates much few-
er candidate feature subsets than the total number
of features, using wrapper model with candidate
feature sets is scalable. Also, since the algorithm
generates candidate feature sets using multiple
criteria and all feature classes jointly, it is able to
capture most of those features which are discrimi-
nating. We now detail our EFS algorithm.
The algorithm takes as input, a set of n features
F = {f1, ..., fn}, a set of t feature selection criteria
Θ = {θ1, ..., θt}, a set of t thresholds Τ = {τ1, ...,
τt} corresponding to the criteria in Θ, and a win-
dow w. τi is the base number of features to be se-
lected for criterion θi. w is used to vary τi (thus the
number of features) to be used by the wrapper
approach.
</bodyText>
<listItem confidence="0.98051959375">
Algorithm: EFS (F, Θ, Τ, w)
1. for each θi e Θ
2. Rank all features in F based on criterion θi and
let ξi denotes the ranked features
3. endfor
4. for i = 1 to t
5. Ci +- 0
6. for τ = τi – w to τ = τi + w
7. select first τ features ζi from ξi and add ζi to Ci
in order
8. endfor
9. endfor
10. // Ci = {ζ1, ..., ζ2w + 1}, where ζi is a set of fea-
tures
11. OptCandFeatures +- 0;
12. Repeat steps 13 – 18
13. A +- 0
14. for i = 1 to t
15. select and remove the first feature set ζi e Ci
from Ci in order
16. A +- A v ζi
17. endfor
18. add A to OptCandFeatures
19. // A is a set of features comprising of features in
// feature sets ζi e Ci in the same position V i
20. until Ci = 0 V i
21. for each A e OptCandFeatures
22. A.score +- accuracy of 10-fold CV on training
data on a chosen classifier (learning algo-
rithm)
23. endfor
24. return arg max { A  |A e OptCandFeatures}
</listItem>
<bodyText confidence="0.9891288">
A.score
We now explain our EFS algorithm. Using a set of
different feature selection measures, Θ, we rank
all features in our feature pool, F, using the set of
criteria (lines 1–3). This is similar to the filter ap-
proach. In lines 4–9, we generate feature sets Ci, 1
&lt; i &lt; t for each of the t criteria. Each set Ci con-
tains feature subsets, and each subset ζi is the set of
top τ features in ξi ranked based on criterion θi in
lines 1–2. τ varies from τi – w to τi + w where τi is
the threshold for criterion θi and w the window
size. We vary τ and generate 2w + 1 feature sets
and add all such feature sets ζi to Ci (in lines 6–8)
in order. We do so because it is difficult to know
the optimal threshold τi for each criterion θi. It
should be noted that “adding in order” ensures the
ordering of feature sets �i as shown in line 10,
which will be later used to “select and remove in
order” in line 15. In lines 11–20 we generate can-
didate feature sets using Ci and add each such
</bodyText>
<page confidence="0.996052">
212
</page>
<bodyText confidence="0.999965674418605">
candidate feature set Λ to OptCandFeatures. Each
candidate feature set Λ is a collection of top
ranked features based on multiple criteria. It is
generated by unioning the features in the first fea-
ture subset Ci, which is then removed from Ci for
each criterion Bi (lines 14-17). Each candidate fea-
ture set is added to OptCandFeatures in line 18.
Since each Ci has 2w+1 feature subsets Ci, there
are a total of 2w+1 candidate feature sets Λ in
OptCandFeatures. Lines 21–23 assign an accuracy
to each candidate feature set Λ Ԗ OptCandFeatures
by running 10-fold cross validation on the training
data using a chosen classifier with the features in
Λ. Finally, the optimal feature set Λ Ԗ OptCand-
Features is returned in line 24.
An interesting question arising in the EFS al-
gorithm is: How does one select the threshold ri
for each criterion Bi and the window size w? Intui-
tively, suppose that for criterion Bi, the optimal
subset of features is Sopt_i based on some optimal
threshold ri. Then the final feature set is a collec-
tion of all features f Ԗ Sopt_i ∀ i. However, finding
such optimal feature set Sopt_i or optimal threshold
ri is a difficult problem. To counter this, we use
the window w to select various feature subsets
close to the top ri features in �i. Thus, the thre-
shold values ri and window size w should be ap-
proximated by experiments. In our experiments,
we used ri = top 1/20th of the features ranked in �i
for ∀ i and window size w = |F|/100, and got good
results. Fortunately, as we will see in Section 6.2,
these parameters are not sensitive at all, and any
reasonably large size feature set seems to work
equally well.
Finally, we are aware that there are some exist-
ing ensemble feature selection methods in the ma-
chine learning literature (Garganté et al., 2007; Tuv
et al., 2009). However, they are very different
from our approach. They mainly use ensemble
classification methods to help choose good fea-
tures rather than combining different feature se-
lection criteria and integrating different feature
selection approaches as in our method.
</bodyText>
<subsectionHeader confidence="0.982313">
4.2 Feature Selection Criteria
</subsectionHeader>
<bodyText confidence="0.9995041">
The set of feature selection criteria O = {B1...Bt}
used in our work are those commonly used indi-
vidual selection criteria in the filter approach.
Let C ={c1, c2, ..., cm} denotes the set of
classes, and F = {f1, f2, ..., fn} the set of features.
We list the criteria in O used in our work below.
Information Gain (IG): This is perhaps the most
commonly used criterion, which is based on en-
tropy. The scoring function for information gain
of a feature f is given by:
</bodyText>
<equation confidence="0.86485715">
m m
c P c +∑ ∑
Pf P c f P c f
i) log ( ) ( ) (  |) log (  |)
i i i
f f
, i=1
Mutual Information (MI): This metric is com-
monly used in statistical language modeling. The
mutual information MI(f, c) between a class c and
a feature f is defined as:
Pf c
( , )
log
P f P c
( ) ( )
f f c c
, ,
rion is the max among all classes. MI(f)
{MI (f,
</equation>
<bodyText confidence="0.9639547">
(which we use). The weighted average
over all classes can also be applied as the scoring
function.
Statistic: The
statistic measures the lack of
independence between a feature f and class c, and
can be compared to the
distribution with one
degree of freedom. We use a 2x2 contingency ta-
ble of a feature f an
</bodyText>
<equation confidence="0.5364444">
= maxi
ci)}
χ2
χ2
χ2
</equation>
<bodyText confidence="0.327907">
d a class c to introduce χ2 test.
</bodyText>
<table confidence="0.438418666666667">
c c
f W X
f Y Z
</table>
<tableCaption confidence="0.8803495">
Table 4: Two-way contingency table
and c
</tableCaption>
<bodyText confidence="0.9809361">
In the table, W denotes the number of documents
in the corpus in which feature f and class c co-
occur, X the number of documents in which f oc-
curs without c, Y the number of documents in
which c occurs without f, an
of f
d Z the number of
documents in which neither c nor f occurs. Thus,
N = W + X + Y + Z is the total number of docu-
ments in the corpus.
</bodyText>
<equation confidence="0.732867">
χ2 test is defined as:
(W+Y)(X+Z)(W+ X)(Y+ Z)
</equation>
<bodyText confidence="0.997759857142857">
The scoring function generally used as the crite-
The scoring function using the
statistic is either
the weighted average or max over all classes. In
our experiments, we use the weighted average:
Cross Entropy (CE): This metric is similar to
mutual information (Mladenic an
</bodyText>
<equation confidence="0.98845125">
χ2
�2(f) = ∑= m P c i f c i
( ) χ 2 ( , )
i 1
d Grobelnik,
2
N WZ YX
( − )
∑
IG
( )
f = − P(
i
= 1
MI(f , c ) =∑∑ P f c
( , )
2
c
=
,
)
χ
f
(
</equation>
<page confidence="0.83808">
213
</page>
<equation confidence="0.944254875">
1998):
m
CE(f) = P(f)
∑=
i 1
P(ci  |� log P f
( )
ci |
</equation>
<bodyText confidence="0.958779">
Weight of Evidence for Text (WET): This crite-
rion is based on the average absolute weight of
evidence (Mladenic and Grobelnik, 1998):
214 we compared with three representatives in (Arga-
</bodyText>
<equation confidence="0.74123865">
P(
i)P(
=∑=
c
f)  |log
1
P(ci  |f)
(1
P c
( )(1 (  |))
− P c f
i i
WET f
( )
|
i
))
P(
−
ci
</equation>
<sectionHeader confidence="0.797896" genericHeader="method">
5 Feature Value Assignments
</sectionHeader>
<bodyText confidence="0.978221851851852">
Naïve
t.
mon et al., 2007), (Schler et al., 2006) and (Yan
and Yan, 2006). Since they do not have publicly
available systems, we implemented them. Each of
them just uses a subset of the features used in our
system. Recall our system includes all their fea-
tures and our own POS pattern based features. For
systems, we compared with two public domain
systems, Gender Genie (BookBlog, 2007) and
Gender Guesser (Krawetz, 2006), which imple-
mented variations of the algorithm in (Argamon
et. al, 2003).
We used SVM classification, SVM regression,
and
Bayes (NB) as learning algorithms.
Although SVM regression is not designed for
classification, it can be applied based on the out-
put of positive or negative values. It actually
worked better than SVM classification for our
data. For SVM classification and regression, we
used SVMLight (Joachims, 1999), and for NB we
used (Borgelt, 2003). In all our experiments, we
used accuracy as the evaluation measure as the
two classes (male and female) are roughly ba-
lanced (see the data description below), and both
classes are equally importan
</bodyText>
<subsectionHeader confidence="0.999758">
6.1 Blog Data Set
</subsectionHeader>
<bodyText confidence="0.992067333333333">
on the appearances of the pattern d 330 words for women.
in the POS
tagged document.
</bodyText>
<sectionHeader confidence="0.995471" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.988225">
6.2 Results
</subsectionHeader>
<bodyText confidence="0.982755883720931">
d systems. For algorithms, P(
m
After selecting features belonging to different
classes, values are assigned differently to different
classes of features. There are three common ways
of feature value assignments: Boolean, TF (Term
Frequency) and TF-IDF (product of term and in-
verted document frequency). For details of feature
value assignments, interested readers are referred
to (Joachims, 1997). While the Boolean scheme
assigns a 1 to the feature value if the feature is
present in the document and a 0 otherwise, the TF
scheme assigns the relative frequency of the num-
ber of times that the feature occurs in the docu-
ment. We did not use TF-IDF as it did not yield
good results in our preliminary experiments.
The feature value assignment to different
classes of features is done as follows: The value
of F-measure was assigned based on its actual
value. Stylistic features such words, and blog
words were assigned values 1 or 0 in the Boolean
scheme and the relative frequency in the TF
scheme (we experimented with both schemes).
Feature values for gender preferential features
were also assigned in a similar way. Factor and
word class features were assigned values accord-
ing to the Boolean or TF scheme if any of the
words belonging to the feature class exists (factor
or word class appeared in that document). Each
POS sequence pattern feature was assigned a val-
ue according to the Boolean (or TF) scheme based
To keep the problem of gender classification of
informal text as general as possible, we collected
blog posts from many blog hosting sites and blog
search engines, e.g., blogger.com, technorati.com,
etc. The data set consists of 3100 blogs. Each blog
is labeled with the gender of its author. The gend-
er of the author was determined by visiting the
profile of the author. Profile pictures or avatars
associated with the profile were also helpful in
confirming the gender especially when the gender
information was not available explicitly. To en-
sure quality of the labels, one group of students
collected the blogs and did the initial labeling, and
the other group double-checked the labels by visit-
ing the actual blog pages. Out of 3100 posts, 1588
(51.2%) were written by men and 1512 (48.8%)
were written by women. The average post length
is 250 words for men an
This section evaluates the proposed techniques
and sees how they affect the classification accura-
cy. We also compare with the existing state-of-
the-art algorithms an
We used all features from different feature classes
(Section 3) along with our POS pattern
s as our
pool of features. We used τ and w values stated in
Section 4.1 and criteria mentioned in Section 4.2
for our EFS algorithm. EFS was compared with
three commonly used feature selection methods
on SVM classification (denoted by SVM), SVM
regression (denoted by SVM_R) and the NB clas-
sifier. The results are shown in Table 5. All results
were obtained through 10-fold cross validation.
Also, the total number of features selected by
IG, MI, χ2, and EFS were roughly the same. Thus,
the improvement in accuracy brought forth by
EFS was chiefly due to the combination of fea-
tures selected (based on multi-criteria).
To measure the accuracy improvement of using
our POS patterns over common POS n-grams, we
also compared our results with those from POS n-
grams (Koppel et al., 2002). The comparison re-
sults are given in Table 6. Table 6 also includes
results to show the overall improvement in accu-
racy with our two new techniques. We tested our
system without any feature selection and without
using the POS sequence patterns as features.
The comparison results with existing algo-
rithms and public domain systems using our real-
life blog data set are tabulated in Table 7.
Also, to see whether feature selection helps and
how many features are optimal, we varied τ and w
of the EFS algorithm and plotted the accuracy vs.
no. of features. These results are shown in Figure
1.
</bodyText>
<table confidence="0.9997125">
Feature Value NB SVM SVM R
Selection Assignment _
IG Boolean 71.32 76.61 78.32
IG TF 66.01 72.84 74.13
MI Boolean 72.01 78.62 79.48
MI TF 70.86 73.14 74.58
χ2 Boolean 72.90 80.71 81.52
χ2 TF 71.84 73.57 75.24
EFS Boolean 73.57 86.24 88.56
EFS TF 72.82 82.05 83.53
</table>
<tableCaption confidence="0.943687">
Table 5: Accuracies of SVM, SVM_R and NB with
different feature selection methods
</tableCaption>
<table confidence="0.9998624">
Settings NB SVM SVM_R
All features 63.01 68.84 70.03
All features, no POS patterns 60.73 65.17 66.17
POS 1,2,3-grams + EFS 71.24 82.71 83.86
POS Patterns + EFS 73.57 86.24 88.56
</table>
<tableCaption confidence="0.987607">
Table 6: Accuracies of POS n-grams and POS patterns
with or without EFS (Boolean value assignment)
</tableCaption>
<table confidence="0.999555714285714">
System Accuracy (%)
Gender Genie 61.69
Gender Guesser 63.78
(Argamon et al., 2007) 77.86
(Schler et al., 2006) 79.63
(Yan and Yan, 2006) 68.75
Our method 88.56
</table>
<tableCaption confidence="0.992211">
Table 7: Accuracy comparison with other systems
</tableCaption>
<table confidence="0.766732">
No. of features
SVM Classification with EFS
SVM Regression with EFS
Naïve Bayes with EFS
</table>
<figureCaption confidence="0.996094">
Figure 1: Accuracy vs. no. of features using EFS
</figureCaption>
<subsectionHeader confidence="0.976099">
6.3 Observations and Discussions
</subsectionHeader>
<bodyText confidence="0.999876">
Based on the results given in the previous section,
we make the following observations:
</bodyText>
<listItem confidence="0.8706465">
• SVM regression (SVM_R) performs the best
(Table 5). SVM classification (SVM) also
gives good accuracies. NB did not do so well.
• Table 5 also shows that our EFS feature selec-
</listItem>
<bodyText confidence="0.997086">
tion method brings about 6-10% improvement
in accuracy over the other feature selection me-
thods based on SVM classification and SVM
regression. The reason has been explained in
the introduction section. Paired t-tests showed
that all the improvements are statistically sig-
nificant at the confidence level of 95%. For
NB, the benefit is less (3%).
</bodyText>
<listItem confidence="0.954263142857143">
• Keeping all other parameters constant, Table 5
also shows that Boolean feature values yielded
better results than the TF scheme across all
classifiers and feature selection methods.
• Row 1 of Table 6 tells us that feature selection
is very useful. Without feature selection (All
features), SVM regression only achieves 70%
</listItem>
<bodyText confidence="0.9920548">
accuracy, which is way inferior to the 88.56%
accuracy obtained using EFS feature selection.
Row 2 shows that without EFS and without
POS sequence patterns, the results are even
worse.
</bodyText>
<figure confidence="0.995074">
100
90
80
70
60
50
Accuracy
</figure>
<page confidence="0.993939">
215
</page>
<listItem confidence="0.706573">
• Keeping all other parameters intact, Table 6
</listItem>
<bodyText confidence="0.983939440000001">
also demonstrated the effectiveness of our POS
pattern features over POS n-grams. We have
discussed the reason in Section 3.2 and 3.5.
• From Tables 5 and 6, we can infer that the
overall accuracy improvement using EFS and
all feature classes described in Section 3 is
about 15% for SVM classification and regres-
sion and 10% for NB. Also, using POS se-
quence patterns with EFS brings about a 5%
improvement over POS n-grams (Table 6). The
improvement is more pronounced for SVM
based methods than NB.
• Table 7 summarizes the accuracy improvement
brought by our proposed techniques over the
existing state-of-art systems. Our techniques
have resulted in substantial (around 9%) accu-
racy improvement over the best of the existing
systems. Note that (Argamon et al., 2007) used
Logistic Regression with word classes and
POS unigrams as features. (Schler et al., 2006)
used Winnow classifier with function words,
content word classes, and POS features. (Yan
and Yan, 2006) used Naive Bayes with content
words and blog-words as features. For all these
systems, we used their features and ran their
original classifiers and also the three classifiers
in this paper and report the best results. For
example, for (Argamon et al., 2007), we ran
Logistic Regression and our three methods.
SVM based methods always gave slightly bet-
ter results. We could not run Winnow due to
some technical issues. SVM and SVM_R gave
comparable results to those given in their orig-
inal papers. These results again show that our
techniques are useful. All the gains are statisti-
cally significant at the confidence level of
95%.
• From Figure 1, we see that when the number of
features selected is small (&lt;100) the classifica-
tion accuracy is lower than that obtained by us-
ing all features (no feature selection).
However, the accuracy increases rapidly as the
number of selected features increases. After
obtaining the best case accuracy, it roughly
maintains the accuracy over a long range. The
accuracies then gradually decrease with the in-
crease in the number of features. This trend is
consistent with the prior findings in (Mladenic,
1998; Rogati and Yang, 2002; Forman 2003;
Riloff et al., 2006; Houvardas and Stamatatos,
2006).
It is important to note here that over a long
range of 2000 to 20000 features, the accuracy
is high and stable. This means that the thre-
sholds of EFS are easy to set. As long as they
are in the range, the accuracy will be good.
Finally, we would like to mention that (Herring
and Paolillo, 06) has used genre relationships with
gender classification. Their finding that subgenre
“diary” contains more “female” and subgenre “fil-
ter” having more “male” stylistic features inde-
pendent of the author gender, may obscure gender
classification as there are many factors to be con-
sidered. Herring and Paolillo referred only words
as features which are not as fine grained as our
POS sequence patterns. We are also aware of oth-
er factors influencing gender classification like
genre, age and ethnicity. However, much of such
information is hard to obtain reliably in blogs.
They definitely warren some future studies. Also,
EFS being a useful method for feature selection in
machine learning, it would be useful to perform
further experiments to investigate how well it per-
forms on a variety of classification datasets. This
again will be an interesting future work.
</bodyText>
<sectionHeader confidence="0.999633" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999923952380952">
This paper studied the problem of gender classifi-
cation. Although there have been several existing
papers studying the problem, the current accuracy
is still far from ideal. In this work, we followed
the supervised approach and proposed two novel
techniques to improve the current state-of-the-art.
In particular, we proposed a new class of features
which are POS sequence patterns that are able to
capture complex stylistic regularities of male and
female authors. Since there are a large number
features that have been considered, it is important
to find a subset of features that have positive ef-
fects on the classification task. Here, we proposed
an ensemble feature selection method which takes
advantage of many different types of feature se-
lection criteria in feature selection. Experimental
results based on a real-life blog data set demon-
strated the effectiveness of the proposed tech-
niques. They help achieve significantly higher
accuracy than the current state-of-the-art tech-
niques and systems.
</bodyText>
<page confidence="0.998354">
216
</page>
<sectionHeader confidence="0.99834" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999916990825688">
Agrawal, R. and Srikant, R. 1994. Fast Algorithms for
Mining Association Rules. VLDB. pp. 487-499.
Argamon, S., Koppel, M., J Fine, AR Shimoni. 2003.
Gender, genre, and writing style in formal written
texts. Text-Interdisciplinary Journal, 2003.
Argamon, S., Koppel, M., Pennebaker, J. W., Schler, J.
2007. Mining the Blogosphere: Age, Gender and
the varieties of self-expression, First Monday, 2007
- firstmonday.org
Baayen, H., H van Halteren, F Tweedie. 1996. Outside
the cave of shadows: Using syntactic annotation to
enhance authorship attribution, Literary and Lin-
guistic Computing, 11, 1996.
Blum, A. and Langley, P. 1997. Selection of relevant
features and examples in machine learning. Artifi-
cial Intelligence, 97(1-2):245-271.
BookBlog, Gender Genie, Copyright 2003-2007,
http://www.bookblog.net/gender/genie.html
Borgelt, C. 2003. Bayes Classifier Induction.
http://www.borgelt.net/doc/bayes/bayes.html
Chung, C. K. and Pennebaker, J. W. 2007. Revealing
people’s thinking in natural language: Using an au-
tomated meaning extraction method in open–ended
self–descriptions, J. of Research in Personality.
Corney, M., Vel, O., Anderson, A., Mohay, G. 2002.
Gender Preferential Text Mining of E-mail Dis-
course. 18th annual Computer Security Applica-
tions Conference (ACSAC), 2002.
J. Dean and S. Ghemawat. 2004. Mapreduce: Simpli-
fied data processing on large clusters, Operating
Systems Design and Implementation, 2004.
Forman, G., 2003. An extensive empirical study of fea-
ture selection metrics for text classification. JMLR,
3:1289 - 1306 , 2003.
Garganté, R. A., Marchiori, T. E., and Kowalczyk, S.
R. W., 2007. A Genetic Algorithm to Ensemble Fea-
ture Selection. Masters Thesis. Vrije Universiteit,
Amsterdam.
Gefen, D., D. W. Straub. 1997. Gender differences in
the perception and use of e-mail: An extension to
the technology acceptance model. MIS Quart. 21(4)
389–400.
Herring, S. C., &amp; Paolillo, J. C. 2006. Gender and ge-
nre variation in weblogs, Journal of Sociolinguis-
tics, 10 (4), 439-459.
Heylighen, F., and Dewaele, J. 2002. Variation in the
contextuality of language: an empirical measure.
Foundations of Science, 7, 293–340.
Houvardas, J. and Stamatatos, E. 2006. N-gram Fea-
ture Selection for Authorship Identification, Proc. of
the 12th Int. Conf. on Artificial Intelligence: Me-
thodology, Systems, Applications, pp. 77-86.
Joachims, T. 1999. Making large-Scale SVM Learning
Practical. Advances in Kernel Methods - Support
Vector Learning, B. Schölkopf and C. Burges and
A. Smola (ed.), MIT-Press, 1999.
Joachims, T. 1997. Text categorization with support
vector machines, Technical report, LS VIII Number
23, University of Dortmund, 1997
Kohavi, R. and John, G. 1997. Wrappers for feature
subset selection. Artificial Intelligence, 97(1-
2):273-324.
Koppel, M., Argamon, S., Shimoni, A. R.. 2002. Auto-
matically Categorizing Written Text by Author
Gender. Literary and Linguistic Computing.
Krawetz, N. 2006. Gender Guesser. Hacker Factor
Solutions. http://www.hackerfactor.com/ Gender-
Guesser.html
Mladenic, D. 1998. Feature subset selection in text
learning. In Proc. of ECML-98, pp. 95–100.
Mladenic, D. and Grobelnik, D.1998. Feature selection
for classification based on text hierarchy. Proceed-
ings of the Workshop on Learning from Text and
the Web, 1998
Nowson, S., Oberlander J., Gill, A. J., 2005. Gender,
Genres, and Individual Differences. In Proceedings
of the 27th annual meeting of the Cognitive Science
Society (p. 1666–1671). Stresa, Italy.
Riloff, E., Patwardhan, S., Wiebe, J.. 2006. Feature
Subsumption for opinion Analysis. EMNLP,
Rogati, M. and Yang, Y.2002. High performing and
scalable feature selection for text classification. In
CIKM, pp. 659-661, 2002.
Schiffman, H. 2002. Bibliography of Gender and Lan-
guage. http://ccat.sas.upenn.edu/~haroldfs/ pop-
cult/bibliogs/gender/genbib.htm
Schler, J., Koppel, M., Argamon, S, and Pennebaker J.
2006. Effects of age and gender on blogging, In
Proc. of the AAAI Spring Symposium Computa-
tional Approaches to Analyzing Weblogs.
Silva, J., Dias, F., Guillore, S., Lopes, G. 1999. Using
LocalMaxs Algortihm for the Extraction of Conti-
guous and Noncontiguous Multiword Lexical Units.
Springer Lecture Notes in AI 1695, 1999
Srikant, R. and Agrawal, R. 1996. Mining sequential
patterns: Generalizations and performance im-
provements, In Proc. 5th Int. Conf. Extending Data-
base Technology (EDBT’96), Avignon, France.
Tannen, D. (1990). You just don’t understand, New
York: Ballantine.
Tsuruoka, Y. and Tsujii, J. 2005. Bidirectional Infe-
rence with the Easiest-First Strategy for Tagging
Sequence Data, HLT/EMNLP 2005, pp. 467-474.
Tuv, E., Borisov, A., Runger, G., and Torkkola, K.
2009. Feature selection with ensembles, artificial
variables, and redundancy elimination. JMLR, 10.
Yan, X., Yan, L. 2006. Gender Classification of Web-
log Authors. Computational Approaches to Analyz-
ing Weblogs, AAAI.
</reference>
<page confidence="0.998403">
217
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.963743">
<title confidence="0.999774">Improving Gender Classification of Blog Authors</title>
<author confidence="0.997746">Arjun Mukherjee Bing Liu</author>
<affiliation confidence="0.9999445">Department of Computer Science University of Illinois at Chicago</affiliation>
<address confidence="0.997192">851 South Morgan Street Chicago, IL 60607, USA</address>
<email confidence="0.999759">amukherj@cs.uic.edu</email>
<affiliation confidence="0.999914">Department of Computer Science University of Illinois at Chicago</affiliation>
<address confidence="0.9967045">851 South Morgan Street Chicago, IL 60607, USA</address>
<email confidence="0.999864">liub@cs.uic.edu</email>
<abstract confidence="0.9989038">The problem of automatically classifying the gender of a blog author has important applications in many commercial domains. Existing systems mainly use features such as words, word classes, and POS (part-ofspeech) n-grams, for classification learning. In this paper, we propose two new techniques to improve the current result. The first technique introduces a new class of features which are variable length POS sequence patterns mined from the training data using a sequence pattern mining algorithm. The second technique is a new feature selection method which is based on an ensemble of several feature selection criteria and approaches. Empirical evaluation using a real-life blog data set shows that these two techniques improve the classification accuracy of the current state-ofthe-art methods significantly.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Agrawal</author>
<author>R Srikant</author>
</authors>
<title>Fast Algorithms for Mining Association Rules.</title>
<date>1994</date>
<pages>487--499</pages>
<publisher>VLDB.</publisher>
<contexts>
<context position="19571" citStr="Agrawal and Srikant, 1994" startWordPosition="3174" endWordPosition="3177">equence patterns are stored in SP1. Since adherence is not defined for a single element, we have SP1 = F1 (line 3). In each subsequent pass k until MAX-length (which is the maximum length limit of the mined patterns), there are three steps: 1. Using Fk-1 (frequent sequences found in the (k1) pass) as a set of seeds, the algorithm applies candidate-gen() to generate all possibly frequent POS k-sequences (sequences of length k) (line 5). Those infrequent sequences (which are not in Fk-1) are discarded as adding more POS tags will not make them frequent based on the downward closure property in (Agrawal and Srikant, 1994). 2. D is then scanned to compute the actual support count of each candidate in Ck (lines 6-11). 3. At the end of each scan, it determines which candidate sequences have minsup and minadherence (lines 12 - 13). We compute Fk and SPk separately because adherence does not have the downward closure property as the support. Finally, the algorithm returns the set of all sequence patterns (line 15) that meet the minsup and minadherence thresholds. The candidate-gen() function generates all possibly frequent k-sequences by adding each POS tag t to c as suffix. c is a k-1-sequence in Fk-1. In our expe</context>
</contexts>
<marker>Agrawal, Srikant, 1994</marker>
<rawString>Agrawal, R. and Srikant, R. 1994. Fast Algorithms for Mining Association Rules. VLDB. pp. 487-499.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Argamon</author>
<author>M Koppel</author>
<author>J Fine</author>
<author>AR Shimoni</author>
</authors>
<title>Gender, genre, and writing style in formal written texts. Text-Interdisciplinary Journal,</title>
<date>2003</date>
<contexts>
<context position="4830" citStr="Argamon et al., 2003" startWordPosition="754" endWordPosition="758">tures. A combination of them should be able to capture the most useful or discriminative features. Our experimental results based on a real life blog data set collected from a large number of blog hosting sites show that the two new techniques enable classification algorithms to significantly improve the accuracy of the current stateof-the-art techniques (Argamon et al., 2007; Schler et al., 2006; Yan and Yan, 2006). We also compare with two publicly available systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006). Both systems implemented variations of the method given in (Argamon et al., 2003). Here, the improvement of our techniques is even greater. 2 Related Work There have been several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Argamon et al., 2007), results of dictionary based content analysis, POS unigram (Yan and Yan, 2006), and personality types (Nowson et al., 2005) to capture stylistic behavior of authors’ writings for classifying gender. (Koppel et al. 2002) als</context>
</contexts>
<marker>Argamon, Koppel, Fine, Shimoni, 2003</marker>
<rawString>Argamon, S., Koppel, M., J Fine, AR Shimoni. 2003. Gender, genre, and writing style in formal written texts. Text-Interdisciplinary Journal, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Argamon</author>
<author>M Koppel</author>
<author>J W Pennebaker</author>
<author>J Schler</author>
</authors>
<title>Mining the Blogosphere: Age, Gender and the varieties of self-expression,</title>
<date>2007</date>
<location>First Monday,</location>
<note>firstmonday.org</note>
<contexts>
<context position="3151" citStr="Argamon et al., 2007" startWordPosition="482" endWordPosition="485">cally short and unstructured, and consist of mostly informal sentences, which can contain spurious information and are full of grammar errors, abbreviations, slang words and phrases, and wrong spellings. Due to these reasons, gender classification of blog posts is a harder problem than gender classification of traditional formal text. Recent work has also attempted gender classification of blog authors using features such as content words, dictionary based content analysis results, POS (part-of-speech) tags and feature selection along with a supervised learning algorithm (Schler et al., 2006; Argamon et al., 2007; Yan and Yan, 2006). This paper improves these existing methods by proposing two novel techniques. The first technique adds a new class of pattern based features to learning, which are not used in any existing work. The patterns are frequent sequences of POS tags which can capture complex stylistic characteristics of male and female authors. We note that these patterns are very different from the traditional n-grams because the 207 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 207–217, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Associati</context>
<context position="4587" citStr="Argamon et al., 2007" startWordPosition="715" endWordPosition="718">echnique is a new feature selection algorithm which uses an ensemble of feature selection criteria and methods. It is well known that each individual feature selection criterion and method can be biased and tends to favor certain types of features. A combination of them should be able to capture the most useful or discriminative features. Our experimental results based on a real life blog data set collected from a large number of blog hosting sites show that the two new techniques enable classification algorithms to significantly improve the accuracy of the current stateof-the-art techniques (Argamon et al., 2007; Schler et al., 2006; Yan and Yan, 2006). We also compare with two publicly available systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006). Both systems implemented variations of the method given in (Argamon et al., 2003). Here, the improvement of our techniques is even greater. 2 Related Work There have been several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Ar</context>
<context position="6778" citStr="Argamon et al., 2007" startWordPosition="1071" endWordPosition="1075"> and may obscure classification. Feature selection is thus needed. Following the idea, this paper proposes a new ensemble feature selection method which is capable of extracting good features from different feature classes using multiple criteria. We also note some less relevant literature. For example, (Tannen, 1990) deals with gender differences in “conversational style” and in “formal written essays”, and (Gefen and Straub, 1997) reports differences in perception of males and females in the use of emails. Our new POS pattern features are related to POS n-grams used in (Koppel et al., 2002; Argamon et al., 2007), which considered POS 3-grams, 2-grams and unigrams as features. As shown in (Baayen et. al. 1996), POS n-grams are very effective in capturing the fine-grained stylistic and heavier syntactic information. In this work, we go further by finding POS sequence patterns. As discussed in the introduction, our patterns are entirely different from POS n-grams. First of all, they are of variable lengths depending on whatever lengths can catch the regularities. They also need to satisfy some constraints to ensure that they truly represent some significant regularity of male or female writings. Further</context>
<context position="12376" citStr="Argamon et al., 2007" startWordPosition="1983" endWordPosition="1986">ing with al f3 words ending with ful f4 words ending with ible f5 words ending with ic f6 words ending with ive f7 words ending with less f8 words ending with ly f9 words ending with ous f10 sorry words Table 1: Gender preferential features 3.4 Factor Analysis and Word Classes Factor or word factor analysis refers to the process of finding groups of similar words that tend to occur in similar documents. This process is referred to as meaning extraction in (Chung and Pennebaker, 2007). Word lists for twenty factors, along with suggested labels/headings (for reference) were used as features in (Argamon et al., 2007). Here we list some of those features (word 209 classes) in Table 2. For the detailed list of such word classes, the reader is referred to (Argamon et al., 2007). We also used these word classes as features in our work. In addition, we added three more new word classes implying positive, negative and emotional connotations and used them as features in our experiments. These are listed in Table 3. Factor Words Conversa-new, know, people, think, person, tell, feel, friends, talk, tion talking, mean, ask, understand, feelings, care, thinking, friend, relationship, realize, question, answer, sayin</context>
<context position="35711" citStr="Argamon et al., 2007" startWordPosition="6154" endWordPosition="6157"> 66.01 72.84 74.13 MI Boolean 72.01 78.62 79.48 MI TF 70.86 73.14 74.58 χ2 Boolean 72.90 80.71 81.52 χ2 TF 71.84 73.57 75.24 EFS Boolean 73.57 86.24 88.56 EFS TF 72.82 82.05 83.53 Table 5: Accuracies of SVM, SVM_R and NB with different feature selection methods Settings NB SVM SVM_R All features 63.01 68.84 70.03 All features, no POS patterns 60.73 65.17 66.17 POS 1,2,3-grams + EFS 71.24 82.71 83.86 POS Patterns + EFS 73.57 86.24 88.56 Table 6: Accuracies of POS n-grams and POS patterns with or without EFS (Boolean value assignment) System Accuracy (%) Gender Genie 61.69 Gender Guesser 63.78 (Argamon et al., 2007) 77.86 (Schler et al., 2006) 79.63 (Yan and Yan, 2006) 68.75 Our method 88.56 Table 7: Accuracy comparison with other systems No. of features SVM Classification with EFS SVM Regression with EFS Naïve Bayes with EFS Figure 1: Accuracy vs. no. of features using EFS 6.3 Observations and Discussions Based on the results given in the previous section, we make the following observations: • SVM regression (SVM_R) performs the best (Table 5). SVM classification (SVM) also gives good accuracies. NB did not do so well. • Table 5 also shows that our EFS feature selection method brings about 6-10% improve</context>
<context position="37979" citStr="Argamon et al., 2007" startWordPosition="6531" endWordPosition="6534"> 5 and 6, we can infer that the overall accuracy improvement using EFS and all feature classes described in Section 3 is about 15% for SVM classification and regression and 10% for NB. Also, using POS sequence patterns with EFS brings about a 5% improvement over POS n-grams (Table 6). The improvement is more pronounced for SVM based methods than NB. • Table 7 summarizes the accuracy improvement brought by our proposed techniques over the existing state-of-art systems. Our techniques have resulted in substantial (around 9%) accuracy improvement over the best of the existing systems. Note that (Argamon et al., 2007) used Logistic Regression with word classes and POS unigrams as features. (Schler et al., 2006) used Winnow classifier with function words, content word classes, and POS features. (Yan and Yan, 2006) used Naive Bayes with content words and blog-words as features. For all these systems, we used their features and ran their original classifiers and also the three classifiers in this paper and report the best results. For example, for (Argamon et al., 2007), we ran Logistic Regression and our three methods. SVM based methods always gave slightly better results. We could not run Winnow due to some</context>
</contexts>
<marker>Argamon, Koppel, Pennebaker, Schler, 2007</marker>
<rawString>Argamon, S., Koppel, M., Pennebaker, J. W., Schler, J. 2007. Mining the Blogosphere: Age, Gender and the varieties of self-expression, First Monday, 2007 - firstmonday.org</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Baayen</author>
<author>H van Halteren</author>
<author>F Tweedie</author>
</authors>
<title>Outside the cave of shadows: Using syntactic annotation to enhance authorship attribution,</title>
<date>1996</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<volume>11</volume>
<marker>Baayen, van Halteren, Tweedie, 1996</marker>
<rawString>Baayen, H., H van Halteren, F Tweedie. 1996. Outside the cave of shadows: Using syntactic annotation to enhance authorship attribution, Literary and Linguistic Computing, 11, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>P Langley</author>
</authors>
<title>Selection of relevant features and examples in machine learning.</title>
<date>1997</date>
<journal>Artificial Intelligence,</journal>
<pages>97--1</pages>
<contexts>
<context position="21365" citStr="Blum and Langley, 1997" startWordPosition="3488" endWordPosition="3491">ts complexity does not affect the final prediction, as it will be later shown that for model building and prediction, standard machine learning methods are used. 4 Ensemble Feature Selection Since all classes of features discussed in Section 3 are useful, we want to employ all of them. This results in a huge number of features. Many of 1 − n fairSCP(x1 ... xn) = n − 1 1 L 2 ) P(x1 ... xn ) )P(xi+1 ...xn P(x1 ... xi i =1 211 them are redundant and even harmful. Feature selection thus becomes important. There are two common approaches to feature selection: the filter and the wrapper approaches (Blum and Langley, 1997; Kohavi and John, 1997). In the filter approach, features are first ranked based on a feature selection criterion such as information gain, chisquare (x2) test, and mutual information. A set of top ranked features are selected. On the contrary, the wrapper model chooses features and adds to the current feature pool based on whether the new features improve the classification accuracy. Both these approaches have drawbacks. While the wrapper approach becomes very time consuming and impractical when the number of features is large as each feature is tested by building a new classifier. The filte</context>
</contexts>
<marker>Blum, Langley, 1997</marker>
<rawString>Blum, A. and Langley, P. 1997. Selection of relevant features and examples in machine learning. Artificial Intelligence, 97(1-2):245-271.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Gender Genie BookBlog</author>
</authors>
<note>Copyright 2003-2007, http://www.bookblog.net/gender/genie.html</note>
<marker>BookBlog, </marker>
<rawString>BookBlog, Gender Genie, Copyright 2003-2007, http://www.bookblog.net/gender/genie.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Borgelt</author>
</authors>
<title>Bayes Classifier Induction.</title>
<date>2003</date>
<note>http://www.borgelt.net/doc/bayes/bayes.html</note>
<contexts>
<context position="30750" citStr="Borgelt, 2003" startWordPosition="5312" endWordPosition="5313"> own POS pattern based features. For systems, we compared with two public domain systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006), which implemented variations of the algorithm in (Argamon et. al, 2003). We used SVM classification, SVM regression, and Bayes (NB) as learning algorithms. Although SVM regression is not designed for classification, it can be applied based on the output of positive or negative values. It actually worked better than SVM classification for our data. For SVM classification and regression, we used SVMLight (Joachims, 1999), and for NB we used (Borgelt, 2003). In all our experiments, we used accuracy as the evaluation measure as the two classes (male and female) are roughly balanced (see the data description below), and both classes are equally importan 6.1 Blog Data Set on the appearances of the pattern d 330 words for women. in the POS tagged document. 6 Experimental Results 6.2 Results d systems. For algorithms, P( m After selecting features belonging to different classes, values are assigned differently to different classes of features. There are three common ways of feature value assignments: Boolean, TF (Term Frequency) and TF-IDF (product o</context>
</contexts>
<marker>Borgelt, 2003</marker>
<rawString>Borgelt, C. 2003. Bayes Classifier Induction. http://www.borgelt.net/doc/bayes/bayes.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>C K Chung</author>
<author>J W Pennebaker</author>
</authors>
<title>Revealing people’s thinking in natural language: Using an automated meaning extraction method in open–ended self–descriptions,</title>
<date>2007</date>
<journal>J. of Research</journal>
<note>in Personality.</note>
<contexts>
<context position="12243" citStr="Chung and Pennebaker, 2007" startWordPosition="1962" endWordPosition="1965">ogies as used in (Corney et al., 2002). The feature value assignment will be discussed in Section 5. f1 words ending with able f2 words ending with al f3 words ending with ful f4 words ending with ible f5 words ending with ic f6 words ending with ive f7 words ending with less f8 words ending with ly f9 words ending with ous f10 sorry words Table 1: Gender preferential features 3.4 Factor Analysis and Word Classes Factor or word factor analysis refers to the process of finding groups of similar words that tend to occur in similar documents. This process is referred to as meaning extraction in (Chung and Pennebaker, 2007). Word lists for twenty factors, along with suggested labels/headings (for reference) were used as features in (Argamon et al., 2007). Here we list some of those features (word 209 classes) in Table 2. For the detailed list of such word classes, the reader is referred to (Argamon et al., 2007). We also used these word classes as features in our work. In addition, we added three more new word classes implying positive, negative and emotional connotations and used them as features in our experiments. These are listed in Table 3. Factor Words Conversa-new, know, people, think, person, tell, feel,</context>
</contexts>
<marker>Chung, Pennebaker, 2007</marker>
<rawString>Chung, C. K. and Pennebaker, J. W. 2007. Revealing people’s thinking in natural language: Using an automated meaning extraction method in open–ended self–descriptions, J. of Research in Personality.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Corney</author>
<author>O Vel</author>
<author>A Anderson</author>
<author>G Mohay</author>
</authors>
<date>2002</date>
<booktitle>Gender Preferential Text Mining of E-mail Discourse. 18th annual Computer Security Applications Conference (ACSAC),</booktitle>
<contexts>
<context position="7863" citStr="Corney et al., 2002" startWordPosition="1238" endWordPosition="1241">o need to satisfy some constraints to ensure that they truly represent some significant regularity of male or female writings. Furthermore, our POS sequence patterns can take care of n-grams and capture additional sequence regularities. These automatically mined pattern features are thus more discriminating for classification. 3 Feature Engineering and Mining There are different classes of features that have been experimented for gender classification, e.g., F-measure, stylistic features, gender preferential features, factor analysis and word classes (Nowson et al., 2005; Schler et al., 2006; Corney et al., 2002; Argamon et al., 2007). We use all these existing features and also propose a new class of features that are POS sequence patterns, which replace existing POS n-grams. Also, as mentioned before, using all feature classes gives us features with varied granularities. Upon extracting all these classes of features, a new ensemble feature selection (EFS) algorithm is proposed to select a subset of good or discriminative features. 208 since we mine all POS sequence patterns and use them as features, most discriminative POS ngrams are already covered. In Section 5, we will also show that POS n-grams</context>
<context position="10804" citStr="Corney et al., 2002" startWordPosition="1718" endWordPosition="1721">atures These are features which capture people’s writing styles. The style of writing is typically captured by three types of features: part of speech, words, and in the blog context, words such as lol, hmm, and smiley that appear with high frequency. In this work, we use words and blog words as stylistic features. Part of speech features are mined using our POS sequence pattern mining algorithm. POS n-grams can also be used as features. However, 3.3 Gender Preferential Features Gender preferential features consist of a set of signals that has been used in an email gender classification task (Corney et al., 2002). These features come from various studies that have been undertaken on the issue of gender and language use (Schiffman, 2002). It was suggested by these studies and also various other works that women’s language makes more frequent use of emotionally intensive adverbs and adjectives like “so”, “terribly”, “awfully”, “dreadfully” and women’s language is more punctuated. On the other hand, men’s conversational patterns express “independence” (Corney et al., 2002). In brief, the language expressed by males is more proactive at solving problems while the language used by females is more reactive </context>
</contexts>
<marker>Corney, Vel, Anderson, Mohay, 2002</marker>
<rawString>Corney, M., Vel, O., Anderson, A., Mohay, G. 2002. Gender Preferential Text Mining of E-mail Discourse. 18th annual Computer Security Applications Conference (ACSAC), 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dean</author>
<author>S Ghemawat</author>
</authors>
<title>Mapreduce: Simplified data processing on large clusters,</title>
<date>2004</date>
<booktitle>Operating Systems Design and Implementation,</booktitle>
<contexts>
<context position="20556" citStr="Dean and Ghemawat, 2004" startWordPosition="3346" endWordPosition="3349">of all sequence patterns (line 15) that meet the minsup and minadherence thresholds. The candidate-gen() function generates all possibly frequent k-sequences by adding each POS tag t to c as suffix. c is a k-1-sequence in Fk-1. In our experiments, we used MAX-length = 7, minsup = 30%, and minadherence = 20% to mine all POS sequence patterns. All the mined patterns are used as features. Finally, it is worthwhile to note that minePOS-pat is very similar to the well-known GSP algorithm (Srikant and Agrawal, 1996). Likewise, it has linear scale up with data size. If needed, one can use MapReduce (Dean and Ghemawat, 2004) with suitable modifications in mine-POS-pats to speed things up by distributing to multiple machines for large corpora. Moreover, mining is a part of preprocessing of the algorithm and its complexity does not affect the final prediction, as it will be later shown that for model building and prediction, standard machine learning methods are used. 4 Ensemble Feature Selection Since all classes of features discussed in Section 3 are useful, we want to employ all of them. This results in a huge number of features. Many of 1 − n fairSCP(x1 ... xn) = n − 1 1 L 2 ) P(x1 ... xn ) )P(xi+1 ...xn P(x1 .</context>
</contexts>
<marker>Dean, Ghemawat, 2004</marker>
<rawString>J. Dean and S. Ghemawat. 2004. Mapreduce: Simplified data processing on large clusters, Operating Systems Design and Implementation, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Forman</author>
</authors>
<title>An extensive empirical study of feature selection metrics for text classification.</title>
<date>2003</date>
<booktitle>JMLR, 3:1289 - 1306 ,</booktitle>
<contexts>
<context position="39360" citStr="Forman 2003" startWordPosition="6761" endWordPosition="6762">re statistically significant at the confidence level of 95%. • From Figure 1, we see that when the number of features selected is small (&lt;100) the classification accuracy is lower than that obtained by using all features (no feature selection). However, the accuracy increases rapidly as the number of selected features increases. After obtaining the best case accuracy, it roughly maintains the accuracy over a long range. The accuracies then gradually decrease with the increase in the number of features. This trend is consistent with the prior findings in (Mladenic, 1998; Rogati and Yang, 2002; Forman 2003; Riloff et al., 2006; Houvardas and Stamatatos, 2006). It is important to note here that over a long range of 2000 to 20000 features, the accuracy is high and stable. This means that the thresholds of EFS are easy to set. As long as they are in the range, the accuracy will be good. Finally, we would like to mention that (Herring and Paolillo, 06) has used genre relationships with gender classification. Their finding that subgenre “diary” contains more “female” and subgenre “filter” having more “male” stylistic features independent of the author gender, may obscure gender classification as the</context>
</contexts>
<marker>Forman, 2003</marker>
<rawString>Forman, G., 2003. An extensive empirical study of feature selection metrics for text classification. JMLR, 3:1289 - 1306 , 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Garganté</author>
<author>T E Marchiori</author>
<author>S R W Kowalczyk</author>
</authors>
<title>A Genetic Algorithm to Ensemble Feature Selection. Masters Thesis. Vrije Universiteit,</title>
<date>2007</date>
<location>Amsterdam.</location>
<contexts>
<context position="27159" citStr="Garganté et al., 2007" startWordPosition="4579" endWordPosition="4582">unter this, we use the window w to select various feature subsets close to the top ri features in �i. Thus, the threshold values ri and window size w should be approximated by experiments. In our experiments, we used ri = top 1/20th of the features ranked in �i for ∀ i and window size w = |F|/100, and got good results. Fortunately, as we will see in Section 6.2, these parameters are not sensitive at all, and any reasonably large size feature set seems to work equally well. Finally, we are aware that there are some existing ensemble feature selection methods in the machine learning literature (Garganté et al., 2007; Tuv et al., 2009). However, they are very different from our approach. They mainly use ensemble classification methods to help choose good features rather than combining different feature selection criteria and integrating different feature selection approaches as in our method. 4.2 Feature Selection Criteria The set of feature selection criteria O = {B1...Bt} used in our work are those commonly used individual selection criteria in the filter approach. Let C ={c1, c2, ..., cm} denotes the set of classes, and F = {f1, f2, ..., fn} the set of features. We list the criteria in O used in our wo</context>
</contexts>
<marker>Garganté, Marchiori, Kowalczyk, 2007</marker>
<rawString>Garganté, R. A., Marchiori, T. E., and Kowalczyk, S. R. W., 2007. A Genetic Algorithm to Ensemble Feature Selection. Masters Thesis. Vrije Universiteit, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gefen</author>
<author>D W Straub</author>
</authors>
<title>Gender differences in the perception and use of e-mail: An extension to the technology acceptance model.</title>
<date>1997</date>
<journal>MIS Quart.</journal>
<volume>21</volume>
<issue>4</issue>
<pages>389--400</pages>
<contexts>
<context position="6593" citStr="Gefen and Straub, 1997" startWordPosition="1037" endWordPosition="1040">y feature classes is very useful as they provide features with varied granularities and diversities. However, this also results in a huge number of features and many of them are redundant and may obscure classification. Feature selection is thus needed. Following the idea, this paper proposes a new ensemble feature selection method which is capable of extracting good features from different feature classes using multiple criteria. We also note some less relevant literature. For example, (Tannen, 1990) deals with gender differences in “conversational style” and in “formal written essays”, and (Gefen and Straub, 1997) reports differences in perception of males and females in the use of emails. Our new POS pattern features are related to POS n-grams used in (Koppel et al., 2002; Argamon et al., 2007), which considered POS 3-grams, 2-grams and unigrams as features. As shown in (Baayen et. al. 1996), POS n-grams are very effective in capturing the fine-grained stylistic and heavier syntactic information. In this work, we go further by finding POS sequence patterns. As discussed in the introduction, our patterns are entirely different from POS n-grams. First of all, they are of variable lengths depending on wh</context>
</contexts>
<marker>Gefen, Straub, 1997</marker>
<rawString>Gefen, D., D. W. Straub. 1997. Gender differences in the perception and use of e-mail: An extension to the technology acceptance model. MIS Quart. 21(4) 389–400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Herring</author>
<author>J C Paolillo</author>
</authors>
<title>Gender and genre variation in weblogs,</title>
<date>2006</date>
<journal>Journal of Sociolinguistics,</journal>
<volume>10</volume>
<issue>4</issue>
<pages>439--459</pages>
<marker>Herring, Paolillo, 2006</marker>
<rawString>Herring, S. C., &amp; Paolillo, J. C. 2006. Gender and genre variation in weblogs, Journal of Sociolinguistics, 10 (4), 439-459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Heylighen</author>
<author>J Dewaele</author>
</authors>
<title>Variation in the contextuality of language: an empirical measure.</title>
<date>2002</date>
<journal>Foundations of Science,</journal>
<volume>7</volume>
<pages>293--340</pages>
<contexts>
<context position="8750" citStr="Heylighen and Dewaele, 2002" startWordPosition="1383" endWordPosition="1386">rities. Upon extracting all these classes of features, a new ensemble feature selection (EFS) algorithm is proposed to select a subset of good or discriminative features. 208 since we mine all POS sequence patterns and use them as features, most discriminative POS ngrams are already covered. In Section 5, we will also show that POS n-grams do not perform as well as our POS sequence patterns. Below, we first introduce the existing features, and then present the proposed class of new pattern based features and how to discover them. 3.1 F-measure The F-measure feature was originally proposed in (Heylighen and Dewaele, 2002) and has been used in (Nowson et al., 2005) with good results. Note that F-measure here is not the F-score or Fmeasure used in text classification or information retrieval for measuring the classification or retrieval effectiveness (or accuracy). F-measure explores the notion of implicitness of text and is a unitary measure of text’s relative contextuality (implicitness), as opposed to its formality (explicitness). Contextuality and formality can be captured by certain parts of speech. A lower score of F-measure indicates contextuality, marked by greater relative use of pronouns, verbs, adverb</context>
</contexts>
<marker>Heylighen, Dewaele, 2002</marker>
<rawString>Heylighen, F., and Dewaele, J. 2002. Variation in the contextuality of language: an empirical measure. Foundations of Science, 7, 293–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Houvardas</author>
<author>E Stamatatos</author>
</authors>
<title>N-gram Feature Selection for Authorship Identification,</title>
<date>2006</date>
<booktitle>Proc. of the 12th Int. Conf. on Artificial Intelligence: Methodology, Systems, Applications,</booktitle>
<pages>77--86</pages>
<contexts>
<context position="5547" citStr="Houvardas and Stamatatos, 2006" startWordPosition="871" endWordPosition="874">een several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Argamon et al., 2007), results of dictionary based content analysis, POS unigram (Yan and Yan, 2006), and personality types (Nowson et al., 2005) to capture stylistic behavior of authors’ writings for classifying gender. (Koppel et al. 2002) also used POS n-grams together with content words on the British National Corpus (BNC). (Houvardas and Stamatatos, 2006) even applied character (rather than word or tag) n-grams to capture stylistic features for authorship classification of news articles in Reuters. However, these works use only one or a subset of the classes of features. None of them uses all features for classification learning. Given the complexity of blog posts, it makes sense to apply all classes of features jointly in order to classify genders. Moreover, having many feature classes is very useful as they provide features with varied granularities and diversities. However, this also results in a huge number of features and many of them are</context>
<context position="39414" citStr="Houvardas and Stamatatos, 2006" startWordPosition="6767" endWordPosition="6770">e confidence level of 95%. • From Figure 1, we see that when the number of features selected is small (&lt;100) the classification accuracy is lower than that obtained by using all features (no feature selection). However, the accuracy increases rapidly as the number of selected features increases. After obtaining the best case accuracy, it roughly maintains the accuracy over a long range. The accuracies then gradually decrease with the increase in the number of features. This trend is consistent with the prior findings in (Mladenic, 1998; Rogati and Yang, 2002; Forman 2003; Riloff et al., 2006; Houvardas and Stamatatos, 2006). It is important to note here that over a long range of 2000 to 20000 features, the accuracy is high and stable. This means that the thresholds of EFS are easy to set. As long as they are in the range, the accuracy will be good. Finally, we would like to mention that (Herring and Paolillo, 06) has used genre relationships with gender classification. Their finding that subgenre “diary” contains more “female” and subgenre “filter” having more “male” stylistic features independent of the author gender, may obscure gender classification as there are many factors to be considered. Herring and Paol</context>
</contexts>
<marker>Houvardas, Stamatatos, 2006</marker>
<rawString>Houvardas, J. and Stamatatos, E. 2006. N-gram Feature Selection for Authorship Identification, Proc. of the 12th Int. Conf. on Artificial Intelligence: Methodology, Systems, Applications, pp. 77-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<date>1999</date>
<booktitle>Making large-Scale SVM Learning Practical. Advances in Kernel Methods - Support Vector Learning,</booktitle>
<editor>B. Schölkopf and C. Burges and A. Smola (ed.), MIT-Press,</editor>
<contexts>
<context position="30714" citStr="Joachims, 1999" startWordPosition="5305" endWordPosition="5306">m includes all their features and our own POS pattern based features. For systems, we compared with two public domain systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006), which implemented variations of the algorithm in (Argamon et. al, 2003). We used SVM classification, SVM regression, and Bayes (NB) as learning algorithms. Although SVM regression is not designed for classification, it can be applied based on the output of positive or negative values. It actually worked better than SVM classification for our data. For SVM classification and regression, we used SVMLight (Joachims, 1999), and for NB we used (Borgelt, 2003). In all our experiments, we used accuracy as the evaluation measure as the two classes (male and female) are roughly balanced (see the data description below), and both classes are equally importan 6.1 Blog Data Set on the appearances of the pattern d 330 words for women. in the POS tagged document. 6 Experimental Results 6.2 Results d systems. For algorithms, P( m After selecting features belonging to different classes, values are assigned differently to different classes of features. There are three common ways of feature value assignments: Boolean, TF (T</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Joachims, T. 1999. Making large-Scale SVM Learning Practical. Advances in Kernel Methods - Support Vector Learning, B. Schölkopf and C. Burges and A. Smola (ed.), MIT-Press, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text categorization with support vector machines,</title>
<date>1997</date>
<tech>Technical report, LS VIII Number 23,</tech>
<institution>University of Dortmund,</institution>
<contexts>
<context position="31484" citStr="Joachims, 1997" startWordPosition="5428" endWordPosition="5429">alanced (see the data description below), and both classes are equally importan 6.1 Blog Data Set on the appearances of the pattern d 330 words for women. in the POS tagged document. 6 Experimental Results 6.2 Results d systems. For algorithms, P( m After selecting features belonging to different classes, values are assigned differently to different classes of features. There are three common ways of feature value assignments: Boolean, TF (Term Frequency) and TF-IDF (product of term and inverted document frequency). For details of feature value assignments, interested readers are referred to (Joachims, 1997). While the Boolean scheme assigns a 1 to the feature value if the feature is present in the document and a 0 otherwise, the TF scheme assigns the relative frequency of the number of times that the feature occurs in the document. We did not use TF-IDF as it did not yield good results in our preliminary experiments. The feature value assignment to different classes of features is done as follows: The value of F-measure was assigned based on its actual value. Stylistic features such words, and blog words were assigned values 1 or 0 in the Boolean scheme and the relative frequency in the TF schem</context>
</contexts>
<marker>Joachims, 1997</marker>
<rawString>Joachims, T. 1997. Text categorization with support vector machines, Technical report, LS VIII Number 23, University of Dortmund, 1997</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kohavi</author>
<author>G John</author>
</authors>
<title>Wrappers for feature subset selection.</title>
<date>1997</date>
<journal>Artificial Intelligence,</journal>
<pages>97--1</pages>
<contexts>
<context position="21389" citStr="Kohavi and John, 1997" startWordPosition="3492" endWordPosition="3495">ffect the final prediction, as it will be later shown that for model building and prediction, standard machine learning methods are used. 4 Ensemble Feature Selection Since all classes of features discussed in Section 3 are useful, we want to employ all of them. This results in a huge number of features. Many of 1 − n fairSCP(x1 ... xn) = n − 1 1 L 2 ) P(x1 ... xn ) )P(xi+1 ...xn P(x1 ... xi i =1 211 them are redundant and even harmful. Feature selection thus becomes important. There are two common approaches to feature selection: the filter and the wrapper approaches (Blum and Langley, 1997; Kohavi and John, 1997). In the filter approach, features are first ranked based on a feature selection criterion such as information gain, chisquare (x2) test, and mutual information. A set of top ranked features are selected. On the contrary, the wrapper model chooses features and adds to the current feature pool based on whether the new features improve the classification accuracy. Both these approaches have drawbacks. While the wrapper approach becomes very time consuming and impractical when the number of features is large as each feature is tested by building a new classifier. The filter approach often uses on</context>
</contexts>
<marker>Kohavi, John, 1997</marker>
<rawString>Kohavi, R. and John, G. 1997. Wrappers for feature subset selection. Artificial Intelligence, 97(1-2):273-324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Koppel</author>
<author>S Argamon</author>
<author>A R Shimoni</author>
</authors>
<title>Automatically Categorizing Written Text by Author Gender. Literary and Linguistic Computing.</title>
<date>2002</date>
<contexts>
<context position="5426" citStr="Koppel et al. 2002" startWordPosition="853" endWordPosition="856"> (Argamon et al., 2003). Here, the improvement of our techniques is even greater. 2 Related Work There have been several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Argamon et al., 2007), results of dictionary based content analysis, POS unigram (Yan and Yan, 2006), and personality types (Nowson et al., 2005) to capture stylistic behavior of authors’ writings for classifying gender. (Koppel et al. 2002) also used POS n-grams together with content words on the British National Corpus (BNC). (Houvardas and Stamatatos, 2006) even applied character (rather than word or tag) n-grams to capture stylistic features for authorship classification of news articles in Reuters. However, these works use only one or a subset of the classes of features. None of them uses all features for classification learning. Given the complexity of blog posts, it makes sense to apply all classes of features jointly in order to classify genders. Moreover, having many feature classes is very useful as they provide feature</context>
<context position="6755" citStr="Koppel et al., 2002" startWordPosition="1067" endWordPosition="1070">of them are redundant and may obscure classification. Feature selection is thus needed. Following the idea, this paper proposes a new ensemble feature selection method which is capable of extracting good features from different feature classes using multiple criteria. We also note some less relevant literature. For example, (Tannen, 1990) deals with gender differences in “conversational style” and in “formal written essays”, and (Gefen and Straub, 1997) reports differences in perception of males and females in the use of emails. Our new POS pattern features are related to POS n-grams used in (Koppel et al., 2002; Argamon et al., 2007), which considered POS 3-grams, 2-grams and unigrams as features. As shown in (Baayen et. al. 1996), POS n-grams are very effective in capturing the fine-grained stylistic and heavier syntactic information. In this work, we go further by finding POS sequence patterns. As discussed in the introduction, our patterns are entirely different from POS n-grams. First of all, they are of variable lengths depending on whatever lengths can catch the regularities. They also need to satisfy some constraints to ensure that they truly represent some significant regularity of male or f</context>
<context position="34413" citStr="Koppel et al., 2002" startWordPosition="5928" endWordPosition="5931">monly used feature selection methods on SVM classification (denoted by SVM), SVM regression (denoted by SVM_R) and the NB classifier. The results are shown in Table 5. All results were obtained through 10-fold cross validation. Also, the total number of features selected by IG, MI, χ2, and EFS were roughly the same. Thus, the improvement in accuracy brought forth by EFS was chiefly due to the combination of features selected (based on multi-criteria). To measure the accuracy improvement of using our POS patterns over common POS n-grams, we also compared our results with those from POS ngrams (Koppel et al., 2002). The comparison results are given in Table 6. Table 6 also includes results to show the overall improvement in accuracy with our two new techniques. We tested our system without any feature selection and without using the POS sequence patterns as features. The comparison results with existing algorithms and public domain systems using our reallife blog data set are tabulated in Table 7. Also, to see whether feature selection helps and how many features are optimal, we varied τ and w of the EFS algorithm and plotted the accuracy vs. no. of features. These results are shown in Figure 1. Feature</context>
</contexts>
<marker>Koppel, Argamon, Shimoni, 2002</marker>
<rawString>Koppel, M., Argamon, S., Shimoni, A. R.. 2002. Automatically Categorizing Written Text by Author Gender. Literary and Linguistic Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Krawetz</author>
</authors>
<title>Gender Guesser. Hacker Factor Solutions.</title>
<date>2006</date>
<note>http://www.hackerfactor.com/ GenderGuesser.html</note>
<contexts>
<context position="4747" citStr="Krawetz, 2006" startWordPosition="742" endWordPosition="743">n criterion and method can be biased and tends to favor certain types of features. A combination of them should be able to capture the most useful or discriminative features. Our experimental results based on a real life blog data set collected from a large number of blog hosting sites show that the two new techniques enable classification algorithms to significantly improve the accuracy of the current stateof-the-art techniques (Argamon et al., 2007; Schler et al., 2006; Yan and Yan, 2006). We also compare with two publicly available systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006). Both systems implemented variations of the method given in (Argamon et al., 2003). Here, the improvement of our techniques is even greater. 2 Related Work There have been several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Argamon et al., 2007), results of dictionary based content analysis, POS unigram (Yan and Yan, 2006), and personality types (Nowson et al., 2005) to capture styli</context>
<context position="30290" citStr="Krawetz, 2006" startWordPosition="5239" endWordPosition="5240">c and Grobelnik, 1998): 214 we compared with three representatives in (ArgaP( i)P( =∑= c f) |log 1 P(ci |f) (1 P c ( )(1 ( |)) − P c f i i WET f ( ) | i )) P( − ci 5 Feature Value Assignments Naïve t. mon et al., 2007), (Schler et al., 2006) and (Yan and Yan, 2006). Since they do not have publicly available systems, we implemented them. Each of them just uses a subset of the features used in our system. Recall our system includes all their features and our own POS pattern based features. For systems, we compared with two public domain systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006), which implemented variations of the algorithm in (Argamon et. al, 2003). We used SVM classification, SVM regression, and Bayes (NB) as learning algorithms. Although SVM regression is not designed for classification, it can be applied based on the output of positive or negative values. It actually worked better than SVM classification for our data. For SVM classification and regression, we used SVMLight (Joachims, 1999), and for NB we used (Borgelt, 2003). In all our experiments, we used accuracy as the evaluation measure as the two classes (male and female) are roughly balanced (see the data</context>
</contexts>
<marker>Krawetz, 2006</marker>
<rawString>Krawetz, N. 2006. Gender Guesser. Hacker Factor Solutions. http://www.hackerfactor.com/ GenderGuesser.html</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mladenic</author>
</authors>
<title>Feature subset selection in text learning.</title>
<date>1998</date>
<booktitle>In Proc. of ECML-98,</booktitle>
<pages>95--100</pages>
<contexts>
<context position="39324" citStr="Mladenic, 1998" startWordPosition="6755" endWordPosition="6756"> techniques are useful. All the gains are statistically significant at the confidence level of 95%. • From Figure 1, we see that when the number of features selected is small (&lt;100) the classification accuracy is lower than that obtained by using all features (no feature selection). However, the accuracy increases rapidly as the number of selected features increases. After obtaining the best case accuracy, it roughly maintains the accuracy over a long range. The accuracies then gradually decrease with the increase in the number of features. This trend is consistent with the prior findings in (Mladenic, 1998; Rogati and Yang, 2002; Forman 2003; Riloff et al., 2006; Houvardas and Stamatatos, 2006). It is important to note here that over a long range of 2000 to 20000 features, the accuracy is high and stable. This means that the thresholds of EFS are easy to set. As long as they are in the range, the accuracy will be good. Finally, we would like to mention that (Herring and Paolillo, 06) has used genre relationships with gender classification. Their finding that subgenre “diary” contains more “female” and subgenre “filter” having more “male” stylistic features independent of the author gender, may </context>
</contexts>
<marker>Mladenic, 1998</marker>
<rawString>Mladenic, D. 1998. Feature subset selection in text learning. In Proc. of ECML-98, pp. 95–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mladenic</author>
<author>D 1998 Grobelnik</author>
</authors>
<title>Feature selection for classification based on text hierarchy.</title>
<date>1998</date>
<booktitle>Proceedings of the Workshop on Learning from Text and the</booktitle>
<contexts>
<context position="29698" citStr="Mladenic and Grobelnik, 1998" startWordPosition="5120" endWordPosition="5123">: (W+Y)(X+Z)(W+ X)(Y+ Z) The scoring function generally used as the criteThe scoring function using the statistic is either the weighted average or max over all classes. In our experiments, we use the weighted average: Cross Entropy (CE): This metric is similar to mutual information (Mladenic an χ2 �2(f) = ∑= m P c i f c i ( ) χ 2 ( , ) i 1 d Grobelnik, 2 N WZ YX ( − ) ∑ IG ( ) f = − P( i = 1 MI(f , c ) =∑∑ P f c ( , ) 2 c = , ) χ f ( 213 1998): m CE(f) = P(f) ∑= i 1 P(ci |� log P f ( ) ci | Weight of Evidence for Text (WET): This criterion is based on the average absolute weight of evidence (Mladenic and Grobelnik, 1998): 214 we compared with three representatives in (ArgaP( i)P( =∑= c f) |log 1 P(ci |f) (1 P c ( )(1 ( |)) − P c f i i WET f ( ) | i )) P( − ci 5 Feature Value Assignments Naïve t. mon et al., 2007), (Schler et al., 2006) and (Yan and Yan, 2006). Since they do not have publicly available systems, we implemented them. Each of them just uses a subset of the features used in our system. Recall our system includes all their features and our own POS pattern based features. For systems, we compared with two public domain systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006), which </context>
</contexts>
<marker>Mladenic, Grobelnik, 1998</marker>
<rawString>Mladenic, D. and Grobelnik, D.1998. Feature selection for classification based on text hierarchy. Proceedings of the Workshop on Learning from Text and the Web, 1998</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nowson</author>
<author>J Oberlander</author>
<author>A J Gill</author>
</authors>
<title>Gender, Genres, and Individual Differences.</title>
<date>2005</date>
<booktitle>In Proceedings of the 27th annual meeting of the Cognitive Science Society (p. 1666–1671). Stresa,</booktitle>
<location>Italy.</location>
<contexts>
<context position="5065" citStr="Nowson et al., 2005" startWordPosition="795" endWordPosition="799">hniques enable classification algorithms to significantly improve the accuracy of the current stateof-the-art techniques (Argamon et al., 2007; Schler et al., 2006; Yan and Yan, 2006). We also compare with two publicly available systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006). Both systems implemented variations of the method given in (Argamon et al., 2003). Here, the improvement of our techniques is even greater. 2 Related Work There have been several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Argamon et al., 2007), results of dictionary based content analysis, POS unigram (Yan and Yan, 2006), and personality types (Nowson et al., 2005) to capture stylistic behavior of authors’ writings for classifying gender. (Koppel et al. 2002) also used POS n-grams together with content words on the British National Corpus (BNC). (Houvardas and Stamatatos, 2006) even applied character (rather than word or tag) n-grams to capture stylistic features for authorship classification </context>
<context position="7821" citStr="Nowson et al., 2005" startWordPosition="1229" endWordPosition="1233">ngths can catch the regularities. They also need to satisfy some constraints to ensure that they truly represent some significant regularity of male or female writings. Furthermore, our POS sequence patterns can take care of n-grams and capture additional sequence regularities. These automatically mined pattern features are thus more discriminating for classification. 3 Feature Engineering and Mining There are different classes of features that have been experimented for gender classification, e.g., F-measure, stylistic features, gender preferential features, factor analysis and word classes (Nowson et al., 2005; Schler et al., 2006; Corney et al., 2002; Argamon et al., 2007). We use all these existing features and also propose a new class of features that are POS sequence patterns, which replace existing POS n-grams. Also, as mentioned before, using all feature classes gives us features with varied granularities. Upon extracting all these classes of features, a new ensemble feature selection (EFS) algorithm is proposed to select a subset of good or discriminative features. 208 since we mine all POS sequence patterns and use them as features, most discriminative POS ngrams are already covered. In Sec</context>
<context position="10073" citStr="Nowson et al., 2005" startWordPosition="1595" endWordPosition="1598">ns, adjectives, prepositions, and articles. F-measure is defined based on the frequency of the POS usage in a text (freq.x below means the frequency of the part-of-speech x): F = 0.5 * [(freq.noun + freq.adj + freq.prep + freq.art) – (freq.pron + freq.verb + freq.adv + freq.int) + 100] (Heylighen and Dewaele, 2002) applied the Fmeasure to a corpus with known author genders and found a distinct difference between the sexes. Females scored lower preferring a more contextual style while males scored higher preferring a more formal style. F-measure values for male and female writings reported in (Nowson et al., 2005) also demonstrated a similar trend. In our work, we also use F-measure as one of the features. 3.2 Stylistic Features These are features which capture people’s writing styles. The style of writing is typically captured by three types of features: part of speech, words, and in the blog context, words such as lol, hmm, and smiley that appear with high frequency. In this work, we use words and blog words as stylistic features. Part of speech features are mined using our POS sequence pattern mining algorithm. POS n-grams can also be used as features. However, 3.3 Gender Preferential Features Gende</context>
</contexts>
<marker>Nowson, Oberlander, Gill, 2005</marker>
<rawString>Nowson, S., Oberlander J., Gill, A. J., 2005. Gender, Genres, and Individual Differences. In Proceedings of the 27th annual meeting of the Cognitive Science Society (p. 1666–1671). Stresa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>S Patwardhan</author>
<author>J Wiebe</author>
</authors>
<title>Feature Subsumption for opinion Analysis.</title>
<date>2006</date>
<publisher>EMNLP,</publisher>
<contexts>
<context position="39381" citStr="Riloff et al., 2006" startWordPosition="6763" endWordPosition="6766">lly significant at the confidence level of 95%. • From Figure 1, we see that when the number of features selected is small (&lt;100) the classification accuracy is lower than that obtained by using all features (no feature selection). However, the accuracy increases rapidly as the number of selected features increases. After obtaining the best case accuracy, it roughly maintains the accuracy over a long range. The accuracies then gradually decrease with the increase in the number of features. This trend is consistent with the prior findings in (Mladenic, 1998; Rogati and Yang, 2002; Forman 2003; Riloff et al., 2006; Houvardas and Stamatatos, 2006). It is important to note here that over a long range of 2000 to 20000 features, the accuracy is high and stable. This means that the thresholds of EFS are easy to set. As long as they are in the range, the accuracy will be good. Finally, we would like to mention that (Herring and Paolillo, 06) has used genre relationships with gender classification. Their finding that subgenre “diary” contains more “female” and subgenre “filter” having more “male” stylistic features independent of the author gender, may obscure gender classification as there are many factors t</context>
</contexts>
<marker>Riloff, Patwardhan, Wiebe, 2006</marker>
<rawString>Riloff, E., Patwardhan, S., Wiebe, J.. 2006. Feature Subsumption for opinion Analysis. EMNLP,</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rogati</author>
<author>Y 2002 Yang</author>
</authors>
<title>High performing and scalable feature selection for text classification.</title>
<date>2002</date>
<booktitle>In CIKM,</booktitle>
<pages>659--661</pages>
<contexts>
<context position="39347" citStr="Rogati and Yang, 2002" startWordPosition="6757" endWordPosition="6760">useful. All the gains are statistically significant at the confidence level of 95%. • From Figure 1, we see that when the number of features selected is small (&lt;100) the classification accuracy is lower than that obtained by using all features (no feature selection). However, the accuracy increases rapidly as the number of selected features increases. After obtaining the best case accuracy, it roughly maintains the accuracy over a long range. The accuracies then gradually decrease with the increase in the number of features. This trend is consistent with the prior findings in (Mladenic, 1998; Rogati and Yang, 2002; Forman 2003; Riloff et al., 2006; Houvardas and Stamatatos, 2006). It is important to note here that over a long range of 2000 to 20000 features, the accuracy is high and stable. This means that the thresholds of EFS are easy to set. As long as they are in the range, the accuracy will be good. Finally, we would like to mention that (Herring and Paolillo, 06) has used genre relationships with gender classification. Their finding that subgenre “diary” contains more “female” and subgenre “filter” having more “male” stylistic features independent of the author gender, may obscure gender classifi</context>
</contexts>
<marker>Rogati, Yang, 2002</marker>
<rawString>Rogati, M. and Yang, Y.2002. High performing and scalable feature selection for text classification. In CIKM, pp. 659-661, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schiffman</author>
</authors>
<title>Bibliography of Gender and Language.</title>
<date>2002</date>
<note>http://ccat.sas.upenn.edu/~haroldfs/ popcult/bibliogs/gender/genbib.htm</note>
<contexts>
<context position="10930" citStr="Schiffman, 2002" startWordPosition="1741" endWordPosition="1742">ures: part of speech, words, and in the blog context, words such as lol, hmm, and smiley that appear with high frequency. In this work, we use words and blog words as stylistic features. Part of speech features are mined using our POS sequence pattern mining algorithm. POS n-grams can also be used as features. However, 3.3 Gender Preferential Features Gender preferential features consist of a set of signals that has been used in an email gender classification task (Corney et al., 2002). These features come from various studies that have been undertaken on the issue of gender and language use (Schiffman, 2002). It was suggested by these studies and also various other works that women’s language makes more frequent use of emotionally intensive adverbs and adjectives like “so”, “terribly”, “awfully”, “dreadfully” and women’s language is more punctuated. On the other hand, men’s conversational patterns express “independence” (Corney et al., 2002). In brief, the language expressed by males is more proactive at solving problems while the language used by females is more reactive to the contribution of others - agreeing, understanding and supporting. We used the gender preferential features listed in Tab</context>
</contexts>
<marker>Schiffman, 2002</marker>
<rawString>Schiffman, H. 2002. Bibliography of Gender and Language. http://ccat.sas.upenn.edu/~haroldfs/ popcult/bibliogs/gender/genbib.htm</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schler</author>
<author>M Koppel</author>
<author>S Argamon</author>
<author>J Pennebaker</author>
</authors>
<title>Effects of age and gender on blogging,</title>
<date>2006</date>
<booktitle>In Proc. of the AAAI Spring Symposium Computational Approaches to Analyzing Weblogs.</booktitle>
<contexts>
<context position="3129" citStr="Schler et al., 2006" startWordPosition="478" endWordPosition="481">, blog posts are typically short and unstructured, and consist of mostly informal sentences, which can contain spurious information and are full of grammar errors, abbreviations, slang words and phrases, and wrong spellings. Due to these reasons, gender classification of blog posts is a harder problem than gender classification of traditional formal text. Recent work has also attempted gender classification of blog authors using features such as content words, dictionary based content analysis results, POS (part-of-speech) tags and feature selection along with a supervised learning algorithm (Schler et al., 2006; Argamon et al., 2007; Yan and Yan, 2006). This paper improves these existing methods by proposing two novel techniques. The first technique adds a new class of pattern based features to learning, which are not used in any existing work. The patterns are frequent sequences of POS tags which can capture complex stylistic characteristics of male and female authors. We note that these patterns are very different from the traditional n-grams because the 207 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 207–217, MIT, Massachusetts, USA, 9-11 October </context>
<context position="4608" citStr="Schler et al., 2006" startWordPosition="719" endWordPosition="722">ure selection algorithm which uses an ensemble of feature selection criteria and methods. It is well known that each individual feature selection criterion and method can be biased and tends to favor certain types of features. A combination of them should be able to capture the most useful or discriminative features. Our experimental results based on a real life blog data set collected from a large number of blog hosting sites show that the two new techniques enable classification algorithms to significantly improve the accuracy of the current stateof-the-art techniques (Argamon et al., 2007; Schler et al., 2006; Yan and Yan, 2006). We also compare with two publicly available systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006). Both systems implemented variations of the method given in (Argamon et al., 2003). Here, the improvement of our techniques is even greater. 2 Related Work There have been several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Argamon et al., 2007), </context>
<context position="7842" citStr="Schler et al., 2006" startWordPosition="1234" endWordPosition="1237">egularities. They also need to satisfy some constraints to ensure that they truly represent some significant regularity of male or female writings. Furthermore, our POS sequence patterns can take care of n-grams and capture additional sequence regularities. These automatically mined pattern features are thus more discriminating for classification. 3 Feature Engineering and Mining There are different classes of features that have been experimented for gender classification, e.g., F-measure, stylistic features, gender preferential features, factor analysis and word classes (Nowson et al., 2005; Schler et al., 2006; Corney et al., 2002; Argamon et al., 2007). We use all these existing features and also propose a new class of features that are POS sequence patterns, which replace existing POS n-grams. Also, as mentioned before, using all feature classes gives us features with varied granularities. Upon extracting all these classes of features, a new ensemble feature selection (EFS) algorithm is proposed to select a subset of good or discriminative features. 208 since we mine all POS sequence patterns and use them as features, most discriminative POS ngrams are already covered. In Section 5, we will also </context>
<context position="29917" citStr="Schler et al., 2006" startWordPosition="5174" endWordPosition="5177">ropy (CE): This metric is similar to mutual information (Mladenic an χ2 �2(f) = ∑= m P c i f c i ( ) χ 2 ( , ) i 1 d Grobelnik, 2 N WZ YX ( − ) ∑ IG ( ) f = − P( i = 1 MI(f , c ) =∑∑ P f c ( , ) 2 c = , ) χ f ( 213 1998): m CE(f) = P(f) ∑= i 1 P(ci |� log P f ( ) ci | Weight of Evidence for Text (WET): This criterion is based on the average absolute weight of evidence (Mladenic and Grobelnik, 1998): 214 we compared with three representatives in (ArgaP( i)P( =∑= c f) |log 1 P(ci |f) (1 P c ( )(1 ( |)) − P c f i i WET f ( ) | i )) P( − ci 5 Feature Value Assignments Naïve t. mon et al., 2007), (Schler et al., 2006) and (Yan and Yan, 2006). Since they do not have publicly available systems, we implemented them. Each of them just uses a subset of the features used in our system. Recall our system includes all their features and our own POS pattern based features. For systems, we compared with two public domain systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006), which implemented variations of the algorithm in (Argamon et. al, 2003). We used SVM classification, SVM regression, and Bayes (NB) as learning algorithms. Although SVM regression is not designed for classification, it can be</context>
<context position="35739" citStr="Schler et al., 2006" startWordPosition="6159" endWordPosition="6162"> 72.01 78.62 79.48 MI TF 70.86 73.14 74.58 χ2 Boolean 72.90 80.71 81.52 χ2 TF 71.84 73.57 75.24 EFS Boolean 73.57 86.24 88.56 EFS TF 72.82 82.05 83.53 Table 5: Accuracies of SVM, SVM_R and NB with different feature selection methods Settings NB SVM SVM_R All features 63.01 68.84 70.03 All features, no POS patterns 60.73 65.17 66.17 POS 1,2,3-grams + EFS 71.24 82.71 83.86 POS Patterns + EFS 73.57 86.24 88.56 Table 6: Accuracies of POS n-grams and POS patterns with or without EFS (Boolean value assignment) System Accuracy (%) Gender Genie 61.69 Gender Guesser 63.78 (Argamon et al., 2007) 77.86 (Schler et al., 2006) 79.63 (Yan and Yan, 2006) 68.75 Our method 88.56 Table 7: Accuracy comparison with other systems No. of features SVM Classification with EFS SVM Regression with EFS Naïve Bayes with EFS Figure 1: Accuracy vs. no. of features using EFS 6.3 Observations and Discussions Based on the results given in the previous section, we make the following observations: • SVM regression (SVM_R) performs the best (Table 5). SVM classification (SVM) also gives good accuracies. NB did not do so well. • Table 5 also shows that our EFS feature selection method brings about 6-10% improvement in accuracy over the ot</context>
<context position="38074" citStr="Schler et al., 2006" startWordPosition="6546" endWordPosition="6549">escribed in Section 3 is about 15% for SVM classification and regression and 10% for NB. Also, using POS sequence patterns with EFS brings about a 5% improvement over POS n-grams (Table 6). The improvement is more pronounced for SVM based methods than NB. • Table 7 summarizes the accuracy improvement brought by our proposed techniques over the existing state-of-art systems. Our techniques have resulted in substantial (around 9%) accuracy improvement over the best of the existing systems. Note that (Argamon et al., 2007) used Logistic Regression with word classes and POS unigrams as features. (Schler et al., 2006) used Winnow classifier with function words, content word classes, and POS features. (Yan and Yan, 2006) used Naive Bayes with content words and blog-words as features. For all these systems, we used their features and ran their original classifiers and also the three classifiers in this paper and report the best results. For example, for (Argamon et al., 2007), we ran Logistic Regression and our three methods. SVM based methods always gave slightly better results. We could not run Winnow due to some technical issues. SVM and SVM_R gave comparable results to those given in their original paper</context>
</contexts>
<marker>Schler, Koppel, Argamon, Pennebaker, 2006</marker>
<rawString>Schler, J., Koppel, M., Argamon, S, and Pennebaker J. 2006. Effects of age and gender on blogging, In Proc. of the AAAI Spring Symposium Computational Approaches to Analyzing Weblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Silva</author>
<author>F Dias</author>
<author>S Guillore</author>
<author>G Lopes</author>
</authors>
<title>Using LocalMaxs Algortihm for the Extraction of Contiguous and Noncontiguous Multiword Lexical Units.</title>
<date>1999</date>
<booktitle>Lecture Notes in AI 1695,</booktitle>
<publisher>Springer</publisher>
<contexts>
<context position="16672" citStr="Silva et al., 1999" startWordPosition="2599" endWordPosition="2602">d minimum adherence (minadherence) thresholds or constraints. These thresholds ensure that the mined patterns represent significant regularities. The main idea of the algorithm is to perform a level-wise search for such patterns, which are POS sequences with minsup and minadherence. The support of a pattern is simply the proportion of documents that contain the pattern. If a pattern appears too few times, it is probably spurious. A sequence is called a frequent sequence if it satisfies minsup. The adherence of a pattern is measured using the symmetrical conditional probability (SCP) given in (Silva et al., 1999). The SCP of a sequence with two elements |xy |is the product of the conditional probability of each given the other, SCP x y = P x y P y x = ( , ) ( |) ( |) Given a consecutive sequence of POS tags |x1...xn|, called a POS sequence of length n, a dispersion point defines two subparts of the sequence. A sequence of length n contains n-1 possible dispersion points. The SCP of the sequence |x1...xn |given the dispersion point (denoted by *) |x1...xn-1*xn |is: SCP x x x (( ... ), ) 1 n− 1 n The SCP measure can be extended so that all possible dispersion points are accounted for. 2 P x y ( , ) P ( </context>
</contexts>
<marker>Silva, Dias, Guillore, Lopes, 1999</marker>
<rawString>Silva, J., Dias, F., Guillore, S., Lopes, G. 1999. Using LocalMaxs Algortihm for the Extraction of Contiguous and Noncontiguous Multiword Lexical Units. Springer Lecture Notes in AI 1695, 1999</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Srikant</author>
<author>R Agrawal</author>
</authors>
<title>Mining sequential patterns: Generalizations and performance improvements,</title>
<date>1996</date>
<booktitle>In Proc. 5th Int. Conf. Extending Database Technology (EDBT’96),</booktitle>
<location>Avignon, France.</location>
<contexts>
<context position="20447" citStr="Srikant and Agrawal, 1996" startWordPosition="3327" endWordPosition="3330">e adherence does not have the downward closure property as the support. Finally, the algorithm returns the set of all sequence patterns (line 15) that meet the minsup and minadherence thresholds. The candidate-gen() function generates all possibly frequent k-sequences by adding each POS tag t to c as suffix. c is a k-1-sequence in Fk-1. In our experiments, we used MAX-length = 7, minsup = 30%, and minadherence = 20% to mine all POS sequence patterns. All the mined patterns are used as features. Finally, it is worthwhile to note that minePOS-pat is very similar to the well-known GSP algorithm (Srikant and Agrawal, 1996). Likewise, it has linear scale up with data size. If needed, one can use MapReduce (Dean and Ghemawat, 2004) with suitable modifications in mine-POS-pats to speed things up by distributing to multiple machines for large corpora. Moreover, mining is a part of preprocessing of the algorithm and its complexity does not affect the final prediction, as it will be later shown that for model building and prediction, standard machine learning methods are used. 4 Ensemble Feature Selection Since all classes of features discussed in Section 3 are useful, we want to employ all of them. This results in a</context>
</contexts>
<marker>Srikant, Agrawal, 1996</marker>
<rawString>Srikant, R. and Agrawal, R. 1996. Mining sequential patterns: Generalizations and performance improvements, In Proc. 5th Int. Conf. Extending Database Technology (EDBT’96), Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tannen</author>
</authors>
<title>You just don’t understand,</title>
<date>1990</date>
<location>New York: Ballantine.</location>
<contexts>
<context position="6476" citStr="Tannen, 1990" startWordPosition="1021" endWordPosition="1022"> it makes sense to apply all classes of features jointly in order to classify genders. Moreover, having many feature classes is very useful as they provide features with varied granularities and diversities. However, this also results in a huge number of features and many of them are redundant and may obscure classification. Feature selection is thus needed. Following the idea, this paper proposes a new ensemble feature selection method which is capable of extracting good features from different feature classes using multiple criteria. We also note some less relevant literature. For example, (Tannen, 1990) deals with gender differences in “conversational style” and in “formal written essays”, and (Gefen and Straub, 1997) reports differences in perception of males and females in the use of emails. Our new POS pattern features are related to POS n-grams used in (Koppel et al., 2002; Argamon et al., 2007), which considered POS 3-grams, 2-grams and unigrams as features. As shown in (Baayen et. al. 1996), POS n-grams are very effective in capturing the fine-grained stylistic and heavier syntactic information. In this work, we go further by finding POS sequence patterns. As discussed in the introduct</context>
</contexts>
<marker>Tannen, 1990</marker>
<rawString>Tannen, D. (1990). You just don’t understand, New York: Ballantine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>J Tsujii</author>
</authors>
<title>Bidirectional Inference with the Easiest-First Strategy for Tagging Sequence Data,</title>
<date>2005</date>
<pages>467--474</pages>
<location>HLT/EMNLP</location>
<contexts>
<context position="15584" citStr="Tsuruoka and Tsujii, 2005" startWordPosition="2422" endWordPosition="2425">ed, hurt, hysterical, innocent, interested, jealous, lonely, mischievous, miserable, optimistic, paranoid, peaceful, proud, puzzled, regretful, relieved, sad, satisfied, shocked, shy, sorry, surprised, suspicious, thoughtful, undecided, withdrawn Table 3: Words implying positive, negative and emotional connotations 3.5 Proposed POS Sequence Pattern Features We now present the proposed POS sequence pattern features and the mining algorithm. This results in a new feature class. A POS sequence pattern is a sequence of consecutive POS tags that satisfy some constraints (discussed below). We used (Tsuruoka and Tsujii, 2005) as our POS tagger. As shown in (Baayen et. al., 1996), POS ngrams are good at capturing the heavy stylistic and syntactic information. Instead of using all such n-grams, we want to discover all those patterns that represent true regularities, and we also want to have flexible lengths (not fixed lengths as in n-grams). POS sequence patterns serve these purposes. Its mining algorithm mines all such patterns that satisfy the user-specified minimum support (minsup) and minimum adherence (minadherence) thresholds or constraints. These thresholds ensure that the mined patterns represent significant</context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Tsuruoka, Y. and Tsujii, J. 2005. Bidirectional Inference with the Easiest-First Strategy for Tagging Sequence Data, HLT/EMNLP 2005, pp. 467-474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Tuv</author>
<author>A Borisov</author>
<author>G Runger</author>
<author>K Torkkola</author>
</authors>
<title>Feature selection with ensembles, artificial variables, and redundancy elimination.</title>
<date>2009</date>
<journal>JMLR,</journal>
<volume>10</volume>
<contexts>
<context position="27178" citStr="Tuv et al., 2009" startWordPosition="4583" endWordPosition="4586">window w to select various feature subsets close to the top ri features in �i. Thus, the threshold values ri and window size w should be approximated by experiments. In our experiments, we used ri = top 1/20th of the features ranked in �i for ∀ i and window size w = |F|/100, and got good results. Fortunately, as we will see in Section 6.2, these parameters are not sensitive at all, and any reasonably large size feature set seems to work equally well. Finally, we are aware that there are some existing ensemble feature selection methods in the machine learning literature (Garganté et al., 2007; Tuv et al., 2009). However, they are very different from our approach. They mainly use ensemble classification methods to help choose good features rather than combining different feature selection criteria and integrating different feature selection approaches as in our method. 4.2 Feature Selection Criteria The set of feature selection criteria O = {B1...Bt} used in our work are those commonly used individual selection criteria in the filter approach. Let C ={c1, c2, ..., cm} denotes the set of classes, and F = {f1, f2, ..., fn} the set of features. We list the criteria in O used in our work below. Informati</context>
</contexts>
<marker>Tuv, Borisov, Runger, Torkkola, 2009</marker>
<rawString>Tuv, E., Borisov, A., Runger, G., and Torkkola, K. 2009. Feature selection with ensembles, artificial variables, and redundancy elimination. JMLR, 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Yan</author>
<author>L Yan</author>
</authors>
<title>Gender Classification of Weblog Authors. Computational Approaches to Analyzing Weblogs,</title>
<date>2006</date>
<publisher>AAAI.</publisher>
<contexts>
<context position="3171" citStr="Yan and Yan, 2006" startWordPosition="486" endWordPosition="489">ctured, and consist of mostly informal sentences, which can contain spurious information and are full of grammar errors, abbreviations, slang words and phrases, and wrong spellings. Due to these reasons, gender classification of blog posts is a harder problem than gender classification of traditional formal text. Recent work has also attempted gender classification of blog authors using features such as content words, dictionary based content analysis results, POS (part-of-speech) tags and feature selection along with a supervised learning algorithm (Schler et al., 2006; Argamon et al., 2007; Yan and Yan, 2006). This paper improves these existing methods by proposing two novel techniques. The first technique adds a new class of pattern based features to learning, which are not used in any existing work. The patterns are frequent sequences of POS tags which can capture complex stylistic characteristics of male and female authors. We note that these patterns are very different from the traditional n-grams because the 207 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 207–217, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational</context>
<context position="4628" citStr="Yan and Yan, 2006" startWordPosition="723" endWordPosition="726">hm which uses an ensemble of feature selection criteria and methods. It is well known that each individual feature selection criterion and method can be biased and tends to favor certain types of features. A combination of them should be able to capture the most useful or discriminative features. Our experimental results based on a real life blog data set collected from a large number of blog hosting sites show that the two new techniques enable classification algorithms to significantly improve the accuracy of the current stateof-the-art techniques (Argamon et al., 2007; Schler et al., 2006; Yan and Yan, 2006). We also compare with two publicly available systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006). Both systems implemented variations of the method given in (Argamon et al., 2003). Here, the improvement of our techniques is even greater. 2 Related Work There have been several recent papers on gender classification of blogs (e.g., Schler et al., 2006, Argamon et al., 2007; Yan and Yan, 2006; Nowson et al., 2005). These systems use function/content words, POS tag features, word classes (Schler et al., 2006), content word classes (Argamon et al., 2007), results of dictionar</context>
<context position="29941" citStr="Yan and Yan, 2006" startWordPosition="5179" endWordPosition="5182">similar to mutual information (Mladenic an χ2 �2(f) = ∑= m P c i f c i ( ) χ 2 ( , ) i 1 d Grobelnik, 2 N WZ YX ( − ) ∑ IG ( ) f = − P( i = 1 MI(f , c ) =∑∑ P f c ( , ) 2 c = , ) χ f ( 213 1998): m CE(f) = P(f) ∑= i 1 P(ci |� log P f ( ) ci | Weight of Evidence for Text (WET): This criterion is based on the average absolute weight of evidence (Mladenic and Grobelnik, 1998): 214 we compared with three representatives in (ArgaP( i)P( =∑= c f) |log 1 P(ci |f) (1 P c ( )(1 ( |)) − P c f i i WET f ( ) | i )) P( − ci 5 Feature Value Assignments Naïve t. mon et al., 2007), (Schler et al., 2006) and (Yan and Yan, 2006). Since they do not have publicly available systems, we implemented them. Each of them just uses a subset of the features used in our system. Recall our system includes all their features and our own POS pattern based features. For systems, we compared with two public domain systems, Gender Genie (BookBlog, 2007) and Gender Guesser (Krawetz, 2006), which implemented variations of the algorithm in (Argamon et. al, 2003). We used SVM classification, SVM regression, and Bayes (NB) as learning algorithms. Although SVM regression is not designed for classification, it can be applied based on the ou</context>
<context position="35765" citStr="Yan and Yan, 2006" startWordPosition="6164" endWordPosition="6167">86 73.14 74.58 χ2 Boolean 72.90 80.71 81.52 χ2 TF 71.84 73.57 75.24 EFS Boolean 73.57 86.24 88.56 EFS TF 72.82 82.05 83.53 Table 5: Accuracies of SVM, SVM_R and NB with different feature selection methods Settings NB SVM SVM_R All features 63.01 68.84 70.03 All features, no POS patterns 60.73 65.17 66.17 POS 1,2,3-grams + EFS 71.24 82.71 83.86 POS Patterns + EFS 73.57 86.24 88.56 Table 6: Accuracies of POS n-grams and POS patterns with or without EFS (Boolean value assignment) System Accuracy (%) Gender Genie 61.69 Gender Guesser 63.78 (Argamon et al., 2007) 77.86 (Schler et al., 2006) 79.63 (Yan and Yan, 2006) 68.75 Our method 88.56 Table 7: Accuracy comparison with other systems No. of features SVM Classification with EFS SVM Regression with EFS Naïve Bayes with EFS Figure 1: Accuracy vs. no. of features using EFS 6.3 Observations and Discussions Based on the results given in the previous section, we make the following observations: • SVM regression (SVM_R) performs the best (Table 5). SVM classification (SVM) also gives good accuracies. NB did not do so well. • Table 5 also shows that our EFS feature selection method brings about 6-10% improvement in accuracy over the other feature selection meth</context>
<context position="38178" citStr="Yan and Yan, 2006" startWordPosition="6562" endWordPosition="6565">equence patterns with EFS brings about a 5% improvement over POS n-grams (Table 6). The improvement is more pronounced for SVM based methods than NB. • Table 7 summarizes the accuracy improvement brought by our proposed techniques over the existing state-of-art systems. Our techniques have resulted in substantial (around 9%) accuracy improvement over the best of the existing systems. Note that (Argamon et al., 2007) used Logistic Regression with word classes and POS unigrams as features. (Schler et al., 2006) used Winnow classifier with function words, content word classes, and POS features. (Yan and Yan, 2006) used Naive Bayes with content words and blog-words as features. For all these systems, we used their features and ran their original classifiers and also the three classifiers in this paper and report the best results. For example, for (Argamon et al., 2007), we ran Logistic Regression and our three methods. SVM based methods always gave slightly better results. We could not run Winnow due to some technical issues. SVM and SVM_R gave comparable results to those given in their original papers. These results again show that our techniques are useful. All the gains are statistically significant </context>
</contexts>
<marker>Yan, Yan, 2006</marker>
<rawString>Yan, X., Yan, L. 2006. Gender Classification of Weblog Authors. Computational Approaches to Analyzing Weblogs, AAAI.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>