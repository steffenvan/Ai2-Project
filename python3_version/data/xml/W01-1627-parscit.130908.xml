<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001502">
<title confidence="0.989059">
Dialogue tagsets in oncology
</title>
<author confidence="0.999055">
Mary McGee Wood
</author>
<affiliation confidence="0.9979045">
Department of Computer Science
University of Manchester
</affiliation>
<address confidence="0.963637">
Manchester M13 9PL U.K.
</address>
<email confidence="0.998681">
mary@cs.man.ac.uk
</email>
<sectionHeader confidence="0.980074" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999758083333333">
Dialogue analysis is widely used in oncol-
ogy for training health professionals in
communication skills. Parameters and
tagsets have been developed indepen-
dently of work in natural language pro-
cessing. In relation to emergent stan-
dards in NLP, syntactic tagging is mini-
mal, semantics is domain-specific, prag-
matics is comparable, and the analysis of
cognitive affect is richly developed. We
suggest productive directions for conver-
gence.
</bodyText>
<sectionHeader confidence="0.977128" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.999819372093024">
Dialogue analysis systems have been developed
in oncology as a tool for assessing and improv-
ing the communication skills of health profession-
als. Rates of psychiatric morbidity (clinical anxi-
ety and depression) in cancer patients are lowered
when health professionals have adequate commu-
nication skills to discover and address the patients’
concerns and worries. Health professionals inter-
viewing patients sometimes exhibit negative be-
haviours, such as “blocking” a certain line of in-
vestigation rather than encouraging the patient
to describe his or her problem. On the other
hand, a skilled interviewer uses active interven-
tions to direct the progress of the interview, as
well as more passive responses. Several oncology
research groups have demonstrated that these pat-
terns can be detected and quantified through anal-
ysis of conversations between health professionals
and patients. This in turn can form a basis for
more effective training in communication skills.
The Psychological Medicine Group at Manch-
ester (PMG), funded by the Cancer Research
Campaign (CRC), is a leading group in dialogue
analysis in oncology. This paper describes the
parameters and tagsets (analogous to “Dialogue
Act” tagging (Stolcke et al 2000)), which they and
three other groups have developed for this highly
specialised domain.
This domain offers an interesting contrast to the
“instructional” or “service” dialogues commonly
studied. The health professional is the “expert” in
the conventional sense, and at times conveys med-
ical information to the less knowledgeable patient
in a conventional way. At other times, the patient
should be seen as the “expert” with regard to his
or her own perceived physical and mental condi-
tion, and the task of the health professional is ef-
fectively that of “knowledge elicitation” as under-
stood in expert systems development. This flexi-
ble and dynamic shifting of participants’ roles in a
dialogue poses an interesting challenge, compared
to the clearly defined and static roles assumed in
much work in dialogue analysis.
</bodyText>
<sectionHeader confidence="0.944455" genericHeader="introduction">
2 Parameters for dialogue tagging
</sectionHeader>
<bodyText confidence="0.999882461538462">
Complete and accurate tagging of dialogue must
encode a number of independent aspects of each
utterance. These are represented as “layers”
in the DAMSL system (Core &amp; Allen 1997).
Form-based tags (question, statement) are sup-
plemented with diacritics indicating other types
of information, such as task-management or
communication-management.
The four oncology dialogue tagging systems
considered here all share this basic principle, al-
though they differ in the specifics. Butow et
al (1995:1115) cite the recognition as early as
1983 of “layers of meaning ... such as the con-
tent, the process, the emotion and the purpose”.
Their own CN-LOGIT system encodes three “di-
mensions”: “source” (who is speaking), “process”
(questions, responses, initiated statements), and
“content”. A complete dialogue can be mapped
into a three-dimensional information space, and
measures can be applied such as how much time
was spent in each cell of the cube. Ong et al
(1998) use the Roter Interaction Analysis Sys-
tem (RIAS). Each utterance in a dialogue is cat-
egorised, and also rated on five distinct “global
affect” scales. The Medical Interaction Process
System (MIPS) of Ford et al (2000) also stresses
the multi-dimensional nature of dialogue annota-
tion, using fifteen “content codes” and eight “af-
fective modes”. PMG (Maguire &amp; Faulkner 1988;
Maguire p.c.) have separate tagsets for Form,
Function, Content, Level, Cue, Cue Management,
Blocking, and Focus.
One can see an implicit consensus here that (to
use NLP terms) syntactic form, overt semantic
content, pragmatic force, and cognitive affect are
distinct and are all significant. The differing de-
grees of detail and prominence they receive in the
different systems are discussed under those head-
ings in the next section.
</bodyText>
<sectionHeader confidence="0.987976" genericHeader="method">
3 Dialogue tagsets
</sectionHeader>
<bodyText confidence="0.999937285714286">
Not surprisingly, the actual tagsets developed in
oncology reflect their domain more closely than
the parameter sets do. In comparison with NLP
work, syntactic classification is minimal and func-
tionally oriented, while communication manage-
ment and psychological / emotional loading re-
ceive prominent, fine-grained analysis.
</bodyText>
<subsectionHeader confidence="0.989812">
3.1 Form
</subsectionHeader>
<bodyText confidence="0.999344379310345">
Although all four oncology systems encode the
form of an utterance in some way, the classifica-
tions have a strong pragmatic bias. Questions are
distinguished, not in traditional syntactic terms
as yes-no or wh-, but according to their effect on
the flow of the dialogue. The simplest set is that
of Butow et al: Open Question, Closed Question,
Response to Question, Statement, Other. PMG
add Directive Question (open), Directive Question
(closed), Screening Question, Leading Question,
Multiple Question.
Ford et al distinguish “modes” from “con-
tent codes”, but even the modes encode coarse-
grained content information as well as affective
classification. The form categories of Ong et al
are “instrumental” (Directions, Question-asking,
Information-giving, &amp;c), and they specify that “if
a decision must be made between categorizing an
utterance in an instrumental or affect category,
the affect category should be used” - quite rea-
sonably, given the purpose of their analysis.
Even with a prior commitment to maintaining
separate and independent levels of analysis, some
leakage between levels can occur. (The set of
forty-two Dialogue Act labels used by Stolcke et al
(2000) shows some similar mixing of levels, includ-
ing both purely syntactic tags (such as Declarative
Yes-No Question) and affective tags (such as Ap-
preciation).)
</bodyText>
<subsectionHeader confidence="0.99881">
3.2 Content
</subsectionHeader>
<bodyText confidence="0.99997308">
The content of an utterance is also encoded in all
four systems, and the tagsets on this level are the
most domain-specific. Butow et al cite seven con-
tent categories: Treatment, Diagnosis, Prognosis,
History, Other medical matters, Social matters.
Ford et al, with 15 content codes, and PMG,
with 38, are the most fully developed. Both
include Medical (further distinguished by PMG,
with four categories for diagnosis and two for prog-
nosis), Treatment, Psychological, Social, Lifestyle,
&amp;c. PMG are particularly detailed in their cat-
egories for psychological and emotional issues,
shading into the affect level: Concerns, Feelings,
Emotions, Religion, &amp;c. Again, this is what one
would expect, given that their reason for carry-
ing out the analysis is to assess the health pro-
fessional’s success in getting the patient to talk
about exactly these issues.
Both Ford and PMG also include the opening
and closing of the interview under this heading,
where it sits oddly. A separate level of commu-
nication management, as in DAMSL, would ac-
commodate these and the open/ closed/ directive
question distinction currently made in the Form
tagsets, clarifying all three.
</bodyText>
<subsectionHeader confidence="0.989304">
3.3 Pragmatics
</subsectionHeader>
<bodyText confidence="0.999948538461538">
As noted above, the Form classes used in the four
coding schemes express more pragmatic than syn-
tactic information. Ong et al’s “instrumental clus-
ters and categories” (Directions, Question- ask-
ing, Information-giving, Counselling) can be con-
sidered pragmatic. So can PMG’s “Function”
codes: eliciting, checking, acknowledgement (psy-
chological, general, cognitions); reassurance, ne-
gotiation, information giving. These are similar
to some of the Dialogue Act labels used in NLP
work: Stolcke et al’s (2000) agreement, response
acknowledgement, summarize, or VERBMOBIL’s
suggest, confirm, clarify (Jekat et al 1995).
</bodyText>
<subsectionHeader confidence="0.885459">
3.4 Affect
</subsectionHeader>
<bodyText confidence="0.9980543">
Cognitive affect - the psychological force, for a
patient, of an utterance or a complete dialogue -
is the focus of interest in oncology and thus the
most highly developed area. Ford et al pick out
eight of their “modes” as affective, including the
expression of irritation, gratitude, apology, and
concern.
Ong et al rate both doctor and patient, by cod-
ing their utterances, on five distinct “global affect”
scales: Anger/ irritation, Anxiety/ nervousness,
Dominance/ assertiveness, Interest/ engagement,
Friendliness/ warmth. Their “affective clusters
and categories” comprise (with subheadings) so-
cial behaviour, verbal attentiveness, showing con-
cern, and negative talk.
PMG do not represent affect as a separate pa-
rameter, as such. Their function codes include
affective functions such as Empathy and Reassur-
ance. Many of their content codes can also repre-
sent affect, as noted above. Topics such as Con-
cerns, Feelings about health care, Religion / spiri-
tual issues can be addressed at any level from sim-
ply factual to deeply emotional, blurring the pic-
ture: this would be clarified if the affect level were
explicitly factored out. The most direct represen-
tation of affective level comes in the two codes
Psychological explicit and Psychological implicit.
Each utterance in a dialogue can be given several
content codes, commonly including one of these
two, as seen in the sample dialogue below.
Cognitive affect has barely been touched on by
NLP research in dialogue tagging. It is clearly
more subtle and difficult than syntactic, seman-
tic, or pragmatic analysis, and also less significant
in instructional or service dialogues than in the
highly charged, life-critical domain of cancer care.
It is, however, an important aspect of dialogue and
speaker modelling, and of the design of appropri-
ate responses. In this area, NLP could learn some
valuable lessons from oncology.
</bodyText>
<sectionHeader confidence="0.934489" genericHeader="method">
4 An example
</sectionHeader>
<bodyText confidence="0.9989415">
Here is a brief typical example from a PMG anno-
tated dialogue. Notice the multiple and somewhat
diverse content codes, and the classification of
cue management (somewhat counter-intuitively
attached to the cue utterance itself, not the
response).
</bodyText>
<figure confidence="0.847082272727273">
P26: I said there’s only another thing that I hope I
never have to have and that’s selectron treatment.
Content: 23 (Psychological implicit)
24 (Treatment)
Level: 1 (Hint)
Cue: 1 (Patient cue)
Cue management: 4 (Cue explored)
N27: Mmmm.
Form: 02 (Response)
Function: 06 (Acknowledgement - general)
Content: 24 (Psychological implicit)
</figure>
<footnote confidence="0.471878">
P27: But I says ...... if I have to I will do, I said
whatever you say, I said.
Content: 24 (Treatment)
14 (Information)
</footnote>
<note confidence="0.766154166666667">
N28: Now why did you say that about selectron?
Form: 04 (Open directive question)
Function: 04 (Clarification - general)
Content: 24 (Treatment)
P28: No it were me that said that.
Content: 24 (Treatment)
</note>
<figure confidence="0.9466626875">
N29: Right,
Form: 02 (Response)
Function: 06 (Acknowledgement - general)
Content: 24 (Treatment)
have you had it before?
Form: 05 (Directive question (closed)
Function: 04 (Clarification - general)
Content: 24 (Treatment)
13 (History)
P29: I said, I, I don’t mind what you do but I hope
I’ve never to have selectron treatment again, but I
said if I have to, if it’s a necessity then I will.
Content: 23 (Psychological implicit)
24 (Treatment)
33 (The future)
Level: 1 (Hint)
</figure>
<table confidence="0.613029578947369">
Cue: 1 (Patient cue)
Cue management: 2 (Minimal acknowledgement)
N30: Right.
Form: 02 (Response)
Function: 06 (Acknowledgement - general)
Content: 24 (Treatment)
14 (Information)
P30: But I hope I never have.
Content: 23 (Psychological implicit)
24 (Treatment)
33 (The future)
Level: 1 (Hint)
Cue: 1 (Patient cue)
Cue management: 4 (Cue explored)
N31: And why was that, because you were isolated
or what was it....?
Form: 08 (Multiple question)
Function: 03 (Clarification - psychological)
Content: 23 (Psychological implicit)
</table>
<page confidence="0.625731">
24 (Treatment)
</page>
<sectionHeader confidence="0.980566" genericHeader="evaluation">
5 Implementations
</sectionHeader>
<bodyText confidence="0.9999815">
All the dialogue tagging work in oncology has been
done manually. A few primitive software tools
have been developed to support the tagging pro-
cess and to analyse the results.
Ong et al (1998) have developed a Turbo Pas-
cal “computerized version” of the RIAS coding
system. The advantages they claim for it give one
some idea of average state of its field:
“With this program, classification of utterances
can be done directly on computer. As a result,
the extra step of entering paper and pencil data
into the computer is omitted. Also, sequential in-
formation is kept. Moreover, because the ten last
classifications are constantly visible on the screen
there is direct feedback about the ongoing conver-
sation. This provides an important memory aid
with respect to which utterance has to be coded
next. As a consequence, the task becomes less at-
tention demanding and therefore less error- prone.
By giving the opportunity to save the content of
the last coded utterance, an additional memory
aid is provided for shorter and longer breaks.”
(Ong et al 1998:400)
Butow’s group have developed a “computer-
based interaction analysis system” with three
parts: “(i) micro level analysis coded in real time
and retaining the sequence of events, (ii) event
counts and (iii) macro level analysis of consulta-
tion style and affect” (Butow et al 1995:1116). “At
the micro level the aim is to break the consul-
tation down into its components and to charac-
terise, count and/or time them... At the macro
level, the aim is to characterise the consulta-
tion in a more holistic way, such as patient-
centred vs doctor-centred, authoritarian vs affil-
iative or friendly vs hostile.” (ibid:1115) All three
forms of analysis depend on counting and timing
utterance-events classified according to the three-
dimensional model described above, although Bu-
tow et al stress that they also “retain the sequence
of events”. “In future analyses we will explore se-
quential information effects” (ibid:1120). This is
evidently a significant innovation in its field. The
fundamental concept of a grammar of dialogue
is simply missing from the oncology work. On
the other hand, their techniques for “macro-level”
analysis of dialogues may well have something to
offer, especially in the subtle areas of modelling
and adapting to speakers’ attitudes and underly-
ing intentions.
</bodyText>
<sectionHeader confidence="0.998016" genericHeader="conclusions">
6 Prospects
</sectionHeader>
<bodyText confidence="0.999971470588235">
All this work has been developed with care, in the
light of experience, to serve a specific and unusual
purpose. However, it shows no awareness of dia-
logue tagging work in NLP. Both fields can benefit
from collaboration.
The author, together with Prof. Peter Maguire
of PMG, has recently been granted support by
CRC to develop practical software support for
the PMG oncology dialogue annotators. This
paper presents a preliminary analysis, part of a
feasibility study for that project. An associated
PhD studentship, awarded by the University of
Manchester Department of Computer Science,
ensures that the NLP perspective will be rep-
resented and the theoretical issues addressed.
We look forward to presenting more detailed
analyses, and original proposals, in the future.
</bodyText>
<sectionHeader confidence="0.997299" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9472345">
Prof. Peter Maguire and Ian Fletcher of PMG
have been generous with their time and support
in the research leading to this paper. We also
gratefully acknowledge the support of the Can-
cer Research Campaign and of the Department of
Computer Science, University of Manchester.
</bodyText>
<sectionHeader confidence="0.996925" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99845828125">
Butow, PN, SM Dunn, MHN Tattersall, &amp; Q. J.
Jones. 1995. Computer-based interaction analy-
sis of the cancer consultation. British Journal of
Cancer 71:1115-1121.
Core, M. &amp; J Allen. 1997. Coding Dialogs with
the DAMSL annotation scheme. AAAI fall sym-
posium on Communicative Action in Humans and
Machines.
Ford, S, A Hall, D Ratcliffe, &amp; L Fallowfield.
2000. The Medical Interaction Process System
(MIPS): an instrument for analysing interviews of
oncologists and patients with cancer. Social Sci-
ence and Medicine 50:553-566.
Jekat, S, A Klein, E Maier, I Maleck, M Mast, &amp;
J Quantz. 1995. Dialogue acts in VERBMOBIL.
Verbmobil-Report 65, Universitat Hamburg et al.
Maguire, P &amp; A Faulkner. 1988. How to im-
prove the counselling skills of doctors and nurses
in cancer care. British Journal of Medicine 297,
847.
Ong, LML, MRM Visser, IPM Kruyver,
JM Bensing, A van den Brink-Muinen, JML
Stouthard, FB Lammes &amp; JCJM de Haes. 1998.
The Roter Interaction Analysis System (RIAS) in
Oncological Consultations: Psychometric Proper-
ties. Psycho- Oncology 7:387-401.
Stolcke, A, K Ries, N Coccaro, E. Shriberg, R
Bates, D Jurafsky, P Taylor, R Martin, C van Ess-
Dykema, &amp; M Meteer. 2000. Dialogue Act Mod-
elling for Automatic Tagging and Recognition of
Conversational Speech. Computational Linguis-
tics 26(3):339-373.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.024722">
<title confidence="0.989301">Dialogue tagsets in oncology</title>
<author confidence="0.999966">Mary McGee</author>
<affiliation confidence="0.9998045">Department of Computer University of</affiliation>
<address confidence="0.960565">Manchester M13 9PL</address>
<email confidence="0.993194">mary@cs.man.ac.uk</email>
<abstract confidence="0.995188973333333">Dialogue analysis is widely used in oncology for training health professionals in communication skills. Parameters and tagsets have been developed independently of work in natural language processing. In relation to emergent standards in NLP, syntactic tagging is minimal, semantics is domain-specific, pragmatics is comparable, and the analysis of cognitive affect is richly developed. We suggest productive directions for convergence. 1 Motivation Dialogue analysis systems have been developed in oncology as a tool for assessing and improving the communication skills of health professionals. Rates of psychiatric morbidity (clinical anxiety and depression) in cancer patients are lowered when health professionals have adequate communication skills to discover and address the patients’ concerns and worries. Health professionals interviewing patients sometimes exhibit negative behaviours, such as “blocking” a certain line of investigation rather than encouraging the patient to describe his or her problem. On the other hand, a skilled interviewer uses active interventions to direct the progress of the interview, as well as more passive responses. Several oncology research groups have demonstrated that these patterns can be detected and quantified through analysis of conversations between health professionals and patients. This in turn can form a basis for more effective training in communication skills. The Psychological Medicine Group at Manchester (PMG), funded by the Cancer Research Campaign (CRC), is a leading group in dialogue analysis in oncology. This paper describes the parameters and tagsets (analogous to “Dialogue Act” tagging (Stolcke et al 2000)), which they and three other groups have developed for this highly specialised domain. This domain offers an interesting contrast to the “instructional” or “service” dialogues commonly studied. The health professional is the “expert” in the conventional sense, and at times conveys medical information to the less knowledgeable patient in a conventional way. At other times, the patient should be seen as the “expert” with regard to his or her own perceived physical and mental condition, and the task of the health professional is effectively that of “knowledge elicitation” as understood in expert systems development. This flexible and dynamic shifting of participants’ roles in a dialogue poses an interesting challenge, compared to the clearly defined and static roles assumed in much work in dialogue analysis. 2 Parameters for dialogue tagging Complete and accurate tagging of dialogue must encode a number of independent aspects of each utterance. These are represented as “layers” in the DAMSL system (Core &amp; Allen 1997). Form-based tags (question, statement) are supplemented with diacritics indicating other types of information, such as task-management or communication-management. The four oncology dialogue tagging systems considered here all share this basic principle, although they differ in the specifics. Butow et al (1995:1115) cite the recognition as early as 1983 of “layers of meaning ... such as the content, the process, the emotion and the purpose”. Their own CN-LOGIT system encodes three “dimensions”: “source” (who is speaking), “process” (questions, responses, initiated statements), and “content”. A complete dialogue can be mapped into a three-dimensional information space, and measures can be applied such as how much time was spent in each cell of the cube. Ong et al (1998) use the Roter Interaction Analysis System (RIAS). Each utterance in a dialogue is categorised, and also rated on five distinct “global affect” scales. The Medical Interaction Process System (MIPS) of Ford et al (2000) also stresses the multi-dimensional nature of dialogue annotation, using fifteen “content codes” and eight “affective modes”. PMG (Maguire &amp; Faulkner 1988; Maguire p.c.) have separate tagsets for Form, Function, Content, Level, Cue, Cue Management, Blocking, and Focus. One can see an implicit consensus here that (to use NLP terms) syntactic form, overt semantic content, pragmatic force, and cognitive affect are distinct and are all significant. The differing degrees of detail and prominence they receive in the different systems are discussed under those headings in the next section. 3 Dialogue tagsets Not surprisingly, the actual tagsets developed in oncology reflect their domain more closely than the parameter sets do. In comparison with NLP work, syntactic classification is minimal and functionally oriented, while communication management and psychological / emotional loading receive prominent, fine-grained analysis. 3.1 Form Although all four oncology systems encode the form of an utterance in some way, the classifications have a strong pragmatic bias. Questions are distinguished, not in traditional syntactic terms as yes-no or wh-, but according to their effect on the flow of the dialogue. The simplest set is that of Butow et al: Open Question, Closed Question, Response to Question, Statement, Other. PMG add Directive Question (open), Directive Question (closed), Screening Question, Leading Question, Multiple Question. Ford et al distinguish “modes” from “content codes”, but even the modes encode coarsegrained content information as well as affective classification. The form categories of Ong et al are “instrumental” (Directions, Question-asking, Information-giving, &amp;c), and they specify that “if a decision must be made between categorizing an utterance in an instrumental or affect category, the affect category should be used” quite reasonably, given the purpose of their analysis. Even with a prior commitment to maintaining separate and independent levels of analysis, some leakage between levels can occur. (The set of forty-two Dialogue Act labels used by Stolcke et al (2000) shows some similar mixing of levels, including both purely syntactic tags (such as Declarative Yes-No Question) and affective tags (such as Appreciation).) 3.2 Content The content of an utterance is also encoded in all four systems, and the tagsets on this level are the most domain-specific. Butow et al cite seven content categories: Treatment, Diagnosis, Prognosis, History, Other medical matters, Social matters. Ford et al, with 15 content codes, and PMG, with 38, are the most fully developed. Both include Medical (further distinguished by PMG, with four categories for diagnosis and two for prognosis), Treatment, Psychological, Social, Lifestyle, &amp;c. PMG are particularly detailed in their categories for psychological and emotional issues, shading into the affect level: Concerns, Feelings, Emotions, Religion, &amp;c. Again, this is what one would expect, given that their reason for carrying out the analysis is to assess the health professional’s success in getting the patient to talk about exactly these issues. Both Ford and PMG also include the opening and closing of the interview under this heading, where it sits oddly. A separate level of communication management, as in DAMSL, would accommodate these and the open/ closed/ directive question distinction currently made in the Form tagsets, clarifying all three. 3.3 Pragmatics As noted above, the Form classes used in the four coding schemes express more pragmatic than syntactic information. Ong et al’s “instrumental clusters and categories” (Directions, Questionasking, Information-giving, Counselling) can be considered pragmatic. So can PMG’s “Function” codes: eliciting, checking, acknowledgement (psychological, general, cognitions); reassurance, negotiation, information giving. These are similar to some of the Dialogue Act labels used in NLP work: Stolcke et al’s (2000) agreement, response acknowledgement, summarize, or VERBMOBIL’s suggest, confirm, clarify (Jekat et al 1995). 3.4 Affect Cognitive affect the psychological force, for a patient, of an utterance or a complete dialogue is the focus of interest in oncology and thus the most highly developed area. Ford et al pick out eight of their “modes” as affective, including the expression of irritation, gratitude, apology, and concern. Ong et al rate both doctor and patient, by coding their utterances, on five distinct “global affect” scales: Anger/ irritation, Anxiety/ nervousness, Dominance/ assertiveness, Interest/ engagement, Friendliness/ warmth. Their “affective clusters and categories” comprise (with subheadings) social behaviour, verbal attentiveness, showing concern, and negative talk. PMG do not represent affect as a separate parameter, as such. Their function codes include affective functions such as Empathy and Reassurance. Many of their content codes can also represent affect, as noted above. Topics such as Concerns, Feelings about health care, Religion / spiritual issues can be addressed at any level from simply factual to deeply emotional, blurring the picture: this would be clarified if the affect level were explicitly factored out. The most direct representation of affective level comes in the two codes Psychological explicit and Psychological implicit. Each utterance in a dialogue can be given several content codes, commonly including one of these two, as seen in the sample dialogue below. Cognitive affect has barely been touched on by NLP research in dialogue tagging. It is clearly more subtle and difficult than syntactic, semantic, or pragmatic analysis, and also less significant in instructional or service dialogues than in the highly charged, life-critical domain of cancer care. It is, however, an important aspect of dialogue and speaker modelling, and of the design of appropriate responses. In this area, NLP could learn some valuable lessons from oncology. 4 An example Here is a brief typical example from a PMG annotated dialogue. Notice the multiple and somewhat diverse content codes, and the classification of cue management (somewhat counter-intuitively attached to the cue utterance itself, not the response). P26: I said there’s only another thing that I hope I never have to have and that’s selectron treatment.</abstract>
<note confidence="0.981933535714286">Content: 23 (Psychological implicit) 24 (Treatment) Level: 1 (Hint) Cue: 1 (Patient cue) Cue management: 4 (Cue explored) N27: Mmmm. Form: 02 (Response) Function: 06 (Acknowledgement general) Content: 24 (Psychological implicit) P27: But I says ...... if I have to I will do, I said whatever you say, I said. Content: 24 (Treatment) 14 (Information) N28: Now why did you say that about selectron? Form: 04 (Open directive question) Function: 04 (Clarification general) Content: 24 (Treatment) P28: No it were me that said that. Content: 24 (Treatment) N29: Right, Form: 02 (Response) Function: 06 (Acknowledgement general) Content: 24 (Treatment) have you had it before? Form: 05 (Directive question (closed) Function: 04 (Clarification general) Content: 24 (Treatment) 13 (History) P29: I said, I, I don’t mind what you do but I hope I’ve never to have selectron treatment again, but I said if I have to, if it’s a necessity then I will. Content: 23 (Psychological implicit) 24 (Treatment) 33 (The future) Level: 1 (Hint) Cue: 1 (Patient cue) Cue management: 2 (Minimal acknowledgement) N30: Right. Form: 02 (Response) Function: 06 (Acknowledgement general) Content: 24 (Treatment) 14 (Information) P30: But I hope I never have. Content: 23 (Psychological implicit) 24 (Treatment) 33 (The future) Level: 1 (Hint) Cue: 1 (Patient cue) Cue management: 4 (Cue explored) N31: And why was that, because you were isolated or what was it....? Form: 08 (Multiple question) Function: 03 (Clarification psychological) Content: 23 (Psychological implicit) 24 (Treatment) 5 Implementations</note>
<abstract confidence="0.979838917808219">All the dialogue tagging work in oncology has been done manually. A few primitive software tools have been developed to support the tagging process and to analyse the results. Ong et al (1998) have developed a Turbo Pascal “computerized version” of the RIAS coding system. The advantages they claim for it give one some idea of average state of its field: “With this program, classification of utterances can be done directly on computer. As a result, the extra step of entering paper and pencil data into the computer is omitted. Also, sequential information is kept. Moreover, because the ten last classifications are constantly visible on the screen there is direct feedback about the ongoing conversation. This provides an important memory aid with respect to which utterance has to be coded next. As a consequence, the task becomes less attention demanding and therefore less errorprone. By giving the opportunity to save the content of the last coded utterance, an additional memory aid is provided for shorter and longer breaks.” (Ong et al 1998:400) Butow’s group have developed a “computerbased interaction analysis system” with three parts: “(i) micro level analysis coded in real time and retaining the sequence of events, (ii) event counts and (iii) macro level analysis of consultation style and affect” (Butow et al 1995:1116). “At the micro level the aim is to break the consultation down into its components and to characterise, count and/or time them... At the macro level, the aim is to characterise the consultation in a more holistic way, such as patientauthoritarian affilor friendly (ibid:1115) All three forms of analysis depend on counting and timing utterance-events classified according to the threedimensional model described above, although Butow et al stress that they also “retain the sequence of events”. “In future analyses we will explore sequential information effects” (ibid:1120). This is evidently a significant innovation in its field. The concept of a dialogue is simply missing from the oncology work. On the other hand, their techniques for “macro-level” analysis of dialogues may well have something to offer, especially in the subtle areas of modelling and adapting to speakers’ attitudes and underlying intentions. 6 Prospects All this work has been developed with care, in the light of experience, to serve a specific and unusual purpose. However, it shows no awareness of dialogue tagging work in NLP. Both fields can benefit from collaboration. The author, together with Prof. Peter Maguire of PMG, has recently been granted support by CRC to develop practical software support for the PMG oncology dialogue annotators. This paper presents a preliminary analysis, part of a feasibility study for that project. An associated PhD studentship, awarded by the University of Manchester Department of Computer Science, ensures that the NLP perspective will be represented and the theoretical issues addressed. We look forward to presenting more detailed analyses, and original proposals, in the future. Acknowledgments Prof. Peter Maguire and Ian Fletcher of PMG have been generous with their time and support in the research leading to this paper. We also gratefully acknowledge the support of the Can-</abstract>
<note confidence="0.942800228571429">cer Research Campaign and of the Department of Computer Science, University of Manchester. References Butow, PN, SM Dunn, MHN Tattersall, &amp; Q. J. Jones. 1995. Computer-based interaction analysis of the cancer consultation. British Journal of Cancer 71:1115-1121. Core, M. &amp; J Allen. 1997. Coding Dialogs with the DAMSL annotation scheme. AAAI fall symposium on Communicative Action in Humans and Machines. Ford, S, A Hall, D Ratcliffe, &amp; L Fallowfield. 2000. The Medical Interaction Process System (MIPS): an instrument for analysing interviews of oncologists and patients with cancer. Social Science and Medicine 50:553-566. Jekat, S, A Klein, E Maier, I Maleck, M Mast, &amp; J Quantz. 1995. Dialogue acts in VERBMOBIL. Verbmobil-Report 65, Universitat Hamburg et al. Maguire, P &amp; A Faulkner. 1988. How to improve the counselling skills of doctors and nurses in cancer care. British Journal of Medicine 297, 847. Ong, LML, MRM Visser, IPM Kruyver, JM Bensing, A van den Brink-Muinen, JML Stouthard, FB Lammes &amp; JCJM de Haes. 1998. The Roter Interaction Analysis System (RIAS) in Oncological Consultations: Psychometric Properties. Psycho- Oncology 7:387-401. Stolcke, A, K Ries, N Coccaro, E. Shriberg, R Bates, D Jurafsky, P Taylor, R Martin, C van Ess- Dykema, &amp; M Meteer. 2000. Dialogue Act Modelling for Automatic Tagging and Recognition of Conversational Speech. Computational Linguistics 26(3):339-373.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>PN Butow</author>
<author>SM Dunn</author>
<author>MHN Tattersall</author>
<author>Q J Jones</author>
</authors>
<title>Computer-based interaction analysis of the cancer consultation.</title>
<date>1995</date>
<journal>British Journal of Cancer</journal>
<pages>71--1115</pages>
<contexts>
<context position="3171" citStr="Butow et al (1995" startWordPosition="477" endWordPosition="480"> compared to the clearly defined and static roles assumed in much work in dialogue analysis. 2 Parameters for dialogue tagging Complete and accurate tagging of dialogue must encode a number of independent aspects of each utterance. These are represented as “layers” in the DAMSL system (Core &amp; Allen 1997). Form-based tags (question, statement) are supplemented with diacritics indicating other types of information, such as task-management or communication-management. The four oncology dialogue tagging systems considered here all share this basic principle, although they differ in the specifics. Butow et al (1995:1115) cite the recognition as early as 1983 of “layers of meaning ... such as the content, the process, the emotion and the purpose”. Their own CN-LOGIT system encodes three “dimensions”: “source” (who is speaking), “process” (questions, responses, initiated statements), and “content”. A complete dialogue can be mapped into a three-dimensional information space, and measures can be applied such as how much time was spent in each cell of the cube. Ong et al (1998) use the Roter Interaction Analysis System (RIAS). Each utterance in a dialogue is categorised, and also rated on five distinct “glo</context>
<context position="13121" citStr="Butow et al 1995" startWordPosition="2041" endWordPosition="2044">des an important memory aid with respect to which utterance has to be coded next. As a consequence, the task becomes less attention demanding and therefore less error- prone. By giving the opportunity to save the content of the last coded utterance, an additional memory aid is provided for shorter and longer breaks.” (Ong et al 1998:400) Butow’s group have developed a “computerbased interaction analysis system” with three parts: “(i) micro level analysis coded in real time and retaining the sequence of events, (ii) event counts and (iii) macro level analysis of consultation style and affect” (Butow et al 1995:1116). “At the micro level the aim is to break the consultation down into its components and to characterise, count and/or time them... At the macro level, the aim is to characterise the consultation in a more holistic way, such as patientcentred vs doctor-centred, authoritarian vs affiliative or friendly vs hostile.” (ibid:1115) All three forms of analysis depend on counting and timing utterance-events classified according to the threedimensional model described above, although Butow et al stress that they also “retain the sequence of events”. “In future analyses we will explore sequential i</context>
</contexts>
<marker>Butow, Dunn, Tattersall, Jones, 1995</marker>
<rawString>Butow, PN, SM Dunn, MHN Tattersall, &amp; Q. J. Jones. 1995. Computer-based interaction analysis of the cancer consultation. British Journal of Cancer 71:1115-1121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Core</author>
<author>J Allen</author>
</authors>
<date>1997</date>
<booktitle>Coding Dialogs with the DAMSL annotation scheme. AAAI fall symposium on Communicative Action in Humans and Machines.</booktitle>
<contexts>
<context position="2859" citStr="Core &amp; Allen 1997" startWordPosition="434" endWordPosition="437">xpert” with regard to his or her own perceived physical and mental condition, and the task of the health professional is effectively that of “knowledge elicitation” as understood in expert systems development. This flexible and dynamic shifting of participants’ roles in a dialogue poses an interesting challenge, compared to the clearly defined and static roles assumed in much work in dialogue analysis. 2 Parameters for dialogue tagging Complete and accurate tagging of dialogue must encode a number of independent aspects of each utterance. These are represented as “layers” in the DAMSL system (Core &amp; Allen 1997). Form-based tags (question, statement) are supplemented with diacritics indicating other types of information, such as task-management or communication-management. The four oncology dialogue tagging systems considered here all share this basic principle, although they differ in the specifics. Butow et al (1995:1115) cite the recognition as early as 1983 of “layers of meaning ... such as the content, the process, the emotion and the purpose”. Their own CN-LOGIT system encodes three “dimensions”: “source” (who is speaking), “process” (questions, responses, initiated statements), and “content”. </context>
</contexts>
<marker>Core, Allen, 1997</marker>
<rawString>Core, M. &amp; J Allen. 1997. Coding Dialogs with the DAMSL annotation scheme. AAAI fall symposium on Communicative Action in Humans and Machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ford</author>
<author>A Hall</author>
<author>D Ratcliffe</author>
<author>L Fallowfield</author>
</authors>
<title>The Medical Interaction Process System (MIPS): an instrument for analysing interviews of oncologists and patients with cancer.</title>
<date>2000</date>
<journal>Social Science and Medicine</journal>
<pages>50--553</pages>
<contexts>
<context position="3857" citStr="Ford et al (2000)" startWordPosition="589" endWordPosition="592">. such as the content, the process, the emotion and the purpose”. Their own CN-LOGIT system encodes three “dimensions”: “source” (who is speaking), “process” (questions, responses, initiated statements), and “content”. A complete dialogue can be mapped into a three-dimensional information space, and measures can be applied such as how much time was spent in each cell of the cube. Ong et al (1998) use the Roter Interaction Analysis System (RIAS). Each utterance in a dialogue is categorised, and also rated on five distinct “global affect” scales. The Medical Interaction Process System (MIPS) of Ford et al (2000) also stresses the multi-dimensional nature of dialogue annotation, using fifteen “content codes” and eight “affective modes”. PMG (Maguire &amp; Faulkner 1988; Maguire p.c.) have separate tagsets for Form, Function, Content, Level, Cue, Cue Management, Blocking, and Focus. One can see an implicit consensus here that (to use NLP terms) syntactic form, overt semantic content, pragmatic force, and cognitive affect are distinct and are all significant. The differing degrees of detail and prominence they receive in the different systems are discussed under those headings in the next section. 3 Dialogu</context>
</contexts>
<marker>Ford, Hall, Ratcliffe, Fallowfield, 2000</marker>
<rawString>Ford, S, A Hall, D Ratcliffe, &amp; L Fallowfield. 2000. The Medical Interaction Process System (MIPS): an instrument for analysing interviews of oncologists and patients with cancer. Social Science and Medicine 50:553-566.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Jekat</author>
<author>A Klein</author>
<author>E Maier</author>
<author>I Maleck</author>
<author>M Mast</author>
<author>J Quantz</author>
</authors>
<date>1995</date>
<note>Dialogue acts in VERBMOBIL. Verbmobil-Report 65, Universitat Hamburg et al.</note>
<contexts>
<context position="7935" citStr="Jekat et al 1995" startWordPosition="1210" endWordPosition="1213">ics As noted above, the Form classes used in the four coding schemes express more pragmatic than syntactic information. Ong et al’s “instrumental clusters and categories” (Directions, Question- asking, Information-giving, Counselling) can be considered pragmatic. So can PMG’s “Function” codes: eliciting, checking, acknowledgement (psychological, general, cognitions); reassurance, negotiation, information giving. These are similar to some of the Dialogue Act labels used in NLP work: Stolcke et al’s (2000) agreement, response acknowledgement, summarize, or VERBMOBIL’s suggest, confirm, clarify (Jekat et al 1995). 3.4 Affect Cognitive affect - the psychological force, for a patient, of an utterance or a complete dialogue - is the focus of interest in oncology and thus the most highly developed area. Ford et al pick out eight of their “modes” as affective, including the expression of irritation, gratitude, apology, and concern. Ong et al rate both doctor and patient, by coding their utterances, on five distinct “global affect” scales: Anger/ irritation, Anxiety/ nervousness, Dominance/ assertiveness, Interest/ engagement, Friendliness/ warmth. Their “affective clusters and categories” comprise (with su</context>
</contexts>
<marker>Jekat, Klein, Maier, Maleck, Mast, Quantz, 1995</marker>
<rawString>Jekat, S, A Klein, E Maier, I Maleck, M Mast, &amp; J Quantz. 1995. Dialogue acts in VERBMOBIL. Verbmobil-Report 65, Universitat Hamburg et al.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Maguire</author>
<author>A Faulkner</author>
</authors>
<title>How to improve the counselling skills of doctors and nurses in cancer care.</title>
<date>1988</date>
<journal>British Journal of Medicine</journal>
<volume>297</volume>
<pages>847</pages>
<contexts>
<context position="4012" citStr="Maguire &amp; Faulkner 1988" startWordPosition="612" endWordPosition="615">process” (questions, responses, initiated statements), and “content”. A complete dialogue can be mapped into a three-dimensional information space, and measures can be applied such as how much time was spent in each cell of the cube. Ong et al (1998) use the Roter Interaction Analysis System (RIAS). Each utterance in a dialogue is categorised, and also rated on five distinct “global affect” scales. The Medical Interaction Process System (MIPS) of Ford et al (2000) also stresses the multi-dimensional nature of dialogue annotation, using fifteen “content codes” and eight “affective modes”. PMG (Maguire &amp; Faulkner 1988; Maguire p.c.) have separate tagsets for Form, Function, Content, Level, Cue, Cue Management, Blocking, and Focus. One can see an implicit consensus here that (to use NLP terms) syntactic form, overt semantic content, pragmatic force, and cognitive affect are distinct and are all significant. The differing degrees of detail and prominence they receive in the different systems are discussed under those headings in the next section. 3 Dialogue tagsets Not surprisingly, the actual tagsets developed in oncology reflect their domain more closely than the parameter sets do. In comparison with NLP w</context>
</contexts>
<marker>Maguire, Faulkner, 1988</marker>
<rawString>Maguire, P &amp; A Faulkner. 1988. How to improve the counselling skills of doctors and nurses in cancer care. British Journal of Medicine 297, 847.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LML Ong</author>
<author>MRM Visser</author>
<author>IPM Kruyver</author>
<author>JM Bensing</author>
</authors>
<title>A van den Brink-Muinen,</title>
<date>1998</date>
<journal>JML Stouthard, FB Lammes &amp; JCJM de Haes.</journal>
<contexts>
<context position="3639" citStr="Ong et al (1998)" startWordPosition="553" endWordPosition="556"> The four oncology dialogue tagging systems considered here all share this basic principle, although they differ in the specifics. Butow et al (1995:1115) cite the recognition as early as 1983 of “layers of meaning ... such as the content, the process, the emotion and the purpose”. Their own CN-LOGIT system encodes three “dimensions”: “source” (who is speaking), “process” (questions, responses, initiated statements), and “content”. A complete dialogue can be mapped into a three-dimensional information space, and measures can be applied such as how much time was spent in each cell of the cube. Ong et al (1998) use the Roter Interaction Analysis System (RIAS). Each utterance in a dialogue is categorised, and also rated on five distinct “global affect” scales. The Medical Interaction Process System (MIPS) of Ford et al (2000) also stresses the multi-dimensional nature of dialogue annotation, using fifteen “content codes” and eight “affective modes”. PMG (Maguire &amp; Faulkner 1988; Maguire p.c.) have separate tagsets for Form, Function, Content, Level, Cue, Cue Management, Blocking, and Focus. One can see an implicit consensus here that (to use NLP terms) syntactic form, overt semantic content, pragmati</context>
<context position="11977" citStr="Ong et al (1998)" startWordPosition="1852" endWordPosition="1855">) Content: 24 (Treatment) 14 (Information) P30: But I hope I never have. Content: 23 (Psychological implicit) 24 (Treatment) 33 (The future) Level: 1 (Hint) Cue: 1 (Patient cue) Cue management: 4 (Cue explored) N31: And why was that, because you were isolated or what was it....? Form: 08 (Multiple question) Function: 03 (Clarification - psychological) Content: 23 (Psychological implicit) 24 (Treatment) 5 Implementations All the dialogue tagging work in oncology has been done manually. A few primitive software tools have been developed to support the tagging process and to analyse the results. Ong et al (1998) have developed a Turbo Pascal “computerized version” of the RIAS coding system. The advantages they claim for it give one some idea of average state of its field: “With this program, classification of utterances can be done directly on computer. As a result, the extra step of entering paper and pencil data into the computer is omitted. Also, sequential information is kept. Moreover, because the ten last classifications are constantly visible on the screen there is direct feedback about the ongoing conversation. This provides an important memory aid with respect to which utterance has to be co</context>
</contexts>
<marker>Ong, Visser, Kruyver, Bensing, 1998</marker>
<rawString>Ong, LML, MRM Visser, IPM Kruyver, JM Bensing, A van den Brink-Muinen, JML Stouthard, FB Lammes &amp; JCJM de Haes. 1998. The Roter Interaction Analysis System (RIAS) in Oncological Consultations: Psychometric Properties. Psycho- Oncology 7:387-401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>K Ries</author>
<author>N Coccaro</author>
<author>E Shriberg</author>
<author>R Bates</author>
<author>D Jurafsky</author>
<author>P Taylor</author>
<author>R Martin</author>
<author>C van EssDykema</author>
<author>M Meteer</author>
</authors>
<title>Dialogue Act Modelling for Automatic Tagging and Recognition of Conversational Speech.</title>
<date>2000</date>
<journal>Computational Linguistics</journal>
<pages>26--3</pages>
<marker>Stolcke, Ries, Coccaro, Shriberg, Bates, Jurafsky, Taylor, Martin, van EssDykema, Meteer, 2000</marker>
<rawString>Stolcke, A, K Ries, N Coccaro, E. Shriberg, R Bates, D Jurafsky, P Taylor, R Martin, C van EssDykema, &amp; M Meteer. 2000. Dialogue Act Modelling for Automatic Tagging and Recognition of Conversational Speech. Computational Linguistics 26(3):339-373.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>