<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.976739">
Pseudo-word for Phrase-based Machine Translation
</title>
<author confidence="0.989224">
Xiangyu Duan Min Zhang Haizhou Li
</author>
<affiliation confidence="0.980299">
Institute for Infocomm Research, A-STAR, Singapore
</affiliation>
<email confidence="0.971823">
{Xduan, mzhang, hli}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.993586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99936805">
The pipeline of most Phrase-Based Statistical
Machine Translation (PB-SMT) systems starts
from automatically word aligned parallel cor-
pus. But word appears to be too fine-grained
in some cases such as non-compositional
phrasal equivalences, where no clear word
alignments exist. Using words as inputs to PB-
SMT pipeline has inborn deficiency. This pa-
per proposes pseudo-word as a new start point
for PB-SMT pipeline. Pseudo-word is a kind
of basic multi-word expression that character-
izes minimal sequence of consecutive words in
sense of translation. By casting pseudo-word
searching problem into a parsing framework,
we search for pseudo-words in a monolingual
way and a bilingual synchronous way. Ex-
periments show that pseudo-word significantly
outperforms word for PB-SMT model in both
travel translation domain and news translation
domain.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999885">
The pipeline of most Phrase-Based Statistical
Machine Translation (PB-SMT) systems starts
from automatically word aligned parallel corpus
generated from word-based models (Brown et al.,
1993), proceeds with step of induction of phrase
table (Koehn et al., 2003) or synchronous gram-
mar (Chiang, 2007) and with model weights tun-
ing step. Words are taken as inputs to PB-SMT at
the very beginning of the pipeline. But there is a
deficiency in such manner that word is too fine-
grained in some cases such as non-compositional
phrasal equivalences, where clear word align-
ments do not exist. For example in Chinese-to-
English translation, “tH” and “would like to”
constitute a 1-to-n phrasal equivalence, “多少
钱” and “how much is it” constitute a m-to-n
phrasal equivalence. No clear word alignments
are there in such phrasal equivalences. Moreover,
should basic translational unit be word or coarse-
grained multi-word is an open problem for opti-
mizing SMT models.
Some researchers have explored coarse-
grained translational unit for machine translation.
Marcu and Wong (2002) attempted to directly
learn phrasal alignments instead of word align-
ments. But computational complexity is prohibi-
tively high for the exponentially large number of
decompositions of a sentence pair into phrase
pairs. Cherry and Lin (2007) and Zhang et al.
(2008) used synchronous ITG (Wu, 1997) and
constraints to find non-compositional phrasal
equivalences, but they suffered from intractable
estimation problem. Blunsom et al. (2008; 2009)
induced phrasal synchronous grammar, which
aimed at finding hierarchical phrasal equiva-
lences.
Another direction of questioning word as basic
translational unit is to directly question word
segmentation on languages where word bounda-
ries are not orthographically marked. In Chinese-
to-English translation task where Chinese word
boundaries are not marked, Xu et al. (2004) used
word aligner to build a Chinese dictionary to re-
segment Chinese sentence. Xu et al. (2008) used
a Bayesian semi-supervised method that com-
bines Chinese word segmentation model and
Chinese-to-English translation model to derive a
Chinese segmentation suitable for machine trans-
lation. There are also researches focusing on the
impact of various segmentation tools on machine
translation (Ma et al. 2007; Chang et al. 2008;
Zhang et al. 2008). Since there are many 1-to-n
phrasal equivalences in Chinese-to-English trans-
lation (Ma and Way. 2009), only focusing on
Chinese word as basic translational unit is not
adequate to model 1-to-n translations. Ma and
Way (2009) tackle this problem by using word
aligner to bootstrap bilingual segmentation suit-
able for machine translation. Lambert and
Banchs (2005) detect bilingual multi-word ex-
</bodyText>
<page confidence="0.962891">
148
</page>
<note confidence="0.9446955">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999492466666667">
pressions by monotonically segmenting a given
Spanish-English sentence pair into bilingual
units, where word aligner is also used.
IBM model 3, 4, 5 (Brown et al., 1993) and
Deng and Byrne (2005) are another kind of re-
lated works that allow 1-to-n alignments, but
they rarely questioned if such alignments exist in
word units level, that is, they rarely questioned
word as basic translational unit. Moreover, m-to-
n alignments were not modeled.
This paper focuses on determining the basic
translational units on both language sides without
using word aligner before feeding them into PB-
SMT pipeline. We call such basic translational
unit as pseudo-word to differentiate with word.
Pseudo-word is a kind of multi-word expression
(includes both unary word and multi-word).
Pseudo-word searching problem is the same to
decomposition of a given sentence into pseudo-
words. We assume that such decomposition is in
the Gibbs distribution. We use a measurement,
which characterizes pseudo-word as minimal
sequence of consecutive words in sense of trans-
lation, as potential function in Gibbs distribution.
Note that the number of decomposition of one
sentence into pseudo-words grows exponentially
with sentence length. By fitting decomposition
problem into parsing framework, we can find
optimal pseudo-word sequence in polynomial
time. Then we feed pseudo-words into PB-SMT
pipeline, and find that pseudo-words as basic
translational units improve translation perform-
ance over words as basic translational units. Fur-
ther experiments of removing the power of
higher order language model and longer max
phrase length, which are inherent in pseudo-
words, show that pseudo-words still improve
translational performance significantly over
unary words.
This paper is structured as follows: In section
2, we define the task of searching for pseudo-
words and its solution. We present experimental
results and analyses of using pseudo-words in
PB-SMT model in section 3. The conclusion is
presented at section 4.
</bodyText>
<sectionHeader confidence="0.976548" genericHeader="method">
2 Searching for Pseudo-words
</sectionHeader>
<bodyText confidence="0.9992756">
Pseudo-word searching problem is equal to de-
composition of a given sentence into pseudo-
words. We assume that the distribution of such
decomposition is in the form of Gibbs distribu-
tion as below:
</bodyText>
<equation confidence="0.97508775">
1
P(Y  |X) = exp( ∑ Sigy ) (1)
Z k
X k
</equation>
<bodyText confidence="0.97685275">
where X denotes the sentence, Y denotes a de-
composition of X. Sig function acts as potential
function on each multi-word yk, and ZX acts as
partition function. Note that the number of yk is
not fixed given X because X can be decomposed
into various number of multi-words.
Given X, ZX is fixed, so searching for optimal
decomposition is as below:
</bodyText>
<equation confidence="0.9998515">
Y = ARGMAXP(Y  |X) = ARGMAX∑Sigyk
Y Y K 1 k
</equation>
<bodyText confidence="0.999988363636364">
where Y1K denotes K multi-word units from de-
composition of X. A multi-word sequence with
maximal sum of Sig function values is the search
target — pseudo-word sequence. From (2) we
can see that Sig function is vital for pseudo-word
searching. In this paper Sig function calculates
sequence significance which is proposed to char-
acterize pseudo-word as minimal sequence of
consecutive words in sense of translation. The
detail of sequence significance is described in the
following section.
</bodyText>
<subsectionHeader confidence="0.998769">
2.1 Sequence Significance
</subsectionHeader>
<bodyText confidence="0.99876975">
Two kinds of definitions of sequence signifi-
cance are proposed. One is monolingual se-
quence significance. X and Y are monolingual
sentence and monolingual multi-words respec-
tively in this monolingual scenario. The other is
bilingual sequence significance. X and Y are sen-
tence pair and multi-word pairs respectively in
this bilingual scenario.
</bodyText>
<subsectionHeader confidence="0.965114">
2.1.1 Monolingual Sequence Significance
</subsectionHeader>
<bodyText confidence="0.999742111111111">
Given a sentence w1, ..., wn, where wi denotes
unary word, monolingual sequence significance
is defined as:
where Freqi, j (i≤j) represents frequency of word
sequence wi, ..., wj in the corpus, Sigi, j repre-
sents monolingual sequence significance of a
word sequence wi, ..., wj. We also denote word
sequence wi, ..., wj as span[i, j], whole sentence
as span[1, n]. Each span is also a multi-word ex-
pression.
Monolingual sequence significance of span[i, j]
is proportional to span[i, j]’s frequency, while is
inversely proportion to frequency of expanded
span (span[i-1, j+1]). Such definition character-
izes minimal sequence of consecutive words
which we are looking for. Our target is to find
pseudo-word sequence which has maximal sum
of spans’ significances:
</bodyText>
<equation confidence="0.972470380952381">
Sig = (3)
i j
Freqi j
,
, Freqi
1
−
+
1,
j
(2)
149
1 Sig span
(4)
k
pw 1
K
span 1
K = ARGMAX
K
∑ k=
</equation>
<bodyText confidence="0.999297764705882">
where pw denotes pseudo-word, K is equal to or
less than sentence’s length. spank is the kth span
of K spans span1 K. Equation (4) is the rewrite of
equation (2) in monolingual scenario. Searching
for pseudo-words pw1K is the same to finding
optimal segmentation of a sentence into K seg-
ments span1K (K is a variable too). Details of
searching algorithm are described in section
2.2.1.
We firstly search for monolingual pseudo-
words on source and target side individually.
Then we apply word alignment techniques to
build pseudo-word alignments. We argue that
word alignment techniques will work fine if non-
existent word alignments in such as non-
compositional phrasal equivalences have been
filtered by pseudo-words.
</bodyText>
<subsectionHeader confidence="0.950107">
2.1.2 Bilingual Sequence Significance
</subsectionHeader>
<bodyText confidence="0.999942782608696">
Bilingual sequence significance is proposed to
characterize pseudo-word pairs. Co-occurrence
of sequences on both language sides is used to
define bilingual sequence significance. Given a
bilingual sequence pair: span-pair[is, js, it, jt]
(source side span[is, js] and target side span[it, jt]),
bilingual sequence significance is defined as be-
low:
where Freq denotes the frequency of a span-pair.
Bilingual sequence significance is an extension
of monolingual sequence significance. Its value
is proportional to frequency of span-pair[is, js, it,
jt], while is inversely proportional to frequency
of expanded span-pair[is-1, js+1, it-1, jt+1].
Pseudo-word pairs of one sentence pair are such
pairs that maximize the sum of span-pairs’ bilin-
gual sequence significances:
pwp represents pseudo-word pair. Equation (6) is
the rewrite of equation (2) in bilingual scenario.
Searching for pseudo-word pairs pwp1K is equal
to bilingual segmentation of a sentence pair into
optimal span-pair1 K. Details of searching algo-
rithm are presented in section 2.2.2.
</bodyText>
<subsectionHeader confidence="0.961763">
2.2 Algorithms of Searching for Pseudo-
words
</subsectionHeader>
<bodyText confidence="0.999984692307692">
Pseudo-word searching problem is equal to de-
composition of a sentence into pseudo-words.
But the number of possible decompositions of
the sentence grows exponentially with the sen-
tence length in both monolingual scenario and
bilingual scenario. By casting such decomposi-
tion problem into parsing framework, we can
find pseudo-word sequence in polynomial time.
According to the two scenarios, searching for
pseudo-words can be performed in a monolin-
gual way and a synchronous way. Details of the
two kinds of searching algorithms are described
in the following two sections.
</bodyText>
<subsectionHeader confidence="0.9845525">
2.2.1 Algorithm of Searching for Monolin-
gual Pseudo-words (SMP)
</subsectionHeader>
<bodyText confidence="0.9932866">
Searching for monolingual pseudo-words is
based on the computation of monolingual se-
quence significance. Figure 1 presents the search
algorithm. It is performed in a way similar to
CKY (Cocke-Kasami-Younger) parser.
</bodyText>
<equation confidence="0.860952">
Initialization: Wi, i = Sigi, i;
Wi, j = 0, (i≠j);
</equation>
<listItem confidence="0.8812232">
1: for d = 2 ... n do
2: for all i, j s.t. j-i=d-1 do
3: for k = i ... j – 1 do
4: v = Wi, k + Wk+1, j
5: if v &gt; Wi, j then
</listItem>
<equation confidence="0.65710025">
6: Wi, j = v;
7: u = Sigi, j
8: if u &gt; Wi, j then
9: Wi, j = u;
</equation>
<figureCaption confidence="0.9989235">
Figure 1. Algorithm of searching for monolingual
pseudo-words (SMP).
</figureCaption>
<bodyText confidence="0.9999485">
In this algorithm, Wi, j records maximal sum of
monolingual sequence significances of sub spans
of span[i, j]. During initialization, Wi, i is initial-
ized as Sigi,i (note that this sequence is word wi
only). For all spans that have more than one
word (i≠j), Wi, j is initialized as zero.
In the main algorithm, d represents span’s
length, ranging from 2 to n, i represents start po-
sition of a span, j represents end position of a
span, k represents decomposition position of
span[i,j]. For span[i, j], Wi, j is updated if higher
sum of monolingual sequence significances is
found.
The algorithm is performed in a bottom-up
way. Small span’s computation is first. After
maximal sum of significances is found in small
spans, big span’s computation, which uses small
spans’ maximal sum, is continued. Maximal sum
of significances for whole sentence (W1,n, n is
sentence’s length) is guaranteed in this way, and
optimal decomposition is obtained correspond-
ingly.
</bodyText>
<equation confidence="0.9899796875">
Freqi j i j
s s t t
, , ,
Sig = (5)
i j i j Freq
s s t t
, , ,
i s
1,js +1,it −1,jt + 1
K K
= ARGMAX ∑ = 1 Sig
k span −
pwp 1 K
span pair
− 1
pairk (6)
</equation>
<page confidence="0.969976">
150
</page>
<bodyText confidence="0.99995">
The method of fitting the decomposition prob-
lem into CKY parsing framework is located at
steps 7-9. After steps 3-6, all possible decompo-
sitions of span[i, j] are explored and Wi, j of op-
timal decomposition of span[i, j] is recorded.
Then monolingual sequence significance Sigi,j of
span[i, j] is computed at step 7, and it is com-
pared to Wi, j at step 8. Update of Wi, j is taken at
step 9 if Sigi,j is bigger than Wi, j, which indicates
that span[i, j] is non-decomposable. Thus
whether span[i, j] should be non-decomposable
or not is decided through steps 7-9.
</bodyText>
<subsectionHeader confidence="0.992538">
2.2.2 Algorithm of Synchronous Searching
for Pseudo-words (SSP)
</subsectionHeader>
<bodyText confidence="0.99932">
Synchronous searching for pseudo-words utilizes
bilingual sequence significance. Figure 2 pre-
sents the search algorithm. It is similar to ITG
(Wu, 1997), except that it has no production
rules and non-terminal nodes of a synchronous
grammar. What it cares about is the span-pairs
that maximize the sum of bilingual sequence sig-
nificances.
</bodyText>
<equation confidence="0.9920955">
Initialization: if is = js or it = jt then
Wi ,j, i ,j = Sig
s s t t
else
Wi , j , i , j = 0 ;
s s t
</equation>
<listItem confidence="0.91134575">
1: for ds = 2 ... ns, dt = 2 ... nt do
2: for all is, js, it, jt s.t. js-is=ds-1 and jt-it=dt-1 do
3: for ks = is ... js – 1, kt = it ... jt – 1 do
4: v = max{ Wi ,k,i ,k +W k +1,j ,k +1,j ,
</listItem>
<equation confidence="0.98717475">
s s t t s s t t
Wi, k ,k +1,j + Wk +1,j ,i, k
s s t t s s t t }
5: if v &gt; W then
i , j ,i , jt
s s t
9: W = u;
i , j , i , j s s t t
</equation>
<figureCaption confidence="0.991494">
Figure 2. Algorithm of Synchronous Searching for
Pseudo-words(SSP).
</figureCaption>
<bodyText confidence="0.930068758620689">
In the algorithm, Wi s ,js,it, jt records maximal
sum of bilingual sequence significances of sub
span-pairs of span-pair[is, js, it, jt]. For 1-to-m
span-pairs, Ws are initialized as bilingual se-
quence significances of such span-pairs. For
other span-pairs, Ws are initialized as zero.
In the main algorithm, ds/dt denotes the length
of a span on source/target side, ranging from 2 to
ns/nt (source/target sentence’s length). is/it is the
start position of a span-pair on source/target side,
js/jt is the end position of a span-pair on
source/target side, ks/kt is the decomposition po-
sition of a span-pair[is, js, it, jt] on source/target
side.
Update steps in Figure 2 are similar to that of
Figure 1, except that the update is about span-
pairs, not monolingual spans. Reversed and non-
reversed alignments inside a span-pair are com-
pared at step 4. For span-pair[is, js, it, jt],
Wis ,js , it ,jt is updated at step 6 if higher sum of
bilingual sequence significances is found.
Fitting the bilingually searching for pseudo-
words into ITG framework is located at steps 7-9.
Steps 3-6 have explored all possible decomposi-
tions of span-pair[is, js, it, jt] and have recorded
maximal Wi i of these decompositions. Then
, j
bilingual sequence significance of span-pair[is, js,
it, jt] is computed at step 7. It is compared to
</bodyText>
<equation confidence="0.856638142857143">
Wi ,j ,i ,j
s s t t at step 8. Update is taken at step 9 if
bilingual sequence significance of span-pair[is, js,
it, jt] is bigger than Wi , which indicates that
s s t t
, j , i , j
span-pair[is, js, it, jt] is non-decomposable.
</equation>
<bodyText confidence="0.9828809">
Whether the span-pair[is, js, it, jt] should be non-
decomposable or not is decided through steps 7-
9.
In addition to the initialization step, all span-
pairs’ bilingual sequence significances are com-
puted. Maximal sum of bilingual sequence sig-
nificances for one sentence pair is guaranteed
through this bottom-up way, and the optimal de-
composition of the sentence pair is obtained cor-
respondingly.
</bodyText>
<listItem confidence="0.9340925">
• Algorithm of Excluded Synchronous
Searching for Pseudo-words (ESSP)
</listItem>
<bodyText confidence="0.9999005">
The algorithm of SSP in Figure 2 explores all
span-pairs, but it neglects NULL alignments,
where words and “empty” word are aligned. In
fact, SSP requires that all parts of a sentence pair
should be aligned. This requirement is too strong
because NULL alignments are very common in
many language pairs. In SSP, words that should
be aligned to “empty” word are programmed to
be aligned to real words.
Unlike most word alignment methods (Och
and Ney, 2003) that add “empty” word to ac-
count for NULL alignment entries, we propose a
method to naturally exclude such NULL align-
ments. We call this method as Excluded Syn-
chronous Searching for Pseudo-words (ESSP).
The main difference between ESSP and SSP is
in steps 3-6 in Figure 3. We illustrate Figure 3’s
span-pair configuration in Figure 4.
</bodyText>
<equation confidence="0.854254135135135">
7: W = v;
8: u = Sigis ,js,it ,jt
9: if u &gt; W then
ijt
s js it
, ,
,
i ,jt
s j s i
, ,
t
i s , j s , i t , j t ;
151
Initialization: if is = js or it = jt then
W = Sig ;
i j i j i j i j
s s t t
, , , s s t t
, ,
else
Wi , j , i , j = 0 ;
s s t t
1: for ds = 2 ... ns, dt = 2 ... nt do
2: for all is, js, it, jt s.t. js-is=ds-1 and jt-it=dt-1 do
3: for ks1=is+1 ... js, ks2=ks1-1 ... js-1
kt1=it+1 ... jt, kt2=kt1-1 ... jt-1 do
4: v = max{Wi , k 1 , i , k 1W k 1,j, k 1, j
+ ,
− −
s s 1 +
t t 1 s2+ s t2 t
Wis,ks1−1,kt2+1,jt + Wks2+1,jdt,kt1−1 }
5: if v &gt; W then
i s j s i
, , t ,j t
9: W = u;
i s , j s , i t , j t
</equation>
<figureCaption confidence="0.998137">
Figure 3. Algorithm of Excluded Synchronous
</figureCaption>
<bodyText confidence="0.9602732">
Searching for Pseudo-words (ESSP).
The solid boxes in Figure 4 represent excluded
parts of span-pair[is, js, it, jt] in ESSP. Note that,
in SSP, there is no excluded part, that is, ks1=ks2
and kt1=kt2.
We can see that in Figure 4, each monolingual
span is configured into three parts, for example:
span[is, ks1-1], span[ks1, ks2] and span[ks2+1, js]
on source language side. ks1 and ks2 are two new
variables gliding between is and js, span[ks1, ks2]
is source side excluded part of span-pair[is, js, it,
jt]. Bilingual sequence significance is computed
only on pairs of blank boxes, solid boxes are ex-
cluded in this computation to represent NULL
alignment cases.
</bodyText>
<figureCaption confidence="0.996201">
Figure 4. Illustration of excluded configuration.
</figureCaption>
<bodyText confidence="0.999859823529412">
Note that, in Figure 4, solid box on either lan-
guage side can be void (i.e., length is zero) if
there is no NULL alignment on its side. If all
solid boxes are shrunk into void, algorithm of
ESSP is the same to SSP.
Generally, span length of NULL alignment is
not very long, so we can set a length threshold
for NULL alignments, eg. ks2-ks1≤EL, where EL
denotes Excluded Length threshold. Computa-
tional complexity of the ESSP remains the same
to SSP’s complexity O(ns3.nt3), except multiply a
constant EL2.
There is one kind of NULL alignments that
ESSP can not consider. Since we limit excluded
parts in the middle of a span-pair, the algorithm
will end without considering boundary parts of a
sentence pair as NULL alignments.
</bodyText>
<sectionHeader confidence="0.998551" genericHeader="evaluation">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.998271423076923">
In our experiments, pseudo-words are fed into
PB-SMT pipeline. The pipeline uses GIZA++
model 4 (Brown et al., 1993; Och and Ney, 2003)
for pseudo-word alignment, uses Moses (Koehn
et al., 2007) as phrase-based decoder, uses the
SRI Language Modeling Toolkit to train lan-
guage model with modified Kneser-Ney smooth-
ing (Kneser and Ney 1995; Chen and Goodman
1998). Note that MERT (Och, 2003) is still on
original words of target language. In our experi-
ments, pseudo-word length is limited to no more
than six unary words on both sides of the lan-
guage pair.
We conduct experiments on Chinese-to-
English machine translation. Two data sets are
adopted, one is small corpus of IWSLT-2008
BTEC task of spoken language translation in
travel domain (Paul, 2008), the other is large
corpus in news domain, which consists Hong
Kong News (LDC2004T08), Sinorama Magazine
(LDC2005T10), FBIS (LDC2003E14), Xinhua
(LDC2002E18), Chinese News Translation
(LDC2005T06), Chinese Treebank
(LDC2003E07), Multiple Translation Chinese
(LDC2004T07). Table 1 lists statistics of the
corpus used in these experiments.
</bodyText>
<footnote confidence="0.5541748">
large
Ch — En
1,239k
31.7m 35.5m
25.6 28.6
</footnote>
<tableCaption confidence="0.996802">
Table 1. Statistics of corpora, “Ch” denotes Chinese,
“En” denotes English, “Sent.” row is the number of
sentence pairs, “word” row is the number of words,
“ASL” denotes average sentence length.
</tableCaption>
<figure confidence="0.997584">
Sig
is,js,it,jt
7: u =
6: W = v;
i jt
s js it
, ,
,
8: if u &gt; W then
i i t , j t
s j s
,
,
is ks1 ks2 js
it kt1 kt2 jt
a) non-reversed
is ks1 ks2 js
it kt1 kt2 jt
b) reversed
small
Ch — En
23k
190k 213k
8.3 9.2
Sent.
word
ASL
</figure>
<page confidence="0.990182">
152
</page>
<bodyText confidence="0.999890176470588">
For small corpus, we use CSTAR03 as devel-
opment set, use IWSLT08 official test set for test.
A 5-gram language model is trained on English
side of parallel corpus. For large corpus, we use
NIST02 as development set, use NIST03 as test
set. Xinhua portion of the English Gigaword3
corpus is used together with English side of large
corpus to train a 4-gram language model.
Experimental results are evaluated by case-
insensitive BLEU-4 (Papineni et al., 2001).
Closest reference sentence length is used for
brevity penalty. Additionally, NIST score (Dod-
dington, 2002) and METEOR (Banerjee and La-
vie, 2005) are also used to check the consistency
of experimental results. Statistical significance in
BLEU score differences was tested by paired
bootstrap re-sampling (Koehn, 2004).
</bodyText>
<subsectionHeader confidence="0.996404">
3.1 Baseline Performance
</subsectionHeader>
<bodyText confidence="0.998518857142857">
Our baseline system feeds word into PB-SMT
pipeline. We use GIZA++ model 4 for word
alignment, use Moses for phrase-based decoding.
The setting of language model order for each
corpus is not changed. Baseline performances on
test sets of small corpus and large corpus are re-
ported in table 2.
</bodyText>
<table confidence="0.99827125">
small Large
BLEU 0.4029 0.3146
NIST 7.0419 8.8462
METEOR 0.5785 0.5335
</table>
<tableCaption confidence="0.9990465">
Table 2. Baseline performances on test sets of small
corpus and large corpus.
</tableCaption>
<subsectionHeader confidence="0.998474">
3.2 Pseudo-word Unpacking
</subsectionHeader>
<bodyText confidence="0.9999365">
Because pseudo-word is a kind of multi-word
expression, it has inborn advantage of higher
language model order and longer max phrase
length over unary word. To see if such inborn
advantage is the main contribution to the per-
formance or not, we unpack pseudo-word into
words after GIZA++ aligning. Aligned pseudo-
words are unpacked into m×n word alignments.
PB-SMT pipeline is executed thereafter. The ad-
vantage of longer max phrase length is removed
during phrase extraction, and the advantage of
higher order of language model is also removed
during decoding since we use language model
trained on unary words. Performances of pseudo-
word unpacking are reported in section 3.3.1 and
3.4.1. Ma and Way (2009) used the unpacking
after phrase extraction, then re-estimated phrase
translation probability and lexical reordering
model. The advantage of longer max phrase
length is still used in their method.
</bodyText>
<subsectionHeader confidence="0.97946">
3.3 Pseudo-word Performances on Small
Corpus
</subsectionHeader>
<bodyText confidence="0.99990375">
Table 3 presents performances of SMP, SSP,
ESSP on small data set. pwchpwen denotes that
pseudo-words are on both language side of train-
ing data, and they are input strings during devel-
opment and testing, and translations are also
pseudo-words, which will be converted to words
as final output. wchpwen/pwchwen denotes that
pseudo-words are adopted only on Eng-
lish/Chinese side of the data set.
We can see from table 3 that, ESSP attains the
best performance, while SSP attains the worst
performance. This shows that excluding NULL
alignments in synchronous searching for pseudo-
words is effective. SSP puts overly strong align-
ment constraints on parallel corpus, which im-
pacts performance dramatically. ESSP is superior
to SMP indicating that bilingually motivated
searching for pseudo-words is more effective.
Both SMP and ESSP outperform baseline consis-
tently in BLEU, NIST and METEOR.
There is a common phenomenon among SMP,
SSP and ESSP. wchpwen always performs better
than the other two cases. It seems that Chinese
word prefers to have English pseudo-word
equivalence which has more than or equal to one
word. pwchpwen in ESSP performs similar to the
baseline, which reflects that our direct pseudo-
word pairs do not work very well with GIZA++
alignments. Such disagreement is weakened by
using pseudo-words on only one language side
(wchpwen or pwchwen), while the advantage of
pseudo-words is still leveraged in the alignments.
Best ESSP (wchpwen) is significantly better
than baseline (p&lt;0.01) in BLEU score, best SMP
(wchpwen) is significantly better than baseline
(p&lt;0.05) in BLEU score. This indicates that
pseudo-words, through either monolingual
searching or synchronous searching, are more
effective than words as to being basic transla-
tional units.
Figure 5 illustrates examples of pseudo-words
of one Chinese-to-English sentence pair. Gold
standard word alignments are shown at the bot-
tom of figure 5. We can see that “front desk” is
recognized as one pseudo-word in ESSP. Be-
cause SMP performs monolingually, it can not
consider “前台” and “front desk” simultaneously.
SMP only detects frequent monolingual multi-
words as pseudo-words. SSP has a strong con-
straint that all parts of a sentence pair should be
aligned, so source sentence and target sentence
have same length after merging words into
</bodyText>
<page confidence="0.997061">
153
</page>
<table confidence="0.9998134">
SMP SSP ESSP baseline
pwchpwen wchpwen pwchwen pwchpwen wchpwen pwchwen pwchpwen wchpwen pwchwen
BLEU 0.3996 0.4155 0.4024 0.3184 0.3661 0.3552 0.3998 0.4229 0.4147 0.4029
NIST 7.4711 7.6452 7.6186 6.4099 6.9284 6.8012 7.1665 7.4373 7.4235 7.0419
METEOR 0.5900 0.6008 0.6000 0.5255 0.5569 0.5454 0.5739 0.5963 0.5891 0.5785
</table>
<tableCaption confidence="0.99934">
Table 3. Performance of using pseudo-words on small data.
</tableCaption>
<bodyText confidence="0.6001855">
pseudo-words. We can see that too many pseudo-
words are detected by SSP.
</bodyText>
<figureCaption confidence="0.99899925">
Figure 5. Outputs of the three algorithms ESSP,
SMP and SSP on one sentence pair and gold standard
word alignments. Words in one pseudo-word are con-
catenated by “_”.
</figureCaption>
<bodyText confidence="0.975047666666667">
pseudo-word itself as basic translational unit,
does not rely very much on higher language
model order or longer max phrase length setting.
</bodyText>
<subsectionHeader confidence="0.9903075">
3.4 Pseudo-word Performances on Large
Corpus
</subsectionHeader>
<bodyText confidence="0.999840421052632">
Table 5 lists the performance of using pseudo-
words on large corpus. We apply SMP on this
task. ESSP is not applied because of its high
computational complexity. Table 5 shows that all
three configurations (pwchpwen, wchpwen, pwchwen)
of SMP outperform the baseline. If we go back to
the definition of sequence significance, we can
see that it is a data-driven definition that utilizes
corpus frequencies. Corpus scale has an influ-
ence on computation of sequence significance in
long sentences which appear frequently in news
domain. SMP benefits from large corpus, and
wchpwen is significantly better than baseline
(p&lt;0.01). Similar to performances on small cor-
pus, wchpwen always performs better than the
other two cases, which indicates that Chinese
word prefers to have English pseudo-word
equivalence which has more than or equal to one
word.
</bodyText>
<equation confidence="0.8508734">
前台 的 那个 人 真 粗鲁 。 ESSP
The guy at the front_desk is pretty rude .
前台 的 那个 人 真 粗鲁 。 SMP
The guy at the front desk is pretty rude .
前台 的 那个 人 真 粗鲁 。 SSP
</equation>
<bodyText confidence="0.8490625">
The guy_at the front_desk is pretty_rude .
前台 的 那个 人 真 粗鲁 。
The guy at the front desk is pretty rude .
Gold standard word alignments
</bodyText>
<subsectionHeader confidence="0.4148215">
3.3.1 Pseudo-word Unpacking Perform-
ances on Small Corpus
</subsectionHeader>
<bodyText confidence="0.7822565">
We test pseudo-word unpacking in ESSP. Table
4 presents its performances on small corpus.
</bodyText>
<table confidence="0.9953838">
unpackingESSP pwchwen baseline
pwchpwen wchpwen
BLEU 0.4097 0.4182 0.4031 0.4029
NIST 7.5547 7.2893 7.2670 7.0419
METEOR 0.5951 0.5874 0.5846 0.5785
</table>
<tableCaption confidence="0.9926095">
Table 4. Performances of pseudo-word unpacking on
small corpus.
</tableCaption>
<bodyText confidence="0.999886285714286">
We can see that pseudo-word unpacking sig-
nificantly outperforms baseline. wchpwen is sig-
nificantly better than baseline (p&lt;0.04) in BLEU
score. Unpacked pseudo-word performs com-
paratively with pseudo-word without unpacking.
There is no statistical difference between them. It
shows that the improvement derives from
</bodyText>
<table confidence="0.998976">
pwchpwen SMP pwchwen baseline
wchpwen
BLEU 0.3185 0.3230 0.3166 0.3146
NIST 8.9216 9.0447 8.9210 8.8462
METEOR 0.5402 0.5489 0.5435 0.5335
</table>
<tableCaption confidence="0.999661">
Table 5. Performance of using pseudo-words on large
</tableCaption>
<bodyText confidence="0.46162">
corpus.
</bodyText>
<subsectionHeader confidence="0.618205">
3.4.1 Pseudo-word Unpacking Perform-
ances on Large Corpus
</subsectionHeader>
<bodyText confidence="0.994200909090909">
Table 6 presents pseudo-word unpacking per-
formances on large corpus. All three configura-
tions improve performance over baseline after
pseudo-word unpacking. pwchpwen attains the
best BLEU among the three configurations, and
is significantly better than baseline (p&lt;0.03).
wchpwen is also significantly better than baseline
(p&lt;0.04). By comparing table 6 with table 5, we
can see that unpacked pseudo-word performs
comparatively with pseudo-word without un-
packing. There is no statistical difference be-
</bodyText>
<page confidence="0.999263">
154
</page>
<bodyText confidence="0.999642888888889">
tween them. It shows that the improvement de-
rives from pseudo-word itself as basic transla-
tional unit, does not rely very much on higher
language model order or longer max phrase
length setting. In fact, slight improvement in
pwchpwen and pwchwen is seen after pseudo-word
unpacking, which indicates that higher language
model order and longer max phrase length im-
pact the performance in these two configurations.
</bodyText>
<table confidence="0.9980054">
UnpackingSMP pwchwen Baseline
pwchpwen wchpwen
BLEU 0.3219 0.3192 0.3187 0.3146
NIST 8.9458 8.9325 8.9801 8.8462
METEOR 0.5429 0.5424 0.5411 0.5335
</table>
<tableCaption confidence="0.9902225">
Table 6. Performance of pseudo-word unpacking on
large corpus.
</tableCaption>
<subsectionHeader confidence="0.918034">
3.5 Comparison to English Chunking
</subsectionHeader>
<bodyText confidence="0.9999522">
English chunking is experimented to compare
with pseudo-word. We use FlexCRFs (Xuan-
Hieu Phan et al., 2005) to get English chunks.
Since there is no standard Chinese chunking data
and code, only English chunking is executed.
The experimental results show that English
chunking performs far below baseline, usually 8
absolute BLEU points below. It shows that sim-
ple chunks are not suitable for being basic trans-
lational units.
</bodyText>
<sectionHeader confidence="0.999375" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999993368421053">
We have presented pseudo-word as a novel ma-
chine translational unit for phrase-based machine
translation. It is proposed to replace too fine-
grained word as basic translational unit. Pseudo-
word is a kind of basic multi-word expression
that characterizes minimal sequence of consecu-
tive words in sense of translation. By casting
pseudo-word searching problem into a parsing
framework, we search for pseudo-words in poly-
nomial time. Experimental results of Chinese-to-
English translation task show that, in phrase-
based machine translation model, pseudo-word
performs significantly better than word in both
spoken language translation domain and news
domain. Removing the power of higher order
language model and longer max phrase length,
which are inherent in pseudo-words, shows that
pseudo-words still improve translational per-
formance significantly over unary words.
</bodyText>
<sectionHeader confidence="0.998354" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999801943396227">
S. Banerjee, and A. Lavie. 2005. METEOR: An
automatic metric for MT evaluation with im-
proved correlation with human judgments. In
Proceedings of the ACL Workshop on Intrinsic and
Extrinsic Evaluation Measures for Machine Trans-
lation and/or Summarization (ACL’05). 65–72.
P. Blunsom, T. Cohn, C. Dyer, M. Osborne. 2009. A
Gibbs Sampler for Phrasal Synchronous
Grammar Induction. In Proceedings of ACL-
IJCNLP, Singapore.
P. Blunsom, T. Cohn, M. Osborne. 2008. Bayesian
synchronous grammar induction. In Proceed-
ings of NIPS 21, Vancouver, Canada.
P. Brown, S. Della Pietra, V. Della Pietra, and R.
Mercer. 1993. The mathematics of machine
translation: Parameter estimation. Computa-
tional Linguistics, 19:263–312.
P.-C. Chang, M. Galley, and C. D. Manning. 2008.
Optimizing Chinese word segmentation for
machine translation performance. In Proceed-
ings of the 3rd Workshop on Statistical Machine
Translation (SMT’08). 224–232.
Chen, Stanley F. and Joshua Goodman. 1998. An
empirical study of smoothing techniques for
language modeling. Technical Report TR-10-98,
Harvard University Center for Research in Com-
puting Technology.
C. Cherry, D. Lin. 2007. Inversion transduction
grammar for joint phrasal translation model-
ing. In Proc. of the HLTNAACL Workshop on
Syntax and Structure in Statistical Translation
(SSST 2007), Rochester, USA.
D. Chiang. 2007. Hierarchical phrase-based
translation.Computational Linguistics, 33(2):201–
228.
Y. Deng and W. Byrne. 2005. HMM word and
phrase alignment for statistical machine trans-
lation. In Proc. of HLT-EMNLP, pages 169–176.
G. Doddington. 2002. Automatic evaluation of ma-
chine translation quality using n-gram cooc-
currence statistics. In Proceedings of the 2nd In-
ternational Conference on Human Language Tech-
nology (HLT’02). 138–145.
Kneser, Reinhard and Hermann Ney. 1995. Improved
backing-off for M-gram language modeling. In
Proceedings of the IEEE International Conference
on Acoustics, Speech, and Signal Processing,
pages 181–184, Detroit, MI.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M.
Federico, N. Bertoldi, B. Cowan,W. Shen, C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
E. Herbst. 2007. Moses: Open source toolkit for
statistical machine translation. In Proc. of the
</reference>
<page confidence="0.986769">
155
</page>
<reference confidence="0.999667714285715">
45th Annual Meeting of the ACL (ACL-2007),
Prague.
P. Koehn, F. J. Och, D. Marcu. 2003. Statistical
phrasebased translation. In Proc. of the 3rd In-
ternational conference on Human Language Tech-
nology Research and 4th Annual Meeting of the
NAACL (HLT-NAACL 2003), 81–88, Edmonton,
Canada.
P. Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proceed-
ings of EMNLP.
P. Lambert and R. Banchs. 2005. Data Inferred
Multi-word Expressions for Statistical Ma-
chine Translation. In Proceedings of MT Summit
X.
Y. Ma, N. Stroppa, and A. Way. 2007. Bootstrap-
ping word alignment via word packing. In Pro-
ceedings of the 45th Annual Meeting of the Asso-
ciation of Computational Linguistics (ACL’07).
304–311.
Y. Ma, and A. Way. 2009. Bilingually Motivated
Word Segmentation for Statistical Machine
Translation. In ACM Transactions on Asian Lan-
guage Information Processing, 8(2).
D. Marcu,W.Wong. 2002. A phrase-based, joint
probability model for statistical machine
translation. In Proc. of the 2002 Conference on
Empirical Methods in Natural Language Process-
ing (EMNLP-2002), 133–139, Philadelphia. Asso-
ciation for Computational Linguistics.
F. J. Och. 2003. Minimum error rate training in
statistical machine translation. In Proc. of ACL,
pages 160–167.
F. J. Och and H. Ney. 2003. A systematic compari-
son of various statistical alignment models.
Computational Linguistics, 29(1):19–51.
Xuan-Hieu Phan, Le-Minh Nguyen, and Cam-Tu
Nguyen. 2005. FlexCRFs: Flexible Conditional
Random Field Toolkit, http://flexcrfs.sourceforge.
net
K. Papineni, S. Roukos, T. Ward, W. Zhu. 2001. Bleu:
a method for automatic evaluation of machine
translation, 2001.
M. Paul, 2008. Overview of the IWSLT 2008
evaluation campaign. In Proc. of Internationa
Workshop on Spoken Language Translation, 20-21
October 2008.
A. Stolcke. (2002). SRILM - an extensible lan-
guage modeling toolkit. In Proceedings of
ICSLP, Denver, Colorado.
D. Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel
corpora. Computational Linguistics, 23(3):377–
403.
J. Xu, Zens., and H. Ney. 2004. Do we need Chi-
nese word segmentation for statistical ma-
chine translation? In Proceedings of the ACL
Workshop on Chinese Language Processing
SIGHAN’04). 122–128.
J. Xu, J. Gao, K. Toutanova, and H. Ney. 2008.
Bayesian semi-supervised chinese word seg-
mentation for statistical machine translation.
In Proceedings of the 22nd International Confer-
ence on Computational Linguistics (COLING’08).
1017–1024.
H. Zhang, C. Quirk, R. C. Moore, D. Gildea. 2008.
Bayesian learning of non-compositional
phrases with synchronous parsing. In Proc. of
the 46th Annual Conference of the Association for
Computational Linguistics: Human Language
Technologies (ACL-08:HLT), 97–105, Columbus,
Ohio.
R. Zhang, K. Yasuda, and E. Sumita. 2008. Improved
statistical machine translation by multiple
Chinese word segmentation. In Proceedings of
the 3rd Workshop on Statistical Machine Transla-
tion (SMT’08). 216–223.
</reference>
<page confidence="0.998785">
156
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.401064">
<title confidence="0.999321">Pseudo-word for Phrase-based Machine Translation</title>
<author confidence="0.985201">Xiangyu Duan Min Zhang Haizhou Li</author>
<affiliation confidence="0.68823">for Infocomm Research, Singapore</affiliation>
<email confidence="0.694879">Xduan@i2r.a-star.edu.sg</email>
<email confidence="0.694879">mzhang@i2r.a-star.edu.sg</email>
<email confidence="0.694879">hli@i2r.a-star.edu.sg</email>
<abstract confidence="0.994779">The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus. But word appears to be too fine-grained in some cases such as non-compositional phrasal equivalences, where no clear word alignments exist. Using words as inputs to PB- SMT pipeline has inborn deficiency. This paper proposes pseudo-word as a new start point for PB-SMT pipeline. Pseudo-word is a kind of basic multi-word expression that characterizes minimal sequence of consecutive words in sense of translation. By casting pseudo-word searching problem into a parsing framework, we search for pseudo-words in a monolingual way and a bilingual synchronous way. Experiments show that pseudo-word significantly outperforms word for PB-SMT model in both travel translation domain and news translation domain.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>A Lavie</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with improved correlation with human judgments.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization (ACL’05).</booktitle>
<pages>65--72</pages>
<contexts>
<context position="21038" citStr="Banerjee and Lavie, 2005" startWordPosition="3625" endWordPosition="3629">9.2 Sent. word ASL 152 For small corpus, we use CSTAR03 as development set, use IWSLT08 official test set for test. A 5-gram language model is trained on English side of parallel corpus. For large corpus, we use NIST02 as development set, use NIST03 as test set. Xinhua portion of the English Gigaword3 corpus is used together with English side of large corpus to train a 4-gram language model. Experimental results are evaluated by caseinsensitive BLEU-4 (Papineni et al., 2001). Closest reference sentence length is used for brevity penalty. Additionally, NIST score (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) are also used to check the consistency of experimental results. Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004). 3.1 Baseline Performance Our baseline system feeds word into PB-SMT pipeline. We use GIZA++ model 4 for word alignment, use Moses for phrase-based decoding. The setting of language model order for each corpus is not changed. Baseline performances on test sets of small corpus and large corpus are reported in table 2. small Large BLEU 0.4029 0.3146 NIST 7.0419 8.8462 METEOR 0.5785 0.5335 Table 2. Baseline performances on tes</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>S. Banerjee, and A. Lavie. 2005. METEOR: An automatic metric for MT evaluation with improved correlation with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization (ACL’05). 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blunsom</author>
<author>T Cohn</author>
<author>C Dyer</author>
<author>M Osborne</author>
</authors>
<title>A Gibbs Sampler for Phrasal Synchronous Grammar Induction.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLIJCNLP,</booktitle>
<marker>Blunsom, Cohn, Dyer, Osborne, 2009</marker>
<rawString>P. Blunsom, T. Cohn, C. Dyer, M. Osborne. 2009. A Gibbs Sampler for Phrasal Synchronous Grammar Induction. In Proceedings of ACLIJCNLP, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blunsom</author>
<author>T Cohn</author>
<author>M Osborne</author>
</authors>
<title>Bayesian synchronous grammar induction.</title>
<date>2008</date>
<booktitle>In Proceedings of NIPS 21,</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2541" citStr="Blunsom et al. (2008" startWordPosition="375" endWordPosition="378"> or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation mode</context>
</contexts>
<marker>Blunsom, Cohn, Osborne, 2008</marker>
<rawString>P. Blunsom, T. Cohn, M. Osborne. 2008. Bayesian synchronous grammar induction. In Proceedings of NIPS 21, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--263</pages>
<contexts>
<context position="1232" citStr="Brown et al., 1993" startWordPosition="169" endWordPosition="172">a kind of basic multi-word expression that characterizes minimal sequence of consecutive words in sense of translation. By casting pseudo-word searching problem into a parsing framework, we search for pseudo-words in a monolingual way and a bilingual synchronous way. Experiments show that pseudo-word significantly outperforms word for PB-SMT model in both travel translation domain and news translation domain. 1 Introduction The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus generated from word-based models (Brown et al., 1993), proceeds with step of induction of phrase table (Koehn et al., 2003) or synchronous grammar (Chiang, 2007) and with model weights tuning step. Words are taken as inputs to PB-SMT at the very beginning of the pipeline. But there is a deficiency in such manner that word is too finegrained in some cases such as non-compositional phrasal equivalences, where clear word alignments do not exist. For example in Chinese-toEnglish translation, “tH” and “would like to” constitute a 1-to-n phrasal equivalence, “多少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments </context>
<context position="4121" citStr="Brown et al., 1993" startWordPosition="610" endWordPosition="613">s basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics pressions by monotonically segmenting a given Spanish-English sentence pair into bilingual units, where word aligner is also used. IBM model 3, 4, 5 (Brown et al., 1993) and Deng and Byrne (2005) are another kind of related works that allow 1-to-n alignments, but they rarely questioned if such alignments exist in word units level, that is, they rarely questioned word as basic translational unit. Moreover, m-ton alignments were not modeled. This paper focuses on determining the basic translational units on both language sides without using word aligner before feeding them into PBSMT pipeline. We call such basic translational unit as pseudo-word to differentiate with word. Pseudo-word is a kind of multi-word expression (includes both unary word and multi-word).</context>
<context position="18992" citStr="Brown et al., 1993" startWordPosition="3271" endWordPosition="3274">ment is not very long, so we can set a length threshold for NULL alignments, eg. ks2-ks1≤EL, where EL denotes Excluded Length threshold. Computational complexity of the ESSP remains the same to SSP’s complexity O(ns3.nt3), except multiply a constant EL2. There is one kind of NULL alignments that ESSP can not consider. Since we limit excluded parts in the middle of a span-pair, the algorithm will end without considering boundary parts of a sentence pair as NULL alignments. 3 Experiments and Results In our experiments, pseudo-words are fed into PB-SMT pipeline. The pipeline uses GIZA++ model 4 (Brown et al., 1993; Och and Ney, 2003) for pseudo-word alignment, uses Moses (Koehn et al., 2007) as phrase-based decoder, uses the SRI Language Modeling Toolkit to train language model with modified Kneser-Ney smoothing (Kneser and Ney 1995; Chen and Goodman 1998). Note that MERT (Och, 2003) is still on original words of target language. In our experiments, pseudo-word length is limited to no more than six unary words on both sides of the language pair. We conduct experiments on Chinese-toEnglish machine translation. Two data sets are adopted, one is small corpus of IWSLT-2008 BTEC task of spoken language tran</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19:263–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P-C Chang</author>
<author>M Galley</author>
<author>C D Manning</author>
</authors>
<title>Optimizing Chinese word segmentation for machine translation performance.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd Workshop on Statistical Machine Translation (SMT’08).</booktitle>
<pages>224--232</pages>
<contexts>
<context position="3346" citStr="Chang et al. 2008" startWordPosition="495" endWordPosition="498">tion word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Lingui</context>
</contexts>
<marker>Chang, Galley, Manning, 2008</marker>
<rawString>P.-C. Chang, M. Galley, and C. D. Manning. 2008. Optimizing Chinese word segmentation for machine translation performance. In Proceedings of the 3rd Workshop on Statistical Machine Translation (SMT’08). 224–232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<institution>Harvard University Center for Research in Computing Technology.</institution>
<contexts>
<context position="19239" citStr="Chen and Goodman 1998" startWordPosition="3311" endWordPosition="3314">nstant EL2. There is one kind of NULL alignments that ESSP can not consider. Since we limit excluded parts in the middle of a span-pair, the algorithm will end without considering boundary parts of a sentence pair as NULL alignments. 3 Experiments and Results In our experiments, pseudo-words are fed into PB-SMT pipeline. The pipeline uses GIZA++ model 4 (Brown et al., 1993; Och and Ney, 2003) for pseudo-word alignment, uses Moses (Koehn et al., 2007) as phrase-based decoder, uses the SRI Language Modeling Toolkit to train language model with modified Kneser-Ney smoothing (Kneser and Ney 1995; Chen and Goodman 1998). Note that MERT (Och, 2003) is still on original words of target language. In our experiments, pseudo-word length is limited to no more than six unary words on both sides of the language pair. We conduct experiments on Chinese-toEnglish machine translation. Two data sets are adopted, one is small corpus of IWSLT-2008 BTEC task of spoken language translation in travel domain (Paul, 2008), the other is large corpus in news domain, which consists Hong Kong News (LDC2004T08), Sinorama Magazine (LDC2005T10), FBIS (LDC2003E14), Xinhua (LDC2002E18), Chinese News Translation (LDC2005T06), Chinese Tre</context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Chen, Stanley F. and Joshua Goodman. 1998. An empirical study of smoothing techniques for language modeling. Technical Report TR-10-98, Harvard University Center for Research in Computing Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cherry</author>
<author>D Lin</author>
</authors>
<title>Inversion transduction grammar for joint phrasal translation modeling.</title>
<date>2007</date>
<booktitle>In Proc. of the HLTNAACL Workshop on Syntax and Structure in Statistical Translation (SSST 2007),</booktitle>
<location>Rochester, USA.</location>
<contexts>
<context position="2345" citStr="Cherry and Lin (2007)" startWordPosition="347" endWordPosition="350"> equivalence, “多少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to bui</context>
</contexts>
<marker>Cherry, Lin, 2007</marker>
<rawString>C. Cherry, D. Lin. 2007. Inversion transduction grammar for joint phrasal translation modeling. In Proc. of the HLTNAACL Workshop on Syntax and Structure in Statistical Translation (SSST 2007), Rochester, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.Computational Linguistics,</title>
<date>2007</date>
<volume>33</volume>
<issue>2</issue>
<pages>228</pages>
<contexts>
<context position="1340" citStr="Chiang, 2007" startWordPosition="189" endWordPosition="190">tion. By casting pseudo-word searching problem into a parsing framework, we search for pseudo-words in a monolingual way and a bilingual synchronous way. Experiments show that pseudo-word significantly outperforms word for PB-SMT model in both travel translation domain and news translation domain. 1 Introduction The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus generated from word-based models (Brown et al., 1993), proceeds with step of induction of phrase table (Koehn et al., 2003) or synchronous grammar (Chiang, 2007) and with model weights tuning step. Words are taken as inputs to PB-SMT at the very beginning of the pipeline. But there is a deficiency in such manner that word is too finegrained in some cases such as non-compositional phrasal equivalences, where clear word alignments do not exist. For example in Chinese-toEnglish translation, “tH” and “would like to” constitute a 1-to-n phrasal equivalence, “多少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained m</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>D. Chiang. 2007. Hierarchical phrase-based translation.Computational Linguistics, 33(2):201– 228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Deng</author>
<author>W Byrne</author>
</authors>
<title>HMM word and phrase alignment for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. of HLT-EMNLP,</booktitle>
<pages>169--176</pages>
<contexts>
<context position="4147" citStr="Deng and Byrne (2005)" startWordPosition="615" endWordPosition="618">it is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics pressions by monotonically segmenting a given Spanish-English sentence pair into bilingual units, where word aligner is also used. IBM model 3, 4, 5 (Brown et al., 1993) and Deng and Byrne (2005) are another kind of related works that allow 1-to-n alignments, but they rarely questioned if such alignments exist in word units level, that is, they rarely questioned word as basic translational unit. Moreover, m-ton alignments were not modeled. This paper focuses on determining the basic translational units on both language sides without using word aligner before feeding them into PBSMT pipeline. We call such basic translational unit as pseudo-word to differentiate with word. Pseudo-word is a kind of multi-word expression (includes both unary word and multi-word). Pseudo-word searching pro</context>
</contexts>
<marker>Deng, Byrne, 2005</marker>
<rawString>Y. Deng and W. Byrne. 2005. HMM word and phrase alignment for statistical machine translation. In Proc. of HLT-EMNLP, pages 169–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram cooccurrence statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2nd International Conference on Human Language Technology (HLT’02).</booktitle>
<pages>138--145</pages>
<contexts>
<context position="21000" citStr="Doddington, 2002" startWordPosition="3620" endWordPosition="3622">all Ch — En 23k 190k 213k 8.3 9.2 Sent. word ASL 152 For small corpus, we use CSTAR03 as development set, use IWSLT08 official test set for test. A 5-gram language model is trained on English side of parallel corpus. For large corpus, we use NIST02 as development set, use NIST03 as test set. Xinhua portion of the English Gigaword3 corpus is used together with English side of large corpus to train a 4-gram language model. Experimental results are evaluated by caseinsensitive BLEU-4 (Papineni et al., 2001). Closest reference sentence length is used for brevity penalty. Additionally, NIST score (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) are also used to check the consistency of experimental results. Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004). 3.1 Baseline Performance Our baseline system feeds word into PB-SMT pipeline. We use GIZA++ model 4 for word alignment, use Moses for phrase-based decoding. The setting of language model order for each corpus is not changed. Baseline performances on test sets of small corpus and large corpus are reported in table 2. small Large BLEU 0.4029 0.3146 NIST 7.0419 8.8462 METEOR 0.5785 0.5335</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>G. Doddington. 2002. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Proceedings of the 2nd International Conference on Human Language Technology (HLT’02). 138–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Kneser</author>
<author>Hermann Ney</author>
</authors>
<title>Improved backing-off for M-gram language modeling.</title>
<date>1995</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<pages>181--184</pages>
<location>Detroit, MI.</location>
<contexts>
<context position="19215" citStr="Kneser and Ney 1995" startWordPosition="3307" endWordPosition="3310"> except multiply a constant EL2. There is one kind of NULL alignments that ESSP can not consider. Since we limit excluded parts in the middle of a span-pair, the algorithm will end without considering boundary parts of a sentence pair as NULL alignments. 3 Experiments and Results In our experiments, pseudo-words are fed into PB-SMT pipeline. The pipeline uses GIZA++ model 4 (Brown et al., 1993; Och and Ney, 2003) for pseudo-word alignment, uses Moses (Koehn et al., 2007) as phrase-based decoder, uses the SRI Language Modeling Toolkit to train language model with modified Kneser-Ney smoothing (Kneser and Ney 1995; Chen and Goodman 1998). Note that MERT (Och, 2003) is still on original words of target language. In our experiments, pseudo-word length is limited to no more than six unary words on both sides of the language pair. We conduct experiments on Chinese-toEnglish machine translation. Two data sets are adopted, one is small corpus of IWSLT-2008 BTEC task of spoken language translation in travel domain (Paul, 2008), the other is large corpus in news domain, which consists Hong Kong News (LDC2004T08), Sinorama Magazine (LDC2005T10), FBIS (LDC2003E14), Xinhua (LDC2002E18), Chinese News Translation (</context>
</contexts>
<marker>Kneser, Ney, 1995</marker>
<rawString>Kneser, Reinhard and Hermann Ney. 1995. Improved backing-off for M-gram language modeling. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing, pages 181–184, Detroit, MI.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
</authors>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, </marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan,W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of the 45th Annual Meeting of the ACL (ACL-2007),</booktitle>
<location>Prague.</location>
<marker>Herbst, 2007</marker>
<rawString>E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. of the 45th Annual Meeting of the ACL (ACL-2007), Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrasebased translation.</title>
<date>2003</date>
<booktitle>In Proc. of the 3rd International conference on Human Language Technology Research and 4th Annual Meeting of the NAACL (HLT-NAACL</booktitle>
<pages>81--88</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1302" citStr="Koehn et al., 2003" startWordPosition="181" endWordPosition="184">nce of consecutive words in sense of translation. By casting pseudo-word searching problem into a parsing framework, we search for pseudo-words in a monolingual way and a bilingual synchronous way. Experiments show that pseudo-word significantly outperforms word for PB-SMT model in both travel translation domain and news translation domain. 1 Introduction The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus generated from word-based models (Brown et al., 1993), proceeds with step of induction of phrase table (Koehn et al., 2003) or synchronous grammar (Chiang, 2007) and with model weights tuning step. Words are taken as inputs to PB-SMT at the very beginning of the pipeline. But there is a deficiency in such manner that word is too finegrained in some cases such as non-compositional phrasal equivalences, where clear word alignments do not exist. For example in Chinese-toEnglish translation, “tH” and “would like to” constitute a 1-to-n phrasal equivalence, “多少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic transla</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. J. Och, D. Marcu. 2003. Statistical phrasebased translation. In Proc. of the 3rd International conference on Human Language Technology Research and 4th Annual Meeting of the NAACL (HLT-NAACL 2003), 81–88, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Statistical Significance Tests for Machine Translation Evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="21210" citStr="Koehn, 2004" startWordPosition="3652" endWordPosition="3653">. For large corpus, we use NIST02 as development set, use NIST03 as test set. Xinhua portion of the English Gigaword3 corpus is used together with English side of large corpus to train a 4-gram language model. Experimental results are evaluated by caseinsensitive BLEU-4 (Papineni et al., 2001). Closest reference sentence length is used for brevity penalty. Additionally, NIST score (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) are also used to check the consistency of experimental results. Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004). 3.1 Baseline Performance Our baseline system feeds word into PB-SMT pipeline. We use GIZA++ model 4 for word alignment, use Moses for phrase-based decoding. The setting of language model order for each corpus is not changed. Baseline performances on test sets of small corpus and large corpus are reported in table 2. small Large BLEU 0.4029 0.3146 NIST 7.0419 8.8462 METEOR 0.5785 0.5335 Table 2. Baseline performances on test sets of small corpus and large corpus. 3.2 Pseudo-word Unpacking Because pseudo-word is a kind of multi-word expression, it has inborn advantage of higher language model </context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>P. Koehn. 2004. Statistical Significance Tests for Machine Translation Evaluation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Lambert</author>
<author>R Banchs</author>
</authors>
<title>Data Inferred Multi-word Expressions for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of MT Summit X.</booktitle>
<contexts>
<context position="3730" citStr="Lambert and Banchs (2005)" startWordPosition="554" endWordPosition="557"> Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics pressions by monotonically segmenting a given Spanish-English sentence pair into bilingual units, where word aligner is also used. IBM model 3, 4, 5 (Brown et al., 1993) and Deng and Byrne (2005) are another kind of related works that allow 1-to-n alignments, but they rarely questioned if such alignments exist in word units level, that is, they rarely questioned word as basic</context>
</contexts>
<marker>Lambert, Banchs, 2005</marker>
<rawString>P. Lambert and R. Banchs. 2005. Data Inferred Multi-word Expressions for Statistical Machine Translation. In Proceedings of MT Summit X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ma</author>
<author>N Stroppa</author>
<author>A Way</author>
</authors>
<title>Bootstrapping word alignment via word packing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07).</booktitle>
<pages>304--311</pages>
<contexts>
<context position="3327" citStr="Ma et al. 2007" startWordPosition="491" endWordPosition="494">to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for C</context>
</contexts>
<marker>Ma, Stroppa, Way, 2007</marker>
<rawString>Y. Ma, N. Stroppa, and A. Way. 2007. Bootstrapping word alignment via word packing. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL’07). 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ma</author>
<author>A Way</author>
</authors>
<title>Bilingually Motivated Word Segmentation for Statistical Machine Translation. In</title>
<date>2009</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>8</volume>
<issue>2</issue>
<contexts>
<context position="3592" citStr="Ma and Way (2009)" startWordPosition="534" endWordPosition="537">egment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by using word aligner to bootstrap bilingual segmentation suitable for machine translation. Lambert and Banchs (2005) detect bilingual multi-word ex148 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 148–156, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics pressions by monotonically segmenting a given Spanish-English sentence pair into bilingual units, where word aligner is also used. IBM model 3, 4, 5 (Brown et al., 1993) and Deng and Byrne (2005) are another kind of related works that allow</context>
<context position="22411" citStr="Ma and Way (2009)" startWordPosition="3845" endWordPosition="3848"> language model order and longer max phrase length over unary word. To see if such inborn advantage is the main contribution to the performance or not, we unpack pseudo-word into words after GIZA++ aligning. Aligned pseudowords are unpacked into m×n word alignments. PB-SMT pipeline is executed thereafter. The advantage of longer max phrase length is removed during phrase extraction, and the advantage of higher order of language model is also removed during decoding since we use language model trained on unary words. Performances of pseudoword unpacking are reported in section 3.3.1 and 3.4.1. Ma and Way (2009) used the unpacking after phrase extraction, then re-estimated phrase translation probability and lexical reordering model. The advantage of longer max phrase length is still used in their method. 3.3 Pseudo-word Performances on Small Corpus Table 3 presents performances of SMP, SSP, ESSP on small data set. pwchpwen denotes that pseudo-words are on both language side of training data, and they are input strings during development and testing, and translations are also pseudo-words, which will be converted to words as final output. wchpwen/pwchwen denotes that pseudo-words are adopted only on E</context>
</contexts>
<marker>Ma, Way, 2009</marker>
<rawString>Y. Ma, and A. Way. 2009. Bilingually Motivated Word Segmentation for Statistical Machine Translation. In ACM Transactions on Asian Language Information Processing, 8(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
<author>W Wong</author>
</authors>
<title>A phrase-based, joint probability model for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP-2002), 133–139, Philadelphia. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2106" citStr="Marcu and Wong (2002)" startWordPosition="311" endWordPosition="314"> manner that word is too finegrained in some cases such as non-compositional phrasal equivalences, where clear word alignments do not exist. For example in Chinese-toEnglish translation, “tH” and “would like to” constitute a 1-to-n phrasal equivalence, “多少 钱” and “how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational u</context>
</contexts>
<marker>Marcu, Wong, 2002</marker>
<rawString>D. Marcu,W.Wong. 2002. A phrase-based, joint probability model for statistical machine translation. In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP-2002), 133–139, Philadelphia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="19267" citStr="Och, 2003" startWordPosition="3318" endWordPosition="3319">ignments that ESSP can not consider. Since we limit excluded parts in the middle of a span-pair, the algorithm will end without considering boundary parts of a sentence pair as NULL alignments. 3 Experiments and Results In our experiments, pseudo-words are fed into PB-SMT pipeline. The pipeline uses GIZA++ model 4 (Brown et al., 1993; Och and Ney, 2003) for pseudo-word alignment, uses Moses (Koehn et al., 2007) as phrase-based decoder, uses the SRI Language Modeling Toolkit to train language model with modified Kneser-Ney smoothing (Kneser and Ney 1995; Chen and Goodman 1998). Note that MERT (Och, 2003) is still on original words of target language. In our experiments, pseudo-word length is limited to no more than six unary words on both sides of the language pair. We conduct experiments on Chinese-toEnglish machine translation. Two data sets are adopted, one is small corpus of IWSLT-2008 BTEC task of spoken language translation in travel domain (Paul, 2008), the other is large corpus in news domain, which consists Hong Kong News (LDC2004T08), Sinorama Magazine (LDC2005T10), FBIS (LDC2003E14), Xinhua (LDC2002E18), Chinese News Translation (LDC2005T06), Chinese Treebank (LDC2003E07), Multiple</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of ACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="16414" citStr="Och and Ney, 2003" startWordPosition="2739" endWordPosition="2742">ottom-up way, and the optimal decomposition of the sentence pair is obtained correspondingly. • Algorithm of Excluded Synchronous Searching for Pseudo-words (ESSP) The algorithm of SSP in Figure 2 explores all span-pairs, but it neglects NULL alignments, where words and “empty” word are aligned. In fact, SSP requires that all parts of a sentence pair should be aligned. This requirement is too strong because NULL alignments are very common in many language pairs. In SSP, words that should be aligned to “empty” word are programmed to be aligned to real words. Unlike most word alignment methods (Och and Ney, 2003) that add “empty” word to account for NULL alignment entries, we propose a method to naturally exclude such NULL alignments. We call this method as Excluded Synchronous Searching for Pseudo-words (ESSP). The main difference between ESSP and SSP is in steps 3-6 in Figure 3. We illustrate Figure 3’s span-pair configuration in Figure 4. 7: W = v; 8: u = Sigis ,js,it ,jt 9: if u &gt; W then ijt s js it , , , i ,jt s j s i , , t i s , j s , i t , j t ; 151 Initialization: if is = js or it = jt then W = Sig ; i j i j i j i j s s t t , , , s s t t , , else Wi , j , i , j = 0 ; s s t t 1: for ds = 2 ... </context>
<context position="19012" citStr="Och and Ney, 2003" startWordPosition="3275" endWordPosition="3278">g, so we can set a length threshold for NULL alignments, eg. ks2-ks1≤EL, where EL denotes Excluded Length threshold. Computational complexity of the ESSP remains the same to SSP’s complexity O(ns3.nt3), except multiply a constant EL2. There is one kind of NULL alignments that ESSP can not consider. Since we limit excluded parts in the middle of a span-pair, the algorithm will end without considering boundary parts of a sentence pair as NULL alignments. 3 Experiments and Results In our experiments, pseudo-words are fed into PB-SMT pipeline. The pipeline uses GIZA++ model 4 (Brown et al., 1993; Och and Ney, 2003) for pseudo-word alignment, uses Moses (Koehn et al., 2007) as phrase-based decoder, uses the SRI Language Modeling Toolkit to train language model with modified Kneser-Ney smoothing (Kneser and Ney 1995; Chen and Goodman 1998). Note that MERT (Och, 2003) is still on original words of target language. In our experiments, pseudo-word length is limited to no more than six unary words on both sides of the language pair. We conduct experiments on Chinese-toEnglish machine translation. Two data sets are adopted, one is small corpus of IWSLT-2008 BTEC task of spoken language translation in travel do</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuan-Hieu Phan</author>
<author>Le-Minh Nguyen</author>
<author>Cam-Tu Nguyen</author>
</authors>
<title>FlexCRFs: Flexible Conditional Random Field Toolkit,</title>
<date>2005</date>
<location>http://flexcrfs.sourceforge. net</location>
<contexts>
<context position="29106" citStr="Phan et al., 2005" startWordPosition="4896" endWordPosition="4899">del order or longer max phrase length setting. In fact, slight improvement in pwchpwen and pwchwen is seen after pseudo-word unpacking, which indicates that higher language model order and longer max phrase length impact the performance in these two configurations. UnpackingSMP pwchwen Baseline pwchpwen wchpwen BLEU 0.3219 0.3192 0.3187 0.3146 NIST 8.9458 8.9325 8.9801 8.8462 METEOR 0.5429 0.5424 0.5411 0.5335 Table 6. Performance of pseudo-word unpacking on large corpus. 3.5 Comparison to English Chunking English chunking is experimented to compare with pseudo-word. We use FlexCRFs (XuanHieu Phan et al., 2005) to get English chunks. Since there is no standard Chinese chunking data and code, only English chunking is executed. The experimental results show that English chunking performs far below baseline, usually 8 absolute BLEU points below. It shows that simple chunks are not suitable for being basic translational units. 4 Conclusion We have presented pseudo-word as a novel machine translational unit for phrase-based machine translation. It is proposed to replace too finegrained word as basic translational unit. Pseudoword is a kind of basic multi-word expression that characterizes minimal sequenc</context>
</contexts>
<marker>Phan, Nguyen, Nguyen, 2005</marker>
<rawString>Xuan-Hieu Phan, Le-Minh Nguyen, and Cam-Tu Nguyen. 2005. FlexCRFs: Flexible Conditional Random Field Toolkit, http://flexcrfs.sourceforge. net</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation,</title>
<date>2001</date>
<contexts>
<context position="20892" citStr="Papineni et al., 2001" startWordPosition="3604" endWordPosition="3607">then i i t , j t s j s , , is ks1 ks2 js it kt1 kt2 jt a) non-reversed is ks1 ks2 js it kt1 kt2 jt b) reversed small Ch — En 23k 190k 213k 8.3 9.2 Sent. word ASL 152 For small corpus, we use CSTAR03 as development set, use IWSLT08 official test set for test. A 5-gram language model is trained on English side of parallel corpus. For large corpus, we use NIST02 as development set, use NIST03 as test set. Xinhua portion of the English Gigaword3 corpus is used together with English side of large corpus to train a 4-gram language model. Experimental results are evaluated by caseinsensitive BLEU-4 (Papineni et al., 2001). Closest reference sentence length is used for brevity penalty. Additionally, NIST score (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) are also used to check the consistency of experimental results. Statistical significance in BLEU score differences was tested by paired bootstrap re-sampling (Koehn, 2004). 3.1 Baseline Performance Our baseline system feeds word into PB-SMT pipeline. We use GIZA++ model 4 for word alignment, use Moses for phrase-based decoding. The setting of language model order for each corpus is not changed. Baseline performances on test sets of small corpus and </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, W. Zhu. 2001. Bleu: a method for automatic evaluation of machine translation, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Paul</author>
</authors>
<title>Overview of the IWSLT</title>
<date>2008</date>
<booktitle>In Proc. of Internationa Workshop on Spoken Language Translation,</booktitle>
<contexts>
<context position="19629" citStr="Paul, 2008" startWordPosition="3379" endWordPosition="3380">seudo-word alignment, uses Moses (Koehn et al., 2007) as phrase-based decoder, uses the SRI Language Modeling Toolkit to train language model with modified Kneser-Ney smoothing (Kneser and Ney 1995; Chen and Goodman 1998). Note that MERT (Och, 2003) is still on original words of target language. In our experiments, pseudo-word length is limited to no more than six unary words on both sides of the language pair. We conduct experiments on Chinese-toEnglish machine translation. Two data sets are adopted, one is small corpus of IWSLT-2008 BTEC task of spoken language translation in travel domain (Paul, 2008), the other is large corpus in news domain, which consists Hong Kong News (LDC2004T08), Sinorama Magazine (LDC2005T10), FBIS (LDC2003E14), Xinhua (LDC2002E18), Chinese News Translation (LDC2005T06), Chinese Treebank (LDC2003E07), Multiple Translation Chinese (LDC2004T07). Table 1 lists statistics of the corpus used in these experiments. large Ch — En 1,239k 31.7m 35.5m 25.6 28.6 Table 1. Statistics of corpora, “Ch” denotes Chinese, “En” denotes English, “Sent.” row is the number of sentence pairs, “word” row is the number of words, “ASL” denotes average sentence length. Sig is,js,it,jt 7: u = </context>
</contexts>
<marker>Paul, 2008</marker>
<rawString>M. Paul, 2008. Overview of the IWSLT 2008 evaluation campaign. In Proc. of Internationa Workshop on Spoken Language Translation, 20-21 October 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<location>Denver, Colorado.</location>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. (2002). SRILM - an extensible language modeling toolkit. In Proceedings of ICSLP, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<pages>403</pages>
<contexts>
<context position="2401" citStr="Wu, 1997" startWordPosition="359" endWordPosition="360">l equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. X</context>
<context position="13265" citStr="Wu, 1997" startWordPosition="2137" endWordPosition="2138"> and Wi, j of optimal decomposition of span[i, j] is recorded. Then monolingual sequence significance Sigi,j of span[i, j] is computed at step 7, and it is compared to Wi, j at step 8. Update of Wi, j is taken at step 9 if Sigi,j is bigger than Wi, j, which indicates that span[i, j] is non-decomposable. Thus whether span[i, j] should be non-decomposable or not is decided through steps 7-9. 2.2.2 Algorithm of Synchronous Searching for Pseudo-words (SSP) Synchronous searching for pseudo-words utilizes bilingual sequence significance. Figure 2 presents the search algorithm. It is similar to ITG (Wu, 1997), except that it has no production rules and non-terminal nodes of a synchronous grammar. What it cares about is the span-pairs that maximize the sum of bilingual sequence significances. Initialization: if is = js or it = jt then Wi ,j, i ,j = Sig s s t t else Wi , j , i , j = 0 ; s s t 1: for ds = 2 ... ns, dt = 2 ... nt do 2: for all is, js, it, jt s.t. js-is=ds-1 and jt-it=dt-1 do 3: for ks = is ... js – 1, kt = it ... jt – 1 do 4: v = max{ Wi ,k,i ,k +W k +1,j ,k +1,j , s s t t s s t t Wi, k ,k +1,j + Wk +1,j ,i, k s s t t s s t t } 5: if v &gt; W then i , j ,i , jt s s t 9: W = u; i , j , i </context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>D. Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377– 403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xu</author>
<author>Zens</author>
<author>H Ney</author>
</authors>
<title>Do we need Chinese word segmentation for statistical machine translation?</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL Workshop on Chinese Language Processing SIGHAN’04).</booktitle>
<pages>122--128</pages>
<contexts>
<context position="2920" citStr="Xu et al. (2004)" startWordPosition="429" endWordPosition="432"> into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translatio</context>
</contexts>
<marker>Xu, Zens, Ney, 2004</marker>
<rawString>J. Xu, Zens., and H. Ney. 2004. Do we need Chinese word segmentation for statistical machine translation? In Proceedings of the ACL Workshop on Chinese Language Processing SIGHAN’04). 122–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xu</author>
<author>J Gao</author>
<author>K Toutanova</author>
<author>H Ney</author>
</authors>
<title>Bayesian semi-supervised chinese word segmentation for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING’08).</booktitle>
<pages>1017--1024</pages>
<contexts>
<context position="3016" citStr="Xu et al. (2008)" startWordPosition="446" endWordPosition="449">) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary to resegment Chinese sentence. Xu et al. (2008) used a Bayesian semi-supervised method that combines Chinese word segmentation model and Chinese-to-English translation model to derive a Chinese segmentation suitable for machine translation. There are also researches focusing on the impact of various segmentation tools on machine translation (Ma et al. 2007; Chang et al. 2008; Zhang et al. 2008). Since there are many 1-to-n phrasal equivalences in Chinese-to-English translation (Ma and Way. 2009), only focusing on Chinese word as basic translational unit is not adequate to model 1-to-n translations. Ma and Way (2009) tackle this problem by </context>
</contexts>
<marker>Xu, Gao, Toutanova, Ney, 2008</marker>
<rawString>J. Xu, J. Gao, K. Toutanova, and H. Ney. 2008. Bayesian semi-supervised chinese word segmentation for statistical machine translation. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING’08). 1017–1024.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>C Quirk</author>
<author>R C Moore</author>
<author>D Gildea</author>
</authors>
<title>Bayesian learning of non-compositional phrases with synchronous parsing.</title>
<date>2008</date>
<booktitle>In Proc. of the 46th Annual Conference of the Association for Computational Linguistics: Human Language Technologies (ACL-08:HLT), 97–105,</booktitle>
<location>Columbus, Ohio.</location>
<contexts>
<context position="2369" citStr="Zhang et al. (2008)" startWordPosition="352" endWordPosition="355">how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary </context>
</contexts>
<marker>Zhang, Quirk, Moore, Gildea, 2008</marker>
<rawString>H. Zhang, C. Quirk, R. C. Moore, D. Gildea. 2008. Bayesian learning of non-compositional phrases with synchronous parsing. In Proc. of the 46th Annual Conference of the Association for Computational Linguistics: Human Language Technologies (ACL-08:HLT), 97–105, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zhang</author>
<author>K Yasuda</author>
<author>E Sumita</author>
</authors>
<title>Improved statistical machine translation by multiple Chinese word segmentation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd Workshop on Statistical Machine Translation (SMT’08).</booktitle>
<pages>216--223</pages>
<contexts>
<context position="2369" citStr="Zhang et al. (2008)" startWordPosition="352" endWordPosition="355">how much is it” constitute a m-to-n phrasal equivalence. No clear word alignments are there in such phrasal equivalences. Moreover, should basic translational unit be word or coarsegrained multi-word is an open problem for optimizing SMT models. Some researchers have explored coarsegrained translational unit for machine translation. Marcu and Wong (2002) attempted to directly learn phrasal alignments instead of word alignments. But computational complexity is prohibitively high for the exponentially large number of decompositions of a sentence pair into phrase pairs. Cherry and Lin (2007) and Zhang et al. (2008) used synchronous ITG (Wu, 1997) and constraints to find non-compositional phrasal equivalences, but they suffered from intractable estimation problem. Blunsom et al. (2008; 2009) induced phrasal synchronous grammar, which aimed at finding hierarchical phrasal equivalences. Another direction of questioning word as basic translational unit is to directly question word segmentation on languages where word boundaries are not orthographically marked. In Chineseto-English translation task where Chinese word boundaries are not marked, Xu et al. (2004) used word aligner to build a Chinese dictionary </context>
</contexts>
<marker>Zhang, Yasuda, Sumita, 2008</marker>
<rawString>R. Zhang, K. Yasuda, and E. Sumita. 2008. Improved statistical machine translation by multiple Chinese word segmentation. In Proceedings of the 3rd Workshop on Statistical Machine Translation (SMT’08). 216–223.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>