<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.59144">
Why Synchronous Tree Substitution Grammars?
</title>
<author confidence="0.714924">
Andreas Maletti
</author>
<affiliation confidence="0.4858765">
Universitat Rovira i Virgili, Departament de Filologies Rom`aniques
Avinguda de Catalunya 35, 43002 Tarragona, Spain
</affiliation>
<email confidence="0.98265">
andreas.maletti@urv.cat
</email>
<sectionHeader confidence="0.99371" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9922076">
Synchronous tree substitution grammars are a
translation model that is used in syntax-based
machine translation. They are investigated in
a formal setting and compared to a competi-
tor that is at least as expressive. The competi-
tor is the extended multi bottom-up tree trans-
ducer, which is the bottom-up analogue with
one essential additional feature. This model
has been investigated in theoretical computer
science, but seems widely unknown in natu-
ral language processing. The two models are
compared with respect to standard algorithms
(binarization, regular restriction, composition,
application). Particular attention is paid to the
complexity of the algorithms.
</bodyText>
<sectionHeader confidence="0.998769" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999737966666666">
Every machine translation system uses a transla-
tion model, which is a formal model that describes
the translation process. Either this system is hand-
crafted (in rule-based translation systems) or it is
trained with the help of statistical processes. Brown
et al. (1990) discuss automatically trainable transla-
tion models in their seminal paper on the latter ap-
proach. The IBM models of Brown et al. (1993) are
string-based in the sense that they base the transla-
tion decision on the words and the surrounding con-
text. In the field of syntax-based machine transla-
tion, the translation models have access to the syntax
(in the form of parse trees) of the sentences. Knight
(2007) presents a good exposition to both fields.
In this paper, we focus on syntax-based transla-
tion models, and in particular, synchronous tree sub-
stitution grammars (STSGs), or the equally pow-
erful (linear and nondeleting) extended (top-down)
tree transducers of Graehl et al. (2008). Chiang and
Knight (2006) gives a good introduction to STSGs,
which originate from the syntax-directed transla-
tion schemes of Aho and Ullman (1972) [nowadays
more commonly known as synchronous context-free
grammars]. Roughly speaking, an STSG has rules
in which a nonterminal is replaced by two trees con-
taining terminal and nonterminal symbols. In addi-
tion, the nonterminals in the two trees are linked and
a rule is only applied to linked nonterminals.
Several algorithms for STSGs have been dis-
cussed in the literature. For example, we can
</bodyText>
<listItem confidence="0.9989885">
• train them [see Graehl et al. (2008)],
• attempt to binarize them using the methods of
(Zhang et al., 2006; Huang et al., 2009; DeNero
et al., 2009b),
• parse them [see DeNero et al. (2009a)], or
• attempt to compose them.
</listItem>
<bodyText confidence="0.999530444444445">
However, some important algorithms are partial be-
cause it is known that the construction might not be
possible in general. This is the case, for example,
for binarization and composition.
In the theoretical computer science community,
alternative models have been explored. Such
a model is the multi bottom-up tree transducer
(MBOT) of Arnold and Dauchet (1982) and Lilin
(1981), which essentially is the bottom-up analogue
of STSGs with the additional feature that nontermi-
nals can have an arbitrary rank (the rank of a non-
terminal of an STSG can be considered to be fixed
to 1). This model is even more expressive than
STSGs, but still offers good computational proper-
ties. In this contribution, we will compare STSGs
and MBOTs with respect to some standard algo-
rithms. Generally, MBOTs offer algorithmic ben-
efits over STSG, which can be summarized as fol-
</bodyText>
<page confidence="0.980015">
876
</page>
<note confidence="0.727612">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 876–884,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.247098">
lows:
</bodyText>
<listItem confidence="0.994303714285714">
• Every STSG can be transformed into an equiv-
alent MBOT in linear time.
• MBOTs can be fully binarized in linear
time whereas only partial binarizations (or
asynchronous binarizations) are possible for
STSGs.
• The input language of an MBOT M can be reg-
ularly restricted in O(|M |· |S|3), whereas the
corresponding construction for an STSG M is
in O(|M |· |S|2 rk(M)+5) where rk(M) is the
maximal number of nonterminals in a rule of
the STSG M.
• MBOTs can be composed, whereas this cannot
be achieved for STSGs.
</listItem>
<bodyText confidence="0.999763125">
Overall, we thus conclude that, from an algorith-
mic perspective, it would be beneficial to work with
MBOTs instead of STSGs. However, the full power
of MBOTs should not be tapped because, in gen-
eral, MBOTs have the finite-copying property [see
Engelfriet et al. (1980)], which complicates the al-
gorithms for forward and backward application (see
Section 7).
</bodyText>
<sectionHeader confidence="0.977265" genericHeader="method">
2 Preliminary definitions
</sectionHeader>
<bodyText confidence="0.999868333333333">
An alphabet is a finite set of symbols. Our weighted
devices use real-number weights, but the results
translate easily to the more general setting of com-
mutative semirings [see Golan (1999)]. A weighted
string automaton as in Sch¨utzenberger (1961) and
Eilenberg (1974) is a system (S, F, I, T, F) where
</bodyText>
<listItem confidence="0.998322">
• S and F are alphabets of states and input sym-
bols, respectively,
• I, F : S → R assign initial and final weights,
respectively, and
• T: S × F × S → R assigns a weight to each
transition.
</listItem>
<bodyText confidence="0.9352554">
Let w = -y1 · · · -yk ∈ F* be an input string of
length k. A run on w is r: {0, ... , k} → S. The
weight of the run r is wt(r) = Hkz=1 T(rz_1, -yz, rz).
The semantics of the automaton A then assigns to w
the weight
</bodyText>
<equation confidence="0.9990115">
A(w) = � I(r0) · wt(r) · F(rk) .
r run on w
</equation>
<bodyText confidence="0.994089736842105">
A good introduction to weighted string automata can
be found in Mohri (2009) and Sakarovitch (2009).
To simplify the theoretical discussion, we as-
sume that each symbol that we use in trees has a
fixed rank, which determines the number of chil-
dren of each node with that label. A ranked alpha-
bet E = Uk&gt;0 Ek is an alphabet whose symbols
have assigned ranks. The set Ek contains all sym-
bols of rank k. The set TΣ(V ) of E-trees indexed
by a set V is the smallest set such that V ⊆ TΣ(V )
and Q(t1, ... , tk) ∈ TΣ(V ) for every Q ∈ Ek and
t1, ... , tk ∈ TΣ(V ). The size |t |of the tree t ∈ TΣ
is the number of occurrences of symbols from E∪V
that appear in t. A context c is a tree of TΣujuj(V ),
in which the nullary symbol ❑ occurs exactly once.
The set of all such contexts is CΣ(V ). The tree c[t]
is obtained from c by replacing the symbol ❑ by t.
A weighted synchronous tree substitution gram-
mar (STSG) is a system (N, E, A, I, P) where
</bodyText>
<listItem confidence="0.9960167">
• N is an alphabet of nonterminals,
• E and A are ranked alphabets of input and out-
put symbols, respectively,
• I : N → R assigns initial weights, and
• P is a finite set of productions n: t ↔� u with
n ∈ N, t ∈ TΣ(N), a ∈ R, and u ∈ TΔ(N)
such that
– every n&apos; ∈ N that occurs in t occurs ex-
actly once in u and vice versa, and
– t ∈�N or u ∈�N.
</listItem>
<bodyText confidence="0.9996666">
Note that our distinction between nonterminals and
terminals is rather uncommon for STSG [see Chi-
ang (2005)], but improves the generative power. We
chose the symbol “↔” because STSG productions
are symmetric. The size |n: t H u |of a produc-
</bodyText>
<equation confidence="0.966065375">
tion is |t |+ |u|, and the size |M |of the STSG M is
E
pcP |p|. It is a weighted tree substitution grammar
(TSG) if t= u for all productions n: t ↔� u ∈ P.
Further, it is in normal form if for every production
n: t ↔� u ∈ P there exist Q ∈ Ek, 6 ∈ Ak, and
nonterminals n1, ... , nk, n&apos;1, ... , n&apos;k ∈ N such that
t = Q(n1, ... , nk) and u = S(n&apos;1, ... , n&apos;k). A de-
</equation>
<bodyText confidence="0.843716125">
tailed exposition to STSGs and STSGs in normal
form (also called synchronous context-free gram-
mars) can be found in Chiang (2005). Further details
on TSGs can be found in Berstel and Reutenauer
(1982) and F¨ul¨op and Vogler (2009).
Equal nonterminals in t and u of a produc-
tion n: t ↔� u ∈ P are linked. To keep the pre-
sentation simple, we assume that those links are re-
</bodyText>
<page confidence="0.982473">
877
</page>
<figure confidence="0.876148">
x1 x2
</figure>
<figureCaption confidence="0.968506333333333">
Figure 1: STSG production (top) and corresponding
MBOT rule (bottom) where @ is an arbitrary symbol that
is introduced during binarization.
</figureCaption>
<equation confidence="0.560779625">
→
S
S
U
x2 x3
U&apos;
→ x2 @
x1 x3
x1 x2
→
@
V
x2
NP
x3
S
NP1 @
V NP2
S
↔ V @
NP1 NP2
S
S
x2 @
x1 x3
S
@
NP
→
x1
V
x2
NP
x3
U&apos;
S
NP
x1
U
x2 x3
</equation>
<listItem confidence="0.985196833333333">
membered also in sentential forms. In addition, we
assume that N ∩ E = ∅. For every c, c&apos; ∈ CΣ(N)
and n ∈ N, let (c[n], c&apos;[n]) &apos;⇒ (c[t], c&apos;[u]) if
• there is a production n: t H u ∈ P, and
• the explicit (the ones replacing ❑) occurrences
of n in c[n] and c&apos;[n] are linked.
</listItem>
<bodyText confidence="0.8760365">
Left-most derivations are defined as usual, and the
weight of a derivation D: �0 ⇒ · · · ��
</bodyText>
<equation confidence="0.983425166666667">
�� ⇒ �k is
wt(D) = nkz=1 az. The weight assigned by the
grammar M to a pair (t, u) ∈ TΣ × TΔ is
1: 1:
M(t,u) = I(n) ·
nEN D left-most derivation
</equation>
<bodyText confidence="0.9359695">
from (n, n) to (t, u)
The second restriction on productions ensures that
derivations are of finite length, and thus that the
sums in the definition of M(t, u) are finite.
In the following, we will use syntactic simplifica-
tions such as
</bodyText>
<listItem confidence="0.9250442">
• several occurrences of the same nonterminal in
a tree (disambiguated by decoration).
• symbols that are terminals (of E and A) and
nonterminals. We will print nonterminals in
italics and terminal symbols upright.
• omission of the nonterminal n (or the weight a)
of a rule n: t ↔� u if the terminal n occurs at
the root of t and u (or a = 1).
→ t instead of n: t �
� ↔ t if it is a TSG.
</listItem>
<bodyText confidence="0.88856">
A sample STSG production (using those simplifica-
tions) is displayed in Figure 1. Our STSGs are es-
sentially equivalent to the (nondeleting and linear)
extended tree transducers of Graehl et al. (2008) and
Maletti et al. (2009).
</bodyText>
<figureCaption confidence="0.9728725">
Figure 2: Sample MBOT rules in one-symbol normal
form.
</figureCaption>
<sectionHeader confidence="0.956899" genericHeader="method">
3 Multi bottom-up tree transducers
</sectionHeader>
<bodyText confidence="0.999827">
As indicated in the Introduction, we will compare
STSGs to weighted multi bottom-up tree transduc-
ers, which have been introduced by Arnold and
Dauchet (1982) and Lilin (1981). A more detailed
(and English) presentation can be found in Engel-
friet et al. (2009). Let us quickly recall the formal
definition. We use a fixed set X = {x1, x2,... }
of (formal) variables. For a ranked alphabet S and
</bodyText>
<equation confidence="0.8662395">
L ⊆ TΣ(X) we let
S(L) = {s(t1, ... , tk)  |s ∈ Sk, t1, ... , tk ∈ L}
</equation>
<bodyText confidence="0.991783">
and we treat elements of S(L) like elements
of TΣuS(X).
</bodyText>
<construct confidence="0.4299285">
Definition 1 A weighted multi bottom-up tree trans-
ducer (MBOT) is a system (S, E, A, F, R) where
</construct>
<listItem confidence="0.999775625">
• S, E, and A are ranked alphabets of states, in-
put symbols, and output symbols, respectively,
• F : S1 → R assigns final weights, and
• R is a finite set of rules l →� r where a ∈ R,
l ∈ TΣ(S(X)), and r ∈ S(TΔ(X)) such that
– every x ∈ X that occurs in l occurs ex-
actly once in r and vice versa, and
– l ∈� S(X) or r ∈� S(X).
</listItem>
<bodyText confidence="0.9938904">
Roughly speaking, an MBOT is the bottom-up
version of an extended top-down tree transducer, in
which the states can have a rank different from 1. We
chose the symbol “→” because rules have a distin-
guished left- and right-hand side. The size |l � r |of
</bodyText>
<figure confidence="0.97887152">
wt(D) .
• n
878
S
S
@
�
�
NP
t1
NP
t1
V
t2
U
t2 t3
NP
t3
S
S
t2 @
t1 t3
U0
� t2 @
t1 t3
</figure>
<figureCaption confidence="0.991335">
Figure 3: Derivation using the MBOT rules of Fig. 2.
</figureCaption>
<figure confidence="0.7979475">
a rule is |l|+|r|, and the size |M |of an MBOT M is
E
</figure>
<figureCaption confidence="0.416612">
rER|r|. Again the second condition on the rules
</figureCaption>
<bodyText confidence="0.999012142857143">
will ensure that derivations will be finite. Let us
continue with the rewrite semantics for the MBOT
(S, E, A, F, R). To simplify the presentation, we
again assume that S n (E U A) = 0. We need
the concept of substitution. Let O: X —* To and
t E To(X). Then tO is the tree obtained by replac-
ing every occurrence of x E X in t by O(x).
</bodyText>
<construct confidence="0.5573665">
Definition 2 Let c E CE(S(X)) and O: X —* To.
Then c[lO] � c[rO] ifl � r E R. The weight of a
</construct>
<equation confidence="0.902969571428572">
�1 � �k is wt(D) = nk
derivation D: �0 � · · · �� ��1 az.
The weight assigned by the MBOT M to a pair
(t, u) E TE x To is
M(t, u) = � F(s) · � wt(D) .
sES1 D left-most derivation
from t to s(u)
</equation>
<bodyText confidence="0.984636222222222">
We use the simplifications already mentioned in
the previous section also for MBOTs. Figures
1 and 2 display example rules of an MBOT. The
rules of Figure 2 are applied in a derivation in Fig-
ure 3. The first displayed derivation step uses the
context S(NP(t1), ❑) and any substitution O such
that O(x2) = t2 and O(x3) = t3.
It is argued by Chiang (2005) and Graehl et
al. (2008) that STSGs (and extended tree trans-
ducers) have sufficient power for syntax-based ma-
chine translation. Knight (2007) presents a detailed
overview that also mentions short-comings. Since
our newly proposed device, the MBOT, should be
at least as powerful as STSGs, we quickly demon-
strate how each STSG can be coded as an MBOT.
An STSG production and the corresponding MBOT
rule are displayed in Figure 1. Since the correspon-
dence is rather trivial, we omit a formal definition.
</bodyText>
<construct confidence="0.560999">
Theorem 3 For every STSG M, an equivalent
MBOT can be constructed in time 0(|M|).
</construct>
<sectionHeader confidence="0.993269" genericHeader="method">
4 Binarization
</sectionHeader>
<bodyText confidence="0.999632">
Whenever nondeterminism enters the playfield, bi-
narization becomes an important tool for efficiency
reasons. This is based on the simple, yet powerful
observation that instead of making 5 choices from a
space of n in one instant (represented by n5 rules),
it is more efficient (Wang et al., 2007) to make them
one-by-one (represented by 5n rules). Clearly, this
cannot always be done but positive examples exist in
abundance; e.g., binarization of context-free gram-
mars [see CHOMSKY normal form in Hopcroft and
Ullman (1979)].
Binarization of tree language devices typically
consists of two steps: (i) binarization of the involved
trees (using the auxiliary symbol @) and (ii) adjust-
ment (binarization) of the processing device to work
on (and fully utilize) the binarized trees. If success-
ful, then this leads to binarized derivation trees for
the processing device. In Figure 4 we show the bi-
narization of the trees in an STSG production. An-
other binarization of the rule of Figure 4 is displayed
in Figure 1. The binarization is evident enough, so
we can assume that all trees considered in the fol-
lowing are binarized.
The binarization in Figure 1 is unfortunate be-
cause the obtained production cannot be factor-
ized such that only two nonterminals occur in each
rule. However, the binarization of Figure 4 allows
the factorization into S(U, NP) H S(U, NP) and
U : @(NP, V ) H @(V , NP), which are fully bina-
rized productions. However, in general, STSGs (or
SCFGs or extended tree transducers) cannot be fully
binarized as shown in Aho and Ullman (1972).
Zhang et al. (2006) and Wang et al. (2007) show
the benefits of fully binarized STSGs and present a
linear-time algorithm for the binarization of binariz-
able STSGs. We show that those benefits can be
reaped for all STSGs by a simple change of model.
</bodyText>
<page confidence="0.996975">
879
</page>
<figureCaption confidence="0.994636">
Figure 4: Binarization of trees in an STSG production.
Top: Original — Bottom: Binarized trees.
</figureCaption>
<bodyText confidence="0.974551666666667">
We have already demonstrated that every STSG can
be transformed into an equivalent MBOT in linear
time. Next, we discuss binarization of MBOTs.
An MBOT is in one-symbol normal form if there
is at most one input and at most one output symbol,
but at least one symbol in each rule (see Figure 2).
Raoult (1993) and Engelfriet et al. (2009) prove that
every MBOT can be transformed into one-symbol
normal form. The procedure presented there runs in
linear time in the size of the input MBOT. Conse-
quently, we can transform each STSG to an equiv-
alent MBOT in one-symbol normal form in linear
time. Finally, we note that a MBOT in one-symbol
normal form has binarized derivation trees, which
proves that we fully binarized the STSG.
Theorem 4 For every STSG M an equivalent, fully
binarized MBOT can be constructed in O(|M|).
The construction of Engelfriet et al. (2009) is il-
lustrated in Figure 2, which shows the rules of an
MBOT in one-symbol normal form. Those rules are
constructed from the unlucky binarization of Fig-
ure 1. In the next section, we show the benefit of the
full binarization on the example of the BAR-HILLEL
construction.
</bodyText>
<sectionHeader confidence="0.98713" genericHeader="method">
5 Input and output restriction
</sectionHeader>
<bodyText confidence="0.999371361111111">
A standard construction for transformation devices
(and recognition devices alike) is the regular restric-
tion of the input or output language. This con-
struction is used in parsing, integration of a lan-
guage model, and the computation of certain metrics
[see Nederhof and Satta (2003), Nederhof and Satta
(2008), and Satta (2010) for a detailed account]. The
construction is generally known as BAR-HILLEL
construction [see Bar-Hillel et al. (1964) for the
original construction on context-free grammars].
STSGs (and extended tree transducers) are sym-
metric, so that input and output can freely be
swapped. Let M be an STSG and A a weighted
string automaton with states S. In the BAR-HILLEL
construction for M and A, the maximal rank rk(M)
of a symbol in the derivation forest of M enters as an
exponent into the complexity O(|M |· |S|2 rk(M)+5).
Since full binarization is not possible in general, the
maximal rank cannot be limited to 2. In contrast,
full binarization is possible for MBOTs (with only
linear overhead), so let us investigate whether we
can exploit this in a BAR-HILLEL construction for
MBOTs.
Let M = (S, E, A, F, R) be an MBOT in one-
symbol normal form. The symbols in E ∪ A have
rank at most 2. Moreover, let G = (N, E, E, I, P)
be a TSG in normal form. We want to construct an
MBOT M&apos; such that M&apos;(t, u) = M(t, u) · G(t) for
every t ∈ TE and u ∈ To. In other words, each
input tree should be rescored according to G; in the
unweighted case this yields that the translation of M
is filtered to the set of input trees accepted by G.
We occasionally write the pair (a, b) in angled
parentheses (‘h’ and ‘i’). In addition, we use the
center line ellipsis ‘· ·’ (also with decoration) like a
variable (especially for sequences).
</bodyText>
<construct confidence="0.500842">
Definition 5 The input product Prod(M, G) is the
MBOT Prod(M, G) = (S ×N, E, A, F&apos;, R&apos;) where
</construct>
<listItem confidence="0.948666571428571">
• F&apos;(hs, ni) = F(s) · I(n) for every s ∈ S and
n ∈ N,
• for every rule s(··) a→ s&apos;(· ·&apos;) ∈ R with
s, s&apos; ∈ S and every n ∈ N, there exists a rule
hs, ni(· ·) a→ hs&apos;, ni(· ·&apos;) ∈ R&apos; ,
• for every rule u(s1(· ·1), ... , sk(· ·k)) →a s(· ·)
in R with a ∈ Ek and s, s1, ... , sk ∈ S, and
</listItem>
<bodyText confidence="0.783157">
every production n →b Q(n1, ... , nk) ∈ P, the
following rule is in R&apos;:
</bodyText>
<equation confidence="0.438479">
a(hs1, n1i(· ·1), ... , hsk, nki(··k)) →ab hs, ni(· ·) .
</equation>
<bodyText confidence="0.998126833333333">
The first type of rule (second item) does not in-
volve an input symbol, and thus the nonterminal
of G is just forwarded to the new state. Since no
step with respect to G is made, only the weight of
the rule of M is charged. The second type of rule
(third item) uses a rule of R with the input symbol a
</bodyText>
<equation confidence="0.679001266666667">
S
@
NP2
S
@ NP2 ↔
NP1 V
V NP1
S
NP1 V NP2
S
V NP1 NP2
↔
880
T(31,7,32)
h81,82i → &apos;Y
</equation>
<figureCaption confidence="0.991574">
Figure 5: Constructing a TSG from a weighted string au-
tomaton.
</figureCaption>
<bodyText confidence="0.999382564102564">
and a production of P that also contains Q. The rule
and the production are executed in parallel in the re-
sulting rule and its weight is thus the product of the
weights of the original rule and production. Over-
all, this is a classical product construction, which is
similar to other product constructions such as Bor-
chardt (2004). A straightforward proof shows that
M0(t, u) = M(t, u) · G(t) for every t ∈ TE and
u ∈ TA, which proves the correctness.
Next, let us look at the complexity. The MBOT
Prod(M, G) can be obtained in time O(|M |· |G|).
Furthermore, it is known [see, for example, Maletti
and Satta (2009)] that for every weighted string au-
tomaton A with states S, we can construct a TSG G
in normal form, which has size O(|E |· |S|3) and
recognizes each tree of TE with the weight that the
automaton A assigns to its yield. The idea of this
construction is illustrated in Figure 5. Consequently,
our BAR-HILLEL construction has the well-known
complexity O(|M |· |S|3). This should be compared
to the complexity of the corresponding construction
for an STSG M, which is in O(|M |· |S|2 rk(M)+5)
where rk(M) is the maximal number of (different)
nonterminals in a production of M. Thus, the STSG
should be transformed into an equivalent MBOT in
one-symbol normal form, which can be achieved
in linear time, and the BAR-HILLEL construction
should be performed on this MBOT.
Since STSGs are symmetric, our approach can
also be applied to the output side of an STSG.
However, it should be noted that we can apply it
only to one side (the input side) of the MBOT. A
construction for the output side of the MBOT can
be defined, but it would suffer from a similarly
high complexity as already presented for STSGs.
More precisely, we expect a complexity of roughly
O(|M |· |S|2 rk(M)+2) for this construction. The
small gain is due to the one-symbol normal form and
binarization.
</bodyText>
<sectionHeader confidence="0.995156" genericHeader="method">
6 Composition
</sectionHeader>
<bodyText confidence="0.999117">
Another standard construction for transformations is
(relational) composition. Composition constructs a
translation from a language L to L00 given transla-
tions from L to L0 and from L0 to L00. Formally,
given transformations M0: TE × TA → R and
M00: TA ×Tr → R, the composition of M0 and M00
is a tranformation M0 ; M00: TE × Tr → R with
</bodyText>
<equation confidence="0.994589">
(M0 ; M00)(t, v) = � M0(t, u) · M00(u, v)
u∈TA
</equation>
<bodyText confidence="0.999673583333333">
for every t ∈ TE and v ∈ Tr. Mind that the sum-
mation might be infinite, but we will only consider
compositions, in which it is finite.
Unfortunately, Arnold and Dauchet (1982) show
that the composition of two transformations com-
puted by STSGs cannot necessarily be computed by
an STSG. Consequently, there cannot be a general
composition algorithm for STSGs.
Let us consider the problem of composition for
MBOTs. Essentially, we will follow the unweighted
approach of Engelfriet et al. (2009) to obtain a com-
position construction, which we present next. Let
</bodyText>
<equation confidence="0.9996465">
M0 = (S0, E, A, F0, R0) and
M00 = (S00, A, F, F00, R00)
</equation>
<bodyText confidence="0.999106818181818">
be MBOTs in one-symbol normal form. We ex-
tend the rewrite semantics (see Definition 2) to
trees that include symbols foreign to a MBOT. In
other words, we (virtually) extend the input and
output alphabets to contain all used symbols (in
particular also the states of another MBOT). How-
ever, since we do not extend the set of rules, the
MBOT cannot process foreign symbols. Neverthe-
less it can perform rewrite steps on known sym-
bols (or apply rules that do not contain input sym-
bols). We use ⇒R, and ⇒R,, for derivation steps
</bodyText>
<equation confidence="0.9937859">
h81,83i→Or(h81,82i,h82,83i)
s1 1&apos; s2
Q
Q
s1 s3
h81,82i→Q(h81,82i)
s1 s2 s2 s3
T(s1,&apos;Y, s2)
s1 s2
s1 s2
</equation>
<page confidence="0.984603">
881
</page>
<figure confidence="0.990146928571429">
s&apos;&apos;
1
t1 ··· tm
u1 ··· un
q
x3 x1 x2
··· s&apos;&apos;k
s&apos;
original rule:
σ
q1
q2
→ a
x3
x1 x2
constructed rule:
∼=
I &apos;&apos;
s s1&amp;quot;,...,sk
σ
q
q1
q2
p1
→ a
p2
p3
t1 ··· tm ··· u1 ··· un
</figure>
<figureCaption confidence="0.999502">
Figure 6: Identification in sentential forms.
</figureCaption>
<equation confidence="0.97745">
p1 p2 p3
x4 x5 x1 x2 x3
</equation>
<bodyText confidence="0.934618857142857">
that exclusively use rules of R&apos; and R&apos;&apos;, respectively.
In addition, we identify s&apos;(s&apos;&apos;1(· ·1), ... , s&apos;&apos;k(· ·k))
with s&apos;hs&apos;&apos;1, ... , s&apos;&apos;ki(· ·1, ... , · ·k) fors&apos; ∈ S&apos; and
s&apos;&apos;1, ... , s&apos;&apos;k ∈ S&apos;&apos;. This identification is illustrated
in Figure 6.
Definition 6 The MBOT M&apos; ; M&apos;&apos; = (S, E, F, F, R)
is such that
</bodyText>
<listItem confidence="0.929264666666667">
• for every s&apos; ∈ S&apos;k and s&apos;&apos; 1 ∈ S&apos;&apos; `1,... , s&apos;&apos;k ∈ S&apos;&apos;
`ry
we have s&apos;hs&apos;&apos;1, ... , s&apos;&apos;ki ∈ S`1+&apos;&apos;&apos;+`ry,
• F(s&apos;hs&apos;i) = F&apos;(s&apos;) · F&apos;&apos;(s&apos;&apos;) for every s&apos; ∈ S&apos;1
and s&apos;&apos; ∈ S&apos;&apos;1 , and
• the rules l a→ r of R, all of which are such that
the variables in l occur in order (x1,... , xk)
from left-to-right, are constructed in 3 ways:
– l a⇒R&apos; r by a single rule of R&apos;,
</listItem>
<bodyText confidence="0.97626265">
– l a⇒R&apos;&apos; r by a single rule of R&apos;&apos;, or
– l a1⇒R&apos; ξ a2⇒R&apos;&apos; r with a = a1 · a2 and
the applied rule of R&apos; contains an output
symbol.
If a rule l a→ r can be constructed in several
ways (with exactly weight a), then the weights
of all possibilities are added for the weight of
the new rule.
Intuitively, a single rule of R&apos; without output sym-
bols is used in the first type (because otherwise
r would have the wrong shape). In the second type, a
single rule of R&apos;&apos; without input symbols is used. Fi-
nally, in the third type, first a rule of R&apos; that produces
an output symbol of 0 is used and then this symbol
is processed by a single rule of R&apos;&apos;. Note that every
rule of R&apos; can produce at most one output symbol
and the rules of R&apos;&apos; either process none or one input
symbol due to the assumption that M&apos; and M&apos;&apos; are
in one-symbol normal form. We illustrate a rule of
the first in Figure 7.
</bodyText>
<equation confidence="0.747228">
x1 x2 x3 x4 x5
</equation>
<figureCaption confidence="0.999799">
Figure 7: Example of a constructed rule of type 1.
</figureCaption>
<bodyText confidence="0.9999755">
The correctness proof of this construction can es-
sentially (i.e., for the unweighted case) be found in
Engelfriet et al. (2009). Before we can extend it to
the weighted case, we need to make sure that the
sum in the definition of composition is finite. We
achieve this by requiring that
</bodyText>
<listItem confidence="0.989986285714286">
• for every t ∈ TE and s ∈ S&apos;1 there are finitely
many u ∈ To such that t a1⇒ · · · a�⇒ s(u), or
• for every v ∈ Tr and s ∈ S&apos;&apos;1 there are finitely
many u ∈ To such that u a1⇒ · · · a�⇒ s(v).
In other words, M&apos; may not have cyclic input ε-rules
or M&apos;&apos; may not have cyclic output ε-rules. Now we
can state the main theorem.
</listItem>
<bodyText confidence="0.9507570625">
Theorem 7 For all MBOTs M&apos; and M&apos;&apos; with the
above restriction the composition M&apos; ; M&apos;&apos; of their
transformations can be computed by another MBOT.
This again shows an advantage of MBOTs. The
composition result relies essentially on the one-
symbol normal form (or full binarization), which
can always be achieved for MBOTs, but cannot for
STSGs. Consequently, MBOTs can be composed,
whereas STSGs cannot be composed in general. In-
deed, STSGs in one-symbol normal form, which can
be defined as for MBOTs, can be composed as well,
which shows that the one-symbol normal form is the
key for composition.
Finally, let us discuss the complexity of compo-
sition. Let rk(M&apos;) be the maximal rank of a state
in S&apos;. Then there are
</bodyText>
<listItem confidence="0.9991275">
• O(|M&apos; |· |S&apos;&apos;|rk(M&apos;)) rules of type 1,
• O(|M&apos;&apos;|· |S&apos;&apos;|rk(M&apos;)) rules of type 2, and
</listItem>
<page confidence="0.956316">
882
</page>
<listItem confidence="0.946957">
• O(|M&apos; |· |M&apos;&apos; |· |S&apos;&apos;|rk(M&apos;)) rules of type 3.
</listItem>
<bodyText confidence="0.970986636363636">
Each rule can be constructed in linear time in the size
of the participating rules, so that we obtain a final
complexity of O(|M&apos; |· |M&apos;&apos; |· |S&apos;&apos;|rk(M&apos;)). Note that
if M&apos; is obtained from an STSG M (via Theorem 4),
then rk(M&apos;) ≤ rk(M). This shows that binarization
does not avoid the exponent for composition, but at
least enables composition in the general case. More-
over, the complexity could be slightly improved by
the observation that our construction only relies on
(i) M&apos; having at most one output symbol per rule and
(ii) M&apos;&apos; having at most one input symbol per rule.
</bodyText>
<sectionHeader confidence="0.970687" genericHeader="evaluation">
7 Forward and backward application
</sectionHeader>
<bodyText confidence="0.999990789473684">
We might want to apply a transformation not just to
a single tree, but rather to a set of trees, which are,
in some cases, already weighted. In general, the set
of trees is given by a TSG G and we expect the re-
sult to be represented by a TSG as well. Forward
and backward application amount to computing the
image and pre-image of G under the transformation,
respectively. Since STSG are symmetric, we need to
solve only one of the problems if the transformation
is given by an STSG. The other problem can then be
solved by inverting the STSG (exchanging input and
output) and using the method for the solved prob-
lem. We chose to address forward application here.
Forward application can be reduced to the prob-
lem of computing the co-domain (or range) with the
help of a product construction for STSG, which is
similar to the one presented in Definition 5. The co-
domain codM of the tranformation computed by an
STSG M assigns to each t ∈ TE the weight
</bodyText>
<equation confidence="0.9370875">
codM(t) _ � M(t, u) .
UETA
</equation>
<bodyText confidence="0.999714872340426">
This sum might not be well-defined. However, if
u ∈� N for all productions n: t H u of the STSG,
then the sum is well-defined and the output-side
TSG (i.e., for every production n: t H u in the
STSG there is a production n � u in the TSG)
computes the co-domain. The restriction “u ∈� N”
guarantees that the output side is a TSG. Overall, do-
main, co-domain, and forward and backward appli-
cations (using the product construction) can be com-
puted given such minor new requirements.
Also for transformations computed by MBOTs
we can reduce the problem of forward applica-
tion to the problem of computing the co-domain
with the help of the product construction of Defi-
nition 5. However, the co-domain of an MBOT is
not necessarily representable by a TSG, which is
not due to well-definedness problems but rather the
finite-copying property (Engelfriet et al., 1980) of
MBOTs. This property yields that the co-domain
might not be a regular tree language (or context-free
string language). Consequently, we cannot com-
pute forward or backward applications for arbitrary
MBOT. However, if the MBOT is equivalent to an
STSG (for example, because it was constructed by
the method presented before Theorem 3), then for-
ward and backward application can be computed es-
sentially as for STSG. This can be understood as
a warning. MBOT can efficiently be used (with
computational benefits) as an alternative represen-
tation for transformations computed by STSG (or
compositions of STSG). However, MBOT can also
compute transformations, of which the domain or
range cannot be represented by a TSG. Thus, if we
train MBOT directly and utilize their full expressive
power, then we might not be able to perform forward
and backward application.
In the unweighted case, backward application can
always be computed for MBOT. Moreover, it can be
decided using (´Esik, 1984) whether all forward ap-
plications can be represented by TSGs. However, for
a given specific TSG, it cannot be decided whether
the forward application is representable by a TSG,
which was proved by F¨ul¨op (1994). A subclass
of transformations computable by MBOT (that still
contains all transformations computable by STSG),
which allows all forward and backward applications,
has been identified by Raoult (1993).
</bodyText>
<sectionHeader confidence="0.919309" genericHeader="conclusions">
Conclusion and acknowledgement
</sectionHeader>
<bodyText confidence="0.998777222222222">
We compared STSGs and MBOTs on several stan-
dard algorithms (binarization, regular restriction,
composition, and application). We prove that
MBOTs offer computational benefits on all men-
tioned algorithms as long as the original transforma-
tion is computable by an STSG.
The author was financially supported by the Min-
isterio de Educaci´on y Ciencia (MEC) grants JDCI-
2007-760 and MTM-2007-63422.
</bodyText>
<page confidence="0.998316">
883
</page>
<sectionHeader confidence="0.993794" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999957067307692">
Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory
of Parsing, Translation, and Compiling. Prentice Hall.
Andr´e Arnold and Max Dauchet. 1982. Morphismes
et bimorphismes d’arbres. Theoret. Comput. Sci.,
20(1):33–93.
Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On for-
mal properties of simple phrase structure grammars.
In Language and Information: Selected Essays on
their Theory and Application, pages 116–150. Addi-
son Wesley.
Jean Berstel and Christophe Reutenauer. 1982. Recog-
nizable formal power series on trees. Theoret. Com-
put. Sci., 18(2):115–148.
Bj¨orn Borchardt. 2004. A pumping lemma and decid-
ability problems for recognizable tree series. Acta Cy-
bernet., 16(4):509–544.
Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Fredrick Jelinek, John D. Laf-
ferty, Robert L. Mercer, and Paul S. Roossin. 1990. A
statistical approach to machine translation. Computa-
tional Linguistics, 16(2):79–85.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. Mathematics of
statistical machine translation: Parameter estimation.
Computational Linguistics, 19(2):263–311.
David Chiang and Kevin Knight. 2006. An introduction
to synchronous grammars. In Proc. ACL tutorial.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proc. ACL, pages
263–270.
John DeNero, Mohit Bansal, Adam Pauls, and Dan Klein.
2009a. Efficient parsing for transducer grammars. In
Proc. NAACL, pages 227–235.
John DeNero, Adam Pauls, and Dan Klein. 2009b.
Asynchronous binarization for synchronous gram-
mars. In Proc. ACL, pages 141–144.
Samuel Eilenberg. 1974. Automata, Languages, and
Machines. Academic Press.
Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki.
1980. Tree transducers, L systems, and two-way ma-
chines. J. Comput. System Sci., 20(2):150–202.
Joost Engelfriet, Eric Lilin, and Andreas Maletti. 2009.
Extended multi bottom-up tree transducers: Composi-
tion and decomposition. Acta Inform., 46(8):561–590.
Zolt´an ´Esik. 1984. Decidability results concerning tree
transducers II. Acta Cybernet., 6(3):303–314.
Zolt´an F¨ul¨op and Heiko Vogler. 2009. Weighted tree au-
tomata and tree transducers. In Handbook of Weighted
Automata, chapter IX, pages 313–403. Springer.
Zolt´an F¨ul¨op. 1994. Undecidable properties of determin-
istic top-down tree transducers. Theoret. Comput. Sci.,
134(2):311–328.
Jonathan S. Golan. 1999. Semirings and their Applica-
tions. Kluwer Academic, Dordrecht.
Jonathan Graehl, Kevin Knight, and Jonathan May. 2008.
Training tree transducers. Computational Linguistics,
34(3):391–427.
John E. Hopcroft and Jeffrey D. Ullman. 1979. Intro-
duction to Automata Theory, Languages and Compu-
tation. Addison Wesley.
Liang Huang, Hao Zhang, Daniel Gildea, and Kevin
Knight. 2009. Binarization of synchronous
context-free grammars. Computational Linguistics,
35(4):559–595.
Kevin Knight. 2007. Capturing practical natu-
ral language transformations. Machine Translation,
21(2):121–133.
Eric Lilin. 1981. Propri´et´es de clˆoture d’une extension
de transducteurs d’arbres d´eterministes. In CAAP, vol-
ume 112 of LNCS, pages 280–289. Springer.
Andreas Maletti and Giorgio Satta. 2009. Parsing algo-
rithms based on tree automata. In Proc. IWPT, pages
1–12.
Andreas Maletti, Jonathan Graehl, Mark Hopkins, and
Kevin Knight. 2009. The power of extended top-down
tree transducers. SIAM J. Comput., 39(2):410–430.
Mehryar Mohri. 2009. Weighted automata algorithms.
In Handbook of Weighted Automata, pages 213–254.
Springer.
Mark-Jan Nederhof and Giorgio Satta. 2003. Probabilis-
tic parsing as intersection. In Proc. IWPT, pages 137–
148.
Mark-Jan Nederhof and Giorgio Satta. 2008. Compu-
tation of distances for regular and context-free prob-
abilistic languages. Theoret. Comput. Sci., 395(2–
3):235–254.
Jean-Claude Raoult. 1993. Recursively defined tree
transductions. In Proc. RTA, volume 690 of LNCS,
pages 343–357. Springer.
Jacques Sakarovitch. 2009. Rational and recognisable
power series. In Handbook of Weighted Automata,
chapter IV, pages 105–174. Springer.
Giorgio Satta. 2010. Translation algorithms by means of
language intersection. Manuscript.
Marcel Paul Sch¨utzenberger. 1961. On the definition of
a family of automata. Information and Control, 4(2–
3):245–270.
Wei Wang, Kevin Knight, and Daniel Marcu. 2007. Bi-
narizing syntax trees to improve syntax-based machine
translation accuracy. In Proc. EMNLP-CoNLL, pages
746–754.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous binarization for machine
translation. In Proc. NAACL-HLT, pages 256–263.
</reference>
<page confidence="0.998754">
884
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.781075">
<title confidence="0.999054">Why Synchronous Tree Substitution Grammars?</title>
<author confidence="0.962391">Andreas</author>
<affiliation confidence="0.990085">Universitat Rovira i Virgili, Departament de Filologies</affiliation>
<address confidence="0.816793">Avinguda de Catalunya 35, 43002 Tarragona,</address>
<email confidence="0.989788">andreas.maletti@urv.cat</email>
<abstract confidence="0.9995163125">Synchronous tree substitution grammars are a translation model that is used in syntax-based machine translation. They are investigated in a formal setting and compared to a competitor that is at least as expressive. The competitor is the extended multi bottom-up tree transducer, which is the bottom-up analogue with one essential additional feature. This model has been investigated in theoretical computer science, but seems widely unknown in natural language processing. The two models are compared with respect to standard algorithms (binarization, regular restriction, composition, application). Particular attention is paid to the complexity of the algorithms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>Jeffrey D Ullman</author>
</authors>
<date>1972</date>
<booktitle>The Theory of Parsing, Translation, and Compiling.</booktitle>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="1997" citStr="Aho and Ullman (1972)" startWordPosition="299" endWordPosition="302">ords and the surrounding context. In the field of syntax-based machine translation, the translation models have access to the syntax (in the form of parse trees) of the sentences. Knight (2007) presents a good exposition to both fields. In this paper, we focus on syntax-based translation models, and in particular, synchronous tree substitution grammars (STSGs), or the equally powerful (linear and nondeleting) extended (top-down) tree transducers of Graehl et al. (2008). Chiang and Knight (2006) gives a good introduction to STSGs, which originate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals. Several algorithms for STSGs have been discussed in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the methods of (Zhang et al., 2006; Huang et al., 2009; DeNero et al., 2009b), • parse them [see DeNero et al. (2009a)], or • atte</context>
<context position="13901" citStr="Aho and Ullman (1972)" startWordPosition="2617" endWordPosition="2620">tion. Another binarization of the rule of Figure 4 is displayed in Figure 1. The binarization is evident enough, so we can assume that all trees considered in the following are binarized. The binarization in Figure 1 is unfortunate because the obtained production cannot be factorized such that only two nonterminals occur in each rule. However, the binarization of Figure 4 allows the factorization into S(U, NP) H S(U, NP) and U : @(NP, V ) H @(V , NP), which are fully binarized productions. However, in general, STSGs (or SCFGs or extended tree transducers) cannot be fully binarized as shown in Aho and Ullman (1972). Zhang et al. (2006) and Wang et al. (2007) show the benefits of fully binarized STSGs and present a linear-time algorithm for the binarization of binarizable STSGs. We show that those benefits can be reaped for all STSGs by a simple change of model. 879 Figure 4: Binarization of trees in an STSG production. Top: Original — Bottom: Binarized trees. We have already demonstrated that every STSG can be transformed into an equivalent MBOT in linear time. Next, we discuss binarization of MBOTs. An MBOT is in one-symbol normal form if there is at most one input and at most one output symbol, but at</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Alfred V. Aho and Jeffrey D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e Arnold</author>
<author>Max Dauchet</author>
</authors>
<title>Morphismes et bimorphismes d’arbres.</title>
<date>1982</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="2979" citStr="Arnold and Dauchet (1982)" startWordPosition="462" endWordPosition="465">in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the methods of (Zhang et al., 2006; Huang et al., 2009; DeNero et al., 2009b), • parse them [see DeNero et al. (2009a)], or • attempt to compose them. However, some important algorithms are partial because it is known that the construction might not be possible in general. This is the case, for example, for binarization and composition. In the theoretical computer science community, alternative models have been explored. Such a model is the multi bottom-up tree transducer (MBOT) of Arnold and Dauchet (1982) and Lilin (1981), which essentially is the bottom-up analogue of STSGs with the additional feature that nonterminals can have an arbitrary rank (the rank of a nonterminal of an STSG can be considered to be fixed to 1). This model is even more expressive than STSGs, but still offers good computational properties. In this contribution, we will compare STSGs and MBOTs with respect to some standard algorithms. Generally, MBOTs offer algorithmic benefits over STSG, which can be summarized as fol876 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pa</context>
<context position="9489" citStr="Arnold and Dauchet (1982)" startWordPosition="1761" endWordPosition="1764">rminal n (or the weight a) of a rule n: t ↔� u if the terminal n occurs at the root of t and u (or a = 1). → t instead of n: t � � ↔ t if it is a TSG. A sample STSG production (using those simplifications) is displayed in Figure 1. Our STSGs are essentially equivalent to the (nondeleting and linear) extended tree transducers of Graehl et al. (2008) and Maletti et al. (2009). Figure 2: Sample MBOT rules in one-symbol normal form. 3 Multi bottom-up tree transducers As indicated in the Introduction, we will compare STSGs to weighted multi bottom-up tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A more detailed (and English) presentation can be found in Engelfriet et al. (2009). Let us quickly recall the formal definition. We use a fixed set X = {x1, x2,... } of (formal) variables. For a ranked alphabet S and L ⊆ TΣ(X) we let S(L) = {s(t1, ... , tk) |s ∈ Sk, t1, ... , tk ∈ L} and we treat elements of S(L) like elements of TΣuS(X). Definition 1 A weighted multi bottom-up tree transducer (MBOT) is a system (S, E, A, F, R) where • S, E, and A are ranked alphabets of states, input symbols, and output symbols, respectively, • F : S1 → R assigns final weights, and • R is </context>
<context position="20572" citStr="Arnold and Dauchet (1982)" startWordPosition="3867" endWordPosition="3870">ue to the one-symbol normal form and binarization. 6 Composition Another standard construction for transformations is (relational) composition. Composition constructs a translation from a language L to L00 given translations from L to L0 and from L0 to L00. Formally, given transformations M0: TE × TA → R and M00: TA ×Tr → R, the composition of M0 and M00 is a tranformation M0 ; M00: TE × Tr → R with (M0 ; M00)(t, v) = � M0(t, u) · M00(u, v) u∈TA for every t ∈ TE and v ∈ Tr. Mind that the summation might be infinite, but we will only consider compositions, in which it is finite. Unfortunately, Arnold and Dauchet (1982) show that the composition of two transformations computed by STSGs cannot necessarily be computed by an STSG. Consequently, there cannot be a general composition algorithm for STSGs. Let us consider the problem of composition for MBOTs. Essentially, we will follow the unweighted approach of Engelfriet et al. (2009) to obtain a composition construction, which we present next. Let M0 = (S0, E, A, F0, R0) and M00 = (S00, A, F, F00, R00) be MBOTs in one-symbol normal form. We extend the rewrite semantics (see Definition 2) to trees that include symbols foreign to a MBOT. In other words, we (virtu</context>
</contexts>
<marker>Arnold, Dauchet, 1982</marker>
<rawString>Andr´e Arnold and Max Dauchet. 1982. Morphismes et bimorphismes d’arbres. Theoret. Comput. Sci., 20(1):33–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
<author>M Perles</author>
<author>E Shamir</author>
</authors>
<title>On formal properties of simple phrase structure grammars.</title>
<date>1964</date>
<booktitle>In Language and Information: Selected Essays on their Theory and Application,</booktitle>
<pages>116--150</pages>
<publisher>Addison Wesley.</publisher>
<contexts>
<context position="15868" citStr="Bar-Hillel et al. (1964)" startWordPosition="2951" endWordPosition="2954">unlucky binarization of Figure 1. In the next section, we show the benefit of the full binarization on the example of the BAR-HILLEL construction. 5 Input and output restriction A standard construction for transformation devices (and recognition devices alike) is the regular restriction of the input or output language. This construction is used in parsing, integration of a language model, and the computation of certain metrics [see Nederhof and Satta (2003), Nederhof and Satta (2008), and Satta (2010) for a detailed account]. The construction is generally known as BAR-HILLEL construction [see Bar-Hillel et al. (1964) for the original construction on context-free grammars]. STSGs (and extended tree transducers) are symmetric, so that input and output can freely be swapped. Let M be an STSG and A a weighted string automaton with states S. In the BAR-HILLEL construction for M and A, the maximal rank rk(M) of a symbol in the derivation forest of M enters as an exponent into the complexity O(|M |· |S|2 rk(M)+5). Since full binarization is not possible in general, the maximal rank cannot be limited to 2. In contrast, full binarization is possible for MBOTs (with only linear overhead), so let us investigate whet</context>
</contexts>
<marker>Bar-Hillel, Perles, Shamir, 1964</marker>
<rawString>Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On formal properties of simple phrase structure grammars. In Language and Information: Selected Essays on their Theory and Application, pages 116–150. Addison Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Berstel</author>
<author>Christophe Reutenauer</author>
</authors>
<title>Recognizable formal power series on trees.</title>
<date>1982</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>18</volume>
<issue>2</issue>
<contexts>
<context position="7422" citStr="Berstel and Reutenauer (1982)" startWordPosition="1334" endWordPosition="1337">se STSG productions are symmetric. The size |n: t H u |of a production is |t |+ |u|, and the size |M |of the STSG M is E pcP |p|. It is a weighted tree substitution grammar (TSG) if t= u for all productions n: t ↔� u ∈ P. Further, it is in normal form if for every production n: t ↔� u ∈ P there exist Q ∈ Ek, 6 ∈ Ak, and nonterminals n1, ... , nk, n&apos;1, ... , n&apos;k ∈ N such that t = Q(n1, ... , nk) and u = S(n&apos;1, ... , n&apos;k). A detailed exposition to STSGs and STSGs in normal form (also called synchronous context-free grammars) can be found in Chiang (2005). Further details on TSGs can be found in Berstel and Reutenauer (1982) and F¨ul¨op and Vogler (2009). Equal nonterminals in t and u of a production n: t ↔� u ∈ P are linked. To keep the presentation simple, we assume that those links are re877 x1 x2 Figure 1: STSG production (top) and corresponding MBOT rule (bottom) where @ is an arbitrary symbol that is introduced during binarization. → S S U x2 x3 U&apos; → x2 @ x1 x3 x1 x2 → @ V x2 NP x3 S NP1 @ V NP2 S ↔ V @ NP1 NP2 S S x2 @ x1 x3 S @ NP → x1 V x2 NP x3 U&apos; S NP x1 U x2 x3 membered also in sentential forms. In addition, we assume that N ∩ E = ∅. For every c, c&apos; ∈ CΣ(N) and n ∈ N, let (c[n], c&apos;[n]) &apos;⇒ (c[t], c&apos;[u]</context>
</contexts>
<marker>Berstel, Reutenauer, 1982</marker>
<rawString>Jean Berstel and Christophe Reutenauer. 1982. Recognizable formal power series on trees. Theoret. Comput. Sci., 18(2):115–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bj¨orn Borchardt</author>
</authors>
<title>A pumping lemma and decidability problems for recognizable tree series.</title>
<date>2004</date>
<journal>Acta Cybernet.,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="18447" citStr="Borchardt (2004)" startWordPosition="3482" endWordPosition="3484">ct to G is made, only the weight of the rule of M is charged. The second type of rule (third item) uses a rule of R with the input symbol a S @ NP2 S @ NP2 ↔ NP1 V V NP1 S NP1 V NP2 S V NP1 NP2 ↔ 880 T(31,7,32) h81,82i → &apos;Y Figure 5: Constructing a TSG from a weighted string automaton. and a production of P that also contains Q. The rule and the production are executed in parallel in the resulting rule and its weight is thus the product of the weights of the original rule and production. Overall, this is a classical product construction, which is similar to other product constructions such as Borchardt (2004). A straightforward proof shows that M0(t, u) = M(t, u) · G(t) for every t ∈ TE and u ∈ TA, which proves the correctness. Next, let us look at the complexity. The MBOT Prod(M, G) can be obtained in time O(|M |· |G|). Furthermore, it is known [see, for example, Maletti and Satta (2009)] that for every weighted string automaton A with states S, we can construct a TSG G in normal form, which has size O(|E |· |S|3) and recognizes each tree of TE with the weight that the automaton A assigns to its yield. The idea of this construction is illustrated in Figure 5. Consequently, our BAR-HILLEL construc</context>
</contexts>
<marker>Borchardt, 2004</marker>
<rawString>Bj¨orn Borchardt. 2004. A pumping lemma and decidability problems for recognizable tree series. Acta Cybernet., 16(4):509–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="1161" citStr="Brown et al. (1990)" startWordPosition="163" endWordPosition="166">dditional feature. This model has been investigated in theoretical computer science, but seems widely unknown in natural language processing. The two models are compared with respect to standard algorithms (binarization, regular restriction, composition, application). Particular attention is paid to the complexity of the algorithms. 1 Introduction Every machine translation system uses a translation model, which is a formal model that describes the translation process. Either this system is handcrafted (in rule-based translation systems) or it is trained with the help of statistical processes. Brown et al. (1990) discuss automatically trainable translation models in their seminal paper on the latter approach. The IBM models of Brown et al. (1993) are string-based in the sense that they base the translation decision on the words and the surrounding context. In the field of syntax-based machine translation, the translation models have access to the syntax (in the form of parse trees) of the sentences. Knight (2007) presents a good exposition to both fields. In this paper, we focus on syntax-based translation models, and in particular, synchronous tree substitution grammars (STSGs), or the equally powerf</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>Peter F. Brown, John Cocke, Stephen A. Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin. 1990. A statistical approach to machine translation. Computational Linguistics, 16(2):79–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>Mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1297" citStr="Brown et al. (1993)" startWordPosition="186" endWordPosition="189">sing. The two models are compared with respect to standard algorithms (binarization, regular restriction, composition, application). Particular attention is paid to the complexity of the algorithms. 1 Introduction Every machine translation system uses a translation model, which is a formal model that describes the translation process. Either this system is handcrafted (in rule-based translation systems) or it is trained with the help of statistical processes. Brown et al. (1990) discuss automatically trainable translation models in their seminal paper on the latter approach. The IBM models of Brown et al. (1993) are string-based in the sense that they base the translation decision on the words and the surrounding context. In the field of syntax-based machine translation, the translation models have access to the syntax (in the form of parse trees) of the sentences. Knight (2007) presents a good exposition to both fields. In this paper, we focus on syntax-based translation models, and in particular, synchronous tree substitution grammars (STSGs), or the equally powerful (linear and nondeleting) extended (top-down) tree transducers of Graehl et al. (2008). Chiang and Knight (2006) gives a good introduc</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. Mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Kevin Knight</author>
</authors>
<title>An introduction to synchronous grammars.</title>
<date>2006</date>
<booktitle>In Proc. ACL tutorial.</booktitle>
<contexts>
<context position="1875" citStr="Chiang and Knight (2006)" startWordPosition="280" endWordPosition="283">pproach. The IBM models of Brown et al. (1993) are string-based in the sense that they base the translation decision on the words and the surrounding context. In the field of syntax-based machine translation, the translation models have access to the syntax (in the form of parse trees) of the sentences. Knight (2007) presents a good exposition to both fields. In this paper, we focus on syntax-based translation models, and in particular, synchronous tree substitution grammars (STSGs), or the equally powerful (linear and nondeleting) extended (top-down) tree transducers of Graehl et al. (2008). Chiang and Knight (2006) gives a good introduction to STSGs, which originate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals. Several algorithms for STSGs have been discussed in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the meth</context>
</contexts>
<marker>Chiang, Knight, 2006</marker>
<rawString>David Chiang and Kevin Knight. 2006. An introduction to synchronous grammars. In Proc. ACL tutorial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="6726" citStr="Chiang (2005)" startWordPosition="1188" endWordPosition="1190">(V ). The tree c[t] is obtained from c by replacing the symbol ❑ by t. A weighted synchronous tree substitution grammar (STSG) is a system (N, E, A, I, P) where • N is an alphabet of nonterminals, • E and A are ranked alphabets of input and output symbols, respectively, • I : N → R assigns initial weights, and • P is a finite set of productions n: t ↔� u with n ∈ N, t ∈ TΣ(N), a ∈ R, and u ∈ TΔ(N) such that – every n&apos; ∈ N that occurs in t occurs exactly once in u and vice versa, and – t ∈�N or u ∈�N. Note that our distinction between nonterminals and terminals is rather uncommon for STSG [see Chiang (2005)], but improves the generative power. We chose the symbol “↔” because STSG productions are symmetric. The size |n: t H u |of a production is |t |+ |u|, and the size |M |of the STSG M is E pcP |p|. It is a weighted tree substitution grammar (TSG) if t= u for all productions n: t ↔� u ∈ P. Further, it is in normal form if for every production n: t ↔� u ∈ P there exist Q ∈ Ek, 6 ∈ Ak, and nonterminals n1, ... , nk, n&apos;1, ... , n&apos;k ∈ N such that t = Q(n1, ... , nk) and u = S(n&apos;1, ... , n&apos;k). A detailed exposition to STSGs and STSGs in normal form (also called synchronous context-free grammars) can </context>
<context position="11745" citStr="Chiang (2005)" startWordPosition="2257" endWordPosition="2258">) and O: X —* To. Then c[lO] � c[rO] ifl � r E R. The weight of a �1 � �k is wt(D) = nk derivation D: �0 � · · · �� ��1 az. The weight assigned by the MBOT M to a pair (t, u) E TE x To is M(t, u) = � F(s) · � wt(D) . sES1 D left-most derivation from t to s(u) We use the simplifications already mentioned in the previous section also for MBOTs. Figures 1 and 2 display example rules of an MBOT. The rules of Figure 2 are applied in a derivation in Figure 3. The first displayed derivation step uses the context S(NP(t1), ❑) and any substitution O such that O(x2) = t2 and O(x3) = t3. It is argued by Chiang (2005) and Graehl et al. (2008) that STSGs (and extended tree transducers) have sufficient power for syntax-based machine translation. Knight (2007) presents a detailed overview that also mentions short-comings. Since our newly proposed device, the MBOT, should be at least as powerful as STSGs, we quickly demonstrate how each STSG can be coded as an MBOT. An STSG production and the corresponding MBOT rule are displayed in Figure 1. Since the correspondence is rather trivial, we omit a formal definition. Theorem 3 For every STSG M, an equivalent MBOT can be constructed in time 0(|M|). 4 Binarization </context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proc. ACL, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Mohit Bansal</author>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Efficient parsing for transducer grammars.</title>
<date>2009</date>
<booktitle>In Proc. NAACL,</booktitle>
<pages>227--235</pages>
<contexts>
<context position="2542" citStr="DeNero et al., 2009" startWordPosition="392" endWordPosition="395">nate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals. Several algorithms for STSGs have been discussed in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the methods of (Zhang et al., 2006; Huang et al., 2009; DeNero et al., 2009b), • parse them [see DeNero et al. (2009a)], or • attempt to compose them. However, some important algorithms are partial because it is known that the construction might not be possible in general. This is the case, for example, for binarization and composition. In the theoretical computer science community, alternative models have been explored. Such a model is the multi bottom-up tree transducer (MBOT) of Arnold and Dauchet (1982) and Lilin (1981), which essentially is the bottom-up analogue of STSGs with the additional feature that nonterminals can have an arbitrary rank (the rank of a non</context>
</contexts>
<marker>DeNero, Bansal, Pauls, Klein, 2009</marker>
<rawString>John DeNero, Mohit Bansal, Adam Pauls, and Dan Klein. 2009a. Efficient parsing for transducer grammars. In Proc. NAACL, pages 227–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Asynchronous binarization for synchronous grammars.</title>
<date>2009</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>141--144</pages>
<contexts>
<context position="2542" citStr="DeNero et al., 2009" startWordPosition="392" endWordPosition="395">nate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals. Several algorithms for STSGs have been discussed in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the methods of (Zhang et al., 2006; Huang et al., 2009; DeNero et al., 2009b), • parse them [see DeNero et al. (2009a)], or • attempt to compose them. However, some important algorithms are partial because it is known that the construction might not be possible in general. This is the case, for example, for binarization and composition. In the theoretical computer science community, alternative models have been explored. Such a model is the multi bottom-up tree transducer (MBOT) of Arnold and Dauchet (1982) and Lilin (1981), which essentially is the bottom-up analogue of STSGs with the additional feature that nonterminals can have an arbitrary rank (the rank of a non</context>
</contexts>
<marker>DeNero, Pauls, Klein, 2009</marker>
<rawString>John DeNero, Adam Pauls, and Dan Klein. 2009b. Asynchronous binarization for synchronous grammars. In Proc. ACL, pages 141–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Eilenberg</author>
</authors>
<title>Automata, Languages, and Machines.</title>
<date>1974</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="4849" citStr="Eilenberg (1974)" startWordPosition="773" endWordPosition="774">an algorithmic perspective, it would be beneficial to work with MBOTs instead of STSGs. However, the full power of MBOTs should not be tapped because, in general, MBOTs have the finite-copying property [see Engelfriet et al. (1980)], which complicates the algorithms for forward and backward application (see Section 7). 2 Preliminary definitions An alphabet is a finite set of symbols. Our weighted devices use real-number weights, but the results translate easily to the more general setting of commutative semirings [see Golan (1999)]. A weighted string automaton as in Sch¨utzenberger (1961) and Eilenberg (1974) is a system (S, F, I, T, F) where • S and F are alphabets of states and input symbols, respectively, • I, F : S → R assign initial and final weights, respectively, and • T: S × F × S → R assigns a weight to each transition. Let w = -y1 · · · -yk ∈ F* be an input string of length k. A run on w is r: {0, ... , k} → S. The weight of the run r is wt(r) = Hkz=1 T(rz_1, -yz, rz). The semantics of the automaton A then assigns to w the weight A(w) = � I(r0) · wt(r) · F(rk) . r run on w A good introduction to weighted string automata can be found in Mohri (2009) and Sakarovitch (2009). To simplify the</context>
</contexts>
<marker>Eilenberg, 1974</marker>
<rawString>Samuel Eilenberg. 1974. Automata, Languages, and Machines. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
<author>Grzegorz Rozenberg</author>
<author>Giora Slutzki</author>
</authors>
<title>Tree transducers, L systems, and two-way machines.</title>
<date>1980</date>
<journal>J. Comput. System Sci.,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="4464" citStr="Engelfriet et al. (1980)" startWordPosition="713" endWordPosition="716">asynchronous binarizations) are possible for STSGs. • The input language of an MBOT M can be regularly restricted in O(|M |· |S|3), whereas the corresponding construction for an STSG M is in O(|M |· |S|2 rk(M)+5) where rk(M) is the maximal number of nonterminals in a rule of the STSG M. • MBOTs can be composed, whereas this cannot be achieved for STSGs. Overall, we thus conclude that, from an algorithmic perspective, it would be beneficial to work with MBOTs instead of STSGs. However, the full power of MBOTs should not be tapped because, in general, MBOTs have the finite-copying property [see Engelfriet et al. (1980)], which complicates the algorithms for forward and backward application (see Section 7). 2 Preliminary definitions An alphabet is a finite set of symbols. Our weighted devices use real-number weights, but the results translate easily to the more general setting of commutative semirings [see Golan (1999)]. A weighted string automaton as in Sch¨utzenberger (1961) and Eilenberg (1974) is a system (S, F, I, T, F) where • S and F are alphabets of states and input symbols, respectively, • I, F : S → R assign initial and final weights, respectively, and • T: S × F × S → R assigns a weight to each tr</context>
<context position="27416" citStr="Engelfriet et al., 1980" startWordPosition="5183" endWordPosition="5186">G) computes the co-domain. The restriction “u ∈� N” guarantees that the output side is a TSG. Overall, domain, co-domain, and forward and backward applications (using the product construction) can be computed given such minor new requirements. Also for transformations computed by MBOTs we can reduce the problem of forward application to the problem of computing the co-domain with the help of the product construction of Definition 5. However, the co-domain of an MBOT is not necessarily representable by a TSG, which is not due to well-definedness problems but rather the finite-copying property (Engelfriet et al., 1980) of MBOTs. This property yields that the co-domain might not be a regular tree language (or context-free string language). Consequently, we cannot compute forward or backward applications for arbitrary MBOT. However, if the MBOT is equivalent to an STSG (for example, because it was constructed by the method presented before Theorem 3), then forward and backward application can be computed essentially as for STSG. This can be understood as a warning. MBOT can efficiently be used (with computational benefits) as an alternative representation for transformations computed by STSG (or compositions </context>
</contexts>
<marker>Engelfriet, Rozenberg, Slutzki, 1980</marker>
<rawString>Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki. 1980. Tree transducers, L systems, and two-way machines. J. Comput. System Sci., 20(2):150–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
<author>Eric Lilin</author>
<author>Andreas Maletti</author>
</authors>
<title>Extended multi bottom-up tree transducers: Composition and decomposition.</title>
<date>2009</date>
<journal>Acta Inform.,</journal>
<volume>46</volume>
<issue>8</issue>
<contexts>
<context position="9591" citStr="Engelfriet et al. (2009)" startWordPosition="1778" endWordPosition="1782">1). → t instead of n: t � � ↔ t if it is a TSG. A sample STSG production (using those simplifications) is displayed in Figure 1. Our STSGs are essentially equivalent to the (nondeleting and linear) extended tree transducers of Graehl et al. (2008) and Maletti et al. (2009). Figure 2: Sample MBOT rules in one-symbol normal form. 3 Multi bottom-up tree transducers As indicated in the Introduction, we will compare STSGs to weighted multi bottom-up tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A more detailed (and English) presentation can be found in Engelfriet et al. (2009). Let us quickly recall the formal definition. We use a fixed set X = {x1, x2,... } of (formal) variables. For a ranked alphabet S and L ⊆ TΣ(X) we let S(L) = {s(t1, ... , tk) |s ∈ Sk, t1, ... , tk ∈ L} and we treat elements of S(L) like elements of TΣuS(X). Definition 1 A weighted multi bottom-up tree transducer (MBOT) is a system (S, E, A, F, R) where • S, E, and A are ranked alphabets of states, input symbols, and output symbols, respectively, • F : S1 → R assigns final weights, and • R is a finite set of rules l →� r where a ∈ R, l ∈ TΣ(S(X)), and r ∈ S(TΔ(X)) such that – every x ∈ X that </context>
<context position="14590" citStr="Engelfriet et al. (2009)" startWordPosition="2739" endWordPosition="2742"> fully binarized STSGs and present a linear-time algorithm for the binarization of binarizable STSGs. We show that those benefits can be reaped for all STSGs by a simple change of model. 879 Figure 4: Binarization of trees in an STSG production. Top: Original — Bottom: Binarized trees. We have already demonstrated that every STSG can be transformed into an equivalent MBOT in linear time. Next, we discuss binarization of MBOTs. An MBOT is in one-symbol normal form if there is at most one input and at most one output symbol, but at least one symbol in each rule (see Figure 2). Raoult (1993) and Engelfriet et al. (2009) prove that every MBOT can be transformed into one-symbol normal form. The procedure presented there runs in linear time in the size of the input MBOT. Consequently, we can transform each STSG to an equivalent MBOT in one-symbol normal form in linear time. Finally, we note that a MBOT in one-symbol normal form has binarized derivation trees, which proves that we fully binarized the STSG. Theorem 4 For every STSG M an equivalent, fully binarized MBOT can be constructed in O(|M|). The construction of Engelfriet et al. (2009) is illustrated in Figure 2, which shows the rules of an MBOT in one-sym</context>
<context position="20889" citStr="Engelfriet et al. (2009)" startWordPosition="3916" endWordPosition="3919">×Tr → R, the composition of M0 and M00 is a tranformation M0 ; M00: TE × Tr → R with (M0 ; M00)(t, v) = � M0(t, u) · M00(u, v) u∈TA for every t ∈ TE and v ∈ Tr. Mind that the summation might be infinite, but we will only consider compositions, in which it is finite. Unfortunately, Arnold and Dauchet (1982) show that the composition of two transformations computed by STSGs cannot necessarily be computed by an STSG. Consequently, there cannot be a general composition algorithm for STSGs. Let us consider the problem of composition for MBOTs. Essentially, we will follow the unweighted approach of Engelfriet et al. (2009) to obtain a composition construction, which we present next. Let M0 = (S0, E, A, F0, R0) and M00 = (S00, A, F, F00, R00) be MBOTs in one-symbol normal form. We extend the rewrite semantics (see Definition 2) to trees that include symbols foreign to a MBOT. In other words, we (virtually) extend the input and output alphabets to contain all used symbols (in particular also the states of another MBOT). However, since we do not extend the set of rules, the MBOT cannot process foreign symbols. Nevertheless it can perform rewrite steps on known symbols (or apply rules that do not contain input symb</context>
<context position="23628" citStr="Engelfriet et al. (2009)" startWordPosition="4481" endWordPosition="4484"> of R&apos;&apos; without input symbols is used. Finally, in the third type, first a rule of R&apos; that produces an output symbol of 0 is used and then this symbol is processed by a single rule of R&apos;&apos;. Note that every rule of R&apos; can produce at most one output symbol and the rules of R&apos;&apos; either process none or one input symbol due to the assumption that M&apos; and M&apos;&apos; are in one-symbol normal form. We illustrate a rule of the first in Figure 7. x1 x2 x3 x4 x5 Figure 7: Example of a constructed rule of type 1. The correctness proof of this construction can essentially (i.e., for the unweighted case) be found in Engelfriet et al. (2009). Before we can extend it to the weighted case, we need to make sure that the sum in the definition of composition is finite. We achieve this by requiring that • for every t ∈ TE and s ∈ S&apos;1 there are finitely many u ∈ To such that t a1⇒ · · · a�⇒ s(u), or • for every v ∈ Tr and s ∈ S&apos;&apos;1 there are finitely many u ∈ To such that u a1⇒ · · · a�⇒ s(v). In other words, M&apos; may not have cyclic input ε-rules or M&apos;&apos; may not have cyclic output ε-rules. Now we can state the main theorem. Theorem 7 For all MBOTs M&apos; and M&apos;&apos; with the above restriction the composition M&apos; ; M&apos;&apos; of their transformations can b</context>
</contexts>
<marker>Engelfriet, Lilin, Maletti, 2009</marker>
<rawString>Joost Engelfriet, Eric Lilin, and Andreas Maletti. 2009. Extended multi bottom-up tree transducers: Composition and decomposition. Acta Inform., 46(8):561–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zolt´an ´Esik</author>
</authors>
<title>Decidability results concerning tree transducers II.</title>
<date>1984</date>
<journal>Acta Cybernet.,</journal>
<volume>6</volume>
<issue>3</issue>
<marker>´Esik, 1984</marker>
<rawString>Zolt´an ´Esik. 1984. Decidability results concerning tree transducers II. Acta Cybernet., 6(3):303–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zolt´an F¨ul¨op</author>
<author>Heiko Vogler</author>
</authors>
<title>Weighted tree automata and tree transducers.</title>
<date>2009</date>
<booktitle>In Handbook of Weighted Automata, chapter IX,</booktitle>
<pages>313--403</pages>
<publisher>Springer.</publisher>
<marker>F¨ul¨op, Vogler, 2009</marker>
<rawString>Zolt´an F¨ul¨op and Heiko Vogler. 2009. Weighted tree automata and tree transducers. In Handbook of Weighted Automata, chapter IX, pages 313–403. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zolt´an F¨ul¨op</author>
</authors>
<title>Undecidable properties of deterministic top-down tree transducers.</title>
<date>1994</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>134</volume>
<issue>2</issue>
<marker>F¨ul¨op, 1994</marker>
<rawString>Zolt´an F¨ul¨op. 1994. Undecidable properties of deterministic top-down tree transducers. Theoret. Comput. Sci., 134(2):311–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan S Golan</author>
</authors>
<title>Semirings and their Applications.</title>
<date>1999</date>
<publisher>Kluwer Academic,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="4769" citStr="Golan (1999)" startWordPosition="762" endWordPosition="763">eas this cannot be achieved for STSGs. Overall, we thus conclude that, from an algorithmic perspective, it would be beneficial to work with MBOTs instead of STSGs. However, the full power of MBOTs should not be tapped because, in general, MBOTs have the finite-copying property [see Engelfriet et al. (1980)], which complicates the algorithms for forward and backward application (see Section 7). 2 Preliminary definitions An alphabet is a finite set of symbols. Our weighted devices use real-number weights, but the results translate easily to the more general setting of commutative semirings [see Golan (1999)]. A weighted string automaton as in Sch¨utzenberger (1961) and Eilenberg (1974) is a system (S, F, I, T, F) where • S and F are alphabets of states and input symbols, respectively, • I, F : S → R assign initial and final weights, respectively, and • T: S × F × S → R assigns a weight to each transition. Let w = -y1 · · · -yk ∈ F* be an input string of length k. A run on w is r: {0, ... , k} → S. The weight of the run r is wt(r) = Hkz=1 T(rz_1, -yz, rz). The semantics of the automaton A then assigns to w the weight A(w) = � I(r0) · wt(r) · F(rk) . r run on w A good introduction to weighted stri</context>
</contexts>
<marker>Golan, 1999</marker>
<rawString>Jonathan S. Golan. 1999. Semirings and their Applications. Kluwer Academic, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Jonathan May</author>
</authors>
<title>Training tree transducers.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="1849" citStr="Graehl et al. (2008)" startWordPosition="276" endWordPosition="279"> paper on the latter approach. The IBM models of Brown et al. (1993) are string-based in the sense that they base the translation decision on the words and the surrounding context. In the field of syntax-based machine translation, the translation models have access to the syntax (in the form of parse trees) of the sentences. Knight (2007) presents a good exposition to both fields. In this paper, we focus on syntax-based translation models, and in particular, synchronous tree substitution grammars (STSGs), or the equally powerful (linear and nondeleting) extended (top-down) tree transducers of Graehl et al. (2008). Chiang and Knight (2006) gives a good introduction to STSGs, which originate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals. Several algorithms for STSGs have been discussed in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to bi</context>
<context position="9214" citStr="Graehl et al. (2008)" startWordPosition="1717" endWordPosition="1720">ntactic simplifications such as • several occurrences of the same nonterminal in a tree (disambiguated by decoration). • symbols that are terminals (of E and A) and nonterminals. We will print nonterminals in italics and terminal symbols upright. • omission of the nonterminal n (or the weight a) of a rule n: t ↔� u if the terminal n occurs at the root of t and u (or a = 1). → t instead of n: t � � ↔ t if it is a TSG. A sample STSG production (using those simplifications) is displayed in Figure 1. Our STSGs are essentially equivalent to the (nondeleting and linear) extended tree transducers of Graehl et al. (2008) and Maletti et al. (2009). Figure 2: Sample MBOT rules in one-symbol normal form. 3 Multi bottom-up tree transducers As indicated in the Introduction, we will compare STSGs to weighted multi bottom-up tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A more detailed (and English) presentation can be found in Engelfriet et al. (2009). Let us quickly recall the formal definition. We use a fixed set X = {x1, x2,... } of (formal) variables. For a ranked alphabet S and L ⊆ TΣ(X) we let S(L) = {s(t1, ... , tk) |s ∈ Sk, t1, ... , tk ∈ L} and we treat element</context>
<context position="11770" citStr="Graehl et al. (2008)" startWordPosition="2260" endWordPosition="2263">Then c[lO] � c[rO] ifl � r E R. The weight of a �1 � �k is wt(D) = nk derivation D: �0 � · · · �� ��1 az. The weight assigned by the MBOT M to a pair (t, u) E TE x To is M(t, u) = � F(s) · � wt(D) . sES1 D left-most derivation from t to s(u) We use the simplifications already mentioned in the previous section also for MBOTs. Figures 1 and 2 display example rules of an MBOT. The rules of Figure 2 are applied in a derivation in Figure 3. The first displayed derivation step uses the context S(NP(t1), ❑) and any substitution O such that O(x2) = t2 and O(x3) = t3. It is argued by Chiang (2005) and Graehl et al. (2008) that STSGs (and extended tree transducers) have sufficient power for syntax-based machine translation. Knight (2007) presents a detailed overview that also mentions short-comings. Since our newly proposed device, the MBOT, should be at least as powerful as STSGs, we quickly demonstrate how each STSG can be coded as an MBOT. An STSG production and the corresponding MBOT rule are displayed in Figure 1. Since the correspondence is rather trivial, we omit a formal definition. Theorem 3 For every STSG M, an equivalent MBOT can be constructed in time 0(|M|). 4 Binarization Whenever nondeterminism e</context>
</contexts>
<marker>Graehl, Knight, May, 2008</marker>
<rawString>Jonathan Graehl, Kevin Knight, and Jonathan May. 2008. Training tree transducers. Computational Linguistics, 34(3):391–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John E Hopcroft</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages and Computation.</title>
<date>1979</date>
<publisher>Addison Wesley.</publisher>
<contexts>
<context position="12869" citStr="Hopcroft and Ullman (1979)" startWordPosition="2439" endWordPosition="2442">ion. Theorem 3 For every STSG M, an equivalent MBOT can be constructed in time 0(|M|). 4 Binarization Whenever nondeterminism enters the playfield, binarization becomes an important tool for efficiency reasons. This is based on the simple, yet powerful observation that instead of making 5 choices from a space of n in one instant (represented by n5 rules), it is more efficient (Wang et al., 2007) to make them one-by-one (represented by 5n rules). Clearly, this cannot always be done but positive examples exist in abundance; e.g., binarization of context-free grammars [see CHOMSKY normal form in Hopcroft and Ullman (1979)]. Binarization of tree language devices typically consists of two steps: (i) binarization of the involved trees (using the auxiliary symbol @) and (ii) adjustment (binarization) of the processing device to work on (and fully utilize) the binarized trees. If successful, then this leads to binarized derivation trees for the processing device. In Figure 4 we show the binarization of the trees in an STSG production. Another binarization of the rule of Figure 4 is displayed in Figure 1. The binarization is evident enough, so we can assume that all trees considered in the following are binarized. T</context>
</contexts>
<marker>Hopcroft, Ullman, 1979</marker>
<rawString>John E. Hopcroft and Jeffrey D. Ullman. 1979. Introduction to Automata Theory, Languages and Computation. Addison Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
<author>Kevin Knight</author>
</authors>
<title>Binarization of synchronous context-free grammars.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="2521" citStr="Huang et al., 2009" startWordPosition="388" endWordPosition="391">o STSGs, which originate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals. Several algorithms for STSGs have been discussed in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the methods of (Zhang et al., 2006; Huang et al., 2009; DeNero et al., 2009b), • parse them [see DeNero et al. (2009a)], or • attempt to compose them. However, some important algorithms are partial because it is known that the construction might not be possible in general. This is the case, for example, for binarization and composition. In the theoretical computer science community, alternative models have been explored. Such a model is the multi bottom-up tree transducer (MBOT) of Arnold and Dauchet (1982) and Lilin (1981), which essentially is the bottom-up analogue of STSGs with the additional feature that nonterminals can have an arbitrary ra</context>
</contexts>
<marker>Huang, Zhang, Gildea, Knight, 2009</marker>
<rawString>Liang Huang, Hao Zhang, Daniel Gildea, and Kevin Knight. 2009. Binarization of synchronous context-free grammars. Computational Linguistics, 35(4):559–595.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Capturing practical natural language transformations.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1569" citStr="Knight (2007)" startWordPosition="235" endWordPosition="236"> is a formal model that describes the translation process. Either this system is handcrafted (in rule-based translation systems) or it is trained with the help of statistical processes. Brown et al. (1990) discuss automatically trainable translation models in their seminal paper on the latter approach. The IBM models of Brown et al. (1993) are string-based in the sense that they base the translation decision on the words and the surrounding context. In the field of syntax-based machine translation, the translation models have access to the syntax (in the form of parse trees) of the sentences. Knight (2007) presents a good exposition to both fields. In this paper, we focus on syntax-based translation models, and in particular, synchronous tree substitution grammars (STSGs), or the equally powerful (linear and nondeleting) extended (top-down) tree transducers of Graehl et al. (2008). Chiang and Knight (2006) gives a good introduction to STSGs, which originate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing termina</context>
<context position="11887" citStr="Knight (2007)" startWordPosition="2279" endWordPosition="2280">d by the MBOT M to a pair (t, u) E TE x To is M(t, u) = � F(s) · � wt(D) . sES1 D left-most derivation from t to s(u) We use the simplifications already mentioned in the previous section also for MBOTs. Figures 1 and 2 display example rules of an MBOT. The rules of Figure 2 are applied in a derivation in Figure 3. The first displayed derivation step uses the context S(NP(t1), ❑) and any substitution O such that O(x2) = t2 and O(x3) = t3. It is argued by Chiang (2005) and Graehl et al. (2008) that STSGs (and extended tree transducers) have sufficient power for syntax-based machine translation. Knight (2007) presents a detailed overview that also mentions short-comings. Since our newly proposed device, the MBOT, should be at least as powerful as STSGs, we quickly demonstrate how each STSG can be coded as an MBOT. An STSG production and the corresponding MBOT rule are displayed in Figure 1. Since the correspondence is rather trivial, we omit a formal definition. Theorem 3 For every STSG M, an equivalent MBOT can be constructed in time 0(|M|). 4 Binarization Whenever nondeterminism enters the playfield, binarization becomes an important tool for efficiency reasons. This is based on the simple, yet </context>
</contexts>
<marker>Knight, 2007</marker>
<rawString>Kevin Knight. 2007. Capturing practical natural language transformations. Machine Translation, 21(2):121–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Lilin</author>
</authors>
<title>Propri´et´es de clˆoture d’une extension de transducteurs d’arbres d´eterministes.</title>
<date>1981</date>
<booktitle>In CAAP,</booktitle>
<volume>112</volume>
<pages>280--289</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2996" citStr="Lilin (1981)" startWordPosition="467" endWordPosition="468">, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the methods of (Zhang et al., 2006; Huang et al., 2009; DeNero et al., 2009b), • parse them [see DeNero et al. (2009a)], or • attempt to compose them. However, some important algorithms are partial because it is known that the construction might not be possible in general. This is the case, for example, for binarization and composition. In the theoretical computer science community, alternative models have been explored. Such a model is the multi bottom-up tree transducer (MBOT) of Arnold and Dauchet (1982) and Lilin (1981), which essentially is the bottom-up analogue of STSGs with the additional feature that nonterminals can have an arbitrary rank (the rank of a nonterminal of an STSG can be considered to be fixed to 1). This model is even more expressive than STSGs, but still offers good computational properties. In this contribution, we will compare STSGs and MBOTs with respect to some standard algorithms. Generally, MBOTs offer algorithmic benefits over STSG, which can be summarized as fol876 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 876–884, Los </context>
<context position="9506" citStr="Lilin (1981)" startWordPosition="1766" endWordPosition="1767">a rule n: t ↔� u if the terminal n occurs at the root of t and u (or a = 1). → t instead of n: t � � ↔ t if it is a TSG. A sample STSG production (using those simplifications) is displayed in Figure 1. Our STSGs are essentially equivalent to the (nondeleting and linear) extended tree transducers of Graehl et al. (2008) and Maletti et al. (2009). Figure 2: Sample MBOT rules in one-symbol normal form. 3 Multi bottom-up tree transducers As indicated in the Introduction, we will compare STSGs to weighted multi bottom-up tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A more detailed (and English) presentation can be found in Engelfriet et al. (2009). Let us quickly recall the formal definition. We use a fixed set X = {x1, x2,... } of (formal) variables. For a ranked alphabet S and L ⊆ TΣ(X) we let S(L) = {s(t1, ... , tk) |s ∈ Sk, t1, ... , tk ∈ L} and we treat elements of S(L) like elements of TΣuS(X). Definition 1 A weighted multi bottom-up tree transducer (MBOT) is a system (S, E, A, F, R) where • S, E, and A are ranked alphabets of states, input symbols, and output symbols, respectively, • F : S1 → R assigns final weights, and • R is a finite set of r</context>
</contexts>
<marker>Lilin, 1981</marker>
<rawString>Eric Lilin. 1981. Propri´et´es de clˆoture d’une extension de transducteurs d’arbres d´eterministes. In CAAP, volume 112 of LNCS, pages 280–289. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
<author>Giorgio Satta</author>
</authors>
<title>Parsing algorithms based on tree automata.</title>
<date>2009</date>
<booktitle>In Proc. IWPT,</booktitle>
<pages>1--12</pages>
<contexts>
<context position="18732" citStr="Maletti and Satta (2009)" startWordPosition="3536" endWordPosition="3539">utomaton. and a production of P that also contains Q. The rule and the production are executed in parallel in the resulting rule and its weight is thus the product of the weights of the original rule and production. Overall, this is a classical product construction, which is similar to other product constructions such as Borchardt (2004). A straightforward proof shows that M0(t, u) = M(t, u) · G(t) for every t ∈ TE and u ∈ TA, which proves the correctness. Next, let us look at the complexity. The MBOT Prod(M, G) can be obtained in time O(|M |· |G|). Furthermore, it is known [see, for example, Maletti and Satta (2009)] that for every weighted string automaton A with states S, we can construct a TSG G in normal form, which has size O(|E |· |S|3) and recognizes each tree of TE with the weight that the automaton A assigns to its yield. The idea of this construction is illustrated in Figure 5. Consequently, our BAR-HILLEL construction has the well-known complexity O(|M |· |S|3). This should be compared to the complexity of the corresponding construction for an STSG M, which is in O(|M |· |S|2 rk(M)+5) where rk(M) is the maximal number of (different) nonterminals in a production of M. Thus, the STSG should be t</context>
</contexts>
<marker>Maletti, Satta, 2009</marker>
<rawString>Andreas Maletti and Giorgio Satta. 2009. Parsing algorithms based on tree automata. In Proc. IWPT, pages 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
<author>Jonathan Graehl</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
</authors>
<title>The power of extended top-down tree transducers.</title>
<date>2009</date>
<journal>SIAM J. Comput.,</journal>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="9240" citStr="Maletti et al. (2009)" startWordPosition="1722" endWordPosition="1725">uch as • several occurrences of the same nonterminal in a tree (disambiguated by decoration). • symbols that are terminals (of E and A) and nonterminals. We will print nonterminals in italics and terminal symbols upright. • omission of the nonterminal n (or the weight a) of a rule n: t ↔� u if the terminal n occurs at the root of t and u (or a = 1). → t instead of n: t � � ↔ t if it is a TSG. A sample STSG production (using those simplifications) is displayed in Figure 1. Our STSGs are essentially equivalent to the (nondeleting and linear) extended tree transducers of Graehl et al. (2008) and Maletti et al. (2009). Figure 2: Sample MBOT rules in one-symbol normal form. 3 Multi bottom-up tree transducers As indicated in the Introduction, we will compare STSGs to weighted multi bottom-up tree transducers, which have been introduced by Arnold and Dauchet (1982) and Lilin (1981). A more detailed (and English) presentation can be found in Engelfriet et al. (2009). Let us quickly recall the formal definition. We use a fixed set X = {x1, x2,... } of (formal) variables. For a ranked alphabet S and L ⊆ TΣ(X) we let S(L) = {s(t1, ... , tk) |s ∈ Sk, t1, ... , tk ∈ L} and we treat elements of S(L) like elements of</context>
</contexts>
<marker>Maletti, Graehl, Hopkins, Knight, 2009</marker>
<rawString>Andreas Maletti, Jonathan Graehl, Mark Hopkins, and Kevin Knight. 2009. The power of extended top-down tree transducers. SIAM J. Comput., 39(2):410–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Weighted automata algorithms.</title>
<date>2009</date>
<booktitle>In Handbook of Weighted Automata,</booktitle>
<pages>213--254</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5409" citStr="Mohri (2009)" startWordPosition="904" endWordPosition="905">on as in Sch¨utzenberger (1961) and Eilenberg (1974) is a system (S, F, I, T, F) where • S and F are alphabets of states and input symbols, respectively, • I, F : S → R assign initial and final weights, respectively, and • T: S × F × S → R assigns a weight to each transition. Let w = -y1 · · · -yk ∈ F* be an input string of length k. A run on w is r: {0, ... , k} → S. The weight of the run r is wt(r) = Hkz=1 T(rz_1, -yz, rz). The semantics of the automaton A then assigns to w the weight A(w) = � I(r0) · wt(r) · F(rk) . r run on w A good introduction to weighted string automata can be found in Mohri (2009) and Sakarovitch (2009). To simplify the theoretical discussion, we assume that each symbol that we use in trees has a fixed rank, which determines the number of children of each node with that label. A ranked alphabet E = Uk&gt;0 Ek is an alphabet whose symbols have assigned ranks. The set Ek contains all symbols of rank k. The set TΣ(V ) of E-trees indexed by a set V is the smallest set such that V ⊆ TΣ(V ) and Q(t1, ... , tk) ∈ TΣ(V ) for every Q ∈ Ek and t1, ... , tk ∈ TΣ(V ). The size |t |of the tree t ∈ TΣ is the number of occurrences of symbols from E∪V that appear in t. A context c is a t</context>
</contexts>
<marker>Mohri, 2009</marker>
<rawString>Mehryar Mohri. 2009. Weighted automata algorithms. In Handbook of Weighted Automata, pages 213–254. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark-Jan Nederhof</author>
<author>Giorgio Satta</author>
</authors>
<title>Probabilistic parsing as intersection.</title>
<date>2003</date>
<booktitle>In Proc. IWPT,</booktitle>
<pages>137--148</pages>
<contexts>
<context position="15705" citStr="Nederhof and Satta (2003)" startWordPosition="2927" endWordPosition="2930">nstruction of Engelfriet et al. (2009) is illustrated in Figure 2, which shows the rules of an MBOT in one-symbol normal form. Those rules are constructed from the unlucky binarization of Figure 1. In the next section, we show the benefit of the full binarization on the example of the BAR-HILLEL construction. 5 Input and output restriction A standard construction for transformation devices (and recognition devices alike) is the regular restriction of the input or output language. This construction is used in parsing, integration of a language model, and the computation of certain metrics [see Nederhof and Satta (2003), Nederhof and Satta (2008), and Satta (2010) for a detailed account]. The construction is generally known as BAR-HILLEL construction [see Bar-Hillel et al. (1964) for the original construction on context-free grammars]. STSGs (and extended tree transducers) are symmetric, so that input and output can freely be swapped. Let M be an STSG and A a weighted string automaton with states S. In the BAR-HILLEL construction for M and A, the maximal rank rk(M) of a symbol in the derivation forest of M enters as an exponent into the complexity O(|M |· |S|2 rk(M)+5). Since full binarization is not possibl</context>
</contexts>
<marker>Nederhof, Satta, 2003</marker>
<rawString>Mark-Jan Nederhof and Giorgio Satta. 2003. Probabilistic parsing as intersection. In Proc. IWPT, pages 137– 148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark-Jan Nederhof</author>
<author>Giorgio Satta</author>
</authors>
<title>Computation of distances for regular and context-free probabilistic languages.</title>
<date>2008</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>395</volume>
<issue>2</issue>
<pages>3--235</pages>
<contexts>
<context position="15732" citStr="Nederhof and Satta (2008)" startWordPosition="2931" endWordPosition="2934"> al. (2009) is illustrated in Figure 2, which shows the rules of an MBOT in one-symbol normal form. Those rules are constructed from the unlucky binarization of Figure 1. In the next section, we show the benefit of the full binarization on the example of the BAR-HILLEL construction. 5 Input and output restriction A standard construction for transformation devices (and recognition devices alike) is the regular restriction of the input or output language. This construction is used in parsing, integration of a language model, and the computation of certain metrics [see Nederhof and Satta (2003), Nederhof and Satta (2008), and Satta (2010) for a detailed account]. The construction is generally known as BAR-HILLEL construction [see Bar-Hillel et al. (1964) for the original construction on context-free grammars]. STSGs (and extended tree transducers) are symmetric, so that input and output can freely be swapped. Let M be an STSG and A a weighted string automaton with states S. In the BAR-HILLEL construction for M and A, the maximal rank rk(M) of a symbol in the derivation forest of M enters as an exponent into the complexity O(|M |· |S|2 rk(M)+5). Since full binarization is not possible in general, the maximal r</context>
</contexts>
<marker>Nederhof, Satta, 2008</marker>
<rawString>Mark-Jan Nederhof and Giorgio Satta. 2008. Computation of distances for regular and context-free probabilistic languages. Theoret. Comput. Sci., 395(2– 3):235–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Claude Raoult</author>
</authors>
<title>Recursively defined tree transductions.</title>
<date>1993</date>
<booktitle>In Proc. RTA,</booktitle>
<volume>690</volume>
<pages>343--357</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="14561" citStr="Raoult (1993)" startWordPosition="2736" endWordPosition="2737">ow the benefits of fully binarized STSGs and present a linear-time algorithm for the binarization of binarizable STSGs. We show that those benefits can be reaped for all STSGs by a simple change of model. 879 Figure 4: Binarization of trees in an STSG production. Top: Original — Bottom: Binarized trees. We have already demonstrated that every STSG can be transformed into an equivalent MBOT in linear time. Next, we discuss binarization of MBOTs. An MBOT is in one-symbol normal form if there is at most one input and at most one output symbol, but at least one symbol in each rule (see Figure 2). Raoult (1993) and Engelfriet et al. (2009) prove that every MBOT can be transformed into one-symbol normal form. The procedure presented there runs in linear time in the size of the input MBOT. Consequently, we can transform each STSG to an equivalent MBOT in one-symbol normal form in linear time. Finally, we note that a MBOT in one-symbol normal form has binarized derivation trees, which proves that we fully binarized the STSG. Theorem 4 For every STSG M an equivalent, fully binarized MBOT can be constructed in O(|M|). The construction of Engelfriet et al. (2009) is illustrated in Figure 2, which shows th</context>
</contexts>
<marker>Raoult, 1993</marker>
<rawString>Jean-Claude Raoult. 1993. Recursively defined tree transductions. In Proc. RTA, volume 690 of LNCS, pages 343–357. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Sakarovitch</author>
</authors>
<title>Rational and recognisable power series.</title>
<date>2009</date>
<booktitle>In Handbook of Weighted Automata, chapter IV,</booktitle>
<pages>105--174</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5432" citStr="Sakarovitch (2009)" startWordPosition="907" endWordPosition="908">nberger (1961) and Eilenberg (1974) is a system (S, F, I, T, F) where • S and F are alphabets of states and input symbols, respectively, • I, F : S → R assign initial and final weights, respectively, and • T: S × F × S → R assigns a weight to each transition. Let w = -y1 · · · -yk ∈ F* be an input string of length k. A run on w is r: {0, ... , k} → S. The weight of the run r is wt(r) = Hkz=1 T(rz_1, -yz, rz). The semantics of the automaton A then assigns to w the weight A(w) = � I(r0) · wt(r) · F(rk) . r run on w A good introduction to weighted string automata can be found in Mohri (2009) and Sakarovitch (2009). To simplify the theoretical discussion, we assume that each symbol that we use in trees has a fixed rank, which determines the number of children of each node with that label. A ranked alphabet E = Uk&gt;0 Ek is an alphabet whose symbols have assigned ranks. The set Ek contains all symbols of rank k. The set TΣ(V ) of E-trees indexed by a set V is the smallest set such that V ⊆ TΣ(V ) and Q(t1, ... , tk) ∈ TΣ(V ) for every Q ∈ Ek and t1, ... , tk ∈ TΣ(V ). The size |t |of the tree t ∈ TΣ is the number of occurrences of symbols from E∪V that appear in t. A context c is a tree of TΣujuj(V ), in w</context>
</contexts>
<marker>Sakarovitch, 2009</marker>
<rawString>Jacques Sakarovitch. 2009. Rational and recognisable power series. In Handbook of Weighted Automata, chapter IV, pages 105–174. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
</authors>
<title>Translation algorithms by means of language intersection.</title>
<date>2010</date>
<tech>Manuscript.</tech>
<contexts>
<context position="15750" citStr="Satta (2010)" startWordPosition="2936" endWordPosition="2937">igure 2, which shows the rules of an MBOT in one-symbol normal form. Those rules are constructed from the unlucky binarization of Figure 1. In the next section, we show the benefit of the full binarization on the example of the BAR-HILLEL construction. 5 Input and output restriction A standard construction for transformation devices (and recognition devices alike) is the regular restriction of the input or output language. This construction is used in parsing, integration of a language model, and the computation of certain metrics [see Nederhof and Satta (2003), Nederhof and Satta (2008), and Satta (2010) for a detailed account]. The construction is generally known as BAR-HILLEL construction [see Bar-Hillel et al. (1964) for the original construction on context-free grammars]. STSGs (and extended tree transducers) are symmetric, so that input and output can freely be swapped. Let M be an STSG and A a weighted string automaton with states S. In the BAR-HILLEL construction for M and A, the maximal rank rk(M) of a symbol in the derivation forest of M enters as an exponent into the complexity O(|M |· |S|2 rk(M)+5). Since full binarization is not possible in general, the maximal rank cannot be limi</context>
</contexts>
<marker>Satta, 2010</marker>
<rawString>Giorgio Satta. 2010. Translation algorithms by means of language intersection. Manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcel Paul Sch¨utzenberger</author>
</authors>
<title>On the definition of a family of automata.</title>
<date>1961</date>
<journal>Information and Control,</journal>
<volume>4</volume>
<issue>2</issue>
<pages>3--245</pages>
<marker>Sch¨utzenberger, 1961</marker>
<rawString>Marcel Paul Sch¨utzenberger. 1961. On the definition of a family of automata. Information and Control, 4(2– 3):245–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Binarizing syntax trees to improve syntax-based machine translation accuracy.</title>
<date>2007</date>
<booktitle>In Proc. EMNLP-CoNLL,</booktitle>
<pages>746--754</pages>
<contexts>
<context position="12641" citStr="Wang et al., 2007" startWordPosition="2404" endWordPosition="2407">l as STSGs, we quickly demonstrate how each STSG can be coded as an MBOT. An STSG production and the corresponding MBOT rule are displayed in Figure 1. Since the correspondence is rather trivial, we omit a formal definition. Theorem 3 For every STSG M, an equivalent MBOT can be constructed in time 0(|M|). 4 Binarization Whenever nondeterminism enters the playfield, binarization becomes an important tool for efficiency reasons. This is based on the simple, yet powerful observation that instead of making 5 choices from a space of n in one instant (represented by n5 rules), it is more efficient (Wang et al., 2007) to make them one-by-one (represented by 5n rules). Clearly, this cannot always be done but positive examples exist in abundance; e.g., binarization of context-free grammars [see CHOMSKY normal form in Hopcroft and Ullman (1979)]. Binarization of tree language devices typically consists of two steps: (i) binarization of the involved trees (using the auxiliary symbol @) and (ii) adjustment (binarization) of the processing device to work on (and fully utilize) the binarized trees. If successful, then this leads to binarized derivation trees for the processing device. In Figure 4 we show the bina</context>
<context position="13945" citStr="Wang et al. (2007)" startWordPosition="2626" endWordPosition="2629">e 4 is displayed in Figure 1. The binarization is evident enough, so we can assume that all trees considered in the following are binarized. The binarization in Figure 1 is unfortunate because the obtained production cannot be factorized such that only two nonterminals occur in each rule. However, the binarization of Figure 4 allows the factorization into S(U, NP) H S(U, NP) and U : @(NP, V ) H @(V , NP), which are fully binarized productions. However, in general, STSGs (or SCFGs or extended tree transducers) cannot be fully binarized as shown in Aho and Ullman (1972). Zhang et al. (2006) and Wang et al. (2007) show the benefits of fully binarized STSGs and present a linear-time algorithm for the binarization of binarizable STSGs. We show that those benefits can be reaped for all STSGs by a simple change of model. 879 Figure 4: Binarization of trees in an STSG production. Top: Original — Bottom: Binarized trees. We have already demonstrated that every STSG can be transformed into an equivalent MBOT in linear time. Next, we discuss binarization of MBOTs. An MBOT is in one-symbol normal form if there is at most one input and at most one output symbol, but at least one symbol in each rule (see Figure 2</context>
</contexts>
<marker>Wang, Knight, Marcu, 2007</marker>
<rawString>Wei Wang, Kevin Knight, and Daniel Marcu. 2007. Binarizing syntax trees to improve syntax-based machine translation accuracy. In Proc. EMNLP-CoNLL, pages 746–754.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Liang Huang</author>
<author>Daniel Gildea</author>
<author>Kevin Knight</author>
</authors>
<title>Synchronous binarization for machine translation.</title>
<date>2006</date>
<booktitle>In Proc. NAACL-HLT,</booktitle>
<pages>256--263</pages>
<contexts>
<context position="2501" citStr="Zhang et al., 2006" startWordPosition="384" endWordPosition="387"> good introduction to STSGs, which originate from the syntax-directed translation schemes of Aho and Ullman (1972) [nowadays more commonly known as synchronous context-free grammars]. Roughly speaking, an STSG has rules in which a nonterminal is replaced by two trees containing terminal and nonterminal symbols. In addition, the nonterminals in the two trees are linked and a rule is only applied to linked nonterminals. Several algorithms for STSGs have been discussed in the literature. For example, we can • train them [see Graehl et al. (2008)], • attempt to binarize them using the methods of (Zhang et al., 2006; Huang et al., 2009; DeNero et al., 2009b), • parse them [see DeNero et al. (2009a)], or • attempt to compose them. However, some important algorithms are partial because it is known that the construction might not be possible in general. This is the case, for example, for binarization and composition. In the theoretical computer science community, alternative models have been explored. Such a model is the multi bottom-up tree transducer (MBOT) of Arnold and Dauchet (1982) and Lilin (1981), which essentially is the bottom-up analogue of STSGs with the additional feature that nonterminals can </context>
<context position="13922" citStr="Zhang et al. (2006)" startWordPosition="2621" endWordPosition="2624">ion of the rule of Figure 4 is displayed in Figure 1. The binarization is evident enough, so we can assume that all trees considered in the following are binarized. The binarization in Figure 1 is unfortunate because the obtained production cannot be factorized such that only two nonterminals occur in each rule. However, the binarization of Figure 4 allows the factorization into S(U, NP) H S(U, NP) and U : @(NP, V ) H @(V , NP), which are fully binarized productions. However, in general, STSGs (or SCFGs or extended tree transducers) cannot be fully binarized as shown in Aho and Ullman (1972). Zhang et al. (2006) and Wang et al. (2007) show the benefits of fully binarized STSGs and present a linear-time algorithm for the binarization of binarizable STSGs. We show that those benefits can be reaped for all STSGs by a simple change of model. 879 Figure 4: Binarization of trees in an STSG production. Top: Original — Bottom: Binarized trees. We have already demonstrated that every STSG can be transformed into an equivalent MBOT in linear time. Next, we discuss binarization of MBOTs. An MBOT is in one-symbol normal form if there is at most one input and at most one output symbol, but at least one symbol in </context>
</contexts>
<marker>Zhang, Huang, Gildea, Knight, 2006</marker>
<rawString>Hao Zhang, Liang Huang, Daniel Gildea, and Kevin Knight. 2006. Synchronous binarization for machine translation. In Proc. NAACL-HLT, pages 256–263.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>