<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.023235">
<title confidence="0.86606">
Accessing GermaNet Data and Computing Semantic Relatedness
</title>
<author confidence="0.425494">
Iryna Gurevych and Hendrik Niederlich
</author>
<affiliation confidence="0.239286">
EML Research gGmbH
</affiliation>
<address confidence="0.375339">
Schloss-Wolfsbrunnenweg 33
69118 Heidelberg, Germany
</address>
<email confidence="0.672177">
http://www.eml-research.de/ gurevych
</email>
<sectionHeader confidence="0.985062" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999975071428571">
We present an API developed to access
GermaNet, a lexical semantic database for
German represented in XML. The API
provides a set of software functions for
parsing and retrieving information from
GermaNet. Then, we present a case study
which builds upon the GermaNet API and
implements an application for computing
semantic relatedness according to five dif-
ferent metrics. The package can, again,
serve as a software library to be deployed
in natural language processing applica-
tions. A graphical user interface allows to
interactively experiment with the system.
</bodyText>
<sectionHeader confidence="0.990022" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.999710631578947">
The knowledge encoded in WordNet (Fellbaum,
1998) has proved valuable in many natural lan-
guage processing (NLP) applications. One particu-
lar way to integrate semantic knowledge into appli-
cations is to compute semantic similarity of Word-
Net concepts. This can be used e.g. to perform word
sense disambiguation (Patwardhan et al., 2003),
to find predominant word senses in untagged text
(McCarthy et al., 2004), to automatically generate
spoken dialogue summaries (Gurevych &amp; Strube,
2004), and to perform spelling correction (Hirst &amp;
Budanitsky, 2005).
Extensive research concerning the integration of
semantic knowledge into NLP for the English lan-
guage has been arguably fostered by the emergence
of WordNet::Similarity package (Pedersen et al.,
2004).1 In its turn, the development of the WordNet
based semantic similarity software has been facil-
itated by the availability of tools to easily retrieve
</bodyText>
<footnote confidence="0.987091">
1http://www.d.umn.edu/ tpederse/similarity.html
</footnote>
<bodyText confidence="0.996711444444444">
data from WordNet, e.g. WordNet::QueryData,2
jwnl.3
Research integrating semantic knowledge into
NLP for languages other than English is scarce. On
the one hand, there are fewer computational know-
ledge resources like dictionaries, broad enough in
coverage to be integrated in robust NLP applica-
tions. On the other hand, there is little off-the-shelf
software that allows to develop applications utilizing
semantic knowledge from scratch. While WordNet
counterparts do exist for many languages, e.g. Ger-
maNet (Kunze &amp; Lemnitzer, 2002) and EuroWord-
Net (Vossen, 1999), they differ from WordNet in
certain design aspects. E.g. GermaNet features non-
lexicalized, so called artificial concepts that are non-
existent in WordNet. Also, the adjectives are struc-
tured hierarchically which is not the case in Word-
Net. These and other structural differences led to
divergences in the data model. Therefore, WordNet
based implementations are not applicable to Ger-
maNet. Also, there is generally lack of experimental
evidence concerning the portability of e.g. WordNet
based semantic similarity metrics to other wordnets
and their sensitivity to specific factors, such as net-
work structure, language, etc. Thus, for a researcher
who wants to build a semantic relatedness applica-
tion for a language other than English, it is difficult
to assess the effort and challenges involved in that.
Departing from that, we present an API which
allows to parse and retrieve data from GermaNet.
Though it was developed following the guidelines
for creating WordNet, GermaNet features a cou-
ple of divergent design decisions, such as e.g. the
use of non-lexicalized concepts, the association re-
lation between synsets and the small number of tex-
tual definitions of word senses. Furthermore, we
</bodyText>
<footnote confidence="0.9999235">
2http://search.cpan.org/dist/WordNet-QueryData
3http://sourceforge.net/projects/jwordnet
</footnote>
<page confidence="0.87625">
5
</page>
<note confidence="0.3900465">
Proceedings of the ACL Interactive Poster and Demonstration Sessions,
pages 5–8, Ann Arbor, June 2005. c�2005 Association for Computational Linguistics
</note>
<bodyText confidence="0.9996045">
build an application accessing the knowledge in Ger-
maNet and computing semantic relatedness of Ger-
maNet word senses according to five different met-
rics. Three of these metrics have been adapted from
experiments on English with WordNet, while the re-
maining two are based on automatically generated
definitions of word senses and were developed in the
context of work with GermaNet.
</bodyText>
<sectionHeader confidence="0.988421" genericHeader="introduction">
2 GermaNet API
</sectionHeader>
<bodyText confidence="0.9999761">
The API for accessing GermaNet has to provide
functions similar to the API developed for WordNet.
We evaluated the C-library distributed together with
GermaNet V4.0 and the XML encoded version
of GermaNet (Lemnitzer &amp; Kunze, 2002). As we
wanted the code to be portable across platforms, we
built upon the latter. The XML version of GermaNet
is parsed with the help of the Apache Xerces parser,
http://xml.apache.org/ to create a JAVA object repre-
senting GermaNet. For stemming the words, we use
the functionality provided by the Porter stemmer
for the German language, freely available from
http://snowball.tartarus.org/german/stemmer.html.
Thus, the GermaNet object exists in two versions,
the original one, where the information can be
accessed using words, and the stemmed one, where
the information can be accessed using word stems.
We implemented a range of JAVA based meth-
ods for querying the data. These methods are orga-
nized around the notions of word sense and synset.
On the word sense (WS) level, we have the follow-
ing methods: getAntonyms() retrieves all antonyms
of a given WS; getArtificial() indicates whether a
WS is an artificial concept; getGrapheme() gets a
graphemic representation of a WS; getParticipleOf()
retrieves the WS of the verb that the word sense is
a participle of; getPartOfSpeech() gets the part of
speech associated with a WS; getPertonym() gives
the WS that the word sense is derived from; get-
ProperName() indicates whether the WS is a proper
name; getSense() yields the sense number of a WS in
GermaNet; getStyle() indicates if the WS is stylisti-
cally marked; getSynset() returns the corresponding
synset; toString() yields a string representing a WS.
On the synset level, the following information can
be accessed: getAssociations() returns all associa-
tions; getCausations() gets the effects that a given
synset is a cause of; getEntailments() yields synsets
that entail a given synset; getHolonyms(), getHy-
ponyms(), getHypernyms(), getMeronyms() return a
list of holonyms, hyponyms, immediate hypernyms,
and meronyms respectively; getPartOfSpeech() re-
turns the part of speech associated with word senses
of a synset; getWordSenses() returns all word senses
constituting the synset; toString() yields a string re-
presentation of a synset.
The metrics of semantic relatedness are designed
to employ this API. They are implemented as classes
which use the API methods on an instance of the
GermaNet object.
</bodyText>
<sectionHeader confidence="0.99819" genericHeader="method">
3 Semantic Relatedness Software
</sectionHeader>
<bodyText confidence="0.999984620689655">
In GermaNet, nouns, verbs and adjectives are struc-
tured within hierarchies of is-a relations.4 Ger-
maNet also contains information on additional
lexical and semantic relations, e.g. hypernymy,
meronymy, antonymy, etc. (Kunze &amp; Lemnitzer,
2002). A semantic relatedness metric specifies to
what degree the meanings of two words are related
to each other. E.g. the meanings of Glas (Engl.
glass) and Becher (Engl. cup) will be typically clas-
sified as being closely related to each other, while
the relation between Glas and Juwel (Engl. gem)
is more distant. RelatednessComparator is a class
which takes two words as input and returns a nu-
meric value indicating semantic relatedness for the
two words. Semantic relatedness metrics have been
implemented as descendants of this class.
Three of the metrics for computing semantic relat-
edness are information content based (Resnik, 1995;
Jiang &amp; Conrath, 1997; Lin, 1998) and are also im-
plemented in WordNet::Similarity package. How-
ever, some aspects in the normalization of their
results and the task definition according to which
the evaluation is conducted have been changed
(Gurevych &amp; Niederlich, 2005). The metrics are
implemented as classes derived from Information-
BasedComparator, which is in its turn derived from
the class PathBasedComparator. They make use of
both the GermaNet hierarchy and statistical corpus
evidence, i.e. information content.
</bodyText>
<footnote confidence="0.98576375">
4As mentioned before, GermaNet abandoned the cluster-
approach taken in WordNet to group adjectives. Instead a hi-
erarchical structuring based on the work by Hundsnurscher &amp;
Splett (1982) applies, as is the case with nouns and verbs.
</footnote>
<page confidence="0.997693">
6
</page>
<bodyText confidence="0.9998231875">
We implemented a set of utilities for computing
information content of German word senses from
German corpora according to the method by Resnik
(1995). The TreeTagger (Schmid, 1997) is em-
ployed to compile a part-of-speech tagged word fre-
quency list. The information content values of Ger-
maNet synsets are saved in a text file called an in-
formation content map. We experimented with dif-
ferent configurations of the system, one of which in-
volved stemming of corpora and the other did not
involve any morphological processing. Contrary to
our intuition, there was almost no difference in the
information content maps arising from the both sys-
tem configurations, with and without morphological
processing. Therefore, the use of stemming in com-
puting information content of German synsets seems
to be unjustified.
The remaining two metrics of semantic related-
ness are based on the Lesk algorithm (Lesk, 1986).
The Lesk algorithm computes the number of over-
laps in the definitions of words, which are some-
times extended with the definitions of words related
to the given word senses (Patwardhan et al., 2003).
This algorithm for computing semantic relatedness
is very attractive. It is conceptually simple and does
not require an additional effort of corpus analysis
compared with information content based metrics.
However, a straightforward adaptation of the Lesk
metric to GermaNet turned out to be impossible.
Textual definitions of word senses in GermaNet are
fairly short and small in number. In cotrast to Word-
Net, GermaNet cannot be employed as a machine-
readable dictionary, but is primarily a conceptual
network. In order to deal with this, we developed
a novel methodology which generates definitions
of word senses automatically from GermaNet us-
ing the GermaNet API. Examples of such automati-
cally generated definitions can be found in Gurevych
&amp; Niederlich (2005). The method is implemented
in the class PseudoGlossGenerator of our software,
which automatically generates glosses on the basis
of the conceptual hierarchy.
Two metrics of semantic relatedness are, then,
based on the application of the Lesk algorithm to
definitions, generated automatically according to
two system configurations. The generated defini-
tions can be tailored to the task at hand according to
a set of parameters defining which related concepts
</bodyText>
<figureCaption confidence="0.999861">
Figure 1: The concept of user-system interaction.
</figureCaption>
<bodyText confidence="0.999965555555555">
have to be included in the final definition. Exper-
iments carried out to determine the most effective
parameters for generating the definitions and em-
ploying those to compute semantic relatedness is de-
scribed in Gurevych (2005). Gurevych &amp; Niederlich
(2005) present a description of the evaluation proce-
dure for five implemented semantic relatedness met-
rics against a human Gold Standard and the evalua-
tion results.
</bodyText>
<sectionHeader confidence="0.955281" genericHeader="method">
4 Graphical User Interface
</sectionHeader>
<bodyText confidence="0.999955">
We developed a graphical user interface to interac-
tively experiment with the software for computing
semantic relatedness. The system runs on a standard
Linux or Windows machine. Upon initialization, we
configured the system to load an information con-
tent map computed from the German taz corpus.5
The information content values encoded therein are
employed by the information content based metrics.
For the Lesk based metrics, two best configurations
for generating definitions of word senses are offered
via the GUI: one including three hypernyms of a
word sense, and the other one including all related
synsets (two iterations) except hyponyms. The rep-
resentation of synsets in a generated definition is
constituted by one (the first) of their word senses.
The user of the GUI can enter two words to-
gether with their part-of-speech and specify one of
the five metrics. Then, the system displays the cor-
responding word stems, possible word senses ac-
</bodyText>
<footnote confidence="0.986009">
5www.taz.de
</footnote>
<page confidence="0.99946">
7
</page>
<bodyText confidence="0.999928647058824">
cording to GermaNet, definitions generated for these
word senses and their information content values.
Furthermore, possible combinations of word senses
for the two words are created and returned together
with various diagnostic information specific to each
of the metrics. This may be e.g. word overlaps in
definitions for the Lesk based metrics, or lowest
common subsumers and their respective information
content values, depending on what is appropriate.
Finally, the best word sense combination for the two
words is determined and this is compactly displayed
together with a semantic relatedness score. The in-
terface allows the user to add notes to the results by
directly editing the data shown in the GUI and save
the detailed analysis in a text file for off-line inspec-
tion. The process of user-system interaction is sum-
marized in Figure 1.
</bodyText>
<sectionHeader confidence="0.998201" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999990214285714">
We presented software implementing an API to
GermaNet and a case study built with this API, a
package to compute five semantic relatedness met-
rics. We revised the metrics and in some cases re-
designed them for the German language and Ger-
maNet, as the latter is different from WordNet in a
number of respects. The set of software functions
resulting from our work is implemented in a JAVA
library and can be used to build NLP applications
with GermaNet or integrate GermaNet based seman-
tic relatedness metrics into NLP systems. Also, we
provide a graphical user interface which allows to
interactively experiment with the system and study
the performance of different metrics.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999832">
This work has been funded by the Klaus Tschira
Foundation. We thank Michael Strube for his valu-
able comments concerning this work.
</bodyText>
<sectionHeader confidence="0.998978" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99961">
Fellbaum, Christiane (Ed.) (1998). WordNet: An Electronic
Lexical Database. Cambridge, Mass.: MIT Press.
Gurevych, Iryna (2005). Using the Structure of a Conceptual
Network in Computing Semantic Relatedness. Submitted.
Gurevych, Iryna &amp; Hendrik Niederlich (2005). Computing
semantic relatedness of GermaNet concepts. In Bernhard
Fisseni, Hans-Christian Schmitz, Bernhard Schr¨oder &amp; Pe-
tra Wagner (Eds.), Sprachtechnologie, mobile Kommunika-
tion und linguistische Ressourcen: Proceedings of Workshop
”Applications of GermaNet II” at GLDV’2005, pp. 462–474.
Peter Lang.
Gurevych, Iryna &amp; Michael Strube (2004). Semantic similar-
ity applied to spoken dialogue summarization. In Proceed-
ings of the 20th International Conference on Computational
Linguistics, Geneva, Switzerland, 23 – 27 August 2004, pp.
764–770.
Hirst, Graeme &amp; Alexander Budanitsky (2005). Correcting real-
word spelling errors by restoring lexical cohesion. Natural
Language Engineering, 11(1):87–111.
Hundsnurscher, F. &amp; J. Splett (1982). Semantik der Adjektive
im Deutschen: Analyse der semantischen Relationen. West-
deutscher Verlag.
Jiang, Jay J. &amp; David W. Conrath (1997). Semantic similar-
ity based on corpus statistics and lexical taxonomy. In Pro-
ceedings of the 10th International Conference on Research
in Computational Linguistics (ROCLING). Tapei, Taiwan.
Kunze, Claudia &amp; Lothar Lemnitzer (2002). GermaNet - rep-
resentation, visualization, application. In Proceedings of the
International Conference on Language Resources and Eval-
uation (LREC), Las Palmas, Canary Islands, Spain, 29 - 31
May, pp. 1485–1491.
Lemnitzer, Lothar &amp; Claudia Kunze (2002). Adapting Ger-
maNet for the Web. In Proceedings of the first Global
WordNet Conference, Central Institute ofIndian Languages.
Mysore, India, pp. 174–181.
Lesk, Michael (1986). Automatic sense disambiguation using
machine readable dictionaries: How to tell a pine cone from
an ice cream cone. In Proceedings of the 5th Annual In-
ternational Conference on Systems Documentation, Toronto,
Ontario, Canada, June, pp. 24–26.
Lin, Dekang (1998). An information-theoretic definition of sim-
ilarity. In Proceedings of the 15th International Conference
on Machine Learning, San Francisco, Cal., pp. 296–304.
McCarthy, Diana, Rob Koeling, Julie Weeds &amp; John Carroll
(2004). Finding predominant senses in untagged text. In
Proceedings of the 42nd Annual Meeting of the Association
for Computational Linguistics, Barcelona, Spain, 21–26 July
2004, pp. 280 – 287.
Patwardhan, Siddharth, Satanjeev Banerjee &amp; Ted Pedersen
(2003). Using measures of semantic relatedness for word
sense disambiguation. In Proceedings of the Fourth Interna-
tional Conference on Intelligent Text Processing and Com-
putational Linguistics, Mexico City, Mexico, pp. 241–257.
Pedersen, Ted, Siddharth Patwardhan &amp; Jason Michelizzi
(2004). WordNet::Similarity – Measuring the relatedness of
concepts. In Demonstrations of the Human Language Tech-
nology Conference of the North American Chapter of the As-
sociation for Computational Linguistics, Boston, Mass., 2–7
May 2004, pp. 267–270.
Resnik, Phil (1995). Using information content to evalu-
ate semantic similarity in a taxonomy. In Proceedings of
the 14th International Joint Conference on Artificial Intel-
ligence, Montr´eal, Canada, 20–25 August 1995, Vol. 1, pp.
448–453.
Schmid, Helmut (1997). Probabilistic part-of-speech tagging
using decision trees. In Daniel Jones &amp; Harold Somers
(Eds.), New Methods in Language Processing, Studies in
Computational Linguistics, pp. 154–164. London, UK: UCL
Press.
Vossen, Piek (1999). EuroWordNet: a mutlilingual database
with lexical-semantic networks. Dordrecht: Kluwer Aca-
demic Publishers.
</reference>
<page confidence="0.998492">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.019442">
<title confidence="0.999708">Accessing GermaNet Data and Computing Semantic Relatedness</title>
<author confidence="0.997254">Iryna Gurevych</author>
<author confidence="0.997254">Hendrik Niederlich</author>
<affiliation confidence="0.97195">EML Research gGmbH</affiliation>
<address confidence="0.969096">Schloss-Wolfsbrunnenweg 33 69118 Heidelberg, Germany</address>
<web confidence="0.821332">http://www.eml-research.de/ gurevych</web>
<abstract confidence="0.996188157706094">We present an API developed to access GermaNet, a lexical semantic database for German represented in XML. The API provides a set of software functions for parsing and retrieving information from GermaNet. Then, we present a case study which builds upon the GermaNet API and implements an application for computing semantic relatedness according to five different metrics. The package can, again, serve as a software library to be deployed in natural language processing applications. A graphical user interface allows to interactively experiment with the system. 1 Motivation The knowledge encoded in WordNet (Fellbaum, 1998) has proved valuable in many natural language processing (NLP) applications. One particular way to integrate semantic knowledge into applications is to compute semantic similarity of Word- Net concepts. This can be used e.g. to perform word sense disambiguation (Patwardhan et al., 2003), to find predominant word senses in untagged text (McCarthy et al., 2004), to automatically generate spoken dialogue summaries (Gurevych &amp; Strube, 2004), and to perform spelling correction (Hirst &amp; Budanitsky, 2005). Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al., In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve tpederse/similarity.html from WordNet, e.g. Research integrating semantic knowledge into NLP for languages other than English is scarce. On the one hand, there are fewer computational knowledge resources like dictionaries, broad enough in coverage to be integrated in robust NLP applications. On the other hand, there is little off-the-shelf software that allows to develop applications utilizing semantic knowledge from scratch. While WordNet counterparts do exist for many languages, e.g. GermaNet (Kunze &amp; Lemnitzer, 2002) and EuroWord- Net (Vossen, 1999), they differ from WordNet in certain design aspects. E.g. GermaNet features nonso called that are nonexistent in WordNet. Also, the adjectives are structured hierarchically which is not the case in Word- Net. These and other structural differences led to divergences in the data model. Therefore, WordNet based implementations are not applicable to GermaNet. Also, there is generally lack of experimental evidence concerning the portability of e.g. WordNet based semantic similarity metrics to other wordnets and their sensitivity to specific factors, such as network structure, language, etc. Thus, for a researcher who wants to build a semantic relatedness application for a language other than English, it is difficult to assess the effort and challenges involved in that. Departing from that, we present an API which allows to parse and retrieve data from GermaNet. Though it was developed following the guidelines for creating WordNet, GermaNet features a couple of divergent design decisions, such as e.g. the use of non-lexicalized concepts, the association relation between synsets and the small number of textual definitions of word senses. Furthermore, we 5 Proceedings of the ACL Interactive Poster and Demonstration Sessions, 5–8, Ann Arbor, June 2005. Association for Computational Linguistics build an application accessing the knowledge in GermaNet and computing semantic relatedness of GermaNet word senses according to five different metrics. Three of these metrics have been adapted from experiments on English with WordNet, while the remaining two are based on automatically generated definitions of word senses and were developed in the context of work with GermaNet. 2 GermaNet API The API for accessing GermaNet has to provide functions similar to the API developed for WordNet. We evaluated the C-library distributed together with GermaNet V4.0 and the XML encoded version of GermaNet (Lemnitzer &amp; Kunze, 2002). As we wanted the code to be portable across platforms, we built upon the latter. The XML version of GermaNet is parsed with the help of the Apache Xerces parser, http://xml.apache.org/ to create a JAVA object representing GermaNet. For stemming the words, we use the functionality provided by the Porter stemmer for the German language, freely available from http://snowball.tartarus.org/german/stemmer.html. Thus, the GermaNet object exists in two versions, the original one, where the information can be accessed using words, and the stemmed one, where the information can be accessed using word stems. We implemented a range of JAVA based methods for querying the data. These methods are organized around the notions of word sense and synset. On the word sense (WS) level, we have the followmethods: all antonyms a given WS; whether a is an artificial concept; a representation of a WS; retrieves the WS of the verb that the word sense is participle of; the part of associated with a WS; WS that the word sense is derived from; getwhether the WS is a proper the sense number of a WS in if the WS is stylistimarked; the corresponding a string representing a WS. On the synset level, the following information can accessed: all associathe effects that a given is a cause of; synsets entail a given synset; getHya list of holonyms, hyponyms, immediate hypernyms, meronyms respectively; returns the part of speech associated with word senses a synset; all word senses the synset; a string representation of a synset. The metrics of semantic relatedness are designed to employ this API. They are implemented as classes which use the API methods on an instance of the GermaNet object. 3 Semantic Relatedness Software In GermaNet, nouns, verbs and adjectives are strucwithin hierarchies of GermaNet also contains information on additional lexical and semantic relations, e.g. hypernymy, meronymy, antonymy, etc. (Kunze &amp; Lemnitzer, 2002). A semantic relatedness metric specifies to what degree the meanings of two words are related each other. E.g. the meanings of and will be typically classified as being closely related to each other, while relation between more distant. a class which takes two words as input and returns a numeric value indicating semantic relatedness for the two words. Semantic relatedness metrics have been implemented as descendants of this class. Three of the metrics for computing semantic relatedness are information content based (Resnik, 1995; Jiang &amp; Conrath, 1997; Lin, 1998) and are also implemented in WordNet::Similarity package. However, some aspects in the normalization of their results and the task definition according to which the evaluation is conducted have been changed (Gurevych &amp; Niederlich, 2005). The metrics are as classes derived from Informationwhich is in its turn derived from class They make use of both the GermaNet hierarchy and statistical corpus evidence, i.e. information content. mentioned before, GermaNet abandoned the clusterapproach taken in WordNet to group adjectives. Instead a hierarchical structuring based on the work by Hundsnurscher &amp; Splett (1982) applies, as is the case with nouns and verbs. 6 We implemented a set of utilities for computing information content of German word senses from German corpora according to the method by Resnik (1995). The TreeTagger (Schmid, 1997) is employed to compile a part-of-speech tagged word frequency list. The information content values of GermaNet synsets are saved in a text file called an information content map. We experimented with different configurations of the system, one of which involved stemming of corpora and the other did not involve any morphological processing. Contrary to our intuition, there was almost no difference in the information content maps arising from the both system configurations, with and without morphological processing. Therefore, the use of stemming in computing information content of German synsets seems to be unjustified. The remaining two metrics of semantic relatedness are based on the Lesk algorithm (Lesk, 1986). The Lesk algorithm computes the number of overlaps in the definitions of words, which are sometimes extended with the definitions of words related to the given word senses (Patwardhan et al., 2003). This algorithm for computing semantic relatedness is very attractive. It is conceptually simple and does not require an additional effort of corpus analysis compared with information content based metrics. However, a straightforward adaptation of the Lesk metric to GermaNet turned out to be impossible. Textual definitions of word senses in GermaNet are fairly short and small in number. In cotrast to Word- Net, GermaNet cannot be employed as a machinereadable dictionary, but is primarily a conceptual network. In order to deal with this, we developed a novel methodology which generates definitions of word senses automatically from GermaNet using the GermaNet API. Examples of such automatically generated definitions can be found in Gurevych &amp; Niederlich (2005). The method is implemented the class our software, which automatically generates glosses on the basis of the conceptual hierarchy. Two metrics of semantic relatedness are, then, based on the application of the Lesk algorithm to definitions, generated automatically according to two system configurations. The generated definitions can be tailored to the task at hand according to a set of parameters defining which related concepts Figure 1: The concept of user-system interaction. have to be included in the final definition. Experiments carried out to determine the most effective parameters for generating the definitions and employing those to compute semantic relatedness is described in Gurevych (2005). Gurevych &amp; Niederlich (2005) present a description of the evaluation procedure for five implemented semantic relatedness metagainst a human Standard the evaluation results. 4 Graphical User Interface We developed a graphical user interface to interactively experiment with the software for computing semantic relatedness. The system runs on a standard Linux or Windows machine. Upon initialization, we configured the system to load an information conmap computed from the German The information content values encoded therein are employed by the information content based metrics. For the Lesk based metrics, two best configurations for generating definitions of word senses are offered via the GUI: one including three hypernyms of a word sense, and the other one including all related synsets (two iterations) except hyponyms. The representation of synsets in a generated definition is constituted by one (the first) of their word senses. The user of the GUI can enter two words together with their part-of-speech and specify one of the five metrics. Then, the system displays the corword stems, possible word senses ac- 7 cording to GermaNet, definitions generated for these word senses and their information content values. Furthermore, possible combinations of word senses for the two words are created and returned together with various diagnostic information specific to each of the metrics. This may be e.g. word overlaps in definitions for the Lesk based metrics, or lowest common subsumers and their respective information content values, depending on what is appropriate. Finally, the best word sense combination for the two words is determined and this is compactly displayed together with a semantic relatedness score. The interface allows the user to add notes to the results by directly editing the data shown in the GUI and save the detailed analysis in a text file for off-line inspection. The process of user-system interaction is summarized in Figure 1. 5 Conclusions We presented software implementing an API to GermaNet and a case study built with this API, a package to compute five semantic relatedness metrics. We revised the metrics and in some cases redesigned them for the German language and GermaNet, as the latter is different from WordNet in a number of respects. The set of software functions resulting from our work is implemented in a JAVA library and can be used to build NLP applications with GermaNet or integrate GermaNet based semantic relatedness metrics into NLP systems. Also, we provide a graphical user interface which allows to interactively experiment with the system and study the performance of different metrics.</abstract>
<note confidence="0.890247756410257">Acknowledgments This work has been funded by the Klaus Tschira Foundation. We thank Michael Strube for his valuable comments concerning this work. References Christiane (Ed.) (1998). An Electronic Cambridge, Mass.: MIT Press. Iryna (2005). the Structure of a Conceptual in Computing Semantic Submitted. Gurevych, Iryna &amp; Hendrik Niederlich (2005). Computing semantic relatedness of GermaNet concepts. In Bernhard Fisseni, Hans-Christian Schmitz, Bernhard Schr¨oder &amp; Pe- Wagner (Eds.), mobile Kommunikation und linguistische Ressourcen: Proceedings of Workshop of GermaNet II” at pp. 462–474. Peter Lang. Gurevych, Iryna &amp; Michael Strube (2004). Semantic similarapplied to spoken dialogue summarization. In Proceedings of the 20th International Conference on Computational Switzerland, 23 – 27 August 2004, pp. 764–770. Hirst, Graeme &amp; Alexander Budanitsky (2005). Correcting realspelling errors by restoring lexical cohesion. 11(1):87–111. F. &amp; J. Splett (1982). der Adjektive Deutschen: Analyse der semantischen Westdeutscher Verlag. Jiang, Jay J. &amp; David W. Conrath (1997). Semantic similarbased on corpus statistics and lexical taxonomy. In Proceedings of the 10th International Conference on Research Computational Linguistics Tapei, Taiwan. Kunze, Claudia &amp; Lothar Lemnitzer (2002). GermaNet repvisualization, application. In of the International Conference on Language Resources and Eval- (LREC), Palmas, Canary Islands, Spain, 29 - 31 May, pp. 1485–1491. Lemnitzer, Lothar &amp; Claudia Kunze (2002). Adapting Gerfor the Web. In of the first Global WordNet Conference, Central Institute ofIndian Languages. pp. 174–181. Lesk, Michael (1986). Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from ice cream cone. In of the 5th Annual In- Conference on Systems Documentation, Ontario, Canada, June, pp. 24–26. Lin, Dekang (1998). An information-theoretic definition of sim- In of the 15th International Conference Machine Learning, Francisco, Cal., pp. 296–304. McCarthy, Diana, Rob Koeling, Julie Weeds &amp; John Carroll (2004). Finding predominant senses in untagged text. In Proceedings of the 42nd Annual Meeting of the Association Computational Linguistics, Spain, 21–26 July 2004, pp. 280 – 287. Patwardhan, Siddharth, Satanjeev Banerjee &amp; Ted Pedersen (2003). Using measures of semantic relatedness for word disambiguation. In of the Fourth International Conference on Intelligent Text Processing and Com- Linguistics, City, Mexico, pp. 241–257. Pedersen, Ted, Siddharth Patwardhan &amp; Jason Michelizzi (2004). WordNet::Similarity – Measuring the relatedness of In of the Human Language Technology Conference of the North American Chapter of the Asfor Computational Linguistics, Mass., 2–7 May 2004, pp. 267–270. Resnik, Phil (1995). Using information content to evalusemantic similarity in a taxonomy. In of the 14th International Joint Conference on Artificial Intel- Canada, 20–25 August 1995, Vol. 1, pp. 448–453. Schmid, Helmut (1997). Probabilistic part-of-speech tagging using decision trees. In Daniel Jones &amp; Harold Somers Methods in Language Studies in Computational Linguistics, pp. 154–164. London, UK: UCL Press. Piek (1999). a mutlilingual database lexical-semantic Dordrecht: Kluwer Academic Publishers. 8</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="841" citStr="Fellbaum, 1998" startWordPosition="117" endWordPosition="118">an API developed to access GermaNet, a lexical semantic database for German represented in XML. The API provides a set of software functions for parsing and retrieving information from GermaNet. Then, we present a case study which builds upon the GermaNet API and implements an application for computing semantic relatedness according to five different metrics. The package can, again, serve as a software library to be deployed in natural language processing applications. A graphical user interface allows to interactively experiment with the system. 1 Motivation The knowledge encoded in WordNet (Fellbaum, 1998) has proved valuable in many natural language processing (NLP) applications. One particular way to integrate semantic knowledge into applications is to compute semantic similarity of WordNet concepts. This can be used e.g. to perform word sense disambiguation (Patwardhan et al., 2003), to find predominant word senses in untagged text (McCarthy et al., 2004), to automatically generate spoken dialogue summaries (Gurevych &amp; Strube, 2004), and to perform spelling correction (Hirst &amp; Budanitsky, 2005). Extensive research concerning the integration of semantic knowledge into NLP for the English lang</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, Christiane (Ed.) (1998). WordNet: An Electronic Lexical Database. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
</authors>
<title>Using the Structure of a Conceptual Network in Computing Semantic Relatedness.</title>
<date>2005</date>
<publisher>Submitted.</publisher>
<contexts>
<context position="10856" citStr="Gurevych (2005)" startWordPosition="1646" endWordPosition="1647">he basis of the conceptual hierarchy. Two metrics of semantic relatedness are, then, based on the application of the Lesk algorithm to definitions, generated automatically according to two system configurations. The generated definitions can be tailored to the task at hand according to a set of parameters defining which related concepts Figure 1: The concept of user-system interaction. have to be included in the final definition. Experiments carried out to determine the most effective parameters for generating the definitions and employing those to compute semantic relatedness is described in Gurevych (2005). Gurevych &amp; Niederlich (2005) present a description of the evaluation procedure for five implemented semantic relatedness metrics against a human Gold Standard and the evaluation results. 4 Graphical User Interface We developed a graphical user interface to interactively experiment with the software for computing semantic relatedness. The system runs on a standard Linux or Windows machine. Upon initialization, we configured the system to load an information content map computed from the German taz corpus.5 The information content values encoded therein are employed by the information content </context>
</contexts>
<marker>Gurevych, 2005</marker>
<rawString>Gurevych, Iryna (2005). Using the Structure of a Conceptual Network in Computing Semantic Relatedness. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Hendrik Niederlich</author>
</authors>
<title>Computing semantic relatedness of GermaNet concepts.</title>
<date>2005</date>
<booktitle>In Bernhard Fisseni, Hans-Christian Schmitz, Bernhard Schr¨oder &amp; Petra Wagner (Eds.), Sprachtechnologie, mobile Kommunikation und linguistische Ressourcen: Proceedings of Workshop ”Applications of GermaNet II” at GLDV’2005,</booktitle>
<pages>462--474</pages>
<note>Peter Lang.</note>
<contexts>
<context position="7767" citStr="Gurevych &amp; Niederlich, 2005" startWordPosition="1163" endWordPosition="1166">uwel (Engl. gem) is more distant. RelatednessComparator is a class which takes two words as input and returns a numeric value indicating semantic relatedness for the two words. Semantic relatedness metrics have been implemented as descendants of this class. Three of the metrics for computing semantic relatedness are information content based (Resnik, 1995; Jiang &amp; Conrath, 1997; Lin, 1998) and are also implemented in WordNet::Similarity package. However, some aspects in the normalization of their results and the task definition according to which the evaluation is conducted have been changed (Gurevych &amp; Niederlich, 2005). The metrics are implemented as classes derived from InformationBasedComparator, which is in its turn derived from the class PathBasedComparator. They make use of both the GermaNet hierarchy and statistical corpus evidence, i.e. information content. 4As mentioned before, GermaNet abandoned the clusterapproach taken in WordNet to group adjectives. Instead a hierarchical structuring based on the work by Hundsnurscher &amp; Splett (1982) applies, as is the case with nouns and verbs. 6 We implemented a set of utilities for computing information content of German word senses from German corpora accord</context>
<context position="10120" citStr="Gurevych &amp; Niederlich (2005)" startWordPosition="1533" endWordPosition="1536"> of corpus analysis compared with information content based metrics. However, a straightforward adaptation of the Lesk metric to GermaNet turned out to be impossible. Textual definitions of word senses in GermaNet are fairly short and small in number. In cotrast to WordNet, GermaNet cannot be employed as a machinereadable dictionary, but is primarily a conceptual network. In order to deal with this, we developed a novel methodology which generates definitions of word senses automatically from GermaNet using the GermaNet API. Examples of such automatically generated definitions can be found in Gurevych &amp; Niederlich (2005). The method is implemented in the class PseudoGlossGenerator of our software, which automatically generates glosses on the basis of the conceptual hierarchy. Two metrics of semantic relatedness are, then, based on the application of the Lesk algorithm to definitions, generated automatically according to two system configurations. The generated definitions can be tailored to the task at hand according to a set of parameters defining which related concepts Figure 1: The concept of user-system interaction. have to be included in the final definition. Experiments carried out to determine the most</context>
</contexts>
<marker>Gurevych, Niederlich, 2005</marker>
<rawString>Gurevych, Iryna &amp; Hendrik Niederlich (2005). Computing semantic relatedness of GermaNet concepts. In Bernhard Fisseni, Hans-Christian Schmitz, Bernhard Schr¨oder &amp; Petra Wagner (Eds.), Sprachtechnologie, mobile Kommunikation und linguistische Ressourcen: Proceedings of Workshop ”Applications of GermaNet II” at GLDV’2005, pp. 462–474. Peter Lang.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Michael Strube</author>
</authors>
<title>Semantic similarity applied to spoken dialogue summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics, Geneva, Switzerland, 23 – 27</booktitle>
<pages>764--770</pages>
<contexts>
<context position="1279" citStr="Gurevych &amp; Strube, 2004" startWordPosition="182" endWordPosition="185">in natural language processing applications. A graphical user interface allows to interactively experiment with the system. 1 Motivation The knowledge encoded in WordNet (Fellbaum, 1998) has proved valuable in many natural language processing (NLP) applications. One particular way to integrate semantic knowledge into applications is to compute semantic similarity of WordNet concepts. This can be used e.g. to perform word sense disambiguation (Patwardhan et al., 2003), to find predominant word senses in untagged text (McCarthy et al., 2004), to automatically generate spoken dialogue summaries (Gurevych &amp; Strube, 2004), and to perform spelling correction (Hirst &amp; Budanitsky, 2005). Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al., 2004).1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/ tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is</context>
</contexts>
<marker>Gurevych, Strube, 2004</marker>
<rawString>Gurevych, Iryna &amp; Michael Strube (2004). Semantic similarity applied to spoken dialogue summarization. In Proceedings of the 20th International Conference on Computational Linguistics, Geneva, Switzerland, 23 – 27 August 2004, pp. 764–770.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>Alexander Budanitsky</author>
</authors>
<title>Correcting realword spelling errors by restoring lexical cohesion.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="1342" citStr="Hirst &amp; Budanitsky, 2005" startWordPosition="191" endWordPosition="194">interface allows to interactively experiment with the system. 1 Motivation The knowledge encoded in WordNet (Fellbaum, 1998) has proved valuable in many natural language processing (NLP) applications. One particular way to integrate semantic knowledge into applications is to compute semantic similarity of WordNet concepts. This can be used e.g. to perform word sense disambiguation (Patwardhan et al., 2003), to find predominant word senses in untagged text (McCarthy et al., 2004), to automatically generate spoken dialogue summaries (Gurevych &amp; Strube, 2004), and to perform spelling correction (Hirst &amp; Budanitsky, 2005). Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al., 2004).1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/ tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce. On the one hand, there are fewer computational knowled</context>
</contexts>
<marker>Hirst, Budanitsky, 2005</marker>
<rawString>Hirst, Graeme &amp; Alexander Budanitsky (2005). Correcting realword spelling errors by restoring lexical cohesion. Natural Language Engineering, 11(1):87–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Hundsnurscher</author>
<author>J Splett</author>
</authors>
<title>Semantik der Adjektive im Deutschen: Analyse der semantischen Relationen.</title>
<date>1982</date>
<publisher>Westdeutscher Verlag.</publisher>
<contexts>
<context position="8202" citStr="Hundsnurscher &amp; Splett (1982)" startWordPosition="1226" endWordPosition="1229">larity package. However, some aspects in the normalization of their results and the task definition according to which the evaluation is conducted have been changed (Gurevych &amp; Niederlich, 2005). The metrics are implemented as classes derived from InformationBasedComparator, which is in its turn derived from the class PathBasedComparator. They make use of both the GermaNet hierarchy and statistical corpus evidence, i.e. information content. 4As mentioned before, GermaNet abandoned the clusterapproach taken in WordNet to group adjectives. Instead a hierarchical structuring based on the work by Hundsnurscher &amp; Splett (1982) applies, as is the case with nouns and verbs. 6 We implemented a set of utilities for computing information content of German word senses from German corpora according to the method by Resnik (1995). The TreeTagger (Schmid, 1997) is employed to compile a part-of-speech tagged word frequency list. The information content values of GermaNet synsets are saved in a text file called an information content map. We experimented with different configurations of the system, one of which involved stemming of corpora and the other did not involve any morphological processing. Contrary to our intuition, </context>
</contexts>
<marker>Hundsnurscher, Splett, 1982</marker>
<rawString>Hundsnurscher, F. &amp; J. Splett (1982). Semantik der Adjektive im Deutschen: Analyse der semantischen Relationen. Westdeutscher Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proceedings of the 10th International Conference on Research in Computational Linguistics (ROCLING). Tapei,</booktitle>
<location>Taiwan.</location>
<contexts>
<context position="7519" citStr="Jiang &amp; Conrath, 1997" startWordPosition="1125" endWordPosition="1128">ies to what degree the meanings of two words are related to each other. E.g. the meanings of Glas (Engl. glass) and Becher (Engl. cup) will be typically classified as being closely related to each other, while the relation between Glas and Juwel (Engl. gem) is more distant. RelatednessComparator is a class which takes two words as input and returns a numeric value indicating semantic relatedness for the two words. Semantic relatedness metrics have been implemented as descendants of this class. Three of the metrics for computing semantic relatedness are information content based (Resnik, 1995; Jiang &amp; Conrath, 1997; Lin, 1998) and are also implemented in WordNet::Similarity package. However, some aspects in the normalization of their results and the task definition according to which the evaluation is conducted have been changed (Gurevych &amp; Niederlich, 2005). The metrics are implemented as classes derived from InformationBasedComparator, which is in its turn derived from the class PathBasedComparator. They make use of both the GermaNet hierarchy and statistical corpus evidence, i.e. information content. 4As mentioned before, GermaNet abandoned the clusterapproach taken in WordNet to group adjectives. In</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jiang, Jay J. &amp; David W. Conrath (1997). Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of the 10th International Conference on Research in Computational Linguistics (ROCLING). Tapei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Kunze</author>
<author>Lothar Lemnitzer</author>
</authors>
<title>GermaNet - representation, visualization, application.</title>
<date>2002</date>
<journal></journal>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation (LREC), Las Palmas, Canary Islands,</booktitle>
<volume>31</volume>
<pages>1485--1491</pages>
<contexts>
<context position="2276" citStr="Kunze &amp; Lemnitzer, 2002" startWordPosition="324" endWordPosition="327">e availability of tools to easily retrieve 1http://www.d.umn.edu/ tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce. On the one hand, there are fewer computational knowledge resources like dictionaries, broad enough in coverage to be integrated in robust NLP applications. On the other hand, there is little off-the-shelf software that allows to develop applications utilizing semantic knowledge from scratch. While WordNet counterparts do exist for many languages, e.g. GermaNet (Kunze &amp; Lemnitzer, 2002) and EuroWordNet (Vossen, 1999), they differ from WordNet in certain design aspects. E.g. GermaNet features nonlexicalized, so called artificial concepts that are nonexistent in WordNet. Also, the adjectives are structured hierarchically which is not the case in WordNet. These and other structural differences led to divergences in the data model. Therefore, WordNet based implementations are not applicable to GermaNet. Also, there is generally lack of experimental evidence concerning the portability of e.g. WordNet based semantic similarity metrics to other wordnets and their sensitivity to spe</context>
<context position="6860" citStr="Kunze &amp; Lemnitzer, 2002" startWordPosition="1019" endWordPosition="1022">rns the part of speech associated with word senses of a synset; getWordSenses() returns all word senses constituting the synset; toString() yields a string representation of a synset. The metrics of semantic relatedness are designed to employ this API. They are implemented as classes which use the API methods on an instance of the GermaNet object. 3 Semantic Relatedness Software In GermaNet, nouns, verbs and adjectives are structured within hierarchies of is-a relations.4 GermaNet also contains information on additional lexical and semantic relations, e.g. hypernymy, meronymy, antonymy, etc. (Kunze &amp; Lemnitzer, 2002). A semantic relatedness metric specifies to what degree the meanings of two words are related to each other. E.g. the meanings of Glas (Engl. glass) and Becher (Engl. cup) will be typically classified as being closely related to each other, while the relation between Glas and Juwel (Engl. gem) is more distant. RelatednessComparator is a class which takes two words as input and returns a numeric value indicating semantic relatedness for the two words. Semantic relatedness metrics have been implemented as descendants of this class. Three of the metrics for computing semantic relatedness are inf</context>
</contexts>
<marker>Kunze, Lemnitzer, 2002</marker>
<rawString>Kunze, Claudia &amp; Lothar Lemnitzer (2002). GermaNet - representation, visualization, application. In Proceedings of the International Conference on Language Resources and Evaluation (LREC), Las Palmas, Canary Islands, Spain, 29 - 31 May, pp. 1485–1491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lothar Lemnitzer</author>
<author>Claudia Kunze</author>
</authors>
<title>Adapting GermaNet for the Web. In</title>
<date>2002</date>
<booktitle>Proceedings of the first Global WordNet Conference, Central Institute ofIndian Languages. Mysore, India,</booktitle>
<pages>174--181</pages>
<contexts>
<context position="4374" citStr="Lemnitzer &amp; Kunze, 2002" startWordPosition="639" endWordPosition="642">ild an application accessing the knowledge in GermaNet and computing semantic relatedness of GermaNet word senses according to five different metrics. Three of these metrics have been adapted from experiments on English with WordNet, while the remaining two are based on automatically generated definitions of word senses and were developed in the context of work with GermaNet. 2 GermaNet API The API for accessing GermaNet has to provide functions similar to the API developed for WordNet. We evaluated the C-library distributed together with GermaNet V4.0 and the XML encoded version of GermaNet (Lemnitzer &amp; Kunze, 2002). As we wanted the code to be portable across platforms, we built upon the latter. The XML version of GermaNet is parsed with the help of the Apache Xerces parser, http://xml.apache.org/ to create a JAVA object representing GermaNet. For stemming the words, we use the functionality provided by the Porter stemmer for the German language, freely available from http://snowball.tartarus.org/german/stemmer.html. Thus, the GermaNet object exists in two versions, the original one, where the information can be accessed using words, and the stemmed one, where the information can be accessed using word </context>
</contexts>
<marker>Lemnitzer, Kunze, 2002</marker>
<rawString>Lemnitzer, Lothar &amp; Claudia Kunze (2002). Adapting GermaNet for the Web. In Proceedings of the first Global WordNet Conference, Central Institute ofIndian Languages. Mysore, India, pp. 174–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the 5th Annual International Conference on Systems Documentation,</booktitle>
<pages>24--26</pages>
<location>Toronto, Ontario, Canada,</location>
<contexts>
<context position="9154" citStr="Lesk, 1986" startWordPosition="1383" endWordPosition="1384"> synsets are saved in a text file called an information content map. We experimented with different configurations of the system, one of which involved stemming of corpora and the other did not involve any morphological processing. Contrary to our intuition, there was almost no difference in the information content maps arising from the both system configurations, with and without morphological processing. Therefore, the use of stemming in computing information content of German synsets seems to be unjustified. The remaining two metrics of semantic relatedness are based on the Lesk algorithm (Lesk, 1986). The Lesk algorithm computes the number of overlaps in the definitions of words, which are sometimes extended with the definitions of words related to the given word senses (Patwardhan et al., 2003). This algorithm for computing semantic relatedness is very attractive. It is conceptually simple and does not require an additional effort of corpus analysis compared with information content based metrics. However, a straightforward adaptation of the Lesk metric to GermaNet turned out to be impossible. Textual definitions of word senses in GermaNet are fairly short and small in number. In cotrast</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Lesk, Michael (1986). Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 5th Annual International Conference on Systems Documentation, Toronto, Ontario, Canada, June, pp. 24–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<location>San Francisco, Cal.,</location>
<contexts>
<context position="7531" citStr="Lin, 1998" startWordPosition="1129" endWordPosition="1130">meanings of two words are related to each other. E.g. the meanings of Glas (Engl. glass) and Becher (Engl. cup) will be typically classified as being closely related to each other, while the relation between Glas and Juwel (Engl. gem) is more distant. RelatednessComparator is a class which takes two words as input and returns a numeric value indicating semantic relatedness for the two words. Semantic relatedness metrics have been implemented as descendants of this class. Three of the metrics for computing semantic relatedness are information content based (Resnik, 1995; Jiang &amp; Conrath, 1997; Lin, 1998) and are also implemented in WordNet::Similarity package. However, some aspects in the normalization of their results and the task definition according to which the evaluation is conducted have been changed (Gurevych &amp; Niederlich, 2005). The metrics are implemented as classes derived from InformationBasedComparator, which is in its turn derived from the class PathBasedComparator. They make use of both the GermaNet hierarchy and statistical corpus evidence, i.e. information content. 4As mentioned before, GermaNet abandoned the clusterapproach taken in WordNet to group adjectives. Instead a hier</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Lin, Dekang (1998). An information-theoretic definition of similarity. In Proceedings of the 15th International Conference on Machine Learning, San Francisco, Cal., pp. 296–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding predominant senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>280--287</pages>
<location>Barcelona,</location>
<contexts>
<context position="1200" citStr="McCarthy et al., 2004" startWordPosition="172" endWordPosition="175"> metrics. The package can, again, serve as a software library to be deployed in natural language processing applications. A graphical user interface allows to interactively experiment with the system. 1 Motivation The knowledge encoded in WordNet (Fellbaum, 1998) has proved valuable in many natural language processing (NLP) applications. One particular way to integrate semantic knowledge into applications is to compute semantic similarity of WordNet concepts. This can be used e.g. to perform word sense disambiguation (Patwardhan et al., 2003), to find predominant word senses in untagged text (McCarthy et al., 2004), to automatically generate spoken dialogue summaries (Gurevych &amp; Strube, 2004), and to perform spelling correction (Hirst &amp; Budanitsky, 2005). Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al., 2004).1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/ tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Resea</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>McCarthy, Diana, Rob Koeling, Julie Weeds &amp; John Carroll (2004). Finding predominant senses in untagged text. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, Barcelona, Spain, 21–26 July 2004, pp. 280 – 287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Using measures of semantic relatedness for word sense disambiguation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>241--257</pages>
<location>Mexico City, Mexico,</location>
<contexts>
<context position="1126" citStr="Patwardhan et al., 2003" startWordPosition="160" endWordPosition="163">n application for computing semantic relatedness according to five different metrics. The package can, again, serve as a software library to be deployed in natural language processing applications. A graphical user interface allows to interactively experiment with the system. 1 Motivation The knowledge encoded in WordNet (Fellbaum, 1998) has proved valuable in many natural language processing (NLP) applications. One particular way to integrate semantic knowledge into applications is to compute semantic similarity of WordNet concepts. This can be used e.g. to perform word sense disambiguation (Patwardhan et al., 2003), to find predominant word senses in untagged text (McCarthy et al., 2004), to automatically generate spoken dialogue summaries (Gurevych &amp; Strube, 2004), and to perform spelling correction (Hirst &amp; Budanitsky, 2005). Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al., 2004).1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/ tpederse</context>
<context position="9353" citStr="Patwardhan et al., 2003" startWordPosition="1415" endWordPosition="1418">did not involve any morphological processing. Contrary to our intuition, there was almost no difference in the information content maps arising from the both system configurations, with and without morphological processing. Therefore, the use of stemming in computing information content of German synsets seems to be unjustified. The remaining two metrics of semantic relatedness are based on the Lesk algorithm (Lesk, 1986). The Lesk algorithm computes the number of overlaps in the definitions of words, which are sometimes extended with the definitions of words related to the given word senses (Patwardhan et al., 2003). This algorithm for computing semantic relatedness is very attractive. It is conceptually simple and does not require an additional effort of corpus analysis compared with information content based metrics. However, a straightforward adaptation of the Lesk metric to GermaNet turned out to be impossible. Textual definitions of word senses in GermaNet are fairly short and small in number. In cotrast to WordNet, GermaNet cannot be employed as a machinereadable dictionary, but is primarily a conceptual network. In order to deal with this, we developed a novel methodology which generates definitio</context>
</contexts>
<marker>Patwardhan, Banerjee, Pedersen, 2003</marker>
<rawString>Patwardhan, Siddharth, Satanjeev Banerjee &amp; Ted Pedersen (2003). Using measures of semantic relatedness for word sense disambiguation. In Proceedings of the Fourth International Conference on Intelligent Text Processing and Computational Linguistics, Mexico City, Mexico, pp. 241–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity – Measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Demonstrations of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>267--270</pages>
<location>Boston, Mass.,</location>
<contexts>
<context position="1544" citStr="Pedersen et al., 2004" startWordPosition="220" endWordPosition="223">particular way to integrate semantic knowledge into applications is to compute semantic similarity of WordNet concepts. This can be used e.g. to perform word sense disambiguation (Patwardhan et al., 2003), to find predominant word senses in untagged text (McCarthy et al., 2004), to automatically generate spoken dialogue summaries (Gurevych &amp; Strube, 2004), and to perform spelling correction (Hirst &amp; Budanitsky, 2005). Extensive research concerning the integration of semantic knowledge into NLP for the English language has been arguably fostered by the emergence of WordNet::Similarity package (Pedersen et al., 2004).1 In its turn, the development of the WordNet based semantic similarity software has been facilitated by the availability of tools to easily retrieve 1http://www.d.umn.edu/ tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce. On the one hand, there are fewer computational knowledge resources like dictionaries, broad enough in coverage to be integrated in robust NLP applications. On the other hand, there is little off-the-shelf software that allows to develop applications utiliz</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, Ted, Siddharth Patwardhan &amp; Jason Michelizzi (2004). WordNet::Similarity – Measuring the relatedness of concepts. In Demonstrations of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, Boston, Mass., 2–7 May 2004, pp. 267–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence,</booktitle>
<volume>1</volume>
<pages>448--453</pages>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="7496" citStr="Resnik, 1995" startWordPosition="1123" endWordPosition="1124"> metric specifies to what degree the meanings of two words are related to each other. E.g. the meanings of Glas (Engl. glass) and Becher (Engl. cup) will be typically classified as being closely related to each other, while the relation between Glas and Juwel (Engl. gem) is more distant. RelatednessComparator is a class which takes two words as input and returns a numeric value indicating semantic relatedness for the two words. Semantic relatedness metrics have been implemented as descendants of this class. Three of the metrics for computing semantic relatedness are information content based (Resnik, 1995; Jiang &amp; Conrath, 1997; Lin, 1998) and are also implemented in WordNet::Similarity package. However, some aspects in the normalization of their results and the task definition according to which the evaluation is conducted have been changed (Gurevych &amp; Niederlich, 2005). The metrics are implemented as classes derived from InformationBasedComparator, which is in its turn derived from the class PathBasedComparator. They make use of both the GermaNet hierarchy and statistical corpus evidence, i.e. information content. 4As mentioned before, GermaNet abandoned the clusterapproach taken in WordNet </context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik, Phil (1995). Using information content to evaluate semantic similarity in a taxonomy. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, Montr´eal, Canada, 20–25 August 1995, Vol. 1, pp. 448–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1997</date>
<booktitle>In Daniel Jones &amp; Harold Somers (Eds.), New Methods in Language Processing, Studies in Computational Linguistics,</booktitle>
<pages>154--164</pages>
<publisher>UCL Press.</publisher>
<location>London, UK:</location>
<contexts>
<context position="8432" citStr="Schmid, 1997" startWordPosition="1266" endWordPosition="1267">m InformationBasedComparator, which is in its turn derived from the class PathBasedComparator. They make use of both the GermaNet hierarchy and statistical corpus evidence, i.e. information content. 4As mentioned before, GermaNet abandoned the clusterapproach taken in WordNet to group adjectives. Instead a hierarchical structuring based on the work by Hundsnurscher &amp; Splett (1982) applies, as is the case with nouns and verbs. 6 We implemented a set of utilities for computing information content of German word senses from German corpora according to the method by Resnik (1995). The TreeTagger (Schmid, 1997) is employed to compile a part-of-speech tagged word frequency list. The information content values of GermaNet synsets are saved in a text file called an information content map. We experimented with different configurations of the system, one of which involved stemming of corpora and the other did not involve any morphological processing. Contrary to our intuition, there was almost no difference in the information content maps arising from the both system configurations, with and without morphological processing. Therefore, the use of stemming in computing information content of German synse</context>
</contexts>
<marker>Schmid, 1997</marker>
<rawString>Schmid, Helmut (1997). Probabilistic part-of-speech tagging using decision trees. In Daniel Jones &amp; Harold Somers (Eds.), New Methods in Language Processing, Studies in Computational Linguistics, pp. 154–164. London, UK: UCL Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
</authors>
<title>EuroWordNet: a mutlilingual database with lexical-semantic networks.</title>
<date>1999</date>
<publisher>Kluwer Academic Publishers.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="2307" citStr="Vossen, 1999" startWordPosition="331" endWordPosition="332"> 1http://www.d.umn.edu/ tpederse/similarity.html data from WordNet, e.g. WordNet::QueryData,2 jwnl.3 Research integrating semantic knowledge into NLP for languages other than English is scarce. On the one hand, there are fewer computational knowledge resources like dictionaries, broad enough in coverage to be integrated in robust NLP applications. On the other hand, there is little off-the-shelf software that allows to develop applications utilizing semantic knowledge from scratch. While WordNet counterparts do exist for many languages, e.g. GermaNet (Kunze &amp; Lemnitzer, 2002) and EuroWordNet (Vossen, 1999), they differ from WordNet in certain design aspects. E.g. GermaNet features nonlexicalized, so called artificial concepts that are nonexistent in WordNet. Also, the adjectives are structured hierarchically which is not the case in WordNet. These and other structural differences led to divergences in the data model. Therefore, WordNet based implementations are not applicable to GermaNet. Also, there is generally lack of experimental evidence concerning the portability of e.g. WordNet based semantic similarity metrics to other wordnets and their sensitivity to specific factors, such as network </context>
</contexts>
<marker>Vossen, 1999</marker>
<rawString>Vossen, Piek (1999). EuroWordNet: a mutlilingual database with lexical-semantic networks. Dordrecht: Kluwer Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>