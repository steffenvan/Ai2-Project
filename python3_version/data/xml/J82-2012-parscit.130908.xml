<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.900977">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<title confidence="0.953298">
Abstracts of Current Literature
</title>
<note confidence="0.7402315">
GLISP User&apos;s Manual
Gordon S. Novak Jr.
</note>
<subsectionHeader confidence="0.662000666666667">
Computer Science Department
Stanford University
Stanford, California 94305
</subsectionHeader>
<bodyText confidence="0.970170473684211">
Report No. HPP-82-1, January 1982, 36 pages.
GLISP is a high-level, LISP-based language which is
compiled into LISP. GLISP provides a powerful ab-
stract datatype facility, allowing description and use of
both LISP objects and objects in AI representation
languages. GLISP language features include
PASCAL-like control structures, infix expressions with
operators which facilitate list manipulation, and refer-
ence to objects in PASCAL-like or English-like syn-
tax. English-like definite reference to features of ob-
jects which are in the current computational context is
allowed; definite references are understood and com-
piled relative to a knowledge base of object descrip-
tions. Object-centered programming is supported;
GLISP can substantially improve runtime performance
of object-centered programs by optimized compilation
of references to objects. This manual describes the
GLISP language and use of GLISP within INTER-
LISP.
</bodyText>
<note confidence="0.933154">
How to Solve It with PROLOG
</note>
<author confidence="0.621786">
Helder Coelho, Jose C. Cotta, and Luis M. Pereira
</author>
<affiliation confidence="0.59393">
Centro de Informatica
</affiliation>
<note confidence="0.4133025">
Laboratorio Nacional de Engenharia Civil
101, Av. do Brasil
1799 Lisboa Codex, PORTUGAL
Research Report, 2nd edition, 1980, 215 pages.
</note>
<bodyText confidence="0.9998578">
Our purpose is to present the outstanding features
of PROLOG through a collection of small problems
and exercises, divided in general application areas such
as deductive reasoning over data bases, natural lan-
guage, symbolic calculus, etc.
</bodyText>
<subsectionHeader confidence="0.806703333333333">
Logic Programming Bibliography
Helder Coelho
Centro de lnformatica
</subsectionHeader>
<bodyText confidence="0.279917">
Laboratorio Nacional de Engenharia Civil
101, Av. do Brasil
</bodyText>
<sectionHeader confidence="0.303372" genericHeader="abstract">
1799 Lisboa Codex, PORTUGAL
</sectionHeader>
<keyword confidence="0.225664">
Research Report, 2nd edition, October 1981, 41 pages.
</keyword>
<bodyText confidence="0.957646384615385">
This is a provisional version of an evolving bibliog-
raphy on logic programming and PROLOG, covering
field work carried out in all known groups spread over
the whole world. It is the first draft, and consequently
incomplete. The purpose behind its construction is
very simple. Every researcher needs to have available
an up-to-date and complete list of references. The
motivation to work out this list came from the bibliog-
raphy for my previous report &amp;quot;How to Solve it With
PROLOG,&amp;quot; and from the Hungarian list delivered
during the Logic Programming Workshop at Debrecen,
July 1980.
A New Point of View on Children&apos;s Stories
</bodyText>
<subsectionHeader confidence="0.43338675">
IBertram Bruce
Bolt Beranek and Newman Inc.
10 Moulton Street
Cambridge, Massachusetts 02238
</subsectionHeader>
<subsubsectionHeader confidence="0.639319">
Reading Education Report No. 25, July 1981, 45 pages.
</subsubsectionHeader>
<bodyText confidence="0.999865">
Recent work on text analysis at the Center for the
Study of Reading and elsewhere has produced surpris-
ing results regarding the texts that children read in
school. These results support the hypothesis that part
of the difficulty children encounter in making the
transition from beginning to skilled reading lies in an
abrupt shift in text characteristics between lower and
upper elementary school. Moreover, a comparison
between school texts and popular trade books shows
that the school texts may provide inadequate prepara-
tion for the texts that skilled readers need to master.
Thus, characteristics of the texts that children are ex-
pected to read may hinder rather than help in the at-
tainment of educational goals.
</bodyText>
<subsectionHeader confidence="0.9343342">
Why Readability Formulas Fail
Bertram Bruce, Andee Rubin, and Kathleen Starr
Bolt Beranek and Newman Inc.
10 Moulton Street
Cambridge, Massachusetts 02238
</subsectionHeader>
<subsubsectionHeader confidence="0.678058">
Reading Education Report No. 28, Aug. 1981, 13 pages.
</subsubsectionHeader>
<bodyText confidence="0.99991525">
Being able to measure the readability of a text with
a simple formula is an attractive prospect, and many
groups have been using readability formulas in a varie-
ty of situations where estimates of text complexity are
thought to be necessary. The most obvious and ex-
plicit use of readability formulas is by educational
publishers designing basal and remedial reading texts;
some states, in fact, will consider using a basal series
only if it fits certain readability formula criteria. In-
creasingly, public documents such as insurance poli-
cies, tax forms, contracts, and jury instructions must
meet criteria stated in terms of readability formulas.
Unfortunately, readability formlas just don&apos;t fulfill
their promise. We attempt here to categorize and
summarize some of the problems with readability for-
mulas and their use.
</bodyText>
<subsectionHeader confidence="0.9108164">
Stories Within Stories
Bertram Bruce
Bolt Beranek and Newman Inc.
10 Moulton Street
Cambridge, Massachusetts 02238
</subsectionHeader>
<subsubsectionHeader confidence="0.620886">
Reading Education Report No. 29, Aug. 1981, 15 pages.
</subsubsectionHeader>
<page confidence="0.683008">
90 American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982
</page>
<note confidence="0.391309">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<bodyText confidence="0.999457857142857">
What appears to be a single story is often a complex
set of stories within stories, each with its distinct au-
thor and reader. Examples of such stories within sto-
ries are presented. Results of analyses of basal read-
ers and trade books in terms of embedded stories are
also discussed. These suggest that a greater variety of
stories could and should be made available to children.
</bodyText>
<subsectionHeader confidence="0.973345333333333">
Conceptual Readability:
New Ways to Look at Text
Andee Rubin (Editor)
Bolt Beranek and Newman Inc.
10 Moulton Street
Cambridge, Massachusetts 02238
</subsectionHeader>
<subsubsectionHeader confidence="0.792112">
Reading Education Report No. 31, Sept. 1981, 61 pages.
</subsubsectionHeader>
<bodyText confidence="0.999992947368421">
The papers in this collection describe a notion of
&amp;quot;conceptual readability&amp;quot; which contrasts our approach
to text with that assumed by standard readability for-
mulas. Traditionally, the readability level of a text has
been calculated by considering text characteristics such
as the number of words per sentence and the degree of
familiarity of individual words. Our approach focuses
instead on the concepts communicated by the text:
how arguments are presented, what place examples
play in an exposition, how characters&apos; interactions are
developed and described.
In this report, we first demonstrate how certain
uses of traditional readability formulas may actually
lead to more difficult texts. Next, we discuss two
alternative text analysis methods which are sensitive to
structural, semantic and discourse characteristics. Fi-
nally, we suggest an educational method which encour-
ages children to focus on the conceptual level of text
in their early reading and writing experiences.
</bodyText>
<subsectionHeader confidence="0.987292428571429">
Text Readability:
Proceedings of the March 1980 Conference
Alice Davison, Richard Lutz, and Ann Roalef (Editors)
Center for the Study of Reading
University of Illinois
51 Gerty Drive
Champaign, Illinois 61820
</subsectionHeader>
<subsubsectionHeader confidence="0.523052">
Technical Report No, 213, August 1981, 145 pages.
</subsubsectionHeader>
<bodyText confidence="0.9999479">
The papers which make up this technical report are
summaries of oral presentations on readability and
readability formulas delivered in March 1980 at the
Center for the Study of Reading. The papers included
here represent as closely as possible the content and
organization of the oral presentations, in a more read-
able format than a verbatim transcript. The purpose
of the conference was to raise a number of issues for
discussion and to present a spectrum of ideas and
viewpoints from which readability formulas could be
judged or criticized. We have not tried to make the
papers exhaustive summaries of all that has been done
on a certain subject or to represent only the most
&amp;quot;correct&amp;quot; and orthodox positions on any topic. We
feel that the views expressed here, while diverse and in
some cases programmatic, will be useful in provoking
discussion and reexamining assumptions about reada-
bility formulas, perhaps in defining research which
might lead to a better understanding of what makes
things difficult to read.
</bodyText>
<subsectionHeader confidence="0.929341625">
Learning the Rules of the Game:
Four Views of the Relation Between
Social Interaction and Syntax Acquisition
Marilyn Shatz
Center for the Study of Reading
University of Illinois
51 Gerty Drive
Champaign, Illinois 61820
</subsectionHeader>
<subsubsectionHeader confidence="0.808338">
Technical Report No. 214, September 1981, 38 pages.
</subsubsectionHeader>
<bodyText confidence="0.9999667">
That language is a phenomenon belonging primarily
to the domain of social activities is hardly an arguable
point. While one can list nonsocial uses of language
as well as types of social interaction that are not lin-
guistic, the fact remains that the overlap between lan-
guage use and social interaction, though imperfect, is
still considerable. Moreover, some minimal amount of
social interaction seems to be necessary for language
acquisition to take place. The obvious kinship be-
tween language and social interaction suggests the
possibility of a relationship between knowledge in the
social sphere and the learning of linguistic forms. In
this paper four different kinds of relationships between
social interaction and syntax acquisition are outlined
and evaluated. The positions range from a strong one,
deriving syntax acquisition directly from interactionally
provided social knowledge, to a weak one, where the
relatively autonomous process of syntax acquisition
can be facilitated by the efficient distribution of proc-
essing resources.
</bodyText>
<subsectionHeader confidence="0.8975778">
A Social Interaction Model of Reading
Bertram Bruce
Bolt Beranek and Newman Inc.
10 Moulton Street
Cambridge, Massachusetts 02238
</subsectionHeader>
<subsubsectionHeader confidence="0.692272">
Technical Report No. 218, September 1981, 83 pages.
</subsubsectionHeader>
<bodyText confidence="0.991109777777778">
An author and a reader are engaged in a social
interaction which depends on their goals and their
beliefs about the world and each other. One aspect of
this interaction is the creation of another level of so-
cial interaction involving an &amp;quot;implied author&amp;quot; and an
&amp;quot;implied reader.&amp;quot; The newly created characters may,
in their turn, create another level of social interaction
involving, for example, a &amp;quot;narrator&amp;quot; and a &amp;quot;narratee.&amp;quot;
Each level so created permits the creation of an addi-
American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 91
The FINITE STRING Newsletter Abstracts of Current Literature
tional level. A model for the levels of social interac-
tion in reading is discussed in the paper. The model
provides a framework for examining devices such as
author commentary, irony, stories within stories, first
person narration, and point of view. Examples such as
The Tale of Benjamin Bunny and The Turn of the Screw
are discussed.
</bodyText>
<subsectionHeader confidence="0.9563795">
Translating English Into Logical Form
Stanley J. Rosenschein and Stuart M. Shieber
Artificial Intelligence Center
SRI International
333 Ravenswood Avenue
Menlo Park, California 94025
</subsectionHeader>
<subsubsectionHeader confidence="0.915478">
Proc. 20th Annual ACL Meeting, June 1982, 1-8.
</subsubsectionHeader>
<bodyText confidence="0.9988883">
A scheme for syntax-directed translation that mir-
rors compositional model-theoretic semantics is dis-
cussed. The scheme is the basis for an English trans-
lation system called PATR and was used to specify a
semantically interesting fragment of English, including
such constructs as tense, aspect, modals, and various
lexically controlled verb complement structures.
PATR was embedded in a question-answering system
that replied appropriately to questions requiring the
computation of logical entailments.
</bodyText>
<subsectionHeader confidence="0.630223">
Linguistic and Computational Semantics
Brian Cantwell Smith
</subsectionHeader>
<table confidence="0.917055666666667">
XEROX Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto, California 94304
</table>
<subsubsectionHeader confidence="0.709704">
Proc. 20th Annual ACL Meeting, June 1982, 9-15.
</subsubsectionHeader>
<bodyText confidence="0.999962111111111">
We argue that because the very concept of compu-
tation rests on notions of interpretation, the semantics
of natural languages and the semantics of computa-
tional formalisms are in the deepest sense the same
subject. The attempt to use computational formalisms
in aid of an explanation of natural language semantics,
therefore, is an enterprise that must be undertaken
with particular care. We describe a framework for
semantical analysis that we have used in the computa-
tional realm, and suggest that it may serve to under-
write computationally-oriented linguistic semantics as
well. The major feature of this framework is the ex-
plicit recognition of both the declarative and the pro-
cedural import of meaningful expressions; we argue
that whereas these two viewpoints have traditionally
been taken as alternative, any comprehensive semanti-
cal theory must account for how both aspects of an
expression contribute to its overall significance.
</bodyText>
<note confidence="0.6586765">
The Representation of Inconsistent Information
in a Dynamic Model-Theoretic Semantics
</note>
<table confidence="0.5743545">
IDouglas B. Moran
Department of Computer Science
Oregon State University
&apos;Corvallis, Oregon 97331
</table>
<subsubsectionHeader confidence="0.699078">
Proc. 20th Annual ACL Meeting, June 1982, 16-18.
</subsubsectionHeader>
<bodyText confidence="0.9990612">
Model-theoretic semantics provides a computation-
ally attractive means of) representing the semantics of
natural language. However, the models used in this
formalism are static and are usually infinite. Dynamic
models are incomplete models that include only the
information needed for an application and to which
information can be added. Dynamic models are basi-
cally approximations of larger conventional models,
but differ in several interesting ways.
The difference discussed here is the possibility of
inconsistent information being included in the model.
If a computation causes the model to expand, the re-
sult of that computation may be different than the
result of performing that same computation with re-
spect to the newly expanded model (i.e. the result is
inconsistent with the information currently in the dy-
namic model). Mechanisms are introduced to elimi-
nate these local (temporary) inconsistencies, but the
most natural mechanism can introduce permanent in-
consistencies in the information contained in the dy-
namic model. These inconsistencies are similar to
those that people have in their knowledge and beliefs.
The mechanism presented is shown to be related to
both the intensional isomorphism and impossible
worlds approaches to this problem.
</bodyText>
<subsectionHeader confidence="0.9388476">
What&apos;s in a Semantic Network?
James F. Allen and Alan M. Frisch
Computer Science Department
The University of Rochester
Rochester, New York 14627
</subsectionHeader>
<subsubsectionHeader confidence="0.84285">
Proc. 20th Annual ACL Meeting, June 1982, 19-27.
</subsubsectionHeader>
<bodyText confidence="0.999816666666667">
Ever since Woods&apos;s &amp;quot;What&apos;s in a Link&amp;quot; paper, there
has been a growing concern for formalization in the
study of knowledge representation. Several arguments
have been made that frame representation languages
and semantic-network languages are syntactic variants
of the first-order predicate calculus (FOPC). The
typical argument proceeds by showing how any given
frame or network representation can be mapped to a
logically isomorphic FOPC representation. For the
past two years we have been studying the formaliza-
tion of knowledge retrievers as well as the representa-
tion languages that they operate on. This paper pres-
ents a representation language in the notation of
FOPC whose form facilitates the design of a semantic-
network-like retriever.
</bodyText>
<page confidence="0.54754">
92 American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982
</page>
<table confidence="0.9486905">
The FINITE STRING Newsletter Abstracts of Current Literature
Dependencies of Discourse Structure
on the Modality of Communication:
Telephone vs. Teletype
Philip R. Cohen
Department of Computer Science
Oregon State University
Corvallis, Oregon 97331
Scott Fertig
Bolt Beranek and Newman. Inc.
10 Moulton Street
Cambridge, Massachusetts 02239
Kathy Starr
Bolt Beranek and Newman, Inc.
10 Moulton Street
Cambridge, Massachusetts 02239
</table>
<subsubsectionHeader confidence="0.724735">
Proc. 20th Annual ACL Meeting, June 1982, 28-35.
</subsubsectionHeader>
<bodyText confidence="0.9997878">
A desirable long-range goal in building future
speech understanding systems would be to accept the
kind of language people spontaneously produce. We
show that people do not speak to one another in the
same way they converse in typewritten language. Spo-
ken language is finer-grained and more indirect. The
differences are striking and pervasive. Current techni-
ques for engaging in typewritten dialogue will need to
be extended to accommodate the structure of spoken
language.
</bodyText>
<subsectionHeader confidence="0.965485">
Towards a Theory of Comprehension of
Declarative Contexts
Fernando Gomez
Department of Computer Science
University of Central Florida
Orlando, Florida 32816
</subsectionHeader>
<subsubsectionHeader confidence="0.810575">
Proc. 20th Annual ACL Meeting, June 1982, 36-43.
</subsubsectionHeader>
<bodyText confidence="0.999959636363636">
An outline of a theory of comprehension of declara-
tive contexts is presented. The main aspect of the
theory being developed is based on Kant&apos;s distinction
between concepts as rules (we have called them con-
ceptual specialists) and concepts as an abstract repre-
sentation (schemata, frames). Comprehension is
viewed as a process dependent on the conceptual spe-
cialists (they contain the inferential knowledge), the
schemata or frames (they contain the declarative
knowledge), and a parser. The function of the parser
is to produce a segmentation of the sentences in a case
frame structure, thus determining the meaning of pre-
positions, polysemous verbs, noun groups, etc. The
function of this parser is not to produce an output to
be interpreted by semantic routines or an interpreter,
but to start the parsing process and proceed until a
concept relevant to the theme of the text is recogniz-
ed. Then the concept takes control of the comprehen-
sion process overriding the lower level linguistic proc-
ess. Hence comprehension is viewed as a process in
which high level sources of knowledge (concepts) over-
ride lower level linguistic processes.
</bodyText>
<subsectionHeader confidence="0.8645508">
Natural Language Database Updates
Sharon C. Salveter and David Maier
Computer Science Department
SUNY Stony Brook
Stony Brook, New York 11794
</subsectionHeader>
<subsubsectionHeader confidence="0.803811">
Proc. 20th Annual ACL Meeting, June 1982, 67-73.
</subsubsectionHeader>
<bodyText confidence="0.99997">
Although a great deal of research effort has been
expended in support of natural language (NL) data-
base querying, little effort has gone to NL database
update. One reason for this state of affairs is that in
NL querying, one can tie nouns and stative verbs in
the query to database objects (relation names, attrib-
utes, and domain values). In many cases this corres-
pondence seems sufficient to interpret NL queries.
NL update seems to require database counterparts for
active verbs, such as &amp;quot;hire,&amp;quot; &amp;quot;schedule,&amp;quot; and &amp;quot;enroll,&amp;quot;
rather than for stative entities. There seem to be no
natural candidates to fill this role.
We suggest a database counterpart for active verbs,
which we call verbgraphs. The verbgraphs may be
used to support NL update. A verbgraph is a struc-
ture for representing the various database changes that
a given verb might describe. In addition to describing
the variants of a verb, they may be used to disambigu-
ate the update command. Other possible uses of verb-
graphs include specification of defaults, prompting of
the user to guide but not dictate user interaction and
enforcing a variety of types of integrity constraints.
</bodyText>
<subsectionHeader confidence="0.986156">
Processing English with a Generalized
Phrase Structure Grammar
</subsectionHeader>
<bodyText confidence="0.5458385">
J.M. Gawron, J. King, J. Lamping, E. Loebner,
E.A. Paulson, G.K. Pullum, I.A. Sag, and T. Wasow
</bodyText>
<subsectionHeader confidence="0.7665">
Computer Research Center
Hewlett Packard Company
1501 Page Mill Road
Palo Alto, California 94304
</subsectionHeader>
<subsubsectionHeader confidence="0.666444">
Proc. 20th Annual ACL Meeting, June 1982, 74-81.
</subsubsectionHeader>
<bodyText confidence="0.999942">
This paper describes a natural language processing
system implemented at Hewlett-Packard&apos;s Computer
Research Center. The system&apos;s main components are:
a Generalized Phrase Structure Grammar (GPSG); a
top-down parser; a logic transducer that outputs a
first-order logical representation; and a disambiguator
that uses sortal information to convert normal-form
first-order logical expressions into the query language
for HIRE, a relational database hosted in the SPHERE
system. We argue that theoretical developments in
GPSG syntax and in Montague semantics have specific
advantages to bring to this domain of computational
linguistics. The syntax and semantics of the system are
totally domain-independent, and thus, in principle,
highly portable. We discuss the prospects for extend-
ing domain-independence to the lexical semantics as
well, and thus to the logical semantic representations.
</bodyText>
<note confidence="0.455530375">
American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 93
The FINITE STRING Newsletter Abstracts of Current Literature
Experience with an Easily Computed Metric
for Ranking Alternative Parses
George E. Heidorn
Computer Sciences Department
IBM Thomas J. Watson Research Center
Yorktown Heights, New York 10598
</note>
<subsubsectionHeader confidence="0.538719">
Proc. 20th Annual ACL Meeting, June 1982, 82-84.
</subsubsectionHeader>
<bodyText confidence="0.99855675">
This brief paper, which is itself an extended abstract
for a forthcoming paper, describes a metric that can be
easily computed during either bottom-up or top-down
construction of a parse tree for ranking the desirability
of alternative parses. In its simplest form, the metric
tends to prefer trees in which constituents are pushed
as far down as possible, but by appropriate modifica-
tion of a constant in the formula other behavior can
be obtained also. This paper includes an introduction
to the EPISTLE system being developed at IBM Re-
search and a discussion of the results of using this
metric with that system.
</bodyText>
<subsectionHeader confidence="0.815513125">
An Improved Heuristic for Ellipsis Processing
Ralph M. Weischedel
Department of Computer and Information Sciences
University of Delaware
Newark, Delaware 19711
Norman K. Sondheimer
Software Research
Sperry Univac MS 2G3
</subsectionHeader>
<bodyText confidence="0.442909">
Blue Bell, Pennsylvania 19424
</bodyText>
<subsubsectionHeader confidence="0.786588">
Proc. 20th Annual ACL Meeting, June 1982, 85-88.
</subsubsectionHeader>
<bodyText confidence="0.9999303">
Robust response to ellipsis (fragmentary sentences)
is essential to acceptable natural language interfaces.
For instance, an experiment with the REL English
query system showed 10% elliptical input. This paper
presents a method of automatically interpreting ellipsis
based on dialogue context. Our method expands on
previous work by allowing for expansion ellipsis and
by allowing for all combinations of statement follow-
ing question, question following statement, question
following question, etc.
</bodyText>
<subsectionHeader confidence="0.788666">
Planning Natural Language Referring
Expressions
Douglas E. Appelt
SRI International
333 Ravenswood Avenue
Menlo Park, California 94025
</subsectionHeader>
<subsubsectionHeader confidence="0.814551">
Proc. 20th Annual ACL Meeting, June 1982, 108-112.
</subsubsectionHeader>
<bodyText confidence="0.9999662">
This paper describes how a language-planning sys-
tem can produce natural-language referring expres-
sions that satisfy multiple goals. It describes a formal
representation for reasoning about several agents&apos;
mutual knowledge using possible-worlds semantics and
the general organization of a system that uses the for-
malism to reason about plans combining physical and
linguistic actions at different levels of abstraction. It
discusses the planning of concept activation actions
that are realized by definite referring expressions in
the planned utterances, and shows how it is possible to
integrate physical actions for communicating intentions
with linguistic actions, resulting in plans that include
pointing as one of the communicative actions available
to the speaker.
</bodyText>
<subsectionHeader confidence="0.655409714285714">
The TEXT System for Natural Language
Generation: An Overview
Kathleen R. McKeown
Department of Computer and Information Science
The Moore School
University of Pennsylvania
Philadelphia, Pennsylvania 19104
</subsectionHeader>
<subsubsectionHeader confidence="0.828872">
Proc. 20th Annual ACL Meeting, June 1982, 113-120.
</subsubsectionHeader>
<bodyText confidence="0.9976563125">
Computer-based generation of natural language
requires consideration of two different types of prob-
lems: 1) determining the content and textual shape of
what is to be said, and 2) transforming that message
into English. A computational solution to the prob-
lems of deciding what to say and how to organize it
effectively is proposed that relies on an interaction
between structural and semantic processes. Schemas,
which encode aspects of discourse structure, are used
to guide the generation process. A focusing mecha-
nism monitors the use of the schemas, providing const-
raints on what can be said at any point. These mecha-
nisms have been implemented as part of a generation
method within the context of a natural language data-
base system, addressing the specific problem of re-
sponding to questions about database structure.
</bodyText>
<subsectionHeader confidence="0.833085428571429">
Augmenting a Database Knowledge
Representation for Natural Language Generation
Kathleen F. McCoy
Department of Computer and Information Science
The Moore School
University of Pennsylvannia
Philadelphia, Pennsylvania 19104
</subsectionHeader>
<subsubsectionHeader confidence="0.833341">
Proc. 20th Annual ACL Meeting, June 1982, 121-128.
</subsubsectionHeader>
<bodyText confidence="0.99998">
The knowledge representation is an important fac-
tor in natural language generation since it limits the
semantic capabilities of the generation system. This
paper identifies several information types in a knowl-
edge representation that can be used to generate
meaningful responses to questions about database
structure. Creating such a knowledge representation,
however, is a long and tedious process. A system is
presented which uses the contents of the database to
form part of this knowledge representation automati-
cally. It employs three types of world knowledge axi-
oms to ensure that the representation formed is mean-
ingful and contains salient information.
</bodyText>
<page confidence="0.859835">
94 American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982
</page>
<note confidence="0.793273">
The FINITE STRING Newsletter Abstracts of Current Literature
</note>
<reference confidence="0.919408428571429">
Salience: The Key to the Selection Problem in
Natural Language Generation
E. Jeffrey Conklin and David. D. McDonald
Department of Computer and Information Science
University of Massachusetts
Amherst, Massachusetts 01003
Proc. 20th Annual ACL Meeting, June 1982, 129-135.
</reference>
<bodyText confidence="0.999622">
We argue that in domains where a strong notion of
salience can be defined, it can be used to provide: I)
an elegant solution to the selection problem, i.e. the
problem of how to decide whether a given fact should
or should not be mentioned in the text; and 2) a sim-
ple and direct control framework for the entire deep
generation process, coordinating proposing, planning,
and realization. (Deep generation involves reasoning
about conceptual and rhetorical facts, as opposed to
the narrowly linguistic reasoning that takes place dur-
ing realization). We report on an empirical study of
salience in pictures of natural scenes, and its use in a
computer program that generates descriptive para-
graphs comparable to those produced by people.
</bodyText>
<subsectionHeader confidence="0.761435">
A Knowledge Engineering Approach to
Natural Language Understanding
Stuart C. Shapiro and Jeannette G. Neal
Department of Computer Science
</subsectionHeader>
<bodyText confidence="0.3903675">
State University of New York at Buffalo
Amherst, New York 14226
</bodyText>
<subsubsectionHeader confidence="0.602249">
Proc. 20th Annual ACL Meeting, June 1982, 136-144.
</subsubsectionHeader>
<bodyText confidence="0.99989975">
This paper describes the results of a preliminary
study of a knowledge engineering approach to natural
language understanding. A computer system is being
developed to handle the acquisition, representation,
and use of linguistic knowledge. The computer system
is rule-based and utilizes a semantic network for
knowledge storage and representation. In order to
facilitate the interaction between user and system,
input of linguistic knowledge and computer responses
are in natural language. Knowledge of various types
can be entered and utilized: syntactic and semantic;
assertions and rules. The inference tracing facility is
also being developed as a part of the rule-based sys-
tem with output in natural language. A detailed exam-
ple is presented to illustrate the current capabilities
and features of the system.
</bodyText>
<reference confidence="0.634555">
A Model of Early Syntactic Development
Pat Langley
The Robotics Institute
Carnegie-Mellon University
Pittsburgh, Pennsylvania 15213
Proc. 20th Annual ACL Meeting, June 1982, 145-151.
</reference>
<bodyText confidence="0.998672941176471">
AMBER is a model of first language acquisition
that improves its performance through a process of
error recovery. The model is implemented as an adap-
tive production system that introduces new condition-
action rules on the basis of experience. AMBER
starts with the ability to say only one word at a time,
but adds rules for ordering goals and producing gram-
matical morphemes, based on comparisons between
predicted and observed sentences. The morpheme
rules may be overly general and lead to errors of com-
mission; such errors evoke a discrimination process,
producing more conservative rules with additional
conditions. The system&apos;s performance improves grad-
ually, since rules must be relearned many times before
they are used. AMBER&apos;s learning mechanisms ac-
count for some of the major developments observed in
children&apos;s early speech.
</bodyText>
<note confidence="0.366467">
American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 95
</note>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000123">
<title confidence="0.962258666666667">The FINITE STRING Newsletter Abstracts of Current Literature Abstracts of Current Literature GLISP User&apos;s Manual</title>
<author confidence="0.995466">Gordon S Novak Jr</author>
<affiliation confidence="0.99993">Computer Science Department Stanford University</affiliation>
<address confidence="0.99963">Stanford, California 94305</address>
<abstract confidence="0.995821157894737">Report No. HPP-82-1, January 1982, 36 pages. a high-level, LISP-based language which is compiled into LISP. GLISP provides a powerful abstract datatype facility, allowing description and use of both LISP objects and objects in AI representation languages. GLISP language features include PASCAL-like control structures, infix expressions with operators which facilitate list manipulation, and reference to objects in PASCAL-like or English-like syntax. English-like definite reference to features of objects which are in the current computational context is allowed; definite references are understood and compiled relative to a knowledge base of object descriptions. Object-centered programming is supported; GLISP can substantially improve runtime performance of object-centered programs by optimized compilation of references to objects. This manual describes the GLISP language and use of GLISP within INTER- LISP.</abstract>
<title confidence="0.955594">How to Solve It with PROLOG</title>
<author confidence="0.998012">Helder Coelho</author>
<author confidence="0.998012">Jose C Cotta</author>
<author confidence="0.998012">Luis M Pereira</author>
<affiliation confidence="0.987147">Centro de Informatica Laboratorio Nacional de Engenharia Civil</affiliation>
<address confidence="0.9975795">101, Av. do Brasil 1799 Lisboa Codex, PORTUGAL</address>
<abstract confidence="0.982870333333333">Research Report, 2nd edition, 1980, 215 pages. Our purpose is to present the outstanding features of PROLOG through a collection of small problems and exercises, divided in general application areas such as deductive reasoning over data bases, natural language, symbolic calculus, etc.</abstract>
<title confidence="0.664686">Logic Programming Bibliography</title>
<author confidence="0.99186">Helder Coelho</author>
<affiliation confidence="0.9880455">Centro de lnformatica Laboratorio Nacional de Engenharia Civil</affiliation>
<address confidence="0.9974595">101, Av. do Brasil 1799 Lisboa Codex, PORTUGAL</address>
<abstract confidence="0.981398083333333">Research Report, 2nd edition, October 1981, 41 pages. This is a provisional version of an evolving bibliography on logic programming and PROLOG, covering field work carried out in all known groups spread over the whole world. It is the first draft, and consequently incomplete. The purpose behind its construction is very simple. Every researcher needs to have available an up-to-date and complete list of references. The motivation to work out this list came from the bibliography for my previous report &amp;quot;How to Solve it With PROLOG,&amp;quot; and from the Hungarian list delivered during the Logic Programming Workshop at Debrecen,</abstract>
<date confidence="0.954801">July 1980.</date>
<title confidence="0.996238">A New Point of View on Children&apos;s Stories</title>
<author confidence="0.982219">IBertram Bruce</author>
<affiliation confidence="0.996032">Bolt Beranek and Newman Inc.</affiliation>
<address confidence="0.999708">10 Moulton Street Cambridge, Massachusetts 02238</address>
<abstract confidence="0.983607533333333">Reading Education Report No. 25, July 1981, 45 pages. Recent work on text analysis at the Center for the Study of Reading and elsewhere has produced surprising results regarding the texts that children read in school. These results support the hypothesis that part of the difficulty children encounter in making the transition from beginning to skilled reading lies in an abrupt shift in text characteristics between lower and upper elementary school. Moreover, a comparison between school texts and popular trade books shows that the school texts may provide inadequate preparation for the texts that skilled readers need to master. Thus, characteristics of the texts that children are expected to read may hinder rather than help in the attainment of educational goals.</abstract>
<title confidence="0.963112">Why Readability Formulas Fail</title>
<author confidence="0.999902">Bertram Bruce</author>
<author confidence="0.999902">Andee Rubin</author>
<author confidence="0.999902">Kathleen Starr</author>
<affiliation confidence="0.995073">Bolt Beranek and Newman Inc.</affiliation>
<address confidence="0.9997575">10 Moulton Street Cambridge, Massachusetts 02238</address>
<abstract confidence="0.998813176470588">Reading Education Report No. 28, Aug. 1981, 13 pages. Being able to measure the readability of a text with a simple formula is an attractive prospect, and many groups have been using readability formulas in a variety of situations where estimates of text complexity are thought to be necessary. The most obvious and explicit use of readability formulas is by educational publishers designing basal and remedial reading texts; some states, in fact, will consider using a basal series only if it fits certain readability formula criteria. Increasingly, public documents such as insurance policies, tax forms, contracts, and jury instructions must meet criteria stated in terms of readability formulas. Unfortunately, readability formlas just don&apos;t fulfill their promise. We attempt here to categorize and summarize some of the problems with readability formulas and their use.</abstract>
<title confidence="0.995443">Stories Within Stories</title>
<author confidence="0.999903">Bertram Bruce</author>
<affiliation confidence="0.996618">Bolt Beranek and Newman Inc.</affiliation>
<address confidence="0.999006">10 Moulton Street Cambridge, Massachusetts 02238</address>
<note confidence="0.9566325">Reading Education Report No. 29, Aug. 1981, 15 pages. Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982</note>
<title confidence="0.901958">The FINITE STRING Newsletter Abstracts of Current Literature</title>
<abstract confidence="0.960413857142857">What appears to be a single story is often a complex set of stories within stories, each with its distinct author and reader. Examples of such stories within stories are presented. Results of analyses of basal readers and trade books in terms of embedded stories are also discussed. These suggest that a greater variety of stories could and should be made available to children.</abstract>
<title confidence="0.8042475">Conceptual Readability: New Ways to Look at Text</title>
<author confidence="0.993458">Andee Rubin</author>
<affiliation confidence="0.99199">Bolt Beranek and Newman Inc.</affiliation>
<address confidence="0.9997395">10 Moulton Street Cambridge, Massachusetts 02238</address>
<abstract confidence="0.99855745">Reading Education Report No. 31, Sept. 1981, 61 pages. The papers in this collection describe a notion of &amp;quot;conceptual readability&amp;quot; which contrasts our approach to text with that assumed by standard readability formulas. Traditionally, the readability level of a text has been calculated by considering text characteristics such as the number of words per sentence and the degree of familiarity of individual words. Our approach focuses instead on the concepts communicated by the text: how arguments are presented, what place examples play in an exposition, how characters&apos; interactions are developed and described. In this report, we first demonstrate how certain uses of traditional readability formulas may actually lead to more difficult texts. Next, we discuss two alternative text analysis methods which are sensitive to structural, semantic and discourse characteristics. Finally, we suggest an educational method which encourages children to focus on the conceptual level of text in their early reading and writing experiences.</abstract>
<note confidence="0.857784333333333">Text Readability: Proceedings of the March 1980 Conference Alice Davison, Richard Lutz, and Ann Roalef (Editors)</note>
<affiliation confidence="0.996476">Center for the Study of Reading University of Illinois</affiliation>
<address confidence="0.993075">51 Gerty Drive Champaign, Illinois 61820</address>
<abstract confidence="0.998745095238095">Technical Report No, 213, August 1981, 145 pages. The papers which make up this technical report are summaries of oral presentations on readability and readability formulas delivered in March 1980 at the Center for the Study of Reading. The papers included here represent as closely as possible the content and organization of the oral presentations, in a more readable format than a verbatim transcript. The purpose of the conference was to raise a number of issues for discussion and to present a spectrum of ideas and viewpoints from which readability formulas could be judged or criticized. We have not tried to make the exhaustive summaries of has been done on a certain subject or to represent only the most &amp;quot;correct&amp;quot; and orthodox positions on any topic. We feel that the views expressed here, while diverse and in some cases programmatic, will be useful in provoking discussion and reexamining assumptions about readability formulas, perhaps in defining research which might lead to a better understanding of what makes things difficult to read.</abstract>
<title confidence="0.993674666666667">Learning the Rules of the Game: Four Views of the Relation Between Social Interaction and Syntax Acquisition</title>
<author confidence="0.99998">Marilyn Shatz</author>
<affiliation confidence="0.999873">Center for the Study of Reading University of Illinois</affiliation>
<address confidence="0.993085">51 Gerty Drive Champaign, Illinois 61820</address>
<abstract confidence="0.998214666666667">Technical Report No. 214, September 1981, 38 pages. That language is a phenomenon belonging primarily to the domain of social activities is hardly an arguable point. While one can list nonsocial uses of language as well as types of social interaction that are not linguistic, the fact remains that the overlap between language use and social interaction, though imperfect, is still considerable. Moreover, some minimal amount of social interaction seems to be necessary for language acquisition to take place. The obvious kinship between language and social interaction suggests the possibility of a relationship between knowledge in the social sphere and the learning of linguistic forms. In this paper four different kinds of relationships between social interaction and syntax acquisition are outlined and evaluated. The positions range from a strong one, deriving syntax acquisition directly from interactionally provided social knowledge, to a weak one, where the relatively autonomous process of syntax acquisition can be facilitated by the efficient distribution of processing resources.</abstract>
<title confidence="0.908549">A Social Interaction Model of Reading</title>
<author confidence="0.998685">Bertram Bruce</author>
<affiliation confidence="0.996605">Bolt Beranek and Newman Inc.</affiliation>
<address confidence="0.9997635">10 Moulton Street Cambridge, Massachusetts 02238</address>
<abstract confidence="0.965350315789474">Technical Report No. 218, September 1981, 83 pages. An author and a reader are engaged in a social interaction which depends on their goals and their beliefs about the world and each other. One aspect of this interaction is the creation of another level of social interaction involving an &amp;quot;implied author&amp;quot; and an &amp;quot;implied reader.&amp;quot; The newly created characters may, in their turn, create another level of social interaction involving, for example, a &amp;quot;narrator&amp;quot; and a &amp;quot;narratee.&amp;quot; level so created permits the creation of an addi- Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 The FINITE STRING Newsletter Abstracts of Current Literature tional level. A model for the levels of social interaction in reading is discussed in the paper. The model provides a framework for examining devices such as author commentary, irony, stories within stories, first person narration, and point of view. Examples such as Tale of Benjamin Bunny Turn of the Screw are discussed.</abstract>
<title confidence="0.957147">Translating English Into Logical Form</title>
<author confidence="0.999979">Stanley J Rosenschein</author>
<author confidence="0.999979">Stuart M Shieber</author>
<affiliation confidence="0.999759">Artificial Intelligence Center SRI International</affiliation>
<address confidence="0.998117">333 Ravenswood Avenue Menlo Park, California 94025</address>
<abstract confidence="0.961201090909091">Proc. 20th Annual ACL Meeting, June 1982, 1-8. A scheme for syntax-directed translation that mirrors compositional model-theoretic semantics is discussed. The scheme is the basis for an English translation system called PATR and was used to specify a semantically interesting fragment of English, including such constructs as tense, aspect, modals, and various lexically controlled verb complement structures. PATR was embedded in a question-answering system that replied appropriately to questions requiring the computation of logical entailments.</abstract>
<title confidence="0.983761">Linguistic and Computational Semantics</title>
<author confidence="0.999835">Brian Cantwell Smith</author>
<affiliation confidence="0.999817">XEROX Palo Alto Research Center</affiliation>
<address confidence="0.998503">3333 Coyote Hill Road Palo Alto, California 94304</address>
<abstract confidence="0.988730947368421">Proc. 20th Annual ACL Meeting, June 1982, 9-15. We argue that because the very concept of computation rests on notions of interpretation, the semantics of natural languages and the semantics of computational formalisms are in the deepest sense the same subject. The attempt to use computational formalisms in aid of an explanation of natural language semantics, therefore, is an enterprise that must be undertaken with particular care. We describe a framework for semantical analysis that we have used in the computational realm, and suggest that it may serve to underwrite computationally-oriented linguistic semantics as well. The major feature of this framework is the explicit recognition of both the declarative and the procedural import of meaningful expressions; we argue that whereas these two viewpoints have traditionally been taken as alternative, any comprehensive semantical theory must account for how both aspects of an expression contribute to its overall significance.</abstract>
<title confidence="0.993444">The Representation of Inconsistent Information in a Dynamic Model-Theoretic Semantics</title>
<author confidence="0.999622">IDouglas B Moran</author>
<affiliation confidence="0.9999515">Department of Computer Science Oregon State University</affiliation>
<address confidence="0.996641">apos;Corvallis, Oregon 97331</address>
<abstract confidence="0.979346461538461">Annual ACL Meeting, June 1982, 16-18. Model-theoretic semantics provides a computationattractive means representing the semantics of natural language. However, the models used in this formalism are static and are usually infinite. Dynamic models are incomplete models that include only the information needed for an application and to which information can be added. Dynamic models are basically approximations of larger conventional models, but differ in several interesting ways. The difference discussed here is the possibility of inconsistent information being included in the model. If a computation causes the model to expand, the result of that computation may be different than the result of performing that same computation with respect to the newly expanded model (i.e. the result is inconsistent with the information currently in the dynamic model). Mechanisms are introduced to eliminate these local (temporary) inconsistencies, but the most natural mechanism can introduce permanent inconsistencies in the information contained in the dynamic model. These inconsistencies are similar to those that people have in their knowledge and beliefs. The mechanism presented is shown to be related to both the intensional isomorphism and impossible worlds approaches to this problem.</abstract>
<title confidence="0.9432">What&apos;s in a Semantic Network?</title>
<author confidence="0.999933">James F Allen</author>
<author confidence="0.999933">Alan M Frisch</author>
<affiliation confidence="0.999878">Computer Science Department The University of Rochester</affiliation>
<address confidence="0.999268">Rochester, New York 14627</address>
<abstract confidence="0.9440544375">Proc. 20th Annual ACL Meeting, June 1982, 19-27. Ever since Woods&apos;s &amp;quot;What&apos;s in a Link&amp;quot; paper, there has been a growing concern for formalization in the study of knowledge representation. Several arguments have been made that frame representation languages and semantic-network languages are syntactic variants of the first-order predicate calculus (FOPC). The typical argument proceeds by showing how any given frame or network representation can be mapped to a isomorphic For the past two years we have been studying the formalization of knowledge retrievers as well as the representation languages that they operate on. This paper presents a representation language in the notation of FOPC whose form facilitates the design of a semanticnetwork-like retriever.</abstract>
<note confidence="0.931046">Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982</note>
<title confidence="0.9058435">The FINITE STRING Newsletter Abstracts of Current Literature Dependencies of Discourse Structure on the Modality of Communication: Telephone vs. Teletype</title>
<author confidence="0.999949">Philip R Cohen</author>
<affiliation confidence="0.9999555">Department of Computer Science Oregon State University</affiliation>
<address confidence="0.999827">Corvallis, Oregon 97331</address>
<author confidence="0.998727">Scott Fertig</author>
<affiliation confidence="0.994584">Bolt Beranek and Newman. Inc.</affiliation>
<address confidence="0.999744">10 Moulton Street Cambridge, Massachusetts 02239</address>
<author confidence="0.996323">Kathy Starr</author>
<affiliation confidence="0.982877">Bolt Beranek and Newman, Inc.</affiliation>
<address confidence="0.9995815">10 Moulton Street Cambridge, Massachusetts 02239</address>
<abstract confidence="0.955332818181818">Proc. 20th Annual ACL Meeting, June 1982, 28-35. A desirable long-range goal in building future speech understanding systems would be to accept the kind of language people spontaneously produce. We show that people do not speak to one another in the same way they converse in typewritten language. Spoken language is finer-grained and more indirect. The differences are striking and pervasive. Current techniques for engaging in typewritten dialogue will need to be extended to accommodate the structure of spoken language.</abstract>
<title confidence="0.9688625">Towards a Theory of Comprehension of Declarative Contexts</title>
<author confidence="0.999987">Fernando Gomez</author>
<affiliation confidence="0.9995815">Department of Computer Science University of Central Florida</affiliation>
<address confidence="0.994929">Orlando, Florida 32816</address>
<abstract confidence="0.975264173913044">Proc. 20th Annual ACL Meeting, June 1982, 36-43. An outline of a theory of comprehension of declarative contexts is presented. The main aspect of the theory being developed is based on Kant&apos;s distinction between concepts as rules (we have called them conspecialists) and concepts as an abstract representation (schemata, frames). Comprehension viewed as a process dependent on the conceptual specialists (they contain the inferential knowledge), the schemata or frames (they contain the declarative knowledge), and a parser. The function of the parser is to produce a segmentation of the sentences in a case frame structure, thus determining the meaning of prepositions, polysemous verbs, noun groups, etc. The function of this parser is not to produce an output to be interpreted by semantic routines or an interpreter, but to start the parsing process and proceed until a concept relevant to the theme of the text is recognized. Then the concept takes control of the comprehenprocess lower level linguistic process. Hence comprehension is viewed as a process in high level sources of knowledge (concepts) overlevel linguistic processes.</abstract>
<title confidence="0.988543">Natural Language Database Updates</title>
<author confidence="0.999982">Sharon C Salveter</author>
<author confidence="0.999982">David Maier</author>
<affiliation confidence="0.9878975">Computer Science Department SUNY Stony Brook</affiliation>
<address confidence="0.951872">Stony Brook, New York 11794</address>
<abstract confidence="0.964225391304348">Proc. 20th Annual ACL Meeting, June 1982, 67-73. Although a great deal of research effort has been expended in support of natural language (NL) database querying, little effort has gone to NL database reason for this state of affairs is that in NL querying, one can tie nouns and stative verbs in the query to database objects (relation names, attributes, and domain values). In many cases this correspondence seems sufficient to interpret NL queries. NL update seems to require database counterparts for active verbs, such as &amp;quot;hire,&amp;quot; &amp;quot;schedule,&amp;quot; and &amp;quot;enroll,&amp;quot; rather than for stative entities. There seem to be no natural candidates to fill this role. We suggest a database counterpart for active verbs, we call verbgraphs may be used to support NL update. A verbgraph is a structure for representing the various database changes that a given verb might describe. In addition to describing the variants of a verb, they may be used to disambiguate the update command. Other possible uses of verbgraphs include specification of defaults, prompting of the user to guide but not dictate user interaction and enforcing a variety of types of integrity constraints.</abstract>
<title confidence="0.9835895">Processing English with a Generalized Phrase Structure Grammar</title>
<author confidence="0.986939">J M Gawron</author>
<author confidence="0.986939">J King</author>
<author confidence="0.986939">J Lamping</author>
<author confidence="0.986939">E Loebner</author>
<author confidence="0.986939">E A Paulson</author>
<author confidence="0.986939">G K Pullum</author>
<author confidence="0.986939">I A Sag</author>
<author confidence="0.986939">T Wasow</author>
<affiliation confidence="0.889754">Computer Research Center Hewlett Packard Company</affiliation>
<address confidence="0.998771">1501 Page Mill Road Palo Alto, California 94304</address>
<abstract confidence="0.980926888888889">Proc. 20th Annual ACL Meeting, June 1982, 74-81. This paper describes a natural language processing system implemented at Hewlett-Packard&apos;s Computer Research Center. The system&apos;s main components are: a Generalized Phrase Structure Grammar (GPSG); a top-down parser; a logic transducer that outputs a logical representation; and a uses sortal information to convert first-order logical expressions into the query language for HIRE, a relational database hosted in the SPHERE system. We argue that theoretical developments in GPSG syntax and in Montague semantics have specific advantages to bring to this domain of computational linguistics. The syntax and semantics of the system are totally domain-independent, and thus, in principle, highly portable. We discuss the prospects for extending domain-independence to the lexical semantics as well, and thus to the logical semantic representations.</abstract>
<note confidence="0.93516">Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982</note>
<title confidence="0.994895333333333">The FINITE STRING Newsletter Abstracts of Current Literature Experience with an Easily Computed Metric for Ranking Alternative Parses</title>
<author confidence="0.999996">George E Heidorn</author>
<affiliation confidence="0.9993455">Computer Sciences Department IBM Thomas J. Watson Research Center</affiliation>
<address confidence="0.951352">Yorktown Heights, New York 10598</address>
<abstract confidence="0.98367725">Proc. 20th Annual ACL Meeting, June 1982, 82-84. This brief paper, which is itself an extended abstract for a forthcoming paper, describes a metric that can be easily computed during either bottom-up or top-down construction of a parse tree for ranking the desirability of alternative parses. In its simplest form, the metric tends to prefer trees in which constituents are pushed as far down as possible, but by appropriate modifica-</abstract>
<intro confidence="0.582133">tion of a constant in the formula other behavior can</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Salience: The Key to the Selection Problem in Natural Language Generation</title>
<marker></marker>
<rawString>Salience: The Key to the Selection Problem in Natural Language Generation</rawString>
</citation>
<citation valid="true">
<authors>
<author>D</author>
</authors>
<date>0100</date>
<booktitle>Proc. 20th Annual ACL Meeting,</booktitle>
<pages>129--135</pages>
<institution>McDonald Department of Computer and Information Science University of Massachusetts</institution>
<location>Amherst, Massachusetts</location>
<marker>D, 0100</marker>
<rawString>E. Jeffrey Conklin and David. D. McDonald Department of Computer and Information Science University of Massachusetts Amherst, Massachusetts 01003 Proc. 20th Annual ACL Meeting, June 1982, 129-135.</rawString>
</citation>
<citation valid="true">
<title>A Model of Early Syntactic Development Pat Langley The Robotics Institute Carnegie-Mellon</title>
<date>1521</date>
<booktitle>Proc. 20th Annual ACL Meeting,</booktitle>
<pages>145--151</pages>
<location>University Pittsburgh, Pennsylvania</location>
<marker>1521</marker>
<rawString>A Model of Early Syntactic Development Pat Langley The Robotics Institute Carnegie-Mellon University Pittsburgh, Pennsylvania 15213 Proc. 20th Annual ACL Meeting, June 1982, 145-151.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>