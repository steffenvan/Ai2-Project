<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000443">
<title confidence="0.9506085">
COMPARING TWO GRAMMAR-BASED GENERATION ALGORITHMS:
A CASE STUDY
</title>
<author confidence="0.98068">
Miroslav Martinovic and Tomek Strzalkowski
</author>
<affiliation confidence="0.7890405">
Courant Institute of Mathematical Sciences
New York University
</affiliation>
<address confidence="0.994551">
715 Broadway, rm. 704
New York, N.Y., 10003
</address>
<email confidence="0.588449">
ABSTRACT
</email>
<figureCaption confidence="0.691536631578948">
In this paper we compare two grammar-based gen-
eration algorithms: the Semantic-Head-Driven Genera-
tion Algorithm (SHDGA), and the Essential Arguments
Algorithm (EAA). Both algorithms have successfully
addressed several outstanding problems in grammar-
based generation, including dealing with non-mono-
tonic compositionality of representation, left-recursion,
deadlock-prone rules, and nondeterminism. We con-
centrate here on the comparison of selected properties:
generality, efficiency, and determinism. We show that
EAA&apos;s traversals of the analysis tree for a given lan-
guage construct, include also the one taken on by
SHDGA. We also demonstrate specific and common
situations in which SHDGA will invariably run into
serious inefficiency and nondeterminism, and which
EAA will handle in an efficient and deterministic
manner. We also point out that only EAA allows to
treat the underlying grammar in a truly multi-directional
manner.
</figureCaption>
<sectionHeader confidence="0.998202" genericHeader="abstract">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.977058033333333">
Recently, two important new algorithms have been
published ([SNMP89], [SNMP90], [S90al, [S90b] and
[S91]) that address the problem of automated genera-
tion of natural language expressions from a structured
representation of meaning. Both algorithms follow the
same general principle: given a grammar, and a struc-
tured representation of meaning, produce one or more
corresponding surface strings, and do so with a mini-
mal possible effort. In this paper we limit our analysis
of the two algorithms to unification-based formalisms.
The first algorithm, which we call here the Seman-
tic-Head-Driven Generation Algorithm (SHDGA), uses
information about semantic heads&apos; in grammar rules
to obtain the best possible traversal of the generation
tree, using a mixed top-down/bottom-up strategy.
The semantic head of a rule is the literal on the right-hand
side that shares the semantics with the literal on the left.
The second algorithm, which we call the Essential Ar-
guments Algorithm (EAA), rearranges grammar pro-
ductions at compile time in such a way that a simple
top-down left-to-right evaluation will follow an opti-
mal path.
Both algorithms have resolved several outstanding
problems in dealing with natural language grammars,
including handling of left recursive rules, non-mono-
tonic compositionality of representation, and deadlock-
prone rules2. In this paper we attempt to compare these
two algorithms along their generality and efficiency
lines. Throughout this paper we follow the notation used
in [SNMP90].
</bodyText>
<sectionHeader confidence="0.9999025" genericHeader="method">
2. MAIN CHARACTERISTICS OF SIIDGA&apos;S
AND EAA&apos;S TRAVERSALS
</sectionHeader>
<bodyText confidence="0.99969105">
SHDGA traverses the derivation tree in the seman-
tic-head-first fashion. Starting from the goal predicate
node (called the root), containing a structured repre-
sentation (semantics) from which to generate, it selects
a production whose left-hand side semantics unifies with
the semantics of the root. If the selected production
passes the semantics unchanged from the left to some
nonterminal on the right (the so-called chain rule), this
later nonterminal becomes the new root and the algo-
rithm is applied recursively. On the other hand, if no
right-hand side literal has the same semantics as the
root (the so called non-chain rule), the production is
expanded, and the algorithm is recursively applied to
every literal on its right-hand side. When the evalu-
ation of a non-chain rule is completed, SHDGA con-
nects its left-hand side literal (called the pivot) to the
initial root using (in a backward manner) a series of
appropriate chain rules. At this time, all remaining
literals in the chain rules are expanded in a fixed order
(left-to-right).
</bodyText>
<footnote confidence="0.795523666666667">
2 Deadlock-prone rules are rules in which the order of the ex-
pansion of right-hand side literals cannot be determined locally
(i.e. using only information available in this rule).
</footnote>
<page confidence="0.999092">
81
</page>
<bodyText confidence="0.999956411764706">
Since SHDGA traverses the derivation tree in the
fashion described above, this traversal is neither top-
down (TD), nor bottom-up (BU), nor left-to-right (LR)
globally, with respect to the entire tree. However, it
is LR locally, when the siblings of the semantic head
literal are selected for expansion on the right-band side
of a chain rule, or when a non-chain rule is evaluated.
In fact the overall traversal strategy combines both the
TD mode (non-chain rule application) and the BU mode
(backward application of chain rules).
EAA takes a unification grammar (usually Prolog-
coded) and normalizes it by rewriting certain left re-
cursive rules and altering the order of right-hand side
nonterminals in other rules. It reorders literals in the
original grammar (both locally within each rule, and
globally between different rules) in such a way that the
optimal traversal order is achieved for a given evalu-
ation strategy (eg. top-down left-to-right). This restruc-
turing is done at compile time, so in effect a new
executable grammar is produced. The resulting parser
or generator is TD but not LR with respect to the origi-
nal grammar, however, the new grammar is evaluated
TD and LR (i.e., using a standard Prolog interpreter).
As a part of the node reordering process EAA calcu-
lates the minimal sets of essential arguments (msea&apos;s)
for all literals in the grammar, which in turn will al-
low to project an optimal evaluation order. The opti-
mal evaluation order is achieved by expanding only those
literals which are ready at any given moment, i.e., those
that have at least one of their mseas instantiated. The
following example illustrates the traversal strategies of
both algorithms. The grammar is taken from [SNMP90],
and nonnalized to remove deadlock-prone rules in order
to simplify the exposition.3
</bodyText>
<listItem confidence="0.99790047826087">
(0) sentence/decl(S) &gt; s(fmite)/S.
(1) sentence/imp(S) &gt; vp(nonfmite,[npC)/you])
IS.
(2) s(Form)/S &gt; Subj, vp(Form,[Subj/S.
(3) vp(Form,Subcat)/S &gt; v(Form,Z)/S,
vpl (Form, Z)/Subcat.
(4) vpl(Form,[Compl I Z])/Ar &gt; vpl(Form,Z)/Ar,
Compl.
(5) vpl(Form,Ar)/Ar.
(6) vp(Form,[Subj])/S &gt; v(Form,[Subj])/VP,
aux(Form,[Subj],VP)/S.
EAA eliminates such rules using global node reordering ([S91]).
(7) aux(Form,[Subj],S)/S.
(8) aux(Form,[Subj],A)/Z &gt; adv(A)/B,
aux(Form[Subj],B)/Z.
(9) v(finite,[npU/0,np(3-sing)/S])/love(S,O) &gt;
[loves].
(10) v(fmite,[np(D/O,p/up,np(3-sing)/S])/
call_up(S , 0) &gt; [calls].
(11) v(fmite,[np(3-sing)/S])/leave(S) &gt; [leaves].
(12) np(3-sing)/john &gt; [john].
(13) np(3-p1)/friends &gt; [friends].
(14) adv(VP)/often(VP) &gt; [often].
</listItem>
<bodyText confidence="0.999988375">
The analysis tree for both algorithms is presented on
the next page. (Figure 1.). The input semantics is given
as decl(call_up(john friends)). The output string be-
comes john calls up friends. The difference lists for
each step are also provided. They are separated from
the rest of the predicate by the symbol I . The differ-
ent orders in which the two algorithms expand the
branches of the derivation tree and generate the termi-
nal nodes are marked, in italics for SHDGA, and in
roman case for EAA. The rules that were applied at
each level are also given.
If EAA is rerun for alternative solutions, it will pro-
duce the same output string, but the order in which nodes
vpl (finite Jp/up,np(3-sing)/johnpOubjl/S1 _S2, and
npOlfriends/S2_11 (level 4), and also, vpl (finite fhp(3-
sing)/johnjASubil/S1 _S12, and p/up/S12_S2, at the
level below, are visited, will be reversed. This hap-
pens because both literals in both pairs are ready for
the expansion at the moment when the selection is to
be made. Note that the traversal made by SHDGA and
the first traversal taken by EAA actually generate the
terminal nodes in the same order. This property is
formally defined below.
Definition. Two traversals T&apos; and T&amp;quot; of a tree T are
said to be the same-to-a-subtree (stas), if the follow-
ing claim holds: Let N be any node of the tree T, and
all subtrees rooted at N. If the order in which
the subtrees will be taken on for the traversal by T&apos; is
Si&apos;,...,Sin and by T&amp;quot; Sj1,..., Sin, then
(Ski is one of the subtrees rooted at N, for any k, and 1)
Stas however does not imply that the order in which
the nodes are visited will necessarily be the same.
</bodyText>
<page confidence="0.979079">
82
</page>
<figure confidence="0.998251428571429">
sentence/ded(call_up(john, friends)) I Stringi]
s(finite)/eall_up(john,friends) I Stringil
2
Subj I String_SO vp(finite,[Subjj)/call_up(john,friends) I SOJI
np(3-sing)/john I String_SO
np(3-sing)/john I [john I SOLSO 3 3
Rule (0)
Rule (I)
Rule (12) Rule (3)
John v(iinite,Z)/call_up(john, friends) I SO_SI vpl(finke,Z)/(Subji I SU]
IV IV v(ilnite,inp( )/friends,p/up,np(3-sing)/kboD/ vpl(finite,[np(j/friends,p/up,np(3-sing)/johnl)/
eali_up(john,friends) (mai SUSI (Subji I Slij
Rule (10) Rule (4)
calls vpl(finite,[p/up,np(3-sing)/johnH/[Subj] I SI_S2 npO/friends I S2 _fl
/ I
Rule (4) np(3-p1)/friends I (friends&apos; [II
k
5 6 8 I 9 Ru (13)
III friends HI
4 17 Rule (5)
vpHfinite,[np(3-sing)/johnp/inp(3-sing)/johni I SI_SI
</figure>
<figureCaption confidence="0.988361">
FIGURE 1: EAA&apos;s and SHDGA&apos;s Traversals of An Analysis Tree.
</figureCaption>
<figure confidence="0.959390833333333">
vp1(linite,[np(3-sing)/johnKSubji I SI_5I2
phip]S12_S2
liluPINPISIL
S2
6 Is
Il up H
</figure>
<sectionHeader confidence="0.994091" genericHeader="method">
3. GENERALITY-WISE SUPERIORITY OF
EAA OVER SHDGA
</sectionHeader>
<bodyText confidence="0.999249057142857">
The traversals by SHDGA and EAA as marked on
the graph are stas. This means that the order in which
the terminals were produced (the leaves were visited)
is the same (in this case: calls up friends john). As noted
previously, EAA can make other traversals to produce
the same output string, and the order in which the
terminals are generated will be different in each case.
(This should not be confused with the order of the ter-
minals in the output string, which is always the same).
The orders in which terminals are generated during al-
ternative EAA traversals are: up calls friends John,
friends calls up john, friends up calls John. In general,
EAA can be forced to make a traversal corresponding
to any permutation of ready literals in the right-hand
side of a rule.
We should notice that in the above example SHDGA
happened to make all the right moves, i.e., it always
expanded a literal whose msea happened to be instan-
tiated. As we will see in the following sections, this
will not always be the case for SHDGA and will be-
come a source of serious efficiency problems. On the
other hand, whenever SHDGA indeed follows an
optimal traversal, EAA will have a traversal that is same-
to-a-subtree with it.
The previous discussion can be summarized by the
next theorem.
Theorem: If the SHDGA, at each particular step dur-
ing its implicit traversal of the analysis tree, visits only
the vertices representing literals that have at least one
of their sets of essential arguments instantiated at the
moment of the visit, then the traversal taken by the
SHDGA is the same-to-a-subtree (stas) as one of the
traversals taken by EAA.
The claim of the theorem is an immediate consequence
of two facts. The first is that the EAA always selects
</bodyText>
<page confidence="0.994706">
83
</page>
<bodyText confidence="0.932739">
for the expansion one of the literals with a msea cur-
rently instantiated. The other is the defmition of
traversals being same-to-a-subtree (always choosing the
same subtree for the next traversal).
The following simple extract from a grammar, de-
fining a wh-question, illustrates the forementioned (see
Figure 2. below):
</bodyText>
<listItem confidence="0.977288285714286">
(1) whques/WhSem --&gt; whsubj(Num)/WhSubj,
whpred(Num, Tense , [WhSubj ,WhObj])
/WhSem, whobj/WhObj.
(2) whsubj(D/who &gt; [who].
(3) whsubj( J/what --&gt; [what].
(4) whpred(sing ,perf, [ Subj , Obj])/wrote(Subj , Obj)
--&gt; [wrote].
</listItem>
<bodyText confidence="0.995656555555555">
up by SHDGA and top-down by EAA. whpred is
expanded first by SHDGA (because it shares the se-
mantics with the root, and there is an applicable non-
chain rule), and also by EAA (because it is the only
literal on the right-hand side of the rule (1) that has
one of its msea&apos;s instantiated (its semantics)).
After the middle subtree is completely expanded, both
sibling literals for the whp red have their semantics in-
stantiated and thus they are both ready for expansion.
We must note that SHDGA will always select the left-
most literal (in this case, whsubj), whether it is ready
or not. EAA will select the same in the first pass, but
it will expand whobj first, and then whsubj, if we force
a second pass. In the first pass, the terminals are gen-
erated in the order wrote who this, while in the second
pass the order is wrote this who. The first traversal for
EAA, and the only one for SHDGA are same-to-a-
subtree.
</bodyText>
<listItem confidence="0.759979">
4. EFFICIENCY-WISE SUPERIORITY OF
EAA OVER SHDGA
(5) whobj/this --&gt; [this].
</listItem>
<bodyText confidence="0.999761333333333">
The input semantics for this example is
wrote(who,this), and the output string who wrote this.
The numbering for the edges taken by the SHDGA is
given in italics, and for the EAA in roman case. Both
algorithms expand the middle subtree first, then the left,
and finally the right one.
Each of the three subtrees has only one path, there-
fore the choices of their subtrees are unique, and there-
fore both algorithms agree on that, too. However, the
way they actually traverse these subtrees is different.
For example, the middle subtree is traversed bottom-
The following example is a simplified fragment of a
parser-oriented grammar for yes or no questions. Using
this fragment we will illustrate some deficiencies of
SHDGA.
</bodyText>
<listItem confidence="0.9967285">
(1) sentence/ques(askif(S)) &gt; yesnoq/askif(S).
(2) yesnoq/askif(S) &gt;
</listItem>
<bodyText confidence="0.9873776">
aux_verb(Num,Pers,Form)/Aux,
subj(Num,Pers)/Subj,
main_verb(Form,[Subj,Obj])/Verb,
objC,_)/Obj,
adjaVerbD/S.
</bodyText>
<figure confidence="0.970596">
whques/wrote(who314s) I Ques_fl
1
Rule (1)
whsubj(Num)/WhSulki I Ques RI whpred(Num,Forw,[WhSubj,WhObj])/
wrote(w ho3his) I RI_R2
whobj/WhObj 1R2_1)
1Rule (5)
4 o
4 r 3
Role (2)
3 3 or 4 Rule (4) 2
who wrote this
/I II or III III III or U
</figure>
<figureCaption confidence="0.962171">
FIGURE 2: EAA&apos;s and SHDGA&apos;s STAS Traversals of Who Question&apos;s Analysis Tree.
</figureCaption>
<page confidence="0.992358">
84
</page>
<listItem confidence="0.941713958333333">
(3) aux_verb(sing,one,pres_perf)/have(pres_perf,sing)
&gt; [have].
(4) aux_verb(sing,one,pres_cont)/be(pres_cont,
sing-1) &gt; [am].
(5) aux_verb(sing, one,pres)/do(pres , sing- 1) --&gt; [do].
(6) aux_verb(sing,two,pres)/do(pres,sing-2) &gt; [do].
(7) aux_verb (sing , three, pres)/do (pres , sing-3) &gt;
[does].
(8) aux_verb(pl, one, pres)/do(pres ,p1-1) &gt; [do].
(9) subj(Num,Pers)/Subj &gt; np(Num,Pers,su)/Subj.
(10) obj(Num,Pers)/Obj &gt; np(Num,Pers,ob)/Obj.
(11) np(Num,Pers,Case)/NP
&gt; noun(Num,Pers,Case)/NP.
(12) np(Num,Pers,Case)/NP
&gt; pnoun(Num,Pers,Case)/NP.
(13) pnoun(sing,two,su)/you &gt; [you].
(14) pnoun(sing,three,ob)/him &gt; [him].
(15) main_verb(pres , [Subj ,Obj])/see(Subj , Obj)
&gt; [see].
(15a) main_verb(pres_perf, [Subj ,Obj])/seen(Subj ,Obj)
&gt; [seen].
(15b) main_verb(perf,[Subj,Obj])/saw(Subj,Obj)
&gt; [saw].
(16) adj([Verb])/often(Verb) &gt; [often].
</listItem>
<bodyText confidence="0.994890296296296">
The analysis tree (given on Figure 3.) for the input
semantics ques ( askif ( often ( see ( you,him ) ) ) ) (the
output string being do you see him often) is presented
below.
Both algorithms start with the rule (1). SHDGA se-
lects (1) because it has the left-hand side nonterminal
with the same semantics as the root, and it is a non-
chain rule. EAA selects (1) because its left-hand side
unifies with the initial query (-?- sentence (OutStringffi
/ ques (askif(often(see (you ,him)))) ).
Next, rule (2) is selected by both algorithms. Again,
by SHDGA, because it has the left-hand side nonter-
minal with the same semantics as the current root
(yesnoq/aslcif...), and it is a non-chain rule; and by EAA,
because the yesnoq/askif... is the only nonterminal on
the right-hand side of the previously chosen rule and
it has an instantiated msea (its semantics). The crucial
difference takes place when the right-hand side of rule
(2) is processed. EAA deterministically selects adj for
expansion, because it is the only rhs literal with an
instantiated msea&apos;s. As a result of expanding adj, the
main verb semantics becomes instantiated, and therefore
main verb is the next literal selected for expansion. After
processing of main_verb is completed, Subject, Object,
and Tense variables are instantiated, so that both subj
and obj become ready. Also, the tense argument for
aux verb is instantiated (Form in rule (2)). After subj,
</bodyText>
<figure confidence="0.667674842105263">
se ntence/ques(askiftoften(see(You,bbn)))) I Sitiolla
1 Rule (1)
2 3 yesnoq/askif(ollen(see(you, him))) I String() R2I_R2 obj(sing,t1wee) 10 Rule (2) 2
aux_verb(sing,two,pres)/ I subj(sing,two)/ main_verb(pres,[you,him))/ 7 him l[him I R31_R3 adj(Isee(you,him)])/ Ill
do(pres,sing-2) I [do I ROLM) you I [you I RIJ_RI see(you,him) I [see I Ill Rule (10) 8 often(see(
Rule (6) Rale (9) 6 Rule (15) np(sing,three,ob)/ you, him)) I
11 5 4 him I [him R3)_R3 [often I DU)
do I see Rule (16)
V op(sing,two,su)/ 3
you I [you I 111)_R1 often
Rule (12)
6 Is Rule (12) 9 I&apos;
pnoun(sing,two,su)/ pnoun(sing,three,ob)/
you I [you I 1111_R1 him I [him I R3I_R3
Rule (13)
7 14
Rule (14)
you
ill II
</figure>
<figureCaption confidence="0.464104">
FIGURE 3: EAA&apos;s and SIIDGA&apos;s Traversals of If Question&apos;s Analysis Tree.
</figureCaption>
<page confidence="0.990513">
85
</page>
<bodyText confidence="0.99756645">
However, this solution seems to put additional bur-
den on the grammar writer, who need not be aware of
the evaluation strategy to be used for its grammar.
and obj are expanded (in any order), Num, and Pers
for aux_verb are bound, and fmally aux_verb is ready,
too.
In contrast, the SHDGA will proceed by selecting
the leftmost literal (aux_verb(Num,Pers,Form)/Awc) of
the rule (2). At this moment, none of its arguments is
instantiated and any attempt to unify with an auxiliary
verb in a lexicon will succeed. Suppose then that have
is returned and unified with aux_verb with pres _pmf
as Tense and sing_l as Number. This restricts further
choices of subj and main_verb. However, obj will still
be completely randomly chosen, and then ad] will reject
all previous choices. The decision for rejecting them
will come when the literal adj is expanded, because its
semantics is often(see(you,him)) as inherited from
yesnoq, but it does not match the previous choices for
aux_verb, subj, main_verb, and obj. Thus we are forced
to backtrack repeatedly, and it may be a while before
the correct choices are made.
In fact the same problem will occur whenever SHDGA
selects a rule for expansion such that its leftmost right-
hand side literal (first to be processed) is not ready.
Since SHDGA does not check for readiness before ex-
panding a predicate, other examples similar to the one
discussed above can be found easily. We may also point
out that the fragment used in the previous example is
extracted from an actual computer grammar for Eng-
lish (Sager&apos;s String Grammar), and therefore, it is not
an artificial problem.
The only way to avoid such problems with SHDGA
would be to rewrite the underlying grammar, so that
the choice of the most instantiated literal on the righthand
side of a rule is forced. This could be done by chang-
ing rule (2) in the example above into several rules which
use meta nonterminals Aux, Subj, Main_Verb, and Obj
in place of literals aux_verb, subj, main_verb, and obj
respectively, as shown below:
</bodyText>
<equation confidence="0.556138">
yesnoq/askif(S) &gt; asldf/S.
askif/S &gt;
Aux, Subj, Main_Verb, Obj,
adj ([Verb] , [Aux , Subj ,Main_Verb, Obj])/S
</equation>
<bodyText confidence="0.7394315">
Since Aux, Subj, Main_Verb, and Obj are uninstan-
tiated variables, we are forced to go directly to ad] first.
After ad] is expanded the nonterminals to the left of it
will become properly instantiated for expansion, so in
effect their expansion has been delayed.
Both algorithms handle left recursion satisfactorily.
SHDGA processes recursive chain rules rules in a con-
strained bottom-up fashion, and this also includes dead-
lock prone rules. EAA gets rid of left recursive rules
during the grammar normalization process that takes
place at compile-time, thus avoiding the run-time
overhead.
</bodyText>
<sectionHeader confidence="0.985495" genericHeader="evaluation">
5. MULTI-DIRECTIONALITY
</sectionHeader>
<bodyText confidence="0.99972775">
Another property of EAA regarded as superior over
the SHDGA is its multi-directionality. EAA can be used
for parsing as well as for generation. The algorithm
will simply recognize that the top-level msea is now
the string, and will adjust to the new situation. More-
over, EAA can be run in any direction paved by the
predicates&apos; mseas as they become instantiated at the time
a rule is taken up for expansion.
In contrast, SHDGA can only be guaranteed to work
in one direction, given any particular grammar, although
the same architecture can apparently be used for both
generation, [SNMP90], and parsing, [K90], [N89].
The point is that some grammars (as shown in the
example above) need to be rewritten for parsing or
generation, or else they must be constructed in such a
way so as to avoid indeterminacy. While it is possible
to rewrite grammars in a form appropriate for head-
first computation, there are real grammars which will
not evaluate efficiently with SHDGA, even though EAA
can handle such grammars with no problems.
</bodyText>
<sectionHeader confidence="0.999607" genericHeader="conclusions">
6. CONCLUSION
</sectionHeader>
<bodyText confidence="0.986122461538462">
In this paper we discussed several aspects of two natu-
ral language generation algorithms: SHDGA and EAA.
Both algorithms operate under the same general set of
conditions, that is, given a grammar, and a structured
representation of meaning, they attempt to produce one
or more corresponding surface strings, and do so with
a minimal possible effort. We analyzed the perform-
ance of each algorithm in a few specific situations, and
concluded that EAA is both more general and more ef-
ficient algorithm than SHDGA. Where EAA enforces
the optimal traversal of the derivation tree by precom-
puting all possible orderings for nonterminal expan-
sion, SHDGA can be guaranteed to display a compa-
</bodyText>
<page confidence="0.988442">
86
</page>
<bodyText confidence="0.999121777777778">
rable performance only if its grammar is appropriately
designed, and the semantic heads are carefully assigned
(manually). With other grammars SHDGA will follow
non-optimal generation paths which may lead to ex-
treme inefficiency.
In addition, EAA is a truly multi-directional algo-
rithm, while SHDGA is not, which is a simple conse-
quence of the restricted form of grammar that SHDGA
can safely accept.
This comparison can be broadened in several direc-
tions. For example, an interesting problem that remains
to be worked out is a formal characterization of the
grammars for which each of the two generation algo-
rithms is guaranteed to produce a finite and/or opti-
mal search tree. Moreover, while we showed that
SHDGA will work properly only on a subset of EAA&apos;s
grammars, there may be legitimate grammars that neither
algorithm can handle.
</bodyText>
<sectionHeader confidence="0.996832" genericHeader="acknowledgments">
7. ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999502">
This paper is based upon work supported by the
Defense Advanced Research Project Agency under
Contract N00014-90-J-1851 from the Office of Naval
Research, the National Science Foundation under Grant
IRI-89-02304, and the Canadian Institute for Robot-
ics and Intelligent Systems (IRIS).
</bodyText>
<sectionHeader confidence="0.999527" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999886866666667">
[C78] COLMERAUER, A. 1978. &amp;quot;Metamor-
phosis Grammars &amp;quot;In Natural Language Communi-
cation with Computers, Edited by L. Bole. Lecture
Notes in Computer Science, 63. Springer-Verlag, New
York, NY, pp. 133-189.
[D90a] DYMETMAN, M. 1990. &amp;quot;A Gener-
alized Greibach Normal Form for DCG&apos;s.&amp;quot; CCRIT,
Laval, Quebec: Ministere des Communications Can-
ada.
[D90b] DYMETMAN, M. 1990. &amp;quot;Left-Re-
cursion Elimination, Guiding, and Bidirectionality in
Lexical Grammars.&amp;quot; To Appear.
[DA84] DAHL, V., and ABRAMSON, H.
1984. &amp;quot;On Gapping Grammars.&amp;quot; Proceedings of the
Second International Conference on Logic
Programming. Uppsala, Sweden, pp. 77-88.
[D188] DYMETMAN, M., and ISABELLE,
P. 1988. &amp;quot;Reversible Logic Grammars for Machine
Translation.&amp;quot; Proceedings of the 2nd International
Conference on Theoretical and Methodological Issues
in Machine Translation of Natural Languages. Car-
negie-Mellon University, Pittsburgh, PA.
[D11390] DYMETMAN, M., ISABELLE, P.,
and PERRAULT, F. 1991. &amp;quot;A Symmetrical Approach
to Parsing and Generation.&amp;quot; Proceedings of the 13th
International Conference on Computational Linguis-
tics (COLING-90). Helsinki, Finland, Vol. 3., pp. 90-
96.
[GM89] GAZDAR, G., and MELLISH, C.
1989. Natural Language Promssing in Prolog. Addison-
Wesley, Reading, MA.
[K90] KAY, M. 1990. &amp;quot;Head-Driven Pars-
ing.&amp;quot; In M. Tomita (ed.), Current Issues in Parsing
Technology, Kluwer Academic Publishers, Dordrecht,
the Netherlands.
[K84] KAY, M. 1984. &amp;quot;Functional Unifica-
tion Grammar: A Formalism for Machine Translation.&amp;quot;
Proceedings of the 10th International Conference on
Computational Linguistics (COLING-84). Stanford
University, Stanford, CA., pp. 75-78.
[N89] VAN NOORD, G. 1989. &amp;quot;An Over-
view of Head-Driven Bottom-Up Generation.&amp;quot; In Pro-
ceedings of the Second European Workshop on Natu-
ral Language Generation. Edinburgh, Scotland.
[PS90] PENG, P., and STRZALKOWSKI, T.
1990. &amp;quot;An Implementation of A Reversible Grammar.&amp;quot;
Proceedings of the &amp;h Conference of the Canadian So-
ciety for the Computational Studies of Intelligence
(CSCSI-90). University of Ottawa, Ottawa, Ontario,
pp. 121-127.
[S90a] STRZALKOWSKI, T. 1990. &amp;quot;How to
Invert A Natural Language Parser into An Efficient Gen-
erator: An Algorithm for Logic Grammars.&amp;quot; Proceed-
ings of the 13th international Conference on Compu-
tational Linguistics (COLING-90). Helsinki, Finland,
Vol. 2., pp. 90-96.
[S90b] STRZALKOWSKI, T. 1990. &amp;quot;Revers-
ible Logic Grammars for Natural Language Parsing and
Generation.&amp;quot; Computational Intelligence Journal,
Volume 6., pp. 145-171.
</reference>
<page confidence="0.987823">
87
</page>
<reference confidence="0.999534388888889">
[S91] STRZALKOWSKI, T. 1991. &amp;quot;A Gen-
eral Computational Method for Grammar Inversion.&amp;quot;
Proceedings of a Workshop Sponsored by the Special
Interest Groups on Generation and Parsing of the ACL.
Berkeley, CA., pp. 91-99.
[SNMP89] SHIEBER, S.M., VAN NOORD,
G., MOORE, R.C., and PEREIRA, F.C.N. 1989. &amp;quot;A
Semantic-Head-Driven Generation Algorithm for Uni-
fication-Based Formalisms.&amp;quot; Proceedings of the 27th
Meeting of the ACL. Vancouver, B.C., pp. 7-17.
[SNMP90] SHIEBER, S.M., VAN NOORD,
G., MOORE, R.C., and PEREIRA, F.C.N. 1990.
&amp;quot;Semantic-Head-Driven Generation.&amp;quot; Computational
Linguistics, Volume 16, Number 1.
[W88] WEDEKIND, J. 1988. &amp;quot;Generation as
Structure Driven Derivation.&amp;quot; Proceedings of the 12th
International Conference on Computational Linguis-
tics (COLING-88). Budapest, Hungary, pp. 732-737.
</reference>
<page confidence="0.999403">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.851054">
<title confidence="0.9547545">COMPARING TWO GRAMMAR-BASED GENERATION ALGORITHMS: A CASE STUDY</title>
<author confidence="0.991556">Miroslav Martinovic</author>
<author confidence="0.991556">Tomek Strzalkowski</author>
<affiliation confidence="0.9978955">Courant Institute of Mathematical Sciences New York University</affiliation>
<address confidence="0.9989445">715 Broadway, rm. 704 New York, N.Y., 10003</address>
<abstract confidence="0.99706795">In this paper we compare two grammar-based generation algorithms: the Semantic-Head-Driven Generation Algorithm (SHDGA), and the Essential Arguments Algorithm (EAA). Both algorithms have successfully addressed several outstanding problems in grammarbased generation, including dealing with non-monotonic compositionality of representation, left-recursion, deadlock-prone rules, and nondeterminism. We concentrate here on the comparison of selected properties: generality, efficiency, and determinism. We show that EAA&apos;s traversals of the analysis tree for a given language construct, include also the one taken on by SHDGA. We also demonstrate specific and common situations in which SHDGA will invariably run into serious inefficiency and nondeterminism, and which EAA will handle in an efficient and deterministic manner. We also point out that only EAA allows to treat the underlying grammar in a truly multi-directional manner.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A COLMERAUER</author>
</authors>
<title>Metamorphosis Grammars &amp;quot;In Natural Language Communication with Computers, Edited by</title>
<date>1978</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>63</volume>
<pages>133--189</pages>
<publisher>Springer-Verlag,</publisher>
<location>New York, NY,</location>
<marker>[C78]</marker>
<rawString>COLMERAUER, A. 1978. &amp;quot;Metamorphosis Grammars &amp;quot;In Natural Language Communication with Computers, Edited by L. Bole. Lecture Notes in Computer Science, 63. Springer-Verlag, New York, NY, pp. 133-189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M DYMETMAN</author>
</authors>
<title>A Generalized Greibach Normal Form for DCG&apos;s.&amp;quot; CCRIT,</title>
<date>1990</date>
<booktitle>Ministere des Communications Canada.</booktitle>
<location>Laval, Quebec:</location>
<marker>[D90a]</marker>
<rawString>DYMETMAN, M. 1990. &amp;quot;A Generalized Greibach Normal Form for DCG&apos;s.&amp;quot; CCRIT, Laval, Quebec: Ministere des Communications Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M DYMETMAN</author>
</authors>
<title>Left-Recursion Elimination, Guiding, and Bidirectionality in Lexical Grammars.&amp;quot;</title>
<date>1990</date>
<note>To Appear.</note>
<marker>[D90b]</marker>
<rawString>DYMETMAN, M. 1990. &amp;quot;Left-Recursion Elimination, Guiding, and Bidirectionality in Lexical Grammars.&amp;quot; To Appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V DAHL</author>
<author>H ABRAMSON</author>
</authors>
<title>On Gapping Grammars.&amp;quot;</title>
<date>1984</date>
<booktitle>Proceedings of the Second International Conference on Logic Programming.</booktitle>
<pages>77--88</pages>
<location>Uppsala,</location>
<marker>[DA84]</marker>
<rawString>DAHL, V., and ABRAMSON, H. 1984. &amp;quot;On Gapping Grammars.&amp;quot; Proceedings of the Second International Conference on Logic Programming. Uppsala, Sweden, pp. 77-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M DYMETMAN</author>
<author>P ISABELLE</author>
</authors>
<title>Reversible Logic Grammars for Machine Translation.&amp;quot;</title>
<date>1988</date>
<booktitle>Proceedings of the 2nd International Conference on Theoretical and Methodological Issues in Machine Translation of Natural</booktitle>
<institution>Languages. Carnegie-Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<marker>[D188]</marker>
<rawString>DYMETMAN, M., and ISABELLE, P. 1988. &amp;quot;Reversible Logic Grammars for Machine Translation.&amp;quot; Proceedings of the 2nd International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Languages. Carnegie-Mellon University, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M DYMETMAN</author>
<author>P ISABELLE</author>
<author>F PERRAULT</author>
</authors>
<title>A Symmetrical Approach to Parsing and Generation.&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of the 13th International Conference on Computational Linguistics (COLING-90).</booktitle>
<volume>3</volume>
<pages>90--96</pages>
<location>Helsinki, Finland,</location>
<marker>[D11390]</marker>
<rawString>DYMETMAN, M., ISABELLE, P., and PERRAULT, F. 1991. &amp;quot;A Symmetrical Approach to Parsing and Generation.&amp;quot; Proceedings of the 13th International Conference on Computational Linguistics (COLING-90). Helsinki, Finland, Vol. 3., pp. 90-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G GAZDAR</author>
<author>C MELLISH</author>
</authors>
<date>1989</date>
<booktitle>Natural Language Promssing in Prolog.</booktitle>
<publisher>AddisonWesley,</publisher>
<location>Reading, MA.</location>
<marker>[GM89]</marker>
<rawString>GAZDAR, G., and MELLISH, C. 1989. Natural Language Promssing in Prolog. AddisonWesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M KAY</author>
</authors>
<title>Head-Driven Parsing.&amp;quot;</title>
<date>1990</date>
<booktitle>Current Issues in Parsing Technology,</booktitle>
<editor>In M. Tomita (ed.),</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht, the Netherlands.</location>
<contexts>
<context position="19948" citStr="[K90]" startWordPosition="3148" endWordPosition="3148">her property of EAA regarded as superior over the SHDGA is its multi-directionality. EAA can be used for parsing as well as for generation. The algorithm will simply recognize that the top-level msea is now the string, and will adjust to the new situation. Moreover, EAA can be run in any direction paved by the predicates&apos; mseas as they become instantiated at the time a rule is taken up for expansion. In contrast, SHDGA can only be guaranteed to work in one direction, given any particular grammar, although the same architecture can apparently be used for both generation, [SNMP90], and parsing, [K90], [N89]. The point is that some grammars (as shown in the example above) need to be rewritten for parsing or generation, or else they must be constructed in such a way so as to avoid indeterminacy. While it is possible to rewrite grammars in a form appropriate for headfirst computation, there are real grammars which will not evaluate efficiently with SHDGA, even though EAA can handle such grammars with no problems. 6. CONCLUSION In this paper we discussed several aspects of two natural language generation algorithms: SHDGA and EAA. Both algorithms operate under the same general set of conditio</context>
</contexts>
<marker>[K90]</marker>
<rawString>KAY, M. 1990. &amp;quot;Head-Driven Parsing.&amp;quot; In M. Tomita (ed.), Current Issues in Parsing Technology, Kluwer Academic Publishers, Dordrecht, the Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M KAY</author>
</authors>
<title>Functional Unification Grammar: A Formalism for Machine Translation.&amp;quot;</title>
<date>1984</date>
<booktitle>Proceedings of the 10th International Conference on Computational Linguistics (COLING-84).</booktitle>
<pages>75--78</pages>
<institution>Stanford University,</institution>
<location>Stanford, CA.,</location>
<marker>[K84]</marker>
<rawString>KAY, M. 1984. &amp;quot;Functional Unification Grammar: A Formalism for Machine Translation.&amp;quot; Proceedings of the 10th International Conference on Computational Linguistics (COLING-84). Stanford University, Stanford, CA., pp. 75-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G VAN NOORD</author>
</authors>
<title>An Overview of Head-Driven Bottom-Up Generation.&amp;quot;</title>
<date>1989</date>
<booktitle>In Proceedings of the Second European Workshop on Natural Language Generation.</booktitle>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="19955" citStr="[N89]" startWordPosition="3149" endWordPosition="3149">perty of EAA regarded as superior over the SHDGA is its multi-directionality. EAA can be used for parsing as well as for generation. The algorithm will simply recognize that the top-level msea is now the string, and will adjust to the new situation. Moreover, EAA can be run in any direction paved by the predicates&apos; mseas as they become instantiated at the time a rule is taken up for expansion. In contrast, SHDGA can only be guaranteed to work in one direction, given any particular grammar, although the same architecture can apparently be used for both generation, [SNMP90], and parsing, [K90], [N89]. The point is that some grammars (as shown in the example above) need to be rewritten for parsing or generation, or else they must be constructed in such a way so as to avoid indeterminacy. While it is possible to rewrite grammars in a form appropriate for headfirst computation, there are real grammars which will not evaluate efficiently with SHDGA, even though EAA can handle such grammars with no problems. 6. CONCLUSION In this paper we discussed several aspects of two natural language generation algorithms: SHDGA and EAA. Both algorithms operate under the same general set of conditions, tha</context>
</contexts>
<marker>[N89]</marker>
<rawString>VAN NOORD, G. 1989. &amp;quot;An Overview of Head-Driven Bottom-Up Generation.&amp;quot; In Proceedings of the Second European Workshop on Natural Language Generation. Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P PENG</author>
<author>T STRZALKOWSKI</author>
</authors>
<title>An Implementation of A Reversible Grammar.&amp;quot;</title>
<date>1990</date>
<booktitle>Proceedings of the &amp;h Conference of the Canadian Society for the Computational Studies of Intelligence (CSCSI-90).</booktitle>
<pages>121--127</pages>
<institution>University of Ottawa,</institution>
<location>Ottawa, Ontario,</location>
<marker>[PS90]</marker>
<rawString>PENG, P., and STRZALKOWSKI, T. 1990. &amp;quot;An Implementation of A Reversible Grammar.&amp;quot; Proceedings of the &amp;h Conference of the Canadian Society for the Computational Studies of Intelligence (CSCSI-90). University of Ottawa, Ottawa, Ontario, pp. 121-127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T STRZALKOWSKI</author>
</authors>
<title>How to Invert A Natural Language Parser into An Efficient Generator: An Algorithm for Logic Grammars.&amp;quot;</title>
<date>1990</date>
<booktitle>Proceedings of the 13th international Conference on Computational Linguistics (COLING-90).</booktitle>
<volume>2</volume>
<pages>90--96</pages>
<location>Helsinki, Finland,</location>
<marker>[S90a]</marker>
<rawString>STRZALKOWSKI, T. 1990. &amp;quot;How to Invert A Natural Language Parser into An Efficient Generator: An Algorithm for Logic Grammars.&amp;quot; Proceedings of the 13th international Conference on Computational Linguistics (COLING-90). Helsinki, Finland, Vol. 2., pp. 90-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T STRZALKOWSKI</author>
</authors>
<title>Reversible Logic Grammars for Natural Language Parsing and Generation.&amp;quot;</title>
<date>1990</date>
<journal>Computational Intelligence Journal,</journal>
<volume>6</volume>
<pages>145--171</pages>
<contexts>
<context position="1265" citStr="[S90b]" startWordPosition="174" endWordPosition="174">of selected properties: generality, efficiency, and determinism. We show that EAA&apos;s traversals of the analysis tree for a given language construct, include also the one taken on by SHDGA. We also demonstrate specific and common situations in which SHDGA will invariably run into serious inefficiency and nondeterminism, and which EAA will handle in an efficient and deterministic manner. We also point out that only EAA allows to treat the underlying grammar in a truly multi-directional manner. 1. INTRODUCTION Recently, two important new algorithms have been published ([SNMP89], [SNMP90], [S90al, [S90b] and [S91]) that address the problem of automated generation of natural language expressions from a structured representation of meaning. Both algorithms follow the same general principle: given a grammar, and a structured representation of meaning, produce one or more corresponding surface strings, and do so with a minimal possible effort. In this paper we limit our analysis of the two algorithms to unification-based formalisms. The first algorithm, which we call here the Semantic-Head-Driven Generation Algorithm (SHDGA), uses information about semantic heads&apos; in grammar rules to obtain the b</context>
</contexts>
<marker>[S90b]</marker>
<rawString>STRZALKOWSKI, T. 1990. &amp;quot;Reversible Logic Grammars for Natural Language Parsing and Generation.&amp;quot; Computational Intelligence Journal, Volume 6., pp. 145-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T STRZALKOWSKI</author>
</authors>
<title>A General Computational Method for Grammar Inversion.&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of a Workshop Sponsored by the Special Interest Groups on Generation and Parsing of the ACL.</booktitle>
<pages>91--99</pages>
<location>Berkeley, CA.,</location>
<contexts>
<context position="1275" citStr="[S91]" startWordPosition="176" endWordPosition="176"> properties: generality, efficiency, and determinism. We show that EAA&apos;s traversals of the analysis tree for a given language construct, include also the one taken on by SHDGA. We also demonstrate specific and common situations in which SHDGA will invariably run into serious inefficiency and nondeterminism, and which EAA will handle in an efficient and deterministic manner. We also point out that only EAA allows to treat the underlying grammar in a truly multi-directional manner. 1. INTRODUCTION Recently, two important new algorithms have been published ([SNMP89], [SNMP90], [S90al, [S90b] and [S91]) that address the problem of automated generation of natural language expressions from a structured representation of meaning. Both algorithms follow the same general principle: given a grammar, and a structured representation of meaning, produce one or more corresponding surface strings, and do so with a minimal possible effort. In this paper we limit our analysis of the two algorithms to unification-based formalisms. The first algorithm, which we call here the Semantic-Head-Driven Generation Algorithm (SHDGA), uses information about semantic heads&apos; in grammar rules to obtain the best possib</context>
<context position="6156" citStr="[S91]" startWordPosition="935" endWordPosition="935"> mseas instantiated. The following example illustrates the traversal strategies of both algorithms. The grammar is taken from [SNMP90], and nonnalized to remove deadlock-prone rules in order to simplify the exposition.3 (0) sentence/decl(S) &gt; s(fmite)/S. (1) sentence/imp(S) &gt; vp(nonfmite,[npC)/you]) IS. (2) s(Form)/S &gt; Subj, vp(Form,[Subj/S. (3) vp(Form,Subcat)/S &gt; v(Form,Z)/S, vpl (Form, Z)/Subcat. (4) vpl(Form,[Compl I Z])/Ar &gt; vpl(Form,Z)/Ar, Compl. (5) vpl(Form,Ar)/Ar. (6) vp(Form,[Subj])/S &gt; v(Form,[Subj])/VP, aux(Form,[Subj],VP)/S. EAA eliminates such rules using global node reordering ([S91]). (7) aux(Form,[Subj],S)/S. (8) aux(Form,[Subj],A)/Z &gt; adv(A)/B, aux(Form[Subj],B)/Z. (9) v(finite,[npU/0,np(3-sing)/S])/love(S,O) &gt; [loves]. (10) v(fmite,[np(D/O,p/up,np(3-sing)/S])/ call_up(S , 0) &gt; [calls]. (11) v(fmite,[np(3-sing)/S])/leave(S) &gt; [leaves]. (12) np(3-sing)/john &gt; [john]. (13) np(3-p1)/friends &gt; [friends]. (14) adv(VP)/often(VP) &gt; [often]. The analysis tree for both algorithms is presented on the next page. (Figure 1.). The input semantics is given as decl(call_up(john friends)). The output string becomes john calls up friends. The difference lists for each step are also pro</context>
</contexts>
<marker>[S91]</marker>
<rawString>STRZALKOWSKI, T. 1991. &amp;quot;A General Computational Method for Grammar Inversion.&amp;quot; Proceedings of a Workshop Sponsored by the Special Interest Groups on Generation and Parsing of the ACL. Berkeley, CA., pp. 91-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M SHIEBER</author>
<author>G VAN NOORD</author>
<author>R C MOORE</author>
<author>F C N PEREIRA</author>
</authors>
<title>A Semantic-Head-Driven Generation Algorithm for Unification-Based Formalisms.&amp;quot;</title>
<date>1989</date>
<booktitle>Proceedings of the 27th Meeting of the ACL.</booktitle>
<pages>7--17</pages>
<location>Vancouver, B.C.,</location>
<contexts>
<context position="1239" citStr="[SNMP89]" startWordPosition="171" endWordPosition="171">rate here on the comparison of selected properties: generality, efficiency, and determinism. We show that EAA&apos;s traversals of the analysis tree for a given language construct, include also the one taken on by SHDGA. We also demonstrate specific and common situations in which SHDGA will invariably run into serious inefficiency and nondeterminism, and which EAA will handle in an efficient and deterministic manner. We also point out that only EAA allows to treat the underlying grammar in a truly multi-directional manner. 1. INTRODUCTION Recently, two important new algorithms have been published ([SNMP89], [SNMP90], [S90al, [S90b] and [S91]) that address the problem of automated generation of natural language expressions from a structured representation of meaning. Both algorithms follow the same general principle: given a grammar, and a structured representation of meaning, produce one or more corresponding surface strings, and do so with a minimal possible effort. In this paper we limit our analysis of the two algorithms to unification-based formalisms. The first algorithm, which we call here the Semantic-Head-Driven Generation Algorithm (SHDGA), uses information about semantic heads&apos; in gra</context>
</contexts>
<marker>[SNMP89]</marker>
<rawString>SHIEBER, S.M., VAN NOORD, G., MOORE, R.C., and PEREIRA, F.C.N. 1989. &amp;quot;A Semantic-Head-Driven Generation Algorithm for Unification-Based Formalisms.&amp;quot; Proceedings of the 27th Meeting of the ACL. Vancouver, B.C., pp. 7-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M SHIEBER</author>
<author>G VAN NOORD</author>
<author>R C MOORE</author>
<author>F C N PEREIRA</author>
</authors>
<title>Semantic-Head-Driven Generation.&amp;quot;</title>
<date>1990</date>
<journal>Computational Linguistics, Volume</journal>
<volume>16</volume>
<contexts>
<context position="1249" citStr="[SNMP90]" startWordPosition="172" endWordPosition="172">on the comparison of selected properties: generality, efficiency, and determinism. We show that EAA&apos;s traversals of the analysis tree for a given language construct, include also the one taken on by SHDGA. We also demonstrate specific and common situations in which SHDGA will invariably run into serious inefficiency and nondeterminism, and which EAA will handle in an efficient and deterministic manner. We also point out that only EAA allows to treat the underlying grammar in a truly multi-directional manner. 1. INTRODUCTION Recently, two important new algorithms have been published ([SNMP89], [SNMP90], [S90al, [S90b] and [S91]) that address the problem of automated generation of natural language expressions from a structured representation of meaning. Both algorithms follow the same general principle: given a grammar, and a structured representation of meaning, produce one or more corresponding surface strings, and do so with a minimal possible effort. In this paper we limit our analysis of the two algorithms to unification-based formalisms. The first algorithm, which we call here the Semantic-Head-Driven Generation Algorithm (SHDGA), uses information about semantic heads&apos; in grammar rules</context>
<context position="2677" citStr="[SNMP90]" startWordPosition="389" endWordPosition="389">e left. The second algorithm, which we call the Essential Arguments Algorithm (EAA), rearranges grammar productions at compile time in such a way that a simple top-down left-to-right evaluation will follow an optimal path. Both algorithms have resolved several outstanding problems in dealing with natural language grammars, including handling of left recursive rules, non-monotonic compositionality of representation, and deadlockprone rules2. In this paper we attempt to compare these two algorithms along their generality and efficiency lines. Throughout this paper we follow the notation used in [SNMP90]. 2. MAIN CHARACTERISTICS OF SIIDGA&apos;S AND EAA&apos;S TRAVERSALS SHDGA traverses the derivation tree in the semantic-head-first fashion. Starting from the goal predicate node (called the root), containing a structured representation (semantics) from which to generate, it selects a production whose left-hand side semantics unifies with the semantics of the root. If the selected production passes the semantics unchanged from the left to some nonterminal on the right (the so-called chain rule), this later nonterminal becomes the new root and the algorithm is applied recursively. On the other hand, if n</context>
<context position="5685" citStr="[SNMP90]" startWordPosition="879" endWordPosition="879">o the original grammar, however, the new grammar is evaluated TD and LR (i.e., using a standard Prolog interpreter). As a part of the node reordering process EAA calculates the minimal sets of essential arguments (msea&apos;s) for all literals in the grammar, which in turn will allow to project an optimal evaluation order. The optimal evaluation order is achieved by expanding only those literals which are ready at any given moment, i.e., those that have at least one of their mseas instantiated. The following example illustrates the traversal strategies of both algorithms. The grammar is taken from [SNMP90], and nonnalized to remove deadlock-prone rules in order to simplify the exposition.3 (0) sentence/decl(S) &gt; s(fmite)/S. (1) sentence/imp(S) &gt; vp(nonfmite,[npC)/you]) IS. (2) s(Form)/S &gt; Subj, vp(Form,[Subj/S. (3) vp(Form,Subcat)/S &gt; v(Form,Z)/S, vpl (Form, Z)/Subcat. (4) vpl(Form,[Compl I Z])/Ar &gt; vpl(Form,Z)/Ar, Compl. (5) vpl(Form,Ar)/Ar. (6) vp(Form,[Subj])/S &gt; v(Form,[Subj])/VP, aux(Form,[Subj],VP)/S. EAA eliminates such rules using global node reordering ([S91]). (7) aux(Form,[Subj],S)/S. (8) aux(Form,[Subj],A)/Z &gt; adv(A)/B, aux(Form[Subj],B)/Z. (9) v(finite,[npU/0,np(3-sing)/S])/love(S,</context>
<context position="19928" citStr="[SNMP90]" startWordPosition="3145" endWordPosition="3145">LTI-DIRECTIONALITY Another property of EAA regarded as superior over the SHDGA is its multi-directionality. EAA can be used for parsing as well as for generation. The algorithm will simply recognize that the top-level msea is now the string, and will adjust to the new situation. Moreover, EAA can be run in any direction paved by the predicates&apos; mseas as they become instantiated at the time a rule is taken up for expansion. In contrast, SHDGA can only be guaranteed to work in one direction, given any particular grammar, although the same architecture can apparently be used for both generation, [SNMP90], and parsing, [K90], [N89]. The point is that some grammars (as shown in the example above) need to be rewritten for parsing or generation, or else they must be constructed in such a way so as to avoid indeterminacy. While it is possible to rewrite grammars in a form appropriate for headfirst computation, there are real grammars which will not evaluate efficiently with SHDGA, even though EAA can handle such grammars with no problems. 6. CONCLUSION In this paper we discussed several aspects of two natural language generation algorithms: SHDGA and EAA. Both algorithms operate under the same gen</context>
</contexts>
<marker>[SNMP90]</marker>
<rawString>SHIEBER, S.M., VAN NOORD, G., MOORE, R.C., and PEREIRA, F.C.N. 1990. &amp;quot;Semantic-Head-Driven Generation.&amp;quot; Computational Linguistics, Volume 16, Number 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J WEDEKIND</author>
</authors>
<title>Generation as Structure Driven Derivation.&amp;quot;</title>
<date>1988</date>
<booktitle>Proceedings of the 12th International Conference on Computational Linguistics (COLING-88).</booktitle>
<pages>732--737</pages>
<location>Budapest, Hungary,</location>
<marker>[W88]</marker>
<rawString>WEDEKIND, J. 1988. &amp;quot;Generation as Structure Driven Derivation.&amp;quot; Proceedings of the 12th International Conference on Computational Linguistics (COLING-88). Budapest, Hungary, pp. 732-737.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>