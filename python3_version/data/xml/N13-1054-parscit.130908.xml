<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007377">
<title confidence="0.9982115">
Improving speech synthesis quality by reducing pitch peaks
in the source recordings
</title>
<author confidence="0.99099">
Luisina Violante, Pablo Rodriguez Zivic and Agustin Gravano
</author>
<affiliation confidence="0.8806295">
Departamento de Computaci´on, FCEyN
Universidad de Buenos Aires, Argentina
</affiliation>
<email confidence="0.998762">
{lviolante,prodriguez,gravano}@dc.uba.ar
</email>
<sectionHeader confidence="0.998599" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995277">
We present a method for improving the perceived nat-
uralness of corpus-based speech synthesizers. It con-
sists in removing pronounced pitch peaks in the origi-
nal recordings, which typically lead to noticeable dis-
continuities in the synthesized speech. We perceptu-
ally evaluated this method using two concatenative and
two HMM-based synthesis systems, and found that us-
ing it on the source recordings managed to improve
the naturalness of the synthesizers and had no effect
on their intelligibility.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999839052631579">
By definition, corpus-based speech synthesizers,
such as concatenative and HMM-based systems,
rely heavily on the quality of the speech corpus used
for building the systems. Creating speech corpora
for this purpose is expensive and time consuming, so
when the synthesized speech obtained is not as good
as expected, it may be desirable to modify or correct
the corpus rather than record a new one. Common
corrections are limited to discarding mispronounced
words or noisy units. In this work we describe a sim-
ple method for attenuating pronounced pitch peaks,
a frequent problem in recordings made by profes-
sional speakers, and evaluate it using four different
corpus-based systems. Sections 2 and 3 describe the
speech synthesis systems and corpus employed in
this work. In Section 4 we present the method for
reducing pitch peaks. In Section 5 we describe how
we evaluated the effect of our method on intelligibil-
ity and naturalness of the synthesizers.
</bodyText>
<sectionHeader confidence="0.981358" genericHeader="method">
2 Synthesis systems
</sectionHeader>
<bodyText confidence="0.99982932">
Festival1 is a general framework for building speech
synthesis systems, written in C++ and developed by
the Center of Speech Technology Research at the
University of Edinburgh (Black et al., 2001). It
provides an implementation of concatenative speech
synthesis as well as synthesis based on Hidden
Markov Models (HMM). In this work we used a Fes-
tival module called Clunits unit selection engine to
build concatenative synthesizers. The unit size is the
phone, although since a percentage of the previous
unit is included in the acoustic distance measure, the
unit size is rather “phone plus previous phone”, thus
similar to a diphone (Black and Lenzo, 2007). Ad-
ditionally, we used a second Festival module called
Clustergen parametric synthesis engine for building
HMM-based speech synthesizers.
MARY TTS2 is an open-source synthesis plat-
form written in Java, originally jointly developed
by the Language Technology Lab at the German
Research Center for Artificial Intelligence (DFKI)
and the Institute of Phonetics at Saarland Univer-
sity, and currently maintained by DFKI. Like Fes-
tival, MARY provides toolkits for building unit se-
lection and HMM-based synthesis voices (Schr¨oder
and Trouvain, 2003).
</bodyText>
<sectionHeader confidence="0.996368" genericHeader="method">
3 Corpus
</sectionHeader>
<bodyText confidence="0.997628333333333">
For building our systems we used the SECYT cor-
pus, created by the Laboratorio de Investigacio-
nes Sensoriales (Universidad de Buenos Aires) for
</bodyText>
<footnote confidence="0.9999765">
1http://festvox.org/festival
2http://mary.dfki.de
</footnote>
<page confidence="0.943869">
502
</page>
<subsectionHeader confidence="0.286519">
Proceedings of NAACL-HLT 2013, pages 502–506,
</subsectionHeader>
<bodyText confidence="0.990606">
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
studying the prosody of Argentine Spanish (Torres
and Gurlekian, 2004). It consists of 741 declarative
sentences recorded by a female professional speaker
(pitch range: 130-380Hz). On average, sentences
are 7 words and 3.9 seconds long. The entire corpus
has manual phonetic transcriptions and time align-
ments, following a version of the Speech Assessment
Methods Phonetic Alphabet (SAMPA) adapted for
Argentine Spanish (Gurlekian et al., 2001).
A priori, this corpus is a very good candidate for
building a synthesis system – its 741 sentences are
phonetically balanced, the audio quality is excellent,
and it has precise time-aligned phonetic transcrip-
tions. We thus built two concatenation systems us-
ing this corpus: Festival’s diphone-like and MARY’s
diphone systems. The results were not satisfactory.
The new voices presented clearly noticeable discon-
tinuities, both in intensity and pitch, which affected
their naturalness – as judged impressionistically by
the authors and non-expert colleagues.
In an attempt to attenuate these problems, we lev-
eled the intensity of all recordings to a mean of 72dB
using linear interpolation. Specifically, each sound
was multiplied by a number such that its new aver-
age RMS intensity was 72dB; so that all sentences
in the corpus ended up with the same average inten-
sity. After this conversion, we rebuilt the systems.
The resulting voices sounded somewhat better, but
their most noticeable problem, severe pitch discon-
tinuities, persisted.
Further analysis of the corpus recordings revealed
that this issue was likely due to the speaking style
employed by the professional speaker. It contains
frequent pronounced pitch peaks, a verbal stylistic
device acquired by the speaker as part of her pro-
fessional training. These events produced units with
very different pitch levels and slopes, thus leading to
the discontinuities mentioned above.
</bodyText>
<sectionHeader confidence="0.893361" genericHeader="method">
4 Reduction of pitch peaks
</sectionHeader>
<bodyText confidence="0.996678052631579">
We searched for ways to reduce the magnitude of
these pitch peaks by manipulating the pitch track
of the recordings using the Time-Domain Pitch-
Synchronous OverLap-and-Add (TD-PSOLA) sig-
nal processing technique (Moulines and Charpen-
tier, 1990). We used the implementation of TD-
PSOLA included in the Praat toolkit (Boersma and
Weenink, 2012).
We tried several formulas for TD-PSOLA and
ended up choosing the one that appeared to yield the
best results, evaluated perceptually by the authors:
This formula linearly scales the pitch track by a scal-
ing factor s above a threshold T, and leaves it intact
below T. When 0 &lt; s &lt; 1, the pitch track gets com-
pressed above the threshold. We experimented with
several values for the two constants, and selected
T = 200Hz and s = 0.4 as the ones producing the
best results. Figure 1 illustrates the pitch peak re-
duction method. The black solid line corresponds to
</bodyText>
<figureCaption confidence="0.996613">
Figure 1: Reduction of pitch peaks. The original pitch
track (in black) is scaled down 40% above 200Hz.
</figureCaption>
<bodyText confidence="0.999254">
the pitch track of the original audio; the red dotted
line, to the pitch track of the modified audio. Note
that the modified pitch track is scaled down above
200Hz, but identical to the original below it.
</bodyText>
<sectionHeader confidence="0.87026" genericHeader="evaluation">
5 Evaluation of the method
</sectionHeader>
<bodyText confidence="0.999494">
Next we proceeded to evaluate the effect on synthe-
sizer quality of reducing pitch peaks in the train-
ing corpus. For this purpose we prepared two ver-
sions of the SECYT corpus – with and without ap-
plying our pitch-peak reduction technique. We refer
to these two as the original and modified recordings,
respectively. In both cases, the intensity level of all
audios was first leveled to a mean of 72dB using
linear interpolation, to compensate for differences
across recordings.
</bodyText>
<figure confidence="0.994423416666667">
1.0 1.5 2.0 2.5
Time (s)
Hz
300
250
200
150
Original
Modified
f(x) = r (x − T) *s + T if x &gt; T
x
otherwise.
</figure>
<page confidence="0.994862">
503
</page>
<bodyText confidence="0.9999924375">
Subsequently, we built 8 speech synthesizers,
consisting in all combinations of: Festival and
MARY frameworks, concatenative and HMM-based
synthesis, and original and modified recordings. We
refer to these systems using the following nota-
tion: {fest, mary} {conc, hmm} {orig, mod}; e.g.,
mary conc mod is a concatenative system built us-
ing the MARY framework with the modified corpus.
We evaluated these systems along two dimen-
sions: intelligibility and naturalness. Our goal was
to compare four system pairs: systems built using
the original recordings vs. those built using the mod-
ified recordings. The null hypothesis was that there
was no difference between ‘orig’ and ‘mod’ sys-
tems; and the alternative hypothesis was that ‘mod’
systems were better than ‘orig’ ones.
</bodyText>
<subsectionHeader confidence="0.653125">
5.1 Intelligibility
</subsectionHeader>
<bodyText confidence="0.990739130434783">
To evaluate intelligibility we used the Semantically
Unpredictable Sentences (SUS) method (Nye and
Gaitenby, 1974), which consists in asking partici-
pants to listen to and transcribe sentences with cor-
rect syntax but no semantic sense, for later measur-
ing and comparing the number of transcription er-
rors. We used a set of 50 such sentences, each 6-10
words long, created by Gurlekian et al. (2012) for
evaluating Spanish speech synthesizers. A sample
sentence is, El viento dulce arm´o un libro de pan-
queques (The sweet wind made a book of pancakes).
For each participant, 40 sentences were selected
at random and synthesized with the 8 systems (5 sen-
tences per system, with no repetitions). Participants
were given the following instructions,
La primera tarea consiste en escuchar varios audios, y
transcribir para cada audio la oraci´on que escuches.
Prest´a atenci´on, porque pod´es escuchar cada audio
una sola vez.
(The first task consists in listening to several audios,
and transcribing for each audio the sentence you hear.
Pay attention, because you can only listen to each au-
dio once.)
</bodyText>
<subsectionHeader confidence="0.983163">
5.2 Naturalness
</subsectionHeader>
<bodyText confidence="0.999443666666667">
To evaluate naturalness we used the Mean Opin-
ion Score (MOS) method, in which participants
are asked to rate the overall quality of synthe-
sized speech on a 10-point scale (Viswanathan and
Viswanathan, 2005).
We used a set of 20 sentences, each 5-20 words
long, created by Gurlekian et al. (2012), plus 20 ad-
ditional sentences created for this study. A sample
sentence is, El sector de inform´atica es el nuevo
generador de empleo del pais (The information
technology sector is the country’s new job creator).
Again, for each participant, 40 sentences were se-
lected at random and synthesized with the 8 systems
(5 sentences per system). Participants were given
the following instructions,
</bodyText>
<construct confidence="0.7179775">
La segunda (y ´ultima) tarea consiste en escuchar otros
audios, y puntuar la naturalidad de cada uno. Usar
una escala de 1 a 10, donde 1 significa “no suena nat-
ural en lo absoluto” y 10 significa “suena completa-
mente natural”. En este caso, pod´es escuchar cada
audio una o m´as veces.
</construct>
<figureCaption confidence="0.5508745">
(The second (and last) task consists in listening to
other audios, and score the naturalness of each. Use
a scale from 1 to 10, where 1 means “it does not sound
natural at all” and 10 means “it sounds completely nat-
ural”. In this case, you may listen to each audio one or
more times.)
</figureCaption>
<subsectionHeader confidence="0.629063">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.99993332">
SUS and MOS tests were administered on a com-
puter interface in a silent laboratory using regular
headphones. 14 graduate and undergraduate stu-
dents (11 male, 3 female; mean age: 27.6) com-
pleted both tests – first SUS, followed by MOS.
The transcriptions of the SUS tests were manually
corrected for obvious typos and spelling errors that
did not form a valid Spanish word. Suspected typos
and spelling errors that formed a valid word were not
corrected. For example, peliculas was corrected to
peliculas, and precion to presi´on; but canto was not
corrected to cant´o, since it is a valid word. Subse-
quently, we computed the Levenshtein distance be-
tween each transcription and the corresponding sen-
tence. Figure 2 shows the distribution of Leven-
shtein distances for each of our eight systems. We
observe that all systems had a low error count, with
a median of 0 or 1 errors per sentence. Two-tail
Wilcoxon signed-rank tests revealed no significant
differences between the systems built with the origi-
nal and modified recordings (p = 0.70 for fest conc,
p = 0.40 for fest hmm, p = 0.69 for mary conc,
p=0.40 for mary hmm, and p=0.41 for all systems
together). These results indicate that the intelligibil-
ity of all four system types was not affected by the
</bodyText>
<page confidence="0.994528">
504
</page>
<figure confidence="0.977364888888889">
7
6
5
4
3
2
1
0
1
</figure>
<figureCaption confidence="0.999388">
Figure 2: Intelligibility (SUS) results.
</figureCaption>
<bodyText confidence="0.986332333333333">
modifications performed on the corpus for reducing
pitch peaks.
To account for the different interpretations of the
10-point scale, we normalized all MOS test scores
by participant using z-scores.3 Figure 3 shows the
distribution of values for each system.
</bodyText>
<figureCaption confidence="0.99699">
Figure 3: Naturalness (MOS) results.
</figureCaption>
<bodyText confidence="0.999879444444444">
We performed a series of Wilcoxon signed-rank
tests to assess the statistical significance of the ob-
served differences. The null hypothesis was that
there was no difference between ‘orig’ and ‘mod’
systems; and the alternative hypothesis was that
‘mod’ systems were perceived as more natural than
‘orig’ ones. Table 5.3 summarizes these results.
For mary conc and mary hmm (concatenative
and HMM-based systems built using the MARY
</bodyText>
<footnote confidence="0.9380615">
3z = (x − x)/s, where x and s are estimates of the partici-
pant’s mean and standard deviation, respectively.
</footnote>
<table confidence="0.9991305">
W p-value
2485 0.559
2175 0.126
1933 0.016
1680.5 0.001
34064.5 0.004
</table>
<tableCaption confidence="0.9206475">
Table 1: Results of Wilcoxon tests comparing systems
using the original and modified audios.
</tableCaption>
<bodyText confidence="0.999486">
framework) the perceived naturalness was signifi-
cantly higher for systems built using the modified
recordings (i.e., after reducing pitch peaks) than
for systems built with the original recordings. For
fest conc (concatenative system built with Festival)
we found no evidence of such differences. Finally,
for fest hmm (Festival HMM-based) the difference
approaches significance at 0.126.
</bodyText>
<sectionHeader confidence="0.997264" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9992538">
In this paper we presented a method for improving
the perceived naturalness of corpus-based speech
synthesizers. It consists in removing pronounced
pitch peaks in the original recordings, which typ-
ically produce discontinuities in the synthesized
speech. We evaluated this method using two com-
mon technologies (concatenative and HMM-based
synthesis) and two different implementations (Festi-
val and MARY), aiming at a good coverage of state-
of-the-art speech synthesizers, and obtained clear re-
sults. First, its utilization on the source recordings
had no effect (negative or positive) on the intelligi-
bility of any of the systems. Second, the natural-
ness of the concatenative and HMM-based systems
built with the MARY framework improved signif-
icantly; the HMM-based system built with Festival
showed an improved naturalness at a level approach-
ing significance; and the Festival concatenative sys-
tem showed no improvement. In summary, the pre-
sented method did not harm the intelligibility of the
systems, and in some cases managed to improve
their naturalness. Therefore, since the impact of the
proposed modifications on all four systems was pos-
itive to neutral, developers may find this methodol-
ogy beneficial.
</bodyText>
<figure confidence="0.932551475">
z-score
0
3
2
3 fest
conc
orig
1
1
2
fest
conc
mod
fest
hmm
orig
fest
hmm
mod
mary
conc
orig
mary
conc
mod
mary
hmm
orig
mary
hmm
mod
Levenshtein distance
fest fest fest fest mary mary mary mary
conc conc hmm hmm conc conc hmm hmm
mod orig mod orig mod orig mod orig
fest conc
fest hmm
mary conc
mary hmm
All systems
</figure>
<page confidence="0.991842">
505
</page>
<sectionHeader confidence="0.999526" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.858377">
This work was funded in part by CONICET, ANPCYT
PICT 2009-0026, and UBACYT 20020090300087. The
authors thank Jorge A. Gurlekian, Humberto M. Torres
and Christian G. Cossio-Mercado from LIS (INIGEM,
CONICET-UBA) for kindly sharing the SECYT corpus
and other materials for the present study, as well as for
valuable suggestions and comments.
</bodyText>
<sectionHeader confidence="0.994335" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999712428571429">
Alan W. Black and Kevin A. Lenzo. 2007. Building
Synthetic Voices. Language Technologies Institute,
Carnegie Mellon University, http://festvox.org/bsv.
A. Black, P. Taylor, R. Caley, R. Clark, K. Richmond,
S. King, V. Strom, and H. Zen. 2001. The festival
speech synthesis system.
Paul Boersma and David Weenink. 2012. Praat: doing
phonetics by computer. http://www.praat.org/.
J. Gurlekian, L. Colantoni, and H. Torres. 2001. El al-
fabeto fon´etico SAMPA y el dise˜no de corpora fon´e-
ticamente balanceados. Fonoaudiol´ogica, 47:58–69.
J. A. Gurlekian, C. Cossio-Mercado, H. Torres, and M. E.
Vaccari. 2012. Subjective evaluation of a high quality
text-to-speech system for Argentine Spanish. In Pro-
ceedings of Iberspeech, Madrid, Spain.
E. Moulines and F. Charpentier. 1990. Pitch-syn-
chronous waveform processing techniques for text-to-
speech synthesis using diphones. Speech communica-
tion, 9(5):453–467.
P. W. Nye and J. H. Gaitenby. 1974. The intelligibility
of synthetic monosyllabic words in short, syntactically
normal sentences. Haskins Laboratories Status Report
on Speech Research, 37(38):169–190.
M. Schr¨oder and J. Trouvain. 2003. The German text-to-
speech synthesis system MARY: A tool for research,
development and teaching. International Journal of
Speech Technology, 6(4):365–377.
H. M. Torres and J. A. Gurlekian. 2004. Automatic de-
termination of phrase breaks for Argentine Spanish. In
Speech Prosody 2004, International Conference.
Mahesh Viswanathan and Madhubalan Viswanathan.
2005. Measuring speech quality for text-to-speech
systems: Development and assessment of a modified
mean opinion score (MOS) scale. Computer Speech
&amp; Language, 19(1):55–83.
</reference>
<page confidence="0.998392">
506
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.962873">
<title confidence="0.992587">Improving speech synthesis quality by reducing pitch in the source recordings</title>
<author confidence="0.994729">Rodriguez Zivic</author>
<affiliation confidence="0.992373">Departamento de Computaci´on, Universidad de Buenos Aires,</affiliation>
<abstract confidence="0.999457181818182">We present a method for improving the perceived naturalness of corpus-based speech synthesizers. It consists in removing pronounced pitch peaks in the original recordings, which typically lead to noticeable discontinuities in the synthesized speech. We perceptually evaluated this method using two concatenative and two HMM-based synthesis systems, and found that using it on the source recordings managed to improve the naturalness of the synthesizers and had no effect on their intelligibility.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alan W Black</author>
<author>Kevin A Lenzo</author>
</authors>
<title>Building Synthetic Voices. Language Technologies Institute,</title>
<date>2007</date>
<location>Carnegie Mellon University, http://festvox.org/bsv.</location>
<contexts>
<context position="2415" citStr="Black and Lenzo, 2007" startWordPosition="369" endWordPosition="372"> building speech synthesis systems, written in C++ and developed by the Center of Speech Technology Research at the University of Edinburgh (Black et al., 2001). It provides an implementation of concatenative speech synthesis as well as synthesis based on Hidden Markov Models (HMM). In this work we used a Festival module called Clunits unit selection engine to build concatenative synthesizers. The unit size is the phone, although since a percentage of the previous unit is included in the acoustic distance measure, the unit size is rather “phone plus previous phone”, thus similar to a diphone (Black and Lenzo, 2007). Additionally, we used a second Festival module called Clustergen parametric synthesis engine for building HMM-based speech synthesizers. MARY TTS2 is an open-source synthesis platform written in Java, originally jointly developed by the Language Technology Lab at the German Research Center for Artificial Intelligence (DFKI) and the Institute of Phonetics at Saarland University, and currently maintained by DFKI. Like Festival, MARY provides toolkits for building unit selection and HMM-based synthesis voices (Schr¨oder and Trouvain, 2003). 3 Corpus For building our systems we used the SECYT co</context>
</contexts>
<marker>Black, Lenzo, 2007</marker>
<rawString>Alan W. Black and Kevin A. Lenzo. 2007. Building Synthetic Voices. Language Technologies Institute, Carnegie Mellon University, http://festvox.org/bsv.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Black</author>
<author>P Taylor</author>
<author>R Caley</author>
<author>R Clark</author>
<author>K Richmond</author>
<author>S King</author>
<author>V Strom</author>
<author>H Zen</author>
</authors>
<title>The festival speech synthesis system.</title>
<date>2001</date>
<contexts>
<context position="1953" citStr="Black et al., 2001" startWordPosition="294" endWordPosition="297">peaks, a frequent problem in recordings made by professional speakers, and evaluate it using four different corpus-based systems. Sections 2 and 3 describe the speech synthesis systems and corpus employed in this work. In Section 4 we present the method for reducing pitch peaks. In Section 5 we describe how we evaluated the effect of our method on intelligibility and naturalness of the synthesizers. 2 Synthesis systems Festival1 is a general framework for building speech synthesis systems, written in C++ and developed by the Center of Speech Technology Research at the University of Edinburgh (Black et al., 2001). It provides an implementation of concatenative speech synthesis as well as synthesis based on Hidden Markov Models (HMM). In this work we used a Festival module called Clunits unit selection engine to build concatenative synthesizers. The unit size is the phone, although since a percentage of the previous unit is included in the acoustic distance measure, the unit size is rather “phone plus previous phone”, thus similar to a diphone (Black and Lenzo, 2007). Additionally, we used a second Festival module called Clustergen parametric synthesis engine for building HMM-based speech synthesizers.</context>
</contexts>
<marker>Black, Taylor, Caley, Clark, Richmond, King, Strom, Zen, 2001</marker>
<rawString>A. Black, P. Taylor, R. Caley, R. Clark, K. Richmond, S. King, V. Strom, and H. Zen. 2001. The festival speech synthesis system.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
<author>David Weenink</author>
</authors>
<title>Praat: doing phonetics by computer.</title>
<date>2012</date>
<note>http://www.praat.org/.</note>
<contexts>
<context position="5548" citStr="Boersma and Weenink, 2012" startWordPosition="836" endWordPosition="839"> It contains frequent pronounced pitch peaks, a verbal stylistic device acquired by the speaker as part of her professional training. These events produced units with very different pitch levels and slopes, thus leading to the discontinuities mentioned above. 4 Reduction of pitch peaks We searched for ways to reduce the magnitude of these pitch peaks by manipulating the pitch track of the recordings using the Time-Domain PitchSynchronous OverLap-and-Add (TD-PSOLA) signal processing technique (Moulines and Charpentier, 1990). We used the implementation of TDPSOLA included in the Praat toolkit (Boersma and Weenink, 2012). We tried several formulas for TD-PSOLA and ended up choosing the one that appeared to yield the best results, evaluated perceptually by the authors: This formula linearly scales the pitch track by a scaling factor s above a threshold T, and leaves it intact below T. When 0 &lt; s &lt; 1, the pitch track gets compressed above the threshold. We experimented with several values for the two constants, and selected T = 200Hz and s = 0.4 as the ones producing the best results. Figure 1 illustrates the pitch peak reduction method. The black solid line corresponds to Figure 1: Reduction of pitch peaks. Th</context>
</contexts>
<marker>Boersma, Weenink, 2012</marker>
<rawString>Paul Boersma and David Weenink. 2012. Praat: doing phonetics by computer. http://www.praat.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gurlekian</author>
<author>L Colantoni</author>
<author>H Torres</author>
</authors>
<title>El alfabeto fon´etico SAMPA y el dise˜no de corpora fon´eticamente balanceados.</title>
<date>2001</date>
<journal>Fonoaudiol´ogica,</journal>
<pages>47--58</pages>
<contexts>
<context position="3740" citStr="Gurlekian et al., 2001" startWordPosition="557" endWordPosition="560">p://festvox.org/festival 2http://mary.dfki.de 502 Proceedings of NAACL-HLT 2013, pages 502–506, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics studying the prosody of Argentine Spanish (Torres and Gurlekian, 2004). It consists of 741 declarative sentences recorded by a female professional speaker (pitch range: 130-380Hz). On average, sentences are 7 words and 3.9 seconds long. The entire corpus has manual phonetic transcriptions and time alignments, following a version of the Speech Assessment Methods Phonetic Alphabet (SAMPA) adapted for Argentine Spanish (Gurlekian et al., 2001). A priori, this corpus is a very good candidate for building a synthesis system – its 741 sentences are phonetically balanced, the audio quality is excellent, and it has precise time-aligned phonetic transcriptions. We thus built two concatenation systems using this corpus: Festival’s diphone-like and MARY’s diphone systems. The results were not satisfactory. The new voices presented clearly noticeable discontinuities, both in intensity and pitch, which affected their naturalness – as judged impressionistically by the authors and non-expert colleagues. In an attempt to attenuate these problem</context>
</contexts>
<marker>Gurlekian, Colantoni, Torres, 2001</marker>
<rawString>J. Gurlekian, L. Colantoni, and H. Torres. 2001. El alfabeto fon´etico SAMPA y el dise˜no de corpora fon´eticamente balanceados. Fonoaudiol´ogica, 47:58–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Gurlekian</author>
<author>C Cossio-Mercado</author>
<author>H Torres</author>
<author>M E Vaccari</author>
</authors>
<title>Subjective evaluation of a high quality text-to-speech system for Argentine Spanish.</title>
<date>2012</date>
<booktitle>In Proceedings of Iberspeech,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="8224" citStr="Gurlekian et al. (2012)" startWordPosition="1293" endWordPosition="1296">ilt using the modified recordings. The null hypothesis was that there was no difference between ‘orig’ and ‘mod’ systems; and the alternative hypothesis was that ‘mod’ systems were better than ‘orig’ ones. 5.1 Intelligibility To evaluate intelligibility we used the Semantically Unpredictable Sentences (SUS) method (Nye and Gaitenby, 1974), which consists in asking participants to listen to and transcribe sentences with correct syntax but no semantic sense, for later measuring and comparing the number of transcription errors. We used a set of 50 such sentences, each 6-10 words long, created by Gurlekian et al. (2012) for evaluating Spanish speech synthesizers. A sample sentence is, El viento dulce arm´o un libro de panqueques (The sweet wind made a book of pancakes). For each participant, 40 sentences were selected at random and synthesized with the 8 systems (5 sentences per system, with no repetitions). Participants were given the following instructions, La primera tarea consiste en escuchar varios audios, y transcribir para cada audio la oraci´on que escuches. Prest´a atenci´on, porque pod´es escuchar cada audio una sola vez. (The first task consists in listening to several audios, and transcribing for</context>
</contexts>
<marker>Gurlekian, Cossio-Mercado, Torres, Vaccari, 2012</marker>
<rawString>J. A. Gurlekian, C. Cossio-Mercado, H. Torres, and M. E. Vaccari. 2012. Subjective evaluation of a high quality text-to-speech system for Argentine Spanish. In Proceedings of Iberspeech, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Moulines</author>
<author>F Charpentier</author>
</authors>
<title>Pitch-synchronous waveform processing techniques for text-tospeech synthesis using diphones. Speech communication,</title>
<date>1990</date>
<pages>9--5</pages>
<contexts>
<context position="5451" citStr="Moulines and Charpentier, 1990" startWordPosition="819" endWordPosition="823">gs revealed that this issue was likely due to the speaking style employed by the professional speaker. It contains frequent pronounced pitch peaks, a verbal stylistic device acquired by the speaker as part of her professional training. These events produced units with very different pitch levels and slopes, thus leading to the discontinuities mentioned above. 4 Reduction of pitch peaks We searched for ways to reduce the magnitude of these pitch peaks by manipulating the pitch track of the recordings using the Time-Domain PitchSynchronous OverLap-and-Add (TD-PSOLA) signal processing technique (Moulines and Charpentier, 1990). We used the implementation of TDPSOLA included in the Praat toolkit (Boersma and Weenink, 2012). We tried several formulas for TD-PSOLA and ended up choosing the one that appeared to yield the best results, evaluated perceptually by the authors: This formula linearly scales the pitch track by a scaling factor s above a threshold T, and leaves it intact below T. When 0 &lt; s &lt; 1, the pitch track gets compressed above the threshold. We experimented with several values for the two constants, and selected T = 200Hz and s = 0.4 as the ones producing the best results. Figure 1 illustrates the pitch </context>
</contexts>
<marker>Moulines, Charpentier, 1990</marker>
<rawString>E. Moulines and F. Charpentier. 1990. Pitch-synchronous waveform processing techniques for text-tospeech synthesis using diphones. Speech communication, 9(5):453–467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Nye</author>
<author>J H Gaitenby</author>
</authors>
<title>The intelligibility of synthetic monosyllabic words in short, syntactically normal sentences. Haskins Laboratories Status Report on Speech Research,</title>
<date>1974</date>
<pages>37--38</pages>
<contexts>
<context position="7941" citStr="Nye and Gaitenby, 1974" startWordPosition="1243" endWordPosition="1246">.g., mary conc mod is a concatenative system built using the MARY framework with the modified corpus. We evaluated these systems along two dimensions: intelligibility and naturalness. Our goal was to compare four system pairs: systems built using the original recordings vs. those built using the modified recordings. The null hypothesis was that there was no difference between ‘orig’ and ‘mod’ systems; and the alternative hypothesis was that ‘mod’ systems were better than ‘orig’ ones. 5.1 Intelligibility To evaluate intelligibility we used the Semantically Unpredictable Sentences (SUS) method (Nye and Gaitenby, 1974), which consists in asking participants to listen to and transcribe sentences with correct syntax but no semantic sense, for later measuring and comparing the number of transcription errors. We used a set of 50 such sentences, each 6-10 words long, created by Gurlekian et al. (2012) for evaluating Spanish speech synthesizers. A sample sentence is, El viento dulce arm´o un libro de panqueques (The sweet wind made a book of pancakes). For each participant, 40 sentences were selected at random and synthesized with the 8 systems (5 sentences per system, with no repetitions). Participants were give</context>
</contexts>
<marker>Nye, Gaitenby, 1974</marker>
<rawString>P. W. Nye and J. H. Gaitenby. 1974. The intelligibility of synthetic monosyllabic words in short, syntactically normal sentences. Haskins Laboratories Status Report on Speech Research, 37(38):169–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Schr¨oder</author>
<author>J Trouvain</author>
</authors>
<title>The German text-tospeech synthesis system MARY: A tool for research, development and teaching.</title>
<date>2003</date>
<journal>International Journal of Speech Technology,</journal>
<volume>6</volume>
<issue>4</issue>
<marker>Schr¨oder, Trouvain, 2003</marker>
<rawString>M. Schr¨oder and J. Trouvain. 2003. The German text-tospeech synthesis system MARY: A tool for research, development and teaching. International Journal of Speech Technology, 6(4):365–377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Torres</author>
<author>J A Gurlekian</author>
</authors>
<title>Automatic determination of phrase breaks for Argentine Spanish.</title>
<date>2004</date>
<booktitle>In Speech Prosody 2004, International Conference.</booktitle>
<contexts>
<context position="3366" citStr="Torres and Gurlekian, 2004" startWordPosition="502" endWordPosition="505">KI) and the Institute of Phonetics at Saarland University, and currently maintained by DFKI. Like Festival, MARY provides toolkits for building unit selection and HMM-based synthesis voices (Schr¨oder and Trouvain, 2003). 3 Corpus For building our systems we used the SECYT corpus, created by the Laboratorio de Investigaciones Sensoriales (Universidad de Buenos Aires) for 1http://festvox.org/festival 2http://mary.dfki.de 502 Proceedings of NAACL-HLT 2013, pages 502–506, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics studying the prosody of Argentine Spanish (Torres and Gurlekian, 2004). It consists of 741 declarative sentences recorded by a female professional speaker (pitch range: 130-380Hz). On average, sentences are 7 words and 3.9 seconds long. The entire corpus has manual phonetic transcriptions and time alignments, following a version of the Speech Assessment Methods Phonetic Alphabet (SAMPA) adapted for Argentine Spanish (Gurlekian et al., 2001). A priori, this corpus is a very good candidate for building a synthesis system – its 741 sentences are phonetically balanced, the audio quality is excellent, and it has precise time-aligned phonetic transcriptions. We thus b</context>
</contexts>
<marker>Torres, Gurlekian, 2004</marker>
<rawString>H. M. Torres and J. A. Gurlekian. 2004. Automatic determination of phrase breaks for Argentine Spanish. In Speech Prosody 2004, International Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahesh Viswanathan</author>
<author>Madhubalan Viswanathan</author>
</authors>
<title>Measuring speech quality for text-to-speech systems: Development and assessment of a modified mean opinion score (MOS) scale.</title>
<date>2005</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="9145" citStr="Viswanathan and Viswanathan, 2005" startWordPosition="1441" endWordPosition="1444">tions). Participants were given the following instructions, La primera tarea consiste en escuchar varios audios, y transcribir para cada audio la oraci´on que escuches. Prest´a atenci´on, porque pod´es escuchar cada audio una sola vez. (The first task consists in listening to several audios, and transcribing for each audio the sentence you hear. Pay attention, because you can only listen to each audio once.) 5.2 Naturalness To evaluate naturalness we used the Mean Opinion Score (MOS) method, in which participants are asked to rate the overall quality of synthesized speech on a 10-point scale (Viswanathan and Viswanathan, 2005). We used a set of 20 sentences, each 5-20 words long, created by Gurlekian et al. (2012), plus 20 additional sentences created for this study. A sample sentence is, El sector de inform´atica es el nuevo generador de empleo del pais (The information technology sector is the country’s new job creator). Again, for each participant, 40 sentences were selected at random and synthesized with the 8 systems (5 sentences per system). Participants were given the following instructions, La segunda (y ´ultima) tarea consiste en escuchar otros audios, y puntuar la naturalidad de cada uno. Usar una escala </context>
</contexts>
<marker>Viswanathan, Viswanathan, 2005</marker>
<rawString>Mahesh Viswanathan and Madhubalan Viswanathan. 2005. Measuring speech quality for text-to-speech systems: Development and assessment of a modified mean opinion score (MOS) scale. Computer Speech &amp; Language, 19(1):55–83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>