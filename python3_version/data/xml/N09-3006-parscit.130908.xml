<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.035155">
<title confidence="0.9995435">
Pronunciation Modeling in Spelling Correction
for Writers of English as a Foreign Language
</title>
<author confidence="0.986914">
Adriane Boyd
</author>
<affiliation confidence="0.994048">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.6687565">
1712 Neil Avenue
Columbus, Ohio 43210, USA
</address>
<email confidence="0.999198">
adriane@ling.osu.edu
</email>
<sectionHeader confidence="0.993907" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9989589375">
We propose a method for modeling pronunci-
ation variation in the context of spell checking
for non-native writers of English. Spell check-
ers, typically developed for native speakers,
fail to address many of the types of spelling
errors peculiar to non-native speakers, espe-
cially those errors influenced by differences in
phonology. Our model of pronunciation varia-
tion is used to extend a pronouncing dictionary
for use in the spelling correction algorithm
developed by Toutanova and Moore (2002),
which includes models for both orthography
and pronunciation. The pronunciation vari-
ation modeling is shown to improve perfor-
mance for misspellings produced by Japanese
writers of English.
</bodyText>
<sectionHeader confidence="0.998978" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999868823529412">
Spell checkers identify misspellings, select appro-
priate words as suggested corrections, and rank the
suggested corrections so that the likely intended
word is high in the list. Since traditional spell
checkers have been developed with competent na-
tive speakers as the target users, they do not appro-
priately address many types of errors made by non-
native writers and they often fail to suggest the ap-
propriate corrections. Non-native writers of English
struggle with many of the same idiosyncrasies of En-
glish spelling that cause difficulty for native speak-
ers, but differences between English phonology and
the phonology of their native language lead to types
of spelling errors not anticipated by traditional spell
checkers (Okada, 2004; Mitton and Okada, 2007).
Okada (2004) and Mitton and Okada (2007) in-
vestigate spelling errors made by Japanese writers
</bodyText>
<page confidence="0.998102">
31
</page>
<bodyText confidence="0.999990925925926">
of English as a foreign language (JWEFL). Okada
(2004) identifies two main sources of errors for
JWEFL: differences between English and Japanese
phonology and differences between the English al-
phabet and the Japanese romazi writing system,
which uses a subset of English letters. Phonolog-
ical differences result in number of distinctions in
English that are not present in Japanese and romazi
causes difficulties for JWEFL because the Latin let-
ters correspond to very different sounds in Japanese.
We propose a method for creating a model of
pronunciation variation from a phonetically untran-
scribed corpus of read speech recorded by non-
native speakers. The pronunciation variation model
is used to generate multiple pronunciations for each
canonical pronunciation in a pronouncing dictionary
and these variations are used in the spelling correc-
tion approach developed by Toutanova and Moore
(2002), which uses statistical models of spelling er-
rors that consider both orthography and pronuncia-
tion. Several conventions are used throughout this
paper: a word is a sequence of characters from the
given alphabet found in the word list. A word list
is a list of words. A misspelling, marked with *, is
a sequence of characters not found in the word list.
A candidate correction is a word from the word list
proposed as a potential correction.
</bodyText>
<sectionHeader confidence="0.981845" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.992163333333333">
Research in spell checking (see Kukich, 1992, for
a survey of spell checking research) has focused
on three main problems: non-word error detec-
tion, isolated-word error correction, and context-
dependent word correction. We focus on the first
two tasks. A non-word is a sequence of letters that
</bodyText>
<note confidence="0.6682945">
Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 31–36,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999948285714286">
is not a possible word in the language in any con-
text, e.g., English *thier. Once a sequence of let-
ters has been determined to be a non-word, isolated-
word error correction is the process of determining
the appropriate word to substitute for the non-word.
Given a sequence of letters, there are thus two
main subtasks: 1) determine whether this is a non-
word, 2) if so, select and rank candidate words as
potential corrections to present to the writer. The
first subtask can be accomplished by searching for
the sequence of letters in a word list. The second
subtask can be stated as follows (Brill and Moore,
2000): Given an alphabet E, a word list D of strings
∈ E*, and a string r ∈/ D and ∈ E*, find w ∈ D
such that w is the most likely correction. Minimum
edit distance is used to select the most likely candi-
date corrections. The general idea is that a minimum
number of edit operations such as insertion and sub-
stitution are needed to convert the misspelling into a
word. Words requiring the smallest numbers of edit
operations are selected as the candidate corrections.
</bodyText>
<subsectionHeader confidence="0.998958">
2.1 Edit Operations and Edit Weights
</subsectionHeader>
<bodyText confidence="0.999995235294118">
In recent spelling correction approaches, edit op-
erations have been extended beyond single charac-
ter edits and the methods for calculating edit opera-
tion weights have become more sophisticated. The
spelling error model proposed by Brill and Moore
(2000) allows generic string edit operations up to a
certain length. Each edit operation also has an asso-
ciated probability that improves the ranking of can-
didate corrections by modeling how likely particu-
lar edits are. Brill and Moore (2000) estimate the
probability of each edit from a corpus of spelling er-
rors. Toutanova and Moore (2002) extend Brill and
Moore (2000) to consider edits over both letter se-
quences and sequences of phones in the pronuncia-
tions of the word and misspelling. They show that
including pronunciation information improves per-
formance as compared to Brill and Moore (2000).
</bodyText>
<subsectionHeader confidence="0.993692">
2.2 Noisy Channel Spelling Correction
</subsectionHeader>
<bodyText confidence="0.9990465625">
The spelling correction models from Brill and
Moore (2000) and Toutanova and Moore (2002) use
the noisy channel model approach to determine the
types and weights of edit operations. The idea be-
hind this approach is that a writer starts out with the
intended word w in mind, but as it is being writ-
ten the word passes through a noisy channel result-
ing in the observed non-word r. In order to de-
termine how likely a candidate correction is, the
spelling correction model determines the probabil-
ity that the word w was the intended word given the
misspelling r: P(w|r). To find the best correction,
the word w is found for which P(w|r) is maximized:
argmax,,, P(w|r). Applying Bayes’ Rule and dis-
carding the normalizing constant P(r) gives the cor-
rection model:
</bodyText>
<equation confidence="0.495095">
argmax,,, P(w|r) = argmax,,, P(w)P(r|w)
</equation>
<bodyText confidence="0.99994109375">
P(w), how probable the word w is overall, and
P(r|w), how probable it is for a writer intending to
write w to output r, can be estimated from corpora
containing misspellings. In the following experi-
ments, P(w) is assumed be equal for all words to fo-
cus this work on estimating the error model P(r|w)
for JWEFL.1
Brill and Moore (2000) allow all edit operations
α → Q where E is the alphabet and α, Q ∈ E*, with
a constraint on the length of α and Q. In order to
consider all ways that a word w may generate r with
the possibility that any, possibly empty, substring α
of w becomes any, possibly empty, substring Q of
r, it is necessary to consider all ways that w and r
may be partitioned into substrings. This error model
over letters, called PL, is approximated by Brill and
Moore (2000) as shown in Figure 1 by considering
only the pair of partitions of w and r with the max-
imum product of the probabilities of individual sub-
stitutions. Part(w) is all possible partitions of w,
|R |is number of segments in a particular partition,
and Ri is the ith segment of the partition.
The parameters for PL(r|w) are estimated from
a corpus of pairs of misspellings and target words.
The method, which is described in detail in Brill and
Moore (2000), involves aligning the letters in pairs
of words and misspellings, expanding each align-
ment with up to N neighboring alignments, and cal-
culating the probability of each α → Q alignment.
Since we will be using a training corpus that con-
sists solely of pairs of misspellings and words (see
section 3), we would have lower probabilities for
</bodyText>
<footnote confidence="0.703802">
1Of course, P(w) is not equal for all words, but it is not
possible to estimate it from the available training corpus, the
Atsuo-Henry Corpus (Okada, 2004), because it contains only
pairs of words and misspellings for around 1,000 target words.
</footnote>
<page confidence="0.942202">
32
</page>
<equation confidence="0.98760225">
PL(r|w) ≈ maxREPart(r),TEPart(w) � |R |P(Ri → Ti)
i=1
�PPHL(r|w) ≈ 1 max PPH (pronw  |pronr)P(pronr  |r)
pronw  |pronw  |pronr
</equation>
<figureCaption confidence="0.99961">
Figure 1: Approximations of PL from Brill and Moore (2000) and PPHL from Toutanova and Moore (2002)
</figureCaption>
<bodyText confidence="0.99973525">
α → α than would be found in a corpus with mis-
spellings observed in context with correct words. To
compensate, we approximate P(α → α) by assign-
ing it a minimum probability m:
</bodyText>
<equation confidence="0.99650625">
� m + (1 − m)count(ca→β) if α = Q
count(ca)
(1 − m)count(ca→β) if α =6 Q
count(ca)
</equation>
<subsectionHeader confidence="0.905907">
2.2.1 Extending to Pronunciation
</subsectionHeader>
<bodyText confidence="0.999989142857143">
Toutanova and Moore (2002) describe an extension
to Brill and Moore (2000) where the same noisy
channel error model is used to model phone se-
quences instead of letter sequences. Instead of the
word w and the non-word r, the error model con-
siders the pronunciation of the non-word r, pronr,
and the pronunciation of the word w, pronw. The
error model over phone sequences, called PPH, is
just like PL shown in Figure 1 except that r and w
are replaced with their pronunciations. The model is
trained like PL using alignments between phones.
Since a spelling correction model needs to rank
candidate words rather than candidate pronuncia-
tions, Toutanova and Moore (2002) derive an er-
ror model that determines the probability that a
word w was spelled as the non-word r based on
their pronunciations. Their approximation of this
model, called PPHL, is also shown in Figure 1.
PPH(pronw|pronr) is the phone error model de-
scribed above and P(pronr|r) is provided by the
letter-to-phone model described below.
</bodyText>
<subsectionHeader confidence="0.858602">
2.3 Letter-To-Phone Model
</subsectionHeader>
<bodyText confidence="0.999981695652174">
A letter-to-phone (LTP) model is needed to predict
the pronunciation of misspellings for PPHL, since
they are not found in a pronouncing dictionary. Like
Toutanova and Moore (2002), we use the n-gram
LTP model from Fisher (1999) to predict these pro-
nunciations. The n-gram LTP model predicts the
pronunciation of each letter in a word considering
up to four letters of context to the left and right. The
most specific context found for each letter and its
context in the training data is used to predict the pro-
nunciation of a word. We extended the prediction
step to consider the most probable phone for the top
M most specific contexts.
We implemented the LTP algorithm and trained
and evaluated it using pronunciations from CMU-
DICT. A training corpus was created by pairing the
words from the size 70 CMUDICT-filtered SCOWL
word list (see section 3) with their pronunciations.
This list of approximately 62,000 words was split
into a training set with 80% of entries and a test set
with the remaining 20%. We found that the best per-
formance is seen when M = 3, giving 95.5% phone
accuracy and 74.9% word accuracy.
</bodyText>
<subsectionHeader confidence="0.999491">
2.4 Calculating Final Scores
</subsectionHeader>
<bodyText confidence="0.999655090909091">
For a misspelling r and a candidate correction w,
the letter model PL gives the probability that w was
written as r due to the noisy channel taking into ac-
count only the orthography. PPH does the same for
the pronunciations of r and w, giving the probability
that pronw was output was pronr. The pronuncia-
tion model PPHL relates the pronunciations mod-
eled by PPH to the orthography in order to give the
probability that r was written as w based on pronun-
ciation. PL and PPHL are then combined as follows
to calculate a score for each candidate correction.
</bodyText>
<equation confidence="0.993176">
SCMB(r|w) = logPL(r|w) + AlogPPHL(r|w)
</equation>
<sectionHeader confidence="0.996237" genericHeader="method">
3 Resources and Data Preparation
</sectionHeader>
<bodyText confidence="0.9997036">
Our spelling correction approach, which includes
error models for both orthography and pronuncia-
tion (see section 2.2) and which considers pronun-
ciation variation for JWEFL requires a number of
resources: 1) spoken corpora of American English
(TIMIT, TIMIT 1991) and Japanese English (ERJ,
see below) are used to model pronunciation vari-
ation, 2) a pronunciation dictionary (CMUDICT,
CMUDICT 1998) provides American English pro-
nunciations for the target words, 3) a corpus of
</bodyText>
<equation confidence="0.994353">
P(α → Q) =
</equation>
<page confidence="0.98569">
33
</page>
<bodyText confidence="0.999391392857143">
spelling errors made by JWEFL (Atsuo-Henry Cor-
pus, see below) is used to train spelling error mod-
els and test the spell checker’s performance, and 4)
Spell Checker Oriented Word Lists (SCOWL, see
below) are adapted for our use.
The English Read by Japanese Corpus (Mine-
matsu et al., 2002) consists of 70,000 prompts con-
taining phonemic and prosodic cues recorded by 200
native Japanese speakers with varying English com-
petence. See Minematsu et al. (2002) for details on
the construction of the corpus.
The Atsuo-Henry Corpus (Okada, 2004) in-
cludes a corpus of spelling errors made by JWEFL
that consists of a collection of spelling errors from
multiple corpora.2 For use with our spell checker,
the corpus has been cleaned up and modified to fit
our task, resulting in 4,769 unique misspellings of
1,046 target words. The data is divided into training
(80%), development (10%), and test (10%) sets.
For our word lists, we use adapted versions of the
Spell Checker Oriented Word Lists.3 The size 50
word lists are used in order to create a general pur-
pose word list that covers all the target words from
the Atsuo-Henry Corpus. Since the target pronun-
ciation of each item is needed for the pronunciation
model, the word list was filtered to remove words
whose pronunciation is not in CMUDICT. After fil-
tering, the word list contains 54,001 words.
</bodyText>
<sectionHeader confidence="0.993177" genericHeader="method">
4 Method
</sectionHeader>
<bodyText confidence="0.999983384615385">
This section presents our method for modeling pro-
nunciation variation from a phonetically untran-
scribed corpus of read speech. The pronunciation-
based spelling correction approach developed in
Toutanova and Moore (2002) requires a list of pos-
sible pronunciations in order to compare the pro-
nunciation of the misspelling to the pronunciation
of correct words. To account for target pronuncia-
tions specific to Japanese speakers, we observe the
pronunciation variation in the ERJ and generate ad-
ditional pronunciations for each word in the word
list. Since the ERJ is not transcribed, we begin
by adapting a recognizer trained on native English
</bodyText>
<footnote confidence="0.9871356">
2Some of the spelling errors come from an elicitation task,
so the distribution of target words is not representative of typi-
cal JWEFL productions, e.g., the corpus contains 102 different
misspellings of albatross.
3SCOWL is available at http://wordlist.sourceforge.net.
</footnote>
<bodyText confidence="0.9992376">
speech. First, the ERJ is recognized using a mono-
phone recognizer trained on TIMIT. Next, the most
frequent variations between the canonical and rec-
ognized pronunciations are used to adapt the recog-
nizer. The adapted recognizer is then used to rec-
ognize the ERJ in forced alignment with the canon-
ical pronunciations. Finally, the variations from the
previous step are used to create models of pronun-
ciation variation for each phone, which are used to
generate multiple pronunciations for each word.
</bodyText>
<subsectionHeader confidence="0.993582">
4.1 Initial Recognizer
</subsectionHeader>
<bodyText confidence="0.9999955">
A monophone speech recognizer was trained on all
TIMIT data using the Hidden Markov Model Toolkit
(HTK).4 This recognizer is used to generate a phone
string for each utterance in the ERJ. Each recog-
nized phone string is then aligned with the canon-
ical pronunciation provided to the speakers. Correct
alignments and substitutions are considered with no
context and insertions are conditioned on the previ-
ous phone. Due to restrictions in HTK, deletions are
currently ignored.
The frequency of phone alignments for all utter-
ances in the ERJ are calculated. Because of the low
phone accuracy of monophone recognizers, espe-
cially on non-native speech, alignments are observed
between nearly all pairs of phones. In order to focus
on the most frequent alignments common to multi-
ple speakers and utterances, any alignment observed
less than 20% as often as the most frequent align-
ment for that canonical phone is discarded, which re-
sults in an average of three variants of each phone.5
</bodyText>
<subsectionHeader confidence="0.999569">
4.2 Adapting the Recognizer
</subsectionHeader>
<bodyText confidence="0.99978575">
Now that we have probability distributions over ob-
served phones, the HMMs trained on TIMIT are
modified as follows to allow the observed varia-
tion. To allow, for instance, variation between p
and th, the states for th from the original recog-
nizer are inserted into the model for p as a separate
path. The resulting phone model is shown in Fig-
ure 2. The transition probabilities into the first states
</bodyText>
<footnote confidence="0.962145571428571">
4HTK is available at http://htk.eng.cam.ac.uk.
5There are 119 variants of 39 phones. The cutoff of 20%
was chosen to allow a few variations for most phones. A small
number of phones have no variants (e.g., iy, w) while a few
have over nine variants (e.g., ah, l). It is not surprising that
phones that are well-known to be difficult for Japanese speakers
(cf. Minematsu et al., 2002) are the ones with the most variation.
</footnote>
<page confidence="0.996077">
34
</page>
<figureCaption confidence="0.9915745">
Figure 2: Adapted phone model for p accounting for vari-
ation between p and th
</figureCaption>
<bodyText confidence="0.9999846875">
of the phones come from the probability distribution
observed in the initial recognition step. The transi-
tion probabilities between the three states for each
variant phone remain unchanged. All HMMs are
adapted in this manner using the probability distri-
butions from the initial recognition step.
The adapted HMMs are used to recognize the ERJ
Corpus for a second time, this time in forced align-
ment with the canonical pronunciations. The state
transitions indicate which variant of each phone was
recognized and the correspondences between the
canonical phones and recognized phones are used
to generate a new probability distribution over ob-
served phones for each canonical phone. These are
used to find the most probable pronunciation varia-
tions for a native-speaker pronouncing dictionary.
</bodyText>
<subsectionHeader confidence="0.999193">
4.3 Generating Pronunciations
</subsectionHeader>
<bodyText confidence="0.999996666666667">
The observed phone variation is used to generate
multiple pronunciations for each pronunciation in
the word list. The OpenFst Library6 is used to find
the most probable pronunciations in each case. First,
FSTs are created for each phone using the proba-
bility distributions from the previous section. Next,
an FST is created for the entire word by concate-
nating the FSTs for the pronunciation from CMU-
DICT. The pronunciations corresponding to the best
n paths through the FST and the original canon-
ical pronunciation become possible pronunciations
in the extended pronouncing dictionary. The size 50
word list contains 54,001 words and when expanded
to contain the top five variations of each pronuncia-
tion, there are 255,827 unique pronunciations.
</bodyText>
<sectionHeader confidence="0.999875" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999956">
In order to evaluate the effect of pronunciation vari-
ation in Toutanova and Moore (2002)’s spelling cor-
rection approach, we compare the performance of
the pronunciation model and the combined model
</bodyText>
<footnote confidence="0.979365">
6OpenFst is available at http://www.openfst.org/.
</footnote>
<bodyText confidence="0.999715416666667">
with and without pronunciation variation.
We implemented the letter and pronunciation
spelling correction models as described in sec-
tion 2.2. The letter error model PL and the phone
error model PPH are trained on the training set.
The development set is used to tune the parameters
introduced in previous sections.7 In order to rank
the words as candidate corrections for a misspelling
r, PL(rlw) and PPHL(rlw) are calculated for each
word in the word list using the algorithm described
in Brill and Moore (2000). Finally, PL and PPHL
are combined using SCMB to rank each word.
</bodyText>
<subsectionHeader confidence="0.873945">
5.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999996444444444">
The open source spell checker GNU Aspell8 is used
to determine the baseline performance of a tradi-
tional spell checker using the same word list. An
Aspell dictionary was created with the word list de-
scribed in section 3. Aspell’s performance is shown
in Table 1. The 1-Best performance is the percent-
age of test items for which the target word was the
first candidate correction, 2-Best is the percentage
for which the target was in the top two, etc.
</bodyText>
<subsectionHeader confidence="0.99967">
5.2 Evaluation of Pronunciation Variation
</subsectionHeader>
<bodyText confidence="0.9999414">
The effect of introducing pronunciation variation us-
ing the method described in section 4 can be eval-
uated by examining the performance on the test set
for PPHL with and without the additional variations.
The results in Table 1 show that the addition of pro-
nunciation variations does indeed improve the per-
formance of PPHL across the board. The 1-Best,
3-Best, and 4-Best cases for PPHL with variation
show significant improvement (p&lt;0.05) over PPHL
without variation.
</bodyText>
<subsectionHeader confidence="0.994193">
5.3 Evaluation of the Combined Model
</subsectionHeader>
<bodyText confidence="0.999964125">
We evaluated the effect of including pronunciation
variation in the combined model by comparing the
performance of the combined model with and with-
out pronunciation variation, see results in Table 1.
Despite the improvements seen in PPHL with pro-
nunciation variation, there are no significant differ-
ences between the results for the combined model
with and without variation. The combined model
</bodyText>
<footnote confidence="0.999775666666667">
7The values are: N = 3 for the letter model, N = 4 for the
phone model, m = 80%, and A = 0.15 in SCMB.
8GNU Aspell is available at http://aspell.net.
</footnote>
<figure confidence="0.7866635">
.6
.4
th-1 th-2 th-3
p-1 p-2 p-3
</figure>
<page confidence="0.877414">
35
</page>
<table confidence="0.999763142857143">
Model 1-Best 2-Best 3-Best 4-Best 5-Best 6-Best
Aspell 44.1 54.0 64.1 68.3 70.0 72.5
Letter (L) 64.7 74.6 79.6 83.2 84.0 85.3
Pronunciation (PHL) without Pron. Var. 47.9 60.7 67.9 70.8 75.0 77.3
Pronunciation (PHL) with Pron. Var. 50.6 62.2 70.4 73.1 76.7 78.2
Combined (CMB) without Pron. Var. 64.9 75.2 78.6 81.1 82.6 83.2
Combined (CMB) with Pron. Var. 65.5 75.0 78.4 80.7 82.6 84.0
</table>
<tableCaption confidence="0.998005">
Table 1: Percentage of Correct Suggestions on the Atsuo-Henry Corpus Test Set for All Models
</tableCaption>
<table confidence="0.938257666666667">
Rank Aspell L PHL CMB
1 enemy enemy any enemy
2 envy envy Emmy envy
3 energy money Ne any
4 eye emery gunny deny
5 teeny deny ebony money
6 Ne any anything emery
7 deny nay senna nay
8 any ivy journey ivy
</table>
<tableCaption confidence="0.998765">
Table 2: Misspelling *eney, Intended Word any
</tableCaption>
<bodyText confidence="0.999883">
with variation is also not significantly different from
the letter model PL except for the drop in the 4-Best
case.
To illustrate the performance of each model, the
ranked lists in Table 2 give an example of the can-
didate corrections for the misspelling of any as
*eney. Aspell preserves the initial letter of the mis-
spelling and vowels in many of its candidates. PL’s
top candidates also overlap a great deal in orthogra-
phy, but there is more initial letter and vowel varia-
tion. As we would predict, PPHL ranks any as the
top correction, but some of the lower-ranked candi-
dates for PPHL differ greatly in length.
</bodyText>
<subsectionHeader confidence="0.994884">
5.4 Summary of Results
</subsectionHeader>
<bodyText confidence="0.999999">
The noisy channel spelling correction approach de-
veloped by Brill and Moore (2000) and Toutanova
and Moore (2002) appears well-suited for writers
of English as a foreign language. The letter and
combined models outperform the traditional spell
checker Aspell by a wide margin. Although in-
cluding pronunciation variation does not improve
the combined model, it leads to significant improve-
ments in the pronunciation-based model PPHL.
</bodyText>
<sectionHeader confidence="0.999681" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999924">
We have presented a method for modeling pronun-
ciation variation from a phonetically untranscribed
corpus of read non-native speech by adapting a
monophone recognizer initially trained on native
speech. This model allows a native pronouncing
dictionary to be extended to include non-native pro-
nunciation variations. We incorporated a pronounc-
ing dictionary extended for Japanese writers of En-
glish into the spelling correction model developed
by Toutanova and Moore (2002), which combines
orthography-based and pronunciation-based mod-
els. Although the extended pronunciation dictio-
nary does not lead to improvement in the combined
model, it does leads to significant improvement in
the pronunciation-based model.
</bodyText>
<sectionHeader confidence="0.9982" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999973333333333">
I would like to thank Eric Fosler-Lussier, the Ohio
State computational linguistics discussion group,
and anonymous reviewers for their helpful feedback.
</bodyText>
<sectionHeader confidence="0.999115" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999739222222222">
Brill, Eric and Robert C. Moore (2000). An Improved
Error Model for Noisy Channel Spelling Correction.
In Proceedings of ACL 2000.
CMUDICT (1998). CMU Pronouncing Dictionary
version 0.6. http://www.speech.cs.cmu.edu/cgi-bin/
cmudict.
Fisher, Willam (1999). A statistical text-to-phone func-
tion using ngrams and rules. In Proceedings ofICASSP
1999.
Kukich, Karen (1992). Technique for automatically cor-
recting words in text. ACM Computing Surveys 24(4).
Minematsu, N., Y. Tomiyama, K. Yoshimoto,
K. Shimizu, S. Nakagawa, M. Dantsuji, and S. Makino
(2002). English Speech Database Read by Japanese
Learners for CALL System Development. In
Proceedings of LREC 2002.
Mitton, Roger and Takeshi Okada (2007). The adapta-
tion of an English spellchecker for Japanese writers.
In Symposium on Second Language Writing.
Okada, Takeshi (2004). A Corpus Analysis of Spelling
Errors Made by Japanese EFL Writers. Yamagata En-
glish Studies 9.
TIMIT (1991). TIMIT Acoustic-Phonetic Continuous
Speech Corpus. NIST Speech Disc CD1-1.1.
Toutanova, Kristina and Robert Moore (2002). Pronunci-
ation Modeling for Improved Spelling Correction. In
Proceedings of ACL 2002.
</reference>
<page confidence="0.99894">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.860447">
<title confidence="0.9966975">Pronunciation Modeling in Spelling for Writers of English as a Foreign Language</title>
<author confidence="0.968614">Adriane</author>
<affiliation confidence="0.969691">Department of The Ohio State</affiliation>
<address confidence="0.9958365">1712 Neil Columbus, Ohio 43210,</address>
<email confidence="0.999716">adriane@ling.osu.edu</email>
<abstract confidence="0.996327705882353">We propose a method for modeling pronunciation variation in the context of spell checking for non-native writers of English. Spell checkers, typically developed for native speakers, fail to address many of the types of spelling errors peculiar to non-native speakers, especially those errors influenced by differences in phonology. Our model of pronunciation variation is used to extend a pronouncing dictionary for use in the spelling correction algorithm developed by Toutanova and Moore (2002), which includes models for both orthography and pronunciation. The pronunciation variation modeling is shown to improve performance for misspellings produced by Japanese writers of English.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert C Moore</author>
</authors>
<title>An Improved Error Model for Noisy Channel Spelling Correction.</title>
<date>2000</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="4225" citStr="Brill and Moore, 2000" startWordPosition="663" endWordPosition="666">guistics is not a possible word in the language in any context, e.g., English *thier. Once a sequence of letters has been determined to be a non-word, isolatedword error correction is the process of determining the appropriate word to substitute for the non-word. Given a sequence of letters, there are thus two main subtasks: 1) determine whether this is a nonword, 2) if so, select and rank candidate words as potential corrections to present to the writer. The first subtask can be accomplished by searching for the sequence of letters in a word list. The second subtask can be stated as follows (Brill and Moore, 2000): Given an alphabet E, a word list D of strings ∈ E*, and a string r ∈/ D and ∈ E*, find w ∈ D such that w is the most likely correction. Minimum edit distance is used to select the most likely candidate corrections. The general idea is that a minimum number of edit operations such as insertion and substitution are needed to convert the misspelling into a word. Words requiring the smallest numbers of edit operations are selected as the candidate corrections. 2.1 Edit Operations and Edit Weights In recent spelling correction approaches, edit operations have been extended beyond single character</context>
<context position="5573" citStr="Brill and Moore (2000)" startWordPosition="892" endWordPosition="895">d by Brill and Moore (2000) allows generic string edit operations up to a certain length. Each edit operation also has an associated probability that improves the ranking of candidate corrections by modeling how likely particular edits are. Brill and Moore (2000) estimate the probability of each edit from a corpus of spelling errors. Toutanova and Moore (2002) extend Brill and Moore (2000) to consider edits over both letter sequences and sequences of phones in the pronunciations of the word and misspelling. They show that including pronunciation information improves performance as compared to Brill and Moore (2000). 2.2 Noisy Channel Spelling Correction The spelling correction models from Brill and Moore (2000) and Toutanova and Moore (2002) use the noisy channel model approach to determine the types and weights of edit operations. The idea behind this approach is that a writer starts out with the intended word w in mind, but as it is being written the word passes through a noisy channel resulting in the observed non-word r. In order to determine how likely a candidate correction is, the spelling correction model determines the probability that the word w was the intended word given the misspelling r: P</context>
<context position="7201" citStr="Brill and Moore (2000)" startWordPosition="1185" endWordPosition="1188">llings. In the following experiments, P(w) is assumed be equal for all words to focus this work on estimating the error model P(r|w) for JWEFL.1 Brill and Moore (2000) allow all edit operations α → Q where E is the alphabet and α, Q ∈ E*, with a constraint on the length of α and Q. In order to consider all ways that a word w may generate r with the possibility that any, possibly empty, substring α of w becomes any, possibly empty, substring Q of r, it is necessary to consider all ways that w and r may be partitioned into substrings. This error model over letters, called PL, is approximated by Brill and Moore (2000) as shown in Figure 1 by considering only the pair of partitions of w and r with the maximum product of the probabilities of individual substitutions. Part(w) is all possible partitions of w, |R |is number of segments in a particular partition, and Ri is the ith segment of the partition. The parameters for PL(r|w) are estimated from a corpus of pairs of misspellings and target words. The method, which is described in detail in Brill and Moore (2000), involves aligning the letters in pairs of words and misspellings, expanding each alignment with up to N neighboring alignments, and calculating t</context>
<context position="8830" citStr="Brill and Moore (2000)" startWordPosition="1472" endWordPosition="1475">or around 1,000 target words. 32 PL(r|w) ≈ maxREPart(r),TEPart(w) � |R |P(Ri → Ti) i=1 �PPHL(r|w) ≈ 1 max PPH (pronw |pronr)P(pronr |r) pronw |pronw |pronr Figure 1: Approximations of PL from Brill and Moore (2000) and PPHL from Toutanova and Moore (2002) α → α than would be found in a corpus with misspellings observed in context with correct words. To compensate, we approximate P(α → α) by assigning it a minimum probability m: � m + (1 − m)count(ca→β) if α = Q count(ca) (1 − m)count(ca→β) if α =6 Q count(ca) 2.2.1 Extending to Pronunciation Toutanova and Moore (2002) describe an extension to Brill and Moore (2000) where the same noisy channel error model is used to model phone sequences instead of letter sequences. Instead of the word w and the non-word r, the error model considers the pronunciation of the non-word r, pronr, and the pronunciation of the word w, pronw. The error model over phone sequences, called PPH, is just like PL shown in Figure 1 except that r and w are replaced with their pronunciations. The model is trained like PL using alignments between phones. Since a spelling correction model needs to rank candidate words rather than candidate pronunciations, Toutanova and Moore (2002) deriv</context>
<context position="19093" citStr="Brill and Moore (2000)" startWordPosition="3161" endWordPosition="3164">rformance of the pronunciation model and the combined model 6OpenFst is available at http://www.openfst.org/. with and without pronunciation variation. We implemented the letter and pronunciation spelling correction models as described in section 2.2. The letter error model PL and the phone error model PPH are trained on the training set. The development set is used to tune the parameters introduced in previous sections.7 In order to rank the words as candidate corrections for a misspelling r, PL(rlw) and PPHL(rlw) are calculated for each word in the word list using the algorithm described in Brill and Moore (2000). Finally, PL and PPHL are combined using SCMB to rank each word. 5.1 Baseline The open source spell checker GNU Aspell8 is used to determine the baseline performance of a traditional spell checker using the same word list. An Aspell dictionary was created with the word list described in section 3. Aspell’s performance is shown in Table 1. The 1-Best performance is the percentage of test items for which the target word was the first candidate correction, 2-Best is the percentage for which the target was in the top two, etc. 5.2 Evaluation of Pronunciation Variation The effect of introducing pr</context>
<context position="22201" citStr="Brill and Moore (2000)" startWordPosition="3703" endWordPosition="3706">n the 4-Best case. To illustrate the performance of each model, the ranked lists in Table 2 give an example of the candidate corrections for the misspelling of any as *eney. Aspell preserves the initial letter of the misspelling and vowels in many of its candidates. PL’s top candidates also overlap a great deal in orthography, but there is more initial letter and vowel variation. As we would predict, PPHL ranks any as the top correction, but some of the lower-ranked candidates for PPHL differ greatly in length. 5.4 Summary of Results The noisy channel spelling correction approach developed by Brill and Moore (2000) and Toutanova and Moore (2002) appears well-suited for writers of English as a foreign language. The letter and combined models outperform the traditional spell checker Aspell by a wide margin. Although including pronunciation variation does not improve the combined model, it leads to significant improvements in the pronunciation-based model PPHL. 6 Conclusion We have presented a method for modeling pronunciation variation from a phonetically untranscribed corpus of read non-native speech by adapting a monophone recognizer initially trained on native speech. This model allows a native pronoun</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Brill, Eric and Robert C. Moore (2000). An Improved Error Model for Noisy Channel Spelling Correction. In Proceedings of ACL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CMUDICT</author>
</authors>
<title>CMU Pronouncing Dictionary version 0.6.</title>
<date>1998</date>
<note>http://www.speech.cs.cmu.edu/cgi-bin/ cmudict.</note>
<contexts>
<context position="11957" citStr="CMUDICT 1998" startWordPosition="2001" endWordPosition="2002">ty that r was written as w based on pronunciation. PL and PPHL are then combined as follows to calculate a score for each candidate correction. SCMB(r|w) = logPL(r|w) + AlogPPHL(r|w) 3 Resources and Data Preparation Our spelling correction approach, which includes error models for both orthography and pronunciation (see section 2.2) and which considers pronunciation variation for JWEFL requires a number of resources: 1) spoken corpora of American English (TIMIT, TIMIT 1991) and Japanese English (ERJ, see below) are used to model pronunciation variation, 2) a pronunciation dictionary (CMUDICT, CMUDICT 1998) provides American English pronunciations for the target words, 3) a corpus of P(α → Q) = 33 spelling errors made by JWEFL (Atsuo-Henry Corpus, see below) is used to train spelling error models and test the spell checker’s performance, and 4) Spell Checker Oriented Word Lists (SCOWL, see below) are adapted for our use. The English Read by Japanese Corpus (Minematsu et al., 2002) consists of 70,000 prompts containing phonemic and prosodic cues recorded by 200 native Japanese speakers with varying English competence. See Minematsu et al. (2002) for details on the construction of the corpus. The </context>
</contexts>
<marker>CMUDICT, 1998</marker>
<rawString>CMUDICT (1998). CMU Pronouncing Dictionary version 0.6. http://www.speech.cs.cmu.edu/cgi-bin/ cmudict.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willam Fisher</author>
</authors>
<title>A statistical text-to-phone function using ngrams and rules.</title>
<date>1999</date>
<booktitle>In Proceedings ofICASSP</booktitle>
<contexts>
<context position="10014" citStr="Fisher (1999)" startWordPosition="1671" endWordPosition="1672">tanova and Moore (2002) derive an error model that determines the probability that a word w was spelled as the non-word r based on their pronunciations. Their approximation of this model, called PPHL, is also shown in Figure 1. PPH(pronw|pronr) is the phone error model described above and P(pronr|r) is provided by the letter-to-phone model described below. 2.3 Letter-To-Phone Model A letter-to-phone (LTP) model is needed to predict the pronunciation of misspellings for PPHL, since they are not found in a pronouncing dictionary. Like Toutanova and Moore (2002), we use the n-gram LTP model from Fisher (1999) to predict these pronunciations. The n-gram LTP model predicts the pronunciation of each letter in a word considering up to four letters of context to the left and right. The most specific context found for each letter and its context in the training data is used to predict the pronunciation of a word. We extended the prediction step to consider the most probable phone for the top M most specific contexts. We implemented the LTP algorithm and trained and evaluated it using pronunciations from CMUDICT. A training corpus was created by pairing the words from the size 70 CMUDICT-filtered SCOWL w</context>
</contexts>
<marker>Fisher, 1999</marker>
<rawString>Fisher, Willam (1999). A statistical text-to-phone function using ngrams and rules. In Proceedings ofICASSP 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Technique for automatically correcting words in text.</title>
<date>1992</date>
<journal>ACM Computing Surveys</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="3191" citStr="Kukich, 1992" startWordPosition="494" endWordPosition="495">tionary and these variations are used in the spelling correction approach developed by Toutanova and Moore (2002), which uses statistical models of spelling errors that consider both orthography and pronunciation. Several conventions are used throughout this paper: a word is a sequence of characters from the given alphabet found in the word list. A word list is a list of words. A misspelling, marked with *, is a sequence of characters not found in the word list. A candidate correction is a word from the word list proposed as a potential correction. 2 Background Research in spell checking (see Kukich, 1992, for a survey of spell checking research) has focused on three main problems: non-word error detection, isolated-word error correction, and contextdependent word correction. We focus on the first two tasks. A non-word is a sequence of letters that Proceedings of the NAACL HLT Student Research Workshop and Doctoral Consortium, pages 31–36, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics is not a possible word in the language in any context, e.g., English *thier. Once a sequence of letters has been determined to be a non-word, isolatedword error correction is the </context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Kukich, Karen (1992). Technique for automatically correcting words in text. ACM Computing Surveys 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Minematsu</author>
<author>Y Tomiyama</author>
<author>K Yoshimoto</author>
<author>K Shimizu</author>
<author>S Nakagawa</author>
<author>M Dantsuji</author>
<author>S Makino</author>
</authors>
<title>English Speech Database Read by Japanese Learners for CALL System Development.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="12338" citStr="Minematsu et al., 2002" startWordPosition="2066" endWordPosition="2070">riation for JWEFL requires a number of resources: 1) spoken corpora of American English (TIMIT, TIMIT 1991) and Japanese English (ERJ, see below) are used to model pronunciation variation, 2) a pronunciation dictionary (CMUDICT, CMUDICT 1998) provides American English pronunciations for the target words, 3) a corpus of P(α → Q) = 33 spelling errors made by JWEFL (Atsuo-Henry Corpus, see below) is used to train spelling error models and test the spell checker’s performance, and 4) Spell Checker Oriented Word Lists (SCOWL, see below) are adapted for our use. The English Read by Japanese Corpus (Minematsu et al., 2002) consists of 70,000 prompts containing phonemic and prosodic cues recorded by 200 native Japanese speakers with varying English competence. See Minematsu et al. (2002) for details on the construction of the corpus. The Atsuo-Henry Corpus (Okada, 2004) includes a corpus of spelling errors made by JWEFL that consists of a collection of spelling errors from multiple corpora.2 For use with our spell checker, the corpus has been cleaned up and modified to fit our task, resulting in 4,769 unique misspellings of 1,046 target words. The data is divided into training (80%), development (10%), and test </context>
<context position="16631" citStr="Minematsu et al., 2002" startWordPosition="2773" endWordPosition="2776">r instance, variation between p and th, the states for th from the original recognizer are inserted into the model for p as a separate path. The resulting phone model is shown in Figure 2. The transition probabilities into the first states 4HTK is available at http://htk.eng.cam.ac.uk. 5There are 119 variants of 39 phones. The cutoff of 20% was chosen to allow a few variations for most phones. A small number of phones have no variants (e.g., iy, w) while a few have over nine variants (e.g., ah, l). It is not surprising that phones that are well-known to be difficult for Japanese speakers (cf. Minematsu et al., 2002) are the ones with the most variation. 34 Figure 2: Adapted phone model for p accounting for variation between p and th of the phones come from the probability distribution observed in the initial recognition step. The transition probabilities between the three states for each variant phone remain unchanged. All HMMs are adapted in this manner using the probability distributions from the initial recognition step. The adapted HMMs are used to recognize the ERJ Corpus for a second time, this time in forced alignment with the canonical pronunciations. The state transitions indicate which variant </context>
</contexts>
<marker>Minematsu, Tomiyama, Yoshimoto, Shimizu, Nakagawa, Dantsuji, Makino, 2002</marker>
<rawString>Minematsu, N., Y. Tomiyama, K. Yoshimoto, K. Shimizu, S. Nakagawa, M. Dantsuji, and S. Makino (2002). English Speech Database Read by Japanese Learners for CALL System Development. In Proceedings of LREC 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Mitton</author>
<author>Takeshi Okada</author>
</authors>
<title>The adaptation of an English spellchecker for Japanese writers. In</title>
<date>2007</date>
<booktitle>Symposium on Second Language Writing.</booktitle>
<contexts>
<context position="1695" citStr="Mitton and Okada, 2007" startWordPosition="253" endWordPosition="256">y intended word is high in the list. Since traditional spell checkers have been developed with competent native speakers as the target users, they do not appropriately address many types of errors made by nonnative writers and they often fail to suggest the appropriate corrections. Non-native writers of English struggle with many of the same idiosyncrasies of English spelling that cause difficulty for native speakers, but differences between English phonology and the phonology of their native language lead to types of spelling errors not anticipated by traditional spell checkers (Okada, 2004; Mitton and Okada, 2007). Okada (2004) and Mitton and Okada (2007) investigate spelling errors made by Japanese writers 31 of English as a foreign language (JWEFL). Okada (2004) identifies two main sources of errors for JWEFL: differences between English and Japanese phonology and differences between the English alphabet and the Japanese romazi writing system, which uses a subset of English letters. Phonological differences result in number of distinctions in English that are not present in Japanese and romazi causes difficulties for JWEFL because the Latin letters correspond to very different sounds in Japanese. We </context>
</contexts>
<marker>Mitton, Okada, 2007</marker>
<rawString>Mitton, Roger and Takeshi Okada (2007). The adaptation of an English spellchecker for Japanese writers. In Symposium on Second Language Writing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Okada</author>
</authors>
<title>A Corpus Analysis of Spelling Errors Made by Japanese EFL Writers.</title>
<date>2004</date>
<journal>Yamagata English Studies</journal>
<volume>9</volume>
<contexts>
<context position="1670" citStr="Okada, 2004" startWordPosition="251" endWordPosition="252">hat the likely intended word is high in the list. Since traditional spell checkers have been developed with competent native speakers as the target users, they do not appropriately address many types of errors made by nonnative writers and they often fail to suggest the appropriate corrections. Non-native writers of English struggle with many of the same idiosyncrasies of English spelling that cause difficulty for native speakers, but differences between English phonology and the phonology of their native language lead to types of spelling errors not anticipated by traditional spell checkers (Okada, 2004; Mitton and Okada, 2007). Okada (2004) and Mitton and Okada (2007) investigate spelling errors made by Japanese writers 31 of English as a foreign language (JWEFL). Okada (2004) identifies two main sources of errors for JWEFL: differences between English and Japanese phonology and differences between the English alphabet and the Japanese romazi writing system, which uses a subset of English letters. Phonological differences result in number of distinctions in English that are not present in Japanese and romazi causes difficulties for JWEFL because the Latin letters correspond to very differen</context>
<context position="8148" citStr="Okada, 2004" startWordPosition="1353" endWordPosition="1354">a corpus of pairs of misspellings and target words. The method, which is described in detail in Brill and Moore (2000), involves aligning the letters in pairs of words and misspellings, expanding each alignment with up to N neighboring alignments, and calculating the probability of each α → Q alignment. Since we will be using a training corpus that consists solely of pairs of misspellings and words (see section 3), we would have lower probabilities for 1Of course, P(w) is not equal for all words, but it is not possible to estimate it from the available training corpus, the Atsuo-Henry Corpus (Okada, 2004), because it contains only pairs of words and misspellings for around 1,000 target words. 32 PL(r|w) ≈ maxREPart(r),TEPart(w) � |R |P(Ri → Ti) i=1 �PPHL(r|w) ≈ 1 max PPH (pronw |pronr)P(pronr |r) pronw |pronw |pronr Figure 1: Approximations of PL from Brill and Moore (2000) and PPHL from Toutanova and Moore (2002) α → α than would be found in a corpus with misspellings observed in context with correct words. To compensate, we approximate P(α → α) by assigning it a minimum probability m: � m + (1 − m)count(ca→β) if α = Q count(ca) (1 − m)count(ca→β) if α =6 Q count(ca) 2.2.1 Extending to Pronun</context>
<context position="12589" citStr="Okada, 2004" startWordPosition="2108" endWordPosition="2109">nglish pronunciations for the target words, 3) a corpus of P(α → Q) = 33 spelling errors made by JWEFL (Atsuo-Henry Corpus, see below) is used to train spelling error models and test the spell checker’s performance, and 4) Spell Checker Oriented Word Lists (SCOWL, see below) are adapted for our use. The English Read by Japanese Corpus (Minematsu et al., 2002) consists of 70,000 prompts containing phonemic and prosodic cues recorded by 200 native Japanese speakers with varying English competence. See Minematsu et al. (2002) for details on the construction of the corpus. The Atsuo-Henry Corpus (Okada, 2004) includes a corpus of spelling errors made by JWEFL that consists of a collection of spelling errors from multiple corpora.2 For use with our spell checker, the corpus has been cleaned up and modified to fit our task, resulting in 4,769 unique misspellings of 1,046 target words. The data is divided into training (80%), development (10%), and test (10%) sets. For our word lists, we use adapted versions of the Spell Checker Oriented Word Lists.3 The size 50 word lists are used in order to create a general purpose word list that covers all the target words from the Atsuo-Henry Corpus. Since the t</context>
</contexts>
<marker>Okada, 2004</marker>
<rawString>Okada, Takeshi (2004). A Corpus Analysis of Spelling Errors Made by Japanese EFL Writers. Yamagata English Studies 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TIMIT</author>
</authors>
<title>TIMIT Acoustic-Phonetic Continuous Speech Corpus.</title>
<date>1991</date>
<journal>NIST Speech Disc</journal>
<pages>1--1</pages>
<contexts>
<context position="11822" citStr="TIMIT 1991" startWordPosition="1981" endWordPosition="1982">t was pronr. The pronunciation model PPHL relates the pronunciations modeled by PPH to the orthography in order to give the probability that r was written as w based on pronunciation. PL and PPHL are then combined as follows to calculate a score for each candidate correction. SCMB(r|w) = logPL(r|w) + AlogPPHL(r|w) 3 Resources and Data Preparation Our spelling correction approach, which includes error models for both orthography and pronunciation (see section 2.2) and which considers pronunciation variation for JWEFL requires a number of resources: 1) spoken corpora of American English (TIMIT, TIMIT 1991) and Japanese English (ERJ, see below) are used to model pronunciation variation, 2) a pronunciation dictionary (CMUDICT, CMUDICT 1998) provides American English pronunciations for the target words, 3) a corpus of P(α → Q) = 33 spelling errors made by JWEFL (Atsuo-Henry Corpus, see below) is used to train spelling error models and test the spell checker’s performance, and 4) Spell Checker Oriented Word Lists (SCOWL, see below) are adapted for our use. The English Read by Japanese Corpus (Minematsu et al., 2002) consists of 70,000 prompts containing phonemic and prosodic cues recorded by 200 na</context>
</contexts>
<marker>TIMIT, 1991</marker>
<rawString>TIMIT (1991). TIMIT Acoustic-Phonetic Continuous Speech Corpus. NIST Speech Disc CD1-1.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Robert Moore</author>
</authors>
<title>Pronunciation Modeling for Improved Spelling Correction.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="725" citStr="Toutanova and Moore (2002)" startWordPosition="104" endWordPosition="107">Boyd Department of Linguistics The Ohio State University 1712 Neil Avenue Columbus, Ohio 43210, USA adriane@ling.osu.edu Abstract We propose a method for modeling pronunciation variation in the context of spell checking for non-native writers of English. Spell checkers, typically developed for native speakers, fail to address many of the types of spelling errors peculiar to non-native speakers, especially those errors influenced by differences in phonology. Our model of pronunciation variation is used to extend a pronouncing dictionary for use in the spelling correction algorithm developed by Toutanova and Moore (2002), which includes models for both orthography and pronunciation. The pronunciation variation modeling is shown to improve performance for misspellings produced by Japanese writers of English. 1 Introduction Spell checkers identify misspellings, select appropriate words as suggested corrections, and rank the suggested corrections so that the likely intended word is high in the list. Since traditional spell checkers have been developed with competent native speakers as the target users, they do not appropriately address many types of errors made by nonnative writers and they often fail to suggest</context>
<context position="2692" citStr="Toutanova and Moore (2002)" startWordPosition="406" endWordPosition="409">etters. Phonological differences result in number of distinctions in English that are not present in Japanese and romazi causes difficulties for JWEFL because the Latin letters correspond to very different sounds in Japanese. We propose a method for creating a model of pronunciation variation from a phonetically untranscribed corpus of read speech recorded by nonnative speakers. The pronunciation variation model is used to generate multiple pronunciations for each canonical pronunciation in a pronouncing dictionary and these variations are used in the spelling correction approach developed by Toutanova and Moore (2002), which uses statistical models of spelling errors that consider both orthography and pronunciation. Several conventions are used throughout this paper: a word is a sequence of characters from the given alphabet found in the word list. A word list is a list of words. A misspelling, marked with *, is a sequence of characters not found in the word list. A candidate correction is a word from the word list proposed as a potential correction. 2 Background Research in spell checking (see Kukich, 1992, for a survey of spell checking research) has focused on three main problems: non-word error detecti</context>
<context position="5313" citStr="Toutanova and Moore (2002)" startWordPosition="850" endWordPosition="853"> 2.1 Edit Operations and Edit Weights In recent spelling correction approaches, edit operations have been extended beyond single character edits and the methods for calculating edit operation weights have become more sophisticated. The spelling error model proposed by Brill and Moore (2000) allows generic string edit operations up to a certain length. Each edit operation also has an associated probability that improves the ranking of candidate corrections by modeling how likely particular edits are. Brill and Moore (2000) estimate the probability of each edit from a corpus of spelling errors. Toutanova and Moore (2002) extend Brill and Moore (2000) to consider edits over both letter sequences and sequences of phones in the pronunciations of the word and misspelling. They show that including pronunciation information improves performance as compared to Brill and Moore (2000). 2.2 Noisy Channel Spelling Correction The spelling correction models from Brill and Moore (2000) and Toutanova and Moore (2002) use the noisy channel model approach to determine the types and weights of edit operations. The idea behind this approach is that a writer starts out with the intended word w in mind, but as it is being written</context>
<context position="8463" citStr="Toutanova and Moore (2002)" startWordPosition="1403" endWordPosition="1406">nt. Since we will be using a training corpus that consists solely of pairs of misspellings and words (see section 3), we would have lower probabilities for 1Of course, P(w) is not equal for all words, but it is not possible to estimate it from the available training corpus, the Atsuo-Henry Corpus (Okada, 2004), because it contains only pairs of words and misspellings for around 1,000 target words. 32 PL(r|w) ≈ maxREPart(r),TEPart(w) � |R |P(Ri → Ti) i=1 �PPHL(r|w) ≈ 1 max PPH (pronw |pronr)P(pronr |r) pronw |pronw |pronr Figure 1: Approximations of PL from Brill and Moore (2000) and PPHL from Toutanova and Moore (2002) α → α than would be found in a corpus with misspellings observed in context with correct words. To compensate, we approximate P(α → α) by assigning it a minimum probability m: � m + (1 − m)count(ca→β) if α = Q count(ca) (1 − m)count(ca→β) if α =6 Q count(ca) 2.2.1 Extending to Pronunciation Toutanova and Moore (2002) describe an extension to Brill and Moore (2000) where the same noisy channel error model is used to model phone sequences instead of letter sequences. Instead of the word w and the non-word r, the error model considers the pronunciation of the non-word r, pronr, and the pronuncia</context>
<context position="9966" citStr="Toutanova and Moore (2002)" startWordPosition="1660" endWordPosition="1663">ank candidate words rather than candidate pronunciations, Toutanova and Moore (2002) derive an error model that determines the probability that a word w was spelled as the non-word r based on their pronunciations. Their approximation of this model, called PPHL, is also shown in Figure 1. PPH(pronw|pronr) is the phone error model described above and P(pronr|r) is provided by the letter-to-phone model described below. 2.3 Letter-To-Phone Model A letter-to-phone (LTP) model is needed to predict the pronunciation of misspellings for PPHL, since they are not found in a pronouncing dictionary. Like Toutanova and Moore (2002), we use the n-gram LTP model from Fisher (1999) to predict these pronunciations. The n-gram LTP model predicts the pronunciation of each letter in a word considering up to four letters of context to the left and right. The most specific context found for each letter and its context in the training data is used to predict the pronunciation of a word. We extended the prediction step to consider the most probable phone for the top M most specific contexts. We implemented the LTP algorithm and trained and evaluated it using pronunciations from CMUDICT. A training corpus was created by pairing the</context>
<context position="13624" citStr="Toutanova and Moore (2002)" startWordPosition="2279" endWordPosition="2282">he Spell Checker Oriented Word Lists.3 The size 50 word lists are used in order to create a general purpose word list that covers all the target words from the Atsuo-Henry Corpus. Since the target pronunciation of each item is needed for the pronunciation model, the word list was filtered to remove words whose pronunciation is not in CMUDICT. After filtering, the word list contains 54,001 words. 4 Method This section presents our method for modeling pronunciation variation from a phonetically untranscribed corpus of read speech. The pronunciationbased spelling correction approach developed in Toutanova and Moore (2002) requires a list of possible pronunciations in order to compare the pronunciation of the misspelling to the pronunciation of correct words. To account for target pronunciations specific to Japanese speakers, we observe the pronunciation variation in the ERJ and generate additional pronunciations for each word in the word list. Since the ERJ is not transcribed, we begin by adapting a recognizer trained on native English 2Some of the spelling errors come from an elicitation task, so the distribution of target words is not representative of typical JWEFL productions, e.g., the corpus contains 102</context>
<context position="18421" citStr="Toutanova and Moore (2002)" startWordPosition="3056" endWordPosition="3059">d for each phone using the probability distributions from the previous section. Next, an FST is created for the entire word by concatenating the FSTs for the pronunciation from CMUDICT. The pronunciations corresponding to the best n paths through the FST and the original canonical pronunciation become possible pronunciations in the extended pronouncing dictionary. The size 50 word list contains 54,001 words and when expanded to contain the top five variations of each pronunciation, there are 255,827 unique pronunciations. 5 Results In order to evaluate the effect of pronunciation variation in Toutanova and Moore (2002)’s spelling correction approach, we compare the performance of the pronunciation model and the combined model 6OpenFst is available at http://www.openfst.org/. with and without pronunciation variation. We implemented the letter and pronunciation spelling correction models as described in section 2.2. The letter error model PL and the phone error model PPH are trained on the training set. The development set is used to tune the parameters introduced in previous sections.7 In order to rank the words as candidate corrections for a misspelling r, PL(rlw) and PPHL(rlw) are calculated for each word </context>
<context position="22232" citStr="Toutanova and Moore (2002)" startWordPosition="3708" endWordPosition="3711">trate the performance of each model, the ranked lists in Table 2 give an example of the candidate corrections for the misspelling of any as *eney. Aspell preserves the initial letter of the misspelling and vowels in many of its candidates. PL’s top candidates also overlap a great deal in orthography, but there is more initial letter and vowel variation. As we would predict, PPHL ranks any as the top correction, but some of the lower-ranked candidates for PPHL differ greatly in length. 5.4 Summary of Results The noisy channel spelling correction approach developed by Brill and Moore (2000) and Toutanova and Moore (2002) appears well-suited for writers of English as a foreign language. The letter and combined models outperform the traditional spell checker Aspell by a wide margin. Although including pronunciation variation does not improve the combined model, it leads to significant improvements in the pronunciation-based model PPHL. 6 Conclusion We have presented a method for modeling pronunciation variation from a phonetically untranscribed corpus of read non-native speech by adapting a monophone recognizer initially trained on native speech. This model allows a native pronouncing dictionary to be extended </context>
</contexts>
<marker>Toutanova, Moore, 2002</marker>
<rawString>Toutanova, Kristina and Robert Moore (2002). Pronunciation Modeling for Improved Spelling Correction. In Proceedings of ACL 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>