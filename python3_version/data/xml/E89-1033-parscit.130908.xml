<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.961686">
Interactive Incremental Chart Parsing
</title>
<author confidence="0.76828">
Mats Wiren
</author>
<affiliation confidence="0.72856">
Department of Computer and Information Science
LinkOping University
</affiliation>
<address confidence="0.798581">
S-581 83 LinkOping, Sweden
</address>
<email confidence="0.996016">
mgw@ida.liu.se
</email>
<sectionHeader confidence="0.993778" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99991875">
This paper presents an algorithm for incremental
chart parsing, outlines how this could be embed-
ded in an interactive parsing system, and discusses
why this might be useful. Incremental parsing here
means that input is analysed in a piecemeal fash-
ion, in particular allowing arbitrary changes of previ-
ous input without exhaustive reanalysis. Interactive
parsing means that the analysis process is prompted
immediately at the onset of new input, and possibly
that the system then may interact with the user in
order to resolve problems that occur. The combina-
tion of these techniques could be used as a parsing
kernel for highly interactive and &amp;quot;reactive&amp;quot; natural-
language processors, such as parsers for dialogue
systems, interactive computer-aided translation sys-
tems, and language-sensitive text editors. An incre-
mental chart parser embodying the ideas put for-
ward in this paper has been implemented, and an
embedding of this in an interactive parsing system
is near completion.
</bodyText>
<sectionHeader confidence="0.954072" genericHeader="keywords">
1 Background
and Introduction
</sectionHeader>
<subsectionHeader confidence="0.999324">
1.1 The Problem
</subsectionHeader>
<bodyText confidence="0.998618">
Ideally, a parser for an interactive natural-language
system ought to analyse input in real time in such a
way that the system produces an analysis of the in-
put while this is being received. One aspect of this
is that the system should be able to &amp;quot;keep up&amp;quot; with
This research has been supported by the National Swedish
Board for Technical Development. The system is imple-
mented on machines donated by the Xerox Corporation
through their University Grants Program.
I would like to thank several people for fruitful discussions
on the topics of this paper, in particular Lars Ahrenberg (also
for commenting on drafts), Bernt Nilsson, and Peter Fritzson;
furthermore Nils Dahlblick, Arne Jiinsson, Magnus Merkel,
Henry Thompson, and an anonymous referee. In addition, I
would like to thank Ulf Dahlen, Asa Detterfelt, Mikael Karla-
son, Per Larses, Jukka Nylund, and Michael Spicar for imple-
menting (the interactive portion of) LIPS.
new input that, piece by piece, is entered from left
to right. Another aspect is that it ought to be able
to keep up also with piecemeal changes of previous
input. For example, in changing one word in the be-
ginning of some utterance(s), one would not want
all the input (either from the beginning or from the
change point) to be completely reanalysed. From
the perspective of efficiency as well as of modelling
intelligent behaviour, the amount of processing re-
quired to analyse an update ought to be somehow
correlated with the difficulty of this update. Thus,
a necessary (but not sufficient) condition for realiz-
ing a real-time parsing system as suggested above is
an interactive and incremental parsing system. The
goal of this paper is to develop a basic machinery
for incremental chart parsing and to outline how this
could be embedded in an interactive parsing system.
</bodyText>
<subsectionHeader confidence="0.892859">
1.2 Incremental Parsing
</subsectionHeader>
<bodyText confidence="0.989275631578947">
The word &amp;quot;incremental&amp;quot; has been used in two dif-
fering senses in the (passing) literature. The first
sense stresses that input should be analysed in a
piecemeal fashion, for example Bobrow and Webber
(1980), Mellish (1985), Pulman (1985, 1987), Hirst
(1987), Haddock (1987). According to this view, an
incremental parser constructs the analysis of an ut-
terance bit by bit (typically from left to right), rather
than in one go when it has come to an end.
The other sense of &amp;quot;incremental&amp;quot; stresses the
necessity of efficiently handling arbitrary changes
within current input. Thus, according to this view,
an incremental parser should be able to efficiently
handle not only piecemeal additions to a sentence,
but, more generally, arbitrary insertions and dele-
tions in it. This view of incremental parsing is typi-
cal of research on interactive programming environ-
ments, e.g. Lindstrom (1970), Earley and Caizergues
(1972), Ghezzi and Mandrioli (1979, 1980), Reps and
Teitelbaum (1987).
As indicated above, we are here interested in the
latter view, which we summarize in the following
working definition.
- 241 -
Incremental parser. A parser capable of handling
changes of previous input while expending an
amount of effort which is proportional to the
complexity of the changes.&apos;
It should be pointed out that we are here limit-
ing ourselves to a machinery for incremental parsing
as opposed to incremental interpretation. In other
words, the derivation of an utterance here takes
into account only &amp;quot;context-free&amp;quot; (lexical, syntactic,
compositional-semantic) information obtained from
grammar and dictionary. Nevertheless, I believe that
this framework may be of some value also when ap-
proaching the more difficult problem of incremental
interpretation.
</bodyText>
<subsectionHeader confidence="0.957686">
1.3 Interactive Parsing
</subsectionHeader>
<bodyText confidence="0.9967651">
We adopt the following working definition.
Interactive parser. (Synonym: on-line parser.) A
parser which monitors a text-input process,
starting to parse immediately at the onset of
new input, thereby achieving enhanced effi-
ciency as well as a potential for dynamic im-
provement of its performance, for example by
promptly reporting errors, asking for clarifica-
tions, etc.2
Within the area of programming environments,
(generators for) language-based editors have been
developed that make use of interactive (and incre-
mental) parsing and compilation to perform pro-
gram analysis, to report errors, and to generate code
while the program is being edited, for example Men-
tor, Gandalf, and the Synthesizer Generator (Reps
and Teitelbaum 1987).
Within natural-language processing, Tomita (1985)
and Yonezawa and Ohsawa (1988) have reported
parsers which operate on-line, but, incidentally, not
incrementally in the sense adopted here.3
1This definition is formed partly in analogy with a defini-
tion of &amp;quot;incremental compilation&amp;quot; by Earley and Caizergues
(1972:1040). We use &amp;quot;complexity&amp;quot; instead of &amp;quot;size&amp;quot; because
different updates of the same size may cause differing process-
ing efforts depending on the degree of grammatical complexity
(ambiguity, context-sensitiveness) constraining the updates in
question.
2Incidentally, interactive parsing could be seen as one ex-
ample of a general trend towards immediate computation (Reps
and Teitelbaum 1987:31), also manifest in applications such
as WYSIWYG word processing and spreadsheet programs,
and sparked off by the availability of personal workstations
with dedicated processors.
3The user may delete input from right to left, causing the
systems to &amp;quot;unparse&amp;quot; this input. This means that if the user
wants to update some small fragment in the beginning of a
sentence, the system has to reparse exhaustively from this
update and on. (Of course, in reality the user has to first
backspace and then retype everything from the change.)
</bodyText>
<subsectionHeader confidence="0.997359">
1.4 Outline of Paper
</subsectionHeader>
<bodyText confidence="0.999852666666667">
Section 2 presents an algorithm for incremental char
parsing. Section 3 discusses some additional aspect
and alternative strategies. Section 4 gives a brie
outline of the combined interactive and incrementa
parsing system, and section 5 summarizes the con
clusions.
</bodyText>
<sectionHeader confidence="0.991898" genericHeader="method">
2 Incremental Chart Parsing
</sectionHeader>
<subsectionHeader confidence="0.992307">
2.1 Chart Parsing
</subsectionHeader>
<bodyText confidence="0.99042825">
The incremental parser has been grounded in
chart-parsing framework (Kay 1980, Thompso
1981, Thompson and Ritchie 1984) for the follow
ing reasons:
</bodyText>
<listItem confidence="0.995496833333333">
• chart parsing is an efficient, open-ended, we
understood, and frequently adopted techniqu
in natural-language processing;
• chart parsing gives us a previously unexplorei
possibility of embedding incrementality at a loi
cost.
</listItem>
<subsectionHeader confidence="0.999215">
2.2 Edge Dependencies
</subsectionHeader>
<bodyText confidence="0.999781045454546">
The idea of incremental chart parsing, as put foi
ward here, is based on the following observatior
The chart, while constituting a record of partia
analyses (chart edges), may easily be provided wit
information also about the dependencies betwee
those analyses. This is just what we need in in
cremental parsing since we want to propagate th
effects of a change precisely to those parts of th
previous analysis that, directly or indirectly, depen
on the updated information.
In what ways could chart edges be said to depen
on each other? Put simply, an edge depends upo
another edge if it is formed using the latter &amp;Iv
Thus, an edge formed through a prediction step d(
pends on the (one) edge that triggered it.4 Likewis(
an edge formed through a combination3 depends o
the active—inactive edge pair that generated it.
scanned edge, on the other hand, does not depen
upon any other edge, as scanning can be seen as
kind of initialization of the chart.6
In order to account for edge dependencies we assc
ciate with each edge the set of its immediate sourc
</bodyText>
<footnote confidence="0.913682">
4In the case of an initial top-down prediction, the sour&lt;
would be non-existent.
6The completer operation in Earley (1970); the fundament
rule in Thompson (1981:2).
6It might be argued that a dependency should be estal
lished also in the case of an edge being proposed but rejecte
(owing to a redundancy test) because it already exists. Hoy
ever, as long as updates affect all preterminal edges extendir
from a vertex, this appears not to be crucial.
- 242 -
</footnote>
<bodyText confidence="0.999961541666667">
edges (&amp;quot;back pointers&amp;quot;). This information could be
used to derive the corresponding sets of dependent
edges (&amp;quot;forward pointers&amp;quot;) that we are interested in.
For example, when a word in the previous input has
been deleted, we want to remove all edges which
depend on the preterminal (lexical) edge(s) corre-
sponding to this word, as well as those preterminal
edges themselves.
Formally, let D be a binary dependency relation
such that e D e&apos; if and only if e&apos; is a dependant of
e, i.e., e&apos; has been formed (directly) using e. If D*
is the reflexive transitive closure of P, all edges e&amp;quot;
should be removed for which e D* e&amp;quot; holds, i.e., all
edges which directly or indirectly depend on e, as
well as e itself. In addition, we are going to make
use of the transitive closure of D, D+.
The resulting style of incremental parsing resem-
bles truth (or reason) maintenance, in particular
ATMS (de Kleer 1986). A chart edge here corre-
sponds to an ATMS node, a preterminal edge corre-
sponds to an assumption node, the immediate source
information of an edge corresponds to a justifica-
tion, the dependency relation D* provides informa-
tion corresponding to ATMS labels, etc.
</bodyText>
<subsectionHeader confidence="0.811594">
2.3 Technical Preliminaries
2.3.1 The Chart
</subsectionHeader>
<bodyText confidence="0.992297926829269">
The chart is a directed graph. The nodes, or ver-
tices, v1, ..., vn+1 correspond to the positions sur-
rounding the words of an n-word sentence w1• • wn.
A pair of vertices vt, vi may be connected by arcs,
or edges, bearing information about (partially) anal-
ysed constituents between vi and v1. We will take
an edge to be a tuple
(s, t, X0 —■ D,
starting from vertex v, and ending at vertex vt with
dotted rule X0 —■ a./3,7 a dag D (cf. section 2.3.3),
and the set of immediately dependent edges, E.8
In order to lay the ground for easy splitting and
joining of chart fragments, we will take a vertex to
consist of three parts, (L, Aloop, R), left, middle, and
right. L and R will have internal structure, so that
the full vertex structure will come out like
((Ain, /in), Aioop, (Aout,
The left part, (A1„,h,i), consists of the incoming
active and inactive edges which will remain with
the left portion of the chart when it is split due
TA dotted rule X0 —+ a./3 corresponds to an (active) Xo
edge containing an analysis of constituent (s) a, requiring con-
stituent(s) # in order to yield an inactive edge.
°In other words, the set E of an edge e consists of all edges
ei for which e P ei holds.
to some internal sentence-editing operation. Cor-
respondingly, the right part, (A„.„t, /out), consists of
the outgoing active and inactive edges which will
remain with the right portion of the chart. The
middle part, Ak,op, consists of the active looping
edges which, depending on the rule-invocation strat-
egy, should remain either with the left or the right
portion of the chart (cf. section 3.1).
We will make use of dots for qualifying within el-
ements of tuples. For example, e.s will stand for the
starting vertex of edge e. Likewise, vi.L will stand
for the set of edges belonging to the left half of vertex
number 1, and vi.Ai„ will denote the set of its active
incoming edges. In addition, we will use vi./30.1 as
a shorthand for the set of inactive outgoing edges at
vt which are also preterminal (lexical).
</bodyText>
<subsectionHeader confidence="0.780651">
2.3.2 Editing Operations
</subsectionHeader>
<bodyText confidence="0.993584625">
In general, parsing could be seen as a mapping from
a sentence to a structure representing the analysis
of the sentence — in this case a chart. Incremental
parsing requires a more complex mapping
F(n,
IC, r, co) c1
from an edit operation Th a pair of cursor positions lc,
a sequence of words r (empty in the case of deletion),
and an initial chart co to a new chart c1 (and using
a grammar and dictionary as usual).
We are going to assume three kinds of editing op-
eration, insert, delete, and replace. Furthermore, we
assume that every operation applies to a continuous
sequence of words wt • • • w,., each of which maps to
one or several preterminal edges extending from ver-
tices , vr, respectively.9
Thus, n may here take the values insert, delete,
or replace; ic is a pair of positions 1, r such that the
sequence of positions 1, , r map directly to ver-
tices , vr, and r is the corresponding sequence
of words tut • • • wr.
In addition, we will make use of the constant 6 =
r — 1+ 1, denoting the number of words affected by
the editing operation.
</bodyText>
<subsectionHeader confidence="0.85415">
2.3.3 Grammatical Formalism
</subsectionHeader>
<bodyText confidence="0.94663375">
In the algorithm below, as well as in the actual im-
plementation, we have adopted a unification-based
grammatical formalism with a context-free base,
PATR (Shieber et al. 1983, Shieber 1986), because
this seems to be the best candidate for a lingua
franca in current natural-language processing. How-
ever, this formalism here shows up only within the
edges, where we have an extra dag element (D), and
when referring to rules, each of which consists of a
°Character editing is processed by the scanner; cf. section
3.3.
- 243 -
pair (X0 —■ D) of a production and a dag. In
the dag representation of the rule, we will store the
context-free base under cat features as usual. We
assume that the grammar is cycle-free.
</bodyText>
<subsectionHeader confidence="0.64941">
2.4 An Algorithm
for Incremental Chart Parsing
2.4.1 Introduction
</subsectionHeader>
<bodyText confidence="0.998409666666667">
This section states an algorithm for incremental
chart parsing, divided into update routines, subrou-
tines, and an underlying chart parser. It handles
update of the chart according to one edit operation;
hence, it should be repeated for each such opera-
tion. The underlying chart parser specified in the
end of section 2.4.2 makes use of a bottom-up rule-
invocation strategy. Top-down rule invocation will
be discussed in section 3.1.
</bodyText>
<subsubsectionHeader confidence="0.787142">
2.4.2 Incremental Chart-Parsing Algorithm
</subsubsectionHeader>
<bodyText confidence="0.830548">
Input: An edit operation n, a pair of vertex num-
bers 1, r, a sequence of words wi • • wr, and a chart
co. We assume that chart co consists of vertices
• • • , vtain, where last &gt; 1. We furthermore as-
sume the constant 6 = r — 1+1 to be available.
</bodyText>
<sectionHeader confidence="0.675031" genericHeader="method">
Output: A chart
</sectionHeader>
<bodyText confidence="0.9126778">
Method: On the basis of the input, select and exe-
cute the appropriate update routine below.
Update Routines
Insertl: Insertion at right end of co
for i := I, r do Scan(wi);
</bodyText>
<equation confidence="0.865604">
last := last + 6;
RunChart.
</equation>
<bodyText confidence="0.89722025">
This case occurs when 6 words WI • • • tar have
been inserted at the right end of previous input
(i.e., 1 = last). This is the special case corre-
sponding to ordinary left-to-right chart parsing,
causing the original chart co to be extended 6
steps to the right.
Deletel: Deletion at right end of co
for := 1, r do
</bodyText>
<equation confidence="0.9943295">
Ye: e E vi.Pout RemoveEdgesInD*(e);
last := last — 6.
</equation>
<bodyText confidence="0.960636125">
This case occurs when 6 words WI • • • tvr have
been deleted up to and including the right end
of previous input (i.e., r = last — 1). It is han-
dled by removing the preterminal edges corre-
sponding to the deleted words along with all
their dependent edges.
Delete2: Deletion before right end of co
for i:= I,..,r do
</bodyText>
<equation confidence="0.943369">
Ye: e E vi.Potd RemoveEdgesInD*(e);
MoveVertex/RightHalf(r + 1,1,-6);
for i := / + 1 to last — 6 do
MoveVertex(i + 6,i,-6);
last := last — 6;
RunChart.
</equation>
<bodyText confidence="0.944255666666667">
This case occurs when 6 words tut • • • w,. have
been deleted in an interval within or at the left
end of previous input (i.e., r &lt; last — 1). It
is handled by removing the preterminal edges
corresponding to the deleted words along with
all their dependent edges, and then collapsing
the chart, moving all edges from vertex v,..4.1
and on 6 steps to the left.
In.sert2: Insertion before right end of co
</bodyText>
<equation confidence="0.549748714285714">
RemoveCrossingEdges(1);
for i := last downto 1+ 1 do
MoveVertex (i, i + 5,6);
MoveVertex/RightHalf(/, r + 1,6);
for i := I, r do Scan(wi);
last := last + 6;
RunChart.
</equation>
<bodyText confidence="0.959346692307692">
This case occurs when 6 words wt • • wr have
been inserted at a position within or at the left
end of previous input (i.e., I &lt; last). It is han-
dled by first removing all edges that &amp;quot;cross&amp;quot; ver-
tex vi (the vertex at which the new insertion is
about to start). Secondly, the chart is split at
vertex t)1 by moving all edges extending from
this vertex or some vertex to the right of it 6
steps to the right. Finally, the new input is
scanned and the resulting edges inserted into
the chart.
Replace: Replacement within co
for i:= I, , r do
</bodyText>
<equation confidence="0.82209">
Ye: e E vi.Pout RemoveEdgesInD*(e);
</equation>
<bodyText confidence="0.933445142857143">
for := 1, , r do Scan(wi);
RunChart.
This case occurs when 6 words wi • • w,. have
been replaced by 6 other words at the corre-
sponding positions within previous input (i.e.,
1 &lt; I and r &lt; last; typically I = r). It is handled
by first removing the preterminal edges corre-
sponding to the replaced words along with all
their dependent edges, and then scan the new
words and insert the resulting edges into the
chart.
Alternatively, we could of course realize replace
through delete and insert, but having a dedi-
cated replace operation is more efficient.
</bodyText>
<note confidence="0.42656275">
- 244 -
Subroutines
RemoveEdgesInD*(e):
Ye&apos;: e D* e&apos; remove e1.
</note>
<bodyText confidence="0.915271">
This routine removes all edges that are in the re-
flexive transitive dependency closure of a given
edge
</bodyText>
<equation confidence="0.997016166666667">
MoveVertex(from, to, 8):
vto := &apos;,from;
Vfrom := 0;
Ye: e E vto.Atoop U vto.R
e.s := e.s + 8;
e.t := e.t + S.
</equation>
<bodyText confidence="0.999925666666667">
This routine moves the contents of a vertex from
vimm to vto and assigns new connectivity infor-
mation to the affected (outgoing) edges.
</bodyText>
<equation confidence="0.998334625">
MoveVertex/RightHalf(from, to, 5):
vto.R := virom.R;
Vto•Aloop Vfrom •Aloop;
vfrom.R := 0;
vfrom.Aloop := 0;
Ye: e E vto.Atoop U vto.R
e.a := e.s + 8;
e.t := e.t + 5.
</equation>
<bodyText confidence="0.99994275">
This routine moves the contents of the right half
(including active looping edges) of a vertex from
vi„, to vto and assigns new connectivity infor-
mation to the affected (outgoing) edges.
</bodyText>
<equation confidence="0.839119">
RemoveCrossingEdges(e):
VeV f V g:
f E
g E vi.Post
e E {f D+ e} n {gD+ el
remove e.
</equation>
<bodyText confidence="0.9901515">
The purpose of this routine, which is called from
Insert2, is to remove all edges that &amp;quot;cross&amp;quot; ver-
tex vt where the new insertion is about to start.
This can be done in different ways. The solu-
tion above makes use of dependency informa-
tion, removing every edge which is a dependant
of both some preterminal edge incident to the
change vertex and some preterminal edge ex-
tending from it.11 Alternatively, one could sim-
ply remove every edge e whose left connection
&lt;16.8 and whose right connection e.t &gt; 1.
wIt may sometimes be the case that not all edges in the
dependency closure need to be removed because, in the course
of updating, some edge receives the same value as previously.
This happens for example if a word is replaced by itself, or,
given a grammar with atomic categories, if (say) a noun is
replaced by another noun. One could reformulate the routines
in such a way that they check for this before removing an edge.
&amp;quot;For simplicity, we presuppose that preterminal edges only
extend between adjacent vertices.
</bodyText>
<subsectionHeader confidence="0.8367535">
Chart Parser
Scan(wi):
</subsectionHeader>
<bodyText confidence="0.997489166666667">
If wi = a, then, for all lexical entries of the
form (X0 —+ a, D), add the edge (i, I + 1, Xo --+
a.,D,0).
Informally, this means adding an inactive,
preterminal edge for each word sense of the
word.
</bodyText>
<sectionHeader confidence="0.797059" genericHeader="method">
RunChart:
</sectionHeader>
<bodyText confidence="0.9984085">
For each vertex v, do the following two steps
until no more edges can be added to the chart.
</bodyText>
<listItem confidence="0.531787">
1. Predict/BottomUp: For each edge e
</listItem>
<bodyText confidence="0.9986776">
starting at vi of the form (i, j, X0 a., D,
E) and each rule of the form (Yo
D&apos;) such that D&apos;((YI. cat)) = D((X() cat)),
add an edge of the form (i,i, Yo
D&apos;, {e}) if this edge is not subsumed12 by
another edge.
Informally, this means predicting an edge
according to each rule whose first right-
hand-side category matches the category
of the inactive edge under consideration.
</bodyText>
<listItem confidence="0.826066">
2. Combine: For each edge e of the form
(1, j, Xo E) and each edge e&apos;
of the form (j, k, Yo ry., D&apos;, E&apos;), add the
</listItem>
<bodyText confidence="0.986727">
edge (i, k, X0 D u[X„,: D&apos;(Y0)],
{e, el) if the unification succeeds and this
edge is not subsumed by another edge.
Informally, this means forming a new edge
whenever the category of the first needed
constituent of an active edge matches the
category of an inactive edge,13 and the dag
of the inactive edge can be unified in with
the dag of the needed constituent.
</bodyText>
<sectionHeader confidence="0.999912" genericHeader="method">
3 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999272">
3.1 Top-Down Parsing
</subsectionHeader>
<bodyText confidence="0.989916048387097">
The algorithm given in section 2.4.2 could be mod-
ified to top-down parsing by changing the predic-
tor (see e.g. Wirer: 1988) and by having Move-
Vertex/RightHalf not move active looping edges
(v/..Atoop) since, in top-down, these &amp;quot;belong&amp;quot; to the
left portion of the chart where the predictions of
them were generated.
In general, the algorithm works better bottom-up
than top-down because bottom-up predictions are
120ne edge subsumes another edge if and only if the first
three elements of the edges are identical and the fourth ele-
ment of the first edge subsumes that of the second edge. For
a definition of subsumption, see Shieber (1986:14).
&amp;quot;Note that this condition is tested by the unification which
specifically ensures that D((.7Cm cat)) = B((Y0 cat)).
- 245 -
made &amp;quot;locally&amp;quot; at the starting vertex of the trigger-
ing (inactive) edge in question. Therefore, a changed
preterminal edge will typically have its dependants
locally, and, as a consequence, the whole update
can be kept local. In top-down parsing, on the
other hand, predictions are &amp;quot;forward-directed&amp;quot;, be-
ing made at the ending vertex of the triggering (ac-
tive) edge. As a result of this, an update will, in
particular, cause all predicted and combined edges
after the change to be removed. The reason for this
is that we have forward-directed predictions having
generated active and inactive edges, the former of
which in turn have generated forward-directed pre-
dictions, and so on through the chart.
On the one hand, one might accept this, argu-
ing that this is simply the way top-down works: It
generates forward-directed hypotheses based on the
preceding context, and if we change the preceding
context, the forward hypotheses should change as
well. Also, it is still slightly more well-behaved than
exhaustive reanalysis from the change.
On the other hand, the point of incremental pars-
ing is to keep updates local, and if we want to take
this seriously, it seems like a waste to destroy possi-
bly usable structure to the right of the change. For
example, in changing the sentence &amp;quot;Sarah gave Kim
a green apple&amp;quot; to &amp;quot;Sarah gave a green apple to Kim&amp;quot;,
there is no need for the phrase &amp;quot;a green apple&amp;quot; to be
reanalysed.
One approach to this problem would be for the
edge-removal process to introduce a &amp;quot;cut&amp;quot; whenever
a top-down prediction having some dependant edge
is encountered, mark it as &amp;quot;uncertain&amp;quot;, and repeat-
edly, at some later points in time, try to find a new
source for it. Eventually, if such a source cannot be
found, the edge (along with dependants) should be
&amp;quot;garbage-collected&amp;quot; because there is no way for the
normal update machinery to remove an edge with-
out a source (except for preterminal edges).
In sum, it would be desirable if we were able to
retain the open-endedness of chart parsing also with
respect to rule invocation while still providing for
efficient incremental update. However, the precise
strategy for best achieving this remains to be worked
out (also in the light of a fully testable interactive
system).
</bodyText>
<subsectionHeader confidence="0.896800333333333">
3.2 Alternative Ways
of Determining Affected Edges
8.2.1 Maintain Sources Only
</subsectionHeader>
<bodyText confidence="0.9998651">
Henry Thompson (personal communication 1988)
has pointed out that, instead of computing sets of
dependants from source edges, it might suffice to
simply record the latter, provided that the frequency
of updates is small and the total number of edges is
not too large. The idea is to sweep the whole edge
space each time there is an update, repeatedly delet-
ing anything with a non-existent source edge, and it-
erating until one gets through a whole pass with no
new deletions.
</bodyText>
<subsectionHeader confidence="0.9962225">
3.2.2 Maintain Neither Sources
Nor Dependencies
</subsectionHeader>
<bodyText confidence="0.9999483125">
If we confine ourselves to bottom-up parsing, and if
we accept that an update will unconditionally cause
all edges in the dependency closure to be removed
(not allowing the kind of refinements discussed in
footnote 10, it is in fact not necessary to record
sources or dependencies at all. The reason for this is
that, in effect, removing all dependants of all preter-
minal edges extending between vertices vt, , vr+1
in the bottom-up case amounts to removing all edges
that extend somewhere within this interval (except
for bottom-up predictions at vertex vr+i which are
triggered by edges outside of the interval). Given a
suitable matrix representation for the chart (where
edges are simultaneously indexed with respect to
starting and ending vertices), this may provide for a
very efficient solution.
</bodyText>
<subsectionHeader confidence="0.8307285">
3.2.3 Maintain Dependencies
between Features
</subsectionHeader>
<bodyText confidence="0.999919636363636">
There is a trade-off between updating as local a unit
as possible and the complexity of the algorithm for
doing so. Given a complex-feature-based formalism
like PATR, one extreme would be to maintain de-
pendencies between feature instances of the chart
instead of between chart edges. In principle, this
is the approach of the Synthesizer Generator (Reps
and Teitelbaum 1987), which adopts attribute gram-
mar for the language specification and maintains de-
pendencies between the attribute instances of the
derivation tree.
</bodyText>
<subsectionHeader confidence="0.999813">
3.3 Lexical Component
</subsectionHeader>
<bodyText confidence="0.94597815">
An approach to the lexical component which seems
particularly suitable with respect to this type of
parser, and which is adopted in the actual implemen-
tation, is the letter-tree format.14 This approach
takes advantage of the fact that words normally are
entered from left to right, and supports the idea of a
dynamic pointer which follows branches of the tree
as a word is entered, immediately calling for reaction
when an illegal string is detected. In particular, this
allows you to distinguish an incomplete word from a
(definitely) illegal word. Another advantage of this
14 This according to the terminology of Aho, Hoperoft, and
Ullman (1987:168).
- 246 -
approach is that one may easily add two-level mor-
phology (Koskenniemi 1983) as an additional filter.
A radical approach, not pursued here, would be to
employ the same type of incremental chart-parsing
machinery at the lexical level as we do at the sen-
tence level.
</bodyText>
<subsectionHeader confidence="0.977644">
3.4 Dependencies across Sentences
</subsectionHeader>
<bodyText confidence="0.997887076923077">
Incremental parsing would be even more beneficial if
it were extended to handle dependencies across mul-
tiple sentences, for example with respect to noun-
phrases. Considering a language-sensitive text edi-
tor, the purpose of which would be to keep track of
an input text, to detect (and maybe correct) certain
linguistic errors, a change in one sentence often re-
quires changes also in the surrounding text as in the
following examples:
The house is full of mould. It has been
judged insanitary by the public health com-
mittee. They say it has to be torn down.
The salmon jumped. It likes to play.
In the first example, changing the number of
&amp;quot;house&amp;quot; forces several grammatical changes in the
subsequent sentences, requiring reanalysis. In the
second example, changing &amp;quot;it (likes)&amp;quot; to &amp;quot;they (like)&amp;quot;
constrains the noun-phrase of the previous sentence
to be interpreted as plural, which could be reflected
for example by putting the edges of the singular anal-
ysis to sleep.
Cross-sentence dependencies require a level of in-
cremental interpretation and a database with non-
monotonic reasoning capabilities. For a recent ap-
proach in this direction, see Zernik and Brown
(1988).
</bodyText>
<sectionHeader confidence="0.999488" genericHeader="method">
4 Interactive Parsing
</sectionHeader>
<bodyText confidence="0.999726083333333">
This section outlines how the incremental parser is
embedded in an interactive parsing system, called
LIP3.15
Figure 1 shows the main components of the sys-
tem. The user types a sentence into the editor (a
Xerox T EDIT text editor). The words are analysed
on-line by the scanner and handed over to the parser
proper which keeps the chart consistent with the in-
put sentence. Unknown words are marked as illegal
in the edit window. The system displays the chart
incrementally, drawing and erasing individual edges
in tandem with the parsing process.
</bodyText>
<subsubsectionHeader confidence="0.214965">
&amp;quot;Linkoping Interactive Parsing System.
</subsubsectionHeader>
<figureCaption confidence="0.970381">
Figure 1. Main components of the LIPS system
</figureCaption>
<bodyText confidence="0.999851181818182">
It is planned to maintain a dynamic agenda of up-
date tasks (either at the level of update functions
or, preferably, at the level of individual edges), re-
moving tasks which are no longer needed because
the user has made them obsolete (for example by
immediately deleting an inserted text).
In the long run, an interactive parsing system
probably has to have some built-in notion of time, for
example through time-stamped editing operations
and (adjustable) strategies for timing of update op-
erations.
</bodyText>
<sectionHeader confidence="0.999297" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999846166666667">
This paper has demonstrated how a chart parser by
simple means could be augmented to perform in-
cremental parsing, and has suggested how this sys-
tem in turn could be embedded in an interactive
parsing system. Incrementality and interactivity are
two independent properties, but, in practice, an in-
cremental system that is not interactive would be
pointless, and an interactive system that is not in-
cremental would at least be less efficient than it
could be. Although exhaustive recomputation can
be fast enough for small problems, incrementality is
ultimately needed in order to cope with longer and
more complex texts. In addition, incremental pars-
ing brings to the system a certain &amp;quot;naturalness&amp;quot; —
analyses are put together piece by piece, and there
is a built-in correlation between the amount of pro-
ceasing required for a task and its difficulty.
&amp;quot;Easy things should be easy...&amp;quot; (Alan Kay).
</bodyText>
<sectionHeader confidence="0.998582" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994919846153846">
Aho, Alfred V., John E. Hoperoft, and Jeffrey D.
Ullman (1987). Data Structures and Algorithms.
Addison-Wesley, Reading, Massachusetts.
Bobrow, Robert J. and Bonnie Lynn Webber (1980).
Knowledge Representation for Syntactic/Semantic
Processing. Proc. First Annual National Conference
on Artificial Intelligence, Stanford, California: 316-
323.
de Kleer, Johan (1986). An Assumption-based TMS.
Artificial Intelligence 28(2):127-162.
Earley, Jay (1970). An Efficient Context-Free
Parsing Algorithm. Communications of the ACM
13(2):94-102.
</reference>
<figure confidence="0.970307555555555">
Text editor
Lexicon
Scanner
Grammar
Incremental
chart parser
Chart
CP-R
- 247 -
</figure>
<reference confidence="0.996645388888889">
Earley, Jay and Paul Caizergues (1972). A Method
for Incrementally Compiling Languages with Nested
Statement Structure. Communications of the ACM
15 (12): 1040-1044.
Ghezzi, Carlo and Dino Mandrioli (1979). Incremen-
tal Parsing. ACM Transactions on Programming
Languages and Systems 1(1):58-70.
Ghezzi, Carlo and Dino Mandrioli (1980). Aug-
menting Parsers to Support Incrementality. Jour-
nal of the Association for Computing Machinery
27(3):564-579.
Haddock, Nicholas J. (1987). Incremental Interpre-
tation and Combinatory Categorial Grammar. Proc.
Tenth International Joint Conference on Artificial
Intelligence, Milan, Italy: 661-663.
Hirst, Graeme (1987). Semantic Interpretation and
the Resolution of Ambiguity. Cambridge University
Press, Cambridge, England.
Kay, Martin (1980). Algorithm Schemata and Data
Structures in Syntactic Processing. Report CSL-80-
12, Xerox PARC, Palo Alto, California. Also in:
Sture Allen, ed. (1982), Text Processing. Proceed-
ings of Nobel Symposium 51. Almqvist &amp; Wiksell
International, Stockholm, Sweden: 327-358.
Koskenniemi, Kimmo (1983). Two-Level Morphol-
ogy: A General Computational Model for Word-
Form Recognition and Production. Publication No.
11, Department of General Linguistics, University of
Helsinki, Helsinki, Finland.
Lindstrom, G. (1970). The Design of Parsers for
Incremental Language Processors. Proc. End ACM
Symposium on Theory of Computing, Northampton,
Massachusetts: 81-91.
Mellish, Christopher S. (1985). Computer Interpre-
tation of Natural Language Descriptions. Ellis Hor-
wood, Chichester, England.
Pulman, Steven G. (1985). A Parser That Doesn&apos;t.
Proc. Second Conference of the European Chapter
of the Association for Computational Linguistics,
Geneva, Switzerland: 128-135.
Pulman, Steven G. (1987). The Syntax-Semantics
Interface. In: Pete Whitelock, Mary McGee Wood,
Harold Somers, Rod Johnson, and Paul Bennett, ed.,
Linguistic Theory and Computer Applications. Aca-
demic Press, London, England: 189-224.
Reps, Thomas and Tim Teitelbaum (1987). Lan-
guage Processing in Program Editors. Computer
20(11):29-40.
Shieber, Stuart M. (1986). An Introduction to
Unification-Based Approaches to Grammar. CSLI
Lecture Notes No. 4. University of Chicago Press,
Chicago, Illinois.
Shieber, Stuart M., Hans Uszkoreit, Fernando C. N.
Pereira, Jane J. Robinson, and Mabry Tyson (1983).
The Formalism and Implementation of PATR-II. In:
Barbara Grosz and Mark Stickel, eds., Research on
Interactive Acquisition and Use of Knowledge. SRI
Final Report 1894, SRI International, Menlo Park,
California.
Thompson, Henry (1981). Chart Parsing and Rule
Schemata in GPSG. Research Paper No. 165, De-
partment of Artificial Intelligence, University of Ed-
inburgh, Edinburgh, Scotland. Also in: Proc. 19th
Annual Meeting of the Association for Computa-
tional Linguistics, Stanford, California: 167-172.
Thompson, Henry and Graeme Ritchie (1984). Im-
plementing Natural Language Parsers. In: Tim
O&apos;Shea and Marc Eisenstadt, Artificial Intelligence:
Tools, Techniques, and Applications. Harper &amp; Row,
New York, New York: 245-300.
Tomita, Masaru (1985). An Efficient Context-Free
Parsing Algorithm for Natural Languages. Proc.
Ninth International Joint Conference on Artificial
Intelligence, Los Angeles, California: 756-764.
Yonezawa, Akinori and Ichiro Ohsawa (1988).
Object-Oriented Parallel Parsing for Context-Free
Grammars. Proc. 12th International Conference
on Computational Linguistics, Budapest, Hungary:
773-778.
Wiren, Mats (1988). A Control-Strategy-Indepen-
dent Parser for PATR. Proc. First Scandinavian
Conference on Artificial Intelligence, Tromso, Nor-
way: 161-172. Also research report LiTH-IDA-R-
88-10, Department of Computer and Information
Science, LinkOping University, Linkoping, Sweden.
Zernik, Uri and Allen Brown (1988). Default Rea-
soning in Natural Language Processing. Proc. 12th
International Conference on Computational Linguis-
tics, Budapest, Hungary: 801-805.
- 248 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.976061">
<title confidence="0.999943">Interactive Incremental Chart Parsing</title>
<author confidence="0.999264">Mats Wiren</author>
<affiliation confidence="0.999974">Department of Computer and Information Science LinkOping University</affiliation>
<address confidence="0.992191">S-581 83 LinkOping, Sweden</address>
<email confidence="0.989164">mgw@ida.liu.se</email>
<abstract confidence="0.999886">This paper presents an algorithm for incremental chart parsing, outlines how this could be embedded in an interactive parsing system, and discusses why this might be useful. Incremental parsing here means that input is analysed in a piecemeal fashion, in particular allowing arbitrary changes of previous input without exhaustive reanalysis. Interactive parsing means that the analysis process is prompted immediately at the onset of new input, and possibly that the system then may interact with the user in order to resolve problems that occur. The combination of these techniques could be used as a parsing kernel for highly interactive and &amp;quot;reactive&amp;quot; naturallanguage processors, such as parsers for dialogue systems, interactive computer-aided translation systems, and language-sensitive text editors. An incremental chart parser embodying the ideas put forward in this paper has been implemented, and an embedding of this in an interactive parsing system is near completion.</abstract>
<intro confidence="0.997238">1 Background</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred V Aho</author>
<author>John E Hoperoft</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>Data Structures and Algorithms.</title>
<date>1987</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, Massachusetts.</location>
<marker>Aho, Hoperoft, Ullman, 1987</marker>
<rawString>Aho, Alfred V., John E. Hoperoft, and Jeffrey D. Ullman (1987). Data Structures and Algorithms. Addison-Wesley, Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert J Bobrow</author>
<author>Bonnie Lynn Webber</author>
</authors>
<title>Knowledge Representation for Syntactic/Semantic Processing.</title>
<date>1980</date>
<booktitle>Proc. First Annual National Conference on Artificial Intelligence,</booktitle>
<pages>316--323</pages>
<location>Stanford, California:</location>
<contexts>
<context position="3228" citStr="Bobrow and Webber (1980)" startWordPosition="513" endWordPosition="516"> update ought to be somehow correlated with the difficulty of this update. Thus, a necessary (but not sufficient) condition for realizing a real-time parsing system as suggested above is an interactive and incremental parsing system. The goal of this paper is to develop a basic machinery for incremental chart parsing and to outline how this could be embedded in an interactive parsing system. 1.2 Incremental Parsing The word &amp;quot;incremental&amp;quot; has been used in two differing senses in the (passing) literature. The first sense stresses that input should be analysed in a piecemeal fashion, for example Bobrow and Webber (1980), Mellish (1985), Pulman (1985, 1987), Hirst (1987), Haddock (1987). According to this view, an incremental parser constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is </context>
</contexts>
<marker>Bobrow, Webber, 1980</marker>
<rawString>Bobrow, Robert J. and Bonnie Lynn Webber (1980). Knowledge Representation for Syntactic/Semantic Processing. Proc. First Annual National Conference on Artificial Intelligence, Stanford, California: 316-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan de Kleer</author>
</authors>
<title>An Assumption-based TMS.</title>
<date>1986</date>
<journal>Artificial Intelligence</journal>
<pages>28--2</pages>
<marker>de Kleer, 1986</marker>
<rawString>de Kleer, Johan (1986). An Assumption-based TMS. Artificial Intelligence 28(2):127-162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Earley</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm.</title>
<date>1970</date>
<journal>Communications of the ACM</journal>
<pages>13--2</pages>
<contexts>
<context position="8681" citStr="Earley (1970)" startWordPosition="1360" endWordPosition="1361"> upo another edge if it is formed using the latter &amp;Iv Thus, an edge formed through a prediction step d( pends on the (one) edge that triggered it.4 Likewis( an edge formed through a combination3 depends o the active—inactive edge pair that generated it. scanned edge, on the other hand, does not depen upon any other edge, as scanning can be seen as kind of initialization of the chart.6 In order to account for edge dependencies we assc ciate with each edge the set of its immediate sourc 4In the case of an initial top-down prediction, the sour&lt; would be non-existent. 6The completer operation in Earley (1970); the fundament rule in Thompson (1981:2). 6It might be argued that a dependency should be estal lished also in the case of an edge being proposed but rejecte (owing to a redundancy test) because it already exists. Hoy ever, as long as updates affect all preterminal edges extendir from a vertex, this appears not to be crucial. - 242 - edges (&amp;quot;back pointers&amp;quot;). This information could be used to derive the corresponding sets of dependent edges (&amp;quot;forward pointers&amp;quot;) that we are interested in. For example, when a word in the previous input has been deleted, we want to remove all edges which depend o</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>Earley, Jay (1970). An Efficient Context-Free Parsing Algorithm. Communications of the ACM 13(2):94-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Earley</author>
<author>Paul Caizergues</author>
</authors>
<title>A Method for Incrementally Compiling Languages with Nested Statement Structure.</title>
<date>1972</date>
<journal>Communications of the ACM</journal>
<volume>15</volume>
<issue>12</issue>
<pages>1040--1044</pages>
<contexts>
<context position="3940" citStr="Earley and Caizergues (1972)" startWordPosition="625" endWordPosition="628">is view, an incremental parser constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of research on interactive programming environments, e.g. Lindstrom (1970), Earley and Caizergues (1972), Ghezzi and Mandrioli (1979, 1980), Reps and Teitelbaum (1987). As indicated above, we are here interested in the latter view, which we summarize in the following working definition. - 241 - Incremental parser. A parser capable of handling changes of previous input while expending an amount of effort which is proportional to the complexity of the changes.&apos; It should be pointed out that we are here limiting ourselves to a machinery for incremental parsing as opposed to incremental interpretation. In other words, the derivation of an utterance here takes into account only &amp;quot;context-free&amp;quot; (lexica</context>
<context position="5849" citStr="Earley and Caizergues (1972" startWordPosition="908" endWordPosition="911">tors for) language-based editors have been developed that make use of interactive (and incremental) parsing and compilation to perform program analysis, to report errors, and to generate code while the program is being edited, for example Mentor, Gandalf, and the Synthesizer Generator (Reps and Teitelbaum 1987). Within natural-language processing, Tomita (1985) and Yonezawa and Ohsawa (1988) have reported parsers which operate on-line, but, incidentally, not incrementally in the sense adopted here.3 1This definition is formed partly in analogy with a definition of &amp;quot;incremental compilation&amp;quot; by Earley and Caizergues (1972:1040). We use &amp;quot;complexity&amp;quot; instead of &amp;quot;size&amp;quot; because different updates of the same size may cause differing processing efforts depending on the degree of grammatical complexity (ambiguity, context-sensitiveness) constraining the updates in question. 2Incidentally, interactive parsing could be seen as one example of a general trend towards immediate computation (Reps and Teitelbaum 1987:31), also manifest in applications such as WYSIWYG word processing and spreadsheet programs, and sparked off by the availability of personal workstations with dedicated processors. 3The user may delete input fr</context>
</contexts>
<marker>Earley, Caizergues, 1972</marker>
<rawString>Earley, Jay and Paul Caizergues (1972). A Method for Incrementally Compiling Languages with Nested Statement Structure. Communications of the ACM 15 (12): 1040-1044.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Ghezzi</author>
<author>Dino Mandrioli</author>
</authors>
<title>Incremental Parsing.</title>
<date>1979</date>
<journal>ACM Transactions on Programming Languages and Systems</journal>
<pages>1--1</pages>
<contexts>
<context position="3968" citStr="Ghezzi and Mandrioli (1979" startWordPosition="629" endWordPosition="632"> constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of research on interactive programming environments, e.g. Lindstrom (1970), Earley and Caizergues (1972), Ghezzi and Mandrioli (1979, 1980), Reps and Teitelbaum (1987). As indicated above, we are here interested in the latter view, which we summarize in the following working definition. - 241 - Incremental parser. A parser capable of handling changes of previous input while expending an amount of effort which is proportional to the complexity of the changes.&apos; It should be pointed out that we are here limiting ourselves to a machinery for incremental parsing as opposed to incremental interpretation. In other words, the derivation of an utterance here takes into account only &amp;quot;context-free&amp;quot; (lexical, syntactic, compositional-</context>
</contexts>
<marker>Ghezzi, Mandrioli, 1979</marker>
<rawString>Ghezzi, Carlo and Dino Mandrioli (1979). Incremental Parsing. ACM Transactions on Programming Languages and Systems 1(1):58-70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Ghezzi</author>
<author>Dino Mandrioli</author>
</authors>
<title>Augmenting Parsers to Support Incrementality.</title>
<date>1980</date>
<journal>Journal of the Association for Computing Machinery</journal>
<pages>27--3</pages>
<marker>Ghezzi, Mandrioli, 1980</marker>
<rawString>Ghezzi, Carlo and Dino Mandrioli (1980). Augmenting Parsers to Support Incrementality. Journal of the Association for Computing Machinery 27(3):564-579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas J Haddock</author>
</authors>
<title>Incremental Interpretation and Combinatory Categorial Grammar.</title>
<date>1987</date>
<booktitle>Proc. Tenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>661--663</pages>
<location>Milan, Italy:</location>
<contexts>
<context position="3295" citStr="Haddock (1987)" startWordPosition="524" endWordPosition="525">us, a necessary (but not sufficient) condition for realizing a real-time parsing system as suggested above is an interactive and incremental parsing system. The goal of this paper is to develop a basic machinery for incremental chart parsing and to outline how this could be embedded in an interactive parsing system. 1.2 Incremental Parsing The word &amp;quot;incremental&amp;quot; has been used in two differing senses in the (passing) literature. The first sense stresses that input should be analysed in a piecemeal fashion, for example Bobrow and Webber (1980), Mellish (1985), Pulman (1985, 1987), Hirst (1987), Haddock (1987). According to this view, an incremental parser constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of research on interactive programming environments, e.g. L</context>
</contexts>
<marker>Haddock, 1987</marker>
<rawString>Haddock, Nicholas J. (1987). Incremental Interpretation and Combinatory Categorial Grammar. Proc. Tenth International Joint Conference on Artificial Intelligence, Milan, Italy: 661-663.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Semantic Interpretation and the Resolution of Ambiguity.</title>
<date>1987</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<contexts>
<context position="3279" citStr="Hirst (1987)" startWordPosition="522" endWordPosition="523">his update. Thus, a necessary (but not sufficient) condition for realizing a real-time parsing system as suggested above is an interactive and incremental parsing system. The goal of this paper is to develop a basic machinery for incremental chart parsing and to outline how this could be embedded in an interactive parsing system. 1.2 Incremental Parsing The word &amp;quot;incremental&amp;quot; has been used in two differing senses in the (passing) literature. The first sense stresses that input should be analysed in a piecemeal fashion, for example Bobrow and Webber (1980), Mellish (1985), Pulman (1985, 1987), Hirst (1987), Haddock (1987). According to this view, an incremental parser constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of research on interactive programming envi</context>
</contexts>
<marker>Hirst, 1987</marker>
<rawString>Hirst, Graeme (1987). Semantic Interpretation and the Resolution of Ambiguity. Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Algorithm Schemata and Data Structures in Syntactic Processing. Report CSL-80-12, Xerox PARC,</title>
<date>1980</date>
<booktitle>Text Processing. Proceedings of Nobel Symposium 51. Almqvist &amp; Wiksell International,</booktitle>
<pages>327--358</pages>
<editor>in: Sture Allen, ed.</editor>
<location>Palo Alto, California. Also</location>
<contexts>
<context position="7182" citStr="Kay 1980" startWordPosition="1111" endWordPosition="1112">t in the beginning of a sentence, the system has to reparse exhaustively from this update and on. (Of course, in reality the user has to first backspace and then retype everything from the change.) 1.4 Outline of Paper Section 2 presents an algorithm for incremental char parsing. Section 3 discusses some additional aspect and alternative strategies. Section 4 gives a brie outline of the combined interactive and incrementa parsing system, and section 5 summarizes the con clusions. 2 Incremental Chart Parsing 2.1 Chart Parsing The incremental parser has been grounded in chart-parsing framework (Kay 1980, Thompso 1981, Thompson and Ritchie 1984) for the follow ing reasons: • chart parsing is an efficient, open-ended, we understood, and frequently adopted techniqu in natural-language processing; • chart parsing gives us a previously unexplorei possibility of embedding incrementality at a loi cost. 2.2 Edge Dependencies The idea of incremental chart parsing, as put foi ward here, is based on the following observatior The chart, while constituting a record of partia analyses (chart edges), may easily be provided wit information also about the dependencies betwee those analyses. This is just what</context>
</contexts>
<marker>Kay, 1980</marker>
<rawString>Kay, Martin (1980). Algorithm Schemata and Data Structures in Syntactic Processing. Report CSL-80-12, Xerox PARC, Palo Alto, California. Also in: Sture Allen, ed. (1982), Text Processing. Proceedings of Nobel Symposium 51. Almqvist &amp; Wiksell International, Stockholm, Sweden: 327-358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Two-Level Morphology: A General Computational Model for WordForm Recognition and Production.</title>
<date>1983</date>
<tech>Publication No. 11,</tech>
<institution>Department of General Linguistics, University of Helsinki,</institution>
<location>Helsinki, Finland.</location>
<contexts>
<context position="26440" citStr="Koskenniemi 1983" startWordPosition="4509" endWordPosition="4510"> adopted in the actual implementation, is the letter-tree format.14 This approach takes advantage of the fact that words normally are entered from left to right, and supports the idea of a dynamic pointer which follows branches of the tree as a word is entered, immediately calling for reaction when an illegal string is detected. In particular, this allows you to distinguish an incomplete word from a (definitely) illegal word. Another advantage of this 14 This according to the terminology of Aho, Hoperoft, and Ullman (1987:168). - 246 - approach is that one may easily add two-level morphology (Koskenniemi 1983) as an additional filter. A radical approach, not pursued here, would be to employ the same type of incremental chart-parsing machinery at the lexical level as we do at the sentence level. 3.4 Dependencies across Sentences Incremental parsing would be even more beneficial if it were extended to handle dependencies across multiple sentences, for example with respect to nounphrases. Considering a language-sensitive text editor, the purpose of which would be to keep track of an input text, to detect (and maybe correct) certain linguistic errors, a change in one sentence often requires changes als</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, Kimmo (1983). Two-Level Morphology: A General Computational Model for WordForm Recognition and Production. Publication No. 11, Department of General Linguistics, University of Helsinki, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lindstrom</author>
</authors>
<title>The Design of Parsers for Incremental Language Processors.</title>
<date>1970</date>
<booktitle>Proc. End ACM Symposium on Theory of Computing,</booktitle>
<pages>81--91</pages>
<location>Northampton, Massachusetts:</location>
<contexts>
<context position="3910" citStr="Lindstrom (1970)" startWordPosition="623" endWordPosition="624">). According to this view, an incremental parser constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of research on interactive programming environments, e.g. Lindstrom (1970), Earley and Caizergues (1972), Ghezzi and Mandrioli (1979, 1980), Reps and Teitelbaum (1987). As indicated above, we are here interested in the latter view, which we summarize in the following working definition. - 241 - Incremental parser. A parser capable of handling changes of previous input while expending an amount of effort which is proportional to the complexity of the changes.&apos; It should be pointed out that we are here limiting ourselves to a machinery for incremental parsing as opposed to incremental interpretation. In other words, the derivation of an utterance here takes into accou</context>
</contexts>
<marker>Lindstrom, 1970</marker>
<rawString>Lindstrom, G. (1970). The Design of Parsers for Incremental Language Processors. Proc. End ACM Symposium on Theory of Computing, Northampton, Massachusetts: 81-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher S Mellish</author>
</authors>
<title>Computer Interpretation of Natural Language Descriptions. Ellis Horwood,</title>
<date>1985</date>
<location>Chichester, England.</location>
<contexts>
<context position="3244" citStr="Mellish (1985)" startWordPosition="517" endWordPosition="518">w correlated with the difficulty of this update. Thus, a necessary (but not sufficient) condition for realizing a real-time parsing system as suggested above is an interactive and incremental parsing system. The goal of this paper is to develop a basic machinery for incremental chart parsing and to outline how this could be embedded in an interactive parsing system. 1.2 Incremental Parsing The word &amp;quot;incremental&amp;quot; has been used in two differing senses in the (passing) literature. The first sense stresses that input should be analysed in a piecemeal fashion, for example Bobrow and Webber (1980), Mellish (1985), Pulman (1985, 1987), Hirst (1987), Haddock (1987). According to this view, an incremental parser constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of resea</context>
</contexts>
<marker>Mellish, 1985</marker>
<rawString>Mellish, Christopher S. (1985). Computer Interpretation of Natural Language Descriptions. Ellis Horwood, Chichester, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven G Pulman</author>
</authors>
<title>A Parser That Doesn&apos;t.</title>
<date>1985</date>
<booktitle>Proc. Second Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>128--135</pages>
<location>Geneva, Switzerland:</location>
<contexts>
<context position="3258" citStr="Pulman (1985" startWordPosition="519" endWordPosition="520">h the difficulty of this update. Thus, a necessary (but not sufficient) condition for realizing a real-time parsing system as suggested above is an interactive and incremental parsing system. The goal of this paper is to develop a basic machinery for incremental chart parsing and to outline how this could be embedded in an interactive parsing system. 1.2 Incremental Parsing The word &amp;quot;incremental&amp;quot; has been used in two differing senses in the (passing) literature. The first sense stresses that input should be analysed in a piecemeal fashion, for example Bobrow and Webber (1980), Mellish (1985), Pulman (1985, 1987), Hirst (1987), Haddock (1987). According to this view, an incremental parser constructs the analysis of an utterance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of research on interac</context>
</contexts>
<marker>Pulman, 1985</marker>
<rawString>Pulman, Steven G. (1985). A Parser That Doesn&apos;t. Proc. Second Conference of the European Chapter of the Association for Computational Linguistics, Geneva, Switzerland: 128-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven G Pulman</author>
</authors>
<title>The Syntax-Semantics Interface. In:</title>
<date>1987</date>
<booktitle>Linguistic Theory and Computer Applications.</booktitle>
<pages>189--224</pages>
<editor>Pete Whitelock, Mary McGee Wood, Harold Somers, Rod Johnson, and Paul Bennett, ed.,</editor>
<publisher>Academic Press,</publisher>
<location>London, England:</location>
<marker>Pulman, 1987</marker>
<rawString>Pulman, Steven G. (1987). The Syntax-Semantics Interface. In: Pete Whitelock, Mary McGee Wood, Harold Somers, Rod Johnson, and Paul Bennett, ed., Linguistic Theory and Computer Applications. Academic Press, London, England: 189-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Reps</author>
<author>Tim Teitelbaum</author>
</authors>
<date>1987</date>
<booktitle>Language Processing in Program Editors. Computer</booktitle>
<pages>20--11</pages>
<contexts>
<context position="4003" citStr="Reps and Teitelbaum (1987)" startWordPosition="634" endWordPosition="637">rance bit by bit (typically from left to right), rather than in one go when it has come to an end. The other sense of &amp;quot;incremental&amp;quot; stresses the necessity of efficiently handling arbitrary changes within current input. Thus, according to this view, an incremental parser should be able to efficiently handle not only piecemeal additions to a sentence, but, more generally, arbitrary insertions and deletions in it. This view of incremental parsing is typical of research on interactive programming environments, e.g. Lindstrom (1970), Earley and Caizergues (1972), Ghezzi and Mandrioli (1979, 1980), Reps and Teitelbaum (1987). As indicated above, we are here interested in the latter view, which we summarize in the following working definition. - 241 - Incremental parser. A parser capable of handling changes of previous input while expending an amount of effort which is proportional to the complexity of the changes.&apos; It should be pointed out that we are here limiting ourselves to a machinery for incremental parsing as opposed to incremental interpretation. In other words, the derivation of an utterance here takes into account only &amp;quot;context-free&amp;quot; (lexical, syntactic, compositional-semantic) information obtained from</context>
<context position="5534" citStr="Reps and Teitelbaum 1987" startWordPosition="864" endWordPosition="867">s a text-input process, starting to parse immediately at the onset of new input, thereby achieving enhanced efficiency as well as a potential for dynamic improvement of its performance, for example by promptly reporting errors, asking for clarifications, etc.2 Within the area of programming environments, (generators for) language-based editors have been developed that make use of interactive (and incremental) parsing and compilation to perform program analysis, to report errors, and to generate code while the program is being edited, for example Mentor, Gandalf, and the Synthesizer Generator (Reps and Teitelbaum 1987). Within natural-language processing, Tomita (1985) and Yonezawa and Ohsawa (1988) have reported parsers which operate on-line, but, incidentally, not incrementally in the sense adopted here.3 1This definition is formed partly in analogy with a definition of &amp;quot;incremental compilation&amp;quot; by Earley and Caizergues (1972:1040). We use &amp;quot;complexity&amp;quot; instead of &amp;quot;size&amp;quot; because different updates of the same size may cause differing processing efforts depending on the degree of grammatical complexity (ambiguity, context-sensitiveness) constraining the updates in question. 2Incidentally, interactive parsing</context>
<context position="25534" citStr="Reps and Teitelbaum 1987" startWordPosition="4362" endWordPosition="4365">of the interval). Given a suitable matrix representation for the chart (where edges are simultaneously indexed with respect to starting and ending vertices), this may provide for a very efficient solution. 3.2.3 Maintain Dependencies between Features There is a trade-off between updating as local a unit as possible and the complexity of the algorithm for doing so. Given a complex-feature-based formalism like PATR, one extreme would be to maintain dependencies between feature instances of the chart instead of between chart edges. In principle, this is the approach of the Synthesizer Generator (Reps and Teitelbaum 1987), which adopts attribute grammar for the language specification and maintains dependencies between the attribute instances of the derivation tree. 3.3 Lexical Component An approach to the lexical component which seems particularly suitable with respect to this type of parser, and which is adopted in the actual implementation, is the letter-tree format.14 This approach takes advantage of the fact that words normally are entered from left to right, and supports the idea of a dynamic pointer which follows branches of the tree as a word is entered, immediately calling for reaction when an illegal </context>
</contexts>
<marker>Reps, Teitelbaum, 1987</marker>
<rawString>Reps, Thomas and Tim Teitelbaum (1987). Language Processing in Program Editors. Computer 20(11):29-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar.</title>
<date>1986</date>
<journal>CSLI Lecture Notes</journal>
<volume>4</volume>
<institution>University of Chicago Press,</institution>
<location>Chicago, Illinois.</location>
<contexts>
<context position="13522" citStr="Shieber 1986" startWordPosition="2233" endWordPosition="2234">s extending from vertices , vr, respectively.9 Thus, n may here take the values insert, delete, or replace; ic is a pair of positions 1, r such that the sequence of positions 1, , r map directly to vertices , vr, and r is the corresponding sequence of words tut • • • wr. In addition, we will make use of the constant 6 = r — 1+ 1, denoting the number of words affected by the editing operation. 2.3.3 Grammatical Formalism In the algorithm below, as well as in the actual implementation, we have adopted a unification-based grammatical formalism with a context-free base, PATR (Shieber et al. 1983, Shieber 1986), because this seems to be the best candidate for a lingua franca in current natural-language processing. However, this formalism here shows up only within the edges, where we have an extra dag element (D), and when referring to rules, each of which consists of a °Character editing is processed by the scanner; cf. section 3.3. - 243 - pair (X0 —■ D) of a production and a dag. In the dag representation of the rule, we will store the context-free base under cat features as usual. We assume that the grammar is cycle-free. 2.4 An Algorithm for Incremental Chart Parsing 2.4.1 Introduction This sect</context>
<context position="21341" citStr="Shieber (1986" startWordPosition="3671" endWordPosition="3672">ection 2.4.2 could be modified to top-down parsing by changing the predictor (see e.g. Wirer: 1988) and by having MoveVertex/RightHalf not move active looping edges (v/..Atoop) since, in top-down, these &amp;quot;belong&amp;quot; to the left portion of the chart where the predictions of them were generated. In general, the algorithm works better bottom-up than top-down because bottom-up predictions are 120ne edge subsumes another edge if and only if the first three elements of the edges are identical and the fourth element of the first edge subsumes that of the second edge. For a definition of subsumption, see Shieber (1986:14). &amp;quot;Note that this condition is tested by the unification which specifically ensures that D((.7Cm cat)) = B((Y0 cat)). - 245 - made &amp;quot;locally&amp;quot; at the starting vertex of the triggering (inactive) edge in question. Therefore, a changed preterminal edge will typically have its dependants locally, and, as a consequence, the whole update can be kept local. In top-down parsing, on the other hand, predictions are &amp;quot;forward-directed&amp;quot;, being made at the ending vertex of the triggering (active) edge. As a result of this, an update will, in particular, cause all predicted and combined edges after the ch</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, Stuart M. (1986). An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes No. 4. University of Chicago Press, Chicago, Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
<author>Hans Uszkoreit</author>
<author>Fernando C N Pereira</author>
<author>Jane J Robinson</author>
<author>Mabry Tyson</author>
</authors>
<title>The Formalism and Implementation of PATR-II.</title>
<date>1983</date>
<booktitle>Research on Interactive Acquisition and Use of Knowledge. SRI Final Report 1894, SRI International,</booktitle>
<editor>In: Barbara Grosz and Mark Stickel, eds.,</editor>
<location>Menlo Park, California.</location>
<contexts>
<context position="13507" citStr="Shieber et al. 1983" startWordPosition="2229" endWordPosition="2232">eral preterminal edges extending from vertices , vr, respectively.9 Thus, n may here take the values insert, delete, or replace; ic is a pair of positions 1, r such that the sequence of positions 1, , r map directly to vertices , vr, and r is the corresponding sequence of words tut • • • wr. In addition, we will make use of the constant 6 = r — 1+ 1, denoting the number of words affected by the editing operation. 2.3.3 Grammatical Formalism In the algorithm below, as well as in the actual implementation, we have adopted a unification-based grammatical formalism with a context-free base, PATR (Shieber et al. 1983, Shieber 1986), because this seems to be the best candidate for a lingua franca in current natural-language processing. However, this formalism here shows up only within the edges, where we have an extra dag element (D), and when referring to rules, each of which consists of a °Character editing is processed by the scanner; cf. section 3.3. - 243 - pair (X0 —■ D) of a production and a dag. In the dag representation of the rule, we will store the context-free base under cat features as usual. We assume that the grammar is cycle-free. 2.4 An Algorithm for Incremental Chart Parsing 2.4.1 Introdu</context>
</contexts>
<marker>Shieber, Uszkoreit, Pereira, Robinson, Tyson, 1983</marker>
<rawString>Shieber, Stuart M., Hans Uszkoreit, Fernando C. N. Pereira, Jane J. Robinson, and Mabry Tyson (1983). The Formalism and Implementation of PATR-II. In: Barbara Grosz and Mark Stickel, eds., Research on Interactive Acquisition and Use of Knowledge. SRI Final Report 1894, SRI International, Menlo Park, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Thompson</author>
</authors>
<title>Chart Parsing and Rule Schemata in GPSG.</title>
<date>1981</date>
<booktitle>Proc. 19th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<tech>Research Paper No. 165,</tech>
<pages>167--172</pages>
<institution>Department of Artificial Intelligence, University of Edinburgh,</institution>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="8719" citStr="Thompson (1981" startWordPosition="1366" endWordPosition="1367">ng the latter &amp;Iv Thus, an edge formed through a prediction step d( pends on the (one) edge that triggered it.4 Likewis( an edge formed through a combination3 depends o the active—inactive edge pair that generated it. scanned edge, on the other hand, does not depen upon any other edge, as scanning can be seen as kind of initialization of the chart.6 In order to account for edge dependencies we assc ciate with each edge the set of its immediate sourc 4In the case of an initial top-down prediction, the sour&lt; would be non-existent. 6The completer operation in Earley (1970); the fundament rule in Thompson (1981:2). 6It might be argued that a dependency should be estal lished also in the case of an edge being proposed but rejecte (owing to a redundancy test) because it already exists. Hoy ever, as long as updates affect all preterminal edges extendir from a vertex, this appears not to be crucial. - 242 - edges (&amp;quot;back pointers&amp;quot;). This information could be used to derive the corresponding sets of dependent edges (&amp;quot;forward pointers&amp;quot;) that we are interested in. For example, when a word in the previous input has been deleted, we want to remove all edges which depend on the preterminal (lexical) edge(s) co</context>
</contexts>
<marker>Thompson, 1981</marker>
<rawString>Thompson, Henry (1981). Chart Parsing and Rule Schemata in GPSG. Research Paper No. 165, Department of Artificial Intelligence, University of Edinburgh, Edinburgh, Scotland. Also in: Proc. 19th Annual Meeting of the Association for Computational Linguistics, Stanford, California: 167-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henry Thompson</author>
<author>Graeme Ritchie</author>
</authors>
<title>Implementing Natural Language Parsers. In: Tim O&apos;Shea and Marc Eisenstadt,</title>
<date>1984</date>
<booktitle>Artificial Intelligence: Tools, Techniques, and Applications. Harper &amp; Row,</booktitle>
<pages>245--300</pages>
<location>New York, New York:</location>
<contexts>
<context position="7224" citStr="Thompson and Ritchie 1984" startWordPosition="1115" endWordPosition="1118">sentence, the system has to reparse exhaustively from this update and on. (Of course, in reality the user has to first backspace and then retype everything from the change.) 1.4 Outline of Paper Section 2 presents an algorithm for incremental char parsing. Section 3 discusses some additional aspect and alternative strategies. Section 4 gives a brie outline of the combined interactive and incrementa parsing system, and section 5 summarizes the con clusions. 2 Incremental Chart Parsing 2.1 Chart Parsing The incremental parser has been grounded in chart-parsing framework (Kay 1980, Thompso 1981, Thompson and Ritchie 1984) for the follow ing reasons: • chart parsing is an efficient, open-ended, we understood, and frequently adopted techniqu in natural-language processing; • chart parsing gives us a previously unexplorei possibility of embedding incrementality at a loi cost. 2.2 Edge Dependencies The idea of incremental chart parsing, as put foi ward here, is based on the following observatior The chart, while constituting a record of partia analyses (chart edges), may easily be provided wit information also about the dependencies betwee those analyses. This is just what we need in in cremental parsing since we </context>
</contexts>
<marker>Thompson, Ritchie, 1984</marker>
<rawString>Thompson, Henry and Graeme Ritchie (1984). Implementing Natural Language Parsers. In: Tim O&apos;Shea and Marc Eisenstadt, Artificial Intelligence: Tools, Techniques, and Applications. Harper &amp; Row, New York, New York: 245-300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaru Tomita</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm for Natural Languages.</title>
<date>1985</date>
<booktitle>Proc. Ninth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>756--764</pages>
<location>Los Angeles, California:</location>
<contexts>
<context position="5585" citStr="Tomita (1985)" startWordPosition="871" endWordPosition="872">set of new input, thereby achieving enhanced efficiency as well as a potential for dynamic improvement of its performance, for example by promptly reporting errors, asking for clarifications, etc.2 Within the area of programming environments, (generators for) language-based editors have been developed that make use of interactive (and incremental) parsing and compilation to perform program analysis, to report errors, and to generate code while the program is being edited, for example Mentor, Gandalf, and the Synthesizer Generator (Reps and Teitelbaum 1987). Within natural-language processing, Tomita (1985) and Yonezawa and Ohsawa (1988) have reported parsers which operate on-line, but, incidentally, not incrementally in the sense adopted here.3 1This definition is formed partly in analogy with a definition of &amp;quot;incremental compilation&amp;quot; by Earley and Caizergues (1972:1040). We use &amp;quot;complexity&amp;quot; instead of &amp;quot;size&amp;quot; because different updates of the same size may cause differing processing efforts depending on the degree of grammatical complexity (ambiguity, context-sensitiveness) constraining the updates in question. 2Incidentally, interactive parsing could be seen as one example of a general trend to</context>
</contexts>
<marker>Tomita, 1985</marker>
<rawString>Tomita, Masaru (1985). An Efficient Context-Free Parsing Algorithm for Natural Languages. Proc. Ninth International Joint Conference on Artificial Intelligence, Los Angeles, California: 756-764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yonezawa</author>
</authors>
<title>Akinori and Ichiro Ohsawa</title>
<date>1988</date>
<booktitle>Proc. 12th International Conference on Computational Linguistics,</booktitle>
<pages>773--778</pages>
<location>Budapest, Hungary:</location>
<marker>Yonezawa, 1988</marker>
<rawString>Yonezawa, Akinori and Ichiro Ohsawa (1988). Object-Oriented Parallel Parsing for Context-Free Grammars. Proc. 12th International Conference on Computational Linguistics, Budapest, Hungary: 773-778.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Wiren</author>
</authors>
<title>A Control-Strategy-Independent Parser for PATR.</title>
<date>1988</date>
<booktitle>Proc. First Scandinavian Conference on Artificial Intelligence,</booktitle>
<pages>161--172</pages>
<institution>Department of Computer and Information Science, LinkOping University, Linkoping, Sweden.</institution>
<location>Tromso, Norway:</location>
<note>Also research report LiTH-IDA-R88-10,</note>
<marker>Wiren, 1988</marker>
<rawString>Wiren, Mats (1988). A Control-Strategy-Independent Parser for PATR. Proc. First Scandinavian Conference on Artificial Intelligence, Tromso, Norway: 161-172. Also research report LiTH-IDA-R88-10, Department of Computer and Information Science, LinkOping University, Linkoping, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uri Zernik</author>
<author>Allen Brown</author>
</authors>
<title>Default Reasoning in Natural Language Processing.</title>
<date>1988</date>
<booktitle>Proc. 12th International Conference on Computational Linguistics,</booktitle>
<pages>801--805</pages>
<location>Budapest, Hungary:</location>
<contexts>
<context position="27830" citStr="Zernik and Brown (1988)" startWordPosition="4735" endWordPosition="4738"> torn down. The salmon jumped. It likes to play. In the first example, changing the number of &amp;quot;house&amp;quot; forces several grammatical changes in the subsequent sentences, requiring reanalysis. In the second example, changing &amp;quot;it (likes)&amp;quot; to &amp;quot;they (like)&amp;quot; constrains the noun-phrase of the previous sentence to be interpreted as plural, which could be reflected for example by putting the edges of the singular analysis to sleep. Cross-sentence dependencies require a level of incremental interpretation and a database with nonmonotonic reasoning capabilities. For a recent approach in this direction, see Zernik and Brown (1988). 4 Interactive Parsing This section outlines how the incremental parser is embedded in an interactive parsing system, called LIP3.15 Figure 1 shows the main components of the system. The user types a sentence into the editor (a Xerox T EDIT text editor). The words are analysed on-line by the scanner and handed over to the parser proper which keeps the chart consistent with the input sentence. Unknown words are marked as illegal in the edit window. The system displays the chart incrementally, drawing and erasing individual edges in tandem with the parsing process. &amp;quot;Linkoping Interactive Parsin</context>
</contexts>
<marker>Zernik, Brown, 1988</marker>
<rawString>Zernik, Uri and Allen Brown (1988). Default Reasoning in Natural Language Processing. Proc. 12th International Conference on Computational Linguistics, Budapest, Hungary: 801-805.</rawString>
</citation>
<citation valid="false">
<pages>248</pages>
<marker></marker>
<rawString>- 248 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>