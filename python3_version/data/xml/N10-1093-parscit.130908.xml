<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012439">
<title confidence="0.988014">
Improving Data Driven Dependency Parsing using Clausal Information
</title>
<author confidence="0.988966">
Phani Gadde, Karan Jindal, Samar Husain, Dipti Misra Sharma, Rajeev Sangal
</author>
<affiliation confidence="0.969975">
Language Technologies Research Centre, IIIT-Hyderabad, India.
</affiliation>
<email confidence="0.8389865">
phani.gadde@research.iiit.ac.in, karan_jindal@students.iiit.ac.in,
{samar,dipti,sangal}@mail.iiit.ac.in
</email>
<sectionHeader confidence="0.992991" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997162">
The paper describes a data driven dependency
parsing approach which uses clausal informa-
tion of a sentence to improve the parser per-
formance. The clausal information is added
automatically during the parsing process. We
demonstrate the experiments on Hindi, a lan-
guage with relatively rich case marking sys-
tem and free-word-order. All the experiments
are done using a modified version of
MSTParser. We did all the experiments on the
ICON 2009 parsing contest data. We achieved
an improvement of 0.87% and 0.77% in unla-
beled attachment and labeled attachment accu-
racies respectively over the baseline parsing
accuracies.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999915326530612">
Linguistic analysis of morphologically rich free-
word-order languages (MoRFWO) using depen-
dency framework have been argued to be more
effective (Shieber, 1985; Mel’čuk, 1988, Bharati et
al., 1993). Not surprisingly, most parsers for such
languages are dependency based (Nivre et al.,
2007a; Bharati et al., 2008a; Hall et al., 2007). In
spite of availability of annotated treebanks, state-
of-the-art parsers for MoRFWO have not reached
the performance obtained for English. Some of the
reasons stated for the low performance are small
treebank size, complex linguistic phenomenon,
long-distance dependencies, and non-projective
structures (Nivre et al., 2007a, 2007b; Bharati et
al., 2008a).
Several approaches have been tried to handle these
difficulties in such languages. For Hindi, Bharati et
al. (2008a) and Ambati et al. (2009) used semantic
features in parsing to reduce the negative impact of
unavailable syntactic features and showed that use
of minimal semantics can help in identifying cer-
tain core dependency labels. Various attempts have
proved to simplify the structure by dividing the
sentence into suitable linguistic units (Attardi and
Dell’Orletta 2008; Bharati et al., 1993, 2008b,
2009; Husain et al., 2009). These approaches han-
dle complex structures by breaking the parsing
process into several steps. Attardi and Dell&apos;Orletta
(2008) used chunk information as a feature to
MaltParser (Nivre et al., 2007a) for parsing Eng-
lish. Bharati et al., 1993 used the notion of local
word groups, while Bharati et al., 2009 and Husain
et al., 2009 used clauses.
In this paper, we describe a data driven depen-
dency parsing approach which uses clausal infor-
mation of a sentence to improve the parser
performance. Previous attempts at data driven
parsing for Hindi have failed to exploit this feature
explicitly. The clausal information is added auto-
matically during the parsing process. We demon-
strate the experiments on Hindi1. All the
experiments are done using a modified version of
MSTParser (McDonald et al., 2005a and the refer-
ences therein) (henceforth MST) on the ICON
2009 parsing contest2 (Husain, 2009) data. We
achieved an improvement of 0.87% and 0.77% in
unlabeled attachment and labeled attachment accu-
racies respectively over the baseline parsing accu-
racies.
</bodyText>
<footnote confidence="0.99868475">
1 Hindi is a verb final language with free word order and a rich
case marking system. It is an official language of India and is
spoken by ~800 million people.
2 http://www.icon2009.in/contests.html
</footnote>
<page confidence="0.924615">
657
</page>
<subsubsectionHeader confidence="0.462545">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 657–660,
</subsubsectionHeader>
<subsectionHeader confidence="0.095487">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.960091428571428">
2 Why Clausal Information? number, person, vibhakti3 or TAM4 markers of the
node
Traditionally, a clause is defined as a group of
words having a subject and a predicate. Clause
boundary identification is the process of dividing
the given sentence into a set of clauses. It can be
seen as a partial parsing step after chunking, in
which one tries to divide the sentence into mea-
ningful units. It is evident that most of the depen-
dents of words in a clause appear inside the same
clause; in other words the dependencies of the
words in a clause are mostly localized within the
clause boundary.
In the dependency parsing task, a parser has to
disambiguate between several words in the sen-
tence to find the parent/child of a particular word.
This work is to see whether the clause boundary
information can help the parser to reduce the
search space when it is trying to find the correct
parent/child for a word. The search space of the
parser can be reduced by a large extent if we solve
a relatively small problem of identifying the claus-
es. Interestingly, it has been shown recently that
most of the non-projective cases in Hindi are inter-
clausal (Mannem et al., 2009). Identifying clausal
boundaries, therefore, should prove to be helpful in
parsing non-projective structures. The same holds
true for many long-distance dependencies.
</bodyText>
<sectionHeader confidence="0.996148" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.976944">
3.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999991411764706">
The experiments reported in this paper have been
done on Hindi; the data was released as part of the
ICON 2009 parsing contest (Husain, 2009). The
sentences used for this contest are subset of the
Hyderabad Dependency Treebank (HyDT) devel-
oped for Hindi (Begum et al., 2008). The depen-
dency relations in the treebank are syntactico-
semantic. The dependency tagset in the annotation
scheme has around 28 relations. The dependency
trees in the treebank show relations between chunk
heads. Note, therefore, that the experiments and
results described in this paper are based on parse
trees that have chunk head as nodes.
The data provided in the task contained morpho-
logical features along with the lemma, POS tag,
and coarse POS tag, for each word. These are six
morphological features namely category, gender,
</bodyText>
<subsectionHeader confidence="0.999719">
3.2 Clause Boundary Identifier
</subsectionHeader>
<bodyText confidence="0.999989972222222">
We used the Stage15 parser of Husain et al. (2009),
to provide the clause boundary information that is
then incorporated as features during the actual
parsing process. The Stage1 parser uses MST to
identify just the intra-clausal relations. To achieve
this, Husain et al., introduce a special dummy node
named _ROOT_ which becomes the head of the
sentence. All the clauses are connected to this
dummy node with a dummy relation. In effect the
Stage1 parser gives only intra-clausal relations. In
the current work, we used MaltParser6 (Nivre et al.,
2007b) (henceforth Malt) to do this task. This is
because Malt performs better than MST in case of
intra-clausal relations, which are mostly short dis-
tance dependencies. We use the same algorithm
and feature setting of Bharati et al., (2008a) to train
the Stage1 parser.
Since the above tool parses clauses, therefore
along with the clause boundary information we
also know the root of the clausal sub-tree. Several
experiments were done to identify the most optim-
al set of clausal features available from the partial
parse. The best results are obtained when the
clause boundary information, along with the head
information i.e. head node of a clause, is given as a
feature to each node.
We trained the Stage1 parser by converting the
treebank data into the stage1 format, following the
steps that were given in Husain et al. (2009). This
conversion depends on the definition of the clause.
We experimented with different definitions of
clause in order to tune the tool to give the optimal
clause boundary and head information required for
parsing. For the results reported in this paper, a
clause is a sequence of words, with a single verb,
unless the verb is a child of another verb.
</bodyText>
<footnote confidence="0.83520125">
3 Vibhakti is a generic term for preposition, post-position and
suffix.
4TAM: Tense, Aspect and Modality.
5Stage1 handles intra-clausal dependency relations. These
relations generally correspond to the argument structure of the
verb, noun-noun genitive relation, infinitive-noun relation,
adjective-noun, adverb-verb relations, etc.
6 Malt version 1.2
</footnote>
<page confidence="0.975093">
658
</page>
<table confidence="0.999907">
Precision Recall one clause and each verb in the sentence has its
own argument structure. We achieved the best per-
formance by using both as features (F4) during the
parsing process.
Clause Boundary 84.83% 91.23%
Head Information 92.42% 99.40%
</table>
<tableCaption confidence="0.999958">
Table 1. Accuracies of the features being used
</tableCaption>
<bodyText confidence="0.992355454545455">
Table 1 gives the accuracy of the clausal informa-
tion being used as features in parsing. It is clear
from Table1 that the tool being used doesn’t have
very high clause boundary identification perfor-
mance; nevertheless, the performance is sufficient
enough to make an improvement in parsing expe-
riments. On the other hand, the head of the clause
(or, the root head in the clausal sub-tree) is identi-
fied efficiently. All the above experiments for pa-
rameter tuning were done on the development data
of the ICON 2009 parsing contest.
</bodyText>
<subsectionHeader confidence="0.975535">
3.3 Parser
</subsectionHeader>
<bodyText confidence="0.996367545454546">
We used MSTParser7 for the actual parsing step.
MST uses Chu-Liu-Edmonds Maximum Spanning
Tree Algorithm for non-projective parsing and
Eisner&apos;s algorithm for projective parsing (Eisner,
1996). It uses online large margin learning as the
learning algorithm (McDonald et al., 2005b).
We modified MST so that it uses the clause
boundary. Unlike the normal features that MST
uses, the clause boundary features span across
many words.
.
</bodyText>
<sectionHeader confidence="0.997652" genericHeader="method">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999867866666667">
We experimented with different combinations of
the information provided in the data (as mentioned
in 3.1). Vibhakti and TAM fields gave better re-
sults than others. This is consistent with the best
previous settings for Hindi parsing (Bharati et al.,
2008a, Ambati et al., 2009). We used the results
obtained using this setting as our baseline (F1).
We first experimented by giving only the clause
inclusion (boundary) information to each node
(F2). This feature should help the parser reduce its
search space during parsing decisions. Then, we
provided only the head and non-head information
(whether that node is the head of the clause or not)
(F3). The head or non-head information helps in
handling complex sentences that have more than
</bodyText>
<page confidence="0.891079">
7 MST version 0.4b
</page>
<table confidence="0.9998206">
LA (%) UA (%) L (%)
F1 73.62 91.00 76.04
F2 72.66 91.00 74.74
F3 73.88 91.35 75.78
F4 74.39 91.87 76.21
</table>
<tableCaption confidence="0.999929">
Table 2. Parsing accuracies with different features
</tableCaption>
<bodyText confidence="0.9832612">
Table 2 gives the results for all the settings. It is
interesting to note that the boundary information
(F1) alone does not cross the baseline; however
this feature is reliable enough to give the best per-
formance when combined with F3.
</bodyText>
<sectionHeader confidence="0.996355" genericHeader="method">
5 Observations
</sectionHeader>
<bodyText confidence="0.998584538461538">
We see from the above results (F4 in Table 2) that
there is a rise of 0.87% in UA (unlabeled
attachment) and 0.77% in LA (labeled attachment)
over previous best (F1). This shows the positive
effect of using the clausal information during the
parsing process.
We analyzed the performance of both the pars-
ers in handling the long distance dependencies and
non-projective dependencies. We found that the
non-projective arcs handled by F4 have a precision
and recall of 41.1% and 50% respectively for UA,
compared to 30.5% and 39.2% for the same arcs
during F1.
</bodyText>
<figureCaption confidence="0.95871">
Figure 1 compares the accuracies of the depen-
dencies at various distances. It is clear that the ef-
fect of clausal information become more
Figure 1. Distance stats
</figureCaption>
<page confidence="0.997543">
659
</page>
<bodyText confidence="0.999">
pronounced as the distance increases. This means
F4 does help the parser in effectively handling long
distance dependencies as well.
</bodyText>
<sectionHeader confidence="0.954061" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999965631578947">
The results show that there is a significant
improvement in the parsing accuracy when the
clausal information is being used.
The clausal information is presently being used
only as attachment features in MST. Experiments
can be done in future, to find out if there is a label
bias to the clause boundary, which also helps in
reducing the search space for specific labels. Im-
proving the feature set for the labeled parse also
improves the unlabeled attachment accuracy, as
MST does attachments and labels in a single step,
and the labels of processed nodes will also be tak-
en in features.
We can see from Table1 that the precision of the
clause boundary is 84.83%. Using a tool, targeted
at getting just the clausal information, instead of
using a parser can improve the accuracy of the
clausal information, which helps improving pars-
ing.
</bodyText>
<sectionHeader confidence="0.998111" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992529125">
B. R. Ambati, P. Gadde, and K. Jindal. 2009. Experi-
ments in Indian Language Dependency Parsing. In
Proceedings of the ICON09 NLP Tools Contest: In-
dian Language Dependency Parsing, pp 32-37.
B. R. Ambati, P. Gade and C. GSK. 2009. Effect ofMi-
nimal Semantics on Dependency Parsing. In the Pro-
ceedings of RANLP 2009 Student Research
Workshop.
G. Attardi and F. Dell’Orletta. Chunking and Depen-
dency Parsing. LREC Workshop on Partial Parsing:
Between Chunking and Deep Parsing. Marrakech,
Morocco. 2008.
R. Begum, S. Husain, A. Dhwaj, D. Sharma, L. Bai, and
R. Sangal. 2008. Dependency annotation scheme for
Indian languages. In Proceedings of IJCNLP-2008.
A. Bharati and R. Sangal. 1993. Parsing Free Word Or-
der Languages in the Paninian Framework. Proceed-
ings of ACL:93.
A. Bharati, S. Husain, B. Ambati, S. Jain, D. Sharma
and R. Sangal. 2008a. Two Semantic features make
all the difference in Parsing accuracy. In Proceed-
ings. of International Conference on Natural Lan-
guage Processing-2008.
A. Bharati, S. Husain, D. Sharma, and R. Sangal. 2008b.
A two stage constraint based dependency parser for
free word order languages. In Proceedings. of
COLIPS International Conference on Asian Lan-
guage Processing. Thailand. 2008.
A. Bharati, S. Husain, D. M. Sharma and R. Sangal.
Two stage constraint based hybrid approach to free
word order language dependency parsing. In the Pro-
ceedings of the 11th International Conference on
Parsing Technologies (IWPT09). Paris. 2009.
J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi, M.
Nilsson,M. Saers.2007. Single Malt or Blended? A
Study in Multilingual Parser Optimization.
In Proceedings of the CoNLL Shared Task Session of
EMNLP-CoNLL 2007.
S. Husain. 2009. Dependency Parsers for Indian Lan-
guages. In Proceedings of ICON09 NLP Tools Con-
test:Indian Language Dependency Parsing.
Hyderabad, India. 2009.
S. Husain, P. Gadde, B. Ambati, D. M. Sharma and Ra-
jeev Sangal. 2009. A modular cascaded approach to
complete parsing. In the Proceedings of COLIPS In-
ternational Conference on Asian Language
Processing. Singapore. 2009.
P. Mannem and H. Chaudhry.2009. Insights into Non-
projectivity in Hindi. In ACL-IJCNLP Student paper
workshop. 2009.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic.
2005a. Non-projective dependency parsing using
spanning tree algorithms. In the Proceedings of
HLT/EMNLP, pp. 523–530.
R. McDonald, K. Crammer, and F. Pereira. 2005b. On-
line large-margin training of dependency parsers. In
the Proceedings of ACL 2005. pp. 91–98.
I. A. Mel&apos;Cuk. 1988. Dependency Syntax: Theory and
Practice, State University Press of New York.
J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S.
Riedel and D. Yuret. 2007a. The CoNLL 2007
Shared Task on Dependency Parsing. In Proceedings
of the CoNLL Shared Task Session of EMNLP-
CoNLL 2007.
J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S.
Kübler, S. Marinov and E Marsi. 2007b. MaltParser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(2), 95-135.
S. M. Shieber. 1985. Evidence against the context-
freeness of natural language. In Linguistics and Phi-
losophy, p. 8, 334–343.
</reference>
<page confidence="0.996871">
660
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.539822">
<title confidence="0.99973">Improving Data Driven Dependency Parsing using Clausal Information</title>
<author confidence="0.980806">Phani Gadde</author>
<author confidence="0.980806">Karan Jindal</author>
<author confidence="0.980806">Samar Husain</author>
<author confidence="0.980806">Dipti Misra Sharma</author>
<author confidence="0.980806">Rajeev</author>
<affiliation confidence="0.816604">Language Technologies Research Centre, IIIT-Hyderabad,</affiliation>
<email confidence="0.809139">phani.gadde@research.iiit.ac.in,{samar,dipti,sangal}@mail.iiit.ac.in</email>
<abstract confidence="0.998722375">The paper describes a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance. The clausal information is added automatically during the parsing process. We demonstrate the experiments on Hindi, a language with relatively rich case marking system and free-word-order. All the experiments are done using a modified version of MSTParser. We did all the experiments on the ICON 2009 parsing contest data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B R Ambati</author>
<author>P Gadde</author>
<author>K Jindal</author>
</authors>
<title>Experiments in Indian Language Dependency Parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing,</booktitle>
<pages>32--37</pages>
<contexts>
<context position="1783" citStr="Ambati et al. (2009)" startWordPosition="247" endWordPosition="250">ly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negative impact of unavailable syntactic features and showed that use of minimal semantics can help in identifying certain core dependency labels. Various attempts have proved to simplify the structure by dividing the sentence into suitable linguistic units (Attardi and Dell’Orletta 2008; Bharati et al., 1993, 2008b, 2009; Husain et al., 2009). These approaches handle complex structures by breaking the parsing process into several steps. Attardi and Dell&apos;Orletta (2008) used chunk information as a feature to MaltParser (Nivre et al., 2007a) for p</context>
<context position="9499" citStr="Ambati et al., 2009" startWordPosition="1497" endWordPosition="1500">jective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005b). We modified MST so that it uses the clause boundary. Unlike the normal features that MST uses, the clause boundary features span across many words. . 4 Experiments and Results We experimented with different combinations of the information provided in the data (as mentioned in 3.1). Vibhakti and TAM fields gave better results than others. This is consistent with the best previous settings for Hindi parsing (Bharati et al., 2008a, Ambati et al., 2009). We used the results obtained using this setting as our baseline (F1). We first experimented by giving only the clause inclusion (boundary) information to each node (F2). This feature should help the parser reduce its search space during parsing decisions. Then, we provided only the head and non-head information (whether that node is the head of the clause or not) (F3). The head or non-head information helps in handling complex sentences that have more than 7 MST version 0.4b LA (%) UA (%) L (%) F1 73.62 91.00 76.04 F2 72.66 91.00 74.74 F3 73.88 91.35 75.78 F4 74.39 91.87 76.21 Table 2. Parsi</context>
</contexts>
<marker>Ambati, Gadde, Jindal, 2009</marker>
<rawString>B. R. Ambati, P. Gadde, and K. Jindal. 2009. Experiments in Indian Language Dependency Parsing. In Proceedings of the ICON09 NLP Tools Contest: Indian Language Dependency Parsing, pp 32-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B R Ambati</author>
<author>P Gade</author>
<author>C GSK</author>
</authors>
<title>Effect ofMinimal Semantics on Dependency Parsing.</title>
<date>2009</date>
<booktitle>In the Proceedings of RANLP 2009 Student Research Workshop.</booktitle>
<contexts>
<context position="1783" citStr="Ambati et al. (2009)" startWordPosition="247" endWordPosition="250">ly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negative impact of unavailable syntactic features and showed that use of minimal semantics can help in identifying certain core dependency labels. Various attempts have proved to simplify the structure by dividing the sentence into suitable linguistic units (Attardi and Dell’Orletta 2008; Bharati et al., 1993, 2008b, 2009; Husain et al., 2009). These approaches handle complex structures by breaking the parsing process into several steps. Attardi and Dell&apos;Orletta (2008) used chunk information as a feature to MaltParser (Nivre et al., 2007a) for p</context>
<context position="9499" citStr="Ambati et al., 2009" startWordPosition="1497" endWordPosition="1500">jective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005b). We modified MST so that it uses the clause boundary. Unlike the normal features that MST uses, the clause boundary features span across many words. . 4 Experiments and Results We experimented with different combinations of the information provided in the data (as mentioned in 3.1). Vibhakti and TAM fields gave better results than others. This is consistent with the best previous settings for Hindi parsing (Bharati et al., 2008a, Ambati et al., 2009). We used the results obtained using this setting as our baseline (F1). We first experimented by giving only the clause inclusion (boundary) information to each node (F2). This feature should help the parser reduce its search space during parsing decisions. Then, we provided only the head and non-head information (whether that node is the head of the clause or not) (F3). The head or non-head information helps in handling complex sentences that have more than 7 MST version 0.4b LA (%) UA (%) L (%) F1 73.62 91.00 76.04 F2 72.66 91.00 74.74 F3 73.88 91.35 75.78 F4 74.39 91.87 76.21 Table 2. Parsi</context>
</contexts>
<marker>Ambati, Gade, GSK, 2009</marker>
<rawString>B. R. Ambati, P. Gade and C. GSK. 2009. Effect ofMinimal Semantics on Dependency Parsing. In the Proceedings of RANLP 2009 Student Research Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Attardi</author>
<author>F Dell’Orletta</author>
</authors>
<title>Chunking and Dependency Parsing.</title>
<date>2008</date>
<booktitle>LREC Workshop on Partial Parsing: Between Chunking and Deep Parsing.</booktitle>
<location>Marrakech,</location>
<marker>Attardi, Dell’Orletta, 2008</marker>
<rawString>G. Attardi and F. Dell’Orletta. Chunking and Dependency Parsing. LREC Workshop on Partial Parsing: Between Chunking and Deep Parsing. Marrakech, Morocco. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Begum</author>
<author>S Husain</author>
<author>A Dhwaj</author>
<author>D Sharma</author>
<author>L Bai</author>
<author>R Sangal</author>
</authors>
<title>Dependency annotation scheme for Indian languages.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCNLP-2008.</booktitle>
<contexts>
<context position="5275" citStr="Begum et al., 2008" startWordPosition="817" endWordPosition="820">ying the clauses. Interestingly, it has been shown recently that most of the non-projective cases in Hindi are interclausal (Mannem et al., 2009). Identifying clausal boundaries, therefore, should prove to be helpful in parsing non-projective structures. The same holds true for many long-distance dependencies. 3 Experimental Setup 3.1 Dataset The experiments reported in this paper have been done on Hindi; the data was released as part of the ICON 2009 parsing contest (Husain, 2009). The sentences used for this contest are subset of the Hyderabad Dependency Treebank (HyDT) developed for Hindi (Begum et al., 2008). The dependency relations in the treebank are syntacticosemantic. The dependency tagset in the annotation scheme has around 28 relations. The dependency trees in the treebank show relations between chunk heads. Note, therefore, that the experiments and results described in this paper are based on parse trees that have chunk head as nodes. The data provided in the task contained morphological features along with the lemma, POS tag, and coarse POS tag, for each word. These are six morphological features namely category, gender, 3.2 Clause Boundary Identifier We used the Stage15 parser of Husain</context>
</contexts>
<marker>Begum, Husain, Dhwaj, Sharma, Bai, Sangal, 2008</marker>
<rawString>R. Begum, S. Husain, A. Dhwaj, D. Sharma, L. Bai, and R. Sangal. 2008. Dependency annotation scheme for Indian languages. In Proceedings of IJCNLP-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>R Sangal</author>
</authors>
<title>Parsing Free Word Order Languages in the Paninian Framework.</title>
<date>1993</date>
<booktitle>Proceedings of ACL:93.</booktitle>
<marker>Bharati, Sangal, 1993</marker>
<rawString>A. Bharati and R. Sangal. 1993. Parsing Free Word Order Languages in the Paninian Framework. Proceedings of ACL:93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>S Husain</author>
<author>B Ambati</author>
<author>S Jain</author>
<author>D Sharma</author>
<author>R Sangal</author>
</authors>
<title>Two Semantic features make all the difference in Parsing accuracy.</title>
<date>2008</date>
<booktitle>In Proceedings. of International Conference on Natural Language Processing-2008.</booktitle>
<contexts>
<context position="1262" citStr="Bharati et al., 2008" startWordPosition="170" endWordPosition="173">rder. All the experiments are done using a modified version of MSTParser. We did all the experiments on the ICON 2009 parsing contest data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Introduction Linguistic analysis of morphologically rich freeword-order languages (MoRFWO) using dependency framework have been argued to be more effective (Shieber, 1985; Mel’čuk, 1988, Bharati et al., 1993). Not surprisingly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negative impact of unavailable</context>
<context position="6628" citStr="Bharati et al., (2008" startWordPosition="1036" endWordPosition="1039">The Stage1 parser uses MST to identify just the intra-clausal relations. To achieve this, Husain et al., introduce a special dummy node named _ROOT_ which becomes the head of the sentence. All the clauses are connected to this dummy node with a dummy relation. In effect the Stage1 parser gives only intra-clausal relations. In the current work, we used MaltParser6 (Nivre et al., 2007b) (henceforth Malt) to do this task. This is because Malt performs better than MST in case of intra-clausal relations, which are mostly short distance dependencies. We use the same algorithm and feature setting of Bharati et al., (2008a) to train the Stage1 parser. Since the above tool parses clauses, therefore along with the clause boundary information we also know the root of the clausal sub-tree. Several experiments were done to identify the most optimal set of clausal features available from the partial parse. The best results are obtained when the clause boundary information, along with the head information i.e. head node of a clause, is given as a feature to each node. We trained the Stage1 parser by converting the treebank data into the stage1 format, following the steps that were given in Husain et al. (2009). This </context>
<context position="9476" citStr="Bharati et al., 2008" startWordPosition="1493" endWordPosition="1496">e Algorithm for non-projective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005b). We modified MST so that it uses the clause boundary. Unlike the normal features that MST uses, the clause boundary features span across many words. . 4 Experiments and Results We experimented with different combinations of the information provided in the data (as mentioned in 3.1). Vibhakti and TAM fields gave better results than others. This is consistent with the best previous settings for Hindi parsing (Bharati et al., 2008a, Ambati et al., 2009). We used the results obtained using this setting as our baseline (F1). We first experimented by giving only the clause inclusion (boundary) information to each node (F2). This feature should help the parser reduce its search space during parsing decisions. Then, we provided only the head and non-head information (whether that node is the head of the clause or not) (F3). The head or non-head information helps in handling complex sentences that have more than 7 MST version 0.4b LA (%) UA (%) L (%) F1 73.62 91.00 76.04 F2 72.66 91.00 74.74 F3 73.88 91.35 75.78 F4 74.39 91.</context>
</contexts>
<marker>Bharati, Husain, Ambati, Jain, Sharma, Sangal, 2008</marker>
<rawString>A. Bharati, S. Husain, B. Ambati, S. Jain, D. Sharma and R. Sangal. 2008a. Two Semantic features make all the difference in Parsing accuracy. In Proceedings. of International Conference on Natural Language Processing-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>S Husain</author>
<author>D Sharma</author>
<author>R Sangal</author>
</authors>
<title>A two stage constraint based dependency parser for free word order languages.</title>
<date>2008</date>
<booktitle>In Proceedings. of COLIPS International Conference on Asian Language Processing.</booktitle>
<contexts>
<context position="1262" citStr="Bharati et al., 2008" startWordPosition="170" endWordPosition="173">rder. All the experiments are done using a modified version of MSTParser. We did all the experiments on the ICON 2009 parsing contest data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Introduction Linguistic analysis of morphologically rich freeword-order languages (MoRFWO) using dependency framework have been argued to be more effective (Shieber, 1985; Mel’čuk, 1988, Bharati et al., 1993). Not surprisingly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negative impact of unavailable</context>
<context position="6628" citStr="Bharati et al., (2008" startWordPosition="1036" endWordPosition="1039">The Stage1 parser uses MST to identify just the intra-clausal relations. To achieve this, Husain et al., introduce a special dummy node named _ROOT_ which becomes the head of the sentence. All the clauses are connected to this dummy node with a dummy relation. In effect the Stage1 parser gives only intra-clausal relations. In the current work, we used MaltParser6 (Nivre et al., 2007b) (henceforth Malt) to do this task. This is because Malt performs better than MST in case of intra-clausal relations, which are mostly short distance dependencies. We use the same algorithm and feature setting of Bharati et al., (2008a) to train the Stage1 parser. Since the above tool parses clauses, therefore along with the clause boundary information we also know the root of the clausal sub-tree. Several experiments were done to identify the most optimal set of clausal features available from the partial parse. The best results are obtained when the clause boundary information, along with the head information i.e. head node of a clause, is given as a feature to each node. We trained the Stage1 parser by converting the treebank data into the stage1 format, following the steps that were given in Husain et al. (2009). This </context>
<context position="9476" citStr="Bharati et al., 2008" startWordPosition="1493" endWordPosition="1496">e Algorithm for non-projective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005b). We modified MST so that it uses the clause boundary. Unlike the normal features that MST uses, the clause boundary features span across many words. . 4 Experiments and Results We experimented with different combinations of the information provided in the data (as mentioned in 3.1). Vibhakti and TAM fields gave better results than others. This is consistent with the best previous settings for Hindi parsing (Bharati et al., 2008a, Ambati et al., 2009). We used the results obtained using this setting as our baseline (F1). We first experimented by giving only the clause inclusion (boundary) information to each node (F2). This feature should help the parser reduce its search space during parsing decisions. Then, we provided only the head and non-head information (whether that node is the head of the clause or not) (F3). The head or non-head information helps in handling complex sentences that have more than 7 MST version 0.4b LA (%) UA (%) L (%) F1 73.62 91.00 76.04 F2 72.66 91.00 74.74 F3 73.88 91.35 75.78 F4 74.39 91.</context>
</contexts>
<marker>Bharati, Husain, Sharma, Sangal, 2008</marker>
<rawString>A. Bharati, S. Husain, D. Sharma, and R. Sangal. 2008b. A two stage constraint based dependency parser for free word order languages. In Proceedings. of COLIPS International Conference on Asian Language Processing. Thailand. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>S Husain</author>
<author>D M Sharma</author>
<author>R Sangal</author>
</authors>
<title>Two stage constraint based hybrid approach to free word order language dependency parsing.</title>
<date>2009</date>
<booktitle>In the Proceedings of the 11th International Conference on Parsing Technologies (IWPT09).</booktitle>
<location>Paris.</location>
<contexts>
<context position="2484" citStr="Bharati et al., 2009" startWordPosition="357" endWordPosition="360">yntactic features and showed that use of minimal semantics can help in identifying certain core dependency labels. Various attempts have proved to simplify the structure by dividing the sentence into suitable linguistic units (Attardi and Dell’Orletta 2008; Bharati et al., 1993, 2008b, 2009; Husain et al., 2009). These approaches handle complex structures by breaking the parsing process into several steps. Attardi and Dell&apos;Orletta (2008) used chunk information as a feature to MaltParser (Nivre et al., 2007a) for parsing English. Bharati et al., 1993 used the notion of local word groups, while Bharati et al., 2009 and Husain et al., 2009 used clauses. In this paper, we describe a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance. Previous attempts at data driven parsing for Hindi have failed to exploit this feature explicitly. The clausal information is added automatically during the parsing process. We demonstrate the experiments on Hindi1. All the experiments are done using a modified version of MSTParser (McDonald et al., 2005a and the references therein) (henceforth MST) on the ICON 2009 parsing contest2 (Husain, 2009) data. We ac</context>
</contexts>
<marker>Bharati, Husain, Sharma, Sangal, 2009</marker>
<rawString>A. Bharati, S. Husain, D. M. Sharma and R. Sangal. Two stage constraint based hybrid approach to free word order language dependency parsing. In the Proceedings of the 11th International Conference on Parsing Technologies (IWPT09). Paris. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hall</author>
<author>J Nilsson</author>
<author>J Nivre</author>
<author>G Eryigit</author>
<author>B Megyesi</author>
<author>M Nilsson</author>
<author>M Saers 2007</author>
</authors>
<title>Single Malt or Blended? A Study in Multilingual Parser Optimization.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<contexts>
<context position="1283" citStr="Hall et al., 2007" startWordPosition="174" endWordPosition="177">ts are done using a modified version of MSTParser. We did all the experiments on the ICON 2009 parsing contest data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Introduction Linguistic analysis of morphologically rich freeword-order languages (MoRFWO) using dependency framework have been argued to be more effective (Shieber, 1985; Mel’čuk, 1988, Bharati et al., 1993). Not surprisingly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negative impact of unavailable syntactic features a</context>
</contexts>
<marker>Hall, Nilsson, Nivre, Eryigit, Megyesi, Nilsson, 2007, 2007</marker>
<rawString>J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi, M. Nilsson,M. Saers.2007. Single Malt or Blended? A Study in Multilingual Parser Optimization. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Husain</author>
</authors>
<title>Dependency Parsers for Indian Languages.</title>
<date>2009</date>
<booktitle>In Proceedings of ICON09 NLP Tools Contest:Indian Language Dependency Parsing.</booktitle>
<location>Hyderabad,</location>
<contexts>
<context position="3072" citStr="Husain, 2009" startWordPosition="454" endWordPosition="455">hile Bharati et al., 2009 and Husain et al., 2009 used clauses. In this paper, we describe a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance. Previous attempts at data driven parsing for Hindi have failed to exploit this feature explicitly. The clausal information is added automatically during the parsing process. We demonstrate the experiments on Hindi1. All the experiments are done using a modified version of MSTParser (McDonald et al., 2005a and the references therein) (henceforth MST) on the ICON 2009 parsing contest2 (Husain, 2009) data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Hindi is a verb final language with free word order and a rich case marking system. It is an official language of India and is spoken by ~800 million people. 2 http://www.icon2009.in/contests.html 657 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 657–660, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics 2 Why Clausal Information? number, pe</context>
<context position="5142" citStr="Husain, 2009" startWordPosition="797" endWordPosition="798">d for a word. The search space of the parser can be reduced by a large extent if we solve a relatively small problem of identifying the clauses. Interestingly, it has been shown recently that most of the non-projective cases in Hindi are interclausal (Mannem et al., 2009). Identifying clausal boundaries, therefore, should prove to be helpful in parsing non-projective structures. The same holds true for many long-distance dependencies. 3 Experimental Setup 3.1 Dataset The experiments reported in this paper have been done on Hindi; the data was released as part of the ICON 2009 parsing contest (Husain, 2009). The sentences used for this contest are subset of the Hyderabad Dependency Treebank (HyDT) developed for Hindi (Begum et al., 2008). The dependency relations in the treebank are syntacticosemantic. The dependency tagset in the annotation scheme has around 28 relations. The dependency trees in the treebank show relations between chunk heads. Note, therefore, that the experiments and results described in this paper are based on parse trees that have chunk head as nodes. The data provided in the task contained morphological features along with the lemma, POS tag, and coarse POS tag, for each wo</context>
</contexts>
<marker>Husain, 2009</marker>
<rawString>S. Husain. 2009. Dependency Parsers for Indian Languages. In Proceedings of ICON09 NLP Tools Contest:Indian Language Dependency Parsing. Hyderabad, India. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Husain</author>
<author>P Gadde</author>
<author>B Ambati</author>
<author>D M Sharma</author>
<author>Rajeev Sangal</author>
</authors>
<title>A modular cascaded approach to complete parsing.</title>
<date>2009</date>
<booktitle>In the Proceedings of COLIPS International Conference on Asian Language Processing.</booktitle>
<contexts>
<context position="2177" citStr="Husain et al., 2009" startWordPosition="307" endWordPosition="310">, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negative impact of unavailable syntactic features and showed that use of minimal semantics can help in identifying certain core dependency labels. Various attempts have proved to simplify the structure by dividing the sentence into suitable linguistic units (Attardi and Dell’Orletta 2008; Bharati et al., 1993, 2008b, 2009; Husain et al., 2009). These approaches handle complex structures by breaking the parsing process into several steps. Attardi and Dell&apos;Orletta (2008) used chunk information as a feature to MaltParser (Nivre et al., 2007a) for parsing English. Bharati et al., 1993 used the notion of local word groups, while Bharati et al., 2009 and Husain et al., 2009 used clauses. In this paper, we describe a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance. Previous attempts at data driven parsing for Hindi have failed to exploit this feature explicitly. The cl</context>
<context position="5889" citStr="Husain et al. (2009)" startWordPosition="916" endWordPosition="919"> 2008). The dependency relations in the treebank are syntacticosemantic. The dependency tagset in the annotation scheme has around 28 relations. The dependency trees in the treebank show relations between chunk heads. Note, therefore, that the experiments and results described in this paper are based on parse trees that have chunk head as nodes. The data provided in the task contained morphological features along with the lemma, POS tag, and coarse POS tag, for each word. These are six morphological features namely category, gender, 3.2 Clause Boundary Identifier We used the Stage15 parser of Husain et al. (2009), to provide the clause boundary information that is then incorporated as features during the actual parsing process. The Stage1 parser uses MST to identify just the intra-clausal relations. To achieve this, Husain et al., introduce a special dummy node named _ROOT_ which becomes the head of the sentence. All the clauses are connected to this dummy node with a dummy relation. In effect the Stage1 parser gives only intra-clausal relations. In the current work, we used MaltParser6 (Nivre et al., 2007b) (henceforth Malt) to do this task. This is because Malt performs better than MST in case of in</context>
<context position="7221" citStr="Husain et al. (2009)" startWordPosition="1136" endWordPosition="1139">ng of Bharati et al., (2008a) to train the Stage1 parser. Since the above tool parses clauses, therefore along with the clause boundary information we also know the root of the clausal sub-tree. Several experiments were done to identify the most optimal set of clausal features available from the partial parse. The best results are obtained when the clause boundary information, along with the head information i.e. head node of a clause, is given as a feature to each node. We trained the Stage1 parser by converting the treebank data into the stage1 format, following the steps that were given in Husain et al. (2009). This conversion depends on the definition of the clause. We experimented with different definitions of clause in order to tune the tool to give the optimal clause boundary and head information required for parsing. For the results reported in this paper, a clause is a sequence of words, with a single verb, unless the verb is a child of another verb. 3 Vibhakti is a generic term for preposition, post-position and suffix. 4TAM: Tense, Aspect and Modality. 5Stage1 handles intra-clausal dependency relations. These relations generally correspond to the argument structure of the verb, noun-noun ge</context>
</contexts>
<marker>Husain, Gadde, Ambati, Sharma, Sangal, 2009</marker>
<rawString>S. Husain, P. Gadde, B. Ambati, D. M. Sharma and Rajeev Sangal. 2009. A modular cascaded approach to complete parsing. In the Proceedings of COLIPS International Conference on Asian Language Processing. Singapore. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Mannem</author>
<author>H Chaudhry 2009</author>
</authors>
<title>Insights into Nonprojectivity in Hindi.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP Student paper workshop.</booktitle>
<marker>Mannem, 2009, 2009</marker>
<rawString>P. Mannem and H. Chaudhry.2009. Insights into Nonprojectivity in Hindi. In ACL-IJCNLP Student paper workshop. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In the Proceedings of HLT/EMNLP,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="2977" citStr="McDonald et al., 2005" startWordPosition="437" endWordPosition="440">(Nivre et al., 2007a) for parsing English. Bharati et al., 1993 used the notion of local word groups, while Bharati et al., 2009 and Husain et al., 2009 used clauses. In this paper, we describe a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance. Previous attempts at data driven parsing for Hindi have failed to exploit this feature explicitly. The clausal information is added automatically during the parsing process. We demonstrate the experiments on Hindi1. All the experiments are done using a modified version of MSTParser (McDonald et al., 2005a and the references therein) (henceforth MST) on the ICON 2009 parsing contest2 (Husain, 2009) data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Hindi is a verb final language with free word order and a rich case marking system. It is an official language of India and is spoken by ~800 million people. 2 http://www.icon2009.in/contests.html 657 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 657–660, Los Angeles, California, Ju</context>
<context position="9042" citStr="McDonald et al., 2005" startWordPosition="1422" endWordPosition="1425">nce; nevertheless, the performance is sufficient enough to make an improvement in parsing experiments. On the other hand, the head of the clause (or, the root head in the clausal sub-tree) is identified efficiently. All the above experiments for parameter tuning were done on the development data of the ICON 2009 parsing contest. 3.3 Parser We used MSTParser7 for the actual parsing step. MST uses Chu-Liu-Edmonds Maximum Spanning Tree Algorithm for non-projective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005b). We modified MST so that it uses the clause boundary. Unlike the normal features that MST uses, the clause boundary features span across many words. . 4 Experiments and Results We experimented with different combinations of the information provided in the data (as mentioned in 3.1). Vibhakti and TAM fields gave better results than others. This is consistent with the best previous settings for Hindi parsing (Bharati et al., 2008a, Ambati et al., 2009). We used the results obtained using this setting as our baseline (F1). We first experimented by giving only the clause inclusion (boundary) in</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005a. Non-projective dependency parsing using spanning tree algorithms. In the Proceedings of HLT/EMNLP, pp. 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In the Proceedings of ACL</booktitle>
<pages>91--98</pages>
<contexts>
<context position="2977" citStr="McDonald et al., 2005" startWordPosition="437" endWordPosition="440">(Nivre et al., 2007a) for parsing English. Bharati et al., 1993 used the notion of local word groups, while Bharati et al., 2009 and Husain et al., 2009 used clauses. In this paper, we describe a data driven dependency parsing approach which uses clausal information of a sentence to improve the parser performance. Previous attempts at data driven parsing for Hindi have failed to exploit this feature explicitly. The clausal information is added automatically during the parsing process. We demonstrate the experiments on Hindi1. All the experiments are done using a modified version of MSTParser (McDonald et al., 2005a and the references therein) (henceforth MST) on the ICON 2009 parsing contest2 (Husain, 2009) data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Hindi is a verb final language with free word order and a rich case marking system. It is an official language of India and is spoken by ~800 million people. 2 http://www.icon2009.in/contests.html 657 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 657–660, Los Angeles, California, Ju</context>
<context position="9042" citStr="McDonald et al., 2005" startWordPosition="1422" endWordPosition="1425">nce; nevertheless, the performance is sufficient enough to make an improvement in parsing experiments. On the other hand, the head of the clause (or, the root head in the clausal sub-tree) is identified efficiently. All the above experiments for parameter tuning were done on the development data of the ICON 2009 parsing contest. 3.3 Parser We used MSTParser7 for the actual parsing step. MST uses Chu-Liu-Edmonds Maximum Spanning Tree Algorithm for non-projective parsing and Eisner&apos;s algorithm for projective parsing (Eisner, 1996). It uses online large margin learning as the learning algorithm (McDonald et al., 2005b). We modified MST so that it uses the clause boundary. Unlike the normal features that MST uses, the clause boundary features span across many words. . 4 Experiments and Results We experimented with different combinations of the information provided in the data (as mentioned in 3.1). Vibhakti and TAM fields gave better results than others. This is consistent with the best previous settings for Hindi parsing (Bharati et al., 2008a, Ambati et al., 2009). We used the results obtained using this setting as our baseline (F1). We first experimented by giving only the clause inclusion (boundary) in</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005b. Online large-margin training of dependency parsers. In the Proceedings of ACL 2005. pp. 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel&apos;Cuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice,</title>
<date>1988</date>
<publisher>State University Press of</publisher>
<location>New York.</location>
<marker>Mel&apos;Cuk, 1988</marker>
<rawString>I. A. Mel&apos;Cuk. 1988. Dependency Syntax: Theory and Practice, State University Press of New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S Kubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>Shared Task on Dependency Parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL</booktitle>
<contexts>
<context position="1239" citStr="Nivre et al., 2007" startWordPosition="166" endWordPosition="169">ystem and free-word-order. All the experiments are done using a modified version of MSTParser. We did all the experiments on the ICON 2009 parsing contest data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Introduction Linguistic analysis of morphologically rich freeword-order languages (MoRFWO) using dependency framework have been argued to be more effective (Shieber, 1985; Mel’čuk, 1988, Bharati et al., 1993). Not surprisingly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negativ</context>
<context position="6392" citStr="Nivre et al., 2007" startWordPosition="997" endWordPosition="1000">features namely category, gender, 3.2 Clause Boundary Identifier We used the Stage15 parser of Husain et al. (2009), to provide the clause boundary information that is then incorporated as features during the actual parsing process. The Stage1 parser uses MST to identify just the intra-clausal relations. To achieve this, Husain et al., introduce a special dummy node named _ROOT_ which becomes the head of the sentence. All the clauses are connected to this dummy node with a dummy relation. In effect the Stage1 parser gives only intra-clausal relations. In the current work, we used MaltParser6 (Nivre et al., 2007b) (henceforth Malt) to do this task. This is because Malt performs better than MST in case of intra-clausal relations, which are mostly short distance dependencies. We use the same algorithm and feature setting of Bharati et al., (2008a) to train the Stage1 parser. Since the above tool parses clauses, therefore along with the clause boundary information we also know the root of the clausal sub-tree. Several experiments were done to identify the most optimal set of clausal features available from the partial parse. The best results are obtained when the clause boundary information, along with </context>
</contexts>
<marker>Nivre, Hall, Kubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. Kubler, R. McDonald, J. Nilsson, S. Riedel and D. Yuret. 2007a. The CoNLL 2007 Shared Task on Dependency Parsing. In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>J Nilsson</author>
<author>A Chanev</author>
<author>G Eryigit</author>
<author>S Kübler</author>
<author>S Marinov</author>
<author>E Marsi</author>
</authors>
<title>MaltParser: A language-independent system for data-driven dependency parsing.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>2</issue>
<pages>95--135</pages>
<contexts>
<context position="1239" citStr="Nivre et al., 2007" startWordPosition="166" endWordPosition="169">ystem and free-word-order. All the experiments are done using a modified version of MSTParser. We did all the experiments on the ICON 2009 parsing contest data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Introduction Linguistic analysis of morphologically rich freeword-order languages (MoRFWO) using dependency framework have been argued to be more effective (Shieber, 1985; Mel’čuk, 1988, Bharati et al., 1993). Not surprisingly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in such languages. For Hindi, Bharati et al. (2008a) and Ambati et al. (2009) used semantic features in parsing to reduce the negativ</context>
<context position="6392" citStr="Nivre et al., 2007" startWordPosition="997" endWordPosition="1000">features namely category, gender, 3.2 Clause Boundary Identifier We used the Stage15 parser of Husain et al. (2009), to provide the clause boundary information that is then incorporated as features during the actual parsing process. The Stage1 parser uses MST to identify just the intra-clausal relations. To achieve this, Husain et al., introduce a special dummy node named _ROOT_ which becomes the head of the sentence. All the clauses are connected to this dummy node with a dummy relation. In effect the Stage1 parser gives only intra-clausal relations. In the current work, we used MaltParser6 (Nivre et al., 2007b) (henceforth Malt) to do this task. This is because Malt performs better than MST in case of intra-clausal relations, which are mostly short distance dependencies. We use the same algorithm and feature setting of Bharati et al., (2008a) to train the Stage1 parser. Since the above tool parses clauses, therefore along with the clause boundary information we also know the root of the clausal sub-tree. Several experiments were done to identify the most optimal set of clausal features available from the partial parse. The best results are obtained when the clause boundary information, along with </context>
</contexts>
<marker>Nivre, Hall, Nilsson, Chanev, Eryigit, Kübler, Marinov, Marsi, 2007</marker>
<rawString>J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S. Kübler, S. Marinov and E Marsi. 2007b. MaltParser: A language-independent system for data-driven dependency parsing. Natural Language Engineering, 13(2), 95-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Evidence against the contextfreeness of natural language.</title>
<date>1985</date>
<booktitle>In Linguistics and Philosophy,</booktitle>
<pages>8--334</pages>
<contexts>
<context position="1109" citStr="Shieber, 1985" startWordPosition="148" endWordPosition="149">matically during the parsing process. We demonstrate the experiments on Hindi, a language with relatively rich case marking system and free-word-order. All the experiments are done using a modified version of MSTParser. We did all the experiments on the ICON 2009 parsing contest data. We achieved an improvement of 0.87% and 0.77% in unlabeled attachment and labeled attachment accuracies respectively over the baseline parsing accuracies. 1 Introduction Linguistic analysis of morphologically rich freeword-order languages (MoRFWO) using dependency framework have been argued to be more effective (Shieber, 1985; Mel’čuk, 1988, Bharati et al., 1993). Not surprisingly, most parsers for such languages are dependency based (Nivre et al., 2007a; Bharati et al., 2008a; Hall et al., 2007). In spite of availability of annotated treebanks, stateof-the-art parsers for MoRFWO have not reached the performance obtained for English. Some of the reasons stated for the low performance are small treebank size, complex linguistic phenomenon, long-distance dependencies, and non-projective structures (Nivre et al., 2007a, 2007b; Bharati et al., 2008a). Several approaches have been tried to handle these difficulties in </context>
</contexts>
<marker>Shieber, 1985</marker>
<rawString>S. M. Shieber. 1985. Evidence against the contextfreeness of natural language. In Linguistics and Philosophy, p. 8, 334–343.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>