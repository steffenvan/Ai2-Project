<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.9986225">
Collaborative Decoding: Partial Hypothesis Re-ranking
Using Translation Consensus between Decoders
</title>
<author confidence="0.997066">
Mu Li1, Nan Duan2, Dongdong Zhang1, Chi-Ho Li1, Ming Zhou1
</author>
<affiliation confidence="0.976245">
1Microsoft Research Asia 2Tianjin University
</affiliation>
<address confidence="0.583274">
Beijing, China Tianjin, China
</address>
<email confidence="0.994901">
{muli,v-naduan,dozhang,chl,mingzhou}@microsoft.com
</email>
<sectionHeader confidence="0.994954" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999884476190476">
This paper presents collaborative decoding
(co-decoding), a new method to improve ma-
chine translation accuracy by leveraging trans-
lation consensus between multiple machine
translation decoders. Different from system
combination and MBR decoding, which post-
process the n-best lists or word lattice of ma-
chine translation decoders, in our method mul-
tiple machine translation decoders collaborate
by exchanging partial translation results. Us-
ing an iterative decoding approach, n-gram
agreement statistics between translations of
multiple decoders are employed to re-rank
both full and partial hypothesis explored in
decoding. Experimental results on data sets for
NIST Chinese-to-English machine translation
task show that the co-decoding method can
bring significant improvements to all baseline
decoders, and the outputs from co-decoding
can be used to further improve the result of
system combination.
</bodyText>
<sectionHeader confidence="0.99812" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964166666667">
Recent research has shown substantial improve-
ments can be achieved by utilizing consensus
statistics obtained from outputs of multiple ma-
chine translation systems. Translation consensus
can be measured either at sentence level or at
word level. For example, Minimum Bayes Risk
(MBR) (Kumar and Byrne, 2004) decoding over
n-best list tries to find a hypothesis with lowest
expected loss with respect to all the other transla-
tions, which can be viewed as sentence-level
consensus-based decoding. Word based methods
proposed range from straightforward consensus
voting (Bangalore et al., 2001; Matusov et al.,
2006) to more complicated word-based system
combination model (Rosti et al., 2007; Sim et al.,
2007). Typically, the resulting systems take out-
puts of individual machine translation systems as
input, and build a new confusion network for
second-pass decoding.
There have been many efforts dedicated to ad-
vance the state-of-the-art performance by com-
bining multiple systems’ outputs. Most of the
work focused on seeking better word alignment
for consensus-based confusion network decoding
(Matusov et al., 2006) or word-level system
combination (He et al., 2008; Ayan et al., 2008).
In addition to better alignment, Rosti et al.
(2008) introduced an incremental strategy for
confusion network construction; and Hildebrand
and Vogel (2008) proposed a hypotheses re-
ranking model for multiple systems’ outputs with
more features including word translation proba-
bility and n-gram agreement statistics.
A common property of all the work mentioned
above is that the combination models work on
the basis of n-best translation lists (full hypo-
theses) of existing machine translation systems.
However, the n-best list only presents a very
small portion of the entire search space of a Sta-
tistical Machine Translation (SMT) model while
a majority of the space, within which there are
many potentially good translations, is pruned
away in decoding. In fact, due to the limitations
of present-day computational resources, a consi-
derable number of promising possibilities have to
be abandoned at the early stage of the decoding
process. It is therefore expected that exploring
additional possibilities beyond n-best hypotheses
lists for full sentences could bring improvements
to consensus-based decoding.
In this paper, we present collaborative decod-
ing (or co-decoding), a new SMT decoding
scheme to leverage consensus information be-
tween multiple machine translation systems. In
this scheme, instead of using a post-processing
step, multiple machine translation decoders col-
laborate during the decoding process, and trans-
lation consensus statistics are taken into account
to improve ranking not only for full translations,
but also for partial hypotheses. In this way, we
</bodyText>
<note confidence="0.886319">
585
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 585–592,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999623185185185">
expect to reduce search errors caused by partial
hypotheses pruning, maximize the contribution
of translation consensus, and result in better final
translations.
We will discuss the general co-decoding mod-
el, requirements for decoders that enable colla-
borative decoding and describe the updated mod-
el structures. We will present experimental re-
sults on the data sets of NIST Chinese-to-English
machine translation task, and demonstrate that
co-decoding can bring significant improvements
to baseline systems. We also conduct extensive
investigations when different settings of co-
decoding are applied, and make comparisons
with related methods such as word-level system
combination of hypothesis selection from mul-
tiple n-best lists.
The rest of the paper is structured as follows.
Section 2 gives a formal description of the co-
decoding model, the strategy to apply consensus
information and hypotheses ranking in decoding.
In Section 3, we make detailed comparison be-
tween co-decoding and related work such as sys-
tem combination and hypotheses selection out of
multiple systems. Experimental results and dis-
cussions are presented in Section 4. Section 5
concludes the paper.
</bodyText>
<sectionHeader confidence="0.953025" genericHeader="method">
2 Collaborative Decoding
</sectionHeader>
<subsectionHeader confidence="0.916501">
2.1 Overview
</subsectionHeader>
<bodyText confidence="0.999651285714286">
Collaborative decoding does not present a full
SMT model as other SMT decoders do such as
Pharaoh (Koehn, 2004) or Hiero (Chiang, 2005).
Instead, it provides a framework that accommo-
dates and coordinates multiple MT decoders.
Conceptually, collaborative decoding incorpo-
rates the following four constituents:
</bodyText>
<listItem confidence="0.924495476190476">
1. Co-decoding model. A co-decoding model
consists of a set of member models, which
are a set of augmented baseline models. We
call decoders based on member models
member decoders, and those based on base-
line models baseline decoders. In our work,
any Maximum A Posteriori (MAP) SMT
model with log-linear formulation (Och,
2002) can be a qualified candidate for a
baseline model. The requirement for a log-
linear model aims to provide a natural way to
integrate the new co-decoding features.
2. Co-decoding features. Member models are
built by adding additional translation consen-
sus -based co-decoding features to baseline
models. A baseline model can be viewed as a
special case of member model with all co-
decoding feature values set to 0. Accordingly,
a baseline decoder can be viewed as a special
setting of a member decoder.
3. Decoder coordinating. In co-decoding, each
</listItem>
<bodyText confidence="0.9970055">
member decoder cannot proceed solely based
on its own agenda. To share consensus statis-
tics with others, the decoding must be per-
formed in a coordinated way.
</bodyText>
<listItem confidence="0.971851">
4. Model training. Since we use multiple inter-
</listItem>
<bodyText confidence="0.998522">
related decoders and introduce more features
in member models, we also need to address
the parameter estimation issue in the frame-
work of co-decoding.
In the following sub-sections we first establish a
general model for co-decoding, and then present
details of feature design and decoder implemen-
tation, as well as parameter estimation in the co-
decoding framework. We leave the investigation
of using specific member models to the experi-
ment section.
</bodyText>
<subsectionHeader confidence="0.970608">
2.2 Generic Collaborative Decoding Model
</subsectionHeader>
<bodyText confidence="0.963804">
For a given source sentence f, a member model
in co-decoding finds the best translation 𝑒∗
among the set of possible candidate translations
ℋ(𝑓) based on a scoring function 𝐹:
</bodyText>
<equation confidence="0.995053">
𝑒∗ = argmax𝑒∈ℋ(𝑓)𝐹(𝑒) (1)
</equation>
<bodyText confidence="0.999482">
In the following, we will use 𝑑𝑘 to denote the
𝑘𝑡ℎ member decoder, and also use the notation
ℋ𝑘 (𝑓) for the translation hypothesis space of f
determined by 𝑑𝑘. The 𝑚𝑡ℎ member model can
be written as:
</bodyText>
<equation confidence="0.951987666666667">
𝐹𝑚 𝑒 = Φ𝑚 (𝑓, 𝑒) +
Ψ𝑘(𝑒, ℋ𝑘(𝑓)) (2)
𝑘,𝑘≠𝑚
</equation>
<bodyText confidence="0.99993575">
where Φ𝑚 (𝑓, 𝑒) is the score function of the 𝑚𝑡ℎ
baseline model, and each Ψ𝑘 (𝑒, ℋ𝑘 (𝑓)) is a par-
tial consensus score function with respect to 𝑑𝑘
and is defined over e and ℋ𝑘 𝑓 :
</bodyText>
<equation confidence="0.881905">
Ψ𝑘 𝑒, ℋ𝑘 𝑓 = 𝜆𝑘,𝑙 ℎ𝑘,𝑙(𝑒, ℋ𝑘 𝑓 )
𝑙
</equation>
<bodyText confidence="0.999584">
where each ℎ𝑘,𝑙 (𝑒, ℋ𝑘 𝑓 ) is a feature function
based on a consensus measure between e and
ℋ𝑘 𝑓 , and 𝜆𝑘,𝑙 is the corresponding feature
weight. Feature index l ranges over all consen-
sus-based features in Equation 3.
</bodyText>
<subsectionHeader confidence="0.995132">
2.3 Decoder Coordination
</subsectionHeader>
<bodyText confidence="0.999781">
Before discussing the design and computation of
translation consensus -based features, we first
</bodyText>
<equation confidence="0.566223">
(3)
586
</equation>
<bodyText confidence="0.999923214285714">
describe the multiple decoder coordination issue
in co-decoding. Note that in Equation 2, though
the baseline score function 4),,, (f, e) can be
computed inside each decoder, the case of
Tk (e, xk (f)) is more complicated. Because
usually it is not feasible to enumerate the entire
hypothesis space for machine translation, we ap-
proximate xk (f) with n-best hypotheses by
convention. Then there is a circular dependency
between co-decoding features and xk (f) : on
one hand, searching for n-best approximation of
xk (f) requires using Equation 2 to select top-
ranked hypotheses; while on the other hand, Eq-
uation 2 cannot be computed until every xk (f)
is available.
We address this issue by employing a boot-
strapping method, in which the key idea is that
we can use baseline models’ n-best hypotheses
as seeds, and iteratively refine member models’
n-best hypotheses with co-decoding. Similar to a
typical phrase-based decoder (Koehn, 2004), we
associate each hypothesis with a coverage vector
c to track translated source words in it. We will
use xk (c, f) for the set of hypotheses associated
with c, and we also denote with xk (f) _
Uc xk (c, f) the set of all hypotheses generated
by member decoder dk in decoding. The co-
decoding process can be described as follows:
</bodyText>
<listItem confidence="0.953313625">
1. For each member decoder dk, perform de-
coding with a baseline model, and memorize
all translation hypotheses generated during
decoding in xk (f);
2. Re-group translation hypotheses in xk (f)
into a set of buckets xk (c, f) by the cover-
age vector c associated with each hypothesis;
3. Use member decoders to re-decode source
</listItem>
<bodyText confidence="0.929885355555555">
sentence f with member models. For mem-
ber decoder dk, consensus-based features of
any hypotheses associated with coverage
vector c are computed based on current set-
ting of xS (c, f) for all s but k. New hypo-
theses generated by dk in re-decoding are
cached in xk′ (f);
x2, and in turn x1 benefits from improved x2,
and so forth.
Step 2 is used to facilitate the computation of
feature functions hk,l (e, xk (• )), which require
both e and every hypothesis in xk (• ) should be
translations of the same set of source words. This
step seems to be redundant for CKY-style MT
decoders (Liu et al., 2006; Xiong et al., 2006;
Chiang, 2005) since the grouping is immediately
available from decoders because all hypotheses
spanning the same range of source sentence have
been stacked together in the same chart cell. But
to be a general framework, this step is necessary
for some state-of-the-art phrase-based decoders
(Koehn, 2007; Och and Ney, 2004) because in
these decoders, hypotheses with different cover-
age vectors can co-exist in the same bin, or hypo-
theses associated with the same coverage vector
might appear in different bins.
Note that a member model does not enlarge
the theoretical search space of its baseline model,
the only change is hypothesis scoring. By re-
running a complete decoding process, member
model can be applied to re-score all hypotheses
explored by a decoder. Therefore step 3 can be
viewed as full-scale hypothesis re-ranking be-
cause the re-ranking scope is beyond the limited
n-best hypotheses currently cached in xk.
In the implementation of member decoders,
there are two major modifications compared to
their baseline decoders. One is the support for
co-decoding features, including computation of
feature values and the use of augmented co-
decoding score function (Equation 2) for hypo-
thesis ranking and pruning. The other is hypothe-
sis grouping based on coverage vector and a me-
chanism to effectively access grouped hypothes-
es in step 2 and step 3.
</bodyText>
<subsectionHeader confidence="0.997892">
2.4 Co-decoding Features
</subsectionHeader>
<bodyText confidence="0.75727975">
We now present the consensus-based feature
functions hk,l (e, xk (f)) introduced in Equation
3. In this work all the consensus-based features
have the following formulation:
</bodyText>
<listItem confidence="0.788203">
4. Update all xk (f) with xk ′ (f); hk,l(e,xk(f)) _ I P(e′ I dk) Gl(e,e′) (4)
5. Iterate from step 2 to step 4 until a preset
iteration limit is reached.
</listItem>
<bodyText confidence="0.9992158">
In the iterative decoding procedure described
above, hypotheses of different decoders can be
mutually improved. For example, given two de-
coders d1 and d2 with hypotheses sets x1 and
x2, improvements on x1 enable d2 to improve
</bodyText>
<equation confidence="0.511766">
e′Exk (f
</equation>
<bodyText confidence="0.996474">
where e is a translation of f by decoder d,,, (,,, #
k), e′ is a translation in xk (f) and P (e′ I dk) is
the posterior probability of translation e′ deter-
mined by decoder dk given source sentence f.
Gl (e, e′) is a consensus measure defined on e and
e′, by varying which different feature functions
can be obtained.
</bodyText>
<page confidence="0.516093">
587
</page>
<bodyText confidence="0.997923333333333">
Referring to the log-linear model formulation,
the translation posterior 𝑃 𝑒′ 𝑑𝑘 can be com-
puted as:
</bodyText>
<equation confidence="0.7619435">
exp 𝛼𝐹𝑘 𝑒′
𝑒′′ ∈ℋ𝑘 𝑓 exp 𝛼𝐹𝑘 𝑒′′
</equation>
<bodyText confidence="0.999878470588235">
where 𝐹𝑘 (∙) is the score function given in Equa-
tion 2, and 𝛼 is a scaling factor following the
work of Tromble et al. (2008)
To compute the consensus measures, we fur-
ther decompose each 𝐺𝑙 𝑒, 𝑒′ into n-gram
matching statistics between e and 𝑒′. Here we do
not discriminate among different lexical n-grams
and are only concerned with statistics aggrega-
tion of all n-grams of the same order. For each n-
gram of order n, we introduce a pair of comple-
mentary consensus measure functions 𝐺𝑛+ 𝑒, 𝑒′
and 𝐺𝑛− 𝑒, 𝑒′ described as follows:
𝐺𝑛+ 𝑒, 𝑒′ is the n-gram agreement measure
function which counts the number of occurrences
in 𝑒′ of n-grams in e. So the corresponding fea-
ture value will be the expected number of occur-
rences in ℋ𝑘 𝑓 of all n-grams in e:
</bodyText>
<equation confidence="0.986981285714286">
𝑒 −𝑛+1
𝐺𝑛+ 𝑒, 𝑒′ = 𝜏(𝑒𝑖+𝑛−1 𝑒′)
𝑖
𝑖=1
where 𝜏(∙,∙) is a binary indicator function –
𝜏 ′
𝑒′ and 0 otherwise.
𝑖+𝑛−1𝑖+𝑛−1
𝐺𝑛− 𝑒, 𝑒′ is the n-gram disagreement meas-
ure function which is complementary to
𝐺𝑛+ 𝑒, 𝑒′ :
𝑒 −𝑛+1
𝐺𝑛− 𝑒, 𝑒′ = 1 − 𝜏 𝑒𝑖 𝑖+𝑛−1, 𝑒′
𝑖=1
</equation>
<bodyText confidence="0.999471333333333">
This feature is designed because 𝐺𝑛+ 𝑒, 𝑒 ′
does not penalize long translation with low pre-
cision. Obviously we have the following:
</bodyText>
<equation confidence="0.977632">
𝐺𝑛+ 𝑒, 𝑒′ + 𝐺𝑛− 𝑒, 𝑒′ = 𝑒 − 𝑛+ 1
</equation>
<bodyText confidence="0.9999556">
So if the weights of agreement and disagree-
ment features are equal, the disagreement-based
features will be equivalent to the translation
length features. Using disagreement measures
instead of translation length there could be two
potential advantages: 1) a length feature has been
included in the baseline model and we do not
need to add one; 2) we can scale disagreement
features independently and gain more modeling
flexibility.
Similar to a language model score, n-gram
consensus -based feature values cannot be
summed up from smaller hypotheses. Instead, it
must be re-computed when building each new
hypothesis.
</bodyText>
<subsectionHeader confidence="0.996612">
2.5 Model Training
</subsectionHeader>
<bodyText confidence="0.999868166666667">
We adapt the Minimum Error Rate Training
(MERT) (Och, 2003) algorithm to estimate pa-
rameters for each member model in co-decoding.
Let 𝝀𝑚 be the feature weight vector for member
decoder 𝑑𝑚, the training procedure proceeds as
follows:
</bodyText>
<listItem confidence="0.943818375">
1. Choose initial values for 𝝀1,..., 𝝀𝑀
2. Perform co-decoding using all member de-
coders on a development set D with
𝝀1, ...,𝝀𝑀. For each decoder 𝑑𝑚, find a new
feature weight vector 𝝀𝑚 ′ which optimizes
the specified evaluation criterion L on D us-
ing the MERT algorithm based on the n-best
list ℋ𝑚 generated by 𝑑𝑚:
</listItem>
<equation confidence="0.847161">
𝝀𝑚 ′= argmax𝝀 𝐿 (𝑇 |𝝀, ℋ𝑚 , 𝐷))
</equation>
<bodyText confidence="0.999776666666667">
where T denotes the translations selected by
re-ranking the translations in ℋ𝑚 using a
new feature weight vector 𝝀
</bodyText>
<listItem confidence="0.978006333333333">
3. Let 𝝀1 = 𝝀1 ′ , ... ,𝝀𝑀 = 𝝀𝑀′ and repeat step 2
until convergence or a preset iteration limit is
reached.
</listItem>
<figureCaption confidence="0.999821">
Figure 1. Model training for co-decoding
</figureCaption>
<bodyText confidence="0.998520857142857">
In step 2, there is no global criterion to optim-
ize the co-decoding parameters across member
models. Instead, parameters of different member
models are tuned to maximize the evaluation cri-
teria on each member decoder’s own n-best out-
put. Figure 1 illustrates the training process of
co-decoding with 2 member decoders.
</bodyText>
<figure confidence="0.9640688">

Source sentence
decoder1
MERT
ℋ1
1
co-decoding
ref
decoder2
2
MERT
ℋ2
𝑃 𝑒′ 𝑑𝑘 =
(5)
588
</figure>
<subsectionHeader confidence="0.910839">
2.6 Output Selection
</subsectionHeader>
<bodyText confidence="0.999955571428571">
Since there is more than one model in co-
decoding, we cannot rely on member model’s
score function to choose one best translation
from multiple decoders’ outputs because the
model scores are not directly comparable. We
will examine the following two system combina-
tion -based solutions to this task:
</bodyText>
<listItem confidence="0.999197">
• Word-level system combination (Rosti et al.,
2007) of member decoders’ n-best outputs
• Hypothesis selection from combined n-best
lists as proposed in Hildebrand and Vogel
(2008)
</listItem>
<sectionHeader confidence="0.998486" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999946333333333">
In this section we present experiments to eva-
luate the co-decoding method. We first describe
the data sets and baseline systems.
</bodyText>
<subsectionHeader confidence="0.997725">
3.1 Data and Metric
</subsectionHeader>
<bodyText confidence="0.999679">
We conduct our experiments on the test data
from the NIST 2005 and NIST 2008 Chinese-to-
English machine translation tasks. The NIST
2003 test data is used for development data to
estimate model parameters. Statistics of the data
sets are shown in Table 1. In our experiments all
the models are optimized with case-insensitive
NIST version of BLEU score and we report re-
sults using this metric in percentage numbers.
</bodyText>
<table confidence="0.83878075">
Data set # Sentences # Words
NIST 2003 (dev) 919 23,782
NIST 2005 (test) 1,082 29,258
NIST 2008 (test) 1,357 31,592
</table>
<tableCaption confidence="0.999641">
Table 1: Data set statistics
</tableCaption>
<bodyText confidence="0.9999264375">
We use the parallel data available for the
NIST 2008 constrained track of Chinese-to-
English machine translation task as bilingual
training data, which contains 5.1M sentence
pairs, 128M Chinese words and 147M English
words after pre-processing. GIZA++ is used to
perform word alignment in both directions with
default settings, and the intersect-diag-grow me-
thod is used to generate symmetric word align-
ment refinement.
The language model used for all models (in-
clude decoding models and system combination
models described in Section 2.6) is a 5-gram
model trained with the English part of bilingual
data and xinhua portion of LDC English Giga-
word corpus version 3.
</bodyText>
<subsectionHeader confidence="0.997887">
3.2 Member Decoders
</subsectionHeader>
<bodyText confidence="0.999978172413793">
We use three baseline decoders in the experi-
ments. The first one (SYS1) is re-implementation
of Hiero, a hierarchical phrase-based decoder.
Phrasal rules are extracted from all bilingual sen-
tence pairs, while rules with variables are ex-
tracted only from selected data sets including
LDC2003E14, LDC2003E07, LDC2005T06 and
LDC2005T10, which contain around 350,000
sentence pairs, 8.8M Chinese words and 10.3M
English words. The second one (SYS2) is a BTG
decoder with lexicalized reordering model based
on maximum entropy principle as proposed by
Xiong et al. (2006). We use all the bilingual data
to extract phrases up to length 3. The third one
(SYS3) is a string-to-dependency tree –based
decoder as proposed by Shen et al. (2008). For
rule extraction we use the same setting as in
SYS1. We parsed the language model training
data with Berkeley parser, and then trained a de-
pendency language model based on the parsing
output. All baseline decoders are extended with
n-gram consensus –based co-decoding features
to construct member decoders. By default, the
beam size of 20 is used for all decoders in the
experiments. We run two iterations of decoding
for each member decoder, and hold the value of
𝛼 in Equation 5 as a constant 0.05, which is
tuned on the test data of NIST 2004 Chinese-to-
English machine translation task.
</bodyText>
<subsectionHeader confidence="0.99907">
3.3 Translation Results
</subsectionHeader>
<bodyText confidence="0.961172166666666">
We first present the overall results of co-
decoding on both test sets using the settings as
we described. For member decoders, up to 4-
gram agreement and disagreement features are
used. We also implemented the word-level sys-
tem combination (Rosti et al., 2007) and the hy-
pothesis selection method (Hildebrand and Vogel,
2008). 20-best translations from all decoders are
used in the experiments for these two combina-
tion methods. Parameters for both system com-
bination and hypothesis selection are also tuned
on NIST 2003 test data. The results are shown in
</bodyText>
<tableCaption confidence="0.974977">
Table 2.
</tableCaption>
<table confidence="0.978761">
NIST 2005 NIST 2008
SYS1 38.66/40.08 27.67/29.19
SYS2 38.04/39.93 27.25/29.14
SYS3 39.50/40.32 28.75/29.68
Word-level Comb 40.45/40.85 29.52/30.35
Hypo Selection 40.09/40.50 29.02/29.71
</table>
<tableCaption confidence="0.997854">
Table 2: Co-decoding results on test data
</tableCaption>
<page confidence="0.91889">
589
</page>
<bodyText confidence="0.999957903225807">
In the Table 2, the results of a member decod-
er and its corresponding baseline decoder are
grouped together with the later one for the mem-
ber decoders. On both test sets, every member
decoder performs significantly better than its
baseline decoder (using the method proposed in
Koehn (2004) for statistical significance test).
We apply system combination methods to the
n-best outputs of both baseline decoders and
member decoders. We notice that we can achieve
even better performance by applying system
combination methods to member decoders’ n-
best outputs. However, the improvement margins
are smaller than those of baseline decoders on
both test sets. This could be the result of less di-
versified outputs from co-decoding than those
from baseline decoders. In particular, the results
for hypothesis selection are only slightly better
than the best system in co-decoding.
We also evaluate the performance of system
combination using different n-best sizes, and the
results on NIST 2005 data set are shown in Fig-
ure 2, where bl- and co- legends denote combina-
tion results of baseline decoding and co-decoding
respectively. From the results we can see that
combination based on co-decoding’s outputs per-
forms consistently better than that based on base-
line decoders’ outputs for all n-best sizes we ex-
perimented with. However, we did not observe
any significant improvements for both combina-
tion schemes when n-best size is larger than 20.
</bodyText>
<figure confidence="0.904719333333333">
41.3
39.5
10 20 50 100 200
</figure>
<figureCaption confidence="0.961337">
Figure 2. Performance of system combination
with different sizes of n-best lists
</figureCaption>
<bodyText confidence="0.999463666666667">
One interesting observation in Table 2 is that
the performance gap between baseline decoders
is narrowed through co-decoding. For example,
the 1.5 points gap between SYS2 and SYS3 on
NIST 2008 data set is narrowed to 0.5. Actually
we find that the TER score between two member
decoders’ outputs are significantly reduced (as
shown in Table 3), which indicates that the out-
puts become more similar due to the use of con-
sensus information. For example, the TER score
between SYS2 and SYS3 of the NIST 2008 out-
puts are reduced from 0.4238 to 0.2665.
</bodyText>
<note confidence="0.58932125">
NIST 2005 NIST 2008
SYS1 vs. SYS2 0.3190/0.2274 0.4016/0.2686
SYS1 vs. SYS3 0.3252/0.1840 0.4176/0.2469
SYS2 vs. SYS3 0.3498/0.2171 0.4238/0.2665
</note>
<tableCaption confidence="0.99226">
Table 3: TER scores between co-decoding
translation outputs
</tableCaption>
<bodyText confidence="0.999610461538462">
In the rest of this section we run a series of
experiments to investigate the impacts of differ-
ent factors in co-decoding. All the results are
reported on NIST 2005 test set.
We start with investigating the performance
gain due to partial hypothesis re-ranking. Be-
cause Equation 3 is a general model that can be
applied to both partial hypothesis and n-best (full
hypothesis) re-scoring, we compare the results of
both cases. Figure 3 shows the BLEU score
curves with up to 1000 candidates used for re-
ranking. In Figure 3, the suffix p denotes results
for partial hypothesis re-ranking, and f for n-best
re-ranking only. For partial hypothesis re-
ranking, obtaining more top-ranked results re-
quires increasing the beam size, which is not af-
fordable for large numbers in experiments. We
work around this issue by approximating beam
sizes larger than 20 by only enlarging the beam
size for the span covering the entire source sen-
tence. From Figure 3 we can see that all decoders
can gain improvements before the size of candi-
date set reaches 100. When the size is larger than
50, co-decoding performs consistently and sig-
nificantly better than the re-ranking results on
any baseline decoder’s n-best outputs.
</bodyText>
<figure confidence="0.996774666666667">
41.5 SYS1f
41.0 SYS2f
40.5 SYS3f
40.0 SYS1p
39.5 SYS2p
39.0 SYS3p
38.5
38.0
10 20 50 100 200 500 1000
</figure>
<figureCaption confidence="0.9876905">
Figure 3. Partial hypothesis vs. n-best re-ranking
results on NIST 2005 test data
</figureCaption>
<bodyText confidence="0.998506875">
Figure 4 shows the BLEU scores of a two-
system co-decoding as a function of re-decoding
iterations. From the results we can see that the
results for both decoders converge after two ite-
rations.
In Figure 4, iteration 0 denotes decoding with
baseline model. The setting of iteration 1 can be
viewed as the case of partial co-decoding, in
</bodyText>
<figure confidence="0.959241090909091">
41.0
40.8
40.5
40.3
40.0
39.8
bl-comb
co-comb
bl-hyposel
co-hyposel
590
</figure>
<bodyText confidence="0.989678">
which one decoder uses member model and the
other keeps using baseline model. The results
show that member models help each other: al-
though improvements can be made using a single
member model, best BLEU scores can only be
achieved when both member models are used as
shown by the results of iteration 2. The results
also help justify the independent parameter esti-
mation of member decoders described in Section
2.5, since optimizing the performance of one de-
coder will eventually bring performance im-
provements to all member decoders.
Figure 4. Results using incremental iterations
in co-decoding
Next we examine the impacts of different con-
sensus-based features in co-decoding. Table 4
shows the comparison results of a two-system
co-decoding using different settings of n-gram
agreement and disagreement features. It is clear-
ly shown that both n-gram agreement and disa-
greement types of features are helpful, and using
them together is the best choice.
</bodyText>
<table confidence="0.99459">
SYS1 SYS2
Baseline 38.66 38.04
+agreement –disagreement 39.36 39.02
–agreement +disagreement 39.12 38.67
+agreement +disagreement 39.68 39.61
</table>
<tableCaption confidence="0.9097295">
Table 4: Co-decoding with/without n-gram
agreement and disagreement features
</tableCaption>
<bodyText confidence="0.99888475">
In Table 5 we show in another dimension the
impact of consensus-based features by restricting
the maximum order of n-grams used to compute
agreement statistics.
</bodyText>
<table confidence="0.761876857142857">
SYS1 SYS2
1 38.75 38.27
2 39.21 39.10
3 39.48 39.25
4 39.68 39.61
5 39.52 39.36
6 39.58 39.47
</table>
<tableCaption confidence="0.8152325">
Table 5: Co-decoding with varied n-gram agree-
ment and disagreement features
</tableCaption>
<bodyText confidence="0.9974845">
From the results we do not observe BLEU im-
provement for 𝑛 &gt; 4. One reason could be that
the data sparsity for high-order n-grams leads to
over fitting on development data.
We also empirically investigated the impact of
scaling factor 𝛼 in Equation 5. It is observed in
Figure 5 that the optimal value is between 0.01 ~
0.1 on both development and test data.
</bodyText>
<figureCaption confidence="0.947771">
Figure 5. Impact of scaling factor 𝛼
</figureCaption>
<sectionHeader confidence="0.999499" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999926242424243">
Word-level system combination (system combi-
nation hereafter) (Rosti et al., 2007; He et al.,
2008) has been proven to be an effective way to
improve machine translation quality by using
outputs from multiple systems. Our method is
different from system combination in several
ways. System combination uses unigram consen-
sus only and a standalone decoding model irrele-
vant to single decoders. Our method uses agree-
ment information of n-grams, and consensus fea-
tures are integrated into decoding models. By
constructing a confusion network, system com-
bination is able to generate new translations dif-
ferent from any one in the input n-best lists,
while our method does not extend the search
spaces of baseline decoding models. Member
decoders only change the scoring and ranking of
the candidates in the search spaces. Results in
Table 2 show that these two approaches can be
used together to obtain further improvements.
The work on multi-system hypothesis selec-
tion of Hildebrand and Vogel (2008) bears more
resemblance to our method in that both make use
of n-gram agreement statistics. They also empiri-
cally show that n-gram agreement is the most
important factor for improvement apart from
language models.
Lattice MBR decoding (Tromble et al., 2008)
also uses n-gram agreement statistics. Their work
focuses on exploring larger evidence space by
using a translation lattice instead of the n-best list.
They also show the connection between expected
n-gram change and corpus Log-BLEU loss.
</bodyText>
<figure confidence="0.98446295">
40.0
39.5
39.0
SYS1
38.5
SYS2
38.0
37.5
0 1 2 3 4
0 0.01 0.03 0.05 0.1 0.2 0.5 1
40.0
39.5
39.0
38.5
38.0
Dev SYS1
Dev SYS2
Test SYS1
Test SYS2
591
</figure>
<sectionHeader confidence="0.959794" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999911933333333">
Improving machine translation with multiple sys-
tems has been a focus in recent SMT research. In
this paper, we present a framework of collabora-
tive decoding, in which multiple MT decoders
are coordinated to search for better translations
by re-ranking partial hypotheses using aug-
mented log-linear models with translation con-
sensus -based features. An iterative approach is
proposed to re-rank all hypotheses explored in
decoding. Experimental results show that with
collaborative decoding every member decoder
performs significantly better than its baseline
decoder. In the future, we will extend our method
to use lattice or hypergraph to compute consen-
sus statistics instead of n-best lists.
</bodyText>
<sectionHeader confidence="0.998453" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999874975609756">
Necip Fazil Ayan, Jing Zheng, and Wen Wang. 2008.
Improving alignments for better confusion net-
works for combining machine translation systems.
In Proc. Coling, pages 33-40.
Srinivas Bangalore, German Bordel and Giuseppe
Riccardi. 2001. Computing consensus translation
from multiple machine translation systems. In
Proc. ASRU, pages 351-354.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Proc.
ACL, pages 263-270.
Xiaodong He, Mei Yang, Jianfeng Gao, Patrick
Nguyen, and Robert Moore. 2008. Indirect-hmm-
based hypothesis for combining outputs from ma-
chine translation systems. In Proc. EMNLP, pages
98-107.
Almut Silja Hildebrand and Stephan Vogel. 2008.
Combination of machine translation systems via
hypothesis selection from combined n-best lists. In
8th AMTA conference, pages 254-261.
Philipp Koehn, 2004. Statistical significance tests for
machine translation evaluation. In Proc. EMNLP.
Philipp Koehn, 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation
model. In Proc. 6th AMTA Conference, pages 115-
124.
Philipp Koehn, Hieu Hoang, Alexandra Brich, Chris
Callison-Burch, Marcello Federico, Nicola Bertol-
di, Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proc. ACL, demonstration session.
Shankar Kumar and William Byrne 2004. Minimum
Bayes-Risk Decoding for Statistical Machine
Translation. In HLT-NAACL, pages 169-176.
Yang Liu, Qun Liu, Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine
translation. In Proc. ACL-Coling, pages 609-616.
Evgeny Matusov, Nicola Ueffi ng, and Hermann Ney.
2006. Computing consensus translation from mul-
tiple machine translation systems using enchanced
hypotheses alignment. In Proc. EACL, pages 33-
40.
Franz Och and Hermann Ney. 2002. Discriminative
training and maximum entropy models for statis-
tical machine translation. In Proc. ACL, pages 295-
302.
Franz Och. 2003. Minimum error rate training in sta-
tistical machine translation. In Proc. ACL, pages
160-167.
Franz Och and Hermann Ney. 2004. The alignment
template approach to statistical machine transla-
tion. Computational Linguistics, 30(4), pages 417-
449
Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang,
Spyros Matsoukas, Richard Schwartz, and Bonnie
Dorr. 2007. Combining outputs from multiple ma-
chine translation systems. In HLT-NAACL, pages
228-235
Antti-Veikko Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz. 2008. Incremental hypothe-
sis alignment for building confusion networks with
application to machine translation system combina-
tion. In Proc. Of the Third ACL Workshop on Sta-
tistical Machine Translation, pages 183-186.
K.C. Sim, W. Byrne, M. Gales, H. Sahbi, and P.
Woodland. 2007. Consensus network decoding for
statistical machine translation system combination.
In ICASSP.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation al-
gorithm with a target dependency language model.
In Proc. HLT-ACL, pages 577-585.
Roy W. Tromble, Shankar Kumar, Franz Och, and
Wolfgang Macherey. 2008. Lattice minimum
bayes-risk decoding for statistical machine transla-
tion. In Proc. EMNLP, pages 620-629.
Deyi Xiong, Qun Liu and Shouxun Lin. 2006. Maxi-
mum entropy based phrase reordering model for
statistical machine translation. In Proc. ACL, pages
521-528.
</reference>
<page confidence="0.888907">
592
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.973119">
<title confidence="0.999191">Collaborative Decoding: Partial Hypothesis Re-ranking Using Translation Consensus between Decoders</title>
<author confidence="0.994686">Nan Dongdong Chi-Ho Ming</author>
<affiliation confidence="0.999861">Research Asia University</affiliation>
<address confidence="0.992009">Beijing, China Tianjin, China</address>
<email confidence="0.999908">muli@microsoft.com</email>
<email confidence="0.999908">v-naduan@microsoft.com</email>
<email confidence="0.999908">dozhang@microsoft.com</email>
<email confidence="0.999908">chl@microsoft.com</email>
<email confidence="0.999908">mingzhou@microsoft.com</email>
<abstract confidence="0.999441363636364">This paper presents collaborative decoding (co-decoding), a new method to improve machine translation accuracy by leveraging translation consensus between multiple machine translation decoders. Different from system combination and MBR decoding, which postprocess the n-best lists or word lattice of machine translation decoders, in our method multiple machine translation decoders collaborate by exchanging partial translation results. Using an iterative decoding approach, n-gram agreement statistics between translations of multiple decoders are employed to re-rank both full and partial hypothesis explored in decoding. Experimental results on data sets for NIST Chinese-to-English machine translation task show that the co-decoding method can bring significant improvements to all baseline decoders, and the outputs from co-decoding can be used to further improve the result of system combination.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Jing Zheng</author>
<author>Wen Wang</author>
</authors>
<title>Improving alignments for better confusion networks for combining machine translation systems.</title>
<date>2008</date>
<booktitle>In Proc. Coling,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="2398" citStr="Ayan et al., 2008" startWordPosition="334" endWordPosition="337">ngalore et al., 2001; Matusov et al., 2006) to more complicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). In addition to better alignment, Rosti et al. (2008) introduced an incremental strategy for confusion network construction; and Hildebrand and Vogel (2008) proposed a hypotheses reranking model for multiple systems’ outputs with more features including word translation probability and n-gram agreement statistics. A common property of all the work mentioned above is that the combination models work on the basis of n-best translation lists (full hypotheses) of existing machine translation systems. However, the n-best list only presents a very small portion of the entire search space of a Stati</context>
</contexts>
<marker>Ayan, Zheng, Wang, 2008</marker>
<rawString>Necip Fazil Ayan, Jing Zheng, and Wen Wang. 2008. Improving alignments for better confusion networks for combining machine translation systems. In Proc. Coling, pages 33-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>German Bordel</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems.</title>
<date>2001</date>
<booktitle>In Proc. ASRU,</booktitle>
<pages>351--354</pages>
<contexts>
<context position="1800" citStr="Bangalore et al., 2001" startWordPosition="243" endWordPosition="246">stem combination. 1 Introduction Recent research has shown substantial improvements can be achieved by utilizing consensus statistics obtained from outputs of multiple machine translation systems. Translation consensus can be measured either at sentence level or at word level. For example, Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) decoding over n-best list tries to find a hypothesis with lowest expected loss with respect to all the other translations, which can be viewed as sentence-level consensus-based decoding. Word based methods proposed range from straightforward consensus voting (Bangalore et al., 2001; Matusov et al., 2006) to more complicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). </context>
</contexts>
<marker>Bangalore, Bordel, Riccardi, 2001</marker>
<rawString>Srinivas Bangalore, German Bordel and Giuseppe Riccardi. 2001. Computing consensus translation from multiple machine translation systems. In Proc. ASRU, pages 351-354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="5486" citStr="Chiang, 2005" startWordPosition="803" endWordPosition="804">e rest of the paper is structured as follows. Section 2 gives a formal description of the codecoding model, the strategy to apply consensus information and hypotheses ranking in decoding. In Section 3, we make detailed comparison between co-decoding and related work such as system combination and hypotheses selection out of multiple systems. Experimental results and discussions are presented in Section 4. Section 5 concludes the paper. 2 Collaborative Decoding 2.1 Overview Collaborative decoding does not present a full SMT model as other SMT decoders do such as Pharaoh (Koehn, 2004) or Hiero (Chiang, 2005). Instead, it provides a framework that accommodates and coordinates multiple MT decoders. Conceptually, collaborative decoding incorporates the following four constituents: 1. Co-decoding model. A co-decoding model consists of a set of member models, which are a set of augmented baseline models. We call decoders based on member models member decoders, and those based on baseline models baseline decoders. In our work, any Maximum A Posteriori (MAP) SMT model with log-linear formulation (Och, 2002) can be a qualified candidate for a baseline model. The requirement for a loglinear model aims to </context>
<context position="10464" citStr="Chiang, 2005" startWordPosition="1663" endWordPosition="1664">ber models. For member decoder dk, consensus-based features of any hypotheses associated with coverage vector c are computed based on current setting of xS (c, f) for all s but k. New hypotheses generated by dk in re-decoding are cached in xk′ (f); x2, and in turn x1 benefits from improved x2, and so forth. Step 2 is used to facilitate the computation of feature functions hk,l (e, xk (• )), which require both e and every hypothesis in xk (• ) should be translations of the same set of source words. This step seems to be redundant for CKY-style MT decoders (Liu et al., 2006; Xiong et al., 2006; Chiang, 2005) since the grouping is immediately available from decoders because all hypotheses spanning the same range of source sentence have been stacked together in the same chart cell. But to be a general framework, this step is necessary for some state-of-the-art phrase-based decoders (Koehn, 2007; Och and Ney, 2004) because in these decoders, hypotheses with different coverage vectors can co-exist in the same bin, or hypotheses associated with the same coverage vector might appear in different bins. Note that a member model does not enlarge the theoretical search space of its baseline model, the only</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proc. ACL, pages 263-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong He</author>
<author>Mei Yang</author>
<author>Jianfeng Gao</author>
<author>Patrick Nguyen</author>
<author>Robert Moore</author>
</authors>
<title>Indirect-hmmbased hypothesis for combining outputs from machine translation systems.</title>
<date>2008</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>98--107</pages>
<contexts>
<context position="2378" citStr="He et al., 2008" startWordPosition="330" endWordPosition="333">sensus voting (Bangalore et al., 2001; Matusov et al., 2006) to more complicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). In addition to better alignment, Rosti et al. (2008) introduced an incremental strategy for confusion network construction; and Hildebrand and Vogel (2008) proposed a hypotheses reranking model for multiple systems’ outputs with more features including word translation probability and n-gram agreement statistics. A common property of all the work mentioned above is that the combination models work on the basis of n-best translation lists (full hypotheses) of existing machine translation systems. However, the n-best list only presents a very small portion of the entire sea</context>
<context position="26088" citStr="He et al., 2008" startWordPosition="4278" endWordPosition="4281">39.61 5 39.52 39.36 6 39.58 39.47 Table 5: Co-decoding with varied n-gram agreement and disagreement features From the results we do not observe BLEU improvement for 𝑛 &gt; 4. One reason could be that the data sparsity for high-order n-grams leads to over fitting on development data. We also empirically investigated the impact of scaling factor 𝛼 in Equation 5. It is observed in Figure 5 that the optimal value is between 0.01 ~ 0.1 on both development and test data. Figure 5. Impact of scaling factor 𝛼 4 Discussion Word-level system combination (system combination hereafter) (Rosti et al., 2007; He et al., 2008) has been proven to be an effective way to improve machine translation quality by using outputs from multiple systems. Our method is different from system combination in several ways. System combination uses unigram consensus only and a standalone decoding model irrelevant to single decoders. Our method uses agreement information of n-grams, and consensus features are integrated into decoding models. By constructing a confusion network, system combination is able to generate new translations different from any one in the input n-best lists, while our method does not extend the search spaces of</context>
</contexts>
<marker>He, Yang, Gao, Nguyen, Moore, 2008</marker>
<rawString>Xiaodong He, Mei Yang, Jianfeng Gao, Patrick Nguyen, and Robert Moore. 2008. Indirect-hmmbased hypothesis for combining outputs from machine translation systems. In Proc. EMNLP, pages 98-107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Stephan Vogel</author>
</authors>
<title>Combination of machine translation systems via hypothesis selection from combined n-best lists.</title>
<date>2008</date>
<booktitle>In 8th AMTA conference,</booktitle>
<pages>254--261</pages>
<contexts>
<context position="2555" citStr="Hildebrand and Vogel (2008)" startWordPosition="356" endWordPosition="359">y, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). In addition to better alignment, Rosti et al. (2008) introduced an incremental strategy for confusion network construction; and Hildebrand and Vogel (2008) proposed a hypotheses reranking model for multiple systems’ outputs with more features including word translation probability and n-gram agreement statistics. A common property of all the work mentioned above is that the combination models work on the basis of n-best translation lists (full hypotheses) of existing machine translation systems. However, the n-best list only presents a very small portion of the entire search space of a Statistical Machine Translation (SMT) model while a majority of the space, within which there are many potentially good translations, is pruned away in decoding. </context>
<context position="16416" citStr="Hildebrand and Vogel (2008)" startWordPosition="2699" endWordPosition="2702">o-decoding with 2 member decoders.  Source sentence decoder1 MERT ℋ1 1 co-decoding ref decoder2 2 MERT ℋ2 𝑃 𝑒′ 𝑑𝑘 = (5) 588 2.6 Output Selection Since there is more than one model in codecoding, we cannot rely on member model’s score function to choose one best translation from multiple decoders’ outputs because the model scores are not directly comparable. We will examine the following two system combination -based solutions to this task: • Word-level system combination (Rosti et al., 2007) of member decoders’ n-best outputs • Hypothesis selection from combined n-best lists as proposed in Hildebrand and Vogel (2008) 3 Experiments In this section we present experiments to evaluate the co-decoding method. We first describe the data sets and baseline systems. 3.1 Data and Metric We conduct our experiments on the test data from the NIST 2005 and NIST 2008 Chinese-toEnglish machine translation tasks. The NIST 2003 test data is used for development data to estimate model parameters. Statistics of the data sets are shown in Table 1. In our experiments all the models are optimized with case-insensitive NIST version of BLEU score and we report results using this metric in percentage numbers. Data set # Sentences </context>
<context position="19503" citStr="Hildebrand and Vogel, 2008" startWordPosition="3205" endWordPosition="3208">fault, the beam size of 20 is used for all decoders in the experiments. We run two iterations of decoding for each member decoder, and hold the value of 𝛼 in Equation 5 as a constant 0.05, which is tuned on the test data of NIST 2004 Chinese-toEnglish machine translation task. 3.3 Translation Results We first present the overall results of codecoding on both test sets using the settings as we described. For member decoders, up to 4- gram agreement and disagreement features are used. We also implemented the word-level system combination (Rosti et al., 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). 20-best translations from all decoders are used in the experiments for these two combination methods. Parameters for both system combination and hypothesis selection are also tuned on NIST 2003 test data. The results are shown in Table 2. NIST 2005 NIST 2008 SYS1 38.66/40.08 27.67/29.19 SYS2 38.04/39.93 27.25/29.14 SYS3 39.50/40.32 28.75/29.68 Word-level Comb 40.45/40.85 29.52/30.35 Hypo Selection 40.09/40.50 29.02/29.71 Table 2: Co-decoding results on test data 589 In the Table 2, the results of a member decoder and its corresponding baseline decoder are grouped together with the later one </context>
<context position="26986" citStr="Hildebrand and Vogel (2008)" startWordPosition="4422" endWordPosition="4425">nt to single decoders. Our method uses agreement information of n-grams, and consensus features are integrated into decoding models. By constructing a confusion network, system combination is able to generate new translations different from any one in the input n-best lists, while our method does not extend the search spaces of baseline decoding models. Member decoders only change the scoring and ranking of the candidates in the search spaces. Results in Table 2 show that these two approaches can be used together to obtain further improvements. The work on multi-system hypothesis selection of Hildebrand and Vogel (2008) bears more resemblance to our method in that both make use of n-gram agreement statistics. They also empirically show that n-gram agreement is the most important factor for improvement apart from language models. Lattice MBR decoding (Tromble et al., 2008) also uses n-gram agreement statistics. Their work focuses on exploring larger evidence space by using a translation lattice instead of the n-best list. They also show the connection between expected n-gram change and corpus Log-BLEU loss. 40.0 39.5 39.0 SYS1 38.5 SYS2 38.0 37.5 0 1 2 3 4 0 0.01 0.03 0.05 0.1 0.2 0.5 1 40.0 39.5 39.0 38.5 38</context>
</contexts>
<marker>Hildebrand, Vogel, 2008</marker>
<rawString>Almut Silja Hildebrand and Stephan Vogel. 2008. Combination of machine translation systems via hypothesis selection from combined n-best lists. In 8th AMTA conference, pages 254-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="5462" citStr="Koehn, 2004" startWordPosition="799" endWordPosition="800">ltiple n-best lists. The rest of the paper is structured as follows. Section 2 gives a formal description of the codecoding model, the strategy to apply consensus information and hypotheses ranking in decoding. In Section 3, we make detailed comparison between co-decoding and related work such as system combination and hypotheses selection out of multiple systems. Experimental results and discussions are presented in Section 4. Section 5 concludes the paper. 2 Collaborative Decoding 2.1 Overview Collaborative decoding does not present a full SMT model as other SMT decoders do such as Pharaoh (Koehn, 2004) or Hiero (Chiang, 2005). Instead, it provides a framework that accommodates and coordinates multiple MT decoders. Conceptually, collaborative decoding incorporates the following four constituents: 1. Co-decoding model. A co-decoding model consists of a set of member models, which are a set of augmented baseline models. We call decoders based on member models member decoders, and those based on baseline models baseline decoders. In our work, any Maximum A Posteriori (MAP) SMT model with log-linear formulation (Och, 2002) can be a qualified candidate for a baseline model. The requirement for a </context>
<context position="9175" citStr="Koehn, 2004" startWordPosition="1426" endWordPosition="1427">pproximate xk (f) with n-best hypotheses by convention. Then there is a circular dependency between co-decoding features and xk (f) : on one hand, searching for n-best approximation of xk (f) requires using Equation 2 to select topranked hypotheses; while on the other hand, Equation 2 cannot be computed until every xk (f) is available. We address this issue by employing a bootstrapping method, in which the key idea is that we can use baseline models’ n-best hypotheses as seeds, and iteratively refine member models’ n-best hypotheses with co-decoding. Similar to a typical phrase-based decoder (Koehn, 2004), we associate each hypothesis with a coverage vector c to track translated source words in it. We will use xk (c, f) for the set of hypotheses associated with c, and we also denote with xk (f) _ Uc xk (c, f) the set of all hypotheses generated by member decoder dk in decoding. The codecoding process can be described as follows: 1. For each member decoder dk, perform decoding with a baseline model, and memorize all translation hypotheses generated during decoding in xk (f); 2. Re-group translation hypotheses in xk (f) into a set of buckets xk (c, f) by the coverage vector c associated with eac</context>
<context position="20266" citStr="Koehn (2004)" startWordPosition="3325" endWordPosition="3326">thesis selection are also tuned on NIST 2003 test data. The results are shown in Table 2. NIST 2005 NIST 2008 SYS1 38.66/40.08 27.67/29.19 SYS2 38.04/39.93 27.25/29.14 SYS3 39.50/40.32 28.75/29.68 Word-level Comb 40.45/40.85 29.52/30.35 Hypo Selection 40.09/40.50 29.02/29.71 Table 2: Co-decoding results on test data 589 In the Table 2, the results of a member decoder and its corresponding baseline decoder are grouped together with the later one for the member decoders. On both test sets, every member decoder performs significantly better than its baseline decoder (using the method proposed in Koehn (2004) for statistical significance test). We apply system combination methods to the n-best outputs of both baseline decoders and member decoders. We notice that we can achieve even better performance by applying system combination methods to member decoders’ nbest outputs. However, the improvement margins are smaller than those of baseline decoders on both test sets. This could be the result of less diversified outputs from co-decoding than those from baseline decoders. In particular, the results for hypothesis selection are only slightly better than the best system in co-decoding. We also evaluat</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn, 2004. Statistical significance tests for machine translation evaluation. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a beam search decoder for phrase-based statistical machine translation model.</title>
<date>2004</date>
<booktitle>In Proc. 6th AMTA Conference,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="5462" citStr="Koehn, 2004" startWordPosition="799" endWordPosition="800">ltiple n-best lists. The rest of the paper is structured as follows. Section 2 gives a formal description of the codecoding model, the strategy to apply consensus information and hypotheses ranking in decoding. In Section 3, we make detailed comparison between co-decoding and related work such as system combination and hypotheses selection out of multiple systems. Experimental results and discussions are presented in Section 4. Section 5 concludes the paper. 2 Collaborative Decoding 2.1 Overview Collaborative decoding does not present a full SMT model as other SMT decoders do such as Pharaoh (Koehn, 2004) or Hiero (Chiang, 2005). Instead, it provides a framework that accommodates and coordinates multiple MT decoders. Conceptually, collaborative decoding incorporates the following four constituents: 1. Co-decoding model. A co-decoding model consists of a set of member models, which are a set of augmented baseline models. We call decoders based on member models member decoders, and those based on baseline models baseline decoders. In our work, any Maximum A Posteriori (MAP) SMT model with log-linear formulation (Och, 2002) can be a qualified candidate for a baseline model. The requirement for a </context>
<context position="9175" citStr="Koehn, 2004" startWordPosition="1426" endWordPosition="1427">pproximate xk (f) with n-best hypotheses by convention. Then there is a circular dependency between co-decoding features and xk (f) : on one hand, searching for n-best approximation of xk (f) requires using Equation 2 to select topranked hypotheses; while on the other hand, Equation 2 cannot be computed until every xk (f) is available. We address this issue by employing a bootstrapping method, in which the key idea is that we can use baseline models’ n-best hypotheses as seeds, and iteratively refine member models’ n-best hypotheses with co-decoding. Similar to a typical phrase-based decoder (Koehn, 2004), we associate each hypothesis with a coverage vector c to track translated source words in it. We will use xk (c, f) for the set of hypotheses associated with c, and we also denote with xk (f) _ Uc xk (c, f) the set of all hypotheses generated by member decoder dk in decoding. The codecoding process can be described as follows: 1. For each member decoder dk, perform decoding with a baseline model, and memorize all translation hypotheses generated during decoding in xk (f); 2. Re-group translation hypotheses in xk (f) into a set of buckets xk (c, f) by the coverage vector c associated with eac</context>
<context position="20266" citStr="Koehn (2004)" startWordPosition="3325" endWordPosition="3326">thesis selection are also tuned on NIST 2003 test data. The results are shown in Table 2. NIST 2005 NIST 2008 SYS1 38.66/40.08 27.67/29.19 SYS2 38.04/39.93 27.25/29.14 SYS3 39.50/40.32 28.75/29.68 Word-level Comb 40.45/40.85 29.52/30.35 Hypo Selection 40.09/40.50 29.02/29.71 Table 2: Co-decoding results on test data 589 In the Table 2, the results of a member decoder and its corresponding baseline decoder are grouped together with the later one for the member decoders. On both test sets, every member decoder performs significantly better than its baseline decoder (using the method proposed in Koehn (2004) for statistical significance test). We apply system combination methods to the n-best outputs of both baseline decoders and member decoders. We notice that we can achieve even better performance by applying system combination methods to member decoders’ nbest outputs. However, the improvement margins are smaller than those of baseline decoders on both test sets. This could be the result of less diversified outputs from co-decoding than those from baseline decoders. In particular, the results for hypothesis selection are only slightly better than the best system in co-decoding. We also evaluat</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn, 2004. Pharaoh: a beam search decoder for phrase-based statistical machine translation model. In Proc. 6th AMTA Conference, pages 115-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Brich</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL, demonstration session.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst.</location>
<marker>Koehn, Hoang, Brich, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Brich, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proc. ACL, demonstration session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes-Risk Decoding for Statistical Machine Translation. In</title>
<date>2004</date>
<booktitle>HLT-NAACL,</booktitle>
<pages>169--176</pages>
<contexts>
<context position="1517" citStr="Kumar and Byrne, 2004" startWordPosition="201" endWordPosition="204">explored in decoding. Experimental results on data sets for NIST Chinese-to-English machine translation task show that the co-decoding method can bring significant improvements to all baseline decoders, and the outputs from co-decoding can be used to further improve the result of system combination. 1 Introduction Recent research has shown substantial improvements can be achieved by utilizing consensus statistics obtained from outputs of multiple machine translation systems. Translation consensus can be measured either at sentence level or at word level. For example, Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) decoding over n-best list tries to find a hypothesis with lowest expected loss with respect to all the other translations, which can be viewed as sentence-level consensus-based decoding. Word based methods proposed range from straightforward consensus voting (Bangalore et al., 2001; Matusov et al., 2006) to more complicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated </context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William Byrne 2004. Minimum Bayes-Risk Decoding for Statistical Machine Translation. In HLT-NAACL, pages 169-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Tree-tostring alignment template for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ACL-Coling,</booktitle>
<pages>609--616</pages>
<contexts>
<context position="10429" citStr="Liu et al., 2006" startWordPosition="1655" endWordPosition="1658">o re-decode source sentence f with member models. For member decoder dk, consensus-based features of any hypotheses associated with coverage vector c are computed based on current setting of xS (c, f) for all s but k. New hypotheses generated by dk in re-decoding are cached in xk′ (f); x2, and in turn x1 benefits from improved x2, and so forth. Step 2 is used to facilitate the computation of feature functions hk,l (e, xk (• )), which require both e and every hypothesis in xk (• ) should be translations of the same set of source words. This step seems to be redundant for CKY-style MT decoders (Liu et al., 2006; Xiong et al., 2006; Chiang, 2005) since the grouping is immediately available from decoders because all hypotheses spanning the same range of source sentence have been stacked together in the same chart cell. But to be a general framework, this step is necessary for some state-of-the-art phrase-based decoders (Koehn, 2007; Och and Ney, 2004) because in these decoders, hypotheses with different coverage vectors can co-exist in the same bin, or hypotheses associated with the same coverage vector might appear in different bins. Note that a member model does not enlarge the theoretical search sp</context>
</contexts>
<marker>Liu, Liu, Lin, 2006</marker>
<rawString>Yang Liu, Qun Liu, Shouxun Lin. 2006. Tree-tostring alignment template for statistical machine translation. In Proc. ACL-Coling, pages 609-616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Nicola Ueffi ng</author>
<author>Hermann Ney</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems using enchanced hypotheses alignment.</title>
<date>2006</date>
<booktitle>In Proc. EACL,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="1823" citStr="Matusov et al., 2006" startWordPosition="247" endWordPosition="250">oduction Recent research has shown substantial improvements can be achieved by utilizing consensus statistics obtained from outputs of multiple machine translation systems. Translation consensus can be measured either at sentence level or at word level. For example, Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) decoding over n-best list tries to find a hypothesis with lowest expected loss with respect to all the other translations, which can be viewed as sentence-level consensus-based decoding. Word based methods proposed range from straightforward consensus voting (Bangalore et al., 2001; Matusov et al., 2006) to more complicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). In addition to better a</context>
</contexts>
<marker>Matusov, ng, Ney, 2006</marker>
<rawString>Evgeny Matusov, Nicola Ueffi ng, and Hermann Ney. 2006. Computing consensus translation from multiple machine translation systems using enchanced hypotheses alignment. In Proc. EACL, pages 33-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>295--302</pages>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proc. ACL, pages 295-302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="14717" citStr="Och, 2003" startWordPosition="2408" endWordPosition="2409">sed features will be equivalent to the translation length features. Using disagreement measures instead of translation length there could be two potential advantages: 1) a length feature has been included in the baseline model and we do not need to add one; 2) we can scale disagreement features independently and gain more modeling flexibility. Similar to a language model score, n-gram consensus -based feature values cannot be summed up from smaller hypotheses. Instead, it must be re-computed when building each new hypothesis. 2.5 Model Training We adapt the Minimum Error Rate Training (MERT) (Och, 2003) algorithm to estimate parameters for each member model in co-decoding. Let 𝝀𝑚 be the feature weight vector for member decoder 𝑑𝑚, the training procedure proceeds as follows: 1. Choose initial values for 𝝀1,..., 𝝀𝑀 2. Perform co-decoding using all member decoders on a development set D with 𝝀1, ...,𝝀𝑀. For each decoder 𝑑𝑚, find a new feature weight vector 𝝀𝑚 ′ which optimizes the specified evaluation criterion L on D using the MERT algorithm based on the n-best list ℋ𝑚 generated by 𝑑𝑚: 𝝀𝑚 ′= argmax𝝀 𝐿 (𝑇 |𝝀, ℋ𝑚 , 𝐷)) where T denotes the translations selected by re-ranking the translations in ℋ</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ACL, pages 160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<pages>417--449</pages>
<contexts>
<context position="10774" citStr="Och and Ney, 2004" startWordPosition="1709" endWordPosition="1712">th. Step 2 is used to facilitate the computation of feature functions hk,l (e, xk (• )), which require both e and every hypothesis in xk (• ) should be translations of the same set of source words. This step seems to be redundant for CKY-style MT decoders (Liu et al., 2006; Xiong et al., 2006; Chiang, 2005) since the grouping is immediately available from decoders because all hypotheses spanning the same range of source sentence have been stacked together in the same chart cell. But to be a general framework, this step is necessary for some state-of-the-art phrase-based decoders (Koehn, 2007; Och and Ney, 2004) because in these decoders, hypotheses with different coverage vectors can co-exist in the same bin, or hypotheses associated with the same coverage vector might appear in different bins. Note that a member model does not enlarge the theoretical search space of its baseline model, the only change is hypothesis scoring. By rerunning a complete decoding process, member model can be applied to re-score all hypotheses explored by a decoder. Therefore step 3 can be viewed as full-scale hypothesis re-ranking because the re-ranking scope is beyond the limited n-best hypotheses currently cached in xk.</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4), pages 417-449</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko Rosti</author>
<author>Necip Fazil Ayan</author>
<author>Bing Xiang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>Bonnie Dorr</author>
</authors>
<title>Combining outputs from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>228--235</pages>
<contexts>
<context position="1899" citStr="Rosti et al., 2007" startWordPosition="258" endWordPosition="261">utilizing consensus statistics obtained from outputs of multiple machine translation systems. Translation consensus can be measured either at sentence level or at word level. For example, Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) decoding over n-best list tries to find a hypothesis with lowest expected loss with respect to all the other translations, which can be viewed as sentence-level consensus-based decoding. Word based methods proposed range from straightforward consensus voting (Bangalore et al., 2001; Matusov et al., 2006) to more complicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). In addition to better alignment, Rosti et al. (2008) introduced an incremental strategy for confusi</context>
<context position="16288" citStr="Rosti et al., 2007" startWordPosition="2680" endWordPosition="2683">imize the evaluation criteria on each member decoder’s own n-best output. Figure 1 illustrates the training process of co-decoding with 2 member decoders.  Source sentence decoder1 MERT ℋ1 1 co-decoding ref decoder2 2 MERT ℋ2 𝑃 𝑒′ 𝑑𝑘 = (5) 588 2.6 Output Selection Since there is more than one model in codecoding, we cannot rely on member model’s score function to choose one best translation from multiple decoders’ outputs because the model scores are not directly comparable. We will examine the following two system combination -based solutions to this task: • Word-level system combination (Rosti et al., 2007) of member decoders’ n-best outputs • Hypothesis selection from combined n-best lists as proposed in Hildebrand and Vogel (2008) 3 Experiments In this section we present experiments to evaluate the co-decoding method. We first describe the data sets and baseline systems. 3.1 Data and Metric We conduct our experiments on the test data from the NIST 2005 and NIST 2008 Chinese-toEnglish machine translation tasks. The NIST 2003 test data is used for development data to estimate model parameters. Statistics of the data sets are shown in Table 1. In our experiments all the models are optimized with </context>
<context position="19438" citStr="Rosti et al., 2007" startWordPosition="3195" endWordPosition="3198"> co-decoding features to construct member decoders. By default, the beam size of 20 is used for all decoders in the experiments. We run two iterations of decoding for each member decoder, and hold the value of 𝛼 in Equation 5 as a constant 0.05, which is tuned on the test data of NIST 2004 Chinese-toEnglish machine translation task. 3.3 Translation Results We first present the overall results of codecoding on both test sets using the settings as we described. For member decoders, up to 4- gram agreement and disagreement features are used. We also implemented the word-level system combination (Rosti et al., 2007) and the hypothesis selection method (Hildebrand and Vogel, 2008). 20-best translations from all decoders are used in the experiments for these two combination methods. Parameters for both system combination and hypothesis selection are also tuned on NIST 2003 test data. The results are shown in Table 2. NIST 2005 NIST 2008 SYS1 38.66/40.08 27.67/29.19 SYS2 38.04/39.93 27.25/29.14 SYS3 39.50/40.32 28.75/29.68 Word-level Comb 40.45/40.85 29.52/30.35 Hypo Selection 40.09/40.50 29.02/29.71 Table 2: Co-decoding results on test data 589 In the Table 2, the results of a member decoder and its corres</context>
<context position="26070" citStr="Rosti et al., 2007" startWordPosition="4274" endWordPosition="4277">39.48 39.25 4 39.68 39.61 5 39.52 39.36 6 39.58 39.47 Table 5: Co-decoding with varied n-gram agreement and disagreement features From the results we do not observe BLEU improvement for 𝑛 &gt; 4. One reason could be that the data sparsity for high-order n-grams leads to over fitting on development data. We also empirically investigated the impact of scaling factor 𝛼 in Equation 5. It is observed in Figure 5 that the optimal value is between 0.01 ~ 0.1 on both development and test data. Figure 5. Impact of scaling factor 𝛼 4 Discussion Word-level system combination (system combination hereafter) (Rosti et al., 2007; He et al., 2008) has been proven to be an effective way to improve machine translation quality by using outputs from multiple systems. Our method is different from system combination in several ways. System combination uses unigram consensus only and a standalone decoding model irrelevant to single decoders. Our method uses agreement information of n-grams, and consensus features are integrated into decoding models. By constructing a confusion network, system combination is able to generate new translations different from any one in the input n-best lists, while our method does not extend th</context>
</contexts>
<marker>Rosti, Ayan, Xiang, Matsoukas, Schwartz, Dorr, 2007</marker>
<rawString>Antti-Veikko Rosti, Necip Fazil Ayan, Bing Xiang, Spyros Matsoukas, Richard Schwartz, and Bonnie Dorr. 2007. Combining outputs from multiple machine translation systems. In HLT-NAACL, pages 228-235</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko Rosti</author>
<author>Bing Zhang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Incremental hypothesis alignment for building confusion networks with application to machine translation system combination.</title>
<date>2008</date>
<booktitle>In Proc. Of the Third ACL Workshop on Statistical Machine Translation,</booktitle>
<pages>183--186</pages>
<contexts>
<context position="2452" citStr="Rosti et al. (2008)" startWordPosition="343" endWordPosition="346">omplicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). In addition to better alignment, Rosti et al. (2008) introduced an incremental strategy for confusion network construction; and Hildebrand and Vogel (2008) proposed a hypotheses reranking model for multiple systems’ outputs with more features including word translation probability and n-gram agreement statistics. A common property of all the work mentioned above is that the combination models work on the basis of n-best translation lists (full hypotheses) of existing machine translation systems. However, the n-best list only presents a very small portion of the entire search space of a Statistical Machine Translation (SMT) model while a majorit</context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2008</marker>
<rawString>Antti-Veikko Rosti, Bing Zhang, Spyros Matsoukas, and Richard Schwartz. 2008. Incremental hypothesis alignment for building confusion networks with application to machine translation system combination. In Proc. Of the Third ACL Workshop on Statistical Machine Translation, pages 183-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K C Sim</author>
<author>W Byrne</author>
<author>M Gales</author>
<author>H Sahbi</author>
<author>P Woodland</author>
</authors>
<title>Consensus network decoding for statistical machine translation system combination.</title>
<date>2007</date>
<booktitle>In ICASSP.</booktitle>
<contexts>
<context position="1918" citStr="Sim et al., 2007" startWordPosition="262" endWordPosition="265">statistics obtained from outputs of multiple machine translation systems. Translation consensus can be measured either at sentence level or at word level. For example, Minimum Bayes Risk (MBR) (Kumar and Byrne, 2004) decoding over n-best list tries to find a hypothesis with lowest expected loss with respect to all the other translations, which can be viewed as sentence-level consensus-based decoding. Word based methods proposed range from straightforward consensus voting (Bangalore et al., 2001; Matusov et al., 2006) to more complicated word-based system combination model (Rosti et al., 2007; Sim et al., 2007). Typically, the resulting systems take outputs of individual machine translation systems as input, and build a new confusion network for second-pass decoding. There have been many efforts dedicated to advance the state-of-the-art performance by combining multiple systems’ outputs. Most of the work focused on seeking better word alignment for consensus-based confusion network decoding (Matusov et al., 2006) or word-level system combination (He et al., 2008; Ayan et al., 2008). In addition to better alignment, Rosti et al. (2008) introduced an incremental strategy for confusion network construc</context>
</contexts>
<marker>Sim, Byrne, Gales, Sahbi, Woodland, 2007</marker>
<rawString>K.C. Sim, W. Byrne, M. Gales, H. Sahbi, and P. Woodland. 2007. Consensus network decoding for statistical machine translation system combination. In ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In Proc. HLT-ACL,</booktitle>
<pages>577--585</pages>
<contexts>
<context position="18559" citStr="Shen et al. (2008)" startWordPosition="3046" endWordPosition="3049">cal phrase-based decoder. Phrasal rules are extracted from all bilingual sentence pairs, while rules with variables are extracted only from selected data sets including LDC2003E14, LDC2003E07, LDC2005T06 and LDC2005T10, which contain around 350,000 sentence pairs, 8.8M Chinese words and 10.3M English words. The second one (SYS2) is a BTG decoder with lexicalized reordering model based on maximum entropy principle as proposed by Xiong et al. (2006). We use all the bilingual data to extract phrases up to length 3. The third one (SYS3) is a string-to-dependency tree –based decoder as proposed by Shen et al. (2008). For rule extraction we use the same setting as in SYS1. We parsed the language model training data with Berkeley parser, and then trained a dependency language model based on the parsing output. All baseline decoders are extended with n-gram consensus –based co-decoding features to construct member decoders. By default, the beam size of 20 is used for all decoders in the experiments. We run two iterations of decoding for each member decoder, and hold the value of 𝛼 in Equation 5 as a constant 0.05, which is tuned on the test data of NIST 2004 Chinese-toEnglish machine translation task. 3.3 T</context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A new string-to-dependency machine translation algorithm with a target dependency language model. In Proc. HLT-ACL, pages 577-585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy W Tromble</author>
<author>Shankar Kumar</author>
<author>Franz Och</author>
<author>Wolfgang Macherey</author>
</authors>
<title>Lattice minimum bayes-risk decoding for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>620--629</pages>
<contexts>
<context position="12978" citStr="Tromble et al. (2008)" startWordPosition="2092" endWordPosition="2095">ents on x1 enable d2 to improve e′Exk (f where e is a translation of f by decoder d,,, (,,, # k), e′ is a translation in xk (f) and P (e′ I dk) is the posterior probability of translation e′ determined by decoder dk given source sentence f. Gl (e, e′) is a consensus measure defined on e and e′, by varying which different feature functions can be obtained. 587 Referring to the log-linear model formulation, the translation posterior 𝑃 𝑒′ 𝑑𝑘 can be computed as: exp 𝛼𝐹𝑘 𝑒′ 𝑒′′ ∈ℋ𝑘 𝑓 exp 𝛼𝐹𝑘 𝑒′′ where 𝐹𝑘 (∙) is the score function given in Equation 2, and 𝛼 is a scaling factor following the work of Tromble et al. (2008) To compute the consensus measures, we further decompose each 𝐺𝑙 𝑒, 𝑒′ into n-gram matching statistics between e and 𝑒′. Here we do not discriminate among different lexical n-grams and are only concerned with statistics aggregation of all n-grams of the same order. For each ngram of order n, we introduce a pair of complementary consensus measure functions 𝐺𝑛+ 𝑒, 𝑒′ and 𝐺𝑛− 𝑒, 𝑒′ described as follows: 𝐺𝑛+ 𝑒, 𝑒′ is the n-gram agreement measure function which counts the number of occurrences in 𝑒′ of n-grams in e. So the corresponding feature value will be the expected number of occurrences in ℋ𝑘</context>
<context position="27243" citStr="Tromble et al., 2008" startWordPosition="4463" endWordPosition="4466">-best lists, while our method does not extend the search spaces of baseline decoding models. Member decoders only change the scoring and ranking of the candidates in the search spaces. Results in Table 2 show that these two approaches can be used together to obtain further improvements. The work on multi-system hypothesis selection of Hildebrand and Vogel (2008) bears more resemblance to our method in that both make use of n-gram agreement statistics. They also empirically show that n-gram agreement is the most important factor for improvement apart from language models. Lattice MBR decoding (Tromble et al., 2008) also uses n-gram agreement statistics. Their work focuses on exploring larger evidence space by using a translation lattice instead of the n-best list. They also show the connection between expected n-gram change and corpus Log-BLEU loss. 40.0 39.5 39.0 SYS1 38.5 SYS2 38.0 37.5 0 1 2 3 4 0 0.01 0.03 0.05 0.1 0.2 0.5 1 40.0 39.5 39.0 38.5 38.0 Dev SYS1 Dev SYS2 Test SYS1 Test SYS2 591 5 Conclusion Improving machine translation with multiple systems has been a focus in recent SMT research. In this paper, we present a framework of collaborative decoding, in which multiple MT decoders are coordin</context>
</contexts>
<marker>Tromble, Kumar, Och, Macherey, 2008</marker>
<rawString>Roy W. Tromble, Shankar Kumar, Franz Och, and Wolfgang Macherey. 2008. Lattice minimum bayes-risk decoding for statistical machine translation. In Proc. EMNLP, pages 620-629.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum entropy based phrase reordering model for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>521--528</pages>
<contexts>
<context position="10449" citStr="Xiong et al., 2006" startWordPosition="1659" endWordPosition="1662"> sentence f with member models. For member decoder dk, consensus-based features of any hypotheses associated with coverage vector c are computed based on current setting of xS (c, f) for all s but k. New hypotheses generated by dk in re-decoding are cached in xk′ (f); x2, and in turn x1 benefits from improved x2, and so forth. Step 2 is used to facilitate the computation of feature functions hk,l (e, xk (• )), which require both e and every hypothesis in xk (• ) should be translations of the same set of source words. This step seems to be redundant for CKY-style MT decoders (Liu et al., 2006; Xiong et al., 2006; Chiang, 2005) since the grouping is immediately available from decoders because all hypotheses spanning the same range of source sentence have been stacked together in the same chart cell. But to be a general framework, this step is necessary for some state-of-the-art phrase-based decoders (Koehn, 2007; Och and Ney, 2004) because in these decoders, hypotheses with different coverage vectors can co-exist in the same bin, or hypotheses associated with the same coverage vector might appear in different bins. Note that a member model does not enlarge the theoretical search space of its baseline </context>
<context position="18392" citStr="Xiong et al. (2006)" startWordPosition="3016" endWordPosition="3019">nglish Gigaword corpus version 3. 3.2 Member Decoders We use three baseline decoders in the experiments. The first one (SYS1) is re-implementation of Hiero, a hierarchical phrase-based decoder. Phrasal rules are extracted from all bilingual sentence pairs, while rules with variables are extracted only from selected data sets including LDC2003E14, LDC2003E07, LDC2005T06 and LDC2005T10, which contain around 350,000 sentence pairs, 8.8M Chinese words and 10.3M English words. The second one (SYS2) is a BTG decoder with lexicalized reordering model based on maximum entropy principle as proposed by Xiong et al. (2006). We use all the bilingual data to extract phrases up to length 3. The third one (SYS3) is a string-to-dependency tree –based decoder as proposed by Shen et al. (2008). For rule extraction we use the same setting as in SYS1. We parsed the language model training data with Berkeley parser, and then trained a dependency language model based on the parsing output. All baseline decoders are extended with n-gram consensus –based co-decoding features to construct member decoders. By default, the beam size of 20 is used for all decoders in the experiments. We run two iterations of decoding for each m</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu and Shouxun Lin. 2006. Maximum entropy based phrase reordering model for statistical machine translation. In Proc. ACL, pages 521-528.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>