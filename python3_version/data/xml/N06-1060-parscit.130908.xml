<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997869">
Cross Linguistic Name Matching in English and Arabic: A “One to
Many Mapping” Extension of the Levenshtein Edit Distance Algorithm
</title>
<author confidence="0.9372825">
Dr. Andrew T. Freeman, Dr. Sherri L. Condon and
Christopher M. Ackerman
</author>
<affiliation confidence="0.920307">
The Mitre Corporation
</affiliation>
<address confidence="0.8245715">
7525 Colshire Dr
McLean, Va 22102-7505
</address>
<email confidence="0.994608">
{afreeman, scondon, cackerman}@mitre.org
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999670583333333">
This paper presents a solution to the prob-
lem of matching personal names in Eng-
lish to the same names represented in
Arabic script. Standard string comparison
measures perform poorly on this task due
to varying transliteration conventions in
both languages and the fact that Arabic
script does not usually represent short
vowels. Significant improvement is
achieved by augmenting the classic
Levenshtein edit-distance algorithm with
character equivalency classes.
</bodyText>
<sectionHeader confidence="0.978296" genericHeader="method">
1 Introduction to the problem
</sectionHeader>
<bodyText confidence="0.999910185185185">
Personal names are problematic for all language
technology that processes linguistic content, espe-
cially in applications such as information retrieval,
document clustering, entity extraction, and transla-
tion. Name matching is not a trivial problem even
within a language because names have more than
one part, including titles, nicknames, and qualifiers
such as Jr. or II. Across documents, instances of
the name might not include the same name parts,
and within documents, the second or third mention
of a name will often have only one salient part. In
multilingual applications, the problem is compli-
cated by the fact that when a name is represented
in a script different from its native script, there
may be several alternative representations for each
phoneme, leading to large number of potential
variants for multi-part names.
A good example of the problem is the name of
the current leader of Libya. In Arabic, there is
only one way to write the consonants and long
vowels of any person’s name, and the current
leader of Libya’s name in un-vocalized Arabic text
can only be written as jpi)y2l) _}--. In English,
his name has many common representations. Ta-
ble 1 documents the top five hits returned from a
web search at www.google.com, using various
English spellings of the name.
</bodyText>
<figure confidence="0.709400666666667">
Version Occurrences
Muammar Gaddafi 43,500
Muammar Qaddafi 35,900
Moammar Gadhafi 34,100
Muammar Qadhafi 15,000
Muammar al Qadhafi 11,500
</figure>
<tableCaption confidence="0.987635">
Table 1. Qadhafy’s names in English
</tableCaption>
<bodyText confidence="0.999589125">
Part of this variation is due to the lack of an
English phoneme corresponding to the Standard
Arabic phoneme /q/. The problem is further com-
pounded by the fact that in many dialects spoken in
the Arabic-speaking world, including Libya, this
phoneme is pronounced as [g].
The engineering problem is how one reliably
matches all versions of a particular name in lan-
guage A to all possible versions of the same name
in language B. Most solutions employ standard
string similarity measures, which require the
names to be represented in a common character
set. The solution presented here exploits translit-
eration conventions in normalization procedures
and equivalence mappings for the standard Leven-
shtein distance measure.
</bodyText>
<sectionHeader confidence="0.980754" genericHeader="method">
2 Fuzzy string matching
</sectionHeader>
<bodyText confidence="0.9998868">
The term fuzzy matching is used to describe
methods that match strings based on similarity
rather than identity. Common fuzzy matching
techniques include edit distance, n-gram matching,
and normalization procedures such as Soundex.
</bodyText>
<page confidence="0.982771">
471
</page>
<note confidence="0.995438">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 471–478,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.900685">
This section surveys methods and tools currently
used for fuzzy matching.
</bodyText>
<subsectionHeader confidence="0.928956">
2.1 Soundex
</subsectionHeader>
<bodyText confidence="0.992077555555556">
Patented in 1918 by Odell and Russell the
Soundex algorithm was designed to find spelling
variations of names. Soundex represents classes of
sounds that can be lumped together. The precise
classes and algorithm are shown below in figures 1
and 2.
Code: 0 1 2 3 4 5 6
Letters: aeiouy bp cgjkq dt l mn r
hw fv sxz
</bodyText>
<figureCaption confidence="0.991599">
Figure 1: Soundex phonetic codes
</figureCaption>
<listItem confidence="0.969157111111111">
1. Replace all but the first letter of the string by its
phonetic code.
2. Eliminate any adjacent repetitions of codes.
3. Eliminate all occurrences of code 0, i.e. eliminate
all vowels.
4. Return the first four characters of the resulting
string.
5. Examples: Patrick = P362, Peter = P36, Peterson =
P3625
</listItem>
<figureCaption confidence="0.999474">
Figure 2: The Soundex algorithm
</figureCaption>
<bodyText confidence="0.999947333333333">
The examples in figure 2 demonstrate that
many different names can appear to match each
other when using the Soundex algorithm.
</bodyText>
<subsectionHeader confidence="0.999108">
2.2 Levenshtein Edit Distance
</subsectionHeader>
<bodyText confidence="0.999972157894737">
The Levenshtein algorithm is a string edit-
distance algorithm. A very comprehensive and
accessible explanation of the Levenshtein algo-
rithm is available on the web at
http://www.merriampark.com/ld.htm.
The Levenshtein algorithm measures the edit
distance where edit distance is defined as the num-
ber of insertions, deletions or substitutions required
to make the two strings match. A score of zero
represents a perfect match.
With two strings, string s of size m and string t
of size n, the algorithm has O(nm) time and space
complexity. A matrix is constructed with n rows
and m columns. The function e(si,tj) where si is a
character in the string s, and tj is a character in
string t returns a 0 if the two characters are equal
and a 1 otherwise. The algorithm can be repre-
sented compactly with the recurrence relation
shown in figure 3.
</bodyText>
<equation confidence="0.9990071">
for each i from 0 to |s|
for each j from 0 to |t|
levenshtein(0; 0) = 0
levenshtein(i; 0) = i
levenshtein(0;j) = j
levenshtein (i;j) =
min[levenshtein (i − 1; j) + 1;
levenshtein(i; j − 1) + 1;
levenshtein(i − 1; j − 1) +
e(si; tj )]
</equation>
<figureCaption confidence="0.996088">
Figure 3. Recurrence relation for Levenshtein edit distance
</figureCaption>
<bodyText confidence="0.999966222222222">
A simple “fuzzy-match” algorithm can be cre-
ated by dividing the Levenshtein edit distance
score by the length of the shortest (or longest)
string, subtracting this number from one, and set-
ting a threshold score that must be achieved in or-
der for the strings to be considered a match. In this
simple approach, longer pairs of strings are more
likely to be matched than shorter pairs of strings
with the same number of different characters.
</bodyText>
<subsectionHeader confidence="0.995229">
2.3 Editex
</subsectionHeader>
<bodyText confidence="0.999503214285714">
The Editex algorithm is described by Zobel and
Dart (1996). It combines a Soundex style algo-
rithm with Levenshtein by replacing the e(si,tj)
function of Levenshtein with a function r(si,tj).
The function r(si,tj) returns 0 if the two letters are
identical, 1 if they belong to the same letter group
and 2 otherwise. The full algorithm with the letter
groups is shown in figures 4 and 5. The Editex
algorithm neutralizes the h and w. This shows up
in the algorithm description as d(si-1,si). It is the
same as r(si,tj), with two exceptions. It compares
letters of the same string rather than letters from
the different strings. The other difference is that if
si-1 is h or w, and si-1≠si, then d(si-1,si) is one.
</bodyText>
<equation confidence="0.998210444444445">
for each i from 0 to |s|
for each j from 0 to |t|
editex(0; 0) = 0
editex(i; 0) = editex(i − 1; 0) + d(si−1; si)
editex(0; j) = editex(0; j − 1) + d(tj−1; tj )
editex(i; j) = min[editex (i − 1; j) +
d(si−1; si);
ediext(i; j − 1) + d(tj−1; tj);
editex(i − 1; j − 1) + r(si; tj )]
</equation>
<figureCaption confidence="0.938553">
Figure 4: Recurrence relation for Editex edit distance
</figureCaption>
<equation confidence="0.396475">
0 1 2 3 4 5 6 7 8 9
</equation>
<page confidence="0.9803">
472
</page>
<figureCaption confidence="0.9913295">
aeiouy bp ckq dt lr mn gj fpv sxz csz
Figure 5: Editex letter groups
</figureCaption>
<bodyText confidence="0.9999632">
Zobel and Dart (1996) discuss several en-
hancements to the Soundex and Levenshtein string
matching algorithms. One enhancement is what
they call “tapering.” Tapering involves weighting
mismatches at the beginning of the word with a
higher score than mismatches towards the end of
the word. The other enhancement is what they call
phonometric methods, in which the input strings
are mapped to pronunciation based phonemic rep-
resentations. The edit distance algorithm is then
applied to the phonemic representations of the
strings.
Zobel and Dart report that the Editex algorithm
performed significantly better than alternatives
they tested, including Soundex, Levenshtein edit
distance, algorithms based on counting common n-
gram sequences, and about ten permutations of
tapering and phoneme based enhancements to as-
sorted combinations of Soundex, n-gram counting
and Levenshtein.
</bodyText>
<subsectionHeader confidence="0.998492">
2.4 SecondString
</subsectionHeader>
<bodyText confidence="0.999979571428571">
SecondString, described by Cohen, Ravikumar
and Fienberg (2003) is an open-source library of
string-matching algorithms implemented in Java.
It is freely available at the web site
http://secondstring.sourceforge.net.
The SecondString library offers a wide assort-
ment of string matching algorithms, both those
based on the “edit distance” algorithm, and those
based on other string matching algorithms. Sec-
ondString also provides tools for combining
matching algorithms to produce hybrid-matching
algorithms, tools for training on string matching
metrics and tools for matching on tokens within
strings for multi-token strings.
</bodyText>
<sectionHeader confidence="0.990633" genericHeader="method">
3 Baseline task
</sectionHeader>
<bodyText confidence="0.999910523809524">
An initial set of identical names in English and
Arabic script were obtained from 106 Arabic texts
and 105 English texts in a corpus of newswire arti-
cles. We extracted 408 names from the English
language articles and 255 names from the Arabic
language articles. Manual cross-script matching
identified 29 names common to both lists.
For a baseline measure, we matched the entire
list of names from the Arabic language texts
against the entire list of English language names
using algorithms from the SecondString toolkit.
The Arabic names were transliterated using the
computer program Artrans produced by Basis
(2004).
For each of these string matching metrics, the
matching threshold was empirically set to a value
that would return some matches, but minimized
false matches. The Levenshtein “edit-distance”
algorithm returns a simple integer indicating the
number of edits required to make the two strings
match. We normalized this number by using the
</bodyText>
<equation confidence="0.965877">
Levenshtein(s, t) 
formula 1 −   ,
</equation>
<bodyText confidence="0.757956">
where any pair
</bodyText>
<equation confidence="0.811168">
s+t
 
</equation>
<bodyText confidence="0.995693828571429">
of strings with a fuzzy match score less than 0.875
was not considered to be a match. The intent of
dividing by the length of both names is to mini-
mize the weight of a mismatched character in
longer strings.
For the purposes of defining recall and preci-
sion, we ignored all issues dealing with the fact
that many English names correctly matched more
than one Arabic name, and that many Arabic
names correctly matched more than one English
name. The number of correct matches is the num-
ber of correct matches for each Arabic name,
summed across all Arabic names having one or
more matches. Recall R is defined as the number
of correctly matched English names divided by the
number of available correct English matches in the
test set. Precision P is defined as the total number
of correct names returned by the algorithm divided
by the total number of names returned. The F-
score is 2 ⋅(PR) .
P+R
Figure 5 shows the results obtained from the
four algorithms that were tested. Smith-Waterman
is based on Levenshtein edit-distance algorithm,
with some parameterization of the gap score.
SLIM is an iterative statistical learning algorithm
based on a variety of estimation-maximization in
which a Levenshtein edit-distance matrix is itera-
tively processed to find the statistical probabilities
of the overlap between two strings. Jaro is a type
n-gram algorithm which measures the number and
the order of the common characters between two
strings. Needleman-Wunsch from Cohen et al.’s
(2003) SecondString Java code library is the Java
implementation referred to as “Levenshtein edit
</bodyText>
<page confidence="0.996456">
473
</page>
<bodyText confidence="0.995404">
distance” in this report. The Levenshtein algo-
rithms clearly out performed the other metrics.
</bodyText>
<table confidence="0.9989472">
Algorithm Recall Precision F-score
Smith Waterman 14/29 14/18 0.5957
SLIM 3/29 3/8 0.1622
Jaro 8/29 8/11 0.4
NeedlemanWunsch 19/29 19/23 0.7308
</table>
<figureCaption confidence="0.992861">
Figure 5: Comparison of string similarity metrics
</figureCaption>
<sectionHeader confidence="0.845266" genericHeader="method">
4 Motivation of enhancements
</sectionHeader>
<bodyText confidence="0.999914333333333">
One insight is that each letter in an Arabic
name has more than one possible letter in its Eng-
lish representation. For instance, the first letter of
former Egyptian president Gamal Abd Al-Nasser’s
first name is written with the Arabic letter ��,
which in most other dialects of Arabic is pro-
nounced either as [δΖ] or [Ζ], most closely resem-
bling the English pronunciation of the letter “j”.
As previously noted, ـﻗ has the received pronun-
ciation of [q], but in many dialects it is pronounced
as [g], just like the Egyptian pronunciation of Nas-
ser’s first name Gamal. The conclusion is that
there is no principled way to predict a single repre-
sentation in English for an Arabic letter.
Similarly, Arabic representations of non-native
names are not entirely predictable. Accented syl-
lables will be given a long vowel, but in longer
names, different writers will place the long vowels
showing the accented syllables in different places.
We observed six different ways to represent the
name Milosevic in Arabic.
The full set of insights and “real-world” knowl-
edge of the craft for representing foreign names in
Arabic and English is summarized in figure 6.
These rules are based on first author Dr. Andrew
Freeman’s1 experience with reading and translating
Arabic language texts for more than 16 years.
</bodyText>
<listItem confidence="0.73815325">
1) The hamza (o) and the ‘ayn (p) will
often appear in English language texts
as an apostrophe or as the vowel that
follows.
2) Names not native to Arabic will have a
long vowel or diphthong for accented
syllables represented by “w,” “y” or “A.
3) The high front un-rounded diphthong
</listItem>
<bodyText confidence="0.817705">
(“i,” “ay”, “igh”) found in non-Arabic
names will often be represented with an
</bodyText>
<table confidence="0.960149045454546">
alif-yaa (4) sequence in the Arabic
1 Dr. Freeman’s PhD dissertation was on Arabic dialectology.
script.
The back rounded diphthongs, (ow, au,
oo) will be represented with a single
“waw” in Arabic.
The Roman scripts letters “p” and “v”
are represented by “b” and “f” in Arabic.
The English letter “x” will appear as the
sequence “ks” in Arabic
Silent letters, such as final “e” and in-
ternal “gh” in English names will not
appear in the Arabic script.
Doubled English letters will not be rep-
resented in the Arabic script.
Many Arabic names will not have any
short vowels represented.
The “ch” in the English name “Richard”
will be represented with the two charac-
ter sequence “t” (L-) and “sh” (cam). The
name “Buchanan” will be represented in
Arabic with the letter “k” (A).
</table>
<figureCaption confidence="0.714501">
Figure 6: Rules for Arabic and English representations
</figureCaption>
<sectionHeader confidence="0.831206" genericHeader="method">
5 Implementation of the enhancements
</sectionHeader>
<subsectionHeader confidence="0.977103">
5.1 Character Equivalence Classes (CEQ):
</subsectionHeader>
<bodyText confidence="0.999989166666667">
The implementation of the enhancements has
six parts. We replaced the comparison for the
character match in the Levenshtein algorithm with
a function Ar(si, tj ) that returns zero if the character
tj from the English string is in the match set for the
Arabic character si;, otherwise it returns a one.
</bodyText>
<equation confidence="0.9962082">
for each i from 0 to |s|
for each j from 0 to |t|
levenshtein(0; 0) = 0
levenshtein(i; 0) = i
levenshtein(0;j) = j
levenshtein (i;j) =
min
[levenshtein (i − 1; j) + 1;
levenshtein(i; j − 1) + 1;
levenshtein(i − 1; j − 1) + Ar(si; tj )]
</equation>
<figureCaption confidence="0.998315">
Figure 7: Cross linguistic Levenshtein
</figureCaption>
<bodyText confidence="0.999977375">
String similarity measures require the strings to
have the same character set, and we chose to use
transliterated Arabic so that investigators who
could not read Arabic script could still view and
understand the results. The full set of transliterated
Arabic equivalence classes is shown in Figure 8.
The set was intentionally designed to handle Ara-
bic text transliterated into either the Buckwalter
</bodyText>
<page confidence="0.995762">
474
</page>
<figure confidence="0.8642235">
i i, e ـِ
u u, o ُ
</figure>
<figureCaption confidence="0.999195">
Figure 8: Arabic to English character equivalence sets
</figureCaption>
<bodyText confidence="0.985365333333333">
transliteration (Buckwalter, 2002) or the default
setting of the transliteration software developed by
Basis Technology (Basis, 2004).
</bodyText>
<subsectionHeader confidence="0.998272">
5.2 Normalizing the Arabic string
</subsectionHeader>
<bodyText confidence="0.9999635">
The settings used with the Basis Artrans trans-
literation tool transforms certain Arabic letters into
English digraphs with the appropriate two charac-
ters from the following set: (kh, sh, th, dh). The
Buckwalter transliteration method requires a one-
to-one and recoverable mapping from the Arabic
script to the transliterated script. We transformed
these characters into the Basis representation with
regular expressions. These regular expressions are
shown in figure 9 as perl script.
</bodyText>
<table confidence="0.990234585365854">
Translit- English equivalence class Arabic
eration letter
&apos; &apos;,a ,A,e,E,i,I,o,O,u,U ء
 |&apos;,a ,A,e ,E,i ,I,o ,O,u ,U ﺁ
&gt; &apos;,a ,A,e ,E,i ,I,o ,O,u ,U r
&amp; &apos;,a ,A,e ,E,i ,I,o ,O,u ,U ؤ
&lt; &apos;,a ,A,e ,E,i ,I,o ,O,u ,U إ
} &apos;,a ,A,e ,E,i ,I,o ,O,u ,U is
A &apos;,a ,A,e ,E,i ,I,o ,O,u ,U ا
b b ,B,p ,P,v,V ب
p a ,e ة
+ a ,e ة
t t,T ت
v t ,T ث
J J,J,g,G ـﺟ
H h, H ـﺣ
x k, K ـﺧ
d d, D د
* d, D ذ
r r, R ر
z z, Z ز
s s, S,c, C س
$ s, S ش
S s, S w
D d, D ض
T t, T ط
Z z, Z,d, D ظ
E &apos;,`,c,a,A,e,E,i,I,o,O,u,U ع
` &apos;,`,c,a,A,e,E,i,I,o,O,u,U ع
g g, G غ
f f, F,v, V ف
q q, Q, g, G,k, K ق
k k, K,c, C,S, s ك
l l, L ل
m m, M م
n n, N ن
h h, H ـه
w w, W,u, u,o, O, 0 و
y y, Y, i, I, e, E, ,J, J ي
Y a, A,e, E,i, I, o,O,u, U ى
a a, e ـَ
</table>
<equation confidence="0.996616727272727">
$s1 =~ s/\$/sh/g; # normalize Buckwalter
$s1 =~ s/v/th/g; # normalize Buckwalter
$s1 =~ s/\*/dh/g; # normalize Buckwalter
$s1 =~ s/x/kh/g; # normalize Buckwalter
$s1 =~ s/(F|K|N|o|~)//g; # remove case vowels,
# the shadda and the sukuun
$s1 =~ s/\&apos;aa/\|/g; # normalize basis w/
# Buckwalter madda
$s1 =~ s/(U|W|I|A)/A/g; # normalize hamza
$s1 =~ s/_//; # eliminate underscores
$s1 =~ s/\s//g; # eliminate white space
</equation>
<figureCaption confidence="0.998258">
Figure 9. Normalizing the Arabic
</figureCaption>
<subsectionHeader confidence="0.989724">
5.3 Normalizing the English string
</subsectionHeader>
<bodyText confidence="0.9997415">
Normalization enhancements were aimed at
making the English string more closely match the
transliterated form of the Arabic string. These cor-
respond to points 2 through 7 of the list in Figure
6. The perl code that implemented these transfor-
mations is shown in figure 10.
</bodyText>
<equation confidence="0.9980078">
$s2 =~ s/(a|e|i|A|E|I)(e|i|y)/y/g;
# hi dipthongs go to y in Arabic
$s2 =~ s/(e|a|o)(u|w|o)/w/g;
# lo dipthongs go to w in Arabic
$s2 =~ s/(P|p)h/f/g; # ph -&gt; f in Arabic
$s2 =~ s/(S|s)ch/sh/g; # sch is sh
$s2 =~ s/(C|c)h/tsh/g; # ch is tsh or k ,
# we catch the &amp;quot;k&amp;quot; on the pass
$s2 =~ s/-//g; # eliminate all hyphens
$s2 =~ s/x/ks/g; # x-&gt;ks in Arabic
$s2 =~ s/e( |$)/$1/g; # the silent final e
$s2 =~ s/(\S)\1/$1/g; # eliminate duplicates
$s2 =~ s/(\S)gh/$1/g; # eliminate silent gh
$s2 =~ s/\s//g; # eliminate white space
$s2 =~ s/(\.|,|;)//g; # eliminate punctuation
</equation>
<figureCaption confidence="0.957497">
Figure 10. Normalizing the English
</figureCaption>
<subsectionHeader confidence="0.99585">
5.4 Normalizing the vowel representations
</subsectionHeader>
<bodyText confidence="0.9990848">
Normalization of the vowel representations is
based on two observations that correspond to
points 2 and 8 of Figure 6. Figure 11 shows some
English names represented in Arabic transliterated
using the Buckwalter transliteration method.
</bodyText>
<table confidence="0.99815625">
Name in English Name in Arabic Arabic
transliteration
Bill Clinton ﻥﻭﺘﻨﻴﻠﻜ لﻴﺒ byl klyntwn
Colin Powell لﻭﺎﺒ ﻥﻴﻟﻭﻜ kwlyn bAwl
</table>
<page confidence="0.802537">
475
</page>
<figure confidence="0.3625445">
Richard Cheney DIPLiFfrOL�F rytshArd strings. The algorithm is a variant of a sorted file
tshyny merge.
</figure>
<figureCaption confidence="0.983632">
Figure 11. English names as represented in Arabic
</figureCaption>
<bodyText confidence="0.998045">
All full, accented vowels are represented in the
Arabic as a long vowel or diphthong. This vowel
or diphthong will appear in the transliterated un-
vocalized text as either a “w,” “y” or “A.” Unac-
cented short vowels such as the “e” found in the
second syllable of “Powell” are not represented in
Arabic. Contrast figure 11 with the data in figure
12.
</bodyText>
<table confidence="0.997398333333333">
Name in Arabic Name in English
Arabic transliteration
,at.�_ mSTfY Alshykh Mustafa al Sheikh
,.,,, Z�411 dyb Deeb
ULz N--- mHmd EATf Muhammad Atef
J-)L- ,,­ Hsny mbArk Hosni Mubarak
</table>
<figureCaption confidence="0.946002">
Figure 12. Arabic names as represented in English
</figureCaption>
<bodyText confidence="0.999807583333333">
The Arabic only has the lengtheners “y”, “w”,
or “A” where there are lexically determined long
vowels or diphthongs in Arabic. The English rep-
resentation of these names must contain a vowel
for every syllable. The edit-distance score for
matching “Muhammad” with “mHmd” will fail
since only 4 out of 7 characters match. Lowering
the match threshold will raise the recall score while
lowering the precision score. Stripping all vowels
from both strings will raise the precision on the
matches for Arabic names in English, but will
lower the precision for English names in Arabic.
</bodyText>
<subsectionHeader confidence="0.319504">
For each i from 0 to min(|Estring|, |Astring|),
</subsectionHeader>
<bodyText confidence="0.3822125">
each j from 0 to min(|Estring|, |Astring|)
if Astringi equals Estringj
</bodyText>
<equation confidence="0.215699">
Outstringi = Estringi increment i and j
if vowel(Astringi) and vowel(Estringj)
Outstringi = Estringi increment i and j
</equation>
<bodyText confidence="0.2644585">
if not vowel(Astringi) and vowel(Estringj)
increment j but not i
</bodyText>
<figure confidence="0.219271428571429">
if j &lt; |Estring|
Outstringi = Estring; increment i and j
otherwise
Outstringi = Estringi; increment i and j
Finally if there is anything left of Estring,
strip all vowels from what is left
append Estring to end of Outstring
</figure>
<figureCaption confidence="0.978986">
Figure 13. Algorithm for retaining matching vowels
</figureCaption>
<bodyText confidence="0.933040461538462">
The algorithm presented in figure 13 retains
only those vowels that are represented in both
5.5 Normalizing “ch” representations with a
separate pass
This enhancement requires a separate pass. The
name “Buchanan” is represented in Arabic as “by-
wkAnAn” and “Richard” is “rytshArd.” Thus,
whichever choice the software makes for the cor-
rect value of the English substring “ch,” it will
choose incorrectly some significant number of
times. In one pass, every “ch” in the English string
gets mapped to “tsh.” In a separate pass, every
“ch” in the English string is transformed into a “k.”
</bodyText>
<subsectionHeader confidence="0.998271">
5.6 Light Stemming
</subsectionHeader>
<bodyText confidence="0.999977333333333">
The light stemming performed here was to re-
move the first letter of the transliterated Arabic
name if it matched the prefixes “b,” “l” or “w” and
run the algorithm another time if the match score
was below the match threshold but above another
lower threshold. The first two items are preposi-
tions that attach to any noun. The third is a con-
junction that attaches to any word. Full stemming
for Arabic is a separate and non-trivial problem.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999750333333333">
The algorithm with all enhancements was im-
plemented in perl and in Java. Figure 14 presents
the results of the enhanced algorithm on the origi-
nal baseline as compared with the baseline algo-
rithm. The enhancements improved the F-score by
22%.
</bodyText>
<table confidence="0.976085666666667">
Algorithm Recall Precision F-score
Baseline 19/29 19/23 0.7308
Enhancements 29/29 29/32 0.9508
</table>
<figureCaption confidence="0.983718">
Figure 14. Enhanced edit distance on original data set
</figureCaption>
<subsectionHeader confidence="0.987733">
6.1 Results with a larger data set
</subsectionHeader>
<bodyText confidence="0.999972777777778">
After trying the algorithm out on a couple more
“toy” data sets with similar results, we used a more
realistic data set, which I will call the TDT data
set. This data set was composed of 577 Arabic
names and 968 English names that had been manu-
ally extracted from approximately 250 Arabic and
English news articles on common topics in a NIST
TDT corpus. There are 272 common names. The
number of strings on the English side that correctly
</bodyText>
<page confidence="0.997322">
476
</page>
<bodyText confidence="0.999860583333333">
match an Arabic language string is 591. The actual
number of matches in the set is 641, since many
Arabic strings match to the same set of English
names. For instance, “Edmond Pope” has nine
variants in English and six variants in Arabic. This
gives 36 correct matches for the six Arabic spell-
ings of Edmond Pope.
We varied the match threshold for various
combinations of the described enhancements. The
plots of the F-score, precision and recall from these
experiments using the TDT data set are shown in
figures 15, 16, and 17.
</bodyText>
<sectionHeader confidence="0.999625" genericHeader="conclusions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.99914925">
Figure 15 shows that simply adding the “char-
acter equivalency classes” (CEQ) to the baseline
algorithm boosts the F-score from around 48% to
around 72%. Adding all other enhancements to the
baseline algorithm, without adding CEQ only im-
proves the f-score marginally. Combining these
same enhancements with the CEQ raises the f-
score by roughly 7% to almost 80%.
When including CEQ, the algorithm has a peak
performance with a threshold near 85%. When
CEQ is not included, the algorithm has a peak per-
formance when the match threshold is around 70%.
The baseline algorithm will declare that the strings
match at a cutoff of 70%. Because we are normal-
izing by dividing by the lengths of both strings,
this allows strings to match when half of their let-
ters do not match. The CEQ forces a structure
onto which characters are an allowable mismatch
before the threshold is applied. This apparently
leads to a reduction in the number allowable mis-
matches when the match threshold is tested.
The time and space complexity of the baseline
Levenshtein algorithm is a function of the length of
the two input strings, being |s |* |t|. This makes the
time complexity (N2) where N is the size of the
average input string. The enhancements described
here add to the time complexity. The increase is
an average two or three extra compares per charac-
ter and thus can be factored out of any equation.
The new time complexity is K(|s|*|t|) where K &gt;=
3.
What we do here is the opposite of the approach
taken by the Soundex and Editex algorithms. They
try to reduce the complexity by collapsing groups
of characters into a single super-class of characters.
The algorithm here does some of that with the
steps that normalize the strings. However, the
largest boost in performance is with CEQ, which
expands the number of allowable cross-language
matches for many characters.
One could expect that increasing the allowable
number of matches would over-generate, raising
the recall while lowering the precision.
Referring to Figure 8, we see that’s ome Arabic
graphemes map to overlapping sets of characters in
the English language strings.
Arabic ـﺠ can be realized, as either [j] or [g],
and one of the reflexes in English for Arabic ® can
be [g] as well. How do we differentiate the one
from the other? Quite simply, the Arabic input is
not random data. Those dialects that produce ® as
a [g] will as a rule not produce ـﺟ as [g] and vice
versa. The Arabic pronunciation of the string de-
termines the correct alternation of the two charac-
ters for us as it is written in English. On a string-
by-string basis, it is very unlikely that the two rep-
resentations will conflict. The numbers show that
by adding CEQ, the baseline algorithm’s recall at
threshold of 72.5%, goes from 57% to around 67%
at a threshold of 85% for Arabic to English cross-
linguistic name matching. Combining all of the
enhancements raises the recall at a threshold of
85%, to 82%. As previously noted, augmenting
the baseline algorithm with all enhancements ex-
cept CEQ, does improve the performance dramati-
cally. CEQ combines well with the other
enhancements.
It is true that there is room for a lot improve-
ment with an f-score of 80%. However, anyone
doing cross-linguistic name matches would proba-
bly benefit by implementing some form of the
character equivalence classes detailed here.
</bodyText>
<page confidence="0.99181">
477
</page>
<figure confidence="0.84876375">
F all enh F str norm
F vowel dance F String Norm &amp; Vowel Dance
F all No Eq Class F baseline
F Eq Class only F EC StrN VowD
</figure>
<sectionHeader confidence="0.676067" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999353083333333">
Basis Technology. 2004. Arabic Transliteration Mod-
ule. Artrans documentation. (The documentation is
available for download at
http://www.basistech.com/arabic-editor.)
Bilenko, Mikael, Mooney, Ray, Cohen, William W.,
Ravikumar, Pradeep and Fienberg, Steve. 2003.
Adaptive Name-Matching. in Information Integration
in IEEE Intelligent Systems, 18(5): 16-23.
Buckwalter, Tim. 2002. Arabic Transliteration.
http://www.qamus.org/transliteration.htm.
Cohen, William W., Ravikumar, Pradeep and Fienberg,
Steve. 2003. A Comparison of String Distance Met-
rics for Name-Matching Tasks. IIWeb 2003: 73-78.
Jackson, Peter and Moulinier, Isabelle. 2002 . Natural
Language Processing for Online Applications: Text
Retrieval, Extraction, and Categorization (Natural
Language Processing, 5). John Benjamins Publish-
ing.
Jurafsky, Daniel, and James H. Martin. 2000. Speech
and Language Processing: An Introduction to Natu-
ral Language Processing, Speech Recognition, and
Computational Linguistics. Prentice-Hall.
Knuth, Donald E. 1973. The Art of Computer Pro-
gramming, Volume 3: Sorting and Searching. . Addi-
son-Wesley Publishing Company,
Ukonnen, E. 1992. Approximate string-matching with
q-grams and maximal matches. Theoretical Com-
puter Science, 92: 191-211.
Wright, W. 1967. A Grammar of the Arabic Language.
Cambridge. Cambridge University Press.
Zobel, Justin and Dart, Philip. 1996. Phonetic string
matching: Lessons from information retrieval.in
Proceedings of the Eighteenth ACM SIGIR Interna-
tional Conference on Research and Development in
Information Retrieval, Zurich, Switzerland, August
1996, pp. 166-173.
</reference>
<figure confidence="0.998186846153846">
F-score
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0.875 0.85 0.825 0.8 0.775 0.75 0.725 0.7
Threshold
</figure>
<figureCaption confidence="0.9846625">
Figure 15: F-score by match threshold
Figure 16: Recall by threshold
</figureCaption>
<figure confidence="0.983588833333333">
1
0.9
0.8
0.7
0.6
0.5
R
0.4
0.3
0.2
0.1
0
R EC StrN Vow D R all
R baseline R StrNrm &amp; VowoelD R eq class only
0.875 0.85 0.825 0.8 0.775 0.75 0.725 0.7
1
0.9
0.8
0.7
0.6
P
0.5
0.4
0.3
0.2
0.1
0
Threshold
0.875 0.85 0.825 0.8 0.775 0.75 0.725 0.7
P eq class only P all P baseline P all No Eq Class
</figure>
<figureCaption confidence="0.973944">
Figure 17: Precision by threshold
</figureCaption>
<page confidence="0.994261">
478
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.655128">
<title confidence="0.8994065">Cross Linguistic Name Matching in English and Arabic: A “One Many Mapping” Extension of the Levenshtein Edit Distance Algorithm</title>
<author confidence="0.941759">Andrew T Freeman</author>
<author confidence="0.941759">Dr Sherri L Condon Christopher M</author>
<affiliation confidence="0.883237">The Mitre</affiliation>
<address confidence="0.9703915">7525 Colshire McLean, Va 22102-7505</address>
<email confidence="0.987928">afreeman@mitre.org</email>
<email confidence="0.987928">scondon@mitre.org</email>
<email confidence="0.987928">cackerman@mitre.org</email>
<abstract confidence="0.999287076923077">This paper presents a solution to the problem of matching personal names in English to the same names represented in Arabic script. Standard string comparison measures perform poorly on this task due to varying transliteration conventions in both languages and the fact that Arabic script does not usually represent short vowels. Significant improvement achieved by augmenting the classic Levenshtein edit-distance algorithm with character equivalency classes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Basis Technology</author>
</authors>
<title>Arabic Transliteration Module. Artrans documentation. (The documentation is available for download at http://www.basistech.com/arabic-editor.)</title>
<date>2004</date>
<marker>Technology, 2004</marker>
<rawString>Basis Technology. 2004. Arabic Transliteration Module. Artrans documentation. (The documentation is available for download at http://www.basistech.com/arabic-editor.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikael Bilenko</author>
<author>Ray Mooney</author>
<author>William W Cohen</author>
<author>Pradeep Ravikumar</author>
<author>Steve Fienberg</author>
</authors>
<date>2003</date>
<journal>Adaptive Name-Matching. in Information Integration in IEEE Intelligent Systems,</journal>
<volume>18</volume>
<issue>5</issue>
<pages>16--23</pages>
<marker>Bilenko, Mooney, Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>Bilenko, Mikael, Mooney, Ray, Cohen, William W., Ravikumar, Pradeep and Fienberg, Steve. 2003. Adaptive Name-Matching. in Information Integration in IEEE Intelligent Systems, 18(5): 16-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Arabic Transliteration.</title>
<date>2002</date>
<note>http://www.qamus.org/transliteration.htm.</note>
<contexts>
<context position="15197" citStr="Buckwalter, 2002" startWordPosition="2518" endWordPosition="2519">venshtein(i; j − 1) + 1; levenshtein(i − 1; j − 1) + Ar(si; tj )] Figure 7: Cross linguistic Levenshtein String similarity measures require the strings to have the same character set, and we chose to use transliterated Arabic so that investigators who could not read Arabic script could still view and understand the results. The full set of transliterated Arabic equivalence classes is shown in Figure 8. The set was intentionally designed to handle Arabic text transliterated into either the Buckwalter 474 i i, e ـِ u u, o ُ Figure 8: Arabic to English character equivalence sets transliteration (Buckwalter, 2002) or the default setting of the transliteration software developed by Basis Technology (Basis, 2004). 5.2 Normalizing the Arabic string The settings used with the Basis Artrans transliteration tool transforms certain Arabic letters into English digraphs with the appropriate two characters from the following set: (kh, sh, th, dh). The Buckwalter transliteration method requires a oneto-one and recoverable mapping from the Arabic script to the transliterated script. We transformed these characters into the Basis representation with regular expressions. These regular expressions are shown in figure</context>
</contexts>
<marker>Buckwalter, 2002</marker>
<rawString>Buckwalter, Tim. 2002. Arabic Transliteration. http://www.qamus.org/transliteration.htm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Pradeep Ravikumar</author>
<author>Steve Fienberg</author>
</authors>
<title>A Comparison of String Distance Metrics for Name-Matching Tasks. IIWeb</title>
<date>2003</date>
<pages>73--78</pages>
<marker>Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>Cohen, William W., Ravikumar, Pradeep and Fienberg, Steve. 2003. A Comparison of String Distance Metrics for Name-Matching Tasks. IIWeb 2003: 73-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Jackson</author>
<author>Isabelle Moulinier</author>
</authors>
<title>Natural Language Processing for Online Applications:</title>
<date>2002</date>
<booktitle>Text Retrieval, Extraction, and Categorization (Natural Language Processing,</booktitle>
<volume>5</volume>
<publisher>John Benjamins Publishing.</publisher>
<marker>Jackson, Moulinier, 2002</marker>
<rawString>Jackson, Peter and Moulinier, Isabelle. 2002 . Natural Language Processing for Online Applications: Text Retrieval, Extraction, and Categorization (Natural Language Processing, 5). John Benjamins Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics.</title>
<date>2000</date>
<publisher>Prentice-Hall.</publisher>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Jurafsky, Daniel, and James H. Martin. 2000. Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald E Knuth</author>
</authors>
<title>The Art of Computer Programming, Volume 3: Sorting</title>
<date>1973</date>
<publisher>Addison-Wesley Publishing Company,</publisher>
<marker>Knuth, 1973</marker>
<rawString>Knuth, Donald E. 1973. The Art of Computer Programming, Volume 3: Sorting and Searching. . Addison-Wesley Publishing Company,</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ukonnen</author>
</authors>
<title>Approximate string-matching with q-grams and maximal matches.</title>
<date>1992</date>
<journal>Theoretical Computer Science,</journal>
<volume>92</volume>
<pages>191--211</pages>
<marker>Ukonnen, 1992</marker>
<rawString>Ukonnen, E. 1992. Approximate string-matching with q-grams and maximal matches. Theoretical Computer Science, 92: 191-211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wright</author>
</authors>
<title>A Grammar of the Arabic Language. Cambridge.</title>
<date>1967</date>
<publisher>Cambridge University Press.</publisher>
<marker>Wright, 1967</marker>
<rawString>Wright, W. 1967. A Grammar of the Arabic Language. Cambridge. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Zobel</author>
<author>Philip Dart</author>
</authors>
<title>Phonetic string matching: Lessons from information retrieval.in</title>
<date>1996</date>
<booktitle>Proceedings of the Eighteenth ACM SIGIR International Conference on Research and Development in Information Retrieval,</booktitle>
<pages>166--173</pages>
<location>Zurich, Switzerland,</location>
<contexts>
<context position="6003" citStr="Zobel and Dart (1996)" startWordPosition="979" endWordPosition="982"> j − 1) + 1; levenshtein(i − 1; j − 1) + e(si; tj )] Figure 3. Recurrence relation for Levenshtein edit distance A simple “fuzzy-match” algorithm can be created by dividing the Levenshtein edit distance score by the length of the shortest (or longest) string, subtracting this number from one, and setting a threshold score that must be achieved in order for the strings to be considered a match. In this simple approach, longer pairs of strings are more likely to be matched than shorter pairs of strings with the same number of different characters. 2.3 Editex The Editex algorithm is described by Zobel and Dart (1996). It combines a Soundex style algorithm with Levenshtein by replacing the e(si,tj) function of Levenshtein with a function r(si,tj). The function r(si,tj) returns 0 if the two letters are identical, 1 if they belong to the same letter group and 2 otherwise. The full algorithm with the letter groups is shown in figures 4 and 5. The Editex algorithm neutralizes the h and w. This shows up in the algorithm description as d(si-1,si). It is the same as r(si,tj), with two exceptions. It compares letters of the same string rather than letters from the different strings. The other difference is that if</context>
</contexts>
<marker>Zobel, Dart, 1996</marker>
<rawString>Zobel, Justin and Dart, Philip. 1996. Phonetic string matching: Lessons from information retrieval.in Proceedings of the Eighteenth ACM SIGIR International Conference on Research and Development in Information Retrieval, Zurich, Switzerland, August 1996, pp. 166-173.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>