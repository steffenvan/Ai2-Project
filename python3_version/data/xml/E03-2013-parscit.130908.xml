<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.029862">
<title confidence="0.97134">
Robust Generic and Query-based Summarisation
</title>
<author confidence="0.911793333333333">
Horacio Saggion
Kalina Bontcheva
Hamish Cunningham
</author>
<affiliation confidence="0.99767">
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.9669145">
211 Portobello Street - Sheffield - Si 4DP
England - United Kingdom
</address>
<email confidence="0.992168">
Isaggion, kalina, hamishl@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.993624" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999783727272727">
We present a robust summarisation sys-
tem developed within the GATE archi-
tecture that makes use of robust compo-
nents for semantic tagging and corefer-
ence resolution provided by GATE. Our
system combines GATE components with
well established statistical techniques de-
veloped for the purpose of text summari-
sation research. The system supports
&amp;quot;generic&amp;quot; and query-based summarisation
addressing the need for user adaptation.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999972848484849">
Two approaches are generally considered in au-
tomatic text summarisation research: the shallow
sentence extraction approach and the deep, un-
derstand and generate approach (Mani, 2000).
Sentence extraction methods are quite robust, but
sentence extracts suffer from lack of cohesion and
coherence. Methods that identify the essential
information of the document by either information
extraction or text understanding and that use the
key information to produce a new text, lead to
high-quality summarisation (Paice and Jones,
1993; Saggion and Lapalme, 2002) but suffer
from the knowledge-bottleneck problem: adapting
information extraction rules, templates, and gen-
eration grammars to new tasks or domains is time
consuming. An alternative to these approaches is to
use combination of robust techniques for semantic
tagging together with statistical methods (Saggion,
2002).
Here, we present a summarisation system that
makes use of robust components for semantic tag-
ging and coreference resolution provided by GATE
(Cunningham et al., 2002). Our system combines
GATE components with well established statistical
techniques developed for the purpose of text sum-
marisation. The result is the sentence extraction
system shown in Figure 1, the relevant sentences
of the document are highlighted in the GATE user
interface. The figure also shows semantic informa-
tion identified within the document (e.g., named en-
tities). All summarisation components developed as
part of this research are made available as a Java Li-
brary for research purposes 1.
</bodyText>
<sectionHeader confidence="0.914161" genericHeader="method">
2 The Summariser
</sectionHeader>
<bodyText confidence="0.999938823529412">
Our system is a pipeline of linguistic and statisti-
cal components. Some of them are based on AN-
NIE, a free IE system available as part of GATE2. A
number of components have been developed for the
purpose of this research and they make use of the
information produced by ANNIE. These modules
can be coupled and decoupled to produce different
summarisation configurations. The system supports
&amp;quot;generic&amp;quot; and query-based summarisation address-
ing the need for user adaptation.
The input to the process is a document, a compres-
sion rate, and a query (optional). The document is
automatically transformed by a text structure anal-
yser into a GATE document: a structure containing
the &amp;quot;text&amp;quot; of the original input and a number of an-
notation sets. Each component in the pipeline adds
new information to the document in the form of new
</bodyText>
<footnote confidence="0.929512">
&apos;The summarisation components can be obtained by con-
tacting Horacio Saggion http://www.dcs.shef.ac.
uk/-saggion.
2http: //gate.ac.uk/.
</footnote>
<page confidence="0.996996">
235
</page>
<figureCaption confidence="0.999641">
Figure 1. Summarisation results
</figureCaption>
<figure confidence="0.993078837209303">
men forth F grne
she herse7M147 reneived
gsNed Figs Imes,
—0441.(1710-cate leave
arller
Gate 6.4 1047
Opgione Toole Help
E hapliFL•ons
- FP,MAIENT ANAL
SLAWAAPLELP
A TECH-2
llAg TECH-I
in CORM.
I a llesourdeg
Es TEEM FREQUEILEC
STALKTIC COME..
SENTENCE COMESI
POSITION
--10 COE?, • CnXurAENT
7 A
LAW IWO LEGAL AFFAIRS (LAW)
11/11301•1_114ONS, STRIVER WAGES, REOREITMENT(LAR)
.LAIN • LEGAL ISSUES ANIS LEGISLATION (LEE
E.AcF0AENT IssuES OIJ1D
NEW LE125E711,0
NOR, AmERIGA tu.E)
unicrED STATES 0J6,
crthew notIv.7114-2 could erg el:0014 reRalle 1/7
OsEeno later [&apos;miler am,. elec.,&apos; MI was en-
Men Ede VIM legve wee at a rrgerm¢r, Macrelon and
cluE1 apply. men•
H-i
Eirsteenson
Moller
L
L)
El NO-.
ri
MiL■a
sereence_vetbr
u...marlgos anndat
rewIelcns aero
ouc
</figure>
<bodyText confidence="0.9977232">
annotations or document features. Some summari-
sation components compute numerical features for
the purpose of sentence scoring. These features are
linearly combined in order to produce the sentence
final score.
</bodyText>
<subsectionHeader confidence="0.940508">
2.1 General Purpose Components
</subsectionHeader>
<bodyText confidence="0.9833655">
These general purpose components are part of the
ANNIE system, distributed with GATE:
</bodyText>
<listItem confidence="0.983226535714286">
• Unicode tokeniser: splits text into simple to-
kens, such as numbers, punctuation, symbols,
and words of different types (e.g. with an ini-
tial capital, all upper case);
• Sentence splitter that identifies sentence
boundaries;
• Gazetteer lookup that identifies and classifies
key words related to particular entity types and
help in the process of named entity recognition;
• Named entity recogniser that identifies and
classifies more complex sequences of tokens in
the source document. We use JAPE (Java An-
notation Pattern Engine), a pattern-matching
engine implemented in Java, to identify entities
of type person, location, organisation, money,
date, percentage, and address. For other se-
mantic categories in particular domains, spe-
cific grammar rules can be developed.
• Part-of-speech tagging is done with an imple-
mentation of the &amp;quot;independence and commit-
ment&amp;quot; learning approach to POS tagging;
• Morphological analyser (this module is not
part of the GATE distribution), is a rule-based
lemmatiser that produces an affix and root for
each noun and verb in the input text.
• Coreference resolution, it is a light-weight,
corpus-based approach for the resolution of
named entities anaphora in text.
</listItem>
<subsectionHeader confidence="0.992422">
2.2 Summarisation Components and Scoring
</subsectionHeader>
<bodyText confidence="0.998626">
These modules have been developed for the purpose
of summarisation research and are made available as
a library of Java classes and configuration file (i.e.
creole in GATE terminology):
</bodyText>
<listItem confidence="0.996192769230769">
• Corpus statistics: token statistics including to-
ken frequency and lemma (or root) frequency
are computed in this step.
• Vector space model (Salton, 1988): is used to
create a vector representation of different text
units. Each vector contains the tokens of the
text unit and the value token frequency * in-
verted document frequency. Inverted document
frequencies (i.e., distribution of tokens in a big
collection) for English is computed using the
British National Corpus (this information is a
parameter of the summariser making possible
to experiment with frequencies from different
</listItem>
<page confidence="0.994209">
236
</page>
<bodyText confidence="0.9986352">
corpora). Vector representations are produced
for : (a) the whole document, (b) the lead-part
of the document (the n% initial tokens of the
document, where n is given as a parameter),
and (c) each sentence.
</bodyText>
<listItem confidence="0.964715363636364">
• Term frequency: this module computes the
value E t f * idf for each sentence in the doc-
ument. The sum is taken over the sentence to-
kens and normalised by the maximum term fre-
quency over all sentences.
• Content-based analysis: this module computes
the similarity between two text units by com-
puting the cosine between their vector repre-
sentations (other similarity metrics will be in-
corporated in the future). We perform the fol-
lowing computations:
</listItem>
<bodyText confidence="0.97006735">
similarity between each sentence and the
whole document;
similarity between each sentence and the
lead-part of the document;
similarity between each sentence and its
previous sentence (similarity forward);
similarity between each sentence and its
following sentence (similarity backwards);
The similarities forward and backward are
combined in a single numeric value represent-
ing how &amp;quot;cohesive&amp;quot; the sentence is to the previ-
ous and following text. We identify sentences
that: (a) begin segments (they are dissimilar
with the previous sentence but similar to the
following sentence); (b) are in the middle of
a segment (are similar to both previous and
following sentences); (c) close segments (they
are similar to the previous sentence but not to
the following sentence); or (d) have no relation
with previous or following sentences.
</bodyText>
<listItem confidence="0.748305933333333">
• Named entity statistics module: based on the
output of the coreference module we compute
coreference classes grouping together all men-
tions of the same named entity (e.g., &amp;quot;Bill Clin-
ton&amp;quot; and &amp;quot;Mr. Clinton&amp;quot; belong to the same
class). For each coreference class we iden-
tify its size and frequency (ne_f req), the sen-
tence containing the first mention of an ele-
ment in the coreference class, and the inverted
NE frequency (or i _ne_f req) (e.g., the ratio of
the number of sentences / the number of sen-
tences containing an element of the corefer-
ence class).
• Named entity scorer. This module performs the
following computations:
</listItem>
<bodyText confidence="0.884567108108108">
first mention of a named entity: sentences
containing the first mention of a class with
more than one instance receive a bonus;
named entity density: is the ratio of the
number of coreference classes in the sentences
to the number of coreference classes in the text;
in a way similar to the content based anal-
ysis of sentences, we measure the cohesiveness
of sentences; based on the links named entities
have in the text (e.g., forward and backward
links);
in a way similar to the term distribu-
tion scorer, we compute a composite value
representing the distribution of the corefer-
ence classes in the sentence (E ne_f req *
i_ne_f req), this value is normalised by the
maximum value obtained for all sentences.
• Sentence position: for each sentence two val-
ues are computed. Absolute position: sentence
i receives the value i —1. Relative position: if
the sentence is at the beginning of a paragraph,
this value is set to initial, if the sentence is at
the end of the paragraph (for paragraphs with
more than one sentence), this value is set to fi-
nal, if the sentence is in the middle of the para-
graph (for paragraphs with more than two sen-
tences), this value is set to middle. These three
values are parameters of the sentence position
scorer.
• Query-based scorer: a query (e.g., string) can
be specified as parameter to the summarisation
process in order to boost the value of sentences
which &apos;content&apos; is close to the query &apos;content&apos;.
The query is analysed and a vector represen-
tation is produced for it. A similarity value
is computed between each sentence and the
query.
</bodyText>
<page confidence="0.990851">
237
</page>
<bodyText confidence="0.99232">
The final score for a sentence is computed using
the following formula:
EriLi value( f eaturei) * weighti
where the weights are obtained experimentally
and constitute parameters of the summarisation pro-
cess (the summariser comes with pre established
weights that can be modified by the user). The
scores are used to produce a ranked list of sentences.
Sentences on the ranked list are included in the sum-
mary until the compression rate is reached. A mod-
ule is also available that allows the user to spec-
ify &amp;quot;text units&amp;quot;, section headings for example, that
should be excluded from the ranked list. The anno-
tations can be used to produce a stand-alone version
of the summary.
</bodyText>
<sectionHeader confidence="0.999677" genericHeader="conclusions">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999981948717949">
Evaluation is an essential step of any natural lan-
guage processing task. However, many research
projects make use of in-house evaluation, making
it difficult to replicate experiments, to compare re-
sults, or to use evaluation data for training purposes.
When text summarisation systems are evaluated by
comparing extracted sentences to a set of &amp;quot;correct&amp;quot;
extracted sentences, then co-selection is measured
by precision, recall and F-score. Gate&apos;s Annota-
tionDiff tool enables two sets of annotations on a
document to be quantitative compared (i,e. two
summaries produced by two summarisation con-
figurations). We are making use of human anno-
tated corpus (source documents and sets of extracts)
(Saggion et al., 2002b) in order to evaluate dif-
ferent system configurations and to identify exper-
imentally the best feature combination. Process-
ing resources for content-based evaluation have al-
ready been integrated in the system (Pastra and Sag-
gion, 2003). Future work will include the use of
document-summary (non extractive) pairs (from the
Document Understanding Conferences Corpus as
well as from the HKNews Corpus (Saggion et al.,
2002a)) and machine learning algorithms to obtain
the best combination of the summarisation features,
where &apos;extracts&apos; will be learn based on the automatic
alignment between the non-extractive summaries
and their source documents. The summarisation
system presented here provides a framework for ex-
perimentation in text summarisation research. The
summariser combines two orthogonal approaches in
a simple way taking advantage of robust techniques
for semantic tagging, coreference resolution, and
statistical analysis. Our work in progress is also
looking at the automatic acquisition of &apos;cue phases&apos;
from corpora in order to implement the indicator
phrases method. Future versions of this system will
contain multi-document and multi-lingual summari-
sation components.
</bodyText>
<sectionHeader confidence="0.999191" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999863636363636">
Cunningham, H., Maynard, D., Bontcheva, K., and
Tablan, V. (2002). GATE: A framework and graph-
ical development environment for robust NLP tools
and applications. In ACL 2002.
Mani, I. (2000). Automatic Text Summarization. John
Benjamins Publishing Company.
Paice, C. D. and Jones, P. A. (1993). The Identification
of Important Concepts in Highly Structured Technical
Papers. In Korfhage, R., Rasmussen, E., and Willett,
P., editors, Proc. of the 16th ACM-SIGIR Conference,
pages 69-78.
Pastra, K. and Saggion, H. (2003). Colouring sum-
maries Bleu. In Proceedings of Evaluation Initiatives
in Natural Language Processing, Budapest, Hungary.
EACL.
Saggion, H. (2002). Shallow-based Robust Summariza-
tion. in Automatic Summarization: Solutions and Per-
spectives, ATALA.
Saggion, H. and Lapalme, G. (2002). Generat-
ing Indicative-Informative Summaries with SumUM.
Computational Linguistics.
Saggion, H., Radev, D., Teufel, S., and Lam, W. (2002a).
Meta-evaluation of Summaries in a Cross-lingual En-
vironment using Content-based Metrics. In Proceed-
ings of COLING 2002, pages 849-855, Taipei, taiwan.
Saggion, H., Radev, D., Teufel, S., Wai, L., and Strassel,
S. (2002b). Developing Infrastructure for the Eval-
uation of Single and Multi-document Summarization
Systems in a Cross-lingual Environment. In LREC
2002, pages 747-754, Las Palmas, Gran Canaria,
Spain.
Salton, G. (1988). Automatic Text Processing. Addison-
Wesley Publishing Company.
</reference>
<page confidence="0.997058">
238
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.361025">
<title confidence="0.750262">Robust Generic and Query-based Summarisation Horacio Saggion</title>
<author confidence="0.9990455">Kalina Bontcheva Hamish Cunningham</author>
<affiliation confidence="0.9999695">Department of Computer Science University of Sheffield</affiliation>
<address confidence="0.8721575">211 Portobello Street - Sheffield - Si 4DP England - United Kingdom</address>
<email confidence="0.944182">Isaggion,kalina,hamishl@dcs.shef.ac.uk</email>
<abstract confidence="0.999615333333333">We present a robust summarisation system developed within the GATE architecture that makes use of robust components for semantic tagging and coreference resolution provided by GATE. Our system combines GATE components with well established statistical techniques developed for the purpose of text summarisation research. The system supports &amp;quot;generic&amp;quot; and query-based summarisation addressing the need for user adaptation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>D Maynard</author>
<author>K Bontcheva</author>
<author>V Tablan</author>
</authors>
<title>GATE: A framework and graphical development environment for robust NLP tools and applications. In</title>
<date>2002</date>
<booktitle>ACL</booktitle>
<contexts>
<context position="1746" citStr="Cunningham et al., 2002" startWordPosition="246" endWordPosition="249">nd that use the key information to produce a new text, lead to high-quality summarisation (Paice and Jones, 1993; Saggion and Lapalme, 2002) but suffer from the knowledge-bottleneck problem: adapting information extraction rules, templates, and generation grammars to new tasks or domains is time consuming. An alternative to these approaches is to use combination of robust techniques for semantic tagging together with statistical methods (Saggion, 2002). Here, we present a summarisation system that makes use of robust components for semantic tagging and coreference resolution provided by GATE (Cunningham et al., 2002). Our system combines GATE components with well established statistical techniques developed for the purpose of text summarisation. The result is the sentence extraction system shown in Figure 1, the relevant sentences of the document are highlighted in the GATE user interface. The figure also shows semantic information identified within the document (e.g., named entities). All summarisation components developed as part of this research are made available as a Java Library for research purposes 1. 2 The Summariser Our system is a pipeline of linguistic and statistical components. Some of them </context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>Cunningham, H., Maynard, D., Bontcheva, K., and Tablan, V. (2002). GATE: A framework and graphical development environment for robust NLP tools and applications. In ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
</authors>
<title>Automatic Text Summarization.</title>
<date>2000</date>
<publisher>John Benjamins Publishing Company.</publisher>
<contexts>
<context position="888" citStr="Mani, 2000" startWordPosition="123" endWordPosition="124">nt a robust summarisation system developed within the GATE architecture that makes use of robust components for semantic tagging and coreference resolution provided by GATE. Our system combines GATE components with well established statistical techniques developed for the purpose of text summarisation research. The system supports &amp;quot;generic&amp;quot; and query-based summarisation addressing the need for user adaptation. 1 Introduction Two approaches are generally considered in automatic text summarisation research: the shallow sentence extraction approach and the deep, understand and generate approach (Mani, 2000). Sentence extraction methods are quite robust, but sentence extracts suffer from lack of cohesion and coherence. Methods that identify the essential information of the document by either information extraction or text understanding and that use the key information to produce a new text, lead to high-quality summarisation (Paice and Jones, 1993; Saggion and Lapalme, 2002) but suffer from the knowledge-bottleneck problem: adapting information extraction rules, templates, and generation grammars to new tasks or domains is time consuming. An alternative to these approaches is to use combination o</context>
</contexts>
<marker>Mani, 2000</marker>
<rawString>Mani, I. (2000). Automatic Text Summarization. John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
<author>P A Jones</author>
</authors>
<title>The Identification of Important Concepts in Highly Structured Technical Papers.</title>
<date>1993</date>
<booktitle>Proc. of the 16th ACM-SIGIR Conference,</booktitle>
<pages>69--78</pages>
<editor>In Korfhage, R., Rasmussen, E., and Willett, P., editors,</editor>
<contexts>
<context position="1234" citStr="Paice and Jones, 1993" startWordPosition="172" endWordPosition="175">neric&amp;quot; and query-based summarisation addressing the need for user adaptation. 1 Introduction Two approaches are generally considered in automatic text summarisation research: the shallow sentence extraction approach and the deep, understand and generate approach (Mani, 2000). Sentence extraction methods are quite robust, but sentence extracts suffer from lack of cohesion and coherence. Methods that identify the essential information of the document by either information extraction or text understanding and that use the key information to produce a new text, lead to high-quality summarisation (Paice and Jones, 1993; Saggion and Lapalme, 2002) but suffer from the knowledge-bottleneck problem: adapting information extraction rules, templates, and generation grammars to new tasks or domains is time consuming. An alternative to these approaches is to use combination of robust techniques for semantic tagging together with statistical methods (Saggion, 2002). Here, we present a summarisation system that makes use of robust components for semantic tagging and coreference resolution provided by GATE (Cunningham et al., 2002). Our system combines GATE components with well established statistical techniques devel</context>
</contexts>
<marker>Paice, Jones, 1993</marker>
<rawString>Paice, C. D. and Jones, P. A. (1993). The Identification of Important Concepts in Highly Structured Technical Papers. In Korfhage, R., Rasmussen, E., and Willett, P., editors, Proc. of the 16th ACM-SIGIR Conference, pages 69-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Pastra</author>
<author>H Saggion</author>
</authors>
<title>Colouring summaries Bleu.</title>
<date>2003</date>
<booktitle>In Proceedings of Evaluation Initiatives in Natural Language Processing,</booktitle>
<location>Budapest, Hungary. EACL.</location>
<contexts>
<context position="11702" citStr="Pastra and Saggion, 2003" startWordPosition="1849" endWordPosition="1853">entences to a set of &amp;quot;correct&amp;quot; extracted sentences, then co-selection is measured by precision, recall and F-score. Gate&apos;s AnnotationDiff tool enables two sets of annotations on a document to be quantitative compared (i,e. two summaries produced by two summarisation configurations). We are making use of human annotated corpus (source documents and sets of extracts) (Saggion et al., 2002b) in order to evaluate different system configurations and to identify experimentally the best feature combination. Processing resources for content-based evaluation have already been integrated in the system (Pastra and Saggion, 2003). Future work will include the use of document-summary (non extractive) pairs (from the Document Understanding Conferences Corpus as well as from the HKNews Corpus (Saggion et al., 2002a)) and machine learning algorithms to obtain the best combination of the summarisation features, where &apos;extracts&apos; will be learn based on the automatic alignment between the non-extractive summaries and their source documents. The summarisation system presented here provides a framework for experimentation in text summarisation research. The summariser combines two orthogonal approaches in a simple way taking ad</context>
</contexts>
<marker>Pastra, Saggion, 2003</marker>
<rawString>Pastra, K. and Saggion, H. (2003). Colouring summaries Bleu. In Proceedings of Evaluation Initiatives in Natural Language Processing, Budapest, Hungary. EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Saggion</author>
</authors>
<title>Shallow-based Robust Summarization. in Automatic Summarization: Solutions and Perspectives,</title>
<date>2002</date>
<location>ATALA.</location>
<contexts>
<context position="1578" citStr="Saggion, 2002" startWordPosition="222" endWordPosition="223"> from lack of cohesion and coherence. Methods that identify the essential information of the document by either information extraction or text understanding and that use the key information to produce a new text, lead to high-quality summarisation (Paice and Jones, 1993; Saggion and Lapalme, 2002) but suffer from the knowledge-bottleneck problem: adapting information extraction rules, templates, and generation grammars to new tasks or domains is time consuming. An alternative to these approaches is to use combination of robust techniques for semantic tagging together with statistical methods (Saggion, 2002). Here, we present a summarisation system that makes use of robust components for semantic tagging and coreference resolution provided by GATE (Cunningham et al., 2002). Our system combines GATE components with well established statistical techniques developed for the purpose of text summarisation. The result is the sentence extraction system shown in Figure 1, the relevant sentences of the document are highlighted in the GATE user interface. The figure also shows semantic information identified within the document (e.g., named entities). All summarisation components developed as part of this </context>
</contexts>
<marker>Saggion, 2002</marker>
<rawString>Saggion, H. (2002). Shallow-based Robust Summarization. in Automatic Summarization: Solutions and Perspectives, ATALA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Saggion</author>
<author>G Lapalme</author>
</authors>
<title>Generating Indicative-Informative Summaries with SumUM. Computational Linguistics.</title>
<date>2002</date>
<contexts>
<context position="1262" citStr="Saggion and Lapalme, 2002" startWordPosition="176" endWordPosition="179">summarisation addressing the need for user adaptation. 1 Introduction Two approaches are generally considered in automatic text summarisation research: the shallow sentence extraction approach and the deep, understand and generate approach (Mani, 2000). Sentence extraction methods are quite robust, but sentence extracts suffer from lack of cohesion and coherence. Methods that identify the essential information of the document by either information extraction or text understanding and that use the key information to produce a new text, lead to high-quality summarisation (Paice and Jones, 1993; Saggion and Lapalme, 2002) but suffer from the knowledge-bottleneck problem: adapting information extraction rules, templates, and generation grammars to new tasks or domains is time consuming. An alternative to these approaches is to use combination of robust techniques for semantic tagging together with statistical methods (Saggion, 2002). Here, we present a summarisation system that makes use of robust components for semantic tagging and coreference resolution provided by GATE (Cunningham et al., 2002). Our system combines GATE components with well established statistical techniques developed for the purpose of text</context>
</contexts>
<marker>Saggion, Lapalme, 2002</marker>
<rawString>Saggion, H. and Lapalme, G. (2002). Generating Indicative-Informative Summaries with SumUM. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Saggion</author>
<author>D Radev</author>
<author>S Teufel</author>
<author>W Lam</author>
</authors>
<title>Meta-evaluation of Summaries in a Cross-lingual Environment using Content-based Metrics.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING 2002,</booktitle>
<pages>849--855</pages>
<location>Taipei,</location>
<contexts>
<context position="11466" citStr="Saggion et al., 2002" startWordPosition="1814" endWordPosition="1817">rch projects make use of in-house evaluation, making it difficult to replicate experiments, to compare results, or to use evaluation data for training purposes. When text summarisation systems are evaluated by comparing extracted sentences to a set of &amp;quot;correct&amp;quot; extracted sentences, then co-selection is measured by precision, recall and F-score. Gate&apos;s AnnotationDiff tool enables two sets of annotations on a document to be quantitative compared (i,e. two summaries produced by two summarisation configurations). We are making use of human annotated corpus (source documents and sets of extracts) (Saggion et al., 2002b) in order to evaluate different system configurations and to identify experimentally the best feature combination. Processing resources for content-based evaluation have already been integrated in the system (Pastra and Saggion, 2003). Future work will include the use of document-summary (non extractive) pairs (from the Document Understanding Conferences Corpus as well as from the HKNews Corpus (Saggion et al., 2002a)) and machine learning algorithms to obtain the best combination of the summarisation features, where &apos;extracts&apos; will be learn based on the automatic alignment between the non-e</context>
</contexts>
<marker>Saggion, Radev, Teufel, Lam, 2002</marker>
<rawString>Saggion, H., Radev, D., Teufel, S., and Lam, W. (2002a). Meta-evaluation of Summaries in a Cross-lingual Environment using Content-based Metrics. In Proceedings of COLING 2002, pages 849-855, Taipei, taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Saggion</author>
<author>D Radev</author>
<author>S Teufel</author>
<author>L Wai</author>
<author>S Strassel</author>
</authors>
<title>Developing Infrastructure for the Evaluation of Single and Multi-document Summarization Systems in a Cross-lingual Environment.</title>
<date>2002</date>
<booktitle>In LREC 2002,</booktitle>
<pages>747--754</pages>
<location>Las Palmas, Gran Canaria,</location>
<contexts>
<context position="11466" citStr="Saggion et al., 2002" startWordPosition="1814" endWordPosition="1817">rch projects make use of in-house evaluation, making it difficult to replicate experiments, to compare results, or to use evaluation data for training purposes. When text summarisation systems are evaluated by comparing extracted sentences to a set of &amp;quot;correct&amp;quot; extracted sentences, then co-selection is measured by precision, recall and F-score. Gate&apos;s AnnotationDiff tool enables two sets of annotations on a document to be quantitative compared (i,e. two summaries produced by two summarisation configurations). We are making use of human annotated corpus (source documents and sets of extracts) (Saggion et al., 2002b) in order to evaluate different system configurations and to identify experimentally the best feature combination. Processing resources for content-based evaluation have already been integrated in the system (Pastra and Saggion, 2003). Future work will include the use of document-summary (non extractive) pairs (from the Document Understanding Conferences Corpus as well as from the HKNews Corpus (Saggion et al., 2002a)) and machine learning algorithms to obtain the best combination of the summarisation features, where &apos;extracts&apos; will be learn based on the automatic alignment between the non-e</context>
</contexts>
<marker>Saggion, Radev, Teufel, Wai, Strassel, 2002</marker>
<rawString>Saggion, H., Radev, D., Teufel, S., Wai, L., and Strassel, S. (2002b). Developing Infrastructure for the Evaluation of Single and Multi-document Summarization Systems in a Cross-lingual Environment. In LREC 2002, pages 747-754, Las Palmas, Gran Canaria, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
</authors>
<title>Automatic Text Processing.</title>
<date>1988</date>
<publisher>AddisonWesley Publishing Company.</publisher>
<contexts>
<context position="5933" citStr="Salton, 1988" startWordPosition="899" endWordPosition="900">n), is a rule-based lemmatiser that produces an affix and root for each noun and verb in the input text. • Coreference resolution, it is a light-weight, corpus-based approach for the resolution of named entities anaphora in text. 2.2 Summarisation Components and Scoring These modules have been developed for the purpose of summarisation research and are made available as a library of Java classes and configuration file (i.e. creole in GATE terminology): • Corpus statistics: token statistics including token frequency and lemma (or root) frequency are computed in this step. • Vector space model (Salton, 1988): is used to create a vector representation of different text units. Each vector contains the tokens of the text unit and the value token frequency * inverted document frequency. Inverted document frequencies (i.e., distribution of tokens in a big collection) for English is computed using the British National Corpus (this information is a parameter of the summariser making possible to experiment with frequencies from different 236 corpora). Vector representations are produced for : (a) the whole document, (b) the lead-part of the document (the n% initial tokens of the document, where n is give</context>
</contexts>
<marker>Salton, 1988</marker>
<rawString>Salton, G. (1988). Automatic Text Processing. AddisonWesley Publishing Company.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>