<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.866357">
American Journal of Computational Linguistics Microfiche 42
</title>
<note confidence="0.795242">
THE FINITE STRING
</note>
<sectionHeader confidence="0.4310195" genericHeader="method">
NEWSLETTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
VOLUME 13 - NUMBER 2 FEBRUARY 1976
</sectionHeader>
<bodyText confidence="0.455655666666667">
Abstracts from the 1975 LSA Meeting . 2
Current Bibliography 9
Proceedings, 2nd US-Japan Computer Conference 82
</bodyText>
<note confidence="0.634232571428571">
AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS is published
by the Center for Applied Linguistics for the Association
for Computational Linguistics.
EDITOR: David G. Hays, Professor of Linguistics and of Computer
Science, State University of New York, Buffalo.
EDITORIAL ASSISTANT: William Benzon
EDITORIAL ADDRESS: Twin Willows, Wanakah, New York 14075.
MANAGING EDITOR: A. Hood Roberts, Deputy Director, Center for
Applied Linguistics
ASSISTANT: David Hoffman
PRODUCTION AND SUBSCRIPTION ADDRESS: 1611 North Kent Street,
Arlington, Virginia 22209.
CoPyright 1976 by the Association for Computational Linguistics
American Journal of Computational Linguistics Micronche 42 : 2
</note>
<sectionHeader confidence="0.84635075" genericHeader="method">
ABSTRACTS OF PAPERS
ON COMPUTATIONAL LINGUISTICS
LINGUISTIC SOCIETY
OF AMERICA
</sectionHeader>
<address confidence="0.325104">
1-9 7 5 ANNUAL MEETING
</address>
<bodyText confidence="0.8122645">
A session was organized by Aravind K Joshi on behalf of
ACL. The abstracts are reprinted on the following pages
from the Meeting Handbook, with the permission of the
Society
</bodyText>
<note confidence="0.850970333333333">
LSA MEETING 197$ 3
A MODEL FOR FUNDAMENTAL FREQUENCY
BASED ON CbMMUNICATIVE FUNCTION
</note>
<author confidence="0.87013">
Jonathan Allen
</author>
<affiliation confidence="0.857966">
Massachusetts Institute of Technology
</affiliation>
<bodyText confidence="0.997394842105263">
By examining the communicative speech aeL performed with an
utterance, a comprehensive model for the generation ol funda-
mental frequency contours can be derived. Each utterance is
considered to have propositional, interpersonal, and discourse
function, and the model shows how each of these determine a
relation between the underlying syntax and semantics, and the
surface fundamental frequency. The underlying performative
and proposition control the basic contour shape, which is then
perturbed by markers of the speaker&apos;s attitude toward the pro-
position and the choice of focus-shifting transformations.
The interpersonal function is supplied by modal operators
which indicate the speaker&apos;s attachment to the truth-value of
the proposition, and we show how modals and their scope are
realized in the fundamental frequency contour The use of
focus-shifting transformations to achieve discourse effects
is also strongly marked by pitch movements, and these are
characterized for a wide range of transformations. All of
these effects are shown to be essential for a comprehensive
model of pitch contours.
</bodyText>
<note confidence="0.945957">
LSA MEETING 1975 4
NEGATIONI GRAMMATICAL, SEMANTICAL, AND PRAGMATICAL
</note>
<sectionHeader confidence="0.439041" genericHeader="method">
Felix Dreizin
</sectionHeader>
<subsectionHeader confidence="0.758923">
Bar-flan University
</subsectionHeader>
<bodyText confidence="0.981066181818182">
It is generally agreed upon that presuppositions are not af-
fected by negation. This is not so for a vast class of speaker
presuppositions--those about the information at the disposition
of the hearer. Example: with respect to the sentence &apos;It was
not John who killed Mary&apos; a presupposition of the above kind
(&apos;John killed Mary ) is normally affected by Uttering this
sentence. I propose to distinguish between three kinds of
negation: (a) grammatical (GN) &amp;quot;not&amp;quot;; (b) semantical (SN)
if &amp;quot;missed&amp;quot; is described with respect to a basic semantic
unity &amp;quot;hit&amp;quot;, then &amp;quot;missed&amp;quot; = NEG (hit), (c) pragmatical (PN):
&amp;quot;no&amp;quot;: rejecting a piece of information which the hearer is
</bodyText>
<note confidence="0.765388176470588">
assumed to be aware of. This yields eight sentence types (&apos;A&apos;
stands for &amp;quot;Assertien&amp;quot;).
(1) SN GN PN It wasn&apos;t John who killed Mary.
(2) SN GN PA ? Seems not to exist.
SN GA PN He missed the target. (Contrastive stress)
SN GA PA He missed the target.
SA GN PN He didn&apos;t miss the target.
SA aT PA ? Seems not to exist.
SA GA PN It was John (rather than Mary) who killed Bill.
SA GA PA He hit the target.
The subtle differences between semantically equivalent sen-
tences (5) and (8) can be ascribed to the opposition PN vs. PA.
The above framework is a useful tool to account for negation
in discourse.
LSA MEETING 1975 5
NATURAL LANGUAGE ANALYSIS
IN A FUNCTION ORIENTED SYSTEM
</note>
<author confidence="0.796501">
G. C. Goldbogen E. C. Chylinski
</author>
<affiliation confidence="0.799063">
Union College General Electric Corporate Research and Development
</affiliation>
<bodyText confidence="0.991008388888889">
For English comprehension and deduction in an interactive sys-
tem an ATN produces a binary syntactic tree; semantic analysis
tollapses the tree and yields a LISP program representation,
used in one module as a function on the system data base and in
the other as a WFF to be verified from the data base. FORNAP
(function Oriented natural language processor) grew out of SIGS,
written at SUNY Albany for graph theory. A domain of discourse
consists of elements and functions; in graph theory, elements
are points, lines, graphs, integers, and boolean T, F; one
function is COMPONENTS, mapping graphs into integers. The ATN
model restricts English; restricting each word to a single
part of speech results in no ambiguity for legal sentences.
The semantic collapse is bottom up, it works with rightmost
parent node with two terminal sons, using syntax, dictionary,
and argument table. Some triples cause arguments to be checked
semantically and staeked for later reference; other types cause
pieces of the WFF to be assembled, possibly using stacked data.
Applications using WFFs in the theorem proving module,
</bodyText>
<note confidence="0.585153">
LSA MEETING 1975 6
</note>
<sectionHeader confidence="0.946558" genericHeader="method">
CLAIM STRUCTURE ,GRAMMAR
</sectionHeader>
<subsectionHeader confidence="0.9589575">
Linda Misek
vassar Cold eo
</subsectionHeader>
<bodyText confidence="0.984116409090909">
Kaplan is optimistic that Woods-type &amp;quot;augmented transition net-
work&amp;quot; grammars can capture the psysghological reality of human
language processing by modeling linguistic performance and com-
petenCe. Cognitive mappings from surface strings are also of
interest to Schank, whose &amp;quot;conceptual dependencies&amp;quot; infer deep-
case relations from parsable featurts. Both approaches promise
to lead us from language to patterns of thought. This paper
presents recent developments in Claim Structure Grammar a
stratified system representing real world text as sets of con-
ceptual &amp;quot;claims&amp;quot; or assertions which bind entities, relations,
and their properties. CSG postulates thematic deep structures
by conceptually interpreting events at nodes and on transition
arcs in surface networks. Discourse parsed for &amp;quot;claims&amp;quot; may
be a well-formed text, sentence, or clausc.--or simply a frag-
ment whose terms nonetheless entail ontological commitments.
The form of CSG is a transition net, its function is to diffe-
rentiate among the users of a language and among the separate
states through which an individual speaker or writer transitions
in process of gommunicating world knowledge. Originally deve-
loped in the context of rhetoric and stylistics, CSG gains in
power and significance when viewed from the computational per-
spectives of Woods, Schank, and others.
</bodyText>
<note confidence="0.825135">
L$A MEETING 1975 7
</note>
<sectionHeader confidence="0.7967635" genericHeader="method">
USE OF NATURAL LANGUAGE IN
COMPUTER PROOF CHECKING
</sectionHeader>
<author confidence="0.88656">
Robert Smith &amp; Lee Blaine
</author>
<affiliation confidence="0.681442">
Stanford University
</affiliation>
<bodyText confidence="0.999060176470588">
The EXCHECK system is a proof checker designed to check .and
discuss student proofs given in a style approaching that of
standard university mathematics. EXCHECK is currently being
used to teach axiomatic set theory at Stanford. Informal ma-
thematical proofs suppress an enormous amount of detail that
simply gets in the way of understanding the proof. The suppres-
sion of this detail involves the use of natural language, in-
corporating many of the known problems such as elliptic and
contextual references, operator scope and precedence, and the
use of semantic information. In order to check such proofs,
it is necessary to understand the relationship between rigorous
mathematical proofs and their informal presentation in a mathe-
matics curriculum. Film and slides show the current version of
the EXCHECK proof checker, with emphasis on the NL aspects.
Furthermore, we discuss our efforts to represent the structure
of a student&apos;s developing- proof EXCHECK runs on the IMSSS
PDP10/TENEX timesharing system at Stanford
</bodyText>
<note confidence="0.521561666666667">
LSA MEETING 1975 8
A SYSTEM FOR COMPUTING
PRESUPPOSITIONS AND ENTAILMENTS
</note>
<author confidence="0.592449">
Ralph Weischedel
</author>
<affiliation confidence="0.544487">
Universaty of California, ilvine
</affiliation>
<bodyText confidence="0.9739575">
Presupposition and entailment are a subclass of inferences
tied to the structure of a language. Presuppositions. may
arise from syntactic structure and from the meaning of indi-
vidual words; entailments arise from the meaning of particular
words. Since they are tied to the structure of language, they
may be computed by tree transformations, independent of context
not inherent in the structure of a sentence. This is a parti-
cularly simple computation, in sharp contrast to other computa-
tional mechanisms suggested for the general class of inferences.
Other aspects of the uniqueness of presuppositions and entail-
ment as a class of inferences will be considered. A program
which accepts as input individual sentences and gives as output
the presuppositions and entailments of each sentence will be
described.
</bodyText>
<subsectionHeader confidence="0.607388">
American Journal of Computational Linguistics Microfiche 42 :
</subsectionHeader>
<sectionHeader confidence="0.704003" genericHeader="method">
CURRENT BIBLIOGRAPHY
</sectionHeader>
<bodyText confidence="0.987387473684211">
The tentative rules for selection of material and the tentattve
subject categories used to classify it are about to &apos;disappear.
The number of members responding to this year&apos;s directory call
is more than 100; the number of categories checked per member
is so large as to signify a misfit between the categories and
the members&apos; self descriptions. A cluster analysis is being
made in an informal way; the clusters will be adopted as new
subject headings, replacing or extending the present system.
The new categories will appear in the index to be delivered in
about a month and in the next issue of The Finite String.
The number of members interested in certain bopics (see
Microfiche 37) is so small ag to raise questions about the
effort expended to provide, bibliographic coverage. After con-
sultation with the Editorial Board, the Editor expects to
terminate coverage-of some areas--unless our handling of those
areas is superior to other abstract journals, and our quality
can be used to attract More members quickly,
See the following frame for - list of subject headings with
frame numbers.
</bodyText>
<sectionHeader confidence="0.931201714285714" genericHeader="method">
SUBJECT HEADINGS
GENERAL
PHONETICS-PHONOLOGY
Recognition
Segmentation
Synthesis
WRITING
</sectionHeader>
<subsectionHeader confidence="0.593444333333333">
Recognition
Chinese
Synthesis
</subsectionHeader>
<sectionHeader confidence="0.948315470588235" genericHeader="method">
Character sets
LEXICOGRAPHY-LEXICOLOC
Statistics
Clustering
Dictionary
Paradigms
GRAMMAR
Morphology
Parser
Generator
SEMANTICS-DISCOURSE
Comprehension
Memory
Text grammar
Expression
LINGUISTICS-
Methods
</sectionHeader>
<subsectionHeader confidence="0.682765666666667">
Mathematical
Statistical
Historical
</subsectionHeader>
<figure confidence="0.909522243243243">
I 0
COMPUTATION
11 Inference 56
Information structures 57
Pictorial systems 5g
21 DOCUMENTATION 61
Retrieval 6
TRANSLATION 66
SOCIAL-BEHAVIORAL SCIENCE
uk•
28 Psycholog)
29 Psycholinguistics
30 HUMANITIES
31 Concordance 75
32 Analysis 76
34 INSTRUCTION 77
34 ROBOTICS 30
36
36
37
38
39
40
46
49
50
51
52
55
55
GENERAL 11
Learning, Automatic Language Analysis: Their Application to Information
Retrieval
Appremissage, analyse autamatique du langage, application a la documentation
A. Andre0“ky, C. rluhr, and Debralne
Cemre d&apos;Etudes Nuctcaires, Saclay, France
l&apos;ocument de Owls:Nue Quantitative, No. 20; Parts: Dunod, 1W3, $20.00
</figure>
<tableCaption confidence="0.3623236">
A collection of papers reporting aspects or work by the Groupe de linguistique automatique
at CEN-Sacla): Strategy for a learning program for computatiomil linguistics: Algorithms for
synthesiting French sentences; A ”stem or discriminathe analysis, machine indexing,
hierarthical divtiment search, and decilion aids. 1he last combines a Bayesian model with the
output from automatic parsing &apos;and semantic analysis.
</tableCaption>
<sectionHeader confidence="0.780478" genericHeader="method">
GENERAL
</sectionHeader>
<subsectionHeader confidence="0.81211175">
Outline of Natural Language Systems
S. Yoshida
Department of Computer Science, Kyushu Institute of Technology. Tobaras KittrAmsbu,..lapan
gernoirl of the Kyushu institute of Technology, No. 5:59-71, March /975
</subsectionHeader>
<bodyText confidence="0.9574922">
Develops systems (NL stem) for describing human thinking processes by means of natural
language. Basic hypotheses giving base for describiag thinking processes in natural language
are stated. Outlines of whole system constructions and their behaviors on these bases are
presented. The feature or the NL srsterns is that they are constructed from the standpoint of
engineering and, therefore, many useful sub-systems may be constructed from these systems.
</bodyText>
<sectionHeader confidence="0.768569" genericHeader="method">
GENERAL
</sectionHeader>
<subsectionHeader confidence="0.646179666666667">
Five Lectures on Artificial Intelligence
Terry Winograd
Stanford University
</subsectionHeader>
<note confidence="0.7431125">
NT1S: AD/44-000 085/1, September i974
PC 14,75/111.4 12,25
</note>
<tableCaption confidence="0.67629">
contents : Computer systems for natural language; SttROL(J, a system tot duez
Representation, tormalisms for knowledge; Frauc tillt ideas for a new 1rutiscn:
Conceptual programming, applying artificial intelligence to program writing.
</tableCaption>
<sectionHeader confidence="0.943074" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.9037685">
Automatic Segmentation of Speech into Syllabic Units
l&apos;aut Mernitisitin
</subsectionHeader>
<bodyText confidence="0.603543">
Haskins tabolatones, New Haven, Connecticut
</bodyText>
<subsectionHeader confidence="0.76925">
Journal of th.t. Acoustic Society of 4merico 5$.180-383, 1Q75
</subsectionHeader>
<bodyText confidence="0.997296714285714">
The segmentation algorithm judges whether a loudness minimum is a s)llabic boundar.), using
the .difference between the convex hull of the loudness function and the loudness function
Itself. Tested on roughly 400 s)llables of continuous text. the algorithm results in 6.9%
syllables missed and 2.6% extra syllables relative to a nominal, slow-speech syllabic count.
The algorithm doesn&apos;t. proceed from left to right in time, but where real-time operation is
essential it could be modified to operate left to right with hacktracking O■fet an interval no
greater than 500 msec.
</bodyText>
<table confidence="0.176789333333333">
PHONETICS-PHONOLOGY: RECOGNITION 13
Real Time Analysis of Voiced Sounds
J. P. !long
National Aeronautics and Space Admitristration, Pasadena, California
Patent Appfiration NAS.4-C4SE-NPO 13465-1 NTIS: PAT-APPL-53I 575
PC $3.25/A1P $2.25
</table>
<bodyText confidence="0.999504714285714">
A power spectrum analysis or the harmonic content of a voiced sound signal is conducted in
real time by phase-lock-loop tracking of the fundamental frequency of the signal and
suicessive harmonics 14 through lin of the fundamenatal frequency. The quadratuic power and
phase or each 1&apos;N:twenty tracked is measured, differvntiating the power measurements of the
harmonio in adjacent pairs and inuilyring SUCcessiT e differentials. 1he differentials are used
to determine peak power points in the pbwer spectrum for display or use in analysis of
voiced sotind, such as for voice recognition.
</bodyText>
<sectionHeader confidence="0.788218" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.270856">
Auditory Speech Features: The Sound of English as Processed by a Model of
the Ear
</subsectionHeader>
<author confidence="0.699858">
John L Godfrey
</author>
<affiliation confidence="0.906855">
Ohio Research Institute, University of Dayton
</affiliation>
<table confidence="0.2691765">
Report September 1974 NTIS: 4D/A-002 604/7GA
PC $3.15/ $2.25
</table>
<bodyText confidence="0.999814285714286">
The model identifies bowels by features closely resembling. spectral feirmants. Fine temporal
dethil is prmrved, which is useful for s,ounds characterized by rapid changes in the signal.
Duration. pitth and diphthongalintion are registered. The model %Turks well for the
consonants studied, preserving fine tempqral detail. Some consonant features required special
purpose circuitry. Also iiscussed are strategies. based on the phonetic composition .of some
sounds. for writing integrated phonemic recognition algorithms: results of some preliminary
tests are presented.
</bodyText>
<sectionHeader confidence="0.355176" genericHeader="method">
PHONET1CS-PHONOLOGY: RECOGNITION 14
</sectionHeader>
<subsectionHeader confidence="0.800599">
Analysis of Intonational Signals by Computer Simulation of Pitch-Periceptioo
</subsectionHeader>
<figure confidence="0.5712094">
Tukefuta
Department of Speech Commurticattom, Oh4o State rnivervriy, Cotymb44x 4.110
Report TR-15, Fetortiory 1974; NrIS: 7761647
PC 33.25/MF $2.25
A computer. progszin is developed to can:Kt fund4mettali rqk1nçks. inteasit Itioat, aped
</figure>
<figureCaption confidence="0.347116">
durailon. characteristics.. A. second program: writ:Aires melody dieves and vegotatis the% lotto
constituent units of intonation patterm A thud program Zinalysts f104tM4U/Vti yebody owns
and identifies pitch otte.rns based upon tlit 14114.Mif04% alia4i4sis or pallet* kelvins,.
</figureCaption>
<sectionHeader confidence="0.884046" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.879632">
Automatic Verification of Hypothesized Phonemic Strings in Continuous
Speech
</subsectionHeader>
<sectionHeader confidence="0.443702" genericHeader="method">
R. A. Gillman
</sectionHeader>
<subsectionHeader confidence="0.824366">
System Dcyclopment Corp-oration, Siva Aitmitv, (*dile-F.1142 %WOO
</subsectionHeader>
<bodyText confidence="0.982138363636364">
Report SDC-TM-5315/000/00, 10 May I 9:- 5; STIS: 4D-i`i&amp;quot;9/ 06 / OGA
PC $3.00/ MP $2.25
A parser (wIth. 30 rewrite rules) predicts a. set of. possible words. including initial words from
a vocabulary of 160 words.. A. .lexicon contains plkonernic spellings and appmirnate duration
times for each phoneme of a word. A .phonemic-acoustic. mapping program is based on rive
rough scgine:nt labels: silence... low-amplitude.. yoked or unvoiced:: vowel-like: strong friliatiom
other. Two phonemic locators (vowels and SOilorants, and consona.nts) use the range
boundaries given by the lexicon to search the atoustic string. Phonemes are proceed
according to a goodness score which is a. function of the phone:me% distance- to the newest.
fixed boundary and of the class of the phoneme.. In a trial of 20 utter-a:nom the program was
able to identify the correct word in first place 89% of the time..
</bodyText>
<sectionHeader confidence="0.323973" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION 15
</sectionHeader>
<subsectionHeader confidence="0.4482115">
Acoustic Phonetic Research in Speech Understanding
Ricbard W. Raker, and Faust() Pon
</subsectionHeader>
<subsubsectionHeader confidence="0.4224485">
Stanford Rovarch &apos;Institute, Menlo Park, California
IEEE,Iilransactioiks Aetiutiiks, Speech,. (Fj RIttal Processing 23:416-426. 1975
</subsubsectionHeader>
<bodyText confidence="0.503278222222222">
The entire tytilem uses pragrnatic,--smantic, and. syntactic information to propose candidate
words at specific points in the acontiC &apos;dream whictt irm_accepted or rejected .11y the acoustic
processor. I-his verification is done in two stages, First, cach 10-ms segnitmt is classified as
one or ten primitixe cla hy diiiaI riltering. If ihe proposed word is consistent with the-
pattern of primitin classes,Athe corresponding point in the aco.ustic.stream,, further analysis
k$ done using linetir IffedIttivi) coding and other.diuit:il filters, Vie roulnof Ilti$ analysts
are used to segment the acekstie signal and. to NNW?&apos; classify.410`,fNoittealkkermentS.,1 Because
this segmentation and aissification can be tailored for tali .antalvsivbroblems
caused by coarticulation between adjacent sounds can be successfully solved
</bodyText>
<sectionHeader confidence="0.911252" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.964945">
Analysis and Recognition of Voiceless Fricative Consonants in Japanese
</subsectionHeader>
<bodyText confidence="0.83686">
!lima Fujisaki, and Osamu Kunisaki
</bodyText>
<subsubsectionHeader confidence="0.405312">
Department of Electrical&apos; Engineering, Faculty of Engineering, University of Tavo, Japan
</subsubsectionHeader>
<construct confidence="0.5275625">
Annual Bulletin, Research Institute of Logopedics and Phoniatrics, University of Tokyo,
9:123-126, ;975
</construct>
<bodyText confidence="0.9962876">
Based on an equivalent circuit representation of the production mechanism for the voiceless
fricative consonants /s/ and /sh/ (in Japanese), a model is derived for their frequency
spectra up to 5 ktii. Using 60 words of CV and CVC type containing these consonants,
spectra were obtained and measured and found to agree with the model, suggesting the use of
the model for automatic. recognition.
</bodyText>
<note confidence="0.473158">
PHONETICS-PHONOLOGY: RECOGNITION 16
Automatic Recognition of Semivowels in Spoken words
LI iroya Fujisaki
Research Institute of Logopedics ti if d Phoniatrics, University of Tokyo
</note>
<author confidence="0.790571">
Yasuo Salo, No%hiro Noguchi, and Takao Yatuakura
</author>
<affiliation confidence="0.757938">
Department of Electrical Engineering, University of Tokyo
</affiliation>
<construct confidence="0.6142915">
Annual Bulletin: Research Institute of Logopedics and Phoniatrirs, University of roAyo,
Q:119-122, 1975
</construct>
<bodyText confidence="0.977751375">
Al the.first stage of the recognition process the input spcct-h is sqmoittNi h Anal)sis-by-
Synthesis Of formant trajectories into intenals that possess a set or target formant fiequencies
corresponding to the Japanese s\owels /a/, hi, /0, id, and /o/, la!, /el, and /of can be
unlquell rtwogntred at this stage, As the formant frequencies of the %ods Iii and t&apos;u/ .are
respectiveN,Pentical to those of the selni\o‘sels .ii/ and imf, a Ncciond &apos;stage of analrsis is
nettted, ,W,11101 ut4i,es uifotination about duration and speech rate. A recognitton etrertment
has,h0iiiperformeti,on a total or 300 utterances of both meaningful and nonsense words and
a MO recognition rate was achievea.
</bodyText>
<sectionHeader confidence="0.872013" genericHeader="method">
PHONET1CS-P-4ONDLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.9978515">
Perception of Time-Varying Resonance Frequencies In Speech and Non-
Speech Stimuli
</subsectionHeader>
<bodyText confidence="0.534851">
Iiiroya Fujisaki, and Sotaro Selsinioto
</bodyText>
<subsectionHeader confidence="0.520698333333333">
Research Institute of Logopedics and Phoniatrics, University ofsrokyo
Annual .Bulletin: Research Institute of Iogopedi_es and Phoniatrics, University of Toltvo,
9:127-I36, 1975
</subsectionHeader>
<bodyText confidence="0.9996436">
Based on the analysis of formant transitions in natural speech, sr nthctic .speech stimuli %ere
generated with various values of magnitude. rate, and duration of formant transitions.
Discrimination tests of dynamic and static Stimuli indicated the existence of perceptual
extrapolation that tmderlies formant transitions. Results of discrimination tests on non-
speech stimuli with similar formant transitions suggested that the extrapolation was to a large
extent auditory, and thus was not specific to perception. of speech stimuli. On the other
hand, identification tests of dynamic and static speech stimuli clearly indicated the short-term
context effect in perception of connected segments, which Aas quantified as the arnount of
temporary shift in the threshold for phonemic judgment due to perception of the immediately
preceding segment.
</bodyText>
<sectionHeader confidence="0.440391" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION 17
</sectionHeader>
<subsectionHeader confidence="0.861418">
Syllable Recognition Using an Adaptive Pattern Recognition Technique
</subsectionHeader>
<bodyText confidence="0.498021">
M. All, and R. Ahmed
</bodyText>
<subsubsectionHeader confidence="0.433981">
Aligarh Muslim Umversi ) India
</subsubsectionHeader>
<bodyText confidence="0.834841">
Journal of the Institution of Electronics and Telecommunications Engineers 19: 676-683,
December 1973.
Sonograms of VC syllables spoken by,. a single mare speaker, and VC, CV, CVC syllubles
spoken hyorwtsPinale, speakeg were converted into I40-dimensional and 144-dimensipnal
quantind n3perns. W141 the comPhilents are optimally weighted before beigintimine4 th8
weighted stilt&apos; witserveA, the4asic of recognition. Al) index of correct recognition hasffhteen
defiled _aild a rtilfrOf:Ifimillr at the coned&apos; &apos;weirhts of the individual components ha &apos;hen
stated. AnvaqioniVifieeight deterniming deice is proposed to optImite the weiDlas durig
the learning phut of Atie machine.
</bodyText>
<sectionHeader confidence="0.935001" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.992323">
Simulation of a Recognition System for Connected Speech Sounds Using
Linguistic Information
</subsectionHeader>
<bodyText confidence="0.821058">
S. ink-cm and E. Kawatinhi,
</bodyText>
<subsubsectionHeader confidence="0.8636615">
Kyushu Umrersity, Fukuoka, Japan
electronics and Communications in Japan 56, No, 9:34-46, September 1973
</subsubsectionHeader>
<bodyText confidence="0.99895875">
Imperfect sound sequences which have been recognited on the basis of physical features are
transformed into a variety or possible character sequences. The latter are then transformed
into a variety Of possible character sequences. The latter are then transformed into word
sequences Which are then adjusted for sentence structure. This process eliminates sequences
which do not satisfy the rules of syntax. In computer simulation of this system, the, input
sound sequences were unclear weather forecasts (124 texts). Listening tests were conducted
and it was found that for an input of about 60% correct sequences the output was improved
to about 93%.
</bodyText>
<sectionHeader confidence="0.687369" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION 18
</sectionHeader>
<subsectionHeader confidence="0.835695">
Talker Recognition by Statistical Features of Spooh Sounds
</subsectionHeader>
<bodyText confidence="0.565716">
S. haul, and F. ltakura
Nrr, musushino,, Japan
</bodyText>
<subsubsectionHeader confidence="0.538118">
Electronics and Communications i I Opt? 56, No. t1:62-71„ November 191.1
</subsubsectionHeader>
<subsectionHeader confidence="0.783353">
Speeck sounds of,, seviena words ate represented by time setioems or prtitai kukto-ottititk
</subsectionHeader>
<bodyText confidence="0.9602242">
coeMclents and fundamental frequency. Talkit reognition experimet Is ate id on
parameters and include sevecal statistical measures suci. as averaged vatures,, starvdatd dev
and correlation coefficients between prarneters. Several words art used for the dectsksit.
When reference gunnies are obtained from four tutasurettlentS at 3-mouth intervals and four
words are combined, an average recognition te of 99.1% s obtained in4` identifying one
talker from 9 and 99,2% for verifyin4 ont talker in 37 after 3 months from the last
referertct sample. The long-term variatton of Nature parameters, which catritS recognition
error, is considered and the results indicate quantitatively that, although the parameters are
stable for sevetal days, variations become large ant rward.
PHONETICS-PHONOLOGY: RECOGNITION
</bodyText>
<title confidence="0.232931">
Speech&apos; Feature Extraction by a Modulated Fourier Function
</title>
<author confidence="0.561076">
N. Miki
</author>
<affiliation confidence="0.666761">
Hokkaido University, Sapporo, Japan
</affiliation>
<sectionHeader confidence="0.356755" genericHeader="method">
Yoshimoto
</sectionHeader>
<subsectionHeader confidence="0.764486">
Electronics and Communications in Japan 57, No. 1;56-63, January 19,14.
</subsectionHeader>
<bodyText confidence="0.999829444444445">
A method of estimating the speech spectrum envelope employs the Fourier transform of the
impulse response h(r) of the filter obtained by solving Wiener&apos;s inverse filter problem.
Noting that if t is made sufficiently large the impulse response converges toward zero, the
authors have considered expansion of h(t) in terms of a system of damped oscillating
orthogonal functions (a modulated Fourier system). 1his system permits representation of
featutes with fewer terms than are needed with Fourier transforms, and feature patterns
having ploes can be obtained in the same manner as formants. Effectiveness of the proposed
method is considered with respect to implementation on equipment which can use parallel
processing in extraction.
</bodyText>
<note confidence="0.309927">
PHONETICS-PHONOLOGY: RECOWTION 19
</note>
<title confidence="0.1906225">
Discrimination of Vowels by Use of the Static Features of the Local Peaks in
Flogiutency Spectra
</title>
<author confidence="0.322691">
K. Kido4 and T. Matsuoka
</author>
<affiliation confidence="0.176896">
7uitli24 UniversitA Sendai, Japan
</affiliation>
<construct confidence="0.4311615">
Woof ei the Research Institute of Electrical Communication,
Tohoku ritivers1tr26:/-24,1974
</construct>
<bodyText confidence="0.999857444444444">
The speech sanVles are frequency-analyzed by a filter bank composed of 29 single peak
filters of Q*6* -Olt center frequencies of the filters are every 1/6 octave from 250 Hz to
6300 Hz. [he 430-ustil parameters Pl, P2, Pel, Pe2, and PO are induced from the six
largest local peaks of the frequency spectrum obtained by the anaIes with the filter bank by
.appl)ing the peak prpeessing rules. The vowels samples uttered , both in isolation and in
continuation can be- tforined almost perfectly into the phonemic symbols. The rate of
the correct Wansformatiofo Lw.! vowels in spoken words into the plioneinit symbols is about
tiU%. The speech,sznimilgs are 5 jtipapese vowels uttered by 31 male adol,ts and tAenty \vords
uttered by 5 male adtilts.
</bodyText>
<sectionHeader confidence="0.8585385" genericHeader="method">
PHONETICS-PHONOLOGY: RECOGNITION
A Speech Processing System
</sectionHeader>
<author confidence="0.862349">
S. H. Saib
</author>
<affiliation confidence="0.9682125">
University of California, Los Angeles
Thesis. University Microfilms, Ann Arbor, Michigan. No. 75-2239,
</affiliation>
<subsubsectionHeader confidence="0.363603">
PC 111.00/MF 45.00
</subsubsectionHeader>
<bodyText confidence="0.998621333333333">
The study was limited to English vowels spoken in sentences and concentrated on a search for
those features which are speaker invariant. An abtomatic formant tracker was implemented
to reduce the data rate from 10,000 to 1600. bytes per second and to provide an accurate
indication or the formant frequencies and pitch frequency. The reduced formant and pitch
data were then plotted versus time. Each speaker&apos;s characteristics were calculated by taking
the sample average and sample variance of his formant frequencies. The normalized farnant
frequencies were used as features in a recognition algorithm applied to the original vowel
data and to an independent set of vowel data. Significantly lower error rates are achieved for
13 speakers&apos; vowels.
</bodyText>
<note confidence="0.8378466">
PHONETICS-PHONOLOGY: RECOGNITION 20
Prosodic Aids to Speech Recognition: VI, Timing Cues to Linguistic Structure
and Improved Computer Programs for Prosodic Analysis
Wayne A. Lea, and Dear R, Klohr
Sperry UNIVAC, St. Pauli Atinnesota
</note>
<table confidence="0.782996703703704">
Report PX-11230, March 31, 1915 4P-,4010 :111(64
PC $4.25/A1F $2.25
DeNctiptions of computer programs for detecting syntactic boundaries WOUND 3) alid
locating stressed syllables (STRFS,S), F‘petiments \titre conaucted vu Nainotts Unn its, that
correlate with phonological and nLwtk hraN,e boundario. T-urther opera:molts are planned.
PHONETICS-PHONOLOGY: RECOGNITION
k-nearest-neighbor Decision Rule Performance in a- Speech Recognition
System
G. M. White, and P. J. Fong
,Verox Corporation, Palo Alto, California
I(-nearest-neighbor decision rules were tested on classification of vocal utterances, with k 2
and k 2 9, Accuracy was greater with k 1.
PHONETICS-PHONOLOGY: RECOGNITION 21
Digitgl Representation of Speech Signals
R. VA &apos;Schafer, and 1. H. Rabiner
Bea naboratories, Murray Hill, N. f.
Proceedings of the IEEE 63:662-677, April 1975
Several digital signal processing methods for representing speech are presented and critically
discussed: simple waveform coding methods, time domain techniques; frliquency domain
representations; nonlinear or homorphic methods; and finally linear predictive coding
techniques. 49 refs.
PHONETICS-PHONOLOGY: RECOGNITION: SEGMENTATION
A General Language-Operated Decision Implementation System (GLOD1$): Its
Application to Continuous-Speech Segmentation
N. R. Dixon, and IL F. Silverman
IBM Thomas I, Watson Research (&amp;quot;ewe YorAtown Heights, New
Report 5368 (19741
</table>
<bodyText confidence="0.870233625">
The general language-oriented decision implementation system (GLODIS) represents a flexible,
operating-system approach to the generation and implementation of complex rules for
decision making in pattern recognition. GLOMS is currently implemented as a phonemic-
level seginenter for continuous speech. The segrnenter is presented in stifficient detail for
duplication by others, not only for speech segmentation but also for alternate applications.
Performance data are given for a large amount (8 1/2 minutes) of continuous speech. Recent
results from a total continuous speech recognition system, which incorporates the above, are
also given.
</bodyText>
<table confidence="0.8562044">
PHONETICS-PHONOLOGY: SYNTHESIS 22
Automatic Phonemization in Practice
Goratt Fngstrom
ReAcarch tiroup for Quantitative I inguisao, StorAhohn
Statistical !Jabot/3 in linguistics 8:39-55, 012
</table>
<tableCaption confidence="0.45251075">
The systetn which cited&amp; trade mark worth tor the Swedish ht t orrim
orthopaphic input. mnstructs poqible syllable representations, matches input syIWks wkh
syllables already stored in the nytchine, and dtterminAN Vilktitter or not th 4nputword is
similar to any other word currently beinit usett as a.tratkfulark vt.orti.‘ torkonant thrpters art
</tableCaption>
<bodyText confidence="0.9684424">
analyted to establish possible sOlable dtvisions. &amp;quot;Each tttibk is phonerniat IivididIy
and, when the price SS complete., the phonemic representations Mach bre, intentionally,
tmly approxima(e) are syntheslied into pouitIle ji ttllitS tor the input sivotti (intliicatictig
the rangt ti ptonunciations the wool is likely to be Oven) mid the matchint pnxtvt, not
des/albeit ,in this pper, it un.
</bodyText>
<sectionHeader confidence="0.916463" genericHeader="method">
WRITING: RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.995752">
Computer Recognition of Handwritten Numerals by Polygonal Approximations
</subsectionHeader>
<bodyText confidence="0.830695666666667">
Theadestas Pallidix, and Farhat All
computer Science 1.42 atory, Department of El.ectrical Ensineeriag, Princeton (fincersityi
Princeton, New Jersey
</bodyText>
<subsectionHeader confidence="0.437953">
IEEE Transactions on Systems, Man, and Cykractio 5:6/0-6/4, /915
</subsectionHeader>
<bodyText confidence="0.999395">
The outlines of handwritten numerals are approximated by polygons enabling a simple
evaluation of many intuitively descriptive features for numerals, for example, relative position
and &apos;opt of concare arcs. The method was tested on the Munson data (IEEE Data. Base 1.2.2),
and an ov.erall error rate of 9.4 percent was achieved without any statistical optimization. A
characteristic property of this approach i3 the existence of two steps: the fiNt step (primitive
feature generation) is primarily numerh:al, and the second step (feature selection and
classification) makes extensive use of semantics..
</bodyText>
<table confidence="0.695069">
2 3
Research Approach to the Modeling and Analysis of Different
Proposed for HuMarrPerception of Capital Letters
CSistk OtWs141
Operations Ittearritj&apos;togra Department of industrial Engineering, ,State University of
New Vork, limffaiolTi14
Lewis It (eer
Depart/nem of itidastri 1 Fng1erIng, Northestern University, Boston, Atassaehysetts
</table>
<subsubsectionHeader confidence="0.618203">
Coinputers and Operations Restotarch 2:61-70, 1975
</subsubsectionHeader>
<bodyText confidence="0.9428602">
A Matkov chain feature traigitlon model of capital letter&apos; recognition is ptcsented fot
synthesiting empirically derived 26 by 26 capital letter COlifilt1011 nitttrice4 (i I Townsend)
The trentation proonines toted with the features in the diode) are used as the solution
vtettir In an optimlintiutt problem4 the obtectivt being to raininilie *the stun tif per cell
squared dereliction between the empLrleal conrualon matrix and the synthesited matrix Three
</bodyText>
<figure confidence="0.517558894736842">
Pro reature pets are used in conjunction *v•ith the model to tlyntliesikie three 4!mpirica1
matrices. Variants or model ate considered-and mutts a* tabulated and analyzed
WRITING. RECOGNITION
On Feature Extraction in Character Recognition (in German)
L Ms awl J. Schumann
AEG relefankett, Oettuany
Witteaschajiliche Berichie AEG-Telefanken 47:100-110, 1974
A two system transforms a high number of original measurements into a lower number
Of *ton features before classifying tberri. The pruicipal component apptoach is used The
principal axis transformation is interpreted as a translation and rotation or the coordinate
system In the original measurement space. Feature extraction is ac‘omplished by truncating
the transformed coordinate system. This approach is compared with the alternative of
directly truncating the orrginal coordinate system
WRITING: RECOONMON
A Linguistic Pattern Recognition System
Cooley
UnttvrAy of Utah, Solt vike City
huvtrstty ,Victt. I Ann ‘4rhor, t an; . 3 It
1 1,00/ I
</figure>
<bodyText confidence="0.925343571428571">
I,inguistic rather than metric techniques are kinplo■..cd for p.ittern descriptitNn and
chsmfication. aspe‘.&amp;quot;ts of system de.ign, encompassik both pie-prokessl:. and
categort/ation function haw been inrestqi.a-ted. The rewgni:er ditto- from those&apos; of
prodous linguistic ssstems in that it N trainable in Mviih the same s,;:lse Ort&apos;
tvv■TrlilerS, an evict inatLh or parse of an input strik is 1101 th\y‘\:11,,I, tor caselfication
Using Munson&apos;s numeric character data, ;arecv.,,,mition of as &apos;ot,tained thc
unrNo,,mited, of the total ACTO hg COUM 011SIdv:IC&apos;d
</bodyText>
<sectionHeader confidence="0.722975" genericHeader="method">
WRITING RECOGNITION
</sectionHeader>
<subsectionHeader confidence="0.419505">
Pattern Matching by Dynamic Prog ammin (In Japanese)
</subsectionHeader>
<bodyText confidence="0.958706">
Y. Isomithi; and T. Ogavia
Chi.. Institute or Technology,, Japan
idurnat of the I rtformation Processing Society I Jo 1,n 16:11 January 19.75
In order to recognize handwritten charactem a new tyN of pattern matching technique is used
which depends, on t11e• hypothesis that patterns are a kind of elastic body Within, this
h.ypothesis, distance between two patterns is defined as the in of sums of the internal
energy or the elastic.. bodies and thee mismatching. quantities- Dynamic programming is used
to accomplish the minimization. The patterns, are presented on.. 20 by 20 lattice points_
</bodyText>
<note confidence="0.85566125">
WRITING: RECOGNMON 25
Choice of an Algorithms for the Recognition of Handwritten Characters (in
Russian)
N.. K. Milostasskaya
</note>
<sectionHeader confidence="0.289285" genericHeader="method">
Vibar I Peredoeha Informatsil 4216-21, 1914
</sectionHeader>
<bodyText confidence="0.987759">
After consideration or the principle difficulties encountered in machine recognition of
handwritten ttaracters, it is concluded that an algurithni employing image parameter
normaluation would be best. A formal analysis shows that the use of regulai mirinalintion
permits the recognition of characters with different angles or orientation; the property, or
conservation of a certain stability in the horilontal dimensions or 11character in a. line makes
possible the use of a simple dt4cision rule based on comparison or the area of an image with
a standard.
</bodyText>
<sectionHeader confidence="0.750589" genericHeader="method">
WRITING RECOGIITION
</sectionHeader>
<subsectionHeader confidence="0.626417">
On-line Character Recognition
</subsectionHeader>
<author confidence="0.400377">
A. C. Weaver
</author>
<affiliation confidence="0.461415">
University of Illinois
</affiliation>
<table confidence="0.846569214285714">
NrIS: PI1-235 875/2, August 1974
PC&apos; 11175/Alr 52,25
Discusses state-of-the-art in recognition or handwritten characters. A new recognition
method is developed using a voltage gradient tabret for input and clever software for essential
feature extraction. A simulation program is included as an appendix.
WEIMNG: RECOGNITION 26
Context in Word Recognition
A; R1 Hanson, F. Ithermit% and i, Go, Fisher
itstirtl-mty of Atits.varhuteits, Amherst
NTIS: 44D-7O 759/1, August fv74, J411/11C
Relatively low charaut error it can often lead to ptolnhtme kd vt *ova e,rt
Sovral techniques for integrating an indepciutent conte‘tual rostproces.sor WW1 litao &apos;A run
classcaiton NNstvm, are el,ainineti. The Ctl) detects errors .and is the %-ontrol structure for
directIng additional processing for error correctton.
</table>
<figure confidence="0.626433">
WRITING: RECOGNITION
Character Reader
/svrec /mc.
U.S. PUttlf1 37$4982, S January 1Q74. Coninlissioner of Patents, Washington, D. C. :0231
$0.50
An electro-optical character reader for handAritten chara4:ters.
WRITING RECOGNITION 27
Optical Charactel ecognition
Recograton Equipment
US. rttlerif 376491 Januar) 1974. Cinninissioner of Paten Washington, 0. C. 202314
$0.50
</figure>
<bodyText confidence="0.876543">
This. patent describes a system. for normaliting. signals produced by optically scanning
different sites and fonts- of chaiacters into a singlt format of signal for character
retiognition,
MUM. RECOGNITION
</bodyText>
<figure confidence="0.75163975">
Optical Character Recognition
Recognition Equipment Mr.
U.S. &amp;leo: J786416 15 January 1974. Ceiminissioner of Patents Washington, D. C. 20231.
$0.50
</figure>
<figureCaption confidence="0.726980666666667">
Printed characters, superimposed on a contrasting center bar, are identified by scanning akin
serticially aligned, laterally spaced paths to generate sigials dependent upon encountering
character portions.
</figureCaption>
<figure confidence="0.423497">
WRING: RECOGNITION 28
Character Recognition
Hitachi ltd.
U,S. Patent i$0J55.1. 9 .4pril (9144 CottitttiSxioner of Atiettis. Wohissiao, A C., 201.11,
$0,50
Choracters are identified by pattern matching Nvith stantind characters.Ive system es
particularly 6ititab1e for &apos;Chinese choral:1M.
WRITING: RECOGNITION: CHINESE
A Method ot Resolving Handwritten .Chiinese Characters and Its Computer
Simulation (In Japanese)
Sietuki
</figure>
<subsectionHeader confidence="0.487606">
Shibattra &apos;,fanfare of Technology, Japan
Jolama of the htformetion Procr.ssing. Society of .111$44 15:Q2P634, °teem,Ner 1974
</subsectionHeader>
<bodyText confidence="0.9997276">
A spatial circuit is designed Ahich is pcv.essed of two facunies of rL-tulving and contrastive
pictures. The usefulness of the circuit in the recognition of handuritten rhtnese characters is
tested by computer, simulation. A technique for converting the 3T13i01.1 information-Kok-min
system into a digital informition-processmg system by means of the Fourier transformation
for additive operators is explained.
</bodyText>
<figure confidence="0.376687285714286">
WRITING: RECOGNITION: CHINESE 29
Recognition of Chinese Characters by Means of Hierarchical Pattern
Representation
IL Ottawa, and Y. Tezuka
OsaAa University Japan
Technology Reports of the Osaka University, _Faculty of Engineering 24:603-615
October 1914
</figure>
<figureCaption confidence="0.736888375">
Four kinds of local patterns are enough to represent a Chinese character. The proposed
system- consists of three kinds of sub-systems: front-end processor, B-pattern recognizer, and
K-nattern Lecogniter, The front-end processor makes a thick character slender and extracts
attention points (intersections and end points of strokes), &apos;1 he li-pattern reLogniter&amp;quot; is able to
observe pre-patterns at attention points and to extract the II-pattern, To kinds of -measures
were defined and utilired: the similarity measure showing a degree of similarity or sub-
patterns and the mulling measure showing a degree of possibility of a B-patterii, The K-
pattern recogniter decides a K-pattern a character) by using reeognized B-patterns,,
</figureCaption>
<figure confidence="0.932861729927007">
WRITING: SYNTHESIS
A New Computer-baed System for Chinese Character Generation
Ryohei Kagaya
Project on Computational AnalysiS, National 1nter-University Research Institute of Asian
African, Languages Cultures, 4-51-21 Nishigahara, Kitaku, Tokyo, 114 Japan
Yu Kobayashi
Section of Communrcation Research, Tokyo Metropolitan Institute of Gerontology, japan
Computational Analyses of Asian African Languages, 2:9-35, 1975
A 111DP-9 program translates identifying strings into graphiv patterns. One part translates a
unit representation into strokes; another treats spatial arrangement of constituent units; the
third part displays the character.
WRITING: CHARACTER SETS
X3.17-1974t 19/5 $10.50
American National Standards institute, New YorA
Charadter Set and Print Quality of Optical Character Recognition (OCR-A)
11.■ •
V c) C
a., 0
= emit
s$ ....; •....
..-..
s... rz
1... tr.: ....,,
..c •---
,-
2 .:.... :7;
r•-•
....
..........
to• VC ti .....
.-.
--
„or .
eOr -- fa
III., VI
it. Cs. fa
lit ofS 0••
...0
4&amp;quot;, .:.••. C
•.,..,
.--
—
=
—,
.--
.... ...e &amp;quot;0
...a
t..... t.&amp;quot;.. .—
44!
440
%
0
1.1■•■•
ow.
tO .— 17.!
re., ..&apos;. i&apos;l 0
_ol... .0 ,,,,_ • —
0r
‘...
6... S,11 =
g
...• ..,,
to l
C.; ...... ,..,
...=
›•6 CI. &apos;&apos;.
to, In rl C
...0)
9., .— •--
CO
Co c..;
Co
&amp;quot;0 ::: = t73 Ci-
,--
....1..., --
C
r.:
to&apos;:
....6 ...::: ....-:: 0
IX ti
oft, 0
.re •■•••
I*
r&amp;quot;.•
1.—&apos;
.....„ ..... 6...
.... ...
v ....
!M.
LO CI
• •■•• aMtir ,
.... I..
•■=
rj C
....0 •C tj 2)
735
..... ,_. ....
&apos;
=
,..... .....
t... ..v t-.
... C. ....
so .....
...I &amp;quot;J .r&amp;quot;.&amp;quot; 75
11
1„) cIMP v.
• C&amp;quot; 0.0
14 &amp;quot;0
tv,
C
fe,
7„, •
.&amp;C .1&amp;quot;: ;51
147 6,0
ems. U./
Cal
Art, ••&amp;quot;&amp;quot;:
cr
fLO
1—.
4.50
CL.
U.;
LEXICOGRAPHY-LEXICOLOGY 31
Suffix Removal and Word Conflation
J. L. Dawson
Literary and Linguistic Computing Centre, Cambridge ,Universio
Bulletin of the Association for Literary and Linguistic Computing 2, No, 3,33-46, 1974
The system has a suffix removal program and a conflation program (which groups together
worts with lexically equivalent stems), The first program is based on an approach which
requires no dictionary of word stems and is specifically designed to precede the second
program,
LEX1COGRAPHY-LEXICOLOGY
Rank distribution in text and speech
Rangorye raspredeleniya tekste i yazyke
M. V, Arapor, N, Mum, and Yu. A. Shrejder
Moscow, USSR
</figure>
<table confidence="0.864535941176471">
Naguchno-Tekhnicheskaya Informatsiya, Seriya 2, 1975, No. 2, 3-7
Explication of Ziprs law.
LEXICOGRAPHY-LEXICOLOGY 32
Directions in Artificial intelligence: Natural Language Processing
Ralph Grishman, editor
Computer Seiener Deportment, Cowan( tLitt of Valhemoiicat Sciences„ New rorlk
Universiiy, 25,1 Mercer Strcei,, New York NW.
Repori No. NS0-7, 1975
Symposium, Modeling Dictionary Data, by Robert Simmons and Robert Amster;
Computeri/ed Di,scovery or Semantic Word:Classes in Nvicntiric FidaN,. by Naomi SAATet; The
OWL Concept Hierarchy, py William Martin&apos;. and Design of the 1,}iTaertving Structure for a
Data Base Retrieval System, by Stanley Petrick; Discussion, See abstracts of contributions
elsewhere on this fiche.
LEXICOGRAPHY-LEXICOLOGY: STATISTICS
English Lexical Collocations
S, Jones
London School of Economics
</table>
<author confidence="0.916665">
J. Men, Sinclair
</author>
<affiliation confidence="0.977792">
University of Birmingham, ,England
</affiliation>
<subsubsectionHeader confidence="0.789719">
Cahiers de Lexicologie 24:15-61, 1974
</subsubsectionHeader>
<bodyText confidence="0.996778777777778">
A study of two texts, a transcription of 135,000 words of spontaneous conversation and
12,000 words of written scientific text, suggest reasonable grounds for hypothesizing a lexical
level of language organization independent from, hut interacting with, both syntax and
semantics, Grammatical (functor words) collocations differ statistically from lexical
(tontentives) collocations and are more likely to be position dependent while lexical&apos;
collactions are position free. Association between lexical -items is subject to grammatical
influence (e.g. adjectives are consistently preceded by adverbs) and while:the data suggest that
grammatically free lexical sets exists, considerably more material will have to be analyzed for
collocations in order to identify them.
</bodyText>
<figure confidence="0.713449666666667">
LEXICOGRAPHY-LEXICOLOGY: STATISTICS Zi 3
On the Meaning of Rank Distributions
0 mph rongovykh raspredelenij
M. V. Arapov, E. N. Efimova, and Yu. A. Shrolder
Moscow; USSR
Nauchno-Tekhniches4oya Informaisiya, Scrlya 2, 1975, No. 1,,9-20
</figure>
<figureCaption confidence="0.7608682">
Social organisms and rank distribution. Some examples. Attempt at probabilistic
formali/ation. Another attempt. Alternative, to the i&apos;irthodox probabilistic approach. Some
words about the aggregate situation with rank distribution. Again about Ow collective of N
participants. Approx»nate description or the rank distribution in a closed text. Zipt&apos;s law
and the family of rank distributions. Ihe case of small text.
</figureCaption>
<sectionHeader confidence="0.801542" genericHeader="method">
LEXICOGRAPHY-LEXICOLOGY: STATISTICS
</sectionHeader>
<subsectionHeader confidence="0.920495">
The Concept of Lexical Structure of Text
</subsectionHeader>
<table confidence="0.25097396">
Ponyaite IcksichrsAoi struktury icksia
M. V. Aropov, and E. N. Efimova
Moscow, USSR
Notichno-rekhnichrsAoya Inforrnotslya, Scriya 2, 1975, No. 6, 3-7
An explication of Ziprs law.
LEXICOGRAPHY-LEXICOLOGY: STATISTICS: CLUSTERING 34
Computerized Discovery of Semantic Word Ctasses It Scientific &apos;PMI&apos;s
Nunnal Sager
linguistic String PrOfeet, New nth University&amp;quot; 251 Mercer Street )fork. 10012
Directions in ifrliffPinf initifttfore, Atentrat LtottiteRe ProcEi ettiteti 6
Cowman. Report No. NS0-11, couuut atsitote of Mathemojte. 197$
The trick i&amp; tO cluster words that. are similar in their rArlIMAkkat
word as their operator or nrgurneni Musters from 4&amp;entente&amp; of texts 6
ill I ,
displayed. Eg,,, a class of motion verbs relate ion wortiu-to cell voords (Tim grammatical
trees tor deep structures were made by human. analysts, pending earkhinent of the
transformational con:4)041ml of the string parser.)
LEXICOGFIAPHY-LEXICOLOGY: DICTIONARY
Computer Recognition in English Word Senses
Edward F. Kelley
Department of Electrical Engineering, Doke University, Durham, North Carolina
Philip J. Stone
Depamnent of Social Relations, Har yard University, Cambridge, ittassachasets
North-Holland Linguistic Series, Vol. 13, 1915. American EleleYier, New York,. N.Y. $17.50.
Elsevier/Excerpta Atedica, North-Holland, PO. Box 211 Amsterdam, The Netherlands
</table>
<sectionHeader confidence="0.211197" genericHeader="method">
DA 42.00
</sectionHeader>
<bodyText confidence="0.999705">
Developed, from a large corpus of text representative of typical content analysis applications,
the contextual search rules associated with each entry in the preprocessor dictionary
(containing over 1000 &apos;entries) resolve text words into word senses, Large scale valitiaticn tests
then prove that, relative to its specification of possible senses, the dietitanary correctly
resolves lexical ambiguity more than 90% of the time.. This represents a major advancd&apos; in the
power and accuracy of automated content analysis procedures. The &amp;quot;disambiguation
dictionary&amp;quot; has already been incorporated into the &amp;quot;General Inquirer&amp;quot;.
</bodyText>
<note confidence="0.716407">
LEXICOGRAPHY :LEXICOLOGY: DICTIONARY 35
</note>
<title confidence="0.458734">
Automated Language Analysis
</title>
<author confidence="0.735805">
Sally Yates Sedelow
</author>
<affiliation confidence="0.787955">
University of Kansas, Lawrence
</affiliation>
<address confidence="0.299659">
NTIS:AD/4-002 463/8(31
</address>
<bodyText confidence="0.6890305">
The report includes; 1) A description of the editing of a computer-accessible version of
Ropes &apos;International Thesaurus; 2) A discussion of mathematical aptproaches to the modelling
of Thesauri, with Rogers ser‘ing as an example; 3) Graph Theory applications to the study of
the structure of Ropes.
</bodyText>
<sectionHeader confidence="0.781469" genericHeader="method">
LEXICOGRAPHY-LEXICOLOGY: DICTIONARY
</sectionHeader>
<bodyText confidence="0.81949725">
A Bilingual Lexicon of 1001 Words&apos; from 24 Chapters of the Revised
Statutes of Canada - Un lexique Bilingue de •1001 mots extraits de 24
chapitres des statuts revises du Canada
V. Bergeron, and D. Burke
</bodyText>
<subsubsectionHeader confidence="0.5938725">
Faculte de Droll, Section de Droit Civil, Universite d&apos;Ottawa, Ontario, Canada
Report
</subsubsectionHeader>
<bodyText confidence="0.93533325">
English-French micro-dictionary with illustrative citations, produced from computer-stored
bilingual texts. The JURIVOC system is conversational: the system finds parallel sentences in
the two languages which contain a given term, and presents them via a CRT terminal to a
linguist-monitor who selects from them and prunes the contexts by keyboard manipulation.
</bodyText>
<table confidence="0.895053833333333">
LEXICOGRAPHY LEX1COLOGY. DICTIONARY: PARADIGMS
f■Aodeling Dictionary Data
Robert F. Simmons, and Robert A. Amsler
Department o) Computer ,Ne.;.enet,..s, Un rsu of as, tisun
DiieCliOns in Artificial ,10 lligence.. Natural ,,,,agr , R.:
(Irishman, Report No, NS() Courant 10;st:rule of Pfrtil,!i *I.
</table>
<tableCaption confidence="0.5031805">
Forms and structures of definitions (of vrbs in Nerriam-Websiers diaionaties arc
presented to eh:11Ni: models of NUIIC‘liOn C&apos;0111.i.1/41N, SOIS.0 meaninf...„ind hietarchical
</tableCaption>
<listItem confidence="0.8718745">
• relations amonz. Vet b.s., The sense-meanini: model. 1.s presented as a case-r,o,: semanti...s
accompanied h) time-ordered sets of assertions mariked for truth ra;ue Srstematk• e\metion.
</listItem>
<bodyText confidence="0.605204666666667">
of these types or models from dictionar) data is ,Thr:iied to !line of
research.
GRAMMAR: MORPHOLOGY
</bodyText>
<subsectionHeader confidence="0.467384">
Synthesis of Russian Nominal Word-forms by Means of a Computer
</subsectionHeader>
<bodyText confidence="0.664957142857143">
T. 1. Kominn
USSR
Az uchno-rci hiiischsA ova Informatc •d, Seriya 2, N
A description of an algorithm for the synthesis of Russian nominal word-forms on. the Nisis
of the morphology model developed by Es&apos;kova.. Mel.chulk and Sannilkov (1M). The.
programming language,. ASTRA, used to encode the algorithm is .described in brief..
&apos;Specimens of word-forms from BESM-6 computer printout are appended..
</bodyText>
<figure confidence="0.932449222222222">
1.)7
. 11_
.11.
GRAMMAR: PARSER 37
A Best-First Parser
William H. Paxton
Artificial Intelligence Center nford Research Institute, Menlo Park, Calif
IEEE Transactions on Acoustics, Speech, and Signal Processiv 23:426-432, 1975
The Parser uses a hest-first strategy in which alternative paths are ,wigiied priorities and
</figure>
<figureCaption confidence="0.501090285714286">
paths are suspended as long as there is a higher priority alternative. There are 4 types of steps
in t parse: I) Swtactic-..-selection of particular erammatical constructions, •2) Lexical - choice
of a particular word from a particular class, 3) Word Verification - proposed words are
matched against acoustic data, and 4).11110-parse Cooperation - cooperation among competing
parses. Priorities are ossignee al each step along a ,path. The system extends the path with the
hiehest i.&apos;itintilative priority (1000 times ttle product of step priorities to that point),
Experimental results are given,
</figureCaption>
<sectionHeader confidence="0.512637" genericHeader="method">
GRAMMAR: PARSER
</sectionHeader>
<subsectionHeader confidence="0.970144">
Syntactic Analysis in R.E.L. Erfgfish
</subsectionHeader>
<bodyText confidence="0.9650705">
flzen Iknisz Dostert, and Fredrick Burtis Thompson
California ltivitute of Technology, Pasadena
</bodyText>
<subsubsectionHeader confidence="0.623675">
Statistical Methods in linguistics 8:5-38, 1912
</subsubsectionHeader>
<bodyText confidence="0.999344875">
REL(Rapidly Extensible Language) English has, been made more powerful with the addition
of procedures for handling case (Fillmore) and pronouns. Thus verbs are analyzed as
propositions expressing, relations between nouns. Using a modified form or the Martin Kay
parser, case labels become incorporated into the arc labels of the, parsing graph. Pronouns
and quantifiers are variables which must remain an active part of analysis as long as they are
free, with their meaning being determined at the point in analysis when they can be bound.
A list of 411 free variables in a phrase and pointers to each occurrence of each variable is
included in the arc labels io the parsing graph.
</bodyText>
<note confidence="0.48332225">
GRAMMAR: PARSER 38
A System for Automatic Syntactic Analysis of Russian Texts
G. P. Aleksandreva, G. C. Ilelonpyr A. L Novoveclol, and E tStegov
USSR
</note>
<subsubsectionHeader confidence="0.297577">
Nirstehno-retitnische.thyo Ittforttlif#30t. Seript 2, No. 3:30-35, 1915
</subsubsectionHeader>
<bodyText confidence="0.9987126">
No restrictions are impowt1 on the structure and the word stock of the texts being&apos; analyzed.
which is achieved by means of, a procedure or ow automatic 4\sigitittent or the III-4minatizat
features to the &apos;new&apos; words. In scientific or technical texts. the system provides for the
identification of stxme S5% or relations between words.. With simpler texts (abAtiacts). q)% of
identifml relations :ire correct.
</bodyText>
<sectionHeader confidence="0.951443" genericHeader="method">
GRAMMAR: GENERATOR
</sectionHeader>
<reference confidence="0.4341868">
Automatic Generation of Engilsli Sentences
Autoiarische Er:eugung englischer Saet:e
K. Detering, IL Pilch, :and D. Clement
Alltert-Ludwrgs-Univ4rsodet, Freiburg, Germany
Janua Linguarum, Series Practica, No. 110; Mouton, Thc Hague, (13
</reference>
<bodyText confidence="0.9989768">
A purely syntactic combinatory synthesizer of grammatically correct English sentences is
based on the hypothesis that the synthesis process is the inverse or the analysis process. The
formalism is sufficiently general to describe otheD languages. A chapter deals with its limits
f,e.g. sentence length and complexity), marginally acceptable utterances, rule collisions. 70
examples of output are reproduced.
</bodyText>
<figure confidence="0.9361074">
SEMANTICS-DISCOURSE 39
Do Machines Understand More than They Did?
Yorick Wilks
Artificial intelligence I aboratory, Stanford University
Nature 252:275-278, 1974
</figure>
<figureCaption confidence="0.895597307692308">
Transformational generative theory has three defects: 1) the generation of sentences is not a
signif cant demonstration of human undefStanding, 2) the competence-performance distinction
isolates linguistics from tests of system of rules, ;” it has little room for inferences,
Winogrmils SHRPLU system is vulnerable to these criticisms: 1) the linguistic: system is
conservative, 2) its semantics is tied to a simple referential world, and 1) and it is strongly
deductive and logically closed. Current fashion is strongly linked. to Minsky&apos;s frame
paradigm Charniak&apos;s demon theory is superficial in that his demons are in item-to-item
correspondence with English sentences. (.&apos;onceptual Dependenc theo.ry (Seilani%) and
Preference Semonlics (Wilks) proside a deeper view b), the reduction or concepts to
primitives. Current points of contention: 1) do we make and retain massive forward
inferences or only generate deep inferences when shallow ones fail, 2) do we decouple syntax
and semantics or achieve the results of syntactic analysis by a sufficiently potful semantic
analyzer?
</figureCaption>
<bodyText confidence="0.427403">
SEMANTIOS-OISCOURSE
</bodyText>
<sectionHeader confidence="0.353227" genericHeader="method">
Semantic Approaches for Models of Automatic Analysis of Natural Languages
</sectionHeader>
<bodyText confidence="0.759369166666667">
APproches seinamiques&apos;pour les modeles d&apos;analyse automaiique de longues naiurelles
CIL NAM, rind J. airwave
Groupe (Etudes pour to Traduction ,Automatique, Instittut de Recherches en iWuthentatiques
&amp;unreel, Unirersite Scientifique et Medicate de Grenoble, B. P. No Si - 3$041 Grenoble
Cedc.r, France
Mimeographed /975
</bodyText>
<subsectionHeader confidence="0.698395">
Analytic Teview or models and systems for ssing from text to deep structure or
</subsectionHeader>
<bodyText confidence="0.923288666666667">
representation of meaning. Levels of representation. Coding (string, tree graph), functions,
algorithms. Criteria of power, simulation, complexity, adequacy. Systems: TITUS II,
CETA,GETA, Mefehuk, Simmons, Wilks, TLC, Winograd, Schank.
</bodyText>
<table confidence="0.698776333333333">
SEMANTICS-DISCOURSE COMPREl.lENSION 4 0
CompUtational Understanding: Analysis of entences and Context
Christopher Kevin Riesbeek
Derwritilent of (omptacr Screncr, StanjrtItinivorsit,v, S t &apos;Ord qrn4 to4305
Report Nos. sTAN-CS-74-437 V`. NTIS &apos;,4-005 040
PC $7 50/ Mr $2.25
</table>
<tableCaption confidence="0.4721216">
The construction of .this system for the of IA rum) to„ts v4as l&apos;Andod rout
aSSUMptions: 1) lhe priniar,s goat of comprehension is alwars to fina as s,,Noil as
poy..oble, (.thos tasks, such as tits.00VIM, the s)ntactie relationshir,, Airc perforn.Q‘l on vihen
essential to deeisions at,out alcaniwz, :2) An jitcmpt istno&amp; to unaers(and each \Nord as soon
as it is read: 3) (:omprehension means not old) anderstandine. NI, hat has t..n Ni&apos;,47n hut also
</tableCaption>
<table confidence="0.260704">
predb,:tinl; what is lilk,d) to bk.. iv,: \I. 4) Ifie 11110tds of a text pros id,: the et I or find in
the information nevessary for comprehending that
SEMANT1CS-OISCOUSSE COMPREll tsISION
The SRI Speech Understanding System
D01141id F,. Walker
</table>
<subsubsectionHeader confidence="0.653502">
Arti &apos;ciat In(elligencr t Stanford Reset] insti
IEEE Transactions On ,1coustics, Speech, and Sig
</subsubsectionHeader>
<bodyText confidence="0.9479394">
In the SRI, system, krlowledge from Various sources grammar and semantics, world model,
user and discourse model&apos;s, acqustie-phonetie data) is% coyrelinate.d a &amp;quot;bcst-first&amp;quot; parser to
predict the sequence of words in an utter:ince, and word functions—programs that represent
acougtic characteristics of a word—are used to test the predictions. Data on the s)stem&apos;s
performance are presented and discussed.
</bodyText>
<note confidence="0.5384025">
SEMANTICS-DISCOURSE: CO HEN$ION 41
SAM--A Story Understander
</note>
<author confidence="0.218332">
Ittiter Sebank, and the &apos;Yale iroc
</author>
<affiliation confidence="0.59732">
Department of Computer Science, le University, New Huven, Connecticut.
</affiliation>
<subsubsectionHeader confidence="0.367866">
ReTeurch Report 43 August 1915
</subsubsectionHeader>
<bodyText confidence="0.980030125">
A script is a causally organi/ed conceptual structure representing actions performed in
stereotyped situation-7i (el, eating in restaurant)„ SAM (Script Applier Mechanism)
understands stories thar rely- heavily on scripts. IA can produce a short or a long paraphrase of
the input story, a summary of the story, and it has a question answering program and a
program to translate stories into Chinese. tach script is organited around a goal (such as
IN( 1:ST for eating in a restaurant), sshich usually implies mutual obligations among
participants in the script, and tABININtS of tracks (eating at MtDonalds, eating at an vcpensive
restaurant, CO which consist ot scenes V4 MO consist or statwenres.
</bodyText>
<sectionHeader confidence="0.788655" genericHeader="method">
SEMAI&apos;MCS-DiSCOURSE: COMPREHENSION
</sectionHeader>
<subsectionHeader confidence="0.733847">
An Environment and System Jor Machine Understanding of Connected Speech
</subsectionHeader>
<figure confidence="0.558255">
D. Etnum
anford University
,Unirersitv littera ifirAigart, No, 74-27012
PC $11.001,Vr $5.00
</figure>
<bodyText confidence="0.969983333333333">
The HLARSAY system uses synrt tic, semantic, and contextual information, as well as the
more traditional domains of atotbtic-phonetic, phonological, and lexical knowledge, in order
to recognize, and understand utterhnem
</bodyText>
<figure confidence="0.9533482">
SEMANTICS-DISCOURSE COMPREHENSION 442
Computer Assisted Application System
trial ti n Mikehons
I ThOlftt13* J. Watsoes Rerrarch neRta reff
Repoti 5i$1
A system is being developed to brifkle the tap NAAVV14 appkatilon pcvigunil Iota iristr
irieN,Nciemed in the fcomputm 1-ht over c‘ploivs the chArlderamik-s
programs by a naturol, latipta.ge diatovire with the stem Thc difitofix 5444411.1iit0. by 3
knoviWil,C N&apos;St tAPeeting, NO the pr unum. ribli pot/
addreNses the problems of representation ;and tato:live invol&apos;irJ,
SEMANTICS-DISCOURSE: COMPREliENSION 43
Semantic and Argumentative Text Description: A Contribution to the
Simulation of Speech Communication
.5(7,71c:wise-hes und argumemative Tode,skription: Ein lleftrag zur Simulation sprachlirber
Kommtlitikarion
&amp;quot;fried Lenders
Unslirut fuer lommunikat tonsfor.chung und Phonetik, 001111, Germany
Helmut Ruske k&apos;&apos;&apos;erlag, Hamburg, 1975
ISBN 3-871M-199-1
Contents
</figure>
<bodyText confidence="0.952373294117647">
:oundations of computational-linguistic text description . • • %%%%%%%% 1
Machine text description as the simulation or verbal behavior; automatic text general
characterirition of machine systems; linguistic text description and text
comprehension; word meaning and argumentative text analysis--two ranges of
linguistic text description
2 Methods of machine contentive text description 69
Development of semantics in linguistic data processing; lexicographic oriented models;
computer oriented models; roiesv of published methods
Reflections on the meaning presentation of speech elements in linguistic
description systems. 163
Theoretical preliminaries; praxis of meaning repreyentatrom problems of meaning co-
ordination
4 Argumentative text analysis . 193
Theoretical part; practical pit; proposal for an argumentative text analysis; dosing
review or argumentative analysis
Literature (241 entries). .... ............. 247
....
</bodyText>
<note confidence="0.520076285714286">
SEMANT1CS-D1SCOUSSE: COMPREHENSION 44
Speech Understanding Systems: Quarterly Progress Report No. 11, 1 Nov 74
- 1 Feb 75
William A. Woods, Richard M. Schvoarti, JONI W. Kloistad, Craig C. &apos;Cook, and Jared J. Molt
lion lilertinfit, and Newman he., 50 Moulton Street, Ctunkititze, Atituaehusetts 0.31.18
Report No. 3018, 1975; AD-444007 586/1CM
IC $435: AO&apos; $2.25
</note>
<bodyText confidence="0.9319762">
Acoustic phonetics, lexical retrieval, verification, and nbturat-language syntax,
semanties,, and pragthatics. Part 1: Brief survgy of progrtm in the tridividual components of
the pro*. Part 2: 1A-bilk:A niites containing detailed spevifications of everiments
performed, programs implemented, design studtes, and %here appropriate sunvorting data and
aripendices.
</bodyText>
<sectionHeader confidence="0.981326" genericHeader="method">
SEMANTICS-DISCOURSE: COMPREHENSION
</sectionHeader>
<subsectionHeader confidence="0.743502">
The Simple Simons: Three Pedagogical Examples of the Use of ENT 2212
</subsectionHeader>
<bodyText confidence="0.411975">
Da.rid B Benson, and Thomas R. West
</bodyText>
<subsubsectionHeader confidence="0.5951225">
Computer Science Department, Washittston %Vale University, Pullman 99163
Report No. CS-74-015
</subsubsectionHeader>
<bodyText confidence="0.999808">
Simple Simon 1 is a completely trivial extension to Ent 2210 illustrating the basic semantic
and extension capabilities of Ent, Definition; illustration; reformulation us Simple Simon 1.5
with equal &amp;quot;understanding&amp;quot; of English. Simple Simon 2 uses subset and set membership
fad lities and recursion .to demonstrate&apos; an elementary method of distinguishing &amp;quot;fact&amp;quot; from
&amp;quot;possibility&amp;quot;. Simple Simon 3 illustrates a method of treating pronouns and anaphoric
references; time is handled as a relation. Use of extension capabilities to define numerous
semantic subroutines and to establish a good notation for association entry and retrieval.
</bodyText>
<sectionHeader confidence="0.755746" genericHeader="method">
SEMANTICS-DISCOURSE COMPREHENSION 45
</sectionHeader>
<subsectionHeader confidence="0.569825">
Understanding Understanding Systems
David Ililahr
</subsectionHeader>
<reference confidence="0.979545125">
arnegie-Mellon University
Ire W. Gregg, Mijor, Knowledge and Cognition, Lawrence Erlbaum Associates, Inc.,
2957-.100, 1974
&amp;quot;lhis is a discussion of MERLIN (Moore and Newell) and HEARSAY (Rectd), and Newell)--
both papers are abstracted elsewhere on this fiche, Human learning of language and of
knowledge in general Likes place in situations where complex error correction (from adults) is
available,. Both Merlin and Hearsay are silent on the issue or the source or knowledge. This
raises the following issue: Can a system that &apos;has not self-constructed most c&apos;g its knowledge-
-through a cycle of aNS1 mi latirni and accOmmodation—erer manifest deep uliderstanding?
Roth Merlin and Hearsay deal with sgeond-hand. preproeslssed knowledge.
SEMANTICS-DISCOURSE: COMPREHENSION
Knowledge and Its Representation in a Speech Understanding System
Raj Reddy, and Allen NCYICII
Carnegie-Mellon University
Lee if&apos;. Gregg, Editor, Knowledge and Cognition, Lawrence Erlbaum Associates, Inc.,
25J-2$5, (974
</reference>
<bodyText confidence="0.974869666666667">
HEARSAY operates in tbe microworld of voice-chess. Knowledge from acoustic, syntactic
and semantic sources is used to generate hypotheses about the incoming speech signal, thereby
restricting the search space. Given that a word such as &amp;quot;captures&amp;quot; or &amp;quot;takes&amp;quot; appears in the
partial sentence hypothesis, this knqwledge can be used to restrict the search to the capture
moses in that board posirion. The grammar is context free. The parser is a modified top-
down parsec and uSes antiproductions (giving all contexts for every s)mbol appearing in the
grammar) in parsing backwards and forwards. Phonemic description is used for mapping
words in the 31 item lexicon onto segments of the incoming utterance. At the phonemic
level, characteristies of the phonemes, rules for predicting missing and extra segments in
relaxed speech, juncture rules and rules that distinguish between pairs of phonemes, are
available to the system. Knowledge of allophonic variability and speaker variability are also
Used. A detailed discussion of one example (&amp;quot;Bishop to Queen knight three&amp;quot;) is given,
</bodyText>
<figure confidence="0.191484833333333">
SEMANTICS-DISCOURSE: MEMORY 46
A Framework for Reptesenting Knowledge
Marvin Minsky
Artificial Intelligence Iltboratory, Atassachuletts Instimte of Tech:142km C4unô4ge O21J9
Re orf At-At...106, June 1974; NM: AD-A011 168/20A
PC $4.7,SAIF $2.25
</figure>
<bodyText confidence="0.999736">
The theory coMbines classical-and modern concepts (rom p holog.Unistk and AL trat
new situation one selects from memory a structure called `a frame: a remembered rtZtIte*Oek
to be Adapted to fit reality by changing &amp;Mitt as netessary, and a data-strwt....re rOt
tepresenting a stereotyped situation. A.ttartled to cub: frame are several kinds ot information
- how to use the frame„ what one can expect to happen net and what to do if these
expectations are not confirmed. The report discusses collections ot related frames that ate
linked together into fmne systems..
</bodyText>
<sectionHeader confidence="0.981528" genericHeader="method">
SEMANTICS-DISCOURSE: MEMORY
</sectionHeader>
<reference confidence="0.510608">
Frames, Planes and Nets: A Synthesis
Greg W. Scragg
</reference>
<subsubsectionHeader confidence="0.536061">
Istituto per gil Studi Semontici e Cogaitivi, Castoztiolas Switzer&apos; nd
Worklng Papers 19, 1975
</subsubsectionHeader>
<bodyText confidence="0.99988175">
By incorporating the notion of frames into seniantte nets it becomes possible to establish a
level of representation for a concept intermediate between the nodes adjacent to the concept
node and the entire net. Weak bi-difictional links are formed between a key node and the
nodes in the plane for key node. The plane is a franre?like unit Each concept node is the
key word of some plane and each plane is exactly the same as the list of planes in which a
node appears. As a node is activated so is its associated frame. A short first-in first-out list
of active planes is established as a basis for context maintenance, resolution of word
ambiguity. and other inferential processes.
</bodyText>
<note confidence="0.646355">
SEMANTICS-DISCOURSE: MEMORY 47
</note>
<sectionHeader confidence="0.35601" genericHeader="method">
A Memory-Process Model of Symbolic Assimilation
</sectionHeader>
<reference confidence="0.942349875">
W. C. Mann
Cbrnegie-ittellon University
NT1S: AD/4-004 331/5, April &apos;1974, 291p,
P(&apos; $8.73/AIP 32.25&apos;
1 he assimilation problem concerns making kgowledge to make available information useful.
Research conducted on this problem has resulted in a model of human short term memory
and an effect‘■e collection or new general methods for information science. The program
manipulates knovdcdge and experience represented as labelled directed graph&apos;
.
SEMANTICS-DISCOURSE: MEMORY
Conceptual Memory: A Theory and Computer Program for Processing the
Meaning Content of Natural Language Utterances
C. J. Rieger
Department of Computer Sciences, Stanford University
Report Nos. ST4N-05-74-714, AIM-233, July /074; NT1S: AD/A-000 086/9, 412p
PC 110.50/ME $2.25
</reference>
<bodyText confidence="0.9245616">
Humans perform vast quantities of spontaneous, subconscious computation in order to
understand even the simplest language uttecances. The computation is principally meaning-
based, with syhtax and traditional semantics playing insignificant roles. This thesis supports
this conjecture by synthesis of. a thecly and computer program which account for many
asPects of language behavior in humans. It is a theory of language and memory.
</bodyText>
<figure confidence="0.974217">
SEMANTICS-DISCOURSE: MEMORY 4 $
A Brief&apos; on Case
Fugene Charniak
Istituto per sal Stwit Sernantici e (ognitiN, 6916 (&apos;astagnola, Switzerland
Working Papers 22, /Q75
</figure>
<figureCaption confidence="0.273649">
Cases are the-few ways arguments can be related ,to a predicant_ blItnefits (mtanag
</figureCaption>
<bodyText confidence="0.9933575">
can be factored Intt . meaning of predicate: ang of case; determining: what arguments may
appear in surface structure; ordering arguments) dryly app,Lar in Al; the reasons are
notational problems, lack of semantic definitions of casm and • representations too far from
SAjtrne. strurture4 Selection restrictions can be stated without cases so can implied but
unstated arguments, In Al, the main benefit of case is lacilitAton of inferences; but often a
change of notation gains the sante inferences without cast Case notation is popular bteatirse
it suits networks, whereas positional potation suits predicate formulas; but current. Ali systems
use the iloiatton without its theoretical .content.
</bodyText>
<sectionHeader confidence="0.8896895" genericHeader="method">
SEMANTICS-DISCOURSE: MEMORY
A Structure for Actions
</sectionHeader>
<bodyText confidence="0.376949">
Greg W. Suing
</bodyText>
<subsubsectionHeader confidence="0.530326">
Istituto per gli Studi Semantic&apos; e Cognitivi, Castagnola, Switzerland
Working Paper 20, 1915
</subsubsectionHeader>
<bodyText confidence="0.989299125">
Knowledge of actions is used in Al s)stems for performance, plai‘ning, qUestion
understanding, cause-and-effect representation,. and beliefs. KOP Aknowledge of Procedure)
nets are intended to be mychologically reasonable and a suitable basis for all these
applications, blending easily with static representations for world. knowledge.. KOP nets
contain three types of events: GOAL, ROTE, and WAIT. They are tied together in a
structure containing time orderings. reasons., major steps, results, methods. and static
information. Both task and motive-directed processors. are emisaged to account for the
difference between actions described in English with different adverbs,.
</bodyText>
<sectionHeader confidence="0.320919" genericHeader="method">
SEMANTICS-DISCOURSE: MEMORY 49
</sectionHeader>
<reference confidence="0.85660025">
The OWL Concept Hierarchy
William Martin
Matsachusetts Institute of Technology, Cambridge 02H9
Directions in Artificial Intelligence: Natural Language Processing, edited by Ralph
Grishman. Report No. NSO-7, Courant Institute of Mathematical Sciences, 1975, pp. 49-59.
The right representation is important in eliminating complexity so that very large programs
can be made. &apos;The representation communicates the way a field is organiyed... Multiple
representations are needed for differant processes, pedlar atirr
u...N.nt levels, even jt one IS
canonkal. No one set of primitives provides a decent way to think about the world, Pattern
Makhing is more important than logic, deduction, or procedure execution: long chains or
reasoning tail in Al, but finding that a problem belongs to a class with known solution opt
suctiteds. 1 he whole problem of getting knouledge into a canonical repreqmation will be
done by,&amp;quot;volunteeis&amp;quot; if a good form is proposed. OWL uses specification and semantic.cases:
examples.
SEMANTICS-DISCOURSE: TEXT GRAMMAR
Sublanguage Grammar in Science Information Processing
Naomi Sager
Linguistic String Project, New York University
Journal of the American Society for Information Science 26:10-16, 1975
</reference>
<bodyText confidence="0.934710333333333">
The literature of a science subfield has characteristic restrictions on language usage which can
be used to doctor, information formats for text sentences in the subfield. The text grammar
for the subfield of .pharmacology we have investigated has four levels: 1) Start at the bottom
of the parses and collect nouns into classes on the basis of co-occurrence with verbs and
verbs into classes on the basis of co-occurrence with nouns. At the bottom level a verb with
noun subject and noun object is an elementary sentence. Elementary sentences may have
operators on them and these operators yield 3 more levels. 2) Quantity words as operators
3) Sentence connecting verbs. 4) Verbs with human subjects which express the scientist&apos;s
relation to the events.
</bodyText>
<sectionHeader confidence="0.425224" genericHeader="method">
SEMANTICS-DISCOURSE EXPRESStON 50
</sectionHeader>
<reference confidence="0.8256232">
A Program for G.en.erating Repots on the Status and History of Stochastically
Modifiable Semantic Models of Arbitrary Universes
Sheldon Mein, John. 1). Oakley, David 3. Niktirloalle, and Robert A. litsoiler
Computer Sciences Department, Unirersity ufWi4COOtitt* Atttat$044.!
Sit/HS/kW. Methods in Linguistics 8:64 91, (972
</reference>
<bodyText confidence="0.948423222222222">
A three levet model of language Which has an affinity to tatuhs Stratifitational mntar
(though transformations are used .in. the vsteni), is used to write: a story, Ihe input data
consists of; 1) a list or participants (e-,g. Georm.cigars, party, Georges apartment( etc..), 2) a
list of relations (e.g. in, dislikos„ jealous., etc4).; 1), a statement ot classes Ottil„ MOMS, W.),
4.) the attributes of the human participants (bald, Italian, sexy, etc.).`, 5) propositiOns (triples)
about the human particifiants (George likes nightclub.. George is in computing, etc.).„ and 6) a
set of probalistic rules for generating plOt epimles, such as inv;)ting people a party, kw iting
drunk, etc. The first five lists define initial conditions and the list of rules opetattS On these
conditions to Produce a list of episodes in the stoty,
</bodyText>
<sectionHeader confidence="0.748047" genericHeader="method">
SEMANTICS-DISCOURSE: EXPRESSION
</sectionHeader>
<reference confidence="0.760597666666667">
A Study of- the Paragraph Structure
Adam J. Sumer
Computer Science, Division, National Physical Laboratory, Teddington, En land
</reference>
<subsectionHeader confidence="0.703322">
Statistical Methods in Linguistics 1973:79-90
</subsectionHeader>
<bodyText confidence="0.9998342">
A study of 45 American and British scientific articles comprising 1532 paragraphs and 1453
sentences showed a mean of 4.87 sentences per paragraph with a standard deviation of 2.18.
This lends weight to the assumption that the number of semantic units (assumed to be
sentences) in a paragraph corresponds to the Miller-Yngve limit (7, plus or minus 2) of
human short term memory. An algorithm for dividing a continuous text into paragraphs
consists of two runs. On the first the text is scanned for links (indicative of semantic
relationships) by using short lists of appropriate words and phrases. The second scan searches
for fluctuating patterns of repeated words. The algorithm was tested by macnine for some
procedures with others being carefully hand simulated. The test was fairly, but not
completely, successful.
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.821375904761905">Journal of Computational Linguistics 42 THE FINITE STRING OF THE ASSOCIATION FOR COMPUTATIONAL VOLUME 13 - NUMBER 2 FEBRUARY 1976 Abstracts from the 1975 LSA Meeting . 2 Current Bibliography 9 Proceedings, 2nd US-Japan Computer Conference 82 AMERICAN JOURNAL OF COMPUTATIONAL LINGUISTICS is published by the Center for Applied Linguistics for the Association for Computational Linguistics. G. Hays, Professor of and State University of York, Buffalo. ASSISTANT: Benzon Willows, Wanakah, York 14075. EDITOR: Center for Applied Linguistics Hoffman AND SUBSCRIPTION ADDRESS: North 22209. the Association for Computational Linguistics Journal of Computational Linguistics 42 : 2</note>
<affiliation confidence="0.83456">ABSTRACTS OF PAPERS ON COMPUTATIONAL LINGUISTICS LINGUISTIC SOCIETY OF AMERICA</affiliation>
<address confidence="0.605009">7 ANNUAL MEETING</address>
<degree confidence="0.338969666666667">A session was organized by Aravind K Joshi on behalf of ACL. The abstracts are reprinted on the following pages from the Meeting Handbook, with the permission of the</degree>
<title confidence="0.76694375">Society LSA MEETING 197$ 3 A MODEL FOR FUNDAMENTAL BASED ON CbMMUNICATIVE FUNCTION</title>
<author confidence="0.999912">Jonathan Allen</author>
<abstract confidence="0.9817089">of By examining the communicative speech aeL performed with an utterance, a comprehensive model for the generation ol fundamental frequency contours can be derived. Each utterance is considered to have propositional, interpersonal, and discourse and model shows how each of these determine a relation between the underlying syntax and semantics, and the surface fundamental frequency. The underlying performative and proposition control the basic contour shape, which is then perturbed by markers of the speaker&apos;s attitude toward the proand the of focus-shifting transformations. The interpersonal function is supplied by modal operators indicate the speaker&apos;s attachment truth-value of the proposition, and we show how modals and their scope are realized in the fundamental frequency contour The use of transformations to achieve effects also strongly marked movements, and these are characterized for a wide range of transformations. All of these effects are shown to be essential for a comprehensive model of pitch contours.</abstract>
<date confidence="0.544575">MEETING 1975</date>
<title confidence="0.933169">NEGATIONI GRAMMATICAL, SEMANTICAL, AND PRAGMATICAL</title>
<author confidence="0.997394">Felix Dreizin</author>
<affiliation confidence="0.999552">Bar-flan University</affiliation>
<abstract confidence="0.9958346">It is generally agreed upon that presuppositions are not affected by negation. This is not so for a vast class of speaker presuppositions--those about the information at the disposition of the hearer. Example: with respect to the sentence &apos;It was John who killed a presupposition of the above kind killed ) is normally affected by Uttering this sentence. I propose to distinguish between three kinds of negation: (a) grammatical (GN) &amp;quot;not&amp;quot;; (b) semantical (SN) if &amp;quot;missed&amp;quot; is described with respect to a basic semantic unity &amp;quot;hit&amp;quot;, then &amp;quot;missed&amp;quot; = NEG (hit), (c) pragmatical (PN): &amp;quot;no&amp;quot;: rejecting a piece of information which the hearer is assumed to be aware of. This yields eight sentence types (&apos;A&apos; stands for &amp;quot;Assertien&amp;quot;). (1) SN GN PN It wasn&apos;t John who killed Mary. (2) SN GN PA ? Seems not to exist. SN GA PN He missed the target. (Contrastive stress) SN GA PA He missed the target. SA GN PN He didn&apos;t miss the target. SA aT PA ? Seems not to exist. SA GA PN It was John (rather than Mary) who killed Bill. SA GA PA He hit the target. The subtle differences between semantically equivalent sentences (5) and (8) can be ascribed to the opposition PN vs. PA. The above framework is a useful tool to account for negation in discourse.</abstract>
<note confidence="0.448309">LSA MEETING 1975 5</note>
<title confidence="0.989711">NATURAL LANGUAGE ANALYSIS IN A FUNCTION ORIENTED SYSTEM</title>
<author confidence="0.998179">G C Goldbogen E C Chylinski</author>
<affiliation confidence="0.944676">Union College General Electric Corporate Research and Development</affiliation>
<abstract confidence="0.961568789473684">For English comprehension and deduction in an interactive system an ATN produces a binary syntactic tree; semantic analysis tollapses the tree and yields a LISP program representation, used in one module as a function on the system data base and in the other as a WFF to be verified from the data base. FORNAP (function Oriented natural language processor) grew out of SIGS, written at SUNY Albany for graph theory. A domain of discourse consists of elements and functions; in graph theory, elements points, lines, graphs, and boolean T, F; one function is COMPONENTS, mapping graphs into integers. The ATN model restricts English; restricting each word to a single part of speech results in no ambiguity for legal sentences. The semantic collapse is bottom up, it works with rightmost parent node with two terminal sons, using syntax, dictionary, argument table. Some cause arguments be checked and staeked for later types cause pieces of the WFF to be assembled, possibly using stacked data. Applications using WFFs in the theorem proving module, LSA MEETING 1975 6</abstract>
<title confidence="0.58375">STRUCTURE</title>
<author confidence="0.93645">Linda Misek</author>
<abstract confidence="0.981933826086956">eo Kaplan is optimistic that Woods-type &amp;quot;augmented transition network&amp;quot; grammars can capture the psysghological reality of human processing by modeling linguistic performance and competenCe. Cognitive mappings from surface strings are also of interest to Schank, whose &amp;quot;conceptual dependencies&amp;quot; infer deepcase relations from parsable featurts. Both approaches promise to lead us from language to patterns of thought. This paper presents recent developments in Claim Structure Grammar a stratified system representing real world text as sets of conceptual &amp;quot;claims&amp;quot; or assertions which bind entities, relations, and their properties. CSG postulates thematic deep structures by conceptually interpreting events at nodes and on transition arcs in surface networks. Discourse parsed for &amp;quot;claims&amp;quot; may be a well-formed text, sentence, or clausc.--or simply a fragterms nonetheless entail commitments. The form of CSG is a transition net, its function is to differentiate among the users of a language and among the separate states through which an individual speaker or writer transitions in process of gommunicating world knowledge. Originally devein the of rhetoric stylistics, CSG gains in and significance viewed the perspectives of Woods, Schank, and others.</abstract>
<note confidence="0.864896">L$A MEETING 1975 7</note>
<title confidence="0.8940085">USE OF NATURAL LANGUAGE IN COMPUTER PROOF CHECKING</title>
<author confidence="0.996625">Robert Smith</author>
<author confidence="0.996625">Lee Blaine</author>
<affiliation confidence="0.99976">Stanford University</affiliation>
<abstract confidence="0.975595941176471">The EXCHECK system is a proof checker designed to check .and discuss student proofs given in a style approaching that of standard university mathematics. EXCHECK is currently being used to teach axiomatic set theory at Stanford. Informal mathematical proofs suppress an enormous amount of detail that simply gets in the way of understanding the proof. The suppression of this detail involves the use of natural language, incorporating many of the known problems such as elliptic and references, operator scope and precedence, the use of semantic information. In order to check such proofs, it is necessary to understand the relationship between rigorous mathematical proofs and their informal presentation in a mathematics curriculum. Film and slides show the current version of the EXCHECK proof checker, with emphasis on the NL aspects. Furthermore, we discuss our efforts to represent the structure a student&apos;s developingproof EXCHECK on the PDP10/TENEX timesharing system at Stanford</abstract>
<phone confidence="0.692689">1975 8</phone>
<title confidence="0.997205">FOR COMPUTING PRESUPPOSITIONS AND ENTAILMENTS</title>
<author confidence="0.998362">Ralph Weischedel</author>
<affiliation confidence="0.685538">Universaty of California, ilvine</affiliation>
<abstract confidence="0.979085228571429">Presupposition and entailment are a subclass of inferences to the structure of a language. may arise from syntactic structure and from the meaning of individual words; entailments arise from the meaning of particular words. Since they are tied to the structure of language, they may be computed by tree transformations, independent of context not inherent in the structure of a sentence. This is a particularly simple computation, in sharp contrast to other computational mechanisms suggested for the general class of inferences. Other aspects of the uniqueness of presuppositions and entailas a class of inferences will be considered. which accepts as input individual sentences and gives as output the presuppositions and entailments of each sentence will be described. Journal of Computational Linguistics : CURRENT BIBLIOGRAPHY The tentative rules for selection of material and the tentattve subject categories used to classify it are about to &apos;disappear. The number of members responding to this year&apos;s directory call is more than 100; the number of categories checked per member is so large as to signify a misfit between the categories and the members&apos; self descriptions. A cluster analysis is being made in an informal way; the clusters will be adopted as new subject headings, replacing or extending the present system. The new categories will appear in the index to be delivered in about a month and in the next issue of The Finite String. The number of members interested in certain bopics (see Microfiche 37) is so small ag to raise questions about the expended to bibliographic coverage. After conwith Board, the Editor expects to some areas--unless our handling of those areas is superior to other abstract journals, and our quality be used to More members quickly, frame of subject headings with frame numbers.</abstract>
<title confidence="0.967889633333333">SUBJECT HEADINGS GENERAL PHONETICS-PHONOLOGY Recognition Segmentation Synthesis WRITING Recognition Chinese Synthesis Character sets LEXICOGRAPHY-LEXICOLOC Statistics Clustering Dictionary Paradigms GRAMMAR Morphology Parser Generator SEMANTICS-DISCOURSE Comprehension Memory Text grammar Expression LINGUISTICS- Methods Mathematical Statistical Historical</title>
<abstract confidence="0.5660546">COMPUTATION structures systems SOCIAL-BEHAVIORAL SCIENCE uk•</abstract>
<note confidence="0.7157743">75 30 36 36 37 38 39 40 46 49 50 51 52 55 55 Learning, Automatic Language Analysis: Their Application to Information Retrieval Appremissage, analyse autamatique du langage, application a la documentation A. Andre0“ky, C. rluhr, and Debralne Cemre d&apos;Etudes Nuctcaires, Saclay, France</note>
<abstract confidence="0.961485833333333">l&apos;ocument de Owls:Nue Quantitative, No. 20; Parts: Dunod, 1W3, $20.00 of papers reporting aspects or work by the Groupe de linguistique automatique at CEN-Sacla): Strategy for a learning program for computatiomil linguistics: Algorithms for French sentences; A ”stem analysis, machine indexing, hierarthical divtiment search, and decilion aids. 1he last combines a Bayesian model with the output from automatic parsing &apos;and semantic analysis.</abstract>
<title confidence="0.8048885">GENERAL Outline of Natural Language Systems</title>
<author confidence="0.7579665">lapan KittrAmsbu</author>
<abstract confidence="0.987442666666667">of the Kyushu institute of Technology, No. Develops systems (NL stem) for describing human thinking processes by means of natural language. Basic hypotheses giving base for describiag thinking processes in natural language are stated. Outlines of whole system constructions and their behaviors on these bases are The feature NL srsterns is that they are constructed from the standpoint of engineering and, therefore, many useful sub-systems may be constructed from these systems.</abstract>
<title confidence="0.824877">GENERAL Five Lectures on Artificial Intelligence</title>
<author confidence="0.99942">Terry Winograd</author>
<affiliation confidence="0.999972">Stanford University</affiliation>
<address confidence="0.753386">AD/44-000 085/1, September 12,25</address>
<abstract confidence="0.869303333333333">contents : Computer systems for natural language; SttROL(J, a system tot duez tormalisms for knowledge; Frauc tillt ideas for Conceptual programming, applying artificial intelligence to program writing.</abstract>
<title confidence="0.725783333333333">PHONETICS-PHONOLOGY: RECOGNITION Automatic Segmentation of Speech into Syllabic Units l&apos;aut Mernitisitin</title>
<author confidence="0.543655">Haskins tabolatones</author>
<author confidence="0.543655">New Haven</author>
<author confidence="0.543655">Connecticut</author>
<abstract confidence="0.991329625">of th.t. Acoustic Society 4merico 1Q75 segmentation algorithm whether a loudness minimum is a s)llabic boundar.), using between the convex hull of the loudness function and the loudness function Itself. Tested on roughly 400 s)llables of continuous text. the algorithm results in 6.9% syllables missed and 2.6% extra syllables relative to a nominal, slow-speech syllabic count. algorithm proceed from left to right in time, but where real-time operation is essential it could be modified to operate left to right with hacktracking O■fet an interval no greater than 500 msec.</abstract>
<title confidence="0.869426">RECOGNITION Real Time Analysis of Voiced Sounds</title>
<author confidence="0.994184">J P long</author>
<affiliation confidence="0.760994">National Aeronautics and Space Admitristration, Pasadena, California</affiliation>
<address confidence="0.485929">Patent Appfiration NAS.4-C4SE-NPO 13465-1 NTIS: PAT-APPL-53I 575</address>
<abstract confidence="0.905452875">PC $3.25/A1P $2.25 A power spectrum analysis or the harmonic content of a voiced sound signal is conducted in real time by phase-lock-loop tracking of the fundamental frequency of the signal and suicessive harmonics 14 through lin of the fundamenatal frequency. The quadratuic power and 1&apos;N:twenty tracked differvntiating the power measurements of the in adjacent pairs and inuilyring e 1he differentials are used to determine peak power points in the pbwer spectrum for display or use in analysis of voiced sotind, such as for voice recognition.</abstract>
<title confidence="0.655259666666667">PHONETICS-PHONOLOGY: RECOGNITION Auditory Speech Features: The Sound of English as Processed by a Model of the Ear</title>
<author confidence="0.750717">John L Godfrey</author>
<affiliation confidence="0.99123">Ohio Research Institute, University of Dayton</affiliation>
<abstract confidence="0.801576157894737">Report September 1974 NTIS: 4D/A-002 604/7GA PC $3.15/ $2.25 model bowels by features closely resembling. spectral feirmants. Fine temporal dethil is prmrved, which is useful for s,ounds characterized by rapid changes in the signal. Duration. pitth and diphthongalintion are registered. The model %Turks well for the consonants studied, preserving fine tempqral detail. Some consonant features required special purpose circuitry. Also iiscussed are strategies. based on the phonetic composition .of some sounds. for writing integrated phonemic recognition algorithms: results of some preliminary tests are presented. RECOGNITION Analysis of Intonational Signals by Computer Simulation of Pitch-Periceptioo Tukefuta of Speech Commurticattom, Oh4o State rnivervriy, 4.110 Report TR-15, Fetortiory 1974; NrIS: 7761647 PC 33.25/MF $2.25 progszin is developed to can:Kt fund4mettali inteasit aped durailon. characteristics.. A. second program: writ:Aires melody dieves and vegotatis the% lotto units of intonation patterm A thud program Zinalysts owns identifies pitch otte.rns based upon 14114.Mif04% kelvins,.</abstract>
<title confidence="0.964659">PHONETICS-PHONOLOGY: RECOGNITION Automatic Verification of Hypothesized Phonemic Strings in Continuous Speech</title>
<author confidence="0.999895">R A Gillman</author>
<affiliation confidence="0.982947">Dcyclopment Corp-oration, Siva Aitmitv, %WOO</affiliation>
<address confidence="0.6353105">SDC-TM-5315/000/00, 10 May I 5; 4D-i`i&amp;quot;9/ / OGA PC $3.00/ MP $2.25</address>
<abstract confidence="0.975420555555556">A parser (wIth. 30 rewrite rules) predicts a. set of. possible words. including initial words from a vocabulary of 160 words.. A. .lexicon contains plkonernic spellings and appmirnate duration for each phoneme of a word. A mapping program is based on rive scgine:nt labels: silence... low-amplitude.. yoked or vowel-like: strong friliatiom Two phonemic locators (vowels and consona.nts) use the range boundaries given by the lexicon to search the atoustic string. Phonemes are proceed to a goodness score which is a. function of the phone:me% to the newest. fixed boundary and of the class of the phoneme.. In a trial of 20 utter-a:nom the program was able to identify the correct word in first place 89% of the time..</abstract>
<note confidence="0.609024">PHONETICS-PHONOLOGY: RECOGNITION 15</note>
<title confidence="0.978857">Acoustic Phonetic Research in Speech Understanding</title>
<author confidence="0.771022">Ricbard W Raker</author>
<author confidence="0.771022">Faust Pon Stanford Rovarch &apos;Institute</author>
<author confidence="0.771022">Menlo Park</author>
<author confidence="0.771022">California</author>
<abstract confidence="0.97357">IEEE,Iilransactioiks Aetiutiiks, Speech,. (Fj RIttal Processing 23:416-426. 1975 uses pragrnatic,--smantic, and. syntactic information to propose candidate at specific points in the acontiC &apos;dream whictt irm_accepted or rejected the acoustic verification is done in two stages, First, cach 10-ms segnitmt is classified as or ten cla hy diiiaI riltering. If ihe proposed word is consistent with of primitin classes,Athe corresponding point in the further analysis using linetir IffedIttivi) coding and other.diuit:il filters, Vie roulnof Ilti$ analysts used to segment the acekstie signal and. to NNW?&apos; Because this segmentation and aissification can be tailored for tali caused by coarticulation between adjacent sounds can be successfully solved</abstract>
<title confidence="0.895823">PHONETICS-PHONOLOGY: RECOGNITION Analysis and Recognition of Voiceless Fricative Consonants in Japanese</title>
<author confidence="0.979004">lima Fujisaki</author>
<author confidence="0.979004">Osamu Kunisaki</author>
<affiliation confidence="0.996325">Department of Electrical&apos; Engineering, Faculty of Engineering, University of Tavo, Japan Annual Bulletin, Research Institute of Logopedics and Phoniatrics, University of Tokyo,</affiliation>
<address confidence="0.931031">9:123-126, ;975</address>
<abstract confidence="0.808363">Based on an equivalent circuit representation of the production mechanism for the voiceless fricative consonants /s/ and /sh/ (in Japanese), a model is derived for their frequency spectra up to 5 ktii. Using 60 words of CV and CVC type containing these consonants, spectra were obtained and measured and found to agree with the model, suggesting the use of the model for automatic. recognition. RECOGNITION Automatic Recognition of Semivowels in Spoken words iroya</abstract>
<affiliation confidence="0.896571">Institute of Logopedics if d University of Tokyo</affiliation>
<author confidence="0.691133">Nohiro Noguchi</author>
<author confidence="0.691133">Takao Yatuakura</author>
<affiliation confidence="0.994239">Department of Electrical Engineering, University of Tokyo</affiliation>
<abstract confidence="0.8878614">Annual Bulletin: Research Institute of Logopedics and Phoniatrirs, University of roAyo, Q:119-122, 1975 stage of the recognition process the input sqmoittNi h Anal)sis-bytrajectories into intenals that possess a set formant fiequencies to the Japanese s\owels /a/, hi, /0, /o/, la!, /el, and /of can be unlquell rtwogntred at this stage, As the formant frequencies of the %ods Iii and t&apos;u/ .are to those of the selni\o‘sels imf, Ncciond is ,W,11101 ut4i,es uifotination duration and speech rate. A recognitton etrertment a total utterances of both meaningful and nonsense words and rate was achievea.</abstract>
<title confidence="0.580573333333333">PHONET1CS-P-4ONDLOGY: RECOGNITION Perception of Time-Varying Resonance Frequencies In Speech and Non- Speech Stimuli</title>
<author confidence="0.671602">Iiiroya Fujisaki</author>
<author confidence="0.671602">Sotaro Selsinioto</author>
<affiliation confidence="0.989584">Research Institute of Logopedics and Phoniatrics, University ofsrokyo Annual .Bulletin: Research Institute of Iogopedi_es and Phoniatrics, University of Toltvo,</affiliation>
<address confidence="0.921812">9:127-I36, 1975</address>
<abstract confidence="0.9966008">Based on the analysis of formant transitions in natural speech, sr nthctic .speech stimuli %ere generated with various values of magnitude. rate, and duration of formant transitions. Discrimination tests of dynamic and static Stimuli indicated the existence of perceptual extrapolation that tmderlies formant transitions. Results of discrimination tests on nonspeech stimuli with similar formant transitions suggested that the extrapolation was to a large extent auditory, and thus was not specific to perception. of speech stimuli. On the other hand, identification tests of dynamic and static speech stimuli clearly indicated the short-term context effect in perception of connected segments, which Aas quantified as the arnount of temporary shift in the threshold for phonemic judgment due to perception of the immediately preceding segment.</abstract>
<title confidence="0.819259">RECOGNITION Syllable Recognition Using an Adaptive Pattern Recognition Technique</title>
<author confidence="0.921924">R Ahmed All</author>
<affiliation confidence="0.29429">Aligarh Muslim Umversi ) India</affiliation>
<abstract confidence="0.932250444444444">of the Institution of Electronics and Telecommunications Engineers December 1973. of VC syllables spoken a single mare speaker, and VC, CV, CVC syllubles speakeg were converted into I40-dimensional and 144-dimensipnal quantind n3perns. W141 the comPhilents are optimally weighted before beigintimine4 th8 weighted stilt&apos; witserveA, the4asic of recognition. Al) index of correct recognition hasffhteen defiled _aild a rtilfrOf:Ifimillr at the coned&apos; &apos;weirhts of the individual components ha &apos;hen deterniming deice is proposed to weiDlas durig the learning phut of Atie machine.</abstract>
<title confidence="0.972315333333333">PHONETICS-PHONOLOGY: RECOGNITION Simulation of a Recognition System for Connected Speech Sounds Using Linguistic Information</title>
<author confidence="0.7427415">E Kawatinhi</author>
<author confidence="0.7427415">Kyushu Umrersity</author>
<author confidence="0.7427415">Japan Fukuoka</author>
<abstract confidence="0.950118777777778">and Communications in sound sequences which have been recognited on the of physical features are into a variety character sequences. The latter then transformed variety Of possible character sequences. The latter are then transformed into word sequences Which are then adjusted for sentence structure. This process eliminates sequences which do not satisfy the rules of syntax. In computer simulation of this system, the, input sound sequences were unclear weather forecasts (124 texts). Listening tests were conducted and it was found that for an input of about 60% correct sequences the output was improved to about 93%.</abstract>
<title confidence="0.7775395">RECOGNITION Talker Recognition by Statistical Features of Spooh Sounds</title>
<author confidence="0.681577">S haul</author>
<author confidence="0.681577">F ltakura</author>
<abstract confidence="0.995975454545455">and Communications i Opt? No. t1:62-71„ sounds of,, seviena words by time setioems and fundamental frequency. Talkit reognition Is ate id and include sevecal statistical measures suci. as averaged starvdatd dev correlation coefficients between prarneters. Several words for dectsksit. reference gunnies are obtained from four tutasurettlentS and four an average recognition te of 99.1% sobtained identifying from 9 and 99,2% for verifyin4 talker in 37 after 3 months from the last referertct sample. The long-term variatton of Nature parameters, which catritS recognition error, is considered and the results indicate quantitatively that, although the parameters are stable for sevetal days, variations become large ant rward.</abstract>
<title confidence="0.937714">PHONETICS-PHONOLOGY: RECOGNITION Speech&apos; Feature Extraction by a Modulated Fourier Function</title>
<author confidence="0.97787">N Miki</author>
<affiliation confidence="0.975373">Hokkaido University, Sapporo, Japan</affiliation>
<note confidence="0.523934666666667">Yoshimoto Electronics and Communications in Japan 57, No. 1;56-63, January 19,14. A method of estimating the speech spectrum envelope employs the Fourier transform of the</note>
<abstract confidence="0.9983385">impulse response h(r) of the filter obtained by solving Wiener&apos;s inverse filter problem. that if made sufficiently large the impulse response converges toward zero, the have considered expansion of terms of a system of damped oscillating orthogonal functions (a modulated Fourier system). 1his system permits representation of featutes with fewer terms than are needed with Fourier transforms, and feature patterns having ploes can be obtained in the same manner as formants. Effectiveness of the proposed method is considered with respect to implementation on equipment which can use parallel processing in extraction.</abstract>
<title confidence="0.701058">RECOWTION Discrimination of Vowels by Use of the Static Features of the Local Peaks in</title>
<author confidence="0.673917">Flogiutency Spectra</author>
<affiliation confidence="0.745266666666667">and T. Sendai, Japan Woof ei the Research Institute of Electrical Communication,</affiliation>
<address confidence="0.782278">Tohoku ritivers1tr26:/-24,1974</address>
<abstract confidence="0.984006">The speech sanVles are frequency-analyzed by a filter bank composed of 29 single peak of Q*6* center frequencies of the filters are every 1/6 octave from 250 Hz to Hz. [he parameters Pl, P2, Pel, Pe2, and PO are induced from the six largest local peaks of the frequency spectrum obtained by the anaIes with the filter bank by .appl)ing the peak prpeessing rules. The vowels samples uttered , both in isolation and in continuation can betforined almost perfectly into the phonemic symbols. The rate of correct Wansformatiofo in words into plioneinit symbols is about tiU%. The speech,sznimilgs are 5 jtipapese vowels uttered by 31 male adol,ts and tAenty \vords uttered by 5 male adtilts.</abstract>
<title confidence="0.98666">PHONETICS-PHONOLOGY: RECOGNITION A Speech Processing System</title>
<author confidence="0.999974">S H Saib</author>
<affiliation confidence="0.997708">University of California, Los Angeles</affiliation>
<address confidence="0.445317">Thesis. University Microfilms, Ann Arbor, Michigan. No. 75-2239, PC 111.00/MF 45.00</address>
<abstract confidence="0.998351111111111">study was limited to English vowels spoken in sentences and concentrated on a for features which are speaker An abtomatic formant tracker was implemented to reduce the data rate from 10,000 to 1600. bytes per second and to provide an accurate frequencies and pitch frequency. The reduced formant and pitch data were then plotted versus time. Each speaker&apos;s characteristics were calculated by taking the sample average and sample variance of his formant frequencies. The normalized farnant frequencies were used as features in a recognition algorithm applied to the original vowel data and to an independent set of vowel data. Significantly lower error rates are achieved for 13 speakers&apos; vowels.</abstract>
<title confidence="0.937049333333333">RECOGNITION Aids Speech Recognition: VI, Timing Cues to Linguistic Structure and Improved Computer Programs for Prosodic Analysis</title>
<author confidence="0.962112">A Lea</author>
<author confidence="0.962112">R Dear</author>
<affiliation confidence="0.769898">UNIVAC, St. Atinnesota</affiliation>
<address confidence="0.468756">Report PX-11230, March 31, 1915 4P-,4010 :111(64</address>
<abstract confidence="0.85399525">PC $4.25/A1F $2.25 DeNctiptions of computer programs for detecting syntactic boundaries WOUND 3) alid stressed syllables (STRFS,S), F‘petiments \titre conaucted Nainotts Unn its, correlate with phonological and nLwtk hraN,e boundario. T-urther opera:molts are planned.</abstract>
<title confidence="0.923299333333333">PHONETICS-PHONOLOGY: RECOGNITION k-nearest-neighbor Decision Rule Performance in a- Speech Recognition System</title>
<author confidence="0.994743">M</author>
<author confidence="0.994743">P J Fong</author>
<address confidence="0.56005">Verox Corporation, Palo Alto, California</address>
<abstract confidence="0.791308">decision rules were tested on classification of vocal utterances, with 2 k 2 Accuracy was greater with 1.</abstract>
<title confidence="0.772891">RECOGNITION Digitgl Representation of Speech Signals</title>
<author confidence="0.434603">VA &apos;Schafer</author>
<note confidence="0.9673455">Bea naboratories, Murray Hill, N. f. Proceedings of the IEEE 63:662-677, April 1975</note>
<abstract confidence="0.92115275">Several digital signal processing methods for representing speech are presented and critically discussed: simple waveform coding methods, time domain techniques; frliquency domain representations; nonlinear or homorphic methods; and finally linear predictive coding techniques. 49 refs.</abstract>
<title confidence="0.974774">PHONETICS-PHONOLOGY: RECOGNITION: SEGMENTATION A General Language-Operated Decision Implementation System (GLOD1$): Its Application to Continuous-Speech Segmentation</title>
<author confidence="0.995496">IL F Silverman</author>
<affiliation confidence="0.883609">IBM Thomas I, Watson Research (&amp;quot;ewe YorAtown Heights, New</affiliation>
<address confidence="0.488067">Report 5368 (19741</address>
<abstract confidence="0.904709090909091">The general language-oriented decision implementation system (GLODIS) represents a flexible, operating-system approach to the generation and implementation of complex rules for decision making in pattern recognition. GLOMS is currently implemented as a phonemiclevel seginenter for continuous speech. The segrnenter is presented in stifficient detail for duplication by others, not only for speech segmentation but also for alternate applications. Performance data are given for a large amount (8 1/2 minutes) of continuous speech. Recent results from a total continuous speech recognition system, which incorporates the above, are also given. SYNTHESIS Automatic Phonemization in Practice Goratt Fngstrom tiroup for I linguistics The systetn which cited&amp; trade mark worth tor the Swedish ht t orrim orthopaphic input. mnstructs poqible syllable representations, matches input syIWks wkh already stored in the and not th 4nputword is any word currently beinit usett as a.tratkfulark vt.orti.‘ torkonant thrpters art to possible sOlable dtvisions. &amp;quot;Each tttibk is phonerniat IivididIy when the price SS complete., the phonemic representations Mach are syntheslied into pouitIle ji the input sivotti (intliicatictig rangt ti ptonunciations the wool is likely to be Oven) the matchint pnxtvt, not this pper, it un.</abstract>
<title confidence="0.968907">WRITING: RECOGNITION Computer Recognition of Handwritten Numerals by Polygonal Approximations</title>
<author confidence="0.989257">Farhat All</author>
<affiliation confidence="0.6765885">Science atory, Department of Ensineeriag, Princeton (fincersityi Princeton, New Jersey</affiliation>
<abstract confidence="0.808248">Transactions on Systems, Man, and The outlines of handwritten numerals are approximated by polygons enabling a simple of many features for numerals, for example, relative position and &apos;opt of concare arcs. The method was tested on the Munson data (IEEE Data. Base 1.2.2), and an ov.erall error rate of 9.4 percent was achieved without any statistical optimization. A characteristic property of this approach i3 the existence of two steps: the fiNt step (primitive feature generation) is primarily numerh:al, and the second step (feature selection and classification) makes extensive use of semantics.. 2 3 Approach the Modeling and Analysis of Proposed for HuMarrPerception of Capital Letters CSistk OtWs141</abstract>
<note confidence="0.93242825">Operations Ittearritj&apos;togra Department of industrial Engineering, ,State University of New Vork, limffaiolTi14 itidastri 1 Fng1erIng, Northestern University, Boston, Atassaehysetts Coinputers and Operations Restotarch 2:61-70, 1975</note>
<abstract confidence="0.832705666666667">Matkov chain feature traigitlon model of capital recognition is ptcsented empirically derived by capital letter I Townsend) trentation proonines features in diode) are used as the vtettir In an optimlintiutt problem4 the obtectivt being to raininilie *the stun tif per cell dereliction between the empLrleal conrualon the synthesited matrix Three reature are used in *v•ith the model to three 4!mpirica1 Variants or ate considered-and mutts tabulated analyzed WRITING. RECOGNITION Feature Extraction Character Recognition (in German) awl J. Schumann AEG relefankett, Oettuany Witteaschajiliche Berichie AEG-Telefanken 47:100-110, 1974 system a of original measurements into a number features before classifying tberri. pruicipal component apptoach is used axis is interpreted as translation and rotation the space. Feature extraction is ac‘omplished by truncating the transformed coordinate system. This approach is compared with the alternative of directly truncating the orrginal coordinate system</abstract>
<title confidence="0.9633755">WRITING: RECOONMON A Linguistic Pattern Recognition System</title>
<author confidence="0.779341">Cooley</author>
<affiliation confidence="0.886567">UnttvrAy of Utah, Solt vike City</affiliation>
<abstract confidence="0.929740666666667">Ann ‘4rhor, t an; . 3 It 1 1,00/ I rather than metric techniques are for p.ittern descriptitNn and chsmfication. aspe‘.&amp;quot;ts of system de.ign, encompassik both pie-prokessl:. categort/ation function haw been inrestqi.a-ted. The rewgni:er dittofrom those&apos; of linguistic ssstems in that it N trainable in same s,;:lse evict inatLh or parse of an input strik is caselfication Munson&apos;s numeric character data, ;arecv.,,,mition of as thc of the total hg 011SIdv:IC&apos;d</abstract>
<title confidence="0.941618">WRITING RECOGNITION Pattern Matching by Dynamic Prog ammin (In Japanese)</title>
<author confidence="0.985436">Y Isomithi</author>
<author confidence="0.985436">T Ogavia</author>
<affiliation confidence="0.886665">Institute Japan</affiliation>
<abstract confidence="0.965108333333333">I rtformation Processing Society I Jo 1,n 19.75 In order to recognize handwritten charactem a new tyN of pattern matching technique is used which depends, on t11e• hypothesis that patterns are a kind of elastic body Within, this h.ypothesis, distance between two patterns is defined as the in of sums of the elastic.. bodies and thee mismatching. quantities- Dynamic programming is used to accomplish the minimization. The patterns, are presented on.. 20 by 20 lattice points_ RECOGNMON Choice of an Algorithms for the Recognition of Handwritten Characters (in Russian) K. Vibar I Peredoeha Informatsil 4216-21, 1914 consideration principle difficulties encountered in machine recognition of handwritten ttaracters, it is concluded that an algurithni employing image parameter normaluation would be best. A formal analysis shows that the use of regulai mirinalintion the recognition of characters with different angles the property, of a certain stability in the horilontal dimensions in line makes the use of a simple rule based on comparison area of an with a standard.</abstract>
<title confidence="0.948804">WRITING RECOGIITION On-line Character Recognition</title>
<author confidence="0.594411">C</author>
<affiliation confidence="0.824418">University of Illinois</affiliation>
<address confidence="0.274913">NrIS: PI1-235 875/2, August 1974</address>
<abstract confidence="0.7104609375">11175/Alr state-of-the-art in recognition characters. A new recognition is developed using a voltage gradient tabret for input clever software for essential feature extraction. A simulation program is included as an appendix. WEIMNG: RECOGNITION 26 Context in Word Recognition R1 F. Ithermit% and i, Go, Fisher of NTIS: 44D-7O 759/1, August fv74, J411/11C low charaut it can often lead to ptolnhtme kd vt techniques for integrating an indepciutent conte‘tual rostproces.sor WW1 &apos;A NNstvm, are el,ainineti. The Ctl) detects errors .and is the structure for directIng additional processing for error correctton. WRITING: RECOGNITION Character Reader /svrec /mc.</abstract>
<note confidence="0.705488333333333">PUttlf1 S January 1Q74. Coninlissioner of Patents, Washington, D. C. :0231 $0.50 An electro-optical character reader for handAritten chara4:ters.</note>
<title confidence="0.787424666666667">RECOGNITION Optical Charactel ecognition Recograton Equipment</title>
<abstract confidence="0.71247755">US. rttlerif 376491 Januar) 1974. Cinninissioner of Paten Washington, 0. C. 202314 $0.50 This. patent describes a system. for normaliting. signals produced by optically scanning different sites and fontsof chaiacters into a singlt format of signal for character retiognition, MUM. RECOGNITION Optical Character Recognition Recognition Equipment Mr. 15 January 1974. Ceiminissioner of Patents Washington, D. C. 20231. $0.50 characters, superimposed on a contrasting center bar, are identified scanning serticially aligned, laterally spaced paths to generate sigials dependent upon encountering character portions. RECOGNITION Character Recognition Hitachi ltd. U,S. Patent i$0J55.1. 9 .4pril (9144 CottitttiSxioner of Atiettis. Wohissiao, A C., 201.11, $0,50 Choracters are identified by pattern matching Nvith stantind characters.Ive system es particularly 6ititab1e for &apos;Chinese choral:1M.</abstract>
<title confidence="0.94946">WRITING: RECOGNITION: CHINESE A Method ot Resolving Handwritten .Chiinese Characters and Its Computer Simulation (In Japanese)</title>
<author confidence="0.939061">Sietuki</author>
<affiliation confidence="0.996721">apos;,fanfare Technology,</affiliation>
<address confidence="0.937536">Procr.ssing. 1974</address>
<abstract confidence="0.989744">circuit is Ahich is pcv.essed of two facunies of rL-tulving and contrastive The usefulness the circuit in recognition handuritten rhtnese characters is computer, simulation. A technique for converting the into a informition-processmg system by means of Fourier transformation for additive operators is explained.</abstract>
<title confidence="0.959608333333333">RECOGNITION: CHINESE Recognition of Chinese Characters by Means of Hierarchical Pattern Representation</title>
<author confidence="0.999407">Y Tezuka</author>
<affiliation confidence="0.998494">OsaAa University Japan</affiliation>
<pubnum confidence="0.928193">Technology Reports of the Osaka University, _Faculty of Engineering 24:603-615</pubnum>
<date confidence="0.998812">October 1914</date>
<abstract confidence="0.992284625">Four kinds of local patterns are enough to represent a Chinese character. The proposed consists of three kinds of sub-systems: front-end processor, B-pattern recognizer, and K-nattern Lecogniter, The front-end processor makes a thick character slender and extracts points (intersections and end points of strokes), he reLogniter&amp;quot; is able to pre-patterns at attention points and to extract the II-pattern, To kinds of were defined and utilired: the similarity measure showing a degree of similarity or subpatterns and the mulling measure showing a degree of possibility of a B-patterii, The Krecogniter decides a K-pattern a character) by using reeognized</abstract>
<title confidence="0.927438">WRITING: SYNTHESIS Computer-baed System for Chinese Character Generation</title>
<author confidence="0.549503">Ryohei Kagaya</author>
<note confidence="0.412317">Project on Computational AnalysiS, National 1nter-University Research Institute of Asian African, Languages Cultures, 4-51-21 Nishigahara, Kitaku, Tokyo, 114 Japan Yu Kobayashi Section of Communrcation Research, Tokyo Metropolitan Institute of Gerontology, japan Computational Analyses of Asian African Languages, 2:9-35, 1975</note>
<abstract confidence="0.95158532183908">111DP-9 program identifying strings into graphiv patterns. One part translates a unit representation into strokes; another treats spatial arrangement of constituent units; the third part displays the character. WRITING: CHARACTER SETS 19/5 $10.50 American National Standards institute, New YorA Charadter Set and Print Quality of Optical Character Recognition (OCR-A) 11.■ • V c) C a., 0 = emit s$ ....; •.... ..-.. s... rz 1... tr.: ....,, ..c •--- ,- .:.... :7; r•-• .... .......... to• VC ti ..... .-. -- „or . VI lit ofS 0•• ...0 .:.••. C •.,.., .-- — = —, .-- .... ...e &amp;quot;0 ...a t..... t.&amp;quot;.. .— 440 % 0 ow. tO .— 17.! ..&apos;. i&apos;l _ol... .0 ,,,,_ • — 0r ‘... 6... S,11 = g to l ...... ,.., ...= ›•6 CI. &apos;&apos;. In rl C ...0) 9., .— •-- CO Co c..; ::: = t73Ci- ,-- ....1..., -- C r.: to&apos;: ....6 ...::: ....-:: 0 IX ti oft, 0 •■••• I* r&amp;quot;.• .....„ ..... 6... .... ... v .... !M. CI • •■•• aMtir , .... I.. •■= rj C ....0 •C tj2) ..... ,_. .... &apos; = ,..... ..... t... ..v t-. ... C. .... .....</abstract>
<note confidence="0.832161842105263">I &amp;quot;J 75 11 1„)v. • C&amp;quot;0.0 14 &amp;quot;0 tv, C • .1&amp;quot;: ems. U./ Cal Art, ••&amp;quot;&amp;quot;: cr fLO 1—. 4.50 CL. U.; LEXICOGRAPHY-LEXICOLOGY 31</note>
<title confidence="0.818358">Suffix Removal and Word Conflation</title>
<abstract confidence="0.915766181818182">L. and Linguistic Computing Centre, Cambridge of the Association for Literary and Linguistic Computing 2, The system has a suffix removal program and a conflation program (which groups together worts with lexically equivalent stems), The first program is based on an approach which requires no dictionary of word stems and is specifically designed to precede the second program, LEX1COGRAPHY-LEXICOLOGY Rank distribution in text and speech Rangorye raspredeleniya tekste i yazyke Arapor, N, Mum, and Yu. A. Shrejder</abstract>
<address confidence="0.676653">Moscow, USSR</address>
<note confidence="0.504233428571429">Naguchno-Tekhnicheskaya Informatsiya, Seriya 2, 1975, No. 2, 3-7 Explication of Ziprs law. Directions in Artificial intelligence: Natural Language Processing editor of Sciences„ Mercer Strcei,, Repori No. NS0-7, 1975</note>
<title confidence="0.699522857142857">Symposium, Modeling Dictionary Data, by Robert Simmons and Robert Amster; Di,scovery Word:Classes in FidaN,. Naomi The OWL Concept Hierarchy, py William Martin&apos;. and Design of the 1,}iTaertving Structure for a Data Base Retrieval System, by Stanley Petrick; Discussion, See abstracts of contributions elsewhere on this fiche. LEXICOGRAPHY-LEXICOLOGY: STATISTICS English Lexical Collocations</title>
<author confidence="0.572702">S Jones</author>
<affiliation confidence="0.618821">London School of Economics</affiliation>
<author confidence="0.914341">J Men</author>
<author confidence="0.914341">Sinclair</author>
<abstract confidence="0.903415272727273">of ,England de Lexicologie 24:15-61, A study of two texts, a transcription of 135,000 words of spontaneous conversation and 12,000 words of written scientific text, suggest reasonable grounds for hypothesizing a lexical level of language organization independent from, hut interacting with, both syntax and semantics, Grammatical (functor words) collocations differ statistically from lexical (tontentives) collocations and are more likely to be position dependent while lexical&apos; collactions are position free. Association between lexical -items is subject to grammatical influence (e.g. adjectives are consistently preceded by adverbs) and while:the data suggest that grammatically free lexical sets exists, considerably more material will have to be analyzed for collocations in order to identify them.</abstract>
<title confidence="0.840594666666667">STATISTICS On the Meaning of Rank Distributions rongovykh raspredelenij</title>
<author confidence="0.996292">A Shrolder</author>
<affiliation confidence="0.750692">Moscow; USSR</affiliation>
<pubnum confidence="0.519657">Nauchno-Tekhniches4oya Informaisiya, Scrlya 2, 1975, No. 1,,9-20</pubnum>
<abstract confidence="0.9433678">Social organisms and rank distribution. Some examples. Attempt at probabilistic formali/ation. Another attempt. Alternative, to the i&apos;irthodox probabilistic approach. Some words about the aggregate situation with rank distribution. Again about Ow collective of N Approx»nate description rank distribution in a closed text. Zipt&apos;s law and the family of rank distributions. Ihe case of small text.</abstract>
<title confidence="0.844754">LEXICOGRAPHY-LEXICOLOGY: STATISTICS The Concept of Lexical Structure of Text IcksichrsAoi struktury</title>
<author confidence="0.896904">V</author>
<author confidence="0.896904">E N Efimova</author>
<address confidence="0.566259">Moscow, USSR</address>
<note confidence="0.7133794">Inforrnotslya, Scriya 2, 1975, No. 6, An explication of Ziprs law. LEXICOGRAPHY-LEXICOLOGY: STATISTICS: CLUSTERING 34 Computerized Discovery of Semantic Word Ctasses It Scientific &apos;PMI&apos;s String PrOfeet, New nth University&amp;quot; 251 Mercer Street 10012</note>
<abstract confidence="0.9518695">in LtottiteRe ettiteti 6 Report No. couuut of Mathemojte. trick i&amp; tO cluster words that. are similar in their their operator or nrgurneni Musters from 4&amp;entente&amp; of texts 6 , displayed. Eg,,, a class of motion verbs relate ion wortiu-to cell voords (Tim grammatical trees tor deep structures were made by human. analysts, pending earkhinent of the transformational con:4)041ml of the string parser.</abstract>
<title confidence="0.772441">LEXICOGFIAPHY-LEXICOLOGY: DICTIONARY Computer Recognition in English Word Senses</title>
<author confidence="0.962674">Kelley</author>
<affiliation confidence="0.424512">Electrical Engineering, Doke University, Durham, North Carolina</affiliation>
<note confidence="0.83562275">Social Relations, Har yard University, Cambridge, ittassachasets Linguistic Series, Vol. 13, EleleYier, New York,. N.Y. $17.50. Atedica, North-Holland, PO. Box 211 Amsterdam, Developed, from a large corpus of text representative of typical content analysis applications,</note>
<abstract confidence="0.9747505">contextual search rules associated with each the preprocessor dictionary (containing over 1000 &apos;entries) resolve text words into word senses, Large scale valitiaticn tests then prove that, relative to its specification of possible senses, the dietitanary correctly resolves lexical ambiguity more than 90% of the time.. This represents a major advancd&apos; in the power and accuracy of automated content analysis procedures. The &amp;quot;disambiguation dictionary&amp;quot; has already been incorporated into the &amp;quot;General Inquirer&amp;quot;.</abstract>
<title confidence="0.8881675">LEXICOLOGY: DICTIONARY Automated Language Analysis</title>
<author confidence="0.999133">Sally Yates Sedelow</author>
<affiliation confidence="0.995627">University of Kansas, Lawrence</affiliation>
<address confidence="0.50207">NTIS:AD/4-002 463/8(31</address>
<abstract confidence="0.6714208">The report includes; 1) A description of the editing of a computer-accessible version of Ropes &apos;International Thesaurus; 2) A discussion of mathematical aptproaches to the modelling of Thesauri, with Rogers ser‘ing as an example; 3) Graph Theory applications to the study of the structure of Ropes. LEXICOGRAPHY-LEXICOLOGY: DICTIONARY A Bilingual Lexicon of 1001 Words&apos; from 24 Chapters of the Revised Statutes of Canada - Un lexique Bilingue de •1001 mots extraits de 24 chapitres des statuts revises du Canada V. Bergeron, and D. Burke Faculte de Droll, Section de Droit Civil, Universite d&apos;Ottawa, Ontario, Canada Report English-French micro-dictionary with illustrative citations, produced from computer-stored bilingual texts. The JURIVOC system is conversational: the system finds parallel sentences in the two languages which contain a given term, and presents them via a CRT terminal to a linguist-monitor who selects from them and prunes the contexts by keyboard manipulation.</abstract>
<title confidence="0.8053155">DICTIONARY: PARADIGMS f■Aodeling Dictionary Data</title>
<author confidence="0.989718">Robert F Simmons</author>
<author confidence="0.989718">Robert A Amsler</author>
<abstract confidence="0.86154275">o) Computer Un rsu of in (Irishman, Report No, NS() ,10 lligence.. Natural ,,,,agr , 10;st:rule Pfrtil,!i *I. Forms and structures of definitions (of vrbs in Nerriam-Websiers diaionaties arc to eh:11Ni: models of C&apos;0111.i.1/41N, SOIS.0 hietarchical relations amonz. b.s., sense-meanini: presented as a accompanied h) time-ordered sets of assertions mariked for truth ra;ue Srstematk• e\metion. these types from dictionar) data is ,Thr:iied to !line research. GRAMMAR: MORPHOLOGY Synthesis of Russian Nominal Word-forms by Means of a Computer Kominn USSR hiiischsA •d, Seriya of an algorithm for the synthesis of Russian nominal word-forms the Nisis of the morphology model developed by Es&apos;kova.. Mel.chulk and Sannilkov (1M). The. programming language,. ASTRA, used to encode the algorithm is .described in brief.. &apos;Specimens of word-forms from BESM-6 computer printout are appended.. 1.)7 .11.</abstract>
<title confidence="0.8932695">PARSER A Best-First Parser</title>
<author confidence="0.440209">Paxton</author>
<note confidence="0.9550025">Artificial Intelligence Center nford Research Institute, Menlo Park, Calif IEEE Transactions on Acoustics, Speech, and Signal Processiv 23:426-432, 1975</note>
<abstract confidence="0.825238142857143">Parser a hest-first strategy in which alternative paths are and are suspended as long there is a higher priority alternative. There are 4 types of steps t parse: I) Swtactic-..-selection of particular •2) choice of a particular word from a particular class, 3) Word Verification proposed words are against acoustic data, and Cooperation cooperation among competing Priorities are al step along a ,path. The system extends the path with the hiehest i.&apos;itintilative priority (1000 times ttle product of step priorities to that point), Experimental results are given, GRAMMAR: PARSER Syntactic Analysis in R.E.L. Erfgfish Iknisz Dostert, Fredrick Thompson California ltivitute of Technology, Pasadena Methods in linguistics 8:5-38, REL(Rapidly Extensible Language) English has, been made more powerful with the addition of procedures for handling case (Fillmore) and pronouns. Thus verbs are analyzed as expressing, relations between nouns. Using a modified form Martin Kay parser, case labels become incorporated into the arc labels of the, parsing graph. Pronouns and quantifiers are variables which must remain an active part of analysis as long as they are free, with their meaning being determined at the point in analysis when they can be bound. A list of 411 free variables in a phrase and pointers to each occurrence of each variable is included in the arc labels io the parsing graph.</abstract>
<title confidence="0.881908">A System for Automatic Syntactic Analysis of Russian Texts</title>
<author confidence="0.840201">P G C A L Novoveclol</author>
<author confidence="0.840201">E tStegov</author>
<abstract confidence="0.535991142857143">USSR Nirstehno-retitnische.thyo Ittforttlif#30t. Seript 2, No. 3:30-35, 1915 No restrictions are impowt1 on the structure and the word stock of the texts being&apos; analyzed. is achieved by means of, a procedure ow 4\sigitittent or the features to the &apos;new&apos; words. In scientific or technical texts. the system provides for the of stxme S5% between words.. With simpler texts (abAtiacts). q)% of :ire correct.</abstract>
<title confidence="0.521205333333333">GRAMMAR: GENERATOR Generation of Engilsli Autoiarische Er:eugung englischer Saet:e</title>
<author confidence="0.292546">IL Pilch</author>
<author confidence="0.292546">D Clement</author>
<address confidence="0.742327">Alltert-Ludwrgs-Univ4rsodet, Freiburg, Germany Janua Linguarum, Series Practica, No. 110; Mouton, Thc Hague, (13</address>
<abstract confidence="0.9854282">A purely syntactic combinatory synthesizer of grammatically correct English sentences is on the hypothesis that the synthesis process is the inverse analysis process. The formalism is sufficiently general to describe otheD languages. A chapter deals with its limits f,e.g. sentence length and complexity), marginally acceptable utterances, rule collisions. 70 examples of output are reproduced.</abstract>
<title confidence="0.656826">Do Machines Understand More than They Did?</title>
<author confidence="0.876281">Yorick Wilks</author>
<affiliation confidence="0.990439">Artificial intelligence I aboratory, Stanford University</affiliation>
<address confidence="0.670808">Nature 252:275-278, 1974</address>
<abstract confidence="0.996190076923077">Transformational generative theory has three defects: 1) the generation of sentences is not a signif cant demonstration of human undefStanding, 2) the competence-performance distinction isolates linguistics from tests of system of rules, ;” it has little room for inferences, Winogrmils SHRPLU system is vulnerable to these criticisms: 1) the linguistic: system is conservative, 2) its semantics is tied to a simple referential world, and 1) and it is strongly deductive and logically closed. Current fashion is strongly linked. to Minsky&apos;s paradigm Charniak&apos;s demon theory is superficial in that his demons are in item-to-item correspondence with English sentences. (.&apos;onceptual Dependenc theo.ry (Seilani%) and Preference Semonlics (Wilks) proside a deeper view b), the reduction or concepts to primitives. Current points of contention: 1) do we make and retain massive forward inferences or only generate deep inferences when shallow ones fail, 2) do we decouple syntax and semantics or achieve the results of syntactic analysis by a sufficiently potful semantic analyzer?</abstract>
<title confidence="0.691629333333333">SEMANTIOS-OISCOURSE Semantic Approaches for Models of Automatic Analysis of Natural Languages APproches seinamiques&apos;pour les modeles d&apos;analyse automaiique de longues naiurelles</title>
<author confidence="0.833862">CIL NAM</author>
<author confidence="0.833862">rind J airwave</author>
<affiliation confidence="0.755646">Groupe (Etudes pour to Traduction ,Automatique, Instittut de Recherches en iWuthentatiques Unirersite Scientifique de Grenoble, B. P. No Si - 3$041 Grenoble</affiliation>
<address confidence="0.789192">Cedc.r, France</address>
<abstract confidence="0.782706666666667">Teview and systems for ssing from text to deep structure or representation of meaning. Levels of representation. Coding (string, tree graph), functions, algorithms. Criteria of power, simulation, complexity, adequacy. Systems: TITUS II,</abstract>
<note confidence="0.62795">CETA,GETA, Mefehuk, Simmons, Wilks, TLC, Winograd, Schank. 0</note>
<title confidence="0.623116">CompUtational Understanding: Analysis of entences and Context</title>
<author confidence="0.849076">Christopher Kevin Riesbeek</author>
<note confidence="0.476473">omptacr Screncr, S t &apos;Ord qrn4 to4305 Nos. NTIS &apos;,4-005 040 PC $7 50/ Mr $2.25</note>
<abstract confidence="0.996777375">construction of system for of IA rum) to„ts v4as l&apos;Andod rout 1) priniar,s goat of comprehension is alwars to fina as s,,Noil as (.thos such as tits.00VIM, the s)ntactie Airc perforn.Q‘l on vihen to deeisions alcaniwz, :2) An jitcmpt istno&amp; to unaers(and each \Nord as soon it is read: 3) (:omprehension means not old) anderstandine. NI, hat has Ni&apos;,47n hut also what is lilk,d) to 4) Ifie of a et I or the information nevessary for comprehending that SEMANT1CS-OISCOUSSE COMPREll tsISION</abstract>
<title confidence="0.740992">The SRI Speech Understanding System</title>
<note confidence="0.769495">F,. Arti &apos;ciat In(elligencr t Stanford Reset] insti IEEE Transactions On ,1coustics, Speech, and Sig</note>
<abstract confidence="0.9848972">the system, krlowledge from Various sources grammar and semantics, world model, and discourse data) is% coyrelinate.d a predict the sequence of words in an utter:ince, and word functions—programs that represent acougtic characteristics of a word—are used to test the predictions. Data on the s)stem&apos;s performance are presented and discussed.</abstract>
<title confidence="0.3751385">CO HEN$ION SAM--A Story Understander</title>
<author confidence="0.571455">Sebank</author>
<author confidence="0.571455">the &apos;Yale</author>
<affiliation confidence="0.938863">Department of Computer Science, le University, New Huven, Connecticut.</affiliation>
<date confidence="0.319815">ReTeurch Report 43 August 1915</date>
<abstract confidence="0.8618501">A script is a causally organi/ed conceptual structure representing actions performed in (el, eating in restaurant)„ SAM (Script Applier stories thar relyheavily on scripts. produce a short or a long paraphrase of the input story, a summary of the story, and it has a question answering program and a program to translate stories into Chinese. tach script is organited around a goal (such as IN( 1:ST for eating in a restaurant), sshich usually implies mutual obligations among in the script, and tABININtS of tracks MtDonalds, eating at an vcpensive CO which consist ot scenes consist SEMAI&apos;MCS-DiSCOURSE: COMPREHENSION Environment and System Jor Machine Understanding of Connected</abstract>
<affiliation confidence="0.995635">anford University</affiliation>
<address confidence="0.961496">littera ifirAigart, No, 74-27012</address>
<abstract confidence="0.81308425">PC $11.001,Vr $5.00 The HLARSAY system uses synrt tic, semantic, and contextual information, as well as the traditional domains of atotbtic-phonetic, phonological, and lexical in order to recognize, and understand utterhnem</abstract>
<title confidence="0.78931525">COMPREHENSION Computer Assisted Application System Mikehons Watsoes Rerrarch</title>
<abstract confidence="0.945320787878788">Repoti 5i$1 system is being developed to brifkle the tap pcvigunil Iota iristr in the c‘ploivs the chArlderamik-s by a naturol, latipta.ge diatovire with the stem Thc difitofix by N&apos;St tAPeeting, NO pr unum. ribli addreNses the problems of representation ;and tato:live invol&apos;irJ, COMPREliENSION Semantic and Argumentative Text Description: A Contribution to the Simulation of Speech Communication und argumemative Tode,skription: Ein lleftrag zur Simulation sprachlirber Kommtlitikarion Lenders fuer lommunikat tonsfor.chungund Phonetik, Helmut Ruske k&apos;&apos;&apos;erlag, Hamburg, 1975 ISBN 3-871M-199-1 Contents of computational-linguistic text description . • • text description as the simulation behavior; automatic text general characterirition of machine systems; linguistic text description and text comprehension; word meaning and argumentative text analysis--two ranges of linguistic text description 2 Methods of machine contentive text description Development of semantics in linguistic data processing; lexicographic oriented models; computer oriented models; roiesv of published methods Reflections on the meaning presentation of speech elements in linguistic description systems. 163 Theoretical preliminaries; praxis of meaning repreyentatrom problems of meaning coordination 4 Argumentative text analysis . part; practical proposal for an argumentative text analysis; dosing analysis Literature (241 entries). .... ............. ....</abstract>
<note confidence="0.895632571428571">SEMANT1CS-D1SCOUSSE: COMPREHENSION 44 Understanding Systems: Quarterly Progress Report No. 1 Nov 74 - 1 Feb 75 A. Woods, Richard M. Schvoarti, Kloistad, Craig C. &apos;Cook, and Jared J. Molt lilertinfit, and he., 50 Moulton Street, Ctunkititze, Atituaehusetts Report No. 3018, 1975; AD-444007 586/1CM AO&apos; $2.25</note>
<abstract confidence="0.9584454">Acoustic phonetics, lexical retrieval, verification, and nbturat-language syntax, semanties,, and pragthatics. Part 1: Brief survgy of progrtm in the tridividual components of the pro*. Part 2: 1A-bilk:A niites containing detailed spevifications of everiments performed, programs implemented, design studtes, and %here appropriate sunvorting data and aripendices.</abstract>
<title confidence="0.5995155">SEMANTICS-DISCOURSE: COMPREHENSION The Simple Simons: Three Pedagogical Examples of the Use of ENT 2212</title>
<author confidence="0.934946">Da rid B Benson</author>
<author confidence="0.934946">Thomas R West</author>
<pubnum confidence="0.969445">Computer Science Department, Washittston %Vale University, Pullman 99163 Report No. CS-74-015</pubnum>
<abstract confidence="0.984374428571429">Simple Simon 1 is a completely trivial extension to Ent 2210 illustrating the basic semantic and extension capabilities of Ent, Definition; illustration; reformulation us Simple Simon 1.5 with equal &amp;quot;understanding&amp;quot; of English. Simple Simon 2 uses subset and set membership fad lities and recursion .to demonstrate&apos; an elementary method of distinguishing &amp;quot;fact&amp;quot; from &amp;quot;possibility&amp;quot;. Simple Simon 3 illustrates a method of treating pronouns and anaphoric references; time is handled as a relation. Use of extension capabilities to define numerous semantic subroutines and to establish a good notation for association entry and retrieval.</abstract>
<title confidence="0.758364">COMPREHENSION Understanding Understanding Systems</title>
<author confidence="0.999799">David Ililahr</author>
<affiliation confidence="0.845479">arnegie-Mellon University Gregg, Knowledge and Cognition, Lawrence Erlbaum Associates, Inc.,</affiliation>
<address confidence="0.978554">2957-.100, 1974</address>
<abstract confidence="0.990801714285714">a discussion of MERLIN (Moore and Newell) and HEARSAY (Rectd), and Newell)-both papers are abstracted elsewhere on this fiche, Human learning of language and of knowledge in general Likes place in situations where complex error correction (from adults) is Both Merlin and Hearsay are silent on the issue source or knowledge. This raises the following issue: Can a system that &apos;has not self-constructed most c&apos;g its knowledgea cycle of mi and accOmmodation—erer manifest deep uliderstanding? Roth Merlin and Hearsay deal with sgeond-hand. preproeslssed knowledge.</abstract>
<title confidence="0.9243805">SEMANTICS-DISCOURSE: COMPREHENSION Knowledge and Its Representation in a Speech Understanding System</title>
<author confidence="0.613972">Reddy</author>
<author confidence="0.613972">Allen</author>
<affiliation confidence="0.9835965">Carnegie-Mellon University Editor, Knowledge and Cognition, Lawrence Erlbaum Associates, Inc.,</affiliation>
<address confidence="0.990142">25J-2$5, (974</address>
<abstract confidence="0.955333">in tbe microworld of voice-chess. Knowledge from acoustic, syntactic and semantic sources is used to generate hypotheses about the incoming speech signal, thereby restricting the search space. Given that a word such as &amp;quot;captures&amp;quot; or &amp;quot;takes&amp;quot; appears in the partial sentence hypothesis, this knqwledge can be used to restrict the search to the capture moses in that board posirion. The grammar is context free. The parser is a modified topdown parsec and uSes antiproductions (giving all contexts for every s)mbol appearing in the grammar) in parsing backwards and forwards. Phonemic description is used for mapping words in the 31 item lexicon onto segments of the incoming utterance. At the phonemic characteristies the rules for predicting missing and extra segments in relaxed speech, juncture rules and rules that distinguish between pairs of phonemes, are available to the system. Knowledge of allophonic variability and speaker variability are also A discussion of one example (&amp;quot;Bishop to Queen knight three&amp;quot;) is given, MEMORY</abstract>
<title confidence="0.99483">for Reptesenting Knowledge</title>
<author confidence="0.997702">Marvin Minsky</author>
<note confidence="0.62506">Artificial Intelligence Iltboratory, Atassachuletts Instimte of Tech:142km C4unô4ge O21J9 Re orf At-At...106, June 1974; NM: AD-A011 168/20A $2.25</note>
<abstract confidence="0.996841">theory coMbines classical-and concepts p holog.Unistk and AL trat situation one selects from memory a structure called `a frame: a remembered Adapted to fit reality by changing &amp;Mitt as netessary, and a data-strwt....re stereotyped situation. A.ttartled to cub: frame are several kinds ot information how to use the frame„ what one can expect to happen net and what to do if these expectations are not confirmed. The report discusses collections ot related frames that ate linked together into fmne systems..</abstract>
<title confidence="0.940941">SEMANTICS-DISCOURSE: MEMORY Planes and Nets: A</title>
<author confidence="0.996525">Greg W Scragg</author>
<note confidence="0.4051755">per gil Studi Semontici e Cogaitivi, Switzer&apos; Worklng Papers 19, 1975</note>
<abstract confidence="0.949247588235294">By incorporating the notion of frames into seniantte nets it becomes possible to establish a level of representation for a concept intermediate between the nodes adjacent to the concept and the entire net. Weak bi-difictional are formed between a node the in the key node. The plane is a franre?like unit Each concept node is the key word of some plane and each plane is exactly the same as the list of planes in which a node appears. As a node is activated so is its associated frame. A short first-in first-out list of active planes is established as a basis for context maintenance, resolution of word ambiguity. and other inferential processes. MEMORY Model of Symbolic Assimilation Mann NT1S: AD/4-004 331/5, April &apos;1974, 291p, 1 he assimilation problem concerns making kgowledge to make available information useful. Research conducted on this problem has resulted in a model of human short term memory an effect‘■e collection general methods for information science. The program manipulates knovdcdge and experience represented as labelled directed graph&apos; .</abstract>
<title confidence="0.891201666666667">SEMANTICS-DISCOURSE: MEMORY Conceptual Memory: A Theory and Computer Program for Processing the Meaning Content of Natural Language Utterances</title>
<author confidence="0.999997">C J Rieger</author>
<affiliation confidence="0.999788">Department of Computer Sciences, Stanford University</affiliation>
<address confidence="0.655749">Nos. ST4N-05-74-714, AIM-233, July AD/A-000 086/9, 412p</address>
<abstract confidence="0.90337065">PC 110.50/ME $2.25 Humans perform vast quantities of spontaneous, subconscious computation in order to understand even the simplest language uttecances. The computation is principally meaningbased, with syhtax and traditional semantics playing insignificant roles. This thesis supports this conjecture by synthesis of. a thecly and computer program which account for many asPects of language behavior in humans. It is a theory of language and memory. MEMORY $ A Brief&apos; on Case Fugene Charniak per sal Stwit Sernantici e (ognitiN, Switzerland Papers 22, Cases are the-few ways arguments can be related ,to a predicant_ blItnefits (mtanag be factored meaning of predicate: ang of case; determining: what arguments may appear in surface structure; ordering arguments) dryly app,Lar in Al; the reasons are notational problems, lack of semantic definitions of casm and • representations too far from SAjtrne. strurture4 Selection restrictions can be stated without cases so can implied but unstated arguments, In Al, the main benefit of case is lacilitAton of inferences; but often a change of notation gains the sante inferences without cast Case notation is popular bteatirse suits networks, whereas positional potation suits predicate formulas; but Ali systems the its theoretical .content.</abstract>
<title confidence="0.9723375">SEMANTICS-DISCOURSE: MEMORY A Structure for Actions</title>
<author confidence="0.999626">Greg W Suing</author>
<address confidence="0.338522">Istituto per gli Studi Semantic&apos; e Cognitivi, Castagnola, Switzerland</address>
<pubnum confidence="0.612273">Working Paper 20, 1915</pubnum>
<abstract confidence="0.97607075">Knowledge of actions is used in Al s)stems for performance, plai‘ning, qUestion understanding, cause-and-effect representation,. and beliefs. KOP Aknowledge of Procedure) are intended to mychologically reasonable and a suitable basis for all these blending easily with static representations for world. KOP nets contain three types of events: GOAL, ROTE, and WAIT. They are tied together in a structure containing time orderings. reasons., major steps, results, methods. and static information. Both task and motive-directed processors. are emisaged to account for the between actions in English with different adverbs,.</abstract>
<title confidence="0.7763505">MEMORY The OWL Concept Hierarchy</title>
<author confidence="0.984321">William Martin</author>
<note confidence="0.839686">Matsachusetts Institute of Technology, Cambridge 02H9 Directions in Artificial Intelligence: Natural Language Processing, edited by Ralph Grishman. Report No. NSO-7, Courant Institute of Mathematical Sciences, 1975, pp. 49-59.</note>
<title confidence="0.454536">The right representation is important in eliminating complexity so that very large programs</title>
<abstract confidence="0.993764333333333">can be made. &apos;The representation communicates the way a field is organiyed... Multiple representations are needed for differant processes, pedlar atirr levels, even jt No one set of primitives provides a decent way to think about the world, more important than logic, deduction, or procedure execution: long chains or reasoning tail in Al, but finding that a problem belongs to a class with known solution opt suctiteds. 1 he whole problem of getting knouledge into a canonical repreqmation will be done by,&amp;quot;volunteeis&amp;quot; if a good form is proposed. OWL uses specification and semantic.cases: examples.</abstract>
<title confidence="0.9398585">SEMANTICS-DISCOURSE: TEXT GRAMMAR Sublanguage Grammar in Science Information Processing</title>
<author confidence="0.999776">Naomi Sager</author>
<affiliation confidence="0.983168">Linguistic String Project, New York University</affiliation>
<date confidence="0.372831">Journal of the American Society for Information Science 26:10-16, 1975</date>
<abstract confidence="0.994487222222222">The literature of a science subfield has characteristic restrictions on language usage which can be used to doctor, information formats for text sentences in the subfield. The text grammar the subfield of we have investigated has four levels: 1) Start at the bottom of the parses and collect nouns into classes on the basis of co-occurrence with verbs and verbs into classes on the basis of co-occurrence with nouns. At the bottom level a verb with and noun object is an elementary sentence. Elementary sentences may have operators on them and these operators yield 3 more levels. 2) Quantity words as operators 3) Sentence connecting verbs. 4) Verbs with human subjects which express the scientist&apos;s the events.</abstract>
<email confidence="0.34303">EXPRESStON</email>
<title confidence="0.907911">A Program for G.en.erating Repots on the Status and History of Stochastically Modifiable Semantic Models of Arbitrary Universes</title>
<author confidence="0.934048">Niktirloalle</author>
<author confidence="0.934048">A litsoiler</author>
<affiliation confidence="0.847078">Sciences Department, Unirersity Atttat$044.!</affiliation>
<address confidence="0.76532">Methods Linguistics 8:64 91, (972</address>
<abstract confidence="0.978109888888889">A three levet model of language Which has an affinity to tatuhs Stratifitational mntar transformations are used .in. the is used to write: a story, Ihe input data of; 1) a list or participants (e-,g. party, Georges etc..), 2) a of relations (e.g. in, dislikos„ jealous., a statement ot classes MOMS, 4.) the attributes of the human participants (bald, Italian, sexy, etc.).`, 5) propositiOns (triples) about the human particifiants (George likes nightclub.. George is in computing, etc.).„ and 6) a set of probalistic rules for generating plOt epimles, such as inv;)ting people a party, kw etc. The first five lists define initial conditions and the list of rules opetattS conditions to Produce a list of episodes in the stoty,</abstract>
<title confidence="0.988296">A Study ofthe Paragraph Structure</title>
<author confidence="0.99978">Adam J Sumer</author>
<affiliation confidence="0.837877">Division, National Physical Laboratory, Teddington, En land</affiliation>
<abstract confidence="0.946443">Statistical Methods in Linguistics 1973:79-90 study of 45 and British scientific articles comprising 1532 paragraphs and 1453 sentences showed a mean of 4.87 sentences per paragraph with a standard deviation of 2.18. This lends weight to the assumption that the number of semantic units (assumed to be sentences) in a paragraph corresponds to the Miller-Yngve limit (7, plus or minus 2) of short term An algorithm for a into paragraphs consists of two runs. On the first the text is scanned for links (indicative of semantic relationships) by using short lists of appropriate words and phrases. The second scan searches fluctuating of repeated words. The algorithm was tested by macnine for some procedures with others being carefully hand simulated. The test was fairly, but not completely, successful.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>K Detering</author>
<author>IL Pilch</author>
<author>D Clement</author>
</authors>
<title>Automatic Generation of Engilsli Sentences Autoiarische Er:eugung englischer Saet:e</title>
<location>Freiburg, Germany</location>
<marker>Detering, Pilch, Clement, </marker>
<rawString>Automatic Generation of Engilsli Sentences Autoiarische Er:eugung englischer Saet:e K. Detering, IL Pilch, :and D. Clement Alltert-Ludwrgs-Univ4rsodet, Freiburg, Germany</rawString>
</citation>
<citation valid="false">
<authors>
<author>Thc Hague Mouton</author>
</authors>
<title>arnegie-Mellon University Ire</title>
<date></date>
<marker>Mouton, </marker>
<rawString>Janua Linguarum, Series Practica, No. 110; Mouton, Thc Hague, (13 arnegie-Mellon University Ire W. Gregg, Mijor, Knowledge and Cognition, Lawrence Erlbaum Associates, Inc., 2957-.100, 1974 &amp;quot;lhis is a discussion of MERLIN (Moore and Newell) and HEARSAY (Rectd), and Newell)--both papers are abstracted elsewhere on this fiche, Human learning of language and of knowledge in general Likes place in situations where complex error correction (from adults) is available,. Both Merlin and Hearsay are silent on the issue or the source or knowledge. This raises the following issue: Can a system that &apos;has not self-constructed most c&apos;g its knowledge-through a cycle of aNS1 mi latirni and accOmmodation—erer manifest deep uliderstanding? Roth Merlin and Hearsay deal with sgeond-hand. preproeslssed knowledge.</rawString>
</citation>
<citation valid="false">
<authors>
<author>SEMANTICS-DISCOURSE COMPREHENSION</author>
</authors>
<title>Knowledge and Its Representation in a Speech Understanding System</title>
<marker>COMPREHENSION, </marker>
<rawString>SEMANTICS-DISCOURSE: COMPREHENSION Knowledge and Its Representation in a Speech Understanding System</rawString>
</citation>
<citation valid="false">
<authors>
<author>Raj Reddy</author>
</authors>
<title>and Allen NCYICII Carnegie-Mellon University Lee if&apos;.</title>
<journal>Gregg, Editor, Knowledge and Cognition, Lawrence Erlbaum Associates, Inc.,</journal>
<volume>25</volume>
<pages>974</pages>
<marker>Reddy, </marker>
<rawString>Raj Reddy, and Allen NCYICII Carnegie-Mellon University Lee if&apos;. Gregg, Editor, Knowledge and Cognition, Lawrence Erlbaum Associates, Inc., 25J-2$5, (974</rawString>
</citation>
<citation valid="false">
<authors>
<author>Planes Frames</author>
<author>Nets A Synthesis Greg W Scragg W C</author>
</authors>
<title>Mann Cbrnegie-ittellon University NT1S: AD/4-004 331/5, April &apos;1974, 291p, P(&apos; $8.73/AIP 32.25&apos; 1 he assimilation problem concerns making kgowledge to make available information useful. Research conducted on this problem has resulted in a model of human short term memory and an effect‘■e collection or new general methods for information science. The program manipulates knovdcdge and experience represented as labelled directed graph&apos;</title>
<publisher></publisher>
<marker>Frames, C, </marker>
<rawString>Frames, Planes and Nets: A Synthesis Greg W. Scragg W. C. Mann Cbrnegie-ittellon University NT1S: AD/4-004 331/5, April &apos;1974, 291p, P(&apos; $8.73/AIP 32.25&apos; 1 he assimilation problem concerns making kgowledge to make available information useful. Research conducted on this problem has resulted in a model of human short term memory and an effect‘■e collection or new general methods for information science. The program manipulates knovdcdge and experience represented as labelled directed graph&apos; .</rawString>
</citation>
<citation valid="true">
<authors>
<author>SEMANTICS-DISCOURSE MEMORY</author>
</authors>
<title>Conceptual Memory: A Theory and Computer Program for Processing the Meaning Content of Natural Language Utterances</title>
<date></date>
<booktitle>074; NT1S: AD/A-000 086/9, 412p PC 110.50/ME</booktitle>
<tech>Report Nos. ST4N-05-74-714, AIM-233,</tech>
<pages>2--25</pages>
<institution>Rieger Department of Computer Sciences, Stanford University</institution>
<marker>MEMORY, </marker>
<rawString>SEMANTICS-DISCOURSE: MEMORY Conceptual Memory: A Theory and Computer Program for Processing the Meaning Content of Natural Language Utterances C. J. Rieger Department of Computer Sciences, Stanford University Report Nos. ST4N-05-74-714, AIM-233, July /074; NT1S: AD/A-000 086/9, 412p PC 110.50/ME $2.25</rawString>
</citation>
<citation valid="true">
<title>The OWL Concept Hierarchy William Martin Matsachusetts Institute of Technology, Cambridge 02H9 Directions in Artificial Intelligence: Natural Language Processing, edited by Ralph Grishman.</title>
<date>1975</date>
<tech>Report No. NSO-7,</tech>
<pages>49--59</pages>
<institution>Courant Institute of Mathematical Sciences,</institution>
<marker>1975</marker>
<rawString>The OWL Concept Hierarchy William Martin Matsachusetts Institute of Technology, Cambridge 02H9 Directions in Artificial Intelligence: Natural Language Processing, edited by Ralph Grishman. Report No. NSO-7, Courant Institute of Mathematical Sciences, 1975, pp. 49-59.</rawString>
</citation>
<citation valid="false">
<title>The right representation is important in eliminating complexity so that very large programs can be made. &apos;The representation communicates the way a field is organiyed... Multiple representations are needed for differant processes, pedlar atirr u...N.nt levels, even jt one IS</title>
<marker></marker>
<rawString>The right representation is important in eliminating complexity so that very large programs can be made. &apos;The representation communicates the way a field is organiyed... Multiple representations are needed for differant processes, pedlar atirr u...N.nt levels, even jt one IS</rawString>
</citation>
<citation valid="false">
<authors>
<author>canonkal</author>
</authors>
<title>No one set of primitives provides a decent way to think about the world, Pattern Makhing is more important than logic, deduction, or procedure execution: long chains or reasoning tail in Al, but finding that a problem belongs to a class with known solution opt suctiteds. 1 he whole problem of getting knouledge into a canonical repreqmation will be done by,&amp;quot;volunteeis&amp;quot; if a good form is proposed. OWL uses specification and semantic.cases: examples.</title>
<marker>canonkal, </marker>
<rawString>canonkal. No one set of primitives provides a decent way to think about the world, Pattern Makhing is more important than logic, deduction, or procedure execution: long chains or reasoning tail in Al, but finding that a problem belongs to a class with known solution opt suctiteds. 1 he whole problem of getting knouledge into a canonical repreqmation will be done by,&amp;quot;volunteeis&amp;quot; if a good form is proposed. OWL uses specification and semantic.cases: examples.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SEMANTICS-DISCOURSE TEXT</author>
</authors>
<title>GRAMMAR Sublanguage Grammar in Science Information Processing Naomi Sager Linguistic String Project,</title>
<date>1975</date>
<journal>Journal of the American Society for Information Science</journal>
<pages>26--10</pages>
<location>New York University</location>
<marker>TEXT, 1975</marker>
<rawString>SEMANTICS-DISCOURSE: TEXT GRAMMAR Sublanguage Grammar in Science Information Processing Naomi Sager Linguistic String Project, New York University Journal of the American Society for Information Science 26:10-16, 1975 A Program for G.en.erating Repots on the Status and History of Stochastically Modifiable Semantic Models of Arbitrary Universes</rawString>
</citation>
<citation valid="false">
<authors>
<author>Niktirloalle</author>
<author>A Robert</author>
</authors>
<booktitle>litsoiler Computer Sciences Department, Unirersity ufWi4COOtitt* Atttat$044.! Sit/HS/kW. Methods in Linguistics 8:64 91,</booktitle>
<pages>972</pages>
<marker>Niktirloalle, Robert, </marker>
<rawString>Sheldon Mein, John. 1). Oakley, David 3. Niktirloalle, and Robert A. litsoiler Computer Sciences Department, Unirersity ufWi4COOtitt* Atttat$044.! Sit/HS/kW. Methods in Linguistics 8:64 91, (972</rawString>
</citation>
<citation valid="false">
<title>A Study of- the Paragraph Structure Adam</title>
<institution>J. Sumer Computer Science, Division, National Physical Laboratory,</institution>
<location>Teddington, En land</location>
<marker></marker>
<rawString>A Study of- the Paragraph Structure Adam J. Sumer Computer Science, Division, National Physical Laboratory, Teddington, En land</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>