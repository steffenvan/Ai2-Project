<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.051369">
<title confidence="0.998103">
Assisting Translators in Indirect Lexical Transfer
</title>
<author confidence="0.998318">
Bogdan Babych, Anthony Hartley, Serge Sharoff Olga Mudraya
</author>
<affiliation confidence="0.992158">
Centre for Translation Studies Department of Linguistics
University of Leeds, UK Lancaster University, UK
</affiliation>
<email confidence="0.996337">
{b.babych,a.hartley,s.sharoff}@leeds.ac.uk o.mudraya@lancs.ac.uk
</email>
<sectionHeader confidence="0.993843" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999483272727273">
We present the design and evaluation of a
translator’s amenuensis that uses compa-
rable corpora to propose and rank non-
literal solutions to the translation of expres-
sions from the general lexicon. Using dis-
tributional similarity and bilingual diction-
aries, the method outperforms established
techniques for extracting translation
equivalents from parallel corpora. The in-
terface to the system is available at:
http://corpus.leeds.ac.uk/assist/v05/
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999843767857143">
This paper describes a system designed to assist
humans in translating expressions that do not nec-
essarily have a literal or compositional equivalent
in the target language (TL). In the spirit of (Kay,
1997), it is intended as a translator&apos;s amenuensis
&amp;quot;under the tight control of a human translator ... to
help increase his productivity and not to supplant him&amp;quot;.
One area where human translators particularly
appreciate assistance is in the translation of expres-
sions from the general lexicon. Unlike equivalent
technical terms, which generally share the same
part-of-speech (POS) across languages and are in
the ideal case univocal, the contextually appropri-
ate equivalents of general language expressions are
often indirect and open to variation. While the
transfer module in RBMT may acceptably under-
generate through a many-to-one mapping between
source and target expressions, human translators,
even in non-literary fields, value legitimate varia-
tion. Thus the French expression il faillit échouer
(lit.: he faltered to fail) may be variously rendered
as he almost/nearly/all but failed; he was on the
verge/brink of failing/failure; failure loomed. All
of these translations are indirect in that they in-
volve lexical shifts or POS transformations.
Finding such translations is a hard task that can
benefit from automated assistance. &apos;Mining&apos; such
indirect equivalents is difficult, precisely because
of the structural mismatch, but also because of the
paucity of suitable aligned corpora. The approach
adopted here includes the use of comparable cor-
pora in source and target languages, which are
relatively easy to create. The challenge is to gener-
ate a list of usable solutions and to rank them such
that the best are at the top.
Thus the present system is unlike SMT (Och and
Ney, 2003), where lexical selection is effected by a
translation model based on aligned, parallel cor-
pora, but the novel techniques it has developed are
exploitable in the SMT paradigm. It also differs
from now traditional uses of comparable corpora
for detecting translation equivalents (Rapp, 1999)
or extracting terminology (Grefenstette, 2002),
which allows a one-to-one correspondence irre-
spective of the context. Our system addresses diffi-
culties in expressions in the general lexicon, whose
translation is context-dependent.
The structure of the paper is as follows. In Sec-
tion 2 we present the method we use for mining
translation equivalents. In Section 3 we present the
results of an objective evaluation of the quality of
suggestions produced by the system by comparing
our output against a parallel corpus. Finally, in
Section 4 we present a subjective evaluation focus-
ing on the integration of the system into the work-
flow of human translators.
</bodyText>
<sectionHeader confidence="0.996679" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.982882">
The software acts as a decision support system for
translators. It integrates different technologies for
</bodyText>
<page confidence="0.98159">
136
</page>
<note confidence="0.925499">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 136–143,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.9989146">
extracting indirect translation equivalents from
large comparable corpora. In the following subsec-
tions we give the user perspective on the system
and describe the methodology underlying each of
its sub-tasks.
</bodyText>
<subsectionHeader confidence="0.984529">
2.1 User perspective
</subsectionHeader>
<bodyText confidence="0.9999935">
Unlike traditional dictionaries, the system is a
dynamic translation resource in that it can success-
fully find translation equivalents for units which
have not been stored in advance, even for idiosyn-
cratic multiword expressions which almost cer-
tainly will not figure in a dictionary. While our
system can rectify gaps and omissions in static
lexicographical resources, its major advantage is
that it is able to cope with an open set of transla-
tion problems, searching for translation equivalents
in comparable corpora in runtime. This makes it
more than just an extended dictionary.
</bodyText>
<subsectionHeader confidence="0.765719">
Contextual descriptors
</subsectionHeader>
<bodyText confidence="0.959311054054054">
From the user perspective the system extracts indi-
rect translation equivalents as sets of contextual
descriptors – content words that are lexically cen-
tral in a given sentence, phrase or construction.
The choice of these descriptors may determine the
general syntactic perspective of the sentence and
the use of supporting lexical items. Many transla-
tion problems arise from the fact that the mapping
between such descriptors is not straightforward.
The system is designed to find possible indirect
mappings between sets of descriptors and to verify
the acceptability of the mapping into the TL. For
example, in the following Russian sentence, the
bolded contextual descriptors require indirect
translation into English.
Дети посещают nnoxo ompentoumupo-
eanubte школы, в которых xedocmaem
самого neo6xoduntozo
(Children attend badly repaired schools, in
which [it] is missing the most necessary)
Combining direct translation equivalents of
these words (e.g., translations found in the Oxford
Russian Dictionary – ORD) may produce a non-
natural English sentence, like the literal translation
given above. In such cases human translators usu-
ally apply structural and lexical transformations,
for instance changing the descriptors’ POS and/or
replacing them with near-synonyms which fit to-
gether in the context of a TL sentence (Munday,
2001: 57-58). Thus, a structural transformation of
плохо отремонтированные (badly repaired) may
give in poor repair while a lexical transformation
of недостает самого необходимого ([it] is missing
the most necessary) gives lacking basic essentials.
Our system models such transformations of the
descriptors and checks the consistency of the re-
sulting sets in the TL.
</bodyText>
<subsectionHeader confidence="0.889859">
Using the system
</subsectionHeader>
<bodyText confidence="0.976233452380952">
Human translators submit queries in the form of
one or more SL descriptors which in their opinion
may require indirect translation. When the transla-
tors use the system for translating into their native
language, the returned descriptors are usually suf-
ficient for them to produce a correct TL construc-
tion or phrase around them (even though the de-
scriptors do not always form a naturally sounding
expression). When the translators work into a non-
native language, they often find it useful to gener-
ate concordances for the returned descriptors to
verify their usage within TL constructions.
For example, for the sentence above translators
may submit two queries: плохо отремонт-
ированные (badly repaired) and недостает
необходимого (missing necessary). For the first
query the system returns a list of descriptor pairs
(with information on their frequency in the English
corpus) ranked by distributional proximity to the
original query, which we explain in Section 2.2. At
the top of the list come:
bad repair = 30 (11.005)
bad maintenance = 16 (5.301)
bad restoration = 2 (5.079)
poor repair = 60 (5.026)...
Underlined hyperlinks lead translators to actual
contexts in the English corpus, e.g., poor repair
generates a concordance containing a desirable TL
construction which is a structural transformation of
the SL query:
in such a poor state of repair
bridge in as poor a state of repair as the highways
building in poor repair.
dwellings are in poor repair;
Similarly, the result of the second query may
give the translators an idea about possible lexical
transformation:
missing need = 14 (5.035)
important missing = 8 (2.930)
missing vital = 8 (2.322)
lack necessary = 204 (1.982)...
essential lack = 86 (0.908)...
</bodyText>
<page confidence="0.996993">
137
</page>
<bodyText confidence="0.998651571428571">
The concordance for the last pair of descriptors
contains the phrase they lack the three essentials,
which illustrates the transformation. The resulting
translation may be the following:
Children attend schools that are in poor re-
pair and lacking basic essentials
Thus our system supports translators in making
decisions about indirect translation equivalents in a
number of ways: it suggests possible structural and
lexical transformations for contextual descriptors;
it verifies which translation variants co-occur in
the TL corpus; and it illustrates the use of the
transformed TL lexical descriptors in actual con-
texts.
</bodyText>
<subsectionHeader confidence="0.998604">
2.2 Generating translation equivalents
</subsectionHeader>
<bodyText confidence="0.999861717948718">
We have generalised the method used in our previ-
ous study (Sharoff et al., 2006) for extracting
equivalents for continuous multiword expressions
(MWEs). Essentially, the method expands the
search space for each word and its dictionary trans-
lations with entries from automatically computed
thesauri, and then checks which combinations are
possible in target corpora. These potential transla-
tion equivalents are then ranked by their similarity
to the original query and presented to the user. The
range of retrievable equivalents is now extended
from a relatively limited range of two-word con-
structions which mirror POS categories in SL and
TL to a much wider set of co-occurring lexical
content items, which may appear in a different or-
der, at some distance from each other, and belong
to different POS categories.
The method works best for expressions from the
general lexicon, which do not have established
equivalents, but not yet for terminology. It relies
on a high-quality bilingual dictionary (en-ru ~30k,
ru-en ~50K words, combining ORD and the core
part of Multitran) and large comparable corpora
(~200M En, ~70M Ru) of news texts.
For each of the SL query terms q the system
generates its dictionary translation Tr(q) and its
similarity class S(q) – a set of words with a similar
distribution in a monolingual corpus. Similarity is
measured as the cosine between collocation vec-
tors, whose dimensionality is reduced by SVD us-
ing the implementation by Rapp (2004). The de-
scriptor and each word in the similarity class are
then translated into the TL using ORD or the Mul-
titran dictionary, resulting in {Tr(q)v Tr(S(q))}.
On the TL side we also generate similarity classes,
but only for dictionary translations of query terms
Tr(q) (not for Tr(S(q)), which can make output too
noisy). We refer to the resulting set of TL words as
a translation class T.
</bodyText>
<equation confidence="0.98494">
T = {Tr(q) v Tr(S(q)) v S(Tr(q))}
</equation>
<bodyText confidence="0.999956">
Translation classes approximate lexical and
structural transformations which can potentially be
applied to each of the query terms. Automatically
computed similarity classes do not require re-
sources like WordNet, and they are much more
suitable for modelling translation transformations,
since they often contain a wider range of words of
different POS which share the same context, e.g.,
the similarity class of the word lack contains words
such as absence, insufficient, inadequate, lost,
shortage, failure, paucity, poor, weakness, inabil-
ity, need. This clearly goes beyond the range of
traditional thesauri.
For multiword queries, the system performs a
consistency check on possible combinations of
words from different translation classes. In particu-
lar, it computes the Cartesian product for pairs of
translation classes T1 and T2 to generate the set P
of word pairs, where each word (w1 and w2) comes
from a different translation class:
</bodyText>
<equation confidence="0.995771">
P = T1 x T2 = {(w1, w2)  |w1 E T1 and w2 E T2}
</equation>
<bodyText confidence="0.99997825">
Then the system checks whether each word pair
from the set P exists in the database D of discon-
tinuous content word bi-grams which actually co-
occur in the TL corpus:
</bodyText>
<equation confidence="0.978038">
P’ = P n D
</equation>
<bodyText confidence="0.999731153846154">
The database contains the set of all bi-grams that
occur in the corpus with a frequency ≥ 4 within a
window of 5 words (over 9M bigrams for each
language). The bi-grams in D and in P are sorted
alphabetically, so their order in the query is not
important.
Larger N-grams (N &gt; 2) in queries are split into
combinations of bi-grams, which we found to be
an optimal solution to the problem of the scarcity
of higher order N-grams in the corpus. Thus, for
the query gain significant importance the system
generates P’1(significant importance), P’2(gain impor-
tance), P’3(gain significant) and computes P’ as:
</bodyText>
<equation confidence="0.9977425">
P’ = {(w1,w2,w3) |(w1,w2) E P’1 &amp; (w1, w3) E P’2
&amp; (w2,w3) E P’3 },
</equation>
<bodyText confidence="0.998960333333333">
which allows the system to find an indirect equiva-
lent nonyuumb eecouoe 3xauexue (lit.: receive
weighty meaning).
</bodyText>
<page confidence="0.99257">
138
</page>
<bodyText confidence="0.999956538461538">
Even though P’ on average contains about 2% -
4% of the theoretically possible number of bi-
grams present in P, the returned number of poten-
tial translation equivalents may still be large and
contain much noise. Typically there are several
hundred elements in P’, of which only a few are
really useful for translation. To make the system
usable in practice, i.e., to get useful solutions to
appear close to the top (preferably on the first
screen of the output), we developed methods of
ranking and filtering the returned TL contextual
descriptor pairs, which we present in the following
sections.
</bodyText>
<subsectionHeader confidence="0.999039">
2.3 Hypothesis ranking
</subsectionHeader>
<bodyText confidence="0.999991111111111">
The system ranks the returned list of contextual
descriptors by their distributional proximity to the
original query, i.e. it uses scores cos(vq, vw) gener-
ated for words in similarity classes – the cosine of
the angle between the collocation vector for a word
and the collocation vector for the query or diction-
ary translation of the query. Thus, words whose
equivalents show similar usage in a comparable
corpus receive the highest scores. These scores are
computed for each individual word in the output,
so there are several ways to combine them to
weight words in translation classes and word com-
binations in the returned list of descriptors.
We established experimentally that the best way
to combine similarity scores is to multiply weights
W(T) computed for each word within its translation
class T. The weight W(P’(w1,w2)) for each pair of
contextual descriptors (w1, w2)�E P&apos; is computed as:
</bodyText>
<equation confidence="0.996462">
W(P’(w1,w2)) = W(T(w1)) × W` 1 (w2));
</equation>
<bodyText confidence="0.99951140625">
Computing W(T(w)), however, is not straightfor-
ward either, since some words in similarity classes
of different translation equivalents for the query
term may be the same, or different words from the
similarity class of the original query may have the
same translation. Therefore, a word w within a
translation class may have come by several routes
simultaneously, and may have done that several
times. For each word w in T there is a possibility
that it arrived in T either because it is in Tr(q) or
occurs n times in Tr(S(q)) or k times in S(Tr(q)).
We found that the number of occurrences n and
k of each word w in each subset gives valuable in-
formation for ranking translation candidates. In our
experiments we computed the weight W(T) as the
sum of similarity scores which w receives in each
of the subsets. We also discovered that ranking
improves if for each query term we compute in
addition a larger (and potentially noisy) space of
candidates that includes TL similarity classes of
translations of the SL similarity class S(Tr(S(q))).
These candidates do not appear in the system out-
put, but they play an important role in ranking the
displayed candidates. The improvement may be
due to the fact that this space is much larger, and
may better support relevant candidates since there
is a greater chance that appropriate indirect equiva-
lents are found several times within SL and TL
similarity classes. The best ranking results were
achieved when the original W(T) scores were mul-
tiplied by 2 and added to the scores for the newly
introduced similarity space S(Tr(S(q))):
</bodyText>
<equation confidence="0.9800234">
W(T(w))= 2×(1 if w∈Tr(q) )+
2×∑( cos(vq, vTr(w))  |{w  |w∈ Tr(S(q)) } ) +
2×∑( cos(vTr(q), vw)  |{w  |w∈ S(Tr(q)) } ) +
∑(cos(vq, vTr(w))×cos (vTr(q), vw) |
{w  |w∈ S(Tr(S(q))) } )
</equation>
<bodyText confidence="0.998511782608696">
For example, the system gives the following
ranking for the indirect translation equivalents of
the Russian phrase весомое значение (lit.: weighty
meaning) – figures in brackets represent W(P’)
scores for each pair of TL descriptors:
significant importance = 7 (3.610)
significant value = 128 (3.211)
measurable value = 6 (2.657)...
dramatic importance = 2 (2.028)
important significant = 70 (2.014)
convincing importance = 6 (1.843)
The Russian similarity class for весомый
(weighty, ponderous) contains: убедительный
(convincing) (0.469), значимый (significant)
(0.461), ощутимый (notable) (0.452) драма-
тичный (dramatic) (0.371). The equivalent of
significant is not at the top of the similarity class of
the Russian query, but it appears at the top of the
final ranking of pairs in P’, because this hypothesis
is supported by elements of the set formed by
S(Tr(S(q))); it appears in similarity classes for no-
table (0.353) and dramatic (0.315), which contrib-
uted these values to the W(T) score of significant:
</bodyText>
<equation confidence="0.885513666666667">
W(T(significant)) =
2 × (Tr(значимый)=significant (0.461))
+ (Tr(ощутимый)=notable (0.452)
</equation>
<bodyText confidence="0.9900982">
× S(notable)=significant (0.353))
+ (Tr(драматичный)=dramatic (0.371)
× S(dramatic)= significant (0.315))
The word dramatic itself is not usable as a
translation equivalent in this case, but its similarity
</bodyText>
<page confidence="0.995479">
139
</page>
<bodyText confidence="0.999836">
class contains the support for relevant candidates,
so it can be viewed as useful noise. On the other
hand, the word convincing does not receive such
support from the hypothesis space, even though its
Russian equivalent is ranked higher in the SL simi-
larity class.
</bodyText>
<subsectionHeader confidence="0.994446">
2.4 Semantic filtering
</subsectionHeader>
<bodyText confidence="0.999807">
Ranking of translation candidates can be further
improved when translators use an option to filter
the returned list by certain lexical criteria, e.g., to
display only those examples that contain a certain
lexical item, or to require one of the items to be a
dictionary translation of the query term. However,
lexical filtering is often too restrictive: in many
cases translators need to see a number of related
words from the same semantic field or subject do-
main, without knowing the lexical items in ad-
vance. In this section we present the semantic fil-
ter, which is based on Russian and English seman-
tic taggers which use the same semantic field tax-
onomy for both languages.
The semantic filter displays only those items
which have specified semantic field tags or tag
combinations; it can be applied to one or both
words in each translation hypothesis in P’. The
default setting for the semantic filter is the re-
quirement for both words in the resulting TL can-
didates to contain any of the semantic field tags
from a SL query term.
In the next section we present evaluation results
for this default setting (which is applied when the
user clicks the Semantic Filter button), but human
translators have further options – to filter by tags
of individual words, to use semantic classes from
SL or TL terms, etc.
For example, applying the default semantic filter
for the output of the query плохо отремон-
тированные (badly repaired) removes the high-
lighted items from the list:
</bodyText>
<listItem confidence="0.974151375">
1. bad repair = 30 (11.005)
[2. good repair = 154 (8.884) ]
3. bad rebuild = 6 (5.920)
[4. bad maintenance = 16 (5.301) ]
5. bad restoration = 2 (5.079)
6. poor repair = 60 (5.026)
[7. good rebuild = 38 (4.779) ]
8. bad construction = 14 (4.779)
</listItem>
<bodyText confidence="0.999893523809524">
Items 2 and 7 are generated by the system be-
cause good, well and bad are in the same similar-
ity cluster for many words (they often share the
same collocations). The semantic filter removes
examples with good and well on the grounds that
they do not have any of the tags which come from
the word плохо (badly): in particular, instead of
tag A5– (Evaluation: Negative) they have tag A5+
(Evaluation: Positive). Item 4 is removed on the
grounds that the words отремонтированный
(repaired) and maintenance do not have any tags
in common – they appear ontologically too far
apart from the point of view of the semantic tagger.
The core of the system’s multilingual semantic
tagging is a knowledge base in which single words
and MWEs are mapped to their potential semantic
field categories. Often a lexical item is mapped to
multiple semantic categories, reflecting its poten-
tial multiple senses. In such cases, the tags are ar-
ranged by the order of likelihood of meanings,
with the most prominent first.
</bodyText>
<sectionHeader confidence="0.997079" genericHeader="method">
3 Objective evaluation
</sectionHeader>
<bodyText confidence="0.999996777777778">
In the objective evaluation we tested the perform-
ance of our system on a selection of indirect trans-
lation problems, extracted from a parallel corpus
consisting mostly of articles from English and
Russian newspapers (118,497 words in the R-E
direction, 589,055 words in the E-R direction). It
has been aligned on the sentence level by JAPA
(Langlais et al., 1998), and further on the word
level by GIZA++ (Och and Ney, 2003).
</bodyText>
<subsectionHeader confidence="0.998512">
3.1 Comparative performance
</subsectionHeader>
<bodyText confidence="0.9999722">
The intuition behind the objective evaluation
experiment is that the capacity of our tool to find
indirect translation equivalents in comparable cor-
pora can be compared with the results of automatic
alignment of parallel texts used in translation mod-
els in SMT: one of the major advantages of the
SMT paradigm is its ability to reuse indirect
equivalents found in parallel corpora (equivalents
that may never come up in hand-crafted dictionar-
ies). Thus, automatically generated GIZA++ dic-
tionaries with word alignment contain many exam-
ples of indirect translation equivalents.
We use these dictionaries to simulate the genera-
tor of translation classes T, which we recombine to
construct their Cartesian product P, similarly to the
procedure we use to generate the output of our sys-
tem. However, the two approaches generate indi-
rect translation equivalence hypotheses on the ba-
sis of radically different material: the GIZA dic-
tionary uses evidence from parallel corpora of ex-
</bodyText>
<page confidence="0.993066">
140
</page>
<bodyText confidence="0.999857036363637">
isting human translations, while our system re-
combines translation candidates on the basis of
their distributional similarity in monolingual com-
parable corpora. Therefore we took GIZA as a
baseline.
Translation problems for the objective evalua-
tion experiment were manually extracted from two
parallel corpora: a section of about 10,000 words
of a corpus of English and Russian newspapers,
which we also used to train GIZA, and a section of
the same length from a corpus of interviews pub-
lished on the Euronews.net website.
We selected expressions which represented
cases of lexical transformations (as illustrated in
Section 0), containing at least two content words
both in the SL and TL. These expressions were
converted into pairs of contextual descriptors –
e.g., recent success, reflect success – and submit-
ted to the system and to the GIZA dictionary. We
compared the ability of our system and of GIZA to
find indirect translation equivalents which matched
the equivalents used by human translators. The
output from both systems was checked to see
whether it contained the contextual descriptors
used by human translators. We submitted 388 pairs
of descriptors extracted from the newspaper trans-
lation corpus and 174 pairs extracted from the Eu-
ronews interview corpus. Half of these pairs were
Russian, and the other half English.
We computed recall figures for 2-word combi-
nations of contextual descriptors and single de-
scriptors within those combinations. We also show
the recall of translation variants provided by the
ORD on this data set. For example, for the query
xedocmaem xeo6xo6uuo0o ([it] is missing neces-
sary [things]) human translators give the solution
lacking essentials; the lemmatised descriptors are
lack and essential. ORD returns direct translation
equivalents missing and necessary. The GIZA dic-
tionary in addition contains several translation
equivalents for the second term (with alignment
probabilities) including: necessary ~0.332, need
~0.226, essential ~0.023. Our system returns both
descriptors used in human translation as a pair –
lack essential (ranked 41 without filtering and 22
with the default semantic filter). Thus, for a 2-word
combination of the descriptors only the output of
our system matched the human solution, which we
counted as one hit for the system and no hits for
ORD or GIZA. For 1-word descriptors we counted
2 hits for our system (both words in the human
solution are matched), and 1 hit for GIZA – it
matches the word essential ~0.023 (which also il-
lustrates its ability to find indirect translation
equivalents).
</bodyText>
<table confidence="0.9993924">
2w descriptors 1w descriptors
news interv news interv
ORD 6.7% 4.6% 32.9% 29.3%
GIZA++ 13.9% 3.4% 35.6% 29.0%
Our system 21.9% 19.5% 55.8% 49.4%
</table>
<tableCaption confidence="0.999784">
Table 1 Conservative estimate of recall
</tableCaption>
<bodyText confidence="0.997776903225806">
It can be seen from Table 1 that for the newspa-
per corpus on which it was trained, GIZA covers a
wider set of indirect translation variants than ORD.
But our recall is even better both for 2-word and 1-
word descriptors.
However, note that GIZA’s ability to retrieve
from the newspaper corpus certain indirect transla-
tion equivalents may be due to the fact that it has
previously seen them frequently enough to gener-
ate a correct alignment and the corresponding dic-
tionary entry.
The Euronews interview corpus was not used for
training GIZA. It represents spoken language and
is expected to contain more ‘radical’ transforma-
tions. The small decline in ORD figures here can
be attributed to the fact that there is a difference in
genre between written and spoken texts and conse-
quently between transformation types in them.
However, the performance of GIZA drops radi-
cally on unseen text and becomes approximately
the same as the ORD.
This shows that indirect translation equivalents
in the parallel corpus used for training GIZA are
too sparse to be learnt one by one and successfully
applied to unseen data, since solutions which fit
one context do not necessarily suit others.
The performance of our system stays at about
the same level for this new type of text; the decline
in its performance is comparable to the decline in
ORD figures, and can again be explained by the
differences in genre.
</bodyText>
<subsectionHeader confidence="0.999938">
3.2 Evaluation of hypothesis ranking
</subsectionHeader>
<bodyText confidence="0.999505714285714">
As we mentioned, correct ranking of translation
candidates improves the usability of the system.
Again, the objective evaluation experiment gives
only a conservative estimate of ranking, because
there may be many more useful indirect solutions
further up the list in the output of the system which
are legitimate variants of the solutions found in the
</bodyText>
<page confidence="0.996609">
141
</page>
<bodyText confidence="0.999282666666667">
parallel corpus. Therefore, evaluation figures
should be interpreted in a comparative rather then
an absolute sense.
We use ranking by frequency as a baseline for
comparing the ranking described in Section 2.3 –
by distributional similarity between a candidate
and the original query.
Table 2 shows the average rank of human solu-
tions found in parallel corpora and the recall of
these solutions for the top 300 examples. Since
there are no substantial differences between the
figures for the newspaper texts and for the inter-
views, we report the results jointly for 556 transla-
tion problems in both selections (lower rank fig-
ures are better).
</bodyText>
<table confidence="0.998793222222222">
Recall Average rank
2-word descriptors
frequency (baseline) 16.7% rank--93.7
distributional similarity 19.5% rank--44.4
sim. + semantic filter 14.4% rank--26.7
1-word descriptors
frequency (baseline) 48.2% rank--42.7
distributional similarity 52.8% rank--21.6
sim. + semantic filter 44.1% rank--11.3
</table>
<tableCaption confidence="0.999083">
Table 2 Ranking: frequency, similarity and filter
</tableCaption>
<bodyText confidence="0.999224785714286">
It can be seen from the table that ranking by
similarity yields almost a twofold improvement for
the average rank figures compared to the baseline.
There is also a small improvement in recall, since
there are more relevant examples that appear
within the top 300 entries.
The semantic filter once again gives an almost
twofold improvement in ranking, since it removes
many noisy items. The average is now within the
top 30 items, which means that there is a high
chance that a translation solution will be displayed
on the first screen. The price for improved ranking
is decline in recall, since it may remove some rele-
vant lexical transformations if they appear to be
ontologically too far apart. But the decline is
smaller: about 26.2% for 2-word descriptors and
16.5% for 1-word descriptors. The semantic filter
is an optional tool, which can be used to great ef-
fect on noisy output: its improvement of ranking
outweighs the decline in recall.
Note that the distribution of ranks is not normal,
so in Figure 1 we present frequency polygons for
rank groups of 30 (which is the number of items
that fit on a single screen, i.e., the number of items
in the first group (r030) shows solutions that will
be displayed on the first screen). The majority of
solutions ranked by similarity appear high in the
list (in fact, on the first two or three screens).
</bodyText>
<figureCaption confidence="0.90664">
Figure 1 Frequency polygons for ranks
</figureCaption>
<sectionHeader confidence="0.989256" genericHeader="method">
4 Subjective evaluation
</sectionHeader>
<bodyText confidence="0.999839777777778">
The objective evaluation reported above uses a
single reference translation and is correspondingly
conservative in estimating the coverage of the sys-
tem. However, many expressions studied have
more than one fluent translation. For instance, in
poor repair is not the only equivalent for the Rus-
sian expression rwoxo ompemoxmupoeaxxbie. It is
also possible to translate it as unsatisfactory condi-
tion, bad state of repair, badly in need of repair,
and so on. The objective evaluation shows that the
system has been able to find the suggestion used
by a particular translator for the problem studied. It
does not tell us whether the system has found some
other translations suitable for the context. Such
legitimate translation variation implies that the per-
formance of a system should be studied on the ba-
sis of multiple reference translations, though typi-
cally just two reference translations are used (Pap-
ineni, et al, 2001). This might be enough for the
purposes of a fully automatic MT tool, but in the
context of a translator&apos;s amanuensis which deals
with expressions difficult for human translators, it
is reasonable to work with a larger range of ac-
ceptable target expressions.
With this in mind we evaluated the performance
of the tool with a panel of 12 professional transla-
tors. Problematic expressions were highlighted and
the translators were asked to find suitable sugges-
tions produced by the tool for these expressions
and rank their usability on a scale from 1 to 5 (not
acceptable to fully idiomatic, so 1 means that no
usable translation was found at all).
Sentences themselves were selected from prob-
lems discussed on professional translation forums
proz.com and forum.lingvo.ru. Given the range of
corpora used in the system (reference and newspa-
</bodyText>
<figure confidence="0.9930681">
60
50
40
30
20
70
10
0
similarity
frequency
</figure>
<page confidence="0.98824">
142
</page>
<bodyText confidence="0.999794578947368">
per corpora), the examples were filtered to address
expressions used in newspapers.
The goal of the subjective evaluation experiment
was to establish the usefulness of the system for
translators beyond the conservative estimate given
by the objective evaluation. The intuition behind
the experiment is that if there are several admissi-
ble translations for the SL contextual descriptors,
and system output matches any of these solutions,
then the system has generated something useful.
Therefore, we computed recall on sets of human
solutions rather than on individual solutions. We
matched 210 different human solutions to 36 trans-
lation problems. To compute more realistic recall
figures, we counted cases when the system output
matches any of the human solutions in the set.
Table 3 compares the conservative estimate of the
objective evaluation and the more realistic estimate
on a single data set.
</bodyText>
<table confidence="0.988228">
2w default 2w with sem filt
Conservative 32.4%; r=53.68 21.9%; r=34.67
Realistic 75.0%; r=7.48 61.1%; r=3.95
</table>
<tableCaption confidence="0.992132">
Table 3 Recall and rank for 2-word descriptors
</tableCaption>
<bodyText confidence="0.999840142857143">
Since the data set is different, the figures for the
conservative estimate are higher than those for the
objective evaluation data set. However, the table
shows the there is a gap between the conservative
estimate and the realistic coverage of the transla-
tion problems by the system, and that real coverage
of indirect translation equivalents is potentially
much higher.
Table 4 shows averages (and standard deviation
σ) of the usability scores divided in four groups: (1)
solutions that are found both by our system and the
ORD; (2) solutions found only by our system; (3)
solutions found only by ORD (4) solutions found
by
</bodyText>
<tableCaption confidence="0.86071">
Table 4 Human scores and σ for system output
</tableCaption>
<bodyText confidence="0.99744275">
It can be seen from the table that human users find
the system most useful for those problems where
the solution does not match any of the direct dic-
tionary equivalents, but is generated by the system.
</bodyText>
<sectionHeader confidence="0.999787" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999985736842105">
We have presented a method of finding indirect
translation equivalents in comparable corpora, and
integrated it into a system which assists translators
in indirect lexical transfer. The method outper-
forms established methods of extracting indirect
translation equivalents from parallel corpora.
We can interpret these results as an indication
that our method, rather than learning individual
indirect transformations, models the entire family
of transformations entailed by indirect lexical
transfer. In other words it learns a translation strat-
egy which is based on the distributional similarity
of words in a monolingual corpus, and applies this
strategy to novel, previously unseen examples.
The coverage of the tool and additional filtering
techniques make it useful for professional transla-
tors in automating the search for non-trivial, indi-
rect translation equivalents, especially equivalents
for multiword expressions.
</bodyText>
<sectionHeader confidence="0.999278" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996620233333333">
Gregory Grefenstette. 2002. Multilingual corpus-based
extraction and the very large lexicon. In: Lars Borin,
editor, Language and Computers, Parallel corpora,
parallel worlds, pages 137-149. Rodopi.
Martin Kay. 1997. The proper place of men and ma-
chines in language translation. Machine Translation,
12(1-2):3-23.
Philippe Langlais, Michel Simard, and Jean Véronis.
1998. Methods and practical issues in evaluating
alignment techniques. In Proc. Joint COLING-ACL-
98, pages 711-717.
Jeremy Munday. 2001. Introducing translation studies.
Theories and Applications. Routledge, New York.
Franz Josef Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19-51.
Papineni, K., Roukos, S., Ward, T., &amp; Zhu, W.-J.
(2001). Bleu: a method for automatic evaluation of
machine translation, RC22176 W0109-022: IBM.
Reinhard Rapp. 1999. Automatic identification of word
translations from unrelated English and German cor-
pora. In Procs. the 37th ACL, pages 395-398.
Reinhard Rapp. 2004. A freely available automatically
generated thesaurus of related words. In Procs. LREC
2004, pages 395-398, Lisbon.
Serge Sharoff, Bogdan Babych and Anthony Hartley
2006. Using Comparable Corpora to Solve Problems
Difficult for Human Translators. In: Proceedings of
the COLING/ACL 2006 Main Conference Poster
Sessions, pp. 739-746.
</reference>
<table confidence="0.696584666666667">
system (+) system (–)
ORD (+) 4.03 (0.42) 3.62 (0.89)
ORD (–) 4.25 (0.79) 3.15 (1.15)
</table>
<page confidence="0.991642">
143
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.639460">
<title confidence="0.999777">Assisting Translators in Indirect Lexical Transfer</title>
<author confidence="0.997137">Bogdan Babych</author>
<author confidence="0.997137">Anthony Hartley</author>
<author confidence="0.997137">Serge Sharoff Olga Mudraya</author>
<affiliation confidence="0.9975285">Centre for Translation Studies Department of Linguistics University of Leeds, UK Lancaster University, UK</affiliation>
<email confidence="0.943572">b.babych@leeds.ac.uko.mudraya@lancs.ac.uk</email>
<email confidence="0.943572">a.hartley@leeds.ac.uko.mudraya@lancs.ac.uk</email>
<email confidence="0.943572">s.sharoff@leeds.ac.uko.mudraya@lancs.ac.uk</email>
<abstract confidence="0.971860454545455">We present the design and evaluation of a amenuensis uses comparable corpora to propose and rank nonliteral solutions to the translation of expressions from the general lexicon. Using distributional similarity and bilingual dictionaries, the method outperforms established techniques for extracting translation equivalents from parallel corpora. The interface to the system is available at:</abstract>
<web confidence="0.934268">http://corpus.leeds.ac.uk/assist/v05/</web>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Multilingual corpus-based extraction and the very large lexicon.</title>
<date>2002</date>
<booktitle>Language and Computers, Parallel corpora, parallel worlds,</booktitle>
<pages>137--149</pages>
<editor>In: Lars Borin, editor,</editor>
<publisher>Rodopi.</publisher>
<contexts>
<context position="2884" citStr="Grefenstette, 2002" startWordPosition="423" endWordPosition="424">ted here includes the use of comparable corpora in source and target languages, which are relatively easy to create. The challenge is to generate a list of usable solutions and to rank them such that the best are at the top. Thus the present system is unlike SMT (Och and Ney, 2003), where lexical selection is effected by a translation model based on aligned, parallel corpora, but the novel techniques it has developed are exploitable in the SMT paradigm. It also differs from now traditional uses of comparable corpora for detecting translation equivalents (Rapp, 1999) or extracting terminology (Grefenstette, 2002), which allows a one-to-one correspondence irrespective of the context. Our system addresses difficulties in expressions in the general lexicon, whose translation is context-dependent. The structure of the paper is as follows. In Section 2 we present the method we use for mining translation equivalents. In Section 3 we present the results of an objective evaluation of the quality of suggestions produced by the system by comparing our output against a parallel corpus. Finally, in Section 4 we present a subjective evaluation focusing on the integration of the system into the workflow of human tr</context>
</contexts>
<marker>Grefenstette, 2002</marker>
<rawString>Gregory Grefenstette. 2002. Multilingual corpus-based extraction and the very large lexicon. In: Lars Borin, editor, Language and Computers, Parallel corpora, parallel worlds, pages 137-149. Rodopi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>The proper place of men and machines in language translation.</title>
<date>1997</date>
<journal>Machine Translation,</journal>
<pages>12--1</pages>
<contexts>
<context position="959" citStr="Kay, 1997" startWordPosition="127" endWordPosition="128">uensis that uses comparable corpora to propose and rank nonliteral solutions to the translation of expressions from the general lexicon. Using distributional similarity and bilingual dictionaries, the method outperforms established techniques for extracting translation equivalents from parallel corpora. The interface to the system is available at: http://corpus.leeds.ac.uk/assist/v05/ 1 Introduction This paper describes a system designed to assist humans in translating expressions that do not necessarily have a literal or compositional equivalent in the target language (TL). In the spirit of (Kay, 1997), it is intended as a translator&apos;s amenuensis &amp;quot;under the tight control of a human translator ... to help increase his productivity and not to supplant him&amp;quot;. One area where human translators particularly appreciate assistance is in the translation of expressions from the general lexicon. Unlike equivalent technical terms, which generally share the same part-of-speech (POS) across languages and are in the ideal case univocal, the contextually appropriate equivalents of general language expressions are often indirect and open to variation. While the transfer module in RBMT may acceptably undergen</context>
</contexts>
<marker>Kay, 1997</marker>
<rawString>Martin Kay. 1997. The proper place of men and machines in language translation. Machine Translation, 12(1-2):3-23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Langlais</author>
<author>Michel Simard</author>
<author>Jean Véronis</author>
</authors>
<title>Methods and practical issues in evaluating alignment techniques.</title>
<date>1998</date>
<booktitle>In Proc. Joint COLING-ACL98,</booktitle>
<pages>711--717</pages>
<contexts>
<context position="20628" citStr="Langlais et al., 1998" startWordPosition="3302" endWordPosition="3305">tic field categories. Often a lexical item is mapped to multiple semantic categories, reflecting its potential multiple senses. In such cases, the tags are arranged by the order of likelihood of meanings, with the most prominent first. 3 Objective evaluation In the objective evaluation we tested the performance of our system on a selection of indirect translation problems, extracted from a parallel corpus consisting mostly of articles from English and Russian newspapers (118,497 words in the R-E direction, 589,055 words in the E-R direction). It has been aligned on the sentence level by JAPA (Langlais et al., 1998), and further on the word level by GIZA++ (Och and Ney, 2003). 3.1 Comparative performance The intuition behind the objective evaluation experiment is that the capacity of our tool to find indirect translation equivalents in comparable corpora can be compared with the results of automatic alignment of parallel texts used in translation models in SMT: one of the major advantages of the SMT paradigm is its ability to reuse indirect equivalents found in parallel corpora (equivalents that may never come up in hand-crafted dictionaries). Thus, automatically generated GIZA++ dictionaries with word a</context>
</contexts>
<marker>Langlais, Simard, Véronis, 1998</marker>
<rawString>Philippe Langlais, Michel Simard, and Jean Véronis. 1998. Methods and practical issues in evaluating alignment techniques. In Proc. Joint COLING-ACL98, pages 711-717.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeremy Munday</author>
</authors>
<title>Introducing translation studies. Theories and Applications.</title>
<date>2001</date>
<publisher>Routledge,</publisher>
<location>New York.</location>
<contexts>
<context position="5979" citStr="Munday, 2001" startWordPosition="890" endWordPosition="891">и посещают nnoxo ompentoumupoeanubte школы, в которых xedocmaem самого neo6xoduntozo (Children attend badly repaired schools, in which [it] is missing the most necessary) Combining direct translation equivalents of these words (e.g., translations found in the Oxford Russian Dictionary – ORD) may produce a nonnatural English sentence, like the literal translation given above. In such cases human translators usually apply structural and lexical transformations, for instance changing the descriptors’ POS and/or replacing them with near-synonyms which fit together in the context of a TL sentence (Munday, 2001: 57-58). Thus, a structural transformation of плохо отремонтированные (badly repaired) may give in poor repair while a lexical transformation of недостает самого необходимого ([it] is missing the most necessary) gives lacking basic essentials. Our system models such transformations of the descriptors and checks the consistency of the resulting sets in the TL. Using the system Human translators submit queries in the form of one or more SL descriptors which in their opinion may require indirect translation. When the translators use the system for translating into their native language, the retu</context>
</contexts>
<marker>Munday, 2001</marker>
<rawString>Jeremy Munday. 2001. Introducing translation studies. Theories and Applications. Routledge, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="2547" citStr="Och and Ney, 2003" startWordPosition="372" endWordPosition="375">ions are indirect in that they involve lexical shifts or POS transformations. Finding such translations is a hard task that can benefit from automated assistance. &apos;Mining&apos; such indirect equivalents is difficult, precisely because of the structural mismatch, but also because of the paucity of suitable aligned corpora. The approach adopted here includes the use of comparable corpora in source and target languages, which are relatively easy to create. The challenge is to generate a list of usable solutions and to rank them such that the best are at the top. Thus the present system is unlike SMT (Och and Ney, 2003), where lexical selection is effected by a translation model based on aligned, parallel corpora, but the novel techniques it has developed are exploitable in the SMT paradigm. It also differs from now traditional uses of comparable corpora for detecting translation equivalents (Rapp, 1999) or extracting terminology (Grefenstette, 2002), which allows a one-to-one correspondence irrespective of the context. Our system addresses difficulties in expressions in the general lexicon, whose translation is context-dependent. The structure of the paper is as follows. In Section 2 we present the method w</context>
<context position="20689" citStr="Och and Ney, 2003" startWordPosition="3314" endWordPosition="3317">semantic categories, reflecting its potential multiple senses. In such cases, the tags are arranged by the order of likelihood of meanings, with the most prominent first. 3 Objective evaluation In the objective evaluation we tested the performance of our system on a selection of indirect translation problems, extracted from a parallel corpus consisting mostly of articles from English and Russian newspapers (118,497 words in the R-E direction, 589,055 words in the E-R direction). It has been aligned on the sentence level by JAPA (Langlais et al., 1998), and further on the word level by GIZA++ (Och and Ney, 2003). 3.1 Comparative performance The intuition behind the objective evaluation experiment is that the capacity of our tool to find indirect translation equivalents in comparable corpora can be compared with the results of automatic alignment of parallel texts used in translation models in SMT: one of the major advantages of the SMT paradigm is its ability to reuse indirect equivalents found in parallel corpora (equivalents that may never come up in hand-crafted dictionaries). Thus, automatically generated GIZA++ dictionaries with word alignment contain many examples of indirect translation equiva</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W-J Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation,</title>
<date>2001</date>
<pages>22176--0109</pages>
<publisher>IBM.</publisher>
<contexts>
<context position="29583" citStr="Papineni, et al, 2001" startWordPosition="4748" endWordPosition="4752">ession rwoxo ompemoxmupoeaxxbie. It is also possible to translate it as unsatisfactory condition, bad state of repair, badly in need of repair, and so on. The objective evaluation shows that the system has been able to find the suggestion used by a particular translator for the problem studied. It does not tell us whether the system has found some other translations suitable for the context. Such legitimate translation variation implies that the performance of a system should be studied on the basis of multiple reference translations, though typically just two reference translations are used (Papineni, et al, 2001). This might be enough for the purposes of a fully automatic MT tool, but in the context of a translator&apos;s amanuensis which deals with expressions difficult for human translators, it is reasonable to work with a larger range of acceptable target expressions. With this in mind we evaluated the performance of the tool with a panel of 12 professional translators. Problematic expressions were highlighted and the translators were asked to find suitable suggestions produced by the tool for these expressions and rank their usability on a scale from 1 to 5 (not acceptable to fully idiomatic, so 1 mean</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Papineni, K., Roukos, S., Ward, T., &amp; Zhu, W.-J. (2001). Bleu: a method for automatic evaluation of machine translation, RC22176 W0109-022: IBM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated English and German corpora.</title>
<date>1999</date>
<booktitle>In Procs. the 37th ACL,</booktitle>
<pages>395--398</pages>
<contexts>
<context position="2837" citStr="Rapp, 1999" startWordPosition="418" endWordPosition="419">able aligned corpora. The approach adopted here includes the use of comparable corpora in source and target languages, which are relatively easy to create. The challenge is to generate a list of usable solutions and to rank them such that the best are at the top. Thus the present system is unlike SMT (Och and Ney, 2003), where lexical selection is effected by a translation model based on aligned, parallel corpora, but the novel techniques it has developed are exploitable in the SMT paradigm. It also differs from now traditional uses of comparable corpora for detecting translation equivalents (Rapp, 1999) or extracting terminology (Grefenstette, 2002), which allows a one-to-one correspondence irrespective of the context. Our system addresses difficulties in expressions in the general lexicon, whose translation is context-dependent. The structure of the paper is as follows. In Section 2 we present the method we use for mining translation equivalents. In Section 3 we present the results of an objective evaluation of the quality of suggestions produced by the system by comparing our output against a parallel corpus. Finally, in Section 4 we present a subjective evaluation focusing on the integrat</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated English and German corpora. In Procs. the 37th ACL, pages 395-398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>A freely available automatically generated thesaurus of related words.</title>
<date>2004</date>
<booktitle>In Procs. LREC 2004,</booktitle>
<pages>395--398</pages>
<location>Lisbon.</location>
<contexts>
<context position="10220" citStr="Rapp (2004)" startWordPosition="1559" endWordPosition="1560"> general lexicon, which do not have established equivalents, but not yet for terminology. It relies on a high-quality bilingual dictionary (en-ru ~30k, ru-en ~50K words, combining ORD and the core part of Multitran) and large comparable corpora (~200M En, ~70M Ru) of news texts. For each of the SL query terms q the system generates its dictionary translation Tr(q) and its similarity class S(q) – a set of words with a similar distribution in a monolingual corpus. Similarity is measured as the cosine between collocation vectors, whose dimensionality is reduced by SVD using the implementation by Rapp (2004). The descriptor and each word in the similarity class are then translated into the TL using ORD or the Multitran dictionary, resulting in {Tr(q)v Tr(S(q))}. On the TL side we also generate similarity classes, but only for dictionary translations of query terms Tr(q) (not for Tr(S(q)), which can make output too noisy). We refer to the resulting set of TL words as a translation class T. T = {Tr(q) v Tr(S(q)) v S(Tr(q))} Translation classes approximate lexical and structural transformations which can potentially be applied to each of the query terms. Automatically computed similarity classes do </context>
</contexts>
<marker>Rapp, 2004</marker>
<rawString>Reinhard Rapp. 2004. A freely available automatically generated thesaurus of related words. In Procs. LREC 2004, pages 395-398, Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serge Sharoff</author>
<author>Bogdan Babych</author>
<author>Anthony Hartley</author>
</authors>
<title>Using Comparable Corpora to Solve Problems Difficult for Human Translators. In:</title>
<date>2006</date>
<booktitle>Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>739--746</pages>
<contexts>
<context position="8828" citStr="Sharoff et al., 2006" startWordPosition="1335" endWordPosition="1338"> transformation. The resulting translation may be the following: Children attend schools that are in poor repair and lacking basic essentials Thus our system supports translators in making decisions about indirect translation equivalents in a number of ways: it suggests possible structural and lexical transformations for contextual descriptors; it verifies which translation variants co-occur in the TL corpus; and it illustrates the use of the transformed TL lexical descriptors in actual contexts. 2.2 Generating translation equivalents We have generalised the method used in our previous study (Sharoff et al., 2006) for extracting equivalents for continuous multiword expressions (MWEs). Essentially, the method expands the search space for each word and its dictionary translations with entries from automatically computed thesauri, and then checks which combinations are possible in target corpora. These potential translation equivalents are then ranked by their similarity to the original query and presented to the user. The range of retrievable equivalents is now extended from a relatively limited range of two-word constructions which mirror POS categories in SL and TL to a much wider set of co-occurring l</context>
</contexts>
<marker>Sharoff, Babych, Hartley, 2006</marker>
<rawString>Serge Sharoff, Bogdan Babych and Anthony Hartley 2006. Using Comparable Corpora to Solve Problems Difficult for Human Translators. In: Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pp. 739-746.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>