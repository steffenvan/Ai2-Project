<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.989562">
“Hello Emily, how are you today?”
Personalised dialogue in a toy to engage children
</title>
<author confidence="0.992392">
Carole Adam Lawrence Cavedon Lin Padgham
</author>
<affiliation confidence="0.9377635">
RMIT University RMIT University RMIT University
Melbourne, Australia. Melbourne, Australia. Melbourne, Australia.
</affiliation>
<email confidence="0.995089">
carole.adam.rmit@gmail.com lawrence.cavedon@rmit.edu.au lin.padgham@rmit.edu.au
</email>
<sectionHeader confidence="0.99381" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999978769230769">
In line with the growing interest in conver-
sational agents as companions, we are de-
veloping a toy companion for children that
is capable of engaging interactions and of
developing a long-term relationship with
them, and is extensible so as to evolve with
them. In this paper, we investigate the im-
portance of personalising interaction both
for engagement and for long-term relation-
ship development. In particular, we pro-
pose a framework for representing, gath-
ering and using personal knowledge about
the child during dialogue interaction. 1
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942476190476">
In recent years there has been an increasing in-
terest in so-called Companion agents: agents that
are intelligent, and built to interact naturally (via
speech and other modalities) with their user over a
prolonged period of time, personalising the inter-
action to them and developing a relationship with
them. The EU Companions project2 is the most
well known such project, with applications such
as a companion for the elderly (Field et al., 2009),
and a health and fitness companion (Stahl et al.,
2009). In our work, together with industry part-
ners, we are developing a speech-enabled compan-
ion toy for children. While there are many “smart
toys” on the market, as far as we are aware our
work is unique in attempting to develop a “com-
panion toy” for a child, evolving with them over
a long period of time. As with other projects on
intelligent companions, a crucial task is to build a
long-term relationship with the user, by a series of
interactions over time, that the user experiences as
engaging and valuable.
</bodyText>
<footnote confidence="0.99323325">
1A slightly longer version of this paper is currently under
review elsewhere. If both papers are accepted for publication
we will modify to ensure that they expand different aspects.
2Seewww.companions-project.org.
</footnote>
<bodyText confidence="0.999729571428572">
According to models of the “enjoyability” of
human-computer interaction (Brandtzaeg et al.,
2006), there are three main features making an in-
teractive system engaging for the user: the user
should feel in control of the interaction (which
includes being able to customise it and getting
timely feedback); the demands on the user should
be adapted to their capabilities, i.e. the interaction
should be challenging and surprising but not over-
whelming; and the system should support social
interaction rather than isolating the user. Another
important aspect of any engaging interaction is for
it to be personalised, i.e. customised to the par-
ticular interlocutor and their environment. Other
important features for engagement include coher-
ence of the dialogue, emotional management, and
personality. In this paper we focus specifically on
the issue of appropriate personalisation of interac-
tions with a child, and how to realise this.
Existing personalised systems mainly have a
task-oriented focus, i.e. they aim at building a
user profile and using it to facilitate the user’s task
(e.g. Web navigation assistants or product recom-
mendation systems (Abbattista et al., 2003)), and
at being user-configurable. On the contrary we
aim at personalising the interaction to build a re-
lationship and engage a child. The main novelties
of our system are that: it is not task-oriented; it
is specifically designed for children; and its be-
haviour is derived from actual interaction data. In-
deed, in order to understand the kinds of person-
alisation occurring in natural dialogues with chil-
dren, we have analysed corpora of children’s dia-
logues (MacWhinney, 1995; MacWhinney, 2000).
We have then developed a framework that enables
the implementation of a number of these person-
alised behaviours within our intelligent toy.
The contribution of this paper is the identifi-
cation of different kinds of personalisation be-
haviours in dialogue with children, based on actual
data, plus the framework to realise these within
an implemented system.
</bodyText>
<page confidence="0.99306">
19
</page>
<note confidence="0.8326955">
Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 19–24,
Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.844462" genericHeader="method">
2 Personalisation behaviours
</sectionHeader>
<subsectionHeader confidence="0.999628">
2.1 Corpus analysis
</subsectionHeader>
<bodyText confidence="0.999971142857143">
We have analysed examples of children-adult di-
alogues (mainly from the CHILDES database
(MacWhinney, 1995; MacWhinney, 2000); one
dialogue from a forthcoming study performed
with a puppet as part of this project) in order to
determine the types of behaviours that adults use
to personalise their interaction with a child.
</bodyText>
<sectionHeader confidence="0.510265" genericHeader="method">
Relation to self
</sectionHeader>
<bodyText confidence="0.99402225">
A first observation is that children often try to re-
late conversation to themselves. This is illustrated
by this conversation between a girl (G) and her
mother (M) about a visit to the doctor.
</bodyText>
<construct confidence="0.502289833333333">
G What’s polio?
M An illness that makes you crippled. That’s why you get
all those injections and... A long time ago, kiddies, kid-
dies used to die with all that things.
G will I ?
M hmm. You aren’t going to die.
</construct>
<subsectionHeader confidence="0.793672">
Personal questions
</subsectionHeader>
<bodyText confidence="0.9988266">
Adults also often ask the child questions about
themselves. This dialogue illustrates a conversa-
tion between an adult (A) and a child (C) about C’s
holidays. Notice that the questions are adapted to
the context (ask about holidays in summer).
</bodyText>
<figure confidence="0.97788825">
A Did you go on vacation over the summer? Did you?
A Where’d you go? To the beach?
C Yes.
A Yeah? Did you go by yourself? No. Why laugh? You
could go by yourself.
A Do you have brothers and sisters?
C Just a little sister.
A A sister? Did she go too? On vacation?
</figure>
<subsectionHeader confidence="0.560786">
Child control
</subsectionHeader>
<bodyText confidence="0.999573428571429">
Even if the adult is asking the questions, the child
retains some control over the interaction. The fol-
lowing dialogue between a boy (B) and his grand-
mother (G) shows how the adult follows the child
when he switches away from a disliked topic. This
dialogue also shows the adult commenting on the
child’s tastes based on her knowledge of them.
</bodyText>
<figure confidence="0.991745">
G how are you getting on in school?
B we’re not going to go shopping today.
G eh?
B shopping today.
G ...
B and chips.
G going to have chips?
B mm.
G you likes that.
</figure>
<sectionHeader confidence="0.398172" genericHeader="method">
Reciprocity
</sectionHeader>
<bodyText confidence="0.988220857142857">
Another way for the adult to learn personal infor-
mation about the child without asking questions
is to confide personal information first, which en-
courages the child to reciprocate. In this dialogue
between a child (C) and a puppet (P) controlled
by an adult, P confides personal information (its
tastes), which leads the child to do the same.
</bodyText>
<construct confidence="0.4013792">
P My favourite drink is lemon. Lemon soft drink. I like
that.
C Mine is orange juice.
P mmhm. Orange one? You like the orange one?
C Orange juice (nodding)
</construct>
<subsectionHeader confidence="0.660088">
Recalling shared activities
</subsectionHeader>
<bodyText confidence="0.998723">
Another form of personalisation is recalling past
shared activities. In the following dialogue, a
mother (M) reads a book to her child (C); when
a picture of a snowman appears in the book she
recalls the child recently making one with her.
</bodyText>
<figure confidence="0.797855">
M what did we make outside here today?
C um I don’t know.
M did we make a man?
C yeah.
M a snowman?
C yeah.
Child’s preferences
</figure>
<bodyText confidence="0.9951172">
Another way to personalise interaction is to recall
a child’s preferences. For example this dialogue
involves a child (C) and an interrogator (I) wanting
to record a story. Here the child corrects incorrect
knowledge; this update should be remembered.
</bodyText>
<construct confidence="0.8599818">
I Do you wanna tell a story?
C No. I won’t.
I No, you don’t.
I You told me down there that you like stories.
C No, I hate stories.
</construct>
<subsectionHeader confidence="0.518253">
Child’s agenda
</subsectionHeader>
<bodyText confidence="0.999108">
Parents may also use knowledge about a child’s
agenda (i.e. planned future activities, school, etc.)
and make relevant and timely comments about it.
In this dialogue a mother (M) and her friend (F)
talk with a boy (B) about his next school day, when
he is supposed to see chicken eggs hatching.
</bodyText>
<figure confidence="0.930942090909091">
F Oh you’re going to see the little chicks tomorrow are
you. You’ll have to tell me what it’s like. I haven’t
never seen any.
B I I haven’t either.
F I haven’t.
M We’ve seen them on the tellie, haven’t we?
F I haven’t seen those little ones.
M haven’t you?
F So you’ll have to tell me.
M Have you seen them on the tellie?
B mm [= yes].
</figure>
<bodyText confidence="0.9996926">
We notice again that when the mother’s friend
confides some information (she never saw that),
the child reciprocates (he neither). Moreover the
mother again shows memory of past activities
(seeing something on television).
</bodyText>
<page confidence="0.962197">
20
</page>
<subsectionHeader confidence="0.998548">
2.2 Personalisation strategies
</subsectionHeader>
<bodyText confidence="0.999984142857143">
Based on our analysis of adult-children dialogue
corpora, we have designed a number of strategies
to allow our toy to generate these kinds of person-
alised interactions with the child. These strategies
fit into two categories: strategies for gathering
personal information, and strategies for exploiting
personal information.
</bodyText>
<subsectionHeader confidence="0.91147">
Information gathering
</subsectionHeader>
<bodyText confidence="0.99995405">
The Toy can gather and then use different types of
information: (1) personal information (e.g. fam-
ily, friends, pets); (2) preferences (e.g. favourite
movie, favourite food); (3) agenda (plays foot-
ball on Saturday, has maths every Thursday);
(4) activity-specific information (preferred stories,
current level of quiz difficulty); (5) interaction en-
vironment (e.g. time, day, season, weather).
The easiest strategy to gather this information
is to explicitly query the child. These queries have
to be made opportunistically, e.g. when matching
the current conversational topic, so as to seam-
lessly integrate information gathering into a con-
versation. Other strategies include confiding per-
sonal information to make the child reciprocate
and confide similar information; or extracting per-
sonal information from spontaneous child’s input.
These strategies are useful so as to avoid asking
too many questions, which would dirupt the con-
versation flow and could annoy the child.
</bodyText>
<subsectionHeader confidence="0.471536">
Information exploitation
</subsectionHeader>
<bodyText confidence="0.99991125">
One of the challenges for using the gathered per-
sonal information in a conversation is to deter-
mine the appropriate opportunities to do so. The
personal information can be used to engage the
child in various ways, reproducing the types of be-
haviours illustrated above. In particular, our toy
has the following information exploiting strate-
gies: (1) use child’s name; (2) insert comments
using personal information; (3) ask about daily ac-
tivities; (4) adapt interaction (e.g. greetings) to the
context (e.g. time of day); (5) take child’s prefer-
ences into account in topic or activity selection.
</bodyText>
<sectionHeader confidence="0.9881" genericHeader="method">
3 The Toy architecture: overview
</sectionHeader>
<bodyText confidence="0.968311">
This section outlines the general architecture of
the toy. The integration of our personalisation
framework is detailed in Section 4.
The central component of the Toy is the Dia-
logue Manager (DM) which is made up of two
components: the input/output manager (IOM) re-
ceives input from Automatic Speech Recognition
(ASR)3 and sends output to Text-to-Speech (TTS);
the Semantic Interaction Manager (SIM) receives
input from IOM, generates the toy’s response and
sends it back to IOM (see Figure 1).
</bodyText>
<figureCaption confidence="0.999765">
Figure 1: Architecture of the Toy
</figureCaption>
<bodyText confidence="0.999992916666667">
Our current approach to ASR and utterance pro-
cessing is grammar-based: on sending an out-
put utterance for synthesis, the DM loads into the
speech recogniser a parameterised grammar speci-
fying the set of expected user responses to this out-
put. The DM is multi-domain and extensible via
domain modules, designed to handle utterances
about a particular domain, and encapsulating data
required for this: a knowledge-base segment; a set
of conversational fragments (see Section 3.2.2); a
collection of the topics it is designed to handle;
and an entry grammar to assign a topic to inputs.
</bodyText>
<subsectionHeader confidence="0.982918">
3.1 Input Output Manager
</subsectionHeader>
<bodyText confidence="0.999897555555556">
The IOM is implemented using a BDI agent-
oriented methodology, with dialogue processing
“strategies” built as plans. For example, there are
plans designed to handle errors or low-confidence
results from speech recognition; plans to handle
utterance content and update the information state;
and plans to manage concurrent conversational
threads and select which of a number of candidate
responses to output.
</bodyText>
<subsectionHeader confidence="0.996043">
3.2 Semantic Interaction Manager
</subsectionHeader>
<bodyText confidence="0.999420833333333">
The Semantic Interaction Manager (SIM) is a
component designed to manage flexible conver-
sational flow. The SIM maintains an agenda of
things to say. When an input is received from
the IOM, it is pre-processed to generate an in-
put analysis that informs the further stages of the
</bodyText>
<footnote confidence="0.8131555">
3We have mainly used SRI’s Dynaspeak system which is
designed for small computational platforms.
</footnote>
<page confidence="0.998635">
21
</page>
<bodyText confidence="0.999764875">
SIM plan. In particular the input is then either
dispatched to an existing ongoing activity if it
matches its expected answers, or an appropriate
new activity is created. The chosen activity se-
lects a conversational fragment in the topic net-
work corresponding to its topic, and writes it in
the conversational agenda. Finally the output is
generated from the agenda and sent to the IOM.
</bodyText>
<subsectionHeader confidence="0.888439">
3.2.1 The conversational agenda
</subsectionHeader>
<bodyText confidence="0.999988555555555">
The conversational agenda maintained by the SIM
has two main parts. The history represents the past
interaction and stores past questions under discus-
sion (QUD) (Ginzburg, 1997) with their received
answer. The stack represents the future interac-
tion and lists QUD to be asked next, in order. The
agenda also stores the current ongoing activities
(Section 3.2.3), making it possible to switch back
and forth between them.
</bodyText>
<subsectionHeader confidence="0.709593">
3.2.2 Conversational fragments
</subsectionHeader>
<bodyText confidence="0.999979277777778">
In our system, we use pre-scripted pieces of dia-
logue that we call conversational fragments. The
designers of domain modules will provide a topic
network describing its domain, with nodes being
the possible topics, having links with other topics,
and providing a pool of fragments to possibly use
when talking about this topic. Each fragment has
an applicability condition, and provides the text of
an output as well as a list of expected answer pat-
terns with associated processing (e.g. giving feed-
back) applied when the child’s response matches.
This representation obviates the need for full
natural language generation (NLG) by provid-
ing semi-scripted outputs, and also informs the
grammar-based ASR by providing a list of ex-
pected child answers. Moreover it allows the Toy
to generate quite flexible interactions by switching
between topics and using fragments in any order.
</bodyText>
<subsectionHeader confidence="0.796444">
3.2.3 Activities
</subsectionHeader>
<bodyText confidence="0.999986764705882">
When interacting with the child, the Toy suggests
possible activities (e.g. quiz, story) about the avail-
able topics. Each type of activity uses specific
types of fragments (e.g. quiz questions with ex-
pected (in)correct answers; story steps with ex-
pected questions) and has particular success and
failure conditions (e.g. a number of (in)correct an-
swers for a quiz; or reaching the end for a story).
This concept of activity helps to keep the dia-
logue cohesive, while allowing flexibility. It also
meets the requirement that an engaging interaction
should be demanding for the child while staying
controlled by them. Indeed a number of activities
can be listed in the agenda at the same time, be-
ing resumed or paused to allow switching between
them (e.g. to follow the child’s topic requests or to
insert personalised contributions).
</bodyText>
<sectionHeader confidence="0.970822" genericHeader="method">
4 The toy personalisation framework
</sectionHeader>
<bodyText confidence="0.9999705">
We now describe our framework for implementing
the personalisation strategies specified earlier.
</bodyText>
<subsectionHeader confidence="0.994496">
4.1 The personalisation frame
</subsectionHeader>
<bodyText confidence="0.99640872">
All the information that our toy needs to person-
alise an interaction is gathered using a structure
called the personalisation frame. This structure is
tailored to the requirements imposed by our archi-
tecture, namely the grammar-based speech recog-
nition and the absence of natural language pro-
cessing. It consists of: (1) a static list of per-
sonal information fields (e.g. child name, age); (2)
a static indexed list of rules specifying when it is
appropriate to insert personal comments or ques-
tions in the interaction; (3) a dynamic child pro-
file, storing the current values of (some) personal
information fields, updated during interaction.
Personal information fields (PIFs)
Each personal information field contains: a list of
possible values for this field (informing the ASR
grammar); and a grammar of specific ways in
which the child may spontaneously provide infor-
mation relevant to this field (allowing the toy to
interpret such input and extract the value).
For example the field “favourite animal” has a
list of animals as its values, and its grammar con-
tains patterns such as “My favourite animal is X”
or “I love X” (where the variable X ranges over
the possible values of this field).
</bodyText>
<subsectionHeader confidence="0.795401">
Personalisation rules
</subsectionHeader>
<bodyText confidence="0.999824454545454">
Each personalisation rule specifies the opportunity
that triggers it, and the text of the output. The
text of personalisation comments and questions is
scripted, and used to automatically generate con-
versation fragments from the frame. Comment
rules also specify the list of personal information
fields that are used in the text of the comment,
while Question rules specify the name of the field
set by their answer and a grammar of expected an-
swers, with their interpretation in terms of which
value the corresponding field should receive.
</bodyText>
<page confidence="0.991336">
22
</page>
<bodyText confidence="0.999979666666667">
For example, there may be a comment rule re-
ferring to the field pet type, enabling the output
“I know you have a pet type” when the keyword
pet type is detected. There may also be a ques-
tion rule for asking “What is your favourite ani-
mal?” when talking about the zoo; expected an-
swers would include “I like A”; so if the child an-
swers “I like tigers” then the favourite animal
field would receive the value “tigers” as a result.
</bodyText>
<subsectionHeader confidence="0.786763">
Opportunities
</subsectionHeader>
<bodyText confidence="0.9995633">
Personalisation must be integrated into the con-
versational management so as not to disrupt dia-
logue (i.e. the toy should still maintain a coherent
interaction). It is thus important to accurately de-
tect appropriate opportunities to insert personali-
sation side-talk. There are three types of oppor-
tunities that can trigger the personalisation rules:
(1) keyword opportunities (a particular keyword
appears in the child’s input, e.g. the child uses the
word “mother”); (2) topic opportunities (the in-
teraction is focused on a particular topic, e.g. the
child is talking about koalas); (3) activity op-
portunities (a particular activity is in a particular
state, e.g. start of a story).
The following sections describe how this per-
sonalisation frame is used in the Conversation
Manager process to personalise the conversation
that is generated: we first outline the full process,
before giving details about the steps where the per-
sonalisation frame is used.
</bodyText>
<subsectionHeader confidence="0.974617">
4.2 Personalised input handling
</subsectionHeader>
<bodyText confidence="0.9999525">
The following algorithm is the result of the inte-
gration of personalisation into the response gen-
eration plan of the SIM. Steps manipulating the
personalisation frame will be detailed below.
</bodyText>
<listItem confidence="0.999595428571429">
1. Initialisation (load child profile,
update environment description);
2. Input reception (from IOM):
3. Input analysis (preprocess input,
detect opportunities);
4. Profile update;
5. Input dispatching (to selected
activity);
6. Activity progressing (fragment
selection);
7. Personalisation generation (generate
fragment from best applicable
triggered rule);
8. Agenda processing (prioritisation
of activity vs personalisation
fragments);
9. Personalisation of output (detection
of opportunities, modification of
output);
10. Output generation (sent to IOM);
11. End turn (save profile).
</listItem>
<subsectionHeader confidence="0.816292">
Fragment selection (step 6)
</subsectionHeader>
<bodyText confidence="0.993709888888889">
Fragment selection is personalised in two ways.
First, some fragments have applicability condi-
tions concerning the interaction context and the
child’s profile. For example a fragment such as
“Hi, what’s your name?” is only applicable if
the toy does not know the child’s name. A greet-
ing fragment such as “Hi! How was school to-
day?” is only applicable at the end of a school
day. Other greeting fragments are available for dif-
ferent contexts. Second, some fragments have an
adaptable content, using variables referring to the
child’s profile and to the context. These fragments
are only applicable if the value of these variables is
known and can be used to instantiate the variable
when generating output. For example a fragment
with the text “Hello child name! How are you?”
is applicable once the child’s name is known. Or
a fragment saying “I know you have a pet type
called pet name.” will be instantiated as “I know
you have a cat called Simba”.
Personalisation fragments generation (step 7)
When an opportunistic rule in the personalisation
frame is triggered, its applicability is checked:
comment rules are only applicable if the fields
used have a value; question rules are only appli-
cable if the field set has no value. Then the appli-
cable rule of highest priority is used to generate a
personalisation fragment. Its topic is the current
topic provided in the input analysis; its type is ei-
ther “personal question” or “personal comment”;
and its text is as specified in the rule. Comment
fragments have no additional applicability condi-
tion and no expected answers. Question fragments
receive the generic expected answers specified in
the rule, instantiated with the possible values of
the field set by this question; the process associ-
ated with them consists in setting the value of this
field to the value extracted from the input; the de-
fault process stores the full input as the value.
For example with the question rule “What is
your favourite animal?” shown above, the gener-
ated fragment will expect answers such as “I like
tigers”, “I like giraffes”, etc. If a matching an-
swer is received, then the corresponding animal is
stored as the child’s favourite one in their profile.
</bodyText>
<subsectionHeader confidence="0.579856">
Prioritisation (step 8)
</subsectionHeader>
<bodyText confidence="0.997377">
When updating the agenda, several situations can
arise depending on the relative priorities of person-
alising the interaction vs continuing the current ac-
</bodyText>
<page confidence="0.993009">
23
</page>
<bodyText confidence="0.999902444444444">
tivity. If the activity can be disrupted at this point,
personalisation question fragments can be added
on top of the stack in the agenda, while comments
can be appended to the activity output; if the per-
sonalisation fragment has too low priority to dis-
rupt the activity, then it is dropped. This priority
of personalisation depends in particular on the pri-
ority of the triggered rule and on the time since
personalisation was last inserted.
</bodyText>
<sectionHeader confidence="0.998865" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999537307692308">
This framework for personalisation has been im-
plemented in our toy using the Java-based agent
platform Gorite (Ronnquist, 2008). The following
is an example of the type of dialogues we intend
to generate with it (T is the Toy and C a child); it
illustrates a number of our personalisation strate-
gies. Our infrastructure technically allows it to
happen, however we still need to add more con-
tent (domain modules and fragments in them) to
make it actually happen; we are working on writ-
ing such content, as well as on providing tools to
make it easier for designers to write this content in
the future.
</bodyText>
<figure confidence="0.987777333333333">
C Hi there
T Hello Emily! [Use child’s name]
T What did you do on such a sunny week-end?
[Context-adaptation]
C I went to the zoo!
T Great! That must have been fun. Which animals did
you see?
C I saw tigers
T Tigers are cats, but much bigger than your cat Simba.
What else did you see?
C Koalas!
T Oh, that’s your favourite animal, isn’t it?
[Personal comment]
C Yes
T You must have been really happy. My favourite ani-
mal is orangutan, did you see any? [Confide
personal information]
C No
</figure>
<figureCaption confidence="0.573092666666667">
T Pity... Allright, enough chatting. I know you love
stories. Do you want to hear a story about tigers?
[Choose favourite activity]
</figureCaption>
<bodyText confidence="0.999815172413793">
The ASR is not functional yet due to the spe-
cific challenges of recognizing children voices, so
for now we are only experimenting with a textual
interface. This may look similar to a chatbot but
has additional functionalities such as playing ac-
tivities, and maintaining a context of interaction,
including the history of the past interaction (in or-
der not to repeat itself), physical context (to tai-
lor interaction to the date, time, weather...), and
a profile of the user (to personalise interaction to
them). Contrarily to a chatbot which is designed
for short-term interactions, we expect such a com-
panion agent to be able to develop a long-term re-
lationship with the user. This will be tested with a
Wizard of Oz setting before our industrial partner
provides us with a children-specific ASR.
The dialogue above is obviously not as rich as
child-mother interactions from the CHILDES cor-
pus; in particular it lacks the recognition of emo-
tions and expression of empathy that is essential
in human interactions. Therefore future directions
for research include detecting the child’s emotions
(we have been experimenting with OpenEar (Ey-
ben et al., 2009) to detect emotions from voice);
reasoning about detected emotions, using an exist-
ing BDI model of emotions (Adam, 2007); helping
the child to cope with them, in particular by show-
ing empathy; and endowing the toy with its own
personality (Goldberg, 1993).
</bodyText>
<sectionHeader confidence="0.999605" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.779669">
This project is supported by the Australian Re-
search Council, and RealThing Pty Ltd. under
Linkage Grant LP0882013
</bodyText>
<sectionHeader confidence="0.98094" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998268172413793">
F. Abbattista, G. Catucci, M. Degemmis, P. Lops, G. Semer-
aro, and F. Zambetta. 2003. A framework for the devel-
opment of personalized agents. In KES.
C. Adam. 2007. Emotions: from psychological theories to
logical formalisation and implementation in a BDI agent.
Ph.D. thesis, INP Toulouse, France.
P. B. Brandtzaeg, A. Folstad, and J. Heim. 2006. Enjoyment:
Lessons from karasek. In M. A. Blythe, K. Overbeeke,
A. F. Monk, and P. C. Wright, editors, Funology: From
Usability to Enjoyment. Springer.
F. Eyben, M. Wollmer, and B. Schuller. 2009. openEAR:
Introducing the Munich open-source emotion and affect
recognition toolkit. In ACII, Amsterdam.
D. Field, R. Catizone, W. Cheng, A. Dingli, S. Worgan, L. Ye,
and Y. Wilks. 2009. The senior companion: a semantic
web dialogue system. (demo). In AAMAS.
J. Ginzburg. 1997. Resolving questions I and II. Linguistics
and Philosophy, 17 and 18.
L. R. Goldberg. 1993. The structure of phenotypic personal-
ity traits. American Psychologist, 48:26–34.
B. MacWhinney. 1995. The CHILDES Database.
B. MacWhinney. 2000. The CHILDES project: Tools for
analyzing talk. Lawrence Erlbaum Associates.
R. Ronnquist. 2008. The goal oriented teams (gorite) frame-
work. In Programming Multi-Agent Systems, volume
LNCS 4908, pages 27–41. Springer.
O. Stahl, B. Gamback, M. Turunen, and J. Hakulinen. 2009.
A mobile health and fitness companion demonstrator. In
EACL.
</reference>
<page confidence="0.999167">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.740052">
<title confidence="0.866152">Hello Emily, how are you Personalised dialogue in a toy to engage children</title>
<author confidence="0.998995">Carole Adam Lawrence Cavedon Lin Padgham</author>
<affiliation confidence="0.999991">RMIT University RMIT University RMIT University</affiliation>
<address confidence="0.99464">Melbourne, Australia. Melbourne, Australia. Melbourne, Australia.</address>
<email confidence="0.998918">carole.adam.rmit@gmail.comlawrence.cavedon@rmit.edu.aulin.padgham@rmit.edu.au</email>
<abstract confidence="0.999052642857143">In line with the growing interest in converagents as we are developing a toy companion for children that is capable of engaging interactions and of developing a long-term relationship with them, and is extensible so as to evolve with them. In this paper, we investigate the importance of personalising interaction both for engagement and for long-term relationship development. In particular, we propose a framework for representing, gathering and using personal knowledge about child during dialogue interaction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Abbattista</author>
<author>G Catucci</author>
<author>M Degemmis</author>
<author>P Lops</author>
<author>G Semeraro</author>
<author>F Zambetta</author>
</authors>
<title>A framework for the development of personalized agents.</title>
<date>2003</date>
<booktitle>In KES.</booktitle>
<contexts>
<context position="3288" citStr="Abbattista et al., 2003" startWordPosition="504" endWordPosition="507">aspect of any engaging interaction is for it to be personalised, i.e. customised to the particular interlocutor and their environment. Other important features for engagement include coherence of the dialogue, emotional management, and personality. In this paper we focus specifically on the issue of appropriate personalisation of interactions with a child, and how to realise this. Existing personalised systems mainly have a task-oriented focus, i.e. they aim at building a user profile and using it to facilitate the user’s task (e.g. Web navigation assistants or product recommendation systems (Abbattista et al., 2003)), and at being user-configurable. On the contrary we aim at personalising the interaction to build a relationship and engage a child. The main novelties of our system are that: it is not task-oriented; it is specifically designed for children; and its behaviour is derived from actual interaction data. Indeed, in order to understand the kinds of personalisation occurring in natural dialogues with children, we have analysed corpora of children’s dialogues (MacWhinney, 1995; MacWhinney, 2000). We have then developed a framework that enables the implementation of a number of these personalised be</context>
</contexts>
<marker>Abbattista, Catucci, Degemmis, Lops, Semeraro, Zambetta, 2003</marker>
<rawString>F. Abbattista, G. Catucci, M. Degemmis, P. Lops, G. Semeraro, and F. Zambetta. 2003. A framework for the development of personalized agents. In KES.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Adam</author>
</authors>
<title>Emotions: from psychological theories to logical formalisation and implementation in a BDI agent.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>INP Toulouse,</institution>
<marker>Adam, 2007</marker>
<rawString>C. Adam. 2007. Emotions: from psychological theories to logical formalisation and implementation in a BDI agent. Ph.D. thesis, INP Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P B Brandtzaeg</author>
<author>A Folstad</author>
<author>J Heim</author>
</authors>
<title>Enjoyment: Lessons from karasek.</title>
<date>2006</date>
<editor>In M. A. Blythe, K. Overbeeke, A. F. Monk, and P. C. Wright, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="2212" citStr="Brandtzaeg et al., 2006" startWordPosition="337" endWordPosition="340"> in attempting to develop a “companion toy” for a child, evolving with them over a long period of time. As with other projects on intelligent companions, a crucial task is to build a long-term relationship with the user, by a series of interactions over time, that the user experiences as engaging and valuable. 1A slightly longer version of this paper is currently under review elsewhere. If both papers are accepted for publication we will modify to ensure that they expand different aspects. 2Seewww.companions-project.org. According to models of the “enjoyability” of human-computer interaction (Brandtzaeg et al., 2006), there are three main features making an interactive system engaging for the user: the user should feel in control of the interaction (which includes being able to customise it and getting timely feedback); the demands on the user should be adapted to their capabilities, i.e. the interaction should be challenging and surprising but not overwhelming; and the system should support social interaction rather than isolating the user. Another important aspect of any engaging interaction is for it to be personalised, i.e. customised to the particular interlocutor and their environment. Other importa</context>
</contexts>
<marker>Brandtzaeg, Folstad, Heim, 2006</marker>
<rawString>P. B. Brandtzaeg, A. Folstad, and J. Heim. 2006. Enjoyment: Lessons from karasek. In M. A. Blythe, K. Overbeeke, A. F. Monk, and P. C. Wright, editors, Funology: From Usability to Enjoyment. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Eyben</author>
<author>M Wollmer</author>
<author>B Schuller</author>
</authors>
<title>openEAR: Introducing the Munich open-source emotion and affect recognition toolkit.</title>
<date>2009</date>
<booktitle>In ACII,</booktitle>
<location>Amsterdam.</location>
<marker>Eyben, Wollmer, Schuller, 2009</marker>
<rawString>F. Eyben, M. Wollmer, and B. Schuller. 2009. openEAR: Introducing the Munich open-source emotion and affect recognition toolkit. In ACII, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Field</author>
<author>R Catizone</author>
<author>W Cheng</author>
<author>A Dingli</author>
<author>S Worgan</author>
<author>L Ye</author>
<author>Y Wilks</author>
</authors>
<title>The senior companion: a semantic web dialogue system. (demo).</title>
<date>2009</date>
<booktitle>In AAMAS.</booktitle>
<contexts>
<context position="1330" citStr="Field et al., 2009" startWordPosition="193" endWordPosition="196">ip development. In particular, we propose a framework for representing, gathering and using personal knowledge about the child during dialogue interaction. 1 1 Introduction In recent years there has been an increasing interest in so-called Companion agents: agents that are intelligent, and built to interact naturally (via speech and other modalities) with their user over a prolonged period of time, personalising the interaction to them and developing a relationship with them. The EU Companions project2 is the most well known such project, with applications such as a companion for the elderly (Field et al., 2009), and a health and fitness companion (Stahl et al., 2009). In our work, together with industry partners, we are developing a speech-enabled companion toy for children. While there are many “smart toys” on the market, as far as we are aware our work is unique in attempting to develop a “companion toy” for a child, evolving with them over a long period of time. As with other projects on intelligent companions, a crucial task is to build a long-term relationship with the user, by a series of interactions over time, that the user experiences as engaging and valuable. 1A slightly longer version of </context>
</contexts>
<marker>Field, Catizone, Cheng, Dingli, Worgan, Ye, Wilks, 2009</marker>
<rawString>D. Field, R. Catizone, W. Cheng, A. Dingli, S. Worgan, L. Ye, and Y. Wilks. 2009. The senior companion: a semantic web dialogue system. (demo). In AAMAS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ginzburg</author>
</authors>
<title>Resolving questions I and II.</title>
<date>1997</date>
<journal>Linguistics and Philosophy,</journal>
<volume>17</volume>
<contexts>
<context position="12880" citStr="Ginzburg, 1997" startWordPosition="2096" endWordPosition="2097">onal platforms. 21 SIM plan. In particular the input is then either dispatched to an existing ongoing activity if it matches its expected answers, or an appropriate new activity is created. The chosen activity selects a conversational fragment in the topic network corresponding to its topic, and writes it in the conversational agenda. Finally the output is generated from the agenda and sent to the IOM. 3.2.1 The conversational agenda The conversational agenda maintained by the SIM has two main parts. The history represents the past interaction and stores past questions under discussion (QUD) (Ginzburg, 1997) with their received answer. The stack represents the future interaction and lists QUD to be asked next, in order. The agenda also stores the current ongoing activities (Section 3.2.3), making it possible to switch back and forth between them. 3.2.2 Conversational fragments In our system, we use pre-scripted pieces of dialogue that we call conversational fragments. The designers of domain modules will provide a topic network describing its domain, with nodes being the possible topics, having links with other topics, and providing a pool of fragments to possibly use when talking about this topi</context>
</contexts>
<marker>Ginzburg, 1997</marker>
<rawString>J. Ginzburg. 1997. Resolving questions I and II. Linguistics and Philosophy, 17 and 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Goldberg</author>
</authors>
<title>The structure of phenotypic personality traits.</title>
<date>1993</date>
<journal>American Psychologist,</journal>
<pages>48--26</pages>
<marker>Goldberg, 1993</marker>
<rawString>L. R. Goldberg. 1993. The structure of phenotypic personality traits. American Psychologist, 48:26–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B MacWhinney</author>
</authors>
<title>The CHILDES project: Tools for analyzing talk. Lawrence Erlbaum Associates.</title>
<date>1995</date>
<publisher>The</publisher>
<contexts>
<context position="3764" citStr="MacWhinney, 1995" startWordPosition="584" endWordPosition="585">ofile and using it to facilitate the user’s task (e.g. Web navigation assistants or product recommendation systems (Abbattista et al., 2003)), and at being user-configurable. On the contrary we aim at personalising the interaction to build a relationship and engage a child. The main novelties of our system are that: it is not task-oriented; it is specifically designed for children; and its behaviour is derived from actual interaction data. Indeed, in order to understand the kinds of personalisation occurring in natural dialogues with children, we have analysed corpora of children’s dialogues (MacWhinney, 1995; MacWhinney, 2000). We have then developed a framework that enables the implementation of a number of these personalised behaviours within our intelligent toy. The contribution of this paper is the identification of different kinds of personalisation behaviours in dialogue with children, based on actual data, plus the framework to realise these within an implemented system. 19 Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 19–24, Uppsala, Sweden, 15 July 2010. c�2010 Association for Computational Linguistics 2 Personalisation behaviours 2.1 Corpus analysis</context>
</contexts>
<marker>MacWhinney, 1995</marker>
<rawString>B. MacWhinney. 1995. The CHILDES Database. B. MacWhinney. 2000. The CHILDES project: Tools for analyzing talk. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Ronnquist</author>
</authors>
<title>The goal oriented teams (gorite) framework.</title>
<date>2008</date>
<booktitle>In Programming Multi-Agent Systems, volume LNCS 4908,</booktitle>
<pages>27--41</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="22007" citStr="Ronnquist, 2008" startWordPosition="3563" endWordPosition="3564">on vs continuing the current ac23 tivity. If the activity can be disrupted at this point, personalisation question fragments can be added on top of the stack in the agenda, while comments can be appended to the activity output; if the personalisation fragment has too low priority to disrupt the activity, then it is dropped. This priority of personalisation depends in particular on the priority of the triggered rule and on the time since personalisation was last inserted. 5 Conclusion This framework for personalisation has been implemented in our toy using the Java-based agent platform Gorite (Ronnquist, 2008). The following is an example of the type of dialogues we intend to generate with it (T is the Toy and C a child); it illustrates a number of our personalisation strategies. Our infrastructure technically allows it to happen, however we still need to add more content (domain modules and fragments in them) to make it actually happen; we are working on writing such content, as well as on providing tools to make it easier for designers to write this content in the future. C Hi there T Hello Emily! [Use child’s name] T What did you do on such a sunny week-end? [Context-adaptation] C I went to the </context>
</contexts>
<marker>Ronnquist, 2008</marker>
<rawString>R. Ronnquist. 2008. The goal oriented teams (gorite) framework. In Programming Multi-Agent Systems, volume LNCS 4908, pages 27–41. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Stahl</author>
<author>B Gamback</author>
<author>M Turunen</author>
<author>J Hakulinen</author>
</authors>
<title>A mobile health and fitness companion demonstrator.</title>
<date>2009</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="1387" citStr="Stahl et al., 2009" startWordPosition="203" endWordPosition="206"> representing, gathering and using personal knowledge about the child during dialogue interaction. 1 1 Introduction In recent years there has been an increasing interest in so-called Companion agents: agents that are intelligent, and built to interact naturally (via speech and other modalities) with their user over a prolonged period of time, personalising the interaction to them and developing a relationship with them. The EU Companions project2 is the most well known such project, with applications such as a companion for the elderly (Field et al., 2009), and a health and fitness companion (Stahl et al., 2009). In our work, together with industry partners, we are developing a speech-enabled companion toy for children. While there are many “smart toys” on the market, as far as we are aware our work is unique in attempting to develop a “companion toy” for a child, evolving with them over a long period of time. As with other projects on intelligent companions, a crucial task is to build a long-term relationship with the user, by a series of interactions over time, that the user experiences as engaging and valuable. 1A slightly longer version of this paper is currently under review elsewhere. If both p</context>
</contexts>
<marker>Stahl, Gamback, Turunen, Hakulinen, 2009</marker>
<rawString>O. Stahl, B. Gamback, M. Turunen, and J. Hakulinen. 2009. A mobile health and fitness companion demonstrator. In EACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>