<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.995094">
A Comparison of Chinese Parsers for Stanford Dependencies
</title>
<author confidence="0.896141">
Wanxiang Chet
</author>
<email confidence="0.949245">
car@ir.hit.edu.cn
</email>
<author confidence="0.773914">
Valentin I. Spitkovsky�
</author>
<email confidence="0.963996">
vals@stanford.edu
</email>
<author confidence="0.846992">
Ting Liut
</author>
<email confidence="0.760794">
tliu@ir.hit.edu.cn
</email>
<affiliation confidence="0.9968285">
tSchool of Computer Science and Technology
Harbin Institute of Technology
</affiliation>
<address confidence="0.697088">
Harbin, China, 150001
</address>
<sectionHeader confidence="0.943896" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914913043478">
Stanford dependencies are widely used in nat-
ural language processing as a semantically-
oriented representation, commonly generated
either by (i) converting the output of a con-
stituent parser, or (ii) predicting dependencies
directly. Previous comparisons of the two ap-
proaches for English suggest that starting from
constituents yields higher accuracies. In this
paper, we re-evaluate both methods for Chi-
nese, using more accurate dependency parsers
than in previous work. Our comparison of per-
formance and efficiency across seven popular
open source parsers (four constituent and three
dependency) shows, by contrast, that recent
higher-order graph-based techniques can be
more accurate, though somewhat slower, than
constituent parsers. We demonstrate also that
n-way jackknifing is a useful technique for
producing automatic (rather than gold) part-
of-speech tags to train Chinese dependency
parsers. Finally, we analyze the relations pro-
duced by both kinds of parsing and suggest
which specific parsers to use in practice.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.983204384615385">
Stanford dependencies (de Marneffe and Man-
ning, 2008) provide a simple description of rela-
tions between pairs of words in a sentence. This
semantically-oriented representation is intuitive and
easy to apply, requiring little linguistic expertise.
Consequently, Stanford dependencies are widely
used: in biomedical text mining (Kim et al., 2009),
as well as in textual entailment (Androutsopou-
los and Malakasiotis, 2010), information extrac-
tion (Wu and Weld, 2010; Banko et al., 2007) and
sentiment analysis (Meena and Prabhakar, 2007).
In addition to English, there is a Chinese ver-
sion of Stanford dependencies (Chang et al., 2009),
</bodyText>
<affiliation confidence="0.702442">
tComputer Science Department
Stanford University
</affiliation>
<address confidence="0.407402">
Stanford, CA, 94305
</address>
<figure confidence="0.967903">
(a) A constituent parse tree.
(b) Stanford dependencies.
</figure>
<figureCaption confidence="0.9357366">
Figure 1: A sample Chinese constituent parse tree and its
corresponding Stanford dependencies for the sentence
China (中国) encourages (鼓励) private (民营)
entrepreneurs (企业家) to invest (投资) in
national (国家) infrastructure (基础) construction (建设).
</figureCaption>
<bodyText confidence="0.994199176470588">
which is also useful for many applications, such as
Chinese sentiment analysis (Wu et al., 2011; Wu et
al., 2009; Zhuang et al., 2006) and relation extrac-
tion (Huang et al., 2008). Figure 1 shows a sample
constituent parse tree and the corresponding Stan-
ford dependencies for a sentence in Chinese. Al-
though there are several variants of Stanford depen-
dencies for English,1 so far only a basic version (i.e,
dependency tree structures) is available for Chinese.
Stanford dependencies were originally obtained
from constituent trees, using rules (de Marneffe et
al., 2006). But as dependency parsing technolo-
gies mature (K¨ubler et al., 2009), they offer increas-
ingly attractive alternatives that eliminate the need
for an intermediate representation. Cer et al. (2010)
reported that Stanford’s implementation (Klein and
Manning, 2003) underperforms other constituent
</bodyText>
<footnote confidence="0.461602">
1nlp.stanford.edu/software/dependencies_manual.pdf
</footnote>
<page confidence="0.99333">
11
</page>
<note confidence="0.6857445">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 11–16,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<tableCaption confidence="0.999833">
Table 1: Basic information for the seven parsers included in our experiments.
</tableCaption>
<table confidence="0.917014090909091">
Parser Version Algorithm URL
Berkeley 1.1 PCFG code.google.com/p/berkeleyparser
Bikel 1.2 PCFG www.cis.upenn.edu/˜dbikel/download.html
Charniak Nov. 2009 PCFG www.cog.brown.edu/˜mj/Software.htm
Stanford 2.0 Factored nlp.stanford.edu/software/lex-parser.shtml
MaltParser 1.6.1 Arc-Eager maltparser.org
Mate 2.0 2nd-order MST code.google.com/p/mate-tools
MSTParser 0.5 MST sourceforge.net/projects/mstparser
Type
Constituent
Dependency
</table>
<bodyText confidence="0.984739571428571">
parsers, for English, on both accuracy and speed.
Their thorough investigation also showed that con-
stituent parsers systematically outperform parsing
directly to Stanford dependencies. Nevertheless, rel-
ative standings could have changed in recent years:
dependency parsers are now significantly more ac-
curate, thanks to advances like the high-order maxi-
mum spanning tree (MST) model (Koo and Collins,
2010) for graph-based dependency parsing (McDon-
ald and Pereira, 2006). Therefore, we deemed it im-
portant to re-evaluate the performance of constituent
and dependency parsers. But the main purpose of
our work is to apply the more sophisticated depen-
dency parsing algorithms specifically to Chinese.
</bodyText>
<table confidence="0.95015775">
Number of \in Train Dev Test Total
files 2,083 160 205 2,448
sentences 46,572 2,079 2,796 51,447
tokens 1,039,942 59,955 81,578 1,181,475
</table>
<tableCaption confidence="0.961227">
Table 2: Statistics for Chinese TreeBank (CTB) 7.0 data.
</tableCaption>
<sectionHeader confidence="0.990721" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.9999136">
We compared seven popular open source constituent
and dependency parsers, focusing on both accuracy
and parsing speed. We hope that our analysis will
help end-users select a suitable method for parsing
to Stanford dependencies in their own applications.
</bodyText>
<subsectionHeader confidence="0.993418">
2.1 Parsers
</subsectionHeader>
<bodyText confidence="0.992479875">
We considered four constituent parsers. They are:
Berkeley (Petrov et al., 2006), Bikel (2004), Char-
niak (2000) and Stanford (Klein and Manning,
2003) chineseFactored, which is also the default
used by Stanford dependencies. The three depen-
dency parsers are: MaltParser (Nivre et al., 2006),
Mate (Bohnet, 2010)2 and MSTParser (McDonald
and Pereira, 2006). Table 1 has more information.
</bodyText>
<footnote confidence="0.768425">
2A second-order MST parser (with the speed optimization).
</footnote>
<subsectionHeader confidence="0.99898">
2.2 Corpus
</subsectionHeader>
<bodyText confidence="0.999918833333333">
We used the latest Chinese TreeBank (CTB) 7.0 in
all experiments.3 CTB 7.0 is larger and has more
sources (e.g., web text), compared to previous ver-
sions. We split the data into train/development/test
sets (see Table 2), with gold word segmentation, fol-
lowing the guidelines suggested in documentation.
</bodyText>
<subsectionHeader confidence="0.997718">
2.3 Settings
</subsectionHeader>
<bodyText confidence="0.999896">
Every parser was run with its own default options.
However, since the default classifier used by Malt-
Parser is libsvm (Chang and Lin, 2011) with a poly-
nomial kernel, it may be too slow for training models
on all of CTB 7.0 training data in acceptable time.
Therefore, we also tested this particular parser with
the faster liblinear (Fan et al., 2008) classifier. All
experiments were performed on a machine with In-
tel’s Xeon E5620 2.40GHz CPU and 24GB RAM.
</bodyText>
<subsectionHeader confidence="0.946912">
2.4 Features
</subsectionHeader>
<bodyText confidence="0.999686153846154">
Unlike constituent parsers, dependency models re-
quire exogenous part-of-speech (POS) tags, both in
training and in inference. We used the Stanford tag-
ger (Toutanova et al., 2003) v3.1, with the MEMM
model,4 in combination with 10-way jackknifing.5
Word lemmas — which are generalizations of
words — are another feature known to be useful
for dependency parsing. Here we lemmatized each
Chinese word down to its last character, since — in
contrast to English — a Chinese word’s suffix often
carries that word’s core sense (Tseng et al., 2005).
For example, bicycle (自 行 车), car (汽 车) and
train (火车) are all various kinds of vehicle (车).
</bodyText>
<footnote confidence="0.568198666666667">
3www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2010T07
4nlp.stanford.edu/software/tagger.shtml
</footnote>
<bodyText confidence="0.939265666666667">
5Training sentences in each fold were tagged using a model
based on the other nine folds; development and test sentences
were tagged using a model based on all ten of the training folds.
</bodyText>
<page confidence="0.993567">
12
</page>
<table confidence="0.947979538461538">
Dev Test
Parser UAS LAS UAS LAS Parsing Time
Berkeley 82.0 77.0 82.9 77.8 45:56
Bikel 79.4 74.1 80.0 74.3 6,861:31
Charniak 77.8 71.7 78.3 72.3 128:04
Stanford 76.9 71.2 77.3 71.4 330:50
MaltParser (liblinear) 76.0 71.2 76.3 71.2 0:11
MaltParser (libsvm) 77.3 72.7 78.0 73.1 556:51
Mate (2nd-order) 82.8 78.2 83.1 78.1 87:19
MSTParser (1st-order) 78.8 73.4 78.9 73.1 12:17
Type
Constituent
Dependency
</table>
<tableCaption confidence="0.986743">
Table 3: Performance and efficiency for all parsers on CTB data: unlabeled and labeled attachment scores (UAS/LAS)
are for both development and test data sets; parsing times (minutes:seconds) are for the test data only and exclude gen-
eration of basic Stanford dependencies (for constituent parsers) and part-of-speech tagging (for dependency parsers).
</tableCaption>
<sectionHeader confidence="0.999345" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.991640666666667">
Table 3 tabulates efficiency and performance for all
parsers; UAS and LAS are unlabeled and labeled at-
tachment scores, respectively — the standard crite-
ria for evaluating dependencies. They can be com-
puted via a CoNLL-X shared task dependency pars-
ing evaluation tool (without scoring punctuation).6
</bodyText>
<subsectionHeader confidence="0.998275">
3.1 Chinese
</subsectionHeader>
<bodyText confidence="0.999851307692308">
Mate scored highest, and Berkeley was the most ac-
curate of constituent parsers, slightly behind Mate,
using half of the time. MaltParser (liblinear) was by
far the most efficient but also the least performant; it
scored higher with libsvm but took much more time.
The 1st-order MSTParser was more accurate than
MaltParser (libsvm) — a result that differs from that
of Cer et al. (2010) for English (see §3.2). The Stan-
ford parser (the default for Stanford dependencies)
was only slightly more accurate than MaltParser (li-
blinear). Bikel’s parser was too slow to be used in
practice; and Charniak’s parser — which performs
best for English — did not work well for Chinese.
</bodyText>
<subsectionHeader confidence="0.998663">
3.2 English
</subsectionHeader>
<bodyText confidence="0.973597722222222">
Our replication of Cer et al.’s (2010, Table 1) evalua-
tion revealed a bug: MSTParser normalized all num-
bers to a &lt;num&gt; symbol, which decreased its scores
in the evaluation tool used with Stanford dependen-
cies. After fixing this glitch, MSTParser’s perfor-
mance improved from 78.8 (reported) to 82.5%, thus
making it more accurate than MaltParser (81.1%)
and hence the better dependency parser for English,
consistent with our results for Chinese (see Table 3).
6ilk.uvt.nl/conll/software/eval.pl
Our finding does not contradict the main qualita-
tive result of Cer et al. (2010), however, since the
constituent parser of Charniak and Johnson (2005)
still scores substantially higher (89.1%), for English,
compared to all dependency parsers.7 In a separate
experiment (parsing web data),8 we found Mate to
be less accurate than Charniak-Johnson — and im-
provement from jackknifing smaller — on English.
</bodyText>
<sectionHeader confidence="0.995355" genericHeader="method">
4 Analysis
</sectionHeader>
<bodyText confidence="0.997245272727273">
To further compare the constituent and dependency
approaches to generating Stanford dependencies, we
focused on Mate and Berkeley parsers — the best
of each type. Overall, the difference between their
accuracies is not statistically significant (p &gt; 0.05).9
Table 4 highlights performance (Fl scores) for the
most frequent relation labels. Mate does better on
most relations, noun compound modifiers (nn) and
adjectival modifiers (amod) in particular; and the
Berkeley parser is better at root and dep.10 Mate
seems to excel at short-distance dependencies, pos-
sibly because it uses more local features (even with
a second-order model) than the Berkeley parser,
whose PCFG can capture longer-distance rules.
Since POS-tags are especially informative of Chi-
nese dependencies (Li et al., 2011), we harmonized
training and test data, using 10-way jackknifing (see
§2.4). This method is more robust than training a
7One (small) factor contributing to the difference between
the two languages is that in the Chinese setup we stop with basic
Stanford dependencies — there is no penalty for further conver-
sion; another is not using discriminative reranking for Chinese.
</bodyText>
<footnote confidence="0.90858375">
8sites.google.com/site/sancl2012/home/shared-task
9For LAS, p z:� 0.11; and for UAS, p z:� 0.25, according to
www.cis.upenn.edu/˜dbikel/download/compare.pl
10An unmatched (default) relation (Chang et al., 2009, §3.1).
</footnote>
<page confidence="0.974648">
13
</page>
<table confidence="0.9999313125">
Relation Count Mate Berkeley
nn 7,783 91.3 89.3
dep 4,651 69.4 70.3
nsubj 4,531 87.1 85.5
advmod 4,028 94.3 93.8
dobj 3,990 86.0 85.0
conj 2,159 76.0 75.8
prep 2,091 94.3 94.1
root 2,079 81.2 82.3
nummod 1,614 97.4 96.7
assmod 1,593 86.3 84.1
assm 1,590 88.9 87.2
pobj 1,532 84.2 82.9
amod 1,440 85.6 81.1
rcmod 1,433 74.0 70.6
cpm 1,371 84.4 83.2
</table>
<tableCaption confidence="0.993199">
Table 4: Performance (Fl scores) for the fifteen most-
frequent dependency relations in the CTB 7.0 develop-
ment data set attained by both Mate and Berkeley parsers.
</tableCaption>
<bodyText confidence="0.648939125">
parser with gold tags because it improves consis-
tency, particularly for Chinese, where tagging accu-
racies are lower than in English. On development
data, Mate scored worse given gold tags (75.4 versus
78.2%).11 Lemmatization offered additional useful
cues for overcoming data sparseness (77.8 without,
versus 78.2% with lemma features). Unsupervised
word clusters could thus also help (Koo et al., 2008).
</bodyText>
<sectionHeader confidence="0.99961" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.991803651162791">
Our results suggest that if accuracy is of primary
concern, then Mate should be preferred;12 however,
Berkeley parser offers a trade-off between accuracy
and speed. If neither parser satisfies the demands
of a practical application (e.g., real-time processing
or bulk-parsing the web), then MaltParser (liblinear)
may be the only viable option. Fortunately, it comes
with much headroom for improving accuracy, in-
cluding a tunable margin parameter C for the classi-
fier, richer feature sets (Zhang and Nivre, 2011) and
ensemble models (Surdeanu and Manning, 2010).
Stanford dependencies are not the only popular
dependency representation. We also considered the
11Berkeley’s performance suffered with jackknifed tags (76.5
versus 77.0%), possibly because it parses and tags better jointly.
12Although Mate’s performance was not significantly better
than Berkeley’s in our setting, it has the potential to tap richer
features and other advantages of dependency parsers (Nivre and
McDonald, 2008) to further boost accuracy, which may be diffi-
cult in the generative framework of a typical constituent parser.
conversion scheme of the Penn2Malt tool,13 used
in a series of CoNLL shared tasks (Buchholz and
Marsi, 2006; Nivre et al., 2007; Surdeanu et al.,
2008; Hajiˇc et al., 2009). However, this tool relies
on function tag information from the CTB in deter-
mining dependency relations. Since these tags usu-
ally cannot be produced by constituent parsers, we
could not, in turn, obtain CoNLL-style dependency
trees from their output. This points to another advan-
tage of dependency parsers: they need only the de-
pendency tree corpus to train and can conveniently
make use of native (unconverted) corpora, such as
the Chinese Dependency Treebank (Liu et al., 2006).
Lastly, we must note that although the Berkeley
parser is on par with Charniak’s (2000) system for
English (Cer et al., 2010, Table 1), its scores for Chi-
nese are substantially higher. There may be subtle
biases in Charniak’s approach (e.g., the conditioning
hierarchy used in smoothing) that could turn out to
be language-specific. The Berkeley parser appears
more general — without quite as many parameters
or idiosyncratic design decisions — as evidenced by
a recent application to French (Candito et al., 2010).
</bodyText>
<sectionHeader confidence="0.998686" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999948846153846">
We compared seven popular open source parsers —
four constituent and three dependency — for gen-
erating Stanford dependencies in Chinese. Mate, a
high-order MST dependency parser, with lemmati-
zation and jackknifed POS-tags, appears most accu-
rate; but Berkeley’s faster constituent parser, with
jointly-inferred tags, is statistically no worse. This
outcome is different from English, where constituent
parsers systematically outperform direct methods.
Though Mate scored higher overall, Berkeley’s
parser was better at recovering longer-distance re-
lations, suggesting that a combined approach could
perhaps work better still (Rush et al., 2010, §4.2).
</bodyText>
<sectionHeader confidence="0.996108" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.976856428571429">
We thank Daniel Cer, for helping us replicate the English ex-
perimental setup and for suggesting that we explore jackknifing
methods, and the anonymous reviewers, for valuable comments.
Supported in part by the National Natural Science Founda-
tion of China (NSFC) via grant 61133012, the National “863”
Major Project grant 2011AA01A207, and the National “863”
Leading Technology Research Project grant 2012AA011102.
</bodyText>
<page confidence="0.70172">
13w3.msi.vxu.se/˜nivre/research/Penn2Malt.html
14
</page>
<bodyText confidence="0.999828625">
Second author gratefully acknowledges the continued help
and support of his advisor, Dan Jurafsky, and of the Defense
Advanced Research Projects Agency (DARPA) Machine Read-
ing Program, under the Air Force Research Laboratory (AFRL)
prime contract no. FA8750-09-C-0181. Any opinions, findings,
and conclusions or recommendations expressed in this material
are those of the authors and do not necessarily reflect the views
of DARPA, AFRL, or the US government.
</bodyText>
<sectionHeader confidence="0.817164" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.913146910714286">
Ion Androutsopoulos and Prodromos Malakasiotis. 2010.
A survey of paraphrasing and textual entailment methods.
Journal of Artificial Intelligence Research, 38(1):135–187,
May.
Michele Banko, Michael J. Cafarella, Stephen Soderland, Matt
Broadhead, and Oren Etzioni. 2007. Open information ex-
traction from the web. In Proceedings of the 20th interna-
tional joint conference on Artifical intelligence, IJCAI’07,
pages 2670–2676, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Daniel M. Bikel. 2004. A distributional analysis of a lexi-
calized statistical parsing model. In Dekang Lin and Dekai
Wu, editors, Proceedings of EMNLP 2004, pages 182–189,
Barcelona, Spain, July. Association for Computational Lin-
guistics.
Bernd Bohnet. 2010. Top accuracy and fast dependency pars-
ing is not a contradiction. In Proceedings of the 23rd Inter-
national Conference on Computational Linguistics (Coling
2010), pages 89–97, Beijing, China, August. Coling 2010
Organizing Committee.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proceedings of
the Tenth Conference on Computational Natural Language
Learning (CoNLL-X), pages 149–164, New York City, June.
Association for Computational Linguistics.
Marie Candito, Joakim Nivre, Pascal Denis, and Enrique Hene-
stroza Anguiano. 2010. Benchmarking of statistical depen-
dency parsers for French. In Coling 2010: Posters, pages
108–116, Beijing, China, August. Coling 2010 Organizing
Committee.
Daniel Cer, Marie-Catherine de Marneffe, Daniel Jurafsky, and
Christopher D. Manning. 2010. Parsing to Stanford depen-
dencies: Trade-offs between speed and accuracy. In Pro-
ceedings of the 7th International Conference on Language
Resources and Evaluation (LREC 2010).
Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A li-
brary for support vector machines. ACM Transactions on
Intelligent Systems and Technology, 2(3):27:1–27:27, May.
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and Christo-
pher D. Manning. 2009. Discriminative reordering with
Chinese grammatical relations features. In Proceedings of
the Third Workshop on Syntax and Structure in Statistical
Translation, Boulder, Colorado, June.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-fine n-
best parsing and MaxEnt discriminative reranking. In Pro-
ceedings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL’05), pages 173–180, Ann
Arbor, Michigan, June. Association for Computational Lin-
guistics.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the 1st North American chapter
of the Association for Computational Linguistics conference,
NAACL 2000, pages 132–139, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Marie-Catherine de Marneffe and Christopher D. Manning.
2008. The Stanford typed dependencies representation. In
</bodyText>
<reference confidence="0.968413551020408">
COLING Workshop on Cross-framework and Cross-domain
Parser Evaluation.
Marie-Catherine de Marneffe, Bill MacCartney, and Christo-
pher D. Manning. 2006. Generating typed dependency
parses from phrase structure parses. In Proceedings of the
Fifth International Conference on Language Resources and
Evaluation (LREC’06).
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui
Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library
for large linear classification. Journal of Machine Learning
Research, 9:1871–1874, June.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson,
Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs M`arquez,
Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek,
Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and
Yi Zhang. 2009. The CoNLL-2009 shared task: Syntac-
tic and semantic dependencies in multiple languages. In
Proceedings of the Thirteenth Conference on Computational
Natural Language Learning (CoNLL 2009): Shared Task,
pages 1–18, Boulder, Colorado, June. Association for Com-
putational Linguistics.
Ruihong Huang, Le Sun, and Yuanyong Feng. 2008. Study
of kernel-based methods for Chinese relation extraction. In
Proceedings of the 4th Asia information retrieval conference
on Information retrieval technology, AIRS’08, pages 598–
604, Berlin, Heidelberg. Springer-Verlag.
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu
Kano, and Jun’ichi Tsujii. 2009. Overview of BioNLP’09
shared task on event extraction. In Proceedings of the Work-
shop on Current Trends in Biomedical Natural Language
Processing: Shared Task, BioNLP ’09, pages 1–9, Strouds-
burg, PA, USA. Association for Computational Linguistics.
Dan Klein and Christopher D. Manning. 2003. Accurate unlex-
icalized parsing. In Proceedings of the 41st Annual Meet-
ing on Association for Computational Linguistics - Volume
1, ACL ’03, pages 423–430, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Terry Koo and Michael Collins. 2010. Efficient third-order de-
pendency parsers. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics, ACL
’10, pages 1–11, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Terry Koo, Xavier Carreras, and Michael Collins. 2008. Sim-
ple semi-supervised dependency parsing. In Proceedings of
ACL-08: HLT, pages 595–603, Columbus, Ohio, June. As-
sociation for Computational Linguistics.
Sandra K¨ubler, Ryan T. McDonald, and Joakim Nivre. 2009.
Dependency Parsing. Synthesis Lectures on Human Lan-
guage Technologies. Morgan &amp; Claypool Publishers.
</reference>
<page confidence="0.989287">
15
</page>
<bodyText confidence="0.695718592592592">
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wenliang
Chen, and Haizhou Li. 2011. Joint models for Chinese POS
tagging and dependency parsing. In Proceedings of the 2011
Conference on Empirical Methods in Natural Language Pro-
cessing, pages 1180–1191, Edinburgh, Scotland, UK., July.
Association for Computational Linguistics.
Ting Liu, Jinshan Ma, and Sheng Li. 2006. Building a de-
pendency treebank for improving Chinese parser. Journal of
Chinese Language and Computing, 16(4).
Ryan McDonald and Fernando Pereira. 2006. Online learning
of approximate dependency parsing algorithms. In Proceed-
ings of the 11th Conference of the European Chapter of the
ACL (EACL 2006), pages 81–88.
Arun Meena and T. V. Prabhakar. 2007. Sentence level sen-
timent analysis in the presence of conjuncts using linguistic
analysis. In Proceedings of the 29th European conference on
IR research, ECIR’07, pages 573–580, Berlin, Heidelberg.
Springer-Verlag.
Joakim Nivre and Ryan McDonald. 2008. Integrating graph-
based and transition-based dependency parsers. In Proceed-
ings of ACL-08: HLT, pages 950–958, Columbus, Ohio,
June. Association for Computational Linguistics.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2006. MaltParser:
A data-driven parser-generator for dependency parsing. In
Proceedings of the Fifth International Conference on Lan-
guage Resources and Evaluation (LREC’06), pages 2216–
2219.
</bodyText>
<reference confidence="0.9898435">
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald,
Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007.
The CoNLL 2007 shared task on dependency parsing. In
Proceedings of the CoNLL Shared Task Session of EMNLP-
CoNLL 2007, pages 915–932, Prague, Czech Republic, June.
Association for Computational Linguistics.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein.
2006. Learning accurate, compact, and interpretable tree an-
notation. In Proceedings of the 21st International Confer-
ence on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics, pages
433–440, Sydney, Australia, July. Association for Computa-
tional Linguistics.
Alexander M. Rush, David Sontag, Michael Collins, and
Tommi Jaakkola. 2010. On dual decomposition and linear
programming relaxations for natural language processing. In
Proceedings of the 2010 Conference on Empirical Methods
in Natural Language Processing, pages 1–11, Cambridge,
MA, October. Association for Computational Linguistics.
Mihai Surdeanu and Christopher D. Manning. 2010. Ensemble
models for dependency parsing: cheap and good? In Hu-
man Language Technologies: The 2010 Annual Conference
of the North American Chapter of the Association for Com-
putational Linguistics, HLT ’10, pages 649–652, Strouds-
burg, PA, USA. Association for Computational Linguistics.
Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluis
M`arquez, and Joakim Nivre. 2008. The CoNLL 2008 shared
task on joint parsing of syntactic and semantic dependen-
cies. In CoNLL 2008: Proceedings of the Twelfth Confer-
ence on Computational Natural Language Learning, pages
159–177, Manchester, England, August. Coling 2008 Orga-
nizing Committee.
Kristina Toutanova, Dan Klein, Christopher D. Manning, and
Yoram Singer. 2003. Feature-rich part-of-speech tagging
with a cyclic dependency network. In Proceedings of the
2003 Conference of the North American Chapter of the
Association for Computational Linguistics on Human Lan-
guage Technology - Volume 1, NAACL ’03, pages 173–180,
Stroudsburg, PA, USA. Association for Computational Lin-
guistics.
Huihsin Tseng, Daniel Jurafsky, and Christopher Manning.
2005. Morphological features help POS tagging of un-
known words across language varieties. In Proceedings of
the fourth SIGHAN bakeoff.
Fei Wu and Daniel S. Weld. 2010. Open information extraction
using Wikipedia. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics, ACL
’10, pages 118–127, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009.
Phrase dependency parsing for opinion mining. In Proceed-
ings of the 2009 Conference on Empirical Methods in Nat-
ural Language Processing: Volume 3 - Volume 3, EMNLP
’09, pages 1533–1541, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2011.
Structural opinion mining for graph-based sentiment rep-
resentation. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, EMNLP ’11,
pages 1332–1341, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Yue Zhang and Joakim Nivre. 2011. Transition-based depen-
dency parsing with rich non-local features. In Proceedings
of the 49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies: short
papers - Volume 2, HLT ’11, pages 188–193, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie re-
view mining and summarization. In Proceedings of the 15th
ACM international conference on Information and knowl-
edge management, CIKM ’06, pages 43–50, New York, NY,
USA. ACM.
</reference>
<page confidence="0.998626">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.138020">
<title confidence="0.978981">A Comparison of Chinese Parsers for Stanford Dependencies</title>
<abstract confidence="0.411311">car@ir.hit.edu.cn I.</abstract>
<email confidence="0.957751">vals@stanford.edu</email>
<author confidence="0.463862">tliuir hit edu cn</author>
<affiliation confidence="0.988527">of Computer Science and Technology Harbin Institute of Technology</affiliation>
<address confidence="0.999745">Harbin, China, 150001</address>
<abstract confidence="0.999623791666667">Stanford dependencies are widely used in natural language processing as a semanticallyoriented representation, commonly generated either by (i) converting the output of a constituent parser, or (ii) predicting dependencies directly. Previous comparisons of the two approaches for English suggest that starting from constituents yields higher accuracies. In this paper, we re-evaluate both methods for Chinese, using more accurate dependency parsers than in previous work. Our comparison of performance and efficiency across seven popular open source parsers (four constituent and three dependency) shows, by contrast, that recent higher-order graph-based techniques can be more accurate, though somewhat slower, than constituent parsers. We demonstrate also that jackknifing is a useful technique for producing automatic (rather than gold) partof-speech tags to train Chinese dependency parsers. Finally, we analyze the relations produced by both kinds of parsing and suggest which specific parsers to use in practice.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.</booktitle>
<marker></marker>
<rawString>COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC’06).</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC’06).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>Xiang-Rui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="6229" citStr="Fan et al., 2008" startWordPosition="889" endWordPosition="892">all experiments.3 CTB 7.0 is larger and has more sources (e.g., web text), compared to previous versions. We split the data into train/development/test sets (see Table 2), with gold word segmentation, following the guidelines suggested in documentation. 2.3 Settings Every parser was run with its own default options. However, since the default classifier used by MaltParser is libsvm (Chang and Lin, 2011) with a polynomial kernel, it may be too slow for training models on all of CTB 7.0 training data in acceptable time. Therefore, we also tested this particular parser with the faster liblinear (Fan et al., 2008) classifier. All experiments were performed on a machine with Intel’s Xeon E5620 2.40GHz CPU and 24GB RAM. 2.4 Features Unlike constituent parsers, dependency models require exogenous part-of-speech (POS) tags, both in training and in inference. We used the Stanford tagger (Toutanova et al., 2003) v3.1, with the MEMM model,4 in combination with 10-way jackknifing.5 Word lemmas — which are generalizations of words — are another feature known to be useful for dependency parsing. Here we lemmatized each Chinese word down to its last character, since — in contrast to English — a Chinese word’s suf</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874, June.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Llu´ıs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task,</booktitle>
<pages>1--18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Mart´ı, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, pages 1–18, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Le Sun</author>
<author>Yuanyong Feng</author>
</authors>
<title>Study of kernel-based methods for Chinese relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 4th Asia information retrieval conference on Information retrieval technology, AIRS’08,</booktitle>
<pages>598--604</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Huang, Le Sun, Feng, 2008</marker>
<rawString>Ruihong Huang, Le Sun, and Yuanyong Feng. 2008. Study of kernel-based methods for Chinese relation extraction. In Proceedings of the 4th Asia information retrieval conference on Information retrieval technology, AIRS’08, pages 598– 604, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Sampo Pyysalo</author>
<author>Yoshinobu Kano</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Overview of BioNLP’09 shared task on event extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing: Shared Task, BioNLP ’09,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1650" citStr="Kim et al., 2009" startWordPosition="229" endWordPosition="232">y jackknifing is a useful technique for producing automatic (rather than gold) partof-speech tags to train Chinese dependency parsers. Finally, we analyze the relations produced by both kinds of parsing and suggest which specific parsers to use in practice. 1 Introduction Stanford dependencies (de Marneffe and Manning, 2008) provide a simple description of relations between pairs of words in a sentence. This semantically-oriented representation is intuitive and easy to apply, requiring little linguistic expertise. Consequently, Stanford dependencies are widely used: in biomedical text mining (Kim et al., 2009), as well as in textual entailment (Androutsopoulos and Malakasiotis, 2010), information extraction (Wu and Weld, 2010; Banko et al., 2007) and sentiment analysis (Meena and Prabhakar, 2007). In addition to English, there is a Chinese version of Stanford dependencies (Chang et al., 2009), tComputer Science Department Stanford University Stanford, CA, 94305 (a) A constituent parse tree. (b) Stanford dependencies. Figure 1: A sample Chinese constituent parse tree and its corresponding Stanford dependencies for the sentence China (中国) encourages (鼓励) private (民营) entrepreneurs (企业家) to invest (投资</context>
</contexts>
<marker>Kim, Ohta, Pyysalo, Kano, Tsujii, 2009</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, Yoshinobu Kano, and Jun’ichi Tsujii. 2009. Overview of BioNLP’09 shared task on event extraction. In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing: Shared Task, BioNLP ’09, pages 1–9, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3142" citStr="Klein and Manning, 2003" startWordPosition="454" endWordPosition="457">ituent parse tree and the corresponding Stanford dependencies for a sentence in Chinese. Although there are several variants of Stanford dependencies for English,1 so far only a basic version (i.e, dependency tree structures) is available for Chinese. Stanford dependencies were originally obtained from constituent trees, using rules (de Marneffe et al., 2006). But as dependency parsing technologies mature (K¨ubler et al., 2009), they offer increasingly attractive alternatives that eliminate the need for an intermediate representation. Cer et al. (2010) reported that Stanford’s implementation (Klein and Manning, 2003) underperforms other constituent 1nlp.stanford.edu/software/dependencies_manual.pdf 11 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 11–16, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Table 1: Basic information for the seven parsers included in our experiments. Parser Version Algorithm URL Berkeley 1.1 PCFG code.google.com/p/berkeleyparser Bikel 1.2 PCFG www.cis.upenn.edu/˜dbikel/download.html Charniak Nov. 2009 PCFG www.cog.brown.edu/˜mj/Software.htm Stanford 2.0 Factored nlp.stanford.edu/software/l</context>
<context position="5257" citStr="Klein and Manning, 2003" startWordPosition="732" endWordPosition="735">umber of \in Train Dev Test Total files 2,083 160 205 2,448 sentences 46,572 2,079 2,796 51,447 tokens 1,039,942 59,955 81,578 1,181,475 Table 2: Statistics for Chinese TreeBank (CTB) 7.0 data. 2 Methodology We compared seven popular open source constituent and dependency parsers, focusing on both accuracy and parsing speed. We hope that our analysis will help end-users select a suitable method for parsing to Stanford dependencies in their own applications. 2.1 Parsers We considered four constituent parsers. They are: Berkeley (Petrov et al., 2006), Bikel (2004), Charniak (2000) and Stanford (Klein and Manning, 2003) chineseFactored, which is also the default used by Stanford dependencies. The three dependency parsers are: MaltParser (Nivre et al., 2006), Mate (Bohnet, 2010)2 and MSTParser (McDonald and Pereira, 2006). Table 1 has more information. 2A second-order MST parser (with the speed optimization). 2.2 Corpus We used the latest Chinese TreeBank (CTB) 7.0 in all experiments.3 CTB 7.0 is larger and has more sources (e.g., web text), compared to previous versions. We split the data into train/development/test sets (see Table 2), with gold word segmentation, following the guidelines suggested in docume</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 423–430, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient third-order dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>1--11</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4339" citStr="Koo and Collins, 2010" startWordPosition="592" endWordPosition="595">p.stanford.edu/software/lex-parser.shtml MaltParser 1.6.1 Arc-Eager maltparser.org Mate 2.0 2nd-order MST code.google.com/p/mate-tools MSTParser 0.5 MST sourceforge.net/projects/mstparser Type Constituent Dependency parsers, for English, on both accuracy and speed. Their thorough investigation also showed that constituent parsers systematically outperform parsing directly to Stanford dependencies. Nevertheless, relative standings could have changed in recent years: dependency parsers are now significantly more accurate, thanks to advances like the high-order maximum spanning tree (MST) model (Koo and Collins, 2010) for graph-based dependency parsing (McDonald and Pereira, 2006). Therefore, we deemed it important to re-evaluate the performance of constituent and dependency parsers. But the main purpose of our work is to apply the more sophisticated dependency parsing algorithms specifically to Chinese. Number of \in Train Dev Test Total files 2,083 160 205 2,448 sentences 46,572 2,079 2,796 51,447 tokens 1,039,942 59,955 81,578 1,181,475 Table 2: Statistics for Chinese TreeBank (CTB) 7.0 data. 2 Methodology We compared seven popular open source constituent and dependency parsers, focusing on both accurac</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient third-order dependency parsers. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 1–11, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>595--603</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="12245" citStr="Koo et al., 2008" startWordPosition="1827" endWordPosition="1830">5.6 81.1 rcmod 1,433 74.0 70.6 cpm 1,371 84.4 83.2 Table 4: Performance (Fl scores) for the fifteen mostfrequent dependency relations in the CTB 7.0 development data set attained by both Mate and Berkeley parsers. parser with gold tags because it improves consistency, particularly for Chinese, where tagging accuracies are lower than in English. On development data, Mate scored worse given gold tags (75.4 versus 78.2%).11 Lemmatization offered additional useful cues for overcoming data sparseness (77.8 without, versus 78.2% with lemma features). Unsupervised word clusters could thus also help (Koo et al., 2008). 5 Discussion Our results suggest that if accuracy is of primary concern, then Mate should be preferred;12 however, Berkeley parser offers a trade-off between accuracy and speed. If neither parser satisfies the demands of a practical application (e.g., real-time processing or bulk-parsing the web), then MaltParser (liblinear) may be the only viable option. Fortunately, it comes with much headroom for improving accuracy, including a tunable margin parameter C for the classifier, richer feature sets (Zhang and Nivre, 2011) and ensemble models (Surdeanu and Manning, 2010). Stanford dependencies </context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings of ACL-08: HLT, pages 595–603, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan T McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency Parsing. Synthesis Lectures on Human Language Technologies.</title>
<date>2009</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan T. McDonald, and Joakim Nivre. 2009. Dependency Parsing. Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL 2007,</booktitle>
<pages>915--932</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLPCoNLL 2007, pages 915–932, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="5187" citStr="Petrov et al., 2006" startWordPosition="721" endWordPosition="724">isticated dependency parsing algorithms specifically to Chinese. Number of \in Train Dev Test Total files 2,083 160 205 2,448 sentences 46,572 2,079 2,796 51,447 tokens 1,039,942 59,955 81,578 1,181,475 Table 2: Statistics for Chinese TreeBank (CTB) 7.0 data. 2 Methodology We compared seven popular open source constituent and dependency parsers, focusing on both accuracy and parsing speed. We hope that our analysis will help end-users select a suitable method for parsing to Stanford dependencies in their own applications. 2.1 Parsers We considered four constituent parsers. They are: Berkeley (Petrov et al., 2006), Bikel (2004), Charniak (2000) and Stanford (Klein and Manning, 2003) chineseFactored, which is also the default used by Stanford dependencies. The three dependency parsers are: MaltParser (Nivre et al., 2006), Mate (Bohnet, 2010)2 and MSTParser (McDonald and Pereira, 2006). Table 1 has more information. 2A second-order MST parser (with the speed optimization). 2.2 Corpus We used the latest Chinese TreeBank (CTB) 7.0 in all experiments.3 CTB 7.0 is larger and has more sources (e.g., web text), compared to previous versions. We split the data into train/development/test sets (see Table 2), wit</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 433–440, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>David Sontag</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--11</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="15189" citStr="Rush et al., 2010" startWordPosition="2274" endWordPosition="2277"> open source parsers — four constituent and three dependency — for generating Stanford dependencies in Chinese. Mate, a high-order MST dependency parser, with lemmatization and jackknifed POS-tags, appears most accurate; but Berkeley’s faster constituent parser, with jointly-inferred tags, is statistically no worse. This outcome is different from English, where constituent parsers systematically outperform direct methods. Though Mate scored higher overall, Berkeley’s parser was better at recovering longer-distance relations, suggesting that a combined approach could perhaps work better still (Rush et al., 2010, §4.2). Acknowledgments We thank Daniel Cer, for helping us replicate the English experimental setup and for suggesting that we explore jackknifing methods, and the anonymous reviewers, for valuable comments. Supported in part by the National Natural Science Foundation of China (NSFC) via grant 61133012, the National “863” Major Project grant 2011AA01A207, and the National “863” Leading Technology Research Project grant 2012AA011102. 13w3.msi.vxu.se/˜nivre/research/Penn2Malt.html 14 Second author gratefully acknowledges the continued help and support of his advisor, Dan Jurafsky, and of the D</context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>Alexander M. Rush, David Sontag, Michael Collins, and Tommi Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1–11, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Christopher D Manning</author>
</authors>
<title>Ensemble models for dependency parsing: cheap and good?</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>649--652</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12821" citStr="Surdeanu and Manning, 2010" startWordPosition="1914" endWordPosition="1917">rd clusters could thus also help (Koo et al., 2008). 5 Discussion Our results suggest that if accuracy is of primary concern, then Mate should be preferred;12 however, Berkeley parser offers a trade-off between accuracy and speed. If neither parser satisfies the demands of a practical application (e.g., real-time processing or bulk-parsing the web), then MaltParser (liblinear) may be the only viable option. Fortunately, it comes with much headroom for improving accuracy, including a tunable margin parameter C for the classifier, richer feature sets (Zhang and Nivre, 2011) and ensemble models (Surdeanu and Manning, 2010). Stanford dependencies are not the only popular dependency representation. We also considered the 11Berkeley’s performance suffered with jackknifed tags (76.5 versus 77.0%), possibly because it parses and tags better jointly. 12Although Mate’s performance was not significantly better than Berkeley’s in our setting, it has the potential to tap richer features and other advantages of dependency parsers (Nivre and McDonald, 2008) to further boost accuracy, which may be difficult in the generative framework of a typical constituent parser. conversion scheme of the Penn2Malt tool,13 used in a seri</context>
</contexts>
<marker>Surdeanu, Manning, 2010</marker>
<rawString>Mihai Surdeanu and Christopher D. Manning. 2010. Ensemble models for dependency parsing: cheap and good? In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 649–652, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Lluis M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<title>The CoNLL</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,</booktitle>
<pages>159--177</pages>
<location>Manchester, England,</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluis M`arquez, and Joakim Nivre. 2008. The CoNLL 2008 shared task on joint parsing of syntactic and semantic dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning, pages 159–177, Manchester, England, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03,</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6527" citStr="Toutanova et al., 2003" startWordPosition="936" endWordPosition="939"> its own default options. However, since the default classifier used by MaltParser is libsvm (Chang and Lin, 2011) with a polynomial kernel, it may be too slow for training models on all of CTB 7.0 training data in acceptable time. Therefore, we also tested this particular parser with the faster liblinear (Fan et al., 2008) classifier. All experiments were performed on a machine with Intel’s Xeon E5620 2.40GHz CPU and 24GB RAM. 2.4 Features Unlike constituent parsers, dependency models require exogenous part-of-speech (POS) tags, both in training and in inference. We used the Stanford tagger (Toutanova et al., 2003) v3.1, with the MEMM model,4 in combination with 10-way jackknifing.5 Word lemmas — which are generalizations of words — are another feature known to be useful for dependency parsing. Here we lemmatized each Chinese word down to its last character, since — in contrast to English — a Chinese word’s suffix often carries that word’s core sense (Tseng et al., 2005). For example, bicycle (自 行 车), car (汽 车) and train (火车) are all various kinds of vehicle (车). 3www.ldc.upenn.edu/Catalog/CatalogEntry.jsp? catalogId=LDC2010T07 4nlp.stanford.edu/software/tagger.shtml 5Training sentences in each fold wer</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03, pages 173–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huihsin Tseng</author>
<author>Daniel Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>Morphological features help POS tagging of unknown words across language varieties.</title>
<date>2005</date>
<booktitle>In Proceedings of the fourth SIGHAN bakeoff.</booktitle>
<contexts>
<context position="6890" citStr="Tseng et al., 2005" startWordPosition="997" endWordPosition="1000">d on a machine with Intel’s Xeon E5620 2.40GHz CPU and 24GB RAM. 2.4 Features Unlike constituent parsers, dependency models require exogenous part-of-speech (POS) tags, both in training and in inference. We used the Stanford tagger (Toutanova et al., 2003) v3.1, with the MEMM model,4 in combination with 10-way jackknifing.5 Word lemmas — which are generalizations of words — are another feature known to be useful for dependency parsing. Here we lemmatized each Chinese word down to its last character, since — in contrast to English — a Chinese word’s suffix often carries that word’s core sense (Tseng et al., 2005). For example, bicycle (自 行 车), car (汽 车) and train (火车) are all various kinds of vehicle (车). 3www.ldc.upenn.edu/Catalog/CatalogEntry.jsp? catalogId=LDC2010T07 4nlp.stanford.edu/software/tagger.shtml 5Training sentences in each fold were tagged using a model based on the other nine folds; development and test sentences were tagged using a model based on all ten of the training folds. 12 Dev Test Parser UAS LAS UAS LAS Parsing Time Berkeley 82.0 77.0 82.9 77.8 45:56 Bikel 79.4 74.1 80.0 74.3 6,861:31 Charniak 77.8 71.7 78.3 72.3 128:04 Stanford 76.9 71.2 77.3 71.4 330:50 MaltParser (liblinear)</context>
</contexts>
<marker>Tseng, Jurafsky, Manning, 2005</marker>
<rawString>Huihsin Tseng, Daniel Jurafsky, and Christopher Manning. 2005. Morphological features help POS tagging of unknown words across language varieties. In Proceedings of the fourth SIGHAN bakeoff.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction using Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>118--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1768" citStr="Wu and Weld, 2010" startWordPosition="247" endWordPosition="250">endency parsers. Finally, we analyze the relations produced by both kinds of parsing and suggest which specific parsers to use in practice. 1 Introduction Stanford dependencies (de Marneffe and Manning, 2008) provide a simple description of relations between pairs of words in a sentence. This semantically-oriented representation is intuitive and easy to apply, requiring little linguistic expertise. Consequently, Stanford dependencies are widely used: in biomedical text mining (Kim et al., 2009), as well as in textual entailment (Androutsopoulos and Malakasiotis, 2010), information extraction (Wu and Weld, 2010; Banko et al., 2007) and sentiment analysis (Meena and Prabhakar, 2007). In addition to English, there is a Chinese version of Stanford dependencies (Chang et al., 2009), tComputer Science Department Stanford University Stanford, CA, 94305 (a) A constituent parse tree. (b) Stanford dependencies. Figure 1: A sample Chinese constituent parse tree and its corresponding Stanford dependencies for the sentence China (中国) encourages (鼓励) private (民营) entrepreneurs (企业家) to invest (投资) in national (国家) infrastructure (基础) construction (建设). which is also useful for many applications, such as Chinese </context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Fei Wu and Daniel S. Weld. 2010. Open information extraction using Wikipedia. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 118–127, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, EMNLP ’09,</booktitle>
<pages>1533--1541</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2420" citStr="Wu et al., 2009" startWordPosition="345" endWordPosition="348">nalysis (Meena and Prabhakar, 2007). In addition to English, there is a Chinese version of Stanford dependencies (Chang et al., 2009), tComputer Science Department Stanford University Stanford, CA, 94305 (a) A constituent parse tree. (b) Stanford dependencies. Figure 1: A sample Chinese constituent parse tree and its corresponding Stanford dependencies for the sentence China (中国) encourages (鼓励) private (民营) entrepreneurs (企业家) to invest (投资) in national (国家) infrastructure (基础) construction (建设). which is also useful for many applications, such as Chinese sentiment analysis (Wu et al., 2011; Wu et al., 2009; Zhuang et al., 2006) and relation extraction (Huang et al., 2008). Figure 1 shows a sample constituent parse tree and the corresponding Stanford dependencies for a sentence in Chinese. Although there are several variants of Stanford dependencies for English,1 so far only a basic version (i.e, dependency tree structures) is available for Chinese. Stanford dependencies were originally obtained from constituent trees, using rules (de Marneffe et al., 2006). But as dependency parsing technologies mature (K¨ubler et al., 2009), they offer increasingly attractive alternatives that eliminate the ne</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, EMNLP ’09, pages 1533–1541, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Structural opinion mining for graph-based sentiment representation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1332--1341</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2403" citStr="Wu et al., 2011" startWordPosition="341" endWordPosition="344">) and sentiment analysis (Meena and Prabhakar, 2007). In addition to English, there is a Chinese version of Stanford dependencies (Chang et al., 2009), tComputer Science Department Stanford University Stanford, CA, 94305 (a) A constituent parse tree. (b) Stanford dependencies. Figure 1: A sample Chinese constituent parse tree and its corresponding Stanford dependencies for the sentence China (中国) encourages (鼓励) private (民营) entrepreneurs (企业家) to invest (投资) in national (国家) infrastructure (基础) construction (建设). which is also useful for many applications, such as Chinese sentiment analysis (Wu et al., 2011; Wu et al., 2009; Zhuang et al., 2006) and relation extraction (Huang et al., 2008). Figure 1 shows a sample constituent parse tree and the corresponding Stanford dependencies for a sentence in Chinese. Although there are several variants of Stanford dependencies for English,1 so far only a basic version (i.e, dependency tree structures) is available for Chinese. Stanford dependencies were originally obtained from constituent trees, using rules (de Marneffe et al., 2006). But as dependency parsing technologies mature (K¨ubler et al., 2009), they offer increasingly attractive alternatives that</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2011</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2011. Structural opinion mining for graph-based sentiment representation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1332–1341, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>188--193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="12772" citStr="Zhang and Nivre, 2011" startWordPosition="1907" endWordPosition="1910"> 78.2% with lemma features). Unsupervised word clusters could thus also help (Koo et al., 2008). 5 Discussion Our results suggest that if accuracy is of primary concern, then Mate should be preferred;12 however, Berkeley parser offers a trade-off between accuracy and speed. If neither parser satisfies the demands of a practical application (e.g., real-time processing or bulk-parsing the web), then MaltParser (liblinear) may be the only viable option. Fortunately, it comes with much headroom for improving accuracy, including a tunable margin parameter C for the classifier, richer feature sets (Zhang and Nivre, 2011) and ensemble models (Surdeanu and Manning, 2010). Stanford dependencies are not the only popular dependency representation. We also considered the 11Berkeley’s performance suffered with jackknifed tags (76.5 versus 77.0%), possibly because it parses and tags better jointly. 12Although Mate’s performance was not significantly better than Berkeley’s in our setting, it has the potential to tap richer features and other advantages of dependency parsers (Nivre and McDonald, 2008) to further boost accuracy, which may be difficult in the generative framework of a typical constituent parser. conversi</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 188–193, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiao-Yan Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM international conference on Information and knowledge management, CIKM ’06,</booktitle>
<pages>43--50</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2442" citStr="Zhuang et al., 2006" startWordPosition="349" endWordPosition="352">d Prabhakar, 2007). In addition to English, there is a Chinese version of Stanford dependencies (Chang et al., 2009), tComputer Science Department Stanford University Stanford, CA, 94305 (a) A constituent parse tree. (b) Stanford dependencies. Figure 1: A sample Chinese constituent parse tree and its corresponding Stanford dependencies for the sentence China (中国) encourages (鼓励) private (民营) entrepreneurs (企业家) to invest (投资) in national (国家) infrastructure (基础) construction (建设). which is also useful for many applications, such as Chinese sentiment analysis (Wu et al., 2011; Wu et al., 2009; Zhuang et al., 2006) and relation extraction (Huang et al., 2008). Figure 1 shows a sample constituent parse tree and the corresponding Stanford dependencies for a sentence in Chinese. Although there are several variants of Stanford dependencies for English,1 so far only a basic version (i.e, dependency tree structures) is available for Chinese. Stanford dependencies were originally obtained from constituent trees, using rules (de Marneffe et al., 2006). But as dependency parsing technologies mature (K¨ubler et al., 2009), they offer increasingly attractive alternatives that eliminate the need for an intermediate</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie review mining and summarization. In Proceedings of the 15th ACM international conference on Information and knowledge management, CIKM ’06, pages 43–50, New York, NY, USA. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>