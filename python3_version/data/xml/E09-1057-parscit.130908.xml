<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9974595">
Language-independent bilingual terminology extraction from a
multilingual parallel corpus
</title>
<author confidence="0.977157">
Els Lefever1 2, Lieve Macken1 2 and Veronique Hoste1 2
</author>
<affiliation confidence="0.852006625">
1LT3
School of Translation Studies
University College Ghent
Groot-Brittanni¨elaan 45
9000 Gent, Belgium
2Department of Applied Mathematics
and Computer Science
Ghent University
</affiliation>
<address confidence="0.8458875">
Krijgslaan281-S9
9000 Gent, Belgium
</address>
<email confidence="0.997141">
{Els.Lefever, Lieve.Macken, Veronique.Hoste}@hogent.be
</email>
<sectionHeader confidence="0.99382" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999685208333334">
We present a language-pair independent
terminology extraction module that is
based on a sub-sentential alignment sys-
tem that links linguistically motivated
phrases in parallel texts. Statistical filters
are applied on the bilingual list of candi-
date terms that is extracted from the align-
ment output.
We compare the performance of both
the alignment and terminology extrac-
tion module for three different language
pairs (French-English, French-Italian and
French-Dutch) and highlight language-
pair specific problems (e.g. different com-
pounding strategy in French and Dutch).
Comparisons with standard terminology
extraction programs show an improvement
of up to 20% for bilingual terminology ex-
traction and competitive results (85% to
90% accuracy) for monolingual terminol-
ogy extraction, and reveal that the linguis-
tically based alignment module is particu-
larly well suited for the extraction of com-
plex multiword terms.
</bodyText>
<sectionHeader confidence="0.998417" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99086847826087">
Automatic Term Recognition (ATR) systems are
usually categorized into two main families. On the
one hand, the linguistically-based or rule-based
approaches use linguistic information such as PoS
tags, chunk information, etc. to filter out stop
words and restrict candidate terms to predefined
syntactic patterns (Ananiadou, 1994), (Dagan and
Church, 1994). On the other hand, the statistical
corpus-based approaches select n-gram sequences
as candidate terms that are filtered by means of
statistical measures. More recent ATR systems
use hybrid approaches that combine both linguis-
tic and statistical information (Frantzi and Anani-
adou, 1999).
Most bilingual terminology extraction systems
first identify candidate terms in the source lan-
guage based on predefined source patterns, and
then select translation candidates for these terms
in the target language (Kupiec, 1993).
We present an alternative approach that gen-
erates candidate terms directly from the aligned
words and phrases in our parallel corpus. In a sec-
ond step, we use frequency information of a gen-
eral purpose corpus and the n-gram frequencies
of the automotive corpus to determine the term
specificity. Our approach is more flexible in the
sense that we do not first generate candidate terms
based on language-dependent predefined PoS pat-
terns (e.g. for French, N N, N Prep N, and N
Adj are typical patterns), but immediately link lin-
guistically motivated phrases in our parallel cor-
pus based on lexical correspondences and syntac-
tic similarity.
This article reports on the term extraction ex-
periments for 3 language pairs, i.e. French-Dutch,
French-English and French-Italian. The focus was
on the extraction of automative lexicons.
The remainder of this paper is organized as fol-
lows: Section 2 describes the corpus. In Section 3
we present our linguistically-based sub-sentential
alignment system and in Section 4 we describe
how we generate and filter our list of candidate
terms. We compare the performance of our sys-
tem with both bilingual and monolingual state-of-
the-art terminology extraction systems. Section 5
concludes this paper.
</bodyText>
<note confidence="0.9232375">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 496–504,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.99835">
496
</page>
<sectionHeader confidence="0.984121" genericHeader="introduction">
2 Corpus
</sectionHeader>
<bodyText confidence="0.999734411764706">
The focus of this research project was on the au-
tomatic extraction of 20 bilingual automative lex-
icons. All work was carried out in the framework
of a customer project for a major French automo-
tive company. The final goal of the project is to
improve vocabulary consistency in technical texts
across the 20 languages in the customer’s portfo-
lio. The French database contains about 400,000
entries (i.e. sentences and parts of sentences with
an average length of 9 words) and the translation
percentage of the database into 19 languages de-
pends on the target market.
For the development of the alignment and termi-
nology extraction module, we created three paral-
lel corpora (Italian, English, Dutch) with French
as a central language. Figures about the size of
each parallel corpus can be found in table 1.
</bodyText>
<table confidence="0.9987915">
Target Lang. # Sentence pairs # words
French Italian 364,221 6,408,693
French English 363,651 7,305,151
French Dutch 364,311 7,100,585
</table>
<tableCaption confidence="0.962532">
Table 1: Number of sentence pairs and total num-
ber of words in the three parallel corpora
</tableCaption>
<subsectionHeader confidence="0.992605">
2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999967">
We PoS-tagged and lemmatized the French, En-
glish and Italian corpora with the freely available
TreeTagger tool (Schmid, 1994) and we used Tad-
Pole (Van den Bosch et al., 2007) to annotate the
Dutch corpus.
In a next step, chunk information was added
by a rule-based language-independent chunker
(Macken et al., 2008) that contains distituency
rules, which implies that chunk boundaries are
added between two PoS codes that cannot occur
in the same constituent.
</bodyText>
<subsectionHeader confidence="0.999844">
2.2 Test and development corpus
</subsectionHeader>
<bodyText confidence="0.999952076923077">
As we presume that sentence length has an impact
on the alignment performance, and thus on term
extraction, we created three test sets with vary-
ing sentence lengths. We distinguished short sen-
tences (2-7 words), medium-length sentences (8-
19 words) and long sentences (&gt; 19 words). Each
test corpus contains approximately 9,000 words;
the number of sentence pairs per test set can be
found in table 2. We also created a development
corpus with sentences of varying length to debug
the linguistic processing and the alignment mod-
ule as well as to define the thresholds for the sta-
tistical filtering of the candidate terms (see 4.1).
</bodyText>
<table confidence="0.9997954">
# Words # Sentence pairs
Short (&lt; 8 words) +- 9,000 823
Medium (8-19 words) +- 9,000 386
Long (&gt; 19 words) +- 9,000 180
Development corpus +-5,000 393
</table>
<tableCaption confidence="0.9346145">
Table 2: Number of words and sentence pairs in
the test and development corpora
</tableCaption>
<sectionHeader confidence="0.964296" genericHeader="method">
3 Sub-sentential alignment module
</sectionHeader>
<bodyText confidence="0.999971382352941">
As the basis for our terminology extraction sys-
tem, we used the sub-sentential alignment sys-
tem of (Macken and Daelemans, 2009) that links
linguistically motivated phrases in parallel texts
based on lexical correspondences and syntactic
similarity. In the first phase of this system, anchor
chunks are linked, i.e. chunks that can be linked
with a very high precision. We think these anchor
chunks offer a valid and language-independent al-
ternative to identify candidate terms based on pre-
defined PoS patterns. As the automotive corpus
contains rather literal translations, we expect that a
high percentage of anchor chunks can be retrieved.
Although the architecture of the sub-sentential
alignment system is language-independent, some
language-specific resources are used. First, a
bilingual lexicon to generate the lexical correspon-
dences and second, tools to generate additional
linguistic information (PoS tagger, lemmatizer and
a chunker). The sub-sentential alignment system
takes as input sentence-aligned texts, together with
the additional linguistic annotations for the source
and the target texts.
The source and target sentences are divided into
chunks based on PoS information, and lexical cor-
respondences are retrieved from a bilingual dic-
tionary. In order to extract bilingual dictionaries
from the three parallel corpora, we used the Perl
implementation of IBM Model One that is part of
the Microsoft Bilingual Sentence Aligner (Moore,
2002).
In order to link chunks based on lexical clues
and chunk similarity, the following steps are taken
for each sentence pair:
</bodyText>
<listItem confidence="0.999048666666667">
1. Creation of the lexical link matrix
2. Linking chunks based on lexical correspon-
dences and chunk similarity
</listItem>
<page confidence="0.976214">
497
</page>
<sectionHeader confidence="0.512945" genericHeader="method">
3. Linking remaining chunks
</sectionHeader>
<subsectionHeader confidence="0.996044">
3.1 Lexical Link Matrix
</subsectionHeader>
<bodyText confidence="0.9999717">
For each source and target word, all translations
for the word form and the lemma are retrieved
from the bilingual dictionary. In the process of
building the lexical link matrix, function words are
neglected. For all content words, a lexical link is
created if a source word occurs in the set of pos-
sible translations of a target word, or if a target
word occurs in the set of possible translations of
the source words. Identical strings in source and
target language are also linked.
</bodyText>
<subsectionHeader confidence="0.999908">
3.2 Linking Anchor chunks
</subsectionHeader>
<bodyText confidence="0.999964">
Candidate anchor chunks are selected based on the
information available in the lexical link matrix.
The candidate target chunk is built by concatenat-
ing all target chunks from a begin index until an
end index. The begin index points to the first target
chunk with a lexical link to the source chunk un-
der consideration. The end index points to the last
target chunk with a lexical link to the source chunk
under consideration. This way, 1:1 and 1:n candi-
date target chunks are built. The process of select-
ing candidate chunks as described above, is per-
formed a second time starting from the target sen-
tence. This way, additional n:1 candidates are con-
structed. For each selected candidate pair, a simi-
larity test is performed. Chunks are considered to
be similar if at least a certain percentage of words
of source and target chunk(s) are either linked by
means of a lexical link or can be linked on the basis
of corresponding part-of-speech codes. The per-
centage of words that have to be linked was em-
pirically set at 85%.
</bodyText>
<subsectionHeader confidence="0.999892">
3.3 Linking Remaining Chunks
</subsectionHeader>
<bodyText confidence="0.989923735294118">
In a second step, chunks consisting of one function
word – mostly punctuation marks and conjunc-
tions – are linked based on corresponding part-of-
speech codes if their left or right neighbour on the
diagonal is an anchor chunk. Corresponding final
punctuation marks are also linked.
In a final step, additional candidates are con-
structed by selecting non-anchor chunks in the
source and target sentence that have correspond-
ing left and right anchor chunks as neigbours. The
anchor chunks of the first step are used as contex-
tual information to link n:m chunks or chunks for
which no lexical link was found in the lexical link
matrix.
In Figure 1, the chunks [Fr: gradient] – [En:
gradient] and the final punctuation mark have been
retrieved in the first step as anchor chunk. In the
last step, the n:m chunk [Fr: de remont´ee p´edale
d’ embrayage] – [En: of rising of the clutch pedal]
is selected as candidate anchor chunk because it is
enclosed within anchor chunks.
Figure 1: n:m candidate chunk: ’A’ stands for an-
chor chunks, ’L’ for lexical links, ’P’ for words
linked on the basis of corresponding PoS codes
and ’R’ for words linked by language-dependent
rules.
As the contextual clues (the left and right neig-
bours of the additional candidate chunks are an-
chor chunks) provide some extra indication that
the chunks can be linked, the similarity test for
the final candidates was somewhat relaxed: the
percentage of words that have to be linked was
lowered to 0.80 and a more relaxed PoS matching
function was used.
</bodyText>
<subsectionHeader confidence="0.945174">
3.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.99997875">
To test our alignment module, we manually indi-
cated all translational correspondences in the three
test corpora. We used the evaluation methodology
of Och and Ney (2003) to evaluate the system’s
performance. They distinguished sure alignments
(S) and possible alignments (P) and introduced the
following redefined precision and recall measures
(where A refers to the set of alignments):
</bodyText>
<equation confidence="0.9948565">
precision = |A ∩ P ||A ∩ S|
|A |, recall = |S |(1)
</equation>
<bodyText confidence="0.904024">
and the alignment error rate (AER):
</bodyText>
<equation confidence="0.9941905">
AER(S, P; A) = 1 − |A ∩ P |+ |A ∩ S |(2)
|A |+ |S|
</equation>
<page confidence="0.96978">
498
</page>
<bodyText confidence="0.99884375">
Table 3 shows the alignment results for the three
language pairs. (Macken et al., 2008) showed that
the results for French-English were competitive to
state-of-the-art alignment systems.
</bodyText>
<table confidence="0.8609424">
SHORT MEDIUM LONG
p r e p r e p r e
Italian .99 .93 .04 .95 .89 .08 .95 .89 .07
English .97 .91 .06 .95 .85 .10 .92 .85 .12
Dutch .96 .83 .11 .87 .73 .20 .87 .67 .24
</table>
<tableCaption confidence="0.99521">
Table 3: Precision (p), recall (r) and alignment er-
</tableCaption>
<bodyText confidence="0.997648411764706">
ror rate (e) for our sub-sentential alignment sys-
tem evaluated on French-Italian, French-English
and French-Dutch
As expected, the results show that the align-
ment quality is closely related to the similarity be-
tween languages. As shown in example (1), Ital-
ian and French are syntactically almost identical
– and hence easier to align, English and French
are still close but show some differences (e.g dif-
ferent compounding strategy and word order) and
French and Dutch present a very different lan-
guage structure (e.g. in Dutch the different com-
pound parts are not separated by spaces, separable
verbs, i.e. verbs with prefixes that are stripped off,
occur frequently (losmaken as an infinitive versus
maak los in the conjugated forms) and a different
word order is adopted).
</bodyText>
<figureCaption confidence="0.4342985">
(1) Fr: d´eclipper le renvoi de ceinture de s´ecurit´e.
(En: unclip the mounting of the belt of safety)
It: sganciare il dispositivo di riavvolgimento della
cintura di sicurezza.
</figureCaption>
<bodyText confidence="0.974159">
(En: unclip the mounting of the belt of satefy)
En: unclip the seat belt mounting.
Du: maak de oprolautomaat van de autogordel los.
(En: clip the mounting of the seat-belt un)
We tried to improve the low recall for French-
Dutch by adding a decompounding module to our
alignment system. In case the target word does
not have a lexical correspondence in the source
sentence, we decompose the Dutch word into its
meaningful parts and look for translations of the
compound parts. This implies that, without de-
compounding, in example 2 only the correspon-
dences doublure – binnenpaneel, arc – dakverste-
viging and arri`ere – achter will be found. By de-
composing the compound into its meaningful parts
(binnenpaneel = binnen + paneel, dakversteviging
= dak + versteviging) and retrieving the lexical
links for the compound parts, we were able to link
the missing correspondence: pavillon – dakverste-
viging.
(2) Fr: doublure arc pavillon arri`ere.
(En: rear roof arch lining)
Du: binnenpaneel dakversteviging achter.
We experimented with the decompounding mod-
ule of (Vandeghinste, 2008), which is based on
the Celex lexical database (Baayen et al., 1993).
The module, however, did not adapt well to the
highly technical automotive domain, which is re-
flected by its low recall and the low confidence
values for many technical terms. In order to adapt
the module to the automotive domain, we imple-
mented a domain-dependent extension to the de-
compounding module on the basis of the devel-
opment corpus. This was done by first running the
decompounding module on the Dutch sentences to
construct a list with possible compound heads, be-
ing valid compound parts in Dutch. This list was
updated by inspecting the decompounding results
on the development corpus. While decomposing,
we go from right to left and strip off the longest
valid part that occurs in our preconstructed list
with compound parts and we repeat this process
on the remaining part of the word until we reach
the beginning of the word.
Table 4 shows the impact of the decompound-
ing module, which is more prominent for short
and medium sentences than for long sentences. A
superficial error analysis revealed that long sen-
tences combine a lot of other French – Dutch
alignment difficulties next to the decompounding
problem (e.g. different word order and separable
verbs).
</bodyText>
<table confidence="0.9406104">
SHORT MEDIUM LONG
p r e p r e p r e
Dutch
no dec .95 .76 .16 .88 .67 .24 .88 .64 .26
dec .96 .83 .11 .87 .73 .20 .87 .67 .24
</table>
<tableCaption confidence="0.756245333333333">
Table 4: Precision (p), recall (r) and alignment er-
ror rate (e) for French-Dutch without and with de-
compounding information
</tableCaption>
<sectionHeader confidence="0.991792" genericHeader="method">
4 Term extraction module
</sectionHeader>
<bodyText confidence="0.999804">
As described in Section 1, we generate candi-
date terms from the aligned phrases. We believe
these anchor chunks offer a more flexible approach
</bodyText>
<page confidence="0.996681">
499
</page>
<bodyText confidence="0.999922875">
because the method is language-pair independent
and is not restricted to a predefined set of PoS pat-
terns to identify valid candidate terms. In a second
step, we use a general-purpose corpus and the n-
gram frequency of the automotive corpus to deter-
mine the specificity of the candidate terms.
The candidate terms are generated in several
steps, as illustrated below for example (3).
</bodyText>
<listItem confidence="0.9341965">
(3) Fr: Tableau de commande de climatisation automa-
tique
En: Automatic air conditioning control panel
1. Selection of all anchor chunks (minimal
chunks that could be linked together) and lex-
ical links within the anchor chunks:
</listItem>
<table confidence="0.391634">
tableau de commande control panel
climatisation air conditioning
commande control
tableau panel
2. combine each NP + PP chunk:
commande de climatisa-
tion automatique
tableau de commande de
climatisation automatique
</table>
<listItem confidence="0.957525">
3. strip off the adjectives from the anchor
chunks:
</listItem>
<bodyText confidence="0.94957825">
commande de climatisa-
tion
tableau de commande de
climatisation
</bodyText>
<subsectionHeader confidence="0.997198">
4.1 Filtering candidate terms
</subsectionHeader>
<bodyText confidence="0.9983465">
To filter our candidate terms, we keep following
criteria in mind:
</bodyText>
<listItem confidence="0.999193428571428">
• each entry in the extracted lexicon should re-
fer to an object or action that is relevant for
the domain (notion of termhood that is used
to express “the degree to which a linguis-
tic unit is related to domain-specific context”
(Kageura and Umino, 1996))
• multiword terms should present a high de-
gree of cohesiveness (notion of unithood that
expresses the “degree of strength or stability
of syntagmatic combinations or collocations”
(Kageura and Umino, 1996))
• all term pairs should contain valid translation
pairs (translation quality is also taken into
consideration)
</listItem>
<bodyText confidence="0.999861">
To measure the termhood criterion and to fil-
ter out general vocabulary words, we applied
Log-Likelihood filters on the French single-word
terms. In order to filter on low unithood values,
we calculated the Mutual Expectation Measure for
the multiword terms in both source and target lan-
guage.
</bodyText>
<subsectionHeader confidence="0.420153">
4.1.1 Log-Likelihood Measure
</subsectionHeader>
<bodyText confidence="0.999977">
The Log-Likehood measure (LL) should allow us
to detect single word terms that are distinctive
enough to be kept in our bilingual lexicon (Daille,
1995). This metric considers word frequencies
weighted over two different corpora (in our case a
technical automotive corpus and the more general
purpose corpus “Le Monde”1), in order to assign
high LL-values to words having much higher or
lower frequencies than expected. We implemented
the formula for both the expected values and the
Log-Likelihood values as described by (Rayson
and Garside, 2000).
Manual inspection of the Log-Likelihood fig-
ures confirmed our hypothesis that more domain-
specific terms in our corpus were assigned high
LL-values. We experimentally defined the thresh-
old for Log-Likelihood values corresponding to
distinctive terms on our development corpus. Ex-
ample (4) shows some translation pairs which are
filtered out by applying the LL threshold.
</bodyText>
<figure confidence="0.459889444444444">
(4) Fr: cependant – En: however – It: tuttavia – Du:
echter
Fr: choix – En: choice – It: scelta – Du: keuze
Fr: continuer – En: continue – It: continuare – Du:
verdergaan
Fr: cadre – En: frame – It: cornice – Du: frame
(erroneous filtering)
Fr: all´egement – En: lightening – It: alleggerire –
Du: verlichten (erroneous filtering)
</figure>
<subsectionHeader confidence="0.766498">
4.1.2 Mutual Expectation Measure
</subsectionHeader>
<bodyText confidence="0.999816222222222">
The Mutual Expectation measure as described by
Dias and Kaalep (2003) is used to measure the
degree of cohesiveness between words in a text.
This way, candidate multiword terms whose com-
ponents do not occur together more often than ex-
pected by chance get filtered out. In a first step,
we have calculated all n-gram frequencies (up to
8-grams) for our four automotive corpora and then
used these frequencies to derive the Normalised
</bodyText>
<footnote confidence="0.859587">
1http://catalog.elra.info/product info.php?products id=438
</footnote>
<bodyText confidence="0.500196714285714">
automatic air condition-
ing control
automatic air condition-
ing control panel
air conditioning control
air conditioning control
panel
</bodyText>
<page confidence="0.915099">
500
</page>
<bodyText confidence="0.998126">
Expectation (NE) values for all multiword entries,
as specified by the formula of Dias and Kaalep:
</bodyText>
<equation confidence="0.97925">
prob(n − gram)
NE = (3)
n E prob(n − 1 − grams)
</equation>
<bodyText confidence="0.981727592592593">
The Normalised Expectation value expresses the
cost, in terms of cohesiveness, of the possible loss
of one word in an n-gram. The higher the fre-
quency of the n-1-grams, the smaller the NE, and
the smaller the chance that it is a valid multiword
expression. The final Mutual Expectation (ME)
value is then obtained by multiplying the NE val-
ues by the n-gram frequency. This way, the Mu-
tual Expectation between n words in a multiword
expression is based on the Normalised Expecta-
tion and the relative frequency of the n-gram in
the corpus.
We calculated Mutual Expectation values for all
candidate multiword term pairs and filtered out in-
complete or erroneous terms having ME values be-
low an experimentally set threshold (being below
0.005 for both source and target multiword or be-
low 0.0002 for one of the two multiwords in the
translation pair). The following incomplete can-
didate terms in example (5) were filtered out by
applying the ME filter:
(5) Fr: fermeture embout - En: end closing - It:
chiusura terminale - Du: afsluiting deel
(should be: Fr: fermeture embout de brancard - En:
chassis member end closing panel - It: chiusura ter-
minale del longherone - Du: afsluiting voorste deel
van langsbalk)
</bodyText>
<subsectionHeader confidence="0.94569">
4.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.99999195">
The terminology extraction module was tested on
all sentences from the three test corpora. The out-
put was manually labeled and the annotators were
asked to judge both the translational quality of the
entry (both languages should refer to the same ref-
erential unit) as well as the relevance of the term
in an automotive context. Three labels were used:
OK (valid entry), NOK (not a valid entry) and
MAYBE (in case the annotator was not sure about
the relevance of the term).
First, the impact of the statistical filtering was
measured on the bilingual term extraction. Sec-
ondly, we compared the output of our system with
the output of a commercial bilingual terminology
extraction module and with the output of a set of
standard monolingual term extraction modules.
Since the annotators labeled system output, the
reported scores all refer to precision scores. In fu-
ture work, we will develop a gold standard corpus
which will enable us to also calculate recall scores.
</bodyText>
<subsectionHeader confidence="0.816464">
4.2.1 Impact of filtering
</subsectionHeader>
<bodyText confidence="0.99994625">
Table 5 shows the difference in performance for
both single and multiword terms with and with-
out filtering. Single-word filtering seems to have a
bigger impact on the results than multiword filter-
ing. This can be explained by the fact that our can-
didate multiword terms are generated from anchor
chunks (chunks aligned with a very high preci-
sion) that already answer to strict syntactical con-
straints. The annotators also mentioned the diffi-
culty of judging the relevance of single word terms
for the automotive domain (no clear distinction be-
tween technical and common vocabulary).
</bodyText>
<table confidence="0.978867545454545">
NOT FILTERED FILTERED
OK NOK MAY OK NOK MAY
FR-EN
Sing w 82% 17% 1% 86.5% 12% 1.5%
Mult w 81% 16.5% 2.5% 83% 14.5% 2.5%
FR-IT
Sing w 80.5% 19% 0.5% 84.5% 15% 0.5%
Mult w 69% 30% 1.0% 72% 27% 1.0%
FR-DU
Sing w 72% 25% 3% 75% 22% 3%
Mult w 83% 15% 2% 84% 14% 2%
</table>
<tableCaption confidence="0.987363">
Table 5: Impact of statistical filters on Single and
Multiword terminology extraction
</tableCaption>
<subsectionHeader confidence="0.417138">
4.2.2 Comparison with bilingual terminology
extraction
</subsectionHeader>
<bodyText confidence="0.999919266666667">
We compared the three filtered bilingual lexi-
cons (French versus English-Italian-Dutch) with
the output of a commercial state-of-the-art termi-
nology extraction program SDL MultiTerm Ex-
tract2. MultiTerm is a statistically based system
that first generates a list of candidate terms in the
source language (French in our case) and then
looks for translations of these terms in the target
language. We ran MultiTerm with its default set-
tings (default noise-silence threshold, default stop-
word list, etc.) on a large portion of our parallel
corpus that also contains all test sentences3. We
ran our system (where term extraction happens on
a sentence per sentence basis) on the three test
sets.
</bodyText>
<footnote confidence="0.99744975">
2www.translationzone.com/en/products/sdlmultitermextract
370,000 sentences seemed to be the maximum size of
the corpus that could be easily processed within MultiTerm
Extract.
</footnote>
<page confidence="0.99648">
501
</page>
<tableCaption confidence="0.522119">
Table 6 shows that even after applying statistical
filters, our term extraction module retains a much
higher number of candidate terms than MultiTerm.
</tableCaption>
<table confidence="0.997749">
FR-EN 4052 3386 1831
FR-IT 4381 3601 1704
FR-DU 3285 2662 1637
</table>
<tableCaption confidence="0.95656525">
Table 6: Number of terms before and after apply-
ing Log-Likelihood and ME filters
Table 7 lists the results of both systems and
shows the differences in performance for single
</tableCaption>
<listItem confidence="0.893">
and multiword terms. Following observations can
be made:
• The performance of both systems is compa-
rable for the extraction of single word terms,
but our system clearly outperforms Multi-
Term when it comes to the extraction of more
complex multiword terms.
• Although the alignment results for French-
</listItem>
<bodyText confidence="0.8803569375">
Italian were very good, we do not achieve
comparable results for Italian multiword ex-
traction. This can be due to the fact that the
syntactic structure is very similar in both lan-
guages. As a result, smaller syntactic chunks
are linked. However one can argue that, just
because of the syntactic resemblance of both
languages, the need for complex multiword
terms is less prominent in closely related lan-
guages as translators can just paste smaller
noun phrases together in the same order in
both languages. If we take the following ex-
ample for instance:
d´eposer – l’ embout – de brancard
togliere – il terminale – del sotto-
porta
</bodyText>
<listItem confidence="0.766422166666667">
we can recompose the larger compound
l’embout de brancard or il terminale del sot-
toporta by translating the smaller parts in the
same order (l’embout – il terminale and de
brancard – del sottoporta
• Despite the worse alignment results for
</listItem>
<bodyText confidence="0.997485545454545">
Dutch, we achieve good accuracy results on
the multiword term extraction. Part of that
can be explained by the fact that French and
Dutch use a different compounding strategy:
whereas French compounds are created by
concatenating prepositional phrases, Dutch
usually tends to concatenate noun phrases
(even without inserting spaces between the
different compound parts). This way we can
extract larger Dutch chunks that correspond
to several French chunks, for instance:
</bodyText>
<table confidence="0.883944117647059">
Fr: feu r´egulateur – de pression
carburant.
Du: brandstofdrukregelaar.
ANCHOR CHUNK APPROACH MULTITERM
OK NOK MAY OK NOK MAY
FR-EN
Sing w 86.5% 12% 1.5% 77% 21% 2%
Mult w 83% 14.5% 2.5% 47% 51% 2%
Total 84.5% 13.5% 2 % 64% 34% 2%
FR-IT
Sing w 84.5% 15% 0.5% 85% 14% 1%
Mult w 72% 27% 1.0% 65% 34% 1%
Total 77.5% 22% 1% 76.5% 22.5% 1%
FR-DU
Sing w 75% 22% 3% 64.5% 33% 2.5%
Mult w 84% 14% 2% 49.5% 49.5% 1%
Total 79.5% 20% 2.5% 58% 40% 2%
</table>
<tableCaption confidence="0.991994">
Table 7: Precision figures for our term extraction
system and for SDL MultiTerm Extract
</tableCaption>
<subsectionHeader confidence="0.9381835">
4.2.3 Comparison with monolingual
terminology extraction
</subsectionHeader>
<bodyText confidence="0.999798923076923">
In order to have insights in the performance of
our terminology extraction module, without con-
sidering the validity of the bilingual terminology
pairs, we contrasted our extracted English terms
with state-of-the art monolingual terminology sys-
tems. As we want to include both single words and
multiword terms in our technical automotive lex-
icon, we only considered ATR systems which ex-
tract both categories. We used the implementation
for these systems from (Zhang et al., 2008) which
is freely available at1.
We compared our system against 5 other ATR
systems:
</bodyText>
<listItem confidence="0.932627375">
1. Baseline system (Simple Term Frequency)
2. Weirdness algorithm (Ahmad et al., 2007)
which compares term frequencies in the tar-
get and reference corpora
3. C-value (Frantzi and Ananiadou, 1999)
which uses term frequencies as well as
unit-hood filters (to measure the collocation
strength of units)
</listItem>
<footnote confidence="0.952413">
1http://www.dcs.shef.ac.uk/˜ziqizhang/resources/tools/
</footnote>
<table confidence="0.906085">
# Extracted terms
MultiTerm
# Terms after filtering
</table>
<page confidence="0.981954">
502
</page>
<listItem confidence="0.604165333333333">
4. Glossex (Kozakov et al., 2004) which uses
term frequency information from both the tar-
get and reference corpora and compares term
frequencies with frequencies of the multi-
word components
5. TermExtractor (Sclano and Velardi, 2007)
</listItem>
<bodyText confidence="0.97899156">
which is comparable to Glossex but intro-
duces the ”domain consensus” which ”sim-
ulates the consensus that a term must gain in
a community before being considered a rele-
vant domain term”
For all of the above algorithms, the input auto-
motive corpus is PoS tagged and linguistic filters
(selecting nouns and noun phrases) are applied to
extract candidate terms. In a second step, stop-
words are removed and the same set of extracted
candidate terms (1105 single words and 1341 mul-
tiwords) is ranked differently by each algorithm.
To compare the performance of the ranking algo-
rithms, we selected the top terms (300 single and
multiword terms) produced by all algorithms and
compared these with our top candidate terms that
are ranked by descending Log-likelihood (calcu-
lated on the BNC corpus) and Mutual Expectation
values. Our filtered list of unique English automo-
tive terms contains 1279 single words and 1879
multiwords in total. About 10% of the terms do
not overlap between the two term lists. All can-
didate terms have been manually labeled by lin-
guists. Table 8 shows the results of this compari-
son.
</bodyText>
<table confidence="0.950370333333333">
SINGLE WORD TERMS MULTIWORD TERMS
OK NOK MAY OK NOK MAY
Baseline 80% 19.5% 0.5% 84.5% 14.5% 1%
Weirdness 95.5% 3.5% 1% 96% 2.5% 1.5%
C-value 80% 19.5% 0.5% 94% 5% 1%
Glossex 94.5% 4.5% 1% 85.5% 14% 0.5%
TermExtr. 85% 15% 0% 79% 20% 1%
AC 85.5% 14.5% 0% 90% 8% 2%
approach
</table>
<tableCaption confidence="0.7876755">
Table 8: Results for monolingual Term Extraction
on the English part of the automotive corpus
</tableCaption>
<bodyText confidence="0.996885333333334">
Although our term extraction module has been tai-
lored towards bilingual term extraction, the results
look competitive to monolingual state-of-the-art
ATR systems. If we compare these results with
our bilingual term extraction results, we can ob-
serve that we gain more in performance for mul-
tiwords than for single words, which might mean
that the filtering and ranking based on the Mutual
Expectation works better than the Log-Likelihood
ranking.
An error analysis of the results leads to the fol-
lowing insights:
</bodyText>
<listItem confidence="0.867707571428571">
• All systems suffer from partial retrieval of
complex multiwords (e.g. ATR management
ecu instead of engine management ecu, AC
approach chassis leg end piece closure in-
stead of chassis leg end piece closure panel).
• We manage to extract nice sets of multiwords
that can be associated with a given concept,
which could be nice for automatic ontology
population (e.g. AC approach gearbox cas-
ing, gearbox casing earth, gearbox casing
earth cable, gearbox control, gearbox control
cables, gearbox cover, gearbox ecu, gearbox
ecu initialisation procedure, gearbox fixing,
gearbox lower fixings, gearbox oil, gearbox
oil cooler protective plug).
• Sometimes smaller compounds are not ex-
tracted because they belong to the same syn-
tactic chunk (E.g we extract passenger com-
partment assembly, passenger compartment
safety, passenger compartment side panel,
etc. but not passenger compartment as such).
</listItem>
<sectionHeader confidence="0.981523" genericHeader="conclusions">
5 Conclusions and further work
</sectionHeader>
<bodyText confidence="0.9999580625">
We presented a bilingual terminology extraction
module that starts from sub-sentential alignments
in parallel corpora and applied it on three differ-
ent parallel corpora that are part of the same auto-
motive corpus. Comparisons with standard termi-
nology extraction programs show an improvement
of up to 20% for bilingual terminology extraction
and competitive results (85% to 90% accuracy) for
monolingual terminology extraction. In the near
future we want to experiment with other filtering
techniques, especially to measure the domain dis-
tinctiveness of terms and work on a gold standard
for measuring recall next to accuracy. We will
also investigate our approach on languages which
are more distant from each other (e.g. French –
Swedish).
</bodyText>
<sectionHeader confidence="0.998842" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998785">
We would like to thank PSA Peugeot Citro¨en for
funding this project.
</bodyText>
<page confidence="0.99781">
503
</page>
<sectionHeader confidence="0.995895" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999786097826087">
K. Ahmad, L. Gillam, and L. Tostevin. 2007. Uni-
versity of surrey participation in trec8: Weirdness
indexing for logical document extrapolation and
rerieval (wilder). In Proceedings of the Eight Text
REtrieval Conference (TREC-8).
S. Ananiadou. 1994. A methodology for automatic
term recognition. In Proceedings of the 15th con-
ference on computational linguistics, pages 1034–
1038.
R.H. Baayen, R. Piepenbrock, and H. van Rijn. 1993.
The celex lexical database on cd-rom.
I. Dagan and K. Church. 1994. Termight: identifying
and translating technical terminology. In Proceed-
ings of Applied Language Processing, pages 34–40.
B. Daille. 1995. Study and implementation of com-
bined techniques for automatic extraction of termi-
nology. In J. Klavans and P. Resnik, editors, The
Balancing Act: Combining Symbolic and Statistical
Approaches to Language, pages 49–66. MIT Press,
Cambridge, Massachusetts; London, England.
G. Dias and H. Kaalep. 2003. Automatic extraction
of multiword units for estonian: Phrasal verbs. Lan-
guages in Development, 41:81–91.
K.T. Frantzi and S. Ananiadou. 1999. the c-value/nc-
value domain independent method for multiword
term extraction. journal of Natural Language Pro-
cessing, 6(3):145–180.
K. Kageura and B. Umino. 1996. Methods of au-
tomatic term recognition: a review. Terminology,
3(2):259–289.
L. Kozakov, Y. Park, T.-H Fin, Y. Drissi, Y.N. Do-
ganata, and T. Confino. 2004. Glossary extraction
and knowledge in large organisations via semantic
web technologies. In Proceedings of the 6th Inter-
national Semantic Web Conference and he 2nd Asian
Semantic Web Conference (Se-mantic Web Chal-
lenge Track).
J. Kupiec. 1993. An algorithm for finding noun phrase
correspondences in bilingual corpora. In Proceed-
ings of the 31st Annual Meeting of the Association
for Computational Linguistics.
L. Macken and W. Daelemans. 2009. Aligning lin-
guistically motivated phrases. In van Halteren H.
Verberne, S. and P.-A. Coppen, editors, Selected Pa-
pers from the 18th Computational Linguistics in the
Netherlands Meeting, pages 37–52, Nijmegen, The
Netherlands.
L. Macken, E. Lefever, and V. Hoste. 2008.
Linguistically-based sub-sentential alignment for
terminology extraction from a bilingual automotive
corpus. In Proceedings of the 22nd International
Conference on Computational Linguistics (Coling
2008), pages 529–536, Manchester, United King-
dom.
R. C. Moore. 2002. Fast and accurate sentence align-
ment of bilingual corpora. In Proceedings of the 5th
Conference of the Association for Machine Trans-
lation in the Americas, Machine Translation: from
research to real users, pages 135–244, Tiburon, Cal-
ifornia.
F. J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19–51.
P. Rayson and R. Garside. 2000. Comparing cor-
pora using frequency profiling. In Proceedings of
the workshop on Comparing Corpora, 38th annual
meeting of the Association for Computational Lin-
guistics (ACL 2000), pages 1–6.
H. Schmid. 1994. Probabilistic part-of-speech tagging
using decision trees. In International Conference on
New Methods in Language Processing, Manchester,
UK.
F. Sclano and P. Velardi. 2007. Termextractor: a web
application to learn the shared terminology of emer-
gent web communities. In Proceedings of the 3rd
International Conference on Interoperability for En-
terprise Software and Applications (I-ESA 2007).
A. Van den Bosch, G.J. Busser, W. Daelemans, and
S. Canisius. 2007. An efficient memory-based mor-
phosyntactic tagger and parser for dutch. In Selected
Papers of the 17th Computational Linguistics in the
Netherlands Meeting, pages 99–114, Leuven, Bel-
gium.
V. Vandeghinste. 2008. A Hybrid Modular Machine
Translation System. LoRe-MT: Low Resources Ma-
chine Translation. Ph.D. thesis, Centre for Compu-
tational Linguistics, KULeuven.
Z. Zhang, J. Iria, C. Brewster, and F. Ciravegna. 2008.
A comparative evaluation of term recognition algo-
rithms. In Proceedings of the sixth international
conference of Language Resources and Evaluation
(LREC 2008).
</reference>
<page confidence="0.998312">
504
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.043067">
<abstract confidence="0.43712725">Language-independent bilingual terminology extraction from a multilingual parallel corpus Lieve 2and Veronique 2 1LT3</abstract>
<affiliation confidence="0.988014">School of Translation Studies University College Ghent</affiliation>
<address confidence="0.9969075">Groot-Brittanni¨elaan 45 9000 Gent, Belgium</address>
<affiliation confidence="0.769066">of Applied Mathematics and Computer Science Ghent University</affiliation>
<address confidence="0.9986385">Krijgslaan281-S9 9000 Gent, Belgium</address>
<email confidence="0.85036">Lieve.Macken,</email>
<abstract confidence="0.99906324">We present a language-pair independent terminology extraction module that is based on a sub-sentential alignment system that links linguistically motivated phrases in parallel texts. Statistical filters are applied on the bilingual list of candidate terms that is extracted from the alignment output. We compare the performance of both the alignment and terminology extraction module for three different language pairs (French-English, French-Italian and French-Dutch) and highlight languagepair specific problems (e.g. different compounding strategy in French and Dutch). Comparisons with standard terminology extraction programs show an improvement of up to 20% for bilingual terminology extraction and competitive results (85% to 90% accuracy) for monolingual terminology extraction, and reveal that the linguistically based alignment module is particularly well suited for the extraction of complex multiword terms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Ahmad</author>
<author>L Gillam</author>
<author>L Tostevin</author>
</authors>
<title>University of surrey participation in trec8: Weirdness indexing for logical document extrapolation and rerieval (wilder).</title>
<date>2007</date>
<booktitle>In Proceedings of the Eight Text REtrieval Conference (TREC-8).</booktitle>
<contexts>
<context position="26899" citStr="Ahmad et al., 2007" startWordPosition="4395" endWordPosition="4398">the performance of our terminology extraction module, without considering the validity of the bilingual terminology pairs, we contrasted our extracted English terms with state-of-the art monolingual terminology systems. As we want to include both single words and multiword terms in our technical automotive lexicon, we only considered ATR systems which extract both categories. We used the implementation for these systems from (Zhang et al., 2008) which is freely available at1. We compared our system against 5 other ATR systems: 1. Baseline system (Simple Term Frequency) 2. Weirdness algorithm (Ahmad et al., 2007) which compares term frequencies in the target and reference corpora 3. C-value (Frantzi and Ananiadou, 1999) which uses term frequencies as well as unit-hood filters (to measure the collocation strength of units) 1http://www.dcs.shef.ac.uk/˜ziqizhang/resources/tools/ # Extracted terms MultiTerm # Terms after filtering 502 4. Glossex (Kozakov et al., 2004) which uses term frequency information from both the target and reference corpora and compares term frequencies with frequencies of the multiword components 5. TermExtractor (Sclano and Velardi, 2007) which is comparable to Glossex but introd</context>
</contexts>
<marker>Ahmad, Gillam, Tostevin, 2007</marker>
<rawString>K. Ahmad, L. Gillam, and L. Tostevin. 2007. University of surrey participation in trec8: Weirdness indexing for logical document extrapolation and rerieval (wilder). In Proceedings of the Eight Text REtrieval Conference (TREC-8).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ananiadou</author>
</authors>
<title>A methodology for automatic term recognition.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th conference on computational linguistics,</booktitle>
<pages>1034--1038</pages>
<contexts>
<context position="1686" citStr="Ananiadou, 1994" startWordPosition="229" endWordPosition="230">nt of up to 20% for bilingual terminology extraction and competitive results (85% to 90% accuracy) for monolingual terminology extraction, and reveal that the linguistically based alignment module is particularly well suited for the extraction of complex multiword terms. 1 Introduction Automatic Term Recognition (ATR) systems are usually categorized into two main families. On the one hand, the linguistically-based or rule-based approaches use linguistic information such as PoS tags, chunk information, etc. to filter out stop words and restrict candidate terms to predefined syntactic patterns (Ananiadou, 1994), (Dagan and Church, 1994). On the other hand, the statistical corpus-based approaches select n-gram sequences as candidate terms that are filtered by means of statistical measures. More recent ATR systems use hybrid approaches that combine both linguistic and statistical information (Frantzi and Ananiadou, 1999). Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). We present an alternative approach that generates can</context>
</contexts>
<marker>Ananiadou, 1994</marker>
<rawString>S. Ananiadou. 1994. A methodology for automatic term recognition. In Proceedings of the 15th conference on computational linguistics, pages 1034– 1038.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Baayen</author>
<author>R Piepenbrock</author>
<author>H van Rijn</author>
</authors>
<title>The celex lexical database on cd-rom.</title>
<date>1993</date>
<marker>Baayen, Piepenbrock, van Rijn, 1993</marker>
<rawString>R.H. Baayen, R. Piepenbrock, and H. van Rijn. 1993. The celex lexical database on cd-rom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>K Church</author>
</authors>
<title>Termight: identifying and translating technical terminology.</title>
<date>1994</date>
<booktitle>In Proceedings of Applied Language Processing,</booktitle>
<pages>34--40</pages>
<contexts>
<context position="1712" citStr="Dagan and Church, 1994" startWordPosition="231" endWordPosition="234"> bilingual terminology extraction and competitive results (85% to 90% accuracy) for monolingual terminology extraction, and reveal that the linguistically based alignment module is particularly well suited for the extraction of complex multiword terms. 1 Introduction Automatic Term Recognition (ATR) systems are usually categorized into two main families. On the one hand, the linguistically-based or rule-based approaches use linguistic information such as PoS tags, chunk information, etc. to filter out stop words and restrict candidate terms to predefined syntactic patterns (Ananiadou, 1994), (Dagan and Church, 1994). On the other hand, the statistical corpus-based approaches select n-gram sequences as candidate terms that are filtered by means of statistical measures. More recent ATR systems use hybrid approaches that combine both linguistic and statistical information (Frantzi and Ananiadou, 1999). Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). We present an alternative approach that generates candidate terms directly from</context>
</contexts>
<marker>Dagan, Church, 1994</marker>
<rawString>I. Dagan and K. Church. 1994. Termight: identifying and translating technical terminology. In Proceedings of Applied Language Processing, pages 34–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Daille</author>
</authors>
<title>Study and implementation of combined techniques for automatic extraction of terminology.</title>
<date>1995</date>
<booktitle>The Balancing Act: Combining Symbolic and Statistical Approaches to Language,</booktitle>
<pages>49--66</pages>
<editor>In J. Klavans and P. Resnik, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts; London, England.</location>
<contexts>
<context position="17659" citStr="Daille, 1995" startWordPosition="2867" endWordPosition="2868"> (Kageura and Umino, 1996)) • all term pairs should contain valid translation pairs (translation quality is also taken into consideration) To measure the termhood criterion and to filter out general vocabulary words, we applied Log-Likelihood filters on the French single-word terms. In order to filter on low unithood values, we calculated the Mutual Expectation Measure for the multiword terms in both source and target language. 4.1.1 Log-Likelihood Measure The Log-Likehood measure (LL) should allow us to detect single word terms that are distinctive enough to be kept in our bilingual lexicon (Daille, 1995). This metric considers word frequencies weighted over two different corpora (in our case a technical automotive corpus and the more general purpose corpus “Le Monde”1), in order to assign high LL-values to words having much higher or lower frequencies than expected. We implemented the formula for both the expected values and the Log-Likelihood values as described by (Rayson and Garside, 2000). Manual inspection of the Log-Likelihood figures confirmed our hypothesis that more domainspecific terms in our corpus were assigned high LL-values. We experimentally defined the threshold for Log-Likeli</context>
</contexts>
<marker>Daille, 1995</marker>
<rawString>B. Daille. 1995. Study and implementation of combined techniques for automatic extraction of terminology. In J. Klavans and P. Resnik, editors, The Balancing Act: Combining Symbolic and Statistical Approaches to Language, pages 49–66. MIT Press, Cambridge, Massachusetts; London, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Dias</author>
<author>H Kaalep</author>
</authors>
<title>Automatic extraction of multiword units for estonian: Phrasal verbs.</title>
<date>2003</date>
<booktitle>Languages in Development,</booktitle>
<pages>41--81</pages>
<contexts>
<context position="18860" citStr="Dias and Kaalep (2003)" startWordPosition="3056" endWordPosition="3059">eshold for Log-Likelihood values corresponding to distinctive terms on our development corpus. Example (4) shows some translation pairs which are filtered out by applying the LL threshold. (4) Fr: cependant – En: however – It: tuttavia – Du: echter Fr: choix – En: choice – It: scelta – Du: keuze Fr: continuer – En: continue – It: continuare – Du: verdergaan Fr: cadre – En: frame – It: cornice – Du: frame (erroneous filtering) Fr: all´egement – En: lightening – It: alleggerire – Du: verlichten (erroneous filtering) 4.1.2 Mutual Expectation Measure The Mutual Expectation measure as described by Dias and Kaalep (2003) is used to measure the degree of cohesiveness between words in a text. This way, candidate multiword terms whose components do not occur together more often than expected by chance get filtered out. In a first step, we have calculated all n-gram frequencies (up to 8-grams) for our four automotive corpora and then used these frequencies to derive the Normalised 1http://catalog.elra.info/product info.php?products id=438 automatic air conditioning control automatic air conditioning control panel air conditioning control air conditioning control panel 500 Expectation (NE) values for all multiword</context>
</contexts>
<marker>Dias, Kaalep, 2003</marker>
<rawString>G. Dias and H. Kaalep. 2003. Automatic extraction of multiword units for estonian: Phrasal verbs. Languages in Development, 41:81–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K T Frantzi</author>
<author>S Ananiadou</author>
</authors>
<title>the c-value/ncvalue domain independent method for multiword term extraction.</title>
<date>1999</date>
<journal>journal of Natural Language Processing,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="2000" citStr="Frantzi and Ananiadou, 1999" startWordPosition="272" endWordPosition="276">Recognition (ATR) systems are usually categorized into two main families. On the one hand, the linguistically-based or rule-based approaches use linguistic information such as PoS tags, chunk information, etc. to filter out stop words and restrict candidate terms to predefined syntactic patterns (Ananiadou, 1994), (Dagan and Church, 1994). On the other hand, the statistical corpus-based approaches select n-gram sequences as candidate terms that are filtered by means of statistical measures. More recent ATR systems use hybrid approaches that combine both linguistic and statistical information (Frantzi and Ananiadou, 1999). Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). We present an alternative approach that generates candidate terms directly from the aligned words and phrases in our parallel corpus. In a second step, we use frequency information of a general purpose corpus and the n-gram frequencies of the automotive corpus to determine the term specificity. Our approach is more flexible in the sense that we do not first generat</context>
<context position="27008" citStr="Frantzi and Ananiadou, 1999" startWordPosition="4412" endWordPosition="4415">ual terminology pairs, we contrasted our extracted English terms with state-of-the art monolingual terminology systems. As we want to include both single words and multiword terms in our technical automotive lexicon, we only considered ATR systems which extract both categories. We used the implementation for these systems from (Zhang et al., 2008) which is freely available at1. We compared our system against 5 other ATR systems: 1. Baseline system (Simple Term Frequency) 2. Weirdness algorithm (Ahmad et al., 2007) which compares term frequencies in the target and reference corpora 3. C-value (Frantzi and Ananiadou, 1999) which uses term frequencies as well as unit-hood filters (to measure the collocation strength of units) 1http://www.dcs.shef.ac.uk/˜ziqizhang/resources/tools/ # Extracted terms MultiTerm # Terms after filtering 502 4. Glossex (Kozakov et al., 2004) which uses term frequency information from both the target and reference corpora and compares term frequencies with frequencies of the multiword components 5. TermExtractor (Sclano and Velardi, 2007) which is comparable to Glossex but introduces the ”domain consensus” which ”simulates the consensus that a term must gain in a community before being </context>
</contexts>
<marker>Frantzi, Ananiadou, 1999</marker>
<rawString>K.T. Frantzi and S. Ananiadou. 1999. the c-value/ncvalue domain independent method for multiword term extraction. journal of Natural Language Processing, 6(3):145–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kageura</author>
<author>B Umino</author>
</authors>
<title>Methods of automatic term recognition: a review.</title>
<date>1996</date>
<journal>Terminology,</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="16865" citStr="Kageura and Umino, 1996" startWordPosition="2743" endWordPosition="2746">ditioning commande control tableau panel 2. combine each NP + PP chunk: commande de climatisation automatique tableau de commande de climatisation automatique 3. strip off the adjectives from the anchor chunks: commande de climatisation tableau de commande de climatisation 4.1 Filtering candidate terms To filter our candidate terms, we keep following criteria in mind: • each entry in the extracted lexicon should refer to an object or action that is relevant for the domain (notion of termhood that is used to express “the degree to which a linguistic unit is related to domain-specific context” (Kageura and Umino, 1996)) • multiword terms should present a high degree of cohesiveness (notion of unithood that expresses the “degree of strength or stability of syntagmatic combinations or collocations” (Kageura and Umino, 1996)) • all term pairs should contain valid translation pairs (translation quality is also taken into consideration) To measure the termhood criterion and to filter out general vocabulary words, we applied Log-Likelihood filters on the French single-word terms. In order to filter on low unithood values, we calculated the Mutual Expectation Measure for the multiword terms in both source and targ</context>
</contexts>
<marker>Kageura, Umino, 1996</marker>
<rawString>K. Kageura and B. Umino. 1996. Methods of automatic term recognition: a review. Terminology, 3(2):259–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kozakov</author>
<author>Y Park</author>
<author>T-H Fin</author>
<author>Y Drissi</author>
<author>Y N Doganata</author>
<author>T Confino</author>
</authors>
<title>Glossary extraction and knowledge in large organisations via semantic web technologies.</title>
<date>2004</date>
<booktitle>In Proceedings of the 6th International Semantic Web Conference and he 2nd Asian Semantic Web Conference (Se-mantic Web Challenge Track).</booktitle>
<contexts>
<context position="27257" citStr="Kozakov et al., 2004" startWordPosition="4444" endWordPosition="4447">tract both categories. We used the implementation for these systems from (Zhang et al., 2008) which is freely available at1. We compared our system against 5 other ATR systems: 1. Baseline system (Simple Term Frequency) 2. Weirdness algorithm (Ahmad et al., 2007) which compares term frequencies in the target and reference corpora 3. C-value (Frantzi and Ananiadou, 1999) which uses term frequencies as well as unit-hood filters (to measure the collocation strength of units) 1http://www.dcs.shef.ac.uk/˜ziqizhang/resources/tools/ # Extracted terms MultiTerm # Terms after filtering 502 4. Glossex (Kozakov et al., 2004) which uses term frequency information from both the target and reference corpora and compares term frequencies with frequencies of the multiword components 5. TermExtractor (Sclano and Velardi, 2007) which is comparable to Glossex but introduces the ”domain consensus” which ”simulates the consensus that a term must gain in a community before being considered a relevant domain term” For all of the above algorithms, the input automotive corpus is PoS tagged and linguistic filters (selecting nouns and noun phrases) are applied to extract candidate terms. In a second step, stopwords are removed a</context>
</contexts>
<marker>Kozakov, Park, Fin, Drissi, Doganata, Confino, 2004</marker>
<rawString>L. Kozakov, Y. Park, T.-H Fin, Y. Drissi, Y.N. Doganata, and T. Confino. 2004. Glossary extraction and knowledge in large organisations via semantic web technologies. In Proceedings of the 6th International Semantic Web Conference and he 2nd Asian Semantic Web Conference (Se-mantic Web Challenge Track).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kupiec</author>
</authors>
<title>An algorithm for finding noun phrase correspondences in bilingual corpora.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2231" citStr="Kupiec, 1993" startWordPosition="308" endWordPosition="309">t candidate terms to predefined syntactic patterns (Ananiadou, 1994), (Dagan and Church, 1994). On the other hand, the statistical corpus-based approaches select n-gram sequences as candidate terms that are filtered by means of statistical measures. More recent ATR systems use hybrid approaches that combine both linguistic and statistical information (Frantzi and Ananiadou, 1999). Most bilingual terminology extraction systems first identify candidate terms in the source language based on predefined source patterns, and then select translation candidates for these terms in the target language (Kupiec, 1993). We present an alternative approach that generates candidate terms directly from the aligned words and phrases in our parallel corpus. In a second step, we use frequency information of a general purpose corpus and the n-gram frequencies of the automotive corpus to determine the term specificity. Our approach is more flexible in the sense that we do not first generate candidate terms based on language-dependent predefined PoS patterns (e.g. for French, N N, N Prep N, and N Adj are typical patterns), but immediately link linguistically motivated phrases in our parallel corpus based on lexical c</context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>J. Kupiec. 1993. An algorithm for finding noun phrase correspondences in bilingual corpora. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Macken</author>
<author>W Daelemans</author>
</authors>
<title>Aligning linguistically motivated phrases. In</title>
<date>2009</date>
<booktitle>Selected Papers from the 18th Computational Linguistics in the Netherlands Meeting,</booktitle>
<pages>37--52</pages>
<editor>van Halteren H. Verberne, S. and P.-A. Coppen, editors,</editor>
<location>Nijmegen, The Netherlands.</location>
<contexts>
<context position="6222" citStr="Macken and Daelemans, 2009" startWordPosition="960" endWordPosition="963">e 2. We also created a development corpus with sentences of varying length to debug the linguistic processing and the alignment module as well as to define the thresholds for the statistical filtering of the candidate terms (see 4.1). # Words # Sentence pairs Short (&lt; 8 words) +- 9,000 823 Medium (8-19 words) +- 9,000 386 Long (&gt; 19 words) +- 9,000 180 Development corpus +-5,000 393 Table 2: Number of words and sentence pairs in the test and development corpora 3 Sub-sentential alignment module As the basis for our terminology extraction system, we used the sub-sentential alignment system of (Macken and Daelemans, 2009) that links linguistically motivated phrases in parallel texts based on lexical correspondences and syntactic similarity. In the first phase of this system, anchor chunks are linked, i.e. chunks that can be linked with a very high precision. We think these anchor chunks offer a valid and language-independent alternative to identify candidate terms based on predefined PoS patterns. As the automotive corpus contains rather literal translations, we expect that a high percentage of anchor chunks can be retrieved. Although the architecture of the sub-sentential alignment system is language-independ</context>
</contexts>
<marker>Macken, Daelemans, 2009</marker>
<rawString>L. Macken and W. Daelemans. 2009. Aligning linguistically motivated phrases. In van Halteren H. Verberne, S. and P.-A. Coppen, editors, Selected Papers from the 18th Computational Linguistics in the Netherlands Meeting, pages 37–52, Nijmegen, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Macken</author>
<author>E Lefever</author>
<author>V Hoste</author>
</authors>
<title>Linguistically-based sub-sentential alignment for terminology extraction from a bilingual automotive corpus.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>529--536</pages>
<location>Manchester, United Kingdom.</location>
<contexts>
<context position="5020" citStr="Macken et al., 2008" startWordPosition="759" endWordPosition="762">out the size of each parallel corpus can be found in table 1. Target Lang. # Sentence pairs # words French Italian 364,221 6,408,693 French English 363,651 7,305,151 French Dutch 364,311 7,100,585 Table 1: Number of sentence pairs and total number of words in the three parallel corpora 2.1 Preprocessing We PoS-tagged and lemmatized the French, English and Italian corpora with the freely available TreeTagger tool (Schmid, 1994) and we used TadPole (Van den Bosch et al., 2007) to annotate the Dutch corpus. In a next step, chunk information was added by a rule-based language-independent chunker (Macken et al., 2008) that contains distituency rules, which implies that chunk boundaries are added between two PoS codes that cannot occur in the same constituent. 2.2 Test and development corpus As we presume that sentence length has an impact on the alignment performance, and thus on term extraction, we created three test sets with varying sentence lengths. We distinguished short sentences (2-7 words), medium-length sentences (8- 19 words) and long sentences (&gt; 19 words). Each test corpus contains approximately 9,000 words; the number of sentence pairs per test set can be found in table 2. We also created a de</context>
<context position="11560" citStr="Macken et al., 2008" startWordPosition="1851" endWordPosition="1854">ion To test our alignment module, we manually indicated all translational correspondences in the three test corpora. We used the evaluation methodology of Och and Ney (2003) to evaluate the system’s performance. They distinguished sure alignments (S) and possible alignments (P) and introduced the following redefined precision and recall measures (where A refers to the set of alignments): precision = |A ∩ P ||A ∩ S| |A |, recall = |S |(1) and the alignment error rate (AER): AER(S, P; A) = 1 − |A ∩ P |+ |A ∩ S |(2) |A |+ |S| 498 Table 3 shows the alignment results for the three language pairs. (Macken et al., 2008) showed that the results for French-English were competitive to state-of-the-art alignment systems. SHORT MEDIUM LONG p r e p r e p r e Italian .99 .93 .04 .95 .89 .08 .95 .89 .07 English .97 .91 .06 .95 .85 .10 .92 .85 .12 Dutch .96 .83 .11 .87 .73 .20 .87 .67 .24 Table 3: Precision (p), recall (r) and alignment error rate (e) for our sub-sentential alignment system evaluated on French-Italian, French-English and French-Dutch As expected, the results show that the alignment quality is closely related to the similarity between languages. As shown in example (1), Italian and French are syntacti</context>
</contexts>
<marker>Macken, Lefever, Hoste, 2008</marker>
<rawString>L. Macken, E. Lefever, and V. Hoste. 2008. Linguistically-based sub-sentential alignment for terminology extraction from a bilingual automotive corpus. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 529–536, Manchester, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Fast and accurate sentence alignment of bilingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the 5th Conference of the Association for Machine Translation in the Americas, Machine</booktitle>
<pages>135--244</pages>
<location>Tiburon, California.</location>
<contexts>
<context position="7553" citStr="Moore, 2002" startWordPosition="1157" endWordPosition="1158">second, tools to generate additional linguistic information (PoS tagger, lemmatizer and a chunker). The sub-sentential alignment system takes as input sentence-aligned texts, together with the additional linguistic annotations for the source and the target texts. The source and target sentences are divided into chunks based on PoS information, and lexical correspondences are retrieved from a bilingual dictionary. In order to extract bilingual dictionaries from the three parallel corpora, we used the Perl implementation of IBM Model One that is part of the Microsoft Bilingual Sentence Aligner (Moore, 2002). In order to link chunks based on lexical clues and chunk similarity, the following steps are taken for each sentence pair: 1. Creation of the lexical link matrix 2. Linking chunks based on lexical correspondences and chunk similarity 497 3. Linking remaining chunks 3.1 Lexical Link Matrix For each source and target word, all translations for the word form and the lemma are retrieved from the bilingual dictionary. In the process of building the lexical link matrix, function words are neglected. For all content words, a lexical link is created if a source word occurs in the set of possible tra</context>
</contexts>
<marker>Moore, 2002</marker>
<rawString>R. C. Moore. 2002. Fast and accurate sentence alignment of bilingual corpora. In Proceedings of the 5th Conference of the Association for Machine Translation in the Americas, Machine Translation: from research to real users, pages 135–244, Tiburon, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="11113" citStr="Och and Ney (2003)" startWordPosition="1767" endWordPosition="1770">f corresponding PoS codes and ’R’ for words linked by language-dependent rules. As the contextual clues (the left and right neigbours of the additional candidate chunks are anchor chunks) provide some extra indication that the chunks can be linked, the similarity test for the final candidates was somewhat relaxed: the percentage of words that have to be linked was lowered to 0.80 and a more relaxed PoS matching function was used. 3.4 Evaluation To test our alignment module, we manually indicated all translational correspondences in the three test corpora. We used the evaluation methodology of Och and Ney (2003) to evaluate the system’s performance. They distinguished sure alignments (S) and possible alignments (P) and introduced the following redefined precision and recall measures (where A refers to the set of alignments): precision = |A ∩ P ||A ∩ S| |A |, recall = |S |(1) and the alignment error rate (AER): AER(S, P; A) = 1 − |A ∩ P |+ |A ∩ S |(2) |A |+ |S| 498 Table 3 shows the alignment results for the three language pairs. (Macken et al., 2008) showed that the results for French-English were competitive to state-of-the-art alignment systems. SHORT MEDIUM LONG p r e p r e p r e Italian .99 .93 .</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Rayson</author>
<author>R Garside</author>
</authors>
<title>Comparing corpora using frequency profiling.</title>
<date>2000</date>
<booktitle>In Proceedings of the workshop on Comparing Corpora, 38th annual meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>1--6</pages>
<contexts>
<context position="18055" citStr="Rayson and Garside, 2000" startWordPosition="2926" endWordPosition="2929">iword terms in both source and target language. 4.1.1 Log-Likelihood Measure The Log-Likehood measure (LL) should allow us to detect single word terms that are distinctive enough to be kept in our bilingual lexicon (Daille, 1995). This metric considers word frequencies weighted over two different corpora (in our case a technical automotive corpus and the more general purpose corpus “Le Monde”1), in order to assign high LL-values to words having much higher or lower frequencies than expected. We implemented the formula for both the expected values and the Log-Likelihood values as described by (Rayson and Garside, 2000). Manual inspection of the Log-Likelihood figures confirmed our hypothesis that more domainspecific terms in our corpus were assigned high LL-values. We experimentally defined the threshold for Log-Likelihood values corresponding to distinctive terms on our development corpus. Example (4) shows some translation pairs which are filtered out by applying the LL threshold. (4) Fr: cependant – En: however – It: tuttavia – Du: echter Fr: choix – En: choice – It: scelta – Du: keuze Fr: continuer – En: continue – It: continuare – Du: verdergaan Fr: cadre – En: frame – It: cornice – Du: frame (erroneou</context>
</contexts>
<marker>Rayson, Garside, 2000</marker>
<rawString>P. Rayson and R. Garside. 2000. Comparing corpora using frequency profiling. In Proceedings of the workshop on Comparing Corpora, 38th annual meeting of the Association for Computational Linguistics (ACL 2000), pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="4830" citStr="Schmid, 1994" startWordPosition="728" endWordPosition="729">rket. For the development of the alignment and terminology extraction module, we created three parallel corpora (Italian, English, Dutch) with French as a central language. Figures about the size of each parallel corpus can be found in table 1. Target Lang. # Sentence pairs # words French Italian 364,221 6,408,693 French English 363,651 7,305,151 French Dutch 364,311 7,100,585 Table 1: Number of sentence pairs and total number of words in the three parallel corpora 2.1 Preprocessing We PoS-tagged and lemmatized the French, English and Italian corpora with the freely available TreeTagger tool (Schmid, 1994) and we used TadPole (Van den Bosch et al., 2007) to annotate the Dutch corpus. In a next step, chunk information was added by a rule-based language-independent chunker (Macken et al., 2008) that contains distituency rules, which implies that chunk boundaries are added between two PoS codes that cannot occur in the same constituent. 2.2 Test and development corpus As we presume that sentence length has an impact on the alignment performance, and thus on term extraction, we created three test sets with varying sentence lengths. We distinguished short sentences (2-7 words), medium-length sentenc</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sclano</author>
<author>P Velardi</author>
</authors>
<title>Termextractor: a web application to learn the shared terminology of emergent web communities.</title>
<date>2007</date>
<booktitle>In Proceedings of the 3rd International Conference on Interoperability for Enterprise Software and Applications (I-ESA</booktitle>
<contexts>
<context position="27457" citStr="Sclano and Velardi, 2007" startWordPosition="4474" endWordPosition="4477">(Simple Term Frequency) 2. Weirdness algorithm (Ahmad et al., 2007) which compares term frequencies in the target and reference corpora 3. C-value (Frantzi and Ananiadou, 1999) which uses term frequencies as well as unit-hood filters (to measure the collocation strength of units) 1http://www.dcs.shef.ac.uk/˜ziqizhang/resources/tools/ # Extracted terms MultiTerm # Terms after filtering 502 4. Glossex (Kozakov et al., 2004) which uses term frequency information from both the target and reference corpora and compares term frequencies with frequencies of the multiword components 5. TermExtractor (Sclano and Velardi, 2007) which is comparable to Glossex but introduces the ”domain consensus” which ”simulates the consensus that a term must gain in a community before being considered a relevant domain term” For all of the above algorithms, the input automotive corpus is PoS tagged and linguistic filters (selecting nouns and noun phrases) are applied to extract candidate terms. In a second step, stopwords are removed and the same set of extracted candidate terms (1105 single words and 1341 multiwords) is ranked differently by each algorithm. To compare the performance of the ranking algorithms, we selected the top </context>
</contexts>
<marker>Sclano, Velardi, 2007</marker>
<rawString>F. Sclano and P. Velardi. 2007. Termextractor: a web application to learn the shared terminology of emergent web communities. In Proceedings of the 3rd International Conference on Interoperability for Enterprise Software and Applications (I-ESA 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Van den Bosch</author>
<author>G J Busser</author>
<author>W Daelemans</author>
<author>S Canisius</author>
</authors>
<title>An efficient memory-based morphosyntactic tagger and parser for dutch.</title>
<date>2007</date>
<booktitle>In Selected Papers of the 17th Computational Linguistics in the Netherlands Meeting,</booktitle>
<pages>99--114</pages>
<location>Leuven, Belgium.</location>
<marker>Van den Bosch, Busser, Daelemans, Canisius, 2007</marker>
<rawString>A. Van den Bosch, G.J. Busser, W. Daelemans, and S. Canisius. 2007. An efficient memory-based morphosyntactic tagger and parser for dutch. In Selected Papers of the 17th Computational Linguistics in the Netherlands Meeting, pages 99–114, Leuven, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vandeghinste</author>
</authors>
<title>A Hybrid Modular Machine Translation System. LoRe-MT: Low Resources Machine Translation.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>Centre for Computational Linguistics, KULeuven.</institution>
<contexts>
<context position="13908" citStr="Vandeghinste, 2008" startWordPosition="2243" endWordPosition="2244">e compound parts. This implies that, without decompounding, in example 2 only the correspondences doublure – binnenpaneel, arc – dakversteviging and arri`ere – achter will be found. By decomposing the compound into its meaningful parts (binnenpaneel = binnen + paneel, dakversteviging = dak + versteviging) and retrieving the lexical links for the compound parts, we were able to link the missing correspondence: pavillon – dakversteviging. (2) Fr: doublure arc pavillon arri`ere. (En: rear roof arch lining) Du: binnenpaneel dakversteviging achter. We experimented with the decompounding module of (Vandeghinste, 2008), which is based on the Celex lexical database (Baayen et al., 1993). The module, however, did not adapt well to the highly technical automotive domain, which is reflected by its low recall and the low confidence values for many technical terms. In order to adapt the module to the automotive domain, we implemented a domain-dependent extension to the decompounding module on the basis of the development corpus. This was done by first running the decompounding module on the Dutch sentences to construct a list with possible compound heads, being valid compound parts in Dutch. This list was updated</context>
</contexts>
<marker>Vandeghinste, 2008</marker>
<rawString>V. Vandeghinste. 2008. A Hybrid Modular Machine Translation System. LoRe-MT: Low Resources Machine Translation. Ph.D. thesis, Centre for Computational Linguistics, KULeuven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhang</author>
<author>J Iria</author>
<author>C Brewster</author>
<author>F Ciravegna</author>
</authors>
<title>A comparative evaluation of term recognition algorithms.</title>
<date>2008</date>
<booktitle>In Proceedings of the sixth international conference of Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="26729" citStr="Zhang et al., 2008" startWordPosition="4368" endWordPosition="4371">e 7: Precision figures for our term extraction system and for SDL MultiTerm Extract 4.2.3 Comparison with monolingual terminology extraction In order to have insights in the performance of our terminology extraction module, without considering the validity of the bilingual terminology pairs, we contrasted our extracted English terms with state-of-the art monolingual terminology systems. As we want to include both single words and multiword terms in our technical automotive lexicon, we only considered ATR systems which extract both categories. We used the implementation for these systems from (Zhang et al., 2008) which is freely available at1. We compared our system against 5 other ATR systems: 1. Baseline system (Simple Term Frequency) 2. Weirdness algorithm (Ahmad et al., 2007) which compares term frequencies in the target and reference corpora 3. C-value (Frantzi and Ananiadou, 1999) which uses term frequencies as well as unit-hood filters (to measure the collocation strength of units) 1http://www.dcs.shef.ac.uk/˜ziqizhang/resources/tools/ # Extracted terms MultiTerm # Terms after filtering 502 4. Glossex (Kozakov et al., 2004) which uses term frequency information from both the target and referenc</context>
</contexts>
<marker>Zhang, Iria, Brewster, Ciravegna, 2008</marker>
<rawString>Z. Zhang, J. Iria, C. Brewster, and F. Ciravegna. 2008. A comparative evaluation of term recognition algorithms. In Proceedings of the sixth international conference of Language Resources and Evaluation (LREC 2008).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>