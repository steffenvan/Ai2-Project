<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016658">
<title confidence="0.984087">
Text Categorization from Category Name via Lexical Reference
</title>
<author confidence="0.998357">
Libby Barak
</author>
<affiliation confidence="0.9986605">
Department of Computer Science
University of Toronto
</affiliation>
<address confidence="0.828195">
Toronto, Canada M5S 1A4
</address>
<email confidence="0.998794">
libbyb@cs.toronto.edu
</email>
<author confidence="0.974795">
Ido Dagan and Eyal Shnarch
</author>
<affiliation confidence="0.9912865">
Department of Computer Science
Bar-Ilan University
</affiliation>
<address confidence="0.51607">
Ramat-Gan 52900, Israel
</address>
<email confidence="0.996187">
{dagan, shey}@cs.biu.ac.il
</email>
<sectionHeader confidence="0.995586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999560888888889">
Requiring only category names as user input
is a highly attractive, yet hardly explored, set-
ting for text categorization. Earlier bootstrap-
ping results relied on similarity in LSA space,
which captures rather coarse contextual sim-
ilarity. We suggest improving this scheme by
identifying concrete references to the category
name’s meaning, obtaining a special variant of
lexical expansion.
</bodyText>
<sectionHeader confidence="0.998983" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999299333333333">
Topical Text Categorization (TC), the task of clas-
sifying documents by pre-defined topics, is most
commonly addressed as a supervised learning task.
However, the supervised setting requires a substan-
tial amount of manually labeled documents, which
is often impractical in real-life settings.
Keyword-based TC methods (see Section 2) aim
at a more practical setting. Each category is rep-
resented by a list of characteristic keywords, which
should capture the category meaning. Classifica-
tion is then based on measuring similarity between
the category keywords and the classified documents,
typically followed by a bootstrapping step. The
manual effort is thus reduced to providing a key-
word list per category, which was partly automated
in some works through clustering.
The keyword-based approach still requires non-
negligible manual work in creating a representative
keyword list per category. (Gliozzo et al., 2005)
succeeded eliminating this requirement by using the
category name alone as the initial keyword, yet ob-
</bodyText>
<page confidence="0.986648">
33
</page>
<bodyText confidence="0.999906735294118">
taining superior performance within the keyword-
based approach. This was achieved by measur-
ing similarity between category names and docu-
ments in Latent Semantic space (LSA), which im-
plicitly captures contextual similarities for the cate-
gory name through unsupervised dimensionality re-
duction. Requiring only category names as user in-
put seems very attractive, particularly when labeled
training data is too costly while modest performance
(relative to supervised methods) is still useful.
The goal of our research is to further improve the
scheme of text categorization from category name,
which was hardly explored in prior work. When an-
alyzing the behavior of the LSA representation of
(Gliozzo et al., 2005) we noticed that it captures
two types of similarities between the category name
and document terms. One type regards words which
refer specifically to the category name’s meaning,
such as pitcher for the category Baseball. How-
ever, typical context words for the category which do
not necessarily imply its specific meaning, like sta-
dium, also come up as similar to baseball in LSA
space. This limits the method’s precision, due to
false-positive classifications of contextually-related
documents that do not discuss the specific category
topic (such as other sports documents wrongly clas-
sified to Baseball). This behavior is quite typical
for query expansion methods, which expand a query
with contextually correlated terms.
We propose a novel scheme that models sepa-
rately these two types of similarity. For one, it
identifies words that are likely to refer specifically
to the category name’s meaning (Glickman et al.,
2006), based on certain relations in WordNet and
</bodyText>
<subsubsectionHeader confidence="0.833809">
Proceedings of NAACL HLT 2009: Short Papers, pages 33–36,
</subsubsectionHeader>
<bodyText confidence="0.951736875">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
Wikipedia. In tandem, we assess the general contex-
tual fit of the category topic using an LSA model,
to overcome lexical ambiguity and passing refer-
ences. The evaluations show that tracing lexical
references indeed increases classification precision,
which in turn improves the eventual classifier ob-
tained through bootstrapping.
</bodyText>
<sectionHeader confidence="0.9771715" genericHeader="method">
2 Background: Keyword-based Text
Categorization
</sectionHeader>
<bodyText confidence="0.999923285714286">
The majority of keyword-based TC methods fit the
general bootstrapping scheme outlined in Figure 1,
which is cast in terms of a vector-space model. The
simplest version for step 1 is manual generation of
the keyword lists (McCallum and Nigam, 1999).
(Ko and Seo, 2004; Liu et al., 2004) partly auto-
mated this step, using clustering to generate candi-
date keywords. These methods employed a standard
term-space representation in step 2.
As described in Section 1, the keyword list in
(Gliozzo et al., 2005) consisted of the category name
alone. This was accompanied by representing the
category names and documents (step 2) in LSA
space, obtained through cooccurrence-based dimen-
sionality reduction. In this space, words that tend
to cooccur together, or occur in similar contexts, are
represented by similar vectors. Thus, vector similar-
ity in LSA space (in step 3) captures implicitly the
similarity between the category name and contextu-
ally related words within the classified documents.
Step 3 yields an initial similarity-based classifi-
cation that assigns a single (most similar) category
to each document, with 5im(c, d) typically being
the cosine between the corresponding vectors. This
classification is used, in the subsequent bootstrap-
ping step, to train a standard supervised classifier
(either single- or multi-class), yielding the eventual
classifier for the category set.
</bodyText>
<sectionHeader confidence="0.886192" genericHeader="method">
3 Integrating Reference and Context
</sectionHeader>
<bodyText confidence="0.999349111111111">
Our goal is to augment the coarse contextual simi-
larity measurement in earlier work with the identifi-
cation of concrete references to the category name’s
meaning. We were mostly inspired by (Glickman et
al., 2006), which coined the term lexical reference
to denote concrete references in text to the specific
meaning of a given term. They further showed that
Input: set of categories and unlabeled documents
Output: a classifier
</bodyText>
<listItem confidence="0.999577">
1. Acquire a keyword list per category
2. Represent each category c and document d
as vectors in a common space
3. For each document d
</listItem>
<equation confidence="0.779846">
CatSZm(d) = argmaxi(5im(c, d))
</equation>
<listItem confidence="0.891922">
4. Train a supervised classifier on step (3) output
</listItem>
<figureCaption confidence="0.996305">
Figure 1: Keyword-based categorization scheme
</figureCaption>
<table confidence="0.9997728">
Category name WordNet Wikipedia
Cryptography decipher digital signature
Medicine cardiology biofeedback, homeopathy
Macintosh Apple Mac, Mac
Motorcycle bike, cycle Honda VR600
</table>
<tableCaption confidence="0.999923">
Table 1: Referring terms from WordNet and Wikipedia
</tableCaption>
<bodyText confidence="0.999797071428571">
an entailing text (in the textual entailment setting)
typically includes a concrete reference to each term
in the entailed statement. Analogously, we assume
that a relevant document for a category typically in-
cludes concrete terms that refer specifically to the
category name’s meaning.
We thus extend the scheme in Figure 1 by cre-
ating two vectors per category (in steps 1 and 2): a
reference vector 5ref in term space, consisting of re-
ferring terms for the category name; and a context
vector cion, representing the category name in LSA
space, as in (Gliozzo et al., 2005). Step 3 then com-
putes a combined similarity score for categories and
documents based on the two vectors.
</bodyText>
<subsectionHeader confidence="0.998736">
3.1 References to category names
</subsectionHeader>
<bodyText confidence="0.999954615384615">
Referring terms are collected from WordNet and
Wikipedia, by utilizing relations that are likely to
correspond to lexical reference. Table 1 illustrates
that WordNet provides mostly referring terms of
general terminology while Wikipedia provides more
specific terms. While these resources were used pre-
viously for text categorization, it was mostly for en-
hancing document representation in supervised set-
tings, e.g. (Rodriguez et al., 2000).
WordNet. Referring terms were found in Word-
Net starting from relevant senses of the category
name and transitively following relation types that
correspond to lexical reference. To that end, we
</bodyText>
<page confidence="0.99551">
34
</page>
<bodyText confidence="0.995465542857143">
specified for each category name those senses which
fit the category’s meaning, such as the outer space
sense for the category Space.1
A category name sense is first expanded by its
synonyms and derivations, all of which are then ex-
panded by their hyponyms. When a term has no
hyponyms it is expanded by its meronyms instead,
since we observed that in such cases they often spec-
ify unique components that imply the holonym’s
meaning, such as Egypt for Middle East. However,
when a term is not a leaf in the hyponymy hierarchy
then its meronyms often refer to generic sub-parts,
such as door for car. Finally, the hyponyms and
meronyms are expanded by their derivations. As
a common heuristic, we considered only the most
frequent senses (top 4) of referring terms, avoiding
low-ranked (rare) senses which are likely to intro-
duce noise.
Wikipedia. We utilized a subset of a lexical ref-
erence resource extracted from Wikipedia (anony-
mous reference). For each category name we ex-
tracted referring terms of two types, capturing hy-
ponyms and synonyms. Terms of the first type are
Wikipedia page titles for which the first definition
sentence includes a syntactic “is-a” pattern whose
complement is the category name, such as Chevrolet
for the category Autos. Terms of the second type
are extracted from Wikipedia’s redirect links, which
capture synonyms such as x11 for Windows-X.
The reference vector cref for a category consists
of the category name and all its referring terms,
equally weighted. The corresponding similarity
function is Simref(c, d) = cos(cref, �dterm)), where
�
dterm is the document vector in term space.
</bodyText>
<subsectionHeader confidence="0.998613">
3.2 Incorporating context similarity
</subsectionHeader>
<bodyText confidence="0.999926375">
Our key motivation is to utilize Simref as the ba-
sis for classification in step 3 (Figure 1). However,
this may yield false positive classifications in two
cases: (a) inappropriate sense of an ambiguous re-
ferring term, e.g., the narcotic sense of drug should
not yield classification to Medicine; (b) a passing
reference, e.g., an analogy to cars in a software doc-
ument, should not yield classification to Autos.
</bodyText>
<footnote confidence="0.61783875">
1We assume that it is reasonable to specify relevant senses
as part of the typically manual process of defining the set of
categories and their names. Otherwise, when expanding names
through all their senses F1-score dropped by about 2%.
</footnote>
<bodyText confidence="0.955253105263158">
In both these cases the overall context in the docu-
ment is expected to be atypical for the triggered cat-
egory. We therefore measure the contextual similar-
ity between a category c and a document d utilizing
LSA space, replicating the method in (Gliozzo et
�
al., 2005): ccon and dLSA are taken as the LSA vec-
tors of the category name and the document, respec-
tively, yielding Simcon(c, d) = cos(15con, �dLSA)).2
The overall similarity score of step 3 is de-
fined as Sim(c, d) = Simref(c, d) · Simcon(c, d).
This formula fulfils the requirement of finding at
least one referring term in the document; otherwise
Simref(c, d) would be zero. Simcon(c, d) is com-
puted in the reduced LSA space and is thus prac-
tically non-zero, and would downgrade Sim(c, d)
when there is low contextual similarity between the
category name and the document. Documents for
which Sim(c, d) = 0 for all categories are omitted.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="evaluation">
4 Results and Conclusions
</sectionHeader>
<bodyText confidence="0.999982333333333">
We tested our method on the two corpora used in
(Gliozzo et al., 2005): 20-NewsGroups, classified
by a single-class scheme (single category per doc-
ument), and Reuters-10 3, of a multi-class scheme.
As in their work, non-standard category names were
adjusted, such as Foreign exchange for Money-fx.
</bodyText>
<subsectionHeader confidence="0.987694">
4.1 Initial classification
</subsectionHeader>
<bodyText confidence="0.999989066666667">
Table 2 presents the results of the initial classifica-
tion (step 3). The first 4 lines refer to classification
based on Simref alone. As a baseline, including
only the category name in the reference vector (Cat-
Name) yields particularly low recall. Expansion by
WordNet is notably more powerful than by the auto-
matically extracted Wikipedia resource; still, the lat-
ter consistently provides a small marginal improve-
ment when using both resources (Reference), indi-
cating their complementary nature.
As we hypothesized, the Reference model
achieves much better precision than the Context
model from (Gliozzo et al., 2005) alone (Simcon).
For 20-NewsGroups the recall of Reference is lim-
ited, due to partial coverage of our current expansion
</bodyText>
<footnote confidence="0.99531825">
2The original method includes a Gaussian Mixture re-
scaling step for Sim..., which wasn’t found helpful when
combined with Sim,.,f (as specified next).
310 most frequent categories in Reuters-21578
</footnote>
<page confidence="0.988379">
35
</page>
<table confidence="0.9939905">
Reuters-10 20 Newsgroups
Method R P F1 R P F1
CatName 0.22 0.67 0.33 0.19 0.55 0.28
WordNet 0.67 0.78 0.72 0.29 0.56 0.38
Wikipedia 0.24 0.68 0.35 0.22 0.57 0.31
Reference 0.69 0.80 0.74 0.31 0.57 0.40
Context 0.59 0.64 0.61 0.46 0.46 0.46
Combined 0.71 0.82 0.76 0.32 0.58 0.41
</table>
<tableCaption confidence="0.860107">
Table 2: Initial categorization results (step 3)
</tableCaption>
<table confidence="0.999977222222222">
Method Feature Reuters-10 20 NG
Set
R P F1 F1
Reference TF-IDF 0.91 0.50 0.65 0.51
LSA 0.89 0.67 0.76 0.56
Context TF-IDF 0.84 0.48 0.61 0.48
LSA 0.73 0.56 0.63 0.44
Combined TF-IDF 0.92 0.50 0.65 0.52
LSA 0.89 0.71 0.79 0.56
</table>
<tableCaption confidence="0.999778">
Table 3: Final bootstrapping results (step 4)
</tableCaption>
<bodyText confidence="0.99982575">
resources, yielding a lower F1. Yet, its higher pre-
cision pays off for the bootstrapping step (Section
4.2). Finally, when the two models are Combined a
small precision improvement is observed.
</bodyText>
<subsectionHeader confidence="0.984709">
4.2 Final bootstrapping results
</subsectionHeader>
<bodyText confidence="0.999928210526316">
The output of step 3 was fed as standard training
for a binary SVM classifier for each category (step
4). We used the default setting for SVM-light, apart
from the j parameter which was set to the number of
categories in each data set, as suggested by (Morik
et al., 1999). For Reuters-10, classification was
determined independently by the classifier of each
category, allowing multiple classes per document.
For 20-NewsGroups, the category which yielded the
highest classification score was chosen (one-versus-
all), fitting the single-class setting. We experimented
with two document representations for the super-
vised step: either as vectors in tf-idf weighted term
space or as vectors in LSA space.
Table 3 shows the final classification results.4
First, we observe that for the noisy bootstrapping
training data LSA document representation is usu-
ally preferred. Most importantly, our Reference and
Combined models clearly improve over the earlier
</bodyText>
<footnote confidence="0.862597666666667">
4Notice that P=R=F1 when all documents are classified to
a single class, as in step 4 for 20-NewsGroups, while in step 3
some documents are not classified, yielding distinct P/R/F1.
</footnote>
<bodyText confidence="0.9984034">
Context. Combining reference and context yields
some improvement for Reuters-10, but not for 20-
NewsGroups. We noticed though that the actual ac-
curacy of our method on 20-NewsGroups is notably
higher than measured relative to the gold standard,
due to its single-class scheme: in many cases, a doc-
ument should truly belong to more than one cate-
gory while that chosen by our algorithm was counted
as false positive. Future research is proposed to in-
crease the method’s recall via broader coverage lexi-
cal reference resources, and to improve its precision
through better context models than LSA, which was
found rather noisy for quite a few categories.
To conclude, the results support our main contri-
bution – the benefit of identifying referring terms for
the category name over using noisier context mod-
els alone. Overall, our work highlights the potential
of text categorization from category names when la-
beled training sets are not available, and indicates
important directions for further research.
</bodyText>
<sectionHeader confidence="0.9982" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99991775">
The authors would like to thank Carlo Strapparava
and Alfio Gliozzo for valuable discussions. This
work was partially supported by the NEGEV project
(www.negev-initiative.org).
</bodyText>
<sectionHeader confidence="0.999258" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999621142857143">
O. Glickman, E. Shnarch, and I. Dagan. 2006. Lexical
reference: a semantic matching subtask. In EMNLP.
A. Gliozzo, C. Strapparava, and I. Dagan. 2005. Inves-
tigating unsupervised learning for text categorization
bootstrapping. In Proc. ofHLT/EMNLP.
Y. Ko and J. Seo. 2004. Learning with unlabeled data
for text categorization using bootstrapping and feature
projection techniques. In Proc. ofACL.
B. Liu, X. Li, W. S. Lee, and P. S. Yu. 2004. Text classi-
fication by labeling words. In Proc. ofAAAI.
A. McCallum and K. Nigam. 1999. Text classification
by bootstrapping with keywords, EM and shrinkage.
In ACL Workshop for Unsupervised Learning in NLP.
K. Morik, P. Brockhausen, and T. Joachims. 1999. Com-
bining statistical learning with a knowledge-based ap-
proach - a case study in intensive care monitoring. In
Proc. of the 16th Int’l Conf. on Machine Learning.
M. d. B. Rodriguez, J. M. G´omez-Hidalgo, and B. Diaz-
Agudo, 2000. Using WordNet to complement training
information in text categorization, volume 189 of Cur-
rent Issues in Linguistic Theory, pages 353–364.
</reference>
<page confidence="0.998942">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.350503">
<title confidence="0.991136">Text Categorization from Category Name via Lexical Reference</title>
<author confidence="0.999037">Libby</author>
<affiliation confidence="0.9998345">Department of Computer University of</affiliation>
<address confidence="0.628968">Toronto, Canada M5S</address>
<email confidence="0.99884">libbyb@cs.toronto.edu</email>
<author confidence="0.978015">Dagan</author>
<affiliation confidence="0.8175245">Department of Computer Bar-Ilan</affiliation>
<address confidence="0.68261">Ramat-Gan 52900,</address>
<abstract confidence="0.9980578">Requiring only category names as user input is a highly attractive, yet hardly explored, setting for text categorization. Earlier bootstrapping results relied on similarity in LSA space, which captures rather coarse contextual similarity. We suggest improving this scheme by identifying concrete references to the category name’s meaning, obtaining a special variant of lexical expansion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>O Glickman</author>
<author>E Shnarch</author>
<author>I Dagan</author>
</authors>
<title>Lexical reference: a semantic matching subtask.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="3374" citStr="Glickman et al., 2006" startWordPosition="502" endWordPosition="505"> specific meaning, like stadium, also come up as similar to baseball in LSA space. This limits the method’s precision, due to false-positive classifications of contextually-related documents that do not discuss the specific category topic (such as other sports documents wrongly classified to Baseball). This behavior is quite typical for query expansion methods, which expand a query with contextually correlated terms. We propose a novel scheme that models separately these two types of similarity. For one, it identifies words that are likely to refer specifically to the category name’s meaning (Glickman et al., 2006), based on certain relations in WordNet and Proceedings of NAACL HLT 2009: Short Papers, pages 33–36, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics Wikipedia. In tandem, we assess the general contextual fit of the category topic using an LSA model, to overcome lexical ambiguity and passing references. The evaluations show that tracing lexical references indeed increases classification precision, which in turn improves the eventual classifier obtained through bootstrapping. 2 Background: Keyword-based Text Categorization The majority of keyword-based TC methods </context>
<context position="5567" citStr="Glickman et al., 2006" startWordPosition="834" endWordPosition="837">al similarity-based classification that assigns a single (most similar) category to each document, with 5im(c, d) typically being the cosine between the corresponding vectors. This classification is used, in the subsequent bootstrapping step, to train a standard supervised classifier (either single- or multi-class), yielding the eventual classifier for the category set. 3 Integrating Reference and Context Our goal is to augment the coarse contextual similarity measurement in earlier work with the identification of concrete references to the category name’s meaning. We were mostly inspired by (Glickman et al., 2006), which coined the term lexical reference to denote concrete references in text to the specific meaning of a given term. They further showed that Input: set of categories and unlabeled documents Output: a classifier 1. Acquire a keyword list per category 2. Represent each category c and document d as vectors in a common space 3. For each document d CatSZm(d) = argmaxi(5im(c, d)) 4. Train a supervised classifier on step (3) output Figure 1: Keyword-based categorization scheme Category name WordNet Wikipedia Cryptography decipher digital signature Medicine cardiology biofeedback, homeopathy Maci</context>
</contexts>
<marker>Glickman, Shnarch, Dagan, 2006</marker>
<rawString>O. Glickman, E. Shnarch, and I. Dagan. 2006. Lexical reference: a semantic matching subtask. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gliozzo</author>
<author>C Strapparava</author>
<author>I Dagan</author>
</authors>
<title>Investigating unsupervised learning for text categorization bootstrapping.</title>
<date>2005</date>
<booktitle>In Proc. ofHLT/EMNLP.</booktitle>
<contexts>
<context position="1630" citStr="Gliozzo et al., 2005" startWordPosition="231" endWordPosition="234">word-based TC methods (see Section 2) aim at a more practical setting. Each category is represented by a list of characteristic keywords, which should capture the category meaning. Classification is then based on measuring similarity between the category keywords and the classified documents, typically followed by a bootstrapping step. The manual effort is thus reduced to providing a keyword list per category, which was partly automated in some works through clustering. The keyword-based approach still requires nonnegligible manual work in creating a representative keyword list per category. (Gliozzo et al., 2005) succeeded eliminating this requirement by using the category name alone as the initial keyword, yet ob33 taining superior performance within the keywordbased approach. This was achieved by measuring similarity between category names and documents in Latent Semantic space (LSA), which implicitly captures contextual similarities for the category name through unsupervised dimensionality reduction. Requiring only category names as user input seems very attractive, particularly when labeled training data is too costly while modest performance (relative to supervised methods) is still useful. The g</context>
<context position="4437" citStr="Gliozzo et al., 2005" startWordPosition="664" endWordPosition="667">urn improves the eventual classifier obtained through bootstrapping. 2 Background: Keyword-based Text Categorization The majority of keyword-based TC methods fit the general bootstrapping scheme outlined in Figure 1, which is cast in terms of a vector-space model. The simplest version for step 1 is manual generation of the keyword lists (McCallum and Nigam, 1999). (Ko and Seo, 2004; Liu et al., 2004) partly automated this step, using clustering to generate candidate keywords. These methods employed a standard term-space representation in step 2. As described in Section 1, the keyword list in (Gliozzo et al., 2005) consisted of the category name alone. This was accompanied by representing the category names and documents (step 2) in LSA space, obtained through cooccurrence-based dimensionality reduction. In this space, words that tend to cooccur together, or occur in similar contexts, are represented by similar vectors. Thus, vector similarity in LSA space (in step 3) captures implicitly the similarity between the category name and contextually related words within the classified documents. Step 3 yields an initial similarity-based classification that assigns a single (most similar) category to each doc</context>
<context position="6849" citStr="Gliozzo et al., 2005" startWordPosition="1038" endWordPosition="1041"> 1: Referring terms from WordNet and Wikipedia an entailing text (in the textual entailment setting) typically includes a concrete reference to each term in the entailed statement. Analogously, we assume that a relevant document for a category typically includes concrete terms that refer specifically to the category name’s meaning. We thus extend the scheme in Figure 1 by creating two vectors per category (in steps 1 and 2): a reference vector 5ref in term space, consisting of referring terms for the category name; and a context vector cion, representing the category name in LSA space, as in (Gliozzo et al., 2005). Step 3 then computes a combined similarity score for categories and documents based on the two vectors. 3.1 References to category names Referring terms are collected from WordNet and Wikipedia, by utilizing relations that are likely to correspond to lexical reference. Table 1 illustrates that WordNet provides mostly referring terms of general terminology while Wikipedia provides more specific terms. While these resources were used previously for text categorization, it was mostly for enhancing document representation in supervised settings, e.g. (Rodriguez et al., 2000). WordNet. Referring </context>
<context position="10932" citStr="Gliozzo et al., 2005" startWordPosition="1713" endWordPosition="1716">Simcon(c, d) = cos(15con, �dLSA)).2 The overall similarity score of step 3 is defined as Sim(c, d) = Simref(c, d) · Simcon(c, d). This formula fulfils the requirement of finding at least one referring term in the document; otherwise Simref(c, d) would be zero. Simcon(c, d) is computed in the reduced LSA space and is thus practically non-zero, and would downgrade Sim(c, d) when there is low contextual similarity between the category name and the document. Documents for which Sim(c, d) = 0 for all categories are omitted. 4 Results and Conclusions We tested our method on the two corpora used in (Gliozzo et al., 2005): 20-NewsGroups, classified by a single-class scheme (single category per document), and Reuters-10 3, of a multi-class scheme. As in their work, non-standard category names were adjusted, such as Foreign exchange for Money-fx. 4.1 Initial classification Table 2 presents the results of the initial classification (step 3). The first 4 lines refer to classification based on Simref alone. As a baseline, including only the category name in the reference vector (CatName) yields particularly low recall. Expansion by WordNet is notably more powerful than by the automatically extracted Wikipedia resou</context>
</contexts>
<marker>Gliozzo, Strapparava, Dagan, 2005</marker>
<rawString>A. Gliozzo, C. Strapparava, and I. Dagan. 2005. Investigating unsupervised learning for text categorization bootstrapping. In Proc. ofHLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ko</author>
<author>J Seo</author>
</authors>
<title>Learning with unlabeled data for text categorization using bootstrapping and feature projection techniques.</title>
<date>2004</date>
<booktitle>In Proc. ofACL.</booktitle>
<contexts>
<context position="4200" citStr="Ko and Seo, 2004" startWordPosition="625" endWordPosition="628">ss the general contextual fit of the category topic using an LSA model, to overcome lexical ambiguity and passing references. The evaluations show that tracing lexical references indeed increases classification precision, which in turn improves the eventual classifier obtained through bootstrapping. 2 Background: Keyword-based Text Categorization The majority of keyword-based TC methods fit the general bootstrapping scheme outlined in Figure 1, which is cast in terms of a vector-space model. The simplest version for step 1 is manual generation of the keyword lists (McCallum and Nigam, 1999). (Ko and Seo, 2004; Liu et al., 2004) partly automated this step, using clustering to generate candidate keywords. These methods employed a standard term-space representation in step 2. As described in Section 1, the keyword list in (Gliozzo et al., 2005) consisted of the category name alone. This was accompanied by representing the category names and documents (step 2) in LSA space, obtained through cooccurrence-based dimensionality reduction. In this space, words that tend to cooccur together, or occur in similar contexts, are represented by similar vectors. Thus, vector similarity in LSA space (in step 3) ca</context>
</contexts>
<marker>Ko, Seo, 2004</marker>
<rawString>Y. Ko and J. Seo. 2004. Learning with unlabeled data for text categorization using bootstrapping and feature projection techniques. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
<author>X Li</author>
<author>W S Lee</author>
<author>P S Yu</author>
</authors>
<title>Text classification by labeling words.</title>
<date>2004</date>
<booktitle>In Proc. ofAAAI.</booktitle>
<contexts>
<context position="4219" citStr="Liu et al., 2004" startWordPosition="629" endWordPosition="632">textual fit of the category topic using an LSA model, to overcome lexical ambiguity and passing references. The evaluations show that tracing lexical references indeed increases classification precision, which in turn improves the eventual classifier obtained through bootstrapping. 2 Background: Keyword-based Text Categorization The majority of keyword-based TC methods fit the general bootstrapping scheme outlined in Figure 1, which is cast in terms of a vector-space model. The simplest version for step 1 is manual generation of the keyword lists (McCallum and Nigam, 1999). (Ko and Seo, 2004; Liu et al., 2004) partly automated this step, using clustering to generate candidate keywords. These methods employed a standard term-space representation in step 2. As described in Section 1, the keyword list in (Gliozzo et al., 2005) consisted of the category name alone. This was accompanied by representing the category names and documents (step 2) in LSA space, obtained through cooccurrence-based dimensionality reduction. In this space, words that tend to cooccur together, or occur in similar contexts, are represented by similar vectors. Thus, vector similarity in LSA space (in step 3) captures implicitly t</context>
</contexts>
<marker>Liu, Li, Lee, Yu, 2004</marker>
<rawString>B. Liu, X. Li, W. S. Lee, and P. S. Yu. 2004. Text classification by labeling words. In Proc. ofAAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>K Nigam</author>
</authors>
<title>Text classification by bootstrapping with keywords, EM and shrinkage.</title>
<date>1999</date>
<booktitle>In ACL Workshop for Unsupervised Learning in NLP.</booktitle>
<contexts>
<context position="4181" citStr="McCallum and Nigam, 1999" startWordPosition="621" endWordPosition="624">ikipedia. In tandem, we assess the general contextual fit of the category topic using an LSA model, to overcome lexical ambiguity and passing references. The evaluations show that tracing lexical references indeed increases classification precision, which in turn improves the eventual classifier obtained through bootstrapping. 2 Background: Keyword-based Text Categorization The majority of keyword-based TC methods fit the general bootstrapping scheme outlined in Figure 1, which is cast in terms of a vector-space model. The simplest version for step 1 is manual generation of the keyword lists (McCallum and Nigam, 1999). (Ko and Seo, 2004; Liu et al., 2004) partly automated this step, using clustering to generate candidate keywords. These methods employed a standard term-space representation in step 2. As described in Section 1, the keyword list in (Gliozzo et al., 2005) consisted of the category name alone. This was accompanied by representing the category names and documents (step 2) in LSA space, obtained through cooccurrence-based dimensionality reduction. In this space, words that tend to cooccur together, or occur in similar contexts, are represented by similar vectors. Thus, vector similarity in LSA s</context>
</contexts>
<marker>McCallum, Nigam, 1999</marker>
<rawString>A. McCallum and K. Nigam. 1999. Text classification by bootstrapping with keywords, EM and shrinkage. In ACL Workshop for Unsupervised Learning in NLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Morik</author>
<author>P Brockhausen</author>
<author>T Joachims</author>
</authors>
<title>Combining statistical learning with a knowledge-based approach - a case study in intensive care monitoring.</title>
<date>1999</date>
<booktitle>In Proc. of the 16th Int’l Conf. on Machine Learning.</booktitle>
<contexts>
<context position="13223" citStr="Morik et al., 1999" startWordPosition="2089" endWordPosition="2092">0.56 0.63 0.44 Combined TF-IDF 0.92 0.50 0.65 0.52 LSA 0.89 0.71 0.79 0.56 Table 3: Final bootstrapping results (step 4) resources, yielding a lower F1. Yet, its higher precision pays off for the bootstrapping step (Section 4.2). Finally, when the two models are Combined a small precision improvement is observed. 4.2 Final bootstrapping results The output of step 3 was fed as standard training for a binary SVM classifier for each category (step 4). We used the default setting for SVM-light, apart from the j parameter which was set to the number of categories in each data set, as suggested by (Morik et al., 1999). For Reuters-10, classification was determined independently by the classifier of each category, allowing multiple classes per document. For 20-NewsGroups, the category which yielded the highest classification score was chosen (one-versusall), fitting the single-class setting. We experimented with two document representations for the supervised step: either as vectors in tf-idf weighted term space or as vectors in LSA space. Table 3 shows the final classification results.4 First, we observe that for the noisy bootstrapping training data LSA document representation is usually preferred. Most i</context>
</contexts>
<marker>Morik, Brockhausen, Joachims, 1999</marker>
<rawString>K. Morik, P. Brockhausen, and T. Joachims. 1999. Combining statistical learning with a knowledge-based approach - a case study in intensive care monitoring. In Proc. of the 16th Int’l Conf. on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M d B Rodriguez</author>
<author>J M G´omez-Hidalgo</author>
<author>B DiazAgudo</author>
</authors>
<title>Using WordNet to complement training information in text categorization, volume 189 of Current Issues in Linguistic Theory,</title>
<date>2000</date>
<pages>353--364</pages>
<marker>Rodriguez, G´omez-Hidalgo, DiazAgudo, 2000</marker>
<rawString>M. d. B. Rodriguez, J. M. G´omez-Hidalgo, and B. DiazAgudo, 2000. Using WordNet to complement training information in text categorization, volume 189 of Current Issues in Linguistic Theory, pages 353–364.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>