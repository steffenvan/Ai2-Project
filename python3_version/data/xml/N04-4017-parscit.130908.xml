<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.114434">
<title confidence="0.9953005">
A Comparison of Rule—Based and Statistical Methods for Semantic
Language Modeling and Confidence Measurement
</title>
<author confidence="0.844185">
Ruhi Sarikaya Yuqing Gao Michael Picheny
</author>
<affiliation confidence="0.668439">
IBM T.J. Watson Research Center
</affiliation>
<address confidence="0.660339">
Yorktown Heights, NY 10598
</address>
<email confidence="0.996319">
{sarikaya,yuqing,picheny}@us.ibm.com
</email>
<sectionHeader confidence="0.995633" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988676">
This paper presents a comparison of a rule-
based and a statistical semantic informa-
tion modeling technique. For the rule—
based method we employ Embedded Gram-
mar (EG) tagging and for the statistical
method we use a previously proposed Seman-
tic Structured Language Modeling (SSLM)
technique. Both EG and SSLM achieve
around 15% relative improvement in speech
recognition performance over the baseline di-
alog state—based trigram language model in
a financial transaction domain. Combining
EG and SSLM using linear interpolation re-
sults in further improvement. We also use
the features obtained from EG and SSLM
for confidence measurement. Word level con-
fidence measurement experiments using EG
and SSLM—based semantic features combined
with posterior probability show over 20%
relative improvement in correct acceptance
rate (CA) at 5% false alarm (FA) rate over
the posterior probability based feature. In
both language model rescoring and confidence
measurement experiments SSLM outperforms
EG by a small margin.
</bodyText>
<sectionHeader confidence="0.997049" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999933868852459">
There are two main approaches for semantic informa-
tion modeling: rule—based (or grammar—based) and
statistical. For spoken dialog systems, grammar and
statistical methods occupy the opposite sides of the
spectrum in terms of the assumptions they make on
users and the &amp;quot;completeness&amp;quot; of utterances. In general,
grammar—based approaches expect sophisticated users,
who can form detailed, grammatical and complete ut-
terances. On the other side of the spectrum, statisti-
cal methods treat speech as an inherently incomplete
process, since users in general do not know the system
coverage and also they may not always form grammati-
cal sentences (i.e., spontaneous speech). Both methods
have advantages and disadvantages. Statistical meth-
ods require significant amount of annotated data for
reliable information modeling. They usually do not
need a priori information about the task, which makes
them portable to other tasks as long as there is an-
notated data for those domains. However, statistical
methods suffer from poor generalizations when data is
insufficient. On the other hand, grammar—based meth-
ods do not need annotated training data, but require
major effort by experts to hand—code the a priori infor-
mation into the system. Grammar—based methods for
language modeling are attractive alternatives to sta-
tistical models in domains that lack extensive speech
corpora (Jurafsky, 1995).
We introduced a set of statistical language modeling
techniques that use semantic analysis for spoken dia-
log systems (Erdogan, 2002). The motivation was to
incorporate the semantic information from the seman-
tic parse tree into language modeling. The SSLM uses
varying levels of lexical and semantic information using
maximum entropy (ME) modeling.
Semantic information can also be used for confidence
measurement. Since the speech recognition output is
always subject to some level of uncertainty, it is es-
sential to employ a measure that indicates the reliabil-
ity (of the correctness) of hypothesized words. There
are a number of overlapping speech recognition based
features that were exploited in many studies (San-
Segundo, 2001; Zhang, 2001; Pao, 1999). For do-
main independent large vocabulary speech recognition
systems, posterior probability based on a word graph
was shown to be the single most useful confidence fea-
ture (Wessel, 2000). In many, if not all, of the previous
studies the way semantic information was incorporated
into decision process is rather ad hoc. For example
in (Pao, 1999), semantic weights assigned to words are
based on heuristics. Likewise, in (Carpenter, 2001)
semantic features such as &amp;quot;uncovered word percent-
age&amp;quot;, &amp;quot;gap number&amp;quot;, &amp;quot;slot number&amp;quot;, etc. were gener-
ated experimentally in an effort to incorporate seman-
tic information into confidence metric. We proposed
two methods to obtain semantic information from the
parser output to incorporate into the posterior proba-
bility (Sarikaya, 2004; Sarikaya, 2003). In this study,
we compare and combine the grammar and statistical
methods for language modeling and the features ob-
tained from them for confidence measurement.
The rest of the paper is organized as follows: in Sec-
</bodyText>
<figure confidence="0.989697416666666">
!S!
BAL-REF
FUND
fb fb
fund fund fund
null
bal-ref
bal-ref
null null null null
::MAINMENU
in the real estate fund
:MAYIHELPYOU can i have the balance .
</figure>
<bodyText confidence="0.9978078125">
token. In addition to regular n—gram questions, four
more questions are used regarding the semantic struc-
ture of the sentence. These questions are (1) current
active parent label (Li), (2) Li and number of words
to the left since starting the current concept (Ni), (3)
Li, Ni and previous word token, (4) the previous com-
pleted constituent (0,) and number of words to the
left since completing O. The history given in Eq. 1
consists of answers to these questions.
The language model score for a given word in
MELM2 model is conditioned not only on the previous
words but also on the labels and the relative coverage
of these labels over words. The SSLM presents an ef-
fective statistical method to combine word sequences
with semantic parse tree. Therefore we can use the
SSLM score as a feature for confidence measurement.
</bodyText>
<sectionHeader confidence="0.9978105" genericHeader="method">
4 Experimental Results and
Discussions
</sectionHeader>
<bodyText confidence="0.999943027027027">
The experiments are conducted on a financial transac-
tion task. The SSLM used 28.3K semantically anno-
tated sentences (105K words) as training data. The
ME—based SSLM is trained with the improved itera-
tive scaling algorithm using fuzzy smoothing (Erdo-
gan, 2002; Chen, 2000). The acoustic data of the
SSLM training data is used as confidence measure-
ment training data. The confidence measurement test
data consists of 3152 sentences amounting to 11.4K
words. The confidence training and test data have
27.9% and 28.1% word error rates (WEB), respectively.
The speech recognition acoustic models are trained us-
ing generic telephony data. A dialog state—based tri-
gram language model (DS-3gr) with deleted interpo-
lation is used for the speech recognition to obtain the
baseline WER and generate an N—best list. The base-
line DS-3gr used a separate 194K sentences as training
and additional 10K sentences as held—out data from the
financial domain.
The N—best list contains an average of 34 alternative
hypotheses per sentence with an oracle WER of 16.2%.
The SSLM and EG are used to rescore the N—best list
hypothesis. Table 1 shows the baseline DS-3gr, EG
and the ME—based SSLM results. The EG achieved
a 15.3% relative improvement over the baseline lan-
guage model. The SSLM resulted in 15.7% improve-
ment. These improvements are due to the inclusion
of new semantic information that was not part of the
original speech recognition system. Even though indi-
vidual improvements are similar, linearly interpolating
EG with SSLM led to further improvement. The over-
all improvement compared to baseline is 18.9%. The
interpolation weight used for EG and SSLM is 0.5. The
results indicate that EG models local semantics in a
sentence and SSLM models overall semantic structure
of a sentence. Combining them can improve the se-
mantic modeling of the sentence.
</bodyText>
<table confidence="0.974090333333333">
Language Model Rescoring
LM WER (%)
DS-3gr 28.1
EG 23.8
SSLM 23.7
EG ± SSLM 22.8
</table>
<tableCaption confidence="0.9865395">
Table 1: Word error rates for the baseline, EG and
SSLM—based language models.
</tableCaption>
<bodyText confidence="0.9885548">
The posterior probabilities are based on the sausages
which are obtained from the word graph (Mangu,
1999). A sausage is a simplified word graph with a
specific topology. The goal in this conversion is to
minimize the WER rather than the sentence error rate.
The technique is named as &amp;quot;sausage&amp;quot; since the visual
representation of this graph looks like a sausage in its
literal sense. The word graph is converted into a se-
quence of confusion sets along time. Each confusion
set consists of a group of words, which are competing
hypotheses for a certain time interval. The posterior
probability for each word is obtained by summing the
probabilities of all the paths going over that word.
A sausage is generated for each sentence in the confi-
dence training and test data. The best path from the
sausage is hypothesized as the speech recognition out-
put. Each word is labeled as correct (&amp;quot;1&amp;quot;) or incorrect
(&amp;quot;0&amp;quot;) after aligning the hypothesis with the reference
transcript. All recognition hypotheses are parsed using
the statistical semantic parser. Each sentence is scored
with both EG and SSLM to assign semantic probabil-
ities to each word. The corresponding semantic fea-
tures are extracted for all the words in the sentence.
All of the positive (correct recognition) and negative
(misrecognition) examples are pooled in two sets. A
decision tree is built using the respective features. The
decision tree used the raw scores of each feature. The
tree is grown by partitioning the data recursively at
each node until either the node becomes homogeneous
or contains too few observations (&lt; 500).
Receiver operating characteristic (ROC) curve is one
of the commonly used tools for confidence measure-
ment performance. The most interesting part of the
ROC curve for dialog systems is where the false accep-
tance rate is low and correct acceptance rate is high,
because one needs to accept as many correct words as
possible at low False Acceptance (FA) rates. The FA
and CA are calculated using the following formula:
# of falsely accepted words
x 100
</bodyText>
<subsectionHeader confidence="0.633697">
Total # of negative examples
</subsectionHeader>
<bodyText confidence="0.984862714285714">
# of correctly accepted words x 100 (2)
Total # of positive examples
Here, EG refers to EG language model score, SSLM
refers to the semantic language model score, and post
refers to posterior probability for a given word. Based
on the individual feature performances post outper-
formed both EG and SSLM for almost all of the FA
</bodyText>
<figure confidence="0.980898105263158">
FA
CA
100
90
80
70
Correct Acceptance (%)
60
50
40
30
20
10
0
0 5 10 15 20 25 30 35 40
False Acceptance (%)
post
post + SSLM
post + EG
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.807880">
<title confidence="0.999213">A Comparison of Rule—Based and Statistical Methods for Semantic Language Modeling and Confidence Measurement</title>
<author confidence="0.999492">Ruhi Sarikaya Yuqing Gao Michael Picheny</author>
<affiliation confidence="0.996548">IBM T.J. Watson Research</affiliation>
<address confidence="0.883254">Yorktown Heights, NY 10598</address>
<email confidence="0.999529">sarikaya@us.ibm.com</email>
<email confidence="0.999529">yuqing@us.ibm.com</email>
<email confidence="0.999529">picheny@us.ibm.com</email>
<abstract confidence="0.996674192307692">paper presents a comparison of a and a statistical semantic informamodeling technique. For the based method we employ Embedded Grammar (EG) tagging and for the statistical method we use a previously proposed Semantic Structured Language Modeling (SSLM) technique. Both EG and SSLM achieve improvement in speech recognition performance over the baseline dialog state—based trigram language model in a financial transaction domain. Combining EG and SSLM using linear interpolation results in further improvement. We also use the features obtained from EG and SSLM for confidence measurement. Word level confidence measurement experiments using EG and SSLM—based semantic features combined with posterior probability show over 20% relative improvement in correct acceptance rate (CA) at 5% false alarm (FA) rate over the posterior probability based feature. In both language model rescoring and confidence measurement experiments SSLM outperforms EG by a small margin.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>