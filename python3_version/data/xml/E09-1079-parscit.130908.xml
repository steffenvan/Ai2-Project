<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.98985">
Tagging Urdu Text with Parts of Speech: A Tagger Comparison
</title>
<author confidence="0.990748">
Hassan Sajjad Helmut Schmid
</author>
<affiliation confidence="0.9628135">
Universität Stuttgart Universität Stuttgart
Stuttgart. Germany Stuttgart, Germany
</affiliation>
<email confidence="0.984708">
sajjad@ims.uni-stuttgart.de schmid@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.993573" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999549545454546">
In this paper, four state-of-art probabilistic
taggers i.e. TnT tagger, TreeTagger, RF tagger
and SVM tool, are applied to the Urdu lan-
guage. For the purpose of the experiment, a
syntactic tagset is proposed. A training corpus
of 100,000 tokens is used to train the models.
Using the lexicon extracted from the training
corpus, SVM tool shows the best accuracy of
94.15%. After providing a separate lexicon of
70,568 types, SVM tool again shows the best
accuracy of 95.66%.
</bodyText>
<sectionHeader confidence="0.946758" genericHeader="method">
1 Urdu Language
</sectionHeader>
<bodyText confidence="0.999874916666666">
Urdu belongs to the Indo-Aryan language family.
It is the national language of Pakistan and is one
of the official languages of India. The majority
of the speakers of Urdu spread over the area of
South Asia, South Africa and the United King-
dom1.
Urdu is a free order language with general
word order SOV. It shares its phonological, mor-
phological and syntactic structures with Hindi.
Some linguists considered them as two different
dialects of one language (Bhatia and Koul,
2000). However, Urdu is written in Perso-arabic
script and inherits most of the vocabulary from
Arabic and Persian. On the other hand, Hindi is
written in Devanagari script and inherits vocabu-
lary from Sanskrit.
Urdu is a morphologically rich language.
Forms of the verb, as well as case, gender, and
number are expressed by the morphology. Urdu
represents case with a separate character after the
head noun of the noun phrase. Due to their sepa-
rate occurrence and their place of occurrence,
they are sometimes considered as postpositions.
Considering them as case markers, Urdu has no-
</bodyText>
<footnote confidence="0.704154">
1 http://www.ethnologue.com/14/show_language.asp?
code=URD
</footnote>
<bodyText confidence="0.992914333333333">
minative, ergative, accusative, dative, instrumen-
tal, genitive and locative cases (Butt, 1995: pg
10). The Urdu verb phrase contains a main verb,
a light verb describing the aspect, and a tense
verb describing the tense of the phrase (Hardie,
2003; Hardie, 2003a).
</bodyText>
<sectionHeader confidence="0.978592" genericHeader="method">
2 Urdu Tagset
</sectionHeader>
<bodyText confidence="0.999931774193548">
There are various questions that need to be ans-
wered during the design of a tagset. The granu-
larity of the tagset is the first problem in this re-
gard. A tagset may consist either of general parts
of speech only or it may consist of additional
morpho-syntactic categories such as number,
gender and case. In order to facilitate the tagger
training and to reduce the lexical and syntactic
ambiguity, we decided to concentrate on the syn-
tactic categories of the language. Purely syntactic
categories lead to a smaller number of tags which
also improves the accuracy of manual tagging2
(Marcus et al., 1993).
Urdu is influenced from Arabic, and can
be considered as having three main parts of
speech, namely noun, verb and particle (Platts,
1909; Javed, 1981; Haq, 1987). However, some
grammarians proposed ten main parts of speech
for Urdu (Schmidt, 1999). The work of Urdu
grammar writers provides a full overview of all
the features of the language. However, in the
perspective of the tagset, their analysis is lacking
the computational grounds. The semantic, mor-
phological and syntactic categories are mixed in
their distribution of parts of speech. For example,
Haq (1987) divides the common nouns into sit-
uational (smile, sadness, darkness), locative
(park, office, morning, evening), instrumental
(knife, sword) and collective nouns (army, data).
In 2003, Hardie proposed the first com-
putational part of speech tagset for Urdu (Hardie,
</bodyText>
<footnote confidence="0.9933105">
2 A part of speech tagger for Indian languages, available at
http://shiva.iiit.ac.in/SPSAL2007 /iiit_tagset_guidelines.pdf
</footnote>
<note confidence="0.9623305">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 692–700,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.995668">
692
</page>
<bodyText confidence="0.999781375">
2003a). It is a morpho-syntactic tagset based on
the EAGLES guidelines. The tagset contains 350
different tags with information about number,
gender, case, etc. (van Halteren, 2005). The
EAGLES guidelines are based on three levels,
major word classes, recommended attributes and
optional attributes. Major word classes include
thirteen tags: noun, verb, adjective, pro-
noun/determiner, article, adverb, adposition, con-
junction, numeral, interjection, unassigned, resi-
dual and punctuation. The recommended
attributes include number, gender, case, finite-
ness, voice, etc.3 In this paper, we will focus on
purely syntactic distributions thus will not go
into the details of the recommended attributes of
the EAGLES guidelines. Considering the
EAGLES guidelines and the tagset of Hardie in
comparison with the general parts of speech of
Urdu, there are no articles in Urdu. Due to the
phrase level and semantic differences, pronoun
and demonstrative are separate parts of speech in
Urdu. In the Hardie tagset, the possessive pro-
nouns like ►-&gt;,- /mera/ (my), ►,ttz /tumhara/
(your), ►_)&gt;� /humara/ (our) are assigned to the
category of possessive adjective. Most of the Ur-
du grammarians consider them as pronouns
(Platts, 1909; Javed, 1981; Haq, 1987). However,
all these possessive pronouns require a noun in
their noun phrase, thus show a similar behavior
as demonstratives. The locative and temporal
adverbs (uy, /yahan/ (here), jlis /wahan/ (there),
Y► /ab/ (now), etc.) and, the locative and tempor-
al nouns (C.1— /subah/ (morning), �U /sham/
(evening), -*K /gher/ (home)) appear in a very
similar syntactic context. In order to keep the
structure of pronoun and noun consistent, loca-
tive and temporal adverbs are treated as pro-
nouns. The tense and aspect of a verb in Urdu is
represented by a sequence of auxiliaries. Consid-
er the example4:
</bodyText>
<equation confidence="0.531558">
�� v_) &gt;, vis fl� 6L-:-
</equation>
<bodyText confidence="0.912937333333333">
Hai raha Ja kerta kam Jan
Is Doing Kept Work John
John is kept on doing work
</bodyText>
<listItem confidence="0.70973475">
“Table 1: The aspect of the verb U-A /kerta/
(doing) is represented by two separate words t:-
/ja/ and li_) /raha/ and the last word of the sen-
tence ,-, /hai/ (is) shows the tense of the verb.”
</listItem>
<footnote confidence="0.989837">
3 The details on the EAGLES guidelines can be found at:
http://www.ilc.cnr.it/EAGLES/browse.html
4 Urdu is written in right to left direction.
</footnote>
<bodyText confidence="0.999965346938776">
The above considerations lead to the following
tagset design for Urdu. The general parts of
speech are noun, pronoun, demonstrative, verb,
adjective, adverb, conjunction, particle, number
and punctuation. The further refinement of the
tagset is based on syntactic properties. The mor-
phologically motivated features of the language
are not encoded in the tagset. For example, an
Urdu verb has 60 forms which are morphologi-
cally derived from its root form. All these forms
are annotated with the same category i.e. verb.
During manual tagging, some words are
hard for the linguist to disambiguate reliably. In
order to keep the training data consistent, such
words are assigned a separate tag. For instance,
the semantic marker =- /se/ gets a separate tag
due to its various confusing usages such as loca-
tive and instrumental (Platts, 1909).
The tagset used in the experiments reported
in this paper contains 42 tags including three
special tags. Nouns are divided into noun (NN)
and proper name (PN). Demonstratives are di-
vided into personal (PD), KAF (KD), adverbial
(AD) and relative demonstratives (RD). All four
categories of demonstratives are ambiguous with
four categories of pronouns. Pronouns are di-
vided into six types i.e. personal (PP), reflexive
(RP), relative (REP), adverbial (AP), KAF (KP)
and adverbial KAF (AKP) pronouns. Based on
phrase level differences, genitive reflexive (GR)
and genitive (G) are kept separate from pro-
nouns. The verb phrase is divided into verb, as-
pectual auxiliaries and tense auxiliaries. Numer-
als are divided into cardinal (CA), ordinal (OR),
fractional (FR) and multiplicative (MUL). Con-
junctions are divided into coordinating (CC) and
subordinating (SC) conjunctions. All semantic
markers except ,=- /se/ are kept in one category.
Adjective (ADJ), adverb (ADV), quantifier (Q),
measuring unit (U), intensifier (I), interjection
(INT), negation (NEG) and question words
(QW) are handled as separate categories. Adjec-
tival particle (A), KER (KER), SE (SE) and
WALA (WALA) are ambiguous entities which
are annotated with separate tags. A complete list
of the tags with the examples is given in appen-
dix A. The examples of the weird categories such
as WALA, KAF pronoun, KAF demonstratives,
etc. are given in appendix B.
</bodyText>
<sectionHeader confidence="0.990442" genericHeader="method">
3 Tagging Methodologies
</sectionHeader>
<bodyText confidence="0.999242">
The work on automatic part of speech tagging
started in early 1960s. Klein and Simmons
</bodyText>
<page confidence="0.998708">
693
</page>
<bodyText confidence="0.999352129032258">
(1963) rule based POS tagger can be considered
as the first automatic tagging system. In the rule
based approach, after assigning each word its
potential tags, a list of hand written disambigua-
tion rules are used to reduce the number of tags
to one (Klein and Simmons, 1963; Green and
Rubin, 1971; Hindle, 1989; Chanod and Tapa-
nainen 1994). A rule based model has the disad-
vantage of requiring lots of linguistic efforts to
write rules for the language.
Data-driven approaches resolve this prob-
lem by automatically extracting the information
from an already tagged corpus. Ambiguity be-
tween the tags is resolved by selecting the most
likely tag for a word (Bahl and Mercer, 1976;
Church, 1988; Brill, 1992). Brill’s transformation
based tagger uses lexical rules to assign each
word the most frequent tag and then applies con-
textual rules over and over again to get a high
accuracy. However, Brill’s tagger requires train-
ing on a large number of rules which reduces the
efficiency of machine learning process. Statistic-
al approaches usually achieve an accuracy of
96%-97% (Hardie, 2003: 295). However, statis-
tical taggers require a large training corpus to
avoid data sparseness. The problem of low fre-
quencies can be resolved by applying different
methods such as smoothing, decision trees, etc.
In the next section, an overview of the statistical
taggers is provided which are evaluated on the
Urdu tagset.
</bodyText>
<subsectionHeader confidence="0.99816">
3.1 Probabilistic Disambiguation
</subsectionHeader>
<bodyText confidence="0.999924743243244">
The Hidden Markov model is the most widely
used method for statistical part of speech tag-
ging. Each tag is considered as a state. States are
connected by transition probabilities which
represent the cost of moving from one state to
another. The probability of a word having a par-
ticular tag is called lexical probability. Both, the
transitional and the lexical probabilities are used
to select the tag of a particular word.
As a standard HMM tagger, The TnT
tagger is used for the experiments. The TnT tag-
ger is a trigram HMM tagger in which the transi-
tion probability depends on two preceding tags.
The performance of the tagger was tested on
NEGRA corpus and Penn Treebank corpus. The
average accuracy of the tagger is 96% to 97%
(Brants, 2000).
The second order Markov model used by
the TnT tagger requires large amounts of tagged
data to get reasonable frequencies of POS tri-
grams. The TnT tagger smooths the probability
with linear interpolation to handle the problem of
data sparseness. The Tags of unknown words are
predicted based on the word suffix. The longest
ending string of an unknown word having one or
more occurrences in the training corpus is consi-
dered as a suffix. The tag probabilities of a suffix
are evaluated from all the words in the training
corpus (Brants, 2000).
In 1994, Schmid proposed a probabilistic
part of speech tagger very similar to a HMM
based tagger. The transition probabilities are cal-
culated by decision trees. The decision tree
merges infrequent trigrams with similar contexts
until the trigram frequencies are large enough to
get reliable estimates of the transition probabili-
ties. The TreeTagger uses an unknown word
POS guesser similar to that of the TnT tagger.
The TreeTagger was trained on 2 million words
of the Penn-Treebank corpus and was evaluated
on 100,000 words. Its accuracy is compared
against a trigram tagger built on the same data.
The TreeTagger showed an accuracy of 96.06%
(Schmid, 1994a).
In 2004, Giménez and Màrquez pro-
posed a part of speech tagger (SVM tool) based
on support vector machines and reported accura-
cy higher than all state-of-art taggers. The aim of
the development was to have a simple, efficient,
robust tagger with high accuracy. The support
vector machine does a binary classification of the
data. It constructs an N-dimensional hyperplane
that separates the data into positive and negative
classes. Each data element is considered as a
vector. Those vectors which are close to the se-
parating hyperplane are called support vectors5.
A support vector machine has to be
trained for each tag. The complexity is controlled
by introducing a lexicon extracted from the train-
ing data. Each word tag pair in the training cor-
pus is considered as a positive case for that tag
class and all other tags in the lexicon are consi-
dered negative cases for that word. This feature
avoids generating useless cases for the compari-
son of classes.
The SVM tool was evaluated on the
English Penn Treebank. Experiments were con-
ducted using both polynomial and linear kernels.
When using n-gram features, the linear kernel
showed a significant improvement in speed and
accuracy. Unknown words are considered as the
most ambiguous words by assigning them all
open class POS tags. The disambiguation of un-
knowns uses features such as prefixes, suffixes,
</bodyText>
<footnote confidence="0.7167935">
5 Andrew Moore:
http://www.autonlab.org/tutorials/svm.html
</footnote>
<page confidence="0.997143">
694
</page>
<bodyText confidence="0.999944310344828">
upper case, lower case, word length, etc. On the
Penn Treebank corpus, SVM tool showed an ac-
curacy of 97.16% (Giménez and Màrquez,
2004).
In 2008, Schmid and Florian proposed a
probabilistic POS tagger for fine grained tagsets.
The basic idea is to consider POS tags as sets of
attributes. The context probability of a tag is the
product of the probabilities of its attributes. The
probability of an attribute given the previous tags
is estimated with a decision tree. The decision
tree uses different context features for the predic-
tion of different attributes (Schmid and Laws,
2008).
The RF tagger is well suited for lan-
guages with a rich morphology and a large fine
grained tagset. The RF tagger was evaluated on
the German Tiger Treebank and Czech Academ-
ic corpus which contain 700 and 1200 POS tags,
respectively. The RF tagger achieved a higher
accuracy than TnT and SVMTool.
Urdu is a morphologically rich language.
Training a tagger on a large fine grained tagset
requires a large training corpus. Therefore, the
tagset which we are using for these experiments
is only based on syntactic distributions. Howev-
er, it is always interesting to evaluate new dis-
ambiguation ideas like RF tagger on different
languages.
</bodyText>
<sectionHeader confidence="0.999735" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.99972148">
A corpus of approx 110,000 tokens was taken
from a news corpus (www.jang.com.pk). In the
filtering phase, diacritics were removed from the
text and normalization was applied to keep the
Unicode of the characters consistent. The prob-
lem of space insertion and space deletion was
manually solved and space is defined as the word
boundary. The data was randomly divided into
two parts, 90% training corpus and 10% test cor-
pus. A part of the training set was also used as
held out data to optimize the parameters of the
taggers. The statistics of the training corpus and
test corpus are shown in table 2 and table 3. The
optimized parameters of the TreeTagger are con-
text size 2, with minimum information gain for
decision tree 0.1 and information gain at leaf
node 1.4. For TnT, a default trigram tagger is
used with suffix length of 10, sparse data mode 4
with lambda1 0.03 and lambda2 0.4. The RF
tagger uses a context length of 4 with threshold
of suffix tree pruning 1.5. The SVM tool is
trained at right to left direction with model 4.
Model 4 improves the detection of unknown
words by artificially marking some known words
as unknown words and then learning the model.
</bodyText>
<table confidence="0.9968385">
Training corpus Test corpus
Tokens 100,000 9000
Types 7514 1931
Unknown -- 754
Tokens
Unknown -- 444
Types
“Table 2: Statistics of training and test data.”
Tag Total Un- Tag To- Un-
known tal known
NN 2537 458 PN 459 101
P 1216 0 AA 379 0
VB 971 81 TA 285 0
ADJ 510 68 ADV 158 21
</table>
<tableCaption confidence="0.8238855">
“Table 3: Eight most frequent tags in the test
corpus.”
</tableCaption>
<bodyText confidence="0.999777625">
In the first experiment, no external lexicon was
provided. The types from the training corpus
were used as the lexicon by the tagger. SVM tool
showed the best accuracy for both known and
unknown words. Table 4 shows the accuracies of
all the taggers. The baseline result where each
word is annotated with its most frequent tag, ir-
respective of the context, is 88.0%.
</bodyText>
<table confidence="0.999194285714286">
TnT TreeTagger RF tagger SVM
tagger tagger
93.40% 93.02% 93.28% 94.15%
Known
95.78% 95.60% 95.68% 96.15%
Unknown
68.44% 65.92% 68.08% 73.21%
</table>
<bodyText confidence="0.920733615384615">
“Table 4: Accuracies of the taggers without us-
ing any external lexicon. SVM tool shows the
best result for both known and unknown words.”
The taggers show poor accuracy while detecting
proper names. In most of the cases, proper name
is confused with adjective and noun. This is be-
cause in Urdu, there is no clear distinction be-
tween noun and proper name. Also, the usage of
an adjective as a proper name is a frequent phe-
nomenon in Urdu. The accuracies of open class
tags are shown in table 5. The detailed discussion
on the results of the taggers is done after provid-
ing an external lexicon to the taggers.
</bodyText>
<page confidence="0.991887">
695
</page>
<table confidence="0.999384571428571">
Tag TnT Tree- RF SVM
tagger Tagger tagger tagger
VB 93.20% 91.86% 92.68% 94.23%
NN 94.12% 96.21% 93.89% 96.45%
PN 73.20% 66.88% 72.77% 68.62%
ADV 75.94% 72.78% 74.68% 72.15%
ADJ 85.67% 80.78% 86.5% 85.88%
</table>
<tableCaption confidence="0.7820505">
“Table 5: Accuracies of open class tags without
having an external lexicon”
</tableCaption>
<bodyText confidence="0.999488916666667">
In the second stage of the experiment, a large
lexicon consisting of 70,568 types was pro-
vided6. After adding the lexicon, there are 112
unknown tokens and 81 unknown types in the
test corpus7. SVM tool again showed the best
accuracy of 95.66%. Table 6 shows the accuracy
of the taggers. The results of open class words
significantly improve due to the smaller number
of unknown words in the test corpus. The total
accuracy of open class tags and their accuracy on
unknown words are given in table 7 and table 8
respectively.
</bodyText>
<table confidence="0.989071285714286">
TnT tag- Tree- RF tagger SVM
ger Tagger tool
94.91% 95.17% 95.26% 95.66%
Known
95.42% 95.65% 95.66% 96.11%
Unknown
56.25% 58.04% 64.60% 61.61%
</table>
<bodyText confidence="0.6566365">
“Table 6: Accuracies of the taggers after adding
the lexicon. SVM tool shows the best accuracy
for known word disambiguation. RF tagger
shows the best accuracy for unknown words.”
</bodyText>
<table confidence="0.998974142857143">
Tag TnT Tree- RF SVM
tagger Tagger tagger tool
VB 95.88% 95.88% 96.58% 96.80%
NN 94.64% 95.85% 94.79% 96.64%
PN 86.92% 79.73% 84.96% 81.70%
ADV 82.28% 79.11% 81.64% 81.01%
ADJ 91.59% 89.82% 92.37% 88.26%
</table>
<tableCaption confidence="0.952045">
“Table 7: Accuracies of open class tags after
adding an external lexicon.”
</tableCaption>
<footnote confidence="0.6278848">
6 Additional lexicon is taken from CRULP, Lahore, Paki-
stan (www.crulp.org).
7 The lexicon was added by using the default settings pro-
vided by each tagger. No probability distribution informa-
tion was given with the lexicon.
</footnote>
<table confidence="0.998153142857143">
Tag TnT Tree- RF SVM
tagger Tagger tagger tool
VB 28.57% 0.00% 42.86% 42.86%
NN 74.47% 95.74% 80.85% 80.85%
PN 68.18% 54.54% 63.63% 50.00%
ADV 8.33% 0.00% 8.33% 0.00%
ADJ 30.00% 20.00% 70.00% 80.00%
</table>
<figureCaption confidence="0.54600175">
“Table 8: Accuracies of open class tags on un-
known words. The number of unknown words
with tag VB and ADJ are less than 10 in this ex-
periment.”
</figureCaption>
<bodyText confidence="0.992674833333334">
The results of the taggers are analyzed by finding
the most frequently confused pairs for all the
taggers. It includes both the known and unknown
words. Only those pairs are added in the table
which have an occurrence of more than 10. Table
9 shows the results.
</bodyText>
<table confidence="0.9990105">
Confused TnT Tree- RF SVM
pair tagger Tagger tagger tool
NN ADJ 85 87 87 95
NN PN 118 140 129 109
NN ADV 12 15 13 15
NN VB 14 17 12 12
VB TA 12 0 0 0
KER P 14 14 14 0
ADV ADJ 11 14 13 11
PD PP 26 26 30 14
</table>
<bodyText confidence="0.6384475">
“Table 9: Most frequently confused tag pairs
with total number of occurrences.”
</bodyText>
<sectionHeader confidence="0.998917" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9999506875">
The output of table 9 can be analyzed in many
ways e.g. ambiguous tags, unknown words, open
class tags, close class tags, etc. In the close class
tags, the most frequent errors are between de-
monstrative and pronoun, and between KER tag
and semantic marker (P). The difference between
demonstrative and pronoun is at the phrase level.
Demonstratives are followed by a noun which
belongs to the same noun phrase whereas pro-
nouns form a noun phrase by itself. Taggers ana-
lyze the language in a flat structure and are una-
ble to handle the phrase level differences. It is
interesting to see that the SVM tool shows a
clear improvement in detecting the phrase level
differences over the other taggers. It might be
due to the SVM tool ability to look not only at
</bodyText>
<page confidence="0.99841">
696
</page>
<table confidence="0.931762538461538">
“Table 11: (a) Verbal noun with semantic mark-
er, (b) syntactic structure of KER tag.”8
the neighboring tags but at the neighboring
words as well.
�� ����� ���� ��� ��
Gay gayain Gana log Voh
TA VB NN NN PD
Will sing Song people Those
Those people will sing a song.
&apos;A u�9 Ut e9
Gay Gayain gana Voh
TA VB NN PP
Will Sing Song those
</table>
<bodyText confidence="0.977510666666667">
Those will sing a song.
“Table 10: The word o9 /voh/ is occurring both as
pronoun and demonstrative. In both of the cases,
it is followed by a noun. But looking at the
phrases, demonstrative o9 has the noun inside the
noun phrase.”
The second most frequent error among the closed
class tags is the distinction between the KER tag
,=� /kay/ and the semantic marker =� /kay/. The
KER tag always takes a verb before it and the
semantic marker always takes a noun before it.
The ambiguity arises when a verbal noun occurs.
In the tagset, verbal nouns are handled as verb.
Syntactically, verbal nouns occur at the place of
a noun and can also take a semantic marker after
them. This decreases the accuracy in two ways;
the wrong disambiguation of KER tag and the
wrong disambiguation of unknown verbal nouns.
Due to the small amount of training data, un-
known words are frequent in the test corpus.
Whenever an unknown word occurs at the place
of a noun, the most probable tag for that word
will be noun which is wrong in our case. Table
11 shows an example of such a scenario.
</bodyText>
<table confidence="0.80394625">
.l.., 1__� 1::�_S flS
baad Kay kernay kam
NN P VB NN
after -- doing work
After doing work
|XML |xmlLoc_6 xmlBold_no xmlItalic_no xmlFontSize_common xmlPic_no xmlTable_no xmlBullet_yes bi_xmlSFBIA_new bi_xmlPara_new
1__� -A rl�
kay ker kam
KER VB NN
-- Doing work
(After) doing work
All the taggers other than the SVM tool have
difficulties to disambiguate between KER tags
and semantic markers.
�� ����� -4 u_4 ��������
do khoraak Ko log zarorat-
mand
VB NN P NN ADJ
give food To people needy
Give food to the needy people
.s� ����� �� ��������
do khoraak ko zaroratmand
VB NN P NN
give food To needy
</table>
<bodyText confidence="0.994873875">
Give food to the needy
“Table 12: (a) Occurrence of adjective with
noun, (b) dropping of main noun from the noun
phrase. In that case, adjective becomes the
noun.”
Coming to open class tags, the most frequent
errors are between noun and the other open class
tags in the noun phrase like proper noun, adjec-
tive and adverb. In Urdu, there is no clear dis-
tinction between noun and proper noun. The
phenomenon of dropping of words is also fre-
quent in Urdu. If a noun in a noun phrase is
dropped, the adjective becomes a noun in that
phrase (see table 12). The ambiguity between
noun and verb is due to verbal nouns as ex-
plained above (see table 11).
</bodyText>
<sectionHeader confidence="0.995037" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999805444444445">
In this paper, probabilistic part of speech tagging
technologies are tested on the Urdu language.
The main goal of this work is to investigate
whether general disambiguation techniques and
standard POS taggers can be used for the tagging
of Urdu. The results of the taggers clearly answer
this question positively. With the small training
corpus, all the taggers showed accuracies around
95%. The SVM tool shows the best accuracy in
</bodyText>
<footnote confidence="0.9950608">
8 One possible solution to this problem could be to intro-
duce a separate tag for verbal nouns which will certainly
remove the ambiguity between the KER tag and the seman-
tic marker and reduce the ambiguity between verb and
noun.
</footnote>
<page confidence="0.995936">
697
</page>
<bodyText confidence="0.981661">
disambiguating the known words and the RF
tagger shows the best accuracy in detecting the
tags of unknown words.
</bodyText>
<subsectionHeader confidence="0.264306">
Appendices
</subsectionHeader>
<bodyText confidence="0.452691333333333">
Appendix A. Urdu part of speech tagset
Following is the complete list of the tags of Ur-
du. There are some occurrences in which two
Urdu words are mapped to the same translation
of English. There are two reasons for that, ei-
ther the Urdu words have different case or there
is no significant meaning difference between
the two words which can be described by dif-
ferent English translations.
</bodyText>
<table confidence="0.999884843373494">
Tag Example
Personal demonstra- [\ Z (you) Y
tive (PD) Z (we) Y~
#� Z(this) ]� Z(you9)
(that) ^1 Z(that)
Relative demonstra- Z (that)`- Z (that) !�
tive (RD) (that)j!�-
Kaf demonstrative {�!� Z (whose)`&amp;
(KD) (someone)
Adverbial demonstr- Z (then) |6 Z (now) Yl
ative (AD) (here) vY, Z (here) �*►
Noun (NN) (earth) `~~~ Z (ship) ~���
�€�� Z (boy) ��•&amp;quot; Z
Z (inside) �$�� Z (above)
(like) ‚-ƒ Z (with) •���
Proper noun (PN) Z (Germany) {&gt;���
(Pakistan) &amp;U...!a€
Personal pronoun Z (you) Y
(PP) Z (we) Y~ Z (I)~~~
#� Z (he) ]� Z (you) [\
(he)^1 Z (he)
Reflexive pronoun [\ Z (myself) *!&lt;
(RP) (myself)
Relative pronoun Z (that)`� Z (that)!-
(REP) (that)u!�-
Adverbial pronoun Z (then) |6 Z (now) Yl
(AD) (here) vY. Z (here) �*►
Kaf pronoun (KP) {�!� Z (who) �!�
(which) `A Z Z(someone)
Adverbial kaf pro |6 Z (where) _&gt;}$&amp;quot;
(AKP) (how) L...4 Z (when)
Genitive reflexive (my) �&gt;€�
(GR)
Genitives (G) Z (your) ������ Z (my) ����
(your) I.0 Z (our) I_)L-�
Verb (VB) Z (eat) U• 4 Z (write) U †&amp;quot;
(do) U-4 Z (go) LL:-
Aspectual auxiliary 10 ]†‡ Z~~~~ Z~~~
(AA)
Tense auxiliary (TA) L�P Z (are) u: Z (is) ��
(were) =,�P Z(was)
Adjective (ADJ) ‰~!Š&apos;!&lt; Z (cruel) Y&amp;quot;~ˆ
-)9‹�� Z(beautiful)
(weak)
Adverb (ADV) Z (very) •���� Z (very) •�&apos;
(very) l•&apos;
Quantifier (Q) Z (all) SUSZ (some) ~Œ~
•S Z (this much) =I
(total)
Cardinal (CA) `�� Z (two) �* Z (one) ‘��
(three)
Ordinal (OR) ~~~~* Z (first) ’�€
(last) “y\ Z (second)
Fractional (FR) Z (one fourth){~~~
!‡
(two and a half) {��}”
Multiplicative (two UL Z (times)U&amp;
(MUL) times)
Measuring unit (U) (kilo) !•~
Coordinating (CC) (or) &gt; , (and) -)9►
Subordinating (SC) (because) ]†~!~~,(that) ]~
Intensifier (I) !� Z{ep Z{~
Adjectival particle (like) LW
KER -A Z�
Pre-title (PRT) (Mr.)LA- Z (Mr.)‰�–—
Post-title (POT) (Mr.)|—1— Z {-
Case marker (P) Z~~ Z �� Z {� Z !� Z ��
Z~€ Z ‘•� ‘� Z~~~
SE (SE) ��
WALA (WALA) �&amp;quot;�� Z{&amp;quot;~~ Z˜~~
Negation (NEG) [ (not/no)u�H Z ]~]
Interjection (INT) Z› vLœ�. , (hurrah) #��
(Good)4‡l
Question word (why) Li!4 Z (what) LS
(QW)
Sentence marker ‘.’, ‘?’
(SM)
Phrase marker (PM) ‘,’ , ‘;’
DATE 2007, 1999
Expression (Exp): Any word or symbol which
is not handled in the tagset will be catered un-
der expression. It can be mathematical sym-
bols, digits, etc.
</table>
<tableCaption confidence="0.545371">
“Table 13: Tagset of Urdu”
</tableCaption>
<footnote confidence="0.934935">
9 Polite form of you which is used while talking with the elders and
with the strangers
10 They always occur with a verb and can not be translated stand-
alone.
</footnote>
<page confidence="0.992467">
698
</page>
<bodyText confidence="0.689865">
Appendix B. Examples of WALA, Noun with
locative behavior, KAF pronoun and KAF
demonstrative and multiplicative.
</bodyText>
<table confidence="0.959177260869565">
WALA ˜Is:
Attributive Demonstrative Occupation
˜19 ‰‹ž ˜19 ]� ˜19 }*j*
Respectable This one Milk man
Manner Possession Time
˜19 ]„...�\ !&amp;€ ˜li LJ!Ÿ�L -)L,sl ˜li C.—
The one with the Flower with Morning
manner “slow” thorns newspaper
Place Doer --
li!, ˜�� ���&apos; ˜�� �&gt;}•€ --
Shoes which is The one whose --
bought from study
some other
country
“Table 14: Examples of tag WALA”
Noun with locative behavior:
Adverb Noun
d1 � li\ �� �Œ�&amp;quot; from
Down shop Coming
downstairs
Postposition Noun
~Œ~~ �� ‹�� ���� ~Œ~~
Under the table Goes down
</table>
<tableCaption confidence="0.38564">
“Table 15: Examples of noun with locative be-
havior
</tableCaption>
<sectionHeader confidence="0.323276" genericHeader="conclusions">
Multiplicative:
</sectionHeader>
<bodyText confidence="0.837484384615385">
¢�� �£!� (�&gt;��*) &gt;&gt;�* �� +¡� #.s
He is two times fatter than me.
“Table 16: Example of Multiplicative
KAF pronoun and KAF demonstrative:
KAF pronoun
¥ v„ =„¤&amp;quot; ,=*‡1 ~\ !~ �!�!&amp;quot; `�
Which people like mangoes?
KAF Demonstrative
Adverbial KAF pronoun
¥ �� ��� �}$� #�
Where did he go?
“Table 17: Examples of KAF pronoun and KAF
demonstrative
</bodyText>
<sectionHeader confidence="0.994801" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981370193548387">
Bahl, L. R. and Mercer, R. L. 1976. Part of
speech assignment by a statistical decision algo-
rithm, IEEE International Symposium on Infor-
mation Theory, pp. 88-89.
Bhatia, TK and Koul, A. 2000. Colloquial Urdu.
London: Routledge.
Brants, Thorsten. 2000. TnT – a statistical part-
of-speech tagger. In Proceedings of the Sixth Ap-
plied Natural Language Processing Conference
ANLP-2000 Seattle, WA.
Brill, E. 1992. A simple rule-based part of
speech tagger, Department of Computer Science,
University of Pennsylvania.
Butt, M. 1995. The structure of complex predi-
cates in Urdu. CSLI, Stanford.
Chanod, Jean-Pierre and Tapananinen, Pasi
1994. Statistical and constraint-Based taggers for
French, Technical report MLTT-016, RXRC
Grenoble.
Church, K. W. 1988. A stochastic parts program
and noun phrase parser for unrestricted test, In
the proceedings of 2nd conference on Applied
Natural Language Processing, pp. 136-143.
Giménez and Màrquez. 2004. SVMTool: A gen-
eral POS tagger generator based on support vec-
tor machines. In Proceedings of the IV Interna-
tional Conference on Language Resources and
Evaluation (LREC’ 04), Lisbon, Portugal.
Green, B. and Rubin, G. 1971. Automated
grammatical tagging of English, Department of
Linguistics, Brown University.
</reference>
<figure confidence="0.836663">
¥ � �„¤&amp;quot; GSI �\ !4 `6
Which one like mangoes?
</figure>
<page confidence="0.987009">
699
</page>
<reference confidence="0.999372261904762">
Haq, M. Abdul. 1987. j�J j-1 s may—, Amju-
man-e-Taraqqi Urdu (Hind).
Hardie, A. 2003. Developing a tag-set for auto-
mated part-of-speech tagging in Urdu. In Archer,
D, Rayson, P, Wilson, A, and McEnery, T (eds.)
Proceedings of the Corpus Linguistics 2003 con-
ference. UCREL Technical Papers Volume 16.
Department of Linguistics, Lancaster University,
UK.
Hardie, A. 2003a. The computational analysis of
morphosyntactic categories in Urdu, PhD thesis,
Lancaster University.
Hindle, D. 1989. Acquiring disambiguation rules
from text, Proceedings of 27th annual meeting of
Association for Computational Linguistics.
van Halteren, H, 2005. Syntactic Word Class
Tagging, Springer.
Javed, Ismat. 1981. �� ����� s.�J, Taraqqi Urdu
Bureau, New Delhi.
Klein, S. and Simmons, R.F. 1963. A computa-
tional approach to grammatical coding of English
words, JACM 10: pp. 334-347.
Marcus, M. P., Santorini, B. and Marcinkiewicz,
M. A. 1993. Building a large annotated corpus of
English: the Penn Treebank Computational Lin-
guistics 19, pp. 313-330
Platts, John T 1909. A grammar of the Hindusta-
ni or Urdu language, London.
Schmid, H. 1994. Probabilistic part-of-speech
tagging using decision tree, Institut für Maschi-
nelle Sprachverarbeitung, Universität Stuttgart,
Germany.
Schmid, H. 1994a. Part-of-speech tagging with
neural networks, In the Proceedings of Interna-
tional Conference on Computational Linguistics,
pp. 172-176, Kyoto, Japan.
Schmid, H. and Laws, F. 2008. Estimation of
conditional Probabilities with Decision Trees and
an Application to Fine-Grained POS tagging,
COLING 2008, Manchester, Great Britain.
Schmidt, RL 1999. Urdu: an essential grammar,
London: Routledge.
</reference>
<page confidence="0.996412">
700
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.996957">Tagging Urdu Text with Parts of Speech: A Tagger Comparison</title>
<author confidence="0.967631">Hassan Sajjad Helmut Schmid</author>
<affiliation confidence="0.997807">Universität Stuttgart Universität Stuttgart</affiliation>
<address confidence="0.954703">Stuttgart. Germany Stuttgart, Germany</address>
<email confidence="0.84864">sajjad@ims.uni-stuttgart.deschmid@ims.uni-stuttgart.de</email>
<abstract confidence="0.956768380165289">In this paper, four state-of-art probabilistic taggers i.e. TnT tagger, TreeTagger, RF tagger and SVM tool, are applied to the Urdu language. For the purpose of the experiment, a syntactic tagset is proposed. A training corpus of 100,000 tokens is used to train the models. Using the lexicon extracted from the training corpus, SVM tool shows the best accuracy of 94.15%. After providing a separate lexicon of 70,568 types, SVM tool again shows the best accuracy of 95.66%. 1 Urdu Language Urdu belongs to the Indo-Aryan language family. It is the national language of Pakistan and is one of the official languages of India. The majority of the speakers of Urdu spread over the area of South Asia, South Africa and the United King- Urdu is a free order language with general word order SOV. It shares its phonological, morphological and syntactic structures with Hindi. Some linguists considered them as two different dialects of one language (Bhatia and Koul, 2000). However, Urdu is written in Perso-arabic script and inherits most of the vocabulary from Arabic and Persian. On the other hand, Hindi is written in Devanagari script and inherits vocabulary from Sanskrit. Urdu is a morphologically rich language. Forms of the verb, as well as case, gender, and number are expressed by the morphology. Urdu represents case with a separate character after the head noun of the noun phrase. Due to their separate occurrence and their place of occurrence, they are sometimes considered as postpositions. them as case markers, Urdu has nocode=URD minative, ergative, accusative, dative, instrumental, genitive and locative cases (Butt, 1995: pg 10). The Urdu verb phrase contains a main verb, a light verb describing the aspect, and a tense verb describing the tense of the phrase (Hardie, 2003; Hardie, 2003a). 2 Urdu Tagset There are various questions that need to be answered during the design of a tagset. The granularity of the tagset is the first problem in this regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which improves the accuracy of manual 1993). Urdu is influenced from Arabic, and can be considered as having three main parts of speech, namely noun, verb and particle (Platts, 1909; Javed, 1981; Haq, 1987). However, some grammarians proposed ten main parts of speech for Urdu (Schmidt, 1999). The work of Urdu grammar writers provides a full overview of all the features of the language. However, in the perspective of the tagset, their analysis is lacking the computational grounds. The semantic, morphological and syntactic categories are mixed in their distribution of parts of speech. For example, Haq (1987) divides the common nouns into situational (smile, sadness, darkness), locative (park, office, morning, evening), instrumental (knife, sword) and collective nouns (army, data). In 2003, Hardie proposed the first computational part of speech tagset for Urdu (Hardie, part of speech tagger for Indian languages, available at http://shiva.iiit.ac.in/SPSAL2007 /iiit_tagset_guidelines.pdf of the 12th Conference of the European Chapter of the pages 692–700, Greece, 30 March – 3 April 2009. Association for Computational Linguistics 692 2003a). It is a morpho-syntactic tagset based on the EAGLES guidelines. The tagset contains 350 different tags with information about number, gender, case, etc. (van Halteren, 2005). The EAGLES guidelines are based on three levels, major word classes, recommended attributes and optional attributes. Major word classes include thirteen tags: noun, verb, adjective, pronoun/determiner, article, adverb, adposition, conjunction, numeral, interjection, unassigned, residual and punctuation. The recommended attributes include number, gender, case, finitevoice, In this paper, we will focus on purely syntactic distributions thus will not go into the details of the recommended attributes of the EAGLES guidelines. Considering the EAGLES guidelines and the tagset of Hardie in comparison with the general parts of speech of Urdu, there are no articles in Urdu. Due to the phrase level and semantic differences, pronoun and demonstrative are separate parts of speech in Urdu. In the Hardie tagset, the possessive pronouns like ►-&gt;,- /mera/ (my), ►,ttz /tumhara/ (your), ►_)&gt;� /humara/ (our) are assigned to the category of possessive adjective. Most of the Urdu grammarians consider them as pronouns (Platts, 1909; Javed, 1981; Haq, 1987). However, all these possessive pronouns require a noun in their noun phrase, thus show a similar behavior as demonstratives. The locative and temporal adverbs (uy, /yahan/ (here), jlis /wahan/ (there), Y► /ab/ (now), etc.) and, the locative and temporal nouns (C.1— /subah/ (morning), �U /sham/ (evening), -*K /gher/ (home)) appear in a very similar syntactic context. In order to keep the structure of pronoun and noun consistent, locative and temporal adverbs are treated as pronouns. The tense and aspect of a verb in Urdu is represented by a sequence of auxiliaries. Considthe �� v_) &gt;, vis fl� 6L-:-</abstract>
<author confidence="0.733324">Hai raha Ja kerta kam Jan Is Doing Kept Work John John is kept on doing work</author>
<abstract confidence="0.989544290178571">Table 1: The aspect of the verb U-A /kerta/ (doing) is represented by two separate words t:- /ja/ and li_) /raha/ and the last word of the sentence ,-, /hai/ (is) shows the tense of the verb.” details on the EAGLES guidelines can be found at: http://www.ilc.cnr.it/EAGLES/browse.html is written in right to left direction. The above considerations lead to the following tagset design for Urdu. The general parts of speech are noun, pronoun, demonstrative, verb, adjective, adverb, conjunction, particle, number and punctuation. The further refinement of the tagset is based on syntactic properties. The morphologically motivated features of the language are not encoded in the tagset. For example, an Urdu verb has 60 forms which are morphologically derived from its root form. All these forms are annotated with the same category i.e. verb. During manual tagging, some words are hard for the linguist to disambiguate reliably. In order to keep the training data consistent, such words are assigned a separate tag. For instance, the semantic marker =- /se/ gets a separate tag due to its various confusing usages such as locative and instrumental (Platts, 1909). The tagset used in the experiments reported in this paper contains 42 tags including three special tags. Nouns are divided into noun (NN) and proper name (PN). Demonstratives are divided into personal (PD), KAF (KD), adverbial (AD) and relative demonstratives (RD). All four categories of demonstratives are ambiguous with four categories of pronouns. Pronouns are divided into six types i.e. personal (PP), reflexive (RP), relative (REP), adverbial (AP), KAF (KP) and adverbial KAF (AKP) pronouns. Based on phrase level differences, genitive reflexive (GR) and genitive (G) are kept separate from pronouns. The verb phrase is divided into verb, aspectual auxiliaries and tense auxiliaries. Numerals are divided into cardinal (CA), ordinal (OR), fractional (FR) and multiplicative (MUL). Conjunctions are divided into coordinating (CC) and subordinating (SC) conjunctions. All semantic markers except ,=- /se/ are kept in one category. Adjective (ADJ), adverb (ADV), quantifier (Q), measuring unit (U), intensifier (I), interjection (INT), negation (NEG) and question words (QW) are handled as separate categories. Adjectival particle (A), KER (KER), SE (SE) and WALA (WALA) are ambiguous entities which are annotated with separate tags. A complete list of the tags with the examples is given in appendix A. The examples of the weird categories such as WALA, KAF pronoun, KAF demonstratives, etc. are given in appendix B. 3 Tagging Methodologies The work on automatic part of speech tagging started in early 1960s. Klein and Simmons 693 (1963) rule based POS tagger can be considered as the first automatic tagging system. In the rule based approach, after assigning each word its potential tags, a list of hand written disambiguation rules are used to reduce the number of tags to one (Klein and Simmons, 1963; Green and Rubin, 1971; Hindle, 1989; Chanod and Tapanainen 1994). A rule based model has the disadvantage of requiring lots of linguistic efforts to write rules for the language. Data-driven approaches resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Brill’s tagger requires training on a large number of rules which reduces the efficiency of machine learning process. Statistical approaches usually achieve an accuracy of 96%-97% (Hardie, 2003: 295). However, statistical taggers require a large training corpus to avoid data sparseness. The problem of low frequencies can be resolved by applying different methods such as smoothing, decision trees, etc. In the next section, an overview of the statistical taggers is provided which are evaluated on the Urdu tagset. 3.1 Probabilistic Disambiguation The Hidden Markov model is the most widely used method for statistical part of speech tagging. Each tag is considered as a state. States are connected by transition probabilities which represent the cost of moving from one state to another. The probability of a word having a particular tag is called lexical probability. Both, the transitional and the lexical probabilities are used to select the tag of a particular word. As a standard HMM tagger, The TnT tagger is used for the experiments. The TnT tagger is a trigram HMM tagger in which the transition probability depends on two preceding tags. The performance of the tagger was tested on NEGRA corpus and Penn Treebank corpus. The average accuracy of the tagger is 96% to 97% (Brants, 2000). The second order Markov model used by the TnT tagger requires large amounts of tagged data to get reasonable frequencies of POS trigrams. The TnT tagger smooths the probability with linear interpolation to handle the problem of data sparseness. The Tags of unknown words are predicted based on the word suffix. The longest ending string of an unknown word having one or more occurrences in the training corpus is considered as a suffix. The tag probabilities of a suffix are evaluated from all the words in the training corpus (Brants, 2000). In 1994, Schmid proposed a probabilistic part of speech tagger very similar to a HMM based tagger. The transition probabilities are calculated by decision trees. The decision tree merges infrequent trigrams with similar contexts until the trigram frequencies are large enough to get reliable estimates of the transition probabilities. The TreeTagger uses an unknown word POS guesser similar to that of the TnT tagger. The TreeTagger was trained on 2 million words of the Penn-Treebank corpus and was evaluated on 100,000 words. Its accuracy is compared against a trigram tagger built on the same data. The TreeTagger showed an accuracy of 96.06% (Schmid, 1994a). In 2004, Giménez and Màrquez proposed a part of speech tagger (SVM tool) based on support vector machines and reported accuracy higher than all state-of-art taggers. The aim of the development was to have a simple, efficient, robust tagger with high accuracy. The support vector machine does a binary classification of the data. It constructs an N-dimensional hyperplane that separates the data into positive and negative classes. Each data element is considered as a vector. Those vectors which are close to the sehyperplane are called support A support vector machine has to be trained for each tag. The complexity is controlled by introducing a lexicon extracted from the training data. Each word tag pair in the training corpus is considered as a positive case for that tag class and all other tags in the lexicon are considered negative cases for that word. This feature avoids generating useless cases for the comparison of classes. The SVM tool was evaluated on the English Penn Treebank. Experiments were conducted using both polynomial and linear kernels. When using n-gram features, the linear kernel showed a significant improvement in speed and accuracy. Unknown words are considered as the most ambiguous words by assigning them all open class POS tags. The disambiguation of unknowns uses features such as prefixes, suffixes, Moore: http://www.autonlab.org/tutorials/svm.html 694 upper case, lower case, word length, etc. On the Penn Treebank corpus, SVM tool showed an accuracy of 97.16% (Giménez and Màrquez, 2004). In 2008, Schmid and Florian proposed a probabilistic POS tagger for fine grained tagsets. The basic idea is to consider POS tags as sets of attributes. The context probability of a tag is the product of the probabilities of its attributes. The probability of an attribute given the previous tags is estimated with a decision tree. The decision tree uses different context features for the prediction of different attributes (Schmid and Laws, 2008). The RF tagger is well suited for languages with a rich morphology and a large fine grained tagset. The RF tagger was evaluated on the German Tiger Treebank and Czech Academic corpus which contain 700 and 1200 POS tags, respectively. The RF tagger achieved a higher accuracy than TnT and SVMTool. Urdu is a morphologically rich language. Training a tagger on a large fine grained tagset requires a large training corpus. Therefore, the tagset which we are using for these experiments is only based on syntactic distributions. However, it is always interesting to evaluate new disambiguation ideas like RF tagger on different languages. 4 Experiments A corpus of approx 110,000 tokens was taken from a news corpus (www.jang.com.pk). In the filtering phase, diacritics were removed from the text and normalization was applied to keep the Unicode of the characters consistent. The problem of space insertion and space deletion was manually solved and space is defined as the word boundary. The data was randomly divided into two parts, 90% training corpus and 10% test corpus. A part of the training set was also used as held out data to optimize the parameters of the taggers. The statistics of the training corpus and test corpus are shown in table 2 and table 3. The optimized parameters of the TreeTagger are context size 2, with minimum information gain for decision tree 0.1 and information gain at leaf node 1.4. For TnT, a default trigram tagger is used with suffix length of 10, sparse data mode 4 with lambda1 0.03 and lambda2 0.4. The RF tagger uses a context length of 4 with threshold of suffix tree pruning 1.5. The SVM tool is trained at right to left direction with model 4. Model 4 improves the detection of unknown words by artificially marking some known words as unknown words and then learning the model.</abstract>
<note confidence="0.686746875">Training corpus Test corpus Tokens 100,000 9000 Types 7514 1931 Unknown Tokens -- 754 Unknown Types -- 444 “Table 2: Statistics of training and test data.” Tag Total Unknown Tag Total Un-known NN 2537 458 PN 459 101</note>
<phone confidence="0.687306">P 1216 0 AA 379 0 VB 971 81 TA 285 0</phone>
<abstract confidence="0.993091444444444">ADJ 510 68 ADV 158 21 “Table 3: Eight most frequent tags in the test corpus.” In the first experiment, no external lexicon was provided. The types from the training corpus were used as the lexicon by the tagger. SVM tool showed the best accuracy for both known and unknown words. Table 4 shows the accuracies of all the taggers. The baseline result where each word is annotated with its most frequent tag, irrespective of the context, is 88.0%. TnT tagger TreeTagger RF tagger SVM tagger 93.40% 93.02% 93.28% 94.15% Known 95.78% 95.60% 95.68% 96.15% Unknown 68.44% 65.92% 68.08% 73.21% “Table 4: Accuracies of the taggers without using any external lexicon. SVM tool shows the best result for both known and unknown words.” The taggers show poor accuracy while detecting proper names. In most of the cases, proper name is confused with adjective and noun. This is because in Urdu, there is no clear distinction between noun and proper name. Also, the usage of an adjective as a proper name is a frequent phenomenon in Urdu. The accuracies of open class tags are shown in table 5. The detailed discussion on the results of the taggers is done after providing an external lexicon to the taggers. 695 Tag TnT tagger Tree- Tagger RF tagger SVM tagger VB 93.20% 91.86% 92.68% 94.23% NN 94.12% 96.21% 93.89% 96.45% PN 73.20% 66.88% 72.77% 68.62% ADV 75.94% 72.78% 74.68% 72.15% ADJ 85.67% 80.78% 86.5% 85.88% “Table 5: Accuracies of open class tags without having an external lexicon” In the second stage of the experiment, a large lexicon consisting of 70,568 types was pro- After adding the lexicon, there are 112 unknown tokens and 81 unknown types in the SVM tool again showed the best accuracy of 95.66%. Table 6 shows the accuracy of the taggers. The results of open class words significantly improve due to the smaller number of unknown words in the test corpus. The total accuracy of open class tags and their accuracy on unknown words are given in table 7 and table 8 respectively. TnT tagger Tree- Tagger RF tagger SVM tool 94.91% 95.17% 95.26% 95.66% Known 95.42% 95.65% 95.66% 96.11% Unknown 56.25% 58.04% 64.60% 61.61% “Table 6: Accuracies of the taggers after adding the lexicon. SVM tool shows the best accuracy for known word disambiguation. RF tagger shows the best accuracy for unknown words.” Tag TnT tagger Tree- Tagger RF tagger SVM tool VB 95.88% 95.88% 96.58% 96.80% NN 94.64% 95.85% 94.79% 96.64% PN 86.92% 79.73% 84.96% 81.70% ADV 82.28% 79.11% 81.64% 81.01% ADJ 91.59% 89.82% 92.37% 88.26% “Table 7: Accuracies of open class tags after adding an external lexicon.” lexicon is taken from CRULP, Lahore, Pakistan (www.crulp.org). lexicon was added by using the default settings provided by each tagger. No probability distribution information was given with the lexicon. Tag TnT tagger Tree- Tagger RF tagger SVM tool VB 28.57% 0.00% 42.86% 42.86% NN 74.47% 95.74% 80.85% 80.85% PN 68.18% 54.54% 63.63% 50.00% ADV 8.33% 0.00% 8.33% 0.00% ADJ 30.00% 20.00% 70.00% 80.00% “Table 8: Accuracies of open class tags on unknown words. The number of unknown words with tag VB and ADJ are less than 10 in this experiment.” The results of the taggers are analyzed by finding the most frequently confused pairs for all the taggers. It includes both the known and unknown words. Only those pairs are added in the table which have an occurrence of more than 10. Table 9 shows the results.</abstract>
<note confidence="0.902497111111111">Confused pair TnT tagger Tree- Tagger RF tagger SVM tool NN ADJ 85 87 87 95 NN PN 118 140 129 109 NN ADV 12 15 13 15 NN VB 14 17 12 12 VB TA 12 0 0 0 KER P 14 14 14 0 ADV ADJ 11 14 13 11 PD PP 26 26 30 14</note>
<abstract confidence="0.936996586206897">Table 9: Most frequently confused tag pairs with total number of occurrences.” The output of table 9 can be analyzed in many ways e.g. ambiguous tags, unknown words, open class tags, close class tags, etc. In the close class tags, the most frequent errors are between demonstrative and pronoun, and between KER tag and semantic marker (P). The difference between demonstrative and pronoun is at the phrase level. Demonstratives are followed by a noun which belongs to the same noun phrase whereas pronouns form a noun phrase by itself. Taggers analyze the language in a flat structure and are unable to handle the phrase level differences. It is interesting to see that the SVM tool shows a clear improvement in detecting the phrase level differences over the other taggers. It might be due to the SVM tool ability to look not only at 696 “Table 11: (a) Verbal noun with semantic mark- (b) syntactic structure of KER the neighboring tags but at the neighboring words as well. �� ����� ���� ��� �� Gay gayain Gana log Voh TA VB NN NN PD Will sing Song people Those Those people will sing a song. u�9 Ut e9</abstract>
<author confidence="0.752173">Gay Gayain gana Voh TA VB NN PP Will Sing Song those</author>
<abstract confidence="0.964785908256881">Those will sing a song. “Table 10: The word o9 /voh/ is occurring both as pronoun and demonstrative. In both of the cases, it is followed by a noun. But looking at the phrases, demonstrative o9 has the noun inside the noun phrase.” The second most frequent error among the closed class tags is the distinction between the KER tag ,=� /kay/ and the semantic marker =� /kay/. The KER tag always takes a verb before it and the semantic marker always takes a noun before it. The ambiguity arises when a verbal noun occurs. In the tagset, verbal nouns are handled as verb. Syntactically, verbal nouns occur at the place of a noun and can also take a semantic marker after them. This decreases the accuracy in two ways; the wrong disambiguation of KER tag and the wrong disambiguation of unknown verbal nouns. Due to the small amount of training data, unknown words are frequent in the test corpus. Whenever an unknown word occurs at the place of a noun, the most probable tag for that word will be noun which is wrong in our case. Table 11 shows an example of such a scenario. .l.., 1__� 1::�_S flS baad Kay kernay kam NN P VB NN after -doing work After doing work -A rl� kay ker kam KER VB NN -- Doing work (After) doing work All the taggers other than the SVM tool have difficulties to disambiguate between KER tags and semantic markers. �� ����� -4 u_4 �������� do khoraak Ko log zaroratmand VB NN P NN ADJ give food To people needy Give food to the needy people .s� ����� �� �������� do khoraak ko zaroratmand VB NN P NN give food To needy Give food to the needy “Table 12: (a) Occurrence of adjective with noun, (b) dropping of main noun from the noun phrase. In that case, adjective becomes the noun.” Coming to open class tags, the most frequent errors are between noun and the other open class tags in the noun phrase like proper noun, adjective and adverb. In Urdu, there is no clear distinction between noun and proper noun. The phenomenon of dropping of words is also frequent in Urdu. If a noun in a noun phrase is dropped, the adjective becomes a noun in that phrase (see table 12). The ambiguity between noun and verb is due to verbal nouns as explained above (see table 11). 6 Conclusion In this paper, probabilistic part of speech tagging technologies are tested on the Urdu language. The main goal of this work is to investigate whether general disambiguation techniques and standard POS taggers can be used for the tagging of Urdu. The results of the taggers clearly answer this question positively. With the small training corpus, all the taggers showed accuracies around 95%. The SVM tool shows the best accuracy in possible solution to this problem could be to introduce a separate tag for verbal nouns which will certainly remove the ambiguity between the KER tag and the semantic marker and reduce the ambiguity between verb and noun. 697 disambiguating the known words and the RF tagger shows the best accuracy in detecting the tags of unknown words. Appendices Appendix A. Urdu part of speech tagset Following is the complete list of the tags of Urdu. There are some occurrences in which two Urdu words are mapped to the same translation of English. There are two reasons for that, either the Urdu words have different case or there is no significant meaning difference between the two words which can be described by different English translations. Tag Example Personal demonstrative (PD) [\ Z (you) Y Z (we) Y~ Z(this) ]� (that) ^1 Z(that) Relative demonstrative (RD) Z (that)`- Z (that) !� (that)j!�- Kaf demonstrative (KD) {�!� Z (whose)`&amp; (someone) Adverbial demonstrative (AD) Z (then) |6 Z (now) Yl (here) vY, Z (here) �*► Noun (NN) (earth) `~~~ Z (ship) ~��� �€�� Z (boy) ��•&amp;quot; Z Z (inside) �$�� Z (above) (like) ‚-ƒ Z (with) •��� Proper noun (PN) Z (Germany) {&gt;��� (Pakistan) &amp;U...!a€ Personal pronoun (PP) Z (you) Y Z (we) Y~ Z (I)~~~ #� Z (he) ]� Z (you) [\ (he)^1 Z (he) Reflexive pronoun (RP) [\ Z (myself) *!&lt; (myself) Relative pronoun (REP) Z (that)`� Z (that)!- (that)u!�- Adverbial pronoun (AD) Z (then) |6 Z (now) Yl (here) vY. Z (here) �*►</abstract>
<note confidence="0.8809175">Kaf pronoun (KP) {�!� Z (who) �!� (which) `A Z Z(someone) Adverbial kaf pro (AKP) |6 Z (where) _&gt;}$&amp;quot; (how) L...4 Z (when) Genitive reflexive (GR) (my) �&gt;€� Genitives (G) Z (your) ������ Z (my) ���� (your) I.0 Z (our) I_)L-� Verb (VB) Z (eat) U• 4 Z (write) U †&amp;quot; (do) U-4 Z (go) LL:- Aspectual auxiliary (AA) 10]†‡ Z~~~~ Z~~~ Tense auxiliary (TA) L�P Z (are) u: Z (is) �� Z(was) Adjective (ADJ) ‰~!Š&apos;!&lt; Z (cruel) Y&amp;quot;~ˆ -)9‹�� Z(beautiful)</note>
<email confidence="0.361338">(weak)</email>
<abstract confidence="0.777362916666667">Adverb (ADV) Z (very) •���� Z (very) •�&apos; (very) l•&apos; Quantifier (Q) Z (all) SUSZ (some) ~Œ~ •S Z (this much) =I (total) Cardinal (CA) `�� Z (two) �* Z (one) ‘�� (three) Ordinal (OR) ~~~~* Z (first) ’�€ (last) “y\ Z (second) Fractional (FR) (one !‡ (two and a half) {��}” Multiplicative (MUL) (two UL Z (times)U&amp; times) Measuring unit (U) (kilo) !•~ Coordinating (CC) (or) &gt; , (and) -)9►</abstract>
<title confidence="0.723368666666667">Subordinating (SC) (because) ]†~!~~,(that) ]~ Intensifier (I) Adjectival particle (like) LW KER -A Z� Pre-title (PRT) (Mr.)LA- Z (Mr.)‰�–— Post-title (POT) Z {-</title>
<author confidence="0.712977">Z</author>
<note confidence="0.598953">Negation (NEG) [ (not/no)u�H Z ]~] Interjection (INT) Z› vLœ�. , (hurrah) #�� (Good)4‡l Question word (QW) (why) Li!4 Z (what) LS Sentence marker (SM) ‘.’, ‘?’ Phrase marker (PM) ‘,’ , ‘;’ DATE 2007, 1999</note>
<abstract confidence="0.841722666666667">Expression (Exp): Any word or symbol which not handled in the tagset will be catered unexpression. It can be mathematical bols, digits, etc. “Table 13: Tagset of Urdu” 9Polite form of you which is used while talking with the elders and with the strangers 10They always occur with a verb and can not be translated standalone. 698 Appendix B. Examples of WALA, Noun with locative behavior, KAF pronoun and KAF demonstrative and multiplicative. Attributive Demonstrative Occupation ˜19 ‰‹ž ˜19 ]� ˜19 }*j* Respectable This one Milk man Manner Possession Time ˜19 ]„...�\  !&amp;€ ˜li LJ!Ÿ�L ˜li C.— The one with the manner “slow” Flower with Morning thorns newspaper Place Doer -li!, ˜�� ���&apos; ˜�� �&gt;}•€ -- Shoes which is The one whose -bought from study some other country “Table 14: Examples of tag WALA” Noun with locative behavior: Adverb Noun d1 � �� from Down shop Coming downstairs Postposition Noun �� ‹�� Under the table Goes down “Table 15: Examples of noun with locative behavior Multiplicative: �£!� �� +¡� #.s He is two times fatter than me. “Table 16: Example of Multiplicative KAF pronoun and KAF demonstrative: KAF pronoun =„¤&amp;quot; ~\ !~ �!�!&amp;quot; `� Which people like mangoes? KAF Demonstrative Adverbial KAF pronoun ��� �}$� #� Where did he go? “Table 17: Examples of KAF pronoun and KAF demonstrative</abstract>
<note confidence="0.8231065">References Bahl, L. R. and Mercer, R. L. 1976. Part of speech assignment by a statistical decision algo- International Symposium on Inforpp. 88-89. Bhatia, TK and Koul, A. 2000. Colloquial Urdu. London: Routledge. Brants, Thorsten. 2000. TnT – a statistical parttagger. In of the Sixth Applied Natural Language Processing Conference WA. Brill, E. 1992. A simple rule-based part of</note>
<affiliation confidence="0.93032">speech tagger, Department of Computer Science, University of Pennsylvania.</affiliation>
<address confidence="0.749008">Butt, M. 1995. The structure of complex predi-</address>
<note confidence="0.948063074074074">cates in Urdu. CSLI, Stanford. Chanod, Jean-Pierre and Tapananinen, Pasi 1994. Statistical and constraint-Based taggers for French, Technical report MLTT-016, RXRC Grenoble. Church, K. W. 1988. A stochastic parts program and noun phrase parser for unrestricted test, In proceedings of conference on Applied Language pp. 136-143. Giménez and Màrquez. 2004. SVMTool: A general POS tagger generator based on support vecmachines. In of the IV International Conference on Language Resources and (LREC’ Lisbon, Portugal. Green, B. and Rubin, G. 1971. Automated grammatical tagging of English, Department of Linguistics, Brown University. �„¤&amp;quot; �\ !4 `6 Which one like mangoes? 699 Haq, M. Abdul. 1987. j�J j-1 s may—, Amjuman-e-Taraqqi Urdu (Hind). Hardie, A. 2003. Developing a tag-set for autopart-of-speech tagging in Urdu. In D, Rayson, P, Wilson, A, and McEnery, T (eds.) of Corpus Linguistics 2003 conference. UCREL Technical Papers Volume 16.</note>
<affiliation confidence="0.7385452">Department of Linguistics, Lancaster University, UK. Hardie, A. 2003a. The computational analysis of morphosyntactic categories in Urdu, PhD thesis, Lancaster University.</affiliation>
<address confidence="0.41506">Hindle, D. 1989. Acquiring disambiguation rules</address>
<note confidence="0.910069941176471">text, Proceedings of annual meeting of Association for Computational Linguistics. van Halteren, H, 2005. Syntactic Word Class Tagging, Springer. Javed, Ismat. 1981. �� ����� s.�J, Taraqqi Urdu Bureau, New Delhi. Klein, S. and Simmons, R.F. 1963. A computational approach to grammatical coding of English words, JACM 10: pp. 334-347. Marcus, M. P., Santorini, B. and Marcinkiewicz, M. A. 1993. Building a large annotated corpus of English: the Penn Treebank Computational Linguistics 19, pp. 313-330 Platts, John T 1909. A grammar of the Hindustani or Urdu language, London. Schmid, H. 1994. Probabilistic part-of-speech tagging using decision tree, Institut für Maschi-</note>
<affiliation confidence="0.928852">nelle Sprachverarbeitung, Universität Stuttgart,</affiliation>
<address confidence="0.967643">Germany.</address>
<note confidence="0.823255272727273">Schmid, H. 1994a. Part-of-speech tagging with networks, In the Proceedings of Interna- Conference on Computational pp. 172-176, Kyoto, Japan. Schmid, H. and Laws, F. 2008. Estimation of conditional Probabilities with Decision Trees and an Application to Fine-Grained POS tagging, Manchester, Great Britain. Schmidt, RL 1999. Urdu: an essential grammar, London: Routledge. 700</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L R Bahl</author>
<author>R L Mercer</author>
</authors>
<title>Part of speech assignment by a statistical decision algorithm,</title>
<date>1976</date>
<booktitle>IEEE International Symposium on Information Theory,</booktitle>
<pages>88--89</pages>
<contexts>
<context position="9198" citStr="Bahl and Mercer, 1976" startWordPosition="1457" endWordPosition="1460">st automatic tagging system. In the rule based approach, after assigning each word its potential tags, a list of hand written disambiguation rules are used to reduce the number of tags to one (Klein and Simmons, 1963; Green and Rubin, 1971; Hindle, 1989; Chanod and Tapanainen 1994). A rule based model has the disadvantage of requiring lots of linguistic efforts to write rules for the language. Data-driven approaches resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Brill’s tagger requires training on a large number of rules which reduces the efficiency of machine learning process. Statistical approaches usually achieve an accuracy of 96%-97% (Hardie, 2003: 295). However, statistical taggers require a large training corpus to avoid data sparseness. The problem of low frequencies can be resolved by applying different methods such as smoothing, de</context>
</contexts>
<marker>Bahl, Mercer, 1976</marker>
<rawString>Bahl, L. R. and Mercer, R. L. 1976. Part of speech assignment by a statistical decision algorithm, IEEE International Symposium on Information Theory, pp. 88-89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TK Bhatia</author>
<author>A Koul</author>
</authors>
<title>Colloquial Urdu.</title>
<date>2000</date>
<location>London: Routledge.</location>
<contexts>
<context position="1205" citStr="Bhatia and Koul, 2000" startWordPosition="184" endWordPosition="187">est accuracy of 94.15%. After providing a separate lexicon of 70,568 types, SVM tool again shows the best accuracy of 95.66%. 1 Urdu Language Urdu belongs to the Indo-Aryan language family. It is the national language of Pakistan and is one of the official languages of India. The majority of the speakers of Urdu spread over the area of South Asia, South Africa and the United Kingdom1. Urdu is a free order language with general word order SOV. It shares its phonological, morphological and syntactic structures with Hindi. Some linguists considered them as two different dialects of one language (Bhatia and Koul, 2000). However, Urdu is written in Perso-arabic script and inherits most of the vocabulary from Arabic and Persian. On the other hand, Hindi is written in Devanagari script and inherits vocabulary from Sanskrit. Urdu is a morphologically rich language. Forms of the verb, as well as case, gender, and number are expressed by the morphology. Urdu represents case with a separate character after the head noun of the noun phrase. Due to their separate occurrence and their place of occurrence, they are sometimes considered as postpositions. Considering them as case markers, Urdu has no1 http://www.ethnolo</context>
</contexts>
<marker>Bhatia, Koul, 2000</marker>
<rawString>Bhatia, TK and Koul, A. 2000. Colloquial Urdu. London: Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>TnT – a statistical partof-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Applied Natural Language Processing Conference ANLP-2000</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="10708" citStr="Brants, 2000" startWordPosition="1710" endWordPosition="1711">tes are connected by transition probabilities which represent the cost of moving from one state to another. The probability of a word having a particular tag is called lexical probability. Both, the transitional and the lexical probabilities are used to select the tag of a particular word. As a standard HMM tagger, The TnT tagger is used for the experiments. The TnT tagger is a trigram HMM tagger in which the transition probability depends on two preceding tags. The performance of the tagger was tested on NEGRA corpus and Penn Treebank corpus. The average accuracy of the tagger is 96% to 97% (Brants, 2000). The second order Markov model used by the TnT tagger requires large amounts of tagged data to get reasonable frequencies of POS trigrams. The TnT tagger smooths the probability with linear interpolation to handle the problem of data sparseness. The Tags of unknown words are predicted based on the word suffix. The longest ending string of an unknown word having one or more occurrences in the training corpus is considered as a suffix. The tag probabilities of a suffix are evaluated from all the words in the training corpus (Brants, 2000). In 1994, Schmid proposed a probabilistic part of speech</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Brants, Thorsten. 2000. TnT – a statistical partof-speech tagger. In Proceedings of the Sixth Applied Natural Language Processing Conference ANLP-2000 Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger,</title>
<date>1992</date>
<institution>Department of Computer Science, University of Pennsylvania.</institution>
<contexts>
<context position="9226" citStr="Brill, 1992" startWordPosition="1463" endWordPosition="1464">ule based approach, after assigning each word its potential tags, a list of hand written disambiguation rules are used to reduce the number of tags to one (Klein and Simmons, 1963; Green and Rubin, 1971; Hindle, 1989; Chanod and Tapanainen 1994). A rule based model has the disadvantage of requiring lots of linguistic efforts to write rules for the language. Data-driven approaches resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Brill’s tagger requires training on a large number of rules which reduces the efficiency of machine learning process. Statistical approaches usually achieve an accuracy of 96%-97% (Hardie, 2003: 295). However, statistical taggers require a large training corpus to avoid data sparseness. The problem of low frequencies can be resolved by applying different methods such as smoothing, decision trees, etc. In the ne</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Brill, E. 1992. A simple rule-based part of speech tagger, Department of Computer Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Butt</author>
</authors>
<title>The structure of complex predicates in Urdu.</title>
<date>1995</date>
<publisher>CSLI, Stanford.</publisher>
<contexts>
<context position="1937" citStr="Butt, 1995" startWordPosition="296" endWordPosition="297">r hand, Hindi is written in Devanagari script and inherits vocabulary from Sanskrit. Urdu is a morphologically rich language. Forms of the verb, as well as case, gender, and number are expressed by the morphology. Urdu represents case with a separate character after the head noun of the noun phrase. Due to their separate occurrence and their place of occurrence, they are sometimes considered as postpositions. Considering them as case markers, Urdu has no1 http://www.ethnologue.com/14/show_language.asp? code=URD minative, ergative, accusative, dative, instrumental, genitive and locative cases (Butt, 1995: pg 10). The Urdu verb phrase contains a main verb, a light verb describing the aspect, and a tense verb describing the tense of the phrase (Hardie, 2003; Hardie, 2003a). 2 Urdu Tagset There are various questions that need to be answered during the design of a tagset. The granularity of the tagset is the first problem in this regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to co</context>
</contexts>
<marker>Butt, 1995</marker>
<rawString>Butt, M. 1995. The structure of complex predicates in Urdu. CSLI, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Pierre Chanod</author>
<author>Pasi Tapananinen</author>
</authors>
<title>Statistical and constraint-Based taggers for French,</title>
<date>1994</date>
<tech>Technical report MLTT-016, RXRC Grenoble.</tech>
<marker>Chanod, Tapananinen, 1994</marker>
<rawString>Chanod, Jean-Pierre and Tapananinen, Pasi 1994. Statistical and constraint-Based taggers for French, Technical report MLTT-016, RXRC Grenoble.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted test,</title>
<date>1988</date>
<booktitle>In the proceedings of 2nd conference on Applied Natural Language Processing,</booktitle>
<pages>136--143</pages>
<contexts>
<context position="9212" citStr="Church, 1988" startWordPosition="1461" endWordPosition="1462">stem. In the rule based approach, after assigning each word its potential tags, a list of hand written disambiguation rules are used to reduce the number of tags to one (Klein and Simmons, 1963; Green and Rubin, 1971; Hindle, 1989; Chanod and Tapanainen 1994). A rule based model has the disadvantage of requiring lots of linguistic efforts to write rules for the language. Data-driven approaches resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Brill’s tagger requires training on a large number of rules which reduces the efficiency of machine learning process. Statistical approaches usually achieve an accuracy of 96%-97% (Hardie, 2003: 295). However, statistical taggers require a large training corpus to avoid data sparseness. The problem of low frequencies can be resolved by applying different methods such as smoothing, decision trees, </context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Church, K. W. 1988. A stochastic parts program and noun phrase parser for unrestricted test, In the proceedings of 2nd conference on Applied Natural Language Processing, pp. 136-143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giménez</author>
<author>Màrquez</author>
</authors>
<title>SVMTool: A general POS tagger generator based on support vector machines.</title>
<date>2004</date>
<booktitle>In Proceedings of the IV International Conference on Language Resources and Evaluation (LREC’ 04),</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="13474" citStr="Giménez and Màrquez, 2004" startWordPosition="2161" endWordPosition="2164">he comparison of classes. The SVM tool was evaluated on the English Penn Treebank. Experiments were conducted using both polynomial and linear kernels. When using n-gram features, the linear kernel showed a significant improvement in speed and accuracy. Unknown words are considered as the most ambiguous words by assigning them all open class POS tags. The disambiguation of unknowns uses features such as prefixes, suffixes, 5 Andrew Moore: http://www.autonlab.org/tutorials/svm.html 694 upper case, lower case, word length, etc. On the Penn Treebank corpus, SVM tool showed an accuracy of 97.16% (Giménez and Màrquez, 2004). In 2008, Schmid and Florian proposed a probabilistic POS tagger for fine grained tagsets. The basic idea is to consider POS tags as sets of attributes. The context probability of a tag is the product of the probabilities of its attributes. The probability of an attribute given the previous tags is estimated with a decision tree. The decision tree uses different context features for the prediction of different attributes (Schmid and Laws, 2008). The RF tagger is well suited for languages with a rich morphology and a large fine grained tagset. The RF tagger was evaluated on the German Tiger Tr</context>
</contexts>
<marker>Giménez, Màrquez, 2004</marker>
<rawString>Giménez and Màrquez. 2004. SVMTool: A general POS tagger generator based on support vector machines. In Proceedings of the IV International Conference on Language Resources and Evaluation (LREC’ 04), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Green</author>
<author>G Rubin</author>
</authors>
<title>Automated grammatical tagging of English,</title>
<date>1971</date>
<institution>Department of Linguistics, Brown University.</institution>
<contexts>
<context position="8816" citStr="Green and Rubin, 1971" startWordPosition="1394" endWordPosition="1397">tated with separate tags. A complete list of the tags with the examples is given in appendix A. The examples of the weird categories such as WALA, KAF pronoun, KAF demonstratives, etc. are given in appendix B. 3 Tagging Methodologies The work on automatic part of speech tagging started in early 1960s. Klein and Simmons 693 (1963) rule based POS tagger can be considered as the first automatic tagging system. In the rule based approach, after assigning each word its potential tags, a list of hand written disambiguation rules are used to reduce the number of tags to one (Klein and Simmons, 1963; Green and Rubin, 1971; Hindle, 1989; Chanod and Tapanainen 1994). A rule based model has the disadvantage of requiring lots of linguistic efforts to write rules for the language. Data-driven approaches resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Bril</context>
</contexts>
<marker>Green, Rubin, 1971</marker>
<rawString>Green, B. and Rubin, G. 1971. Automated grammatical tagging of English, Department of Linguistics, Brown University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Abdul Haq</author>
</authors>
<date>1987</date>
<note>j�J j-1 s may—, Amjuman-e-Taraqqi Urdu (Hind).</note>
<contexts>
<context position="2889" citStr="Haq, 1987" startWordPosition="460" endWordPosition="461">set may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging2 (Marcus et al., 1993). Urdu is influenced from Arabic, and can be considered as having three main parts of speech, namely noun, verb and particle (Platts, 1909; Javed, 1981; Haq, 1987). However, some grammarians proposed ten main parts of speech for Urdu (Schmidt, 1999). The work of Urdu grammar writers provides a full overview of all the features of the language. However, in the perspective of the tagset, their analysis is lacking the computational grounds. The semantic, morphological and syntactic categories are mixed in their distribution of parts of speech. For example, Haq (1987) divides the common nouns into situational (smile, sadness, darkness), locative (park, office, morning, evening), instrumental (knife, sword) and collective nouns (army, data). In 2003, Hardie </context>
<context position="5110" citStr="Haq, 1987" startWordPosition="790" endWordPosition="791">us will not go into the details of the recommended attributes of the EAGLES guidelines. Considering the EAGLES guidelines and the tagset of Hardie in comparison with the general parts of speech of Urdu, there are no articles in Urdu. Due to the phrase level and semantic differences, pronoun and demonstrative are separate parts of speech in Urdu. In the Hardie tagset, the possessive pronouns like ►-&gt;,- /mera/ (my), ►,ttz /tumhara/ (your), ►_)&gt;� /humara/ (our) are assigned to the category of possessive adjective. Most of the Urdu grammarians consider them as pronouns (Platts, 1909; Javed, 1981; Haq, 1987). However, all these possessive pronouns require a noun in their noun phrase, thus show a similar behavior as demonstratives. The locative and temporal adverbs (uy, /yahan/ (here), jlis /wahan/ (there), Y► /ab/ (now), etc.) and, the locative and temporal nouns (C.1— /subah/ (morning), �U /sham/ (evening), -*K /gher/ (home)) appear in a very similar syntactic context. In order to keep the structure of pronoun and noun consistent, locative and temporal adverbs are treated as pronouns. The tense and aspect of a verb in Urdu is represented by a sequence of auxiliaries. Consider the example4: �� v_</context>
</contexts>
<marker>Haq, 1987</marker>
<rawString>Haq, M. Abdul. 1987. j�J j-1 s may—, Amjuman-e-Taraqqi Urdu (Hind).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hardie</author>
</authors>
<title>Developing a tag-set for automated part-of-speech tagging in Urdu.</title>
<date>2003</date>
<booktitle>Proceedings of the Corpus Linguistics 2003 conference. UCREL Technical Papers Volume 16. Department of Linguistics,</booktitle>
<editor>In Archer, D, Rayson, P, Wilson, A, and McEnery, T (eds.)</editor>
<publisher>University, UK.</publisher>
<location>Lancaster</location>
<contexts>
<context position="2091" citStr="Hardie, 2003" startWordPosition="324" endWordPosition="325"> as case, gender, and number are expressed by the morphology. Urdu represents case with a separate character after the head noun of the noun phrase. Due to their separate occurrence and their place of occurrence, they are sometimes considered as postpositions. Considering them as case markers, Urdu has no1 http://www.ethnologue.com/14/show_language.asp? code=URD minative, ergative, accusative, dative, instrumental, genitive and locative cases (Butt, 1995: pg 10). The Urdu verb phrase contains a main verb, a light verb describing the aspect, and a tense verb describing the tense of the phrase (Hardie, 2003; Hardie, 2003a). 2 Urdu Tagset There are various questions that need to be answered during the design of a tagset. The granularity of the tagset is the first problem in this regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of ma</context>
<context position="9605" citStr="Hardie, 2003" startWordPosition="1524" endWordPosition="1525">hes resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Brill’s tagger requires training on a large number of rules which reduces the efficiency of machine learning process. Statistical approaches usually achieve an accuracy of 96%-97% (Hardie, 2003: 295). However, statistical taggers require a large training corpus to avoid data sparseness. The problem of low frequencies can be resolved by applying different methods such as smoothing, decision trees, etc. In the next section, an overview of the statistical taggers is provided which are evaluated on the Urdu tagset. 3.1 Probabilistic Disambiguation The Hidden Markov model is the most widely used method for statistical part of speech tagging. Each tag is considered as a state. States are connected by transition probabilities which represent the cost of moving from one state to another. Th</context>
</contexts>
<marker>Hardie, 2003</marker>
<rawString>Hardie, A. 2003. Developing a tag-set for automated part-of-speech tagging in Urdu. In Archer, D, Rayson, P, Wilson, A, and McEnery, T (eds.) Proceedings of the Corpus Linguistics 2003 conference. UCREL Technical Papers Volume 16. Department of Linguistics, Lancaster University, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hardie</author>
</authors>
<title>The computational analysis of morphosyntactic categories in Urdu, PhD thesis,</title>
<date>2003</date>
<institution>Lancaster University.</institution>
<contexts>
<context position="2091" citStr="Hardie, 2003" startWordPosition="324" endWordPosition="325"> as case, gender, and number are expressed by the morphology. Urdu represents case with a separate character after the head noun of the noun phrase. Due to their separate occurrence and their place of occurrence, they are sometimes considered as postpositions. Considering them as case markers, Urdu has no1 http://www.ethnologue.com/14/show_language.asp? code=URD minative, ergative, accusative, dative, instrumental, genitive and locative cases (Butt, 1995: pg 10). The Urdu verb phrase contains a main verb, a light verb describing the aspect, and a tense verb describing the tense of the phrase (Hardie, 2003; Hardie, 2003a). 2 Urdu Tagset There are various questions that need to be answered during the design of a tagset. The granularity of the tagset is the first problem in this regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of ma</context>
<context position="9605" citStr="Hardie, 2003" startWordPosition="1524" endWordPosition="1525">hes resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Brill’s tagger requires training on a large number of rules which reduces the efficiency of machine learning process. Statistical approaches usually achieve an accuracy of 96%-97% (Hardie, 2003: 295). However, statistical taggers require a large training corpus to avoid data sparseness. The problem of low frequencies can be resolved by applying different methods such as smoothing, decision trees, etc. In the next section, an overview of the statistical taggers is provided which are evaluated on the Urdu tagset. 3.1 Probabilistic Disambiguation The Hidden Markov model is the most widely used method for statistical part of speech tagging. Each tag is considered as a state. States are connected by transition probabilities which represent the cost of moving from one state to another. Th</context>
</contexts>
<marker>Hardie, 2003</marker>
<rawString>Hardie, A. 2003a. The computational analysis of morphosyntactic categories in Urdu, PhD thesis, Lancaster University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Acquiring disambiguation rules from text,</title>
<date>1989</date>
<booktitle>Proceedings of 27th annual meeting of Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8830" citStr="Hindle, 1989" startWordPosition="1398" endWordPosition="1399">s. A complete list of the tags with the examples is given in appendix A. The examples of the weird categories such as WALA, KAF pronoun, KAF demonstratives, etc. are given in appendix B. 3 Tagging Methodologies The work on automatic part of speech tagging started in early 1960s. Klein and Simmons 693 (1963) rule based POS tagger can be considered as the first automatic tagging system. In the rule based approach, after assigning each word its potential tags, a list of hand written disambiguation rules are used to reduce the number of tags to one (Klein and Simmons, 1963; Green and Rubin, 1971; Hindle, 1989; Chanod and Tapanainen 1994). A rule based model has the disadvantage of requiring lots of linguistic efforts to write rules for the language. Data-driven approaches resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high accuracy. However, Brill’s tagger req</context>
</contexts>
<marker>Hindle, 1989</marker>
<rawString>Hindle, D. 1989. Acquiring disambiguation rules from text, Proceedings of 27th annual meeting of Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H van Halteren</author>
</authors>
<title>Syntactic Word Class Tagging,</title>
<date>2005</date>
<publisher>Springer.</publisher>
<marker>van Halteren, 2005</marker>
<rawString>van Halteren, H, 2005. Syntactic Word Class Tagging, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ismat Javed</author>
</authors>
<title>s.�J, Taraqqi Urdu Bureau,</title>
<date>1981</date>
<location>New Delhi.</location>
<contexts>
<context position="2877" citStr="Javed, 1981" startWordPosition="458" endWordPosition="459">regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging2 (Marcus et al., 1993). Urdu is influenced from Arabic, and can be considered as having three main parts of speech, namely noun, verb and particle (Platts, 1909; Javed, 1981; Haq, 1987). However, some grammarians proposed ten main parts of speech for Urdu (Schmidt, 1999). The work of Urdu grammar writers provides a full overview of all the features of the language. However, in the perspective of the tagset, their analysis is lacking the computational grounds. The semantic, morphological and syntactic categories are mixed in their distribution of parts of speech. For example, Haq (1987) divides the common nouns into situational (smile, sadness, darkness), locative (park, office, morning, evening), instrumental (knife, sword) and collective nouns (army, data). In 2</context>
<context position="5098" citStr="Javed, 1981" startWordPosition="788" endWordPosition="789">tributions thus will not go into the details of the recommended attributes of the EAGLES guidelines. Considering the EAGLES guidelines and the tagset of Hardie in comparison with the general parts of speech of Urdu, there are no articles in Urdu. Due to the phrase level and semantic differences, pronoun and demonstrative are separate parts of speech in Urdu. In the Hardie tagset, the possessive pronouns like ►-&gt;,- /mera/ (my), ►,ttz /tumhara/ (your), ►_)&gt;� /humara/ (our) are assigned to the category of possessive adjective. Most of the Urdu grammarians consider them as pronouns (Platts, 1909; Javed, 1981; Haq, 1987). However, all these possessive pronouns require a noun in their noun phrase, thus show a similar behavior as demonstratives. The locative and temporal adverbs (uy, /yahan/ (here), jlis /wahan/ (there), Y► /ab/ (now), etc.) and, the locative and temporal nouns (C.1— /subah/ (morning), �U /sham/ (evening), -*K /gher/ (home)) appear in a very similar syntactic context. In order to keep the structure of pronoun and noun consistent, locative and temporal adverbs are treated as pronouns. The tense and aspect of a verb in Urdu is represented by a sequence of auxiliaries. Consider the exa</context>
</contexts>
<marker>Javed, 1981</marker>
<rawString>Javed, Ismat. 1981. �� ����� s.�J, Taraqqi Urdu Bureau, New Delhi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Klein</author>
<author>R F Simmons</author>
</authors>
<title>A computational approach to grammatical coding of English words,</title>
<date>1963</date>
<journal>JACM</journal>
<volume>10</volume>
<pages>334--347</pages>
<contexts>
<context position="8793" citStr="Klein and Simmons, 1963" startWordPosition="1390" endWordPosition="1393">s entities which are annotated with separate tags. A complete list of the tags with the examples is given in appendix A. The examples of the weird categories such as WALA, KAF pronoun, KAF demonstratives, etc. are given in appendix B. 3 Tagging Methodologies The work on automatic part of speech tagging started in early 1960s. Klein and Simmons 693 (1963) rule based POS tagger can be considered as the first automatic tagging system. In the rule based approach, after assigning each word its potential tags, a list of hand written disambiguation rules are used to reduce the number of tags to one (Klein and Simmons, 1963; Green and Rubin, 1971; Hindle, 1989; Chanod and Tapanainen 1994). A rule based model has the disadvantage of requiring lots of linguistic efforts to write rules for the language. Data-driven approaches resolve this problem by automatically extracting the information from an already tagged corpus. Ambiguity between the tags is resolved by selecting the most likely tag for a word (Bahl and Mercer, 1976; Church, 1988; Brill, 1992). Brill’s transformation based tagger uses lexical rules to assign each word the most frequent tag and then applies contextual rules over and over again to get a high </context>
</contexts>
<marker>Klein, Simmons, 1963</marker>
<rawString>Klein, S. and Simmons, R.F. 1963. A computational approach to grammatical coding of English words, JACM 10: pp. 334-347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English:</title>
<date>1993</date>
<journal>the Penn Treebank Computational Linguistics</journal>
<volume>19</volume>
<pages>313--330</pages>
<contexts>
<context position="2726" citStr="Marcus et al., 1993" startWordPosition="431" endWordPosition="434">). 2 Urdu Tagset There are various questions that need to be answered during the design of a tagset. The granularity of the tagset is the first problem in this regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging2 (Marcus et al., 1993). Urdu is influenced from Arabic, and can be considered as having three main parts of speech, namely noun, verb and particle (Platts, 1909; Javed, 1981; Haq, 1987). However, some grammarians proposed ten main parts of speech for Urdu (Schmidt, 1999). The work of Urdu grammar writers provides a full overview of all the features of the language. However, in the perspective of the tagset, their analysis is lacking the computational grounds. The semantic, morphological and syntactic categories are mixed in their distribution of parts of speech. For example, Haq (1987) divides the common nouns into</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, M. P., Santorini, B. and Marcinkiewicz, M. A. 1993. Building a large annotated corpus of English: the Penn Treebank Computational Linguistics 19, pp. 313-330</rawString>
</citation>
<citation valid="true">
<authors>
<author>John T Platts</author>
</authors>
<title>A grammar of the Hindustani or Urdu language,</title>
<date>1909</date>
<location>London.</location>
<contexts>
<context position="2864" citStr="Platts, 1909" startWordPosition="456" endWordPosition="457">oblem in this regard. A tagset may consist either of general parts of speech only or it may consist of additional morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging2 (Marcus et al., 1993). Urdu is influenced from Arabic, and can be considered as having three main parts of speech, namely noun, verb and particle (Platts, 1909; Javed, 1981; Haq, 1987). However, some grammarians proposed ten main parts of speech for Urdu (Schmidt, 1999). The work of Urdu grammar writers provides a full overview of all the features of the language. However, in the perspective of the tagset, their analysis is lacking the computational grounds. The semantic, morphological and syntactic categories are mixed in their distribution of parts of speech. For example, Haq (1987) divides the common nouns into situational (smile, sadness, darkness), locative (park, office, morning, evening), instrumental (knife, sword) and collective nouns (army</context>
<context position="5085" citStr="Platts, 1909" startWordPosition="786" endWordPosition="787"> syntactic distributions thus will not go into the details of the recommended attributes of the EAGLES guidelines. Considering the EAGLES guidelines and the tagset of Hardie in comparison with the general parts of speech of Urdu, there are no articles in Urdu. Due to the phrase level and semantic differences, pronoun and demonstrative are separate parts of speech in Urdu. In the Hardie tagset, the possessive pronouns like ►-&gt;,- /mera/ (my), ►,ttz /tumhara/ (your), ►_)&gt;� /humara/ (our) are assigned to the category of possessive adjective. Most of the Urdu grammarians consider them as pronouns (Platts, 1909; Javed, 1981; Haq, 1987). However, all these possessive pronouns require a noun in their noun phrase, thus show a similar behavior as demonstratives. The locative and temporal adverbs (uy, /yahan/ (here), jlis /wahan/ (there), Y► /ab/ (now), etc.) and, the locative and temporal nouns (C.1— /subah/ (morning), �U /sham/ (evening), -*K /gher/ (home)) appear in a very similar syntactic context. In order to keep the structure of pronoun and noun consistent, locative and temporal adverbs are treated as pronouns. The tense and aspect of a verb in Urdu is represented by a sequence of auxiliaries. Con</context>
<context position="6981" citStr="Platts, 1909" startWordPosition="1104" endWordPosition="1105">nt of the tagset is based on syntactic properties. The morphologically motivated features of the language are not encoded in the tagset. For example, an Urdu verb has 60 forms which are morphologically derived from its root form. All these forms are annotated with the same category i.e. verb. During manual tagging, some words are hard for the linguist to disambiguate reliably. In order to keep the training data consistent, such words are assigned a separate tag. For instance, the semantic marker =- /se/ gets a separate tag due to its various confusing usages such as locative and instrumental (Platts, 1909). The tagset used in the experiments reported in this paper contains 42 tags including three special tags. Nouns are divided into noun (NN) and proper name (PN). Demonstratives are divided into personal (PD), KAF (KD), adverbial (AD) and relative demonstratives (RD). All four categories of demonstratives are ambiguous with four categories of pronouns. Pronouns are divided into six types i.e. personal (PP), reflexive (RP), relative (REP), adverbial (AP), KAF (KP) and adverbial KAF (AKP) pronouns. Based on phrase level differences, genitive reflexive (GR) and genitive (G) are kept separate from </context>
</contexts>
<marker>Platts, 1909</marker>
<rawString>Platts, John T 1909. A grammar of the Hindustani or Urdu language, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision tree, Institut für Maschinelle Sprachverarbeitung,</title>
<date>1994</date>
<location>Universität Stuttgart, Germany.</location>
<contexts>
<context position="11912" citStr="Schmid, 1994" startWordPosition="1909" endWordPosition="1910">f speech tagger very similar to a HMM based tagger. The transition probabilities are calculated by decision trees. The decision tree merges infrequent trigrams with similar contexts until the trigram frequencies are large enough to get reliable estimates of the transition probabilities. The TreeTagger uses an unknown word POS guesser similar to that of the TnT tagger. The TreeTagger was trained on 2 million words of the Penn-Treebank corpus and was evaluated on 100,000 words. Its accuracy is compared against a trigram tagger built on the same data. The TreeTagger showed an accuracy of 96.06% (Schmid, 1994a). In 2004, Giménez and Màrquez proposed a part of speech tagger (SVM tool) based on support vector machines and reported accuracy higher than all state-of-art taggers. The aim of the development was to have a simple, efficient, robust tagger with high accuracy. The support vector machine does a binary classification of the data. It constructs an N-dimensional hyperplane that separates the data into positive and negative classes. Each data element is considered as a vector. Those vectors which are close to the separating hyperplane are called support vectors5. A support vector machine has to </context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, H. 1994. Probabilistic part-of-speech tagging using decision tree, Institut für Maschinelle Sprachverarbeitung, Universität Stuttgart, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Part-of-speech tagging with neural networks,</title>
<date>1994</date>
<booktitle>In the Proceedings of International Conference on Computational Linguistics,</booktitle>
<pages>172--176</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="11912" citStr="Schmid, 1994" startWordPosition="1909" endWordPosition="1910">f speech tagger very similar to a HMM based tagger. The transition probabilities are calculated by decision trees. The decision tree merges infrequent trigrams with similar contexts until the trigram frequencies are large enough to get reliable estimates of the transition probabilities. The TreeTagger uses an unknown word POS guesser similar to that of the TnT tagger. The TreeTagger was trained on 2 million words of the Penn-Treebank corpus and was evaluated on 100,000 words. Its accuracy is compared against a trigram tagger built on the same data. The TreeTagger showed an accuracy of 96.06% (Schmid, 1994a). In 2004, Giménez and Màrquez proposed a part of speech tagger (SVM tool) based on support vector machines and reported accuracy higher than all state-of-art taggers. The aim of the development was to have a simple, efficient, robust tagger with high accuracy. The support vector machine does a binary classification of the data. It constructs an N-dimensional hyperplane that separates the data into positive and negative classes. Each data element is considered as a vector. Those vectors which are close to the separating hyperplane are called support vectors5. A support vector machine has to </context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, H. 1994a. Part-of-speech tagging with neural networks, In the Proceedings of International Conference on Computational Linguistics, pp. 172-176, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
<author>F Laws</author>
</authors>
<date>2008</date>
<booktitle>Estimation of conditional Probabilities with Decision Trees and an Application to Fine-Grained POS tagging, COLING 2008,</booktitle>
<location>Manchester, Great Britain.</location>
<contexts>
<context position="13923" citStr="Schmid and Laws, 2008" startWordPosition="2235" endWordPosition="2238">.autonlab.org/tutorials/svm.html 694 upper case, lower case, word length, etc. On the Penn Treebank corpus, SVM tool showed an accuracy of 97.16% (Giménez and Màrquez, 2004). In 2008, Schmid and Florian proposed a probabilistic POS tagger for fine grained tagsets. The basic idea is to consider POS tags as sets of attributes. The context probability of a tag is the product of the probabilities of its attributes. The probability of an attribute given the previous tags is estimated with a decision tree. The decision tree uses different context features for the prediction of different attributes (Schmid and Laws, 2008). The RF tagger is well suited for languages with a rich morphology and a large fine grained tagset. The RF tagger was evaluated on the German Tiger Treebank and Czech Academic corpus which contain 700 and 1200 POS tags, respectively. The RF tagger achieved a higher accuracy than TnT and SVMTool. Urdu is a morphologically rich language. Training a tagger on a large fine grained tagset requires a large training corpus. Therefore, the tagset which we are using for these experiments is only based on syntactic distributions. However, it is always interesting to evaluate new disambiguation ideas li</context>
</contexts>
<marker>Schmid, Laws, 2008</marker>
<rawString>Schmid, H. and Laws, F. 2008. Estimation of conditional Probabilities with Decision Trees and an Application to Fine-Grained POS tagging, COLING 2008, Manchester, Great Britain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>RL Schmidt</author>
</authors>
<title>Urdu: an essential grammar,</title>
<date>1999</date>
<location>London: Routledge.</location>
<contexts>
<context position="2975" citStr="Schmidt, 1999" startWordPosition="473" endWordPosition="474">onal morpho-syntactic categories such as number, gender and case. In order to facilitate the tagger training and to reduce the lexical and syntactic ambiguity, we decided to concentrate on the syntactic categories of the language. Purely syntactic categories lead to a smaller number of tags which also improves the accuracy of manual tagging2 (Marcus et al., 1993). Urdu is influenced from Arabic, and can be considered as having three main parts of speech, namely noun, verb and particle (Platts, 1909; Javed, 1981; Haq, 1987). However, some grammarians proposed ten main parts of speech for Urdu (Schmidt, 1999). The work of Urdu grammar writers provides a full overview of all the features of the language. However, in the perspective of the tagset, their analysis is lacking the computational grounds. The semantic, morphological and syntactic categories are mixed in their distribution of parts of speech. For example, Haq (1987) divides the common nouns into situational (smile, sadness, darkness), locative (park, office, morning, evening), instrumental (knife, sword) and collective nouns (army, data). In 2003, Hardie proposed the first computational part of speech tagset for Urdu (Hardie, 2 A part of s</context>
</contexts>
<marker>Schmidt, 1999</marker>
<rawString>Schmidt, RL 1999. Urdu: an essential grammar, London: Routledge.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>