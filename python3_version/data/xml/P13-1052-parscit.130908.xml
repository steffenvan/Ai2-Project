<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.957578">
GlossBoot: Bootstrapping Multilingual Domain Glossaries from the Web
</title>
<author confidence="0.767192">
Flavio De Benedictis, Stefano Faralli and Roberto Navigli
</author>
<affiliation confidence="0.480482">
Dipartimento di Informatica
</affiliation>
<address confidence="0.292427">
Sapienza Universit`a di Roma
</address>
<email confidence="0.903848">
flavio.debene@gmail.com,{faralli,navigli}@di.uniroma1.it
</email>
<sectionHeader confidence="0.996305" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999922153846154">
We present GlossBoot, an effective
minimally-supervised approach to ac-
quiring wide-coverage domain glossaries
for many languages. For each language
of interest, given a small number of
hypernymy relation seeds concerning a
target domain, we bootstrap a glossary
from the Web for that domain by means of
iteratively acquired term/gloss extraction
patterns. Our experiments show high
performance in the acquisition of domain
terminologies and glossaries for three
different languages.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999869507692308">
Much textual content, such as that available on
the Web, contains a great deal of information fo-
cused on specific areas of knowledge. However,
it is not infrequent that, when reading a domain-
specific text, we humans do not know the mean-
ing of one or more terms. To help the human
understanding of specialized texts, repositories of
textual definitions for technical terms, called glos-
saries, are compiled as reference resources within
each domain of interest. Interestingly, electronic
glossaries have been shown to be key resources
not only for humans, but also in Natural Language
Processing (NLP) tasks such as Question Answer-
ing (Cui et al., 2007), Word Sense Disambiguation
(Duan and Yates, 2010; Faralli and Navigli, 2012)
and ontology learning (Navigli et al., 2011; Ve-
lardi et al., 2013).
Today large numbers of glossaries are available
on the Web. However most such glossaries are
small-scale, being made up of just some hundreds
of definitions. Consequently, individual glossaries
typically provide a partial view of a given domain.
Moreover, there is no easy way of retrieving the
subset of Web glossaries which appertains to a do-
main of interest. Although online services such
as Google Define allow the user to retrieve defi-
nitions for an input term, such definitions are ex-
tracted from Web glossaries and put together for
the given term regardless of their domain. As a re-
sult, gathering a large-scale, full-fledged domain
glossary is not a speedy operation.
Collaborative efforts are currently producing
large-scale encyclopedias, such as Wikipedia,
which are proving very useful in NLP (Hovy et al.,
2013). Interestingly, wikipedias also include man-
ually compiled glossaries. However, such glos-
saries still suffer from the same above-mentioned
problems, i.e., being incomplete or over-specific,1
and hard to customize according to a user’s needs.
To automatically obtain large domain glos-
saries, over recent years computational ap-
proaches have been developed which extract tex-
tual definitions from corpora (Navigli and Velardi,
2010; Reiplinger et al., 2012) or the Web (Fujii
and Ishikawa, 2000). The former methods start
from a given set of terms (possibly automatically
extracted from a domain corpus) and then har-
vest textual definitions for these terms from the
input corpus using a supervised system. Web-
based methods, instead, extract text snippets from
Web pages which match pre-defined lexical pat-
terns, such as “X is a Y”, along the lines of Hearst
(1992). These approaches typically perform with
high precision and low recall, because they fall
short of detecting the high variability of the syn-
tactic structure of textual definitions. To address
the low-recall issue, recurring cue terms occurring
within dictionary and encyclopedic resources can
be automatically extracted and incorporated into
lexical patterns (Saggion, 2004). However, this
approach is term-specific and does not scale to ar-
bitrary terminologies and domains.
In this paper we propose GlossBoot, a novel
approach which reduces human intervention to a
bare minimum and exploits the Web to learn a
</bodyText>
<footnote confidence="0.975135">
1http://en.wikipedia.org/wiki/Portal:Contents/Glossaries
</footnote>
<page confidence="0.829407">
528
</page>
<note confidence="0.9184835">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 528–538,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<figure confidence="0.999684047619048">
1 2 3 4 5
Initial seed
selection
initial
seeds
Seed
queries
search
results
Pattern and
glossary extraction
new
seeds
Gloss ranking
and filtering
domain
glossary Gk
Seed
selection
final
glossary
</figure>
<figureCaption confidence="0.999995">
Figure 1: The GlossBoot bootstrapping process for glossary learning.
</figureCaption>
<bodyText confidence="0.999802571428572">
full-fledged domain glossary. Given a domain and
a language of interest, we bootstrap the glossary
learning process with just a few hypernymy rela-
tions (such as computer is-a device), with the only
condition that the (term, hypernym) pairs must be
specific enough to implicitly identify the domain
in the target language. Hence we drop the require-
ment of a large domain corpus, and also avoid the
use of training data or a manually defined set of
lexical patterns. To the best of our knowledge, this
is the first approach which jointly acquires large
amounts of terms and glosses from the Web with
minimal supervision for any target domain and
language.
</bodyText>
<sectionHeader confidence="0.997449" genericHeader="introduction">
2 GlossBoot
</sectionHeader>
<bodyText confidence="0.982890782608696">
Our objective is to harvest a domain glossary G
containing pairs of terms/glosses in a given lan-
guage. To this end, we automatically populate a
set of HTML patterns P which we use to extract
definitions from Web glossaries. Initially, both
P := 0 and G := 0. We incrementally populate
the two sets by means of an initial seed selection
step and four iterative steps (cf. Figure 1):
Step 1. Initial seed selection: first, we manu-
ally select a set of K hypernymy relation seeds
S = {(ti, hi), ... , (tK, hK)}, where the pair (ti,
hi) contains a term ti and its generalization hi
(e.g., (firewall, security system)). This is the only
human input to the entire glossary learning pro-
cess. The selection of the input seeds plays a key
role in the bootstrapping process, in that the pat-
tern and gloss extraction process will be driven by
these seeds. The chosen hypernymy relations thus
have to be as topical and representative as pos-
sible for the domain of interest (e.g., (compiler,
computer program) is an appropriate pair for com-
puter science, while (byte, unit of measurement)
is not, as it might cause the extraction of several
glossaries of units and measures).
We now set the iteration counter k to 1 and start
the first iteration of the glossary bootstrapping pro-
cess (steps 2-5). After each iteration k, we keep
track of the set of glosses Gk, acquired during it-
eration k.
Step 2. Seed queries: for each seed pair (ti, hi),
we submit the following query to a Web search
engine: “ti” “hi” glossaryKeyword2 (where
glossaryKeyword is the term in the target lan-
guage referring to glossary (i.e., glossary for En-
glish, glossaire for French etc.)) and collect the
top-ranking results for each query.3 Each result-
ing page is a candidate glossary for the domain
implicitly identified by our relation seeds S.
Step 3. Pattern and glossary extraction: we
initialize the glossary for iteration k as follows:
Gk := 0. Next, from each resulting page, we har-
vest all the text snippets s starting with ti and end-
ing with hi (e.g., “firewall&lt;/b&gt; – a &lt;i&gt;security
system” where ti = firewall and hi = security sys-
tem), i.e., s = ti ... hi. For each such text snippet
s, we perform the following substeps:
</bodyText>
<listItem confidence="0.993995823529412">
(a) extraction of the term/gloss separator: we
start from ti and move right until we extract
the longest sequence pM of HTML tags and
non-alphanumeric characters, which we call the
term/gloss separator, between ti and the glossary
definition (e.g., “&lt;/b&gt; -” between “firewall” and
“a” in the above example).
(b) gloss extraction: we expand the snippet s
to the right of hi in search of the entire gloss
of ti, i.e., until we reach a block element (e.g.,
&lt;span&gt;, &lt;p&gt;, &lt;div&gt;), while ignoring format-
ting elements such as &lt;b&gt;, &lt;i&gt; and &lt;a&gt; which
are typically included within a definition sen-
tence. As a result, we obtain the sequence
ti pM glosss(ti) pR, where glosss(ti) is our gloss
for seed term ti in snippet s (which includes hi by
construction) and pR is the HTML block element
</listItem>
<footnote confidence="0.999128">
2In what follows we use the typewriter font for
keywords and term/gloss separators.
3We use the Google Ajax APIs, which return the 64 top-
ranking search results.
</footnote>
<page confidence="0.994615">
529
</page>
<table confidence="0.993303307692308">
Generalized pattern HTML text snippet
&lt;strong&gt; * &lt;/strong&gt; - * &lt;/span&gt; &lt;strong&gt;Interrupt&lt;/strong&gt; - The suspension of normal
program execution to perform a higher priority service rou-
tine as requested by a peripheral device. &lt;/span&gt;
&lt;dt&gt; * &lt;/dt&gt;&lt;dd&gt; * &lt;/dd&gt; &lt;dt&gt;Netiquette&lt;/dt&gt;&lt;dd&gt;The established conventions
of online politeness are called netiquette.&lt;/dd&gt;
&lt;h3&gt; * &lt;/h3&gt;&lt;p&gt; * &lt;/p&gt; &lt;h3&gt;Compiler&lt;/h3&gt;&lt;p&gt;A program that translates
source code, such as C++ or Pascal, into directly executable
machine code.&lt;/p&gt;
&lt;span&gt; * &lt;/span&gt; - * &lt;/p&gt; &lt;span&gt;Signature&lt;/span&gt; - A function’s name and param-
eter list. &lt;/p&gt;
&lt;span&gt; * &lt;/span&gt;: * &lt;span&gt; &lt;span&gt;Blog&lt;/span&gt;: Short for “web log”, a blog is an
online journal. &lt;span&gt;
</table>
<tableCaption confidence="0.999278">
Table 1: Examples of generalized patterns together with matching HTML text snippets.
</tableCaption>
<figureCaption confidence="0.974727">
Figure 2: An example of decomposition during pattern extraction for a snippet matching the seed pair
(firewall, security system).
</figureCaption>
<bodyText confidence="0.854676">
to the right of the extracted gloss. In Figure 2 we
show the decomposition of our example snippet
matching the seed (firewall, security system).
(c) pattern instance extraction: we extract the
following pattern instance:
</bodyText>
<equation confidence="0.789766">
pL ti pM glosss(ti) pR,
</equation>
<bodyText confidence="0.999746666666667">
where pL is the longest sequence of HTML tags
and non-alphanumeric characters obtained when
moving to the left of ti (see Figure 2).
</bodyText>
<listItem confidence="0.575459">
(d) pattern extraction: we generalize the above
pattern instance to the following pattern:
</listItem>
<equation confidence="0.967919">
pL * pM * pR,
</equation>
<bodyText confidence="0.952871724137931">
i.e., we replace ti and glosss(ti) with *. For the
above example, we obtain the following pattern:
&lt;p&gt;&lt;b&gt; * &lt;/b&gt; - * &lt;/p&gt;.
Finally, we add the generalized pattern to the set
of patterns P, i.e., P := P U {pL * pM * pR}.
We also add the first sentence of the retrieved gloss
glosss(ti) to our glossary Gk, i.e., Gk := Gk U
{(ti, first(glosss(ti)))}, where first(g) returns
the first sentence of gloss g.
(e) pattern matching: finally, we look for addi-
tional pairs of terms/glosses in the Web page con-
taining the snippet s by matching the page against
the generalized pattern pL * pM * pR. We then
add to Gk the new (term, gloss) pairs matching the
generalized pattern. In Table 1 we show some non-
trivial generalized patterns together with matching
HTML text snippets.
As a result of step 3, we obtain a glossary Gk
for the terms discovered at iteration k.
Step 4. Gloss ranking and filtering: impor-
tantly, not all the extracted definitions pertain to
the domain of interest. In order to rank the glosses
obtained at iteration k by domain pertinence, we
assume that the terms acquired at previous itera-
tions belong to the target domain, i.e., they are do-
main terms at iteration k. Formally, we define the
terminology T k−1
1 of the domain terms accumu-
lated up until iteration k − 1 as follows: Tk−1
</bodyText>
<equation confidence="0.996945">
1 :=
Uk−1
i=
</equation>
<bodyText confidence="0.906684142857143">
Ti, where Ti := It : I(t, g) E Gi}. For the
base step k = 1, we define T10 := It : I(t, g) E
G1}, i.e., we use the first-iteration terminology it-
self.
To rank the glosses, we first transform each ac-
quired gloss g to its bag-of-word representation
Bag(g), which contains all the single- and multi-
word expressions in g. We use the lexicon of the
target language’s Wikipedia together with Tk−1
1 in
order to obtain the bag of content words.4 Then we
4In fact Wikipedia is only utilized in the multi-word iden-
tification phase. We do not use Wikipedia for discovering
new terms.
</bodyText>
<page confidence="0.864544">
530
</page>
<bodyText confidence="0.736061714285714">
Term Gloss Hypernym # Seeds Score
dynamic packet filter A firewall facility that can monitor the state of ac- firewall 2 0.75
tive connections and use this information to determine
which network packets to allow through the firewall
die An integrated circuit chip cut from a finished wafer. integrated circuit 1 0.75
constructor a method used to help create a new object and ini- method 0 1.00
tialise its data
</bodyText>
<tableCaption confidence="0.914284">
Table 2: Examples of extracted terms, glosses and hypernyms (seeds are in bold, domain terms, i.e., in
</tableCaption>
<equation confidence="0.9573986">
T k−1
1 , are underlined, non-domain terms in italics).
calculate the domain score of a gloss g as follows:
score(g) = IBag(g) fl T k−1
1 �
</equation>
<bodyText confidence="0.992014333333333">
Finally, we use a threshold θ (whose tuning is
described in the experimental section) to remove
from Gk those glosses g whose score(g) &lt; θ.
In Table 2 we show some glosses in the com-
puter science domain (second column, domain
terms are underlined) together with their scores
(last column).
Step 5. Seed selection for next iteration: we
now aim at selecting the new set of hypernymy
relation seeds to be used to start the next iteration.
We perform three substeps:
(a) Hypernym extraction: for each newly-
acquired term/gloss pair (t, g) E Gk, we automati-
cally extract a candidate hypernym h from the tex-
tual gloss g. To do this we use a simple unsuper-
vised heuristic which just selects the first term in
the gloss.5 We show an example of hypernym ex-
traction for some terms in Table 2 (we report the
term in column 1, the gloss in column 2 and the
hypernyms extracted by the first term hypernym
extraction heuristic in column 3).
</bodyText>
<listItem confidence="0.865799333333333">
(b) (Term, Hypernym)-ranking: we sort all the
glosses in Gk by the number of seed terms found
in each gloss. In the case of ties (i.e., glosses with
</listItem>
<bodyText confidence="0.686156142857143">
the same number of seed terms), we further sort
the glosses by the score given in Formula 1. We
show an example of rank for some glosses in Table
2, where seed terms are in bold, domain terms (i.e.,
in Tk−1
1 ) are underlined, and non-domain terms
are shown in italics.
</bodyText>
<footnote confidence="0.5682828">
5While more complex strategies could be used, such as
supervised classifiers (Navigli and Velardi, 2010), we found
that this heuristic works well because, even when it is not a
hypernym, the first term plays the role of a cue word for the
defined term.
</footnote>
<listItem confidence="0.958570333333333">
(c) New seed selection: we select the (term, hy-
pernym) pairs corresponding to the K top-ranking
glosses.
</listItem>
<bodyText confidence="0.999042625">
Finally, if k equals the maximum number of it-
erations, we stop. Else, we increment the iteration
counter (i.e., k := k + 1) and jump to step (2) of
our glossary bootstrapping algorithm after replac-
ing S with the new set of seeds.
The output of glossary bootstrapping is a do-
main glossary G := Ui=1,...,max Gi, which
includes a domain terminology T := {t :
</bodyText>
<equation confidence="0.8433745">
1(t, g) E G} (i.e., T := T max
1 ) and a set of
glosses glosses(t) for each term t E T (i.e.,
glosses(t) := {g : 1(t, g) E G}).
</equation>
<sectionHeader confidence="0.999477" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.999688">
3.1 Domains and Gold Standards
</subsectionHeader>
<bodyText confidence="0.999910117647059">
For our experiments we focused on four differ-
ent domains, namely, Computing, Botany, Envi-
ronment, and Finance, and on three languages,
namely, English, French and Italian. Note that not
all the four domains are clear-cut. For instance, the
Environment domain is quite interdisciplinary, in-
cluding terms from fields such as Chemistry, Biol-
ogy, Law, Politics, etc.
For each domain and language we selected
as gold standards well-reputed glossaries on
the Web, such as: the Utah computing glos-
sary,6 the Wikipedia glossary of botanical terms,7
a set of Wikipedia glossaries about environ-
ment,8 and the Reuters glossary for Finance9
(full list at http://lcl.uniroma1.it/
glossboot/). We report the size of the four
gold-standard datasets in Table 4.
</bodyText>
<footnote confidence="0.999830166666667">
6http://www.math.utah.edu/∼wisnia/glossary.html
7http://en.wikipedia.org/wiki/Glossary of botanical terms
8http://en.wikipedia.org/wiki/List of environmental issues,
http://en.wikipedia.org/wiki/Glossary of environmental science,
http://en.wikipedia.org/wiki/Glossary of climate change
9http://glossary.reuters.com/index.php/Main Page
</footnote>
<equation confidence="0.9731715">
IBag(g)I
. (1)
</equation>
<page confidence="0.948885">
531
</page>
<bodyText confidence="0.952556">
Computing Botany Environment Finance
chip circuit leaf organ sewage waste eurobond bond
destructor method grass plant acid rain rain asset play stock
compiler program cultivar variety ecosystem system income stock security
scanner device gymnosperm plant air monitoring sampling financial intermediary institution
firewall security system flower reproductive organ global warming temperature derivative financial product
</bodyText>
<tableCaption confidence="0.720948">
Table 3: Hypernymy relation seeds used to bootstrap glossary learning in the four domains for the English
language.
</tableCaption>
<subsectionHeader confidence="0.999772">
3.2 Seed Selection
</subsectionHeader>
<bodyText confidence="0.99996625">
For each domain and language we manually se-
lected five seed hypernymy relations, shown for
the English language in Table 3. The seeds
were selected by the authors on the basis of
just two conditions: i) the seeds should cover
different aspects of the domain and should, in-
deed, identify the domain implicitly, ii) at least
10,000 results should be returned by the search
engine when querying it with the seeds plus the
glossaryKeyword (see step (2) of GlossBoot).
The seed selection was not fine-tuned (i.e., it was
not adjusted to improve performance), so it might
well be that better seeds would provide better
results (see, e.g., (Kozareva and Hovy, 2010b)).
However, this type of consideration is beyond the
scope of this paper.
</bodyText>
<subsectionHeader confidence="0.515983">
3.2.1 Evaluation measures
</subsectionHeader>
<bodyText confidence="0.999752291666666">
We performed experiments to evaluate the quality
of both terms and glosses, as jointly extracted by
GlossBoot.
Terms. For each domain and language we cal-
culated coverage, extra-coverage and precision of
the acquired terms T. Coverage is the ratio of ex-
tracted terms in T also contained in the gold stan-
dard Tˆ to the size of Tˆ. Extra-coverage is calcu-
lated as the ratio of the additional extracted terms
in T \ Tˆ over the number of gold standard terms
Tˆ. Finally, precision is the ratio of extracted terms
in T deemed to be within the domain. To calcu-
late precision we randomly sampled 5% of the re-
trieved terms and asked two human annotators to
manually tag their domain pertinence (with adju-
dication in case of disagreement; n = .62, indicat-
ing substantial agreement). Note that by sampling
on the entire set T, we calculate the precision of
both terms in T n Tˆ, i.e., in the gold standard, and
terms in T \ Tˆ, i.e., not in the gold standard, which
are not necessarily outside the domain.
Glosses. We calculated the precision of the ex-
tracted glosses as the ratio of glosses which were
both well-formed textual definitions and specific
</bodyText>
<table confidence="0.9998419">
Botany Comput. Environ. Finance
EN Gold std. terms 772 421 713 1777
GlossBoot terms 5598 3738 4120 5294
glosses 11663 4245 5127 6703
FR Gold std. terms 662 278 117 109
GlossBoot terms 3450 3462 1941 1486
glosses 5649 3812 2095 1692
IT Gold std. terms 205 244 450 441
GlossBoot terms 1965 3356 1630 3601
glosses 2678 5891 1759 5276
</table>
<tableCaption confidence="0.999456">
Table 4: Size of the gold-standard and
</tableCaption>
<bodyText confidence="0.987954714285714">
automatically-acquired glossaries for the four
domains in the three languages of interest.
to the target domain. Precision was determined on
a random sample of 5% of the acquired glosses for
each domain and language. The annotation was
made by two annotators, with n = .675, indicat-
ing substantial agreement.
</bodyText>
<subsectionHeader confidence="0.998326">
3.3 Parameter tuning
</subsectionHeader>
<bodyText confidence="0.999865266666667">
We tuned the minimum and maximum length of
both pL and pR (see step (3) of GlossBoot) and
the threshold 0 that we use to filter out non-domain
glosses (see step (4) of GlossBoot) using an extra
domain, i.e., the Arts domain. To do this, we cre-
ated a development dataset made up of the full set
of 394 terms from the Tate Gallery glossary,10 and
bootstrapped our glossary extraction method with
just one seed, i.e., (fresco, painting). We chose an
optimal value of 0 = 0.1 on the basis of a har-
monic mean of coverage and precision. Note that,
since precision also concerns terms not in the gold
standard, we had to manually validate a sample of
the extracted terms for each of the 21 tested values
of 0 E {0, 0.05, 0.1, ... ,1.0}.
</bodyText>
<sectionHeader confidence="0.999902" genericHeader="method">
4 Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.654301">
4.1 Terms
</subsectionHeader>
<bodyText confidence="0.993016">
The size of the extracted terminologies for the four
domains after five iterations are reported in Table
4. In Table 5 we show examples of the possi-
ble scenarios for terms: in-domain extracted terms
</bodyText>
<footnote confidence="0.881777">
10http://www.tate.org.uk/collections/glossary/
</footnote>
<page confidence="0.946696">
532
</page>
<table confidence="0.9997655">
In-domain In-domain Out-of-domain In-domain
(in gold std, E Tˆ n T) (not in gold std, E T \ Tˆ) (not in gold std, E T \ Tˆ) (missed, E Tˆ \ T)
Computing software, inheritance, mi- clipboard, even parity, su- gs1-128 label, grayscale, openwindows, sun mi-
croprocessor doer quantum dots crosystems, hardwired
Botany pollinium, stigma, spore vegetation, dichogamous, ion, free radicals, mana- nomenclature, endemism,
fertilisation mana insectivorous
Environment carcinogen, footprint, solar frigid soil, biosafety, fire epidermis, science park, g8, best practice,
power simulator alum polystyrene
Finance cash, bond, portfolio trustor, naked option, mar- precedent, immigration, co-location, petrodollars,
ket price heavy industry euronext
</table>
<tableCaption confidence="0.984694">
Table 5: Examples of extracted (and missed) terms.
</tableCaption>
<table confidence="0.9999568">
Botany Comput. Environ. Finance
EN Precision 95% 98% 94% 98%
Coverage 85% 40% 35% 32%
Extra-coverage 640% 848% 542% 266%
FR Precision 80% 97% 83% 98%
Coverage 97% 27% 14% 26%
Extra-coverage 425% 1219% 1646% 1350%
IT Precision 89% 98% 76% 99%
Coverage 42% 27% 11% 73%
Extra-coverage 511% 1349% 356% 746%
</table>
<tableCaption confidence="0.8019485">
Table 6: Precision, coverage and extra-coverage of
the term extraction phase after 5 iterations.
</tableCaption>
<bodyText confidence="0.999579066666667">
which are also found in the gold standard (col-
umn 2), in-domain extracted terms but not in the
gold standard (column 3), out-of-domain extracted
terms (column 4), and domain terms in the gold
standard but not extracted by our approach (col-
umn 5).
A quantitative evaluation is provided in Table
6, which shows the percentage results in terms of
precision, coverage, and extra-coverage after 5 it-
erations of GlossBoot. For the English language
we observe good coverage (between 32% and 40%
on three domains, with a high peak of 85% cover-
age on Botany) and generally very high precision
values. Moreover for the French and the Italian
languages we observe a peak in the Botany and Fi-
nance domains respectively, while the lowest per-
formances in terms of precision and coverage are
observed for Environment, i.e., the most interdis-
ciplinary domain.
In all three languages GlossBoot provides very
high extra coverage of domain terms, i.e., addi-
tional terms which are not in the gold standard but
are returned by our system. The figures, shown in
Table 6, range between 266% (4726/1777) for the
English Finance domain and 1646% (1926/117)
for the French Environment domain. These re-
sults, together with the generally high precision
values, indicate the larger extent of our boot-
strapped glossaries compared to our gold stan-
dards.
</bodyText>
<table confidence="0.996914">
Botany Computing Environm. Finance
Min Max Min Max Min Max Min Max
26% 68% 8% 39% 5% 33% 14% 30%
</table>
<tableCaption confidence="0.897962">
Table 7: Coverage ranges for single-seed term ex-
traction for the English language.
</tableCaption>
<bodyText confidence="0.998179088235294">
Number of seeds. Although the choice of se-
lecting five hypernymy relation seeds is quite arbi-
trary, it shows that we can acquire a reliable termi-
nology with minimal human intervention. Now, an
obvious question arises: what if we bootstrapped
GlossBoot with fewer hypernym seeds, e.g., just
one seed? To answer this question we replicated
our English experiments on each single (term, hy-
pernym) pair in our seed set. In Table 7 we show
the coverage ranges – i.e., the minimum and max-
imum coverage values – for the five seeds on each
domain. We observe that the maximum coverage
can attain values very close to those obtained with
five seeds. However, the minimum coverage val-
ues are much lower. So, if we adopt a 1-seed boot-
strapping policy there is a high risk of acquiring
a poorer terminology unless we select the single
seed very carefully, whereas we have shown that
just a few seeds can cope with domain variabil-
ity. Similar considerations can be made regarding
different seed set sizes (we also tried 2, 3 and 4).
So five is not a magic number, just one which can
guarantee an adequate coverage of the domain.
Number of iterations. In order to study the cov-
erage trend over iterations we selected 5 seeds for
our tuning domain (i.e., Arts, see Section 3.3).
Figure 3 shows the size (left graph), coverage,
extra-coverage and precision (middle graph) of the
acquired glossary after each iteration, from 1 to
20. As expected, (extra-)coverage grows over iter-
ations, while precision drops. Stopping at iteration
5, as we do, is optimal in terms of the harmonic
mean of precision and coverage (right graph in
Figure 3).
</bodyText>
<page confidence="0.993168">
533
</page>
<figure confidence="0.998560483870968">
Number of terms and glosses extracted over iterations
2 4 6 8 10 12 14 16 18 20
iteration
Coverage, extra-coverage and precision over iterations
40%
38%
36%
34%
32%
precision
coverage
extra-coverage
30%
2 4 6 8 10 12 14 16 18 20
iteration
7000
6000
5000
4000
3000
2000
1000
1000%
100%
10%
terms
glosses
Harmonic mean of precision and coverage over iterations
harmonic mean of precision and coverage
2 4 6 8 10 12 14 16 18 20
iteration
</figure>
<figureCaption confidence="0.999544">
Figure 3: Size, coverage and precision trends for Arts (tuning domain) over 20 iterations for English.
</figureCaption>
<table confidence="0.9995835">
Botany Comput. Environm. Finance
EN 96% 94% 97% 97%
FR 88% 89% 88% 95%
IT 94% 98% 83% 99%
</table>
<tableCaption confidence="0.9890455">
Table 8: Precision of the glosses for the four do-
mains and for the three languages.
</tableCaption>
<subsectionHeader confidence="0.819831">
4.2 Glosses
</subsectionHeader>
<bodyText confidence="0.999990066666667">
We show the results of gloss evaluation in Ta-
ble 8. Precision ranges between 83% and 99%,
with three domains performing above 92% on av-
erage across languages, and the Environment do-
main performing relatively worse because of its
highly interdisciplinary nature (89% on average).
We observe that these results are strongly corre-
lated with the precision of the extracted terms (cf.
Table 6), because the retrieved glosses of domain
terms are usually in-domain too, and follow a def-
initional style because they come from glossaries.
Note, however, that the gloss precision can also
be higher than term precision, because many perti-
nent glosses might be extracted for the same term,
cf. Table 4.
</bodyText>
<sectionHeader confidence="0.999307" genericHeader="method">
5 Comparative Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999825">
5.1 Comparison with Google Define
</subsectionHeader>
<bodyText confidence="0.999685">
We performed a comparison with Google De-
fine,11 a state-of-the-art definition search service.
This service inputs a term query and outputs a list
of glosses. First, we randomly sampled 100 terms
from our gold standard for each domain and each
of the three languages. Next, for each domain and
language, we manually calculated the fraction of
terms for which an in-domain definition was pro-
vided by Google Define and GlossBoot. Table 9
shows the coverage results.
Google Define outperforms our system on all
four domains (with a few exceptions). However
</bodyText>
<footnote confidence="0.5950435">
11Accessible from Google search by means of the
define: keyword.
</footnote>
<table confidence="0.999831571428571">
Botany Comput. Environm. Finance
EN Google Define 90% 87% 84% 82%
GlossBoot 77% 47% 44% 51%
FR Google Define 40% 48% 36% 82%
GlossBoot 88% 42% 22% 32%
IT Google Define 52% 74% 78% 80%
GlossBoot 64% 38% 44% 92%
</table>
<tableCaption confidence="0.979091">
Table 9: Number of domain glosses (from a ran-
</tableCaption>
<bodyText confidence="0.9470143">
dom sample of 100 gold standard terms per do-
main) retrieved using Google Define and Gloss-
Boot.
we note that Google Define: i) requires knowing
the domain term to be defined in advance, whereas
we jointly acquire thousands of terms and glosses
starting from just a few seeds; ii) does not discrim-
inate between glosses pertaining to the target do-
main and glosses concerning other fields or senses,
whereas we extract domain-specific glosses.
</bodyText>
<subsectionHeader confidence="0.999695">
5.2 Comparison with TaxoLearn
</subsectionHeader>
<bodyText confidence="0.999979315789474">
We also compared GlossBoot with a recent ap-
proach to glossary learning embedded into a
framework for graph-based taxonomy learning
from scratch, called TaxoLearn (Navigli et al.,
2011). Since this approach requires the manual
selection of a domain corpus to automatically ex-
tract terms and glosses, we decided to keep a level
playing field and experimented with the same do-
main used by the authors, i.e., Artificial Intelli-
gence (AI). TaxoLearn was applied to the entire
set of IJCAI 2009 proceedings, resulting in the ex-
traction of 427 terms and 834 glosses.12 As re-
gards GlossBoot, we selected 10 seeds to cover all
the fields of AI, obtaining 5827 terms and 6716
glosses after 5 iterations, one order of magnitude
greater than TaxoLearn.
As for the precision of the extracted terms, we
randomly sampled 50% of them for each system.
We show in Table 10 (first row) the estimated term
</bodyText>
<footnote confidence="0.981886">
12Available at: http://lcl.uniroma1.it/taxolearn
</footnote>
<page confidence="0.988255">
534
</page>
<table confidence="0.999563333333333">
GlossBoot TaxoLearn
Term Precision 82.3% (2398/2913) 77.0% (164/213)
Gloss Precision 82.8% (2780/3358) 78.9% (329/417)
</table>
<tableCaption confidence="0.964005">
Table 10: Estimated term and gloss precision of
</tableCaption>
<bodyText confidence="0.972355">
GlossBoot and TaxoLearn for the Artificial Intel-
ligence domain.
precision for GlossBoot and TaxoLearn. The pre-
cision value for GlossBoot is lower than the preci-
sion values of the four domains in Table 6, due
to the AI domain being highly interdisciplinary.
TaxoLearn obtained a lower precision because it
acquires a full-fledged taxonomy for the domain,
thus also including higher-level concepts which do
not necessarily pertain to the domain.
We performed a similar evaluation for the pre-
cision of the acquired glosses, by randomly sam-
pling 50% of them for each system. We show in
Table 10 (second row) the estimated gloss preci-
sion of GlossBoot and TaxoLearn. Again, Gloss-
Boot outperforms TaxoLearn, retrieving a larger
amount of glosses (6716 vs. 834) with higher pre-
cision. We remark, however, that in TaxoLearn
glossary extraction is a by-product of the taxon-
omy learning process.
Finally, we note that we cannot compare with
approaches based on lexical patterns (such as
(Kozareva and Hovy, 2010a)), because they are
not aimed at learning glossaries, but just at re-
trieving sentence snippets which contain pairs of
terms/hypernyms (e.g., “supervised systems such
as decision trees”).
</bodyText>
<sectionHeader confidence="0.99994" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999904">
There are several techniques in the literature for
the automated acquisition of definitional knowl-
edge. Fujii and Ishikawa (2000) use an n-gram
model to determine the definitional nature of text
fragments, whereas Klavans and Muresan (2001)
apply pattern matching techniques at the lexical
level guided by cue phrases such as “is called”
and “is defined as”. Cafarella et al. (2005) de-
veloped a Web search engine which handles more
general and complex patterns like “cities such as
ProperNoun(Head(NP))” in which it is possi-
ble to constrain the results with syntactic proper-
ties. More recently, a domain-independent super-
vised approach was presented which learns Word-
Class Lattices (WCLs), i.e. lattice-based definition
classifiers that are applied to candidate sentences
containing the input terms (Navigli and Velardi,
2010). WCLs have been shown to perform with
high precision in several domains (Velardi et al.,
2013).
To avoid the burden of manually creating a
training dataset, definitional patterns can be ex-
tracted automatically. Reiplinger et al. (2012) ex-
perimented with two different approaches for the
acquisition of lexical-syntactic patterns. The first
approach involves bootstrapping patterns from a
domain corpus, and then manually refining the ac-
quired patterns. The second approach, instead,
involves automatically acquiring definitional sen-
tences by using a more sophisticated syntactic and
semantic processing. The results shows high pre-
cision in both cases.
However, these approaches to glossary learning
extract unrestricted textual definitions from open
text. In order to filter out non-domain definitions,
Velardi et al. (2008) automatically extract a do-
main terminology from an input corpus which they
later use for assigning a domain score to each har-
vested definition and filtering out non-domain can-
didates. The extraction of domain terms from cor-
pora can be performed either by means of statis-
tical measures such as specificity and cohesion
(Park et al., 2002), or just TF*IDF (Kim et al.,
2009).
To avoid the use of a large domain corpus, ter-
minologies can be obtained from the Web by using
Doubly-Anchored Patterns (DAPs) which, given a
(term, hypernym) pair, harvest sentences match-
ing manually-defined patterns like “&lt;hypernym&gt;
such as &lt;term&gt;, and *” (Kozareva et al., 2008).
Kozareva and Hovy (2010a) further extend this
term extraction process by harvesting new hy-
pernyms using the corresponding inverse patterns
(called DAP−1) like “* such as &lt;term1&gt;, and
&lt;term2&gt;”. Similarly to our approach, they drop
the requirement of a domain corpus and start
from a small number of (term, hypernym) seeds.
However, while Doubly-Anchored Patterns have
proven useful in the induction of domain tax-
onomies (Kozareva and Hovy, 2010a), they cannot
be applied to the glossary learning task, because
the extracted sentences are not formal definitions.
In contrast, GlossBoot performs the novel task
of multilingual glossary learning from the Web by
bootstrapping the extraction process with a few
(term, hypernym) seeds. Bootstrapping techniques
(Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca
et al., 2006) have been successfully applied to
several tasks, including high-precision semantic
lexicon extraction from large corpora (Riloff and
Jones, 1999; Thelen and Riloff, 2002; McIntosh
</bodyText>
<page confidence="0.995049">
535
</page>
<table confidence="0.999469875">
Domain Term Gloss
EN Botany deciduous losing foliage at the end of the growing season.
Computing information space The abstract concept of everything accessible using networks: the Web.
Finance discount The difference between the lower price paid for a security and the security’s
face amount at issue.
FR Botany insectivore Qui capture des insectes et en absorbe les mati`eres nutritives.
Computing notebook C’est l’appellation d’un petit portable d’une taille proche d’une feuille A4.
Environment ´ecosyst`eme Ensemble des ˆetres vivants et des ´el´ements non vivants d’un milieu qui sont
li´es vitalement entre eux.
IT Computing link Collegamento tra diverse pagine web, pu`o essere costituito da immagini o
testo.
Environment effetto serra Riscaldamento dell’atmosfera terrestre dovuto alla presenza di gas
nell’atmosfera (anidride carbonica, metano e vapore acqueo) che osta-
colano l’uscita delle radiazioni infrarosse emesse dal suolo terreste verso
l’alto.
Finance spread Indica la differenza tra la quotazione di acquisto e quella di vendita.
</table>
<tableCaption confidence="0.99974">
Table 11: An excerpt of the domain glossaries acquired for the three languages.
</tableCaption>
<bodyText confidence="0.999883625">
and Curran, 2008; McIntosh and Curran, 2009),
learning semantic relations (Pantel and Pennac-
chiotti, 2006), extracting surface text patterns for
open-domain question answering (Ravichandran
and Hovy, 2002), semantic tagging (Huang and
Riloff, 2010) and unsupervised Word Sense Dis-
ambiguation (Yarowsky, 1995). By exploiting the
(term, hypernym) seeds to bootstrap the itera-
tive acquisition of extraction patterns from Web
glossary pages, we can cover the high variabil-
ity of textual definitions, including both sentences
matching the above-mentioned lexico-syntactic
patterns (e.g., “a corpus is a collection of docu-
ments”) and glossary-style definitions (e.g., “cor-
pus: a collection of document”) independently of
the target domain and language.
</bodyText>
<sectionHeader confidence="0.999465" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999687045454546">
In this paper we have presented GlossBoot, a
new, minimally-supervised approach to multilin-
gual glossary learning. Starting from a few hyper-
nymy relation seeds which implicitly identify the
domain of interest, we apply a bootstrapping ap-
proach which iteratively obtains HTML patterns
from Web glossaries and then applies them to the
extraction of term/gloss pairs. To our knowledge,
GlossBoot is the first approach to large-scale glos-
sary learning which jointly acquires thousands of
terms and glosses for a target domain and language
with minimal supervision.
The gist of GlossBoot is our glossary bootstrap-
ping approach, thanks to which we can drop the
requirements of existing techniques such as the
availability of domain text corpora, which often
do not contain enough definitions, and the man-
ual specification of lexical patterns, which typi-
cally extract sentence snippets, instead of formal
glosses.
GlossBoot will be made available to the re-
search community as open-source software. Be-
yond the immediate usability of its output and
its effective use for domain Word Sense Disam-
biguation (Faralli and Navigli, 2012), we wish
to show the benefit of GlossBoot in gloss-driven
approaches to ontology learning (Navigli et al.,
2011; Velardi et al., 2013) and semantic network
enrichment (Navigli and Ponzetto, 2012). In Ta-
ble 11 we show an excerpt of the acquired glos-
saries. All the glossaries and gold standards cre-
ated for our experiments are available from the au-
thors’ Web site http://lcl.uniroma1.it/
glossboot/.
We remark that the terminologies covered with
GlossBoot are not only precise, but also one or-
der of magnitude greater than those covered in
individual online glossaries. As future work we
plan to study the ability of GlossBoot to acquire
domain glossaries at different levels of specificity
(i.e., domains vs. subdomains). We also plan to
exploit the acquired HTML patterns for imple-
menting an open-source glossary crawler, along
the lines of Google Define.
</bodyText>
<sectionHeader confidence="0.998813" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998530333333333">
The authors gratefully acknowledge
the support of the ERC Starting
Grant MultiJEDI No. 259234.
</bodyText>
<page confidence="0.997362">
536
</page>
<sectionHeader confidence="0.996172" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999489018518519">
Eugene Agichtein and Luis Gravano. 2000. Snow-
ball: extracting relations from large plain-text col-
lections. In Proceedings of the 5th ACM confer-
ence on Digital Libraries, pages 85–94, San Anto-
nio, Texas, USA.
Sergey Brin. 1998. Extracting patterns and relations
from the World Wide Web. In Proceedings of the
International Workshop on The World Wide Web and
Databases, pages 172–183, London, UK.
Michael J. Cafarella, Doug Downey, Stephen Soder-
land, and Oren Etzioni. 2005. KnowItNow: Fast,
scalable information extraction from the web. In
Proceedings of Human Language Technology Con-
ference and Conference on Empirical Methods in
Natural Language Processing, pages 563–570, Van-
couver, British Columbia, Canada.
Hang Cui, Min-Yen Kan, and Tat-Seng Chua. 2007.
Soft pattern matching models for definitional ques-
tion answering. ACM Transactions on Information
Systems, 25(2):1–30.
Weisi Duan and Alexander Yates. 2010. Extracting
glosses to disambiguate word senses. In Proceed-
ings of Human Language Technologies: The 11th
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 627–635, Los Angeles, CA, USA.
Stefano Faralli and Roberto Navigli. 2012. A
New Minimally-supervised Framework for Domain
Word Sense Disambiguation. In Proceedings of
the 2012 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Compu-
tational Natural Language Learning, pages 1411–
1422, Jeju, Korea.
Atsushi Fujii and Tetsuya Ishikawa. 2000. Utilizing
the World Wide Web as an encyclopedia: extract-
ing term descriptions from semi-structured texts. In
Proceedings of the 38th Annual Meeting on Associa-
tion for Computational Linguistics, pages 488–495,
Hong Kong.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 15th International Conference on Computational
Linguistics, pages 539–545, Nantes, France.
Eduard H. Hovy, Roberto Navigli, and Simone Paolo
Ponzetto. 2013. Collaboratively built semi-
structured content and Artificial Intelligence: The
story so far. Artificial Intelligence, 194:2–27.
Ruihong Huang and Ellen Riloff. 2010. Induc-
ing domain-specific semantic class taggers from (al-
most) nothing. In Proceedings of the 48th Annual
Meeting of the Association for Computational Lin-
guistics, pages 275–285, Uppsala, Sweden.
Su Nam Kim, Timothy Baldwin, and Min-Yen Kan.
2009. An unsupervised approach to domain-specific
term extraction. In Proceedings of the Australasian
Language Technology Workshop, pages 94–98, Syd-
ney, Australia.
Judith Klavans and Smaranda Muresan. 2001. Evalu-
ation of the DEFINDER system for fully automatic
glossary construction. In Proceedings of the Amer-
ican Medical Informatics Association (AMIA) Sym-
posium, pages 324–328, Washington, D.C., USA.
Zornitsa Kozareva and Eduard Hovy. 2010a. A
semi-supervised method to learn and construct tax-
onomies using the Web. In Proceedings of Empiri-
cal Methods in Natural Language Processing, pages
1110–1118, Cambridge, MA, USA.
Zornitsa Kozareva and Eduard H. Hovy. 2010b. Not
all seeds are equal: Measuring the quality of text
mining seeds. In Proceedings of Human Lan-
guage Technologies: The 11th Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 618–626, Los
Angeles, California, USA.
Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008. Semantic class learning from the Web with
hyponym pattern linkage graphs. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics, pages 1048–1056, Colum-
bus, Ohio, USA.
Tara McIntosh and James R. Curran. 2008. Weighted
mutual exclusion bootstrapping for domain indepen-
dent lexicon and template acquisition. In Proceed-
ings of the Australasian Language Technology Asso-
ciation Workshop, pages 97–105, CSIRO ICT Cen-
tre, Tasmania.
Tara McIntosh and James R. Curran. 2009. Reducing
semantic drift with bagging and distributional sim-
ilarity. In Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th In-
ternational Joint Conference on Natural Language
Processing of the AFNLP, pages 396–404, Suntec,
Singapore.
Roberto Navigli and Simone Paolo Ponzetto. 2012.
BabelNet: The automatic construction, evaluation
and application of a wide-coverage multilingual se-
mantic network. Artificial Intelligence, 193:217–
250.
Roberto Navigli and Paola Velardi. 2010. Learning
Word-Class Lattices for definition and hypernym ex-
traction. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 1318–1327, Uppsala, Sweden.
Roberto Navigli, Paola Velardi, and Stefano Faralli.
2011. A graph-based algorithm for inducing lexi-
cal taxonomies from scratch. In Proceedings of the
22th International Joint Conference on Artificial In-
telligence, pages 1872–1877, Barcelona, Spain.
</reference>
<page confidence="0.972681">
537
</page>
<reference confidence="0.999850222222222">
Marius Pas¸ca, Dekang Lin, Jeffrey Bigham, Andrei
Lifchits, and Alpa Jain. 2006. Names and similari-
ties on the web: Fact extraction in the fast lane. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 809–816, Sydney, Australia.
Patrick Pantel and Marco Pennacchiotti. 2006.
Espresso: Leveraging Generic Patterns for Auto-
matically Harvesting Semantic Relations. In Pro-
ceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics
(COLING-ACL), Sydney, Australia, pages 113–120,
Sydney, Australia.
Youngja Park, Roy J. Byrd, and Branimir K. Boguraev.
2002. Automatic glossary extraction: beyond termi-
nology identification. In Proceedings of the 19th In-
ternational Conference on Computational Linguis-
tics, pages 1–7, Taipei, Taiwan.
Deepak Ravichandran and Eduard Hovy. 2002. Learn-
ing surface text patterns for a question answering
system. In Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics, pages
41–47, Philadelphia, Pennsylvania.
Melanie Reiplinger, Ulrich Sch¨afer, and Magdalena
Wolska. 2012. Extracting glossary sentences from
scholarly articles: A comparative evaluation of pat-
tern bootstrapping and deep analysis. In Proceed-
ings of the ACL-2012 Special Workshop on Redis-
covering 50 Years of Discoveries, pages 55–65, Jeju
Island, Korea.
Ellen Riloff and Rosie Jones. 1999. Learning dic-
tionaries for information extraction by multi-level
bootstrapping. In Proceedings of the sixteenth na-
tional conference on Artificial intelligence and the
eleventh Innovative applications of artificial intelli-
gence conference, pages 474–479, Menlo Park, CA,
USA.
Horacio Saggion. 2004. Identifying definitions in text
collections for question answering. In Proceedings
of the Fourth International Conference on Language
Resources and Evaluation, pages 1927–1930, Lis-
bon, Portugal.
Michael Thelen and Ellen Riloff. 2002. A bootstrap-
ping method for learning semantic lexicons using
extraction pattern contexts. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 214–221, Salt Lake City,
UT, USA.
Paola Velardi, Roberto Navigli, and Pierluigi
D’Amadio. 2008. Mining the Web to create
specialized glossaries. IEEE Intelligent Systems,
23(5):18–25.
Paola Velardi, Stefano Faralli, and Roberto Navigli.
2013. OntoLearn Reloaded: A graph-based algo-
rithm for taxonomy induction. Computational Lin-
guistics, 39(3).
David Yarowsky. 1995. Unsupervised Word Sense
Disambiguation rivalin� supervised methods. In
Proceedings of the 33r Annual Meeting of the As-
sociation for Computational Linguistics, pages 189–
196, Cambridge, MA, USA.
</reference>
<page confidence="0.996808">
538
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.445885">
<title confidence="0.996189">GlossBoot: Bootstrapping Multilingual Domain Glossaries from the Web</title>
<author confidence="0.75154">Stefano Faralli Dipartimento di_Sapienza Universit`a di De_Benedictis</author>
<abstract confidence="0.999301">We present GlossBoot, an effective minimally-supervised approach to acquiring wide-coverage domain glossaries for many languages. For each language of interest, given a small number of hypernymy relation seeds concerning a target domain, we bootstrap a glossary from the Web for that domain by means of iteratively acquired term/gloss extraction patterns. Our experiments show high performance in the acquisition of domain terminologies and glossaries for three different languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th ACM conference on Digital Libraries,</booktitle>
<pages>85--94</pages>
<location>San Antonio, Texas, USA.</location>
<contexts>
<context position="32158" citStr="Agichtein and Gravano, 2000" startWordPosition="5272" endWordPosition="5275">s &lt;term1&gt;, and &lt;term2&gt;”. Similarly to our approach, they drop the requirement of a domain corpus and start from a small number of (term, hypernym) seeds. However, while Doubly-Anchored Patterns have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010a), they cannot be applied to the glossary learning task, because the extracted sentences are not formal definitions. In contrast, GlossBoot performs the novel task of multilingual glossary learning from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including high-precision semantic lexicon extraction from large corpora (Riloff and Jones, 1999; Thelen and Riloff, 2002; McIntosh 535 Domain Term Gloss EN Botany deciduous losing foliage at the end of the growing season. Computing information space The abstract concept of everything accessible using networks: the Web. Finance discount The difference between the lower price paid for a security and the security’s face amount at issue. FR Botany insectivore Qui capture des insectes et en absorbe les mati`eres nutritives. Com</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and Luis Gravano. 2000. Snowball: extracting relations from large plain-text collections. In Proceedings of the 5th ACM conference on Digital Libraries, pages 85–94, San Antonio, Texas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
</authors>
<title>Extracting patterns and relations from the World Wide Web.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Workshop on The World Wide Web and Databases,</booktitle>
<pages>172--183</pages>
<location>London, UK.</location>
<contexts>
<context position="32129" citStr="Brin, 1998" startWordPosition="5270" endWordPosition="5271">ke “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to our approach, they drop the requirement of a domain corpus and start from a small number of (term, hypernym) seeds. However, while Doubly-Anchored Patterns have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010a), they cannot be applied to the glossary learning task, because the extracted sentences are not formal definitions. In contrast, GlossBoot performs the novel task of multilingual glossary learning from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including high-precision semantic lexicon extraction from large corpora (Riloff and Jones, 1999; Thelen and Riloff, 2002; McIntosh 535 Domain Term Gloss EN Botany deciduous losing foliage at the end of the growing season. Computing information space The abstract concept of everything accessible using networks: the Web. Finance discount The difference between the lower price paid for a security and the security’s face amount at issue. FR Botany insectivore Qui capture des insectes et en absorbe </context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>Sergey Brin. 1998. Extracting patterns and relations from the World Wide Web. In Proceedings of the International Workshop on The World Wide Web and Databases, pages 172–183, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Cafarella</author>
<author>Doug Downey</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>KnowItNow: Fast, scalable information extraction from the web.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>563--570</pages>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="29436" citStr="Cafarella et al. (2005)" startWordPosition="4860" endWordPosition="4863">rns (such as (Kozareva and Hovy, 2010a)), because they are not aimed at learning glossaries, but just at retrieving sentence snippets which contain pairs of terms/hypernyms (e.g., “supervised systems such as decision trees”). 6 Related Work There are several techniques in the literature for the automated acquisition of definitional knowledge. Fujii and Ishikawa (2000) use an n-gram model to determine the definitional nature of text fragments, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. Cafarella et al. (2005) developed a Web search engine which handles more general and complex patterns like “cities such as ProperNoun(Head(NP))” in which it is possible to constrain the results with syntactic properties. More recently, a domain-independent supervised approach was presented which learns WordClass Lattices (WCLs), i.e. lattice-based definition classifiers that are applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). WCLs have been shown to perform with high precision in several domains (Velardi et al., 2013). To avoid the burden of manually creating a training dataset</context>
</contexts>
<marker>Cafarella, Downey, Soderland, Etzioni, 2005</marker>
<rawString>Michael J. Cafarella, Doug Downey, Stephen Soderland, and Oren Etzioni. 2005. KnowItNow: Fast, scalable information extraction from the web. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 563–570, Vancouver, British Columbia, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Cui</author>
<author>Min-Yen Kan</author>
<author>Tat-Seng Chua</author>
</authors>
<title>Soft pattern matching models for definitional question answering.</title>
<date>2007</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="1399" citStr="Cui et al., 2007" startWordPosition="198" endWordPosition="201"> available on the Web, contains a great deal of information focused on specific areas of knowledge. However, it is not infrequent that, when reading a domainspecific text, we humans do not know the meaning of one or more terms. To help the human understanding of specialized texts, repositories of textual definitions for technical terms, called glossaries, are compiled as reference resources within each domain of interest. Interestingly, electronic glossaries have been shown to be key resources not only for humans, but also in Natural Language Processing (NLP) tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Navigli et al., 2011; Velardi et al., 2013). Today large numbers of glossaries are available on the Web. However most such glossaries are small-scale, being made up of just some hundreds of definitions. Consequently, individual glossaries typically provide a partial view of a given domain. Moreover, there is no easy way of retrieving the subset of Web glossaries which appertains to a domain of interest. Although online services such as Google Define allow the user to retrieve definitions for an</context>
</contexts>
<marker>Cui, Kan, Chua, 2007</marker>
<rawString>Hang Cui, Min-Yen Kan, and Tat-Seng Chua. 2007. Soft pattern matching models for definitional question answering. ACM Transactions on Information Systems, 25(2):1–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weisi Duan</author>
<author>Alexander Yates</author>
</authors>
<title>Extracting glosses to disambiguate word senses.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>627--635</pages>
<location>Los Angeles, CA, USA.</location>
<contexts>
<context position="1448" citStr="Duan and Yates, 2010" startWordPosition="205" endWordPosition="208">f information focused on specific areas of knowledge. However, it is not infrequent that, when reading a domainspecific text, we humans do not know the meaning of one or more terms. To help the human understanding of specialized texts, repositories of textual definitions for technical terms, called glossaries, are compiled as reference resources within each domain of interest. Interestingly, electronic glossaries have been shown to be key resources not only for humans, but also in Natural Language Processing (NLP) tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Navigli et al., 2011; Velardi et al., 2013). Today large numbers of glossaries are available on the Web. However most such glossaries are small-scale, being made up of just some hundreds of definitions. Consequently, individual glossaries typically provide a partial view of a given domain. Moreover, there is no easy way of retrieving the subset of Web glossaries which appertains to a domain of interest. Although online services such as Google Define allow the user to retrieve definitions for an input term, such definitions are extracted from </context>
</contexts>
<marker>Duan, Yates, 2010</marker>
<rawString>Weisi Duan and Alexander Yates. 2010. Extracting glosses to disambiguate word senses. In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 627–635, Los Angeles, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>A New Minimally-supervised Framework for Domain Word Sense Disambiguation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1411--1422</pages>
<location>Jeju,</location>
<contexts>
<context position="1476" citStr="Faralli and Navigli, 2012" startWordPosition="209" endWordPosition="212">on specific areas of knowledge. However, it is not infrequent that, when reading a domainspecific text, we humans do not know the meaning of one or more terms. To help the human understanding of specialized texts, repositories of textual definitions for technical terms, called glossaries, are compiled as reference resources within each domain of interest. Interestingly, electronic glossaries have been shown to be key resources not only for humans, but also in Natural Language Processing (NLP) tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Navigli et al., 2011; Velardi et al., 2013). Today large numbers of glossaries are available on the Web. However most such glossaries are small-scale, being made up of just some hundreds of definitions. Consequently, individual glossaries typically provide a partial view of a given domain. Moreover, there is no easy way of retrieving the subset of Web glossaries which appertains to a domain of interest. Although online services such as Google Define allow the user to retrieve definitions for an input term, such definitions are extracted from Web glossaries and put toget</context>
<context position="35378" citStr="Faralli and Navigli, 2012" startWordPosition="5746" endWordPosition="5749">osses for a target domain and language with minimal supervision. The gist of GlossBoot is our glossary bootstrapping approach, thanks to which we can drop the requirements of existing techniques such as the availability of domain text corpora, which often do not contain enough definitions, and the manual specification of lexical patterns, which typically extract sentence snippets, instead of formal glosses. GlossBoot will be made available to the research community as open-source software. Beyond the immediate usability of its output and its effective use for domain Word Sense Disambiguation (Faralli and Navigli, 2012), we wish to show the benefit of GlossBoot in gloss-driven approaches to ontology learning (Navigli et al., 2011; Velardi et al., 2013) and semantic network enrichment (Navigli and Ponzetto, 2012). In Table 11 we show an excerpt of the acquired glossaries. All the glossaries and gold standards created for our experiments are available from the authors’ Web site http://lcl.uniroma1.it/ glossboot/. We remark that the terminologies covered with GlossBoot are not only precise, but also one order of magnitude greater than those covered in individual online glossaries. As future work we plan to stud</context>
</contexts>
<marker>Faralli, Navigli, 2012</marker>
<rawString>Stefano Faralli and Roberto Navigli. 2012. A New Minimally-supervised Framework for Domain Word Sense Disambiguation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1411– 1422, Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
<author>Tetsuya Ishikawa</author>
</authors>
<title>Utilizing the World Wide Web as an encyclopedia: extracting term descriptions from semi-structured texts.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>488--495</pages>
<location>Hong Kong.</location>
<contexts>
<context position="2860" citStr="Fujii and Ishikawa, 2000" startWordPosition="423" endWordPosition="426">efforts are currently producing large-scale encyclopedias, such as Wikipedia, which are proving very useful in NLP (Hovy et al., 2013). Interestingly, wikipedias also include manually compiled glossaries. However, such glossaries still suffer from the same above-mentioned problems, i.e., being incomplete or over-specific,1 and hard to customize according to a user’s needs. To automatically obtain large domain glossaries, over recent years computational approaches have been developed which extract textual definitions from corpora (Navigli and Velardi, 2010; Reiplinger et al., 2012) or the Web (Fujii and Ishikawa, 2000). The former methods start from a given set of terms (possibly automatically extracted from a domain corpus) and then harvest textual definitions for these terms from the input corpus using a supervised system. Webbased methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as “X is a Y”, along the lines of Hearst (1992). These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textual definitions. To address the low-recall issue, recurring cue te</context>
<context position="29183" citStr="Fujii and Ishikawa (2000)" startWordPosition="4819" endWordPosition="4822">ing a larger amount of glosses (6716 vs. 834) with higher precision. We remark, however, that in TaxoLearn glossary extraction is a by-product of the taxonomy learning process. Finally, we note that we cannot compare with approaches based on lexical patterns (such as (Kozareva and Hovy, 2010a)), because they are not aimed at learning glossaries, but just at retrieving sentence snippets which contain pairs of terms/hypernyms (e.g., “supervised systems such as decision trees”). 6 Related Work There are several techniques in the literature for the automated acquisition of definitional knowledge. Fujii and Ishikawa (2000) use an n-gram model to determine the definitional nature of text fragments, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. Cafarella et al. (2005) developed a Web search engine which handles more general and complex patterns like “cities such as ProperNoun(Head(NP))” in which it is possible to constrain the results with syntactic properties. More recently, a domain-independent supervised approach was presented which learns WordClass Lattices (WCLs), i.e. lattice-based definition classifie</context>
</contexts>
<marker>Fujii, Ishikawa, 2000</marker>
<rawString>Atsushi Fujii and Tetsuya Ishikawa. 2000. Utilizing the World Wide Web as an encyclopedia: extracting term descriptions from semi-structured texts. In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, pages 488–495, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>539--545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="3229" citStr="Hearst (1992)" startWordPosition="487" endWordPosition="488">tomatically obtain large domain glossaries, over recent years computational approaches have been developed which extract textual definitions from corpora (Navigli and Velardi, 2010; Reiplinger et al., 2012) or the Web (Fujii and Ishikawa, 2000). The former methods start from a given set of terms (possibly automatically extracted from a domain corpus) and then harvest textual definitions for these terms from the input corpus using a supervised system. Webbased methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as “X is a Y”, along the lines of Hearst (1992). These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textual definitions. To address the low-recall issue, recurring cue terms occurring within dictionary and encyclopedic resources can be automatically extracted and incorporated into lexical patterns (Saggion, 2004). However, this approach is term-specific and does not scale to arbitrary terminologies and domains. In this paper we propose GlossBoot, a novel approach which reduces human intervention to a bare minimum and exploits the Web</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 15th International Conference on Computational Linguistics, pages 539–545, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Collaboratively built semistructured content and Artificial Intelligence: The story so far.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--2</pages>
<contexts>
<context position="2369" citStr="Hovy et al., 2013" startWordPosition="352" endWordPosition="355">ovide a partial view of a given domain. Moreover, there is no easy way of retrieving the subset of Web glossaries which appertains to a domain of interest. Although online services such as Google Define allow the user to retrieve definitions for an input term, such definitions are extracted from Web glossaries and put together for the given term regardless of their domain. As a result, gathering a large-scale, full-fledged domain glossary is not a speedy operation. Collaborative efforts are currently producing large-scale encyclopedias, such as Wikipedia, which are proving very useful in NLP (Hovy et al., 2013). Interestingly, wikipedias also include manually compiled glossaries. However, such glossaries still suffer from the same above-mentioned problems, i.e., being incomplete or over-specific,1 and hard to customize according to a user’s needs. To automatically obtain large domain glossaries, over recent years computational approaches have been developed which extract textual definitions from corpora (Navigli and Velardi, 2010; Reiplinger et al., 2012) or the Web (Fujii and Ishikawa, 2000). The former methods start from a given set of terms (possibly automatically extracted from a domain corpus) </context>
</contexts>
<marker>Hovy, Navigli, Ponzetto, 2013</marker>
<rawString>Eduard H. Hovy, Roberto Navigli, and Simone Paolo Ponzetto. 2013. Collaboratively built semistructured content and Artificial Intelligence: The story so far. Artificial Intelligence, 194:2–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Ellen Riloff</author>
</authors>
<title>Inducing domain-specific semantic class taggers from (almost) nothing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>275--285</pages>
<location>Uppsala,</location>
<contexts>
<context position="33743" citStr="Huang and Riloff, 2010" startWordPosition="5499" endWordPosition="5502">to dell’atmosfera terrestre dovuto alla presenza di gas nell’atmosfera (anidride carbonica, metano e vapore acqueo) che ostacolano l’uscita delle radiazioni infrarosse emesse dal suolo terreste verso l’alto. Finance spread Indica la differenza tra la quotazione di acquisto e quella di vendita. Table 11: An excerpt of the domain glossaries acquired for the three languages. and Curran, 2008; McIntosh and Curran, 2009), learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). By exploiting the (term, hypernym) seeds to bootstrap the iterative acquisition of extraction patterns from Web glossary pages, we can cover the high variability of textual definitions, including both sentences matching the above-mentioned lexico-syntactic patterns (e.g., “a corpus is a collection of documents”) and glossary-style definitions (e.g., “corpus: a collection of document”) independently of the target domain and language. 7 Conclusions In this paper we have presented GlossBoot, a new, minimally-supervised approach to mult</context>
</contexts>
<marker>Huang, Riloff, 2010</marker>
<rawString>Ruihong Huang and Ellen Riloff. 2010. Inducing domain-specific semantic class taggers from (almost) nothing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 275–285, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
<author>Min-Yen Kan</author>
</authors>
<title>An unsupervised approach to domain-specific term extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Australasian Language Technology Workshop,</booktitle>
<pages>94--98</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="31078" citStr="Kim et al., 2009" startWordPosition="5108" endWordPosition="5111">nd semantic processing. The results shows high precision in both cases. However, these approaches to glossary learning extract unrestricted textual definitions from open text. In order to filter out non-domain definitions, Velardi et al. (2008) automatically extract a domain terminology from an input corpus which they later use for assigning a domain score to each harvested definition and filtering out non-domain candidates. The extraction of domain terms from corpora can be performed either by means of statistical measures such as specificity and cohesion (Park et al., 2002), or just TF*IDF (Kim et al., 2009). To avoid the use of a large domain corpus, terminologies can be obtained from the Web by using Doubly-Anchored Patterns (DAPs) which, given a (term, hypernym) pair, harvest sentences matching manually-defined patterns like “&lt;hypernym&gt; such as &lt;term&gt;, and *” (Kozareva et al., 2008). Kozareva and Hovy (2010a) further extend this term extraction process by harvesting new hypernyms using the corresponding inverse patterns (called DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to our approach, they drop the requirement of a domain corpus and start from a small number of (term, hypernym) </context>
</contexts>
<marker>Kim, Baldwin, Kan, 2009</marker>
<rawString>Su Nam Kim, Timothy Baldwin, and Min-Yen Kan. 2009. An unsupervised approach to domain-specific term extraction. In Proceedings of the Australasian Language Technology Workshop, pages 94–98, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Klavans</author>
<author>Smaranda Muresan</author>
</authors>
<title>Evaluation of the DEFINDER system for fully automatic glossary construction.</title>
<date>2001</date>
<booktitle>In Proceedings of the American Medical Informatics Association (AMIA) Symposium,</booktitle>
<pages>324--328</pages>
<location>Washington, D.C., USA.</location>
<contexts>
<context position="29294" citStr="Klavans and Muresan (2001)" startWordPosition="4836" endWordPosition="4839">ssary extraction is a by-product of the taxonomy learning process. Finally, we note that we cannot compare with approaches based on lexical patterns (such as (Kozareva and Hovy, 2010a)), because they are not aimed at learning glossaries, but just at retrieving sentence snippets which contain pairs of terms/hypernyms (e.g., “supervised systems such as decision trees”). 6 Related Work There are several techniques in the literature for the automated acquisition of definitional knowledge. Fujii and Ishikawa (2000) use an n-gram model to determine the definitional nature of text fragments, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. Cafarella et al. (2005) developed a Web search engine which handles more general and complex patterns like “cities such as ProperNoun(Head(NP))” in which it is possible to constrain the results with syntactic properties. More recently, a domain-independent supervised approach was presented which learns WordClass Lattices (WCLs), i.e. lattice-based definition classifiers that are applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). WCLs have be</context>
</contexts>
<marker>Klavans, Muresan, 2001</marker>
<rawString>Judith Klavans and Smaranda Muresan. 2001. Evaluation of the DEFINDER system for fully automatic glossary construction. In Proceedings of the American Medical Informatics Association (AMIA) Symposium, pages 324–328, Washington, D.C., USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard Hovy</author>
</authors>
<title>A semi-supervised method to learn and construct taxonomies using the Web. In</title>
<date>2010</date>
<booktitle>Proceedings of Empirical Methods in Natural Language Processing,</booktitle>
<pages>1110--1118</pages>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="16649" citStr="Kozareva and Hovy, 2010" startWordPosition="2722" endWordPosition="2725">nually selected five seed hypernymy relations, shown for the English language in Table 3. The seeds were selected by the authors on the basis of just two conditions: i) the seeds should cover different aspects of the domain and should, indeed, identify the domain implicitly, ii) at least 10,000 results should be returned by the search engine when querying it with the seeds plus the glossaryKeyword (see step (2) of GlossBoot). The seed selection was not fine-tuned (i.e., it was not adjusted to improve performance), so it might well be that better seeds would provide better results (see, e.g., (Kozareva and Hovy, 2010b)). However, this type of consideration is beyond the scope of this paper. 3.2.1 Evaluation measures We performed experiments to evaluate the quality of both terms and glosses, as jointly extracted by GlossBoot. Terms. For each domain and language we calculated coverage, extra-coverage and precision of the acquired terms T. Coverage is the ratio of extracted terms in T also contained in the gold standard Tˆ to the size of Tˆ. Extra-coverage is calculated as the ratio of the additional extracted terms in T \ Tˆ over the number of gold standard terms Tˆ. Finally, precision is the ratio of extra</context>
<context position="28850" citStr="Kozareva and Hovy, 2010" startWordPosition="4770" endWordPosition="4773">er-level concepts which do not necessarily pertain to the domain. We performed a similar evaluation for the precision of the acquired glosses, by randomly sampling 50% of them for each system. We show in Table 10 (second row) the estimated gloss precision of GlossBoot and TaxoLearn. Again, GlossBoot outperforms TaxoLearn, retrieving a larger amount of glosses (6716 vs. 834) with higher precision. We remark, however, that in TaxoLearn glossary extraction is a by-product of the taxonomy learning process. Finally, we note that we cannot compare with approaches based on lexical patterns (such as (Kozareva and Hovy, 2010a)), because they are not aimed at learning glossaries, but just at retrieving sentence snippets which contain pairs of terms/hypernyms (e.g., “supervised systems such as decision trees”). 6 Related Work There are several techniques in the literature for the automated acquisition of definitional knowledge. Fujii and Ishikawa (2000) use an n-gram model to determine the definitional nature of text fragments, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. Cafarella et al. (2005) developed a W</context>
<context position="31386" citStr="Kozareva and Hovy (2010" startWordPosition="5157" endWordPosition="5160">corpus which they later use for assigning a domain score to each harvested definition and filtering out non-domain candidates. The extraction of domain terms from corpora can be performed either by means of statistical measures such as specificity and cohesion (Park et al., 2002), or just TF*IDF (Kim et al., 2009). To avoid the use of a large domain corpus, terminologies can be obtained from the Web by using Doubly-Anchored Patterns (DAPs) which, given a (term, hypernym) pair, harvest sentences matching manually-defined patterns like “&lt;hypernym&gt; such as &lt;term&gt;, and *” (Kozareva et al., 2008). Kozareva and Hovy (2010a) further extend this term extraction process by harvesting new hypernyms using the corresponding inverse patterns (called DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to our approach, they drop the requirement of a domain corpus and start from a small number of (term, hypernym) seeds. However, while Doubly-Anchored Patterns have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010a), they cannot be applied to the glossary learning task, because the extracted sentences are not formal definitions. In contrast, GlossBoot performs the novel task of multilingual</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard Hovy. 2010a. A semi-supervised method to learn and construct taxonomies using the Web. In Proceedings of Empirical Methods in Natural Language Processing, pages 1110–1118, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard H Hovy</author>
</authors>
<title>Not all seeds are equal: Measuring the quality of text mining seeds.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>618--626</pages>
<location>Los Angeles, California, USA.</location>
<contexts>
<context position="16649" citStr="Kozareva and Hovy, 2010" startWordPosition="2722" endWordPosition="2725">nually selected five seed hypernymy relations, shown for the English language in Table 3. The seeds were selected by the authors on the basis of just two conditions: i) the seeds should cover different aspects of the domain and should, indeed, identify the domain implicitly, ii) at least 10,000 results should be returned by the search engine when querying it with the seeds plus the glossaryKeyword (see step (2) of GlossBoot). The seed selection was not fine-tuned (i.e., it was not adjusted to improve performance), so it might well be that better seeds would provide better results (see, e.g., (Kozareva and Hovy, 2010b)). However, this type of consideration is beyond the scope of this paper. 3.2.1 Evaluation measures We performed experiments to evaluate the quality of both terms and glosses, as jointly extracted by GlossBoot. Terms. For each domain and language we calculated coverage, extra-coverage and precision of the acquired terms T. Coverage is the ratio of extracted terms in T also contained in the gold standard Tˆ to the size of Tˆ. Extra-coverage is calculated as the ratio of the additional extracted terms in T \ Tˆ over the number of gold standard terms Tˆ. Finally, precision is the ratio of extra</context>
<context position="28850" citStr="Kozareva and Hovy, 2010" startWordPosition="4770" endWordPosition="4773">er-level concepts which do not necessarily pertain to the domain. We performed a similar evaluation for the precision of the acquired glosses, by randomly sampling 50% of them for each system. We show in Table 10 (second row) the estimated gloss precision of GlossBoot and TaxoLearn. Again, GlossBoot outperforms TaxoLearn, retrieving a larger amount of glosses (6716 vs. 834) with higher precision. We remark, however, that in TaxoLearn glossary extraction is a by-product of the taxonomy learning process. Finally, we note that we cannot compare with approaches based on lexical patterns (such as (Kozareva and Hovy, 2010a)), because they are not aimed at learning glossaries, but just at retrieving sentence snippets which contain pairs of terms/hypernyms (e.g., “supervised systems such as decision trees”). 6 Related Work There are several techniques in the literature for the automated acquisition of definitional knowledge. Fujii and Ishikawa (2000) use an n-gram model to determine the definitional nature of text fragments, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. Cafarella et al. (2005) developed a W</context>
<context position="31386" citStr="Kozareva and Hovy (2010" startWordPosition="5157" endWordPosition="5160">corpus which they later use for assigning a domain score to each harvested definition and filtering out non-domain candidates. The extraction of domain terms from corpora can be performed either by means of statistical measures such as specificity and cohesion (Park et al., 2002), or just TF*IDF (Kim et al., 2009). To avoid the use of a large domain corpus, terminologies can be obtained from the Web by using Doubly-Anchored Patterns (DAPs) which, given a (term, hypernym) pair, harvest sentences matching manually-defined patterns like “&lt;hypernym&gt; such as &lt;term&gt;, and *” (Kozareva et al., 2008). Kozareva and Hovy (2010a) further extend this term extraction process by harvesting new hypernyms using the corresponding inverse patterns (called DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to our approach, they drop the requirement of a domain corpus and start from a small number of (term, hypernym) seeds. However, while Doubly-Anchored Patterns have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010a), they cannot be applied to the glossary learning task, because the extracted sentences are not formal definitions. In contrast, GlossBoot performs the novel task of multilingual</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard H. Hovy. 2010b. Not all seeds are equal: Measuring the quality of text mining seeds. In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 618–626, Los Angeles, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantic class learning from the Web with hyponym pattern linkage graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1048--1056</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="31361" citStr="Kozareva et al., 2008" startWordPosition="5153" endWordPosition="5156">rminology from an input corpus which they later use for assigning a domain score to each harvested definition and filtering out non-domain candidates. The extraction of domain terms from corpora can be performed either by means of statistical measures such as specificity and cohesion (Park et al., 2002), or just TF*IDF (Kim et al., 2009). To avoid the use of a large domain corpus, terminologies can be obtained from the Web by using Doubly-Anchored Patterns (DAPs) which, given a (term, hypernym) pair, harvest sentences matching manually-defined patterns like “&lt;hypernym&gt; such as &lt;term&gt;, and *” (Kozareva et al., 2008). Kozareva and Hovy (2010a) further extend this term extraction process by harvesting new hypernyms using the corresponding inverse patterns (called DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to our approach, they drop the requirement of a domain corpus and start from a small number of (term, hypernym) seeds. However, while Doubly-Anchored Patterns have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010a), they cannot be applied to the glossary learning task, because the extracted sentences are not formal definitions. In contrast, GlossBoot performs the n</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008. Semantic class learning from the Web with hyponym pattern linkage graphs. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, pages 1048–1056, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tara McIntosh</author>
<author>James R Curran</author>
</authors>
<title>Weighted mutual exclusion bootstrapping for domain independent lexicon and template acquisition.</title>
<date>2008</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop,</booktitle>
<pages>97--105</pages>
<location>Tasmania.</location>
<marker>McIntosh, Curran, 2008</marker>
<rawString>Tara McIntosh and James R. Curran. 2008. Weighted mutual exclusion bootstrapping for domain independent lexicon and template acquisition. In Proceedings of the Australasian Language Technology Association Workshop, pages 97–105, CSIRO ICT Centre, Tasmania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tara McIntosh</author>
<author>James R Curran</author>
</authors>
<title>Reducing semantic drift with bagging and distributional similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>396--404</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="33539" citStr="McIntosh and Curran, 2009" startWordPosition="5473" endWordPosition="5476">el´ements non vivants d’un milieu qui sont li´es vitalement entre eux. IT Computing link Collegamento tra diverse pagine web, pu`o essere costituito da immagini o testo. Environment effetto serra Riscaldamento dell’atmosfera terrestre dovuto alla presenza di gas nell’atmosfera (anidride carbonica, metano e vapore acqueo) che ostacolano l’uscita delle radiazioni infrarosse emesse dal suolo terreste verso l’alto. Finance spread Indica la differenza tra la quotazione di acquisto e quella di vendita. Table 11: An excerpt of the domain glossaries acquired for the three languages. and Curran, 2008; McIntosh and Curran, 2009), learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). By exploiting the (term, hypernym) seeds to bootstrap the iterative acquisition of extraction patterns from Web glossary pages, we can cover the high variability of textual definitions, including both sentences matching the above-mentioned lexico-syntactic patterns (e.g., “a corpus is a collection of documents”) and glossary-style d</context>
</contexts>
<marker>McIntosh, Curran, 2009</marker>
<rawString>Tara McIntosh and James R. Curran. 2009. Reducing semantic drift with bagging and distributional similarity. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 396–404, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<volume>193</volume>
<pages>250</pages>
<contexts>
<context position="35574" citStr="Navigli and Ponzetto, 2012" startWordPosition="5776" endWordPosition="5779">such as the availability of domain text corpora, which often do not contain enough definitions, and the manual specification of lexical patterns, which typically extract sentence snippets, instead of formal glosses. GlossBoot will be made available to the research community as open-source software. Beyond the immediate usability of its output and its effective use for domain Word Sense Disambiguation (Faralli and Navigli, 2012), we wish to show the benefit of GlossBoot in gloss-driven approaches to ontology learning (Navigli et al., 2011; Velardi et al., 2013) and semantic network enrichment (Navigli and Ponzetto, 2012). In Table 11 we show an excerpt of the acquired glossaries. All the glossaries and gold standards created for our experiments are available from the authors’ Web site http://lcl.uniroma1.it/ glossboot/. We remark that the terminologies covered with GlossBoot are not only precise, but also one order of magnitude greater than those covered in individual online glossaries. As future work we plan to study the ability of GlossBoot to acquire domain glossaries at different levels of specificity (i.e., domains vs. subdomains). We also plan to exploit the acquired HTML patterns for implementing an op</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217– 250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Learning Word-Class Lattices for definition and hypernym extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1318--1327</pages>
<location>Uppsala,</location>
<contexts>
<context position="2796" citStr="Navigli and Velardi, 2010" startWordPosition="412" endWordPosition="415">ledged domain glossary is not a speedy operation. Collaborative efforts are currently producing large-scale encyclopedias, such as Wikipedia, which are proving very useful in NLP (Hovy et al., 2013). Interestingly, wikipedias also include manually compiled glossaries. However, such glossaries still suffer from the same above-mentioned problems, i.e., being incomplete or over-specific,1 and hard to customize according to a user’s needs. To automatically obtain large domain glossaries, over recent years computational approaches have been developed which extract textual definitions from corpora (Navigli and Velardi, 2010; Reiplinger et al., 2012) or the Web (Fujii and Ishikawa, 2000). The former methods start from a given set of terms (possibly automatically extracted from a domain corpus) and then harvest textual definitions for these terms from the input corpus using a supervised system. Webbased methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as “X is a Y”, along the lines of Hearst (1992). These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textua</context>
<context position="13546" citStr="Navigli and Velardi, 2010" startWordPosition="2246" endWordPosition="2249"> in column 2 and the hypernyms extracted by the first term hypernym extraction heuristic in column 3). (b) (Term, Hypernym)-ranking: we sort all the glosses in Gk by the number of seed terms found in each gloss. In the case of ties (i.e., glosses with the same number of seed terms), we further sort the glosses by the score given in Formula 1. We show an example of rank for some glosses in Table 2, where seed terms are in bold, domain terms (i.e., in Tk−1 1 ) are underlined, and non-domain terms are shown in italics. 5While more complex strategies could be used, such as supervised classifiers (Navigli and Velardi, 2010), we found that this heuristic works well because, even when it is not a hypernym, the first term plays the role of a cue word for the defined term. (c) New seed selection: we select the (term, hypernym) pairs corresponding to the K top-ranking glosses. Finally, if k equals the maximum number of iterations, we stop. Else, we increment the iteration counter (i.e., k := k + 1) and jump to step (2) of our glossary bootstrapping algorithm after replacing S with the new set of seeds. The output of glossary bootstrapping is a domain glossary G := Ui=1,...,max Gi, which includes a domain terminology </context>
<context position="29880" citStr="Navigli and Velardi, 2010" startWordPosition="4925" endWordPosition="4928">ents, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. Cafarella et al. (2005) developed a Web search engine which handles more general and complex patterns like “cities such as ProperNoun(Head(NP))” in which it is possible to constrain the results with syntactic properties. More recently, a domain-independent supervised approach was presented which learns WordClass Lattices (WCLs), i.e. lattice-based definition classifiers that are applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). WCLs have been shown to perform with high precision in several domains (Velardi et al., 2013). To avoid the burden of manually creating a training dataset, definitional patterns can be extracted automatically. Reiplinger et al. (2012) experimented with two different approaches for the acquisition of lexical-syntactic patterns. The first approach involves bootstrapping patterns from a domain corpus, and then manually refining the acquired patterns. The second approach, instead, involves automatically acquiring definitional sentences by using a more sophisticated syntactic and semantic process</context>
</contexts>
<marker>Navigli, Velardi, 2010</marker>
<rawString>Roberto Navigli and Paola Velardi. 2010. Learning Word-Class Lattices for definition and hypernym extraction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
<author>Stefano Faralli</author>
</authors>
<title>A graph-based algorithm for inducing lexical taxonomies from scratch.</title>
<date>2011</date>
<booktitle>In Proceedings of the 22th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1872--1877</pages>
<location>Barcelona,</location>
<contexts>
<context position="1520" citStr="Navigli et al., 2011" startWordPosition="216" endWordPosition="219"> infrequent that, when reading a domainspecific text, we humans do not know the meaning of one or more terms. To help the human understanding of specialized texts, repositories of textual definitions for technical terms, called glossaries, are compiled as reference resources within each domain of interest. Interestingly, electronic glossaries have been shown to be key resources not only for humans, but also in Natural Language Processing (NLP) tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Navigli et al., 2011; Velardi et al., 2013). Today large numbers of glossaries are available on the Web. However most such glossaries are small-scale, being made up of just some hundreds of definitions. Consequently, individual glossaries typically provide a partial view of a given domain. Moreover, there is no easy way of retrieving the subset of Web glossaries which appertains to a domain of interest. Although online services such as Google Define allow the user to retrieve definitions for an input term, such definitions are extracted from Web glossaries and put together for the given term regardless of their d</context>
<context position="26927" citStr="Navigli et al., 2011" startWordPosition="4460" endWordPosition="4463">erms per domain) retrieved using Google Define and GlossBoot. we note that Google Define: i) requires knowing the domain term to be defined in advance, whereas we jointly acquire thousands of terms and glosses starting from just a few seeds; ii) does not discriminate between glosses pertaining to the target domain and glosses concerning other fields or senses, whereas we extract domain-specific glosses. 5.2 Comparison with TaxoLearn We also compared GlossBoot with a recent approach to glossary learning embedded into a framework for graph-based taxonomy learning from scratch, called TaxoLearn (Navigli et al., 2011). Since this approach requires the manual selection of a domain corpus to automatically extract terms and glosses, we decided to keep a level playing field and experimented with the same domain used by the authors, i.e., Artificial Intelligence (AI). TaxoLearn was applied to the entire set of IJCAI 2009 proceedings, resulting in the extraction of 427 terms and 834 glosses.12 As regards GlossBoot, we selected 10 seeds to cover all the fields of AI, obtaining 5827 terms and 6716 glosses after 5 iterations, one order of magnitude greater than TaxoLearn. As for the precision of the extracted terms</context>
<context position="35490" citStr="Navigli et al., 2011" startWordPosition="5764" endWordPosition="5767">pproach, thanks to which we can drop the requirements of existing techniques such as the availability of domain text corpora, which often do not contain enough definitions, and the manual specification of lexical patterns, which typically extract sentence snippets, instead of formal glosses. GlossBoot will be made available to the research community as open-source software. Beyond the immediate usability of its output and its effective use for domain Word Sense Disambiguation (Faralli and Navigli, 2012), we wish to show the benefit of GlossBoot in gloss-driven approaches to ontology learning (Navigli et al., 2011; Velardi et al., 2013) and semantic network enrichment (Navigli and Ponzetto, 2012). In Table 11 we show an excerpt of the acquired glossaries. All the glossaries and gold standards created for our experiments are available from the authors’ Web site http://lcl.uniroma1.it/ glossboot/. We remark that the terminologies covered with GlossBoot are not only precise, but also one order of magnitude greater than those covered in individual online glossaries. As future work we plan to study the ability of GlossBoot to acquire domain glossaries at different levels of specificity (i.e., domains vs. su</context>
</contexts>
<marker>Navigli, Velardi, Faralli, 2011</marker>
<rawString>Roberto Navigli, Paola Velardi, and Stefano Faralli. 2011. A graph-based algorithm for inducing lexical taxonomies from scratch. In Proceedings of the 22th International Joint Conference on Artificial Intelligence, pages 1872–1877, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
<author>Dekang Lin</author>
<author>Jeffrey Bigham</author>
<author>Andrei Lifchits</author>
<author>Alpa Jain</author>
</authors>
<title>Names and similarities on the web: Fact extraction in the fast lane.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>809--816</pages>
<location>Sydney, Australia.</location>
<marker>Pas¸ca, Lin, Bigham, Lifchits, Jain, 2006</marker>
<rawString>Marius Pas¸ca, Dekang Lin, Jeffrey Bigham, Andrei Lifchits, and Alpa Jain. 2006. Names and similarities on the web: Fact extraction in the fast lane. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 809–816, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL),</booktitle>
<pages>113--120</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="33601" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="5480" endWordPosition="5484">nt entre eux. IT Computing link Collegamento tra diverse pagine web, pu`o essere costituito da immagini o testo. Environment effetto serra Riscaldamento dell’atmosfera terrestre dovuto alla presenza di gas nell’atmosfera (anidride carbonica, metano e vapore acqueo) che ostacolano l’uscita delle radiazioni infrarosse emesse dal suolo terreste verso l’alto. Finance spread Indica la differenza tra la quotazione di acquisto e quella di vendita. Table 11: An excerpt of the domain glossaries acquired for the three languages. and Curran, 2008; McIntosh and Curran, 2009), learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). By exploiting the (term, hypernym) seeds to bootstrap the iterative acquisition of extraction patterns from Web glossary pages, we can cover the high variability of textual definitions, including both sentences matching the above-mentioned lexico-syntactic patterns (e.g., “a corpus is a collection of documents”) and glossary-style definitions (e.g., “corpus: a collection of document”) independ</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Sydney, Australia, pages 113–120, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngja Park</author>
<author>Roy J Byrd</author>
<author>Branimir K Boguraev</author>
</authors>
<title>Automatic glossary extraction: beyond terminology identification.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>1--7</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="31043" citStr="Park et al., 2002" startWordPosition="5101" endWordPosition="5104">ing a more sophisticated syntactic and semantic processing. The results shows high precision in both cases. However, these approaches to glossary learning extract unrestricted textual definitions from open text. In order to filter out non-domain definitions, Velardi et al. (2008) automatically extract a domain terminology from an input corpus which they later use for assigning a domain score to each harvested definition and filtering out non-domain candidates. The extraction of domain terms from corpora can be performed either by means of statistical measures such as specificity and cohesion (Park et al., 2002), or just TF*IDF (Kim et al., 2009). To avoid the use of a large domain corpus, terminologies can be obtained from the Web by using Doubly-Anchored Patterns (DAPs) which, given a (term, hypernym) pair, harvest sentences matching manually-defined patterns like “&lt;hypernym&gt; such as &lt;term&gt;, and *” (Kozareva et al., 2008). Kozareva and Hovy (2010a) further extend this term extraction process by harvesting new hypernyms using the corresponding inverse patterns (called DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to our approach, they drop the requirement of a domain corpus and start from </context>
</contexts>
<marker>Park, Byrd, Boguraev, 2002</marker>
<rawString>Youngja Park, Roy J. Byrd, and Branimir K. Boguraev. 2002. Automatic glossary extraction: beyond terminology identification. In Proceedings of the 19th International Conference on Computational Linguistics, pages 1–7, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>41--47</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="33700" citStr="Ravichandran and Hovy, 2002" startWordPosition="5493" endWordPosition="5496">i o testo. Environment effetto serra Riscaldamento dell’atmosfera terrestre dovuto alla presenza di gas nell’atmosfera (anidride carbonica, metano e vapore acqueo) che ostacolano l’uscita delle radiazioni infrarosse emesse dal suolo terreste verso l’alto. Finance spread Indica la differenza tra la quotazione di acquisto e quella di vendita. Table 11: An excerpt of the domain glossaries acquired for the three languages. and Curran, 2008; McIntosh and Curran, 2009), learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). By exploiting the (term, hypernym) seeds to bootstrap the iterative acquisition of extraction patterns from Web glossary pages, we can cover the high variability of textual definitions, including both sentences matching the above-mentioned lexico-syntactic patterns (e.g., “a corpus is a collection of documents”) and glossary-style definitions (e.g., “corpus: a collection of document”) independently of the target domain and language. 7 Conclusions In this paper we have presented GlossBoot, a</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 41–47, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melanie Reiplinger</author>
<author>Ulrich Sch¨afer</author>
<author>Magdalena Wolska</author>
</authors>
<title>Extracting glossary sentences from scholarly articles: A comparative evaluation of pattern bootstrapping and deep analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries,</booktitle>
<pages>55--65</pages>
<location>Jeju Island,</location>
<marker>Reiplinger, Sch¨afer, Wolska, 2012</marker>
<rawString>Melanie Reiplinger, Ulrich Sch¨afer, and Magdalena Wolska. 2012. Extracting glossary sentences from scholarly articles: A comparative evaluation of pattern bootstrapping and deep analysis. In Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 55–65, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the sixteenth national conference on Artificial intelligence and the eleventh Innovative applications of artificial intelligence conference,</booktitle>
<pages>474--479</pages>
<location>Menlo Park, CA, USA.</location>
<contexts>
<context position="32325" citStr="Riloff and Jones, 1999" startWordPosition="5295" endWordPosition="5298">bly-Anchored Patterns have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010a), they cannot be applied to the glossary learning task, because the extracted sentences are not formal definitions. In contrast, GlossBoot performs the novel task of multilingual glossary learning from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including high-precision semantic lexicon extraction from large corpora (Riloff and Jones, 1999; Thelen and Riloff, 2002; McIntosh 535 Domain Term Gloss EN Botany deciduous losing foliage at the end of the growing season. Computing information space The abstract concept of everything accessible using networks: the Web. Finance discount The difference between the lower price paid for a security and the security’s face amount at issue. FR Botany insectivore Qui capture des insectes et en absorbe les mati`eres nutritives. Computing notebook C’est l’appellation d’un petit portable d’une taille proche d’une feuille A4. Environment ´ecosyst`eme Ensemble des ˆetres vivants et des ´el´ements no</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In Proceedings of the sixteenth national conference on Artificial intelligence and the eleventh Innovative applications of artificial intelligence conference, pages 474–479, Menlo Park, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horacio Saggion</author>
</authors>
<title>Identifying definitions in text collections for question answering.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation,</booktitle>
<pages>1927--1930</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3604" citStr="Saggion, 2004" startWordPosition="539" endWordPosition="540">ual definitions for these terms from the input corpus using a supervised system. Webbased methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as “X is a Y”, along the lines of Hearst (1992). These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textual definitions. To address the low-recall issue, recurring cue terms occurring within dictionary and encyclopedic resources can be automatically extracted and incorporated into lexical patterns (Saggion, 2004). However, this approach is term-specific and does not scale to arbitrary terminologies and domains. In this paper we propose GlossBoot, a novel approach which reduces human intervention to a bare minimum and exploits the Web to learn a 1http://en.wikipedia.org/wiki/Portal:Contents/Glossaries 528 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 528–538, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 1 2 3 4 5 Initial seed selection initial seeds Seed queries search results Pattern and glossary extraction new seed</context>
</contexts>
<marker>Saggion, 2004</marker>
<rawString>Horacio Saggion. 2004. Identifying definitions in text collections for question answering. In Proceedings of the Fourth International Conference on Language Resources and Evaluation, pages 1927–1930, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Thelen</author>
<author>Ellen Riloff</author>
</authors>
<title>A bootstrapping method for learning semantic lexicons using extraction pattern contexts.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>214--221</pages>
<location>Salt Lake City, UT, USA.</location>
<contexts>
<context position="32350" citStr="Thelen and Riloff, 2002" startWordPosition="5299" endWordPosition="5302">ve proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010a), they cannot be applied to the glossary learning task, because the extracted sentences are not formal definitions. In contrast, GlossBoot performs the novel task of multilingual glossary learning from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including high-precision semantic lexicon extraction from large corpora (Riloff and Jones, 1999; Thelen and Riloff, 2002; McIntosh 535 Domain Term Gloss EN Botany deciduous losing foliage at the end of the growing season. Computing information space The abstract concept of everything accessible using networks: the Web. Finance discount The difference between the lower price paid for a security and the security’s face amount at issue. FR Botany insectivore Qui capture des insectes et en absorbe les mati`eres nutritives. Computing notebook C’est l’appellation d’un petit portable d’une taille proche d’une feuille A4. Environment ´ecosyst`eme Ensemble des ˆetres vivants et des ´el´ements non vivants d’un milieu qui</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>Michael Thelen and Ellen Riloff. 2002. A bootstrapping method for learning semantic lexicons using extraction pattern contexts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 214–221, Salt Lake City, UT, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Velardi</author>
<author>Roberto Navigli</author>
<author>Pierluigi D’Amadio</author>
</authors>
<title>Mining the Web to create specialized glossaries.</title>
<date>2008</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>23</volume>
<issue>5</issue>
<marker>Velardi, Navigli, D’Amadio, 2008</marker>
<rawString>Paola Velardi, Roberto Navigli, and Pierluigi D’Amadio. 2008. Mining the Web to create specialized glossaries. IEEE Intelligent Systems, 23(5):18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Velardi</author>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>OntoLearn Reloaded: A graph-based algorithm for taxonomy induction.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="1543" citStr="Velardi et al., 2013" startWordPosition="220" endWordPosition="224"> reading a domainspecific text, we humans do not know the meaning of one or more terms. To help the human understanding of specialized texts, repositories of textual definitions for technical terms, called glossaries, are compiled as reference resources within each domain of interest. Interestingly, electronic glossaries have been shown to be key resources not only for humans, but also in Natural Language Processing (NLP) tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Navigli et al., 2011; Velardi et al., 2013). Today large numbers of glossaries are available on the Web. However most such glossaries are small-scale, being made up of just some hundreds of definitions. Consequently, individual glossaries typically provide a partial view of a given domain. Moreover, there is no easy way of retrieving the subset of Web glossaries which appertains to a domain of interest. Although online services such as Google Define allow the user to retrieve definitions for an input term, such definitions are extracted from Web glossaries and put together for the given term regardless of their domain. As a result, gat</context>
<context position="29975" citStr="Velardi et al., 2013" startWordPosition="4941" endWordPosition="4944">ed by cue phrases such as “is called” and “is defined as”. Cafarella et al. (2005) developed a Web search engine which handles more general and complex patterns like “cities such as ProperNoun(Head(NP))” in which it is possible to constrain the results with syntactic properties. More recently, a domain-independent supervised approach was presented which learns WordClass Lattices (WCLs), i.e. lattice-based definition classifiers that are applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). WCLs have been shown to perform with high precision in several domains (Velardi et al., 2013). To avoid the burden of manually creating a training dataset, definitional patterns can be extracted automatically. Reiplinger et al. (2012) experimented with two different approaches for the acquisition of lexical-syntactic patterns. The first approach involves bootstrapping patterns from a domain corpus, and then manually refining the acquired patterns. The second approach, instead, involves automatically acquiring definitional sentences by using a more sophisticated syntactic and semantic processing. The results shows high precision in both cases. However, these approaches to glossary lear</context>
<context position="35513" citStr="Velardi et al., 2013" startWordPosition="5768" endWordPosition="5771">ch we can drop the requirements of existing techniques such as the availability of domain text corpora, which often do not contain enough definitions, and the manual specification of lexical patterns, which typically extract sentence snippets, instead of formal glosses. GlossBoot will be made available to the research community as open-source software. Beyond the immediate usability of its output and its effective use for domain Word Sense Disambiguation (Faralli and Navigli, 2012), we wish to show the benefit of GlossBoot in gloss-driven approaches to ontology learning (Navigli et al., 2011; Velardi et al., 2013) and semantic network enrichment (Navigli and Ponzetto, 2012). In Table 11 we show an excerpt of the acquired glossaries. All the glossaries and gold standards created for our experiments are available from the authors’ Web site http://lcl.uniroma1.it/ glossboot/. We remark that the terminologies covered with GlossBoot are not only precise, but also one order of magnitude greater than those covered in individual online glossaries. As future work we plan to study the ability of GlossBoot to acquire domain glossaries at different levels of specificity (i.e., domains vs. subdomains). We also plan</context>
</contexts>
<marker>Velardi, Faralli, Navigli, 2013</marker>
<rawString>Paola Velardi, Stefano Faralli, and Roberto Navigli. 2013. OntoLearn Reloaded: A graph-based algorithm for taxonomy induction. Computational Linguistics, 39(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation rivalin� supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33r Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="33803" citStr="Yarowsky, 1995" startWordPosition="5509" endWordPosition="5510">ra (anidride carbonica, metano e vapore acqueo) che ostacolano l’uscita delle radiazioni infrarosse emesse dal suolo terreste verso l’alto. Finance spread Indica la differenza tra la quotazione di acquisto e quella di vendita. Table 11: An excerpt of the domain glossaries acquired for the three languages. and Curran, 2008; McIntosh and Curran, 2009), learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). By exploiting the (term, hypernym) seeds to bootstrap the iterative acquisition of extraction patterns from Web glossary pages, we can cover the high variability of textual definitions, including both sentences matching the above-mentioned lexico-syntactic patterns (e.g., “a corpus is a collection of documents”) and glossary-style definitions (e.g., “corpus: a collection of document”) independently of the target domain and language. 7 Conclusions In this paper we have presented GlossBoot, a new, minimally-supervised approach to multilingual glossary learning. Starting from a few hypernymy re</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised Word Sense Disambiguation rivalin� supervised methods. In Proceedings of the 33r Annual Meeting of the Association for Computational Linguistics, pages 189– 196, Cambridge, MA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>