<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000022">
<title confidence="0.986929">
Named Entity Recognition with Bilingual Constraints
</title>
<author confidence="0.930289">
Wanxiang Che† Mengqiu Wang$ Christopher D. Manning$ Ting Liu†
</author>
<email confidence="0.829929">
†{car, tliu}@ir.hit.edu.cn ${mengqiu, manning}@stanford.edu
</email>
<affiliation confidence="0.975719">
School of Computer Science and Technology Computer Science Department
Harbin Institute of Technology Stanford University
</affiliation>
<address confidence="0.521848">
Harbin, China, 150001 Stanford, CA, 94305
</address>
<sectionHeader confidence="0.990792" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99924625">
Different languages contain complementary
cues about entities, which can be used to im-
prove Named Entity Recognition (NER) sys-
tems. We propose a method that formu-
lates the problem of exploring such signals on
unannotated bilingual text as a simple Inte-
ger Linear Program, which encourages entity
tags to agree via bilingual constraints. Bilin-
gual NER experiments on the large OntoNotes
4.0 Chinese-English corpus show that the pro-
posed method can improve strong baselines
for both Chinese and English. In particular,
Chinese performance improves by over 5%
absolute Fl score. We can then annotate a
large amount of bilingual text (80k sentence
pairs) using our method, and add it as up-
training data to the original monolingual NER
training corpus. The Chinese model retrained
on this new combined dataset outperforms the
strong baseline by over 3% Fl score.
</bodyText>
<sectionHeader confidence="0.999468" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999020166666667">
Named Entity Recognition (NER) is an important
task for many applications, such as information ex-
traction and machine translation. State-of-the-art su-
pervised NER methods require large amounts of an-
notated data, which are difficult and expensive to
produce manually, especially for resource-poor lan-
guages.
A promising approach for improving NER per-
formance without annotating more data is to exploit
unannotated bilingual text (bitext), which are rela-
tively easy to obtain for many language pairs, bor-
rowing from the resources made available by statis-
</bodyText>
<page confidence="0.976206">
52
</page>
<bodyText confidence="0.999409363636364">
tical machine translation research.1 Different lan-
guages contain complementary cues about entities.
For example, in Figure 1, the word “本 (Ben)” is
common in Chinese but rarely appears as a trans-
lated foreign name. However, its aligned word on
the English side (“Ben”) provides a strong clue that
this is a person name. Judicious use of this type of
bilingual cues can help to recognize errors a mono-
lingual tagger would make, allowing us to produce
more accurately tagged bitext. Each side of the
tagged bitext can then be used to expand the orig-
inal monolingual training dataset, which may lead
to higher accuracy in the monolingual taggers.
Previous work such as Li et al. (2012) and Kim
et al. (2012) demonstrated that bilingual corpus an-
notated with NER labels can be used to improve
monolingual tagger performance. But a major draw-
back of their approaches are the need for manual
annotation efforts to create such corpora. To avoid
this requirement, Burkett et al. (2010) suggested a
“multi-view” learning scheme based on re-ranking.
Noisy output of a “strong” tagger is used as training
data to learn parameters of a log-linear re-ranking
model with additional bilingual features, simulated
by a “weak” tagger. The learned parameters are then
reused with the “strong” tagger to re-rank its own
outputs for unseen inputs. Designing good “weak”
taggers so that they complement the “view” of bilin-
gual features in the log-linear re-ranker is crucial to
the success of this algorithm. Unfortunately there is
no principled way of designing such “weak” taggers.
In this paper, we would like to explore a conceptu-
ally much simpler idea that can also take advantage
</bodyText>
<footnote confidence="0.568946">
1opus.lingfil.uu.se
</footnote>
<note confidence="0.5575065">
Proceedings of NAACL-HLT 2013, pages 52–62,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<equation confidence="0.5344215">
TheO chairmanO ofO theB−ORG FederalI−ORG ReserveI−ORG isO BenB−PER BernankeI−PER
美联储B−ORG 主席O 是O 本B−PER 伯南克I−PER
</equation>
<figureCaption confidence="0.9999">
Figure 1: Example of NER labels between two word-aligned bilingual parallel sentences.
</figureCaption>
<bodyText confidence="0.999815789473684">
of the large amount of unannotated bitext, without
complicated machinery. More specifically, we in-
troduce a joint inference method that formulates the
bilingual NER tagging problem as an Integer Linear
Program (ILP) and solves it during decoding. We
propose a set of intuitive and effective bilingual con-
straints that encourage NER results to agree across
the two languages.
Experimental results on the OntoNotes 4.0 named
entity annotated Chinese-English parallel corpus
show that the proposed method can improve the
strong Chinese NER baseline by over 5% F1 score
and also give small improvements over the English
baseline. Moreover, by adding the automatically
tagged data to the original NER training corpus
and retraining the monolingual model using an up-
training regimen (Petrov et al., 2010), we can im-
prove the monolingual Chinese NER performance
by over 3% F1 score.
</bodyText>
<sectionHeader confidence="0.980971" genericHeader="introduction">
2 Constraint-based Monolingual NER
</sectionHeader>
<bodyText confidence="0.9995004">
NER is a sequence labeling task where we assign
a named entity tag to each word in an input sen-
tence. One commonly used tagging scheme is the
BIO scheme. The tag B-X (Begin) represents the
first word of a named entity of type X, for example,
PER (Person) or LOC (Location). The tag I-X (In-
side) indicates that a word is part of an entity but not
first word. The tag O (Outside) is used for all non-
entity words.2 See Figure 1 for an example tagged
sentence.
</bodyText>
<listItem confidence="0.669188">
Conditional Random Fields (CRF) (Lafferty et al.,
2001) is a state-of-the-art sequence labeling model
widely used in NER. A first-order linear-chain CRF
</listItem>
<bodyText confidence="0.859788333333333">
2While the performance of NER is measured at the entity
level (not the tag level).
defines the following conditional probability:
</bodyText>
<equation confidence="0.9920985">
1 PCRF(y|x) = Z(x) �Mi(yi,yi−1|x) (1)
i
</equation>
<bodyText confidence="0.999702538461538">
where x and y are the input and output sequences,
respectively, Z(x) is the partition function, and Mi
is the clique potential for edge clique i. Decoding
in CRF involves finding the most likely output se-
quence that maximizes this objective, and is com-
monly done by the Viterbi algorithm.
Roth and Yih (2005) proposed an ILP inference
algorithm, which can capture more task-specific and
global constraints than the vanilla Viterbi algorithm.
Our work is inspired by Roth and Yih (2005). But
instead of directly solving the shortest-path problem
in the ILP formulation, we re-define the conditional
probability as:
</bodyText>
<equation confidence="0.992949">
PMAR(y|x) = � P(yi|x) (2)
i
</equation>
<bodyText confidence="0.999938333333333">
where P(yi|x) is the marginal probability given by
an underlying CRF model computed using forward-
backward inference. Since the early HMM litera-
ture, it has been well known that using the marginal
distributions at each position works well, as opposed
to Viterbi MAP sequence labeling (M´erialdo, 1994).
Our experimental results also supports this claim, as
we will show in Section 6. Our objective is to find
an optimal NER tag sequence:
</bodyText>
<equation confidence="0.9987245">
y� = arg max PMAR(y|x)
Y
= arg max � log P(yi|x) (3)
Y i
</equation>
<bodyText confidence="0.9919815">
Then an ILP can be used to solve the inference
problem as classification problem with constraints.
</bodyText>
<page confidence="0.946884">
53
</page>
<equation confidence="0.9825245">
zyi log P y (4)
i
</equation>
<bodyText confidence="0.997777357142857">
where Y is the set of all possible named entity tags.
Piy = P(yi = y|x) is the CRF marginal probabil-
ity that the ith word is tagged with y, and zyi is an
indicator that equals 1 iff the ith word is tagged y;
otherwise, zyi is 0.
If no constraints are identified, then Eq. (4)
achieves maximum when all zyi are assigned to 1,
which violates the condition that each word should
only be assigned a single entity tag. We can express
this with constraints:
Similarly, “本” and “Ben” as well as “伯南克” and
“Bernanke” were all tagged with the tag PER.
The objective function for bilingual NER can be
expressed as follows:
</bodyText>
<equation confidence="0.9863685">
zj log P y
y j (7)
</equation>
<bodyText confidence="0.95780275">
where Piy and Pjy are the probabilities of the ith Chi-
nese word and jth English word to be tagged with y,
respectively. xc and xe are respectively the Chinese
and English sentences.
Similar to monolingual constrained NER (Sec-
tion 2), monolingual constraints are added for each
language as shown in Eqs. (8) and (9):
The objective function is:
</bodyText>
<equation confidence="0.999887375">
max X |X |X
i=1 y∈Y
zi log P y
y i +
X |Xc|
i=1
max
X
y∈Y
X |Xe|
j=1
X
y∈Y
X zi = 1 X X zyj = 1 (8)
Vi : y (5) Vi : zyi = 1; Vj :
y∈Y y∈Y y∈Y
</equation>
<bodyText confidence="0.999985142857143">
After adding the constraints, the probability of the
sequence is maximized when each word is assigned
the tag with highest probability. However, some in-
valid results may still exist. For example a tag O
may be wrongly followed by a tag I-X, although a
named entity cannot start with I-X. Therefore, we
can add the following constraints:
</bodyText>
<equation confidence="0.9699859">
Vi, VX : zB-X
i−1 + zI-X
i−1 _ zI-X
i &gt; 0 (6)
which specifies that when the ith word is tagged with
I-X (zI-X
i = 1), then the previous word can only be
tagged with B-X or I-X (zB-X
i−1 + zI-X
i−1 &gt; 1).
</equation>
<sectionHeader confidence="0.973559" genericHeader="method">
3 NER with Bilingual Constraints
</sectionHeader>
<bodyText confidence="0.9997696">
This section demonstrates how to jointly perform
NER for two languages with bilingual constraints.
We assume sentences have been aligned into pairs,
and the word alignment between each pair of sen-
tences is also given.
</bodyText>
<subsectionHeader confidence="0.999612">
3.1 Hard Bilingual Constraints
</subsectionHeader>
<bodyText confidence="0.999958833333333">
We first introduce the simplest hard constraints, i.e.,
each word alignment pair should have the same
named entity tag. For example, in Figure 1, the
Chinese word “美联储” was aligned with the En-
glish words “the”, “Federal” and “Reserve”. There-
fore, they have the same named entity tags ORG.3
</bodyText>
<footnote confidence="0.893309">
3The prefix B- and I- are ignored.
</footnote>
<equation confidence="0.9970805">
Vi, VX : zB-X
i + zI-X
i _ zB-X
i+1 &gt; 0 (9)
Vj, VX : zB-X j+ zI-X
j _ zB-X
j+1 &gt; 0
Bilingual constraints are added in Eq. (10):
V(i, j) E A, VX : zB-X
i + zI-X
i = zB-X
j + zI-X j(10)
</equation>
<bodyText confidence="0.999976">
where A = {(i, j)} is the word alignment pair set,
i.e., the ith Chinese word and the jth English word
were aligned together. Chinese word i is tagged with
a named entity type X (zB-X
</bodyText>
<equation confidence="0.967401">
i + zI-X
i = 1), iff English
word j is tagged with X (zB-X
j +zI-X
</equation>
<bodyText confidence="0.999740722222222">
j = 1). Therefore,
these hard bilingual constraints guarantee that when
two words are aligned, they are tagged with the same
named entity tag.
However, in practice, aligned word pairs do not
always have the same tag because of the difference
in annotation standards across different languages.
For example, in Figure 2(a), the Chinese word “开发
区” is a location. However, it is aligned to the words,
“development” and “zone”, which are not named en-
tities in English. Word alignment error is another se-
rious problem that can cause violation of hard con-
straints. In Figure 2(b), the English word “Agency”
is wrongly aligned with the Chinese word “电 (re-
port)”. Thus, these two words cannot be assigned
with the same tag.
To address these two problems, we present a prob-
abilistic model for bilingual NER which can lead to
</bodyText>
<page confidence="0.973252">
54
</page>
<figure confidence="0.822287">
ThisO developmentO zoneO isO locatedO inO ...
. . .
(a) Inconsistent named entity standards
XinhuaB−ORG NewsI−ORG AgencyI−ORG FebruaryO 16thO
新华社B−ORG 二月B−LOC 十六日O 电O
</figure>
<bodyText confidence="0.9998527">
and arrive at the third factor of Eq. (12). These fac-
tors represent the two major sources of information
in the model: monolingual surface observation, and
cross-lingual word associations.
The first two factors of Eq. (12) can be further
decomposed into the product of probabilities of all
words in each language sentence like Eq. (2).
Assuming that the tags are independent between
different word alignment pairs, then the last factor
of Eq. (12) can be decomposed into:
</bodyText>
<figure confidence="0.98536225">
这个O 开发区B−LOC 位O 于O
(b) Word alignment error P(yc, ye|A) Y= P(ycayea)
a∈A P(yca)P(yea)
P(yc|A)P(ye|A)
</figure>
<figureCaption confidence="0.991157">
Figure 2: Errors of hard bilingual constraints method. Y= λycye (13)
a∈A a
</figureCaption>
<bodyText confidence="0.995775333333333">
an optimization problem with two soft bilingual con-
straints:
1) allow word-aligned pairs to have different
named entity tags; 2) consider word alignment prob-
abilities to reduce the influence of wrong word align-
ments.
</bodyText>
<subsectionHeader confidence="0.985733">
3.2 Soft Constraints with Tag Uncertainty
</subsectionHeader>
<bodyText confidence="0.992896272727273">
The new probabilistic model for bilingual NER is:
where yca and yea respectively denotes Chinese and
English named entity tags in a word alignment pair
a. λycye = P(ycye) P(yc)P(ye) is the pointwise mutual infor-
mation (PMI) score between a Chinese named en-
tity tag yc and an English named entity tag ye. If
yc = ye, then the score will be high; otherwise the
score will be low. A number of methods for calculat-
ing the scores are provided at the end of this section.
We use ILP to maximize Eq. (12). The new ob-
jective function is expressed as follow:
</bodyText>
<equation confidence="0.999457615384616">
P(yc, ye, xc, xe, A)
P(yc, ye|xc, xe, A) =
P(yc, xc, xe, A) P(ye, xc, xe, A)
� P(xc, xe, A)
P(xc, xe, A)
P(xc, xe, A)
max X |Xc |X zi log P y X |Xe |X zj log P y
i=1 y∈Y y i + j=1 y∈Y y
j
P(yc, ye, xc, xe, A)P(xc, xe, A) �(11)
P(yc, xc, xe, A)P(ye, xc, xe, A)
� P(yc|xc)P(ye|xe) P (yc, ye|A)
P(yc|A)P (ye|A) (12)
</equation>
<bodyText confidence="0.988931625">
where yc and ye respectively denotes Chinese and
English named entity output sequences. A is the set
of word alignment pairs.
If we assume that named entity tag assignments in
Chinese is only dependent on the observed Chinese
sentence, then we can drop the A and xe term in the
first factor of Eq. (11), and arrive at the first factor of
Eq. (12); similarly we can use the same assumption
to derive the second factor in Eq. (12) for English;
alternatively, if we assume the named entity tag as-
signments are only dependent on the cross-lingual
word associations via word alignment, then we can
drop xc and xe terms in the third factor of Eq. (11)
zaycye log λycye a(14)
where zycye
a is an indicator that equals 1 iff the Chi-
nese and English named entity tags are yc and ye
respectively, given a word alignment pair a; other-
wise, zaycye is 0.
Monolingual constraints such as Eqs. (8) and (9)
need to be added. In addition, one and only one pos-
sible named entity tag pair exists for a word align-
ment pair. This condition can be expressed as the
following constraints:
</bodyText>
<equation confidence="0.9953875">
baEA: X X zaycye = 1 (15)
yc∈Y ye∈Y
</equation>
<bodyText confidence="0.997066">
When the tag pair of a word alignment pair is de-
termined, the corresponding monolingual named en-
</bodyText>
<equation confidence="0.755087714285714">
X
+
a∈A
X
yc∈Y
X
ye∈Y
</equation>
<page confidence="0.981685">
55
</page>
<bodyText confidence="0.996642">
tity tags can also be identified. This rule can be ex-
pressed by the following constraints:
</bodyText>
<equation confidence="0.958009375">
ba = (i, j) E A : zycye
a &lt; zyc
i , zycye
a &lt; zye
j (16)
Thus, if zycye
a = 1, then zyc
i and zye
</equation>
<bodyText confidence="0.984973055555556">
j must be both
equal to 1. Here, the ith Chinese word and the jth
English word are aligned together.
In contrast to hard bilingual constraints, inconsis-
tent named entity tags for an aligned word pair are
allowed in soft bilingual constraints, but are given
lower λycye scores.
To calculate the λycye score, an annotated bilin-
gual NER corpus is consulted. We count from all
word alignment pairs the number of times yc and ye
occur together (C(ycye)) and separately (C(yc) and
C(ye)). Afterwards, λycye is calculated with maxi-
mum likelihood estimation as follows:
word alignments are; the larger the θ, the more pos-
sible word alignments are lost. To ameliorate this
problem, we introduce another set of soft bilingual
constraints.
We can re-express Eq. (13) as follows:
</bodyText>
<equation confidence="0.923083">
(λacye)I&apos; (18)
</equation>
<bodyText confidence="0.9798816">
where 9/ is the set of all word pairs between two
languages. Ia = 1 iff Pa &gt; θ; otherwise, Ia = 0.
We can then replace the hard indicator Ia with
the word alignment probability Pa, Eq. (14) is then
transformed into the following equation:
</bodyText>
<equation confidence="0.802796">
Aycye =
A riycye
ri
a∈A
max |Wc |� � zyi log Piy + |We |� � zyj log Pjy
i y∈Y j y∈Y
P(ycye) N x C(ycye) C(yc)C(ye) (17) � � � zycye
λycye = + yc∈Y ye∈Y a Pa log λycye
P(yc)P(ye) a∈.d a (19)
</equation>
<bodyText confidence="0.999957578947368">
where N is the total number of word alignment
pairs.
However, in this paper, we assume that no named
entity annotated bilingual corpus is available. Thus,
the above method is only used as Oracle. A real-
istic method for calculating the λycye score requires
the use of two initial monolingual NER models, such
as baseline CRF, to predict named entity tags for
each language on an unannotated bitext. We count
from this automatically tagged corpus the statistics
mentioned above. This method is henceforth re-
ferred to as Auto.
A simpler approach is to manually set the value
of λycye: if yc = ye then we assign a larger value
to λycye; else we assign an ad-hoc smaller value. In
fact, if we set λycye = 1 iff yc = ye; otherwise,
λycye = 0, then the soft constraints backs off to hard
constraints. We refer to this set of soft constraints as
Soft-tag.
</bodyText>
<subsectionHeader confidence="0.998624">
3.3 Constraints with Alignment Uncertainty
</subsectionHeader>
<bodyText confidence="0.9990146">
So far, we assumed that a word alignment set A is
known. In practice, only the word alignment proba-
bility Pa for each word pair a is provided. We can
set a threshold θ for Pa to tune the set A: a E A
iff Pa &gt; θ. This condition can be regarded as a
kind of hard word alignment. However, the follow-
ing problem exists: the smaller the θ, the noisier the
We name the set of constraints above
Soft-align, which has the same constraints
as Soft-tag, i.e., Eqs. (8), (9), (15) and (16).
</bodyText>
<sectionHeader confidence="0.999306" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999935913043478">
We conduct experiments on the latest OntoNotes
4.0 corpus (LDC2011T03). OntoNotes is a large,
manually annotated corpus that contains various text
genres and annotations, such as part-of-speech tags,
named entity labels, syntactic parse trees, predicate-
argument structures and co-references (Hovy et al.,
2006). Aside from English, this corpus also con-
tains several Chinese and Arabic corpora. Some of
these corpora contain bilingual parallel documents.
We used the Chinese-English parallel corpus with
named entity labels as our development and test
data. This corpus includes about 400 document pairs
(chtb 0001-0325, ectb 1001-1078). We used odd-
numbered documents as development data and even-
numbered documents as test data. We used all other
portions of the named entity annotated corpus as
training data for the monolingual systems. There
were a total of —660 Chinese documents (—16k sen-
tences) and —1,400 English documents (—39k sen-
tences). OntoNotes annotates 18 named entity types,
such as person, location, date and money. In this
paper, we selected the four most common named
entity types, i.e., PER (Person), LOC (Location),
</bodyText>
<page confidence="0.98921">
56
</page>
<table confidence="0.978252285714286">
Chinese NER Templates
00: 1 (class bias param)
1: wi+k,−1 ≤ k ≤ 1
2: wi+k−1 ◦ wi+k, 0 ≤ k ≤ 1
3: shape(wi+k), −4 ≤ k ≤ 4
4: prefix(wi, k),1 ≤ k ≤ 4
5: prefix(wi−1, k),1 ≤ k ≤ 4
6: suffix(wi, k),1 ≤ k ≤ 4
7: suffix(wi−1, k),1 ≤ k ≤ 4
8: radical(wi, k),1 ≤ k ≤ len(wi)
Unigram Features
yi◦ 00 – 08
Bigram Features
yi−1 ◦ yi◦ 00 – 08
</table>
<tableCaption confidence="0.999807">
Table 1: Basic features of Chinese NER.
</tableCaption>
<bodyText confidence="0.998795296296296">
ORG (Organization) and GPE (Geo-Political Enti-
ties), and discarded the others.
Since the bilingual corpus is only aligned at the
document level, we performed sentence alignment
using the Champollion Tool Kit (CTK).4 After re-
moving sentences with no aligned sentence, a total
of 8,249 sentence pairs were retained.
We used the BerkeleyAligner,5 to produce
word alignments over the sentence-aligned datasets.
BerkeleyAligner also gives posterior probabilities
Pa for each aligned word pair.
We used the CRF-based Stanford NER tagger (us-
ing Viterbi decoding) as our baseline monolingual
NER tool.6 English features were taken from Finkel
et al. (2005). Table 1 lists the basic features of
Chinese NER, where ◦ means string concatenation
and yi is the named entity tag of the ith word wi.
Moreover, shape(wi) is the shape of wi, such as
date and number. prefix/suffix(wi, k) denotes the
k-characters prefix/suffix of wi. radical(wi, k) de-
notes the radical of the kth Chinese character of wi.7
len(wi) is the number of Chinese characters in wi.
To make the baseline CRF taggers stronger, we
added word clustering features to improve gener-
alization over unseen data for both Chinese and
English. Word clustering features have been suc-
cessfully used in several English tasks, including
</bodyText>
<footnote confidence="0.9747464">
4champollion.sourceforge.net
5code.google.com/p/berkeleyaligner
6nlp.stanford.edu/software/CRF-NER.shtml,
which has included our English and Chinese NER implementations.
7The radical of a Chinese character can be found at: www.
</footnote>
<page confidence="0.395175">
unicode.org/charts/unihan.html
</page>
<bodyText confidence="0.977695076923077">
NER (Miller et al., 2004) and dependency pars-
ing (Koo et al., 2008). To our knowledge, this work
is the first use of word clustering features for Chi-
nese NER. A C++ implementation of the Brown
word clustering algorithms (Brown et al., 1992) was
used to obtain the word clusters (Liang, 2005).8
Raw text was obtained from the fifth edition of Chi-
nese Gigaword (LDC2011T13). One million para-
graphs from Xinhua news section were randomly
selected, and the Stanford Word Segmenter with
LDC standard was applied to segment Chinese text
into words.9 About 46 million words were obtained
which were clustered into 1,000 word classes.
</bodyText>
<sectionHeader confidence="0.994648" genericHeader="method">
5 Threshold Tuning
</sectionHeader>
<bodyText confidence="0.999902466666667">
During development, we tuned the word alignment
probability thresholds to find the best value. Figure 3
shows the performance curves.
When the word alignment probability threshold 0
is set to 0.9, the hard bilingual constraints perform
well for both Chinese and English. But as the thresh-
olds value gets smaller, and more noisy word align-
ments are introduced, we see the hard bilingual con-
straints method starts to perform badly.
In Soft-tag setting, where inconsistent tag as-
signments within aligned word pairs are allowed but
penalized, different languages have different optimal
threshold values. For example, Chinese has an opti-
mal threshold of 0.7, whereas English has 0.2. Thus,
the optimal thresholds for different languages need
to be selected with care when Soft-tag is applied
in practice.
Soft-align eliminates the need for careful
tuning of word alignment thresholds, and therefore
can be more easily used in practice. Experimen-
tal results of Soft-align confirms our hypothe-
sis – the performance of both Chinese and English
NER systems improves with decreasing threshold.
However, we can still improve efficiency by set-
ting a low threshold to prune away very unlikely
word alignments. We set the threshold to 0.1 for
Soft-align to increase speed, and we observed
very minimal performance lost when doing so.
We also found that automatically estimated bilin-
gual tag PMI scores (Auto) gave comparable results
</bodyText>
<footnote confidence="0.8681305">
8github.com/percyliang/brown-cluster
9nlp.stanford.edu/software/segmenter.shtml
</footnote>
<page confidence="0.992744">
57
</page>
<figure confidence="0.999118409090909">
performance (F1)
performance (F1)
80
60
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
threshold of word alignment probability
75
70
65
Hard
Soft-label (Oracle)
Soft-label (Auto)
Soft-align (Oracle)
Soft-align (Auto)
75
70
65
60
55
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
threshold of word alignment probability
(a) Chinese (b) English
</figure>
<figureCaption confidence="0.981457">
Figure 3: Performance curves of different bilingual constraints methods on development set.
</figureCaption>
<figure confidence="0.9633124">
Hard
Soft-label (Oracle)
Soft-label (Auto)
Soft-align (Oracle)
Soft-align (Auto)
</figure>
<bodyText confidence="0.962894">
to Oracle. Therefore this technique is effective
for computing the PMI scores, avoiding the need of
manually annotating named entity bilingual corpus.
</bodyText>
<sectionHeader confidence="0.997951" genericHeader="method">
6 Bilingual NER Results
</sectionHeader>
<bodyText confidence="0.999842047619048">
The main results on Chinese and English test sets
with the optimal word alignment threshold for each
method are shown in Table 2.
The CRF-based Chinese NER with and without
word clustering features are compared here. The
word clustering features significantly (p &lt; 0.01) im-
proved the performance of Chinese NER, 10 giving
us a strong Chinese NER baseline.11 The effective-
ness of word clustering for English NER has been
proved in previous work.
The performance of ILP with only monolingual
constraints is quite comparable with the CRF re-
sults, especially on English. The greater ILP perfor-
mance on English is probably due to more accurate
marginal probabilities estimated by the English CRF
model.
The ILP model with hard bilingual constraints
gives a slight performance improvement on Chi-
nese, but affects performance negatively on English.
Once we introduced tagging uncertainties into the
Soft-tag bilingual constraints, we see a very sig-
</bodyText>
<footnote confidence="0.8366844">
10We use paired bootstrap resampling significance test (Efron
and Tibshirani, 1993).
11To the best of our knowledge, there was no performance
report of state-of-the-art NER results on the latest OntoNotes
dataset.
</footnote>
<bodyText confidence="0.995461607142857">
nificant (p &lt; 0.01) performance boost on Chinese.
This method also improves the recall on English,
with a smaller decrease in precision. Overall, it im-
proves English Fi score by about 0.4%, which is un-
fortunately not statistically significant.
Compared with Soft-tag, the final
Soft-align method can further improve
performance on both Chinese and English. This is
likely to be because: 1) Soft-align includes
more word alignment pairs, thereby improving
recall; and 2) uses probabilities to cut wrong
word alignments, thereby improving precision. In
particular, compared with the strong CRF baseline,
the gain on Chinese side is almost 5.5% in absolute
Fl score.
Decoding/inferenc efficiency of different methods
are shown in the last column of Table 2.12 Com-
pared with Viterbi decoding in CRF, monolingual
ILP decoding is about 2.3 times slower. Bilingual
ILP decoding, with either hard or soft constraints, is
significantly slower than the monolingual methods.
The reason is that the number of monolingual ILP
constraints doubles, and there are additionally many
more bilingual constraints. The difference in speed
between the Soft-tag and Soft-align meth-
ods is attributed to the difference in number of word
alignment pairs.
Since each sentence pair can be decoded indepen-
</bodyText>
<footnote confidence="0.610992">
12CPU: Intel Xeon E5-2660 2.20GHz. And the speed cal-
culation of ILP inference methods exclude the time needed to
obtain marginal probabilities from the CRF models.
</footnote>
<page confidence="0.993663">
58
</page>
<table confidence="0.999197125">
Chinese English Speed
P R F1 P R F1 #sent/s
CRF (No Cluster) 74.74 56.17 64.13 – – – –
CRF (Word Cluster) 76.90 63.32 69.45 82.95 76.67 79.68 317.3
Monolingual ILP 76.20 63.06 69.01 82.88 76.68 79.66 138.0
Hard 74.38 65.78 69.82 82.66 75.36 78.84 21.1
Soft-tag (Auto) 77.37 71.14 74.13 81.36 78.74 80.03 5.9
Soft-align(Auto) 77.71 72.51 75.02 81.94 78.35 80.10 1.5
</table>
<tableCaption confidence="0.999866">
Table 2: Results on bilingual parallel test set.
</tableCaption>
<bodyText confidence="0.9387055">
dently, parallelization the decoding process can re-
sult in significant speedup.
</bodyText>
<sectionHeader confidence="0.988514" genericHeader="method">
7 Semi-supervised NER Results
</sectionHeader>
<bodyText confidence="0.9999609375">
The above results show the usefulness of our method
in a bilingual setting, where we are presented with
sentence aligned data, and are tagging both lan-
guages at the same time. To have a greater impact
on general monolingual NER systems, we employ
a semi-supervised learning setting. First, we tag a
large amount of unannotated bitext with our bilin-
gual constraint-based NER tagger. Then we mix the
automatically tagged results with the original mono-
lingual Chinese training data to train a new model.
Our bitext is derived from the Chinese-English
part of the Foreign Broadcast Information Service
corpus (FBIS, LDC2003E14). The best perform-
ing bilingual model Soft-align with threshold
0 = 0.1 was used under the same experimental set-
ting as described in Section 4
</bodyText>
<table confidence="0.999599166666667">
Method #sent P R F1
CRF -16k 76.90 63.32 69.45
10k 77.60 66.51 71.62
Semi 20k 77.28 67.26 71.92
40k 77.40 67.81 72.29
80k 77.44 68.64 72.77
</table>
<tableCaption confidence="0.999705">
Table 3: Semi-supervised results on Chinese test set.
</tableCaption>
<bodyText confidence="0.993283444444445">
Table 3 shows that the performance of the semi-
supervised method improves with more additional
data. We simply appended these data to the orig-
inal training data. We also have done the experi-
ments to down weight the additional training data
by duplicating the original training data. There
was some slight improvements, but not very signif-
icant. Finally, when we add 80k sentences, the F1
score is improved by 3.32%, which is significantly
(p &lt; 0.01) better than the baseline, and most of the
contribution comes from recall improvement.
Before the end of experimental section, let us
summarize the usage of different kinds of data re-
sources used in our experiments, as shown in Ta-
ble 4, where ✓ and x denote whether the corre-
sponding resources are required. In the bilingual
case, during training, only the monolingual named
entity annotated data (NE-mono) is necessary to
train a monolingual NER tagger. During the test,
unannotated bitext (Bitext) is required by the word
aligner and our bilingual NER tagger. Named entity
annotated bitext (NE-bitext) is used to evaluate our
bilingual model. In the semi-supervised case, be-
sides the original NE-mono data, the Bitext is used
as input to our bilingual NER tagger to product ad-
ditional training data. To evaluate the final NER
model, only NE-mono is needed.
</bodyText>
<table confidence="0.9985868">
NE-mono Bitext NE-bitext
Bilingual train &apos;/ x x
test x ,/ ,/
Semi train ./ ./ x
test ,/ x x
</table>
<tableCaption confidence="0.999798">
Table 4: Summarization of the data resource usage
</tableCaption>
<sectionHeader confidence="0.999087" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999953125">
Previous work explored the use of bilingual corpora
to improve existing monolingual analyzers. Huang
et al. (2009) proposed methods to improve parsing
performance using bilingual parallel corpus. Li et
al. (2012) jointly labeled bilingual named entities
with a cyclic CRF model, where approximate in-
ference was done using loopy belief propagation.
These methods require manually annotated bilingual
</bodyText>
<page confidence="0.997371">
59
</page>
<bodyText confidence="0.999958708333334">
corpora, which are expensive to construct, and hard
to obtain. Kim et al. (2012) proposed a method of
labeling bilingual corpora with named entity labels
automatically based on Wikipedia. However, this
method is restricted to topics covered by Wikipedia.
Similar to our work, Burkett et al. (2010) also as-
sumed that annotated bilingual corpora are scarce.
Beyond the difference discussed in Section 1, their
re-ranking strategy may lose the correct named en-
tity results if they are not included in the top-N out-
puts. Furthermore, we consider the word alignment
probabilities in our method which can reduce the in-
fluence of word alignment errors. Finally, we test
our method on a large standard publicly available
corpus (8,249 sentences), while they used a much
smaller (200 sentences) manually annotated bilin-
gual NER corpus for results validation.
In addition to bilingual corpora, bilingual dictio-
naries are also useful resources. Huang and Vo-
gel (2002) and Chen et al. (2010) proposed ap-
proaches for extracting bilingual named entity pairs
from unannotated bitext, in which verification is
based on bilingual named entity dictionaries. How-
ever, large-scale bilingual named entity dictionaries
are difficult to obtain for most language pairs.
Yarowsky and Ngai (2001) proposed a projection
method that transforms high-quality analysis results
of one language, such as English, into other lan-
guages on the basis of word alignment. Das and
Petrov (2011) applied the above idea to part-of-
speech tagging with a more complex model. Fu et al.
(2011) projected English named entities onto Chi-
nese by carefully designed heuristic rules. Although
this type of method does not require manually an-
notated bilingual corpora or dictionaries, errors in
source language results, wrong word alignments and
inconsistencies between the languages limit applica-
tion of this method.
Constraint-based monolingual methods by using
ILP have been successfully applied to many natural
language processing tasks, such as Semantic Role
Labeling (Punyakanok et al., 2004), Dependency
Parsing (Martins et al., 2009) and Textual Entail-
ment (Berant et al., 2011). Zhuang and Zong (2010)
proposed a joint inference method for bilingual se-
mantic role labeling with ILP. However, their ap-
proach requires training an alignment model with a
manually annotated corpus.
</bodyText>
<sectionHeader confidence="0.997134" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999980391304348">
We proposed a novel ILP based inference algorithm
with bilingual constraints for NER. This method
can jointly infer bilingual named entities without
using any annotated bilingual corpus. We in-
vestigate various bilingual constraints: hard and
soft constraints. Out empirical study on large-
scale OntoNotes Chinese-English parallel NER data
showed that Soft-align method, which allows
inconsistent named entity tags between two aligned
words and considers word alignment probabilities,
can significantly improve over the performance of
a strong Chinese NER baseline. Our work is the
first to evaluate performance on a large-scale stan-
dard dataset. Finally, we can also improve mono-
lingual Chinese NER performance significantly, by
combining the original monolingual training data
with new data obtained from bitext tagged by our
method. The final ILP-based bilingual NER tag-
ger with soft constraints is publicly available at:
github.com/carfly/bi_ilp
Future work could apply the bilingual constraint-
based method to other tasks, such as part-of-speech
tagging and relation extraction.
</bodyText>
<sectionHeader confidence="0.99863" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999810888888889">
The authors would like to thank Rob Voigt and the
three anonymous reviewers for their valuable com-
ments and suggestions. We gratefully acknowledge
the support of the National Natural Science Foun-
dation of China (NSFC) via grant 61133012, the
National “863” Project via grant 2011AA01A207
and 2012AA011102, the Ministry of Education Re-
search of Social Sciences Youth funded projects
via grant 12YJCZH304, the Defense Advanced Re-
search Projects Agency (DARPA) Machine Read-
ing Program under Air Force Research Laboratory
(AFRL) prime contract no. FA8750-09-C-0181 and
the support of the DARPA Broad Operational Lan-
guage Translation (BOLT) program through IBM.
Any opinions, findings, and conclusion or recom-
mendations expressed in this material are those of
the authors and do not necessarily reflect the view of
the DARPA, AFRL, or the US government.
</bodyText>
<page confidence="0.997831">
60
</page>
<sectionHeader confidence="0.996334" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999881314285715">
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2011. Global learning of typed entailment rules. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 610–619, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vin-
cent J. Della Pietra, and Jenifer C. Lai. 1992. Class-
based n-gram models of natural language. Comput.
Linguist., 18(4):467–479, December.
David Burkett, Slav Petrov, John Blitzer, and Dan Klein.
2010. Learning better monolingual models with unan-
notated bilingual text. In Proceedings of the Four-
teenth Conference on Computational Natural Lan-
guage Learning, pages 46–54, Uppsala, Sweden, July.
Association for Computational Linguistics.
Yufeng Chen, Chengqing Zong, and Keh-Yih Su. 2010.
On jointly recognizing and aligning bilingual named
entities. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
pages 631–639, Uppsala, Sweden, July. Association
for Computational Linguistics.
Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based pro-
jections. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, pages 600–609, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
B. Efron and R. J. Tibshirani. 1993. An Introduction to
the Bootstrap. Chapman &amp; Hall, New York.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local information
into information extraction systems by gibbs sampling.
In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL’05),
pages 363–370, Ann Arbor, Michigan, June. Associa-
tion for Computational Linguistics.
Ruiji Fu, Bing Qin, and Ting Liu. 2011. Generating
chinese named entity data from a parallel corpus. In
Proceedings of 5th International Joint Conference on
Natural Language Processing, pages 264–272, Chiang
Mai, Thailand, November. Asian Federation of Natural
Language Processing.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. Ontonotes:
the 90% solution. In Proceedings of the Human Lan-
guage Technology Conference of the NAACL, Com-
panion Volume: Short Papers, NAACL-Short ’06,
pages 57–60, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Fei Huang and Stephan Vogel. 2002. Improved named
entity translation and bilingual named entity extrac-
tion. In Proceedings of the 4th IEEE International
Conference on Multimodal Interfaces, ICMI 2002,
Washington, DC, USA. IEEE Computer Society.
Liang Huang, Wenbin Jiang, and Qun Liu. 2009.
Bilingually-constrained (monolingual) shift-reduce
parsing. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing,
pages 1222–1231, Singapore, August. Association for
Computational Linguistics.
Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.
2012. Multilingual named entity recognition using
parallel data and metadata from wikipedia. In Pro-
ceedings of the 50th Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 694–702, Jeju Island, Korea, July. As-
sociation for Computational Linguistics.
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
Simple semi-supervised dependency parsing. In Pro-
ceedings of ACL-08: HLT, pages 595–603, Columbus,
Ohio, June. Association for Computational Linguis-
tics.
Shankar Kumar. 2005. Minimum bayes-risk techniques
in automatic speech recognition and statistical ma-
chine translation. Ph.D. thesis, Baltimore, MD, USA.
AAI3155633.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Proba-
bilistic models for segmenting and labeling sequence
data. In Proceedings of the Eighteenth International
Conference on Machine Learning, ICML ’01, pages
282–289, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Qi Li, Haibo Li, Heng Ji, Wen Wang, Jing Zheng, and Fei
Huang. 2012. Joint bilingual name tagging for paral-
lel corpora. In Proceedings of the 21st ACM Inter-
national Conference on Information and Knowledge
Management (CIKM 2012), Honolulu, Hawaii, Octo-
ber.
Percy Liang. 2005. Semi-supervised learning for natural
language. Master’s thesis, MIT.
Andre Martins, Noah Smith, and Eric Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proceedings of the Joint Con-
ference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 342–350, Sun-
tec, Singapore, August. Association for Computational
Linguistics.
Bernard M´erialdo. 1994. Tagging english text with a
probabilistic model. Comput. Linguist., 20(2):155–
171.
</reference>
<page confidence="0.983277">
61
</page>
<reference confidence="0.999387540540541">
Scott Miller, Jethran Guinness, and Alex Zamanian.
2004. Name tagging with word clusters and dis-
criminative training. In Daniel Marcu Susan Dumais
and Salim Roukos, editors, HLT-NAACL 2004: Main
Proceedings, pages 337–342, Boston, Massachusetts,
USA, May 2 - May 7. Association for Computational
Linguistics.
Slav Petrov, Pi-Chuan Chang, Michael Ringgaard, and
Hiyan Alshawi. 2010. Uptraining for accurate deter-
ministic question parsing. In Proceedings of the 2010
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 705–713, Cambridge, MA,
October. Association for Computational Linguistics.
Vasin Punyakanok, Dan Roth, Wen-tau Yih, and Dav Zi-
mak. 2004. Semantic role labeling via integer lin-
ear programming inference. In Proceedings of Coling
2004, pages 1346–1352, Geneva, Switzerland, Aug
23–Aug 27. COLING.
Dan Roth and Wen-tau Yih. 2005. Integer linear pro-
gramming inference for conditional random fields. In
Proceedings of the 22nd international conference on
Machine learning, ICML ’05, pages 736–743, New
York, NY, USA. ACM.
David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual POS taggers and NP bracketers via robust
projection across aligned corpora. In Proceedings of
the second meeting of the North American Chapter of
the Association for Computational Linguistics on Lan-
guage technologies, NAACL ’01, pages 1–8, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Tao Zhuang and Chengqing Zong. 2010. Joint inference
for bilingual semantic role labeling. In Proceedings of
the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 304–314, Cambridge,
MA, October. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.999182">
62
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341839">
<title confidence="0.99555">Named Entity Recognition with Bilingual Constraints</title>
<author confidence="0.541848">D</author>
<affiliation confidence="0.9998975">School of Computer Science and Technology Computer Science Department Harbin Institute of Technology Stanford University</affiliation>
<address confidence="0.999867">Harbin, China, 150001 Stanford, CA, 94305</address>
<abstract confidence="0.982060238095238">Different languages contain complementary cues about entities, which can be used to improve Named Entity Recognition (NER) systems. We propose a method that formulates the problem of exploring such signals on unannotated bilingual text as a simple Integer Linear Program, which encourages entity tags to agree via bilingual constraints. Bilingual NER experiments on the large OntoNotes 4.0 Chinese-English corpus show that the proposed method can improve strong baselines for both Chinese and English. In particular, Chinese performance improves by over 5% We can then annotate a large amount of bilingual text (80k sentence pairs) using our method, and add it as uptraining data to the original monolingual NER training corpus. The Chinese model retrained on this new combined dataset outperforms the baseline by over 3%</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global learning of typed entailment rules.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>610--619</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="30151" citStr="Berant et al., 2011" startWordPosition="5060" endWordPosition="5063">e complex model. Fu et al. (2011) projected English named entities onto Chinese by carefully designed heuristic rules. Although this type of method does not require manually annotated bilingual corpora or dictionaries, errors in source language results, wrong word alignments and inconsistencies between the languages limit application of this method. Constraint-based monolingual methods by using ILP have been successfully applied to many natural language processing tasks, such as Semantic Role Labeling (Punyakanok et al., 2004), Dependency Parsing (Martins et al., 2009) and Textual Entailment (Berant et al., 2011). Zhuang and Zong (2010) proposed a joint inference method for bilingual semantic role labeling with ILP. However, their approach requires training an alignment model with a manually annotated corpus. 9 Conclusions We proposed a novel ILP based inference algorithm with bilingual constraints for NER. This method can jointly infer bilingual named entities without using any annotated bilingual corpus. We investigate various bilingual constraints: hard and soft constraints. Out empirical study on largescale OntoNotes Chinese-English parallel NER data showed that Soft-align method, which allows inc</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2011</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2011. Global learning of typed entailment rules. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 610–619, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V deSouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Classbased n-gram models of natural language.</title>
<date>1992</date>
<journal>Comput. Linguist.,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="19493" citStr="Brown et al., 1992" startWordPosition="3378" endWordPosition="3381"> for both Chinese and English. Word clustering features have been successfully used in several English tasks, including 4champollion.sourceforge.net 5code.google.com/p/berkeleyaligner 6nlp.stanford.edu/software/CRF-NER.shtml, which has included our English and Chinese NER implementations. 7The radical of a Chinese character can be found at: www. unicode.org/charts/unihan.html NER (Miller et al., 2004) and dependency parsing (Koo et al., 2008). To our knowledge, this work is the first use of word clustering features for Chinese NER. A C++ implementation of the Brown word clustering algorithms (Brown et al., 1992) was used to obtain the word clusters (Liang, 2005).8 Raw text was obtained from the fifth edition of Chinese Gigaword (LDC2011T13). One million paragraphs from Xinhua news section were randomly selected, and the Stanford Word Segmenter with LDC standard was applied to segment Chinese text into words.9 About 46 million words were obtained which were clustered into 1,000 word classes. 5 Threshold Tuning During development, we tuned the word alignment probability thresholds to find the best value. Figure 3 shows the performance curves. When the word alignment probability threshold 0 is set to 0.</context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Classbased n-gram models of natural language. Comput. Linguist., 18(4):467–479, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Slav Petrov</author>
<author>John Blitzer</author>
<author>Dan Klein</author>
</authors>
<title>Learning better monolingual models with unannotated bilingual text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>46--54</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="2751" citStr="Burkett et al. (2010)" startWordPosition="426" endWordPosition="429">ual cues can help to recognize errors a monolingual tagger would make, allowing us to produce more accurately tagged bitext. Each side of the tagged bitext can then be used to expand the original monolingual training dataset, which may lead to higher accuracy in the monolingual taggers. Previous work such as Li et al. (2012) and Kim et al. (2012) demonstrated that bilingual corpus annotated with NER labels can be used to improve monolingual tagger performance. But a major drawback of their approaches are the need for manual annotation efforts to create such corpora. To avoid this requirement, Burkett et al. (2010) suggested a “multi-view” learning scheme based on re-ranking. Noisy output of a “strong” tagger is used as training data to learn parameters of a log-linear re-ranking model with additional bilingual features, simulated by a “weak” tagger. The learned parameters are then reused with the “strong” tagger to re-rank its own outputs for unseen inputs. Designing good “weak” taggers so that they complement the “view” of bilingual features in the log-linear re-ranker is crucial to the success of this algorithm. Unfortunately there is no principled way of designing such “weak” taggers. In this paper,</context>
<context position="28315" citStr="Burkett et al. (2010)" startWordPosition="4778" endWordPosition="4781">ngual analyzers. Huang et al. (2009) proposed methods to improve parsing performance using bilingual parallel corpus. Li et al. (2012) jointly labeled bilingual named entities with a cyclic CRF model, where approximate inference was done using loopy belief propagation. These methods require manually annotated bilingual 59 corpora, which are expensive to construct, and hard to obtain. Kim et al. (2012) proposed a method of labeling bilingual corpora with named entity labels automatically based on Wikipedia. However, this method is restricted to topics covered by Wikipedia. Similar to our work, Burkett et al. (2010) also assumed that annotated bilingual corpora are scarce. Beyond the difference discussed in Section 1, their re-ranking strategy may lose the correct named entity results if they are not included in the top-N outputs. Furthermore, we consider the word alignment probabilities in our method which can reduce the influence of word alignment errors. Finally, we test our method on a large standard publicly available corpus (8,249 sentences), while they used a much smaller (200 sentences) manually annotated bilingual NER corpus for results validation. In addition to bilingual corpora, bilingual dic</context>
</contexts>
<marker>Burkett, Petrov, Blitzer, Klein, 2010</marker>
<rawString>David Burkett, Slav Petrov, John Blitzer, and Dan Klein. 2010. Learning better monolingual models with unannotated bilingual text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 46–54, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yufeng Chen</author>
<author>Chengqing Zong</author>
<author>Keh-Yih Su</author>
</authors>
<title>On jointly recognizing and aligning bilingual named entities.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>631--639</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="28997" citStr="Chen et al. (2010)" startWordPosition="4888" endWordPosition="4891">d the difference discussed in Section 1, their re-ranking strategy may lose the correct named entity results if they are not included in the top-N outputs. Furthermore, we consider the word alignment probabilities in our method which can reduce the influence of word alignment errors. Finally, we test our method on a large standard publicly available corpus (8,249 sentences), while they used a much smaller (200 sentences) manually annotated bilingual NER corpus for results validation. In addition to bilingual corpora, bilingual dictionaries are also useful resources. Huang and Vogel (2002) and Chen et al. (2010) proposed approaches for extracting bilingual named entity pairs from unannotated bitext, in which verification is based on bilingual named entity dictionaries. However, large-scale bilingual named entity dictionaries are difficult to obtain for most language pairs. Yarowsky and Ngai (2001) proposed a projection method that transforms high-quality analysis results of one language, such as English, into other languages on the basis of word alignment. Das and Petrov (2011) applied the above idea to part-ofspeech tagging with a more complex model. Fu et al. (2011) projected English named entities</context>
</contexts>
<marker>Chen, Zong, Su, 2010</marker>
<rawString>Yufeng Chen, Chengqing Zong, and Keh-Yih Su. 2010. On jointly recognizing and aligning bilingual named entities. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 631–639, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>600--609</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="29472" citStr="Das and Petrov (2011)" startWordPosition="4958" endWordPosition="4961">ults validation. In addition to bilingual corpora, bilingual dictionaries are also useful resources. Huang and Vogel (2002) and Chen et al. (2010) proposed approaches for extracting bilingual named entity pairs from unannotated bitext, in which verification is based on bilingual named entity dictionaries. However, large-scale bilingual named entity dictionaries are difficult to obtain for most language pairs. Yarowsky and Ngai (2001) proposed a projection method that transforms high-quality analysis results of one language, such as English, into other languages on the basis of word alignment. Das and Petrov (2011) applied the above idea to part-ofspeech tagging with a more complex model. Fu et al. (2011) projected English named entities onto Chinese by carefully designed heuristic rules. Although this type of method does not require manually annotated bilingual corpora or dictionaries, errors in source language results, wrong word alignments and inconsistencies between the languages limit application of this method. Constraint-based monolingual methods by using ILP have been successfully applied to many natural language processing tasks, such as Semantic Role Labeling (Punyakanok et al., 2004), Depende</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 600–609, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Efron</author>
<author>R J Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap.</title>
<date>1993</date>
<publisher>Chapman &amp; Hall,</publisher>
<location>New York.</location>
<contexts>
<context position="23094" citStr="Efron and Tibshirani, 1993" startWordPosition="3933" endWordPosition="3936">r English NER has been proved in previous work. The performance of ILP with only monolingual constraints is quite comparable with the CRF results, especially on English. The greater ILP performance on English is probably due to more accurate marginal probabilities estimated by the English CRF model. The ILP model with hard bilingual constraints gives a slight performance improvement on Chinese, but affects performance negatively on English. Once we introduced tagging uncertainties into the Soft-tag bilingual constraints, we see a very sig10We use paired bootstrap resampling significance test (Efron and Tibshirani, 1993). 11To the best of our knowledge, there was no performance report of state-of-the-art NER results on the latest OntoNotes dataset. nificant (p &lt; 0.01) performance boost on Chinese. This method also improves the recall on English, with a smaller decrease in precision. Overall, it improves English Fi score by about 0.4%, which is unfortunately not statistically significant. Compared with Soft-tag, the final Soft-align method can further improve performance on both Chinese and English. This is likely to be because: 1) Soft-align includes more word alignment pairs, thereby improving recall; and 2)</context>
</contexts>
<marker>Efron, Tibshirani, 1993</marker>
<rawString>B. Efron and R. J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman &amp; Hall, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>363--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="18363" citStr="Finkel et al. (2005)" startWordPosition="3206" endWordPosition="3209">Geo-Political Entities), and discarded the others. Since the bilingual corpus is only aligned at the document level, we performed sentence alignment using the Champollion Tool Kit (CTK).4 After removing sentences with no aligned sentence, a total of 8,249 sentence pairs were retained. We used the BerkeleyAligner,5 to produce word alignments over the sentence-aligned datasets. BerkeleyAligner also gives posterior probabilities Pa for each aligned word pair. We used the CRF-based Stanford NER tagger (using Viterbi decoding) as our baseline monolingual NER tool.6 English features were taken from Finkel et al. (2005). Table 1 lists the basic features of Chinese NER, where ◦ means string concatenation and yi is the named entity tag of the ith word wi. Moreover, shape(wi) is the shape of wi, such as date and number. prefix/suffix(wi, k) denotes the k-characters prefix/suffix of wi. radical(wi, k) denotes the radical of the kth Chinese character of wi.7 len(wi) is the number of Chinese characters in wi. To make the baseline CRF taggers stronger, we added word clustering features to improve generalization over unseen data for both Chinese and English. Word clustering features have been successfully used in se</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 363–370, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruiji Fu</author>
<author>Bing Qin</author>
<author>Ting Liu</author>
</authors>
<title>Generating chinese named entity data from a parallel corpus.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>264--272</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="29564" citStr="Fu et al. (2011)" startWordPosition="4975" endWordPosition="4978">es. Huang and Vogel (2002) and Chen et al. (2010) proposed approaches for extracting bilingual named entity pairs from unannotated bitext, in which verification is based on bilingual named entity dictionaries. However, large-scale bilingual named entity dictionaries are difficult to obtain for most language pairs. Yarowsky and Ngai (2001) proposed a projection method that transforms high-quality analysis results of one language, such as English, into other languages on the basis of word alignment. Das and Petrov (2011) applied the above idea to part-ofspeech tagging with a more complex model. Fu et al. (2011) projected English named entities onto Chinese by carefully designed heuristic rules. Although this type of method does not require manually annotated bilingual corpora or dictionaries, errors in source language results, wrong word alignments and inconsistencies between the languages limit application of this method. Constraint-based monolingual methods by using ILP have been successfully applied to many natural language processing tasks, such as Semantic Role Labeling (Punyakanok et al., 2004), Dependency Parsing (Martins et al., 2009) and Textual Entailment (Berant et al., 2011). Zhuang and </context>
</contexts>
<marker>Fu, Qin, Liu, 2011</marker>
<rawString>Ruiji Fu, Bing Qin, and Ting Liu. 2011. Generating chinese named entity data from a parallel corpus. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 264–272, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>Ontonotes: the 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, NAACL-Short ’06,</booktitle>
<pages>57--60</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="16515" citStr="Hovy et al., 2006" startWordPosition="2893" endWordPosition="2896"> a E A iff Pa &gt; θ. This condition can be regarded as a kind of hard word alignment. However, the following problem exists: the smaller the θ, the noisier the We name the set of constraints above Soft-align, which has the same constraints as Soft-tag, i.e., Eqs. (8), (9), (15) and (16). 4 Experimental Setup We conduct experiments on the latest OntoNotes 4.0 corpus (LDC2011T03). OntoNotes is a large, manually annotated corpus that contains various text genres and annotations, such as part-of-speech tags, named entity labels, syntactic parse trees, predicateargument structures and co-references (Hovy et al., 2006). Aside from English, this corpus also contains several Chinese and Arabic corpora. Some of these corpora contain bilingual parallel documents. We used the Chinese-English parallel corpus with named entity labels as our development and test data. This corpus includes about 400 document pairs (chtb 0001-0325, ectb 1001-1078). We used oddnumbered documents as development data and evennumbered documents as test data. We used all other portions of the named entity annotated corpus as training data for the monolingual systems. There were a total of —660 Chinese documents (—16k sentences) and —1,400</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. Ontonotes: the 90% solution. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, NAACL-Short ’06, pages 57–60, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Stephan Vogel</author>
</authors>
<title>Improved named entity translation and bilingual named entity extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 4th IEEE International Conference on Multimodal Interfaces, ICMI 2002,</booktitle>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="28974" citStr="Huang and Vogel (2002)" startWordPosition="4882" endWordPosition="4886">l corpora are scarce. Beyond the difference discussed in Section 1, their re-ranking strategy may lose the correct named entity results if they are not included in the top-N outputs. Furthermore, we consider the word alignment probabilities in our method which can reduce the influence of word alignment errors. Finally, we test our method on a large standard publicly available corpus (8,249 sentences), while they used a much smaller (200 sentences) manually annotated bilingual NER corpus for results validation. In addition to bilingual corpora, bilingual dictionaries are also useful resources. Huang and Vogel (2002) and Chen et al. (2010) proposed approaches for extracting bilingual named entity pairs from unannotated bitext, in which verification is based on bilingual named entity dictionaries. However, large-scale bilingual named entity dictionaries are difficult to obtain for most language pairs. Yarowsky and Ngai (2001) proposed a projection method that transforms high-quality analysis results of one language, such as English, into other languages on the basis of word alignment. Das and Petrov (2011) applied the above idea to part-ofspeech tagging with a more complex model. Fu et al. (2011) projected</context>
</contexts>
<marker>Huang, Vogel, 2002</marker>
<rawString>Fei Huang and Stephan Vogel. 2002. Improved named entity translation and bilingual named entity extraction. In Proceedings of the 4th IEEE International Conference on Multimodal Interfaces, ICMI 2002, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Wenbin Jiang</author>
<author>Qun Liu</author>
</authors>
<title>Bilingually-constrained (monolingual) shift-reduce parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1222--1231</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27730" citStr="Huang et al. (2009)" startWordPosition="4690" endWordPosition="4693"> by the word aligner and our bilingual NER tagger. Named entity annotated bitext (NE-bitext) is used to evaluate our bilingual model. In the semi-supervised case, besides the original NE-mono data, the Bitext is used as input to our bilingual NER tagger to product additional training data. To evaluate the final NER model, only NE-mono is needed. NE-mono Bitext NE-bitext Bilingual train &apos;/ x x test x ,/ ,/ Semi train ./ ./ x test ,/ x x Table 4: Summarization of the data resource usage 8 Related Work Previous work explored the use of bilingual corpora to improve existing monolingual analyzers. Huang et al. (2009) proposed methods to improve parsing performance using bilingual parallel corpus. Li et al. (2012) jointly labeled bilingual named entities with a cyclic CRF model, where approximate inference was done using loopy belief propagation. These methods require manually annotated bilingual 59 corpora, which are expensive to construct, and hard to obtain. Kim et al. (2012) proposed a method of labeling bilingual corpora with named entity labels automatically based on Wikipedia. However, this method is restricted to topics covered by Wikipedia. Similar to our work, Burkett et al. (2010) also assumed t</context>
</contexts>
<marker>Huang, Jiang, Liu, 2009</marker>
<rawString>Liang Huang, Wenbin Jiang, and Qun Liu. 2009. Bilingually-constrained (monolingual) shift-reduce parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1222–1231, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungchul Kim</author>
<author>Kristina Toutanova</author>
<author>Hwanjo Yu</author>
</authors>
<title>Multilingual named entity recognition using parallel data and metadata from wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>694--702</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="2478" citStr="Kim et al. (2012)" startWordPosition="382" endWordPosition="385">ut entities. For example, in Figure 1, the word “本 (Ben)” is common in Chinese but rarely appears as a translated foreign name. However, its aligned word on the English side (“Ben”) provides a strong clue that this is a person name. Judicious use of this type of bilingual cues can help to recognize errors a monolingual tagger would make, allowing us to produce more accurately tagged bitext. Each side of the tagged bitext can then be used to expand the original monolingual training dataset, which may lead to higher accuracy in the monolingual taggers. Previous work such as Li et al. (2012) and Kim et al. (2012) demonstrated that bilingual corpus annotated with NER labels can be used to improve monolingual tagger performance. But a major drawback of their approaches are the need for manual annotation efforts to create such corpora. To avoid this requirement, Burkett et al. (2010) suggested a “multi-view” learning scheme based on re-ranking. Noisy output of a “strong” tagger is used as training data to learn parameters of a log-linear re-ranking model with additional bilingual features, simulated by a “weak” tagger. The learned parameters are then reused with the “strong” tagger to re-rank its own out</context>
<context position="28098" citStr="Kim et al. (2012)" startWordPosition="4745" endWordPosition="4748">xt Bilingual train &apos;/ x x test x ,/ ,/ Semi train ./ ./ x test ,/ x x Table 4: Summarization of the data resource usage 8 Related Work Previous work explored the use of bilingual corpora to improve existing monolingual analyzers. Huang et al. (2009) proposed methods to improve parsing performance using bilingual parallel corpus. Li et al. (2012) jointly labeled bilingual named entities with a cyclic CRF model, where approximate inference was done using loopy belief propagation. These methods require manually annotated bilingual 59 corpora, which are expensive to construct, and hard to obtain. Kim et al. (2012) proposed a method of labeling bilingual corpora with named entity labels automatically based on Wikipedia. However, this method is restricted to topics covered by Wikipedia. Similar to our work, Burkett et al. (2010) also assumed that annotated bilingual corpora are scarce. Beyond the difference discussed in Section 1, their re-ranking strategy may lose the correct named entity results if they are not included in the top-N outputs. Furthermore, we consider the word alignment probabilities in our method which can reduce the influence of word alignment errors. Finally, we test our method on a l</context>
</contexts>
<marker>Kim, Toutanova, Yu, 2012</marker>
<rawString>Sungchul Kim, Kristina Toutanova, and Hwanjo Yu. 2012. Multilingual named entity recognition using parallel data and metadata from wikipedia. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 694–702, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>595--603</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="19320" citStr="Koo et al., 2008" startWordPosition="3348" endWordPosition="3351"> len(wi) is the number of Chinese characters in wi. To make the baseline CRF taggers stronger, we added word clustering features to improve generalization over unseen data for both Chinese and English. Word clustering features have been successfully used in several English tasks, including 4champollion.sourceforge.net 5code.google.com/p/berkeleyaligner 6nlp.stanford.edu/software/CRF-NER.shtml, which has included our English and Chinese NER implementations. 7The radical of a Chinese character can be found at: www. unicode.org/charts/unihan.html NER (Miller et al., 2004) and dependency parsing (Koo et al., 2008). To our knowledge, this work is the first use of word clustering features for Chinese NER. A C++ implementation of the Brown word clustering algorithms (Brown et al., 1992) was used to obtain the word clusters (Liang, 2005).8 Raw text was obtained from the fifth edition of Chinese Gigaword (LDC2011T13). One million paragraphs from Xinhua news section were randomly selected, and the Stanford Word Segmenter with LDC standard was applied to segment Chinese text into words.9 About 46 million words were obtained which were clustered into 1,000 word classes. 5 Threshold Tuning During development, w</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings of ACL-08: HLT, pages 595–603, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
</authors>
<title>Minimum bayes-risk techniques in automatic speech recognition and statistical machine translation.</title>
<date>2005</date>
<booktitle>Ph.D. thesis,</booktitle>
<location>Baltimore, MD, USA. AAI3155633.</location>
<marker>Kumar, 2005</marker>
<rawString>Shankar Kumar. 2005. Minimum bayes-risk techniques in automatic speech recognition and statistical machine translation. Ph.D. thesis, Baltimore, MD, USA. AAI3155633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="5209" citStr="Lafferty et al., 2001" startWordPosition="817" endWordPosition="820">e can improve the monolingual Chinese NER performance by over 3% F1 score. 2 Constraint-based Monolingual NER NER is a sequence labeling task where we assign a named entity tag to each word in an input sentence. One commonly used tagging scheme is the BIO scheme. The tag B-X (Begin) represents the first word of a named entity of type X, for example, PER (Person) or LOC (Location). The tag I-X (Inside) indicates that a word is part of an entity but not first word. The tag O (Outside) is used for all nonentity words.2 See Figure 1 for an example tagged sentence. Conditional Random Fields (CRF) (Lafferty et al., 2001) is a state-of-the-art sequence labeling model widely used in NER. A first-order linear-chain CRF 2While the performance of NER is measured at the entity level (not the tag level). defines the following conditional probability: 1 PCRF(y|x) = Z(x) �Mi(yi,yi−1|x) (1) i where x and y are the input and output sequences, respectively, Z(x) is the partition function, and Mi is the clique potential for edge clique i. Decoding in CRF involves finding the most likely output sequence that maximizes this objective, and is commonly done by the Viterbi algorithm. Roth and Yih (2005) proposed an ILP inferen</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01, pages 282–289, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Haibo Li</author>
<author>Heng Ji</author>
<author>Wen Wang</author>
<author>Jing Zheng</author>
<author>Fei Huang</author>
</authors>
<title>Joint bilingual name tagging for parallel corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st ACM International Conference on Information and Knowledge Management (CIKM 2012),</booktitle>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="2456" citStr="Li et al. (2012)" startWordPosition="377" endWordPosition="380">omplementary cues about entities. For example, in Figure 1, the word “本 (Ben)” is common in Chinese but rarely appears as a translated foreign name. However, its aligned word on the English side (“Ben”) provides a strong clue that this is a person name. Judicious use of this type of bilingual cues can help to recognize errors a monolingual tagger would make, allowing us to produce more accurately tagged bitext. Each side of the tagged bitext can then be used to expand the original monolingual training dataset, which may lead to higher accuracy in the monolingual taggers. Previous work such as Li et al. (2012) and Kim et al. (2012) demonstrated that bilingual corpus annotated with NER labels can be used to improve monolingual tagger performance. But a major drawback of their approaches are the need for manual annotation efforts to create such corpora. To avoid this requirement, Burkett et al. (2010) suggested a “multi-view” learning scheme based on re-ranking. Noisy output of a “strong” tagger is used as training data to learn parameters of a log-linear re-ranking model with additional bilingual features, simulated by a “weak” tagger. The learned parameters are then reused with the “strong” tagger </context>
<context position="27828" citStr="Li et al. (2012)" startWordPosition="4704" endWordPosition="4707">to evaluate our bilingual model. In the semi-supervised case, besides the original NE-mono data, the Bitext is used as input to our bilingual NER tagger to product additional training data. To evaluate the final NER model, only NE-mono is needed. NE-mono Bitext NE-bitext Bilingual train &apos;/ x x test x ,/ ,/ Semi train ./ ./ x test ,/ x x Table 4: Summarization of the data resource usage 8 Related Work Previous work explored the use of bilingual corpora to improve existing monolingual analyzers. Huang et al. (2009) proposed methods to improve parsing performance using bilingual parallel corpus. Li et al. (2012) jointly labeled bilingual named entities with a cyclic CRF model, where approximate inference was done using loopy belief propagation. These methods require manually annotated bilingual 59 corpora, which are expensive to construct, and hard to obtain. Kim et al. (2012) proposed a method of labeling bilingual corpora with named entity labels automatically based on Wikipedia. However, this method is restricted to topics covered by Wikipedia. Similar to our work, Burkett et al. (2010) also assumed that annotated bilingual corpora are scarce. Beyond the difference discussed in Section 1, their re</context>
</contexts>
<marker>Li, Li, Ji, Wang, Zheng, Huang, 2012</marker>
<rawString>Qi Li, Haibo Li, Heng Ji, Wen Wang, Jing Zheng, and Fei Huang. 2012. Joint bilingual name tagging for parallel corpora. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management (CIKM 2012), Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
</authors>
<title>Semi-supervised learning for natural language.</title>
<date>2005</date>
<tech>Master’s thesis, MIT.</tech>
<contexts>
<context position="19544" citStr="Liang, 2005" startWordPosition="3389" endWordPosition="3390">ve been successfully used in several English tasks, including 4champollion.sourceforge.net 5code.google.com/p/berkeleyaligner 6nlp.stanford.edu/software/CRF-NER.shtml, which has included our English and Chinese NER implementations. 7The radical of a Chinese character can be found at: www. unicode.org/charts/unihan.html NER (Miller et al., 2004) and dependency parsing (Koo et al., 2008). To our knowledge, this work is the first use of word clustering features for Chinese NER. A C++ implementation of the Brown word clustering algorithms (Brown et al., 1992) was used to obtain the word clusters (Liang, 2005).8 Raw text was obtained from the fifth edition of Chinese Gigaword (LDC2011T13). One million paragraphs from Xinhua news section were randomly selected, and the Stanford Word Segmenter with LDC standard was applied to segment Chinese text into words.9 About 46 million words were obtained which were clustered into 1,000 word classes. 5 Threshold Tuning During development, we tuned the word alignment probability thresholds to find the best value. Figure 3 shows the performance curves. When the word alignment probability threshold 0 is set to 0.9, the hard bilingual constraints perform well for </context>
</contexts>
<marker>Liang, 2005</marker>
<rawString>Percy Liang. 2005. Semi-supervised learning for natural language. Master’s thesis, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>342--350</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="30106" citStr="Martins et al., 2009" startWordPosition="5052" endWordPosition="5055">above idea to part-ofspeech tagging with a more complex model. Fu et al. (2011) projected English named entities onto Chinese by carefully designed heuristic rules. Although this type of method does not require manually annotated bilingual corpora or dictionaries, errors in source language results, wrong word alignments and inconsistencies between the languages limit application of this method. Constraint-based monolingual methods by using ILP have been successfully applied to many natural language processing tasks, such as Semantic Role Labeling (Punyakanok et al., 2004), Dependency Parsing (Martins et al., 2009) and Textual Entailment (Berant et al., 2011). Zhuang and Zong (2010) proposed a joint inference method for bilingual semantic role labeling with ILP. However, their approach requires training an alignment model with a manually annotated corpus. 9 Conclusions We proposed a novel ILP based inference algorithm with bilingual constraints for NER. This method can jointly infer bilingual named entities without using any annotated bilingual corpus. We investigate various bilingual constraints: hard and soft constraints. Out empirical study on largescale OntoNotes Chinese-English parallel NER data sh</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 342–350, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard M´erialdo</author>
</authors>
<title>Tagging english text with a probabilistic model.</title>
<date>1994</date>
<journal>Comput. Linguist.,</journal>
<volume>20</volume>
<issue>2</issue>
<pages>171</pages>
<marker>M´erialdo, 1994</marker>
<rawString>Bernard M´erialdo. 1994. Tagging english text with a probabilistic model. Comput. Linguist., 20(2):155– 171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Jethran Guinness</author>
<author>Alex Zamanian</author>
</authors>
<title>Name tagging with word clusters and discriminative training.</title>
<date>2004</date>
<booktitle>In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings,</booktitle>
<volume>2</volume>
<pages>337--342</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="19278" citStr="Miller et al., 2004" startWordPosition="3340" endWordPosition="3343"> radical of the kth Chinese character of wi.7 len(wi) is the number of Chinese characters in wi. To make the baseline CRF taggers stronger, we added word clustering features to improve generalization over unseen data for both Chinese and English. Word clustering features have been successfully used in several English tasks, including 4champollion.sourceforge.net 5code.google.com/p/berkeleyaligner 6nlp.stanford.edu/software/CRF-NER.shtml, which has included our English and Chinese NER implementations. 7The radical of a Chinese character can be found at: www. unicode.org/charts/unihan.html NER (Miller et al., 2004) and dependency parsing (Koo et al., 2008). To our knowledge, this work is the first use of word clustering features for Chinese NER. A C++ implementation of the Brown word clustering algorithms (Brown et al., 1992) was used to obtain the word clusters (Liang, 2005).8 Raw text was obtained from the fifth edition of Chinese Gigaword (LDC2011T13). One million paragraphs from Xinhua news section were randomly selected, and the Stanford Word Segmenter with LDC standard was applied to segment Chinese text into words.9 About 46 million words were obtained which were clustered into 1,000 word classes</context>
</contexts>
<marker>Miller, Guinness, Zamanian, 2004</marker>
<rawString>Scott Miller, Jethran Guinness, and Alex Zamanian. 2004. Name tagging with word clusters and discriminative training. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings, pages 337–342, Boston, Massachusetts, USA, May 2 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Pi-Chuan Chang</author>
<author>Michael Ringgaard</author>
<author>Hiyan Alshawi</author>
</authors>
<title>Uptraining for accurate deterministic question parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>705--713</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="4584" citStr="Petrov et al., 2010" startWordPosition="702" endWordPosition="705">em as an Integer Linear Program (ILP) and solves it during decoding. We propose a set of intuitive and effective bilingual constraints that encourage NER results to agree across the two languages. Experimental results on the OntoNotes 4.0 named entity annotated Chinese-English parallel corpus show that the proposed method can improve the strong Chinese NER baseline by over 5% F1 score and also give small improvements over the English baseline. Moreover, by adding the automatically tagged data to the original NER training corpus and retraining the monolingual model using an uptraining regimen (Petrov et al., 2010), we can improve the monolingual Chinese NER performance by over 3% F1 score. 2 Constraint-based Monolingual NER NER is a sequence labeling task where we assign a named entity tag to each word in an input sentence. One commonly used tagging scheme is the BIO scheme. The tag B-X (Begin) represents the first word of a named entity of type X, for example, PER (Person) or LOC (Location). The tag I-X (Inside) indicates that a word is part of an entity but not first word. The tag O (Outside) is used for all nonentity words.2 See Figure 1 for an example tagged sentence. Conditional Random Fields (CRF</context>
</contexts>
<marker>Petrov, Chang, Ringgaard, Alshawi, 2010</marker>
<rawString>Slav Petrov, Pi-Chuan Chang, Michael Ringgaard, and Hiyan Alshawi. 2010. Uptraining for accurate deterministic question parsing. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 705–713, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
<author>Dav Zimak</author>
</authors>
<title>Semantic role labeling via integer linear programming inference.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>1346--1352</pages>
<publisher>COLING.</publisher>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="30063" citStr="Punyakanok et al., 2004" startWordPosition="5046" endWordPosition="5049"> alignment. Das and Petrov (2011) applied the above idea to part-ofspeech tagging with a more complex model. Fu et al. (2011) projected English named entities onto Chinese by carefully designed heuristic rules. Although this type of method does not require manually annotated bilingual corpora or dictionaries, errors in source language results, wrong word alignments and inconsistencies between the languages limit application of this method. Constraint-based monolingual methods by using ILP have been successfully applied to many natural language processing tasks, such as Semantic Role Labeling (Punyakanok et al., 2004), Dependency Parsing (Martins et al., 2009) and Textual Entailment (Berant et al., 2011). Zhuang and Zong (2010) proposed a joint inference method for bilingual semantic role labeling with ILP. However, their approach requires training an alignment model with a manually annotated corpus. 9 Conclusions We proposed a novel ILP based inference algorithm with bilingual constraints for NER. This method can jointly infer bilingual named entities without using any annotated bilingual corpus. We investigate various bilingual constraints: hard and soft constraints. Out empirical study on largescale Ont</context>
</contexts>
<marker>Punyakanok, Roth, Yih, Zimak, 2004</marker>
<rawString>Vasin Punyakanok, Dan Roth, Wen-tau Yih, and Dav Zimak. 2004. Semantic role labeling via integer linear programming inference. In Proceedings of Coling 2004, pages 1346–1352, Geneva, Switzerland, Aug 23–Aug 27. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>Integer linear programming inference for conditional random fields.</title>
<date>2005</date>
<booktitle>In Proceedings of the 22nd international conference on Machine learning, ICML ’05,</booktitle>
<pages>736--743</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="5785" citStr="Roth and Yih (2005)" startWordPosition="912" endWordPosition="915">Random Fields (CRF) (Lafferty et al., 2001) is a state-of-the-art sequence labeling model widely used in NER. A first-order linear-chain CRF 2While the performance of NER is measured at the entity level (not the tag level). defines the following conditional probability: 1 PCRF(y|x) = Z(x) �Mi(yi,yi−1|x) (1) i where x and y are the input and output sequences, respectively, Z(x) is the partition function, and Mi is the clique potential for edge clique i. Decoding in CRF involves finding the most likely output sequence that maximizes this objective, and is commonly done by the Viterbi algorithm. Roth and Yih (2005) proposed an ILP inference algorithm, which can capture more task-specific and global constraints than the vanilla Viterbi algorithm. Our work is inspired by Roth and Yih (2005). But instead of directly solving the shortest-path problem in the ILP formulation, we re-define the conditional probability as: PMAR(y|x) = � P(yi|x) (2) i where P(yi|x) is the marginal probability given by an underlying CRF model computed using forwardbackward inference. Since the early HMM literature, it has been well known that using the marginal distributions at each position works well, as opposed to Viterbi MAP s</context>
</contexts>
<marker>Roth, Yih, 2005</marker>
<rawString>Dan Roth and Wen-tau Yih. 2005. Integer linear programming inference for conditional random fields. In Proceedings of the 22nd international conference on Machine learning, ICML ’05, pages 736–743, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29288" citStr="Yarowsky and Ngai (2001)" startWordPosition="4929" endWordPosition="4932">Finally, we test our method on a large standard publicly available corpus (8,249 sentences), while they used a much smaller (200 sentences) manually annotated bilingual NER corpus for results validation. In addition to bilingual corpora, bilingual dictionaries are also useful resources. Huang and Vogel (2002) and Chen et al. (2010) proposed approaches for extracting bilingual named entity pairs from unannotated bitext, in which verification is based on bilingual named entity dictionaries. However, large-scale bilingual named entity dictionaries are difficult to obtain for most language pairs. Yarowsky and Ngai (2001) proposed a projection method that transforms high-quality analysis results of one language, such as English, into other languages on the basis of word alignment. Das and Petrov (2011) applied the above idea to part-ofspeech tagging with a more complex model. Fu et al. (2011) projected English named entities onto Chinese by carefully designed heuristic rules. Although this type of method does not require manually annotated bilingual corpora or dictionaries, errors in source language results, wrong word alignments and inconsistencies between the languages limit application of this method. Const</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Zhuang</author>
<author>Chengqing Zong</author>
</authors>
<title>Joint inference for bilingual semantic role labeling.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>304--314</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="30175" citStr="Zhuang and Zong (2010)" startWordPosition="5064" endWordPosition="5067"> al. (2011) projected English named entities onto Chinese by carefully designed heuristic rules. Although this type of method does not require manually annotated bilingual corpora or dictionaries, errors in source language results, wrong word alignments and inconsistencies between the languages limit application of this method. Constraint-based monolingual methods by using ILP have been successfully applied to many natural language processing tasks, such as Semantic Role Labeling (Punyakanok et al., 2004), Dependency Parsing (Martins et al., 2009) and Textual Entailment (Berant et al., 2011). Zhuang and Zong (2010) proposed a joint inference method for bilingual semantic role labeling with ILP. However, their approach requires training an alignment model with a manually annotated corpus. 9 Conclusions We proposed a novel ILP based inference algorithm with bilingual constraints for NER. This method can jointly infer bilingual named entities without using any annotated bilingual corpus. We investigate various bilingual constraints: hard and soft constraints. Out empirical study on largescale OntoNotes Chinese-English parallel NER data showed that Soft-align method, which allows inconsistent named entity t</context>
</contexts>
<marker>Zhuang, Zong, 2010</marker>
<rawString>Tao Zhuang and Chengqing Zong. 2010. Joint inference for bilingual semantic role labeling. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 304–314, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>