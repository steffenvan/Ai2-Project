<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.998806">
Efficient Graph-Based Semi-Supervised Learning
of Structured Tagging Models
</title>
<author confidence="0.944577">
Amarnag Subramanya Slav Petrov Fernando Pereira
</author>
<affiliation confidence="0.921535">
Google Research Google Research Google Research
</affiliation>
<address confidence="0.945959">
Mountain View, CA 94043 New York, NY 10011 Mountain View, CA 94043
</address>
<email confidence="0.993876">
asubram@google.com slav@google.com pereira@google.com
</email>
<sectionHeader confidence="0.984672" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994738125">
We describe a new scalable algorithm for
semi-supervised training of conditional ran-
dom fields (CRF) and its application to part-
of-speech (POS) tagging. The algorithm uses
a similarity graph to encourage similar n-
grams to have similar POS tags. We demon-
strate the efficacy of our approach on a do-
main adaptation task, where we assume that
we have access to large amounts of unlabeled
data from the target domain, but no additional
labeled data. The similarity graph is used dur-
ing training to smooth the state posteriors on
the target domain. Standard inference can be
used at test time. Our approach is able to scale
to very large problems and yields significantly
improved target domain accuracy.
</bodyText>
<sectionHeader confidence="0.99248" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997954306122449">
Semi-supervised learning (SSL) is the use of
small amounts of labeled data with relatively large
amounts of unlabeled data to train predictors. In
some cases, the labeled data can be sufficient to pro-
vide reasonable accuracy on in-domain data, but per-
formance on even closely related out-of-domain data
may lag far behind. Annotating training data for all
sub-domains of a varied domain such as all of Web
text is impractical, giving impetus to the develop-
ment of SSL techniques that can learn from unla-
beled data to perform well across domains. The ear-
liest SSL algorithm is self-training (Scudder, 1965),
where one makes use of a previously trained model
to annotate unlabeled data which is then used to
re-train the model. While self-training is widely
used and can yield good results in some applica-
tions (Yarowsky, 1995), it has no theoretical guaran-
tees except under certain stringent conditions, which
rarely hold in practice(Haffari and Sarkar, 2007).
Other SSL methods include co-training (Blum
and Mitchell, 1998), transductive support vector ma-
chines (SVMs) (Joachims, 1999), and graph-based
SSL (Zhu et al., 2003). Several surveys cover a
broad range of methods (Seeger, 2000; Zhu, 2005;
Chapelle et al., 2007; Blitzer and Zhu, 2008). A ma-
jority of SSL algorithms are computationally expen-
sive; for example, solving a transductive SVM ex-
actly is intractable. Thus we have a conflict between
wanting to use SSL with large unlabeled data sets
for best accuracy, but being unable to do so because
of computational complexity. Some researchers at-
tempted to resolve this conflict by resorting to ap-
proximations (Collobert et al., 2006), but those lead
to suboptimal results (Chapelle et al., 2007).
Graph-based SSL algorithms (Zhu et al., 2003;
Joachims, 2003; Corduneanu and Jaakkola, 2003;
Belkin et al., 2005; Subramanya and Bilmes, 2009)
are an important subclass of SSL techniques that
have received much attention in the recent past, as
they outperform other approaches and also scale eas-
ily to large problems. Here one assumes that the data
(both labeled and unlabeled) is represented by ver-
tices in a graph. Graph edges link vertices that are
likely to have the same label. Edge weights govern
how strongly the labels of the nodes linked by the
edge should agree.
Most previous work in SSL has focused on un-
structured classification problems, that is, problems
with a relatively small set of atomic labels. There
</bodyText>
<note confidence="0.808622666666667">
167
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 167–176,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999975671875">
has been much less work on SSL for structured pre-
diction where labels are composites of many atomic
labels with constraints between them. While the
number of atomic labels might be small, there will
generally be exponentially many ways to combine
them into the final structured label. Structured pre-
diction problems over sequences appear for exam-
ple in speech recognition, named-entity recogni-
tion, and part-of-speech tagging; in machine trans-
lation and syntactic parsing, the output may be tree-
structured.
Altun et al. (2005) proposed a max-margin ob-
jective for semi-supervised learning over structured
spaces. Their objective is similar to that of manifold
regularization (Belkin et al., 2005) and they make
use of a graph as a smoothness regularizer. However
their solution involves inverting a matrix whose size
depends on problem size, making it impractical for
very large problems. Brefeld and Scheffer (2006)
present a modified version of the co-training algo-
rithm for structured output spaces. In both of the
above cases, the underlying model is based on struc-
tured SVM, which does not scale well to very large
datasets. More recently Wang et al. (2009) proposed
to train a conditional random field (CRF) (Lafferty et
al., 2001) using an entropy-based regularizer. Their
approach is similar to the entropy minimization al-
gorithm (Grandvalet and Bengio, 2005). The prob-
lem here is that their objective is not convex and thus
can pose issues for large problems. Further, graph-
based SSL algorithms outperform algorithms based
on entropy minimization (Chapelle et al., 2007).
In this work, we propose a graph-based SSL
method for CRFs that is computationally practical
for very large problems, unlike the methods in the
studies cited above. Our method is scalable be-
cause it trains with efficient standard building blocks
for CRF inference and learning and also standard
graph label propagation machinery. Graph regular-
izer computations are only used for training, so at
test time, standard CRF inference can be used, un-
like in graph-based transductive methods. Briefly,
our approach starts by training a CRF on the source
domain labeled data, and then uses it to decode unla-
beled data from the target domain. The state posteri-
ors on the target domain are then smoothed using the
graph regularizer. Best state sequences for the unla-
beled target data are then created by Viterbi decod-
ing with the smoothed state posteriors, and this au-
tomatic target domain annotation is combined with
the labeled source domain data to retrain the CRF.
We demonstrate our new method in domain adap-
tation for a CRF part-of-speech (POS) tagger. While
POS tagging accuracies have reached the level of
inter-annotator agreement (&gt;97%) on the standard
PennTreebank test set (Toutanova et al., 2003; Shen
et al., 2007), performance on out-of-domain data is
often well below 90%, impairing language process-
ing tasks that need syntactic information. For exam-
ple, on the question domain used in this paper, the
tagging accuracy of a supervised CRF is only 84%.
Our domain adaptation algorithm improves perfor-
mance to 87%, which is still far below in-domain
performance, but a significant reduction in error.
</bodyText>
<sectionHeader confidence="0.930213" genericHeader="method">
2 Supervised CRF
</sectionHeader>
<bodyText confidence="0.996101333333333">
We assume that we have a set of labeled source do-
main examples Dl = {(xi, yi)}li=1, but only un-
labeled target domain examples Du = {xi}l+u
</bodyText>
<equation confidence="0.99394625">
i=l+1.
Here xi = x(1)
i x(2)
i · · · x(|Xi|)
</equation>
<bodyText confidence="0.883893666666667">
i is the sequence of
words in sentence i and yi = y(1) iy(2) i · · · y(|Xi|) iis
the corresponding POS tag sequence, with y(j)
</bodyText>
<equation confidence="0.85574">
i E Y
</equation>
<bodyText confidence="0.809743">
where Y is the set of POS tags. Our goal is to learn
a CRF of the form:
</bodyText>
<equation confidence="0.788152">
Ni K 1
P(yi |xi; A) a exp XXλkfk(y�j−1),y�j), xi, j)�
=1k=1 /
for the target domain. In the above equation, A =
{λ1, . . . ,λK} E RK, fk(y(j−1)
i , y(j)
</equation>
<bodyText confidence="0.997471833333333">
i , xi, j) is the k-
th feature function applied to two consecutive CRF
states and some window of the input sequence, and
λk is the weight of that feature. We discuss our fea-
tures in detail in Section 6. Given only labeled data
Dl, the optimal feature weights are given by:
</bodyText>
<equation confidence="0.7469955">
Il
Xlog p(yi|xi;A)+γJJA112 (1)
Here
is the squared
</equation>
<bodyText confidence="0.989981142857143">
and acts as the
regularizer, and
is atrade-off parameter whose set-
ting we discuss in Section 6. In our case, we also
have access to the unlabeled data Du from the target
domain which we would like to use for training the
CRF. We first descri
</bodyText>
<equation confidence="0.92709675">
�A�2
`2-norm
γ
be how we construct a similarity
A* =argmin
ΛE[PK
i=1
168
</equation>
<bodyText confidence="0.996731">
graph over the unlabeled which will be used in our
algorithm as a graph regularizer.
</bodyText>
<sectionHeader confidence="0.98559" genericHeader="method">
3 Graph Construction
</sectionHeader>
<bodyText confidence="0.981062">
Graph construction is the most important step in
graph-based SSL. The standard approach for un-
structured problems is to construct a graph whose
vertices are labeled and unlabeled examples, and
whose weighted edges encode the degree to which
the examples they link should have the same la-
bel (Zhu et al., 2003). Then the main graph con-
struction choice is what similarity function to use
for the weighted edges between examples. How-
ever, in structured problems the situation is more
complicated. Consider the case of sequence tag-
ging we are studying. While we might be able to
choose some appropriate sequence similarity to con-
struct the graph, such as edit distance or a string
kernel, it is not clear how to use whole sequence
similarity to constrain whole tag sequences assigned
to linked examples in the learning algorithm. Al-
tun et al. (2005) had the nice insight of doing the
graph construction not for complete structured ex-
amples but instead for the parts of structured exam-
ples (also known as factors in graphical model ter-
minology), which encode the local dependencies be-
tween input data and output labels in the structured
problem. However, their approach is too demanding
computationally (see Section 5), so instead we use
local sequence contexts as graph vertices, exploting
the empirical observation that the part of speech of
a word occurrence is mostly determined by its local
context.
Specifically, the set V of graph vertices consists
of all the word n-grams1 (types) that have occur-
rences (tokens) in training sentences (labeled and
unlabeled). We partition V = Vl U Vu where Vl cor-
responds to n-grams that occur at least once in the
labeled data, and Vu corresponds to n-grams that oc-
cur only in the unlabeled data.
Given a symmetric similarity function between
types to be defined below, we link types u and v with
1We pad the n-grams at the beginning and end of sentences
with appropriate dummy symbols.
</bodyText>
<table confidence="0.999659">
Description Feature
Trigram + Context x1 x2 x3 x4 x5
Trigram x2 x3 x4
Left Context x1 x2
Right Context x4 x5
Center Word x2
Trigram – Center Word x2 x4
Left Word + Right Context x2 x4 x5
Left Context + Right Word x1 x2 x4
Suffix HasSuffix(x3)
</table>
<tableCaption confidence="0.932314">
Table 1: Features we extract given a sequence of words
“x1 x2 x3 x4 xs” where the trigram is “x2 x3 x4”.
</tableCaption>
<bodyText confidence="0.903715">
an edge of weight wuv, defined as:
�
</bodyText>
<equation confidence="0.951649">
sim(u, v) if v E K(u) or u E K(v)
wuv =
0 otherwise
</equation>
<bodyText confidence="0.999982642857143">
where K(u) is the set of k-nearest neighbors of u ac-
cording to the given similarity. For all experiments
in this paper, n = 3 and k = 5.
To define the similarity function, for each token
of a given type in the labeled and unlabeled data,
we extract a set of context features. For example,
for the token x2 x3 x4 occurring in the sequence
x1 x2 x3 x4 x5, we use feature templates that cap-
ture the left (x1 x2) and right contexts (x4 x5). Addi-
tionally, we extract suffix features from the word in
the middle. Table 1 gives an overview of the features
that we used. For each n-gram type, we compute the
vector of pointwise mutual information (PMI) val-
ues between the type and each of the features that
occur with tokens of that type. Finally, we use the
cosine distance between those PMI vectors as our
similarity function.
We have thus circumvented the problem of defin-
ing similarities over sequences by defining the graph
over types that represent local sequence contexts.
Since our CRF tagger only uses local features of the
input to score tag pairs, we believe that the graph
we construct captures all significant context infor-
mation. Figure 1 shows an excerpt from our graph.
The figure shows the neighborhoods of a subset of
the vertices with the center word ‘book.’ To reduce
clutter, we included only closest neighbors and the
edges that involve the nodes of interest.
</bodyText>
<page confidence="0.670354">
169
</page>
<figureCaption confidence="0.993035">
Figure 1: Vertices with center word ‘book’ and their local neighborhoods, as well as the shortest-path distance between
them. Note that the noun (NN) and verb (VB) interpretations form two disjoint connected components.
</figureCaption>
<figure confidence="0.999133609756097">
VB
[to schedule a]
VB
[to postpone a]
[to run a]
[to book some]
[the conference on]
[a movie agent]
7
[U.N.-backed conference on]
auction on]
[the conference speakers]
NN
6
4
[whose book on]
VB
[to start a] NN
NN [the
[to ace a]
3
4
[a clearing agent]
6
[you book a]
[to fly some]
[you log a]
[the movie that]
[the job that]
NN
[to approve some]
VB
[to book a]
[a book agent]
NN
[the book that]
[you rent a]
[to approve parental-consent]
[you unrar a]
[the city that]
[the constituition that]
</figure>
<bodyText confidence="0.999939367346939">
It is remarkable that the neighborhoods are co-
herent, showing very similar syntactic configura-
tions. Furthermore, different vertices that (should)
have the same label are close to each other, form-
ing connected components for each part-of-speech
category (for nouns and verbs in the figure). We ex-
pect the similarity graph to provide information that
cannot be expressed directly in a sequence model.
In particular, it is not possible in a CRF to directly
enforce the constraint that similar trigrams appear-
ing in different sentences should have similar POS
tags. This constraint however is important dur-
ing (semi-supervised) learning, and is what makes
our approach different and more effective than self-
training.
In practice, we expect two main benefits from
our graph-based approach. First, the graph allows
new features to be discovered. Many words occur
only in the unlabeled data and a purely supervised
CRF would not be able to learn feature weights for
those observations. We could use self-training to
learn weights for those features, but self-training just
tends to reinforce the knowledge that the supervised
model already has. The similarity graph on the other
hand can link events that occur only in the unlabeled
data to similar events in the labeled data. Further-
more, because the graph is built over types rather
than tokens, it will encourage the same interpreta-
tion to be chosen for similar trigrams occurring in
different sentences. For example, the word ‘unrar’
will most likely not occur in the labeled training
data. Seeing it in the neighborhood of words for
which we know the POS tag will help us learn the
correct POS tag for this otherwise unknown word
(see Figure 1).
Second, the graph propagates adjustments to the
weights of known features. Many words occur only
a handful of times in our labeled data, resulting in
poor estimates of their contributions. Even for fre-
quently occurring events, their distribution in the tar-
get domain might be different from their distribution
in the source domain. While self-training might be
able to help adapt to such domain changes, its ef-
fectiveness will be limited because the model will
always be inherently biased towards the source do-
main. In contrast, labeled vertices in the similar-
ity graph can help disambiguate ambiguous contexts
and correct (some of) the errors of the supervised
model.
</bodyText>
<sectionHeader confidence="0.998486" genericHeader="method">
4 Semi-Supervised CRF
</sectionHeader>
<bodyText confidence="0.997616538461539">
Given unlabeled data D,,, we only have access to
the prior p(x). As the CRF is a discriminative
model, the lack of label information renders the
CRF weights independent of p(x) and thus we can-
not directly utilize the unlabeled data when train-
ing the CRF. Therefore, semi-supervised approaches
to training discriminative models typically use the
unlabeled data to construct a regularizer that is
used to guide the learning process (Joachims, 1999;
Lawrence and Jordan, 2005). Here we use the graph
as a smoothness regularizer to train CRFs in a semi-
supervised manner.
Our algorithm iterates between the following five
</bodyText>
<equation confidence="0.871015857142857">
170
Algorithm 1 Semi-Supervised CRF Training
Λs = crf-train(Dl, Λ0)
Set Λ(t) 0= Λ(s)
while not converged do
{p} = posterior decode(Du, Λold)
{q} = token to type({p})
{ˆq} = graph propagate({q})
D(1)
u = viterbi decode({ˆq}, Λold)
Λ(t)
n+1 = crf-train(Dl ∪ D(1)
u , Λ(t)
n )
</equation>
<bodyText confidence="0.948066">
end while
Return last Λ(t)
simple (and convex) steps: Given a set of CRF pa-
rameters, we first compute marginals over the un-
labeled data (posterior decode). The marginals
over tokens are then aggregated to marginals over
types (token to type), which are used to initial-
ize the graph label distributions. After running la-
bel propagation (graph propagate), the posteriors
from the graph are used to smooth the state posteri-
ors. Decoding the unlabeled data (viterbi decode)
produces a new set of automatic annotations that can
be combined with the labeled data to retrain the CRF
using the supervised CRF training objective (crf-
train). These steps, summarized in Algorithm 1, are
iterated until convergence.
</bodyText>
<subsectionHeader confidence="0.987412">
4.1 Posterior Decoding
</subsectionHeader>
<bodyText confidence="0.995766666666667">
Let Λ(t)
n (t refers to target domain) represent the esti-
mate of the CRF parameters for the target domain af-
ter the n-th iteration.2 In this step, we use the current
parameter estimates to compute the marginal proba-
bilities
</bodyText>
<equation confidence="0.9821605">
p(y(j)
i |xi; Λ(t)
</equation>
<bodyText confidence="0.931451">
n ) 1 ≤ j ≤ |xi|, i ∈ Dl
over POS tags for every word position j for i index-
ing over sentences in Dl ∪ Du.
</bodyText>
<subsectionHeader confidence="0.925373">
4.2 Token-to-Type Mapping
</subsectionHeader>
<bodyText confidence="0.925644428571428">
Recall that our graph is defined over types while
the posteriors computed above involve particular to-
kens. We accumulate token-based marginals to cre-
ate type marginals as follows. For a sentence i and
word position j in that sentence, let T(i, j) be the
2In the first iteration, we initialize the target domain param-
eters to the source domain parameters: �(t)
</bodyText>
<equation confidence="0.970562">
0 = A(3).
</equation>
<bodyText confidence="0.999360142857143">
trigram (graph node) centered at position j. Con-
versely, for a trigram type u, let T−1(u) be the set
of actual occurrences (tokens) of that trigram u; that
is, all pairs (i, j) where i is the index of a sentence
where u occurs and j is the position of the center
word of an occurrence of u in that sentence. We cal-
culate type-level posteriors as follows:
</bodyText>
<equation confidence="0.9704786">
X
qu(y) g 1p(y(j)
i |xi;Λ(t)
n )
|T−1(u)|
</equation>
<bodyText confidence="0.9997656">
This combination rule connects the token-centered
CRF with the type-centered graph. Other ways
of combining the token marginals, such as using
weights derived from the entropies of marginals,
might be worth investigating.
</bodyText>
<subsectionHeader confidence="0.99389">
4.3 Graph Propagation
</subsectionHeader>
<bodyText confidence="0.999985666666667">
We now use our similarity graph (Section 3) to
smooth the type-level marginals by minimizing the
following convex objective:
</bodyText>
<equation confidence="0.996985333333333">
C(q) = X kru − quk2
uEV�
+ µ X Xwuvkqu − qvk2 + v kqu − Uk2
uEV,vEAr(i) uEV
Xs.t. qu(y) = 1 ∀u &amp; qu(y) ≥ 0 ∀u, y (2)
y
</equation>
<bodyText confidence="0.999944947368421">
where q = {q1, q2,... q|V |}. The setting of the
hyperparameters µ and v will be discussed in Sec-
tion 6, N(u) is the set of neighbors of node u, and
ru is the empirical marginal label distribution for tri-
gram u in the labeled data. We use a squared loss to
penalize neighboring nodes that have different label
distributions: kqu − qvk2 = Py(qu(y) − qv(y))2,
additionally regularizing the label distributions to-
wards the uniform distribution U over all possible
labels Y. It can be shown that the above objective is
convex in q.
Our graph propagation objective can be seen as a
multi-class generalization of the quadratic cost crite-
rion (Bengio et al., 2007). The first term in the above
objective requires that we respect the information
in our labeled data. The second term is the graph
smoothness regularizer which requires that the qi’s
be smooth with respect to the graph. In other words,
if wuv is large, then qu and qv should be close in the
</bodyText>
<equation confidence="0.615556333333333">
.
(i,j)ET−1(u)
171
</equation>
<bodyText confidence="0.999951214285714">
squared-error sense. This implies that vertices u and
v are likely to have similar marginals over POS tags.
The last term is a regularizer and encourages all type
marginals to be uniform to the extent that is allowed
by the first two terms. If a unlabeled vertex does
not have a path to any labeled vertex, this term en-
sures that the converged marginal for this vertex will
be uniform over all tags, ensuring that our algorithm
performs at least as well as a standard self-training
based algorithm, as we will see later.
While the objective in Equation 2 admits a closed
form solution, it involves inverting a matrix of or-
der |V  |and thus we use instead the simple iterative
update given by
</bodyText>
<equation confidence="0.997643333333333">
q(m)
u (y) = γu(y)
κu
γu(y) = ru(y)δ(u E Vl)
+ X wuvq(m−1)
v (y) + νU(y),
vEN(u)
κu = δ(u E Vl) + ν + µ X wuv (3)
vEN(u)
</equation>
<bodyText confidence="0.999382666666667">
where m is the iteration index and δ is the indica-
tor function that returns 1 if and only if the con-
dition is true. The iterative procedure starts with
</bodyText>
<equation confidence="0.89982">
qu (y) = qu(y) as given in the previous section.
(0)
</equation>
<bodyText confidence="0.999952">
In all our experiments we run 10 iterations of the
above algorithm, and we denote the type marginals
at completion by q*u(y).
</bodyText>
<subsectionHeader confidence="0.997194">
4.4 Viterbi Decoding
</subsectionHeader>
<bodyText confidence="0.99999125">
Given the type marginals computed in the previous
step, we interpolate them with the original CRF to-
ken marginals. This interpolation between type and
token marginals encourages similar n-grams to have
similar posteriors, while still allowing n-grams in
different sentences to differ in their posteriors. For
each unlabeled sentence i and word position j in it,
we calculate the following interpolated tag marginal:
</bodyText>
<equation confidence="0.9952762">
ˆp(y(j)
i = y|xi) = αp(y(j)
i = y|xi; Λ(t)
n )
+ (1 − α)q�T(m,n)(y) (4)
</equation>
<bodyText confidence="0.999960611111111">
where α is a mixing coefficient which reflects the
relative confidence between the original posteriors
from the CRF and the smoothed posteriors from the
graph. We discuss how we set α in Section 6.
The interpolated marginals summarize all the in-
formation obtained so far about the tag distribution
at each position. However, if we were to use them on
their own to select the most likely POS tag sequence,
the first-order tag dependencies modeled by the CRF
would be mostly ignored. This happens because the
type marginals obtained from the graph after label
propagation will have lost most of the sequence in-
formation. To enforce the first-order tag dependen-
cies we therefore use Viterbi decoding over the com-
bined interpolated marginals and the CRF transition
potentials to compute the best POS tag sequence for
each unlabeled sentence. We refer to these 1-best
transcripts as yz , i E Du.
</bodyText>
<subsectionHeader confidence="0.996899">
4.5 Re-training the CRF
</subsectionHeader>
<bodyText confidence="0.999976333333333">
Now that we have successfully labeled the unlabeled
target domain data, we can use it in conjunction with
the source domain labeled data to re-train the CRF:
</bodyText>
<equation confidence="0.991836333333333">
� Xl
Λ(t)
n+1 =argmin − log p(yi|xi; Λ(t)
n )
ΛE[PK i=1
log p(yz |xi; Λ(t))+γJIΛJI2] (5)
</equation>
<bodyText confidence="0.999876833333333">
where η and γ are hyper-parameters whose setting
we discuss in Section 6. Given the new CRF pa-
rameters Λ we loop back to step 1 (Section 4.1) and
iterate until convergence. It is important to note that
every step of our algorithm is convex, although their
combination clearly is not.
</bodyText>
<sectionHeader confidence="0.999769" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999381533333333">
Our work differs from previous studies of
SSL (Blitzer et al., 2006; III, 2007; Huang
and Yates, 2009) for improving POS tagging in
several ways. First, our algorithm can be general-
ized to other structured semi-supervised learning
problems, although POS tagging is our motivating
task and test application. Unlike III (2007), we
do not require target domain labeled data. While
the SCL algorithm (Blitzer et al., 2006) has been
evaluated without target domain labeled data, that
evaluation was to some extent transductive in that
the target test data (unlabeled) was included in the
unsupervised stage of SCL training that creates the
structural correspondence between the two domains.
where
</bodyText>
<equation confidence="0.779410333333333">
− η Xl+u
i=l+1
172
</equation>
<bodyText confidence="0.999985277777778">
We mentioned already the algorithm of Altun et
al. (2005), which is unlikely to scale up because
its dual formulation requires the inversion of a ma-
trix whose size depends on the graph size. Gupta
et al. (2009) also constrain similar trigrams to have
similar POS tags by forming cliques of similar tri-
grams and maximizing the agreement score over
these cliques. Computing clique agreement poten-
tials however is NP-hard and so they propose ap-
proximation algorithms that are still quite complex
computationally. We achieve similar effects by us-
ing our simple, scalable convex graph regularization
framework. Further, unlike other graph-propagation
algorithms (Alexandrescu and Kirchhoff, 2009), our
approach is inductive. While one might be able
to make inductive extensions of transductive ap-
proaches (Sindhwani et al., 2005), these usually re-
quire extensive computational resources at test time.
</bodyText>
<sectionHeader confidence="0.976784" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.988425323076923">
We use the Wall Street Journal (WSJ) section of
the Penn Treebank as our labeled source domain
training set. We follow standard setup procedures
for this task and train on sections 00-18, compris-
ing of 38,219 POS-tagged sentences with a total of
912,344 words. To evaluate our domain-adaptation
approach, we consider two different target domains:
questions and biomedical data. Both target do-
mains are relatively far from the source domain
(newswire), making this a very challenging task.
The QuestionBank (Judge et al., 2006), provides
an excellent corpus consisting of 4,000 questions
that were manually annotated with POS tags and
parse trees. We used the first half as our develop-
ment set and the second half as our test set. Ques-
tions are difficult to tag with WSJ-trained taggers
primarily because the word order is very different
than that of the mostly declarative sentences in the
training data. Additionally, the unknown word rate
is more than twice as high as on the in-domain de-
velopment set (7.29% vs. 3.39%). As our unla-
beled data, we use a set of 10 million questions
collected from anonymized Internet search queries.
These queries were selected to be similar in style
and length to the questions in the QuestionBank.3
3In particular, we selected queries that start with an English
function word that can be used to start a question (what, who,
As running the CRF over 10 million sentences can
be rather cumbersome and probably unnecessary, we
randomly select 100,000 of these queries and treat
this as D&amp;quot;. Because the graph nodes and the features
used in the similarity function are based on n-grams,
data sparsity can be a serious problem, and we there-
fore use the entire unlabeled data set for graph con-
struction. We estimate the mutual information-based
features for each trigram type over all the 10 million
questions, and then construct the graph over only
the set of trigram types that actually occurs in the
100,000 random subset and the WSJ training set.
For our second target domain, we use the Penn
BioTreebank (PennBioIE, 2005). This corpus con-
sists of 1,061 sentences that have been manually an-
notated with POS tags. We used the first 500 sen-
tences as a development set and the remaining 561
sentences as our final test set. The high unknown
word rate (23.27%) makes this corpus very difficult
to tag. Furthermore, the POS tag set for this data is a
super-set of the Penn Treebank’s, including the two
new tags HYPH (for hyphens) and AFX (for com-
mon post-modifiers of biomedical entities such as
genes). These tags were introduced due to the im-
portance of hyphenated entities in biomedical text,
and are used for 1.8% of the words in the test set.
Any tagger trained only on WSJ text will automati-
cally predict wrong tags for those words. For unla-
beled data we used 100,000 sentences that were cho-
sen by searching MEDLINE for abstracts pertaining
to cancer, in particular genomic variations and muta-
tions (Blitzer et al., 2006). Since we did not have ac-
cess to additional unlabeled data, we used the same
set of sentences as target domain unlabeled data, D&amp;quot;.
The graph here was constructed over the 100,000 un-
labeled sentences and the WSJ training set. Finally,
we remind the reader that we did not use label infor-
mation for graph construction in either corpus.
</bodyText>
<subsectionHeader confidence="0.999449">
6.1 Baselines
</subsectionHeader>
<bodyText confidence="0.961454">
Our baseline supervised CRF is competitive
with state-of-the-art discriminative POS taggers
(Toutanova et al., 2003; Shen et al., 2007), achieving
97.17% on the WSJ development set (sections 19-
21). We use a fairly standard set of features, includ-
ing word identity, suffixes and prefixes and detectors
when, etc.), and have between 30 and 160 characters.
</bodyText>
<page confidence="0.607505">
173
</page>
<table confidence="0.9995802">
Questions Bio
Dev Eval Dev Eval
Supervised CRF 84.8 83.8 86.5 86.2
Self-trained CRF 85.4 84.0 87.5 87.1
Semi-supervised CRF 87.6 86.8 87.5 87.6
</table>
<tableCaption confidence="0.997613">
Table 2: Domain adaptation experiments. POS tagging accuracies in %.
</tableCaption>
<bodyText confidence="0.999986352941177">
for special characters such as dashes and digits. We
do not use of observation-dependent transition fea-
tures. Both supervised and semi-supervised models
are regularized with a squared `2-norm regularizer
with weight set to 0.01.
In addition to the supervised baseline trained ex-
clusively on the WSJ, we also consider a semi-
supervised self-trained baseline (“Self-trained CRF”
in Table 2). In this approach, we first train a su-
pervised CRF on the labeled data and then do semi-
supervised training without label propagation. This
is different from plain self-training because it aggre-
gates the posteriors over tokens into posteriors over
types. This aggregation step allows instances of the
same trigram in different sentences to share infor-
mation and works better in practice than direct self-
training on the output of the supervised CRF.
</bodyText>
<subsectionHeader confidence="0.997739">
6.2 Domain Adaptation Results
</subsectionHeader>
<bodyText confidence="0.999996722222222">
The data set obtained concatenating the WSJ train-
ing set with the 10 million questions had about 20
million trigram types. Of those, only about 1.1 mil-
lion trigram types occurred in the WSJ training set
or in the 100,000 sentence sub-sample. For the
biomedical domain, the graph had about 2.2 mil-
lion trigrams. For all our experiments we set hy-
perparameters as follows: for graph propagation,
p = 0.5, v = 0.01, for Viterbi decoding mixing,
α = 0.6, for CRF re-training, ,q = 0.001, -y = 0.01.
These parameters were chosen based on develop-
ment set performance. All CRF objectives were op-
timized using L-BFGS (Bertsekas, 2004).
Table 2 shows the results for both domains. For
the question corpus, the supervised CRF performs
at only 85% on the development set. While it is al-
most impossible to improve in-domain tagging ac-
curacy and tagging is therefore considered a solved
problem by many, these results clearly show that
the problem is far from solved. Self-training im-
proves over the baseline by about 0.6% on the de-
velopment set. However the gains from self-training
are more modest (0.2%) on the evaluation (test) set.
Our approach is able to provide a more solid im-
provement of about 3% absolute over the super-
vised baseline and about 2% absolute over the self-
trained system on the question development set. Un-
like self-training, on the question evaluation set, our
approach provides about 3% absolute improvement
over the supervised baseline. For the biomedical
data, while the performances of our approach and
self-training are statistically indistinguishable on the
development set, we see modest gains of about 0.5%
absolute on the evaluation set. On the same data, we
see that our approach provides about 1.4% absolute
improvement over the supervised baseline.
</bodyText>
<sectionHeader confidence="0.898055" genericHeader="conclusions">
7 Analysis &amp; Conclusion
</sectionHeader>
<bodyText confidence="0.999995272727273">
The results suggest that our proposed approach pro-
vides higher gains relative to self-training on the
question data than on the biomedical corpus. We
hypothesize that this caused by sparsity in the graph
generated from the biomedical dataset. For the ques-
tions graph, the PMI statistics were estimated over
10 million sentences while in the case of the biomed-
ical dataset, the same statistics were computed over
just 100,000 sentences. We hypothesize that the lack
of well-estimated features in the case of the biomed-
ical dataset leads to a sparse graph.
To verify the above hypothesis, we measured the
percentage of trigrams that occur in the target do-
main (unlabeled) data that do not have any path to
a trigram in the source domain data, and the aver-
age minimum path length between a trigram in the
target data and a trigram in the source data (when
such a path exists). The results are shown in Ta-
ble 3. For the biomedical data, close to 50% of the
trigrams from the target data do not have a path to
a trigram from the source data. Even when such a
path exists, the average path length is about 22. On
</bodyText>
<page confidence="0.526642">
174
</page>
<table confidence="0.999176625">
Questions Bio
% of unlabeled trigrams 12.4 46.8
not connected to
any labeled trigrams
average path length 9.4 22.4
between an unlabeled
trigram and its nearest
labeled trigram
</table>
<tableCaption confidence="0.998425">
Table 3: Analysis of the graphs constructed for the two
</tableCaption>
<bodyText confidence="0.986002904761905">
datasets discussed in Section 6. Unlabeled trigrams occur
in the target domain only. Labeled trigrams occur at least
once in the WSJ training data.
the other hand, for the question corpus, only about
12% of the target domain trigrams are disconnected,
and the average path length is about 9. These re-
sults clearly show the sparse nature of the biomed-
ical graph. We believe that it is this sparsity that
causes the graph propagation to not have a more no-
ticeable effect on the final performance. It is note-
worthy that making use of even such a sparse graph
does not lead to any degradation in results, which we
attribute to the choice of graph-propagation regular-
izer (Section 4.3).
We presented a simple, scalable algorithm for
training structured prediction models in a semi-
supervised manner. The approach is based on using
as a regularizer a nearest-neighbor graph constructed
over trigram types. Our results show that the ap-
proach not only scales to large datasets but also pro-
duces significantly improved tagging accuracies.
</bodyText>
<sectionHeader confidence="0.994241" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999758253731343">
A. Alexandrescu and K. Kirchhoff. 2009. Graph-based
learning for statistical machine translation. In NAACL.
Y. Altun, D. McAllester, and M. Belkin. 2005. Max-
imum margin semi-supervised learning for structured
variables. In Advances in Neural Information Process-
ing Systems 18, page 18.
M. Belkin, P. Niyogi, and V. Sindhwani. 2005. On man-
ifold regularization. In Proc. of the Conference on Ar-
tificial Intelligence and Statistics (AISTATS).
Y. Bengio, O. Delalleau, and N. L. Roux, 2007. Semi-
Supervised Learning, chapter Label Propogation and
Quadratic Criterion. MIT Press.
D Bertsekas. 2004. Nonlinear Programming. Athena
Scientific Publishing.
J. Blitzer and J. Zhu. 2008. ACL 2008 tutorial on Semi-
Supervised learning.
J. Blitzer, R. McDonald, and F. Pereira. 2006. Domain
adaptation with structural correspondence learning. In
EMNLP ’06.
A. Blum and T. Mitchell. 1998. Combining labeled and
unlabeled data with co-training. In COLT: Proceed-
ings of the Workshop on Computational Learning The-
ory.
U. Brefeld and T. Scheffer. 2006. Semi-supervised learn-
ing for structured output variables. In ICML06, 23rd
International Conference on Machine Learning.
O. Chapelle, B. Scholkopf, and A. Zien. 2007. Semi-
Supervised Learning. MIT Press.
R. Collobert, F. Sinz, J. Weston, L. Bottou, and
T. Joachims. 2006. Large scale transductive svms.
Journal of Machine Learning Research.
A. Corduneanu and T. Jaakkola. 2003. On informa-
tion regularization. In Uncertainty in Artificial Intelli-
gence.
Y. Grandvalet and Y. Bengio. 2005. Semi-supervised
learning by entropy minimization. In CAP.
R. Gupta, S. Sarawagi, and A. A. Diwan. 2009. General-
ized collective inference with symmetric clique poten-
tials. CoRR, abs/0907.0589.
G. R. Haffari and A. Sarkar. 2007. Analysis of semi-
supervised learning with the Yarowsky algorithm. In
UAI.
F. Huang and A. Yates. 2009. Distributional represen-
tations for handling sparsity in supervised sequence-
labeling. In ACL-IJCNLP ’09: Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Volume
1. Association for Computational Linguistics.
H. Daume III. 2007. Frustratingly easy domain adapta-
tion. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
256–263, Prague, Czech Republic, June. Association
for Computational Linguistics.
T. Joachims. 1999. Transductive inference for text clas-
sification using support vector machines. In Proc. of
the International Conference on Machine Learning
(ICML).
Thorsten Joachims. 2003. Transductive learning via
spectral graph partitioning. In Proc. of the Interna-
tional Conference on Machine Learning (ICML).
J. Judge, A. Cahill, and J. van Genabith. 2006. Question-
bank: Creating a corpus of parse-annotated questions.
In Proceedings of the 21st International Conference
on Computational Linguist ics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 497–504.
</reference>
<page confidence="0.609427">
175
</page>
<reference confidence="0.999923675">
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proc. of the In-
ternational Conference on Machine Learning (ICML).
N. D. Lawrence and M. I. Jordan. 2005. Semi-supervised
learning via gaussian processes. In NIPS.
PennBioIE. 2005. Mining the bibliome project. In
http://bioie.ldc.upenn.edu/.
H. J. Scudder. 1965. Probability of Error of some Adap-
tive Pattern-Recognition Machines. IEEE Transac-
tions on Information Theory, 11.
M. Seeger. 2000. Learning with labeled and unlabeled
data. Technical report, University of Edinburgh, U.K.
L. Shen, G. Satta, and A. Joshi. 2007. Guided learning
for bidirectional sequence classification. In ACL ’07.
V. Sindhwani, P. Niyogi, and M. Belkin. 2005. Beyond
the point cloud: from transductive to semi-supervised
learning. In Proc. of the International Conference on
Machine Learning (ICML).
A. Subramanya and J. A. Bilmes. 2009. Entropic graph
regularization in non-parametric semi-supervised clas-
sification. In Neural Information Processing Society
(NIPS), Vancouver, Canada, December.
K. Toutanova, D. Klein, C. D. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In HLT-NAACL ’03.
Y. Wang, G. Haffari, S. Wang, and G. Mori. 2009.
A rate distortion approach for semi-supervised condi-
tional random fields.
D. Yarowsky. 1995. Unsupervised word sense disam-
biguation rivaling supervised methods. In Proceed-
ings of the 33rd Annual Meeting of the Association for
Computational Linguistics.
X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semi-
supervised learning using gaussian fields and har-
monic functions. In Proc. of the International Con-
ference on Machine Learning (ICML).
X. Zhu. 2005. Semi-supervised learning literature sur-
vey. Technical Report 1530, Computer Sciences, Uni-
versity of Wisconsin-Madison.
</reference>
<page confidence="0.946451">
176
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.965767">
<title confidence="0.999329">Efficient Graph-Based Semi-Supervised of Structured Tagging Models</title>
<author confidence="0.997387">Amarnag Subramanya Slav Petrov Fernando Pereira</author>
<affiliation confidence="0.995226">Google Research Google Research Google Research</affiliation>
<address confidence="0.999602">Mountain View, CA 94043 New York, NY 10011 Mountain View, CA 94043</address>
<email confidence="0.996438">asubram@google.comslav@google.compereira@google.com</email>
<abstract confidence="0.998627117647059">We describe a new scalable algorithm for semi-supervised training of conditional random fields (CRF) and its application to partof-speech (POS) tagging. The algorithm uses similarity graph to encourage similar grams to have similar POS tags. We demonstrate the efficacy of our approach on a domain adaptation task, where we assume that we have access to large amounts of unlabeled data from the target domain, but no additional labeled data. The similarity graph is used during training to smooth the state posteriors on the target domain. Standard inference can be used at test time. Our approach is able to scale to very large problems and yields significantly improved target domain accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Alexandrescu</author>
<author>K Kirchhoff</author>
</authors>
<title>Graph-based learning for statistical machine translation.</title>
<date>2009</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="23701" citStr="Alexandrescu and Kirchhoff, 2009" startWordPosition="4043" endWordPosition="4046"> which is unlikely to scale up because its dual formulation requires the inversion of a matrix whose size depends on the graph size. Gupta et al. (2009) also constrain similar trigrams to have similar POS tags by forming cliques of similar trigrams and maximizing the agreement score over these cliques. Computing clique agreement potentials however is NP-hard and so they propose approximation algorithms that are still quite complex computationally. We achieve similar effects by using our simple, scalable convex graph regularization framework. Further, unlike other graph-propagation algorithms (Alexandrescu and Kirchhoff, 2009), our approach is inductive. While one might be able to make inductive extensions of transductive approaches (Sindhwani et al., 2005), these usually require extensive computational resources at test time. 6 Experiments and Results We use the Wall Street Journal (WSJ) section of the Penn Treebank as our labeled source domain training set. We follow standard setup procedures for this task and train on sections 00-18, comprising of 38,219 POS-tagged sentences with a total of 912,344 words. To evaluate our domain-adaptation approach, we consider two different target domains: questions and biomedic</context>
</contexts>
<marker>Alexandrescu, Kirchhoff, 2009</marker>
<rawString>A. Alexandrescu and K. Kirchhoff. 2009. Graph-based learning for statistical machine translation. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Altun</author>
<author>D McAllester</author>
<author>M Belkin</author>
</authors>
<title>Maximum margin semi-supervised learning for structured variables.</title>
<date>2005</date>
<booktitle>In Advances in Neural Information Processing Systems 18,</booktitle>
<pages>18</pages>
<contexts>
<context position="4170" citStr="Altun et al. (2005)" startWordPosition="655" endWordPosition="658">MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics has been much less work on SSL for structured prediction where labels are composites of many atomic labels with constraints between them. While the number of atomic labels might be small, there will generally be exponentially many ways to combine them into the final structured label. Structured prediction problems over sequences appear for example in speech recognition, named-entity recognition, and part-of-speech tagging; in machine translation and syntactic parsing, the output may be treestructured. Altun et al. (2005) proposed a max-margin objective for semi-supervised learning over structured spaces. Their objective is similar to that of manifold regularization (Belkin et al., 2005) and they make use of a graph as a smoothness regularizer. However their solution involves inverting a matrix whose size depends on problem size, making it impractical for very large problems. Brefeld and Scheffer (2006) present a modified version of the co-training algorithm for structured output spaces. In both of the above cases, the underlying model is based on structured SVM, which does not scale well to very large dataset</context>
<context position="8977" citStr="Altun et al. (2005)" startWordPosition="1487" endWordPosition="1491">egree to which the examples they link should have the same label (Zhu et al., 2003). Then the main graph construction choice is what similarity function to use for the weighted edges between examples. However, in structured problems the situation is more complicated. Consider the case of sequence tagging we are studying. While we might be able to choose some appropriate sequence similarity to construct the graph, such as edit distance or a string kernel, it is not clear how to use whole sequence similarity to constrain whole tag sequences assigned to linked examples in the learning algorithm. Altun et al. (2005) had the nice insight of doing the graph construction not for complete structured examples but instead for the parts of structured examples (also known as factors in graphical model terminology), which encode the local dependencies between input data and output labels in the structured problem. However, their approach is too demanding computationally (see Section 5), so instead we use local sequence contexts as graph vertices, exploting the empirical observation that the part of speech of a word occurrence is mostly determined by its local context. Specifically, the set V of graph vertices con</context>
<context position="23067" citStr="Altun et al. (2005)" startWordPosition="3947" endWordPosition="3950">st, our algorithm can be generalized to other structured semi-supervised learning problems, although POS tagging is our motivating task and test application. Unlike III (2007), we do not require target domain labeled data. While the SCL algorithm (Blitzer et al., 2006) has been evaluated without target domain labeled data, that evaluation was to some extent transductive in that the target test data (unlabeled) was included in the unsupervised stage of SCL training that creates the structural correspondence between the two domains. where − η Xl+u i=l+1 172 We mentioned already the algorithm of Altun et al. (2005), which is unlikely to scale up because its dual formulation requires the inversion of a matrix whose size depends on the graph size. Gupta et al. (2009) also constrain similar trigrams to have similar POS tags by forming cliques of similar trigrams and maximizing the agreement score over these cliques. Computing clique agreement potentials however is NP-hard and so they propose approximation algorithms that are still quite complex computationally. We achieve similar effects by using our simple, scalable convex graph regularization framework. Further, unlike other graph-propagation algorithms </context>
</contexts>
<marker>Altun, McAllester, Belkin, 2005</marker>
<rawString>Y. Altun, D. McAllester, and M. Belkin. 2005. Maximum margin semi-supervised learning for structured variables. In Advances in Neural Information Processing Systems 18, page 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Belkin</author>
<author>P Niyogi</author>
<author>V Sindhwani</author>
</authors>
<title>On manifold regularization.</title>
<date>2005</date>
<booktitle>In Proc. of the Conference on Artificial Intelligence and Statistics (AISTATS).</booktitle>
<contexts>
<context position="2834" citStr="Belkin et al., 2005" startWordPosition="443" endWordPosition="446"> Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003; Belkin et al., 2005; Subramanya and Bilmes, 2009) are an important subclass of SSL techniques that have received much attention in the recent past, as they outperform other approaches and also scale easily to large problems. Here one assumes that the data (both labeled and unlabeled) is represented by vertices in a graph. Graph edges link vertices that are likely to have the same label. Edge weights govern how strongly the labels of the nodes linked by the edge should agree. Most previous work in SSL has focused on unstructured classification problems, that is, problems with a relatively small set of atomic labe</context>
<context position="4339" citStr="Belkin et al., 2005" startWordPosition="679" endWordPosition="682">omposites of many atomic labels with constraints between them. While the number of atomic labels might be small, there will generally be exponentially many ways to combine them into the final structured label. Structured prediction problems over sequences appear for example in speech recognition, named-entity recognition, and part-of-speech tagging; in machine translation and syntactic parsing, the output may be treestructured. Altun et al. (2005) proposed a max-margin objective for semi-supervised learning over structured spaces. Their objective is similar to that of manifold regularization (Belkin et al., 2005) and they make use of a graph as a smoothness regularizer. However their solution involves inverting a matrix whose size depends on problem size, making it impractical for very large problems. Brefeld and Scheffer (2006) present a modified version of the co-training algorithm for structured output spaces. In both of the above cases, the underlying model is based on structured SVM, which does not scale well to very large datasets. More recently Wang et al. (2009) proposed to train a conditional random field (CRF) (Lafferty et al., 2001) using an entropy-based regularizer. Their approach is simi</context>
</contexts>
<marker>Belkin, Niyogi, Sindhwani, 2005</marker>
<rawString>M. Belkin, P. Niyogi, and V. Sindhwani. 2005. On manifold regularization. In Proc. of the Conference on Artificial Intelligence and Statistics (AISTATS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bengio</author>
<author>O Delalleau</author>
<author>N L Roux</author>
</authors>
<date>2007</date>
<booktitle>SemiSupervised Learning, chapter Label Propogation and Quadratic Criterion.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="18876" citStr="Bengio et al., 2007" startWordPosition="3213" endWordPosition="3216">ting of the hyperparameters µ and v will be discussed in Section 6, N(u) is the set of neighbors of node u, and ru is the empirical marginal label distribution for trigram u in the labeled data. We use a squared loss to penalize neighboring nodes that have different label distributions: kqu − qvk2 = Py(qu(y) − qv(y))2, additionally regularizing the label distributions towards the uniform distribution U over all possible labels Y. It can be shown that the above objective is convex in q. Our graph propagation objective can be seen as a multi-class generalization of the quadratic cost criterion (Bengio et al., 2007). The first term in the above objective requires that we respect the information in our labeled data. The second term is the graph smoothness regularizer which requires that the qi’s be smooth with respect to the graph. In other words, if wuv is large, then qu and qv should be close in the . (i,j)ET−1(u) 171 squared-error sense. This implies that vertices u and v are likely to have similar marginals over POS tags. The last term is a regularizer and encourages all type marginals to be uniform to the extent that is allowed by the first two terms. If a unlabeled vertex does not have a path to any</context>
</contexts>
<marker>Bengio, Delalleau, Roux, 2007</marker>
<rawString>Y. Bengio, O. Delalleau, and N. L. Roux, 2007. SemiSupervised Learning, chapter Label Propogation and Quadratic Criterion. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bertsekas</author>
</authors>
<title>Nonlinear Programming. Athena Scientific Publishing.</title>
<date>2004</date>
<contexts>
<context position="29301" citStr="Bertsekas, 2004" startWordPosition="4978" endWordPosition="4979">set obtained concatenating the WSJ training set with the 10 million questions had about 20 million trigram types. Of those, only about 1.1 million trigram types occurred in the WSJ training set or in the 100,000 sentence sub-sample. For the biomedical domain, the graph had about 2.2 million trigrams. For all our experiments we set hyperparameters as follows: for graph propagation, p = 0.5, v = 0.01, for Viterbi decoding mixing, α = 0.6, for CRF re-training, ,q = 0.001, -y = 0.01. These parameters were chosen based on development set performance. All CRF objectives were optimized using L-BFGS (Bertsekas, 2004). Table 2 shows the results for both domains. For the question corpus, the supervised CRF performs at only 85% on the development set. While it is almost impossible to improve in-domain tagging accuracy and tagging is therefore considered a solved problem by many, these results clearly show that the problem is far from solved. Self-training improves over the baseline by about 0.6% on the development set. However the gains from self-training are more modest (0.2%) on the evaluation (test) set. Our approach is able to provide a more solid improvement of about 3% absolute over the supervised base</context>
</contexts>
<marker>Bertsekas, 2004</marker>
<rawString>D Bertsekas. 2004. Nonlinear Programming. Athena Scientific Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>J Zhu</author>
</authors>
<date>2008</date>
<publisher>ACL</publisher>
<note>tutorial on SemiSupervised learning.</note>
<contexts>
<context position="2261" citStr="Blitzer and Zhu, 2008" startWordPosition="351" endWordPosition="354">use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003; Belkin et al., 2005; Subramanya and Bilmes, 20</context>
</contexts>
<marker>Blitzer, Zhu, 2008</marker>
<rawString>J. Blitzer and J. Zhu. 2008. ACL 2008 tutorial on SemiSupervised learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In EMNLP ’06.</booktitle>
<contexts>
<context position="22366" citStr="Blitzer et al., 2006" startWordPosition="3836" endWordPosition="3839">he CRF Now that we have successfully labeled the unlabeled target domain data, we can use it in conjunction with the source domain labeled data to re-train the CRF: � Xl Λ(t) n+1 =argmin − log p(yi|xi; Λ(t) n ) ΛE[PK i=1 log p(yz |xi; Λ(t))+γJIΛJI2] (5) where η and γ are hyper-parameters whose setting we discuss in Section 6. Given the new CRF parameters Λ we loop back to step 1 (Section 4.1) and iterate until convergence. It is important to note that every step of our algorithm is convex, although their combination clearly is not. 5 Related Work Our work differs from previous studies of SSL (Blitzer et al., 2006; III, 2007; Huang and Yates, 2009) for improving POS tagging in several ways. First, our algorithm can be generalized to other structured semi-supervised learning problems, although POS tagging is our motivating task and test application. Unlike III (2007), we do not require target domain labeled data. While the SCL algorithm (Blitzer et al., 2006) has been evaluated without target domain labeled data, that evaluation was to some extent transductive in that the target test data (unlabeled) was included in the unsupervised stage of SCL training that creates the structural correspondence betwee</context>
<context position="26888" citStr="Blitzer et al., 2006" startWordPosition="4580" endWordPosition="4583">hermore, the POS tag set for this data is a super-set of the Penn Treebank’s, including the two new tags HYPH (for hyphens) and AFX (for common post-modifiers of biomedical entities such as genes). These tags were introduced due to the importance of hyphenated entities in biomedical text, and are used for 1.8% of the words in the test set. Any tagger trained only on WSJ text will automatically predict wrong tags for those words. For unlabeled data we used 100,000 sentences that were chosen by searching MEDLINE for abstracts pertaining to cancer, in particular genomic variations and mutations (Blitzer et al., 2006). Since we did not have access to additional unlabeled data, we used the same set of sentences as target domain unlabeled data, D&amp;quot;. The graph here was constructed over the 100,000 unlabeled sentences and the WSJ training set. Finally, we remind the reader that we did not use label information for graph construction in either corpus. 6.1 Baselines Our baseline supervised CRF is competitive with state-of-the-art discriminative POS taggers (Toutanova et al., 2003; Shen et al., 2007), achieving 97.17% on the WSJ development set (sections 19- 21). We use a fairly standard set of features, including</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>J. Blitzer, R. McDonald, and F. Pereira. 2006. Domain adaptation with structural correspondence learning. In EMNLP ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>T Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In COLT: Proceedings of the Workshop on Computational Learning Theory.</booktitle>
<contexts>
<context position="2039" citStr="Blum and Mitchell, 1998" startWordPosition="316" endWordPosition="319">of Web text is impractical, giving impetus to the development of SSL techniques that can learn from unlabeled data to perform well across domains. The earliest SSL algorithm is self-training (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Coll</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>A. Blum and T. Mitchell. 1998. Combining labeled and unlabeled data with co-training. In COLT: Proceedings of the Workshop on Computational Learning Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Brefeld</author>
<author>T Scheffer</author>
</authors>
<title>Semi-supervised learning for structured output variables.</title>
<date>2006</date>
<booktitle>In ICML06, 23rd International Conference on Machine Learning.</booktitle>
<contexts>
<context position="4559" citStr="Brefeld and Scheffer (2006)" startWordPosition="714" endWordPosition="717">uctured prediction problems over sequences appear for example in speech recognition, named-entity recognition, and part-of-speech tagging; in machine translation and syntactic parsing, the output may be treestructured. Altun et al. (2005) proposed a max-margin objective for semi-supervised learning over structured spaces. Their objective is similar to that of manifold regularization (Belkin et al., 2005) and they make use of a graph as a smoothness regularizer. However their solution involves inverting a matrix whose size depends on problem size, making it impractical for very large problems. Brefeld and Scheffer (2006) present a modified version of the co-training algorithm for structured output spaces. In both of the above cases, the underlying model is based on structured SVM, which does not scale well to very large datasets. More recently Wang et al. (2009) proposed to train a conditional random field (CRF) (Lafferty et al., 2001) using an entropy-based regularizer. Their approach is similar to the entropy minimization algorithm (Grandvalet and Bengio, 2005). The problem here is that their objective is not convex and thus can pose issues for large problems. Further, graphbased SSL algorithms outperform a</context>
</contexts>
<marker>Brefeld, Scheffer, 2006</marker>
<rawString>U. Brefeld and T. Scheffer. 2006. Semi-supervised learning for structured output variables. In ICML06, 23rd International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Chapelle</author>
<author>B Scholkopf</author>
<author>A Zien</author>
</authors>
<title>SemiSupervised Learning.</title>
<date>2007</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2237" citStr="Chapelle et al., 2007" startWordPosition="347" endWordPosition="350">1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003; Belkin et al., 2005; S</context>
<context position="5222" citStr="Chapelle et al., 2007" startWordPosition="821" endWordPosition="824">ining algorithm for structured output spaces. In both of the above cases, the underlying model is based on structured SVM, which does not scale well to very large datasets. More recently Wang et al. (2009) proposed to train a conditional random field (CRF) (Lafferty et al., 2001) using an entropy-based regularizer. Their approach is similar to the entropy minimization algorithm (Grandvalet and Bengio, 2005). The problem here is that their objective is not convex and thus can pose issues for large problems. Further, graphbased SSL algorithms outperform algorithms based on entropy minimization (Chapelle et al., 2007). In this work, we propose a graph-based SSL method for CRFs that is computationally practical for very large problems, unlike the methods in the studies cited above. Our method is scalable because it trains with efficient standard building blocks for CRF inference and learning and also standard graph label propagation machinery. Graph regularizer computations are only used for training, so at test time, standard CRF inference can be used, unlike in graph-based transductive methods. Briefly, our approach starts by training a CRF on the source domain labeled data, and then uses it to decode unl</context>
</contexts>
<marker>Chapelle, Scholkopf, Zien, 2007</marker>
<rawString>O. Chapelle, B. Scholkopf, and A. Zien. 2007. SemiSupervised Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
<author>F Sinz</author>
<author>J Weston</author>
<author>L Bottou</author>
<author>T Joachims</author>
</authors>
<title>Large scale transductive svms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="2658" citStr="Collobert et al., 2006" startWordPosition="416" endWordPosition="419">998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003; Belkin et al., 2005; Subramanya and Bilmes, 2009) are an important subclass of SSL techniques that have received much attention in the recent past, as they outperform other approaches and also scale easily to large problems. Here one assumes that the data (both labeled and unlabeled) is represented by vertices in a graph. Graph edges link vertices that are likely to have the same label. Edge weights govern how strongly the labels of the no</context>
</contexts>
<marker>Collobert, Sinz, Weston, Bottou, Joachims, 2006</marker>
<rawString>R. Collobert, F. Sinz, J. Weston, L. Bottou, and T. Joachims. 2006. Large scale transductive svms. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Corduneanu</author>
<author>T Jaakkola</author>
</authors>
<title>On information regularization.</title>
<date>2003</date>
<booktitle>In Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="2813" citStr="Corduneanu and Jaakkola, 2003" startWordPosition="439" endWordPosition="442">thods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003; Belkin et al., 2005; Subramanya and Bilmes, 2009) are an important subclass of SSL techniques that have received much attention in the recent past, as they outperform other approaches and also scale easily to large problems. Here one assumes that the data (both labeled and unlabeled) is represented by vertices in a graph. Graph edges link vertices that are likely to have the same label. Edge weights govern how strongly the labels of the nodes linked by the edge should agree. Most previous work in SSL has focused on unstructured classification problems, that is, problems with a relatively sma</context>
</contexts>
<marker>Corduneanu, Jaakkola, 2003</marker>
<rawString>A. Corduneanu and T. Jaakkola. 2003. On information regularization. In Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Grandvalet</author>
<author>Y Bengio</author>
</authors>
<title>Semi-supervised learning by entropy minimization.</title>
<date>2005</date>
<booktitle>In CAP.</booktitle>
<contexts>
<context position="5010" citStr="Grandvalet and Bengio, 2005" startWordPosition="787" endWordPosition="790">ss regularizer. However their solution involves inverting a matrix whose size depends on problem size, making it impractical for very large problems. Brefeld and Scheffer (2006) present a modified version of the co-training algorithm for structured output spaces. In both of the above cases, the underlying model is based on structured SVM, which does not scale well to very large datasets. More recently Wang et al. (2009) proposed to train a conditional random field (CRF) (Lafferty et al., 2001) using an entropy-based regularizer. Their approach is similar to the entropy minimization algorithm (Grandvalet and Bengio, 2005). The problem here is that their objective is not convex and thus can pose issues for large problems. Further, graphbased SSL algorithms outperform algorithms based on entropy minimization (Chapelle et al., 2007). In this work, we propose a graph-based SSL method for CRFs that is computationally practical for very large problems, unlike the methods in the studies cited above. Our method is scalable because it trains with efficient standard building blocks for CRF inference and learning and also standard graph label propagation machinery. Graph regularizer computations are only used for trainin</context>
</contexts>
<marker>Grandvalet, Bengio, 2005</marker>
<rawString>Y. Grandvalet and Y. Bengio. 2005. Semi-supervised learning by entropy minimization. In CAP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gupta</author>
<author>S Sarawagi</author>
<author>A A Diwan</author>
</authors>
<title>Generalized collective inference with symmetric clique potentials.</title>
<date>2009</date>
<location>CoRR, abs/0907.0589.</location>
<contexts>
<context position="23220" citStr="Gupta et al. (2009)" startWordPosition="3975" endWordPosition="3978">ion. Unlike III (2007), we do not require target domain labeled data. While the SCL algorithm (Blitzer et al., 2006) has been evaluated without target domain labeled data, that evaluation was to some extent transductive in that the target test data (unlabeled) was included in the unsupervised stage of SCL training that creates the structural correspondence between the two domains. where − η Xl+u i=l+1 172 We mentioned already the algorithm of Altun et al. (2005), which is unlikely to scale up because its dual formulation requires the inversion of a matrix whose size depends on the graph size. Gupta et al. (2009) also constrain similar trigrams to have similar POS tags by forming cliques of similar trigrams and maximizing the agreement score over these cliques. Computing clique agreement potentials however is NP-hard and so they propose approximation algorithms that are still quite complex computationally. We achieve similar effects by using our simple, scalable convex graph regularization framework. Further, unlike other graph-propagation algorithms (Alexandrescu and Kirchhoff, 2009), our approach is inductive. While one might be able to make inductive extensions of transductive approaches (Sindhwani</context>
</contexts>
<marker>Gupta, Sarawagi, Diwan, 2009</marker>
<rawString>R. Gupta, S. Sarawagi, and A. A. Diwan. 2009. Generalized collective inference with symmetric clique potentials. CoRR, abs/0907.0589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R Haffari</author>
<author>A Sarkar</author>
</authors>
<title>Analysis of semisupervised learning with the Yarowsky algorithm.</title>
<date>2007</date>
<booktitle>In UAI.</booktitle>
<contexts>
<context position="1974" citStr="Haffari and Sarkar, 2007" startWordPosition="307" endWordPosition="310"> training data for all sub-domains of a varied domain such as all of Web text is impractical, giving impetus to the development of SSL techniques that can learn from unlabeled data to perform well across domains. The earliest SSL algorithm is self-training (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attemp</context>
</contexts>
<marker>Haffari, Sarkar, 2007</marker>
<rawString>G. R. Haffari and A. Sarkar. 2007. Analysis of semisupervised learning with the Yarowsky algorithm. In UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huang</author>
<author>A Yates</author>
</authors>
<title>Distributional representations for handling sparsity in supervised sequencelabeling.</title>
<date>2009</date>
<booktitle>In ACL-IJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="22401" citStr="Huang and Yates, 2009" startWordPosition="3842" endWordPosition="3845">lly labeled the unlabeled target domain data, we can use it in conjunction with the source domain labeled data to re-train the CRF: � Xl Λ(t) n+1 =argmin − log p(yi|xi; Λ(t) n ) ΛE[PK i=1 log p(yz |xi; Λ(t))+γJIΛJI2] (5) where η and γ are hyper-parameters whose setting we discuss in Section 6. Given the new CRF parameters Λ we loop back to step 1 (Section 4.1) and iterate until convergence. It is important to note that every step of our algorithm is convex, although their combination clearly is not. 5 Related Work Our work differs from previous studies of SSL (Blitzer et al., 2006; III, 2007; Huang and Yates, 2009) for improving POS tagging in several ways. First, our algorithm can be generalized to other structured semi-supervised learning problems, although POS tagging is our motivating task and test application. Unlike III (2007), we do not require target domain labeled data. While the SCL algorithm (Blitzer et al., 2006) has been evaluated without target domain labeled data, that evaluation was to some extent transductive in that the target test data (unlabeled) was included in the unsupervised stage of SCL training that creates the structural correspondence between the two domains. where − η Xl+u i</context>
</contexts>
<marker>Huang, Yates, 2009</marker>
<rawString>F. Huang and A. Yates. 2009. Distributional representations for handling sparsity in supervised sequencelabeling. In ACL-IJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Daume</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>256--263</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<marker>Daume, 2007</marker>
<rawString>H. Daume III. 2007. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 256–263, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Transductive inference for text classification using support vector machines.</title>
<date>1999</date>
<booktitle>In Proc. of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="2101" citStr="Joachims, 1999" startWordPosition="326" endWordPosition="327">chniques that can learn from unlabeled data to perform well across domains. The earliest SSL algorithm is self-training (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Cha</context>
<context position="15415" citStr="Joachims, 1999" startWordPosition="2601" endWordPosition="2602">trast, labeled vertices in the similarity graph can help disambiguate ambiguous contexts and correct (some of) the errors of the supervised model. 4 Semi-Supervised CRF Given unlabeled data D,,, we only have access to the prior p(x). As the CRF is a discriminative model, the lack of label information renders the CRF weights independent of p(x) and thus we cannot directly utilize the unlabeled data when training the CRF. Therefore, semi-supervised approaches to training discriminative models typically use the unlabeled data to construct a regularizer that is used to guide the learning process (Joachims, 1999; Lawrence and Jordan, 2005). Here we use the graph as a smoothness regularizer to train CRFs in a semisupervised manner. Our algorithm iterates between the following five 170 Algorithm 1 Semi-Supervised CRF Training Λs = crf-train(Dl, Λ0) Set Λ(t) 0= Λ(s) while not converged do {p} = posterior decode(Du, Λold) {q} = token to type({p}) {ˆq} = graph propagate({q}) D(1) u = viterbi decode({ˆq}, Λold) Λ(t) n+1 = crf-train(Dl ∪ D(1) u , Λ(t) n ) end while Return last Λ(t) simple (and convex) steps: Given a set of CRF parameters, we first compute marginals over the unlabeled data (posterior decode)</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Transductive inference for text classification using support vector machines. In Proc. of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Transductive learning via spectral graph partitioning.</title>
<date>2003</date>
<booktitle>In Proc. of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="2782" citStr="Joachims, 2003" startWordPosition="437" endWordPosition="438">road range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003; Belkin et al., 2005; Subramanya and Bilmes, 2009) are an important subclass of SSL techniques that have received much attention in the recent past, as they outperform other approaches and also scale easily to large problems. Here one assumes that the data (both labeled and unlabeled) is represented by vertices in a graph. Graph edges link vertices that are likely to have the same label. Edge weights govern how strongly the labels of the nodes linked by the edge should agree. Most previous work in SSL has focused on unstructured classification problems, that is,</context>
</contexts>
<marker>Joachims, 2003</marker>
<rawString>Thorsten Joachims. 2003. Transductive learning via spectral graph partitioning. In Proc. of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Judge</author>
<author>A Cahill</author>
<author>J van Genabith</author>
</authors>
<title>Questionbank: Creating a corpus of parse-annotated questions.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguist ics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>497--504</pages>
<marker>Judge, Cahill, van Genabith, 2006</marker>
<rawString>J. Judge, A. Cahill, and J. van Genabith. 2006. Questionbank: Creating a corpus of parse-annotated questions. In Proceedings of the 21st International Conference on Computational Linguist ics and 44th Annual Meeting of the Association for Computational Linguistics, pages 497–504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proc. of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="4880" citStr="Lafferty et al., 2001" startWordPosition="769" endWordPosition="772">eir objective is similar to that of manifold regularization (Belkin et al., 2005) and they make use of a graph as a smoothness regularizer. However their solution involves inverting a matrix whose size depends on problem size, making it impractical for very large problems. Brefeld and Scheffer (2006) present a modified version of the co-training algorithm for structured output spaces. In both of the above cases, the underlying model is based on structured SVM, which does not scale well to very large datasets. More recently Wang et al. (2009) proposed to train a conditional random field (CRF) (Lafferty et al., 2001) using an entropy-based regularizer. Their approach is similar to the entropy minimization algorithm (Grandvalet and Bengio, 2005). The problem here is that their objective is not convex and thus can pose issues for large problems. Further, graphbased SSL algorithms outperform algorithms based on entropy minimization (Chapelle et al., 2007). In this work, we propose a graph-based SSL method for CRFs that is computationally practical for very large problems, unlike the methods in the studies cited above. Our method is scalable because it trains with efficient standard building blocks for CRF in</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N D Lawrence</author>
<author>M I Jordan</author>
</authors>
<title>Semi-supervised learning via gaussian processes.</title>
<date>2005</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="15443" citStr="Lawrence and Jordan, 2005" startWordPosition="2603" endWordPosition="2606">ertices in the similarity graph can help disambiguate ambiguous contexts and correct (some of) the errors of the supervised model. 4 Semi-Supervised CRF Given unlabeled data D,,, we only have access to the prior p(x). As the CRF is a discriminative model, the lack of label information renders the CRF weights independent of p(x) and thus we cannot directly utilize the unlabeled data when training the CRF. Therefore, semi-supervised approaches to training discriminative models typically use the unlabeled data to construct a regularizer that is used to guide the learning process (Joachims, 1999; Lawrence and Jordan, 2005). Here we use the graph as a smoothness regularizer to train CRFs in a semisupervised manner. Our algorithm iterates between the following five 170 Algorithm 1 Semi-Supervised CRF Training Λs = crf-train(Dl, Λ0) Set Λ(t) 0= Λ(s) while not converged do {p} = posterior decode(Du, Λold) {q} = token to type({p}) {ˆq} = graph propagate({q}) D(1) u = viterbi decode({ˆq}, Λold) Λ(t) n+1 = crf-train(Dl ∪ D(1) u , Λ(t) n ) end while Return last Λ(t) simple (and convex) steps: Given a set of CRF parameters, we first compute marginals over the unlabeled data (posterior decode). The marginals over tokens </context>
</contexts>
<marker>Lawrence, Jordan, 2005</marker>
<rawString>N. D. Lawrence and M. I. Jordan. 2005. Semi-supervised learning via gaussian processes. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>PennBioIE</author>
</authors>
<title>Mining the bibliome project.</title>
<date>2005</date>
<note>In http://bioie.ldc.upenn.edu/.</note>
<contexts>
<context position="25987" citStr="PennBioIE, 2005" startWordPosition="4423" endWordPosition="4424">ably unnecessary, we randomly select 100,000 of these queries and treat this as D&amp;quot;. Because the graph nodes and the features used in the similarity function are based on n-grams, data sparsity can be a serious problem, and we therefore use the entire unlabeled data set for graph construction. We estimate the mutual information-based features for each trigram type over all the 10 million questions, and then construct the graph over only the set of trigram types that actually occurs in the 100,000 random subset and the WSJ training set. For our second target domain, we use the Penn BioTreebank (PennBioIE, 2005). This corpus consists of 1,061 sentences that have been manually annotated with POS tags. We used the first 500 sentences as a development set and the remaining 561 sentences as our final test set. The high unknown word rate (23.27%) makes this corpus very difficult to tag. Furthermore, the POS tag set for this data is a super-set of the Penn Treebank’s, including the two new tags HYPH (for hyphens) and AFX (for common post-modifiers of biomedical entities such as genes). These tags were introduced due to the importance of hyphenated entities in biomedical text, and are used for 1.8% of the w</context>
</contexts>
<marker>PennBioIE, 2005</marker>
<rawString>PennBioIE. 2005. Mining the bibliome project. In http://bioie.ldc.upenn.edu/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H J Scudder</author>
</authors>
<title>Probability of Error of some Adaptive Pattern-Recognition Machines.</title>
<date>1965</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>11</volume>
<contexts>
<context position="1621" citStr="Scudder, 1965" startWordPosition="253" endWordPosition="254">oduction Semi-supervised learning (SSL) is the use of small amounts of labeled data with relatively large amounts of unlabeled data to train predictors. In some cases, the labeled data can be sufficient to provide reasonable accuracy on in-domain data, but performance on even closely related out-of-domain data may lag far behind. Annotating training data for all sub-domains of a varied domain such as all of Web text is impractical, giving impetus to the development of SSL techniques that can learn from unlabeled data to perform well across domains. The earliest SSL algorithm is self-training (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chape</context>
</contexts>
<marker>Scudder, 1965</marker>
<rawString>H. J. Scudder. 1965. Probability of Error of some Adaptive Pattern-Recognition Machines. IEEE Transactions on Information Theory, 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Seeger</author>
</authors>
<title>Learning with labeled and unlabeled data.</title>
<date>2000</date>
<tech>Technical report,</tech>
<institution>University of Edinburgh, U.K.</institution>
<contexts>
<context position="2203" citStr="Seeger, 2000" startWordPosition="343" endWordPosition="344"> self-training (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaak</context>
</contexts>
<marker>Seeger, 2000</marker>
<rawString>M. Seeger. 2000. Learning with labeled and unlabeled data. Technical report, University of Edinburgh, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>G Satta</author>
<author>A Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In ACL ’07.</booktitle>
<contexts>
<context position="6442" citStr="Shen et al., 2007" startWordPosition="1021" endWordPosition="1024">eled data from the target domain. The state posteriors on the target domain are then smoothed using the graph regularizer. Best state sequences for the unlabeled target data are then created by Viterbi decoding with the smoothed state posteriors, and this automatic target domain annotation is combined with the labeled source domain data to retrain the CRF. We demonstrate our new method in domain adaptation for a CRF part-of-speech (POS) tagger. While POS tagging accuracies have reached the level of inter-annotator agreement (&gt;97%) on the standard PennTreebank test set (Toutanova et al., 2003; Shen et al., 2007), performance on out-of-domain data is often well below 90%, impairing language processing tasks that need syntactic information. For example, on the question domain used in this paper, the tagging accuracy of a supervised CRF is only 84%. Our domain adaptation algorithm improves performance to 87%, which is still far below in-domain performance, but a significant reduction in error. 2 Supervised CRF We assume that we have a set of labeled source domain examples Dl = {(xi, yi)}li=1, but only unlabeled target domain examples Du = {xi}l+u i=l+1. Here xi = x(1) i x(2) i · · · x(|Xi|) i is the seq</context>
<context position="27372" citStr="Shen et al., 2007" startWordPosition="4660" endWordPosition="4663"> chosen by searching MEDLINE for abstracts pertaining to cancer, in particular genomic variations and mutations (Blitzer et al., 2006). Since we did not have access to additional unlabeled data, we used the same set of sentences as target domain unlabeled data, D&amp;quot;. The graph here was constructed over the 100,000 unlabeled sentences and the WSJ training set. Finally, we remind the reader that we did not use label information for graph construction in either corpus. 6.1 Baselines Our baseline supervised CRF is competitive with state-of-the-art discriminative POS taggers (Toutanova et al., 2003; Shen et al., 2007), achieving 97.17% on the WSJ development set (sections 19- 21). We use a fairly standard set of features, including word identity, suffixes and prefixes and detectors when, etc.), and have between 30 and 160 characters. 173 Questions Bio Dev Eval Dev Eval Supervised CRF 84.8 83.8 86.5 86.2 Self-trained CRF 85.4 84.0 87.5 87.1 Semi-supervised CRF 87.6 86.8 87.5 87.6 Table 2: Domain adaptation experiments. POS tagging accuracies in %. for special characters such as dashes and digits. We do not use of observation-dependent transition features. Both supervised and semi-supervised models are regul</context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>L. Shen, G. Satta, and A. Joshi. 2007. Guided learning for bidirectional sequence classification. In ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sindhwani</author>
<author>P Niyogi</author>
<author>M Belkin</author>
</authors>
<title>Beyond the point cloud: from transductive to semi-supervised learning.</title>
<date>2005</date>
<booktitle>In Proc. of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="23834" citStr="Sindhwani et al., 2005" startWordPosition="4064" endWordPosition="4067">l. (2009) also constrain similar trigrams to have similar POS tags by forming cliques of similar trigrams and maximizing the agreement score over these cliques. Computing clique agreement potentials however is NP-hard and so they propose approximation algorithms that are still quite complex computationally. We achieve similar effects by using our simple, scalable convex graph regularization framework. Further, unlike other graph-propagation algorithms (Alexandrescu and Kirchhoff, 2009), our approach is inductive. While one might be able to make inductive extensions of transductive approaches (Sindhwani et al., 2005), these usually require extensive computational resources at test time. 6 Experiments and Results We use the Wall Street Journal (WSJ) section of the Penn Treebank as our labeled source domain training set. We follow standard setup procedures for this task and train on sections 00-18, comprising of 38,219 POS-tagged sentences with a total of 912,344 words. To evaluate our domain-adaptation approach, we consider two different target domains: questions and biomedical data. Both target domains are relatively far from the source domain (newswire), making this a very challenging task. The QuestionB</context>
</contexts>
<marker>Sindhwani, Niyogi, Belkin, 2005</marker>
<rawString>V. Sindhwani, P. Niyogi, and M. Belkin. 2005. Beyond the point cloud: from transductive to semi-supervised learning. In Proc. of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Subramanya</author>
<author>J A Bilmes</author>
</authors>
<title>Entropic graph regularization in non-parametric semi-supervised classification.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Society (NIPS),</booktitle>
<location>Vancouver, Canada,</location>
<contexts>
<context position="2864" citStr="Subramanya and Bilmes, 2009" startWordPosition="447" endWordPosition="450">7; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003; Belkin et al., 2005; Subramanya and Bilmes, 2009) are an important subclass of SSL techniques that have received much attention in the recent past, as they outperform other approaches and also scale easily to large problems. Here one assumes that the data (both labeled and unlabeled) is represented by vertices in a graph. Graph edges link vertices that are likely to have the same label. Edge weights govern how strongly the labels of the nodes linked by the edge should agree. Most previous work in SSL has focused on unstructured classification problems, that is, problems with a relatively small set of atomic labels. There 167 Proceedings of t</context>
</contexts>
<marker>Subramanya, Bilmes, 2009</marker>
<rawString>A. Subramanya and J. A. Bilmes. 2009. Entropic graph regularization in non-parametric semi-supervised classification. In Neural Information Processing Society (NIPS), Vancouver, Canada, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C D Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>HLT-NAACL ’03.</booktitle>
<contexts>
<context position="6422" citStr="Toutanova et al., 2003" startWordPosition="1017" endWordPosition="1020"> uses it to decode unlabeled data from the target domain. The state posteriors on the target domain are then smoothed using the graph regularizer. Best state sequences for the unlabeled target data are then created by Viterbi decoding with the smoothed state posteriors, and this automatic target domain annotation is combined with the labeled source domain data to retrain the CRF. We demonstrate our new method in domain adaptation for a CRF part-of-speech (POS) tagger. While POS tagging accuracies have reached the level of inter-annotator agreement (&gt;97%) on the standard PennTreebank test set (Toutanova et al., 2003; Shen et al., 2007), performance on out-of-domain data is often well below 90%, impairing language processing tasks that need syntactic information. For example, on the question domain used in this paper, the tagging accuracy of a supervised CRF is only 84%. Our domain adaptation algorithm improves performance to 87%, which is still far below in-domain performance, but a significant reduction in error. 2 Supervised CRF We assume that we have a set of labeled source domain examples Dl = {(xi, yi)}li=1, but only unlabeled target domain examples Du = {xi}l+u i=l+1. Here xi = x(1) i x(2) i · · · </context>
<context position="27352" citStr="Toutanova et al., 2003" startWordPosition="4656" endWordPosition="4659">,000 sentences that were chosen by searching MEDLINE for abstracts pertaining to cancer, in particular genomic variations and mutations (Blitzer et al., 2006). Since we did not have access to additional unlabeled data, we used the same set of sentences as target domain unlabeled data, D&amp;quot;. The graph here was constructed over the 100,000 unlabeled sentences and the WSJ training set. Finally, we remind the reader that we did not use label information for graph construction in either corpus. 6.1 Baselines Our baseline supervised CRF is competitive with state-of-the-art discriminative POS taggers (Toutanova et al., 2003; Shen et al., 2007), achieving 97.17% on the WSJ development set (sections 19- 21). We use a fairly standard set of features, including word identity, suffixes and prefixes and detectors when, etc.), and have between 30 and 160 characters. 173 Questions Bio Dev Eval Dev Eval Supervised CRF 84.8 83.8 86.5 86.2 Self-trained CRF 85.4 84.0 87.5 87.1 Semi-supervised CRF 87.6 86.8 87.5 87.6 Table 2: Domain adaptation experiments. POS tagging accuracies in %. for special characters such as dashes and digits. We do not use of observation-dependent transition features. Both supervised and semi-supervi</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>K. Toutanova, D. Klein, C. D. Manning, and Y. Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In HLT-NAACL ’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wang</author>
<author>G Haffari</author>
<author>S Wang</author>
<author>G Mori</author>
</authors>
<title>A rate distortion approach for semi-supervised conditional random fields.</title>
<date>2009</date>
<contexts>
<context position="4805" citStr="Wang et al. (2009)" startWordPosition="757" endWordPosition="760">argin objective for semi-supervised learning over structured spaces. Their objective is similar to that of manifold regularization (Belkin et al., 2005) and they make use of a graph as a smoothness regularizer. However their solution involves inverting a matrix whose size depends on problem size, making it impractical for very large problems. Brefeld and Scheffer (2006) present a modified version of the co-training algorithm for structured output spaces. In both of the above cases, the underlying model is based on structured SVM, which does not scale well to very large datasets. More recently Wang et al. (2009) proposed to train a conditional random field (CRF) (Lafferty et al., 2001) using an entropy-based regularizer. Their approach is similar to the entropy minimization algorithm (Grandvalet and Bengio, 2005). The problem here is that their objective is not convex and thus can pose issues for large problems. Further, graphbased SSL algorithms outperform algorithms based on entropy minimization (Chapelle et al., 2007). In this work, we propose a graph-based SSL method for CRFs that is computationally practical for very large problems, unlike the methods in the studies cited above. Our method is sc</context>
</contexts>
<marker>Wang, Haffari, Wang, Mori, 2009</marker>
<rawString>Y. Wang, G. Haffari, S. Wang, and G. Mori. 2009. A rate distortion approach for semi-supervised conditional random fields.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1841" citStr="Yarowsky, 1995" startWordPosition="290" endWordPosition="291">nable accuracy on in-domain data, but performance on even closely related out-of-domain data may lag far behind. Annotating training data for all sub-domains of a varied domain such as all of Web text is impractical, giving impetus to the development of SSL techniques that can learn from unlabeled data to perform well across domains. The earliest SSL algorithm is self-training (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL wit</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
<author>J Lafferty</author>
</authors>
<title>Semisupervised learning using gaussian fields and harmonic functions.</title>
<date>2003</date>
<booktitle>In Proc. of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="2141" citStr="Zhu et al., 2003" startWordPosition="331" endWordPosition="334"> data to perform well across domains. The earliest SSL algorithm is self-training (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL alg</context>
<context position="8441" citStr="Zhu et al., 2003" startWordPosition="1397" endWordPosition="1400">lso have access to the unlabeled data Du from the target domain which we would like to use for training the CRF. We first descri �A�2 `2-norm γ be how we construct a similarity A* =argmin ΛE[PK i=1 168 graph over the unlabeled which will be used in our algorithm as a graph regularizer. 3 Graph Construction Graph construction is the most important step in graph-based SSL. The standard approach for unstructured problems is to construct a graph whose vertices are labeled and unlabeled examples, and whose weighted edges encode the degree to which the examples they link should have the same label (Zhu et al., 2003). Then the main graph construction choice is what similarity function to use for the weighted edges between examples. However, in structured problems the situation is more complicated. Consider the case of sequence tagging we are studying. While we might be able to choose some appropriate sequence similarity to construct the graph, such as edit distance or a string kernel, it is not clear how to use whole sequence similarity to constrain whole tag sequences assigned to linked examples in the learning algorithm. Altun et al. (2005) had the nice insight of doing the graph construction not for co</context>
</contexts>
<marker>Zhu, Ghahramani, Lafferty, 2003</marker>
<rawString>X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semisupervised learning using gaussian fields and harmonic functions. In Proc. of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
</authors>
<title>Semi-supervised learning literature survey.</title>
<date>2005</date>
<tech>Technical Report 1530,</tech>
<institution>Computer Sciences, University of Wisconsin-Madison.</institution>
<contexts>
<context position="2214" citStr="Zhu, 2005" startWordPosition="345" endWordPosition="346"> (Scudder, 1965), where one makes use of a previously trained model to annotate unlabeled data which is then used to re-train the model. While self-training is widely used and can yield good results in some applications (Yarowsky, 1995), it has no theoretical guarantees except under certain stringent conditions, which rarely hold in practice(Haffari and Sarkar, 2007). Other SSL methods include co-training (Blum and Mitchell, 1998), transductive support vector machines (SVMs) (Joachims, 1999), and graph-based SSL (Zhu et al., 2003). Several surveys cover a broad range of methods (Seeger, 2000; Zhu, 2005; Chapelle et al., 2007; Blitzer and Zhu, 2008). A majority of SSL algorithms are computationally expensive; for example, solving a transductive SVM exactly is intractable. Thus we have a conflict between wanting to use SSL with large unlabeled data sets for best accuracy, but being unable to do so because of computational complexity. Some researchers attempted to resolve this conflict by resorting to approximations (Collobert et al., 2006), but those lead to suboptimal results (Chapelle et al., 2007). Graph-based SSL algorithms (Zhu et al., 2003; Joachims, 2003; Corduneanu and Jaakkola, 2003;</context>
</contexts>
<marker>Zhu, 2005</marker>
<rawString>X. Zhu. 2005. Semi-supervised learning literature survey. Technical Report 1530, Computer Sciences, University of Wisconsin-Madison.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>