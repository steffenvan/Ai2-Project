<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000125">
<note confidence="0.630911">
COMPUTER AIDED INTERPRETATION OF LEXICAL COOCCURRENCES
</note>
<author confidence="0.962311">
Paola Velardi (*)
Maria Teresa Pazienza (**)
</author>
<affiliation confidence="0.999129">
()University of Ancona, Istituto di Informatica, via Brecce Bianche, Ancona
(&amp;quot;)University of Roma, Dip. di Informatica e Sistemistica, via Buonarroti 12, Roma
</affiliation>
<sectionHeader confidence="0.96327" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999948684210527">
This paper addresses the problem of developing a
large semantic lexicon for natural language
processing. The increasing availability of machine
readable documents offers an opportunity to the
field of lexical semantics, by providing experimental
evidence of word uses (on-line texts) and word
definitions (on-line dictionaries).
The system presented hereafter, PETRARCA,
detects word cooccurrences from a large sample of
press agency releases on finance and economics,
and uses these associations to build a case-based
semantic lexicon. Synt.ctically valid cooccurences
including a new word W are detected by a
high-coverage morphosyntactic analyzer. Syntactic
relations are interpreted e.g. replaced by case
relations, using a a catalogue of
patterns/interpretation pairs, a concept type
hierarchy, and a set of selectional restriction rules
on semantic interpretation types.
</bodyText>
<sectionHeader confidence="0.960969" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.980004">
Semantic knowledge codification for language
processing requires two important issues to be
considered:
I. Meaning representation. Each word is a world:
how can we conveniently circumscribe the
semantic information associated to a lexical
entry?
2. Acquisition. For a language processor to
implement a useful application, several
thousands of terms must have an entry in the
semantic lexicon: how do we cope with one
such a prohibitive task?
The problem of meaning representation is one
which preoccupied scientists of different disciplines
since the early history of human culture. We will
not attempt an overall survey of the field of
semantics, that provided material for many
fascinating books; rather, we will concentrate on
the computer science perspective, i.e. how do we
go about representing language expressions on a
computer, in a way that can be useful for natural
language processing applications, e.g. machine
translation, information retrieval, user-friendly
interfaces.
In the field of computational linguistics, several
approaches were followed for representing semantic
knowledge. We are not concerned here with
semantic languages, which are relatively well
developed; the diversity lies in the meaning
representation principles. We will classify the
methods of meaning representations in two
categories: conceptual (or deep) and collocative (or
surface). The terms &amp;quot;conceptual&amp;quot; and &amp;quot;collocative&amp;quot;
have been introduced in [8l; we decided to adopt an
existing terminology, even though our
interpretation of the above two categories is
broader than for their inventor.
I. Conceptual Meaning Conceptual meaning is the
cognitive content of words; it can be expressed
by features or by primitives. Conceptual
meaning is &amp;quot;deep&amp;quot; in that it expresses
phenomena that are deeply embedded in
language.
2. Collocative meaning. What is communicated
through associations between words or word
classes. Collocative meaning is &amp;quot;superficial&amp;quot; in
that does not seek for &amp;quot;the deep sense&amp;quot; of a
word, but rather it &apos;describes&amp;quot; its uses in
everyday language, or in some sub-world
</bodyText>
<page confidence="0.998031">
185
</page>
<bodyText confidence="0.999821408163265">
language (economy, computers, etc.). It
provides more than a simple analysis of
cooccurrences, because it attempts an
explanation of word associations in terms of
conceptual relations between a lexical item and
other items or classes.
Both conceptual and collocative meaning
representations are based on some subjective,
human-produced set of primitives (features,
conceptual dependencies, relations, type hierarchies
etc.) on which there is no shared agreement at the
current state of the art. As far as conceptual
meaning is concerned, the quality and quantity of
phenomena to be shown in a representation is
subjective as well. On the contrary, surface meaning
can rely on the solid evidence represented by word
associations; the interpretation of an association is
subjective, but valid associations are an observable,
even though vast, phenomenon. To confirm this,
one can notice that different implementations of
lexicons based on surface meaning are
surprisingly similar, whereas conceptual lexicons are
very dishomogeneous.
In principle, the inferential power of collocative, or
surface [18] meaning representation is lower than
for conceptual meaning. In our previous work on
semantic knowledge representation, however, [10]
[18] [12] we showed that a semantic dictionary in
the style of surface meaning is a useful basis for
semantic interpretation.
The knowledge power provided by the semantic
lexicon (limited to about 1000 manually entered
definitions) was measured by the capability of the.
language processor DANTE [2] [18] [11] to answer
a variety of questions concerning previously
analyzed sentences (press agency releases on finance
and economics). It was found that, even though
the system was unable to perform complex
inferences, it could successfully answer more than
90% of the questions [121&apos;. In other terms, surface
semantics seems to capture what, at first glance, a
human reader understands of a piece of text.
In[26] , the usefulness of this meaning
representation method is demonstrated for
TRANSALTOR, a system used for machine
translation in the field of computers.
An important advantage of surface meaning is that
makes it easier the acquisition of the semantic
lexicon. This issue is examined in the next section.
</bodyText>
<subsectionHeader confidence="0.919197">
Acquisition of Lexical Semantic
Knowledge.
</subsectionHeader>
<bodyText confidence="0.999933454545455">
Acquiring semantic knowledge on a systematic
basis is quite a complex task. One needs not to
look at metaphors or idioms to find this; even the
interpretation of apparently simple sentences is
riddled with such difficulties that makes it hard
even cutting out a piece of the problem. A manual
codification of the lexicon is a prohibitive task,
regardless of the framework adopted for semantic
knowledge representation; even when a large team
of knowledge enters is available, consistency and
completeness are a major problem. We believe
That automatic, or semi-automatic acquisition of
the lexicon is a critical factor in determining how
widespread the use of natural language processors
will be in the next few years. &apos;
Recently a few methods were presented for
computer aided semantic knowledge acquisition. A
widely used approach is accessing on-line dictionary
definitions to solve ambiguity problems [3] or to
derive type hierarchies and semantic features [24].
The information presented in a standard dictionary
has in our view some intrinsic limitation:
</bodyText>
<listItem confidence="0.995449666666667">
• definitions are often circular e.g. the definition
of a term A may refer to a term B that in turn
points to A;
• definitions are not homogeneous as far as the
quality and quantity of provided information:
they can be very sketchy, or give detailed
structural information, or list examples of
use-types, or attempt some conceptual meaning
definition;
• a dictionary is the result of a conceptualization
effort performed by some human specialist(s);
this effort may not be consistent with, or
</listItem>
<bodyText confidence="0.9982935">
The test was performed over a 6 month period on about 50 occasional visitors and staff members of the
IBM Rome scientific center, unaware of the system capabilities and structure. The user would look at 60
different releases, previously analyzed by the system (or re-analyzed during the demo), and freely asks
questions about the content of these texts. In the last few months, the test was extended to a different
domain, e.g. the Italian Constitution, without significant performance changes. See the referenced papers for
examples of sentences and of (answered and not answered) query types On general wh-questions).
</bodyText>
<page confidence="0.995704">
186
</page>
<figure confidence="0.962006636363636">
ext (from [8]):
boy = + animate -adult + male
ex2 (from (251):
help =
Y carrying out Z, X uses his resources W in order for W to help
Y to carry out Z; the use of resources by X and the carrying out of Z
by Y are simultaneous
ex2 (from (161):
throw =
actor PROPELS and object from a source LOCation to a
destination LOCation
</figure>
<figureCaption confidence="0.999213">
Figure I. Examples of conceptual meaning representation in the literature
</figureCaption>
<bodyText confidence="0.995425879310345">
suitable for, the objectives of an application for
which a language processor is built.
A second approach is using corpora rather than
human-oriented dictionary entries. Corpora provide
an experimental evidence of word uses, word
associations, and language phenomena as
metaphors, idioms, and metonymies.
The problem and at the same time the advantage of
corpora is that they are raw texts whereas
dictionary entries use some formal notation that
facilitates the task of linguistic data processing.
No computer program may ever be able to derive
formatted data from a completely unformatted
source. Hence the ability of extracting lexical
semantic information form a corpus depends upon
a powerful set of mapping rules between phrasal
patterns and human-produced semantic primitives
and relations. We do not believe that a semantic
representation framework is &amp;quot;good&amp;quot; if it mimics a
human cognitive model; more realistically, we
believe that a set of primitives, relations and
mapping rules is &amp;quot;fair&amp;quot;, when its coverage over a
language subworld is suitable for the purpose of
some useful language processing activity. Corpora
represent an &apos;objective&apos; description of that
subworld, against which it is possible to evaluate
the power of a representation scheme; and they are
particularly suitable for the acquisition of a
collocative meaning based semantic lexicon.
Besides our work [191, the only knowledge
acquisition system based on corpora (as far as we
know) is described in [71. In this work, when an
unknown word is encountered, the system uses
pre-existing knowledge on the context in which the
word occurred to derive its conceptual category.
The context is provided by on line texts in the
economic domain. For example, the unknown
word merger in &amp;quot;another merger offer&amp;quot; is
categorized as merger-transaction using semantic
knowledge on the word offer and on pre-analyzed
sentences referring to a previous offer event, as
suggested by the word another. This method is
interesting but relies upon a pre-existing semantic
lexicon and contextual knowledge; in our work, the
only pre-existing knowledge is the set of conceptual
relations and primitives.
PETRARCA: a method for the
acquisition and interpretation of
cooccurrences
PETRA RCA detects cooccurrences using a
powerful morphologic and syntactic analyzer [141
[11; cooccurences are interpreted by a set of
phrasal-patterns/ semantic-interpretation mapping
rules. The semantic language is Conceptual Graphs
[171; the adopted type hierarchy and conceptual
relations are described in [101. The following is a
summary description of the algorithm:
For any word W,
</bodyText>
<listItem confidence="0.8631185">
1. (A) Parse every sentence in the corpus that
uses W.
</listItem>
<bodyText confidence="0.820821333333333">
Ex: W = AGREEMENT
&amp;quot;Yesterday an agreement was reached among
the companies&amp;quot;.
</bodyText>
<page confidence="0.96519">
187
</page>
<figure confidence="0.986188529411765">
exl (from 1181):
agreement =
is_a decision_act
participant person, organization
theme transaction
cause conununication_exchange
manner interesting important effective..
ex2 (from PR:
person =
isa creature
agent_of take put find speech-action mental-action
consist of hand foot..
source_of speech-action
destination_of speech-action
power human
speed slow
mass human
</figure>
<figureCaption confidence="0.999735">
Figure 2. Examples of collocative meaning representation in the literature
</figureCaption>
<table confidence="0.925083047619048">
2. (A) Determine all syntactic attachments of W • step 3 might produce more than one
(e.g. syntactically valid cooccurrences) Ex: interpretation for a single word pattern, due to
the low selectivity of some semantic rule.
• step 3 might fail to produce an interpretation
NP_PP(AGREEMENT,AMONG,COMPANY). for metonymies and idioms, which violate
VP OBJ(TO REACH,AGREEMENT). semantic constraints. Strong syntactic evidence
(unambiguous syntactic rules) is used to
3. (A) Generate a semantic interpretation for &amp;quot;signal&amp;quot; the user this type of failure.
each attachment :
Ex: Knowledge sources used by PETRARCA
IAGREEMENTI-&gt; (PARTICIPANT)- &gt; (COMPANY].
4. (A) Generalize the interpretations.
Ex: Given the following examples:
(AGREEMENT).&apos; (PARTICIPANT). &gt; /COMPANY).
[AGREEMENT). &gt; (PARTICIPANT).&apos; ICOUNTRY-ORGANIZATIONI.
(AGREEMENT). &gt; (PARTICIPANT). &gt; [PRESIDENTI.
derive the most general constraint:
(AGREEMENT)., (PARTICIPANT). &gt; RIUMAN_ENTITYI. The
above is a new case description added to the
definition of AGREEMENT
5. (M) Check the newly derived entry.
</table>
<tableCaption confidence="0.879234666666667">
Steps marked (A) are automatic; steps marked (M)
are manual. The only manual step is the last one:
this step is however necessary because of the
following:
To perform its analysis, PETRARCA uses five
knowledge sources:
</tableCaption>
<listItem confidence="0.971077909090909">
1. an on line natural corpus (press agency
releases) to select a variety of language
expressions including a new word W;
2. a high coverage morphosyntactic analyzer, to
derive phrasal patterns centered around W;
3. a catalogue of patterns/interpretation pairs,
called Syntax-to-Semantic (SS rules);
4. a set of rules expressing selectional restriction
on conceptual relation uses (CR rules);
5. a hierarchy of conceptual classes and a
catalogue associating to words concept types.
</listItem>
<bodyText confidence="0.99266525">
The natural corpus and the parser are used in steps
1 and 2 of the above algorithm; SS rules, CR rules
and the word/concept catalogue are used in step 3;
the type hierarchy is used in steps 3 and 4
</bodyText>
<page confidence="0.994034">
188
</page>
<bodyText confidence="0.9991763">
The parser used by PETRARCA is a high coverage
morphosyntactic analyzer developed in the context
of the DANTE system. The lexical parser is based
on a Context Free grammar, the complete set of
Italian prefixes and suffixes, and a lexicon of 7000
elementary lemmata (stems without affixes). At
present, the morphologic component has an 100%
coverage over the analyzed corpus (100,000 words)
(141114
The syntactic analysis determines syntactic
attachment between words by verifying grammar
rules and forms agreement; the system is based on
an Attribute Grammar, augmented with lookahead
sets II; the coverage is about 80%; when compiled,
the parsing time is around 1-2 sec. of CPU time for
a sentence with 3-4 prepositional phrases; the CPU
is an IBM mainframe.
The syntactic relations detected by the parser are
associated to possible semantic interpretations using
SS rules. An excerpt of SS rules is given below for
</bodyText>
<equation confidence="0.62171925">
the phrasal pattern:
noun_phrase(NP)+ prepositional_phrase(PP)
(di= of).
NP_PP(*wordi,di.&apos;word3) &lt; rel(POSSESSAI,•word2.&apos;word1).
</equation>
<table confidence="0.975838466666667">
Pane di Pietro (the dog of Peter)&apos;/
NP_PP(*wordl,d1,•word2) &lt; rel(SOC RELATION,d1,•word2,•word1).
ria madre di Piero (the mather of Peter)&apos;/
NP_PP(•word1411,*word2) &lt; • rel(PART1CIPANT,di,•wordi,*word2).
Priunione del delepli (the meeting of the delegates)&apos;/
NP_PP(wort11,d1.&apos;word2) C. rel(SUBSET,d1.*wordMword1).
/&apos;due di not (two of us)&apos;/
NP PP(&apos;wordl,di,*word1) &lt; • rel(PART 01,41.&apos;word2,*word1).
rp;gine del libro (the pages of the book)&apos;!
NP PP(*wonil.di,•word2) C. rel(MATTE12,41,.wordl,•word2).
/*mien° di levy) (an object of wood)&apos;/
NP PP(&apos;wordl.di.&apos;word2) &lt; - rel(PRODUCER,01,*wordl,•word2).
/*nil/pito dei leoni (the roar of the lions)&apos;/
NP PP(*wordl,d1,*word2) &lt; rei(CHARACTERISTIC411,4vord2,*word1).
dell&apos;uomo (the intelligence of the man)/
</table>
<bodyText confidence="0.985073754716981">
Overall, we adopted about 50 conceptual relations
to describe the set of semantic relations commonly
found in language; see 1101 for a complete list. The
catalogue of SS rules includes about 200 pairs.
Given a phrasal pattern produced by the syntactic
parser, SS rules select a first set of conceptual
relations that are candidate interpretations for the
pattern.
Selectional restriction rules on conceptual relations
are used to select a unique interpretation, when
possible. Writing CR rules was a very complex
task, that required a process of progressive
refinement based on the observation of the results.
The following is an example of CR rule for the
conceptual relation PARTICIPANT:
participant =
has_participant: meeting, agreement, fly, sail
is_participant: human_entity
Examples of phrasal patterns interpreted by the
participant relation are:
John flies ( to New York); the meeting among
parties; the march of the pacifists, a contract
between Fiat and Alfa; the assembly of the
administrators, etc.
An interesting result of the above algorithm is the
following: in general, syntax will also accept
semantically invalid cooccurrences. In addition, in
step 3, ambiguous words can be replaced by the
&amp;quot;wrong&amp;quot; concept names. Despite this, selectional
restrictions are able to interpret only valid
associations and reject the others. For example,
consider the sentence: &amp;quot;The party decided a new
strategy&amp;quot;. The syntax detects the association
SUBJ(DECIDE,PARTY). Now, the word &amp;quot;party&amp;quot;
has two concept names associated with it:
POL_PARTY, and FEAST, hence in step 3 both
interpretations are examined. I lowever, no
conceptual relation is found to interpret the pattern
&amp;quot;FEAST DECIDE&amp;quot;. This association is hence
rejected.
Simalirily, in the sentence: &amp;quot;An agreement is
reached among the companies, the syntactic
analyzer will submit to the semantic interpreter two
associations:
NP_PP(AGREEMENT,AMONG,COMPANY) and
VP_PP(REACII,AMONG,COMPAN1&apos;) . Now,
the preposition among in the SS rules, points to
such conceptual relations as PARTICIPANT,
SUBSET (e.g. &amp;quot;two among all us&amp;quot;), and
LOCATION (e.g. &amp;quot;a pine among the trees&amp;quot;), but
none of the above relates a MOVE_ACT with a
IIUMAN_ORGANIZATION. The association is
hence rejected.
</bodyText>
<subsectionHeader confidence="0.638755">
Future experimentation issues
</subsectionHeader>
<bodyText confidence="0.93390125">
This section highlights the current limitations and
experimentation issues with PETRARCA.
Definition of type hierarchies
PETRA RCA gets as input not only the word W,
but a list of concept labels CWi, corresponding to
the possible senses of W. For each of these CWi,
the supertype in the hierarchy must be provided.
Notice .however that the system knows nothing
</bodyText>
<page confidence="0.998027">
189
</page>
<bodyText confidence="0.991561113402062">
about conceptual classes; the hierarchy is only an
ordered set of labels.
In order to assign a supertype to a concept, three
methods are currently being investigated. First, a
program may &amp;quot;guide&amp;quot; the user towards the choice of
the appropriate supertype, visiting top down the
hierarchy. This approach is similar to the one
described in 1261.
Alternatively, the user may give a list of
synonymous or near synonymous words. If one of
these was already included in the hierarchy, the
same supertype is proposed to the user.
A third method lets the system propose the
supertype. The system assumes CW = W and
proceeds through steps 1, 2 and 3 of the case
descriptions derivation procedure. As the supertype
of CW is unknown, CR rules are less effective at
determining a unique interpretation of syntactic
patterns. If in some of these patterns the partner
word is already defined in the dictionary, its case
descriptions can be used to restrict the analysis.
For example, suppose that the word president is
unknown in:
The president nominated etc.
Pertirii was a good president&apos;
the knowledge on possible AGENTs for
NOMINATE let us infer
PRESIDENT &lt; HUMAN ENTITY; from the
second sentence, it is possible to further restrict to:
PRESIDENT &lt; HUMAN_ROLE. The third
method is interesting because it is automatic,
however it has some drawbacks. For example, it is
slow as compared to methods 1 and 2; a trained
user would rather use his experience to decide a
supertype. Secondly, if the word is found with
different meanings in the sample sentences, the
system might never get to a consistent solution.
Finally, if the database includes very few or vague
examples, the answer may be useless (e.g. ACT, or
TOP). It should also be considered that the effort
required to assign a supertype to, say, 10.000 words
is comparable with the encoding of the
morphologic lexicon. This latter required about one
month of data entry by 5-6 part-time researchers,
plus about 2-3 months for an extensive testing.
The complexity of hierarchically organizing
concepts however, is not circumscribed to the time
consumed in associating a type label to some
thousand words. All NLP researchers
experimented the difficulty of associating concept
types to words in a consistent way. Despite the
efforts, no commonly accepted hierarchies have
been proposed so far. In our view, there is no
evidence in humans of primitive conceptual
categories, except for a few categories as animacy,
time, etc. We should perhaps accept the very fact
that type hierarchies are a computer method to be
used in NLP systems for representing semantic
knowledge in a more compact form. Accordingly,
we are starting a research on semi-automatic word
clustering (in some given language subworld
described by a natural corpus), based on fuzzy set
and conceptual clustering theories.
Interpretation of idiomatic expressions
In the current version of PETRA RCA, in case of
idiomatic expressions the user must provide the
correct interpretation. In case of metaphors,
syntactic evidence is used to detect a metaphor,
under the hypothesis that input sentences to the
system are syntactically and semantically correct.
At the current state of implementation, the system
does not provide automatic interpretation of
metaphors. IIowever, an interesting method was
proposed in 1201. According to this method, when
for example a pattern such as &amp;quot;car drinks&amp;quot; is
detected, the system uses knowledge of canonical
definitions of the concepts &amp;quot;DRINK&amp;quot; and &amp;quot;CAR&amp;quot;
to establish whether &amp;quot;CAR&amp;quot; is used metaphorically
as a IIUMAN_ENTITY, or &amp;quot;DRINK&amp;quot; is used
metaphorically as &amp;quot;TO_BE_FED_BY&amp;quot;. An
interesting user aided computer program for
idiomatic expressions analysis is also described in
1231.
Generalization of case descriptions
In PF,RTRA RCA, phrasal patterns are first
mapped into &apos;low level&amp;quot; case description; in step 4,
&amp;quot;similar&amp;quot; patterns are merged into &amp;quot;high level&apos; case
descriptions. In a first implementation, two or
three low level case descriptions had to be derived
before creating a more general semantic rule. This
approach is biased by the availability of example
sentences. A word often occurs in dozens of
different contexts, and only occasionally two
phrasal patterns reflect the same semantic relation.
For example, consider the sentences:
The company signs a contract for new funding
The ACE stipulates a contract to increase its influence
</bodyText>
<page confidence="0.993559">
190
</page>
<bodyText confidence="0.889841">
Restricting ourselves to the word &amp;quot;contract, we get
the following semantic interpretations of syntactic
patterns:
Lim (THEM/1}.(CONTRACTI
</bodyText>
<note confidence="0.841469">
21CONTRACT)-.(PURPOSE).. (FUNDING)
34STIPULATE)..(THEME)..iCONTRACTI
4.1CONTRACT1-. (PURPOS8)-. (INCREASE)
</note>
<bodyText confidence="0.9477734">
In patterns 1 and 3 &apos;sign&apos; and &amp;quot;stipulate&amp;quot; belong to
the same suPertYPe, i.e.
INFORMATION EXCHANGE; hence a new
case description can be tentatively created for
CONTRACT:
</bodyText>
<sectionHeader confidence="0.622983" genericHeader="method">
(CONTRACRI., (THEME)., (INFORMATION EXCHANGE)
</sectionHeader>
<bodyText confidence="0.998105833333333">
Indeed, one can tell, talk about, describe etc. a
contract.
Conversely, patterns 3 and 4 have no common
supertype; hence two low level&apos; case descriptions
are added to the definition of CONTRACT.
(CONTRACT)., (PURPOSE)-&apos; (FUNDING)
(CONTRACT). . (PURPOSE)- . (INCREASE)
Even with a large number of input sentences, the
system creates many of these specific patterns; a
human user must review the results and provide for
case descriptions generalization when he/she feels
this being reasonable.
A second approach is to generalize on the basis of
a single example, and then retract (split) the rule if
a counterexample is found. Currently, we are
studying different policies and comparing the
results; one interesting issue is the exploitation of
counterexamples.
</bodyText>
<subsectionHeader confidence="0.884786">
Concluding remarks
</subsectionHeader>
<bodyText confidence="0.999936944444444">
Even though PETRARCA is still an experiment
and has many unsolved issues, it is, to our
knowledge, the first reported system for extensive
semantic knowledge acquisition. There is room for
many improvements; for example, PETRARCA
only detects, but does not interpret idioms; neither
it knows what to do with errors; if a wrong
interpretation of a phrasal pattern is derived, error
correction and refinement of the knowledge base is
performed by the programmer. However
PETRARCA is able to process automatically raw
language expressions and to perform a first
classification and encoding of these data. The rich
linguistic material produced by PETRARCA
provides a basis for future analysis and refinements.
Despite its limitations, we believe this method
being a first, useful step towards a more complete
system of language learning.
</bodyText>
<sectionHeader confidence="0.998807" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999216275862069">
[Ij F. Antonacci, P. Velardi, M.T. Pazienza, A
High Coverage Grammar for the Italian
Language, Journal of the Assoc. for Literary
and Linguistic Computing, in print 1988.
[21 F. Antonacci, M.T. Pazienza, M. Russo,
P.Velardi, Representation and Control
Strategies for large Knowledge Domains : an
Application to NLP, Journal of Applied
Artificial Intelligence, in print 1988.
JL. Binot and K. Jensen A Semantic Expert
Using an On-line Standard Dictionary
Proceedings of the IJCAI Milano, 1987
K. Dahlgren and J. McDowell Kind Types in
Knowledge Representation Proceedings of the
Coling-86 1986
Ileidorn G.E. &amp;quot;Augmented Phrase Structure
Grammar&amp;quot; in &apos;Theoretical Issues in Natural
Language Processing&apos; Nash-Webber and
Schank ,eds,ACL 1975
161 J. Katz, P. Postal An Integrated Theory of
Linguistic Descriptions Cambridge, M.I.T.
Press, 1964.
[71 P. Jacobs, U. Zernik Acquiring Lexical
Knowledge from Text: a Case Study,
Proceedings of the AAA188, St. Paul, August
1988
181 Geoffrey Leech Semantics: The Study of
Meaning second edition, Penguin Books 1981.
191 Michalsky R.S., Carbonell J.C., Mitchell
T.M. Machine Learning vol I Tioga
Publishing Company Palo Alto, 1983
[101 M.T. Pazienza and P. Velardi, A Structured
Representation of Word Senses for Semantic
Analysis Third Conference of the European
1 9 1
Chapter of the ACL, Copenhagen, April 1-3
1987.
[11] M.T. Pazienza and P. Velardi, Integrating
Conceptual Graphs and Logic in a Natural
Language Understanding System, in &amp;quot;Natural
Language Understanding and Logic
Programming II&amp;quot;, V. Dahl and P.
Saint-Dizier editors, North-Holland, 1988.
[12] M.T. Pazienza, P. Velardi, Using a Semantic
Knowledge Base to Support A Natural
Language Interface to a Text Database, 7th
International Conference on
Entity-Relationship Approach, Rome,
November 16-18 1988.
[13] M. Russo, A Rule Based System for the
Morphologic and Morphosyntactic Analysis of
the Italian Language, in &amp;quot;Natural Language
Understanding and Logic Programming II&amp;quot;,
V. Dahl and P. Saint-Dizier editors,
North-Holland, 1988.
[14] M. Russo, A Generative Grammar-Approach
for the Morphologic and Morphosyntactic
Analysis of Italian, Third Conference of the
European Chapter of the ACL, Copenhagen,
April 1-3 1987.
Shank R.C. Conceptual Dependency: a
theory of natural language understanding.
Cognitive Psicolov, vol 3 1972
Shank R.C, Goldman, Rieger, Riesbeck
Conceptual Information Processing
Noth-Hollandlamerican Elsevier 1975
J. F. Sowa, Conceptual Structures:
Information Processing in Mind and Machine,
Addison-Wesley, Reading, 1984.
1181 P. Velardi, M.T. Pazienza and M.
DeGiovanetti, Conceptual Graphs for the
Analysis and generation of sentences, IBM
Journal of Research and Development, March
1988.
1191 P. Velardi, M.T. Pazienza, S. Magrini
Acquisition of Semantic Patterns from a
natural corpus of texts ACM-SIGART special
issue on knowledge acquisition in print
1201 E. Way Dinamic Type Hierachies: An
Approach to Knowledge Representation
through Metaphor PhD dissertation, Dept. of
System Science, State Univ. of NY at
Binghamton 1987.
[211 Y. Wilks, Preference Semantics Memoranda
from the Artificial Intelligence Laboratory,
Stanford University Stanford, 1973
1221 Y. Wilks, Deep and Superficial Parsing, in
&amp;quot;Parsing natural Language&amp;quot; M. King editor,
Academic Press, 1983.
[231 U. Zernik Strategies in Language Acquisition:
Learning Phrases from Examples in
Contexts. Phd dissertation, Tech. Rept.
UCLA-AI-87-1, University of California, Los
Angeles 1987
[24] R. Byrd, N. Calzolari, M. Chodorow, J.
Klavans, M. Neff, 0. Rizk Large lexicons for
Natural Language Processing: Utilizing the
grammar Coding System of LDOCE
Computational Linguistics, special issue of the
Lexicon D. Walker, A. Zampolli, N. Calzolari
editors July-December 1987 1987.
[251 I. Mercuk, A. Polguere A Formal Lexicon in
Meaning-Text Theory (or How To Do Lexica
with Words) Computational Linguistics,
special issue of the Lexicon D. Walker, A.
Zampolli, N. Calzolari editors July-December
1987 1987.
[26] S. Nirenburg, V. Raskin The Subworld
Concept Lexicon and the Lexicon
Management System Computational
Linguistics, special issue of the Lexicon D.
Walker, A. Zampolli, N. Calzolari editors
July-December 1987 1987.
[27] J. Pustejovsky Constraints on the Acquisition
of Semantic Knowledge, Journal of Intelligent
Information Systems, vol 3, n. 3, fall 1988
</reference>
<page confidence="0.998196">
192
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.876634">
<title confidence="0.997247">COMPUTER AIDED INTERPRETATION OF LEXICAL COOCCURRENCES</title>
<author confidence="0.968093">Paola Velardi Maria Teresa Pazienza</author>
<address confidence="0.970988">of Ancona, Istituto di Informatica, Brecce Bianche, Ancona of Roma, Dip. di Informatica e Sistemistica, Buonarroti 12, Roma</address>
<abstract confidence="0.99980325">This paper addresses the problem of developing a large semantic lexicon for natural language processing. The increasing availability of machine readable documents offers an opportunity to the field of lexical semantics, by providing experimental evidence of word uses (on-line texts) and word definitions (on-line dictionaries). The system presented hereafter, PETRARCA, detects word cooccurrences from a large sample of press agency releases on finance and economics, and uses these associations to build a case-based semantic lexicon. Synt.ctically valid cooccurences including a new word W are detected by a high-coverage morphosyntactic analyzer. Syntactic interpreted replaced by case relations, using a a catalogue of patterns/interpretation pairs, a concept type hierarchy, and a set of selectional restriction rules on semantic interpretation types.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>A High Coverage Grammar for the Italian Language, Journal of the Assoc. for Literary and Linguistic Computing, in print</title>
<date>1988</date>
<marker>1988</marker>
<rawString>[Ij F. Antonacci, P. Velardi, M.T. Pazienza, A High Coverage Grammar for the Italian Language, Journal of the Assoc. for Literary and Linguistic Computing, in print 1988.</rawString>
</citation>
<citation valid="true">
<title>Representation and Control Strategies for large Knowledge Domains : an Application to NLP,</title>
<date>1988</date>
<journal>Journal of Applied Artificial Intelligence, in print</journal>
<marker>1988</marker>
<rawString>[21 F. Antonacci, M.T. Pazienza, M. Russo, P.Velardi, Representation and Control Strategies for large Knowledge Domains : an Application to NLP, Journal of Applied Artificial Intelligence, in print 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Binot</author>
<author>K Jensen</author>
</authors>
<title>A Semantic Expert Using an On-line Standard Dictionary</title>
<date>1987</date>
<booktitle>Proceedings of the IJCAI</booktitle>
<location>Milano,</location>
<marker>Binot, Jensen, 1987</marker>
<rawString>JL. Binot and K. Jensen A Semantic Expert Using an On-line Standard Dictionary Proceedings of the IJCAI Milano, 1987 K. Dahlgren and J. McDowell Kind Types in Knowledge Representation Proceedings of the Coling-86 1986</rawString>
</citation>
<citation valid="true">
<authors>
<author>G E Ileidorn</author>
</authors>
<title>Augmented Phrase Structure Grammar&amp;quot; in &apos;Theoretical Issues</title>
<date>1975</date>
<booktitle>in Natural Language Processing&apos; Nash-Webber and Schank ,eds,ACL</booktitle>
<marker>Ileidorn, 1975</marker>
<rawString>Ileidorn G.E. &amp;quot;Augmented Phrase Structure Grammar&amp;quot; in &apos;Theoretical Issues in Natural Language Processing&apos; Nash-Webber and Schank ,eds,ACL 1975</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Katz</author>
<author>P</author>
</authors>
<title>Postal An Integrated Theory of Linguistic Descriptions Cambridge,</title>
<date>1964</date>
<publisher>M.I.T. Press,</publisher>
<marker>Katz, P, 1964</marker>
<rawString>161 J. Katz, P. Postal An Integrated Theory of Linguistic Descriptions Cambridge, M.I.T. Press, 1964.</rawString>
</citation>
<citation valid="true">
<title>Zernik Acquiring Lexical Knowledge from Text: a Case Study,</title>
<date>1988</date>
<booktitle>Proceedings of the AAA188, St.</booktitle>
<location>Paul,</location>
<marker>1988</marker>
<rawString>[71 P. Jacobs, U. Zernik Acquiring Lexical Knowledge from Text: a Case Study, Proceedings of the AAA188, St. Paul, August 1988</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey</author>
</authors>
<title>Leech Semantics: The Study of Meaning second edition,</title>
<date>1981</date>
<publisher>Penguin Books</publisher>
<marker>Geoffrey, 1981</marker>
<rawString>181 Geoffrey Leech Semantics: The Study of Meaning second edition, Penguin Books 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Michalsky</author>
<author>J C Carbonell</author>
<author>T M Mitchell</author>
</authors>
<date>1983</date>
<booktitle>Machine Learning vol I Tioga Publishing Company</booktitle>
<location>Palo Alto,</location>
<marker>Michalsky, Carbonell, Mitchell, 1983</marker>
<rawString>191 Michalsky R.S., Carbonell J.C., Mitchell T.M. Machine Learning vol I Tioga Publishing Company Palo Alto, 1983</rawString>
</citation>
<citation valid="true">
<title>A Structured Representation of Word Senses for Semantic Analysis Third</title>
<date>1987</date>
<journal>Conference of the European</journal>
<booktitle>Chapter of the ACL,</booktitle>
<volume>1</volume>
<location>Copenhagen,</location>
<marker>1987</marker>
<rawString>[101 M.T. Pazienza and P. Velardi, A Structured Representation of Word Senses for Semantic Analysis Third Conference of the European 1 9 1 Chapter of the ACL, Copenhagen, April 1-3 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Pazienza</author>
<author>P Velardi</author>
</authors>
<title>Integrating Conceptual Graphs and Logic in a Natural Language Understanding System, in &amp;quot;Natural Language Understanding and Logic Programming II&amp;quot;,</title>
<date>1988</date>
<editor>V. Dahl and P. Saint-Dizier editors,</editor>
<publisher>North-Holland,</publisher>
<marker>Pazienza, Velardi, 1988</marker>
<rawString>[11] M.T. Pazienza and P. Velardi, Integrating Conceptual Graphs and Logic in a Natural Language Understanding System, in &amp;quot;Natural Language Understanding and Logic Programming II&amp;quot;, V. Dahl and P. Saint-Dizier editors, North-Holland, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Pazienza</author>
<author>P Velardi</author>
</authors>
<title>Using a Semantic Knowledge Base to Support A Natural Language Interface to a Text Database,</title>
<date></date>
<marker>Pazienza, Velardi, </marker>
<rawString>[12] M.T. Pazienza, P. Velardi, Using a Semantic Knowledge Base to Support A Natural Language Interface to a Text Database, 7th</rawString>
</citation>
<citation valid="true">
<date>1988</date>
<booktitle>International Conference on Entity-Relationship Approach,</booktitle>
<location>Rome,</location>
<marker>1988</marker>
<rawString>International Conference on Entity-Relationship Approach, Rome, November 16-18 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Russo</author>
</authors>
<title>A Rule Based System for the Morphologic and Morphosyntactic Analysis of the Italian Language, in &amp;quot;Natural Language Understanding and Logic Programming II&amp;quot;,</title>
<date>1988</date>
<editor>V. Dahl and P. Saint-Dizier editors,</editor>
<publisher>North-Holland,</publisher>
<marker>Russo, 1988</marker>
<rawString>[13] M. Russo, A Rule Based System for the Morphologic and Morphosyntactic Analysis of the Italian Language, in &amp;quot;Natural Language Understanding and Logic Programming II&amp;quot;, V. Dahl and P. Saint-Dizier editors, North-Holland, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Russo</author>
</authors>
<title>A Generative Grammar-Approach for the Morphologic and Morphosyntactic Analysis of Italian,</title>
<date>1987</date>
<booktitle>Third Conference of the European Chapter of the ACL,</booktitle>
<location>Copenhagen,</location>
<marker>Russo, 1987</marker>
<rawString>[14] M. Russo, A Generative Grammar-Approach for the Morphologic and Morphosyntactic Analysis of Italian, Third Conference of the European Chapter of the ACL, Copenhagen, April 1-3 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Shank</author>
</authors>
<title>Conceptual Dependency: a theory of natural language understanding.</title>
<date>1972</date>
<journal>Cognitive Psicolov,</journal>
<volume>3</volume>
<marker>Shank, 1972</marker>
<rawString>Shank R.C. Conceptual Dependency: a theory of natural language understanding. Cognitive Psicolov, vol 3 1972</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Shank</author>
<author>Rieger Goldman</author>
</authors>
<date>1975</date>
<booktitle>Riesbeck Conceptual Information Processing Noth-Hollandlamerican Elsevier</booktitle>
<marker>Shank, Goldman, 1975</marker>
<rawString>Shank R.C, Goldman, Rieger, Riesbeck Conceptual Information Processing Noth-Hollandlamerican Elsevier 1975</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Sowa</author>
</authors>
<title>Conceptual Structures:</title>
<date>1984</date>
<booktitle>Information Processing in Mind and Machine,</booktitle>
<publisher>Addison-Wesley,</publisher>
<location>Reading,</location>
<marker>Sowa, 1984</marker>
<rawString>J. F. Sowa, Conceptual Structures: Information Processing in Mind and Machine, Addison-Wesley, Reading, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Velardi</author>
<author>M T Pazienza</author>
<author>M DeGiovanetti</author>
</authors>
<title>Conceptual Graphs for the Analysis and generation of sentences,</title>
<date>1988</date>
<journal>IBM Journal of Research</journal>
<marker>Velardi, Pazienza, DeGiovanetti, 1988</marker>
<rawString>1181 P. Velardi, M.T. Pazienza and M. DeGiovanetti, Conceptual Graphs for the Analysis and generation of sentences, IBM Journal of Research and Development, March 1988.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Velardi</author>
<author>M T Pazienza</author>
<author>S</author>
</authors>
<title>Magrini Acquisition of Semantic Patterns from a natural corpus of texts ACM-SIGART special issue on knowledge acquisition</title>
<note>in print</note>
<marker>Velardi, Pazienza, S, </marker>
<rawString>1191 P. Velardi, M.T. Pazienza, S. Magrini Acquisition of Semantic Patterns from a natural corpus of texts ACM-SIGART special issue on knowledge acquisition in print</rawString>
</citation>
<citation valid="true">
<authors>
<author>E</author>
</authors>
<title>Way Dinamic Type Hierachies: An Approach to Knowledge Representation through Metaphor</title>
<date>1987</date>
<tech>PhD dissertation,</tech>
<institution>Dept. of System Science, State Univ. of NY at Binghamton</institution>
<marker>E, 1987</marker>
<rawString>1201 E. Way Dinamic Type Hierachies: An Approach to Knowledge Representation through Metaphor PhD dissertation, Dept. of System Science, State Univ. of NY at Binghamton 1987.</rawString>
</citation>
<citation valid="true">
<title>Preference Semantics Memoranda from the Artificial Intelligence Laboratory,</title>
<date>1973</date>
<location>Stanford University Stanford,</location>
<marker>1973</marker>
<rawString>[211 Y. Wilks, Preference Semantics Memoranda from the Artificial Intelligence Laboratory, Stanford University Stanford, 1973</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
</authors>
<title>Deep and Superficial Parsing, in &amp;quot;Parsing natural Language&amp;quot;</title>
<date>1983</date>
<editor>M. King editor,</editor>
<publisher>Academic Press,</publisher>
<marker>Wilks, 1983</marker>
<rawString>1221 Y. Wilks, Deep and Superficial Parsing, in &amp;quot;Parsing natural Language&amp;quot; M. King editor, Academic Press, 1983.</rawString>
</citation>
<citation valid="true">
<title>Zernik Strategies in Language Acquisition: Learning Phrases from Examples in Contexts.</title>
<date>1987</date>
<tech>Phd dissertation, Tech. Rept. UCLA-AI-87-1,</tech>
<institution>University of California,</institution>
<location>Los Angeles</location>
<marker>1987</marker>
<rawString>[231 U. Zernik Strategies in Language Acquisition: Learning Phrases from Examples in Contexts. Phd dissertation, Tech. Rept. UCLA-AI-87-1, University of California, Los Angeles 1987</rawString>
</citation>
<citation valid="true">
<date>1987</date>
<booktitle>Large lexicons for Natural Language Processing: Utilizing the grammar Coding System of LDOCE Computational Linguistics, special issue of the Lexicon</booktitle>
<editor>[24] R. Byrd, N. Calzolari, M. Chodorow, J. Klavans, M. Neff, 0. Rizk</editor>
<marker>1987</marker>
<rawString>[24] R. Byrd, N. Calzolari, M. Chodorow, J. Klavans, M. Neff, 0. Rizk Large lexicons for Natural Language Processing: Utilizing the grammar Coding System of LDOCE Computational Linguistics, special issue of the Lexicon D. Walker, A. Zampolli, N. Calzolari editors July-December 1987 1987.</rawString>
</citation>
<citation valid="true">
<title>Polguere A Formal Lexicon</title>
<date>1987</date>
<booktitle>in Meaning-Text Theory (or How To Do Lexica with Words) Computational Linguistics, special issue of the Lexicon</booktitle>
<editor>D. Walker, A. Zampolli, N. Calzolari editors July-December</editor>
<marker>1987</marker>
<rawString>[251 I. Mercuk, A. Polguere A Formal Lexicon in Meaning-Text Theory (or How To Do Lexica with Words) Computational Linguistics, special issue of the Lexicon D. Walker, A. Zampolli, N. Calzolari editors July-December 1987 1987.</rawString>
</citation>
<citation valid="true">
<date>1987</date>
<booktitle>The Subworld Concept Lexicon and the Lexicon Management System Computational Linguistics, special issue of the Lexicon</booktitle>
<editor>[26] S. Nirenburg, V. Raskin</editor>
<marker>1987</marker>
<rawString>[26] S. Nirenburg, V. Raskin The Subworld Concept Lexicon and the Lexicon Management System Computational Linguistics, special issue of the Lexicon D. Walker, A. Zampolli, N. Calzolari editors July-December 1987 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J</author>
</authors>
<title>Pustejovsky Constraints on the Acquisition of Semantic Knowledge,</title>
<date>1988</date>
<journal>Journal of Intelligent Information Systems,</journal>
<volume>3</volume>
<pages>fall</pages>
<marker>J, 1988</marker>
<rawString>[27] J. Pustejovsky Constraints on the Acquisition of Semantic Knowledge, Journal of Intelligent Information Systems, vol 3, n. 3, fall 1988</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>