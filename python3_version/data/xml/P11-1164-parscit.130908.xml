<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.999183">
Extracting Comparative Entities and Predicates from Texts Using
Comparative Type Classification
</title>
<author confidence="0.99831">
Seon Yang Youngjoong Ko
</author>
<affiliation confidence="0.862158">
Department of Computer Engineering, Department of Computer Engineering,
Dong-A University, Dong-A University,
Busan, Korea Busan, Korea
</affiliation>
<email confidence="0.995555">
seony.yang@gmail.com yjko@dau.ac.kr
</email>
<sectionHeader confidence="0.998575" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999179230769231">
The automatic extraction of comparative in-
formation is an important text mining
problem and an area of increasing interest.
In this paper, we study how to build a
Korean comparison mining system. Our
work is composed of two consecutive tasks:
1) classifying comparative sentences into
different types and 2) mining comparative
entities and predicates. We perform various
experiments to find relevant features and
learning techniques. As a result, we achieve
outstanding performance enough for
practical use.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999752826086957">
Almost every day, people are faced with a situation
that they must decide upon one thing or the other.
To make better decisions, they probably attempt to
compare entities that they are interesting in. These
days, many web search engines are helping people
look for their interesting entities. It is clear that
getting information from a large amount of web
data retrieved by the search engines is a much
better and easier way than the traditional survey
methods. However, it is also clear that directly
reading each document is not a perfect solution. If
people only have access to a small amount of data,
they may get a biased point of view. On the other
hand, investigating large amounts of data is a time-
consuming job. Therefore, a comparison mining
system, which can automatically provide a
summary of comparisons between two (or more)
entities from a large quantity of web documents,
would be very useful in many areas such as
marketing.
We divide our work into two tasks to effectively
build a comparison mining system. The first task is
related to a sentence classification problem and the
second is related to an information extraction
problem.
Task 1. Classifying comparative sentences into
one non-comparative class and seven
comparative classes (or types); 1) Equality, 2)
Similarity, 3) Difference, 4) Greater or lesser, 5)
Superlative, 6) Pseudo, and 7) Implicit
comparisons. The purpose of this task is to
efficiently perform the following task.
Task 2. Mining comparative entities and
predicates taking into account the characteristics
of each type. For example, from the sentence
“Stock-X is worth more than stock-Y.” belonging
to “4) Greater or lesser” type, we extract “stock-
X” as a subject entity (SE), “stock-Y” as an
object entity (OE), and “worth” as a comparative
predicate (PR).
These tasks are not easy or simple problems as
described below.
Classifying comparative sentences (Task 1): For
the first task, we extract comparative sentences
from text documents and then classify the
extracted comparative sentences into seven
</bodyText>
<page confidence="0.929571">
1636
</page>
<note confidence="0.897428">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1636–1644,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
reports our experimental results and finally Section
6 concludes.
</note>
<sectionHeader confidence="0.962826" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998053">
comparative types. Our basic idea is a keyword
search. Since Ha (1999a) categorized dozens of
Korean comparative keywords, we easily build an
initial keyword set as follows:
</bodyText>
<listItem confidence="0.983443">
▪ Кling = {“같 ([gat]: same)”, “보다 ([bo-da]: than)”,
“가장 ([ga-jang]: most)”, ...}
</listItem>
<bodyText confidence="0.983933285714286">
In addition, we easily match each of these
keywords to a particular type anchored to Ha&apos;s
research, e.g., “같 ([gat]: same)” to “1) Equality”,
“보다 ([bo-da]: than)” to “4) Greater or lesser”.
However, any method that depends on just these
linguistic-based keywords has obvious limitations
as follows:
</bodyText>
<listItem confidence="0.995328833333333">
1) Кling is insufficient to cover all of the actual
comparison expressions.
2) There are many non-comparative sentences
that contain some elements of Кling.
3) There is no one-to-one relationship between
keyword types and sentence types.
</listItem>
<bodyText confidence="0.99205325">
Mining comparative entities and predicates
(Task 2): Our basic idea for the second task is
selecting candidates first and finding answers from
the candidates later. We regard each of noun words
as a candidate for SE/OE, and each of adjective (or
verb) words as a candidate for PR. However, this
candidate detection has serious problems as
follows:
</bodyText>
<listItem confidence="0.976355833333333">
4) There are many actual SEs, OEs, and PRs that
consist of multiple words.
5) There are many sentences with no OE,
especially among superlative sentences. It
means that the ellipsis is frequently occurred in
superlative sentences.
</listItem>
<bodyText confidence="0.999961035087719">
We focus on solving the above five problems.
We perform various experiments to find relevant
features and proper machine learning techniques.
The final experimental results in 5-fold cross
validation show the overall accuracy of 88.59% for
the first task and the overall accuracy of 86.81%
for the second task.
The remainder of the paper is organized as
follows. Section 2 briefly introduces related work.
Section 3 and Section 4 describe our first task and
second task in detail, respectively. Section 5
Linguistic researchers focus on defining the syntax
and semantics of comparative constructs. Ha
(1999a; 1999b) classified the structures of Korean
comparative sentences into several classes and
arranged comparison-bearing words from a
linguistic perspective. Since he summarized the
modern Korean comparative studies, his research
helps us have a linguistic point of view. We also
refer to Jeong (2000) and Oh (2004). Jeong
classified adjective superlatives using certain
measures, and Oh discussed the gradability of
comparatives.
In computer engineering, we found five previous
studies related to comparison mining. Jindal and
Liu (2006a; 2006b) studied to mine comparative
relations from English text documents. They used
comparative and superlative POS tags, and some
additional keywords. Their methods applied Class
Sequential Rules and Label Sequential Rules.
Yang and Ko (2009; 2011) studied to extract
comparative sentences in Korean text documents.
Li et al. (2010) studied to mine comparable entities
from English comparative questions that users
posted online. They focused on finding a set of
comparable entities given a user&apos;s input entity.
Opinion mining is also related to our work
because many comparative sentences also contain
the speaker&apos;s opinion/sentiment. Lee et al. (2008)
surveyed various techniques that have been
developed for the key tasks of opinion mining.
Kim and Hovy (2006) introduced a methodology
for analyzing judgment opinion. Riloff and Wiebe
(2003) presented a bootstrapping process that
learns linguistically rich extraction patterns for
subjective expressions.
In this study, three learning techniques are
employed: the maximum entropy method (MEM)
as a representative probabilistic model, the support
vector machine (SVM) as a kernel model, and
transformation-based learning (TBL) as a rule-
based model. Berger et al. (1996) presented a
Maximum Entropy Approach to natural language
processing. Joachims (1998) introduced SVM for
text classification. Various TBL studies have been
performed. Brill (1992; 1995) first introduced TBL
and presented a case study on part-of-speech
</bodyText>
<page confidence="0.988698">
1637
</page>
<bodyText confidence="0.98578775">
tagging. Ramshaw and Marcus (1995) applied
TBL for locating chunks in tagged texts. Black and
Vasilakopoulos (2002) used a modified TBL
technique for Named Entity Recognition.
</bodyText>
<sectionHeader confidence="0.944814" genericHeader="method">
3 Classifying Comparative Sentences
(Task 1)
</sectionHeader>
<bodyText confidence="0.999976">
We first classify the sentences into comparatives
and non-comparatives by extracting only
comparatives from text documents. Then we
classify the comparatives into seven types.
</bodyText>
<subsectionHeader confidence="0.996425">
3.1 Extracting comparative sentences from
text documents
</subsectionHeader>
<bodyText confidence="0.972837402985075">
Our strategy is to first detect Comparative
Sentence candidates (CS-candidates), and then
eliminate non-comparative sentences from the
candidates. As mentioned in the introduction
section, we easily construct a linguistic-based
keyword set, Kling. However, we observe that Kling
is not enough to capture all the actual comparison
expressions. Hence, we build a comparison lexicon
as follows:
▪ Comparison Lexicon = Kling U {Additional
keywords that are frequently used for actual
comparative expressions}
This lexicon is composed of three parts. The first
part includes the elements of Kling and their
synonyms. The second part consists of idioms. For
example, an idiom “X 7} T_31,�] -kVr+ [X-ga meon-jeo
u-seot-da]” commonly means “The winner is X”
while it literally means “X laughed first”. The last
part consists of long-distance-words sequences,
e.g., “&lt;X - [X-neun], �n} [ji-man], Y - [Y-neun], r+
[da]&gt;”. This sequence means that the sentence is
formed as &lt; S(X) + V + but + S(Y) + V &gt; in
English (S: subject phrase; V: verb phrase; X, Y:
proper nouns). We could regard a word, “�]n} ([ji-
man]: but),” as a single keyword. However, this
word also captures numerous non-comparative
sentences. Namely, the precision value can fall too
much due to this word. By using long-distance-
words sequences instead of single keywords, we
can keep the precision value from dropping
seriously low.
The comparison lexicon finally has a total of
177 elements. We call each element “CK”
hereafter. Note that our lexicon does not include
comparative/superlative POS tags. Unlike English,
there is no Korean comparative/superlative POS
tag from POS tagger commonly. Our lexicon
covers 95.96% of the comparative sentences in our
corpus. It means that we successfully defined a
comparison lexicon for CS-candidate detection.
However, the lexicon shows a relatively low
precision of 68.39%. While detecting CS-
candidates, the lexicon also captures many non-
comparative sentences, e.g., following Ex1:
▪ Ex1. “Ll]° ° Tom]°l _2_40- 31 ;-r+.” ([nai-il-eun ju-
sik-i o-reul-geot gat-da]: I think stock price will
rise tomorrow.)
This sentence is a non-comparative sentence even
though it contains a CK, “;-[gat].” This CK
generally means “same,” but it often expresses
“conjecture.” Since it is an adjective in both cases,
it is difficult to distinguish the difference.
To effectively filter out non-comparative
sentences from CS-candidates, we use the
sequences of “continuous POS tags within a radius
of 3 words from each CK” as features. Each word
in the sequence is replaced with its POS tag in
order to reflect various expressions. However, as
CKs play the most important role, they are
represented as a combination of their lexicalization
and POS tag, e.g., “;-/pa1.” Finally, the feature has
the form of “X 4 y” (“X” means a sequence and
“y” means a class; y1: comparative, y2: non-
comparative). For instance, “&lt;pv etm nbn ;-/pa ef
sf 2 &gt;4 y2” is one of the features from Ex1
sentence. Finally, we achieved an f1-score of
90.23% using SVM.
</bodyText>
<subsectionHeader confidence="0.9630095">
3.2 Classifying comparative sentences into
seven types
</subsectionHeader>
<bodyText confidence="0.9924776">
As we extract comparative sentences successfully,
the next step is to classify the comparatives into
different types. We define seven comparative types
and then employ TBL for comparative sentence
classification.
We first define six broad comparative types
based on modern Korean linguistics: 1) Equality,
2) Similarity, 3) Difference, 4) Greater or lesser,
5) Superlative, 6) Pseudo comparisons. The first
five types can be understood intuitively, whereas
</bodyText>
<footnote confidence="0.93626">
1 The POS tag “pa” means “the stem of an adjective”.
2 The labels such as “pv”, “etm” are Korean POS Tags.
</footnote>
<page confidence="0.992471">
1638
</page>
<bodyText confidence="0.999378">
the sixth type needs more explanation. “6) Pseudo”
comparison includes comparative sentences that
compare two (or more) properties of one entity
such as “Smartphone-X is a computer rather than a
phone.” This type of sentence is often classified
into “4) Greater or lesser.” However, since this
paper focuses on comparisons between different
entities, we separate “6) Pseudo” type from “4)
Greater or lesser” type.
The seventh type is “7) Implicit” comparison. It
is added with the goal of covering literally
“implicit” comparisons. For example, the sentence
“Shopping Mall X guarantees no fee full refund,
but Shopping Mall Y requires refund-fee” does not
directly compare two shopping malls. It implicitly
gives a hint that X is more beneficial to use than Y.
It can be considered as a non-comparative sentence
from a linguistic point of view. However, we
conclude that this kind of sentence is as important
as the other explicit comparisons from an
engineering point of view.
After defining the seven comparative types, we
simply match each sentences to a particular type
based on the CK types; e.g., a sentence which
contains the word “7P9 ([ga-jang]: most)” is
matched to “Superlative” type. However, a method
that uses just the CK information has a serious
problem. For example, although we easily match
the CK “-V-r+ ([bo-da]: than)” to “Greater or lesser”
without doubt, we observe that the type of CK
itself does not guarantee the correct type of the
sentence as we can see in the following three
sentences:
</bodyText>
<listItem confidence="0.995020642857143">
▪ Ex2. “X .5�1 W` V Y -V-r+ a xl_= `T _H xl_= %r+.” ([X-
eui pum-jil-eun Y-bo-da jo-chi-do na-ppeu-ji-do an-
ta]: The quality of X is neither better nor worse
than that of Y.) 4 It can be interpreted as “The
quality of X is similar to that of Y.” (Similarity)
▪ Ex3. “X 7} Y -V-r+ W` V01 ar+.” ([X-ga Y-bo-da pum-
jil-I jo-ta]: The quality of X is better than that of
Y.) 4 It is consistent with the CK type
(Greater or lesser)
▪ Ex4. “X 3_= r+ --O- oj�l 7}Ml4-V-r+ W` V01 ar+.” ([X-
neun da-reun eo-tteon ka-me-ra-bo-da pum-jil-i jo-
ta]: X is better than any other cameras in
quality.) 4 It can be interpreted as “X is the
best camera in quality.” (Superlative)
</listItem>
<bodyText confidence="0.997403769230769">
If we only rely on the CK type, we should label the
above three sentences as “Greater or lesser”.
However, each of these three sentences belongs to
a different type. This fact addresses that many CKs
could have an ambiguity problem just like the CK
of “-V-r+ ([bo-da]: than).”
To solve this ambiguity problem, we employ
TBL. We first roughly annotate the type of
sentences using the type of CK itself. After this
initial annotating, TBL generates a set of error-
driven transformation rules, and then a scoring
function ranks the rules. We define our scoring
function as Equation (1):
</bodyText>
<equation confidence="0.989611">
Score(r;) = C; - E; (1)
</equation>
<bodyText confidence="0.998083">
Here, ri is the i-th transformation rule, C; is the
number of corrected sentences after ri is applied,
and E; is the number of the opposite case. The
ranking process is executed iteratively. The
iterations stop when the scoring function reaches a
certain threshold. We finally set up the threshold
value as 1 after tuning. This means that we use
only the rules whose score is 2 or more.
</bodyText>
<sectionHeader confidence="0.7190045" genericHeader="method">
4 Mining Comparative Entities and
Predicates (Task 2)
</sectionHeader>
<bodyText confidence="0.999960454545455">
This section explains how to extract comparative
entities and predicates. Our strategy is to first
detect Comparative Element candidates (CE-
candidates), and then choose the answer among the
candidates.
In this paper, we only present the results of two
types: “Greater or lesser” and “Superlative.” As
we will see in the experiment section, these two
types cover 65.8% of whole comparative sentences.
We are still studying the other five types and plan
to report their results soon.
</bodyText>
<subsectionHeader confidence="0.982683">
4.1 Comparative elements
</subsectionHeader>
<bodyText confidence="0.9800535">
We extract three kinds of comparative elements in
this paper: SE, OE and PR
</bodyText>
<listItem confidence="0.864449428571429">
▪ Ex5. “X *017} Y *01-V-r+ ,4a 311-5ar+.” ([X-pa-i-ga
Y-pa-i-bo-da ssa-go mas-it-da]: Pie X is cheaper
and more delicious than Pie Y.)
▪ Ex6. “u lO 4--V-R s Z 7} 7P9 J1 0-31t}r+.” ([dai-
seon hu-bo-deul jung Z-ga ga-jang mit-eum-jik-
ha-da]: “Z is the most trustworthy among the
presidential candidates.”)
</listItem>
<page confidence="0.984037">
1639
</page>
<bodyText confidence="0.999972956521739">
In Ex5 sentence, “X 파이 (Pie X)” is a SE, “Y 파이
(Pie Y)” is an OE, and “싸고 맛있다 (cheaper and
more delicious)” is a PR. In Ex6 sentence, “Z” is a
SE, “대선 후보들 (the presidential candidates)” is an
OE, and “믿음직하다 (trustworthy)” is a PR.
Note that comparative elements are not limited
to just one word. For example, “싸고 맛있다
(cheaper and more delicious)” and “대선 후보들 (the
presidential candidates)” are composed of multiple
words. After investigating numerous actual
comparison expressions, we conclude that SEs,
OEs, and PRs should not be limited to a single
word. It can miss a considerable amount of
important information to restrict comparative
elements to only one word. Hence, we define as
follows:
In addition to the above examples, several
processes are performed. We regard all the “N”s as
CE-candidates for SE/OE and all the “P”s as CE-
candidates for PR. It is possible that a more
analytic method is used instead of this
simplification task, e.g., by a syntactic parser. We
leave this to our future work.
</bodyText>
<subsectionHeader confidence="0.999303">
4.3 Finding final answers
</subsectionHeader>
<bodyText confidence="0.999342">
We now generate features. The patterns that
consist of POS tags, CKs, and “P”/“N” sequences
within a radius of 4 POS tags from each “N” or
“P” are considered as features.
</bodyText>
<equation confidence="0.888445333333333">
“X 파이가 Y 파이보다 싸고 맛있다.”
(Pie X is cheaper and more
delicious than Pie Y.)
</equation>
<bodyText confidence="0.822690866666667">
Original
sentence
▪ Comparative elements (SE, OE, and PR) are After POS X 파이/nq + 가/jcs + Y 파이/nq +
composed of one or more consecutive words. tagging 보다/jca + 싸/pa + 고/ecc + 맛있/pa +
다/ef +./sf
It should also be noted that a number of superlative
sentences are expressed without OE. In our corpus,
the percentage of the Superlative sentences without
any OE is close to 70%. Hence, we define as
follows:
After
simplification
process
Patterns for
SE
</bodyText>
<equation confidence="0.999227">
X 파이/N(SE) + 가/jcs +
Y 파이/N(OE) + 보다/jca +
싸고맛있다/P(PR) + ./sf
</equation>
<bodyText confidence="0.420355333333333">
&lt;N(SE), jcs, N, 보다/jca,P&gt;, ...,
&lt;N(SE), jcs&gt;
▪ OEs can be omitted in the Superlative sentences.
</bodyText>
<subsectionHeader confidence="0.897566">
4.2 Detecting CE-candidates
</subsectionHeader>
<bodyText confidence="0.994188823529412">
As comparative elements are allowed to have
multiple words, we need some preprocessing steps
for easy detection of CE-candidates. We thus apply
some simplification processes. Through the
simplification processes, we represent potential
SEs/OEs as one “N” and potential PRs as one “P”.
The following process is one of the simplification
processes for making “N”
- Change each noun (or each noun compound) to
a symbol “N”.
And, the following two example processes are for
“P”.
- Change “pa (adjective)” and “pv (verb)” to a
symbol “P”.
- Change “P + ecc (a suffix whose meaning is
“and”) + P” to one “P”, e.g., “cheaper and
more delicious” is tagged as one “P”.
</bodyText>
<table confidence="0.95684125">
Patterns for &lt;N, jcs, N(OE), 보다/jca,P, sf&gt;, ...,
OE &lt;N(OE), 보다/jca &gt;
Patterns for &lt;N, jcs, N, 보다/jca,P(PR), sf&gt;, ...,
PR &lt;P(PR), sf&gt;
</table>
<tableCaption confidence="0.748256">
Table 1: Feature examples for mining comparative
elements
Table 1 lists some examples. Since the CKs play
</tableCaption>
<bodyText confidence="0.994860285714286">
an important role, they are represented as a
combination of their lexicalization and POS tag.
After feature generation, we calculate each
probability value of all CE-candidates using SVM.
For example, if a sentence has three “P”s, one “P”
with the highest probability value is selected as the
answer PR.
</bodyText>
<sectionHeader confidence="0.997853" genericHeader="evaluation">
5 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.932868">
5.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.9999948">
The experiments are conducted on 7,384 sentences
collected from the web by three trained human
labelers. Firstly, two labelers annotated the corpus.
A Kappa value of 0.85 showed that it was safe to
say that the two labelers agreed in their judgments.
</bodyText>
<page confidence="0.977074">
1640
</page>
<bodyText confidence="0.947595333333333">
in overall experiments, we employ SVM as our
proposed learning technique. Table 3 summarizes
the overall results.
Systems Precision Recall F1-score
Secondly, the third labeler annotated the
conflicting part of the corpus. All three labelers
discussed any conflict, and finally reached an
agreement. Table 2 lists the distribution of the
corpus.
</bodyText>
<figure confidence="0.72443235">
baseline 87.86 72.57 79.49
Comparative Sentence comparison lexicon 68.39 95.96 79.87
Types Portion only
Non-comparative: 5,001 (67.7%)
Comparative: 2,383 (32.3%)
Total (Corpus) 7,384 (100%)
comparison lexicon
&amp; SVM
(proposed)
92.24 88.31 90.23
1) Equality 3.6%
2) Similarity 7.2%
Among 3) Difference 4.8%
Comparative
Sentences
4) Greater or lesser 54.5%
5) Superlative 11.3%
6) Pseudo 1.3%
7) Implicit 17.5%
Total (Comparative) 100%
</figure>
<tableCaption confidence="0.91415">
Table 2: Distribution of the corpus
</tableCaption>
<subsectionHeader confidence="0.999742">
5.2 Classifying comparative sentences
</subsectionHeader>
<bodyText confidence="0.999980272727273">
Our experimental results for Task 1 showed an f1-
score of 90.23% in extracting comparative
sentences from text documents and an accuracy of
81.67% in classifying the comparative sentences
into seven comparative types.
The integrated results showed an accuracy of
88.59%. Non-comparative sentences were regarded
as an eighth comparative type in this integrated
result. It means that we classify entire sentences
into eight types (seven comparative types and one
non-comparative type).
</bodyText>
<subsectionHeader confidence="0.971">
5.2.1 Extracting comparative sentences.
</subsectionHeader>
<bodyText confidence="0.954933043478261">
Before evaluating our proposed method for
comparative sentence extraction, we conducted
four experiments with all of the lexical unigrams
and bigrams using MEM and SVM. Among these
four cases, SVM with lexical unigrams showed the
highest performance, an f1-score of 79.49%. We
regard this score as our baseline performance.
Next, we did experiments using all of the
continuous lexical sequences and using all of the
POS tags sequences within a radius of n words
from each CK as features (n=1,2,3,4,5). Among
these ten cases, “the POS tags sequences within a
radius of 3” showed the best performance. Besides,
as SVM showed the better performance than MEM
Table 3: Final results in comparative sentence
extraction (%)
As given above, we successfully detected CS-
candidates with considerably high recall by using
the comparison lexicon. We also successfully
filtered the candidates with high precision while
still preserving high recall by applying machine
learning technique. Finally, we could achieve an
outstanding performance, an f1-score of 90.23%.
</bodyText>
<subsectionHeader confidence="0.756117">
5.2.2 Classifying comparative sentences into
seven types.
</subsectionHeader>
<bodyText confidence="0.999963384615385">
Like the previous comparative sentence extraction
task, we also conducted experiments for type
classification using the same features (continuous
POS tags sequences within a radius of 3 words
from each CK) and the same learning technique
(SVM). Here, we achieved an accuracy of 73.64%.
We regard this score as our baseline performance.
Next, we tested a completely different technique,
the TBL method. TBL is well-known to be
relatively strong in sparse problems. We observed
that the performance of type classification can be
influenced by very subtle differences in many
cases. Hence, we think that an error-driven
approach can perform well in comparative type
classification. Experimental results showed that
TBL actually performed better than SVM or MEM.
In the first step, we roughly annotated the type
of a sentence using the type of the CK itself. Then,
we generated error-driven transformation rules
from the incorrectly annotated sentences.
Transformation templates we defined are given in
Table 4. Numerous transformation rules were
generated on the basis of the templates. For
example, “Change the type of the current sentence
from “Greater or lesser” to “Superlative” if this
sentence holds the CK of “보다 ([bo-da]: than)”,
</bodyText>
<page confidence="0.9794">
1641
</page>
<bodyText confidence="0.999577818181818">
and the second preceding word of the CK is tagged
as mm” is a transformation rule generated by the
third template.
The integrated results showed an overall accuracy
of 88.59% for the eight-type classification. To
evaluate the effectiveness of our two-step
processing, we performed one-step processing
experiments using SVM and TBL. Table 6 shows a
comparison of the results.
Change the type of the current sentence from x to y if
this sentence holds the CK of k, and ...
</bodyText>
<listItem confidence="0.9753513">
1. the preceding word of k is tagged z.
2. the following word of k is tagged z.
3. the second preceding word of k is tagged z.
4. the second following word of k is tagged z.
5. the preceding word of k is tagged z, and the
following word of k is tagged w.
6. the preceding word of k is tagged z, and the
second preceding word of k is tagged w.
7. the following word of k is tagged z, and the
second following word of k is tagged w.
</listItem>
<tableCaption confidence="0.991158">
Table 4: Transformation templates
</tableCaption>
<bodyText confidence="0.9598084">
For evaluation of threshold values, we
performed experiments with three options as given
in Table 5.
Threshold 0 1 2
Accuracy 79.99 81.67 80.04
</bodyText>
<tableCaption confidence="0.97374">
Table 5: Evaluation of threshold option (%);
</tableCaption>
<equation confidence="0.6117635">
Threshold n means that the learning iterations continues while
Ci-Ei ≥ n+1
</equation>
<bodyText confidence="0.999948">
We achieved the best performance with the
threshold option 1. Finally, we classified
comparative sentences into seven types using TBL
with an accuracy of 81.67%.
</bodyText>
<subsectionHeader confidence="0.401851">
5.2.3 Integrated results of Task 1
</subsectionHeader>
<bodyText confidence="0.883971818181818">
We sum up our proposed method for Task 1 as two
steps as follows;
1) The comparison lexicon detects CS-candidates
in text documents, and then SVM eliminates
the non-comparative sentences from the
candidates. Thus, all of the sentences are
divided into two classes: a comparative class
and a non-comparative class.
2) TBL then classifies the sentences placed in the
comparative class in the previous step into
seven comparative types.
</bodyText>
<subsectionHeader confidence="0.961828">
Processing Accuracy
</subsectionHeader>
<bodyText confidence="0.887256166666667">
One-step
processing
(classifying eight
types at a time)
Two-step processing 88.59
(proposed)
</bodyText>
<tableCaption confidence="0.90359">
Table 6: Integrated results for Task 1 (%)
</tableCaption>
<bodyText confidence="0.997277">
As shown above, Task 1 was successfully divided
into two steps.
</bodyText>
<subsectionHeader confidence="0.9117515">
5.3 Mining comparative entities and
predicates
</subsectionHeader>
<bodyText confidence="0.99483">
For the mining task of comparative entities and
predicates, we used 460 comparative sentences
(Greater or lesser: 300, Superlative: 160). As
previously mentioned, we allowed multiple-word
comparative elements. Table 7 lists the portion of
multiple-word comparative elements.
</bodyText>
<table confidence="0.99523975">
Multi-word rate SE OE PR
Greater or lesser 30.0 31.3 8.3
Superlative 24.4 9.4 8.1
(32.6)
</table>
<tableCaption confidence="0.998824">
Table 7: Portion (%) of multiple-word comparative
</tableCaption>
<bodyText confidence="0.979411714285714">
elements
As given above, each multiple-word portion,
especially in SEs and OEs, is quite high. This fact
proves that it is absolutely necessary to allow
multiple-word comparative elements. Relatively
lower rate of 9.4% in Superlative-OEs is caused by
a number of omitted OEs. If sentences that do not
have any OEs are excluded, the portion of
multiple-words becomes 32.6% as written in
parentheses.
Table 8 shows the effectiveness of simplification
processes. We calculated the error rates of CE-
candidate detection before and after simplification
processes.
</bodyText>
<figure confidence="0.9424984">
comparison
75.64
lexicon &amp; SVM
lexicon &amp; TBL 72.49
comparison
</figure>
<page confidence="0.950136">
1642
</page>
<table confidence="0.99965725">
Simplification SE OE PR
processes
Greater or Before 34.7 39.3 10.0
lesser After 4.7 8.0 1.7
Before 26.3 85.0 9.4
(38.9)
Superlative After 1.9 75.6 1.3
(6.3)
</table>
<tableCaption confidence="0.999624">
Table 8: Error rate (%) in CE-candidate detection
</tableCaption>
<bodyText confidence="0.999880565217391">
Here, the first value of 34.7% means that the real
SEs of 104 sentences (among total 300 Greater or
lesser sentences) were not detected by CE-
candidate detection before simplification processes.
After the processes, the error rate decreased to
4.7%. The significant differences between before
and after indicate that we successfully detect CE-
candidates through the simplification processes.
Although the Superlative-OEs still show the
seriously high rate of 75.6%, it is also caused by a
number of omitted OEs. If sentences that do not
have any OEs are excluded, the error rate is only
6.3% as written in parentheses.
The final results for Task 2 are reported in Table
9. We calculated each probability of CE-candidates
using MEM and SVM. Both MEM and SVM
showed outstanding performance; there was no
significant difference between the two machine
learning methods (SVM and MEM). Hence, we
only report the results of SVM. Note that many
sentences do not contain any OE. To identify such
sentences, if SVM tagged every “N” in a sentence
as “not OE”, we tagged the sentence as “no OE”.
</bodyText>
<table confidence="0.98989225">
Final Results SE OE PR
Greater or lesser 86.00 89.67 92.67
Superlative 84.38 71.25 90.00
Total 85.43 83.26 91.74
</table>
<tableCaption confidence="0.99741">
Table 9: Final results of Task 2 (Accuracy, %)
</tableCaption>
<bodyText confidence="0.9997345">
As shown above, we successfully extracted the
comparative entities and predicates with
outstanding performance, an overall accuracy of
86.81%.
</bodyText>
<sectionHeader confidence="0.999525" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999991421052632">
This paper has studied a Korean comparison
mining system. Our proposed system achieved an
accuracy of 88.59% for classifying comparative
sentences into eight types (one non-comparative
type and seven comparative types), and an
accuracy of 86.81% for mining comparative
entities and predicates. These results demonstrated
that our proposed method could be used effectively
in practical applications. Since the comparison
mining is an area of increasing interest around the
world, our study can contribute greatly to text
mining research.
In our future work, we have the following plans.
Our first plan is to complete the mining process on
all the types of sentences. The second one is to
conduct more experiments for obtaining better
performance. The final one is about an integrated
system. Since we perform Task 1 and Task 2
separately, we need to build an end-to-end system.
</bodyText>
<sectionHeader confidence="0.98669" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.9864016">
This research was supported by Basic Science
Research Program through the National Research
Foundation of Korea (NRF) funded by the
Ministry of Education, Science and Technology
(2010-0015613)
</bodyText>
<sectionHeader confidence="0.998944" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999881173913044">
Adam L. Berger, Stephen A. Della Pietra and Vicent J.
Della Pietra. 1996. A Maximum Entropy Approach
to Natural Language Processing. Computational
Linguistics, 22(1):39-71.
William J. Black and Argyrios Vasilakopoulos. 2002.
Language-Independent named Entity Classification
by modified Transformation-based Learning and by
Decision Tree Induction. In Proceedings of
CoNLL’02, 24:1-4.
Eric Brill. 1992. A simple rule-based part of speech
tagger. In Proceedings of ANLP’92, 152-155.
Eric Brill. 1995. Transformation-based Error-Driven
Learning and Natural language Processing: A Case
Study in Part-of-Speech tagging. Computational
Linguistics, 543-565.
Gil-jong Ha. 1999a. Korean Modern Comparative
Syntax, Pijbook Press, Seoul, Korea.
Gil-jong Ha. 1999b. Research on Korean Equality
Comparative Syntax, Association for Korean
Linguistics, 5:229-265.
In-su Jeong. 2000. Research on Korean Adjective
Superlative Comparative Syntax. Korean Han-min-
jok Eo-mun-hak, 36:61-86.
</reference>
<page confidence="0.558248">
1643
</page>
<reference confidence="0.999702216216216">
Nitin Jindal and Bing Liu. 2006. Identifying
Comparative Sentences in Text Documents, In
Proceedings of SIGIR’06, 244-251.
Nitin Jindal and Bing Liu. 2006. Mining Comparative
Sentences and Relations, In Proceedings of AAAI’06,
1331-1336.
Thorsten Joachims. 1998. Text Categorization with
Support Vector Machines: Learning with Many
relevant Features. In Proceedings of ECML’98, 137-
142
Soomin Kim and Eduard Hovy. 2006. Automatic
Detection of Opinion Bearing Words and Sentences.
In Proceedings of ACL’06.
Dong-joo Lee, OK-Ran Jeong and Sang-goo Lee. 2008.
Opinion Mining of Customer Feedback Data on the
Web. In Proceedings of ICUIMC’08, 247-252.
Shasha Li, Chin-Yew Lin, Young-In Song and Zhoujun
Li. 2010. Comparable Entity Mining from
Comparative Questions. In Proceedings of ACL’10,
650-658.
Kyeong-sook Oh. 2004. The Difference between `Man-
kum&apos; Comparative and `Cheo-rum&apos; Comparative.
Society of Korean Semantics, 14:197-221.
Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text
Chunking using Transformation-Based Learning. In
Proceedings of NLP/VLC’95, 82-94.
Ellen Riloff and Janyce Wiebe. 2003. Learning
Extraction Patterns for Subjective Expressions. In
Proceedings of EMNLP’03.
Seon Yang and Youngjoong Ko. 2009. Extracting
Comparative Sentences from Korean Text
Documents Using Comparative Lexical Patterns and
Machine Learning Techniques. In Proceedings of
ACL-IJNLP:Short Papers, 153-156
Seon Yang and Youngjoong Ko. 2011. Finding relevant
features for Korean comparative sentence extraction.
Pattern Recognition Letters, 32(2):293-296
</reference>
<page confidence="0.994635">
1644
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.857017">
<title confidence="0.999325">Extracting Comparative Entities and Predicates from Texts Comparative Type Classification</title>
<author confidence="0.999561">Seon Yang Youngjoong Ko</author>
<affiliation confidence="0.999653">Department of Computer Engineering, Department of Computer Engineering, Dong-A University, Dong-A University,</affiliation>
<address confidence="0.903761">Busan, Korea Busan, Korea</address>
<email confidence="0.969246">seony.yang@gmail.comyjko@dau.ac.kr</email>
<abstract confidence="0.998304642857143">The automatic extraction of comparative information is an important text mining problem and an area of increasing interest. In this paper, we study how to build a Korean comparison mining system. Our work is composed of two consecutive tasks: 1) classifying comparative sentences into different types and 2) mining comparative entities and predicates. We perform various experiments to find relevant features and learning techniques. As a result, we achieve outstanding performance enough for practical use.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen A Della Pietra</author>
<author>Vicent J Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="6890" citStr="Berger et al. (1996)" startWordPosition="1043" endWordPosition="1046"> the speaker&apos;s opinion/sentiment. Lee et al. (2008) surveyed various techniques that have been developed for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion. Riloff and Wiebe (2003) presented a bootstrapping process that learns linguistically rich extraction patterns for subjective expressions. In this study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Approach to natural language processing. Joachims (1998) introduced SVM for text classification. Various TBL studies have been performed. Brill (1992; 1995) first introduced TBL and presented a case study on part-of-speech 1637 tagging. Ramshaw and Marcus (1995) applied TBL for locating chunks in tagged texts. Black and Vasilakopoulos (2002) used a modified TBL technique for Named Entity Recognition. 3 Classifying Comparative Sentences (Task 1) We first classify the sentences into comparatives and non-comparatives by extracting only comparatives from text documents</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen A. Della Pietra and Vicent J. Della Pietra. 1996. A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, 22(1):39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William J Black</author>
<author>Argyrios Vasilakopoulos</author>
</authors>
<title>Language-Independent named Entity Classification by modified Transformation-based Learning and by Decision Tree Induction.</title>
<date>2002</date>
<booktitle>In Proceedings of CoNLL’02,</booktitle>
<pages>24--1</pages>
<contexts>
<context position="7262" citStr="Black and Vasilakopoulos (2002)" startWordPosition="1096" endWordPosition="1099">his study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Approach to natural language processing. Joachims (1998) introduced SVM for text classification. Various TBL studies have been performed. Brill (1992; 1995) first introduced TBL and presented a case study on part-of-speech 1637 tagging. Ramshaw and Marcus (1995) applied TBL for locating chunks in tagged texts. Black and Vasilakopoulos (2002) used a modified TBL technique for Named Entity Recognition. 3 Classifying Comparative Sentences (Task 1) We first classify the sentences into comparatives and non-comparatives by extracting only comparatives from text documents. Then we classify the comparatives into seven types. 3.1 Extracting comparative sentences from text documents Our strategy is to first detect Comparative Sentence candidates (CS-candidates), and then eliminate non-comparative sentences from the candidates. As mentioned in the introduction section, we easily construct a linguistic-based keyword set, Kling. However, we o</context>
</contexts>
<marker>Black, Vasilakopoulos, 2002</marker>
<rawString>William J. Black and Argyrios Vasilakopoulos. 2002. Language-Independent named Entity Classification by modified Transformation-based Learning and by Decision Tree Induction. In Proceedings of CoNLL’02, 24:1-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of ANLP’92,</booktitle>
<pages>152--155</pages>
<contexts>
<context position="7068" citStr="Brill (1992" startWordPosition="1069" endWordPosition="1070">for analyzing judgment opinion. Riloff and Wiebe (2003) presented a bootstrapping process that learns linguistically rich extraction patterns for subjective expressions. In this study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Approach to natural language processing. Joachims (1998) introduced SVM for text classification. Various TBL studies have been performed. Brill (1992; 1995) first introduced TBL and presented a case study on part-of-speech 1637 tagging. Ramshaw and Marcus (1995) applied TBL for locating chunks in tagged texts. Black and Vasilakopoulos (2002) used a modified TBL technique for Named Entity Recognition. 3 Classifying Comparative Sentences (Task 1) We first classify the sentences into comparatives and non-comparatives by extracting only comparatives from text documents. Then we classify the comparatives into seven types. 3.1 Extracting comparative sentences from text documents Our strategy is to first detect Comparative Sentence candidates (CS</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Eric Brill. 1992. A simple rule-based part of speech tagger. In Proceedings of ANLP’92, 152-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based Error-Driven Learning and Natural language Processing: A Case Study in Part-of-Speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>543--565</pages>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based Error-Driven Learning and Natural language Processing: A Case Study in Part-of-Speech tagging. Computational Linguistics, 543-565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gil-jong Ha</author>
</authors>
<title>Korean Modern Comparative Syntax,</title>
<date>1999</date>
<publisher>Pijbook Press,</publisher>
<location>Seoul,</location>
<contexts>
<context position="3219" citStr="Ha (1999" startWordPosition="490" endWordPosition="491">predicate (PR). These tasks are not easy or simple problems as described below. Classifying comparative sentences (Task 1): For the first task, we extract comparative sentences from text documents and then classify the extracted comparative sentences into seven 1636 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1636–1644, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics reports our experimental results and finally Section 6 concludes. 2 Related Work comparative types. Our basic idea is a keyword search. Since Ha (1999a) categorized dozens of Korean comparative keywords, we easily build an initial keyword set as follows: ▪ Кling = {“같 ([gat]: same)”, “보다 ([bo-da]: than)”, “가장 ([ga-jang]: most)”, ...} In addition, we easily match each of these keywords to a particular type anchored to Ha&apos;s research, e.g., “같 ([gat]: same)” to “1) Equality”, “보다 ([bo-da]: than)” to “4) Greater or lesser”. However, any method that depends on just these linguistic-based keywords has obvious limitations as follows: 1) Кling is insufficient to cover all of the actual comparison expressions. 2) There are many non-comparative sente</context>
<context position="5127" citStr="Ha (1999" startWordPosition="790" endWordPosition="791">. We focus on solving the above five problems. We perform various experiments to find relevant features and proper machine learning techniques. The final experimental results in 5-fold cross validation show the overall accuracy of 88.59% for the first task and the overall accuracy of 86.81% for the second task. The remainder of the paper is organized as follows. Section 2 briefly introduces related work. Section 3 and Section 4 describe our first task and second task in detail, respectively. Section 5 Linguistic researchers focus on defining the syntax and semantics of comparative constructs. Ha (1999a; 1999b) classified the structures of Korean comparative sentences into several classes and arranged comparison-bearing words from a linguistic perspective. Since he summarized the modern Korean comparative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English te</context>
</contexts>
<marker>Ha, 1999</marker>
<rawString>Gil-jong Ha. 1999a. Korean Modern Comparative Syntax, Pijbook Press, Seoul, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gil-jong Ha</author>
</authors>
<date>1999</date>
<booktitle>Research on Korean Equality Comparative Syntax, Association for Korean Linguistics,</booktitle>
<pages>5--229</pages>
<contexts>
<context position="3219" citStr="Ha (1999" startWordPosition="490" endWordPosition="491">predicate (PR). These tasks are not easy or simple problems as described below. Classifying comparative sentences (Task 1): For the first task, we extract comparative sentences from text documents and then classify the extracted comparative sentences into seven 1636 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1636–1644, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics reports our experimental results and finally Section 6 concludes. 2 Related Work comparative types. Our basic idea is a keyword search. Since Ha (1999a) categorized dozens of Korean comparative keywords, we easily build an initial keyword set as follows: ▪ Кling = {“같 ([gat]: same)”, “보다 ([bo-da]: than)”, “가장 ([ga-jang]: most)”, ...} In addition, we easily match each of these keywords to a particular type anchored to Ha&apos;s research, e.g., “같 ([gat]: same)” to “1) Equality”, “보다 ([bo-da]: than)” to “4) Greater or lesser”. However, any method that depends on just these linguistic-based keywords has obvious limitations as follows: 1) Кling is insufficient to cover all of the actual comparison expressions. 2) There are many non-comparative sente</context>
<context position="5127" citStr="Ha (1999" startWordPosition="790" endWordPosition="791">. We focus on solving the above five problems. We perform various experiments to find relevant features and proper machine learning techniques. The final experimental results in 5-fold cross validation show the overall accuracy of 88.59% for the first task and the overall accuracy of 86.81% for the second task. The remainder of the paper is organized as follows. Section 2 briefly introduces related work. Section 3 and Section 4 describe our first task and second task in detail, respectively. Section 5 Linguistic researchers focus on defining the syntax and semantics of comparative constructs. Ha (1999a; 1999b) classified the structures of Korean comparative sentences into several classes and arranged comparison-bearing words from a linguistic perspective. Since he summarized the modern Korean comparative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English te</context>
</contexts>
<marker>Ha, 1999</marker>
<rawString>Gil-jong Ha. 1999b. Research on Korean Equality Comparative Syntax, Association for Korean Linguistics, 5:229-265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In-su Jeong</author>
</authors>
<title>Research on Korean Adjective Superlative Comparative Syntax. Korean Han-minjok Eo-mun-hak,</title>
<date>2000</date>
<pages>36--61</pages>
<contexts>
<context position="5428" citStr="Jeong (2000)" startWordPosition="833" endWordPosition="834">he second task. The remainder of the paper is organized as follows. Section 2 briefly introduces related work. Section 3 and Section 4 describe our first task and second task in detail, respectively. Section 5 Linguistic researchers focus on defining the syntax and semantics of comparative constructs. Ha (1999a; 1999b) classified the structures of Korean comparative sentences into several classes and arranged comparison-bearing words from a linguistic perspective. Since he summarized the modern Korean comparative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English text documents. They used comparative and superlative POS tags, and some additional keywords. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable </context>
</contexts>
<marker>Jeong, 2000</marker>
<rawString>In-su Jeong. 2000. Research on Korean Adjective Superlative Comparative Syntax. Korean Han-minjok Eo-mun-hak, 36:61-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Identifying Comparative Sentences in Text Documents,</title>
<date>2006</date>
<booktitle>In Proceedings of SIGIR’06,</booktitle>
<pages>244--251</pages>
<contexts>
<context position="5664" citStr="Jindal and Liu (2006" startWordPosition="864" endWordPosition="867">hers focus on defining the syntax and semantics of comparative constructs. Ha (1999a; 1999b) classified the structures of Korean comparative sentences into several classes and arranged comparison-bearing words from a linguistic perspective. Since he summarized the modern Korean comparative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English text documents. They used comparative and superlative POS tags, and some additional keywords. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from English comparative questions that users posted online. They focused on finding a set of comparable entities given a user&apos;s input entity. Opinion mining is also related to our work because many comparative sentences also c</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006. Identifying Comparative Sentences in Text Documents, In Proceedings of SIGIR’06, 244-251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Mining Comparative Sentences and Relations,</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI’06,</booktitle>
<pages>1331--1336</pages>
<contexts>
<context position="5664" citStr="Jindal and Liu (2006" startWordPosition="864" endWordPosition="867">hers focus on defining the syntax and semantics of comparative constructs. Ha (1999a; 1999b) classified the structures of Korean comparative sentences into several classes and arranged comparison-bearing words from a linguistic perspective. Since he summarized the modern Korean comparative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English text documents. They used comparative and superlative POS tags, and some additional keywords. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from English comparative questions that users posted online. They focused on finding a set of comparable entities given a user&apos;s input entity. Opinion mining is also related to our work because many comparative sentences also c</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006. Mining Comparative Sentences and Relations, In Proceedings of AAAI’06, 1331-1336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text Categorization with Support Vector Machines: Learning with Many relevant Features.</title>
<date>1998</date>
<booktitle>In Proceedings of ECML’98,</booktitle>
<pages>137--142</pages>
<contexts>
<context position="6975" citStr="Joachims (1998)" startWordPosition="1056" endWordPosition="1057">been developed for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion. Riloff and Wiebe (2003) presented a bootstrapping process that learns linguistically rich extraction patterns for subjective expressions. In this study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Approach to natural language processing. Joachims (1998) introduced SVM for text classification. Various TBL studies have been performed. Brill (1992; 1995) first introduced TBL and presented a case study on part-of-speech 1637 tagging. Ramshaw and Marcus (1995) applied TBL for locating chunks in tagged texts. Black and Vasilakopoulos (2002) used a modified TBL technique for Named Entity Recognition. 3 Classifying Comparative Sentences (Task 1) We first classify the sentences into comparatives and non-comparatives by extracting only comparatives from text documents. Then we classify the comparatives into seven types. 3.1 Extracting comparative sent</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. 1998. Text Categorization with Support Vector Machines: Learning with Many relevant Features. In Proceedings of ECML’98, 137-142</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soomin Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic Detection of Opinion Bearing Words and Sentences.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL’06.</booktitle>
<contexts>
<context position="6431" citStr="Kim and Hovy (2006)" startWordPosition="979" endWordPosition="982">words. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from English comparative questions that users posted online. They focused on finding a set of comparable entities given a user&apos;s input entity. Opinion mining is also related to our work because many comparative sentences also contain the speaker&apos;s opinion/sentiment. Lee et al. (2008) surveyed various techniques that have been developed for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion. Riloff and Wiebe (2003) presented a bootstrapping process that learns linguistically rich extraction patterns for subjective expressions. In this study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Approach to natural language processing. Joachims (1998) introduced SVM for text classification. Various TBL stu</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soomin Kim and Eduard Hovy. 2006. Automatic Detection of Opinion Bearing Words and Sentences. In Proceedings of ACL’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong-joo Lee</author>
<author>OK-Ran Jeong</author>
<author>Sang-goo Lee</author>
</authors>
<title>Opinion Mining of Customer Feedback Data on the Web. In</title>
<date>2008</date>
<booktitle>Proceedings of ICUIMC’08,</booktitle>
<pages>247--252</pages>
<contexts>
<context position="6321" citStr="Lee et al. (2008)" startWordPosition="961" endWordPosition="964">lations from English text documents. They used comparative and superlative POS tags, and some additional keywords. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from English comparative questions that users posted online. They focused on finding a set of comparable entities given a user&apos;s input entity. Opinion mining is also related to our work because many comparative sentences also contain the speaker&apos;s opinion/sentiment. Lee et al. (2008) surveyed various techniques that have been developed for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion. Riloff and Wiebe (2003) presented a bootstrapping process that learns linguistically rich extraction patterns for subjective expressions. In this study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Ap</context>
</contexts>
<marker>Lee, Jeong, Lee, 2008</marker>
<rawString>Dong-joo Lee, OK-Ran Jeong and Sang-goo Lee. 2008. Opinion Mining of Customer Feedback Data on the Web. In Proceedings of ICUIMC’08, 247-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shasha Li</author>
<author>Chin-Yew Lin</author>
<author>Young-In Song</author>
<author>Zhoujun Li</author>
</authors>
<title>Comparable Entity Mining from Comparative Questions.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL’10,</booktitle>
<pages>650--658</pages>
<contexts>
<context position="6000" citStr="Li et al. (2010)" startWordPosition="913" endWordPosition="916">point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English text documents. They used comparative and superlative POS tags, and some additional keywords. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from English comparative questions that users posted online. They focused on finding a set of comparable entities given a user&apos;s input entity. Opinion mining is also related to our work because many comparative sentences also contain the speaker&apos;s opinion/sentiment. Lee et al. (2008) surveyed various techniques that have been developed for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion. Riloff and Wiebe (2003) presented a bootstrapping process that learns linguistically rich extraction patterns f</context>
</contexts>
<marker>Li, Lin, Song, Li, 2010</marker>
<rawString>Shasha Li, Chin-Yew Lin, Young-In Song and Zhoujun Li. 2010. Comparable Entity Mining from Comparative Questions. In Proceedings of ACL’10, 650-658.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyeong-sook Oh</author>
</authors>
<title>The Difference between `Mankum&apos; Comparative and `Cheo-rum&apos;</title>
<date>2004</date>
<journal>Comparative. Society of Korean Semantics,</journal>
<pages>14--197</pages>
<contexts>
<context position="5442" citStr="Oh (2004)" startWordPosition="836" endWordPosition="837">he remainder of the paper is organized as follows. Section 2 briefly introduces related work. Section 3 and Section 4 describe our first task and second task in detail, respectively. Section 5 Linguistic researchers focus on defining the syntax and semantics of comparative constructs. Ha (1999a; 1999b) classified the structures of Korean comparative sentences into several classes and arranged comparison-bearing words from a linguistic perspective. Since he summarized the modern Korean comparative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English text documents. They used comparative and superlative POS tags, and some additional keywords. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from </context>
</contexts>
<marker>Oh, 2004</marker>
<rawString>Kyeong-sook Oh. 2004. The Difference between `Mankum&apos; Comparative and `Cheo-rum&apos; Comparative. Society of Korean Semantics, 14:197-221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance A Ramshaw</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Text Chunking using Transformation-Based Learning.</title>
<date>1995</date>
<booktitle>In Proceedings of NLP/VLC’95,</booktitle>
<pages>82--94</pages>
<contexts>
<context position="7181" citStr="Ramshaw and Marcus (1995)" startWordPosition="1084" endWordPosition="1087">ns linguistically rich extraction patterns for subjective expressions. In this study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Approach to natural language processing. Joachims (1998) introduced SVM for text classification. Various TBL studies have been performed. Brill (1992; 1995) first introduced TBL and presented a case study on part-of-speech 1637 tagging. Ramshaw and Marcus (1995) applied TBL for locating chunks in tagged texts. Black and Vasilakopoulos (2002) used a modified TBL technique for Named Entity Recognition. 3 Classifying Comparative Sentences (Task 1) We first classify the sentences into comparatives and non-comparatives by extracting only comparatives from text documents. Then we classify the comparatives into seven types. 3.1 Extracting comparative sentences from text documents Our strategy is to first detect Comparative Sentence candidates (CS-candidates), and then eliminate non-comparative sentences from the candidates. As mentioned in the introduction </context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text Chunking using Transformation-Based Learning. In Proceedings of NLP/VLC’95, 82-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning Extraction Patterns for Subjective Expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP’03.</booktitle>
<contexts>
<context position="6512" citStr="Riloff and Wiebe (2003)" startWordPosition="990" endWordPosition="993">s. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from English comparative questions that users posted online. They focused on finding a set of comparable entities given a user&apos;s input entity. Opinion mining is also related to our work because many comparative sentences also contain the speaker&apos;s opinion/sentiment. Lee et al. (2008) surveyed various techniques that have been developed for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion. Riloff and Wiebe (2003) presented a bootstrapping process that learns linguistically rich extraction patterns for subjective expressions. In this study, three learning techniques are employed: the maximum entropy method (MEM) as a representative probabilistic model, the support vector machine (SVM) as a kernel model, and transformation-based learning (TBL) as a rulebased model. Berger et al. (1996) presented a Maximum Entropy Approach to natural language processing. Joachims (1998) introduced SVM for text classification. Various TBL studies have been performed. Brill (1992; 1995) first introduced TBL and presented a</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning Extraction Patterns for Subjective Expressions. In Proceedings of EMNLP’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seon Yang</author>
<author>Youngjoong Ko</author>
</authors>
<title>Extracting Comparative Sentences from Korean Text Documents Using Comparative Lexical Patterns and Machine Learning Techniques.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJNLP:Short Papers,</booktitle>
<pages>153--156</pages>
<contexts>
<context position="5909" citStr="Yang and Ko (2009" startWordPosition="899" endWordPosition="902">e summarized the modern Korean comparative studies, his research helps us have a linguistic point of view. We also refer to Jeong (2000) and Oh (2004). Jeong classified adjective superlatives using certain measures, and Oh discussed the gradability of comparatives. In computer engineering, we found five previous studies related to comparison mining. Jindal and Liu (2006a; 2006b) studied to mine comparative relations from English text documents. They used comparative and superlative POS tags, and some additional keywords. Their methods applied Class Sequential Rules and Label Sequential Rules. Yang and Ko (2009; 2011) studied to extract comparative sentences in Korean text documents. Li et al. (2010) studied to mine comparable entities from English comparative questions that users posted online. They focused on finding a set of comparable entities given a user&apos;s input entity. Opinion mining is also related to our work because many comparative sentences also contain the speaker&apos;s opinion/sentiment. Lee et al. (2008) surveyed various techniques that have been developed for the key tasks of opinion mining. Kim and Hovy (2006) introduced a methodology for analyzing judgment opinion. Riloff and Wiebe (20</context>
</contexts>
<marker>Yang, Ko, 2009</marker>
<rawString>Seon Yang and Youngjoong Ko. 2009. Extracting Comparative Sentences from Korean Text Documents Using Comparative Lexical Patterns and Machine Learning Techniques. In Proceedings of ACL-IJNLP:Short Papers, 153-156</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seon Yang</author>
<author>Youngjoong Ko</author>
</authors>
<title>Finding relevant features for Korean comparative sentence extraction.</title>
<date>2011</date>
<journal>Pattern Recognition Letters,</journal>
<pages>32--2</pages>
<marker>Yang, Ko, 2011</marker>
<rawString>Seon Yang and Youngjoong Ko. 2011. Finding relevant features for Korean comparative sentence extraction. Pattern Recognition Letters, 32(2):293-296</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>