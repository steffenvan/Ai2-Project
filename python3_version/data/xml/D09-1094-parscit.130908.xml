<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<title confidence="0.9284615">
Statistical Estimation of Word Acquisition with
Application to Readability Prediction
</title>
<author confidence="0.997968">
Paul Kidwell
</author>
<affiliation confidence="0.990757">
Department of Statistics
Purdue University
</affiliation>
<address confidence="0.47482">
West Lafayette, IN
</address>
<email confidence="0.987802">
kidwellpaul@gmail.com
</email>
<author confidence="0.984612">
Guy Lebanon
</author>
<affiliation confidence="0.998708">
College of Computing
Georgia Institute of Technology
</affiliation>
<address confidence="0.957397">
Atlanta, GA
</address>
<email confidence="0.998843">
lebanon@cc.gatech.edu
</email>
<author confidence="0.822119">
Kevyn Collins-Thompson
</author>
<affiliation confidence="0.834807">
Microsoft Research
</affiliation>
<address confidence="0.942554">
Redmond, WA
</address>
<email confidence="0.998078">
kevynct@microsoft.com
</email>
<sectionHeader confidence="0.997385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998905">
Models of language learning play a cen-
tral role in a wide range of applica-
tions: from psycholinguistic theories of
how people acquire new word knowledge,
to information systems that can automati-
cally match content to users’ reading abil-
ity. We present a novel statistical ap-
proach that can infer the distribution of
a word’s likely acquisition age automati-
cally from authentic texts collected from
the Web. We then show that combining
these acquisition age distributions for all
words in a document provides an effective
semantic component for predicting read-
ing difficulty of new texts. We also com-
pare our automatically inferred acquisition
ages with norms from existing oral stud-
ies, revealing interesting historical trends
as well as differences between oral and
written word acquisition processes.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999986615384615">
Word acquisition refers to the temporal process by
which children learn the meaning and understand-
ing of new words. Some words are acquired at
a very early age, some are acquired at early pri-
mary school grades, and some are acquired at high
school or even later in life as the individual under-
goes experiences related to that word. A related
concept to acquisition age is document grade level
readability which refers to the school grade level
of the document’s intended audience. It applies
in situations where documents are written with the
expressed intent of being understood by children
in a certain school grade. For example, textbooks
authored specifically for fourth graders are said to
have readability grade level four.
We develop and evaluate a novel statistical
model that draws a connection between document
grade level readability and age acquisition distri-
butions. Based on previous work in the area, we
define a model for document readability using a
logistic Rasch model and the quantiles of the ac-
quisition age distributions. We then proceed to in-
fer the age acquisition distributions for different
words from document readability data collected
by crawling the web.
We examine the inferred acquisition distribu-
tions from two perspectives. First, we analyze and
contrast them with previous studies on oral word
acquisition, revealing interesting historical trends
as well as differences between oral and written
word acquisition processes. Second, the inferred
acquisition distributions serve as parameters for
the readability model, which enables us to predict
the readability level of novel documents.
To our knowledge, this is the first published
study of a method to ‘reverse-engineer’ individ-
ual word acquisition statistics from graded texts.
By obtaining such a fine-grained model of how
language evolves over time, we obtain a new,
rich source of semantic features for a document.
The increasing amounts of content available from
the Web and other sources also means that these
flexible models of authentic usage can be eas-
ily adapted for different tasks and populations.
Our work serves to complement the growing body
of research using statistics and machine learn-
ing for language learning tasks, and has appli-
cations including predicting reading difficulty for
Web pages and other non-traditional documents,
reader-specific example and question generation
for lexical practice in intelligent tutoring systems,
and analysis tools for language learning research.
</bodyText>
<sectionHeader confidence="0.9476385" genericHeader="method">
2 A Model for Document Readability
and Word Acquisition
</sectionHeader>
<bodyText confidence="0.925217">
For a fixed word and a fixed population of indi-
viduals T the age of acquisition (AoA) distribu-
tion pw represents the age at which word w was
</bodyText>
<page confidence="0.932292">
900
</page>
<note confidence="0.996608">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 900–909,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999041777777778">
acquired by the population. Existing AoA norm
studies almost universally summarize AoA ratings
in terms of two parameters: mean and standard
deviation, ignoring higher-level moments such as
skew. For direct comparison with these studies we
follow this convention and thus our goal is to esti-
mate AoA for a word w in terms of mean µw and
standard deviation σw parameters using the (trun-
cated) normal distribution
</bodyText>
<equation confidence="0.864249">
−(t−µw)2/(2σ2w)
V12πσ2w
</equation>
<bodyText confidence="0.999977818181818">
where the proportionality constant ensures that the
distribution is normalized over the range of ages
under consideration e.g., t E [6,18] for school
grades. It is important to note that our model is
not restricted by the assumption of (1) and can be
readily extended to the Gamma family of distribu-
tions, if modeling asymmetric spread in the distri-
bution is appropriate.
For a fixed vocabulary V of distinct words the
age acquisition distributions for all words w E V
are defined using 2|V  |parameters
</bodyText>
<equation confidence="0.962376">
{(µw, σw) : w E V }. (2)
</equation>
<bodyText confidence="0.999569923076923">
These parameters, which are the main objects of
interest, can in principle be estimated from data
using standard statistical techniques. Unfortu-
nately, data containing explicit acquisition ages is
very difficult to obtain reliably. Explicit word ac-
quisition data is based on interviewing adults re-
garding their age acquisition process during child-
hood and so may be unreliable and difficult to ob-
tain for a large representative group of people.
On the other hand, it is possible to reliably col-
lect large quantities of readability data defined as
pairs of documents and ages of intended audience.
As we demonstrate later in the paper, such data
may be automatically obtained by crawling spe-
cialized resources on the Web. We demonstrate
how to use such data to estimate the word acqui-
sition parameters (2) and to use the estimates to
predict future readability ages.
Traditionally, document readability has been
defined in terms of the school grade level at which
a large portion of the words have been acquired
by most children (Chall and Dale, 1995). We pro-
pose the following interpretation of that definition,
which is made appropriate for quantitative studies
by taking into account the inherent randomness in
the acquisition process.
</bodyText>
<construct confidence="0.7974552">
Definition 1. A document d = (w1,... , wm) is
said to have (1 − ǫ1, 1 − ǫ2)-readability level t if
by age t no less than 1−ǫ1 percent of the words in
d have been acquired each by no less than 1 − ǫ2
percent of the population.
</construct>
<bodyText confidence="0.9970914">
We denote by qw the quantile function of the cdf
corresponding to the acquisition distribution pw.
In other words, qw(r) represents the age at which
r percent of the population T have acquired word
w. Despite the fact that it does not have a closed
form, it is a continuous and smooth function of the
parameters µw, σw in (1) (assuming T is infinite)
and can be tabulated before inference begins.
Following Definition 1 we define a logistic
Rasch readability model:
</bodyText>
<equation confidence="0.9535235">
P(d is (s, r)-readable at age t)
log
1 − P(d is (s, r)-readable at age t)
= θ(qd(s,r) − t) (3)
</equation>
<bodyText confidence="0.997723">
where qd(s, r) is the s quantile of {qwi(r) : i =
1,... , m}. An equivalent formulation to (3) that
makes the probability model more explicit is
</bodyText>
<equation confidence="0.930683666666667">
P(d is (s, r)-readable at age t)
=exp (θ(qd(s, r) − t))
1 + exp(θ(qd(s, r) − t)). (4)
</equation>
<bodyText confidence="0.999612125">
In other words, the probability of a document d
being (s, r)-readable increases exponentially with
qd(s, r) which is the age at which s percent of the
words in d have been acquired each by r percent
of the population.
The parameter r = 1 − ǫ2 determines what it
means for a word to be acquired and is typically
considered to be a high value such as 0.8. The
parameter s = 1 − ǫ1 determines how many of
the document words need to be acquired for it to
be readable. It can be set to a high value such as
0.9 if a very precise understanding is required for
readability but can be reduced when a more mod-
est definition of readability applies.
We note that due to the discreteness of the set
{qwi(r) : i = 1, ... , m}, neither qd(s, r) nor the
loglikelihood are differentiable in the parameters
(2). This raises some practical difficulties with
respect to the computational maximization of the
likelihood and subsequent estimation of (2). How-
ever, for long documents containing a large num-
ber of words, qd(s, r) is approximately smooth
which motivates a maximum likelihood procedure
using gradient descent on a smoothed version of
</bodyText>
<equation confidence="0.985188">
e
pw(t) oC N(t i µw, σw) =
(1)
</equation>
<page confidence="0.966603">
901
</page>
<bodyText confidence="0.998902352941176">
qd(s). Alternative optimization techniques which
do not require smoothness may also be used.
In the case of a normal distribution (1) we have
that a word is acquired by r percent of the pop-
ulation at age w = µ + Φ−1(r)σ, where Φ is
the cumulative distribution function (cdf) of the
normal distribution. To investigate the distribu-
tion of acquisition ages we assume that the µ, σ
parameters corresponding to different words in a
document are drawn from Gamma distributions
µ — G(α1,β1) and σ — G(α2,β2). The normal
and Gamma distributions are chosen in part be-
cause they are flexible enough to model many sit-
uations and also admit good statistical estimation
theory. Noting that Φ−1(r)σ — G(α2, Φ−1(r)β2),
we can write the distribution of the acquisition
ages as the following convolution
</bodyText>
<figure confidence="0.99266375">
3.0
2.5
2.0
1.5
1.0
0.5
50 100 150 200
Document Length
</figure>
<figureCaption confidence="0.8437625">
Figure 1: A comparison of model (dashed) vs. em-
pirical (solid) 95% confidence interval widths as a
</figureCaption>
<bodyText confidence="0.984722857142857">
function of document length (r = 0.9 and s =
0.7). CI widths were computed using 1000 Monte
Carlo samples generated from the fW model fit to
the data and from the empirical distribution. Word
distributions correspond to a 1577 word document
written for a 7th grade audience taken from the
Web 1-12 corpus.
</bodyText>
<equation confidence="0.9573904">
fW(w) =
wα1+α2−1e−w/β2
Γ(α1)Γ(α2)βα1
1 βα2
2 �
(01−02)tw
1 tα1−1e 0102
1 dt
(1 � t)1−α2
95% CI Width
</equation>
<bodyText confidence="0.998835631578948">
which reverts to a Gamma when β1 = β2.
The distribution of the s-percentile of fW,
which amounts to (r, s)-readability of documents,
can be analyzed by combining fW above with a
standard normal approximation of order statistics
(e.g., (David and Nagaraja, 2003))
where m is the document length and FW is the cdf
corresponding to fW.
Figure 1 shows the relationship between docu-
ment length and confidence interval (CI) width in
readability prediction. It contrasts the CI widths
for model based intervals and empirical intervals.
In both cases, documents of lengths larger than
100 words provide CI widths shorter than 1 year.
This finding is also noteworthy as it provides
empirical support for the long-standing ‘rule-of-
thumb’ that readability measures become unreli-
able for passages of less than 100 words (Fry,
1990).
</bodyText>
<sectionHeader confidence="0.995994" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.99998303030303">
Our experimental study is divided into three parts.
The first part examines the word acquisition dis-
tributions that were estimated based on readabil-
ity data. The second part compares the estimated
(written) acquisition ages with oral acquisition
ages obtained from interview studies reported in
the literature. The third part focuses on using the
estimated word acquisition distributions to predict
document readability. These three experimental
studies are described in the three subsections be-
low.
In our experiments we used three readability
datasets. The corpora were compiled by crawl-
ing web pages containing documents authored for
audiences of specific grade levels. The Web 1-
12 data contains 373 documents, with each doc-
ument written for a particular school grade level
in the range 1-12. The Weekly Reader (WR)
dataset, was obtained by crawling the commercial
website www.wrtoolkit.com after receiving spe-
cial permission. That dataset contains a total of
1780 documents, with 4 readability levels rang-
ing from 2 to 5 indicating the school grade lev-
els of the intended audience. A total of 788 doc-
uments with readability between grades 2 and 5
and having length greater than 50 words were se-
lected from 1780 documents. The Reading A-Z
dataset, contains a set of 215 documents was ob-
tained from Reading A-Z.com, spanning grade 1
through grade 6.
The grade levels in these three corpora, which
correspond to US school grades, were either ex-
plicitly specified by the organization or authors
</bodyText>
<equation confidence="0.87687675">
X Lmp] — N FW1(p)
m[
f
(
1(p�))]2
p(1 — p)
W
FW
</equation>
<page confidence="0.968991">
902
</page>
<bodyText confidence="0.999982384615385">
who created the text, or implicit in the class-
room curriculum page where the document was
acquired. The pages were drawn from a wide
range of subject areas, including history, science,
geography, and fiction.
To reduce the possibility of overfitting, we used
a common feature selection technique of eliminat-
ing words appearing in less than 4 documents. In
the experiments we used maximum likelihood to
estimate the model parameters {(µw, σ2w) : w ∈
V } for the Rasch model (3). The maximum likeli-
hood was obtained using a non-smooth coordinate
descent procedure.
</bodyText>
<subsectionHeader confidence="0.9678395">
3.1 Estimation of Word Acquisition
Distributions
</subsectionHeader>
<bodyText confidence="0.999935441860465">
Figure 2 displays the inferred age acquisition dis-
tributions and empirical word appearances of three
words: thought (left), multitude (middle),
and assimilate (right). In these plots, the em-
pirical cdf of word appearances is indicated by a
piecewise constant line while the probability den-
sity function of the estimated AoA distribution is
indicated by a dashed line. The vertical line in-
dicates the 0.8 quantile of the AoA distribution
which corresponds to the grade by which 80% of
the children have acquired the word.
The word assimilation appears in 2 doc-
uments having 12th grade readability. The high
grade level of these documents results in a high es-
timated acquisition age and the paucity of observa-
tions leads to a large uncertainty in this estimate as
seen by the variance of the acquisition age distri-
bution. The word thought appears several times
in multiple grades. It is first observed in the 1st
grade and not again until the 4th grade resulting in
an estimated acquisition age falling between the
two. The variance of this acquisition distribution
is relatively small due to the frequent use of this
word. The empirical cdf shows that multitude
is used in grades 6, 8, and 9. Relative to thought
and assimilation the word multitude was
used less and more frequently respectively, which
leads to an acquisition age distribution with a
larger variance than that of thought and smaller
than that of assimilation.
The relationship in Figure 2 between the em-
pirical word appearances and the age acquisition
distribution demonstrates the following behavior:
(a) The variance of the age acquisition distribu-
tion goes down as the word appears in more doc-
uments, and (b) the mean of the AoA distribution
tends to be lower than the mean of the empirical
word appearance distribution, and in many cases
even smaller than the first grade in which the word
appeared. This is to be expected as authors use
specific words only after they believe the words
were acquired by a large portion of the intended
audience.
</bodyText>
<subsectionHeader confidence="0.999822">
3.2 Comparison with Oral Studies
</subsectionHeader>
<bodyText confidence="0.999820341463415">
Among the related work in the linguistic commu-
nity, are several studies concerning oral acquisi-
tions of words. These studies estimate the age
at which a word is acquired for oral use based
an interview processes with participating adults.
We focus specifically on the seminal study of ac-
quisition ages performed by Gilhooly and Logie
(GL) (1980) and made available through the MRC
database (Coltheart, 1981).
There are some substantial differences between
these previous studies and our approach. We an-
alyze the age acquisition process through docu-
ment readability which leads to a written, rather
than oral, notion of word acquisition. Further-
more, our estimates are based on documents writ-
ten with a specific audience in mind, while the pre-
vious studies are based on interviewing adults re-
garding their childhood word acquisition process
which is arguably less reliable due to the age dif-
ference between the acquisition and the interview.
Finally, the GL study was performed in the late
1970s while our study uses contemporary internet
data. Conceivably, the word acquisition process
changed over the past 3 decades.
Despite these differences, it is interesting to
contrast our inferred age acquisitions with the GL
study and consider the differences and similari-
ties. Figure 3 displays the relationship between
the GL age of acquisition (AoA) and the acquisi-
tion ages obtained from readability data based on
the s = 0.8 quantile. Some correlation is present
(r2 = 0.34) but the two measures differ consid-
erably. As expected, the acquisition ages obtained
from written readability data tend to be higher than
the oral studies. The distributions of differences
between the GL acquisition ages and the ones in-
ferred from the readability data appears in Fig-
ure 4.
Comparing the acquisition ages obtained from
readability data to the GL study results in a mean
absolute error of 0.9 to 1.5, depending on the spe-
</bodyText>
<page confidence="0.907199">
903
</page>
<note confidence="0.429008">
mu: 9
mu: 1.9 mu: 5
sigma: 0.5 sigma: 1.2 sigma: 3.4
</note>
<figure confidence="0.592886">
5 10 15 5 10 15 5 10 15
</figure>
<figureCaption confidence="0.4857895">
Figure 2: A comparison of empirical word appearances and AoA distributions for three words:
thought (left), multitude (middle), and assimilation (right). The empirical cdf of word ap-
pearances appears as a piecewise constant line and the estimated pdf is indicated by the dashed curve
with its 0.8 quantile indicated by a vertical line.
cific value of the Rasch parameter θ. Interestingly,
the tendency for the written acquisition age to ex-
ceed the oral one diminishes as the grade level in-
creases. This represents the notion that at higher
grades words are acquired in both oral and written
senses at the same age.
</figureCaption>
<figure confidence="0.713668">
Predicted versus Oral Acquisition Age
GL AoA
</figure>
<figureCaption confidence="0.90626025">
Figure 3: A scatter plot (s = 80, n = 50) of pre-
dicted age of acquisition versus Gilhooly and Lo-
gie’s values reveals the tendency for the written
estimate to exceed the oral estimate (r2 = 0.34).
</figureCaption>
<bodyText confidence="0.999817307692308">
A comparison to two more recent studies con-
firms relationships that are similar to those ob-
served with GL AoA. The Bristol Norm study
(Stadthagen-Gonzalez and Davis, 2006) was per-
formed in an identical way to the GL study and
comparing the lists of acquisition ages results
in a mean absolute error of approximately 0.5
which is much lower than the .9 to 1.5 relative to
GL. The recent AoA list of Cortese and Khanna
(2008) showed an increase in correlation relative
to the GL study (r2 = 0.43) potentially reflecting
change in the acquisition process due to temporal
effects.
</bodyText>
<figure confidence="0.849315">
Residual Distribution: Predicted AoA versus Oral AoA
S−percentile=80
−4 −2 0 2 4
Error (Predicted AoA − Actual AoA)
</figure>
<figureCaption confidence="0.997535">
Figure 4: The difference distribution between
</figureCaption>
<bodyText confidence="0.975677869565217">
the GL and the inferred AoA from Web 1-12 is
skewed to the right as would be expected since
written AoA is higher than oral AoA. Relaxing
the definition of readability by decreasing s re-
sults in higher inferred acquisition ages. Values
of s in [0.5, 0.9] produced reasonable results, with
s = 0.65 achieving smallest mean absolute error.
Those words that have the same written and
verbal acquisition age are partially attributable to
those words learned prior to first grade. Many
words are learned between the ages of 2 and 5,
while reading materials are typically not assigned
a grade level of less than 1 or age 6. Approxi-
mately 40% of the words assigned the same grade
level by both Gilhooly and our prediction had an
AoA of 1st grade.
In some cases, the ages of acquisition obtained
from readability data is actually lower than the
ages reported in the older oral studies. This phe-
nomenon is likely caused by a combination of
a shift in educational standards, a change in so-
cial standards, or estimation errors due to sample
size and modeling assumptions. Approximately
</bodyText>
<figure confidence="0.995514538461538">
2 4 6 8 10
Predicted AoA
10
8
6
4
2
Percent
20
15
10
5
0
</figure>
<page confidence="0.996644">
904
</page>
<bodyText confidence="0.999850666666667">
30 years have passed since Gilhooly and Logie’s
study was conducted. Specifically, society has
made efforts to enhance the safety and health of
children and to increase the attention to science
education in very early grades. For example, the
word drug appeared in writing 0.94 grades ear-
lier than the age in which it was acquired orally
according to the GL study. The newer Bristol
Norm study confirms this observation as it pre-
dicts a decrease in grade level for drug of 0.88
over GL as well. A similar decrease in acqui-
sition age relative to the GL norms was noted
for many other words such as hypothesis,
conclusion, engineer, diet, exercise,
and vitamin.
</bodyText>
<subsectionHeader confidence="0.998107">
3.3 Global Readability Prediction
</subsectionHeader>
<bodyText confidence="0.998664">
Once acquisition age distributions are available,
whether estimated statistically from data or ob-
tained from a survey, they may be used to predict
the grade level of novel documents. Specifically,
the model predicts readability level t* for a novel
document d if it is the minimal grade for which
readability is established:
</bodyText>
<equation confidence="0.983173">
t* = min{t : P(d is readable at age t) &gt; Q(t)}
(5)
</equation>
<bodyText confidence="0.999936857142857">
where Q(t) is a parameter describing the strictness
of the readability requirement. Note that we allow
Q(t) to vary as a function of time (grade level). We
discuss the justification for this below.
A critical issue for reading difficulty predic-
tion is how to handle words that appear in a new
document that have never been seen in the train-
ing/development texts. In a statistical approach,
the solution to this smoothing problem has two
steps. First, we must decide how much total proba-
bility mass to allocate to all unknown words. Sec-
ond, we must decide how to subdivide this total
mass for individual words or classes of words us-
ing word-specific priors.
Our experience suggests that the first step of
estimating total probability mass is particularly
important: the likelihood of seeing an unknown
word increases as a function of total vocabulary
size, which is continuously growing with time.
We model this by defining the following dynamic
threshold
We learn the growth rate parameter a in (6) from
the data at the same time as we learn the read-
ability model’s quantile parameters s = 1 − E1,
r = 1 − E2. The range of the resulting Q(t) is
typically 0.5 in lower grades, increasing to 0.9 in
higher grades. We discuss fitting these parameters
and their optimal values further in Sec. 3.3.1. We
found that using any fixed Q value for all grades
was generally much less effective than a dynamic
Q(t) threshold, and so we focus on the latter in our
evaluation.
For the second (word-specific) smoothing step,
we simply assign uniform probability across
grades, once the total unseen mass is determined.
More sophisticated word-specific priors incorpo-
rating word length, morphological features, se-
mantic clusters and so on are certainly possible
and an interesting direction for future work.
In the following section we conduct three exper-
iments involving readability prediction. First, we
confirm the effectiveness of the AoA-based model
compared to other predictive models. Second, we
examine how prediction effectiveness is affected
when our learned (written) acquisition ages are re-
placed with existing oral AoA norms. Third, we
examine the ability of our model to generalize to
new content by training and testing on different
(non-overlapping) corpora.
</bodyText>
<subsectionHeader confidence="0.978527">
3.3.1 Effectiveness of Readability Prediction
</subsectionHeader>
<bodyText confidence="0.992044695652174">
In order to assess the effectiveness of our model
in predicting the readability grade levels of novel
documents we apply the model to two corpora.
First, we use the Web 1-12 corpus to learn opti-
mal parameter values for a , r, and s and then as-
sess prediction error using a test-training paradigm
for the proposed model, Naive Bayes, and support
vector regression. Second, the trained model is ap-
plied with to the Reader A-Z corpus and the results
are compared with alternative semantic variables.
Because corpora can vary significantly in text ho-
mogeneity, amount of noise, document size, and
other factors, training and testing across different
corpora – rather than relying on cross-validation
with a single pooled dataset – gives valuable in-
formation about how a prediction method might
be expected to perform on data with widely differ-
ent characteristics. This particular choice of Web
1-12 for training and ReadingA-Z for testing was
arbitrary.
To evaluate the best values for the a parameter
in (6) and s, r parameters in Definition 1 we gen-
exp(at − 0.5)
</bodyText>
<equation confidence="0.998273">
Q(t) =
1 + exp(at − 0.5). (6)
</equation>
<page confidence="0.998609">
905
</page>
<figure confidence="0.993976655172414">
Predicted v Actual Grade Level
12
10
8
6
Correlation
4
2
Readability Level Prediction: MAE and Correlation
0.5 0.6 0.7 0.8 0.9
Mean Absolute Error
2
3
1
0.9
0.8
Predicted Grade Level
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
S−th Percentile
2 4 6 8 10 12
Actual Grade Level
</figure>
<figureCaption confidence="0.742013875">
Figure 5: Mean absolute error (MAE) and correla-
tion coefficient as functions of the quantile param-
eter s at optimal levels of a and r, averaged over
100 training/test samples. The MAE is displayed
as the solid line and is aligned with the left axis
while the correlation is displayed as a dashed line
and is aligned with the right axis. 90% bootstrap
confidence intervals are displayed.
</figureCaption>
<bodyText confidence="0.99974737037037">
erated 100 independent test and training samples
and computed the mean absolute prediction error
(MAE) and the correlation coefficient between the
predicted and actual levels. Figure 5 (left) shows
these two quantities: in each group of three lines,
the top and bottom lines delineate the upper and
lower 90% confidence bounds for the middle line.
Each middle line gives mean error or correlation
as a function of the quantile parameter s at opti-
mal levels of r and a, averaged over the 100 train-
ing/test samples. The optimal value of s for both
quantities is around 0.6 (0.65 for the MAE). The
optimal value for parameter a was approximately
1.55. The best MAE is 1.4 which compares favor-
ably to the 2.92 MAE obtained by always predict-
ing Grade 6 which is the optimal “dumb” classifier
in the sense that of all constant predictors it pro-
vides the smallest expected MSE over a uniform
grade distribution as is the case with the Web1-
12 corpus. Figure 6 is a scatter plot comparing
predicted grades vs. actual grades, with a strong
correlation of 0.89.
We compared the predictions of model (3) to
two standard classifiers: naive Bayes and support
vector regression (SVR). SVR was applied twice
using different sets of features - once with the doc-
ument word frequencies and once with the esti-
</bodyText>
<figureCaption confidence="0.995890333333333">
Figure 6: The scatter plot demonstrates the strong
relationship between predicted and actual global
readability levels.
</figureCaption>
<table confidence="0.988365">
Prediction Rule MAE LB UB
Age of Acquisition 1.40 1.19 1.67
Naive Bayes 1.98 1.71 2.26
SVR (word frequency) 1.86 1.69 2.06
SVR (AoA percentiles) 1.36 1.22 1.58
Grade 6 2.92 - -
</table>
<figureCaption confidence="0.8540348">
Figure 7: A comparison of mean absolute error
(MAE) across prediction algorithms shows the age
of acquisition model compares favorably. The
confidence bounds (LB,UB) were computed by re-
peating each model building procedure 100 times.
</figureCaption>
<bodyText confidence="0.999881666666666">
mated AoA percentiles for the document words.
The document word frequency vector is compa-
rable to the semantic component of the machine
learning approach used by (Heilman et al., 2008).
The 75-25 training-test model building paradigm
was used over documents from grades 1 to 12
to obtain predicted values. The MAE for these
predictors and their 90% confidence intervals are
shown in Figure 7. Predicting readability using
word frequencies had inferior performance, with
the naive Bayes model performing poorly and the
SVR and Rasch model obtaining MAE around 1.4.
In the second experiment, we compared our
model to published correlation results (Collins-
Thompson and Callan, 2005) for multiple alter-
native semantic variables using the same Reading
A-Z corpus, with the results shown in Fig. 8. De-
tails on these semantic variables, which have been
used in previous statistical learning approaches,
are available in the same study. Interestingly, the
correlation of the model was comparable to ex-
</bodyText>
<page confidence="0.995033">
906
</page>
<table confidence="0.998616333333333">
Correlation Correlation
GL (Web) .65 UNK .78
GL (WR) .40 Type .86
Bristol (Web) .76 MLF .49
Bristol (WR) .57 FK .30
Inferred (Web) .59 Unigram .63
</table>
<figureCaption confidence="0.6989225">
Figure 8: Comparison of the correlation of AoA
and other semantic variables with grade level for
the Reading A-Z corpus, showing the AoA model
with the dynamic threshold compares well to ex-
isting methods. The competitor methods used
are from (Collins-Thompson and Callan, 2005)
and comprise the Smoothed Unigram, UNK (rel-
ative to revised Dale-Chall), TYPE (number of
unique words), MLF (mean log frequency), and
FK (Flesch-Kincaid readability).
</figureCaption>
<bodyText confidence="0.999933636363636">
isting variables, but did vary depending upon the
source of AoA. Note that because the Reading A-Z
texts were assigned grades by their creators using
some of the same semantic variables (e.g. Type),
it is not surprising that those variables perform es-
pecially well on this dataset.
High quality readability prediction is a worth-
while result in itself; however, we can also use the
prediction mechanism to study the validity of Def-
inition 1 and the Rasch model. We do so by apply-
ing other predictive algorithms using the inferred
acquisition age distribution for each document as
the predictor variables and comparing the MAE
with the MAE obtained by the estimated Rasch
model. In particular, we examine the performance
of support vector regression (SVR) using the esti-
mated AoA percentiles for each document as pre-
dictor variables. The results displayed in Fig-
ure 7 show that SVR and the dynamic threshold
prediction rule perform similarly well, suggesting
that Definition 1 and the Rasch model are suitable
models for readability prediction.
</bodyText>
<subsectionHeader confidence="0.8742255">
3.3.2 Prediction with Existing Acquisition
Age Norms
</subsectionHeader>
<bodyText confidence="0.999677222222222">
We now examine how predicting readability of
novel documents using acquisition ages obtained
in surveys perform in comparison to the ages ob-
tained from the maximum likelihood estimation.
We use the GL and Bristol age of acquisition
norms. The intersection of AoA norm data and the
Web Corpus are 1217 and 1012 words respectively
for the GL and Bristol measure; additionally, the
highest grade level associated with these word sets
</bodyText>
<table confidence="0.9841958">
S-th Dynamic
Prediction Rule Percentile Threshold
Age of Acquisition 1.69 1.40
GL Norms 1.73 1.42
Bristol Norms 1.97 1.79
</table>
<figureCaption confidence="0.81503425">
Figure 9: The Gilhooly and Logie AoA norms and
the Bristol norms are independent sources for ages
of acquisition. A comparison of the prediction
quality using these norms shows two things: 1) the
definition provides comparable prediction quality
using expert norms, and 2) the dynamic threshold
Q(t) improves prediction over the static threshold
(optimal s-th percentile) for the norms.
</figureCaption>
<table confidence="0.994292333333333">
AoA Web 1-12 Weekly
Source Reader
Inferred (Weekly Reader) - .91
Inferred (Web 1-12) 1.89 -
GL 2.05 1.14
Bristol 1.57 1.34
</table>
<bodyText confidence="0.9850961875">
Figure 10: The readability of WR documents was
predicted using 4 sources of AoA data. The pa-
rameters of the prediction model were fit using
only the Web data, or the WR data, or both sources
in the case of the GL and Bristol norms AoA data.
are eight and seven respectively. When applying
the prediction rule using AoA norms r is implic-
itly selected in the norming process as the result
is a single value instead of a distribution. Interest-
ingly, the optimal ranges of s-percentile, from 92
to 100, were the same for both the GL and Bristol
norms. Table 9 shows that the prediction accuracy
obtained using the GL Norms was almost identical
to that obtained with the inferred AoA, while the
Bristol Norms performed as well as some of the
competitor procedures.
</bodyText>
<subsectionHeader confidence="0.8399335">
3.3.3 Prediction Effectiveness across
Different Corpora
</subsectionHeader>
<bodyText confidence="0.9999655">
To provide additional evidence for our model’s
ability to generalize to new corpora, we exam-
ine how the learned r and s values vary when the
model is learned on one corpus and evaluated on
another, and how this affects the accuracy of the
readability prediction.
Figure 10 demonstrates the corpus used for tun-
ing the readability prediction has a large impact
on the quality of the prediction. Comparing the
MAE of the readability predictions on WR data
</bodyText>
<page confidence="0.990444">
907
</page>
<bodyText confidence="0.999992466666667">
when the age of acquisition is inferred from Web
data to the MAE when the AoA is inferred from
WR data shows the error rate more than doubles
from 0.90 to 1.89. The increase in error rate also
appears when the age of acquisition for WR data
is predicted using the AoA norm data. In this case
the prediction was performed using the parameters
identified when the model was trained on Web data
and when the model was trained on WR data. In
each case a tendency to overfit appears as the MAE
increases from 1.14 to 2.05 for the GL norms and
1.34 to 1.57 for the Bristol norms. Interestingly,
the Bristol norms perform better on WR data when
fit using the Web data, while the GL norms per-
form better when fit using the WR data.
</bodyText>
<sectionHeader confidence="0.999989" genericHeader="evaluation">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999948444444445">
Age of acquisition for word reading and under-
standing has been extensively studied as a learn-
ing factor in the psycholinguistics literature, where
AoA norms have been obtained using surveys. Ex-
amples of relevant literature are (Gilhooly and Lo-
gie, 1980; Zevin and Seidenberg, 2002). Our ap-
proach differs by connecting AoA to readability
through Definition 1 and using readability data to
estimate AoA norms from large amounts of au-
thentic language data. A related study is that by
Crossley et al. (2007) who used AoA to help dis-
criminate between authentic and simplified texts
for second-language readers.
In the past decade, there has been renewed in-
terest in corpus-based statistical models for read-
ability prediction. One example is the popular
Lexile measure (Stenner, 1996) which uses word
frequency statistics from a large English corpus.
Collins-Thompson and Callan (2005) introduced a
new approach based on statistical language mod-
eling, treating a document as a mixture of lan-
guage models for individual grades. Further re-
cent refinements in methods for readability predic-
tion include using machine learning methods such
as Support Vector Machines (Schwarm and Os-
tendorf, 2005), log-linear models (Heilman et al.,
2008), k-NN classifiers and combining semantic
and grammatical features (Heilman et al., 2007).
The growing number of features investigated by
these machine learning approaches reflect the fact
that reading difficulty is a complex phenomenon
involving many factors, from semantic difficulty
(vocabulary) to syntax and discourse complex-
ity, reader background, and others. While a full-
featured comparison between previous approaches
that includes AoA features would be very inter-
esting, our goal in this study was to provide a
clear analysis of the most fundamental factor of
readability, semantic difficulty, which accounts for
80-90% of the variance in readability prediction
scores (Chall and Dale, 1995). Because AoA is
a semantic, vocabulary-based representation, we
compare its effectiveness with the correspond-
ing semantic components from previous machine-
learning approaches in Sec. 3.3.1.
</bodyText>
<sectionHeader confidence="0.999867" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9999735">
While there have been several recent studies re-
garding word acquisition and readability our work
is the first to provide a quantitative connection be-
tween these two concepts in a statistically mean-
ingful way. The core assumption that we make
is Definition 1 which is consistent with standard
readability definitions e.g., (Chall and Dale, 1995)
and states that document readability level is deter-
mined by most people understanding most words.
The connection between word acquisition and
readability is both intuitive and useful. It allows
two degrees of freedom s = 1− E1 and r = 1− E2
to handle situations where different readability no-
tions exist. Experiments validate the model and
demonstrate interesting trends in word acquisi-
tions as compared to older oral acquisition stud-
ies. Experimental results show that the proposed
model is also effective in terms of predicting read-
ability level of documents on multiple datasets.
It compares favorably to naive Bayes and sup-
port vector regression, the latter being one of the
strongest regression baselines.
</bodyText>
<sectionHeader confidence="0.998965" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99974775">
The authors thank Joshua Dillon for downloading
the weekly reader data and pre-processing it. The
work described in this paper was funded in part by
NSF grant DMS-0604486.
</bodyText>
<sectionHeader confidence="0.999641" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992604571428571">
J. S. Chall and E. Dale. 1995. Readability Revisited:
The New Dale-Chall Readability Formula. Brook-
line Books, Brookline, MA.
K. Collins-Thompson and J. Callan. 2005. Predicting
reading difficulty with statistical language models.
J. of the American Soc. for Info. Science and Tech.,
56(13):598–605.
</reference>
<page confidence="0.983465">
908
</page>
<reference confidence="0.996364372093023">
M. Coltheart. 1981. The MRC psycholinguistic
database. Quarterly Journal of Experimental Psy-
chology, 33A:497–505.
M. Cortese and M. Khanna. 2008. Age acquisition
ratings for 3000 monosyllabic words. Behavior Re-
search Methods, 40:791–794.
S. A. Crossley, P. M. McCarthy, and D. S. McNa-
mara. 2007. Discriminating between second lan-
guage learning text-types. In Proc. of the Twenti-
eth International Florida Artificial Intelligence Re-
search Society Conference.
H. A. David and H. N. Nagaraja. 2003. Order Statis-
tics. Wiley, Marblehead, MA.
E. Fry. 1990. A readability formula for short passages.
Journal of Reading.
K. J. Gilhooly and R. H. Logie. 1980. Age of acquisi-
tion, imagery, concreteness, familiarity and ambigu-
ity measures for 1944 words. Behaviour Research
Methods and Instrumentation, 12:395–427.
M. Heilman, K. Collins-Thompson, J. Callan, and
M. Eskenazi. 2007. Combining lexical and gram-
matical features to improve readability measures for
first and second language texts. In Proc. of the Hu-
man Language Technology Conference.
M. Heilman, K. Collins-Thompson, and M. Eskenazi.
2008. An analysis of statistical models and features
for reading difficulty prediction. In The 3rd Work-
shop on Innovative Use ofNLP for Building Educa-
tional Applications.
S. E. Schwarm and M. Ostendorf. 2005. Reading level
assessment using support vector machines and sta-
tistical language models. In Proc. of the Association
of Computational Linguistics.
H. Stadthagen-Gonzalez and C. J. Davis. 2006. The
bristol norms for age of acquisition, imageabil-
ity, and familiarity. Behavior Research Methods,
38:598–605.
A. J. Stenner. 1996. Measuring reading comprehen-
sion with the Lexile Framework. Metametrics, Inc.,
Durham, NC.
J. D. Zevin and M. S. Seidenberg. 2002. Age of acqui-
sition effects in word reading and other tasks. Jour-
nal ofMemory and Language, 47(1):1–29.
</reference>
<page confidence="0.998718">
909
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.508081">
<title confidence="0.9986965">Statistical Estimation of Word Acquisition Application to Readability Prediction</title>
<author confidence="0.993795">Paul</author>
<affiliation confidence="0.8891435">Department of Purdue</affiliation>
<address confidence="0.882519">West Lafayette, IN</address>
<email confidence="0.999263">kidwellpaul@gmail.com</email>
<author confidence="0.993068">Guy</author>
<affiliation confidence="0.997883">College of Georgia Institute of</affiliation>
<address confidence="0.896719">Atlanta, GA</address>
<email confidence="0.998783">lebanon@cc.gatech.edu</email>
<author confidence="0.798065">Kevyn</author>
<affiliation confidence="0.938294">Microsoft</affiliation>
<address confidence="0.990002">Redmond, WA</address>
<email confidence="0.9999">kevynct@microsoft.com</email>
<abstract confidence="0.999610619047619">Models of language learning play a central role in a wide range of applications: from psycholinguistic theories of how people acquire new word knowledge, to information systems that can automatically match content to users’ reading ability. We present a novel statistical approach that can infer the distribution of a word’s likely acquisition age automatically from authentic texts collected from the Web. We then show that combining these acquisition age distributions for all words in a document provides an effective semantic component for predicting reading difficulty of new texts. We also compare our automatically inferred acquisition ages with norms from existing oral studies, revealing interesting historical trends as well as differences between oral and written word acquisition processes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J S Chall</author>
<author>E Dale</author>
</authors>
<title>Readability Revisited: The New Dale-Chall Readability Formula. Brookline Books,</title>
<date>1995</date>
<location>Brookline, MA.</location>
<contexts>
<context position="6040" citStr="Chall and Dale, 1995" startWordPosition="943" endWordPosition="946">roup of people. On the other hand, it is possible to reliably collect large quantities of readability data defined as pairs of documents and ages of intended audience. As we demonstrate later in the paper, such data may be automatically obtained by crawling specialized resources on the Web. We demonstrate how to use such data to estimate the word acquisition parameters (2) and to use the estimates to predict future readability ages. Traditionally, document readability has been defined in terms of the school grade level at which a large portion of the words have been acquired by most children (Chall and Dale, 1995). We propose the following interpretation of that definition, which is made appropriate for quantitative studies by taking into account the inherent randomness in the acquisition process. Definition 1. A document d = (w1,... , wm) is said to have (1 − ǫ1, 1 − ǫ2)-readability level t if by age t no less than 1−ǫ1 percent of the words in d have been acquired each by no less than 1 − ǫ2 percent of the population. We denote by qw the quantile function of the cdf corresponding to the acquisition distribution pw. In other words, qw(r) represents the age at which r percent of the population T have ac</context>
<context position="34162" citStr="Chall and Dale, 1995" startWordPosition="5695" endWordPosition="5698">al., 2007). The growing number of features investigated by these machine learning approaches reflect the fact that reading difficulty is a complex phenomenon involving many factors, from semantic difficulty (vocabulary) to syntax and discourse complexity, reader background, and others. While a fullfeatured comparison between previous approaches that includes AoA features would be very interesting, our goal in this study was to provide a clear analysis of the most fundamental factor of readability, semantic difficulty, which accounts for 80-90% of the variance in readability prediction scores (Chall and Dale, 1995). Because AoA is a semantic, vocabulary-based representation, we compare its effectiveness with the corresponding semantic components from previous machinelearning approaches in Sec. 3.3.1. 5 Discussion While there have been several recent studies regarding word acquisition and readability our work is the first to provide a quantitative connection between these two concepts in a statistically meaningful way. The core assumption that we make is Definition 1 which is consistent with standard readability definitions e.g., (Chall and Dale, 1995) and states that document readability level is determ</context>
</contexts>
<marker>Chall, Dale, 1995</marker>
<rawString>J. S. Chall and E. Dale. 1995. Readability Revisited: The New Dale-Chall Readability Formula. Brookline Books, Brookline, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Collins-Thompson</author>
<author>J Callan</author>
</authors>
<title>Predicting reading difficulty with statistical language models.</title>
<date>2005</date>
<journal>J. of the American Soc. for Info. Science and Tech.,</journal>
<volume>56</volume>
<issue>13</issue>
<contexts>
<context position="27895" citStr="Collins-Thompson and Callan, 2005" startWordPosition="4667" endWordPosition="4670">g. 8. Details on these semantic variables, which have been used in previous statistical learning approaches, are available in the same study. Interestingly, the correlation of the model was comparable to ex906 Correlation Correlation GL (Web) .65 UNK .78 GL (WR) .40 Type .86 Bristol (Web) .76 MLF .49 Bristol (WR) .57 FK .30 Inferred (Web) .59 Unigram .63 Figure 8: Comparison of the correlation of AoA and other semantic variables with grade level for the Reading A-Z corpus, showing the AoA model with the dynamic threshold compares well to existing methods. The competitor methods used are from (Collins-Thompson and Callan, 2005) and comprise the Smoothed Unigram, UNK (relative to revised Dale-Chall), TYPE (number of unique words), MLF (mean log frequency), and FK (Flesch-Kincaid readability). isting variables, but did vary depending upon the source of AoA. Note that because the Reading A-Z texts were assigned grades by their creators using some of the same semantic variables (e.g. Type), it is not surprising that those variables perform especially well on this dataset. High quality readability prediction is a worthwhile result in itself; however, we can also use the prediction mechanism to study the validity of Defin</context>
<context position="33113" citStr="Collins-Thompson and Callan (2005)" startWordPosition="5539" endWordPosition="5542">e, 1980; Zevin and Seidenberg, 2002). Our approach differs by connecting AoA to readability through Definition 1 and using readability data to estimate AoA norms from large amounts of authentic language data. A related study is that by Crossley et al. (2007) who used AoA to help discriminate between authentic and simplified texts for second-language readers. In the past decade, there has been renewed interest in corpus-based statistical models for readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins-Thompson and Callan (2005) introduced a new approach based on statistical language modeling, treating a document as a mixture of language models for individual grades. Further recent refinements in methods for readability prediction include using machine learning methods such as Support Vector Machines (Schwarm and Ostendorf, 2005), log-linear models (Heilman et al., 2008), k-NN classifiers and combining semantic and grammatical features (Heilman et al., 2007). The growing number of features investigated by these machine learning approaches reflect the fact that reading difficulty is a complex phenomenon involving many</context>
</contexts>
<marker>Collins-Thompson, Callan, 2005</marker>
<rawString>K. Collins-Thompson and J. Callan. 2005. Predicting reading difficulty with statistical language models. J. of the American Soc. for Info. Science and Tech., 56(13):598–605.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Coltheart</author>
</authors>
<title>The MRC psycholinguistic database.</title>
<date>1981</date>
<journal>Quarterly Journal of Experimental Psychology,</journal>
<pages>33--497</pages>
<contexts>
<context position="15217" citStr="Coltheart, 1981" startWordPosition="2522" endWordPosition="2523">e in which the word appeared. This is to be expected as authors use specific words only after they believe the words were acquired by a large portion of the intended audience. 3.2 Comparison with Oral Studies Among the related work in the linguistic community, are several studies concerning oral acquisitions of words. These studies estimate the age at which a word is acquired for oral use based an interview processes with participating adults. We focus specifically on the seminal study of acquisition ages performed by Gilhooly and Logie (GL) (1980) and made available through the MRC database (Coltheart, 1981). There are some substantial differences between these previous studies and our approach. We analyze the age acquisition process through document readability which leads to a written, rather than oral, notion of word acquisition. Furthermore, our estimates are based on documents written with a specific audience in mind, while the previous studies are based on interviewing adults regarding their childhood word acquisition process which is arguably less reliable due to the age difference between the acquisition and the interview. Finally, the GL study was performed in the late 1970s while our st</context>
</contexts>
<marker>Coltheart, 1981</marker>
<rawString>M. Coltheart. 1981. The MRC psycholinguistic database. Quarterly Journal of Experimental Psychology, 33A:497–505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cortese</author>
<author>M Khanna</author>
</authors>
<title>Age acquisition ratings for 3000 monosyllabic words. Behavior Research Methods,</title>
<date>2008</date>
<pages>40--791</pages>
<contexts>
<context position="18079" citStr="Cortese and Khanna (2008)" startWordPosition="3010" endWordPosition="3013">L AoA Figure 3: A scatter plot (s = 80, n = 50) of predicted age of acquisition versus Gilhooly and Logie’s values reveals the tendency for the written estimate to exceed the oral estimate (r2 = 0.34). A comparison to two more recent studies confirms relationships that are similar to those observed with GL AoA. The Bristol Norm study (Stadthagen-Gonzalez and Davis, 2006) was performed in an identical way to the GL study and comparing the lists of acquisition ages results in a mean absolute error of approximately 0.5 which is much lower than the .9 to 1.5 relative to GL. The recent AoA list of Cortese and Khanna (2008) showed an increase in correlation relative to the GL study (r2 = 0.43) potentially reflecting change in the acquisition process due to temporal effects. Residual Distribution: Predicted AoA versus Oral AoA S−percentile=80 −4 −2 0 2 4 Error (Predicted AoA − Actual AoA) Figure 4: The difference distribution between the GL and the inferred AoA from Web 1-12 is skewed to the right as would be expected since written AoA is higher than oral AoA. Relaxing the definition of readability by decreasing s results in higher inferred acquisition ages. Values of s in [0.5, 0.9] produced reasonable results, </context>
</contexts>
<marker>Cortese, Khanna, 2008</marker>
<rawString>M. Cortese and M. Khanna. 2008. Age acquisition ratings for 3000 monosyllabic words. Behavior Research Methods, 40:791–794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A Crossley</author>
<author>P M McCarthy</author>
<author>D S McNamara</author>
</authors>
<title>Discriminating between second language learning text-types.</title>
<date>2007</date>
<booktitle>In Proc. of the Twentieth International Florida Artificial Intelligence Research Society Conference.</booktitle>
<contexts>
<context position="32737" citStr="Crossley et al. (2007)" startWordPosition="5483" endWordPosition="5486">r on WR data when fit using the Web data, while the GL norms perform better when fit using the WR data. 4 Related Work Age of acquisition for word reading and understanding has been extensively studied as a learning factor in the psycholinguistics literature, where AoA norms have been obtained using surveys. Examples of relevant literature are (Gilhooly and Logie, 1980; Zevin and Seidenberg, 2002). Our approach differs by connecting AoA to readability through Definition 1 and using readability data to estimate AoA norms from large amounts of authentic language data. A related study is that by Crossley et al. (2007) who used AoA to help discriminate between authentic and simplified texts for second-language readers. In the past decade, there has been renewed interest in corpus-based statistical models for readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins-Thompson and Callan (2005) introduced a new approach based on statistical language modeling, treating a document as a mixture of language models for individual grades. Further recent refinements in methods for readability prediction include using mac</context>
</contexts>
<marker>Crossley, McCarthy, McNamara, 2007</marker>
<rawString>S. A. Crossley, P. M. McCarthy, and D. S. McNamara. 2007. Discriminating between second language learning text-types. In Proc. of the Twentieth International Florida Artificial Intelligence Research Society Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H A David</author>
<author>H N Nagaraja</author>
</authors>
<title>Order Statistics.</title>
<date>2003</date>
<publisher>Wiley,</publisher>
<location>Marblehead, MA.</location>
<contexts>
<context position="10017" citStr="David and Nagaraja, 2003" startWordPosition="1665" endWordPosition="1668">= 0.7). CI widths were computed using 1000 Monte Carlo samples generated from the fW model fit to the data and from the empirical distribution. Word distributions correspond to a 1577 word document written for a 7th grade audience taken from the Web 1-12 corpus. fW(w) = wα1+α2−1e−w/β2 Γ(α1)Γ(α2)βα1 1 βα2 2 � (01−02)tw 1 tα1−1e 0102 1 dt (1 � t)1−α2 95% CI Width which reverts to a Gamma when β1 = β2. The distribution of the s-percentile of fW, which amounts to (r, s)-readability of documents, can be analyzed by combining fW above with a standard normal approximation of order statistics (e.g., (David and Nagaraja, 2003)) where m is the document length and FW is the cdf corresponding to fW. Figure 1 shows the relationship between document length and confidence interval (CI) width in readability prediction. It contrasts the CI widths for model based intervals and empirical intervals. In both cases, documents of lengths larger than 100 words provide CI widths shorter than 1 year. This finding is also noteworthy as it provides empirical support for the long-standing ‘rule-ofthumb’ that readability measures become unreliable for passages of less than 100 words (Fry, 1990). 3 Experimental Results Our experimental </context>
</contexts>
<marker>David, Nagaraja, 2003</marker>
<rawString>H. A. David and H. N. Nagaraja. 2003. Order Statistics. Wiley, Marblehead, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Fry</author>
</authors>
<title>A readability formula for short passages.</title>
<date>1990</date>
<journal>Journal of Reading.</journal>
<contexts>
<context position="10575" citStr="Fry, 1990" startWordPosition="1757" endWordPosition="1758">f order statistics (e.g., (David and Nagaraja, 2003)) where m is the document length and FW is the cdf corresponding to fW. Figure 1 shows the relationship between document length and confidence interval (CI) width in readability prediction. It contrasts the CI widths for model based intervals and empirical intervals. In both cases, documents of lengths larger than 100 words provide CI widths shorter than 1 year. This finding is also noteworthy as it provides empirical support for the long-standing ‘rule-ofthumb’ that readability measures become unreliable for passages of less than 100 words (Fry, 1990). 3 Experimental Results Our experimental study is divided into three parts. The first part examines the word acquisition distributions that were estimated based on readability data. The second part compares the estimated (written) acquisition ages with oral acquisition ages obtained from interview studies reported in the literature. The third part focuses on using the estimated word acquisition distributions to predict document readability. These three experimental studies are described in the three subsections below. In our experiments we used three readability datasets. The corpora were com</context>
</contexts>
<marker>Fry, 1990</marker>
<rawString>E. Fry. 1990. A readability formula for short passages. Journal of Reading.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K J Gilhooly</author>
<author>R H Logie</author>
</authors>
<title>Age of acquisition, imagery, concreteness, familiarity and ambiguity measures for 1944 words.</title>
<date>1980</date>
<booktitle>Behaviour Research Methods and Instrumentation,</booktitle>
<pages>12--395</pages>
<contexts>
<context position="32486" citStr="Gilhooly and Logie, 1980" startWordPosition="5440" endWordPosition="5444"> was trained on Web data and when the model was trained on WR data. In each case a tendency to overfit appears as the MAE increases from 1.14 to 2.05 for the GL norms and 1.34 to 1.57 for the Bristol norms. Interestingly, the Bristol norms perform better on WR data when fit using the Web data, while the GL norms perform better when fit using the WR data. 4 Related Work Age of acquisition for word reading and understanding has been extensively studied as a learning factor in the psycholinguistics literature, where AoA norms have been obtained using surveys. Examples of relevant literature are (Gilhooly and Logie, 1980; Zevin and Seidenberg, 2002). Our approach differs by connecting AoA to readability through Definition 1 and using readability data to estimate AoA norms from large amounts of authentic language data. A related study is that by Crossley et al. (2007) who used AoA to help discriminate between authentic and simplified texts for second-language readers. In the past decade, there has been renewed interest in corpus-based statistical models for readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins</context>
</contexts>
<marker>Gilhooly, Logie, 1980</marker>
<rawString>K. J. Gilhooly and R. H. Logie. 1980. Age of acquisition, imagery, concreteness, familiarity and ambiguity measures for 1944 words. Behaviour Research Methods and Instrumentation, 12:395–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Heilman</author>
<author>K Collins-Thompson</author>
<author>J Callan</author>
<author>M Eskenazi</author>
</authors>
<title>Combining lexical and grammatical features to improve readability measures for first and second language texts.</title>
<date>2007</date>
<booktitle>In Proc. of the Human Language Technology Conference.</booktitle>
<contexts>
<context position="33551" citStr="Heilman et al., 2007" startWordPosition="5605" endWordPosition="5608"> readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins-Thompson and Callan (2005) introduced a new approach based on statistical language modeling, treating a document as a mixture of language models for individual grades. Further recent refinements in methods for readability prediction include using machine learning methods such as Support Vector Machines (Schwarm and Ostendorf, 2005), log-linear models (Heilman et al., 2008), k-NN classifiers and combining semantic and grammatical features (Heilman et al., 2007). The growing number of features investigated by these machine learning approaches reflect the fact that reading difficulty is a complex phenomenon involving many factors, from semantic difficulty (vocabulary) to syntax and discourse complexity, reader background, and others. While a fullfeatured comparison between previous approaches that includes AoA features would be very interesting, our goal in this study was to provide a clear analysis of the most fundamental factor of readability, semantic difficulty, which accounts for 80-90% of the variance in readability prediction scores (Chall and </context>
</contexts>
<marker>Heilman, Collins-Thompson, Callan, Eskenazi, 2007</marker>
<rawString>M. Heilman, K. Collins-Thompson, J. Callan, and M. Eskenazi. 2007. Combining lexical and grammatical features to improve readability measures for first and second language texts. In Proc. of the Human Language Technology Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Heilman</author>
<author>K Collins-Thompson</author>
<author>M Eskenazi</author>
</authors>
<title>An analysis of statistical models and features for reading difficulty prediction.</title>
<date>2008</date>
<booktitle>In The 3rd Workshop on Innovative Use ofNLP for Building Educational Applications.</booktitle>
<contexts>
<context position="26658" citStr="Heilman et al., 2008" startWordPosition="4469" endWordPosition="4472">lobal readability levels. Prediction Rule MAE LB UB Age of Acquisition 1.40 1.19 1.67 Naive Bayes 1.98 1.71 2.26 SVR (word frequency) 1.86 1.69 2.06 SVR (AoA percentiles) 1.36 1.22 1.58 Grade 6 2.92 - - Figure 7: A comparison of mean absolute error (MAE) across prediction algorithms shows the age of acquisition model compares favorably. The confidence bounds (LB,UB) were computed by repeating each model building procedure 100 times. mated AoA percentiles for the document words. The document word frequency vector is comparable to the semantic component of the machine learning approach used by (Heilman et al., 2008). The 75-25 training-test model building paradigm was used over documents from grades 1 to 12 to obtain predicted values. The MAE for these predictors and their 90% confidence intervals are shown in Figure 7. Predicting readability using word frequencies had inferior performance, with the naive Bayes model performing poorly and the SVR and Rasch model obtaining MAE around 1.4. In the second experiment, we compared our model to published correlation results (CollinsThompson and Callan, 2005) for multiple alternative semantic variables using the same Reading A-Z corpus, with the results shown in</context>
<context position="33462" citStr="Heilman et al., 2008" startWordPosition="5593" endWordPosition="5596">n the past decade, there has been renewed interest in corpus-based statistical models for readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins-Thompson and Callan (2005) introduced a new approach based on statistical language modeling, treating a document as a mixture of language models for individual grades. Further recent refinements in methods for readability prediction include using machine learning methods such as Support Vector Machines (Schwarm and Ostendorf, 2005), log-linear models (Heilman et al., 2008), k-NN classifiers and combining semantic and grammatical features (Heilman et al., 2007). The growing number of features investigated by these machine learning approaches reflect the fact that reading difficulty is a complex phenomenon involving many factors, from semantic difficulty (vocabulary) to syntax and discourse complexity, reader background, and others. While a fullfeatured comparison between previous approaches that includes AoA features would be very interesting, our goal in this study was to provide a clear analysis of the most fundamental factor of readability, semantic difficult</context>
</contexts>
<marker>Heilman, Collins-Thompson, Eskenazi, 2008</marker>
<rawString>M. Heilman, K. Collins-Thompson, and M. Eskenazi. 2008. An analysis of statistical models and features for reading difficulty prediction. In The 3rd Workshop on Innovative Use ofNLP for Building Educational Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Schwarm</author>
<author>M Ostendorf</author>
</authors>
<title>Reading level assessment using support vector machines and statistical language models.</title>
<date>2005</date>
<booktitle>In Proc. of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="33420" citStr="Schwarm and Ostendorf, 2005" startWordPosition="5586" endWordPosition="5590">d simplified texts for second-language readers. In the past decade, there has been renewed interest in corpus-based statistical models for readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins-Thompson and Callan (2005) introduced a new approach based on statistical language modeling, treating a document as a mixture of language models for individual grades. Further recent refinements in methods for readability prediction include using machine learning methods such as Support Vector Machines (Schwarm and Ostendorf, 2005), log-linear models (Heilman et al., 2008), k-NN classifiers and combining semantic and grammatical features (Heilman et al., 2007). The growing number of features investigated by these machine learning approaches reflect the fact that reading difficulty is a complex phenomenon involving many factors, from semantic difficulty (vocabulary) to syntax and discourse complexity, reader background, and others. While a fullfeatured comparison between previous approaches that includes AoA features would be very interesting, our goal in this study was to provide a clear analysis of the most fundamental</context>
</contexts>
<marker>Schwarm, Ostendorf, 2005</marker>
<rawString>S. E. Schwarm and M. Ostendorf. 2005. Reading level assessment using support vector machines and statistical language models. In Proc. of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Stadthagen-Gonzalez</author>
<author>C J Davis</author>
</authors>
<title>The bristol norms for age of acquisition, imageability, and familiarity. Behavior Research Methods,</title>
<date>2006</date>
<pages>38--598</pages>
<contexts>
<context position="17827" citStr="Stadthagen-Gonzalez and Davis, 2006" startWordPosition="2962" endWordPosition="2965">e tendency for the written acquisition age to exceed the oral one diminishes as the grade level increases. This represents the notion that at higher grades words are acquired in both oral and written senses at the same age. Predicted versus Oral Acquisition Age GL AoA Figure 3: A scatter plot (s = 80, n = 50) of predicted age of acquisition versus Gilhooly and Logie’s values reveals the tendency for the written estimate to exceed the oral estimate (r2 = 0.34). A comparison to two more recent studies confirms relationships that are similar to those observed with GL AoA. The Bristol Norm study (Stadthagen-Gonzalez and Davis, 2006) was performed in an identical way to the GL study and comparing the lists of acquisition ages results in a mean absolute error of approximately 0.5 which is much lower than the .9 to 1.5 relative to GL. The recent AoA list of Cortese and Khanna (2008) showed an increase in correlation relative to the GL study (r2 = 0.43) potentially reflecting change in the acquisition process due to temporal effects. Residual Distribution: Predicted AoA versus Oral AoA S−percentile=80 −4 −2 0 2 4 Error (Predicted AoA − Actual AoA) Figure 4: The difference distribution between the GL and the inferred AoA from</context>
</contexts>
<marker>Stadthagen-Gonzalez, Davis, 2006</marker>
<rawString>H. Stadthagen-Gonzalez and C. J. Davis. 2006. The bristol norms for age of acquisition, imageability, and familiarity. Behavior Research Methods, 38:598–605.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Stenner</author>
</authors>
<title>Measuring reading comprehension with the Lexile Framework.</title>
<date>1996</date>
<publisher>Metametrics, Inc.,</publisher>
<location>Durham, NC.</location>
<contexts>
<context position="33012" citStr="Stenner, 1996" startWordPosition="5527" endWordPosition="5528">en obtained using surveys. Examples of relevant literature are (Gilhooly and Logie, 1980; Zevin and Seidenberg, 2002). Our approach differs by connecting AoA to readability through Definition 1 and using readability data to estimate AoA norms from large amounts of authentic language data. A related study is that by Crossley et al. (2007) who used AoA to help discriminate between authentic and simplified texts for second-language readers. In the past decade, there has been renewed interest in corpus-based statistical models for readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins-Thompson and Callan (2005) introduced a new approach based on statistical language modeling, treating a document as a mixture of language models for individual grades. Further recent refinements in methods for readability prediction include using machine learning methods such as Support Vector Machines (Schwarm and Ostendorf, 2005), log-linear models (Heilman et al., 2008), k-NN classifiers and combining semantic and grammatical features (Heilman et al., 2007). The growing number of features investigated by these machin</context>
</contexts>
<marker>Stenner, 1996</marker>
<rawString>A. J. Stenner. 1996. Measuring reading comprehension with the Lexile Framework. Metametrics, Inc., Durham, NC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Zevin</author>
<author>M S Seidenberg</author>
</authors>
<title>Age of acquisition effects in word reading and other tasks.</title>
<date>2002</date>
<journal>Journal ofMemory and Language,</journal>
<volume>47</volume>
<issue>1</issue>
<contexts>
<context position="32515" citStr="Zevin and Seidenberg, 2002" startWordPosition="5445" endWordPosition="5448">nd when the model was trained on WR data. In each case a tendency to overfit appears as the MAE increases from 1.14 to 2.05 for the GL norms and 1.34 to 1.57 for the Bristol norms. Interestingly, the Bristol norms perform better on WR data when fit using the Web data, while the GL norms perform better when fit using the WR data. 4 Related Work Age of acquisition for word reading and understanding has been extensively studied as a learning factor in the psycholinguistics literature, where AoA norms have been obtained using surveys. Examples of relevant literature are (Gilhooly and Logie, 1980; Zevin and Seidenberg, 2002). Our approach differs by connecting AoA to readability through Definition 1 and using readability data to estimate AoA norms from large amounts of authentic language data. A related study is that by Crossley et al. (2007) who used AoA to help discriminate between authentic and simplified texts for second-language readers. In the past decade, there has been renewed interest in corpus-based statistical models for readability prediction. One example is the popular Lexile measure (Stenner, 1996) which uses word frequency statistics from a large English corpus. Collins-Thompson and Callan (2005) i</context>
</contexts>
<marker>Zevin, Seidenberg, 2002</marker>
<rawString>J. D. Zevin and M. S. Seidenberg. 2002. Age of acquisition effects in word reading and other tasks. Journal ofMemory and Language, 47(1):1–29.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>