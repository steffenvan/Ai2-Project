<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012690">
<title confidence="0.9941835">
Comparing Wikipedia and German Wordnet
by Evaluating Semantic Relatedness on Multiple Datasets
</title>
<author confidence="0.869689">
Torsten Zesch and Iryna Gurevych and Max Mühlhäuser
</author>
<affiliation confidence="0.9222315">
Ubiquitous Knowledge Processing Group, Telecooperation Division
Darmstadt University of Technology, D-64289 Darmstadt, Germany
</affiliation>
<email confidence="0.896839">
{zesch,gurevych,max} (at) tk.informatik.tu-darmstadt.de
</email>
<sectionHeader confidence="0.990918" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999731769230769">
We evaluate semantic relatedness mea-
sures on different German datasets show-
ing that their performance depends on: (i)
the definition of relatedness that was un-
derlying the construction of the evalua-
tion dataset, and (ii) the knowledge source
used for computing semantic relatedness.
We analyze how the underlying knowl-
edge source influences the performance
of a measure. Finally, we investigate the
combination of wordnets and Wikipedia to
improve the performance of semantic re-
latedness measures.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999945837837838">
Semantic similarity (SS) is typically defined via the
lexical relations of synonymy (automobile – car)
and hypernymy (vehicle – car), while semantic re-
latedness (SR) is defined to cover any kind of lexi-
cal or functional association that may exist between
two words. Many NLP applications, like sense tag-
ging or spelling correction, require knowledge about
semantic relatedness rather than just similarity (Bu-
danitsky and Hirst, 2006). For these tasks, it is not
necessary to know the exact type of semantic rela-
tion between two words, but rather if they are closely
semantically related or not. This is also true for the
work presented herein, which is part of a project
on electronic career guidance. In this domain, it
is important to conclude that the words “baker” and
“bagel” are closely related, while the exact type of a
semantic relation does not need to be determined.
As we work on German documents, we evalu-
ate a number of SR measures on different German
datasets. We show that the performance of mea-
sures strongly depends on the underlying knowledge
source. While WordNet (Fellbaum, 1998) mod-
els SR, wordnets for other languages, such as the
German wordnet GermaNet (Kunze, 2004), contain
only few links expressing SR. Thus, they are not
well suited for estimating SR.
Therefore, we apply the Wikipedia category graph
as a knowledge source for SR measures. We show
that Wikipedia based SR measures yield better cor-
relation with human judgments on SR datasets than
GermaNet measures. However, using Wikipedia
also leads to a performance drop on SS datasets,
as knowledge about classical taxonomic relations
is not explicitly modeled. Therefore, we combine
GermaNet with Wikipedia, and yield substantial im-
provements over measures operating on a single
knowledge source.
</bodyText>
<sectionHeader confidence="0.994508" genericHeader="introduction">
2 Datasets
</sectionHeader>
<bodyText confidence="0.999482947368421">
Several German datasets for evaluation of SS or SR
have been created so far (see Table 1). Gurevych
(2005) conducted experiments with a German trans-
lation of an English dataset (Rubenstein and Goode-
nough, 1965), but argued that the dataset (Gur65)
is too small (it contains only 65 noun pairs), and
does not model SR. Thus, she created a German
dataset containing 350 word pairs (Gur350) con-
taining nouns, verbs and adjectives that are con-
nected by classical and non-classical relations (Mor-
ris and Hirst, 2004). However, the dataset is bi-
ased towards strong classical relations, as word
pairs were manually selected. Thus, Zesch and
Gurevych (2006) semi-automatically created word
pairs from domain-specific corpora. The resulting
ZG222 dataset contains 222 word pairs that are con-
nected by all kinds of lexical semantic relations.
Hence, it is particularly suited for analyzing the ca-
pability of a measure to estimate SR.
</bodyText>
<page confidence="0.985374">
205
</page>
<note confidence="0.609756833333333">
Proceedings of NAACL HLT 2007, Companion Volume, pages 205–208,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
DATASET YEAR LANGUAGE # PAIRS POS TYPE
Gur65 2005 German 65 N SS
Gur350 2006 German 350 N, V, A SR
ZG222 2006 German 222 N, V, A SR
</note>
<table confidence="0.9391554">
CORRELATION r
SCORES # SUBJECTS INTER INTRA
discrete {0,1,2,3,4} 24 .810 -
discrete {0,1,2,3,4} 8 .690 -
discrete {0,1,2,3,4} 21 .490 .647
</table>
<tableCaption confidence="0.999905">
Table 1: Comparison of datasets used for evaluating semantic relatedness.
</tableCaption>
<sectionHeader confidence="0.972436" genericHeader="method">
3 Semantic Relatedness Measures
</sectionHeader>
<bodyText confidence="0.999877636363636">
Semantic wordnet based measures Lesk (1986)
introduced a measure (Les) based on the number of
word overlaps in the textual definitions (or glosses)
of two terms, where higher overlap means higher
similarity. As GermaNet does not contain glosses,
this measure cannot be employed. Gurevych (2005)
proposed an alternative algorithm (PG) generating
surrogate glosses by using a concept’s relations
within the hierarchy. Following the description in
Budanitsky and Hirst (2006), we further define sev-
eral measures using the taxonomy structure.
</bodyText>
<equation confidence="0.999936875">
simPL = l(c1, c2)
l(c1, c2)
simLC = − log
2 x depth
simR,s = IC(ci) = − log(p(lcs(c1, c2)))
distiC = IC(c1) + IC(c2) − 2IC(lcs(c1, c2))
IC(lcs(c1, c2))
IC(c1) + IC(c2)
</equation>
<bodyText confidence="0.999948470588235">
PL is the taxonomic path length l(c1, c2) between
two concepts c1 and c2. LC normalizes the path
length with the depth of the taxonomy. Res com-
putes SS as the information content (IC) of the low-
est common subsumer (lcs) of two concepts, while
JC combines path based and IC features.1 Lin is
derived from information theory.
Wikipedia based measures For computing the
SR of two words w1 and w2 using Wikipedia, we
first retrieve the articles or disambiguation pages
with titles that equal w1 and w2 (see Figure 1). If
we hit a redirect page, we retrieve the correspond-
ing article or disambiguation page instead. In case
of an article, we insert it into the candidate article
set (A1 for w1, A2 for w2). In case of a disam-
biguation page, the page contains links to all en-
coded word senses, but it may also contain other
</bodyText>
<footnote confidence="0.6386235">
1Note that JC returns a distance value instead of a similarity
value resulting in negative correlation with human judgments.
</footnote>
<subsectionHeader confidence="0.552527">
Semantic Relatedness
</subsectionHeader>
<bodyText confidence="0.437839">
Semantic relatedness of (w1, w2)
</bodyText>
<figureCaption confidence="0.997716">
Figure 1: Steps for computing SR using Wikipedia.
</figureCaption>
<bodyText confidence="0.997715235294118">
links. Therefore, we only consider links conforming
to the pattern (Title_(DisambiguationText))2 (e.g.
“Train_(roller coaster)”). Following all such links
gives the candidate article set. If no disambiguation
links are found, we take the first link on the page, as
most important links tend to come first. We add the
corresponding articles to the candidate set. We form
pairs from each candidate article ai E A1 and each
article aj E A2. We then compute SR(ai, aj) for
each pair. The output of the algorithm is the maxi-
mum SR value maxazEA1iajEA2(SR(ai, aj)).3
As most SR measures have been developed for
taxonomic wordnets, porting them to Wikipedia re-
quires some modifications (see Figure 2). Text over-
lap measures can be computed based on the article
text, while path based measures operate on the cate-
gory graph. We compute the overlap between article
</bodyText>
<footnote confidence="0.856494333333333">
2‘_(DisambiguationText)’ is optional.
3Different from our approach, Strube and Ponzetto (2006)
use a disambiguation strategy that returns only a single candi-
date article pair. This unnecessarily limits a measure’s potential
to consider SR between all candidate article pairs. They also
limit the search for a lcs to a manually specified threshold of 4.
</footnote>
<figure confidence="0.998530130434783">
Candidate
article
sets
Candidate
article
pairs
Word w1
a
Article
A1
1
a
Redirects
a
Disambig. page
2
A2
1
Word w2
a
3
Max
simLin = 2 x
</figure>
<page confidence="0.804901">
206
</page>
<figureCaption confidence="0.999019">
Figure 2: SR measures adapted on Wikipedia.
</figureCaption>
<bodyText confidence="0.999825214285714">
texts based on (i) the first paragraph, as it usually
contains a short gloss, and (ii) the full article text.
As Wikipedia articles do not form a taxonomy, path
based measures have to be adapted to the Wikipedia
category graph (see the right part of Figure 2). We
define C1 and C2 as the set of categories assigned to
article az and aj, respectively. We compute the SR
value for each category pair (ck, cl) with ck E C1
and cl E C2. We use two different strategies to com-
bine the resulting SR values: First, we choose the
best value among all pairs (ck, cl), i.e., the minimum
for path based, and the maximum for information
content based measures. As a second strategy, we
average over all category pairs.
</bodyText>
<sectionHeader confidence="0.997496" genericHeader="method">
4 Experiments &amp; Results
</sectionHeader>
<bodyText confidence="0.999972131147541">
Table 2 gives an overview of our experimental re-
sults on three German datasets. Best values for each
dataset and knowledge source are in bold. We use
the PG measure in optimal configuration as reported
by Gurevych (2005). For the Les measure, we give
the results for considering: (i) only the first para-
graph (+First) and (ii) the full text (+Full). For the
path length based measures, we give the values for
averaging over all category pairs (+Avg), or tak-
ing the best SR value computed among the pairs
(+Best). For each dataset, we report Pearson’s cor-
relation r with human judgments on pairs that are
found in both resources (BOTH). Otherwise, the re-
sults would not be comparable. We additionally use
a subset containing only noun-noun pairs (BOTH
NN). This comparison is fairer, because article titles
in Wikipedia are usually nouns. Table 2 also gives
the inter annotator agreement for each subset. It con-
stitutes an upper bound of a measure’s performance.
Our results on Gur65 using GermaNet are very
close to those published by Gurevych (2005), rang-
ing from 0.69–0.75. For Gur350, the performance
drops to 0.38–0.50, due to the lower upper bound,
and because GermaNet does not model SR well.
These findings are endorsed by an even more sig-
nificant performance drop on ZG222. The measures
based on Wikipedia behave less uniformly. Les
yields acceptable results on Gur350, but is generally
not among the best performing measures. LC +Avg
yields the best performance on Gur65, but is outper-
formed on the other datasets by PL +Best, which
performs equally good for all datasets.
If we compare GermaNet based and Wikipedia
based measures, we find that the knowledge source
has a major influence on performance. When evalu-
ated on Gur65, that contains pairs connected by SS,
GermaNet based measures perform near the upper
bound and outperform Wikipedia based measures by
a wide margin. On Gur350 containing a mix of SS
and SR pairs, most measures perform comparably.
Finally, on ZG222, that contains pairs connected by
SR, the best Wikipedia based measure outperforms
all GermaNet based measures.
The impressive performance of PL on the
SR datasets cannot be explained with the struc-
tural properties of the category graph (Zesch and
Gurevych, 2007). Semantically related terms, that
would not be closely related in a taxonomic word-
net structure, are very likely to be categorized under
the same Wikipedia category, resulting in short path
lengths leading to high SR. These findings are con-
trary to that of (Strube and Ponzetto, 2006), where
LC outperformed path length. They limited the
search depth using a manually defined threshold,
and did not compute SR between all candidate ar-
ticle pairs.
Our results show that judgments on the perfor-
mance of a measure must always be made with re-
spect to the task at hand: computing SS or SR. De-
pending on this decision, we can choose the best un-
derlying knowledge source. GermaNet is better for
</bodyText>
<figure confidence="0.997381111111111">
Article1
Article2
A B
B D
Text1
Text2
C
Text based
Text1
Text1
First paragraph
Full text
Text2
Text2
Catego
Category
pairs
Combinati
strate
Wikipedia
category
graph
C1
Ca
of
A
A
</figure>
<page confidence="0.974796">
207
</page>
<table confidence="0.998618444444445">
GUR65 GUR350 ZG222
BOTH NN BOTH BOTH NN BOTH BOTH NN
# Word Pairs 53 116 91 55 45
Inter Annotator Agreement 0.80 0.64 0.63 0.44 0.43
PG 0.69 0.38 0.42 0.23 0.21
JC -0.75 -0.52 -0.48 -0.19 -0.25
GermaNet Lin 0.73 0.50 0.50 0.08 -0.12
Res 0.71 0.42 0.42 0.10 0.13
Les +First 0.16 0.36 0.32 0.01 0.11
Les +Full 0.19 0.34 0.37 0.13 0.17
PL +Avg -0.32 -0.34 -0.46 -0.36 -0.43
Wikipedia -0.35 -0.42 -0.53 -0.43 -0.49
PL +Best
LC +Avg 0.37 0.25 0.34 0.30 0.30
LC +Best 0.21 0.12 0.21 0.15 0.12
Linear 0.77 0.59 0.60 0.38 0.43
Combination - 0.55 - 0.48 -
POS
</table>
<tableCaption confidence="0.999716">
Table 2: Correlation r of human judgments with SR measures on different datasets.
</tableCaption>
<bodyText confidence="0.999593090909091">
estimating SS, while Wikipedia should be used to
estimate SR. Therefore, a measure based on a single
knowledge source is unlikely to perform well in all
settings. We computed a linear combination of the
best measure from GermaNet and from Wikipedia.
Results for this experiment are labeled Linear in Ta-
ble 2. POS is an alternative combination strategy,
where Wikipedia is only used for noun-noun pairs.
GermaNet is used for all other part-of-speech (POS)
combinations. For most datasets, we find a combi-
nation strategy that outperforms all single measures.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99968375">
We have shown that in deciding for a specific mea-
sure and knowledge source it is important to con-
sider (i) whether the task at hand requires SS or
SR, and (ii) which POS are involved. We pointed
out that the underlying knowledge source has a ma-
jor influence on these points. GermaNet is better
used for SS, and contains nouns, verbs, and adjec-
tives, while Wikipedia is better used for SR between
nouns. Thus, GermaNet and Wikipedia can be re-
garded as complementary. We have shown that com-
bining them significantly improves the performance
of SR measures up to the level of human perfor-
mance.
Future research should focus on improving the
strategies for combining complementary knowledge
sources. We also need to evaluate a wider range of
measures to validate our findings. As the simple PL
measure performs remarkably well, we should also
consider computing SR based on the Wikipedia arti-
cle graph instead of the category graph.
</bodyText>
<sectionHeader confidence="0.999236" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.691584">
This work was supported by the German Research Foundation
under grant &amp;quot;Semantic Information Retrieval from Texts in the
Example Domain Electronic Career Guidance&amp;quot;, GU 798/1-2.
</bodyText>
<sectionHeader confidence="0.993397" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.982786133333333">
Alexander Budanitsky and Graeme Hirst. 2006. Evaluating
WordNet-based Measures of Semantic Distance. Computa-
tional Linguistics, 32(1).
Christiane Fellbaum. 1998. WordNet An Electronic Lexical
Database. MIT Press, Cambridge, MA.
Iryna Gurevych. 2005. Using the Structure of a Conceptual
Network in Computing Semantic Relatedness. In Proc. of
IJCNLP, pages 767–778.
Claudia Kunze, 2004. Lexikalisch-semantische Wortnetze,
chapter Computerlinguistik und Sprachtechnologie, pages
423–431. Spektrum Akademischer Verlag.
Michael Lesk. 1986. Automatic Sense Disambiguation Us-
ing Machine Readable Dictionaries: How to tell a pine cone
from an ice cream cone. In Proc. of the 5th Annual Interna-
tional Conference on Systems Documentation, pages 24–26.
Jane Morris and Graeme Hirst. 2004. Non-Classical Lexical
Semantic Relations. In Proc. of the Workshop on Computa-
tional Lexical Semantics, NAACL-HTL.
Herbert Rubenstein and John B. Goodenough. 1965. Contex-
tual Correlates of Synonymy. Communications of the ACM,
8(10):627–633.
Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate!
Computing Semantic Relatedness Using Wikipedia. In Proc.
of AAAI, pages 1219–1224.
Torsten Zesch and Iryna Gurevych. 2006. Automatically Creat-
ing Datasets for Measures of Semantic Relatedness. In Proc.
of the Workshop on Linguistic Distances, ACL, pages 16–24.
T. Zesch and I. Gurevych. 2007. Analysis of the Wikipedia
Category Graph for NLP Applications. In Proc. of the
TextGraphs-2 Workshop, NAACL-HLT, (to appear).
</reference>
<page confidence="0.996186">
208
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.520230">
<title confidence="0.860323">Comparing Wikipedia and German by Evaluating Semantic Relatedness on Multiple Datasets</title>
<author confidence="0.700545">Zesch Gurevych</author>
<affiliation confidence="0.9104635">Ubiquitous Knowledge Processing Group, Telecooperation Darmstadt University of Technology, D-64289 Darmstadt,</affiliation>
<email confidence="0.982687">zesch(at)tk.informatik.tu-darmstadt.de</email>
<email confidence="0.982687">gurevych(at)tk.informatik.tu-darmstadt.de</email>
<email confidence="0.982687">max(at)tk.informatik.tu-darmstadt.de</email>
<abstract confidence="0.998163714285714">We evaluate semantic relatedness measures on different German datasets showing that their performance depends on: (i) the definition of relatedness that was underlying the construction of the evaluation dataset, and (ii) the knowledge source used for computing semantic relatedness. We analyze how the underlying knowledge source influences the performance of a measure. Finally, we investigate the combination of wordnets and Wikipedia to improve the performance of semantic relatedness measures.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating WordNet-based Measures of Semantic Distance.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="1285" citStr="Budanitsky and Hirst, 2006" startWordPosition="176" endWordPosition="180">dge source influences the performance of a measure. Finally, we investigate the combination of wordnets and Wikipedia to improve the performance of semantic relatedness measures. 1 Introduction Semantic similarity (SS) is typically defined via the lexical relations of synonymy (automobile – car) and hypernymy (vehicle – car), while semantic relatedness (SR) is defined to cover any kind of lexical or functional association that may exist between two words. Many NLP applications, like sense tagging or spelling correction, require knowledge about semantic relatedness rather than just similarity (Budanitsky and Hirst, 2006). For these tasks, it is not necessary to know the exact type of semantic relation between two words, but rather if they are closely semantically related or not. This is also true for the work presented herein, which is part of a project on electronic career guidance. In this domain, it is important to conclude that the words “baker” and “bagel” are closely related, while the exact type of a semantic relation does not need to be determined. As we work on German documents, we evaluate a number of SR measures on different German datasets. We show that the performance of measures strongly depends</context>
<context position="4561" citStr="Budanitsky and Hirst (2006)" startWordPosition="702" endWordPosition="705">,3,4} 8 .690 - discrete {0,1,2,3,4} 21 .490 .647 Table 1: Comparison of datasets used for evaluating semantic relatedness. 3 Semantic Relatedness Measures Semantic wordnet based measures Lesk (1986) introduced a measure (Les) based on the number of word overlaps in the textual definitions (or glosses) of two terms, where higher overlap means higher similarity. As GermaNet does not contain glosses, this measure cannot be employed. Gurevych (2005) proposed an alternative algorithm (PG) generating surrogate glosses by using a concept’s relations within the hierarchy. Following the description in Budanitsky and Hirst (2006), we further define several measures using the taxonomy structure. simPL = l(c1, c2) l(c1, c2) simLC = − log 2 x depth simR,s = IC(ci) = − log(p(lcs(c1, c2))) distiC = IC(c1) + IC(c2) − 2IC(lcs(c1, c2)) IC(lcs(c1, c2)) IC(c1) + IC(c2) PL is the taxonomic path length l(c1, c2) between two concepts c1 and c2. LC normalizes the path length with the depth of the taxonomy. Res computes SS as the information content (IC) of the lowest common subsumer (lcs) of two concepts, while JC combines path based and IC features.1 Lin is derived from information theory. Wikipedia based measures For computing th</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating WordNet-based Measures of Semantic Distance. Computational Linguistics, 32(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1952" citStr="Fellbaum, 1998" startWordPosition="295" endWordPosition="296">xact type of semantic relation between two words, but rather if they are closely semantically related or not. This is also true for the work presented herein, which is part of a project on electronic career guidance. In this domain, it is important to conclude that the words “baker” and “bagel” are closely related, while the exact type of a semantic relation does not need to be determined. As we work on German documents, we evaluate a number of SR measures on different German datasets. We show that the performance of measures strongly depends on the underlying knowledge source. While WordNet (Fellbaum, 1998) models SR, wordnets for other languages, such as the German wordnet GermaNet (Kunze, 2004), contain only few links expressing SR. Thus, they are not well suited for estimating SR. Therefore, we apply the Wikipedia category graph as a knowledge source for SR measures. We show that Wikipedia based SR measures yield better correlation with human judgments on SR datasets than GermaNet measures. However, using Wikipedia also leads to a performance drop on SS datasets, as knowledge about classical taxonomic relations is not explicitly modeled. Therefore, we combine GermaNet with Wikipedia, and yiel</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
</authors>
<title>Using the Structure of a Conceptual Network in Computing Semantic Relatedness.</title>
<date>2005</date>
<booktitle>In Proc. of IJCNLP,</booktitle>
<pages>767--778</pages>
<contexts>
<context position="2750" citStr="Gurevych (2005)" startWordPosition="421" endWordPosition="422">erefore, we apply the Wikipedia category graph as a knowledge source for SR measures. We show that Wikipedia based SR measures yield better correlation with human judgments on SR datasets than GermaNet measures. However, using Wikipedia also leads to a performance drop on SS datasets, as knowledge about classical taxonomic relations is not explicitly modeled. Therefore, we combine GermaNet with Wikipedia, and yield substantial improvements over measures operating on a single knowledge source. 2 Datasets Several German datasets for evaluation of SS or SR have been created so far (see Table 1). Gurevych (2005) conducted experiments with a German translation of an English dataset (Rubenstein and Goodenough, 1965), but argued that the dataset (Gur65) is too small (it contains only 65 noun pairs), and does not model SR. Thus, she created a German dataset containing 350 word pairs (Gur350) containing nouns, verbs and adjectives that are connected by classical and non-classical relations (Morris and Hirst, 2004). However, the dataset is biased towards strong classical relations, as word pairs were manually selected. Thus, Zesch and Gurevych (2006) semi-automatically created word pairs from domain-specif</context>
<context position="4383" citStr="Gurevych (2005)" startWordPosition="680" endWordPosition="681"> 65 N SS Gur350 2006 German 350 N, V, A SR ZG222 2006 German 222 N, V, A SR CORRELATION r SCORES # SUBJECTS INTER INTRA discrete {0,1,2,3,4} 24 .810 - discrete {0,1,2,3,4} 8 .690 - discrete {0,1,2,3,4} 21 .490 .647 Table 1: Comparison of datasets used for evaluating semantic relatedness. 3 Semantic Relatedness Measures Semantic wordnet based measures Lesk (1986) introduced a measure (Les) based on the number of word overlaps in the textual definitions (or glosses) of two terms, where higher overlap means higher similarity. As GermaNet does not contain glosses, this measure cannot be employed. Gurevych (2005) proposed an alternative algorithm (PG) generating surrogate glosses by using a concept’s relations within the hierarchy. Following the description in Budanitsky and Hirst (2006), we further define several measures using the taxonomy structure. simPL = l(c1, c2) l(c1, c2) simLC = − log 2 x depth simR,s = IC(ci) = − log(p(lcs(c1, c2))) distiC = IC(c1) + IC(c2) − 2IC(lcs(c1, c2)) IC(lcs(c1, c2)) IC(c1) + IC(c2) PL is the taxonomic path length l(c1, c2) between two concepts c1 and c2. LC normalizes the path length with the depth of the taxonomy. Res computes SS as the information content (IC) of </context>
<context position="8186" citStr="Gurevych (2005)" startWordPosition="1332" endWordPosition="1333"> respectively. We compute the SR value for each category pair (ck, cl) with ck E C1 and cl E C2. We use two different strategies to combine the resulting SR values: First, we choose the best value among all pairs (ck, cl), i.e., the minimum for path based, and the maximum for information content based measures. As a second strategy, we average over all category pairs. 4 Experiments &amp; Results Table 2 gives an overview of our experimental results on three German datasets. Best values for each dataset and knowledge source are in bold. We use the PG measure in optimal configuration as reported by Gurevych (2005). For the Les measure, we give the results for considering: (i) only the first paragraph (+First) and (ii) the full text (+Full). For the path length based measures, we give the values for averaging over all category pairs (+Avg), or taking the best SR value computed among the pairs (+Best). For each dataset, we report Pearson’s correlation r with human judgments on pairs that are found in both resources (BOTH). Otherwise, the results would not be comparable. We additionally use a subset containing only noun-noun pairs (BOTH NN). This comparison is fairer, because article titles in Wikipedia a</context>
</contexts>
<marker>Gurevych, 2005</marker>
<rawString>Iryna Gurevych. 2005. Using the Structure of a Conceptual Network in Computing Semantic Relatedness. In Proc. of IJCNLP, pages 767–778.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Kunze</author>
</authors>
<title>Lexikalisch-semantische Wortnetze, chapter Computerlinguistik und Sprachtechnologie,</title>
<date>2004</date>
<pages>423--431</pages>
<publisher>Spektrum Akademischer Verlag.</publisher>
<contexts>
<context position="2043" citStr="Kunze, 2004" startWordPosition="310" endWordPosition="311">related or not. This is also true for the work presented herein, which is part of a project on electronic career guidance. In this domain, it is important to conclude that the words “baker” and “bagel” are closely related, while the exact type of a semantic relation does not need to be determined. As we work on German documents, we evaluate a number of SR measures on different German datasets. We show that the performance of measures strongly depends on the underlying knowledge source. While WordNet (Fellbaum, 1998) models SR, wordnets for other languages, such as the German wordnet GermaNet (Kunze, 2004), contain only few links expressing SR. Thus, they are not well suited for estimating SR. Therefore, we apply the Wikipedia category graph as a knowledge source for SR measures. We show that Wikipedia based SR measures yield better correlation with human judgments on SR datasets than GermaNet measures. However, using Wikipedia also leads to a performance drop on SS datasets, as knowledge about classical taxonomic relations is not explicitly modeled. Therefore, we combine GermaNet with Wikipedia, and yield substantial improvements over measures operating on a single knowledge source. 2 Datasets</context>
</contexts>
<marker>Kunze, 2004</marker>
<rawString>Claudia Kunze, 2004. Lexikalisch-semantische Wortnetze, chapter Computerlinguistik und Sprachtechnologie, pages 423–431. Spektrum Akademischer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic Sense Disambiguation Using Machine Readable Dictionaries: How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proc. of the 5th Annual International Conference on Systems Documentation,</booktitle>
<pages>24--26</pages>
<contexts>
<context position="4132" citStr="Lesk (1986)" startWordPosition="641" endWordPosition="642">ng the capability of a measure to estimate SR. 205 Proceedings of NAACL HLT 2007, Companion Volume, pages 205–208, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics DATASET YEAR LANGUAGE # PAIRS POS TYPE Gur65 2005 German 65 N SS Gur350 2006 German 350 N, V, A SR ZG222 2006 German 222 N, V, A SR CORRELATION r SCORES # SUBJECTS INTER INTRA discrete {0,1,2,3,4} 24 .810 - discrete {0,1,2,3,4} 8 .690 - discrete {0,1,2,3,4} 21 .490 .647 Table 1: Comparison of datasets used for evaluating semantic relatedness. 3 Semantic Relatedness Measures Semantic wordnet based measures Lesk (1986) introduced a measure (Les) based on the number of word overlaps in the textual definitions (or glosses) of two terms, where higher overlap means higher similarity. As GermaNet does not contain glosses, this measure cannot be employed. Gurevych (2005) proposed an alternative algorithm (PG) generating surrogate glosses by using a concept’s relations within the hierarchy. Following the description in Budanitsky and Hirst (2006), we further define several measures using the taxonomy structure. simPL = l(c1, c2) l(c1, c2) simLC = − log 2 x depth simR,s = IC(ci) = − log(p(lcs(c1, c2))) distiC = IC(</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic Sense Disambiguation Using Machine Readable Dictionaries: How to tell a pine cone from an ice cream cone. In Proc. of the 5th Annual International Conference on Systems Documentation, pages 24–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Morris</author>
<author>Graeme Hirst</author>
</authors>
<title>Non-Classical Lexical Semantic Relations.</title>
<date>2004</date>
<booktitle>In Proc. of the Workshop on Computational Lexical Semantics, NAACL-HTL.</booktitle>
<contexts>
<context position="3155" citStr="Morris and Hirst, 2004" startWordPosition="485" endWordPosition="489"> Wikipedia, and yield substantial improvements over measures operating on a single knowledge source. 2 Datasets Several German datasets for evaluation of SS or SR have been created so far (see Table 1). Gurevych (2005) conducted experiments with a German translation of an English dataset (Rubenstein and Goodenough, 1965), but argued that the dataset (Gur65) is too small (it contains only 65 noun pairs), and does not model SR. Thus, she created a German dataset containing 350 word pairs (Gur350) containing nouns, verbs and adjectives that are connected by classical and non-classical relations (Morris and Hirst, 2004). However, the dataset is biased towards strong classical relations, as word pairs were manually selected. Thus, Zesch and Gurevych (2006) semi-automatically created word pairs from domain-specific corpora. The resulting ZG222 dataset contains 222 word pairs that are connected by all kinds of lexical semantic relations. Hence, it is particularly suited for analyzing the capability of a measure to estimate SR. 205 Proceedings of NAACL HLT 2007, Companion Volume, pages 205–208, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics DATASET YEAR LANGUAGE # PAIRS POS TYPE Gur6</context>
</contexts>
<marker>Morris, Hirst, 2004</marker>
<rawString>Jane Morris and Graeme Hirst. 2004. Non-Classical Lexical Semantic Relations. In Proc. of the Workshop on Computational Lexical Semantics, NAACL-HTL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Rubenstein</author>
<author>John B Goodenough</author>
</authors>
<title>Contextual Correlates of Synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="2854" citStr="Rubenstein and Goodenough, 1965" startWordPosition="434" endWordPosition="438">e show that Wikipedia based SR measures yield better correlation with human judgments on SR datasets than GermaNet measures. However, using Wikipedia also leads to a performance drop on SS datasets, as knowledge about classical taxonomic relations is not explicitly modeled. Therefore, we combine GermaNet with Wikipedia, and yield substantial improvements over measures operating on a single knowledge source. 2 Datasets Several German datasets for evaluation of SS or SR have been created so far (see Table 1). Gurevych (2005) conducted experiments with a German translation of an English dataset (Rubenstein and Goodenough, 1965), but argued that the dataset (Gur65) is too small (it contains only 65 noun pairs), and does not model SR. Thus, she created a German dataset containing 350 word pairs (Gur350) containing nouns, verbs and adjectives that are connected by classical and non-classical relations (Morris and Hirst, 2004). However, the dataset is biased towards strong classical relations, as word pairs were manually selected. Thus, Zesch and Gurevych (2006) semi-automatically created word pairs from domain-specific corpora. The resulting ZG222 dataset contains 222 word pairs that are connected by all kinds of lexic</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>Herbert Rubenstein and John B. Goodenough. 1965. Contextual Correlates of Synonymy. Communications of the ACM, 8(10):627–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>WikiRelate! Computing Semantic Relatedness Using Wikipedia.</title>
<date>2006</date>
<booktitle>In Proc. of AAAI,</booktitle>
<pages>1219--1224</pages>
<contexts>
<context position="6793" citStr="Strube and Ponzetto (2006)" startWordPosition="1079" endWordPosition="1082">onding articles to the candidate set. We form pairs from each candidate article ai E A1 and each article aj E A2. We then compute SR(ai, aj) for each pair. The output of the algorithm is the maximum SR value maxazEA1iajEA2(SR(ai, aj)).3 As most SR measures have been developed for taxonomic wordnets, porting them to Wikipedia requires some modifications (see Figure 2). Text overlap measures can be computed based on the article text, while path based measures operate on the category graph. We compute the overlap between article 2‘_(DisambiguationText)’ is optional. 3Different from our approach, Strube and Ponzetto (2006) use a disambiguation strategy that returns only a single candidate article pair. This unnecessarily limits a measure’s potential to consider SR between all candidate article pairs. They also limit the search for a lcs to a manually specified threshold of 4. Candidate article sets Candidate article pairs Word w1 a Article A1 1 a Redirects a Disambig. page 2 A2 1 Word w2 a 3 Max simLin = 2 x 206 Figure 2: SR measures adapted on Wikipedia. texts based on (i) the first paragraph, as it usually contains a short gloss, and (ii) the full article text. As Wikipedia articles do not form a taxonomy, pa</context>
<context position="10499" citStr="Strube and Ponzetto, 2006" startWordPosition="1712" endWordPosition="1715">a mix of SS and SR pairs, most measures perform comparably. Finally, on ZG222, that contains pairs connected by SR, the best Wikipedia based measure outperforms all GermaNet based measures. The impressive performance of PL on the SR datasets cannot be explained with the structural properties of the category graph (Zesch and Gurevych, 2007). Semantically related terms, that would not be closely related in a taxonomic wordnet structure, are very likely to be categorized under the same Wikipedia category, resulting in short path lengths leading to high SR. These findings are contrary to that of (Strube and Ponzetto, 2006), where LC outperformed path length. They limited the search depth using a manually defined threshold, and did not compute SR between all candidate article pairs. Our results show that judgments on the performance of a measure must always be made with respect to the task at hand: computing SS or SR. Depending on this decision, we can choose the best underlying knowledge source. GermaNet is better for Article1 Article2 A B B D Text1 Text2 C Text based Text1 Text1 First paragraph Full text Text2 Text2 Catego Category pairs Combinati strate Wikipedia category graph C1 Ca of A A 207 GUR65 GUR350 Z</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate! Computing Semantic Relatedness Using Wikipedia. In Proc. of AAAI, pages 1219–1224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torsten Zesch</author>
<author>Iryna Gurevych</author>
</authors>
<title>Automatically Creating Datasets for Measures of Semantic Relatedness.</title>
<date>2006</date>
<booktitle>In Proc. of the Workshop on Linguistic Distances, ACL,</booktitle>
<pages>16--24</pages>
<contexts>
<context position="3293" citStr="Zesch and Gurevych (2006)" startWordPosition="507" endWordPosition="510">for evaluation of SS or SR have been created so far (see Table 1). Gurevych (2005) conducted experiments with a German translation of an English dataset (Rubenstein and Goodenough, 1965), but argued that the dataset (Gur65) is too small (it contains only 65 noun pairs), and does not model SR. Thus, she created a German dataset containing 350 word pairs (Gur350) containing nouns, verbs and adjectives that are connected by classical and non-classical relations (Morris and Hirst, 2004). However, the dataset is biased towards strong classical relations, as word pairs were manually selected. Thus, Zesch and Gurevych (2006) semi-automatically created word pairs from domain-specific corpora. The resulting ZG222 dataset contains 222 word pairs that are connected by all kinds of lexical semantic relations. Hence, it is particularly suited for analyzing the capability of a measure to estimate SR. 205 Proceedings of NAACL HLT 2007, Companion Volume, pages 205–208, Rochester, NY, April 2007. c�2007 Association for Computational Linguistics DATASET YEAR LANGUAGE # PAIRS POS TYPE Gur65 2005 German 65 N SS Gur350 2006 German 350 N, V, A SR ZG222 2006 German 222 N, V, A SR CORRELATION r SCORES # SUBJECTS INTER INTRA discr</context>
</contexts>
<marker>Zesch, Gurevych, 2006</marker>
<rawString>Torsten Zesch and Iryna Gurevych. 2006. Automatically Creating Datasets for Measures of Semantic Relatedness. In Proc. of the Workshop on Linguistic Distances, ACL, pages 16–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zesch</author>
<author>I Gurevych</author>
</authors>
<title>Analysis of the Wikipedia Category Graph for NLP Applications.</title>
<date>2007</date>
<booktitle>In Proc. of the TextGraphs-2 Workshop, NAACL-HLT,</booktitle>
<note>(to appear).</note>
<contexts>
<context position="10214" citStr="Zesch and Gurevych, 2007" startWordPosition="1665" endWordPosition="1668">a based measures, we find that the knowledge source has a major influence on performance. When evaluated on Gur65, that contains pairs connected by SS, GermaNet based measures perform near the upper bound and outperform Wikipedia based measures by a wide margin. On Gur350 containing a mix of SS and SR pairs, most measures perform comparably. Finally, on ZG222, that contains pairs connected by SR, the best Wikipedia based measure outperforms all GermaNet based measures. The impressive performance of PL on the SR datasets cannot be explained with the structural properties of the category graph (Zesch and Gurevych, 2007). Semantically related terms, that would not be closely related in a taxonomic wordnet structure, are very likely to be categorized under the same Wikipedia category, resulting in short path lengths leading to high SR. These findings are contrary to that of (Strube and Ponzetto, 2006), where LC outperformed path length. They limited the search depth using a manually defined threshold, and did not compute SR between all candidate article pairs. Our results show that judgments on the performance of a measure must always be made with respect to the task at hand: computing SS or SR. Depending on t</context>
</contexts>
<marker>Zesch, Gurevych, 2007</marker>
<rawString>T. Zesch and I. Gurevych. 2007. Analysis of the Wikipedia Category Graph for NLP Applications. In Proc. of the TextGraphs-2 Workshop, NAACL-HLT, (to appear).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>