<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.817208">
Americium Journal of Computational Linguistics Microfiche 35
PROCEEDINGS
</note>
<sectionHeader confidence="0.935979666666667" genericHeader="abstract">
13TH ANNUAL MEETING
ASSOCIATION FOR COMPUTATIONAL LINGUISTICS
4: MODELING DISCOURSE AND WORLD KNOWLEDGE I
</sectionHeader>
<author confidence="0.519303">
Timothy C. Diller, Editor
</author>
<affiliation confidence="0.30203">
Sperry-Univac
</affiliation>
<note confidence="0.70233325">
St. Paul, Minnesota 55101
Copyright 45 1975 by the Association for Computational Linguistics
2
PREFACE
</note>
<bodyText confidence="0.966561608695652">
Session 4 centered around two major topics: modeling
the flow of information in discourse and representing and
utilizing the knowledge of the world shared by communicators.
The paper by Deutsch describes a mechahism for identifying
the referents of definite noun phrases within a task-oriented
dialogue. (Note the closely related paper by Klappholz and
Lockman in Session 5.) Bruce compares two discourse models:
a &amp;quot;discourse grammar&amp;quot; which defines the set of found and/or
likely discourse structures, and a &amp;quot;demand processor&amp;quot;, which
accounts for utterances as responses to and activators of
internal demands. Phillips presents various cohesive links
found in coherent discourse and then considers the inferen-
tial process essential to filling in knowledge only implicit
in the linking mechanisms. Cullingford discusses the major
components of SAM (Script Applier Mechanism), a computational
system modeling the organization and management of extra-
linguistic world knowledge. Badler describes a system for
translating visual input into propositional descriptions of
&amp;screte events. Focussing on a particular type of visual
input (American Sign Language), Kegl and Chinchor present the
use of frame analysis in describing various communicatory
devices in ASL. Thanks to Carl Hewitt for chairing this
session.--Timothy C. Diller, Program Committee Chairman
</bodyText>
<note confidence="0.330302">
TABLE OF CONTENTS
SESSION 4- MODELING DISCOURSE AND WORLD KNOWLEDGE
</note>
<title confidence="0.874931">
Establishing Context in Task-oriented Dialogs Barbara
</title>
<author confidence="0.981865">
G. Deutsch . . • • • • • • • • . 4
</author>
<affiliation confidence="0.957371">
Discourse Models and Language Comprehension Bertram C. Bruce 19
Judging the Coherency of Discourse Brian Phillips . . . 36
</affiliation>
<note confidence="0.478161333333333">
An Approach to the Organization of Mundane World Know-
ledge: The Generation and Management of Scripts R. E.
Cullingford . • • • • • . • • . 50
</note>
<title confidence="0.479309">
The Conceptual Description of Physical Activities Norman
</title>
<author confidence="0.554964">
Badler . • • • • • • • • . • • • • • 70
</author>
<affiliation confidence="0.262328">
A Frame Analysis of American Sign Language Judy Anne Kegl
</affiliation>
<note confidence="0.5679495">
and Nancy Chinchor • • • • • • • • • • 84
American Journal of Computational Linguistics Microfiche 35
</note>
<title confidence="0.310303">
ESTABLISHING CONTEXT IN TASK-ORIENTED DIALOGS
</title>
<author confidence="0.70461">
BARBARA G. DEOTSCH
</author>
<affiliation confidence="0.704798666666667">
Artificial Intelligence Center
Stanford Research Institute
Menlo Park, California 94025
</affiliation>
<sectionHeader confidence="0.940005" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999682416666667">
This paper describes part of the discourse component of a
speech understanding system for taskworiented dialogs,
specifically, a mechanism for establishing a focus of attention
to aid in identifying the referents of definite noun Phrases. In
building a representation of the dialog context, the discourse
processor takes advantage of the fact that task•orionted dialogs
hive a Structure that closely parallels the structure of the
task, The semantic network of the system is partitioned into
focus spaces with each focus space containing only those concepts
pertinent to the dialog relating to • subtask, The focus spaces
are linked to their corresponding subtasks and ordered in
hierarchy determined by the relations among subtasksi
</bodyText>
<sectionHeader confidence="0.683441" genericHeader="keywords">
Actnowledgment
</sectionHeader>
<footnote confidence="0.877600666666667">
This research was supported by the Defense Advanced Research
Projects Agency of the Department of Defense and monitored by the
U,$„ Army Research Office under Contract No, DAKC04•75•C•0006.
</footnote>
<note confidence="0.726513">
5
</note>
<sectionHeader confidence="0.970358" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.966226708333334">
Language communication entails the transmission of concepts
from the speaker&apos;s model of the world to the listener&apos;s, It is
crucial that the speaker be able to communicate descriptions of
concepts in his model in a way that allows the listener to Pick
out the relevant related concept in his model. In normal human
communication it IS not neceisary to describe a concept in a
completely unambiguous way, Contextual clues from both the
situation and the surrounding dialog are counted on to help
disambiguate, The listener&apos;s Problem is to use that context to
help in hi$ identification of the concept being communicated, As
a simple example, consider the utterance, &amp;quot;Hand me the box-end
wrench,&amp;quot; as it might occur in a conversation between two people
working on a maintenance task, Although many boxwend wrenches
may be known to both the speaker and the listener, the fact that
the listener has a Particular boxwend wrench in his hand makes
the noun phrase unambiguous, (For other examples, see Norman,
Rumelhart, et ai., 1975). In the most extreme case, the use of
pronouns depends entirely on the dialog context to determine the
intended referents &amp;quot;it&amp;quot; can refer to any single Inanimate object
or event.
A related problem arises with elliptical expressions. Often
the surrounding dialog supplies enough information so that only a
word or two suffices to communicate an entire (complex) idea,
For example, consider the following exchange:
</bodyText>
<note confidence="0.405825">
6
</note>
<title confidence="0.4819315">
Eg Bolt the pump to the Platform,
As 0,K,
Eg What tools are you using (to bolt the Pump
to the Platform],
AS My fingers tare the tools I am Using 1,13
The expressions in brackets indicate the full Utterance that was
</title>
<bodyText confidence="0.9573493">
meant by the partial utterance, The listener must fill in this
information from the surrounding dialog,
This paper considers such phenomena as they occur in
taskaoriented dialogs, By tasksioriented dialog we mean
conversation directed toward the completion of some task, In
Particular, we will be concerned with a ComPUter-based consultant
task in which an apprentice technician communicates with a
computer system about the repair of electromechanical devices,
The understanding System must maintain models of the world and of
the dialog to disambiguate references in the apprentice&apos;s speech,
</bodyText>
<sectionHeader confidence="0.671716" genericHeader="method">
DISCOURSE IN SPEECH UNDERSTANDING
</sectionHeader>
<bodyText confidence="0.9917414">
In a speech understanding system, the discourse component is
one of several sources of knowledge that must interact in
interpreting an utterance (see Paxton and A, Robinson, 1975;
Jo Robinson, 1975), Because of the uncertainty in the acoustic
signal, it is important that higher level sources of knowledge
Ilk , discourse give advice to the system at early stages in the
analysis, For this reason, in our current speech system,
routines for identifying the referents of definite noun Phrases
are applied as soon as a possible noun Phrase is identified
rather than waiting for an interpretation of the entire
</bodyText>
<page confidence="0.895804">
7
</page>
<bodyText confidence="0.999817">
utterance, In essence, the Procedure entails searching the
recent context to find possible referents and returning a list of
candidates,
Ellipsis and pronoun resolution require a more local context
than the resolution of nonpronominal definite noun phrases
(DNI4), A description of the processing for ellipsis and pronoun
resolution is contained in the section &amp;quot;Discourse Analysis and
Pragmatics&apos; in Walker et ale, 1975, In this paper we concentrate
on mechanisms for resolving DM&apos;
</bodyText>
<sectionHeader confidence="0.996175" genericHeader="method">
DEFINITE NOUN PHRASES
</sectionHeader>
<bodyText confidence="0.985112733333333">
The problem of resolving DRPs is basically a problem of
finding a matching structure in memory, In the case of a
computer system with a semantic network knowledge base, the
problem is that of finding the network structure corresponding to
the structure of the noun phrase, The node that maps onto the
head node of the parse structure representing the noun phrase is
the concept being identified by the noun phrase. For example, if
the knowledge base contains the nodes shown in Figure 1 (and
there are no other nodes with e (element) or s (superset) arcs to
wrenches), then either node WI or node W3, but not W2, will match
the phrase &amp;quot;the boxwend wrench&amp;quot;, Matching is not always so
Straightforward, For example, consider the Situation Portrayed
In Figure 2, The ed, or delineating element, arc (see
Hendrix, 1975a) links a node to delineating information about
members of the class that node represents, 13.0E is a set of
</bodyText>
<figure confidence="0.277533">
end type
TA-740522-83
</figure>
<figureCaption confidence="0.260415">
FIGURE 1 NETWORK DESCRIPTION OF THREE WRENCHES
</figureCaption>
<note confidence="0.737153">
SA 3805 27
FIGURE 2 SEMANTIC NET SHOWING MEMBERS OF TWO SUBSETS OF THE
SET &amp;quot;WRENCHES&amp;quot;
FIGURE 3 SEMANTIC NET SHOWING PARSE SPACE FOR
&amp;quot;BOX-END WRENCH&amp;quot;
</note>
<figure confidence="0.948620333333333">
HEW, DEF1
end type I
I
_1
FBEW, DEF.—
Iend type
I
L
9
</figure>
<bodyText confidence="0.980689142857143">
boxwend wrenches to which Wi belongs, &apos;OPE is a set of her-end
wrenches to which W2 belongs, If the apprentice now says,
a,,, the box•end wrench&amp;quot;, he means WI, The utterance level
structure created by parsing (see Hendrix. 1975b) for the phrase
the boxwend wrench&amp;quot;
deduction must be done
and W3.
The
the IMP
and arcs
is inside the space NP in Figure 3, some
to establish the correspondence between WI
structure matching routines that form a basic part of
resolver take as inputs a parse level network of nodes
and a data network to match it against, (The current
Matcher was written by Rs Ee &apos;likes), In general, a large number
of objects in the data net may be candidates for the matcher
(1,611, objects that are elements of the same set as the object
being identified bY the DNP)„ Since, in itself, the matcher ht
no way of deciding which objects to consider first, additional
mechanisms are needed to limit the search,
</bodyText>
<sectionHeader confidence="0.907108" genericHeader="method">
FOCUS SPACES
</sectionHeader>
<bodyText confidence="0.999731625">
The discourse componerit must determine a subnet of the
semantic net knowledge base for consideration by the matcher,
That is, it must be able to establish as a local context that
subset of the system&apos;s total knowledge base that is relevant ata
given point in the dialog, This is analogous to determining what
im in the user&apos;s focus of attention, Put another way, we would
like to highlight certain nodes and arcs of the semantic network,
In tasksoriented dialogs, tn. dialog Context is actually a
</bodyText>
<page confidence="0.68882">
10
</page>
<bodyText confidence="0.997721576923077">
composite of three different component contexts: a verbal
context, a task context, and a context of general world
knowledge. The verbal context includes the history of preceding
utterances, their syntactic form, the objects and actions
discussed in them, and the particular words used, The task
context is the focus supplied by the task being worked on, It
includes such information as: where the eurrent subtask fits in
the overall plane what its subtasks are, what actions are likely
to follow, what objects are important, The context of general
world knowledge is the information that reflects a background
understanding of the properties and interrelations of objects and
actions: for example, the fact that tool boxes typically contain
tools and that attaching entails some kind of fastening.
To highlight objects in the dialog and provide verbal
context, network partitioning is used in a new way, Hendrix
(i975a) has suggested imPosing a logical Partitioning on network
structures for encoding logical connectives and quantifiers,
Using the same technique, a focus partitioning may be used to
divide the network to a number of local contexts. Nodes and
arcs belong to both logical and focus spaces. The logical and
fOCUS partitions are independent of one another In the sense that
the logical spaces on which a node or arc lies neither determine
nor depend on the focus spaces in which the node or arc lies,
A new focus sPace is created for each subtask that cnters
the dialog. The task model (described shortly) imposes a
hierarchical ordering, bed on the subta k hierarchy, on these
</bodyText>
<page confidence="0.921441">
11
</page>
<bodyText confidence="0.921419">
spaces, This hierarchy determines what nodes and arcs are
visible from a given space, The arcs and nodes that belong to a
space are the only ones immediately visible from that space.
Arcs and nodes in spaces that are above a given space in the
hierarchy are potentially visible, but must be requested
specifically to be seen, Other arcs and nodes are not visible,
</bodyText>
<sectionHeader confidence="0.913504" genericHeader="method">
4 node may appear in anY number of focus spaces, When the
</sectionHeader>
<bodyText confidence="0.988246315789474">
same object is used in two different subtasks, either the same or
different aspects of the object may be in focus in the two
subtasks, It is also possible for a node or arc to be in no
focus space. In this case, the object is not stronglY associated
with the actual performance of any particular subtask, Such
objects must be described relative to the global task
environment, For completeness, we define a top-most space,
called the &amp;quot;communal sPace&amp;quot;, and a bottom-most space, called the
&amp;quot;vista space&amp;quot;, The communal space contains the relationships
that are time invariant (e.g., the fact that tools are found in
tool bones) or comnon to ell contexts, The vista space is below
all other spaces and hence can see everything in the sementic
net. This perspective is useful for determining all the
relationships into which an object has entered.
The task model in our system will be embodied in
procedural net which encodes the task structure in a hierarchy of
subtasks and encodes each subtask as a partial ordering of steps
(glactrdoti, 1975), The procedural net system also allows tasxs
to be expanded dynamically to further levels of detail when
</bodyText>
<page confidence="0.834428">
12
</page>
<bodyText confidence="0.935752846153846">
necessary, A representation of the hierarchy of subtasks is
important for reference resolution, An examination of
task•oriented dialogs shows that references operate within tasks
and up the hierarchy chain (Deutsch, 1974), Using the hierarchy
of the procedural net to impose a hierarchy on the focus spaces
enables us to search for references in hierarchical order.
Having a representation of the partial ordering of tasks allows
us to capture the alternatives the apprentice has in choosing
subsequent tasks.
We have explicitly separated the three components of the
dialog context, The representation of an object in a focus spice
will include only the relationships that have been mentioned in
the dialog concerning the corresponding subtask or that are
</bodyText>
<subsectionHeader confidence="0.536609285714286">
inherent in
Thus, the
recorded in
objects in
procedural
information
resolving a
</subsectionHeader>
<bodyText confidence="0.9976082">
the procedural net description of the local task,
verbal component is suPPlied bY the information
the focus space hierarchy, Forward references to
the task (task component) are found by examining the
net, The general world knowledge component is
that is present in the communal space, When
DNP, we can dynamically allocnt effort between
examining links in the local focus spacer looking forwnrd in the
task, looking back up the focus space) hierarchy, and looking
deeper into knowledge bag.* information,
</bodyText>
<sectionHeader confidence="0.755465" genericHeader="method">
GENERAL STRATZGY
</sectionHeader>
<bodyText confidence="0.982259">
The !;trategy we nro currently exploring is first to clmine
</bodyText>
<page confidence="0.825376">
13
</page>
<bodyText confidence="0.999584">
the currently active focus space and then to examine the next
level of detail in the task. If the referent cannot be found in
either of these location, we look UP the focus epees hierarchy
and then turtner down the task chain, The current context to be
used by the discourse processor includes:
</bodyText>
<listItem confidence="0.998735333333333">
(i) A focus space containing the objects currently in focus
(2) A link to the associated node in the task model
(3) A type flag used Jr setting up expectations,
</listItem>
<bodyText confidence="0.971983045454545">
The type is necessary because there are subdialogs that do not
directly reflect on the task structure, For example, there are
subdialogs about tool identification (&amp;quot;What is a wheelpuller?&amp;quot;)
and tool use (&amp;quot;How do I use this wrench?&amp;quot;). References in these
Subdialoqs do not follow the same focus space hierarchy and task
structure,
The dialog shown in Table 1 will be examined to show how a
comeination of a task model and focus spaces may be used to help
resolve DNPs,
Es I would like you to assemble the air compressor,
As 0,K,
Es I suggest you begin by attaching the pump to the Platform.
As 0,K,
Es What are you doing now?
As Using the pliers to get the nuts in underneath the platform.
ES I retlize this is a difficult task,
As I&apos;m tightening the bolts now, They&apos;re all in Place,
ES Coca.
As How tightly should I install this pipe elbow that fits into
the Pump?
Table is SubdialOg for aircompressor assembly.
A partial procedural net for assembling an air compreAsor is
</bodyText>
<page confidence="0.608509">
14
</page>
<bodyText confidence="0.994162157894737">
shown in Figure 4, The terms &amp;quot;install&amp;quot;. &amp;quot;connect&amp;quot;, &amp;quot;attach&amp;quot;
refer to conceptual actions rather than lexical items, The
dashed lines connect higher level tasks to their constituent
subtasks. The time sequence of steps in the task is left to
right. The partial ordering of tasks is encoded with the S and J
nodes, The S, or ANDSPLIT, node indicates the beginning of
Parallel branches in the partial ordering. The nodes on arcs
coming out of an 3 node may be done in any order, The J. or
ANDJOIN, node indicates a point where several parallel tasks must
be completed, The boxes labeled T are relevant to the subdialog
fragment.
In the following analysis of the dialog, the utterances are
considered seguentiallY. DNP resolution is Considered in
relation to the dialog history and the procedural net task model.
(The search for references inside foculi spaces is currently
implemented, integration with the task model is not.) The context
information listed under (1)-(3) above is shown in the
accompanying figures as follows: (1) label on spaceS in the
network, (2) PNETTIE; (3) FSTYPE,
</bodyText>
<sectionHeader confidence="0.894428666666667" genericHeader="method">
El I would like you to assemble the air compfessor.
Ai O.K.
El I Suggest you begin by attaching the pump to the platform.
</sectionHeader>
<bodyText confidence="0.718248">
CAt this Point, we are at task Tip focus spaces FSO and FM showr
in Figure 5 have been set up.)
As 0„K„
EThiS Could mean I&apos;m done, but the response comes right after th:
instruction and the task t4K414 a while.]
</bodyText>
<figure confidence="0.998921218045113">
I
1
1
1
1
L
1
I
I
T5
1
I
INSTALL
AFTERCOOL ER
ELBOW
1
I
I
I
CONNECT
A5TERCOOLER
ELBOW TO
PUMP
CONNECT
PUMP TO S
PLATFORM
I I \
Li T3
1
1
1
1
1
T2
I NST AL L
BELT
II
I I
- ---1
CONN ECT
BELT TO
PUMP
PULLEY
CONNECT
BELT TO
MOTOR PULLEY
CONN ECT
A F TERCOOLER
TO
AF TERCOOLER
ELBOW
CONNECT
AFTERCOOLER
TO TANK
CONNECT
BELT
HOUSING
COVER TO
BE LT
HOUSING
FRAME
I
INSTALL
PUMP
PULLEY
/
/
/
/
/
/
POSITION
PUMP ON
PLATFORM
•
•
•
ATTACH
PUMP TO
PLATFORM
a • •
START PUMP-
MOUNT NUTS
AND BOLTS
T6
• • •
S.,
• • 0
• • •
1
I
\
,
/
• 41 •
• • •
• • •
• • •
INSTALL
PUMP
CONNECT
PUMP
......2-4 PULLEY
TO PUMP
CONNECT
PUMP BRACE
TO PUMP
I
T4 I
TIGHTEN PUMP-
MOUNT NUTS
AND BOLTS
FIGURE 5 FOCUS SPACES FSO AND FS1
TA -740522-86
FSO
PNETTIE TO
FSTYPE TASK
ASSEMBLE-OPS
FS1
PNETTIE Ti
FSTYPE TASK
TA 740522 85
major-part
fasteners
objects
POSITIONINGS
tool
LFS4
ATTACH-OPS
FS4
PNETTIE T4
FSTYPE TASK
16
</figure>
<footnote confidence="0.703199">
FIGURE 6 FOCUS SPACE FOR STARTING BOLT/NUTS OPERATION
</footnote>
<page confidence="0.735686">
17
</page>
<bodyText confidence="0.923199666666667">
Et What are you doing now?
(Atter a suitable waiting period, the expert queries the progress
of the user.]
</bodyText>
<subsectionHeader confidence="0.585594">
A: Using the Pliers to get the nuts in underneath the Platfor
</subsectionHeader>
<bodyText confidence="0.995027733333333">
(&amp;quot;The pliers&amp;quot; can be resolved because there is only one pair; if
this weLe floc the case, the task model would have to be
consulted, For both &amp;quot;the nuts&amp;quot; and &amp;quot;the platform&amp;quot;, the FS
hierarchy is consulted, &amp;quot;The platform&amp;quot;, Pi is in focus in the
current FS, There is no sign of nuts so we look forward in the
task model. The relevant Parts are located in subtask T49 This
Causes a new context, to be established at shown in Figure 6,3
Et I realize this is a difficult task,
(An attempt to assess the apprentice&apos;s perception of the problem.
Note that at this point the task has barely begun and the expert
does not have a very good model of the apprentice,)
At I&apos;m tightening the bolts now, They&apos;re all in Place,
(F64 contains &amp;quot;the bolts&amp;quot;; they were brought into focus when T4
was started, &amp;quot;They&amp;quot; is determined to refer to &amp;quot;the bolts&amp;quot; by
checking the objects in the previous utterance for number
agreement, Note that the last statement confirms the closure of
T4. &amp;quot;Tighten&amp;quot; Opens T5,1
E: Good,
As How tightly should I install this pipe elbow that fits into
the pump?
(There is no piPe elbow in the current FS, (Note that up until
that point in the query the apprentice might have been asking
about task T5), We close T51 because of the task structure this
brings us back up to the top level, we are at the point of
looking into new tasks. At present all of the tasks are
Cono:dered equally, Eventually T6 is found to involve an elbow,3
In summation, then, the focus spaces provide a way of
isolating certain Parts of the semantic net, thus providing a way
to focus on immediately relevant information, By tying the focus
Spaces to a model of the task, we are able to consider forward
</bodyText>
<subsectionHeader confidence="0.39364">
18
</subsectionHeader>
<bodyText confidence="0.994129428571428">
task references. Both the task model and the focus spaces are
linked to the genera&apos; knowledge base, thus, it is possible to go
from an item in either the task model or a focui space to other
known but not previously referenced information about that item,
The focus spaces and task model provide access to context
information about objects in the domain, making it possible to
focus on a relevant subset of the system&apos;s knowledge,
</bodyText>
<sectionHeader confidence="0.767002" genericHeader="method">
References
</sectionHeader>
<table confidence="0.971255090909091">
Deutsch, Barbara G, The Structure of Task•Oriented Dialogs.
Contributed Papers, IEEE Symposium on Speech Recognition,
Carnegie.Mellon University, Pittsburgh, Pennsylvania,
15.19 April 1974, IEEE, New York. 1974, 230.254,
Hendrix, Gary G. Expanding the Utility of Semantic Networks
Through Partitioning, Advance Papers of the Fourth International
Joint Conference on Artificial Intelligence, Tbilisi,
Georgia, USSR, 3.1 September 1975, 115-121 (a).
Hendrix, Gary Gil Semantic Processing for speech
Understanding. Presented at the Thirteenth Annual Meeting of the
Association for Computational Linguistics, Boston, Massachusetts,
30 October • 1 November 1975 (b).
Norman, De Aof Rumelhart, D, Et, at al., Explorations in
Cognition, W. H, Freeman and Company, San Francisco, 1975.
Paxton, William lis, and Robinson, Ann E, System Integration
and Control in a Speech Understanding System, Presented at the
Thirteenth Annual Meeting of the Association tor Computational
Linguistics, Boston, Massachusetts, 30 October - 1 November 1975,
Robinson, Jane J, A Tuneable Performance Grammar.
Presented at the Thirteenth Annual meeting of the Association tor
Computational Linguistics, Boston, Massachusetts, 30 October 1
November 1975.
Secerdoti, Earl, A Structure tor Plans and Behavior,
Technical Note 109, Artificial Intelligence Center, Stanford
Research Institute, Menlo Park, California, August 1975,
Walker, Donald E., et al. Speech Understanding Researcn,
Annual Report, Project 3004, Artificial Intelligence Center,
Stanford Research Institute, Menlo Park, California, June 1975,
of C arofiche 3$
DISCOURSE MODELS AND LANGUAGE COMPREHENSION
BERTRAM C. BRUCE
Bolt Beranek and Newman Inc.
50 Moulton Street Cambridge, Massachusetts 02138
</table>
<sectionHeader confidence="0.596327" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9142446875">
Higher order structures such as &amp;quot;discourse&amp;quot; and &amp;quot;intention&amp;quot;
must be included in any complete theory of language
understanding. This paper compares two approaches to modeling
discourse. The first centers on the concept of a &amp;quot;discourse
grammar&amp;quot; which defines the set of likely (i.e. easily
understood) discourse structures.
A second approach is a &amp;quot;demand processing&amp;quot; model which
utterances create demands on both the speaker and the hearer.
Responses to these demands are based on their relative
&amp;quot;importance&amp;quot;. he length of time they have been around, and
conditions attached to each demand. The flow of responses
provides another level of explanation for the discourse
structure.
These two approaches are discussed in terms of flexibility,
efficiency, and of their role in a more complete theory of
discourse understanding.
</bodyText>
<figure confidence="0.4275315">
20
Introdug
</figure>
<bodyText confidence="0.935252285714286">
As has ben said many times, understanding anything a
problem, an action, a word - demands some knowledge of the
context in which it appears. Certainly this is true of language,
where an utterance s meaning may depend upon who the speaker
when he is talking, what has just been said, who the listeners
are, what the Purpose of the conversation is, and so on. It is
reasonable to define language understanding as the process of
applying contextual knowledge to a sound (or string of symbols)
to produce a change in that context. Successful language
understanding occurg whenever the changes in the hearer s context
(model of the world) coincides with changes the speaker intended.
Of course, stating a problem in a different way does not
solve- it. Instead it suggests a series of subsidiary questions
such as:
</bodyText>
<listItem confidence="0.999172111111111">
(1) What is a context? What does it look like? What are
its components, its structural characteristics?
(2) How does a new utterance change an existing
context? What is the assimilation process? What must be
kept; what can de discarded?
(3) How does a model of changing context account for
observed phenomena such as the ability to switch
contexts, and to return later (but not too much later)?
(4) How does the domain of conversation influence the
</listItem>
<page confidence="0.529541">
21
</page>
<bodyText confidence="0.999420923076923">
structure of a &amp;quot;context&amp;quot;? Do different mechanisms
operate when the subject matter is tightly constrained?
It may be quite a while before questions of this type can be
answered fully. This paper is a discussion of some of the issues
and of the characteristics required of a solution. To do this,
we will examine two classes of discourse models which have been
proposed. The first is a &amp;quot;discourse grammar&amp;quot; approach which
attempts to define the set of likely sequences of utterances.
the second is a &amp;quot;demand processor&amp;quot; approach which attempts to
account for utterances as responses to internal demands. Before
discussing the specifics of these models, a sample dialogue, from
the much restricted world of man-machine communication, is
presented and discussed in Section 2.
</bodyText>
<listItem confidence="0.5756">
2. An Example from Travel Budget Management
</listItem>
<bodyText confidence="0.8084854">
The problem of discourse understanding is complex enough
that a complete analysis is certainly premature. We will examine
here a micro-discourse, restricted to two conversants, one of
them a machine, and, a conversation restricted in scope to that
of managing a travel budget. Imagine that a person responsible
for a travei budget is trying to decide how many people to send
to an upcoming conference. He has available a computer system
which can answer questions about the budget, conferences, trips
and so on. In talking to such a system, the travel budget
22
manager is engaging in an admittedly simple dialogue, but one
which nevertheless exhibits many interesting properties of
discourse understanding. (The following dialogue is
hypothetical; however a system of this type is being developed at
BBN (Woods, et al (1974, 1975))). The (human) manager begins:
</bodyText>
<listItem confidence="0.994040428571429">
(1) WHEN IS THE NEXT ASSP CONFERENCE?
May 15-18, 1975
(2) IS THAT IN OUR CURRENT BUDGET YEAR?
Yes.
(3) HOW MUCH MONEY DO WE HAVE LEFT?
$316,41 remains in the budget.
(4) WHAT IS THE COST OF THE ASSP CONFERENCE?
</listItem>
<bodyText confidence="0.989986">
The registration fee is $25. Would you like me to estimate
the cost of a trip to the conference?
</bodyText>
<listItem confidence="0.726852">
(5) YES. FOR THREE PEOPLE.
</listItem>
<bodyText confidence="0.6279792">
Assuming they travel by air ...
Assuming each person spends three days in
Philadelphia ...
Assuming a per day expense of $25 400
The cost would,be $371.50.
</bodyText>
<listItem confidence="0.997683">
(6) WILL THE BUDGET COVER THAT?
No, the deficit would be $55.09.
(7) ASSUME THEY GO BY BUS.
</listItem>
<bodyText confidence="0.970457">
The cost would be $327.40. The budget deficit would be
$10.99.
</bodyText>
<figure confidence="0.5414164">
23
(8) OK. SCHEDULE A TRIP FOR THREE PEOPLE BY EUS TO THE
ASP
MEETING.
Done. That leaves -10.99 in the budget.
</figure>
<bodyText confidence="0.96310947368421">
Even in a simple dialogue like the one above we see
important discourse phenomena. For example, the manager&apos;s input
(4) is ambiguous to the system. &amp;quot;Cost&amp;quot; could tr.ean &amp;quot;registration
fee&amp;quot; or &amp;quot;cost of a trip to the conference&amp;quot;. The system has to
ask about this ambiguity, producing an embedded question-answer
pair within the original question-answer pair (cf. Schegloff s
(1972) &amp;quot;insertion sequences&amp;quot;). However, there is more than &apos;a
Q-1, Q-2, A-2, A-1 pattern in (4) and (5). The system does not
just say, &amp;quot;Did you mean fee cost or &apos;trip cost&apos;?&amp;quot;. Assuming
that &amp;quot;fee cost&amp;quot; is a reasonable interpretation, and useful to
know besides, it simply states that fact, and asks about the
other interpretation, which would demand more computation. A
discourse model should account for this apparent awareness of
cotputational difficulty, which is exhibited in human
conversation and between a human and our idealized machine above.
Another phenomenon worth noting in this dialogue 4 (7, the
variation in detail and precision among the utterances. Sentence
(8) is fairly precise and complete. Since alternatives have been
considered to the trip he has decided upon it is important.
</bodyText>
<page confidence="0.607159">
24
</page>
<bodyText confidence="0.998592833333333">
stress those aspects of the trip &amp;quot;three people&amp;quot;, &amp;quot;by bus&amp;quot; MN*
which have been in question. on the other hand, sentence (3) is
clearly elliptical. This is all right since the question is
merely exploratory. Furthermore, the previous question insures
that &amp;quot;money • • • left&amp;quot; refers to money in the current budget. An
adequate discourse model should account as well for our apparent
ability to accommodate for the speech channel capacity, to
minimize transmission errors through the use of redundancy and
stress, and in general to attempt to optimize the communication.
One way to account for these and related phenomena is to
postulate a discourse grammar. The grammar might say that part
of a dialogue is a &amp;quot;question-answer&amp;quot; pair, and that it may be
recursive in the sense that question-answer pairs may be embedded
within it. This approach is discussed in the next section. A
contrasting approach is to say that each utterance produces
&amp;quot;demands&amp;quot; in the heads of the listeners. Responses to these
demands may take the form of subsequent utterances. This latter
model is discussed in Section 4.
</bodyText>
<sectionHeader confidence="0.503841" genericHeader="method">
3. grammar liodelz of Discourse
</sectionHeader>
<bodyText confidence="0.9665725">
Upon reading a dialogue like the example in Section 2, most
of us readily form an opinion about its structure. In any
dialogue we see this kind of structure; one peroon is asking
another to do something; two people are arguing about politics,
or discussing a novel. There is almost always a structure higher
25
than the individual sentences. In the example ction 2, the
travel budget manager seems to be entering into a &amp;quot;scnedule a
trip&amp;quot; dialogue. His question about a future conference is one of
the cues to a bundle of information known by both him and the
system about scheduling trips. Such a bundle has been variously
referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a
&amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot;
(Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a
&amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)).
The information associated with scheduling a trip includes
facts about dates and times, about the budget, about travel,
about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is,
time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In
this case, the goal is scheduling a trip to a conference. (See
also Bruce and Schmidt (1974), Schmidt (1975)). One such
partially instantiated plan might be -
</bodyText>
<listItem confidence="0.974964888888889">
1. Find out to which budget the trip should belong.
2. Determine how much is in the budget (budget).
3. Figure the cost of the trip (tripcost).
4. Decide whether (budget - tripcost) is acceptable.
5. If acceptable, schedule the trip and stop.
6. If not acceptable, determine if trip can be&apos;
modified to be cheaper.
a. If modifiable, go to 3.
b. If not modifiable, stop.
</listItem>
<page confidence="0.536822">
26
</page>
<bodyText confidence="0.999826444444444">
The steps (1 - 6) above are ordered, though nothing is said
about their relative lengths. Also, there are variants on the
plan where the order might be changed, e.g. step 3 might come
before step 2 in some other plan. The structure of such a plan,
coupled with the by now commonplace observation that a discourse
is structured, leads to the natural idea of representing a
discourse by a grammar. Such a grammar may be large; it may be
probabilistic; it may apply in only limited domains.
Nevertheless it does give some idea of what to expect in a
dialogue and may play a central role in language comprehension.
A portion of the grammar for our example dialogue is shown
in Figure 1. This is an Augmented Transition Network Network
(ATN) in which the arcs may refer to other networks (PUSH arcs),
may signify direct transitions to other states (JUMP arcs), or
may signify conclusion of the path (POP arcs). For example, in
addition to this &amp;quot;SCHEDULE&amp;quot; network there is an &amp;quot;ENTER&amp;quot; network
wherein the manager describes a new trip to be entered and the
system asks him questions to complete the description.
</bodyText>
<figure confidence="0.996148875">
P S PUSH
BELONG! BUDGET?
27
PUSH
COST?
l&apos;U MP
PUS H SC1DA4 STOP
ENTER (PoP)
</figure>
<figureCaption confidence="0.99703">
Fig. 1. ATN for scheduling a trip.
</figureCaption>
<bodyText confidence="0.9796705">
A discourse or dialogue grammar can be used with a modified
ATN parser to &amp;quot;parse&amp;quot; a dialogue, generating both analyses of the
current utterance and predictions about the one to come. In
fact, one such modified parser and grammar has been implemented
for the BBN speech system (Bruce(1975c), Woods, et al (1975)).
For many dialogues, the grammar applies quite well, testing for
the head verb in the utterance, the mood, and checking
presuppositions of the action implied. When successful, it makes
</bodyText>
<page confidence="0.698422">
28
</page>
<bodyText confidence="0.99973044">
corresponding predictions for application to the next utterance.
Unfortunately, when the grammar fails it is not very good at
recovering from its error.
Discourse grammars seem to be most effective in tightly
constrained domains, more for instance in a discussion about how
to cook a turkey, where there are specific subproblems to
analyze, than in the travel budget management domain, and less
still in a general question answering context. (Cf. Deutsch
(1974, 1975)).
Lest it be thought that discourse parsing is just sentence
parsing for &amp;quot;big sentences&amp;quot;, I should emphasize some of the
differences, differences which some would say preclude the use of
terms like &amp;quot;grammar&amp;quot;, &amp;quot;ATN&amp;quot;, and &amp;quot;parsing&amp;quot;. First, discourse
parsing p&apos;roceeds in a mode of partial parse, then output, then
partial parse, etc. In other words, the goal is to derive
information from the partial discourse which has occurred to
suggest what may follow and to explicate the role of the current
utterance. The parse is never completed, no structure is built.
Since the entire discourse is not available to the parser (as the
entire sentence is to a sentence parser), it is necessarily
probabilistic, One can never know how the next utterance may
alter the current interpretation of the trend of the dialogue.
Another important difference is that PUSH&apos;s and POP&apos;s in the
discourse grammar are &amp;quot;sloppy&amp;quot;. That is, the participants in a
dialogue may descend several levels (&amp;quot;Before you finish, let me
</bodyText>
<page confidence="0.711783">
29
</page>
<bodyText confidence="0.95569675">
tell you about ...&amp;quot;, &amp;quot;Before that ...&amp;quot;) and never &amp;quot;pop&amp;quot; back up
to the original level of the discourse. A discourse parser is
faced with the peculiar phenomenon that a PUSH usually implies a
POP but not always.
Some, but not all of these oddities of a discourse grammar
are resolved by an approach which emphasizes internal models of
the speaker and the listeners. This approach is discussed in the
next section.
</bodyText>
<sectionHeader confidence="0.929379" genericHeader="method">
4. Demand Models of Discourse
</sectionHeader>
<bodyText confidence="0.991151933333333">
One obvious characteristic of a discourse is that many
processes may be occurring at once. A person cannot, nor does he
wish to respond at one time to all unanswered questions; extend
each unfinished line of thought, or deal with every
inconsistency. While a grammar may predict the most likely
action for a given point in a dialogue, it is not very good at
suggesting alternatives out of the main line. There appears to
be an additional mechanism of roughly the following form:
An event in a discourse (or prior to it) sets up a number of
internal demands. Examples of such demands are to confirm what
was said, explore its consequences, dispute it, answer it, etc.
For any given event (such as an_utterance) there may be none,
one, or many demands created. A person&apos;s own action may place
demands upon himself. If X asks a question of Y, then Y normally
establishes an internal demand to answer the question. But X may
</bodyText>
<page confidence="0.580616">
30
</page>
<bodyText confidence="0.999484291666667">
also establish a demand of the form, &amp;quot;check to see if the
question has been answered&amp;quot;. This latter demand may generate a
later utterance such as, &amp;quot;Why haven t you answered me?&amp;quot;.
Simple demand models already exist in a few systems. In
general, they suggest that utterances are produced in response to
conditions in the (internal model of the) environment rather than
as units in a larger linguistic form. (See also Stansfield
(1975)). It would be premature to argue that either a demand
model or a grammar model is sufficient by itself. Instead, what
follows is simply a description of a demand model for the travel
budget management domain mentioned above.
Internal demands on the travel budget system help to explain
how one computation of a response can be pushed down, while a
whole dialogue takes place to obtain missing information, and how
a computation can spawn subsequent expectations or digressions.
Associated with each demand is a priority, a pointer (purpose) to
the demand which spawned this one (if any), and a time marker
indicating how long the demand has been around. An active
unanswered question is a typical demand with high priority.
Demands of lower priority include such things as a notice by the
system that the manager is over his budget. Such a notice might
not be communicated until after direct questions had been
answered. The fact that some questions cannot be answered
without more informatioDm ieads to- the
</bodyText>
<page confidence="0.955925">
31
</page>
<figure confidence="0.90175975">
User-makes-query
System-asks-question
User-clarifies
System-answers-query
</figure>
<bodyText confidence="0.95310935">
kind of embedding which is typically represented in a discourse
grammar by a PUSH to a &amp;quot;clarification&amp;quot; state.
Counter-demands are questions the system has explicitly or
implicitly asked the user. While it should not hold on to these
as long as it does to demands, nor expect too strongly that they
will be met, the system can reasonably expect that most
counter-demands will be resolved in some way. This is an
additional influence on the discourse structure.
A demand model also includes a representation of the current
topic, the active focus of attention in the dialogue. For the
travel budget system, it could be the actual budget, a
hypothetical budget, a particular trip, or a conference. The
current topic is used as an anchor point for resolving references
and deciding how much detail to give in responses. Again, this
structure leads to certain modes of interaction. For example, if
the manager says &amp;quot;Enter a trip,&amp;quot; the system notes that the
current topic has changed to an incompletely described trip.
This results in demands that cause standard fill-in questions to
be asked. If the manager wants to complete the trip description
later, then the completion of the trip description becomes a low
</bodyText>
<figure confidence="0.763314666666667">
32
priority demand.
5. Synthesis?
</figure>
<figureCaption confidence="0.784280375">
Discourse has been. an object of study for many both in and
out of the field of computational Linguistics. Especially worth
noting is the work of sociolinguists such as Labov (1972), Sacks,
Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists
(e.g. Grimes), sociologists (e.g. Goffman (1971)), and
philosophers (e.g. Austin (1962), Searle (1969)) have important
direct or related contributions. I certainly can&apos;t presume in
this short paper tn give the definitive solution to all the
</figureCaption>
<bodyText confidence="0.934236785714286">
problems revolving around the discourse question. What I have
tried to do is to emphasize a distinction in approach between
looking at a discourse as a linguistic whole with subparts being
individual utterances, and as a side effect of responses to task
demands.
Both approaches are useful in exemplifying ways in which the
otherwise hazy area of discourse might be modeled. The grammar
approach makes the strongest statement about actual discourse
structure and can best be used where the structure is well known
or can be tightly constrained, e.g. in generating a discourse or
in a man-machine system where the computer imposes control on the
dialogue. A grammar and a discourse parser can be very efficient
in such situations. When the dialogue is less predictable the
(more bottom-up) demand processing approach may be more resistant
</bodyText>
<equation confidence="0.7673">
33
to &amp;quot;surprises&amp;quot; in the dialogue.
</equation>
<bodyText confidence="0.999940333333333">
The ultimate discourse model probably contains aspects of
both goal-directed grammars and of localized responses to
demands. What should be particularly interesting to see is how
characteristics of the model are affected by the type of
discourse, human-machine v. human-human, problem-oriented v.
information-exchanging, or new domain v. old.
</bodyText>
<sectionHeader confidence="0.928856" genericHeader="method">
REFERENCES
</sectionHeader>
<reference confidence="0.856005671428572">
Abelson, Robert. &amp;quot;Concepts for Representing Mundane Reality in
Plans&amp;quot;. In Representation and Understanding: Studies in
Cognitive Science (Ed: D. Bobrow and A. Collins), Academic
Press, New York, 1975.
Austin, J. L. How to Do Things with Words. Clarendon Press,
Oxford, 1962.
Bruce, Bertram. &amp;quot;Belief Systems and Language Understanding&amp;quot;.
BBN Report No. 2973, 1975a.
. &amp;quot;Generation as a Social Action&amp;quot;. In Theoretical Issues
in Natural Language Processing (Ed: B, L. Nash-Webber and R.
C. Schank), ACL, 1975b.
. &amp;quot;Pragmatics in Speech Understanding&amp;quot;. Proc. 4th IJCAI,
Tbilisi, 1975c.
and C. F. Schmidt. &amp;quot;Episode Understanding and Belief
Guided Parsing&amp;quot;. Presented at 12th ACL Meeting, Amherst,
1974. (Also Rutgers Computer Science Dept. Report
34
CBM-TR-32).
Deutsch, Barbara G. &amp;quot;The Structure of Task Oriented Dialogues&amp;quot;.
Contributed Papers, IEEE Symposium on Speech Recognition, CMU,
Pittsburgh, 1974.
&amp;quot;Discourse Analysis and Pragmatics&amp;quot;. In Speech
Understanding Research (D. Walker, W. Paxton, J. Robinson,
G. Hendrix, B. Deutsch, and A. Robinson), Annual Technical
Report, SRI, 1975.
Goffman, Erving. Relations in Public. Basic Books, New York,
1971.
Grimes, Joseph. The Thread of Discourse. Mouton, Paris, in
press.
Labov, William. &amp;quot;Rules for Ritual Insults&amp;quot;. In Studies dn
Social Interaction (Ed: David Sudnow), The Free Press
(Macmillan), 1972.
Minsky, Marvin. &amp;quot;A Framework for the Representation of
Knowledge&amp;quot;. In The Psychology of Computer Vision (Ed: P.
Winston), 1975.
Phillips, Brian. Topic Analysis. Ph. D. Thesis, SUNY Buffalo,
1975.
Rumelhart, David. &amp;quot;Notes, on a Schema for Stories&amp;quot;. In
Representation and Understanding: Studies in Cognitive Science
(Ed: D. Bobrow and A. Collins), Academic Press, New York,
1975.
Sacks, Harvey, Emanuel Schegloff and Gail Jefferson. &amp;quot;A Simplest
Systematics for the Organization of Turn-Taking for
35
Conversations&amp;quot;. Semiotica, 1974.
Schank, Roger and Robert Abelson. &amp;quot;Scripts Plans and Knowledge&amp;quot;.
Proc. 4th IJCAI, Tbilisi, 1975.
Schegloff, Emanuel A. &amp;quot;Notes on a Conversational Practice:
Formulating Place&amp;quot;. In Studies in Social InteraOtion (Ed:
David Sudnow), The Free Press (Macmillan), 1972.
Schmidt, Charles F. &amp;quot;Understanding Human Action: Recognizing the
Motives and Plans of Other Persons&amp;quot;. Carnegie Symposium on
Cognition: CogRition and Social Behavior, CMU, Pittsburgh,
1975.
Searle, J. R. Speech Acts. Cambridge University Press, London,
1969.
Stansfield, James L. Programming a Dialogue Teaching Situation.
Ph. D. Thesis, U. of Edinburgh, 1974.
Winograd, Terry. &amp;quot;Frame Representations and the
Declarative-Procedural Controversy&amp;quot;. In Representation and
Ullderstanding: Studies in Cognitive Science (Ed: D. Bobrow
and A. Collins), Academic Press, New York, 1975.
Woods, William, M. Bates, B. Bruce, J. Colarusso, C. Cook, L.
Gould, D. Grabel, J. Makhoul, B. Nash-Webber, R. Schwartz,
J. Wolf. &amp;quot;Natural Communication with Computers, Final Report
- Vol. I, Speech Understanding Research at BBN&amp;quot;. BBN Report
No. 2976, 1974.
Woods, William A., R. Schwartz, C. Cook, J. Klovstad, L.
Bates, B. Nash-Webber, B. Bruce, J. Makhoul. &amp;quot;Speech
Understanding Systems: QTPR 3&amp;quot;. BBN Report No. 3115, 1975.
</reference>
<note confidence="0.744901">
American Journal of Computational Linguistics Microfiche 35 : 36
</note>
<sectionHeader confidence="0.695448" genericHeader="method">
JUDGING THE COHERENCY OF DISCOURSE
</sectionHeader>
<subsectionHeader confidence="0.434294">
BRIAN PHILLIPS
</subsectionHeader>
<subsubsectionHeader confidence="0.287835">
Department of Information Engineering
University of Illinois at Chicago Circle
Box 4348, Chicago 60680
</subsubsectionHeader>
<sectionHeader confidence="0.727905" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.873159083333333">
The component propositions of a coherent discourse exhibit anaphoric,
spatio-temporal, causal and thematic structures. Not all of this struc-
ture is explicit, but must be inferred using a model of cognitive know-
ledge. The organization of knowledge in the model allows a bottom-up
analysis of discourse. Further, knowledge is formed into small complexes
rather than into the large monolithic structures found in Scripts/Frames.
1. The Structure of Coherent Discourse.
A discourse is judged coherent if its constituent propositions are
connected. Various types of cohesive links are observed in discourse:
anaphoric, spatial, temporal, causal and thematic. We will formally
describe the structure of a well-formed discourse in terms of these
connectives.
</bodyText>
<subsectionHeader confidence="0.530386">
1.1 Anaphora.
</subsectionHeader>
<bodyText confidence="0.743055214285714">
Two kinds of anaphora can be distinguished. The first is marked
by the presence of a preform (or by the repetition of a form):
(1) Henry travels too much. He is getting a foreign accent.
Antecedents may be nominal, verbal or clausal.
The second kind of anaphora has a dependent that is an abstract
37
term for the antecedent. For example,
(2) John put the car into &apos;reverse&apos; instead of &apos;drive&apos;
and hit a wall. The mistake cost him $200 in repairs.
&apos;Mistake&apos; in (2) is an abstract characterization of the gear selection
expressed in the first sentence.
A conventional way to label the recurring actors in discourse is
as &apos;dramatis personae&apos;. However cohesion can result not only from
multiple appearances of people, but of any concept, as in (2).
</bodyText>
<subsectionHeader confidence="0.834713">
1.2 Spatio-temporal and Causal Connectives.
</subsectionHeader>
<bodyText confidence="0.9302902">
Space, time and cause give coherency to a set of propositions.
(3) The King was in the counting house, counting out his
money. The Queen was in the parlour, eating bread
and honey.
The actions in (3) are set in different rooms, but of the same &apos;palace&apos;.
</bodyText>
<listItem confidence="0.818524333333333">
(4) After Richard talked to the reporter, he went to lunch.
The temporal sequence of events in (4) is expressed by &apos;after&apos;.
(5) John eats garlic. Martha avoids him.
</listItem>
<bodyText confidence="0.961354285714285">
To non-aficionados garlic is known only for its aroma, detection of
which causes evasive action.
Cause, illustrated in (5) is an Important discourse connective.
Note however, that this is an ethnocentric view; in other cultures a
different position may have to be taken, for example, a teleological
world view (White: 1975).
This dimension of discourse structure is termed its &apos;plot&apos; structure.
</bodyText>
<footnote confidence="0.698139">
1.3 Thematicity.
Discourse is expected to have a theme, to have a topic. For example,
</footnote>
<note confidence="0.5731315">
38
(6) Dino Frances drowned today in Middle Branch Resevoir
after rescuing his son Dino Jr. who had fallen into
the water while on a fishing trip.
</note>
<bodyText confidence="0.896987590909091">
is a new story from the New York Times, with a theme of, say, &apos;tragedy&apos;.
Discourse may have more than one theme, but these should not conflict.
(7) Eating the fish made Gerry sick. He had measles in May.
In (7) we have an incoherent structure. The proposition &apos;Gerry sick&apos;
belongs both to. a topic &apos;food-poisoning&apos; and to a biography of illnesses.
The analysis of fairy-tales by Lakoff (1972) suggests that discourse has
a strictly tree-like thematic organization.
It is concluded that the propositions of a coherent discourse are
connected either by coreference OL (preferably) causally, and that it
has a single theme (which may be the root of a tree of themes).
2. The Role of Inference.
Not all of discourse structure is overtly stated; discourse is highly
elliptic. In (4) the discourse connective &apos;after&apos; is present to mark a
temporal sequence, but in (5) there is no realization of the causal relation
between the two propositions. Normally one assumes that a discourse is
coherent; hence (3) is most acceptable if the rooms are taken as being with-
in the same habitation. Evidently a reader must infer omitted structure.
The inferences are made from his cognitive store of world knowledge.
There is much discussion at present about inference as part of under-
standing. To make inferences is easy; the problem is to make the right
ones. It helps to have a goal. It is suggested that discourse can be
said to be understood when it has been judged coherent, as defined above.
</bodyText>
<page confidence="0.524837">
39
</page>
<sectionHeader confidence="0.266592" genericHeader="method">
3. Mechanisms of Inference.
</sectionHeader>
<bodyText confidence="0.9913793">
A model of cognitive knowledge -- an encyclopedia -- should be
capable of making the inferences necessary to form an opinion about
the coherency of a discourse. The present encyclopedia originated with
Hays (1973); a fuller description can be found in Phillips (1975). It
is implemented as a directed graph. Labeled nodes characterize concepts
and labeled arcs relations between concepts.
Propositions have a structure of case-related concepts, based on
Fillmore (19e9). This is our vsyntagmatic&apos; organization of knowledge.
As propositions are essentially the building blocks of discourse, we
will not dwell on their structure here.
</bodyText>
<subsectionHeader confidence="0.995933">
3.1 Anaphora.
</subsectionHeader>
<bodyText confidence="0.98264368">
If the dependent is a proform then part of understanding is to
determine the correct antecedent. There are syntactic constraints
(Langacker: 1969) which serve to narrow down choices for antecedents and
to give an order of preference. The chosen antecedent will be the first
that, when substituted for the proform, produces a meaningful proposition
that is coherent in context.
A meaningful proposition is one that has a counterpart in the ency-
clopedia. The counterpart may be the self-same proposition, or more
likely, a generalized proposition (hereafter a GP). For example,
rather than &apos;Joan drink milk&apos;, we would expect to find &apos;animal imbibe
liquid&apos;.
How are GPs found?- All concepts belong to partially ordered
taxonomic structures in the encyclopedia (our &apos;paradigmatic&apos; organiz-
ation of concepts). From any concept it is possible to follow para-
digmatic relations to a more general concept, which may be a constit-
40
uent of a proposition. An intersection of paradigmatic paths origin-
ating from each concept in a discourse proposition (hereafter a DP),
taking account ofsyntagmatic structure, gives a GP. If there is no
such intersection, then the DP is not consistent with encyclopedic
knowledge.
Abstract terms can be defined by complexes of GPs, each having
sufficient conceptual content to define situations in which they apply.
For example, a definition of &apos;mistake&apos; must be such that it applies to
part of the first sentence in (2).
</bodyText>
<subsectionHeader confidence="0.986114">
3.2 Space, Time and Cause.
</subsectionHeader>
<bodyText confidence="0.996199625">
To infer omitted spatio-temporal and causal relations (termed
&apos;discursive&apos; relations in the encyclopedia), it is also necessary to
locate GPs. The encyclopedia, of course, includes these relations, but
between GPs. Schematically, from a discourse proposition P1 we can
locate P2&apos; a GP, in the manner outlined above. P2 may have a discursive
relation R to another GP, P3. A proposition P41 a particularized version
of P3&apos; and the relation R, between P1 and P4,
discourse, figure 1.
</bodyText>
<figure confidence="0.342915">
P2
11\
</figure>
<page confidence="0.80897625">
P1
P
3
P4
</page>
<figure confidence="0.920067">
can be added to the
ENCYCLOPEDIA
DISCOURSE
</figure>
<figureCaption confidence="0.998772">
Figure 1.
</figureCaption>
<bodyText confidence="0.924852">
41
Often P4 will be a proposition already stated in the discourse; merely
the relation need be inferred to augment the plot structure. It may,
however, be necessary to infer a chain of propositions to link the
original DPs. The question arises whether there is a limit on the
number of propositid &apos;sensible&apos; in a sensible&apos; inferred path. Intuitively
there is, but at present we have no formal insight.
</bodyText>
<subsectionHeader confidence="0.542433">
3.3 Thematicity.
</subsectionHeader>
<bodyText confidence="0.986673102564103">
A theme is a complex of GPs, structurally indistinguishable from
that used in characterizing abstract terms like &apos;mistake&apos;. The potential
presence of a theme is detected in the process of seeking GPs for DPs.
All GPs, whether or not they are part of a thematic definition, can be
located by paradigmatic searches; some GPs have additional structure
indicating that they are components of themes. It is not sufficient to
establish a theme for discourse by separately finding DPs that correspond
to all the GPs of a theme. The thematic definition and the relevant
part of the discourse must be tested holistically to ensure that the
correct coreferentialities exist among the propositions.
314 Overview of Inference.
There are two basic processes underlying inference. First there
is the process of locating a GP given a DP. This is implemented essen-
tially by a breadth-first search through the paradigmata_c structure of
the encyclopedia. Secondly there is the process of matching a complex
of propositions in discourse against an encyclopedic complex. The
latter process is qualitatively different as it involves tests for co-
reference that the former does not.
Complexes of propositions have obvious functional similarities with
&apos;Paraplates&apos; (Wilks: 1975), &apos;Scripts&apos; (Schank and Abelson: 1975) and
42
&apos;Frames&apos; (Minsky: 1975). Adding to the expanding terminology, our
version is known as &apos;metalingual definitions&apos;.
Metalingual definitions serve to define abstract terms (&apos;mistake&apos;),
themes (&amp;quot;tragedy&apos;) and plans (used by Furugori (1974) in his robot
planner). The distinctions are more terminological than substantive,
their functions are interchangable; in other contexts a plan could be a
theme, a theme an abstract term, etc.
When an abstract concept has a metalingual definition, a matching
discourse may be rewritten in terms of that concept. For example, &apos;buy&apos;
has such a definition, say &apos;person, gives object to person2, person2
gives money to persona:. To properly make the transduction to &apos;person2
buys object from person11, there must be a case frame for &apos;buy&apos; linked
to concepts in its definition. A proposition produced by abstraction
is structurally indistinguishable from a proposition that was in the
original discourse, and can be subject to any encyclopedic process,
including further abstraction. Conversely, if a proposition contains
a concept having a metalingual definition, then the proposition can
be decomposed into a complex of propositions patterned on the definition.
</bodyText>
<listItem confidence="0.444822">
4. An Example.
</listItem>
<bodyText confidence="0.69777">
A schematic analysis of (6) shows the inference system in operation,
resulting., in a structure that satisfies the criteria of coherence.
At each step we will indicate the encyclopedic knowledge used in
the inference, and the current state of the discourse. The original
discourse propositions are indicated by IP and inferred propositions
by 0
Step 0. Initial State.
</bodyText>
<page confidence="0.96209">
43
</page>
<figure confidence="0.592061833333333">
0 Father
drowns
Father
rescue
son
//10111Son in
co water
Son
falls
Step 1. Fall causes injury.
Father
drowns
4110
Father
rescue
son
Son in
water
CAUSE
Son Son
falls injured
Step 2. Injury causes inability to act.
410 Father
drowns
410
Father
rescue
son
Son in
water
CAUSE CAUSE
&gt;0
Son Son not able
injured to act
Son
falls
</figure>
<bodyText confidence="0.270487">
Step 3. In water and not Able to act causes rescue.
</bodyText>
<sectionHeader confidence="0.940544" genericHeader="method">
4, Father
</sectionHeader>
<subsectionHeader confidence="0.566134">
drowns
</subsectionHeader>
<bodyText confidence="0.9454525">
Conjunetion is indicated by Part-whole relations. Note that a link to
one of the original propositions has been established.
</bodyText>
<figure confidence="0.990710551724138">
CAUSE
Father
rescue
son
Son in
water
Son Son Son not able
falls injured to act
1+ 4
Step 4. To rescue someone who is in water it may be necessary to be
in water.
0 Father
drowns
Step 5. Acting can make you weary.
ipFather
drowns
Son Son Son not able
falls injured to act
CAUSE Father in
water
CAUSE
Father
rescue
son
%\&apos;&apos;s
Son in
water
411 CAUSE )(7.&gt; CAUSE
Son Son
falls injured
Son not able
to act
CAUSE _&gt;c) Father in
water
CAUSE CAUSE
Father Father
rescue weary
Son in
water
CAUSE CAUSE
45
Step 6. If weary then unable to act.
ah. Father
drowns
A link to the final proposition of the discourse is made. Corefer-
CAUSE
CAUSE
Father Father Father not
rescue weary able to act
son
Son in
water
4e,)
CAUSE
Son Son
falls injured
Son not able
to act
Step 7. If in water and not able to act then drown.
CAUSE).* Father
drowns
•
Father in
&gt;0 water
CAUSE
CAUSE
CAUSE
-e
Father in
water
CAUSE CAUSE
Son not able
to act
Son
falls
Son
injured
CAUSE
Father Father Father not
rescue weary able to act
son
Son in
water
CAUSE CAUSE
47
agr
&lt;s&amp;quot;
</figure>
<page confidence="0.668881">
46
</page>
<bodyText confidence="0.98564205">
entiality conditions prevent &apos;son in water&apos; and &apos;Father not able to
act&apos; conjoining to satisfy the conditions on this inference.
Note that the antecedent condition on this inference is the same
as at step 3. Both resultant situations are possible, and are noted.
The system can select either. However, the wrong choice does not lead
to a connected structure, and a back up to the alternative has to be
made.
The discourse now has an inferred causal structure connecting all
the original propositions.
From a thematic analysis of drowning stories in general (Phillips:
1975), the common theme can be described as &apos;giving a cause for the
person being in tIle water, and giving a cause for the victim not being
able to act (thereby not being able to save himself)&apos;. This theme fits
the discourse by virtue of propositions 0) and which stand in
causal relations to &apos;being in the water&apos; and &apos;not able to act&apos; for the
victim. The theme &apos;tragedy&apos; is defined as &apos;someone does something good
and dies as a result of this action&apos;. The father&apos;s rescue of his son and
subsequent demise satisfy this theme (0 and e). For the story to
be coherent, these themes must not overlap; in fact we see that the
&apos;drowning&apos; theme is properly contained by &apos;tragedy&apos;.
</bodyText>
<sectionHeader confidence="0.745718" genericHeader="method">
5. Discussion.
</sectionHeader>
<bodyText confidence="0.8371162">
The analysis is so organized that the themes are determined in
a bottom up manner, as are all generalized facts used in the analysis.
Though not presently implemented, it should be possible to use potential
themes, ones for which only some component propositions have been found,
in a predictive manner.
</bodyText>
<page confidence="0.492499">
48
</page>
<bodyText confidence="0.999331">
The complexes of propositions, in metalingual definitions of themes
and elsewhere, are really not that complex. The ones in the example
contain only a few propositions. Each has only the essentials of the
situation. The final structure arises from many small pieces of
knowledge rather than from one monolithic aggregate. This seems to be
a more natural organization, as each of the simpler structures can be
freely applied in many contexts, rather than being bound to one situation.
The discourse judgement is relative to the knowledge of the hearer.
Whether the inferences are those intended by the author is another
question. Ideally they should be or differences should be unimportant.
A misleading inference indicates poor writing by the author; he has
misjudged the knowledge of his audience.
Directing inferences on a discourse towards the goal of judging it
coherent provides a normalized version of the discourse, if the process
is successful. The normalized structure can form the basis for further
processing: content analyis, stylistic analysis, etc. It may also
provoke various questions, for example, we could ask if the inferences
were correct; we have the &apos;rescue&apos; situation applying to the father, but
he wasn&apos;t rescued, why not.
</bodyText>
<page confidence="0.466011">
49
</page>
<sectionHeader confidence="0.553944" genericHeader="method">
keferences
</sectionHeader>
<reference confidence="0.978862">
?illmore, C. J. 1969. Toward a Modern Theory of Case.
Furugori, In Reibel and Schane.
T. 1974. &amp;quot;A memory model and simulation of memory processes
for driving a car.&amp;quot; Technical Report No. 77, Department of
Computer Science, SUNY Buffalo.
Hays, D. G. 1973. Types of Processes on Cognitive Networks.
In Proceedings of the 1973 International Conference on
Computational Iii.Eguistics. Pisa.
Lakoff, G. 1972. Structural Complexity in Fairy Tales.
The Study of Man 1, 128-150.
Langacker, R. W. 1969. On Pronominalization and the Chain of Command.
In Reibel and Schane.
Minsky, M. 1975. A Framework for Representing Knowledge.
In P. H. Winston (ed.), The Esychologx. of Computer Vision.
McGraw-Hill, NY.
Phillips, B. 1975. Topic Analysis. Unpublished Ph.D. Thesis.
SUNY Buffalo.
Reibel, D. A. and D. A. Schane (eds.). 1969. Modern Studies in English.
Readings in Transformational Grammar. Prentice-Hall,
Englewood Cliffs.
Schank, R. C. and R. P. Abelson. 1975. Scripts, Plans, and Knowledge.
In Advance Papers of the Fourth International Joint
Conference on Artificial Intelligence. IJCAI.
White; M. 1975. Abstract Definition in the Cognitive Network:
The Metaphysical Terminology of a Contemporary Millenarian
Community. Unpublished Ph.D. Thesis. SUNY Buffalo.
Wilks, Y. 1975. A Preferential, Pattern-Seeking, Semantics for
Natural Language Inference. Artificial Intelligence 6, 53-74.
American Journal of Computational Linguistics Microfiche 35 : 50
</reference>
<sectionHeader confidence="0.7163365" genericHeader="method">
AN APPROACH TO THE ORGANIZATION OF MUNDANE WORLD KNOWLEDGE:
THE GENERATION AND MANAGEMENT OF SCRIPTS
</sectionHeader>
<reference confidence="0.510654333333333">
R. E. CULLINGFORD
Yale University
New Haven, Connecticut 06511
</reference>
<sectionHeader confidence="0.702192" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.897350941176471">
In understanding stories or natural-language discourse,
hearers draw upon an enormous base of shared world knowledge
about common situations like going to restaurants, theaters or
supermarkets to help establish the needed context. This paper
presents an approach to the management of this type of knowledge
based upon the concept of a situational script [Schank and
Abelson, 1975]. The application of scripts in story
understanding is illustrated via a computer model called SAM
(Script Applier Mechanism).
In simple one-script stories, SAM constructs a trace
through a preformed data structure containing the input, other
events not mentioned but commonly assumed, the important
AMMI•111•••••111111111.00101.....M.101•••■■■=11111.•111.1••••••=1.1.11•141!■■•■•■■
The research described in this paper was supported in part
by the Advanced Research Projects Agency of the Department of
Defense and monitored under the Office of Naval Research under
contract N00014-75-C-1111.
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000793">
<title confidence="0.8122474">Journal of Computational Linguistics PROCEEDINGS ANNUAL ASSOCIATION FOR COMPUTATIONAL LINGUISTICS MODELING DISCOURSE AND WORLD KNOWLEDGE</title>
<author confidence="0.992782">Timothy C Diller</author>
<author confidence="0.992782">Editor</author>
<affiliation confidence="0.388277">Sperry-Univac</affiliation>
<address confidence="0.825128">St. Paul, Minnesota 55101</address>
<note confidence="0.972803">Copyright 45 1975 by the Association for Computational Linguistics</note>
<abstract confidence="0.95548932">2 PREFACE Session 4 centered around two major topics: modeling the flow of information in discourse and representing and the knowledge of world shared by communicators. paper by Deutsch describes a mechahism for definite noun a task-oriented (Note the paper by Klappholz and in Session 5.) Bruce two discourse models: &amp;quot;discourse grammar&amp;quot; which defines set of found and/or structures, and a &amp;quot;demand processor&amp;quot;, which accounts for utterances as responses to and activators of internal demands. Phillips presents various cohesive links in coherent discourse then considers inferenprocess to filling in knowledge only implicit in the linking mechanisms. Cullingford discusses the major of SAM (Script Applier Mechanism), computational system modeling the organization and management of extraworld Badler describes a system for translating visual input into propositional descriptions of &amp;screte events. Focussing on a particular type of visual (American Sign Language), Kegl and Chinchor the use of frame analysis in describing various communicatory devices in ASL. Thanks to Carl Hewitt for chairing this session.--Timothy C. Diller, Program Committee Chairman</abstract>
<note confidence="0.3973775">TABLE OF CONTENTS SESSION 4- MODELING DISCOURSE AND WORLD KNOWLEDGE Context in Task-oriented Dialogs Deutsch . . • • • • • • • • . Models and Language Comprehension C. Bruce the Coherency of Discourse Phillips . . . An Approach to the Organization of Mundane World Know- The Generation and Management of Scripts E. . • • • • • . • • . Conceptual Description of Physical Activities . • • • • • • • • . • • • • • Frame Analysis of American Sign Language Anne Kegl Nancy Chinchor • • • • • • • • • • Journal of Computational Linguistics 35</note>
<title confidence="0.979487">CONTEXT IN DIALOGS</title>
<author confidence="0.997796">BARBARA G DEOTSCH</author>
<affiliation confidence="0.9999625">Artificial Intelligence Center Stanford Research Institute</affiliation>
<address confidence="0.999876">Menlo Park, California 94025</address>
<abstract confidence="0.996262714285714">This paper describes part of the discourse component of a speech understanding system for taskworiented dialogs, specifically, a mechanism for establishing a focus of attention aid in identifying the referents of definite In building a representation of the dialog context, the discourse processor takes advantage of the fact that task•orionted dialogs hive a Structure that closely parallels the structure of the The semantic network of the system is partitioned focus spaces with each focus space containing only those concepts pertinent to the dialog relating to • subtask, The focus spaces linked to their corresponding subtasks and ordered hierarchy determined by the relations among subtasksi Actnowledgment</abstract>
<note confidence="0.996700333333333">This research was supported by the Defense Advanced Research Agency of the Department of Defense and monitored U,$„ Army Research Office under Contract No, DAKC04•75•C•0006.</note>
<intro confidence="0.499312">5</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert Abelson</author>
</authors>
<title>Concepts for Representing Mundane Reality in Plans&amp;quot;.</title>
<date>1975</date>
<booktitle>In Representation and Understanding: Studies in Cognitive Science (Ed: D. Bobrow</booktitle>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="29450" citStr="Abelson (1975)" startWordPosition="4904" endWordPosition="4905">t its structure. In any dialogue we see this kind of structure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might be - 1. Find out to which budget the trip shoul</context>
</contexts>
<marker>Abelson, 1975</marker>
<rawString>Abelson, Robert. &amp;quot;Concepts for Representing Mundane Reality in Plans&amp;quot;. In Representation and Understanding: Studies in Cognitive Science (Ed: D. Bobrow and A. Collins), Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Austin</author>
</authors>
<title>How to Do Things with Words.</title>
<date>1962</date>
<publisher>Clarendon Press,</publisher>
<location>Oxford,</location>
<contexts>
<context position="38033" citStr="Austin (1962)" startWordPosition="6338" endWordPosition="6339">changed to an incompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are useful in exemplifying ways in which the otherwise hazy area of discourse might be modeled. The grammar approach makes the strongest statement about actual discour</context>
</contexts>
<marker>Austin, 1962</marker>
<rawString>Austin, J. L. How to Do Things with Words. Clarendon Press, Oxford, 1962.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bertram Bruce</author>
</authors>
<title>Belief Systems and Language Understanding&amp;quot;.</title>
<date>1975</date>
<tech>BBN Report No. 2973,</tech>
<contexts>
<context position="29589" citStr="Bruce (1975" startWordPosition="4924" endWordPosition="4925">itics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might be - 1. Find out to which budget the trip should belong. 2. Determine how much is in the budget (budget). 3. Figure the cost of the trip (tripcost). 4. Decide whether (budget - tripcost)</context>
</contexts>
<marker>Bruce, 1975</marker>
<rawString>Bruce, Bertram. &amp;quot;Belief Systems and Language Understanding&amp;quot;. BBN Report No. 2973, 1975a.</rawString>
</citation>
<citation valid="true">
<title>Generation as a Social Action&amp;quot;. In</title>
<date>1975</date>
<booktitle>Theoretical Issues in Natural Language Processing (Ed: B, L. Nash-Webber</booktitle>
<contexts>
<context position="25654" citStr="(1974, 1975)" startWordPosition="4260" endWordPosition="4261"> restricted in scope to that of managing a travel budget. Imagine that a person responsible for a travei budget is trying to decide how many people to send to an upcoming conference. He has available a computer system which can answer questions about the budget, conferences, trips and so on. In talking to such a system, the travel budget 22 manager is engaging in an admittedly simple dialogue, but one which nevertheless exhibits many interesting properties of discourse understanding. (The following dialogue is hypothetical; however a system of this type is being developed at BBN (Woods, et al (1974, 1975))). The (human) manager begins: (1) WHEN IS THE NEXT ASSP CONFERENCE? May 15-18, 1975 (2) IS THAT IN OUR CURRENT BUDGET YEAR? Yes. (3) HOW MUCH MONEY DO WE HAVE LEFT? $316,41 remains in the budget. (4) WHAT IS THE COST OF THE ASSP CONFERENCE? The registration fee is $25. Would you like me to estimate the cost of a trip to the conference? (5) YES. FOR THREE PEOPLE. Assuming they travel by air ... Assuming each person spends three days in Philadelphia ... Assuming a per day expense of $25 400 The cost would,be $371.50. (6) WILL THE BUDGET COVER THAT? No, the deficit would be $55.09. (7) ASSUME T</context>
<context position="29404" citStr="(1975)" startWordPosition="4899" endWordPosition="4899">ost of us readily form an opinion about its structure. In any dialogue we see this kind of structure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might b</context>
<context position="31906" citStr="(1975)" startWordPosition="5328" endWordPosition="5328">in addition to this &amp;quot;SCHEDULE&amp;quot; network there is an &amp;quot;ENTER&amp;quot; network wherein the manager describes a new trip to be entered and the system asks him questions to complete the description. P S PUSH BELONG! BUDGET? 27 PUSH COST? l&apos;U MP PUS H SC1DA4 STOP ENTER (PoP) Fig. 1. ATN for scheduling a trip. A discourse or dialogue grammar can be used with a modified ATN parser to &amp;quot;parse&amp;quot; a dialogue, generating both analyses of the current utterance and predictions about the one to come. In fact, one such modified parser and grammar has been implemented for the BBN speech system (Bruce(1975c), Woods, et al (1975)). For many dialogues, the grammar applies quite well, testing for the head verb in the utterance, the mood, and checking presuppositions of the action implied. When successful, it makes 28 corresponding predictions for application to the next utterance. Unfortunately, when the grammar fails it is not very good at recovering from its error. Discourse grammars seem to be most effective in tightly constrained domains, more for instance in a discussion about how to cook a turkey, where there are specific subproblems to analyze, than in the travel budget management domain, and less still in a gene</context>
<context position="35363" citStr="(1975)" startWordPosition="5909" endWordPosition="5909"> created. A person&apos;s own action may place demands upon himself. If X asks a question of Y, then Y normally establishes an internal demand to answer the question. But X may 30 also establish a demand of the form, &amp;quot;check to see if the question has been answered&amp;quot;. This latter demand may generate a later utterance such as, &amp;quot;Why haven t you answered me?&amp;quot;. Simple demand models already exist in a few systems. In general, they suggest that utterances are produced in response to conditions in the (internal model of the) environment rather than as units in a larger linguistic form. (See also Stansfield (1975)). It would be premature to argue that either a demand model or a grammar model is sufficient by itself. Instead, what follows is simply a description of a demand model for the travel budget management domain mentioned above. Internal demands on the travel budget system help to explain how one computation of a response can be pushed down, while a whole dialogue takes place to obtain missing information, and how a computation can spawn subsequent expectations or digressions. Associated with each demand is a priority, a pointer (purpose) to the demand which spawned this one (if any), and a time </context>
<context position="37912" citStr="(1975)" startWordPosition="6324" endWordPosition="6324">odes of interaction. For example, if the manager says &amp;quot;Enter a trip,&amp;quot; the system notes that the current topic has changed to an incompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are useful in exemplifying ways in which the o</context>
</contexts>
<marker>1975</marker>
<rawString>. &amp;quot;Generation as a Social Action&amp;quot;. In Theoretical Issues in Natural Language Processing (Ed: B, L. Nash-Webber and R. C. Schank), ACL, 1975b.</rawString>
</citation>
<citation valid="true">
<title>Pragmatics in Speech Understanding&amp;quot;.</title>
<date>1975</date>
<booktitle>Proc. 4th IJCAI,</booktitle>
<location>Tbilisi,</location>
<contexts>
<context position="25654" citStr="(1974, 1975)" startWordPosition="4260" endWordPosition="4261"> restricted in scope to that of managing a travel budget. Imagine that a person responsible for a travei budget is trying to decide how many people to send to an upcoming conference. He has available a computer system which can answer questions about the budget, conferences, trips and so on. In talking to such a system, the travel budget 22 manager is engaging in an admittedly simple dialogue, but one which nevertheless exhibits many interesting properties of discourse understanding. (The following dialogue is hypothetical; however a system of this type is being developed at BBN (Woods, et al (1974, 1975))). The (human) manager begins: (1) WHEN IS THE NEXT ASSP CONFERENCE? May 15-18, 1975 (2) IS THAT IN OUR CURRENT BUDGET YEAR? Yes. (3) HOW MUCH MONEY DO WE HAVE LEFT? $316,41 remains in the budget. (4) WHAT IS THE COST OF THE ASSP CONFERENCE? The registration fee is $25. Would you like me to estimate the cost of a trip to the conference? (5) YES. FOR THREE PEOPLE. Assuming they travel by air ... Assuming each person spends three days in Philadelphia ... Assuming a per day expense of $25 400 The cost would,be $371.50. (6) WILL THE BUDGET COVER THAT? No, the deficit would be $55.09. (7) ASSUME T</context>
<context position="29404" citStr="(1975)" startWordPosition="4899" endWordPosition="4899">ost of us readily form an opinion about its structure. In any dialogue we see this kind of structure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might b</context>
<context position="31906" citStr="(1975)" startWordPosition="5328" endWordPosition="5328">in addition to this &amp;quot;SCHEDULE&amp;quot; network there is an &amp;quot;ENTER&amp;quot; network wherein the manager describes a new trip to be entered and the system asks him questions to complete the description. P S PUSH BELONG! BUDGET? 27 PUSH COST? l&apos;U MP PUS H SC1DA4 STOP ENTER (PoP) Fig. 1. ATN for scheduling a trip. A discourse or dialogue grammar can be used with a modified ATN parser to &amp;quot;parse&amp;quot; a dialogue, generating both analyses of the current utterance and predictions about the one to come. In fact, one such modified parser and grammar has been implemented for the BBN speech system (Bruce(1975c), Woods, et al (1975)). For many dialogues, the grammar applies quite well, testing for the head verb in the utterance, the mood, and checking presuppositions of the action implied. When successful, it makes 28 corresponding predictions for application to the next utterance. Unfortunately, when the grammar fails it is not very good at recovering from its error. Discourse grammars seem to be most effective in tightly constrained domains, more for instance in a discussion about how to cook a turkey, where there are specific subproblems to analyze, than in the travel budget management domain, and less still in a gene</context>
<context position="35363" citStr="(1975)" startWordPosition="5909" endWordPosition="5909"> created. A person&apos;s own action may place demands upon himself. If X asks a question of Y, then Y normally establishes an internal demand to answer the question. But X may 30 also establish a demand of the form, &amp;quot;check to see if the question has been answered&amp;quot;. This latter demand may generate a later utterance such as, &amp;quot;Why haven t you answered me?&amp;quot;. Simple demand models already exist in a few systems. In general, they suggest that utterances are produced in response to conditions in the (internal model of the) environment rather than as units in a larger linguistic form. (See also Stansfield (1975)). It would be premature to argue that either a demand model or a grammar model is sufficient by itself. Instead, what follows is simply a description of a demand model for the travel budget management domain mentioned above. Internal demands on the travel budget system help to explain how one computation of a response can be pushed down, while a whole dialogue takes place to obtain missing information, and how a computation can spawn subsequent expectations or digressions. Associated with each demand is a priority, a pointer (purpose) to the demand which spawned this one (if any), and a time </context>
<context position="37912" citStr="(1975)" startWordPosition="6324" endWordPosition="6324">odes of interaction. For example, if the manager says &amp;quot;Enter a trip,&amp;quot; the system notes that the current topic has changed to an incompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are useful in exemplifying ways in which the o</context>
</contexts>
<marker>1975</marker>
<rawString>. &amp;quot;Pragmatics in Speech Understanding&amp;quot;. Proc. 4th IJCAI, Tbilisi, 1975c.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Schmidt</author>
</authors>
<title>Episode Understanding and Belief Guided Parsing&amp;quot;. Presented at 12th ACL Meeting,</title>
<date>1974</date>
<tech>Report CBM-TR-32).</tech>
<institution>Also Rutgers Computer Science Dept.</institution>
<location>Amherst,</location>
<contexts>
<context position="29941" citStr="Schmidt (1974)" startWordPosition="4980" endWordPosition="4981">ips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might be - 1. Find out to which budget the trip should belong. 2. Determine how much is in the budget (budget). 3. Figure the cost of the trip (tripcost). 4. Decide whether (budget - tripcost) is acceptable. 5. If acceptable, schedule the trip and stop. 6. If not acceptable, determine if trip can be&apos; modified to be cheaper. a. If modifiable, go to 3. b. If not modifiable, stop. 26 The steps (1 - 6) above are ordered, though nothing is said about their relative lengths. Also, there are variants on the plan where the order might be changed,</context>
</contexts>
<marker>Schmidt, 1974</marker>
<rawString>and C. F. Schmidt. &amp;quot;Episode Understanding and Belief Guided Parsing&amp;quot;. Presented at 12th ACL Meeting, Amherst, 1974. (Also Rutgers Computer Science Dept. Report CBM-TR-32).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara G Deutsch</author>
</authors>
<title>The Structure of Task Oriented Dialogues&amp;quot;. Contributed Papers,</title>
<date>1974</date>
<booktitle>IEEE Symposium on Speech Recognition, CMU,</booktitle>
<location>Pittsburgh,</location>
<contexts>
<context position="12888" citStr="Deutsch, 1974" startWordPosition="2097" endWordPosition="2098">ive is useful for determining all the relationships into which an object has entered. The task model in our system will be embodied in procedural net which encodes the task structure in a hierarchy of subtasks and encodes each subtask as a partial ordering of steps (glactrdoti, 1975), The procedural net system also allows tasxs to be expanded dynamically to further levels of detail when 12 necessary, A representation of the hierarchy of subtasks is important for reference resolution, An examination of task•oriented dialogs shows that references operate within tasks and up the hierarchy chain (Deutsch, 1974), Using the hierarchy of the procedural net to impose a hierarchy on the focus spaces enables us to search for references in hierarchical order. Having a representation of the partial ordering of tasks allows us to capture the alternatives the apprentice has in choosing subsequent tasks. We have explicitly separated the three components of the dialog context, The representation of an object in a focus spice will include only the relationships that have been mentioned in the dialog concerning the corresponding subtask or that are inherent in Thus, the recorded in objects in procedural informati</context>
<context position="32556" citStr="Deutsch (1974" startWordPosition="5429" endWordPosition="5430">plies quite well, testing for the head verb in the utterance, the mood, and checking presuppositions of the action implied. When successful, it makes 28 corresponding predictions for application to the next utterance. Unfortunately, when the grammar fails it is not very good at recovering from its error. Discourse grammars seem to be most effective in tightly constrained domains, more for instance in a discussion about how to cook a turkey, where there are specific subproblems to analyze, than in the travel budget management domain, and less still in a general question answering context. (Cf. Deutsch (1974, 1975)). Lest it be thought that discourse parsing is just sentence parsing for &amp;quot;big sentences&amp;quot;, I should emphasize some of the differences, differences which some would say preclude the use of terms like &amp;quot;grammar&amp;quot;, &amp;quot;ATN&amp;quot;, and &amp;quot;parsing&amp;quot;. First, discourse parsing p&apos;roceeds in a mode of partial parse, then output, then partial parse, etc. In other words, the goal is to derive information from the partial discourse which has occurred to suggest what may follow and to explicate the role of the current utterance. The parse is never completed, no structure is built. Since the entire discourse is no</context>
</contexts>
<marker>Deutsch, 1974</marker>
<rawString>Deutsch, Barbara G. &amp;quot;The Structure of Task Oriented Dialogues&amp;quot;. Contributed Papers, IEEE Symposium on Speech Recognition, CMU, Pittsburgh, 1974.</rawString>
</citation>
<citation valid="true">
<title>Discourse Analysis and Pragmatics&amp;quot;. In Speech Understanding Research</title>
<date>1975</date>
<tech>Technical Report, SRI,</tech>
<contexts>
<context position="25654" citStr="(1974, 1975)" startWordPosition="4260" endWordPosition="4261"> restricted in scope to that of managing a travel budget. Imagine that a person responsible for a travei budget is trying to decide how many people to send to an upcoming conference. He has available a computer system which can answer questions about the budget, conferences, trips and so on. In talking to such a system, the travel budget 22 manager is engaging in an admittedly simple dialogue, but one which nevertheless exhibits many interesting properties of discourse understanding. (The following dialogue is hypothetical; however a system of this type is being developed at BBN (Woods, et al (1974, 1975))). The (human) manager begins: (1) WHEN IS THE NEXT ASSP CONFERENCE? May 15-18, 1975 (2) IS THAT IN OUR CURRENT BUDGET YEAR? Yes. (3) HOW MUCH MONEY DO WE HAVE LEFT? $316,41 remains in the budget. (4) WHAT IS THE COST OF THE ASSP CONFERENCE? The registration fee is $25. Would you like me to estimate the cost of a trip to the conference? (5) YES. FOR THREE PEOPLE. Assuming they travel by air ... Assuming each person spends three days in Philadelphia ... Assuming a per day expense of $25 400 The cost would,be $371.50. (6) WILL THE BUDGET COVER THAT? No, the deficit would be $55.09. (7) ASSUME T</context>
<context position="29404" citStr="(1975)" startWordPosition="4899" endWordPosition="4899">ost of us readily form an opinion about its structure. In any dialogue we see this kind of structure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might b</context>
<context position="31906" citStr="(1975)" startWordPosition="5328" endWordPosition="5328">in addition to this &amp;quot;SCHEDULE&amp;quot; network there is an &amp;quot;ENTER&amp;quot; network wherein the manager describes a new trip to be entered and the system asks him questions to complete the description. P S PUSH BELONG! BUDGET? 27 PUSH COST? l&apos;U MP PUS H SC1DA4 STOP ENTER (PoP) Fig. 1. ATN for scheduling a trip. A discourse or dialogue grammar can be used with a modified ATN parser to &amp;quot;parse&amp;quot; a dialogue, generating both analyses of the current utterance and predictions about the one to come. In fact, one such modified parser and grammar has been implemented for the BBN speech system (Bruce(1975c), Woods, et al (1975)). For many dialogues, the grammar applies quite well, testing for the head verb in the utterance, the mood, and checking presuppositions of the action implied. When successful, it makes 28 corresponding predictions for application to the next utterance. Unfortunately, when the grammar fails it is not very good at recovering from its error. Discourse grammars seem to be most effective in tightly constrained domains, more for instance in a discussion about how to cook a turkey, where there are specific subproblems to analyze, than in the travel budget management domain, and less still in a gene</context>
<context position="35363" citStr="(1975)" startWordPosition="5909" endWordPosition="5909"> created. A person&apos;s own action may place demands upon himself. If X asks a question of Y, then Y normally establishes an internal demand to answer the question. But X may 30 also establish a demand of the form, &amp;quot;check to see if the question has been answered&amp;quot;. This latter demand may generate a later utterance such as, &amp;quot;Why haven t you answered me?&amp;quot;. Simple demand models already exist in a few systems. In general, they suggest that utterances are produced in response to conditions in the (internal model of the) environment rather than as units in a larger linguistic form. (See also Stansfield (1975)). It would be premature to argue that either a demand model or a grammar model is sufficient by itself. Instead, what follows is simply a description of a demand model for the travel budget management domain mentioned above. Internal demands on the travel budget system help to explain how one computation of a response can be pushed down, while a whole dialogue takes place to obtain missing information, and how a computation can spawn subsequent expectations or digressions. Associated with each demand is a priority, a pointer (purpose) to the demand which spawned this one (if any), and a time </context>
<context position="37912" citStr="(1975)" startWordPosition="6324" endWordPosition="6324">odes of interaction. For example, if the manager says &amp;quot;Enter a trip,&amp;quot; the system notes that the current topic has changed to an incompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are useful in exemplifying ways in which the o</context>
</contexts>
<marker>1975</marker>
<rawString>&amp;quot;Discourse Analysis and Pragmatics&amp;quot;. In Speech Understanding Research (D. Walker, W. Paxton, J. Robinson, G. Hendrix, B. Deutsch, and A. Robinson), Annual Technical Report, SRI, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erving Goffman</author>
</authors>
<title>Relations in Public.</title>
<date>1971</date>
<publisher>Basic Books,</publisher>
<location>New York,</location>
<contexts>
<context position="37994" citStr="Goffman (1971)" startWordPosition="6333" endWordPosition="6334">system notes that the current topic has changed to an incompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are useful in exemplifying ways in which the otherwise hazy area of discourse might be modeled. The grammar approach makes the s</context>
</contexts>
<marker>Goffman, 1971</marker>
<rawString>Goffman, Erving. Relations in Public. Basic Books, New York, 1971.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Joseph Grimes</author>
</authors>
<title>The Thread of Discourse.</title>
<location>Mouton, Paris,</location>
<note>in press.</note>
<marker>Grimes, </marker>
<rawString>Grimes, Joseph. The Thread of Discourse. Mouton, Paris, in press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Labov</author>
</authors>
<title>Rules for Ritual Insults&amp;quot;. In Studies dn Social Interaction (Ed: David Sudnow), The Free</title>
<date>1972</date>
<publisher>Press (Macmillan),</publisher>
<contexts>
<context position="37872" citStr="Labov (1972)" startWordPosition="6318" endWordPosition="6319">nses. Again, this structure leads to certain modes of interaction. For example, if the manager says &amp;quot;Enter a trip,&amp;quot; the system notes that the current topic has changed to an incompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are us</context>
</contexts>
<marker>Labov, 1972</marker>
<rawString>Labov, William. &amp;quot;Rules for Ritual Insults&amp;quot;. In Studies dn Social Interaction (Ed: David Sudnow), The Free Press (Macmillan), 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marvin Minsky</author>
</authors>
<title>A Framework for the Representation of Knowledge&amp;quot;.</title>
<date>1975</date>
<booktitle>In The Psychology of Computer Vision</booktitle>
<contexts>
<context position="29404" citStr="Minsky (1975)" startWordPosition="4898" endWordPosition="4899">on 2, most of us readily form an opinion about its structure. In any dialogue we see this kind of structure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might b</context>
</contexts>
<marker>Minsky, 1975</marker>
<rawString>Minsky, Marvin. &amp;quot;A Framework for the Representation of Knowledge&amp;quot;. In The Psychology of Computer Vision (Ed: P. Winston), 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Phillips</author>
</authors>
<title>Topic Analysis.</title>
<date>1975</date>
<tech>Ph. D. Thesis,</tech>
<location>SUNY Buffalo,</location>
<contexts>
<context position="29506" citStr="Phillips (1975)" startWordPosition="4912" endWordPosition="4913">ructure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might be - 1. Find out to which budget the trip should belong. 2. Determine how much is in the budget (budget</context>
</contexts>
<marker>Phillips, 1975</marker>
<rawString>Phillips, Brian. Topic Analysis. Ph. D. Thesis, SUNY Buffalo, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Rumelhart</author>
</authors>
<title>Notes, on a Schema for Stories&amp;quot;.</title>
<date>1975</date>
<booktitle>In Representation and Understanding: Studies in Cognitive Science (Ed: D. Bobrow</booktitle>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker>Rumelhart, 1975</marker>
<rawString>Rumelhart, David. &amp;quot;Notes, on a Schema for Stories&amp;quot;. In Representation and Understanding: Studies in Cognitive Science (Ed: D. Bobrow and A. Collins), Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey Sacks</author>
<author>Emanuel Schegloff</author>
<author>Gail Jefferson</author>
</authors>
<title>A Simplest Systematics for the Organization of Turn-Taking for Conversations&amp;quot;. Semiotica,</title>
<date>1974</date>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>Sacks, Harvey, Emanuel Schegloff and Gail Jefferson. &amp;quot;A Simplest Systematics for the Organization of Turn-Taking for Conversations&amp;quot;. Semiotica, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Schank</author>
<author>Robert Abelson</author>
</authors>
<title>Scripts Plans and Knowledge&amp;quot;.</title>
<date>1975</date>
<booktitle>Proc. 4th IJCAI,</booktitle>
<location>Tbilisi,</location>
<contexts>
<context position="29477" citStr="Schank and Abelson (1975)" startWordPosition="4906" endWordPosition="4909"> In any dialogue we see this kind of structure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might be - 1. Find out to which budget the trip should belong. 2. Determine how </context>
</contexts>
<marker>Schank, Abelson, 1975</marker>
<rawString>Schank, Roger and Robert Abelson. &amp;quot;Scripts Plans and Knowledge&amp;quot;. Proc. 4th IJCAI, Tbilisi, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emanuel A Schegloff</author>
</authors>
<title>Notes on a Conversational Practice: Formulating Place&amp;quot;.</title>
<date>1972</date>
<booktitle>In Studies in Social InteraOtion (Ed: David Sudnow), The</booktitle>
<publisher>Free Press (Macmillan),</publisher>
<contexts>
<context position="37934" citStr="Schegloff (1972)" startWordPosition="6326" endWordPosition="6327">raction. For example, if the manager says &amp;quot;Enter a trip,&amp;quot; the system notes that the current topic has changed to an incompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are useful in exemplifying ways in which the otherwise hazy area of </context>
</contexts>
<marker>Schegloff, 1972</marker>
<rawString>Schegloff, Emanuel A. &amp;quot;Notes on a Conversational Practice: Formulating Place&amp;quot;. In Studies in Social InteraOtion (Ed: David Sudnow), The Free Press (Macmillan), 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles F Schmidt</author>
</authors>
<title>Understanding Human Action: Recognizing the Motives and Plans of Other Persons&amp;quot;. Carnegie</title>
<date>1975</date>
<booktitle>Symposium on Cognition: CogRition and Social Behavior,</booktitle>
<location>CMU, Pittsburgh,</location>
<contexts>
<context position="29957" citStr="Schmidt (1975)" startWordPosition="4982" endWordPosition="4983">le has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might be - 1. Find out to which budget the trip should belong. 2. Determine how much is in the budget (budget). 3. Figure the cost of the trip (tripcost). 4. Decide whether (budget - tripcost) is acceptable. 5. If acceptable, schedule the trip and stop. 6. If not acceptable, determine if trip can be&apos; modified to be cheaper. a. If modifiable, go to 3. b. If not modifiable, stop. 26 The steps (1 - 6) above are ordered, though nothing is said about their relative lengths. Also, there are variants on the plan where the order might be changed, e.g. step 3 mig</context>
</contexts>
<marker>Schmidt, 1975</marker>
<rawString>Schmidt, Charles F. &amp;quot;Understanding Human Action: Recognizing the Motives and Plans of Other Persons&amp;quot;. Carnegie Symposium on Cognition: CogRition and Social Behavior, CMU, Pittsburgh, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>Speech Acts.</title>
<date>1969</date>
<publisher>Cambridge University Press,</publisher>
<location>London,</location>
<contexts>
<context position="38048" citStr="Searle (1969)" startWordPosition="6340" endWordPosition="6341">ncompletely described trip. This results in demands that cause standard fill-in questions to be asked. If the manager wants to complete the trip description later, then the completion of the trip description becomes a low 32 priority demand. 5. Synthesis? Discourse has been. an object of study for many both in and out of the field of computational Linguistics. Especially worth noting is the work of sociolinguists such as Labov (1972), Sacks, Schegloff, and Jefferson (1975), and Schegloff (1972). Linguists (e.g. Grimes), sociologists (e.g. Goffman (1971)), and philosophers (e.g. Austin (1962), Searle (1969)) have important direct or related contributions. I certainly can&apos;t presume in this short paper tn give the definitive solution to all the problems revolving around the discourse question. What I have tried to do is to emphasize a distinction in approach between looking at a discourse as a linguistic whole with subparts being individual utterances, and as a side effect of responses to task demands. Both approaches are useful in exemplifying ways in which the otherwise hazy area of discourse might be modeled. The grammar approach makes the strongest statement about actual discourse structure an</context>
</contexts>
<marker>Searle, 1969</marker>
<rawString>Searle, J. R. Speech Acts. Cambridge University Press, London, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James L Stansfield</author>
</authors>
<title>Programming a Dialogue Teaching Situation.</title>
<date>1974</date>
<tech>Ph. D. Thesis,</tech>
<institution>U. of Edinburgh,</institution>
<marker>Stansfield, 1974</marker>
<rawString>Stansfield, James L. Programming a Dialogue Teaching Situation. Ph. D. Thesis, U. of Edinburgh, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Frame Representations and the Declarative-Procedural Controversy&amp;quot;.</title>
<date>1975</date>
<booktitle>In Representation and Ullderstanding: Studies in Cognitive Science (Ed: D. Bobrow</booktitle>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="29421" citStr="Winograd (1975)" startWordPosition="4900" endWordPosition="4901">s readily form an opinion about its structure. In any dialogue we see this kind of structure; one peroon is asking another to do something; two people are arguing about politics, or discussing a novel. There is almost always a structure higher 25 than the individual sentences. In the example ction 2, the travel budget manager seems to be entering into a &amp;quot;scnedule a trip&amp;quot; dialogue. His question about a future conference is one of the cues to a bundle of information known by both him and the system about scheduling trips. Such a bundle has been variously referred to as a &amp;quot;frame&amp;quot; (Minsky (1975), Winograd (1975)), a &amp;quot;script&amp;quot; (Abelson (1975), Schank and Abelson (1975)), a &amp;quot;theme&amp;quot; (Phillips (1975)), a &amp;quot;story schema&amp;quot; (Runelhart (1975)), and a &amp;quot;social action paradigm&amp;quot; (Bruce (1975a, 1975b)). The information associated with scheduling a trip includes facts about dates and times, about the budget, about travel, about conferences, and so on. It also includes &amp;quot;plans&amp;quot;, that is, time ordered structures of beliefs about achieving &amp;quot;goals&amp;quot;. In this case, the goal is scheduling a trip to a conference. (See also Bruce and Schmidt (1974), Schmidt (1975)). One such partially instantiated plan might be - 1. Find out t</context>
</contexts>
<marker>Winograd, 1975</marker>
<rawString>Winograd, Terry. &amp;quot;Frame Representations and the Declarative-Procedural Controversy&amp;quot;. In Representation and Ullderstanding: Studies in Cognitive Science (Ed: D. Bobrow and A. Collins), Academic Press, New York, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Woods</author>
<author>M Bates</author>
<author>B Bruce</author>
<author>J Colarusso</author>
<author>C Cook</author>
<author>L Gould</author>
<author>D Grabel</author>
<author>J Makhoul</author>
<author>B Nash-Webber</author>
<author>R Schwartz</author>
<author>J Wolf</author>
</authors>
<title>Natural Communication with Computers, Final Report - Vol. I, Speech Understanding Research at BBN&amp;quot;.</title>
<date>1974</date>
<tech>BBN Report No. 2976,</tech>
<contexts>
<context position="25647" citStr="Woods, et al (1974" startWordPosition="4257" endWordPosition="4260"> conversation restricted in scope to that of managing a travel budget. Imagine that a person responsible for a travei budget is trying to decide how many people to send to an upcoming conference. He has available a computer system which can answer questions about the budget, conferences, trips and so on. In talking to such a system, the travel budget 22 manager is engaging in an admittedly simple dialogue, but one which nevertheless exhibits many interesting properties of discourse understanding. (The following dialogue is hypothetical; however a system of this type is being developed at BBN (Woods, et al (1974, 1975))). The (human) manager begins: (1) WHEN IS THE NEXT ASSP CONFERENCE? May 15-18, 1975 (2) IS THAT IN OUR CURRENT BUDGET YEAR? Yes. (3) HOW MUCH MONEY DO WE HAVE LEFT? $316,41 remains in the budget. (4) WHAT IS THE COST OF THE ASSP CONFERENCE? The registration fee is $25. Would you like me to estimate the cost of a trip to the conference? (5) YES. FOR THREE PEOPLE. Assuming they travel by air ... Assuming each person spends three days in Philadelphia ... Assuming a per day expense of $25 400 The cost would,be $371.50. (6) WILL THE BUDGET COVER THAT? No, the deficit would be $55.09. (7) A</context>
</contexts>
<marker>Woods, Bates, Bruce, Colarusso, Cook, Gould, Grabel, Makhoul, Nash-Webber, Schwartz, Wolf, 1974</marker>
<rawString>Woods, William, M. Bates, B. Bruce, J. Colarusso, C. Cook, L. Gould, D. Grabel, J. Makhoul, B. Nash-Webber, R. Schwartz, J. Wolf. &amp;quot;Natural Communication with Computers, Final Report - Vol. I, Speech Understanding Research at BBN&amp;quot;. BBN Report No. 2976, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Woods</author>
<author>R Schwartz</author>
<author>C Cook</author>
<author>J Klovstad</author>
<author>L Bates</author>
<author>B Nash-Webber</author>
<author>B Bruce</author>
<author>J Makhoul</author>
</authors>
<title>Speech Understanding Systems: QTPR 3&amp;quot;.</title>
<date>1975</date>
<tech>BBN Report No. 3115,</tech>
<contexts>
<context position="31906" citStr="Woods, et al (1975)" startWordPosition="5325" endWordPosition="5328">For example, in addition to this &amp;quot;SCHEDULE&amp;quot; network there is an &amp;quot;ENTER&amp;quot; network wherein the manager describes a new trip to be entered and the system asks him questions to complete the description. P S PUSH BELONG! BUDGET? 27 PUSH COST? l&apos;U MP PUS H SC1DA4 STOP ENTER (PoP) Fig. 1. ATN for scheduling a trip. A discourse or dialogue grammar can be used with a modified ATN parser to &amp;quot;parse&amp;quot; a dialogue, generating both analyses of the current utterance and predictions about the one to come. In fact, one such modified parser and grammar has been implemented for the BBN speech system (Bruce(1975c), Woods, et al (1975)). For many dialogues, the grammar applies quite well, testing for the head verb in the utterance, the mood, and checking presuppositions of the action implied. When successful, it makes 28 corresponding predictions for application to the next utterance. Unfortunately, when the grammar fails it is not very good at recovering from its error. Discourse grammars seem to be most effective in tightly constrained domains, more for instance in a discussion about how to cook a turkey, where there are specific subproblems to analyze, than in the travel budget management domain, and less still in a gene</context>
</contexts>
<marker>Woods, Schwartz, Cook, Klovstad, Bates, Nash-Webber, Bruce, Makhoul, 1975</marker>
<rawString>Woods, William A., R. Schwartz, C. Cook, J. Klovstad, L. Bates, B. Nash-Webber, B. Bruce, J. Makhoul. &amp;quot;Speech Understanding Systems: QTPR 3&amp;quot;. BBN Report No. 3115, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Furugori illmore</author>
<author>C J</author>
</authors>
<title>Toward a Modern Theory of Case.</title>
<date>1969</date>
<booktitle>In Reibel</booktitle>
<tech>Technical Report No. 77,</tech>
<institution>Department of Computer Science, SUNY Buffalo.</institution>
<marker>illmore, J, 1969</marker>
<rawString>?illmore, Furugori, C. J. 1969. Toward a Modern Theory of Case. In Reibel and Schane. T. 1974. &amp;quot;A memory model and simulation of memory processes for driving a car.&amp;quot; Technical Report No. 77, Department of Computer Science, SUNY Buffalo.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>