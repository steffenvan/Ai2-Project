<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9970525">
Automatic Annotation of Bibliographical References with Target
Language
</title>
<author confidence="0.995628">
Harald Hammarstr¨om
</author>
<affiliation confidence="0.9873235">
Dept. of Comp. Sci.
Chalmers University
</affiliation>
<address confidence="0.8622005">
S-412 96 Gothenburg
SWEDEN
</address>
<email confidence="0.993746">
harald2@chalmers.se
</email>
<sectionHeader confidence="0.993741" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999921529411765">
In a large-scale project to list bibliograph-
ical references to all of the ca 7 000 lan-
guages of the world, the need arises to
automatically annotated the bibliographi-
cal entries with ISO-639-3 language iden-
tifiers. The task can be seen as a special
case of a more general Information Extrac-
tion problem: to classify short text snip-
pets in various languages into a large num-
ber of classes. We will explore supervised
and unsupervised approaches motivated by
distributional characterists of the specific
domain and availability of data sets. In
all cases, we make use of a database with
language names and identifiers. The sug-
gested methods are rigorously evaluated on
a fresh representative data set.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955857142857">
There are about 7 000 languages in the world
(Hammarstr¨om, 2008) and there is a quite accu-
rate database of which they are (Gordon, 2005).
Language description, i.e., producing a phonologi-
cal description, grammatical description, wordlist,
dictionary, text collection or the like, of these 7
000 languages has been on-going on a larger scale
since about 200 years. This process is fully de-
centralized, and at present there is no database over
which languages of the world have been described,
which have not, and which have partial descrip-
tions already produced (Hammarstr¨om, 2007b).
We are conducting a large-scale project of listing
all published descriptive work on the languages
</bodyText>
<footnote confidence="0.90287025">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.996534657142857">
of the world, especially lesser-known languages.
In this project, the following problem naturally
arises:
Given: A database of the world’s languages (con-
sisting minimally of &lt;unique-id, language-
name&gt;-pairs)
Input: A bibliographical reference to a work with
descriptive language data of (at least one of)
the language in the database
Desired output: The identification of which lan-
guage(s) is described in the bibliographical
reference
We would like to achieve this with as little human
labour as possible. In particular, this means that
thresholds that are to be set by humans are to be
avoided. However, we will allow (and do make
use of – see below) supervision in the form of data-
bases of language references annotated with target
language as long as they are freely available.
As an example, say that we are given a bibli-
ographical reference to a descriptive work as fol-
lows:
Dammann, Ernst 1957 Studien zum
Kwangali: Grammatik, Texte, Glossar,
Hamburg: Cram, de Gruyter &amp; Co. [Ab-
handlungen aus dem Gebiet der Aus-
landskunde / Reihe B, V¨olkerkunde,
Kulturgeschichte und Sprachen 35]
This reference happens to describe a Namibian-
Angolan language called Kwangali [kwn]. The
task is to automatically infer this, for an arbitrary
bibliographical entry in an arbitrary language, us-
ing the database of the world’s languages and/or
databases of annotated entries, but without hu-
manly tuned thresholds. (We will assume that
</bodyText>
<page confidence="0.986974">
57
</page>
<note confidence="0.6956505">
Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 57–64
Manchester, August 2008
</note>
<bodyText confidence="0.9983755">
the bibliographical comes segmented into fields,
at least as to the title, though this does not matter
much.)
Unfortunately, the problem is not simply that
of a clean database lookup. As shall be seen,
the distributional characteristics of the world lan-
guage database and input data give rise to a special
case of a more general Information Extraction (IE)
problem. To be more precise, an abstract IE prob-
lem may be defined as follows:
</bodyText>
<listItem confidence="0.976503285714286">
• There is a set of natural language objects O
• There is a fixed set of categories C
• Each object in O belong to zero or more cat-
egories, i.e., there is a function C : O →
Powerset(C)
• The task is to find classification function f
that mimics C.
The special case we are considering here is such
that:
• Each object in O contains a small amount of
text, on the order of 100 words
• The language of objects in O varies across
objects, i.e., not all objects are written in the
same language
• |C |is large, i.e., there are many classes (about
7 000 in our case)
• |C(o) |is small for most objects o E O, i.e.,
most objects belong to very few categories
(typically exactly one category)
• Most objects o E O contain a few tokens
that near-uniquely identifies C(o), i.e., there
are some words that are very informative as
to category, while the majority of tokens are
very little informative. (This characteristic
excludes the logical possibility that each to-
ken is fairly informative, and that the tokens
together, on an equal footing, serve to pin-
point category.)
</listItem>
<bodyText confidence="0.99807875">
We will explore and compare ways to exploit these
skewed distributional properties for more informed
database lookups, applied and evaluated on the
outlined reference-annotation problem.
</bodyText>
<sectionHeader confidence="0.794654" genericHeader="introduction">
2 Data and Specifics
</sectionHeader>
<bodyText confidence="0.9998956">
The exact nature of the data at hand is felt to be
quite important for design choices in our proposed
algorithm, and is assumed to be unfamiliar to most
readers, wherefore we go through it in some detail
here.
</bodyText>
<subsectionHeader confidence="0.997119">
2.1 World Language Database
</subsectionHeader>
<bodyText confidence="0.999895916666667">
The Ethnologue (Gordon, 2005) is a database that
aims to catalogue all the known living languages
of the world.1 As far as language inventory goes,
the database is near perfect and language/dialect
divisions are generally accurate, though this issue
is thornier (Hammarstr¨om, 2005).
Each language is given a unique three-letter
identifier, a canonical name and a set of variant
and/or dialect names.2 The three-letter codes are
draft ISO-639-3 standard. This database is freely
downloadable3. For example, the entry for Kwan-
gali [kwn] contains the following information:
</bodyText>
<construct confidence="0.625695">
Canonical name: Kwangali
ISO 639-3: kwn
Alternative names4: {Kwangali,
Shisambyu, Cuangar, Sambio, Kwan-
gari, Kwangare, Sambyu, Sikwangali,
Sambiu, Kwangali, Rukwangali}.
</construct>
<bodyText confidence="0.99914125">
The database contains 7 299 languages (thus 7
299 unique id:s) and a total of 42 768 name tokens.
Below are some important characteristics of these
collections:
</bodyText>
<listItem confidence="0.69618425">
• Neither the canonical names nor the alterna-
tive names are guaranteed to be unique (to
one language). There are 39 419 unique name
strings (but 42 768 name tokens in the data-
base!). Thus the average number of different
languages (= unique id:s) a name denotes is
1.08, the median is 1 and the maximum is 14
(for Miao).
</listItem>
<footnote confidence="0.997763133333333">
1It also contains some sign languages and some extinct
attested languages, but it does not aim or claim to be complete
for extinct and signed languages.
2Further information is also given, such as number of
speakers and existence of a bible translation is also given, but
is of no concern for the present purposes.
3From http://www.sil.org/iso639-3/
download.asp accessed 20 Oct 2007.
4The database actually makes a difference between dialect
names and other variant names. In this case Sikwangali, Ruk-
wangali, Kwangari, Kwangare are altername names denoting
Kwangali, while Sambyu is the name of a specific dialect and
Shisambyu, Sambiu, Sambio are variants of Sambyu. We will
not make use of the distinction between a dialect name and
some other alternative name.
</footnote>
<page confidence="0.996687">
58
</page>
<listItem confidence="0.617438594594595">
• The average number of names (including the
canonical name) of a language is 5.86, the
median is 4, and the maximum is 77 (for Ar-
menian [hye]).
• It is not yet well-understood how complete
database of alternative names is. In the prepa-
ration of the test set (see Section 2.4) an at-
tempt to estimate this was made, yielding the
following results. 100 randomly chosen bib-
liographical entries contained 104 language
names in the title. 43 of these names (41.3%)
existed in the database as written. 66 (63.5%)
existed in the database allowing for variation
in spelling (cf. Section 1). A more interesting
test, which could not be carried out for prac-
tical reasons, would be to look at a language
and gather all publications relating to that lan-
guage, and collect the names occurring in ti-
tles of these. (To collect the full range of
names denoting languages used in the bodies
of such publications is probably not a well-
defined task.) The Ethnologue itself does not
systematically contain bibliographical refer-
ences, so it is not possible to deduce from
where/how the database of alternative names
was constructed.
• A rough indication of the ratio between
spelling variants versus alternative roots
among alternative names is as follows. For
each of the 7299 sets of alternative names,
we conflate the names which have an edit dis-
tance5 of G i for i = 0,... , 4. The mean, me-
dian and max number of names after conflat-
ing is shown below. What this means is that
languages in the database have about 3 names
on average and another 3 spelling variants on
average.
</listItem>
<table confidence="0.7067535">
i Mean Median Max
0 5.86 4 77 ’hye’
1 4.80 3 65 ’hye’
2 4.07 3 56 ’eng’
3 3.41 2 54 ’eng’
4 2.70 2 47 ’eng’
</table>
<subsectionHeader confidence="0.999099">
2.2 Bibliographical Data
</subsectionHeader>
<bodyText confidence="0.952885625">
Descriptive data on the languages of the world
are found in books, PhD/MA theses, journal arti-
cles, conference articles, articles in collections and
5Penalty weights set to 1 for deletion, insertion and sub-
stitution alike.
manuscripts. If only a small number of languages
is covered in one publication, the title usually car-
ries sufficient information for an experienced hu-
man to deduce which language(s) is covered. On
the other hand, if a larger number of languages is
targeted, the title usually only contains approxi-
mate information as to the covered languages, e.g.,
Talen en dialecten van Nederlands Nieuw-Guinea
or West African Language Data Sheets. The (meta-
)language [as opposed to target language] of de-
scriptive works varies (cf. Section 2.4).
</bodyText>
<subsectionHeader confidence="0.999821">
2.3 Free Annotated Databases
</subsectionHeader>
<bodyText confidence="0.99998375">
Training of a classifier (’language annotator’) in a
supervised framework, requires a set of annotated
entries with a distribution similar to the set of en-
tries to be annotated. We know of only two such
databases which can be freely accessed6; WALS
and the library catalogue of MPI/EVA in Leipzig.
WALS: The bibliography for the World At-
las of Language Structures book can now
be accessed online (http://www.wals.
info/). This database contains 5633 entries
annotated to 2053 different languages.
MPI/EVA: The library catalogue for the library
of the Max Planck Institute for Evolution An-
thropology (http://biblio.eva.mpg.
de/) is queryable online. In May 2006 it con-
tained 7266 entries annotated to 2246 differ-
ent languages.
Neither database is free from errors, impreci-
sions and inconsistencies (impressionistically 5%
of the entries contain such errors). Nevertheless,
for training and development, we used both data-
bases put together. The two databases put together,
duplicates removed, contains 8584 entries anno-
tated to 2799 different languages.
</bodyText>
<subsectionHeader confidence="0.999862">
2.4 Test Data
</subsectionHeader>
<bodyText confidence="0.999843">
In a large-scale on-going project, we are trying
to collect all references to descriptive work for
lesser-known languages. This is done by tediously
</bodyText>
<footnote confidence="0.9125202">
6For example, the very wide coverage database world-
cat (http://www.worldcat.org/) does not index in-
dividual articles and has insufficient language annotation;
sometimes no annotation or useless categories such as
’other’ or ’Papuan’. The SIL Bibliography (http://
www.ethnologue.com/bibliography.asp)iswell-
annotated but contains only work produced by the SIL. (SIL
has, however, worked on very many languages, but not all
publications of the de-centralized SIL organization are listed
in the so-called SIL Bibliography.)
</footnote>
<page confidence="0.997893">
59
</page>
<bodyText confidence="0.999908722222222">
going through handbooks, overviews and biblio-
graphical for all parts of the world alike. In this
bibliography, the (meta-)language of descriptive
data is be English, German, French, Spanish, Por-
tuguese, Russian, Dutch, Italian, Chinese, Indone-
sian, Thai, Turkish, Persian, Arabic, Urdu, Nepali,
Hindi, Georgian, Japanese, Swedish, Norwegian,
Danish, Finnish and Bulgarian (in decreasing or-
der of incidence)7. Currently it contains 11788 en-
tries. It is this database that needs to be annotated
as to target language. The overlap with the joint
WALS-MPI/EVA database is 3984 entries.8 Thus
11788 − 3984 = 7804 entries remain to be an-
notated. From these 7 804 entries, 100 were ran-
domly selected and humanly annotated to form a
test set. This test set was not used in the develop-
ment at all, and was kept totally fresh for the final
tests.
</bodyText>
<sectionHeader confidence="0.999815" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999491333333334">
We conducted experiments with three different
methods, plus the enhancement of spelling varia-
tion on top of each one.
Naive Lookup: Each word in the title is looked
up as a possible language name in the world
language database and the output is the union
of all answers to the look-ups.
Term Weight Lookup: Each word is given a
weight according to the number of unique-
id:s it is associated with in the training data.
Based on these weights, the words of the
title are split into two groups; informative
and non-informative words. The output is
the union of the look-up:s of the informative
words in the world language database.
Following a subsection on terminology and defin-
itions, these will be presented in increasing order
of sophistication.
</bodyText>
<subsectionHeader confidence="0.617457">
3.1 Terminology and Definitions
</subsectionHeader>
<listItem confidence="0.890472">
• C: The set of 7 299 unique three-letter lan-
guage id:s
• N: The set of 39 419 language name strings
in the Ethnologue (as above)
• C(c): The set of names C N associated with
the code c E C in the Ethnologue database
(as above)
• LN(w) = {id|w E C(id), id E C}: The set
of id:s C C that have w as one of its names
• CS(c) = UwinC(c)Spellings(w): The set
of variant spellings of the set of names C
N associated with the code c E C in the
Ethnologye database. For reference, the
Spelling(w)-function is defined in detail in
Table 1.
• LNS(w) = {id|w E CS(id), id E C}: The
set of id:s C C that have w as a possible
spelling of one of its names
• WE: The set of entries in the joint WALS-
MPI/EVA database (as above). Each entry e
has a title et and a set ec of language id:s C C
• Words(et): The set of words, everything
lowercased and interpunctation removed, in
the title et
• LWEN(w) = {id|e E WE, w E et, id E
ec}: The set of codes associated with the en-
tries whose titles contain the word w
</listItem>
<bodyText confidence="0.9780328">
Term Weight Lookup with Group Disambiguation:
As above, except that names of genealogical
(sub-)groups and country names that occur
in the title are used for narrowing down the
result.
</bodyText>
<footnote confidence="0.839536">
7Those entries which are natively written with a different
alphabet always also have a transliteration or translation (or
both) into ascii characters.
8This overlap at first appears surprisingly low. Part of
the discrepancy is due to the fact that many references in the
WALS database are in fact to secondary sources, which are
not intended to be covered at all in the on-going project of
listing. Another reason for the discrepancy is due to a de-
prioritization of better-known languages as well as dictionar-
ies (as opposed to grammars) in the on-going project. Even-
tually, all unique references will of course be merged.
</footnote>
<bodyText confidence="0.971204166666667">
• TD(w) = LN(w) U LWEN(w): The set
of codes tied to the word w either as a lan-
guage name or as a word that occurs in a ti-
tle of an code-tagged entry (in fact, an Eth-
nologue entry can be seen as a special kind of
bibliographical entry, with a title consisting of
alternative names annotated with exactly one
category)
• TDS = LNS(w) U LWEN(w): The set of
codes tied to the word w either as a (variant
spelling of a) language name or as a word that
occurs in a title of an code-tagged entry
</bodyText>
<page confidence="0.988514">
60
</page>
<listItem confidence="0.94636">
• WC(w) = |TD(w)|: The number of differ-
ent codes associated with the word w
• WI(w) =|{et|w E Words(et), et E
WE}|: The number of different bibliographi-
cal entries for which the word w occurs in the
title
• A: The set of entries in the test set (as above).
Each entry e has a title et and a set ec of lan-
guage id:s C C
• PAA(X) = �{e�X(e)==ec,eEA}�: The perfect
�A�
</listItem>
<bodyText confidence="0.8689505">
accuracy of a classifier function X on test
set A is the number of entries in A which
are classified correctly (the sets of categories
have to be fully equal)
</bodyText>
<listItem confidence="0.938077">
• SA r 1{X(e)nec11: The sum ac-
A(X ) = EeEA lecuX(e)
</listItem>
<bodyText confidence="0.99300025">
curacy of a classifier function X on a test set
A is the sum of the (possibly imperfect) ac-
curacy of the entries of A (individual entries
match with score between 0 and 1)
</bodyText>
<subsectionHeader confidence="0.993787">
3.2 Naive Union Lookup
</subsectionHeader>
<bodyText confidence="0.971929333333333">
As a baseline to beat, we define a naive lookup
classifier. Given an entry e, we define naive union
lookup (NUL) as:
</bodyText>
<equation confidence="0.992999">
NUL(e) = UwEWords(et)LN(w)
</equation>
<bodyText confidence="0.978160476190476">
For example, consider the following entry e:
Anne Gwena¨ı´elle Fabre 2002 ´Etude du
Samba Leko, parler d’Allani (Cameroun
du Nord, Famille Adamawa), PhD The-
sis, Universit´e de Paris III – Sorbonne
Nouvelle
The steps in its NUL-classification is as follows
are given in Table 2.
Finally, NUL(e) = {ndi, lse, smx, dux, lec,
ccg}, but, simply enough, ec = {ndi}.
The resulting accuracies are PANUL(A) ≈
0.15 and SANUL(A) ≈ 0.21. NUL performs
even worse with spelling variants enabled. Not
surprisingly, NUL overclassifies a lot, i.e., it con-
sistently guesses more languages than is the case.
This is because guessing that a title word indicates
a target language just because there is one lan-
guage with such a name, is not a sound practice.
In fact, common words like du [dux], in [irr], the
[thx], to [toz], and la [wbm, lic, tdd] happen to be
names of languages (!).
</bodyText>
<subsectionHeader confidence="0.994275">
3.3 Term Weight Lookup
</subsectionHeader>
<bodyText confidence="0.999773102040817">
We learn from the Naive Union Lookup experi-
ment that we cannot guess blindly which word(s)
in the title indicate the target language. Some-
thing has to be done to individate the informa-
tiveness of each word. Domain knowledge tells
us two relevant things. Firstly, a title of a pub-
lication in language description typically contains
one or few words with very precise information on
the target language(s), namely the name of the lan-
guage(s), and in addition a number of words which
recur throughout many titles, such as ’a’, ’gram-
mar’, etc. Secondly, most of the language of the
world are poorly described, there are only a few,
if any, publications with original descriptive data.
Inspired by the tf-idf measure in Information Re-
trieval (Baeza-Yates and Ribeiro-Neto, 1997), we
claim that informativeness of a word w, given an-
notated training data, can be assessed as WC(w),
i.e., the number of distinct codes associated with
w in the training data or Ethnologue database. The
idea is that a uniquitous word like ’the’ will be as-
sociated with many codes, while a fairly unique
language name will be associated with only one or
a few codes. For example, consider the following
entry:
W. M. Rule 1977 A Comparative Study
of the Foe, Huli and Pole Languages
of Papua New Guinea, University of
Sydney, Australia [Oceania Linguistic
Monographs 20]
Table 3 shows the title words and their associ-
ated number of codes associated (sorted in ascend-
ing order).
So far so good, we now have an informative-
ness value for each word, but at which point (above
which value?) do the scores mean that word is a
near-unique language name rather than a relatively
ubiquitous non-informative word? Luckily, we are
assuming that there are only those two kinds of
words, and that at least one near-unique language
will appear. This means that if we cluster the val-
ues into two clusters, the two categories are likely
to emerge nicely. The simplest kind of clustering
of scalar values into two clusters is to sort the val-
ues and put the border where the relative increase
is the highest. Typically, in titles where there is
exactly one near-unique language name, the bor-
der will almost always isolate that name. In the
example above, where we actually have three near-
</bodyText>
<page confidence="0.994503">
61
</page>
<figure confidence="0.976892142857143">
# Substition Reg. Exp. Replacement
\’\`\&amp;quot;\\&amp;quot; ’’
[qk](?=[ei]) qu
k(?=[aou]|$)|q(?=[ao]) c
oo|ou|oe u
[hgo]?u(?=[aouei]|$) w
((?:[&amp;quot;aouei]*[aouei]
[&amp;quot;aouei]*)+?)
(?:an$|ana$|ano$|o$) \1a
eca$ ec
tsch|tx|tj ch
dsch|dj j
x(?=i) sh
i(?=[aouei]) y
ern$|i?sche?$ ’’
([a-z])\1 \1
[bdgv] b/p,d/t,g/k,v/f
[oe] o/u,e/i
Comment
diacritics truncated
k-sound before soft vowel to qu
k-sound before hard vowel to c
oo,ou,oetou
hu-sound before hard vowel to w
an? to a
ecatoec
tsch,txtoch
dsch, dj to j
</figure>
<bodyText confidence="0.543435636363636">
x before i to sh
i before a vowel to y
final sche, ern removed
remove doublets
devoice b, d, g, v
lower vowels
Table 1: Given a language name w, its normalized spelling variants are enumerate according to the fol-
lowing (ordered) list of substitution rules. The set of spelling variants Spelling(w) should be understood
as the strings {w/actions−Z|i ≤ 15}, where w/actions−Z is the string with substitutions 1 thru i carried
out. This normalization scheme is based on extensive experience with language name searching by the
present author.
</bodyText>
<table confidence="0.998888428571428">
Words(et) LN(Words(et)) Words(et) LN(Words(et))
etude {} cameroun {}
du {dux} du {dux}
samba {ndi, ccg, smx} nord {}
leko {ndi, lse, lec} famille {}
parler {} adamawa {}
d’allani {}
</table>
<tableCaption confidence="0.999659">
Table 2: The calculation of NUL for an example entry
</tableCaption>
<bodyText confidence="0.998791142857143">
unique identifiers, this procedure correctly puts the
border so that Foe, Pole and Huli are near-unique
and the rest are non-informative.
Now, that we have a method to isolate the group
of most informative words in a title et (denoted
SIGWC(et)), we can restrict lookup only to them.
TWL is thus defined as follows:
</bodyText>
<equation confidence="0.973678">
TWL(e) = U-ESIGWc(ec)LN(w)
</equation>
<bodyText confidence="0.998935928571429">
In the example above, TWL(et) is
{fli, kjy, foi, hui} which is almost correct,
containing only a spurious [fli] because Huli is
also an alternative name for Fali in Cameroon,
nowhere near Papua New Guinea. This is a
complication that we will return to in the next
section.
The resulting accuracies jump up to
PATWL(A) ≈ 0.57 and SATWL(A) ≈ 0.73.
Given that we “know” which words in the ti-
tle are the supposed near-unique language names,
we can afford, i.e., not risk too much overgenera-
tion, to allow for spelling variants. Define TWLS
(“with spelling variants”) as:
</bodyText>
<equation confidence="0.911294">
TWLS(e) = U-ESIGWc(ec)LNS(w)
</equation>
<bodyText confidence="0.99704575">
We get slight improvements in accuracy
PATWLS(A) ≈ 0.61 and SATWLS(A) ≈ 0.74.
The WC(w)-counts make use of the annotated
entries in the training data. An intriguing modi-
fication is to estimate WC(w) without this anno-
tation. It turns out that WC(w) can be sharply
estimated with WI(w), i.e., the raw number of en-
tries in the training set in which w occurs in the
</bodyText>
<page confidence="0.997737">
62
</page>
<table confidence="0.991416333333333">
foe pole huli papua guinea comparative new study languages and a the of
1 2 3 57 106 110 145 176 418 1001 1101 1169 1482
1.0 2.0 1.5 19.0 1.86 1.04 1.32 1.21 2.38 2.39 1.10 1.06 1.27
</table>
<tableCaption confidence="0.996997">
Table 3: The values of WC(w) for w taken from an example entry (mid row). The bottom row shows
</tableCaption>
<bodyText confidence="0.993520130434783">
the relative increase of the sequence of values in the mid-row, i.e., each value divided by the previous
value (with the first set to 1.0).
title. This identity breaks down to the extent that a
word w occurs in many entries, all of them point-
ing to one and the same language id. From domain
knowledge, we know that this is unlikely if w is
a near-unique language name, because most lan-
guages do not have many descriptive works about
them. The TWL-classifier is now unsupervised in
the sense that it does not have to have annotated
training entries, but it still needs raw entries which
have a realistic distribution. (The test set, or the
set of entries to be annotated, can of course itself
serve as such a set.)
Modeling Term Weight Lookup with WI in
place of WC, call it TWI, yields slight accu-
racy drops PATWI(A) ≈ 0.55 and SATWI(A) ≈
0.70, and with spelling variants PATWIS(A) ≈
0.59 and SATWIS(A) ≈ 0.71. Since, we do in
fact have access to annotated data, we will use the
supervised classifier in the future, but it is impor-
tant to know that the unsupervised variant is nearly
as strong.
</bodyText>
<sectionHeader confidence="0.999042" genericHeader="method">
4 Term Weight Lookup with Group
Disambiguation
</sectionHeader>
<bodyText confidence="0.9999488">
Again, from our domain knowledge, we know that
a large number of entries contain a “group name”,
i.e., the name of a country, region of genealogical
(sub-)group in addition to a near-unique language
name. Since group names will naturally tend to be
associated with many codes, they will sorted into
the non-informative camp with the TWL-method,
and thus ignored. This is unfortunate, because
such group names can serve to disambiguate in-
herent small ambivalences among near-unique lan-
guage names, as in the case of Huli above. Group
names are not like language names. They are much
fewer, they are typically longer (often multi-word),
and they exhibit less spelling variation.
Fortunately, the Ethnologue database also con-
tains information on language classification and
the country (or countries) where each language
is spoken. Therefore, it was a simple task to
build a database of group names with genealog-
ical groups and sub-groups as well as countries.
</bodyText>
<table confidence="0.984632375">
PA SA
NUL 0.15 0.21
TWL 0.57 0.73
TWLS 0.61 0.74
TWI 0.55 0.70
TWIS 0.59 0.71
TWG 0.59 0.74
TWGS 0.64 0.77
</table>
<tableCaption confidence="0.9303545">
Table 4: Summary of methods and corresponding
accuracy scores.
</tableCaption>
<bodyText confidence="0.998704357142857">
All group names are unique9 as group names (but
some group names of small genetic groups are
the same as that of a prominent language in that
group). In total, this database contained 3 202
groups. This database is relatively complete for
English names of (sub-)families and countries, but
should be enlarged with the corresponding names
in other languages.
We can add group-based disambiguation to
TWL as follows. The non-significant words of a
title is searched for matching group names. The set
of languages denoted by a group name is denoted
L(g) with L(g) = C if g is not a group name found
in the database.
</bodyText>
<equation confidence="0.991653">
TWG(e) = (Uw∈SIGWC(et)LN(w))
ng∈(Words(et)\SIGWC(et))L(g)
</equation>
<bodyText confidence="0.999256">
We get slight improvements in accuracy
PATWG(A) ≈ 0.59 and SATWG(A) ≈ 0.74.
The corresponding accuracies with spelling vari-
ation enabled are PATWG(A) ≈ 0.64 and
SATWG(A) ≈ 0.77.
</bodyText>
<sectionHeader confidence="0.999826" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9929975">
A summary of accuracy scores are given in Table
4.
All scores conform to expected intuitions and
motivations. The key step beyond naive lookup
</bodyText>
<footnote confidence="0.94739075">
9In a few cases they were forced unique, e.g., when two
families X, Y were listed as having subgroups called Eastern
(or the like), the corresponding group names were forced to
Eastern-X and Eastern-Y respectively.
</footnote>
<page confidence="0.999373">
63
</page>
<bodyText confidence="0.999327333333333">
is the usage of term weighting (and the fact the
we were able to do this without a threshold or the
like).
In the future, it appears fruitful to look more
closely at automatic extraction of groups from an-
notated data. Initial experiments along this line
were unsucessful, because data with evidence for
groups is sparse. It also seems worthwhile to
take multiword language names seriously (which
is more implementational than conceptual work).
Given that near-unique language names and group
names can be reliably identified, it is easy to
generate frames for typical titles of publications
with language description data, in many languages.
Such frames can be combed over large amounts of
raw data to speed up the collection of further rel-
evant references, in the typical manner of contem-
porary Information Extraction.
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999810785714286">
As far as we are aware, the same problem or an
isomorphic problem has not previously been dis-
cussed in the literature. It seems likely that isomor-
phic problems exist, perhaps in Information Ex-
traction in the bioinformatics and/or medical do-
mains, but so far we have not found such work.
The problem of language identification, i.e.,
identify the language of a (written) document
given a set of candidate languages and train-
ing data for them, is a very different problem
– requiring very different techniques (see Ham-
marstr¨om (2007a) for a survey and references).
We have made important use of ideas from In-
formation Retrieval and Data Clustering.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999996125">
We have presented (what is believed to be) the first
algorithms for the specific problem of annotating
language references with their target language(s).
The methods used are tailored closely to the do-
main and our knowledge of it, but it is likely that
there are isomorphic domains with the same prob-
lem(s). We have made a proper evaluation and the
accuracy achieved is definetely useful.
</bodyText>
<sectionHeader confidence="0.998948" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.99892025">
We wish to thank the responsible entities for post-
ing the Ethnologue, WALS, and the MPI/EVA li-
brary catalogue online. Without these resources,
this study would have been impossible.
</bodyText>
<sectionHeader confidence="0.996272" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997422">
Baeza-Yates, Ricardo and Berthier Ribeiro-Neto. 1997.
Modern Information Retrieval. Addison-Wesley.
Gordon, Jr., Raymond G., editor. 2005. Ethnologue:
Languages of the World. SIL International, Dallas,
15 edition.
Hammarstr¨om, Harald. 2005. Review of the Eth-
nologue, 15th ed., Raymond G. Gordon, Jr. (ed.),
SIL international, Dallas, 2005. LINGUIST LIST,
16(2637), September.
Hammarstr¨om, Harald. 2007a. A fine-grained model
for language identification. In Proceedings of
iNEWS-07 Workshop at SIGIR 2007, 23-27 July
2007, Amsterdam, pages 14–20. ACM.
Hammarstr¨om, Harald. 2007b. Handbook of Descrip-
tive Language Knowledge: A Full-Scale Reference
Guide forTypologists, volume 22 of LINCOM Hand-
books in Linguistics. Lincom GmbH.
Hammarstr¨om, Harald. 2008. On the ethnologue and
the number of languages in the world. Submitted
Manuscript.
</reference>
<page confidence="0.999407">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.179949">
<title confidence="0.99908">Automatic Annotation of Bibliographical References with Target Language</title>
<author confidence="0.972784">Harald</author>
<affiliation confidence="0.97568">Dept. of Comp.</affiliation>
<address confidence="0.301546">Chalmers</address>
<phone confidence="0.502531">S-412 96</phone>
<email confidence="0.729053">harald2@chalmers.se</email>
<abstract confidence="0.998174833333333">In a large-scale project to list bibliographical references to all of the ca 7 000 languages of the world, the need arises to automatically annotated the bibliographical entries with ISO-639-3 language identifiers. The task can be seen as a special case of a more general Information Extraction problem: to classify short text snippets in various languages into a large number of classes. We will explore supervised and unsupervised approaches motivated by distributional characterists of the specific domain and availability of data sets. In all cases, we make use of a database with language names and identifiers. The suggested methods are rigorously evaluated on a fresh representative data set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ricardo Baeza-Yates</author>
<author>Berthier Ribeiro-Neto</author>
</authors>
<title>Modern Information Retrieval.</title>
<date>1997</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="17988" citStr="Baeza-Yates and Ribeiro-Neto, 1997" startWordPosition="3028" endWordPosition="3031">thing has to be done to individate the informativeness of each word. Domain knowledge tells us two relevant things. Firstly, a title of a publication in language description typically contains one or few words with very precise information on the target language(s), namely the name of the language(s), and in addition a number of words which recur throughout many titles, such as ’a’, ’grammar’, etc. Secondly, most of the language of the world are poorly described, there are only a few, if any, publications with original descriptive data. Inspired by the tf-idf measure in Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1997), we claim that informativeness of a word w, given annotated training data, can be assessed as WC(w), i.e., the number of distinct codes associated with w in the training data or Ethnologue database. The idea is that a uniquitous word like ’the’ will be associated with many codes, while a fairly unique language name will be associated with only one or a few codes. For example, consider the following entry: W. M. Rule 1977 A Comparative Study of the Foe, Huli and Pole Languages of Papua New Guinea, University of Sydney, Australia [Oceania Linguistic Monographs 20] Table 3 shows the title words </context>
</contexts>
<marker>Baeza-Yates, Ribeiro-Neto, 1997</marker>
<rawString>Baeza-Yates, Ricardo and Berthier Ribeiro-Neto. 1997. Modern Information Retrieval. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<date>2005</date>
<booktitle>Ethnologue: Languages of the World. SIL International,</booktitle>
<volume>15</volume>
<pages>edition.</pages>
<editor>Gordon, Jr., Raymond G., editor.</editor>
<location>Dallas,</location>
<marker>2005</marker>
<rawString>Gordon, Jr., Raymond G., editor. 2005. Ethnologue: Languages of the World. SIL International, Dallas, 15 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Hammarstr¨om</author>
</authors>
<title>Review of the Ethnologue,</title>
<date>2005</date>
<journal>LINGUIST LIST,</journal>
<volume>16</volume>
<issue>2637</issue>
<editor>15th ed., Raymond G. Gordon, Jr. (ed.), SIL international, Dallas,</editor>
<marker>Hammarstr¨om, 2005</marker>
<rawString>Hammarstr¨om, Harald. 2005. Review of the Ethnologue, 15th ed., Raymond G. Gordon, Jr. (ed.), SIL international, Dallas, 2005. LINGUIST LIST, 16(2637), September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Hammarstr¨om</author>
</authors>
<title>A fine-grained model for language identification.</title>
<date>2007</date>
<booktitle>In Proceedings of iNEWS-07 Workshop at SIGIR</booktitle>
<pages>23--27</pages>
<publisher>ACM.</publisher>
<location>Amsterdam,</location>
<marker>Hammarstr¨om, 2007</marker>
<rawString>Hammarstr¨om, Harald. 2007a. A fine-grained model for language identification. In Proceedings of iNEWS-07 Workshop at SIGIR 2007, 23-27 July 2007, Amsterdam, pages 14–20. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Hammarstr¨om</author>
</authors>
<title>Handbook of Descriptive Language Knowledge: A Full-Scale Reference Guide forTypologists,</title>
<date>2007</date>
<booktitle>of LINCOM Handbooks in Linguistics. Lincom GmbH.</booktitle>
<volume>22</volume>
<marker>Hammarstr¨om, 2007</marker>
<rawString>Hammarstr¨om, Harald. 2007b. Handbook of Descriptive Language Knowledge: A Full-Scale Reference Guide forTypologists, volume 22 of LINCOM Handbooks in Linguistics. Lincom GmbH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Hammarstr¨om</author>
</authors>
<title>On the ethnologue and the number of languages in the world.</title>
<date>2008</date>
<note>Submitted Manuscript.</note>
<marker>Hammarstr¨om, 2008</marker>
<rawString>Hammarstr¨om, Harald. 2008. On the ethnologue and the number of languages in the world. Submitted Manuscript.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>