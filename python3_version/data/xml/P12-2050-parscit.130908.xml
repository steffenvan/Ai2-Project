<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9980155">
Coarse Lexical Semantic Annotation with Supersenses:
An Arabic Case Study
</title>
<author confidence="0.998644">
Nathan Schneider† Behrang Mohit* Kemal Oflazer* Noah A. Smith†
</author>
<affiliation confidence="0.8810615">
School of Computer Science, Carnegie Mellon University
*Doha, Qatar †Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.997907">
{nschneid@cs.,behrang@,ko@cs.,nasmith@cs.}cmu.edu
</email>
<sectionHeader confidence="0.997377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999886727272727">
“Lightweight” semantic annotation of text
calls for a simple representation, ideally with-
out requiring a semantic lexicon to achieve
good coverage in the language and domain.
In this paper, we repurpose WordNet’s super-
sense tags for annotation, developing specific
guidelines for nominal expressions and ap-
plying them to Arabic Wikipedia articles in
four topical domains. The resulting corpus
has high coverage and was completed quickly
with reasonable inter-annotator agreement.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9995111875">
The goal of “lightweight” semantic annotation of
text, particularly in scenarios with limited resources
and expertise, presents several requirements for a
representation: simplicity; adaptability to new lan-
guages, topics, and genres; and coverage. This
paper describes coarse lexical semantic annotation
of Arabic Wikipedia articles subject to these con-
straints. Traditional lexical semantic representations
are either narrow in scope, like named entities,1 or
make reference to a full-fledged lexicon/ontology,
which may insufficiently cover the language/domain
of interest or require prohibitive expertise and ef-
fort to apply.2 We therefore turn to supersense tags
(SSTs), 40 coarse lexical semantic classes (25 for
nouns, 15 for verbs) originating in WordNet. Previ-
ously these served as groupings of English lexicon
</bodyText>
<footnote confidence="0.980821111111111">
1Some ontologies like those in Sekine et al. (2002) and BBN
Identifinder (Bikel et al., 1999) include a large selection of
classes, which tend to be especially relevant to proper names.
2E.g., a WordNet (Fellbaum, 1998) sense annotation effort
reported by Passonneau et al. (2010) found considerable inter-
annotator variability for some lexemes; FrameNet (Baker et
al., 1998) is limited in coverage, even for English; and Prop-
Bank (Kingsbury and Palmer, 2002) does not capture semantic
relationships across lexemes. We note that the Omega ontol-
</footnote>
<note confidence="0.548302">
ogy (Philpot et al., 2003) has been used for fine-grained cross-
lingual annotation (Hovy et al., 2006; Dorr et al., 2010).
</note>
<figure confidence="0.950978">
COMMUNICATION
GROUP
859 ø
XCJ
Ó .
AD
</figure>
<sectionHeader confidence="0.33725" genericHeader="method">
ACT TIME
</sectionHeader>
<bodyText confidence="0.633542333333333">
‘The Guinness Book of World Records considers the
University of Al-Karaouine in Fez, Morocco, established
in the year 859 AD, the oldest university in the world.’
</bodyText>
<figureCaption confidence="0.886008">
Figure 1: A sentence from the article “Islamic Golden
Age,” with the supersense tagging from one of two anno-
tators. The Arabic is shown left-to-right.
</figureCaption>
<bodyText confidence="0.998058142857143">
entries, but here we have repurposed them as target
labels for direct human annotation.
Part of the earliest versions of WordNet, the
supersense categories (originally, “lexicographer
classes”) were intended to partition all English noun
and verb senses into broad groupings, or semantic
fields (Miller, 1990; Fellbaum, 1990). More re-
cently, the task of automatic supersense tagging has
emerged for English (Ciaramita and Johnson, 2003;
Curran, 2005; Ciaramita and Altun, 2006; Paaß and
Reichartz, 2009), as well as for Italian (Picca et al.,
2008; Picca et al., 2009; Attardi et al., 2010) and
Chinese (Qiu et al., 2011), languages with WordNets
mapped to English WordNet.3 In principle, we be-
lieve supersenses ought to apply to nouns and verbs
in any language, and need not depend on the avail-
ability of a semantic lexicon.4 In this work we focus
on the noun SSTs, summarized in figure 2 and ap-
plied to an Arabic sentence in figure 1.
SSTs both refine and relate lexical items: they
capture lexical polysemy on the one hand—e.g.,
</bodyText>
<footnote confidence="0.98265075">
3Note that work in supersense tagging used text with fine-
grained sense annotations that were then coarsened to SSTs.
4The noun/verb distinction might prove problematic in some
languages.
</footnote>
<figure confidence="0.999059339622642">
Q�.JªK
��
considers
•~
JJ
k.
Guinness
H. A~J»
book
�
CË
éJ��ƒAJ
Ë@
ÐA;P
��
à@
that
for-records the-standard
éªÓAg.
�
university
à@ðQ���®Ë@
Al-Karaouine
€Ai
in Fez
H. Q ªÖÏ@
�
Morocco
éªÓAg.
�
oldest university
�
ÐY¯~@
ú¯
�
ú¯
�
in
ARTIFACT LOCATION
ÕËAªË@
the-world
�
AîD„J�ƒA�K
established
é�Jƒ~
in year
IJ �
~ Õç
k was
where
ú¯
�
LOCATION
</figure>
<page confidence="0.987092">
253
</page>
<note confidence="0.8648575">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 253–258,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<table confidence="0.5264145">
Crusades · Damascus · Ibn Tolun Mosque · Imam Hussein Shrine · Islamic Golden Age · Islamic History · Ummayad Mosque 434s 16,185t 5,859m
Atom · Enrico Fermi · Light · Nuclear power · Periodic Table · Physics · Muhammad al-Razi 777s 18,559t 6,477m
2004 Summer Olympics · Christiano Ronaldo · Football · FIFA World Cup · Portugal football team · Ra´ul Gonz´ales · Real Madrid 390s 13,716t 5,149m
Computer · Computer Software · Internet · Linux · Richard Stallman · Solaris · X Window System 618s 16,992t 5,754m
</table>
<tableCaption confidence="0.982962">
Table 1: Snapshot of the supersense-annotated data. The 7 article titles (translated) in each domain, with total counts
</tableCaption>
<bodyText confidence="0.96124252173913">
of sentences, tokens, and supersense mentions. Overall, there are 2,219 sentences with 65,452 tokens and 23,239
mentions (1.3 tokens/mention on average). Counts exclude sentences marked as problematic and mentions marked ?.
disambiguating PERSON vs. POSSESSION for the
noun principal—and generalize across lexemes on
the other—e.g., principal, teacher, and student can
all be PERSONs. This lumping property might be
expected to give too much latitude to annotators; yet
we find that in practice, it is possible to elicit reason-
able inter-annotator agreement, even for a language
other than English. We encapsulate our interpreta-
tion of the tags in a set of brief guidelines that aims
to be usable by anyone who can read and understand
a text in the target language; our annotators had no
prior expertise in linguistics or linguistic annotation.
Finally, we note that ad hoc categorization
schemes not unlike SSTs have been developed for
purposes ranging from question answering (Li and
Roth, 2002) to animacy hierarchy representation for
corpus linguistics (Zaenen et al., 2004). We believe
the interpretation of the SSTs adopted here can serve
as a single starting point for diverse resource en-
gineering efforts and applications, especially when
fine-grained sense annotation is not feasible.
</bodyText>
<sectionHeader confidence="0.965645" genericHeader="method">
2 Tagging Conventions
</sectionHeader>
<bodyText confidence="0.999854266666667">
WordNet’s definitions of the supersenses are terse,
and we could find little explicit discussion of the
specific rationales behind each category. Thus,
we have crafted more specific explanations, sum-
marized for nouns in figure 2. English examples
are given, but the guidelines are intended to be
language-neutral. A more systematic breakdown,
formulated as a 43-rule decision list, is included
with the corpus.5 In developing these guidelines
we consulted English WordNet (Fellbaum, 1998)
and SemCor (Miller et al., 1993) for examples and
synset definitions, occasionally making simplifying
decisions where we found distinctions that seemed
esoteric or internally inconsistent. Special cases
(e.g., multiword expressions, anaphora, figurative
</bodyText>
<footnote confidence="0.8665175">
5For example, one rule states that all man-made structures
(buildings, rooms, bridges, etc.) are to be tagged as ARTIFACTs.
</footnote>
<bodyText confidence="0.522537">
language) are addressed with additional rules.
</bodyText>
<sectionHeader confidence="0.969606" genericHeader="method">
3 Arabic Wikipedia Annotation
</sectionHeader>
<bodyText confidence="0.999600151515152">
The annotation in this work was on top of a small
corpus of Arabic Wikipedia articles that had al-
ready been annotated for named entities (Mohit et
al., 2012). Here we use two different annotators,
both native speakers of Arabic attending a university
with English as the language of instruction.
Data &amp; procedure. The dataset (table 1) consists of
the main text of 28 articles selected from the topical
domains of history, sports, science, and technology.
The annotation task was to identify and categorize
mentions, i.e., occurrences of terms belonging to
noun supersenses. Working in a custom, browser-
based interface, annotators were to tag each relevant
token with a supersense category by selecting the to-
ken and typing a tag symbol. Any token could be
marked as continuing a multiword unit by typing &lt;.
If the annotator was ambivalent about a token they
were to mark it with the ? symbol. Sentences were
pre-tagged with suggestions where possible.6 Anno-
tators noted obvious errors in sentence splitting and
grammar so ill-formed sentences could be excluded.
Training. Over several months, annotators alter-
nately annotated sentences from 2 designated arti-
cles of each domain, and reviewed the annotations
for consistency. All tagging conventions were deve-
loped collaboratively by the author(s) and annotators
during this period, informed by points of confusion
and disagreement. WordNet and SemCor were con-
sulted as part of developing the guidelines, but not
during annotation itself so as to avoid complicating
the annotation process or overfitting to WordNet’s
idiosyncracies. The training phase ended once inter-
annotator mention FI had reached 75%.
</bodyText>
<footnote confidence="0.9968392">
6Suggestions came from the previous named entity annota-
tion of PERSONs, organizations (GROUP), and LOCATIONs, as
well as heuristic lookup in lexical resources—Arabic WordNet
entries (Elkateb et al., 2006) mapped to English WordNet, and
named entities in OntoNotes (Hovy et al., 2006).
</footnote>
<page confidence="0.990552">
254
</page>
<table confidence="0.712496966666667">
O NATURAL OBJECT natural feature or nonliving object in
nature barrier reef nest neutron star
planet sky fishpond metamorphic rock Mediterranean cave
stepping stone boulder Orion ember universe
A ARTIFACT man-made structures and objects bridge
restaurant bedroom stage cabinet toaster antidote aspirin
L LOCATION any name of a geopolitical entity, as well as
other nouns functioning as locations or regions
Cote d’Ivoire New York City downtown stage left India
Newark interior airspace
P PERSON humans or personified beings; names of social
groups (ethnic, political, etc.) that can refer to an individ-
ual in the singular Persian deity glasscutter mother
kibbutznik firstborn worshiper Roosevelt Arab consumer
appellant guardsman Muslim American communist
G GROUP groupings of people or objects, including: orga-
nizations/institutions; followers of social movements
collection flock army meeting clergy Mennonite Church
trumpet section health profession peasantry People’s Party
U.S. State Department University of California population
consulting firm communism Islam (= set of Muslims)
$ SUBSTANCE a material or substance krypton mocha
atom hydrochloric acid aluminum sand cardboard DNA
H POSSESSION term for an entity involved in ownership or
payment birthday present tax shelter money loan
T TIME a temporal point, period, amount, or measurement
10 seconds day Eastern Time leap year 2nd millenium BC
2011 (=year) velocity frequency runtime latency/delay
middle age half life basketball season words per minute
curfew industrial revolution instant/moment August
</table>
<bodyText confidence="0.676129875">
= RELATION relations between entities or quantities
ratio scale reverse personal relation exponential function
angular position unconnectedness transitivity
Q QUANTITY quantities and units of measure, including
cardinal numbers and fractional amounts 7 cm 1.8 million
12 percent/12% volume (= spatial extent) volt real number
square root digit 90 degrees handful ounce half
F FEELING subjective emotions indifference wonder
</bodyText>
<subsectionHeader confidence="0.370738">
murderousness grudge desperation astonishment suffering
</subsectionHeader>
<bodyText confidence="0.773129555555556">
M MOTIVE an abstract external force that causes someone
to intend to do something reason incentive
C COMMUNICATION information encoding and transmis-
sion, except in the sense of a physical object
grave accent Book of Common Prayer alphabet
Cree language onomatopoeia reference concert hotel bill
broadcast television program discussion contract proposal
equation denial sarcasm concerto software
ˆ COGNITION aspects of mind/thought/knowledge/belief/
perception; techniques and abilities; fields of academic
study; social or philosophical movements referring to the
system of beliefs Platonism hypothesis
logic biomedical science necromancy hierarchical structure
democracy innovativeness vocational program woodcraft
reference visual image Islam (= Islamic belief system) dream
scientific method consciousness puzzlement skepticism
reasoning design intuition inspiration muscle memory skill
aptitude/talent method sense of touch awareness
</bodyText>
<subsectionHeader confidence="0.172029">
S STATE stable states of affairs; diseases and their symp-
</subsectionHeader>
<bodyText confidence="0.941829214285714">
toms symptom reprieve potency
poverty altitude sickness tumor fever measles bankruptcy
infamy opulence hunger opportunity darkness (= lack of light)
@ ATTRIBUTE characteristics of people/objects that can be
judged resilience buxomness virtue immateriality
admissibility coincidence valence sophistication simplicity
temperature (= degree of hotness) darkness (= dark coloring)
I ACT things people do or cause to happen; learned pro-
fessions meddling malpractice faith healing dismount
carnival football game acquisition engineering (=profession)
E EVENT things that happens at a given place and time
bomb blast ordeal miracle upheaval accident tide
R PROCESS a sustained phenomenon or one marked by
gradual changes through a series of states
</bodyText>
<subsectionHeader confidence="0.4605765">
oscillation distillation overheating aging accretion/growth
extinction evaporation
</subsectionHeader>
<bodyText confidence="0.879841222222222">
X PHENOMENON a physical force or something that hap-
pens/occurs electricity suction tailwind tornado effect
+ SHAPE two and three dimensional shapes
D FOOD things used as food or drink
B BODY human body parts, excluding diseases and their
symptoms
Y PLANT a plant or fungus
N ANIMAL non-human, non-plant life
Science chemicals, molecules, atoms, and subatomic
particles are tagged as SUBSTANCE
Sports championships/tournaments are EVENTs
(Information) Technology Software names, kinds, and
components are tagged as COMMUNICATION (e.g. kernel,
version, distribution, environment). A connection is a RE-
LATION; project, support, and a configuration are tagged
as COGNITION; development and collaboration are ACTs.
Arabic conventions Masdar constructions (verbal
nouns) are treated as nouns. Anaphora are not tagged.
</bodyText>
<figureCaption confidence="0.612711">
Figure 2: Above: The complete supersense tagset for nouns; each tag is briefly described by its symbol, NAME,
short description, and examples. Some examples and longer descriptions have been omitted due to space constraints.
Below: A few domain- and language-specific elaborations of the general guidelines.
</figureCaption>
<page confidence="0.994777">
255
</page>
<figureCaption confidence="0.83779875">
Figure 3: Distribution of supersense mentions by
domain (left), and counts for tags occurring over
800 times (below). (Counts are of the union of the
annotators’ choices, even when they disagree.)
</figureCaption>
<table confidence="0.999095">
tag num tag num
ACT (!) 3473 LOCATION (G) 1583
COMMUNICATION (C) 3007 GROUP (L) 1501
PERSON (P) 2650 TIME (T) 1407
ARTIFACT (A) 2164 SUBSTANCE ($) 1291
COGNITION (ˆ) 1672 QUANTITY (Q) 1022
</table>
<bodyText confidence="0.994006933333333">
Main annotation. After training, the two annota-
tors proceeded on a per-document basis: first they
worked together to annotate several sentences from
the beginning of the article, then each was inde-
pendently assigned about half of the remaining sen-
tences (typically with 5–10 shared to measure agree-
ment). Throughout the process, annotators were en-
couraged to discuss points of confusion with each
other, but each sentence was annotated in its entirety
and never revisited. Annotation of 28 articles re-
quired approximately 100 annotator-hours. Articles
used in pilot rounds were re-annotated from scratch.
Analysis. Figure 3 shows the distribution of SSTs in
the corpus. Some of the most concrete tags—BODY,
ANIMAL, PLANT, NATURAL OBJECT, and FOOD—
were barely present, but would likely be frequent
in life sciences domains. Others, such as MOTIVE,
POSSESSION, and SHAPE, are limited in scope.
To measure inter-annotator agreement, 87 sen-
tences (2,774 tokens) distributed across 19 of the ar-
ticles (not including those used in pilot rounds) were
annotated independently by each annotator. Inter-
annotator mention Fl (counting agreement over en-
tire mentions and their labels) was 70%. Excluding
the 1,397 tokens left blank by both annotators, the
token-level agreement rate was 71%, with Cohen’s
n = 0.69, and token-level Fl was 83%.7
We also measured agreement on a tag-by-tag ba-
sis. For 8 of the 10 most frequent SSTs (fig-
ure 3), inter-annotator mention Fl ranged from 73%
to 80%. The two exceptions were QUANTITY at
63%, and COGNITION (probably the most heteroge-
neous category) at 49%. An examination of the con-
fusion matrix reveals four pairs of supersense cate-
gories that tended to provoke the most disagreement:
COMMUNICATION/COGNITION, ACT/COGNITION,
ACT/PROCESS, and ARTIFACT/COMMUNICATION.
7Token-level measures consider both the supersense label
and whether it begins or continues the mention.
The last is exhibited for the first mention in figure 1,
where one annotator chose ARTIFACT (referring to
the physical book) while the other chose COMMU-
NICATION (the content). Also in that sentence, an-
notators disagreed on the second use of university
(ARTIFACT vs. GROUP). As with any sense anno-
tation effort, some disagreements due to legitimate
ambiguity and different interpretations of the tags—
especially the broadest ones—are unavoidable.
A “soft” agreement measure (counting as matches
any two mentions with the same label and at least
one token in common) gives an Fl of 79%, show-
ing that boundary decisions account for a major por-
tion of the disagreement. E.g., the city Fez, Mo-
rocco (figure 1) was tagged as a single LOCATION
by one annotator and as two by the other. Further
examples include the technical term ‘thin client’,
for which one annotator omitted the adjective; and
‘World Cup Football Championship’, where one an-
notator tagged the entire phrase as an EVENT while
the other tagged ‘football’ as a separate ACT.
</bodyText>
<sectionHeader confidence="0.997438" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999819875">
We have codified supersense tags as a simple an-
notation scheme for coarse lexical semantics, and
have shown that supersense annotation of Ara-
bic Wikipedia can be rapid, reliable, and robust
(about half the tokens in our data are covered
by a nominal supersense). Our tagging guide-
lines and corpus are available for download at
http://www.ark.cs.cmu.edu/ArabicSST/.
</bodyText>
<sectionHeader confidence="0.991715" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999968714285714">
We thank Nourhen Feki and Sarah Mustafa for assistance
with annotation, as well as Emad Mohamed, CMU ARK
members, and anonymous reviewers for their comments.
This publication was made possible by grant NPRP-08-
485-1-083 from the Qatar National Research Fund (a
member of the Qatar Foundation). The statements made
herein are solely the responsibility of the authors.
</bodyText>
<page confidence="0.997675">
256
</page>
<sectionHeader confidence="0.984655" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.962462355769231">
Giuseppe Attardi, Stefano Dei Rossi, Giulia Di Pietro,
Alessandro Lenci, Simonetta Montemagni, and Maria
Simi. 2010. A resource and tool for super-sense
tagging of Italian texts. In Nicoletta Calzolari,
Khalid Choukri, Bente Maegaard, Joseph Mariani,
Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel
Tapias, editors, Proceedings of the Seventh Interna-
tional Conference on Language Resources and Evalu-
ation (LREC’10), Valletta, Malta, May. European Lan-
guage Resources Association (ELRA).
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proceed-
ings of the 36th Annual Meeting of the Association
for Computational Linguistics and 17th International
Conference on Computational Linguistics (COLING-
ACL ’98), pages 86–90, Montreal, Quebec, Canada,
August. Association for Computational Linguistics.
D. M. Bikel, R. Schwartz, and R. M. Weischedel. 1999.
An algorithm that learns what’s in a name. Machine
Learning, 34(1).
Massimiliano Ciaramita and Yasemin Altun. 2006.
Broad-coverage sense disambiguation and information
extraction with a supersense sequence tagger. In Pro-
ceedings of the 2006 Conference on Empirical Meth-
ods in Natural Language Processing, pages 594–602,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
Massimiliano Ciaramita and Mark Johnson. 2003. Su-
persense tagging of unknown nouns in WordNet. In
Proceedings of the 2003 Conference on Empirical
Methods in Natural Language Processing, pages 168–
175, Sapporo, Japan, July.
James R. Curran. 2005. Supersense tagging of unknown
nouns using semantic similarity. In Proceedings of
the 43rd Annual Meeting on Association for Computa-
tional Linguistics (ACL’05), pages 26–33, Ann Arbor,
Michigan, June.
Bonnie J. Dorr, Rebecca J. Passonneau, David Farwell,
Rebecca Green, Nizar Habash, Stephen Helmreich,
Eduard Hovy, Lori Levin, Keith J. Miller, Teruko
Mitamura, Owen Rambow, and Advaith Siddharthan.
2010. Interlingual annotation of parallel text corpora:
a new framework for annotation and evaluation. Nat-
ural Language Engineering, 16(03):197–243.
Sabri Elkateb, William Black, Horacio Rodriguez, Musa
Alkhalifa, Piek Vossen, Adam Pease, and Christiane
Fellbaum. 2006. Building a WordNet for Arabic.
In Proceedings of The Fifth International Conference
on Language Resources and Evaluation (LREC 2006),
pages 29–34, Genoa, Italy.
Christiane Fellbaum. 1990. English verbs as a semantic
net. International Journal of Lexicography, 3(4):278–
301, December.
Christiane Fellbaum, editor. 1998. WordNet: an elec-
tronic lexical database. MIT Press, Cambridge, MA.
Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
Ramshaw, and Ralph Weischedel. 2006. OntoNotes:
the 90% solution. In Proceedings of the Human Lan-
guage Technology Conference of the NAACL (HLT-
NAACL), pages 57–60, New York City, USA, June.
Association for Computational Linguistics.
Paul Kingsbury and Martha Palmer. 2002. From Tree-
Bank to PropBank. In Proceedings of the Third In-
ternational Conference on Language Resources and
Evaluation (LREC-02), Las Palmas, Canary Islands,
May.
Xin Li and Dan Roth. 2002. Learning question classi-
fiers. In Proceedings of the 19th International Con-
ference on Computational Linguistics (COLING’02),
pages 1–7, Taipei, Taiwan, August. Association for
Computational Linguistics.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A semantic concordance. In
Proceedings of the Workshop on Human Language
Technology (HLT ’93), HLT ’93, pages 303–308,
Plainsboro, NJ, USA, March. Association for Compu-
tational Linguistics.
George A. Miller. 1990. Nouns in WordNet: a lexical
inheritance system. International Journal of Lexicog-
raphy, 3(4):245–264, December.
Behrang Mohit, Nathan Schneider, Rishav Bhowmick,
Kemal Oflazer, and Noah A. Smith. 2012.
Recall-oriented learning of named entities in Arabic
Wikipedia. In Proceedings of the 13th Conference of
the European Chapter of the Association for Computa-
tional Linguistics (EACL 2012), pages 162–173, Avi-
gnon, France, April. Association for Computational
Linguistics.
Gerhard Paaß and Frank Reichartz. 2009. Exploiting
semantic constraints for estimating supersenses with
CRFs. In Proceedings of the Ninth SIAM International
Conference on Data Mining, pages 485–496, Sparks,
Nevada, USA, May. Society for Industrial and Applied
Mathematics.
Rebecca J. Passonneau, Ansaf Salleb-Aoussi, Vikas
Bhardwaj, and Nancy Ide. 2010. Word sense anno-
tation of polysemous words by multiple annotators.
In Nicoletta Calzolari, Khalid Choukri, Bente Mae-
gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,
Mike Rosner, and Daniel Tapias, editors, Proceed-
ings of the Seventh International Conference on Lan-
guage Resources and Evaluation (LREC’10), Valletta,
Malta, May. European Language Resources Associa-
tion (ELRA).
</reference>
<page confidence="0.959217">
257
</page>
<reference confidence="0.99937443902439">
Andrew G. Philpot, Michael Fleischman, and Eduard H.
Hovy. 2003. Semi-automatic construction of a general
purpose ontology. In Proceedings of the International
Lisp Conference, New York, NY, USA, October.
Davide Picca, Alfio Massimiliano Gliozzo, and Mas-
similiano Ciaramita. 2008. Supersense Tagger
for Italian. In Nicoletta Calzolari, Khalid Choukri,
Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios
Piperidis, and Daniel Tapias, editors, Proceedings of
the Sixth International Language Resources and Eval-
uation (LREC’08), pages 2386–2390, Marrakech, Mo-
rocco, May. European Language Resources Associa-
tion (ELRA).
Davide Picca, Alfio Massimiliano Gliozzo, and Simone
Campora. 2009. Bridging languages by SuperSense
entity tagging. In Proceedings of the 2009 Named
Entities Workshop: Shared Task on Transliteration
(NEWS 2009), pages 136–142, Suntec, Singapore, Au-
gust. Association for Computational Linguistics.
Likun Qiu, Yunfang Wu, Yanqiu Shao, and Alexander
Gelbukh. 2011. Combining contextual and struc-
tural information for supersense tagging of Chinese
unknown words. In Computational Linguistics and In-
telligent Text Processing: Proceedings of the 12th In-
ternational Conference on Computational Linguistics
and Intelligent Text Processing (CICLing’11), volume
6608 of Lecture Notes in Computer Science, pages 15–
28. Springer, Berlin.
Satoshi Sekine, Kiyoshi Sudo, and Chikashi Nobata.
2002. Extended named entity hierarchy. In Proceed-
ings of the Third International Conference on Lan-
guage Resources and Evaluation (LREC-02), Las Pal-
mas, Canary Islands, May.
Annie Zaenen, Jean Carletta, Gregory Garretson, Joan
Bresnan, Andrew Koontz-Garboden, Tatiana Nikitina,
M. Catherine O’Connor, and Tom Wasow. 2004. An-
imacy encoding in English: why and how. In Bon-
nie Webber and Donna K. Byron, editors, ACL 2004
Workshop on Discourse Annotation, pages 118–125,
Barcelona, Spain, July. Association for Computational
Linguistics.
</reference>
<page confidence="0.996116">
258
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.702457">
<title confidence="0.901223">Coarse Lexical Semantic Annotation with An Arabic Case Study</title>
<author confidence="0.801432">Kemal Noah A</author>
<affiliation confidence="0.997796">School of Computer Science, Carnegie Mellon</affiliation>
<address confidence="0.965458">Qatar PA 15213,</address>
<abstract confidence="0.997584083333333">Lightweight” semantic annotation of text calls for a simple representation, ideally without requiring a semantic lexicon to achieve good coverage in the language and domain. this paper, we repurpose WordNet’s supertags annotation, developing specific guidelines for nominal expressions and applying them to Arabic Wikipedia articles in four topical domains. The resulting corpus has high coverage and was completed quickly with reasonable inter-annotator agreement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Giuseppe Attardi</author>
<author>Stefano Dei Rossi</author>
<author>Giulia Di Pietro</author>
<author>Alessandro Lenci</author>
<author>Simonetta Montemagni</author>
<author>Maria Simi</author>
</authors>
<title>A resource and tool for super-sense tagging of Italian texts.</title>
<date>2010</date>
<booktitle>Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10),</booktitle>
<editor>In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors,</editor>
<location>Valletta, Malta,</location>
<marker>Attardi, Rossi, Di Pietro, Lenci, Montemagni, Simi, 2010</marker>
<rawString>Giuseppe Attardi, Stefano Dei Rossi, Giulia Di Pietro, Alessandro Lenci, Simonetta Montemagni, and Maria Simi. 2010. A resource and tool for super-sense tagging of Italian texts. In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors, Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10), Valletta, Malta, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics (COLINGACL ’98),</booktitle>
<pages>86--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montreal, Quebec, Canada,</location>
<contexts>
<context position="1979" citStr="Baker et al., 1998" startWordPosition="274" endWordPosition="277"> or require prohibitive expertise and effort to apply.2 We therefore turn to supersense tags (SSTs), 40 coarse lexical semantic classes (25 for nouns, 15 for verbs) originating in WordNet. Previously these served as groupings of English lexicon 1Some ontologies like those in Sekine et al. (2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr et al., 2010). COMMUNICATION GROUP 859 ø XCJ Ó . AD ACT TIME ‘The Guinness Book of World Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics (COLINGACL ’98), pages 86–90, Montreal, Quebec, Canada, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Bikel</author>
<author>R Schwartz</author>
<author>R M Weischedel</author>
</authors>
<title>An algorithm that learns what’s in a name.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="1698" citStr="Bikel et al., 1999" startWordPosition="232" endWordPosition="235">annotation of Arabic Wikipedia articles subject to these constraints. Traditional lexical semantic representations are either narrow in scope, like named entities,1 or make reference to a full-fledged lexicon/ontology, which may insufficiently cover the language/domain of interest or require prohibitive expertise and effort to apply.2 We therefore turn to supersense tags (SSTs), 40 coarse lexical semantic classes (25 for nouns, 15 for verbs) originating in WordNet. Previously these served as groupings of English lexicon 1Some ontologies like those in Sekine et al. (2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr et al., 2010). COMMUNICATION GROUP 859 ø XC</context>
</contexts>
<marker>Bikel, Schwartz, Weischedel, 1999</marker>
<rawString>D. M. Bikel, R. Schwartz, and R. M. Weischedel. 1999. An algorithm that learns what’s in a name. Machine Learning, 34(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Yasemin Altun</author>
</authors>
<title>Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>594--602</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="3106" citStr="Ciaramita and Altun, 2006" startWordPosition="453" endWordPosition="456">gure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence in figure 1. SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand—e.g., 3Note that work in supersense tagging used t</context>
</contexts>
<marker>Ciaramita, Altun, 2006</marker>
<rawString>Massimiliano Ciaramita and Yasemin Altun. 2006. Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 594–602, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Mark Johnson</author>
</authors>
<title>Supersense tagging of unknown nouns in WordNet.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>168--175</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="3065" citStr="Ciaramita and Johnson, 2003" startWordPosition="447" endWordPosition="450">AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence in figure 1. SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand—e.g., 3No</context>
</contexts>
<marker>Ciaramita, Johnson, 2003</marker>
<rawString>Massimiliano Ciaramita and Mark Johnson. 2003. Supersense tagging of unknown nouns in WordNet. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, pages 168– 175, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
</authors>
<title>Supersense tagging of unknown nouns using semantic similarity.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL’05),</booktitle>
<pages>26--33</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="3079" citStr="Curran, 2005" startWordPosition="451" endWordPosition="452">the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence in figure 1. SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand—e.g., 3Note that work i</context>
</contexts>
<marker>Curran, 2005</marker>
<rawString>James R. Curran. 2005. Supersense tagging of unknown nouns using semantic similarity. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL’05), pages 26–33, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Rebecca J Passonneau</author>
<author>David Farwell</author>
<author>Rebecca Green</author>
<author>Nizar Habash</author>
<author>Stephen Helmreich</author>
<author>Eduard Hovy</author>
<author>Lori Levin</author>
<author>Keith J Miller</author>
<author>Teruko Mitamura</author>
<author>Owen Rambow</author>
<author>Advaith Siddharthan</author>
</authors>
<title>Interlingual annotation of parallel text corpora: a new framework for annotation and evaluation.</title>
<date>2010</date>
<journal>Natural Language Engineering,</journal>
<volume>16</volume>
<issue>03</issue>
<contexts>
<context position="2268" citStr="Dorr et al., 2010" startWordPosition="322" endWordPosition="325">(2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr et al., 2010). COMMUNICATION GROUP 859 ø XCJ Ó . AD ACT TIME ‘The Guinness Book of World Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun </context>
</contexts>
<marker>Dorr, Passonneau, Farwell, Green, Habash, Helmreich, Hovy, Levin, Miller, Mitamura, Rambow, Siddharthan, 2010</marker>
<rawString>Bonnie J. Dorr, Rebecca J. Passonneau, David Farwell, Rebecca Green, Nizar Habash, Stephen Helmreich, Eduard Hovy, Lori Levin, Keith J. Miller, Teruko Mitamura, Owen Rambow, and Advaith Siddharthan. 2010. Interlingual annotation of parallel text corpora: a new framework for annotation and evaluation. Natural Language Engineering, 16(03):197–243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabri Elkateb</author>
<author>William Black</author>
<author>Horacio Rodriguez</author>
<author>Musa Alkhalifa</author>
<author>Piek Vossen</author>
<author>Adam Pease</author>
<author>Christiane Fellbaum</author>
</authors>
<title>Building a WordNet for Arabic.</title>
<date>2006</date>
<booktitle>In Proceedings of The Fifth International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>29--34</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="9137" citStr="Elkateb et al., 2006" startWordPosition="1403" endWordPosition="1406">onventions were developed collaboratively by the author(s) and annotators during this period, informed by points of confusion and disagreement. WordNet and SemCor were consulted as part of developing the guidelines, but not during annotation itself so as to avoid complicating the annotation process or overfitting to WordNet’s idiosyncracies. The training phase ended once interannotator mention FI had reached 75%. 6Suggestions came from the previous named entity annotation of PERSONs, organizations (GROUP), and LOCATIONs, as well as heuristic lookup in lexical resources—Arabic WordNet entries (Elkateb et al., 2006) mapped to English WordNet, and named entities in OntoNotes (Hovy et al., 2006). 254 O NATURAL OBJECT natural feature or nonliving object in nature barrier reef nest neutron star planet sky fishpond metamorphic rock Mediterranean cave stepping stone boulder Orion ember universe A ARTIFACT man-made structures and objects bridge restaurant bedroom stage cabinet toaster antidote aspirin L LOCATION any name of a geopolitical entity, as well as other nouns functioning as locations or regions Cote d’Ivoire New York City downtown stage left India Newark interior airspace P PERSON humans or personifie</context>
</contexts>
<marker>Elkateb, Black, Rodriguez, Alkhalifa, Vossen, Pease, Fellbaum, 2006</marker>
<rawString>Sabri Elkateb, William Black, Horacio Rodriguez, Musa Alkhalifa, Piek Vossen, Adam Pease, and Christiane Fellbaum. 2006. Building a WordNet for Arabic. In Proceedings of The Fifth International Conference on Language Resources and Evaluation (LREC 2006), pages 29–34, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>English verbs as a semantic net.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<pages>301</pages>
<contexts>
<context position="2955" citStr="Fellbaum, 1990" startWordPosition="432" endWordPosition="433">rld Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence i</context>
</contexts>
<marker>Fellbaum, 1990</marker>
<rawString>Christiane Fellbaum. 1990. English verbs as a semantic net. International Journal of Lexicography, 3(4):278– 301, December.</rawString>
</citation>
<citation valid="true">
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: an electronic lexical database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: the 90% solution.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL (HLTNAACL),</booktitle>
<pages>57--60</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="2248" citStr="Hovy et al., 2006" startWordPosition="318" endWordPosition="321">e in Sekine et al. (2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr et al., 2010). COMMUNICATION GROUP 859 ø XCJ Ó . AD ACT TIME ‘The Guinness Book of World Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partiti</context>
<context position="9216" citStr="Hovy et al., 2006" startWordPosition="1416" endWordPosition="1419">his period, informed by points of confusion and disagreement. WordNet and SemCor were consulted as part of developing the guidelines, but not during annotation itself so as to avoid complicating the annotation process or overfitting to WordNet’s idiosyncracies. The training phase ended once interannotator mention FI had reached 75%. 6Suggestions came from the previous named entity annotation of PERSONs, organizations (GROUP), and LOCATIONs, as well as heuristic lookup in lexical resources—Arabic WordNet entries (Elkateb et al., 2006) mapped to English WordNet, and named entities in OntoNotes (Hovy et al., 2006). 254 O NATURAL OBJECT natural feature or nonliving object in nature barrier reef nest neutron star planet sky fishpond metamorphic rock Mediterranean cave stepping stone boulder Orion ember universe A ARTIFACT man-made structures and objects bridge restaurant bedroom stage cabinet toaster antidote aspirin L LOCATION any name of a geopolitical entity, as well as other nouns functioning as locations or regions Cote d’Ivoire New York City downtown stage left India Newark interior airspace P PERSON humans or personified beings; names of social groups (ethnic, political, etc.) that can refer to an</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: the 90% solution. In Proceedings of the Human Language Technology Conference of the NAACL (HLTNAACL), pages 57–60, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>From TreeBank to PropBank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-02),</booktitle>
<location>Las Palmas, Canary Islands,</location>
<contexts>
<context position="2063" citStr="Kingsbury and Palmer, 2002" startWordPosition="288" endWordPosition="291"> supersense tags (SSTs), 40 coarse lexical semantic classes (25 for nouns, 15 for verbs) originating in WordNet. Previously these served as groupings of English lexicon 1Some ontologies like those in Sekine et al. (2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr et al., 2010). COMMUNICATION GROUP 859 ø XCJ Ó . AD ACT TIME ‘The Guinness Book of World Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurpo</context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2002. From TreeBank to PropBank. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-02), Las Palmas, Canary Islands, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Li</author>
<author>Dan Roth</author>
</authors>
<title>Learning question classifiers.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02),</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="6014" citStr="Li and Roth, 2002" startWordPosition="934" endWordPosition="937">SONs. This lumping property might be expected to give too much latitude to annotators; yet we find that in practice, it is possible to elicit reasonable inter-annotator agreement, even for a language other than English. We encapsulate our interpretation of the tags in a set of brief guidelines that aims to be usable by anyone who can read and understand a text in the target language; our annotators had no prior expertise in linguistics or linguistic annotation. Finally, we note that ad hoc categorization schemes not unlike SSTs have been developed for purposes ranging from question answering (Li and Roth, 2002) to animacy hierarchy representation for corpus linguistics (Zaenen et al., 2004). We believe the interpretation of the SSTs adopted here can serve as a single starting point for diverse resource engineering efforts and applications, especially when fine-grained sense annotation is not feasible. 2 Tagging Conventions WordNet’s definitions of the supersenses are terse, and we could find little explicit discussion of the specific rationales behind each category. Thus, we have crafted more specific explanations, summarized for nouns in figure 2. English examples are given, but the guidelines are </context>
</contexts>
<marker>Li, Roth, 2002</marker>
<rawString>Xin Li and Dan Roth. 2002. Learning question classifiers. In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02), pages 1–7, Taipei, Taiwan, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross T Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology (HLT ’93), HLT ’93,</booktitle>
<pages>303--308</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Plainsboro, NJ, USA,</location>
<contexts>
<context position="6854" citStr="Miller et al., 1993" startWordPosition="1058" endWordPosition="1061">applications, especially when fine-grained sense annotation is not feasible. 2 Tagging Conventions WordNet’s definitions of the supersenses are terse, and we could find little explicit discussion of the specific rationales behind each category. Thus, we have crafted more specific explanations, summarized for nouns in figure 2. English examples are given, but the guidelines are intended to be language-neutral. A more systematic breakdown, formulated as a 43-rule decision list, is included with the corpus.5 In developing these guidelines we consulted English WordNet (Fellbaum, 1998) and SemCor (Miller et al., 1993) for examples and synset definitions, occasionally making simplifying decisions where we found distinctions that seemed esoteric or internally inconsistent. Special cases (e.g., multiword expressions, anaphora, figurative 5For example, one rule states that all man-made structures (buildings, rooms, bridges, etc.) are to be tagged as ARTIFACTs. language) are addressed with additional rules. 3 Arabic Wikipedia Annotation The annotation in this work was on top of a small corpus of Arabic Wikipedia articles that had already been annotated for named entities (Mohit et al., 2012). Here we use two di</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A semantic concordance. In Proceedings of the Workshop on Human Language Technology (HLT ’93), HLT ’93, pages 303–308, Plainsboro, NJ, USA, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Nouns in WordNet: a lexical inheritance system.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="2938" citStr="Miller, 1990" startWordPosition="430" endWordPosition="431">ess Book of World Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an </context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>George A. Miller. 1990. Nouns in WordNet: a lexical inheritance system. International Journal of Lexicography, 3(4):245–264, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Mohit</author>
<author>Nathan Schneider</author>
<author>Rishav Bhowmick</author>
<author>Kemal Oflazer</author>
<author>Noah A Smith</author>
</authors>
<title>Recall-oriented learning of named entities in Arabic Wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2012),</booktitle>
<pages>162--173</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Avignon, France,</location>
<contexts>
<context position="7434" citStr="Mohit et al., 2012" startWordPosition="1142" endWordPosition="1145"> 1998) and SemCor (Miller et al., 1993) for examples and synset definitions, occasionally making simplifying decisions where we found distinctions that seemed esoteric or internally inconsistent. Special cases (e.g., multiword expressions, anaphora, figurative 5For example, one rule states that all man-made structures (buildings, rooms, bridges, etc.) are to be tagged as ARTIFACTs. language) are addressed with additional rules. 3 Arabic Wikipedia Annotation The annotation in this work was on top of a small corpus of Arabic Wikipedia articles that had already been annotated for named entities (Mohit et al., 2012). Here we use two different annotators, both native speakers of Arabic attending a university with English as the language of instruction. Data &amp; procedure. The dataset (table 1) consists of the main text of 28 articles selected from the topical domains of history, sports, science, and technology. The annotation task was to identify and categorize mentions, i.e., occurrences of terms belonging to noun supersenses. Working in a custom, browserbased interface, annotators were to tag each relevant token with a supersense category by selecting the token and typing a tag symbol. Any token could be </context>
</contexts>
<marker>Mohit, Schneider, Bhowmick, Oflazer, Smith, 2012</marker>
<rawString>Behrang Mohit, Nathan Schneider, Rishav Bhowmick, Kemal Oflazer, and Noah A. Smith. 2012. Recall-oriented learning of named entities in Arabic Wikipedia. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2012), pages 162–173, Avignon, France, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Paaß</author>
<author>Frank Reichartz</author>
</authors>
<title>Exploiting semantic constraints for estimating supersenses with CRFs.</title>
<date>2009</date>
<journal>Society for Industrial and Applied Mathematics.</journal>
<booktitle>In Proceedings of the Ninth SIAM International Conference on Data Mining,</booktitle>
<pages>485--496</pages>
<location>Sparks, Nevada, USA,</location>
<contexts>
<context position="3133" citStr="Paaß and Reichartz, 2009" startWordPosition="457" endWordPosition="460"> article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence in figure 1. SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand—e.g., 3Note that work in supersense tagging used text with finegrained sense </context>
</contexts>
<marker>Paaß, Reichartz, 2009</marker>
<rawString>Gerhard Paaß and Frank Reichartz. 2009. Exploiting semantic constraints for estimating supersenses with CRFs. In Proceedings of the Ninth SIAM International Conference on Data Mining, pages 485–496, Sparks, Nevada, USA, May. Society for Industrial and Applied Mathematics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Rebecca J Passonneau</author>
<author>Ansaf Salleb-Aoussi</author>
<author>Vikas Bhardwaj</author>
<author>Nancy Ide</author>
</authors>
<title>Word sense annotation of polysemous words by multiple annotators.</title>
<date>2010</date>
<booktitle>Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10),</booktitle>
<editor>In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors,</editor>
<location>Valletta, Malta,</location>
<contexts>
<context position="1885" citStr="Passonneau et al. (2010)" startWordPosition="261" endWordPosition="264"> to a full-fledged lexicon/ontology, which may insufficiently cover the language/domain of interest or require prohibitive expertise and effort to apply.2 We therefore turn to supersense tags (SSTs), 40 coarse lexical semantic classes (25 for nouns, 15 for verbs) originating in WordNet. Previously these served as groupings of English lexicon 1Some ontologies like those in Sekine et al. (2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr et al., 2010). COMMUNICATION GROUP 859 ø XCJ Ó . AD ACT TIME ‘The Guinness Book of World Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure</context>
</contexts>
<marker>Passonneau, Salleb-Aoussi, Bhardwaj, Ide, 2010</marker>
<rawString>Rebecca J. Passonneau, Ansaf Salleb-Aoussi, Vikas Bhardwaj, and Nancy Ide. 2010. Word sense annotation of polysemous words by multiple annotators. In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike Rosner, and Daniel Tapias, editors, Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10), Valletta, Malta, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew G Philpot</author>
<author>Michael Fleischman</author>
<author>Eduard H Hovy</author>
</authors>
<title>Semi-automatic construction of a general purpose ontology.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Lisp Conference,</booktitle>
<location>New York, NY, USA,</location>
<contexts>
<context position="2174" citStr="Philpot et al., 2003" startWordPosition="306" endWordPosition="309">iously these served as groupings of English lexicon 1Some ontologies like those in Sekine et al. (2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr et al., 2010). COMMUNICATION GROUP 859 ø XCJ Ó . AD ACT TIME ‘The Guinness Book of World Records considers the University of Al-Karaouine in Fez, Morocco, established in the year 859 AD, the oldest university in the world.’ Figure 1: A sentence from the article “Islamic Golden Age,” with the supersense tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense</context>
</contexts>
<marker>Philpot, Fleischman, Hovy, 2003</marker>
<rawString>Andrew G. Philpot, Michael Fleischman, and Eduard H. Hovy. 2003. Semi-automatic construction of a general purpose ontology. In Proceedings of the International Lisp Conference, New York, NY, USA, October.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Davide Picca</author>
<author>Alfio Massimiliano Gliozzo</author>
<author>Massimiliano Ciaramita</author>
</authors>
<title>Supersense Tagger for Italian.</title>
<date>2008</date>
<booktitle>Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<pages>2386--2390</pages>
<editor>In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios Piperidis, and Daniel Tapias, editors,</editor>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="3177" citStr="Picca et al., 2008" startWordPosition="466" endWordPosition="469">tagging from one of two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence in figure 1. SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand—e.g., 3Note that work in supersense tagging used text with finegrained sense annotations that were then coarsened to SSTs</context>
</contexts>
<marker>Picca, Gliozzo, Ciaramita, 2008</marker>
<rawString>Davide Picca, Alfio Massimiliano Gliozzo, and Massimiliano Ciaramita. 2008. Supersense Tagger for Italian. In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios Piperidis, and Daniel Tapias, editors, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), pages 2386–2390, Marrakech, Morocco, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Davide Picca</author>
<author>Alfio Massimiliano Gliozzo</author>
<author>Simone Campora</author>
</authors>
<title>Bridging languages by SuperSense entity tagging.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009),</booktitle>
<pages>136--142</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="3197" citStr="Picca et al., 2009" startWordPosition="470" endWordPosition="473">two annotators. The Arabic is shown left-to-right. entries, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence in figure 1. SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand—e.g., 3Note that work in supersense tagging used text with finegrained sense annotations that were then coarsened to SSTs. 4The noun/verb dis</context>
</contexts>
<marker>Picca, Gliozzo, Campora, 2009</marker>
<rawString>Davide Picca, Alfio Massimiliano Gliozzo, and Simone Campora. 2009. Bridging languages by SuperSense entity tagging. In Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009), pages 136–142, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Likun Qiu</author>
<author>Yunfang Wu</author>
<author>Yanqiu Shao</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Combining contextual and structural information for supersense tagging of Chinese unknown words.</title>
<date>2011</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing: Proceedings of the 12th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing’11),</booktitle>
<volume>6608</volume>
<pages>15--28</pages>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="3251" citStr="Qiu et al., 2011" startWordPosition="480" endWordPosition="483">ies, but here we have repurposed them as target labels for direct human annotation. Part of the earliest versions of WordNet, the supersense categories (originally, “lexicographer classes”) were intended to partition all English noun and verb senses into broad groupings, or semantic fields (Miller, 1990; Fellbaum, 1990). More recently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; Paaß and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNets mapped to English WordNet.3 In principle, we believe supersenses ought to apply to nouns and verbs in any language, and need not depend on the availability of a semantic lexicon.4 In this work we focus on the noun SSTs, summarized in figure 2 and applied to an Arabic sentence in figure 1. SSTs both refine and relate lexical items: they capture lexical polysemy on the one hand—e.g., 3Note that work in supersense tagging used text with finegrained sense annotations that were then coarsened to SSTs. 4The noun/verb distinction might prove problematic in some languages. Q�</context>
</contexts>
<marker>Qiu, Wu, Shao, Gelbukh, 2011</marker>
<rawString>Likun Qiu, Yunfang Wu, Yanqiu Shao, and Alexander Gelbukh. 2011. Combining contextual and structural information for supersense tagging of Chinese unknown words. In Computational Linguistics and Intelligent Text Processing: Proceedings of the 12th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing’11), volume 6608 of Lecture Notes in Computer Science, pages 15– 28. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
<author>Kiyoshi Sudo</author>
<author>Chikashi Nobata</author>
</authors>
<title>Extended named entity hierarchy.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-02),</booktitle>
<location>Las Palmas, Canary Islands,</location>
<contexts>
<context position="1656" citStr="Sekine et al. (2002)" startWordPosition="225" endWordPosition="228">is paper describes coarse lexical semantic annotation of Arabic Wikipedia articles subject to these constraints. Traditional lexical semantic representations are either narrow in scope, like named entities,1 or make reference to a full-fledged lexicon/ontology, which may insufficiently cover the language/domain of interest or require prohibitive expertise and effort to apply.2 We therefore turn to supersense tags (SSTs), 40 coarse lexical semantic classes (25 for nouns, 15 for verbs) originating in WordNet. Previously these served as groupings of English lexicon 1Some ontologies like those in Sekine et al. (2002) and BBN Identifinder (Bikel et al., 1999) include a large selection of classes, which tend to be especially relevant to proper names. 2E.g., a WordNet (Fellbaum, 1998) sense annotation effort reported by Passonneau et al. (2010) found considerable interannotator variability for some lexemes; FrameNet (Baker et al., 1998) is limited in coverage, even for English; and PropBank (Kingsbury and Palmer, 2002) does not capture semantic relationships across lexemes. We note that the Omega ontology (Philpot et al., 2003) has been used for fine-grained crosslingual annotation (Hovy et al., 2006; Dorr e</context>
</contexts>
<marker>Sekine, Sudo, Nobata, 2002</marker>
<rawString>Satoshi Sekine, Kiyoshi Sudo, and Chikashi Nobata. 2002. Extended named entity hierarchy. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-02), Las Palmas, Canary Islands, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wasow</author>
</authors>
<title>Animacy encoding in English: why and how.</title>
<date>2004</date>
<booktitle>ACL 2004 Workshop on Discourse Annotation,</booktitle>
<pages>118--125</pages>
<editor>Annie Zaenen, Jean Carletta, Gregory Garretson, Joan Bresnan, Andrew Koontz-Garboden, Tatiana Nikitina, M. Catherine O’Connor, and Tom</editor>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<marker>Wasow, 2004</marker>
<rawString>Annie Zaenen, Jean Carletta, Gregory Garretson, Joan Bresnan, Andrew Koontz-Garboden, Tatiana Nikitina, M. Catherine O’Connor, and Tom Wasow. 2004. Animacy encoding in English: why and how. In Bonnie Webber and Donna K. Byron, editors, ACL 2004 Workshop on Discourse Annotation, pages 118–125, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>