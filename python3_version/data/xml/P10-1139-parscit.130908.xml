<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.998611">
A Unified Graph Model for Sentence-based Opinion Retrieval
</title>
<author confidence="0.999664">
Binyang Li, Lanjun Zhou, Shi Feng, Kam-Fai Wong
</author>
<affiliation confidence="0.99654">
Department of Systems Engineering and Engineering Management
The Chinese University of Hong Kong
</affiliation>
<email confidence="0.991532">
{byli, ljzhou, sfeng, kfwong}@se.cuhk.edu.hk
</email>
<sectionHeader confidence="0.993728" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99993115625">
There is a growing research interest in opinion
retrieval as on-line users’ opinions are becom-
ing more and more popular in business, social
networks, etc. Practically speaking, the goal of
opinion retrieval is to retrieve documents,
which entail opinions or comments, relevant to
a target subject specified by the user’s query. A
fundamental challenge in opinion retrieval is
information representation. Existing research
focuses on document-based approaches and
documents are represented by bag-of-word.
However, due to loss of contextual information,
this representation fails to capture the associa-
tive information between an opinion and its
corresponding target. It cannot distinguish dif-
ferent degrees of a sentiment word when asso-
ciated with different targets. This in turn se-
riously affects opinion retrieval performance.
In this paper, we propose a sentence-based ap-
proach based on a new information representa-
tion, namely topic-sentiment word pair, to cap-
ture intra-sentence contextual information be-
tween an opinion and its target. Additionally,
we consider inter-sentence information to cap-
ture the relationships among the opinions on
the same topic. Finally, the two types of infor-
mation are combined in a unified graph-based
model, which can effectively rank the docu-
ments. Compared with existing approaches,
experimental results on the COAE08 dataset
showed that our graph-based model achieved
significant improvement.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999968306122449">
In recent years, there is a growing interest in
sharing personal opinions on the Web, such as
product reviews, economic analysis, political
polls, etc. These opinions cannot only help inde-
pendent users make decisions, but also obtain
valuable feedbacks (Pang et al., 2008). Opinion
oriented research, including sentiment classifica-
tion, opinion extraction, opinion question ans-
wering, and opinion summarization, etc. are re-
ceiving growing attention (Wilson, et al., 2005;
Liu et al., 2005; Oard et al., 2006). However,
most existing works concentrate on analyzing
opinions expressed in the documents, and none
on how to represent the information needs re-
quired to retrieve opinionated documents. In this
paper, we focus on opinion retrieval, whose goal
is to find a set of documents containing not only
the query keyword(s) but also the relevant opi-
nions. This requirement brings about the chal-
lenge on how to represent information needs for
effective opinion retrieval.
In order to solve the above problem, previous
work adopts a 2-stage approach. In the first stage,
relevant documents are determined and ranked
by a score, i.e. tf-idf value. In the second stage,
an opinion score is generated for each relevant
document (Macdonald and Ounis, 2007; Oard et
al., 2006). The opinion score can be acquired by
either machine learning-based sentiment classifi-
ers, such as SVM (Zhang and Yu, 2007), or a
sentiment lexicons with weighted scores from
training documents (Amati et al., 2007; Hannah
et al., 2007; Na et al., 2009). Finally, an overall
score combining the two is computed by using a
score function, e.g. linear combination, to re-rank
the retrieved documents.
Retrieval in the 2-stage approach is based on
document and document is represented by
bag-of-word. This representation, however, can
only ensure that there is at least one opinion in
each relevant document, but it cannot determine
the relevance pairing of individual opinion to its
target. In general, by simply representing a
document in bag-of-word, contextual informa-
tion i.e. the corresponding target of an opinion, is
neglected. This may result in possible mismatch
between an opinion and a target and in turn af-
fects opinion retrieval performance. By the same
token, the effect to documents consisting of mul-
</bodyText>
<page confidence="0.948552">
1367
</page>
<note confidence="0.942556">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1367–1375,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999893157894737">
tiple topics, which is common in blogs and
on-line reviews, is also significant. In this setting,
even if a document is regarded opinionated, it
cannot ensure that all opinions in the document
are indeed relevant to the target concerned.
Therefore, we argue that existing information
representation i.e. bag-of-word, cannot satisfy
the information needs for opinion retrieval.
In this paper, we propose to handle opinion re-
trieval in the granularity of sentence. It is ob-
served that a complete opinion is always ex-
pressed in one sentence, and the relevant target
of the opinion is mostly the one found in it.
Therefore, it is crucial to maintain the associative
information between an opinion and its target
within a sentence. We define the notion of a top-
ic-sentiment word pair, which is composed of a
topic term (i.e. the target) and a sentiment word
(i.e. opinion) of a sentence. Word pairs can
maintain intra-sentence contextual information to
express the potential relevant opinions. In addi-
tion, inter-sentence contextual information is also
captured by word pairs to represent the relation-
ship among opinions on the same topic. In prac-
tice, the inter-sentence information reflects the
degree of a word pair. Finally, we combine both
intra-sentence and inter-sentence contextual in-
formation to construct a unified undirected graph
to achieve effective opinion retrieval.
The rest of the paper is organized as follows.
In Section 2, we describe the motivation of our
approach. Section 3 presents a novel unified
graph-based model for opinion retrieval. We
evaluated our model and the results are presented
in Section 4. We review related works on opi-
nion retrieval in Section 5. Finally, in Section 6,
the paper is concluded and future work is sug-
gested.
</bodyText>
<sectionHeader confidence="0.975908" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999511">
In this section, we start from briefly describing
the objective of opinion retrieval. We then illu-
strate the limitations of current opinion retrieval
approaches, and analyze the motivation of our
method.
</bodyText>
<subsectionHeader confidence="0.902744">
2.1 Formal Description of Problem
</subsectionHeader>
<bodyText confidence="0.999952785714286">
Opinion retrieval was first presented in the
TREC 2006 Blog track, and the objective is to
retrieve documents that express an opinion about
a given target. The opinion target can be a “tradi-
tional” named entity (e.g. a name of person, lo-
cation, or organization, etc.), a concept (e.g. a
type of technology), or an event (e.g. presidential
election). The topic of the document is not re-
quired to be the same as the target, but an opi-
nion about the target has to be presented in the
document or one of the comments to the docu-
ment (Macdonald and Ounis, 2006). Therefore,
in this paper we regard the information needs for
opinion retrieval as relevant opinion.
</bodyText>
<subsectionHeader confidence="0.999912">
2.2 Motivation of Our Approach
</subsectionHeader>
<bodyText confidence="0.999975476190476">
In traditional information retrieval (IR)
bag-of-word representation is the most common
way to express information needs. However, in
opinion retrieval, information need target at re-
levant opinion, and this renders bag-of-word re-
presentation ineffective.
Consider the example in Figure 1. There are
three sentences A, B, and C in a document di.
Now given an opinion-oriented query Q related
to ‘Avatar’. According to the conventional
2-stage opinion retrieval approach, di is
represented by a bag-of-word. Among the words,
there is a topic term Avatar (t1) occurring twice,
i.e. Avatar in A and Avatar in C, and two senti-
ment words comfortable (o1) and favorite (o2)
(refer to Figure 2 (a)). In order to rank this doc-
ument, an overall score of the document di is
computed by a simple combination of the rele-
vant score ( Scorerel ) and the opinion score
(Scoreop), e.g. equal weighted linear combination,
as follows.
</bodyText>
<equation confidence="0.411976">
Scoredoc = Scorerel + Scoreop
</equation>
<bodyText confidence="0.9145615">
For simplicity, we let Scorerel = tfQ X idfQ, and
Scoreop be computed by using lexicon-based
</bodyText>
<figure confidence="0.812190714285714">
method: Scoreop = Weigℎtcomfortable + Weigℎtfavorite.
A. PP ),t9H*rtrPQI--11qo
Tomorrow, Avatar will be shown in China.
B. RfATYJ_TIMAXWrArPJk fAKnftfo
I’ve reserved a comfortable seat in IMAX.
C. PP ),tARJk—!XXn— R 3D F,Wo
Avatar is my favorite 3D movie.
</figure>
<figureCaption confidence="0.9649">
Figure 1: A retrieved document di on the target
‘Avatar’.
</figureCaption>
<bodyText confidence="0.980688666666667">
Although bag-of-word representation achieves
good performance in retrieving relevant docu-
ments, our study shows that it cannot satisfy the
information needs for retrieval of relevant opi-
nion. It suffers from the following limitations:
(1) It cannot maintain contextual information;
thus, an opinion may not be related to the target
of the retrieved document is neglected. In this
example, only the opinion favorite (o2) on Avatar
in C is the relevant opinion. But due to loss of
contextual information between the opinion and
its corresponding target, Avatar in A and com-
</bodyText>
<page confidence="0.988201">
1368
</page>
<bodyText confidence="0.999231666666667">
fortable (o1) are also regarded as relevant opi-
nion mistakenly, creating a false positive. In re-
ality comfortable (o1) describes “the seats in
IMAX”, which is an irrelevant opinion, and sen-
tence A is a factual statement rather than an opi-
nion statement.
</bodyText>
<figure confidence="0.98506">
(a) (b)
</figure>
<figureCaption confidence="0.835701666666667">
Figure 2: Two kinds of information representa-
tion of opinion retrieval. (t1=‘Avatar’ o1= ‘com-
fortable’, o2=‘favorite’)
</figureCaption>
<bodyText confidence="0.972392407407407">
(1) Current approaches cannot capture the re-
lationship among opinions about the same topic.
Suppose there is another document including
sentence C which expresses the same opinion on
Avatar. Existing information representation
simply does not cater for the two identical opi-
nions from different documents. In addition, if
many documents contain opinions on Avatar, the
relationship among them is not clearly
represented by existing approaches.
In this paper, we process opinion retrieval in
the granularity of sentence as we observe that a
complete opinion always exists within a sentence
(refer to Figure 2 (b)). To represent a relevant
opinion, we define the notion of topic-sentiment
word pair, which consists of a topic term and a
sentiment word. A word pair maintains the asso-
ciative information between the two words, and
enables systems to draw up the relationship
among all the sentences with the same opinion
on an identical target. This relationship informa-
tion can identify all documents with sentences
including the sentiment words and to determine
the contributions of such words to the target
(topic term). Furthermore, based on word pairs,
we designed a unified graph-based method for
opinion retrieval (see later in Section 3).
</bodyText>
<sectionHeader confidence="0.999331" genericHeader="method">
3 Graph-based model
</sectionHeader>
<subsectionHeader confidence="0.998331">
3.1 Basic Idea
</subsectionHeader>
<bodyText confidence="0.999353620689655">
Different from existing approaches which simply
make use of document relevance to reflect the
relevance of opinions embedded in them, our
approach concerns more on identifying the re-
levance of individual opinions. Intuitively, we
believed that the more relevant opinions appear
in a document, the more relevant is that docu-
ment for subsequent opinion analysis operations.
Further, since the lexical scope of an opinion
does not usually go beyond a sentence, we pro-
pose to handle opinion retrieval in the granularity
of sentence.
Without loss of generality, we assume that
there is a document set D = {dl, dZ, d3, •••, dj, and
a specific query Q = {ql, qZ, q3, ••• , qZ} , where
ql, qz, q3, ••• , qZ are query keywords. Opinion re-
trieval aims at retrieving documents from D
with relevant opinion about the query Q. In ad-
dition, we construct a sentiment word lexicon vo
and a topic term lexicon vt (see Section 4). To
maintain the associative information between the
target and the opinion, we consider the document
set as a bag of sentences, and define a sentence
set as S = {sl,s2,s3,•••,sN}. For each sentence, we
capture the intra-sentence information through
the topic-sentiment word pair.
Definition 1. topic-sentiment word pair pij con-
sists of two elements, one is from vt, and the
other one is from vo.
</bodyText>
<equation confidence="0.821601">
pij = {&lt; ti, Oj &gt; |ti E vt , Oj E vA.
</equation>
<bodyText confidence="0.999994235294118">
The topic term from vt determines relevance
by the query term matching, and the sentiment
word from vo is used to express an opinion. We
use the word pair to maintain the associative in-
formation between the topic term and the opinion
word (also referred to as sentiment word). The
word pair is used to identify a relevant opinion in
a sentence. In Figure 2 (b), t1, i.e. Avatar in C, is
a topic term relevant to the query, and o2 (‘favo-
rite’) is supposed to be an opinion; and the word
pair &lt; t1, o2&gt; indicates sentence C contains a re-
levant opinion. Similarly, we map each sentence
in word pairs by the following rule, and express
the intra-sentence information using word pairs.
For each sentiment word of a sentence, we
choose the topic term with minimum distance as
the other element of the word pair:
</bodyText>
<equation confidence="0.716749">
s1 -4 {&lt; ti, Oj &gt; |ti = minDist(ti, Oj) for each Oj}
</equation>
<bodyText confidence="0.999919214285714">
According to the mapping rule, although a
sentence may give rise to a number of word pairs,
only the pair with the minimum word distance is
selected. We do not take into consideration of the
other words in a sentence as relevant opinions
are generally formed in close proximity. A sen-
tence is regarded non-opinionated unless it con-
tains at least one word pair.
In practice, not all word pairs carry equal
weights to express a relevant opinion as the con-
tribution of an opinion word differs from differ-
ent target topics, and vice versa. For example,
the word pair &lt; t1, o2&gt; should be more probable
as a relevant opinion than &lt; t1, o1&gt;. To consider
</bodyText>
<page confidence="0.976595">
1369
</page>
<bodyText confidence="0.999975833333333">
that, inter-sentence contextual information is ex-
plored. This is achieved by assigning a weight to
each word pair to measure their associative de-
grees to different queries. We believe that the
more a word pair appears the higher should be
the weight between the opinion and the target in
the context.
We will describe how to utilize intra-sentence
contextual information to express relevant opi-
nion, and inter-sentence information to measure
the degree of each word pair through a
graph-based model in the following section.
</bodyText>
<subsectionHeader confidence="0.887637">
3.2 HITS Model
</subsectionHeader>
<bodyText confidence="0.984679444444444">
We propose an opinion retrieval model based on
HITS, a popular graph ranking algorithm
(Kleinberg, 1999). By considering both in-
tra-sentence information and inter-sentence in-
formation, we can determine the weight of a
word pair and rank the documents.
HITS algorithm distinguishes hubs and au-
thorities in objects. A hub object has links to
many authorities. An authority object, which has
high-quality content, would have many hubs
linking to it. The hub scores and authority scores
are computed in an iterative way. Our proposed
opinion retrieval model contains two layers. The
upper level contains all the topic-sentiment word
pairs ݌௜௝ ൌ ൛൏ ݐ௜, ݋௝ ൐ |ݐ௜ א ܸ௧, ݋௝ א ܸ௢ሻൟ . The lower
level contains all the documents to be retrieved.
Figure 3 gives the bipartite graph representation
of the HITS model.
</bodyText>
<figureCaption confidence="0.963231">
Figure 3: Bipartite link graph.
</figureCaption>
<bodyText confidence="0.999902958333333">
For our purpose, the word pairs layer is consi-
dered as hubs and the documents layer authori-
ties. If a word pair occurs in one sentence of a
document, there will be an edge between them.
In Figure 3, we can see that the word pair that
has links to many documents can be assigned a
high weight to denote a strong associative degree
between the topic term and a sentiment word,
and it likely expresses a relevant opinion. On the
other hand, if a document has links to many word
pairs, the document is with many relevant opi-
nions, and it will result in high ranking.
Formally, the representation for the bipartite
graph is denoted as ܩ ൌ൏ ܪ௣, ܣௗ, ܧௗ௣ ൐ , where
ܪ௣ ൌ ሼ݌௜௝ሽ is the set of all pairs of topic words
and sentiment words, which appear in one sen-
tence. ܣௗ ൌ ሼ݀௞ ሽ is the set of documents.
ܧௗ௣ ൌ ሼ݁௜௝௞ |݌௜௝ א ܪ௣, ݀௞ א ܣௗሽ corresponds to the
connection between documents and top-
ic-sentiment word pairs. Each edge ݁௜௝௞ is asso-
ciated with a weight ݓ௜௝௞ א ሾ0,1ሿ denoting the
contribution of ݌௜௝ to the document ݀௞ . The
weight ݓ௜௝௞ is computed by the contribution of
word pair ݌௜௝ in all sentences of ݀௞ as follows:
</bodyText>
<equation confidence="0.9944642">
ݓ௜௝ ௞ ൌ ଵ
|ௗೖ |∑௣೔ೕא௦೗אௗೖൣߣ · ݎ݈݁ሺݐ௜, ݏ௟ሻ ൅ ሺ1 െ ߣሻ݋݌݊൫݋௝, ݏ௟൯൧ ሺ1ሻ
■ |݀௞ |is the number of sentences in ݀௞;
■ ߣ is introduced as the trade-off parameter to
balance the ݎ݈݁ሺݐ௜, ݏ௟ሻ and ݋݌݊൫݋௝, ݏ௟൯;
■ ݎ݈݁ሺݐ௜, ݏ௟ሻ is computed to judge the relevance
of ݐ௜ in ݏ௟ which belongs to ݀௞;
ݎ݈݁ሺݐ௜,ݏ௟ሻ ൌ ݐ݂௧೔,௦೗ ൈ ݅ݏ݂௧೔
݅ݏ݂௧೔ൌlogሺ ேାଵ ሻ (3)
଴.ହା௦௙೟೔
</equation>
<bodyText confidence="0.83391475">
where ݏ݂௧೔ is the number of sentences that the
word ݐ௜ appears in.
■ ݋݌݊൫݋௝, ݏ௟൯ is the contribution of ݋௝ in ݏ௟
which belongs to ݀௞.
</bodyText>
<equation confidence="0.988859">
݋݌݊൫݋௝, ݏ௟൯ ൌ ݐ݂݋݆,ݏ݈
݈݁݊ሺݏ݈ሻ (4)
ݐ݂݋݆,ݏ݈൅0.5൅ሺ1.5ൈܽݏ݈ ሻ
</equation>
<bodyText confidence="0.999673928571428">
where ܽݏ݈ is the average number of sentences in
݀௞; ݐ݂௧೔,௢ೕ is the number of ݋௝ appears in ݏ௟ (Al-
lan et al., 2003; Otterbacher et al., 2005).
It is found that the contribution of a sentiment
word ݋௝ will not decrease even if it appears in
all the sentences. Therefore in Equation 4, we
just use the length of a sentence instead of ݅ݏ݂௢ೕ
to normalize long sentences which would likely
contain more sentiment words.
The authority score ܣݑݐ݄ܵܿ݋ݎ݁ሺ்ାଵሻሺ݀௞ሻ of
document ݀௞ and a hub score ܪݑܾܵܿ݋ݎ݁ሺ்ାଵሻሺ݌௜௝ሻ
of ݌௜௝ at the ሺܶ ൅ 1ሻ୲୦ iteration are computed
based on the hub scores and authority scores in
the ܶ୲୦ iteration as follows.
</bodyText>
<equation confidence="0.98753075">
ܣݑݐ݄ܵܿ݋ݎ݁ሺ்ାଵሻሺ݀௞ሻ ൌ ∑ ݓ௜௝
௣౟ౠאு౦ ௞ ൈ ܪݑܾܵܿ݋ݎ்݁ሺ݌௜௝ሻ (5)
ܪݑܾܵܿ݋ݎ݁ሺ்ାଵሻ൫݌௜௝൯ ൌ ∑ ݓ௜௝
ௗౡא஺ౚ ௞ ൈ ܣݑݐ݄ܵܿ݋ݎ்݁ሺ݀௞ሻ (6)
We let ܮ ൌ ൫ܮ௜,௝൯|ு೛|ൈ|஺೏ |denote the adjacency
matrix.
ܽറሺ்ାଵሻൌ ܮ݄ሬറሺ்ሻ (7)
݄ሬറሺ்ାଵሻൌ ܮ்ܽറሺ்ሻ (8)
</equation>
<bodyText confidence="0.9488682">
where ܽറሺ்ሻ ൌ ሾܣݑݐ݄ܵܿ݋ݎ்݁ሺ݀௞ሻሿ|஺೏|ൈଵ is the vector
of authority scores for documents at the ܶ୲୦ ite-
ration and ݄ሬറሺ்ሻ ൌ ሾܪݑܾܵܿ݋ݎ்݁ሺ݌௜௝ሻሿ|ு೛|ൈଵ is the
vector of hub scores for the word pairs at ܶ୲୦
iteration. In order to ensure convergence of the
iterative form, ܽറ and ݄ሬറ are normalized in each
iteration cycle.
(2)
where ݐ݂௧౟,௦ౢ is the number of ݐ௜ appears in ݏ௟,
and
</bodyText>
<page confidence="0.956705">
1370
</page>
<bodyText confidence="0.956005466666667">
For computation of the final scores, the initial
scores of all documents are set to 1✓n, and top-
ic-sentiment word pairs are set to 1
✓,�M. The
above iterative steps are then used to compute
the new scores until convergence. Usually the
convergence of the iteration algorithm is
achieved when the difference between the scores
computed at two successive iterations for any
nodes falls below a given threshold (Wan et al.,
2008; Li et al., 2009; Erkan and Radev, 2004). In
our model, we use the hub scores to denote the
associative degree of each word pair and the au-
thority scores as the total scores. The documents
are then ranked based on the total scores.
</bodyText>
<sectionHeader confidence="0.999403" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.999953833333333">
We performed the experiments on the Chinese
benchmark dataset to verify our proposed ap-
proach for opinion retrieval. We first tested the
effect of the parameter A of our model. To
demonstrate the effectiveness of our opinion re-
trieval model, we compared its performance with
the same of other approaches. In addition, we
studied each individual query to investigate the
influence of query to our model. Furthermore,
we showed the top-5 highest weight word pairs
of 5 queries to further demonstrate the effect of
word pair.
</bodyText>
<subsectionHeader confidence="0.9529335">
4.1 Experiment Setup
4.1.1 Benchmark Datasets
</subsectionHeader>
<bodyText confidence="0.999994384615385">
Our experiments are based on the Chinese
benchmark dataset, COAE08 (Zhao et al., 2008).
COAE dataset is the benchmark data set for the
opinion retrieval track in the Chinese Opinion
Analysis Evaluation (COAE) workshop, consist-
ing of blogs and reviews. 20 queries are provided
in COAE08. In our experiment, we created re-
levance judgments through pooling method,
where documents are ranked at different levels:
irrelevant, relevant but without opinion, and re-
levant with opinion. Since polarity is not consi-
dered, all relevant documents with opinion are
classified into the same level.
</bodyText>
<subsubsectionHeader confidence="0.540907">
4.1.2 Sentiment Lexicon
</subsubsectionHeader>
<bodyText confidence="0.998658333333333">
In our experiment, the sentiment lexicon is
composed by the following resources (Xu et al.,
2007):
</bodyText>
<listItem confidence="0.9296878">
(1) The Lexicon of Chinese Positive Words,
which consists of 5,054 positive words and
the Lexicon of Chinese Negative Words,
which consists of 3,493 negative words;
(2) The opinion word lexicon provided by Na-
tional Taiwan University which consists of
2,812 positive words and 8,276 negative
words;
(3) Sentiment word lexicon and comment word
lexicon from Hownet. It contains 1836 posi-
</listItem>
<bodyText confidence="0.874740111111111">
tive sentiment words, 3,730 positive com-
ments, 1,254 negative sentiment words and
3,116 negative comment words.
The different graphemes corresponding to
Traditional Chinese and Simplified Chinese are
both considered so that the sentiment lexicons
from different sources are applicable to process
Simplified Chinese text. The lexicon was ma-
nually verified.
</bodyText>
<subsubsectionHeader confidence="0.478394">
4.1.3 Topic Term Collection
</subsubsectionHeader>
<bodyText confidence="0.999974214285714">
In order to acquire the collection of topic terms,
we adopt two expansion methods, dictio-
nary-based method and pseudo relevance feed-
back method.
The dictionary-based method utilizes Wikipe-
dia (Popescu and Etzioni, 2005) to find an entry
page for a phrase or a single term in a query. If
such an entry exists, all titles of the entry page
are extracted as synonyms of the query concept.
For example, if we search “绿坝” (Green Tsu-
nami, a firewall) in Wikipedia, it is re-directed to
an entry page titled “花季护航” (Youth Escort).
This term is then added as a synonym of “绿坝”
(Green Tsunami) in the query. Synonyms are
treated the same as the original query terms in a
retrieval process. The content words in the entry
page are ranked by their frequencies in the page.
The top-k terms are returned as potential ex-
panded topic terms.
The second query expansion method is a
web-based method. It is similar to the pseudo
relevance feedback expansion but using web
documents as the document collection. The
query is submitted to a web search engine, such
as Google, which returns a ranked list of docu-
ments. In the top-n documents, the top-m topic
terms which are highly correlated to the query
terms are returned.
</bodyText>
<subsectionHeader confidence="0.8953335">
4.2 Performance Evaluation
4.2.1 Parameter Tuning
</subsectionHeader>
<bodyText confidence="0.99991475">
We first studied how the parameter A (see Equ-
ation 1) influenced the mean average precision
(MAP) in our model. The result is given in Fig-
ure 4.
</bodyText>
<page confidence="0.994476">
1371
</page>
<figureCaption confidence="0.912341">
Figure 4: Performance of MAP with varying A.
</figureCaption>
<bodyText confidence="0.93484525">
Best MAP performance was achieved in
COAE08 evaluation, when A was set between
0.4 and 0.6. Therefore, in the following experi-
ments, we set A ൌ 0.4.
</bodyText>
<subsectionHeader confidence="0.599594">
4.2.2 Opinion Retrieval Model Comparison
</subsectionHeader>
<bodyText confidence="0.999966">
To demonstrate the effectiveness of our proposed
model, we compared it with the following mod-
els using different evaluation metrics:
</bodyText>
<listItem confidence="0.991856619047619">
(1) IR: We adopted a classical information re-
trieval model, and further assumed that all re-
trieved documents contained relevant opinions.
(2) Doc: The 2-stage document-based opinion
retrieval model was adopted. The model used
sentiment lexicon-based method for opinion
identification and a conventional information
retrieval method for relevance detection.
(3) ROSC: This was the model which achieved
the best run in TREC Blog 07. It employed ma-
chine learning method to identify opinions for
each sentence, and to determine the target topic
by a NEAR operator.
(4) ROCC: This model was similar to ROSC,
but it considered the factor of sentence and re-
garded the count of relevant opinionated sen-
tence to be the opinion score (Zhang and Yu,
2007). In our experiment, we treated this model
as the evaluation baseline.
(5) GORM: our proposed graph-based opinion
retrieval model.
</listItem>
<table confidence="0.999484125">
Approach COAE08
Evaluation metrics
Run id MAP R-pre bPref P@10
IR 0.2797 0.3545 0.2474 0.4868
Doc 0.3316 0.3690 0.3030 0.6696
ROSC 0.3762 0.4321 0.4162 0.7089
Baseline 0.3774 0.4411 0.4198 0.6931
GORM 0.3978 0.4835 0.4265 0.7309
</table>
<tableCaption confidence="0.7838955">
Table 1: Comparison of different approaches on
COAE08 dataset, and the best is highlighted.
</tableCaption>
<bodyText confidence="0.999867363636364">
Most of the above models were originally de-
signed for opinion retrieval in English, and
re-designed them to handle Chinese opinionated
documents. We incorporated our own Chinese
sentiment lexicon for this purpose. In our expe-
riments, in addition to MAP, other metrics such
as R-precision (R-prec), binary Preference (bPref)
and Precision at 10 documents (P@10) were also
used. The evaluation results based on these me-
trics are shown in Table 1.
Table 1 summarized the results obtained. We
found that GORM achieved the best performance
in all the evaluation metrics. Our baseline, ROSC
and GORM which were sentence-based ap-
proaches achieved better performance than the
document-based approaches by 20% in average.
Moreover, our GORM approach did not use ma-
chine learning techniques, but it could still
achieve outstanding performance.
To study GORM influenced by different que-
ries, the MAP from median average precision on
individual topic was shown in Figure 5.
</bodyText>
<figure confidence="0.966710875">
Difference from Median Average Precision per
Topic
0
-0.1
-0.2
-0.3
-0.4 1 2 3 4 5 6 7 8 9 1011121314151617181920
Topic
</figure>
<figureCaption confidence="0.8401125">
Figure 5: Difference of MAP from Median on
COAE08 dataset. (MAP of Median is 0.3724)
</figureCaption>
<bodyText confidence="0.999922958333333">
As shown in Figure 5, the MAP performance
was very low on topic 8 and topic 11. Topic 8, i.e.
‘)AA’ (Jackie Chan), it was influenced by topic
7, i.e. ‘�i?!c’ (Jet Lee) as there were a number
of similar relevant targets for the two topics, and
therefore many word pairs ended up the same.
As a result, documents belonging to topic 7 and
topic 8 could not be differentiated, and they both
performed badly. In order to solve this problem,
we extracted the topic term with highest relevant
weight in the sentence to form word pairs so that
it reduce the impact on the topic terms in com-
mon. 24% and 30% improvement were achieved,
respectively.
As to topic 11, i.e. ‘4H4,T-’ (Lord of King),
there were only 8 relevant documents without
any opinion and 14 documents with relevant
opinions. As a result, the graph constructed by
insufficient documents worked ineffectively.
Except for the above queries, GORM per-
formed well in most of the others. To further in-
vestigate the effect of word pair, we summarized
the top-5 word pairs with highest weight of 5
queries in Table 2.
</bodyText>
<figure confidence="0.9974496875">
0.4
0.35
MAP
0.3
0.25
0.2
COAE08
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
λ
Difference
0.6
0.5
0.4
0.3
0.2
0.1
</figure>
<page confidence="0.965094">
1372
</page>
<table confidence="0.978766538461538">
Top-5 MAP
陈凯歌 国六条 宏观调控 周星驰 Vista
Chen Kaige Six States Macro-regulation Stephen Chow Vista
&lt;陈凯歌 支持&gt; &lt;房价 上涨&gt; &lt;经济 平稳&gt; &lt;电影 喜欢&gt; &lt;价格 贵&gt;
Chen Kaige Support Room rate Rise Economics Steady Movie Like Price Expensive
&lt;陈凯歌 最佳&gt; &lt;调控 加强&gt; &lt;价格 上涨&gt; &lt;周星驰 喜欢&gt; &lt;微软 喜欢&gt;
Chen Kaige Best Regulate Strengthen Price Rise Stephen Chow Like Microsoft Like
&lt;《无极》 骂&gt; &lt;中央 加强&gt; &lt;发展 平稳&gt; &lt;主角 最佳&gt; &lt;Vista 推荐&gt;
Limitless Revile CCP Strengthen Development Steady Protagonist Best Vista Recommend
&lt;影片 优秀&gt; &lt;房价 平稳&gt; &lt;消费 上涨&gt; &lt;喜剧 好&gt; &lt;问题 重要&gt;
Movie Excellent Room rate Steady Consume Rise Comedy Good Problem Vital
&lt;阵容 强大的&gt; &lt;住房 保障&gt; &lt;社会 保障&gt; &lt;作品 精彩&gt; &lt;性能 不&gt;
Cast Strong Housing Security Social Security Works Splendid Performance No
</table>
<tableCaption confidence="0.810208">
Table 2: Top-5 highest weight word pairs for 5 queries in COAE08 dataset.
Table 2 showed that most word pairs could
</tableCaption>
<bodyText confidence="0.993671333333333">
represent the relevant opinions about the corres-
ponding queries. This showed that inter-sentence
information was very helpful to identify the as-
sociative degree of a word pair. Furthermore,
since word pairs can indicate relevant opinions
effectively, it is worth further study on how they
could be applied to other opinion oriented appli-
cations, e.g. opinion summarization, opinion
prediction, etc.
</bodyText>
<sectionHeader confidence="0.99985" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99997875">
Our research focuses on relevant opinion rather
than on relevant document retrieval. We, there-
fore, review related works in opinion identifica-
tion research. Furthermore, we do not support the
conventional 2-stage opinion retrieval approach.
We conducted literature review on unified opi-
nion retrieval models and related work in this
area is presented in the section.
</bodyText>
<subsectionHeader confidence="0.996997">
5.1 Lexicon-based Opinion Identification
</subsectionHeader>
<bodyText confidence="0.99997158974359">
Different from traditional IR, opinion retrieval
focuses on the opinion nature of documents.
During the last three years, NTICR and TREC
evaluations have shown that sentiment lex-
icon-based methods led to good performance in
opinion identification.
A lightweight lexicon-based statistical ap-
proach was proposed by Hannah et al. (2007). In
this method, the distribution of terms in relevant
opinionated documents was compared to their
distribution in relevant fact-based documents to
calculate an opinion weight. These weights were
used to compute opinion scores for each re-
trieved document. A weighted dictionary was
generated from previous TREC relevance data
(Amati et al., 2007). This dictionary was submit-
ted as a query to a search engine to get an initial
query-independent opinion score of all retrieved
documents. Similarly, a pseudo opinionated
word composed of all opinion words was first
created, and then used to estimate the opinion
score of a document (Na et al., 2009). This me-
thod was shown to be very effective in TREC
evaluations (Lee et al., 2008). More recently,
Huang and Croft (2009) proposed an effective
relevance model, which integrated both
query-independent and query-dependent senti-
ment words into a mixture model.
In our approach, we also adopt sentiment lex-
icon-based method for opinion identification.
Unlike the above methods, we generate a weight
to a sentiment word for each target (associated
topic term) rather than assign a unified weight or
an equal weight to the sentiment word for the
whole topics. Besides, in our model no training
data is required. We just utilize the structure of
our graph to generate a weight to reflect the as-
sociative degree between the two elements of a
word pair in different context.
</bodyText>
<subsectionHeader confidence="0.986598">
5.2 Unified Opinion Retrieval Model
</subsectionHeader>
<bodyText confidence="0.999939166666667">
In addition to conventional 2-stage approach,
there has been some research on unified opinion
retrieval models.
Eguchi and Lavrenko proposed an opinion re-
trieval model in the framework of generative
language modeling (Eguchi and Lavrenko, 2006).
They modeled a collection of natural language
documents or statements, each of which con-
sisted of some topic-bearing and some senti-
ment-bearing words. The sentiment was either
represented by a group of predefined seed words,
or extracted from a training sentiment corpus.
This model was shown to be effective on the
MPQA corpus.
Mei et al. tried to build a fine-grained opinion
retrieval system for consumer products (Mei et
al., 2007). The opinion score for a product was a
mixture of several facets. Due to the difficulty in
</bodyText>
<page confidence="0.966035">
1373
</page>
<bodyText confidence="0.999975571428572">
associating sentiment with products and facets,
the system was only tested using small scale text
collections.
Zhang and Ye proposed a generative model to
unify topic relevance and opinion generation
(Zhang and Ye, 2008). This model led to satis-
factory performance, but an intensive computa-
tion load was inevitable during retrieval, since
for each possible candidate document, an opinion
score was summed up from the generative prob-
ability of thousands of sentiment words.
Huang and Croft proposed a unified opinion
retrieval model according to the Kullback-Leib-
ler divergence between the two probability dis-
tributions of opinion relevance model and docu-
ment model (Huang and Croft, 2009). They di-
vided the sentiment words into query-dependent
and query-independent by utilizing several sen-
timent expansion techniques, and integrated them
into a mixed model. However, in this model, the
contribution of a sentiment word was its corres-
ponding incremental mean average precision
value. This method required that large amount of
training data and manual labeling.
Different from the above opinion retrieval ap-
proaches, our proposed graph-based model
processes opinion retrieval in the granularity of
sentence. Instead of bag-of-word, the sentence is
split into word pairs which can maintain the
contextual information. On the one hand, word
pair can identify the relevant opinion according
to intra-sentence contextual information. On the
other hand, it can measure the degree of a rele-
vant opinion by considering the inter-sentence
contextual information.
</bodyText>
<sectionHeader confidence="0.996435" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.998989396226415">
In this work we focus on the problem of opinion
retrieval. Different from existing approaches,
which regard document relevance as the key in-
dicator of opinion relevance, we propose to ex-
plore the relevance of individual opinion. To do
that, opinion retrieval is performed in the granu-
larity of sentence. We define the notion of word
pair, which can not only maintain the association
between the opinion and the corresponding target
in the sentence, but it can also build up the rela-
tionship among sentences through the same word
pair. Furthermore, we convert the relationships
between word pairs and sentences into a unified
graph, and use the HITS algorithm to achieve
document ranking for opinion retrieval. Finally,
we compare our approach with existing methods.
Experimental results show that our proposed
model performs well on COAE08 dataset.
The novelty of our work lies in using word
pairs to represent the information needs for opi-
nion retrieval. On the one hand, word pairs can
identify the relevant opinion according to in-
tra-sentence contextual information. On the other
hand, word pairs can measure the degree of a
relevant opinion by taking inter-sentence con-
textual information into consideration. With the
help of word pairs, the information needs for
opinion retrieval can be represented appropriate-
ly.
In the future, more research is required in the
following directions:
(1) Since word pairs can indicate relevant opi-
nions effectively, it is worth further study on
how they could be applied to other opinion
oriented applications, e.g. opinion summa-
rization, opinion prediction, etc.
(2) The characteristics of blogs will be taken
into consideration, i.e., the post time, which
could be helpful to create a more time sensi-
tivity graph to filter out fake opinions.
(3) Opinion holder is another important role of
an opinion, and the identification of opinion
holder is a main task in NTCIR. It would be
interesting to study opinion holders, e.g. its
seniority, for opinion retrieval.
Acknowledgements: This work is partially
supported by the Innovation and Technology
Fund of Hong Kong SAR (No. ITS/182/08) and
National 863 program (No. 2009AA01Z150).
Special thanks to Xu Hongbo for providing the
Chinese sentiment resources. We also thank Bo
Chen, Wei Gao, Xu Han and anonymous re-
viewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998609" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999206">
James Allan, Courtney Wade, and Alvaro Bolivar.
2003. Retrieval and novelty detection at the sen-
tence level. In SIGIR ’03: Proceedings of the 26th
annual international ACM SIGIR conference on
Research and development in information retrieval,
pages 314-321. ACM.
Giambattista Amati, Edgardo Ambrosi, Marco Bianc-
hi, Carlo Gaibisso, and Giorgio Gambosi. 2007.
FUB, IASI-CNR and University of Tor Vergata at
TREC 2007 Blog Track. In Proceedings of the 15th
Text Retrieval Conference.
Koji Eguchi and Victor Lavrenko. Sentiment retrieval
using generative models. 2006. In EMNLP ’06,
Proceedings of 2006 Conference on Empirical Me-
thods in Natural Language Processing, page
345-354.
</reference>
<page confidence="0.873521">
1374
</page>
<reference confidence="0.999448864583333">
Gunes Erkan and Dragomir R. Radev. 2004. Lexpa-
gerank: Prestige in multi-document text summariza-
tion. In EMNLP ’04, Proceedings of 2004 Confe-
rence on Empirical Methods in Natural Language
Processing.
David Hannah, Craig Macdonald, Jie Peng, Ben He,
and Iadh Ounis. 2007. University of Glasgow at
TREC 2007: Experiments in Blog and Enterprise
Tracks with Terrier. In Proceedings of the 15th Text
Retrieval Conference.
Xuanjing Huang, William Bruce Croft. 2009. A Uni-
fied Relevance Model for Opinion Retrieval. In
Proceedings of CIKM.
Jon M. Kleinberg. 1999. Authoritative sources in a
hyperlinked environment. J. ACM, 46(5): 604-632.
Yeha Lee, Seung-Hoon Na, Jungi Kim, Sang-Hyob
Nam, Hun-young Jung, Jong-Hyeok Lee. 2008.
KLE at TREC 2008 Blog Track: Blog Post and Feed
Retrieval. In Proceedings of the 15th Text Retrieval
Conference.
Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan
Zhu. 2009. Answering Opinion Questions with
Random Walks on Graphs. In ACL ’09, Proceedings
of the 48th Annual Meeting of the Association for
Computational Linguistics.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: Analyzing and comparing opi-
nion s on the web. In WWW ’05: Proceedings of the
14th International Conference on World Wide Web.
Craig Macdonald and Iadh Ounis. 2007. Overview of
the TREC-2007 Blog Track. In Proceedings of the
15th Text Retrieval Conference.
Craig Macdonald and Iadh Ounis. 2006. Overview of
the TREC-2006 Blog Track. In Proceedings of the
14th Text Retrieval Conference.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and Chengxiang Zhai. 2007. Topic sentiment mix-
ture: Modeling facets and opinions in weblogs. In
WWW ’07: Proceedings of the 16 International
Conference on World Wide Web.
Seung-Hoon Na, Yeha Lee, Sang-Hyob Nam, and
Jong-Hyeok Lee. 2009. Improving opinion retrieval
based on query-specific sentiment lexicon. In
ECIR ’09: Proceedings of the 31st annual European
Conference on Information Retrieval, pages
734-738.
Douglas Oard, Tamer Elsayed, Jianqiang Wang, Ye-
jun Wu, Pengyi Zhang, Eileen Abels, Jimmy Lin,
and Dagbert Soergel. 2006. TREC-2006 at Mary-
land: Blog, Enterprise, Legal and QA Tracks. In
Proceedings of the 15th Text Retrieval Conference.
Jahna Otterbacher, Gunes Erkan, and Dragomir R.
Radev. 2005. Using random walks for ques-
tion-focused sentence retrieval. In EMNLP ’05,
Proceedings of 2005 Conference on Empirical Me-
thods in Natural Language Processing.
Larry Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1998. The pagerank citation ranking:
Bringing order to the web. Technical report, Stan-
ford University.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval, 2(1-2): 1-135.
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinion s from reviews. In
EMNLP ’05, Proceedings of 2005 Conference on
Empirical Methods in Natural Language
Processing.
Xiaojun Wan and Jianwu Yang. 2008. Mul-
ti-document summarization using cluster-based link
analysis. In SIGIR ’08: Proceedings of the 31th an-
nual international ACM SIGIR conference on Re-
search and development in information retrieval,
pages 299-306. ACM.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in
phrase-level sentiment analysis. In EMNLP ’05,
Proceedings of 2005 Conference on Empirical Me-
thods in Natural Language Processing.
Ruifeng Xu, Kam-Fai Wong and Yunqing Xia. 2007.
Opinmine - Opinion Analysis System by CUHK for
NTCIR-6 Pilot Task. In Proceedings of NTCIR-6.
Min Zhang and Xingyao Ye. 2008. A generation
model to unify topic relevance and lexicon-based
sentiment for opinion retrieval. In SIGIR ’08: Pro-
ceedings of the 31st Annual International ACM SI-
GIR conference on Research and Development in
Information Retrieval, pages 411-418. ACM.
Wei Zhang and Clement Yu. 2007. UIC at TREC
2007 Blog Track. In Proceedings of the 15th Text
Retrieval Conference.
Jun Zhao, Hongbo Xu, Xuanjing Huang, Songbo Tan,
Kang Liu, and Qi Zhang. 2008. Overview of Chi-
nese Opinion Analysis Evaluation 2008. In Pro-
ceedings of the First Chinese Opinion Analysis
Evaluation.
</reference>
<page confidence="0.991601">
1375
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.717192">
<title confidence="0.998746">A Unified Graph Model for Sentence-based Opinion Retrieval</title>
<author confidence="0.998885">Binyang Li</author>
<author confidence="0.998885">Lanjun Zhou</author>
<author confidence="0.998885">Shi Feng</author>
<author confidence="0.998885">Kam-Fai Wong</author>
<affiliation confidence="0.875991">Department of Systems Engineering and Engineering Management The Chinese University of Hong Kong</affiliation>
<email confidence="0.980296">byli@se.cuhk.edu.hk</email>
<email confidence="0.980296">ljzhou@se.cuhk.edu.hk</email>
<email confidence="0.980296">sfeng@se.cuhk.edu.hk</email>
<email confidence="0.980296">kfwong@se.cuhk.edu.hk</email>
<abstract confidence="0.999271727272727">There is a growing research interest in opinion retrieval as on-line users’ opinions are becoming more and more popular in business, social networks, etc. Practically speaking, the goal of opinion retrieval is to retrieve documents, which entail opinions or comments, relevant to a target subject specified by the user’s query. A fundamental challenge in opinion retrieval is information representation. Existing research focuses on document-based approaches and are represented by However, due to loss of contextual information, this representation fails to capture the associative information between an opinion and its corresponding target. It cannot distinguish different degrees of a sentiment word when associated with different targets. This in turn seriously affects opinion retrieval performance. In this paper, we propose a sentence-based approach based on a new information representation, namely topic-sentiment word pair, to capture intra-sentence contextual information between an opinion and its target. Additionally, we consider inter-sentence information to capture the relationships among the opinions on the same topic. Finally, the two types of information are combined in a unified graph-based model, which can effectively rank the documents. Compared with existing approaches, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allan</author>
<author>Courtney Wade</author>
<author>Alvaro Bolivar</author>
</authors>
<title>Retrieval and novelty detection at the sentence level.</title>
<date>2003</date>
<booktitle>In SIGIR ’03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>314--321</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="16464" citStr="Allan et al., 2003" startWordPosition="2725" endWordPosition="2729">ߣ · ݎ݈݁ሺݐ, ݏሻ  ሺ1 െ ߣሻ݊൫, ݏ൯൧ ሺ1ሻ ■ |݀ |is the number of sentences in ݀; ■ ߣ is introduced as the trade-off parameter to balance the ݎ݈݁ሺݐ, ݏሻ and ݊൫, ݏ൯; ■ ݎ݈݁ሺݐ, ݏሻ is computed to judge the relevance of ݐ in ݏ which belongs to ݀; ݎ݈݁ሺݐ,ݏሻ ൌ ݐ݂௧,௦ ൈ ݅ݏ݂௧ ݅ݏ݂௧ൌlogሺ ேାଵ ሻ (3) .ହା௦ where ݏ݂௧ is the number of sentences that the word ݐ appears in. ■ ݊൫, ݏ൯ is the contribution of  in ݏ which belongs to ݀. ݊൫, ݏ൯ ൌ ݐ݂݆,ݏ݈ ݈݁݊ሺݏ݈ሻ (4) ݐ݂݆,ݏ݈0.5ሺ1.5ൈܽݏ݈ ሻ where ܽݏ݈ is the average number of sentences in ݀; ݐ݂௧,ೕ is the number of  appears in ݏ (Allan et al., 2003; Otterbacher et al., 2005). It is found that the contribution of a sentiment word  will not decrease even if it appears in all the sentences. Therefore in Equation 4, we just use the length of a sentence instead of ݅ݏ݂ೕ to normalize long sentences which would likely contain more sentiment words. The authority score ܣݑݐ݄ܵܿݎ݁ሺ்ାଵሻሺ݀ሻ of document ݀ and a hub score ܪݑܾܵܿݎ݁ሺ்ାଵሻሺሻ of  at the ሺܶ  1ሻ୦ iteration are computed based on the hub scores and authority scores in the ܶ୦ iteration as follows. ܣݑݐ݄ܵܿݎ݁ሺ்ାଵሻሺ݀ሻ ൌ ∑ ݓ ౠאு౦  ൈ ܪݑܾܵܿݎ்݁ሺሻ (5) ܪݑܾܵܿݎ݁ሺ்ାଵሻ൫൯ ൌ ∑ ݓ ௗ</context>
</contexts>
<marker>Allan, Wade, Bolivar, 2003</marker>
<rawString>James Allan, Courtney Wade, and Alvaro Bolivar. 2003. Retrieval and novelty detection at the sentence level. In SIGIR ’03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in information retrieval, pages 314-321. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giambattista Amati</author>
<author>Edgardo Ambrosi</author>
<author>Marco Bianchi</author>
<author>Carlo Gaibisso</author>
<author>Giorgio Gambosi</author>
</authors>
<title>Blog Track.</title>
<date>2007</date>
<journal>FUB, IASI-CNR and University of Tor Vergata at TREC</journal>
<booktitle>In Proceedings of the 15th Text Retrieval Conference.</booktitle>
<contexts>
<context position="3189" citStr="Amati et al., 2007" startWordPosition="475" endWordPosition="478">irement brings about the challenge on how to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents are determined and ranked by a score, i.e. tf-idf value. In the second stage, an opinion score is generated for each relevant document (Macdonald and Ounis, 2007; Oard et al., 2006). The opinion score can be acquired by either machine learning-based sentiment classifiers, such as SVM (Zhang and Yu, 2007), or a sentiment lexicons with weighted scores from training documents (Amati et al., 2007; Hannah et al., 2007; Na et al., 2009). Finally, an overall score combining the two is computed by using a score function, e.g. linear combination, to re-rank the retrieved documents. Retrieval in the 2-stage approach is based on document and document is represented by bag-of-word. This representation, however, can only ensure that there is at least one opinion in each relevant document, but it cannot determine the relevance pairing of individual opinion to its target. In general, by simply representing a document in bag-of-word, contextual information i.e. the corresponding target of an opin</context>
<context position="27901" citStr="Amati et al., 2007" startWordPosition="4609" endWordPosition="4612">he opinion nature of documents. During the last three years, NTICR and TREC evaluations have shown that sentiment lexicon-based methods led to good performance in opinion identification. A lightweight lexicon-based statistical approach was proposed by Hannah et al. (2007). In this method, the distribution of terms in relevant opinionated documents was compared to their distribution in relevant fact-based documents to calculate an opinion weight. These weights were used to compute opinion scores for each retrieved document. A weighted dictionary was generated from previous TREC relevance data (Amati et al., 2007). This dictionary was submitted as a query to a search engine to get an initial query-independent opinion score of all retrieved documents. Similarly, a pseudo opinionated word composed of all opinion words was first created, and then used to estimate the opinion score of a document (Na et al., 2009). This method was shown to be very effective in TREC evaluations (Lee et al., 2008). More recently, Huang and Croft (2009) proposed an effective relevance model, which integrated both query-independent and query-dependent sentiment words into a mixture model. In our approach, we also adopt sentimen</context>
</contexts>
<marker>Amati, Ambrosi, Bianchi, Gaibisso, Gambosi, 2007</marker>
<rawString>Giambattista Amati, Edgardo Ambrosi, Marco Bianchi, Carlo Gaibisso, and Giorgio Gambosi. 2007. FUB, IASI-CNR and University of Tor Vergata at TREC 2007 Blog Track. In Proceedings of the 15th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koji Eguchi</author>
<author>Victor Lavrenko</author>
</authors>
<title>Sentiment retrieval using generative models.</title>
<date>2006</date>
<booktitle>In EMNLP ’06, Proceedings of 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>345--354</pages>
<contexts>
<context position="29250" citStr="Eguchi and Lavrenko, 2006" startWordPosition="4828" endWordPosition="4831">ach target (associated topic term) rather than assign a unified weight or an equal weight to the sentiment word for the whole topics. Besides, in our model no training data is required. We just utilize the structure of our graph to generate a weight to reflect the associative degree between the two elements of a word pair in different context. 5.2 Unified Opinion Retrieval Model In addition to conventional 2-stage approach, there has been some research on unified opinion retrieval models. Eguchi and Lavrenko proposed an opinion retrieval model in the framework of generative language modeling (Eguchi and Lavrenko, 2006). They modeled a collection of natural language documents or statements, each of which consisted of some topic-bearing and some sentiment-bearing words. The sentiment was either represented by a group of predefined seed words, or extracted from a training sentiment corpus. This model was shown to be effective on the MPQA corpus. Mei et al. tried to build a fine-grained opinion retrieval system for consumer products (Mei et al., 2007). The opinion score for a product was a mixture of several facets. Due to the difficulty in 1373 associating sentiment with products and facets, the system was onl</context>
</contexts>
<marker>Eguchi, Lavrenko, 2006</marker>
<rawString>Koji Eguchi and Victor Lavrenko. Sentiment retrieval using generative models. 2006. In EMNLP ’06, Proceedings of 2006 Conference on Empirical Methods in Natural Language Processing, page 345-354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunes Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>Lexpagerank: Prestige in multi-document text summarization.</title>
<date>2004</date>
<booktitle>In EMNLP ’04, Proceedings of 2004 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="18031" citStr="Erkan and Radev, 2004" startWordPosition="2992" endWordPosition="2995"> ensure convergence of the iterative form, ܽറ and ݄ሬറ are normalized in each iteration cycle. (2) where ݐ݂௧,௦ is the number of ݐ appears in ݏ, and 1370 For computation of the final scores, the initial scores of all documents are set to 1✓n, and topic-sentiment word pairs are set to 1 ✓,�M. The above iterative steps are then used to compute the new scores until convergence. Usually the convergence of the iteration algorithm is achieved when the difference between the scores computed at two successive iterations for any nodes falls below a given threshold (Wan et al., 2008; Li et al., 2009; Erkan and Radev, 2004). In our model, we use the hub scores to denote the associative degree of each word pair and the authority scores as the total scores. The documents are then ranked based on the total scores. 4 Experiment We performed the experiments on the Chinese benchmark dataset to verify our proposed approach for opinion retrieval. We first tested the effect of the parameter A of our model. To demonstrate the effectiveness of our opinion retrieval model, we compared its performance with the same of other approaches. In addition, we studied each individual query to investigate the influence of query to our</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>Gunes Erkan and Dragomir R. Radev. 2004. Lexpagerank: Prestige in multi-document text summarization. In EMNLP ’04, Proceedings of 2004 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hannah</author>
<author>Craig Macdonald</author>
<author>Jie Peng</author>
<author>Ben He</author>
<author>Iadh Ounis</author>
</authors>
<date>2007</date>
<booktitle>University of Glasgow at TREC 2007: Experiments in Blog and Enterprise Tracks with Terrier. In Proceedings of the 15th Text Retrieval Conference.</booktitle>
<contexts>
<context position="3210" citStr="Hannah et al., 2007" startWordPosition="479" endWordPosition="482"> the challenge on how to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents are determined and ranked by a score, i.e. tf-idf value. In the second stage, an opinion score is generated for each relevant document (Macdonald and Ounis, 2007; Oard et al., 2006). The opinion score can be acquired by either machine learning-based sentiment classifiers, such as SVM (Zhang and Yu, 2007), or a sentiment lexicons with weighted scores from training documents (Amati et al., 2007; Hannah et al., 2007; Na et al., 2009). Finally, an overall score combining the two is computed by using a score function, e.g. linear combination, to re-rank the retrieved documents. Retrieval in the 2-stage approach is based on document and document is represented by bag-of-word. This representation, however, can only ensure that there is at least one opinion in each relevant document, but it cannot determine the relevance pairing of individual opinion to its target. In general, by simply representing a document in bag-of-word, contextual information i.e. the corresponding target of an opinion, is neglected. Th</context>
<context position="27554" citStr="Hannah et al. (2007)" startWordPosition="4557" endWordPosition="4560">in opinion identification research. Furthermore, we do not support the conventional 2-stage opinion retrieval approach. We conducted literature review on unified opinion retrieval models and related work in this area is presented in the section. 5.1 Lexicon-based Opinion Identification Different from traditional IR, opinion retrieval focuses on the opinion nature of documents. During the last three years, NTICR and TREC evaluations have shown that sentiment lexicon-based methods led to good performance in opinion identification. A lightweight lexicon-based statistical approach was proposed by Hannah et al. (2007). In this method, the distribution of terms in relevant opinionated documents was compared to their distribution in relevant fact-based documents to calculate an opinion weight. These weights were used to compute opinion scores for each retrieved document. A weighted dictionary was generated from previous TREC relevance data (Amati et al., 2007). This dictionary was submitted as a query to a search engine to get an initial query-independent opinion score of all retrieved documents. Similarly, a pseudo opinionated word composed of all opinion words was first created, and then used to estimate t</context>
</contexts>
<marker>Hannah, Macdonald, Peng, He, Ounis, 2007</marker>
<rawString>David Hannah, Craig Macdonald, Jie Peng, Ben He, and Iadh Ounis. 2007. University of Glasgow at TREC 2007: Experiments in Blog and Enterprise Tracks with Terrier. In Proceedings of the 15th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuanjing Huang</author>
<author>William Bruce Croft</author>
</authors>
<title>A Unified Relevance Model for Opinion Retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of CIKM.</booktitle>
<contexts>
<context position="28324" citStr="Huang and Croft (2009)" startWordPosition="4682" endWordPosition="4685"> calculate an opinion weight. These weights were used to compute opinion scores for each retrieved document. A weighted dictionary was generated from previous TREC relevance data (Amati et al., 2007). This dictionary was submitted as a query to a search engine to get an initial query-independent opinion score of all retrieved documents. Similarly, a pseudo opinionated word composed of all opinion words was first created, and then used to estimate the opinion score of a document (Na et al., 2009). This method was shown to be very effective in TREC evaluations (Lee et al., 2008). More recently, Huang and Croft (2009) proposed an effective relevance model, which integrated both query-independent and query-dependent sentiment words into a mixture model. In our approach, we also adopt sentiment lexicon-based method for opinion identification. Unlike the above methods, we generate a weight to a sentiment word for each target (associated topic term) rather than assign a unified weight or an equal weight to the sentiment word for the whole topics. Besides, in our model no training data is required. We just utilize the structure of our graph to generate a weight to reflect the associative degree between the two </context>
<context position="30472" citStr="Huang and Croft, 2009" startWordPosition="5023" endWordPosition="5026">y tested using small scale text collections. Zhang and Ye proposed a generative model to unify topic relevance and opinion generation (Zhang and Ye, 2008). This model led to satisfactory performance, but an intensive computation load was inevitable during retrieval, since for each possible candidate document, an opinion score was summed up from the generative probability of thousands of sentiment words. Huang and Croft proposed a unified opinion retrieval model according to the Kullback-Leibler divergence between the two probability distributions of opinion relevance model and document model (Huang and Croft, 2009). They divided the sentiment words into query-dependent and query-independent by utilizing several sentiment expansion techniques, and integrated them into a mixed model. However, in this model, the contribution of a sentiment word was its corresponding incremental mean average precision value. This method required that large amount of training data and manual labeling. Different from the above opinion retrieval approaches, our proposed graph-based model processes opinion retrieval in the granularity of sentence. Instead of bag-of-word, the sentence is split into word pairs which can maintain </context>
</contexts>
<marker>Huang, Croft, 2009</marker>
<rawString>Xuanjing Huang, William Bruce Croft. 2009. A Unified Relevance Model for Opinion Retrieval. In Proceedings of CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>J. ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<pages>604--632</pages>
<contexts>
<context position="13973" citStr="Kleinberg, 1999" startWordPosition="2264" endWordPosition="2265">ual information is explored. This is achieved by assigning a weight to each word pair to measure their associative degrees to different queries. We believe that the more a word pair appears the higher should be the weight between the opinion and the target in the context. We will describe how to utilize intra-sentence contextual information to express relevant opinion, and inter-sentence information to measure the degree of each word pair through a graph-based model in the following section. 3.2 HITS Model We propose an opinion retrieval model based on HITS, a popular graph ranking algorithm (Kleinberg, 1999). By considering both intra-sentence information and inter-sentence information, we can determine the weight of a word pair and rank the documents. HITS algorithm distinguishes hubs and authorities in objects. A hub object has links to many authorities. An authority object, which has high-quality content, would have many hubs linking to it. The hub scores and authority scores are computed in an iterative way. Our proposed opinion retrieval model contains two layers. The upper level contains all the topic-sentiment word pairs  ൌ  ݐ,   |ݐ א ܸ௧,  א ܸሻ . The lower level contains all </context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. J. ACM, 46(5): 604-632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yeha Lee</author>
<author>Seung-Hoon Na</author>
<author>Jungi Kim</author>
<author>Sang-Hyob Nam</author>
<author>Hun-young Jung</author>
<author>Jong-Hyeok Lee</author>
</authors>
<title>Blog Track: Blog Post and Feed Retrieval.</title>
<date>2008</date>
<journal>KLE at TREC</journal>
<booktitle>In Proceedings of the 15th Text Retrieval Conference.</booktitle>
<contexts>
<context position="28285" citStr="Lee et al., 2008" startWordPosition="4676" endWordPosition="4679">n relevant fact-based documents to calculate an opinion weight. These weights were used to compute opinion scores for each retrieved document. A weighted dictionary was generated from previous TREC relevance data (Amati et al., 2007). This dictionary was submitted as a query to a search engine to get an initial query-independent opinion score of all retrieved documents. Similarly, a pseudo opinionated word composed of all opinion words was first created, and then used to estimate the opinion score of a document (Na et al., 2009). This method was shown to be very effective in TREC evaluations (Lee et al., 2008). More recently, Huang and Croft (2009) proposed an effective relevance model, which integrated both query-independent and query-dependent sentiment words into a mixture model. In our approach, we also adopt sentiment lexicon-based method for opinion identification. Unlike the above methods, we generate a weight to a sentiment word for each target (associated topic term) rather than assign a unified weight or an equal weight to the sentiment word for the whole topics. Besides, in our model no training data is required. We just utilize the structure of our graph to generate a weight to reflect </context>
</contexts>
<marker>Lee, Na, Kim, Nam, Jung, Lee, 2008</marker>
<rawString>Yeha Lee, Seung-Hoon Na, Jungi Kim, Sang-Hyob Nam, Hun-young Jung, Jong-Hyeok Lee. 2008. KLE at TREC 2008 Blog Track: Blog Post and Feed Retrieval. In Proceedings of the 15th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Yang Tang</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Answering Opinion Questions with Random Walks on Graphs.</title>
<date>2009</date>
<booktitle>In ACL ’09, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="18007" citStr="Li et al., 2009" startWordPosition="2988" endWordPosition="2991">tion. In order to ensure convergence of the iterative form, ܽറ and ݄ሬറ are normalized in each iteration cycle. (2) where ݐ݂௧,௦ is the number of ݐ appears in ݏ, and 1370 For computation of the final scores, the initial scores of all documents are set to 1✓n, and topic-sentiment word pairs are set to 1 ✓,�M. The above iterative steps are then used to compute the new scores until convergence. Usually the convergence of the iteration algorithm is achieved when the difference between the scores computed at two successive iterations for any nodes falls below a given threshold (Wan et al., 2008; Li et al., 2009; Erkan and Radev, 2004). In our model, we use the hub scores to denote the associative degree of each word pair and the authority scores as the total scores. The documents are then ranked based on the total scores. 4 Experiment We performed the experiments on the Chinese benchmark dataset to verify our proposed approach for opinion retrieval. We first tested the effect of the parameter A of our model. To demonstrate the effectiveness of our opinion retrieval model, we compared its performance with the same of other approaches. In addition, we studied each individual query to investigate the i</context>
</contexts>
<marker>Li, Tang, Huang, Zhu, 2009</marker>
<rawString>Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan Zhu. 2009. Answering Opinion Questions with Random Walks on Graphs. In ACL ’09, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: Analyzing and comparing opinion s on the web.</title>
<date>2005</date>
<booktitle>In WWW ’05: Proceedings of the 14th International Conference on World Wide Web.</booktitle>
<contexts>
<context position="2194" citStr="Liu et al., 2005" startWordPosition="314" endWordPosition="317">, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement. 1 Introduction In recent years, there is a growing interest in sharing personal opinions on the Web, such as product reviews, economic analysis, political polls, etc. These opinions cannot only help independent users make decisions, but also obtain valuable feedbacks (Pang et al., 2008). Opinion oriented research, including sentiment classification, opinion extraction, opinion question answering, and opinion summarization, etc. are receiving growing attention (Wilson, et al., 2005; Liu et al., 2005; Oard et al., 2006). However, most existing works concentrate on analyzing opinions expressed in the documents, and none on how to represent the information needs required to retrieve opinionated documents. In this paper, we focus on opinion retrieval, whose goal is to find a set of documents containing not only the query keyword(s) but also the relevant opinions. This requirement brings about the challenge on how to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents </context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: Analyzing and comparing opinion s on the web. In WWW ’05: Proceedings of the 14th International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craig Macdonald</author>
<author>Iadh Ounis</author>
</authors>
<title>Overview of the TREC-2007 Blog Track.</title>
<date>2007</date>
<booktitle>In Proceedings of the 15th Text Retrieval Conference.</booktitle>
<contexts>
<context position="2955" citStr="Macdonald and Ounis, 2007" startWordPosition="437" endWordPosition="440">esent the information needs required to retrieve opinionated documents. In this paper, we focus on opinion retrieval, whose goal is to find a set of documents containing not only the query keyword(s) but also the relevant opinions. This requirement brings about the challenge on how to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents are determined and ranked by a score, i.e. tf-idf value. In the second stage, an opinion score is generated for each relevant document (Macdonald and Ounis, 2007; Oard et al., 2006). The opinion score can be acquired by either machine learning-based sentiment classifiers, such as SVM (Zhang and Yu, 2007), or a sentiment lexicons with weighted scores from training documents (Amati et al., 2007; Hannah et al., 2007; Na et al., 2009). Finally, an overall score combining the two is computed by using a score function, e.g. linear combination, to re-rank the retrieved documents. Retrieval in the 2-stage approach is based on document and document is represented by bag-of-word. This representation, however, can only ensure that there is at least one opinion i</context>
</contexts>
<marker>Macdonald, Ounis, 2007</marker>
<rawString>Craig Macdonald and Iadh Ounis. 2007. Overview of the TREC-2007 Blog Track. In Proceedings of the 15th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craig Macdonald</author>
<author>Iadh Ounis</author>
</authors>
<title>Overview of the TREC-2006 Blog Track.</title>
<date>2006</date>
<booktitle>In Proceedings of the 14th Text Retrieval Conference.</booktitle>
<contexts>
<context position="6749" citStr="Macdonald and Ounis, 2006" startWordPosition="1051" endWordPosition="1054">alyze the motivation of our method. 2.1 Formal Description of Problem Opinion retrieval was first presented in the TREC 2006 Blog track, and the objective is to retrieve documents that express an opinion about a given target. The opinion target can be a “traditional” named entity (e.g. a name of person, location, or organization, etc.), a concept (e.g. a type of technology), or an event (e.g. presidential election). The topic of the document is not required to be the same as the target, but an opinion about the target has to be presented in the document or one of the comments to the document (Macdonald and Ounis, 2006). Therefore, in this paper we regard the information needs for opinion retrieval as relevant opinion. 2.2 Motivation of Our Approach In traditional information retrieval (IR) bag-of-word representation is the most common way to express information needs. However, in opinion retrieval, information need target at relevant opinion, and this renders bag-of-word representation ineffective. Consider the example in Figure 1. There are three sentences A, B, and C in a document di. Now given an opinion-oriented query Q related to ‘Avatar’. According to the conventional 2-stage opinion retrieval approac</context>
</contexts>
<marker>Macdonald, Ounis, 2006</marker>
<rawString>Craig Macdonald and Iadh Ounis. 2006. Overview of the TREC-2006 Blog Track. In Proceedings of the 14th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Topic sentiment mixture: Modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In WWW ’07: Proceedings of the 16 International Conference on World Wide Web.</booktitle>
<contexts>
<context position="29687" citStr="Mei et al., 2007" startWordPosition="4899" endWordPosition="4902">e research on unified opinion retrieval models. Eguchi and Lavrenko proposed an opinion retrieval model in the framework of generative language modeling (Eguchi and Lavrenko, 2006). They modeled a collection of natural language documents or statements, each of which consisted of some topic-bearing and some sentiment-bearing words. The sentiment was either represented by a group of predefined seed words, or extracted from a training sentiment corpus. This model was shown to be effective on the MPQA corpus. Mei et al. tried to build a fine-grained opinion retrieval system for consumer products (Mei et al., 2007). The opinion score for a product was a mixture of several facets. Due to the difficulty in 1373 associating sentiment with products and facets, the system was only tested using small scale text collections. Zhang and Ye proposed a generative model to unify topic relevance and opinion generation (Zhang and Ye, 2008). This model led to satisfactory performance, but an intensive computation load was inevitable during retrieval, since for each possible candidate document, an opinion score was summed up from the generative probability of thousands of sentiment words. Huang and Croft proposed a uni</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and Chengxiang Zhai. 2007. Topic sentiment mixture: Modeling facets and opinions in weblogs. In WWW ’07: Proceedings of the 16 International Conference on World Wide Web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seung-Hoon Na</author>
<author>Yeha Lee</author>
<author>Sang-Hyob Nam</author>
<author>Jong-Hyeok Lee</author>
</authors>
<title>Improving opinion retrieval based on query-specific sentiment lexicon.</title>
<date>2009</date>
<booktitle>In ECIR ’09: Proceedings of the 31st annual European Conference on Information Retrieval,</booktitle>
<pages>734--738</pages>
<contexts>
<context position="3228" citStr="Na et al., 2009" startWordPosition="483" endWordPosition="486"> to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents are determined and ranked by a score, i.e. tf-idf value. In the second stage, an opinion score is generated for each relevant document (Macdonald and Ounis, 2007; Oard et al., 2006). The opinion score can be acquired by either machine learning-based sentiment classifiers, such as SVM (Zhang and Yu, 2007), or a sentiment lexicons with weighted scores from training documents (Amati et al., 2007; Hannah et al., 2007; Na et al., 2009). Finally, an overall score combining the two is computed by using a score function, e.g. linear combination, to re-rank the retrieved documents. Retrieval in the 2-stage approach is based on document and document is represented by bag-of-word. This representation, however, can only ensure that there is at least one opinion in each relevant document, but it cannot determine the relevance pairing of individual opinion to its target. In general, by simply representing a document in bag-of-word, contextual information i.e. the corresponding target of an opinion, is neglected. This may result in p</context>
<context position="28202" citStr="Na et al., 2009" startWordPosition="4660" endWordPosition="4663">on of terms in relevant opinionated documents was compared to their distribution in relevant fact-based documents to calculate an opinion weight. These weights were used to compute opinion scores for each retrieved document. A weighted dictionary was generated from previous TREC relevance data (Amati et al., 2007). This dictionary was submitted as a query to a search engine to get an initial query-independent opinion score of all retrieved documents. Similarly, a pseudo opinionated word composed of all opinion words was first created, and then used to estimate the opinion score of a document (Na et al., 2009). This method was shown to be very effective in TREC evaluations (Lee et al., 2008). More recently, Huang and Croft (2009) proposed an effective relevance model, which integrated both query-independent and query-dependent sentiment words into a mixture model. In our approach, we also adopt sentiment lexicon-based method for opinion identification. Unlike the above methods, we generate a weight to a sentiment word for each target (associated topic term) rather than assign a unified weight or an equal weight to the sentiment word for the whole topics. Besides, in our model no training data is re</context>
</contexts>
<marker>Na, Lee, Nam, Lee, 2009</marker>
<rawString>Seung-Hoon Na, Yeha Lee, Sang-Hyob Nam, and Jong-Hyeok Lee. 2009. Improving opinion retrieval based on query-specific sentiment lexicon. In ECIR ’09: Proceedings of the 31st annual European Conference on Information Retrieval, pages 734-738.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Douglas Oard</author>
<author>Tamer Elsayed</author>
<author>Jianqiang Wang</author>
<author>Yejun Wu</author>
<author>Pengyi Zhang</author>
<author>Eileen Abels</author>
<author>Jimmy Lin</author>
<author>Dagbert Soergel</author>
</authors>
<title>TREC-2006 at Maryland: Blog, Enterprise, Legal and QA Tracks.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th Text Retrieval Conference. Jahna Otterbacher, Gunes Erkan, and Dragomir</booktitle>
<contexts>
<context position="2214" citStr="Oard et al., 2006" startWordPosition="318" endWordPosition="321">ults on the COAE08 dataset showed that our graph-based model achieved significant improvement. 1 Introduction In recent years, there is a growing interest in sharing personal opinions on the Web, such as product reviews, economic analysis, political polls, etc. These opinions cannot only help independent users make decisions, but also obtain valuable feedbacks (Pang et al., 2008). Opinion oriented research, including sentiment classification, opinion extraction, opinion question answering, and opinion summarization, etc. are receiving growing attention (Wilson, et al., 2005; Liu et al., 2005; Oard et al., 2006). However, most existing works concentrate on analyzing opinions expressed in the documents, and none on how to represent the information needs required to retrieve opinionated documents. In this paper, we focus on opinion retrieval, whose goal is to find a set of documents containing not only the query keyword(s) but also the relevant opinions. This requirement brings about the challenge on how to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents are determined and r</context>
</contexts>
<marker>Oard, Elsayed, Wang, Wu, Zhang, Abels, Lin, Soergel, 2006</marker>
<rawString>Douglas Oard, Tamer Elsayed, Jianqiang Wang, Yejun Wu, Pengyi Zhang, Eileen Abels, Jimmy Lin, and Dagbert Soergel. 2006. TREC-2006 at Maryland: Blog, Enterprise, Legal and QA Tracks. In Proceedings of the 15th Text Retrieval Conference. Jahna Otterbacher, Gunes Erkan, and Dragomir R. Radev. 2005. Using random walks for question-focused sentence retrieval. In EMNLP ’05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1998</date>
<tech>Technical report,</tech>
<institution>Stanford University.</institution>
<marker>Page, Brin, Motwani, Winograd, 1998</marker>
<rawString>Larry Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1998. The pagerank citation ranking: Bringing order to the web. Technical report, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2): 1-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinion s from reviews.</title>
<date>2005</date>
<booktitle>In EMNLP ’05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="20499" citStr="Popescu and Etzioni, 2005" startWordPosition="3380" endWordPosition="3383">. It contains 1836 positive sentiment words, 3,730 positive comments, 1,254 negative sentiment words and 3,116 negative comment words. The different graphemes corresponding to Traditional Chinese and Simplified Chinese are both considered so that the sentiment lexicons from different sources are applicable to process Simplified Chinese text. The lexicon was manually verified. 4.1.3 Topic Term Collection In order to acquire the collection of topic terms, we adopt two expansion methods, dictionary-based method and pseudo relevance feedback method. The dictionary-based method utilizes Wikipedia (Popescu and Etzioni, 2005) to find an entry page for a phrase or a single term in a query. If such an entry exists, all titles of the entry page are extracted as synonyms of the query concept. For example, if we search “绿坝” (Green Tsunami, a firewall) in Wikipedia, it is re-directed to an entry page titled “花季护航” (Youth Escort). This term is then added as a synonym of “绿坝” (Green Tsunami) in the query. Synonyms are treated the same as the original query terms in a retrieval process. The content words in the entry page are ranked by their frequencies in the page. The top-k terms are returned as potential expanded topic </context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinion s from reviews. In EMNLP ’05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
<author>Jianwu Yang</author>
</authors>
<title>Multi-document summarization using cluster-based link analysis.</title>
<date>2008</date>
<booktitle>In SIGIR ’08: Proceedings of the 31th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>299--306</pages>
<publisher>ACM.</publisher>
<marker>Wan, Yang, 2008</marker>
<rawString>Xiaojun Wan and Jianwu Yang. 2008. Multi-document summarization using cluster-based link analysis. In SIGIR ’08: Proceedings of the 31th annual international ACM SIGIR conference on Research and development in information retrieval, pages 299-306. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In EMNLP ’05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2176" citStr="Wilson, et al., 2005" startWordPosition="310" endWordPosition="313">th existing approaches, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement. 1 Introduction In recent years, there is a growing interest in sharing personal opinions on the Web, such as product reviews, economic analysis, political polls, etc. These opinions cannot only help independent users make decisions, but also obtain valuable feedbacks (Pang et al., 2008). Opinion oriented research, including sentiment classification, opinion extraction, opinion question answering, and opinion summarization, etc. are receiving growing attention (Wilson, et al., 2005; Liu et al., 2005; Oard et al., 2006). However, most existing works concentrate on analyzing opinions expressed in the documents, and none on how to represent the information needs required to retrieve opinionated documents. In this paper, we focus on opinion retrieval, whose goal is to find a set of documents containing not only the query keyword(s) but also the relevant opinions. This requirement brings about the challenge on how to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, r</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In EMNLP ’05, Proceedings of 2005 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifeng Xu</author>
</authors>
<title>Kam-Fai Wong and Yunqing Xia.</title>
<date>2007</date>
<booktitle>In Proceedings of NTCIR-6.</booktitle>
<marker>Xu, 2007</marker>
<rawString>Ruifeng Xu, Kam-Fai Wong and Yunqing Xia. 2007. Opinmine - Opinion Analysis System by CUHK for NTCIR-6 Pilot Task. In Proceedings of NTCIR-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Xingyao Ye</author>
</authors>
<title>A generation model to unify topic relevance and lexicon-based sentiment for opinion retrieval.</title>
<date>2008</date>
<booktitle>In SIGIR ’08: Proceedings of the 31st Annual International ACM SIGIR conference on Research and Development in Information Retrieval,</booktitle>
<pages>411--418</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="30004" citStr="Zhang and Ye, 2008" startWordPosition="4951" endWordPosition="4954">nt-bearing words. The sentiment was either represented by a group of predefined seed words, or extracted from a training sentiment corpus. This model was shown to be effective on the MPQA corpus. Mei et al. tried to build a fine-grained opinion retrieval system for consumer products (Mei et al., 2007). The opinion score for a product was a mixture of several facets. Due to the difficulty in 1373 associating sentiment with products and facets, the system was only tested using small scale text collections. Zhang and Ye proposed a generative model to unify topic relevance and opinion generation (Zhang and Ye, 2008). This model led to satisfactory performance, but an intensive computation load was inevitable during retrieval, since for each possible candidate document, an opinion score was summed up from the generative probability of thousands of sentiment words. Huang and Croft proposed a unified opinion retrieval model according to the Kullback-Leibler divergence between the two probability distributions of opinion relevance model and document model (Huang and Croft, 2009). They divided the sentiment words into query-dependent and query-independent by utilizing several sentiment expansion techniques, a</context>
</contexts>
<marker>Zhang, Ye, 2008</marker>
<rawString>Min Zhang and Xingyao Ye. 2008. A generation model to unify topic relevance and lexicon-based sentiment for opinion retrieval. In SIGIR ’08: Proceedings of the 31st Annual International ACM SIGIR conference on Research and Development in Information Retrieval, pages 411-418. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Zhang</author>
<author>Clement Yu</author>
</authors>
<title>UIC at TREC</title>
<date>2007</date>
<booktitle>In Proceedings of the 15th Text Retrieval Conference.</booktitle>
<contexts>
<context position="3099" citStr="Zhang and Yu, 2007" startWordPosition="461" endWordPosition="464">ocuments containing not only the query keyword(s) but also the relevant opinions. This requirement brings about the challenge on how to represent information needs for effective opinion retrieval. In order to solve the above problem, previous work adopts a 2-stage approach. In the first stage, relevant documents are determined and ranked by a score, i.e. tf-idf value. In the second stage, an opinion score is generated for each relevant document (Macdonald and Ounis, 2007; Oard et al., 2006). The opinion score can be acquired by either machine learning-based sentiment classifiers, such as SVM (Zhang and Yu, 2007), or a sentiment lexicons with weighted scores from training documents (Amati et al., 2007; Hannah et al., 2007; Na et al., 2009). Finally, an overall score combining the two is computed by using a score function, e.g. linear combination, to re-rank the retrieved documents. Retrieval in the 2-stage approach is based on document and document is represented by bag-of-word. This representation, however, can only ensure that there is at least one opinion in each relevant document, but it cannot determine the relevance pairing of individual opinion to its target. In general, by simply representing </context>
<context position="22796" citStr="Zhang and Yu, 2007" startWordPosition="3772" endWordPosition="3775">nt opinions. (2) Doc: The 2-stage document-based opinion retrieval model was adopted. The model used sentiment lexicon-based method for opinion identification and a conventional information retrieval method for relevance detection. (3) ROSC: This was the model which achieved the best run in TREC Blog 07. It employed machine learning method to identify opinions for each sentence, and to determine the target topic by a NEAR operator. (4) ROCC: This model was similar to ROSC, but it considered the factor of sentence and regarded the count of relevant opinionated sentence to be the opinion score (Zhang and Yu, 2007). In our experiment, we treated this model as the evaluation baseline. (5) GORM: our proposed graph-based opinion retrieval model. Approach COAE08 Evaluation metrics Run id MAP R-pre bPref P@10 IR 0.2797 0.3545 0.2474 0.4868 Doc 0.3316 0.3690 0.3030 0.6696 ROSC 0.3762 0.4321 0.4162 0.7089 Baseline 0.3774 0.4411 0.4198 0.6931 GORM 0.3978 0.4835 0.4265 0.7309 Table 1: Comparison of different approaches on COAE08 dataset, and the best is highlighted. Most of the above models were originally designed for opinion retrieval in English, and re-designed them to handle Chinese opinionated documents. We</context>
</contexts>
<marker>Zhang, Yu, 2007</marker>
<rawString>Wei Zhang and Clement Yu. 2007. UIC at TREC 2007 Blog Track. In Proceedings of the 15th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhao</author>
</authors>
<title>Hongbo Xu, Xuanjing Huang, Songbo Tan,</title>
<date>2008</date>
<booktitle>In Proceedings of the First Chinese Opinion Analysis Evaluation.</booktitle>
<location>Kang</location>
<marker>Zhao, 2008</marker>
<rawString>Jun Zhao, Hongbo Xu, Xuanjing Huang, Songbo Tan, Kang Liu, and Qi Zhang. 2008. Overview of Chinese Opinion Analysis Evaluation 2008. In Proceedings of the First Chinese Opinion Analysis Evaluation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>