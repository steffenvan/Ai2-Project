<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9982835">
A Competition-Based Explanation of Syntactic Attachment
Preferences and Garden Path Phenomena
</title>
<author confidence="0.995966">
Suzanne Stevenson
</author>
<affiliation confidence="0.9987025">
Department of Computer Science
University of Toronto
</affiliation>
<address confidence="0.763094">
Toronto, Ontario M5S 1A4 Canada
</address>
<email confidence="0.998372">
suzanne@cs.toronto.edu
</email>
<sectionHeader confidence="0.996653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995309">
This paper presents a massively parallel parser that pre-
dicts critical attachment behaviors of the human sentence
processor, without the use of explicit preference heuristics
or revision strategies. The processing of a syntactic am-
biguity is modeled as an active, distributed competition
among the potential attachments for a phrase. Computa-
tionally motivated constraints on the competitive mecha-
nism provide a principled and uniform account of a range
of human attachment preferences and garden path phe-
nomena.
</bodyText>
<sectionHeader confidence="0.918618" genericHeader="method">
1 A Competition-Based Parser
</sectionHeader>
<bodyText confidence="0.999971061538462">
A model of the human parser must explain, among
other factors, the following two aspects of the pro-
cessing of a syntactic ambiguity: the initial attach-
ment preferences that people exhibit, and their abil-
ity or inability to later revise an incorrect attachment.
This paper presents a competition-based parser, CA-
PERS, that predicts critical attachment behaviors of
the human sentence processor, without the use of ex-
plicit preference heuristics or revision strategies. CA-
PERS is a massively parallel network of processing
nodes that represent syntactic phrases and their at-
tachments within a parse tree. A syntactic ambi-
guity leads to a network of alternative attachments
that compete in parallel for numeric activation; an at-
tachment wins over its competitors when it amasses
activation above a certain threshold. The competi-
tion among attachments is achieved solely through
a technique called competition-based spreading ac-
tivation (CBSA) (Reggia 87). The effective use of
CBSA requires restrictions on the syntactic attach-
ments that are allowed to compete simultaneously.
Ensuring these network restrictions necessitates the
further constraint that a stable state of the network
can only represent a single valid parse state. The re-
sulting network structure defines a limited set of corn-
peting attachments that simultaneously define the ini-
tial attachments for the current input phrase, along
with the reanalysis possibilities for phrases previously
structured within the parse tree.
The competitive mechanism and its ensuing restric-
tions have profound consequences for the modeling of
the human sentence processor. Whereas other mod-
els must impose explicit conditions on the parser&apos;s
attachment behavior (Abney 89; Gibson 91; McRoy
&amp; Hirst 90; Pritchett 88), in CAPERS both initial
attachment preferences and reanalyzability are a side
effect of independently motivated computational as-
sumptions. Furthermore, parsing models generally
employ two different computational mechanisms in
determining syntactic attachments: a general parser
to establish the attachment possibilities, and addi-
tional strategies for choosing among them (Abney 89;
Frazier 78; Gibson 91; McRoy &amp; Hirst 90; Shieber
83). By contrast, CAPERS provides a more restric-
tive account, in which a single competitive mechanism
imposes constraints on the parser that determine the
potential attachments, as well as choosing the pre-
ferred attachment from among those.
The competitive mechanism of CAPERS also leads
to an advantageous integration of serialism and paral-
lelism. In order to conform to human memory limita-
tions, other parallel models must be augmented with
a scheme for reducing the number of structures that
are maintained (Gibson 91; Gorrell 87). Such pruning
schemes are unnecessary in CAPERS, since inherent
properties of the competitive mechanism lead to a re-
striction to maintain a single parse state. However,
in spite of this serial aspect, CAPERS is not a sim-
ple serial model. The network incorporates each in-
put phrase through a parallel atomic operation that
determines both the initial attachment for the cur-
rent phrase and any revision of earlier attachments.
Thus, CAPERS avoids the problems of purely serial
or race-based models that rely on backtracking, which
is cognitively implausible, or explicit revision strate-
</bodyText>
<page confidence="0.995948">
266
</page>
<bodyText confidence="0.999953705882353">
gies, which can be unrestrictive (Abney 89; Frazier
78; Inoue k Fodor 92; McRoy Si Hirst 90; Pritchett
88).
Other work (Stevenson 93b, 90) describes the de-
tailed motivation for the CAPERS model, its expla-
nation of serial and parallel effects in human parsing,
and its predictions of a broad range of human attach-
ment preferences. This paper focuses on the competi-
tive mechanism described above. Section 2 briefly de-
scribes the implementation of the parser.I Section 3
discusses the constraints on the network structure,
and Section 4 demonstrates the consequences of these
constraints for the processing of attachment ambigui-
ties. Section 5 summarizes how the competitive mech-
anism provides a principled and uniform account of
the example human attachment preferences and gar-
den path phenomena.
</bodyText>
<sectionHeader confidence="0.96346" genericHeader="method">
2 The Parsing Network
</sectionHeader>
<bodyText confidence="0.975395212121212">
CAPERS dynamically creates the parsing network by
allocating processing nodes in response to the input.
Control of the parse is distributed among these nodes,
which make attachment decisions solely on the basis
of the local communication of simple symbolic fea-
tures and numeric activation. The symbolic informa-
tion determines the grammaticality of potential at-
tachments, while numeric activation weighs the rela-
tive strengths of the valid alternatives. The spread-
ing activation process allows the network to gradually
settle on a set of winning attachments that form a
globally consistent parse tree.
Building the Network
When an input token is read, the parser activates a set
of phrasal nodes, or p-nodes, from a pool of X tem-
plates; their symbolic features are initialized based
on the input token&apos;s lexical entry. Figure 1 shows a
sample X template and its instantiation. Syntactic
phrases are only allocated in response to explicit evi-
dence in the input; top-down hypothesizing of phrases
is disallowed because it greatly increases the complex-
ity of the network. Next, the parser allocates process-
ing nodes to represent the potential attachments be-
tween the current input phrase and the existing parse
tree. Attachment nodes, or a-nodes, are established
between potential sisters in the parse tree; each a-
node connects to exactly two p-nodes, as shown in
Figure 2. (In all figures, a-nodes are shown as squares,
which are black when the a-node is fully activated.)
Once the current phrase is connected to the existing
network, each processing node iteratively updates its
&apos;CAPERS is implemented in Common Lisp, serially simu-
lating the parallel processing of the network.
</bodyText>
<equation confidence="0.721664">
has Case: has_Case: •none*
has_catogory:____ has_category: V
selects_category:_ selects_category: •none*
assigns_Case: assigns_Case: Acc
assigns theta assigns_theta: theme
selects_category:_ selects_category: (N I C)
expect
</equation>
<figureCaption confidence="0.994404">
Figure 1: An X template and sample instantiation.
</figureCaption>
<figure confidence="0.99720025">
(b)
0
0
attachment nodes-----&amp;quot;&amp;quot;
</figure>
<figureCaption confidence="0.979283">
Figure 2: (a) The basic configuration of a phrase in
X theory. (b) Representation of these attachments as
sister relations in CAPERS.
</figureCaption>
<bodyText confidence="0.998813064516129">
symbolic features and numeric activation, and out-
puts them to its neighbors. This network processing
loop continues until the activation level of each a-node
is either above a certain threshold 0, or is zero.2 The
set of active a-nodes in this stable state represents the
current parse tree structure. At this point, the next
input token is read and the process is repeated.
Grammaticality of Attachments
Unlike other connectionist parsers (Cottrell 89; Fanty
85; Selman Az Hirst 85), CAPERS is a hybrid model
whose limited symbolic processing abilities support
the direct representation of the grammar of a cur-
rent linguistic theory. In Government-Binding theory
(GB) (Chomsky 81, 86; Rizzi 90), the validity of syn-
tactic structures is achieved by locally satisfying the
grammatical constraints among neighboring syntac-
tic phrases. CAPERS directly encodes this formula-
tion of linguistic knowledge as a set of simultaneous
local constraints. Symbolic features are simple at-
tribute/value pairs, with the attributes corresponding
to grammatical entities such as Case and theta roles.
The values that these attributes can assume are taken
from a pre-defined list of atoms. GB constraints are
implemented as equality tests on the values of cer-
tain attributes. For example, the Case Filter in GB
states that every NP argument must receive Case. In
CAPERS, this is stated as a condition that the at-
tribute Case must receive a value when the attribute
Category equals Noun and the attribute IsArgument
equals True.
An a-node receives symbolic features from its p-
</bodyText>
<footnote confidence="0.828248">
2The network always stabilizes in less than 100 iterations.
</footnote>
<figure confidence="0.936041333333333">
(a)
267
Sara
</figure>
<figureCaption confidence="0.672881333333333">
Figure 3: The NP can attach as a sister to the V or the
I&apos;. The attachment to the V has a higher grammatical
state value, and thus a higher initial activation level.
</figureCaption>
<bodyText confidence="0.998837064516129">
nodes, which are used to determine the grammatical-
ity of the attachment. If an a-node receives incom-
patible features from its two p-nodes, then it is an in-
valid attachment and it becomes inactive. Otherwise,
it tests the equality conditions that were developed
to encode the following subset of GB constraints: the
Theta Criterion, the Case Filter, categorial selection,
and the binding of traces. The algorithm outputs a
numeric representation of the degree to which these
grammatical constraints are satisfied; this state value
is used in determining the a-node&apos;s activation level.
Choosing Preferred Attachments
Multiple grammatical attachments may exist for a
phrase, as in Figure 3. The network&apos;s task is to focus
activation onto a subset of the grammatical attach-
ments that form a consistent parse tree for the input
processed thus far. Attachment alternatives must be
made to effectively compete with each other for nu-
meric activation, in order to ensure that some a-nodes
become highly activated and others have their activa-
tion suppressed. There are two techniques for pro-
ducing competitive behavior in a connectionist net-
work. The traditional method is to insert inhibitory
links between pairs of competing nodes. Competition-
based spreading activation (CBSA) is a newer tech-
nique that achieves competitive behavior indirectly:
competing nodes vie for output from a common neigh-
bor, which allocates its activation between the com-
petitors. In a CBSA function, the output of a node is
based on the activation levels of its neighbors, as in
equation I.
</bodyText>
<listItem confidence="0.584828666666667">
aak (1)
•
Ojz =
</listItem>
<bodyText confidence="0.979808976744186">
where:
ojj is the output from node ni to node n ;
is the activation of node ni;
ranges over all nodes connected to node ni.
For reasons of space efficiency, flexibility, and cogni-
tive plausibility (Reggia et al. 88), CBSA was adopted
as the means for producing competitive behavior
among the a-nodes in CAPERS. Each p-node uses a
CBSA function to allocate output activation among
its a-nodes, proportional to their current activation
level. For example, the NP node in Figure 3 will send
more of its output to the attachment to the V node
than to the I&apos; node. The CBSA function is designed
so that in a stable state of the network, each p-node
activates a number of a-nodes in accordance with its
grammatical properties. Since every XP must have a
parent in the parse tree, all XP nodes must activate
exactly one a-node. An X or X&apos; node must activate
a number of a-nodes equal to the number of comple-
ments or specifiers, respectively, that it licenses. The
a-nodes enforce consistency among the p-nodes&apos; indi-
vidual attachment decisions: each a-node numerically
ANDs together the input from its two p-nodes to en-
sure that they agree to activate the attachment.
A p-node that has obligatory attachments must at
all times activate the appropriate number of a-nodes
in order for the network to stabilize. However, since
the phrase(s) that the p-node will attach to may oc-
cur later in the input, the parser needs a way to rep-
resent a &amp;quot;null&amp;quot; attachment to act as a placeholder
for the p-node&apos;s eventual sister(s). For this purpose,
the model uses processing nodes called phi-nodes to
represent a &amp;quot;dummy&amp;quot; phrase in the tree.&apos; Every X
and X&apos; node has an a-node that connects to a phi-
node, allowing the possibility of a null attachment. A
phi-node communicates default symbolic information
to its a-node, with two side effects. The a-node is
always grammatically valid, and therefore represents
a default attachment for the p-node it connects to.
But, the default information does not fully satisfy the
grammatical constraints of the a-node, thereby lower-
ing its activation level and making it a less preferred
attachment alternative.
</bodyText>
<sectionHeader confidence="0.93072" genericHeader="method">
3 Restrictions on the Network
</sectionHeader>
<bodyText confidence="0.999817545454545">
The competitive mechanism presented thus far is in-
complete. If all possible attachments are established
between the current phrase and the existing network,
CBSA cannot ensure that the set of active a-nodes
forms a consistent parse tree. CBSA can weed out
locally incompatible a-nodes by requiring that each
p-node activate the grammatically appropriate num-
ber of a-nodes, but it cannot rule out the simulta-
neous activation of certain incompatible attachments
that are farther apart in the tree. Figure 4 shows the
types of structures in which CBSA is an insufficient
</bodyText>
<footnote confidence="0.825716">
3 Phi-nodes also represent the traces of displaced phrases in
the parse tree; see (Stevenson 93a, 93b).
</footnote>
<figure confidence="0.969737125">
O state-.7
act-.175
0
expect to
state-.9
act=.225
268
(b)
</figure>
<figureCaption confidence="0.973334333333333">
Figure 4: Example pairs of incompatible attachments
that CBSA alone cannot prevent from being active
simultaneously.
</figureCaption>
<bodyText confidence="0.998095325581395">
competitive mechanism. Both cases involve violations
of the proper nesting structure of a parse tree. Since
CBSA cannot rule out these invalid structures, the
parsing network must be restricted to prevent these
attachment configurations. The parser could insert
inhibitory links between all pairs of incompatible a-
nodes, but this increases the complexity of the net-
work dramatically. The decision was made to instead
reduce the size and connectedness of the network, si-
multaneously solving the tree structuring problems,
by only allowing attachments between the current
phrase and the right edge of the existing parse tree.
Limiting the attachment of the current phrase to
the right edge of the parse tree rules out all of the
problematic cases represented by Figure 4(a). In-
terestingly, the restriction leads to a solution for the
cases of Figure 4(b) as well. Since there is no global
controller, each syntactic phrase that is activated
must be connected to the existing network so that
it can participate in the parse. However, sometimes
a phrase cannot attach to the existing parse tree; for
example, a subject in English attaches to an inflec-
tion phrase (IP) that follows it. The network con-
nections between these unattached phrases must be
maintained as a stack; this ensures that the current
phrase can only establish attachments to the right
edge of an immediately preceding subtree. The stack
mechanism in CAPERS is implemented as shown in
Figure 5: a phrase pushes itself onto the stack when
its XP node activates an a-node between it and a spe-
cially designated stack node. Because the stack can-
not satisfy grammatical constraints, stack node at-
tachments are only activated if no other attachment
is available for the XP. The flexibility of CBSA al-
lows the stack to activate more than one a-node, so
that multiple phrases can be pushed onto it. The sur-
prising result is that, by having the stack establish a-
nodes that compete for activation like normal attach-
ments, the indirect competitive relationships within
the network effectively suppress all inconsistent at-
tachment possibilities, including those of Figure 4(b).
This result relies on the fact that any incompatible
a-nodes that are created either directly or indirectly
</bodyText>
<figureCaption confidence="0.9376535">
Figure 5: The stack is implemented as a degenerate
p-node that can activate attachments to XP nodes.
Figure 6: Attachments a1—a4 were previously acti-
vated. To attach the current phrase to the tree on
</figureCaption>
<bodyText confidence="0.92195465">
the stack, the following must occur: exactly one of the
prior attachments, ai, must become inactive, and the
corresponding pair of attachments, pi, must become
active. This relationship holds for a tree of arbitrary
depth on the stack.
compete with each other through CBSA. To guaran-
tee this condition, all inactive a-nodes must be deleted
after the network settles on the attachments for each
phrase. Otherwise, losing a-nodes could become acti-
vated later in the parse, when the network is no longer
in a configuration in which they compete with their
incompatible alternatives. Since losing a-nodes are
deleted, CAPERS maintains only a single valid parse
state at any time.
The use of CBSA, and the adoption of a stack mech-
anism to support this, strongly restrict the attach-
ments that can be considered by the parser. The only
a-nodes that can compete simultaneously are those
in the set of attachments between the current phrase
and the tree on top of the stack. The competitive
</bodyText>
<figure confidence="0.970794555555556">
current
phrase
stack
of
partial
parse trees
tree on
top of
stack
current
phrase
top /
of
stack
04
(a)
269
expect
</figure>
<figureCaption confidence="0.999797">
Figure 7: The network after attaching the NP Sara.
</figureCaption>
<figure confidence="0.393957">
Sara
</figure>
<figureCaption confidence="0.890768">
Figure 8: A-nodes a2 and a3 define the necessary at-
</figureCaption>
<bodyText confidence="0.967165538461539">
tachments for the current phrase.
relationships among the allowed a-nodes completely
define the sets of a-nodes that can be simultaneously
active in a stable state of the network. These logi-
cal attachment possibilities, shown in Figure 6, fol-
low directly from the propagation of local competi-
tions among the a-nodes due to CBSA. In over 98%
of the approximately 1400 simulations of attachment
decisions in CAPERS, the network stabilized on one
of these attachment sets (Stevenson 93b). The com-
petitive mechanism of CAPERS thus determines a
circumscribed set of attachment possibilities for both
initial and revised attachments in the parser.
</bodyText>
<sectionHeader confidence="0.985298" genericHeader="method">
4 Parsing Attachment Ambiguities
</sectionHeader>
<bodyText confidence="0.998109333333333">
This section demonstrates the processing of CAPERS
on example attachment ambiguities from the sentence
processing literature.4 In sentence (1), the parser is
</bodyText>
<footnote confidence="0.715874">
4A more complete presentation of CAPERS&apos; explanation of
</footnote>
<figure confidence="0.765753">
to
Sara
</figure>
<figureCaption confidence="0.8213362">
Figure 9: The misattachment of the NP to the V has
been revised.
faced with a noun phrase/sentential complement am-
biguity at the post-verbal NP Sara:
(1) Mary expected Sara to leave.
</figureCaption>
<bodyText confidence="0.971132521739131">
People show a Minimal Attachment preference to at-
tach the NP as the complement of the verb, but have
no conscious difficulty in processing the continuation
of the sentence (Frazier &amp; Rayner 82; Gorrell 87).
The CAPERS network after attaching Sara is shown
in Figure 7.5 The NP has valid attachments to the
stack (ao) and to the V (a1). Since the default stack
attachment is less competitive, a-node al is highly
activated. This initial attachment accounts for the
observed Minimal Attachment preferences. Next, the
word to projects an IP; its initial connections to the
network are shown in Figure 8.6 The same set of a-
nodes that define the initial attachment possibilities
for the current IP phrase, a2 and a3, simultaneously
define the revised attachment necessary for the NP
Sara. A-node al competes with a2 and a3 for the ac-
tivation from the V and NP nodes, respectively; this
competition draws activation away from al. When
the network stabilizes, a2 and a3 are highly active
and al has become inactive, resulting in the tree of
Figure 9. In a single atomic operation, the network
these and related psycholinguistic data can be found in (Steven-
son 93b).
</bodyText>
<footnote confidence="0.772761666666667">
5Note that a tensed verb such as expected projects a full
sentential structure—that is, CP/IP/VP—as in (Abney 86),
although the figures here are simplified by omitting display of
the CP of root clauses.
&apos;In this and the remaining figures, granunatically invalid
a-nodes and irrelevant phi-nodes are not shown.
</footnote>
<figure confidence="0.99349071875">
current
phrase
Mary
current
phrase
past to
Mary
top/of
stack
expect
expect
top
of
stack
270
0
111 1111141%1422&amp;quot; 0° current
phrase
11
0
0 0 0
0
O0 0
O 0 0 • 0
Present
O Present 0 el
Kiva
eat
current
phrase
food
When
</figure>
<figureCaption confidence="0.984192">
eat top / food
Figure 10: The NP food has a single valid attachment of
to the parse tree. stack
</figureCaption>
<bodyText confidence="0.981017565217391">
has revised its earlier attachment hypothesis for the
NP and incorporated the new IP phrase into the parse
tree.
Sentence (2), an example of Late Closure effects, is
initially processed in a similar fashion:
(2) When Kiva eats food gets thrown.
After attaching food, the network has the configura-
tion shown in Figure 10. As in sentence (1), the post-
verbal NP makes the best attachment available to it,
as the complement of the verb. This behavior is again
consistent with the initial preferences of the human
sentence processor (Frazier &amp; Rayner 82). Since the
initial attachment in these cases of Late Closure is de-
termined in exactly the same manner as the Minimal
Attachment cases illustrated by sentence (1), these
two classic preferences receive a uniform account in
the CAPERS model.
Additional processing of the input distinguishes the
sentence types. At gets, a sentential phrase is pro-
jected, and the network settles on the attachments
shown in Figure 11. As in Figure 8, the revision nec-
essary for a valid parse involves the current phrase
and the right edge of the tree. However, in this case,
the misattached NP cannot break its attachment to
the verb and reattach as the specifier of the IP. The
difference from the prior example is that here the V
node has no other a-node to redirect its output to, and
so it continues to activate the NP attachment. The
attachment of the NP to the I&apos; is not strong enough
by itself to draw activation away from the attachment
of the NP to the V. The current I&apos; thus activates the
default phi-node attachment, leading to a clause with
Figure 11: The attachment of the NP food to the I&apos;
is not strong enough to break the attachment of the
NP to the V.
an empty (and unbound) subject. Since the network
settles on an irrecoverably ungrammatical analysis,
CAPERS correctly predicts a garden path.
The next two examples, adapted from (Pritchett
88), involve double object verbs; both types of sen-
tences clearly garden path the human sentence pro-
cessor. In each case, the second post-verbal NP is
the focus of attention. In sentence (3), this NP is the
subject of a relative clause modifying the first NP,
but the parser misinterprets it as the verb&apos;s second
complement:
</bodyText>
<listItem confidence="0.643944">
(3) Jamie gave the child the dog bit a bandaid.
</listItem>
<bodyText confidence="0.996430125">
The initial connections of the NP the dog to the net-
work are shown in Figure 12. The NP can either push
itself onto the stack, or replace the null attachment
of the verb to the phi-node. Since both stack attach-
ments and phi-node attachments are relatively weak,
the NP attachment to the V wins the a-node competi-
tion, and the network settles on the tree in Figure 13.
In accordance with human preferences, the NP is at-
tached as the second object of the verb. When bit
is processed, the network settles on the configuration
in Figure 14. As in the earlier examples, the misat-
tached NP needs to attach as the subject of the cur-
rent clause; however, this would leave the V node with
only one a-node to activate instead of its required two
attachments. CAPERS again settles on an ungram-
matical analysis in which the current clause has an
</bodyText>
<page confidence="0.987863">
271
</page>
<figure confidence="0.996171548387097">
the
421:0 current
phrase
0
CO
000
s
past
o i dog
the child
Jamie
top
of
stack
give
Jamie
top
of
stack
OM, o0
•. current
0e
)n
t
phrase
00i0i0 o0
CD
dog
past
past
the child the
</figure>
<figureCaption confidence="0.99836125">
Figure 12: The initial connections of the NP the dog
to the network.
Figure 13: The NP the dog attaches as the verb&apos;s
second complement.
</figureCaption>
<bodyText confidence="0.9596628">
empty (unbound) subject, consistent with the garden
path effect of this sentence.
The second example with a double object verb in-
volves the opposite problem. In sentence (4), the sec-
ond post-verbal NP is mistakenly interpreted as part
of the first object; in a complete parse, it is part of
the second object:
(4) I convinced her children are noisy.
Initially, the parser attaches her as the NP object
of convinced. The structure of the network after at-
tachment of children is shown in Figure 15. The NP
children cannot replace the phi-node attachment to
the verb, since the second object of convince must be
Figure 14: If the NP the dog activates the attachment
to the I&apos;, the V node would be left with only one active
attachment.
sentential. In order to maximally satisfy the attach-
ment preferences, her is reanalyzed as the specifier of
children, with her children replacing her as the first
object of convinced. This reanalysis is structurally
the same as that required in Figure 8; the relevant a-
nodes have been numbered the same in each figure to
highlight the similarity. Problems arise when the net-
work attaches the next input word, are; see Figure 16.
Once again, the misattached NP needs to attach as
the specifier of the following sentential phrase, but
a V node would be left with only one active a-node
when it requires two. A garden path once more re-
sults from the network settling on an ungrammatical
analysis.
This example highlights another aspect of the com-
petitive mechanism of CAPERS in driving the attach-
ment behavior of the parser: the only way a pre-
vious attachment can be broken is if it participates
in a competition with an attachment to the current
phrase. A correct parse requires her to break its at-
tachment to children and re-attach directly to the
verb. Because the a-node attaching her to children
has no competitor, there is no mechanism for chang-
ing the problematic attachment.
</bodyText>
<sectionHeader confidence="0.997517" genericHeader="conclusions">
5 Summary
</sectionHeader>
<bodyText confidence="0.999965666666667">
In each of the examples of Section 4, the initial attach-
ment of a phrase was incompatible with the remain-
der of the sentence. CAPERS can recover from an
attachment error of this type exactly when the mis-
attached phrase can reattach to the current phrase,
with the current phrase &amp;quot;replacing&amp;quot; the misattached
</bodyText>
<figure confidence="0.577448833333333">
Jamie
top
of
stack
272
her
</figure>
<figureCaption confidence="0.955619">
Figure 15: Attaching the NP children requires reanal-
ysis of the NP her.
</figureCaption>
<bodyText confidence="0.8986469375">
children
her
Figure 16: If the NP headed by children activates
the attachment to the I&apos;, the V node would be left
without an NP complement.
phrase in its original attachment site. If the p-node to
which the misattached phrase was originally attached
does not have an alternative a-node to activate, re-
analysis cannot take place and a garden path results.
The allowable attachment configurations are a direct
consequence of the restrictions imposed by the com-
petitive mechanism of CAPERS. The resulting initial
attachment preferences, and the parser&apos;s ability or in-
ability to revise the incorrect structure, account for
the preferred readings of these temporarily ambigu-
ous sentences, as well as the garden path results.
</bodyText>
<sectionHeader confidence="0.988233" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999767928571429">
Abney, S. (1986). &amp;quot;Functional elements and licensing.&amp;quot; GLOW
Conference, Gerona, Spain.
Abney, S. (1989). &amp;quot;A computational model of human parsing.&amp;quot;
Journal of Psycholinguistic Research 18:1, 129-144.
Chomsky, N. (1981). Lectures on Government and Binding: The
Pisa Lectures. Dordrecht: Foris Publications.
Chomsky, N. (1986). Barriers. Cambridge: MIT Press
Cottrell, G. W. (1989). A Connectionist Approach to Word Sense
Disambiguation. Los Altos, CA: Morgan Kaufmann.
Fanty, M. (1985). &amp;quot;Context-free parsing in connectionist net-
works.&amp;quot; Technical Report TR174, University of Rochester.
Frazier, L. (1978). On Comprehending Sentences: Syntactic
Parsing Strategies. Doctoral dissertation, University of Connecti-
cut. Bloomington, IN: Indiana University Linguistics Club.
Frazier, L., and K. Rayner (1982). &amp;quot;Making and correcting errors
during sentence comprehension: Eye movements in the analysis of
structurally ambiguous sentences.&amp;quot; Cognitive Psychology 14, 178-
210.
Gibson, E. (1991). &amp;quot;A Computational Theory of Human Linguis-
tic Processing: Memory Limitations and Processing Breakdown.&amp;quot;
Doctoral dissertation, Carnegie-Mellon University.
Gorrell, P. (1987). &amp;quot;Studies of Human Syntactic Processing:
Ranked-Parallel versus Serial Models.&amp;quot; Unpublished doctoral dis-
sertation, University of Connecticut, Storrs, CT.
Inoue, A. and J. Fodor (1992). &amp;quot;Information-paced parsing of
Japanese.&amp;quot; Presented at the Fifth Annual CUNY Conference on
Human Sentence Processing, New York.
McRoy, S. and G. Hirst (1990). &amp;quot;Race-Based Parsing and Syntactic
Disambiguation.&amp;quot; Cognitive Science 14, 313-353.
Pritchett, B. (1988). &amp;quot;Garden Path Phenomena and the Grammat-
ical Basis of Language Processing.&amp;quot; Language 64:3, 539-576.
Rizzi, L. (1990). Relativized Minimality. Cambridge: MIT Press.
Reggia, J. (1987). &amp;quot;Properties of a Competition-Based Activation
Mechanism in Neuromimetic Network Models.&amp;quot; Proceedings of the
First International Conference on Neural Networks, San Diego,
11-131-11-138.
Reggia, J., P. Marsland, and R. Berndt (1988). &amp;quot;Competitive Dy-
namics in a Dual-Route Connectionist Model of Print-to-Sound
Transformation.&amp;quot; Complex Systems.
Selman, G., and G. Hirst (1985). &amp;quot;A Rule-Based Connectionist
Parsing Scheme.&amp;quot; Proceedings of the Seventh Annual Conference
of the Cognitive Science Society, 212-219.
Shieber, S. (1983). &amp;quot;Sentence Disambiguation by a Shift-Reduce
Parsing Technique.&amp;quot; Proceedings of the 21st Annual Meeting of
the Association for Computational Linguistics, 113-118.
Stevenson, S. (1993a). &amp;quot;Establishing Long-Distance Dependencies
in a Hybrid Network Model of Human Parsing.&amp;quot; Proceedings of
the 15th Annual Conference of the Cognitive Science Society.
Stevenson, S. (1993b). &amp;quot;A Constrained Active Attachment Model
for Resolving Syntactic Ambiguities in Natural Language Parsing.&amp;quot;
Doctoral dissertation, Computer Science Department, University of
Maryland, College Park.
Stevenson, S. (1990). &amp;quot;A Parallel Constraint Satisfaction and
Spreading Activation Model for Resolving Syntactic Ambiguity.&amp;quot;
Proceedings of the Twelfth Annual Conference of the Cognitive
Science Society, 396-403.
</reference>
<figure confidence="0.9992208125">
current
phrase
past children
top /
ot
stack
convince
top /
ot
stack
convince
present
current
phrase
/I
past
</figure>
<page confidence="0.984423">
273
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000048">
<title confidence="0.9938035">A Competition-Based Explanation of Syntactic Attachment Preferences and Garden Path Phenomena</title>
<author confidence="0.999033">Suzanne Stevenson</author>
<affiliation confidence="0.99998">Department of Computer Science University of Toronto</affiliation>
<address confidence="0.996068">Toronto, Ontario M5S 1A4 Canada</address>
<email confidence="0.999917">suzanne@cs.toronto.edu</email>
<abstract confidence="0.984629757990868">This paper presents a massively parallel parser that predicts critical attachment behaviors of the human sentence processor, without the use of explicit preference heuristics or revision strategies. The processing of a syntactic ambiguity is modeled as an active, distributed competition among the potential attachments for a phrase. Computationally motivated constraints on the competitive mechanism provide a principled and uniform account of a range of human attachment preferences and garden path phenomena. 1 A Competition-Based Parser A model of the human parser must explain, among other factors, the following two aspects of the processing of a syntactic ambiguity: the initial attachment preferences that people exhibit, and their ability or inability to later revise an incorrect attachment. This paper presents a competition-based parser, CA- PERS, that predicts critical attachment behaviors of the human sentence processor, without the use of explicit preference heuristics or revision strategies. CA- PERS is a massively parallel network of processing nodes that represent syntactic phrases and their attachments within a parse tree. A syntactic ambiguity leads to a network of alternative attachments that compete in parallel for numeric activation; an attachment wins over its competitors when it amasses activation above a certain threshold. The competition among attachments is achieved solely through a technique called competition-based spreading activation (CBSA) (Reggia 87). The effective use of CBSA requires restrictions on the syntactic attachments that are allowed to compete simultaneously. Ensuring these network restrictions necessitates the further constraint that a stable state of the network can only represent a single valid parse state. The renetwork structure defines a limited set of cornpeting attachments that simultaneously define the initial attachments for the current input phrase, along with the reanalysis possibilities for phrases previously structured within the parse tree. The competitive mechanism and its ensuing restrictions have profound consequences for the modeling of the human sentence processor. Whereas other models must impose explicit conditions on the parser&apos;s attachment behavior (Abney 89; Gibson 91; McRoy &amp; Hirst 90; Pritchett 88), in CAPERS both initial attachment preferences and reanalyzability are a side effect of independently motivated computational assumptions. Furthermore, parsing models generally employ two different computational mechanisms in determining syntactic attachments: a general parser to establish the attachment possibilities, and additional strategies for choosing among them (Abney 89; 78; Gibson 91; McRoy 90; Shieber 83). By contrast, CAPERS provides a more restrictive account, in which a single competitive mechanism imposes constraints on the parser that determine the potential attachments, as well as choosing the preferred attachment from among those. The competitive mechanism of CAPERS also leads to an advantageous integration of serialism and parallelism. In order to conform to human memory limitations, other parallel models must be augmented with a scheme for reducing the number of structures that are maintained (Gibson 91; Gorrell 87). Such pruning schemes are unnecessary in CAPERS, since inherent properties of the competitive mechanism lead to a restriction to maintain a single parse state. However, in spite of this serial aspect, CAPERS is not a simple serial model. The network incorporates each input phrase through a parallel atomic operation that determines both the initial attachment for the current phrase and any revision of earlier attachments. Thus, CAPERS avoids the problems of purely serial or race-based models that rely on backtracking, which cognitively implausible, or explicit revision strate- 266 gies, which can be unrestrictive (Abney 89; Frazier Inoue k Fodor 92; McRoy 90; Pritchett 88). Other work (Stevenson 93b, 90) describes the detailed motivation for the CAPERS model, its explanation of serial and parallel effects in human parsing, and its predictions of a broad range of human attachment preferences. This paper focuses on the competitive mechanism described above. Section 2 briefly dethe implementation of the Section 3 discusses the constraints on the network structure, and Section 4 demonstrates the consequences of these constraints for the processing of attachment ambiguities. Section 5 summarizes how the competitive mechanism provides a principled and uniform account of the example human attachment preferences and garden path phenomena. Parsing Network CAPERS dynamically creates the parsing network by allocating processing nodes in response to the input. Control of the parse is distributed among these nodes, which make attachment decisions solely on the basis of the local communication of simple symbolic features and numeric activation. The symbolic information determines the grammaticality of potential attachments, while numeric activation weighs the relative strengths of the valid alternatives. The spreading activation process allows the network to gradually settle on a set of winning attachments that form a globally consistent parse tree. Building the Network When an input token is read, the parser activates a set of phrasal nodes, or p-nodes, from a pool of X templates; their symbolic features are initialized based on the input token&apos;s lexical entry. Figure 1 shows a sample X template and its instantiation. Syntactic phrases are only allocated in response to explicit evidence in the input; top-down hypothesizing of phrases is disallowed because it greatly increases the complexity of the network. Next, the parser allocates processing nodes to represent the potential attachments between the current input phrase and the existing parse tree. Attachment nodes, or a-nodes, are established potential the parse tree; each anode connects to exactly two p-nodes, as shown in Figure 2. (In all figures, a-nodes are shown as squares, which are black when the a-node is fully activated.) Once the current phrase is connected to the existing network, each processing node iteratively updates its &apos;CAPERS is implemented in Common Lisp, serially simulating the parallel processing of the network. has Case: has_Case: •none* has_catogory:____ has_category: V selects_category:_ selects_category: •none* assigns_Case: assigns_Case: Acc assigns theta assigns_theta: theme selects_category:_ selects_category: (N I C) expect Figure 1: An X template and sample instantiation. (b) 0 0 Figure 2: (a) The basic configuration of a phrase in X theory. (b) Representation of these attachments as sister relations in CAPERS. symbolic features and numeric activation, and outputs them to its neighbors. This network processing loop continues until the activation level of each a-node either above a certain threshold 0, or is The set of active a-nodes in this stable state represents the current parse tree structure. At this point, the next input token is read and the process is repeated. Grammaticality of Attachments Unlike other connectionist parsers (Cottrell 89; Fanty 85; Selman Az Hirst 85), CAPERS is a hybrid model whose limited symbolic processing abilities support the direct representation of the grammar of a current linguistic theory. In Government-Binding theory (GB) (Chomsky 81, 86; Rizzi 90), the validity of syntactic structures is achieved by locally satisfying the grammatical constraints among neighboring syntactic phrases. CAPERS directly encodes this formulation of linguistic knowledge as a set of simultaneous local constraints. Symbolic features are simple attribute/value pairs, with the attributes corresponding to grammatical entities such as Case and theta roles. The values that these attributes can assume are taken from a pre-defined list of atoms. GB constraints are implemented as equality tests on the values of certain attributes. For example, the Case Filter in GB states that every NP argument must receive Case. In CAPERS, this is stated as a condition that the attribute Case must receive a value when the attribute Category equals Noun and the attribute IsArgument equals True. a-node receives symbolic features from its palways stabilizes in less than 100 iterations. (a) 267 Sara Figure 3: The NP can attach as a sister to the V or the I&apos;. The attachment to the V has a higher grammatical state value, and thus a higher initial activation level. nodes, which are used to determine the grammaticality of the attachment. If an a-node receives incompatible features from its two p-nodes, then it is an invalid attachment and it becomes inactive. Otherwise, it tests the equality conditions that were developed to encode the following subset of GB constraints: the Theta Criterion, the Case Filter, categorial selection, and the binding of traces. The algorithm outputs a numeric representation of the degree to which these grammatical constraints are satisfied; this state value is used in determining the a-node&apos;s activation level. Choosing Preferred Attachments Multiple grammatical attachments may exist for a phrase, as in Figure 3. The network&apos;s task is to focus activation onto a subset of the grammatical attachments that form a consistent parse tree for the input processed thus far. Attachment alternatives must be made to effectively compete with each other for numeric activation, in order to ensure that some a-nodes become highly activated and others have their activation suppressed. There are two techniques for producing competitive behavior in a connectionist network. The traditional method is to insert inhibitory links between pairs of competing nodes. Competitionbased spreading activation (CBSA) is a newer technique that achieves competitive behavior indirectly: competing nodes vie for output from a common neighbor, which allocates its activation between the competitors. In a CBSA function, the output of a node is based on the activation levels of its neighbors, as in equation I. • (1) = where: the output from node to node n ; is the activation of node ni; over all nodes connected to node reasons of space efficiency, flexibility, and cognitive plausibility (Reggia et al. 88), CBSA was adopted as the means for producing competitive behavior among the a-nodes in CAPERS. Each p-node uses a CBSA function to allocate output activation among its a-nodes, proportional to their current activation level. For example, the NP node in Figure 3 will send more of its output to the attachment to the V node than to the I&apos; node. The CBSA function is designed so that in a stable state of the network, each p-node activates a number of a-nodes in accordance with its grammatical properties. Since every XP must have a parent in the parse tree, all XP nodes must activate exactly one a-node. An X or X&apos; node must activate a number of a-nodes equal to the number of complements or specifiers, respectively, that it licenses. The a-nodes enforce consistency among the p-nodes&apos; individual attachment decisions: each a-node numerically ANDs together the input from its two p-nodes to ensure that they agree to activate the attachment. A p-node that has obligatory attachments must at all times activate the appropriate number of a-nodes in order for the network to stabilize. However, since the phrase(s) that the p-node will attach to may occur later in the input, the parser needs a way to represent a &amp;quot;null&amp;quot; attachment to act as a placeholder for the p-node&apos;s eventual sister(s). For this purpose, the model uses processing nodes called phi-nodes to represent a &amp;quot;dummy&amp;quot; phrase in the tree.&apos; Every X and X&apos; node has an a-node that connects to a phinode, allowing the possibility of a null attachment. A phi-node communicates default symbolic information to its a-node, with two side effects. The a-node is always grammatically valid, and therefore represents a default attachment for the p-node it connects to. But, the default information does not fully satisfy the grammatical constraints of the a-node, thereby lowering its activation level and making it a less preferred attachment alternative. on the Network The competitive mechanism presented thus far is incomplete. If all possible attachments are established between the current phrase and the existing network, CBSA cannot ensure that the set of active a-nodes forms a consistent parse tree. CBSA can weed out locally incompatible a-nodes by requiring that each p-node activate the grammatically appropriate number of a-nodes, but it cannot rule out the simultaneous activation of certain incompatible attachments that are farther apart in the tree. Figure 4 shows the types of structures in which CBSA is an insufficient 3Phi-nodes also represent the traces of displaced phrases in the parse tree; see (Stevenson 93a, 93b). act-.175 0 expect to state-.9 act=.225 268 (b) Figure 4: Example pairs of incompatible attachments that CBSA alone cannot prevent from being active simultaneously. competitive mechanism. Both cases involve violations of the proper nesting structure of a parse tree. Since CBSA cannot rule out these invalid structures, the parsing network must be restricted to prevent these attachment configurations. The parser could insert inhibitory links between all pairs of incompatible anodes, but this increases the complexity of the network dramatically. The decision was made to instead size and connectedness of the network, simultaneously solving the tree structuring problems, by only allowing attachments between the current phrase and the right edge of the existing parse tree. Limiting the attachment of the current phrase to the right edge of the parse tree rules out all of the problematic cases represented by Figure 4(a). Interestingly, the restriction leads to a solution for the cases of Figure 4(b) as well. Since there is no global controller, each syntactic phrase that is activated must be connected to the existing network so that it can participate in the parse. However, sometimes a phrase cannot attach to the existing parse tree; for example, a subject in English attaches to an inflection phrase (IP) that follows it. The network connections between these unattached phrases must be maintained as a stack; this ensures that the current phrase can only establish attachments to the right edge of an immediately preceding subtree. The stack mechanism in CAPERS is implemented as shown in Figure 5: a phrase pushes itself onto the stack when its XP node activates an a-node between it and a specially designated stack node. Because the stack cannot satisfy grammatical constraints, stack node attachments are only activated if no other attachment is available for the XP. The flexibility of CBSA allows the stack to activate more than one a-node, so that multiple phrases can be pushed onto it. The surprising result is that, by having the stack establish anodes that compete for activation like normal attachments, the indirect competitive relationships within the network effectively suppress all inconsistent attachment possibilities, including those of Figure 4(b). This result relies on the fact that any incompatible a-nodes that are created either directly or indirectly Figure 5: The stack is implemented as a degenerate p-node that can activate attachments to XP nodes. 6: Attachments were previously activated. To attach the current phrase to the tree on the stack, the following must occur: exactly one of the prior attachments, ai, must become inactive, and the pair of attachments, become active. This relationship holds for a tree of arbitrary depth on the stack. compete with each other through CBSA. To guarantee this condition, all inactive a-nodes must be deleted after the network settles on the attachments for each phrase. Otherwise, losing a-nodes could become activated later in the parse, when the network is no longer in a configuration in which they compete with their incompatible alternatives. Since losing a-nodes are deleted, CAPERS maintains only a single valid parse state at any time. The use of CBSA, and the adoption of a stack mechanism to support this, strongly restrict the attachments that can be considered by the parser. The only a-nodes that can compete simultaneously are those in the set of attachments between the current phrase and the tree on top of the stack. The competitive current phrase stack of partial parse trees tree on top of stack current phrase top / of stack (a) 269 expect 7: The network after attaching the NP Sara 8: A-nodes and define the necessary attachments for the current phrase. relationships among the allowed a-nodes completely define the sets of a-nodes that can be simultaneously active in a stable state of the network. These logical attachment possibilities, shown in Figure 6, follow directly from the propagation of local competitions among the a-nodes due to CBSA. In over 98% of the approximately 1400 simulations of attachment decisions in CAPERS, the network stabilized on one of these attachment sets (Stevenson 93b). The competitive mechanism of CAPERS thus determines a circumscribed set of attachment possibilities for both initial and revised attachments in the parser. Attachment Ambiguities This section demonstrates the processing of CAPERS on example attachment ambiguities from the sentence In sentence (1), the parser is complete presentation of CAPERS&apos; explanation of to Sara Figure 9: The misattachment of the NP to the V has been revised. faced with a noun phrase/sentential complement amat the post-verbal NP (1) Mary expected Sara to leave. People show a Minimal Attachment preference to attach the NP as the complement of the verb, but have no conscious difficulty in processing the continuation the sentence (Frazier 82; Gorrell 87). CAPERS network after attaching shown Figure The NP has valid attachments to the stack (ao) and to the V (a1). Since the default stack is less competitive, a-node is highly activated. This initial attachment accounts for the observed Minimal Attachment preferences. Next, the an IP; its initial connections to the are shown in Figure The same set of anodes that define the initial attachment possibilities the current IP phrase, and simultaneously define the revised attachment necessary for the NP competes with a2 and for the activation from the V and NP nodes, respectively; this competition draws activation away from al. When network stabilizes, and are highly active has become inactive, resulting in the tree of Figure 9. In a single atomic operation, the network these and related psycholinguistic data can be found in (Stevenson 93b). that a tensed verb such as a full sentential structure—that is, CP/IP/VP—as in (Abney 86), although the figures here are simplified by omitting display of the CP of root clauses. &apos;In this and the remaining figures, granunatically invalid a-nodes and irrelevant phi-nodes are not shown. current phrase Mary current phrase past to Mary stack expect top of stack 270 0 0° current phrase</abstract>
<note confidence="0.74031475">0 0 0 0 0 O0 0 O 0 0 • 0 Present Present 0 Kiva</note>
<abstract confidence="0.997954947674418">eat current phrase food When eat top / of food 10: The NP a single valid attachment to the parse tree. stack has revised its earlier attachment hypothesis for the NP and incorporated the new IP phrase into the parse tree. Sentence (2), an example of Late Closure effects, is initially processed in a similar fashion: (2) When Kiva eats food gets thrown. attaching network has the configuration shown in Figure 10. As in sentence (1), the postverbal NP makes the best attachment available to it, as the complement of the verb. This behavior is again consistent with the initial preferences of the human sentence processor (Frazier &amp; Rayner 82). Since the initial attachment in these cases of Late Closure is determined in exactly the same manner as the Minimal Attachment cases illustrated by sentence (1), these two classic preferences receive a uniform account in the CAPERS model. Additional processing of the input distinguishes the types. At sentential phrase is projected, and the network settles on the attachments shown in Figure 11. As in Figure 8, the revision necessary for a valid parse involves the current phrase and the right edge of the tree. However, in this case, the misattached NP cannot break its attachment to the verb and reattach as the specifier of the IP. The difference from the prior example is that here the V node has no other a-node to redirect its output to, and so it continues to activate the NP attachment. The attachment of the NP to the I&apos; is not strong enough by itself to draw activation away from the attachment of the NP to the V. The current I&apos; thus activates the default phi-node attachment, leading to a clause with 11: The attachment of the NP the I&apos; is not strong enough to break the attachment of the NP to the V. an empty (and unbound) subject. Since the network settles on an irrecoverably ungrammatical analysis, CAPERS correctly predicts a garden path. The next two examples, adapted from (Pritchett 88), involve double object verbs; both types of sentences clearly garden path the human sentence processor. In each case, the second post-verbal NP is the focus of attention. In sentence (3), this NP is the subject of a relative clause modifying the first NP, but the parser misinterprets it as the verb&apos;s second complement: (3) Jamie gave the child the dog bit a bandaid. initial connections of the NP dog the network are shown in Figure 12. The NP can either push itself onto the stack, or replace the null attachment of the verb to the phi-node. Since both stack attachments and phi-node attachments are relatively weak, the NP attachment to the V wins the a-node competition, and the network settles on the tree in Figure 13. In accordance with human preferences, the NP is atas the second object of the verb. When is processed, the network settles on the configuration in Figure 14. As in the earlier examples, the misattached NP needs to attach as the subject of the current clause; however, this would leave the V node with only one a-node to activate instead of its required two attachments. CAPERS again settles on an ungrammatical analysis in which the current clause has an 271 the 421:0 current phrase 0 CO s past the child Jamie top of stack give Jamie top of stack OM,o0 •. current t phrase o0 CD dog past past the child the 12: The initial connections of the NP dog to the network. 13: The NP dog as the verb&apos;s second complement. empty (unbound) subject, consistent with the garden path effect of this sentence. The second example with a double object verb involves the opposite problem. In sentence (4), the second post-verbal NP is mistakenly interpreted as part of the first object; in a complete parse, it is part of the second object: (4) I convinced her children are noisy. the parser attaches the NP object structure of the network after atof shown in Figure 15. The NP replace the phi-node attachment to verb, since the second object of be 14: If the NP dog the attachment to the I&apos;, the V node would be left with only one active attachment. sentential. In order to maximally satisfy the attachpreferences, reanalyzed as the specifier of children the first of reanalysis is structurally the same as that required in Figure 8; the relevant anodes have been numbered the same in each figure to highlight the similarity. Problems arise when the netattaches the next input word, Figure 16. Once again, the misattached NP needs to attach as the specifier of the following sentential phrase, but a V node would be left with only one active a-node when it requires two. A garden path once more results from the network settling on an ungrammatical analysis. This example highlights another aspect of the competitive mechanism of CAPERS in driving the attachment behavior of the parser: the only way a previous attachment can be broken is if it participates in a competition with an attachment to the current A correct parse requires break its atto re-attach directly to the Because the a-node attaching has no competitor, there is no mechanism for changing the problematic attachment. In each of the examples of Section 4, the initial attachment of a phrase was incompatible with the remainder of the sentence. CAPERS can recover from an attachment error of this type exactly when the misattached phrase can reattach to the current phrase, with the current phrase &amp;quot;replacing&amp;quot; the misattached Jamie top of stack 272 her 15: Attaching the NP reanalof the NP children her 16: If the NP headed by attachment to the V node would be left without an NP complement. phrase in its original attachment site. If the p-node to which the misattached phrase was originally attached does not have an alternative a-node to activate, reanalysis cannot take place and a garden path results. The allowable attachment configurations are a direct the restrictions imposed by the competitive mechanism of CAPERS. The resulting initial attachment preferences, and the parser&apos;s ability or inability to revise the incorrect structure, account for the preferred readings of these temporarily ambiguous sentences, as well as the garden path results.</abstract>
<note confidence="0.963354130434782">References Abney, S. (1986). &amp;quot;Functional elements and licensing.&amp;quot; GLOW Conference, Gerona, Spain. Abney, S. (1989). &amp;quot;A computational model of human parsing.&amp;quot; of Psycholinguistic Research N. (1981). on Government and Binding: The Lectures. Foris Publications. N. (1986). MIT Press G. W. (1989). Connectionist Word Sense Altos, CA: Morgan Kaufmann. Fanty, M. (1985). &amp;quot;Context-free parsing in connectionist networks.&amp;quot; Technical Report TR174, University of Rochester. L. (1978). On Comprehending Strategies. dissertation, University of Connecticut. Bloomington, IN: Indiana University Linguistics Club. Frazier, L., and K. Rayner (1982). &amp;quot;Making and correcting errors during sentence comprehension: Eye movements in the analysis of ambiguous sentences.&amp;quot; Psychology 178- 210. Gibson, E. (1991). &amp;quot;A Computational Theory of Human Linguistic Processing: Memory Limitations and Processing Breakdown.&amp;quot; Doctoral dissertation, Carnegie-Mellon University. Gorrell, P. (1987). &amp;quot;Studies of Human Syntactic Processing: Ranked-Parallel versus Serial Models.&amp;quot; Unpublished doctoral dissertation, University of Connecticut, Storrs, CT. Inoue, A. and J. Fodor (1992). &amp;quot;Information-paced parsing of Japanese.&amp;quot; Presented at the Fifth Annual CUNY Conference on Human Sentence Processing, New York. McRoy, S. and G. Hirst (1990). &amp;quot;Race-Based Parsing and Syntactic Science Pritchett, B. (1988). &amp;quot;Garden Path Phenomena and the Grammat- Basis of Language Processing.&amp;quot; Language L. (1990). Relativized MIT Press. Reggia, J. (1987). &amp;quot;Properties of a Competition-Based Activation in Neuromimetic Network Models.&amp;quot; of the Conference on Networks, Diego, 11-131-11-138. Reggia, J., P. Marsland, and R. Berndt (1988). &amp;quot;Competitive Dynamics in a Dual-Route Connectionist Model of Print-to-Sound Systems. Selman, G., and G. Hirst (1985). &amp;quot;A Rule-Based Connectionist Scheme.&amp;quot; of the Seventh Conference the Cognitive Shieber, S. (1983). &amp;quot;Sentence Disambiguation by a Shift-Reduce Technique.&amp;quot; Proceedings the 21st of Association for Computational Linguistics,</note>
<degree confidence="0.573185">Stevenson, S. (1993a). &amp;quot;Establishing Long-Distance Dependencies a Hybrid Network Model of Human Parsing.&amp;quot; of 15th Conference the Cognitive Science Stevenson, S. (1993b). &amp;quot;A Constrained Active Attachment Model for Resolving Syntactic Ambiguities in Natural Language Parsing.&amp;quot; Doctoral dissertation, Computer Science Department, University of Maryland, College Park. Stevenson, S. (1990). &amp;quot;A Parallel Constraint Satisfaction and Spreading Activation Model for Resolving Syntactic Ambiguity.&amp;quot; of the Twelfth Conference the Cognitive</degree>
<abstract confidence="0.964355411764706">Society, current phrase past children top / ot stack convince top / ot stack convince present current phrase /I past</abstract>
<intro confidence="0.543069">273</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Functional elements and licensing.&amp;quot;</title>
<date>1986</date>
<booktitle>GLOW Conference,</booktitle>
<location>Gerona,</location>
<marker>Abney, 1986</marker>
<rawString>Abney, S. (1986). &amp;quot;Functional elements and licensing.&amp;quot; GLOW Conference, Gerona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>A computational model of human parsing.&amp;quot;</title>
<date>1989</date>
<journal>Journal of Psycholinguistic Research</journal>
<volume>18</volume>
<pages>129--144</pages>
<marker>Abney, 1989</marker>
<rawString>Abney, S. (1989). &amp;quot;A computational model of human parsing.&amp;quot; Journal of Psycholinguistic Research 18:1, 129-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Lectures on Government and Binding: The Pisa Lectures.</title>
<date>1981</date>
<publisher>Foris Publications.</publisher>
<location>Dordrecht:</location>
<marker>Chomsky, 1981</marker>
<rawString>Chomsky, N. (1981). Lectures on Government and Binding: The Pisa Lectures. Dordrecht: Foris Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<date>1986</date>
<publisher>MIT Press</publisher>
<location>Barriers. Cambridge:</location>
<marker>Chomsky, 1986</marker>
<rawString>Chomsky, N. (1986). Barriers. Cambridge: MIT Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>G W Cottrell</author>
</authors>
<title>A Connectionist Approach to Word Sense Disambiguation.</title>
<date>1989</date>
<publisher>Morgan Kaufmann.</publisher>
<location>Los Altos, CA:</location>
<marker>Cottrell, 1989</marker>
<rawString>Cottrell, G. W. (1989). A Connectionist Approach to Word Sense Disambiguation. Los Altos, CA: Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fanty</author>
</authors>
<title>Context-free parsing in connectionist networks.&amp;quot;</title>
<date>1985</date>
<tech>Technical Report TR174,</tech>
<institution>University of Rochester.</institution>
<marker>Fanty, 1985</marker>
<rawString>Fanty, M. (1985). &amp;quot;Context-free parsing in connectionist networks.&amp;quot; Technical Report TR174, University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
</authors>
<title>On Comprehending Sentences: Syntactic Parsing Strategies. Doctoral dissertation,</title>
<date>1978</date>
<institution>University of Connecticut. Bloomington, IN: Indiana University Linguistics Club.</institution>
<marker>Frazier, 1978</marker>
<rawString>Frazier, L. (1978). On Comprehending Sentences: Syntactic Parsing Strategies. Doctoral dissertation, University of Connecticut. Bloomington, IN: Indiana University Linguistics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
<author>K Rayner</author>
</authors>
<title>Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences.&amp;quot;</title>
<date>1982</date>
<journal>Cognitive Psychology</journal>
<volume>14</volume>
<pages>178--210</pages>
<marker>Frazier, Rayner, 1982</marker>
<rawString>Frazier, L., and K. Rayner (1982). &amp;quot;Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences.&amp;quot; Cognitive Psychology 14, 178-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gibson</author>
</authors>
<title>A Computational Theory of Human Linguistic Processing: Memory Limitations and Processing Breakdown.&amp;quot; Doctoral dissertation,</title>
<date>1991</date>
<institution>Carnegie-Mellon University.</institution>
<marker>Gibson, 1991</marker>
<rawString>Gibson, E. (1991). &amp;quot;A Computational Theory of Human Linguistic Processing: Memory Limitations and Processing Breakdown.&amp;quot; Doctoral dissertation, Carnegie-Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Gorrell</author>
</authors>
<title>Studies of Human Syntactic Processing: Ranked-Parallel versus Serial Models.&amp;quot; Unpublished doctoral dissertation,</title>
<date>1987</date>
<institution>University of Connecticut,</institution>
<location>Storrs, CT.</location>
<marker>Gorrell, 1987</marker>
<rawString>Gorrell, P. (1987). &amp;quot;Studies of Human Syntactic Processing: Ranked-Parallel versus Serial Models.&amp;quot; Unpublished doctoral dissertation, University of Connecticut, Storrs, CT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Inoue</author>
<author>J Fodor</author>
</authors>
<title>Information-paced parsing of Japanese.&amp;quot; Presented at the</title>
<date>1992</date>
<booktitle>Fifth Annual CUNY Conference on Human Sentence Processing,</booktitle>
<location>New York.</location>
<marker>Inoue, Fodor, 1992</marker>
<rawString>Inoue, A. and J. Fodor (1992). &amp;quot;Information-paced parsing of Japanese.&amp;quot; Presented at the Fifth Annual CUNY Conference on Human Sentence Processing, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McRoy</author>
<author>G Hirst</author>
</authors>
<title>Race-Based Parsing and Syntactic Disambiguation.&amp;quot;</title>
<date>1990</date>
<journal>Cognitive Science</journal>
<volume>14</volume>
<pages>313--353</pages>
<marker>McRoy, Hirst, 1990</marker>
<rawString>McRoy, S. and G. Hirst (1990). &amp;quot;Race-Based Parsing and Syntactic Disambiguation.&amp;quot; Cognitive Science 14, 313-353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pritchett</author>
</authors>
<title>Garden Path Phenomena and the Grammatical Basis of Language Processing.&amp;quot;</title>
<date>1988</date>
<journal>Language</journal>
<volume>64</volume>
<pages>539--576</pages>
<marker>Pritchett, 1988</marker>
<rawString>Pritchett, B. (1988). &amp;quot;Garden Path Phenomena and the Grammatical Basis of Language Processing.&amp;quot; Language 64:3, 539-576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Rizzi</author>
</authors>
<title>Relativized Minimality.</title>
<date>1990</date>
<publisher>MIT Press.</publisher>
<location>Cambridge:</location>
<marker>Rizzi, 1990</marker>
<rawString>Rizzi, L. (1990). Relativized Minimality. Cambridge: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reggia</author>
</authors>
<title>Properties of a Competition-Based Activation Mechanism in Neuromimetic Network Models.&amp;quot;</title>
<date>1987</date>
<booktitle>Proceedings of the First International Conference on Neural Networks,</booktitle>
<pages>11--131</pages>
<location>San Diego,</location>
<marker>Reggia, 1987</marker>
<rawString>Reggia, J. (1987). &amp;quot;Properties of a Competition-Based Activation Mechanism in Neuromimetic Network Models.&amp;quot; Proceedings of the First International Conference on Neural Networks, San Diego, 11-131-11-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reggia</author>
<author>P Marsland</author>
<author>R Berndt</author>
</authors>
<title>Competitive Dynamics in a Dual-Route Connectionist Model of Print-to-Sound Transformation.&amp;quot; Complex Systems.</title>
<date>1988</date>
<marker>Reggia, Marsland, Berndt, 1988</marker>
<rawString>Reggia, J., P. Marsland, and R. Berndt (1988). &amp;quot;Competitive Dynamics in a Dual-Route Connectionist Model of Print-to-Sound Transformation.&amp;quot; Complex Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Selman</author>
<author>G Hirst</author>
</authors>
<title>A Rule-Based Connectionist Parsing Scheme.&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings of the Seventh Annual Conference of the Cognitive Science Society,</booktitle>
<pages>212--219</pages>
<marker>Selman, Hirst, 1985</marker>
<rawString>Selman, G., and G. Hirst (1985). &amp;quot;A Rule-Based Connectionist Parsing Scheme.&amp;quot; Proceedings of the Seventh Annual Conference of the Cognitive Science Society, 212-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Shieber</author>
</authors>
<title>Sentence Disambiguation by a Shift-Reduce Parsing Technique.&amp;quot;</title>
<date>1983</date>
<booktitle>Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>113--118</pages>
<marker>Shieber, 1983</marker>
<rawString>Shieber, S. (1983). &amp;quot;Sentence Disambiguation by a Shift-Reduce Parsing Technique.&amp;quot; Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics, 113-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stevenson</author>
</authors>
<title>Establishing Long-Distance Dependencies in a Hybrid Network Model of Human Parsing.&amp;quot;</title>
<date>1993</date>
<booktitle>Proceedings of the 15th Annual Conference of the Cognitive Science Society.</booktitle>
<marker>Stevenson, 1993</marker>
<rawString>Stevenson, S. (1993a). &amp;quot;Establishing Long-Distance Dependencies in a Hybrid Network Model of Human Parsing.&amp;quot; Proceedings of the 15th Annual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stevenson</author>
</authors>
<title>A Constrained Active Attachment Model for Resolving Syntactic Ambiguities in Natural Language Parsing.&amp;quot; Doctoral dissertation,</title>
<date>1993</date>
<institution>Computer Science Department, University of Maryland, College Park.</institution>
<marker>Stevenson, 1993</marker>
<rawString>Stevenson, S. (1993b). &amp;quot;A Constrained Active Attachment Model for Resolving Syntactic Ambiguities in Natural Language Parsing.&amp;quot; Doctoral dissertation, Computer Science Department, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stevenson</author>
</authors>
<title>A Parallel Constraint Satisfaction and Spreading Activation Model for Resolving Syntactic Ambiguity.&amp;quot;</title>
<date>1990</date>
<booktitle>Proceedings of the Twelfth Annual Conference of the Cognitive Science Society,</booktitle>
<pages>396--403</pages>
<marker>Stevenson, 1990</marker>
<rawString>Stevenson, S. (1990). &amp;quot;A Parallel Constraint Satisfaction and Spreading Activation Model for Resolving Syntactic Ambiguity.&amp;quot; Proceedings of the Twelfth Annual Conference of the Cognitive Science Society, 396-403.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>