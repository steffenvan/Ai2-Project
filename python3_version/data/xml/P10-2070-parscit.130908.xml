<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002530">
<title confidence="0.9941985">
Wrapping up a Summary:
from Representation to Generation
</title>
<author confidence="0.567146">
Josef Steinberger and Marco Turchi and
Mijail Kabadjov and Ralf Steinberger
</author>
<affiliation confidence="0.666524">
EC Joint Research Centre
</affiliation>
<address confidence="0.61474">
21027, Ispra (VA), Italy
{Josef.Steinberger, Marco.Turchi,
Mijail.Kabadjov, Ralf.Steinberger}
</address>
<email confidence="0.932918">
@jrc.ec.europa.eu
</email>
<sectionHeader confidence="0.993873" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985166666667">
The main focus of this work is to investi-
gate robust ways for generating summaries
from summary representations without re-
curring to simple sentence extraction and
aiming at more human-like summaries.
This is motivated by empirical evidence
from TAC 2009 data showing that human
summaries contain on average more and
shorter sentences than the system sum-
maries. We report encouraging prelimi-
nary results comparable to those attained
by participating systems at TAC 2009.
</bodyText>
<sectionHeader confidence="0.998804" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.964347">
In this paper we adopt the general framework
for summarization put forward by Sp¨arck-Jones
(1999) – which views summarization as a three-
fold process: interpretation, transformation and
generation – and attempt to provide a clean in-
stantiation for each processing phase, with a par-
ticular emphasis on the last, summary-generation
phase often omitted or over-simplified in the main-
stream work on summarization.
The advantages of looking at the summarization
problem in terms of distinct processing phases are
numerous. It not only serves as a common ground
for comparing different systems and understand-
ing better the underlying logic and assumptions,
but it also provides a neat framework for devel-
oping systems based on clean and extendable de-
signs. For instance, Gong and Liu (2002) pro-
posed a method based on Latent Semantic Anal-
ysis (LSA) and later J. Steinberger et al. (2007)
showed that solely by enhancing the first source
interpretation phase, one is already able to pro-
duce better summaries.
There has been limited work on the last sum-
mary generation phase due to the fact that it is
unarguably a very challenging problem. The vast
Nello Cristianini
University of Bristol,
Bristol, BS8 1UB, UK
nello@support-vector.net
amount of approaches assume simple sentence se-
lection, a type of extractive summarization, where
often the summary representation and the end
summary are, indeed, conflated.
The main focus of this work is, thus, to in-
vestigate robust ways for generating summaries
from summary representations without recurring
to simple sentence extraction and aiming at more
human-like summaries. This decision is also mo-
tivated by empirical evidence from TAC 2009 data
(see table 1) showing that human summaries con-
tain on average more and shorter sentences than
the system summaries. The intuition behind this is
that, by containing more sentences, a summary is
able to capture more of the important content from
the source.
Our initial experimental results show that our
approach is feasible, since it produces summaries,
which when evaluated against the TAC 2009 data1
yield ROUGE scores (Lin and Hovy, 2003) com-
parable to the participating systems in the Sum-
marization task at TAC 2009. Taking into account
that our approach is completely unsupervised and
language-independent, we find our preliminary re-
sults encouraging.
The remainder of the paper is organised as fol-
lows: in the next section we briefly survey the
related work, in §3 we describe our approach to
summarization, in §4 we explain how we tackle
the generation step, in §5 we present and discuss
our experimental results and towards the end we
conclude and give pointers to future work.
</bodyText>
<sectionHeader confidence="0.999803" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999821">
There is a large body of literature on summariza-
tion (Hovy, 2005; Erkan and Radev, 2004; Kupiec
et al., 1995). The most closely related work to the
approach presented hereby is work on summariza-
tion attempting to go beyond simple sentence ex-
</bodyText>
<footnote confidence="0.992862">
1http://www.nist.gov/tac/
</footnote>
<page confidence="0.951787">
382
</page>
<note confidence="0.516388">
Proceedings of the ACL 2010 Conference Short Papers, pages 382–386,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999951107142857">
traction and to a lesser degree work on sentence
compression. We survey below work along these
lines.
Although our approach is related to sentence
compression (Knight and Marcu, 2002; Clarke
and Lapata, 2008), it is subtly different. Firstly, we
reduce the number of terms to be used in the sum-
mary at a global level, not at a local per-sentence
level. Secondly, we directly exploit the resulting
structures from the SVD making the last genera-
tion step fully aware of previous processing stages,
as opposed to tackling the problem of sentence
compression in isolation.
A similar approach to our sentence reconstruc-
tion method has been developed by Quirk et al.
(2004) for paraphrase generation. In their work,
training and test sets contain sentence pairs that
are composed of two different proper English sen-
tences and a paraphrase of a source sentence is
generated by finding the optimal path through a
paraphrases lattice.
Finally, it is worth mentioning that we are aware
of the ‘capsule overview’ summaries proposed by
Boguraev and Kennedy (1997) which is similar to
our TSR (see below), however, as opposed to their
emphasis on a suitable browsing interface rather
than producing a readable summary, we precisely
attempt the latter.
</bodyText>
<sectionHeader confidence="0.990046333333333" genericHeader="method">
3 Three-fold Summarization:
Interpretation, Transformation and
Generation
</sectionHeader>
<bodyText confidence="0.999934">
We chose the LSA paradigm for summarization,
since it provides a clear and direct instantiation of
Sp¨arck-Jones’ three-stage framework.
In LSA-based summarization the interpreta-
tion phase takes the form of building a term-by-
sentence matrix A = [A1, A2, ... , An], where
each column Aj = [a1j, a2j, ... , anj]T represents
the weighted term-frequency vector of sentence j
in a given set of documents. We adopt the same
weighting scheme as the one described in (Stein-
berger et al., 2007), as well as their more general
definition of term entailing not only unigrams and
bigrams, but also named entities.
The transformation phase is done by applying
singular value decomposition (SVD) to the initial
term-by-sentence matrix defined as A = UEVT .
The generation phase is where our main contri-
bution comes in. At this point we depart from stan-
dard LSA-based approaches and aim at produc-
ing a succinct summary representation comprised
only of salient terms – Term Summary Represen-
tation (TSR). Then this TSR is passed on to an-
other module which attempts to produce complete
sentences. The module for sentence reconstruc-
tion is described in detail in section 4, in what fol-
lows we explain the method for producing a TSR.
</bodyText>
<subsectionHeader confidence="0.998948">
3.1 Term Summary Representation
</subsectionHeader>
<bodyText confidence="0.999838379310345">
To explain how a term summary representation
(TSR) is produced, we first need to define two con-
cepts: salience score of a given term and salience
threshold. Salience score for each term in matrix
A is given by the magnitude of the corresponding
vector in the matrix resulting from the dot product
of the matrix of left singular vectors with the diag-
onal matrix of singular values. More formally, let
T = U · E and then for each term i, the salience
score is given by |Tz|. Salience threshold is equal
to the salience score of the top kth term, when all
terms are sorted in descending order on the basis
of their salience scores and a cutoff is defined as a
percentage (e.g., top 15%). In other words, if the
total number of terms is n, then 100 * k/n must be
equal to the percentage cutoff specified.
The generation of a TSR is performed in two
steps. First, an initial pool of sentences is selected
by using the same technique as in (Steinberger and
Je˘zek, 2009) which exploits the dot product of the
diagonal matrix of singular values with the right
singular vectors: E · VT .2 This initial pool of sen-
tences is the output of standard LSA approaches.
Second, the terms from the source matrix A are
identified in the initial pool of sentences and those
terms whose salience score is above the salience
threshold are copied across to the TSR. Thus, the
TSR is formed by the most (globally) salient terms
from each one of the sentences. For example:
</bodyText>
<listItem confidence="0.850477555555555">
• Extracted Sentence: “Irish Prime Minister Bertie
Ahern admitted on Tuesday that he had held a series of
private one-on-one meetings on the Northern Ireland
peace process with Sinn Fein leader Gerry Adams, but
denied they had been secret in any way.”
• TSR Sentence at 10%: “Irish Prime Minister
Bertie Ahern Tuesday had held one-on-one meetings
Northern Ireland peace process Sinn Fein leader Gerry
Adams”3
</listItem>
<footnote confidence="0.99758675">
2Due to space constraints, full details on that step are
omitted here, see (Steinberger and Je˘zek, 2009).
3The TSR sentence is stemmed just before feeding it to
the reconstruction module discussed in the next section.
</footnote>
<page confidence="0.984064">
383
</page>
<table confidence="0.9995562">
Average Human System At 100% At 15% At 10% At 5% At 1%
number of: Summaries Summaries
Sentences/summary 6.17 3.82 3.8 3.95 4.39 5.18 12.58
Words/sentence 15.96 25.01 26.24 25.1 22.61 19.08 7.55
Words/summary 98.46 95.59 99.59 99.25 99.18 98.86 94.96
</table>
<tableCaption confidence="0.994696">
Table 1: Summary statistics on TAC’09 data (initial summaries).
</tableCaption>
<table confidence="0.999893">
Metric LSAeatract At 100% At 15% At 10% At 5% At 1%
ROUGE-1 0.371 0.361 0.362 0.365 0.372 0.298
ROUGE-2 0.096 0.08 0.081 0.083 0.083 0.083
ROUGE-SU4 0.131 0.125 0.126 0.128 0.131 0.104
</table>
<tableCaption confidence="0.996012">
Table 2: Summarization results on TAC’09 data (initial summaries).
</tableCaption>
<sectionHeader confidence="0.981671" genericHeader="method">
4 Noisy-channel model for sentence
reconstruction
</sectionHeader>
<bodyText confidence="0.999964695652174">
This section describes a probabilistic approach to
the reconstruction problem. We adopt the noisy-
channel framework that has been widely used in a
number of other NLP applications. Our interpre-
tation of the noisy channel consists of looking at a
stemmed string without stopwords and imagining
that it was originally a long string and that some-
one removed or stemmed some text from it. In our
framework, reconstruction consists of identifying
the original long string.
To model our interpretation of the noisy chan-
nel, we make use of one of the most popular
classes of SMT systems: the Phrase Based Model
(PBM) (Zens et al., 2002; Och and Ney, 2001;
Koehn et al., 2003). It is an extension of the noisy-
channel model and was introduced by Brown et al.
(1994), using phrases rather than words. In PBM,
a source sentence f is segmented into a sequence
of I phrases fI = [f1, f2,... fI] and the same is
done for the target sentence e, where the notion of
phrase is not related to any grammatical assump-
tion; a phrase is an n-gram. The best translation
ebest of f is obtained by:
</bodyText>
<equation confidence="0.9928965">
ebest = arg max p(e|f) = arg max I φ(fi|ei)λ-P
e e i=1
d(ai − bi−1)λd � |e |pLM(ei|e1 ... ei−1)λLM
i=1
</equation>
<bodyText confidence="0.99999228">
where φ(fi|ei) is the probability of translating
a phrase ei into a phrase fi. d(ai − bi−1) is
the distance-based reordering model that drives
the system to penalize substantial reorderings of
words during translation, while still allowing some
flexibility. In the reordering model, ai denotes the
start position of the source phrase that was trans-
lated into the ith target phrase, and bi−1 denotes
the end position of the source phrase translated
into the (i−1th) target phrase. pLM(ei|e1 ... ei−1)
is the language model probability that is based on
the Markov chain assumption. It assigns a higher
probability to fluent/grammatical sentences. λφ,
λLM and λd are used to give a different weight to
each element (for more details see (Koehn et al.,
2003)).
In our reconstruction problem, the difference
between the source and target sentences is not in
terms of languages, but in terms of forms. In fact,
our source sentence f is a stemmed sentence with-
out stopwords, while the target sentence e is a
complete English sentence. “Translate” means to
reconstruct the most probable sentence e given f
inserting new words and reproducing the inflected
surface forms of the source words.
</bodyText>
<subsectionHeader confidence="0.999139">
4.1 Training of the model
</subsectionHeader>
<bodyText confidence="0.999954333333333">
In Statistical Machine Translation, a PBM system
is trained using parallel sentences, where each sen-
tence in a language is paired with another sentence
in a different language and one is the translation of
the other.
In the reconstruction problem, we use a set, S1
of 2,487,414 English sentences extracted from the
news. This set is duplicated, S2, and for each sen-
tence in S2, stopwords are removed and the re-
maining words are stemmed using Porter’s stem-
mer (Porter, 1980). Our stopword list contains 488
words. Verbs are not included in this list, because
they are relevant for the reconstruction task. To
optimize the lambda parameters, we select 2,000
pairs as development set.
</bodyText>
<page confidence="0.997609">
384
</page>
<bodyText confidence="0.931685">
An example of training sentence pair is:
</bodyText>
<listItem confidence="0.998248333333333">
• Source Sentence: “royal mail ha doubl profit 321
million huge fall number letter post”
• Target Sentence: “royal mail has doubled its prof-
</listItem>
<bodyText confidence="0.883604555555556">
its to 321 million despite a huge fall in the number of
letters being posted”
In this work we use Moses (Koehn et al., 2007),
a complete phrase-based translation toolkit for
academic purposes. It provides all the state-of-the-
art components needed to create a phrase-based
machine translation system. It contains different
modules to preprocess data, train the Language
Models and the Translation Models.
</bodyText>
<sectionHeader confidence="0.994551" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.998262790322581">
For our experiments we made use of the TAC
2009 data which conveniently contains human-
produced summaries against which we could eval-
uate the output of our system (NIST, 2009).
To begin our inquiry we carried out a phase
of exploratory data analysis, in which we mea-
sured the average number of sentences per sum-
mary, words per sentence and words per summary
in human vs. system summaries in the TAC 2009
data. Additionally, we also measured these statis-
tics of summaries produced by our system at five
different percentage cutoffs: 100%, 15%, 10%,
5% and 1%. 4 The results from this exploration
are summarised in table 1. The most notable thing
is that human summaries contain on average more
and shorter sentences than the system summaries
(see 2nd and 3rd column from left to right). Sec-
ondly, we note that as the percentage cutoff de-
creases (from 4th column rightwards) the charac-
teristics of the summaries produced by our system
are increasingly more similar to those of the hu-
man summaries. In other words, within the 100-
word window imposed by the TAC guidelines, our
system is able to fit more (and hence shorter) sen-
tences as we decrease the percentage cutoff.
Summarization performance results are shown
in table 2. We used the standard ROUGE evalu-
ation (Lin and Hovy, 2003) which has been also
used for TAC. We include the usual ROUGE met-
rics: R1 is the maximum number of co-occurring
unigrams, R2 is the maximum number of co-
occurring bigrams and RSU4 is the skip bigram
measure with the addition of unigrams as counting
4Recall from section §3 that the salience threshold is a
function of the percentage cutoff.
unit. The last five columns of table 2 (from left to
right) correspond to summaries produced by our
system at various percentage cutoffs. The 2nd col-
umn, L5Aextract, corresponds to the performance
of our system at producing summaries by sentence
extraction only.5
In the light of the above, the decrease in per-
formance from column L5Aextract to column ‘At
100%’ can be regarded as reconstruction error.6
Then, as we decrease the percentage cutoff (from
4th column rightwards) we are increasingly cover-
ing more of the content comprised by the human
summaries (as far as the ROUGE metrics are able
to gauge this, of course). In other words, the im-
provement of content coverage makes up for the
reconstruction error, and at 5% cutoff we already
obtain ROUGE scores comparable to L5Aextract.
This suggests that if we improve the quality of our
sentence reconstruction we would potentially end
up with a better performing system than a typical
LSA system based on sentence selection. Hence,
we find these results very encouraging.
Finally, we admittedly note that by applying a
percentage cutoff on the initial term set and further
performing the sentence reconstruction we gain in
content coverage, to a certain extent, on the ex-
pense of sentence readability.
</bodyText>
<sectionHeader confidence="0.99936" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999650166666667">
In this paper we proposed a novel approach to
summary generation from summary representa-
tion based on the LSA summarization framework
and on a machine-translation-inspired technique
for sentence reconstruction.
Our preliminary results show that our approach
is feasible, since it produces summaries which re-
semble better human summaries in terms of the av-
erage number of sentences per summary and yield
ROUGE scores comparable to the participating
systems in the Summarization task at TAC 2009.
Bearing in mind that our approach is completely
unsupervised and language-independent, we find
our results promising.
In future work we plan on working towards im-
proving the quality of our sentence reconstruction
step in order to produce better and more readable
sentences.
</bodyText>
<footnote confidence="0.9982508">
5These are, effectively, what we called initial pool of sen-
tences in section 3, before the TSR generation.
6The only difference between the two types of summaries
is the reconstruction step, since we are including 100% of the
terms.
</footnote>
<page confidence="0.99778">
385
</page>
<sectionHeader confidence="0.990193" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999725071428572">
B. Boguraev and C. Kennedy. 1997. Salience-
based content characterisation of text documents. In
I. Mani, editor, Proceedings of the Workshop on In-
telligent and Scalable Text Summarization at the An-
nual Joint Meeting of the ACL/EACL, Madrid.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mer-
cer. 1994. The mathematic of statistical machine
translation: Parameter estimation. Computational
Linguistics, 19(2):263–311.
J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear program-
ming approach. Journal ofArtificial Intelligence Re-
search, 31:273–318.
G. Erkan and D. Radev. 2004. LexRank: Graph-based
centrality as salience in text summarization. Journal
of Artificial Intelligence Research (JAIR).
Y. Gong and X. Liu. 2002. Generic text summarization
using relevance measure and latent semantic analy-
sis. In Proceedings of ACM SIGIR, New Orleans,
US.
E. Hovy. 2005. Automated text summarization. In
Ruslan Mitkov, editor, The Oxford Handbook of
Computational Linguistics, pages 583–598. Oxford
University Press, Oxford, UK.
K. Knight and D. Marcu. 2002. Summarization be-
yond sentence extraction: A probabilistic approach
to sentence compression. Artificial Intelligence,
139(1):91–107.
P. Koehn, F. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proceedings of NAACL
’03, pages 48–54, Morristown, NJ, USA.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings
of ACL ’07, demonstration session.
J. Kupiec, J. Pedersen, and F. Chen. 1995. A trainable
document summarizer. In Proceedings of the ACM
SIGIR, pages 68–73, Seattle, Washington.
C. Lin and E. Hovy. 2003. Automatic evaluation of
summaries using n-gram co-occurrence statistics. In
Proceedings of HLT-NAACL, Edmonton, Canada.
NIST, editor. 2009. Proceeding of the Text Analysis
Conference, Gaithersburg, MD, November.
F. Och and H. Ney. 2001. Discriminative training
and maximum entropy models for statistical ma-
chine translation. In Proceedings of ACL ’02, pages
295–302, Morristown, NJ, USA.
M. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137.
C. Quirk, C. Brockett, and W. Dolan. 2004. Monolin-
gual machine translation for paraphrase generation.
In Proceedings of EMNLP, volume 149. Barcelona,
Spain.
K. Sp¨arck-Jones. 1999. Automatic summarising: Fac-
tors and directions. In I. Mani and M. Maybury,
editors, Advances in Automatic Text Summarization.
MIT Press.
J. Steinberger and K. Je˘zek. 2009. Update summariza-
tion based on novel topic distribution. In Proceed-
ings of the 9th ACM DocEng, Munich, Germany.
J. Steinberger, M. Poesio, M. Kabadjov, and K. Je˘zek.
2007. Two uses of anaphora resolution in summa-
rization. Information Processing and Management,
43(6):1663–1680. Special Issue on Text Summari-
sation (Donna Harman, ed.).
R. Zens, F. J. Och, and H. Ney. 2002. Phrase-based
statistical machine translation. In Proceedings of KI
’02, pages 18–32, London, UK. Springer-Verlag.
</reference>
<page confidence="0.999017">
386
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.579530">
<title confidence="0.997453">Wrapping up a Summary: from Representation to Generation</title>
<author confidence="0.928763">Steinberger Turchi</author>
<author confidence="0.928763">Kabadjov Steinberger</author>
<affiliation confidence="0.999551">EC Joint Research Centre</affiliation>
<address confidence="0.999508">21027, Ispra (VA), Italy</address>
<email confidence="0.9215375">Marco.Turchi,@jrc.ec.europa.eu</email>
<abstract confidence="0.983489615384615">The main focus of this work is to investigate robust ways for generating summaries from summary representations without recurring to simple sentence extraction and aiming at more human-like summaries. This is motivated by empirical evidence from TAC 2009 data showing that human summaries contain on average more and shorter sentences than the system summaries. We report encouraging preliminary results comparable to those attained by participating systems at TAC 2009.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>C Kennedy</author>
</authors>
<title>Saliencebased content characterisation of text documents.</title>
<date>1997</date>
<booktitle>Proceedings of the Workshop on Intelligent and Scalable Text Summarization at the Annual Joint Meeting of the ACL/EACL,</booktitle>
<editor>In I. Mani, editor,</editor>
<location>Madrid.</location>
<contexts>
<context position="4924" citStr="Boguraev and Kennedy (1997)" startWordPosition="771" endWordPosition="774">ing the last generation step fully aware of previous processing stages, as opposed to tackling the problem of sentence compression in isolation. A similar approach to our sentence reconstruction method has been developed by Quirk et al. (2004) for paraphrase generation. In their work, training and test sets contain sentence pairs that are composed of two different proper English sentences and a paraphrase of a source sentence is generated by finding the optimal path through a paraphrases lattice. Finally, it is worth mentioning that we are aware of the ‘capsule overview’ summaries proposed by Boguraev and Kennedy (1997) which is similar to our TSR (see below), however, as opposed to their emphasis on a suitable browsing interface rather than producing a readable summary, we precisely attempt the latter. 3 Three-fold Summarization: Interpretation, Transformation and Generation We chose the LSA paradigm for summarization, since it provides a clear and direct instantiation of Sp¨arck-Jones’ three-stage framework. In LSA-based summarization the interpretation phase takes the form of building a term-bysentence matrix A = [A1, A2, ... , An], where each column Aj = [a1j, a2j, ... , anj]T represents the weighted ter</context>
</contexts>
<marker>Boguraev, Kennedy, 1997</marker>
<rawString>B. Boguraev and C. Kennedy. 1997. Saliencebased content characterisation of text documents. In I. Mani, editor, Proceedings of the Workshop on Intelligent and Scalable Text Summarization at the Annual Joint Meeting of the ACL/EACL, Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematic of statistical machine translation: Parameter estimation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="9885" citStr="Brown et al. (1994)" startWordPosition="1613" endWordPosition="1616">used in a number of other NLP applications. Our interpretation of the noisy channel consists of looking at a stemmed string without stopwords and imagining that it was originally a long string and that someone removed or stemmed some text from it. In our framework, reconstruction consists of identifying the original long string. To model our interpretation of the noisy channel, we make use of one of the most popular classes of SMT systems: the Phrase Based Model (PBM) (Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003). It is an extension of the noisychannel model and was introduced by Brown et al. (1994), using phrases rather than words. In PBM, a source sentence f is segmented into a sequence of I phrases fI = [f1, f2,... fI] and the same is done for the target sentence e, where the notion of phrase is not related to any grammatical assumption; a phrase is an n-gram. The best translation ebest of f is obtained by: ebest = arg max p(e|f) = arg max I φ(fi|ei)λ-P e e i=1 d(ai − bi−1)λd � |e |pLM(ei|e1 ... ei−1)λLM i=1 where φ(fi|ei) is the probability of translating a phrase ei into a phrase fi. d(ai − bi−1) is the distance-based reordering model that drives the system to penalize substantial r</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1994</marker>
<rawString>P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1994. The mathematic of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>M Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>31--273</pages>
<contexts>
<context position="4081" citStr="Clarke and Lapata, 2008" startWordPosition="632" endWordPosition="635">is a large body of literature on summarization (Hovy, 2005; Erkan and Radev, 2004; Kupiec et al., 1995). The most closely related work to the approach presented hereby is work on summarization attempting to go beyond simple sentence ex1http://www.nist.gov/tac/ 382 Proceedings of the ACL 2010 Conference Short Papers, pages 382–386, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics traction and to a lesser degree work on sentence compression. We survey below work along these lines. Although our approach is related to sentence compression (Knight and Marcu, 2002; Clarke and Lapata, 2008), it is subtly different. Firstly, we reduce the number of terms to be used in the summary at a global level, not at a local per-sentence level. Secondly, we directly exploit the resulting structures from the SVD making the last generation step fully aware of previous processing stages, as opposed to tackling the problem of sentence compression in isolation. A similar approach to our sentence reconstruction method has been developed by Quirk et al. (2004) for paraphrase generation. In their work, training and test sets contain sentence pairs that are composed of two different proper English se</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>J. Clarke and M. Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal ofArtificial Intelligence Research, 31:273–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Erkan</author>
<author>D Radev</author>
</authors>
<title>LexRank: Graph-based centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research (JAIR).</journal>
<contexts>
<context position="3538" citStr="Erkan and Radev, 2004" startWordPosition="551" endWordPosition="554">pating systems in the Summarization task at TAC 2009. Taking into account that our approach is completely unsupervised and language-independent, we find our preliminary results encouraging. The remainder of the paper is organised as follows: in the next section we briefly survey the related work, in §3 we describe our approach to summarization, in §4 we explain how we tackle the generation step, in §5 we present and discuss our experimental results and towards the end we conclude and give pointers to future work. 2 Related Work There is a large body of literature on summarization (Hovy, 2005; Erkan and Radev, 2004; Kupiec et al., 1995). The most closely related work to the approach presented hereby is work on summarization attempting to go beyond simple sentence ex1http://www.nist.gov/tac/ 382 Proceedings of the ACL 2010 Conference Short Papers, pages 382–386, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics traction and to a lesser degree work on sentence compression. We survey below work along these lines. Although our approach is related to sentence compression (Knight and Marcu, 2002; Clarke and Lapata, 2008), it is subtly different. Firstly, we reduce the number o</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G. Erkan and D. Radev. 2004. LexRank: Graph-based centrality as salience in text summarization. Journal of Artificial Intelligence Research (JAIR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Gong</author>
<author>X Liu</author>
</authors>
<title>Generic text summarization using relevance measure and latent semantic analysis.</title>
<date>2002</date>
<booktitle>In Proceedings of ACM SIGIR,</booktitle>
<location>New Orleans, US.</location>
<contexts>
<context position="1549" citStr="Gong and Liu (2002)" startWordPosition="227" endWordPosition="230">, transformation and generation – and attempt to provide a clean instantiation for each processing phase, with a particular emphasis on the last, summary-generation phase often omitted or over-simplified in the mainstream work on summarization. The advantages of looking at the summarization problem in terms of distinct processing phases are numerous. It not only serves as a common ground for comparing different systems and understanding better the underlying logic and assumptions, but it also provides a neat framework for developing systems based on clean and extendable designs. For instance, Gong and Liu (2002) proposed a method based on Latent Semantic Analysis (LSA) and later J. Steinberger et al. (2007) showed that solely by enhancing the first source interpretation phase, one is already able to produce better summaries. There has been limited work on the last summary generation phase due to the fact that it is unarguably a very challenging problem. The vast Nello Cristianini University of Bristol, Bristol, BS8 1UB, UK nello@support-vector.net amount of approaches assume simple sentence selection, a type of extractive summarization, where often the summary representation and the end summary are, </context>
</contexts>
<marker>Gong, Liu, 2002</marker>
<rawString>Y. Gong and X. Liu. 2002. Generic text summarization using relevance measure and latent semantic analysis. In Proceedings of ACM SIGIR, New Orleans, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
</authors>
<title>Automated text summarization.</title>
<date>2005</date>
<booktitle>The Oxford Handbook of Computational Linguistics,</booktitle>
<pages>583--598</pages>
<editor>In Ruslan Mitkov, editor,</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford, UK.</location>
<contexts>
<context position="3515" citStr="Hovy, 2005" startWordPosition="549" endWordPosition="550"> the participating systems in the Summarization task at TAC 2009. Taking into account that our approach is completely unsupervised and language-independent, we find our preliminary results encouraging. The remainder of the paper is organised as follows: in the next section we briefly survey the related work, in §3 we describe our approach to summarization, in §4 we explain how we tackle the generation step, in §5 we present and discuss our experimental results and towards the end we conclude and give pointers to future work. 2 Related Work There is a large body of literature on summarization (Hovy, 2005; Erkan and Radev, 2004; Kupiec et al., 1995). The most closely related work to the approach presented hereby is work on summarization attempting to go beyond simple sentence ex1http://www.nist.gov/tac/ 382 Proceedings of the ACL 2010 Conference Short Papers, pages 382–386, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics traction and to a lesser degree work on sentence compression. We survey below work along these lines. Although our approach is related to sentence compression (Knight and Marcu, 2002; Clarke and Lapata, 2008), it is subtly different. Firstly,</context>
</contexts>
<marker>Hovy, 2005</marker>
<rawString>E. Hovy. 2005. Automated text summarization. In Ruslan Mitkov, editor, The Oxford Handbook of Computational Linguistics, pages 583–598. Oxford University Press, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Summarization beyond sentence extraction: A probabilistic approach to sentence compression.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<volume>139</volume>
<issue>1</issue>
<contexts>
<context position="4055" citStr="Knight and Marcu, 2002" startWordPosition="628" endWordPosition="631">k. 2 Related Work There is a large body of literature on summarization (Hovy, 2005; Erkan and Radev, 2004; Kupiec et al., 1995). The most closely related work to the approach presented hereby is work on summarization attempting to go beyond simple sentence ex1http://www.nist.gov/tac/ 382 Proceedings of the ACL 2010 Conference Short Papers, pages 382–386, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics traction and to a lesser degree work on sentence compression. We survey below work along these lines. Although our approach is related to sentence compression (Knight and Marcu, 2002; Clarke and Lapata, 2008), it is subtly different. Firstly, we reduce the number of terms to be used in the summary at a global level, not at a local per-sentence level. Secondly, we directly exploit the resulting structures from the SVD making the last generation step fully aware of previous processing stages, as opposed to tackling the problem of sentence compression in isolation. A similar approach to our sentence reconstruction method has been developed by Quirk et al. (2004) for paraphrase generation. In their work, training and test sets contain sentence pairs that are composed of two d</context>
</contexts>
<marker>Knight, Marcu, 2002</marker>
<rawString>K. Knight and D. Marcu. 2002. Summarization beyond sentence extraction: A probabilistic approach to sentence compression. Artificial Intelligence, 139(1):91–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL ’03,</booktitle>
<pages>48--54</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9797" citStr="Koehn et al., 2003" startWordPosition="1596" endWordPosition="1599">to the reconstruction problem. We adopt the noisychannel framework that has been widely used in a number of other NLP applications. Our interpretation of the noisy channel consists of looking at a stemmed string without stopwords and imagining that it was originally a long string and that someone removed or stemmed some text from it. In our framework, reconstruction consists of identifying the original long string. To model our interpretation of the noisy channel, we make use of one of the most popular classes of SMT systems: the Phrase Based Model (PBM) (Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003). It is an extension of the noisychannel model and was introduced by Brown et al. (1994), using phrases rather than words. In PBM, a source sentence f is segmented into a sequence of I phrases fI = [f1, f2,... fI] and the same is done for the target sentence e, where the notion of phrase is not related to any grammatical assumption; a phrase is an n-gram. The best translation ebest of f is obtained by: ebest = arg max p(e|f) = arg max I φ(fi|ei)λ-P e e i=1 d(ai − bi−1)λd � |e |pLM(ei|e1 ... ei−1)λLM i=1 where φ(fi|ei) is the probability of translating a phrase ei into a phrase fi. d(ai − bi−1)</context>
<context position="11060" citStr="Koehn et al., 2003" startWordPosition="1819" endWordPosition="1822"> drives the system to penalize substantial reorderings of words during translation, while still allowing some flexibility. In the reordering model, ai denotes the start position of the source phrase that was translated into the ith target phrase, and bi−1 denotes the end position of the source phrase translated into the (i−1th) target phrase. pLM(ei|e1 ... ei−1) is the language model probability that is based on the Markov chain assumption. It assigns a higher probability to fluent/grammatical sentences. λφ, λLM and λd are used to give a different weight to each element (for more details see (Koehn et al., 2003)). In our reconstruction problem, the difference between the source and target sentences is not in terms of languages, but in terms of forms. In fact, our source sentence f is a stemmed sentence without stopwords, while the target sentence e is a complete English sentence. “Translate” means to reconstruct the most probable sentence e given f inserting new words and reproducing the inflected surface forms of the source words. 4.1 Training of the model In Statistical Machine Translation, a PBM system is trained using parallel sentences, where each sentence in a language is paired with another se</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proceedings of NAACL ’03, pages 48–54, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL ’07, demonstration session.</booktitle>
<contexts>
<context position="12506" citStr="Koehn et al., 2007" startWordPosition="2065" endWordPosition="2068">n S2, stopwords are removed and the remaining words are stemmed using Porter’s stemmer (Porter, 1980). Our stopword list contains 488 words. Verbs are not included in this list, because they are relevant for the reconstruction task. To optimize the lambda parameters, we select 2,000 pairs as development set. 384 An example of training sentence pair is: • Source Sentence: “royal mail ha doubl profit 321 million huge fall number letter post” • Target Sentence: “royal mail has doubled its profits to 321 million despite a huge fall in the number of letters being posted” In this work we use Moses (Koehn et al., 2007), a complete phrase-based translation toolkit for academic purposes. It provides all the state-of-theart components needed to create a phrase-based machine translation system. It contains different modules to preprocess data, train the Language Models and the Translation Models. 5 Experimental Results For our experiments we made use of the TAC 2009 data which conveniently contains humanproduced summaries against which we could evaluate the output of our system (NIST, 2009). To begin our inquiry we carried out a phase of exploratory data analysis, in which we measured the average number of sent</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of ACL ’07, demonstration session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kupiec</author>
<author>J Pedersen</author>
<author>F Chen</author>
</authors>
<title>A trainable document summarizer.</title>
<date>1995</date>
<booktitle>In Proceedings of the ACM SIGIR,</booktitle>
<pages>68--73</pages>
<location>Seattle, Washington.</location>
<contexts>
<context position="3560" citStr="Kupiec et al., 1995" startWordPosition="555" endWordPosition="558">ummarization task at TAC 2009. Taking into account that our approach is completely unsupervised and language-independent, we find our preliminary results encouraging. The remainder of the paper is organised as follows: in the next section we briefly survey the related work, in §3 we describe our approach to summarization, in §4 we explain how we tackle the generation step, in §5 we present and discuss our experimental results and towards the end we conclude and give pointers to future work. 2 Related Work There is a large body of literature on summarization (Hovy, 2005; Erkan and Radev, 2004; Kupiec et al., 1995). The most closely related work to the approach presented hereby is work on summarization attempting to go beyond simple sentence ex1http://www.nist.gov/tac/ 382 Proceedings of the ACL 2010 Conference Short Papers, pages 382–386, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics traction and to a lesser degree work on sentence compression. We survey below work along these lines. Although our approach is related to sentence compression (Knight and Marcu, 2002; Clarke and Lapata, 2008), it is subtly different. Firstly, we reduce the number of terms to be used in </context>
</contexts>
<marker>Kupiec, Pedersen, Chen, 1995</marker>
<rawString>J. Kupiec, J. Pedersen, and F. Chen. 1995. A trainable document summarizer. In Proceedings of the ACM SIGIR, pages 68–73, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lin</author>
<author>E Hovy</author>
</authors>
<title>Automatic evaluation of summaries using n-gram co-occurrence statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="2891" citStr="Lin and Hovy, 2003" startWordPosition="441" endWordPosition="444">epresentations without recurring to simple sentence extraction and aiming at more human-like summaries. This decision is also motivated by empirical evidence from TAC 2009 data (see table 1) showing that human summaries contain on average more and shorter sentences than the system summaries. The intuition behind this is that, by containing more sentences, a summary is able to capture more of the important content from the source. Our initial experimental results show that our approach is feasible, since it produces summaries, which when evaluated against the TAC 2009 data1 yield ROUGE scores (Lin and Hovy, 2003) comparable to the participating systems in the Summarization task at TAC 2009. Taking into account that our approach is completely unsupervised and language-independent, we find our preliminary results encouraging. The remainder of the paper is organised as follows: in the next section we briefly survey the related work, in §3 we describe our approach to summarization, in §4 we explain how we tackle the generation step, in §5 we present and discuss our experimental results and towards the end we conclude and give pointers to future work. 2 Related Work There is a large body of literature on s</context>
<context position="14092" citStr="Lin and Hovy, 2003" startWordPosition="2328" endWordPosition="2331">ies contain on average more and shorter sentences than the system summaries (see 2nd and 3rd column from left to right). Secondly, we note that as the percentage cutoff decreases (from 4th column rightwards) the characteristics of the summaries produced by our system are increasingly more similar to those of the human summaries. In other words, within the 100- word window imposed by the TAC guidelines, our system is able to fit more (and hence shorter) sentences as we decrease the percentage cutoff. Summarization performance results are shown in table 2. We used the standard ROUGE evaluation (Lin and Hovy, 2003) which has been also used for TAC. We include the usual ROUGE metrics: R1 is the maximum number of co-occurring unigrams, R2 is the maximum number of cooccurring bigrams and RSU4 is the skip bigram measure with the addition of unigrams as counting 4Recall from section §3 that the salience threshold is a function of the percentage cutoff. unit. The last five columns of table 2 (from left to right) correspond to summaries produced by our system at various percentage cutoffs. The 2nd column, L5Aextract, corresponds to the performance of our system at producing summaries by sentence extraction onl</context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>C. Lin and E. Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. In Proceedings of HLT-NAACL, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>editor NIST</author>
</authors>
<date>2009</date>
<booktitle>Proceeding of the Text Analysis Conference,</booktitle>
<location>Gaithersburg, MD,</location>
<contexts>
<context position="12983" citStr="NIST, 2009" startWordPosition="2138" endWordPosition="2139">d its profits to 321 million despite a huge fall in the number of letters being posted” In this work we use Moses (Koehn et al., 2007), a complete phrase-based translation toolkit for academic purposes. It provides all the state-of-theart components needed to create a phrase-based machine translation system. It contains different modules to preprocess data, train the Language Models and the Translation Models. 5 Experimental Results For our experiments we made use of the TAC 2009 data which conveniently contains humanproduced summaries against which we could evaluate the output of our system (NIST, 2009). To begin our inquiry we carried out a phase of exploratory data analysis, in which we measured the average number of sentences per summary, words per sentence and words per summary in human vs. system summaries in the TAC 2009 data. Additionally, we also measured these statistics of summaries produced by our system at five different percentage cutoffs: 100%, 15%, 10%, 5% and 1%. 4 The results from this exploration are summarised in table 1. The most notable thing is that human summaries contain on average more and shorter sentences than the system summaries (see 2nd and 3rd column from left </context>
</contexts>
<marker>NIST, 2009</marker>
<rawString>NIST, editor. 2009. Proceeding of the Text Analysis Conference, Gaithersburg, MD, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
<author>H Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL ’02,</booktitle>
<pages>295--302</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9776" citStr="Och and Ney, 2001" startWordPosition="1592" endWordPosition="1595">abilistic approach to the reconstruction problem. We adopt the noisychannel framework that has been widely used in a number of other NLP applications. Our interpretation of the noisy channel consists of looking at a stemmed string without stopwords and imagining that it was originally a long string and that someone removed or stemmed some text from it. In our framework, reconstruction consists of identifying the original long string. To model our interpretation of the noisy channel, we make use of one of the most popular classes of SMT systems: the Phrase Based Model (PBM) (Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003). It is an extension of the noisychannel model and was introduced by Brown et al. (1994), using phrases rather than words. In PBM, a source sentence f is segmented into a sequence of I phrases fI = [f1, f2,... fI] and the same is done for the target sentence e, where the notion of phrase is not related to any grammatical assumption; a phrase is an n-gram. The best translation ebest of f is obtained by: ebest = arg max p(e|f) = arg max I φ(fi|ei)λ-P e e i=1 d(ai − bi−1)λd � |e |pLM(ei|e1 ... ei−1)λLM i=1 where φ(fi|ei) is the probability of translating a phrase ei into a ph</context>
</contexts>
<marker>Och, Ney, 2001</marker>
<rawString>F. Och and H. Ney. 2001. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of ACL ’02, pages 295–302, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="11988" citStr="Porter, 1980" startWordPosition="1977" endWordPosition="1978"> probable sentence e given f inserting new words and reproducing the inflected surface forms of the source words. 4.1 Training of the model In Statistical Machine Translation, a PBM system is trained using parallel sentences, where each sentence in a language is paired with another sentence in a different language and one is the translation of the other. In the reconstruction problem, we use a set, S1 of 2,487,414 English sentences extracted from the news. This set is duplicated, S2, and for each sentence in S2, stopwords are removed and the remaining words are stemmed using Porter’s stemmer (Porter, 1980). Our stopword list contains 488 words. Verbs are not included in this list, because they are relevant for the reconstruction task. To optimize the lambda parameters, we select 2,000 pairs as development set. 384 An example of training sentence pair is: • Source Sentence: “royal mail ha doubl profit 321 million huge fall number letter post” • Target Sentence: “royal mail has doubled its profits to 321 million despite a huge fall in the number of letters being posted” In this work we use Moses (Koehn et al., 2007), a complete phrase-based translation toolkit for academic purposes. It provides a</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>C Brockett</author>
<author>W Dolan</author>
</authors>
<title>Monolingual machine translation for paraphrase generation.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<volume>149</volume>
<location>Barcelona,</location>
<contexts>
<context position="4540" citStr="Quirk et al. (2004)" startWordPosition="710" endWordPosition="713"> compression. We survey below work along these lines. Although our approach is related to sentence compression (Knight and Marcu, 2002; Clarke and Lapata, 2008), it is subtly different. Firstly, we reduce the number of terms to be used in the summary at a global level, not at a local per-sentence level. Secondly, we directly exploit the resulting structures from the SVD making the last generation step fully aware of previous processing stages, as opposed to tackling the problem of sentence compression in isolation. A similar approach to our sentence reconstruction method has been developed by Quirk et al. (2004) for paraphrase generation. In their work, training and test sets contain sentence pairs that are composed of two different proper English sentences and a paraphrase of a source sentence is generated by finding the optimal path through a paraphrases lattice. Finally, it is worth mentioning that we are aware of the ‘capsule overview’ summaries proposed by Boguraev and Kennedy (1997) which is similar to our TSR (see below), however, as opposed to their emphasis on a suitable browsing interface rather than producing a readable summary, we precisely attempt the latter. 3 Three-fold Summarization: </context>
</contexts>
<marker>Quirk, Brockett, Dolan, 2004</marker>
<rawString>C. Quirk, C. Brockett, and W. Dolan. 2004. Monolingual machine translation for paraphrase generation. In Proceedings of EMNLP, volume 149. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sp¨arck-Jones</author>
</authors>
<title>Automatic summarising: Factors and directions.</title>
<date>1999</date>
<booktitle>Advances in Automatic Text Summarization.</booktitle>
<editor>In I. Mani and M. Maybury, editors,</editor>
<publisher>MIT Press.</publisher>
<marker>Sp¨arck-Jones, 1999</marker>
<rawString>K. Sp¨arck-Jones. 1999. Automatic summarising: Factors and directions. In I. Mani and M. Maybury, editors, Advances in Automatic Text Summarization. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Steinberger</author>
<author>K Je˘zek</author>
</authors>
<title>Update summarization based on novel topic distribution.</title>
<date>2009</date>
<booktitle>In Proceedings of the 9th ACM DocEng,</booktitle>
<location>Munich, Germany.</location>
<marker>Steinberger, Je˘zek, 2009</marker>
<rawString>J. Steinberger and K. Je˘zek. 2009. Update summarization based on novel topic distribution. In Proceedings of the 9th ACM DocEng, Munich, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Steinberger</author>
<author>M Poesio</author>
<author>M Kabadjov</author>
<author>K Je˘zek</author>
</authors>
<title>Two uses of anaphora resolution in summarization.</title>
<date>2007</date>
<booktitle>Information Processing and Management, 43(6):1663–1680. Special Issue on Text Summarisation</booktitle>
<editor>(Donna Harman, ed.).</editor>
<marker>Steinberger, Poesio, Kabadjov, Je˘zek, 2007</marker>
<rawString>J. Steinberger, M. Poesio, M. Kabadjov, and K. Je˘zek. 2007. Two uses of anaphora resolution in summarization. Information Processing and Management, 43(6):1663–1680. Special Issue on Text Summarisation (Donna Harman, ed.).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Phrase-based statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of KI ’02,</booktitle>
<pages>18--32</pages>
<publisher>Springer-Verlag.</publisher>
<location>London, UK.</location>
<contexts>
<context position="9757" citStr="Zens et al., 2002" startWordPosition="1588" endWordPosition="1591">on describes a probabilistic approach to the reconstruction problem. We adopt the noisychannel framework that has been widely used in a number of other NLP applications. Our interpretation of the noisy channel consists of looking at a stemmed string without stopwords and imagining that it was originally a long string and that someone removed or stemmed some text from it. In our framework, reconstruction consists of identifying the original long string. To model our interpretation of the noisy channel, we make use of one of the most popular classes of SMT systems: the Phrase Based Model (PBM) (Zens et al., 2002; Och and Ney, 2001; Koehn et al., 2003). It is an extension of the noisychannel model and was introduced by Brown et al. (1994), using phrases rather than words. In PBM, a source sentence f is segmented into a sequence of I phrases fI = [f1, f2,... fI] and the same is done for the target sentence e, where the notion of phrase is not related to any grammatical assumption; a phrase is an n-gram. The best translation ebest of f is obtained by: ebest = arg max p(e|f) = arg max I φ(fi|ei)λ-P e e i=1 d(ai − bi−1)λd � |e |pLM(ei|e1 ... ei−1)λLM i=1 where φ(fi|ei) is the probability of translating a </context>
</contexts>
<marker>Zens, Och, Ney, 2002</marker>
<rawString>R. Zens, F. J. Och, and H. Ney. 2002. Phrase-based statistical machine translation. In Proceedings of KI ’02, pages 18–32, London, UK. Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>