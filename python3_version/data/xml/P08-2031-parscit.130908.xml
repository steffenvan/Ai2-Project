<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000134">
<title confidence="0.974899">
Using Automatically Transcribed Dialogs to Learn User Models in a Spoken
Dialog System
</title>
<author confidence="0.99224">
Umar Syed
</author>
<affiliation confidence="0.9652175">
Department of Computer Science
Princeton University
</affiliation>
<address confidence="0.765127">
Princeton, NJ 08540, USA
</address>
<email confidence="0.999031">
usyed@cs.princeton.edu
</email>
<author confidence="0.668504">
Jason D. Williams
</author>
<affiliation confidence="0.546051">
Shannon Laboratory
</affiliation>
<address confidence="0.513652">
AT&amp;T Labs — Research
Florham Park, NJ 07932, USA
</address>
<email confidence="0.994303">
jdw@research.att.com
</email>
<sectionHeader confidence="0.998576" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999467">
We use an EM algorithm to learn user mod-
els in a spoken dialog system. Our method
requires automatically transcribed (with ASR)
dialog corpora, plus a model of transcription
errors, but does not otherwise need any man-
ual transcription effort. We tested our method
on a voice-controlled telephone directory ap-
plication, and show that our learned models
better replicate the true distribution of user ac-
tions than those trained by simpler methods
and are very similar to user models estimated
from manually transcribed dialogs.
</bodyText>
<sectionHeader confidence="0.992215" genericHeader="categories and subject descriptors">
1 Introduction and Background
</sectionHeader>
<bodyText confidence="0.999967795454546">
When designing a dialog manager for a spoken dia-
log system, we would ideally like to try different di-
alog management strategies on the actual user pop-
ulation that will be using the system, and select the
one that works best. However, users are typically un-
willing to endure this kind of experimentation. The
next-best approach is to build a model of user behav-
ior. That way we can experiment with the model as
much as we like without troubling actual users.
Of course, for these experiments to be useful,
a high-quality user model is needed. The usual
method of building a user model is to estimate it
from transcribed corpora of human-computer di-
alogs. However, manually transcribing dialogs is
expensive, and consequently these corpora are usu-
ally small and sparse. In this work, we propose a
method of building user models that does not oper-
ate on manually transcribed dialogs, but instead uses
dialogs that have been transcribed by an automatic
speech recognition (ASR) engine. Since this pro-
cess is error-prone, we cannot assume that the tran-
scripts will accurately reflect the users’ true actions
and internal states. To handle this uncertainty, we
employ an EM algorithm that treats this information
as unobserved data. Although this approach does
not directly employ manually transcribed dialogs,
it does require a confusion model for the ASR en-
gine, which is estimated from manually transcribed
dialogs. The key benefit is that the number of manu-
ally transcribed dialogs required to estimate an ASR
confusion model is much smaller, and is fixed with
respect to the complexity of the user model.
Many works have estimated user models from
transcribed data (Georgila et al., 2006; Levin et al.,
2000; Pietquin, 2004; Schatzmann et al., 2007). Our
work is novel in that we do not assume we have ac-
cess to the correct transcriptions at all, but rather
have a model of how errors are made. EM has pre-
viously been applied to estimation of user models:
(Schatzmann et al., 2007) cast the user’s internal
state as a complex hidden variable and estimate its
transitions using the true user actions with EM. Our
work employs EM to infer the model of user actions,
not the model of user goal evolution.
</bodyText>
<sectionHeader confidence="0.970658" genericHeader="method">
2 Method
</sectionHeader>
<bodyText confidence="0.999937">
Before we can estimate a user model, we must define
a larger model of human-computer dialogs, of which
the user model is just one component. In this section
we give a general description of our dialog model;
in Section 3 we instantiate the model for a voice-
controlled telephone directory.
We adopt a probabilistic dialog model (similar
</bodyText>
<page confidence="0.986352">
121
</page>
<reference confidence="0.223216">
Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 121–124,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</reference>
<bodyText confidence="0.990150020833333">
to (Williams and Young, 2007)), depicted schemat-
ically as a graphical model in Figure 1. Follow-
ing the convention for graphical models, we use
directed edges to denote conditional dependencies
among the variables. In our dialog model, a dia-
log transcript x consists of an alternating sequence
of system actions and observed user actions: x =
(S0, �A0, S1, �A1, ...). Here St denotes the system
action, and At the output of the ASR engine when
applied to the true user action At.
A dialog transcript x is generated by our model as
follows: At each time t, the system action is St and
the unobserved user state is Ut. The user state indi-
cates the user’s hidden goal and relevant dialog his-
tory which, due to ASR confusions, is known with
certainty only to the user. Conditioned on (St, Ut),
the user draws an unobserved action At from a dis-
tribution Pr(At  |St, Ut; θ) parameterized by an un-
known parameter θ. For each user action At, the
ASR engine produces a hypothesis At of what the
user said, drawn from a distribution Pr( At  |At),
which is the ASR confusion model. The user state
Ut is updated to Ut+1 according to a deterministic
distribution Pr(Ut+1  |St+1, Ut, At, At). The sys-
tem outputs the next system action St+1 according
to its dialog management policy. Concretely, the val-
ues of St, Ut, At and At are all assumed to belong
to finite sets, and so all the conditional distributions
in our model are multinomials. Hence θ is a vec-
tor that parameterizes the user model according to
Pr(At = a  |St = s, Ut = u; θ) = θasu.
The problem we are interested in is estimating θ
given the set of dialog transcripts X, Pr( At  |At)
and Pr(Ut+1  |St+1, Ut, At, At). Here, we assume
that Pr(At  |At) is relatively straightforward to es-
timate: for example, ASR models that rely a simple
confusion rate and uniform substitutions (which can
be estimated from small number of transcriptions)
have been used to train dialog systems which out-
perform traditional systems (Thomson et al., 2007).
Further, Pr(Ut+1  |St+1, Ut, At, At) is often deter-
ministic and tracks dialog history relevant to action
selection — for example, whether the system cor-
rectly or incorrectly confirms a slot value. Here we
assume that it can be easily hand-crafted.
Formally, given a set of dialog transcripts X, our
goal is find a set of parameters θ* that maximizes the
At
</bodyText>
<figureCaption confidence="0.998808">
Figure 1: A probabilistic graphical model of a human-
computer dialog. The boxed variables are observed; the
circled variables are unobserved.
</figureCaption>
<bodyText confidence="0.952549">
log-likelihood of the observed data, i.e.,
</bodyText>
<equation confidence="0.991345">
θ* = arg max log Pr(X  |θ)
B
</equation>
<bodyText confidence="0.999909">
Unfortunately, directly computing θ* in this equa-
tion is intractable. However, we can efficiently ap-
proximate θ* via an expectation-maximization (EM)
procedure (Dempster et al., 1977). For a dialog tran-
script x, let y be the corresponding sequence of un-
observed values: y = (U0, A0, U1, A1, ...). Let
Y be the set of all sequences of unobserved values
corresponding to the data set X. Given an estimate
θ(t−1), a new estimate θ(t) is produced by
</bodyText>
<equation confidence="0.772727">
θ(t) = arg mB EY [log Pr(X, Y  |θ) X, θ(t−1)]
</equation>
<bodyText confidence="0.999771111111111">
The expectation in this equation is taken over all
possible values for Y. Both the expectation and its
maximization are easy to compute. This is because
our dialog model has a chain-like structure that
closely resembles an Hidden Markov Model, so a
forward-backward procedure can be employed (Ra-
biner, 1990). Under fairly mild conditions, the se-
quence θ(0), θ(1),... converges to a stationary point
estimate of θ* that is usually a local maximum.
</bodyText>
<sectionHeader confidence="0.997922" genericHeader="method">
3 Target Application
</sectionHeader>
<bodyText confidence="0.9989525">
To test the method, we applied it to a voice-
controlled telephone directory. This system is cur-
rently in use in a large company with many thou-
sands of employees. Users call the directory system
and provide the name of a callee they wish to be
connected to. The system then requests additional
</bodyText>
<figure confidence="0.988414625">
i�
CAt
( (T T
1� ��������Ut+1
�� ��
St+1
St
I
</figure>
<page confidence="0.980919">
122
</page>
<bodyText confidence="0.99861">
information from the user, such as the callee’s lo-
cation and type of phone (office, cell). Here is a
small fragment of a typical dialog with the system:
</bodyText>
<note confidence="0.6770835">
S0 = First and last name?
A0 = “John Doe” [ �A0 = Jane Roe ]
</note>
<bodyText confidence="0.9278994">
ognized At such that At =� At. The probabilities
Pr(At  |At) were then constructed by assuming that,
when the ASR engine makes an error recognizing a
user action, it substitutes another randomly chosen
action.
</bodyText>
<note confidence="0.489729333333333">
S1 = Jane Roe. Office or cell?
A1 = “No, no, John Doe” [ �A1 = No ] 4.1 Simulated Data
S2 = First and last name?
</note>
<bodyText confidence="0.993445535714286">
. . .
Because the telephone directory has many names,
the number of possible values for At, At, and St
is potentially very large. To control the size of the
model, we first assumed that the user’s intended
callee does not change during the call, which allows
us to group many user actions together into generic
placeholders e.g. At = FirstNameLastName.
After doing this, there were a total of 13 possible
values for At and At, and 14 values for St.
The user state consists of three bits: one bit indi-
cating whether the system has correctly recognized
the callee’s name, one bit indicating whether the
system has correctly recognized the callee’s “phone
type” (office or cell), and one bit indicating whether
the user has said the callee’s geographic location
(needed for disambiguation when several different
people share the same name). The deterministic dis-
tribution Pr(Ut+1  |St+1, Ut, At, At) simply updates
the user state after each dialog turn in the obvious
way. For example, the “name is correct” bit of Ut+1
is set to 0 when St+1 is a confirmation of a name
which doesn’t match At.
Recall that the user model is a multinomial distri-
bution Pr(At  |St, Ut; θ) parameterized by a vector
θ. Based on the number user actions, system actions,
and user states, θ is a vector of (13 − 1) x 14 x 8 =
1344 unknown parameters for our target application.
</bodyText>
<sectionHeader confidence="0.999734" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.995905923076923">
We conducted two sets of experiments on the tele-
phone directory application, one using simulated
data, and the other using dialogs collected from ac-
tual users. Both sets of experiments assumed that all
the distributions in Figure 1, except the user model,
are known. The ASR confusion model was esti-
mated by transcribing 50 randomly chosen dialogs
from the training set in Section 4.2 and calculat-
ing the frequency with which the ASR engine rec-
Recall that, in our parameterization, the user model
is Pr(At = a  |St = s, Ut = u; θ) = θasu. So
in this set of experiments, we chose a reasonable,
hand-crafted value for θ, and then generated syn-
thetic dialogs by following the probabilistic process
depicted in Figure 1. In this way, we were able to
create synthetic training sets of varying sizes, as well
as a test set of 1000 dialogs. Each generated dialog
d in each training/test set consisted of a sequence of
values for all the observed and unobserved variables:
d = (S0, U0, A0, �A0,...).
For a training/test set D, let K asu be the number
of times t, in all the dialogs in _D, that At = a, St =
s, and Ut = u. Similarly, let K�as be the number of
times t that At = a and St = s.
For each training set D, we estimated θ using the
following three methods:
</bodyText>
<listItem confidence="0.974889333333333">
1. Manual: Let θ be the maximum likelihood
estimate using manually transcribed data, i.e.,
θasu = KD
</listItem>
<bodyText confidence="0.57515">
Easu
a KD asu .
</bodyText>
<listItem confidence="0.862164">
2. Automatic: Let θ be the maximum likelihood
estimate using automatically transcribed data,
. This approach ignores
</listItem>
<bodyText confidence="0.9598065">
transcription errors and assumes that user be-
havior depends only on the observed data.
3. EM: Let θ be the estimate produced by the EM
algorithm described in Section 2, which uses
the automatically transcribed data and the ASR
confusion model.
Now let D be the test set. We evaluated each user
model by calculating the normalized log-likelihood
of the model with respect to the true user actions in
D:
</bodyText>
<equation confidence="0.896415333333333">
�a,s,u K� asu log θasu
`(θ) =
|D|
</equation>
<bodyText confidence="0.995451">
`(θ) is essentially a measure of how well the user
model parameterized by θ replicates the distribution
</bodyText>
<figure confidence="0.9052195">
�KDas
E �KD
a as
i.e., θasu =
</figure>
<page confidence="0.997279">
123
</page>
<bodyText confidence="0.976242">
of user actions in the test set. The normalization is
to allow for easier comparison across data sets of
differing sizes.
We repeated this entire process (generating train-
ing and test sets, estimating and evaluating user
models) 50 times. The results presented in Figure
2 are the average of those 50 runs. They are also
compared to the normalized log-likelihood of the
“Truth”, which is the actual parameter θ used to gen-
erated the data.
The EM method has to estimate a larger number
of parameters than the Automatic method (1344 vs.
168). But as Figure 2 shows, after observing enough
dialogs, the EM method is able to leverage the hid-
den user state to learn a better model of user behav-
ior, with an average normalized log-likelihood that
falls about halfway between that of the models pro-
duced by the Automatic and Manual methods.
Number of dialogs in training set
</bodyText>
<figureCaption confidence="0.8495365">
Figure 2: Normalized log-likelihood of each model
type with respect to the test set vs. size of training
set. Each data point is the average of 50 runs. For the
largest training set, the EM models had higher normal-
ized log-likelihood than the Automatic models in 48 out
of 50 runs.
</figureCaption>
<subsectionHeader confidence="0.992753">
4.2 Real Data
</subsectionHeader>
<bodyText confidence="0.999879636363636">
We tested the three estimation methods from the pre-
vious section on a data set of 461 real dialogs, which
we split into a training set of 315 dialogs and a test
set of 146 dialogs. All the dialogs were both man-
ually and automatically transcribed, so that each of
the three methods was applicable. The normalized
log-likelihood of each user model, with respect to
both the training and test set, is given in Table 1.
Since the output of the EM method depends on a
random choice of starting point θ(0), those results
were averaged over 50 runs.
</bodyText>
<table confidence="0.997836">
Training Set `(θ) Test Set `(θ)
Manual -2.87 -3.73
EM -3.90 -4.33
Automatic -4.60 -5.80
</table>
<tableCaption confidence="0.933655">
Table 1: Normalized log-likelihood of each model type
with respect to the training set and the test set. The
EM values are the average of 50 runs. The EM models
had higher normalized log-likelihood than the Automatic
model in 50 out of 50 runs.
</tableCaption>
<sectionHeader confidence="0.998368" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999695">
We have shown that user models can be estimated
from automatically transcribed dialog corpora by
modeling dialogs within a probabilistic framework
that accounts for transcription errors in a principled
way. This method may lead to many interesting fu-
ture applications, such as continuous learning of a
user model while the dialog system is on-line, en-
abling automatic adaptation.
</bodyText>
<sectionHeader confidence="0.999432" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9990805">
AP Dempster, NM Laird, and DB Rubin. 1977. Maxi-
mum likelihood from incomplete data via the em algo-
rithm. J. Royal Stat. Soc., 39:1–38.
K Georgila, J Henderson, and O Lemon. 2006. User
simulation for spoken dialogue systems: Learning and
evaluation. In Proc ICSLP, Pittsburgh, USA.
E Levin, R Pieraccini, and W Eckert. 2000. A stochas-
tic model of human-machine interaction for learning
dialogue strategies. IEEE Trans on Speech and Audio
Processing, 8(1):11–23.
O Pietquin. 2004. A framework for unsupervised learn-
ing of dialogue strategies. Ph.D. thesis, Faculty of En-
gineering, Mons (TCTS Lab), Belgium.
LR Rabiner, 1990. A tutorial on hidden Markov models
and selected applications in speech recognition, pages
267–296. Morgan Kaufmann Publishers, Inc.
J Schatzmann, B Thomson, and SJ Young. 2007. Sta-
tistical user simulation with a hidden agenda. In Proc
SIGDial, Antwerp, pages 273–282.
B Thomson, J Schatzmann, K Welhammer, H Ye, and
SJ Young. 2007. Training a real-world POMDP-based
dialog system. In Proc NAACL-HLT Workshop Bridg-
ing the Gap: Academic and Industrial Research in Di-
alog Technologies, Rochester, New York, USA, pages
9–17.
JD Williams and SJ Young. 2007. Partially observable
Markov decision processes for spoken dialog systems.
Computer Speech and Language, 21(2):393–422.
</reference>
<figure confidence="0.989048272727273">
Normalized log−likelihood
−3
−4
−5
−% 500 1000 1500
Truth
Manual
EM
Automatic
−6
−7
</figure>
<page confidence="0.963865">
124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.703466">
<title confidence="0.9944425">Using Automatically Transcribed Dialogs to Learn User Models in a Spoken Dialog System</title>
<author confidence="0.987497">Umar Syed</author>
<affiliation confidence="0.999945">Department of Computer Science Princeton University</affiliation>
<address confidence="0.999877">Princeton, NJ 08540, USA</address>
<email confidence="0.999774">usyed@cs.princeton.edu</email>
<author confidence="0.867297">Jason D Williams Shannon Laboratory</author>
<affiliation confidence="0.999873">AT&amp;T Labs — Research</affiliation>
<address confidence="0.999522">Florham Park, NJ 07932, USA</address>
<email confidence="0.999897">jdw@research.att.com</email>
<abstract confidence="0.998504461538461">We use an EM algorithm to learn user models in a spoken dialog system. Our method requires automatically transcribed (with ASR) dialog corpora, plus a model of transcription errors, but does not otherwise need any manual transcription effort. We tested our method on a voice-controlled telephone directory application, and show that our learned models better replicate the true distribution of user actions than those trained by simpler methods and are very similar to user models estimated from manually transcribed dialogs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of ACL-08: HLT, Short Papers (Companion Volume),</booktitle>
<pages>121--124</pages>
<marker></marker>
<rawString>Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 121–124,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Columbus</author>
</authors>
<date>2008</date>
<booktitle>c�2008 Association for Computational Linguistics</booktitle>
<location>Ohio, USA,</location>
<marker>Columbus, 2008</marker>
<rawString>Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>AP Dempster</author>
<author>NM Laird</author>
<author>DB Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the em algorithm.</title>
<date>1977</date>
<journal>J. Royal Stat. Soc.,</journal>
<pages>39--1</pages>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>AP Dempster, NM Laird, and DB Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. J. Royal Stat. Soc., 39:1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Georgila</author>
<author>J Henderson</author>
<author>O Lemon</author>
</authors>
<title>User simulation for spoken dialogue systems: Learning and evaluation.</title>
<date>2006</date>
<booktitle>In Proc ICSLP,</booktitle>
<location>Pittsburgh, USA.</location>
<contexts>
<context position="2555" citStr="Georgila et al., 2006" startWordPosition="406" endWordPosition="409">ately reflect the users’ true actions and internal states. To handle this uncertainty, we employ an EM algorithm that treats this information as unobserved data. Although this approach does not directly employ manually transcribed dialogs, it does require a confusion model for the ASR engine, which is estimated from manually transcribed dialogs. The key benefit is that the number of manually transcribed dialogs required to estimate an ASR confusion model is much smaller, and is fixed with respect to the complexity of the user model. Many works have estimated user models from transcribed data (Georgila et al., 2006; Levin et al., 2000; Pietquin, 2004; Schatzmann et al., 2007). Our work is novel in that we do not assume we have access to the correct transcriptions at all, but rather have a model of how errors are made. EM has previously been applied to estimation of user models: (Schatzmann et al., 2007) cast the user’s internal state as a complex hidden variable and estimate its transitions using the true user actions with EM. Our work employs EM to infer the model of user actions, not the model of user goal evolution. 2 Method Before we can estimate a user model, we must define a larger model of human-</context>
</contexts>
<marker>Georgila, Henderson, Lemon, 2006</marker>
<rawString>K Georgila, J Henderson, and O Lemon. 2006. User simulation for spoken dialogue systems: Learning and evaluation. In Proc ICSLP, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Levin</author>
<author>R Pieraccini</author>
<author>W Eckert</author>
</authors>
<title>A stochastic model of human-machine interaction for learning dialogue strategies.</title>
<date>2000</date>
<booktitle>IEEE Trans on Speech and Audio Processing,</booktitle>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="2575" citStr="Levin et al., 2000" startWordPosition="410" endWordPosition="413">’ true actions and internal states. To handle this uncertainty, we employ an EM algorithm that treats this information as unobserved data. Although this approach does not directly employ manually transcribed dialogs, it does require a confusion model for the ASR engine, which is estimated from manually transcribed dialogs. The key benefit is that the number of manually transcribed dialogs required to estimate an ASR confusion model is much smaller, and is fixed with respect to the complexity of the user model. Many works have estimated user models from transcribed data (Georgila et al., 2006; Levin et al., 2000; Pietquin, 2004; Schatzmann et al., 2007). Our work is novel in that we do not assume we have access to the correct transcriptions at all, but rather have a model of how errors are made. EM has previously been applied to estimation of user models: (Schatzmann et al., 2007) cast the user’s internal state as a complex hidden variable and estimate its transitions using the true user actions with EM. Our work employs EM to infer the model of user actions, not the model of user goal evolution. 2 Method Before we can estimate a user model, we must define a larger model of human-computer dialogs, of</context>
</contexts>
<marker>Levin, Pieraccini, Eckert, 2000</marker>
<rawString>E Levin, R Pieraccini, and W Eckert. 2000. A stochastic model of human-machine interaction for learning dialogue strategies. IEEE Trans on Speech and Audio Processing, 8(1):11–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Pietquin</author>
</authors>
<title>A framework for unsupervised learning of dialogue strategies.</title>
<date>2004</date>
<booktitle>Ph.D. thesis, Faculty of Engineering,</booktitle>
<location>Mons (TCTS Lab), Belgium.</location>
<contexts>
<context position="2591" citStr="Pietquin, 2004" startWordPosition="414" endWordPosition="415">nternal states. To handle this uncertainty, we employ an EM algorithm that treats this information as unobserved data. Although this approach does not directly employ manually transcribed dialogs, it does require a confusion model for the ASR engine, which is estimated from manually transcribed dialogs. The key benefit is that the number of manually transcribed dialogs required to estimate an ASR confusion model is much smaller, and is fixed with respect to the complexity of the user model. Many works have estimated user models from transcribed data (Georgila et al., 2006; Levin et al., 2000; Pietquin, 2004; Schatzmann et al., 2007). Our work is novel in that we do not assume we have access to the correct transcriptions at all, but rather have a model of how errors are made. EM has previously been applied to estimation of user models: (Schatzmann et al., 2007) cast the user’s internal state as a complex hidden variable and estimate its transitions using the true user actions with EM. Our work employs EM to infer the model of user actions, not the model of user goal evolution. 2 Method Before we can estimate a user model, we must define a larger model of human-computer dialogs, of which the user </context>
</contexts>
<marker>Pietquin, 2004</marker>
<rawString>O Pietquin. 2004. A framework for unsupervised learning of dialogue strategies. Ph.D. thesis, Faculty of Engineering, Mons (TCTS Lab), Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LR Rabiner</author>
</authors>
<title>A tutorial on hidden Markov models and selected applications in speech recognition,</title>
<date>1990</date>
<pages>267--296</pages>
<publisher>Morgan Kaufmann Publishers, Inc.</publisher>
<marker>Rabiner, 1990</marker>
<rawString>LR Rabiner, 1990. A tutorial on hidden Markov models and selected applications in speech recognition, pages 267–296. Morgan Kaufmann Publishers, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>B Thomson</author>
<author>SJ Young</author>
</authors>
<title>Statistical user simulation with a hidden agenda.</title>
<date>2007</date>
<booktitle>In Proc SIGDial, Antwerp,</booktitle>
<pages>273--282</pages>
<contexts>
<context position="2617" citStr="Schatzmann et al., 2007" startWordPosition="416" endWordPosition="419">To handle this uncertainty, we employ an EM algorithm that treats this information as unobserved data. Although this approach does not directly employ manually transcribed dialogs, it does require a confusion model for the ASR engine, which is estimated from manually transcribed dialogs. The key benefit is that the number of manually transcribed dialogs required to estimate an ASR confusion model is much smaller, and is fixed with respect to the complexity of the user model. Many works have estimated user models from transcribed data (Georgila et al., 2006; Levin et al., 2000; Pietquin, 2004; Schatzmann et al., 2007). Our work is novel in that we do not assume we have access to the correct transcriptions at all, but rather have a model of how errors are made. EM has previously been applied to estimation of user models: (Schatzmann et al., 2007) cast the user’s internal state as a complex hidden variable and estimate its transitions using the true user actions with EM. Our work employs EM to infer the model of user actions, not the model of user goal evolution. 2 Method Before we can estimate a user model, we must define a larger model of human-computer dialogs, of which the user model is just one componen</context>
</contexts>
<marker>Schatzmann, Thomson, Young, 2007</marker>
<rawString>J Schatzmann, B Thomson, and SJ Young. 2007. Statistical user simulation with a hidden agenda. In Proc SIGDial, Antwerp, pages 273–282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Thomson</author>
<author>J Schatzmann</author>
<author>K Welhammer</author>
<author>H Ye</author>
<author>SJ Young</author>
</authors>
<title>Training a real-world POMDP-based dialog system.</title>
<date>2007</date>
<booktitle>In Proc NAACL-HLT Workshop Bridging the Gap: Academic and Industrial Research in Dialog Technologies,</booktitle>
<pages>9--17</pages>
<location>Rochester, New York, USA,</location>
<marker>Thomson, Schatzmann, Welhammer, Ye, Young, 2007</marker>
<rawString>B Thomson, J Schatzmann, K Welhammer, H Ye, and SJ Young. 2007. Training a real-world POMDP-based dialog system. In Proc NAACL-HLT Workshop Bridging the Gap: Academic and Industrial Research in Dialog Technologies, Rochester, New York, USA, pages 9–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Williams</author>
<author>SJ Young</author>
</authors>
<title>Partially observable Markov decision processes for spoken dialog systems.</title>
<date>2007</date>
<journal>Computer Speech and Language,</journal>
<volume>21</volume>
<issue>2</issue>
<marker>Williams, Young, 2007</marker>
<rawString>JD Williams and SJ Young. 2007. Partially observable Markov decision processes for spoken dialog systems. Computer Speech and Language, 21(2):393–422.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>