<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000280">
<title confidence="0.986864">
Automatic Collocation Suggestion in Academic Writing
</title>
<author confidence="0.991396">
Jian-Cheng Wu1 Yu-Chia Chang1,* Teruko Mitamura2 Jason S. Chang1
</author>
<affiliation confidence="0.6852105">
1 National Tsing Hua University
Hsinchu, Taiwan
</affiliation>
<address confidence="0.673673">
{wujc86, richtrf, jason.jschang}
</address>
<email confidence="0.995688">
@gmail.com
</email>
<sectionHeader confidence="0.993856" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999834222222222">
In recent years, collocation has been
widely acknowledged as an essential
characteristic to distinguish native speak-
ers from non-native speakers. Research
on academic writing has also shown that
collocations are not only common but
serve a particularly important discourse
function within the academic community.
In our study, we propose a machine
learning approach to implementing an
online collocation writing assistant. We
use a data-driven classifier to provide
collocation suggestions to improve word
choices, based on the result of classifica-
tion. The system generates and ranks
suggestions to assist learners’ collocation
usages in their academic writing with sat-
isfactory results.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999860111111111">
The notion of collocation has been widely dis-
cussed in the field of language teaching for dec-
ades. It has been shown that collocation, a suc-
cessive common usage of words in a chain, is
important in helping language learners achieve
native-like fluency. In the field of English for
Academic Purpose, more and more researchers
are also recognizing this important feature in
academic writing. It is often argued that colloca-
tion can influence the effectiveness of a piece of
writing and the lack of such knowledge might
cause cumulative loss of precision (Howarth,
1998).
Many researchers have discussed the function
of collocations in the highly conventionalized
and specialized writing used within academia.
Research also identified noticeable increases in
the quantity and quality of collocational usage by
</bodyText>
<note confidence="0.698081">
*
Corresponding author: Yu-chia Chang (Email address:
</note>
<email confidence="0.961536">
richtrf@gmail.com)
</email>
<affiliation confidence="0.745297">
2 Carnegie Mellon University
Pittsburgh, United States
</affiliation>
<email confidence="0.988117">
teruko@cs.cmu.edu
</email>
<bodyText confidence="0.999947977272727">
native speakers (Howarth, 1998). Granger (1998)
reported that learners underuse native-like collo-
cations and overuse atypical word combinations.
This disparity in collocation usage between na-
tive and non-native speakers is clear and should
receive more attention from the language tech-
nology community.
To tackle such word usage problems, tradi-
tional language technology often employs a da-
tabase of the learners&apos; common errors that are
manually tagged by teachers or specialists (e.g.
Shei and Pain, 2000; Liu, 2002). Such system
then identifies errors via string or pattern match-
ing and offer only pre-stored suggestions. Com-
piling the database is time-consuming and not
easily maintainable, and the usefulness is limited
by the manual collection of pre-stored sugges-
tions. Therefore, it is beneficial if a system can
mainly use untagged data from a corpus contain-
ing correct language usages rather than the error-
tagged data from a learner corpus. A large corpus
of correct language usages is more readily avail-
able and useful than a small labeled corpus of
incorrect language usages.
For this suggestion task, the large corpus not
only provides us with a rich set of common col-
locations but also provides the context within
which these collocations appear. Intuitively, we
can take account of such context of collocation to
generate more suitable suggestions. Contextual
information in this sense often entails more lin-
guistic clues to provide suggestions within sen-
tences or paragraph. However, the contextual
information is messy and complex and thus has
long been overlooked or ignored. To date, most
fashionable suggestion methods still rely upon
the linguistic components within collocations as
well as the linguistic relationship between mis-
used words and their correct counterparts (Chang
et al., 2008; Liu, 2009).
In contrast to other research, we employ con-
textual information to automate suggestions for
verb-noun lexical collocation. Verb-noun collo-
cations are recognized as presenting the most
</bodyText>
<page confidence="0.985928">
115
</page>
<note confidence="0.507459">
Proceedings of the ACL 2010 Conference Short Papers, pages 115–119,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997956">
challenge to students (Howarth, 1996; Liu,
2002). More specifically, in this preliminary
study we start by focusing on the word choice of
verbs in collocations which are considered as the
most difficult ones for learners to master (Liu,
2002; Chang, 2008). The experiment confirms
that our collocation writing assistant proves the
feasibility of using machine learning methods to
automatically prompt learners with collocation
suggestions in academic writing.
</bodyText>
<subsectionHeader confidence="0.583576">
2 Collocation Checking and Suggestion
</subsectionHeader>
<bodyText confidence="0.999651909090909">
This study aims to develop a web service, Collo-
cation Inspector (shown in Figure 1) that accepts
sentences as input and generates the related can-
didates for learners.
In this paper, we focus on automatically pro-
viding academic collocation suggestions when
users are writing up their abstracts. After an ab-
stract is submitted, the system extracts linguistic
features from the user’s text for machine learning
model. By using a corpus of published academic
texts, we hope to match contextual linguistic
clues from users’ text to help elicit the most rele-
vant suggestions. We now formally state the
problem that we are addressing:
Problem Statement: Given a sentence S writ-
ten by a learner and a reference corpus RC, our
goal is to output a set of most probable sugges-
tion candidates c1, c2, ... , cm. For this, we train a
classifier MC to map the context (represented as
feature set f1, f2, ..., fn) of each sentence in RC to
the collocations. At run-time, we predict these
collocations for S as suggestions.
</bodyText>
<subsectionHeader confidence="0.780485">
2.1 Academic Collocation Checker Train-
ing Procedures
Sentence Parsing and Collocation Extraction:
</subsectionHeader>
<bodyText confidence="0.969213866666667">
We start by collecting a large number of ab-
stracts from the Web to develop a reference cor-
pus for collocation suggestion. And we continue
to identify collocations in each sentence for the
subsequent processing.
Collocation extraction is an essential step in
preprocessing data. We only expect to extract the
collocation which comprises components having
a syntactic relationship with one another. How-
ever, this extraction task can be complicated.
Take the following scholarly sentence from the
reference corpus as an example (example (1)):
(1) We introduce a novel method
for learning to find documents
on the web.
</bodyText>
<figureCaption confidence="0.998971">
Figure 2. Dependency parsing of Example (1)
</figureCaption>
<bodyText confidence="0.999046571428572">
Traditionally, through part-of-speech tagging,
we can obtain a tagged sentence as follows (ex-
ample (2)). We can observe that the desired col-
location “introduce method”, conforming to
“VERB+NOUN” relationship, exists within the
sentence. However, the distance between these
two words is often flexible, not necessarily rigid.
Heuristically writing patterns to extract such verb
and noun might not be effective. The patterns
between them can be tremendously varied. In
addition, some verbs and nouns are adjacent, but
they might be intervened by clause and thus have
no syntactic relation with one another (e.g. “pro-
pose model” in example (3)).
</bodyText>
<listItem confidence="0.9631765">
(2) We/PRP introduce/VB a/DT
novel/JJ method/NN for/IN
learning/VBG to/TO find/VB
documents/NNS on/IN the/DT
web/NN ./.
(3) We proposed that the web-
based model would be more ef-
fective than corpus-based one.
</listItem>
<bodyText confidence="0.9970432">
A natural language parser can facilitate the ex-
traction of the target type of collocations. Such
parser is a program that works out the grammati-
cal structure of sentences, for instance, by identi-
fying which group of words go together or which
</bodyText>
<figureCaption confidence="0.998826">
Figure 1. The interface for the collocation suggestion
</figureCaption>
<equation confidence="0.995930285714286">
nsubj (introduce-2, We-1)
det (method-5, a-3)
amod (method-5, novel-4)
dobj (introduce-2, method-5)
prepc_for (introduce-2, learning-7)
aux (find-9, to-8)
É É
</equation>
<page confidence="0.989703">
116
</page>
<bodyText confidence="0.995815094339623">
word is the subject or object of a verb. In our
study, we take advantage of a dependency parser,
Stanford Parser, which extracts typed dependen-
cies for certain grammatical relations (shown in
Figure 2). Within the parsed sentence of example
(1), we can notice that the extracted dependency
“dobj (introduce-2, method-4)” meets the crite-
rion.
Using a Classifier for the Suggestion task: A
classifier is a function generally to take a set of
attributes as an input and to provide a tagged
class as an output. The basic way to build a clas-
sifier is to derive a regression formula from a set
of tagged examples. And this trained classifier
can thus make predication and assign a tag to any
input data.
The suggestion task in this study will be seen
as a classification problem. We treat the colloca-
tion extracted from each sentence as the class tag
(see examples in Table 1). Hopefully, the system
can learn the rules between tagged classes (i.e.
collocations) and example sentences (i.e. schol-
arly sentences) and can predict which collocation
is the most appropriate one given attributes ex-
tracted from the sentences.
Another advantage of using a classifier to
automate suggestion is to provide alternatives
with regard to the similar attributes shared by
sentences. In Table 1, we can observe that these
collocations exhibit a similar discourse function
and can thus become interchangeable in these
sentences. Therefore, based on the outputs along
with the probability from the classifier, we can
provide more than one adequate suggestions.
Feature Selection for Machine Learning: In
the final stage of training, we build a statistical
machine-learning model. For our task, we can
use a supervised method to automatically learn
the relationship between collocations and exam-
ple sentences.
We choose Maximum Entropy (ME) as our train-
ing algorithm to build a collocation suggestion
classifier. One advantage of an ME classifier is
that in addition to assigning a classification it can
provide the probability of each assignment. The
ME framework estimates probabilities based on
the principle of making as few assumptions as
possible. Such constraints are derived from the
training data, expressing relationships between
features and outcomes.
Moreover, an effective feature selection can
increase the precision of machine learning. In our
study, we employ the contextual features which
</bodyText>
<tableCaption confidence="0.962107">
Table 1. Example sentences and class tags (colloca-
tions)
</tableCaption>
<subsectionHeader confidence="0.909491">
Example Sentence Class tag
</subsectionHeader>
<bodyText confidence="0.9995818125">
We introduce a novel method for learning introduce
to find documents on the web.
We presented a method of improving Japa-
nese dependency parsing by using large-
scale statistical information.
In this paper, we will describe a method of
identifying the syntactic role of antece-
dents, which consists of two phases
In this paper, we suggest a method that
automatically constructs an NE tagged cor-
pus from the web to be used for learning of
NER systems.
consist of two elements, the head and the ngram
of context words:
Head: Each collocation comprises two parts,
collocate and head. For example, in a given verb-
noun collocation, the verb is the collocate as well
as the target for which we provide suggestions;
the noun serves as the head of collocation and
convey the essential meaning of the collocation.
We use the head as a feature to condition the
classifier to generate candidates relevant to a
given head.
Ngram: We use the context words around the
target collocation by considering the correspond-
ing unigrams and bigrams words within the sen-
tence. Moreover, to ensure the relevance, those
context words, before and after the punctuation
marks enclosing the collocation in question, will
be excluded. We use the parsed sentence from
previous step (example (2)) to show the extracted
context features1 (example (4)):
</bodyText>
<figure confidence="0.980911833333333">
(4) CN=method UniV_L=we
UniV_R=a UniV_R=novel UniN_L=a
UniN_L=novel UniN_R=for
UniN_R=learn BiV_R=a_novel
BiN_L=a_novel BiN_R=for_learn
BiV_I=we_a BiN_I=novel_for
</figure>
<figureCaption confidence="0.710792">
1 CN refers to the head within collocation. Uni and Bi indi-
cate the unigram and bigram context words of window size
two respectively. V and N differentiate the contexts related
to verb or noun. The ending alphabets L, R, I show the posi-
tion of the words in context, L = left, R = right, and I = in
between.
</figureCaption>
<figure confidence="0.969314666666667">
present
describe
suggest
</figure>
<page confidence="0.956304">
117
</page>
<subsectionHeader confidence="0.9801085">
2.2 Automatic Collocation Suggestion at
Run-time
</subsectionHeader>
<bodyText confidence="0.9633354">
After the ME classifier is automatically trained,
the model is used to find out the best collocation
suggestion. Figure 3 shows the algorithm of pro-
ducing suggestions for a given sentence. The
input is a learner’s sentence in an abstract, along
with an ME model trained from the reference
corpus.
In Step (1) of the algorithm, we parse the sen-
tence for data preprocessing. Based on the parser
output, we extract the collocation from a given
sentence as well as generate features sets in Step
(2) and (3). After that in Step (4), with the
trained machine-learning model, we obtain a set
of likely collocates with probability as predicted
by the ME model. In Step (5), SuggestionFilter
singles out the valid collocation and returns the
best collocation suggestion as output in Step (6).
For example, if a learner inputs the sentence like
Example (5), the features and output candidates
are shown in Table 2.
(5) There are many investiga-
tions about wireless network
communication, especially it is
important to add Internet
transfer calculation speeds.
</bodyText>
<sectionHeader confidence="0.996058" genericHeader="method">
3 Experiment
</sectionHeader>
<bodyText confidence="0.9999452">
From an online research database, CiteSeer, we
have collected a corpus of 20,306 unique ab-
stracts, which contained 95,650 sentences. To
train a Maximum Entropy classifier, 46,255 col-
locations are extracted and 790 verbal collocates
are identified as tagged classes for collocation
suggestions. We tested the classifier on scholarly
sentences in place of authentic student writings
which were not available at the time of this pilot
study. We extracted 364 collocations among 600
randomly selected sentences as the held out test
data not overlapping with the training set. To
automate the evaluation, we blank out the verb
collocates within these sentences and treat these
verbs directly as the only correct suggestions in
question, although two or more suggestions may
be interchangeable or at least appropriate. In this
sense, our evaluation is an underestimate of the
performance of the proposed method.
While evaluating the quality of the suggestions
provided by our system, we used the mean recip-
rocal rank (MRR) of the first relevant sugges-
tions returned so as to assess whether the sugges-
tion list contains an answer and how far up the
answer is in the list as a quality metric of the sys-
</bodyText>
<figure confidence="0.903280285714286">
Procedure CollocationSuggestion(sent, MEmodel)
(1) parsedSen = Parsing(sent)
(2) extractedColl = CollocationExtraction(parsedSent)
(3) features = AssignFeature(ParsedSent)
(4) probCollection = MEprob(features, MEmodel)
(5) candidate = SuggestionFilter(probCollection)
(6) Return candidate
</figure>
<figureCaption confidence="0.7132535">
Figure 3. Collocation Suggestion at Run-time
Table 2. An example from learner’s sentence
</figureCaption>
<figure confidence="0.920281">
Extracted Features Ranked
Collocation Candidates
CN=speed
UniV_L=important
UniV_L=to
UniV_R=internet
UniV_R=transfer
UniN_L=transfer
UniN_L=calculation
BiV_L=important_to
BiV_R=internet_transfer
BiN_L=transfer_calcula-
tion
BiV_I=to_intenet
</figure>
<tableCaption confidence="0.918947">
Table 3. MRR for different feature sets
</tableCaption>
<table confidence="0.9268555">
Feature Sets Included In Classifier MRR
Features of HEAD 0.407
Features of CONTEXT 0.469
Features of HEAD+CONTEXT 0.518
</table>
<bodyText confidence="0.999715071428572">
tem output. Table 3 shows that the best MRR of
our prototype system is 0.518. The results indi-
cate that on average users could easily find an-
swers (exactly reproduction of the blanked out
collocates) in the first two to three ranking of
suggestions. It is very likely that we get a much
higher MMR value if we would go through the
lists and evaluate each suggestion by hand.
Moreover, in Table 3, we can further notice that
contextual features are quite informative in com-
parison with the baseline feature set containing
merely the feature of HEAD. Also the integrated
feature set of HEAD and CONTEXT together
achieves a more satisfactory suggestion result.
</bodyText>
<sectionHeader confidence="0.999535" genericHeader="method">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999937444444444">
Many avenues exist for future research that are
important for improving the proposed method.
For example, we need to carry out the experi-
ment on authentic learners’ texts. We will con-
duct a user study to investigate whether our sys-
tem would improve a learner’s writing in a real
setting. Additionally, adding classifier features
based on the translation of misused words in
learners’ text could be beneficial (Chang et al.,
</bodyText>
<figure confidence="0.8228295">
add speed
improve
increase
determine
maintain
É É
</figure>
<page confidence="0.983936">
118
</page>
<bodyText confidence="0.999968888888889">
2008). The translation can help to resolve preva-
lent collocation misuses influenced by a learner&apos;s
native language. Yet another direction of this
research is to investigate if our methodology is
applicable to other types of collocations, such as
AN and PN in addition to VN dealt with in this
paper.
In summary, we have presented an unsuper-
vised method for suggesting collocations based
on a corpus of abstracts collected from the Web.
The method involves selecting features from the
reference corpus of the scholarly texts. Then a
classifier is automatically trained to determine
the most probable collocation candidates with
regard to the given context. The preliminary re-
sults show that it is beneficial to use classifiers
for identifying and ranking collocation sugges-
tions based on the context features.
</bodyText>
<sectionHeader confidence="0.992987" genericHeader="method">
Reference
</sectionHeader>
<reference confidence="0.999876354838709">
Y. Chang, J. Chang, H. Chen, and H. Liou. 2008. An
automatic collocation writing assistant for Taiwan-
ese EFL learners: A case of corpus-based NLP
technology. Computer Assisted Language Learn-
ing, 21(3), pages 283-299.
S. Granger. 1998. Prefabricated patterns in advanced
EFL writing: collocations and formulae. In Cowie,
A. (ed.) Phraseology: theory, analysis and applica-
tions. Oxford University Press, Oxford, pages 145-
160.
P. Howarth. 1996. Phraseology in English Academic
Writing. Tübingen: Max Niemeyer Verlag.
P. Howarth. 1998. The phraseology of learner’s aca-
demic writing. In Cowie, A. (ed.) Phraseology:
theory, analysis and applications. Oxford Univer-
sity Press, Oxford, pages 161-186.
D. Hawking and N. Craswell. 2002. Overview of the
TREC-2001 Web track. In Proceedings of the 10th
Text Retrieval Conference (TREC 2001), pages 25-
31.
L. E. Liu. 2002. A corpus-based lexical semantic in-
vestigation of verb-noun miscollocations in Taiwan
learners’ English. Unpublished master’s thesis,
Tamkang University, Taipei, January.
A. L. Liu, D. Wible, and N. L. Tsao. 2009. Automated
suggestions for miscollocations. In Proceedings of
the Fourth Workshop on Innovative Use of NLP for
Building Educational Applications, pages 47-50.
C. C. Shei and H. Pain. 2000. An ESL writer’s collo-
cational aid. Computer Assisted Language Learn-
ing, 13, pages 167-182.
</reference>
<page confidence="0.999093">
119
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.745120">
<title confidence="0.999262">Automatic Collocation Suggestion in Academic Writing</title>
<author confidence="0.982635">Yu-Chia Teruko Jason S</author>
<affiliation confidence="0.991688">1National Tsing Hua University</affiliation>
<address confidence="0.93865">Hsinchu, Taiwan</address>
<email confidence="0.9085685">wujc86@gmail.com</email>
<email confidence="0.9085685">richtrf@gmail.com</email>
<email confidence="0.9085685">jason.jschang@gmail.com</email>
<abstract confidence="0.998831894736842">In recent years, collocation has been widely acknowledged as an essential characteristic to distinguish native speakers from non-native speakers. Research on academic writing has also shown that collocations are not only common but serve a particularly important discourse function within the academic community. In our study, we propose a machine learning approach to implementing an online collocation writing assistant. We use a data-driven classifier to provide collocation suggestions to improve word choices, based on the result of classification. The system generates and ranks suggestions to assist learners’ collocation usages in their academic writing with satisfactory results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Chang</author>
<author>J Chang</author>
<author>H Chen</author>
<author>H Liou</author>
</authors>
<title>An automatic collocation writing assistant for Taiwanese EFL learners: A case of corpus-based NLP technology.</title>
<date>2008</date>
<journal>Computer Assisted Language Learning,</journal>
<volume>21</volume>
<issue>3</issue>
<pages>283--299</pages>
<contexts>
<context position="3686" citStr="Chang et al., 2008" startWordPosition="546" endWordPosition="549"> also provides the context within which these collocations appear. Intuitively, we can take account of such context of collocation to generate more suitable suggestions. Contextual information in this sense often entails more linguistic clues to provide suggestions within sentences or paragraph. However, the contextual information is messy and complex and thus has long been overlooked or ignored. To date, most fashionable suggestion methods still rely upon the linguistic components within collocations as well as the linguistic relationship between misused words and their correct counterparts (Chang et al., 2008; Liu, 2009). In contrast to other research, we employ contextual information to automate suggestions for verb-noun lexical collocation. Verb-noun collocations are recognized as presenting the most 115 Proceedings of the ACL 2010 Conference Short Papers, pages 115–119, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics challenge to students (Howarth, 1996; Liu, 2002). More specifically, in this preliminary study we start by focusing on the word choice of verbs in collocations which are considered as the most difficult ones for learners to master (Liu, 2002; Chan</context>
</contexts>
<marker>Chang, Chang, Chen, Liou, 2008</marker>
<rawString>Y. Chang, J. Chang, H. Chen, and H. Liou. 2008. An automatic collocation writing assistant for Taiwanese EFL learners: A case of corpus-based NLP technology. Computer Assisted Language Learning, 21(3), pages 283-299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Granger</author>
</authors>
<title>Prefabricated patterns in advanced EFL writing: collocations and formulae.</title>
<date>1998</date>
<pages>145--160</pages>
<editor>In Cowie, A. (ed.)</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford,</location>
<contexts>
<context position="1923" citStr="Granger (1998)" startWordPosition="274" endWordPosition="275">ng. It is often argued that collocation can influence the effectiveness of a piece of writing and the lack of such knowledge might cause cumulative loss of precision (Howarth, 1998). Many researchers have discussed the function of collocations in the highly conventionalized and specialized writing used within academia. Research also identified noticeable increases in the quantity and quality of collocational usage by * Corresponding author: Yu-chia Chang (Email address: richtrf@gmail.com) 2 Carnegie Mellon University Pittsburgh, United States teruko@cs.cmu.edu native speakers (Howarth, 1998). Granger (1998) reported that learners underuse native-like collocations and overuse atypical word combinations. This disparity in collocation usage between native and non-native speakers is clear and should receive more attention from the language technology community. To tackle such word usage problems, traditional language technology often employs a database of the learners&apos; common errors that are manually tagged by teachers or specialists (e.g. Shei and Pain, 2000; Liu, 2002). Such system then identifies errors via string or pattern matching and offer only pre-stored suggestions. Compiling the database i</context>
</contexts>
<marker>Granger, 1998</marker>
<rawString>S. Granger. 1998. Prefabricated patterns in advanced EFL writing: collocations and formulae. In Cowie, A. (ed.) Phraseology: theory, analysis and applications. Oxford University Press, Oxford, pages 145-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Howarth</author>
</authors>
<date>1996</date>
<booktitle>Phraseology in English Academic Writing.</booktitle>
<publisher>Max Niemeyer Verlag.</publisher>
<location>Tübingen:</location>
<contexts>
<context position="4075" citStr="Howarth, 1996" startWordPosition="602" endWordPosition="603">ored. To date, most fashionable suggestion methods still rely upon the linguistic components within collocations as well as the linguistic relationship between misused words and their correct counterparts (Chang et al., 2008; Liu, 2009). In contrast to other research, we employ contextual information to automate suggestions for verb-noun lexical collocation. Verb-noun collocations are recognized as presenting the most 115 Proceedings of the ACL 2010 Conference Short Papers, pages 115–119, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics challenge to students (Howarth, 1996; Liu, 2002). More specifically, in this preliminary study we start by focusing on the word choice of verbs in collocations which are considered as the most difficult ones for learners to master (Liu, 2002; Chang, 2008). The experiment confirms that our collocation writing assistant proves the feasibility of using machine learning methods to automatically prompt learners with collocation suggestions in academic writing. 2 Collocation Checking and Suggestion This study aims to develop a web service, Collocation Inspector (shown in Figure 1) that accepts sentences as input and generates the rela</context>
</contexts>
<marker>Howarth, 1996</marker>
<rawString>P. Howarth. 1996. Phraseology in English Academic Writing. Tübingen: Max Niemeyer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Howarth</author>
</authors>
<title>The phraseology of learner’s academic writing.</title>
<date>1998</date>
<pages>161--186</pages>
<editor>In Cowie, A. (ed.)</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford,</location>
<contexts>
<context position="1490" citStr="Howarth, 1998" startWordPosition="220" endWordPosition="221">ting with satisfactory results. 1 Introduction The notion of collocation has been widely discussed in the field of language teaching for decades. It has been shown that collocation, a successive common usage of words in a chain, is important in helping language learners achieve native-like fluency. In the field of English for Academic Purpose, more and more researchers are also recognizing this important feature in academic writing. It is often argued that collocation can influence the effectiveness of a piece of writing and the lack of such knowledge might cause cumulative loss of precision (Howarth, 1998). Many researchers have discussed the function of collocations in the highly conventionalized and specialized writing used within academia. Research also identified noticeable increases in the quantity and quality of collocational usage by * Corresponding author: Yu-chia Chang (Email address: richtrf@gmail.com) 2 Carnegie Mellon University Pittsburgh, United States teruko@cs.cmu.edu native speakers (Howarth, 1998). Granger (1998) reported that learners underuse native-like collocations and overuse atypical word combinations. This disparity in collocation usage between native and non-native spe</context>
</contexts>
<marker>Howarth, 1998</marker>
<rawString>P. Howarth. 1998. The phraseology of learner’s academic writing. In Cowie, A. (ed.) Phraseology: theory, analysis and applications. Oxford University Press, Oxford, pages 161-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hawking</author>
<author>N Craswell</author>
</authors>
<title>Overview of the TREC-2001 Web track.</title>
<date>2002</date>
<booktitle>In Proceedings of the 10th Text Retrieval Conference (TREC</booktitle>
<pages>25--31</pages>
<marker>Hawking, Craswell, 2002</marker>
<rawString>D. Hawking and N. Craswell. 2002. Overview of the TREC-2001 Web track. In Proceedings of the 10th Text Retrieval Conference (TREC 2001), pages 25-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L E Liu</author>
</authors>
<title>A corpus-based lexical semantic investigation of verb-noun miscollocations in Taiwan learners’ English. Unpublished master’s thesis,</title>
<date>2002</date>
<institution>Tamkang University,</institution>
<location>Taipei,</location>
<contexts>
<context position="2392" citStr="Liu, 2002" startWordPosition="345" endWordPosition="346">: richtrf@gmail.com) 2 Carnegie Mellon University Pittsburgh, United States teruko@cs.cmu.edu native speakers (Howarth, 1998). Granger (1998) reported that learners underuse native-like collocations and overuse atypical word combinations. This disparity in collocation usage between native and non-native speakers is clear and should receive more attention from the language technology community. To tackle such word usage problems, traditional language technology often employs a database of the learners&apos; common errors that are manually tagged by teachers or specialists (e.g. Shei and Pain, 2000; Liu, 2002). Such system then identifies errors via string or pattern matching and offer only pre-stored suggestions. Compiling the database is time-consuming and not easily maintainable, and the usefulness is limited by the manual collection of pre-stored suggestions. Therefore, it is beneficial if a system can mainly use untagged data from a corpus containing correct language usages rather than the errortagged data from a learner corpus. A large corpus of correct language usages is more readily available and useful than a small labeled corpus of incorrect language usages. For this suggestion task, the </context>
<context position="4087" citStr="Liu, 2002" startWordPosition="604" endWordPosition="605">most fashionable suggestion methods still rely upon the linguistic components within collocations as well as the linguistic relationship between misused words and their correct counterparts (Chang et al., 2008; Liu, 2009). In contrast to other research, we employ contextual information to automate suggestions for verb-noun lexical collocation. Verb-noun collocations are recognized as presenting the most 115 Proceedings of the ACL 2010 Conference Short Papers, pages 115–119, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics challenge to students (Howarth, 1996; Liu, 2002). More specifically, in this preliminary study we start by focusing on the word choice of verbs in collocations which are considered as the most difficult ones for learners to master (Liu, 2002; Chang, 2008). The experiment confirms that our collocation writing assistant proves the feasibility of using machine learning methods to automatically prompt learners with collocation suggestions in academic writing. 2 Collocation Checking and Suggestion This study aims to develop a web service, Collocation Inspector (shown in Figure 1) that accepts sentences as input and generates the related candidat</context>
</contexts>
<marker>Liu, 2002</marker>
<rawString>L. E. Liu. 2002. A corpus-based lexical semantic investigation of verb-noun miscollocations in Taiwan learners’ English. Unpublished master’s thesis, Tamkang University, Taipei, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Liu</author>
<author>D Wible</author>
<author>N L Tsao</author>
</authors>
<title>Automated suggestions for miscollocations.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>47--50</pages>
<marker>Liu, Wible, Tsao, 2009</marker>
<rawString>A. L. Liu, D. Wible, and N. L. Tsao. 2009. Automated suggestions for miscollocations. In Proceedings of the Fourth Workshop on Innovative Use of NLP for Building Educational Applications, pages 47-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C C Shei</author>
<author>H Pain</author>
</authors>
<title>An ESL writer’s collocational aid.</title>
<date>2000</date>
<journal>Computer Assisted Language Learning,</journal>
<volume>13</volume>
<pages>167--182</pages>
<contexts>
<context position="2380" citStr="Shei and Pain, 2000" startWordPosition="341" endWordPosition="344"> Chang (Email address: richtrf@gmail.com) 2 Carnegie Mellon University Pittsburgh, United States teruko@cs.cmu.edu native speakers (Howarth, 1998). Granger (1998) reported that learners underuse native-like collocations and overuse atypical word combinations. This disparity in collocation usage between native and non-native speakers is clear and should receive more attention from the language technology community. To tackle such word usage problems, traditional language technology often employs a database of the learners&apos; common errors that are manually tagged by teachers or specialists (e.g. Shei and Pain, 2000; Liu, 2002). Such system then identifies errors via string or pattern matching and offer only pre-stored suggestions. Compiling the database is time-consuming and not easily maintainable, and the usefulness is limited by the manual collection of pre-stored suggestions. Therefore, it is beneficial if a system can mainly use untagged data from a corpus containing correct language usages rather than the errortagged data from a learner corpus. A large corpus of correct language usages is more readily available and useful than a small labeled corpus of incorrect language usages. For this suggestio</context>
</contexts>
<marker>Shei, Pain, 2000</marker>
<rawString>C. C. Shei and H. Pain. 2000. An ESL writer’s collocational aid. Computer Assisted Language Learning, 13, pages 167-182.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>