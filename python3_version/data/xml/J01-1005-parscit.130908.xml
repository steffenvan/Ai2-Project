<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000025">
<title confidence="0.48135625">
Squibs and Discussions
Unsupervised Named Entity Recognition
Using Syntactic and Semantic Contextual
Evidence
</title>
<author confidence="0.905314">
Alessandro Cucchiarelli* Paola Velardit
</author>
<affiliation confidence="0.589225">
Universita di Ancona Universita di Roma &apos;La Sapienza&apos;
</affiliation>
<bodyText confidence="0.9764024">
Proper nouns form an open class, making the incompleteness of manually or automatically learned
classification rules an obvious problem. The purpose of this paper is twofold.first, to suggest the use
of a complementary &amp;quot;backup&amp;quot; method to increase the robustness of any hand-crafted or machine-
learning-based NE tagger; and second, to explore the effectiveness of using more fine-grained
evidence—namely, syntactic and semantic contextual knowledge—in classifying NEs.
</bodyText>
<sectionHeader confidence="0.463591" genericHeader="method">
1. Proper Noun Classification
</sectionHeader>
<bodyText confidence="0.999711190476191">
In this paper we present a corpus-driven statistical technique that uses a learning
corpus to acquire contextual classification cues, and then uses the results of this
phase to classify unrecognized proper nouns (PN) in an unlabeled corpus. Training
examples of proper nouns are obtained using any available named entity (NE) recog-
nizer (in our experiments we used a rule-based recognizer and a machine-learning-
based recognizer). The contextual model of PN categories is learned without supervi-
sion.
The approach described in this paper is complementary to current methods for
NE recognition: our objective is to improve, without additional manual effort, the
robustness of any available NE system through the use of more &amp;quot;fine-grained&amp;quot; con-
textual knowledge, best exploited at a relatively late stage of analysis. The method is
particularly useful when an available NE system must be rapidly adapted to another
language or to another domain, provided the shift is not dramatic.
Furthermore, our study provides experimental evidence relating to two issues
still under debate: i) the effectiveness, in practical NLP applications, of using syntactic
relations (most systems use plain collocations and morphological features), and ii)
context expansion based on thesauri. While we do not provide a definitive argument
in favor of syntactic contexts and semantic expansion for word sense disambiguation
tasks in general, we do show that they can be successfully used for unknown proper
noun classification. Proper nouns have particular characteristics, such as low or zero
ambiguity, which makes it easier to characterize their contexts.
</bodyText>
<sectionHeader confidence="0.368998" genericHeader="method">
2. Description of the U_PN Classification Method
</sectionHeader>
<bodyText confidence="0.991945666666667">
In this section we briefly summarize the corpus-based tagging technique for the classi-
fication of unknown proper nouns (for more details, see Cucchiarelli, Luzi, and Velardi
[1998]).
</bodyText>
<footnote confidence="0.949256">
* Istituto di Informatica, Via Brecce Bianche 1-60131 Ancona, Italy. E-mail: alex@inform.unian.it
t Dipartimento di Scienze dell&apos;Informazione, Via Salaria 113, 1-00198 Roma, Italy. E-mail: velardi@
dsi.uniromalit
</footnote>
<note confidence="0.842715">
Computational Linguistics Volume 27, Number 1
</note>
<subsectionHeader confidence="0.994617">
2.1 Learning Contextual Sense Indicators
</subsectionHeader>
<bodyText confidence="0.999944894736842">
Our method proceeds as follows: first, by means of any available NE recognition
technique (which we will call an early NE classifier), at least some examples of PNs in
each category are detected. Second, through an unsupervised corpus-based technique,
typical PN syntactic and semantic contexts are learned. Syntactic and semantic cues can
then be used to extend the coverage of the early NE classifier, increasing its robustness
to the limitations of the gazetteers (PN dictionaries) and domain shifts.
In phase one, a learning corpus in the application domain is morphologically
processed. The gazetteer lookup and the early NE classifier are then used to detect
PNs. At the end of this phase, &amp;quot;some&amp;quot; PNs are recognized and classified, depending
upon the size of the gazetteer and the actual performance (in the domain) of the NE
classifier.
In phase two, the objective is to learn a contextual model of each PN category,
augmented with syntactic and semantic features. Since the algorithm is unsupervised,
statistical techniques are applied to smooth the weight of acquired examples as a
function of semantic and syntactic ambiguity.1
Syntactic processing is applied over the corpus. A shallow parser (see details in
Basili, Pazienza, and Velardi 11990 extracts from the learning corpus elementary syn-
tactic relations such as Subject-Object, Noun-Preposition-Noun, etc.&apos; An elementary
syntactic link (es1) is represented as:
</bodyText>
<equation confidence="0.469835">
esl(w,, mod (type,, Wk))
</equation>
<bodyText confidence="0.999945875">
where wi is the headword, wk is the modifier, and type, is the type of syntactic relation
(e.g. Prepositional Phrase, Subject-Verb, Verb-Direct-Object, etc.). For example, esl(close
mod(G_N_V_Act Xerox)) reads: Xerox is the modifier of the head close in a Subject-Verb
(G_N_V_Act ) syntactic relation.
In our study, the context of a word w in a sentence S is represented by the esls
including w as one of its arguments (wi or wk). The esls that include semantically
classified PNs as one of their arguments are grouped in a database, called PN_esl.
This database provides contextual evidence for assigning a category to unknown PNs.
</bodyText>
<subsectionHeader confidence="0.999949">
2.2 Tagging Unknown PNs
</subsectionHeader>
<bodyText confidence="0.998592">
A corpus-driven algorithm is used to classify unknown proper nouns recognized as
such, but not semantically classified by the early NE recognizer.3
</bodyText>
<listItem confidence="0.999578333333333">
• Let U_PN be an unknown proper noun, i.e., a single word or a complex
nominal. Let Cr, = (Cpnl, Cpn2f • CIN) be the set of semantic categories
for proper nouns (e.g. Person, Organization, Product, etc.). Finally, let
ESL be the set of esls (often more than one in a text) that include U_PN
as one of their arguments.
• For each esl, in ESL let:
</listItem>
<footnote confidence="0.91033375">
esli(wi, mod (type,, wk)) = esli(x, LLPN)
1 We say the algorithm is unsupervised because neither the NE items detected by the early recognizer
nor the extracted syntactic contexts are inspected for correctness.
2 Shallow, or partial parsers are a well-established technique for corpus parsing. Several partial parsers
are readily available—for example, the freely downloadable LINK parser.
3 A standard POS tagger augmented with simple heuristics is used to detect possible instances of PNs.
Errors are originated only by ambiguous sentence beginners, as &amp;quot;Owens Illinois&amp;quot; or &amp;quot;Boots Plc&amp;quot;
causing partial recognition.
</footnote>
<page confidence="0.995031">
124
</page>
<note confidence="0.770381">
Cucchiarelli and Velardi Unsupervised Named Entity Recognition
</note>
<bodyText confidence="0.998120666666667">
where x = wl or x = wk and U_PN=wk or wi (the unknown PN can be
either the head or the modifier), type, is the syntactic type of esl (e.g.
N-of-N, N_N, V-for-N, etc.), and furthermore let:
</bodyText>
<equation confidence="0.875127">
pl(es11(x,U_PN))
</equation>
<bodyText confidence="0.9969036">
be the plausibility of a detected esl. Plausibility is a measure of the
statistical evidence of a detected syntactic relation (Basili, Marziali, and
Pazienza 1994; Grishman and Sterling 1994) that depends upon local
(i.e., sentence-level) syntactic ambiguity and global corpus evidence. The
plausibility accounts for the uncertainty arising from syntactic ambiguity.
</bodyText>
<listItem confidence="0.958268705882353">
• Finally, let:
- ESLA be a set of esls in PN_es1 (the previously learned
contextual model) defined as follows: for each est i(x, U_PN) in
ESL, put in ESLA the set of es1j(x,PNI) with type j type 1, x in
the same position as esli, and PNi a known proper noun, in
the same position as UPN in esli.
- ESLB be a set of esls in PN_es1 defined as follows: for each
esli(x,U_PN) in ESL put in ESLB the set of es11(w, PN1) with
type j = type, w in the same position as x in esli, Sim(w, x) &gt;
and PNi a known proper noun, in the same position as U_PN
in esti. Sim(w, x) is a similarity measure between x and w. In
our experiments, Sim(w, x) &gt; E iff w and x have a common
hyperonym H in WordNet. The generality of H (i.e., the
number of levels from x to H) is made parametric, to analyze
the effect of generalization.
• For each semantic category Cp,i, compute evidence(Cm) as:
weight • • (x)D(x,C(PN j))
</listItem>
<equation confidence="0.974279571428571">
evidence (C) = esliEESLA,C(PNi)=Cpni
E weight y(x)D(x,C(PN j))
esiicEsLA
weight y(x)D(x,C(PN j))
esliEESLB,C(PNJ)=Cpni
weight y(x)D(x,C(PN j))
esliEESLB
</equation>
<bodyText confidence="0.79988">
where:
</bodyText>
<listItem confidence="0.959532666666667">
- weight,,(x) = weight „(es1,(x, PI Vj)) = pl(eslz(x, PI V I)) • (1 am1;(kx) 1-1 )
- weighto(w) = weightu(esli(w,PNI)) = pl(esli(w,PNI)) (1 ambk(1-1
- pl(esli(x, PA T j)) is the plausibility and amb(x) is the ambiguity
of x in esti
- k is a constant factor used to incrementally reduce the influence
of ambiguous words. The smoothing is tuned to be higher in
ESLB
- a and are parametric, and can be used to study the evidence
provided by ESLA and ESLB
</listItem>
<page confidence="0.987107">
125
</page>
<note confidence="0.42489">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.9972644">
D(x, C(PNJ)) is a discrimination factor used to determine the
saliency (Yarowsky 1992) of a context es1,(x,_) for a category
C(PNI), i.e., how good a context is at discriminating between
C(PNI)and the other categories.&apos;
The selected category for U_PN is
</bodyText>
<equation confidence="0.990536">
C = argmax(evidence(Cpnk))
</equation>
<bodyText confidence="0.9993415">
When grouping all the evidence of a U_PN in a text, the underlying hypothesis is
that, in a given linguistic domain (finance, medicine, etc.), a PN has a unique sense. This
is a reasonable restriction for Proper Nouns, supported by empirical evidence, though
we would be more skeptical about the applicability of the one-sense-per-discourse
paradigm (Gale, Church, and Yarowsky 1992) to generic words. We believe that it is
precisely this restriction that makes the use of syntactic and semantic contexts effective
for PNs.
Notice that the formula of the evidence has several smoothing factors that work to-
gether to reduce the influence of unreliable or uninformative contexts. The formula also
has parameters (k, a, 0), estimated by running systematic experiments. Standard sta-
tistical techniques have been used to balance experimental conditions and the sources
of variance.
</bodyText>
<subsectionHeader confidence="0.831374">
3. Using WordNet for Context Generalization
</subsectionHeader>
<bodyText confidence="0.999867333333333">
One of the stated objectives of this paper is to investigate the effect of context gen-
eralization (the addend ESLB in the formula of the evidence) on our sense tagging
task.
The use of on-line thesauri for context generalization has already been investigated
with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997;
Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is
quite common, there are no clear indications that this is actually useful in terms of
performance. However, studying the effect of context expansion for a PN tagging task
in particular is relevant because:
</bodyText>
<listItem confidence="0.994758909090909">
• PNs may be hypothesized to have a unique sense in a text, and even in a
domain corpus. Therefore, we can reliably consider as potential sense
indicators all the contexts in which a PN appears. The only source of
ambiguity is then the word wi co-occurring in a syntactic context with a
PN, esli(wi,U_PN), but since in ESLB we group several contexts,
hopefully spurious hyperonyms of wi will gain lower evidence. For
example, consider the context &amp;quot;division of American_Brands_Inc&amp;quot;. Division
is a highly ambiguous word, but, when generalizing it, the majority of
its senses appearing in the same type of syntactic relation with a Proper
Noun (e.g. branch of Drexel_ Burnham_Lambert_Group_Inc, part of Nationale_
Nederlanden_Group) are indeed pertinent senses.
</listItem>
<footnote confidence="0.831814333333333">
4 For example, a Subject_Verb phrase with the verb make (e.g., Ace made a contract) is found with almost
equal probability with Person and Organization names. We used a simple conditional probability
model for D(x,C(PN I)), but we believe that more refined measures could improve performance.
</footnote>
<page confidence="0.988967">
126
</page>
<note confidence="0.836117">
Cucchiarelli and Velardi Unsupervised Named Entity Recognition
</note>
<listItem confidence="0.981328">
• PN categories (e.g., Person, Location, Product) exhibit a more stable and
less ambiguous contextual behavior than other more vague categories,
such as psychological feature.5
• We can study the degree of generalization at which an optimum
performance is achieved.
</listItem>
<sectionHeader confidence="0.923691" genericHeader="method">
4. Experimental Discussion
</sectionHeader>
<bodyText confidence="0.976876">
The purpose of experimental evaluation is twofold:
</bodyText>
<listItem confidence="0.998646428571429">
• To test the improvement in robustness of a state-of-the-art NE recognizer.
• To study the effectiveness of syntactic contexts and of a &amp;quot;cautious&amp;quot;
context generalization on the performance of the U_PN tagger, analyzed
in isolation. The effect of generalization is studied by gradually relaxing
the notion of similarity in the formula of evidence and by tuning,
through the factors a and 0, the contribution of generalized contexts to
the formula of evidence.
</listItem>
<bodyText confidence="0.9989925">
In our experiment, we used the Italian Sole240re half-million-word corpus on
financial news, the one-million-word Wall Street Journal corpus, and WordNet, as stan-
dard on-line available resources, as well as a series of computational tools made avail-
able for our research:
</bodyText>
<listItem confidence="0.99757475">
• the VIE system (Humphreys et al. 1996) for initial detection of Proper
Nouns from the learning corpus; for the same purpose we also used a
machine learning method based on decision lists, described in Paliouras,
Karkaletsis, and Spyropolous (1998).
• the SSA shallow syntactic analyzer (Basili, Pazienza, and Velardi 1994)
for surface corpus parsing.6
• the tool described in Cucchiarelli and Velardi (1998) for corpus-driven
WordNet pruning.&apos;
</listItem>
<subsectionHeader confidence="0.997397">
4.1 Experiment 1: Improving Robustness of NE Recognizers
</subsectionHeader>
<bodyText confidence="0.99991875">
The objective of Experiment 1 is to verify the improvement in robustness of existing
NE recognizers, through the use of our tagger. In Figure 1, three testing experiments
are shown. The table measures the local performance of the NE tagging task achieved
by the early NE recognizer, by our untrained tagger, and finally, the joint performance
of the two methods.
In the first test, we used the Italian Sole240re corpus. Due to the unavailability of
WordNet in Italian, we used a dictionary of strict synonyms for context expansion. In
this test, we &amp;quot;loosely&amp;quot; adapted the English VIE system (as used in MUC-6) to Italian.
</bodyText>
<footnote confidence="0.959210285714286">
5 In Velardi and Cucchiarelli (2000) we formally studied the relation between category type and
learnability of contextual cues for WSD.
6 We also used the GATE partial parser. We were not as successful with this parser because it is not
designed for high-performance VP_PP and NP_PP detection, but prepositional contexts are often the
most informative indicators.
7 This method produces a 20-30% reduction of the initial WordNet ambiguity, depending on the specific
corpus.
</footnote>
<page confidence="0.98597">
127
</page>
<table confidence="0.987791833333333">
Computational Linguistics Volume 27, Number 1
A B C D E F G H I J K L
Test 1 239 3 55 67.32% 339 70.50% 60 83 72.29% 75 80.00% 84.23% 88.20%
Test 2 650 793 81.90% 759 85.63% 67 83 80.72% 80 83.75% 90.42% 94.47%
Test 3 3,040 4,168 72.94% 3,233 94.03% 585 935 62.57% 810 72.22% 86.97% 89.66%
Legend
A: PNs correctly tagged by the early NE recognizer
B: Total PNs in the Test Corpus
C: Local Recall of the early NE recognizer (A/B)
D: Total PNs detected by the early NE recognizer (D = A + Al (errors) + G(unknown)
E: Local Precision of the early NE recognizer (A/D)
F: UPNs correctly tagged by the UPN tagger in the Test Corpus
G: Total UPNs not detected by the early NE recognizer
Local recall of UPN tagger (Phase2) (F/G)
I: Total UPNs for which a decision was possible by the UPN tagger
J: Local precision of the UPN tagger
K: Joint Recall of the two methods (A + F)/ B
L: Joint Precision of the two methods (A+F)/D
</table>
<figureCaption confidence="0.961044">
Figure 1
</figureCaption>
<bodyText confidence="0.989339481481482">
Outline of results on the Sole240re corpus.
We used the English gazetteer as it was and we applied simple &amp;quot;language porting&amp;quot; to
the NE grammar (e.g., replacing English words and prepositions with corresponding
Italian words, and little more).8 This justifies the low performance of the rule-based
classifier. Note that our context-based tagger produces a considerable improvement in
performance (around 18%), therefore the global performance (column K and L) turns
out to be comparable with state-of-the-art systems, without a significant readaptation
effort.
In the second test, we used again VIE, on the English Wall Street Journal corpus.
We used a version of VIE that was designed to detect NE in a management succession
domain (we are testing the effect of a domain shift here). Local performance was
somewhat lower than in MUC-6. Again, we measured a 9% improvement using our
tagger, and very high global performance.
The third test was the most demanding. Here, we used only half of the named
entity gazetteer used in previous experiments. The purpose of this test was also to
verify the effect on performance of a poorly populated gazetteer. In this test, rather than
using LASIE, we used a machine learning method described in Paliouras, Karkaletsis
and Spyropolous (1998). This method uses as a training set the available half of the
gazetteer to learn a context-based decision list for NE classification.
As shown in Test 3, column B, the initial number of PNs in the test corpus is now
considerably higher. The decision-list classifier is tuned to classify with high precision
and lower recall. Therefore, only the &amp;quot;hardest&amp;quot; cases are submitted to our untrained
classifier. In fact, local performance of our classifier is around 10% lower than for pre-
vious tests, but nevertheless, global performance (in terms of joint precision and recall)
shows an improvement. Finally, we observe that the performance figures reported in
Figure 1 say nothing about the various sources of errors. Errors and misses occur both
during the off-line learning phase (as we said, NE instances and syntactic contexts
</bodyText>
<footnote confidence="0.8678">
8 Most location and company names known worldwide (e.g., NewYork, IBM) are in fact mentioned in
economic journals regardless of the language.
</footnote>
<page confidence="0.993274">
128
</page>
<note confidence="0.886255">
Cucchiarelli and Velardi Unsupervised Named Entity Recognition
</note>
<bodyText confidence="0.99989425">
are not inspected for correctness, therefore the contextual knowledge base is error
prone) and prior to the U_PN tagging phase: a compound PN may be incompletely
recognized during POS tagging, causing the generation of an uninformative syntactic
context (e.g., &amp;quot;Owens Illinois&amp;quot; at the beginning of a sentence is recognized as &amp;quot;owens
Illinois&amp;quot;, causing a spurious N_N(owen,Illinois) context to be generated).
Because all these &amp;quot;external&amp;quot; sources of noise are not filtered out, we may then
reliably conclude that our tagger is effective at improving the robustness of proper
noun classification, though clearly the amount of improvement depends upon the
baseline performances of the early method used for PN classification.
Although the classification evidence provided by syntactic contexts is somewhat
noise prone, it proves to be useful as a &amp;quot;backup,&amp;quot; when other &amp;quot;simpler&amp;quot; contextual
evidence does not allow a reliable decision.
</bodyText>
<subsectionHeader confidence="0.999879">
4.2 Effectiveness of Syntactic and Semantic Cues for Semantic Classification
</subsectionHeader>
<bodyText confidence="0.999684222222222">
In a second experiment, we used the experimental set up of Test 2 (WSJ+VIE described
above) to evaluate the effectiveness of context expansion on system performance. We
applied a pruning method on WordNet (Cucchiarelli and Velardi 1998) to reduce initial
ambiguity of contexts. This pruning method allowed an average of 27% reduction in
the initial ambiguity of the total number of the 13,428 common nouns in the Wall
Street Journal corpus. The objective of this experiment was to allow a more detailed
evaluation of our method, with respect to several parameters.
We built four test sets with the same distribution of PN categories and frequency
distribution as in the application corpus. We selected four frequency ranges (1, 2, 3-9,
&gt; 10) and in each range we selected 100 PNs, reflecting the frequency distribution
in the corpus of the three main PN semantic categories—Person, Organization, and
Location. We then built another test set, called TSA11, with 400 PNs again reflecting the
frequency and category distribution of the corpus. The 400 PNs were then removed
from the set of 37,018 esls extracted by our parser and from the gazetteer (whenever
included).
In this experiment, we wanted to measure the performance of the U_PN tagger
over the 400 words in the test set, in terms of F-measure, according to several varying
factors:
</bodyText>
<listItem confidence="0.9996474">
• the category type;
• the amount of initial contextual evidence (i.e., the frequency range,
reflected by the different test sets);
• the factors a and 0, i.e., the influence of local and generalized contexts;
• the level of generalization L.
</listItem>
<bodyText confidence="0.9986508">
Figures 2 summarizes the results of the experiment. Figure 2(a) shows the increase
in performance as a function of the values of a and 0 and the generalization level. N
means no generalization, only the evidence provided by ESLA is computed; 0 means
that ESLB collects the evidence provided by contexts in which w is a strict synonym of
x according to WordNet; 1, 2, and 3 refer to incremental levels of generalization in the
(pruned) WordNet hierarchy. The figure shows that context generalization produces up
to 7% improvement in performance. Best results are obtained with L =-- 2 and a 0.7,
= 0.3. Further generalization may cause a drop in performance. High ambiguity is
the cause of this behavior, despite WordNet pruning (without WordNet pruning, we
observed a performance inversion at level 1; this experiment is not reported due to
</bodyText>
<page confidence="0.991316">
129
</page>
<figure confidence="0.9997245625">
Computational Linguistics
84%
82%
781.
Volume 27, Number 1
F-Wasure (L2)
..................
1210
....... 1-2
...........
951.
011%
851
7174
(I Level of Generalization 2
(a) (b)
</figure>
<figureCaption confidence="0.994862">
Figure 2
</figureCaption>
<bodyText confidence="0.990848153846154">
Evaluation of the effectiveness of context expansion.
limitations of space). Figure 2(b) illustrates the influence of initial contextual evidence.
Recognition of singleton PNs remains almost constant as the contribution of gener-
alized and nongeneralized contexts varies. Looking more in detail, we observe that
recall increases with 13 = (1— a), but precision decreases. Generalization on the basis of
a unique context does not allow any filtering of spurious senses, while when grouping
several contexts, spurious senses gain lower evidence (as anticipated in Section 3).
Finally, we designed an experiment to evaluate the influence of the test set com-
position on the U_PN tagger performances. We performed an analysis of variance
(ANOVA test Noel 19711) on the results obtained by processing nine different test
sets of 400 PNs each, selected randomly. In all our experiments the details of which
we omit, for lack of space), we found that the U-PN tagging method performances
were independent of the variations of the test set.
</bodyText>
<sectionHeader confidence="0.988068" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999372254901961">
Agirre, Eneko and German Rigau. 1996.
Word Sense Disambiguation using
Conceptual Density. In Proceedings of the
16th International Conference on
Computational Linguistics (COLING &apos;96),
Copenhagen, Denmark.
Basili, Roberto, Alessandro Marziali, and
Maria Teresa Pazienza. 1994. Modelling
syntax uncertainty in lexical acquisition
from texts. Journal of Quantitative
Linguistics, 1(1).
Basili, Roberto, Maria Teresa Pazienza, and
Paola Velardi. 1994. A (not-so) shallow
parser for collocational analysis. In
Proceedings of the 15th International
Conference on Computational Linguistics
(GANG &apos;94), Kyoto, Japan.
Brill, Erik and Philip Resnik. 1994. A
transformation-based approach to
prepositional phrase attachment
disambiguation. In Proceedings of the 15th
International Conference on Computational
Linguistics (COLING &apos;94), Kyoto, Japan.
Cucchiarelli, Alessandro, Danilo Luzi, and
Paola Velardi. 1998. Automatic semantic
tagging of unknown proper names. In
COLING-ACL &apos;98: 36th Annual Meeting of
the Association for Computational Linguistics
and 17th International Conference on
Computational Linguistics, Montreal,
Canada.
Cucchiarelli, Alessandro and Paola Velardi.
1998. Finding a domain-appropriate sense
inventory for semantically tagging a
corpus. International Journal on Natural
Language Engineering, December.
Gale, William, Kenneth Church, and David
Yarowsky. 1992. One sense per discourse.
In Proceedings of the DARPA Speech and
Natural Language Workshop. Harriman, NY.
Grishman, Ralph and John Sterling. 1994.
Generalizing automatically generated
selectional patterns. Proceedings of the 15th
International Conference on Computational
Linguistics (COLING &apos;94), Kyoto, Japan.
Hearst, Marti and Hinrich Schuetze. 1993.
Customizing a lexicon to better suite a
computational task. In Proceedings of
ACL—SIGLEX Workshop on Lexical
Acquisition from Text. Columbus, OH.
Hoel, Paul Gerhard. 1971. Introduction to
</reference>
<page confidence="0.980727">
130
</page>
<note confidence="0.780612">
Cucchiarelli and Velardi Unsupervised Named Entity Recognition
</note>
<reference confidence="0.998701466666667">
Mathematical Statistics. John Wiley &amp; Sons
Inc., New York.
Humphreys, Kevin, Robert Gaizauskas,
Hamish Cunningam, and Sheila Azzan.
1996. Technical Specifications, 1996/10/1815.
ILASH, University of Sheffield, UK.
Paliouras, George, Vartgelis Karkaletsis, and
Constantine Spyropolous. 1998. Results
from the named entity recognition task. In
Deliverable 3.2.1 of the European project
ECRAN LE 2110. Available at: http://
www2.echo.lu/langeng /en/lel /ecran/
ecran.html.
Resnik, Philip. 1997. Selectional reference
and sense disambiguation. In Proceedings
of the ACL Workshop Tagging Text with
Lexical Semantics: Why, What, and How?
Washington, DC.
Velardi, Paola and Alessandro Cucchiarelli.
2000. A theoretical analysis of
contextual-based learning algorithms for
word sense disambiguation. In Proceedings
of ECAI 2000, Berlin, Germany. (To
appear.)
Yarowsky, David. 1992 Word-sense
disambiguation using statistical models of
Roget&apos;s categories trained on large
corpora. In Proceedings of the 14th
International Conference on Computational
Linguistics (COLING &apos;92), Nantes, France.
</reference>
<page confidence="0.998033">
131
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99130075">Squibs and Discussions Unsupervised Named Entity Recognition Using Syntactic and Semantic Contextual Evidence</title>
<author confidence="0.998423">Alessandro Cucchiarelli Paola Velardit</author>
<affiliation confidence="0.905083">Universita di Ancona Universita di Roma &apos;La Sapienza&apos;</affiliation>
<abstract confidence="0.993633266990291">Proper nouns form an open class, making the incompleteness of manually or automatically learned classification rules an obvious problem. The purpose of this paper is twofold.first, to suggest the use of a complementary &amp;quot;backup&amp;quot; method to increase the robustness of any hand-crafted or machinelearning-based NE tagger; and second, to explore the effectiveness of using more fine-grained evidence—namely, syntactic and semantic contextual knowledge—in classifying NEs. 1. Proper Noun Classification In this paper we present a corpus-driven statistical technique that uses a learning corpus to acquire contextual classification cues, and then uses the results of this phase to classify unrecognized proper nouns (PN) in an unlabeled corpus. Training examples of proper nouns are obtained using any available named entity (NE) recognizer (in our experiments we used a rule-based recognizer and a machine-learningbased recognizer). The contextual model of PN categories is learned without supervision. The approach described in this paper is complementary to current methods for NE recognition: our objective is to improve, without additional manual effort, the robustness of any available NE system through the use of more &amp;quot;fine-grained&amp;quot; contextual knowledge, best exploited at a relatively late stage of analysis. The method is particularly useful when an available NE system must be rapidly adapted to another language or to another domain, provided the shift is not dramatic. Furthermore, our study provides experimental evidence relating to two issues still under debate: i) the effectiveness, in practical NLP applications, of using syntactic relations (most systems use plain collocations and morphological features), and ii) context expansion based on thesauri. While we do not provide a definitive argument in favor of syntactic contexts and semantic expansion for word sense disambiguation tasks in general, we do show that they can be successfully used for unknown proper noun classification. Proper nouns have particular characteristics, such as low or zero ambiguity, which makes it easier to characterize their contexts. 2. Description of the U_PN Classification Method In this section we briefly summarize the corpus-based tagging technique for the classification of unknown proper nouns (for more details, see Cucchiarelli, Luzi, and Velardi [1998]). * Istituto di Informatica, Via Brecce Bianche 1-60131 Ancona, Italy. E-mail: alex@inform.unian.it t Dipartimento di Scienze dell&apos;Informazione, Via Salaria 113, 1-00198 Roma, Italy. E-mail: velardi@ dsi.uniromalit Computational Linguistics Volume 27, Number 1 2.1 Learning Contextual Sense Indicators Our method proceeds as follows: first, by means of any available NE recognition (which we will call an NE classifier), least some examples of PNs in each category are detected. Second, through an unsupervised corpus-based technique, typical PN syntactic and semantic contexts are learned. Syntactic and semantic cues can then be used to extend the coverage of the early NE classifier, increasing its robustness to the limitations of the gazetteers (PN dictionaries) and domain shifts. In phase one, a learning corpus in the application domain is morphologically processed. The gazetteer lookup and the early NE classifier are then used to detect PNs. At the end of this phase, &amp;quot;some&amp;quot; PNs are recognized and classified, depending upon the size of the gazetteer and the actual performance (in the domain) of the NE classifier. In phase two, the objective is to learn a contextual model of each PN category, augmented with syntactic and semantic features. Since the algorithm is unsupervised, statistical techniques are applied to smooth the weight of acquired examples as a of semantic and syntactic Syntactic processing is applied over the corpus. A shallow parser (see details in Pazienza, and Velardi 11990 extracts from the learning corpus synrelations as Subject-Object, Noun-Preposition-Noun, etc.&apos; An link is represented as: esl(w,, mod (type,, Wk)) is the headword, wk is the modifier, and the type of syntactic relation Prepositional Phrase, Subject-Verb, Verb-Direct-Object, etc.). For example, the modifier of the head a Subject-Verb (G_N_V_Act ) syntactic relation. our study, the a word w in a sentence S is represented by the esls w as one of its arguments or esls that include semantically PNs as one of their arguments are grouped in a database, called This database provides contextual evidence for assigning a category to unknown PNs. 2.2 Tagging Unknown PNs A corpus-driven algorithm is used to classify unknown proper nouns recognized as but not semantically classified by the early NE Let an unknown proper noun, i.e., a single word or a complex Let Cpn2f the set of semantic categories for proper nouns (e.g. Person, Organization, Product, etc.). Finally, let the set of esls (often more than one in a text) that include as one of their arguments. For each esl, in mod (type,, = esli(x, LLPN) 1 We say the algorithm is unsupervised because neither the NE items detected by the early recognizer nor the extracted syntactic contexts are inspected for correctness. 2 Shallow, or partial parsers are a well-established technique for corpus parsing. Several partial parsers are readily available—for example, the freely downloadable LINK parser. 3 A standard POS tagger augmented with simple heuristics is used to detect possible instances of PNs. Errors are originated only by ambiguous sentence beginners, as &amp;quot;Owens Illinois&amp;quot; or &amp;quot;Boots Plc&amp;quot; causing partial recognition. 124 Cucchiarelli and Velardi Unsupervised Named Entity Recognition = or = and U_PN=wk or (the unknown PN can be the head or the modifier), the syntactic type of esl (e.g. N-of-N, N_N, V-for-N, etc.), and furthermore let: the a detected esl. Plausibility is a measure of the statistical evidence of a detected syntactic relation (Basili, Marziali, and Pazienza 1994; Grishman and Sterling 1994) that depends upon local (i.e., sentence-level) syntactic ambiguity and global corpus evidence. The accounts for the from syntactic ambiguity. • Finally, let: be a set of esls in PN_es1 (the previously learned model) defined as follows: for each i(x, U_PN) put in ESLA the set of jtype x same position as knownproper noun, in same position as be a set of esls in PN_es1 defined as follows: for each ESL put in ESLB the set of j= type, in the same position as Sim(w, x) &gt; knownproper noun, in the same position as Sim(w, x) a similarity measure between w. In experiments, x) w and a common WordNet. The generality of (i.e., of levels from made parametric, to analyze the effect of generalization. For each semantic category weight • • (x)D(x,C(PN j)) evidence (C) = j)) esiicEsLA esliEESLB where: weight,,(x) = weight „(es1,(x, PI = PI V • (1 ) - = = pl(esli(x, PA T j)) the plausibility and the ambiguity k a constant factor used to incrementally reduce the influence of ambiguous words. The smoothing is tuned to be higher in ESLB a and are parametric, and can be used to study the evidence by and 125 Computational Linguistics Volume 27, Number 1 a discrimination factor used to determine the (Yarowsky 1992) of a context a category i.e., how good a context is at discriminating between the other categories.&apos; The selected category for U_PN is argmax(evidence(Cpnk)) When grouping all the evidence of a U_PN in a text, the underlying hypothesis is in a given linguistic domain (finance, medicine, etc.), a PN has a This is a reasonable restriction for Proper Nouns, supported by empirical evidence, though we would be more skeptical about the applicability of the one-sense-per-discourse paradigm (Gale, Church, and Yarowsky 1992) to generic words. We believe that it is precisely this restriction that makes the use of syntactic and semantic contexts effective for PNs. Notice that the formula of the evidence has several smoothing factors that work together to reduce the influence of unreliable or uninformative contexts. The formula also parameters 0), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the addend ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: • PNs may be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense contexts in which a PN appears. The only source of is then the word co-occurring in a syntactic context with a since in we group several contexts, spurious hyperonyms of will gain lower evidence. For consider the context of American_Brands_Inc&amp;quot;. Division is a highly ambiguous word, but, when generalizing it, the majority of its senses appearing in the same type of syntactic relation with a Proper (e.g. of Drexel_ Burnham_Lambert_Group_Inc, part of Nationale_ indeed pertinent senses. For example, a Subject_Verb phrase with the verb made a contract) found with almost equal probability with Person and Organization names. We used a simple conditional probability for we believe that more refined measures could improve performance. 126 Cucchiarelli and Velardi Unsupervised Named Entity Recognition • PN categories (e.g., Person, Location, Product) exhibit a more stable and less ambiguous contextual behavior than other more vague categories, as • We can study the degree of generalization at which an optimum performance is achieved. 4. Experimental Discussion The purpose of experimental evaluation is twofold: To the improvement in robustness of a state-of-the-art NE recognizer. • To study the effectiveness of syntactic contexts and of a &amp;quot;cautious&amp;quot; context generalization on the performance of the U_PN tagger, analyzed in isolation. The effect of generalization is studied by gradually relaxing the notion of similarity in the formula of evidence and by tuning, through the factors a and 0, the contribution of generalized contexts to the formula of evidence. In our experiment, we used the Italian Sole240re half-million-word corpus on news, the one-million-word Street Journal and WordNet, as standard on-line available resources, as well as a series of computational tools made available for our research: • the VIE system (Humphreys et al. 1996) for initial detection of Proper Nouns from the learning corpus; for the same purpose we also used a machine learning method based on decision lists, described in Paliouras, Karkaletsis, and Spyropolous (1998). • the SSA shallow syntactic analyzer (Basili, Pazienza, and Velardi 1994) surface corpus • the tool described in Cucchiarelli and Velardi (1998) for corpus-driven WordNet pruning.&apos; 4.1 Experiment 1: Improving Robustness of NE Recognizers The objective of Experiment 1 is to verify the improvement in robustness of existing NE recognizers, through the use of our tagger. In Figure 1, three testing experiments are shown. The table measures the local performance of the NE tagging task achieved by the early NE recognizer, by our untrained tagger, and finally, the joint performance of the two methods. In the first test, we used the Italian Sole240re corpus. Due to the unavailability of WordNet in Italian, we used a dictionary of strict synonyms for context expansion. In this test, we &amp;quot;loosely&amp;quot; adapted the English VIE system (as used in MUC-6) to Italian. 5 In Velardi and Cucchiarelli (2000) we formally studied the relation between category type and learnability of contextual cues for WSD. 6 We also used the GATE partial parser. We were not as successful with this parser because it is not designed for high-performance VP_PP and NP_PP detection, but prepositional contexts are often the most informative indicators.</abstract>
<note confidence="0.733564222222222">7 This method produces a 20-30% reduction of the initial WordNet ambiguity, depending on the specific corpus. 127 Computational Linguistics Volume 27, Number 1 A B C D E F G H I J K L Test 1 239 3 55 67.32% 339 70.50% 60 83 72.29% 75 80.00% 84.23% 88.20% Test 2 650 793 81.90% 759 85.63% 67 83 80.72% 80 83.75% 90.42% 94.47% Test 3 3,040 4,168 72.94% 3,233 94.03% 585 935 62.57% 810 72.22% 86.97% 89.66% Legend</note>
<degree confidence="0.764365111111111">A: PNs correctly tagged by the early NE recognizer B: Total PNs in the Test Corpus C: Local Recall of the early NE recognizer (A/B) D: Total PNs detected by the early NE recognizer (D = A + Al (errors) + G(unknown) E: Local Precision of the early NE recognizer (A/D) F: UPNs correctly tagged by the UPN tagger in the Test Corpus G: Total UPNs not detected by the early NE recognizer Local recall of UPN tagger (Phase2) (F/G) I: Total UPNs for which a decision was possible by the UPN tagger</degree>
<abstract confidence="0.990759679012345">J: Local precision of the UPN tagger K: Joint Recall of the two methods (A + F)/ B L: Joint Precision of the two methods (A+F)/D Figure 1 Outline of results on the Sole240re corpus. We used the English gazetteer as it was and we applied simple &amp;quot;language porting&amp;quot; to the NE grammar (e.g., replacing English words and prepositions with corresponding words, and little This justifies the low performance of the rule-based classifier. Note that our context-based tagger produces a considerable improvement in performance (around 18%), therefore the global performance (column K and L) turns out to be comparable with state-of-the-art systems, without a significant readaptation effort. the second test, we used again VIE, on the English Street Journal We used a version of VIE that was designed to detect NE in a management succession domain (we are testing the effect of a domain shift here). Local performance was somewhat lower than in MUC-6. Again, we measured a 9% improvement using our tagger, and very high global performance. The third test was the most demanding. Here, we used only half of the named entity gazetteer used in previous experiments. The purpose of this test was also to verify the effect on performance of a poorly populated gazetteer. In this test, rather than using LASIE, we used a machine learning method described in Paliouras, Karkaletsis and Spyropolous (1998). This method uses as a training set the available half of the gazetteer to learn a context-based decision list for NE classification. As shown in Test 3, column B, the initial number of PNs in the test corpus is now considerably higher. The decision-list classifier is tuned to classify with high precision and lower recall. Therefore, only the &amp;quot;hardest&amp;quot; cases are submitted to our untrained classifier. In fact, local performance of our classifier is around 10% lower than for previous tests, but nevertheless, global performance (in terms of joint precision and recall) shows an improvement. Finally, we observe that the performance figures reported in Figure 1 say nothing about the various sources of errors. Errors and misses occur both during the off-line learning phase (as we said, NE instances and syntactic contexts 8 Most location and company names known worldwide (e.g., NewYork, IBM) are in fact mentioned in economic journals regardless of the language. 128 Cucchiarelli and Velardi Unsupervised Named Entity Recognition are not inspected for correctness, therefore the contextual knowledge base is error prone) and prior to the U_PN tagging phase: a compound PN may be incompletely recognized during POS tagging, causing the generation of an uninformative syntactic context (e.g., &amp;quot;Owens Illinois&amp;quot; at the beginning of a sentence is recognized as &amp;quot;owens Illinois&amp;quot;, causing a spurious N_N(owen,Illinois) context to be generated). Because all these &amp;quot;external&amp;quot; sources of noise are not filtered out, we may then reliably conclude that our tagger is effective at improving the robustness of proper noun classification, though clearly the amount of improvement depends upon the baseline performances of the early method used for PN classification. Although the classification evidence provided by syntactic contexts is somewhat noise prone, it proves to be useful as a &amp;quot;backup,&amp;quot; when other &amp;quot;simpler&amp;quot; contextual evidence does not allow a reliable decision. 4.2 Effectiveness of Syntactic and Semantic Cues for Semantic Classification In a second experiment, we used the experimental set up of Test 2 (WSJ+VIE described above) to evaluate the effectiveness of context expansion on system performance. We applied a pruning method on WordNet (Cucchiarelli and Velardi 1998) to reduce initial ambiguity of contexts. This pruning method allowed an average of 27% reduction in initial ambiguity of the total number of the 13,428 in the Wall Street Journal corpus. The objective of this experiment was to allow a more detailed evaluation of our method, with respect to several parameters. We built four test sets with the same distribution of PN categories and frequency distribution as in the application corpus. We selected four frequency ranges (1, 2, 3-9, &gt; 10) and in each range we selected 100 PNs, reflecting the frequency distribution in the corpus of the three main PN semantic categories—Person, Organization, and Location. We then built another test set, called TSA11, with 400 PNs again reflecting the frequency and category distribution of the corpus. The 400 PNs were then removed from the set of 37,018 esls extracted by our parser and from the gazetteer (whenever included). In this experiment, we wanted to measure the performance of the U_PN tagger over the 400 words in the test set, in terms of F-measure, according to several varying factors: • the category type; • the amount of initial contextual evidence (i.e., the frequency range, reflected by the different test sets); • the factors a and 0, i.e., the influence of local and generalized contexts; • the level of generalization L. Figures 2 summarizes the results of the experiment. Figure 2(a) shows the increase in performance as a function of the values of a and 0 and the generalization level. N means no generalization, only the evidence provided by ESLA is computed; 0 means ESLB collects the evidence provided by contexts in which w is a synonym x according to WordNet; 1, 2, and 3 refer to incremental levels of generalization in the (pruned) WordNet hierarchy. The figure shows that context generalization produces up 7% improvement in performance. Best results are obtained with L =-- 2 and Further generalization may cause a drop in performance. High ambiguity is the cause of this behavior, despite WordNet pruning (without WordNet pruning, we observed a performance inversion at level 1; this experiment is not reported due to</abstract>
<note confidence="0.729556384615385">129 Computational Linguistics 84% 82% 781. Volume 27, Number 1 F-Wasure (L2) .................. 1210 ........... 951. 011% 851</note>
<date confidence="0.37396">7174</date>
<abstract confidence="0.995904933333333">of Generalization 2 Figure 2 Evaluation of the effectiveness of context expansion. limitations of space). Figure 2(b) illustrates the influence of initial contextual evidence. Recognition of singleton PNs remains almost constant as the contribution of generalized and nongeneralized contexts varies. Looking more in detail, we observe that increases with = (1— a), but precision decreases. Generalization on the basis of a unique context does not allow any filtering of spurious senses, while when grouping several contexts, spurious senses gain lower evidence (as anticipated in Section 3). Finally, we designed an experiment to evaluate the influence of the test set composition on the U_PN tagger performances. We performed an analysis of variance (ANOVA test Noel 19711) on the results obtained by processing nine different test sets of 400 PNs each, selected randomly. In all our experiments the details of which we omit, for lack of space), we found that the U-PN tagging method performances were independent of the variations of the test set.</abstract>
<note confidence="0.838614760869565">References Agirre, Eneko and German Rigau. 1996. Word Sense Disambiguation using Density. In of the 16th International Conference on Computational Linguistics (COLING &apos;96), Copenhagen, Denmark. Basili, Roberto, Alessandro Marziali, and Maria Teresa Pazienza. 1994. Modelling syntax uncertainty in lexical acquisition texts. of Quantitative Basili, Roberto, Maria Teresa Pazienza, and Paola Velardi. 1994. A (not-so) shallow parser for collocational analysis. In Proceedings of the 15th International Conference on Computational Linguistics &apos;94), Japan. Brill, Erik and Philip Resnik. 1994. A transformation-based approach to prepositional phrase attachment In of the 15th International Conference on Computational (COLING &apos;94), Japan. Cucchiarelli, Alessandro, Danilo Luzi, and Paola Velardi. 1998. Automatic semantic tagging of unknown proper names. In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Linguistics, Canada. Cucchiarelli, Alessandro and Paola Velardi. 1998. Finding a domain-appropriate sense inventory for semantically tagging a Journal on Natural Engineering, Gale, William, Kenneth Church, and David Yarowsky. 1992. One sense per discourse. of the DARPA Speech and Language Workshop. NY. Grishman, Ralph and John Sterling. 1994. Generalizing automatically generated patterns. of the 15th International Conference on Computational (COLING &apos;94), Japan. Hearst, Marti and Hinrich Schuetze. 1993.</note>
<title confidence="0.666705">Customizing a lexicon to better suite a task. In of ACL—SIGLEX Workshop on Lexical</title>
<author confidence="0.475306">OH Paul Gerhard</author>
<note confidence="0.5713613">130 Cucchiarelli and Velardi Unsupervised Named Entity Recognition Statistics. Wiley &amp; Sons Inc., New York. Humphreys, Kevin, Robert Gaizauskas, Hamish Cunningam, and Sheila Azzan. Specifications, 1996/10/1815. ILASH, University of Sheffield, UK. Paliouras, George, Vartgelis Karkaletsis, and Constantine Spyropolous. 1998. Results</note>
<abstract confidence="0.698674954545455">from the named entity recognition task. In Deliverable 3.2.1 of the European project ECRAN LE 2110. Available at: http:// www2.echo.lu/langeng /en/lel /ecran/ ecran.html. Resnik, Philip. 1997. Selectional reference sense disambiguation. In of the ACL Workshop Tagging Text with Lexical Semantics: Why, What, and How? Washington, DC. Velardi, Paola and Alessandro Cucchiarelli. 2000. A theoretical analysis of contextual-based learning algorithms for sense disambiguation. In ECAI 2000, Germany. (To appear.) Yarowsky, David. 1992 Word-sense disambiguation using statistical models of Roget&apos;s categories trained on large In of the 14th International Conference on Computational (COLING &apos;92), France.</abstract>
<intro confidence="0.486255">131</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>German Rigau</author>
</authors>
<title>Word Sense Disambiguation using Conceptual Density.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING &apos;96),</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="9851" citStr="Agirre and Rigau 1996" startWordPosition="1550" endWordPosition="1553">ive contexts. The formula also has parameters (k, a, 0), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. 3. Using WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the addend ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: • PNs may be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense indicators all the contexts in which a PN appears. The only source of ambiguity is then the word wi co-occurring in a syntactic context with a PN, esli(wi,U_PN), but since in ESLB we group </context>
</contexts>
<marker>Agirre, Rigau, 1996</marker>
<rawString>Agirre, Eneko and German Rigau. 1996. Word Sense Disambiguation using Conceptual Density. In Proceedings of the 16th International Conference on Computational Linguistics (COLING &apos;96), Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Alessandro Marziali</author>
<author>Maria Teresa Pazienza</author>
</authors>
<title>Modelling syntax uncertainty in lexical acquisition from texts.</title>
<date>1994</date>
<journal>Journal of Quantitative Linguistics,</journal>
<volume>1</volume>
<issue>1</issue>
<marker>Basili, Marziali, Pazienza, 1994</marker>
<rawString>Basili, Roberto, Alessandro Marziali, and Maria Teresa Pazienza. 1994. Modelling syntax uncertainty in lexical acquisition from texts. Journal of Quantitative Linguistics, 1(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Maria Teresa Pazienza</author>
<author>Paola Velardi</author>
</authors>
<title>A (not-so) shallow parser for collocational analysis.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (GANG &apos;94),</booktitle>
<location>Kyoto, Japan.</location>
<marker>Basili, Pazienza, Velardi, 1994</marker>
<rawString>Basili, Roberto, Maria Teresa Pazienza, and Paola Velardi. 1994. A (not-so) shallow parser for collocational analysis. In Proceedings of the 15th International Conference on Computational Linguistics (GANG &apos;94), Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Brill</author>
<author>Philip Resnik</author>
</authors>
<title>A transformation-based approach to prepositional phrase attachment disambiguation.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94),</booktitle>
<location>Kyoto, Japan.</location>
<contexts>
<context position="9814" citStr="Brill and Resnik 1994" startWordPosition="1544" endWordPosition="1547">nfluence of unreliable or uninformative contexts. The formula also has parameters (k, a, 0), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. 3. Using WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the addend ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: • PNs may be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense indicators all the contexts in which a PN appears. The only source of ambiguity is then the word wi co-occurring in a syntactic context with a PN, esli(</context>
</contexts>
<marker>Brill, Resnik, 1994</marker>
<rawString>Brill, Erik and Philip Resnik. 1994. A transformation-based approach to prepositional phrase attachment disambiguation. In Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94), Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Cucchiarelli</author>
<author>Danilo Luzi</author>
<author>Paola Velardi</author>
</authors>
<title>Automatic semantic tagging of unknown proper names.</title>
<date>1998</date>
<booktitle>In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<location>Montreal, Canada.</location>
<marker>Cucchiarelli, Luzi, Velardi, 1998</marker>
<rawString>Cucchiarelli, Alessandro, Danilo Luzi, and Paola Velardi. 1998. Automatic semantic tagging of unknown proper names. In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Cucchiarelli</author>
<author>Paola Velardi</author>
</authors>
<title>Finding a domain-appropriate sense inventory for semantically tagging a corpus.</title>
<date>1998</date>
<journal>International Journal on Natural Language Engineering,</journal>
<contexts>
<context position="12722" citStr="Cucchiarelli and Velardi (1998)" startWordPosition="1995" endWordPosition="1998">alf-million-word corpus on financial news, the one-million-word Wall Street Journal corpus, and WordNet, as standard on-line available resources, as well as a series of computational tools made available for our research: • the VIE system (Humphreys et al. 1996) for initial detection of Proper Nouns from the learning corpus; for the same purpose we also used a machine learning method based on decision lists, described in Paliouras, Karkaletsis, and Spyropolous (1998). • the SSA shallow syntactic analyzer (Basili, Pazienza, and Velardi 1994) for surface corpus parsing.6 • the tool described in Cucchiarelli and Velardi (1998) for corpus-driven WordNet pruning.&apos; 4.1 Experiment 1: Improving Robustness of NE Recognizers The objective of Experiment 1 is to verify the improvement in robustness of existing NE recognizers, through the use of our tagger. In Figure 1, three testing experiments are shown. The table measures the local performance of the NE tagging task achieved by the early NE recognizer, by our untrained tagger, and finally, the joint performance of the two methods. In the first test, we used the Italian Sole240re corpus. Due to the unavailability of WordNet in Italian, we used a dictionary of strict synony</context>
<context position="18402" citStr="Cucchiarelli and Velardi 1998" startWordPosition="2922" endWordPosition="2925">amount of improvement depends upon the baseline performances of the early method used for PN classification. Although the classification evidence provided by syntactic contexts is somewhat noise prone, it proves to be useful as a &amp;quot;backup,&amp;quot; when other &amp;quot;simpler&amp;quot; contextual evidence does not allow a reliable decision. 4.2 Effectiveness of Syntactic and Semantic Cues for Semantic Classification In a second experiment, we used the experimental set up of Test 2 (WSJ+VIE described above) to evaluate the effectiveness of context expansion on system performance. We applied a pruning method on WordNet (Cucchiarelli and Velardi 1998) to reduce initial ambiguity of contexts. This pruning method allowed an average of 27% reduction in the initial ambiguity of the total number of the 13,428 common nouns in the Wall Street Journal corpus. The objective of this experiment was to allow a more detailed evaluation of our method, with respect to several parameters. We built four test sets with the same distribution of PN categories and frequency distribution as in the application corpus. We selected four frequency ranges (1, 2, 3-9, &gt; 10) and in each range we selected 100 PNs, reflecting the frequency distribution in the corpus of </context>
</contexts>
<marker>Cucchiarelli, Velardi, 1998</marker>
<rawString>Cucchiarelli, Alessandro and Paola Velardi. 1998. Finding a domain-appropriate sense inventory for semantically tagging a corpus. International Journal on Natural Language Engineering, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Gale</author>
<author>Kenneth Church</author>
<author>David Yarowsky</author>
</authors>
<title>One sense per discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the DARPA Speech and Natural Language Workshop.</booktitle>
<location>Harriman, NY.</location>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale, William, Kenneth Church, and David Yarowsky. 1992. One sense per discourse. In Proceedings of the DARPA Speech and Natural Language Workshop. Harriman, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>John Sterling</author>
</authors>
<title>Generalizing automatically generated selectional patterns.</title>
<date>1994</date>
<booktitle>Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94),</booktitle>
<location>Kyoto, Japan.</location>
<contexts>
<context position="6550" citStr="Grishman and Sterling 1994" startWordPosition="994" endWordPosition="997">d to detect possible instances of PNs. Errors are originated only by ambiguous sentence beginners, as &amp;quot;Owens Illinois&amp;quot; or &amp;quot;Boots Plc&amp;quot; causing partial recognition. 124 Cucchiarelli and Velardi Unsupervised Named Entity Recognition where x = wl or x = wk and U_PN=wk or wi (the unknown PN can be either the head or the modifier), type, is the syntactic type of esl (e.g. N-of-N, N_N, V-for-N, etc.), and furthermore let: pl(es11(x,U_PN)) be the plausibility of a detected esl. Plausibility is a measure of the statistical evidence of a detected syntactic relation (Basili, Marziali, and Pazienza 1994; Grishman and Sterling 1994) that depends upon local (i.e., sentence-level) syntactic ambiguity and global corpus evidence. The plausibility accounts for the uncertainty arising from syntactic ambiguity. • Finally, let: - ESLA be a set of esls in PN_es1 (the previously learned contextual model) defined as follows: for each est i(x, U_PN) in ESL, put in ESLA the set of es1j(x,PNI) with type j type 1, x in the same position as esli, and PNi a known proper noun, in the same position as UPN in esli. - ESLB be a set of esls in PN_es1 defined as follows: for each esli(x,U_PN) in ESL put in ESLB the set of es11(w, PN1) with typ</context>
</contexts>
<marker>Grishman, Sterling, 1994</marker>
<rawString>Grishman, Ralph and John Sterling. 1994. Generalizing automatically generated selectional patterns. Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94), Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
<author>Hinrich Schuetze</author>
</authors>
<title>Customizing a lexicon to better suite a computational task.</title>
<date>1993</date>
<booktitle>In Proceedings of ACL—SIGLEX Workshop on Lexical Acquisition from Text.</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="9791" citStr="Hearst and Schuetze 1993" startWordPosition="1540" endWordPosition="1543">k together to reduce the influence of unreliable or uninformative contexts. The formula also has parameters (k, a, 0), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. 3. Using WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the addend ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: • PNs may be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense indicators all the contexts in which a PN appears. The only source of ambiguity is then the word wi co-occurring in a syntactic c</context>
</contexts>
<marker>Hearst, Schuetze, 1993</marker>
<rawString>Hearst, Marti and Hinrich Schuetze. 1993. Customizing a lexicon to better suite a computational task. In Proceedings of ACL—SIGLEX Workshop on Lexical Acquisition from Text. Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Gerhard Hoel</author>
</authors>
<title>Introduction to Mathematical Statistics.</title>
<date>1971</date>
<publisher>John Wiley &amp; Sons Inc.,</publisher>
<location>New York.</location>
<marker>Hoel, 1971</marker>
<rawString>Hoel, Paul Gerhard. 1971. Introduction to Mathematical Statistics. John Wiley &amp; Sons Inc., New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Humphreys</author>
<author>Robert Gaizauskas</author>
<author>Hamish Cunningam</author>
<author>Sheila Azzan</author>
</authors>
<date>1996</date>
<tech>Technical Specifications,</tech>
<publisher>ILASH, University of Sheffield, UK.</publisher>
<contexts>
<context position="12353" citStr="Humphreys et al. 1996" startWordPosition="1939" endWordPosition="1942">ntext generalization on the performance of the U_PN tagger, analyzed in isolation. The effect of generalization is studied by gradually relaxing the notion of similarity in the formula of evidence and by tuning, through the factors a and 0, the contribution of generalized contexts to the formula of evidence. In our experiment, we used the Italian Sole240re half-million-word corpus on financial news, the one-million-word Wall Street Journal corpus, and WordNet, as standard on-line available resources, as well as a series of computational tools made available for our research: • the VIE system (Humphreys et al. 1996) for initial detection of Proper Nouns from the learning corpus; for the same purpose we also used a machine learning method based on decision lists, described in Paliouras, Karkaletsis, and Spyropolous (1998). • the SSA shallow syntactic analyzer (Basili, Pazienza, and Velardi 1994) for surface corpus parsing.6 • the tool described in Cucchiarelli and Velardi (1998) for corpus-driven WordNet pruning.&apos; 4.1 Experiment 1: Improving Robustness of NE Recognizers The objective of Experiment 1 is to verify the improvement in robustness of existing NE recognizers, through the use of our tagger. In Fi</context>
</contexts>
<marker>Humphreys, Gaizauskas, Cunningam, Azzan, 1996</marker>
<rawString>Humphreys, Kevin, Robert Gaizauskas, Hamish Cunningam, and Sheila Azzan. 1996. Technical Specifications, 1996/10/1815. ILASH, University of Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Paliouras</author>
<author>Vartgelis Karkaletsis</author>
<author>Constantine Spyropolous</author>
</authors>
<title>Results from the named entity recognition task.</title>
<date>1998</date>
<booktitle>In Deliverable 3.2.1 of the European project ECRAN LE</booktitle>
<pages>2110</pages>
<note>Available at: http:// www2.echo.lu/langeng /en/lel /ecran/ ecran.html.</note>
<marker>Paliouras, Karkaletsis, Spyropolous, 1998</marker>
<rawString>Paliouras, George, Vartgelis Karkaletsis, and Constantine Spyropolous. 1998. Results from the named entity recognition task. In Deliverable 3.2.1 of the European project ECRAN LE 2110. Available at: http:// www2.echo.lu/langeng /en/lel /ecran/ ecran.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional reference and sense disambiguation.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL Workshop Tagging Text with Lexical Semantics: Why, What, and How?</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="9827" citStr="Resnik 1997" startWordPosition="1548" endWordPosition="1549">or uninformative contexts. The formula also has parameters (k, a, 0), estimated by running systematic experiments. Standard statistical techniques have been used to balance experimental conditions and the sources of variance. 3. Using WordNet for Context Generalization One of the stated objectives of this paper is to investigate the effect of context generalization (the addend ESLB in the formula of the evidence) on our sense tagging task. The use of on-line thesauri for context generalization has already been investigated with limited success (Hearst and Schuetze 1993; Brill and Resnik 1994; Resnik 1997; Agirre and Rigau 1996). Though the idea of using thesauri for context expansion is quite common, there are no clear indications that this is actually useful in terms of performance. However, studying the effect of context expansion for a PN tagging task in particular is relevant because: • PNs may be hypothesized to have a unique sense in a text, and even in a domain corpus. Therefore, we can reliably consider as potential sense indicators all the contexts in which a PN appears. The only source of ambiguity is then the word wi co-occurring in a syntactic context with a PN, esli(wi,U_PN), but</context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>Resnik, Philip. 1997. Selectional reference and sense disambiguation. In Proceedings of the ACL Workshop Tagging Text with Lexical Semantics: Why, What, and How? Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Velardi</author>
<author>Alessandro Cucchiarelli</author>
</authors>
<title>A theoretical analysis of contextual-based learning algorithms for word sense disambiguation.</title>
<date>2000</date>
<booktitle>In Proceedings of ECAI 2000,</booktitle>
<location>Berlin, Germany.</location>
<note>(To appear.)</note>
<contexts>
<context position="13473" citStr="Velardi and Cucchiarelli (2000)" startWordPosition="2117" endWordPosition="2120">t 1 is to verify the improvement in robustness of existing NE recognizers, through the use of our tagger. In Figure 1, three testing experiments are shown. The table measures the local performance of the NE tagging task achieved by the early NE recognizer, by our untrained tagger, and finally, the joint performance of the two methods. In the first test, we used the Italian Sole240re corpus. Due to the unavailability of WordNet in Italian, we used a dictionary of strict synonyms for context expansion. In this test, we &amp;quot;loosely&amp;quot; adapted the English VIE system (as used in MUC-6) to Italian. 5 In Velardi and Cucchiarelli (2000) we formally studied the relation between category type and learnability of contextual cues for WSD. 6 We also used the GATE partial parser. We were not as successful with this parser because it is not designed for high-performance VP_PP and NP_PP detection, but prepositional contexts are often the most informative indicators. 7 This method produces a 20-30% reduction of the initial WordNet ambiguity, depending on the specific corpus. 127 Computational Linguistics Volume 27, Number 1 A B C D E F G H I J K L Test 1 239 3 55 67.32% 339 70.50% 60 83 72.29% 75 80.00% 84.23% 88.20% Test 2 650 793 8</context>
</contexts>
<marker>Velardi, Cucchiarelli, 2000</marker>
<rawString>Velardi, Paola and Alessandro Cucchiarelli. 2000. A theoretical analysis of contextual-based learning algorithms for word sense disambiguation. In Proceedings of ECAI 2000, Berlin, Germany. (To appear.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word-sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING &apos;92),</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="8370" citStr="Yarowsky 1992" startWordPosition="1320" endWordPosition="1321">C(PN j)) esliEESLB where: - weight,,(x) = weight „(es1,(x, PI Vj)) = pl(eslz(x, PI V I)) • (1 am1;(kx) 1-1 ) - weighto(w) = weightu(esli(w,PNI)) = pl(esli(w,PNI)) (1 ambk(1-1 - pl(esli(x, PA T j)) is the plausibility and amb(x) is the ambiguity of x in esti - k is a constant factor used to incrementally reduce the influence of ambiguous words. The smoothing is tuned to be higher in ESLB - a and are parametric, and can be used to study the evidence provided by ESLA and ESLB 125 Computational Linguistics Volume 27, Number 1 D(x, C(PNJ)) is a discrimination factor used to determine the saliency (Yarowsky 1992) of a context es1,(x,_) for a category C(PNI), i.e., how good a context is at discriminating between C(PNI)and the other categories.&apos; The selected category for U_PN is C = argmax(evidence(Cpnk)) When grouping all the evidence of a U_PN in a text, the underlying hypothesis is that, in a given linguistic domain (finance, medicine, etc.), a PN has a unique sense. This is a reasonable restriction for Proper Nouns, supported by empirical evidence, though we would be more skeptical about the applicability of the one-sense-per-discourse paradigm (Gale, Church, and Yarowsky 1992) to generic words. We </context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>Yarowsky, David. 1992 Word-sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora. In Proceedings of the 14th International Conference on Computational Linguistics (COLING &apos;92), Nantes, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>