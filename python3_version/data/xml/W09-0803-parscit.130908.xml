<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000134">
<title confidence="0.993944">
Revisiting multi-tape automata for Semitic morphological analysis and
generation
</title>
<author confidence="0.990354">
Mans Hulden
</author>
<affiliation confidence="0.9975765">
University of Arizona
Department of Linguistics
</affiliation>
<email confidence="0.997233">
mhulden@email.arizona.edu
</email>
<sectionHeader confidence="0.997377" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999853227272727">
Various methods have been devised to pro-
duce morphological analyzers and gen-
erators for Semitic languages, ranging
from methods based on widely used finite-
state technologies to very specific solu-
tions designed for a specific language
or problem. Since the earliest propos-
als of how to adopt the elsewhere suc-
cessful finite-state methods to root-and-
pattern morphologies, the solution of en-
coding Semitic grammars using multi-tape
automata has resurfaced on a regular ba-
sis. Multi-tape automata, however, require
specific algorithms and reimplementation
of finite-state operators across the board,
and hence such technology has not been
readily available to linguists. This paper,
using an actual Arabic grammar as a case
study, describes an approach to encoding
multi-tape automata on a single tape that
can be implemented using any standard
finite-automaton toolkit.
</bodyText>
<sectionHeader confidence="0.999884" genericHeader="keywords">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.988728">
1.1 Root-and-pattern morphology and
finite-state systems
</subsectionHeader>
<bodyText confidence="0.996467097560976">
The special problems and challenges embodied by
Semitic languages have been recognized from the
early days of applying finite-state methods to nat-
ural language morphological analysis. The lan-
guage model which finite-state methods have been
most successful in describing—a model where
morphemes concatenate in mostly strict linear
order—does not translate congenially to the type
of root-and-pattern morphology found in e.g. Ara-
bic and Hebrew (Kataja and Koskenniemi, 1988;
Lavie et al., 1988).
In Arabic, as in most Semitic languages, verbs
have for a long time been analyzed as consist-
ing of three elements: a (most often) triconsonan-
tal root, such as ktb (u u� d), a vowel pattern
containing grammatical information such as voice
(e.g. the vowel a) and a derivational template,
such as CVCVC indicating the class of the verb, all
of which are interdigitated to build a stem, such
�
as katab (�� ����).1 This stem is in turn subject to
more familiar morphological constructions includ-
ing prefixation and suffixation, yielding informa-
tion such as number, person, etc, such as kataba
( ��� ���), the third person singular masculine perfect
form.
The difficulty of capturing this interdigitation
process is not an inherent shortcoming of finite-
state automata or transducers per se, but rather
a result of the methods that are commonly used
to construct automata. Regular expressions that
contain operations such as concatenation, union,
intersection, as well as morphotactic descriptions
through right-linear grammars offer an unwieldy
functionality when it comes to interleaving strings
with one another in a regulated way. But, one
could argue, since large scale morphological ana-
lyzers as finite-state automata/transducers have in-
deed been built (see e.g. Beesley (1996, 1998b,a)),
the question of how to do it becomes one of con-
struction, not feasibility.
</bodyText>
<subsectionHeader confidence="0.994563">
1.2 Multitape automata
</subsectionHeader>
<bodyText confidence="0.999989666666667">
One early approach, suggested by Kay (1987) and
later pursued in different variants by Kiraz (1994,
2000) among others, was to, instead of modeling
morphology along the more traditional finite-state
transducer, modeling it with a n-tape automaton,
where tapes would carry precisely this interleaving
</bodyText>
<footnote confidence="0.996687166666667">
1Following autosegmental analyses, this paper assumes
the model where the vocalization is not merged with the pat-
tern, i.e. we do not list separate patterns for vocalizations
such as CaCaC as is assumed more traditionally. Which anal-
ysis to choose largely a matter of convenience, and the meth-
ods in this paper apply to either one.
</footnote>
<note confidence="0.969221">
Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 19–26,
Athens, Greece, 31 March, 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.999211">
19
</page>
<bodyText confidence="0.999949916666667">
that is called for in Semitic interdigitation. How-
ever, large-scale multitape solutions containing the
magnitude of information in standard Arabic dic-
tionaries such as Wehr (1979) have not been re-
ported.
To our knowledge, two large-scale morphologi-
cal analyzers for Arabic that strive for reasonable
completeness have been been built: one by Xerox
and one by Tim Buckwalter (Buckwalter, 2004).
The Xerox analyzer relies on complex extensions
to the finite-state calculus of one and two-tape
automata (transducers) as documented in Beesley
and Karttunen (2003), while Buckwalter’s system
is a procedural approach written in Perl which de-
composes a word and simultaneously consults lex-
ica for constraining the possible decompositions.
Also, in a similar vein to Xerox’s Arabic analyzer,
Yona and Wintner (2008) report on a large-scale
system for Hebrew built on transducer technology.
Most importantly, none of these very large systems
are built around multi-tape automata even though
such a construction from a linguistic perspective
would appear to be a fitting choice when dealing
with root-and-pattern morphology.
</bodyText>
<subsectionHeader confidence="0.996844">
1.3 n-tape space complexity
</subsectionHeader>
<bodyText confidence="0.999952225">
There is a fundamental space complexity problem
with multi-tape automata, which is that when the
number of tapes grows, the required joint sym-
bol alphabet grows with exponential rapidity un-
less special mechanisms are devised to curtail this
growth. This explosion in the number of transi-
tions in an n-tape automaton can in many cases
be more severe than the growth in the number of
states of a complex grammar.
To take a simple, though admittedly slightly ar-
tificial example: suppose we have a 5-tape au-
tomaton, each tape consisting of the same alpha-
bet of, say 22 symbols {s1, ... , s221. Now, as-
sume we want to restrict the co-occurrence of s1
on any combination of tapes, meaning s1 can only
occur once on one tape in the same position, i.e.
we would be accepting any strings containing a
symbol such as s1:s2:s2:s2:s2 or s2:s2:s2:s2:s3
but not, s1:s2:s3:s4:s1. Without further treatment
of the alphabet behavior, this yields a multi-tape
automaton which has a single state, but 5,056,506
transitions—each transition naturally representing
a legal combination of symbols on the five tapes.
This kind of transition blow-up is not completely
inevitable: of course one can devise many tricks
to avoid it, such as adding certain semantics to
the transition notation—in our example by per-
haps having a special type of ‘failure’ transition
which leads to non-acceptance. For the above ex-
ample this would cut down the number of tran-
sitions from 5,056,506 to 97,126. The drawback
with such methods is that any changes will tend
to affect the entire finite-state system one is work-
ing with, requiring adaptations in almost every un-
derlying algorithm to construct automata. One is
then unable to leverage the power of existing soft-
ware designed for finite-state morphological anal-
ysis, but needs to build special-purpose software
for whatever multi-tape implementation one has in
mind.2
</bodyText>
<subsectionHeader confidence="0.998296">
1.4 The appeal of the multi-tape solution
</subsectionHeader>
<bodyText confidence="0.99655672972973">
The reason multi-tape descriptions of natural lan-
guage morphology are appealing lies not only
in that such solutions seem to be able to han-
dle Semitic verbal interdigitation, but also in
that a multi-tape solution allows for a natural
alignment of information regarding segments and
their grammatical features, something which is
often missing in finite-state-based solutions to
morphological analysis. In the now-classical
way of constructing morphological analyzers, we
have a transducer that maps a string represent-
ing an unanalyzed word form, such as kataba
( ��� �����) to a string representing an analyzed one,
e.g. ktb +FormI +Perfect +Act +3P
+Masc +Sg. Such transductions seldom pro-
vide grammatical component-wise alignment in-
formation telling which parts of the unanalyzed
words contribute to which parts of the grammat-
ical information. Particularly if morphemes signi-
fying a grammatical category are discontinuous,
this information is difficult to provide naturally
in a finite-automaton based system without many
tapes. A multi-tape solution, on the other hand,
2Two anonymous reviewers point out the work by Habash
et al. (2005) and Habash and Rambow (2006) who report an
effort to analyze Arabic with such a multitape system based
on work by Kiraz (2000, 2001) that relies on custom algo-
rithms devised for a multitape alphabet. Although Habash
and Rambow do not discuss the space requirements in their
system, it is to be suspected that the number of transitions
grows quickly using such an method by virtue of the argu-
ment given above. These approaches also use a small number
of tapes (between 3 and 5), and, since the number of tran-
sitions can increase exponentially with the number of tapes
used, such systems do not on the face of it appear to scale
well to more than a handful of tapes without special precau-
tions.
</bodyText>
<page confidence="0.958363">
20
</page>
<table confidence="0.942256272727273">
Tinput k a t a b a
Troot k t b
Tform Form I
Tptrn C V C V C
Tpaff a
Taffp +3P
+Masc
+Sg
Tvoc a a
Tvocp +Act
. . .
</table>
<tableCaption confidence="0.9587225">
Table 1: A possible alignment of 8 tapes to capture
Arabic verbal morphology.
</tableCaption>
<bodyText confidence="0.99999525">
We use the symbol E to specify the alphabet, and
the shorthand \a to denote any symbol in the al-
phabet except a. Slight additional notation will be
introduced in the course of elaborating the model.
</bodyText>
<sectionHeader confidence="0.994431" genericHeader="introduction">
3 Encoding
</sectionHeader>
<bodyText confidence="0.996832111111111">
In our implementation, we have decided to encode
the multi-tape automaton functionality as consist-
ing of a single string read by a single-tape automa-
ton, where the multiple tapes are all evenly inter-
leaved. The first symbol corresponds to the first
symbol on tape 1, the second to the first on tape 2,
etc.:
T1 1 1 1
can provide this information by virtue of its con-
struction. The above example could in an 8-tape
automaton encoding be captured as illustrated in
table 1, assuming here that Tinput is the input tape,
the content of which is provided, and the subse-
quent tapes are output tapes where the parse ap-
pears.
In table 1, we see that the radicals on the root
tape are aligned with the input, as is the pattern on
the pattern tape, the suffix -a on the suffix tape,
which again is aligned with the parse for the suf-
fix on the affix parse tape (affp), and finally the
vocalization a is aligned with the input and the pat-
tern. This is very much in tune with both the type
of analyses linguists seem to prefer (McCarthy,
1981), and more traditional analyses and lexicog-
raphy of root-and-pattern languages such as Ara-
bic.
In what follows, we will present an alternate
encoding for multi-tape automata together with
an implementation of an analyzer for Arabic ver-
bal morphology. The encoding simulates a multi-
tape automaton using a simple one-tape finite-state
machine and can be implemented using standard
toolkits and algorithms given in the literature. The
encoding also avoids the abovementioned blow-up
problems related to symbol combinations on mul-
tiple tapes.
</bodyText>
<sectionHeader confidence="0.986478" genericHeader="method">
2 Notation
</sectionHeader>
<bodyText confidence="0.999877">
We assume the reader is familiar with the basic
notation regarding finite automata and regular ex-
pressions. We will use the standard operators of
Kleene closure (L*), union (L1 U L2), intersec-
tion (L1 n L2), and assume concatenation when-
ever there is no overt operator specified (L1L2).
</bodyText>
<equation confidence="0.923062714285714">
. . .
Tn−1 1 1 1
Tn � � 1
. . .
For instance, the two-tape correspondence:
T1
T2
</equation>
<bodyText confidence="0.988800555555556">
would be encoded as the string abec, e being a spe-
cial symbol used to pad the blanks on a tape to
keep all tapes synchronized.
This means that, for example, for an 8-tape rep-
resentation, every 8th symbol from the beginning
is a symbol representing tape 1.
Although this is the final encoding we wish to
produce, we have added one extra temporary fea-
ture to facilitate the construction: every symbol on
any ‘tape’ is always preceded by a symbol indi-
cating the tape number drawn from an alphabet
T1, ... , Tn. These symbols are removed eventu-
ally. That means that during the construction, the
above two-tape example would be represented by
the string T1aT2bT1eT2c. This simple redundancy
mechanism will ease the writing of grammars and
actually limit the size of intermediate automata
during construction.
</bodyText>
<sectionHeader confidence="0.993655" genericHeader="method">
4 Construction
</sectionHeader>
<subsectionHeader confidence="0.835732">
4.1 Overview
</subsectionHeader>
<bodyText confidence="0.99993525">
We construct a finite-state n-tape simulation gram-
mar in two steps. Firstly we populate each ‘tape’
with all grammatically possible strings. That
means that, for our Arabic example, the root tape
</bodyText>
<figure confidence="0.9999305">
a
b c
</figure>
<page confidence="0.996523">
21
</page>
<bodyText confidence="0.963383916666667">
should contain all possible roots we wish to ac-
cept, the template tape all the possible templates,
etc. We call this language the Base. The second
step is to constrain the co-occurrence of symbols
on the individual tapes, i.e. a consonant on the root
tape must be matched by a consonant of the input
tape as well as the symbol C on the pattern tape,
etc. Our grammar then consists of all the permit-
ted combinations of tape symbols allowed by a)
the Base and b) the Rules. The resulting lan-
guage is simply their intersection, viz.:
Base ∩ Rules
</bodyText>
<subsectionHeader confidence="0.999081">
4.2 Populating the tapes
</subsectionHeader>
<bodyText confidence="0.997616357142857">
We have three auxiliary functions, TapeL(X,Y),
TapeM(X,Y), and TapeA(X,Y), where the ar-
gument X is the tape number, and Y the language
we with to insert on tape X.3 TapeL(X,Y) cre-
ates strings where every symbol from the language
Y is preceded by the tape indicator TX and where
the entire tape is left-aligned, meaning there are
no initial blanks on that tape. TapeM is the same
function, except words on that tape can be pre-
ceded by blanks and succeeded by blanks. TapeA
allows for any alignment of blanks within words
or to the left or right. Hence, to illustrate this
behavior, TapeL(4,C V C V C) will produce
strings like:
</bodyText>
<equation confidence="0.542165">
XT4CXT4VXT4CXT4VXT4CY
</equation>
<bodyText confidence="0.999658555555555">
where X is any sequence of symbols not contain-
ing the symbol T4, and Y any sequence possibly
containing T4 but where T4 is always followed by
a, i.e. we pad all tapes at the end to allow for syn-
chronized strings on other tapes containing more
material to the right.
Now, if, as in our grammar, tape 4 is the tem-
plate tape, we would populate that tape by declar-
ing the language:
</bodyText>
<equation confidence="0.521548">
TapeM(4,Templates)
</equation>
<bodyText confidence="0.994891">
assuming Templates is the language that ac-
cepts all legal template strings, e.g. CVCVC,
CVCCVC, etc.
Hence, our complete Base language (continu-
ing with the 8-tape example) is:
</bodyText>
<footnote confidence="0.914684">
3See the appendix for exact definitions of these functions.
</footnote>
<equation confidence="0.966500555555556">
TapeL(1,Inputs) ∩
TapeA(2,Roots) ∩
TapeL(3,Forms) ∩
TapeM(4,Templates) ∩
TapeA(5,Affixes) ∩
TapeM(6,Parses) ∩
TapeA(7,Voc) ∩
TapeL(8,VocParses) ∩
(T1ET2ET3ET4ET5ET6ET7ET8E)*
</equation>
<bodyText confidence="0.999969785714286">
This will produce the language where all strings
are multiples of 16 in length. Every other sym-
bol is the TX tape marker symbol and every other
symbol is the actual symbol on that tape (allowing
for the special symbol a also to represent blanks on
a tape). Naturally, we will want to define Inputs
occurring on tape 1 as any string containing any
combination of symbols since it represents all pos-
sible input words we wish to parse. Similarly, tape
2 will contain all possible roots, etc. This Base
language is subsequently constrained so that sym-
bols on different tapes align correctly and are only
allowed if they represent a legal parse of the word
on the input tape (tape 1).
</bodyText>
<subsectionHeader confidence="0.999849">
4.3 Constructing the rules
</subsectionHeader>
<bodyText confidence="0.9978545">
When constructing the rules that constrain the co-
occurrence of symbols on the various tapes we
shall primarily take advantage of the ⇒ oper-
ator first introduced for two-level grammars by
Koskenniemi (1983).4 The semantics is as fol-
lows. A statement:
</bodyText>
<equation confidence="0.86107">
X ⇒ L1 R1, ... , L,,, R1,
</equation>
<bodyText confidence="0.9996035">
where X and Li, Ri are all regular languages
defines the regular language where every instance
of a substring drawn from the language X must be
surrounded by some pair Li and Ri to the left and
right, respectively.5
Indeed, all of our rules will consist exclusively
of ⇒ statements.
To take an example: in order to constrain the
template we need two rules that effectively say that
every C and V symbol occurring in the template
</bodyText>
<footnote confidence="0.940307111111111">
4There is a slight, but subtle difference in notation,
though: the original two-level =:&gt;. operator constrained single
symbols only (such as a:b, which was considered at compile-
time a single symbol); here, the argument X refers to any
arbitrary language.
5Many finite-state toolkits contain this as a separate op-
erator. See Yli-Jyr¨a and Koskenniemi (2004) and Hulden
(2008) for how such statements can be converted into regular
expressions and finite automata.
</footnote>
<page confidence="0.998583">
22
</page>
<bodyText confidence="0.999600166666667">
tape must be matched by 1) a consonant on the root
tape and 2) a vowel on the input tape. Because of
our single-tape encoding the first rule translates to
the idea that every T4 C sequence must be directly
preceded by T2 followed by some consonant fol-
lowed by T3 and any symbol at all:
</bodyText>
<equation confidence="0.971254">
T4 C ⇒ T2 Cons T3 E (1)
</equation>
<bodyText confidence="0.647819">
and the second one translates to:
</bodyText>
<equation confidence="0.972554">
T4 ⇒ T1 Vow T2 ET3E (2)
</equation>
<bodyText confidence="0.98227975">
assuming that Vow is the language that contains
any vowel and Cons the language that contains
any consonant.
Similarly, we want to constrain the Forms
parse tape that contains symbols such as Form I,
Form II etc., so that if, for example, Form I oc-
curs on that tape, the pattern CVCVC must occur on
the pattern tape.6
</bodyText>
<equation confidence="0.788073">
T3 Form I ⇒ TapeM(4,C V C V C) (3)
</equation>
<bodyText confidence="0.971602673469388">
and likewise for all the other forms. It should be
noted that most constraints are very strictly local
to within a few symbols, depending slightly on the
ordering and function of the tapes. In (1), for in-
stance, which constrains a symbol on tape 4 with
a consonant on tape 2, there are only 2 interven-
ing symbols, namely that of tape 3. The ordering
of the tapes thus has some bearing on both how
simple the rules are to write, and the size of the re-
sulting automaton. Naturally, tapes that constrain
each other are ideally placed in adjacent positions
whenever possible.
Of course, some long-distance constraints will
be inevitable. For example, Form II is generally
described as a CVCCVC pattern, where the extra
consonant is a geminate, as in the stem kattab,
where the t of the root associates with both C’s
in the pattern. To distinguish this C behavior
from that of Form X which is also commonly de-
scribed with two adjacent C symbols where, how-
ever, there is no such association (as in the stem
staktab) we need to introduce another symbol.
6To be more exact, to be able to match and parse both
fully vocalized words such as wadarasat ( �:s,�j), and un-
vocalized ones, such as wdrst (�,...��j), we want the pattern
CVCVC to actually be represented by the regular expression
C (V) C (V) C, i.e. where the vowels are optional. Note,
however, that the rule that constrains T4 V above only re-
quires that the V matches if there indeed is one. Hence,
by declaring vowels in patterns (and vocalizations) to be op-
tional, we can always parse any partially, fully, or unvocalized
verb. Of course, fully unvocalized words will be much more
ambiguous and yield more parses.
This symbol C2 occurs in Form II, which becomes
CVCC2VC. We then introduce a constraint to the
effect that any C2-symbol must be matched on the
input by a consonant, which is identical to the pre-
vious consonant on the input tape.7 These long-
distance dependencies can be avoided to some ex-
tent by grammar engineering, but so long as they
do not cause a combinatorial explosion in the num-
ber of states of the resulting grammar automaton,
we have decided to include them for the sake of
clarity.
To give an overview of some of the subsequent
constraints that are still necessary, we include here
a few descriptions and examples (where the starred
(***) tape snippets exemplify illegal configura-
tions):
</bodyText>
<listItem confidence="0.917788">
• Every root consonant has a matching conso-
nant on the input tape
</listItem>
<figure confidence="0.852112461538462">
T1 k a t a b a
T2 k t b
T1 k a t a b a
T2*** d r s
• A vowel in the input which is matched by a
V in the pattern, must have a corresponding
vocalization vowel
T1 k a t a b a
T4 C V C V C
T7 a a
T1 k a t a b a
T4 C V C V C
T7*** u i
</figure>
<listItem confidence="0.935377666666667">
• A position where there is a symbol in the in-
put either has a symbol in the pattern tape or
a symbol in the affix tape (but not both)
</listItem>
<figure confidence="0.895339166666667">
T1 k a t a b a
T4 C V C V C
T5 a
T1 k a t a b a
T4 C V C V C
T5***
</figure>
<footnote confidence="0.9737695">
7The idea to preserve the gemination in the grammar is
similar to the solutions regarding gemination and spreading
of Forms II, V, and IX documented in Beesley (1998b) and
Habash and Rambow (2006).
</footnote>
<page confidence="0.997523">
23
</page>
<subsectionHeader confidence="0.99435">
4.4 The final automaton
</subsectionHeader>
<bodyText confidence="0.9587761">
As mentioned above, the symbols {T1, ... , Tn}
are only used during construction of the automa-
ton for the convenience of writing the grammar,
and shall be removed after intersecting the Base
language with the Rules languages. This is a sim-
ple substitution TX —* E, i.e. the empty string.
Hence, the grammar is compiled as:
Grammar = h(Base n Rules)
where h is a homomorphism that replaces TX
symbols with E, the empty string.
</bodyText>
<sectionHeader confidence="0.995824" genericHeader="method">
5 Efficiency Considerations
</sectionHeader>
<bodyText confidence="0.998954633333333">
Because the construction method proposed can
very quickly produce automata of considerable
size, there are a few issues to consider when de-
signing a grammar this way. Of primary concern
is that since one is constructing deterministic au-
tomata, long-distance constraints should be kept
to a minimum. Local constraints, which the ma-
jority of grammar rules encode, yield so-called k-
testable languages when represented as finite au-
tomata, and the state complexity of their inter-
section grows additively. For larger k, however,
growth is more rapid which means that, for ex-
ample, when one is designing the content of the
individual tapes, care should be taken to ensure
that segments or symbols which are related to each
other preferably align very closely on the tapes.
Naturally, this same goal is of linguistic interest as
well and a grammar which does not align gram-
matical information with segments in the input is
likely not a good grammar. However, there are a
couple of ways in which one can go astray. For
instance, in the running example we have pre-
sented, one of the parse tapes has included the
symbol +3P +Masc +Sg, aligned with the affix
that represents the grammatical information:
However, if it be the case that what the parse
tape reflects is a prefix or a circumfix, as will be
the case with the imperfective, subjunctive and
jussive forms, the following alignment would be
somewhat inefficient:
</bodyText>
<equation confidence="0.516753666666667">
. . .
a
. . .
</equation>
<bodyText confidence="0.999474777777778">
This is because the prefix ta, which appears
early in the word, is reflected on tape 6 at the end
of the word, in effect unnecessarily producing a
very long-distance dependency and hence dupli-
cates of states in the automaton encoding the in-
tervening material. A more efficient strategy is to
place the parse or annotation tape material as close
as possible to the segments which have a bearing
on it, i.e.:
</bodyText>
<equation confidence="0.672824333333333">
. . .
a
. . .
</equation>
<bodyText confidence="0.999973619047619">
This alignment can be achieved by a constraint
in the grammar to the effect that the first non-blank
symbol on the affix tape is in the same position as
the first non-blank symbol on the affix parse tape.
It is also worth noting that our implementation
does not yet restrict the co-occurrence of roots and
forms, i.e. it will parse any word in any root in the
lexicon in any of the forms I-VIII, X. Adding these
restrictions will presumably produce some growth
in the automaton. However, for the time being we
have also experimented with accepting any trilit-
eral root—i.e. any valid consonantal combination.
This has drastically cut the size of the resulting
automaton to only roughly 2,000 states without
much overgeneration in the sense that words will
not incorrectly be matched with the wrong root.
The reason for this small footprint when not hav-
ing a ‘real’ lexicon is fairly obvious—all depen-
dencies between the root tape and the pattern tape
and the input tape are instantly resolved in the span
of one ‘column’ or 7 symbols.
</bodyText>
<sectionHeader confidence="0.985553" genericHeader="method">
6 Algorithmic additions
</sectionHeader>
<bodyText confidence="0.9904385">
Naturally, one can parse words by simply inter-
secting TapeL(1, word) n Grammar, where
</bodyText>
<figure confidence="0.997778947368421">
. . .
. . .
T5
T6
+3P
+Masc
+Sg
a
T5 t
T6
+3P
+Fem
+Sg
T5
t
T6
+3P
+Fem
+Sg
</figure>
<page confidence="0.996168">
24
</page>
<bodyText confidence="0.999942333333333">
word is the word at hand and printing out all the
legal strings. Still, this is unwieldy because of
the intersection operation involved and for faster
lookup speeds one needs to consider an algorith-
mic extension that performs this lookup directly
on the Grammar automaton.
</bodyText>
<subsectionHeader confidence="0.993969">
6.1 Single-tape transduction
</subsectionHeader>
<bodyText confidence="0.999913090909091">
For our implementation, we have simply modified
the automaton matching algorithm in the toolkit
we have used, foma8 to, instead of matching ev-
ery symbol, matching the first symbol as the ‘in-
put’, then outputting the subsequent n (where n
is 7 in our example) legal symbols if the subse-
quent input symbols match. Because the grammar
is quite constrained, this produces very little tem-
porary ambiguity in the depth-first search traversal
of the automaton and transduces an input to the
output tapes in nearly linear time.
</bodyText>
<sectionHeader confidence="0.999821" genericHeader="method">
7 Future work
</sectionHeader>
<bodyText confidence="0.999956346153846">
The transduction mechanism mentioned above
works well and is particularly easy to implement
when the first ‘tape’ is the input tape containing
the word one wants to parse, since one can simply
do a depth-first search until the the next symbol
on the input tape (in our running example with 8
tapes, that would be 7 symbols forward) and dis-
card the paths where the subsequent tape 1 sym-
bols do not match, resulting in nearly linear run-
ning time. However, for the generation problem,
the solution is less obvious. If one wanted to sup-
ply any of the other tapes with a ready input (such
as form, root, and a combination of grammatical
categories), and then yield a string on tape 1, the
problem would be more difficult. Naturally, one
can intersect various TapeX(n, content) languages
against the grammar, producing all the possible in-
put strings that could have generated such a parse,
but this method is rather slow and results only in
a few parses per second on our system. Devis-
ing a fast algorithm to achieve this would be desir-
able for applications where one wanted to, for in-
stance, generate all possible vocalization patterns
in a given word, or for IR purposes where one
would automatically apply vocalizations to Arabic
words.
</bodyText>
<footnote confidence="0.908299">
8See the appendix.
</footnote>
<sectionHeader confidence="0.993866" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999960875">
We have described a straightforward method by
which morphological analyzers for languages that
exhibit root-and-pattern morphology can be built
using standard finite-state methods to simulate
multi-tape automata. This enables one to take
advantage of already widely available standard
toolkits designed for construction of single-tape
automata or finite-state transducers. The feasibil-
ity of the approach has been tested with a limited
implementation of Arabic verbal morphology that
contains roughly 2,000 roots, yielding automata of
manageable size. With some care in construction
the method should be readily applicable to larger
projects in Arabic and other languages, in partic-
ular to languages that exhibit root-and-pattern or
templatic morphologies.
</bodyText>
<sectionHeader confidence="0.996897" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.919552448275862">
Beesley, K. and Karttunen, L. (2003). Finite-State
Morphology. CSLI, Stanford.
Beesley, K. R. (1996). Arabic finite-state analysis
and generation. In COLING ’96.
Beesley, K. R. (1998a). Arabic morphology us-
ing only finite-state operations. In Proceedings
of the Workshop on Computational Approaches
to Semitic Languages COLING-ACL, pages 50–
57.
Beesley, K. R. (1998b). Consonant spreading in
Arabic stems. In ACL, volume 36, pages 117–
123. Association for Computational Linguis-
tics.
Beeston, A. F. L. (1968). Written Arabic: An ap-
proach to the basic structures. Cambridge Uni-
versity Press, Cambridge.
Buckwalter, T. (2004). Arabic morphological an-
alyzer 2.0. LDC.
Habash, N. and Rambow, O. (2006). MAGEAD:
A morphological analyzer and generator for the
Arabic dialects. Proceedings of COLING-ACL
2006.
Habash, N., Rambow, O., and Kiraz, G. (2005).
Morphological analysis and generation for Ara-
bic dialects. Proceedings of the Workshop
on Computational Approaches to Semitic Lan-
guages (ACL ’05).
Hulden, M. (2008). Regular expressions and pred-
icate logic in finite-state language processing.
</reference>
<page confidence="0.998447">
25
</page>
<sectionHeader confidence="0.865544" genericHeader="acknowledgments">
9 Appendix
</sectionHeader>
<bodyText confidence="0.999887">
The practical implementation described in the pa-
per was done with the freely available (GNU Li-
cence) foma finite-state toolkit.9. However, all of
the techniques used are available in other toolk-
its as well, such as xfst (Beesley and Karttunen,
2003), or fsa (van Noord, 2000)), and translation
of the notation should be straightforward.
The functions for populating the tapes in section
4.2, were defined in foma as follows:
</bodyText>
<equation confidence="0.918824428571429">
TapeL(X,Y) _
[[Y o [[0x\X \X]* [0xX] E]*]2
[X E|\X \X]*]
TapeM(X,Y) _ [[Y o [0x[\X \X|X E]]*
[0x\X \X]* [0xX] E]*]2 [X E|\X \X]*]
TapeA(X,Y) _ [[Y o
[0x\X \X|X E]* 0xX E]*]2i
</equation>
<bodyText confidence="0.97893575">
Here, TapeX is a function of two variables, X
and Y. Transducer composition is denoted by o,
cross-product by x, the lower projection of a re-
lation by L2, and union by |. Brackets indicate
grouping and E any symbol. The notation \X de-
notes any single symbol, except X. The symbol E
here is the special ‘blank’ symbol used to pad the
tapes and keep them synchronized.
</bodyText>
<reference confidence="0.988151066666667">
In Piskorski, J., Watson, B., and Yli-Jyr¨a, A.,
editors, Proceedings of FSMNLP 2008.
Kataja, L. and Koskenniemi, K. (1988). Finite-
state description of Semitic morphology: a case
study of ancient Akkadian. In COLING ’88,
pages 313–315.
Kay, M. (1987). Nonconcatenative finite-state
morphology. In Proceedings of the third con-
ference on European chapter of the Association
for Computational Linguistics, pages 2–10. As-
sociation for Computational Linguistics.
Kiraz, G. A. (1994). Multi-tape two-level mor-
phology: A case study in Semitic non-linear
morphology. In COLING ’94, pages 180–186.
Kiraz, G. A. (2000). Multi-tiered nonlinear mor-
phology using multitape finite automata: A case
study on Syriac and Arabic. Computational Lin-
guistics, 26(1):77–105.
Kiraz, G. A. (2001). Computational nonlinear
morphology: with emphasis on Semitic lan-
guages. Cambridge University Press, Cam-
bridge.
Koskenniemi, K. (1983). Two-level morphology:
A general computational model for word-form
recognition and production. Publication 11,
University of Helsinki, Department of General
Linguistics, Helsinki.
Lavie, A., Itai, A., and Ornan, U. (1988). On the
applicability of two level morphology to the in-
flection of Hebrew verbs. In Proceedings of
ALLC III, pages 246–260.
McCarthy, J. J. (1981). A Prosodic Theory of Non-
concatenative Morphology. Linguistic Inquiry,
12(3):373–418.
van Noord, G. (2000). FSA 6 Reference Manual.
Wehr, H. (1979). A Dictionary of Modern Writ-
ten Arabic. Spoken Language Services, Inc.,
Ithaca, NY.
Yli-Jyr¨a, A. and Koskenniemi, K. (2004). Compil-
ing contextual restrictions on strings into finite-
state automata. The Eindhoven FASTAR Days
Proceedings.
Yona, S. and Wintner, S. (2008). A finite-state
morphological grammar of Hebrew. Natural
Language Engineering, 14(2):173–190.
</reference>
<footnote confidence="0.754098">
9http://foma.sourceforge.net
</footnote>
<page confidence="0.996841">
26
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.916174">
<title confidence="0.991593">Revisiting multi-tape automata for Semitic morphological analysis and generation</title>
<author confidence="0.960598">Mans</author>
<affiliation confidence="0.998478">University of Department of</affiliation>
<email confidence="0.998687">mhulden@email.arizona.edu</email>
<abstract confidence="0.998695956521739">Various methods have been devised to produce morphological analyzers and generators for Semitic languages, ranging from methods based on widely used finitestate technologies to very specific solutions designed for a specific language or problem. Since the earliest proposals of how to adopt the elsewhere successful finite-state methods to root-andpattern morphologies, the solution of encoding Semitic grammars using multi-tape automata has resurfaced on a regular basis. Multi-tape automata, however, require specific algorithms and reimplementation of finite-state operators across the board, and hence such technology has not been readily available to linguists. This paper, using an actual Arabic grammar as a case study, describes an approach to encoding multi-tape automata on a single tape that can be implemented using any standard finite-automaton toolkit.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Beesley</author>
<author>L Karttunen</author>
</authors>
<title>Finite-State Morphology.</title>
<date>2003</date>
<publisher>CSLI, Stanford.</publisher>
<contexts>
<context position="4372" citStr="Beesley and Karttunen (2003)" startWordPosition="654" endWordPosition="657"> 31 March, 2009. c�2009 Association for Computational Linguistics 19 that is called for in Semitic interdigitation. However, large-scale multitape solutions containing the magnitude of information in standard Arabic dictionaries such as Wehr (1979) have not been reported. To our knowledge, two large-scale morphological analyzers for Arabic that strive for reasonable completeness have been been built: one by Xerox and one by Tim Buckwalter (Buckwalter, 2004). The Xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in Beesley and Karttunen (2003), while Buckwalter’s system is a procedural approach written in Perl which decomposes a word and simultaneously consults lexica for constraining the possible decompositions. Also, in a similar vein to Xerox’s Arabic analyzer, Yona and Wintner (2008) report on a large-scale system for Hebrew built on transducer technology. Most importantly, none of these very large systems are built around multi-tape automata even though such a construction from a linguistic perspective would appear to be a fitting choice when dealing with root-and-pattern morphology. 1.3 n-tape space complexity There is a fund</context>
</contexts>
<marker>Beesley, Karttunen, 2003</marker>
<rawString>Beesley, K. and Karttunen, L. (2003). Finite-State Morphology. CSLI, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R Beesley</author>
</authors>
<title>Arabic finite-state analysis and generation.</title>
<date>1996</date>
<booktitle>In COLING ’96.</booktitle>
<contexts>
<context position="2885" citStr="Beesley (1996" startWordPosition="429" endWordPosition="430">ty of capturing this interdigitation process is not an inherent shortcoming of finitestate automata or transducers per se, but rather a result of the methods that are commonly used to construct automata. Regular expressions that contain operations such as concatenation, union, intersection, as well as morphotactic descriptions through right-linear grammars offer an unwieldy functionality when it comes to interleaving strings with one another in a regulated way. But, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. Beesley (1996, 1998b,a)), the question of how to do it becomes one of construction, not feasibility. 1.2 Multitape automata One early approach, suggested by Kay (1987) and later pursued in different variants by Kiraz (1994, 2000) among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with a n-tape automaton, where tapes would carry precisely this interleaving 1Following autosegmental analyses, this paper assumes the model where the vocalization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as CaCaC </context>
</contexts>
<marker>Beesley, 1996</marker>
<rawString>Beesley, K. R. (1996). Arabic finite-state analysis and generation. In COLING ’96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R Beesley</author>
</authors>
<title>Arabic morphology using only finite-state operations.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Semitic Languages COLING-ACL,</booktitle>
<pages>50--57</pages>
<contexts>
<context position="19758" citStr="Beesley (1998" startWordPosition="3369" endWordPosition="3370">he input tape T1 k a t a b a T2 k t b T1 k a t a b a T2*** d r s • A vowel in the input which is matched by a V in the pattern, must have a corresponding vocalization vowel T1 k a t a b a T4 C V C V C T7 a a T1 k a t a b a T4 C V C V C T7*** u i • A position where there is a symbol in the input either has a symbol in the pattern tape or a symbol in the affix tape (but not both) T1 k a t a b a T4 C V C V C T5 a T1 k a t a b a T4 C V C V C T5*** 7The idea to preserve the gemination in the grammar is similar to the solutions regarding gemination and spreading of Forms II, V, and IX documented in Beesley (1998b) and Habash and Rambow (2006). 23 4.4 The final automaton As mentioned above, the symbols {T1, ... , Tn} are only used during construction of the automaton for the convenience of writing the grammar, and shall be removed after intersecting the Base language with the Rules languages. This is a simple substitution TX —* E, i.e. the empty string. Hence, the grammar is compiled as: Grammar = h(Base n Rules) where h is a homomorphism that replaces TX symbols with E, the empty string. 5 Efficiency Considerations Because the construction method proposed can very quickly produce automata of consider</context>
</contexts>
<marker>Beesley, 1998</marker>
<rawString>Beesley, K. R. (1998a). Arabic morphology using only finite-state operations. In Proceedings of the Workshop on Computational Approaches to Semitic Languages COLING-ACL, pages 50– 57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R Beesley</author>
</authors>
<title>Consonant spreading in Arabic stems.</title>
<date>1998</date>
<booktitle>In ACL,</booktitle>
<volume>36</volume>
<pages>117--123</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19758" citStr="Beesley (1998" startWordPosition="3369" endWordPosition="3370">he input tape T1 k a t a b a T2 k t b T1 k a t a b a T2*** d r s • A vowel in the input which is matched by a V in the pattern, must have a corresponding vocalization vowel T1 k a t a b a T4 C V C V C T7 a a T1 k a t a b a T4 C V C V C T7*** u i • A position where there is a symbol in the input either has a symbol in the pattern tape or a symbol in the affix tape (but not both) T1 k a t a b a T4 C V C V C T5 a T1 k a t a b a T4 C V C V C T5*** 7The idea to preserve the gemination in the grammar is similar to the solutions regarding gemination and spreading of Forms II, V, and IX documented in Beesley (1998b) and Habash and Rambow (2006). 23 4.4 The final automaton As mentioned above, the symbols {T1, ... , Tn} are only used during construction of the automaton for the convenience of writing the grammar, and shall be removed after intersecting the Base language with the Rules languages. This is a simple substitution TX —* E, i.e. the empty string. Hence, the grammar is compiled as: Grammar = h(Base n Rules) where h is a homomorphism that replaces TX symbols with E, the empty string. 5 Efficiency Considerations Because the construction method proposed can very quickly produce automata of consider</context>
</contexts>
<marker>Beesley, 1998</marker>
<rawString>Beesley, K. R. (1998b). Consonant spreading in Arabic stems. In ACL, volume 36, pages 117– 123. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F L Beeston</author>
</authors>
<title>Written Arabic: An approach to the basic structures.</title>
<date>1968</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<marker>Beeston, 1968</marker>
<rawString>Beeston, A. F. L. (1968). Written Arabic: An approach to the basic structures. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Buckwalter</author>
</authors>
<title>Arabic morphological analyzer 2.0.</title>
<date>2004</date>
<publisher>LDC.</publisher>
<contexts>
<context position="4205" citStr="Buckwalter, 2004" startWordPosition="632" endWordPosition="633">hods in this paper apply to either one. Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 19–26, Athens, Greece, 31 March, 2009. c�2009 Association for Computational Linguistics 19 that is called for in Semitic interdigitation. However, large-scale multitape solutions containing the magnitude of information in standard Arabic dictionaries such as Wehr (1979) have not been reported. To our knowledge, two large-scale morphological analyzers for Arabic that strive for reasonable completeness have been been built: one by Xerox and one by Tim Buckwalter (Buckwalter, 2004). The Xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in Beesley and Karttunen (2003), while Buckwalter’s system is a procedural approach written in Perl which decomposes a word and simultaneously consults lexica for constraining the possible decompositions. Also, in a similar vein to Xerox’s Arabic analyzer, Yona and Wintner (2008) report on a large-scale system for Hebrew built on transducer technology. Most importantly, none of these very large systems are built around multi-tape automata even though such a co</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Buckwalter, T. (2004). Arabic morphological analyzer 2.0. LDC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
</authors>
<title>MAGEAD: A morphological analyzer and generator for the Arabic dialects.</title>
<date>2006</date>
<booktitle>Proceedings of COLING-ACL</booktitle>
<contexts>
<context position="8049" citStr="Habash and Rambow (2006)" startWordPosition="1234" endWordPosition="1237"> such as kataba ( ��� �����) to a string representing an analyzed one, e.g. ktb +FormI +Perfect +Act +3P +Masc +Sg. Such transductions seldom provide grammatical component-wise alignment information telling which parts of the unanalyzed words contribute to which parts of the grammatical information. Particularly if morphemes signifying a grammatical category are discontinuous, this information is difficult to provide naturally in a finite-automaton based system without many tapes. A multi-tape solution, on the other hand, 2Two anonymous reviewers point out the work by Habash et al. (2005) and Habash and Rambow (2006) who report an effort to analyze Arabic with such a multitape system based on work by Kiraz (2000, 2001) that relies on custom algorithms devised for a multitape alphabet. Although Habash and Rambow do not discuss the space requirements in their system, it is to be suspected that the number of transitions grows quickly using such an method by virtue of the argument given above. These approaches also use a small number of tapes (between 3 and 5), and, since the number of transitions can increase exponentially with the number of tapes used, such systems do not on the face of it appear to scale w</context>
<context position="19789" citStr="Habash and Rambow (2006)" startWordPosition="3372" endWordPosition="3375"> t a b a T2 k t b T1 k a t a b a T2*** d r s • A vowel in the input which is matched by a V in the pattern, must have a corresponding vocalization vowel T1 k a t a b a T4 C V C V C T7 a a T1 k a t a b a T4 C V C V C T7*** u i • A position where there is a symbol in the input either has a symbol in the pattern tape or a symbol in the affix tape (but not both) T1 k a t a b a T4 C V C V C T5 a T1 k a t a b a T4 C V C V C T5*** 7The idea to preserve the gemination in the grammar is similar to the solutions regarding gemination and spreading of Forms II, V, and IX documented in Beesley (1998b) and Habash and Rambow (2006). 23 4.4 The final automaton As mentioned above, the symbols {T1, ... , Tn} are only used during construction of the automaton for the convenience of writing the grammar, and shall be removed after intersecting the Base language with the Rules languages. This is a simple substitution TX —* E, i.e. the empty string. Hence, the grammar is compiled as: Grammar = h(Base n Rules) where h is a homomorphism that replaces TX symbols with E, the empty string. 5 Efficiency Considerations Because the construction method proposed can very quickly produce automata of considerable size, there are a few issu</context>
</contexts>
<marker>Habash, Rambow, 2006</marker>
<rawString>Habash, N. and Rambow, O. (2006). MAGEAD: A morphological analyzer and generator for the Arabic dialects. Proceedings of COLING-ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>O Rambow</author>
<author>G Kiraz</author>
</authors>
<title>Morphological analysis and generation for Arabic dialects.</title>
<date>2005</date>
<booktitle>Proceedings of the Workshop on Computational Approaches to Semitic Languages (ACL ’05).</booktitle>
<contexts>
<context position="8020" citStr="Habash et al. (2005)" startWordPosition="1229" endWordPosition="1232"> an unanalyzed word form, such as kataba ( ��� �����) to a string representing an analyzed one, e.g. ktb +FormI +Perfect +Act +3P +Masc +Sg. Such transductions seldom provide grammatical component-wise alignment information telling which parts of the unanalyzed words contribute to which parts of the grammatical information. Particularly if morphemes signifying a grammatical category are discontinuous, this information is difficult to provide naturally in a finite-automaton based system without many tapes. A multi-tape solution, on the other hand, 2Two anonymous reviewers point out the work by Habash et al. (2005) and Habash and Rambow (2006) who report an effort to analyze Arabic with such a multitape system based on work by Kiraz (2000, 2001) that relies on custom algorithms devised for a multitape alphabet. Although Habash and Rambow do not discuss the space requirements in their system, it is to be suspected that the number of transitions grows quickly using such an method by virtue of the argument given above. These approaches also use a small number of tapes (between 3 and 5), and, since the number of transitions can increase exponentially with the number of tapes used, such systems do not on the</context>
</contexts>
<marker>Habash, Rambow, Kiraz, 2005</marker>
<rawString>Habash, N., Rambow, O., and Kiraz, G. (2005). Morphological analysis and generation for Arabic dialects. Proceedings of the Workshop on Computational Approaches to Semitic Languages (ACL ’05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hulden</author>
</authors>
<title>Regular expressions and predicate logic in finite-state language processing.</title>
<date>2008</date>
<contexts>
<context position="15915" citStr="Hulden (2008)" startWordPosition="2617" endWordPosition="2618">and right, respectively.5 Indeed, all of our rules will consist exclusively of ⇒ statements. To take an example: in order to constrain the template we need two rules that effectively say that every C and V symbol occurring in the template 4There is a slight, but subtle difference in notation, though: the original two-level =:&gt;. operator constrained single symbols only (such as a:b, which was considered at compiletime a single symbol); here, the argument X refers to any arbitrary language. 5Many finite-state toolkits contain this as a separate operator. See Yli-Jyr¨a and Koskenniemi (2004) and Hulden (2008) for how such statements can be converted into regular expressions and finite automata. 22 tape must be matched by 1) a consonant on the root tape and 2) a vowel on the input tape. Because of our single-tape encoding the first rule translates to the idea that every T4 C sequence must be directly preceded by T2 followed by some consonant followed by T3 and any symbol at all: T4 C ⇒ T2 Cons T3 E (1) and the second one translates to: T4 ⇒ T1 Vow T2 ET3E (2) assuming that Vow is the language that contains any vowel and Cons the language that contains any consonant. Similarly, we want to constrain </context>
</contexts>
<marker>Hulden, 2008</marker>
<rawString>Hulden, M. (2008). Regular expressions and predicate logic in finite-state language processing.</rawString>
</citation>
<citation valid="true">
<date>2008</date>
<booktitle>Proceedings of FSMNLP</booktitle>
<editor>In Piskorski, J., Watson, B., and Yli-Jyr¨a, A., editors,</editor>
<contexts>
<context position="4621" citStr="(2008)" startWordPosition="695" endWordPosition="695">. To our knowledge, two large-scale morphological analyzers for Arabic that strive for reasonable completeness have been been built: one by Xerox and one by Tim Buckwalter (Buckwalter, 2004). The Xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in Beesley and Karttunen (2003), while Buckwalter’s system is a procedural approach written in Perl which decomposes a word and simultaneously consults lexica for constraining the possible decompositions. Also, in a similar vein to Xerox’s Arabic analyzer, Yona and Wintner (2008) report on a large-scale system for Hebrew built on transducer technology. Most importantly, none of these very large systems are built around multi-tape automata even though such a construction from a linguistic perspective would appear to be a fitting choice when dealing with root-and-pattern morphology. 1.3 n-tape space complexity There is a fundamental space complexity problem with multi-tape automata, which is that when the number of tapes grows, the required joint symbol alphabet grows with exponential rapidity unless special mechanisms are devised to curtail this growth. This explosion </context>
<context position="15915" citStr="(2008)" startWordPosition="2618" endWordPosition="2618">ht, respectively.5 Indeed, all of our rules will consist exclusively of ⇒ statements. To take an example: in order to constrain the template we need two rules that effectively say that every C and V symbol occurring in the template 4There is a slight, but subtle difference in notation, though: the original two-level =:&gt;. operator constrained single symbols only (such as a:b, which was considered at compiletime a single symbol); here, the argument X refers to any arbitrary language. 5Many finite-state toolkits contain this as a separate operator. See Yli-Jyr¨a and Koskenniemi (2004) and Hulden (2008) for how such statements can be converted into regular expressions and finite automata. 22 tape must be matched by 1) a consonant on the root tape and 2) a vowel on the input tape. Because of our single-tape encoding the first rule translates to the idea that every T4 C sequence must be directly preceded by T2 followed by some consonant followed by T3 and any symbol at all: T4 C ⇒ T2 Cons T3 E (1) and the second one translates to: T4 ⇒ T1 Vow T2 ET3E (2) assuming that Vow is the language that contains any vowel and Cons the language that contains any consonant. Similarly, we want to constrain </context>
</contexts>
<marker>2008</marker>
<rawString>In Piskorski, J., Watson, B., and Yli-Jyr¨a, A., editors, Proceedings of FSMNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Kataja</author>
<author>K Koskenniemi</author>
</authors>
<title>Finitestate description of Semitic morphology: a case study of ancient Akkadian.</title>
<date>1988</date>
<booktitle>In COLING ’88,</booktitle>
<pages>313--315</pages>
<contexts>
<context position="1586" citStr="Kataja and Koskenniemi, 1988" startWordPosition="221" endWordPosition="224">n a single tape that can be implemented using any standard finite-automaton toolkit. 1 Introduction 1.1 Root-and-pattern morphology and finite-state systems The special problems and challenges embodied by Semitic languages have been recognized from the early days of applying finite-state methods to natural language morphological analysis. The language model which finite-state methods have been most successful in describing—a model where morphemes concatenate in mostly strict linear order—does not translate congenially to the type of root-and-pattern morphology found in e.g. Arabic and Hebrew (Kataja and Koskenniemi, 1988; Lavie et al., 1988). In Arabic, as in most Semitic languages, verbs have for a long time been analyzed as consisting of three elements: a (most often) triconsonantal root, such as ktb (u u� d), a vowel pattern containing grammatical information such as voice (e.g. the vowel a) and a derivational template, such as CVCVC indicating the class of the verb, all of which are interdigitated to build a stem, such � as katab (�� ����).1 This stem is in turn subject to more familiar morphological constructions including prefixation and suffixation, yielding information such as number, person, etc, suc</context>
</contexts>
<marker>Kataja, Koskenniemi, 1988</marker>
<rawString>Kataja, L. and Koskenniemi, K. (1988). Finitestate description of Semitic morphology: a case study of ancient Akkadian. In COLING ’88, pages 313–315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Nonconcatenative finite-state morphology.</title>
<date>1987</date>
<booktitle>In Proceedings of the third conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>2--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3039" citStr="Kay (1987)" startWordPosition="454" endWordPosition="455"> that are commonly used to construct automata. Regular expressions that contain operations such as concatenation, union, intersection, as well as morphotactic descriptions through right-linear grammars offer an unwieldy functionality when it comes to interleaving strings with one another in a regulated way. But, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. Beesley (1996, 1998b,a)), the question of how to do it becomes one of construction, not feasibility. 1.2 Multitape automata One early approach, suggested by Kay (1987) and later pursued in different variants by Kiraz (1994, 2000) among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with a n-tape automaton, where tapes would carry precisely this interleaving 1Following autosegmental analyses, this paper assumes the model where the vocalization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as CaCaC as is assumed more traditionally. Which analysis to choose largely a matter of convenience, and the methods in this paper apply to either one. Proceedings</context>
</contexts>
<marker>Kay, 1987</marker>
<rawString>Kay, M. (1987). Nonconcatenative finite-state morphology. In Proceedings of the third conference on European chapter of the Association for Computational Linguistics, pages 2–10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Kiraz</author>
</authors>
<title>Multi-tape two-level morphology: A case study in Semitic non-linear morphology.</title>
<date>1994</date>
<booktitle>In COLING ’94,</booktitle>
<pages>180--186</pages>
<contexts>
<context position="3094" citStr="Kiraz (1994" startWordPosition="463" endWordPosition="464"> expressions that contain operations such as concatenation, union, intersection, as well as morphotactic descriptions through right-linear grammars offer an unwieldy functionality when it comes to interleaving strings with one another in a regulated way. But, one could argue, since large scale morphological analyzers as finite-state automata/transducers have indeed been built (see e.g. Beesley (1996, 1998b,a)), the question of how to do it becomes one of construction, not feasibility. 1.2 Multitape automata One early approach, suggested by Kay (1987) and later pursued in different variants by Kiraz (1994, 2000) among others, was to, instead of modeling morphology along the more traditional finite-state transducer, modeling it with a n-tape automaton, where tapes would carry precisely this interleaving 1Following autosegmental analyses, this paper assumes the model where the vocalization is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as CaCaC as is assumed more traditionally. Which analysis to choose largely a matter of convenience, and the methods in this paper apply to either one. Proceedings of the EACL 2009 Workshop on Computational Approaches </context>
</contexts>
<marker>Kiraz, 1994</marker>
<rawString>Kiraz, G. A. (1994). Multi-tape two-level morphology: A case study in Semitic non-linear morphology. In COLING ’94, pages 180–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Kiraz</author>
</authors>
<title>Multi-tiered nonlinear morphology using multitape finite automata: A case study</title>
<date>2000</date>
<booktitle>on Syriac and Arabic. Computational Linguistics,</booktitle>
<pages>26--1</pages>
<contexts>
<context position="8146" citStr="Kiraz (2000" startWordPosition="1254" endWordPosition="1255"> +Sg. Such transductions seldom provide grammatical component-wise alignment information telling which parts of the unanalyzed words contribute to which parts of the grammatical information. Particularly if morphemes signifying a grammatical category are discontinuous, this information is difficult to provide naturally in a finite-automaton based system without many tapes. A multi-tape solution, on the other hand, 2Two anonymous reviewers point out the work by Habash et al. (2005) and Habash and Rambow (2006) who report an effort to analyze Arabic with such a multitape system based on work by Kiraz (2000, 2001) that relies on custom algorithms devised for a multitape alphabet. Although Habash and Rambow do not discuss the space requirements in their system, it is to be suspected that the number of transitions grows quickly using such an method by virtue of the argument given above. These approaches also use a small number of tapes (between 3 and 5), and, since the number of transitions can increase exponentially with the number of tapes used, such systems do not on the face of it appear to scale well to more than a handful of tapes without special precautions. 20 Tinput k a t a b a Troot k t </context>
</contexts>
<marker>Kiraz, 2000</marker>
<rawString>Kiraz, G. A. (2000). Multi-tiered nonlinear morphology using multitape finite automata: A case study on Syriac and Arabic. Computational Linguistics, 26(1):77–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Kiraz</author>
</authors>
<title>Computational nonlinear morphology: with emphasis on Semitic languages.</title>
<date>2001</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<marker>Kiraz, 2001</marker>
<rawString>Kiraz, G. A. (2001). Computational nonlinear morphology: with emphasis on Semitic languages. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level morphology: A general computational model for word-form recognition and production.</title>
<date>1983</date>
<journal>Publication</journal>
<volume>11</volume>
<institution>University of Helsinki, Department of General Linguistics,</institution>
<location>Helsinki.</location>
<contexts>
<context position="15041" citStr="Koskenniemi (1983)" startWordPosition="2466" endWordPosition="2467">uts occurring on tape 1 as any string containing any combination of symbols since it represents all possible input words we wish to parse. Similarly, tape 2 will contain all possible roots, etc. This Base language is subsequently constrained so that symbols on different tapes align correctly and are only allowed if they represent a legal parse of the word on the input tape (tape 1). 4.3 Constructing the rules When constructing the rules that constrain the cooccurrence of symbols on the various tapes we shall primarily take advantage of the ⇒ operator first introduced for two-level grammars by Koskenniemi (1983).4 The semantics is as follows. A statement: X ⇒ L1 R1, ... , L,,, R1, where X and Li, Ri are all regular languages defines the regular language where every instance of a substring drawn from the language X must be surrounded by some pair Li and Ri to the left and right, respectively.5 Indeed, all of our rules will consist exclusively of ⇒ statements. To take an example: in order to constrain the template we need two rules that effectively say that every C and V symbol occurring in the template 4There is a slight, but subtle difference in notation, though: the original two-level =:&gt;. operator </context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, K. (1983). Two-level morphology: A general computational model for word-form recognition and production. Publication 11, University of Helsinki, Department of General Linguistics, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lavie</author>
<author>A Itai</author>
<author>U Ornan</author>
</authors>
<title>On the applicability of two level morphology to the inflection of Hebrew verbs.</title>
<date>1988</date>
<booktitle>In Proceedings of ALLC III,</booktitle>
<pages>246--260</pages>
<contexts>
<context position="1607" citStr="Lavie et al., 1988" startWordPosition="225" endWordPosition="228">plemented using any standard finite-automaton toolkit. 1 Introduction 1.1 Root-and-pattern morphology and finite-state systems The special problems and challenges embodied by Semitic languages have been recognized from the early days of applying finite-state methods to natural language morphological analysis. The language model which finite-state methods have been most successful in describing—a model where morphemes concatenate in mostly strict linear order—does not translate congenially to the type of root-and-pattern morphology found in e.g. Arabic and Hebrew (Kataja and Koskenniemi, 1988; Lavie et al., 1988). In Arabic, as in most Semitic languages, verbs have for a long time been analyzed as consisting of three elements: a (most often) triconsonantal root, such as ktb (u u� d), a vowel pattern containing grammatical information such as voice (e.g. the vowel a) and a derivational template, such as CVCVC indicating the class of the verb, all of which are interdigitated to build a stem, such � as katab (�� ����).1 This stem is in turn subject to more familiar morphological constructions including prefixation and suffixation, yielding information such as number, person, etc, such as kataba ( ��� ���</context>
</contexts>
<marker>Lavie, Itai, Ornan, 1988</marker>
<rawString>Lavie, A., Itai, A., and Ornan, U. (1988). On the applicability of two level morphology to the inflection of Hebrew verbs. In Proceedings of ALLC III, pages 246–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J McCarthy</author>
</authors>
<title>A Prosodic Theory of Nonconcatenative Morphology.</title>
<date>1981</date>
<journal>Linguistic Inquiry,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="10149" citStr="McCarthy, 1981" startWordPosition="1634" endWordPosition="1635">utomaton encoding be captured as illustrated in table 1, assuming here that Tinput is the input tape, the content of which is provided, and the subsequent tapes are output tapes where the parse appears. In table 1, we see that the radicals on the root tape are aligned with the input, as is the pattern on the pattern tape, the suffix -a on the suffix tape, which again is aligned with the parse for the suffix on the affix parse tape (affp), and finally the vocalization a is aligned with the input and the pattern. This is very much in tune with both the type of analyses linguists seem to prefer (McCarthy, 1981), and more traditional analyses and lexicography of root-and-pattern languages such as Arabic. In what follows, we will present an alternate encoding for multi-tape automata together with an implementation of an analyzer for Arabic verbal morphology. The encoding simulates a multitape automaton using a simple one-tape finite-state machine and can be implemented using standard toolkits and algorithms given in the literature. The encoding also avoids the abovementioned blow-up problems related to symbol combinations on multiple tapes. 2 Notation We assume the reader is familiar with the basic no</context>
</contexts>
<marker>McCarthy, 1981</marker>
<rawString>McCarthy, J. J. (1981). A Prosodic Theory of Nonconcatenative Morphology. Linguistic Inquiry, 12(3):373–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G van Noord</author>
</authors>
<date>2000</date>
<journal>FSA 6 Reference Manual.</journal>
<marker>van Noord, 2000</marker>
<rawString>van Noord, G. (2000). FSA 6 Reference Manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wehr</author>
</authors>
<title>A Dictionary of Modern Written Arabic. Spoken Language Services,</title>
<date>1979</date>
<publisher>Inc.,</publisher>
<location>Ithaca, NY.</location>
<contexts>
<context position="3992" citStr="Wehr (1979)" startWordPosition="598" endWordPosition="599">n is not merged with the pattern, i.e. we do not list separate patterns for vocalizations such as CaCaC as is assumed more traditionally. Which analysis to choose largely a matter of convenience, and the methods in this paper apply to either one. Proceedings of the EACL 2009 Workshop on Computational Approaches to Semitic Languages, pages 19–26, Athens, Greece, 31 March, 2009. c�2009 Association for Computational Linguistics 19 that is called for in Semitic interdigitation. However, large-scale multitape solutions containing the magnitude of information in standard Arabic dictionaries such as Wehr (1979) have not been reported. To our knowledge, two large-scale morphological analyzers for Arabic that strive for reasonable completeness have been been built: one by Xerox and one by Tim Buckwalter (Buckwalter, 2004). The Xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in Beesley and Karttunen (2003), while Buckwalter’s system is a procedural approach written in Perl which decomposes a word and simultaneously consults lexica for constraining the possible decompositions. Also, in a similar vein to Xerox’s Arabic anal</context>
</contexts>
<marker>Wehr, 1979</marker>
<rawString>Wehr, H. (1979). A Dictionary of Modern Written Arabic. Spoken Language Services, Inc., Ithaca, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Yli-Jyr¨a</author>
<author>K Koskenniemi</author>
</authors>
<title>Compiling contextual restrictions on strings into finitestate automata. The Eindhoven FASTAR Days Proceedings.</title>
<date>2004</date>
<marker>Yli-Jyr¨a, Koskenniemi, 2004</marker>
<rawString>Yli-Jyr¨a, A. and Koskenniemi, K. (2004). Compiling contextual restrictions on strings into finitestate automata. The Eindhoven FASTAR Days Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Yona</author>
<author>S Wintner</author>
</authors>
<title>A finite-state morphological grammar of Hebrew.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="4621" citStr="Yona and Wintner (2008)" startWordPosition="692" endWordPosition="695">not been reported. To our knowledge, two large-scale morphological analyzers for Arabic that strive for reasonable completeness have been been built: one by Xerox and one by Tim Buckwalter (Buckwalter, 2004). The Xerox analyzer relies on complex extensions to the finite-state calculus of one and two-tape automata (transducers) as documented in Beesley and Karttunen (2003), while Buckwalter’s system is a procedural approach written in Perl which decomposes a word and simultaneously consults lexica for constraining the possible decompositions. Also, in a similar vein to Xerox’s Arabic analyzer, Yona and Wintner (2008) report on a large-scale system for Hebrew built on transducer technology. Most importantly, none of these very large systems are built around multi-tape automata even though such a construction from a linguistic perspective would appear to be a fitting choice when dealing with root-and-pattern morphology. 1.3 n-tape space complexity There is a fundamental space complexity problem with multi-tape automata, which is that when the number of tapes grows, the required joint symbol alphabet grows with exponential rapidity unless special mechanisms are devised to curtail this growth. This explosion </context>
</contexts>
<marker>Yona, Wintner, 2008</marker>
<rawString>Yona, S. and Wintner, S. (2008). A finite-state morphological grammar of Hebrew. Natural Language Engineering, 14(2):173–190.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>