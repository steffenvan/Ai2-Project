<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000407">
<note confidence="0.519248">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.998728142857143">
Section 6 (&amp;quot;On Translation&amp;quot;) consists of a single paper by van der Korst in which he
presents a FG MT system. The principles of the system are very simple. The predication
underlying a linguistic expression is language-neutral; therefore the theory provides
a ready-made interlingua. If it is possible to parse and to generate, then it is also
possible to translate. Of course, this is an oversimplification, since different languages
typically use different subsets of the set of possible predicates. Thus, paraphrasing
relations between predications are necessary. Van der Korst provides a lot of useful
examples to illustrate the problems and achievements of his system.
The verdict: This is an important book, since it begins to sketch what a compu-
tational version of FG might look like. It is very important for people working in
functional paradigms such as FG to bring their insights about language use to the
design of NLP systems, which will have real users. However, the book is ultimately
disappointing for a number of reasons. It has the feel of a collection of disparate pa-
pers that are united in their debt to Dik (1978) rather than by their participation in a
coherent research program. The papers are inadequately cross-referenced and display
many needless inconsistencies of style (e.g., &amp;quot;PROLOG&amp;quot; vs. &amp;quot;Prolog&amp;quot;; endnotes vs.
footnotes). The papers build very few bridges between computational FG and what is
going on in the rest of NLP. As we have noted, some of the attempts to do so misfire.
Perhaps most disappointing of all, the volume fails to raise what ought to be the most
interesting question: what, if any, are the distinctive benefits of functional theories
such as FG for NLP?
</bodyText>
<sectionHeader confidence="0.900788" genericHeader="abstract">
References
</sectionHeader>
<bodyText confidence="0.722944611111111">
Bates, Madeleine (1978). &amp;quot;The theory and
practice of augmented transition network
grammars.&amp;quot; In Natural Language
Communication with Computers, edited by
Leonard Bolc, 191-259. Springer-Verlag.
Butler, Christopher S. (1985). Systemic
Linguistics: Theory and Applications.
Batsford.
Dik, Simon C. (1978). Functional Grammar.
North-Holland. (Third printing, 1981,
Foris.)
Mellish, Christopher S. (1988).
&amp;quot;Implementing systemic classification by
unification.&amp;quot; Computational Linguistics,
14(1), 40-51.
Norman Fraser is a research fellow at the University of Surrey. He is currently researching depen-
dency parsing and dialog management. His address is: Social and Computer Sciences Research
Group, University of Surrey, Guildford, Surrey, GU2 5XH, U.K.; e-mail: norman@soc.surrey.ac.uk.
</bodyText>
<sectionHeader confidence="0.339276" genericHeader="categories and subject descriptors">
A Computational Model of Metaphor Interpretation
</sectionHeader>
<reference confidence="0.189448666666667">
James H. Martin
(University of Colorado at Boulder)
Boston: Academic Press, 1990,
xxiii 229 pp.
(Perspectives in Artificial Intelligence 8)
Hardbound, ISBN 0-12-474730-2
</reference>
<footnote confidence="0.4848302">
Reviewed by
Dan Fass
Simon Fraser University
A Computational Model of Metaphor Interpretation, a revised version of Martin&apos;s 1988
Ph.D. thesis, describes a computer program called MIDAS that contains an approach
</footnote>
<page confidence="0.996142">
106
</page>
<subsectionHeader confidence="0.948518">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.9993075625">
to metaphor interpretation based on the &amp;quot;conventional view&amp;quot; of metaphor. The con-
ventional view of metaphor, popularized by Lakoff and Johnson (1980), is that many
metaphors belong to conceptual classes variously referred to as &amp;quot;metaphorical con-
cepts,&amp;quot; &amp;quot;conceptual metaphors,&amp;quot; &amp;quot;conventional metaphors,&amp;quot; and &amp;quot;stock metaphors.&amp;quot;
Examples of metaphorical concepts include &apos;argument is war, time is money,&apos; and &apos;sad
is down.&apos; In the metaphorical concept &apos;argument is war,&apos; for example, &amp;quot; &apos;argument&apos;
is partially structured, understood, performed, and talked about in terms of &apos;war&apos; &amp;quot;
(ibid., p. 5), as in the sentences &amp;quot;He attacked every weak point in my argument&amp;quot; and
&amp;quot;She shot down all my defenses.&amp;quot;
The MIDAS program contains a &amp;quot;knowledge base&amp;quot; of conventional metaphors;
that is, conventional metaphors are explicitly represented in MIDAS&apos;s lexicon. The
program was part of Berkeley&apos;s UC (Unix Consultant) project, which developed a
system that gives advice to naive computer users on how to use the Unix operating
system. MIDAS was used to interpret and acquire conventional metaphors found in
the Unix domain. Many example metaphors in Martin&apos;s book are from that domain,
but other specialist domains are also considered, notably diseases and ideas.
</bodyText>
<listItem confidence="0.823476">
1. Organization of the Book and Its Basic Ideas
</listItem>
<bodyText confidence="0.83037875">
According to the preface, the book is about &amp;quot;the systematic representation, use, and
acquisition of knowledge about metaphors in the language&amp;quot; (p. xxii). Chapter 1, which is
very clear, summarizes Martin&apos;s main ideas and outlines the book&apos;s structure. MIDAS
has three basic components:
</bodyText>
<listItem confidence="0.9784358">
1. The lexicon of word senses and conventional metaphors, which are
represented using the KODIAK knowledge representation language.
2. The Metaphor Interpretation System (MIS), which interprets metaphors for
which there is adequate, explicit knowledge.
3. The Metaphor Extension System (MES), which acquires &amp;quot;novel&amp;quot; metaphors
</listItem>
<bodyText confidence="0.917978368421053">
for which there is no adequate knowledge by systematically extending,
elaborating, and combining already-known metaphors. (Martin attaches
much importance to the acquisition of new metaphors, which he regards
as a form of language acquisition.)
Chapter 2 of the book reviews related work on computational approaches to
metaphor and word-sense acquisition. Martin critiques what he calls &amp;quot;knowledge-
deficient&amp;quot; approaches to metaphor interpretation that do not use explicit knowledge
of conventional metaphors, but instead use some process of partial matching, inference,
or analogy. He suggests that the more successful of these approaches use knowledge
of conventional metaphors implicitly.
Chapter 3 describes Martin&apos;s view of conventional metaphor. A conventional
metaphor is said to consist of a source, a target, and a set of associations linking the
source and target (p. 36). The target &amp;quot;consists of the concepts to which the words are
actually referring&amp;quot; (p. 7) while the source &amp;quot;refers to the concepts in terms of which
the intended target concepts are being viewed&amp;quot; (ibid.). Martin suggests that some
conventional metaphors are core metaphors while others are extended metaphors (p. 42).
A core metaphor is a very general metaphor like non-living-thing-as-living-thing,
which contains subparts shared by more specific metaphors. Extended metaphors are
so called because they contain their own distinct subparts derived from core metaphors
</bodyText>
<page confidence="0.98397">
107
</page>
<note confidence="0.478491">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.999875411764706">
by various kinds of extension. For example, an extended metaphor might be a spe-
cialization of the source of a core metaphor, as with non-living-thing-as-plant, or a
specialization of the target, as with process-as-living-thing. These core and extended
metaphors, Martin argues, can be organized into hierarchies (p. 46) with inheritance
of common subparts down those hierarchies.
Chapters 4 through 9 describe the representation, interpretation, and acquisition
of conventional metaphors in Martin&apos;s model. Chapter 4 explains the representation of
knowledge about metaphors in MIDAS&apos;s lexicon. Individual conventional metaphors
are represented using a KODIAK knowledge structure called a metaphor-sense (p. 63),
and hence contains a source, a target, and a set of associations. Each association is
represented using another KODIAK structure called a metaphor-map. In other words, a
metaphor-sense contains a set of metaphor-maps, each one representing an association
that links concepts from the source and target. Indeed, &amp;quot;metaphor-maps represent the
building blocks out of which meaningful metaphor-senses are constructed&amp;quot; (p. 67).
Conversely, &amp;quot;a metaphor-sense... ties together sets of component metaphor-maps that
together constitute a meaningful conventional metaphor&amp;quot; (ibid.). To give an example:
in the conventional metaphor non-living-thing-as-living-thing, the source is living-
thing, the target is non-living-thing, and an association connects the source and target
that a non-living-thing be viewed as a living-thing. This metaphor is represented as
a metaphor-sense that contains a metaphor-map for the above association. Metaphor-
senses and metaphor-maps are organized into abstraction hierarchies and hence can
represent core and extended metaphors.
Chapter 5 describes the process of metaphor interpretation in MIDAS&apos;s MIS com-
ponent. The algorithm for metaphor interpretation is given on page 95 and is designed
to reflect Martin&apos;s view that literal and metaphorical interpretations have &amp;quot;equal sta-
tus&amp;quot; and &amp;quot;are evaluated using interpretation mechanisms that are fundamentally the
same&amp;quot; (p. 89). Two basic inference processes are used in interpretation, concretion and
metaphoric unviewing, either separately or in tandem. Both are based on constraint
checking and seek the most specific interpretation of a sentence by selecting an inter-
pretation that most tightly matches the concepts derived from the words of the sen-
tences. Concretion replaces an abstract concept with a more specific one; metaphoric
unviewing replaces the source concept in a metaphor with the corresponding target
concept.
Chapters 6-9 describe how MIDAS learns new metaphors through its MES com-
ponent. Learning is achieved by applying three kinds of extension technique to conven-
tional metaphors already in MIDAS&apos;s lexicon: combined extension, similarity
extension, and core extension. Analogical reasoning is used in the similarity-extension
(see p. 147) and core-extension techniques (see p. 170).
Chapter 10 shows that, equipped with suitable conventional metaphors, MIDAS
can handle many, varied examples from the metaphor interpretation literature. For
instance, Jerry Hobbs&apos; example, &amp;quot;N is at zero&amp;quot; is handled using the conventional
metaphor Is-At-Variable-Value (pp. 190-192), Yorick Wilks&apos; &amp;quot;Britain tried to leave the
Common Market&amp;quot; is treated using Enter-Association, a type of Enter-Metaphor
(pp. 196-198), and &amp;quot;My car drinks gasoline&amp;quot; is interpreted using Drinking-Reduce-
Amount (pp. 203-205).
Chapter 11 contains a summary and briefly discusses some problems that Martin
sees with his model. The major interpretation problem, according to Martin, is that
the model blurs the distinction between conventional metaphors and word senses
and that many of his conventional metaphors &amp;quot;would have been treated as distinct
unmotivated word senses in most previous analyses&amp;quot; (p. 215). I agree, especially in
the case for conventional metaphors and verb senses. For example, the conventional
</bodyText>
<page confidence="0.997587">
108
</page>
<subsectionHeader confidence="0.850769">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999904363636364">
metaphor used to interpret &amp;quot;McEnroe killed Connors&amp;quot; is Kill-Sports-Defeat, a type
of Kill-Metaphor. Other analyses might well postulate Kill-Sports-Defeat as a verb
sense rather than a conventional metaphor.
Although the book is well laid out and includes an index (always welcome), it
is quite hard to separate instances of metaphor-senses from metaphor-maps in the
text. In addition, the numbering of sentence examples is somewhat distracting. Each
occurrence of a sentence is numbered separately; hence, for example, &amp;quot;John gave Mary
a cold&amp;quot; is number (24a), (38a), (43), (45a), (46), and so on. Also, unfortunately, there is a
discrepancy in Chapter 3 between the numbering of sentence examples and reference
to them in the text — (11) for (17), (12) for (18), through to (17) for (23) — but fortunately
it only lasts for five pages (pp. 37-42).
</bodyText>
<sectionHeader confidence="0.981116" genericHeader="acknowledgments">
2. Comments
</sectionHeader>
<bodyText confidence="0.999904945945946">
Martin did his Ph.D. at Berkeley, and his work is influenced by past research there
on metaphor, idioms, and fixed phrases by Yigal Arens, Paul Jacobs, George Lakoff,
Peter Norvig, Robert Wilensky, and others. Martin&apos;s work is probably the most exten-
sive pursuit so far of a computational approach to the interpretation of conventional
metaphors (for other approaches see, e.g., Barnden 1989,1990; Carbonell 1982; Norvig
1989, pp. 609-610) and, it is probably fair to say, represents a step forward in our
understanding of metaphor interpretation.
It would have been interesting to have had some discussion of differences be-
tween Martin&apos;s views of conventional metaphor and those of Lakoff and Johnson. It
would also have been interesting to have seen more discussion of the generation of
conventional metaphors. MIDAS was linked to a natural language generator in the
UC system, which could produce metaphorical sentences using knowledge of conven-
tional metaphors so that when a user employed a conventional metaphor in asking a
question, the natural language generator would use the same metaphor in producing
the answer (pp. 11-12). Despite this, metaphor generation is barely mentioned, though
clearly Martin&apos;s model has something to say about this topic, one which has received
very little attention from a computational perspective (though see, e.g., Jacobs 1987,
pp. 323-324,348-349).
MIDAS can probably interpret more sentence metaphors than any other existing
system, including systems that do not use a conventional view of metaphor. Although
it rather looks as if specific conventional metaphors such as Is-At-Variable-Value and
Drinking-Reduce-Amount were added to MIDAS especially for interpreting particu-
lar sentences, MIDAS&apos;s coverage is a persuasive demonstration of the power of the
conventional view of metaphor. However, Martin&apos;s description of his model left this
reviewer with some questions about the apparent open-endedness of the conventional
metaphor approach.
The first question is: how many conventional metaphors are there? The book does
not contain a list of the conventional metaphors used in MIDAS. I compiled an informal
list of metaphors from the figures, examples, and index given in the book and found
69. Of these, 10 were domain-independent metaphors, including 7 very general ones.
Of the 59 domain-specific metaphors, 19 were from the Unix domain, 12 were about
diseases, and 10 concerned the communication of ideas. As can be seen, a large majority
of the conventional metaphors were domain-specific ones. If we assume conservatively
10-15 conventional metaphors per domain, that would mean hundreds of metaphors
in a system with decent coverage.
The second question is: how are conventional metaphors organized? On page 81,
there is a hierarchy of metaphor-maps for the core metaphor Non-Living-Thing-
</bodyText>
<page confidence="0.993725">
109
</page>
<note confidence="0.560712">
Computational Linguistics Volume 17, Number 1
</note>
<bodyText confidence="0.998960466666667">
As-Living-Thing that includes 12 extended metaphors. However, no taxonomies are
given for the other very general core metaphors used in MIDAS, which are Location-
Metaphor, At-State, Have-State, Container-Metaphor, Kill-Metaphor, and Eating-
Metaphor. Moreover, there is little discussion of the relationship between these core
metaphors.
The third question is: is there some way to reduce the enormous number of
metaphorical interpretations that MIDAS seeks? Step 3 of the metaphor interpreta-
tion algorithm given on page 95 states that MIDAS collects &amp;quot;all possible interpreta-
tions, both metaphorical and literal,&amp;quot; including presumably direct application of the
metaphors in MIDAS&apos;s knowledge base plus the use of MIDAS&apos;s metaphor extension
techniques. Metaphors are sought where there are no constraint violations (p. 104).
This is a vast amount of processing, and remember that MIDAS only uses 70 or so
metaphors — a larger system might contain hundreds. Martin might reply that realis-
tic metaphor interpretation does involve an enormous amount of processing. He may
be right.
</bodyText>
<sectionHeader confidence="0.935569" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994742139534884">
•
Barnden, John A. (1989). &amp;quot;Belief,
metaphorically speaking.&amp;quot; In Proceedings,
1st International Conference on Principles of
Knowledge Representation and Reasoning,
Morgan Kaufmann.
Barnden, John A. (1990). &amp;quot;Naive
metaphysics: A metaphor-based approach
to propositional attitude representation
(unabridged version).&amp;quot; Memorandum
MCCS-90-174, Computing Research
Laboratory, New Mexico State University.
Carbonell, Jaime G. (1982). &amp;quot;Metaphor: An
inescapable phenomenon in natural
language comprehension.&amp;quot; In Strategies for
natural language processing, edited by
Wendy G. Lehnert and Martin H. Ringle,
415-434. Lawrence Erlbaum Associates.
Jacobs, Paul S. (1987). &amp;quot;Knowledge-intensive
natural language generation.&amp;quot; Artificial
Intelligence, 33,325-378.
Lakoff, George and Johnson, Mark (1980).
Metaphors We Live By. The University of
Chicago Press.
Norvig, Peter (1989). &amp;quot;Marker passing as a
weak method for text inferencing.&amp;quot;
Cognitive Science, 13, 569-620.
Dan Fass is a visiting fellow at the Centre for Systems Science, Simon Fraser University, Canada.
Before this, he worked for three years at the Computing Research Laboratory, New Mexico State
University, U.S.A. His Ph.D. is from the University of Essex, England. His research interests
include the computer understanding of metaphor and metonymy, lexical ambiguity, machine-
readable dictionaries, ill-formed input, and beliefs. Fass&apos;s address is Centre for Systems Science,
Simon Fraser University, Burnaby, British Columbia, Canada V5A 1S6; e-mail: fass@cs.sfu.ca.
Practical SGML
Eric van Herwijnen
(CERN)
Dordrecht: Kluwer Academic
Publishers, 1990, xviii + 307 pp.
Paperbound, ISBN 0-7923-0635-X,
$39.95
Reviewed by
Carol Van Ess-Dykema
U.S. Department of Defense and Carnegie Mellon University
</reference>
<page confidence="0.998395">
110
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000049">
<title confidence="0.300929">Computational Linguistics Volume 17, Number 1</title>
<abstract confidence="0.95326716">Section 6 (&amp;quot;On Translation&amp;quot;) consists of a single paper by van der Korst in which he presents a FG MT system. The principles of the system are very simple. The predication underlying a linguistic expression is language-neutral; therefore the theory provides a ready-made interlingua. If it is possible to parse and to generate, then it is also possible to translate. Of course, this is an oversimplification, since different languages typically use different subsets of the set of possible predicates. Thus, paraphrasing relations between predications are necessary. Van der Korst provides a lot of useful examples to illustrate the problems and achievements of his system. verdict: is an important book, since it begins to sketch what a computational version of FG might look like. It is very important for people working in functional paradigms such as FG to bring their insights about language use to the design of NLP systems, which will have real users. However, the book is ultimately disappointing for a number of reasons. It has the feel of a collection of disparate papers that are united in their debt to Dik (1978) rather than by their participation in a coherent research program. The papers are inadequately cross-referenced and display many needless inconsistencies of style (e.g., &amp;quot;PROLOG&amp;quot; vs. &amp;quot;Prolog&amp;quot;; endnotes vs. footnotes). The papers build very few bridges between computational FG and what is going on in the rest of NLP. As we have noted, some of the attempts to do so misfire. Perhaps most disappointing of all, the volume fails to raise what ought to be the most interesting question: what, if any, are the distinctive benefits of functional theories such as FG for NLP? References Bates, Madeleine (1978). &amp;quot;The theory and practice of augmented transition network In Language</abstract>
<note confidence="0.944333952380953">with Computers, by Leonard Bolc, 191-259. Springer-Verlag. Christopher S. (1985). Linguistics: Theory and Applications. Batsford. Simon C. (1978). Grammar. North-Holland. (Third printing, 1981, Foris.) Mellish, Christopher S. (1988). &amp;quot;Implementing systemic classification by Linguistics, Fraser a research fellow at the University of Surrey. He is currently researching dependency parsing and dialog management. His address is: Social and Computer Sciences Research Group, University of Surrey, Guildford, Surrey, GU2 5XH, U.K.; e-mail: norman@soc.surrey.ac.uk. A Computational Model of Metaphor Interpretation (University of Colorado at Boulder) Boston: Academic Press, 1990, xxiii 229 pp. (Perspectives in Artificial Intelligence 8) Hardbound, ISBN 0-12-474730-2 Reviewed by</note>
<author confidence="0.982572">Dan Fass</author>
<affiliation confidence="0.981755">Simon Fraser University</affiliation>
<address confidence="0.952233">Computational Model of Metaphor Interpretation, revised version of Martin&apos;s 1988</address>
<abstract confidence="0.996885165680473">Ph.D. thesis, describes a computer program called MIDAS that contains an approach 106 Book Reviews to metaphor interpretation based on the &amp;quot;conventional view&amp;quot; of metaphor. The conventional view of metaphor, popularized by Lakoff and Johnson (1980), is that many metaphors belong to conceptual classes variously referred to as &amp;quot;metaphorical concepts,&amp;quot; &amp;quot;conceptual metaphors,&amp;quot; &amp;quot;conventional metaphors,&amp;quot; and &amp;quot;stock metaphors.&amp;quot; Examples of metaphorical concepts include &apos;argument is war, time is money,&apos; and &apos;sad is down.&apos; In the metaphorical concept &apos;argument is war,&apos; for example, &amp;quot; &apos;argument&apos; is partially structured, understood, performed, and talked about in terms of &apos;war&apos; &amp;quot; p. 5), as in the sentences &amp;quot;He weak point in my argument&amp;quot; and down my defenses.&amp;quot; The MIDAS program contains a &amp;quot;knowledge base&amp;quot; of conventional metaphors; that is, conventional metaphors are explicitly represented in MIDAS&apos;s lexicon. The program was part of Berkeley&apos;s UC (Unix Consultant) project, which developed a system that gives advice to naive computer users on how to use the Unix operating system. MIDAS was used to interpret and acquire conventional metaphors found in the Unix domain. Many example metaphors in Martin&apos;s book are from that domain, but other specialist domains are also considered, notably diseases and ideas. 1. Organization of the Book and Its Basic Ideas to the preface, the book is about &amp;quot;the systematic use, knowledge about metaphors in the language&amp;quot; (p. xxii). Chapter 1, which is very clear, summarizes Martin&apos;s main ideas and outlines the book&apos;s structure. MIDAS has three basic components: The word senses and conventional metaphors, which are represented using the KODIAK knowledge representation language. The Interpretation System (MIS), interprets metaphors for which there is adequate, explicit knowledge. The Extension System which acquires &amp;quot;novel&amp;quot; metaphors for which there is no adequate knowledge by systematically extending, elaborating, and combining already-known metaphors. (Martin attaches much importance to the acquisition of new metaphors, which he regards as a form of language acquisition.) Chapter 2 of the book reviews related work on computational approaches to metaphor and word-sense acquisition. Martin critiques what he calls &amp;quot;knowledgedeficient&amp;quot; approaches to metaphor interpretation that do not use explicit knowledge of conventional metaphors, but instead use some process of partial matching, inference, or analogy. He suggests that the more successful of these approaches use knowledge of conventional metaphors implicitly. Chapter 3 describes Martin&apos;s view of conventional metaphor. A conventional is said to consist of a a set of the source and target (p. 36). The target &amp;quot;consists of the concepts to which the words are actually referring&amp;quot; (p. 7) while the source &amp;quot;refers to the concepts in terms of which the intended target concepts are being viewed&amp;quot; (ibid.). Martin suggests that some metaphors are metaphors others are metaphors 42). core metaphor is a very general metaphor like which contains subparts shared by more specific metaphors. Extended metaphors are so called because they contain their own distinct subparts derived from core metaphors 107 Computational Linguistics Volume 17, Number 1 by various kinds of extension. For example, an extended metaphor might be a speof the source of a core metaphor, as with a of the target, as with core and extended metaphors, Martin argues, can be organized into hierarchies (p. 46) with inheritance of common subparts down those hierarchies. Chapters 4 through 9 describe the representation, interpretation, and acquisition of conventional metaphors in Martin&apos;s model. Chapter 4 explains the representation of knowledge about metaphors in MIDAS&apos;s lexicon. Individual conventional metaphors represented using a KODIAK knowledge structure called a 63), and hence contains a source, a target, and a set of associations. Each association is using another KODIAK structure called a other words, a metaphor-sense contains a set of metaphor-maps, each one representing an association that links concepts from the source and target. Indeed, &amp;quot;metaphor-maps represent the building blocks out of which meaningful metaphor-senses are constructed&amp;quot; (p. 67). Conversely, &amp;quot;a metaphor-sense... ties together sets of component metaphor-maps that together constitute a meaningful conventional metaphor&amp;quot; (ibid.). To give an example: the conventional metaphor source is livingtarget is an association connects the source and target a viewed as a metaphor is represented as a metaphor-sense that contains a metaphor-map for the above association. Metaphorsenses and metaphor-maps are organized into abstraction hierarchies and hence can represent core and extended metaphors. Chapter 5 describes the process of metaphor interpretation in MIDAS&apos;s MIS component. The algorithm for metaphor interpretation is given on page 95 and is designed to reflect Martin&apos;s view that literal and metaphorical interpretations have &amp;quot;equal status&amp;quot; and &amp;quot;are evaluated using interpretation mechanisms that are fundamentally the (p. 89). Two basic inference processes are used in interpretation, unviewing, separately or in tandem. Both are based on constraint checking and seek the most specific interpretation of a sentence by selecting an interpretation that most tightly matches the concepts derived from the words of the sentences. Concretion replaces an abstract concept with a more specific one; metaphoric unviewing replaces the source concept in a metaphor with the corresponding target concept. Chapters 6-9 describe how MIDAS learns new metaphors through its MES component. Learning is achieved by applying three kinds of extension technique to conventional metaphors already in MIDAS&apos;s lexicon: combined extension, similarity extension, and core extension. Analogical reasoning is used in the similarity-extension (see p. 147) and core-extension techniques (see p. 170). Chapter 10 shows that, equipped with suitable conventional metaphors, MIDAS can handle many, varied examples from the metaphor interpretation literature. For Jerry Hobbs&apos; example, is handled using the conventional 190-192), Yorick Wilks&apos; &amp;quot;Britain to leave Market&amp;quot; is treated using type of 196-198), and &amp;quot;My car drinks gasoline&amp;quot; is interpreted using Drinking-Reduce- 203-205). Chapter 11 contains a summary and briefly discusses some problems that Martin sees with his model. The major interpretation problem, according to Martin, is that the model blurs the distinction between conventional metaphors and word senses and that many of his conventional metaphors &amp;quot;would have been treated as distinct unmotivated word senses in most previous analyses&amp;quot; (p. 215). I agree, especially in the case for conventional metaphors and verb senses. For example, the conventional 108 Book Reviews used to interpret &amp;quot;McEnroe killed Connors&amp;quot; is type analyses might well postulate a verb sense rather than a conventional metaphor. Although the book is well laid out and includes an index (always welcome), it is quite hard to separate instances of metaphor-senses from metaphor-maps in the text. In addition, the numbering of sentence examples is somewhat distracting. Each occurrence of a sentence is numbered separately; hence, for example, &amp;quot;John gave Mary a cold&amp;quot; is number (24a), (38a), (43), (45a), (46), and so on. Also, unfortunately, there is a discrepancy in Chapter 3 between the numbering of sentence examples and reference to them in the text — (11) for (17), (12) for (18), through to (17) for (23) — but fortunately it only lasts for five pages (pp. 37-42). 2. Comments Martin did his Ph.D. at Berkeley, and his work is influenced by past research there on metaphor, idioms, and fixed phrases by Yigal Arens, Paul Jacobs, George Lakoff, Peter Norvig, Robert Wilensky, and others. Martin&apos;s work is probably the most extensive pursuit so far of a computational approach to the interpretation of conventional metaphors (for other approaches see, e.g., Barnden 1989,1990; Carbonell 1982; Norvig 1989, pp. 609-610) and, it is probably fair to say, represents a step forward in our understanding of metaphor interpretation. It would have been interesting to have had some discussion of differences between Martin&apos;s views of conventional metaphor and those of Lakoff and Johnson. It would also have been interesting to have seen more discussion of the generation of conventional metaphors. MIDAS was linked to a natural language generator in the UC system, which could produce metaphorical sentences using knowledge of conventional metaphors so that when a user employed a conventional metaphor in asking a question, the natural language generator would use the same metaphor in producing the answer (pp. 11-12). Despite this, metaphor generation is barely mentioned, though clearly Martin&apos;s model has something to say about this topic, one which has received very little attention from a computational perspective (though see, e.g., Jacobs 1987, pp. 323-324,348-349). MIDAS can probably interpret more sentence metaphors than any other existing system, including systems that do not use a conventional view of metaphor. Although rather looks as if specific conventional metaphors such as added to MIDAS especially for interpreting particular sentences, MIDAS&apos;s coverage is a persuasive demonstration of the power of the conventional view of metaphor. However, Martin&apos;s description of his model left this reviewer with some questions about the apparent open-endedness of the conventional metaphor approach. The first question is: how many conventional metaphors are there? The book does not contain a list of the conventional metaphors used in MIDAS. I compiled an informal list of metaphors from the figures, examples, and index given in the book and found 69. Of these, 10 were domain-independent metaphors, including 7 very general ones. Of the 59 domain-specific metaphors, 19 were from the Unix domain, 12 were about diseases, and 10 concerned the communication of ideas. As can be seen, a large majority of the conventional metaphors were domain-specific ones. If we assume conservatively 10-15 conventional metaphors per domain, that would mean hundreds of metaphors in a system with decent coverage. The second question is: how are conventional metaphors organized? On page 81, is a hierarchy of metaphor-maps for the core metaphor 109 Computational Linguistics Volume 17, Number 1 includes 12 extended metaphors. However, no taxonomies are for the other very general core metaphors used in MIDAS, which are Location- At-State, Have-State, Container-Metaphor, Kill-Metaphor, Eatingthere is little discussion of the relationship between these core metaphors. The third question is: is there some way to reduce the enormous number of metaphorical interpretations that MIDAS seeks? Step 3 of the metaphor interpretation algorithm given on page 95 states that MIDAS collects &amp;quot;all possible interpretations, both metaphorical and literal,&amp;quot; including presumably direct application of the metaphors in MIDAS&apos;s knowledge base plus the use of MIDAS&apos;s metaphor extension techniques. Metaphors are sought where there are no constraint violations (p. 104). This is a vast amount of processing, and remember that MIDAS only uses 70 or so metaphors — a larger system might contain hundreds. Martin might reply that realistic metaphor interpretation does involve an enormous amount of processing. He may be right.</abstract>
<note confidence="0.5786836">References • Barnden, John A. (1989). &amp;quot;Belief, speaking.&amp;quot; In 1st International Conference on Principles of</note>
<title confidence="0.846075">Knowledge Representation and Reasoning,</title>
<author confidence="0.878134">Morgan Kaufmann</author>
<address confidence="0.401113">Barnden, John A. (1990). &amp;quot;Naive</address>
<abstract confidence="0.959647">metaphysics: A metaphor-based approach to propositional attitude representation (unabridged version).&amp;quot; Memorandum</abstract>
<affiliation confidence="0.7494615">MCCS-90-174, Computing Research Laboratory, New Mexico State University.</affiliation>
<address confidence="0.888822">Carbonell, Jaime G. (1982). &amp;quot;Metaphor: An</address>
<abstract confidence="0.690033666666667">inescapable phenomenon in natural comprehension.&amp;quot; In for language processing, by</abstract>
<author confidence="0.943838">Wendy G Lehnert</author>
<author confidence="0.943838">Martin H Ringle</author>
<note confidence="0.6802672">415-434. Lawrence Erlbaum Associates. Jacobs, Paul S. (1987). &amp;quot;Knowledge-intensive language generation.&amp;quot; Lakoff, George and Johnson, Mark (1980). We Live The University of Chicago Press. Norvig, Peter (1989). &amp;quot;Marker passing as a weak method for text inferencing.&amp;quot; Science, Fass a visiting fellow at the Centre for Systems Science, Simon Fraser University, Canada. Before this, he worked for three years at the Computing Research Laboratory, New Mexico State University, U.S.A. His Ph.D. is from the University of Essex, England. His research interests include the computer understanding of metaphor and metonymy, lexical ambiguity, machinereadable dictionaries, ill-formed input, and beliefs. Fass&apos;s address is Centre for Systems Science, Simon Fraser University, Burnaby, British Columbia, Canada V5A 1S6; e-mail: fass@cs.sfu.ca.</note>
<title confidence="0.974202">Practical SGML</title>
<author confidence="0.998433">Eric van_Herwijnen</author>
<affiliation confidence="0.6503">(CERN) Dordrecht: Kluwer Academic</affiliation>
<note confidence="0.8282995">Publishers, 1990, xviii + 307 pp. Paperbound, ISBN 0-7923-0635-X, $39.95 Reviewed by</note>
<author confidence="0.999031">Carol Van_Ess-Dykema</author>
<affiliation confidence="0.999266">U.S. Department of Defense and Carnegie Mellon University</affiliation>
<address confidence="0.951755">110</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H James</author>
</authors>
<title>Martin (University of Colorado at Boulder)</title>
<date>1990</date>
<volume>229</volume>
<pages>pp.</pages>
<publisher>Academic Press,</publisher>
<location>Boston:</location>
<marker>James, 1990</marker>
<rawString>James H. Martin (University of Colorado at Boulder) Boston: Academic Press, 1990, xxiii 229 pp.</rawString>
</citation>
<citation valid="false">
<booktitle>(Perspectives in Artificial Intelligence 8) Hardbound, ISBN</booktitle>
<pages>0--12</pages>
<marker></marker>
<rawString>(Perspectives in Artificial Intelligence 8) Hardbound, ISBN 0-12-474730-2 •</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Barnden</author>
</authors>
<title>Belief, metaphorically speaking.&amp;quot;</title>
<date>1989</date>
<booktitle>In Proceedings, 1st International Conference on Principles of Knowledge Representation and Reasoning,</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<marker>Barnden, 1989</marker>
<rawString>Barnden, John A. (1989). &amp;quot;Belief, metaphorically speaking.&amp;quot; In Proceedings, 1st International Conference on Principles of Knowledge Representation and Reasoning, Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Barnden</author>
</authors>
<title>Naive metaphysics: A metaphor-based approach to propositional attitude representation (unabridged version).&amp;quot;</title>
<date>1990</date>
<tech>Memorandum MCCS-90-174,</tech>
<institution>Computing Research Laboratory, New Mexico State University.</institution>
<marker>Barnden, 1990</marker>
<rawString>Barnden, John A. (1990). &amp;quot;Naive metaphysics: A metaphor-based approach to propositional attitude representation (unabridged version).&amp;quot; Memorandum MCCS-90-174, Computing Research Laboratory, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime G Carbonell</author>
</authors>
<title>Metaphor: An inescapable phenomenon in natural language comprehension.&amp;quot; In Strategies for natural language processing, edited by</title>
<date>1982</date>
<pages>415--434</pages>
<marker>Carbonell, 1982</marker>
<rawString>Carbonell, Jaime G. (1982). &amp;quot;Metaphor: An inescapable phenomenon in natural language comprehension.&amp;quot; In Strategies for natural language processing, edited by Wendy G. Lehnert and Martin H. Ringle, 415-434. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul S Jacobs</author>
</authors>
<title>Knowledge-intensive natural language generation.&amp;quot;</title>
<date>1987</date>
<journal>Artificial Intelligence,</journal>
<pages>33--325</pages>
<marker>Jacobs, 1987</marker>
<rawString>Jacobs, Paul S. (1987). &amp;quot;Knowledge-intensive natural language generation.&amp;quot; Artificial Intelligence, 33,325-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>The University of Chicago Press.</publisher>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>Lakoff, George and Johnson, Mark (1980). Metaphors We Live By. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Norvig</author>
</authors>
<title>Marker passing as a weak method for text inferencing.&amp;quot;</title>
<date>1989</date>
<journal>Cognitive Science,</journal>
<volume>13</volume>
<pages>569--620</pages>
<marker>Norvig, 1989</marker>
<rawString>Norvig, Peter (1989). &amp;quot;Marker passing as a weak method for text inferencing.&amp;quot; Cognitive Science, 13, 569-620.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dan</author>
</authors>
<title>Fass is a visiting fellow at the Centre for Systems Science, Simon Fraser University, Canada. Before this, he worked for three years at the Computing Research Laboratory,</title>
<institution>Mexico State University, U.S.A. His Ph.D. is from the University of Essex, England. His</institution>
<location>New</location>
<note>V5A 1S6; e-mail: fass@cs.sfu.ca.</note>
<marker>Dan, </marker>
<rawString>Dan Fass is a visiting fellow at the Centre for Systems Science, Simon Fraser University, Canada. Before this, he worked for three years at the Computing Research Laboratory, New Mexico State University, U.S.A. His Ph.D. is from the University of Essex, England. His research interests include the computer understanding of metaphor and metonymy, lexical ambiguity, machinereadable dictionaries, ill-formed input, and beliefs. Fass&apos;s address is Centre for Systems Science, Simon Fraser University, Burnaby, British Columbia, Canada V5A 1S6; e-mail: fass@cs.sfu.ca.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Practical SGML</author>
</authors>
<title>Eric van Herwijnen (CERN)</title>
<marker>SGML, </marker>
<rawString>Practical SGML Eric van Herwijnen (CERN)</rawString>
</citation>
<citation valid="true">
<date>1990</date>
<journal>xviii +</journal>
<volume>307</volume>
<pages>pp.</pages>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht:</location>
<marker>1990</marker>
<rawString>Dordrecht: Kluwer Academic Publishers, 1990, xviii + 307 pp. Paperbound, ISBN 0-7923-0635-X, $39.95</rawString>
</citation>
<citation valid="false">
<authors>
<author>Reviewed by Carol Van Ess-Dykema U S</author>
</authors>
<institution>Department of Defense and Carnegie Mellon University</institution>
<marker>S, </marker>
<rawString>Reviewed by Carol Van Ess-Dykema U.S. Department of Defense and Carnegie Mellon University</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>