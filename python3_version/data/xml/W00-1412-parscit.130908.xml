<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.996048">
Incremental -EventConceptualization and
Natural Language Generation in Monitoring Environments
</title>
<author confidence="0.892114">
Markus GUHE, Christopher HABEL, Heike TAPPE
</author>
<affiliation confidence="0.9424085">
Research Group Knowledge and Language Processing (WSV),
Department of Informatics, University of Hamburg
</affiliation>
<address confidence="0.7764305">
Vogt-Kolln-StraBe 30
.22527.Hainburg, _Germany, D-22527
</address>
<email confidence="0.873457">
{guhe, habel, tappe}@informatik.uni-hamburg.de
</email>
<sectionHeader confidence="0.998657" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9952074375">
In this paper we present a psycholinguistically
motivated architecture and its prototypical
implementation for an incremental conceptu-
alizer, which monitors dynamic changes in the
world and simultaneously generates warnings
for (possibly) safety-critical developments. It
does so by conceptualizing events and build-
ing up a hierarchical knowledge representa-
tion of the perceived states of affairs. If it
detects a safety problem, it selects suitable
elements from the representation for a warn-
ing, brings them into an appropriate order, and
generates incremental preverbal messages
(propositional structures) from them, which
can be taken by a subsequent component to
encode them linguistically.
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.980701076923077">
Systems that generate natural language descrip-
tions of what happens in a dynamically changing
world can be improved substantially by working
incrementally. Incrementality enhances the overall
quality of the systems for three reasons: (1) The
dynamic nature of a continuous stream of input in-
formation can be handled more directly and, there-
fore, easier. (2) Incremental systems are capable
of producing fluent speech, i.e. speech without ar-
tificial auditory gaps. (3) Parallelism that comes
with incrementality makes better use of the avail-
able resources.
Furthermore, Reiter (1994), who reviews the
</bodyText>
<listItem confidence="0.677008625">
• architecture of some models of natural language
generation, shows that psycholinguistic and engi-
neering approaches often result in systems, which
are similar in crucial respects. In this paper we
ground on two of these common aspects, namely
the distinction between what-to-say and how-to-
say (De Smedt, Horacek &amp; Zock, 1996) and the
use of a pipeline architecture, which divides the
</listItem>
<bodyText confidence="0.999919416666667">
generation process &amp;quot;into multiple modules, with
information flowing in a &apos;pipeline&apos; fashion from
one module to the next&amp;quot; (Reiter, 1994). Reiter
states that these architectures do not require mod-
ules to work in parallel; if parallelism is used one
has an incremental model, cf. De Smedt &amp; Kern-
pen (1987), Ferreira (1996).
The primary research topic of the ConeEvi
project is the what-to-say component, in which the
content of utterances is planned (Reiter&apos;s content
planning, in contrast to the language specific sen-
tence planning component). We use the terminol-
ogy of Levelt (1989), who calls the first
component the conceptualizer, the second the
formulator. These modules interact via preverbal
messages, which are propositional, non-verbal
representations of the utterance built up by the
conceptualizer. They are transformed by the for-
mulator into linguistic structures for spoken or
written output. Besides considering high level
communicative goals (macroplanning), which are
in the focus of most computational approaches to
the what-to-say component, e.g. De Smedt &amp;
Kempen (1987), McKeown (1985), Hovy (1993),
Chu-Carroll &amp; Carberry (1998), Radev &amp; McKe-
own (1998), the type of information to be verbal-
ized also determines the processes of
conceptualization on the level of microplanning,
cf. Levelt (1989). Thus, the traditional top-down
approaches have to be combined with bottom-up
data-driven approaches of text planning (Marcu,
1997). The conceptualizer that is described in de-
tail in section 3 fits the pipeline architecture on a
coarse level, but integrates on finer levels the
ideas of functional modules (Cahill et al., 1999).
In the present paper we focus on the task of
</bodyText>
<note confidence="0.69719575">
I ConcEv (Conceptualizing Events) is supported by the
DFG (German Science Foundation) in the priority pro-
gram &apos;Language Production&apos; under grant Ha-1237/10
to Christopher Habel.
</note>
<page confidence="0.9996">
85
</page>
<bodyText confidence="0.999643603448276">
generating verbal descriptions of continuously in-
coming input from a changing physical world (see
section 2, for similar settings cf. Neumann &amp; No-
vak (1983) and André, Herzog &amp; Rist (1988)).
This specific task requires an incremental pipeline
architecture—as there are certain steps that have
to be carried out in a specific order—and, addi-
tionally, these steps can be organized in such a
way that a sequence of clear-cut modules arises,
which can work in.parallel. Parallel_processing has
the advantage that several tasks can be done si-
multaneously; thus, while utterances are generated
for some input, subsequent input can already be
taken in and processed.
Simultaneous conceptualization can be used as
the basis of systems producing verbal messages
when they detect a (possibly) safety-critical de-
velopment while monitoring a safety-critical sys-
tem, like intensive care units, nuclear power
plants, or airports. A module for the generation of
natural language can be an effective enhancement
for monitoring for mainly two reasons: first, in
most cases operators are busy observing many
displays. Here the auditory presentation of infor-
mation can make use of idle cognitive resources of
the operators and, thus, reduce their workload in
directing their attention to a development that may
lead to hazardous situations.2 Second, the essential
piece of information can be extracted from a
highly complex set of multimodal information and
presented by the system in a crisp way. Language
is the best conceivable means to transfer informa-
tion as pointedly as possible. Moreover, taking the
dynamics of the permanently changing world into
account has the advantage that safety-critical
situations can be anticipated earlier and much
more reliably. Conventional systems, in contrast,
just compare actual measurements with allowed
values and give a warning or an alarm when a
violation occurs. But it is more useful, e.g. for a
nurse if the system tells her that a patient&apos;s blood
pressure is rapidly dropping than that his blood
pressure is already dangerously low.
We see the proposed implementation of an in-
cremental conceptualizer also as a means to gain
2 The multimodal monitoring environment proposed
here reflects the division of labor between the compo-
nents in working memory (Baddeley, 1986), especially
between the visuospatial sketchpad (VSSP) and the
phonological loop. Since the observation of multiple
display units puts a heavy strain on the VSSP, spoken
natural language as input of critical information would
use that subcomponent of working memory, namely the
phonological loop, which is less strained.
_insights into _psycholinguistic. aspects of natural
language processing. Our implementation thus
simulates aspects of behavior, e.g. the effects dif-
fering time pressure has on verbalizations.
</bodyText>
<sectionHeader confidence="0.868232" genericHeader="method">
2 Conceptualizing Events
</sectionHeader>
<bodyText confidence="0.999988127659575">
If the system has to produce descriptions about
what it &apos;sees&apos;, the main conceptual task is building
up conceptual entities representing spatio-
-temporal- constellations -of the -external world, i.e.
event conceptualization. Events emerge from dy-
namic input data, which are segmented by the
conceptual system into meaningful units (Avra-
hami &amp; Kareev, 1994). They are therefore internal
representations rather than external entities: &amp;quot;[...]
events arise in the perception of observers&amp;quot;
(Zacks, 1997). Consequently, a language produc-
tion system designed for verbalizing what the
system perceives has to deal with information
stemming from multiple modalities, e.g. auditory
and spatial. In particular, a continuous multimodal
&apos;perceptual stream&apos; has to be translated into dis-
crete propositional output (preverbal messages)
that can be encoded linguistically, cf. Levelt
(1989). To meet such demands, three subtasks
have to be solved: (1) The input stream has to be
subdivided into &apos;perceptual units&apos;; (2) conceptual
representations have to be built up from these
&apos;percepts&apos;, which (3) have to be combined to pre-
verbal messages. For the time being, we take the
input stream to be strictly sequential, but later ver-
sions of our model will compute simultaneous
events, as well.
According to Habel &amp; Tappe (1999) the func-
tion of the conceptualizer can be subdivided into
the following processes: segmentation &amp; group-
ing, structuring, selection, and linearization. The
first process operates on the (perceptual) input that
is segmented into meaningful basic units (seg-
mentation), and—if possible—two or more of
these units are grouped together to form more
complex entities (grouping). The structuring pro-
cess builds _up multilevel hierarchical structures
from these meaningful basic units.
To exemplify these steps we use the scenario
of monitoring the •:taxiing of an aircraft, viz. the
movements of an aircraft from the terminal to its
assigned runway and vice versa. Air traffic con-
trollers who guide the movements of aircraft on
the ground (surface movement controllers, SMC)
have to rely mainly on visual information—either
looking out of the window of the control tower or
getting information from a airfield control moni-
</bodyText>
<page confidence="0.988166">
86
</page>
<listItem confidence="0.9910765">
• tor—and on communication_with the aircraft
crews. Yet, in some conditions, e.g. in low-
visibility, this method is not failsafe (although re-
liable). It forces the crews to decrease speed—and
such increases number and duration of de-
lays—but it also results in greater safety risks.3 A
supporting system that monitors the occurrences
on the taxiway can mitigate these effects.
</listItem>
<figureCaption confidence="0.998672">
Figure 1. Monitoring the Taxiing of an Aircraft: Phases of a
</figureCaption>
<subsectionHeader confidence="0.83728">
Complex Event
</subsectionHeader>
<bodyText confidence="0.995254581395349">
We will demonstrate the workings of our
model of an incremental conceptualizer, which
produces natural language messages for the SMC,
with the example depicted in Figure 1. The flight
with the number CK-314 shall taxi from the ter-
minal via taxiway Echo to runway 27. The initial
position of the airplane is A. It then starts to move
until it reaches position B right before a junction
where it has to stop and wait until the way is clear
before moving on. It then starts again and contin-
ues (C) but its velocity is too high at point D.
Consequently the plane might not be able to
branch off at the junction, where it is supposed to
turn left into runway 27. At that point the moni-
toring system generates a warning that the plane is
in danger of missing the junction. (If the plane in-
deed misses the junction, an alert is generated, but
our example does not include this.)
For this task two kinds of information have to
be available: the planned movements of the plane
and its actual movements. While the former in-
formation could be handled directly by the con-
ceptualizer because they are inherently discrete,
the latter are information about a continuously
changing world. Here the perpetual continuous in-
put stream has to be transformed into discrete
items. This process consists, on the one hand, of
segmentations into discrete units, e.g. a STOP
3 The reports of incidents and accidents of the Austra-
lian Bureau of Air Safety Investigation is a rich source
of occurrences that should not happen in civil aircraft
operations.
event,-anct on, the ether Jtand of some igroupings.
The movement from position B to position C, for
example, contains—at least—three sub-phases
corresponding to a straight, a curved and a second
straight section of the trajectory. These three
phases can be distinguished by segmentation, but
are combined by a grouping. Furthermore, the
structuring process has to build up the different
phases to form the TAXI event, cf. Figure 3.
The.- third ,ofAhe .:above=mentioned sub-
processes, selection, has two functions: first, it
detects that there is a conflict or a (possibly)
safety-critical development or situation and de-
cides that a warning has to be generated. Second,
it selects the required information for a suitable
warning or alert. Since the verbal warning can be
given on different levels of detail, it is necessary
to select appropriate events from the event hierar-
chy for further verbalization. On the one hand, it
would not be adequate to produce a general
warning like &amp;quot;Taxiing problem&amp;quot;—except perhaps
when there is not enough time or no more infor-
mation available at that moment—on the other
hand, it would not be suitable to give an in-depth
description of each part of the taxiing. Finally, the
selected items are brought into an appropriate or-
der by the forth process, linearization.
Before we describe the internal structure of the
conceptualizer in section 3, we want to discuss the
core idea of &apos;event conceptualization&apos; in more
detail. The first question to be answered is how a
continuous (perceptual) input stream can be seg-
mented into separate events. According to the cut
hypothesis of Avrahami and Kareev (1994, p.
239), &amp;quot;A sub-sequence of stimuli is cut out of a
sequence to become a cognitive entity if it has
been experienced many times in different con-
texts.&amp;quot; This segmentation takes place in the &apos;eye
of the observer&apos;. Hence, event conceptualization
partly depends on individual as well as on con-
textual factors.
The idea of the cut hypothesis implies the ex-
istence of basic events, which are the building
blocks in our experience used to trigger segmen-
tation. They are minimal conceptual entities hu-
man observers ascribe a beginning and an end to.
Thus, they are perceptual wholes—although they
may have an internal structure—, and are there-
fore the basis for the interface between perception
and cognition. Basic events can be grouped to-
gether to form complex events, e.g. assuming that
the four basic events GRIP THE HANDLE OF A
WINDOW, TURNING THE HANDLE, PULL, and LET
GO THE HANDLE are perceived, the complex event
</bodyText>
<figure confidence="0.7895258">
I I I L—
C)* 4-13
—1+1B
27—
Echo
</figure>
<page confidence="0.990769">
87
</page>
<bodyText confidence="0.9990855">
OPENING A WfNDOW can be built .up. Furthermore,
subsequent events of opening all windows of a
room can be grouped to AIRING. But events can
not only be grouped but also segmented: if the
event OPENING A WINDOW is perceived, it can be
segmented into the respective sub-events. We as-
sume that hierarchical event structures, which are
based on knowledge about the internal structure of
prototypical events, e.g. in the format of scripts
_sSchank &amp; Abelson (1977)re. _the representational
backbone of event conceptualization, cf. Habel &amp;
Tappe (1999).
</bodyText>
<sectionHeader confidence="0.962241" genericHeader="method">
3 An Incremental Conceptualizer
</sectionHeader>
<bodyText confidence="0.999909416666667">
Incremental processing is the &apos;piecemeal&apos; and par-
allel processing of a sequential information
stream. It is a specific kind of parallel processing
in that the processes have a fixed order, which De
Smedt &amp; Kempen (1987) describe as a &apos;cascade of
processes&apos;, in analogy to a water cascade. This
metaphor means that, for example, the grammati-
cal encoding—including lexical access—of an
utterance segment cannot take place until the in-
formation &apos;splashes down&apos; from the conceptual
encoding process. Figure 2 sketches such a cas-
cade of dependent parallel processes in our model
of the conceptualizer: The cascade consists of the
processes construction, selection, linearization,
and pvm-generation (preverbal-message-genera-
tion). These processes also constitute a pipeline in
Reiter&apos;s (1994) sense, but they do work in parallel.
One central parameter of incremental process-
ing, which is highly relevant for the format of pre-
verbal messages, is the size of the increments.
Assume that a description (no warning this time)
of the turning of the flight number CK-314 into
taxiway Echo shall be given. This could be done
by a proposition like turn(ck314, goal(tw-echo)),
which is a potential increment for a preverbal
message. Yet, such a proposition would have to be
built up completely, before the subsequent com-
ponents can begin forming it into a sentence like
&apos;Flight CK 314 turns into taxiway Echo.&apos; Hence
the formulator could. not start processing the first
element, say turn, as soon as it is received from
the conceptualizer. In contrast to this, we opt for
an architecture, in which the selection of appropri-
ate lemmas from the lexicon can start for parts of
a preverbal message, before other entities are built
up on the preverbal message level.
As a consequence, the dynamics in incremental
processing demands a modified notion of prever-
bal messages. We conceive of them no longer as
,comp I ete,propositions,as - is ,mostly ;the case In
approaches combining Levelt&apos;s ideas with con-
ceptual semantics—but as sequences of well-
formed propositional structures-on a-sub-proposi-
tional level; in logical terminology: predicate
symbols, functional expressions, terms, etc. The
incremental formulator SYNPHON1CS, which takes
specific .well-formed parts of propositions as in-
put, follows these principles (Abb et al. 1996).
</bodyText>
<figure confidence="0.855485">
ipasic EntlieS
Construction
</figure>
<figureCaption confidence="0.999973">
Figure 2. Model of an Incremental Conceptualizer
</figureCaption>
<subsectionHeader confidence="0.999266">
3.1 Coarse Architecture
</subsectionHeader>
<bodyText confidence="0.999866642857143">
In short, our conceptualizer performs the task
&apos;Give warnings about (possibly) safety-critical
developments and situations!&apos; It operates on two
different input streams: a discrete one, which
contains the plans for the movements of the air-
craft on the ground, and a continuous one, which
originates in the sensors distributed over the taxi-
way. Since the conceptualizer cannot directly op-
erate on the continuous input stream, these input
information must be converted into a stream of
discrete basic entities, which are basic events in
this case. In our example a basic event is induced
by sensoric data sent to the monitoring system,
e.g. that a particular aircraft passes its position.
Since the other input stream is already discrete, it
simply has to be adapted to the required input
format of the conceptualizer, i.e. it has to be con-
verted into basic events, as well. We will neglect
this process and concentrate on the continuous in-
put stream.
Based-on Habel &amp;-Tappe11999) we propose a
model of the conceptualizer as depicted in Fig-
ure 2. It consists mainly of four incremental (cas-
caded) processes that work on the blackboard-like
current conceptual structure (CCR). At first sight,
the use of a data structure, to which more than one
process has access, seems to collide with the no-
tion of a cascaded information stream. These
</bodyText>
<figure confidence="0.997532055555555">
Search
— • • — • •
Change in
• Concept
Traverse
! Lexicon i
Linearization
I Reorder PVM-Generation
CCR &apos; Preverbal Messages
—•• Access to 1. Element cl
Traverse
Change
in CCR
Add
Selection
Request/
Match
Concept Matcher
</figure>
<page confidence="0.993887">
88
</page>
<bodyText confidence="0.997751431372549">
processes are interdependent in .such .a way, how-
ever, that they indeed behave incrementally; e.g.
the selection process cannot select anything that
has not been inserted into the CCR (constructed).
The CCR can be seen as a shared memory unit
with a common data structure. A third kind of in-
formation is needed for a representation of the
state of affairs: the constellation of the terminals,
taxiways, runways, and the participating object(s),
or, more generally: the spatialarrangement ,of the
world and information about objects in it. For ex-
ample, there is one node that stands for flight CK-
314, and all the nodes shown in Figure 3 are
linked to it via an actor relation. Since this type of
information is not in the focus of the present pa-
per, we will not discuss it the following.
In addition to the cascaded processes there is a
concept lexicon, accessible via a concept matcher:
these modules, which are called by the construc-
tion process, find best matches for structures that
can either be subsumed by a more complex con-
cept or may represent still incomplete concepts.
The first is necessary to build up hierarchical
structures at all. The second is needed for the gen-
eration of expectations about developments in the
near future. When, for example, flight CK-314 is
at position D, the expectation is generated that it
will go on straight at the next junction or that it
will be unable to turn left at the next junction
when keeping the current velocity.4 On the other
hand, after the two nodes START1 and cHPos,
(Figure 3) are constructed, these are given to the
concept matcher for a subsumption test, which
consists of trying to match the nodes onto more
complex concepts. This yields that they can be
joined together to a MOVE node (movE1). Thus, it
informs the construction process that a STOP event
(sioPi) will probably occur in the near future,
which illustrates the second function of the
matcher: the generation of expectations. (Even the
last MOVE of a sequence of MOVE events contains
a STOP event, because aircraft stop at the begin-
ning of the runway, which is the last event of the
taxiing, before they commence the takeoff.) The
construction process inserts these two new nodes
together with the information that the STOP, node
is just a hypothesis up to now, nothing actually
perceived.
The four cascaded processes that constitute the
&apos;heart&apos; of the conceptualizer and that will be de-
scribed in more detail in the following sections
</bodyText>
<listItem confidence="0.636057285714286">
4 The computation of the velocity is easily done from
the sensoric data.
are:
(1) construction
(2) selection
(3) linearization
(4) pvm-generation
</listItem>
<bodyText confidence="0.935102166666667">
The first process comprises the processes seg-
mentation &amp; grouping as well as structuring of
Habel &amp; Tappe (1999), apart from the segmenta-
tions that are already done in the pre-processing
step. The selectiorrandihe linearization processes
correlate to the ones in Habel &amp; Tappe (1999),
thus, the first selects nodes for verbalizations,
while the second brings them into an appropriate
order. The pvm-generation is an additional proc-
ess and guarantees that the selection as well as the
linearization have some time to change (the order
of) the selected nodes, before they are passed on
to the formulator. We call this time span the la-
tency time.
For the implementation of this architecture and
(a first version of) the algorithms we use a for-
malism called referential nets (Habel, 1986),
which was developed to represent linguistic as
well as common sense knowledge. Entities are
represented by referential objects (refOs), which
can be connected via relations, so that a network
structure arises. The basic entities the pre-proces-
sing component produces already contain some in-
formation about what attributes (e.g. which sort)
have to be ascribed to a ref0. In the following we
use symbolic constants to refer to refOs. These are
just arbitrary labels; the important point is that the
refOs can be related to suitable refOs of subse-
quent processes, which, for example, stand for
lexical items.
</bodyText>
<subsectionHeader confidence="0.999094">
3.2 Construction
</subsectionHeader>
<bodyText confidence="0.999128882352941">
The construction process takes basic entities as
input and builds up a hierarchical knowledge rep-
resentation of the perceived states of affairs in the
CCR. In the domain we discuss here, three rela-
tions are especially relevant for the representation
of events: (temporal) inclusion (g), temporal
precedence (-&lt;), and the match of planned events
onto actual events (u). For the example described
above the sub-net of the.referential :net that con-
tains the actual events (the ones that have sort A-
Event) is depicted in Figure 3 (the velocity prob-
lem is just detected). MOVE2, for example, is tem-
porally included in the event TAXI (MOVE) g_
TAXI), the event MOVE, is the temporal predeces-
sor of MOVE-) (MOVE! -&lt; MOVED), a matching be-
tween a planned and an actual event is 1.(N/IOVEI,
MOVE,1), where MOVEH stands for the planned
</bodyText>
<page confidence="0.997307">
89
</page>
<figure confidence="0.993346">
TAXI
MOVE
g.
START!.
</figure>
<figureCaption confidence="0.999461">
Figure 3.
</figureCaption>
<bodyText confidence="0.997821586206897">
movement from position A to B.
MOVE is a label for complex events that con-
sists of maximally three sub-events, namely
START, CHPOS (CHANGE OF POSITION), and STOP,
where the first and the last sub-event are optional
and the middle event can be any kind of move-
ment along a trajectory. START, CHPOS, and STOP
nodes contain the sensor data nodes S. Temporal
inclusion relates also TAXI and the basic events
and MOVE and basic events, but are left out in the
figure to keep it readable. The precedence rela-
tion, though, exists explicitly only between nodes
of the same granularity, i.e. between the basic
events and between the nodes of each intermediate
level, e.g. CHPosi -&lt; STOP&apos; START2; the implicit
precedences have to be derived from these. The n
relation is not included in Figure 3. We use four
sorts to subdivide the CCR into four sub-nets,
each consisting of refOs of one sort: planned event
(P-Event), actual event (A-Event), problem
(Problem), and real-world object (R-Object).
The construction process, which builds up the
representation of the actually registered events and
to detect problems, can be realized by the follow-
ing algorithm
I. Generate a new node for the basic entity that is pro-
vided by the pre-processing unit. Link it to other
nodes according to the information (i.e., attributes)
coming with the basic entity.
</bodyText>
<listItem confidence="0.787848789473684">
2. Take the new node, possibly with related nodes—
especially those that stand in the p. relation to this
one—and hand them over to the concept matcher to
find the best matching complex concept that con-
tains these nodes—if there is any—and to find (pos-
sible) problems.
3. In case there is a problem, create a new node for it,
and link it to the involved nodes. Continue with step
2. (In step 2 the &apos;new&apos; node is the &apos;old&apos; one, not the
problem node!) In case of a complex concept, create
a new node for it, together with the simpler nodes
that are still lacking (generation of expectations),
and link it to the basic nodes it subsumes.
4. Try to find relations to other complex nodes with
which links can be established.
5. Continue with step 2 to try to find more complex
concepts and problems, until the next new basic en-
tity enters the system or until there are no more
complex concepts. Then proceed with step I.
</listItem>
<bodyText confidence="0.841932827586207">
In the following application of this algorithm to
the example, the 1.1 relation is left out until the
problem is identified. Up to that point, each node,
except for the S nodes, has a corresponding one in
the sub-structure of planned events, related by it
a. Si is read by the construction process as a basic
event and inserted into the (up to now empty)
knowledge representation. (step 1)
b. This node is handed over to the concept matcher
(there are no related nodes, yet), which responds
that this is a START event. (2)
C. STARTI is generated and linked via g to s1. (3)
d. Steps 4 and 5 yield no results.
e. S2, the next basic event, is inserted. A -&lt; relation
between the two s nodes is established. (I)
f. Because of their temporal vicinity the two s nodes
are taken and given to the concept matcher, which
computes a cHPos event. (2)
cHPos, is generated and linked via g to s2. (3) (It
would equally be possible to take S2 and Si to be
parts of cHPosi. The only reason we chose this pos-
sibility is that it preserves the tree structure—at
least for the moment.)
h. START! and cHPos, are linked by (4)
I. Now START&apos; and cuPos, are given to the concept
matcher, which joins them together in a complex
event MOVE (5, 2).
mOVEI and the &apos;expectation&apos; node STOP&apos; are gener-
ated and MOVE1 is linked via g to its elements (3).
</bodyText>
<listItem confidence="0.7716697">
k. Step 4 yields no result.
I. mOvEi is just part of a more complex event TAXI.
(5,2)
m. TAXI is inserted and linked via g to movEl. (3)
n. Node s3 is read and subsumed to cHPOS1. In this
step the attributes of CHPOS, are updated. (Espe-
cially interesting for our example: the velocity at-
tribute.)
o. Nodes sa to s 7 are integrated and subsumed to
CHPOS 1.
</listItem>
<table confidence="0.490536">
The Knowledge Representation for the Example (sToP2 is only expected)
</table>
<page confidence="0.97148">
90
</page>
<bodyText confidence="0.660477529411765">
p. s8 is read and subsumed to STOP!, -which ris now -
_
changed from an &apos;expectation&apos; node to a &apos;normal&apos;
one. STOP1 comprises the span of time, where flight
number CK-314 is waiting at position B.
q. Nodes s9 and s10 are integrated and subsumed to
STOP&apos;.
r. Nodes SI, to S17 are read in and the START2, CHPOS2,
and movE2 are built up analogously.
s. s18 is read in, inserted, and the velocity attribute of
cHP0s2 is updated while it is linked to cHP0s2. (1)
t. cHPOS2 together withAls,correspowling-planned,
node is given to the concept matcher, which detects
the too high velocity. (2)
u. Problem node PROBLEMv is created. (3)
The rest of the representation is built up analo-
gously.
</bodyText>
<subsectionHeader confidence="0.99681">
3.3 Selection
</subsectionHeader>
<bodyText confidence="0.97889427027027">
The selection process chooses the nodes that will
be verbalized. In the exemplifying domain, only
nodes of the sort Problem are selected for verbali-
zation. These are linked together to form a (par-
tial) path—the traverse—through the network. We
use the notion traverse in two readings: (i) it de-
notes the resulting path, i.e. the concatenation of
all nodes that are actually chosen and verbalized;
(ii) it means the current traverse that contains a
limited number of selected elements that are not
yet taken by the pvm-generation at a given point
of time. Elements that are contained in the current
traverse may be removed and are not contained in
the resulting traverse anymore.5
The selection strategy for the purpose at hand
takes new nodes that are of sort Problem and con-
siders them for insertion into the traverse. The se-
lection process can manipulate the traverse by
means of two operations: appending and replacing
elements. While the first one is more fundamental,
the second especially serves the purpose to sub-
stitute already chosen nodes by better candidates.
Consider a situation in which CK-3I4 is taxiing
too fast (PROBLEM, / velocity too high). Because
of this critical velocity, it also comes too close to a
second aircraft (MG-209); an additional problem
node is constructed (PROBLEMc / aircraft too
close). If the selection process simply chose both
nodes, it would lead to an unclear, redundant, and
cognitively more &apos;complex warning. Thus, if
PROBLEMc is recognized first, but the selection
5 The limited capacity of the current traverse can be
varied for simulations of cognitive behavior with dif-
ferent processing (memory) capacities, leading to dif-
ferent verbalizations. But, for a application oriented
monitoring system, a limitation of the size is undesir-
able as all identified problems should be reported.
</bodyText>
<listItem confidence="0.86798725">
• - - -process AeterminesvPROBLEM, to be-more-urgent
and, additionally, to be essentially the same as
PROBLEM0 the best solution is to generate only
one warning based on PROBLEMv.
</listItem>
<subsectionHeader confidence="0.960284">
3.4 Linearization
</subsectionHeader>
<bodyText confidence="0.999321777777778">
The linearization process has the function of
bringing the selected nodes into an appropriate or-
der. For a general application of a psycholinguistic
ightbel,requiredJor :example; ,to: move -
the more prominent (more informative) item to the
beginning of the sentence and, therefore, to reor-
der the events. In our architecture for monitoring
systems the linearization process is the means for
pushing the most urgent problems to the begin-
ning of the traverse.
In general it is even very probable that chang-
ing the order of selected nodes is necessary more
often than keeping the (randomly) arising one.
This is so, because the sequence of information is
a crucial factor for any speech producing system
to be easily understandable, e.g. it can be essential
to follow the principle &apos;Known information first,
unknown last&apos;.
</bodyText>
<subsectionHeader confidence="0.979702">
3.5 PVM-Generation
</subsectionHeader>
<bodyText confidence="0.999970071428572">
The pvm-generation observes the traverse and
generates preverbal messages from the selected
nodes. There is a latency time between the time
when a node is selected and the moment when the
pvm-generation uses it as preverbal message.
The latency time can be either fixed or vari-
able. The model would be easier with a fixed time
interval, but since we also want to be able to
simulate differing processing loads and differing
time pressure in cognitive systems we favor the
variable variant. Consider, for example, that the
selection process chooses so many nodes that the
traverse is in danger of reaching its maximal
length or, even worse, that selected elements are
lost, because more elements than possible would
need to be stored. An obvious solution would be
to change the selection strategy in such a way that
more complex nodes are selected. But due to other
restraining factors this will not always be possible,
e.g. a certain level of_detail might be required, and
so preverbal messages will be generated with a
higher frequency by reducing the latency time.
This has the effect that all selected nodes are ver-
balized. On the other hand, increasing the latency
time can be a suitable measure against the pro-
duction of too many utterances that are corrections
of previous utterances. Such corrections arise
when the selection process is unable to make nec-
</bodyText>
<page confidence="0.996033">
91
</page>
<bodyText confidence="0.999472774193549">
essary changes (replacements) in the ,traverse, be-
cause the pvm-generation already took the ele-
ments that would otherwise have been replaced.
After the latency time of a node is elapsed the
pvm-generation passes it on to the subsequent
process of the formulator. This means—as we ar-
gued above—that propositions exist only &apos;piece-
wise&apos;. Complete propositions exist, then, on a
higher level of abstraction. When the PROBLEM,
node is selected.as a,isitraterbaLinessageoinforma-
tion about what is the problematic event (moving
too fast), the object involved (the aircraft with the
flight number CK-314) and about the location of
the movement (taxiway Echo) have to be con-
veyed. This is done by handing on not only the
PROBLEM, node but also further nodes that contain
information about the event (in the CHP0S2 node),
the flight (in a FLIGHT node), and about the loca-
tion (in a TW-ECHO node). Thus, the pvm-
generation considers some important relations to
other nodes before the PROBLEM, node is passed
on, and checks what other nodes are needed for
the verbalization and passes them on, as well.
The formulator can establish interrelations
between the refOs by the ascribed relations, e.g.
the PROBLEM, node contains an actor relation to
the FLIGHT node, which enables the formulator to
look up all necessary information at the relevant
nodes. Taken together they are now equivalent to
a proposition like problem(ck-314, veloc-
ity(tooHigh), tw-Echo, goal(rw27).
</bodyText>
<sectionHeader confidence="0.99849" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999243">
We presented a psycholinguistically motivated ar-
chitecture of an incremental conceptualizer to-
gether with some remarks on its prototypical
implementation and how this implementation can
be used for monitoring purposes. The conceptual-
izer watches dynamic changes in the world and
generates on-line propositional, preverbal struc-
tures that can serve as input to a subsequent com-
ponent, which encodes these structures linguisti-
cally.
</bodyText>
<sectionHeader confidence="0.998999" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999871605633803">
Abb, B.; G(inther, C.; Herweg, M.; Lebeth, K:; Maien-
born, M. &amp; Schopp, A. (1996) Incremental gram-
matical encoding—an outline of the SYNPHONICS
formulator. In G. Adorni &amp; M. Zock, eds., Trends in
natural language generation: An artificial intelli-
gence perspective, 277-299, Berlin: Springer.
André, E.; Herzog, G. &amp; Rist, T. (1988) On the simul-
taneous interpretation of real world image sequences
and their natural language description: The system
SOCCER, 449-454. Proc. of the 8th.ECAI, Munich.
Australian Bureau of Air Safety Investigation.
http://www.basi.gov.au
Avrahami, J. &amp; Kareev, Y. (1994) The emergence of
events. Cognition, 53, 239-261.
Baddeley, A. (1986) Working Memory. Oxford: Oxford
University Press.
Cahill, L.; Doran, Ch.; Evans, R.; Mellish, Ch.; Pava,
D.; Reape, M.; Scott, D. &amp; Tipper, N. (1999) In
search of a reference architecture- for NLG systems.
EWNLG-I999, Toulouse.
-elawCarro.14K-.&amp;.Carberry. 4.-S-41998) Collaborative •-re-
sponse generation in planning dialogues. Computa-
tional Linguistics, 24, 355-400.
De Smedt, K.; Horacek, H. &amp; Zock, M. (1996) Archi-
tectures for natural language generation: Problems
and perspectives. In G. Adorni &amp; M. Zock, eds.,
Trends in natural language generation, Berlin:
Springer.
De Smedt, K. &amp; Kempen, G. (1987) Incremental sen-
tence production: Self-correction and coordination.
In G. Kempen, ed., Natural language generation,
365-76, Boston: Martinus Nijhoff.
Ferreira, F. (1996) Is it better to give than donate?
Syntactic flexibility in language production. Journal
of Memory and Language, 35, 724-755.
Habel, Ch. (1986) Prinzipien der Referentialitat: Un-
tersuchungen zur propositionalen Repreisentation
von Wissen. Berlin: Springer.
Habel, Ch. &amp; Tappe, H. (1999) Processes of segmenta-
tion and linearization in describing events. In R. Kla-
bunde &amp; C. von Stutterheim, eds., Representations
and Processes in Language Production, 117-153,
Wiesbaden: Deutscher Universitats-Verlag.
Hovy, E. H. (1993) Automated discourse generation
using discourse structure relations. Artificial Intelli-
gence, 63,341-385.
Levelt, W.J.M. (1989) Speaking: From intention to ar-
ticulation. Cambridge, MA: MIT Press.
Marcu, D. (1997) From local to global coherence: A
bottom-up approach to text planning. Proc. AAAI 97,
629-635.
McKeown, K. (1985) Text generation. Cambridge:
Cambridge University Press.
Neumann, B. &amp; Novak, H. -J. (1983). Event models for
recognition and natural language. IJCAI-83, 724-726.
Radev, D. R. &amp; McKeown, K. (1998) Generating natu-
ral language summaries from multiple on-line
sources. Computational Linguistics, 24,469-500.
Reiter E. (1994) Has a consensus NL generation archi-
tecture appeared, and is it psycholinguistically plau-
sible? IWNLG-1994,163-170,Kennebunkport, ME.
Reithinger, N. (1992) The Performance of an incre-
mental generation component for multi-modal dialog
contributions. In: R. Dale, E. Hovy, D. Rosner &amp; 0.
Stook, eds., Aspects -of automated natural- language
generation, 263-276, Berlin: Springer.
Schank, R. C. &amp; Abelson, R. P. (1977) Scripts, plans,
goals and understanding: An inquiry into human
knowledge structures. Hillsdale: Lawrence Erlbaum.
Zacks, J. (1997) Seeing the structure in events. Manu-
script, Stanford University.
</reference>
<page confidence="0.996032">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.497063">
<title confidence="0.9973145">Incremental -EventConceptualization and Natural Language Generation in Monitoring Environments</title>
<author confidence="0.99849">Markus GUHE</author>
<author confidence="0.99849">Christopher HABEL</author>
<author confidence="0.99849">Heike</author>
<affiliation confidence="0.869177">Research Group Knowledge and Language Processing Department of Informatics, University of Vogt-Kolln-StraBe</affiliation>
<address confidence="0.666888">22527.Hainburg, _Germany,</address>
<email confidence="0.8967">guhe@informatik.uni-hamburg.de</email>
<email confidence="0.8967">habel@informatik.uni-hamburg.de</email>
<email confidence="0.8967">tappe@informatik.uni-hamburg.de</email>
<abstract confidence="0.998712176470588">In this paper we present a psycholinguistically motivated architecture and its prototypical implementation for an incremental conceptualizer, which monitors dynamic changes in the world and simultaneously generates warnings for (possibly) safety-critical developments. It does so by conceptualizing events and building up a hierarchical knowledge representation of the perceived states of affairs. If it detects a safety problem, it selects suitable elements from the representation for a warning, brings them into an appropriate order, and generates incremental preverbal messages (propositional structures) from them, which can be taken by a subsequent component to encode them linguistically.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Incremental grammatical encoding—an outline of the SYNPHONICS formulator.</title>
<date>1996</date>
<booktitle>Trends in natural language generation: An artificial intelligence perspective,</booktitle>
<pages>277--299</pages>
<editor>Abb, B.; G(inther, C.; Herweg, M.; Lebeth, K:; Maienborn, M. &amp; Schopp, A.</editor>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<contexts>
<context position="2371" citStr="(1996)" startWordPosition="339" endWordPosition="339">neering approaches often result in systems, which are similar in crucial respects. In this paper we ground on two of these common aspects, namely the distinction between what-to-say and how-tosay (De Smedt, Horacek &amp; Zock, 1996) and the use of a pipeline architecture, which divides the generation process &amp;quot;into multiple modules, with information flowing in a &apos;pipeline&apos; fashion from one module to the next&amp;quot; (Reiter, 1994). Reiter states that these architectures do not require modules to work in parallel; if parallelism is used one has an incremental model, cf. De Smedt &amp; Kernpen (1987), Ferreira (1996). The primary research topic of the ConeEvi project is the what-to-say component, in which the content of utterances is planned (Reiter&apos;s content planning, in contrast to the language specific sentence planning component). We use the terminology of Levelt (1989), who calls the first component the conceptualizer, the second the formulator. These modules interact via preverbal messages, which are propositional, non-verbal representations of the utterance built up by the conceptualizer. They are transformed by the formulator into linguistic structures for spoken or written output. Besides conside</context>
</contexts>
<marker>1996</marker>
<rawString>Abb, B.; G(inther, C.; Herweg, M.; Lebeth, K:; Maienborn, M. &amp; Schopp, A. (1996) Incremental grammatical encoding—an outline of the SYNPHONICS formulator. In G. Adorni &amp; M. Zock, eds., Trends in natural language generation: An artificial intelligence perspective, 277-299, Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E André</author>
<author>G Herzog</author>
<author>T Rist</author>
</authors>
<title>On the simultaneous interpretation of real world image sequences and their natural language description:</title>
<date>1988</date>
<booktitle>The system SOCCER, 449-454. Proc. of the 8th.ECAI, Munich. Australian Bureau of Air Safety Investigation. http://www.basi.gov.au</booktitle>
<marker>André, Herzog, Rist, 1988</marker>
<rawString>André, E.; Herzog, G. &amp; Rist, T. (1988) On the simultaneous interpretation of real world image sequences and their natural language description: The system SOCCER, 449-454. Proc. of the 8th.ECAI, Munich. Australian Bureau of Air Safety Investigation. http://www.basi.gov.au</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Avrahami</author>
<author>Y Kareev</author>
</authors>
<title>The emergence of events.</title>
<date>1994</date>
<journal>Cognition,</journal>
<volume>53</volume>
<pages>239--261</pages>
<contexts>
<context position="12591" citStr="Avrahami and Kareev (1994" startWordPosition="1948" endWordPosition="1951">aps when there is not enough time or no more information available at that moment—on the other hand, it would not be suitable to give an in-depth description of each part of the taxiing. Finally, the selected items are brought into an appropriate order by the forth process, linearization. Before we describe the internal structure of the conceptualizer in section 3, we want to discuss the core idea of &apos;event conceptualization&apos; in more detail. The first question to be answered is how a continuous (perceptual) input stream can be segmented into separate events. According to the cut hypothesis of Avrahami and Kareev (1994, p. 239), &amp;quot;A sub-sequence of stimuli is cut out of a sequence to become a cognitive entity if it has been experienced many times in different contexts.&amp;quot; This segmentation takes place in the &apos;eye of the observer&apos;. Hence, event conceptualization partly depends on individual as well as on contextual factors. The idea of the cut hypothesis implies the existence of basic events, which are the building blocks in our experience used to trigger segmentation. They are minimal conceptual entities human observers ascribe a beginning and an end to. Thus, they are perceptual wholes—although they may have </context>
<context position="7111" citStr="Avrahami &amp; Kareev, 1994" startWordPosition="1056" endWordPosition="1060">ely the phonological loop, which is less strained. _insights into _psycholinguistic. aspects of natural language processing. Our implementation thus simulates aspects of behavior, e.g. the effects differing time pressure has on verbalizations. 2 Conceptualizing Events If the system has to produce descriptions about what it &apos;sees&apos;, the main conceptual task is building up conceptual entities representing spatio-temporal- constellations -of the -external world, i.e. event conceptualization. Events emerge from dynamic input data, which are segmented by the conceptual system into meaningful units (Avrahami &amp; Kareev, 1994). They are therefore internal representations rather than external entities: &amp;quot;[...] events arise in the perception of observers&amp;quot; (Zacks, 1997). Consequently, a language production system designed for verbalizing what the system perceives has to deal with information stemming from multiple modalities, e.g. auditory and spatial. In particular, a continuous multimodal &apos;perceptual stream&apos; has to be translated into discrete propositional output (preverbal messages) that can be encoded linguistically, cf. Levelt (1989). To meet such demands, three subtasks have to be solved: (1) The input stream has</context>
</contexts>
<marker>Avrahami, Kareev, 1994</marker>
<rawString>Avrahami, J. &amp; Kareev, Y. (1994) The emergence of events. Cognition, 53, 239-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Baddeley</author>
</authors>
<title>Working Memory.</title>
<date>1986</date>
<publisher>University Press.</publisher>
<location>Oxford: Oxford</location>
<contexts>
<context position="6217" citStr="Baddeley, 1986" startWordPosition="931" endWordPosition="932">l situations can be anticipated earlier and much more reliably. Conventional systems, in contrast, just compare actual measurements with allowed values and give a warning or an alarm when a violation occurs. But it is more useful, e.g. for a nurse if the system tells her that a patient&apos;s blood pressure is rapidly dropping than that his blood pressure is already dangerously low. We see the proposed implementation of an incremental conceptualizer also as a means to gain 2 The multimodal monitoring environment proposed here reflects the division of labor between the components in working memory (Baddeley, 1986), especially between the visuospatial sketchpad (VSSP) and the phonological loop. Since the observation of multiple display units puts a heavy strain on the VSSP, spoken natural language as input of critical information would use that subcomponent of working memory, namely the phonological loop, which is less strained. _insights into _psycholinguistic. aspects of natural language processing. Our implementation thus simulates aspects of behavior, e.g. the effects differing time pressure has on verbalizations. 2 Conceptualizing Events If the system has to produce descriptions about what it &apos;sees</context>
</contexts>
<marker>Baddeley, 1986</marker>
<rawString>Baddeley, A. (1986) Working Memory. Oxford: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Cahill</author>
<author>Ch Doran</author>
<author>R Evans</author>
<author>Ch Mellish</author>
<author>D Pava</author>
<author>M Reape</author>
<author>D Scott</author>
<author>N Tipper</author>
</authors>
<title>In search of a reference architecture- for NLG systems. EWNLG-I999,</title>
<date>1999</date>
<location>Toulouse.</location>
<contexts>
<context position="3693" citStr="Cahill et al., 1999" startWordPosition="534" endWordPosition="537">oaches to the what-to-say component, e.g. De Smedt &amp; Kempen (1987), McKeown (1985), Hovy (1993), Chu-Carroll &amp; Carberry (1998), Radev &amp; McKeown (1998), the type of information to be verbalized also determines the processes of conceptualization on the level of microplanning, cf. Levelt (1989). Thus, the traditional top-down approaches have to be combined with bottom-up data-driven approaches of text planning (Marcu, 1997). The conceptualizer that is described in detail in section 3 fits the pipeline architecture on a coarse level, but integrates on finer levels the ideas of functional modules (Cahill et al., 1999). In the present paper we focus on the task of I ConcEv (Conceptualizing Events) is supported by the DFG (German Science Foundation) in the priority program &apos;Language Production&apos; under grant Ha-1237/10 to Christopher Habel. 85 generating verbal descriptions of continuously incoming input from a changing physical world (see section 2, for similar settings cf. Neumann &amp; Novak (1983) and André, Herzog &amp; Rist (1988)). This specific task requires an incremental pipeline architecture—as there are certain steps that have to be carried out in a specific order—and, additionally, these steps can be orga</context>
</contexts>
<marker>Cahill, Doran, Evans, Mellish, Pava, Reape, Scott, Tipper, 1999</marker>
<rawString>Cahill, L.; Doran, Ch.; Evans, R.; Mellish, Ch.; Pava, D.; Reape, M.; Scott, D. &amp; Tipper, N. (1999) In search of a reference architecture- for NLG systems. EWNLG-I999, Toulouse.</rawString>
</citation>
<citation valid="false">
<title>elawCarro.14K-.&amp;.Carberry. 4.-S-41998) Collaborative •-response generation in planning dialogues.</title>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<pages>355--400</pages>
<marker></marker>
<rawString>-elawCarro.14K-.&amp;.Carberry. 4.-S-41998) Collaborative •-response generation in planning dialogues. Computational Linguistics, 24, 355-400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K De Smedt</author>
<author>H Horacek</author>
<author>M Zock</author>
</authors>
<title>Architectures for natural language generation: Problems and perspectives.</title>
<date>1996</date>
<booktitle>Trends in natural language generation,</booktitle>
<editor>In G. Adorni &amp; M. Zock, eds.,</editor>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<marker>De Smedt, Horacek, Zock, 1996</marker>
<rawString>De Smedt, K.; Horacek, H. &amp; Zock, M. (1996) Architectures for natural language generation: Problems and perspectives. In G. Adorni &amp; M. Zock, eds., Trends in natural language generation, Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K De Smedt</author>
<author>G Kempen</author>
</authors>
<title>Incremental sentence production: Self-correction and coordination.</title>
<date>1987</date>
<booktitle>Natural language generation,</booktitle>
<pages>365--76</pages>
<editor>In G. Kempen, ed.,</editor>
<location>Boston: Martinus Nijhoff.</location>
<marker>De Smedt, Kempen, 1987</marker>
<rawString>De Smedt, K. &amp; Kempen, G. (1987) Incremental sentence production: Self-correction and coordination. In G. Kempen, ed., Natural language generation, 365-76, Boston: Martinus Nijhoff.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ferreira</author>
</authors>
<title>Is it better to give than donate? Syntactic flexibility in language production.</title>
<date>1996</date>
<journal>Journal of Memory and Language,</journal>
<volume>35</volume>
<pages>724--755</pages>
<contexts>
<context position="2371" citStr="Ferreira (1996)" startWordPosition="338" endWordPosition="339"> and engineering approaches often result in systems, which are similar in crucial respects. In this paper we ground on two of these common aspects, namely the distinction between what-to-say and how-tosay (De Smedt, Horacek &amp; Zock, 1996) and the use of a pipeline architecture, which divides the generation process &amp;quot;into multiple modules, with information flowing in a &apos;pipeline&apos; fashion from one module to the next&amp;quot; (Reiter, 1994). Reiter states that these architectures do not require modules to work in parallel; if parallelism is used one has an incremental model, cf. De Smedt &amp; Kernpen (1987), Ferreira (1996). The primary research topic of the ConeEvi project is the what-to-say component, in which the content of utterances is planned (Reiter&apos;s content planning, in contrast to the language specific sentence planning component). We use the terminology of Levelt (1989), who calls the first component the conceptualizer, the second the formulator. These modules interact via preverbal messages, which are propositional, non-verbal representations of the utterance built up by the conceptualizer. They are transformed by the formulator into linguistic structures for spoken or written output. Besides conside</context>
</contexts>
<marker>Ferreira, 1996</marker>
<rawString>Ferreira, F. (1996) Is it better to give than donate? Syntactic flexibility in language production. Journal of Memory and Language, 35, 724-755.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ch Habel</author>
</authors>
<title>Prinzipien der Referentialitat: Untersuchungen zur propositionalen Repreisentation von Wissen.</title>
<date>1986</date>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<contexts>
<context position="21487" citStr="Habel, 1986" startWordPosition="3411" endWordPosition="3412">pre-processing step. The selectiorrandihe linearization processes correlate to the ones in Habel &amp; Tappe (1999), thus, the first selects nodes for verbalizations, while the second brings them into an appropriate order. The pvm-generation is an additional process and guarantees that the selection as well as the linearization have some time to change (the order of) the selected nodes, before they are passed on to the formulator. We call this time span the latency time. For the implementation of this architecture and (a first version of) the algorithms we use a formalism called referential nets (Habel, 1986), which was developed to represent linguistic as well as common sense knowledge. Entities are represented by referential objects (refOs), which can be connected via relations, so that a network structure arises. The basic entities the pre-processing component produces already contain some information about what attributes (e.g. which sort) have to be ascribed to a ref0. In the following we use symbolic constants to refer to refOs. These are just arbitrary labels; the important point is that the refOs can be related to suitable refOs of subsequent processes, which, for example, stand for lexica</context>
</contexts>
<marker>Habel, 1986</marker>
<rawString>Habel, Ch. (1986) Prinzipien der Referentialitat: Untersuchungen zur propositionalen Repreisentation von Wissen. Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tappe</author>
</authors>
<title>Processes of segmentation and linearization in describing events. In</title>
<date>1999</date>
<booktitle>Representations and Processes in Language Production,</booktitle>
<pages>117--153</pages>
<editor>R. Klabunde &amp; C. von Stutterheim, eds.,</editor>
<institution>Deutscher Universitats-Verlag.</institution>
<location>Wiesbaden:</location>
<contexts>
<context position="8061" citStr="Tappe (1999)" startWordPosition="1204" endWordPosition="1205">ular, a continuous multimodal &apos;perceptual stream&apos; has to be translated into discrete propositional output (preverbal messages) that can be encoded linguistically, cf. Levelt (1989). To meet such demands, three subtasks have to be solved: (1) The input stream has to be subdivided into &apos;perceptual units&apos;; (2) conceptual representations have to be built up from these &apos;percepts&apos;, which (3) have to be combined to preverbal messages. For the time being, we take the input stream to be strictly sequential, but later versions of our model will compute simultaneous events, as well. According to Habel &amp; Tappe (1999) the function of the conceptualizer can be subdivided into the following processes: segmentation &amp; grouping, structuring, selection, and linearization. The first process operates on the (perceptual) input that is segmented into meaningful basic units (segmentation), and—if possible—two or more of these units are grouped together to form more complex entities (grouping). The structuring process builds _up multilevel hierarchical structures from these meaningful basic units. To exemplify these steps we use the scenario of monitoring the •:taxiing of an aircraft, viz. the movements of an aircraft</context>
<context position="14089" citStr="Tappe (1999)" startWordPosition="2203" endWordPosition="2204"> perceived, the complex event I I I L— C)* 4-13 —1+1B 27— Echo 87 OPENING A WfNDOW can be built .up. Furthermore, subsequent events of opening all windows of a room can be grouped to AIRING. But events can not only be grouped but also segmented: if the event OPENING A WINDOW is perceived, it can be segmented into the respective sub-events. We assume that hierarchical event structures, which are based on knowledge about the internal structure of prototypical events, e.g. in the format of scripts _sSchank &amp; Abelson (1977)re. _the representational backbone of event conceptualization, cf. Habel &amp; Tappe (1999). 3 An Incremental Conceptualizer Incremental processing is the &apos;piecemeal&apos; and parallel processing of a sequential information stream. It is a specific kind of parallel processing in that the processes have a fixed order, which De Smedt &amp; Kempen (1987) describe as a &apos;cascade of processes&apos;, in analogy to a water cascade. This metaphor means that, for example, the grammatical encoding—including lexical access—of an utterance segment cannot take place until the information &apos;splashes down&apos; from the conceptual encoding process. Figure 2 sketches such a cascade of dependent parallel processes in ou</context>
<context position="20815" citStr="Tappe (1999)" startWordPosition="3301" endWordPosition="3302"> taxiing, before they commence the takeoff.) The construction process inserts these two new nodes together with the information that the STOP, node is just a hypothesis up to now, nothing actually perceived. The four cascaded processes that constitute the &apos;heart&apos; of the conceptualizer and that will be described in more detail in the following sections 4 The computation of the velocity is easily done from the sensoric data. are: (1) construction (2) selection (3) linearization (4) pvm-generation The first process comprises the processes segmentation &amp; grouping as well as structuring of Habel &amp; Tappe (1999), apart from the segmentations that are already done in the pre-processing step. The selectiorrandihe linearization processes correlate to the ones in Habel &amp; Tappe (1999), thus, the first selects nodes for verbalizations, while the second brings them into an appropriate order. The pvm-generation is an additional process and guarantees that the selection as well as the linearization have some time to change (the order of) the selected nodes, before they are passed on to the formulator. We call this time span the latency time. For the implementation of this architecture and (a first version of)</context>
</contexts>
<marker>Tappe, 1999</marker>
<rawString>Habel, Ch. &amp; Tappe, H. (1999) Processes of segmentation and linearization in describing events. In R. Klabunde &amp; C. von Stutterheim, eds., Representations and Processes in Language Production, 117-153, Wiesbaden: Deutscher Universitats-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Automated discourse generation using discourse structure relations.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--341</pages>
<contexts>
<context position="3168" citStr="Hovy (1993)" startWordPosition="454" endWordPosition="455">ecific sentence planning component). We use the terminology of Levelt (1989), who calls the first component the conceptualizer, the second the formulator. These modules interact via preverbal messages, which are propositional, non-verbal representations of the utterance built up by the conceptualizer. They are transformed by the formulator into linguistic structures for spoken or written output. Besides considering high level communicative goals (macroplanning), which are in the focus of most computational approaches to the what-to-say component, e.g. De Smedt &amp; Kempen (1987), McKeown (1985), Hovy (1993), Chu-Carroll &amp; Carberry (1998), Radev &amp; McKeown (1998), the type of information to be verbalized also determines the processes of conceptualization on the level of microplanning, cf. Levelt (1989). Thus, the traditional top-down approaches have to be combined with bottom-up data-driven approaches of text planning (Marcu, 1997). The conceptualizer that is described in detail in section 3 fits the pipeline architecture on a coarse level, but integrates on finer levels the ideas of functional modules (Cahill et al., 1999). In the present paper we focus on the task of I ConcEv (Conceptualizing Ev</context>
</contexts>
<marker>Hovy, 1993</marker>
<rawString>Hovy, E. H. (1993) Automated discourse generation using discourse structure relations. Artificial Intelligence, 63,341-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J M Levelt</author>
</authors>
<title>Speaking: From intention to articulation.</title>
<date>1989</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="2633" citStr="Levelt (1989)" startWordPosition="379" endWordPosition="380">architecture, which divides the generation process &amp;quot;into multiple modules, with information flowing in a &apos;pipeline&apos; fashion from one module to the next&amp;quot; (Reiter, 1994). Reiter states that these architectures do not require modules to work in parallel; if parallelism is used one has an incremental model, cf. De Smedt &amp; Kernpen (1987), Ferreira (1996). The primary research topic of the ConeEvi project is the what-to-say component, in which the content of utterances is planned (Reiter&apos;s content planning, in contrast to the language specific sentence planning component). We use the terminology of Levelt (1989), who calls the first component the conceptualizer, the second the formulator. These modules interact via preverbal messages, which are propositional, non-verbal representations of the utterance built up by the conceptualizer. They are transformed by the formulator into linguistic structures for spoken or written output. Besides considering high level communicative goals (macroplanning), which are in the focus of most computational approaches to the what-to-say component, e.g. De Smedt &amp; Kempen (1987), McKeown (1985), Hovy (1993), Chu-Carroll &amp; Carberry (1998), Radev &amp; McKeown (1998), the type</context>
<context position="7629" citStr="Levelt (1989)" startWordPosition="1130" endWordPosition="1131">a, which are segmented by the conceptual system into meaningful units (Avrahami &amp; Kareev, 1994). They are therefore internal representations rather than external entities: &amp;quot;[...] events arise in the perception of observers&amp;quot; (Zacks, 1997). Consequently, a language production system designed for verbalizing what the system perceives has to deal with information stemming from multiple modalities, e.g. auditory and spatial. In particular, a continuous multimodal &apos;perceptual stream&apos; has to be translated into discrete propositional output (preverbal messages) that can be encoded linguistically, cf. Levelt (1989). To meet such demands, three subtasks have to be solved: (1) The input stream has to be subdivided into &apos;perceptual units&apos;; (2) conceptual representations have to be built up from these &apos;percepts&apos;, which (3) have to be combined to preverbal messages. For the time being, we take the input stream to be strictly sequential, but later versions of our model will compute simultaneous events, as well. According to Habel &amp; Tappe (1999) the function of the conceptualizer can be subdivided into the following processes: segmentation &amp; grouping, structuring, selection, and linearization. The first proces</context>
</contexts>
<marker>Levelt, 1989</marker>
<rawString>Levelt, W.J.M. (1989) Speaking: From intention to articulation. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
</authors>
<title>From local to global coherence: A bottom-up approach to text planning.</title>
<date>1997</date>
<booktitle>Proc. AAAI 97,</booktitle>
<pages>629--635</pages>
<contexts>
<context position="3497" citStr="Marcu, 1997" startWordPosition="503" endWordPosition="504">he formulator into linguistic structures for spoken or written output. Besides considering high level communicative goals (macroplanning), which are in the focus of most computational approaches to the what-to-say component, e.g. De Smedt &amp; Kempen (1987), McKeown (1985), Hovy (1993), Chu-Carroll &amp; Carberry (1998), Radev &amp; McKeown (1998), the type of information to be verbalized also determines the processes of conceptualization on the level of microplanning, cf. Levelt (1989). Thus, the traditional top-down approaches have to be combined with bottom-up data-driven approaches of text planning (Marcu, 1997). The conceptualizer that is described in detail in section 3 fits the pipeline architecture on a coarse level, but integrates on finer levels the ideas of functional modules (Cahill et al., 1999). In the present paper we focus on the task of I ConcEv (Conceptualizing Events) is supported by the DFG (German Science Foundation) in the priority program &apos;Language Production&apos; under grant Ha-1237/10 to Christopher Habel. 85 generating verbal descriptions of continuously incoming input from a changing physical world (see section 2, for similar settings cf. Neumann &amp; Novak (1983) and André, Herzog &amp; </context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Marcu, D. (1997) From local to global coherence: A bottom-up approach to text planning. Proc. AAAI 97, 629-635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
</authors>
<title>Text generation. Cambridge:</title>
<date>1985</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3155" citStr="McKeown (1985)" startWordPosition="452" endWordPosition="453"> the language specific sentence planning component). We use the terminology of Levelt (1989), who calls the first component the conceptualizer, the second the formulator. These modules interact via preverbal messages, which are propositional, non-verbal representations of the utterance built up by the conceptualizer. They are transformed by the formulator into linguistic structures for spoken or written output. Besides considering high level communicative goals (macroplanning), which are in the focus of most computational approaches to the what-to-say component, e.g. De Smedt &amp; Kempen (1987), McKeown (1985), Hovy (1993), Chu-Carroll &amp; Carberry (1998), Radev &amp; McKeown (1998), the type of information to be verbalized also determines the processes of conceptualization on the level of microplanning, cf. Levelt (1989). Thus, the traditional top-down approaches have to be combined with bottom-up data-driven approaches of text planning (Marcu, 1997). The conceptualizer that is described in detail in section 3 fits the pipeline architecture on a coarse level, but integrates on finer levels the ideas of functional modules (Cahill et al., 1999). In the present paper we focus on the task of I ConcEv (Conce</context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>McKeown, K. (1985) Text generation. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Neumann</author>
<author>H -J Novak</author>
</authors>
<title>Event models for recognition and natural language.</title>
<date>1983</date>
<pages>83--724</pages>
<contexts>
<context position="4076" citStr="Neumann &amp; Novak (1983)" startWordPosition="594" endWordPosition="598">n approaches of text planning (Marcu, 1997). The conceptualizer that is described in detail in section 3 fits the pipeline architecture on a coarse level, but integrates on finer levels the ideas of functional modules (Cahill et al., 1999). In the present paper we focus on the task of I ConcEv (Conceptualizing Events) is supported by the DFG (German Science Foundation) in the priority program &apos;Language Production&apos; under grant Ha-1237/10 to Christopher Habel. 85 generating verbal descriptions of continuously incoming input from a changing physical world (see section 2, for similar settings cf. Neumann &amp; Novak (1983) and André, Herzog &amp; Rist (1988)). This specific task requires an incremental pipeline architecture—as there are certain steps that have to be carried out in a specific order—and, additionally, these steps can be organized in such a way that a sequence of clear-cut modules arises, which can work in.parallel. Parallel_processing has the advantage that several tasks can be done simultaneously; thus, while utterances are generated for some input, subsequent input can already be taken in and processed. Simultaneous conceptualization can be used as the basis of systems producing verbal messages whe</context>
</contexts>
<marker>Neumann, Novak, 1983</marker>
<rawString>Neumann, B. &amp; Novak, H. -J. (1983). Event models for recognition and natural language. IJCAI-83, 724-726.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Radev</author>
<author>K McKeown</author>
</authors>
<title>Generating natural language summaries from multiple on-line sources.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--469</pages>
<contexts>
<context position="3223" citStr="Radev &amp; McKeown (1998)" startWordPosition="460" endWordPosition="464">the terminology of Levelt (1989), who calls the first component the conceptualizer, the second the formulator. These modules interact via preverbal messages, which are propositional, non-verbal representations of the utterance built up by the conceptualizer. They are transformed by the formulator into linguistic structures for spoken or written output. Besides considering high level communicative goals (macroplanning), which are in the focus of most computational approaches to the what-to-say component, e.g. De Smedt &amp; Kempen (1987), McKeown (1985), Hovy (1993), Chu-Carroll &amp; Carberry (1998), Radev &amp; McKeown (1998), the type of information to be verbalized also determines the processes of conceptualization on the level of microplanning, cf. Levelt (1989). Thus, the traditional top-down approaches have to be combined with bottom-up data-driven approaches of text planning (Marcu, 1997). The conceptualizer that is described in detail in section 3 fits the pipeline architecture on a coarse level, but integrates on finer levels the ideas of functional modules (Cahill et al., 1999). In the present paper we focus on the task of I ConcEv (Conceptualizing Events) is supported by the DFG (German Science Foundatio</context>
</contexts>
<marker>Radev, McKeown, 1998</marker>
<rawString>Radev, D. R. &amp; McKeown, K. (1998) Generating natural language summaries from multiple on-line sources. Computational Linguistics, 24,469-500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
</authors>
<title>Has a consensus NL generation architecture appeared, and is it psycholinguistically plausible?</title>
<date>1994</date>
<pages>1994--163</pages>
<contexts>
<context position="1649" citStr="Reiter (1994)" startWordPosition="222" endWordPosition="223">linguistically. 1 Introduction Systems that generate natural language descriptions of what happens in a dynamically changing world can be improved substantially by working incrementally. Incrementality enhances the overall quality of the systems for three reasons: (1) The dynamic nature of a continuous stream of input information can be handled more directly and, therefore, easier. (2) Incremental systems are capable of producing fluent speech, i.e. speech without artificial auditory gaps. (3) Parallelism that comes with incrementality makes better use of the available resources. Furthermore, Reiter (1994), who reviews the • architecture of some models of natural language generation, shows that psycholinguistic and engineering approaches often result in systems, which are similar in crucial respects. In this paper we ground on two of these common aspects, namely the distinction between what-to-say and how-tosay (De Smedt, Horacek &amp; Zock, 1996) and the use of a pipeline architecture, which divides the generation process &amp;quot;into multiple modules, with information flowing in a &apos;pipeline&apos; fashion from one module to the next&amp;quot; (Reiter, 1994). Reiter states that these architectures do not require module</context>
</contexts>
<marker>Reiter, 1994</marker>
<rawString>Reiter E. (1994) Has a consensus NL generation architecture appeared, and is it psycholinguistically plausible? IWNLG-1994,163-170,Kennebunkport, ME.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reithinger</author>
</authors>
<title>The Performance of an incremental generation component for multi-modal dialog contributions. In:</title>
<date>1992</date>
<booktitle>Aspects -of automated natural- language generation,</booktitle>
<pages>263--276</pages>
<editor>R. Dale, E. Hovy, D. Rosner &amp; 0. Stook, eds.,</editor>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<marker>Reithinger, 1992</marker>
<rawString>Reithinger, N. (1992) The Performance of an incremental generation component for multi-modal dialog contributions. In: R. Dale, E. Hovy, D. Rosner &amp; 0. Stook, eds., Aspects -of automated natural- language generation, 263-276, Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schank</author>
<author>R P Abelson</author>
</authors>
<title>Scripts, plans, goals and understanding: An inquiry into human knowledge structures.</title>
<date>1977</date>
<location>Hillsdale: Lawrence Erlbaum.</location>
<contexts>
<context position="14002" citStr="Schank &amp; Abelson (1977)" startWordPosition="2190" endWordPosition="2193">four basic events GRIP THE HANDLE OF A WINDOW, TURNING THE HANDLE, PULL, and LET GO THE HANDLE are perceived, the complex event I I I L— C)* 4-13 —1+1B 27— Echo 87 OPENING A WfNDOW can be built .up. Furthermore, subsequent events of opening all windows of a room can be grouped to AIRING. But events can not only be grouped but also segmented: if the event OPENING A WINDOW is perceived, it can be segmented into the respective sub-events. We assume that hierarchical event structures, which are based on knowledge about the internal structure of prototypical events, e.g. in the format of scripts _sSchank &amp; Abelson (1977)re. _the representational backbone of event conceptualization, cf. Habel &amp; Tappe (1999). 3 An Incremental Conceptualizer Incremental processing is the &apos;piecemeal&apos; and parallel processing of a sequential information stream. It is a specific kind of parallel processing in that the processes have a fixed order, which De Smedt &amp; Kempen (1987) describe as a &apos;cascade of processes&apos;, in analogy to a water cascade. This metaphor means that, for example, the grammatical encoding—including lexical access—of an utterance segment cannot take place until the information &apos;splashes down&apos; from the conceptual e</context>
</contexts>
<marker>Schank, Abelson, 1977</marker>
<rawString>Schank, R. C. &amp; Abelson, R. P. (1977) Scripts, plans, goals and understanding: An inquiry into human knowledge structures. Hillsdale: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zacks</author>
</authors>
<title>Seeing the structure in events.</title>
<date>1997</date>
<tech>Manuscript,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="7253" citStr="Zacks, 1997" startWordPosition="1078" endWordPosition="1079">ates aspects of behavior, e.g. the effects differing time pressure has on verbalizations. 2 Conceptualizing Events If the system has to produce descriptions about what it &apos;sees&apos;, the main conceptual task is building up conceptual entities representing spatio-temporal- constellations -of the -external world, i.e. event conceptualization. Events emerge from dynamic input data, which are segmented by the conceptual system into meaningful units (Avrahami &amp; Kareev, 1994). They are therefore internal representations rather than external entities: &amp;quot;[...] events arise in the perception of observers&amp;quot; (Zacks, 1997). Consequently, a language production system designed for verbalizing what the system perceives has to deal with information stemming from multiple modalities, e.g. auditory and spatial. In particular, a continuous multimodal &apos;perceptual stream&apos; has to be translated into discrete propositional output (preverbal messages) that can be encoded linguistically, cf. Levelt (1989). To meet such demands, three subtasks have to be solved: (1) The input stream has to be subdivided into &apos;perceptual units&apos;; (2) conceptual representations have to be built up from these &apos;percepts&apos;, which (3) have to be comb</context>
</contexts>
<marker>Zacks, 1997</marker>
<rawString>Zacks, J. (1997) Seeing the structure in events. Manuscript, Stanford University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>