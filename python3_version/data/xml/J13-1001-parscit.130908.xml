<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.021317">
<title confidence="0.39939">
Obituary
</title>
<author confidence="0.519236">
George A. Miller
Christiane Fellbaum
</author>
<affiliation confidence="0.471459">
Princeton University
</affiliation>
<bodyText confidence="0.988751260869566">
George Armitage Miller died on July 22, 2012, at the age of ninety-two. He led a rich
life full of accomplishments in the three areas of activity that he had chosen as a young
man: psychology, writing, and golf.
Miller was not only a witness but a key player in the major paradigm shift of the
20th century that came to be known as the cognitive revolution. Incredible as it may
seem today, his teachers at Harvard followed the behaviorist dogma and recognized
neither the autonomy nor the significance of the human mind. It took two courageous
young scientists—George Miller and Jerome Bruner—to assert, each in their own do-
main of investigation, that the mind is a worthwhile subject of study. They started out
by teaching a course boldly entitled “Cognition” and eventually established the Center
for Cognitive Studies, ultimately making behaviorism obsolete.
Miller drew an analogy between the human mind and a computer, noting that
both store and process huge amounts of information. At the same time, human short-
term memory is limited, as his most celebrated paper on the “Magical Number Seven”
demonstrates (Miller 1956/1994). Miller showed that chunking information into mean-
ingful units helps recall, though the number of units that can be memorized seems to
hover around seven. For example, U.S. telephone numbers are broken down into three
groups of three, three, and four digits (area code, local exchange, and individual num-
ber). Chunk parsers (Abney 1991) build on the idea that sentence processing proceeds
in phrases, reflected in prosodic patterns.
Among our cognitive faculties, it was language in particular that fascinated George,
a gifted writer. One attraction was that linguistic behavior could be observed, tested,
and evaluated quantitatively with the experimental paradigms available to psycholin-
guists at a time when brain imaging techniques had not yet been developed. The rules
of language, with their recursive aspects, could be seen as a kind of program. Although
he collaborated with Noam Chomsky on the formal aspects of language, Miller in later
life harbored a suspicion of highly abstract theories of syntax. His interest lay primarily
in the lexicon, not only because of his authorial love of words, but also because of its
size, open-endedness, and dynamic aspects. Moreover, the growth of children’s lexicons
offered a window into their cognitive development.
Miller is probably best known to readers of Computational Linguistics for his creation
of the large lexical database WordNet (Miller 1995). WordNet’s use as a resource for
natural language processing was in fact unintended, and its rapid adoption by the NLP
community came as a surprise. George was interested in human semantic organization
and wanted to test the then-fashionable concept of semantic networks, which allowed
for plausible and elegant models of semantic representation and seemed supported
by experiments testing lexical access and retrieval (Collins and Quillian 1969). Miller
wondered whether a semantic network could in fact be built for the bulk of the English
lexicon. In the mid 1980s, he recruited a group of colleagues, students, and his wife
Kitty and, without much further instruction, asked them to cluster nouns, verbs, and
© 2013 Association for Computational Linguistics
Computational Linguistics Volume 39, Number 1
adjectives into “synsets” that could be interrelated with a handful of semantic relations.
Relying on conventional lexical resources and intuition, the WordNet team created tens
of thousands of entries manually, a fact that provokes head-shaking among the new
generation of WordNet builders, who proceed fully or semi-automatically. Each senior
member was assigned a different part of speech; Kitty was the “Adjective Lady,” and
George took charge of the noun lexicon. Both would come to the Cognitive Science
Laboratory every day and patiently perform their lexicographic labor. Once or twice a
week, George would leave in the afternoon for the golf course. Well into this eighties, he
participated in tournaments and, more often than not, his team was among the winners.
A government sponsor’s requirement that the database be publicly released was
duly followed, but the response from the budding NLP community was entirely
unanticipated by the WordNet team, which was unaware of the challenge of word
sense disambiguation. WordNet turned out to be a tool that promised help with the
vexing task of word sense discrimination, and its graph structure became the basis
for a number of algorithms that measured semantic similarity among words in terms
of their distance in the network. Being unique in coverage and design, WordNet not
only survived but continued to grow, though its claims to modeling human seman-
tic memory were largely abandoned. George was proud to say that WordNet de-
fined a new kind of electronic lexicography, and WordNet became a common noun.
WordNets have been built for dozens of genetically and typologically unrelated
languages (http://www.globalwordnet.org).
While working on WordNet, George became interested in children’s literacy. He
believed that children did not learn words and their meanings from dictionaries, as they
were instructed to do in school. To test this hypothesis, he asked children to look up
unfamiliar words in a dictionary and write sentences using the new words. As George
had guessed, the results were both appalling and amusing. For example, when asked
to write a sentence with the word meticulous, children would produce sentences like she
was meticulous about falling off the cliff after having seen a dictionary entry that defined
this adjective as careful, scrupulous, fastidious.
Moreover, George guessed that children enjoy reading but, when encountering
an unfamiliar word, are generally disinclined to put their books down and consult a
dictionary. His idea was to present new words in their contexts, based on evidence that
context-based learning was both natural and efficient (Miller and Gildea 1987). He and
his team began to manually annotate a digitized book with entries from WordNet; an
interface would allow the children to read the book on the screen, click on unfamiliar
words and be presented with the context-appropriate WordNet sense. It should be
remembered that George’s idea of reading books on a screen was long before the
invention of e-readers!
The text-to-WordNet link gave birth to the idea of the semantic concordance. A large
team of Princeton students manually annotated nouns, verbs, and adjectives from texts
in the Brown Corpus against the corresponding WordNet senses. George thought that
this would be a straightforward task: Just as lexicographers create dictionary entries
based on tokens in a text, their entries should be mappable back to words in texts in a
one-to-one fashion. We learned that dictionaries with enumerative, discrete word senses
are in fact not a particularly good way of modeling speakers’ lexicons. Today, research
into semantic annotation and measurements of inter-annotator agreement is a lively
area of investigation.
Although he had to transfer to emeritus status at the then-mandatory retirement
age, George did not give up teaching. He organized an informal course on the lexicon
and for each of twelve weekly meetings prepared beautifully written lectures that
</bodyText>
<page confidence="0.970983">
2
</page>
<subsectionHeader confidence="0.328516">
Fellbaum Obituary
</subsectionHeader>
<bodyText confidence="0.999786923076923">
the participants would discuss and critique. The lectures would become The Science
of Words, a prize-winning book on the lexicon that was translated into numerous lan-
guages. In this and several other books (including Language and Communication [1963]
and Spontaneous Apprentices [1977]), George’s lively, lucid prose made a scientific sub-
ject accessible to the general public and conveyed his fascination with language and
cognition. His landmark book Language and Perception (1976), co-authored with Philip
Johnson-Laird, remains a classic among psycholinguists to this day. Co-authoring a
paper with George invariably involved a final editing step on his part, which he referred
to as “Millerizing.”
George collected many prizes, medals, and honorary doctorates. He was modest
about it and only very occasionally did a new frame appear on his office walls alongside
graduation and wedding pictures of former students and the fake Renoir that he had
kindly bought from a street vendor.
</bodyText>
<sectionHeader confidence="0.997204" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.99985868">
Abney, Steven. 1991. Parsing by chunks. In
Principle-Based Parsing. Kluwer Academic
Publishers, pages 257–278.
Collins, Allan M. and M. Ross Quillian. 1969.
Retrieval time from semantic memory.
Journal of Verbal Learning and Verbal
Behavior, 8(2):240–247.
Miller, George A. 1956/1994. The magical
number seven, plus or minus two: Some
limits on our capacity for processing
information. Psychological Review (special
centennial issue), 101:343–352.
Miller, George A. 1963. Language and
Communication. McGraw Hill, New York.
Miller, George A. 1977. Spontaneous
Apprentices. Seabury Press, New York.
Miller, George A. 1995. WordNet: A lexical
database for English. Communications of the
ACM, 38(11):39–41.
Miller, George A. and Patricia M. Gildea.
1987. How children learn words. Scientific
American, 257(3):94–99.
Miller, George A. and Philip Johnson-Laird.
1976. Language and Perception. Belknap
Press, Cambridge, MA.
</reference>
<page confidence="0.998277">
3
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.010957">
<title confidence="0.987968">Obituary</title>
<author confidence="0.897414">George A Miller Christiane Fellbaum</author>
<affiliation confidence="0.999717">Princeton University</affiliation>
<author confidence="0.336877">He led a rich</author>
<abstract confidence="0.998313676190476">life full of accomplishments in the three areas of activity that he had chosen as a young man: psychology, writing, and golf. Miller was not only a witness but a key player in the major paradigm shift of the 20th century that came to be known as the cognitive revolution. Incredible as it may seem today, his teachers at Harvard followed the behaviorist dogma and recognized neither the autonomy nor the significance of the human mind. It took two courageous young scientists—George Miller and Jerome Bruner—to assert, each in their own domain of investigation, that the mind is a worthwhile subject of study. They started out by teaching a course boldly entitled “Cognition” and eventually established the Center for Cognitive Studies, ultimately making behaviorism obsolete. Miller drew an analogy between the human mind and a computer, noting that both store and process huge amounts of information. At the same time, human shortterm memory is limited, as his most celebrated paper on the “Magical Number Seven” demonstrates (Miller 1956/1994). Miller showed that chunking information into meaningful units helps recall, though the number of units that can be memorized seems to hover around seven. For example, U.S. telephone numbers are broken down into three groups of three, three, and four digits (area code, local exchange, and individual number). Chunk parsers (Abney 1991) build on the idea that sentence processing proceeds in phrases, reflected in prosodic patterns. Among our cognitive faculties, it was language in particular that fascinated George, a gifted writer. One attraction was that linguistic behavior could be observed, tested, and evaluated quantitatively with the experimental paradigms available to psycholinguists at a time when brain imaging techniques had not yet been developed. The rules of language, with their recursive aspects, could be seen as a kind of program. Although he collaborated with Noam Chomsky on the formal aspects of language, Miller in later life harbored a suspicion of highly abstract theories of syntax. His interest lay primarily in the lexicon, not only because of his authorial love of words, but also because of its size, open-endedness, and dynamic aspects. Moreover, the growth of children’s lexicons offered a window into their cognitive development. is probably best known to readers of Linguistics his creation of the large lexical database WordNet (Miller 1995). WordNet’s use as a resource for natural language processing was in fact unintended, and its rapid adoption by the NLP community came as a surprise. George was interested in human semantic organization and wanted to test the then-fashionable concept of semantic networks, which allowed for plausible and elegant models of semantic representation and seemed supported by experiments testing lexical access and retrieval (Collins and Quillian 1969). Miller wondered whether a semantic network could in fact be built for the bulk of the English lexicon. In the mid 1980s, he recruited a group of colleagues, students, and his wife Kitty and, without much further instruction, asked them to cluster nouns, verbs, and © 2013 Association for Computational Linguistics Computational Linguistics Volume 39, Number 1 adjectives into “synsets” that could be interrelated with a handful of semantic relations. Relying on conventional lexical resources and intuition, the WordNet team created tens of thousands of entries manually, a fact that provokes head-shaking among the new generation of WordNet builders, who proceed fully or semi-automatically. Each senior member was assigned a different part of speech; Kitty was the “Adjective Lady,” and George took charge of the noun lexicon. Both would come to the Cognitive Science Laboratory every day and patiently perform their lexicographic labor. Once or twice a week, George would leave in the afternoon for the golf course. Well into this eighties, he participated in tournaments and, more often than not, his team was among the winners. A government sponsor’s requirement that the database be publicly released was duly followed, but the response from the budding NLP community was entirely unanticipated by the WordNet team, which was unaware of the challenge of word sense disambiguation. WordNet turned out to be a tool that promised help with the vexing task of word sense discrimination, and its graph structure became the basis for a number of algorithms that measured semantic similarity among words in terms of their distance in the network. Being unique in coverage and design, WordNet not only survived but continued to grow, though its claims to modeling human semantic memory were largely abandoned. George was proud to say that WordNet defined a new kind of electronic lexicography, and WordNet became a common noun. WordNets have been built for dozens of genetically and typologically unrelated While working on WordNet, George became interested in children’s literacy. He believed that children did not learn words and their meanings from dictionaries, as they were instructed to do in school. To test this hypothesis, he asked children to look up unfamiliar words in a dictionary and write sentences using the new words. As George had guessed, the results were both appalling and amusing. For example, when asked write a sentence with the word children would produce sentences like meticulous about falling off the cliff having seen a dictionary entry that defined adjective as scrupulous, Moreover, George guessed that children enjoy reading but, when encountering an unfamiliar word, are generally disinclined to put their books down and consult a dictionary. His idea was to present new words in their contexts, based on evidence that context-based learning was both natural and efficient (Miller and Gildea 1987). He and his team began to manually annotate a digitized book with entries from WordNet; an interface would allow the children to read the book on the screen, click on unfamiliar words and be presented with the context-appropriate WordNet sense. It should be remembered that George’s idea of reading books on a screen was long before the invention of e-readers! The text-to-WordNet link gave birth to the idea of the semantic concordance. A large team of Princeton students manually annotated nouns, verbs, and adjectives from texts in the Brown Corpus against the corresponding WordNet senses. George thought that this would be a straightforward task: Just as lexicographers create dictionary entries based on tokens in a text, their entries should be mappable back to words in texts in a one-to-one fashion. We learned that dictionaries with enumerative, discrete word senses are in fact not a particularly good way of modeling speakers’ lexicons. Today, research into semantic annotation and measurements of inter-annotator agreement is a lively area of investigation. Although he had to transfer to emeritus status at the then-mandatory retirement age, George did not give up teaching. He organized an informal course on the lexicon and for each of twelve weekly meetings prepared beautifully written lectures that 2 Fellbaum Obituary participants would discuss and critique. The lectures would become Science a prize-winning book on the lexicon that was translated into numerous lan- In this and several other books (including and Communication Apprentices George’s lively, lucid prose made a scientific subject accessible to the general public and conveyed his fascination with language and His landmark book and Perception co-authored with Philip Johnson-Laird, remains a classic among psycholinguists to this day. Co-authoring a paper with George invariably involved a final editing step on his part, which he referred to as “Millerizing.” George collected many prizes, medals, and honorary doctorates. He was modest about it and only very occasionally did a new frame appear on his office walls alongside graduation and wedding pictures of former students and the fake Renoir that he had kindly bought from a street vendor.</abstract>
<note confidence="0.734229956521739">References Abney, Steven. 1991. Parsing by chunks. In Kluwer Academic Publishers, pages 257–278. Collins, Allan M. and M. Ross Quillian. 1969. Retrieval time from semantic memory. Journal of Verbal Learning and Verbal 8(2):240–247. Miller, George A. 1956/1994. The magical number seven, plus or minus two: Some limits on our capacity for processing Review (special 101:343–352. George A. 1963. and McGraw Hill, New York. George A. 1977. Seabury Press, New York. Miller, George A. 1995. WordNet: A lexical for English. of the 38(11):39–41. Miller, George A. and Patricia M. Gildea. How children learn words. 257(3):94–99.</note>
<author confidence="0.820929">George A Miller</author>
<author confidence="0.820929">Philip Johnson-Laird</author>
<affiliation confidence="0.726732">and Belknap</affiliation>
<address confidence="0.819502">Press, Cambridge, MA.</address>
<intro confidence="0.765616">3</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Parsing by chunks. In Principle-Based Parsing.</title>
<date>1991</date>
<pages>257--278</pages>
<publisher>Kluwer Academic Publishers,</publisher>
<contexts>
<context position="1536" citStr="Abney 1991" startWordPosition="247" endWordPosition="248">ete. Miller drew an analogy between the human mind and a computer, noting that both store and process huge amounts of information. At the same time, human shortterm memory is limited, as his most celebrated paper on the “Magical Number Seven” demonstrates (Miller 1956/1994). Miller showed that chunking information into meaningful units helps recall, though the number of units that can be memorized seems to hover around seven. For example, U.S. telephone numbers are broken down into three groups of three, three, and four digits (area code, local exchange, and individual number). Chunk parsers (Abney 1991) build on the idea that sentence processing proceeds in phrases, reflected in prosodic patterns. Among our cognitive faculties, it was language in particular that fascinated George, a gifted writer. One attraction was that linguistic behavior could be observed, tested, and evaluated quantitatively with the experimental paradigms available to psycholinguists at a time when brain imaging techniques had not yet been developed. The rules of language, with their recursive aspects, could be seen as a kind of program. Although he collaborated with Noam Chomsky on the formal aspects of language, Mille</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Abney, Steven. 1991. Parsing by chunks. In Principle-Based Parsing. Kluwer Academic Publishers, pages 257–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allan M Collins</author>
<author>M Ross Quillian</author>
</authors>
<title>Retrieval time from semantic memory.</title>
<date>1969</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>8</volume>
<issue>2</issue>
<contexts>
<context position="3051" citStr="Collins and Quillian 1969" startWordPosition="474" endWordPosition="477">window into their cognitive development. Miller is probably best known to readers of Computational Linguistics for his creation of the large lexical database WordNet (Miller 1995). WordNet’s use as a resource for natural language processing was in fact unintended, and its rapid adoption by the NLP community came as a surprise. George was interested in human semantic organization and wanted to test the then-fashionable concept of semantic networks, which allowed for plausible and elegant models of semantic representation and seemed supported by experiments testing lexical access and retrieval (Collins and Quillian 1969). Miller wondered whether a semantic network could in fact be built for the bulk of the English lexicon. In the mid 1980s, he recruited a group of colleagues, students, and his wife Kitty and, without much further instruction, asked them to cluster nouns, verbs, and © 2013 Association for Computational Linguistics Computational Linguistics Volume 39, Number 1 adjectives into “synsets” that could be interrelated with a handful of semantic relations. Relying on conventional lexical resources and intuition, the WordNet team created tens of thousands of entries manually, a fact that provokes head-</context>
</contexts>
<marker>Collins, Quillian, 1969</marker>
<rawString>Collins, Allan M. and M. Ross Quillian. 1969. Retrieval time from semantic memory. Journal of Verbal Learning and Verbal Behavior, 8(2):240–247.</rawString>
</citation>
<citation valid="false">
<authors>
<author>George A Miller</author>
</authors>
<title>The magical number seven, plus or minus two: Some limits on our capacity for processing information. Psychological Review (special centennial issue),</title>
<pages>101--343</pages>
<marker>Miller, </marker>
<rawString>Miller, George A. 1956/1994. The magical number seven, plus or minus two: Some limits on our capacity for processing information. Psychological Review (special centennial issue), 101:343–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Language and Communication.</title>
<date>1963</date>
<publisher>McGraw Hill,</publisher>
<location>New York.</location>
<marker>Miller, 1963</marker>
<rawString>Miller, George A. 1963. Language and Communication. McGraw Hill, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Spontaneous Apprentices.</title>
<date>1977</date>
<publisher>Seabury Press,</publisher>
<location>New York.</location>
<marker>Miller, 1977</marker>
<rawString>Miller, George A. 1977. Spontaneous Apprentices. Seabury Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: A lexical database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="2604" citStr="Miller 1995" startWordPosition="410" endWordPosition="411">their recursive aspects, could be seen as a kind of program. Although he collaborated with Noam Chomsky on the formal aspects of language, Miller in later life harbored a suspicion of highly abstract theories of syntax. His interest lay primarily in the lexicon, not only because of his authorial love of words, but also because of its size, open-endedness, and dynamic aspects. Moreover, the growth of children’s lexicons offered a window into their cognitive development. Miller is probably best known to readers of Computational Linguistics for his creation of the large lexical database WordNet (Miller 1995). WordNet’s use as a resource for natural language processing was in fact unintended, and its rapid adoption by the NLP community came as a surprise. George was interested in human semantic organization and wanted to test the then-fashionable concept of semantic networks, which allowed for plausible and elegant models of semantic representation and seemed supported by experiments testing lexical access and retrieval (Collins and Quillian 1969). Miller wondered whether a semantic network could in fact be built for the bulk of the English lexicon. In the mid 1980s, he recruited a group of collea</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>Miller, George A. 1995. WordNet: A lexical database for English. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Patricia M Gildea</author>
</authors>
<title>How children learn words.</title>
<date>1987</date>
<journal>Scientific American,</journal>
<volume>257</volume>
<issue>3</issue>
<contexts>
<context position="6078" citStr="Miller and Gildea 1987" startWordPosition="946" endWordPosition="949">results were both appalling and amusing. For example, when asked to write a sentence with the word meticulous, children would produce sentences like she was meticulous about falling off the cliff after having seen a dictionary entry that defined this adjective as careful, scrupulous, fastidious. Moreover, George guessed that children enjoy reading but, when encountering an unfamiliar word, are generally disinclined to put their books down and consult a dictionary. His idea was to present new words in their contexts, based on evidence that context-based learning was both natural and efficient (Miller and Gildea 1987). He and his team began to manually annotate a digitized book with entries from WordNet; an interface would allow the children to read the book on the screen, click on unfamiliar words and be presented with the context-appropriate WordNet sense. It should be remembered that George’s idea of reading books on a screen was long before the invention of e-readers! The text-to-WordNet link gave birth to the idea of the semantic concordance. A large team of Princeton students manually annotated nouns, verbs, and adjectives from texts in the Brown Corpus against the corresponding WordNet senses. Georg</context>
</contexts>
<marker>Miller, Gildea, 1987</marker>
<rawString>Miller, George A. and Patricia M. Gildea. 1987. How children learn words. Scientific American, 257(3):94–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Philip Johnson-Laird</author>
</authors>
<title>Language and Perception.</title>
<date>1976</date>
<publisher>Belknap Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Miller, Johnson-Laird, 1976</marker>
<rawString>Miller, George A. and Philip Johnson-Laird. 1976. Language and Perception. Belknap Press, Cambridge, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>