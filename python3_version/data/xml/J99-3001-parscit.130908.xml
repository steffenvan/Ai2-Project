<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.995754333333333">
Functional Centering—
Grounding Referential Coherence
in Information Structure
</title>
<author confidence="0.999635">
Michael Strube* Udo Hahnt
</author>
<affiliation confidence="0.992563">
University of Pennsylvania Freiburg University
</affiliation>
<bodyText confidence="0.987620461538462">
Considering empirical evidence from a free-word-order language (German) we propose a revi-
sion of the principles guiding the ordering of discourse entities in the forward-looking center list
within the centering model. We claim that grammatical role criteria should be replaced by criteria
that reflect the functional information structure of the utterances. These new criteria are based
on the distinction between hearer-old and hearer-new discourse entities. We demonstrate that
such a functional model of centering can be successfully applied to the analysis of several forms
of referential text phenomena, viz. pronominal, nominal, and functional anaphora. Our method-
ological and empirical claims are substantiated by two evaluation studies. In the first one, we
compare success rates for the resolution of pronominal anaphora that result from a grammatical-
role-driven centering algorithm and from a functional centering algorithm. The second study
deals with a new cost-based evaluation methodology for the assessment of centering data, one
which can be directly derived from and justified by the cognitive load premises of the centering
model.
</bodyText>
<sectionHeader confidence="0.992122" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9999545">
The problem of establishing referential coherence in discourse can be rephrased as the
problem of determining the proper antecedent of a given anaphoric expression in the
current or the preceding utterance(s) and the rendering of both as referentially iden-
tical (coreferential). This task can be approached in a very principled way by stating
general constraints on the grammatical compatibility of the expressions involved (e.g.,
Haddock 1987; Alshawi 1992). Linguists have devoted a lot of effort to identifying
conclusive syntactic and semantic criteria to reach this goal, e.g., for intrasentential
anaphora within the binding theory part of the theory of Government and Binding
(Chomsky 1981), or for intersentential anaphora within the context of the Discourse
Representation Theory (Kamp and Reyle 1993).
Unfortunately, these frameworks fail to uniquely determine anaphoric antecedents
in a variety of cases. As a consequence, referentially ambiguous interpretations have
to be dealt with in those cases in which several alternatives fulfill all the required
syntactic and semantic constraints. It seems that syntactic and semantic criteria con-
stitute only necessary but by no means sufficient conditions for identifying the valid
antecedent among several possible candidates. Hence, one is left with a preferential
choice problem that falls outside of the scope of those strict grammaticality constraints
relating to the level of syntax or semantics only. Its solution requires considering pat-
</bodyText>
<footnote confidence="0.83385">
* Institute for Research in Cognitive Science, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104, USA
t Computational Linguistics Group, Text Understanding Lab, Werthmannplatz 1, 79085 Freiburg,
Germany
</footnote>
<note confidence="0.833437">
C) 1999 Association for Computational Linguistics
Computational Linguistics Volume 25, Number 3
</note>
<bodyText confidence="0.999879361702128">
terns of language use and, thus, introduces the level of discourse context and further
pragmatic factors as a complementary description level.
Computational linguists have recognized the need to account for referential ambi-
guities in discourse and have developed various theories centered around the notion of
discourse focus (Grosz 1977; Sidner 1983). In a seminal paper, Grosz and Sidner (1986)
wrapped up the results of their research and formulated a model in which three levels
of discourse coherence are distinguished—attention, intention, and discourse segment
structure. While this paper gives a comprehensive picture of a complex, yet not ex-
plicitly spelled-out theory of discourse coherence, the centering model (Grosz, Joshi,
and Weinstein, 1983, 1995) marked a major step in clarifying the relationship between
attentional states and (local) discourse segment structure. More precisely, the centering
model accounts for the interactions between local coherence and preferential choices of
referring expressions. It relates differences in coherence (in part) to varying demands
on inferences as required by different types of referring expressions, given a particular
attentional state of the hearer in a discourse setting (Grosz, Joshi, and Weinstein 1995,
204-205). The claim is made then that the lower the inference load put on the hearer,
the more coherent the underlying discourse appears.
The centering model as formulated by Grosz, Joshi, and Weinstein (1995) refines
the structure of &amp;quot;centers&amp;quot; of discourse, which are conceived as the representational
device for the attentional state at the local level of discourse. They distinguish two
basic types of centers, which can be assigned to each utterance U,—a single backward-
looking center, Cb(U,), and a partially ordered set of discourse entities, the forward-
looking centers, Cf(U,). The ordering on Cf is relevant for determining the Cb. It
can be viewed as a salience ranking that reflects the assumption that the higher the
ranking of a discourse entity in Cf, the more likely it will be mentioned again in the
immediately following utterance. Thus, given an adequate ordering of the discourse
entities in Cf, the costs of computations necessary to establish local coherence are
minimized.
Given that the ordering on the Cf list is crucial for determining the Cb, it is no
surprise that there has been much discussion among researchers about the ranking
criteria appropriate for different languages. In fact, Walker, Iida, and Cote (1994) hy-
pothesize that the Cf ranking criteria are the only language-dependent factors within
the centering model. Though evidence for many additional criteria for the Cf ranking
have been brought forward in the literature, to some extent consensus has emerged
that grammatical roles play a major role in making ranking decisions (e.g., whether
the referential expression appears as the grammatical subject, direct object, or indirect
object of an utterance). Our own work on the centering model&apos; (Strube and Hahn 1996;
Hahn and Strube 1996) brings in evidence from German, a free-word-order language
in which grammatical role information is far less predictive of the organization of
centers than for fixed-word-order languages such as English. In establishing proper
referential relations, we found the functional information structure of the utterances
to be much more relevant. By this we mean indicators of whether or not a discourse
entity in the current utterance refers to another discourse entity already introduced
by previous utterances in the discourse. Borrowing terminology from Prince (1981,
1992), an entity that does refer to another discourse entity already introduced is called
discourse-old or hearer-old, while an entity that does not refer to another discourse
entity is called discourse-new or hearer-new.
</bodyText>
<footnote confidence="0.908448333333333">
1 This article is an extended and revised version of our contribution to the 1996 Annual Meeting of the
Association for Computational Linguistics (Strube and Hahn 1996). It contains additional material from
the doctoral thesis of the first author (Strube 1996a).
</footnote>
<page confidence="0.991748">
310
</page>
<note confidence="0.896128">
Strube and Hahn Functional Centering
</note>
<bodyText confidence="0.999627215686275">
Based on evidence from empirical studies in which we considered German as well
as English texts from different domains and genres, we make three contributions to
the centering approach. The first, the introduction of functional notions of information
structure into the centering model, is purely methodological in nature and concerns the
centering approach as a theory of local coherence. The second deals with an empirical
issue, in that we demonstrate how a functional model of centering can be success-
fully applied to the analysis of different forms of anaphoric text phenomena, namely
pronominal, nominal, and functional anaphora. Finally, we propose a new evaluation
methodology for centering data in terms of a cost-based evaluation approach that can
be directly derived from and justified by the cognitive load premises of the centering
model.
At the methodological level, we develop arguments that (at least for some free-
word-order languages) grammatical role criteria should be replaced by functional
role criteria, since they seem to more adequately account for the ordering of discourse
entities in the Cf list. In Section 4, we elaborate on particular information structure
criteria underlying such a functional center ordering. We also make a second, more
general methodological claim for which we have gathered some preliminary, though
still not conclusive evidence. Based on a reevaluation of centering analyses of some
challenging language data that can be found in the literature on centering, we will
argue that exchanging grammatical for functional criteria might also be a reason-
able strategy for fixed-word-order languages. What makes this proposal so attractive
is the obvious gain in the generality of the model—given a functional framework,
fixed- and free-word-order languages might be accounted for by the same ordering
principles.
The second major contribution of this paper is related to the unified treatment of
different text coherence phenomena. It consists of an equally balanced treatment of
intersentential (pro)nominal anaphora and inferables (also called functional, bridging,
or partial anaphora). The latter phenomenon (cf. the examples in the next section and
the in-depth treatment in Hahn, Markert, and Strube [1996]) is usually only sketchily
dealt with in the centering literature, e.g., by asserting that the entity in question &amp;quot;is re-
alized but not directly realized&amp;quot; (Grosz, Joshi, and Weinstein 1995, 217). Furthermore,
the distinction between these two kinds of realization is not part of the centering
mechanisms but delegated to the underlying semantic theory. We will develop argu-
ments for how to discern inferable discourse entities and relate them properly to their
antecedent at the center level. The ordering constraints we supply account for all of
the types of anaphora mentioned above, including (pro)nominal anaphora (Strube and
Hahn 1995; Hahn and Strube 1996). This claim will be validated by a substantial body
of empirical data in Section 5.
Our third contribution relates to the way the results of centering-based anaphora
resolution are usually evaluated. Basically, we argue that rather than counting reso-
lution rates for anaphora or comparing isolated transition types holding among head
positions in the center lists—preferred transition types stand for a high degree of local
coherence, while less preferred ones signal that the underlying discourse might lack
coherence—one should consider adjacent transition pairs and annotate such pairs with
the processing costs they incur. This way, we define a dual theory-internal metric of
inference load by distinguishing between &amp;quot;cheap&amp;quot; and &amp;quot;expensive&amp;quot; transition types.
Based on this distinction, some transition types receiving bad marks in isolation are
ranked &amp;quot;cheap&amp;quot; when they occur in the appropriate context, and vice versa.
The article is organized as follows: In Section 2, we introduce the different types of
anaphora we consider subsequently, viz. pronominal, nominal, and functional anaphora.
We then turn to the proposed modification of the centering model. After a brief in-
</bodyText>
<page confidence="0.995742">
311
</page>
<note confidence="0.881442">
Computational Linguistics Volume 25, Number 3
</note>
<bodyText confidence="0.998300333333333">
troduction into what we call the &amp;quot;grammatical&amp;quot; centering model (actually, a recap of
Grosz, Joshi, and Weinstein [1995]) in Section 3, we turn in Section 4 to our approach,
the functional model of centering. In Section 5, we present the methodological frame-
work and the empirical data from two evaluation studies we carried out. In Section 6,
we relate our work to alternative approaches dealing with local text coherence. In
Section 7, we discuss some remaining unsolved problems.
</bodyText>
<sectionHeader confidence="0.58671" genericHeader="keywords">
2. Types of Anaphoric Expressions
</sectionHeader>
<bodyText confidence="0.999961628571429">
In this paper, we consider anaphora as a textual phenomenon only, and deal with
anaphoric relations that hold between adjacent utterances (intersentential anaphora).2
Text phenomena are a challenging issue for the design of a text parser for any text-
understanding system, since recognition facilities that are imperfect or altogether lack-
ing result in referentially incomplete, invalid, or incohesive text knowledge represen-
tation structures (Hahn, Romacker, and Schulz 1999). Incomplete knowledge structures
emerge when references to already established discourse entities are simply not rec-
ognized, as in the case of conceptually neutral pronominal anaphora (e.g., er, &apos;it,&apos; in
example (1d) co-specifying with 316LT, a particular notebook introduced in exam-
ple (la)). Invalid knowledge structures emerge when each entity that has a different
denotation at the text surface is also treated as a formally distinct item at the level
of text knowledge representation, although they all refer literally to the same entity.
These false referential descriptions result from unresolved nominal anaphora (e.g.,
Rechner, &apos;computer&apos; in example (lc) co-specifies with 316LT in (la)). Finally, incohesive
or artificially fragmented knowledge structures emerge when entities that are linked
by various conceptual relations at the knowledge level occur in a text such that an
implicit reference to these relations can be made without the need for explicit signal-
ing at the text surface level. Corresponding referential relations cannot be established
at the text representation level, since these inferables remain unsolved (such as the
relation between Akkus, &apos;rechargeable battery cell&apos;, and 316LT in examples (lb) and
(la), respectively.&apos; The linking conceptual relation between these two discourse ele-
ments has to be inferred in order to make it explicit at the level of text knowledge
representation structures (for an early statement of this idea in terms of &amp;quot;bridging&amp;quot;
inferences, see Clark [1975]).
Note an interesting asymmetric relationship between these three types of anaphora.
Pronominal anaphora are constrained by morphosyntactic and grammatical agreement
criteria between the pronoun and the antecedent,&apos; and no conceptual constraints ap-
ply. Nominal anaphora are only constrained by number compatibility between the
anaphoric expression and the antecedent, while at the conceptual level the anaphoric
expression is related to its antecedent in terms of a conceptual generalization relation.
Finally, no grammatical constraints apply to inferables, while conceptual constraints
typically require a nongeneralization relation (e.g., part-whole) to hold between the
inferable and its antecedent. Of course, contextual conceptual constraints are intro-
duced for both nominal and pronominal anaphora by sortal requirements set up, e.g.,
by the case roles of the main verb.
</bodyText>
<footnote confidence="0.974317833333333">
2 We have also considered the role of anaphora within sentences. The d-binding criterion we have
developed for resolving intrasentential anaphora is based on dependency grammar notions described
in more detail in Strube and Hahn (1995).
3 Note that Reserve-Batteriepack in Example (la) and Akkus in (lb) denote conceptually different discourse
entities that cannot be coindexed.
4 See Jaeggli (1986) for special cases where this criterion is overruled.
</footnote>
<page confidence="0.980308">
312
</page>
<note confidence="0.85756">
Strube and Hahn Functional Centering
</note>
<bodyText confidence="0.8081115">
Let us illustrate these different types of phenomena by considering the following
text fragment:
</bodyText>
<figure confidence="0.525191857142857">
Example 1
a. Ein Reserve-Batteriepack versorgt den 316LT ca. 2 Minuten mit Strom.
[A reserve battery pack]io. — supplies — the [3/6LT],,, — for
approximately 2 minutes — with power.
The 316LT is supplied with power by a reserve battery pack for
approximately 2 minutes.
b. Der Status des Akkus wird dem Anwender angezeigt.
</figure>
<bodyText confidence="0.993146552631578">
[The status — [of the rechargeable battery celligen]nom — is — [to the userldat —
signalled.
The status of the rechargeable battery cell is signalled to the user.
c. Ca. 30 Minuten vor der Entleerung beginnt der Rechner 5 Sekunden zu
piepen.
Approximately 30 minutes — before discharge — starts — [the
nmaanisc
computer — for 5 seconds — to beep.
Approximately 30 minutes before discharge the computer beeps for 5
seconds.
d. 5 Minuten bevor er sich ausschaltet, fangt die Low-Battery-LED an zu
blinken.
5 minutes — before — [it]nnloag — itself — turns off — begins — [the
low-battery-LED]nom — to flash.
5 minutes before it turns off, the low-battery-LED begins to flash.
Common to all the varieties of anaphora we discuss is the search for the proper
antecedent in previous utterances, the correct determination of which is considered to
be the task of the centering mechanism. The kinds of anaphora we treat can be distin-
guished, however, in terms of the criteria being evaluated for referentiality. In the case
of inferables, the missing conceptual link must be inferred in order to establish local
coherence between the utterances involved. In the surface form of utterance (lb) the in-
formation that Akkus, &apos;rechargeable battery cell&apos;, links up with 316LT is missing, while,
due to obvious conceptual constraints, it cannot link up with Reserve-Batteriepack, for
example. The underlying relation can only be made explicit if conceptual knowledge
about the domain, viz, the relation PART-OF between the concepts RECHARGEBAT-
TERYCELL and 316LT, is available (see Hahn, Markert, and Strube [1996] for a detailed
treatment of the resolution of inferables). In the case of nominal anaphors, a conceptual
specialization relation has to be determined between the specific antecedent and the
more general anaphoric expression, for example, between 316LT and Rechner, &apos;com-
puter&apos;, in (1a) and (1c), respectively. Finally, the resolution of pronominal anaphors
need not take conceptual constraints into account at all, but is restricted to gram-
matical constraints, as illustrated by the masculine gender of Rechner, &apos;computermascc
(co-specifying with 316LT masc) and er &apos;Wmasc. in (1c) and (1d), respectively.
Certainly, the types of phenomena we discuss cover only a limited range of
anaphora. In particular, we leave out the whole range of quantificational studies on
anaphora (in particular, the &amp;quot;hard&amp;quot; issues related to generalized quantifiers), deictic
phenomena, etc., which significantly complicate matters. We return to these unresolved
issues in Section 7.
</bodyText>
<page confidence="0.999151">
313
</page>
<note confidence="0.395901">
Computational Linguistics Volume 25, Number 3
</note>
<tableCaption confidence="0.6554522">
Table 1
Cf ranking by grammatical roles.
subject &gt; object(s) &gt; other(s)
Table 2
Transition types.
</tableCaption>
<equation confidence="0.725710666666667">
Cb(U) = Cp(U,)
Cb(L11) Cp(U,)
Cb(L11) = Cb(Ui_i) Cb(U,) Cb(111_1)
</equation>
<sectionHeader confidence="0.708770666666667" genericHeader="introduction">
CONTINUE SHIFT
RETAIN
3. The Centering Model
</sectionHeader>
<bodyText confidence="0.98994170967742">
The centering model (Grosz, Joshi, and Weinstein 1983, 1995) is intended to describe
the relationship between local coherence and the use of referring expressions. The
model requires two constructs, a single backward-looking center and a list of forward-
looking centers, as well as a few rules and constraints that govern the interpretation
of centers. It is assumed that discourses are composed of constituent segments (Grosz
and Sidner 1986), each of which consists of a sequence of utterances. Each utterance L/i
in a given discourse segment DS is assigned a list of forward-looking centers, Cf(DS,
Ui), and a unique backward-looking center, Cb(DS, Lb). The forward-looking centers
of U, depend only on the discourse entities that constitute the ith utterance; previous
utterances provide no constraints on Cf(DS, U,). A ranking imposed on the elements
of the Cf reflects the assumption that the most highly ranked element of Cf(DS, LJ),
the preferred center Cp(DS, Lli), will most likely be the Cb(DS, U,+1). The most highly
ranked element of Cf(DS, LJ) that is finally realized in Ui+i (i.e., is associated with an
expression that has a valid interpretation in the underlying semantic representation)
is the actual Cb(DS, U,±1). Since in this paper we will not discuss the topics of global
coherence and discourse macro segmentation (for recent treatments of these issues,
see Hahn and Strube [1997] and Walker [1998]), we assume a priori that any centering
data structure is assigned an utterance in a given discourse segment and simplify the
notation of centers to Cb(U1) and Cf(L/i).
Grosz, Joshi, and Weinstein (1995) state that the items in the Cf list have to be
ranked according to a number of factors including grammatical role, text position, and
lexical semantics. As far as their discussion of concrete English discourse phenomena
is concerned, they nevertheless restrict their ranking criteria to those solely based on
grammatical roles, which we repeat in Table 1.
The centering model, in addition, defines transition relations across pairs of adja-
cent utterances (Table 2). These transitions differ from each other according to whether
backward-looking centers of successive utterances are identical or not, and, if they are
identical, whether they match the most highly ranked element of the current forward-
looking center list, the Cp(Ui), or not.
Grosz, Joshi, and Weinstein (1995) also define two rules on center movement and
realization:
</bodyText>
<page confidence="0.998091">
314
</page>
<figure confidence="0.441339">
Strube and Hahn Functional Centering
clauses
tensed untensed
embedded same-level
inaccessible accessible, less salient
direct speech non-report complements
reported speech relative clauses
</figure>
<figureCaption confidence="0.834867">
Figure 1
Kameyama&apos;s intrasentential centering categorization.
</figureCaption>
<subsectionHeader confidence="0.696559">
Rule 1
</subsectionHeader>
<bodyText confidence="0.9808415">
If any element of Cf(u) is realized by a pronoun in U,+1, then the Cb(U11) must be
realized by a pronoun also.
</bodyText>
<subsectionHeader confidence="0.900434">
Rule 2
</subsectionHeader>
<bodyText confidence="0.998690083333333">
Sequences of continuation are to be preferred over sequences of retaining; and se-
quences of retaining are to be preferred over sequences of shifting.
Rule 1 states that no element in an utterance can be realized by a pronoun unless
the backward-looking center is realized by a pronoun, too. This rule is intended to
capture one function of the use of pronominal anaphors—a pronoun in the Cb signals
to the hearer that the speaker is continuing to refer to the same discourse. Rule 2
should reflect the intuition that a pair of utterances that have the same theme is more
coherent than another pair of utterances with more than one theme. The theory claims,
above all, that to the extent that a discourse adheres to these rules and constraints,
its local coherence will increase and the inference load placed upon the hearer will
decrease.
The basic unit for which the centering data structures are generated is the utter-
ance U. Since Grosz, Joshi, and Weinstein (1995) and Brennan, Friedman, and Pollard
(1987) do not give a reasonable definition of utterance, we follow Kameyama&apos;s (1998)
method for dividing a sentence into several center-updating units (Figure 1). Her in-
trasentential centering mechanisms operate at the clause level. While tensed clauses
are defined as utterances on their own, untensed clauses are processed with the main
clause so that the Cf list of the main clause contains the elements of the untensed
embedded clause. Kameyama further distinguishes, for tensed clauses, between se-
quential and hierarchical centering. Except for direct and reported speech (embed-
ded and inaccessible to the superordinate level), nonreport complements, and relative
clauses (both embedded but accessible to the superordinate level; less salient than the
higher levels), all other types of tensed clauses build a chain of utterances at the same
level.
</bodyText>
<subsectionHeader confidence="0.99996">
3.1 A Centering Algorithm for Anaphora Resolution
</subsectionHeader>
<bodyText confidence="0.9995135">
Though the centering model was not originally intended to be used as a blueprint
for anaphora resolution,&apos; several applications tackling this problem have made use of
</bodyText>
<sectionHeader confidence="0.508435" genericHeader="method">
5 Aravind Joshi, personal communication.
</sectionHeader>
<page confidence="0.997711">
315
</page>
<note confidence="0.395554">
Computational Linguistics Volume 25, Number 3
</note>
<tableCaption confidence="0.8010265">
Table 3
Basic centering algorithm.
</tableCaption>
<listItem confidence="0.9658204">
1. If a pronoun in LI, is encountered, test the elements of the Cf(Lii_i) in the given order
until an element under scrutiny satisfies all the required morphosyntactic, binding,
and sortal criteria. This element is chosen as the antecedent of the pronoun.
2. When utterance U, is completely read, compute Cb(U) and generate Cf(U,); rank the
elements according to agreed-upon preference criteria (such as the ones from Table 1).
</listItem>
<bodyText confidence="0.880436714285714">
the model, nevertheless. One interpretation is due to Brennan, Friedman, and Pollard
(1987) who utilize Rule 2 for computing preferences for antecedents of pronouns (see
Section 3.2). In this section, we will specify a simple algorithm that uses the Cf list
directly for providing preferences for the antecedents of pronouns.
The algorithm (which we will refer to as the basic algorithm; Table 3) consists of
two steps, which are triggered independently.
We may illustrate this algorithm by referring to the text fragment in example (2):6
</bodyText>
<subsectionHeader confidence="0.801271">
Example 2
</subsectionHeader>
<bodyText confidence="0.837735">
a. The sentry was not dead.
</bodyText>
<listItem confidence="0.950167">
b. He was, in fact, showing signs of reviving ...
c. He was partially uniformed in a cavalry tunic.
d. Mike stripped this from him and donned it.
e. He tied and gagged the man, . . .
</listItem>
<bodyText confidence="0.997741857142857">
Table 4 gives the centering analysis for this text fragment using the algorithm
from Table 3.7 Since (2a) is the first sentence in this fragment, it has no Cb. In (2b) and
in (2c) the discourse entity SENTRY is referred to by the personal pronoun he. Since
we assume a Cf ranking by grammatical roles in this example, SENTRY is ranked
highest in these sentences (the pronoun always appears in subject position). In (2d),
the discourse entity MIKE is introduced by a proper name in subject position. The
pronoun him is resolved to the most highly ranked element of Cf(2c), namely SENTRY.
Since Mike occupies the subject position, it is ranked higher in the Cf(2d) than SENTRY.
Therefore the pronoun he in (2e) can be resolved correctly to MIKE.
This example not only illustrates anaphora resolution using the basic algorithm
from Table 3 but also incorporates the application of Rule 1 of the centering model.
(2d) contains the pronoun him, which is the Cb of this utterance. In (2e), the Cb is also
realized as a pronoun while SENTRY is realized by the definite noun phrase the man,
which is allowed by Rule 1.
</bodyText>
<subsectionHeader confidence="0.999959">
3.2 The BFP Algorithm
</subsectionHeader>
<bodyText confidence="0.999693">
The centering algorithm described by Brennan, Friedman, and Pollard (1987, hence-
forth BFP algorithm) interprets the centering model in a certain way and applies it
to the resolution of pronouns. The most obvious difference between Grosz, Joshi, and
</bodyText>
<footnote confidence="0.9329445">
6 With slight simplifications taken from the Brown Corpus cn03.
7 In the subsequent tables illustrating centering data, discourse entities, a notion at the representational
level, are denoted by SMALLCAPS and appear on the left side of the colon, while the corresponding
surface expressions, at the level of linguistic data, appear on the right side of the colon.
</footnote>
<page confidence="0.994813">
316
</page>
<figure confidence="0.281252">
Functional Centering
Strube and Hahn
</figure>
<tableCaption confidence="0.812460333333333">
Table 4
Analysis for the text fragment in Example 2 according to
the basic centering algorithm.
</tableCaption>
<table confidence="0.999788133333333">
The sentry was not dead.
Cb: —
Cf: [SENTRY: sentry]
He was, in fact, showing signs of reviving ...
Cb: SENTRY: he
Cf: [SENTRY: he, SIGNS: signs]
He was partially uniformed in a cavalry tunic.
Cb: SENTRY: he
Cf: [SENTRY: he, TUNIC: tunic]
Mike stripped this from him and donned it.
Cb: SENTRY: him
Cf: [MIKE: Mike, TUNIC: this, it, SENTRY: him]
He tied and gagged the man, . . .
Cb: MIKE: he
Cf: [MIKE: he, SENTRY: the man]
</table>
<tableCaption confidence="0.997678">
Table 5
</tableCaption>
<bodyText confidence="0.887055">
Transition types according to BFP.
</bodyText>
<equation confidence="0.998092777777778">
Cb(111) = Cb(U,_1)
OR Cb(U1_1) undef.
Cb(U1) Cb(U,_1)
Cb(U) = Cp(U,)
SMOOTH-SHIFT
CONTINUE
ROUGH-SHIFT
RETAIN
Cb(U) Cp(U,)
</equation>
<bodyText confidence="0.999871181818182">
Weinstein (1983, 1995) and Brennan, Friedman, and Pollard (1987) is that the latter
use two SHIFT transitions instead of only one: SMOOTH-SHIFT8 requires the Cb(U) to
equal Cp(U,), while ROUGH-SHIFT requires inequality (Table 5). Brennan, Friedman,
and Pollard (1987) also allow the Cb(Liz_i) to remain undefined.
Brennan, Friedman, and Pollard (1987) extend the ordering constraints in Cf in
the following way: &amp;quot;We rank the items in Cf by obliqueness of grammatical relations
of the subcategorized functions of the main verb: that is, first the subject, object, and
object2, followed by other subcategorized functions, and finally, adjuncts.&amp;quot; (p. 156). In
order to apply the centering model to pronoun resolution, they use Rule 2 in making
predictions for pronominal reference and redefine the rules as follows (quoting Walker,
Iida, and Cote [1994]):
</bodyText>
<subsectionHeader confidence="0.921716">
Rule 1&apos;
</subsectionHeader>
<bodyText confidence="0.938661">
If some element of Cf(Ui_i) is realized as a pronoun in U„ then so is Cb(U,).
</bodyText>
<page confidence="0.587531">
8 Brennan, Friedman, and Pollard (1987) call these transitions SHIFTING and SHIFTING-1. The more
</page>
<bodyText confidence="0.639724">
figurative names were introduced by Walker, Iida, and Cote (1994).
</bodyText>
<page confidence="0.995236">
317
</page>
<note confidence="0.390292">
Computational Linguistics Volume 25, Number 3
</note>
<tableCaption confidence="0.940225">
Table 6
</tableCaption>
<bodyText confidence="0.558144">
BFP-algorithm.
</bodyText>
<listItem confidence="0.997270416666667">
1. Generate possible Cb-Cf combinations. In this step, all (plausible and implausible)
assignments of pronouns to elements of the previous Cf are computed.
2. Filter by constraints, e.g., contra-indexing, sortal predicates, centering rules and
constraints. This way, possible antecedents are filtered out because of morphosyntactic,
binding, and semantic criteria. Also the realization of noun phrases in the current
utterance (e.g., realization as a pronoun vs. realization as a definite noun phrase or
proper name) comes into play.
3. Rank by transition orderings. This is the step, where the pragmatic constraints of
centering apply. Basically, CONTINUE transitions are preferred, i.e., the antecedent of a
pronoun is more likely to turn up as the Cb of the previous utterance than any other
element of the Cf. In certain configurations, the algorithm includes a preference for
parallelism in linguistic constructions.
</listItem>
<subsectionHeader confidence="0.862759">
Rule 2&apos;
</subsectionHeader>
<bodyText confidence="0.999413272727273">
Transition states are ordered. CONTINUE is preferred to RETAIN is preferred to SMOOTH-
SHIFT is preferred to ROUGH-SHIFT.
Their algorithm (Table 6) consists of three basic steps (as described by Walker, Iida,
and Cote [1994]).9
In order to illustrate this algorithm, we use example (2) from above and supply the
corresponding Cb/Cf data in Table 7. Let us focus on the interpretation of utterance
(2e) where the centering data diverges when one compares the basic and the BFP
algorithms. After step 2 (filtering), the algorithm has produced two readings, which
are rated by the corresponding transitions in step 3. Since SMOOTH-SHIFT is preferred
over ROUGH-SHIFT, the pronoun he is resolved to MIKE, the highest-ranked element of
Cf(2d). Also, Rule 1 would be violated in the rejected reading.
</bodyText>
<subsectionHeader confidence="0.696698">
4. Principles of Functional Centering
</subsectionHeader>
<bodyText confidence="0.999956666666667">
The crucial point underlying functional centering is to relate the ranking of the forward-
looking centers and the information structure of the corresponding utterances. Hence,
a proper correspondence relation between the basic centering data structures and the
relevant functional notions has to be established and formally rephrased in terms
of the centering model. In this section, we first discuss two studies in which the
information structure of utterances is already integrated into the centering model
(Rambow 1993; Hoffman 1996, 1998). Using these proposals as a point of depar-
ture, we shall develop our own proposal—functional centering (Strube and Hahn
1996).
</bodyText>
<subsectionHeader confidence="0.998312">
4.1 Integrating Information Structure and Centering
</subsectionHeader>
<bodyText confidence="0.999928666666667">
As far as the centering model is concerned, the first account involving information
structure criteria was given by Kameyama (1986) and further refined by Walker,
Iida, and Cote (1994) in their study on the use of zero pronouns and topic mark-
</bodyText>
<footnote confidence="0.963403333333333">
9 Walker, Iida, and Cote (1994) note that it is possible to improve the computational efficiency of the
algorithm by interleaving generating, filtering, and ranking steps; cf. the version of the algorithm
described by Walker (1998).
</footnote>
<page confidence="0.99469">
318
</page>
<note confidence="0.880435">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.949623333333333">
Table 7
Centering analysis for the text fragment in example (2) according to the
BFP algorithm.
</tableCaption>
<table confidence="0.989775944444444">
The sentry was not dead. —
Cb:—
Cf: [SENTRY: sentry]
He was, in fact, showing signs of reviving ... CONTINUE
Cb: SENTRY: he
Cf: [SENTRY: he, SIGNS: signs]
He was partially uniformed in a cavalry tunic. CONTINUE
Cb: SENTRY: he
Cf: [SENTRY: he, TUNIC: tunic]
Mike stripped this from him and donned it. RETAIN
Cb: SENTRY: him
Cf: [MIKE: Mike, TUNIC: this, it, SENTRY: him]
He tied and gagged the man, . . . SMOOTH-SHIFT
Cb: MIKE: he
Cf: [MIKE: he, SENTRY: the man]
Cb. MIKE. tJtit
ROUGH-SHIFT
Cf: [SENTRY. he, MIKE. the &apos;ma]
</table>
<bodyText confidence="0.999414724137931">
ers in Japanese. This led them to augment the grammatical ranking conditions for the
forward-looking centers by additional functional notions.
A deeper consideration of information structure principles and their relation to
the centering model has been proposed in two studies concerned with the analysis of
German and Turkish discourse. Rambow (1993) was the first to apply the centering
methodology to German, aiming at the description of information structure aspects
underlying scrambling and topicalization. As a side effect, he used centering to define
the utterance&apos;s theme and rheme in the sense of the functional sentence perspective
(FSP) (Firbas 1974). Viewed from this perspective, the theme/rheme-hierarchy of utter-
ance 11, is determined by the Cf(Ui_i). Elements of Ui that are contained in Cf(Lli_i) are
less rhematic than those not contained in Cf(Ui_i). He then concludes that the Cb(U)
must be the theme of the current utterance. Rambow does not exploit the information
structure of utterances to determine the Cf ranking but formulates it on the basis of
linear textual precedence among the relevant discourse entities.
In order to analyze Turkish texts, Hoffman (1996, 1998) distinguishes between
the information structure of utterances and centering, since both constructs are as-
signed different functions for text understanding. A hearer exploits the information
structure of an utterance to update his discourse model, and he applies the center-
ing constraints in order to connect the current utterance to the previous discourse.
Hoffman describes the information structure of an utterance in terms of topic (theme)
and comment (rheme). The comment is split again into focus and (back)ground (see
also Vallduvi [1990] and Vallduvi and Engdahl [1996]). Based on previous work about
Turkish, Hoffman argues that, in this language, the sentence-initial position corre-
sponds to the topic, the position that immediately precedes the verb yields the focus,
and the remainder of the sentence is to be considered the (back)ground. Further-
more, Hoffman relates this notion of information structure of utterances to center-
ing, claiming that the topic corresponds to the Cb in most cases—with the excep-
tion of segment-initial utterances, which do not have a Cb. Hoffman does not say
anything about the relation between information structure and the ranking of the
</bodyText>
<page confidence="0.99224">
319
</page>
<note confidence="0.427229">
Computational Linguistics Volume 25, Number 3
</note>
<bodyText confidence="0.9992965">
Cf list. In her approach, this ranking is achieved by thematic roles (see also Turan
[1998]).
Both Rambow (1983) as well as Hoffman (1996, 1998) argue for a correlation be-
tween the information structure of utterances and centering. Both of them find a cor-
respondence between the Cb and the theme or the topic of an utterance. They refrain,
however, from establishing a strong link between the information structure and center-
ing as we suggest in our model, one that mirrors the influence of information structure
in the way the forward-looking centers are actually ranked.
</bodyText>
<subsectionHeader confidence="0.999339">
4.2 Functional Centering
</subsectionHeader>
<bodyText confidence="0.999875461538462">
Grosz, Joshi, and Weinstein (1995) admit that several factors may have an influence
on the ranking of the Cf but limit their exposition to the exploitation of grammatical
roles only. We diverge from this proposal and claim that, at least for languages with
relatively free word order (such as German), the functional information structure of
the utterance is crucial for the ranking of discourse entities in the Cf list. Originally,
in Strube and Hahn (1996), we defined the Cf ranking criteria in terms of context-
boundedness. In this paper, we redefine the functional Cf ranking criteria by making
reference to Prince&apos;s work on the assumed familiarity of discourse entities (Prince
1981) and information status (Prince 1992). The term context-bound in Strube and
Hahn (1996) corresponds to the term evoked used by Prince!&apos;
We briefly list the major claims of our approach to centering. In the following
sections, we elaborate on these claims, in particular the ranking of the forward-looking
centers.
</bodyText>
<listItem confidence="0.961880142857143">
• The elements of the Cf list are ordered according to their information
status. Hearer-old discourse entities are ranked higher than hearer-new
discourse entities. The order of the elements of the Cf list for U, provides
the preference for the interpretation of anaphoric expressions in
• The first element of the Cf(L/i), the preferred center, Cp(11,), is the
discourse entity the utterance U, is &amp;quot;about.&amp;quot; In other words, the Cp is the
center of attention.
</listItem>
<bodyText confidence="0.99981025">
In contrast to the BFP algorithm, the model of functional centering requires neither
a backward-looking center, nor transitions, nor transition ranking criteria for anaphora
resolution. For text interpretation, at least, functional centering also makes no com-
mitments to further constraints and rules.
</bodyText>
<subsectionHeader confidence="0.999873">
4.3 Cf Ranking Criteria in Functional Centering
</subsectionHeader>
<bodyText confidence="0.951619615384615">
In this section, we introduce the functional Cf ranking criteria. We first describe a basic
version, which is valid for a wide range of text genres in which pronominal reference
is the predominant text phenomenon. This is the type of discourse to which centering
was mainly applied in previous approaches (see, for example, Walker&apos;s [1989] or Di
Eugenio&apos;s [1998] test sets). We then describe the extended version of the functional
Cf ranking constraints. The two versions differ with respect to the incorporation of (a
subset of) inferables in the second version and, hence, with respect to the requirements
10 In Strube and Hahn (1996), we assumed that the information status of a discourse entity has the main
impact on its salience. In particular, evoked discourse entities were ranked higher in the Cf list than
brand-new discourse entities (using Prince&apos;s terminology). We also restricted the category of the most
salient discourse entities to evoked (i.e., context-bound) discourse entities. In this article, we extend this
category to hearer-old discourse entities, which includes, besides evoked discourse entities, unused
ones (again, referring to Prince&apos;s terminology).
</bodyText>
<page confidence="0.986633">
320
</page>
<note confidence="0.782854">
Strube and Hahn Functional Centering
</note>
<figureCaption confidence="0.974184">
Figure 2
</figureCaption>
<bodyText confidence="0.969892945945946">
Information status and familiarity (basic version).
relating to the availability of world knowledge, which is needed to properly account
for inferables. The extended version assumes a detailed treatment of a particular sub-
set of inferables, so-called functional anaphora (in Hahn, Markert, and Strube [19961,
functional anaphora are referred to as textual ellipses). We claim that the extended
version of ranking constraints is necessary to analyze texts from certain genres, e.g.,
texts from technical or medical domains. In these areas, pronouns are used rather in-
frequently, while functional anaphors are the major text phenomena to achieve local
coherence.
4.3.1 Basic Cf Ranking. Usually, the Cf ranking is represented by an ordering relation
on a single set of elements, e.g., grammatical relations (as in Table 1). We use a layered
representation for our criteria. For the basic Cf ranking criteria, we distinguish between
two different sets of expressions, hearer-old discourse entities in LI, (OLD) and hearer-
new discourse entities in U, (NEW). These sets can be further split into the elements
of Prince&apos;s (1981, 245) familiarity scale. The set of hearer-old discourse entities (OLD)
consists of evoked (E) and unused (U) discourse entities, while the set of hearer-new
discourse entities (NEW) consists of brand-new (BN) discourse entities. For the basic
Cf ranking criteria, it is sufficient to assign inferable (I), containing inferable (IC),
and anchored brand-new (BNA) discourse entities to the set of hearer-new discourse
entities (NEW).11 See Figure 2 for an illustration of Prince&apos;s familiarity scale and its
relation to the two sets. Note that the elements of each set are indistinguishable with
respect to their information status. Evoked and unused discourse entities, for example,
have the same information status because they belong to the set of hearer-old discourse
entities. So the basic Cf ranking in Figure 2 boils down to the preference of OLD
discourse entities over NEW ones.
For an operationalization of Prince&apos;s terms, we state that evoked discourse en-
tities are simply cospecifying (resolved anaphoric) expressions, i.e., pronominal and
nominal anaphora, relative pronouns, previously mentioned proper names, etc. Un-
used discourse entities are proper names and titles. In texts, brand-new proper names
are usually accompanied by a relative clause or an appositive that relates them to
the hearer&apos;s knowledge. The corresponding discourse entity is evoked only after this
elaboration. Whenever these linguistic devices are missing, we treat proper names as
unused.&apos; In the following, we give some examples of evoked, unused, and brand-new
11 Quoting Prince (1992, 305): &amp;quot;Inferrables are like Hearer-new (and, therefore, Discourse-new) entities in
that the hearer is not expected to already have in his/her head the entity in question.&amp;quot;
12 For examples of brand-new proper names and how they are introduced, see, for example, the
beginning of articles in the &amp;quot;obituaries&amp;quot; section of the New York Times.
</bodyText>
<page confidence="0.986116">
321
</page>
<note confidence="0.40136">
Computational Linguistics Volume 25, Number 3
</note>
<bodyText confidence="0.802169">
discourse entities, though in naturally occurring texts these phenomena rarely show
up unadulterated.&apos; The remaining categories will be explained subsequently.
Example 3
</bodyText>
<listItem confidence="0.913509">
a. He lived his final nine years in one of [two rent-subsidized bui/dings]BN
constructed especially for elderly survivors.
b. When the [buildings]E opened — one in 1964, one in 1970 — there were
waiting lists.
c. Once, [they]E held 333 survivors.
</listItem>
<bodyText confidence="0.9861579">
In example (3a), buildings is introduced as a discourse-new discourse entity, which
is brand-new (BN). In (3b), the definite NP the buildings cospecifies the discourse entity
from (3a). Hence, buildings in (3b) is evoked (E), just as is they in (3c).
Certain proper names are assumed to be known by any hearer. Therefore, these
proper names need no further explanation. Winnie Madikizela Mandela in example (4)
is unused (U), i.e., it is discourse-new but hearer-old. Other proper names have to be
introduced because they are discourse-new and hearer-new. In example (5), Marianne
Kador is introduced by means of a lengthy appositive that relates the brand-new proper
name to the knowledge of the hearer. In particular, the noun phrase the apartment
buildings is discourse-old (see example (3)).
</bodyText>
<subsectionHeader confidence="0.692752">
Example 4
</subsectionHeader>
<bodyText confidence="0.989427">
[A defiant Winnie Madikizela Mandela]u testified for more than 10 hours
today, dismissing all evidence that ...
</bodyText>
<subsectionHeader confidence="0.566176">
Example 5
</subsectionHeader>
<bodyText confidence="0.999966">
&amp;quot;He was an undervalued person all his life,&amp;quot; said Marianne Kador, a
social worker for Selthelp Community Services, which operates the
apartment buildings in Queens.
In Table 8, we define various sets, which are used for the specification of the Cf
ranking criteria in Table 9. We distinguish between two different sets of discourse
entities, hearer-old discourse entities (OLD) and hearer-new discourse entities (NEW).
For any two discourse entities (x, pos x) and (y, posy), with x and y denoting the
linguistic surface expression of those entities as they occur in the discourse, and posx
and posy indicating their respective text position, posx 0 posy, in Table 9 we define the
basic ordering constraints on elements in the forward-looking centers Cf(Ui). For any
utterance U, the ordering of discourse entities in the Cf(U) that can be derived from
the above definitions and the ordering constraints (1) to (3) are denoted by the relation
Ordering constraint (1) characterizes the basic relation for the overall ranking of the
elements in the Cf. Accordingly, any hearer-old expression in utterance LI, is given the
highest preference as a potential antecedent for an anaphoric expression in U1±1. Any
</bodyText>
<footnote confidence="0.5475488">
13 Examples (3) and (5)—(8) are from the New York Times, Dec. 11, 1997. (&amp;quot;Remembering one who
remembered. Eugen Zuckermann, survivor, kept the ghosts of the holocaust alive,&amp;quot; by Barry Bearak.)
Example (4) is from the New York Times, Dec. 1, 1997. (&amp;quot;Winnie Mandela is defiant, calling accusations
&apos;lunacy&apos;,&amp;quot; by Suzanne Daley.) We split complex sentences into the units specified by Kameyama (1998)
following the categorization in Figure 1.
</footnote>
<page confidence="0.990756">
322
</page>
<note confidence="0.871133">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.702055111111111">
Table 8
Sets of discourse entities for the basic Cf ranking.
DE the set of discourse entities in Ili
the set of evoked discourse entities in LI,
the set of unused discourse entities in LT,
OLD := E U U
NEW := DE — OLD
Table 9
Basic functional ranking constraints on the Cf list.
</tableCaption>
<listItem confidence="0.997922">
1. If x E OLD and y E NEW, then x y.
2. If x, y E OLD or x,y E NEW, then x y, if posx &lt; posy
3. If (1) or (2) do not apply, then x and y are unordered with respect to the Cf-ranking.
</listItem>
<bodyText confidence="0.989940692307692">
hearer-new expression is ranked below hearer-old expressions. Ordering constraint (2)
captures the ordering for the sets OLD or NEW when they contain elements of the
same type. In this case, the elements of each set are ranked according to their text
position.
4.3.2 Extended Cf Ranking. While the basic Cf ranking criteria are sufficient for texts
with a high proportion of pronouns and nominal anaphora (e.g., literary texts, news-
paper articles about persons), it is necessary to refine the ranking criteria in order to
deal with expository texts, e.g., test reports, discharge summaries. These texts usually
contain few pronouns and are characterized by a large number of inferrables, which
are often the major glue in achieving local coherence. In order to accommodate the
centering model to texts from these genres, we distinguish a third set of expressions;
mediated discourse entities in U, (MED). On Prince&apos;s (1981) familiarity scale, the set
of hearer-old discourse entities (OLD) remains the same as before, i.e., it consists of
evoked (E) and unused (U) discourse entities, while the set of hearer-new discourse
entities (NEW) now consists only of brand-new (BN) discourse entities. Inferable (I),
containing inferable (IC), and anchored brand-new (BNA) discourse entities, which
make up the set of mediated discourse entities, have a status between hearer-old and
hearer-new discourse entities.&apos; See Figure 3 for Prince&apos;s familiarity scale and its rela-
tion to the three sets. Again, the elements of this set are indistinguishable with respect
to their information status—for instance, inferable and anchored brand-new discourse
entities have the same information status because they belong to the set of mediated
discourse entities. Hence, the extended Cf ranking, depicted in Figure 3, will prefer
OLD discourse entities over MEDiated ones, and MEDiated ones will be preferred
over NEW ones.
We assume that the difference between containing inferables and anchored brand-
new discourse entities is negligible. (It was not well defined in Prince [1981] and in
</bodyText>
<footnote confidence="0.75302275">
14 Again, quoting Prince (1992, 305-306): &amp;quot;Inferrables are thus like Hearer-old entities in that they rely on
certain assumptions about what the hearer does know, e.g. that buildings typically have doors [.. .1,
and they are like Discourse-old entities in that they rely on there being already in the discourse-model
some entity to trigger the inference [.. .1.&amp;quot;
</footnote>
<page confidence="0.996358">
323
</page>
<figure confidence="0.824352">
Computational Linguistics Volume 25, Number 3
</figure>
<figureCaption confidence="0.959964">
Figure 3
</figureCaption>
<bodyText confidence="0.978290166666667">
Information status and familiarity (refined version).
Prince [1992] she abandoned the second term.) Therefore, we conflate them into the
category of anchored brand-new discourse entities. These discourse entities require
that the anchor modifies a brand-new head and that the anchor is either an evoked
or an unused discourse entity. In the following, we give examples of inferrables and
anchored brand-new discourse entities.
</bodyText>
<footnote confidence="0.466627">
Example 6
</footnote>
<listItem confidence="0.950514333333333">
a. By his teen-age years, the distorted mentality of anti-Semitism was in full
warp.
b. [The familyli was expelled to Hungary in 1939 ...
</listItem>
<bodyText confidence="0.9993146">
In example 6 the relation between the definite NP the family and the context has
to be inferred, therefore the family belongs to the category inferable (I). It is marked
by definiteness but it is not anaphoric since there is no anaphoric antecedent. Though
inferables are often marked by definiteness, it is possible that they are indefinite, like
an uncle in example (7b).
</bodyText>
<figure confidence="0.675941375">
Example 7
a. He shared this bounty with his father
b. but [a sickly unclell was left to remain hungry.
Anchored brand-new (BNA) discourse entities as in example (8) are heads of
phrases whose modifiers relate (anchor) them to the context.
Example 8
a. He had already lost too many companions.
b. [[His] E fiancée]BNA had died in a car wreck.
</figure>
<bodyText confidence="0.9997536">
With respect to inferables, there exist only a few computational treatments, all
of which are limited in scope. We here restrict inferables to the particular subset de-
fined by Hahn, Markert, and Strube (1996), which we call functional anaphora (FA).
In the following, we will limit our discussion of inferables to those which figure as
functional anaphors. In Table 10, we define the sets needed for the specification of
the extended Cf ranking criteria in Table 11. We distinguish between three different
sets of discourse entities; hearer-old discourse entities (OLD), mediated discourse en-
tities (MED), and hearer-new discourse entities (NEW). Note that the antecedent of a
functional anaphor (the inferred discourse entity) is included in the set of hearer-old
discourse entities.
</bodyText>
<page confidence="0.995612">
324
</page>
<note confidence="0.915796">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.994702">
Table 10
</tableCaption>
<bodyText confidence="0.599405714285714">
Sets of discourse entities for the extended Cf ranking.
DE the set of discourse entities in
the set of evoked discourse entities in 111
the set of unused discourse entities in Ul
FAante the set of antecedents of functional anaphors in 1/1
FA the set of functional anaphors in LI,
BNA the set of anchored brand-new discourse entities in LI,
</bodyText>
<equation confidence="0.779324333333333">
OLD := E U U u FAante
MED := FA U BNA
NEW := DE — (MED U OLD)
</equation>
<tableCaption confidence="0.921187">
Table 11
</tableCaption>
<bodyText confidence="0.395735">
Extended functional ranking constraints on the Cf list.
</bodyText>
<listItem confidence="0.9756886">
1. If x E OLD and y E MED, then x y.
If x E OLD and y E NEW, then x y.
If x E MED and y E NEW, then x y.
2. If x, y E OLD, or x, y E MED, or x,y E NEW, then x y, if posx &lt; posy
3. If (1) or (2) do not apply, then x and y are unordered with respect to the Cf-ranking.
</listItem>
<bodyText confidence="0.999913045454545">
For any two discourse entities (x, posx) and (y, posy), with x and y denoting the
linguistic surface expression of those entities as they occur in the discourse, and posx
and posy indicating their respective text position, posx posy, in Table 11 we define the
extended functional ordering constraints on elements in the forward-looking centers
Cf(Llt). In the following, for any utterance 1.11, the ordering of discourse entities in the
Cf(u) that can be derived from the above definitions and the ordering constraints (1)
to (3) are denoted by the relation &amp;quot;-&amp;quot;.
Ordering constraint (1) characterizes the basic relation for the overall ranking
of the elements in the Cf. Accordingly, any hearer-old expression in utterance U, is
given the highest preference as a potential antecedent for an anaphoric or functional
anaphoric expression in 111±1. Any mediated expression is ranked just below hearer-
old expressions. Any hearer-new expression is ranked lowest. Ordering constraint (2)
fixes the ordering when the sets OLD, MED, or NEW contain elements of the same
type. In these cases, the elements of each set are ranked according to their text position.
In Table 12 we show the analysis of text fragment (2) using the basic algorithm see
Table 3) with the basic functional Cf ranking constraints (see Table 9). The fragment
starts with the evoked discourse entity SENTRY in (2a) (the definiteness of the NP
indicates that it was already mentioned earlier in the text). The pronouns he in (2b)
and (2c) are evoked, while signs and tunic are brand-new. We assume Mike in (2d) to
be evoked, too (MIKE is the main character of that story). MIKE is the leftmost evoked
discourse entity in (2d), hence ranked highest in the Cf(2d) and the most preferred
antecedent for the pronoun he in (2e).
</bodyText>
<sectionHeader confidence="0.990914" genericHeader="method">
5. Evaluation
</sectionHeader>
<bodyText confidence="0.998983">
In this section, we discuss two evaluation experiments on naturally occurring data.
We first compare the success rate of the functional centering algorithm with that of
the BFP algorithm. This evaluation uses the basic Cf ranking constraints from Table 9.
</bodyText>
<page confidence="0.993047">
325
</page>
<table confidence="0.469764">
Computational Linguistics Volume 25, Number 3
</table>
<tableCaption confidence="0.783894">
Table 12
Analysis for text fragment in example (2) according to the
model of functional centering.
</tableCaption>
<table confidence="0.9998272">
The sentry was not dead.
Cb: —
Cf: [SENTRYE: sentry]
He was, in fact, showing signs of reviving ...
Cb: SENTRYE: he
Cf: [SENTRYE: he, SIGNs:BN signs]
He was partially uniformed in a cavalry tunic.
Cb: SENTRYE: he
Cf: [SENTRYE: he, TuNicBN: tunic]
Mike stripped this from him and donned it.
Cb: SENTRYE: him
Cf: [MIKEE: Mike, TumcE: this, it, SENTRYE: him]
He tied and gagged the man, . . .
Cb: MIKEE: he
Cf: [MIKEE: he, SENTRY:E the man]
</table>
<bodyText confidence="0.92311">
We then introduce a new cost-based evaluation method, which we use for comparing
the extended Cf ranking constraints from Table 11 with several other approaches.
</bodyText>
<subsectionHeader confidence="0.99183">
5.1 Success Rate Evaluation
</subsectionHeader>
<bodyText confidence="0.928118714285714">
5.1.1 Data. In order to compare the functional centering algorithm (i.e., the basic al-
gorithm from Table 3 operating with the basic functional Cf ranking constraints from
Table 9) with the BFP algorithm, we analyzed a sample of English and German texts.
The test set (Table 13) consisted of the begirmings of three short stories by Ernest
Hemingway,&apos; three articles from the New York Times (NYT),16 the first three chapters of
a novel by Uwe Johnson,&apos; the first two chapters of a short story by Heiner Muller,&apos;
and seven articles from the Frankfurter Allgemeine Zeitung (FAZ).19
</bodyText>
<table confidence="0.843708">
15 Hemingway, Ernest. 1987. The Complete Short Stories of Ernest Hemingway. Scribner, New York. (&amp;quot;An
African story,&amp;quot; pages 545-554; &amp;quot;Soldier&apos;s home,&amp;quot; pages 111-116; &amp;quot;Up in Michigan,&amp;quot; pages 59-62.)
16 (i) New York Times, Dec. 7, 1997. (&amp;quot;Shot in head, suspect goes free, then to college,&amp;quot; by Jane Fritsch,
pages A45-48.) (ii) New York Times, Dec. 1, 1997. (&amp;quot;Winnie Mandela is defiant, calling accusations
&apos;lunacy&apos;,&amp;quot; by Suzanne Daley, pages A1-12.) (iii) New York Times, Dec. 11, 1997. (&amp;quot;Remembering one who
remembered. Eugen Zuckermann, survivor, kept the ghosts of the holocaust alive,&amp;quot; by Barry Bearak,
pages B1-8.)
17 Johnson, Uwe. 1965. Zwei Ansichten. Suhrkamp Verlag, Frankfurt am Main.
18 Muller, Heiner. 1974. Geschichten aus der Prod uktion 2. Rotbuch Verlag, Berlin. (&amp;quot;Liebesgeschichte,&amp;quot;
pages 57-62.)
19 FAZ, Aug. 28, 1997. (&amp;quot;Die gute Nachricht ist: Wir konnen gewinnen. New Yorks friiherer
Polizeiprasident in Berlin,&amp;quot; by Konrad Schuller.) (ii) FAZ, Nov. 3, 1997. (&amp;quot;Biirgermeister Giuliani steht
vor eirter fast sicheren Wiederwahl,&amp;quot; by Verena Leucken.) (iii) FAZ, Sept. 9, 1997. (&amp;quot;Wir haben viel
voneirtander lemen konnen,&amp;quot; by Claus Peter Muller.) (iv) FAZ, Sept. 10, 1997. (&amp;quot;Die Mutter der
Meirtungsforschung im Streit. 1st Elisabeth Noelle-Neumann eine unverbesserliche Deutsche?&amp;quot; by Kurt
Reumann.) (v) FAZ, Aug. 4, 1997. (&amp;quot;Der zarte Riese, Geisterhaftes Klanglicht und em Zug ins Weite:
</table>
<footnote confidence="0.64008175">
Zum Tode von Swjatoslaw Richter,&amp;quot; by Gerhard R. Koch.) (vi) FAZ, Sept. 2, 1997. (&amp;quot;Glaubwiirdiger als
der Kortigssohn. Der Oppositionspolitiker Sam Rainsy kampft fiir das bessere Kambodscha,&amp;quot; by Erhard
Haubold.) (vii) FAZ, Sept. 3, 1997. (&amp;quot;Bald das Ende des Vorsitzenden Wagner? Wechsel an der Spitze
der CDU-Fraktion,&amp;quot; by Peter jochen Winters.)
</footnote>
<page confidence="0.984819">
326
</page>
<note confidence="0.909045">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.9189775">
Table 13
Test set for success rate evaluation.
</tableCaption>
<table confidence="0.99942725">
Hemingway NYT English Writers FAZ German
3rd pers. &amp; poss. pron. 274 302 576 299 320 619
sentences 153 233 386 186 394 580
words 2785 4546 7331 3195 8005 11200
</table>
<subsubsectionHeader confidence="0.756368">
5.1.2 Method. The evaluation was carried out manually by the authors, supported
</subsubsectionHeader>
<bodyText confidence="0.997432153846154">
by a small-scale discourse annotation tool. We used the following guidelines for our
evaluation: We did not assume any world knowledge as part of the anaphora resolu-
tion process. Only agreement criteria and sortal constraints were applied. We did not
account for false positives and error chains, but marked the latter (see Walker 1989).
We use Kameyama&apos;s (1998) specifications for dealing with complex sentences (for
a description, see Section 3). Following Walker (1989), a discourse segment is defined
as a paragraph unless its first sentence has a pronoun in subject position or a pronoun
whose syntactic features do not match the syntactic features of any of the preceding
sentence-internal noun phrases. Also, at the beginning of a segment, anaphora resolu-
tion is preferentially performed within the same utterance. According to the preference
for intersentential candidates in the original centering model, we defined the following
anaphora resolution strategy (which is not the best solution for the anaphora resolution
problem either, but sufficient for the purposes of the evaluation):
</bodyText>
<listItem confidence="0.9989115">
1. Test elements of Cf (LI,A—according to the BFP algorithm, or the
functional centering (henceforth abbreviated as FunC) algorithm.
2. Test elements of LIi, which precede the pronoun, left-to-right.
3. Test elements of Cf (U,_2), Cf (Ui_3), . in the given order.
</listItem>
<bodyText confidence="0.950355789473684">
Since clauses are short in general, step 2 of the algorithm only rarely applies.
5.1.3 Results. The results of our evaluation are given in Table 14. The first row gives
the number of third person pronouns and possessive pronouns in the data. The up-
per part of the table shows the results for the BFP algorithm, the lower part those
for the FunC algorithm. Overall, the data are consistently in favor of the FuncC al-
gorithm, though no significance judgments can be made (the data were not drawn
as a random sample). The overall error rate of each approach is given in the rows
labeled as &amp;quot;wrong&amp;quot;. We also tried to determine the major sources of errors (see the
nonbold sections in Table 14), and were able to distinguish three different types. One
class of errors relates to the algorithm&apos;s strategy. In the case of the BFP algorithm, the
corresponding row also contains the number of ambiguous cases generated by this
algorithm (we counted ambiguities as errors, since FunC produced only one read-
ing in these cases). A second class of errors results from error chains, mainly caused
by the strategy of each approach or by ambiguities in the BFP algorithm. A third
error class is caused by the intersentential specifications, e.g., the correct antecedent
is not accessible because it is realized in an embedded clause (reported speech). Fi-
nally, other errors were mainly caused by split antecedents (plural pronouns referring
to a couple of antecedents in singular), reference to events (or propositions), and
cataphora.
</bodyText>
<page confidence="0.986628">
327
</page>
<table confidence="0.467642">
Computational Linguistics Volume 25, Number 3
</table>
<tableCaption confidence="0.988546">
Table 14
</tableCaption>
<table confidence="0.993976866666667">
Evaluation results for success rates.
Hemingway NYT English Writers FAZ German
3rd pers. &amp; poss. pron. 274 302 576 299 320 619
correct 193 245 438 (76%) 236 227 463 74,8%
wrong 81 57 138 (24%) 63 93 156 (25,2%)
wrong (strategy) 20 8 28 10 27 37
wrong (error chains) 29 15 44 22 28 50
wrong (intersentential) 17 27 44 18 24 42
wrong (others) 15 7 22 13 14 27
correct 214 252 466 (80,9%) 248 270 518 (83,7%)
wrong 60 50 110 (19,1%) 51 50 101 (16,3%)
wrong (strategy) 8 3 11 3 3 6
wrong (error chains) 18 13 31 18 6 24
wrong (intersentential) 18 27 45 17 27 44
wrong (others) 16 7 23 13 14 27
</table>
<bodyText confidence="0.978286333333333">
5.1.4 Interpretation. While the rate of errors caused by the specifications for complex
sentences and by other reasons is almost identical (the small difference can be ex-
plained by false positives), there is a remarkable difference between the algorithms
with respect to strategic errors and error chains. Strategic errors occur whenever the
preference given by the algorithm under consideration leads to an error. Most of the
strategic errors implied by the FunC algorithm also show up as errors for the BFP
algorithm. We interpret this finding as an indication that these errors are caused by
a lack of semantic or world knowledge. The remaining errors of the BFP algorithm
are caused by the strictly local definition of its criteria and because the BFP algorithm
cannot deal with some particular configurations leading to ambiguities. The FunC al-
gorithm has fewer error chains not only because it yields fewer strategic errors, but
also because it is more robust with respect to real texts. An utterance U1, for instance,
which intervenes between Lti_i and /11+1 without any relation to Ui_i does not affect
the preference decisions in Ui+2 for FunC, although it does affect them for the BFP
algorithm, since the latter cannot assign the Cb(Ui+i). Also, error chains are sometimes
shorter in the FunC analyses.
Example (9) illustrates how the local restrictions as defined by the original cen-
tering model and the BFP algorithm result in errors and lead to rather lengthy error
chains (see Table 15 for the corresponding centering analysis). The discourse entity
SENTENCE, which is cospecified by the pronoun er,
in (9b), is the Cb(9b). There-
fore, it is the most preferred antecedent for the pronoun ihn in (9c), which causes a
strategic error. This error, in turn, is the reason for a consequent error in (9d), because
there are no semantic cues that enforce the correct interpretation, i.e., the coreferen-
tiality between ihn and Giuliani. The possible interruption of the error chain, indicated
by the alternative interpretation in (9c), is ruled out, however, by the preference for
RETAIN over ROUGH-SHIFT transitions (cf. Rule 2&apos;).
</bodyText>
<subsectionHeader confidence="0.636796">
Example 9
</subsectionHeader>
<bodyText confidence="0.942434">
a. Der Satz, mit dem Ruth Messinger eine der Fernsehdebatten im
Burgermeisterwahlkampf in New York eroffnete, wird der einzige sein,
der von ihr in Erinnerung bleibt.
</bodyText>
<page confidence="0.995346">
328
</page>
<note confidence="0.915083">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.995754">
Table 15
</tableCaption>
<table confidence="0.96900875">
BFP results for example (9).
Cb: — _
Cf: [SENTENCE: Satz, dem, der, der, RUTH: Ruth Messinger, ihr,
DEBATES: Fernsehdebatten, RACE: Biirgermeisterwahlkampf,
NEW YORK: New York, RECOLLECTION: Erinnerung]
Cb: SENTENCE: er CONTINUE
.,
Cf: [SENTENCE: er, VICTORY: Wahlsieg, GIULIANI: Rudolph Giuliani]
Cb: SENTENCE: ihn RETAIN
Cf: [NEWSPAPERS: ZeitUngen, SENTENCE: ihn, NEW YORK: Stadt]
Cb: GUILIANI. din
Stadtl
Cf: (NEWSPAPERS. Zeitungen, GIULIANI. ihn, NEW YORK.
Cb: SENTENCE: ihm RETAIN
Cf: [UNIONS: Gewerkschaften, SENTENCE: ihm]
[The sentence]&apos;,with which Ruth Messinger - one of the TV debates
</table>
<bodyText confidence="0.952020769230769">
- opened, - will - the only one - be, - which - of her - in memory -
remains.
The sentence, with which Ruth Messinger opened one of the TV debates,
will be the only one, which will be recollected of her.
b. Am nahezu sicheren Wahlsieg des Amtsinhabers Rudolph Giuliani am
Dienstag wird er nichts andern.
[Of the almost certain - victory in the election - of [the officeholder
Rudolph Giuliani]masc]andaisucnct on Tuesday - will - [itl
smuabjcect - nothing -
alter.
Of the officeholder Rudolph Giuliani&apos;s almost certain victory in the
election on Tuesday, it will alter nothing.
c. Alle Zeitungen der Stadt unterstiitzen ihn.
</bodyText>
<equation confidence="0.769172">
[All - newspapers of the city]nditaresccr-object.
subject — support — [him]
</equation>
<bodyText confidence="0.760264">
He is supported by all newspapers of the city.
</bodyText>
<listItem confidence="0.7130955">
d. Die Gewerkschaften stehen hinter ihm.
[The unions]subject - stand behind - [him]71.
</listItem>
<equation confidence="0.667363">
,flufrect—object •
</equation>
<bodyText confidence="0.98166975">
He is backed up by the unions.
The nonlocal definition of hearer-old discourse entities enables the FunC algo-
rithm to compute the correct antecedent for the pronoun ihn in (9c) preventing it from
running into an error chain (see Table 16 for the functional centering data). GIULIANI,
who was mentioned earlier in the text, is the leftmost evoked discourse entity in (9b)
and therefore the most preferred antecedent for the pronoun in (9c), though there is a
pronoun of the same gender in (9b).
We encountered problems with Kameyama&apos;s (1998) specifications for complex sen-
tences. The differences between clauses that are accessible from a higher syntactic level
and clauses that are not could not be verified by our analyses. Also, her approach is
sometimes too coarse-grained (i.e., there are still antecedents within one utterance),
and sometimes too fine-grained.&apos;
</bodyText>
<footnote confidence="0.698545">
20 An alternative to Kameyama&apos;s intrasentential centering, which overcomes these problems and leads to
</footnote>
<page confidence="0.995744">
329
</page>
<note confidence="0.530538">
Computational Linguistics Volume 25, Number 3
</note>
<tableCaption confidence="0.993812">
Table 16
</tableCaption>
<table confidence="0.978613285714286">
FunC results for example (9).
Cf: [SENTENcEE: Satz, dem, der, der, RuTHE: Ruth Messinger,
RAcEE: Biirgermeisterwahlkampf, NEW YORKE: New York,
DEBATESBNA: Fernsehdebatten, RECOLLECTIONBN: Erbil/ening]
Cf: [CduLIANIE: Rudolph Giuliani, SENTENCEE: er, VICTORYBNA: Wahlsieg]
Cf: [NEW YoREE: Stadt, GIELIANIE: ihn, NEwsPApERsBNA: Zeitungen]
Cf: [Gtuum\nE: ihm, UNioNsBN: Gewerkschaften]
</table>
<tableCaption confidence="0.7926155">
Table 17
Test set for cost-based evaluation.
</tableCaption>
<table confidence="0.9962506">
IT Spiegel Muller E
(pro)nominal anaphors 308 102 153 563
functional anaphors 294 25 20 339
sentences 451 82 87 620
words 5542 1468 867 7877
</table>
<subsectionHeader confidence="0.996447">
5.2 Cost-based Evaluation
</subsectionHeader>
<bodyText confidence="0.98737636">
5.2.1 Data. The test set for our second evaluation experiment consisted of three dif-
ferent text genres: 15 product reviews from the information technology (IT) domain,
one article from the German news magazine Der Spiegel, and the first two chapters
of a short story by the German writer Heiner Muller.&apos; Table 17 summarizes the total
number of (pro)nominal anaphors, functional anaphors, utterances and words in the
test set.
5.2.2 Method (Distribution of Transition Types). Given these sample texts, we com-
pared three approaches to the ranking of the Cf: a model whose ordering principles
are based on grammatical role indicators only (see Table 1); an &amp;quot;intermediate&amp;quot; model,
which can be considered a &amp;quot;naive&amp;quot; approach to free-word-order languages; and the
functional model based on the information structure constraints stated in Table 11. For
reasons discussed below, slightly modified versions of the naive and the grammatical
approaches will also be considered. They are characterized by the additional constraint
that antecedents of functional anaphors are ranked higher than the functional anaphors
themselves. As in Section 5.1, the evaluation was carried out manually by the authors.
Since most of the anaphors in these texts are nominal anaphors, the resolution of
which is much more restricted than that of pronominal anaphors, the success rate for
the whole anaphora resolution process is not distinctive enough for a proper evalu-
ation of the functional constraints. The reason for this lies in the fact that nominal
anaphors are far more constrained by conceptual criteria than pronominal ones. Thus,
the chance of properly resolving a nominal anaphor, even when ranked at a lower
position in the center lists, is greater than for pronominal anaphors. By shifting our
evaluation criteria away from resolution success data to structural conditions reflecting
the proper ordering of center lists (in particular, we focus on the most highly ranked
item of the forward-looking centers), these criteria are intended to compensate for the
</bodyText>
<footnote confidence="0.437390666666667">
a significant improvement in the results, is proposed in Strube (1998).
21 Muller, Heiner. 1974. Geschichten aus der Prod uktion 2. Rotbuch Verlag, Berlin. (&amp;quot;Liebesgeschichte,&amp;quot;
pages 57-62.)
</footnote>
<page confidence="0.996249">
330
</page>
<note confidence="0.934691">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.967165">
Table 18
Quantitative distribution of centering transitions.
</tableCaption>
<table confidence="0.999664666666667">
Transition Types Naive Naive &amp; Grammatical Grammatical &amp; FunC
FA&apos;&apos; &gt; FA FAan&amp;quot; &gt; FA
IT CONTINUE 49 167 102 197 309
RETAIN 269 158 226 131 25
SMOOTH-SHIFT 32 41 24 35 51
ROUGH-SHIFT 39 23 37 26 4
Spiegel CONTINUE 17 28 37 43 50
RETAIN 42 32 28 23 12
SMOOTH-SHIFT 9 9 7 8 13
ROUGH-SHIFT 7 6 3 1 0
Muller CONTINUE 31 31 32 32 36
RETAIN 19 19 18 18 15
SMOOTH-SHIFT 15 17 15 16 18
ROUGH-SHIFT 14 12 14 13 10
E CONTINUE 97 226 171 272 395
RETAIN 330 209 272 172 52
SMOOTH-SHIFT 56 67 46 59 82
ROUGH-SHIFT 60 41 54 40 14
</table>
<bodyText confidence="0.914969">
high proportion of nominal anaphora in our sample. Table 5 enumerates the types of
centering transitions we consider.
</bodyText>
<subsubsectionHeader confidence="0.598069">
5.2.3 Results (Distribution of Transition Types). In Table 18, we give the numbers
</subsubsectionHeader>
<bodyText confidence="0.992837272727273">
of centering transitions between the utterances in the three test sets. The first column
contains those generated by the naive approach (such a proposal was made by Gordon,
Grosz, and Gilliom [1993] as well as by Rambow [1993], who, nevertheless, restricts it to
the German middlefield). We simply ranked the elements of Cif according to their text
position. While it is usually assumed that the functional anaphor (FA) is ranked above
its antecedent (FAante) (Grosz, Joshi, and Weinstein 1995, 217), we assume the opposite.
The second column contains the results of this modification with respect to the naive
approach. In the third column of Table 18, we give the numbers of transitions generated
by the grammatical constraints (Table 1) stated by Grosz, Joshi, and Weinstein (1995,
214, 217). The fourth column supplies the results of the same modification as was used
for the naive approach, namely, antecedents of functional anaphors are ranked higher
than the corresponding anaphoric expressions. The fifth column shows the results
generated by the functional constraints from Table 11.
5.2.4 Interpretation (Distribution of Transition Types). The centering model assumes
a preference order among transition types—CONTINUE ranks above RETAIN and RETAIN
ranks above SHIFT. This preference order reflects the presumed inference load put on
the hearer to coherently decode a discourse. Since the functional approach generates
more CONTINUE transitions (see Table 18), we interpret this as preliminary evidence
that this approach provides for a more efficient processing than its competitors. In
particular, the observation of a predominance of CONTINUES holds irrespective of the
various text genres we considered for functional centering and, to a lesser degree, for
the modified grammatical ranking constraints.
</bodyText>
<page confidence="0.995108">
331
</page>
<note confidence="0.57945">
Computational Linguistics Volume 25, Number 3
</note>
<bodyText confidence="0.9823325">
5.2.5 Method (Costs of Transition Types). The arguments we have given so far do
not seem to be entirely convincing. Counting single occurrences of transition types,
in general, does not reveal the entire validity of the center lists. Considering adja-
cent transition pairs as an indicator of validity should give a more reliable picture,
since depending on the text genre considered (e.g., technical vs. news magazine vs.
literary texts), certain sequences of transition types may be entirely plausible though
they include transitions which, when viewed in isolation, seem to imply consider-
able inferencing load (Table 18). For instance, a CONTINUE transition that follows a
CONTINUE transition is a sequence that requires the lowest processing costs. But a
CONTINUE transition that follows a RETAIN transition implies higher processing costs
than a SMOOTH-SHIFT transition following a RETAIN transition. This is due to the fact
that a RETAIN transition ideally predicts a SMOOTH-SHIFT in the following utterance.
Hence, we claim that no one particular centering transition should be preferred over
another. Instead, we advocate the idea that certain centering transition pairs are to
be preferred over others. Following this line of argumentation, we propose here to
classify all occurrences of centering transition pairs with respect to the &amp;quot;costs&amp;quot; they
imply. The cost-based evaluation of different Cf orderings refers to evaluation criteria
that form an intrinsic part of the centering model.
Transition pairs hold for three immediately successive utterances. We distinguish
between two types of transition pairs, cheap ones and expensive ones.
</bodyText>
<listItem confidence="0.9981496">
• A transition pair is cheap if the backward-looking center of the current
utterance is correctly predicted by the preferred center of the
immediately preceding utterance, i.e., Cb(U) = Cp(U1-1)•
• A transition pair is expensive if the backward-looking center of the
current utterance is not correctly predicted by the preferred center of the
</listItem>
<bodyText confidence="0.981667692307692">
immediately preceding utterance, i.e., Cb(U) Cp(1-11-1)•
In particular, chains of the RETAIN transition in passages where the Cb does not
change (passages with constant theme) show that the grammatical ordering constraints
for the forward-looking centers are not appropriate.
5.2.6 Results (Costs of Transition Types). The numbers of centering transition pairs
generated by the different approaches are shown in Table 19. In general, the func-
tional approach reveals the best results, while the naive and the grammatical ap-
proaches work reasonably well for the literary text, but exhibit a remarkably poorer
performance for the texts from the IT domain and, to a lesser degree, from the news
magazine. The results for the latter approaches improve only slightly with the modifi-
cation of ranking the antecedent of an functional anaphor (FAante) above the functional
anaphor itself (FA). In any case, they do not compare to the results of the functional
approach.
</bodyText>
<subsectionHeader confidence="0.999092">
5.3 Extension of the Centering Transitions
</subsectionHeader>
<bodyText confidence="0.933894571428572">
Our use of the centering transitions led us to the conclusion that CONTINUE and
SMOOTH-SHIFT are not completely specified by Grosz, Joshi, and Weinstein (1995) and
Brennan, Friedman, and Pollard (1987). According to Brennan, Friedman, and Pol-
lard&apos;s definition, it is possible that a transition is labeled SMOOTH-SHIFT even if Cp(U,)
Cp(U,_1). Such a SHIFT is less smooth, because it contradicts the intuition that a
SMOOTH-SHIFT fulfills what a RETAIN predicted. The same applies to a CONTINUE with
this characteristic. Hence, we propose to extend the set of transitions as shown in Ta-
</bodyText>
<page confidence="0.994758">
332
</page>
<note confidence="0.935219">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.8199085">
Table 19
Cost values for centering transition pair types.
</tableCaption>
<table confidence="0.9999217">
Cost Type Naive Naive &amp; Grammatical Grammatical &amp; FunC
FA&amp;quot;&apos; &gt; FA FAante &gt; FA
IT cheap 72 180 129 236 321
expensive 317 209 260 153 68
Spiegel cheap 25 36 45 51 62
expensive 50 39 30 24 13
Milner cheap 45 48 46 48 55
expensive 34 31 33 31 24
cheap 142 264 220 335 438
expensive 401 279 323 208 105
</table>
<tableCaption confidence="0.995896">
Table 20
</tableCaption>
<equation confidence="0.701475875">
Revised transition types.
Cb(LI) = Cb(U1_1) Cb(U) Cbgli_i)
OR Cb(U1-1) undef.
Cb(111) = Cp(U,) AND CONTINUE SMOOTH-SHIFT
cp(u) = Cp(U,-1)
Cb(U) = Cp(U,) AND EXP-CONTINUE EXP-SMOOTH-SHIFT
Cp(U,) 0 Cp(1-11--1)
Cb(U0 0 CP(LJ) RETAIN ROUGH-SHIFT
</equation>
<tableCaption confidence="0.8604935">
Table 21
Costs for transition pairs.
</tableCaption>
<bodyText confidence="0.907893428571429">
CONT. EXP-CONT. RET. SMOOTH-S. EXP-SMOOTH-S. ROUGH-S.
- cheap - exp. - - -
CONT. cheap - cheap exp. - exp.
EXP-CONT. exp. - exp. exp. - exp.
RET. exp. exp. exp. cheap exp. exp.
SMOOTH-S. cheap exp. exp. exp. exp. exp.
EXP-SMOOTH-S. exp. exp. exp. exp. exp. exp.
ROUGH-S. exp. exp. exp. cheap exp. exp.
ble 20. The definitions of CONTINUE and SMOOTH-SHIFT are extended by the condition
that Cp(U,) = Cp(li_i), while EXP-CONTINUE and EXP-SMOOTH-SHIFT (expensive CON-
TINUE and expensive SMOOTH-SHIFT) require the opposite. RETAIN and ROUGH-SHIFT
fulfill Cp(U,) Cp(1.11) without further extensions.
Table 21 contains a complete overview of the transition pairs. Only those whose
second transition fulfills the criterion Cp(U,) = Cp(Ui_i) are labeled as &amp;quot;cheap.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.999475">
5.4 Redefinition of Rule 2
</subsectionHeader>
<bodyText confidence="0.9981545">
Grosz, Joshi, and Weinstein (1995) define Rule 2 of the centering model on the ba-
sis of sequences of transitions. Sequences of CONTINUE transitions are preferred over
</bodyText>
<page confidence="0.997738">
333
</page>
<note confidence="0.640804">
Computational Linguistics Volume 25, Number 3
</note>
<bodyText confidence="0.977666882352941">
sequences of RETAIN transitions, which are preferred over sequences of SHIFT transi-
tions. Brennan, Friedman, and Pollard (1987) utilize this rule for anaphora resolution
but restrict it to single transitions. Based on the preceding discussion of cheap and
expensive transition pairs, we propose to redefine Rule 2 in terms of the costs of
transition types.&apos; Rule 2 then reads as follows:
Rule 2&amp;quot; Cheap transition pairs are preferred over expensive ones.
We believe that this definition of Rule 2 allows for a far better assessment of
referential coherence in discourse than a definition in terms of sequences of transitions.
For anaphora resolution, we interpret Rule 2&amp;quot; such that the preference for an-
tecedents of anaphors in LI, can be derived directly from the Cf(Ui_i). The higher a
discourse entity is ranked in the Cf, the more likely it is the antecedent of a pronoun.
We see the redefinition of Rule 2 as the theoretical basis for a centering algorithm for
pronoun resolution that simply uses the Cf as a preference ranking device like the
basic centering algorithm shown in Table 3. In this algorithm, the metaphor of costs
translates into the number of elements of the Cf that have to be tested until the correct
antecedent is found. If the Cp of the previous utterance is the correct one, then the
costs are indeed very low.
</bodyText>
<subsectionHeader confidence="0.985428">
5.5 Does Functional Centering Provide a More Satisfactory Explanation of the Data?
</subsectionHeader>
<bodyText confidence="0.999966769230769">
We were also interested in finding out whether the functional criteria we propose
might explain the linguistic data in a more satisfactory way than the grammatical-
role-based criteria discussed so far. So, we screened sample data from the literature,
which were already annotated by centering analyses (for English, we considered all
examples discussed in Grosz, Joshi, and Weinstein [1995] and Brennan, Friedman, and
Pollard [1987]). We achieved consistent results for the grammatical and the functional
approach for all the examples contained in Grosz, Joshi, and Weinstein (1995) but found
diverging analyses for some examples discussed by Brennan, Friedman, and Pollard
(1987). While the RETAIN-SHIFT combination in examples (10c) and (10d&apos;) (slightly
modified from Brennan, Friedman, and Pollard [1987, 157]) did not indicate a difference
between the approaches, for the RETAIN-CONTINUE combination in examples (10c) and
(10d), the two approaches led to different results (see Table 22 for the BFP algorithm
and Table 23 for the FunC algorithm).
</bodyText>
<subsectionHeader confidence="0.814148">
Example 10
</subsectionHeader>
<bodyText confidence="0.693769">
a. Brennan drives an Alfa Romeo.
</bodyText>
<listItem confidence="0.869211">
b. She drives too fast.
c. Friedman races her on weekends.
d. She often wins.
d&apos;. She often beats her.
</listItem>
<bodyText confidence="0.991578">
Within the functional approach, the proper name Friedman is unused and, there-
fore, the leftmost hearer-old discourse entity of (10c). Hence, FRIEDMAN is the most
preferred antecedent for the pronoun she in (10d) and (10d&apos;).
</bodyText>
<footnote confidence="0.343492">
22 See Di Eugenio (1998) for a discussion regarding certain pairs of transitions and their relation to zero
vs. strong pronouns.
</footnote>
<page confidence="0.996057">
334
</page>
<note confidence="0.952704">
Strube and Hahn Functional Centering
</note>
<tableCaption confidence="0.771403">
Table 22
BFP interpretation for example (10)—The &amp;quot;Friedman&amp;quot; scenario.
</tableCaption>
<table confidence="0.999418642857143">
Cb: – –
Cf: [BRENNAN: Brennan, ALFA ROMEO: Alfa Romeo]
Cb: [BRENNAN: she] CONTINUE
Cf: [BRENNAN: she]
Cb: [BRENNAN: her] RETAIN
Cf: [FRIEDMAN: Friedman, BRENNAN: her]
Cb: [BRENNAN: she] CONTINUE
Cf: [BRENNAN: she]
Cb: [FRIEDMAN. she]
Cf: [FRIEDMAN. she]
(10d&apos;) Cb: [FRIEDMAN: she] SMOOTH-SHIFT
Cf: [FRIEDMAN: she, BRENNAN: her]
Cb: [FRIEDMAN. ter]
Cf: [BRENNAN. she, FRIEDMAN. ed
</table>
<tableCaption confidence="0.8238355">
Table 23
FunC interpretation for example (10)—The &amp;quot;Friedman&amp;quot; scenario.
</tableCaption>
<table confidence="0.921721">
Cf: [BRENNANu: Brennan, ALFA ROMEOBN: Alfa Romeo]
Cf: [BRENNANE: she]
Cf: [FRIEDMANN: Friedman, BRENNANE: her]
Cf: [FRIEEmANE: she]
(10d&apos;) Cf: [FRIEEmANE: she, BRENNANE: her]
</table>
<bodyText confidence="0.989946277777778">
But is subjecthood really the decisive factor? When we replace Friedman with a
hearer-new discourse entity, e.g., a professional driver, as in (100,&apos; then the procedures
generate inconsistent results, again. In the BFP algorithm, the ranking of the Cf list
depends only on grammatical roles. Hence, DRIVER is ranked higher than BRENNAN
in the Cf(106. In (10d), the pronoun she is resolved to BRENNAN because of the pref-
erence for CONTINUE over SMOOTH-SHIFT. In (10d&apos;), she is resolved to DRIVER because
SMOOTH-SHIFT is preferred over ROUGH-SHIFT (see Table 24).
10c&apos;. A professional driver races her on weekends.
Within the functional approach, the evoked phrase her in (10c&apos;) is ranked higher
than the brand-new phrase a professional driver. Therefore, the preference changes be-
tween example (10c) and (10c&apos;). In (10d) and (10d&apos;) the pronoun she is resolved to
BRENNAN, the discourse entity denoted by her (see Table 25).
We find the analyses of functional centering to match our intuitions about the
underlying referential relations more closely than those that are computed by gram-
matically based centering approaches. Hence, in the light of this still preliminary ev-
idence, we answer the question we posed at the beginning of this subsection in the
affirmative—functional centering indeed explains the data in a more satisfying manner
than other well-known centering principles.
</bodyText>
<footnote confidence="0.695125333333333">
23 We owe this variant to Andrew Kehler. This example may misdirect readers because the phrase a
professional driver might be assigned the &amp;quot;default&amp;quot; gender masculine. Anyway, this example—like the
original example—seems not to be felicitous English and has only illustrative character.
</footnote>
<page confidence="0.995131">
335
</page>
<note confidence="0.60265">
Computational Linguistics Volume 25, Number 3
</note>
<tableCaption confidence="0.931183">
Table 24
BFP interpretation for Example (10)—The &amp;quot;driver&amp;quot; scenario.
</tableCaption>
<table confidence="0.999880625">
Cb: - _
Cf: [BRENNAN: Brennan, ALFA ROMEO: Alfa Romeo]
Cb: [BRENNAN: she] CONTINUE
Cf: [BRENNAN: she]
Cb: [BRENNAN: her] RETAIN
Cf: [DRivER: driver, BRENNAN: her]
(10d) Cb: [BRENNAN: she] CONTINUE
Cf: [BRENNAN: she]
Cb: [aftftfrEitshe]
SMOOTH-SHIFT
Cf: [DRIVER. she]
Cb: [DRIVER: she] SMOOTH-SHIFT
Cf: [DRIVER: she, BRENNAN: her]
iteYfo&apos;d-H-SH-IFT
Cb: [DRIVER. ]
Cf: . she, DRIVER. her]
</table>
<tableCaption confidence="0.948353">
Table 25
FunC interpretation for Example (10)—The &amp;quot;driver&amp;quot; scenario.
</tableCaption>
<table confidence="0.9888966">
Cf: [BRENNANu: Brennan, ALFA ROMEOBN: Alfa Romeo]
Cf: [BRENNANE: she]
Cf: [BRENNANE: her, DRIvERBN: driver]
(10d) Cf: [BRENNANE: she]
Cf: [BRENNANE: she, DRIVERE: her]
</table>
<subsectionHeader confidence="0.999349">
5.6 Summary of Evaluation
</subsectionHeader>
<bodyText confidence="0.999951315789474">
To summarize the results of our empirical evaluation, we claim, first, that our proposal
based on functional criteria leads to substantially improved and—with respect to the
inference load placed on the text understander, whether human or machine—more
plausible results for languages with free word order than the structural constraints
given by Grosz, Joshi, and Weinstein (1995) and those underlying the naive approach.
We base these observations on an evaluation study that considers transition pairs in
terms of the inference load specific pairs imply. Second, we have gathered prelimi-
nary evidence, still far from conclusive, that the functional constraints on centering
seem to explain linguistic data more satisfactorily than the common grammar-oriented
constraints. Hence, we hypothesize that these functional constraints might constitute
a general framework for treating free- and fixed-word-order languages by the same
methodology. This claim, without doubt, has to be further substantiated by additional
cross-linguistic empirical studies.
The cost-based evaluation we focused on in this section refers to evaluation cri-
teria that form an intrinsic part of the centering model. As a consequence, we have
redefined Rule 2 of the Centering Constraints (Grosz, Joshi, and Weinstein 1995, 215)
appropriately. We replaced the characterization of a preference for sequences of CON-
TINUE over sequences of RETAIN and, similarly, sequences of RETAIN over sequences
of SHIFT by one in which cheap transitions are to be preferred over expensive ones.
</bodyText>
<sectionHeader confidence="0.717161" genericHeader="method">
6. Comparison with Related Approaches
</sectionHeader>
<subsectionHeader confidence="0.991887">
6.1 Focus-based Approaches
</subsectionHeader>
<bodyText confidence="0.9963715">
Approaches to anaphora resolution based on focus devices partly use the informa-
tion status of discourse entities to determine the current discourse focus. However, a
</bodyText>
<page confidence="0.994492">
336
</page>
<note confidence="0.76153">
Strube and Hahn Functional Centering
</note>
<bodyText confidence="0.9998932">
common area of criticism of these approaches is the diversity of data structures they
require. These data structures are likely to hide the underlying linguistic regularities,
because they promote the mix of preference and data structure considerations in the fo-
cusing algorithms. As an example, Sidner (1983, 292ff.) distinguishes between an Actor
Focus and a Discourse Focus, as well as corresponding lists, viz. Potential Actor Focus List
and Potential Discourse Focus List. Sufi and McCoy (1994) in their RAFT/RAPR approach
use grammatical roles for ordering the focus lists and make a distinction between Sub-
ject Focus, Current Focus, and corresponding lists. Both focusing algorithms prefer an
element that represents the Focus to the elements in the list when the anaphoric ex-
pression under consideration is not the agent (for Sidner) or the subject (for Suri and
McCoy). Relating these approaches to our proposal, they already exhibit a weak prefer-
ence for a single hearer-old (more precisely, evoked) discourse element. Dahl and Ball
(1990), describing the anaphora resolution module of the PUNDIT system, improve the
focusing mechanism by simplifying its underlying data structures. Thus, their proposal
is more closely related to the centering model than any other focusing mechanism. Fur-
thermore, if there is a pronoun in the sentence for which the Focus List is built, the
corresponding evoked discourse entity is shifted to the front of the list. The following
elements of the Focus List are ordered by grammatical roles again. Hence, their ap-
proach still relies upon grammatical information for the ordering of the centering list,
while we use only the functional information structure as the guiding principle.
</bodyText>
<subsectionHeader confidence="0.998155">
6.2 Heuristics
</subsectionHeader>
<bodyText confidence="0.999957689655173">
Given its embedding in a cognitive theory of inference loads imposed on the hearer
and, even more importantly, its fundamental role in a more comprehensive theory
of discourse understanding based on linguistic, attentional, and intentional layers,
the centering model can be considered the first principled attempt to deal with pref-
erence orders for plausible antecedent selection for anaphors. Its predecessors were
entirely heuristic approaches to anaphora resolution. These were concerned with var-
ious criteria—beyond strictly grammatical constraints such as agreement—for the op-
timization of the referent selection process based on preferential choices. An elaborate
description of several of these preference criteria is supplied by Carbonell and Brown
(1988) who discuss, among others, heuristics involving case role filling, semantic and
pragmatic alignment, syntactic parallelism, syntactic topicalization, and intersentential
recency. Given such a wealth of criteria one may either try to order them a priori in
terms of importance or—as was proposed by the majority of researchers in this field—
define several scoring functions that compute flexible orderings on the fly. These com-
bine the variety of available evidence, each one usually annotated by a specific weight
factor, and, finally, map the weights to a single salience score (Rich and LuperFoy
1988; HajRova, Kubori, and Kubori 1992; Lappin and Leass 1994)
These heuristics helped to improve the performance of discourse-understanding
systems through significant reductions of the available search-space for antecedents.
Their major drawback is that they require a great deal of skilled hand-crafting that,
unfortunately, usually does not scale in broader application domains. Hence, proposals
were made to replace these high-level &amp;quot;symbolic&amp;quot; categories by statistically interpreted
occurrence patterns derived from large text corpora (Dagan and Itai 1990). Preferences
then reflect patterns of statistically significant lexical usage rather than introspective
abstractions of linguistic patterns such as syntactic parallelism or pragmatic alignment.
Among the heuristic approaches to anaphora resolution, those which consider the
identification of heuristics a machine learning (ML) problem are particularly inter-
esting, since their heuristics dynamically adapt to the textual data. Furthermore, ML
procedures operate on incomplete parses (hence, they accept noisy data), which dis-
</bodyText>
<page confidence="0.992935">
337
</page>
<note confidence="0.728083">
Computational Linguistics Volume 25, Number 3
</note>
<bodyText confidence="0.998634466666667">
tinguishes them from the requirements of perfect information and high data fidelity
imposed by almost any other anaphora resolution scheme. Connolly, Burger, and Day
(1994) treat anaphora resolution as an ML classification problem and compare seven
classifier approaches with the solution quality of a naive hand-crafted algorithm whose
heuristics incorporate the well-known agreement and recency indicators. Aone and
Bennett (1996) outline an approach where they consider more than 60 features auto-
matically obtained from the machinery of the host natural language processing system
the learner is embedded in. The features under consideration include lexical ones like
categories, syntactic ones like grammatical roles, semantic ones like semantic classes,
and text positional ones, e.g., the distance between anaphor and antecedent. These
features are packed in feature vectors—for each pair of an anaphor and its possible
antecedent—and used to train a decision tree, employing Quinlan&apos;s C4.5 algorithm
(Aone and Bennett 1996), or a whole battery of alternative classifiers in which hybrid
variants yield the highest scores (Connolly, Burger, and Day 1994). Though still not
fully worked out, it is interesting to note that in both studies ML-derived heuristics
tend to outperform those that were carefully developed by human experts (similar
results are reported by Cardie [1992] with respect to learning resolution heuristics for
relative pronouns pertaining to a case-based learning procedure). This indicates, at
least, that heuristically based methods using simple combinations of features benefit
from being exposed to and having to adapt to training data. ML-based mechanisms
might constitute an interesting perspective for the further tuning of ordering criteria
for the forward-looking centers.
These mixed heuristic approaches, using multidimensional metrics for ranking an-
tecedent candidates, diverge from the assumption that underlies the centering model
that a single type of criterion—the attentional state and its representation in terms
of the backward- and forward-looking centers—is crucial for referent selection. By
incorporating functional considerations in terms of the information structure of utter-
ances into the centering model we actually enrich the types of knowledge that go into
centered anaphora resolution decisions, i.e., we extend the &amp;quot;dimensionality&amp;quot; of the
centering model, too. But unlike the numerical scoring approaches, our combination
remains at the symbolic computation level, preserves the modularity of criteria, and,
in particular, is linguistically justified. Although functional centering is not a com-
plete theory of preferential anaphora resolution, one should clearly stress the different
goals behind heuristics-based systems, such as the ones just discussed, and the model
of centering. Heuristic approaches combine introspectively acquired descriptive evi-
dence and attempt to optimize reference resolution performance by proper evidence
&amp;quot;engineering&amp;quot;. This is often done in an admittedly ad hoc way, requiring tricky retun-
ing when new evidence is added (Rich and LuperFoy 1988). On the other hand, many
of these systems work in a real-world environment (Rich and LuperFoy 1988; Lappin
and Leass 1994; Kennedy and Boguraev 1996) in which noisy data and incomplete,
sometimes even faulty, analysis results have to be accounted for. The centering model
differs from these considerations in that it aims at unfolding a unified theory of dis-
course coherence at the linguistic, attentional, and intentional level (Grosz and Sidner
1986); hence, the search for a more principled, theory-based solution, but also the need
for (almost) perfect linguistic analyses in terms of parsing and semantic interpretation.
</bodyText>
<sectionHeader confidence="0.714967" genericHeader="conclusions">
7. Conclusion
</sectionHeader>
<bodyText confidence="0.985313333333333">
In this paper, we provided a novel account for ordering the forward-looking center
list, a major construct of the centering model. The new formulation is entirely based on
functional notions, grounded in the information structure of utterances in a discourse.
</bodyText>
<page confidence="0.993818">
338
</page>
<note confidence="0.760429">
Strube and Hahn Functional Centering
</note>
<bodyText confidence="0.95029693877551">
We motivated our proposal by the constraints that hold for a free-word-order language
such as German and derived our results from empirical studies of real-world texts.
We also augmented the ordering criteria of the forward-looking center list such that
it accounts not only for (pro)nominal anaphora but also for inferables (restricted to
the subset of functional anaphora), an issue that, up to now, has only been sketchily
dealt with in the centering framework. The extensions we proposed were validated by
the empirical analysis of various texts of considerable length selected from different
domains and genres. The &amp;quot;evaluation metric&amp;quot; we used refers to a new cost-based model
of interpreting the validity of centering data. The distinction between cognitively cheap
and expensive transition pairs led us to replace Rule 2 from the original model by a
formulation that explicitly incorporates this cost-oriented distinction.
A resolution module for (pro)nominal anaphora (Strube and Hahn 1995) and one
for functional anaphora (Hahn, Markert, and Strube 1996) based on this functional
centering model has been implemented as part of PARSETALK, a comprehensive text
parser for German (Hahn, Schacht, and Broker 1994; Hahn, Neuhaus, and Broker
1997) in our group. All these modules are fully operational and integrated within
the text-understanding backbone of SYNDIK ATE, a large-scale text knowledge acqui-
sition system for the two real-world domains of information technology (Hahn and
Schnattinger 1998) and medicine (Hahn, Romacker, and Schulz 1999).
Despite the progress made so far, many research problems remain open for further
consideration in the centering framework. The following list mentions only the most
pertinent issues that have come to our attention and complements the list given by
Grosz, Joshi, and Weinstein (1995):
1. The centering model is rather agnostic about the intricacies of complex
sentences such as relative clauses, subordinate clauses, coordinations,
and complex noun phrases. The problem caused by these structures
for the centering model is how to decompose a complex sentence into
center-updating units and how to process complex utterances consisting
of multiple clauses. A first proposal is due to Kameyama (1998)
who breaks a complex sentence into a hierarchy of center-updating
units. Furthermore, she distinguishes several types of constructions in
order to decide which part of the sentence is relevant for the resolution
of an intersentential anaphor in the following sentence. Strube (1996b)
(with respect to centering) and Suri and McCoy (1994) (with respect to
the focus model) describe similar approaches and provide algorithms for
the interaction of the resolution of inter- and intrasentential anaphora,
but the topic has certainly not been dealt with exhaustively. The problem
of complex NPs was pointed out by Walker and Prince (1996). Since the
grammatical functions in a sentence may be realized by a complex NP, it is
not clear how to rank these phrases in the Cf list. Walker and Prince (1996)
propose a &amp;quot;working hypothesis&amp;quot; based on the surface order. Strube (1998)
provides a complete specification for dealing with complex sentences,
but this approach departs significantly from the centering model.
2. It seems that there exist only a few fully operational implementations of
centering-based algorithms, since the interaction of the algorithm with
global and local ambiguities generated by a sentence parser has not
received much attention until now. A first proposal for how to deal with
center ambiguity in an incremental text parser has been made by Hahn
and Strube (1996).
</bodyText>
<page confidence="0.996704">
339
</page>
<subsectionHeader confidence="0.310981">
Computational Linguistics Volume 25, Number 3
</subsectionHeader>
<bodyText confidence="0.993176151515152">
3. The centering model covers the standard cases of anaphora, i.e.,
pronominal and nominal anaphora and even functional anaphora based
on the proposal we have developed in this article. It does not, however,
take into account several &amp;quot;hard&amp;quot; issues such as plural anaphora, generic
definite noun phrases, propositional anaphora, and deictic forms (but see
Eckert and Strube [1999] for a treatment of discourse-deictic anaphora in
dialogues within a centering-type framework). These shortcomings
might be traced back to the fact that the centering model, up to now, did
not consider the role of the (main) verb of the utterance under scrutiny.
Other cases, such as VP anaphora (Hardt 1992), temporal anaphora
(Kameyama, Passonneau, and Poesio 1993; Hitzeman, Moens, and
Grover 1995) have already been examined within the centering model.
The particular phenomenon of paycheck anaphora is described by Hardt
(1996), though he uses only a rather simplified centering model for this
work. Other cases are only dealt with in the focusing framework such as
propositional anaphora (Dahl and Ball 1990).
4. Evaluations of the centering model have so far only been carried out
manually. This is clearly no longer rewarding, so appropriate
computational support environments have to be provided. What we
have in mind is a kind of discourse structure bank and associated
workbenches comparable to grammar workbenches and parse treebanks.
Aone and Bennett (1994), for example, report on a GUI-based Discourse
Tagging Tool (DTT) that allows a user to link an anaphor with its
antecedent and specify the type of the anaphor (e.g., pronoun, definite
NP, etc.). The tagged result can be written out to an SGML-marked file.
Arguing for the need for discourse taggers, this also implies the
development of a discourse structure interlingua (some sort of Discourse
Structure Mark-up Language) for describing discourse structures in a
common format in order to ease nonproblematic exchange and
world-wide distribution of discourse structure data sets. Such an
environment would provide excellent conditions for further testing, for
example, of our assumption that the information structure constraints we
suggest might apply in a universal manner.
</bodyText>
<listItem confidence="0.7521619375">
5. Centering theory, so far, is a model of local coherence in the minimal
sense, i.e., it allows only the consideration of immediately adjacent
centering structures for establishing proper referential links. In order to
extend that theory to the level of global coherence, various steps have to
be taken.
• At the referential level, mechanisms have to be introduced to
account for reference relationships that extend beyond the
immediately preceding utterance. Empirical evidence for such
phenomena exists in the literature and we also found the need to
have such a mechanism available for longer texts. The extension
of functional centering to these phenomena is presented in Hahn
and Strube (1997), while Walker (1998) builds upon the centering
algorithm described in Brennan, Friedman, and Pollard (1987).
• At the level of discourse pragmatics, a richer notion than mere
reference between terms is needed to account for coherence
relations such as those aimed at by Rhetorical Structure Theory
</listItem>
<page confidence="0.9875">
340
</page>
<note confidence="0.721515">
Strube and Hahn Functional Centering
</note>
<bodyText confidence="0.9996564">
(Mann and Thompson 1988). In addition, an explicit relation to
basic notions from speech act theory is also missing, though it
should be considered vital for the global coherence of discourse
(Grosz and Sidner 1986). In general, it might become
increasingly necessary to integrate very deep forms of reasoning,
perhaps even nonmonotonic (Dunin-Keplicz and Lukaszewicz
1986) or abductive inference mechanisms (Nagao 1989), into the
anaphora resolution process. This might become a sheer
necessity when incrementality of processing receives a higher
level of attention in the centering community.
</bodyText>
<sectionHeader confidence="0.992203" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.978051428571428">
We would like to thank our colleagues from
the Computational Linguistics Group in
Freiburg and at the University of
Pennsylvania for fruitful discussions, in
particular Norbert Broker, Miriam Eckert,
Aravind Joshi, Manfred Klenner, Nobo
Komagata, Katja Markert, Peter Neuhaus,
Ellen Prince, Rashmi Prasad, Owen
Rambow, Susanne Schacht, and Bonnie
Webber. We also owe special thanks to the
four reviewers whose challenges and
suggestions have considerably improved
the presentation of our ideas about
functional centering in this article. The first
author was partially funded by LGFG
Baden-Wurttemberg, a post-doctoral grant
from DFG (Str 545/1-1) and a post-doctoral
fellowship award from the Institute for
Research in Cognitive Science at the
University of Pennsylvania (NSF SBR
8920230).
</bodyText>
<sectionHeader confidence="0.991929" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999450776119403">
Alshawi, Hiyan. 1992. Resolving quasi
logical forms. In H. Alshawi, editor, The
Core Language Engine. MIT Press,
Cambridge, MA, pages 187-216.
Aone, Chinatsu and Scott W. Bennett. 1994.
Discourse tagging tool and
discourse-tagged multilingual corpora. In
Proceedings of the International Workshop on
Sharable Natural Language Resources,
pages 71-77, Ikoma, Nara, Japan, August.
Aone, Chinatsu and Scott W. Bennett. 1996.
Applying machine learning to anaphora
resolution. In S. Wermter, E. Riloff, and G.
Scheler, editors, Connectionist, Statistical
and Symbolic Approaches to Learning for
Natural Language Processing. Springer,
Berlin, pages 302-314.
Brennan, Susan E., Marilyn W. Friedman,
and Carl J. Pollard. 1987. A centering
approach to pronouns. In Proceedings of the
25th Annual Meeting, pages 155-162,
Association for Computational
Linguistics, Stanford, CA, July.
Carbonell, Jaime G. and Ralph D. Brown.
1988. Anaphora resolution: A
multi-strategy approach. In Proceedings of
the 12th International Conference on
Computational Linguistics, volume 1,
pages 96-101, Budapest, Hungary,
August.
Cardie, Claire. 1992. Learning to
disambiguate relative pronouns. In
Proceedings of the 10th National Conference on
Artificial Intelligence, pages 38-43, San
Jose, CA, July.
Chomsky, Noam. 1981. Lectures on
Government and Binding. Foris, Dordrecht.
Clark, Herbert H. 1975. Bridging. In
Proceedings of the Conference on Theoretical
Issues in Natural Language Processing,
pages 169-174, Cambridge, MA, June.
Connolly, Dennis, John D. Burger, and
David S. Day. 1994. A machine learning
approach to anaphoric reference. In
Proceedings of the International Conference on
New Methods in Language Processing,
pages 255-261, Manchester, England,
September.
Dagan, Ido and Alon Itai. 1990. Automatic
processing of large corpora for the
resolution of anaphora references. In
Proceedings of the 13th International
Conference on Computational Linguistics,
volume 3, pages 330-332, Helsinki,
Finland, August.
Dahl, Deborah A. and Catherine N. Ball.
1990. Reference resolution in PUNDIT. In
P. Saint-Dizier and S. Szpakowicz, editors,
Logic and Logic Grammars for Language
Processing. Ellis Horwood, Chichester,
England, pages 168-184.
Di Eugenio, Barbara. 1998. Centering in
Italian. In M. A. Walker, A. K. Joshi, and
E. F. Prince, editors, Centering Theory in
Discourse, Oxford University Press,
Oxford, England, pages 115-137.
Dunin-Keplicz, Barbara and Witold
</reference>
<page confidence="0.993604">
341
</page>
<note confidence="0.691009">
Computational Linguistics Volume 25, Number 3
</note>
<reference confidence="0.998475450819673">
Lukaszewicz. 1986. Towards
discourse-oriented nonmonotonic system.
In Proceedings of the 11th International
Conference on Computational Linguistics,
pages 504-506, Bonn, Germany, August.
Eckert, Miriam and Michael Strube. 1999.
Resolving discourse deictic anaphora in
dialogues. In Proceedings of the 9th
Conference of the European Chapter of the
Association for Computational Linguistics,
pages 37-44, Bergen, Norway, June.
Firbas, Jan. 1974. Some aspects of the
Czechoslovak approach to problems of
functional sentence prespective. In F.
Dane, editor, Papers on Functional Sentence
Perspective. Academia, Prague,
pages 11-37.
Gordon, Peter C., Barbara J. Grosz, and
Laura A. Gilliom. 1993. Pronouns, names,
and the centering of attention in
discourse. Cognitive Science, 17:311-347.
Grosz, Barbara J. 1977. The representation
and use of focus in a system for
understanding dialogs. In Proceedings of
the 5th International Joint Conference on
Artificial Intelligence, volume 1,
pages 67-76, Cambridge, MA, August.
Grosz, Barbara J., Aravind K. Joshi, and
Scott Weinstein. 1983. Providing a unified
account of definite noun phrases in
discourse. In Proceedings of the 21st Annual
Meeting, pages 44-50, Cambridge, MA,
June. Association for Computational
Linguistics.
Grosz, Barbara J., Aravind K. Joshi, and
Scott Weinstein. 1995. Centering: A
framework for modeling the local
coherence of discourse. Computational
Linguistics, 21(2):203-225.
Grosz, Barbara J. and Candace L. Sidner.
1986. Attention, intentions, and the
structure of discourse. Computational
Linguistics, 12(3):175-204.
Haddock, Nicholas J. 1987. Incremental
interpretation and combinatory categorial
grammar. In Proceedings of the 10th
International Joint Conference on Artificial
Intelligence, volume 2, pages 661-663,
Milan, Italy, August.
Hahn, Udo, Katja Markert, and Michael
Strube. 1996. A conceptual reasoning
approach to textual ellipsis. In Proceedings
of the 12th European Conference on Artificial
Intelligence, pages 572-576, Budapest,
Hungary August.
Hahn, Udo, Peter Neuhaus, and Norbert
Broker. 1997. Message-passing protocols
for real-world parsing: An object-oriented
model and its preliminary evaluation. In
Proceedings of the 5th International Workshop
on Parsing Technologies, pages 101-112,
Massachusetts Institute of Technology,
Cambridge, MA, September.
Hahn, Udo, Martin Romacker, and Stefan
Schulz. 1999. Discourse structures in
medical reports—watch out! The
generation of referentially coherent and
valid text knowledge bases in
mEDSvNDIK ATE system. International
Journal of Medical Informatics, 53(1):1-28.
Hahn, Udo, Susanne Schacht, and Norbert
Broker. 1994. Concurrent, object-oriented
natural language parsing: The
PARSETALK model. International Journal of
Human-Computer Studies, 41(1/2):179-222.
Hahn, Udo and Klemens Schrtattinger. 1998.
Towards text knowledge engineering. In
Proceedings of the 15th National Conference on
Artificial Intelligence &amp; the 10th Conference
on Innovative Applications of Artificial
Intelligence, pages 524-531, Madison, WI,
July.
Hahn, Udo and Michael Strube. 1996.
Incremental centering and center
ambiguity. In Proceedings of the 18th Annual
Conference of the Cognitive Science Society,
pages 568-573, LaJolla, CA, July.
Hahn, Udo and Michael Strube. 1997.
Centering in-the-large: Computing
referential discourse segments. In
Proceedings of the 35th Annual Meeting of the
Association for Computational Linguistics and
the 8th Conference of the European Chapter of
the Association for Computational Linguistics,
pages 104-111, Madrid, Spain, July.
HajR&amp;quot;ova, Eva, Vladislav Kuboti, and Petr
Kuborl. 1992. Stock of shared knowledge:
A tool for solving pronominal anaphora.
In Proceedings of the 15th International
Conference on Computational Linguistics,
volume 1, pages 127-133, Nantes, France,
August.
Hardt, Daniel. 1992. An algorithm for VP
ellipsis. In Proceedings of the 30th Annual
Meeting, pages 9-14, Newark, DE,
June–July. Association for Computational
Linguistics.
Hardt, Daniel. 1996. Centering in dynamic
semantics. In Proceedings of the 16th
International Conference on Computational
Linguistics, volume 1, pages 519-524,
Copenhagen, Denmark, August.
Hitzeman, Janet. Marc Moens, and Claire
Grover. 1995. Algorithms for analysing
the temporal structure of discourse. In
Proceedings of the 7th Conference of the
European Chapter of the Association for
Computational Linguistics, pages 253-260,
Dublin, Ireland, March.
Hoffman, Beryl. 1996. Translating into free
word order languages. In Proceedings of the
16th International Conference on
</reference>
<page confidence="0.985931">
342
</page>
<note confidence="0.779846">
Strube and Hahn Functional Centering
</note>
<reference confidence="0.999907967213115">
Computational Linguistics, volume 1,
pages 556-561, Copenhagen, Denmark,
August.
Hoffman, Beryl. 1998. Word order,
information structure, and centering in
Turkish. In M. A. Walker, A. K. Joshi, and
E. F. Prince, editors, Centering Theory in
Discourse, pages 251-271, Oxford
University Press, Oxford, England.
Jaeggli, Osvaldo. 1986. Arbitrary plural
pronominals. Natural Language and
Linguistic Theory, 4:43-76.
Kameyama, Megumi. 1986. A
property-sharing constraint in centering.
In Proceedings of the 24th Annual Meeting,
pages 200-206, New York, NY, June.
Association for Computational
Linguistics.
Kameyama, Megumi. 1998. Intrasentential
centering: A case study. In M. A. Walker,
A. K. Joshi, and E. F. Prince, editors,
Centering Theory in Discourse. Oxford
University Press, Oxford, England,
pages 89-112.
Kameyama, Megumi, Rebecca Passonneau,
and Massimo Poesio. 1993. Temporal
centering. In Proceedings of the 31st Annual
Meeting, pages 70-77, Columbus, OH,
June. Association for Computational
Linguistics.
Kamp, Hans and Uwe Reyle. 1993. From
Discourse to Logic. Introduction to
Modeltheoretic Semantics of Natural
Language, Formal Logic and Discourse
Representation Theory. Kluwer, Dordrecht.
Kennedy, Christopher and Branimir
Boguraev. 1996. Anaphora for everyone:
Pronominal anaphora resolution without
a parser. In Proceedings of the 16th
International Conference on Computational
Linguistics, volume 1, pages 113-118,
Copenhagen, Denmark, August.
Lappin, Shalom and Herbert J. Leass. 1994.
An algorithm for pronominal anaphora
resolution. Computational Linguistics,
20(4):535-561.
Mann, William C. and Sandra A.
Thompson. 1988. Rhetorical Structure
Theory: Toward a functional theory of
text organization. Text, 8(3):243-281.
Nagao, Katashi. 1989. Semantic
interpretation based on the multi-world
model. In Proceedings of the 11th
International Joint Conference on Artificial
Intelligence, pages 1,467-1,473, Detroit, MI,
August.
Prince, Ellen F. 1981. Towards a taxonomy
of given-new information. In P. Cole,
editor, Radical Pragmatics. Academic Press,
New York, NY, pages 223-255.
Prince, Ellen F. 1992. The ZPG letter:
Subjects, definiteness, and
information-status. In W. C. Mann and
S. A. Thompson, editors, Discourse
Description: Diverse Linguistic Analyses of a
Fund-Raising Text. John Benjamins,
Amsterdam, pages 295-325.
Rambow, Owen. 1993. Pragmatic aspects of
scrambling and topicalization in German.
In Workshop on Centering Theory in
Naturally-Occurring Discourse. Institute for
Research in Cognitive Science (IRCS),
University of Pennsylvania, Philadelphia,
PA, May.
Rich, Elaine and Susann LuperFoy. 1988. An
architecture for anaphora resolution. In
Proceedings of the 2nd Conference on Applied
Natural Language Processing, pages 18-24,
Austin, TX, February.
Sidner, Candace L. 1983. Focusing in the
comprehension of definite anaphora. In
M. Brady and R. C. Berwick, editors,
Computational Models of Discourse. MIT
Press, Cambridge, MA, pages 267-330.
Strube, Michael. 1996a. Funktionales
Centering. Ph.D. thesis,
Albert-Ludwigs-Universitat Freiburg,
Freiburg.
Strube, Michael. 1996b. Processing complex
sentences in the centering framework. In
Proceedings of the 34th Annual Meeting,
pages 378-380, Santa Cruz, CA, June.
Association for Computational
Linguistics.
Strube, Michael. 1998. Never look back: An
alternative to centering. In COLING-ACL
&apos;98: 36th Annual Meeting of the Association
for Computational Linguistics and the 17th
International Conference on Computational
Linguistics, Montreal, Quebec, Canada,
volume 2, pages 1,251-1,257.
Strube, Michael and Udo Hahn. 1995.
PARSETALK about sentence- and
text-level anaphora. In Proceedings of the
7th Conference of the European Chapter of the
Association for Computational Linguistics,
pages 237-244, Dublin, Ireland, March.
Strube, Michael and Udo Hahn. 1996.
Functional centering. In Proceedings of the
34th Annual Meeting, pages 270-277, Santa
Cruz, CA, June. Association for
Computational Linguistics.
Suri, Linda Z. and Kathleen F. McCoy. 1994.
RAFT/RAPR and centering: A
comparison and discussion of problems
related to processing complex sentences.
Computational Linguistics, 20(2):301-317.
Turan, Omit Deniz. 1998. Ranking
forward-looking centers in Turkish:
Universal and language specific
properties. In M. A. Walker, A. K. Joshi,
and E. F. Prince, editors, Centering in
</reference>
<page confidence="0.981473">
343
</page>
<note confidence="0.366435">
Computational Linguistics Volume 25, Number 3
</note>
<reference confidence="0.99944478125">
Discourse. Oxford University Press,
Oxford, England, pages 138-160.
Vallduvf, Enric. 1990. The Informational
Component. Ph.D. thesis, Department of
Linguistics, University of Pennsylvania,
Philadelphia, PA.
Vallduvf, Enric and Elisabet Engdahl. 1996.
The linguistic realization of information
packaging. Linguistics, 34:459-519.
Walker, Marilyn A. 1989. Evaluating
discourse processing algorithms. In
Proceedings of the 27th Annual Meeting,
pages 251-261, Vancouver, B.C., Canada,
June. Association for Computational
Linguistics.
Walker, Marilyn A. 1998. Centering
anaphora resolution, and discourse
structure. In M. A. Walker, A. K. Joshi,
and E. F. Prince, editors, Centering Theory
in Discourse. Oxford University Press,
Oxford, England, pages 401-435.
Walker, Marilyn A., Masayo Iida, and
Sharon Cote. 1994. Japanese discourse
and the process of centering.
Computational Linguistics, 20(2):193-233.
Walker, Marilyn A. and Ellen F. Prince. A
bilateral approach to givenness: A
hearer-status algorithm and a centering
algorithm. In T. Fretheim and J. K.
Gundel, editors, Reference and Referent
Accessibility. John Benjamins, Amsterdam,
pages 291-306.
</reference>
<page confidence="0.998987">
344
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.924390">
<title confidence="0.995529333333333">Functional Centering— Grounding Referential Coherence in Information Structure</title>
<author confidence="0.999807">Michael Strube Udo Hahnt</author>
<affiliation confidence="0.999965">University of Pennsylvania Freiburg University</affiliation>
<abstract confidence="0.994693923076923">Considering empirical evidence from a free-word-order language (German) we propose a revision of the principles guiding the ordering of discourse entities in the forward-looking center list within the centering model. We claim that grammatical role criteria should be replaced by criteria that reflect the functional information structure of the utterances. These new criteria are based on the distinction between hearer-old and hearer-new discourse entities. We demonstrate that such a functional model of centering can be successfully applied to the analysis of several forms of referential text phenomena, viz. pronominal, nominal, and functional anaphora. Our methodological and empirical claims are substantiated by two evaluation studies. In the first one, we compare success rates for the resolution of pronominal anaphora that result from a grammaticalrole-driven centering algorithm and from a functional centering algorithm. The second study deals with a new cost-based evaluation methodology for the assessment of centering data, one which can be directly derived from and justified by the cognitive load premises of the centering model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hiyan Alshawi</author>
</authors>
<title>Resolving quasi logical forms.</title>
<date>1992</date>
<booktitle>The Core Language Engine.</booktitle>
<pages>187--216</pages>
<editor>In H. Alshawi, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="1775" citStr="Alshawi 1992" startWordPosition="253" endWordPosition="254"> assessment of centering data, one which can be directly derived from and justified by the cognitive load premises of the centering model. 1. Introduction The problem of establishing referential coherence in discourse can be rephrased as the problem of determining the proper antecedent of a given anaphoric expression in the current or the preceding utterance(s) and the rendering of both as referentially identical (coreferential). This task can be approached in a very principled way by stating general constraints on the grammatical compatibility of the expressions involved (e.g., Haddock 1987; Alshawi 1992). Linguists have devoted a lot of effort to identifying conclusive syntactic and semantic criteria to reach this goal, e.g., for intrasentential anaphora within the binding theory part of the theory of Government and Binding (Chomsky 1981), or for intersentential anaphora within the context of the Discourse Representation Theory (Kamp and Reyle 1993). Unfortunately, these frameworks fail to uniquely determine anaphoric antecedents in a variety of cases. As a consequence, referentially ambiguous interpretations have to be dealt with in those cases in which several alternatives fulfill all the r</context>
</contexts>
<marker>Alshawi, 1992</marker>
<rawString>Alshawi, Hiyan. 1992. Resolving quasi logical forms. In H. Alshawi, editor, The Core Language Engine. MIT Press, Cambridge, MA, pages 187-216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Scott W Bennett</author>
</authors>
<title>Discourse tagging tool and discourse-tagged multilingual corpora.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Workshop on Sharable Natural Language Resources,</booktitle>
<pages>71--77</pages>
<location>Ikoma, Nara, Japan,</location>
<contexts>
<context position="96077" citStr="Aone and Bennett (1994)" startWordPosition="14994" endWordPosition="14997">ng model. The particular phenomenon of paycheck anaphora is described by Hardt (1996), though he uses only a rather simplified centering model for this work. Other cases are only dealt with in the focusing framework such as propositional anaphora (Dahl and Ball 1990). 4. Evaluations of the centering model have so far only been carried out manually. This is clearly no longer rewarding, so appropriate computational support environments have to be provided. What we have in mind is a kind of discourse structure bank and associated workbenches comparable to grammar workbenches and parse treebanks. Aone and Bennett (1994), for example, report on a GUI-based Discourse Tagging Tool (DTT) that allows a user to link an anaphor with its antecedent and specify the type of the anaphor (e.g., pronoun, definite NP, etc.). The tagged result can be written out to an SGML-marked file. Arguing for the need for discourse taggers, this also implies the development of a discourse structure interlingua (some sort of Discourse Structure Mark-up Language) for describing discourse structures in a common format in order to ease nonproblematic exchange and world-wide distribution of discourse structure data sets. Such an environmen</context>
</contexts>
<marker>Aone, Bennett, 1994</marker>
<rawString>Aone, Chinatsu and Scott W. Bennett. 1994. Discourse tagging tool and discourse-tagged multilingual corpora. In Proceedings of the International Workshop on Sharable Natural Language Resources, pages 71-77, Ikoma, Nara, Japan, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Scott W Bennett</author>
</authors>
<title>Applying machine learning to anaphora resolution.</title>
<date>1996</date>
<booktitle>Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing.</booktitle>
<pages>302--314</pages>
<editor>In S. Wermter, E. Riloff, and G. Scheler, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin,</location>
<contexts>
<context position="87296" citStr="Aone and Bennett (1996)" startWordPosition="13673" endWordPosition="13676">ics dynamically adapt to the textual data. Furthermore, ML procedures operate on incomplete parses (hence, they accept noisy data), which dis337 Computational Linguistics Volume 25, Number 3 tinguishes them from the requirements of perfect information and high data fidelity imposed by almost any other anaphora resolution scheme. Connolly, Burger, and Day (1994) treat anaphora resolution as an ML classification problem and compare seven classifier approaches with the solution quality of a naive hand-crafted algorithm whose heuristics incorporate the well-known agreement and recency indicators. Aone and Bennett (1996) outline an approach where they consider more than 60 features automatically obtained from the machinery of the host natural language processing system the learner is embedded in. The features under consideration include lexical ones like categories, syntactic ones like grammatical roles, semantic ones like semantic classes, and text positional ones, e.g., the distance between anaphor and antecedent. These features are packed in feature vectors—for each pair of an anaphor and its possible antecedent—and used to train a decision tree, employing Quinlan&apos;s C4.5 algorithm (Aone and Bennett 1996), </context>
</contexts>
<marker>Aone, Bennett, 1996</marker>
<rawString>Aone, Chinatsu and Scott W. Bennett. 1996. Applying machine learning to anaphora resolution. In S. Wermter, E. Riloff, and G. Scheler, editors, Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing. Springer, Berlin, pages 302-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
<author>Marilyn W Friedman</author>
<author>Carl J Pollard</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proceedings of the 25th Annual Meeting,</booktitle>
<pages>155--162</pages>
<marker>Brennan, Friedman, Pollard, 1987</marker>
<rawString>Brennan, Susan E., Marilyn W. Friedman, and Carl J. Pollard. 1987. A centering approach to pronouns. In Proceedings of the 25th Annual Meeting, pages 155-162,</rawString>
</citation>
<citation valid="false">
<date></date>
<institution>Association for Computational Linguistics,</institution>
<location>Stanford, CA,</location>
<marker></marker>
<rawString>Association for Computational Linguistics, Stanford, CA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime G Carbonell</author>
<author>Ralph D Brown</author>
</authors>
<title>Anaphora resolution: A multi-strategy approach.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>96--101</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="85126" citStr="Carbonell and Brown (1988)" startWordPosition="13370" endWordPosition="13373">ore comprehensive theory of discourse understanding based on linguistic, attentional, and intentional layers, the centering model can be considered the first principled attempt to deal with preference orders for plausible antecedent selection for anaphors. Its predecessors were entirely heuristic approaches to anaphora resolution. These were concerned with various criteria—beyond strictly grammatical constraints such as agreement—for the optimization of the referent selection process based on preferential choices. An elaborate description of several of these preference criteria is supplied by Carbonell and Brown (1988) who discuss, among others, heuristics involving case role filling, semantic and pragmatic alignment, syntactic parallelism, syntactic topicalization, and intersentential recency. Given such a wealth of criteria one may either try to order them a priori in terms of importance or—as was proposed by the majority of researchers in this field— define several scoring functions that compute flexible orderings on the fly. These combine the variety of available evidence, each one usually annotated by a specific weight factor, and, finally, map the weights to a single salience score (Rich and LuperFoy </context>
</contexts>
<marker>Carbonell, Brown, 1988</marker>
<rawString>Carbonell, Jaime G. and Ralph D. Brown. 1988. Anaphora resolution: A multi-strategy approach. In Proceedings of the 12th International Conference on Computational Linguistics, volume 1, pages 96-101, Budapest, Hungary, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Cardie</author>
</authors>
<title>Learning to disambiguate relative pronouns.</title>
<date>1992</date>
<booktitle>In Proceedings of the 10th National Conference on Artificial Intelligence,</booktitle>
<pages>38--43</pages>
<location>San Jose, CA,</location>
<marker>Cardie, 1992</marker>
<rawString>Cardie, Claire. 1992. Learning to disambiguate relative pronouns. In Proceedings of the 10th National Conference on Artificial Intelligence, pages 38-43, San Jose, CA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<date>1981</date>
<booktitle>Lectures on Government and Binding. Foris,</booktitle>
<location>Dordrecht.</location>
<contexts>
<context position="2014" citStr="Chomsky 1981" startWordPosition="289" endWordPosition="290">he problem of determining the proper antecedent of a given anaphoric expression in the current or the preceding utterance(s) and the rendering of both as referentially identical (coreferential). This task can be approached in a very principled way by stating general constraints on the grammatical compatibility of the expressions involved (e.g., Haddock 1987; Alshawi 1992). Linguists have devoted a lot of effort to identifying conclusive syntactic and semantic criteria to reach this goal, e.g., for intrasentential anaphora within the binding theory part of the theory of Government and Binding (Chomsky 1981), or for intersentential anaphora within the context of the Discourse Representation Theory (Kamp and Reyle 1993). Unfortunately, these frameworks fail to uniquely determine anaphoric antecedents in a variety of cases. As a consequence, referentially ambiguous interpretations have to be dealt with in those cases in which several alternatives fulfill all the required syntactic and semantic constraints. It seems that syntactic and semantic criteria constitute only necessary but by no means sufficient conditions for identifying the valid antecedent among several possible candidates. Hence, one is</context>
</contexts>
<marker>Chomsky, 1981</marker>
<rawString>Chomsky, Noam. 1981. Lectures on Government and Binding. Foris, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Bridging.</title>
<date>1975</date>
<booktitle>In Proceedings of the Conference on Theoretical Issues in Natural Language Processing,</booktitle>
<pages>169--174</pages>
<location>Cambridge, MA,</location>
<marker>Clark, 1975</marker>
<rawString>Clark, Herbert H. 1975. Bridging. In Proceedings of the Conference on Theoretical Issues in Natural Language Processing, pages 169-174, Cambridge, MA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Connolly</author>
<author>John D Burger</author>
<author>David S Day</author>
</authors>
<title>A machine learning approach to anaphoric reference.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>255--261</pages>
<location>Manchester, England,</location>
<marker>Connolly, Burger, Day, 1994</marker>
<rawString>Connolly, Dennis, John D. Burger, and David S. Day. 1994. A machine learning approach to anaphoric reference. In Proceedings of the International Conference on New Methods in Language Processing, pages 255-261, Manchester, England, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
</authors>
<title>Automatic processing of large corpora for the resolution of anaphora references.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<volume>3</volume>
<pages>330--332</pages>
<location>Helsinki, Finland,</location>
<contexts>
<context position="86288" citStr="Dagan and Itai 1990" startWordPosition="13537" endWordPosition="13540">the weights to a single salience score (Rich and LuperFoy 1988; HajRova, Kubori, and Kubori 1992; Lappin and Leass 1994) These heuristics helped to improve the performance of discourse-understanding systems through significant reductions of the available search-space for antecedents. Their major drawback is that they require a great deal of skilled hand-crafting that, unfortunately, usually does not scale in broader application domains. Hence, proposals were made to replace these high-level &amp;quot;symbolic&amp;quot; categories by statistically interpreted occurrence patterns derived from large text corpora (Dagan and Itai 1990). Preferences then reflect patterns of statistically significant lexical usage rather than introspective abstractions of linguistic patterns such as syntactic parallelism or pragmatic alignment. Among the heuristic approaches to anaphora resolution, those which consider the identification of heuristics a machine learning (ML) problem are particularly interesting, since their heuristics dynamically adapt to the textual data. Furthermore, ML procedures operate on incomplete parses (hence, they accept noisy data), which dis337 Computational Linguistics Volume 25, Number 3 tinguishes them from the</context>
</contexts>
<marker>Dagan, Itai, 1990</marker>
<rawString>Dagan, Ido and Alon Itai. 1990. Automatic processing of large corpora for the resolution of anaphora references. In Proceedings of the 13th International Conference on Computational Linguistics, volume 3, pages 330-332, Helsinki, Finland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deborah A Dahl</author>
<author>Catherine N Ball</author>
</authors>
<title>Reference resolution</title>
<date>1990</date>
<booktitle>Logic and Logic Grammars for Language Processing. Ellis Horwood,</booktitle>
<pages>168--184</pages>
<editor>in PUNDIT. In P. Saint-Dizier and S. Szpakowicz, editors,</editor>
<location>Chichester, England,</location>
<contexts>
<context position="83669" citStr="Dahl and Ball (1990)" startWordPosition="13154" endWordPosition="13157">r Focus List and Potential Discourse Focus List. Sufi and McCoy (1994) in their RAFT/RAPR approach use grammatical roles for ordering the focus lists and make a distinction between Subject Focus, Current Focus, and corresponding lists. Both focusing algorithms prefer an element that represents the Focus to the elements in the list when the anaphoric expression under consideration is not the agent (for Sidner) or the subject (for Suri and McCoy). Relating these approaches to our proposal, they already exhibit a weak preference for a single hearer-old (more precisely, evoked) discourse element. Dahl and Ball (1990), describing the anaphora resolution module of the PUNDIT system, improve the focusing mechanism by simplifying its underlying data structures. Thus, their proposal is more closely related to the centering model than any other focusing mechanism. Furthermore, if there is a pronoun in the sentence for which the Focus List is built, the corresponding evoked discourse entity is shifted to the front of the list. The following elements of the Focus List are ordered by grammatical roles again. Hence, their approach still relies upon grammatical information for the ordering of the centering list, whi</context>
<context position="95721" citStr="Dahl and Ball 1990" startWordPosition="14939" endWordPosition="14942"> These shortcomings might be traced back to the fact that the centering model, up to now, did not consider the role of the (main) verb of the utterance under scrutiny. Other cases, such as VP anaphora (Hardt 1992), temporal anaphora (Kameyama, Passonneau, and Poesio 1993; Hitzeman, Moens, and Grover 1995) have already been examined within the centering model. The particular phenomenon of paycheck anaphora is described by Hardt (1996), though he uses only a rather simplified centering model for this work. Other cases are only dealt with in the focusing framework such as propositional anaphora (Dahl and Ball 1990). 4. Evaluations of the centering model have so far only been carried out manually. This is clearly no longer rewarding, so appropriate computational support environments have to be provided. What we have in mind is a kind of discourse structure bank and associated workbenches comparable to grammar workbenches and parse treebanks. Aone and Bennett (1994), for example, report on a GUI-based Discourse Tagging Tool (DTT) that allows a user to link an anaphor with its antecedent and specify the type of the anaphor (e.g., pronoun, definite NP, etc.). The tagged result can be written out to an SGML-</context>
</contexts>
<marker>Dahl, Ball, 1990</marker>
<rawString>Dahl, Deborah A. and Catherine N. Ball. 1990. Reference resolution in PUNDIT. In P. Saint-Dizier and S. Szpakowicz, editors, Logic and Logic Grammars for Language Processing. Ellis Horwood, Chichester, England, pages 168-184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
</authors>
<title>Centering in Italian.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse,</booktitle>
<pages>115--137</pages>
<editor>In M. A. Walker, A. K. Joshi, and E. F. Prince, editors,</editor>
<publisher>University Press,</publisher>
<location>Oxford</location>
<marker>Di Eugenio, 1998</marker>
<rawString>Di Eugenio, Barbara. 1998. Centering in Italian. In M. A. Walker, A. K. Joshi, and E. F. Prince, editors, Centering Theory in Discourse, Oxford University Press, Oxford, England, pages 115-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Dunin-Keplicz</author>
<author>Witold Lukaszewicz</author>
</authors>
<title>Towards discourse-oriented nonmonotonic system.</title>
<date>1986</date>
<booktitle>In Proceedings of the 11th International Conference on Computational Linguistics,</booktitle>
<pages>504--506</pages>
<location>Bonn, Germany,</location>
<contexts>
<context position="98267" citStr="Dunin-Keplicz and Lukaszewicz 1986" startWordPosition="15330" endWordPosition="15333">, Friedman, and Pollard (1987). • At the level of discourse pragmatics, a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering (Mann and Thompson 1988). In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse (Grosz and Sidner 1986). In general, it might become increasingly necessary to integrate very deep forms of reasoning, perhaps even nonmonotonic (Dunin-Keplicz and Lukaszewicz 1986) or abductive inference mechanisms (Nagao 1989), into the anaphora resolution process. This might become a sheer necessity when incrementality of processing receives a higher level of attention in the centering community. Acknowledgments We would like to thank our colleagues from the Computational Linguistics Group in Freiburg and at the University of Pennsylvania for fruitful discussions, in particular Norbert Broker, Miriam Eckert, Aravind Joshi, Manfred Klenner, Nobo Komagata, Katja Markert, Peter Neuhaus, Ellen Prince, Rashmi Prasad, Owen Rambow, Susanne Schacht, and Bonnie Webber. We also</context>
</contexts>
<marker>Dunin-Keplicz, Lukaszewicz, 1986</marker>
<rawString>Dunin-Keplicz, Barbara and Witold Lukaszewicz. 1986. Towards discourse-oriented nonmonotonic system. In Proceedings of the 11th International Conference on Computational Linguistics, pages 504-506, Bonn, Germany, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Eckert</author>
<author>Michael Strube</author>
</authors>
<title>Resolving discourse deictic anaphora in dialogues.</title>
<date>1999</date>
<booktitle>In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>37--44</pages>
<location>Bergen, Norway,</location>
<marker>Eckert, Strube, 1999</marker>
<rawString>Eckert, Miriam and Michael Strube. 1999. Resolving discourse deictic anaphora in dialogues. In Proceedings of the 9th Conference of the European Chapter of the Association for Computational Linguistics, pages 37-44, Bergen, Norway, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Firbas</author>
</authors>
<title>Some aspects of the Czechoslovak approach to problems of functional sentence prespective.</title>
<date>1974</date>
<booktitle>Papers on Functional Sentence Perspective. Academia,</booktitle>
<pages>11--37</pages>
<editor>In F. Dane, editor,</editor>
<location>Prague,</location>
<contexts>
<context position="32684" citStr="Firbas 1974" startWordPosition="5042" endWordPosition="5043">matical ranking conditions for the forward-looking centers by additional functional notions. A deeper consideration of information structure principles and their relation to the centering model has been proposed in two studies concerned with the analysis of German and Turkish discourse. Rambow (1993) was the first to apply the centering methodology to German, aiming at the description of information structure aspects underlying scrambling and topicalization. As a side effect, he used centering to define the utterance&apos;s theme and rheme in the sense of the functional sentence perspective (FSP) (Firbas 1974). Viewed from this perspective, the theme/rheme-hierarchy of utterance 11, is determined by the Cf(Ui_i). Elements of Ui that are contained in Cf(Lli_i) are less rhematic than those not contained in Cf(Ui_i). He then concludes that the Cb(U) must be the theme of the current utterance. Rambow does not exploit the information structure of utterances to determine the Cf ranking but formulates it on the basis of linear textual precedence among the relevant discourse entities. In order to analyze Turkish texts, Hoffman (1996, 1998) distinguishes between the information structure of utterances and c</context>
</contexts>
<marker>Firbas, 1974</marker>
<rawString>Firbas, Jan. 1974. Some aspects of the Czechoslovak approach to problems of functional sentence prespective. In F. Dane, editor, Papers on Functional Sentence Perspective. Academia, Prague, pages 11-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter C Gordon</author>
<author>Barbara J Grosz</author>
<author>Laura A Gilliom</author>
</authors>
<title>Pronouns, names, and the centering of attention in discourse.</title>
<date>1993</date>
<journal>Cognitive Science,</journal>
<pages>17--311</pages>
<marker>Gordon, Grosz, Gilliom, 1993</marker>
<rawString>Gordon, Peter C., Barbara J. Grosz, and Laura A. Gilliom. 1993. Pronouns, names, and the centering of attention in discourse. Cognitive Science, 17:311-347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
</authors>
<title>The representation and use of focus in a system for understanding dialogs.</title>
<date>1977</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Artificial Intelligence,</booktitle>
<volume>1</volume>
<pages>67--76</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="3459" citStr="Grosz 1977" startWordPosition="494" endWordPosition="495">nitive Science, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104, USA t Computational Linguistics Group, Text Understanding Lab, Werthmannplatz 1, 79085 Freiburg, Germany C) 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 3 terns of language use and, thus, introduces the level of discourse context and further pragmatic factors as a complementary description level. Computational linguists have recognized the need to account for referential ambiguities in discourse and have developed various theories centered around the notion of discourse focus (Grosz 1977; Sidner 1983). In a seminal paper, Grosz and Sidner (1986) wrapped up the results of their research and formulated a model in which three levels of discourse coherence are distinguished—attention, intention, and discourse segment structure. While this paper gives a comprehensive picture of a complex, yet not explicitly spelled-out theory of discourse coherence, the centering model (Grosz, Joshi, and Weinstein, 1983, 1995) marked a major step in clarifying the relationship between attentional states and (local) discourse segment structure. More precisely, the centering model accounts for the i</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>Grosz, Barbara J. 1977. The representation and use of focus in a system for understanding dialogs. In Proceedings of the 5th International Joint Conference on Artificial Intelligence, volume 1, pages 67-76, Cambridge, MA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Providing a unified account of definite noun phrases in discourse.</title>
<date>1983</date>
<booktitle>In Proceedings of the 21st Annual Meeting,</booktitle>
<pages>44--50</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="3878" citStr="Grosz, Joshi, and Weinstein, 1983" startWordPosition="553" endWordPosition="557"> description level. Computational linguists have recognized the need to account for referential ambiguities in discourse and have developed various theories centered around the notion of discourse focus (Grosz 1977; Sidner 1983). In a seminal paper, Grosz and Sidner (1986) wrapped up the results of their research and formulated a model in which three levels of discourse coherence are distinguished—attention, intention, and discourse segment structure. While this paper gives a comprehensive picture of a complex, yet not explicitly spelled-out theory of discourse coherence, the centering model (Grosz, Joshi, and Weinstein, 1983, 1995) marked a major step in clarifying the relationship between attentional states and (local) discourse segment structure. More precisely, the centering model accounts for the interactions between local coherence and preferential choices of referring expressions. It relates differences in coherence (in part) to varying demands on inferences as required by different types of referring expressions, given a particular attentional state of the hearer in a discourse setting (Grosz, Joshi, and Weinstein 1995, 204-205). The claim is made then that the lower the inference load put on the hearer, t</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1983</marker>
<rawString>Grosz, Barbara J., Aravind K. Joshi, and Scott Weinstein. 1983. Providing a unified account of definite noun phrases in discourse. In Proceedings of the 21st Annual Meeting, pages 44-50, Cambridge, MA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Aravind K Joshi</author>
<author>Scott Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--2</pages>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>Grosz, Barbara J., Aravind K. Joshi, and Scott Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):203-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="3518" citStr="Grosz and Sidner (1986)" startWordPosition="502" endWordPosition="505">, Philadelphia, PA 19104, USA t Computational Linguistics Group, Text Understanding Lab, Werthmannplatz 1, 79085 Freiburg, Germany C) 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 3 terns of language use and, thus, introduces the level of discourse context and further pragmatic factors as a complementary description level. Computational linguists have recognized the need to account for referential ambiguities in discourse and have developed various theories centered around the notion of discourse focus (Grosz 1977; Sidner 1983). In a seminal paper, Grosz and Sidner (1986) wrapped up the results of their research and formulated a model in which three levels of discourse coherence are distinguished—attention, intention, and discourse segment structure. While this paper gives a comprehensive picture of a complex, yet not explicitly spelled-out theory of discourse coherence, the centering model (Grosz, Joshi, and Weinstein, 1983, 1995) marked a major step in clarifying the relationship between attentional states and (local) discourse segment structure. More precisely, the centering model accounts for the interactions between local coherence and preferential choice</context>
<context position="18971" citStr="Grosz and Sidner 1986" startWordPosition="2846" endWordPosition="2849">ical roles. subject &gt; object(s) &gt; other(s) Table 2 Transition types. Cb(U) = Cp(U,) Cb(L11) Cp(U,) Cb(L11) = Cb(Ui_i) Cb(U,) Cb(111_1) CONTINUE SHIFT RETAIN 3. The Centering Model The centering model (Grosz, Joshi, and Weinstein 1983, 1995) is intended to describe the relationship between local coherence and the use of referring expressions. The model requires two constructs, a single backward-looking center and a list of forwardlooking centers, as well as a few rules and constraints that govern the interpretation of centers. It is assumed that discourses are composed of constituent segments (Grosz and Sidner 1986), each of which consists of a sequence of utterances. Each utterance L/i in a given discourse segment DS is assigned a list of forward-looking centers, Cf(DS, Ui), and a unique backward-looking center, Cb(DS, Lb). The forward-looking centers of U, depend only on the discourse entities that constitute the ith utterance; previous utterances provide no constraints on Cf(DS, U,). A ranking imposed on the elements of the Cf reflects the assumption that the most highly ranked element of Cf(DS, LJ), the preferred center Cp(DS, Lli), will most likely be the Cb(DS, U,+1). The most highly ranked element</context>
<context position="90449" citStr="Grosz and Sidner 1986" startWordPosition="14132" endWordPosition="14135">rformance by proper evidence &amp;quot;engineering&amp;quot;. This is often done in an admittedly ad hoc way, requiring tricky retuning when new evidence is added (Rich and LuperFoy 1988). On the other hand, many of these systems work in a real-world environment (Rich and LuperFoy 1988; Lappin and Leass 1994; Kennedy and Boguraev 1996) in which noisy data and incomplete, sometimes even faulty, analysis results have to be accounted for. The centering model differs from these considerations in that it aims at unfolding a unified theory of discourse coherence at the linguistic, attentional, and intentional level (Grosz and Sidner 1986); hence, the search for a more principled, theory-based solution, but also the need for (almost) perfect linguistic analyses in terms of parsing and semantic interpretation. 7. Conclusion In this paper, we provided a novel account for ordering the forward-looking center list, a major construct of the centering model. The new formulation is entirely based on functional notions, grounded in the information structure of utterances in a discourse. 338 Strube and Hahn Functional Centering We motivated our proposal by the constraints that hold for a free-word-order language such as German and derive</context>
<context position="98109" citStr="Grosz and Sidner 1986" startWordPosition="15309" endWordPosition="15312">centering to these phenomena is presented in Hahn and Strube (1997), while Walker (1998) builds upon the centering algorithm described in Brennan, Friedman, and Pollard (1987). • At the level of discourse pragmatics, a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering (Mann and Thompson 1988). In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse (Grosz and Sidner 1986). In general, it might become increasingly necessary to integrate very deep forms of reasoning, perhaps even nonmonotonic (Dunin-Keplicz and Lukaszewicz 1986) or abductive inference mechanisms (Nagao 1989), into the anaphora resolution process. This might become a sheer necessity when incrementality of processing receives a higher level of attention in the centering community. Acknowledgments We would like to thank our colleagues from the Computational Linguistics Group in Freiburg and at the University of Pennsylvania for fruitful discussions, in particular Norbert Broker, Miriam Eckert, Arav</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, Barbara J. and Candace L. Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas J Haddock</author>
</authors>
<title>Incremental interpretation and combinatory categorial grammar.</title>
<date>1987</date>
<booktitle>In Proceedings of the 10th International Joint Conference on Artificial Intelligence,</booktitle>
<volume>2</volume>
<pages>661--663</pages>
<location>Milan, Italy,</location>
<contexts>
<context position="1760" citStr="Haddock 1987" startWordPosition="251" endWordPosition="252">dology for the assessment of centering data, one which can be directly derived from and justified by the cognitive load premises of the centering model. 1. Introduction The problem of establishing referential coherence in discourse can be rephrased as the problem of determining the proper antecedent of a given anaphoric expression in the current or the preceding utterance(s) and the rendering of both as referentially identical (coreferential). This task can be approached in a very principled way by stating general constraints on the grammatical compatibility of the expressions involved (e.g., Haddock 1987; Alshawi 1992). Linguists have devoted a lot of effort to identifying conclusive syntactic and semantic criteria to reach this goal, e.g., for intrasentential anaphora within the binding theory part of the theory of Government and Binding (Chomsky 1981), or for intersentential anaphora within the context of the Discourse Representation Theory (Kamp and Reyle 1993). Unfortunately, these frameworks fail to uniquely determine anaphoric antecedents in a variety of cases. As a consequence, referentially ambiguous interpretations have to be dealt with in those cases in which several alternatives fu</context>
</contexts>
<marker>Haddock, 1987</marker>
<rawString>Haddock, Nicholas J. 1987. Incremental interpretation and combinatory categorial grammar. In Proceedings of the 10th International Joint Conference on Artificial Intelligence, volume 2, pages 661-663, Milan, Italy, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Katja Markert</author>
<author>Michael Strube</author>
</authors>
<title>A conceptual reasoning approach to textual ellipsis.</title>
<date>1996</date>
<booktitle>In Proceedings of the 12th European Conference on Artificial Intelligence,</booktitle>
<pages>572--576</pages>
<location>Budapest, Hungary</location>
<marker>Hahn, Markert, Strube, 1996</marker>
<rawString>Hahn, Udo, Katja Markert, and Michael Strube. 1996. A conceptual reasoning approach to textual ellipsis. In Proceedings of the 12th European Conference on Artificial Intelligence, pages 572-576, Budapest, Hungary August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Peter Neuhaus</author>
<author>Norbert Broker</author>
</authors>
<title>Message-passing protocols for real-world parsing: An object-oriented model and its preliminary evaluation.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th International Workshop on Parsing Technologies,</booktitle>
<pages>101--112</pages>
<marker>Hahn, Neuhaus, Broker, 1997</marker>
<rawString>Hahn, Udo, Peter Neuhaus, and Norbert Broker. 1997. Message-passing protocols for real-world parsing: An object-oriented model and its preliminary evaluation. In Proceedings of the 5th International Workshop on Parsing Technologies, pages 101-112,</rawString>
</citation>
<citation valid="false">
<date></date>
<institution>Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA,</location>
<marker></marker>
<rawString>Massachusetts Institute of Technology, Cambridge, MA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Martin Romacker</author>
<author>Stefan Schulz</author>
</authors>
<title>Discourse structures in medical reports—watch out! The generation of referentially coherent and valid text knowledge bases in mEDSvNDIK ATE system.</title>
<date>1999</date>
<journal>International Journal of Medical Informatics,</journal>
<pages>53--1</pages>
<marker>Hahn, Romacker, Schulz, 1999</marker>
<rawString>Hahn, Udo, Martin Romacker, and Stefan Schulz. 1999. Discourse structures in medical reports—watch out! The generation of referentially coherent and valid text knowledge bases in mEDSvNDIK ATE system. International Journal of Medical Informatics, 53(1):1-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Susanne Schacht</author>
<author>Norbert Broker</author>
</authors>
<title>Concurrent, object-oriented natural language parsing: The PARSETALK model.</title>
<date>1994</date>
<journal>International Journal of Human-Computer Studies,</journal>
<pages>41--1</pages>
<marker>Hahn, Schacht, Broker, 1994</marker>
<rawString>Hahn, Udo, Susanne Schacht, and Norbert Broker. 1994. Concurrent, object-oriented natural language parsing: The PARSETALK model. International Journal of Human-Computer Studies, 41(1/2):179-222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Klemens Schrtattinger</author>
</authors>
<title>Towards text knowledge engineering.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th National Conference on Artificial Intelligence &amp; the 10th Conference on Innovative Applications of Artificial Intelligence,</booktitle>
<pages>524--531</pages>
<location>Madison, WI,</location>
<marker>Hahn, Schrtattinger, 1998</marker>
<rawString>Hahn, Udo and Klemens Schrtattinger. 1998. Towards text knowledge engineering. In Proceedings of the 15th National Conference on Artificial Intelligence &amp; the 10th Conference on Innovative Applications of Artificial Intelligence, pages 524-531, Madison, WI, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Michael Strube</author>
</authors>
<title>Incremental centering and center ambiguity.</title>
<date>1996</date>
<booktitle>In Proceedings of the 18th Annual Conference of the Cognitive Science Society,</booktitle>
<pages>568--573</pages>
<location>LaJolla, CA,</location>
<contexts>
<context position="6169" citStr="Hahn and Strube 1996" startWordPosition="909" endWordPosition="912"> criteria appropriate for different languages. In fact, Walker, Iida, and Cote (1994) hypothesize that the Cf ranking criteria are the only language-dependent factors within the centering model. Though evidence for many additional criteria for the Cf ranking have been brought forward in the literature, to some extent consensus has emerged that grammatical roles play a major role in making ranking decisions (e.g., whether the referential expression appears as the grammatical subject, direct object, or indirect object of an utterance). Our own work on the centering model&apos; (Strube and Hahn 1996; Hahn and Strube 1996) brings in evidence from German, a free-word-order language in which grammatical role information is far less predictive of the organization of centers than for fixed-word-order languages such as English. In establishing proper referential relations, we found the functional information structure of the utterances to be much more relevant. By this we mean indicators of whether or not a discourse entity in the current utterance refers to another discourse entity already introduced by previous utterances in the discourse. Borrowing terminology from Prince (1981, 1992), an entity that does refer t</context>
<context position="10181" citStr="Hahn and Strube 1996" startWordPosition="1514" endWordPosition="1517"> the centering literature, e.g., by asserting that the entity in question &amp;quot;is realized but not directly realized&amp;quot; (Grosz, Joshi, and Weinstein 1995, 217). Furthermore, the distinction between these two kinds of realization is not part of the centering mechanisms but delegated to the underlying semantic theory. We will develop arguments for how to discern inferable discourse entities and relate them properly to their antecedent at the center level. The ordering constraints we supply account for all of the types of anaphora mentioned above, including (pro)nominal anaphora (Strube and Hahn 1995; Hahn and Strube 1996). This claim will be validated by a substantial body of empirical data in Section 5. Our third contribution relates to the way the results of centering-based anaphora resolution are usually evaluated. Basically, we argue that rather than counting resolution rates for anaphora or comparing isolated transition types holding among head positions in the center lists—preferred transition types stand for a high degree of local coherence, while less preferred ones signal that the underlying discourse might lack coherence—one should consider adjacent transition pairs and annotate such pairs with the p</context>
<context position="94576" citStr="Hahn and Strube (1996)" startWordPosition="14763" endWordPosition="14766">he Cf list. Walker and Prince (1996) propose a &amp;quot;working hypothesis&amp;quot; based on the surface order. Strube (1998) provides a complete specification for dealing with complex sentences, but this approach departs significantly from the centering model. 2. It seems that there exist only a few fully operational implementations of centering-based algorithms, since the interaction of the algorithm with global and local ambiguities generated by a sentence parser has not received much attention until now. A first proposal for how to deal with center ambiguity in an incremental text parser has been made by Hahn and Strube (1996). 339 Computational Linguistics Volume 25, Number 3 3. The centering model covers the standard cases of anaphora, i.e., pronominal and nominal anaphora and even functional anaphora based on the proposal we have developed in this article. It does not, however, take into account several &amp;quot;hard&amp;quot; issues such as plural anaphora, generic definite noun phrases, propositional anaphora, and deictic forms (but see Eckert and Strube [1999] for a treatment of discourse-deictic anaphora in dialogues within a centering-type framework). These shortcomings might be traced back to the fact that the centering mo</context>
</contexts>
<marker>Hahn, Strube, 1996</marker>
<rawString>Hahn, Udo and Michael Strube. 1996. Incremental centering and center ambiguity. In Proceedings of the 18th Annual Conference of the Cognitive Science Society, pages 568-573, LaJolla, CA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Michael Strube</author>
</authors>
<title>Centering in-the-large: Computing referential discourse segments.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>104--111</pages>
<location>Madrid, Spain,</location>
<contexts>
<context position="97554" citStr="Hahn and Strube (1997)" startWordPosition="15222" endWordPosition="15225">se, i.e., it allows only the consideration of immediately adjacent centering structures for establishing proper referential links. In order to extend that theory to the level of global coherence, various steps have to be taken. • At the referential level, mechanisms have to be introduced to account for reference relationships that extend beyond the immediately preceding utterance. Empirical evidence for such phenomena exists in the literature and we also found the need to have such a mechanism available for longer texts. The extension of functional centering to these phenomena is presented in Hahn and Strube (1997), while Walker (1998) builds upon the centering algorithm described in Brennan, Friedman, and Pollard (1987). • At the level of discourse pragmatics, a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering (Mann and Thompson 1988). In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse (Grosz and Sidner 1986). In general, it might become increasingly ne</context>
</contexts>
<marker>Hahn, Strube, 1997</marker>
<rawString>Hahn, Udo and Michael Strube. 1997. Centering in-the-large: Computing referential discourse segments. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics and the 8th Conference of the European Chapter of the Association for Computational Linguistics, pages 104-111, Madrid, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva HajRova</author>
<author>Vladislav Kuboti</author>
<author>Petr Kuborl</author>
</authors>
<title>Stock of shared knowledge: A tool for solving pronominal anaphora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>127--133</pages>
<location>Nantes, France,</location>
<marker>HajRova, Kuboti, Kuborl, 1992</marker>
<rawString>HajR&amp;quot;ova, Eva, Vladislav Kuboti, and Petr Kuborl. 1992. Stock of shared knowledge: A tool for solving pronominal anaphora. In Proceedings of the 15th International Conference on Computational Linguistics, volume 1, pages 127-133, Nantes, France, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Hardt</author>
</authors>
<title>An algorithm for VP ellipsis.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting,</booktitle>
<pages>9--14</pages>
<institution>June–July. Association for Computational Linguistics.</institution>
<location>Newark, DE,</location>
<contexts>
<context position="95315" citStr="Hardt 1992" startWordPosition="14880" endWordPosition="14881">al and nominal anaphora and even functional anaphora based on the proposal we have developed in this article. It does not, however, take into account several &amp;quot;hard&amp;quot; issues such as plural anaphora, generic definite noun phrases, propositional anaphora, and deictic forms (but see Eckert and Strube [1999] for a treatment of discourse-deictic anaphora in dialogues within a centering-type framework). These shortcomings might be traced back to the fact that the centering model, up to now, did not consider the role of the (main) verb of the utterance under scrutiny. Other cases, such as VP anaphora (Hardt 1992), temporal anaphora (Kameyama, Passonneau, and Poesio 1993; Hitzeman, Moens, and Grover 1995) have already been examined within the centering model. The particular phenomenon of paycheck anaphora is described by Hardt (1996), though he uses only a rather simplified centering model for this work. Other cases are only dealt with in the focusing framework such as propositional anaphora (Dahl and Ball 1990). 4. Evaluations of the centering model have so far only been carried out manually. This is clearly no longer rewarding, so appropriate computational support environments have to be provided. Wh</context>
</contexts>
<marker>Hardt, 1992</marker>
<rawString>Hardt, Daniel. 1992. An algorithm for VP ellipsis. In Proceedings of the 30th Annual Meeting, pages 9-14, Newark, DE, June–July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Hardt</author>
</authors>
<title>Centering in dynamic semantics.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>519--524</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="95539" citStr="Hardt (1996)" startWordPosition="14911" endWordPosition="14912">ses, propositional anaphora, and deictic forms (but see Eckert and Strube [1999] for a treatment of discourse-deictic anaphora in dialogues within a centering-type framework). These shortcomings might be traced back to the fact that the centering model, up to now, did not consider the role of the (main) verb of the utterance under scrutiny. Other cases, such as VP anaphora (Hardt 1992), temporal anaphora (Kameyama, Passonneau, and Poesio 1993; Hitzeman, Moens, and Grover 1995) have already been examined within the centering model. The particular phenomenon of paycheck anaphora is described by Hardt (1996), though he uses only a rather simplified centering model for this work. Other cases are only dealt with in the focusing framework such as propositional anaphora (Dahl and Ball 1990). 4. Evaluations of the centering model have so far only been carried out manually. This is clearly no longer rewarding, so appropriate computational support environments have to be provided. What we have in mind is a kind of discourse structure bank and associated workbenches comparable to grammar workbenches and parse treebanks. Aone and Bennett (1994), for example, report on a GUI-based Discourse Tagging Tool (D</context>
</contexts>
<marker>Hardt, 1996</marker>
<rawString>Hardt, Daniel. 1996. Centering in dynamic semantics. In Proceedings of the 16th International Conference on Computational Linguistics, volume 1, pages 519-524, Copenhagen, Denmark, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Moens</author>
<author>Claire Grover</author>
</authors>
<title>Algorithms for analysing the temporal structure of discourse.</title>
<date>1995</date>
<booktitle>In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>253--260</pages>
<location>Dublin, Ireland,</location>
<marker>Moens, Grover, 1995</marker>
<rawString>Hitzeman, Janet. Marc Moens, and Claire Grover. 1995. Algorithms for analysing the temporal structure of discourse. In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics, pages 253-260, Dublin, Ireland, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beryl Hoffman</author>
</authors>
<title>Translating into free word order languages.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>556--561</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="30701" citStr="Hoffman 1996" startWordPosition="4724" endWordPosition="4725">ld be violated in the rejected reading. 4. Principles of Functional Centering The crucial point underlying functional centering is to relate the ranking of the forwardlooking centers and the information structure of the corresponding utterances. Hence, a proper correspondence relation between the basic centering data structures and the relevant functional notions has to be established and formally rephrased in terms of the centering model. In this section, we first discuss two studies in which the information structure of utterances is already integrated into the centering model (Rambow 1993; Hoffman 1996, 1998). Using these proposals as a point of departure, we shall develop our own proposal—functional centering (Strube and Hahn 1996). 4.1 Integrating Information Structure and Centering As far as the centering model is concerned, the first account involving information structure criteria was given by Kameyama (1986) and further refined by Walker, Iida, and Cote (1994) in their study on the use of zero pronouns and topic mark9 Walker, Iida, and Cote (1994) note that it is possible to improve the computational efficiency of the algorithm by interleaving generating, filtering, and ranking steps;</context>
<context position="33209" citStr="Hoffman (1996" startWordPosition="5125" endWordPosition="5126"> theme and rheme in the sense of the functional sentence perspective (FSP) (Firbas 1974). Viewed from this perspective, the theme/rheme-hierarchy of utterance 11, is determined by the Cf(Ui_i). Elements of Ui that are contained in Cf(Lli_i) are less rhematic than those not contained in Cf(Ui_i). He then concludes that the Cb(U) must be the theme of the current utterance. Rambow does not exploit the information structure of utterances to determine the Cf ranking but formulates it on the basis of linear textual precedence among the relevant discourse entities. In order to analyze Turkish texts, Hoffman (1996, 1998) distinguishes between the information structure of utterances and centering, since both constructs are assigned different functions for text understanding. A hearer exploits the information structure of an utterance to update his discourse model, and he applies the centering constraints in order to connect the current utterance to the previous discourse. Hoffman describes the information structure of an utterance in terms of topic (theme) and comment (rheme). The comment is split again into focus and (back)ground (see also Vallduvi [1990] and Vallduvi and Engdahl [1996]). Based on prev</context>
<context position="34584" citStr="Hoffman (1996" startWordPosition="5338" endWordPosition="5339"> verb yields the focus, and the remainder of the sentence is to be considered the (back)ground. Furthermore, Hoffman relates this notion of information structure of utterances to centering, claiming that the topic corresponds to the Cb in most cases—with the exception of segment-initial utterances, which do not have a Cb. Hoffman does not say anything about the relation between information structure and the ranking of the 319 Computational Linguistics Volume 25, Number 3 Cf list. In her approach, this ranking is achieved by thematic roles (see also Turan [1998]). Both Rambow (1983) as well as Hoffman (1996, 1998) argue for a correlation between the information structure of utterances and centering. Both of them find a correspondence between the Cb and the theme or the topic of an utterance. They refrain, however, from establishing a strong link between the information structure and centering as we suggest in our model, one that mirrors the influence of information structure in the way the forward-looking centers are actually ranked. 4.2 Functional Centering Grosz, Joshi, and Weinstein (1995) admit that several factors may have an influence on the ranking of the Cf but limit their exposition to </context>
</contexts>
<marker>Hoffman, 1996</marker>
<rawString>Hoffman, Beryl. 1996. Translating into free word order languages. In Proceedings of the 16th International Conference on Computational Linguistics, volume 1, pages 556-561, Copenhagen, Denmark, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beryl Hoffman</author>
</authors>
<title>Word order, information structure, and centering in Turkish.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse,</booktitle>
<pages>251--271</pages>
<editor>In M. A. Walker, A. K. Joshi, and E. F. Prince, editors,</editor>
<publisher>University Press,</publisher>
<location>Oxford</location>
<marker>Hoffman, 1998</marker>
<rawString>Hoffman, Beryl. 1998. Word order, information structure, and centering in Turkish. In M. A. Walker, A. K. Joshi, and E. F. Prince, editors, Centering Theory in Discourse, pages 251-271, Oxford University Press, Oxford, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Osvaldo Jaeggli</author>
</authors>
<title>Arbitrary plural pronominals.</title>
<date>1986</date>
<booktitle>Natural Language and Linguistic Theory,</booktitle>
<pages>4--43</pages>
<contexts>
<context position="15196" citStr="Jaeggli (1986)" startWordPosition="2258" endWordPosition="2259">etween the inferable and its antecedent. Of course, contextual conceptual constraints are introduced for both nominal and pronominal anaphora by sortal requirements set up, e.g., by the case roles of the main verb. 2 We have also considered the role of anaphora within sentences. The d-binding criterion we have developed for resolving intrasentential anaphora is based on dependency grammar notions described in more detail in Strube and Hahn (1995). 3 Note that Reserve-Batteriepack in Example (la) and Akkus in (lb) denote conceptually different discourse entities that cannot be coindexed. 4 See Jaeggli (1986) for special cases where this criterion is overruled. 312 Strube and Hahn Functional Centering Let us illustrate these different types of phenomena by considering the following text fragment: Example 1 a. Ein Reserve-Batteriepack versorgt den 316LT ca. 2 Minuten mit Strom. [A reserve battery pack]io. — supplies — the [3/6LT],,, — for approximately 2 minutes — with power. The 316LT is supplied with power by a reserve battery pack for approximately 2 minutes. b. Der Status des Akkus wird dem Anwender angezeigt. [The status — [of the rechargeable battery celligen]nom — is — [to the userldat — sig</context>
</contexts>
<marker>Jaeggli, 1986</marker>
<rawString>Jaeggli, Osvaldo. 1986. Arbitrary plural pronominals. Natural Language and Linguistic Theory, 4:43-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megumi Kameyama</author>
</authors>
<title>A property-sharing constraint in centering.</title>
<date>1986</date>
<booktitle>In Proceedings of the 24th Annual Meeting,</booktitle>
<pages>200--206</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York, NY,</location>
<contexts>
<context position="31019" citStr="Kameyama (1986)" startWordPosition="4771" endWordPosition="4772">ata structures and the relevant functional notions has to be established and formally rephrased in terms of the centering model. In this section, we first discuss two studies in which the information structure of utterances is already integrated into the centering model (Rambow 1993; Hoffman 1996, 1998). Using these proposals as a point of departure, we shall develop our own proposal—functional centering (Strube and Hahn 1996). 4.1 Integrating Information Structure and Centering As far as the centering model is concerned, the first account involving information structure criteria was given by Kameyama (1986) and further refined by Walker, Iida, and Cote (1994) in their study on the use of zero pronouns and topic mark9 Walker, Iida, and Cote (1994) note that it is possible to improve the computational efficiency of the algorithm by interleaving generating, filtering, and ranking steps; cf. the version of the algorithm described by Walker (1998). 318 Strube and Hahn Functional Centering Table 7 Centering analysis for the text fragment in example (2) according to the BFP algorithm. The sentry was not dead. — Cb:— Cf: [SENTRY: sentry] He was, in fact, showing signs of reviving ... CONTINUE Cb: SENTRY</context>
</contexts>
<marker>Kameyama, 1986</marker>
<rawString>Kameyama, Megumi. 1986. A property-sharing constraint in centering. In Proceedings of the 24th Annual Meeting, pages 200-206, New York, NY, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megumi Kameyama</author>
</authors>
<title>Intrasentential centering: A case study.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse.</booktitle>
<pages>89--112</pages>
<editor>In M. A. Walker, A. K. Joshi, and E. F. Prince, editors,</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford, England,</location>
<contexts>
<context position="44118" citStr="Kameyama (1998)" startWordPosition="6821" endWordPosition="6822">sic relation for the overall ranking of the elements in the Cf. Accordingly, any hearer-old expression in utterance LI, is given the highest preference as a potential antecedent for an anaphoric expression in U1±1. Any 13 Examples (3) and (5)—(8) are from the New York Times, Dec. 11, 1997. (&amp;quot;Remembering one who remembered. Eugen Zuckermann, survivor, kept the ghosts of the holocaust alive,&amp;quot; by Barry Bearak.) Example (4) is from the New York Times, Dec. 1, 1997. (&amp;quot;Winnie Mandela is defiant, calling accusations &apos;lunacy&apos;,&amp;quot; by Suzanne Daley.) We split complex sentences into the units specified by Kameyama (1998) following the categorization in Figure 1. 322 Strube and Hahn Functional Centering Table 8 Sets of discourse entities for the basic Cf ranking. DE the set of discourse entities in Ili the set of evoked discourse entities in LI, the set of unused discourse entities in LT, OLD := E U U NEW := DE — OLD Table 9 Basic functional ranking constraints on the Cf list. 1. If x E OLD and y E NEW, then x y. 2. If x, y E OLD or x,y E NEW, then x y, if posx &lt; posy 3. If (1) or (2) do not apply, then x and y are unordered with respect to the Cf-ranking. hearer-new expression is ranked below hearer-old expre</context>
<context position="93193" citStr="Kameyama (1998)" startWordPosition="14547" endWordPosition="14548">nsideration in the centering framework. The following list mentions only the most pertinent issues that have come to our attention and complements the list given by Grosz, Joshi, and Weinstein (1995): 1. The centering model is rather agnostic about the intricacies of complex sentences such as relative clauses, subordinate clauses, coordinations, and complex noun phrases. The problem caused by these structures for the centering model is how to decompose a complex sentence into center-updating units and how to process complex utterances consisting of multiple clauses. A first proposal is due to Kameyama (1998) who breaks a complex sentence into a hierarchy of center-updating units. Furthermore, she distinguishes several types of constructions in order to decide which part of the sentence is relevant for the resolution of an intersentential anaphor in the following sentence. Strube (1996b) (with respect to centering) and Suri and McCoy (1994) (with respect to the focus model) describe similar approaches and provide algorithms for the interaction of the resolution of inter- and intrasentential anaphora, but the topic has certainly not been dealt with exhaustively. The problem of complex NPs was point</context>
</contexts>
<marker>Kameyama, 1998</marker>
<rawString>Kameyama, Megumi. 1998. Intrasentential centering: A case study. In M. A. Walker, A. K. Joshi, and E. F. Prince, editors, Centering Theory in Discourse. Oxford University Press, Oxford, England, pages 89-112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Megumi Kameyama</author>
<author>Rebecca Passonneau</author>
<author>Massimo Poesio</author>
</authors>
<title>Temporal centering.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting,</booktitle>
<pages>70--77</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, OH,</location>
<marker>Kameyama, Passonneau, Poesio, 1993</marker>
<rawString>Kameyama, Megumi, Rebecca Passonneau, and Massimo Poesio. 1993. Temporal centering. In Proceedings of the 31st Annual Meeting, pages 70-77, Columbus, OH, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic. Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory.</title>
<date>1993</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="2127" citStr="Kamp and Reyle 1993" startWordPosition="303" endWordPosition="306">eding utterance(s) and the rendering of both as referentially identical (coreferential). This task can be approached in a very principled way by stating general constraints on the grammatical compatibility of the expressions involved (e.g., Haddock 1987; Alshawi 1992). Linguists have devoted a lot of effort to identifying conclusive syntactic and semantic criteria to reach this goal, e.g., for intrasentential anaphora within the binding theory part of the theory of Government and Binding (Chomsky 1981), or for intersentential anaphora within the context of the Discourse Representation Theory (Kamp and Reyle 1993). Unfortunately, these frameworks fail to uniquely determine anaphoric antecedents in a variety of cases. As a consequence, referentially ambiguous interpretations have to be dealt with in those cases in which several alternatives fulfill all the required syntactic and semantic constraints. It seems that syntactic and semantic criteria constitute only necessary but by no means sufficient conditions for identifying the valid antecedent among several possible candidates. Hence, one is left with a preferential choice problem that falls outside of the scope of those strict grammaticality constrain</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Kamp, Hans and Uwe Reyle. 1993. From Discourse to Logic. Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
<author>Branimir Boguraev</author>
</authors>
<title>Anaphora for everyone: Pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>113--118</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="90146" citStr="Kennedy and Boguraev 1996" startWordPosition="14085" endWordPosition="14088"> theory of preferential anaphora resolution, one should clearly stress the different goals behind heuristics-based systems, such as the ones just discussed, and the model of centering. Heuristic approaches combine introspectively acquired descriptive evidence and attempt to optimize reference resolution performance by proper evidence &amp;quot;engineering&amp;quot;. This is often done in an admittedly ad hoc way, requiring tricky retuning when new evidence is added (Rich and LuperFoy 1988). On the other hand, many of these systems work in a real-world environment (Rich and LuperFoy 1988; Lappin and Leass 1994; Kennedy and Boguraev 1996) in which noisy data and incomplete, sometimes even faulty, analysis results have to be accounted for. The centering model differs from these considerations in that it aims at unfolding a unified theory of discourse coherence at the linguistic, attentional, and intentional level (Grosz and Sidner 1986); hence, the search for a more principled, theory-based solution, but also the need for (almost) perfect linguistic analyses in terms of parsing and semantic interpretation. 7. Conclusion In this paper, we provided a novel account for ordering the forward-looking center list, a major construct of</context>
</contexts>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>Kennedy, Christopher and Branimir Boguraev. 1996. Anaphora for everyone: Pronominal anaphora resolution without a parser. In Proceedings of the 16th International Conference on Computational Linguistics, volume 1, pages 113-118, Copenhagen, Denmark, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shalom Lappin</author>
<author>Herbert J Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--4</pages>
<contexts>
<context position="85788" citStr="Lappin and Leass 1994" startWordPosition="13471" endWordPosition="13474">nvolving case role filling, semantic and pragmatic alignment, syntactic parallelism, syntactic topicalization, and intersentential recency. Given such a wealth of criteria one may either try to order them a priori in terms of importance or—as was proposed by the majority of researchers in this field— define several scoring functions that compute flexible orderings on the fly. These combine the variety of available evidence, each one usually annotated by a specific weight factor, and, finally, map the weights to a single salience score (Rich and LuperFoy 1988; HajRova, Kubori, and Kubori 1992; Lappin and Leass 1994) These heuristics helped to improve the performance of discourse-understanding systems through significant reductions of the available search-space for antecedents. Their major drawback is that they require a great deal of skilled hand-crafting that, unfortunately, usually does not scale in broader application domains. Hence, proposals were made to replace these high-level &amp;quot;symbolic&amp;quot; categories by statistically interpreted occurrence patterns derived from large text corpora (Dagan and Itai 1990). Preferences then reflect patterns of statistically significant lexical usage rather than introspec</context>
<context position="90118" citStr="Lappin and Leass 1994" startWordPosition="14081" endWordPosition="14084">ering is not a complete theory of preferential anaphora resolution, one should clearly stress the different goals behind heuristics-based systems, such as the ones just discussed, and the model of centering. Heuristic approaches combine introspectively acquired descriptive evidence and attempt to optimize reference resolution performance by proper evidence &amp;quot;engineering&amp;quot;. This is often done in an admittedly ad hoc way, requiring tricky retuning when new evidence is added (Rich and LuperFoy 1988). On the other hand, many of these systems work in a real-world environment (Rich and LuperFoy 1988; Lappin and Leass 1994; Kennedy and Boguraev 1996) in which noisy data and incomplete, sometimes even faulty, analysis results have to be accounted for. The centering model differs from these considerations in that it aims at unfolding a unified theory of discourse coherence at the linguistic, attentional, and intentional level (Grosz and Sidner 1986); hence, the search for a more principled, theory-based solution, but also the need for (almost) perfect linguistic analyses in terms of parsing and semantic interpretation. 7. Conclusion In this paper, we provided a novel account for ordering the forward-looking cente</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Lappin, Shalom and Herbert J. Leass. 1994. An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535-561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text,</tech>
<pages>8--3</pages>
<contexts>
<context position="97918" citStr="Mann and Thompson 1988" startWordPosition="15278" endWordPosition="15281">preceding utterance. Empirical evidence for such phenomena exists in the literature and we also found the need to have such a mechanism available for longer texts. The extension of functional centering to these phenomena is presented in Hahn and Strube (1997), while Walker (1998) builds upon the centering algorithm described in Brennan, Friedman, and Pollard (1987). • At the level of discourse pragmatics, a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering (Mann and Thompson 1988). In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse (Grosz and Sidner 1986). In general, it might become increasingly necessary to integrate very deep forms of reasoning, perhaps even nonmonotonic (Dunin-Keplicz and Lukaszewicz 1986) or abductive inference mechanisms (Nagao 1989), into the anaphora resolution process. This might become a sheer necessity when incrementality of processing receives a higher level of attention in the centering community. Acknowledgments We would like</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>Mann, William C. and Sandra A. Thompson. 1988. Rhetorical Structure Theory: Toward a functional theory of text organization. Text, 8(3):243-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katashi Nagao</author>
</authors>
<title>Semantic interpretation based on the multi-world model.</title>
<date>1989</date>
<booktitle>In Proceedings of the 11th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1--467</pages>
<location>Detroit, MI,</location>
<contexts>
<context position="98314" citStr="Nagao 1989" startWordPosition="15338" endWordPosition="15339"> a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering (Mann and Thompson 1988). In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse (Grosz and Sidner 1986). In general, it might become increasingly necessary to integrate very deep forms of reasoning, perhaps even nonmonotonic (Dunin-Keplicz and Lukaszewicz 1986) or abductive inference mechanisms (Nagao 1989), into the anaphora resolution process. This might become a sheer necessity when incrementality of processing receives a higher level of attention in the centering community. Acknowledgments We would like to thank our colleagues from the Computational Linguistics Group in Freiburg and at the University of Pennsylvania for fruitful discussions, in particular Norbert Broker, Miriam Eckert, Aravind Joshi, Manfred Klenner, Nobo Komagata, Katja Markert, Peter Neuhaus, Ellen Prince, Rashmi Prasad, Owen Rambow, Susanne Schacht, and Bonnie Webber. We also owe special thanks to the four reviewers whose</context>
</contexts>
<marker>Nagao, 1989</marker>
<rawString>Nagao, Katashi. 1989. Semantic interpretation based on the multi-world model. In Proceedings of the 11th International Joint Conference on Artificial Intelligence, pages 1,467-1,473, Detroit, MI, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>Towards a taxonomy of given-new information.</title>
<date>1981</date>
<pages>223--255</pages>
<editor>In P. Cole, editor, Radical Pragmatics.</editor>
<publisher>Academic Press,</publisher>
<location>New York, NY,</location>
<contexts>
<context position="6733" citStr="Prince (1981" startWordPosition="993" endWordPosition="994">el&apos; (Strube and Hahn 1996; Hahn and Strube 1996) brings in evidence from German, a free-word-order language in which grammatical role information is far less predictive of the organization of centers than for fixed-word-order languages such as English. In establishing proper referential relations, we found the functional information structure of the utterances to be much more relevant. By this we mean indicators of whether or not a discourse entity in the current utterance refers to another discourse entity already introduced by previous utterances in the discourse. Borrowing terminology from Prince (1981, 1992), an entity that does refer to another discourse entity already introduced is called discourse-old or hearer-old, while an entity that does not refer to another discourse entity is called discourse-new or hearer-new. 1 This article is an extended and revised version of our contribution to the 1996 Annual Meeting of the Association for Computational Linguistics (Strube and Hahn 1996). It contains additional material from the doctoral thesis of the first author (Strube 1996a). 310 Strube and Hahn Functional Centering Based on evidence from empirical studies in which we considered German a</context>
<context position="35733" citStr="Prince 1981" startWordPosition="5523" endWordPosition="5524">fluence on the ranking of the Cf but limit their exposition to the exploitation of grammatical roles only. We diverge from this proposal and claim that, at least for languages with relatively free word order (such as German), the functional information structure of the utterance is crucial for the ranking of discourse entities in the Cf list. Originally, in Strube and Hahn (1996), we defined the Cf ranking criteria in terms of contextboundedness. In this paper, we redefine the functional Cf ranking criteria by making reference to Prince&apos;s work on the assumed familiarity of discourse entities (Prince 1981) and information status (Prince 1992). The term context-bound in Strube and Hahn (1996) corresponds to the term evoked used by Prince!&apos; We briefly list the major claims of our approach to centering. In the following sections, we elaborate on these claims, in particular the ranking of the forward-looking centers. • The elements of the Cf list are ordered according to their information status. Hearer-old discourse entities are ranked higher than hearer-new discourse entities. The order of the elements of the Cf list for U, provides the preference for the interpretation of anaphoric expressions i</context>
</contexts>
<marker>Prince, 1981</marker>
<rawString>Prince, Ellen F. 1981. Towards a taxonomy of given-new information. In P. Cole, editor, Radical Pragmatics. Academic Press, New York, NY, pages 223-255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>The ZPG letter: Subjects, definiteness, and information-status.</title>
<date>1992</date>
<pages>295--325</pages>
<editor>In W. C. Mann and S. A. Thompson, editors, Discourse</editor>
<location>Amsterdam,</location>
<contexts>
<context position="35770" citStr="Prince 1992" startWordPosition="5528" endWordPosition="5529">limit their exposition to the exploitation of grammatical roles only. We diverge from this proposal and claim that, at least for languages with relatively free word order (such as German), the functional information structure of the utterance is crucial for the ranking of discourse entities in the Cf list. Originally, in Strube and Hahn (1996), we defined the Cf ranking criteria in terms of contextboundedness. In this paper, we redefine the functional Cf ranking criteria by making reference to Prince&apos;s work on the assumed familiarity of discourse entities (Prince 1981) and information status (Prince 1992). The term context-bound in Strube and Hahn (1996) corresponds to the term evoked used by Prince!&apos; We briefly list the major claims of our approach to centering. In the following sections, we elaborate on these claims, in particular the ranking of the forward-looking centers. • The elements of the Cf list are ordered according to their information status. Hearer-old discourse entities are ranked higher than hearer-new discourse entities. The order of the elements of the Cf list for U, provides the preference for the interpretation of anaphoric expressions in • The first element of the Cf(L/i),</context>
<context position="40781" citStr="Prince (1992" startWordPosition="6294" endWordPosition="6295"> entities are simply cospecifying (resolved anaphoric) expressions, i.e., pronominal and nominal anaphora, relative pronouns, previously mentioned proper names, etc. Unused discourse entities are proper names and titles. In texts, brand-new proper names are usually accompanied by a relative clause or an appositive that relates them to the hearer&apos;s knowledge. The corresponding discourse entity is evoked only after this elaboration. Whenever these linguistic devices are missing, we treat proper names as unused.&apos; In the following, we give some examples of evoked, unused, and brand-new 11 Quoting Prince (1992, 305): &amp;quot;Inferrables are like Hearer-new (and, therefore, Discourse-new) entities in that the hearer is not expected to already have in his/her head the entity in question.&amp;quot; 12 For examples of brand-new proper names and how they are introduced, see, for example, the beginning of articles in the &amp;quot;obituaries&amp;quot; section of the New York Times. 321 Computational Linguistics Volume 25, Number 3 discourse entities, though in naturally occurring texts these phenomena rarely show up unadulterated.&apos; The remaining categories will be explained subsequently. Example 3 a. He lived his final nine years in one </context>
<context position="46764" citStr="Prince (1992" startWordPosition="7260" endWordPosition="7261">Again, the elements of this set are indistinguishable with respect to their information status—for instance, inferable and anchored brand-new discourse entities have the same information status because they belong to the set of mediated discourse entities. Hence, the extended Cf ranking, depicted in Figure 3, will prefer OLD discourse entities over MEDiated ones, and MEDiated ones will be preferred over NEW ones. We assume that the difference between containing inferables and anchored brandnew discourse entities is negligible. (It was not well defined in Prince [1981] and in 14 Again, quoting Prince (1992, 305-306): &amp;quot;Inferrables are thus like Hearer-old entities in that they rely on certain assumptions about what the hearer does know, e.g. that buildings typically have doors [.. .1, and they are like Discourse-old entities in that they rely on there being already in the discourse-model some entity to trigger the inference [.. .1.&amp;quot; 323 Computational Linguistics Volume 25, Number 3 Figure 3 Information status and familiarity (refined version). Prince [1992] she abandoned the second term.) Therefore, we conflate them into the category of anchored brand-new discourse entities. These discourse enti</context>
</contexts>
<marker>Prince, 1992</marker>
<rawString>Prince, Ellen F. 1992. The ZPG letter: Subjects, definiteness, and information-status. In W. C. Mann and S. A. Thompson, editors, Discourse Description: Diverse Linguistic Analyses of a Fund-Raising Text. John Benjamins, Amsterdam, pages 295-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
</authors>
<title>Pragmatic aspects of scrambling and topicalization in German.</title>
<date>1993</date>
<booktitle>In Workshop on Centering Theory in Naturally-Occurring Discourse. Institute for Research in Cognitive Science</booktitle>
<institution>(IRCS), University of Pennsylvania,</institution>
<location>Philadelphia, PA,</location>
<contexts>
<context position="30687" citStr="Rambow 1993" startWordPosition="4722" endWordPosition="4723">o, Rule 1 would be violated in the rejected reading. 4. Principles of Functional Centering The crucial point underlying functional centering is to relate the ranking of the forwardlooking centers and the information structure of the corresponding utterances. Hence, a proper correspondence relation between the basic centering data structures and the relevant functional notions has to be established and formally rephrased in terms of the centering model. In this section, we first discuss two studies in which the information structure of utterances is already integrated into the centering model (Rambow 1993; Hoffman 1996, 1998). Using these proposals as a point of departure, we shall develop our own proposal—functional centering (Strube and Hahn 1996). 4.1 Integrating Information Structure and Centering As far as the centering model is concerned, the first account involving information structure criteria was given by Kameyama (1986) and further refined by Walker, Iida, and Cote (1994) in their study on the use of zero pronouns and topic mark9 Walker, Iida, and Cote (1994) note that it is possible to improve the computational efficiency of the algorithm by interleaving generating, filtering, and </context>
<context position="32373" citStr="Rambow (1993)" startWordPosition="4995" endWordPosition="4996">e stripped this from him and donned it. RETAIN Cb: SENTRY: him Cf: [MIKE: Mike, TUNIC: this, it, SENTRY: him] He tied and gagged the man, . . . SMOOTH-SHIFT Cb: MIKE: he Cf: [MIKE: he, SENTRY: the man] Cb. MIKE. tJtit ROUGH-SHIFT Cf: [SENTRY. he, MIKE. the &apos;ma] ers in Japanese. This led them to augment the grammatical ranking conditions for the forward-looking centers by additional functional notions. A deeper consideration of information structure principles and their relation to the centering model has been proposed in two studies concerned with the analysis of German and Turkish discourse. Rambow (1993) was the first to apply the centering methodology to German, aiming at the description of information structure aspects underlying scrambling and topicalization. As a side effect, he used centering to define the utterance&apos;s theme and rheme in the sense of the functional sentence perspective (FSP) (Firbas 1974). Viewed from this perspective, the theme/rheme-hierarchy of utterance 11, is determined by the Cf(Ui_i). Elements of Ui that are contained in Cf(Lli_i) are less rhematic than those not contained in Cf(Ui_i). He then concludes that the Cb(U) must be the theme of the current utterance. Ram</context>
</contexts>
<marker>Rambow, 1993</marker>
<rawString>Rambow, Owen. 1993. Pragmatic aspects of scrambling and topicalization in German. In Workshop on Centering Theory in Naturally-Occurring Discourse. Institute for Research in Cognitive Science (IRCS), University of Pennsylvania, Philadelphia, PA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine Rich</author>
<author>Susann LuperFoy</author>
</authors>
<title>An architecture for anaphora resolution.</title>
<date>1988</date>
<booktitle>In Proceedings of the 2nd Conference on Applied Natural Language Processing,</booktitle>
<pages>18--24</pages>
<location>Austin, TX,</location>
<contexts>
<context position="85730" citStr="Rich and LuperFoy 1988" startWordPosition="13462" endWordPosition="13465">l and Brown (1988) who discuss, among others, heuristics involving case role filling, semantic and pragmatic alignment, syntactic parallelism, syntactic topicalization, and intersentential recency. Given such a wealth of criteria one may either try to order them a priori in terms of importance or—as was proposed by the majority of researchers in this field— define several scoring functions that compute flexible orderings on the fly. These combine the variety of available evidence, each one usually annotated by a specific weight factor, and, finally, map the weights to a single salience score (Rich and LuperFoy 1988; HajRova, Kubori, and Kubori 1992; Lappin and Leass 1994) These heuristics helped to improve the performance of discourse-understanding systems through significant reductions of the available search-space for antecedents. Their major drawback is that they require a great deal of skilled hand-crafting that, unfortunately, usually does not scale in broader application domains. Hence, proposals were made to replace these high-level &amp;quot;symbolic&amp;quot; categories by statistically interpreted occurrence patterns derived from large text corpora (Dagan and Itai 1990). Preferences then reflect patterns of sta</context>
<context position="89996" citStr="Rich and LuperFoy 1988" startWordPosition="14060" endWordPosition="14063">ation level, preserves the modularity of criteria, and, in particular, is linguistically justified. Although functional centering is not a complete theory of preferential anaphora resolution, one should clearly stress the different goals behind heuristics-based systems, such as the ones just discussed, and the model of centering. Heuristic approaches combine introspectively acquired descriptive evidence and attempt to optimize reference resolution performance by proper evidence &amp;quot;engineering&amp;quot;. This is often done in an admittedly ad hoc way, requiring tricky retuning when new evidence is added (Rich and LuperFoy 1988). On the other hand, many of these systems work in a real-world environment (Rich and LuperFoy 1988; Lappin and Leass 1994; Kennedy and Boguraev 1996) in which noisy data and incomplete, sometimes even faulty, analysis results have to be accounted for. The centering model differs from these considerations in that it aims at unfolding a unified theory of discourse coherence at the linguistic, attentional, and intentional level (Grosz and Sidner 1986); hence, the search for a more principled, theory-based solution, but also the need for (almost) perfect linguistic analyses in terms of parsing an</context>
</contexts>
<marker>Rich, LuperFoy, 1988</marker>
<rawString>Rich, Elaine and Susann LuperFoy. 1988. An architecture for anaphora resolution. In Proceedings of the 2nd Conference on Applied Natural Language Processing, pages 18-24, Austin, TX, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>Focusing in the comprehension of definite anaphora.</title>
<date>1983</date>
<booktitle>Computational Models of Discourse.</booktitle>
<pages>267--330</pages>
<editor>In M. Brady and R. C. Berwick, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="3473" citStr="Sidner 1983" startWordPosition="496" endWordPosition="497">ce, 3401 Walnut Street, Suite 400A, Philadelphia, PA 19104, USA t Computational Linguistics Group, Text Understanding Lab, Werthmannplatz 1, 79085 Freiburg, Germany C) 1999 Association for Computational Linguistics Computational Linguistics Volume 25, Number 3 terns of language use and, thus, introduces the level of discourse context and further pragmatic factors as a complementary description level. Computational linguists have recognized the need to account for referential ambiguities in discourse and have developed various theories centered around the notion of discourse focus (Grosz 1977; Sidner 1983). In a seminal paper, Grosz and Sidner (1986) wrapped up the results of their research and formulated a model in which three levels of discourse coherence are distinguished—attention, intention, and discourse segment structure. While this paper gives a comprehensive picture of a complex, yet not explicitly spelled-out theory of discourse coherence, the centering model (Grosz, Joshi, and Weinstein, 1983, 1995) marked a major step in clarifying the relationship between attentional states and (local) discourse segment structure. More precisely, the centering model accounts for the interactions be</context>
<context position="82928" citStr="Sidner (1983" startWordPosition="13040" endWordPosition="13041"> preferred over expensive ones. 6. Comparison with Related Approaches 6.1 Focus-based Approaches Approaches to anaphora resolution based on focus devices partly use the information status of discourse entities to determine the current discourse focus. However, a 336 Strube and Hahn Functional Centering common area of criticism of these approaches is the diversity of data structures they require. These data structures are likely to hide the underlying linguistic regularities, because they promote the mix of preference and data structure considerations in the focusing algorithms. As an example, Sidner (1983, 292ff.) distinguishes between an Actor Focus and a Discourse Focus, as well as corresponding lists, viz. Potential Actor Focus List and Potential Discourse Focus List. Sufi and McCoy (1994) in their RAFT/RAPR approach use grammatical roles for ordering the focus lists and make a distinction between Subject Focus, Current Focus, and corresponding lists. Both focusing algorithms prefer an element that represents the Focus to the elements in the list when the anaphoric expression under consideration is not the agent (for Sidner) or the subject (for Suri and McCoy). Relating these approaches to </context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>Sidner, Candace L. 1983. Focusing in the comprehension of definite anaphora. In M. Brady and R. C. Berwick, editors, Computational Models of Discourse. MIT Press, Cambridge, MA, pages 267-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
</authors>
<title>Funktionales Centering.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<location>Albert-Ludwigs-Universitat Freiburg, Freiburg.</location>
<contexts>
<context position="6169" citStr="Strube 1996" startWordPosition="911" endWordPosition="912"> appropriate for different languages. In fact, Walker, Iida, and Cote (1994) hypothesize that the Cf ranking criteria are the only language-dependent factors within the centering model. Though evidence for many additional criteria for the Cf ranking have been brought forward in the literature, to some extent consensus has emerged that grammatical roles play a major role in making ranking decisions (e.g., whether the referential expression appears as the grammatical subject, direct object, or indirect object of an utterance). Our own work on the centering model&apos; (Strube and Hahn 1996; Hahn and Strube 1996) brings in evidence from German, a free-word-order language in which grammatical role information is far less predictive of the organization of centers than for fixed-word-order languages such as English. In establishing proper referential relations, we found the functional information structure of the utterances to be much more relevant. By this we mean indicators of whether or not a discourse entity in the current utterance refers to another discourse entity already introduced by previous utterances in the discourse. Borrowing terminology from Prince (1981, 1992), an entity that does refer t</context>
<context position="10181" citStr="Strube 1996" startWordPosition="1516" endWordPosition="1517">ering literature, e.g., by asserting that the entity in question &amp;quot;is realized but not directly realized&amp;quot; (Grosz, Joshi, and Weinstein 1995, 217). Furthermore, the distinction between these two kinds of realization is not part of the centering mechanisms but delegated to the underlying semantic theory. We will develop arguments for how to discern inferable discourse entities and relate them properly to their antecedent at the center level. The ordering constraints we supply account for all of the types of anaphora mentioned above, including (pro)nominal anaphora (Strube and Hahn 1995; Hahn and Strube 1996). This claim will be validated by a substantial body of empirical data in Section 5. Our third contribution relates to the way the results of centering-based anaphora resolution are usually evaluated. Basically, we argue that rather than counting resolution rates for anaphora or comparing isolated transition types holding among head positions in the center lists—preferred transition types stand for a high degree of local coherence, while less preferred ones signal that the underlying discourse might lack coherence—one should consider adjacent transition pairs and annotate such pairs with the p</context>
<context position="48655" citStr="Strube (1996)" startWordPosition="7568" endWordPosition="7569">sible that they are indefinite, like an uncle in example (7b). Example 7 a. He shared this bounty with his father b. but [a sickly unclell was left to remain hungry. Anchored brand-new (BNA) discourse entities as in example (8) are heads of phrases whose modifiers relate (anchor) them to the context. Example 8 a. He had already lost too many companions. b. [[His] E fiancée]BNA had died in a car wreck. With respect to inferables, there exist only a few computational treatments, all of which are limited in scope. We here restrict inferables to the particular subset defined by Hahn, Markert, and Strube (1996), which we call functional anaphora (FA). In the following, we will limit our discussion of inferables to those which figure as functional anaphors. In Table 10, we define the sets needed for the specification of the extended Cf ranking criteria in Table 11. We distinguish between three different sets of discourse entities; hearer-old discourse entities (OLD), mediated discourse entities (MED), and hearer-new discourse entities (NEW). Note that the antecedent of a functional anaphor (the inferred discourse entity) is included in the set of hearer-old discourse entities. 324 Strube and Hahn Fun</context>
<context position="92001" citStr="Strube 1996" startWordPosition="14368" endWordPosition="14369">ng framework. The extensions we proposed were validated by the empirical analysis of various texts of considerable length selected from different domains and genres. The &amp;quot;evaluation metric&amp;quot; we used refers to a new cost-based model of interpreting the validity of centering data. The distinction between cognitively cheap and expensive transition pairs led us to replace Rule 2 from the original model by a formulation that explicitly incorporates this cost-oriented distinction. A resolution module for (pro)nominal anaphora (Strube and Hahn 1995) and one for functional anaphora (Hahn, Markert, and Strube 1996) based on this functional centering model has been implemented as part of PARSETALK, a comprehensive text parser for German (Hahn, Schacht, and Broker 1994; Hahn, Neuhaus, and Broker 1997) in our group. All these modules are fully operational and integrated within the text-understanding backbone of SYNDIK ATE, a large-scale text knowledge acquisition system for the two real-world domains of information technology (Hahn and Schnattinger 1998) and medicine (Hahn, Romacker, and Schulz 1999). Despite the progress made so far, many research problems remain open for further consideration in the cent</context>
<context position="93475" citStr="Strube (1996" startWordPosition="14589" endWordPosition="14590"> such as relative clauses, subordinate clauses, coordinations, and complex noun phrases. The problem caused by these structures for the centering model is how to decompose a complex sentence into center-updating units and how to process complex utterances consisting of multiple clauses. A first proposal is due to Kameyama (1998) who breaks a complex sentence into a hierarchy of center-updating units. Furthermore, she distinguishes several types of constructions in order to decide which part of the sentence is relevant for the resolution of an intersentential anaphor in the following sentence. Strube (1996b) (with respect to centering) and Suri and McCoy (1994) (with respect to the focus model) describe similar approaches and provide algorithms for the interaction of the resolution of inter- and intrasentential anaphora, but the topic has certainly not been dealt with exhaustively. The problem of complex NPs was pointed out by Walker and Prince (1996). Since the grammatical functions in a sentence may be realized by a complex NP, it is not clear how to rank these phrases in the Cf list. Walker and Prince (1996) propose a &amp;quot;working hypothesis&amp;quot; based on the surface order. Strube (1998) provides a </context>
</contexts>
<marker>Strube, 1996</marker>
<rawString>Strube, Michael. 1996a. Funktionales Centering. Ph.D. thesis, Albert-Ludwigs-Universitat Freiburg, Freiburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
</authors>
<title>Processing complex sentences in the centering framework.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting,</booktitle>
<pages>378--380</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Santa Cruz, CA,</location>
<contexts>
<context position="6169" citStr="Strube 1996" startWordPosition="911" endWordPosition="912"> appropriate for different languages. In fact, Walker, Iida, and Cote (1994) hypothesize that the Cf ranking criteria are the only language-dependent factors within the centering model. Though evidence for many additional criteria for the Cf ranking have been brought forward in the literature, to some extent consensus has emerged that grammatical roles play a major role in making ranking decisions (e.g., whether the referential expression appears as the grammatical subject, direct object, or indirect object of an utterance). Our own work on the centering model&apos; (Strube and Hahn 1996; Hahn and Strube 1996) brings in evidence from German, a free-word-order language in which grammatical role information is far less predictive of the organization of centers than for fixed-word-order languages such as English. In establishing proper referential relations, we found the functional information structure of the utterances to be much more relevant. By this we mean indicators of whether or not a discourse entity in the current utterance refers to another discourse entity already introduced by previous utterances in the discourse. Borrowing terminology from Prince (1981, 1992), an entity that does refer t</context>
<context position="10181" citStr="Strube 1996" startWordPosition="1516" endWordPosition="1517">ering literature, e.g., by asserting that the entity in question &amp;quot;is realized but not directly realized&amp;quot; (Grosz, Joshi, and Weinstein 1995, 217). Furthermore, the distinction between these two kinds of realization is not part of the centering mechanisms but delegated to the underlying semantic theory. We will develop arguments for how to discern inferable discourse entities and relate them properly to their antecedent at the center level. The ordering constraints we supply account for all of the types of anaphora mentioned above, including (pro)nominal anaphora (Strube and Hahn 1995; Hahn and Strube 1996). This claim will be validated by a substantial body of empirical data in Section 5. Our third contribution relates to the way the results of centering-based anaphora resolution are usually evaluated. Basically, we argue that rather than counting resolution rates for anaphora or comparing isolated transition types holding among head positions in the center lists—preferred transition types stand for a high degree of local coherence, while less preferred ones signal that the underlying discourse might lack coherence—one should consider adjacent transition pairs and annotate such pairs with the p</context>
<context position="48655" citStr="Strube (1996)" startWordPosition="7568" endWordPosition="7569">sible that they are indefinite, like an uncle in example (7b). Example 7 a. He shared this bounty with his father b. but [a sickly unclell was left to remain hungry. Anchored brand-new (BNA) discourse entities as in example (8) are heads of phrases whose modifiers relate (anchor) them to the context. Example 8 a. He had already lost too many companions. b. [[His] E fiancée]BNA had died in a car wreck. With respect to inferables, there exist only a few computational treatments, all of which are limited in scope. We here restrict inferables to the particular subset defined by Hahn, Markert, and Strube (1996), which we call functional anaphora (FA). In the following, we will limit our discussion of inferables to those which figure as functional anaphors. In Table 10, we define the sets needed for the specification of the extended Cf ranking criteria in Table 11. We distinguish between three different sets of discourse entities; hearer-old discourse entities (OLD), mediated discourse entities (MED), and hearer-new discourse entities (NEW). Note that the antecedent of a functional anaphor (the inferred discourse entity) is included in the set of hearer-old discourse entities. 324 Strube and Hahn Fun</context>
<context position="92001" citStr="Strube 1996" startWordPosition="14368" endWordPosition="14369">ng framework. The extensions we proposed were validated by the empirical analysis of various texts of considerable length selected from different domains and genres. The &amp;quot;evaluation metric&amp;quot; we used refers to a new cost-based model of interpreting the validity of centering data. The distinction between cognitively cheap and expensive transition pairs led us to replace Rule 2 from the original model by a formulation that explicitly incorporates this cost-oriented distinction. A resolution module for (pro)nominal anaphora (Strube and Hahn 1995) and one for functional anaphora (Hahn, Markert, and Strube 1996) based on this functional centering model has been implemented as part of PARSETALK, a comprehensive text parser for German (Hahn, Schacht, and Broker 1994; Hahn, Neuhaus, and Broker 1997) in our group. All these modules are fully operational and integrated within the text-understanding backbone of SYNDIK ATE, a large-scale text knowledge acquisition system for the two real-world domains of information technology (Hahn and Schnattinger 1998) and medicine (Hahn, Romacker, and Schulz 1999). Despite the progress made so far, many research problems remain open for further consideration in the cent</context>
<context position="93475" citStr="Strube (1996" startWordPosition="14589" endWordPosition="14590"> such as relative clauses, subordinate clauses, coordinations, and complex noun phrases. The problem caused by these structures for the centering model is how to decompose a complex sentence into center-updating units and how to process complex utterances consisting of multiple clauses. A first proposal is due to Kameyama (1998) who breaks a complex sentence into a hierarchy of center-updating units. Furthermore, she distinguishes several types of constructions in order to decide which part of the sentence is relevant for the resolution of an intersentential anaphor in the following sentence. Strube (1996b) (with respect to centering) and Suri and McCoy (1994) (with respect to the focus model) describe similar approaches and provide algorithms for the interaction of the resolution of inter- and intrasentential anaphora, but the topic has certainly not been dealt with exhaustively. The problem of complex NPs was pointed out by Walker and Prince (1996). Since the grammatical functions in a sentence may be realized by a complex NP, it is not clear how to rank these phrases in the Cf list. Walker and Prince (1996) propose a &amp;quot;working hypothesis&amp;quot; based on the surface order. Strube (1998) provides a </context>
</contexts>
<marker>Strube, 1996</marker>
<rawString>Strube, Michael. 1996b. Processing complex sentences in the centering framework. In Proceedings of the 34th Annual Meeting, pages 378-380, Santa Cruz, CA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
</authors>
<title>Never look back: An alternative to centering.</title>
<date>1998</date>
<booktitle>In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>1--251</pages>
<location>Montreal, Quebec, Canada,</location>
<contexts>
<context position="66585" citStr="Strube (1998)" startWordPosition="10486" endWordPosition="10487"> in the fact that nominal anaphors are far more constrained by conceptual criteria than pronominal ones. Thus, the chance of properly resolving a nominal anaphor, even when ranked at a lower position in the center lists, is greater than for pronominal anaphors. By shifting our evaluation criteria away from resolution success data to structural conditions reflecting the proper ordering of center lists (in particular, we focus on the most highly ranked item of the forward-looking centers), these criteria are intended to compensate for the a significant improvement in the results, is proposed in Strube (1998). 21 Muller, Heiner. 1974. Geschichten aus der Prod uktion 2. Rotbuch Verlag, Berlin. (&amp;quot;Liebesgeschichte,&amp;quot; pages 57-62.) 330 Strube and Hahn Functional Centering Table 18 Quantitative distribution of centering transitions. Transition Types Naive Naive &amp; Grammatical Grammatical &amp; FunC FA&apos;&apos; &gt; FA FAan&amp;quot; &gt; FA IT CONTINUE 49 167 102 197 309 RETAIN 269 158 226 131 25 SMOOTH-SHIFT 32 41 24 35 51 ROUGH-SHIFT 39 23 37 26 4 Spiegel CONTINUE 17 28 37 43 50 RETAIN 42 32 28 23 12 SMOOTH-SHIFT 9 9 7 8 13 ROUGH-SHIFT 7 6 3 1 0 Muller CONTINUE 31 31 32 32 36 RETAIN 19 19 18 18 15 SMOOTH-SHIFT 15 17 15 16 18 RO</context>
<context position="94063" citStr="Strube (1998)" startWordPosition="14686" endWordPosition="14687">ng sentence. Strube (1996b) (with respect to centering) and Suri and McCoy (1994) (with respect to the focus model) describe similar approaches and provide algorithms for the interaction of the resolution of inter- and intrasentential anaphora, but the topic has certainly not been dealt with exhaustively. The problem of complex NPs was pointed out by Walker and Prince (1996). Since the grammatical functions in a sentence may be realized by a complex NP, it is not clear how to rank these phrases in the Cf list. Walker and Prince (1996) propose a &amp;quot;working hypothesis&amp;quot; based on the surface order. Strube (1998) provides a complete specification for dealing with complex sentences, but this approach departs significantly from the centering model. 2. It seems that there exist only a few fully operational implementations of centering-based algorithms, since the interaction of the algorithm with global and local ambiguities generated by a sentence parser has not received much attention until now. A first proposal for how to deal with center ambiguity in an incremental text parser has been made by Hahn and Strube (1996). 339 Computational Linguistics Volume 25, Number 3 3. The centering model covers the s</context>
</contexts>
<marker>Strube, 1998</marker>
<rawString>Strube, Michael. 1998. Never look back: An alternative to centering. In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and the 17th International Conference on Computational Linguistics, Montreal, Quebec, Canada, volume 2, pages 1,251-1,257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Udo Hahn</author>
</authors>
<title>PARSETALK about sentence- and text-level anaphora.</title>
<date>1995</date>
<booktitle>In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>237--244</pages>
<location>Dublin, Ireland,</location>
<contexts>
<context position="10158" citStr="Strube and Hahn 1995" startWordPosition="1510" endWordPosition="1513">ketchily dealt with in the centering literature, e.g., by asserting that the entity in question &amp;quot;is realized but not directly realized&amp;quot; (Grosz, Joshi, and Weinstein 1995, 217). Furthermore, the distinction between these two kinds of realization is not part of the centering mechanisms but delegated to the underlying semantic theory. We will develop arguments for how to discern inferable discourse entities and relate them properly to their antecedent at the center level. The ordering constraints we supply account for all of the types of anaphora mentioned above, including (pro)nominal anaphora (Strube and Hahn 1995; Hahn and Strube 1996). This claim will be validated by a substantial body of empirical data in Section 5. Our third contribution relates to the way the results of centering-based anaphora resolution are usually evaluated. Basically, we argue that rather than counting resolution rates for anaphora or comparing isolated transition types holding among head positions in the center lists—preferred transition types stand for a high degree of local coherence, while less preferred ones signal that the underlying discourse might lack coherence—one should consider adjacent transition pairs and annotat</context>
<context position="15032" citStr="Strube and Hahn (1995)" startWordPosition="2232" endWordPosition="2235"> relation. Finally, no grammatical constraints apply to inferables, while conceptual constraints typically require a nongeneralization relation (e.g., part-whole) to hold between the inferable and its antecedent. Of course, contextual conceptual constraints are introduced for both nominal and pronominal anaphora by sortal requirements set up, e.g., by the case roles of the main verb. 2 We have also considered the role of anaphora within sentences. The d-binding criterion we have developed for resolving intrasentential anaphora is based on dependency grammar notions described in more detail in Strube and Hahn (1995). 3 Note that Reserve-Batteriepack in Example (la) and Akkus in (lb) denote conceptually different discourse entities that cannot be coindexed. 4 See Jaeggli (1986) for special cases where this criterion is overruled. 312 Strube and Hahn Functional Centering Let us illustrate these different types of phenomena by considering the following text fragment: Example 1 a. Ein Reserve-Batteriepack versorgt den 316LT ca. 2 Minuten mit Strom. [A reserve battery pack]io. — supplies — the [3/6LT],,, — for approximately 2 minutes — with power. The 316LT is supplied with power by a reserve battery pack for</context>
<context position="91936" citStr="Strube and Hahn 1995" startWordPosition="14356" endWordPosition="14359">n issue that, up to now, has only been sketchily dealt with in the centering framework. The extensions we proposed were validated by the empirical analysis of various texts of considerable length selected from different domains and genres. The &amp;quot;evaluation metric&amp;quot; we used refers to a new cost-based model of interpreting the validity of centering data. The distinction between cognitively cheap and expensive transition pairs led us to replace Rule 2 from the original model by a formulation that explicitly incorporates this cost-oriented distinction. A resolution module for (pro)nominal anaphora (Strube and Hahn 1995) and one for functional anaphora (Hahn, Markert, and Strube 1996) based on this functional centering model has been implemented as part of PARSETALK, a comprehensive text parser for German (Hahn, Schacht, and Broker 1994; Hahn, Neuhaus, and Broker 1997) in our group. All these modules are fully operational and integrated within the text-understanding backbone of SYNDIK ATE, a large-scale text knowledge acquisition system for the two real-world domains of information technology (Hahn and Schnattinger 1998) and medicine (Hahn, Romacker, and Schulz 1999). Despite the progress made so far, many re</context>
</contexts>
<marker>Strube, Hahn, 1995</marker>
<rawString>Strube, Michael and Udo Hahn. 1995. PARSETALK about sentence- and text-level anaphora. In Proceedings of the 7th Conference of the European Chapter of the Association for Computational Linguistics, pages 237-244, Dublin, Ireland, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Udo Hahn</author>
</authors>
<title>Functional centering.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting,</booktitle>
<pages>270--277</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Santa Cruz, CA,</location>
<contexts>
<context position="6146" citStr="Strube and Hahn 1996" startWordPosition="905" endWordPosition="908">hers about the ranking criteria appropriate for different languages. In fact, Walker, Iida, and Cote (1994) hypothesize that the Cf ranking criteria are the only language-dependent factors within the centering model. Though evidence for many additional criteria for the Cf ranking have been brought forward in the literature, to some extent consensus has emerged that grammatical roles play a major role in making ranking decisions (e.g., whether the referential expression appears as the grammatical subject, direct object, or indirect object of an utterance). Our own work on the centering model&apos; (Strube and Hahn 1996; Hahn and Strube 1996) brings in evidence from German, a free-word-order language in which grammatical role information is far less predictive of the organization of centers than for fixed-word-order languages such as English. In establishing proper referential relations, we found the functional information structure of the utterances to be much more relevant. By this we mean indicators of whether or not a discourse entity in the current utterance refers to another discourse entity already introduced by previous utterances in the discourse. Borrowing terminology from Prince (1981, 1992), an e</context>
<context position="30834" citStr="Strube and Hahn 1996" startWordPosition="4743" endWordPosition="4746">ing is to relate the ranking of the forwardlooking centers and the information structure of the corresponding utterances. Hence, a proper correspondence relation between the basic centering data structures and the relevant functional notions has to be established and formally rephrased in terms of the centering model. In this section, we first discuss two studies in which the information structure of utterances is already integrated into the centering model (Rambow 1993; Hoffman 1996, 1998). Using these proposals as a point of departure, we shall develop our own proposal—functional centering (Strube and Hahn 1996). 4.1 Integrating Information Structure and Centering As far as the centering model is concerned, the first account involving information structure criteria was given by Kameyama (1986) and further refined by Walker, Iida, and Cote (1994) in their study on the use of zero pronouns and topic mark9 Walker, Iida, and Cote (1994) note that it is possible to improve the computational efficiency of the algorithm by interleaving generating, filtering, and ranking steps; cf. the version of the algorithm described by Walker (1998). 318 Strube and Hahn Functional Centering Table 7 Centering analysis for</context>
<context position="35503" citStr="Strube and Hahn (1996)" startWordPosition="5485" endWordPosition="5488"> suggest in our model, one that mirrors the influence of information structure in the way the forward-looking centers are actually ranked. 4.2 Functional Centering Grosz, Joshi, and Weinstein (1995) admit that several factors may have an influence on the ranking of the Cf but limit their exposition to the exploitation of grammatical roles only. We diverge from this proposal and claim that, at least for languages with relatively free word order (such as German), the functional information structure of the utterance is crucial for the ranking of discourse entities in the Cf list. Originally, in Strube and Hahn (1996), we defined the Cf ranking criteria in terms of contextboundedness. In this paper, we redefine the functional Cf ranking criteria by making reference to Prince&apos;s work on the assumed familiarity of discourse entities (Prince 1981) and information status (Prince 1992). The term context-bound in Strube and Hahn (1996) corresponds to the term evoked used by Prince!&apos; We briefly list the major claims of our approach to centering. In the following sections, we elaborate on these claims, in particular the ranking of the forward-looking centers. • The elements of the Cf list are ordered according to t</context>
<context position="37492" citStr="Strube and Hahn (1996)" startWordPosition="5798" endWordPosition="5801">n, we introduce the functional Cf ranking criteria. We first describe a basic version, which is valid for a wide range of text genres in which pronominal reference is the predominant text phenomenon. This is the type of discourse to which centering was mainly applied in previous approaches (see, for example, Walker&apos;s [1989] or Di Eugenio&apos;s [1998] test sets). We then describe the extended version of the functional Cf ranking constraints. The two versions differ with respect to the incorporation of (a subset of) inferables in the second version and, hence, with respect to the requirements 10 In Strube and Hahn (1996), we assumed that the information status of a discourse entity has the main impact on its salience. In particular, evoked discourse entities were ranked higher in the Cf list than brand-new discourse entities (using Prince&apos;s terminology). We also restricted the category of the most salient discourse entities to evoked (i.e., context-bound) discourse entities. In this article, we extend this category to hearer-old discourse entities, which includes, besides evoked discourse entities, unused ones (again, referring to Prince&apos;s terminology). 320 Strube and Hahn Functional Centering Figure 2 Inform</context>
</contexts>
<marker>Strube, Hahn, 1996</marker>
<rawString>Strube, Michael and Udo Hahn. 1996. Functional centering. In Proceedings of the 34th Annual Meeting, pages 270-277, Santa Cruz, CA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda Z Suri</author>
<author>Kathleen F McCoy</author>
</authors>
<title>RAFT/RAPR and centering: A comparison and discussion of problems related to processing complex sentences.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--2</pages>
<contexts>
<context position="93531" citStr="Suri and McCoy (1994)" startWordPosition="14596" endWordPosition="14599"> coordinations, and complex noun phrases. The problem caused by these structures for the centering model is how to decompose a complex sentence into center-updating units and how to process complex utterances consisting of multiple clauses. A first proposal is due to Kameyama (1998) who breaks a complex sentence into a hierarchy of center-updating units. Furthermore, she distinguishes several types of constructions in order to decide which part of the sentence is relevant for the resolution of an intersentential anaphor in the following sentence. Strube (1996b) (with respect to centering) and Suri and McCoy (1994) (with respect to the focus model) describe similar approaches and provide algorithms for the interaction of the resolution of inter- and intrasentential anaphora, but the topic has certainly not been dealt with exhaustively. The problem of complex NPs was pointed out by Walker and Prince (1996). Since the grammatical functions in a sentence may be realized by a complex NP, it is not clear how to rank these phrases in the Cf list. Walker and Prince (1996) propose a &amp;quot;working hypothesis&amp;quot; based on the surface order. Strube (1998) provides a complete specification for dealing with complex sentence</context>
</contexts>
<marker>Suri, McCoy, 1994</marker>
<rawString>Suri, Linda Z. and Kathleen F. McCoy. 1994. RAFT/RAPR and centering: A comparison and discussion of problems related to processing complex sentences. Computational Linguistics, 20(2):301-317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omit Deniz Turan</author>
</authors>
<title>Ranking forward-looking centers in Turkish: Universal and language specific properties.</title>
<date>1998</date>
<booktitle>Centering in Discourse.</booktitle>
<pages>138--160</pages>
<editor>In M. A. Walker, A. K. Joshi, and E. F. Prince, editors,</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford, England,</location>
<marker>Turan, 1998</marker>
<rawString>Turan, Omit Deniz. 1998. Ranking forward-looking centers in Turkish: Universal and language specific properties. In M. A. Walker, A. K. Joshi, and E. F. Prince, editors, Centering in Discourse. Oxford University Press, Oxford, England, pages 138-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enric Vallduvf</author>
</authors>
<title>The Informational Component.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Linguistics, University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<marker>Vallduvf, 1990</marker>
<rawString>Vallduvf, Enric. 1990. The Informational Component. Ph.D. thesis, Department of Linguistics, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enric Vallduvf</author>
<author>Elisabet Engdahl</author>
</authors>
<title>The linguistic realization of information packaging.</title>
<date>1996</date>
<journal>Linguistics,</journal>
<pages>34--459</pages>
<marker>Vallduvf, Engdahl, 1996</marker>
<rawString>Vallduvf, Enric and Elisabet Engdahl. 1996. The linguistic realization of information packaging. Linguistics, 34:459-519.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Evaluating discourse processing algorithms.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Meeting,</booktitle>
<pages>251--261</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, B.C., Canada,</location>
<contexts>
<context position="55838" citStr="Walker 1989" startWordPosition="8764" endWordPosition="8765">st set for success rate evaluation. Hemingway NYT English Writers FAZ German 3rd pers. &amp; poss. pron. 274 302 576 299 320 619 sentences 153 233 386 186 394 580 words 2785 4546 7331 3195 8005 11200 5.1.2 Method. The evaluation was carried out manually by the authors, supported by a small-scale discourse annotation tool. We used the following guidelines for our evaluation: We did not assume any world knowledge as part of the anaphora resolution process. Only agreement criteria and sortal constraints were applied. We did not account for false positives and error chains, but marked the latter (see Walker 1989). We use Kameyama&apos;s (1998) specifications for dealing with complex sentences (for a description, see Section 3). Following Walker (1989), a discourse segment is defined as a paragraph unless its first sentence has a pronoun in subject position or a pronoun whose syntactic features do not match the syntactic features of any of the preceding sentence-internal noun phrases. Also, at the beginning of a segment, anaphora resolution is preferentially performed within the same utterance. According to the preference for intersentential candidates in the original centering model, we defined the followi</context>
</contexts>
<marker>Walker, 1989</marker>
<rawString>Walker, Marilyn A. 1989. Evaluating discourse processing algorithms. In Proceedings of the 27th Annual Meeting, pages 251-261, Vancouver, B.C., Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
</authors>
<title>Centering anaphora resolution, and discourse structure.</title>
<date>1998</date>
<booktitle>Centering Theory in Discourse.</booktitle>
<pages>401--435</pages>
<editor>In M. A. Walker, A. K. Joshi, and E. F. Prince, editors,</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford, England,</location>
<contexts>
<context position="31361" citStr="Walker (1998)" startWordPosition="4828" endWordPosition="4829">parture, we shall develop our own proposal—functional centering (Strube and Hahn 1996). 4.1 Integrating Information Structure and Centering As far as the centering model is concerned, the first account involving information structure criteria was given by Kameyama (1986) and further refined by Walker, Iida, and Cote (1994) in their study on the use of zero pronouns and topic mark9 Walker, Iida, and Cote (1994) note that it is possible to improve the computational efficiency of the algorithm by interleaving generating, filtering, and ranking steps; cf. the version of the algorithm described by Walker (1998). 318 Strube and Hahn Functional Centering Table 7 Centering analysis for the text fragment in example (2) according to the BFP algorithm. The sentry was not dead. — Cb:— Cf: [SENTRY: sentry] He was, in fact, showing signs of reviving ... CONTINUE Cb: SENTRY: he Cf: [SENTRY: he, SIGNS: signs] He was partially uniformed in a cavalry tunic. CONTINUE Cb: SENTRY: he Cf: [SENTRY: he, TUNIC: tunic] Mike stripped this from him and donned it. RETAIN Cb: SENTRY: him Cf: [MIKE: Mike, TUNIC: this, it, SENTRY: him] He tied and gagged the man, . . . SMOOTH-SHIFT Cb: MIKE: he Cf: [MIKE: he, SENTRY: the man]</context>
<context position="97575" citStr="Walker (1998)" startWordPosition="15227" endWordPosition="15228">onsideration of immediately adjacent centering structures for establishing proper referential links. In order to extend that theory to the level of global coherence, various steps have to be taken. • At the referential level, mechanisms have to be introduced to account for reference relationships that extend beyond the immediately preceding utterance. Empirical evidence for such phenomena exists in the literature and we also found the need to have such a mechanism available for longer texts. The extension of functional centering to these phenomena is presented in Hahn and Strube (1997), while Walker (1998) builds upon the centering algorithm described in Brennan, Friedman, and Pollard (1987). • At the level of discourse pragmatics, a richer notion than mere reference between terms is needed to account for coherence relations such as those aimed at by Rhetorical Structure Theory 340 Strube and Hahn Functional Centering (Mann and Thompson 1988). In addition, an explicit relation to basic notions from speech act theory is also missing, though it should be considered vital for the global coherence of discourse (Grosz and Sidner 1986). In general, it might become increasingly necessary to integrate </context>
</contexts>
<marker>Walker, 1998</marker>
<rawString>Walker, Marilyn A. 1998. Centering anaphora resolution, and discourse structure. In M. A. Walker, A. K. Joshi, and E. F. Prince, editors, Centering Theory in Discourse. Oxford University Press, Oxford, England, pages 401-435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Masayo Iida</author>
<author>Sharon Cote</author>
</authors>
<title>Japanese discourse and the process of centering.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--2</pages>
<marker>Walker, Iida, Cote, 1994</marker>
<rawString>Walker, Marilyn A., Masayo Iida, and Sharon Cote. 1994. Japanese discourse and the process of centering. Computational Linguistics, 20(2):193-233.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marilyn A Walker</author>
<author>Ellen F Prince</author>
</authors>
<title>A bilateral approach to givenness: A hearer-status algorithm and a centering algorithm.</title>
<pages>291--306</pages>
<editor>In T. Fretheim and J. K. Gundel, editors,</editor>
<location>Amsterdam,</location>
<marker>Walker, Prince, </marker>
<rawString>Walker, Marilyn A. and Ellen F. Prince. A bilateral approach to givenness: A hearer-status algorithm and a centering algorithm. In T. Fretheim and J. K. Gundel, editors, Reference and Referent Accessibility. John Benjamins, Amsterdam, pages 291-306.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>