<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.85492825">
Dialog Control in a Natural Language Systeml
Michael Gerlach Helmut Horacek
Universitat Hamburg Fachbereich Informatik Projektgruppe WISBER
JungiusstraBe 6 D-2000 Hamburg 36 F.R.G.
</title>
<sectionHeader confidence="0.907331" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.998222066666667">
In this paper a method for controlling
the dialog in a natural language (NL)
system is presented. It provides a deep
modeling of information processing
based on time dependent propositional
attitudes of the interacting agents.
Knowledge about the state of the dialog
is represented in a dedicated language
and changes of this state are described
by a compact set of rules. An appropri-
ate organization of rule application is
introduced including the initiation of
an adequate system reaction. Finally
the application of the method in an NL
consultation system is outlined.
</bodyText>
<sectionHeader confidence="0.997668" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.999775210526316">
The solution of complex problems fre-
quently requires cooperation of multi-
ple agents. A great deal of interaction is
needed to identify suitable tasks whose
completion contributes to attaining a
common goal and to organize those
tasks appropriately. In particular, this
involves carrying out communicative
subtasks including the transfer of
knowledge, the adjustment of beliefs,
expressing wants and pursuing their
satisfaction, all of which is motivated
by the intentions of the interacting
agents [Werner 881. An ambitious dia-
log system (be it an interface, a mani-
pulation system, or a consultation sys-
tem) which is intended to exhibit (some
of) these capabilities should therefore
consider these intentions in processing
</bodyText>
<footnote confidence="0.503873166666667">
1 The work described in this paper is part
of the joint project WISBER, which is sup-
ported by the German Federal Ministery for
Research and Technology under grant ITW-
8502. The partners in the project are: Nixdorf
Computer AG, SCS Orbit GmbH, Siemens
</footnote>
<affiliation confidence="0.5852505">
AG, the University of Hamburg, and the Uni-
versity of Saarbriicken.
</affiliation>
<bodyText confidence="0.992576633333334">
the dialog, at least to the extent that is
required for the particular type of the
dialog and the domain of application.
A considerable amount of work in cur-
rent M research is concerned with in-
ferring intentions from utterances (e.g.,
[Allen 83], [Carberry 83], [Grosz, Sidner
86]) or planning speech acts serving
certain goals (e.g., [Appelt 851), but only
a few uniform approaches to both as-
pects have been presented.
Most approaches to dialog control de-
scribed in the literature offer either
rigid action schemata that enable the
simulation of the desired behavior on
the surface (but lack the necessary de-
gree of flexibility, e. g., [Metzing 79]), or
descriptive methods which may also in-
clude possible alternatives for the con-
tinuation of the dialog, but without ex-
pressing criteria to guide an adequate
choice among them (e. g., [Maing et al.
87], [Bergmann, Gerlach 87]).
Modeling of beliefs and intentions (i.e.,
of propositional attitudes) of the agents
involved is found only in the ARGOT
system [Litman, Allen 84]. This ap-
proach behaves sufficiently well in se-
veral isolated situations, but it fails to
demonstrate a continuously adequate
behavior in the course of a complete dia-
log. An elaborated theoretical frame-
work is provided in [Cohen, Perrault
79] but they explicitly exclude the dele-
tion of propositional attitudes. Hence,
they cannot explain what happens
when a want has been satisfied.
In our approach we have enhanced the
propositional attitudes by associating
them with time intervals expressing
their time of validity. This enables us to
represent the knowledge about the ac-
tual state of the dialog (and also about
past states) seen from the point of view
of a certain agent and to express
changes in the propositional attitudes
- 27 -
occurring in the course of the dialog
and to calculate their effect. This deep
modeling is the essential resource for
controling the progress of the conversa-
tion in approaching its overall goal,
and, in particular, for determining the
next subgoal in the conversation which
manifests itself in a system utterance.
We have applied our method in the NL
consultation system WISBER ([Hora-
cek et al. 88], [Sprenger, Gerlach 88])
which is able to participate in a dialog
in the domain of financial investment.
</bodyText>
<sectionHeader confidence="0.9853885" genericHeader="method">
REPRESENTING
PROPOSITIONAL ATTITUDES
</sectionHeader>
<bodyText confidence="0.9945871">
Knowledge about the state of the dialog
is represented as a set of propositional
attitudes. The following three types of
propositional attitudes of an agent
towards a proposition p form a basic
repertoire:
KNOW: The agent is sure that p is true.
This does not imply that p is really true
since the system has no means to find
out the real state of the world. As-
suming that the user of a dialog system
obeys the sincerity condition (i.e., al-
ways telling the truth, c.f. [Grice 75])
an assertion uttered by the user implies
that the user knows the content of that
assertion.
BELIEVE: The agent believes, but is not
sure, that p is true, or he/she assumes p
without sufficient evidence.
WANT: The agent wants p to be true.
Propositional attitudes are represented
in our semantic representation lan-
guage IRS, which is used by all system
components involved in semantic-prag-
matic processing. IRS is based on predi-
cate calculus, and contains a rich collec-
tion of additional features required by
NL processing (see [Bergmann et al. 87]
for detailed information). A propositio-
nal attitude is written as
</bodyText>
<listItem confidence="0.85238125">
( &lt;type &gt; &lt;agent&gt; &lt;prop &gt; &lt;time &gt; ) :
• &lt;type &gt; is an element of the set:
KNOW, BELIEVE, and WANT.
• The two agents relevant in a dialog
</listItem>
<bodyText confidence="0.959161636363636">
system are the USER and the SYSTEM.
In addition, we use the notion
&apos;mutual knowledge&apos;. Informally,
this means that both the user and
the system know that &lt;prop &gt; is
true, and that each knows that the
other knows, recursively. We will
use the notation (KNOW MUTUAL
&lt;prop &gt; ...) to express that the pro-
position &lt;prop &gt; is mutually known
by the user and the system.
</bodyText>
<listItem confidence="0.920775933333333">
• &lt;prop &gt; is an IRS formula denoting
the proposition the attitude is about.
It may again be a propositional atti-
tude, as in (WANT USER (KNOW USER x
...) ...) which means that the user
wants to know x. The proposition
may also contain the meta-predi-
cates RELATED and AUGMENT: (RELATED
x) means &apos;something which is related
to the individual x&apos;, i.e., it must be
possible to establish a chain of links
connecting the individual and the
proposition. In this general form
RELATED is only used to determine
assumptions about the user&apos;s compe-
</listItem>
<bodyText confidence="0.915889230769231">
tence. For a more intensive applica-
tion, however, further conditions
must be put on the connecting links.
(AUGMENT f) means &apos;something more
specific than the formula f&apos;, i.e., at
least one of the variables must be
quantified or categorized more
precisely or additional propositions
must be associated. These meta-pre-
dicates are used by the dialog con-
trol rules as a very compact way of
expressing general properties of pro-
positions.
</bodyText>
<listItem confidence="0.668692">
• Propositional attitudes as any other
</listItem>
<bodyText confidence="0.780051">
states hold during a period of time.
In WISBER we use Allen&apos;s time
logic [Allen 84] to represent such
temporal information [Poesio 88].
&lt;time &gt; must be an individual of
type TIME-INTERVAL. In this paper,
however, for the sake of brevity we
will use almost exclusively the spe-
cial constants NOW, PAST and FUTURE,
denoting time intervals which are
asserted to be during, before or after
the current time.
</bodyText>
<sectionHeader confidence="0.976098" genericHeader="method">
INFERENCE RULES
</sectionHeader>
<bodyText confidence="0.982392038461539">
As new information is provided by the
user and inferences are made by the
system, the set of propositional atti-
tudes to be represented in the system
will evolve. While the semantic-prag-
matic analysis of user utterances ex-
ploits linguistic features to derive the
- 28 -
attitudes expressed by the utterances
(c.f. [Gerlach, Sprenger 88]), the dialog
control component interprets rules
which embody knowledge about know-
ing and wanting as well as about the
domain of discourse. These rules de-
scribe communicative as well as ion-
communicative actions, and specify
how new propositional attitudes can be
derived. Rules about the domain of dis-
course express state changes including
the involved action. The related states
and the triggering action are associated
with time-intervals so that the correct
temporal sequence can be derived.
Both classes of rules are represented in
a uniform formalism based on the sche-
ma precondition - action - effect:
</bodyText>
<listItem confidence="0.993179545454545">
• The precondition consists of patterns
of propositional attitudes or states
in the domain of discourse. The pat-
terns may contain temporal restric-
tions as well as the meta-predicates
mentioned above. A precondition
may also contain a rule description,
e.g., to express that an agent knows
a rule.
• The action may be either on the lev-
el of communication (in the case of
</listItem>
<bodyText confidence="0.979188714285714">
speech act triggering rules) or on the
level of the domain (actions the dia-
log is about). However, there are al-
so pure inference rules in the dialog
control module; their action part is
void.
• The effect of a rule is a set of descrip-
tions of states of the world and pro-
positional attitudes which are in-
stantiated when applying the rule
yielding new entries in the system&apos;s
knowledge base. We do not delete
propositional attitudes or other pro-
positions, i.e., the system will not
forget them, but we can mark the
time interval associated with an en-
try as being &apos;finished&apos;. Thus we can
express that the entry is no longer
valid, and it will no longer match a
pattern with the time of validity
restricted to NOW.
</bodyText>
<sectionHeader confidence="0.966372" genericHeader="method">
CONTROL STRUCTURE
</sectionHeader>
<bodyText confidence="0.9642058">
So far, we have only discussed how the
actual state of the dialog (from the
point of view of a certain agent) can be
represented and how changes in this
state can be described. We still need a
method to determine and carry out the
relevant changes, given a certain state
of the dialog, after interpreting a user
utterance (i.e., to decide which dialog
rules may be tried and in which order).
For reasons of simplicity we have divid-
ed the set of rules into three subsets
each of them being responsible for ac-
complishing a specific subtask, namely:
• gaining additional information in-
ferable from the interrelation bet-
ween recent information coming
from the last user utterance and the
actual dialog context. The combina-
tion of new and old information may,
e. g., change the degree of certainty
of some proposition, i. e., terminate
an (uncertain) BELIEVE state and cre-
ate a (certain) KNOW state with iden-
tical propositional content (the con-
sistency maintenance rule package).
• pursuing a global (cognitive or ma-
nipulative) goal; this may be done
either by trying to satisfy this goal
directly, or indirectly by substitut-
ing a more adequate goal for it and
pursuing this new goal. In particu-
lar, a goal substitution is urgently
needed in case the original goal is
unsatisfiable (for the system), but a
promising alternative is available
(the goal pursuit rule package).
• pursuing a communicative subgoal.
If a goal can not (yet) be accom-
plished due to lack of information,
this leads to the creation of a WANT
concerning knowledge about the
missing information. When a goal
has been accomplished or a signi-
ficant difference in the beliefs of the
user and the system has been disco-
vered, the system WANTS the user to
be informed about that. All this is
done in the phase concerned with
cognitive goals. Once such a WANT is
created, it can be associated with an
appropriate speech act, provided the
competent dialog partner (be it the
user or an external expert) is deter-
mined (the speech act triggering
rule package).
There is a certain linear dependency
between these subtasks. Therefore the
respective rule packages are applied in
a suitable (sequential) order, whereas
those rules belonging to the same pack-
- 29 -
age may be applied in any order (there
exist no interrelations within a single
rule package). This simple forward in-
ferencing works correctly and with an
acceptable performance for the actual
coverage and degree of complexity of
the system.
A sequence consisting of these three
subtasks forms a (cognitive) processing
cycle of the system from receiving a
user message to initiating an adequate
reply. This procedure is repeated until
there is evidence that the goal of the
conversation has been accomplished (as
indicated by knowledge and assump-
tions about the user&apos;s WANTS) or that
the user wants to finish the dialog. In
either case the system closes the dialog.
</bodyText>
<sectionHeader confidence="0.9999495" genericHeader="method">
APPLICATION IN A
CONSULTATION SYSTEM
</sectionHeader>
<bodyText confidence="0.997659307692308">
In this section we present the applica-
tion of our method in the NL consul-
tation system WISBER involving rath-
er complex interaction with subdialogs,
requests for explanation, recommenda-
tions, and adjustment of proposals.
However, it is possible to introduce
some simplifications typical for consul-
tation dialogs. These are urgently need-
ed in order to reduce the otherwise ex-
cessive amount of complexity. In parti-
cular, we assume that the user does not
lie and take his/her assertions about
real world events as true (the sincerity
condition). Moreover, we take it for
granted that the user is highly interest-
ed in a consultation dialog and, there-
fore, will pay attention to the conversa-
tion on the screen so that it can be rea-
sonably assumed that he/she is fully
aware of all utterances occurring in the
course of the dialog.
Based on these (implicit) expectations,
the following (simplified) assumptions
(1) and (2) represent the starting point
for a consultation dialog:
</bodyText>
<sectionHeader confidence="0.9669411" genericHeader="method">
(1) (BELIEVE SYSTEM
(WANT USER
((EXIST X (STATE X))
(HAS-EXPERIENCER X USER))
NOW) NOW)
(2) (BELIEVE SYSTEM
(KNOW USER
(RELATED ((EXIST Y (STATE Y))
(HAS-EXPERIENCER Y USER)))
NOW) NOW)
</sectionHeader>
<bodyText confidence="0.999702553571429">
They express that the user knows some-
thing that &apos;has to do&apos; (expressed by the
meta-predicate RELATED) with states
(STATE v) concerning him/herself and
that he/she wants to achieve a state
(STATE X). In assumption 1, (STATE X) is in
fact specialized for a consultation sys-
tem as a real world state (instead of a
mental state which is the general as-
sumption in any dialog system). This
state can still be made more concrete
when the domain of application is taken
into account:
In WISBER, we assume that the user
wants his/her money &apos;to be invested.&apos;
The second assumption expresses (a
part of) the competence of the user. This
is not of particular importance for many
other types of dialog systems. In a con-
sultation system, however, this is the
basis for addressing the user in order to
ask him/her to make his/her intentions
more precise. In the course of the dialog
these assumptions are supposed to be
confirmed and, moreover, their content
is expected to become more precise.
In the subsequent paragraphs we out-
line the processing behavior of the sys-
tem by explaining the application and
the effect of some of the most important
dialog rules (at least one of each of the
three packages introduced in the previ-
ous section), thus giving an impression
of the system&apos;s coverage. In the rules
presented below, variables are suitably
quantified as they appear for the first
time in the precondition. In subsequent
appearences they are referred to like
constants. The interpretation of the spe-
cial constants denoting time-intervals
depends on whether they occur on the
left or on the right side of a rule: in the
precondition the associated state/event
must hold/occur during PAST, FUTURE or
overlaps NOW; in the effect the state/
event is associated with a time-interval
that starts at the reference time-inter-
val.
In a consultation dialog, the user&apos;s
wants may not always express a direct
request for information, but rather re-
fer to events and states in the real
world. From such user wants the sys-
tem must derive requests for knowledge
useful when attempting to satisfy
them.2 Consequently the task of infer-
</bodyText>
<table confidence="0.963572538461538">
- 30 -
(KNOW MUTUAL
(WANT USER (KNOW MUTUAL
(EXIST A (ACTION A)) NOW) NOW) (WANT USER
A Si NOW) NOW)
(KNOW SYSTEM A
(UNIQUE R (KNOW MUTUAL
(AND (RULE R) R NOW)
(HAS-ACTION R A) A
(HAS-PRECONDITION R (KNOW MUTUAL
(EXIST Si (STATE Si))) (WANT USER
(HAS-EFFECT R 52 NOW) NOW)
(EXIST S2 (STATE 52))))) NOW)
</table>
<tableCaption confidence="0.873657">
Rule 1: Inference drawn from a user want referring to an action with unambi-
guous consequences (pursuing a global goal)
</tableCaption>
<bodyText confidence="0.991520935897437">
ring communicative goals is of central
importance for the functionality of the
system.
There is, however, a fundamental dis-
tinction whether the content of a want
refers to a state or to an event (to be
more precise, to an action, mostly). In
the latter case some important infer-
ences can be drawn depending on the
domain knowledge about the envi-
sioned action and the degree of preci-
sion expressed in its specificatiqn. If,
according to the system&apos;s domain
model, the effect of the specified action
is unambiguous, the user can be expect-
ed to be familiar with this relation, so
he/she can be assumed to envision the
resulting state and, possibly, the pre-
condition as well, if it is not yet ful-
filled. Thus, in principle, a plan consist-
ing of a sequence of actions could be cre-
ated by application of skillful rule
chaining.
This is exactly what Rule 1 asserts:
Given the mutual knowledge that the
user wants a certain action to occur,
and the system&apos;s knowledge (in form of
a unique rule) about the associated pre-
condition and effect, the system con-
cludes that the user envisions the
resulting state and he/she is familiar
with the connecting causal relation. If
the uniqueness of the rule cannot be
2 unlike other systems, e.g., UC [Wilensky et
al. 84], which can directly perform some kinds
of actions required by the user, WISBER is
unable to affect any part of the real world in
the domain of application.
established, sufficient evidence derived
from the partner model might be an
alternative basis to obtain a sufficient
categorization of the desired event so
that a unique rule is found. Otherwise
the user has to be asked to precise
his/her intention.
Let us suppose, to give an example, that
the user has expressed a want to invest
his/her money. According to WISBER&apos;s
domain model, there is only one match-
ing domain rule expressing that the
user has to possess the money before
but not after investing his/her money,
and obtains, in exchange, an asset of an
equivalent value. Hence Rule 1 fires.
The want expressed by the second part
of the conclusion can be immediately
satisfied as a consequence of the user
utterance &apos;I have inherited 40 000 DM&apos;
by applying Rule 5 (which will be ex-
plained later). The remainder part of
the conclusion matches almost com-
pletely the precondition of Rule 2.
This rule states: If the user wants to
achieve a goal state (G) and is informed
about the way this can be done (he/she
knows the specific RULE R and is capable
of performing the relevant action), the
system is right to assume that the user
is lacking some information which in-
hibits him/her from actually doing it.
Therefore, a want of the user indicating
the intention to know more about this
transaction is created (expressed by the
meta-predicate AUGMENT). If the neces-
sary capability cannot be attributed to
the user a consultation is impossible.
If, to discuss another example, the user
has expressed a want aiming at a cer-
</bodyText>
<table confidence="0.9924835">
- 31
(KNOW MUTUAL (BELIEVE SYSTEM
(WANT USER (WANT USER
(EXISTS (STATE 5)) NOW) NOW) (KNOW USER
A =0 (AUGMENT 5)
(KNOW MUTUAL FUTURE)
(UNIQUE R NOW)
(AND (RULE R) NOW)
(HAS-EFFECT RS)
(HAS-ACTION R
(EXIST A (ACTION A))))) NOW)
A
(KNOW MUTUAL
(CAPABILITY USER A) NOW)
</table>
<tableCaption confidence="0.432696">
Rule 2: Inference drawn from a user want referring to a state, given his/her ac-
quaintance with the associated causal relation (pursuing a global goal)
</tableCaption>
<bodyText confidence="0.999957894736842">
tam n state (e.g., &apos;I want to have my mon-
ey back&apos;), the application of another
rule almost identical to Rule 1 is at-
tempted. When its successful applica-
tion yields the association of a unique
event, the required causal relation is
established. Moreover, the user&apos;s fami-
liarity with this relation must be deri-
vable in order to follow the path indi-
cated by Rule 2. Otherwise, a want of
the user would be created whose con-
tent is to find out about suitable means
to achieve the desired state (as ex-
pressed by Rule 3, leading to a system
reaction like, e.g., &apos;you must dissolve
your savings account&apos;).
It is very frequently the case that the
satisfaction of a want cannot immedi-
ately be achieved because the precision
of its specification is insufficient. When
the domain-specific problem solving
component indicates a clue about what
information would be helpful in this re-
spect this triggers the creation of a sys-
tem want to get acquainted with it.
Whenever the user&apos;s uninformedness in
a particular case is not yet proved, and
this information falls into his/her com-
petence area, control is passed to the ge-
neration component to address a suit-
able question to the user (as expressed
in Rule 4).
Provided with new information hopeful-
ly obtained by the user&apos;s reply the sys-
tem tries again to satisfy the (more pre-
cisely specified) user want. This procesE
is repeated until an adequate degree oi
specification is achieved at some stage.
</bodyText>
<table confidence="0.9991618">
(KNOW MUTUAL (BELIEVE SYSTEM
(WANT USER (WANT USER
(EXIST G (KNOW USER
(STATE G)) NOW) NOW) =0
A FUTURE)
(KNOW SYSTEM NOW)
(EXIST R NOW)
(AND (RULE R)
(HAS-EFFECT R G)
(HAS-PRECONDITION R
(EXIST S (STATE 5)))
(HAS-ACTION R
(EXIST A (ACTION A))))) NOW)
A
(-I (KNOW USER R NOW))
</table>
<tableCaption confidence="0.735209">
Rule 3: Inference drawn from a user want referring to a state, missing his/her ac-
quaintance with the associated causal relation (pursuing a global goal)
</tableCaption>
<table confidence="0.985440153846154">
- 32 -
(WANT SYSTEM (ASK (KNOW MUTUAL
(KNOW SYSTEM SYSTEM (WANT SYSTEM
X FUTURE) NOW) USER (KNOW SYSTEM X
A X) FUTURE)
(BELIEVE SYSTEM NOW) NOW)
(KNOW USER A
(RELATED X) (KNOW MUTUAL
NOW) NOW) (BELIEVE SYSTEM
A (KNOW USER
( (KNOW SYSTEM (RELATED X)
(KNOW USER NOW)
X NOW)) NOW)) NOW) NOW)
</table>
<tableCaption confidence="0.6761745">
Rule 4: Inference drawn from the user&apos;s (assumed) competence and a system
want in this area (triggering a speech act)
</tableCaption>
<bodyText confidence="0.999901">
In the course of the dialog each utter-
ance effects parts of the system&apos;s cur-
rent model of the user (concerning as-
sumptions or temporarily established
knowledge). Therefore, these effects are
checked in order to keep the data base
consistent. Consider, for instance, a
user want aiming at investing some
money which, after a phase of para-
meter assembling, has led to the system
proposal &apos;I recommend you to buy
bonds&apos; apparently accomplishing the
(substitued) goal of obtaining enough
information to perform the envisioned
action. Consequently, the state of the
associated user want is subject to
change which is expressed by Rule 5.
Therefore, the mutual knowledge about
the user want is modified (by closing
the associated time-interval) and the
the user&apos;s want is marked as being &apos;fin-
ished&apos; and added to the (new) mutual
knowledge.
However, this simplified treatment of
the satisfaction of a want includes the
restrictive assumptions that the accept-
ance of the proposal is (implicitly) anti-
cipated, and that modifications of a
want or of a proposal are not manage-
able. In a more elaborated version, the
goal accomplishment has to be marked
as provisory. If the user expresses
his/her acceptance either explicitly or
changes the topic (thus implicitly
agreeing to the proposal), the appli-
cation of Rule 5 is fully justified.
Apart from the problem of the increas-
ing complexity and the amount of ne-
cessary additional rules, the prelimi-
nary status of our solution has much to
do with problems of interpreting the
AUGMENT-predicate which appears in
the representation of a communicative
goal according to the derivation by Rule
2: The system is satisfied by finding any
additional information augmenting the
user&apos;s knowledge, but it is not aware of
the requirement that the information
must be a suitable supplement (which is
recognizable by the user&apos;s confirmation
only).
</bodyText>
<table confidence="0.949230888888889">
(KNOW MUTUAL (MEETS TI NOW)
(WANT USER A
X NOW) (KNOW MUTUAL
(EXIST TI (WANT USER
(AND (TIME-INTERVAL TI) X
(DURING TI NOW)))) PAST)
A NOW)
(KNOW MUTUAL
X NOW)
</table>
<note confidence="0.556167">
Rule 5: Inference drawn from a (mutually known) user want which the user
knows to be accomplished (pursuing consistency maintenance)
</note>
<page confidence="0.984034">
33
</page>
<sectionHeader confidence="0.972613" genericHeader="conclusions">
FUTURE RESEARCH
</sectionHeader>
<bodyText confidence="0.999936846153846">
The method described in this paper is
fully implemented and integrated in
the complete NL system WISBER. A re-
latively small set of rules has proved
sufficient to guide basic consultation di-
alogs. Currently we are extending the
set of dialog control rules to perform
more complex dialogs. Our special in-
terest lies on clarification dialogs to
handle misconceptions and inconsisten-
cies. The first steps towards handling
inconsistent user goals will be an expli-
cit representation of the interrelation-
ships holding between propositional at-
titudes, e.g., goals being simultaneous
or competing, or one goal being a re-
finement of another goal. A major ques-
tion will be specifying the operations
necessary to recognize those interrela-
tionships working on the semantic re-
presentation of the propositional con-
tents. As our set of rules grows, a more
sophisticated control mechanism will
become necessary, structuring the deri-
vation process and employing both for-
ward and backward reasoning.
</bodyText>
<sectionHeader confidence="0.999235" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.994766935483871">
Allen 83
Allen, J.F.: Recognizing Intentions from Natur-
al Language Utterances. In: Brady, M., Ber-
wick, R.C. (eds.): Computational Models of Dis-
course, MIT Press, 1983, pp. 107-166.
Allen 84
Allen, J.F.: Towards a General Theory of Action
and Time. In: Artificial Intelligence 23 (2),
1984, pp. 123-154.
Appelt 85
Appelt, D.E.: Planning English Sentences.
Cambridge University Press, 1985.
Bergmann, Gerlach 88
Bergmann, H., Gerlach, M.: Semantisch-
pragmatische Verarbeitung von AuBerungen
im natUrlichsprachlichen Beratungssystem
WISBER. In: Brauer, W., Wahlster, W. (eds.):
Wissensbasierte Systeme — GI-Kongress 1987.
Springer Verlag, Berlin, 1987, pp. 318-327.
Bergmann et. al. 87
Bergmann, H., Fliegner, M., Gerlach, M.,
Marburger, H., Poesio, M.: IRS - The Internal
Representation Language. WISBER Bericht Nr.
14, Universitat Hamburg, 1987.
Carberry 83
Carberry, S.: Tracking User Goals in an Infor-
mation-Seeking Environment. In: Proceedings
of the AAAI-83, Washington, D.C., 1983, pp.
59-63.
Cohen, Perrault 79
Cohen, P.R., Perrault, C.R.: Elements of a Plan-
Based Theory of Speech Acts. In: Cognitive
Science 3, 1979, pp. 177-212.
Gerlach, Sprenger 88
Gerlach, M., Sprenger, M.: Semantic Interpreta-
tion of Pragmatic Clues: Connectives, Modal
Verbs, and Indirect Speech Acts. In: Proc. of
COLING-88, Budapest, 1988, pp. 191-195.
Grice 75
Grice, H.P.: Logic and Conversation. in: Cole,
Morgan (ed.): Syntax and Semantics, Vol. 3:
Speech Acts, Academic Press, New York, 1975,
pp. 41-58.
Grosz, Sidner 86
Grosz, B.J., Sidner, C.L.: Attention, Intentions,
and the Structure of Discourse. In: Compu-
tational Linguistics 12(3), 1986, pp. 175-204.
Horacek et at. 88
Horacek, H., Bergmann, H., Block, R., Fliegner,
M., Gerlach, M., Poesio, M., Sprenger, M.: From
Meaning to Meaning - a Walk through WIS-
BER. In: Hoeppner, W. (ed.): Kunstliche Intelli-
genz - GWAI-88, Springer Verlag, Berlin, 1988,
pp. 118-129.
Litman, Allen 84
Litman, D.J., Allen, J.F.: A Plan Recognition
Model for Clarification Subdialogues. In: Proc.
COLING&apos;84, Stanford, pp. 302-311.
Melling, et at. 87
Melting, J., Liermann I., Schachter-Radig M.-J.:
Handlungsschemata in Beratungsdialogen -
Am Gesprachsgegenstand orientierte Dialog-
analyse. Bericht Nr. 18, WISBER-Verbundpro-
jekt, Dezember 1987, SCS Organisationsbera-
tung und Informationstechnik GmbH, Ham-
burg.
Metzing 79
Metzing, D.: Zur Entwicklung prozeduraler
Dialogmodelle. In: Metzing, D. (Ed.): Dialog-
muster und Dialogprozesse. Helmut Buske
Verlag, Hamburg, 1979.
Poesio 88
Poesio, M.: Toward a Hybrid Representation of
Time. In: Proc. of the ECAI-88, Munchen, 1988,
pp. 247-252.
Sprenger, Gerlach 88
Sprenger, M., Gerlach, M.: Expectations and
Propositional Attitudes - Pragmatic Issues in
WISBER. In: Proc. of the International Com-
puter Science Conference &apos;88, Hong Kong, 1988.
Werner 88
Werner, E.: Toward a Theory of Communica-
tion and Cooperation for Multiagent Planning.
In: Theoretical Aspects of Reasoning about
Knowledge, Proceedings of the 1988 Confer-
ence, Morgan Kaufman Publishers, Los Altos,
1988, pp. 129-143.
When sky et at.. 84
Wilensky, R., Arens, Y., Chin, D.: Talking to
UNIX in English: An Overview of UC. In: Com-
munications of the ACM, Vol. 27, No. 6, pp. 574-
593.
- 34 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.605341">
<title confidence="0.999765">Dialog Control in a Natural Language Systeml</title>
<author confidence="0.998007">Michael Gerlach Helmut Horacek</author>
<affiliation confidence="0.883533">Universitat Hamburg Fachbereich Informatik Projektgruppe WISBER</affiliation>
<abstract confidence="0.982237352941177">JungiusstraBe 6 D-2000 Hamburg 36 F.R.G. ABSTRACT In this paper a method for controlling the dialog in a natural language (NL) system is presented. It provides a deep modeling of information processing based on time dependent propositional attitudes of the interacting agents. Knowledge about the state of the dialog is represented in a dedicated language and changes of this state are described by a compact set of rules. An appropriate organization of rule application is introduced including the initiation of an adequate system reaction. Finally the application of the method in an NL consultation system is outlined.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<journal>Allen</journal>
<volume>83</volume>
<marker></marker>
<rawString>Allen 83</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Recognizing Intentions from Natural Language Utterances.</title>
<date>1983</date>
<booktitle>Computational Models of Discourse,</booktitle>
<pages>107--166</pages>
<editor>In: Brady, M., Berwick, R.C. (eds.):</editor>
<publisher>MIT Press,</publisher>
<marker>Allen, 1983</marker>
<rawString>Allen, J.F.: Recognizing Intentions from Natural Language Utterances. In: Brady, M., Berwick, R.C. (eds.): Computational Models of Discourse, MIT Press, 1983, pp. 107-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>Towards a General Theory of Action and Time. In:</title>
<date>1984</date>
<journal>Artificial Intelligence</journal>
<volume>23</volume>
<issue>2</issue>
<pages>123--154</pages>
<marker>Allen, 1984</marker>
<rawString>Allen 84 Allen, J.F.: Towards a General Theory of Action and Time. In: Artificial Intelligence 23 (2), 1984, pp. 123-154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Appelt</author>
</authors>
<title>Planning English Sentences.</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<marker>Appelt, 1985</marker>
<rawString>Appelt 85 Appelt, D.E.: Planning English Sentences. Cambridge University Press, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bergmann</author>
<author>M Gerlach</author>
</authors>
<title>Semantischpragmatische Verarbeitung von AuBerungen im natUrlichsprachlichen Beratungssystem WISBER.</title>
<date>1987</date>
<booktitle>Wissensbasierte Systeme — GI-Kongress</booktitle>
<pages>318--327</pages>
<editor>In: Brauer, W., Wahlster, W. (eds.):</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin,</location>
<marker>Bergmann, Gerlach, 1987</marker>
<rawString>Bergmann, Gerlach 88 Bergmann, H., Gerlach, M.: Semantischpragmatische Verarbeitung von AuBerungen im natUrlichsprachlichen Beratungssystem WISBER. In: Brauer, W., Wahlster, W. (eds.): Wissensbasierte Systeme — GI-Kongress 1987. Springer Verlag, Berlin, 1987, pp. 318-327. Bergmann et. al. 87</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bergmann</author>
<author>M Fliegner</author>
<author>M Gerlach</author>
<author>H Marburger</author>
<author>M Poesio</author>
</authors>
<title>IRS - The Internal Representation Language.</title>
<date>1987</date>
<journal>WISBER Bericht Nr.</journal>
<volume>14</volume>
<location>Universitat Hamburg,</location>
<marker>Bergmann, Fliegner, Gerlach, Marburger, Poesio, 1987</marker>
<rawString>Bergmann, H., Fliegner, M., Gerlach, M., Marburger, H., Poesio, M.: IRS - The Internal Representation Language. WISBER Bericht Nr. 14, Universitat Hamburg, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carberry</author>
</authors>
<title>Tracking User Goals in an Information-Seeking Environment. In:</title>
<date>1983</date>
<booktitle>Proceedings of the AAAI-83,</booktitle>
<pages>59--63</pages>
<location>Washington, D.C.,</location>
<marker>Carberry, 1983</marker>
<rawString>Carberry 83 Carberry, S.: Tracking User Goals in an Information-Seeking Environment. In: Proceedings of the AAAI-83, Washington, D.C., 1983, pp. 59-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
<author>Perrault</author>
</authors>
<title>C.R.: Elements of a PlanBased Theory of Speech Acts.</title>
<date>1979</date>
<journal>In: Cognitive Science</journal>
<volume>3</volume>
<pages>177--212</pages>
<marker>Cohen, Perrault, 1979</marker>
<rawString>Cohen, Perrault 79 Cohen, P.R., Perrault, C.R.: Elements of a PlanBased Theory of Speech Acts. In: Cognitive Science 3, 1979, pp. 177-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gerlach</author>
<author>M Sprenger</author>
</authors>
<title>Semantic Interpretation of Pragmatic Clues: Connectives, Modal Verbs, and Indirect Speech Acts. In:</title>
<date>1988</date>
<booktitle>Proc. of COLING-88,</booktitle>
<pages>191--195</pages>
<location>Budapest,</location>
<marker>Gerlach, Sprenger, 1988</marker>
<rawString>Gerlach, Sprenger 88 Gerlach, M., Sprenger, M.: Semantic Interpretation of Pragmatic Clues: Connectives, Modal Verbs, and Indirect Speech Acts. In: Proc. of COLING-88, Budapest, 1988, pp. 191-195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grice</author>
</authors>
<title>H.P.: Logic and Conversation.</title>
<date>1975</date>
<booktitle>Syntax and Semantics,</booktitle>
<volume>3</volume>
<pages>41--58</pages>
<editor>in: Cole, Morgan (ed.):</editor>
<publisher>Speech Acts, Academic Press,</publisher>
<location>New York,</location>
<marker>Grice, 1975</marker>
<rawString>Grice 75 Grice, H.P.: Logic and Conversation. in: Cole, Morgan (ed.): Syntax and Semantics, Vol. 3: Speech Acts, Academic Press, New York, 1975, pp. 41-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Attention Sidner</author>
</authors>
<title>Intentions, and the Structure of Discourse. In:</title>
<date>1986</date>
<journal>Computational Linguistics</journal>
<volume>12</volume>
<issue>3</issue>
<pages>175--204</pages>
<note>Horacek et at. 88</note>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, Sidner 86 Grosz, B.J., Sidner, C.L.: Attention, Intentions, and the Structure of Discourse. In: Computational Linguistics 12(3), 1986, pp. 175-204. Horacek et at. 88</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
<author>H Bergmann</author>
<author>R Block</author>
<author>M Fliegner</author>
<author>M Gerlach</author>
<author>M Poesio</author>
<author>M Sprenger</author>
</authors>
<title>From Meaning to Meaning -</title>
<date>1988</date>
<booktitle>Kunstliche Intelligenz - GWAI-88,</booktitle>
<pages>118--129</pages>
<editor>a Walk through WISBER. In: Hoeppner, W. (ed.):</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin,</location>
<marker>Horacek, Bergmann, Block, Fliegner, Gerlach, Poesio, Sprenger, 1988</marker>
<rawString>Horacek, H., Bergmann, H., Block, R., Fliegner, M., Gerlach, M., Poesio, M., Sprenger, M.: From Meaning to Meaning - a Walk through WISBER. In: Hoeppner, W. (ed.): Kunstliche Intelligenz - GWAI-88, Springer Verlag, Berlin, 1988, pp. 118-129.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D J Litman</author>
<author>Allen</author>
</authors>
<title>J.F.: A Plan Recognition Model for Clarification Subdialogues. In:</title>
<booktitle>Proc. COLING&apos;84,</booktitle>
<pages>302--311</pages>
<location>Stanford,</location>
<marker>Litman, Allen, </marker>
<rawString>Litman, Allen 84 Litman, D.J., Allen, J.F.: A Plan Recognition Model for Clarification Subdialogues. In: Proc. COLING&apos;84, Stanford, pp. 302-311.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Melting</author>
<author>I Liermann</author>
<author>M-J Schachter-Radig</author>
</authors>
<booktitle>Handlungsschemata in Beratungsdialogen -Am Gesprachsgegenstand orientierte Dialoganalyse. Bericht Nr. 18, WISBER-Verbundprojekt, Dezember 1987, SCS Organisationsberatung und Informationstechnik GmbH,</booktitle>
<location>Hamburg.</location>
<marker>Melting, Liermann, Schachter-Radig, </marker>
<rawString>Melling, et at. 87 Melting, J., Liermann I., Schachter-Radig M.-J.: Handlungsschemata in Beratungsdialogen -Am Gesprachsgegenstand orientierte Dialoganalyse. Bericht Nr. 18, WISBER-Verbundprojekt, Dezember 1987, SCS Organisationsberatung und Informationstechnik GmbH, Hamburg.</rawString>
</citation>
<citation valid="true">
<title>Metzing 79 Metzing, D.: Zur Entwicklung prozeduraler Dialogmodelle. In: Metzing,</title>
<date>1979</date>
<editor>D. (Ed.):</editor>
<location>Hamburg,</location>
<marker>1979</marker>
<rawString>Metzing 79 Metzing, D.: Zur Entwicklung prozeduraler Dialogmodelle. In: Metzing, D. (Ed.): Dialogmuster und Dialogprozesse. Helmut Buske Verlag, Hamburg, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>Toward a Hybrid Representation of Time. In:</title>
<date>1988</date>
<booktitle>Proc. of the ECAI-88,</booktitle>
<pages>247--252</pages>
<location>Munchen,</location>
<marker>Poesio, 1988</marker>
<rawString>Poesio 88 Poesio, M.: Toward a Hybrid Representation of Time. In: Proc. of the ECAI-88, Munchen, 1988, pp. 247-252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sprenger</author>
<author>M Gerlach</author>
</authors>
<title>Expectations and Propositional Attitudes - Pragmatic Issues in WISBER. In:</title>
<date>1988</date>
<booktitle>Proc. of the International Computer Science Conference &apos;88,</booktitle>
<location>Hong Kong,</location>
<marker>Sprenger, Gerlach, 1988</marker>
<rawString>Sprenger, Gerlach 88 Sprenger, M., Gerlach, M.: Expectations and Propositional Attitudes - Pragmatic Issues in WISBER. In: Proc. of the International Computer Science Conference &apos;88, Hong Kong, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Werner</author>
</authors>
<title>E.: Toward a Theory of Communication and Cooperation for Multiagent Planning. In: Theoretical Aspects of Reasoning about Knowledge,</title>
<date>1988</date>
<booktitle>Proceedings of the 1988 Conference,</booktitle>
<pages>129--143</pages>
<publisher>Morgan Kaufman Publishers,</publisher>
<location>Los Altos,</location>
<marker>Werner, 1988</marker>
<rawString>Werner 88 Werner, E.: Toward a Theory of Communication and Cooperation for Multiagent Planning. In: Theoretical Aspects of Reasoning about Knowledge, Proceedings of the 1988 Conference, Morgan Kaufman Publishers, Los Altos, 1988, pp. 129-143.</rawString>
</citation>
<citation valid="false">
<authors>
<author>When sky et at</author>
</authors>
<pages>84</pages>
<marker>at, </marker>
<rawString>When sky et at.. 84</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Wilensky</author>
<author>Y Arens</author>
<author>D Chin</author>
</authors>
<title>Talking to UNIX in English: An Overview of UC. In:</title>
<journal>Communications of the ACM,</journal>
<volume>27</volume>
<pages>574--593</pages>
<marker>Wilensky, Arens, Chin, </marker>
<rawString>Wilensky, R., Arens, Y., Chin, D.: Talking to UNIX in English: An Overview of UC. In: Communications of the ACM, Vol. 27, No. 6, pp. 574-593.</rawString>
</citation>
<citation valid="false">
<pages>34</pages>
<marker></marker>
<rawString>- 34 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>