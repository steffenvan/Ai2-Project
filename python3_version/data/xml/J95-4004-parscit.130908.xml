<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99674925">
Transformation-Based Error-Driven
Learning and Natural Language
Processing: A Case Study in
Part-of-Speech Tagging
</title>
<author confidence="0.995672">
Eric Brill*
</author>
<affiliation confidence="0.917299">
The Johns Hopkins University
</affiliation>
<bodyText confidence="0.996308727272727">
Recently, there has been a rebirth of empiricism in the field of natural language processing. Man-
ual encoding of linguistic information is being challenged by automated corpus-based learning
as a method of providing a natural language processing system with linguistic knowledge. Al-
though corpus-based approaches have been successful in many different areas of natural language
processing, it is often the case that these methods capture the linguistic information they are
modelling indirectly in large opaque tables of statistics. This can make it difficult to analyze,
understand and improve the ability of these approaches to model underlying linguistic behavior.
In this paper, we will describe a simple rule-based approach to automated learning of linguistic
knowledge. This approach has been shown for a number of tasks to capture information in a clearer
and more direct fashion without a compromise in performance. We present a detailed case study
of this learning method applied to part-of-speech tagging.
</bodyText>
<sectionHeader confidence="0.99213" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999620578947368">
It has recently become clear that automatically extracting linguistic information from
a sample text corpus can be an extremely powerful method of overcoming the linguis-
tic knowledge acquisition bottleneck inhibiting the creation of robust and accurate
natural language processing systems. A number of part-of-speech taggers are readily
available and widely used, all trained and retrainable on text corpora (Church 1988;
Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity,
which can lead to such difficulties as trying to cope with the many thousands of possi-
ble parses that a grammar can assign to a sentence, can be greatly reduced by adding
empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Je-
linek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of
lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem
that once seemed out of reach for systems without a great deal of handcrafted lin-
guistic and world knowledge, can now in some cases be done with high accuracy
when all information is derived automatically from corpora (Brown, Lai, and Mercer
1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994). An
effort has recently been undertaken to create automated machine translation systems
in which the linguistic information needed for translation is extracted automatically
from aligned corpora (Brown et al. 1990). These are just a few of the many recent
applications of corpus-based techniques in natural language processing.
</bodyText>
<note confidence="0.724712666666667">
* Department of Computer Science, Baltimore, MD 21218-2694. E-mail: brill@cs.jhu.edu.
© 1995 Association for Computational Linguistics
Computational Linguistics Volume 21, Number 4
</note>
<bodyText confidence="0.999771894736842">
Along with great research advances, the infrastructure is in place for this line of
research to grow even stronger, with on-line corpora, the grist of the corpus-based
natural language processing grindstone, getting bigger and better and becoming more
readily available. There are a number of efforts worldwide to manually annotate large
corpora with linguistic information, including parts of speech, phrase structure and
predicate-argument structure (e.g., the Penn Treebank and the British National Corpus
(Marcus, Santorini, and Marcinkiewicz 1993; Leech, Garside, and Bryant 1994)). A vast
amount of on-line text is now available, and much more will become available in the
future. Useful tools, such as large aligned corpora (e.g., the aligned Hansards (Gale
and Church 1991)) and semantic word hierarchies (e.g., Wordnet (Miller 1990)), have
also recently become available.
Corpus-based methods are often able to succeed while ignoring the true complex-
ities of language, banking on the fact that complex linguistic phenomena can often be
indirectly observed through simple epiphenomena. For example, one could accurately
assign a part-of-speech tag to the word race in (1-3) without any reference to phrase
structure or constituent movement: One would only have to realize that, usually, a
word one or two words to the right of a modal is a verb and not a noun. An excep-
tion to this generalization arises when the word is also one word to the right of a
determiner.
</bodyText>
<listItem confidence="0.999397333333333">
(1) He will race/VERB the car.
(2) He will not race/VERB the car.
(3) When will the race/NOUN end?
</listItem>
<bodyText confidence="0.999981454545455">
It is an exciting discovery that simple stochastic n-gram taggers can obtain very
high rates of tagging accuracy simply by observing fixed-length word sequences, with-
out recourse to the underlying linguistic structure. However, in order to make progress
in corpus-based natural language processing, we must become better aware of just
what cues to linguistic structure are being captured and where these approximations
to the true underlying phenomena fail. With many of the current corpus-based ap-
proaches to natural language processing, this is a nearly impossible task. Consider
the part-of-speech tagging example above. In a stochastic n-gram tagger, the informa-
tion about words that follow modals would be hidden deeply in the thousands or
tens of thousands of contextual probabilities (P(Tag, I Tagi_iTag1_2)) and the result of
multiplying different combinations of these probabilities together.
Below, we describe a new approach to corpus-based natural language processing,
called transformation-based error-driven learning. This algorithm has been applied to a
number of natural language problems, including part-of-speech tagging, prepositional
phrase attachment disambiguation, and syntactic parsing (Brill 1992; Brill 1993a; Brill
1993b; Brill and Resnik 1994; Brill 1994). We have also recently begun exploring the
use of this technique for letter-to-sound generation and for building pronunciation
networks for speech recognition. In this approach, the learned linguistic information
is represented in a concise and easily understood form. This property should make
transformation-based learning a useful tool for further exploring linguistic modeling
and attempting to discover ways of more tightly coupling the underlying linguistic
systems and our approximating models.
</bodyText>
<page confidence="0.99421">
544
</page>
<figure confidence="0.989902857142857">
Brill Transformation-Based Error-Driven Learning
UNANNOTATED
TEXT
V
INITIAL
STATE
V
ANNOTATED
--... ..•&apos;-
TRUTH
TEXT
RULES
LEARNER
y
</figure>
<figureCaption confidence="0.906001">
Figure 1
</figureCaption>
<keyword confidence="0.39592">
Transformation-Based Error-Driven Learning.
</keyword>
<sectionHeader confidence="0.795792" genericHeader="keywords">
2. Transformation-Based Error-Driven Learning
</sectionHeader>
<bodyText confidence="0.995047733333333">
Figure 1 illustrates how transformation-based error-driven learning works. First, unan-
notated text is passed through an initial-state annotator. The initial-state annotator can
range in complexity from assigning random structure to assigning the output of a
sophisticated manually created annotator. In part-of-speech tagging, various initial-
state annotators have been used, including: the output of a stochastic n-gram tagger;
labelling all words with their most likely tag as indicated in the training corpus; and
naively labelling all words as nouns. For syntactic parsing, we have explored initial-
state annotations ranging from the output of a sophisticated parser to random tree
structure with random nonterminal labels.
Once text has been passed through the initial-state annotator, it is then compared
to the truth. A manually annotated corpus is used as our reference for truth. An
ordered list of transformations is learned that can be applied to the output of the
initial-state annotator to make it better resemble the truth. There are two components
to a transformation: a rewrite rule and a triggering environment. An example of a
rewrite rule for part-of-speech tagging is:
</bodyText>
<subsubsectionHeader confidence="0.496232">
Change the tag from modal to noun.
</subsubsectionHeader>
<bodyText confidence="0.97127825">
and an example of a triggering environment is:
The preceding word is a determiner.
Taken together, the transformation with this rewrite rule and triggering environ-
ment when applied to the word can would correctly change the mistagged:
</bodyText>
<footnote confidence="0.269165">
The/determiner can/modal rusted/verb ./.
</footnote>
<page confidence="0.992347">
545
</page>
<figure confidence="0.2638707">
Computational Linguistics Volume 21, Number 4
to:
The/determiner can/noun rusted/verb .1.
An example of a bracketing rewrite rule is: change the bracketing of a subtree
from:
to:
/...,
. C
„......---..,,
A B
</figure>
<bodyText confidence="0.935005956521739">
where A, B and C can be either terminals or nonterminals. One possible set of trigger-
ing environments is any combination of words, part-of-speech tags, and nonterminal
labels within and adjacent to the subtree. Using this rewrite rule and the triggering
environment A = the, the bracketing:
( the ( boy ate ) )
would become:
( ( the boy) ate)
In all of the applications we have examined to date, the following greedy search is
applied for deriving a list of transformations: at each iteration of learning, the transfor-
mation is found whose application results in the best score according to the objective
function being used; that transformation is then added to the ordered transforma-
tion list and the training corpus is updated by applying the learned transformation.
Learning continues until no transformation can be found whose application results in
an improvement to the annotated corpus. Other more sophisticated search techniques
could be used, such as simulated annealing or learning with a look-ahead window,
but we have not yet explored these alternatives.
Figure 2 shows an example of learning transformations. In this example, we as-
sume there are only four possible transformations, Ti through T4, and that the ob-
jective function is the total number of errors. The unannotated training corpus is
processed by the initial-state annotator, and this results in an annotated corpus with
5,100 errors, determined by comparing the output of the initial-state annotator with
the manually derived annotations for this corpus. Next, we apply each of the possible
transformations in turn and score the resulting annotated corpus.&apos; In this example,
</bodyText>
<footnote confidence="0.9849245">
1 In the real implementation, the search is data driven, and therefore not all transformations need to be
examined.
</footnote>
<page confidence="0.997893">
546
</page>
<figure confidence="0.99905254">
Brill Transformation-Based Error-Driven Learning
Ti
/2
14
Annotated
Corpus
Errors= 1,410
T3
Annotated
Corpus
Errors = 1,231
Annotated
Corpus
Errors -, 5,100
Unannotated
Corpus
i
Annotated
Corpus
Errors = 3,145
Annotated
Corpus
Errors = 3,910
Annotated
Corpus
Errors = 6,300
T3 ,
Initial State
Annotator
Annotated
Corpus
Errors = 5,100
Annotated
Corpus
Errors = 3,310
Annotated
Corpus
Errors = 1,231
Annotated
Corpus
Errors = 4,255
Annotated
Corpus
Errors = 2,110
Annotated
Corpus
Errors = 1,25
Annotated
Corpus
Errors = 1,231
</figure>
<figureCaption confidence="0.969394">
Figure 2
</figureCaption>
<subsectionHeader confidence="0.817395">
An Example of Transformation-Based Error-Driven Learning.
</subsectionHeader>
<bodyText confidence="0.9797135">
applying transformation T2 results in the largest reduction of errors, so 12 is learned
as the first transformation. T2 is then applied to the entire corpus, and learning con-
tinues. At this stage of learning, transformation 13 results in the largest reduction of
error, so it is learned as the second transformation. After applying the initial-state
annotator, followed by T2 and then T3, no further reduction in errors can be obtained
from applying any of the transformations, so learning stops. To annotate fresh text,
this text is first annotated by the initial-state annotator, followed by the application of
transformation T2 and then by the application of T3.
To define a specific application of transformation-based learning, one must specify
the following:
</bodyText>
<listItem confidence="0.9251782">
I. The initial state-annotator.
2. The space of allowable transformations (rewrite rules and triggering
environments).
3. The objective function for comparing the corpus to the truth and
choosing a transformation.
</listItem>
<bodyText confidence="0.991498">
In cases where the application of a particular transformation in one environment
could affect its application in another environment, two additional parameters must
be specified: the order in which transformations are applied to a corpus, and whether
a transformation is applied immediately or only after the entire corpus has been ex-
amined for triggering environments. For example, take the sequence:
</bodyText>
<sectionHeader confidence="0.647991" genericHeader="introduction">
AAAAAA
</sectionHeader>
<bodyText confidence="0.501055">
and the transformation:
</bodyText>
<page confidence="0.982913">
547
</page>
<figure confidence="0.379673">
Computational Linguistics Volume 21, Number 4
Change the label from A to B if the preceding label is A.
</figure>
<bodyText confidence="0.853193090909091">
If the effect of the application of a transformation is not written out until the entire
file has been processed for that one transformation, then regardless of the order of
processing the output will be:
ABBBBB,
since the triggering environment of a transformation is always checked before that
transformation is applied to any surrounding objects in the corpus. If the effect of a
transformation is recorded immediately, then processing the string left to right would
result in:
ABABAB,
whereas processing right to left would result in:
ABBBBB.
</bodyText>
<sectionHeader confidence="0.669196" genericHeader="method">
3. A Comparison With Decision Trees
</sectionHeader>
<bodyText confidence="0.999947272727273">
The technique employed by the learner is somewhat similar to that used in decision
trees (Breiman et al. 1984; Quinlan 1986; Quinlan and Rivest 1989). A decision tree
is trained on a set of preclassified entities and outputs a set of questions that can be
asked about an entity to determine its proper classification. Decision trees are built
by finding the question whose resulting partition is the purest,2 splitting the training
data according to that question, and then recursively reapplying this procedure on
each resulting subset.
We first show that the set of classifications that can be provided via decision trees
is a proper subset of those that can be provided via transformation lists (an ordered
list of transformation-based rules), given the same set of primitive questions. We then
give some practical differences between the two learning methods.
</bodyText>
<subsectionHeader confidence="0.996964">
3.1 Decision Trees C Transformation Lists
</subsectionHeader>
<bodyText confidence="0.999745">
We prove here that for a fixed set of primitive queries, any binary decision tree can
be converted into a transformation list. Extending the proof beyond binary trees is
straightforward.
</bodyText>
<subsectionHeader confidence="0.874996">
Proof (by induction)
Base Case:
</subsectionHeader>
<bodyText confidence="0.999646">
Given the following primitive decision tree, where the classification is A if the
answer to the query X? is yes, and the classification is B if the answer is no:
</bodyText>
<equation confidence="0.4764955">
X?
B A
</equation>
<page confidence="0.640542">
2 One possible measure for purity is entropy reduction.
548
</page>
<bodyText confidence="0.301145">
Brill Transformation-Based Error-Driven Learning
this tree can be converted into the following transformation list:
</bodyText>
<listItem confidence="0.99196525">
1. Label with S /* Start State Annotation */
2. If X, then S -4 A
3. S B /* Empty Tagging Environment—Always Applies To Entities
Currently Labeled With S */
</listItem>
<subsectionHeader confidence="0.663541">
Induction:
</subsectionHeader>
<bodyText confidence="0.846116">
Assume that two decision trees T1 and T2 have corresponding transformation lists
L1 and L2. Assume that the arbitrary label names chosen in constructing Ll are not
used in L2, and that those in L2 are not used in L1. Given a new decision tree T3
constructed from T1 and T2 as follows:
X?
we construct a new transformation list L3. Assume the first transformation in L1 is:
Label with S&apos;
and the first transformation in L2 is:
Label with S&amp;quot;
The first three transformations in L3 Will then be:
</bodyText>
<listItem confidence="0.990693">
1. Label with S
2. If X then S -4 S&apos;
3. S -.4 S&amp;quot;
</listItem>
<bodyText confidence="0.9625852">
followed by all of the rules in L1 other than the first rule, followed by all of the rules
in L2 other than the first rule. The resulting transformation list will first label an item
as S&apos; if X is true, or as S&amp;quot; if X is false. Next, the tranformations from L1 will be applied
if X is true, since S&apos; is the initial-state label for L1. If X is false, the transformations
from L2 will be applied, because S&amp;quot; is the initial-state label for L2. 0
</bodyText>
<subsectionHeader confidence="0.999036">
3.2 Decision Trees 0 Transformation Lists
</subsectionHeader>
<bodyText confidence="0.9999886">
We show here that there exist transformation lists for which no equivalent decision
trees exist, for a fixed set of primitive queries. The following classification problem is
one example. Given a sequence of characters, classify a character based on whether
the position index of a character is divisible by 4, querying only using a context of
two characters to the left of the character being classified.
</bodyText>
<page confidence="0.982667">
549
</page>
<note confidence="0.446693">
Computational Linguistics Volume 21, Number 4
</note>
<bodyText confidence="0.997169">
Assuming transformations are applied left to right on the sequence, the above
classification problem can be solved for sequences of arbitrary length if the effect of
a transformation is written out immediately, or for sequences up to any prespecified
length if a transformation is carried out only after all triggering environments in the
corpus are checked. We present the proof for the former case.
Given the input sequence:
</bodyText>
<equation confidence="0.4964205">
AAAAAAAAA
0 1 2 3 4 5 6 7 8 9
</equation>
<bodyText confidence="0.999196875">
the underlined characters should be classified as true because their indices are 0, 4,
and 8. To see why a decision tree could not perform this classification, regardless of
order of classification, note that, for the two characters before both A3 and A4, both the
characters and their classifications are the same, although these two characters should
be classified differently. Below is a transformation list for performing this classification.
Once again, we assume transformations are applied left to right and that the result of a
transformation is written out immediately, so that the result of applying transformation
x to character a, will always be known when applying transformation x to ai+i.
</bodyText>
<listItem confidence="0.97466275">
1. Label with S
RESULT: A/S A/S A/S A/S A/S A/S A/S A/S A/S A/S A/S
2. If there is no previous character, then S —&gt; F
RESULT: A/F A/S A/S A/S A/S A/S A/S A/S A/S A/S A/S
3. If the character two to the left is labelled with F, then S —&gt; F
RESULT: A/F A/S A/F A/S A/F A/S A/F A/S A/F A/S A/F
4. If the character two to the left is labelled with F, then F —&gt; S
RESULT: A/F A/S A/S A/S A/F A/S A/S A/S A/F A/S A/S
5. F —&gt; yes
6. S —&gt; no
RESULT: A/yes A/no A/no A/no A/yes A/no A/no A/no A/yes
A/no A/no
</listItem>
<bodyText confidence="0.999887">
The extra power of transformation lists comes from the fact that intermediate
results from the classification of one object are reflected in the current label of that
object, thereby making this intermediate information available for use in classifying
other objects. This is not the case for decision trees, where the outcome of questions
asked is saved implicitly by the current location within the tree.
</bodyText>
<subsectionHeader confidence="0.999478">
3.3 Some Practical Differences Between Decision Trees and Transformation Lists
</subsectionHeader>
<bodyText confidence="0.976187086956522">
There are a number of practical differences between transformation-based error-driven
learning and learning decision trees. One difference is that when training a decision
tree, each time the depth of the tree is increased, the average amount of training mate-
rial available per node at that new depth is halved (for a binary tree). In transformation-
based learning, the entire training corpus is used for finding all transformations. There-
fore, this method is not subject to the sparse data problems that arise as the depth of
the decision tree being learned increases.
Transformations are ordered, with later transformations being dependent upon
the outcome of applying earlier transformations. This allows intermediate results in
550 •
Brill Transformation-Based Error-Driven Learning
classifying one object to be available in classifying other objects. For instance, whether
the previous word is tagged as to-infinitival or to-preposition may be a good cue for de-
termining the part of speech of a word.&apos; If, initially, the word to is not reliably tagged
everywhere in the corpus with its proper tag (or not tagged at all), then this cue will
be unreliable. The transformation-based learner will delay positing a transformation
triggered by the tag of the word to until other transformations have resulted in a more
reliable tagging of this word in the corpus. For a decision tree to take advantage of
this information, any word whose outcome is dependent upon the tagging of to would
need the entire decision tree structure for the proper classification of each occurrence
of to built into its decision tree path. If the classification of to were dependent upon the
classification of yet another word, this would have to be built into the decision tree as
well. Unlike decision trees, in transformation-based learning, intermediate classifica-
tion results are available and can be used as classification progresses. Even if decision
trees are applied to a corpus in a left-to-right fashion, they are allowed only one pass
in which to properly classify.
Since a transformation list is a processor and not a classifier, it can readily be
used as a postprocessor to any annotation system. In addition to annotating from
scratch, rules can be learned to improve the performance of a mature annotation
system by using the mature system as the initial-state annotator. This can have the
added advantage that the list of transformations learned using a mature annotation
system as the initial-state annotator provides a readable description or classification of
the errors the mature system makes, thereby aiding in the refinement of that system.
The fact that it is a processor gives a transformation-based learner greater than the
classifier-based decision tree. For example, in applying transformation-based learning
to parsing, a rule can apply any structural change to a tree. In tagging, a rule such as:
Change the tag of the current word to X, and of the previous word to Y, if Z holds
can easily be handled in the processor-based system, whereas it would be difficult to
handle in a classification system.
In transformation-based learning, the objective function used in training is the
same as that used for evaluation, whenever this is feasible. In a decision tree, using sys-
tem accuracy as an objective function for training typically results in poor performance&apos;
and some measure of node purity, such as entropy reduction, is used instead. The di-
rect correlation between rules and performance improvement in transformation-based
learning can make the learned rules more readily interpretable than decision tree rules
for increasing population purity.&apos;
</bodyText>
<subsectionHeader confidence="0.962788">
4. Part of Speech Tagging: A Case Study in Transformation-Based Error-Driven
Learning
</subsectionHeader>
<bodyText confidence="0.9998655">
In this section we describe the practical application of transformation-based learning
to part-of-speech tagging.&apos; Part-of-speech tagging is a good application to test the
</bodyText>
<footnote confidence="0.909365857142857">
3 The original tagged Brown Corpus (Francis and Kucera, 1982) makes this distinction; the Penn
Treebank (Marcus, Santorini, and Marcinkiewicz, 1993) does not.
4 For a discussion of why this is the case, see Breiman et al. (1984, 94-98).
5 For a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus
(1994).
6 All of the programs described herein are freely available with no restrictions on use or redistribution.
For information on obtaining the tagger, contact the author.
</footnote>
<page confidence="0.98507">
551
</page>
<note confidence="0.449854">
Computational Linguistics Volume 21, Number 4
</note>
<bodyText confidence="0.999983333333333">
learner, for several reasons. There are a number of large tagged corpora available,
allowing for a variety of experiments to be run. Part-of-speech tagging is an active
area of research; a great deal of work has been done in this area over the past few years
(e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo
1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993;
Weischedel et al. 1993; Schutze and Singer 1994).
Part-of-speech tagging is also a very practical application, with uses in many areas,
including speech recognition and generation, machine translation, parsing, information
retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem
in lexical ambiguity, advances in part-of-speech tagging could readily translate to
progress in other areas of lexical, and perhaps structural, ambiguity, such as word-
sense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is
possible to cast a number of other useful problems as part-of-speech tagging problems,
such as letter-to-sound translation (Huang, Son-Bell, and Baggett 1994) and building
pronunciation networks for speech recognition. Recently, a method has been proposed
for using part-of-speech tagging techniques as a method for parsing with lexicalized
grammars (Joshi and Srinivas 1994).
When automated part-of-speech tagging was initially explored (Klein and Sim-
mons 1963; Harris 1962), people manually engineered rules for tagging, sometimes
with the aid of a corpus. As large corpora became available, it became clear that simple
Markov-model based stochastic taggers that were automatically trained could achieve
high rates of tagging accuracy (Jelinek 1985). Markov-model based taggers assign to a
sentence the tag sequence that maximizes Prob(word J tag)*Prob(tag I previous n tags).
These probabilities can be estimated directly from a manually tagged corpus.&apos; These
stochastic taggers have a number of advantages over the manually built taggers, in-
cluding obviating the need for laborious manual rule construction, and possibly cap-
turing useful information that may not have been noticed by the human engineer.
However, stochastic taggers have the disadvantage that linguistic information is cap-
tured only indirectly, in large tables of statistics. Almost all recent work in developing
automatically trained part-of-speech taggers has been on further exploring Markov-
model based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Meri-
aldo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993;
Schutze and Singer 1994).
</bodyText>
<subsectionHeader confidence="0.97189">
4.1 Transformation-based Error-driven Part-of-Speech Tagging
</subsectionHeader>
<bodyText confidence="0.999971">
Transformation-based part of speech tagging works as follows.&apos; The initial-state an-
notator assigns each word its most likely tag as indicated in the training corpus. The
method used for initially tagging unknown words will be described in a later section.
An ordered list of transformations is then learned, to improve tagging accuracy based
on contextual cues. These transformations alter the tagging of a word from X to Y iff
</bodyText>
<footnote confidence="0.835909333333333">
7 In Brill and Resnik (1994), we describe an approach to prepositional phrase attachment disambiguation
that obtains highly competitive performance compared to other corpus-based solutions to this problem.
This system was derived in under two hours from the transformation-based part of speech tagger
described in this paper.
8 One can also estimate these probabilities without a manually tagged corpus, using a hidden Markov
model. However, it appears to be the case that directly estimating probabilities from even a very small
manually tagged corpus gives better results than training a hidden Markov model on a large untagged
corpus (see Merialdo (1994)).
9 Earlier versions of this work were reported in Brill (1992, 1994).
</footnote>
<page confidence="0.966899">
552
</page>
<table confidence="0.35437525">
Brill Transformation-Based Error-Driven Learning
either:
1. The word was not seen in the training corpus OR
2. The word was seen tagged with Y at least once in the training corpus.
</table>
<bodyText confidence="0.964768888888889">
In taggers based on Markov models, the lexicon consists of probabilities of the
somewhat counterintuitive but proper form P(WORD I TAG). In the transformation-
based tagger, the lexicon is simply a list of all tags seen for a word in the training
corpus, with one tag labeled as the most likely. Below we show a lexical entry for the
word half in the transformation-based tagger.1°
half: CD DT JJ NN PDT RB VB
This entry lists the seven tags seen for half in the training corpus, with NN marked
as the most likely. Below are the lexical entries for half in a Markov model tagger,
extracted from the same corpus:
</bodyText>
<equation confidence="0.999945142857143">
P(half I CD) = 0.000066
P(half I DT) = 0.000757
P(half JJ) = 0.000092
P(half I NN) = 0.000702
P(half I PDT) = 0.039945
P(half I RB) = 0.000443
P(half I VB) = 0.000027
</equation>
<bodyText confidence="0.969723666666667">
It is difficult to make much sense of these entries in isolation; they have to be viewed
in the context of the many contextual probabilities.
First, we will describe a nonlexicalized version of the tagger, where transformation
templates do not make reference to specific words. In the nonlexicalized tagger, the
transformation templates we use are:
Change tag a to tag b when:
</bodyText>
<listItem confidence="0.998553">
1. The preceding (following) word is tagged z.
2. The word two before (after) is tagged z.
3. One of the two preceding (following) words is tagged z.
4. One of the three preceding (following) words is tagged z.
5. The preceding word is tagged z and the following word is tagged w.
6. The preceding (following) word is tagged z and the word two before
(after) is tagged w.
</listItem>
<bodyText confidence="0.9933">
where a, b, z and w are variables over the set of parts of speech.
To learn a transformation, the learner, in essence, tries out every possible trans-
formation,&amp;quot; and counts the number of tagging errors after each one is applied. After
</bodyText>
<page confidence="0.673582333333333">
10 A description of the part-of-speech tags is provided in Appendix A.
11 All possible instantiations of transformation templates.
553
</page>
<note confidence="0.42333">
Computational Linguistics Volume 21, Number 4
</note>
<listItem confidence="0.956519875">
1. apply initial-state annotator to corpus
2. while transformations can still be found do
3. for from_tag = tagi to tagn
4. for to_tag = tagi to tagn
5. for corpus_position = 1 to corpus_size
6. if (correct_tag(corpus_position) == to_tag
&amp;&amp; current_tag(corpus_position) == from_tag)
7. num_good_transformations(tag(corpus_position -1))++
8. else if (correct_tag(corpus_position) == from_tag
&amp;&amp; current_tag(corpus_position) == from_tag)
9. num_bad_transformations(tag(corpus_position-1 ))++
10. find maxT (num_good_transformations(T) - num_bad_transformations(T))
11. if this is the best-scoring rule found yet then store as best rule:
Change tag from from_tag to to_tag if previous tag is T
12. apply best rule to training corpus
13. append best rule to ordered list of transformations
</listItem>
<figureCaption confidence="0.4691705">
Figure 3
Pseudocode for learning transformations.
</figureCaption>
<bodyText confidence="0.998077666666667">
all possible transformations have been tried, the transformation that resulted in the
greatest error reduction is chosen. Learning stops when no transformations can be
found whose application reduces errors beyond some prespecified threshold.
In the experiments described below, processing was done left to right. For each
transformation application, all triggering environments are first found in the corpus,
and then the transformation triggered by each triggering environment is carried out.
The search is data-driven, so only a very small percentage of possible transfor-
mations really need be examined. In figure 3, we give pseudocode for the learning
algorithm in the case where there is only one transformation template:
</bodyText>
<subsubsectionHeader confidence="0.68505">
Change the tag from X to Y if the previous tag is Z.
</subsubsectionHeader>
<bodyText confidence="0.9637455">
In each learning iteration, the entire training corpus is examined once for every pair
of tags X and Y, finding the best transformation whose rewrite changes tag X to tag Y.
For every word in the corpus whose environment matches the triggering environment,
if the word has tag X and X is the correct tag, then making this transformation will
result in an additional tagging error, so we increment the number of errors caused
when making the transformation given the part-of-speech tag of the previous word
(lines 8 and 9). If X is the current tag and Y is the correct tag, then the transformation
will result in one less error, so we increment the number of improvements caused
when making the transformation given the part-of-speech tag of the previous word
(lines 6 and 7).
In certain cases, a significant increase in speed for training the transformation-
based tagger can be obtained by indexing in the corpus where different transformations
can and do apply. For a description of a fast index-based training algorithm, see
Ramshaw and Marcus (1994).
In figure 4, we list the first twenty transformations learned from training on the
Penn Treebank Wall Street Journal Corpus (Marcus, Santorini, and Marcinkiewicz
1993).12 The first transformation states that a noun should be changed to a verb if
12 Version 0.5 of the Penn Treebank was used in all experiments reported in this paper.
</bodyText>
<page confidence="0.947703">
554
</page>
<table confidence="0.95751472">
Brill Transformation-Based Error-Driven Learning
Change Tag
# From To Condition
1 NN VB Previous tag is TO
2 VBP VB One of the previous three tags is MD
3 NN VB One of the previous two tags is MD
4 VB NN One of the previous two tags is DT
5 VBD VBN One of the previous three tags is VBZ
6 VBN VBD Previous tag is PRP
7 VBN VBD Previous tag is NNP
8 VBD VBN Previous tag is VBD
9 VBP VB Previous tag is TO
10 POS VBZ Previous tag is PRP
11 VB VBP Previous tag is NNS
12 VBD VBN One of previous three tags is VBP
13 IN WDT One of next two tags is VB
14 VBD VBN One of previous two tags is VB
15 VB VBP Previous tag is PRP
16 IN WDT Next tag is VBZ
17 IN DT Next tag is NN
18 JJ NNP Next tag is NNP
19 IN WDT Next tag is VBD
20 JJR RBR Next tag is JJ
Figure 4
The first 20 nonlexicalized transformations.
</table>
<bodyText confidence="0.999777">
the previous tag is TO, as in: to/TO conflictINNVB with. The second transforma-
tion fixes a tagging such as: might/MD vanishIVBP—*VB. The third fixes might/MD not
reply/NN—VB. The tenth transformation is for the token &apos;s, which is a separate token
in the Penn Treebank. &apos;s is most frequently used as a possessive ending, but after a
personal pronoun, it is a verb (John &apos;s, compared to he &apos;s). The transformations chang-
ing IN to WDT are for tagging the word that, to determine in which environments that
is being used as a synonym of which.
</bodyText>
<subsectionHeader confidence="0.587824">
4.2 Lexicalizing the Tagger
</subsectionHeader>
<bodyText confidence="0.9998032">
In general, no relationships between words have been directly encoded in stochas-
tic n-gram taggers.&apos; In the Markov model typically used for stochastic tagging, state
transition probabilities (P(Tag, Tag,_i .Tagi_,,)) express the likelihood of a tag im-
mediately following n other tags, and emit probabilities (P(Wordi I Tag,)) express the
likelihood of a word, given a tag. Many useful relationships, such as that between a
word and the previous word, or between a tag and the following word, are not di-
rectly captured by Markov-model based taggers. The same is true of the nonlexicalized
transformation-based tagger, where transformation templates do not make reference
to words.
To remedy this problem, we extend the transformation-based tagger by adding
</bodyText>
<footnote confidence="0.6997725">
13 In Kupiec (1992), a limited amount of lexicalization is introduced by having a stochastic tagger with
word states for the 100 most frequent words in the corpus.
</footnote>
<page confidence="0.993552">
555
</page>
<note confidence="0.560403">
Computational Linguistics Volume 21, Number 4
</note>
<bodyText confidence="0.763881666666667">
contextual transformations that can make reference to words as well as part-of-speech
tags. The transformation templates we add are:
Change tag a to tag b when:
</bodyText>
<listItem confidence="0.98865225">
1. The preceding (following) word is w.
2. The word two before (after) is w.
3. One of the two preceding (following) words is w.
4. The current word is w and the preceding (following) word is x.
5. The current word is w and the preceding (following) word is tagged z.
6. The current word is w.
7. The preceding (following) word is w and the preceding (following) tag is
t.
</listItem>
<bodyText confidence="0.958862857142857">
8. The current word is w, the preceding (following) word is w2 and the
preceding (following) tag is t.
where w and x are variables over all words in the training corpus, and z
and t are variables over all parts of speech.
Below we list two lexicalized transformations that were learned, training once
again on the Wall Street Journal.
Change the tag:
</bodyText>
<listItem confidence="0.999121">
(12) From IN to RB if the word two positions to the right is as.
(16) From VBP to VB if one of the previous two words is n&apos;t.14
</listItem>
<bodyText confidence="0.999506">
The Penn Treebank tagging style manual specifies that in the collocation as ...as,
the first as is tagged as an adverb and the second is tagged as a preposition. Since as is
most frequently tagged as a preposition in the training corpus, the initial-state tagger
will mistag the phrase as tall as as:
</bodyText>
<equation confidence="0.767129">
as/IN tall/JJ as/IN
</equation>
<bodyText confidence="0.996334076923077">
The first lexicalized transformation corrects this mistagging. Note that a bigram tagger
trained on our training set would not correctly tag the first occurrence of as. Although
adverbs are more likely than prepositions to follow some verb form tags, the fact
that P(as I IN) is much greater than P(as I RB), and P(JJ I IN) is much greater than
P(JJ RB) lead to as being incorrectly tagged as a preposition by a stochastic tagger. A
trigram tagger will correctly tag this collocation in some instances, due to the fact that
P(IN I RB JJ) is greater than P(IN I IN JJ), but the outcome will be highly dependent
upon the context in which this collocation appears.
The second transformation arises from the fact that when a verb appears in a
context such as We do n&apos;t eat or We did n&apos;t usually drink, the verb is in base form. A
stochastic trigram tagger would have to capture this linguistic information indirectly
from frequency counts of all trigrams of the form shown in figure 5 (where a star can
match any part-of-speech tag) and from the fact that P(n&apos;t I RB) is fairly high.
</bodyText>
<footnote confidence="0.791026">
14 In the Penn Treebank, n&apos;t is treated as a separate token, so don&apos;t becomes dolVBP n&apos;t/RB.
</footnote>
<page confidence="0.995447">
556
</page>
<figure confidence="0.985744">
Brill Transformation-Based Error-Driven Learning
RB VBP
RB VB
RB VBP
RB VB
</figure>
<figureCaption confidence="0.766261">
Figure 5
Trigram Tagger Probability Tables.
</figureCaption>
<bodyText confidence="0.999953933333333">
In Weischedel et al. (1993), results are given when training and testing a Markov-
model based tagger on the Penn Treebank Tagged Wall Street journal Corpus. They cite
results making the closed vocabulary assumption that all possible tags for all words in
the test set are known. When training contextual probabilities on one million words,
an accuracy of 96.7% was achieved. Accuracy dropped to 96.3% when contextual prob-
abilities were trained on 64,000 words. We trained the transformation-based tagger on
the same corpus, making the same closed-vocabulary assumption.&apos; When training
contextual rules on 600,000 words, an accuracy of 97.2% was achieved on a separate
150,000 word test set. When the training set was reduced to 64,000 words, accuracy
dropped to 96.7%. The transformation-based learner achieved better performance, de-
spite the fact that contextual information was captured in a small number of simple
nonstochastic rules, as opposed to 10,000 contextual probabilities that were learned
by the stochastic tagger. These results are summarized in table 1. When training on
600,000 words, a total of 447 transformations were learned. However, transformations
toward the end of the list contribute very little to accuracy: applying only the first 200
learned transformations to the test set achieves an accuracy of 97.0%; applying the first
100 gives an accuracy of 96.8%. To match the 96.7% accuracy achieved by the stochas-
tic tagger when it was trained on one million words, only the first 82 transformations
are needed.
To see whether lexicalized transformations were contributing to the transformation-
based tagger accuracy rate, we first trained the tagger using the nonlexical transfor-
mation template subset, then ran exactly the same test. Accuracy of that tagger was
97.0%. Adding lexicalized transformations resulted in a 6.7% decrease in the error rate
(see table 1).16
We found it a bit surprising that the addition of lexicalized transformations did
not result in a much greater improvement in performance. When transformations are
allowed to make reference to words and word pairs, some relevant information is
probably missed due to sparse data. We are currently exploring the possibility of
incorporating word classes into the rule-based learner, in hopes of overcoming this
problem. The idea is quite simple. Given any source of word class information, such
</bodyText>
<footnote confidence="0.858351222222222">
15 In both Weischedel et al. (1993) and here, the test set was incorporated into the lexicon, but was not
used in learning contextual information. Testing with no unknown words might seem like an
unrealistic test. We have done so for three reasons: (1) to allow for a comparison with previously
quoted results, (2) to isolate known word accuracy from unknown word accuracy and (3) in some
systems, such as a closed vocabulary speech recognition system, the assumption that all words are
known is valid. (We show results when unknown words are included later in the paper.)
16 The training we did here was slightly suboptimal, in that we used the contextual rules learned with
unknown words (described in the next section), and filled in the dictionary, rather than training on a
corpus without unknown words.
</footnote>
<page confidence="0.989127">
557
</page>
<note confidence="0.554062">
Computational Linguistics Volume 21, Number 4
</note>
<tableCaption confidence="0.997764">
Table 1
</tableCaption>
<table confidence="0.991175416666667">
Comparison of Tagging Accuracy With No Unknown Words
Method Training # of Rules Acc.
Corpus or Context. (%)
Size (Words) Probs.
Stochastic 64 K 6,170 96.3
Stochastic 1 Million 10,000 96.7
Rule-Based 64 K 215 96.7
With Lex. Rules
Rule-Based 600 K 447 97.2
With Lex. Rules
Rule-Based 600 K 378 97.0
w/o Lex. Rules
</table>
<bodyText confidence="0.938071">
as WordNet (Miller 1990), the learner is extended such that a rule is allowed to make
reference to parts of speech, words, and word classes, allowing for rules such as
</bodyText>
<subsubsectionHeader confidence="0.718132">
Change the tag from X to Y if the following word belongs to word class Z.
</subsubsectionHeader>
<bodyText confidence="0.9998805">
This approach has already been successfully applied to a system for prepositional
phrase attachment disambiguation (Brill and Resnik 1994).
</bodyText>
<subsectionHeader confidence="0.99987">
4.3 Tagging Unknown Words
</subsectionHeader>
<bodyText confidence="0.970178166666667">
So far, we have not addressed the problem of unknown words. As stated above, the
initial-state annotator for tagging assigns all words their most likely tag, as indicated
in a training corpus. Below we show how a transformation-based approach can be
taken for tagging unknown words, by automatically learning cues to predict the most
likely tag for words not seen in the training corpus. If the most likely tag for unknown
words can be assigned with high accuracy, then the contextual rules can be used to
improve accuracy, as described above.
In the transformation-based unknown-word tagger, the initial-state annotator naively
assumes the most likely tag for an unknown word is &amp;quot;proper noun&amp;quot; if the word is
capitalized and &amp;quot;common noun&amp;quot; otherwise.&apos;
Below, we list the set of allowable transformations.
Change the tag of an unknown word (from X) to Y if:
</bodyText>
<listItem confidence="0.991338428571429">
1. Deleting the prefix (suffix) x, xl &lt;4, results in a word (x is any string of
length 1 to 4).
2. The first (last) (1,2,3,4) characters of the word are x.
3. Adding the character string x as a prefix (suffix) results in a word
(ixl &lt;4).
4. Word w ever appears immediately to the left (right) of the word.
5. Character z appears in the word.
</listItem>
<bodyText confidence="0.950050333333333">
17 If we change the tagger to tag all unknown words as common nouns, then a number of rules are
learned of the form: change tag to proper noun if the prefix is &amp;quot;E&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, etc., since the learner is
not provided with the concept of upper case in its set of transformation templates.
</bodyText>
<page confidence="0.994794">
558
</page>
<table confidence="0.997428869565217">
Brill Transformation-Based Error-Driven Learning
Change Tag
# From To Condition
1 NN NNS Has suffix -s
2 NN CD Has character.
3 NN JJ Has character -
4 NN VBN Has suffix -ed
5 NN VBG Has suffix -ing
6 ?? RB Has suffix -ly
7 ?? JJ Adding suffix -ly results in a word.
8 NN CD The word $ can appear to the left.
9 NN JJ Has suffix -al
10 NN VB The word would can appear to the left.
11 NN CD Has character 0
12 NN JJ The word be can appear to the left.
13 NNS JJ Has suffix -us
14 NNS VBZ The word it can appear to the left.
15 NN JJ Has suffix -ble
16 NN JJ Has suffix -ic
17 NN CD Has character 1
18 NNS NN Has suffix -ss
19 ?? JJ Deleting the prefix un- results in a word
20 NN JJ Has suffix -ive
</table>
<figureCaption confidence="0.753345">
Figure 6
</figureCaption>
<bodyText confidence="0.9716291">
The first 20 transformations for unknown words.
An unannotated text can be used to check the conditions in all of the above trans-
formation templates. Annotated text is necessary in training to measure the effect of
transformations on tagging accuracy. Since the goal is to label each lexical entry for
new words as accurately as possible, accuracy is measured on a per type and not a
per token basis.
Figure 6 shows the first 20 transformations learned for tagging unknown words in
the Wall Street Journal corpus. As an example of how rules can correct errors generated
by prior rules, note that applying the first transformation will result in the mistagging
of the word actress. The 18th learned rule fixes this problem. This rule states:
</bodyText>
<subsectionHeader confidence="0.976039">
Change a tag from plural common noun to singular common noun if the word has
</subsectionHeader>
<bodyText confidence="0.9955026">
suffix ss.
Keep in mind that no specific affixes are prespecified. A transformation can make
reference to any string of characters up to a bounded length. So while the first rule
specifies the English suffix &amp;quot;s&amp;quot;, the rule learner was not constrained from considering
such nonsensical rules as:
</bodyText>
<subsectionHeader confidence="0.546781">
Change a tag to adjective if the word has suffix &amp;quot;xhqr&amp;quot;.
</subsectionHeader>
<bodyText confidence="0.947929">
Also, absolutely no English-specific information (such as an affix list) need be
prespecified in the learner.&amp;quot;
</bodyText>
<page confidence="0.8039345">
18 This learner has also been applied to tagging Old English. See Brill (1993b). Although the
559
</page>
<figure confidence="0.94107775">
Computational Linguistics Volume 21, Number 4
Test Set Accuracy
0 100 200 300 400
Transformation Number
</figure>
<figureCaption confidence="0.9581065">
Figure 7
Accuracy vs. Transformation Number
</figureCaption>
<bodyText confidence="0.997740096774194">
We then ran the following experiment using 1.1 million words of the Penn Tree-
bank Tagged Wall Street Journal Corpus. Of these, 950,000 words were used for training
and 150,000 words were used for testing. Annotations of the test corpus were not used
in any way to train the system. From the 950,000 word training corpus, 350,000 words
were used to learn rules for tagging unknown words, and 600,000 words were used
to learn contextual rules; 243 rules were learned for tagging unknown words, and 447
contextual tagging rules were learned. Unknown word accuracy on the test corpus was
82.2%, and overall tagging accuracy on the test corpus was 96.6%. To our knowledge,
this is the highest overall tagging accuracy ever quoted on the Penn Treebank Corpus
when making the open vocabulary assumption. Using the tagger without lexicalized
rules, an overall accuracy of 96.3% and an unknown word accuracy of 82.0% is ob-
tained. A graph of accuracy as a function of transformation number on the test set for
lexicalized rules is shown in figure 7. Before applying any transformations, test set ac-
curacy is 92.4%, so the transformations reduce the error rate by 50% over the baseline.
The high baseline accuracy is somewhat misleading, as this includes the tagging of
unambiguous words. Baseline accuracy when the words that are unambiguous in our
lexicon are not considered is 86.4%. However, it is difficult to compare taggers using
this figure, as the accuracy of the system depends on the particular lexicon used. For
instance, in our training set the word the was tagged with a number of different tags,
and so according to our lexicon the is ambiguous. If we instead used a lexicon where
the is listed unambiguously as a determiner, the baseline accuracy would be 84.6%.
For tagging unknown words, each word is initially assigned a part-of-speech tag
based on word and word-distribution features. Then, the tag may be changed based
on contextual cues, via contextual transformations that are applied to the entire cor-
pus, both known and unknown-words. When the contextual rule learner learns trans-
formations, it does so in an attempt to maximize overall tagging accuracy, and not
unknown-word tagging accuracy. Unknown words account for only a small percent-
age of the corpus in our experiments, typically two to three percent. Since the distribu-
tional behavior of unknown words is quite different from that of known words, and
transformations are not English-specific, the set of transformation templates would have to be extended
to process languages with dramatically different morphology.
</bodyText>
<page confidence="0.98935">
560
</page>
<table confidence="0.517436">
Brill Transformation-Based Error-Driven Learning
</table>
<tableCaption confidence="0.990968">
Table 2
</tableCaption>
<table confidence="0.9170414">
Tagging Accuracy on Different Corpora
Corpus Accuracy
Penn WSJ 96.6%
Penn Brown 96.3%
Orig Brown 96.5%
</table>
<bodyText confidence="0.998799363636364">
since a transformation that does not increase unknown-word tagging accuracy can
still be beneficial to overall tagging accuracy, the contextual transformations learned
are not optimal in the sense of leading to the highest tagging accuracy on unknown
words. Better unknown-word accuracy may be possible by training and using two
sets of contextual rules, one maximizing known-word accuracy and the other maxi-
mizing unknown-word accuracy, and then applying the appropriate transformations
to a word when tagging, depending upon whether the word appears in the lexicon.
We are currently experimenting with this idea.
In Weischedel et al. (1993), a statistical approach to tagging unknown words is
shown. In this approach, a number of suffixes and important features are prespecified.
Then, for unknown words:
</bodyText>
<equation confidence="0.85413">
p(W I T) = p(unknown word I T) * p(Capitalize-feature I T) * p(suffixes, hyphenation I T)
</equation>
<bodyText confidence="0.999986105263158">
Using this equation for unknown word emit probabilities within the stochastic tagger,
an accuracy of 85% was obtained on the Wall Street Journal corpus. This portion of
the stochastic model has over 1,000 parameters, with 108 possible unique emit proba-
bilities, as opposed to a small number of simple rules that are learned and used in the
rule-based approach. In addition, the transformation-based method learns specific cues
instead of requiring them to be prespecified, allowing for the possibility of uncover-
ing cues not apparent to the human language engineer. We have obtained comparable
performance on unknown words, while capturing the information in a much more
concise and perspicuous manner, and without prespecifying any information specific
to English or to a specific corpus.
In table 2, we show tagging results obtained on a number of different corpora, in
each case training on roughly 9.5 x 105 words total and testing on a separate test set
of 1.5-2 x 108 words. Accuracy is consistent across these corpora and tag sets.
In addition to obtaining high rates of accuracy and representing relevant linguistic
information in a small set of rules, the part-of-speech tagger can also be made to
run extremely fast. Roche and Schabes (1995) show a method for converting a list
of tagging transformations into a deterministic finite state transducer with one state
transition taken per word of input; the result is a transformation-based tagger whose
tagging speed is about ten times that of the fastest Markov-model tagger.
</bodyText>
<subsectionHeader confidence="0.999586">
4.4 K-Best Tags
</subsectionHeader>
<bodyText confidence="0.9999198">
There are certain circumstances where one is willing to relax the one-tag-per-word
requirement in order to increase the probability that the correct tag will be assigned to
each word. In DeMarcken (1990) and Weischedel et al. (1993), k-best tags are assigned
within a stochastic tagger by returning all tags within some threshold of probability
of being correct for a particular word.
</bodyText>
<page confidence="0.995069">
561
</page>
<note confidence="0.624056">
Computational Linguistics Volume 21, Number 4
</note>
<tableCaption confidence="0.992916">
Table 3
</tableCaption>
<table confidence="0.994337875">
Results from k-best tagging.
# of Rules Accuracy Avg. # of tags per word
0 96.5 1.00
50 96.9 1.02
100 97.4 1.04
150 97.9 1.10
200 98.4 1.19
250 99.1 1.50
</table>
<bodyText confidence="0.9990905">
We can modify the transformation-based tagger to return multiple tags for a word
by making a simple modification to the contextual transformations described above.
The initial-state annotator is the tagging output of the previously described one-best
transformation-based tagger. The allowable transformation templates are the same as
the contextual transformation templates listed above, but with the rewrite rule: change
tag X to tag Y modified to add tag X to tag Y or add tag X to word W. Instead of changing
the tagging of a word, transformations now add alternative taggings to a word.
When allowing more than one tag per word, there is a trade-off between accuracy
and the average number of tags for each word. Ideally, we would like to achieve as
large an increase in accuracy with as few extra tags as possible. Therefore, in training
we find transformations that maximize the function:
Number of corrected errors
Number of additional tags
In table 3, we present results from first using the one-tag-per-word transforma-
tion-based tagger described in the previous section and then applying the k-best tag
transformations. These transformations were learned from a separate 240,000 word
corpus. As a baseline, we did k-best tagging of a test corpus. Each known word in the
test corpus was tagged with all tags seen with that word in the training corpus and
the five most likely unknown-word tags were assigned to all words not seen in the
training corpus.&apos; This resulted in an accuracy of 99.0%, with an average of 2.28 tags
per word. The transformation-based tagger obtained the same accuracy with 1.43 tags
per word, one third the number of additional tags as the baseline tagger.&apos;
</bodyText>
<sectionHeader confidence="0.996328" genericHeader="method">
5. Conclusions
</sectionHeader>
<bodyText confidence="0.998812">
In this paper, we have described a new transformation-based approach to corpus-based
learning. We have given details of how this approach has been applied to part-of-
speech tagging and have demonstrated that the transformation-based approach obtains
</bodyText>
<footnote confidence="0.377537333333333">
19 Thanks to Fred Jelinek and Fernando Pereira for suggesting this baseline experiment.
20 Unfortunately, it is difficult to find results to compare these k-best tag results to. In DeMarcken (1990),
the test set is included in the training set, and so it is difficult to know how this system would do on
fresh text. In Weischedel et al. (1993), a k-best tag experiment was run on the Wall Street Journal
corpus. They quote the average number of tags per word for various threshold settings, but do not
provide accuracy results.
</footnote>
<page confidence="0.970896">
562
</page>
<note confidence="0.34732">
Brill Transformation-Based Error-Driven Learning
</note>
<bodyText confidence="0.998738222222222">
competitive performance with stochastic taggers on tagging both unknown and known
words. The transformation-based tagger captures linguistic information in a small
number of simple nonstochastic rules, as opposed to large numbers of lexical and
contextual probabilities. This learning approach has also been applied to a number
of other tasks, including prepositional phrase attachment disambiguation (Brill and
Resnik 1994), bracketing text (Brill 1993a) and labeling nonterminal nodes (Brill 1993c).
Recently, we have begun to explore the possibility of extending these techniques to
other problems, including learning pronunciation networks for speech recognition and
learning mappings between syntactic and semantic representations.
</bodyText>
<sectionHeader confidence="0.805644" genericHeader="method">
Appendix A: Penn Treebank Part-of-Speech Tags (Excluding Punctuation)
</sectionHeader>
<table confidence="0.998748444444444">
CC Coordinating conjunction
CD Cardinal number
DT Determiner
EX Existential &amp;quot;there&amp;quot;
FW Foreign word
IN Preposition or subordinating conjunction
JJ Adjective
ER Adjective, comparative
JJS Adjective, superlative
LS List item marker
MD Modal
NN Noun, singular or mass
NNS Noun, plural
NNP Proper noun, singular
NNPS Proper noun, plural
PDT Predeterminer
POS Possessive ending
PP Personal pronoun
PP$ Possessive pronoun
RB Adverb
RBR Adverb, comparative
RBS Adverb, superlative
RP Particle
SYM Symbol
TO &amp;quot;to&amp;quot;
UH Interjection
VB Verb, base form
VBD Verb, past tense
VBG Verb, gerund or present participle
VBN Verb, past participle
VBP Verb, non-3rd person singular present
VBZ Verb, 3rd person singular present
WDT Wh-determiner
WP Wh-pronoun
WP$ Possessive wh-pronoun
WRB Wh-adverb
</table>
<page confidence="0.900428">
563
</page>
<note confidence="0.709401">
Computational Linguistics Volume 21, Number 4
</note>
<sectionHeader confidence="0.960917" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.952844454545454">
This work was funded in part by NSF grant
IRI-9502312. In addition, this work was
done in part while the author was in the
Spoken Language Systems Group at
Massachusetts Institute of Technology
under ARPA grant N00014-89+1332, and
by DARPA/AFOSR grant AFOSR-90-0066 at
the University of Pennsylvania. Thanks to
Mitch Marcus, Mark Villain, and the
anonymous reviewers for many useful
comments on earlier drafts of this paper.
</bodyText>
<sectionHeader confidence="0.992375" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999653043478261">
Black, Ezra; Jelinek, Fred; Lafferty John;
Magerman, David; Mercer, Robert; and
Roukos, Salim (1993). &amp;quot;Towards
history-based grammars: Using richer
models for probabilistic parsing.&amp;quot; In
Proceedings, 31st Annual Meeting of the
Association for Computational Linguistics.
Columbus, OH.
Black, Ezra; Jelinek, Fred; Lafferty John;
Mercer, Robert, and Roukos, Salim (1992).
&amp;quot;Decision tree models applied to the
labeling of text with parts-of-speech.&amp;quot; In
Darpa Workshop on Speech and Natural
Language. Harriman, NY.
Breiman, Leo; Friedman, Jerome; Olshen,
Richard; and Stone, Charles (1984).
Classification and regression trees.
Wadsworth and Brooks.
Brill, Eric (1992). &amp;quot;A simple rule-based part
of speech tagger.&amp;quot; In Proceedings, Third
Conference on Applied Natural Language
Processing, ACL, Trento, Italy.
Brill, Eric (1993a). &amp;quot;Automatic grammar
induction and parsing free text: A
transformation-based approach.&amp;quot; In
Proceedings, 31st Meeting of the Association of
Computational Linguistics, Columbus, OH.
Brill, Eric (1993b). A Corpus-Based Approach to
Language Learning. Doctoral dissertation,
Department of Computer and Information
Science, University of Pennsylvania.
Brill, Eric (1993c). &amp;quot;Transformation-based
error-driven parsing.&amp;quot; In Proceedings, Third
International Workshop on Parsing
Technologies, Tilburg, The Netherlands.
Brill, Eric (1994). &amp;quot;Some advances in
rule-based part of speech tagging.&amp;quot; In
Proceedings, Twelfth National Conference on
Artificial Intelligence (AAAI-94), Seattle,
WA.
Brill, Eric and Resnik, Philip (1994). &amp;quot;A
transformation-based approach to
prepositional phrase attachment
disambiguation.&amp;quot; In Proceedings, Fifteenth
International Conference on Computational
Linguistics (COLING-1994), Kyoto, Japan.
Brown, Peter; Cocke, John; Della Pietra,
Stephen; Della Pietra, Vincent; Jelinek,
Fred; Lafferty, John; Mercer, Robert; and
Roossin, Paul (1990). &amp;quot;A statistical
approach to machine translation.&amp;quot;
Computational Linguistics, 16(2).
Brown, Peter; Lai, Jennifer; and Mercer,
Robert (1991). &amp;quot;Word-sense
disambiguation using statistical
methods.&amp;quot; In Proceedings, 29th Annual
Meeting of the Association for Computational
Linguistics, Berkeley, CA
Bruce, Rebecca and Wiebe, Janyce (1994).
&amp;quot;Word-sense disambiguation using
decomposable models.&amp;quot; In Proceedings,
32nd Annual Meeting of the Association for
Computational Linguistics, Las Cruces, NM
Charniak, Eugene; Hendrickson, Curtis;
Jacobson, Neil; and Perkowitz, Michael
(1993). &amp;quot;Equations for part of speech
tagging.&amp;quot; In Proceedings, Conference of the
American Association for Artificial
Intelligence (AAAI-93), Washington, DC.
Church, Kenneth (1988). &amp;quot;A stochastic parts
program and noun phrase parser for
unrestricted text.&amp;quot; In Proceedings, Second
Conference on Applied Natural Language
Processing, ACL, Austin, TX.
Cutting, Doug; Kupiec, Julian; Pedersen,
Jan; and Sibun, Penelope (1992). &amp;quot;A
practical part-of-speech tagger.&amp;quot; In
Proceedings, Third Conference on Applied
Natural Language Processing, ACL, Trento,
Italy.
DeMarcken, Carl (1990). &amp;quot;Parsing the lob
corpus.&amp;quot; In Proceedings, 1990 Conference of
the Association for Computational Linguistics,
Pittsburgh, PA.
Derose, Stephen (1988). &amp;quot;Grammatical
category disambiguation by statistical
optimization.&amp;quot; Computational Linguistics,
14.
Francis, Winthrop Nelson and Kucera,
Henry (1982). Frequency analysis of English
usage: Lexicon and grammar. Houghton
Mifflin, Boston.
</reference>
<page confidence="0.973265">
564
</page>
<reference confidence="0.992933327102804">
Brill Transformation-Based Error-Driven Learning
Fujisaki, Tetsu; Jelinek, Fred; Cocke, John;
and Black, Ezra (1989). &amp;quot;Probabilistic
parsing method for sentence
disambiguation.&amp;quot; In Proceedings,
International Workshop on Parsing
Technologies, Carnegie Mellon University,
Pittsburgh, PA.
Gale, William and Church, Kenneth (1991).
&amp;quot;A program for aligning sentences in
bilingual corpora.&amp;quot; In Proceedings, 29th
Annual Meeting of the Association for
Computational Linguistics, Berkeley, CA.
Gale, William; Church, Kenneth; and
Yarowsky, David (1992). &amp;quot;A method for
disambiguating word senses in a large
corpus.&amp;quot; Computers and the Humanities.
Leech, Geoffrey; Garside, Roger; and
Bryant, Michael (1994). &amp;quot;Claws4: The
tagging of the British National Corpus.&amp;quot;
In Proceedings, 15th International Conference
on Computational Linguistics, Kyoto, Japan.
Harris, Zellig (1962). String Analysis of
Language Structure. Mouton and Co., The
Hague.
Hindle, Donald (1989). &amp;quot;Acquiring
disambiguation rules from text.&amp;quot; In
Proceedings, 27th Annual Meeting of the
Association for Computational Linguistics,
Vancouver, BC.
Hindle, D. and Rooth, M. (1993). &amp;quot;Structural
ambiguity and lexical relations.&amp;quot;
Computational Linguistics, 19(1):103-120.
Huang, Caroline; Son-Bell, Mark; and
Baggett, David (1994). &amp;quot;Generation of
pronunciations from orthographies using
transformation-based error-driven
learning.&amp;quot; In International Conference on
Speech and Language Processing (ICSLP),
Yokohama, Japan.
Jelinek, Fred (1985). Self-Organized Language
Modelling for Speech Recognition. Dordrecht.
In Impact of Processing Techniques on
Communication, J. Skwirzinski, ed.
Joshi, Aravind and Srinivas, B. (1994).
&amp;quot;Disambiguation of super parts of speech
(or supertags): Almost parsing.&amp;quot; In
Proceedings, 15th International Conference on
Computational Linguistics, Kyoto, Japan.
Klein, Sheldon and Simmons, Robert (1963).
&amp;quot;A computational approach to
grammatical coding of English words.&amp;quot;
JACM, 10.
Kupiec, Julian (1992). &amp;quot;Robust
part-of-speech tagging using a hidden
Markov model.&amp;quot; Computer Speech and
Language, 6.
Marcus, Mitchell; Santorini, Beatrice; and
Marcinkiewicz, Maryann (1993).
&amp;quot;Building a large annotated corpus of
English: the Penn Treebank.&amp;quot;
Computational Linguistics, 19(2).
Merialdo, Bernard (1994). &amp;quot;Tagging English
text with a probabilistic model.&amp;quot;
Computational Linguistics.
Miller, George (1990). &amp;quot;Wordnet: an on-line
lexical database.&amp;quot; International Journal of
Lexicography, 3(4).
Quinlan, J. Ross (1986). &amp;quot;Induction of
decision trees.&amp;quot; Machine Learning,
1:81-106.
Quinlan, J. Ross and Rivest, Ronald (1989).
&amp;quot;Inferring decision trees using the
minimum description length principle.&amp;quot;
Information and Computation, 80.
Ramshaw, Lance and Marcus, Mitchell
(1994). &amp;quot;Exploring the statistical
derivation of transformational rule
sequences for part-of-speech tagging.&amp;quot; In
The Balancing Act: Proceedings of the ACL
Workshop on Combining Symbolic and
Statistical Approaches to Language, New
Mexico State University, July.
Roche, Emmanuel and Schabes, Yves (1995).
&amp;quot;Deterministic part of speech tagging
with finite state transducers.&amp;quot;
Computational Linguistics, 21(2), 227-253.
Schutze, Hinrich and Singer, Yoram (1994).
Part of speech tagging using a variable
memory Markov model. In Proceedings,
Association for Computational Linguistics,
Las Cruces, NM.
Sharman, Robert; Jelinek, Fred; and Mercer,
Robert (1990). &amp;quot;Generating a grammar for
statistical training.&amp;quot; In Proceedings, 1990
Darpa Speech and Natural Language
Workshop.
Weischedel, Ralph; Meteer, Marie; Schwartz,
Richard; Ramshaw, Lance; and Palmucci,
Jeff (1993). &amp;quot;Coping with ambiguity and
unknown words through probabilistic
models.&amp;quot; Computational Linguistics.
Yarowsky, David (1992). &amp;quot;Word-sense
disambiguation using statistical models of
Roget&apos;s categories trained on large
corpora.&amp;quot; In Proceedings of COLING-92,
pages 454-460, Nantes, France, July.
</reference>
<page confidence="0.998488">
565
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.614878">
<title confidence="0.9978135">Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging</title>
<author confidence="0.999406">Eric Brill</author>
<affiliation confidence="0.999099">The Johns Hopkins University</affiliation>
<abstract confidence="0.963539818181818">Recently, there has been a rebirth of empiricism in the field of natural language processing. Manual encoding of linguistic information is being challenged by automated corpus-based learning as a method of providing a natural language processing system with linguistic knowledge. Although corpus-based approaches have been successful in many different areas of natural language processing, it is often the case that these methods capture the linguistic information they are modelling indirectly in large opaque tables of statistics. This can make it difficult to analyze, understand and improve the ability of these approaches to model underlying linguistic behavior. In this paper, we will describe a simple rule-based approach to automated learning of linguistic knowledge. This approach has been shown for a number of tasks to capture information in a clearer and more direct fashion without a compromise in performance. We present a detailed case study of this learning method applied to part-of-speech tagging.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ezra Black</author>
<author>Fred Jelinek</author>
<author>Lafferty John</author>
<author>David Magerman</author>
<author>Robert Mercer</author>
<author>Salim Roukos</author>
</authors>
<title>Towards history-based grammars: Using richer models for probabilistic parsing.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, 31st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="1996" citStr="Black et al. 1993" startWordPosition="295" endWordPosition="298">tion bottleneck inhibiting the creation of robust and accurate natural language processing systems. A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora (Brown, Lai, and Mercer 1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994). An effort has recently been undertaken to create automated machine translation systems in which the linguistic information needed for translation is extracte</context>
</contexts>
<marker>Black, Jelinek, John, Magerman, Mercer, Roukos, 1993</marker>
<rawString>Black, Ezra; Jelinek, Fred; Lafferty John; Magerman, David; Mercer, Robert; and Roukos, Salim (1993). &amp;quot;Towards history-based grammars: Using richer models for probabilistic parsing.&amp;quot; In Proceedings, 31st Annual Meeting of the Association for Computational Linguistics. Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ezra Black</author>
<author>Fred Jelinek</author>
<author>Lafferty John</author>
<author>Robert Mercer</author>
<author>Salim Roukos</author>
</authors>
<title>Decision tree models applied to the labeling of text with parts-of-speech.&amp;quot;</title>
<date>1992</date>
<booktitle>In Darpa Workshop on Speech and Natural Language.</booktitle>
<location>Harriman, NY.</location>
<contexts>
<context position="22840" citStr="Black et al. 1992" startWordPosition="3609" endWordPosition="3612"> and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambigua</context>
</contexts>
<marker>Black, Jelinek, John, Mercer, Roukos, 1992</marker>
<rawString>Black, Ezra; Jelinek, Fred; Lafferty John; Mercer, Robert, and Roukos, Salim (1992). &amp;quot;Decision tree models applied to the labeling of text with parts-of-speech.&amp;quot; In Darpa Workshop on Speech and Natural Language. Harriman, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
<author>Jerome Friedman</author>
<author>Richard Olshen</author>
<author>Charles Stone</author>
</authors>
<title>Classification and regression trees.</title>
<date>1984</date>
<publisher>Wadsworth and Brooks.</publisher>
<contexts>
<context position="12827" citStr="Breiman et al. 1984" startWordPosition="1941" endWordPosition="1944">ntil the entire file has been processed for that one transformation, then regardless of the order of processing the output will be: ABBBBB, since the triggering environment of a transformation is always checked before that transformation is applied to any surrounding objects in the corpus. If the effect of a transformation is recorded immediately, then processing the string left to right would result in: ABABAB, whereas processing right to left would result in: ABBBBB. 3. A Comparison With Decision Trees The technique employed by the learner is somewhat similar to that used in decision trees (Breiman et al. 1984; Quinlan 1986; Quinlan and Rivest 1989). A decision tree is trained on a set of preclassified entities and outputs a set of questions that can be asked about an entity to determine its proper classification. Decision trees are built by finding the question whose resulting partition is the purest,2 splitting the training data according to that question, and then recursively reapplying this procedure on each resulting subset. We first show that the set of classifications that can be provided via decision trees is a proper subset of those that can be provided via transformation lists (an ordered</context>
<context position="22126" citStr="Breiman et al. (1984" startWordPosition="3493" endWordPosition="3496">ation-based learning can make the learned rules more readily interpretable than decision tree rules for increasing population purity.&apos; 4. Part of Speech Tagging: A Case Study in Transformation-Based Error-Driven Learning In this section we describe the practical application of transformation-based learning to part-of-speech tagging.&apos; Part-of-speech tagging is a good application to test the 3 The original tagged Brown Corpus (Francis and Kucera, 1982) makes this distinction; the Penn Treebank (Marcus, Santorini, and Marcinkiewicz, 1993) does not. 4 For a discussion of why this is the case, see Breiman et al. (1984, 94-98). 5 For a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g.,</context>
</contexts>
<marker>Breiman, Friedman, Olshen, Stone, 1984</marker>
<rawString>Breiman, Leo; Friedman, Jerome; Olshen, Richard; and Stone, Charles (1984). Classification and regression trees. Wadsworth and Brooks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings, Third Conference on Applied Natural Language Processing, ACL,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="1641" citStr="Brill 1992" startWordPosition="238" endWordPosition="239">ect fashion without a compromise in performance. We present a detailed case study of this learning method applied to part-of-speech tagging. 1. Introduction It has recently become clear that automatically extracting linguistic information from a sample text corpus can be an extremely powerful method of overcoming the linguistic knowledge acquisition bottleneck inhibiting the creation of robust and accurate natural language processing systems. A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in </context>
<context position="5740" citStr="Brill 1992" startWordPosition="857" endWordPosition="858">ample above. In a stochastic n-gram tagger, the information about words that follow modals would be hidden deeply in the thousands or tens of thousands of contextual probabilities (P(Tag, I Tagi_iTag1_2)) and the result of multiplying different combinations of these probabilities together. Below, we describe a new approach to corpus-based natural language processing, called transformation-based error-driven learning. This algorithm has been applied to a number of natural language problems, including part-of-speech tagging, prepositional phrase attachment disambiguation, and syntactic parsing (Brill 1992; Brill 1993a; Brill 1993b; Brill and Resnik 1994; Brill 1994). We have also recently begun exploring the use of this technique for letter-to-sound generation and for building pronunciation networks for speech recognition. In this approach, the learned linguistic information is represented in a concise and easily understood form. This property should make transformation-based learning a useful tool for further exploring linguistic modeling and attempting to discover ways of more tightly coupling the underlying linguistic systems and our approximating models. 544 Brill Transformation-Based Erro</context>
<context position="22821" citStr="Brill 1992" startWordPosition="3607" endWordPosition="3608"> see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase at</context>
<context position="26330" citStr="Brill (1992" startWordPosition="4125" endWordPosition="4126">obtains highly competitive performance compared to other corpus-based solutions to this problem. This system was derived in under two hours from the transformation-based part of speech tagger described in this paper. 8 One can also estimate these probabilities without a manually tagged corpus, using a hidden Markov model. However, it appears to be the case that directly estimating probabilities from even a very small manually tagged corpus gives better results than training a hidden Markov model on a large untagged corpus (see Merialdo (1994)). 9 Earlier versions of this work were reported in Brill (1992, 1994). 552 Brill Transformation-Based Error-Driven Learning either: 1. The word was not seen in the training corpus OR 2. The word was seen tagged with Y at least once in the training corpus. In taggers based on Markov models, the lexicon consists of probabilities of the somewhat counterintuitive but proper form P(WORD I TAG). In the transformationbased tagger, the lexicon is simply a list of all tags seen for a word in the training corpus, with one tag labeled as the most likely. Below we show a lexical entry for the word half in the transformation-based tagger.1° half: CD DT JJ NN PDT RB V</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>Brill, Eric (1992). &amp;quot;A simple rule-based part of speech tagger.&amp;quot; In Proceedings, Third Conference on Applied Natural Language Processing, ACL, Trento, Italy.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Brill</author>
</authors>
<title>Eric (1993a). &amp;quot;Automatic grammar induction and parsing free text: A transformation-based approach.&amp;quot;</title>
<booktitle>In Proceedings, 31st Meeting of the Association of Computational Linguistics,</booktitle>
<location>Columbus, OH.</location>
<marker>Brill, </marker>
<rawString>Brill, Eric (1993a). &amp;quot;Automatic grammar induction and parsing free text: A transformation-based approach.&amp;quot; In Proceedings, 31st Meeting of the Association of Computational Linguistics, Columbus, OH.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Brill</author>
</authors>
<title>Eric (1993b). A Corpus-Based Approach to Language Learning.</title>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<note>Doctoral dissertation,</note>
<marker>Brill, </marker>
<rawString>Brill, Eric (1993b). A Corpus-Based Approach to Language Learning. Doctoral dissertation, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Brill</author>
</authors>
<title>Eric (1993c). &amp;quot;Transformation-based error-driven parsing.&amp;quot;</title>
<booktitle>In Proceedings, Third International Workshop on Parsing Technologies,</booktitle>
<location>Tilburg, The Netherlands.</location>
<marker>Brill, </marker>
<rawString>Brill, Eric (1993c). &amp;quot;Transformation-based error-driven parsing.&amp;quot; In Proceedings, Third International Workshop on Parsing Technologies, Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Some advances in rule-based part of speech tagging.&amp;quot;</title>
<date>1994</date>
<booktitle>In Proceedings, Twelfth National Conference on Artificial Intelligence (AAAI-94),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="5802" citStr="Brill 1994" startWordPosition="867" endWordPosition="868">bout words that follow modals would be hidden deeply in the thousands or tens of thousands of contextual probabilities (P(Tag, I Tagi_iTag1_2)) and the result of multiplying different combinations of these probabilities together. Below, we describe a new approach to corpus-based natural language processing, called transformation-based error-driven learning. This algorithm has been applied to a number of natural language problems, including part-of-speech tagging, prepositional phrase attachment disambiguation, and syntactic parsing (Brill 1992; Brill 1993a; Brill 1993b; Brill and Resnik 1994; Brill 1994). We have also recently begun exploring the use of this technique for letter-to-sound generation and for building pronunciation networks for speech recognition. In this approach, the learned linguistic information is represented in a concise and easily understood form. This property should make transformation-based learning a useful tool for further exploring linguistic modeling and attempting to discover ways of more tightly coupling the underlying linguistic systems and our approximating models. 544 Brill Transformation-Based Error-Driven Learning UNANNOTATED TEXT V INITIAL STATE V ANNOTATED</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Brill, Eric (1994). &amp;quot;Some advances in rule-based part of speech tagging.&amp;quot; In Proceedings, Twelfth National Conference on Artificial Intelligence (AAAI-94), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Philip Resnik</author>
</authors>
<title>A transformation-based approach to prepositional phrase attachment disambiguation.&amp;quot;</title>
<date>1994</date>
<booktitle>In Proceedings, Fifteenth International Conference on Computational Linguistics (COLING-1994),</booktitle>
<location>Kyoto, Japan.</location>
<contexts>
<context position="5789" citStr="Brill and Resnik 1994" startWordPosition="863" endWordPosition="866">gger, the information about words that follow modals would be hidden deeply in the thousands or tens of thousands of contextual probabilities (P(Tag, I Tagi_iTag1_2)) and the result of multiplying different combinations of these probabilities together. Below, we describe a new approach to corpus-based natural language processing, called transformation-based error-driven learning. This algorithm has been applied to a number of natural language problems, including part-of-speech tagging, prepositional phrase attachment disambiguation, and syntactic parsing (Brill 1992; Brill 1993a; Brill 1993b; Brill and Resnik 1994; Brill 1994). We have also recently begun exploring the use of this technique for letter-to-sound generation and for building pronunciation networks for speech recognition. In this approach, the learned linguistic information is represented in a concise and easily understood form. This property should make transformation-based learning a useful tool for further exploring linguistic modeling and attempting to discover ways of more tightly coupling the underlying linguistic systems and our approximating models. 544 Brill Transformation-Based Error-Driven Learning UNANNOTATED TEXT V INITIAL STAT</context>
<context position="25638" citStr="Brill and Resnik (1994)" startWordPosition="4018" endWordPosition="4021">Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from X to Y iff 7 In Brill and Resnik (1994), we describe an approach to prepositional phrase attachment disambiguation that obtains highly competitive performance compared to other corpus-based solutions to this problem. This system was derived in under two hours from the transformation-based part of speech tagger described in this paper. 8 One can also estimate these probabilities without a manually tagged corpus, using a hidden Markov model. However, it appears to be the case that directly estimating probabilities from even a very small manually tagged corpus gives better results than training a hidden Markov model on a large untagge</context>
<context position="40384" citStr="Brill and Resnik 1994" startWordPosition="6510" endWordPosition="6513"> of Rules Acc. Corpus or Context. (%) Size (Words) Probs. Stochastic 64 K 6,170 96.3 Stochastic 1 Million 10,000 96.7 Rule-Based 64 K 215 96.7 With Lex. Rules Rule-Based 600 K 447 97.2 With Lex. Rules Rule-Based 600 K 378 97.0 w/o Lex. Rules as WordNet (Miller 1990), the learner is extended such that a rule is allowed to make reference to parts of speech, words, and word classes, allowing for rules such as Change the tag from X to Y if the following word belongs to word class Z. This approach has already been successfully applied to a system for prepositional phrase attachment disambiguation (Brill and Resnik 1994). 4.3 Tagging Unknown Words So far, we have not addressed the problem of unknown words. As stated above, the initial-state annotator for tagging assigns all words their most likely tag, as indicated in a training corpus. Below we show how a transformation-based approach can be taken for tagging unknown words, by automatically learning cues to predict the most likely tag for words not seen in the training corpus. If the most likely tag for unknown words can be assigned with high accuracy, then the contextual rules can be used to improve accuracy, as described above. In the transformation-based </context>
<context position="52891" citStr="Brill and Resnik 1994" startWordPosition="8596" endWordPosition="8599"> Wall Street Journal corpus. They quote the average number of tags per word for various threshold settings, but do not provide accuracy results. 562 Brill Transformation-Based Error-Driven Learning competitive performance with stochastic taggers on tagging both unknown and known words. The transformation-based tagger captures linguistic information in a small number of simple nonstochastic rules, as opposed to large numbers of lexical and contextual probabilities. This learning approach has also been applied to a number of other tasks, including prepositional phrase attachment disambiguation (Brill and Resnik 1994), bracketing text (Brill 1993a) and labeling nonterminal nodes (Brill 1993c). Recently, we have begun to explore the possibility of extending these techniques to other problems, including learning pronunciation networks for speech recognition and learning mappings between syntactic and semantic representations. Appendix A: Penn Treebank Part-of-Speech Tags (Excluding Punctuation) CC Coordinating conjunction CD Cardinal number DT Determiner EX Existential &amp;quot;there&amp;quot; FW Foreign word IN Preposition or subordinating conjunction JJ Adjective ER Adjective, comparative JJS Adjective, superlative LS List</context>
</contexts>
<marker>Brill, Resnik, 1994</marker>
<rawString>Brill, Eric and Resnik, Philip (1994). &amp;quot;A transformation-based approach to prepositional phrase attachment disambiguation.&amp;quot; In Proceedings, Fifteenth International Conference on Computational Linguistics (COLING-1994), Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Brown</author>
<author>John Cocke</author>
<author>Della Pietra</author>
<author>Della Pietra Stephen</author>
</authors>
<title>A statistical approach to machine translation.&amp;quot;</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<location>Vincent; Jelinek, Fred; Lafferty, John; Mercer, Robert; and Roossin, Paul</location>
<contexts>
<context position="2652" citStr="Brown et al. 1990" startWordPosition="394" endWordPosition="397"> of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora (Brown, Lai, and Mercer 1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994). An effort has recently been undertaken to create automated machine translation systems in which the linguistic information needed for translation is extracted automatically from aligned corpora (Brown et al. 1990). These are just a few of the many recent applications of corpus-based techniques in natural language processing. * Department of Computer Science, Baltimore, MD 21218-2694. E-mail: brill@cs.jhu.edu. © 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 4 Along with great research advances, the infrastructure is in place for this line of research to grow even stronger, with on-line corpora, the grist of the corpus-based natural language processing grindstone, getting bigger and better and becoming more readily available. There are a number of efforts worl</context>
</contexts>
<marker>Brown, Cocke, Pietra, Stephen, 1990</marker>
<rawString>Brown, Peter; Cocke, John; Della Pietra, Stephen; Della Pietra, Vincent; Jelinek, Fred; Lafferty, John; Mercer, Robert; and Roossin, Paul (1990). &amp;quot;A statistical approach to machine translation.&amp;quot; Computational Linguistics, 16(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Brown</author>
<author>Jennifer Lai</author>
<author>Robert Mercer</author>
</authors>
<title>Word-sense disambiguation using statistical methods.&amp;quot;</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Berkeley, CA</location>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>Brown, Peter; Lai, Jennifer; and Mercer, Robert (1991). &amp;quot;Word-sense disambiguation using statistical methods.&amp;quot; In Proceedings, 29th Annual Meeting of the Association for Computational Linguistics, Berkeley, CA</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Bruce</author>
<author>Janyce Wiebe</author>
</authors>
<title>Word-sense disambiguation using decomposable models.&amp;quot;</title>
<date>1994</date>
<booktitle>In Proceedings, 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Las Cruces, NM</location>
<contexts>
<context position="2437" citStr="Bruce and Wiebe 1994" startWordPosition="364" endWordPosition="367">sign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora (Brown, Lai, and Mercer 1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994). An effort has recently been undertaken to create automated machine translation systems in which the linguistic information needed for translation is extracted automatically from aligned corpora (Brown et al. 1990). These are just a few of the many recent applications of corpus-based techniques in natural language processing. * Department of Computer Science, Baltimore, MD 21218-2694. E-mail: brill@cs.jhu.edu. © 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 4 Along with great research advances, the infrastructure is in place for this line of resear</context>
</contexts>
<marker>Bruce, Wiebe, 1994</marker>
<rawString>Bruce, Rebecca and Wiebe, Janyce (1994). &amp;quot;Word-sense disambiguation using decomposable models.&amp;quot; In Proceedings, 32nd Annual Meeting of the Association for Computational Linguistics, Las Cruces, NM</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Curtis Hendrickson</author>
<author>Neil Jacobson</author>
<author>Michael Perkowitz</author>
</authors>
<title>Equations for part of speech tagging.&amp;quot;</title>
<date>1993</date>
<booktitle>In Proceedings, Conference of the American Association for Artificial Intelligence (AAAI-93),</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="22896" citStr="Charniak et al. 1993" startWordPosition="3619" endWordPosition="3622">erein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is possible to cast a number of other us</context>
<context position="25069" citStr="Charniak et al. 1993" startWordPosition="3930" endWordPosition="3933">umber of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from X to Y iff 7 In Brill and Resnik (1994), we describe an approach to pr</context>
</contexts>
<marker>Charniak, Hendrickson, Jacobson, Perkowitz, 1993</marker>
<rawString>Charniak, Eugene; Hendrickson, Curtis; Jacobson, Neil; and Perkowitz, Michael (1993). &amp;quot;Equations for part of speech tagging.&amp;quot; In Proceedings, Conference of the American Association for Artificial Intelligence (AAAI-93), Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted text.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, Second Conference on Applied Natural Language Processing,</booktitle>
<location>ACL, Austin, TX.</location>
<contexts>
<context position="1608" citStr="Church 1988" startWordPosition="232" endWordPosition="233">ormation in a clearer and more direct fashion without a compromise in performance. We present a detailed case study of this learning method applied to part-of-speech tagging. 1. Introduction It has recently become clear that automatically extracting linguistic information from a sample text corpus can be an extremely powerful method of overcoming the linguistic knowledge acquisition bottleneck inhibiting the creation of robust and accurate natural language processing systems. A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic</context>
<context position="22752" citStr="Church 1988" startWordPosition="3597" endWordPosition="3598"> a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, am</context>
<context position="24969" citStr="Church 1988" startWordPosition="3915" endWordPosition="3916">can be estimated directly from a manually tagged corpus.&apos; These stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alt</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Church, Kenneth (1988). &amp;quot;A stochastic parts program and noun phrase parser for unrestricted text.&amp;quot; In Proceedings, Second Conference on Applied Natural Language Processing, ACL, Austin, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Doug Cutting</author>
<author>Julian Kupiec</author>
<author>Jan Pedersen</author>
<author>Penelope Sibun</author>
</authors>
<title>A practical part-of-speech tagger.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings, Third Conference on Applied Natural Language Processing, ACL,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="1629" citStr="Cutting et al. 1992" startWordPosition="234" endWordPosition="237"> clearer and more direct fashion without a compromise in performance. We present a detailed case study of this learning method applied to part-of-speech tagging. 1. Introduction It has recently become clear that automatically extracting linguistic information from a sample text corpus can be an extremely powerful method of overcoming the linguistic knowledge acquisition bottleneck inhibiting the creation of robust and accurate natural language processing systems. A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge,</context>
<context position="22861" citStr="Cutting et al. 1992" startWordPosition="3613" endWordPosition="3616"> 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is po</context>
<context position="25034" citStr="Cutting et al. 1992" startWordPosition="3924" endWordPosition="3927"> These stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from X to Y iff 7 In Brill and Resnik (1</context>
</contexts>
<marker>Cutting, Kupiec, Pedersen, Sibun, 1992</marker>
<rawString>Cutting, Doug; Kupiec, Julian; Pedersen, Jan; and Sibun, Penelope (1992). &amp;quot;A practical part-of-speech tagger.&amp;quot; In Proceedings, Third Conference on Applied Natural Language Processing, ACL, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl DeMarcken</author>
</authors>
<title>Parsing the lob corpus.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, 1990 Conference of the Association for Computational Linguistics,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="22794" citStr="DeMarcken 1990" startWordPosition="3603" endWordPosition="3604"> these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation </context>
<context position="24998" citStr="DeMarcken 1990" startWordPosition="3919" endWordPosition="3920">from a manually tagged corpus.&apos; These stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from</context>
<context position="49537" citStr="DeMarcken (1990)" startWordPosition="8059" endWordPosition="8060"> a small set of rules, the part-of-speech tagger can also be made to run extremely fast. Roche and Schabes (1995) show a method for converting a list of tagging transformations into a deterministic finite state transducer with one state transition taken per word of input; the result is a transformation-based tagger whose tagging speed is about ten times that of the fastest Markov-model tagger. 4.4 K-Best Tags There are certain circumstances where one is willing to relax the one-tag-per-word requirement in order to increase the probability that the correct tag will be assigned to each word. In DeMarcken (1990) and Weischedel et al. (1993), k-best tags are assigned within a stochastic tagger by returning all tags within some threshold of probability of being correct for a particular word. 561 Computational Linguistics Volume 21, Number 4 Table 3 Results from k-best tagging. # of Rules Accuracy Avg. # of tags per word 0 96.5 1.00 50 96.9 1.02 100 97.4 1.04 150 97.9 1.10 200 98.4 1.19 250 99.1 1.50 We can modify the transformation-based tagger to return multiple tags for a word by making a simple modification to the contextual transformations described above. The initial-state annotator is the tagging</context>
<context position="52083" citStr="DeMarcken (1990)" startWordPosition="8475" endWordPosition="8476">word. The transformation-based tagger obtained the same accuracy with 1.43 tags per word, one third the number of additional tags as the baseline tagger.&apos; 5. Conclusions In this paper, we have described a new transformation-based approach to corpus-based learning. We have given details of how this approach has been applied to part-ofspeech tagging and have demonstrated that the transformation-based approach obtains 19 Thanks to Fred Jelinek and Fernando Pereira for suggesting this baseline experiment. 20 Unfortunately, it is difficult to find results to compare these k-best tag results to. In DeMarcken (1990), the test set is included in the training set, and so it is difficult to know how this system would do on fresh text. In Weischedel et al. (1993), a k-best tag experiment was run on the Wall Street Journal corpus. They quote the average number of tags per word for various threshold settings, but do not provide accuracy results. 562 Brill Transformation-Based Error-Driven Learning competitive performance with stochastic taggers on tagging both unknown and known words. The transformation-based tagger captures linguistic information in a small number of simple nonstochastic rules, as opposed to </context>
</contexts>
<marker>DeMarcken, 1990</marker>
<rawString>DeMarcken, Carl (1990). &amp;quot;Parsing the lob corpus.&amp;quot; In Proceedings, 1990 Conference of the Association for Computational Linguistics, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Derose</author>
</authors>
<title>Grammatical category disambiguation by statistical optimization.&amp;quot;</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<contexts>
<context position="22765" citStr="Derose 1988" startWordPosition="3599" endWordPosition="3600"> of other issues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such</context>
<context position="24982" citStr="Derose 1988" startWordPosition="3917" endWordPosition="3918">ted directly from a manually tagged corpus.&apos; These stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the taggin</context>
</contexts>
<marker>Derose, 1988</marker>
<rawString>Derose, Stephen (1988). &amp;quot;Grammatical category disambiguation by statistical optimization.&amp;quot; Computational Linguistics, 14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Winthrop Nelson Francis</author>
<author>Henry Kucera</author>
</authors>
<title>Frequency analysis of English usage: Lexicon and grammar.</title>
<date>1982</date>
<location>Houghton Mifflin, Boston.</location>
<contexts>
<context position="21960" citStr="Francis and Kucera, 1982" startWordPosition="3465" endWordPosition="3468">oor performance&apos; and some measure of node purity, such as entropy reduction, is used instead. The direct correlation between rules and performance improvement in transformation-based learning can make the learned rules more readily interpretable than decision tree rules for increasing population purity.&apos; 4. Part of Speech Tagging: A Case Study in Transformation-Based Error-Driven Learning In this section we describe the practical application of transformation-based learning to part-of-speech tagging.&apos; Part-of-speech tagging is a good application to test the 3 The original tagged Brown Corpus (Francis and Kucera, 1982) makes this distinction; the Penn Treebank (Marcus, Santorini, and Marcinkiewicz, 1993) does not. 4 For a discussion of why this is the case, see Breiman et al. (1984, 94-98). 5 For a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a </context>
</contexts>
<marker>Francis, Kucera, 1982</marker>
<rawString>Francis, Winthrop Nelson and Kucera, Henry (1982). Frequency analysis of English usage: Lexicon and grammar. Houghton Mifflin, Boston.</rawString>
</citation>
<citation valid="false">
<institution>Brill Transformation-Based Error-Driven Learning</institution>
<marker></marker>
<rawString>Brill Transformation-Based Error-Driven Learning</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsu Fujisaki</author>
<author>Fred Jelinek</author>
<author>John Cocke</author>
<author>Ezra Black</author>
</authors>
<title>Probabilistic parsing method for sentence disambiguation.&amp;quot;</title>
<date>1989</date>
<booktitle>In Proceedings, International Workshop on Parsing Technologies,</booktitle>
<institution>Mellon University,</institution>
<location>Carnegie</location>
<contexts>
<context position="1941" citStr="Fujisaki et al. 1989" startWordPosition="285" endWordPosition="288">ful method of overcoming the linguistic knowledge acquisition bottleneck inhibiting the creation of robust and accurate natural language processing systems. A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora (Brown, Lai, and Mercer 1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994). An effort has recently been undertaken to create automated machine translation systems in which the li</context>
</contexts>
<marker>Fujisaki, Jelinek, Cocke, Black, 1989</marker>
<rawString>Fujisaki, Tetsu; Jelinek, Fred; Cocke, John; and Black, Ezra (1989). &amp;quot;Probabilistic parsing method for sentence disambiguation.&amp;quot; In Proceedings, International Workshop on Parsing Technologies, Carnegie Mellon University, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Gale</author>
<author>Kenneth Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.&amp;quot;</title>
<date>1991</date>
<booktitle>In Proceedings, 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Berkeley, CA.</location>
<contexts>
<context position="3728" citStr="Gale and Church 1991" startWordPosition="549" endWordPosition="552">s-based natural language processing grindstone, getting bigger and better and becoming more readily available. There are a number of efforts worldwide to manually annotate large corpora with linguistic information, including parts of speech, phrase structure and predicate-argument structure (e.g., the Penn Treebank and the British National Corpus (Marcus, Santorini, and Marcinkiewicz 1993; Leech, Garside, and Bryant 1994)). A vast amount of on-line text is now available, and much more will become available in the future. Useful tools, such as large aligned corpora (e.g., the aligned Hansards (Gale and Church 1991)) and semantic word hierarchies (e.g., Wordnet (Miller 1990)), have also recently become available. Corpus-based methods are often able to succeed while ignoring the true complexities of language, banking on the fact that complex linguistic phenomena can often be indirectly observed through simple epiphenomena. For example, one could accurately assign a part-of-speech tag to the word race in (1-3) without any reference to phrase structure or constituent movement: One would only have to realize that, usually, a word one or two words to the right of a modal is a verb and not a noun. An exception</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>Gale, William and Church, Kenneth (1991). &amp;quot;A program for aligning sentences in bilingual corpora.&amp;quot; In Proceedings, 29th Annual Meeting of the Association for Computational Linguistics, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Gale</author>
<author>Kenneth Church</author>
<author>David Yarowsky</author>
</authors>
<title>A method for disambiguating word senses in a large corpus.&amp;quot; Computers and the Humanities.</title>
<date>1992</date>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale, William; Church, Kenneth; and Yarowsky, David (1992). &amp;quot;A method for disambiguating word senses in a large corpus.&amp;quot; Computers and the Humanities.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
<author>Roger Garside</author>
<author>Michael Bryant</author>
</authors>
<title>Claws4: The tagging of the British National Corpus.&amp;quot; In</title>
<date>1994</date>
<booktitle>Proceedings, 15th International Conference on Computational Linguistics, Kyoto,</booktitle>
<marker>Leech, Garside, Bryant, 1994</marker>
<rawString>Leech, Geoffrey; Garside, Roger; and Bryant, Michael (1994). &amp;quot;Claws4: The tagging of the British National Corpus.&amp;quot; In Proceedings, 15th International Conference on Computational Linguistics, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>String Analysis of Language Structure.</title>
<date>1962</date>
<journal>Mouton and Co., The Hague.</journal>
<contexts>
<context position="23934" citStr="Harris 1962" startWordPosition="3764" endWordPosition="3765">al, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is possible to cast a number of other useful problems as part-of-speech tagging problems, such as letter-to-sound translation (Huang, Son-Bell, and Baggett 1994) and building pronunciation networks for speech recognition. Recently, a method has been proposed for using part-of-speech tagging techniques as a method for parsing with lexicalized grammars (Joshi and Srinivas 1994). When automated part-of-speech tagging was initially explored (Klein and Simmons 1963; Harris 1962), people manually engineered rules for tagging, sometimes with the aid of a corpus. As large corpora became available, it became clear that simple Markov-model based stochastic taggers that were automatically trained could achieve high rates of tagging accuracy (Jelinek 1985). Markov-model based taggers assign to a sentence the tag sequence that maximizes Prob(word J tag)*Prob(tag I previous n tags). These probabilities can be estimated directly from a manually tagged corpus.&apos; These stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for</context>
</contexts>
<marker>Harris, 1962</marker>
<rawString>Harris, Zellig (1962). String Analysis of Language Structure. Mouton and Co., The Hague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Acquiring disambiguation rules from text.&amp;quot;</title>
<date>1989</date>
<booktitle>In Proceedings, 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Vancouver, BC.</location>
<contexts>
<context position="22778" citStr="Hindle 1989" startWordPosition="3601" endWordPosition="3602">ues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense</context>
</contexts>
<marker>Hindle, 1989</marker>
<rawString>Hindle, Donald (1989). &amp;quot;Acquiring disambiguation rules from text.&amp;quot; In Proceedings, 27th Annual Meeting of the Association for Computational Linguistics, Vancouver, BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
<author>M Rooth</author>
</authors>
<title>Structural ambiguity and lexical relations.&amp;quot;</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="2081" citStr="Hindle and Rooth 1993" startWordPosition="307" endWordPosition="310">rocessing systems. A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora (Brown, Lai, and Mercer 1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994). An effort has recently been undertaken to create automated machine translation systems in which the linguistic information needed for translation is extracted automatically from aligned corpora (Brown et al. 1990). These are just a few of the</context>
</contexts>
<marker>Hindle, Rooth, 1993</marker>
<rawString>Hindle, D. and Rooth, M. (1993). &amp;quot;Structural ambiguity and lexical relations.&amp;quot; Computational Linguistics, 19(1):103-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline Huang</author>
<author>Mark Son-Bell</author>
<author>David Baggett</author>
</authors>
<title>Generation of pronunciations from orthographies using transformation-based error-driven learning.&amp;quot;</title>
<date>1994</date>
<booktitle>In International Conference on Speech and Language Processing (ICSLP),</booktitle>
<location>Yokohama, Japan.</location>
<marker>Huang, Son-Bell, Baggett, 1994</marker>
<rawString>Huang, Caroline; Son-Bell, Mark; and Baggett, David (1994). &amp;quot;Generation of pronunciations from orthographies using transformation-based error-driven learning.&amp;quot; In International Conference on Speech and Language Processing (ICSLP), Yokohama, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Jelinek</author>
</authors>
<title>Self-Organized Language Modelling for Speech Recognition.</title>
<date>1985</date>
<booktitle>In Impact of Processing Techniques on Communication,</booktitle>
<editor>J. Skwirzinski, ed.</editor>
<location>Dordrecht.</location>
<contexts>
<context position="22739" citStr="Jelinek 1985" startWordPosition="3595" endWordPosition="3596"> 94-98). 5 For a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps s</context>
<context position="24210" citStr="Jelinek 1985" startWordPosition="3804" endWordPosition="3805">l, and Baggett 1994) and building pronunciation networks for speech recognition. Recently, a method has been proposed for using part-of-speech tagging techniques as a method for parsing with lexicalized grammars (Joshi and Srinivas 1994). When automated part-of-speech tagging was initially explored (Klein and Simmons 1963; Harris 1962), people manually engineered rules for tagging, sometimes with the aid of a corpus. As large corpora became available, it became clear that simple Markov-model based stochastic taggers that were automatically trained could achieve high rates of tagging accuracy (Jelinek 1985). Markov-model based taggers assign to a sentence the tag sequence that maximizes Prob(word J tag)*Prob(tag I previous n tags). These probabilities can be estimated directly from a manually tagged corpus.&apos; These stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almos</context>
</contexts>
<marker>Jelinek, 1985</marker>
<rawString>Jelinek, Fred (1985). Self-Organized Language Modelling for Speech Recognition. Dordrecht. In Impact of Processing Techniques on Communication, J. Skwirzinski, ed.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind Joshi</author>
<author>B Srinivas</author>
</authors>
<title>Disambiguation of super parts of speech (or supertags): Almost parsing.&amp;quot;</title>
<date>1994</date>
<booktitle>In Proceedings, 15th International Conference on Computational Linguistics, Kyoto,</booktitle>
<contexts>
<context position="23834" citStr="Joshi and Srinivas 1994" startWordPosition="3748" endWordPosition="3751">exical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is possible to cast a number of other useful problems as part-of-speech tagging problems, such as letter-to-sound translation (Huang, Son-Bell, and Baggett 1994) and building pronunciation networks for speech recognition. Recently, a method has been proposed for using part-of-speech tagging techniques as a method for parsing with lexicalized grammars (Joshi and Srinivas 1994). When automated part-of-speech tagging was initially explored (Klein and Simmons 1963; Harris 1962), people manually engineered rules for tagging, sometimes with the aid of a corpus. As large corpora became available, it became clear that simple Markov-model based stochastic taggers that were automatically trained could achieve high rates of tagging accuracy (Jelinek 1985). Markov-model based taggers assign to a sentence the tag sequence that maximizes Prob(word J tag)*Prob(tag I previous n tags). These probabilities can be estimated directly from a manually tagged corpus.&apos; These stochastic t</context>
</contexts>
<marker>Joshi, Srinivas, 1994</marker>
<rawString>Joshi, Aravind and Srinivas, B. (1994). &amp;quot;Disambiguation of super parts of speech (or supertags): Almost parsing.&amp;quot; In Proceedings, 15th International Conference on Computational Linguistics, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheldon Klein</author>
<author>Robert Simmons</author>
</authors>
<title>A computational approach to grammatical coding of English words.&amp;quot;</title>
<date>1963</date>
<journal>JACM,</journal>
<volume>10</volume>
<contexts>
<context position="23920" citStr="Klein and Simmons 1963" startWordPosition="3759" endWordPosition="3763"> in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is possible to cast a number of other useful problems as part-of-speech tagging problems, such as letter-to-sound translation (Huang, Son-Bell, and Baggett 1994) and building pronunciation networks for speech recognition. Recently, a method has been proposed for using part-of-speech tagging techniques as a method for parsing with lexicalized grammars (Joshi and Srinivas 1994). When automated part-of-speech tagging was initially explored (Klein and Simmons 1963; Harris 1962), people manually engineered rules for tagging, sometimes with the aid of a corpus. As large corpora became available, it became clear that simple Markov-model based stochastic taggers that were automatically trained could achieve high rates of tagging accuracy (Jelinek 1985). Markov-model based taggers assign to a sentence the tag sequence that maximizes Prob(word J tag)*Prob(tag I previous n tags). These probabilities can be estimated directly from a manually tagged corpus.&apos; These stochastic taggers have a number of advantages over the manually built taggers, including obviatin</context>
</contexts>
<marker>Klein, Simmons, 1963</marker>
<rawString>Klein, Sheldon and Simmons, Robert (1963). &amp;quot;A computational approach to grammatical coding of English words.&amp;quot; JACM, 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
</authors>
<title>Robust part-of-speech tagging using a hidden Markov model.&amp;quot;</title>
<date>1992</date>
<journal>Computer Speech and Language,</journal>
<volume>6</volume>
<contexts>
<context position="22874" citStr="Kupiec 1992" startWordPosition="3617" endWordPosition="3618">s described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is possible to cas</context>
<context position="25047" citStr="Kupiec 1992" startWordPosition="3928" endWordPosition="3929">gers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from X to Y iff 7 In Brill and Resnik (1994), we desc</context>
<context position="33617" citStr="Kupiec (1992)" startWordPosition="5370" endWordPosition="5371">ate transition probabilities (P(Tag, Tag,_i .Tagi_,,)) express the likelihood of a tag immediately following n other tags, and emit probabilities (P(Wordi I Tag,)) express the likelihood of a word, given a tag. Many useful relationships, such as that between a word and the previous word, or between a tag and the following word, are not directly captured by Markov-model based taggers. The same is true of the nonlexicalized transformation-based tagger, where transformation templates do not make reference to words. To remedy this problem, we extend the transformation-based tagger by adding 13 In Kupiec (1992), a limited amount of lexicalization is introduced by having a stochastic tagger with word states for the 100 most frequent words in the corpus. 555 Computational Linguistics Volume 21, Number 4 contextual transformations that can make reference to words as well as part-of-speech tags. The transformation templates we add are: Change tag a to tag b when: 1. The preceding (following) word is w. 2. The word two before (after) is w. 3. One of the two preceding (following) words is w. 4. The current word is w and the preceding (following) word is x. 5. The current word is w and the preceding (follo</context>
</contexts>
<marker>Kupiec, 1992</marker>
<rawString>Kupiec, Julian (1992). &amp;quot;Robust part-of-speech tagging using a hidden Markov model.&amp;quot; Computer Speech and Language, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Maryann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank.&amp;quot;</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="22046" citStr="Marcus, Santorini, and Marcinkiewicz, 1993" startWordPosition="3475" endWordPosition="3479">uction, is used instead. The direct correlation between rules and performance improvement in transformation-based learning can make the learned rules more readily interpretable than decision tree rules for increasing population purity.&apos; 4. Part of Speech Tagging: A Case Study in Transformation-Based Error-Driven Learning In this section we describe the practical application of transformation-based learning to part-of-speech tagging.&apos; Part-of-speech tagging is a good application to test the 3 The original tagged Brown Corpus (Francis and Kucera, 1982) makes this distinction; the Penn Treebank (Marcus, Santorini, and Marcinkiewicz, 1993) does not. 4 For a discussion of why this is the case, see Breiman et al. (1984, 94-98). 5 For a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell; Santorini, Beatrice; and Marcinkiewicz, Maryann (1993). &amp;quot;Building a large annotated corpus of English: the Penn Treebank.&amp;quot; Computational Linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Merialdo</author>
</authors>
<title>Tagging English text with a probabilistic model.&amp;quot; Computational Linguistics.</title>
<date>1994</date>
<contexts>
<context position="22809" citStr="Merialdo 1994" startWordPosition="3605" endWordPosition="3606">ing algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and preposition</context>
<context position="25013" citStr="Merialdo 1994" startWordPosition="3921" endWordPosition="3923">tagged corpus.&apos; These stochastic taggers have a number of advantages over the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from X to Y iff 7 I</context>
<context position="26267" citStr="Merialdo (1994)" startWordPosition="4114" endWordPosition="4115">an approach to prepositional phrase attachment disambiguation that obtains highly competitive performance compared to other corpus-based solutions to this problem. This system was derived in under two hours from the transformation-based part of speech tagger described in this paper. 8 One can also estimate these probabilities without a manually tagged corpus, using a hidden Markov model. However, it appears to be the case that directly estimating probabilities from even a very small manually tagged corpus gives better results than training a hidden Markov model on a large untagged corpus (see Merialdo (1994)). 9 Earlier versions of this work were reported in Brill (1992, 1994). 552 Brill Transformation-Based Error-Driven Learning either: 1. The word was not seen in the training corpus OR 2. The word was seen tagged with Y at least once in the training corpus. In taggers based on Markov models, the lexicon consists of probabilities of the somewhat counterintuitive but proper form P(WORD I TAG). In the transformationbased tagger, the lexicon is simply a list of all tags seen for a word in the training corpus, with one tag labeled as the most likely. Below we show a lexical entry for the word half i</context>
</contexts>
<marker>Merialdo, 1994</marker>
<rawString>Merialdo, Bernard (1994). &amp;quot;Tagging English text with a probabilistic model.&amp;quot; Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>Wordnet: an on-line lexical database.&amp;quot;</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="3788" citStr="Miller 1990" startWordPosition="559" endWordPosition="560">tter and becoming more readily available. There are a number of efforts worldwide to manually annotate large corpora with linguistic information, including parts of speech, phrase structure and predicate-argument structure (e.g., the Penn Treebank and the British National Corpus (Marcus, Santorini, and Marcinkiewicz 1993; Leech, Garside, and Bryant 1994)). A vast amount of on-line text is now available, and much more will become available in the future. Useful tools, such as large aligned corpora (e.g., the aligned Hansards (Gale and Church 1991)) and semantic word hierarchies (e.g., Wordnet (Miller 1990)), have also recently become available. Corpus-based methods are often able to succeed while ignoring the true complexities of language, banking on the fact that complex linguistic phenomena can often be indirectly observed through simple epiphenomena. For example, one could accurately assign a part-of-speech tag to the word race in (1-3) without any reference to phrase structure or constituent movement: One would only have to realize that, usually, a word one or two words to the right of a modal is a verb and not a noun. An exception to this generalization arises when the word is also one wor</context>
<context position="40028" citStr="Miller 1990" startWordPosition="6451" endWordPosition="6452"> did here was slightly suboptimal, in that we used the contextual rules learned with unknown words (described in the next section), and filled in the dictionary, rather than training on a corpus without unknown words. 557 Computational Linguistics Volume 21, Number 4 Table 1 Comparison of Tagging Accuracy With No Unknown Words Method Training # of Rules Acc. Corpus or Context. (%) Size (Words) Probs. Stochastic 64 K 6,170 96.3 Stochastic 1 Million 10,000 96.7 Rule-Based 64 K 215 96.7 With Lex. Rules Rule-Based 600 K 447 97.2 With Lex. Rules Rule-Based 600 K 378 97.0 w/o Lex. Rules as WordNet (Miller 1990), the learner is extended such that a rule is allowed to make reference to parts of speech, words, and word classes, allowing for rules such as Change the tag from X to Y if the following word belongs to word class Z. This approach has already been successfully applied to a system for prepositional phrase attachment disambiguation (Brill and Resnik 1994). 4.3 Tagging Unknown Words So far, we have not addressed the problem of unknown words. As stated above, the initial-state annotator for tagging assigns all words their most likely tag, as indicated in a training corpus. Below we show how a tra</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>Miller, George (1990). &amp;quot;Wordnet: an on-line lexical database.&amp;quot; International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ross Quinlan</author>
</authors>
<title>Induction of decision trees.&amp;quot;</title>
<date>1986</date>
<booktitle>Machine Learning,</booktitle>
<pages>1--81</pages>
<contexts>
<context position="12841" citStr="Quinlan 1986" startWordPosition="1945" endWordPosition="1946">has been processed for that one transformation, then regardless of the order of processing the output will be: ABBBBB, since the triggering environment of a transformation is always checked before that transformation is applied to any surrounding objects in the corpus. If the effect of a transformation is recorded immediately, then processing the string left to right would result in: ABABAB, whereas processing right to left would result in: ABBBBB. 3. A Comparison With Decision Trees The technique employed by the learner is somewhat similar to that used in decision trees (Breiman et al. 1984; Quinlan 1986; Quinlan and Rivest 1989). A decision tree is trained on a set of preclassified entities and outputs a set of questions that can be asked about an entity to determine its proper classification. Decision trees are built by finding the question whose resulting partition is the purest,2 splitting the training data according to that question, and then recursively reapplying this procedure on each resulting subset. We first show that the set of classifications that can be provided via decision trees is a proper subset of those that can be provided via transformation lists (an ordered list of trans</context>
</contexts>
<marker>Quinlan, 1986</marker>
<rawString>Quinlan, J. Ross (1986). &amp;quot;Induction of decision trees.&amp;quot; Machine Learning, 1:81-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ross Quinlan</author>
<author>Ronald Rivest</author>
</authors>
<title>Inferring decision trees using the minimum description length principle.&amp;quot;</title>
<date>1989</date>
<journal>Information and Computation,</journal>
<volume>80</volume>
<contexts>
<context position="12867" citStr="Quinlan and Rivest 1989" startWordPosition="1947" endWordPosition="1950">ssed for that one transformation, then regardless of the order of processing the output will be: ABBBBB, since the triggering environment of a transformation is always checked before that transformation is applied to any surrounding objects in the corpus. If the effect of a transformation is recorded immediately, then processing the string left to right would result in: ABABAB, whereas processing right to left would result in: ABBBBB. 3. A Comparison With Decision Trees The technique employed by the learner is somewhat similar to that used in decision trees (Breiman et al. 1984; Quinlan 1986; Quinlan and Rivest 1989). A decision tree is trained on a set of preclassified entities and outputs a set of questions that can be asked about an entity to determine its proper classification. Decision trees are built by finding the question whose resulting partition is the purest,2 splitting the training data according to that question, and then recursively reapplying this procedure on each resulting subset. We first show that the set of classifications that can be provided via decision trees is a proper subset of those that can be provided via transformation lists (an ordered list of transformation-based rules), gi</context>
</contexts>
<marker>Quinlan, Rivest, 1989</marker>
<rawString>Quinlan, J. Ross and Rivest, Ronald (1989). &amp;quot;Inferring decision trees using the minimum description length principle.&amp;quot; Information and Computation, 80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lance Ramshaw</author>
<author>Mitchell Marcus</author>
</authors>
<title>Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging.&amp;quot; In The Balancing Act:</title>
<date>1994</date>
<booktitle>Proceedings of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language,</booktitle>
<institution>Mexico State University,</institution>
<location>New</location>
<contexts>
<context position="22241" citStr="Ramshaw and Marcus (1994)" startWordPosition="3511" endWordPosition="3514">sing population purity.&apos; 4. Part of Speech Tagging: A Case Study in Transformation-Based Error-Driven Learning In this section we describe the practical application of transformation-based learning to part-of-speech tagging.&apos; Part-of-speech tagging is a good application to test the 3 The original tagged Brown Corpus (Francis and Kucera, 1982) makes this distinction; the Penn Treebank (Marcus, Santorini, and Marcinkiewicz, 1993) does not. 4 For a discussion of why this is the case, see Breiman et al. (1984, 94-98). 5 For a discussion of other issues regarding these two learning algorithms, see Ramshaw and Marcus (1994). 6 All of the programs described herein are freely available with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992;</context>
<context position="31132" citStr="Ramshaw and Marcus (1994)" startWordPosition="4911" endWordPosition="4914">hen making the transformation given the part-of-speech tag of the previous word (lines 8 and 9). If X is the current tag and Y is the correct tag, then the transformation will result in one less error, so we increment the number of improvements caused when making the transformation given the part-of-speech tag of the previous word (lines 6 and 7). In certain cases, a significant increase in speed for training the transformationbased tagger can be obtained by indexing in the corpus where different transformations can and do apply. For a description of a fast index-based training algorithm, see Ramshaw and Marcus (1994). In figure 4, we list the first twenty transformations learned from training on the Penn Treebank Wall Street Journal Corpus (Marcus, Santorini, and Marcinkiewicz 1993).12 The first transformation states that a noun should be changed to a verb if 12 Version 0.5 of the Penn Treebank was used in all experiments reported in this paper. 554 Brill Transformation-Based Error-Driven Learning Change Tag # From To Condition 1 NN VB Previous tag is TO 2 VBP VB One of the previous three tags is MD 3 NN VB One of the previous two tags is MD 4 VB NN One of the previous two tags is DT 5 VBD VBN One of the </context>
</contexts>
<marker>Ramshaw, Marcus, 1994</marker>
<rawString>Ramshaw, Lance and Marcus, Mitchell (1994). &amp;quot;Exploring the statistical derivation of transformational rule sequences for part-of-speech tagging.&amp;quot; In The Balancing Act: Proceedings of the ACL Workshop on Combining Symbolic and Statistical Approaches to Language, New Mexico State University, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Roche</author>
<author>Yves Schabes</author>
</authors>
<title>Deterministic part of speech tagging with finite state transducers.&amp;quot;</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<pages>227--253</pages>
<contexts>
<context position="49034" citStr="Roche and Schabes (1995)" startWordPosition="7978" endWordPosition="7981">le capturing the information in a much more concise and perspicuous manner, and without prespecifying any information specific to English or to a specific corpus. In table 2, we show tagging results obtained on a number of different corpora, in each case training on roughly 9.5 x 105 words total and testing on a separate test set of 1.5-2 x 108 words. Accuracy is consistent across these corpora and tag sets. In addition to obtaining high rates of accuracy and representing relevant linguistic information in a small set of rules, the part-of-speech tagger can also be made to run extremely fast. Roche and Schabes (1995) show a method for converting a list of tagging transformations into a deterministic finite state transducer with one state transition taken per word of input; the result is a transformation-based tagger whose tagging speed is about ten times that of the fastest Markov-model tagger. 4.4 K-Best Tags There are certain circumstances where one is willing to relax the one-tag-per-word requirement in order to increase the probability that the correct tag will be assigned to each word. In DeMarcken (1990) and Weischedel et al. (1993), k-best tags are assigned within a stochastic tagger by returning a</context>
</contexts>
<marker>Roche, Schabes, 1995</marker>
<rawString>Roche, Emmanuel and Schabes, Yves (1995). &amp;quot;Deterministic part of speech tagging with finite state transducers.&amp;quot; Computational Linguistics, 21(2), 227-253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Schutze</author>
<author>Yoram Singer</author>
</authors>
<title>Part of speech tagging using a variable memory Markov model.</title>
<date>1994</date>
<booktitle>In Proceedings, Association for Computational Linguistics,</booktitle>
<location>Las Cruces, NM.</location>
<contexts>
<context position="22946" citStr="Schutze and Singer 1994" startWordPosition="3627" endWordPosition="3630">s on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is possible to cast a number of other useful problems as part-of-speech tagging problems, </context>
<context position="25119" citStr="Schutze and Singer 1994" startWordPosition="3938" endWordPosition="3941">ggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from X to Y iff 7 In Brill and Resnik (1994), we describe an approach to prepositional phrase attachment disambiguation that </context>
</contexts>
<marker>Schutze, Singer, 1994</marker>
<rawString>Schutze, Hinrich and Singer, Yoram (1994). Part of speech tagging using a variable memory Markov model. In Proceedings, Association for Computational Linguistics, Las Cruces, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Sharman</author>
<author>Fred Jelinek</author>
<author>Robert Mercer</author>
</authors>
<title>Generating a grammar for statistical training.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings,</booktitle>
<marker>Sharman, Jelinek, Mercer, 1990</marker>
<rawString>Sharman, Robert; Jelinek, Fred; and Mercer, Robert (1990). &amp;quot;Generating a grammar for statistical training.&amp;quot; In Proceedings, 1990 Darpa Speech and Natural Language Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>Marie Meteer</author>
<author>Richard Schwartz</author>
<author>Lance Ramshaw</author>
<author>Jeff Palmucci</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.&amp;quot; Computational Linguistics.</title>
<date>1993</date>
<contexts>
<context position="1666" citStr="Weischedel et al. 1993" startWordPosition="240" endWordPosition="243">without a compromise in performance. We present a detailed case study of this learning method applied to part-of-speech tagging. 1. Introduction It has recently become clear that automatically extracting linguistic information from a sample text corpus can be an extremely powerful method of overcoming the linguistic knowledge acquisition bottleneck inhibiting the creation of robust and accurate natural language processing systems. A number of part-of-speech taggers are readily available and widely used, all trained and retrainable on text corpora (Church 1988; Cutting et al. 1992; Brill 1992; Weischedel et al. 1993). Endemic structural ambiguity, which can lead to such difficulties as trying to cope with the many thousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with h</context>
<context position="22920" citStr="Weischedel et al. 1993" startWordPosition="3623" endWordPosition="3626">able with no restrictions on use or redistribution. For information on obtaining the tagger, contact the author. 551 Computational Linguistics Volume 21, Number 4 learner, for several reasons. There are a number of large tagged corpora available, allowing for a variety of experiments to be run. Part-of-speech tagging is an active area of research; a great deal of work has been done in this area over the past few years (e.g., Jelinek 1985; Church 1988; Derose 1988; Hindle 1989; DeMarcken 1990; Merialdo 1994; Brill 1992; Black et al. 1992; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). Part-of-speech tagging is also a very practical application, with uses in many areas, including speech recognition and generation, machine translation, parsing, information retrieval and lexicography. Insofar as tagging can be seen as a prototypical problem in lexical ambiguity, advances in part-of-speech tagging could readily translate to progress in other areas of lexical, and perhaps structural, ambiguity, such as wordsense disambiguation and prepositional phrase attachment disambiguation.&apos; Also, it is possible to cast a number of other useful problems as part-of</context>
<context position="25093" citStr="Weischedel et al. 1993" startWordPosition="3934" endWordPosition="3937">er the manually built taggers, including obviating the need for laborious manual rule construction, and possibly capturing useful information that may not have been noticed by the human engineer. However, stochastic taggers have the disadvantage that linguistic information is captured only indirectly, in large tables of statistics. Almost all recent work in developing automatically trained part-of-speech taggers has been on further exploring Markovmodel based tagging (Jelinek 1985; Church 1988; Derose 1988; DeMarcken 1990; Merialdo 1994; Cutting et al. 1992; Kupiec 1992; Charniak et al. 1993; Weischedel et al. 1993; Schutze and Singer 1994). 4.1 Transformation-based Error-driven Part-of-Speech Tagging Transformation-based part of speech tagging works as follows.&apos; The initial-state annotator assigns each word its most likely tag as indicated in the training corpus. The method used for initially tagging unknown words will be described in a later section. An ordered list of transformations is then learned, to improve tagging accuracy based on contextual cues. These transformations alter the tagging of a word from X to Y iff 7 In Brill and Resnik (1994), we describe an approach to prepositional phrase attac</context>
<context position="36469" citStr="Weischedel et al. (1993)" startWordPosition="5880" endWordPosition="5883"> the fact that when a verb appears in a context such as We do n&apos;t eat or We did n&apos;t usually drink, the verb is in base form. A stochastic trigram tagger would have to capture this linguistic information indirectly from frequency counts of all trigrams of the form shown in figure 5 (where a star can match any part-of-speech tag) and from the fact that P(n&apos;t I RB) is fairly high. 14 In the Penn Treebank, n&apos;t is treated as a separate token, so don&apos;t becomes dolVBP n&apos;t/RB. 556 Brill Transformation-Based Error-Driven Learning RB VBP RB VB RB VBP RB VB Figure 5 Trigram Tagger Probability Tables. In Weischedel et al. (1993), results are given when training and testing a Markovmodel based tagger on the Penn Treebank Tagged Wall Street journal Corpus. They cite results making the closed vocabulary assumption that all possible tags for all words in the test set are known. When training contextual probabilities on one million words, an accuracy of 96.7% was achieved. Accuracy dropped to 96.3% when contextual probabilities were trained on 64,000 words. We trained the transformation-based tagger on the same corpus, making the same closed-vocabulary assumption.&apos; When training contextual rules on 600,000 words, an accur</context>
<context position="38860" citStr="Weischedel et al. (1993)" startWordPosition="6252" endWordPosition="6255">ing lexicalized transformations resulted in a 6.7% decrease in the error rate (see table 1).16 We found it a bit surprising that the addition of lexicalized transformations did not result in a much greater improvement in performance. When transformations are allowed to make reference to words and word pairs, some relevant information is probably missed due to sparse data. We are currently exploring the possibility of incorporating word classes into the rule-based learner, in hopes of overcoming this problem. The idea is quite simple. Given any source of word class information, such 15 In both Weischedel et al. (1993) and here, the test set was incorporated into the lexicon, but was not used in learning contextual information. Testing with no unknown words might seem like an unrealistic test. We have done so for three reasons: (1) to allow for a comparison with previously quoted results, (2) to isolate known word accuracy from unknown word accuracy and (3) in some systems, such as a closed vocabulary speech recognition system, the assumption that all words are known is valid. (We show results when unknown words are included later in the paper.) 16 The training we did here was slightly suboptimal, in that w</context>
<context position="47528" citStr="Weischedel et al. (1993)" startWordPosition="7734" endWordPosition="7737">tion that does not increase unknown-word tagging accuracy can still be beneficial to overall tagging accuracy, the contextual transformations learned are not optimal in the sense of leading to the highest tagging accuracy on unknown words. Better unknown-word accuracy may be possible by training and using two sets of contextual rules, one maximizing known-word accuracy and the other maximizing unknown-word accuracy, and then applying the appropriate transformations to a word when tagging, depending upon whether the word appears in the lexicon. We are currently experimenting with this idea. In Weischedel et al. (1993), a statistical approach to tagging unknown words is shown. In this approach, a number of suffixes and important features are prespecified. Then, for unknown words: p(W I T) = p(unknown word I T) * p(Capitalize-feature I T) * p(suffixes, hyphenation I T) Using this equation for unknown word emit probabilities within the stochastic tagger, an accuracy of 85% was obtained on the Wall Street Journal corpus. This portion of the stochastic model has over 1,000 parameters, with 108 possible unique emit probabilities, as opposed to a small number of simple rules that are learned and used in the rule-</context>
<context position="49566" citStr="Weischedel et al. (1993)" startWordPosition="8062" endWordPosition="8065">, the part-of-speech tagger can also be made to run extremely fast. Roche and Schabes (1995) show a method for converting a list of tagging transformations into a deterministic finite state transducer with one state transition taken per word of input; the result is a transformation-based tagger whose tagging speed is about ten times that of the fastest Markov-model tagger. 4.4 K-Best Tags There are certain circumstances where one is willing to relax the one-tag-per-word requirement in order to increase the probability that the correct tag will be assigned to each word. In DeMarcken (1990) and Weischedel et al. (1993), k-best tags are assigned within a stochastic tagger by returning all tags within some threshold of probability of being correct for a particular word. 561 Computational Linguistics Volume 21, Number 4 Table 3 Results from k-best tagging. # of Rules Accuracy Avg. # of tags per word 0 96.5 1.00 50 96.9 1.02 100 97.4 1.04 150 97.9 1.10 200 98.4 1.19 250 99.1 1.50 We can modify the transformation-based tagger to return multiple tags for a word by making a simple modification to the contextual transformations described above. The initial-state annotator is the tagging output of the previously des</context>
<context position="52229" citStr="Weischedel et al. (1993)" startWordPosition="8502" endWordPosition="8505">aseline tagger.&apos; 5. Conclusions In this paper, we have described a new transformation-based approach to corpus-based learning. We have given details of how this approach has been applied to part-ofspeech tagging and have demonstrated that the transformation-based approach obtains 19 Thanks to Fred Jelinek and Fernando Pereira for suggesting this baseline experiment. 20 Unfortunately, it is difficult to find results to compare these k-best tag results to. In DeMarcken (1990), the test set is included in the training set, and so it is difficult to know how this system would do on fresh text. In Weischedel et al. (1993), a k-best tag experiment was run on the Wall Street Journal corpus. They quote the average number of tags per word for various threshold settings, but do not provide accuracy results. 562 Brill Transformation-Based Error-Driven Learning competitive performance with stochastic taggers on tagging both unknown and known words. The transformation-based tagger captures linguistic information in a small number of simple nonstochastic rules, as opposed to large numbers of lexical and contextual probabilities. This learning approach has also been applied to a number of other tasks, including preposit</context>
</contexts>
<marker>Weischedel, Meteer, Schwartz, Ramshaw, Palmucci, 1993</marker>
<rawString>Weischedel, Ralph; Meteer, Marie; Schwartz, Richard; Ramshaw, Lance; and Palmucci, Jeff (1993). &amp;quot;Coping with ambiguity and unknown words through probabilistic models.&amp;quot; Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Word-sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora.&amp;quot;</title>
<date>1992</date>
<booktitle>In Proceedings of COLING-92,</booktitle>
<pages>454--460</pages>
<location>Nantes, France,</location>
<contexts>
<context position="2381" citStr="Yarowsky 1992" startWordPosition="357" endWordPosition="358">ousands of possible parses that a grammar can assign to a sentence, can be greatly reduced by adding empirically derived probabilities to grammar rules (Fujisaki et al. 1989; Sharman, Jelinek, and Mercer 1990; Black et al. 1993) and by computing statistical measures of lexical association (Hindle and Rooth 1993). Word-sense disambiguation, a problem that once seemed out of reach for systems without a great deal of handcrafted linguistic and world knowledge, can now in some cases be done with high accuracy when all information is derived automatically from corpora (Brown, Lai, and Mercer 1991; Yarowsky 1992; Gale, Church, and Yarowsky 1992; Bruce and Wiebe 1994). An effort has recently been undertaken to create automated machine translation systems in which the linguistic information needed for translation is extracted automatically from aligned corpora (Brown et al. 1990). These are just a few of the many recent applications of corpus-based techniques in natural language processing. * Department of Computer Science, Baltimore, MD 21218-2694. E-mail: brill@cs.jhu.edu. © 1995 Association for Computational Linguistics Computational Linguistics Volume 21, Number 4 Along with great research advances</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>Yarowsky, David (1992). &amp;quot;Word-sense disambiguation using statistical models of Roget&apos;s categories trained on large corpora.&amp;quot; In Proceedings of COLING-92, pages 454-460, Nantes, France, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>