<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.998908">
A Pipeline Framework for Dependency Parsing
</title>
<author confidence="0.982779">
Ming-Wei Chang Quang Do Dan Roth
</author>
<affiliation confidence="0.985564">
Department of Computer Science
University of Illinois at Urbana-Champaign
</affiliation>
<address confidence="0.72663">
Urbana, IL 61801
</address>
<email confidence="0.993163">
{mchang21, quangdo2, danr}@uiuc.edu
</email>
<sectionHeader confidence="0.997353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999626578947368">
Pipeline computation, in which a task is
decomposed into several stages that are
solved sequentially, is a common compu-
tational strategy in natural language pro-
cessing. The key problem of this model
is that it results in error accumulation and
suffers from its inability to correct mis-
takes in previous stages. We develop
a framework for decisions made via in
pipeline models, which addresses these
difficulties, and presents and evaluates it
in the context of bottom up dependency
parsing for English. We show improve-
ments in the accuracy of the inferred trees
relative to existing models. Interestingly,
the proposed algorithm shines especially
when evaluated globally, at a sentence
level, where our results are significantly
better than those of existing approaches.
</bodyText>
<sectionHeader confidence="0.999514" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.974695833333333">
A pipeline process over the decisions of learned
classifiers is a common computational strategy in
natural language processing. In this model a task
is decomposed into several stages that are solved
sequentially, where the computation in the ith
stage typically depends on the outcome of com-
putations done in previous stages. For example,
a semantic role labeling program (Punyakanok et
al., 2005) may start by using a part-of-speech tag-
ger, then apply a shallow parser to chunk the sen-
tence into phrases, identify predicates and argu-
ments and then classify them to types. In fact,
any left to right processing of an English sentence
may be viewed as a pipeline computation as it pro-
cesses a token and, potentially, makes use of this
result when processing the token to the right.
The pipeline model is a standard model of
computation in natural language processing for
good reasons. It is based on the assumption that
some decisions might be easier or more reliable
than others, and their outcomes, therefore, can be
counted on when making further decisions. Nev-
ertheless, it is clear that it results in error accu-
mulation and suffers from its inability to correct
mistakes in previous stages. Researchers have re-
cently started to address some of the disadvantages
of this model. E.g., (Roth and Yih, 2004) suggests
a model in which global constraints are taken into
account in a later stage to fix mistakes due to the
pipeline. (Punyakanok et al., 2005; Marciniak
and Strube, 2005) also address some aspects of
this problem. However, these solutions rely on the
fact that all decisions are made with respect to the
same input; specifically, all classifiers considered
use the same examples as their input. In addition,
the pipelines they study are shallow.
This paper develops a general framework for
decisions in pipeline models which addresses
these difficulties. Specifically, we are interested
in deep pipelines – a large number of predictions
that are being chained.
A pipeline process is one in which decisions
made in the ith stage (1) depend on earlier deci-
sions and (2) feed on input that depends on earlier
decisions. The latter issue is especially important
at evaluation time since, at training time, a gold
standard data set might be used to avoid this issue.
We develop and study the framework in the con-
text of a bottom up approach to dependency pars-
ing. We suggest that two principles to guide the
pipeline algorithm development:
(i) Make local decisions as reliable as possible.
(ii) Reduce the number of decisions made.
Using these as guidelines we devise an algo-
</bodyText>
<page confidence="0.993167">
65
</page>
<note confidence="0.7241665">
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 65–72,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999879473684211">
rithm for dependency parsing, prove that it satis-
fies these principles, and show experimentally that
this improves the accuracy of the resulting tree.
Specifically, our approach is based on a shift-
reduced parsing as in (Yamada and Matsumoto,
2003). Our general framework provides insights
that allow us to improve their algorithm, and to
principally justify some of the algorithmic deci-
sions. Specifically, the first principle suggests to
improve the reliability of the local predictions,
which we do by improving the set of actions taken
by the parsing algorithm, and by using a look-
ahead search. The second principle is used to jus-
tify the control policy of the parsing algorithm –
which edges to consider at any point of time. We
prove that our control policy is optimal in some
sense, and that the decisions we made, guided by
these, principles lead to a significant improvement
in the accuracy of the resulting parse tree.
</bodyText>
<subsectionHeader confidence="0.999633">
1.1 Dependency Parsing and Pipeline Models
</subsectionHeader>
<bodyText confidence="0.999841038961039">
Dependency trees provide a syntactic reresenta-
tion that encodes functional relationships between
words; it is relatively independent of the grammar
theory and can be used to represent the structure
of sentences in different languages. Dependency
structures are more efficient to parse (Eisner,
1996) and are believed to be easier to learn, yet
they still capture much of the predicate-argument
information needed in applications (Haghighi et
al., 2005), which is one reason for the recent in-
terest in learning these structures (Eisner, 1996;
McDonald et al., 2005; Yamada and Matsumoto,
2003; Nivre and Scholz, 2004).
Eisner’s work – O(n3) parsing time generative
algorithm – embarked the interest in this area.
His model, however, seems to be limited when
dealing with complex and long sentences. (Mc-
Donald et al., 2005) build on this work, and use
a global discriminative training approach to im-
prove the edges’ scores, along with Eisner’s algo-
rithm, to yield the expected improvement. A dif-
ferent approach was studied by (Yamada and Mat-
sumoto, 2003), that develop a bottom-up approach
and learn the parsing decisions between consecu-
tive words in the sentence. Local actions are used
to generate a dependency tree using a shift-reduce
parsing approach (Aho et al., 1986). This is a
true pipeline approach, as was done in other suc-
cessful parsers, e.g. (Ratnaparkhi, 1997), in that
the classifiers are trained on individual decisions
rather than on the overall quality of the parser, and
chained to yield the global structure. Clearly, it
suffers from the limitations of pipeline process-
ing, such as accumulation of errors, but neverthe-
less, yields very competitive parsing results. A
somewhat similar approach was used in (Nivre and
Scholz, 2004) to develop a hybrid bottom-up/top-
down approach; there, the edges are also labeled
with semantic types, yielding lower accuracy than
the works mentioned above.
The overall goal of dependency parsing (DP)
learning is to infer a tree structure. A common
way to do that is to predict with respect to each
potential edge (i, j) in the tree, and then choose a
global structure that (1) is a tree and that (2) max-
imizes some score. In the context of DPs, this
“edge based factorization method” was proposed
by (Eisner, 1996). In other contexts, this is similar
to the approach of (Roth and Yih, 2004) in that
scoring each edge depends only on the raw data
observed and not on the classifications of other
edges, and that global considerations can be used
to overwrite the local (edge-based) decisions.
On the other hand, the key in a pipeline model
is that making a decision with respect to the edge
(i, j) may gain from taking into account deci-
sions already made with respect to neighboring
edges. However, given that these decisions are
noisy, there is a need to devise policies for reduc-
ing the number of predictions in order to make the
parser more robust. This is exemplified in (Ya-
mada and Matsumoto, 2003) – a bottom-up ap-
proach, that is most related to the work presented
here. Their model is a “traditional” pipeline model
– a classifier suggests a decision that, once taken,
determines the next action to be taken (as well as
the input the next action observes).
In the rest of this paper, we propose and jus-
tify a framework for improving pipeline process-
ing based on the principles mentioned above: (i)
make local decisions as reliably as possible, and
(ii) reduce the number of decisions made. We
use the proposed principles to examine the (Ya-
mada and Matsumoto, 2003) parsing algorithm
and show that this results in modifying some of
the decisions made there and, consequently, better
overall dependency trees.
</bodyText>
<sectionHeader confidence="0.944913" genericHeader="method">
2 Efficient Dependency Parsing
</sectionHeader>
<bodyText confidence="0.9981825">
This section describes our DP algorithm and jus-
tifies its advantages as a pipeline model. We pro-
</bodyText>
<page confidence="0.982567">
66
</page>
<bodyText confidence="0.999065">
pose an improved pipeline framework based on the
mentioned principles.
For many languages such as English, Chinese
and Japanese (with a few exceptions), projective
dependency trees (that is, DPs without edge cross-
ings) are sufficient to analyze most sentences. Our
work is therefore concerned only with projective
trees, which we define below.
For words x, y in the sentence T we introduce
the following notations:
</bodyText>
<equation confidence="0.99659525">
x —* y: x is the direct parent of y.
x —** y: x is an ancestor of y;
xHy:x—*yory—*x.
x &lt; y: x is to the left of y in T.
</equation>
<construct confidence="0.904962666666667">
Definition 1 (Projective Language) (Nivre,
2003) ba, b, c E T, a H b and a &lt; c &lt; b imply
that a —** c or b —** c.
</construct>
<subsectionHeader confidence="0.974066">
2.1 A Pipeline DP Algorithm
</subsectionHeader>
<bodyText confidence="0.99897555882353">
Our parsing algorithm is a modified shift-reduce
parser that makes use of the actions described be-
low and applies them in a left to right manner
on consecutive pairs of words (a, b) (a &lt; b) in
the sentence. This is a bottom-up approach that
uses machine learning algorithms to learn the pars-
ing decisions (actions) between consecutive words
in the sentences. The basic actions used in this
model, as in (Yamada and Matsumoto, 2003), are:
Shift: there is no relation between a and b, or
the action is deferred because the relationship be-
tween a and b cannot be determined at this point.
Right: b is the parent of a,
Left: a is the parent of b.
This is a true pipeline approach in that the clas-
sifiers are trained on individual decisions rather
than on the overall quality of the parsing, and
chained to yield the global structure. And, clearly,
decisions make with respect to a pair of words af-
fect what is considered next by the algorithm.
In order to complete the description of the algo-
rithm we need to describe which edge to consider
once an action is taken. We describe it via the no-
tion of the focus point: when the algorithm con-
siders the pair (a, b), a &lt; b, we call the word a the
current focus point.
Next we describe several policies for determin-
ing the focus point of the algorithm following an
action. We note that, with a few exceptions, de-
termining the focus point does not affect the cor-
rectness of the algorithm. It is easy to show that
for (almost) any focus point chosen, if the correct
action is selected for the corresponding edge, the
algorithm will eventually yield the correct tree (but
may require multiple cycles through the sentence).
In practice, the actions selected are noisy, and a
wasteful focus point policy will result in a large
number of actions, and thus in error accumulation.
To minimize the number of actions taken, we want
to find a good focus point placement policy.
After S, the focus point always moves one word
to the right. After L or R there are there natural
placement policies to consider:
Start Over: Move focus to the first word in T.
Stay: Move focus to the next word to the right.
That is, for T = (a, b, c), and focus being a, an
L action will result is the focus being a, while R
action results in the focus being b.
Step Back: The focus moves to the previous word
(on the left). That is, for T = (a, b, c), and focus
being b, in both cases, a will be the focus point.
In practice, different placement policies have a
significant effect on the number of pairs consid-
ered by the algorithm and, therefore, on the fi-
nal accuracy&apos;. The following analysis justifies the
Step Back policy. We claim that if Step Back
is used, the algorithm will not waste any action.
Thus, it achieves the goal of minimizing the num-
ber of actions in pipeline algorithms. Notice that
using this policy, when L is taken, the pair (a, b) is
reconsidered, but with new information, since now
it is known that c is the child of b. Although this
seems wasteful, we will show this is a necessary
movement to reduce the number of actions.
As mentioned above, each of these policies
yields the correct tree. Table 1 compares the three
policies in terms of the number of actions required
to build a tree.
</bodyText>
<table confidence="0.9773095">
Policy #Shift #Left #Right
Start over 156545 26351 27918
Stay 117819 26351 27918
Step back 43374 26351 27918
</table>
<tableCaption confidence="0.98928">
Table 1: The number of actions required to build
</tableCaption>
<bodyText confidence="0.996364111111111">
all the trees for the sentences in section 23 of Penn
Treebank (Marcus et al., 1993) as a function of
the focus point placement policy. The statistics are
taken with the correct (gold-standard) actions.
It is clear from Table 1 that the policies result
&apos;Note that (Yamada and Matsumoto, 2003) mention that
they move the focus point back after R, but do not state what
they do after executing L actions, and why. (Yamada, 2006)
indicates that they also move focus point back after L.
</bodyText>
<page confidence="0.996993">
67
</page>
<bodyText confidence="0.998975222222222">
Algorithm 2 Pseudo Code of the dependency
parsing algorithm. getFeatures extracts the fea-
tures describing the word pair currently consid-
ered; getAction determines the appropriate action
for the pair; assignParent assigns a parent for the
child word based on the action; and deleteWord
deletes the child word in T at the focus once the
action is taken.
Let t represents for a word token
</bodyText>
<equation confidence="0.932005307692308">
For sentence T = {t1, t2, ... , tn}
focus= 1
while focus&lt; |T |do
V = getFeatures(tfocus, tfocus+1)
α = getAction(tfocus, tfocus+1,v)
if α = L or α = R then
assignParent(tfocus, tfocus+1, α)
deleteWord(T, focus, α)
// performing Step Back here
focus = focus − 1
else
focus = focus + 1
end if
</equation>
<bodyText confidence="0.9559799">
end while
in very different number of actions and that Step
Back is the best choice. Note that, since the ac-
tions are the gold-standard actions, the policy af-
fects only the number of S actions used, and not
the L and R actions, which are a direct function
of the correct tree. The number of required ac-
tions in the testing stage shows the same trend and
the Step Back also gives the best dependency ac-
curacy. Algorithm 2 depicts the parsing algorithm.
</bodyText>
<subsectionHeader confidence="0.998807">
2.2 Correctness and Pipeline Properties
</subsectionHeader>
<bodyText confidence="0.942282296296296">
We can prove two properties of our algorithm.
First we show that the algorithm builds the de-
pendency tree in only one pass over the sentence.
Then, we show that the algorithm does not waste
actions in the sense that it never considers a word
pair twice in the same situation. Consequently,
this shows that under the assumption of a perfect
action predictor, our algorithm makes the smallest
possible number of actions, among all algorithms
that build a tree sequentially in one pass.
Note that this may not be true if the action clas-
sifier is not perfect, and one can contrive examples
in which an algorithm that makes several passes on
a sentence can actually make fewer actions than a
single pass algorithm. In practice, however, as our
experimental data shows, this is unlikely.
Lemma 1 A dependency parsing algorithm that
uses the Step Back policy completes the tree when
it reaches the end of the sentence for the first time.
In order to prove the algorithm we need the fol-
lowing definition. We call a pair of words (a, b) a
free pair if and only if there is a relation between
a and b and the algorithm can perform L or R ac-
tions on that pair when it is considered. Formally,
Definition 2 (free pair) A pair (a, b) considered
by the algorithm is a free pair, if it satisfies the
following conditions:
</bodyText>
<listItem confidence="0.9951888">
1. aHb
2. a, b are consecutive in T (not necessary in
the original sentence).
3. No other word in T is the child of a or b. (a
and b are now part of a complete subtree.)
</listItem>
<bodyText confidence="0.975119733333333">
Proof.: It is easy to see that there is at least one
free pair in T, with |T |&gt; 1. The reason is that
if no such pair exists, there must be three words
{a, b, c} s.t. a H b, a &lt; c &lt; b and -,(a —* c V
b —* c). However, this violates the properties of a
projective language.
Assume {a, b, d} are three consecutive words in
T. Now, we claim that when using Step Back, the
focus point is always to the left of all free pairs in
T. This is clearly true when the algorithm starts.
Assume that (a, b) is the first free pair in T and let
c be just to the left of a and b. Then, the algorithm
will not make a L or R action before the focus
point meets (a, b), and will make one of these ac-
tions then. It’s possible that (c, a V b) becomes a
free pair after removing a or b in T so we need
to move the focus point back. However, we also
know that there is no free pair to the left of c.
Therefore, during the algorithm, the focus point
will always remain to the left of all free pairs. So,
when we reach the end of the sentence, every free
pair in the sentence has been taken care of, and the
sentence has been completely parsed. ❑
Lemma 2 All actions made by a dependency
parsing algorithm that uses the Step Back policy
are necessary.
Proof.: We will show that a pair (a, b) will never
be considered again given the same situation, that
is, when there is no additional information about
relations a or b participate in. Note that if R or
</bodyText>
<page confidence="0.997177">
68
</page>
<bodyText confidence="0.999599894736842">
L is taken, either a or b will become a child word
and be eliminate from further consideration by the
algorithm. Therefore, if the action taken on (a, b)
is R or L, it will never be considered again.
Assume that the action taken is S, and, w.l.o.g.
that this is the rightmost S action taken before a
non-S action happens. Note that it is possible that
there is a relation between a and b, but we can-
not perform R or L now. Therefore, we should
consider (a, b) again only if a child of a or b has
changed. When Step Back is used, we will con-
sider (a, b) again only if the next action is L. (If
next action is R, b will be eliminated.) This is true
because the focus point will move back after per-
forming L, which implies that b has a new child
so we are indeed in a new situation. Since, from
Lemma 1, the algorithm only requires one round.
we therefore consider (a, b) again only if the situ-
ation has changed. ❑
</bodyText>
<subsectionHeader confidence="0.995878">
2.3 Improving the Parsing Action Set
</subsectionHeader>
<bodyText confidence="0.998683953488372">
In order to improve the accuracy of the action pre-
dictors, we suggest a new (hierarchical) set of ac-
tions: Shift, Left, Right, WaitLeft, WaitRight. We
believe that predicting these is easier due to finer
granularity – the S action is broken to sub-actions
in a natural way.
WaitLeft: a &lt; b. a is the parent of b, but it’s
possible that b is a parent of other nodes. Action is
deferred. If we perform Left instead, the child of b
can not find its parents later.
WaitRight: a &lt; b. b is the parent of a, but it’s
possible that a is a parent of other nodes. Similar
to WL, action is deferred.
Thus, we also change the algorithm to perform
S only if there is no relationship between a and b2.
The new set of actions is shown to better support
our parsing algorithm, when tested on different
placement policies. When WaitLeft or WaitRight
is performed, the focus will move to the next word.
It is very interesting to notice that WaitRight is
not needed in projective languages if Step Back
is used. This give us another strong reason to use
Step Back, since the classification becomes more
accurate – a more natural class of actions, with a
smaller number of candidate actions.
Once the parsing algorithm, along with the fo-
cus point policy, is determined, we can train the
2Interestingly, (Yamada and Matsumoto, 2003) mention
the possibility of an additional single Wait action, but do not
add it to the model.
action classifiers. Given an annotated corpus, the
parsing algorithm is used to determine the action
taken for each consecutive pair; this is used to train
a classifier to predict one of the five actions. The
details of the classifier and the feature used are
given in Section 4.
When the learned model is evaluated on new
data, the sentence is processed left to right and the
parsing algorithm, along with the action classifier,
are used to produce the dependency tree. The eval-
uation process is somewhat more involved, since
the action classifier is not used as is, but rather via
a look ahead inference step described next.
</bodyText>
<sectionHeader confidence="0.997826" genericHeader="method">
3 A Pipeline Model with Look Ahead
</sectionHeader>
<bodyText confidence="0.999954555555556">
The advantage of a pipeline model is that it can use
more information, based on the outcomes of previ-
ous predictions. As discussed earlier, this may re-
sult in accumulating error. The importance of hav-
ing a reliable action predictor in a pipeline model
motivates the following approach. We devise a
look ahead algorithm and use it as a look ahead
policy, when determining the predicted action.
This approach can be used in any pipeline
model but we illustrate it below in the context of
our dependency parser.
The following example illustrates a situation in
which an early mistake in predicting an action
causes a chain reaction and results in further mis-
takes. This stresses the importance of correct early
decisions, and motivates our look ahead policy.
Let (w, x, y, z) be a sentence of four words, and
assume that the correct dependency relations are
as shown in the top part of Figure 1. If the system
mistakenly predicts that x is a child of w before y
and z becomes x’s children, we can only consider
the relationship between w and y in the next stage.
Consequently, we will never find the correct parent
for y and z. The previous prediction error propa-
gates and impacts future predictions. On the other
hand, if the algorithm makes a correct prediction,
in the next stage, we do not need to consider w and
y. As shown, getting useful rather than misleading
information in a pipeline model, requires correct
early predictions. Therefore, it is necessary to uti-
lize some inference framework to that may help
resolving the error accumulation problem.
In order to improve the accuracy of the action
prediction, we might want to examine all possible
combinations of action sequences and choose the
one that maximizes some score. It is clearly in-
</bodyText>
<page confidence="0.998958">
69
</page>
<figureCaption confidence="0.980391">
Figure 1: Top figure: the correct dependency rela-
</figureCaption>
<bodyText confidence="0.970431604166667">
tions between w, x, y and z. Bottom figure: if the
algorithm mistakenly decides that x is a child of w
before deciding that y and z are x’s children, we
cannot find the correct parent for y and z.
tractable to find the global optimal prediction se-
quences in a pipeline model of the depth we con-
sider. Therefore, we use a look ahead strategy,
implemented via a local search framework, which
uses additional information but is still tractable.
The local search algorithm is presented in Algo-
rithm 3. The algorithm accepts three parameters,
model, depth and State. We assume a classifier
that can give a confidence in its prediction. This is
represented here by model.
As our learning algorithm we use a regularized
variation of the perceptron update rule, as incorpo-
rated in SNoW (Roth, 1998; Carlson et al., 1999),
a multi-class classifier that is tailored for large
scale learning tasks and has been used successfully
in a large number of NLP tasks (e.g., (Punyakanok
et al., 2005)). SNoW uses softmax over the raw
activation values as its confidence measure, which
can be shown to produce a reliable approximation
of the labels’ conditional probabilities.
The parameter depth is to determine the depth
of the search procedure. State encodes the config-
uration of the environment (in the context of the
dependency parsing this includes the sentence, the
focus point and the current parent and children for
each word). Note that State changes when a pre-
diction is made and that the features extracted for
the action classifier also depend on State.
The search algorithm will perform a search of
length depth. Additive scoring is used to score
the sequence, and the first action in this sequence
is selected and performed. Then, the State is up-
dated, the new features for the action classifiers are
computed and search is called again.
One interesting property of this framework is
that it allows that use of future information in ad-
dition to past information. The pipeline model nat-
urally allows access to all the past information.
Algorithm 3 Pseudo code for the look ahead algo-
rithm. y represents a action sequence. The func-
tion search considers all possible action sequences
with |depth |actions and returns the sequence with
the highest score.
Algo predictAction(model, depth, State)
</bodyText>
<equation confidence="0.943949666666667">
x = getNextFeature(State)
y = search(x, depth, model, State)
lab = y[1]
</equation>
<bodyText confidence="0.644874666666667">
State = update(State, lab)
return lab
Algo search(x, depth, model, State)
</bodyText>
<equation confidence="0.907563866666667">
maxScore = −oc
F = {y  |llyll = depth}
for y in F do
s = 0, TmpState = State
for i = 1... depth do
x = getNextFeature(TmpState)
s = s+ score(y[i], x, model)
TmpState = update(TmpState, y[i])
end for
if s &gt; maxScore then
y� = y
maxScore = s
end if
end for
return
</equation>
<bodyText confidence="0.999697615384615">
Since the algorithm uses a look ahead policy, it
also uses future predictions. The significance of
this becomes clear in Section 4.
There are several parameters, in addition to
depth that can be used to improve the efficiency of
the framework. For example, given that the action
predictor is a multi-class classifier, we do not need
to consider all future possibilities in order to de-
cide the current action. For example, in our exper-
iments, we only consider two actions with highest
score at each level (which was shown to produce
almost the same accuracy as considering all four
actions).
</bodyText>
<sectionHeader confidence="0.996058" genericHeader="method">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999887833333333">
We use the standard corpus for this task, the Penn
Treebank (Marcus et al., 1993). The training set
consists of sections 02 to 21 and the testing set is
section 23. The POS tags for the evaluation data
sets were provided by the tagger of (Toutanova et
al., 2003) (which has an accuracy of 97.2% section
</bodyText>
<figure confidence="0.698945222222222">
Y
W
Z
W
X
Y
Z
X
y�
</figure>
<page confidence="0.959303">
70
</page>
<subsectionHeader confidence="0.5758175">
23 of the Penn Treebank).
4.1 Features for Action Classification
</subsectionHeader>
<bodyText confidence="0.999955357142857">
For each word pair (w1, w2) we use the words,
their POS tags and also these features of the chil-
dren of w1 and w2. We also include the lexicon
and POS tags of 2 words before w1 and 4 words
after w2 (as in (Yamada and Matsumoto, 2003)).
The key additional feature we use, relative to (Ya-
mada and Matsumoto, 2003), is that we include
the previous predicted action as a feature. We
also add conjunctions of above features to ensure
expressiveness of the model. (Yamada and Mat-
sumoto, 2003) makes use of polynomial kernels
of degree 2 which is equivalent to using even more
conjunctive features. Overall, the average number
of active features in an example is about 50.
</bodyText>
<subsectionHeader confidence="0.772389">
4.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999924818181818">
We use the same evaluation metrics as in (McDon-
ald et al., 2005). Dependency accuracy (DA) is the
proportion of non-root words that are assigned the
correct head. Complete accuracy (CA) indicates
the fraction of sentences that have a complete cor-
rect analysis. We also measure that root accuracy
(RA) and leaf accuracy (LA), as in (Yamada and
Matsumoto, 2003). When evaluating the result,
we exclude the punctuation marks, as done in (Mc-
Donald et al., 2005) and (Yamada and Matsumoto,
2003).
</bodyText>
<subsectionHeader confidence="0.633852">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.98423765">
We present the results of several of the experi-
ments that were intended to help us analyze and
understand several of the design decisions in our
pipeline algorithm.
To see the effect of the additional action, we
present in Table 2 a comparison between a system
that does not have the WaitLeft action (similar
to the (Yamada and Matsumoto, 2003) approach)
with one that does. In both cases, we do not use the
look ahead procedure. Note that, as stated above,
the action WaitRight is never needed for our pars-
ing algorithm. It is clear that adding WaitLeft in-
creases the accuracy significantly.
Table 3 investigates the effect of the look ahead,
and presents results with different depth param-
eters (depth= 1 means “no search”), showing a
consistent trend of improvement.
Table 4 breaks down the results as a function
of the sentence length; it is especially noticeable
that the system also performs very well for long
</bodyText>
<table confidence="0.994652">
method DA RA CA LA
w/o WaitLeft 90.27 90.73 39.28 93.87
w WaitLeft 90.53 90.76 39.74 93.94
</table>
<tableCaption confidence="0.994679">
Table 2: The significant of the action WaitLeft.
</tableCaption>
<table confidence="0.9944136">
method DA RA CA LA
depth=1 90.53 90.76 39.74 93.94
depth=2 90.67 91.51 40.23 93.96
depth=3 90.69 92.05 40.52 93.94
depth=4 90.79 92.26 40.68 93.95
</table>
<tableCaption confidence="0.999966">
Table 3: The effect of different depth settings.
</tableCaption>
<bodyText confidence="0.99606725">
sentences, another indication for its global perfor-
mance robustness.
Table 5 shows the results with three settings of
the POS tagger. The best result is, naturally, when
we use the gold standard also in testing. How-
ever, it is worthwhile noticing that it is better to
train with the same POS tagger available in test-
ing, even if its performance is somewhat lower.
Table 6 compares the performances of several
of the state of the art dependency parsing systems
with ours. When comparing with other depen-
dency parsing systems it is especially worth notic-
ing that our system gives significantly better accu-
racy on completely parsed sentences.
Interestingly, in the experiments, we allow the
parsing algorithm to run many rounds to parse a
sentece in the testing stage. However, we found
that over 99% sentences can be parsed in a single
round. This supports for our justification about the
correctness of our model.
</bodyText>
<sectionHeader confidence="0.99786" genericHeader="method">
5 Further Work and Conclusion
</sectionHeader>
<bodyText confidence="0.999791555555555">
We have addressed the problem of using learned
classifiers in a pipeline fashion, where a task is de-
composed into several stages and stage classifiers
are used sequentially, where each stage may use
the outcome of previous stages as its input. This
is a common computational strategy in natural lan-
guage processing and is known to suffer from error
accumulation and an inability to correct mistakes
in previous stages.
</bodyText>
<table confidence="0.979388">
Sent. Len. DA RA CA LA
&lt;11 93.4 96.7 85.2 94.6
11-20 92.4 93.7 56.1 94.7
21-30 90.4 91.8 32.5 93.4
31-40 90.4 89.8 16.8 94.0
&gt;40 89.7 87.9 8.7 93.3
</table>
<tableCaption confidence="0.9818575">
Table 4: The effect of sentences length. The ex-
periment is done with depth = 4.
</tableCaption>
<page confidence="0.978848">
71
</page>
<table confidence="0.99978775">
Train-Test DA RA CA LA
gold−pos 90.7 92.0 40.8 93.8
pos−pos 90.8 92.3 40.7 94.0
gold−gold 92.0 93.9 43.6 95.0
</table>
<tableCaption confidence="0.966999">
Table 5: Comparing different sources of POS tag-
ging in a pipeline model. We set depth= 4 in all
the experiments of this table.
</tableCaption>
<table confidence="0.9996764">
System DA RA CA LA
Y&amp;M03 90.3 91.6 38.4 93.5
N&amp;S04 87.3 84.3 30.4 N/A
M&amp;C&amp;P05 90.9 94.2 37.5 N/A
Current Work 90.8 92.3 40.7 94.0
</table>
<tableCaption confidence="0.9397875">
Table 6: The comparison between the current
work with other dependency parsing systems.
</tableCaption>
<bodyText confidence="0.999991583333333">
We abstracted two natural principles, one which
calls for making the local classifiers used in the
computation more reliable and a second, which
suggests to devise the pipeline algorithm in such
a way that minimizes the number of decisions (ac-
tions) made.
We study this framework in the context of de-
signing a bottom up dependency parsing. Not only
we manage to use this framework to justify several
design decisions, but we also show experimentally
that following these results in improving the accu-
racy of the inferred trees relative to existing mod-
els. Interestingly, we can show that the trees pro-
duced by our algorithm are relatively good even
for long sentences, and that our algorithm is do-
ing especially well when evaluated globally, at a
sentence level, where our results are significantly
better than those of existing approaches – perhaps
showing that the design goals were achieved.
Our future work includes trying to generalize
this work to non-projective dependency parsing,
as well as attempting to incorporate additional
sources of information (e.g., shallow parsing in-
formation) into the pipeline process.
</bodyText>
<sectionHeader confidence="0.999457" genericHeader="conclusions">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.995319375">
We thank Ryan McDonald for providing the anno-
tated data set and to Vasin Punyakanok for useful
comments and suggestions.
This research is supported by the Advanced
Research and Development Activity (ARDA)’s
Advanced Question Answering for Intelligence
(AQUAINT) Program and a DOI grant under the
Reflex program.
</bodyText>
<sectionHeader confidence="0.995993" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999805368421052">
A. V. Aho, R. Sethi, and J. D. Ullman. 1986. Compilers:
Principles, techniques, and tools. In Addison-Wesley Pub-
lishing Company, Reading, MA.
A. Carlson, C. Cumby, J. Rosen, and D. Roth. 1999.
The SNoW learning architecture. Technical Report
UIUCDCS-R-99-2101, UIUC Computer Science Depart-
ment, May.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: An exploration. In Proc. the Inter-
national Conference on Computational Linguistics (COL-
ING), pages 340–345, Copenhagen, August.
A. Haghighi, A. Ng, and C. Manning. 2005. Robust textual
inference via graph matching. In Proceedings of Human
Language Technology Conference and Conference on Em-
pirical Methods in Natural Language Processing, pages
387–394, Vancouver, British Columbia, Canada, October.
Association for Computational Linguistics.
T. Marciniak and M. Strube. 2005. Beyond the pipeline: Dis-
crete optimization in NLP. In Proceedings of the Ninth
Conference on Computational Natural Language Learn-
ing (CoNLL-2005), pages 136–143, Ann Arbor, Michigan,
June. Association for Computational Linguistics.
M. P. Marcus, B. Santorini, and M. Marcinkiewicz. 1993.
Building a large annotated corpus of English: The Penn
Treebank. Computational Linguistics, 19(2):313–330,
June.
R. McDonald, K. Crammer, and F. Pereira. 2005. Online
large-margin training of dependency parsers. In Proc. of
the Annual Meeting of the ACL, pages 91–98, Ann Arbor,
Michigan.
J. Nivre and M. Scholz. 2004. Deterministic dependency
parsing of english text. In COLING2004, pages 64–70.
Joakim Nivre. 2003. An efficient algorithm for projective
dependency parsing. In IWPT, Nancy, France.
V. Punyakanok, D. Roth, and W. Yih. 2005. The necessity
of syntactic parsing for semantic role labeling. In Proc.
of the International Joint Conference on Artificial Intelli-
gence (IJCAI), pages 1117–1123.
A. Ratnaparkhi. 1997. A linear observed time statistical
parser based on maximum entropy models. In EMNLP-
97, The Second Conference on Empirical Methods in Nat-
ural Language Processing, pages 1–10.
D. Roth and W. Yih. 2004. A linear programming for-
mulation for global inference in natural language tasks.
In Hwee Tou Ng and Ellen Riloff, editors, Proc. of the
Annual Conference on Computational Natural Language
Learning (CoNLL), pages 1–8. Association for Computa-
tional Linguistics.
D. Roth. 1998. Learning to resolve natural language ambi-
guities: A unified approach. In Proc. National Conference
on Artificial Intelligence, pages 806–813.
K. Toutanova, D. Klein, and C. Manning. ”2003”. Feature-
rich part-of-speech tagging with a cyclic dependency net-
work. In Proceedings of HLT-NAACL 03.
H. Yamada and Y. Matsumoto. 2003. Statistical dependency
analysis with support vector machines. In IWPT2003.
H. Yamada. 2006. Private communication.
</reference>
<page confidence="0.998715">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.902262">
<title confidence="0.999956">A Pipeline Framework for Dependency Parsing</title>
<author confidence="0.999954">Ming-Wei Chang Quang Do Dan Roth</author>
<affiliation confidence="0.9999235">Department of Computer Science University of Illinois at Urbana-Champaign</affiliation>
<address confidence="0.985168">Urbana, IL 61801</address>
<email confidence="0.912432">quangdo2,</email>
<abstract confidence="0.99972435">Pipeline computation, in which a task is decomposed into several stages that are solved sequentially, is a common computational strategy in natural language processing. The key problem of this model is that it results in error accumulation and suffers from its inability to correct mistakes in previous stages. We develop a framework for decisions made via in pipeline models, which addresses these difficulties, and presents and evaluates it the context of up dependency English. We show improvements in the accuracy of the inferred trees relative to existing models. Interestingly, the proposed algorithm shines especially when evaluated globally, at a sentence level, where our results are significantly better than those of existing approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>R Sethi</author>
<author>J D Ullman</author>
</authors>
<date>1986</date>
<booktitle>Compilers: Principles, techniques, and tools. In</booktitle>
<publisher>Addison-Wesley Publishing Company,</publisher>
<location>Reading, MA.</location>
<contexts>
<context position="5977" citStr="Aho et al., 1986" startWordPosition="959" endWordPosition="962">nerative algorithm – embarked the interest in this area. His model, however, seems to be limited when dealing with complex and long sentences. (McDonald et al., 2005) build on this work, and use a global discriminative training approach to improve the edges’ scores, along with Eisner’s algorithm, to yield the expected improvement. A different approach was studied by (Yamada and Matsumoto, 2003), that develop a bottom-up approach and learn the parsing decisions between consecutive words in the sentence. Local actions are used to generate a dependency tree using a shift-reduce parsing approach (Aho et al., 1986). This is a true pipeline approach, as was done in other successful parsers, e.g. (Ratnaparkhi, 1997), in that the classifiers are trained on individual decisions rather than on the overall quality of the parser, and chained to yield the global structure. Clearly, it suffers from the limitations of pipeline processing, such as accumulation of errors, but nevertheless, yields very competitive parsing results. A somewhat similar approach was used in (Nivre and Scholz, 2004) to develop a hybrid bottom-up/topdown approach; there, the edges are also labeled with semantic types, yielding lower accur</context>
</contexts>
<marker>Aho, Sethi, Ullman, 1986</marker>
<rawString>A. V. Aho, R. Sethi, and J. D. Ullman. 1986. Compilers: Principles, techniques, and tools. In Addison-Wesley Publishing Company, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Carlson</author>
<author>C Cumby</author>
<author>J Rosen</author>
<author>D Roth</author>
</authors>
<title>The SNoW learning architecture.</title>
<date>1999</date>
<tech>Technical Report UIUCDCS-R-99-2101,</tech>
<institution>UIUC Computer Science Department,</institution>
<contexts>
<context position="22753" citStr="Carlson et al., 1999" startWordPosition="4019" endWordPosition="4022">nd z. tractable to find the global optimal prediction sequences in a pipeline model of the depth we consider. Therefore, we use a look ahead strategy, implemented via a local search framework, which uses additional information but is still tractable. The local search algorithm is presented in Algorithm 3. The algorithm accepts three parameters, model, depth and State. We assume a classifier that can give a confidence in its prediction. This is represented here by model. As our learning algorithm we use a regularized variation of the perceptron update rule, as incorporated in SNoW (Roth, 1998; Carlson et al., 1999), a multi-class classifier that is tailored for large scale learning tasks and has been used successfully in a large number of NLP tasks (e.g., (Punyakanok et al., 2005)). SNoW uses softmax over the raw activation values as its confidence measure, which can be shown to produce a reliable approximation of the labels’ conditional probabilities. The parameter depth is to determine the depth of the search procedure. State encodes the configuration of the environment (in the context of the dependency parsing this includes the sentence, the focus point and the current parent and children for each wo</context>
</contexts>
<marker>Carlson, Cumby, Rosen, Roth, 1999</marker>
<rawString>A. Carlson, C. Cumby, J. Rosen, and D. Roth. 1999. The SNoW learning architecture. Technical Report UIUCDCS-R-99-2101, UIUC Computer Science Department, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proc. the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>340--345</pages>
<location>Copenhagen,</location>
<contexts>
<context position="5004" citStr="Eisner, 1996" startWordPosition="802" endWordPosition="803">of the parsing algorithm – which edges to consider at any point of time. We prove that our control policy is optimal in some sense, and that the decisions we made, guided by these, principles lead to a significant improvement in the accuracy of the resulting parse tree. 1.1 Dependency Parsing and Pipeline Models Dependency trees provide a syntactic reresentation that encodes functional relationships between words; it is relatively independent of the grammar theory and can be used to represent the structure of sentences in different languages. Dependency structures are more efficient to parse (Eisner, 1996) and are believed to be easier to learn, yet they still capture much of the predicate-argument information needed in applications (Haghighi et al., 2005), which is one reason for the recent interest in learning these structures (Eisner, 1996; McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). Eisner’s work – O(n3) parsing time generative algorithm – embarked the interest in this area. His model, however, seems to be limited when dealing with complex and long sentences. (McDonald et al., 2005) build on this work, and use a global discriminative training approach to impr</context>
<context position="6971" citStr="Eisner, 1996" startWordPosition="1128" endWordPosition="1129">y competitive parsing results. A somewhat similar approach was used in (Nivre and Scholz, 2004) to develop a hybrid bottom-up/topdown approach; there, the edges are also labeled with semantic types, yielding lower accuracy than the works mentioned above. The overall goal of dependency parsing (DP) learning is to infer a tree structure. A common way to do that is to predict with respect to each potential edge (i, j) in the tree, and then choose a global structure that (1) is a tree and that (2) maximizes some score. In the context of DPs, this “edge based factorization method” was proposed by (Eisner, 1996). In other contexts, this is similar to the approach of (Roth and Yih, 2004) in that scoring each edge depends only on the raw data observed and not on the classifications of other edges, and that global considerations can be used to overwrite the local (edge-based) decisions. On the other hand, the key in a pipeline model is that making a decision with respect to the edge (i, j) may gain from taking into account decisions already made with respect to neighboring edges. However, given that these decisions are noisy, there is a need to devise policies for reducing the number of predictions in o</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. the International Conference on Computational Linguistics (COLING), pages 340–345, Copenhagen, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>A Ng</author>
<author>C Manning</author>
</authors>
<title>Robust textual inference via graph matching.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>387--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="5157" citStr="Haghighi et al., 2005" startWordPosition="824" endWordPosition="827"> decisions we made, guided by these, principles lead to a significant improvement in the accuracy of the resulting parse tree. 1.1 Dependency Parsing and Pipeline Models Dependency trees provide a syntactic reresentation that encodes functional relationships between words; it is relatively independent of the grammar theory and can be used to represent the structure of sentences in different languages. Dependency structures are more efficient to parse (Eisner, 1996) and are believed to be easier to learn, yet they still capture much of the predicate-argument information needed in applications (Haghighi et al., 2005), which is one reason for the recent interest in learning these structures (Eisner, 1996; McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). Eisner’s work – O(n3) parsing time generative algorithm – embarked the interest in this area. His model, however, seems to be limited when dealing with complex and long sentences. (McDonald et al., 2005) build on this work, and use a global discriminative training approach to improve the edges’ scores, along with Eisner’s algorithm, to yield the expected improvement. A different approach was studied by (Yamada and Matsumoto, 2003)</context>
</contexts>
<marker>Haghighi, Ng, Manning, 2005</marker>
<rawString>A. Haghighi, A. Ng, and C. Manning. 2005. Robust textual inference via graph matching. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 387–394, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Marciniak</author>
<author>M Strube</author>
</authors>
<title>Beyond the pipeline: Discrete optimization in NLP.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005),</booktitle>
<pages>136--143</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="2482" citStr="Marciniak and Strube, 2005" startWordPosition="394" endWordPosition="397">rocessing for good reasons. It is based on the assumption that some decisions might be easier or more reliable than others, and their outcomes, therefore, can be counted on when making further decisions. Nevertheless, it is clear that it results in error accumulation and suffers from its inability to correct mistakes in previous stages. Researchers have recently started to address some of the disadvantages of this model. E.g., (Roth and Yih, 2004) suggests a model in which global constraints are taken into account in a later stage to fix mistakes due to the pipeline. (Punyakanok et al., 2005; Marciniak and Strube, 2005) also address some aspects of this problem. However, these solutions rely on the fact that all decisions are made with respect to the same input; specifically, all classifiers considered use the same examples as their input. In addition, the pipelines they study are shallow. This paper develops a general framework for decisions in pipeline models which addresses these difficulties. Specifically, we are interested in deep pipelines – a large number of predictions that are being chained. A pipeline process is one in which decisions made in the ith stage (1) depend on earlier decisions and (2) fe</context>
</contexts>
<marker>Marciniak, Strube, 2005</marker>
<rawString>T. Marciniak and M. Strube. 2005. Beyond the pipeline: Discrete optimization in NLP. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 136–143, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="12644" citStr="Marcus et al., 1993" startWordPosition="2158" endWordPosition="2161">, the pair (a, b) is reconsidered, but with new information, since now it is known that c is the child of b. Although this seems wasteful, we will show this is a necessary movement to reduce the number of actions. As mentioned above, each of these policies yields the correct tree. Table 1 compares the three policies in terms of the number of actions required to build a tree. Policy #Shift #Left #Right Start over 156545 26351 27918 Stay 117819 26351 27918 Step back 43374 26351 27918 Table 1: The number of actions required to build all the trees for the sentences in section 23 of Penn Treebank (Marcus et al., 1993) as a function of the focus point placement policy. The statistics are taken with the correct (gold-standard) actions. It is clear from Table 1 that the policies result &apos;Note that (Yamada and Matsumoto, 2003) mention that they move the focus point back after R, but do not state what they do after executing L actions, and why. (Yamada, 2006) indicates that they also move focus point back after L. 67 Algorithm 2 Pseudo Code of the dependency parsing algorithm. getFeatures extracts the features describing the word pair currently considered; getAction determines the appropriate action for the pair</context>
<context position="25332" citStr="Marcus et al., 1993" startWordPosition="4459" endWordPosition="4462"> The significance of this becomes clear in Section 4. There are several parameters, in addition to depth that can be used to improve the efficiency of the framework. For example, given that the action predictor is a multi-class classifier, we do not need to consider all future possibilities in order to decide the current action. For example, in our experiments, we only consider two actions with highest score at each level (which was shown to produce almost the same accuracy as considering all four actions). 4 Experiments and Results We use the standard corpus for this task, the Penn Treebank (Marcus et al., 1993). The training set consists of sections 02 to 21 and the testing set is section 23. The POS tags for the evaluation data sets were provided by the tagger of (Toutanova et al., 2003) (which has an accuracy of 97.2% section Y W Z W X Y Z X y� 70 23 of the Penn Treebank). 4.1 Features for Action Classification For each word pair (w1, w2) we use the words, their POS tags and also these features of the children of w1 and w2. We also include the lexicon and POS tags of 2 words before w1 and 4 words after w2 (as in (Yamada and Matsumoto, 2003)). The key additional feature we use, relative to (Yamada </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. P. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc. of the Annual Meeting of the ACL,</booktitle>
<pages>91--98</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="5268" citStr="McDonald et al., 2005" startWordPosition="843" endWordPosition="846">ng parse tree. 1.1 Dependency Parsing and Pipeline Models Dependency trees provide a syntactic reresentation that encodes functional relationships between words; it is relatively independent of the grammar theory and can be used to represent the structure of sentences in different languages. Dependency structures are more efficient to parse (Eisner, 1996) and are believed to be easier to learn, yet they still capture much of the predicate-argument information needed in applications (Haghighi et al., 2005), which is one reason for the recent interest in learning these structures (Eisner, 1996; McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). Eisner’s work – O(n3) parsing time generative algorithm – embarked the interest in this area. His model, however, seems to be limited when dealing with complex and long sentences. (McDonald et al., 2005) build on this work, and use a global discriminative training approach to improve the edges’ scores, along with Eisner’s algorithm, to yield the expected improvement. A different approach was studied by (Yamada and Matsumoto, 2003), that develop a bottom-up approach and learn the parsing decisions between consecutive words in the sentence. </context>
<context position="26386" citStr="McDonald et al., 2005" startWordPosition="4655" endWordPosition="4659">include the lexicon and POS tags of 2 words before w1 and 4 words after w2 (as in (Yamada and Matsumoto, 2003)). The key additional feature we use, relative to (Yamada and Matsumoto, 2003), is that we include the previous predicted action as a feature. We also add conjunctions of above features to ensure expressiveness of the model. (Yamada and Matsumoto, 2003) makes use of polynomial kernels of degree 2 which is equivalent to using even more conjunctive features. Overall, the average number of active features in an example is about 50. 4.2 Evaluation We use the same evaluation metrics as in (McDonald et al., 2005). Dependency accuracy (DA) is the proportion of non-root words that are assigned the correct head. Complete accuracy (CA) indicates the fraction of sentences that have a complete correct analysis. We also measure that root accuracy (RA) and leaf accuracy (LA), as in (Yamada and Matsumoto, 2003). When evaluating the result, we exclude the punctuation marks, as done in (McDonald et al., 2005) and (Yamada and Matsumoto, 2003). 4.3 Results We present the results of several of the experiments that were intended to help us analyze and understand several of the design decisions in our pipeline algori</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-margin training of dependency parsers. In Proc. of the Annual Meeting of the ACL, pages 91–98, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>M Scholz</author>
</authors>
<title>Deterministic dependency parsing of english text.</title>
<date>2004</date>
<booktitle>In COLING2004,</booktitle>
<pages>64--70</pages>
<contexts>
<context position="5321" citStr="Nivre and Scholz, 2004" startWordPosition="851" endWordPosition="854">Models Dependency trees provide a syntactic reresentation that encodes functional relationships between words; it is relatively independent of the grammar theory and can be used to represent the structure of sentences in different languages. Dependency structures are more efficient to parse (Eisner, 1996) and are believed to be easier to learn, yet they still capture much of the predicate-argument information needed in applications (Haghighi et al., 2005), which is one reason for the recent interest in learning these structures (Eisner, 1996; McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). Eisner’s work – O(n3) parsing time generative algorithm – embarked the interest in this area. His model, however, seems to be limited when dealing with complex and long sentences. (McDonald et al., 2005) build on this work, and use a global discriminative training approach to improve the edges’ scores, along with Eisner’s algorithm, to yield the expected improvement. A different approach was studied by (Yamada and Matsumoto, 2003), that develop a bottom-up approach and learn the parsing decisions between consecutive words in the sentence. Local actions are used to generate a dependency tree </context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>J. Nivre and M. Scholz. 2004. Deterministic dependency parsing of english text. In COLING2004, pages 64–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In IWPT,</booktitle>
<location>Nancy, France.</location>
<contexts>
<context position="9084" citStr="Nivre, 2003" startWordPosition="1495" endWordPosition="1496">s a pipeline model. We pro66 pose an improved pipeline framework based on the mentioned principles. For many languages such as English, Chinese and Japanese (with a few exceptions), projective dependency trees (that is, DPs without edge crossings) are sufficient to analyze most sentences. Our work is therefore concerned only with projective trees, which we define below. For words x, y in the sentence T we introduce the following notations: x —* y: x is the direct parent of y. x —** y: x is an ancestor of y; xHy:x—*yory—*x. x &lt; y: x is to the left of y in T. Definition 1 (Projective Language) (Nivre, 2003) ba, b, c E T, a H b and a &lt; c &lt; b imply that a —** c or b —** c. 2.1 A Pipeline DP Algorithm Our parsing algorithm is a modified shift-reduce parser that makes use of the actions described below and applies them in a left to right manner on consecutive pairs of words (a, b) (a &lt; b) in the sentence. This is a bottom-up approach that uses machine learning algorithms to learn the parsing decisions (actions) between consecutive words in the sentences. The basic actions used in this model, as in (Yamada and Matsumoto, 2003), are: Shift: there is no relation between a and b, or the action is deferr</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In IWPT, Nancy, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>The necessity of syntactic parsing for semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<pages>1117--1123</pages>
<contexts>
<context position="1396" citStr="Punyakanok et al., 2005" startWordPosition="208" endWordPosition="211">es relative to existing models. Interestingly, the proposed algorithm shines especially when evaluated globally, at a sentence level, where our results are significantly better than those of existing approaches. 1 Introduction A pipeline process over the decisions of learned classifiers is a common computational strategy in natural language processing. In this model a task is decomposed into several stages that are solved sequentially, where the computation in the ith stage typically depends on the outcome of computations done in previous stages. For example, a semantic role labeling program (Punyakanok et al., 2005) may start by using a part-of-speech tagger, then apply a shallow parser to chunk the sentence into phrases, identify predicates and arguments and then classify them to types. In fact, any left to right processing of an English sentence may be viewed as a pipeline computation as it processes a token and, potentially, makes use of this result when processing the token to the right. The pipeline model is a standard model of computation in natural language processing for good reasons. It is based on the assumption that some decisions might be easier or more reliable than others, and their outcome</context>
<context position="22922" citStr="Punyakanok et al., 2005" startWordPosition="4047" endWordPosition="4050"> a local search framework, which uses additional information but is still tractable. The local search algorithm is presented in Algorithm 3. The algorithm accepts three parameters, model, depth and State. We assume a classifier that can give a confidence in its prediction. This is represented here by model. As our learning algorithm we use a regularized variation of the perceptron update rule, as incorporated in SNoW (Roth, 1998; Carlson et al., 1999), a multi-class classifier that is tailored for large scale learning tasks and has been used successfully in a large number of NLP tasks (e.g., (Punyakanok et al., 2005)). SNoW uses softmax over the raw activation values as its confidence measure, which can be shown to produce a reliable approximation of the labels’ conditional probabilities. The parameter depth is to determine the depth of the search procedure. State encodes the configuration of the environment (in the context of the dependency parsing this includes the sentence, the focus point and the current parent and children for each word). Note that State changes when a prediction is made and that the features extracted for the action classifier also depend on State. The search algorithm will perform </context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2005</marker>
<rawString>V. Punyakanok, D. Roth, and W. Yih. 2005. The necessity of syntactic parsing for semantic role labeling. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI), pages 1117–1123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A linear observed time statistical parser based on maximum entropy models.</title>
<date>1997</date>
<booktitle>In EMNLP97, The Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="6078" citStr="Ratnaparkhi, 1997" startWordPosition="978" endWordPosition="979">n dealing with complex and long sentences. (McDonald et al., 2005) build on this work, and use a global discriminative training approach to improve the edges’ scores, along with Eisner’s algorithm, to yield the expected improvement. A different approach was studied by (Yamada and Matsumoto, 2003), that develop a bottom-up approach and learn the parsing decisions between consecutive words in the sentence. Local actions are used to generate a dependency tree using a shift-reduce parsing approach (Aho et al., 1986). This is a true pipeline approach, as was done in other successful parsers, e.g. (Ratnaparkhi, 1997), in that the classifiers are trained on individual decisions rather than on the overall quality of the parser, and chained to yield the global structure. Clearly, it suffers from the limitations of pipeline processing, such as accumulation of errors, but nevertheless, yields very competitive parsing results. A somewhat similar approach was used in (Nivre and Scholz, 2004) to develop a hybrid bottom-up/topdown approach; there, the edges are also labeled with semantic types, yielding lower accuracy than the works mentioned above. The overall goal of dependency parsing (DP) learning is to infer </context>
</contexts>
<marker>Ratnaparkhi, 1997</marker>
<rawString>A. Ratnaparkhi. 1997. A linear observed time statistical parser based on maximum entropy models. In EMNLP97, The Second Conference on Empirical Methods in Natural Language Processing, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Hwee Tou Ng and Ellen Riloff, editors, Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>1--8</pages>
<publisher>Association for Computational Linguistics.</publisher>
<contexts>
<context position="2306" citStr="Roth and Yih, 2004" startWordPosition="364" endWordPosition="367">s a token and, potentially, makes use of this result when processing the token to the right. The pipeline model is a standard model of computation in natural language processing for good reasons. It is based on the assumption that some decisions might be easier or more reliable than others, and their outcomes, therefore, can be counted on when making further decisions. Nevertheless, it is clear that it results in error accumulation and suffers from its inability to correct mistakes in previous stages. Researchers have recently started to address some of the disadvantages of this model. E.g., (Roth and Yih, 2004) suggests a model in which global constraints are taken into account in a later stage to fix mistakes due to the pipeline. (Punyakanok et al., 2005; Marciniak and Strube, 2005) also address some aspects of this problem. However, these solutions rely on the fact that all decisions are made with respect to the same input; specifically, all classifiers considered use the same examples as their input. In addition, the pipelines they study are shallow. This paper develops a general framework for decisions in pipeline models which addresses these difficulties. Specifically, we are interested in deep</context>
<context position="7047" citStr="Roth and Yih, 2004" startWordPosition="1140" endWordPosition="1143"> (Nivre and Scholz, 2004) to develop a hybrid bottom-up/topdown approach; there, the edges are also labeled with semantic types, yielding lower accuracy than the works mentioned above. The overall goal of dependency parsing (DP) learning is to infer a tree structure. A common way to do that is to predict with respect to each potential edge (i, j) in the tree, and then choose a global structure that (1) is a tree and that (2) maximizes some score. In the context of DPs, this “edge based factorization method” was proposed by (Eisner, 1996). In other contexts, this is similar to the approach of (Roth and Yih, 2004) in that scoring each edge depends only on the raw data observed and not on the classifications of other edges, and that global considerations can be used to overwrite the local (edge-based) decisions. On the other hand, the key in a pipeline model is that making a decision with respect to the edge (i, j) may gain from taking into account decisions already made with respect to neighboring edges. However, given that these decisions are noisy, there is a need to devise policies for reducing the number of predictions in order to make the parser more robust. This is exemplified in (Yamada and Mats</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Hwee Tou Ng and Ellen Riloff, editors, Proc. of the Annual Conference on Computational Natural Language Learning (CoNLL), pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
</authors>
<title>Learning to resolve natural language ambiguities: A unified approach.</title>
<date>1998</date>
<booktitle>In Proc. National Conference on Artificial Intelligence,</booktitle>
<pages>806--813</pages>
<contexts>
<context position="22730" citStr="Roth, 1998" startWordPosition="4017" endWordPosition="4018">rent for y and z. tractable to find the global optimal prediction sequences in a pipeline model of the depth we consider. Therefore, we use a look ahead strategy, implemented via a local search framework, which uses additional information but is still tractable. The local search algorithm is presented in Algorithm 3. The algorithm accepts three parameters, model, depth and State. We assume a classifier that can give a confidence in its prediction. This is represented here by model. As our learning algorithm we use a regularized variation of the perceptron update rule, as incorporated in SNoW (Roth, 1998; Carlson et al., 1999), a multi-class classifier that is tailored for large scale learning tasks and has been used successfully in a large number of NLP tasks (e.g., (Punyakanok et al., 2005)). SNoW uses softmax over the raw activation values as its confidence measure, which can be shown to produce a reliable approximation of the labels’ conditional probabilities. The parameter depth is to determine the depth of the search procedure. State encodes the configuration of the environment (in the context of the dependency parsing this includes the sentence, the focus point and the current parent a</context>
</contexts>
<marker>Roth, 1998</marker>
<rawString>D. Roth. 1998. Learning to resolve natural language ambiguities: A unified approach. In Proc. National Conference on Artificial Intelligence, pages 806–813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C Manning</author>
</authors>
<title>Featurerich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL 03.</booktitle>
<contexts>
<context position="25513" citStr="Toutanova et al., 2003" startWordPosition="4493" endWordPosition="4496"> given that the action predictor is a multi-class classifier, we do not need to consider all future possibilities in order to decide the current action. For example, in our experiments, we only consider two actions with highest score at each level (which was shown to produce almost the same accuracy as considering all four actions). 4 Experiments and Results We use the standard corpus for this task, the Penn Treebank (Marcus et al., 1993). The training set consists of sections 02 to 21 and the testing set is section 23. The POS tags for the evaluation data sets were provided by the tagger of (Toutanova et al., 2003) (which has an accuracy of 97.2% section Y W Z W X Y Z X y� 70 23 of the Penn Treebank). 4.1 Features for Action Classification For each word pair (w1, w2) we use the words, their POS tags and also these features of the children of w1 and w2. We also include the lexicon and POS tags of 2 words before w1 and 4 words after w2 (as in (Yamada and Matsumoto, 2003)). The key additional feature we use, relative to (Yamada and Matsumoto, 2003), is that we include the previous predicted action as a feature. We also add conjunctions of above features to ensure expressiveness of the model. (Yamada and Ma</context>
</contexts>
<marker>Toutanova, Klein, Manning, 2003</marker>
<rawString>K. Toutanova, D. Klein, and C. Manning. ”2003”. Featurerich part-of-speech tagging with a cyclic dependency network. In Proceedings of HLT-NAACL 03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>Y Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In IWPT2003.</booktitle>
<contexts>
<context position="3981" citStr="Yamada and Matsumoto, 2003" startWordPosition="636" endWordPosition="639">endency parsing. We suggest that two principles to guide the pipeline algorithm development: (i) Make local decisions as reliable as possible. (ii) Reduce the number of decisions made. Using these as guidelines we devise an algo65 Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 65–72, Sydney, July 2006. c�2006 Association for Computational Linguistics rithm for dependency parsing, prove that it satisfies these principles, and show experimentally that this improves the accuracy of the resulting tree. Specifically, our approach is based on a shiftreduced parsing as in (Yamada and Matsumoto, 2003). Our general framework provides insights that allow us to improve their algorithm, and to principally justify some of the algorithmic decisions. Specifically, the first principle suggests to improve the reliability of the local predictions, which we do by improving the set of actions taken by the parsing algorithm, and by using a lookahead search. The second principle is used to justify the control policy of the parsing algorithm – which edges to consider at any point of time. We prove that our control policy is optimal in some sense, and that the decisions we made, guided by these, principle</context>
<context position="5296" citStr="Yamada and Matsumoto, 2003" startWordPosition="847" endWordPosition="850">ndency Parsing and Pipeline Models Dependency trees provide a syntactic reresentation that encodes functional relationships between words; it is relatively independent of the grammar theory and can be used to represent the structure of sentences in different languages. Dependency structures are more efficient to parse (Eisner, 1996) and are believed to be easier to learn, yet they still capture much of the predicate-argument information needed in applications (Haghighi et al., 2005), which is one reason for the recent interest in learning these structures (Eisner, 1996; McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). Eisner’s work – O(n3) parsing time generative algorithm – embarked the interest in this area. His model, however, seems to be limited when dealing with complex and long sentences. (McDonald et al., 2005) build on this work, and use a global discriminative training approach to improve the edges’ scores, along with Eisner’s algorithm, to yield the expected improvement. A different approach was studied by (Yamada and Matsumoto, 2003), that develop a bottom-up approach and learn the parsing decisions between consecutive words in the sentence. Local actions are used to ge</context>
<context position="7659" citStr="Yamada and Matsumoto, 2003" startWordPosition="1247" endWordPosition="1251"> and Yih, 2004) in that scoring each edge depends only on the raw data observed and not on the classifications of other edges, and that global considerations can be used to overwrite the local (edge-based) decisions. On the other hand, the key in a pipeline model is that making a decision with respect to the edge (i, j) may gain from taking into account decisions already made with respect to neighboring edges. However, given that these decisions are noisy, there is a need to devise policies for reducing the number of predictions in order to make the parser more robust. This is exemplified in (Yamada and Matsumoto, 2003) – a bottom-up approach, that is most related to the work presented here. Their model is a “traditional” pipeline model – a classifier suggests a decision that, once taken, determines the next action to be taken (as well as the input the next action observes). In the rest of this paper, we propose and justify a framework for improving pipeline processing based on the principles mentioned above: (i) make local decisions as reliably as possible, and (ii) reduce the number of decisions made. We use the proposed principles to examine the (Yamada and Matsumoto, 2003) parsing algorithm and show that</context>
<context position="9609" citStr="Yamada and Matsumoto, 2003" startWordPosition="1596" endWordPosition="1599">y; xHy:x—*yory—*x. x &lt; y: x is to the left of y in T. Definition 1 (Projective Language) (Nivre, 2003) ba, b, c E T, a H b and a &lt; c &lt; b imply that a —** c or b —** c. 2.1 A Pipeline DP Algorithm Our parsing algorithm is a modified shift-reduce parser that makes use of the actions described below and applies them in a left to right manner on consecutive pairs of words (a, b) (a &lt; b) in the sentence. This is a bottom-up approach that uses machine learning algorithms to learn the parsing decisions (actions) between consecutive words in the sentences. The basic actions used in this model, as in (Yamada and Matsumoto, 2003), are: Shift: there is no relation between a and b, or the action is deferred because the relationship between a and b cannot be determined at this point. Right: b is the parent of a, Left: a is the parent of b. This is a true pipeline approach in that the classifiers are trained on individual decisions rather than on the overall quality of the parsing, and chained to yield the global structure. And, clearly, decisions make with respect to a pair of words affect what is considered next by the algorithm. In order to complete the description of the algorithm we need to describe which edge to con</context>
<context position="12852" citStr="Yamada and Matsumoto, 2003" startWordPosition="2192" endWordPosition="2195"> of actions. As mentioned above, each of these policies yields the correct tree. Table 1 compares the three policies in terms of the number of actions required to build a tree. Policy #Shift #Left #Right Start over 156545 26351 27918 Stay 117819 26351 27918 Step back 43374 26351 27918 Table 1: The number of actions required to build all the trees for the sentences in section 23 of Penn Treebank (Marcus et al., 1993) as a function of the focus point placement policy. The statistics are taken with the correct (gold-standard) actions. It is clear from Table 1 that the policies result &apos;Note that (Yamada and Matsumoto, 2003) mention that they move the focus point back after R, but do not state what they do after executing L actions, and why. (Yamada, 2006) indicates that they also move focus point back after L. 67 Algorithm 2 Pseudo Code of the dependency parsing algorithm. getFeatures extracts the features describing the word pair currently considered; getAction determines the appropriate action for the pair; assignParent assigns a parent for the child word based on the action; and deleteWord deletes the child word in T at the focus once the action is taken. Let t represents for a word token For sentence T = {t1</context>
<context position="19385" citStr="Yamada and Matsumoto, 2003" startWordPosition="3435" endWordPosition="3438">b2. The new set of actions is shown to better support our parsing algorithm, when tested on different placement policies. When WaitLeft or WaitRight is performed, the focus will move to the next word. It is very interesting to notice that WaitRight is not needed in projective languages if Step Back is used. This give us another strong reason to use Step Back, since the classification becomes more accurate – a more natural class of actions, with a smaller number of candidate actions. Once the parsing algorithm, along with the focus point policy, is determined, we can train the 2Interestingly, (Yamada and Matsumoto, 2003) mention the possibility of an additional single Wait action, but do not add it to the model. action classifiers. Given an annotated corpus, the parsing algorithm is used to determine the action taken for each consecutive pair; this is used to train a classifier to predict one of the five actions. The details of the classifier and the feature used are given in Section 4. When the learned model is evaluated on new data, the sentence is processed left to right and the parsing algorithm, along with the action classifier, are used to produce the dependency tree. The evaluation process is somewhat </context>
<context position="25874" citStr="Yamada and Matsumoto, 2003" startWordPosition="4569" endWordPosition="4572">lts We use the standard corpus for this task, the Penn Treebank (Marcus et al., 1993). The training set consists of sections 02 to 21 and the testing set is section 23. The POS tags for the evaluation data sets were provided by the tagger of (Toutanova et al., 2003) (which has an accuracy of 97.2% section Y W Z W X Y Z X y� 70 23 of the Penn Treebank). 4.1 Features for Action Classification For each word pair (w1, w2) we use the words, their POS tags and also these features of the children of w1 and w2. We also include the lexicon and POS tags of 2 words before w1 and 4 words after w2 (as in (Yamada and Matsumoto, 2003)). The key additional feature we use, relative to (Yamada and Matsumoto, 2003), is that we include the previous predicted action as a feature. We also add conjunctions of above features to ensure expressiveness of the model. (Yamada and Matsumoto, 2003) makes use of polynomial kernels of degree 2 which is equivalent to using even more conjunctive features. Overall, the average number of active features in an example is about 50. 4.2 Evaluation We use the same evaluation metrics as in (McDonald et al., 2005). Dependency accuracy (DA) is the proportion of non-root words that are assigned the cor</context>
<context position="27170" citStr="Yamada and Matsumoto, 2003" startWordPosition="4787" endWordPosition="4790"> that have a complete correct analysis. We also measure that root accuracy (RA) and leaf accuracy (LA), as in (Yamada and Matsumoto, 2003). When evaluating the result, we exclude the punctuation marks, as done in (McDonald et al., 2005) and (Yamada and Matsumoto, 2003). 4.3 Results We present the results of several of the experiments that were intended to help us analyze and understand several of the design decisions in our pipeline algorithm. To see the effect of the additional action, we present in Table 2 a comparison between a system that does not have the WaitLeft action (similar to the (Yamada and Matsumoto, 2003) approach) with one that does. In both cases, we do not use the look ahead procedure. Note that, as stated above, the action WaitRight is never needed for our parsing algorithm. It is clear that adding WaitLeft increases the accuracy significantly. Table 3 investigates the effect of the look ahead, and presents results with different depth parameters (depth= 1 means “no search”), showing a consistent trend of improvement. Table 4 breaks down the results as a function of the sentence length; it is especially noticeable that the system also performs very well for long method DA RA CA LA w/o Wait</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>H. Yamada and Y. Matsumoto. 2003. Statistical dependency analysis with support vector machines. In IWPT2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
</authors>
<date>2006</date>
<note>Private communication.</note>
<contexts>
<context position="12986" citStr="Yamada, 2006" startWordPosition="2219" endWordPosition="2220">ns required to build a tree. Policy #Shift #Left #Right Start over 156545 26351 27918 Stay 117819 26351 27918 Step back 43374 26351 27918 Table 1: The number of actions required to build all the trees for the sentences in section 23 of Penn Treebank (Marcus et al., 1993) as a function of the focus point placement policy. The statistics are taken with the correct (gold-standard) actions. It is clear from Table 1 that the policies result &apos;Note that (Yamada and Matsumoto, 2003) mention that they move the focus point back after R, but do not state what they do after executing L actions, and why. (Yamada, 2006) indicates that they also move focus point back after L. 67 Algorithm 2 Pseudo Code of the dependency parsing algorithm. getFeatures extracts the features describing the word pair currently considered; getAction determines the appropriate action for the pair; assignParent assigns a parent for the child word based on the action; and deleteWord deletes the child word in T at the focus once the action is taken. Let t represents for a word token For sentence T = {t1, t2, ... , tn} focus= 1 while focus&lt; |T |do V = getFeatures(tfocus, tfocus+1) α = getAction(tfocus, tfocus+1,v) if α = L or α = R the</context>
</contexts>
<marker>Yamada, 2006</marker>
<rawString>H. Yamada. 2006. Private communication.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>