<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000068">
<note confidence="0.793429">
Computational Linguistics Volume 27, Number 1
</note>
<title confidence="0.982598">
Construing Experience through Meaning: A Language-based
Approach to Cognition
</title>
<figure confidence="0.638340571428571">
M. A. K. Halliday and Christian M. I. M. Matthiessen
London: Cassell (Open linguistics
series, edited by Robin Fawcett), 1999,
xiii+657 pp; paperback, ISBN
0-304-70490-3, $102.00, £65.00
Reviewed by
John F. Sowa
</figure>
<bodyText confidence="0.9936773125">
Michael Alexander Kirkwood Halliday has been actively analyzing and documenting
the interactions between syntax and semantics for over forty years, and his systemic—
functional theory has been a foundation for important work in computational linguis-
tics for at least thirty years. The first major application of systemic theory was the
SHRDLU system by Winograd (1972). The largest ongoing series of applications has
been developed at the USC Information Sciences Institute: language generation (Mann
1982; Hovy 1988); discourse analysis and rhetorical structure (Mann and Thompson
1992); and the interface between the lexicon and world knowledge (Bateman et al.
1990; Matthiessen 1995).
In this book, Halliday and Matthiessen present a comprehensive survey of seman-
tics and its relationships to syntax and cognition. Although they present their subject
from a systemic—functional point of view, they show how their approach is related
to a wide range of work in both computational and theoretical linguistics. One no-
table omission from their 23-page bibliography is Noam Chomsky, whose period of
active research almost exactly coincides with Halliday&apos;s. They do, however, give a fair
summary of semantic theories based on Chomsky&apos;s approach, ranging from the early
work of Katz and Fodor to the more recent work by Jackendoff.
The book consists of 15 chapters organized in five parts. In Part I, the authors
contrast the systemic approach with a view of knowledge representation as a &amp;quot;piece-
meal accumulation&amp;quot; of concepts with &amp;quot;no overall organization.&amp;quot; Instead of treating
language &amp;quot;as a kind of code in which pre-existing conceptual structures are more or
less distortedly expressed,&amp;quot; they view language as a semiotic system that serves &amp;quot;as
the foundation of human experience.&amp;quot; The goal of systemic theory is to present a
comprehensive view of how humans construe experience through language. Unlike
Chomsky, they do not consider grammar as &amp;quot;autonomous&amp;quot; but as an integral part of
the lexicogrammar, which realizes meaning in words, phrases, sentences, and para-
graphs.
Part II, comprising Chapters 2 through 7, presents the meaning base, which cor-
responds to what many authors would call an ontology. The meaning base, however,
represents categories of experience with a topmost node called phenomenon instead
of categories of existence with a topmost node called entity. The first subdivision of
phenomena is a three-way partitioning according to levels of complexity:
</bodyText>
<footnote confidence="0.85339875">
1. Elementary ideas or elements are realized by the lexicogrammar as
words or short groups of words, such as rain, from the west, or 8
hard-boiled eggs. Computationally, elements may be represented by slots
in a frame, nodes in a graph, or typed variables in logic.
</footnote>
<page confidence="0.979164">
140
</page>
<figure confidence="0.481802">
Book Reviews
</figure>
<listItem confidence="0.996761444444444">
2. Configurations of elements or figures are realized by phrases or clauses,
such as rain ending from the west or chop finely. Computationally, a figure
may be represented by various data structures, such as a frame, list, or
graph.
3. Complexes of figures or sequences are realized by complex sentences or
paragraphs, such as Take 8 hard-boiled eggs, chop finely, mash with 3
tablespoons of soft butter, and add salt and pepper. Computationally, a
sequence could be represented by a network of frames, a list of lists, a
graph of graphs, or structures of objects in an object-oriented language.
</listItem>
<bodyText confidence="0.995428925">
Each of these categories is further divided and subdivided by various distinctions,
some dyadic and some triadic. Elements are classified as participant, circumstance, or
process. Figures are classified by another triad of relational (being or having), material
(doing or happening), and mental (sensing or saying). These categories are further
elaborated and illustrated with numerous examples. To demonstrate the generality of
the approach, Chapter 7 shows how the semantic categories realized in English can
also be realized in Chinese and other languages.
Part III consists of two chapters that show how the theory can be implemented
in a computational system for language generation, with examples of weather reports
and cooking recipes. Part IV consists of three chapters that compare the theoretical
and descriptive techniques of systemic—functional theory to other approaches. The
concluding Part V consists of three chapters that apply systemic theory to an analysis
of how humans construe experience through language. Chapter 14 has an intriguing
analysis of the evolution of linguistic expressions from folk theories to scientific theo-
ries. Instead of drawing a sharp dichotomy between commonsense and scientific ways
of thinking, the authors show how the basic linguistic mechanisms of abstraction and
metaphor are used to systematize and formalize scientific language. Metaphor is fun-
damental to both science and poetry. The primary difference is that poets constantly
strive to create novel metaphors, while scientists recycle, perfect, and build on the
most successful of their colleagues&apos; metaphors.
In summary, this book makes a strong case for the systemic approach as a fruitful
alternative to Chomsky&apos;s view of autonomous syntax. The authors demonstrate that
semantics has important structures that are cross-linguistic and formalizable. Although
they present their data with the terminology, notation, and viewpoint of the systemic—
functional approach, their analyses, distinctions, and categories can be adapted to
semantic theories based on other approaches.
The authors criticize the logic-based, model-theoretic approaches for their limited
ontologies and neglect of important aspects of language, such as metaphor. Yet logi-
cians recognize the need for richer ontologies, and many, if not most, would agree that
semantics is the proper starting point for a study of natural language. The authors try
to draw a sharp distinction between the deductive methods of logic and the method
of inheritance used in frame-based systems. A logician, however, would reply that
inheritance is the oldest of all rules of inference; it was introduced by Aristotle for
syllogisms, and it is a derived rule in every modern system of logic. The methods of
unification used in many logic-based systems implement inheritance in ways that are
equivalent to or more general than frame systems. Rather than being a competitor, the
systemic approach can be a valuable complement to the logic-based approaches.
The authors consider language as a semiotic system, but they only mention the
dyadic version of semiotics developed by Saussure and linguists influenced by Saus-
sure, such as Hjelmslev and Firth. Peirce analyzed the sign relation in greater depth
</bodyText>
<page confidence="0.987233">
141
</page>
<note confidence="0.631567">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.99841905">
than Saussure and emphasized its irreducible triadic nature. Although Halliday and
Mattheissen never mention Peirce, they have rediscovered many of Peirce&apos;s triads in
their systemic analysis (Peirce 1991-1998). Their choice of phenomenon as the most
general category is an unconscious endorsement of Peirce&apos;s point that his categories
were primarily phenomenological rather than ontological. The systemic triad of being—
having, doing—happening, and sensing—saying corresponds to Peirce&apos;s fundamental
triad of Quality, Reaction, and Representation. Most of the other triads in the systemic
meaning base also have a strong Peircean flavor, and a more conscious application of
Peirce&apos;s version of semiotics might help clarify and refine many of the triadic distinc-
tions in the systemic approach.
Perhaps the least attractive feature of the book is its formatting. The authors used
a conventional word processor to print camera-ready copy on A4 paper, which the
publisher reproduced without change. The result is a heavy, unwieldy tome with a
great deal of wasted paper, a generally unfinished appearance, but a price tag of $102.
With that price and format, the book is destined to sell very few copies, the authors
will get little or nothing in royalties, the publisher&apos;s high price will seem to be justified,
and a potentially important book will never be read by students who might profit from
it. The book would get better distribution if the authors had simply put the electronic
version on their Web site; better yet, professional societies such as the ACL should put
books such as these on their Web sites.
</bodyText>
<sectionHeader confidence="0.843565" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.6193823">
Bateman, John A., Robert Kasper, Johanna
Moore, and Richard Whitney. 1990. A
general organization of knowledge for
natural language processing: The Penman
upper model. Research Report.
Information Sciences Institute, University
of Southern California, Marina del Rey.
Hovy, Eduard H. 1988. Generating Natural
Language under Pragmatic Constraints.
Lawrence Erlbaum, Hillsdale, NJ.
</reference>
<figureCaption confidence="0.939360294117647">
Mann, William C. 1982. An overview of the
Penman text generation system. Research
Report 83-114. Information Sciences
Institute, University of Southern
California, Marina del Rey.
Mann, William C., and Sandra A.
Thompson, editors. 1992. Discourse
Description: Diverse Linguistic Analysis of a
Fund-Raising Text. Benjamins, Amsterdam.
Matthiessen, Christian M. I. M. 1995.
Lexicogrammatical Cartography: English
Systems. International Language Sciences
Publishers, Tokyo.
Peirce, C. S. 1991-1998. The Essential Peirce,
volumes 1 and 2. Nathan Houser and
Christian Kloesel, editors. Indiana
University Press, Bloomington.
</figureCaption>
<bodyText confidence="0.887803375">
Winograd, Terry 1972. Understanding Natural
Language. Academic Press, New York.
John F. Sowa worked for 30 years on research and development projects at IBM. Since then, he
has been teaching, writing, and consulting. He has published and edited several books and
numerous articles on knowledge representation, computational linguistics, and related areas of
artificial intelligence. He is a Fellow of the AAAI, best known for his work on the theory of con-
ceptual graphs and their application to natural language semantics. E-mail: sowa@bestweb.net;
URL: www.bestweb.net/r,sowa / direct!.
</bodyText>
<page confidence="0.993265">
142
</page>
<table confidence="0.805183928571429">
Book Reviews
Computing Meaning, volume 1
Harry Bunt and Reinhard Muskens (editors)
(Tilburg University)
Dordrecht: Kluwer Academic
Publishers (Studies in linguistics and
philosophy, edited by Gennaro
Chierchia, Pauline Jacobson, and
Francis J. Pelletier, volume 73), 1999,
vi+360 pp; hardbound, ISBN
0-7923-6108-3, $149.00, £93.00, Dfl
280.00
Reviewed by
Yoad Winter
</table>
<affiliation confidence="0.347194">
Technion—Israel Institute of Technology
</affiliation>
<bodyText confidence="0.814548866666667">
Manipulating meanings of natural language texts and utterances is one of the main
objectives of any large-scale NLP system. However, at present there is no general
theory that explains what natural language meanings precisely are, and how they
are to be effectively computed for purposes of practical NLP. Moreover, in the first
place there is not even an overall agreement as to a general notion of &amp;quot;meaning&amp;quot;
that is computationally relevant. Two prominent approaches to the question can be
recognized.
1. The machine learning approach: In this view, meanings should be
defined according to whatever representation practical NLP systems find
useful. For instance, if a system is to extract travel information from free
text, then meanings in this context can be defined as records in a
database containing fields such as &amp;quot;destination&amp;quot;, &amp;quot;time of arrival&amp;quot;,
&amp;quot;means of transportation&amp;quot;, etc. Such a representation has to be defined
ad hoc for any relevant purpose, but the mapping from natural language
to this formal representation is performed automatically using general
learning algorithms.
2. The formal semantics approach: According to this line, meanings are
logical objects and should be manipulated using logical tools. Work in
the formal-semantic school that developed from Montague grammar
specifies the logically relevant parts of meaning and how to derive them
from a natural language input, while the field of computational
semantics deals with the algorithmic realization of these formal
techniques as NLP systems.
The volume under review is a collection of 16 articles that adopt the second view
as their starting point. In a clear and instructive introduction, the editors present an
overview of the formal approach to the computation of meaning, illustrate it using a
small calculus, and discuss a number of general problems for this approach. Of special
importance is the ambiguity problem: the spurious multiplicity of meanings that even
the most sophisticated syntactic and semantic theories derive. The construction of
underspecified representations of meaning, which is one of the prominent techniques
</bodyText>
<page confidence="0.996021">
143
</page>
<note confidence="0.707563">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.999905633333333">
for tackling the ambiguity problem, is addressed from different angles by five of the
articles in the volume. Another prominent issue in computational semantics is the
dynamic nature of many natural language phenomena, especially those related to
anaphora and presupposition. Six articles in this volume address dynamic semantics
from different perspectives. The other articles in the book deal with different topics
in semantics: compositionality, speech events, belief utterances, motion verbs, and the
interpretation of German compounds.
These topics are vast and highly varied, and a fair description of even the core
ideas in these papers is impossible within the space limits of this review. (A good
overview of the articles in this volume can be found in the introduction.) Many of
the works have important implications for formal semantics or theoretical linguistics,
but those papers that are most relevant for computational linguistics are those that
succeed in extending an existing computational framework to treat phenomena that
it had not previously handled. One such contribution is the paper by Richter and
Sailer, who develop an underspecified semantics in HPSG. Of similar significance is
an interesting paper by Van Genabith and Crouch, who give a semantics of cross-
sentential anaphora using LFG glue language semantics. Other papers would be of
interest mainly to theoretical linguists or to logicians and philosophers of language.
Good examples of works of the first kind are a paper by Ginzburg on ellipsis resolution
and a paper by Stone and Hardt on the anaphoric properties of modals. Examples of
more logically oriented papers are the contribution by Meyer Viol et al. on the use
of epsilon terms for underspecified semantics and the paper by Asher and Fernando
on underspecification using labeled representations. Although these works do not
give algorithmic implementations of their ideas, they include enough formal details
to make small but illustrative computer applications feasible. The book also contains
two articles of a more programmatic nature: on underspecified semantics (by Pinkal)
and on compositionality and minimum description length (by Zadrozny). These works
and others would be of interest to any researcher occupied with problems of natural
language semantics from a formal or computational perspective.
It is also important to make clear what the book does not include:
</bodyText>
<listItem confidence="0.756731714285714">
• It does not provide a unified framework. To understand many of the
proposals in this book, the reader has to become familiar with a
considerable number of notations, techniques, and theoretical
standpoints, sometimes with no real justification for this variety.
• The book does not contain contributions that would be of direct
relevance to the NLP engineer who is especially interested in the
development of practical &amp;quot;real-world&amp;quot; applications.
</listItem>
<bodyText confidence="0.999828166666667">
In general, the editors did a good job in projecting a collection of works repre-
senting the state of the art in computational semantics. The book contains material
that will be of value especially to experts in this field. However, most of the papers in
the volume will also be relevant to researchers from other branches of computational
linguistics who are interested in theoretical aspects of the computation of meaning in
natural language.
</bodyText>
<sectionHeader confidence="0.894756" genericHeader="keywords">
Acknowledgment
</sectionHeader>
<reference confidence="0.94526">
Work on this review was partly supported
by a visit grant from NVVO (the Netherlands
Organization for Scientific Research).
</reference>
<page confidence="0.988752">
144
</page>
<reference confidence="0.9718855">
Book Reviews
Yoad Winter works on problems of formal and computational semantics. He worked at the
IBM Research Lab in Haifa and he is currently a lecturer at the computer science faculty at
the Technion, Haifa. His book Flexibility Principles in Boolean Semantics is to be published by
The MIT Press. Winter&apos;s address is Computer Science, Technion, Haifa 32000, Israel; e-mail:
winter@cs.technion.ac.il.
</reference>
<page confidence="0.9988">
145
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000304">
<title confidence="0.934396666666667">Computational Linguistics Volume 27, Number 1 Construing Experience through Meaning: A Language-based Approach to Cognition</title>
<author confidence="0.995946">M A K Halliday</author>
<author confidence="0.995946">Christian M I M Matthiessen</author>
<note confidence="0.9691832">London: Cassell (Open linguistics series, edited by Robin Fawcett), 1999, xiii+657 pp; paperback, ISBN 0-304-70490-3, $102.00, £65.00 Reviewed by</note>
<author confidence="0.862086">John F Sowa Michael Alexander Kirkwood Halliday has been actively analyzing</author>
<author confidence="0.862086">documenting</author>
<abstract confidence="0.997478509259259">the interactions between syntax and semantics for over forty years, and his systemic— functional theory has been a foundation for important work in computational linguistics for at least thirty years. The first major application of systemic theory was the SHRDLU system by Winograd (1972). The largest ongoing series of applications has been developed at the USC Information Sciences Institute: language generation (Mann 1982; Hovy 1988); discourse analysis and rhetorical structure (Mann and Thompson 1992); and the interface between the lexicon and world knowledge (Bateman et al. 1990; Matthiessen 1995). In this book, Halliday and Matthiessen present a comprehensive survey of semantics and its relationships to syntax and cognition. Although they present their subject from a systemic—functional point of view, they show how their approach is related to a wide range of work in both computational and theoretical linguistics. One noomission from their bibliography is Noam Chomsky, whose of active research almost exactly coincides with Halliday&apos;s. They do, however, give a fair summary of semantic theories based on Chomsky&apos;s approach, ranging from the early work of Katz and Fodor to the more recent work by Jackendoff. The book consists of 15 chapters organized in five parts. In Part I, the authors contrast the systemic approach with a view of knowledge representation as a &amp;quot;piecemeal accumulation&amp;quot; of concepts with &amp;quot;no overall organization.&amp;quot; Instead of treating language &amp;quot;as a kind of code in which pre-existing conceptual structures are more or less distortedly expressed,&amp;quot; they view language as a semiotic system that serves &amp;quot;as the foundation of human experience.&amp;quot; The goal of systemic theory is to present a comprehensive view of how humans construe experience through language. Unlike Chomsky, they do not consider grammar as &amp;quot;autonomous&amp;quot; but as an integral part of in words, phrases, sentences, and paragraphs. II, comprising Chapters 2 through 7, presents the base, corresponds to what many authors would call an ontology. The meaning base, however, categories of experience with a topmost node called categories of existence with a topmost node called first subdivision of phenomena is a three-way partitioning according to levels of complexity: Elementary ideas or realized by the lexicogrammar as or short groups of words, such as from the west, eggs. elements may be represented by slots in a frame, nodes in a graph, or typed variables in logic. 140 Book Reviews 2. Configurations of elements or figures are realized by phrases or as ending from the west finely. a figure may be represented by various data structures, such as a frame, list, or graph. 3. Complexes of figures or sequences are realized by complex sentences such as 8 hard-boiled eggs, chop finely, mash with 3 of soft butter, and add salt and pepper. a sequence could be represented by a network of frames, a list of lists, a graph of graphs, or structures of objects in an object-oriented language. Each of these categories is further divided and subdivided by various distinctions, some dyadic and some triadic. Elements are classified as participant, circumstance, or process. Figures are classified by another triad of relational (being or having), material (doing or happening), and mental (sensing or saying). These categories are further elaborated and illustrated with numerous examples. To demonstrate the generality of the approach, Chapter 7 shows how the semantic categories realized in English can also be realized in Chinese and other languages. Part III consists of two chapters that show how the theory can be implemented in a computational system for language generation, with examples of weather reports and cooking recipes. Part IV consists of three chapters that compare the theoretical and descriptive techniques of systemic—functional theory to other approaches. The concluding Part V consists of three chapters that apply systemic theory to an analysis of how humans construe experience through language. Chapter 14 has an intriguing analysis of the evolution of linguistic expressions from folk theories to scientific theories. Instead of drawing a sharp dichotomy between commonsense and scientific ways of thinking, the authors show how the basic linguistic mechanisms of abstraction and metaphor are used to systematize and formalize scientific language. Metaphor is fundamental to both science and poetry. The primary difference is that poets constantly strive to create novel metaphors, while scientists recycle, perfect, and build on the most successful of their colleagues&apos; metaphors. In summary, this book makes a strong case for the systemic approach as a fruitful alternative to Chomsky&apos;s view of autonomous syntax. The authors demonstrate that semantics has important structures that are cross-linguistic and formalizable. Although they present their data with the terminology, notation, and viewpoint of the systemic— functional approach, their analyses, distinctions, and categories can be adapted to semantic theories based on other approaches. The authors criticize the logic-based, model-theoretic approaches for their limited ontologies and neglect of important aspects of language, such as metaphor. Yet logicians recognize the need for richer ontologies, and many, if not most, would agree that semantics is the proper starting point for a study of natural language. The authors try to draw a sharp distinction between the deductive methods of logic and the method of inheritance used in frame-based systems. A logician, however, would reply that inheritance is the oldest of all rules of inference; it was introduced by Aristotle for syllogisms, and it is a derived rule in every modern system of logic. The methods of unification used in many logic-based systems implement inheritance in ways that are equivalent to or more general than frame systems. Rather than being a competitor, the systemic approach can be a valuable complement to the logic-based approaches. The authors consider language as a semiotic system, but they only mention the dyadic version of semiotics developed by Saussure and linguists influenced by Saussure, such as Hjelmslev and Firth. Peirce analyzed the sign relation in greater depth 141 Computational Linguistics Volume 27, Number 1 than Saussure and emphasized its irreducible triadic nature. Although Halliday and Mattheissen never mention Peirce, they have rediscovered many of Peirce&apos;s triads in their systemic analysis (Peirce 1991-1998). Their choice of phenomenon as the most general category is an unconscious endorsement of Peirce&apos;s point that his categories were primarily phenomenological rather than ontological. The systemic triad of being— having, doing—happening, and sensing—saying corresponds to Peirce&apos;s fundamental triad of Quality, Reaction, and Representation. Most of the other triads in the systemic meaning base also have a strong Peircean flavor, and a more conscious application of Peirce&apos;s version of semiotics might help clarify and refine many of the triadic distinctions in the systemic approach. Perhaps the least attractive feature of the book is its formatting. The authors used a conventional word processor to print camera-ready copy on A4 paper, which the publisher reproduced without change. The result is a heavy, unwieldy tome with a great deal of wasted paper, a generally unfinished appearance, but a price tag of $102. With that price and format, the book is destined to sell very few copies, the authors will get little or nothing in royalties, the publisher&apos;s high price will seem to be justified, and a potentially important book will never be read by students who might profit from it. The book would get better distribution if the authors had simply put the electronic version on their Web site; better yet, professional societies such as the ACL should put books such as these on their Web sites.</abstract>
<affiliation confidence="0.315933">References</affiliation>
<address confidence="0.607572">Bateman, John A., Robert Kasper, Johanna Moore, and Richard Whitney. 1990. A</address>
<abstract confidence="0.733523">general organization of knowledge for natural language processing: The Penman upper model. Research Report.</abstract>
<affiliation confidence="0.601593">Information Sciences Institute, University</affiliation>
<address confidence="0.262906">of Southern California, Marina del Rey.</address>
<note confidence="0.977907833333333">Eduard H. 1988. Natural Language under Pragmatic Constraints. Lawrence Erlbaum, Hillsdale, NJ. Mann, William C. 1982. An overview of the Penman text generation system. Research Report 83-114. Information Sciences</note>
<affiliation confidence="0.844302">Institute, University of Southern California, Marina del Rey.</affiliation>
<address confidence="0.719139">Mann, William C., and Sandra A.</address>
<note confidence="0.810103">editors. 1992. Description: Diverse Linguistic Analysis of a Text. Amsterdam. Matthiessen, Christian M. I. M. 1995. Lexicogrammatical Cartography: English Language Sciences Publishers, Tokyo. C. S. 1991-1998. Essential Peirce, volumes 1 and 2. Nathan Houser and Christian Kloesel, editors. Indiana University Press, Bloomington. Terry 1972. Natural Press, New York. F. Sowa for 30 years on research and development projects at IBM. Since then, he</note>
<abstract confidence="0.9628042">has been teaching, writing, and consulting. He has published and edited several books and numerous articles on knowledge representation, computational linguistics, and related areas of artificial intelligence. He is a Fellow of the AAAI, best known for his work on the theory of conceptual graphs and their application to natural language semantics. E-mail: sowa@bestweb.net; / direct!.</abstract>
<note confidence="0.579128">142</note>
<title confidence="0.9068325">Book Reviews Computing Meaning, volume 1</title>
<author confidence="0.988382">Harry Bunt</author>
<author confidence="0.988382">Reinhard Muskens</author>
<affiliation confidence="0.88003">(Tilburg University) Dordrecht: Kluwer Academic Publishers (Studies in linguistics and</affiliation>
<note confidence="0.762867714285714">philosophy, edited by Gennaro Chierchia, Pauline Jacobson, and Francis J. Pelletier, volume 73), 1999, vi+360 pp; hardbound, ISBN 0-7923-6108-3, $149.00, £93.00, Dfl 280.00 Reviewed by</note>
<author confidence="0.96917">Yoad Winter</author>
<affiliation confidence="0.984409">Technion—Israel Institute of Technology</affiliation>
<abstract confidence="0.998460347826087">Manipulating meanings of natural language texts and utterances is one of the main objectives of any large-scale NLP system. However, at present there is no general theory that explains what natural language meanings precisely are, and how they are to be effectively computed for purposes of practical NLP. Moreover, in the first place there is not even an overall agreement as to a general notion of &amp;quot;meaning&amp;quot; that is computationally relevant. Two prominent approaches to the question can be recognized. 1. The machine learning approach: In this view, meanings should be defined according to whatever representation practical NLP systems find useful. For instance, if a system is to extract travel information from free text, then meanings in this context can be defined as records in a database containing fields such as &amp;quot;destination&amp;quot;, &amp;quot;time of arrival&amp;quot;, &amp;quot;means of transportation&amp;quot;, etc. Such a representation has to be defined ad hoc for any relevant purpose, but the mapping from natural language to this formal representation is performed automatically using general learning algorithms. 2. The formal semantics approach: According to this line, meanings are logical objects and should be manipulated using logical tools. Work in the formal-semantic school that developed from Montague grammar specifies the logically relevant parts of meaning and how to derive them from a natural language input, while the field of computational semantics deals with the algorithmic realization of these formal techniques as NLP systems.</abstract>
<intro confidence="0.749157">The volume under review is a collection of 16 articles that adopt the second view</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John A Bateman</author>
<author>Robert Kasper</author>
<author>Johanna Moore</author>
<author>Richard Whitney</author>
</authors>
<title>A general organization of knowledge for natural language processing: The Penman upper model. Research Report.</title>
<date>1990</date>
<institution>Information Sciences Institute, University of Southern California, Marina del Rey.</institution>
<contexts>
<context position="1003" citStr="Bateman et al. 1990" startWordPosition="141" endWordPosition="144">ively analyzing and documenting the interactions between syntax and semantics for over forty years, and his systemic— functional theory has been a foundation for important work in computational linguistics for at least thirty years. The first major application of systemic theory was the SHRDLU system by Winograd (1972). The largest ongoing series of applications has been developed at the USC Information Sciences Institute: language generation (Mann 1982; Hovy 1988); discourse analysis and rhetorical structure (Mann and Thompson 1992); and the interface between the lexicon and world knowledge (Bateman et al. 1990; Matthiessen 1995). In this book, Halliday and Matthiessen present a comprehensive survey of semantics and its relationships to syntax and cognition. Although they present their subject from a systemic—functional point of view, they show how their approach is related to a wide range of work in both computational and theoretical linguistics. One notable omission from their 23-page bibliography is Noam Chomsky, whose period of active research almost exactly coincides with Halliday&apos;s. They do, however, give a fair summary of semantic theories based on Chomsky&apos;s approach, ranging from the early w</context>
</contexts>
<marker>Bateman, Kasper, Moore, Whitney, 1990</marker>
<rawString>Bateman, John A., Robert Kasper, Johanna Moore, and Richard Whitney. 1990. A general organization of knowledge for natural language processing: The Penman upper model. Research Report. Information Sciences Institute, University of Southern California, Marina del Rey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
</authors>
<title>Generating Natural Language under Pragmatic Constraints. Lawrence Erlbaum,</title>
<date>1988</date>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="853" citStr="Hovy 1988" startWordPosition="121" endWordPosition="122">, 1999, xiii+657 pp; paperback, ISBN 0-304-70490-3, $102.00, £65.00 Reviewed by John F. Sowa Michael Alexander Kirkwood Halliday has been actively analyzing and documenting the interactions between syntax and semantics for over forty years, and his systemic— functional theory has been a foundation for important work in computational linguistics for at least thirty years. The first major application of systemic theory was the SHRDLU system by Winograd (1972). The largest ongoing series of applications has been developed at the USC Information Sciences Institute: language generation (Mann 1982; Hovy 1988); discourse analysis and rhetorical structure (Mann and Thompson 1992); and the interface between the lexicon and world knowledge (Bateman et al. 1990; Matthiessen 1995). In this book, Halliday and Matthiessen present a comprehensive survey of semantics and its relationships to syntax and cognition. Although they present their subject from a systemic—functional point of view, they show how their approach is related to a wide range of work in both computational and theoretical linguistics. One notable omission from their 23-page bibliography is Noam Chomsky, whose period of active research almo</context>
</contexts>
<marker>Hovy, 1988</marker>
<rawString>Hovy, Eduard H. 1988. Generating Natural Language under Pragmatic Constraints. Lawrence Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="false">
<title>Work on this review was partly supported by a visit grant from NVVO (the Netherlands Organization for Scientific Research).</title>
<marker></marker>
<rawString>Work on this review was partly supported by a visit grant from NVVO (the Netherlands Organization for Scientific Research).</rawString>
</citation>
<citation valid="false">
<title>Book Reviews Yoad Winter works on problems of formal and computational semantics. He worked at the IBM Research Lab in Haifa and he is currently a lecturer at the computer science faculty at the Technion, Haifa. His book Flexibility Principles in Boolean Semantics is to be published by The MIT Press. Winter&apos;s address is Computer Science, Technion,</title>
<date></date>
<location>Haifa 32000,</location>
<note>e-mail: winter@cs.technion.ac.il.</note>
<marker></marker>
<rawString>Book Reviews Yoad Winter works on problems of formal and computational semantics. He worked at the IBM Research Lab in Haifa and he is currently a lecturer at the computer science faculty at the Technion, Haifa. His book Flexibility Principles in Boolean Semantics is to be published by The MIT Press. Winter&apos;s address is Computer Science, Technion, Haifa 32000, Israel; e-mail: winter@cs.technion.ac.il.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>