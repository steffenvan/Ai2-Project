<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000226">
<title confidence="0.965607">
Global Learning of Typed Entailment Rules
</title>
<author confidence="0.991238">
Jonathan Berant Ido Dagan Jacob Goldberger
</author>
<affiliation confidence="0.980038">
Tel Aviv University Bar-Ilan University Bar-Ilan University
</affiliation>
<address confidence="0.488272">
Tel Aviv, Israel Ramat-Gan, Israel Ramat-Gan, Israel
</address>
<email confidence="0.991732">
jonatha6@post.tau.ac.il dagan@cs.biu.ac.il goldbej@eng.biu.ac.il
</email>
<sectionHeader confidence="0.997293" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999606833333333">
Extensive knowledge bases of entailment rules
between predicates are crucial for applied se-
mantic inference. In this paper we propose an
algorithm that utilizes transitivity constraints
to learn a globally-optimal set of entailment
rules for typed predicates. We model the task
as a graph learning problem and suggest meth-
ods that scale the algorithm to larger graphs.
We apply the algorithm over a large data set
of extracted predicate instances, from which a
resource of typed entailment rules has been re-
cently released (Schoenmackers et al., 2010).
Our results show that using global transitiv-
ity information substantially improves perfor-
mance over this resource and several base-
lines, and that our scaling methods allow us
to increase the scope of global learning of
entailment-rule graphs.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991798411764706">
Generic approaches for applied semantic infer-
ence from text gained growing attention in recent
years, particularly under the Textual Entailment
(TE) framework (Dagan et al., 2009). TE is a
generic paradigm for semantic inference, where the
objective is to recognize whether a target meaning
can be inferred from a given text. A crucial com-
ponent of inference systems is extensive resources
of entailment rules, also known as inference rules,
i.e., rules that specify a directional inference rela-
tion between fragments of text. One important type
of rule is rules that specify entailment relations be-
tween predicates and their arguments. For example,
the rule ‘X annex Y —* X control Y’ helps recognize
that the text ‘Japan annexed Okinawa’ answers the
question ‘Which country controls Okinawa?’. Thus,
acquisition of such knowledge received considerable
attention in the last decade (Lin and Pantel, 2001;
Sekine, 2005; Szpektor and Dagan, 2009; Schoen-
mackers et al., 2010).
Most past work took a “local learning” approach,
learning each entailment rule independently of oth-
ers. It is clear though, that there are global inter-
actions between predicates. Notably, entailment is
a transitive relation and so the rules A —* B and
B —* C imply A —* C.
Recently, Berant et al. (2010) proposed a global
graph optimization procedure that uses Integer Lin-
ear Programming (ILP) to find the best set of entail-
ment rules under a transitivity constraint. Imposing
this constraint raised two challenges. The first of
ambiguity: transitivity does not always hold when
predicates are ambiguous, e.g., X buy Y —* X acquire
Y and X acquire Y —* X learn Y, but X buy Y --/+ X
learn Y since these two rules correspond to two dif-
ferent senses of acquire. The second challenge is
scalability: ILP solvers do not scale well since ILP
is an NP-complete problem. Berant et al. circum-
vented these issues by learning rules where one of
the predicate’s arguments is instantiated (e.g., ‘X re-
duce nausea —* X affect nausea’), which is useful for
learning small graphs on-the-fly, given a target con-
cept such as nausea. While rules may be effectively
learned when needed, their scope is narrow and they
are not useful as a generic knowledge resource.
This paper aims to take global rule learning one
step further. To this end, we adopt the represen-
tation suggested by Schoenmackers et al. (2010),
who learned inference rules between typed predi-
cates, i.e., predicates where the argument types (e.g.,
city or drug) are specified. Schoenmackers et al. uti-
</bodyText>
<page confidence="0.962303">
610
</page>
<note confidence="0.979552">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 610–619,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999847517241379">
lized typed predicates since they were dealing with
noisy and ambiguous web text. Typing predicates
helps disambiguation and filtering of noise, while
still maintaining rules of wide-applicability. Their
method employs a local learning approach, while the
number of predicates in their data is too large to be
handled directly by an ILP solver.
In this paper we suggest applying global opti-
mization learning to open domain typed entailment
rules. To that end, we show how to construct a
structure termed typed entailment graph, where the
nodes are typed predicates and the edges represent
entailment rules. We suggest scaling techniques that
allow to optimally learn such graphs over a large
set of typed predicates by first decomposing nodes
into components and then applying incremental ILP
(Riedel and Clarke, 2006). Using these techniques,
the obtained algorithm is guaranteed to return an op-
timal solution. We ran our algorithm over the data
set of Schoenmackers et al. and release a resource
of 30,000 rules1 that achieves substantially higher
recall without harming precision. To the best of our
knowledge, this is the first resource of that scale
to use global optimization for learning predicative
entailment rules. Our evaluation shows that global
transitivity improves the Fi score of rule learning by
27% over several baselines and that our scaling tech-
niques allow dealing with larger graphs, resulting in
improved coverage.
</bodyText>
<sectionHeader confidence="0.995486" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.998984">
Most work on learning entailment rules between
predicates considered each rule independently of
others, using two sources of information: lexico-
graphic resources and distributional similarity.
Lexicographic resources are manually-prepared
knowledge bases containing semantic information
on predicates. A widely-used resource is WordNet
(Fellbaum, 1998), where relations such as synonymy
and hyponymy can be used to generate rules. Other
resources include NomLex (Macleod et al., 1998;
Szpektor and Dagan, 2009) and FrameNet (Baker
and Lowe, 1998; Ben Aharon et al., 2010).
Lexicographic resources are accurate but have
</bodyText>
<footnote confidence="0.997063333333333">
1The resource can be downloaded from
http://www.cs.tau.ac.il/˜jonatha6/homepage files/resources
/ACL2011Resource.zip
</footnote>
<bodyText confidence="0.999864622222223">
low coverage. Distributional similarity algorithms
use large corpora to learn broader resources by as-
suming that semantically similar predicates appear
with similar arguments. These algorithms usually
represent a predicate with one or more vectors and
use some function to compute argument similarity.
Distributional similarity algorithms differ in their
feature representation: Some use a binary repre-
sentation: each predicate is represented by one fea-
ture vector where each feature is a pair of argu-
ments (Szpektor et al., 2004; Yates and Etzioni,
2009). This representation performs well, but suf-
fers when data is sparse. The binary-DIRT repre-
sentation deals with sparsity by representing a pred-
icate with a pair of vectors, one for each argument
(Lin and Pantel, 2001). Last, a richer form of repre-
sentation, termed unary, has been suggested where
a different predicate is defined for each argument
(Szpektor and Dagan, 2008). Different algorithms
also differ in their similarity function. Some employ
symmetric functions, geared towards paraphrasing
(bi-directional entailment), while others choose di-
rectional measures more suited for entailment (Bha-
gat et al., 2007). In this paper, We employ several
such functions, such as Lin (Lin and Pantel, 2001),
and BInc (Szpektor and Dagan, 2008).
Schoenmackers et al. (2010) recently used dis-
tributional similarity to learn rules between typed
predicates, where the left-hand-side of the rule may
contain more than a single predicate (horn clauses).
In their work, they used Hearst-patterns (Hearst,
1992) to extract a set of 29 million (argument, type)
pairs from a large web crawl. Then, they employed
several filtering methods to clean this set and au-
tomatically produced a mapping of 1.1 million ar-
guments into 156 types. Examples for (argument,
type) pairs are (EXODUS, book), (CHINA, coun-
try) and (ASTHMA, disease). Schoenmackers et
al. then utilized the types, the mapped arguments
and tuples from TextRunner (Banko et al., 2007)
to generate 10,672 typed predicates (such as con-
quer(country,city) and common in(disease,place)),
and learn 30,000 rules between these predicates2. In
this paper we will learn entailment rules over the
same data set, which was generously provided by
</bodyText>
<footnote confidence="0.995286">
2The rules and the mapping of arguments into types can
be downloaded from http://www.cs.washington.edu/research/
sherlock-hornclauses/
</footnote>
<page confidence="0.996654">
611
</page>
<bodyText confidence="0.9949564">
Schoenmackers et al.
As mentioned above, Berant et al. (2010) used
global transitivity information to learn small entail-
ment graphs. Transitivity was also used as an in-
formation source in other fields of NLP: Taxonomy
Induction (Snow et al., 2006), Co-reference Reso-
lution (Finkel and Manning, 2008), Temporal Infor-
mation Extraction (Ling and Weld, 2010), and Un-
supervised Ontology Induction (Poon and Domin-
gos, 2010). Our proposed algorithm applies to any
sparse transitive relation, and so might be applicable
in these fields as well.
Last, we formulate our optimization problem as
an Integer Linear Program (ILP). ILP is an optimiza-
tion problem where a linear objective function over
a set of integer variables is maximized under a set of
linear constraints. Scaling ILP is challenging since
it is an NP-complete problem. ILP has been exten-
sively used in NLP lately (Clarke and Lapata, 2008;
Martins et al., 2009; Do and Roth, 2010).
</bodyText>
<sectionHeader confidence="0.99522" genericHeader="method">
3 Typed Entailment Graphs
</sectionHeader>
<bodyText confidence="0.997181543478261">
Given a set of typed predicates, entailment rules can
only exist between predicates that share the same
(unordered) pair of types (such as place and coun-
try)3. Hence, every pair of types defines a graph
that describes the entailment relations between pred-
icates sharing those types (Figure 1). Next, we show
how to represent entailment rules between typed
predicates in a structure termed typed entailment
graph, which will be the learning goal of our algo-
rithm.
A typed entailment graph is a directed graph
where the nodes are typed predicates. A typed pred-
icate is a triple p(t1, t2) representing a predicate in
natural language. p is the lexical realization of the
predicate and the types t1, t2 are variables repre-
senting argument types. These are taken from a
set of types T, where each type t ∈ T is a bag
of natural language words or phrases. Examples
for typed predicates are: conquer(country,city) and
contain(product,material). An instance of a typed
predicate is a triple p(a1, a2), where a1 ∈ t1 and
a2 ∈ t2 are termed arguments. For example, be
common in(ASTHMA,AUSTRALIA) is an instance of
be common in(disease,place). For brevity, we refer
3Otherwise, the rule would contain unbound variables.
to typed entailment graphs and typed predicates as
entailment graphs and predicates respectively.
Edges in typed entailment graphs represent en-
tailment rules: an edge (u, v) means that predicate
u entails predicate v. If the type t1 is different
from the type t2, mapping of arguments is straight-
forward, as in the rule ‘be find in(material,product)
→ contain(product,material)’. We term this a two-
types entailment graph. When t1 and t2 are equal,
mapping of arguments is ambiguous: we distin-
guish direct-mapping edges where the first argu-
ment on the left-hand-side (LHS) is mapped to
the first argument on the right-hand-side (RHS),
as in ‘beat(team,team) →−� defeat(team,team)’, and
reversed-mapping edges where the LHS first argu-
ment is mapped to the RHS second argument, as
in ‘beat(team,team) →−r lose to(team,team)’. We
term this a single-type entailment graph. Note
that in single-type entailment graphs reversed-
mapping loops are possible as in ‘play(team,team)
→− play(team,team)’: if team A plays team B, then
</bodyText>
<equation confidence="0.630077">
r
</equation>
<bodyText confidence="0.995678071428571">
team B plays team A.
Since entailment is a transitive relation, typed-
entailment graphs are transitive: if the edges (u, v)
and (v, w) are in the graph so is the edge (u, w).
Note that in single-type entailment graphs one needs
to consider whether mapping of edges is direct or re-
versed: if mapping of both (u, v) and (v, w) is either
direct or reversed, mapping of (u, w) is direct, oth-
erwise it is reversed.
Typing plays an important role in rule transitiv-
ity: if predicates are ambiguous, transitivity does not
necessarily hold. However, typing predicates helps
disambiguate them and so the problem of ambiguity
is greatly reduced.
</bodyText>
<sectionHeader confidence="0.973532" genericHeader="method">
4 Learning Typed Entailment Graphs
</sectionHeader>
<bodyText confidence="0.998599">
Our learning algorithm is composed of two steps:
(1) Given a set of typed predicates and their in-
stances extracted from a corpus, we train a (local)
entailment classifier that estimates for every pair of
predicates whether one entails the other. (2) Using
the classifier scores we perform global optimization,
i.e., learn the set of edges over the nodes that maxi-
mizes the global score of the graph under transitivity
and background-knowledge constraints.
Section 4.1 describes the local classifier training
</bodyText>
<page confidence="0.995179">
612
</page>
<figureCaption confidence="0.999512">
Figure 1: Top: A fragment of a two-types entailment
graph. bottom: A fragment of a single-type entailment
graph. Mapping of solid edges is direct and of dashed
edges is reversed.
</figureCaption>
<bodyText confidence="0.9997645">
procedure. Section 4.2 gives an ILP formulation for
the optimization problem. Sections 4.3 and 4.4 pro-
pose scaling techniques that exploit graph sparsity
to optimally solve larger graphs.
</bodyText>
<subsectionHeader confidence="0.997053">
4.1 Training an entailment classifier
</subsectionHeader>
<bodyText confidence="0.9796612">
Similar to the work of Berant et al. (2010), we
use “distant supervision”. Given a lexicographic re-
source (WordNet) and a set of predicates with their
instances, we perform the following three steps (see
Table 1):
</bodyText>
<listItem confidence="0.986604333333333">
1) Training set generation We use WordNet to
generate positive and negative examples, where each
example is a pair of predicates. Let P be the
set of input typed predicates. For every predicate
p(t1, t2) E P such that p is a single word, we extract
from WordNet the set S of synonyms and direct hy-
pernyms of p. For every p&apos; E S, if p&apos;(t1, t2) E P
then p(t1, t2) —* p&apos;(t1, t2) is taken as a positive ex-
ample.
</listItem>
<bodyText confidence="0.895803555555556">
Negative examples are generated in a similar
manner, with direct co-hyponyms of p (sister nodes
in WordNet) and hyponyms at distance 2 instead of
synonyms and direct hypernyms. We also generate
negative examples by randomly sampling pairs of
typed predicates that share the same types.
2) Feature representation Each example pair of
predicates (p1, p2) is represented by a feature vec-
tor, where each feature is a specific distributional
</bodyText>
<table confidence="0.998557666666667">
Type example
hyper. beat(team,team) —* play(team,team)
syno. reach(team,game) —* arrive at(team,game)
cohypo. invade(country,city) 9 bomb(country,city)
hypo. defeat(city,city) 9 eliminate(city,city)
random hold(place,event) 9 win(place,event)
</table>
<tableCaption confidence="0.999966">
Table 1: Automatically generated training set examples.
</tableCaption>
<bodyText confidence="0.961362095238095">
similarity score estimating whether p1 entails p2.
We compute 11 distributional similarity scores for
each pair of predicates based on the arguments ap-
pearing in the extracted arguments. The first 6
scores are computed by trying all combinations of
the similarity functions Lin and BInc with the fea-
ture representations unary, binary-DIRT and binary
(see Section 2). The other 5 scores were provided
by Schoenmackers et al. (2010) and include SR
(Schoenmackers et al., 2010), LIME (McCreath and
Sharma, 1997), M-estimate (Dzeroski and Brakto,
1992), the standard G-test and a simple implementa-
tion of Cover (Weeds and Weir, 2003). Overall, the
rationale behind this representation is that combin-
ing various scores will yield a better classifier than
each single measure.
3) Training We train over an equal number of
positive and negative examples, as classifiers tend to
perform poorly on the minority class when trained
on imbalanced data (Van Hulse et al., 2007; Nikulin,
2008).
</bodyText>
<subsectionHeader confidence="0.910654">
4.2 ILP formulation
</subsectionHeader>
<bodyText confidence="0.998860533333333">
Once the classifier is trained, we would like to learn
all edges (entailment rules) of each typed entailment
graph. Given a set of predicates V and an entail-
ment score function f : V x V —* R derived from
the classifier, we want to find a graph G = (V, E)
that respects transitivity and maximizes the sum of
edge weights E(u v)EE f (u, v). This problem is
NP-hard by a reduction from the NP-hard Transitive
Subgraph problem (Yannakakis, 1978). Thus, em-
ploying ILP is an appealing approach for obtaining
an optimal solution.
For two-types entailment graphs the formulation
is simple: The ILP variables are indicators Xuv de-
noting whether an edge (u, v) is in the graph, with
the following ILP:
</bodyText>
<figure confidence="0.9986603125">
invade
(country,place)
be part of
(place,country)
annex
(country,place)
province of
(place,country)
be relate to
(drug,drug)
be process from
(drug,drug)
be derive from
(drug,drug)
be convert into
(drug,drug)
</figure>
<page confidence="0.951534">
613
</page>
<table confidence="0.960966166666667">
G� = arg max f(u, v) · Xuv
u�v
s.t. ∀u,v,wEV Xuv + Xvw − Xuw ≤ 1
∀u,vEAyes Xuv = 1
∀u,vEA�v Xuv = 0
∀u7�v Xuv ∈ {0, 1}
</table>
<bodyText confidence="0.995886565217391">
The objective in Eq. 1 is a sum over the weights
of the eventual edges. The constraint in Eq. 2 states
that edges must respect transitivity. The constraints
in Eq. 3 and 4 state that for known node pairs, de-
fined by Ayes and Ano, we have background knowl-
edge indicating whether entailment holds or not. We
elaborate on how Ayes and Ano were constructed in
Section 5. For a graph with n nodes we get n(n −1)
variables and n(n−1)(n−2) transitivity constraints.
The simplest way to expand this formulation for
single-type graphs is to duplicate each predicate
node, with one node for each order of the types, and
then the ILP is unchanged. However, this is inef-
ficient as it results in an ILP with 2n(2n − 1) vari-
ables and 2n(2n−1)(2n−2) transitivity constraints.
Since our main goal is to scale the use of ILP, we
modify it a little. We denote a direct-mapping edge
(u, v) by the indicator Xuv and a reversed-mapping
edge (u, v) by Yuv. The functions fd and fr provide
scores for direct and reversed mappings respectively.
The objective in Eq. 1 and the constraint in Eq. 2 are
replaced by (Eq. 3, 4 and 5 still exist and are carried
over in a trivial manner):
</bodyText>
<equation confidence="0.990056">
Earg max Efd(u, v)Xuv + fr(u, v)Yuv (6)
u�v u,v
s.t. ∀u,v,wEV Xuv + Xvw − Xuw ≤ 1
∀u,v,wEV Xuv + Yvw − Yuw ≤ 1
∀u,v,wEV Yuv + Xvw − Yuw ≤ 1
∀u,v,wEV Yuv + Yvw − Xuw ≤ 1
</equation>
<bodyText confidence="0.9991515">
The modified constraints capture the transitivity
behavior of direct-mapping and reversed-mapping
edges, as described in Section 3. This results in
2n2 − n variables and about 4n3 transitivity con-
straints, cutting the ILP size in half.
Next, we specify how to derive the function f
from the trained classifier using a probabilistic for-
mulation4. Following Snow et al. (2006) and Be-
rant et al. (2010), we utilize a probabilistic entail-
ment classifier that computes the posterior Puv =
P(Xuv = 1|Fuv). We want to use Puv to derive the
posterior P(G|F), where F = ∪u�vFuv and Fuv is
the feature vector for a node pair (u, v).
Since the classifier was trained on a balanced
training set, the prior over the two entailment
classes is uniform and so by Bayes rule Puv ∝
P(Fuv|Xuv = 1). Using that and the exact same
three independence assumptions described by Snow
et al. (2006) and Berant et al. (2010) we can show
that (for brevity, we omit the full derivation):
</bodyText>
<equation confidence="0.957897818181818">
G� = arg maxG log P(G|F) = (7)
Puv · P(Xuv = 1)
(log (1 − Puv)P(Xuv = 0))Xuv
Puv
(log )Xuv + log η · |E|
1 − Puv
whereP(Xuv=1) is the prior odds ratio for
= P(Xuv=0)
an edge in the graph. Comparing Eq. 1 and 7 we
see that f(u, v) =log Puv�P (Xuv=1)
(1�Puv)P (Xuv=0). Note that f
</equation>
<bodyText confidence="0.999950125">
is composed of a likelihood component and an edge
prior expressed by P(Xuv = 1), which we assume
to be some constant. This constant is a parameter
that affects graph sparsity and controls the trade-off
between recall and precision.
Next, we show how sparsity is exploited to scale
the use of ILP solvers. We discuss two-types entail-
ment graphs, but generalization is simple.
</bodyText>
<subsectionHeader confidence="0.996401">
4.3 Graph decomposition
</subsectionHeader>
<bodyText confidence="0.999944125">
Though ILP solvers provide an optimal solution,
they substantially restrict the size of graphs we can
work with. The number of constraints is O(n3),
and solving graphs of size &gt; 50 is often not feasi-
ble. To overcome this, we take advantage of graph
sparsity: most predicates in language do not entail
one another. Thus, it might be possible to decom-
pose graphs into small components and solve each
</bodyText>
<footnote confidence="0.9632385">
4We describe two-types graphs but extending to single-type
graphs is straightforward.
</footnote>
<figure confidence="0.708391181818182">
Earg max
u�v
E= arg max
u�v
614
Algorithm 1 Decomposed-ILP
Input: A set V and a function f : V x V —* R
Output: An optimal set of directed edges E*
1: E&apos; = {(u, v) : f(u, v) &gt; 0 V f(v, u) &gt; 0}
2: V1, V2, ..., Vk +— connected components of
G&apos; = (V, E&apos;)
</figure>
<listItem confidence="0.9153345">
3: for i = 1 to k do
4: EZ +— ApplyILPSolve(VZ,f)
5: end for
6: E* +— UkZ=1 EZ
</listItem>
<bodyText confidence="0.585619">
component separately. This is formalized in the next
proposition.
</bodyText>
<construct confidence="0.8347398">
Proposition 1. If we can partition a set of nodes
V into disjoint sets U, W such that for any cross-
ing edge (u, w) between them (in either direction),
f(u, w) &lt; 0, then the optimal set of edges Eopt does
not contain any crossing edge.
</construct>
<bodyText confidence="0.9145105">
Proof Assume by contradiction that Eopt con-
tains a set of crossing edges Ecross. We can
</bodyText>
<equation confidence="0.889991666666667">
construct Enew = Eopt \ Ecross. Clearly
E(u,v)EEnew f(u, v) &gt; E(u,v)EE, t f(u, v), as
f(u, v) &lt; 0 for any crossing edge.
</equation>
<bodyText confidence="0.943937">
Next, we show that Enew does not violate tran-
sitivity constraints. Assume it does, then the viola-
tion is caused by omitting the edges in Ecross. Thus,
there must be a node u E U and w E W (w.l.o.g)
such that for some node v, (u, v) and (v, w) are in
Enew, but (u, w) is not. However, this means either
(u, v) or (v, w) is a crossing edge, which is impossi-
ble since we omitted all crossing edges. Thus, Enew
is a better solution than Eopt, contradiction.
This proposition suggests a simple algorithm (see
Algorithm 1): Add to the graph an undirected edge
for any node pair with a positive score, then find the
connected components, and apply an ILP solver over
the nodes in each component. The edges returned
by the solver provide an optimal (not approximate)
solution to the optimization problem.
The algorithm’s complexity is dominated by the
ILP solver, as finding connected components takes
O(V 2) time. Thus, efficiency depends on whether
the graph is sparse enough to be decomposed into
small components. Note that the edge prior plays an
important role: low values make the graph sparser
and easier to solve. In Section 5 we empirically test
Algorithm 2 Incremental-ILP
Input: A set V and a function f : V x V —* R
Output: An optimal set of directed edges E*
</bodyText>
<listItem confidence="0.992220666666667">
1: ACT,VIO +— �
2: repeat
3: E* +— ApplyILPSolve(V,f,ACT)
4: VIO violated(V, E*)
5: ACT ACT U VIO
6: until |VIO |= 0
</listItem>
<bodyText confidence="0.9998993">
how typed entailment graphs benefit from decompo-
sition given different prior values.
From a more general perspective, this algo-
rithm can be applied to any problem of learning
a sparse transitive binary relation. Such problems
include Co-reference Resolution (Finkel and Man-
ning, 2008) and Temporal Information Extraction
(Ling and Weld, 2010). Last, the algorithm can be
easily parallelized by solving each component on a
different core.
</bodyText>
<subsectionHeader confidence="0.939152">
4.4 Incremental ILP
</subsectionHeader>
<bodyText confidence="0.99983176">
Another solution for scaling ILP is to employ in-
cremental ILP, which has been used in dependency
parsing (Riedel and Clarke, 2006). The idea is
that even if we omit the transitivity constraints, we
still expect most transitivity constraints to be satis-
fied, given a good local entailment classifier. Thus,
it makes sense to avoid specifying the constraints
ahead of time, but rather add them when they are
violated. This is formalized in Algorithm 2.
Line 1 initializes an active set of constraints and a
violated set of constraints (ACT;VIO). Line 3 applies
the ILP solver with the active constraints. Lines 4
and 5 find the violated constraints and add them to
the active constraints. The algorithm halts when no
constraints are violated. The solution is clearly op-
timal since we obtain a maximal solution for a less-
constrained problem.
A pre-condition for using incremental ILP is that
computing the violated constraints (Line 4) is effi-
cient, as it occurs in every iteration. We do that in
a straightforward manner: For every node v, and
edges (u, v) and (v, w), if (u, w) E� E* we add
(u, v, w) to the violated constraints. This is cubic
in worst-case but assuming the degree of nodes is
bounded by a constant it is linear, and performs very
</bodyText>
<page confidence="0.998091">
615
</page>
<bodyText confidence="0.995576888888889">
fast in practice.
Combining Incremental-ILP and Decomposed-
ILP is easy: We decompose any large graph into
its components and apply Incremental ILP on each
component. We applied this algorithm on our evalu-
ation data set (Section 5) and found that it converges
in at most 6 iterations and that the maximal num-
ber of active constraints in large graphs drops from
_ 106 to _ 103 − 104.
</bodyText>
<sectionHeader confidence="0.992594" genericHeader="evaluation">
5 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.9952476">
In this section we empirically answer the follow-
ing questions: (1) Does transitivity improve rule
learning over typed predicates? (Section 5.1) (2)
Do Decomposed-ILP and Incremental-ILP improve
scalability? (Section 5.2)
</bodyText>
<subsectionHeader confidence="0.98787">
5.1 Experiment 1
</subsectionHeader>
<bodyText confidence="0.99983205882353">
A data set of 1 million TextRunner tuples (Banko
et al., 2007), mapped to 10,672 distinct typed predi-
cates over 156 types was provided by Schoenmack-
ers et al. (2010). Readers are referred to their pa-
per for details on mapping of tuples to typed predi-
cates. Since entailment only occurs between pred-
icates that share the same types, we decomposed
predicates by their types (e.g., all predicates with the
types place and disease) into 2,303 typed entailment
graphs. The largest graph contains 118 nodes and
the total number of potential rules is 263,756.
We generated a training set by applying the proce-
dure described in Section 4.1, yielding 2,644 exam-
ples. We used SVMperf (Joachims, 2005) to train a
Gaussian kernel classifier and computed P,,„ by pro-
jecting the classifier output score, 5,,,,, with the sig-
moid function: P,,„ = 1+exp(−S,,). We tuned two
</bodyText>
<equation confidence="0.690346">
1
</equation>
<bodyText confidence="0.998464175438596">
SVM parameters using 5-fold cross validation and a
development set of two typed entailment graphs.
Next, we used our algorithm to learn rules. As
mentioned in Section 4.2, we integrate background
knowledge using the sets Ayes and Ano that contain
predicate pairs for which we know whether entail-
ment holds. Ayes was constructed with syntactic
rules: We normalized each predicate by omitting the
first word if it is a modal and turning passives to ac-
tives. If two normalized predicates are equal they are
synonymous and inserted into Ayes. Ano was con-
structed from 3 sources (1) Predicates differing by a
single pair of words that are WordNet antonyms (2)
Predicates differing by a single word of negation (3)
Predicates p(t1, t2) and p(t2, t1) where p is a transi-
tive verb (e.g., beat) in VerbNet (Kipper-Schuler et
al., 2000).
We compared our algorithm (termed ILPscale) to
the following baselines. First, to 10,000 rules re-
leased by Schoenmackers et al. (2010) (Sherlock),
where the LHS contains a single predicate (Schoen-
mackers et al. released 30,000 rules but 20,000 of
those have more than one predicate on the LHS,
see Section 2), as we learn rules over the same data
set. Second, to distributional similarity algorithms:
(a) SR: the score used by Schoenmackers et al. as
part of the Sherlock system. (b) DIRT: (Lin and
Pantel, 2001) a widely-used rule learning algorithm.
(c) BInc: (Szpektor and Dagan, 2008) a directional
rule learning algorithm. Third, we compared to the
entailment classifier with no transitivity constraints
(clsf) to see if combining distributional similarity
scores improves performance over single measures.
Last, we added to all baselines background knowl-
edge with Ayes and Ano (adding the subscript Xk to
their name).
To evaluate performance we manually annotated
all edges in 10 typed entailment graphs - 7 two-
types entailment graphs containing 14, 22, 30, 53,
62, 86 and 118 nodes, and 3 single-type entailment
graphs containing 7, 38 and 59 nodes. This annota-
tion yielded 3,427 edges and 35,585 non-edges, re-
sulting in an empirical edge density of 9%. We eval-
uate the algorithms by comparing the set of edges
learned by the algorithms to the gold standard edges.
Figure 2 presents the precision-recall curve of the
algorithms. The curve is formed by varying a score
threshold in the baselines and varying the edge prior
in ILPscale5. For figure clarity, we omit DIRT and
SR, since BInc outperforms them.
Table 2 shows micro-recall, precision and F1 at
the point of maximal F1, and the Area Under the
Curve (AUC) for recall in the range of 0-0.45 for all
algorithms, given background knowledge (knowl-
edge consistently improves performance by a few
points for all algorithms). The table also shows re-
sults for the rules from Sherlockk.
</bodyText>
<footnote confidence="0.997146666666667">
5we stop raising the prior when run time over the graphs
exceeds 2 hours. Often when the solver does not terminate in 2
hours, it also does not terminate after 24 hours or more.
</footnote>
<page confidence="0.99406">
616
</page>
<figureCaption confidence="0.988398">
Figure 2: Precision-recall curve for the algorithms.
</figureCaption>
<table confidence="0.9990855">
micro-average
R (%) P (%) Fi (%) AUC
ILPscale 43.4 42.2 42.8 0.22
clsfk 30.8 37.5 33.8 0.17
Sherlockk 20.6 43.3 27.9 N/A
BInck 31.8 34.1 32.9 0.17
SRk 38.4 23.2 28.9 0.14
DIRTk 25.7 31.0 28.1 0.13
</table>
<tableCaption confidence="0.999451">
Table 2: micro-average Fl and AUC for the algorithms.
</tableCaption>
<bodyText confidence="0.996090125">
Results show that using global transitivity
information substantially improves performance.
ILPscale is better than all other algorithms by a large
margin starting from recall .2, and improves AUC
by 29% and the maximal Fi by 27%. Moreover,
ILPscale doubles recall comparing to the rules from
the Sherlock resource, while maintaining compara-
ble precision.
</bodyText>
<subsectionHeader confidence="0.995637">
5.2 Experiment 2
</subsectionHeader>
<bodyText confidence="0.99972506">
We want to test whether using our scaling tech-
niques, Decomposed-ILP and Incremental-ILP, al-
lows us to reach the optimal solution in graphs that
otherwise we could not solve, and consequently in-
crease the number of learned rules and the overall
recall. To check that, we run ILPscale, with and with-
out these scaling techniques (termed ILP−).
We used the same data set as in Experiment 1
and learned edges for all 2,303 entailment graphs
in the data set. If the ILP solver was unable to
hold the ILP in memory or took more than 2 hours
for some graph, we did not attempt to learn its
edges. We ran ILPscale and ILP− in three den-
sity modes to examine the behavior of the algo-
rithms for different graph densities: (a) log q =
−0.6: the configuration that achieved the best
recall/precision/Fi of 43.4/42.2/42.8. (b) log q =
−1 with recall/precision/Fi of 31.8/55.3/40.4. (c)
log q = −1.75: A high precision configuration with
recall/precision/Fi of 0.15/0.75/0.23 6.
In each run we counted the number of graphs that
could not be learned and the number of rules learned
by each algorithm. In addition, we looked at the
20 largest graphs in our data (49-118 nodes) and
measured the ratio r between the size of the largest
component after applying Decomposed-ILP and the
original size of the graph. We then computed the av-
erage 1−r over the 20 graphs to examine how graph
size drops due to decomposition.
Table 3 shows the results. Column # unlearned
and # rules describe the number of unlearned graphs
and the number of learned rules. Column A shows
relative increase in the number of rules learned and
column Red. shows the average 1 − r.
ILPscale increases the number of graphs that we
are able to learn: in our best configuration (log q =
−0.6) only 3 graphs could not be handled com-
paring to 9 graphs when omitting our scaling tech-
niques. Since the unlearned graphs are among the
largest in the data set, this adds 3,500 additional
rules. We compared the precision of rules learned
only by ILPscale with that of the rules learned by
both, by randomly sampling 100 rules from each and
found precision to be comparable. Thus, the addi-
tional rules learned translate into a 13% increase in
relative recall without harming precision.
Also note that as density increases, the number of
rules learned grows and the effectiveness of decom-
position decreases. This shows how Decomposed-
ILP is especially useful for sparse graphs. We re-
</bodyText>
<footnote confidence="0.747682">
6Experiment was run on an Intel i5 CPU with 4GB RAM.
</footnote>
<figure confidence="0.99099975">
0.8
0.6
0.4
0.2
0
precision
BInc
clsf
BInc_k
clsf_k
ILP_scale
0 0.1 0.2 0.3 0.4recall0.5 0.6 0.7 0.8 0.9
log q # unlearned # rules A Red.
-1.75 9/0 6,242 / 7,466 20% 75%
-1 9/1 16,790 / 19,396 16% 29%
-0.6 9/3 26,330 / 29,732 13% 14%
</figure>
<tableCaption confidence="0.958058">
Table 3: Impact of scaling techinques (ILP−/ILPscale).
</tableCaption>
<page confidence="0.99477">
617
</page>
<bodyText confidence="0.999659833333333">
lease the 29,732 rules learned by the configuration
log ,q = −0.6 as a resource.
To sum up, our scaling techniques allow us to
learn rules from graphs that standard ILP can not
handle and thus considerably increase recall without
harming precision.
</bodyText>
<sectionHeader confidence="0.998814" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999984444444444">
This paper proposes two contributions over two re-
cent works: In the first, Berant et al. (2010) pre-
sented a global optimization procedure to learn en-
tailment rules between predicates using transitivity,
and applied this algorithm over small graphs where
all predicates have one argument instantiated by a
target concept. Consequently, the rules they learn
are of limited applicability. In the second, Schoen-
mackers et al. learned rules of wider applicability by
using typed predicates, but utilized a local approach.
In this paper we developed an algorithm that uses
global optimization to learn widely-applicable en-
tailment rules between typed predicates (where both
arguments are variables). This was achieved by
appropriately defining entailment graphs for typed
predicates, formulating an ILP representation for
them, and introducing scaling techniques that in-
clude graph decomposition and incremental ILP.
Our algorithm is guaranteed to provide an optimal
solution and we have shown empirically that it sub-
stantially improves performance over Schoenmack-
ers et al.’s recent resource and over several baselines.
In future work, we aim to scale the algorithm
further and learn entailment rules between untyped
predicates. This would require explicit modeling of
predicate ambiguity and using approximation tech-
niques when an optimal solution cannot be attained.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999976866666667">
This work was performed with financial support
from the Turing Center at The University of Wash-
ington during a visit of the first author (NSF grant
IIS-0803481). We deeply thank Oren Etzioni and
Stefan Schoenmackers for providing us with the data
sets for this paper and for numerous helpful discus-
sions. We would also like to thank the anonymous
reviewers for their useful comments. This work
was developed under the collaboration of FBK-
irst/University of Haifa and was partially supported
by the Israel Science Foundation grant 1112/08. The
first author is grateful to IBM for the award of an
IBM Fellowship, and has carried out this research
in partial fulllment of the requirements for the Ph.D.
degree.
</bodyText>
<sectionHeader confidence="0.999434" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999492">
J. Fillmore Baker, C. F. and J. B. Lowe. 1998. The
Berkeley framenet project. In Proc. of COLING-ACL.
Michele Banko, Michael Cafarella, Stephen Soderland,
Matt Broadhead, and Oren Etzioni. 2007. Open in-
formation extraction from the web. In Proceedings of
IJCAI.
Roni Ben Aharon, Idan Szpektor, and Ido Dagan. 2010.
Generating entailment rules from framenet. In Pro-
ceedings of ACL.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2010. Global learning of focused entailment graphs.
In Proceedings of ACL.
Rahul Bhagat, Patrick Pantel, and Eduard Hovy. 2007.
LEDIR: An unsupervised algorithm for learning di-
rectionality of inference rules. In Proceedings of
EMNLP-CoNLL.
James Clarke and Mirella Lapata. 2008. Global infer-
ence for sentence compression: An integer linear pro-
gramming approach. Journal of Artificial Intelligence
Research, 31:273–381.
Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth.
2009. Recognizing textual entailment: Rational, eval-
uation and approaches. Natural Language Engineer-
ing, 15(4):1–17.
Quang Do and Dan Roth. 2010. Constraints based
taxonomic relation classification. In Proceedings of
EMNLP.
Saso Dzeroski and Ivan Brakto. 1992. Handling noise
in inductive logic programming. In Proceedings of the
International Workshop on Inductive Logic Program-
ming.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database (Language, Speech, and Com-
munication). The MIT Press.
Jenny Rose Finkel and Christopher D. Manning. 2008.
Enforcing transitivity in coreference resolution. In
Proceedings of ACL-08: HLT, Short Papers.
Marti Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In Proceedings of COLING.
Thorsten Joachims. 2005. A support vector method for
multivariate performance measures. In Proceedings of
ICML.
Karin Kipper-Schuler, Hoa Trand Dang, and Martha
Palmer. 2000. Class-based construction of verb lex-
icon. In Proceedings of AAAI/IAAI.
</reference>
<page confidence="0.977603">
618
</page>
<reference confidence="0.999697946428571">
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules for question answering. Natural Language
Engineering, 7(4):343–360.
Xiao Ling and Daniel S. Weld. 2010. Temporal informa-
tion extraction. In Proceedings of AAAI.
Catherine Macleod, Ralph Grishman, Adam Meyers,
Leslie Barrett, and Ruth Reeves. 1998. NOMLEX:
A lexicon of nominalizations. In Proceedings of COL-
ING.
Andre Martins, Noah Smith, and Eric Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proceedings ofACL.
Eric McCreath and Arun Sharma. 1997. ILP with noise
and fixed example size: a bayesian approach. In Pro-
ceedings of the Fifteenth international joint conference
on artificial intelligence - Volume 2.
Vladimir Nikulin. 2008. Classification of imbalanced
data with random sets and mean-variance filtering.
IJDWM, 4(2):63–78.
Hoifung Poon and Pedro Domingos. 2010. Unsuper-
vised ontology induction from text. In Proceedings of
ACL.
Sebastian Riedel and James Clarke. 2006. Incremental
integer linear programming for non-projective depen-
dency parsing. In Proceedings of EMNLP.
Stefan Schoenmackers, Oren Etzioni Jesse Davis, and
Daniel S. Weld. 2010. Learning first-order horn
clauses from web text. In Proceedings of EMNLP.
Satoshi Sekine. 2005. Automatic paraphrase discovery
based on context and keywords between ne pairs. In
Proceedings of IWP.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous evi-
dence. In Proceedings of ACL.
Idan Szpektor and Ido Dagan. 2008. Learning entailment
rules for unary templates. In Proceedings of COLING.
Idan Szpektor and Ido Dagan. 2009. Augmenting
wordnet-based inference with argument mapping. In
Proceedings of TextInfer.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisition of
entailment relations. In Proceedings of EMNLP.
Jason Van Hulse, Taghi Khoshgoftaar, and Amri Napoli-
tano. 2007. Experimental perspectives on learning
from imbalanced data. In Proceedings of ICML.
Julie Weeds and David Weir. 2003. A general frame-
work for distributional similarity. In Proceedings of
EMNLP.
Mihalis Yannakakis. 1978. Node-and edge-deletion NP-
complete problems. In STOC ’78: Proceedings of the
tenth annual ACM symposium on Theory of comput-
ing, pages 253–264, New York, NY, USA. ACM.
Alexander Yates and Oren Etzioni. 2009. Unsupervised
methods for determining object and relation synonyms
on the web. Journal ofArtificial Intelligence Research,
34:255–296.
</reference>
<page confidence="0.998661">
619
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.922914">
<title confidence="0.999981">Global Learning of Typed Entailment Rules</title>
<author confidence="0.999995">Jonathan Berant Ido Dagan Jacob Goldberger</author>
<affiliation confidence="0.996909">Tel Aviv University Bar-Ilan University Bar-Ilan University</affiliation>
<address confidence="0.958515">Tel Aviv, Israel Ramat-Gan, Israel Ramat-Gan, Israel</address>
<email confidence="0.987522">jonatha6@post.tau.ac.ildagan@cs.biu.ac.ilgoldbej@eng.biu.ac.il</email>
<abstract confidence="0.998732578947368">Extensive knowledge bases of entailment rules between predicates are crucial for applied semantic inference. In this paper we propose an algorithm that utilizes transitivity constraints to learn a globally-optimal set of entailment rules for typed predicates. We model the task as a graph learning problem and suggest methods that scale the algorithm to larger graphs. We apply the algorithm over a large data set of extracted predicate instances, from which a resource of typed entailment rules has been recently released (Schoenmackers et al., 2010). Our results show that using global transitivity information substantially improves performance over this resource and several baselines, and that our scaling methods allow us to increase the scope of global learning of entailment-rule graphs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Fillmore Baker</author>
<author>C F</author>
<author>J B Lowe</author>
</authors>
<title>The Berkeley framenet project.</title>
<date>1998</date>
<booktitle>In Proc. of COLING-ACL.</booktitle>
<marker>Baker, F, Lowe, 1998</marker>
<rawString>J. Fillmore Baker, C. F. and J. B. Lowe. 1998. The Berkeley framenet project. In Proc. of COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<contexts>
<context position="7973" citStr="Banko et al., 2007" startWordPosition="1221" endWordPosition="1224"> learn rules between typed predicates, where the left-hand-side of the rule may contain more than a single predicate (horn clauses). In their work, they used Hearst-patterns (Hearst, 1992) to extract a set of 29 million (argument, type) pairs from a large web crawl. Then, they employed several filtering methods to clean this set and automatically produced a mapping of 1.1 million arguments into 156 types. Examples for (argument, type) pairs are (EXODUS, book), (CHINA, country) and (ASTHMA, disease). Schoenmackers et al. then utilized the types, the mapped arguments and tuples from TextRunner (Banko et al., 2007) to generate 10,672 typed predicates (such as conquer(country,city) and common in(disease,place)), and learn 30,000 rules between these predicates2. In this paper we will learn entailment rules over the same data set, which was generously provided by 2The rules and the mapping of arguments into types can be downloaded from http://www.cs.washington.edu/research/ sherlock-hornclauses/ 611 Schoenmackers et al. As mentioned above, Berant et al. (2010) used global transitivity information to learn small entailment graphs. Transitivity was also used as an information source in other fields of NLP: T</context>
<context position="24613" citStr="Banko et al., 2007" startWordPosition="4072" endWordPosition="4075">large graph into its components and apply Incremental ILP on each component. We applied this algorithm on our evaluation data set (Section 5) and found that it converges in at most 6 iterations and that the maximal number of active constraints in large graphs drops from _ 106 to _ 103 − 104. 5 Experimental Evaluation In this section we empirically answer the following questions: (1) Does transitivity improve rule learning over typed predicates? (Section 5.1) (2) Do Decomposed-ILP and Incremental-ILP improve scalability? (Section 5.2) 5.1 Experiment 1 A data set of 1 million TextRunner tuples (Banko et al., 2007), mapped to 10,672 distinct typed predicates over 156 types was provided by Schoenmackers et al. (2010). Readers are referred to their paper for details on mapping of tuples to typed predicates. Since entailment only occurs between predicates that share the same types, we decomposed predicates by their types (e.g., all predicates with the types place and disease) into 2,303 typed entailment graphs. The largest graph contains 118 nodes and the total number of potential rules is 263,756. We generated a training set by applying the procedure described in Section 4.1, yielding 2,644 examples. We u</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In Proceedings of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roni Ben Aharon</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Generating entailment rules from framenet.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="5822" citStr="Aharon et al., 2010" startWordPosition="901" endWordPosition="904">hs, resulting in improved coverage. 2 Background Most work on learning entailment rules between predicates considered each rule independently of others, using two sources of information: lexicographic resources and distributional similarity. Lexicographic resources are manually-prepared knowledge bases containing semantic information on predicates. A widely-used resource is WordNet (Fellbaum, 1998), where relations such as synonymy and hyponymy can be used to generate rules. Other resources include NomLex (Macleod et al., 1998; Szpektor and Dagan, 2009) and FrameNet (Baker and Lowe, 1998; Ben Aharon et al., 2010). Lexicographic resources are accurate but have 1The resource can be downloaded from http://www.cs.tau.ac.il/˜jonatha6/homepage files/resources /ACL2011Resource.zip low coverage. Distributional similarity algorithms use large corpora to learn broader resources by assuming that semantically similar predicates appear with similar arguments. These algorithms usually represent a predicate with one or more vectors and use some function to compute argument similarity. Distributional similarity algorithms differ in their feature representation: Some use a binary representation: each predicate is repr</context>
</contexts>
<marker>Aharon, Szpektor, Dagan, 2010</marker>
<rawString>Roni Ben Aharon, Idan Szpektor, and Ido Dagan. 2010. Generating entailment rules from framenet. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global learning of focused entailment graphs.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="2361" citStr="Berant et al. (2010)" startWordPosition="358" endWordPosition="361"> ‘X annex Y —* X control Y’ helps recognize that the text ‘Japan annexed Okinawa’ answers the question ‘Which country controls Okinawa?’. Thus, acquisition of such knowledge received considerable attention in the last decade (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2009; Schoenmackers et al., 2010). Most past work took a “local learning” approach, learning each entailment rule independently of others. It is clear though, that there are global interactions between predicates. Notably, entailment is a transitive relation and so the rules A —* B and B —* C imply A —* C. Recently, Berant et al. (2010) proposed a global graph optimization procedure that uses Integer Linear Programming (ILP) to find the best set of entailment rules under a transitivity constraint. Imposing this constraint raised two challenges. The first of ambiguity: transitivity does not always hold when predicates are ambiguous, e.g., X buy Y —* X acquire Y and X acquire Y —* X learn Y, but X buy Y --/+ X learn Y since these two rules correspond to two different senses of acquire. The second challenge is scalability: ILP solvers do not scale well since ILP is an NP-complete problem. Berant et al. circumvented these issues</context>
<context position="8424" citStr="Berant et al. (2010)" startWordPosition="1284" endWordPosition="1287">EXODUS, book), (CHINA, country) and (ASTHMA, disease). Schoenmackers et al. then utilized the types, the mapped arguments and tuples from TextRunner (Banko et al., 2007) to generate 10,672 typed predicates (such as conquer(country,city) and common in(disease,place)), and learn 30,000 rules between these predicates2. In this paper we will learn entailment rules over the same data set, which was generously provided by 2The rules and the mapping of arguments into types can be downloaded from http://www.cs.washington.edu/research/ sherlock-hornclauses/ 611 Schoenmackers et al. As mentioned above, Berant et al. (2010) used global transitivity information to learn small entailment graphs. Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al., 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linea</context>
<context position="13185" citStr="Berant et al. (2010)" startWordPosition="2059" endWordPosition="2062">ver the nodes that maximizes the global score of the graph under transitivity and background-knowledge constraints. Section 4.1 describes the local classifier training 612 Figure 1: Top: A fragment of a two-types entailment graph. bottom: A fragment of a single-type entailment graph. Mapping of solid edges is direct and of dashed edges is reversed. procedure. Section 4.2 gives an ILP formulation for the optimization problem. Sections 4.3 and 4.4 propose scaling techniques that exploit graph sparsity to optimally solve larger graphs. 4.1 Training an entailment classifier Similar to the work of Berant et al. (2010), we use “distant supervision”. Given a lexicographic resource (WordNet) and a set of predicates with their instances, we perform the following three steps (see Table 1): 1) Training set generation We use WordNet to generate positive and negative examples, where each example is a pair of predicates. Let P be the set of input typed predicates. For every predicate p(t1, t2) E P such that p is a single word, we extract from WordNet the set S of synonyms and direct hypernyms of p. For every p&apos; E S, if p&apos;(t1, t2) E P then p(t1, t2) —* p&apos;(t1, t2) is taken as a positive example. Negative examples are</context>
<context position="18252" citStr="Berant et al. (2010)" startWordPosition="2927" endWordPosition="2931">ll exist and are carried over in a trivial manner): Earg max Efd(u, v)Xuv + fr(u, v)Yuv (6) u�v u,v s.t. ∀u,v,wEV Xuv + Xvw − Xuw ≤ 1 ∀u,v,wEV Xuv + Yvw − Yuw ≤ 1 ∀u,v,wEV Yuv + Xvw − Yuw ≤ 1 ∀u,v,wEV Yuv + Yvw − Xuw ≤ 1 The modified constraints capture the transitivity behavior of direct-mapping and reversed-mapping edges, as described in Section 3. This results in 2n2 − n variables and about 4n3 transitivity constraints, cutting the ILP size in half. Next, we specify how to derive the function f from the trained classifier using a probabilistic formulation4. Following Snow et al. (2006) and Berant et al. (2010), we utilize a probabilistic entailment classifier that computes the posterior Puv = P(Xuv = 1|Fuv). We want to use Puv to derive the posterior P(G|F), where F = ∪u�vFuv and Fuv is the feature vector for a node pair (u, v). Since the classifier was trained on a balanced training set, the prior over the two entailment classes is uniform and so by Bayes rule Puv ∝ P(Fuv|Xuv = 1). Using that and the exact same three independence assumptions described by Snow et al. (2006) and Berant et al. (2010) we can show that (for brevity, we omit the full derivation): G� = arg maxG log P(G|F) = (7) Puv · P(X</context>
<context position="32183" citStr="Berant et al. (2010)" startWordPosition="5367" endWordPosition="5370">sf_k ILP_scale 0 0.1 0.2 0.3 0.4recall0.5 0.6 0.7 0.8 0.9 log q # unlearned # rules A Red. -1.75 9/0 6,242 / 7,466 20% 75% -1 9/1 16,790 / 19,396 16% 29% -0.6 9/3 26,330 / 29,732 13% 14% Table 3: Impact of scaling techinques (ILP−/ILPscale). 617 lease the 29,732 rules learned by the configuration log ,q = −0.6 as a resource. To sum up, our scaling techniques allow us to learn rules from graphs that standard ILP can not handle and thus considerably increase recall without harming precision. 6 Conclusions and Future Work This paper proposes two contributions over two recent works: In the first, Berant et al. (2010) presented a global optimization procedure to learn entailment rules between predicates using transitivity, and applied this algorithm over small graphs where all predicates have one argument instantiated by a target concept. Consequently, the rules they learn are of limited applicability. In the second, Schoenmackers et al. learned rules of wider applicability by using typed predicates, but utilized a local approach. In this paper we developed an algorithm that uses global optimization to learn widely-applicable entailment rules between typed predicates (where both arguments are variables). T</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2010</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2010. Global learning of focused entailment graphs. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Patrick Pantel</author>
<author>Eduard Hovy</author>
</authors>
<title>LEDIR: An unsupervised algorithm for learning directionality of inference rules.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="7160" citStr="Bhagat et al., 2007" startWordPosition="1090" endWordPosition="1094">9). This representation performs well, but suffers when data is sparse. The binary-DIRT representation deals with sparsity by representing a predicate with a pair of vectors, one for each argument (Lin and Pantel, 2001). Last, a richer form of representation, termed unary, has been suggested where a different predicate is defined for each argument (Szpektor and Dagan, 2008). Different algorithms also differ in their similarity function. Some employ symmetric functions, geared towards paraphrasing (bi-directional entailment), while others choose directional measures more suited for entailment (Bhagat et al., 2007). In this paper, We employ several such functions, such as Lin (Lin and Pantel, 2001), and BInc (Szpektor and Dagan, 2008). Schoenmackers et al. (2010) recently used distributional similarity to learn rules between typed predicates, where the left-hand-side of the rule may contain more than a single predicate (horn clauses). In their work, they used Hearst-patterns (Hearst, 1992) to extract a set of 29 million (argument, type) pairs from a large web crawl. Then, they employed several filtering methods to clean this set and automatically produced a mapping of 1.1 million arguments into 156 type</context>
</contexts>
<marker>Bhagat, Pantel, Hovy, 2007</marker>
<rawString>Rahul Bhagat, Patrick Pantel, and Eduard Hovy. 2007. LEDIR: An unsupervised algorithm for learning directionality of inference rules. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>31--273</pages>
<contexts>
<context position="9256" citStr="Clarke and Lapata, 2008" startWordPosition="1418" endWordPosition="1421">on (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linear objective function over a set of integer variables is maximized under a set of linear constraints. Scaling ILP is challenging since it is an NP-complete problem. ILP has been extensively used in NLP lately (Clarke and Lapata, 2008; Martins et al., 2009; Do and Roth, 2010). 3 Typed Entailment Graphs Given a set of typed predicates, entailment rules can only exist between predicates that share the same (unordered) pair of types (such as place and country)3. Hence, every pair of types defines a graph that describes the entailment relations between predicates sharing those types (Figure 1). Next, we show how to represent entailment rules between typed predicates in a structure termed typed entailment graph, which will be the learning goal of our algorithm. A typed entailment graph is a directed graph where the nodes are ty</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>James Clarke and Mirella Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal of Artificial Intelligence Research, 31:273–381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Bernardo Magnini</author>
<author>Dan Roth</author>
</authors>
<title>Recognizing textual entailment: Rational, evaluation and approaches.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="1262" citStr="Dagan et al., 2009" startWordPosition="178" endWordPosition="181"> apply the algorithm over a large data set of extracted predicate instances, from which a resource of typed entailment rules has been recently released (Schoenmackers et al., 2010). Our results show that using global transitivity information substantially improves performance over this resource and several baselines, and that our scaling methods allow us to increase the scope of global learning of entailment-rule graphs. 1 Introduction Generic approaches for applied semantic inference from text gained growing attention in recent years, particularly under the Textual Entailment (TE) framework (Dagan et al., 2009). TE is a generic paradigm for semantic inference, where the objective is to recognize whether a target meaning can be inferred from a given text. A crucial component of inference systems is extensive resources of entailment rules, also known as inference rules, i.e., rules that specify a directional inference relation between fragments of text. One important type of rule is rules that specify entailment relations between predicates and their arguments. For example, the rule ‘X annex Y —* X control Y’ helps recognize that the text ‘Japan annexed Okinawa’ answers the question ‘Which country con</context>
</contexts>
<marker>Dagan, Dolan, Magnini, Roth, 2009</marker>
<rawString>Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth. 2009. Recognizing textual entailment: Rational, evaluation and approaches. Natural Language Engineering, 15(4):1–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Do</author>
<author>Dan Roth</author>
</authors>
<title>Constraints based taxonomic relation classification.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="9298" citStr="Do and Roth, 2010" startWordPosition="1426" endWordPosition="1429">tion Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linear objective function over a set of integer variables is maximized under a set of linear constraints. Scaling ILP is challenging since it is an NP-complete problem. ILP has been extensively used in NLP lately (Clarke and Lapata, 2008; Martins et al., 2009; Do and Roth, 2010). 3 Typed Entailment Graphs Given a set of typed predicates, entailment rules can only exist between predicates that share the same (unordered) pair of types (such as place and country)3. Hence, every pair of types defines a graph that describes the entailment relations between predicates sharing those types (Figure 1). Next, we show how to represent entailment rules between typed predicates in a structure termed typed entailment graph, which will be the learning goal of our algorithm. A typed entailment graph is a directed graph where the nodes are typed predicates. A typed predicate is a tri</context>
</contexts>
<marker>Do, Roth, 2010</marker>
<rawString>Quang Do and Dan Roth. 2010. Constraints based taxonomic relation classification. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saso Dzeroski</author>
<author>Ivan Brakto</author>
</authors>
<title>Handling noise in inductive logic programming.</title>
<date>1992</date>
<booktitle>In Proceedings of the International Workshop on Inductive Logic Programming.</booktitle>
<contexts>
<context position="15048" citStr="Dzeroski and Brakto, 1992" startWordPosition="2352" endWordPosition="2355">t) 9 win(place,event) Table 1: Automatically generated training set examples. similarity score estimating whether p1 entails p2. We compute 11 distributional similarity scores for each pair of predicates based on the arguments appearing in the extracted arguments. The first 6 scores are computed by trying all combinations of the similarity functions Lin and BInc with the feature representations unary, binary-DIRT and binary (see Section 2). The other 5 scores were provided by Schoenmackers et al. (2010) and include SR (Schoenmackers et al., 2010), LIME (McCreath and Sharma, 1997), M-estimate (Dzeroski and Brakto, 1992), the standard G-test and a simple implementation of Cover (Weeds and Weir, 2003). Overall, the rationale behind this representation is that combining various scores will yield a better classifier than each single measure. 3) Training We train over an equal number of positive and negative examples, as classifiers tend to perform poorly on the minority class when trained on imbalanced data (Van Hulse et al., 2007; Nikulin, 2008). 4.2 ILP formulation Once the classifier is trained, we would like to learn all edges (entailment rules) of each typed entailment graph. Given a set of predicates V and</context>
</contexts>
<marker>Dzeroski, Brakto, 1992</marker>
<rawString>Saso Dzeroski and Ivan Brakto. 1992. Handling noise in inductive logic programming. In Proceedings of the International Workshop on Inductive Logic Programming.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database (Language, Speech, and Communication).</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Enforcing transitivity in coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers.</booktitle>
<contexts>
<context position="8662" citStr="Finkel and Manning, 2008" startWordPosition="1321" endWordPosition="1324">ty) and common in(disease,place)), and learn 30,000 rules between these predicates2. In this paper we will learn entailment rules over the same data set, which was generously provided by 2The rules and the mapping of arguments into types can be downloaded from http://www.cs.washington.edu/research/ sherlock-hornclauses/ 611 Schoenmackers et al. As mentioned above, Berant et al. (2010) used global transitivity information to learn small entailment graphs. Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al., 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linear objective function over a set of integer variables is maximized under a set of linear constraints. Scaling ILP is challenging since it is an NP-complete problem. ILP has been extensively used in NLP lately (Clarke and Lapata, 2008; Mart</context>
<context position="22481" citStr="Finkel and Manning, 2008" startWordPosition="3711" endWordPosition="3715">an important role: low values make the graph sparser and easier to solve. In Section 5 we empirically test Algorithm 2 Incremental-ILP Input: A set V and a function f : V x V —* R Output: An optimal set of directed edges E* 1: ACT,VIO +— � 2: repeat 3: E* +— ApplyILPSolve(V,f,ACT) 4: VIO violated(V, E*) 5: ACT ACT U VIO 6: until |VIO |= 0 how typed entailment graphs benefit from decomposition given different prior values. From a more general perspective, this algorithm can be applied to any problem of learning a sparse transitive binary relation. Such problems include Co-reference Resolution (Finkel and Manning, 2008) and Temporal Information Extraction (Ling and Weld, 2010). Last, the algorithm can be easily parallelized by solving each component on a different core. 4.4 Incremental ILP Another solution for scaling ILP is to employ incremental ILP, which has been used in dependency parsing (Riedel and Clarke, 2006). The idea is that even if we omit the transitivity constraints, we still expect most transitivity constraints to be satisfied, given a good local entailment classifier. Thus, it makes sense to avoid specifying the constraints ahead of time, but rather add them when they are violated. This is fo</context>
</contexts>
<marker>Finkel, Manning, 2008</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2008. Enforcing transitivity in coreference resolution. In Proceedings of ACL-08: HLT, Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="7542" citStr="Hearst, 1992" startWordPosition="1152" endWordPosition="1153">lgorithms also differ in their similarity function. Some employ symmetric functions, geared towards paraphrasing (bi-directional entailment), while others choose directional measures more suited for entailment (Bhagat et al., 2007). In this paper, We employ several such functions, such as Lin (Lin and Pantel, 2001), and BInc (Szpektor and Dagan, 2008). Schoenmackers et al. (2010) recently used distributional similarity to learn rules between typed predicates, where the left-hand-side of the rule may contain more than a single predicate (horn clauses). In their work, they used Hearst-patterns (Hearst, 1992) to extract a set of 29 million (argument, type) pairs from a large web crawl. Then, they employed several filtering methods to clean this set and automatically produced a mapping of 1.1 million arguments into 156 types. Examples for (argument, type) pairs are (EXODUS, book), (CHINA, country) and (ASTHMA, disease). Schoenmackers et al. then utilized the types, the mapped arguments and tuples from TextRunner (Banko et al., 2007) to generate 10,672 typed predicates (such as conquer(country,city) and common in(disease,place)), and learn 30,000 rules between these predicates2. In this paper we wil</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>A support vector method for multivariate performance measures.</title>
<date>2005</date>
<booktitle>In Proceedings of ICML.</booktitle>
<contexts>
<context position="25241" citStr="Joachims, 2005" startWordPosition="4179" endWordPosition="4180">0,672 distinct typed predicates over 156 types was provided by Schoenmackers et al. (2010). Readers are referred to their paper for details on mapping of tuples to typed predicates. Since entailment only occurs between predicates that share the same types, we decomposed predicates by their types (e.g., all predicates with the types place and disease) into 2,303 typed entailment graphs. The largest graph contains 118 nodes and the total number of potential rules is 263,756. We generated a training set by applying the procedure described in Section 4.1, yielding 2,644 examples. We used SVMperf (Joachims, 2005) to train a Gaussian kernel classifier and computed P,,„ by projecting the classifier output score, 5,,,,, with the sigmoid function: P,,„ = 1+exp(−S,,). We tuned two 1 SVM parameters using 5-fold cross validation and a development set of two typed entailment graphs. Next, we used our algorithm to learn rules. As mentioned in Section 4.2, we integrate background knowledge using the sets Ayes and Ano that contain predicate pairs for which we know whether entailment holds. Ayes was constructed with syntactic rules: We normalized each predicate by omitting the first word if it is a modal and turn</context>
</contexts>
<marker>Joachims, 2005</marker>
<rawString>Thorsten Joachims. 2005. A support vector method for multivariate performance measures. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper-Schuler</author>
<author>Hoa Trand Dang</author>
<author>Martha Palmer</author>
</authors>
<title>Class-based construction of verb lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of AAAI/IAAI.</booktitle>
<contexts>
<context position="26236" citStr="Kipper-Schuler et al., 2000" startWordPosition="4346" endWordPosition="4349">owledge using the sets Ayes and Ano that contain predicate pairs for which we know whether entailment holds. Ayes was constructed with syntactic rules: We normalized each predicate by omitting the first word if it is a modal and turning passives to actives. If two normalized predicates are equal they are synonymous and inserted into Ayes. Ano was constructed from 3 sources (1) Predicates differing by a single pair of words that are WordNet antonyms (2) Predicates differing by a single word of negation (3) Predicates p(t1, t2) and p(t2, t1) where p is a transitive verb (e.g., beat) in VerbNet (Kipper-Schuler et al., 2000). We compared our algorithm (termed ILPscale) to the following baselines. First, to 10,000 rules released by Schoenmackers et al. (2010) (Sherlock), where the LHS contains a single predicate (Schoenmackers et al. released 30,000 rules but 20,000 of those have more than one predicate on the LHS, see Section 2), as we learn rules over the same data set. Second, to distributional similarity algorithms: (a) SR: the score used by Schoenmackers et al. as part of the Sherlock system. (b) DIRT: (Lin and Pantel, 2001) a widely-used rule learning algorithm. (c) BInc: (Szpektor and Dagan, 2008) a directi</context>
</contexts>
<marker>Kipper-Schuler, Dang, Palmer, 2000</marker>
<rawString>Karin Kipper-Schuler, Hoa Trand Dang, and Martha Palmer. 2000. Class-based construction of verb lexicon. In Proceedings of AAAI/IAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="1987" citStr="Lin and Pantel, 2001" startWordPosition="293" endWordPosition="296">eaning can be inferred from a given text. A crucial component of inference systems is extensive resources of entailment rules, also known as inference rules, i.e., rules that specify a directional inference relation between fragments of text. One important type of rule is rules that specify entailment relations between predicates and their arguments. For example, the rule ‘X annex Y —* X control Y’ helps recognize that the text ‘Japan annexed Okinawa’ answers the question ‘Which country controls Okinawa?’. Thus, acquisition of such knowledge received considerable attention in the last decade (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2009; Schoenmackers et al., 2010). Most past work took a “local learning” approach, learning each entailment rule independently of others. It is clear though, that there are global interactions between predicates. Notably, entailment is a transitive relation and so the rules A —* B and B —* C imply A —* C. Recently, Berant et al. (2010) proposed a global graph optimization procedure that uses Integer Linear Programming (ILP) to find the best set of entailment rules under a transitivity constraint. Imposing this constraint raised two challenges. The first of </context>
<context position="6759" citStr="Lin and Pantel, 2001" startWordPosition="1034" endWordPosition="1037"> with similar arguments. These algorithms usually represent a predicate with one or more vectors and use some function to compute argument similarity. Distributional similarity algorithms differ in their feature representation: Some use a binary representation: each predicate is represented by one feature vector where each feature is a pair of arguments (Szpektor et al., 2004; Yates and Etzioni, 2009). This representation performs well, but suffers when data is sparse. The binary-DIRT representation deals with sparsity by representing a predicate with a pair of vectors, one for each argument (Lin and Pantel, 2001). Last, a richer form of representation, termed unary, has been suggested where a different predicate is defined for each argument (Szpektor and Dagan, 2008). Different algorithms also differ in their similarity function. Some employ symmetric functions, geared towards paraphrasing (bi-directional entailment), while others choose directional measures more suited for entailment (Bhagat et al., 2007). In this paper, We employ several such functions, such as Lin (Lin and Pantel, 2001), and BInc (Szpektor and Dagan, 2008). Schoenmackers et al. (2010) recently used distributional similarity to lear</context>
<context position="26750" citStr="Lin and Pantel, 2001" startWordPosition="4432" endWordPosition="4435"> p(t1, t2) and p(t2, t1) where p is a transitive verb (e.g., beat) in VerbNet (Kipper-Schuler et al., 2000). We compared our algorithm (termed ILPscale) to the following baselines. First, to 10,000 rules released by Schoenmackers et al. (2010) (Sherlock), where the LHS contains a single predicate (Schoenmackers et al. released 30,000 rules but 20,000 of those have more than one predicate on the LHS, see Section 2), as we learn rules over the same data set. Second, to distributional similarity algorithms: (a) SR: the score used by Schoenmackers et al. as part of the Sherlock system. (b) DIRT: (Lin and Pantel, 2001) a widely-used rule learning algorithm. (c) BInc: (Szpektor and Dagan, 2008) a directional rule learning algorithm. Third, we compared to the entailment classifier with no transitivity constraints (clsf) to see if combining distributional similarity scores improves performance over single measures. Last, we added to all baselines background knowledge with Ayes and Ano (adding the subscript Xk to their name). To evaluate performance we manually annotated all edges in 10 typed entailment graphs - 7 twotypes entailment graphs containing 14, 22, 30, 53, 62, 86 and 118 nodes, and 3 single-type enta</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Temporal information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="8717" citStr="Ling and Weld, 2010" startWordPosition="1329" endWordPosition="1332">tween these predicates2. In this paper we will learn entailment rules over the same data set, which was generously provided by 2The rules and the mapping of arguments into types can be downloaded from http://www.cs.washington.edu/research/ sherlock-hornclauses/ 611 Schoenmackers et al. As mentioned above, Berant et al. (2010) used global transitivity information to learn small entailment graphs. Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al., 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linear objective function over a set of integer variables is maximized under a set of linear constraints. Scaling ILP is challenging since it is an NP-complete problem. ILP has been extensively used in NLP lately (Clarke and Lapata, 2008; Martins et al., 2009; Do and Roth, 2010). 3 Typed Entailmen</context>
<context position="22539" citStr="Ling and Weld, 2010" startWordPosition="3720" endWordPosition="3723"> to solve. In Section 5 we empirically test Algorithm 2 Incremental-ILP Input: A set V and a function f : V x V —* R Output: An optimal set of directed edges E* 1: ACT,VIO +— � 2: repeat 3: E* +— ApplyILPSolve(V,f,ACT) 4: VIO violated(V, E*) 5: ACT ACT U VIO 6: until |VIO |= 0 how typed entailment graphs benefit from decomposition given different prior values. From a more general perspective, this algorithm can be applied to any problem of learning a sparse transitive binary relation. Such problems include Co-reference Resolution (Finkel and Manning, 2008) and Temporal Information Extraction (Ling and Weld, 2010). Last, the algorithm can be easily parallelized by solving each component on a different core. 4.4 Incremental ILP Another solution for scaling ILP is to employ incremental ILP, which has been used in dependency parsing (Riedel and Clarke, 2006). The idea is that even if we omit the transitivity constraints, we still expect most transitivity constraints to be satisfied, given a good local entailment classifier. Thus, it makes sense to avoid specifying the constraints ahead of time, but rather add them when they are violated. This is formalized in Algorithm 2. Line 1 initializes an active set </context>
</contexts>
<marker>Ling, Weld, 2010</marker>
<rawString>Xiao Ling and Daniel S. Weld. 2010. Temporal information extraction. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Macleod</author>
<author>Ralph Grishman</author>
<author>Adam Meyers</author>
<author>Leslie Barrett</author>
<author>Ruth Reeves</author>
</authors>
<title>NOMLEX: A lexicon of nominalizations.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="5734" citStr="Macleod et al., 1998" startWordPosition="886" endWordPosition="889">7% over several baselines and that our scaling techniques allow dealing with larger graphs, resulting in improved coverage. 2 Background Most work on learning entailment rules between predicates considered each rule independently of others, using two sources of information: lexicographic resources and distributional similarity. Lexicographic resources are manually-prepared knowledge bases containing semantic information on predicates. A widely-used resource is WordNet (Fellbaum, 1998), where relations such as synonymy and hyponymy can be used to generate rules. Other resources include NomLex (Macleod et al., 1998; Szpektor and Dagan, 2009) and FrameNet (Baker and Lowe, 1998; Ben Aharon et al., 2010). Lexicographic resources are accurate but have 1The resource can be downloaded from http://www.cs.tau.ac.il/˜jonatha6/homepage files/resources /ACL2011Resource.zip low coverage. Distributional similarity algorithms use large corpora to learn broader resources by assuming that semantically similar predicates appear with similar arguments. These algorithms usually represent a predicate with one or more vectors and use some function to compute argument similarity. Distributional similarity algorithms differ i</context>
</contexts>
<marker>Macleod, Grishman, Meyers, Barrett, Reeves, 1998</marker>
<rawString>Catherine Macleod, Ralph Grishman, Adam Meyers, Leslie Barrett, and Ruth Reeves. 1998. NOMLEX: A lexicon of nominalizations. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="9278" citStr="Martins et al., 2009" startWordPosition="1422" endWordPosition="1425">008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linear objective function over a set of integer variables is maximized under a set of linear constraints. Scaling ILP is challenging since it is an NP-complete problem. ILP has been extensively used in NLP lately (Clarke and Lapata, 2008; Martins et al., 2009; Do and Roth, 2010). 3 Typed Entailment Graphs Given a set of typed predicates, entailment rules can only exist between predicates that share the same (unordered) pair of types (such as place and country)3. Hence, every pair of types defines a graph that describes the entailment relations between predicates sharing those types (Figure 1). Next, we show how to represent entailment rules between typed predicates in a structure termed typed entailment graph, which will be the learning goal of our algorithm. A typed entailment graph is a directed graph where the nodes are typed predicates. A type</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric McCreath</author>
<author>Arun Sharma</author>
</authors>
<title>ILP with noise and fixed example size: a bayesian approach.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifteenth international joint conference on artificial intelligence -</booktitle>
<volume>2</volume>
<contexts>
<context position="15008" citStr="McCreath and Sharma, 1997" startWordPosition="2347" endWordPosition="2350">minate(city,city) random hold(place,event) 9 win(place,event) Table 1: Automatically generated training set examples. similarity score estimating whether p1 entails p2. We compute 11 distributional similarity scores for each pair of predicates based on the arguments appearing in the extracted arguments. The first 6 scores are computed by trying all combinations of the similarity functions Lin and BInc with the feature representations unary, binary-DIRT and binary (see Section 2). The other 5 scores were provided by Schoenmackers et al. (2010) and include SR (Schoenmackers et al., 2010), LIME (McCreath and Sharma, 1997), M-estimate (Dzeroski and Brakto, 1992), the standard G-test and a simple implementation of Cover (Weeds and Weir, 2003). Overall, the rationale behind this representation is that combining various scores will yield a better classifier than each single measure. 3) Training We train over an equal number of positive and negative examples, as classifiers tend to perform poorly on the minority class when trained on imbalanced data (Van Hulse et al., 2007; Nikulin, 2008). 4.2 ILP formulation Once the classifier is trained, we would like to learn all edges (entailment rules) of each typed entailmen</context>
</contexts>
<marker>McCreath, Sharma, 1997</marker>
<rawString>Eric McCreath and Arun Sharma. 1997. ILP with noise and fixed example size: a bayesian approach. In Proceedings of the Fifteenth international joint conference on artificial intelligence - Volume 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Nikulin</author>
</authors>
<title>Classification of imbalanced data with random sets and mean-variance filtering.</title>
<date>2008</date>
<journal>IJDWM,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="15479" citStr="Nikulin, 2008" startWordPosition="2424" endWordPosition="2425">. The other 5 scores were provided by Schoenmackers et al. (2010) and include SR (Schoenmackers et al., 2010), LIME (McCreath and Sharma, 1997), M-estimate (Dzeroski and Brakto, 1992), the standard G-test and a simple implementation of Cover (Weeds and Weir, 2003). Overall, the rationale behind this representation is that combining various scores will yield a better classifier than each single measure. 3) Training We train over an equal number of positive and negative examples, as classifiers tend to perform poorly on the minority class when trained on imbalanced data (Van Hulse et al., 2007; Nikulin, 2008). 4.2 ILP formulation Once the classifier is trained, we would like to learn all edges (entailment rules) of each typed entailment graph. Given a set of predicates V and an entailment score function f : V x V —* R derived from the classifier, we want to find a graph G = (V, E) that respects transitivity and maximizes the sum of edge weights E(u v)EE f (u, v). This problem is NP-hard by a reduction from the NP-hard Transitive Subgraph problem (Yannakakis, 1978). Thus, employing ILP is an appealing approach for obtaining an optimal solution. For two-types entailment graphs the formulation is sim</context>
</contexts>
<marker>Nikulin, 2008</marker>
<rawString>Vladimir Nikulin. 2008. Classification of imbalanced data with random sets and mean-variance filtering. IJDWM, 4(2):63–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised ontology induction from text.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8780" citStr="Poon and Domingos, 2010" startWordPosition="1338" endWordPosition="1342">ment rules over the same data set, which was generously provided by 2The rules and the mapping of arguments into types can be downloaded from http://www.cs.washington.edu/research/ sherlock-hornclauses/ 611 Schoenmackers et al. As mentioned above, Berant et al. (2010) used global transitivity information to learn small entailment graphs. Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al., 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linear objective function over a set of integer variables is maximized under a set of linear constraints. Scaling ILP is challenging since it is an NP-complete problem. ILP has been extensively used in NLP lately (Clarke and Lapata, 2008; Martins et al., 2009; Do and Roth, 2010). 3 Typed Entailment Graphs Given a set of typed predicates, entailment rules can </context>
</contexts>
<marker>Poon, Domingos, 2010</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2010. Unsupervised ontology induction from text. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>James Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="4618" citStr="Riedel and Clarke, 2006" startWordPosition="723" endWordPosition="726">ty. Their method employs a local learning approach, while the number of predicates in their data is too large to be handled directly by an ILP solver. In this paper we suggest applying global optimization learning to open domain typed entailment rules. To that end, we show how to construct a structure termed typed entailment graph, where the nodes are typed predicates and the edges represent entailment rules. We suggest scaling techniques that allow to optimally learn such graphs over a large set of typed predicates by first decomposing nodes into components and then applying incremental ILP (Riedel and Clarke, 2006). Using these techniques, the obtained algorithm is guaranteed to return an optimal solution. We ran our algorithm over the data set of Schoenmackers et al. and release a resource of 30,000 rules1 that achieves substantially higher recall without harming precision. To the best of our knowledge, this is the first resource of that scale to use global optimization for learning predicative entailment rules. Our evaluation shows that global transitivity improves the Fi score of rule learning by 27% over several baselines and that our scaling techniques allow dealing with larger graphs, resulting in</context>
<context position="22785" citStr="Riedel and Clarke, 2006" startWordPosition="3760" endWordPosition="3763">5: ACT ACT U VIO 6: until |VIO |= 0 how typed entailment graphs benefit from decomposition given different prior values. From a more general perspective, this algorithm can be applied to any problem of learning a sparse transitive binary relation. Such problems include Co-reference Resolution (Finkel and Manning, 2008) and Temporal Information Extraction (Ling and Weld, 2010). Last, the algorithm can be easily parallelized by solving each component on a different core. 4.4 Incremental ILP Another solution for scaling ILP is to employ incremental ILP, which has been used in dependency parsing (Riedel and Clarke, 2006). The idea is that even if we omit the transitivity constraints, we still expect most transitivity constraints to be satisfied, given a good local entailment classifier. Thus, it makes sense to avoid specifying the constraints ahead of time, but rather add them when they are violated. This is formalized in Algorithm 2. Line 1 initializes an active set of constraints and a violated set of constraints (ACT;VIO). Line 3 applies the ILP solver with the active constraints. Lines 4 and 5 find the violated constraints and add them to the active constraints. The algorithm halts when no constraints are</context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>Sebastian Riedel and James Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Schoenmackers</author>
<author>Oren Etzioni Jesse Davis</author>
<author>Daniel S Weld</author>
</authors>
<title>Learning first-order horn clauses from web text.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="823" citStr="Schoenmackers et al., 2010" startWordPosition="113" endWordPosition="116">l jonatha6@post.tau.ac.il dagan@cs.biu.ac.il goldbej@eng.biu.ac.il Abstract Extensive knowledge bases of entailment rules between predicates are crucial for applied semantic inference. In this paper we propose an algorithm that utilizes transitivity constraints to learn a globally-optimal set of entailment rules for typed predicates. We model the task as a graph learning problem and suggest methods that scale the algorithm to larger graphs. We apply the algorithm over a large data set of extracted predicate instances, from which a resource of typed entailment rules has been recently released (Schoenmackers et al., 2010). Our results show that using global transitivity information substantially improves performance over this resource and several baselines, and that our scaling methods allow us to increase the scope of global learning of entailment-rule graphs. 1 Introduction Generic approaches for applied semantic inference from text gained growing attention in recent years, particularly under the Textual Entailment (TE) framework (Dagan et al., 2009). TE is a generic paradigm for semantic inference, where the objective is to recognize whether a target meaning can be inferred from a given text. A crucial comp</context>
<context position="2056" citStr="Schoenmackers et al., 2010" startWordPosition="303" endWordPosition="307">of inference systems is extensive resources of entailment rules, also known as inference rules, i.e., rules that specify a directional inference relation between fragments of text. One important type of rule is rules that specify entailment relations between predicates and their arguments. For example, the rule ‘X annex Y —* X control Y’ helps recognize that the text ‘Japan annexed Okinawa’ answers the question ‘Which country controls Okinawa?’. Thus, acquisition of such knowledge received considerable attention in the last decade (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2009; Schoenmackers et al., 2010). Most past work took a “local learning” approach, learning each entailment rule independently of others. It is clear though, that there are global interactions between predicates. Notably, entailment is a transitive relation and so the rules A —* B and B —* C imply A —* C. Recently, Berant et al. (2010) proposed a global graph optimization procedure that uses Integer Linear Programming (ILP) to find the best set of entailment rules under a transitivity constraint. Imposing this constraint raised two challenges. The first of ambiguity: transitivity does not always hold when predicates are ambi</context>
<context position="3449" citStr="Schoenmackers et al. (2010)" startWordPosition="546" endWordPosition="549">second challenge is scalability: ILP solvers do not scale well since ILP is an NP-complete problem. Berant et al. circumvented these issues by learning rules where one of the predicate’s arguments is instantiated (e.g., ‘X reduce nausea —* X affect nausea’), which is useful for learning small graphs on-the-fly, given a target concept such as nausea. While rules may be effectively learned when needed, their scope is narrow and they are not useful as a generic knowledge resource. This paper aims to take global rule learning one step further. To this end, we adopt the representation suggested by Schoenmackers et al. (2010), who learned inference rules between typed predicates, i.e., predicates where the argument types (e.g., city or drug) are specified. Schoenmackers et al. uti610 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 610–619, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics lized typed predicates since they were dealing with noisy and ambiguous web text. Typing predicates helps disambiguation and filtering of noise, while still maintaining rules of wide-applicability. Their method employs a local learning approach, whi</context>
<context position="7311" citStr="Schoenmackers et al. (2010)" startWordPosition="1116" endWordPosition="1119">dicate with a pair of vectors, one for each argument (Lin and Pantel, 2001). Last, a richer form of representation, termed unary, has been suggested where a different predicate is defined for each argument (Szpektor and Dagan, 2008). Different algorithms also differ in their similarity function. Some employ symmetric functions, geared towards paraphrasing (bi-directional entailment), while others choose directional measures more suited for entailment (Bhagat et al., 2007). In this paper, We employ several such functions, such as Lin (Lin and Pantel, 2001), and BInc (Szpektor and Dagan, 2008). Schoenmackers et al. (2010) recently used distributional similarity to learn rules between typed predicates, where the left-hand-side of the rule may contain more than a single predicate (horn clauses). In their work, they used Hearst-patterns (Hearst, 1992) to extract a set of 29 million (argument, type) pairs from a large web crawl. Then, they employed several filtering methods to clean this set and automatically produced a mapping of 1.1 million arguments into 156 types. Examples for (argument, type) pairs are (EXODUS, book), (CHINA, country) and (ASTHMA, disease). Schoenmackers et al. then utilized the types, the ma</context>
<context position="14930" citStr="Schoenmackers et al. (2010)" startWordPosition="2335" endWordPosition="2338">cohypo. invade(country,city) 9 bomb(country,city) hypo. defeat(city,city) 9 eliminate(city,city) random hold(place,event) 9 win(place,event) Table 1: Automatically generated training set examples. similarity score estimating whether p1 entails p2. We compute 11 distributional similarity scores for each pair of predicates based on the arguments appearing in the extracted arguments. The first 6 scores are computed by trying all combinations of the similarity functions Lin and BInc with the feature representations unary, binary-DIRT and binary (see Section 2). The other 5 scores were provided by Schoenmackers et al. (2010) and include SR (Schoenmackers et al., 2010), LIME (McCreath and Sharma, 1997), M-estimate (Dzeroski and Brakto, 1992), the standard G-test and a simple implementation of Cover (Weeds and Weir, 2003). Overall, the rationale behind this representation is that combining various scores will yield a better classifier than each single measure. 3) Training We train over an equal number of positive and negative examples, as classifiers tend to perform poorly on the minority class when trained on imbalanced data (Van Hulse et al., 2007; Nikulin, 2008). 4.2 ILP formulation Once the classifier is traine</context>
<context position="24716" citStr="Schoenmackers et al. (2010)" startWordPosition="4089" endWordPosition="4093">gorithm on our evaluation data set (Section 5) and found that it converges in at most 6 iterations and that the maximal number of active constraints in large graphs drops from _ 106 to _ 103 − 104. 5 Experimental Evaluation In this section we empirically answer the following questions: (1) Does transitivity improve rule learning over typed predicates? (Section 5.1) (2) Do Decomposed-ILP and Incremental-ILP improve scalability? (Section 5.2) 5.1 Experiment 1 A data set of 1 million TextRunner tuples (Banko et al., 2007), mapped to 10,672 distinct typed predicates over 156 types was provided by Schoenmackers et al. (2010). Readers are referred to their paper for details on mapping of tuples to typed predicates. Since entailment only occurs between predicates that share the same types, we decomposed predicates by their types (e.g., all predicates with the types place and disease) into 2,303 typed entailment graphs. The largest graph contains 118 nodes and the total number of potential rules is 263,756. We generated a training set by applying the procedure described in Section 4.1, yielding 2,644 examples. We used SVMperf (Joachims, 2005) to train a Gaussian kernel classifier and computed P,,„ by projecting the </context>
<context position="26372" citStr="Schoenmackers et al. (2010)" startWordPosition="4367" endWordPosition="4370">ntactic rules: We normalized each predicate by omitting the first word if it is a modal and turning passives to actives. If two normalized predicates are equal they are synonymous and inserted into Ayes. Ano was constructed from 3 sources (1) Predicates differing by a single pair of words that are WordNet antonyms (2) Predicates differing by a single word of negation (3) Predicates p(t1, t2) and p(t2, t1) where p is a transitive verb (e.g., beat) in VerbNet (Kipper-Schuler et al., 2000). We compared our algorithm (termed ILPscale) to the following baselines. First, to 10,000 rules released by Schoenmackers et al. (2010) (Sherlock), where the LHS contains a single predicate (Schoenmackers et al. released 30,000 rules but 20,000 of those have more than one predicate on the LHS, see Section 2), as we learn rules over the same data set. Second, to distributional similarity algorithms: (a) SR: the score used by Schoenmackers et al. as part of the Sherlock system. (b) DIRT: (Lin and Pantel, 2001) a widely-used rule learning algorithm. (c) BInc: (Szpektor and Dagan, 2008) a directional rule learning algorithm. Third, we compared to the entailment classifier with no transitivity constraints (clsf) to see if combinin</context>
</contexts>
<marker>Schoenmackers, Davis, Weld, 2010</marker>
<rawString>Stefan Schoenmackers, Oren Etzioni Jesse Davis, and Daniel S. Weld. 2010. Learning first-order horn clauses from web text. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>Automatic paraphrase discovery based on context and keywords between ne pairs.</title>
<date>2005</date>
<booktitle>In Proceedings of IWP.</booktitle>
<contexts>
<context position="2001" citStr="Sekine, 2005" startWordPosition="297" endWordPosition="298"> from a given text. A crucial component of inference systems is extensive resources of entailment rules, also known as inference rules, i.e., rules that specify a directional inference relation between fragments of text. One important type of rule is rules that specify entailment relations between predicates and their arguments. For example, the rule ‘X annex Y —* X control Y’ helps recognize that the text ‘Japan annexed Okinawa’ answers the question ‘Which country controls Okinawa?’. Thus, acquisition of such knowledge received considerable attention in the last decade (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2009; Schoenmackers et al., 2010). Most past work took a “local learning” approach, learning each entailment rule independently of others. It is clear though, that there are global interactions between predicates. Notably, entailment is a transitive relation and so the rules A —* B and B —* C imply A —* C. Recently, Berant et al. (2010) proposed a global graph optimization procedure that uses Integer Linear Programming (ILP) to find the best set of entailment rules under a transitivity constraint. Imposing this constraint raised two challenges. The first of ambiguity: tra</context>
</contexts>
<marker>Sekine, 2005</marker>
<rawString>Satoshi Sekine. 2005. Automatic paraphrase discovery based on context and keywords between ne pairs. In Proceedings of IWP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8610" citStr="Snow et al., 2006" startWordPosition="1314" endWordPosition="1317"> typed predicates (such as conquer(country,city) and common in(disease,place)), and learn 30,000 rules between these predicates2. In this paper we will learn entailment rules over the same data set, which was generously provided by 2The rules and the mapping of arguments into types can be downloaded from http://www.cs.washington.edu/research/ sherlock-hornclauses/ 611 Schoenmackers et al. As mentioned above, Berant et al. (2010) used global transitivity information to learn small entailment graphs. Transitivity was also used as an information source in other fields of NLP: Taxonomy Induction (Snow et al., 2006), Co-reference Resolution (Finkel and Manning, 2008), Temporal Information Extraction (Ling and Weld, 2010), and Unsupervised Ontology Induction (Poon and Domingos, 2010). Our proposed algorithm applies to any sparse transitive relation, and so might be applicable in these fields as well. Last, we formulate our optimization problem as an Integer Linear Program (ILP). ILP is an optimization problem where a linear objective function over a set of integer variables is maximized under a set of linear constraints. Scaling ILP is challenging since it is an NP-complete problem. ILP has been extensive</context>
<context position="18227" citStr="Snow et al. (2006)" startWordPosition="2922" endWordPosition="2925"> by (Eq. 3, 4 and 5 still exist and are carried over in a trivial manner): Earg max Efd(u, v)Xuv + fr(u, v)Yuv (6) u�v u,v s.t. ∀u,v,wEV Xuv + Xvw − Xuw ≤ 1 ∀u,v,wEV Xuv + Yvw − Yuw ≤ 1 ∀u,v,wEV Yuv + Xvw − Yuw ≤ 1 ∀u,v,wEV Yuv + Yvw − Xuw ≤ 1 The modified constraints capture the transitivity behavior of direct-mapping and reversed-mapping edges, as described in Section 3. This results in 2n2 − n variables and about 4n3 transitivity constraints, cutting the ILP size in half. Next, we specify how to derive the function f from the trained classifier using a probabilistic formulation4. Following Snow et al. (2006) and Berant et al. (2010), we utilize a probabilistic entailment classifier that computes the posterior Puv = P(Xuv = 1|Fuv). We want to use Puv to derive the posterior P(G|F), where F = ∪u�vFuv and Fuv is the feature vector for a node pair (u, v). Since the classifier was trained on a balanced training set, the prior over the two entailment classes is uniform and so by Bayes rule Puv ∝ P(Fuv|Xuv = 1). Using that and the exact same three independence assumptions described by Snow et al. (2006) and Berant et al. (2010) we can show that (for brevity, we omit the full derivation): G� = arg maxG l</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning entailment rules for unary templates.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="6916" citStr="Szpektor and Dagan, 2008" startWordPosition="1059" endWordPosition="1062">stributional similarity algorithms differ in their feature representation: Some use a binary representation: each predicate is represented by one feature vector where each feature is a pair of arguments (Szpektor et al., 2004; Yates and Etzioni, 2009). This representation performs well, but suffers when data is sparse. The binary-DIRT representation deals with sparsity by representing a predicate with a pair of vectors, one for each argument (Lin and Pantel, 2001). Last, a richer form of representation, termed unary, has been suggested where a different predicate is defined for each argument (Szpektor and Dagan, 2008). Different algorithms also differ in their similarity function. Some employ symmetric functions, geared towards paraphrasing (bi-directional entailment), while others choose directional measures more suited for entailment (Bhagat et al., 2007). In this paper, We employ several such functions, such as Lin (Lin and Pantel, 2001), and BInc (Szpektor and Dagan, 2008). Schoenmackers et al. (2010) recently used distributional similarity to learn rules between typed predicates, where the left-hand-side of the rule may contain more than a single predicate (horn clauses). In their work, they used Hear</context>
<context position="26826" citStr="Szpektor and Dagan, 2008" startWordPosition="4443" endWordPosition="4446">rbNet (Kipper-Schuler et al., 2000). We compared our algorithm (termed ILPscale) to the following baselines. First, to 10,000 rules released by Schoenmackers et al. (2010) (Sherlock), where the LHS contains a single predicate (Schoenmackers et al. released 30,000 rules but 20,000 of those have more than one predicate on the LHS, see Section 2), as we learn rules over the same data set. Second, to distributional similarity algorithms: (a) SR: the score used by Schoenmackers et al. as part of the Sherlock system. (b) DIRT: (Lin and Pantel, 2001) a widely-used rule learning algorithm. (c) BInc: (Szpektor and Dagan, 2008) a directional rule learning algorithm. Third, we compared to the entailment classifier with no transitivity constraints (clsf) to see if combining distributional similarity scores improves performance over single measures. Last, we added to all baselines background knowledge with Ayes and Ano (adding the subscript Xk to their name). To evaluate performance we manually annotated all edges in 10 typed entailment graphs - 7 twotypes entailment graphs containing 14, 22, 30, 53, 62, 86 and 118 nodes, and 3 single-type entailment graphs containing 7, 38 and 59 nodes. This annotation yielded 3,427 e</context>
</contexts>
<marker>Szpektor, Dagan, 2008</marker>
<rawString>Idan Szpektor and Ido Dagan. 2008. Learning entailment rules for unary templates. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Augmenting wordnet-based inference with argument mapping.</title>
<date>2009</date>
<booktitle>In Proceedings of TextInfer.</booktitle>
<contexts>
<context position="2027" citStr="Szpektor and Dagan, 2009" startWordPosition="299" endWordPosition="302">text. A crucial component of inference systems is extensive resources of entailment rules, also known as inference rules, i.e., rules that specify a directional inference relation between fragments of text. One important type of rule is rules that specify entailment relations between predicates and their arguments. For example, the rule ‘X annex Y —* X control Y’ helps recognize that the text ‘Japan annexed Okinawa’ answers the question ‘Which country controls Okinawa?’. Thus, acquisition of such knowledge received considerable attention in the last decade (Lin and Pantel, 2001; Sekine, 2005; Szpektor and Dagan, 2009; Schoenmackers et al., 2010). Most past work took a “local learning” approach, learning each entailment rule independently of others. It is clear though, that there are global interactions between predicates. Notably, entailment is a transitive relation and so the rules A —* B and B —* C imply A —* C. Recently, Berant et al. (2010) proposed a global graph optimization procedure that uses Integer Linear Programming (ILP) to find the best set of entailment rules under a transitivity constraint. Imposing this constraint raised two challenges. The first of ambiguity: transitivity does not always </context>
<context position="5761" citStr="Szpektor and Dagan, 2009" startWordPosition="890" endWordPosition="893">nes and that our scaling techniques allow dealing with larger graphs, resulting in improved coverage. 2 Background Most work on learning entailment rules between predicates considered each rule independently of others, using two sources of information: lexicographic resources and distributional similarity. Lexicographic resources are manually-prepared knowledge bases containing semantic information on predicates. A widely-used resource is WordNet (Fellbaum, 1998), where relations such as synonymy and hyponymy can be used to generate rules. Other resources include NomLex (Macleod et al., 1998; Szpektor and Dagan, 2009) and FrameNet (Baker and Lowe, 1998; Ben Aharon et al., 2010). Lexicographic resources are accurate but have 1The resource can be downloaded from http://www.cs.tau.ac.il/˜jonatha6/homepage files/resources /ACL2011Resource.zip low coverage. Distributional similarity algorithms use large corpora to learn broader resources by assuming that semantically similar predicates appear with similar arguments. These algorithms usually represent a predicate with one or more vectors and use some function to compute argument similarity. Distributional similarity algorithms differ in their feature representat</context>
</contexts>
<marker>Szpektor, Dagan, 2009</marker>
<rawString>Idan Szpektor and Ido Dagan. 2009. Augmenting wordnet-based inference with argument mapping. In Proceedings of TextInfer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventura Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="6516" citStr="Szpektor et al., 2004" startWordPosition="994" endWordPosition="997">loaded from http://www.cs.tau.ac.il/˜jonatha6/homepage files/resources /ACL2011Resource.zip low coverage. Distributional similarity algorithms use large corpora to learn broader resources by assuming that semantically similar predicates appear with similar arguments. These algorithms usually represent a predicate with one or more vectors and use some function to compute argument similarity. Distributional similarity algorithms differ in their feature representation: Some use a binary representation: each predicate is represented by one feature vector where each feature is a pair of arguments (Szpektor et al., 2004; Yates and Etzioni, 2009). This representation performs well, but suffers when data is sparse. The binary-DIRT representation deals with sparsity by representing a predicate with a pair of vectors, one for each argument (Lin and Pantel, 2001). Last, a richer form of representation, termed unary, has been suggested where a different predicate is defined for each argument (Szpektor and Dagan, 2008). Different algorithms also differ in their similarity function. Some employ symmetric functions, geared towards paraphrasing (bi-directional entailment), while others choose directional measures more</context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Van Hulse</author>
<author>Taghi Khoshgoftaar</author>
<author>Amri Napolitano</author>
</authors>
<title>Experimental perspectives on learning from imbalanced data.</title>
<date>2007</date>
<booktitle>In Proceedings of ICML.</booktitle>
<marker>Van Hulse, Khoshgoftaar, Napolitano, 2007</marker>
<rawString>Jason Van Hulse, Taghi Khoshgoftaar, and Amri Napolitano. 2007. Experimental perspectives on learning from imbalanced data. In Proceedings of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie Weeds</author>
<author>David Weir</author>
</authors>
<title>A general framework for distributional similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="15129" citStr="Weeds and Weir, 2003" startWordPosition="2366" endWordPosition="2369">ty score estimating whether p1 entails p2. We compute 11 distributional similarity scores for each pair of predicates based on the arguments appearing in the extracted arguments. The first 6 scores are computed by trying all combinations of the similarity functions Lin and BInc with the feature representations unary, binary-DIRT and binary (see Section 2). The other 5 scores were provided by Schoenmackers et al. (2010) and include SR (Schoenmackers et al., 2010), LIME (McCreath and Sharma, 1997), M-estimate (Dzeroski and Brakto, 1992), the standard G-test and a simple implementation of Cover (Weeds and Weir, 2003). Overall, the rationale behind this representation is that combining various scores will yield a better classifier than each single measure. 3) Training We train over an equal number of positive and negative examples, as classifiers tend to perform poorly on the minority class when trained on imbalanced data (Van Hulse et al., 2007; Nikulin, 2008). 4.2 ILP formulation Once the classifier is trained, we would like to learn all edges (entailment rules) of each typed entailment graph. Given a set of predicates V and an entailment score function f : V x V —* R derived from the classifier, we want</context>
</contexts>
<marker>Weeds, Weir, 2003</marker>
<rawString>Julie Weeds and David Weir. 2003. A general framework for distributional similarity. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihalis Yannakakis</author>
</authors>
<title>Node-and edge-deletion NPcomplete problems.</title>
<date>1978</date>
<booktitle>In STOC ’78: Proceedings of the tenth annual ACM symposium on Theory of computing,</booktitle>
<pages>253--264</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="15943" citStr="Yannakakis, 1978" startWordPosition="2509" endWordPosition="2510">nd negative examples, as classifiers tend to perform poorly on the minority class when trained on imbalanced data (Van Hulse et al., 2007; Nikulin, 2008). 4.2 ILP formulation Once the classifier is trained, we would like to learn all edges (entailment rules) of each typed entailment graph. Given a set of predicates V and an entailment score function f : V x V —* R derived from the classifier, we want to find a graph G = (V, E) that respects transitivity and maximizes the sum of edge weights E(u v)EE f (u, v). This problem is NP-hard by a reduction from the NP-hard Transitive Subgraph problem (Yannakakis, 1978). Thus, employing ILP is an appealing approach for obtaining an optimal solution. For two-types entailment graphs the formulation is simple: The ILP variables are indicators Xuv denoting whether an edge (u, v) is in the graph, with the following ILP: invade (country,place) be part of (place,country) annex (country,place) province of (place,country) be relate to (drug,drug) be process from (drug,drug) be derive from (drug,drug) be convert into (drug,drug) 613 G� = arg max f(u, v) · Xuv u�v s.t. ∀u,v,wEV Xuv + Xvw − Xuw ≤ 1 ∀u,vEAyes Xuv = 1 ∀u,vEA�v Xuv = 0 ∀u7�v Xuv ∈ {0, 1} The objective in E</context>
</contexts>
<marker>Yannakakis, 1978</marker>
<rawString>Mihalis Yannakakis. 1978. Node-and edge-deletion NPcomplete problems. In STOC ’78: Proceedings of the tenth annual ACM symposium on Theory of computing, pages 253–264, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Oren Etzioni</author>
</authors>
<title>Unsupervised methods for determining object and relation synonyms on the web.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>34--255</pages>
<contexts>
<context position="6542" citStr="Yates and Etzioni, 2009" startWordPosition="998" endWordPosition="1001">cs.tau.ac.il/˜jonatha6/homepage files/resources /ACL2011Resource.zip low coverage. Distributional similarity algorithms use large corpora to learn broader resources by assuming that semantically similar predicates appear with similar arguments. These algorithms usually represent a predicate with one or more vectors and use some function to compute argument similarity. Distributional similarity algorithms differ in their feature representation: Some use a binary representation: each predicate is represented by one feature vector where each feature is a pair of arguments (Szpektor et al., 2004; Yates and Etzioni, 2009). This representation performs well, but suffers when data is sparse. The binary-DIRT representation deals with sparsity by representing a predicate with a pair of vectors, one for each argument (Lin and Pantel, 2001). Last, a richer form of representation, termed unary, has been suggested where a different predicate is defined for each argument (Szpektor and Dagan, 2008). Different algorithms also differ in their similarity function. Some employ symmetric functions, geared towards paraphrasing (bi-directional entailment), while others choose directional measures more suited for entailment (Bh</context>
</contexts>
<marker>Yates, Etzioni, 2009</marker>
<rawString>Alexander Yates and Oren Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal ofArtificial Intelligence Research, 34:255–296.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>