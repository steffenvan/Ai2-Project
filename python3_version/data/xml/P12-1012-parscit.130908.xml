<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000062">
<title confidence="0.990971">
Temporally Anchored Relation Extraction
</title>
<author confidence="0.976983">
Guillermo Garrido, Anselmo Pe˜nas, Bernardo Cabaleiro, and ´Alvaro Rodrigo
</author>
<affiliation confidence="0.666219">
NLP &amp; IR Group at UNED
</affiliation>
<address confidence="0.931725">
Madrid, Spain
</address>
<email confidence="0.998672">
{ggarrido,anselmo,bcabaleiro,alvarory}@lsi.uned.es
</email>
<sectionHeader confidence="0.995629" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99924185">
Although much work on relation extraction
has aimed at obtaining static facts, many of
the target relations are actually fluents, as their
validity is naturally anchored to a certain time
period. This paper proposes a methodologi-
cal approach to temporally anchored relation
extraction. Our proposal performs distant su-
pervised learning to extract a set of relations
from a natural language corpus, and anchors
each of them to an interval of temporal va-
lidity, aggregating evidence from documents
supporting the relation. We use a rich graph-
based document-level representation to gener-
ate novel features for this task. Results show
that our implementation for temporal anchor-
ing is able to achieve a 69% of the upper
bound performance imposed by the relation
extraction step. Compared to the state of the
art, the overall system achieves the highest
precision reported.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999688756756757">
A question that arises when extracting a relation is
how to capture its temporal validity: Can we assign a
period of time when the obtained relation held? As
pointed out in (Ling and Weld, 2010), while much
research in automatic relation extraction has focused
on distilling static facts from text, many of the tar-
get relations are in fact fluents, dynamic relations
whose truth value is dependent on time (Russell and
Norvig, 2010).
The Temporally anchored relation extraction
problem consists in, given a natural language text
document corpus, C, a target entity, e, and a target
relation, r, extracting from the corpus the value of
that relation for the entity, and a temporal interval
for which the relation was valid.
In this paper, we introduce a methodological ap-
proach to temporal anchoring of relations automat-
ically extracted from unrestricted text. Our system
(see Figure 1) extracts relational facts from text us-
ing distant supervision (Mintz et al., 2009) and then
anchors the relation to an interval of temporal va-
lidity. The intuition is that a distant supervised sys-
tem can effectively extract relations from the source
text collection, and a straightforward date aggrega-
tion can then be applied to anchor them. We pro-
pose a four step process for temporal anchoring:
(1) represent temporal evidence; (2) select tempo-
ral information relevant to the relation; (3) decide
how a relational fact and its relevant temporal in-
formation are themselves related; and (4) aggregate
imprecise temporal intervals across multiple docu-
ments. In contrast with previous approaches that
aim at intra-document temporal information extrac-
tion (Ling and Weld, 2010), we focus on mining
a corpus aggregating temporal evidences across the
supporting documents.
We address the following research questions:
</bodyText>
<listItem confidence="0.976692">
(1) Validate whether distant supervised learning is
suitable for the task, and evaluate its shortcomings.
(2) Explore whether the use of features extracted
</listItem>
<bodyText confidence="0.841515166666667">
from a document-level rich representation could im-
prove distant supervised learning. (3) Compare the
use of document metadata against temporal expres-
sions within the document for relation temporal an-
choring. (4) Analyze how, in a pipeline architecture,
the propagation of errors limits the overall system’s
</bodyText>
<page confidence="0.982773">
107
</page>
<note confidence="0.992541">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 107–116,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999934">
Figure 1: System overview diagram.
</figureCaption>
<bodyText confidence="0.998360083333333">
performance.
The representation we use for temporal informa-
tion is detailed in section 2; the rich document-level
representation we exploit is described in section 3.
For a query entity and target relation, the system first
performs relation extraction (section 4); then, we
find and aggregate time constraint evidence for the
same relation across different documents, to estab-
lish a temporal validity anchor interval (section 5).
Empirical comparative evaluation of our approach is
introduced in section 6; while some related work is
shown in section 7 and conclusions in section 8.
</bodyText>
<sectionHeader confidence="0.994861" genericHeader="introduction">
2 Temporal Anchors
</sectionHeader>
<bodyText confidence="0.999988774193548">
We will denominate relation instance a triple
(entity, relation name, value). We aim at anchor-
ing relation instances to their temporal validity. We
need a representation flexible enough to capture the
imprecise temporal information available in text,
but expressed in a structured style. Allen’s (1983)
interval-based algebra for temporal representation
and reasoning, underlies much research, such as the
Tempeval challenges (Verhagen et al., 2007; Puste-
jovsky and Verhagen, 2009). Our task is different,
as we focus on obtaining the temporal interval as-
sociated to a fact, rather than reasoning about the
temporal relations among the events appearing in a
single text.
Let us assume that each relation instance is valid
during a certain temporal interval, I = [t0, tf]. This
sharp temporal interval fails to capture the impreci-
sion of temporal boundaries conveyed in natural lan-
guage text. The Temporal Slot Filling task at TAC-
KBP 2011 (Ji et al., 2011) proposed a 4-tuple rep-
resentation that we will refer to as imprecise anchor
intervals. An imprecise temporal interval is defined
as an ordered 4-tuple of time points: (t1, t2, t3, t4),
with the following semantics: the relation is true for
a period which starts at some point between t1 and
t2 and ends between t3 and t4. It should hold that:
t1 &lt; t2, t3 &lt; t4, and t1 &lt; t4. Any of the four
endpoints can be left unconstrained (t1 or t3 would
be −oo, and t2 or t4 would be +oo). This represen-
tation is flexible and expressive, although it cannot
capture certain types of information (Ji et al., 2011).
</bodyText>
<sectionHeader confidence="0.983078" genericHeader="method">
3 Document Representation
</sectionHeader>
<bodyText confidence="0.999523761904762">
We use a rich document representation that employs
a graph structure obtained by augmenting the syn-
tactic dependency analysis of the document with se-
mantic information.
A document D is represented as a document
graph GD; with node set VD and edge set, ED. Each
node v E VD represents a chunk of text, which is a
sequence of words1. Each node is labeled with a
dictionary of attributes, some of which are common
for every node: the words it contains, their part-of-
speech annotations (POS) and lemmas. Also, a rep-
resentative descriptor, which is a normalized string
value, is generated from the chunks in the node. Cer-
tain nodes are also annotated with one or more types.
There are three families of types: Events (verbs
that describe an action, annotated with tense, polar-
ity and aspect); standardized Time Expressions; and
Named Entities, with additional annotations such as
gender or age.
Edges in the document graph, e E ED, represent
four kinds of relations between the nodes:
</bodyText>
<listItem confidence="0.999995">
• Syntactic: a dependency relation.
• Coreference: indicates that two chunks refer to
</listItem>
<footnote confidence="0.986985333333333">
1Most chunks consist in one word; we join words into a
chunk (and a node) in two cases: a multi-word named entity
and a verb and its auxiliaries.
</footnote>
<figure confidence="0.999694942857143">
Document
Index
(2) Document
Representation
Training
(3) Distant supervised
learning
Knowledge
Base
Training seeds
&lt; entity, relation name, value &gt;
(4) Classifiers
Training
examples
+ / -
Application
(5) Relation Extraction
relation
instances
unlabelled
candidate
Input: Query
entity
(1) IR candidate document
retrieval
Document
Collection
output:
temporally
anchored
relations
(6) Temporal Anchoring
Date Extraction
Date
Aggregation
</figure>
<page confidence="0.870852">
108
</page>
<figureCaption confidence="0.972049666666667">
Figure 2: Collapsed document graph representation, GC,
for the sample text document “David’s wife, Julia, is cel-
ebrating her birthday. She was born in September 1979”.
</figureCaption>
<bodyText confidence="0.973148">
the same discourse referent.
</bodyText>
<listItem confidence="0.99332825">
• Semantic relations between two nodes, such as
hasClass, hasProperty and hasAge.
• Temporal relations between events and time ex-
pressions.
</listItem>
<bodyText confidence="0.99995325">
The processing includes dependency parsing,
named entity recognition and coreference reso-
lution, done with the Stanford CoreNLP soft-
ware (Klein and Manning, 2003); and events and
temporal information extraction, via the TARSQI
Toolkit (Verhagen et al., 2005).
The document graph GD is then further trans-
formed into a collapsed document graph, GC. Each
node of GC clusters together coreferent nodes, rep-
resenting a discourse referent. Thus, a node u in GC
is a cluster of nodes ul, ... , uk of GD. There is an
edge (u, v) in GC if there was an edge between any
of the nodes clustered into u and any of the nodes
vl, ... , vky. The coreference edges do not appear in
this representation. Additional semantic information
is also blended into this representation: normaliza-
tion of genitives, semantic class indicators inferred
from appositions and genitives, and gender annota-
tion inferred from pronouns. A final graph example
can be seen in Figure 2.
</bodyText>
<sectionHeader confidence="0.991783" genericHeader="method">
4 Distant Supervised Relation Extraction
</sectionHeader>
<bodyText confidence="0.979584">
To perform relation extraction, our proposal fol-
lows a distant supervision approach (Mintz et al.,
2009), which has also inspired other slot filling sys-
tems (Agirre et al., 2009; Surdeanu et al., 2010).
We capture long distance relations by introducing
a document-level representation and deriving novel
features from deep syntactic and semantic analysis.
Seed harvesting. From a reference Knowledge
Base (KB), we extract a set of relation triples
or seeds: (entity, relation, value), where the
relation is one of the target relations. Our
document-level distant supervision assumption is
that if entity and value are found in a document
graph (see section 3), and there is a path connect-
ing them, then the document expresses the relation.
Relation candidates gathering. From a seed triple,
we retrieve candidate documents that contain both
the entity and value, within a span of 20 tokens,
using a standard IR approach. Then, entity and
value are matched to the document graph represen-
tation. We first use approximate string comparison
to find nodes matching the seed entity. After an en-
tity node has been found we use local breadth-first-
search (BFS) to find a matching value and the short-
est connecting path between them. We enforce the
Named Entity type of entity and value to match a
expected type, predefined for the relation.
Our procedure traverses the document graph look-
ing for entity and value nodes meeting those condi-
tions; when found, we generate features for a pos-
itive example for the relation2. If we encounter a
node that matches the expected NE type of the rela-
tion, but does not match the seed value, we generate
a negative example for that relation.
Training. From positive and negative examples, we
generate binary features; some of them are inspired
by previous work (Surdeanu and Ciaramita, 2007;
Mintz et al., 2009; Riedel et al., 2010; Surdeanu et
al., 2010), and others are novel, taking advantage of
our graph representation. Table 1 summarizes our
choice of features. Features appearing in less than 5
training examples were discarded.
Relation instance extraction. Given an input entity
and a target relation, we aim at finding a filler value
for a relation instance. This task is known as Slot
Filling. From the set of retrieved documents relevant
to the query entity, represented as document graphs,
2From the collapsed document graph representation we ob-
tained an average of 9213 positive training examples per slot;
from the uncollapsed document graph, a slightly lower average
of 8178.5 positive examples per slot.
</bodyText>
<figure confidence="0.999818613636364">
David[NNP,David]
is[VBZ,be] celebrating[VBG,celebrate]
NER: PERSON
DESCRIPTOR:
David
POS: N
was[VBD,be] born[VBN,bear]
ASPECT:PROGRESSIVE
TENSE:PRESENT
POLARITY:POS
DESCRIPTOR: celebrate
POS: V
has_wife
ASPECT:NONE
TENSE:PAST
POLARITY:POS
DESCRIPTOR: bear
POS: V
arg0 arg1
arg1
Julia[NNP,Julia]
birthday[NN,birthday]
DESCRIPTOR:
birthday
POS: NN
has
CLASS:WIFE
NER: PERSON
DESCRIPTOR:
Julia
POS: N
GENDER:FEMALE
prep_in
INCLUDES
hasClass
wife[NN,wife]
DESCRIPTOR:
wife
POS: NN
September[NNP,September] 1979[CD,1979]
NER:DATE
TIMEVALUE:197909
DESCRIPTOR: September 1979
POS: NNP
</figure>
<page confidence="0.731733">
109
</page>
<table confidence="0.6229002">
Feature name Description
path dependency path between ENTITY and
VALUE in the sentence
X-annotation NE annotations for X
X-pos Part-of-speech annotations for X
</table>
<tableCaption confidence="0.2222555">
X-gov Governor of X in the dependency path
X-mod Modifiers of X in the dependency path
</tableCaption>
<equation confidence="0.959769428571429">
X-has age X is a NE, with an age attribute
X-has class-C X is a NE, with a class C
X-property-P X is a NE, and it has a property P
X-has-Y X is a NE, with a possessive relation with
another NE, Y
X-is-Y X is a NE, in a copula with another NE, Y
X-gender-G X is a NE, and it has gender G
</equation>
<tableCaption confidence="0.643781142857143">
V-tense Tense of the verb V in the path
V-aspect Aspect of the verb V in the path
V-polarity Polarity (positive or negative) of the verb V
Table 1: Features included in the model. X stands for
ENTITY and VALUE. Verb features are generated from
the verbs, V , identified in the path between ENTITY and
VALUE.
</tableCaption>
<bodyText confidence="0.999473476190476">
we locate matching entities and start a local BFS of
candidate values, generating for them an unlabelled
example. For each of the relations to extract, a bi-
nary classifier (extractor) decides whether the exam-
ple is a valid relation instance. For each particular
relation classifier, only candidates with the expected
entity and value types for the relation were used in
the application phase. Each extractor was a SVM
classifier with linear kernel (Joachims, 2002). All
learning parameters were set to their default values.
The classification process yields a predicted class
label, plus a real number indicating the margin. We
performed an aggregation phase to sum the mar-
gins over distinct occurrences of the same extracted
value. The rationale is that when the same value is
extracted from more than one document, we should
accumulate that evidence.
The output of this phase is the set of extracted re-
lations (positive for each of the classifiers), plus the
documents where the same fact was detected (sup-
porting documents).
</bodyText>
<sectionHeader confidence="0.995093" genericHeader="method">
5 Temporal Anchoring of Relations
</sectionHeader>
<bodyText confidence="0.999631714285715">
In this section, we propose and discuss a unified
methodological approach for temporal anchoring of
relations. We assume the input is a relation instance
and a set of supporting documents. The task is es-
tablishing a imprecise temporal anchor interval for
the relation.
We present a four-step methodological approach:
(1) representation of intra-document temporal infor-
mation; (2) selection of relevant temporal informa-
tion for the relation; (3) mapping of the link between
relational fact and temporal information into an in-
terval; and (4) aggregation of imprecise intervals.
Temporal representation. The first methodologi-
cal step is to obtain and represent the available intra-
document temporal information; the input is a doc-
ument, and the task is to identify temporal signals
and possible links among them. We use the term link
for a relation between a temporal expression (a date)
and an event; we want to avoid confusion with the
term relation (a relational fact extracted from text).
In our particular implementation:
</bodyText>
<listItem confidence="0.91687145">
• We use TARSQI to extract temporal expressions
and link them to events. In particular, TARSQI
uses the following temporal links: included, si-
multaneous, after, before, begun by or ended.
• We focus also on the syntactic pattern [Event-
preposition-Time] within the lexical context of the
candidate entity and value.
• Both are normalized into one from a set of prede-
fined temporal links: within, throughout, begin-
ning, ending, after and before.
Selection of temporal evidence. For each docu-
ment and relational instance, we have to select those
temporal expressions that are relevant.
a. Document-level metadata. The default value
we use is the document creation time (DCT),
if available. The underlying assumption is that
there is a within link from each fact expressed in
the text and the document creation time.
b. Temporal expressions. Temporal evidence
comes also from the temporal expressions
</listItem>
<bodyText confidence="0.928868666666667">
present in the context of a relation. In our par-
ticular implementation, we followed a straight-
forward approach, looking for the time expres-
sion closest in the document graph to the short-
est path between the entity and value nodes. This
search is performed via a limited depth BFS,
starting from the nodes in the path, in order from
value to entity.
Mapping of temporal links into intervals. The
third step is deciding how a relational fact and its rel-
evant temporal information are themselves related.
We have to map this information, expressed in text,
</bodyText>
<page confidence="0.988869">
110
</page>
<table confidence="0.4261415">
Temporal link Constraints mapping
Before t4 = first
After t1 = last
Within and Throughout t2 = first and t3 = last
Beginning t1 = first and t2 = last
Ending t3 = first and t4 = last
</table>
<tableCaption confidence="0.9947485">
Table 2: Mapping from time expression and temporal re-
lation to temporal constraints.
</tableCaption>
<bodyText confidence="0.998678352941177">
to a temporal representation. We will use the impre-
cise anchor intervals described is section 2.
Let T be a temporal expression identified in the
document or its metadata. Now, the mapping of tem-
poral constraints depends on the temporal link to the
time expression identified; also, the semantics of the
event have to be considered in order to decide the
time period associated to a relation instance. This
step is important because the event could refer just to
the beginning of the relation, its ending, or both. For
instance, it is obvious that having the event marry
is different to having the event divorce, when decid-
ing the temporal constraints associated to the spouse
relation.
Table 2 shows our particular mapping between
temporal links and constraints. In particular, for the
default document creation time, we suppose that a
relation which appears in a document with creation
time d held true at least in that date; that is, we are
assuming a within link, and we map t2 = d, t3 = d.
Inter-document temporal evidence aggregation.
The last step is aggregating all the time constraints
found for the same relation and value across differ-
ent documents. If we found that a relation started af-
ter two dates d and d&apos;, where d&apos; &gt; d, the closest con-
straint to the real start of the relation is d&apos;. Mapped to
temporal constraints, it means that we would choose
the biggest t1 possible. Following the same reason-
ing, we would want to maximize t3. On the other
side, when a relation started before two dates d2 and
d&apos;2, where d&apos;2 &gt; d2, the closest constraint is d2 and
we would choose the smallest t2. In summary, we
will maximize t1 and t3 and minimize t2 and t4, so
we will narrow the margins.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="method">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.99999205">
We have used for our evaluation the dataset com-
piled within the TAC-KBP 2011 Temporal Slot Fill-
ing Task (Ji et al., 2011). We employed as initial
KB the one distributed to participants in the task,
which has been compiled from Wikipedia infoboxes.
It contains 898 triples entity, slot type, value) for
100 different entities and up to 8 different slots (re-
lations) per entity3. This gold standard contains the
correct responses pooled from the participant sys-
tems plus a set of responses manually found by
annotators. Each triple has associated a temporal
anchor. The relations had to be extracted from a
domain-general collection of 1.7 million documents.
Our system was one of the five that took part in
the task.We have evaluated the overall system and
the two main components of the architecture: Rela-
tion Extraction, and Temporal Anchoring of the re-
lations. Due to space limitations, the description of
our implementation is very concise; refer to (Garrido
et al., 2011) for further details.
</bodyText>
<subsectionHeader confidence="0.999239">
6.1 Evaluation of Relation Extraction
</subsectionHeader>
<bodyText confidence="0.999886666666667">
System response in the relation extraction step con-
sists in a set of triples entity, slot type, value).
Performance is measured using precision, recall and
F-measure (harmonic mean) with respect to the 898
triples in the key. Target relations (slots) are poten-
tially list-valued, that is, more than one value can
be valid for a relation (possibly at different points
in time). Only correct values yield any score, and
redundant triples are ignored.
Experiments. We run two different system settings
for the relation extraction step. They differ in the
document representation used (detailed in section3),
in order to empirically assess whether clustering of
discourse referents into single nodes benefits the ex-
traction. In SETTING 1, each document is repre-
sented as a document graph, GD, while in SETTING
2 collapsed document graph representation, GC, is
employed.
Results. Results are shown in Table 3 in the col-
umn Relation Extraction. Both settings have a sim-
ilar performance with a slight increase in the case
of graphs with clustered referents. Although preci-
sion is close to 0.5, recall is lower than 0.1. We have
studied the limits of the assumptions our approach
</bodyText>
<footnote confidence="0.97456175">
3There are 7 person relations: cities of residence, state-
orprovinces of residence, countries of residence, employee of,
member of, title, spouse, and an organization relation:
top members/employees.
</footnote>
<page confidence="0.99869">
111
</page>
<bodyText confidence="0.99998052">
is based on. First, our standard retrieval component
performance limits the overall system’s. As a matter
of example, if we retrieve the first 100 documents
per entity, we find relevant documents only for 62%
of the triples in the key. This number means that no
matter how good relation extraction method is, 38%
of relations will not be found.
Second, the distant supervision assumption un-
derlying our approach is that for a seed relation in-
stance (entity, relation, value), any textual men-
tion of entity and value expresses the relation. It
has been shown that this assumption is more often
violated when training knowledge base and docu-
ment collection are of different type, e.g. Wikipedia
and news-wire (Riedel et al., 2010). We have real-
ized that a more determinant factor is the relation
itself and the type of arguments it takes. We ran-
domly sampled 100 training examples per relation,
and manually inspected them to assess if they were
indeed mentions of the relation. While for the re-
lation cities of residence only 30% of the training
examples are expressing the relation, for spouse the
number goes up to 59%. For title, up to 90% of the
examples are correct. This fact explains, at least par-
tially, the zeros we obtain for some relations.
</bodyText>
<subsectionHeader confidence="0.999606">
6.2 Evaluation of Temporal Anchoring
</subsectionHeader>
<bodyText confidence="0.981204923076923">
Under the evaluation metrics proposed by TAC-KBP
2011, if the value of the relation instance is judged
as correct, the score for temporal anchoring depends
on how well the returned interval matches the one
provided in the key. More precisely, let the correct
imprecise anchor interval in the gold standard key
be Sk = (k1, k2, k3, k4) and the system response be
S = (r1, r2, r3, r4). The absence of a constraint in
t1 or t3 is treated as a value of −oo; the absence of
a constraint in t2 or t4 is treated as a value of +oo.
Then, let di = |ki − ri|, for i E 1, ... , 4, be the
difference, a real number measured in years. The
score for the system response is:
</bodyText>
<equation confidence="0.975994333333333">
4
Q(S) = 4E
i=1
</equation>
<bodyText confidence="0.99118718367347">
The score for a target relation Q(r) is computed
by summing Q(S) over all unique instances of the
relation whose value is correct. If the gold standard
contains N responses, and the system output M re-
sponses, then precision is: P = Q(r)/M, and recall:
R = Q(r)/N; F1 is the harmonic mean of P and R.
Experiments. We evaluated two different set-
tings for the temporal anchoring step; both use
the collapsed document graph representation, GC
(SETTING 2). The goal of the experiment is two-
fold. First, test the strength of the document creation
time as evidence for temporal anchoring. Second,
test how hard this metadata-level baseline is to beat
using contextual temporal expressions.
The SETTING 2-I assumes a within temporal link
between the document creation time and any relation
expressed inside the document, and aggregates this
information across the documents that we have iden-
tified as supporting the relation. The SETTING 2-II
considers documents content in order to extract tem-
poral links from the context of the text that expresses
the relation. If no temporal expression is found, the
date of the document is used as default. Temporal
links from all supporting documents are mapped into
intervals and aggregated as detailed in section 5.
The performance on relation extraction is an up-
per bound for temporal anchoring, attainable if tem-
poral anchoring is perfect. Thus, we also evaluate
the temporal anchoring performance as the percent-
age the final system achieves with respect to the re-
lation extraction upper bound.
Results. Results are shown in Table 3 under column
Temporal Anchoring. They are low, due to the upper
bound that error propagation in candidate retrieval
and relation extraction imposes upon this step: tem-
porally anchoring alone achives 69% of its upper
bound. This value corresponds to the baseline SET-
TING 2-I, showing its strength. The difference with
SETTING 2-II shows that this baseline is difficult
to beat by considering temporal evidence inside the
document content. There is a reason for this. The
temporal link mapping into time intervals does not
depend only on the type of link, but also on the se-
mantics of the text that expresses the relation as we
pointed out above. We have to decide how to trans-
form the link between relation and temporal expres-
sion into a temporal interval. Learning a model for
this is a hard open research problem that has a strong
adversary in the baseline proposed.
</bodyText>
<equation confidence="0.6657675">
1
1 + di
</equation>
<page confidence="0.929621">
112
</page>
<table confidence="0.999967166666667">
Relation Extraction Temporal Anchoring
SETTING 1 SETTING 2 SETTING 2-I SETTING 2-II
P R F P R F P R F % P R F %
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0
0.33 0.02 0.03 0 0 0 0 0 0 0 0 0 0 0
0.22 0.09 0.13 0.29 0.11 0.16 0.23 0.09 0.13 79 0.21 0.08 0.11 72
0.53 0.13 0.20 0.54 0.12 0.19 0.34 0.07 0.12 63 0.30 0.06 0.11 56
0.70 0.12 0.20 0.75 0.13 0.22 0.57 0.10 0.16 76 0.50 0.08 0.14 67
0.50 0.06 0.10 0.50 0.07 0.12 0.29 0.04 0.07 58 0.25 0.04 0.06 50
0.25 0.04 0.07 0.20 0.04 0.07 0.15 0.03 0.05 75 0.06 0.01 0.02 30
0.42 0.08 0.14 0.45 0.08 0.14 0.31 0.06 0.10 69 0.27 0.05 0.09 60
</table>
<tableCaption confidence="0.973830666666667">
Table 3: Results of experiments for each relation: (1) per:stateorprovinces of residence; (2) per:employee of; (3)
per:countries of residence; (4) per:member of; (5) per:title; (6) org:top members/employees; (7) per:spouse; (8)
per:cities of residence; (9) overall results (calculated as a micro-average).
</tableCaption>
<table confidence="0.999973727272727">
System # Filled Precision Recall F1
BLENDER2 1206 0.1789 0.3030 0.2250
BLENDER1 1116 0.1796 0.2942 0.2231
BLENDER3 1215 0.1744 0.2976 0.2199
IIRG1 346 0.2457 0.1194 0.1607
Setting 2-1 167 0.2996 0.0703 0.1139
Setting 2-2 167 0.2596 0.0609 0.0986
Stanford 12 5140 0.0233 0.1680 0.0409
Stanford 11 4353 0.0238 0.1453 0.0408
USFD20112 328 0.0152 0.0070 0.0096
USFD20113 127 0.0079 0.0014 0.0024
</table>
<tableCaption confidence="0.976614">
Table 4: System ID, number of filled responses of the
system, precision, recall and F measure.
</tableCaption>
<subsectionHeader confidence="0.998346">
6.3 Comparative Evaluation
</subsectionHeader>
<bodyText confidence="0.999985071428571">
Our approach was compared with the other four
participants at the KBP Temporal Slot Filling Task
2011. Table 4 shows results sorted by F-measure in
comparison to our two settings (described above).
These official results correspond to a previous
dataset containing 712 triples4.
As shown in column Filled our approach returns
less triples than other systems, explaining low recall.
However, our system achieves the highest precision
for the complete task of temporally anchored rela-
tion extraction. Despite low recall, our system ob-
tains the third best Fl value. This is a very promis-
ing result, since several directions can be explored
to consider more candidates and increase recall.
</bodyText>
<sectionHeader confidence="0.999848" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.99151375">
Compiling a Knowledge Base of temporally an-
chored facts is an open research challenge (Weikum
et al., 2011). Despite the vast amount of research fo-
cusing on understanding temporal expressions and
4Slot-fillers from human assessors were not considered
their relation to events in natural language, the com-
plete problem of temporally anchored relation ex-
traction remains relatively unexplored. Also, while
much research has focused on single-document ex-
traction, it seems clear that extracting temporally an-
chored relations needs the aggregation of evidences
across multiple documents.
There have been attempts to extend an existing
knowledge base. Wang et al. (2010) use regular
expressions to mine Wikipedia infoboxes and cat-
egories and it is not suited for unrestricted text. An
earlier attempt (Zhang et al., 2008), is specific for
business and difficult to generalize to other relations.
Two recent promising works are more related to our
research. Wang et al. (2011) uses manually defined
patterns to collect candidate facts and explicit dates,
and re-rank them using a graph label propagation al-
gorithm; their approach is complementary to ours,
as our aim is not to harvest temporal facts but to
extract the relations in which a query entity takes
part; unlike us, they require entity, value, and a ex-
plicit date to appear in the same sentence. Talukdar
et al. (2012) focus on the partial task of temporally
anchoring already known facts, showing the useful-
ness of the document creation time as temporal sig-
nal, aggregated across documents.
Earlier work has dealt mainly with partial aspects
of the problem. The TempEval community focused
on the classification of the temporal links between
pairs of events, or an event and a temporal expres-
sion; using shallow features (Mani et al., 2003; La-
pata and Lascarides, 2004; Chambers et al., 2007),
or syntactic-based structured features (Bethard and
Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007).
Aggregating evidence across different documents
</bodyText>
<page confidence="0.998237">
113
</page>
<bodyText confidence="0.999787740740741">
to temporally anchor facts has been explored in set-
tings different to Information Extraction, such as
answering of definition questions (Pas¸ca, 2008) or
extracting possible dates of well-known historical
events (Schockaert et al., 2010).
Temporal inference or reasoning to solve con-
flicting temporal expressions and induce temporal
order of events has been used in TempEval (Tatu
and Srikanth, 2008; Yoshikawa et al., 2009) and
ACE (Gupta and Ji, 2009) tasks, but focused on
single-document extraction. Ling et al. (2010), use
cross-event joint inference to extract temporal facts,
but only inside a single document.
Evaluation campaigns, such as ACE and TAC-
KBP 2011 have had an important role in promoting
this research. While ACE required only to identify
time expressions and classify their relation to events,
KBP requires to infer explicitly the start/end time of
relations, which is a realistic approach in the context
of building time-aware knowledge bases. KBP rep-
resents an important step for the evaluation of tem-
poral information extraction systems. In general, the
participant systems adapted existing slot filling sys-
tems, adding a temporal classification component:
distant supervised (Chen et al., 2010; Surdeanu et
al., 2010) on manually-defined patterns (Byrne and
Dunnion, 2010).
</bodyText>
<sectionHeader confidence="0.9991" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999984224137931">
This paper introduces the problem of extracting,
from unrestricted natural language text, relational
knowledge anchored to a temporal span, aggregat-
ing temporal evidence from a collection of docu-
ments. Although compiling time-aware knowledge
bases is an important open challenge (Weikum et
al., 2011), it has remained unexplored until very re-
cently (Wang et al., 2011; Talukdar et al., 2012).
We have elucidated the two challenges of the task,
namely relation extraction and temporal anchoring
of the extracted relations.
We have studied how, in a pipeline architecture,
the propagation of errors limits the overall system’s
performance. The performance attainable in the full
task is limited by the quality of the output of the
three main phases: retrieval of candidate passages/
documents, extraction of relations and temporal an-
choring of those.
We have also studied the limits of the distant su-
pervision approach to relation extraction, showing
empirically that its performance depends not only
on the nature of reference knowledge base and doc-
ument corpus (Riedel et al., 2010), but also on the
relation to be extracted. Given a relation between
two arguments, if it is not dominant among textual
expressions of those arguments, the distant supervi-
sion assumption will be more often violated.
We have introduced a novel graph-based docu-
ment level representation, that has allowed us to gen-
erate new features for the task of relation extraction,
capturing long distance structured contexts. Our re-
sults show how, in a document level syntactic repre-
sentation, it yields better results to collapse corefer-
ent nodes.
We have presented a methodological approach
to temporal anchoring composed of: (1) intra-
document temporal information representation; (2)
selection of relation-dependent relevant temporal in-
formation; (3) mapping of temporal links to an inter-
val representation; and (4) aggregation of imprecise
intervals.
Our proposal has been evaluated within a frame-
work that allows for comparability. It has been able
to extract temporally anchored relational informa-
tion with the highest precision among the partici-
pant systems taking part in the competitive evalu-
ation TAC-KBP 2011.
For the temporal anchoring sub-problem, we have
demonstrated the strength of the document creation
time as a temporal signal. It is possible to achieve
a performance of 69% of the upper-bound imposed
by relation extraction by assuming that any relation
mentioned in a document held at the document cre-
ation time (there is a within link between the rela-
tional fact and the document creation time). This
baseline has proved stronger than extracting and an-
alyzing the temporal expressions present in the doc-
ument content.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998399">
This work has been partially supported by the Span-
ish Ministry of Science and Innovation, through
the project Holopedia (TIN2010-21128-C02), and
the Regional Government of Madrid, through the
project MA2VICMR (S2009/TIC1542).
</bodyText>
<page confidence="0.998136">
114
</page>
<sectionHeader confidence="0.990089" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999768298076924">
Eneko Agirre, Angel X. Chang, Daniel S. Jurafsky,
Christopher D. Manning, Valentin I. Spitkovsky, and
Eric Yeh. 2009. Stanford-UBC at TAC-KBP. In TAC
2009, November.
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Commun. ACM, 26:832–843,
November.
Steven Bethard and James H. Martin. 2007. Cu-tmp:
temporal relation classification using syntactic and se-
mantic features. In Proceedings of the 4th Interna-
tional Workshop on Semantic Evaluations, SemEval
’07, pages 129–132, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Lorna Byrne and John Dunnion. 2010. UCD IIRG at
TAC 2010 KBP Slot Filling Task. In Proceedings of
the Third Text Analysis Conference (TAC 2010). NIST,
November.
Nathanael Chambers, Shan Wang, and Dan Jurafsky.
2007. Classifying temporal relations between events.
In Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 173–176, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Zheng Chen, Suzanne Tamang, Adam Lee, Xiang Li,
Wen-Pin Lin, Matthew Snover, Javier Artiles, Marissa
Passantino, and Heng Ji. 2010. CUNY-BLENDER
TAC-KBP2010: Entity linking and slot filling system
description. In Proceedings of the Third Text Analysis
Conference (TAC 2010). NIST, November.
Yuchang Cheng, Masayuki Asahara, and Yuji Mat-
sumoto. 2007. Naist.japan: temporal relation identifi-
cation using dependency parsed tree. In Proceedings
of the 4th International Workshop on Semantic Evalu-
ations, SemEval ’07, pages 245–248, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Guillermo Garrido, Bernardo Cabaleiro, Anselmo Peas,
varo Rodrigo, and Damiano Spina. 2011. A distant
supervised learning system for the TAC-KBP Slot Fill-
ing and Temporal Slot Filling Tasks. In Text Analysis
Conference, TAC 2011 Proceedings Papers.
Prashant Gupta and Heng Ji. 2009. Predicting un-
known time arguments based on cross-event propaga-
tion. In Proceedings of the ACL-IJCNLP 2009 Con-
ference Short Papers, ACLShort ’09, pages 369–372,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011.
Overview of the tac2011 knowledge base population
track. In Text Analysis Conference, TAC 2011 Work-
shop, Notebook Papers.
T. Joachims. 2002. Learning to Classify Text Us-
ing Support Vector Machines – Methods, Theory, and
Algorithms. Kluwer/Springer. We used Joachim’s
SVMLight implementation available at http://
svmlight.joachims.org/.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In ACL 2003, pages 423–430.
Mirella Lapata and Alex Lascarides. 2004. Inferring
sentence-internal temporal relations. In HLT 2004.
Xiao Ling and Daniel S. Weld. 2010. Temporal informa-
tion extraction. In Proceedings of the Twenty-Fourth
AAAI Conference on Artificial Intelligence (AAAI-10).
Inderjeet Mani, Barry Schiffman, and Jianping Zhang.
2003. Inferring temporal ordering of events in news.
In NAACL-Short’03.
Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extraction
without labeled data. In ACL 2009, pages 1003–1011,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
M Pas¸ca. 2008. Answering Definition Questions via
Temporally-Anchored Text Snippets. Proc. of IJC-
NLP2008.
Georgiana Pus¸cas¸u. 2007. Wvali: temporal relation
identification by syntactico-semantic analysis. In Pro-
ceedings of the 4th International Workshop on Se-
mantic Evaluations, SemEval ’07, pages 484–487,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
James Pustejovsky and Marc Verhagen. 2009. SemEval-
2010 task 13: evaluating events, time expressions,
and temporal relations (TempEval-2). In Proceed-
ings of the Workshop on Semantic Evaluations: Re-
cent Achievements and Future Directions, DEW ’09,
pages 112–116, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Jos´e Balc´azar, Francesco Bonchi,
Aristides Gionis, and Mich`ele Sebag, editors, Machine
Learning and Knowledge Discovery in Databases,
volume 6323 of LNCS, pages 148–163. Springer
Berlin / Heidelberg.
Stuart J. Russell and Peter Norvig. 2010. Artificial Intel-
ligence - A Modern Approach (3. internat. ed.). Pear-
son Education.
Steven Schockaert, Martine De Cock, and Etienne Kerre.
2010. Reasoning about fuzzy temporal information
from the web: towards retrieval of historical events.
Soft Computing - A Fusion of Foundations, Method-
ologies and Applications, 14:869–886.
Mihai Surdeanu and Massimiliano Ciaramita. 2007.
Robust information extraction with perceptrons. In
ACE07, March.
</reference>
<page confidence="0.988766">
115
</page>
<reference confidence="0.999819206896552">
Mihai Surdeanu, David McClosky, Julie Tibshirani, John
Bauer, Angel X. Chang, Valentin I. Spitkovsky, and
Christopher D. Manning. 2010. A simple distant
supervision approach for the tac-kbp slot filling task.
In Proceedings of the Third Text Analysis Conference
(TAC 2010), Gaithersburg, Maryland, USA, Novem-
ber. NIST.
Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell.
2012. Coupled temporal scoping of relational facts. In
Proceedings of the Fifth ACM International Confer-
ence on Web Search and Data Mining (WSDM), Seat-
tle, Washington, USA, February. Association for Com-
puting Machinery.
Marta Tatu and Munirathnam Srikanth. 2008. Experi-
ments with reasoning for temporal relations between
events. In COLING’08.
Marc Verhagen, Inderjeet Mani, Roser Sauri, Robert
Knippen, Seok Bae Jang, Jessica Littman, Anna
Rumshisky, John Phillips, and James Pustejovsky.
2005. Automating temporal annotation with TARSQI.
In ACLdemo’05.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. SemEval-2007 task 15: TempEval temporal re-
lation identification. In SemEval’07.
Yafang Wang, Mingjie Zhu, Lizhen Qu, Marc Spaniol,
and Gerhard Weikum. 2010. Timely YAGO: har-
vesting, querying, and visualizing temporal knowledge
from Wikipedia. In Proceedings of the 13th Inter-
national Conference on Extending Database Technol-
ogy, EDBT ’10, pages 697–700, New York, NY, USA.
ACM.
Yafang Wang, Bin Yang, Lizhen Qu, Marc Spaniol, and
Gerhard Weikum. 2011. Harvesting facts from textual
web sources by constrained label propagation. In Pro-
ceedings of the 20th ACM international conference on
Information and knowledge management, CIKM ’11,
pages 837–846, New York, NY, USA. ACM.
Gerhard Weikum, Srikanta Bedathur, and Ralf Schenkel.
2011. Temporal knowledge for timely intelligence.
In Malu Castellanos, Umeshwar Dayal, Volker Markl,
Wil Aalst, John Mylopoulos, Michael Rosemann,
Michael J. Shaw, and Clemens Szyperski, editors, En-
abling Real-Time Business Intelligence, volume 84
of Lecture Notes in Business Information Processing,
pages 1–6. Springer Berlin Heidelberg.
Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-
hara, and Yuji Matsumoto. 2009. Jointly identifying
temporal relations with Markov Logic. In Proceedings
of the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Volume
1 - Volume 1, ACL ’09, pages 405–413, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Qi Zhang, Fabian M. Suchanek, Lihua Yue, and Gerhard
Weikum. 2008. TOB: Timely ontologies for business
relations. In 11th International Workshop on the Web
and Databases, WebDB.
</reference>
<page confidence="0.999024">
116
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.451796">
<title confidence="0.99855">Temporally Anchored Relation Extraction</title>
<author confidence="0.980237">Anselmo Bernardo Cabaleiro Garrido</author>
<affiliation confidence="0.897184">NLP &amp; IR Group at</affiliation>
<address confidence="0.485198">Madrid,</address>
<abstract confidence="0.998558666666667">Although much work on relation extraction has aimed at obtaining static facts, many of target relations are actually as their validity is naturally anchored to a certain time period. This paper proposes a methodological approach to temporally anchored relation extraction. Our proposal performs distant supervised learning to extract a set of relations from a natural language corpus, and anchors each of them to an interval of temporal validity, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Angel X Chang</author>
<author>Daniel S Jurafsky</author>
<author>Christopher D Manning</author>
<author>Valentin I Spitkovsky</author>
<author>Eric Yeh</author>
</authors>
<title>Stanford-UBC at TAC-KBP. In TAC</title>
<date>2009</date>
<contexts>
<context position="8929" citStr="Agirre et al., 2009" startWordPosition="1411" endWordPosition="1414"> between any of the nodes clustered into u and any of the nodes vl, ... , vky. The coreference edges do not appear in this representation. Additional semantic information is also blended into this representation: normalization of genitives, semantic class indicators inferred from appositions and genitives, and gender annotation inferred from pronouns. A final graph example can be seen in Figure 2. 4 Distant Supervised Relation Extraction To perform relation extraction, our proposal follows a distant supervision approach (Mintz et al., 2009), which has also inspired other slot filling systems (Agirre et al., 2009; Surdeanu et al., 2010). We capture long distance relations by introducing a document-level representation and deriving novel features from deep syntactic and semantic analysis. Seed harvesting. From a reference Knowledge Base (KB), we extract a set of relation triples or seeds: (entity, relation, value), where the relation is one of the target relations. Our document-level distant supervision assumption is that if entity and value are found in a document graph (see section 3), and there is a path connecting them, then the document expresses the relation. Relation candidates gathering. From a</context>
</contexts>
<marker>Agirre, Chang, Jurafsky, Manning, Spitkovsky, Yeh, 2009</marker>
<rawString>Eneko Agirre, Angel X. Chang, Daniel S. Jurafsky, Christopher D. Manning, Valentin I. Spitkovsky, and Eric Yeh. 2009. Stanford-UBC at TAC-KBP. In TAC 2009, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Commun. ACM,</journal>
<pages>26--832</pages>
<marker>Allen, 1983</marker>
<rawString>James F. Allen. 1983. Maintaining knowledge about temporal intervals. Commun. ACM, 26:832–843, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
<author>James H Martin</author>
</authors>
<title>Cu-tmp: temporal relation classification using syntactic and semantic features.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07,</booktitle>
<pages>129--132</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29098" citStr="Bethard and Martin, 2007" startWordPosition="4783" endWordPosition="4786">y, value, and a explicit date to appear in the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents. Earlier work has dealt mainly with partial aspects of the problem. The TempEval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression; using shallow features (Mani et al., 2003; Lapata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al., 2009) and ACE (Gupta and Ji, 2009) tasks, but focused on single-document extraction. Ling</context>
</contexts>
<marker>Bethard, Martin, 2007</marker>
<rawString>Steven Bethard and James H. Martin. 2007. Cu-tmp: temporal relation classification using syntactic and semantic features. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07, pages 129–132, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorna Byrne</author>
<author>John Dunnion</author>
</authors>
<title>KBP Slot Filling Task.</title>
<date>2010</date>
<journal>UCD IIRG at TAC</journal>
<booktitle>In Proceedings of the Third Text Analysis Conference (TAC</booktitle>
<publisher>NIST,</publisher>
<contexts>
<context position="30487" citStr="Byrne and Dunnion, 2010" startWordPosition="4991" endWordPosition="4994">had an important role in promoting this research. While ACE required only to identify time expressions and classify their relation to events, KBP requires to infer explicitly the start/end time of relations, which is a realistic approach in the context of building time-aware knowledge bases. KBP represents an important step for the evaluation of temporal information extraction systems. In general, the participant systems adapted existing slot filling systems, adding a temporal classification component: distant supervised (Chen et al., 2010; Surdeanu et al., 2010) on manually-defined patterns (Byrne and Dunnion, 2010). 8 Conclusions This paper introduces the problem of extracting, from unrestricted natural language text, relational knowledge anchored to a temporal span, aggregating temporal evidence from a collection of documents. Although compiling time-aware knowledge bases is an important open challenge (Weikum et al., 2011), it has remained unexplored until very recently (Wang et al., 2011; Talukdar et al., 2012). We have elucidated the two challenges of the task, namely relation extraction and temporal anchoring of the extracted relations. We have studied how, in a pipeline architecture, the propagati</context>
</contexts>
<marker>Byrne, Dunnion, 2010</marker>
<rawString>Lorna Byrne and John Dunnion. 2010. UCD IIRG at TAC 2010 KBP Slot Filling Task. In Proceedings of the Third Text Analysis Conference (TAC 2010). NIST, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Shan Wang</author>
<author>Dan Jurafsky</author>
</authors>
<title>Classifying temporal relations between events.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>173--176</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29032" citStr="Chambers et al., 2007" startWordPosition="4775" endWordPosition="4778">n which a query entity takes part; unlike us, they require entity, value, and a explicit date to appear in the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents. Earlier work has dealt mainly with partial aspects of the problem. The TempEval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression; using shallow features (Mani et al., 2003; Lapata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al., 2009) and ACE (Gupta an</context>
</contexts>
<marker>Chambers, Wang, Jurafsky, 2007</marker>
<rawString>Nathanael Chambers, Shan Wang, and Dan Jurafsky. 2007. Classifying temporal relations between events. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 173–176, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Suzanne Tamang</author>
<author>Adam Lee</author>
<author>Xiang Li</author>
<author>Wen-Pin Lin</author>
<author>Matthew Snover</author>
<author>Javier Artiles</author>
<author>Marissa Passantino</author>
<author>Heng Ji</author>
</authors>
<title>CUNY-BLENDER TAC-KBP2010: Entity linking and slot filling system description.</title>
<date>2010</date>
<booktitle>In Proceedings of the Third Text Analysis Conference (TAC</booktitle>
<publisher>NIST,</publisher>
<contexts>
<context position="30408" citStr="Chen et al., 2010" startWordPosition="4980" endWordPosition="4983">single document. Evaluation campaigns, such as ACE and TACKBP 2011 have had an important role in promoting this research. While ACE required only to identify time expressions and classify their relation to events, KBP requires to infer explicitly the start/end time of relations, which is a realistic approach in the context of building time-aware knowledge bases. KBP represents an important step for the evaluation of temporal information extraction systems. In general, the participant systems adapted existing slot filling systems, adding a temporal classification component: distant supervised (Chen et al., 2010; Surdeanu et al., 2010) on manually-defined patterns (Byrne and Dunnion, 2010). 8 Conclusions This paper introduces the problem of extracting, from unrestricted natural language text, relational knowledge anchored to a temporal span, aggregating temporal evidence from a collection of documents. Although compiling time-aware knowledge bases is an important open challenge (Weikum et al., 2011), it has remained unexplored until very recently (Wang et al., 2011; Talukdar et al., 2012). We have elucidated the two challenges of the task, namely relation extraction and temporal anchoring of the extr</context>
</contexts>
<marker>Chen, Tamang, Lee, Li, Lin, Snover, Artiles, Passantino, Ji, 2010</marker>
<rawString>Zheng Chen, Suzanne Tamang, Adam Lee, Xiang Li, Wen-Pin Lin, Matthew Snover, Javier Artiles, Marissa Passantino, and Heng Ji. 2010. CUNY-BLENDER TAC-KBP2010: Entity linking and slot filling system description. In Proceedings of the Third Text Analysis Conference (TAC 2010). NIST, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuchang Cheng</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Naist.japan: temporal relation identification using dependency parsed tree.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07,</booktitle>
<pages>245--248</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29136" citStr="Cheng et al., 2007" startWordPosition="4789" endWordPosition="4792">the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents. Earlier work has dealt mainly with partial aspects of the problem. The TempEval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression; using shallow features (Mani et al., 2003; Lapata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al., 2009) and ACE (Gupta and Ji, 2009) tasks, but focused on single-document extraction. Ling et al. (2010), use cross-event joint </context>
</contexts>
<marker>Cheng, Asahara, Matsumoto, 2007</marker>
<rawString>Yuchang Cheng, Masayuki Asahara, and Yuji Matsumoto. 2007. Naist.japan: temporal relation identification using dependency parsed tree. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07, pages 245–248, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillermo Garrido</author>
<author>Bernardo Cabaleiro</author>
<author>Anselmo Peas</author>
<author>varo Rodrigo</author>
<author>Damiano Spina</author>
</authors>
<title>A distant supervised learning system for the TAC-KBP Slot Filling and Temporal Slot Filling Tasks.</title>
<date>2011</date>
<booktitle>In Text Analysis Conference, TAC 2011 Proceedings Papers.</booktitle>
<contexts>
<context position="19216" citStr="Garrido et al., 2011" startWordPosition="3106" endWordPosition="3109">relations) per entity3. This gold standard contains the correct responses pooled from the participant systems plus a set of responses manually found by annotators. Each triple has associated a temporal anchor. The relations had to be extracted from a domain-general collection of 1.7 million documents. Our system was one of the five that took part in the task.We have evaluated the overall system and the two main components of the architecture: Relation Extraction, and Temporal Anchoring of the relations. Due to space limitations, the description of our implementation is very concise; refer to (Garrido et al., 2011) for further details. 6.1 Evaluation of Relation Extraction System response in the relation extraction step consists in a set of triples entity, slot type, value). Performance is measured using precision, recall and F-measure (harmonic mean) with respect to the 898 triples in the key. Target relations (slots) are potentially list-valued, that is, more than one value can be valid for a relation (possibly at different points in time). Only correct values yield any score, and redundant triples are ignored. Experiments. We run two different system settings for the relation extraction step. They di</context>
</contexts>
<marker>Garrido, Cabaleiro, Peas, Rodrigo, Spina, 2011</marker>
<rawString>Guillermo Garrido, Bernardo Cabaleiro, Anselmo Peas, varo Rodrigo, and Damiano Spina. 2011. A distant supervised learning system for the TAC-KBP Slot Filling and Temporal Slot Filling Tasks. In Text Analysis Conference, TAC 2011 Proceedings Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prashant Gupta</author>
<author>Heng Ji</author>
</authors>
<title>Predicting unknown time arguments based on cross-event propagation.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09,</booktitle>
<pages>369--372</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29643" citStr="Gupta and Ji, 2009" startWordPosition="4864" endWordPosition="4867">., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al., 2009) and ACE (Gupta and Ji, 2009) tasks, but focused on single-document extraction. Ling et al. (2010), use cross-event joint inference to extract temporal facts, but only inside a single document. Evaluation campaigns, such as ACE and TACKBP 2011 have had an important role in promoting this research. While ACE required only to identify time expressions and classify their relation to events, KBP requires to infer explicitly the start/end time of relations, which is a realistic approach in the context of building time-aware knowledge bases. KBP represents an important step for the evaluation of temporal information extraction </context>
</contexts>
<marker>Gupta, Ji, 2009</marker>
<rawString>Prashant Gupta and Heng Ji. 2009. Predicting unknown time arguments based on cross-event propagation. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09, pages 369–372, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac2011 knowledge base population track.</title>
<date>2011</date>
<booktitle>In Text Analysis Conference, TAC 2011 Workshop, Notebook Papers.</booktitle>
<contexts>
<context position="5149" citStr="Ji et al., 2011" startWordPosition="787" endWordPosition="790">representation and reasoning, underlies much research, such as the Tempeval challenges (Verhagen et al., 2007; Pustejovsky and Verhagen, 2009). Our task is different, as we focus on obtaining the temporal interval associated to a fact, rather than reasoning about the temporal relations among the events appearing in a single text. Let us assume that each relation instance is valid during a certain temporal interval, I = [t0, tf]. This sharp temporal interval fails to capture the imprecision of temporal boundaries conveyed in natural language text. The Temporal Slot Filling task at TACKBP 2011 (Ji et al., 2011) proposed a 4-tuple representation that we will refer to as imprecise anchor intervals. An imprecise temporal interval is defined as an ordered 4-tuple of time points: (t1, t2, t3, t4), with the following semantics: the relation is true for a period which starts at some point between t1 and t2 and ends between t3 and t4. It should hold that: t1 &lt; t2, t3 &lt; t4, and t1 &lt; t4. Any of the four endpoints can be left unconstrained (t1 or t3 would be −oo, and t2 or t4 would be +oo). This representation is flexible and expressive, although it cannot capture certain types of information (Ji et al., 2011)</context>
<context position="18362" citStr="Ji et al., 2011" startWordPosition="2967" endWordPosition="2970"> and d&apos;, where d&apos; &gt; d, the closest constraint to the real start of the relation is d&apos;. Mapped to temporal constraints, it means that we would choose the biggest t1 possible. Following the same reasoning, we would want to maximize t3. On the other side, when a relation started before two dates d2 and d&apos;2, where d&apos;2 &gt; d2, the closest constraint is d2 and we would choose the smallest t2. In summary, we will maximize t1 and t3 and minimize t2 and t4, so we will narrow the margins. 6 Evaluation We have used for our evaluation the dataset compiled within the TAC-KBP 2011 Temporal Slot Filling Task (Ji et al., 2011). We employed as initial KB the one distributed to participants in the task, which has been compiled from Wikipedia infoboxes. It contains 898 triples entity, slot type, value) for 100 different entities and up to 8 different slots (relations) per entity3. This gold standard contains the correct responses pooled from the participant systems plus a set of responses manually found by annotators. Each triple has associated a temporal anchor. The relations had to be extracted from a domain-general collection of 1.7 million documents. Our system was one of the five that took part in the task.We hav</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011. Overview of the tac2011 knowledge base population track. In Text Analysis Conference, TAC 2011 Workshop, Notebook Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Learning to Classify Text Using Support Vector Machines – Methods, Theory, and Algorithms. Kluwer/Springer. We used Joachim’s SVMLight implementation available at http:// svmlight.joachims.org/.</title>
<date>2002</date>
<contexts>
<context position="13189" citStr="Joachims, 2002" startWordPosition="2096" endWordPosition="2097">included in the model. X stands for ENTITY and VALUE. Verb features are generated from the verbs, V , identified in the path between ENTITY and VALUE. we locate matching entities and start a local BFS of candidate values, generating for them an unlabelled example. For each of the relations to extract, a binary classifier (extractor) decides whether the example is a valid relation instance. For each particular relation classifier, only candidates with the expected entity and value types for the relation were used in the application phase. Each extractor was a SVM classifier with linear kernel (Joachims, 2002). All learning parameters were set to their default values. The classification process yields a predicted class label, plus a real number indicating the margin. We performed an aggregation phase to sum the margins over distinct occurrences of the same extracted value. The rationale is that when the same value is extracted from more than one document, we should accumulate that evidence. The output of this phase is the set of extracted relations (positive for each of the classifiers), plus the documents where the same fact was detected (supporting documents). 5 Temporal Anchoring of Relations In</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>T. Joachims. 2002. Learning to Classify Text Using Support Vector Machines – Methods, Theory, and Algorithms. Kluwer/Springer. We used Joachim’s SVMLight implementation available at http:// svmlight.joachims.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In ACL</booktitle>
<pages>423--430</pages>
<contexts>
<context position="7925" citStr="Klein and Manning, 2003" startWordPosition="1241" endWordPosition="1244">rieval Document Collection output: temporally anchored relations (6) Temporal Anchoring Date Extraction Date Aggregation 108 Figure 2: Collapsed document graph representation, GC, for the sample text document “David’s wife, Julia, is celebrating her birthday. She was born in September 1979”. the same discourse referent. • Semantic relations between two nodes, such as hasClass, hasProperty and hasAge. • Temporal relations between events and time expressions. The processing includes dependency parsing, named entity recognition and coreference resolution, done with the Stanford CoreNLP software (Klein and Manning, 2003); and events and temporal information extraction, via the TARSQI Toolkit (Verhagen et al., 2005). The document graph GD is then further transformed into a collapsed document graph, GC. Each node of GC clusters together coreferent nodes, representing a discourse referent. Thus, a node u in GC is a cluster of nodes ul, ... , uk of GD. There is an edge (u, v) in GC if there was an edge between any of the nodes clustered into u and any of the nodes vl, ... , vky. The coreference edges do not appear in this representation. Additional semantic information is also blended into this representation: no</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In ACL 2003, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Inferring sentence-internal temporal relations.</title>
<date>2004</date>
<booktitle>In HLT</booktitle>
<contexts>
<context position="29008" citStr="Lapata and Lascarides, 2004" startWordPosition="4770" endWordPosition="4774">ut to extract the relations in which a query entity takes part; unlike us, they require entity, value, and a explicit date to appear in the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents. Earlier work has dealt mainly with partial aspects of the problem. The TempEval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression; using shallow features (Mani et al., 2003; Lapata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al.,</context>
</contexts>
<marker>Lapata, Lascarides, 2004</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2004. Inferring sentence-internal temporal relations. In HLT 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Temporal information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence (AAAI-10).</booktitle>
<contexts>
<context position="1290" citStr="Ling and Weld, 2010" startWordPosition="193" endWordPosition="196">, aggregating evidence from documents supporting the relation. We use a rich graphbased document-level representation to generate novel features for this task. Results show that our implementation for temporal anchoring is able to achieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported. 1 Introduction A question that arises when extracting a relation is how to capture its temporal validity: Can we assign a period of time when the obtained relation held? As pointed out in (Ling and Weld, 2010), while much research in automatic relation extraction has focused on distilling static facts from text, many of the target relations are in fact fluents, dynamic relations whose truth value is dependent on time (Russell and Norvig, 2010). The Temporally anchored relation extraction problem consists in, given a natural language text document corpus, C, a target entity, e, and a target relation, r, extracting from the corpus the value of that relation for the entity, and a temporal interval for which the relation was valid. In this paper, we introduce a methodological approach to temporal ancho</context>
<context position="2756" citStr="Ling and Weld, 2010" startWordPosition="424" endWordPosition="427">intuition is that a distant supervised system can effectively extract relations from the source text collection, and a straightforward date aggregation can then be applied to anchor them. We propose a four step process for temporal anchoring: (1) represent temporal evidence; (2) select temporal information relevant to the relation; (3) decide how a relational fact and its relevant temporal information are themselves related; and (4) aggregate imprecise temporal intervals across multiple documents. In contrast with previous approaches that aim at intra-document temporal information extraction (Ling and Weld, 2010), we focus on mining a corpus aggregating temporal evidences across the supporting documents. We address the following research questions: (1) Validate whether distant supervised learning is suitable for the task, and evaluate its shortcomings. (2) Explore whether the use of features extracted from a document-level rich representation could improve distant supervised learning. (3) Compare the use of document metadata against temporal expressions within the document for relation temporal anchoring. (4) Analyze how, in a pipeline architecture, the propagation of errors limits the overall system’</context>
</contexts>
<marker>Ling, Weld, 2010</marker>
<rawString>Xiao Ling and Daniel S. Weld. 2010. Temporal information extraction. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence (AAAI-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Barry Schiffman</author>
<author>Jianping Zhang</author>
</authors>
<title>Inferring temporal ordering of events in news.</title>
<date>2003</date>
<booktitle>In NAACL-Short’03.</booktitle>
<contexts>
<context position="28979" citStr="Mani et al., 2003" startWordPosition="4766" endWordPosition="4769">st temporal facts but to extract the relations in which a query entity takes part; unlike us, they require entity, value, and a explicit date to appear in the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents. Earlier work has dealt mainly with partial aspects of the problem. The TempEval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression; using shallow features (Mani et al., 2003; Lapata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srik</context>
</contexts>
<marker>Mani, Schiffman, Zhang, 2003</marker>
<rawString>Inderjeet Mani, Barry Schiffman, and Jianping Zhang. 2003. Inferring temporal ordering of events in news. In NAACL-Short’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data. In ACL</title>
<date>2009</date>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2064" citStr="Mintz et al., 2009" startWordPosition="316" endWordPosition="319">dynamic relations whose truth value is dependent on time (Russell and Norvig, 2010). The Temporally anchored relation extraction problem consists in, given a natural language text document corpus, C, a target entity, e, and a target relation, r, extracting from the corpus the value of that relation for the entity, and a temporal interval for which the relation was valid. In this paper, we introduce a methodological approach to temporal anchoring of relations automatically extracted from unrestricted text. Our system (see Figure 1) extracts relational facts from text using distant supervision (Mintz et al., 2009) and then anchors the relation to an interval of temporal validity. The intuition is that a distant supervised system can effectively extract relations from the source text collection, and a straightforward date aggregation can then be applied to anchor them. We propose a four step process for temporal anchoring: (1) represent temporal evidence; (2) select temporal information relevant to the relation; (3) decide how a relational fact and its relevant temporal information are themselves related; and (4) aggregate imprecise temporal intervals across multiple documents. In contrast with previous</context>
<context position="8856" citStr="Mintz et al., 2009" startWordPosition="1398" endWordPosition="1401">es ul, ... , uk of GD. There is an edge (u, v) in GC if there was an edge between any of the nodes clustered into u and any of the nodes vl, ... , vky. The coreference edges do not appear in this representation. Additional semantic information is also blended into this representation: normalization of genitives, semantic class indicators inferred from appositions and genitives, and gender annotation inferred from pronouns. A final graph example can be seen in Figure 2. 4 Distant Supervised Relation Extraction To perform relation extraction, our proposal follows a distant supervision approach (Mintz et al., 2009), which has also inspired other slot filling systems (Agirre et al., 2009; Surdeanu et al., 2010). We capture long distance relations by introducing a document-level representation and deriving novel features from deep syntactic and semantic analysis. Seed harvesting. From a reference Knowledge Base (KB), we extract a set of relation triples or seeds: (entity, relation, value), where the relation is one of the target relations. Our document-level distant supervision assumption is that if entity and value are found in a document graph (see section 3), and there is a path connecting them, then t</context>
<context position="10590" citStr="Mintz et al., 2009" startWordPosition="1684" endWordPosition="1687">em. We enforce the Named Entity type of entity and value to match a expected type, predefined for the relation. Our procedure traverses the document graph looking for entity and value nodes meeting those conditions; when found, we generate features for a positive example for the relation2. If we encounter a node that matches the expected NE type of the relation, but does not match the seed value, we generate a negative example for that relation. Training. From positive and negative examples, we generate binary features; some of them are inspired by previous work (Surdeanu and Ciaramita, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2010), and others are novel, taking advantage of our graph representation. Table 1 summarizes our choice of features. Features appearing in less than 5 training examples were discarded. Relation instance extraction. Given an input entity and a target relation, we aim at finding a filler value for a relation instance. This task is known as Slot Filling. From the set of retrieved documents relevant to the query entity, represented as document graphs, 2From the collapsed document graph representation we obtained an average of 9213 positive training examples</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In ACL 2009, pages 1003–1011, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
</authors>
<title>Answering Definition Questions via Temporally-Anchored Text Snippets.</title>
<date>2008</date>
<booktitle>Proc. of IJCNLP2008.</booktitle>
<marker>Pas¸ca, 2008</marker>
<rawString>M Pas¸ca. 2008. Answering Definition Questions via Temporally-Anchored Text Snippets. Proc. of IJCNLP2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Pus¸cas¸u</author>
</authors>
<title>Wvali: temporal relation identification by syntactico-semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07,</booktitle>
<pages>484--487</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Pus¸cas¸u, 2007</marker>
<rawString>Georgiana Pus¸cas¸u. 2007. Wvali: temporal relation identification by syntactico-semantic analysis. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07, pages 484–487, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Marc Verhagen</author>
</authors>
<title>SemEval2010 task 13: evaluating events, time expressions, and temporal relations (TempEval-2).</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions, DEW ’09,</booktitle>
<pages>112--116</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4675" citStr="Pustejovsky and Verhagen, 2009" startWordPosition="704" endWordPosition="708">evaluation of our approach is introduced in section 6; while some related work is shown in section 7 and conclusions in section 8. 2 Temporal Anchors We will denominate relation instance a triple (entity, relation name, value). We aim at anchoring relation instances to their temporal validity. We need a representation flexible enough to capture the imprecise temporal information available in text, but expressed in a structured style. Allen’s (1983) interval-based algebra for temporal representation and reasoning, underlies much research, such as the Tempeval challenges (Verhagen et al., 2007; Pustejovsky and Verhagen, 2009). Our task is different, as we focus on obtaining the temporal interval associated to a fact, rather than reasoning about the temporal relations among the events appearing in a single text. Let us assume that each relation instance is valid during a certain temporal interval, I = [t0, tf]. This sharp temporal interval fails to capture the imprecision of temporal boundaries conveyed in natural language text. The Temporal Slot Filling task at TACKBP 2011 (Ji et al., 2011) proposed a 4-tuple representation that we will refer to as imprecise anchor intervals. An imprecise temporal interval is defi</context>
</contexts>
<marker>Pustejovsky, Verhagen, 2009</marker>
<rawString>James Pustejovsky and Marc Verhagen. 2009. SemEval2010 task 13: evaluating events, time expressions, and temporal relations (TempEval-2). In Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions, DEW ’09, pages 112–116, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>Machine Learning and Knowledge Discovery in Databases,</booktitle>
<volume>6323</volume>
<pages>148--163</pages>
<editor>In Jos´e Balc´azar, Francesco Bonchi, Aristides Gionis, and Mich`ele Sebag, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="10611" citStr="Riedel et al., 2010" startWordPosition="1688" endWordPosition="1691">amed Entity type of entity and value to match a expected type, predefined for the relation. Our procedure traverses the document graph looking for entity and value nodes meeting those conditions; when found, we generate features for a positive example for the relation2. If we encounter a node that matches the expected NE type of the relation, but does not match the seed value, we generate a negative example for that relation. Training. From positive and negative examples, we generate binary features; some of them are inspired by previous work (Surdeanu and Ciaramita, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2010), and others are novel, taking advantage of our graph representation. Table 1 summarizes our choice of features. Features appearing in less than 5 training examples were discarded. Relation instance extraction. Given an input entity and a target relation, we aim at finding a filler value for a relation instance. This task is known as Slot Filling. From the set of retrieved documents relevant to the query entity, represented as document graphs, 2From the collapsed document graph representation we obtained an average of 9213 positive training examples per slot; from the u</context>
<context position="21379" citStr="Riedel et al., 2010" startWordPosition="3453" endWordPosition="3456"> example, if we retrieve the first 100 documents per entity, we find relevant documents only for 62% of the triples in the key. This number means that no matter how good relation extraction method is, 38% of relations will not be found. Second, the distant supervision assumption underlying our approach is that for a seed relation instance (entity, relation, value), any textual mention of entity and value expresses the relation. It has been shown that this assumption is more often violated when training knowledge base and document collection are of different type, e.g. Wikipedia and news-wire (Riedel et al., 2010). We have realized that a more determinant factor is the relation itself and the type of arguments it takes. We randomly sampled 100 training examples per relation, and manually inspected them to assess if they were indeed mentions of the relation. While for the relation cities of residence only 30% of the training examples are expressing the relation, for spouse the number goes up to 59%. For title, up to 90% of the examples are correct. This fact explains, at least partially, the zeros we obtain for some relations. 6.2 Evaluation of Temporal Anchoring Under the evaluation metrics proposed by</context>
<context position="31585" citStr="Riedel et al., 2010" startWordPosition="5160" endWordPosition="5163">traction and temporal anchoring of the extracted relations. We have studied how, in a pipeline architecture, the propagation of errors limits the overall system’s performance. The performance attainable in the full task is limited by the quality of the output of the three main phases: retrieval of candidate passages/ documents, extraction of relations and temporal anchoring of those. We have also studied the limits of the distant supervision approach to relation extraction, showing empirically that its performance depends not only on the nature of reference knowledge base and document corpus (Riedel et al., 2010), but also on the relation to be extracted. Given a relation between two arguments, if it is not dominant among textual expressions of those arguments, the distant supervision assumption will be more often violated. We have introduced a novel graph-based document level representation, that has allowed us to generate new features for the task of relation extraction, capturing long distance structured contexts. Our results show how, in a document level syntactic representation, it yields better results to collapse coreferent nodes. We have presented a methodological approach to temporal anchorin</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Jos´e Balc´azar, Francesco Bonchi, Aristides Gionis, and Mich`ele Sebag, editors, Machine Learning and Knowledge Discovery in Databases, volume 6323 of LNCS, pages 148–163. Springer Berlin / Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart J Russell</author>
<author>Peter Norvig</author>
</authors>
<date>2010</date>
<journal>Artificial Intelligence - A Modern Approach</journal>
<volume>3</volume>
<editor>internat. ed.).</editor>
<publisher>Pearson Education.</publisher>
<contexts>
<context position="1528" citStr="Russell and Norvig, 2010" startWordPosition="231" endWordPosition="234">hieve a 69% of the upper bound performance imposed by the relation extraction step. Compared to the state of the art, the overall system achieves the highest precision reported. 1 Introduction A question that arises when extracting a relation is how to capture its temporal validity: Can we assign a period of time when the obtained relation held? As pointed out in (Ling and Weld, 2010), while much research in automatic relation extraction has focused on distilling static facts from text, many of the target relations are in fact fluents, dynamic relations whose truth value is dependent on time (Russell and Norvig, 2010). The Temporally anchored relation extraction problem consists in, given a natural language text document corpus, C, a target entity, e, and a target relation, r, extracting from the corpus the value of that relation for the entity, and a temporal interval for which the relation was valid. In this paper, we introduce a methodological approach to temporal anchoring of relations automatically extracted from unrestricted text. Our system (see Figure 1) extracts relational facts from text using distant supervision (Mintz et al., 2009) and then anchors the relation to an interval of temporal validi</context>
</contexts>
<marker>Russell, Norvig, 2010</marker>
<rawString>Stuart J. Russell and Peter Norvig. 2010. Artificial Intelligence - A Modern Approach (3. internat. ed.). Pearson Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Schockaert</author>
<author>Martine De Cock</author>
<author>Etienne Kerre</author>
</authors>
<title>Reasoning about fuzzy temporal information from the web: towards retrieval of historical events. Soft Computing - A Fusion of Foundations, Methodologies and Applications,</title>
<date>2010</date>
<pages>14--869</pages>
<marker>Schockaert, De Cock, Kerre, 2010</marker>
<rawString>Steven Schockaert, Martine De Cock, and Etienne Kerre. 2010. Reasoning about fuzzy temporal information from the web: towards retrieval of historical events. Soft Computing - A Fusion of Foundations, Methodologies and Applications, 14:869–886.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Massimiliano Ciaramita</author>
</authors>
<title>Robust information extraction with perceptrons.</title>
<date>2007</date>
<booktitle>In ACE07,</booktitle>
<contexts>
<context position="10570" citStr="Surdeanu and Ciaramita, 2007" startWordPosition="1680" endWordPosition="1683">est connecting path between them. We enforce the Named Entity type of entity and value to match a expected type, predefined for the relation. Our procedure traverses the document graph looking for entity and value nodes meeting those conditions; when found, we generate features for a positive example for the relation2. If we encounter a node that matches the expected NE type of the relation, but does not match the seed value, we generate a negative example for that relation. Training. From positive and negative examples, we generate binary features; some of them are inspired by previous work (Surdeanu and Ciaramita, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2010), and others are novel, taking advantage of our graph representation. Table 1 summarizes our choice of features. Features appearing in less than 5 training examples were discarded. Relation instance extraction. Given an input entity and a target relation, we aim at finding a filler value for a relation instance. This task is known as Slot Filling. From the set of retrieved documents relevant to the query entity, represented as document graphs, 2From the collapsed document graph representation we obtained an average of 9213 positi</context>
</contexts>
<marker>Surdeanu, Ciaramita, 2007</marker>
<rawString>Mihai Surdeanu and Massimiliano Ciaramita. 2007. Robust information extraction with perceptrons. In ACE07, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>David McClosky</author>
<author>Julie Tibshirani</author>
<author>John Bauer</author>
<author>Angel X Chang</author>
<author>Valentin I Spitkovsky</author>
<author>Christopher D Manning</author>
</authors>
<title>A simple distant supervision approach for the tac-kbp slot filling task.</title>
<date>2010</date>
<booktitle>In Proceedings of the Third Text Analysis Conference (TAC 2010),</booktitle>
<publisher>NIST.</publisher>
<location>Gaithersburg, Maryland, USA,</location>
<contexts>
<context position="8953" citStr="Surdeanu et al., 2010" startWordPosition="1415" endWordPosition="1418">odes clustered into u and any of the nodes vl, ... , vky. The coreference edges do not appear in this representation. Additional semantic information is also blended into this representation: normalization of genitives, semantic class indicators inferred from appositions and genitives, and gender annotation inferred from pronouns. A final graph example can be seen in Figure 2. 4 Distant Supervised Relation Extraction To perform relation extraction, our proposal follows a distant supervision approach (Mintz et al., 2009), which has also inspired other slot filling systems (Agirre et al., 2009; Surdeanu et al., 2010). We capture long distance relations by introducing a document-level representation and deriving novel features from deep syntactic and semantic analysis. Seed harvesting. From a reference Knowledge Base (KB), we extract a set of relation triples or seeds: (entity, relation, value), where the relation is one of the target relations. Our document-level distant supervision assumption is that if entity and value are found in a document graph (see section 3), and there is a path connecting them, then the document expresses the relation. Relation candidates gathering. From a seed triple, we retriev</context>
<context position="10635" citStr="Surdeanu et al., 2010" startWordPosition="1692" endWordPosition="1695">ntity and value to match a expected type, predefined for the relation. Our procedure traverses the document graph looking for entity and value nodes meeting those conditions; when found, we generate features for a positive example for the relation2. If we encounter a node that matches the expected NE type of the relation, but does not match the seed value, we generate a negative example for that relation. Training. From positive and negative examples, we generate binary features; some of them are inspired by previous work (Surdeanu and Ciaramita, 2007; Mintz et al., 2009; Riedel et al., 2010; Surdeanu et al., 2010), and others are novel, taking advantage of our graph representation. Table 1 summarizes our choice of features. Features appearing in less than 5 training examples were discarded. Relation instance extraction. Given an input entity and a target relation, we aim at finding a filler value for a relation instance. This task is known as Slot Filling. From the set of retrieved documents relevant to the query entity, represented as document graphs, 2From the collapsed document graph representation we obtained an average of 9213 positive training examples per slot; from the uncollapsed document grap</context>
<context position="30432" citStr="Surdeanu et al., 2010" startWordPosition="4984" endWordPosition="4987">aluation campaigns, such as ACE and TACKBP 2011 have had an important role in promoting this research. While ACE required only to identify time expressions and classify their relation to events, KBP requires to infer explicitly the start/end time of relations, which is a realistic approach in the context of building time-aware knowledge bases. KBP represents an important step for the evaluation of temporal information extraction systems. In general, the participant systems adapted existing slot filling systems, adding a temporal classification component: distant supervised (Chen et al., 2010; Surdeanu et al., 2010) on manually-defined patterns (Byrne and Dunnion, 2010). 8 Conclusions This paper introduces the problem of extracting, from unrestricted natural language text, relational knowledge anchored to a temporal span, aggregating temporal evidence from a collection of documents. Although compiling time-aware knowledge bases is an important open challenge (Weikum et al., 2011), it has remained unexplored until very recently (Wang et al., 2011; Talukdar et al., 2012). We have elucidated the two challenges of the task, namely relation extraction and temporal anchoring of the extracted relations. We have</context>
</contexts>
<marker>Surdeanu, McClosky, Tibshirani, Bauer, Chang, Spitkovsky, Manning, 2010</marker>
<rawString>Mihai Surdeanu, David McClosky, Julie Tibshirani, John Bauer, Angel X. Chang, Valentin I. Spitkovsky, and Christopher D. Manning. 2010. A simple distant supervision approach for the tac-kbp slot filling task. In Proceedings of the Third Text Analysis Conference (TAC 2010), Gaithersburg, Maryland, USA, November. NIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Derry Wijaya</author>
<author>Tom Mitchell</author>
</authors>
<title>Coupled temporal scoping of relational facts.</title>
<date>2012</date>
<booktitle>In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining (WSDM),</booktitle>
<publisher>Association for Computing Machinery.</publisher>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="28558" citStr="Talukdar et al. (2012)" startWordPosition="4698" endWordPosition="4701">ted for unrestricted text. An earlier attempt (Zhang et al., 2008), is specific for business and difficult to generalize to other relations. Two recent promising works are more related to our research. Wang et al. (2011) uses manually defined patterns to collect candidate facts and explicit dates, and re-rank them using a graph label propagation algorithm; their approach is complementary to ours, as our aim is not to harvest temporal facts but to extract the relations in which a query entity takes part; unlike us, they require entity, value, and a explicit date to appear in the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents. Earlier work has dealt mainly with partial aspects of the problem. The TempEval community focused on the classification of the temporal links between pairs of events, or an event and a temporal expression; using shallow features (Mani et al., 2003; Lapata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence</context>
<context position="30894" citStr="Talukdar et al., 2012" startWordPosition="5052" endWordPosition="5055">icipant systems adapted existing slot filling systems, adding a temporal classification component: distant supervised (Chen et al., 2010; Surdeanu et al., 2010) on manually-defined patterns (Byrne and Dunnion, 2010). 8 Conclusions This paper introduces the problem of extracting, from unrestricted natural language text, relational knowledge anchored to a temporal span, aggregating temporal evidence from a collection of documents. Although compiling time-aware knowledge bases is an important open challenge (Weikum et al., 2011), it has remained unexplored until very recently (Wang et al., 2011; Talukdar et al., 2012). We have elucidated the two challenges of the task, namely relation extraction and temporal anchoring of the extracted relations. We have studied how, in a pipeline architecture, the propagation of errors limits the overall system’s performance. The performance attainable in the full task is limited by the quality of the output of the three main phases: retrieval of candidate passages/ documents, extraction of relations and temporal anchoring of those. We have also studied the limits of the distant supervision approach to relation extraction, showing empirically that its performance depends n</context>
</contexts>
<marker>Talukdar, Wijaya, Mitchell, 2012</marker>
<rawString>Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell. 2012. Coupled temporal scoping of relational facts. In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining (WSDM), Seattle, Washington, USA, February. Association for Computing Machinery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Tatu</author>
<author>Munirathnam Srikanth</author>
</authors>
<title>Experiments with reasoning for temporal relations between events.</title>
<date>2008</date>
<booktitle>In COLING’08.</booktitle>
<contexts>
<context position="29589" citStr="Tatu and Srikanth, 2008" startWordPosition="4854" endWordPosition="4857"> et al., 2003; Lapata and Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al., 2009) and ACE (Gupta and Ji, 2009) tasks, but focused on single-document extraction. Ling et al. (2010), use cross-event joint inference to extract temporal facts, but only inside a single document. Evaluation campaigns, such as ACE and TACKBP 2011 have had an important role in promoting this research. While ACE required only to identify time expressions and classify their relation to events, KBP requires to infer explicitly the start/end time of relations, which is a realistic approach in the context of building time-aware knowledge bases. KBP represents an important step </context>
</contexts>
<marker>Tatu, Srikanth, 2008</marker>
<rawString>Marta Tatu and Munirathnam Srikanth. 2008. Experiments with reasoning for temporal relations between events. In COLING’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Inderjeet Mani</author>
<author>Roser Sauri</author>
<author>Robert Knippen</author>
</authors>
<title>Automating temporal annotation with TARSQI.</title>
<date>2005</date>
<booktitle>In ACLdemo’05.</booktitle>
<location>Seok Bae Jang, Jessica Littman, Anna Rumshisky, John Phillips, and</location>
<contexts>
<context position="8021" citStr="Verhagen et al., 2005" startWordPosition="1255" endWordPosition="1258">ction Date Aggregation 108 Figure 2: Collapsed document graph representation, GC, for the sample text document “David’s wife, Julia, is celebrating her birthday. She was born in September 1979”. the same discourse referent. • Semantic relations between two nodes, such as hasClass, hasProperty and hasAge. • Temporal relations between events and time expressions. The processing includes dependency parsing, named entity recognition and coreference resolution, done with the Stanford CoreNLP software (Klein and Manning, 2003); and events and temporal information extraction, via the TARSQI Toolkit (Verhagen et al., 2005). The document graph GD is then further transformed into a collapsed document graph, GC. Each node of GC clusters together coreferent nodes, representing a discourse referent. Thus, a node u in GC is a cluster of nodes ul, ... , uk of GD. There is an edge (u, v) in GC if there was an edge between any of the nodes clustered into u and any of the nodes vl, ... , vky. The coreference edges do not appear in this representation. Additional semantic information is also blended into this representation: normalization of genitives, semantic class indicators inferred from appositions and genitives, and</context>
</contexts>
<marker>Verhagen, Mani, Sauri, Knippen, 2005</marker>
<rawString>Marc Verhagen, Inderjeet Mani, Roser Sauri, Robert Knippen, Seok Bae Jang, Jessica Littman, Anna Rumshisky, John Phillips, and James Pustejovsky. 2005. Automating temporal annotation with TARSQI. In ACLdemo’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2007 task 15: TempEval temporal relation identification.</title>
<date>2007</date>
<booktitle>In SemEval’07.</booktitle>
<contexts>
<context position="4642" citStr="Verhagen et al., 2007" startWordPosition="700" endWordPosition="703"> Empirical comparative evaluation of our approach is introduced in section 6; while some related work is shown in section 7 and conclusions in section 8. 2 Temporal Anchors We will denominate relation instance a triple (entity, relation name, value). We aim at anchoring relation instances to their temporal validity. We need a representation flexible enough to capture the imprecise temporal information available in text, but expressed in a structured style. Allen’s (1983) interval-based algebra for temporal representation and reasoning, underlies much research, such as the Tempeval challenges (Verhagen et al., 2007; Pustejovsky and Verhagen, 2009). Our task is different, as we focus on obtaining the temporal interval associated to a fact, rather than reasoning about the temporal relations among the events appearing in a single text. Let us assume that each relation instance is valid during a certain temporal interval, I = [t0, tf]. This sharp temporal interval fails to capture the imprecision of temporal boundaries conveyed in natural language text. The Temporal Slot Filling task at TACKBP 2011 (Ji et al., 2011) proposed a 4-tuple representation that we will refer to as imprecise anchor intervals. An im</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. SemEval-2007 task 15: TempEval temporal relation identification. In SemEval’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yafang Wang</author>
<author>Mingjie Zhu</author>
<author>Lizhen Qu</author>
<author>Marc Spaniol</author>
<author>Gerhard Weikum</author>
</authors>
<title>Timely YAGO: harvesting, querying, and visualizing temporal knowledge from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the 13th International Conference on Extending Database Technology, EDBT ’10,</booktitle>
<pages>697--700</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="27851" citStr="Wang et al. (2010)" startWordPosition="4579" endWordPosition="4582">ed facts is an open research challenge (Weikum et al., 2011). Despite the vast amount of research focusing on understanding temporal expressions and 4Slot-fillers from human assessors were not considered their relation to events in natural language, the complete problem of temporally anchored relation extraction remains relatively unexplored. Also, while much research has focused on single-document extraction, it seems clear that extracting temporally anchored relations needs the aggregation of evidences across multiple documents. There have been attempts to extend an existing knowledge base. Wang et al. (2010) use regular expressions to mine Wikipedia infoboxes and categories and it is not suited for unrestricted text. An earlier attempt (Zhang et al., 2008), is specific for business and difficult to generalize to other relations. Two recent promising works are more related to our research. Wang et al. (2011) uses manually defined patterns to collect candidate facts and explicit dates, and re-rank them using a graph label propagation algorithm; their approach is complementary to ours, as our aim is not to harvest temporal facts but to extract the relations in which a query entity takes part; unlike</context>
</contexts>
<marker>Wang, Zhu, Qu, Spaniol, Weikum, 2010</marker>
<rawString>Yafang Wang, Mingjie Zhu, Lizhen Qu, Marc Spaniol, and Gerhard Weikum. 2010. Timely YAGO: harvesting, querying, and visualizing temporal knowledge from Wikipedia. In Proceedings of the 13th International Conference on Extending Database Technology, EDBT ’10, pages 697–700, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yafang Wang</author>
<author>Bin Yang</author>
<author>Lizhen Qu</author>
<author>Marc Spaniol</author>
<author>Gerhard Weikum</author>
</authors>
<title>Harvesting facts from textual web sources by constrained label propagation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11,</booktitle>
<pages>837--846</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="28156" citStr="Wang et al. (2011)" startWordPosition="4629" endWordPosition="4632">traction remains relatively unexplored. Also, while much research has focused on single-document extraction, it seems clear that extracting temporally anchored relations needs the aggregation of evidences across multiple documents. There have been attempts to extend an existing knowledge base. Wang et al. (2010) use regular expressions to mine Wikipedia infoboxes and categories and it is not suited for unrestricted text. An earlier attempt (Zhang et al., 2008), is specific for business and difficult to generalize to other relations. Two recent promising works are more related to our research. Wang et al. (2011) uses manually defined patterns to collect candidate facts and explicit dates, and re-rank them using a graph label propagation algorithm; their approach is complementary to ours, as our aim is not to harvest temporal facts but to extract the relations in which a query entity takes part; unlike us, they require entity, value, and a explicit date to appear in the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anchoring already known facts, showing the usefulness of the document creation time as temporal signal, aggregated across documents. Earlier work has dealt m</context>
<context position="30870" citStr="Wang et al., 2011" startWordPosition="5048" endWordPosition="5051">n general, the participant systems adapted existing slot filling systems, adding a temporal classification component: distant supervised (Chen et al., 2010; Surdeanu et al., 2010) on manually-defined patterns (Byrne and Dunnion, 2010). 8 Conclusions This paper introduces the problem of extracting, from unrestricted natural language text, relational knowledge anchored to a temporal span, aggregating temporal evidence from a collection of documents. Although compiling time-aware knowledge bases is an important open challenge (Weikum et al., 2011), it has remained unexplored until very recently (Wang et al., 2011; Talukdar et al., 2012). We have elucidated the two challenges of the task, namely relation extraction and temporal anchoring of the extracted relations. We have studied how, in a pipeline architecture, the propagation of errors limits the overall system’s performance. The performance attainable in the full task is limited by the quality of the output of the three main phases: retrieval of candidate passages/ documents, extraction of relations and temporal anchoring of those. We have also studied the limits of the distant supervision approach to relation extraction, showing empirically that i</context>
</contexts>
<marker>Wang, Yang, Qu, Spaniol, Weikum, 2011</marker>
<rawString>Yafang Wang, Bin Yang, Lizhen Qu, Marc Spaniol, and Gerhard Weikum. 2011. Harvesting facts from textual web sources by constrained label propagation. In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11, pages 837–846, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Weikum</author>
<author>Srikanta Bedathur</author>
<author>Ralf Schenkel</author>
</authors>
<title>Temporal knowledge for timely intelligence.</title>
<date>2011</date>
<booktitle>Enabling Real-Time Business Intelligence,</booktitle>
<volume>84</volume>
<pages>1--6</pages>
<editor>In Malu Castellanos, Umeshwar Dayal, Volker Markl,</editor>
<publisher>Springer</publisher>
<location>Wil Aalst, John</location>
<contexts>
<context position="27293" citStr="Weikum et al., 2011" startWordPosition="4498" endWordPosition="4501">d above). These official results correspond to a previous dataset containing 712 triples4. As shown in column Filled our approach returns less triples than other systems, explaining low recall. However, our system achieves the highest precision for the complete task of temporally anchored relation extraction. Despite low recall, our system obtains the third best Fl value. This is a very promising result, since several directions can be explored to consider more candidates and increase recall. 7 Related Work Compiling a Knowledge Base of temporally anchored facts is an open research challenge (Weikum et al., 2011). Despite the vast amount of research focusing on understanding temporal expressions and 4Slot-fillers from human assessors were not considered their relation to events in natural language, the complete problem of temporally anchored relation extraction remains relatively unexplored. Also, while much research has focused on single-document extraction, it seems clear that extracting temporally anchored relations needs the aggregation of evidences across multiple documents. There have been attempts to extend an existing knowledge base. Wang et al. (2010) use regular expressions to mine Wikipedia</context>
<context position="30803" citStr="Weikum et al., 2011" startWordPosition="5036" endWordPosition="5039"> step for the evaluation of temporal information extraction systems. In general, the participant systems adapted existing slot filling systems, adding a temporal classification component: distant supervised (Chen et al., 2010; Surdeanu et al., 2010) on manually-defined patterns (Byrne and Dunnion, 2010). 8 Conclusions This paper introduces the problem of extracting, from unrestricted natural language text, relational knowledge anchored to a temporal span, aggregating temporal evidence from a collection of documents. Although compiling time-aware knowledge bases is an important open challenge (Weikum et al., 2011), it has remained unexplored until very recently (Wang et al., 2011; Talukdar et al., 2012). We have elucidated the two challenges of the task, namely relation extraction and temporal anchoring of the extracted relations. We have studied how, in a pipeline architecture, the propagation of errors limits the overall system’s performance. The performance attainable in the full task is limited by the quality of the output of the three main phases: retrieval of candidate passages/ documents, extraction of relations and temporal anchoring of those. We have also studied the limits of the distant supe</context>
</contexts>
<marker>Weikum, Bedathur, Schenkel, 2011</marker>
<rawString>Gerhard Weikum, Srikanta Bedathur, and Ralf Schenkel. 2011. Temporal knowledge for timely intelligence. In Malu Castellanos, Umeshwar Dayal, Volker Markl, Wil Aalst, John Mylopoulos, Michael Rosemann, Michael J. Shaw, and Clemens Szyperski, editors, Enabling Real-Time Business Intelligence, volume 84 of Lecture Notes in Business Information Processing, pages 1–6. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Katsumasa Yoshikawa</author>
<author>Sebastian Riedel</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Jointly identifying temporal relations with Markov Logic.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09,</booktitle>
<pages>405--413</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29614" citStr="Yoshikawa et al., 2009" startWordPosition="4858" endWordPosition="4861"> Lascarides, 2004; Chambers et al., 2007), or syntactic-based structured features (Bethard and Martin, 2007; Pus¸cas¸u, 2007; Cheng et al., 2007). Aggregating evidence across different documents 113 to temporally anchor facts has been explored in settings different to Information Extraction, such as answering of definition questions (Pas¸ca, 2008) or extracting possible dates of well-known historical events (Schockaert et al., 2010). Temporal inference or reasoning to solve conflicting temporal expressions and induce temporal order of events has been used in TempEval (Tatu and Srikanth, 2008; Yoshikawa et al., 2009) and ACE (Gupta and Ji, 2009) tasks, but focused on single-document extraction. Ling et al. (2010), use cross-event joint inference to extract temporal facts, but only inside a single document. Evaluation campaigns, such as ACE and TACKBP 2011 have had an important role in promoting this research. While ACE required only to identify time expressions and classify their relation to events, KBP requires to infer explicitly the start/end time of relations, which is a realistic approach in the context of building time-aware knowledge bases. KBP represents an important step for the evaluation of tem</context>
</contexts>
<marker>Yoshikawa, Riedel, Asahara, Matsumoto, 2009</marker>
<rawString>Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asahara, and Yuji Matsumoto. 2009. Jointly identifying temporal relations with Markov Logic. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09, pages 405–413, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Zhang</author>
<author>Fabian M Suchanek</author>
<author>Lihua Yue</author>
<author>Gerhard Weikum</author>
</authors>
<title>TOB: Timely ontologies for business relations.</title>
<date>2008</date>
<booktitle>In 11th International Workshop on the Web and Databases,</booktitle>
<location>WebDB.</location>
<contexts>
<context position="28002" citStr="Zhang et al., 2008" startWordPosition="4604" endWordPosition="4607">Slot-fillers from human assessors were not considered their relation to events in natural language, the complete problem of temporally anchored relation extraction remains relatively unexplored. Also, while much research has focused on single-document extraction, it seems clear that extracting temporally anchored relations needs the aggregation of evidences across multiple documents. There have been attempts to extend an existing knowledge base. Wang et al. (2010) use regular expressions to mine Wikipedia infoboxes and categories and it is not suited for unrestricted text. An earlier attempt (Zhang et al., 2008), is specific for business and difficult to generalize to other relations. Two recent promising works are more related to our research. Wang et al. (2011) uses manually defined patterns to collect candidate facts and explicit dates, and re-rank them using a graph label propagation algorithm; their approach is complementary to ours, as our aim is not to harvest temporal facts but to extract the relations in which a query entity takes part; unlike us, they require entity, value, and a explicit date to appear in the same sentence. Talukdar et al. (2012) focus on the partial task of temporally anc</context>
</contexts>
<marker>Zhang, Suchanek, Yue, Weikum, 2008</marker>
<rawString>Qi Zhang, Fabian M. Suchanek, Lihua Yue, and Gerhard Weikum. 2008. TOB: Timely ontologies for business relations. In 11th International Workshop on the Web and Databases, WebDB.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>