<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000041">
<title confidence="0.945774">
Local and Global Algorithms for Disambiguation to Wikipedia
</title>
<author confidence="0.999181">
Lev Ratinov&apos; Dan Roth&apos; Doug Downey&apos; Mike Anderson3
</author>
<affiliation confidence="0.998046">
&apos;University of Illinois at Urbana-Champaign
</affiliation>
<email confidence="0.964168">
{ratinov2|danr}@uiuc.edu
</email>
<affiliation confidence="0.671326">
&apos;Northwestern University
</affiliation>
<email confidence="0.799589">
ddowney@eecs.northwestern.edu
3Rexonomy
mrander@gmail.com
</email>
<sectionHeader confidence="0.995362" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997518">
Disambiguating concepts and entities in a con-
text sensitive way is a fundamental problem
in natural language processing. The compre-
hensiveness of Wikipedia has made the on-
line encyclopedia an increasingly popular tar-
get for disambiguation. Disambiguation to
Wikipedia is similar to a traditional Word
Sense Disambiguation task, but distinct in that
the Wikipedia link structure provides addi-
tional information about which disambigua-
tions are compatible. In this work we analyze
approaches that utilize this information to ar-
rive at coherent sets of disambiguations for a
given document (which we call “global” ap-
proaches), and compare them to more tradi-
tional (local) approaches. We show that previ-
ous approaches for global disambiguation can
be improved, but even then the local disam-
biguation provides a baseline which is very
hard to beat.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999674755555556">
Wikification is the task of identifying and link-
ing expressions in text to their referent Wikipedia
pages. Recently, Wikification has been shown to
form a valuable component for numerous natural
language processing tasks including text classifica-
tion (Gabrilovich and Markovitch, 2007b; Chang et
al., 2008), measuring semantic similarity between
texts (Gabrilovich and Markovitch, 2007a), cross-
document co-reference resolution (Finin et al., 2009;
Mayfield et al., 2009), and other tasks (Kulkarni et
al., 2009).
Previous studies on Wikification differ with re-
spect to the corpora they address and the subset
of expressions they attempt to link. For exam-
ple, some studies focus on linking only named en-
tities, whereas others attempt to link all “interest-
ing” expressions, mimicking the link structure found
in Wikipedia. Regardless, all Wikification systems
are faced with a key Disambiguation to Wikipedia
(D2W) task. In the D2W task, we’re given a text
along with explicitly identified substrings (called
mentions) to disambiguate, and the goal is to out-
put the corresponding Wikipedia page, if any, for
each mention. For example, given the input sen-
tence “I am visiting friends in &lt;Chicago&gt;,” we
output http://en.wikipedia.org/wiki/Chicago – the
Wikipedia page for the city of Chicago, Illinois, and
not (for example) the page for the 2002 film of the
same name.
Local D2W approaches disambiguate each men-
tion in a document separately, utilizing clues such
as the textual similarity between the document and
each candidate disambiguation’s Wikipedia page.
Recent work on D2W has tended to focus on more
sophisticated global approaches to the problem, in
which all mentions in a document are disambiguated
simultaneously to arrive at a coherent set of dis-
ambiguations (Cucerzan, 2007; Milne and Witten,
2008b; Han and Zhao, 2009). For example, if a
mention of “Michael Jordan” refers to the computer
scientist rather than the basketball player, then we
would expect a mention of “Monte Carlo” in the
same document to refer to the statistical technique
rather than the location. Global approaches utilize
the Wikipedia link graph to estimate coherence.
</bodyText>
<page confidence="0.925712">
1375
</page>
<note confidence="0.9926955">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1375–1384,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<figureCaption confidence="0.945584">
Figure 1: Sample Disambiguation to Wikipedia problem with three mentions. The mention “Jiangsu” is unambiguous.
The correct mapping from mentions to titles is marked by heavy edges
</figureCaption>
<bodyText confidence="0.418178">
Document teat with mentions
</bodyText>
<equation confidence="0.9172016">
φ(m1, t1)
φ(m1, t3)
m1 = Taiwan °°°°°°° m2 = China °°°°°°° m3 = Jiangsu Province
φ(m1, t2)
gf(t1, t7) gf(t3, t7) gf(t5, t7)
t1 = Taiwan
t5 =People&apos;s Republic of China
t6 = History of China
t7 = Jiangsu
t2 = Chinese Taipei t3 =Republic of China t4 = China
</equation>
<bodyText confidence="0.999902615384615">
In this paper, we analyze global and local ap-
proaches to the D2W task. Our contributions are
as follows: (1) We present a formulation of the
D2W task as an optimization problem with local and
global variants, and identify the strengths and the
weaknesses of each, (2) Using this formulation, we
present a new global D2W system, called GLOW. In
experiments on existing and novel D2W data sets,1
GLOW is shown to outperform the previous state-
of-the-art system of (Milne and Witten, 2008b), (3)
We present an error analysis and identify the key re-
maining challenge: determining when mentions re-
fer to concepts not captured in Wikipedia.
</bodyText>
<sectionHeader confidence="0.903424" genericHeader="introduction">
2 Problem Definition and Approach
</sectionHeader>
<bodyText confidence="0.999774214285714">
We formalize our Disambiguation to Wikipedia
(D2W) task as follows. We are given a document
d with a set of mentions M = {m1,... , mN},
and our goal is to produce a mapping from the set
of mentions to the set of Wikipedia titles W =
{t1, ... , t|W|}. Often, mentions correspond to a
concept without a Wikipedia page; we treat this case
by adding a special null title to the set W.
The D2W task can be visualized as finding a
many-to-one matching on a bipartite graph, with
mentions forming one partition and Wikipedia ti-
tles the other (see Figure 1). We denote the output
matching as an N-tuple Γ = (t1, ... , tN) where ti
is the output disambiguation for mention mi.
</bodyText>
<subsectionHeader confidence="0.985238">
2.1 Local and Global Disambiguation
</subsectionHeader>
<bodyText confidence="0.996906166666667">
A local D2W approach disambiguates each men-
tion mi separately. Specifically, let 0(mi, tj) be a
score function reflecting the likelihood that the can-
didate title tj E W is the correct disambiguation for
mi E M. A local approach solves the following
optimization problem:
</bodyText>
<equation confidence="0.987281">
0(mi, ti) (1)
</equation>
<bodyText confidence="0.998512111111111">
Local D2W approaches, exemplified by (Bunescu
and Pasca, 2006) and (Mihalcea and Csomai, 2007),
utilize 0 functions that assign higher scores to titles
with content similar to that of the input document.
We expect, all else being equal, that the correct
disambiguations will form a “coherent” set of re-
lated concepts. Global approaches define a coher-
ence function 0, and attempt to solve the following
disambiguation problem:
</bodyText>
<equation confidence="0.998967">
0(mi, ti) + 0(Γ)] (2)
</equation>
<bodyText confidence="0.999439125">
The global optimization problem in Eq. 2 is NP-
hard, and approximations are required (Cucerzan,
2007). The common approach is to utilize the
Wikipedia link graph to obtain an estimate pairwise
relatedness between titles 0(ti, tj) and to efficiently
generate a disambiguation context Γ′, a rough ap-
proximation to the optimal Γ*. We then solve the
easier problem:
</bodyText>
<equation confidence="0.9524921">
Γ*local = arg max
r
N
i=1
Γ* = arg max[
r
N
i=1
N E
i=1 [�(mi, ti) +
</equation>
<footnote confidence="0.899819">
t;Er′
1The data sets are available for download at Γ* Pz� arg max 0(ti, tj)] (3)
http://cogcomp.cs.illinois.edu/Data r
</footnote>
<page confidence="0.968075">
1376
</page>
<bodyText confidence="0.9998848">
ence of unambiguous mentions in the input docu-
ment, and the second approach inevitably adds ir-
relevant titles to the disambiguation context. As we
demonstrate in our experiments, by utilizing a more
accurate disambiguation context, GLOW is able to
achieve better performance.
Eq. 3 can be solved by finding each ti and then map-
ping mi independently as in a local approach, but
still enforces some degree of coherence among the
disambiguations.
</bodyText>
<sectionHeader confidence="0.997065" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.964889658536585">
Wikipedia was first explored as an information
source for named entity disambiguation and in-
formation retrieval by Bunescu and Pasca (2006).
There, disambiguation is performed using an SVM
kernel that compares the lexical context around the
ambiguous named entity to the content of the can-
didate disambiguation’s Wikipedia page. However,
since each ambiguous mention required a separate
SVM model, the experiment was on a very limited
scale. Mihalcea and Csomai applied Word Sense
Disambiguation methods to the Disambiguation to
Wikipedia task (2007). They experimented with
two methods: (a) the lexical overlap between the
Wikipedia page of the candidate disambiguations
and the context of the ambiguous mention, and (b)
training a Naive Bayes classiffier for each ambigu-
ous mention, using the hyperlink information found
in Wikipedia as ground truth. Both (Bunescu and
Pasca, 2006) and (Mihalcea and Csomai, 2007) fall
into the local framework.
Subsequent work on Wikification has stressed that
assigned disambiguations for the same document
should be related, introducing the global approach
(Cucerzan, 2007; Milne and Witten, 2008b; Han and
Zhao, 2009; Ferragina and Scaiella, 2010). The two
critical components of a global approach are the se-
mantic relatedness function ψ between two titles,
and the disambiguation context V. In (Milne and
Witten, 2008b), the semantic context is defined to
be a set of “unambiguous surface forms” in the text,
and the title relatedness ψ is computed as Normal-
ized Google Distance (NGD) (Cilibrasi and Vitanyi,
2007).2 On the other hand, in (Cucerzan, 2007) the
disambiguation context is taken to be all plausible
disambiguations of the named entities in the text,
and title relatedness is based on the overlap in cat-
egories and incoming links. Both approaches have
limitations. The first approach relies on the pres-
2(Milne and Witten, 2008b) also weight each mention in r′
by its estimated disambiguation utility, which can be modeled
by augmenting 0 on per-problem basis.
</bodyText>
<sectionHeader confidence="0.963471" genericHeader="method">
4 System Architecture
</sectionHeader>
<bodyText confidence="0.999786909090909">
In this section, we present our global D2W system,
which solves the optimization problem in Eq. 3. We
refer to the system as GLOW, for Global Wikifica-
tion. We use GLOW as a test bed for evaluating local
and global approaches for D2W. GLOW combines
a powerful local model φ with an novel method
for choosing an accurate disambiguation context V,
which as we show in our experiments allows it to
outperform the previous state of the art.
We represent the functions φ and ψ as weighted
sums of features. Specifically, we set:
</bodyText>
<equation confidence="0.9161205">
φ(m, t) _ � wiφi(m, t) (4)
i
</equation>
<bodyText confidence="0.999954423076923">
where each feature φi(m, t) captures some aspect
of the relatedness between the mention m and the
Wikipedia title t. Feature functions ψi(t, t′) are de-
fined analogously. We detail the specific feature
functions utilized in GLOW in following sections.
The coefficients wi are learned using a Support Vec-
tor Machine over bootstrapped training data from
Wikipedia, as described in Section 4.5.
At a high level, the GLOW system optimizes the
objective function in Eq. 3 in a two-stage process.
We first execute a ranker to obtain the best non-null
disambiguation for each mention in the document,
and then execute a linker that decides whether the
mention should be linked to Wikipedia, or whether
instead switching the top-ranked disambiguation to
null improves the objective function. As our exper-
iments illustrate, the linking task is the more chal-
lenging of the two by a significant margin.
Figure 2 provides detailed pseudocode for GLOW.
Given a document d and a set of mentions M, we
start by augmenting the set of mentions with all
phrases in the document that could be linked to
Wikipedia, but were not included in M. Introducing
these additional mentions provides context that may
be informative for the global coherence computation
(it has no effect on local approaches). In the second
</bodyText>
<page confidence="0.916805">
1377
</page>
<listItem confidence="0.960092090909091">
Algorithm: Disambiguate to Wikipedia Baseline Feature: P(t|m), P(t)
Input: document d, Mentions M = {m1, ... , mN} Local Features: Oi(t, m)
Output: a disambiguation P = (t1, ... , tN). cosine-sim(Text(t),Text(m)) : Naive/Reweighted
1) Let M′ = MU { Other potential mentions in d} cosine-sim(Text(t),Context(m)): Naive/Reweighted
2) For each mention m′i E M′, construct a set of disam- cosine-sim(Context(t),Text(m)): Naive/Reweighted
biguation candidates Ti = {ti1, ... ,tiki}, tij =� null cosine-sim(Context(t),Context(m)): Naive/Reweighted
3) Ranker: Find a solution P = (t′1, ... ,t′ |M′|), where
t′i E Ti is the best non-null disambiguation of m′i.
4) Linker: For each m′i, map t′i to null in P iff doing so
improves the objective function
5) Return P entries for the original mentions M.
</listItem>
<figureCaption confidence="0.9276965">
Figure 2: High-level pseudocode for GLOW.
Global Features: zPi(ti, tj)
</figureCaption>
<equation confidence="0.993365777777778">
I[ti−tj]*PMI(InLinks(ti),InLinks(tj)) : avg/max
I[ti−tj]*NGD(InLinks(ti),InLinks(tj)) : avg/max
I[ti−tj]*PMI(OutLinks(ti),OutLinks(tj)) : avg/max
I[ti−tj]*NGD(OutLinks(ti),OutLinks(tj)) : avg/max
I[ti↔tj] : avg/max
I[ti↔tj]*PMI(InLinks(ti),InLinks(tj)) : avg/max
I[ti↔tj]*NGD(InLinks(ti),InLinks(tj)) : avg/max
I[ti↔tj]*PMI(OutLinks(ti),OutLinks(tj)) : avg/max
I[ti↔tj]*NGD(OutLinks(ti),OutLinks(tj)) : avg/max
</equation>
<bodyText confidence="0.979133983606557">
step, we construct for each mention mi a limited set
of candidate Wikipedia titles Ti that mi may refer to.
Considering only a small subset of Wikipedia titles
as potential disambiguations is crucial for tractabil-
ity (we detail which titles are selected below). In the
third step, the ranker outputs the most appropriate
non-null disambiguation ti for each mention mi.
In the final step, the linker decides whether the
top-ranked disambiguation is correct. The disam-
biguation (mi, ti) may be incorrect for several rea-
sons: (1) mention mi does not have a corresponding
Wikipedia page, (2) mi does have a corresponding
Wikipedia page, but it was not included in Ti, or
(3) the ranker erroneously chose an incorrect disam-
biguation over the correct one.
In the below sections, we describe each step of the
GLOW algorithm, and the local and global features
utilized, in detail. Because we desire a system that
can process documents at scale, each step requires
trade-offs between accuracy and efficiency.
4.1 Disambiguation Candidates Generation
The first step in GLOW is to extract all mentions that
can refer to Wikipedia titles, and to construct a set
of disambiguation candidates for each mention. Fol-
lowing previous work, we use Wikipedia hyperlinks
to perform these steps. GLOW utilizes an anchor-
title index, computed by crawling Wikipedia, that
maps each distinct hyperlink anchor text to its tar-
get Wikipedia titles. For example, the anchor text
“Chicago” is used in Wikipedia to refer both to the
city in Illinois and to the movie. Anchor texts in the
index that appear in document d are used to supple-
ment the mention set M in Step 1 of the GLOW algo-
rithm in Figure 2. Because checking all substrings
Table 1: Ranker features. I[ti_tj] is an indicator variable
which is 1 iff ti links to t1 or vise-versa. I[ti—tj] is 1 iff
the titles point to each other.
in the input text against the index is computation-
ally inefficient, we instead prune the search space
by applying a publicly available shallow parser and
named entity recognition system.3 We consider only
the expressions marked as named entities by the
NER tagger, the noun-phrase chunks extracted by
the shallow parser, and all sub-expressions of up to
5 tokens of the noun-phrase chunks.
To retrieve the disambiguation candidates Ti for
a given mention mi in Step 2 of the algorithm, we
query the anchor-title index. Ti is taken to be the
set of titles most frequently linked to with anchor
text mi in Wikipedia. For computational efficiency,
we utilize only the top 20 most frequent target pages
for the anchor text; the accuracy impact of this opti-
mization is analyzed in Section 6.
From the anchor-title index, we compute two lo-
cal features Oi(m, t). The first, P(tIm), is the frac-
tion of times the title t is the target page for an an-
chor text m. This single feature is a very reliable
indicator of the correct disambiguation (Fader et al.,
2009), and we use it as a baseline in our experiments.
The second, P(t), gives the fraction of all Wikipedia
articles that link to t.
</bodyText>
<table confidence="0.9786436">
4.2 Local Features 0
In addition to the two baseline features mentioned in
the previous section, we compute a set of text-based
3Available at http://cogcomp.cs.illinois.edu/page/software.
1378
</table>
<bodyText confidence="0.991504571428571">
local features 0(t, m). These features capture the in-
tuition that a given Wikipedia title t is more likely to
be referred to by mention m appearing in document
d if the Wikipedia page for t has high textual simi-
larity to d, or if the context surrounding hyperlinks
to t are similar to m’s context in d.
For each Wikipedia title t, we construct a top-
200 token TF-IDF summary of the Wikipedia page
t, which we denote as Text(t) and a top-200 to-
ken TF-IDF summary of the context within which
t was hyperlinked to in Wikipedia, which we denote
as Context(t). We keep the IDF vector for all to-
kens in Wikipedia, and given an input mention m in
a document d, we extract the TF-IDF representation
of d, which we denote Text(d), and a TF-IDF rep-
resentation of a 100-token window around m, which
we denote Context(m). This allows us to define
four local features described in Table 1.
We additionally compute weighted versions of
the features described above. Error analysis has
shown that in many cases the summaries of the dif-
ferent disambiguation candidates for the same sur-
face form s were very similar. For example, con-
sider the disambiguation candidates of “China’ and
their TF-IDF summaries in Figure 1. The major-
ity of the terms selected in all summaries refer to
the general issues related to China, such as “legal-
ism, reform, military, control, etc.”, while a minority
of the terms actually allow disambiguation between
the candidates. The problem stems from the fact
that the TF-IDF summaries are constructed against
the entire Wikipedia, and not against the confusion
set of disambiguation candidates of m. Therefore,
we re-weigh the TF-IDF vectors using the TF-IDF
scheme on the disambiguation candidates as a ad-
hoc document collection, similarly to an approach
in (Joachims, 1997) for classifying documents. In
our scenario, the TF of the a token is the original
TF-IDF summary score (a real number), and the IDF
term is the sum of all the TF-IDF scores for the to-
ken within the set of disambiguation candidates for
m. This adds 4 more “reweighted local” features in
</bodyText>
<tableCaption confidence="0.707008">
Table 1.
</tableCaption>
<subsectionHeader confidence="0.966207">
4.3 Global Features 0
</subsectionHeader>
<bodyText confidence="0.9989735">
Global approaches require a disambiguation context
V and a relatedness measure 0 in Eq. 3. In this sec-
tion, we describe our method for generating a dis-
ambiguation context, and the set of global features
0i(t, t′) forming our relatedness measure.
In previous work, Cucerzan defined the disam-
biguation context as the union of disambiguation
candidates for all the named entity mentions in the
input document (2007). The disadvantage of this ap-
proach is that irrelevant titles are inevitably added to
the disambiguation context, creating noise. Milne
and Witten, on the other hand, use a set of un-
ambiguous mentions (2008b). This approach uti-
lizes only a fraction of the available mentions for
context, and relies on the presence of unambigu-
ous mentions with high disambiguation utility. In
GLOW, we utilize a simple and efficient alternative
approach: we first train a local disambiguation sys-
tem, and then use the predictions of that system as
the disambiguation context. The advantage of this
approach is that unlike (Milne and Witten, 2008b)
we use all the available mentions in the document,
and unlike (Cucerzan, 2007) we reduce the amount
of irrelevant titles in the disambiguation context by
taking only the top-ranked disambiguation per men-
tion.
Our global features are refinements of previously
proposed semantic relatedness measures between
Wikipedia titles. We are aware of two previous
methods for estimating the relatedness between two
Wikipedia concepts: (Strube and Ponzetto, 2006),
which uses category overlap, and (Milne and Wit-
ten, 2008a), which uses the incoming link structure.
Previous work experimented with two relatedness
measures: NGD, and Specificity-weighted Cosine
Similarity. Consistent with previous work, we found
NGD to be the better-performing of the two. Thus
we use only NGD along with a well-known Pon-
twise Mutual Information (PMI) relatedness mea-
sure. Given a Wikipedia title collection W, titles
t1 and t2 with a set of incoming links L1, and L2
respectively, PMI and NGD are defined as follows:
</bodyText>
<equation confidence="0.940397">
1VGD(L1,L2)= Log(|W|) − Log(Min(|L1|,|L2|))
PMI(L1, L2) = |L1 ∩ L2|/|W|
|L1|/|W||L2|/|W|
</equation>
<bodyText confidence="0.999848">
The NGD and the PMI measures can also be com-
puted over the set of outgoing links, and we include
these as features as well. We also included a fea-
ture indicating whether the articles each link to one
</bodyText>
<equation confidence="0.914725">
Log(Max(|L1|, |L2|)) − Log(|L1 ∩ L2|)
</equation>
<page confidence="0.970954">
1379
</page>
<bodyText confidence="0.999863133333333">
another. Lastly, rather than taking the sum of the re-
latedness scores as suggested by Eq. 3, we use two
features: the average and the maximum relatedness
to V. We expect the average to be informative for
many documents. The intuition for also including
the maximum relatedness is that for longer docu-
ments that may cover many different subtopics, the
maximum may be more informative than the aver-
age.
We have experimented with other semantic fea-
tures, such as category overlap or cosine similar-
ity between the TF-IDF summaries of the titles, but
these did not improve performance in our experi-
ments. The complete set of global features used in
GLOW is given in Table 1.
</bodyText>
<subsectionHeader confidence="0.993002">
4.4 Linker Features
</subsectionHeader>
<bodyText confidence="0.99999025">
Given the mention m and the top-ranked disam-
biguation t, the linker attempts to decide whether t is
indeed the correct disambiguation of m. The linker
includes the same features as the ranker, plus addi-
tional features we expect to be particularly relevant
to the task. We include the confidence of the ranker
in t with respect to second-best disambiguation t′,
intended to estimate whether the ranker may have
made a mistake. We also include several properties
of the mention m: the entropy of the distribution
P(tlm), the percent of Wikipedia titles in which m
appears hyperlinked versus the percent of times m
appears as plain text, whether m was detected by
NER as a named entity, and a Good-Turing estimate
of how likely m is to be out-of-Wikipedia concept
based on the counts in P(t1m).
</bodyText>
<subsectionHeader confidence="0.989829">
4.5 Linker and Ranker Training
</subsectionHeader>
<bodyText confidence="0.999968615384615">
We train the coefficients for the ranker features us-
ing a linear Ranking Support Vector Machine, using
training data gathered from Wikipedia. Wikipedia
links are considered gold-standard links for the
training process. The methods for compiling the
Wikipedia training corpus are given in Section 5.
We train the linker as a separate linear Support
Vector Machine. Training data for the linker is ob-
tained by applying the ranker on the training set. The
mentions for which the top-ranked disambiguation
did not match the gold disambiguation are treated
as negative examples, while the mentions the ranker
got correct serve as positive examples.
</bodyText>
<table confidence="0.998018666666667">
Mentions/Distinct titles
data set Gold Identified Solvable
ACE 257/255 213/212 185/184
MSNBC 747/372 530/287 470/273
AQUAINT 727/727 601/601 588/588
Wikipedia 928/813 855/751 843/742
</table>
<tableCaption confidence="0.995327777777778">
Table 2: Number of mentions and corresponding dis-
tinct titles by data set. Listed are (number of men-
tions)/(number of distinct titles) for each data set, for each
of three mention types. Gold mentions include all dis-
ambiguated mentions in the data set. Identified mentions
are gold mentions whose correct disambiguations exist in
GLOW’s author-title index. Solvable mentions are identi-
fied mentions whose correct disambiguations are among
the candidates selected by GLOW (see Table 3).
</tableCaption>
<sectionHeader confidence="0.784043" genericHeader="method">
5 Data sets and Evaluation Methodology
</sectionHeader>
<bodyText confidence="0.999962129032258">
We evaluate GLOW on four data sets, of which
two are from previous work. The first data set,
from (Milne and Witten, 2008b), is a subset of the
AQUAINT corpus of newswire text that is annotated
to mimic the hyperlink structure in Wikipedia. That
is, only the first mentions of “important” titles were
hyperlinked. Titles deemed uninteresting and re-
dundant mentions of the same title are not linked.
The second data set, from (Cucerzan, 2007), is taken
from MSNBC news and focuses on disambiguating
named entities after running NER and co-reference
resolution systems on newsire text. In this case,
all mentions of all the detected named entities are
linked.
We also constructed two additional data sets. The
first is a subset of the ACE co-reference data set,
which has the advantage that mentions and their
types are given, and the co-reference is resolved. We
asked annotators on Amazon’s Mechanical Turk to
link the first nominal mention of each co-reference
chain to Wikipedia, if possible. Finding the accu-
racy of a majority vote of these annotations to be
approximately 85%, we manually corrected the an-
notations to obtain ground truth for our experiments.
The second data set we constructed, Wiki, is a sam-
ple of paragraphs from Wikipedia pages. Mentions
in this data set correspond to existing hyperlinks in
the Wikipedia text. Because Wikipedia editors ex-
plicitly link mentions to Wikipedia pages, their an-
chor text tends to match the title of the linked-to-
page—as a result, in the overwhelming majority of
</bodyText>
<page confidence="0.980209">
1380
</page>
<bodyText confidence="0.998441295454545">
cases, the disambiguation decision is as trivial as
string matching. In an attempt to generate more
challenging data, we extracted 10,000 random para-
graphs for which choosing the top disambiguation
according to P(t|m) results in at least a 10% ranker
error rate. 40 paragraphs of this data was utilized for
testing, while the remainder was used for training.
The data sets are summarized in Table 2. The ta-
ble shows the number of annotated mentions which
were hyperlinked to non-null Wikipedia pages, and
the number of titles in the documents (without
counting repetitions). For example, the AQUAINT
data set contains 727 mentions,4 all of which refer
to distinct titles. The MSNBC data set contains 747
mentions mapped to non-null Wikipedia pages, but
some mentions within the same document refer to
the same titles. There are 372 titles in the data set,
when multiple instances of the same title within one
document are not counted.
To isolate the performance of the individual com-
ponents of GLOW, we use multiple distinct metrics
for evaluation. Ranker accuracy, which measures
the performance of the ranker alone, is computed
only over those mentions with a non-null gold dis-
ambiguation that appears in the candidate set. It is
equal to the fraction of these mentions for which the
ranker returns the correct disambiguation. Thus, a
perfect ranker should achieve a ranker accuracy of
1.0, irrespective of limitations of the candidate gen-
erator. Linker accuracy is defined as the fraction of
all mentions for which the linker outputs the correct
disambiguation (note that, when the title produced
by the ranker is incorrect, this penalizes linker accu-
racy). Lastly, we evaluate our whole system against
other baselines using a previously-employed “bag of
titles” (BOT) evaluation (Milne and Witten, 2008b).
In BOT, we compare the set of titles output for a doc-
ument with the gold set of titles for that document
(ignoring duplicates), and utilize standard precision,
recall, and F1 measures.
In BOT, the set of titles is collected from the men-
tions hyperlinked in the gold annotation. That is,
if the gold annotation is { (China, People’s Repub-
lic of China), (Taiwan, Taiwan), (Jiangsu, Jiangsu)}
</bodyText>
<footnote confidence="0.974713">
4The data set contains votes on how important the mentions
are. We believe that the results in (Milne and Witten, 2008b)
were reported on mentions which the majority of annotators
considered important. In contrast, we used all the mentions.
</footnote>
<table confidence="0.999224833333333">
Generated ACE data sets Wiki
Candidates k MSNBC AQUAINT
1 81.69 72.26 91.01 84.79
3 85.44 86.22 96.83 94.73
5 86.38 87.35 97.17 96.37
20 86.85 88.67 97.83 98.59
</table>
<tableCaption confidence="0.998514">
Table 3: Percent of “solvable” mentions as a function
</tableCaption>
<bodyText confidence="0.980525894736842">
of the number of generated disambiguation candidates.
Listed is the fraction of identified mentions m whose
target disambiguation t is among the top k candidates
ranked in descending order of P(t|m).
and the predicted anotation is: { (China, People’s
Republic of China), (China, History of China), (Tai-
wan, null), (Jiangsu, Jiangsu), (republic, Govern-
ment)} , then the BOT for the gold annotation is:
{People’s Republic of China, Taiwan, Jiangsu} , and
the BOT for the predicted annotation is: {People’s
Republic of China, History of China, Jiangsu} . The
title Government is not included in the BOT for pre-
dicted annotation, because its associate mention re-
public did not appear as a mention in the gold anno-
tation. Both the precision and the recall of the above
prediction is 0.66. We note that in the BOT evalua-
tion, following (Milne and Witten, 2008b) we con-
sider all the titles within a document, even if some
the titles were due to mentions we failed to identify.5
</bodyText>
<sectionHeader confidence="0.994622" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999571176470588">
In this section, we evaluate and analyze GLOW’s
performance on the D2W task. We begin by eval-
uating the mention detection component (Step 1 of
the algorithm). The second column of Table 2 shows
how many of the “non-null” mentions and corre-
sponding titles we could successfully identify (e.g.
out of 747 mentions in the MSNBC data set, only
530 appeared in our anchor-title index). Missing en-
tities were primarily due to especially rare surface
forms, or sometimes due to idiosyncratic capitaliza-
tion in the corpus. Improving the number of iden-
tified mentions substantially is non-trivial; (Zhou et
al., 2010) managed to successfully identify only 59
more entities than we do in the MSNBC data set, us-
ing a much more powerful detection method based
on search engine query logs.
We generate disambiguation candidates for a
</bodyText>
<footnote confidence="0.974211">
5We evaluate the mention identification stage in Section 6.
</footnote>
<page confidence="0.930767">
1381
</page>
<table confidence="0.999775461538462">
Features ACE Data sets Wiki
MSNBC AQUAINT
P(t|m) 94.05 81.91 93.19 85.88
P(t|m)+Local
Naive 95.67 84.04 94.38 92.76
Reweighted 96.21 85.10 95.57 93.59
All above 95.67 84.68 95.40 93.59
P(t|m)+Global
NER 96.21 84.04 94.04 89.56
Unambiguous 94.59 84.46 95.40 89.67
Predictions 96.75 88.51 95.91 89.79
P(t|m)+Local+Global
All features 97.83 87.02 94.38 94.18
</table>
<tableCaption confidence="0.9354608">
Table 4: Ranker Accuracy. Bold values indicate the
best performance in each feature group. The global ap-
proaches marginally outperform the local approaches on
ranker accuracy, while combing the approaches leads to
further marginal performance improvement.
</tableCaption>
<bodyText confidence="0.9998826">
mention m using an anchor-title index, choosing
the 20 titles with maximal P(t|m). Table 3 eval-
uates the accuracy of this generation policy. We
report the percent of mentions for which the cor-
rect disambiguation is generated in the top k can-
didates (called “solvable” mentions). We see that
the baseline prediction of choosing the disambigua-
tion t which maximizes P(t|m) is very strong (80%
of the correct mentions have maximal P(t|m) in all
data sets except MSNBC). The fraction of solvable
mentions increases until about five candidates per
mention are generated, after which the increase is
rather slow. Thus, we believe choosing a limit of 20
candidates per mention offers an attractive trade-off
of accuracy and efficiency. The last column of Ta-
ble 2 reports the number of solvable mentions and
the corresponding number of titles with a cutoff of
20 disambiguation candidates, which we use in our
experiments.
Next, we evaluate the accuracy of the ranker. Ta-
ble 4 compares the ranker performance with base-
line, local and global features. The reweighted lo-
cal features outperform the unweighted (“Naive”)
version, and the global approach outperforms the
local approach on all data sets except Wikipedia.
As the table shows, our approach of defining the
disambiguation context to be the predicted dis-
ambiguations of a simpler local model (“Predic-
tions”) performs better than using NER entities as
in (Cucerzan, 2007), or only the unambiguous enti-
</bodyText>
<table confidence="0.9998736">
Data set Local Global Local+Global
ACE 80.1 → 82.8 80.6 → 80.6 81.5 → 85.1
MSNBC 74.9 → 76.0 77.9 → 77.9 76.5 → 76.9
AQUAINT 93.5 → 91.5 93.8 → 92.1 92.3 → 91.3
Wiki 92.2 → 92.0 88.5 → 87.2 92.8 → 92.6
</table>
<tableCaption confidence="0.8345455">
Table 5: Linker performance. The notation X → Y
means that when linking all mentions, the linking accu-
</tableCaption>
<bodyText confidence="0.66975125">
racy is X, while when applying the trained linker, the
performance is Y . The local approaches are better suited
for linking than the global approaches. The linking accu-
racy is very sensitive to domain changes.
</bodyText>
<table confidence="0.9989315">
System ACE MSNBC AQUAINT Wiki
Baseline: P(t|m) 69.52 72.83 82.67 81.77
GLOW Local 75.60 74.39 84.52 90.20
GLOW Global 74.73 74.58 84.37 86.62
GLOW 77.25 74.88 83.94 90.54
M&amp;W 72.76 68.49 83.61 80.32
</table>
<tableCaption confidence="0.92812825">
Table 6: End systems performance - BOT F1. The per-
formance of the full system (GLOW) is similar to that of
the local version. GLOW outperforms (Milne and Witten,
2008b) on all data sets.
</tableCaption>
<bodyText confidence="0.999875363636363">
ties as in (Milne and Witten, 2008b).6 Combining
the local and the global approaches typically results
in minor improvements.
While the global approaches are most effective for
ranking, the linking problem has different charac-
teristics as shown in Table 5. We can see that the
global features are not helpful in general for predict-
ing whether the top-ranked disambiguation is indeed
the correct one.
Further, although the trained linker improves ac-
curacy in some cases, the gains are marginal—and
the linker decreases performance on some data sets.
One explanation for the decrease is that the linker
is trained on Wikipedia, but is being tested on non-
Wikipedia text which has different characteristics.
However, in separate experiments we found that
training a linker on out-of-Wikipedia text only in-
creased test set performance by approximately 3
percentage points. Clearly, while ranking accuracy
is high overall, different strategies are needed to
achieve consistently high linking performance.
A few examples from the ACE data set help il-
</bodyText>
<footnote confidence="0.993116">
6In NER we used only the top prediction, because using all
candidates as in (Cucerzan, 2007) proved prohibitively ineffi-
cient.
</footnote>
<page confidence="0.981411">
1382
</page>
<bodyText confidence="0.996468795918367">
lustrate the tradeoffs between local and global fea- 7 Conclusions
tures in GLOW. The global system mistakenly links We have formalized the Disambiguation to
“&lt;Dorothy Byrne&gt;, a state coordinator for the Wikipedia (D2W) task as an optimization problem
Florida Green Party, said... ” to the British jour- with local and global variants, and analyzed the
nalist, because the journalist sense has high coher- strengths and weaknesses of each. Our experiments
ence with other mentions in the newswire text. How- revealed that previous approaches for global disam-
ever, the local approach correctly maps the men- biguation can be improved, but even then the local
tion to null because of a lack of local contextual disambiguation provides a baseline which is very
clues. On the other hand, in the sentence “In- hard to beat.
stead of Los Angeles International, for example, As our error analysis illustrates, the primary re-
consider flying into &lt;Burbank&gt; or John Wayne Air- maining challenge is determining when a mention
port in Orange County, Calif.”, the local ranker does not have a corresponding Wikipedia page.
links the mention Burbank to Burbank, California, Wikipedia’s hyperlinks offer a wealth of disam-
while the global system correctly maps the entity to biguated mentions that can be leveraged to train
Bob Hope Airport, because the three airports men- a D2W system. However, when compared with
tioned in the sentence are highly related to one an- mentions from general text, Wikipedia mentions
other. are disproportionately likely to have corresponding
Lastly, in Table 6 we compare the end system Wikipedia pages. Our initial experiments suggest
BOT F1 performance. The local approach proves that accounting for this bias requires more than sim-
a very competitive baseline which is hard to beat. ply training a D2W system on a moderate num-
Combining the global and the local approach leads ber of examples from non-Wikipedia text. Apply-
to marginal improvements. The full GLOW sys- ing distinct semi-supervised and active learning ap-
tem outperforms the existing state-of-the-art system proaches to the task is a primary area of future work.
from (Milne and Witten, 2008b), denoted as M&amp;W, Acknowledgments
on all data sets. We also compared our system with This research supported by the Army Research
the recent TAGME Wikification system (Ferragina Laboratory (ARL) under agreement W911NF-09-
and Scaiella, 2010). However, TAGME is designed 2-0053 and by the Defense Advanced Research
for a different setting than ours: extremely short Projects Agency (DARPA) Machine Reading Pro-
texts, like Twitter posts. The TAGME RESTful API gram under Air Force Research Laboratory (AFRL)
was unable to process some of our documents at prime contract no. FA8750-09-C-0181. The third
once. We attempted to input test documents one sen- author was supported by a Microsoft New Faculty
tence at a time, disambiguating each sentence inde- Fellowship. Any opinions, findings, conclusions or
pendently, which resulted in poor performance (0.07 recommendations are those of the authors and do not
points in F1 lower than the P(tlm) baseline). This necessarily reflect the view of the ARL, DARPA,
happened mainly because the same mentions were AFRL, or the US government.
linked to different titles in different sentences, lead- References
ing to low precision. R. Bunescu and M. Pasca. 2006. Using encyclope-
An important question is why M&amp;W underper- dic knowledge for named entity disambiguation. In
forms the baseline on the MSNBC and Wikipedia Proceedings of the 11th Conference of the European
data sets. In an error analysis, M&amp;W performed Chapter ofthe Association for Computational Linguis-
poorly on the MSNBC data not due to poor disam- tics (EACL-06), Trento, Italy, pages 9–16, April.
biguations, but instead because the data set contains Ming-Wei Chang, Lev Ratinov, Dan Roth, and Vivek
only named entities, which were often delimited in- Srikumar. 2008. Importance of semantic represen-
correctly by M&amp;W. Wikipedia was challenging for tation: dataless classification. In Proceedings of the
a different reason: M&amp;W performs less well on the
short (one paragraph) texts in that set, because they
contain relatively few of the unambiguous entities
the system relies on for disambiguation.
1383
</bodyText>
<reference confidence="0.998255452631579">
23rd national conference on Artificial intelligence -
Volume 2, pages 830–835. AAAI Press.
Rudi L. Cilibrasi and Paul M. B. Vitanyi. 2007. The
google similarity distance. IEEE Trans. on Knowl. and
Data Eng., 19(3):370–383.
Silviu Cucerzan. 2007. Large-scale named entity dis-
ambiguation based on Wikipedia data. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), pages
708–716, Prague, Czech Republic, June. Association
for Computational Linguistics.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2009. Scaling wikipedia-based named entity disam-
biguation to arbitrary web text. In Proceedings of
the WikiAI 09 - IJCAI Workshop: User Contributed
Knowledge and Artificial Intelligence: An Evolving
Synergy, Pasadena, CA, USA, July.
Paolo Ferragina and Ugo Scaiella. 2010. Tagme: on-the-
fly annotation of short text fragments (by wikipedia
entities). In Jimmy Huang, Nick Koudas, Gareth J. F.
Jones, Xindong Wu, Kevyn Collins-Thompson, and
Aijun An, editors, Proceedings of the 19th ACM con-
ference on Information and knowledge management,
pages 1625–1628. ACM.
Tim Finin, Zareen Syed, James Mayfield, Paul Mc-
Namee, and Christine Piatko. 2009. Using Wikitol-
ogy for Cross-Document Entity Coreference Resolu-
tion. In Proceedings of the AAAI Spring Symposium
on Learning by Reading and Learning to Read. AAAI
Press, March.
Evgeniy Gabrilovich and Shaul Markovitch. 2007a.
Computing semantic relatedness using wikipedia-
based explicit semantic analysis. In Proceedings of the
20th international joint conference on Artifical intel-
ligence, pages 1606–1611, San Francisco, CA, USA.
Morgan Kaufmann Publishers Inc.
Evgeniy Gabrilovich and Shaul Markovitch. 2007b.
Harnessing the expertise of 70,000 human editors:
Knowledge-based feature generation for text catego-
rization. J. Mach. Learn. Res., 8:2297–2345, Decem-
ber.
Xianpei Han and Jun Zhao. 2009. Named entity dis-
ambiguation by leveraging wikipedia semantic knowl-
edge. In Proceeding of the 18th ACM conference on
Information and knowledge management, CIKM ’09,
pages 215–224, New York, NY, USA. ACM.
Thorsten Joachims. 1997. A probabilistic analysis of
the rocchio algorithm with tfidf for text categoriza-
tion. In Proceedings of the Fourteenth International
Conference on Machine Learning, ICML ’97, pages
143–151, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and
Soumen Chakrabarti. 2009. Collective annotation
of wikipedia entities in web text. In Proceedings
of the 15th ACM SIGKDD international conference
on Knowledge discovery and data mining, KDD ’09,
pages 457–466, New York, NY, USA. ACM.
James Mayfield, David Alexander, Bonnie Dorr, Jason
Eisner, Tamer Elsayed, Tim Finin, Clay Fink, Mar-
jorie Freedman, Nikesh Garera, James Mayfield, Paul
McNamee, Saif Mohammad, Douglas Oard, Chris-
tine Piatko, Asad Sayeed, Zareen Syed, and Ralph
Weischede. 2009. Cross-Document Coreference Res-
olution: A Key Technology for Learning by Reading.
In Proceedings of the AAAI 2009 Spring Symposium
on Learning by Reading and Learning to Read. AAAI
Press, March.
Rada Mihalcea and Andras Csomai. 2007. Wikify!: link-
ing documents to encyclopedic knowledge. In Pro-
ceedings of the sixteenth ACM conference on Con-
ference on information and knowledge management,
CIKM ’07, pages 233–242, New York, NY, USA.
ACM.
David Milne and Ian H. Witten. 2008a. An effec-
tive, low-cost measure of semantic relatedness ob-
tained from wikipedia links. In In the Wikipedia and
AI Workshop ofAAAI.
David Milne and Ian H. Witten. 2008b. Learning to link
with wikipedia. In Proceedings of the 17th ACM con-
ference on Information and knowledge management,
CIKM ’08, pages 509–518, New York, NY, USA.
ACM.
Michael Strube and Simone Paolo Ponzetto. 2006.
Wikirelate! computing semantic relatedness using
wikipedia. In proceedings of the 21st national confer-
ence on Artificial intelligence - Volume 2, pages 1419–
1424. AAAI Press.
Yiping Zhou, Lan Nie, Omid Rouhani-Kalleh, Flavian
Vasile, and Scott Gaffney. 2010. Resolving surface
forms to wikipedia topics. In Proceedings of the 23rd
International Conference on Computational Linguis-
tics (Coling 2010), pages 1335–1343, Beijing, China,
August. Coling 2010 Organizing Committee.
</reference>
<page confidence="0.993971">
1384
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.356948">
<title confidence="0.838897">Local and Global Algorithms for Disambiguation to Wikipedia</title>
<author confidence="0.471814">of Illinois at</author>
<affiliation confidence="0.981697">University</affiliation>
<email confidence="0.9972545">ddowney@eecs.northwestern.edumrander@gmail.com</email>
<abstract confidence="0.988645380952381">Disambiguating concepts and entities in a context sensitive way is a fundamental problem in natural language processing. The comprehensiveness of Wikipedia has made the online encyclopedia an increasingly popular target for disambiguation. Disambiguation to Wikipedia is similar to a traditional Word Sense Disambiguation task, but distinct in that the Wikipedia link structure provides additional information about which disambiguations are compatible. In this work we analyze approaches that utilize this information to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches. We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>23rd national conference on Artificial intelligence -Volume</booktitle>
<volume>2</volume>
<pages>830--835</pages>
<publisher>AAAI Press.</publisher>
<marker></marker>
<rawString>23rd national conference on Artificial intelligence -Volume 2, pages 830–835. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudi L Cilibrasi</author>
<author>Paul M B Vitanyi</author>
</authors>
<title>The google similarity distance.</title>
<date>2007</date>
<journal>IEEE Trans. on Knowl. and Data Eng.,</journal>
<volume>19</volume>
<issue>3</issue>
<contexts>
<context position="8616" citStr="Cilibrasi and Vitanyi, 2007" startWordPosition="1371" endWordPosition="1374">the local framework. Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010). The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007).2 On the other hand, in (Cucerzan, 2007) the disambiguation context is taken to be all plausible disambiguations of the named entities in the text, and title relatedness is based on the overlap in categories and incoming links. Both approaches have limitations. The first approach relies on the pres2(Milne and Witten, 2008b) also weight each mention in r′ by its estimated disambiguation utility, which can be modeled by augmenting 0 on per-problem basis. 4 System Architecture In this section, we present our global D2W system, which solves the optimization problem in Eq. 3. We refer to the syste</context>
</contexts>
<marker>Cilibrasi, Vitanyi, 2007</marker>
<rawString>Rudi L. Cilibrasi and Paul M. B. Vitanyi. 2007. The google similarity distance. IEEE Trans. on Knowl. and Data Eng., 19(3):370–383.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on Wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>708--716</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="2915" citStr="Cucerzan, 2007" startWordPosition="433" endWordPosition="434">g friends in &lt;Chicago&gt;,” we output http://en.wikipedia.org/wiki/Chicago – the Wikipedia page for the city of Chicago, Illinois, and not (for example) the page for the 2002 film of the same name. Local D2W approaches disambiguate each mention in a document separately, utilizing clues such as the textual similarity between the document and each candidate disambiguation’s Wikipedia page. Recent work on D2W has tended to focus on more sophisticated global approaches to the problem, in which all mentions in a document are disambiguated simultaneously to arrive at a coherent set of disambiguations (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009). For example, if a mention of “Michael Jordan” refers to the computer scientist rather than the basketball player, then we would expect a mention of “Monte Carlo” in the same document to refer to the statistical technique rather than the location. Global approaches utilize the Wikipedia link graph to estimate coherence. 1375 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1375–1384, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: Sample Disambiguation to </context>
<context position="6149" citStr="Cucerzan, 2007" startWordPosition="979" endWordPosition="980"> approach solves the following optimization problem: 0(mi, ti) (1) Local D2W approaches, exemplified by (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007), utilize 0 functions that assign higher scores to titles with content similar to that of the input document. We expect, all else being equal, that the correct disambiguations will form a “coherent” set of related concepts. Global approaches define a coherence function 0, and attempt to solve the following disambiguation problem: 0(mi, ti) + 0(Γ)] (2) The global optimization problem in Eq. 2 is NPhard, and approximations are required (Cucerzan, 2007). The common approach is to utilize the Wikipedia link graph to obtain an estimate pairwise relatedness between titles 0(ti, tj) and to efficiently generate a disambiguation context Γ′, a rough approximation to the optimal Γ*. We then solve the easier problem: Γ*local = arg max r N i=1 Γ* = arg max[ r N i=1 N E i=1 [�(mi, ti) + t;Er′ 1The data sets are available for download at Γ* Pz� arg max 0(ti, tj)] (3) http://cogcomp.cs.illinois.edu/Data r 1376 ence of unambiguous mentions in the input document, and the second approach inevitably adds irrelevant titles to the disambiguation context. As we</context>
<context position="8172" citStr="Cucerzan, 2007" startWordPosition="1300" endWordPosition="1301">methods to the Disambiguation to Wikipedia task (2007). They experimented with two methods: (a) the lexical overlap between the Wikipedia page of the candidate disambiguations and the context of the ambiguous mention, and (b) training a Naive Bayes classiffier for each ambiguous mention, using the hyperlink information found in Wikipedia as ground truth. Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework. Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010). The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007).2 On the other hand, in (Cucerzan, 2007) the disambiguation context is taken to be all plausible disambiguations of the named entities in the text, and tit</context>
<context position="18679" citStr="Cucerzan, 2007" startWordPosition="3019" endWordPosition="3020">mbiguation context, creating noise. Milne and Witten, on the other hand, use a set of unambiguous mentions (2008b). This approach utilizes only a fraction of the available mentions for context, and relies on the presence of unambiguous mentions with high disambiguation utility. In GLOW, we utilize a simple and efficient alternative approach: we first train a local disambiguation system, and then use the predictions of that system as the disambiguation context. The advantage of this approach is that unlike (Milne and Witten, 2008b) we use all the available mentions in the document, and unlike (Cucerzan, 2007) we reduce the amount of irrelevant titles in the disambiguation context by taking only the top-ranked disambiguation per mention. Our global features are refinements of previously proposed semantic relatedness measures between Wikipedia titles. We are aware of two previous methods for estimating the relatedness between two Wikipedia concepts: (Strube and Ponzetto, 2006), which uses category overlap, and (Milne and Witten, 2008a), which uses the incoming link structure. Previous work experimented with two relatedness measures: NGD, and Specificity-weighted Cosine Similarity. Consistent with pr</context>
<context position="23228" citStr="Cucerzan, 2007" startWordPosition="3755" endWordPosition="3756">ndex. Solvable mentions are identified mentions whose correct disambiguations are among the candidates selected by GLOW (see Table 3). 5 Data sets and Evaluation Methodology We evaluate GLOW on four data sets, of which two are from previous work. The first data set, from (Milne and Witten, 2008b), is a subset of the AQUAINT corpus of newswire text that is annotated to mimic the hyperlink structure in Wikipedia. That is, only the first mentions of “important” titles were hyperlinked. Titles deemed uninteresting and redundant mentions of the same title are not linked. The second data set, from (Cucerzan, 2007), is taken from MSNBC news and focuses on disambiguating named entities after running NER and co-reference resolution systems on newsire text. In this case, all mentions of all the detected named entities are linked. We also constructed two additional data sets. The first is a subset of the ACE co-reference data set, which has the advantage that mentions and their types are given, and the co-reference is resolved. We asked annotators on Amazon’s Mechanical Turk to link the first nominal mention of each co-reference chain to Wikipedia, if possible. Finding the accuracy of a majority vote of the</context>
<context position="30878" citStr="Cucerzan, 2007" startWordPosition="4999" endWordPosition="5000">corresponding number of titles with a cutoff of 20 disambiguation candidates, which we use in our experiments. Next, we evaluate the accuracy of the ranker. Table 4 compares the ranker performance with baseline, local and global features. The reweighted local features outperform the unweighted (“Naive”) version, and the global approach outperforms the local approach on all data sets except Wikipedia. As the table shows, our approach of defining the disambiguation context to be the predicted disambiguations of a simpler local model (“Predictions”) performs better than using NER entities as in (Cucerzan, 2007), or only the unambiguous entiData set Local Global Local+Global ACE 80.1 → 82.8 80.6 → 80.6 81.5 → 85.1 MSNBC 74.9 → 76.0 77.9 → 77.9 76.5 → 76.9 AQUAINT 93.5 → 91.5 93.8 → 92.1 92.3 → 91.3 Wiki 92.2 → 92.0 88.5 → 87.2 92.8 → 92.6 Table 5: Linker performance. The notation X → Y means that when linking all mentions, the linking accuracy is X, while when applying the trained linker, the performance is Y . The local approaches are better suited for linking than the global approaches. The linking accuracy is very sensitive to domain changes. System ACE MSNBC AQUAINT Wiki Baseline: P(t|m) 69.52 72</context>
<context position="32944" citStr="Cucerzan, 2007" startWordPosition="5349" endWordPosition="5350">rformance on some data sets. One explanation for the decrease is that the linker is trained on Wikipedia, but is being tested on nonWikipedia text which has different characteristics. However, in separate experiments we found that training a linker on out-of-Wikipedia text only increased test set performance by approximately 3 percentage points. Clearly, while ranking accuracy is high overall, different strategies are needed to achieve consistently high linking performance. A few examples from the ACE data set help il6In NER we used only the top prediction, because using all candidates as in (Cucerzan, 2007) proved prohibitively inefficient. 1382 lustrate the tradeoffs between local and global fea- 7 Conclusions tures in GLOW. The global system mistakenly links We have formalized the Disambiguation to “&lt;Dorothy Byrne&gt;, a state coordinator for the Wikipedia (D2W) task as an optimization problem Florida Green Party, said... ” to the British jour- with local and global variants, and analyzed the nalist, because the journalist sense has high coher- strengths and weaknesses of each. Our experiments ence with other mentions in the newswire text. How- revealed that previous approaches for global disamev</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on Wikipedia data. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 708–716, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Scaling wikipedia-based named entity disambiguation to arbitrary web text.</title>
<date>2009</date>
<booktitle>In Proceedings of the WikiAI 09 - IJCAI Workshop: User Contributed Knowledge and Artificial Intelligence: An Evolving Synergy,</booktitle>
<location>Pasadena, CA, USA,</location>
<contexts>
<context position="15133" citStr="Fader et al., 2009" startWordPosition="2419" endWordPosition="2422">i for a given mention mi in Step 2 of the algorithm, we query the anchor-title index. Ti is taken to be the set of titles most frequently linked to with anchor text mi in Wikipedia. For computational efficiency, we utilize only the top 20 most frequent target pages for the anchor text; the accuracy impact of this optimization is analyzed in Section 6. From the anchor-title index, we compute two local features Oi(m, t). The first, P(tIm), is the fraction of times the title t is the target page for an anchor text m. This single feature is a very reliable indicator of the correct disambiguation (Fader et al., 2009), and we use it as a baseline in our experiments. The second, P(t), gives the fraction of all Wikipedia articles that link to t. 4.2 Local Features 0 In addition to the two baseline features mentioned in the previous section, we compute a set of text-based 3Available at http://cogcomp.cs.illinois.edu/page/software. 1378 local features 0(t, m). These features capture the intuition that a given Wikipedia title t is more likely to be referred to by mention m appearing in document d if the Wikipedia page for t has high textual similarity to d, or if the context surrounding hyperlinks to t are simi</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2009</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2009. Scaling wikipedia-based named entity disambiguation to arbitrary web text. In Proceedings of the WikiAI 09 - IJCAI Workshop: User Contributed Knowledge and Artificial Intelligence: An Evolving Synergy, Pasadena, CA, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Ferragina</author>
<author>Ugo Scaiella</author>
</authors>
<title>Tagme: on-thefly annotation of short text fragments (by wikipedia entities).</title>
<date>2010</date>
<booktitle>Proceedings of the 19th ACM conference on Information and knowledge management,</booktitle>
<pages>1625--1628</pages>
<editor>In Jimmy Huang, Nick Koudas, Gareth J. F. Jones, Xindong Wu, Kevyn Collins-Thompson, and Aijun An, editors,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="8248" citStr="Ferragina and Scaiella, 2010" startWordPosition="1310" endWordPosition="1313">experimented with two methods: (a) the lexical overlap between the Wikipedia page of the candidate disambiguations and the context of the ambiguous mention, and (b) training a Naive Bayes classiffier for each ambiguous mention, using the hyperlink information found in Wikipedia as ground truth. Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework. Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010). The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007).2 On the other hand, in (Cucerzan, 2007) the disambiguation context is taken to be all plausible disambiguations of the named entities in the text, and title relatedness is based on the overlap in categories and incoming links. Bot</context>
</contexts>
<marker>Ferragina, Scaiella, 2010</marker>
<rawString>Paolo Ferragina and Ugo Scaiella. 2010. Tagme: on-thefly annotation of short text fragments (by wikipedia entities). In Jimmy Huang, Nick Koudas, Gareth J. F. Jones, Xindong Wu, Kevyn Collins-Thompson, and Aijun An, editors, Proceedings of the 19th ACM conference on Information and knowledge management, pages 1625–1628. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Finin</author>
<author>Zareen Syed</author>
<author>James Mayfield</author>
<author>Paul McNamee</author>
<author>Christine Piatko</author>
</authors>
<title>Using Wikitology for Cross-Document Entity Coreference Resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Learning by Reading and Learning</booktitle>
<publisher>AAAI Press,</publisher>
<contexts>
<context position="1576" citStr="Finin et al., 2009" startWordPosition="219" endWordPosition="222">w that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat. 1 Introduction Wikification is the task of identifying and linking expressions in text to their referent Wikipedia pages. Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009). Previous studies on Wikification differ with respect to the corpora they address and the subset of expressions they attempt to link. For example, some studies focus on linking only named entities, whereas others attempt to link all “interesting” expressions, mimicking the link structure found in Wikipedia. Regardless, all Wikification systems are faced with a key Disambiguation to Wikipedia (D2W) task. In the D2W task, we’re given a text along with explicitly identified substrings (called mentions) to disambiguate, and the goal</context>
</contexts>
<marker>Finin, Syed, Mayfield, McNamee, Piatko, 2009</marker>
<rawString>Tim Finin, Zareen Syed, James Mayfield, Paul McNamee, and Christine Piatko. 2009. Using Wikitology for Cross-Document Entity Coreference Resolution. In Proceedings of the AAAI Spring Symposium on Learning by Reading and Learning to Read. AAAI Press, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipediabased explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th international joint conference on Artifical intelligence,</booktitle>
<pages>1606--1611</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="1414" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="198" endWordPosition="201">ormation to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches. We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat. 1 Introduction Wikification is the task of identifying and linking expressions in text to their referent Wikipedia pages. Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009). Previous studies on Wikification differ with respect to the corpora they address and the subset of expressions they attempt to link. For example, some studies focus on linking only named entities, whereas others attempt to link all “interesting” expressions, mimicking the link structure found in Wikipedia. Regardless, all Wikification systems are faced with a key Disam</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007a. Computing semantic relatedness using wikipediabased explicit semantic analysis. In Proceedings of the 20th international joint conference on Artifical intelligence, pages 1606–1611, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Harnessing the expertise of 70,000 human editors: Knowledge-based feature generation for text categorization.</title>
<date>2007</date>
<pages>8--2297</pages>
<editor>J. Mach. Learn. Res.,</editor>
<contexts>
<context position="1414" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="198" endWordPosition="201">ormation to arrive at coherent sets of disambiguations for a given document (which we call “global” approaches), and compare them to more traditional (local) approaches. We show that previous approaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat. 1 Introduction Wikification is the task of identifying and linking expressions in text to their referent Wikipedia pages. Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009). Previous studies on Wikification differ with respect to the corpora they address and the subset of expressions they attempt to link. For example, some studies focus on linking only named entities, whereas others attempt to link all “interesting” expressions, mimicking the link structure found in Wikipedia. Regardless, all Wikification systems are faced with a key Disam</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007b. Harnessing the expertise of 70,000 human editors: Knowledge-based feature generation for text categorization. J. Mach. Learn. Res., 8:2297–2345, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Jun Zhao</author>
</authors>
<title>Named entity disambiguation by leveraging wikipedia semantic knowledge.</title>
<date>2009</date>
<booktitle>In Proceeding of the 18th ACM conference on Information and knowledge management, CIKM ’09,</booktitle>
<pages>215--224</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2961" citStr="Han and Zhao, 2009" startWordPosition="439" endWordPosition="442">/en.wikipedia.org/wiki/Chicago – the Wikipedia page for the city of Chicago, Illinois, and not (for example) the page for the 2002 film of the same name. Local D2W approaches disambiguate each mention in a document separately, utilizing clues such as the textual similarity between the document and each candidate disambiguation’s Wikipedia page. Recent work on D2W has tended to focus on more sophisticated global approaches to the problem, in which all mentions in a document are disambiguated simultaneously to arrive at a coherent set of disambiguations (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009). For example, if a mention of “Michael Jordan” refers to the computer scientist rather than the basketball player, then we would expect a mention of “Monte Carlo” in the same document to refer to the statistical technique rather than the location. Global approaches utilize the Wikipedia link graph to estimate coherence. 1375 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1375–1384, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: Sample Disambiguation to Wikipedia problem with three mentions. The men</context>
<context position="8217" citStr="Han and Zhao, 2009" startWordPosition="1306" endWordPosition="1309">a task (2007). They experimented with two methods: (a) the lexical overlap between the Wikipedia page of the candidate disambiguations and the context of the ambiguous mention, and (b) training a Naive Bayes classiffier for each ambiguous mention, using the hyperlink information found in Wikipedia as ground truth. Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework. Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010). The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007).2 On the other hand, in (Cucerzan, 2007) the disambiguation context is taken to be all plausible disambiguations of the named entities in the text, and title relatedness is based on the overlap in cat</context>
</contexts>
<marker>Han, Zhao, 2009</marker>
<rawString>Xianpei Han and Jun Zhao. 2009. Named entity disambiguation by leveraging wikipedia semantic knowledge. In Proceeding of the 18th ACM conference on Information and knowledge management, CIKM ’09, pages 215–224, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>A probabilistic analysis of the rocchio algorithm with tfidf for text categorization.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Machine Learning, ICML ’97,</booktitle>
<pages>143--151</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="17240" citStr="Joachims, 1997" startWordPosition="2778" endWordPosition="2779">r TF-IDF summaries in Figure 1. The majority of the terms selected in all summaries refer to the general issues related to China, such as “legalism, reform, military, control, etc.”, while a minority of the terms actually allow disambiguation between the candidates. The problem stems from the fact that the TF-IDF summaries are constructed against the entire Wikipedia, and not against the confusion set of disambiguation candidates of m. Therefore, we re-weigh the TF-IDF vectors using the TF-IDF scheme on the disambiguation candidates as a adhoc document collection, similarly to an approach in (Joachims, 1997) for classifying documents. In our scenario, the TF of the a token is the original TF-IDF summary score (a real number), and the IDF term is the sum of all the TF-IDF scores for the token within the set of disambiguation candidates for m. This adds 4 more “reweighted local” features in Table 1. 4.3 Global Features 0 Global approaches require a disambiguation context V and a relatedness measure 0 in Eq. 3. In this section, we describe our method for generating a disambiguation context, and the set of global features 0i(t, t′) forming our relatedness measure. In previous work, Cucerzan defined t</context>
</contexts>
<marker>Joachims, 1997</marker>
<rawString>Thorsten Joachims. 1997. A probabilistic analysis of the rocchio algorithm with tfidf for text categorization. In Proceedings of the Fourteenth International Conference on Machine Learning, ICML ’97, pages 143–151, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sayali Kulkarni</author>
<author>Amit Singh</author>
<author>Ganesh Ramakrishnan</author>
<author>Soumen Chakrabarti</author>
</authors>
<title>Collective annotation of wikipedia entities in web text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’09,</booktitle>
<pages>457--466</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1641" citStr="Kulkarni et al., 2009" startWordPosition="230" endWordPosition="233">mproved, but even then the local disambiguation provides a baseline which is very hard to beat. 1 Introduction Wikification is the task of identifying and linking expressions in text to their referent Wikipedia pages. Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009). Previous studies on Wikification differ with respect to the corpora they address and the subset of expressions they attempt to link. For example, some studies focus on linking only named entities, whereas others attempt to link all “interesting” expressions, mimicking the link structure found in Wikipedia. Regardless, all Wikification systems are faced with a key Disambiguation to Wikipedia (D2W) task. In the D2W task, we’re given a text along with explicitly identified substrings (called mentions) to disambiguate, and the goal is to output the corresponding Wikipedia page, if any, for each </context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti. 2009. Collective annotation of wikipedia entities in web text. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’09, pages 457–466, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="false">
<authors>
<author>James Mayfield</author>
<author>David Alexander</author>
<author>Bonnie Dorr</author>
<author>Jason Eisner</author>
<author>Tamer Elsayed</author>
<author>Tim Finin</author>
<author>Clay Fink</author>
<author>Marjorie Freedman</author>
<author>Nikesh Garera</author>
<author>James Mayfield</author>
<author>Paul McNamee</author>
<author>Saif Mohammad</author>
<author>Douglas Oard</author>
<author>Christine Piatko</author>
<author>Asad Sayeed</author>
<author>Zareen Syed</author>
<author>Ralph Weischede</author>
</authors>
<title>Cross-Document Coreference Resolution: A Key Technology for Learning by Reading.</title>
<date>2009</date>
<booktitle>In Proceedings of the AAAI</booktitle>
<publisher>AAAI Press,</publisher>
<contexts>
<context position="1600" citStr="Mayfield et al., 2009" startWordPosition="223" endWordPosition="226">oaches for global disambiguation can be improved, but even then the local disambiguation provides a baseline which is very hard to beat. 1 Introduction Wikification is the task of identifying and linking expressions in text to their referent Wikipedia pages. Recently, Wikification has been shown to form a valuable component for numerous natural language processing tasks including text classification (Gabrilovich and Markovitch, 2007b; Chang et al., 2008), measuring semantic similarity between texts (Gabrilovich and Markovitch, 2007a), crossdocument co-reference resolution (Finin et al., 2009; Mayfield et al., 2009), and other tasks (Kulkarni et al., 2009). Previous studies on Wikification differ with respect to the corpora they address and the subset of expressions they attempt to link. For example, some studies focus on linking only named entities, whereas others attempt to link all “interesting” expressions, mimicking the link structure found in Wikipedia. Regardless, all Wikification systems are faced with a key Disambiguation to Wikipedia (D2W) task. In the D2W task, we’re given a text along with explicitly identified substrings (called mentions) to disambiguate, and the goal is to output the corres</context>
</contexts>
<marker>Mayfield, Alexander, Dorr, Eisner, Elsayed, Finin, Fink, Freedman, Garera, Mayfield, McNamee, Mohammad, Oard, Piatko, Sayeed, Syed, Weischede, 2009</marker>
<rawString>James Mayfield, David Alexander, Bonnie Dorr, Jason Eisner, Tamer Elsayed, Tim Finin, Clay Fink, Marjorie Freedman, Nikesh Garera, James Mayfield, Paul McNamee, Saif Mohammad, Douglas Oard, Christine Piatko, Asad Sayeed, Zareen Syed, and Ralph Weischede. 2009. Cross-Document Coreference Resolution: A Key Technology for Learning by Reading. In Proceedings of the AAAI 2009 Spring Symposium on Learning by Reading and Learning to Read. AAAI Press, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, CIKM ’07,</booktitle>
<pages>233--242</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="5695" citStr="Mihalcea and Csomai, 2007" startWordPosition="903" endWordPosition="906">ite graph, with mentions forming one partition and Wikipedia titles the other (see Figure 1). We denote the output matching as an N-tuple Γ = (t1, ... , tN) where ti is the output disambiguation for mention mi. 2.1 Local and Global Disambiguation A local D2W approach disambiguates each mention mi separately. Specifically, let 0(mi, tj) be a score function reflecting the likelihood that the candidate title tj E W is the correct disambiguation for mi E M. A local approach solves the following optimization problem: 0(mi, ti) (1) Local D2W approaches, exemplified by (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007), utilize 0 functions that assign higher scores to titles with content similar to that of the input document. We expect, all else being equal, that the correct disambiguations will form a “coherent” set of related concepts. Global approaches define a coherence function 0, and attempt to solve the following disambiguation problem: 0(mi, ti) + 0(Γ)] (2) The global optimization problem in Eq. 2 is NPhard, and approximations are required (Cucerzan, 2007). The common approach is to utilize the Wikipedia link graph to obtain an estimate pairwise relatedness between titles 0(ti, tj) and to efficientl</context>
<context position="7977" citStr="Mihalcea and Csomai, 2007" startWordPosition="1271" endWordPosition="1274">didate disambiguation’s Wikipedia page. However, since each ambiguous mention required a separate SVM model, the experiment was on a very limited scale. Mihalcea and Csomai applied Word Sense Disambiguation methods to the Disambiguation to Wikipedia task (2007). They experimented with two methods: (a) the lexical overlap between the Wikipedia page of the candidate disambiguations and the context of the ambiguous mention, and (b) training a Naive Bayes classiffier for each ambiguous mention, using the hyperlink information found in Wikipedia as ground truth. Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework. Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010). The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Dista</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, CIKM ’07, pages 233–242, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>An effective, low-cost measure of semantic relatedness obtained from wikipedia links.</title>
<date>2008</date>
<booktitle>In In the Wikipedia and AI Workshop ofAAAI.</booktitle>
<contexts>
<context position="2939" citStr="Milne and Witten, 2008" startWordPosition="435" endWordPosition="438">icago&gt;,” we output http://en.wikipedia.org/wiki/Chicago – the Wikipedia page for the city of Chicago, Illinois, and not (for example) the page for the 2002 film of the same name. Local D2W approaches disambiguate each mention in a document separately, utilizing clues such as the textual similarity between the document and each candidate disambiguation’s Wikipedia page. Recent work on D2W has tended to focus on more sophisticated global approaches to the problem, in which all mentions in a document are disambiguated simultaneously to arrive at a coherent set of disambiguations (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009). For example, if a mention of “Michael Jordan” refers to the computer scientist rather than the basketball player, then we would expect a mention of “Monte Carlo” in the same document to refer to the statistical technique rather than the location. Global approaches utilize the Wikipedia link graph to estimate coherence. 1375 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1375–1384, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: Sample Disambiguation to Wikipedia problem with t</context>
<context position="4428" citStr="Milne and Witten, 2008" startWordPosition="680" endWordPosition="683">5, t7) t1 = Taiwan t5 =People&apos;s Republic of China t6 = History of China t7 = Jiangsu t2 = Chinese Taipei t3 =Republic of China t4 = China In this paper, we analyze global and local approaches to the D2W task. Our contributions are as follows: (1) We present a formulation of the D2W task as an optimization problem with local and global variants, and identify the strengths and the weaknesses of each, (2) Using this formulation, we present a new global D2W system, called GLOW. In experiments on existing and novel D2W data sets,1 GLOW is shown to outperform the previous stateof-the-art system of (Milne and Witten, 2008b), (3) We present an error analysis and identify the key remaining challenge: determining when mentions refer to concepts not captured in Wikipedia. 2 Problem Definition and Approach We formalize our Disambiguation to Wikipedia (D2W) task as follows. We are given a document d with a set of mentions M = {m1,... , mN}, and our goal is to produce a mapping from the set of mentions to the set of Wikipedia titles W = {t1, ... , t|W|}. Often, mentions correspond to a concept without a Wikipedia page; we treat this case by adding a special null title to the set W. The D2W task can be visualized as f</context>
<context position="8196" citStr="Milne and Witten, 2008" startWordPosition="1302" endWordPosition="1305">isambiguation to Wikipedia task (2007). They experimented with two methods: (a) the lexical overlap between the Wikipedia page of the candidate disambiguations and the context of the ambiguous mention, and (b) training a Naive Bayes classiffier for each ambiguous mention, using the hyperlink information found in Wikipedia as ground truth. Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework. Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010). The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007).2 On the other hand, in (Cucerzan, 2007) the disambiguation context is taken to be all plausible disambiguations of the named entities in the text, and title relatedness is based </context>
<context position="18598" citStr="Milne and Witten, 2008" startWordPosition="3004" endWordPosition="3007">disadvantage of this approach is that irrelevant titles are inevitably added to the disambiguation context, creating noise. Milne and Witten, on the other hand, use a set of unambiguous mentions (2008b). This approach utilizes only a fraction of the available mentions for context, and relies on the presence of unambiguous mentions with high disambiguation utility. In GLOW, we utilize a simple and efficient alternative approach: we first train a local disambiguation system, and then use the predictions of that system as the disambiguation context. The advantage of this approach is that unlike (Milne and Witten, 2008b) we use all the available mentions in the document, and unlike (Cucerzan, 2007) we reduce the amount of irrelevant titles in the disambiguation context by taking only the top-ranked disambiguation per mention. Our global features are refinements of previously proposed semantic relatedness measures between Wikipedia titles. We are aware of two previous methods for estimating the relatedness between two Wikipedia concepts: (Strube and Ponzetto, 2006), which uses category overlap, and (Milne and Witten, 2008a), which uses the incoming link structure. Previous work experimented with two relatedn</context>
<context position="22908" citStr="Milne and Witten, 2008" startWordPosition="3701" endWordPosition="3704">ons and corresponding distinct titles by data set. Listed are (number of mentions)/(number of distinct titles) for each data set, for each of three mention types. Gold mentions include all disambiguated mentions in the data set. Identified mentions are gold mentions whose correct disambiguations exist in GLOW’s author-title index. Solvable mentions are identified mentions whose correct disambiguations are among the candidates selected by GLOW (see Table 3). 5 Data sets and Evaluation Methodology We evaluate GLOW on four data sets, of which two are from previous work. The first data set, from (Milne and Witten, 2008b), is a subset of the AQUAINT corpus of newswire text that is annotated to mimic the hyperlink structure in Wikipedia. That is, only the first mentions of “important” titles were hyperlinked. Titles deemed uninteresting and redundant mentions of the same title are not linked. The second data set, from (Cucerzan, 2007), is taken from MSNBC news and focuses on disambiguating named entities after running NER and co-reference resolution systems on newsire text. In this case, all mentions of all the detected named entities are linked. We also constructed two additional data sets. The first is a su</context>
<context position="26114" citStr="Milne and Witten, 2008" startWordPosition="4221" endWordPosition="4224">uation that appears in the candidate set. It is equal to the fraction of these mentions for which the ranker returns the correct disambiguation. Thus, a perfect ranker should achieve a ranker accuracy of 1.0, irrespective of limitations of the candidate generator. Linker accuracy is defined as the fraction of all mentions for which the linker outputs the correct disambiguation (note that, when the title produced by the ranker is incorrect, this penalizes linker accuracy). Lastly, we evaluate our whole system against other baselines using a previously-employed “bag of titles” (BOT) evaluation (Milne and Witten, 2008b). In BOT, we compare the set of titles output for a document with the gold set of titles for that document (ignoring duplicates), and utilize standard precision, recall, and F1 measures. In BOT, the set of titles is collected from the mentions hyperlinked in the gold annotation. That is, if the gold annotation is { (China, People’s Republic of China), (Taiwan, Taiwan), (Jiangsu, Jiangsu)} 4The data set contains votes on how important the mentions are. We believe that the results in (Milne and Witten, 2008b) were reported on mentions which the majority of annotators considered important. In c</context>
<context position="27817" citStr="Milne and Witten, 2008" startWordPosition="4507" endWordPosition="4510"> { (China, People’s Republic of China), (China, History of China), (Taiwan, null), (Jiangsu, Jiangsu), (republic, Government)} , then the BOT for the gold annotation is: {People’s Republic of China, Taiwan, Jiangsu} , and the BOT for the predicted annotation is: {People’s Republic of China, History of China, Jiangsu} . The title Government is not included in the BOT for predicted annotation, because its associate mention republic did not appear as a mention in the gold annotation. Both the precision and the recall of the above prediction is 0.66. We note that in the BOT evaluation, following (Milne and Witten, 2008b) we consider all the titles within a document, even if some the titles were due to mentions we failed to identify.5 6 Experiments and Results In this section, we evaluate and analyze GLOW’s performance on the D2W task. We begin by evaluating the mention detection component (Step 1 of the algorithm). The second column of Table 2 shows how many of the “non-null” mentions and corresponding titles we could successfully identify (e.g. out of 747 mentions in the MSNBC data set, only 530 appeared in our anchor-title index). Missing entities were primarily due to especially rare surface forms, or so</context>
<context position="31788" citStr="Milne and Witten, 2008" startWordPosition="5164" endWordPosition="5167">at when linking all mentions, the linking accuracy is X, while when applying the trained linker, the performance is Y . The local approaches are better suited for linking than the global approaches. The linking accuracy is very sensitive to domain changes. System ACE MSNBC AQUAINT Wiki Baseline: P(t|m) 69.52 72.83 82.67 81.77 GLOW Local 75.60 74.39 84.52 90.20 GLOW Global 74.73 74.58 84.37 86.62 GLOW 77.25 74.88 83.94 90.54 M&amp;W 72.76 68.49 83.61 80.32 Table 6: End systems performance - BOT F1. The performance of the full system (GLOW) is similar to that of the local version. GLOW outperforms (Milne and Witten, 2008b) on all data sets. ties as in (Milne and Witten, 2008b).6 Combining the local and the global approaches typically results in minor improvements. While the global approaches are most effective for ranking, the linking problem has different characteristics as shown in Table 5. We can see that the global features are not helpful in general for predicting whether the top-ranked disambiguation is indeed the correct one. Further, although the trained linker improves accuracy in some cases, the gains are marginal—and the linker decreases performance on some data sets. One explanation for the decrea</context>
<context position="35157" citStr="Milne and Witten, 2008" startWordPosition="5698" endWordPosition="5701">ponding Lastly, in Table 6 we compare the end system Wikipedia pages. Our initial experiments suggest BOT F1 performance. The local approach proves that accounting for this bias requires more than sima very competitive baseline which is hard to beat. ply training a D2W system on a moderate numCombining the global and the local approach leads ber of examples from non-Wikipedia text. Applyto marginal improvements. The full GLOW sys- ing distinct semi-supervised and active learning aptem outperforms the existing state-of-the-art system proaches to the task is a primary area of future work. from (Milne and Witten, 2008b), denoted as M&amp;W, Acknowledgments on all data sets. We also compared our system with This research supported by the Army Research the recent TAGME Wikification system (Ferragina Laboratory (ARL) under agreement W911NF-09- and Scaiella, 2010). However, TAGME is designed 2-0053 and by the Defense Advanced Research for a different setting than ours: extremely short Projects Agency (DARPA) Machine Reading Protexts, like Twitter posts. The TAGME RESTful API gram under Air Force Research Laboratory (AFRL) was unable to process some of our documents at prime contract no. FA8750-09-C-0181. The third</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. 2008a. An effective, low-cost measure of semantic relatedness obtained from wikipedia links. In In the Wikipedia and AI Workshop ofAAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM conference on Information and knowledge management, CIKM ’08,</booktitle>
<pages>509--518</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2939" citStr="Milne and Witten, 2008" startWordPosition="435" endWordPosition="438">icago&gt;,” we output http://en.wikipedia.org/wiki/Chicago – the Wikipedia page for the city of Chicago, Illinois, and not (for example) the page for the 2002 film of the same name. Local D2W approaches disambiguate each mention in a document separately, utilizing clues such as the textual similarity between the document and each candidate disambiguation’s Wikipedia page. Recent work on D2W has tended to focus on more sophisticated global approaches to the problem, in which all mentions in a document are disambiguated simultaneously to arrive at a coherent set of disambiguations (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009). For example, if a mention of “Michael Jordan” refers to the computer scientist rather than the basketball player, then we would expect a mention of “Monte Carlo” in the same document to refer to the statistical technique rather than the location. Global approaches utilize the Wikipedia link graph to estimate coherence. 1375 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1375–1384, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics Figure 1: Sample Disambiguation to Wikipedia problem with t</context>
<context position="4428" citStr="Milne and Witten, 2008" startWordPosition="680" endWordPosition="683">5, t7) t1 = Taiwan t5 =People&apos;s Republic of China t6 = History of China t7 = Jiangsu t2 = Chinese Taipei t3 =Republic of China t4 = China In this paper, we analyze global and local approaches to the D2W task. Our contributions are as follows: (1) We present a formulation of the D2W task as an optimization problem with local and global variants, and identify the strengths and the weaknesses of each, (2) Using this formulation, we present a new global D2W system, called GLOW. In experiments on existing and novel D2W data sets,1 GLOW is shown to outperform the previous stateof-the-art system of (Milne and Witten, 2008b), (3) We present an error analysis and identify the key remaining challenge: determining when mentions refer to concepts not captured in Wikipedia. 2 Problem Definition and Approach We formalize our Disambiguation to Wikipedia (D2W) task as follows. We are given a document d with a set of mentions M = {m1,... , mN}, and our goal is to produce a mapping from the set of mentions to the set of Wikipedia titles W = {t1, ... , t|W|}. Often, mentions correspond to a concept without a Wikipedia page; we treat this case by adding a special null title to the set W. The D2W task can be visualized as f</context>
<context position="8196" citStr="Milne and Witten, 2008" startWordPosition="1302" endWordPosition="1305">isambiguation to Wikipedia task (2007). They experimented with two methods: (a) the lexical overlap between the Wikipedia page of the candidate disambiguations and the context of the ambiguous mention, and (b) training a Naive Bayes classiffier for each ambiguous mention, using the hyperlink information found in Wikipedia as ground truth. Both (Bunescu and Pasca, 2006) and (Mihalcea and Csomai, 2007) fall into the local framework. Subsequent work on Wikification has stressed that assigned disambiguations for the same document should be related, introducing the global approach (Cucerzan, 2007; Milne and Witten, 2008b; Han and Zhao, 2009; Ferragina and Scaiella, 2010). The two critical components of a global approach are the semantic relatedness function ψ between two titles, and the disambiguation context V. In (Milne and Witten, 2008b), the semantic context is defined to be a set of “unambiguous surface forms” in the text, and the title relatedness ψ is computed as Normalized Google Distance (NGD) (Cilibrasi and Vitanyi, 2007).2 On the other hand, in (Cucerzan, 2007) the disambiguation context is taken to be all plausible disambiguations of the named entities in the text, and title relatedness is based </context>
<context position="18598" citStr="Milne and Witten, 2008" startWordPosition="3004" endWordPosition="3007">disadvantage of this approach is that irrelevant titles are inevitably added to the disambiguation context, creating noise. Milne and Witten, on the other hand, use a set of unambiguous mentions (2008b). This approach utilizes only a fraction of the available mentions for context, and relies on the presence of unambiguous mentions with high disambiguation utility. In GLOW, we utilize a simple and efficient alternative approach: we first train a local disambiguation system, and then use the predictions of that system as the disambiguation context. The advantage of this approach is that unlike (Milne and Witten, 2008b) we use all the available mentions in the document, and unlike (Cucerzan, 2007) we reduce the amount of irrelevant titles in the disambiguation context by taking only the top-ranked disambiguation per mention. Our global features are refinements of previously proposed semantic relatedness measures between Wikipedia titles. We are aware of two previous methods for estimating the relatedness between two Wikipedia concepts: (Strube and Ponzetto, 2006), which uses category overlap, and (Milne and Witten, 2008a), which uses the incoming link structure. Previous work experimented with two relatedn</context>
<context position="22908" citStr="Milne and Witten, 2008" startWordPosition="3701" endWordPosition="3704">ons and corresponding distinct titles by data set. Listed are (number of mentions)/(number of distinct titles) for each data set, for each of three mention types. Gold mentions include all disambiguated mentions in the data set. Identified mentions are gold mentions whose correct disambiguations exist in GLOW’s author-title index. Solvable mentions are identified mentions whose correct disambiguations are among the candidates selected by GLOW (see Table 3). 5 Data sets and Evaluation Methodology We evaluate GLOW on four data sets, of which two are from previous work. The first data set, from (Milne and Witten, 2008b), is a subset of the AQUAINT corpus of newswire text that is annotated to mimic the hyperlink structure in Wikipedia. That is, only the first mentions of “important” titles were hyperlinked. Titles deemed uninteresting and redundant mentions of the same title are not linked. The second data set, from (Cucerzan, 2007), is taken from MSNBC news and focuses on disambiguating named entities after running NER and co-reference resolution systems on newsire text. In this case, all mentions of all the detected named entities are linked. We also constructed two additional data sets. The first is a su</context>
<context position="26114" citStr="Milne and Witten, 2008" startWordPosition="4221" endWordPosition="4224">uation that appears in the candidate set. It is equal to the fraction of these mentions for which the ranker returns the correct disambiguation. Thus, a perfect ranker should achieve a ranker accuracy of 1.0, irrespective of limitations of the candidate generator. Linker accuracy is defined as the fraction of all mentions for which the linker outputs the correct disambiguation (note that, when the title produced by the ranker is incorrect, this penalizes linker accuracy). Lastly, we evaluate our whole system against other baselines using a previously-employed “bag of titles” (BOT) evaluation (Milne and Witten, 2008b). In BOT, we compare the set of titles output for a document with the gold set of titles for that document (ignoring duplicates), and utilize standard precision, recall, and F1 measures. In BOT, the set of titles is collected from the mentions hyperlinked in the gold annotation. That is, if the gold annotation is { (China, People’s Republic of China), (Taiwan, Taiwan), (Jiangsu, Jiangsu)} 4The data set contains votes on how important the mentions are. We believe that the results in (Milne and Witten, 2008b) were reported on mentions which the majority of annotators considered important. In c</context>
<context position="27817" citStr="Milne and Witten, 2008" startWordPosition="4507" endWordPosition="4510"> { (China, People’s Republic of China), (China, History of China), (Taiwan, null), (Jiangsu, Jiangsu), (republic, Government)} , then the BOT for the gold annotation is: {People’s Republic of China, Taiwan, Jiangsu} , and the BOT for the predicted annotation is: {People’s Republic of China, History of China, Jiangsu} . The title Government is not included in the BOT for predicted annotation, because its associate mention republic did not appear as a mention in the gold annotation. Both the precision and the recall of the above prediction is 0.66. We note that in the BOT evaluation, following (Milne and Witten, 2008b) we consider all the titles within a document, even if some the titles were due to mentions we failed to identify.5 6 Experiments and Results In this section, we evaluate and analyze GLOW’s performance on the D2W task. We begin by evaluating the mention detection component (Step 1 of the algorithm). The second column of Table 2 shows how many of the “non-null” mentions and corresponding titles we could successfully identify (e.g. out of 747 mentions in the MSNBC data set, only 530 appeared in our anchor-title index). Missing entities were primarily due to especially rare surface forms, or so</context>
<context position="31788" citStr="Milne and Witten, 2008" startWordPosition="5164" endWordPosition="5167">at when linking all mentions, the linking accuracy is X, while when applying the trained linker, the performance is Y . The local approaches are better suited for linking than the global approaches. The linking accuracy is very sensitive to domain changes. System ACE MSNBC AQUAINT Wiki Baseline: P(t|m) 69.52 72.83 82.67 81.77 GLOW Local 75.60 74.39 84.52 90.20 GLOW Global 74.73 74.58 84.37 86.62 GLOW 77.25 74.88 83.94 90.54 M&amp;W 72.76 68.49 83.61 80.32 Table 6: End systems performance - BOT F1. The performance of the full system (GLOW) is similar to that of the local version. GLOW outperforms (Milne and Witten, 2008b) on all data sets. ties as in (Milne and Witten, 2008b).6 Combining the local and the global approaches typically results in minor improvements. While the global approaches are most effective for ranking, the linking problem has different characteristics as shown in Table 5. We can see that the global features are not helpful in general for predicting whether the top-ranked disambiguation is indeed the correct one. Further, although the trained linker improves accuracy in some cases, the gains are marginal—and the linker decreases performance on some data sets. One explanation for the decrea</context>
<context position="35157" citStr="Milne and Witten, 2008" startWordPosition="5698" endWordPosition="5701">ponding Lastly, in Table 6 we compare the end system Wikipedia pages. Our initial experiments suggest BOT F1 performance. The local approach proves that accounting for this bias requires more than sima very competitive baseline which is hard to beat. ply training a D2W system on a moderate numCombining the global and the local approach leads ber of examples from non-Wikipedia text. Applyto marginal improvements. The full GLOW sys- ing distinct semi-supervised and active learning aptem outperforms the existing state-of-the-art system proaches to the task is a primary area of future work. from (Milne and Witten, 2008b), denoted as M&amp;W, Acknowledgments on all data sets. We also compared our system with This research supported by the Army Research the recent TAGME Wikification system (Ferragina Laboratory (ARL) under agreement W911NF-09- and Scaiella, 2010). However, TAGME is designed 2-0053 and by the Defense Advanced Research for a different setting than ours: extremely short Projects Agency (DARPA) Machine Reading Protexts, like Twitter posts. The TAGME RESTful API gram under Air Force Research Laboratory (AFRL) was unable to process some of our documents at prime contract no. FA8750-09-C-0181. The third</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. 2008b. Learning to link with wikipedia. In Proceedings of the 17th ACM conference on Information and knowledge management, CIKM ’08, pages 509–518, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Wikirelate! computing semantic relatedness using wikipedia.</title>
<date>2006</date>
<booktitle>In proceedings of the 21st national conference on Artificial intelligence -</booktitle>
<volume>2</volume>
<pages>1419--1424</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="19052" citStr="Strube and Ponzetto, 2006" startWordPosition="3070" endWordPosition="3073">ocal disambiguation system, and then use the predictions of that system as the disambiguation context. The advantage of this approach is that unlike (Milne and Witten, 2008b) we use all the available mentions in the document, and unlike (Cucerzan, 2007) we reduce the amount of irrelevant titles in the disambiguation context by taking only the top-ranked disambiguation per mention. Our global features are refinements of previously proposed semantic relatedness measures between Wikipedia titles. We are aware of two previous methods for estimating the relatedness between two Wikipedia concepts: (Strube and Ponzetto, 2006), which uses category overlap, and (Milne and Witten, 2008a), which uses the incoming link structure. Previous work experimented with two relatedness measures: NGD, and Specificity-weighted Cosine Similarity. Consistent with previous work, we found NGD to be the better-performing of the two. Thus we use only NGD along with a well-known Pontwise Mutual Information (PMI) relatedness measure. Given a Wikipedia title collection W, titles t1 and t2 with a set of incoming links L1, and L2 respectively, PMI and NGD are defined as follows: 1VGD(L1,L2)= Log(|W|) − Log(Min(|L1|,|L2|)) PMI(L1, L2) = |L1 </context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Michael Strube and Simone Paolo Ponzetto. 2006. Wikirelate! computing semantic relatedness using wikipedia. In proceedings of the 21st national conference on Artificial intelligence - Volume 2, pages 1419– 1424. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiping Zhou</author>
<author>Lan Nie</author>
<author>Omid Rouhani-Kalleh</author>
<author>Flavian Vasile</author>
<author>Scott Gaffney</author>
</authors>
<title>Resolving surface forms to wikipedia topics.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>1335--1343</pages>
<location>Beijing, China,</location>
<contexts>
<context position="28569" citStr="Zhou et al., 2010" startWordPosition="4633" endWordPosition="4636">d Results In this section, we evaluate and analyze GLOW’s performance on the D2W task. We begin by evaluating the mention detection component (Step 1 of the algorithm). The second column of Table 2 shows how many of the “non-null” mentions and corresponding titles we could successfully identify (e.g. out of 747 mentions in the MSNBC data set, only 530 appeared in our anchor-title index). Missing entities were primarily due to especially rare surface forms, or sometimes due to idiosyncratic capitalization in the corpus. Improving the number of identified mentions substantially is non-trivial; (Zhou et al., 2010) managed to successfully identify only 59 more entities than we do in the MSNBC data set, using a much more powerful detection method based on search engine query logs. We generate disambiguation candidates for a 5We evaluate the mention identification stage in Section 6. 1381 Features ACE Data sets Wiki MSNBC AQUAINT P(t|m) 94.05 81.91 93.19 85.88 P(t|m)+Local Naive 95.67 84.04 94.38 92.76 Reweighted 96.21 85.10 95.57 93.59 All above 95.67 84.68 95.40 93.59 P(t|m)+Global NER 96.21 84.04 94.04 89.56 Unambiguous 94.59 84.46 95.40 89.67 Predictions 96.75 88.51 95.91 89.79 P(t|m)+Local+Global All</context>
</contexts>
<marker>Zhou, Nie, Rouhani-Kalleh, Vasile, Gaffney, 2010</marker>
<rawString>Yiping Zhou, Lan Nie, Omid Rouhani-Kalleh, Flavian Vasile, and Scott Gaffney. 2010. Resolving surface forms to wikipedia topics. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1335–1343, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>