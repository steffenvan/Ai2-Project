<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.972086">
Developing a hybrid NP parser
</title>
<author confidence="0.964606">
Atro Voutilainen
</author>
<affiliation confidence="0.864147666666667">
Department of General Linguistics
P.O. Box 4
FIN-00014 University of Helsinki
</affiliation>
<address confidence="0.591399">
Finland
</address>
<email confidence="0.805988">
avoutilaling.helsinki.fi
</email>
<sectionHeader confidence="0.997272" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999854375">
We describe the use of energy function op-
timisation in very shallow syntactic pars-
ing. The approach can use linguistic
rules and corpus-based statistics, so the
strengths of both linguistic and statisti-
cal approaches to NLP can be combined
in a single framework. The rules are con-
textual constraints for resolving syntactic
ambiguities expressed as alternative tags,
and the statistical language model consists
of corpus-based n-grams of syntactic tags.
The success of the hybrid syntactic dis-
ambiguator is evaluated against a held-out
benchmark corpus. Also the contributions
of the linguistic and statistical language
models to the hybrid model are estimated.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999931210526316">
The language models used by natural language an-
alyzers are traditionally based on two approaches.
In the linguistic approach, the model is based on
hand-crafted rules derived from the linguist&apos;s gen-
eral and/or corpus-based knowledge about the ob-
ject language. In the data-driven approach, the
model is automatically generated from annotated
text corpora, and the model can be represented e.g.
as n-grams (Garside et al., 1987), local rules (Hindle,
1989) or neural nets (Schmid, 1994).
Most hybrid approaches combine statistical infor-
mation with automatically extracted rule-based in-
formation (Brill, 1995; Daelemans et al., 1996). Rel-
atively little attention has been paid to models where
the statistical approach is combined with a truly lin-
guistic model (i.e. one generated by a linguist). This
paper reports one such approach: syntactic rules
written by a linguist are combined with statistical
information using the relaxation labelling algorithm.
</bodyText>
<figure confidence="0.817350166666667">
Lluis Padre)
Dept. Llenguatges i Sistemes Informatics
Universitat Politecnica de Catalunya
C/ Gran Capita s/n. 08034 Barcelona
Catalonia
padroOlsi.upc.es
</figure>
<bodyText confidence="0.999167827586207">
Our application is very shallow parsing: identifi-
cation of verbs, premodifiers, nominal and adverbial
heads, and certain kinds of postmodifiers. We call
this parser a noun phrase parser.
The input is English text morphologically tagged
with a rule-based tagger called EngCG (Voutilainen
et al., 1992; Karlsson et al., 1995). Syntactic word-
tags are added as alternatives (e.g. each adjective
gets a premodifier tag, postmodifier tag and a nomi-
nal head tag as alternatives). The system should re-
move contextually illegitimate tags and leave intact
each word&apos;s most appropriate tag. In other words,
the syntactic language model is applied by a disam-
biguator.
The parser has a recall of 100% if all words retain
the correct morphological and syntactic reading; the
system&apos;s precision is 100% if the output contains no
illegitimate morphological or syntactic readings. In
practice, some correct readings are discarded, and
some ambiguities remain unresolved (i.e. some words
retain two or more alternative analyses).
The system can use linguistic rules and corpus-
based statistics. Notable about the system is that
minimal human effort was needed for creating its
language models (the linguistic consisting of syn-
tactic disambiguation rules based on the Constraint
Grammar framework (Karlsson, 1990; Karlsson et
al., 1995); the corpus-based consisting of bigrams
and trigrams):
</bodyText>
<listItem confidence="0.977221666666666">
• Only one day was spent on writing the 107 syn-
tactic disambiguation rules used by the linguis-
tic parser.
• No human annotators were needed for annotat-
ing the training corpus (218,000 words of jour-
nalese) used by the data-driven learning mod-
ules of this system: the training corpus was an-
notated by (i) tagging it with the EngCG mor-
phological tagger, (ii) making the tagged text
</listItem>
<page confidence="0.996051">
80
</page>
<bodyText confidence="0.999750413793104">
syntactically ambiguous by adding the alterna-
tive syntactic tags to the words, and (iii) re-
solving most of these syntactic ambiguities by
applying the parser with the 107 disambigua-
tion rules.
the system is then presented: first the preparation
of the benchmark corpus is described, then the re-
sults of the tests are given. The paper ends with
some concluding remarks.
The system was tested against a fresh sample of five
texts (6,500 words). The system&apos;s recall and pre-
cision was measured by comparing its output to a
manually disambiguated version of the text. To in-
crease the objectivity of the evaluation, system out-
puts and the benchmark corpus are made publicly
accessible (see Section 6).
Also the relative contributions of the linguistic
and statistical components are evaluated. The lin-
guistic rules seldom discard the correct tag, i.e. they
have a very high recall, but their problem is remain-
ing ambiguity. The problems of the statistical com-
ponents are the opposite: their recall is considerably
lower, but more (if not all) ambiguities are resolved.
When these components are used in a balanced way,
the system&apos;s overall recall is 97.2% — that is, 97.2%
of all words get the correct analysis — and its preci-
sion is 96.1% — that is, of the readings returned by
the system, 96.1% are correct.
The system architecture is presented in Figure 1.
</bodyText>
<figureCaption confidence="0.998796">
Figure 1: Parser architecture.
</figureCaption>
<bodyText confidence="0.999944125">
The structure of the paper is the following. First,
we describe our general framework, the relaxation
labelling algorithm. Then we proceed to the appli-
cation by outlining the grammatical representation
used in our shallow syntax. After this, the disam-
biguation rules and their development are described.
Next in turn is a description of how the data-driven
language model was generated. The evaluation of
</bodyText>
<sectionHeader confidence="0.9692685" genericHeader="introduction">
2 The Relaxation Labelling
Algorithm
</sectionHeader>
<bodyText confidence="0.998556043478261">
Since we are dealing with a set of constraints and
want to find a solution which optimally satisfies
them all, we can use a standard Constraint Satis-
faction algorithm to solve that problem.
Constraint Satisfaction Problems are naturally
modelled as Consistent Labeling Problems (Larrosa
and Meseguer, 1995). An algorithm that solves
CLPs is Relaxation Labelling.
It has been applied to part-of-speech tagging
(Padre), 1996) showing that it can yield as good re-
sults as a HMM tagger when using the same in-
formation. In addition, it can deal with any kind
of constraints, thus the model can be improved
by adding any other constraints available, either
statistics, hand-written or automatically extracted
(Marquez and Rodriguez, 1995; Samuelsson et al.,
1996).
Relaxation labelling is a generic name for a family
of iterative algorithms which perform function opti-
misation, based on local information. See (Torras,
1989) for a summary.
Given a set of variables, a set of possible labels for
each variable, and a set of compatibility constraints
between those labels, the algorithm finds a combina-
tion of weights for the labels that maximises &amp;quot;global
consistency&amp;quot; (see below).
Let V = {vi, v2, , vn} be a set of variables.
Let ti = , be the set of possible
labels for variable vi.
Let CS be a set of constraints between the labels
of the variables. Each constraint C E CS states a
&amp;quot;compatibility value&amp;quot; Cr for a combination of pairs
variable—label. Any number of variables may be in-
volved in a constraint.
The aim of the algorithm is to find a weighted
labellingl such that &amp;quot;global consistency&amp;quot; is max-
imised. Maximising .&amp;quot;global consistency&amp;quot; is .defined
as maximising Ei pti x Sij , Vv, where psj is the
weight for label j in variable vi and Ski the support
received by the same combination. The support for
the pair variable—label expresses how compatible that
pair is with the labels of neighbouring variables, ac-
cording to the constraint set.
&apos;A weighted labelling is a weight assignment for each
label of each variable such that the weights for the labels
of the same variable add up to one.
</bodyText>
<figure confidence="0.995941222222222">
Ambiguous
test corpus
Disambiguated
test corpus
Linguistic
parser
Partially
disambiguated
training corpus
a.
Statistics
collector
Linguistic Statistical
language language
model model
Hybrid language model
Ambiguous
training corpus
</figure>
<page confidence="0.991247">
81
</page>
<bodyText confidence="0.999642">
The support is defined as the sum of the influence
of every constraint on a label.
</bodyText>
<equation confidence="0.895957">
si, =E Inf(r)
rERii
</equation>
<bodyText confidence="0.985009833333333">
where:
R.ij is the set of constraints on label j for variable
i, i.e. the constraints formed by any combination of
variable—label pairs that includes the pair (v4, t&apos;j).
Inf(r) = C,. x p&apos; (m) x x prkdd(m), is the prod-
uct of the current weights2 for .the labels appearing
in the constraint except (v, t) (representing how
applicable the constraint is in the current context)
multiplied by Cr which is the constraint compatibil-
ity value (stating how compatible the pair is with the
context).
Briefly, what the algorithm does is:
</bodyText>
<listItem confidence="0.997421166666667">
1. Start with a random weight assignment.
2. Compute the support value for each label of
each variable. (How compatible it is with the
current weights for the labels of the other vari-
ables.)
3. Increase the weights of the labels more compat-
</listItem>
<bodyText confidence="0.59515325">
ible with the context (support greater than 0)
and decrease those of the less compatible labels
(support less than 0)3, using the updating func-
tion:
</bodyText>
<equation confidence="0.998460666666667">
Pij(M 1) = 4P.ii(m) x (1+ Sii)
EPt(m) x +sik)
k=1
</equation>
<bodyText confidence="0.960135">
where — 1 &lt; Sii &lt; +1
</bodyText>
<listItem confidence="0.5670475">
4. If a stopping/convergence criterion4 is satisfied,
stop, otherwise go to to step 2.
</listItem>
<sectionHeader confidence="0.9714" genericHeader="method">
3 Grammatical representation
</sectionHeader>
<bodyText confidence="0.8358602">
The input of our parser is morphologically analyzed
and disambiguated text enriched with alternative
syntactic tags, e.g.
&amp;quot;&lt;others&gt;&amp;quot;
&amp;quot;other&amp;quot; PRON NOM PL C&gt;N CNH
</bodyText>
<footnote confidence="0.955946285714286">
2p(m) is the weight assigned to label k for variable
r at time m.
3Negative values for support indicate incompatibility.
&apos;The usual criterion is to stop when there are no more
changes, although more sophisticated heuristic proce-
dures are also used to stop relaxation processes (Eklundh
and Rosenfeld, 1978; Richards et al. , 1981).
</footnote>
<figure confidence="0.964303307692308">
&amp;quot;&lt;moved&gt;&amp;quot;
&amp;quot;move&amp;quot; &lt;SV&gt; &lt;SVO&gt; V PAST VFIN CV
&amp;quot;&lt;away&gt;&amp;quot;
&amp;quot;away&amp;quot; ADV ADVL C&gt;A CAH
&amp;quot;&lt;from&gt;&amp;quot;
&amp;quot;from&amp;quot; PREP °DUMMY
&amp;quot;&lt;traditional&gt;&amp;quot;
&amp;quot;traditional&amp;quot; A ABS 0&gt;N 0N&lt; CNH
&amp;quot;&lt;jazz&gt;&amp;quot;
&amp;quot;jazz&amp;quot; &lt;-Indef&gt; N NOM SG 0&gt;N CNH
&amp;quot;&lt;practice&gt;&amp;quot;
&amp;quot;practice&amp;quot; N NOM SG 0&gt;N ONE
&amp;quot;practice&amp;quot; &lt;SVO&gt; V PRES -SG3 VFIN CV
</figure>
<bodyText confidence="0.999696235294118">
Every indented line represents a morphological
reading; the sample shows that some morphological
ambiguities are not resolved by the rule-based mor-
phological disambiguator, known as the EngCG tag-
ger (Voutilainen et al., 1992; Karlsson et al., 1995).
Our syntactic tags start with the &amp;quot;@&amp;quot; sign. A
word is syntactically ambiguous if it has more than
one syntactic tags (e.g. practice above has three al-
ternative syntactic tags). Syntactic tags are added
to the morphological analysis with a simple lookup
module. The syntactic parser&apos;s main task is dis-
ambiguating (rather than adding new information
to the input sentence): contextually illegitimate al-
ternatives should be discarded, while legitimate tags
should be retained (note that also morphological am-
biguities may be resolved as a side effect).
Next we describe the syntactic tags:
</bodyText>
<listItem confidence="0.999545333333333">
• @&gt;N represents premodifiers and determiners.
• ©NG represents a restricted range of postmod-
ifiers and the determiner &amp;quot;enough&amp;quot; following its
nominal head.
• @NH represents nominal heads (nouns, adjec-
tives, pronouns, numerals, ING-forms and non-
finite ED-forms).
• @&gt;A represents those adverbs that premodify
(intensify) adjectives (including adjectival ING-
forms and non-finite ED-forms), adverbs and
various kinds of quantifiers (certain determin-
ers, pronouns and numerals).
• ©AH represents adverbs that function as head
of an adverbial phrase.
• @A&lt; represents the postmodifying adverb
&amp;quot;enough&amp;quot;.
• @V represents verbs and auxiliaries (incl. the
infinitive marker &amp;quot;to&amp;quot;).
</listItem>
<page confidence="0.827049">
82
</page>
<listItem confidence="0.990802285714286">
• @&gt;CC represents words introducing a coordi-
nation (&amp;quot;either&amp;quot;, &amp;quot;neither&amp;quot;, &amp;quot;both&amp;quot;).
• ©CC represents coordinating conjunctions.
• ©CS represents subordinating conjunctions.
• @DUMMY represents all prepositions, i.e. the
parser does not address the attachment of
prepositional phrases.
</listItem>
<sectionHeader confidence="0.933206" genericHeader="method">
4 Syntactic rules
</sectionHeader>
<subsectionHeader confidence="0.990552">
4.1 Rule formalism
</subsectionHeader>
<bodyText confidence="0.999918375">
The rules follow the Constraint Grammar formal-
ism, and they were applied using the recent parser-
compiler CG-2 (Tapanainen, 1996). The parser
reads a sentence at a time and discards those
ambiguity-forming readings that are disallowed by
a constraint.
Next we describe some basic features of the rule
formalism. The rule
</bodyText>
<equation confidence="0.9991515">
REMOVE (0&gt;N)
(*1C &lt;&lt;&lt; OR (0V) OR (CCS) BARRIER (CNH));
</equation>
<bodyText confidence="0.9956845">
removes the premodifier tag @&gt;N from an ambigu-
ous reading if somewhere to the right (*1) there is
an unambiguous (C) occurrence of a member of the
set &lt;&lt;&lt; (sentence boundary symbols) or the verb
tag @V or the subordinating conjunction tag ©CS,
and there are no intervening tags for nominal heads
(©NH).
This is a partial rule about coordination:
</bodyText>
<equation confidence="0.9970735">
REMOVE (0&gt;N)
(NOT 0 (DET) OR (NUM) OR (A))
(1C (CC))
(2C (DET)) ;
</equation>
<bodyText confidence="0.9984255">
It removes the premodifier tag if all three context-
conditions are satisfied:
</bodyText>
<listItem confidence="0.970004333333333">
• the word to be disambiguated (0) is not a de-
terminer, numeral or adjective,
• the first word to the right (1) is an unambiguous
coordinating conjunction, and
• the second word to the right is an unambiguous
determiner.
</listItem>
<bodyText confidence="0.999501916666667">
In addition to REMOVing, also SELECTing a read-
ing is possible: when all context-conditions are sat-
isfied, all readings but the one the rule was expressly
about are discarded.
The rules can refer to words and tags directly or
by means of predefined sets. They can refer not only
to any fixed context positions; also reference to con-
textual patterns is possible. The rules never discard
a last reading, so every word retains at least one
analysis. On the other hand, an ambiguity remains
unresolved if there are no rules for that particular
type of ambiguity.
</bodyText>
<subsectionHeader confidence="0.837342">
4.2 Grammar development
</subsectionHeader>
<bodyText confidence="0.993016666666667">
A day was spent on writing 107 constraints; about
15,000 words of the parser&apos;s output were proofread
during the process. The routine was the following:
</bodyText>
<listItem confidence="0.885383375">
1. The current grammar (containing e.g. 2 rules)
is applied to the ambiguous input in a &apos;trace&apos;
mode in which the parser also indicates, which
rule discarded which analysis,
2. The grammarian observes remaining ambigui-
ties and proposes new rules for disambiguating
them, and
3. He also tries to identify misanalyses (cases
</listItem>
<bodyText confidence="0.991161">
where the correct tag is discarded) and, using
the trace information, corrects the faulty rule
This routine is useful if the development time is
very restricted, and only the most common ambigu-
ity types have to be resolved with reasonable suc-
cess. However, if the grammar should be of a very
high quality (extremely few mispredictions, high de-
gree of ambiguity resolution), a large test corpus,
formally similar to the input except for the manually
added extra information about the correct analysis,
should be used. This kind of test corpus would en-
able the automatic identification of mispredictions
as well as counting of various performance statistics
for the rules. However, manually disambiguating a
test corpus of a few hundred thousand words would
probably require a human effort of at least a month.
</bodyText>
<subsectionHeader confidence="0.981826">
4.3 Sample output
</subsectionHeader>
<bodyText confidence="0.999126714285714">
The following is genuine output of the linguistic
(CG-2) parser using the 107 syntactic disambigua-
tion rules. The traces starting with &amp;quot;S:&amp;quot; indicate
the line on which the applied rule is in the grammar
file. One syntactic (and morphological) ambiguity
remains unresolved: until remains ambiguous due to
preposition and subordinating conjunction readings.
</bodyText>
<equation confidence="0.264298428571429">
&amp;quot;&lt;aachen&gt;&amp;quot; S:46
&amp;quot;aachen&amp;quot; &lt;*&gt; &lt;Proper&gt; N NOM SG CNH
&amp;quot;&lt;remained&gt;&amp;quot;
&amp;quot;remain&amp;quot; &lt;SVC/N&gt; &lt;SVC/A&gt; V PAST VFIN OV
&amp;quot;&lt;a&gt;&amp;quot;
&amp;quot;a&amp;quot; &lt;Indef&gt; DET CENTRAL ART SG 0&gt;N
&amp;quot;&lt;free&gt;&amp;quot; S:316, 49
</equation>
<page confidence="0.988251">
83
</page>
<figure confidence="0.884892052631579">
&amp;quot;free&amp;quot; A ABS C&gt;N
&amp;quot;&lt;imperial&gt;&amp;quot; S:49, 57
&amp;quot;imperial&amp;quot; A ABS 0&gt;N
&amp;quot;&lt;city&gt;&amp;quot; S:46
&amp;quot;city&amp;quot; N NOM SG CNH
&amp;quot;&lt;until&gt;&amp;quot;
&amp;quot;until&amp;quot; PREP °DUMMY
&amp;quot;until&amp;quot; &lt;**CLB&gt; CS OCS
&amp;quot;&lt;occupied&gt;&amp;quot; S:116, 346, 46
&amp;quot;occupy&amp;quot; &lt;SVO&gt; PCP2 OV
&amp;quot;&lt;by&gt;&amp;quot;
&amp;quot;by&amp;quot; PREP ODUMMY
&amp;quot;&lt;france&gt;&amp;quot; S:46
&amp;quot;Prance&amp;quot; &lt;*&gt; &lt;Proper&gt; N NOM SG CNH
&amp;quot;&lt;in&gt;&amp;quot;
&amp;quot;in&amp;quot; PREP ODUMMY
&amp;quot;&lt;1794&gt;&amp;quot; S:121, 49
&amp;quot;1794&amp;quot; &lt;1900&gt; NUM CARD CNH
“&lt;$.&gt;11
</figure>
<sectionHeader confidence="0.90687" genericHeader="method">
5 Hybrid language model
</sectionHeader>
<bodyText confidence="0.999562387096775">
To solve shallow parsing with the relaxation labelling
algorithm we model each word in the sentence as a
variable, and each of its possible readings as a label
for that variable. We start with a uniform weight
distribution.
We will use the algorithm to select the right syn-
tactic tag for every word. Each iteration will in-
crease the weight for the tag which is currently
most compatible with the context and decrease the
weights for the others.
Since constraints are used to decide how compat-
ible a tag is with its context, they have to assess
the compatibility of a combination of readings. We
adapt CG constraints described above.
The REMOVE constraints express total incom-
patibility&apos; and SELECT constraints express total
compatibility (actually, they express incompatibility
of all other possibilities).
The compatibility value for these should be at
least as strong as the strongest value for a statisti-
cally obtained constraint (see below). This produces
a value of about ±10.
But because we want the linguistic part of the
model to be more important than the statistical part
and because a given label will receive the influence
&apos;We model compatibility values using mutual infor-
mation (Cover and Thomas, 1991), which enables us
to use negative numbers to state incompatibility. See
(Padro, 1996) for a performance comparison between
M.I. and other measures when applying relaxation la-
belling to NLP.
of about two bigrarns and three trigrams6, a sin-
gle linguistic constraint might have to override five
statistical constraints. So we will make the compat-
ibility values six times stronger, that is, ±60.
Since in our implementation of the CG parser
(Tapanainen, 1996) constraints tend to be applied
in a certain order — e.g. SELECT constraints are
usually applied before REMOVE constraints — we
adjust the compatibility values to get a similar ef-
fect: if the value for SELECT constraints is +60,
the value for REMOVE constraints will be lower
in absolute value, (i.e. —50). With this we ensure
that two contradictory constraints (if there are any)
do not cancel each other. The SELECT constraint
will win, as if it had been applied before.
This enables using any Constraint Grammar with
this algorithm although we are applying it more flex-
ibly: we do not decide whether a constraint is ap-
plied or not. It is always applied with an influence
(perhaps zero) that depends on the weights of the
labels.
If the algorithm should apply the constraints in
a more strict way, we can introduce an influence
threshold under which a constraint does not have
enough influence, i.e. is not applied.
We can add more information to our model in the
form of statistically derived constraints. Here we use
bigrams and trigrams as constraints.
The 218,000-word corpus of journalese from which
these constraints were extracted was analysed using
the following modules:
</bodyText>
<listItem confidence="0.99174325">
• EngCG morphological tagger
• Module for introducing syntactic ambiguities
• The NP disambiguator using the 107 rules writ-
ten in a day
</listItem>
<bodyText confidence="0.99857375">
No human effort was spent on creating this train-
ing corpus. The training corpus is partly ambigu-
ous, so the bi/trigram information acquired will be
slightly noisy, but accurate enough to provide an al-
most supervised statistical model.
For instance, the following constraints have been
statistically extracted from bi/trigram occurrences
in the training corpus.
</bodyText>
<footnote confidence="0.779333">
-0.415371 (0V)
(1 (0&gt;N));
6The algorithm tends to select one label per variable,
so there is always a bi/trigram which is applied more
significantly than the others.
</footnote>
<page confidence="0.989472">
84
</page>
<equation confidence="0.662397666666667">
4.28089 (0&gt;A)
(-1 (0&gt;A))
(1 (CAH));
</equation>
<bodyText confidence="0.9999336">
The compatibility value is the mutual informa-
tion, computed from the probabilities estimated
from a training corpus. We do not need to assign
the compatibility values here, since we can estimate
them from the corpus.
The compatibility values assigned to the hand-
written constraints express the strength of these con-
straints compared to the statistical ones. Modifying
those values means changing the relative weights of
the linguistic and statistical parts of the model.
</bodyText>
<sectionHeader confidence="0.955672" genericHeader="method">
6 Preparation of the benchmark
corpus
</sectionHeader>
<bodyText confidence="0.990096177777778">
For evaluating the systems, five roughly equal-sized
benchmark corpora not used in the development of
our parsers and taggers were prepared. The texts,
totaling 6,500 words, were copied from the Guten-
berg e-text archive, and they represent present-day
American English. One text is from an article about
AIDS; another concerns brainwashing techniques;
the third describes guerilla warfare tactics; the
fourth addresses the assassination of J. F. Kennedy;
the last is an extract from a speech by Noam Chom-
sky.
The texts were first analysed by a recent version
of the morphological analyser and rule-based dis-
ambiguator EngCG, then the syntactic ambiguities
were added with a simple lookup module. The am-
biguous text was then manually disambiguated. The
disambiguated texts were also proofread afterwards.
Usually, this practice resulted in one analysis per
word. However, there were two types of exception:
1. The input did not contain the desired alterna-
tive (due to a morphological disambiguation er-
ror). In these cases, no reading was marked
as correct. Two such words were found in the
corpora; they detract from the performance fig-
ures.
2. The input contained more than one analyses all
of which seemed equally legitimate, even when
semantic and textual criteria were consulted.
In these cases, all the equal alternatives were
marked as correct. The benchmark corpus con-
tains 18 words (mainly ING-forms and nonfinite
ED-forms) with two correct syntactic analyses.
The number of multiple analyses could proba-
bly be made even smaller by specifying the gram-
matical representation (usage principles of the syn-
tactic tags) in more detail, in particular incorpo-
rating some analysis conventions for certain appar-
ent borderline cases (for a discussion of specify-
ing a parser&apos;s linguistic task, see (Voutilainen and
Jarvinen, 1995)).
To improve the objectivity of the evaluation, the
benchmark corpus (as well as parser outputs) have
been made available from. the following URLs:
http / /ww w . helsinki.fir avoutila/an1p97 .html
http://www—lsi.upc.esrlluisp/an1p97.html
</bodyText>
<sectionHeader confidence="0.980688" genericHeader="evaluation">
7 Experiments and results
</sectionHeader>
<bodyText confidence="0.99978692">
We tested linguistic, statistical and hybrid language
models, using the CG-2 parser (Tapanainen, 1996)
and the relaxation labelling algorithm described in
Section 2.
The statistical models were obtained from a train-
ing corpus of 218,000 words of journalese, syntac-
tically annotated using the linguistic parser (see
above).
Although the linguistic CG-2 parser does not dis-
ambiguate completely, it seems to have an almost
perfect recall (cf. Table 1 below), and the noise in-
troduced by the remaining ambiguity is assumed to
be sufficiently lower than the signal, following the
idea used in (Yarowsky, 1992).
The collected statistics were bigram and trigram
occurrences.
The algorithms and models were tested against a
hand-disambiguated benchmark corpus of over 6,500
words.
We measure the performance of the different mod-
els in terms of recall and precision. Recall is the
percentage of words that get the correct tag among
the tags proposed by the system. Precision is the
percentage of tags proposed by the system that are
correct.
</bodyText>
<table confidence="0.998322666666667">
CG-2 parser Rel. Labelling
prec. - recall prec. - recall
C 90.8% — 99.7% 93.3% — 98.4%
</table>
<tableCaption confidence="0.999157">
Table 1: Results obtained with the linguistic model.
</tableCaption>
<table confidence="0.9975756">
Rel. Labelling
prec. - recall
B 87.4% — 88.0%
T 87.6% — 88.4%
BT 88.1% — 88.8%
</table>
<tableCaption confidence="0.999555">
Table 2: Results obtained with statistical models.
</tableCaption>
<page confidence="0.975608">
85
</page>
<table confidence="0.998334">
Rel. Labelling
prec. - recall
BC 96.0% — 97.0%
TC 95.9% — 97.0%
BTC 96.1% — 97.2%
</table>
<tableCaption confidence="0.999933">
Table 3: Results obtained with hybrid models.
</tableCaption>
<bodyText confidence="0.972738512195122">
Precision and recall results (computed on all
words except punctuation marks, which are unam-
biguous) are given in tables 1, 2 and 3. Models are
coded as follows: B stands for bigrams, T for tri-
grams and C for hand-written constraints. All com-
binations of information types are tested. Since the
CG-2 parser handles only Constraint Grammars, we
cannot test this algorithm with statistical models.
These results suggest the following conclusions:
• Using the same language model (107 rules), the
relaxation algorithm disambiguates more than
the CG-2 parser. This is due to the weighted
rule application, and results in more misanaly-
ses and less remaining ambiguity.
• The statistical models are clearly worse than the
linguistic one. This could be due to the noise in
the training corpus, but it is more likely caused
by the difficulty of the task: we are dealing here
with shallow syntactic parsing, which is prob-
ably more difficult to capture in a statistical
model than e.g. POS tagging.
• The hybrid models produce less ambiguous re-
sults than the other models. The number of
errors is much lower than was the case with the
statistical models, and somewhat higher than
was the case with the linguistic model. The gain
in precision seems to be enough to compensate
for the loss in recal17.
• There does not seem to be much difference be-
tween BC and TC hybrid models. The reason is
probably that the job is mainly done by the lin-
guistic part of the model — which has a higher
relative weight — and that the statistical part
only helps to disambiguate cases where the lin-
guistic model doesn&apos;t make a prediction. The
BTC hybrid model is slightly better than the
other two.
• The small difference between the hybrid models
suggest that some reasonable statistics provide
enough disambiguation, and that not very so-
phisticated information is needed.
</bodyText>
<footnote confidence="0.895624">
7This obviously depends on the flexibility of one&apos;s
requirements.
</footnote>
<sectionHeader confidence="0.990318" genericHeader="conclusions">
8 Discussion
</sectionHeader>
<bodyText confidence="0.998881153846154">
In this paper we have presented a method for com-
bining linguistic hand-crafted rules with statistical
information, and we applied it to a shallow parsing
task.
Results show that adding statistical information
results in an increase in the disambiguation ratio,
getting a higher precision. The price is a decrease
in recall. Nevertheless, the risk can be controlled
since more or less statistical information can be used
depending on the precision/recall tradeoff one wants
to achieve.
We also used this technique to build a shallow
parser with minimal human effort:
</bodyText>
<listItem confidence="0.9232222">
• 107 disambiguation rules were written in a day.
• These rules were used to analyze a training cor-
pus, with a very high recall and a reasonable
precision.
• This slightly ambiguous training corpus is used
</listItem>
<bodyText confidence="0.943575764705882">
for collecting bigram and trigram occurrences.
The noise introduced by the remaining ambigu-
ity is assumed not to distort the resulting statis-
tics too much.
• The hand-written constraints and the statistics
are combined using a relaxation algorithm to
analyze the test corpus, rising the precision to
96.1% and lowering the recall only to 97.2%.
Finally, a reservation must be made: what we have
not investigated in this paper is how much of the
extra work done with the statistical module could
have been done equally well or even better by spend-
ing e.g. another day writing a further collection of
heuristic rules. As suggested e.g. by Tapanainen
and Voutilainen (1994) and Chanod and Tapanainen
(1995), hand-coded heuristics may be a worthwhile
addition to &apos;strictly&apos; grammar-based rules.
</bodyText>
<sectionHeader confidence="0.994207" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999733166666667">
We wish to thank Timo Jarvinen, Path Tapanainen
and two ANLP&apos;97 referees for useful comments on
earlier versions of this paper.
The first author benefited from the collaboration
of Juha Heikkila in the development of the linguistic
description used by the EngCG morphological tag-
ger; the two-level compiler for morphological analy-
sis in EngCG was written by Kimmo Koskenniemi;
the recent version of the Constraint Grammar parser
(CG-2) was written by Pasi Tapanainen. The Con-
straint Grammar framework was originally proposed
by Fred Karlsson.
</bodyText>
<page confidence="0.995304">
86
</page>
<sectionHeader confidence="0.995378" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999895445783132">
E. Brill. 1995. Unsupervised Learning of Disam-
biguation Rules for Part-of-speech Tagging. In
Proceedings of 3rd Workshop on Very Large Cor-
pora, Massachusetts.
J.-P. Chanod and P. Tapanainen 1995. Tagging
French: comparing a statistical and a constraint-
based method. In Proc. EACL&apos;95. ACL, Dublin.
T.M. Cover and J.A. Thomas (Editors) 1991. Ele-
ments of information theory. John Wiley &amp; Sons.
J. Eklundh and A. Rosenfeld. 1978. Convergence
Properties of Relaxation Labelling. Technical Re-
port no. 701. Computer Science Center. Univer-
sity of Maryland.
W. Daelemans, J. Zavrel, P. Berck and S. Gillis.
1996. MTB: A Memory-Based Part-of-Speech
Tagger Generator. In Proceedings of 4th Work-
shop on Very Large Corpora. Copenhagen, Den-
mark.
R. Garside, G. Leech and G. Sampson (Editors)
1987. The Computational Analysis of English.
London and New York: Longman.
D. Hindle. 1989. Acquiring disambiguation rules
from text. In Proc. A CL &apos;89.
F. Karlsson 1990. Constraint Grammar as a Frame-
work for Parsing Running Text. In H. Karlgren
(ed.), Papers presented to the 13th International
Conference on Computational Linguistics, Vol. 3.
Helsinki. 168-173.
F. Karlsson, A. Voutilainen, J. Heikkila and
A. Anttila. (Editors) 1995. Constraint Grammar:
A Language-Independent System for Parsing Un-
restricted Text. Mouton de Gruyter, Berlin and
New York.
J. Larrosa and P. Meseguer. 1995. An Optimization-
based Heuristic for Maximal Constraint Satisfac-
tion. In Proceedings of International Conference
on Principles and Practice of Constraint Program-
ming.
L. Marquez and H. Rodriguez. 1995. Towards
Learning a Constraint Grammar from Annotated
Corpora Using Decision Trees. ESPRIT BRA-
7315 Acquilex II, Working Paper.
L. Padro. 1996. POS Tagging Using Relaxation
Labelling. In Proceedings of 16th International
Conference on Computational Linguistics, Copen-
hagen, Denmark.
J. Richards, D. Landgrebe and P. Swain. 1981. On
the accuracy of pixel relaxation labelling. In IEEE
Transactions on System, Man and Cybernetics.
Vol. SMC-11
C. Samuelsson, P. Tapanainen and A. Voutilainen.
1996. Inducing Constraint Grammars. In Pro-
ceedings of the 3rd International Colloquium on
Grammatical Inference.
H. Schmid 1994. Part-of-speech tagging with neu-
ral networks. In Proceedings of 15th International
Conference on Computational Linguistics, Kyoto,
Japan.
P. Tapanainen 1996. The Constraint Grammar
Parser CG-2. Department of General Linguistics,
University of Helsinki.
P. Tapanainen and A. Voutilainen 1994. Tagging
accurately — Don&apos;t guess if you know. In Pro-
ceedings of the 4th Conference on Applied Natural
Language Processing, ACL. Stuttgart.
C . Torras. 1989. Relaxation and Neural Learning:
Points of Convergence and Divergence. Journal of
Parallel and Distributed Computing, 6:217-244
A . Voutilainen, J. Heikkila and A. Anttila 1992.
Constraint Grammar of English. A Performance-
Oriented Introduction. Publications 21, De-
partment of General Linguistics, University of
Helsinki.
A. Voutilainen and T. Jarvinen. 1995. Specifying
a shallow grammatical representation for parsing
purposes. In Proceedings of the 7th meeting of the
European Association for Computational Linguis-
tics. 210-214.
D. Yarowsky. 1992. Word-sense disambiguations us-
ing statistical models of Roget&apos;s categories trained
on large corpora. In Proceedings of 14th Interna-
tional Conference on Computational Linguistics.
Nantes, France.
</reference>
<page confidence="0.999474">
87
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.456877">
<title confidence="0.999159">Developing a hybrid NP parser</title>
<author confidence="0.999426">Atro Voutilainen</author>
<affiliation confidence="0.991599">Department of General Linguistics</affiliation>
<address confidence="0.619693">4</address>
<affiliation confidence="0.8721025">FIN-00014 University of Helsinki Finland</affiliation>
<email confidence="0.984905">avoutilaling.helsinki.fi</email>
<abstract confidence="0.999538117647059">We describe the use of energy function optimisation in very shallow syntactic parsing. The approach can use linguistic rules and corpus-based statistics, so the strengths of both linguistic and statistical approaches to NLP can be combined in a single framework. The rules are contextual constraints for resolving syntactic ambiguities expressed as alternative tags, and the statistical language model consists of corpus-based n-grams of syntactic tags. The success of the hybrid syntactic disambiguator is evaluated against a held-out benchmark corpus. Also the contributions of the linguistic and statistical language models to the hybrid model are estimated.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Unsupervised Learning of Disambiguation Rules for Part-of-speech Tagging.</title>
<date>1995</date>
<booktitle>In Proceedings of 3rd Workshop on Very Large Corpora,</booktitle>
<location>Massachusetts.</location>
<contexts>
<context position="1449" citStr="Brill, 1995" startWordPosition="211" endWordPosition="212">ction The language models used by natural language analyzers are traditionally based on two approaches. In the linguistic approach, the model is based on hand-crafted rules derived from the linguist&apos;s general and/or corpus-based knowledge about the object language. In the data-driven approach, the model is automatically generated from annotated text corpora, and the model can be represented e.g. as n-grams (Garside et al., 1987), local rules (Hindle, 1989) or neural nets (Schmid, 1994). Most hybrid approaches combine statistical information with automatically extracted rule-based information (Brill, 1995; Daelemans et al., 1996). Relatively little attention has been paid to models where the statistical approach is combined with a truly linguistic model (i.e. one generated by a linguist). This paper reports one such approach: syntactic rules written by a linguist are combined with statistical information using the relaxation labelling algorithm. Lluis Padre) Dept. Llenguatges i Sistemes Informatics Universitat Politecnica de Catalunya C/ Gran Capita s/n. 08034 Barcelona Catalonia padroOlsi.upc.es Our application is very shallow parsing: identification of verbs, premodifiers, nominal and adverb</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>E. Brill. 1995. Unsupervised Learning of Disambiguation Rules for Part-of-speech Tagging. In Proceedings of 3rd Workshop on Very Large Corpora, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-P Chanod</author>
<author>P Tapanainen</author>
</authors>
<title>Tagging French: comparing a statistical and a constraintbased method.</title>
<date>1995</date>
<booktitle>In Proc. EACL&apos;95. ACL,</booktitle>
<location>Dublin.</location>
<contexts>
<context position="26517" citStr="Chanod and Tapanainen (1995)" startWordPosition="4277" endWordPosition="4280">remaining ambiguity is assumed not to distort the resulting statistics too much. • The hand-written constraints and the statistics are combined using a relaxation algorithm to analyze the test corpus, rising the precision to 96.1% and lowering the recall only to 97.2%. Finally, a reservation must be made: what we have not investigated in this paper is how much of the extra work done with the statistical module could have been done equally well or even better by spending e.g. another day writing a further collection of heuristic rules. As suggested e.g. by Tapanainen and Voutilainen (1994) and Chanod and Tapanainen (1995), hand-coded heuristics may be a worthwhile addition to &apos;strictly&apos; grammar-based rules. Acknowledgements We wish to thank Timo Jarvinen, Path Tapanainen and two ANLP&apos;97 referees for useful comments on earlier versions of this paper. The first author benefited from the collaboration of Juha Heikkila in the development of the linguistic description used by the EngCG morphological tagger; the two-level compiler for morphological analysis in EngCG was written by Kimmo Koskenniemi; the recent version of the Constraint Grammar parser (CG-2) was written by Pasi Tapanainen. The Constraint Grammar fram</context>
</contexts>
<marker>Chanod, Tapanainen, 1995</marker>
<rawString>J.-P. Chanod and P. Tapanainen 1995. Tagging French: comparing a statistical and a constraintbased method. In Proc. EACL&apos;95. ACL, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T M Cover</author>
<author>J A Thomas</author>
</authors>
<title>Elements of information theory.</title>
<date>1991</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="16743" citStr="Cover and Thomas, 1991" startWordPosition="2690" endWordPosition="2693">We adapt CG constraints described above. The REMOVE constraints express total incompatibility&apos; and SELECT constraints express total compatibility (actually, they express incompatibility of all other possibilities). The compatibility value for these should be at least as strong as the strongest value for a statistically obtained constraint (see below). This produces a value of about ±10. But because we want the linguistic part of the model to be more important than the statistical part and because a given label will receive the influence &apos;We model compatibility values using mutual information (Cover and Thomas, 1991), which enables us to use negative numbers to state incompatibility. See (Padro, 1996) for a performance comparison between M.I. and other measures when applying relaxation labelling to NLP. of about two bigrarns and three trigrams6, a single linguistic constraint might have to override five statistical constraints. So we will make the compatibility values six times stronger, that is, ±60. Since in our implementation of the CG parser (Tapanainen, 1996) constraints tend to be applied in a certain order — e.g. SELECT constraints are usually applied before REMOVE constraints — we adjust the compa</context>
</contexts>
<marker>Cover, Thomas, 1991</marker>
<rawString>T.M. Cover and J.A. Thomas (Editors) 1991. Elements of information theory. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eklundh</author>
<author>A Rosenfeld</author>
</authors>
<title>Convergence Properties of Relaxation Labelling.</title>
<date>1978</date>
<tech>Technical Report no. 701.</tech>
<institution>Computer Science Center. University of Maryland.</institution>
<contexts>
<context position="9531" citStr="Eklundh and Rosenfeld, 1978" startWordPosition="1526" endWordPosition="1529">Sii) EPt(m) x +sik) k=1 where — 1 &lt; Sii &lt; +1 4. If a stopping/convergence criterion4 is satisfied, stop, otherwise go to to step 2. 3 Grammatical representation The input of our parser is morphologically analyzed and disambiguated text enriched with alternative syntactic tags, e.g. &amp;quot;&lt;others&gt;&amp;quot; &amp;quot;other&amp;quot; PRON NOM PL C&gt;N CNH 2p(m) is the weight assigned to label k for variable r at time m. 3Negative values for support indicate incompatibility. &apos;The usual criterion is to stop when there are no more changes, although more sophisticated heuristic procedures are also used to stop relaxation processes (Eklundh and Rosenfeld, 1978; Richards et al. , 1981). &amp;quot;&lt;moved&gt;&amp;quot; &amp;quot;move&amp;quot; &lt;SV&gt; &lt;SVO&gt; V PAST VFIN CV &amp;quot;&lt;away&gt;&amp;quot; &amp;quot;away&amp;quot; ADV ADVL C&gt;A CAH &amp;quot;&lt;from&gt;&amp;quot; &amp;quot;from&amp;quot; PREP °DUMMY &amp;quot;&lt;traditional&gt;&amp;quot; &amp;quot;traditional&amp;quot; A ABS 0&gt;N 0N&lt; CNH &amp;quot;&lt;jazz&gt;&amp;quot; &amp;quot;jazz&amp;quot; &lt;-Indef&gt; N NOM SG 0&gt;N CNH &amp;quot;&lt;practice&gt;&amp;quot; &amp;quot;practice&amp;quot; N NOM SG 0&gt;N ONE &amp;quot;practice&amp;quot; &lt;SVO&gt; V PRES -SG3 VFIN CV Every indented line represents a morphological reading; the sample shows that some morphological ambiguities are not resolved by the rule-based morphological disambiguator, known as the EngCG tagger (Voutilainen et al., 1992; Karlsson et al., 1995). Our syntactic tags start with the &amp;quot;@&amp;quot; sign. A word </context>
</contexts>
<marker>Eklundh, Rosenfeld, 1978</marker>
<rawString>J. Eklundh and A. Rosenfeld. 1978. Convergence Properties of Relaxation Labelling. Technical Report no. 701. Computer Science Center. University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>P Berck</author>
<author>S Gillis</author>
</authors>
<title>MTB: A Memory-Based Part-of-Speech Tagger Generator.</title>
<date>1996</date>
<booktitle>In Proceedings of 4th Workshop on Very Large Corpora.</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="1474" citStr="Daelemans et al., 1996" startWordPosition="213" endWordPosition="216">guage models used by natural language analyzers are traditionally based on two approaches. In the linguistic approach, the model is based on hand-crafted rules derived from the linguist&apos;s general and/or corpus-based knowledge about the object language. In the data-driven approach, the model is automatically generated from annotated text corpora, and the model can be represented e.g. as n-grams (Garside et al., 1987), local rules (Hindle, 1989) or neural nets (Schmid, 1994). Most hybrid approaches combine statistical information with automatically extracted rule-based information (Brill, 1995; Daelemans et al., 1996). Relatively little attention has been paid to models where the statistical approach is combined with a truly linguistic model (i.e. one generated by a linguist). This paper reports one such approach: syntactic rules written by a linguist are combined with statistical information using the relaxation labelling algorithm. Lluis Padre) Dept. Llenguatges i Sistemes Informatics Universitat Politecnica de Catalunya C/ Gran Capita s/n. 08034 Barcelona Catalonia padroOlsi.upc.es Our application is very shallow parsing: identification of verbs, premodifiers, nominal and adverbial heads, and certain ki</context>
</contexts>
<marker>Daelemans, Zavrel, Berck, Gillis, 1996</marker>
<rawString>W. Daelemans, J. Zavrel, P. Berck and S. Gillis. 1996. MTB: A Memory-Based Part-of-Speech Tagger Generator. In Proceedings of 4th Workshop on Very Large Corpora. Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Garside</author>
<author>G Leech</author>
<author>G Sampson</author>
</authors>
<title>The Computational Analysis of English. London and</title>
<date>1987</date>
<location>New York: Longman.</location>
<contexts>
<context position="1270" citStr="Garside et al., 1987" startWordPosition="185" endWordPosition="188">ntactic disambiguator is evaluated against a held-out benchmark corpus. Also the contributions of the linguistic and statistical language models to the hybrid model are estimated. 1 Introduction The language models used by natural language analyzers are traditionally based on two approaches. In the linguistic approach, the model is based on hand-crafted rules derived from the linguist&apos;s general and/or corpus-based knowledge about the object language. In the data-driven approach, the model is automatically generated from annotated text corpora, and the model can be represented e.g. as n-grams (Garside et al., 1987), local rules (Hindle, 1989) or neural nets (Schmid, 1994). Most hybrid approaches combine statistical information with automatically extracted rule-based information (Brill, 1995; Daelemans et al., 1996). Relatively little attention has been paid to models where the statistical approach is combined with a truly linguistic model (i.e. one generated by a linguist). This paper reports one such approach: syntactic rules written by a linguist are combined with statistical information using the relaxation labelling algorithm. Lluis Padre) Dept. Llenguatges i Sistemes Informatics Universitat Politec</context>
</contexts>
<marker>Garside, Leech, Sampson, 1987</marker>
<rawString>R. Garside, G. Leech and G. Sampson (Editors) 1987. The Computational Analysis of English. London and New York: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Acquiring disambiguation rules from text.</title>
<date>1989</date>
<booktitle>In Proc. A CL &apos;89.</booktitle>
<contexts>
<context position="1298" citStr="Hindle, 1989" startWordPosition="191" endWordPosition="192">gainst a held-out benchmark corpus. Also the contributions of the linguistic and statistical language models to the hybrid model are estimated. 1 Introduction The language models used by natural language analyzers are traditionally based on two approaches. In the linguistic approach, the model is based on hand-crafted rules derived from the linguist&apos;s general and/or corpus-based knowledge about the object language. In the data-driven approach, the model is automatically generated from annotated text corpora, and the model can be represented e.g. as n-grams (Garside et al., 1987), local rules (Hindle, 1989) or neural nets (Schmid, 1994). Most hybrid approaches combine statistical information with automatically extracted rule-based information (Brill, 1995; Daelemans et al., 1996). Relatively little attention has been paid to models where the statistical approach is combined with a truly linguistic model (i.e. one generated by a linguist). This paper reports one such approach: syntactic rules written by a linguist are combined with statistical information using the relaxation labelling algorithm. Lluis Padre) Dept. Llenguatges i Sistemes Informatics Universitat Politecnica de Catalunya C/ Gran Ca</context>
</contexts>
<marker>Hindle, 1989</marker>
<rawString>D. Hindle. 1989. Acquiring disambiguation rules from text. In Proc. A CL &apos;89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Karlsson</author>
</authors>
<title>Constraint Grammar as a Framework for Parsing Running Text.</title>
<date>1990</date>
<booktitle>Papers presented to the 13th International Conference on Computational Linguistics,</booktitle>
<volume>3</volume>
<pages>168--173</pages>
<editor>In H. Karlgren (ed.),</editor>
<contexts>
<context position="3243" citStr="Karlsson, 1990" startWordPosition="480" endWordPosition="481">l of 100% if all words retain the correct morphological and syntactic reading; the system&apos;s precision is 100% if the output contains no illegitimate morphological or syntactic readings. In practice, some correct readings are discarded, and some ambiguities remain unresolved (i.e. some words retain two or more alternative analyses). The system can use linguistic rules and corpusbased statistics. Notable about the system is that minimal human effort was needed for creating its language models (the linguistic consisting of syntactic disambiguation rules based on the Constraint Grammar framework (Karlsson, 1990; Karlsson et al., 1995); the corpus-based consisting of bigrams and trigrams): • Only one day was spent on writing the 107 syntactic disambiguation rules used by the linguistic parser. • No human annotators were needed for annotating the training corpus (218,000 words of journalese) used by the data-driven learning modules of this system: the training corpus was annotated by (i) tagging it with the EngCG morphological tagger, (ii) making the tagged text 80 syntactically ambiguous by adding the alternative syntactic tags to the words, and (iii) resolving most of these syntactic ambiguities by </context>
</contexts>
<marker>Karlsson, 1990</marker>
<rawString>F. Karlsson 1990. Constraint Grammar as a Framework for Parsing Running Text. In H. Karlgren (ed.), Papers presented to the 13th International Conference on Computational Linguistics, Vol. 3. Helsinki. 168-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Karlsson</author>
<author>A Voutilainen</author>
<author>J Heikkila</author>
<author>A Anttila</author>
</authors>
<title>Constraint Grammar: A Language-Independent System for Parsing Unrestricted Text. Mouton de Gruyter,</title>
<date>1995</date>
<location>Berlin and New York.</location>
<contexts>
<context position="2274" citStr="Karlsson et al., 1995" startWordPosition="330" endWordPosition="333">rts one such approach: syntactic rules written by a linguist are combined with statistical information using the relaxation labelling algorithm. Lluis Padre) Dept. Llenguatges i Sistemes Informatics Universitat Politecnica de Catalunya C/ Gran Capita s/n. 08034 Barcelona Catalonia padroOlsi.upc.es Our application is very shallow parsing: identification of verbs, premodifiers, nominal and adverbial heads, and certain kinds of postmodifiers. We call this parser a noun phrase parser. The input is English text morphologically tagged with a rule-based tagger called EngCG (Voutilainen et al., 1992; Karlsson et al., 1995). Syntactic wordtags are added as alternatives (e.g. each adjective gets a premodifier tag, postmodifier tag and a nominal head tag as alternatives). The system should remove contextually illegitimate tags and leave intact each word&apos;s most appropriate tag. In other words, the syntactic language model is applied by a disambiguator. The parser has a recall of 100% if all words retain the correct morphological and syntactic reading; the system&apos;s precision is 100% if the output contains no illegitimate morphological or syntactic readings. In practice, some correct readings are discarded, and some </context>
<context position="10078" citStr="Karlsson et al., 1995" startWordPosition="1615" endWordPosition="1618">res are also used to stop relaxation processes (Eklundh and Rosenfeld, 1978; Richards et al. , 1981). &amp;quot;&lt;moved&gt;&amp;quot; &amp;quot;move&amp;quot; &lt;SV&gt; &lt;SVO&gt; V PAST VFIN CV &amp;quot;&lt;away&gt;&amp;quot; &amp;quot;away&amp;quot; ADV ADVL C&gt;A CAH &amp;quot;&lt;from&gt;&amp;quot; &amp;quot;from&amp;quot; PREP °DUMMY &amp;quot;&lt;traditional&gt;&amp;quot; &amp;quot;traditional&amp;quot; A ABS 0&gt;N 0N&lt; CNH &amp;quot;&lt;jazz&gt;&amp;quot; &amp;quot;jazz&amp;quot; &lt;-Indef&gt; N NOM SG 0&gt;N CNH &amp;quot;&lt;practice&gt;&amp;quot; &amp;quot;practice&amp;quot; N NOM SG 0&gt;N ONE &amp;quot;practice&amp;quot; &lt;SVO&gt; V PRES -SG3 VFIN CV Every indented line represents a morphological reading; the sample shows that some morphological ambiguities are not resolved by the rule-based morphological disambiguator, known as the EngCG tagger (Voutilainen et al., 1992; Karlsson et al., 1995). Our syntactic tags start with the &amp;quot;@&amp;quot; sign. A word is syntactically ambiguous if it has more than one syntactic tags (e.g. practice above has three alternative syntactic tags). Syntactic tags are added to the morphological analysis with a simple lookup module. The syntactic parser&apos;s main task is disambiguating (rather than adding new information to the input sentence): contextually illegitimate alternatives should be discarded, while legitimate tags should be retained (note that also morphological ambiguities may be resolved as a side effect). Next we describe the syntactic tags: • @&gt;N repre</context>
</contexts>
<marker>Karlsson, Voutilainen, Heikkila, Anttila, 1995</marker>
<rawString>F. Karlsson, A. Voutilainen, J. Heikkila and A. Anttila. (Editors) 1995. Constraint Grammar: A Language-Independent System for Parsing Unrestricted Text. Mouton de Gruyter, Berlin and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Larrosa</author>
<author>P Meseguer</author>
</authors>
<title>An Optimizationbased Heuristic for Maximal Constraint Satisfaction.</title>
<date>1995</date>
<booktitle>In Proceedings of International Conference on Principles and Practice of Constraint Programming.</booktitle>
<contexts>
<context position="5838" citStr="Larrosa and Meseguer, 1995" startWordPosition="905" endWordPosition="908">. Then we proceed to the application by outlining the grammatical representation used in our shallow syntax. After this, the disambiguation rules and their development are described. Next in turn is a description of how the data-driven language model was generated. The evaluation of 2 The Relaxation Labelling Algorithm Since we are dealing with a set of constraints and want to find a solution which optimally satisfies them all, we can use a standard Constraint Satisfaction algorithm to solve that problem. Constraint Satisfaction Problems are naturally modelled as Consistent Labeling Problems (Larrosa and Meseguer, 1995). An algorithm that solves CLPs is Relaxation Labelling. It has been applied to part-of-speech tagging (Padre), 1996) showing that it can yield as good results as a HMM tagger when using the same information. In addition, it can deal with any kind of constraints, thus the model can be improved by adding any other constraints available, either statistics, hand-written or automatically extracted (Marquez and Rodriguez, 1995; Samuelsson et al., 1996). Relaxation labelling is a generic name for a family of iterative algorithms which perform function optimisation, based on local information. See (T</context>
</contexts>
<marker>Larrosa, Meseguer, 1995</marker>
<rawString>J. Larrosa and P. Meseguer. 1995. An Optimizationbased Heuristic for Maximal Constraint Satisfaction. In Proceedings of International Conference on Principles and Practice of Constraint Programming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Marquez</author>
<author>H Rodriguez</author>
</authors>
<title>Towards Learning a Constraint Grammar from Annotated Corpora Using Decision Trees.</title>
<date>1995</date>
<booktitle>ESPRIT BRA7315 Acquilex II, Working Paper.</booktitle>
<contexts>
<context position="6263" citStr="Marquez and Rodriguez, 1995" startWordPosition="973" endWordPosition="976">m all, we can use a standard Constraint Satisfaction algorithm to solve that problem. Constraint Satisfaction Problems are naturally modelled as Consistent Labeling Problems (Larrosa and Meseguer, 1995). An algorithm that solves CLPs is Relaxation Labelling. It has been applied to part-of-speech tagging (Padre), 1996) showing that it can yield as good results as a HMM tagger when using the same information. In addition, it can deal with any kind of constraints, thus the model can be improved by adding any other constraints available, either statistics, hand-written or automatically extracted (Marquez and Rodriguez, 1995; Samuelsson et al., 1996). Relaxation labelling is a generic name for a family of iterative algorithms which perform function optimisation, based on local information. See (Torras, 1989) for a summary. Given a set of variables, a set of possible labels for each variable, and a set of compatibility constraints between those labels, the algorithm finds a combination of weights for the labels that maximises &amp;quot;global consistency&amp;quot; (see below). Let V = {vi, v2, , vn} be a set of variables. Let ti = , be the set of possible labels for variable vi. Let CS be a set of constraints between the labels of </context>
</contexts>
<marker>Marquez, Rodriguez, 1995</marker>
<rawString>L. Marquez and H. Rodriguez. 1995. Towards Learning a Constraint Grammar from Annotated Corpora Using Decision Trees. ESPRIT BRA7315 Acquilex II, Working Paper.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Padro</author>
</authors>
<title>POS Tagging Using Relaxation Labelling.</title>
<date>1996</date>
<booktitle>In Proceedings of 16th International Conference on Computational Linguistics,</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="16829" citStr="Padro, 1996" startWordPosition="2705" endWordPosition="2706">d SELECT constraints express total compatibility (actually, they express incompatibility of all other possibilities). The compatibility value for these should be at least as strong as the strongest value for a statistically obtained constraint (see below). This produces a value of about ±10. But because we want the linguistic part of the model to be more important than the statistical part and because a given label will receive the influence &apos;We model compatibility values using mutual information (Cover and Thomas, 1991), which enables us to use negative numbers to state incompatibility. See (Padro, 1996) for a performance comparison between M.I. and other measures when applying relaxation labelling to NLP. of about two bigrarns and three trigrams6, a single linguistic constraint might have to override five statistical constraints. So we will make the compatibility values six times stronger, that is, ±60. Since in our implementation of the CG parser (Tapanainen, 1996) constraints tend to be applied in a certain order — e.g. SELECT constraints are usually applied before REMOVE constraints — we adjust the compatibility values to get a similar effect: if the value for SELECT constraints is +60, t</context>
</contexts>
<marker>Padro, 1996</marker>
<rawString>L. Padro. 1996. POS Tagging Using Relaxation Labelling. In Proceedings of 16th International Conference on Computational Linguistics, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Richards</author>
<author>D Landgrebe</author>
<author>P Swain</author>
</authors>
<title>On the accuracy of pixel relaxation labelling.</title>
<date>1981</date>
<booktitle>In IEEE Transactions on System, Man and Cybernetics. Vol. SMC-11</booktitle>
<marker>Richards, Landgrebe, Swain, 1981</marker>
<rawString>J. Richards, D. Landgrebe and P. Swain. 1981. On the accuracy of pixel relaxation labelling. In IEEE Transactions on System, Man and Cybernetics. Vol. SMC-11</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Samuelsson</author>
<author>P Tapanainen</author>
<author>A Voutilainen</author>
</authors>
<title>Inducing Constraint Grammars.</title>
<date>1996</date>
<booktitle>In Proceedings of the 3rd International Colloquium on Grammatical Inference.</booktitle>
<contexts>
<context position="6289" citStr="Samuelsson et al., 1996" startWordPosition="977" endWordPosition="980">Constraint Satisfaction algorithm to solve that problem. Constraint Satisfaction Problems are naturally modelled as Consistent Labeling Problems (Larrosa and Meseguer, 1995). An algorithm that solves CLPs is Relaxation Labelling. It has been applied to part-of-speech tagging (Padre), 1996) showing that it can yield as good results as a HMM tagger when using the same information. In addition, it can deal with any kind of constraints, thus the model can be improved by adding any other constraints available, either statistics, hand-written or automatically extracted (Marquez and Rodriguez, 1995; Samuelsson et al., 1996). Relaxation labelling is a generic name for a family of iterative algorithms which perform function optimisation, based on local information. See (Torras, 1989) for a summary. Given a set of variables, a set of possible labels for each variable, and a set of compatibility constraints between those labels, the algorithm finds a combination of weights for the labels that maximises &amp;quot;global consistency&amp;quot; (see below). Let V = {vi, v2, , vn} be a set of variables. Let ti = , be the set of possible labels for variable vi. Let CS be a set of constraints between the labels of the variables. Each constr</context>
</contexts>
<marker>Samuelsson, Tapanainen, Voutilainen, 1996</marker>
<rawString>C. Samuelsson, P. Tapanainen and A. Voutilainen. 1996. Inducing Constraint Grammars. In Proceedings of the 3rd International Colloquium on Grammatical Inference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Part-of-speech tagging with neural networks.</title>
<date>1994</date>
<booktitle>In Proceedings of 15th International Conference on Computational Linguistics, Kyoto,</booktitle>
<contexts>
<context position="1328" citStr="Schmid, 1994" startWordPosition="196" endWordPosition="197">rpus. Also the contributions of the linguistic and statistical language models to the hybrid model are estimated. 1 Introduction The language models used by natural language analyzers are traditionally based on two approaches. In the linguistic approach, the model is based on hand-crafted rules derived from the linguist&apos;s general and/or corpus-based knowledge about the object language. In the data-driven approach, the model is automatically generated from annotated text corpora, and the model can be represented e.g. as n-grams (Garside et al., 1987), local rules (Hindle, 1989) or neural nets (Schmid, 1994). Most hybrid approaches combine statistical information with automatically extracted rule-based information (Brill, 1995; Daelemans et al., 1996). Relatively little attention has been paid to models where the statistical approach is combined with a truly linguistic model (i.e. one generated by a linguist). This paper reports one such approach: syntactic rules written by a linguist are combined with statistical information using the relaxation labelling algorithm. Lluis Padre) Dept. Llenguatges i Sistemes Informatics Universitat Politecnica de Catalunya C/ Gran Capita s/n. 08034 Barcelona Cata</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid 1994. Part-of-speech tagging with neural networks. In Proceedings of 15th International Conference on Computational Linguistics, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
</authors>
<title>The Constraint Grammar Parser CG-2.</title>
<date>1996</date>
<institution>Department of General Linguistics, University of Helsinki.</institution>
<contexts>
<context position="11790" citStr="Tapanainen, 1996" startWordPosition="1869" endWordPosition="1870">unction as head of an adverbial phrase. • @A&lt; represents the postmodifying adverb &amp;quot;enough&amp;quot;. • @V represents verbs and auxiliaries (incl. the infinitive marker &amp;quot;to&amp;quot;). 82 • @&gt;CC represents words introducing a coordination (&amp;quot;either&amp;quot;, &amp;quot;neither&amp;quot;, &amp;quot;both&amp;quot;). • ©CC represents coordinating conjunctions. • ©CS represents subordinating conjunctions. • @DUMMY represents all prepositions, i.e. the parser does not address the attachment of prepositional phrases. 4 Syntactic rules 4.1 Rule formalism The rules follow the Constraint Grammar formalism, and they were applied using the recent parsercompiler CG-2 (Tapanainen, 1996). The parser reads a sentence at a time and discards those ambiguity-forming readings that are disallowed by a constraint. Next we describe some basic features of the rule formalism. The rule REMOVE (0&gt;N) (*1C &lt;&lt;&lt; OR (0V) OR (CCS) BARRIER (CNH)); removes the premodifier tag @&gt;N from an ambiguous reading if somewhere to the right (*1) there is an unambiguous (C) occurrence of a member of the set &lt;&lt;&lt; (sentence boundary symbols) or the verb tag @V or the subordinating conjunction tag ©CS, and there are no intervening tags for nominal heads (©NH). This is a partial rule about coordination: REMOVE </context>
<context position="17199" citStr="Tapanainen, 1996" startWordPosition="2764" endWordPosition="2765">t than the statistical part and because a given label will receive the influence &apos;We model compatibility values using mutual information (Cover and Thomas, 1991), which enables us to use negative numbers to state incompatibility. See (Padro, 1996) for a performance comparison between M.I. and other measures when applying relaxation labelling to NLP. of about two bigrarns and three trigrams6, a single linguistic constraint might have to override five statistical constraints. So we will make the compatibility values six times stronger, that is, ±60. Since in our implementation of the CG parser (Tapanainen, 1996) constraints tend to be applied in a certain order — e.g. SELECT constraints are usually applied before REMOVE constraints — we adjust the compatibility values to get a similar effect: if the value for SELECT constraints is +60, the value for REMOVE constraints will be lower in absolute value, (i.e. —50). With this we ensure that two contradictory constraints (if there are any) do not cancel each other. The SELECT constraint will win, as if it had been applied before. This enables using any Constraint Grammar with this algorithm although we are applying it more flexibly: we do not decide wheth</context>
<context position="21786" citStr="Tapanainen, 1996" startWordPosition="3488" endWordPosition="3489">ion (usage principles of the syntactic tags) in more detail, in particular incorporating some analysis conventions for certain apparent borderline cases (for a discussion of specifying a parser&apos;s linguistic task, see (Voutilainen and Jarvinen, 1995)). To improve the objectivity of the evaluation, the benchmark corpus (as well as parser outputs) have been made available from. the following URLs: http / /ww w . helsinki.fir avoutila/an1p97 .html http://www—lsi.upc.esrlluisp/an1p97.html 7 Experiments and results We tested linguistic, statistical and hybrid language models, using the CG-2 parser (Tapanainen, 1996) and the relaxation labelling algorithm described in Section 2. The statistical models were obtained from a training corpus of 218,000 words of journalese, syntactically annotated using the linguistic parser (see above). Although the linguistic CG-2 parser does not disambiguate completely, it seems to have an almost perfect recall (cf. Table 1 below), and the noise introduced by the remaining ambiguity is assumed to be sufficiently lower than the signal, following the idea used in (Yarowsky, 1992). The collected statistics were bigram and trigram occurrences. The algorithms and models were tes</context>
</contexts>
<marker>Tapanainen, 1996</marker>
<rawString>P. Tapanainen 1996. The Constraint Grammar Parser CG-2. Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>A Voutilainen</author>
</authors>
<title>Tagging accurately — Don&apos;t guess if you know.</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th Conference on Applied Natural Language Processing, ACL.</booktitle>
<location>Stuttgart.</location>
<contexts>
<context position="26484" citStr="Tapanainen and Voutilainen (1994)" startWordPosition="4272" endWordPosition="4275">urrences. The noise introduced by the remaining ambiguity is assumed not to distort the resulting statistics too much. • The hand-written constraints and the statistics are combined using a relaxation algorithm to analyze the test corpus, rising the precision to 96.1% and lowering the recall only to 97.2%. Finally, a reservation must be made: what we have not investigated in this paper is how much of the extra work done with the statistical module could have been done equally well or even better by spending e.g. another day writing a further collection of heuristic rules. As suggested e.g. by Tapanainen and Voutilainen (1994) and Chanod and Tapanainen (1995), hand-coded heuristics may be a worthwhile addition to &apos;strictly&apos; grammar-based rules. Acknowledgements We wish to thank Timo Jarvinen, Path Tapanainen and two ANLP&apos;97 referees for useful comments on earlier versions of this paper. The first author benefited from the collaboration of Juha Heikkila in the development of the linguistic description used by the EngCG morphological tagger; the two-level compiler for morphological analysis in EngCG was written by Kimmo Koskenniemi; the recent version of the Constraint Grammar parser (CG-2) was written by Pasi Tapana</context>
</contexts>
<marker>Tapanainen, Voutilainen, 1994</marker>
<rawString>P. Tapanainen and A. Voutilainen 1994. Tagging accurately — Don&apos;t guess if you know. In Proceedings of the 4th Conference on Applied Natural Language Processing, ACL. Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C</author>
</authors>
<title>Relaxation and Neural Learning: Points of Convergence and Divergence.</title>
<date>1989</date>
<journal>Journal of Parallel and Distributed Computing,</journal>
<pages>6--217</pages>
<marker>C, 1989</marker>
<rawString>C . Torras. 1989. Relaxation and Neural Learning: Points of Convergence and Divergence. Journal of Parallel and Distributed Computing, 6:217-244</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Heikkila Voutilainen</author>
<author>A Anttila</author>
</authors>
<title>Constraint Grammar of English. A PerformanceOriented Introduction.</title>
<date>1992</date>
<journal>Publications</journal>
<volume>21</volume>
<institution>Department of General Linguistics, University of Helsinki.</institution>
<marker>Voutilainen, Anttila, 1992</marker>
<rawString>A . Voutilainen, J. Heikkila and A. Anttila 1992. Constraint Grammar of English. A PerformanceOriented Introduction. Publications 21, Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Voutilainen</author>
<author>T Jarvinen</author>
</authors>
<title>Specifying a shallow grammatical representation for parsing purposes.</title>
<date>1995</date>
<booktitle>In Proceedings of the 7th meeting of the European Association for Computational Linguistics.</booktitle>
<pages>210--214</pages>
<contexts>
<context position="21418" citStr="Voutilainen and Jarvinen, 1995" startWordPosition="3436" endWordPosition="3439">hich seemed equally legitimate, even when semantic and textual criteria were consulted. In these cases, all the equal alternatives were marked as correct. The benchmark corpus contains 18 words (mainly ING-forms and nonfinite ED-forms) with two correct syntactic analyses. The number of multiple analyses could probably be made even smaller by specifying the grammatical representation (usage principles of the syntactic tags) in more detail, in particular incorporating some analysis conventions for certain apparent borderline cases (for a discussion of specifying a parser&apos;s linguistic task, see (Voutilainen and Jarvinen, 1995)). To improve the objectivity of the evaluation, the benchmark corpus (as well as parser outputs) have been made available from. the following URLs: http / /ww w . helsinki.fir avoutila/an1p97 .html http://www—lsi.upc.esrlluisp/an1p97.html 7 Experiments and results We tested linguistic, statistical and hybrid language models, using the CG-2 parser (Tapanainen, 1996) and the relaxation labelling algorithm described in Section 2. The statistical models were obtained from a training corpus of 218,000 words of journalese, syntactically annotated using the linguistic parser (see above). Although th</context>
</contexts>
<marker>Voutilainen, Jarvinen, 1995</marker>
<rawString>A. Voutilainen and T. Jarvinen. 1995. Specifying a shallow grammatical representation for parsing purposes. In Proceedings of the 7th meeting of the European Association for Computational Linguistics. 210-214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Word-sense disambiguations using statistical models of Roget&apos;s categories trained on large corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of 14th International Conference on Computational Linguistics.</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="22288" citStr="Yarowsky, 1992" startWordPosition="3568" endWordPosition="3569">nd results We tested linguistic, statistical and hybrid language models, using the CG-2 parser (Tapanainen, 1996) and the relaxation labelling algorithm described in Section 2. The statistical models were obtained from a training corpus of 218,000 words of journalese, syntactically annotated using the linguistic parser (see above). Although the linguistic CG-2 parser does not disambiguate completely, it seems to have an almost perfect recall (cf. Table 1 below), and the noise introduced by the remaining ambiguity is assumed to be sufficiently lower than the signal, following the idea used in (Yarowsky, 1992). The collected statistics were bigram and trigram occurrences. The algorithms and models were tested against a hand-disambiguated benchmark corpus of over 6,500 words. We measure the performance of the different models in terms of recall and precision. Recall is the percentage of words that get the correct tag among the tags proposed by the system. Precision is the percentage of tags proposed by the system that are correct. CG-2 parser Rel. Labelling prec. - recall prec. - recall C 90.8% — 99.7% 93.3% — 98.4% Table 1: Results obtained with the linguistic model. Rel. Labelling prec. - recall B</context>
</contexts>
<marker>Yarowsky, 1992</marker>
<rawString>D. Yarowsky. 1992. Word-sense disambiguations using statistical models of Roget&apos;s categories trained on large corpora. In Proceedings of 14th International Conference on Computational Linguistics. Nantes, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>