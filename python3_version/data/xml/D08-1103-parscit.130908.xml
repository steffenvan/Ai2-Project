<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002289">
<title confidence="0.990565">
Computing Word-Pair Antonymy
</title>
<author confidence="0.993203">
Saif Mohammadf Bonnie Dorr Graeme Hirstφ
</author>
<affiliation confidence="0.989442666666667">
f Laboratory for Computational Linguistics and Information Processing
f Institute for Advanced Computer Studies and Computer Science
f University of Maryland and Human Language Technology Center of Excellence
</affiliation>
<email confidence="0.780171">
saif,bonnie @umiacs.umd.edu
</email>
<affiliation confidence="0.998854">
φDepartment of Computer Science
University of Toronto
</affiliation>
<email confidence="0.99837">
gh@cs.toronto.edu
</email>
<sectionHeader confidence="0.995636" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999493769230769">
Knowing the degree of antonymy between
words has widespread applications in natural
language processing. Manually-created lexi-
cons have limited coverage and do not include
most semantically contrasting word pairs. We
present a new automatic and empirical mea-
sure of antonymy that combines corpus statis-
tics with the structure of a published the-
saurus. The approach is evaluated on a set of
closest-opposite questions, obtaining a preci-
sion of over 80%. Along the way, we discuss
what humans consider antonymous and how
antonymy manifests itself in utterances.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999929346153847">
Native speakers of a language intuitively recog-
nize different degrees of antonymy—whether two
words are strongly antonymous (hot–cold, good-
bad, friend–enemy), just semantically contrasting
(enemy–fan, cold–lukewarm, ascend–slip) or not
antonymous at all (penguin–clown, cold–chilly,
boat–rudder). Over the years, many definitions of
antonymy have been proposed by linguists (Cruse,
1986; Lehrer and Lehrer, 1982), cognitive scien-
tists (Kagan, 1984), psycholinguists (Deese, 1965),
and lexicographers (Egan, 1984), which differ from
each other in small and large respects. In its
strictest sense, antonymy applies to gradable adjec-
tives, such as hot–cold and tall–short, where the
two words represent the two ends of a semantic
dimension. In a broader sense, it includes other
adjectives, nouns, and verbs as well (life–death,
ascend–descend, shout–whisper). In its broadest
sense, it applies to any two words that represent
contrasting meanings. We will use the term de-
gree of antonymy to encompass the complete se-
mantic range—a combined measure of the contrast
in meaning conveyed by two words and the tendency
of native speakers to call them opposites. The higher
the degree of antonymy between a target word pair,
the greater the semantic contrast between them and
the greater their tendency to be considered antonym
pairs by native speakers.
Automatically determining the degree of
antonymy between words has many uses includ-
ing detecting and generating paraphrases (The
dementors caught Sirius Black / Black could not
escape the dementors) and detecting contradictions
(Marneffe et al., 2008; Voorhees, 2008) (Kyoto has
a predominantly wet climate / It is mostly dry in
Kyoto). Of course, such “contradictions” may be
a result of differing sentiment, new information,
non-coreferent mentions, or genuinely contradictory
statements. Antonyms often indicate the discourse
relation of contrast (Marcu and Echihabi, 2002).
They are also useful for detecting humor (Mihalcea
and Strapparava, 2005), as satire and jokes tend
to have contradictions and oxymorons. Lastly, it
is useful to know which words are semantically
contrasting to a target word, even if simply to filter
them out. For example, in the automatic creation
of a thesaurus it is necessary to distinguish near-
synonyms from word pairs that are semantically
contrasting. Measures of distributional similarity
fail to do so. Detecting antonymous words is not
sufficient to solve most of these problems, but it
remains a crucial, and largely unsolved, component.
</bodyText>
<page confidence="0.922473">
982
</page>
<note confidence="0.9624565">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 982–991,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999791076923077">
Lexicons of pairs of words that native speakers
consider antonyms have been created for certain lan-
guages, but their coverage has been limited. Further,
as each term of an antonymous pair can have many
semantically close terms, the contrasting word pairs
far outnumber those that are commonly considered
antonym pairs, and they remain unrecorded. Even
though a number of computational approaches have
been proposed for semantic closeness, and some for
hypernymy–hyponymy (Hearst, 1992), measures of
antonymy have been less successful. To some ex-
tent, this is because antonymy is not as well under-
stood as other classical lexical-semantic relations.
We first very briefly summarize insights and in-
tuitions about this phenomenon, as proposed by lin-
guists and lexicographers (Section 2). We discuss
related work (Section 3). We describe the resources
we use (Section 4) and present experiments that ex-
amine the manifestation of antonymy in text (Sec-
tions 5 and 6). We then propose a new empirical
approach to determine the degree of antonymy be-
tween two words (Section 7). We compiled a dataset
of 950 closest-opposite questions, which we used for
evaluation (Section 8). We conclude with a discus-
sion of the merits and limitations of this approach
and outline future work.
</bodyText>
<sectionHeader confidence="0.789153" genericHeader="introduction">
2 The paradoxes of antonymy
</sectionHeader>
<bodyText confidence="0.999896333333333">
Antonymy, like synonymy and hyponymy, is a
lexical-semantic relation that, strictly speaking, ap-
plies to two lexical units—combinations of surface
form and word sense. (That said, for simplicity and
where appropriate we will use the term “antonymous
words” as a proxy for “antonymous lexical units”.)
However, accepting this leads to two interesting and
seemingly paradoxical questions (described below
in the two subsections).
</bodyText>
<subsectionHeader confidence="0.996386">
2.1 Why are some pairs better antonyms?
</subsectionHeader>
<bodyText confidence="0.999925433333333">
Native speakers of a language consider certain con-
trasting word pairs to be antonymous (for example,
large–small), and certain other seemingly equivalent
word pairs as less so (for example, large–little). A
number of reasons have been suggested: (1) Cruse
(1986) observes that if the meaning of the target
words is completely defined by one semantic dimen-
sion and the words represent the two ends of this se-
mantic dimension, then they tend to be considered
antonyms. We will refer to this semantic dimension
as the dimension of opposition. (2) If on the other
hand, as Lehrer and Lehrer (1982) point out, there is
more to the meaning of the antonymous words than
the dimension of opposition—for example, more se-
mantic dimensions or added connotations—then the
two words are not so strongly antonymous. Most
people do not think of chubby as a direct antonym
of thin because it has the additional connotation of
being cute and informal. (3) Cruse (1986) also pos-
tulates that word pairs are not considered strictly
antonymous if it is difficult to identify the dimension
of opposition (for example, city–farm). (4) Charles
and Miller (1989) claim that two contrasting words
are identified as antonyms if they occur together in
a sentence more often than chance. However, Mur-
phy and Andrew (1993) claim that the greater-than-
chance co-occurrence of antonyms in sentences is
because together they convey contrast well, which
is rhetorically useful, and not really the reason why
they are considered antonyms in the first place.
</bodyText>
<subsectionHeader confidence="0.9429835">
2.2 Are semantic closeness and antonymy
opposites?
</subsectionHeader>
<bodyText confidence="0.987367130434783">
Two words (more precisely, two lexical units) are
considered to be close in meaning if there is a
lexical-semantic relation between them. Lexical-
semantic relations are of two kinds: classical
and non-classical. Examples of classical rela-
tions include synonymy, hyponymy, troponymy, and
meronymy. Non-classical relations, as pointed out
by Morris and Hirst (2004), are much more com-
mon and include concepts pertaining to another con-
cept (kind, chivalrous, formal pertaining to gentle-
manly), and commonly co-occurring words (for ex-
ample, problem–solution pairs such as homeless,
shelter). Semantic distance (or closeness) in this
broad sense is known as semantic relatedness. Two
words are considered to be semantically similar if
they are associated via the synonymy, hyponymy–
hypernymy, or the troponymy relation. So terms
that are semantically similar (plane–glider, doctor–
surgeon) are also semantically related, but terms that
are semantically related may not always be semanti-
cally similar (plane–sky, surgeon–scalpel).
Antonymy is unique among these relations be-
cause it simultaneously conveys both a sense of
</bodyText>
<page confidence="0.998796">
983
</page>
<bodyText confidence="0.916218333333333">
closeness and of distance (Cruse, 1986). Antony-
mous concepts are semantically related but not se-
mantically similar.
</bodyText>
<sectionHeader confidence="0.999852" genericHeader="method">
3 Related work
</sectionHeader>
<bodyText confidence="0.999942453125">
Charles and Miller (1989) proposed that antonyms
occur together in a sentence more often than chance.
This is known as the co-occurrence hypothesis.
They also showed that this was empirically true for
four adjective antonym pairs. Justeson and Katz
(1991) demonstrated the co-occurrence hypothesis
for 35 prototypical antonym pairs (from an original
set of 39 antonym pairs compiled by Deese (1965))
and also for an additional 22 frequent antonym pairs.
All of these pairs were adjectives. Fellbaum (1995)
conducted similar experiments on 47 noun, verb, ad-
jective, and adverb pairs (noun–noun, noun–verb,
noun–adjective, verb–adverb and so on) pertaining
to 18 concepts (for example, lose(v)–gain(n) and
loss(n)–gain(n), where lose(v) and loss(n) pertain to
the concept of “failing to have/maintain”). How-
ever, non-antonymous semantically related words
such as hypernyms, holonyms, meronyms, and near-
synonyms also tend to occur together more often
than chance. Thus, separating antonyms from them
has proven to be difficult.
Lin et al. (2003) used patterns such as “from X
to Y” and “either X or Y” to separate antonym word
pairs from distributionally similar pairs. They eval-
uated their method on 80 pairs of antonyms and 80
pairs of synonyms taken from the Webster’s Colle-
giate Thesaurus (Kay, 1988). In this paper, we pro-
pose a method to determine the degree of antonymy
between any word pair and not just those that are
distributionally similar. Turney (2008) proposed a
uniform method to solve word analogy problems
that require identifying synonyms, antonyms, hyper-
nyms, and other lexical-semantic relations between
word pairs. However, the Turney method is super-
vised whereas the method proposed in this paper is
completely unsupervised.
Harabagiu et al. (2006) detected antonyms
for the purpose of identifying contradictions
by using WordNet chains—synsets connected by
the hypernymy–hyponymy links and exactly one
antonymy link. Lucerto et al. (2002) proposed de-
tecting antonym pairs using the number of words
between two words in text and also cue words such
as but, from, and and. Unfortunately, they evalu-
ated their method on only 18 word pairs. Neither of
these methods determines the degree of antonymy
between words and they have not been shown to
have substantial coverage. Schwab et al. (2002) cre-
ate “antonymous vector” for a target word. The
closer this vector is to the context vectors of the
other target word, the more antonymous the two tar-
get words are. However, the antonymous vectors are
manually created. Further, the approach is not eval-
uated beyond a handful of word pairs.
Work in sentiment detection and opinion mining
aims at determining the polarity of words. For ex-
ample, Pang, Lee and Vaithyanathan (2002) detect
that adjectives such as dazzling, brilliant, and grip-
ping cast their qualifying nouns positively whereas
adjectives such as bad, cliched, and boring portray
the noun negatively. Many of these gradable adjec-
tives have antonyms. but these approaches do not
attempt to determine pairs of positive and negative
polarity words that are antonyms.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="method">
4 Resources
</sectionHeader>
<subsectionHeader confidence="0.999588">
4.1 Published thesauri
</subsectionHeader>
<bodyText confidence="0.999995857142857">
Published thesauri, such as the Roget’s and Mac-
quarie, divide the vocabulary into about a thousand
categories. Words within a category tend to be near-
synonymous or semantically similar. One may also
find antonymous and semantically related words in
the same category, but this is rare. The intuition
is that words within a category represent a coarse
concept. Words with more than one meaning may
be found in more than one category; these repre-
sent its coarse senses. Within a category, the words
are grouped into paragraphs. Words in the same
paragraph tend to be closer in meaning than those in
different paragraphs. We will take advantage of the
structure of the thesaurus in our approach.
</bodyText>
<subsectionHeader confidence="0.969236">
4.2 WordNet
</subsectionHeader>
<bodyText confidence="0.999964">
Unlike the traditional approach to antonymy, Word-
Net encodes antonymy as a lexical relationship—a
relation between two words (not concepts) (Gross et
al., 1989). Even though a synset (a WordNet con-
cept) may be represented by more than one word,
individual words across synsets are marked as (di-
</bodyText>
<page confidence="0.994679">
984
</page>
<bodyText confidence="0.999955333333333">
rect) antonyms. Gross et al. argue that other words
in the synsets form “indirect antonyms”.
Even after including the indirect antonyms, Word-
Net’s coverage is limited. As Marcu and Echi-
habi (2002) point out, WordNet does not en-
code antonymy across part-of-speech (for exam-
ple, legally–embargo). Further, the noun–noun,
verb–verb, and adjective–adjective antonym pairs of
WordNet largely ignore near-opposites as revealed
by our experiments (Section 8 below). Also, Word-
Net (or any other manually-created repository of
antonyms for that matter) does not encode the de-
gree of antonymy between words. Nevertheless, we
investigate the usefulness of WordNet as a source of
seed antonym pairs for our approach.
</bodyText>
<subsectionHeader confidence="0.997504">
4.3 Co-occurrence statistics
</subsectionHeader>
<bodyText confidence="0.999877058823529">
The distributional hypothesis of closeness states
that words that occur in similar contexts tend to
be semantically close (Firth, 1957). Distributional
measures of distance, such as those proposed by Lin
(1998), quantify how similar the two sets of contexts
of a target word pair are. Equation 1 is a modified
form of Lin’s measure that ignores syntactic depen-
dencies and hence it estimates semantic relatedness
rather than semantic similarity:
Here w1 and w2 are the target words; I x y is the
pointwise mutual information between x and y; and
T x is the set of all words y that have positive point-
wise mutual information with the word x (I x y
0).
Mohammad and Hirst (2006) showed that
these distributional word-distance measures per-
form poorly when compared with WordNet-based
concept-distance measures. They argued that this
is because the word-distance measures clump to-
gether the contexts of the different senses of the tar-
get words. They proposed a way to obtain distri-
butional distance between word senses, using any
of the distributional measures such as cosine or that
proposed by Lin, and showed that this approach per-
formed markedly better than the traditional word-
distance approach. They used thesaurus categories
as very coarse word senses. Equation 2 shows how
Lin’s formula is used to determine distributional dis-
tance between two thesaurus categories c1 and c2:
Here T c is the set of all words w that have posi-
tive pointwise mutual information with the thesaurus
category c (I c w 0). We adopt this method
for use in our approach to determine word-pair
antonymy.
</bodyText>
<sectionHeader confidence="0.888368" genericHeader="method">
5 The co-occurrence hypothesis of
antonyms
</sectionHeader>
<bodyText confidence="0.999971076923077">
As a first step towards formulating our approach,
we investigated the co-occurrence hypothesis on a
significantly larger set of antonym pairs than those
studied before. We randomly selected a thousand
antonym pairs (nouns, verbs, and adjectives) from
WordNet and counted the number of times (1) they
occurred individually and (2) they co-occurred in the
same sentence within a window of five words, in the
British National Corpus (BNC) (Burnard, 2000). We
then calculated the mutual information for each of
these word pairs and averaged it. We randomly gen-
erated another set of a thousand word pairs, without
regard to whether they were antonymous or not, and
used it as a control set. The average mutual infor-
mation between the words in the antonym set was
0.94 with a standard deviation of 2.27. The average
mutual information between the words in the con-
trol set was 0.01 with a standard deviation of 0.37.
Thus antonymous word pairs occur together much
more often than chance irrespective of their intended
senses (p 001). Of course, a number of non-
antonymous words also tend to co-occur more of-
ten than chance—commonly known as collocations.
Thus, strong co-occurrence is not a sufficient condi-
tion for detecting antonyms, but these results show
that it can be a useful cue.
</bodyText>
<sectionHeader confidence="0.750707" genericHeader="method">
6 The substitutional and distributional
</sectionHeader>
<subsectionHeader confidence="0.678232">
hypotheses of antonyms
</subsectionHeader>
<bodyText confidence="0.9877045">
Charles and Miller (1989) also proposed that in
most contexts, antonyms may be interchanged. The
</bodyText>
<equation confidence="0.958599166666667">
Lin w1 w2
Y—w Tw1 Tw2 I w1 w I w2 w (1)
Y—w Tw1 I w1 w Y—w Tw2 I w2 w
Lin c1 c2
Y—w Tc1 Tc2 I c1 w I c2 w (2)
Y—w Tc1 I c1 w Y—w Tc2 I c2 w
</equation>
<page confidence="0.987234">
985
</page>
<bodyText confidence="0.9846275">
meaning of the utterance will be inverted, of course,
but the sentence will remain grammatical and lin-
guistically plausible. This came to be known as the
substitutability hypothesis. However, their exper-
iments did not support this claim. They found that
given a sentence with the target adjective removed,
most people did not confound the missing word with
its antonym. Justeson and Katz (1991) later showed
that in sentences that contain both members of an
antonymous adjective pair, the target adjectives do
indeed occur in similar syntactic structures at the
phrasal level. From this (and to some extent from the
co-occurrence hypothesis), we can derive the distri-
butional hypothesis of antonyms: antonyms occur
in similar contexts more often than non-antonymous
words.
We used the same set of one thousand antonym
pairs and one thousand control pairs as in the pre-
vious experiment to gather empirical proof of the
distributional hypothesis. For each word pair from
the antonym set, we calculated the distributional dis-
tance between each of their senses using Moham-
mad and Hirst’s (2006) method of concept distance
along with the modified form of Lin’s (1998) dis-
tributional measure (equation 2). The distance be-
tween the closest senses of the word pairs was av-
eraged for all thousand antonyms. The process was
then repeated for the control set.
The control set had an average semantic close-
ness of 0.23 with a standard deviation of 0.11 on
a scale from 0 (unrelated) to 1 (identical). On the
other hand, antonymous word pairs had an average
semantic closeness of 0.30 with a standard devia-
tion of 0.23.1 This demonstrates that relative to other
word pairs, antonymous words tend to occur in simi-
lar contexts (p 001). However, near-synonymous
and similar word pairs also occur in similar contexts.
(the distributional hypothesis of closeness). Thus,
just like the co-occurrence hypothesis, occurrence
in similar contexts is not sufficient, but rather yet
another useful cue towards detecting antonyms.
&apos;It should be noted that absolute values in the range between
0 and 1 are meaningless by themselves. However, if a set of
word pairs is shown to consistently have higher values than an-
other set, then we can conclude that the members of the former
set tend to be semantically closer than those of the latter.
</bodyText>
<sectionHeader confidence="0.936972" genericHeader="method">
7 Our approach
</sectionHeader>
<bodyText confidence="0.99996475">
We now present an empirical approach to determine
the degree of antonymy between words. In order
to maximize applicability and usefulness in natural
language applications, we model the broad sense of
antonymy. Given a target word pair, the approach
determines whether they are antonymous or not, and
if they are antonymous whether they have a high,
medium, or low degree of antonymy. More pre-
cisely, the approach presents a way to determine
whether one word pair is more antonymous than an-
other.
The approach relies on the structure of the pub-
lished thesaurus as well as the co-occurrence and
distributional hypotheses. As mentioned earlier, a
thesaurus organizes words in sets representing con-
cepts or categories. We first determine pairs of the-
saurus categories that are contrasting in meaning
(Section 7.1). We then use the co-occurrence and
distributional hypotheses to determine the degree of
antonymy (Section 7.2).
</bodyText>
<subsectionHeader confidence="0.999382">
7.1 Detecting contrasting categories
</subsectionHeader>
<bodyText confidence="0.999841166666667">
We propose two ways of detecting thesaurus cate-
gory pairs that represent contrasting concepts (we
will call these pairs contrasting categories): (1) us-
ing a seed set of antonyms and (2) using a simple
heuristic that exploits how thesaurus categories are
ordered.
</bodyText>
<subsectionHeader confidence="0.559329">
7.1.1 Seed sets
</subsectionHeader>
<bodyText confidence="0.9994338125">
Affix-generated seed set Antonym pairs such as
hot–cold and dark–light occur frequently in text,
but in terms of type-pairs they are outnumbered
by those created using affixes, such as un- (clear–
unclear) and dis- (honest–dishonest). Further, this
phenomenon is observed in most languages (Lyons,
1977).
Table 1 lists sixteen morphological rules that tend
to generate antonyms in English. These rules were
applied to each of the words in the Macquarie The-
saurus and if the resulting term was also a valid
word in the thesaurus, then the word-pair was added
to the affix-generated seed set. These sixteen rules
generated 2,734 word pairs. Of course, not all of
them are antonymous, for example sect–insect and
coy–decoy. However, these are relatively few in
</bodyText>
<page confidence="0.990328">
986
</page>
<table confidence="0.998552153846154">
w1 w2 example pair
X abX normal–abnormal
X antiX clockwise–anticlockwise
X disX interest–disinterest
X imX possible–impossible
X inX consistent–inconsistent
X malX adroit–maladroit
w1 w2 example pair w1 w2 example pair
X misX fortune–misfortune imX exX implicit–explicit
X nonX aligned–nonaligned inX exX introvert–extrovert
X unX biased–unbiased upX downX uphill–downhill
lX illX legal–illegal overX underX overdone–underdone
rX irX regular–irregular Xless Xful harmless–harmful
</table>
<tableCaption confidence="0.989312">
Table 1: Sixteen affix rules to generate antonym pairs. Here ‘X’ stands for any sequence of letters common to both
words w1 and w2.
</tableCaption>
<bodyText confidence="0.999978432432433">
number and were found to have only a small impact
on the results.
WordNet seed set We compiled a list of 20,611
semantically contrasting word pairs from WordNet.
If two words from two synsets in WordNet are con-
nected by an antonymy link, then every possible
word pair across the two synsets was considered to
be semantically contrasting. A large number of them
include multiword expressions. For only 10,807 of
the 20,611 pairs were both words found in the Mac-
quarie Thesaurus—the vocabulary used for our ex-
periments. We will refer to them as the WordNet
seed set.
Then, given these two seed sets, if any word in
thesaurus category C1 is antonymous to any word
in category C2 as per a seed antonym pair, then the
two categories are marked as contrasting. It should
be noted, however, that the seed antonym pair may
be antonymous only in certain senses. For example,
consider the antonym pair work–play. Here, play is
antonymous to work only in its ACTIVITY FOR FUN
sense and not its DRAMA sense. In such cases, we
employ the distributional hypothesis of closeness:
two words are antonymous to each other in those
senses which are closest in meaning to each other.
Since the thesaurus category pertaining to WORK is
relatively closer in meaning to the ACTIVITY FOR
FUN sense than the DRAMA sense, those two cat-
egories will be considered contrasting and not the
categories pertaining to WORK and DRAMA.
If no word in C1 is antonymous to any word in C2,
then the categories are considered not contrasting.
As the seed sets, both automatically generated and
manually created, are relatively large in comparison
to the total number of categories in the Macquarie
Thesaurus (812), this simple approach has reason-
able coverage and accuracy.
</bodyText>
<subsectionHeader confidence="0.872803">
7.1.2 Order of thesaurus categories
</subsectionHeader>
<bodyText confidence="0.9999164">
Most published thesauri are ordered such that
contrasting categories tend to be adjacent. This is
not a hard-and-fast rule, and often a category may be
contrasting in meaning to several other categories.
Further, often adjacent categories are not semanti-
cally contrasting. However, since this was an easy-
enough heuristic to implement, we investigated the
usefulness of considering adjacent categories as con-
trasting. We will refer to this as the adjacency
heuristic.
</bodyText>
<subsectionHeader confidence="0.996984">
7.2 Determining the degree of antonymy
</subsectionHeader>
<bodyText confidence="0.9999774">
Once we know which category pairs are contrast-
ing (using the methods from the previous subsec-
tion), we determine the degree of antonymy be-
tween the two categories (Section 7.2.1). The aim
is to assign contrasting category pairs a non-zero
value signifying the degree of contrast. In turn, we
will use that information to determine the degree of
antonymy between any word pair whose members
belong to two contrasting categories (Sections 7.2.2
and 7.2.3).
</bodyText>
<subsectionHeader confidence="0.679097">
7.2.1 Category level
</subsectionHeader>
<bodyText confidence="0.999980230769231">
Using the distributional hypothesis of antonyms,
we claim that the degree of antonymy between two
contrasting concepts (thesaurus categories) is di-
rectly proportional to the distributional closeness of
the two concepts. In other words, the more the words
representing two contrasting concepts occur in sim-
ilar contexts, the more the two concepts are consid-
ered to be antonymous.
Again we used Mohammad and Hirst’s (2006)
method along with Lin’s (1998) distributional mea-
sure to determine the distributional closeness of
two thesaurus concepts. Co-occurrence statistics re-
quired for the approach were computed from the
</bodyText>
<page confidence="0.995968">
987
</page>
<bodyText confidence="0.97756">
BNC. Words that occurred within a window of 5
words were considered to co-occur.
</bodyText>
<subsectionHeader confidence="0.819468">
7.2.2 Lexical unit level
</subsectionHeader>
<bodyText confidence="0.99998525">
Recall that strictly speaking, antonymy (like other
lexical-semantic relations) applies to lexical units (a
combination of surface form and word sense). If
two words are used in senses pertaining to contrast-
ing categories (as per the methods described in Sec-
tion 7.1), then we will consider them to be antony-
mous (degree of antonymy is greater than zero).
If two words are used in senses pertaining to non-
contrasting senses, then we will consider them to be
not antonymous (degree of antonymy is equal to 0).
If the target words belong to the same thesaurus
paragraphs as any of the seed antonyms linking the
two contrasting categories, then the words are con-
sidered to have a high degree of antonymy. This is
because words that occur in the same thesaurus para-
graph tend to be semantically very close in mean-
ing. Relying on the co-occurrence hypothesis, we
claim that for word pairs listed in contrasting cate-
gories, the greater their tendency to co-occur in text,
the higher their degree of antonymy. We use mutual
information to capture the tendency of word–word
co-occurrence.
If the target words do not both belong to the same
paragraphs as a seed antonym pair, but occur in con-
trasting categories, then the target words are consid-
ered to have a low or medium degree of antonymy
(less antonymous than the word pairs discussed
above). Such word pairs that have a higher tendency
to co-occur are considered to have a medium degree
of antonymy, whereas those that have a lower ten-
dency to co-occur are considered to have a low de-
gree of antonymy.
Co-occurrence statistics for this purpose were col-
lected from the Google n-gram corpus (Brants and
Franz, 2006).2 Words that occurred within a window
of 5 words were considered to be co-occurring.
</bodyText>
<subsectionHeader confidence="0.915356">
7.2.3 Word level
</subsectionHeader>
<bodyText confidence="0.930801958333333">
Even though antonymy applies to pairs of word
and sense combinations, most available texts are not
2We used the Google n-gram corpus is created from a text
collection of over 1 trillion words. We intend to use the same
corpus (and not the BNC) to determine semantic distance as
well, in the near future.
sense-annotated. If antonymous occurrences are to
be exploited for any of the purposes listed in the be-
ginning of this paper, then the text must be sense
disambiguated. However, word sense disambigua-
tion is a hard problem. Yet, and to some extent be-
cause unsupervised word sense disambiguation sys-
tems perform poorly, much can be gained by using
simple heuristics. For example, it has been shown
that cohesive text tends to have words that are close
in meaning rather than unrelated words. This, along
with the distributional hypothesis of antonyms, and
the findings by Justeson and Katz (1991) (antony-
mous concepts tend to occur more often than chance
in the same sentence), suggests that if we find a word
pair in a sentence such that two of its senses are
strongly contrasting (as per the algorithm described
in Section 7.2.2), then it is probable that the two
words are used in those contrasting senses.
</bodyText>
<sectionHeader confidence="0.987631" genericHeader="evaluation">
8 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.998696">
8.1 Task and data
</subsectionHeader>
<bodyText confidence="0.99975268">
In order to best evaluate a computational measure
of antonymy, we need a task that not only requires
knowing whether two words are antonymous but
also whether one word pair is more antonymous than
another pair. Therefore, we evaluated our system on
a set of closest-opposite questions. Each question
has one target word and five alternatives. The objec-
tive is to identify that alternative which is the closest
opposite of the target. For example, consider:
adulterate: a. renounce b. forbid
c. purify d. criticize e. correct
Here the target word is adulterate. One of the al-
ternatives provided is correct, which as a verb has a
meaning that contrasts with that of adulterate; how-
ever, purify has a greater degree of antonymy with
adulterate than correct does and must be chosen
in order for the instance to be marked as correctly
answered. This evaluation is similar to how oth-
ers have evaluated semantic distance algorithms on
TOEFL synonym questions (Turney, 2001), except
that in those cases the system had to choose the al-
ternative which is closest in meaning to the target.
We looked on the World Wide Web for large sets
of closest antonym questions. We found two inde-
pendent sets of questions designed to prepare stu-
</bodyText>
<page confidence="0.993975">
988
</page>
<table confidence="0.975490125">
development data test data
P R F P R F
0.20 0.20 0.20 0.20 0.20 0.20
0.72 0.53 0.61 0.71 0.51 0.60
0.79 0.52 0.63 0.75 0.50 0.60
0.77 0.65 0.70 0.73 0.60 0.65
0.81 0.43 0.56 0.83 0.46 0.59
0.75 0.60 0.67 0.76 0.61 0.68
0.76 0.66 0.70 0.76 0.64 0.70
a. random baseline
b. affix-generated seeds only
c. WordNet seeds only
d. both seed sets
e. adjacency heuristic only
f. affix seed set + heuristic
g. both seed sets + heuristic
</table>
<tableCaption confidence="0.999599">
Table 2: Results obtained on closest-opposite questions.
</tableCaption>
<bodyText confidence="0.999730142857143">
dents for the Graduate Record Examination.3 The
first set consists of 162 questions. We used this set
to develop our approach and will refer to it as the de-
velopment set. Even though the algorithm does not
have any tuned parameters per se, the development
set helped determine which cues of antonymy were
useful and which were not. The second set has 1208
closest-opposite questions. We discarded questions
that had a multiword target or alternative. After re-
moving duplicates we were left with 950 questions,
which we used as the unseen test set.
Interestingly, the data contains many instances
that have the same target word used in different
senses. For example:
</bodyText>
<listItem confidence="0.9979152">
(1) obdurate: a. meager b. unsusceptible
c. right d. tender e. intelligent
(2) obdurate: a. yielding b. motivated
c. moribund d. azure e. hard
(3) obdurate: a. transitory b. commensurate
</listItem>
<bodyText confidence="0.979113875">
c. complaisant d. similar e. uncommunicative
In (1), obdurate is used in the HARDENED IN FEEL-
INGS sense and the closest opposite is tender. In (2),
it is used in the RESISTANT TO PERSUASION sense
and the closest opposite is yielding. In (3), it is used
in the PERSISTENT sense and the closest opposite is
transitory.
The datasets also contain questions in which one
or more of the alternatives is a near-synonym of the
target word. For example:
astute: a. shrewd b. foolish
c. callow d. winning e. debating
Observe that shrewd is a near-synonym of astute.
The closest-opposite of astute is foolish. A man-
ual check of a randomly selected set of 100 test-set
questions revealed that, on overage, one in four had
</bodyText>
<footnote confidence="0.731061">
3Both datasets are apparently in the public domain and will
be made available on request.
a near-synonym as one of the alternative.
</footnote>
<subsectionHeader confidence="0.876476">
8.2 Experiments
</subsectionHeader>
<bodyText confidence="0.999988484848485">
We used the algorithm proposed in Section 7 to auto-
matically solve the closest-opposite questions. Since
individual words may have more than one mean-
ing, we relied on the hypothesis that the intended
sense of the alternatives are those which are most
antonymous to one of the senses of the target word.
(This follows from the discussion earlier in Section
7.2.3.) So for each of the alternatives we used the
target word as context (but not the other alterna-
tives). We think that using a larger context to de-
termine antonymy will be especially useful when
the target words are found in sentences and natural
text—something we intend to explore in the future.
Table 2 presents results obtained on the develop-
ment and test data using different combinations of
the seed sets and the adjacency heuristic. If the sys-
tem did not find any evidence of antonymy between
the target and any of its alternatives, then it refrained
from attempting that question. We therefore report
precision (number of questions answered correctly /
number of questions attempted), recall (number of
questions answered correctly / total number of ques-
tions), and F-score values (2 P R P R ).
Observe that all results are well above the ran-
dom baseline of 0.20 (obtained when a system ran-
domly guesses one of the five alternatives to be the
answer). Also, using only the small set of sixteen
affix rules, the system performs almost as well as
when it uses 10,807 WordNet antonym pairs. Using
both the affix-generated and the WordNet seed sets,
the system obtains markedly improved precision and
coverage. Using only the adjacency heuristic gave
best precision values (upwards of 0.8) with substan-
</bodyText>
<page confidence="0.996661">
989
</page>
<bodyText confidence="0.99988725">
tial coverage (attempting close to half the questions).
However, best overall performance was obtained us-
ing both seed sets and the adjacency heuristic (F-
score of 0.7).
</bodyText>
<subsectionHeader confidence="0.876786">
8.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999996793103448">
These results show that, to some degree, the auto-
matic approach does indeed mimic human intuitions
of antonymy. In tasks that require higher precision,
using only the adjacency heuristic is best, whereas
in tasks that require both precision and coverage, the
seed sets may be included. Even when both seed sets
were included, only four instances in the develop-
ment set and twenty in the test set had target–answer
pairs that matched a seed antonym pair. For all re-
maining instances, the approach had to generalize to
determine the closest opposite. This also shows that
even the seemingly large number of direct and in-
direct antonyms from WordNet (more than 10,000)
are by themselves insufficient.
The comparable performance obtained using the
affix rules alone suggests that even in languages
without a wordnet, substantial accuracies may be
achieved. Of course, improved results when using
WordNet antonyms as well suggests that the infor-
mation they provide is complementary.
Error analysis revealed that at times the system
failed to identify that a category pertaining to the
target word contrasted with a category pertaining
to the answer. Additional methods to identify seed
antonym pairs will help in such cases. Certain other
errors occurred because one or more alternatives
other than the official answer were also antonymous
to the target. For example, the system chose accept
as the opposite of chasten instead of reward.
</bodyText>
<sectionHeader confidence="0.996143" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999993161290323">
We have proposed an empirical approach to
antonymy that combines corpus co-occurrence
statistics with the structure of a published thesaurus.
The method can determine the degree of antonymy
or contrast between any two thesaurus categories
(sets of words representing a coarse concept) and
between any two word pairs. We evaluated the ap-
proach on a large set of closest-opposite questions
wherein the system not only identified whether two
words are antonymous but also distinguished be-
tween pairs of antonymous words of different de-
grees. It achieved an F-score of 0.7 in this task where
the random baseline was only 0.2. When aiming for
high precision it scores over 0.8, but there is some
drop in the number of questions attempted. In the
process of developing this approach we validated the
co-occurrence hypothesis proposed by Charles and
Miller (1989) on a large set of 1000 noun, verb, and
adjective pairs. We also gave empirical proof that
antonym pairs tend to be used in similar contexts—
the distributional hypothesis for antonyms.
Our future goals include porting this approach
to a cross-lingual framework in order to determine
antonymy in a resource-poor language by combin-
ing its text with a thesaurus from a resource-rich
language. We will use antonym pairs to identify
contrast relations between sentences to in turn im-
prove automatic summarization. We also intend to
use the approach proposed here in tasks where key-
word matching is especially problematic, for exam-
ple, separating paraphrases from contradictions.
</bodyText>
<sectionHeader confidence="0.997475" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999981">
We thank Smaranda Muresan, Siddharth Patward-
han, members of the CLIP lab at the University of
Maryland, College Park, and the anonymous review-
ers for their valuable feedback. This work was sup-
ported, in part, by the National Science Foundation
under Grant No. IIS-0705832, in part, by the Human
Language Technology Center of Excellence, and in
part, by the Natural Sciences and Engineering Re-
search Council of Canada. Any opinions, findings,
and conclusions or recommendations expressed in
this material are those of the authors and do not nec-
essarily reflect the views of the sponsor.
</bodyText>
<sectionHeader confidence="0.998596" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9991631">
Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram
version 1. Linguistic Data Consortium.
Lou Burnard. 2000. Reference Guide for the British
National Corpus (World Edition). Oxford University
Computing Services.
Walter G. Charles and George A. Miller. 1989. Con-
texts of antonymous adjectives. Applied Psychology,
10:357–375.
David A. Cruse. 1986. Lexical semantics. Cambridge
University Press.
</reference>
<page confidence="0.968704">
990
</page>
<reference confidence="0.999890294117647">
James Deese. 1965. The structure of associations in lan-
guage and thought. The Johns Hopkins Press.
Rose F. Egan. 1984. Survey of the history of English
synonymy. Webster’s New Dictionary of Synonyms,
pages 5a–25a.
Christiane Fellbaum. 1995. Co-occurrence and
antonymy. International Journal of Lexicography,
8:281–303.
John R. Firth. 1957. A synopsis of linguistic theory
1930–55. In Studies in Linguistic Analysis, pages 1–
32, Oxford: The Philological Society. (Reprinted in
F.R. Palmer (ed.), Selected Papers of J.R. Firth 1952-
1959, Longman).
Derek Gross, Ute Fischer, and George A. Miller. 1989.
Antonymy and the representation of adjectival mean-
ings. Memory and Language, 28(1):92–106.
Sanda M. Harabagiu, Andrew Hickl, and Finley Laca-
tusu. 2006. Lacatusu: Negation, contrast and contra-
diction in text processing. In Proceedings of the 23rd
National Conference on Artificial Intelligence (AAAI-
06), Boston, MA.
Marti Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the Fourteenth International Conference on Computa-
tional Linguistics, pages 539–546, Nantes, France.
John S. Justeson and Slava M. Katz. 1991. Co-
occurrences of antonymous adjectives and their con-
texts. Computational Linguistics, 17:1–19.
Jerome Kagan. 1984. The Nature of the Child. Basic
Books.
Maire Weir Kay, editor. 1988. Webster’s Collegiate The-
saurus. Merrian-Webster.
Adrienne Lehrer and K. Lehrer. 1982. Antonymy. Lin-
guistics and Philosophy, 5:483–501.
Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming Zhou.
2003. Identifying synonyms among distributionally
similar words. In Proceedings of the 18th Inter-
national Joint Conference on Artificial Intelligence
(IJCAI-03), pages 1492–1493, Acapulco, Mexico.
Dekang Lin. 1998. Automatic retreival and cluster-
ing of similar words. In Proceedings of the 17th In-
ternational Conference on Computational Linguistics
(COLING-98), pages 768–773, Montreal, Canada.
Cupertino Lucerto, David Pinto, and H´ector Jimi´enez-
Salazar. 2002. An automatic method to identify
antonymy. In Workshop on Lexical Resources and the
Web for Word Sense Disambiguation, pages 105–111,
Puebla, Mexico.
John Lyons. 1977. Semantics, volume 1. Cambridge
University Press.
Daniel Marcu and Abdesammad Echihabi. 2002. An
unsupervised approach to recognizing discourse rela-
tions. In Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics (ACL-
02), Philadelphia, PA.
Marie-Catherine de Marneffe, Anna Rafferty, and
Christopher D. Manning. 2008. Finding contradic-
tions in text. In Proceedings of the 46th Annual Meet-
ing of the Association for Computational Linguistics
(ACL-08), Columbus, OH.
Rada Mihalcea and Carlo Strapparava. 2005. Making
computers laugh: Investigations in automatic humor
recognition. In Proceedings of the Conference on Hu-
man Language Technology and Empirical Methods in
Natural Language Processing, pages 531–538, Van-
couver, Canada.
Saif Mohammad and Graeme Hirst. 2006. Distributional
measures of concept-distance: A task-oriented evalu-
ation. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, Sydney,
Australia.
Jane Morris and Graeme Hirst. 2004. Non-classical
lexical semantic relations. In Proceedings of the
Workshop on Computational Lexical Semantics, HLT,
Boston, MA.
Gregory L. Murphy and Jane M. Andrew. 1993. The
conceptual basis of antonymy and synonymy in adjec-
tives. Journal ofMemory and Language, 32(3):1–19.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using ma-
chine learning techniques. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 79–86, Philadelphia, PA.
Didier Schwab, Mathieu Lafourcade, and Violaine
Prince. 2002. Antonymy and conceptual vectors. In
Proceedings of the 19th International Conference on
Computational Linguistics (COLING-02), pages 904–
910.
Peter Turney. 2001. Mining the web for synonyms:
PMI-IR versus LSA on TOEFL. In Proceedings of the
Twelfth European Conference on Machine Learning,
pages 491–502, Freiburg, Germany.
Peter Turney. 2008. A uniform approach to analogies,
synonyms, antonyms, and associations. In Proceed-
ings of the 22nd International Conference on Com-
putational Linguistics (COLING-08), pages 905–912,
Manchester, UK.
Ellen M Voorhees. 2008. Contradictions and jus-
tifications: Extensions to the textual entailment task.
In Proceedings of the 46th Annual Meeting of the
Association for Computational Linguistics (ACL-08),
Columbus, OH.
</reference>
<page confidence="0.998086">
991
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.200206">
<title confidence="0.998447">Computing Word-Pair Antonymy</title>
<author confidence="0.454512">Dorr Graeme</author>
<degree confidence="0.495606666666667">for Computational Linguistics and Information for Advanced Computer Studies and Computer of Maryland and Human Language Technology Center of</degree>
<email confidence="0.754616">saif,bonnie@umiacs.umd.edu</email>
<affiliation confidence="0.9888765">of Computer University of</affiliation>
<email confidence="0.99909">gh@cs.toronto.edu</email>
<abstract confidence="0.999821071428571">Knowing the degree of antonymy between words has widespread applications in natural language processing. Manually-created lexicons have limited coverage and do not include most semantically contrasting word pairs. We present a new automatic and empirical measure of antonymy that combines corpus statistics with the structure of a published thesaurus. The approach is evaluated on a set of closest-opposite questions, obtaining a precision of over 80%. Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1t 5-gram version 1. Linguistic Data Consortium.</title>
<date>2006</date>
<contexts>
<context position="26407" citStr="Brants and Franz, 2006" startWordPosition="4205" endWordPosition="4208">re the tendency of word–word co-occurrence. If the target words do not both belong to the same paragraphs as a seed antonym pair, but occur in contrasting categories, then the target words are considered to have a low or medium degree of antonymy (less antonymous than the word pairs discussed above). Such word pairs that have a higher tendency to co-occur are considered to have a medium degree of antonymy, whereas those that have a lower tendency to co-occur are considered to have a low degree of antonymy. Co-occurrence statistics for this purpose were collected from the Google n-gram corpus (Brants and Franz, 2006).2 Words that occurred within a window of 5 words were considered to be co-occurring. 7.2.3 Word level Even though antonymy applies to pairs of word and sense combinations, most available texts are not 2We used the Google n-gram corpus is created from a text collection of over 1 trillion words. We intend to use the same corpus (and not the BNC) to determine semantic distance as well, in the near future. sense-annotated. If antonymous occurrences are to be exploited for any of the purposes listed in the beginning of this paper, then the text must be sense disambiguated. However, word sense disa</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram version 1. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>Reference Guide for the British National Corpus (World Edition).</title>
<date>2000</date>
<institution>Oxford University Computing Services.</institution>
<contexts>
<context position="15194" citStr="Burnard, 2000" startWordPosition="2359" endWordPosition="2360"> with the thesaurus category c (I c w 0). We adopt this method for use in our approach to determine word-pair antonymy. 5 The co-occurrence hypothesis of antonyms As a first step towards formulating our approach, we investigated the co-occurrence hypothesis on a significantly larger set of antonym pairs than those studied before. We randomly selected a thousand antonym pairs (nouns, verbs, and adjectives) from WordNet and counted the number of times (1) they occurred individually and (2) they co-occurred in the same sentence within a window of five words, in the British National Corpus (BNC) (Burnard, 2000). We then calculated the mutual information for each of these word pairs and averaged it. We randomly generated another set of a thousand word pairs, without regard to whether they were antonymous or not, and used it as a control set. The average mutual information between the words in the antonym set was 0.94 with a standard deviation of 2.27. The average mutual information between the words in the control set was 0.01 with a standard deviation of 0.37. Thus antonymous word pairs occur together much more often than chance irrespective of their intended senses (p 001). Of course, a number of n</context>
</contexts>
<marker>Burnard, 2000</marker>
<rawString>Lou Burnard. 2000. Reference Guide for the British National Corpus (World Edition). Oxford University Computing Services.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter G Charles</author>
<author>George A Miller</author>
</authors>
<title>Contexts of antonymous adjectives.</title>
<date>1989</date>
<pages>10--357</pages>
<publisher>Applied Psychology,</publisher>
<contexts>
<context position="6570" citStr="Charles and Miller (1989)" startWordPosition="996" endWordPosition="999">he dimension of opposition. (2) If on the other hand, as Lehrer and Lehrer (1982) point out, there is more to the meaning of the antonymous words than the dimension of opposition—for example, more semantic dimensions or added connotations—then the two words are not so strongly antonymous. Most people do not think of chubby as a direct antonym of thin because it has the additional connotation of being cute and informal. (3) Cruse (1986) also postulates that word pairs are not considered strictly antonymous if it is difficult to identify the dimension of opposition (for example, city–farm). (4) Charles and Miller (1989) claim that two contrasting words are identified as antonyms if they occur together in a sentence more often than chance. However, Murphy and Andrew (1993) claim that the greater-thanchance co-occurrence of antonyms in sentences is because together they convey contrast well, which is rhetorically useful, and not really the reason why they are considered antonyms in the first place. 2.2 Are semantic closeness and antonymy opposites? Two words (more precisely, two lexical units) are considered to be close in meaning if there is a lexical-semantic relation between them. Lexicalsemantic relations </context>
<context position="8283" citStr="Charles and Miller (1989)" startWordPosition="1252" endWordPosition="1255">semantic relatedness. Two words are considered to be semantically similar if they are associated via the synonymy, hyponymy– hypernymy, or the troponymy relation. So terms that are semantically similar (plane–glider, doctor– surgeon) are also semantically related, but terms that are semantically related may not always be semantically similar (plane–sky, surgeon–scalpel). Antonymy is unique among these relations because it simultaneously conveys both a sense of 983 closeness and of distance (Cruse, 1986). Antonymous concepts are semantically related but not semantically similar. 3 Related work Charles and Miller (1989) proposed that antonyms occur together in a sentence more often than chance. This is known as the co-occurrence hypothesis. They also showed that this was empirically true for four adjective antonym pairs. Justeson and Katz (1991) demonstrated the co-occurrence hypothesis for 35 prototypical antonym pairs (from an original set of 39 antonym pairs compiled by Deese (1965)) and also for an additional 22 frequent antonym pairs. All of these pairs were adjectives. Fellbaum (1995) conducted similar experiments on 47 noun, verb, adjective, and adverb pairs (noun–noun, noun–verb, noun–adjective, verb</context>
<context position="16111" citStr="Charles and Miller (1989)" startWordPosition="2512" endWordPosition="2515">ntonym set was 0.94 with a standard deviation of 2.27. The average mutual information between the words in the control set was 0.01 with a standard deviation of 0.37. Thus antonymous word pairs occur together much more often than chance irrespective of their intended senses (p 001). Of course, a number of nonantonymous words also tend to co-occur more often than chance—commonly known as collocations. Thus, strong co-occurrence is not a sufficient condition for detecting antonyms, but these results show that it can be a useful cue. 6 The substitutional and distributional hypotheses of antonyms Charles and Miller (1989) also proposed that in most contexts, antonyms may be interchanged. The Lin w1 w2 Y—w Tw1 Tw2 I w1 w I w2 w (1) Y—w Tw1 I w1 w Y—w Tw2 I w2 w Lin c1 c2 Y—w Tc1 Tc2 I c1 w I c2 w (2) Y—w Tc1 I c1 w Y—w Tc2 I c2 w 985 meaning of the utterance will be inverted, of course, but the sentence will remain grammatical and linguistically plausible. This came to be known as the substitutability hypothesis. However, their experiments did not support this claim. They found that given a sentence with the target adjective removed, most people did not confound the missing word with its antonym. Justeson and K</context>
<context position="35329" citStr="Charles and Miller (1989)" startWordPosition="5704" endWordPosition="5707">egories (sets of words representing a coarse concept) and between any two word pairs. We evaluated the approach on a large set of closest-opposite questions wherein the system not only identified whether two words are antonymous but also distinguished between pairs of antonymous words of different degrees. It achieved an F-score of 0.7 in this task where the random baseline was only 0.2. When aiming for high precision it scores over 0.8, but there is some drop in the number of questions attempted. In the process of developing this approach we validated the co-occurrence hypothesis proposed by Charles and Miller (1989) on a large set of 1000 noun, verb, and adjective pairs. We also gave empirical proof that antonym pairs tend to be used in similar contexts— the distributional hypothesis for antonyms. Our future goals include porting this approach to a cross-lingual framework in order to determine antonymy in a resource-poor language by combining its text with a thesaurus from a resource-rich language. We will use antonym pairs to identify contrast relations between sentences to in turn improve automatic summarization. We also intend to use the approach proposed here in tasks where keyword matching is especi</context>
</contexts>
<marker>Charles, Miller, 1989</marker>
<rawString>Walter G. Charles and George A. Miller. 1989. Contexts of antonymous adjectives. Applied Psychology, 10:357–375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Cruse</author>
</authors>
<title>Lexical semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1349" citStr="Cruse, 1986" startWordPosition="183" endWordPosition="184">. The approach is evaluated on a set of closest-opposite questions, obtaining a precision of over 80%. Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances. 1 Introduction Native speakers of a language intuitively recognize different degrees of antonymy—whether two words are strongly antonymous (hot–cold, goodbad, friend–enemy), just semantically contrasting (enemy–fan, cold–lukewarm, ascend–slip) or not antonymous at all (penguin–clown, cold–chilly, boat–rudder). Over the years, many definitions of antonymy have been proposed by linguists (Cruse, 1986; Lehrer and Lehrer, 1982), cognitive scientists (Kagan, 1984), psycholinguists (Deese, 1965), and lexicographers (Egan, 1984), which differ from each other in small and large respects. In its strictest sense, antonymy applies to gradable adjectives, such as hot–cold and tall–short, where the two words represent the two ends of a semantic dimension. In a broader sense, it includes other adjectives, nouns, and verbs as well (life–death, ascend–descend, shout–whisper). In its broadest sense, it applies to any two words that represent contrasting meanings. We will use the term degree of antonymy </context>
<context position="5695" citStr="Cruse (1986)" startWordPosition="850" endWordPosition="851">nits—combinations of surface form and word sense. (That said, for simplicity and where appropriate we will use the term “antonymous words” as a proxy for “antonymous lexical units”.) However, accepting this leads to two interesting and seemingly paradoxical questions (described below in the two subsections). 2.1 Why are some pairs better antonyms? Native speakers of a language consider certain contrasting word pairs to be antonymous (for example, large–small), and certain other seemingly equivalent word pairs as less so (for example, large–little). A number of reasons have been suggested: (1) Cruse (1986) observes that if the meaning of the target words is completely defined by one semantic dimension and the words represent the two ends of this semantic dimension, then they tend to be considered antonyms. We will refer to this semantic dimension as the dimension of opposition. (2) If on the other hand, as Lehrer and Lehrer (1982) point out, there is more to the meaning of the antonymous words than the dimension of opposition—for example, more semantic dimensions or added connotations—then the two words are not so strongly antonymous. Most people do not think of chubby as a direct antonym of th</context>
<context position="8166" citStr="Cruse, 1986" startWordPosition="1236" endWordPosition="1237">tion pairs such as homeless, shelter). Semantic distance (or closeness) in this broad sense is known as semantic relatedness. Two words are considered to be semantically similar if they are associated via the synonymy, hyponymy– hypernymy, or the troponymy relation. So terms that are semantically similar (plane–glider, doctor– surgeon) are also semantically related, but terms that are semantically related may not always be semantically similar (plane–sky, surgeon–scalpel). Antonymy is unique among these relations because it simultaneously conveys both a sense of 983 closeness and of distance (Cruse, 1986). Antonymous concepts are semantically related but not semantically similar. 3 Related work Charles and Miller (1989) proposed that antonyms occur together in a sentence more often than chance. This is known as the co-occurrence hypothesis. They also showed that this was empirically true for four adjective antonym pairs. Justeson and Katz (1991) demonstrated the co-occurrence hypothesis for 35 prototypical antonym pairs (from an original set of 39 antonym pairs compiled by Deese (1965)) and also for an additional 22 frequent antonym pairs. All of these pairs were adjectives. Fellbaum (1995) co</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>David A. Cruse. 1986. Lexical semantics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Deese</author>
</authors>
<title>The structure of associations in language and thought. The Johns</title>
<date>1965</date>
<publisher>Hopkins Press.</publisher>
<contexts>
<context position="1442" citStr="Deese, 1965" startWordPosition="195" endWordPosition="196"> over 80%. Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances. 1 Introduction Native speakers of a language intuitively recognize different degrees of antonymy—whether two words are strongly antonymous (hot–cold, goodbad, friend–enemy), just semantically contrasting (enemy–fan, cold–lukewarm, ascend–slip) or not antonymous at all (penguin–clown, cold–chilly, boat–rudder). Over the years, many definitions of antonymy have been proposed by linguists (Cruse, 1986; Lehrer and Lehrer, 1982), cognitive scientists (Kagan, 1984), psycholinguists (Deese, 1965), and lexicographers (Egan, 1984), which differ from each other in small and large respects. In its strictest sense, antonymy applies to gradable adjectives, such as hot–cold and tall–short, where the two words represent the two ends of a semantic dimension. In a broader sense, it includes other adjectives, nouns, and verbs as well (life–death, ascend–descend, shout–whisper). In its broadest sense, it applies to any two words that represent contrasting meanings. We will use the term degree of antonymy to encompass the complete semantic range—a combined measure of the contrast in meaning convey</context>
<context position="8656" citStr="Deese (1965)" startWordPosition="1311" endWordPosition="1312">unique among these relations because it simultaneously conveys both a sense of 983 closeness and of distance (Cruse, 1986). Antonymous concepts are semantically related but not semantically similar. 3 Related work Charles and Miller (1989) proposed that antonyms occur together in a sentence more often than chance. This is known as the co-occurrence hypothesis. They also showed that this was empirically true for four adjective antonym pairs. Justeson and Katz (1991) demonstrated the co-occurrence hypothesis for 35 prototypical antonym pairs (from an original set of 39 antonym pairs compiled by Deese (1965)) and also for an additional 22 frequent antonym pairs. All of these pairs were adjectives. Fellbaum (1995) conducted similar experiments on 47 noun, verb, adjective, and adverb pairs (noun–noun, noun–verb, noun–adjective, verb–adverb and so on) pertaining to 18 concepts (for example, lose(v)–gain(n) and loss(n)–gain(n), where lose(v) and loss(n) pertain to the concept of “failing to have/maintain”). However, non-antonymous semantically related words such as hypernyms, holonyms, meronyms, and nearsynonyms also tend to occur together more often than chance. Thus, separating antonyms from them h</context>
</contexts>
<marker>Deese, 1965</marker>
<rawString>James Deese. 1965. The structure of associations in language and thought. The Johns Hopkins Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rose F Egan</author>
</authors>
<title>Survey of the history of English synonymy. Webster’s New Dictionary of Synonyms,</title>
<date>1984</date>
<pages>5--25</pages>
<contexts>
<context position="1475" citStr="Egan, 1984" startWordPosition="199" endWordPosition="200">ss what humans consider antonymous and how antonymy manifests itself in utterances. 1 Introduction Native speakers of a language intuitively recognize different degrees of antonymy—whether two words are strongly antonymous (hot–cold, goodbad, friend–enemy), just semantically contrasting (enemy–fan, cold–lukewarm, ascend–slip) or not antonymous at all (penguin–clown, cold–chilly, boat–rudder). Over the years, many definitions of antonymy have been proposed by linguists (Cruse, 1986; Lehrer and Lehrer, 1982), cognitive scientists (Kagan, 1984), psycholinguists (Deese, 1965), and lexicographers (Egan, 1984), which differ from each other in small and large respects. In its strictest sense, antonymy applies to gradable adjectives, such as hot–cold and tall–short, where the two words represent the two ends of a semantic dimension. In a broader sense, it includes other adjectives, nouns, and verbs as well (life–death, ascend–descend, shout–whisper). In its broadest sense, it applies to any two words that represent contrasting meanings. We will use the term degree of antonymy to encompass the complete semantic range—a combined measure of the contrast in meaning conveyed by two words and the tendency </context>
</contexts>
<marker>Egan, 1984</marker>
<rawString>Rose F. Egan. 1984. Survey of the history of English synonymy. Webster’s New Dictionary of Synonyms, pages 5a–25a.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>Co-occurrence and antonymy.</title>
<date>1995</date>
<journal>International Journal of Lexicography,</journal>
<pages>8--281</pages>
<contexts>
<context position="8763" citStr="Fellbaum (1995)" startWordPosition="1328" endWordPosition="1329">ance (Cruse, 1986). Antonymous concepts are semantically related but not semantically similar. 3 Related work Charles and Miller (1989) proposed that antonyms occur together in a sentence more often than chance. This is known as the co-occurrence hypothesis. They also showed that this was empirically true for four adjective antonym pairs. Justeson and Katz (1991) demonstrated the co-occurrence hypothesis for 35 prototypical antonym pairs (from an original set of 39 antonym pairs compiled by Deese (1965)) and also for an additional 22 frequent antonym pairs. All of these pairs were adjectives. Fellbaum (1995) conducted similar experiments on 47 noun, verb, adjective, and adverb pairs (noun–noun, noun–verb, noun–adjective, verb–adverb and so on) pertaining to 18 concepts (for example, lose(v)–gain(n) and loss(n)–gain(n), where lose(v) and loss(n) pertain to the concept of “failing to have/maintain”). However, non-antonymous semantically related words such as hypernyms, holonyms, meronyms, and nearsynonyms also tend to occur together more often than chance. Thus, separating antonyms from them has proven to be difficult. Lin et al. (2003) used patterns such as “from X to Y” and “either X or Y” to sep</context>
</contexts>
<marker>Fellbaum, 1995</marker>
<rawString>Christiane Fellbaum. 1995. Co-occurrence and antonymy. International Journal of Lexicography, 8:281–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R Firth</author>
</authors>
<title>A synopsis of linguistic theory 1930–55.</title>
<date>1957</date>
<booktitle>In Studies in Linguistic Analysis,</booktitle>
<pages>1--32</pages>
<editor>in F.R. Palmer (ed.),</editor>
<publisher>The Philological Society. (Reprinted</publisher>
<location>Oxford:</location>
<contexts>
<context position="13254" citStr="Firth, 1957" startWordPosition="2038" endWordPosition="2039">peech (for example, legally–embargo). Further, the noun–noun, verb–verb, and adjective–adjective antonym pairs of WordNet largely ignore near-opposites as revealed by our experiments (Section 8 below). Also, WordNet (or any other manually-created repository of antonyms for that matter) does not encode the degree of antonymy between words. Nevertheless, we investigate the usefulness of WordNet as a source of seed antonym pairs for our approach. 4.3 Co-occurrence statistics The distributional hypothesis of closeness states that words that occur in similar contexts tend to be semantically close (Firth, 1957). Distributional measures of distance, such as those proposed by Lin (1998), quantify how similar the two sets of contexts of a target word pair are. Equation 1 is a modified form of Lin’s measure that ignores syntactic dependencies and hence it estimates semantic relatedness rather than semantic similarity: Here w1 and w2 are the target words; I x y is the pointwise mutual information between x and y; and T x is the set of all words y that have positive pointwise mutual information with the word x (I x y 0). Mohammad and Hirst (2006) showed that these distributional word-distance measures per</context>
</contexts>
<marker>Firth, 1957</marker>
<rawString>John R. Firth. 1957. A synopsis of linguistic theory 1930–55. In Studies in Linguistic Analysis, pages 1– 32, Oxford: The Philological Society. (Reprinted in F.R. Palmer (ed.), Selected Papers of J.R. Firth 1952-1959, Longman).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derek Gross</author>
<author>Ute Fischer</author>
<author>George A Miller</author>
</authors>
<title>Antonymy and the representation of adjectival meanings.</title>
<date>1989</date>
<journal>Memory and Language,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="12247" citStr="Gross et al., 1989" startWordPosition="1881" endWordPosition="1884">in the same category, but this is rare. The intuition is that words within a category represent a coarse concept. Words with more than one meaning may be found in more than one category; these represent its coarse senses. Within a category, the words are grouped into paragraphs. Words in the same paragraph tend to be closer in meaning than those in different paragraphs. We will take advantage of the structure of the thesaurus in our approach. 4.2 WordNet Unlike the traditional approach to antonymy, WordNet encodes antonymy as a lexical relationship—a relation between two words (not concepts) (Gross et al., 1989). Even though a synset (a WordNet concept) may be represented by more than one word, individual words across synsets are marked as (di984 rect) antonyms. Gross et al. argue that other words in the synsets form “indirect antonyms”. Even after including the indirect antonyms, WordNet’s coverage is limited. As Marcu and Echihabi (2002) point out, WordNet does not encode antonymy across part-of-speech (for example, legally–embargo). Further, the noun–noun, verb–verb, and adjective–adjective antonym pairs of WordNet largely ignore near-opposites as revealed by our experiments (Section 8 below). Als</context>
</contexts>
<marker>Gross, Fischer, Miller, 1989</marker>
<rawString>Derek Gross, Ute Fischer, and George A. Miller. 1989. Antonymy and the representation of adjectival meanings. Memory and Language, 28(1):92–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Andrew Hickl</author>
<author>Finley Lacatusu</author>
</authors>
<title>Lacatusu: Negation, contrast and contradiction in text processing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI06),</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="10026" citStr="Harabagiu et al. (2006)" startWordPosition="1521" endWordPosition="1524">onally similar pairs. They evaluated their method on 80 pairs of antonyms and 80 pairs of synonyms taken from the Webster’s Collegiate Thesaurus (Kay, 1988). In this paper, we propose a method to determine the degree of antonymy between any word pair and not just those that are distributionally similar. Turney (2008) proposed a uniform method to solve word analogy problems that require identifying synonyms, antonyms, hypernyms, and other lexical-semantic relations between word pairs. However, the Turney method is supervised whereas the method proposed in this paper is completely unsupervised. Harabagiu et al. (2006) detected antonyms for the purpose of identifying contradictions by using WordNet chains—synsets connected by the hypernymy–hyponymy links and exactly one antonymy link. Lucerto et al. (2002) proposed detecting antonym pairs using the number of words between two words in text and also cue words such as but, from, and and. Unfortunately, they evaluated their method on only 18 word pairs. Neither of these methods determines the degree of antonymy between words and they have not been shown to have substantial coverage. Schwab et al. (2002) create “antonymous vector” for a target word. The closer </context>
</contexts>
<marker>Harabagiu, Hickl, Lacatusu, 2006</marker>
<rawString>Sanda M. Harabagiu, Andrew Hickl, and Finley Lacatusu. 2006. Lacatusu: Negation, contrast and contradiction in text processing. In Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI06), Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Computational Linguistics,</booktitle>
<pages>539--546</pages>
<location>Nantes, France.</location>
<contexts>
<context position="4151" citStr="Hearst, 1992" startWordPosition="606" endWordPosition="607"> Methods in Natural Language Processing, pages 982–991, Honolulu, October 2008.c�2008 Association for Computational Linguistics Lexicons of pairs of words that native speakers consider antonyms have been created for certain languages, but their coverage has been limited. Further, as each term of an antonymous pair can have many semantically close terms, the contrasting word pairs far outnumber those that are commonly considered antonym pairs, and they remain unrecorded. Even though a number of computational approaches have been proposed for semantic closeness, and some for hypernymy–hyponymy (Hearst, 1992), measures of antonymy have been less successful. To some extent, this is because antonymy is not as well understood as other classical lexical-semantic relations. We first very briefly summarize insights and intuitions about this phenomenon, as proposed by linguists and lexicographers (Section 2). We discuss related work (Section 3). We describe the resources we use (Section 4) and present experiments that examine the manifestation of antonymy in text (Sections 5 and 6). We then propose a new empirical approach to determine the degree of antonymy between two words (Section 7). We compiled a d</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the Fourteenth International Conference on Computational Linguistics, pages 539–546, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Cooccurrences of antonymous adjectives and their contexts.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<pages>17--1</pages>
<contexts>
<context position="8513" citStr="Justeson and Katz (1991)" startWordPosition="1288" endWordPosition="1291">n) are also semantically related, but terms that are semantically related may not always be semantically similar (plane–sky, surgeon–scalpel). Antonymy is unique among these relations because it simultaneously conveys both a sense of 983 closeness and of distance (Cruse, 1986). Antonymous concepts are semantically related but not semantically similar. 3 Related work Charles and Miller (1989) proposed that antonyms occur together in a sentence more often than chance. This is known as the co-occurrence hypothesis. They also showed that this was empirically true for four adjective antonym pairs. Justeson and Katz (1991) demonstrated the co-occurrence hypothesis for 35 prototypical antonym pairs (from an original set of 39 antonym pairs compiled by Deese (1965)) and also for an additional 22 frequent antonym pairs. All of these pairs were adjectives. Fellbaum (1995) conducted similar experiments on 47 noun, verb, adjective, and adverb pairs (noun–noun, noun–verb, noun–adjective, verb–adverb and so on) pertaining to 18 concepts (for example, lose(v)–gain(n) and loss(n)–gain(n), where lose(v) and loss(n) pertain to the concept of “failing to have/maintain”). However, non-antonymous semantically related words su</context>
<context position="16721" citStr="Justeson and Katz (1991)" startWordPosition="2633" endWordPosition="2636"> Miller (1989) also proposed that in most contexts, antonyms may be interchanged. The Lin w1 w2 Y—w Tw1 Tw2 I w1 w I w2 w (1) Y—w Tw1 I w1 w Y—w Tw2 I w2 w Lin c1 c2 Y—w Tc1 Tc2 I c1 w I c2 w (2) Y—w Tc1 I c1 w Y—w Tc2 I c2 w 985 meaning of the utterance will be inverted, of course, but the sentence will remain grammatical and linguistically plausible. This came to be known as the substitutability hypothesis. However, their experiments did not support this claim. They found that given a sentence with the target adjective removed, most people did not confound the missing word with its antonym. Justeson and Katz (1991) later showed that in sentences that contain both members of an antonymous adjective pair, the target adjectives do indeed occur in similar syntactic structures at the phrasal level. From this (and to some extent from the co-occurrence hypothesis), we can derive the distributional hypothesis of antonyms: antonyms occur in similar contexts more often than non-antonymous words. We used the same set of one thousand antonym pairs and one thousand control pairs as in the previous experiment to gather empirical proof of the distributional hypothesis. For each word pair from the antonym set, we calcu</context>
<context position="27408" citStr="Justeson and Katz (1991)" startWordPosition="4374" endWordPosition="4377"> as well, in the near future. sense-annotated. If antonymous occurrences are to be exploited for any of the purposes listed in the beginning of this paper, then the text must be sense disambiguated. However, word sense disambiguation is a hard problem. Yet, and to some extent because unsupervised word sense disambiguation systems perform poorly, much can be gained by using simple heuristics. For example, it has been shown that cohesive text tends to have words that are close in meaning rather than unrelated words. This, along with the distributional hypothesis of antonyms, and the findings by Justeson and Katz (1991) (antonymous concepts tend to occur more often than chance in the same sentence), suggests that if we find a word pair in a sentence such that two of its senses are strongly contrasting (as per the algorithm described in Section 7.2.2), then it is probable that the two words are used in those contrasting senses. 8 Evaluation 8.1 Task and data In order to best evaluate a computational measure of antonymy, we need a task that not only requires knowing whether two words are antonymous but also whether one word pair is more antonymous than another pair. Therefore, we evaluated our system on a set </context>
</contexts>
<marker>Justeson, Katz, 1991</marker>
<rawString>John S. Justeson and Slava M. Katz. 1991. Cooccurrences of antonymous adjectives and their contexts. Computational Linguistics, 17:1–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome Kagan</author>
</authors>
<title>The Nature of the Child.</title>
<date>1984</date>
<publisher>Basic Books.</publisher>
<contexts>
<context position="1411" citStr="Kagan, 1984" startWordPosition="192" endWordPosition="193">tions, obtaining a precision of over 80%. Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances. 1 Introduction Native speakers of a language intuitively recognize different degrees of antonymy—whether two words are strongly antonymous (hot–cold, goodbad, friend–enemy), just semantically contrasting (enemy–fan, cold–lukewarm, ascend–slip) or not antonymous at all (penguin–clown, cold–chilly, boat–rudder). Over the years, many definitions of antonymy have been proposed by linguists (Cruse, 1986; Lehrer and Lehrer, 1982), cognitive scientists (Kagan, 1984), psycholinguists (Deese, 1965), and lexicographers (Egan, 1984), which differ from each other in small and large respects. In its strictest sense, antonymy applies to gradable adjectives, such as hot–cold and tall–short, where the two words represent the two ends of a semantic dimension. In a broader sense, it includes other adjectives, nouns, and verbs as well (life–death, ascend–descend, shout–whisper). In its broadest sense, it applies to any two words that represent contrasting meanings. We will use the term degree of antonymy to encompass the complete semantic range—a combined measure of</context>
</contexts>
<marker>Kagan, 1984</marker>
<rawString>Jerome Kagan. 1984. The Nature of the Child. Basic Books.</rawString>
</citation>
<citation valid="true">
<title>Webster’s Collegiate Thesaurus.</title>
<date>1988</date>
<editor>Maire Weir Kay, editor.</editor>
<publisher>Merrian-Webster.</publisher>
<marker>1988</marker>
<rawString>Maire Weir Kay, editor. 1988. Webster’s Collegiate Thesaurus. Merrian-Webster.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrienne Lehrer</author>
<author>K Lehrer</author>
</authors>
<date>1982</date>
<booktitle>Antonymy. Linguistics and Philosophy,</booktitle>
<pages>5--483</pages>
<contexts>
<context position="1375" citStr="Lehrer and Lehrer, 1982" startWordPosition="185" endWordPosition="188">h is evaluated on a set of closest-opposite questions, obtaining a precision of over 80%. Along the way, we discuss what humans consider antonymous and how antonymy manifests itself in utterances. 1 Introduction Native speakers of a language intuitively recognize different degrees of antonymy—whether two words are strongly antonymous (hot–cold, goodbad, friend–enemy), just semantically contrasting (enemy–fan, cold–lukewarm, ascend–slip) or not antonymous at all (penguin–clown, cold–chilly, boat–rudder). Over the years, many definitions of antonymy have been proposed by linguists (Cruse, 1986; Lehrer and Lehrer, 1982), cognitive scientists (Kagan, 1984), psycholinguists (Deese, 1965), and lexicographers (Egan, 1984), which differ from each other in small and large respects. In its strictest sense, antonymy applies to gradable adjectives, such as hot–cold and tall–short, where the two words represent the two ends of a semantic dimension. In a broader sense, it includes other adjectives, nouns, and verbs as well (life–death, ascend–descend, shout–whisper). In its broadest sense, it applies to any two words that represent contrasting meanings. We will use the term degree of antonymy to encompass the complete </context>
<context position="6026" citStr="Lehrer and Lehrer (1982)" startWordPosition="907" endWordPosition="910">re some pairs better antonyms? Native speakers of a language consider certain contrasting word pairs to be antonymous (for example, large–small), and certain other seemingly equivalent word pairs as less so (for example, large–little). A number of reasons have been suggested: (1) Cruse (1986) observes that if the meaning of the target words is completely defined by one semantic dimension and the words represent the two ends of this semantic dimension, then they tend to be considered antonyms. We will refer to this semantic dimension as the dimension of opposition. (2) If on the other hand, as Lehrer and Lehrer (1982) point out, there is more to the meaning of the antonymous words than the dimension of opposition—for example, more semantic dimensions or added connotations—then the two words are not so strongly antonymous. Most people do not think of chubby as a direct antonym of thin because it has the additional connotation of being cute and informal. (3) Cruse (1986) also postulates that word pairs are not considered strictly antonymous if it is difficult to identify the dimension of opposition (for example, city–farm). (4) Charles and Miller (1989) claim that two contrasting words are identified as anto</context>
</contexts>
<marker>Lehrer, Lehrer, 1982</marker>
<rawString>Adrienne Lehrer and K. Lehrer. 1982. Antonymy. Linguistics and Philosophy, 5:483–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Shaojun Zhao</author>
<author>Lijuan Qin</author>
<author>Ming Zhou</author>
</authors>
<title>Identifying synonyms among distributionally similar words.</title>
<date>2003</date>
<booktitle>In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI-03),</booktitle>
<pages>1492--1493</pages>
<location>Acapulco, Mexico.</location>
<contexts>
<context position="9300" citStr="Lin et al. (2003)" startWordPosition="1403" endWordPosition="1406">l 22 frequent antonym pairs. All of these pairs were adjectives. Fellbaum (1995) conducted similar experiments on 47 noun, verb, adjective, and adverb pairs (noun–noun, noun–verb, noun–adjective, verb–adverb and so on) pertaining to 18 concepts (for example, lose(v)–gain(n) and loss(n)–gain(n), where lose(v) and loss(n) pertain to the concept of “failing to have/maintain”). However, non-antonymous semantically related words such as hypernyms, holonyms, meronyms, and nearsynonyms also tend to occur together more often than chance. Thus, separating antonyms from them has proven to be difficult. Lin et al. (2003) used patterns such as “from X to Y” and “either X or Y” to separate antonym word pairs from distributionally similar pairs. They evaluated their method on 80 pairs of antonyms and 80 pairs of synonyms taken from the Webster’s Collegiate Thesaurus (Kay, 1988). In this paper, we propose a method to determine the degree of antonymy between any word pair and not just those that are distributionally similar. Turney (2008) proposed a uniform method to solve word analogy problems that require identifying synonyms, antonyms, hypernyms, and other lexical-semantic relations between word pairs. However,</context>
</contexts>
<marker>Lin, Zhao, Qin, Zhou, 2003</marker>
<rawString>Dekang Lin, Shaojun Zhao, Lijuan Qin, and Ming Zhou. 2003. Identifying synonyms among distributionally similar words. In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI-03), pages 1492–1493, Acapulco, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retreival and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics (COLING-98),</booktitle>
<pages>768--773</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="13329" citStr="Lin (1998)" startWordPosition="2049" endWordPosition="2050">adjective–adjective antonym pairs of WordNet largely ignore near-opposites as revealed by our experiments (Section 8 below). Also, WordNet (or any other manually-created repository of antonyms for that matter) does not encode the degree of antonymy between words. Nevertheless, we investigate the usefulness of WordNet as a source of seed antonym pairs for our approach. 4.3 Co-occurrence statistics The distributional hypothesis of closeness states that words that occur in similar contexts tend to be semantically close (Firth, 1957). Distributional measures of distance, such as those proposed by Lin (1998), quantify how similar the two sets of contexts of a target word pair are. Equation 1 is a modified form of Lin’s measure that ignores syntactic dependencies and hence it estimates semantic relatedness rather than semantic similarity: Here w1 and w2 are the target words; I x y is the pointwise mutual information between x and y; and T x is the set of all words y that have positive pointwise mutual information with the word x (I x y 0). Mohammad and Hirst (2006) showed that these distributional word-distance measures perform poorly when compared with WordNet-based concept-distance measures. The</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retreival and clustering of similar words. In Proceedings of the 17th International Conference on Computational Linguistics (COLING-98), pages 768–773, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cupertino Lucerto</author>
<author>David Pinto</author>
<author>H´ector Jimi´enezSalazar</author>
</authors>
<title>An automatic method to identify antonymy.</title>
<date>2002</date>
<booktitle>In Workshop on Lexical Resources and the Web for Word Sense Disambiguation,</booktitle>
<pages>105--111</pages>
<location>Puebla, Mexico.</location>
<marker>Lucerto, Pinto, Jimi´enezSalazar, 2002</marker>
<rawString>Cupertino Lucerto, David Pinto, and H´ector Jimi´enezSalazar. 2002. An automatic method to identify antonymy. In Workshop on Lexical Resources and the Web for Word Sense Disambiguation, pages 105–111, Puebla, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lyons</author>
</authors>
<date>1977</date>
<journal>Semantics,</journal>
<volume>1</volume>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="20196" citStr="Lyons, 1977" startWordPosition="3194" endWordPosition="3195">ecting contrasting categories We propose two ways of detecting thesaurus category pairs that represent contrasting concepts (we will call these pairs contrasting categories): (1) using a seed set of antonyms and (2) using a simple heuristic that exploits how thesaurus categories are ordered. 7.1.1 Seed sets Affix-generated seed set Antonym pairs such as hot–cold and dark–light occur frequently in text, but in terms of type-pairs they are outnumbered by those created using affixes, such as un- (clear– unclear) and dis- (honest–dishonest). Further, this phenomenon is observed in most languages (Lyons, 1977). Table 1 lists sixteen morphological rules that tend to generate antonyms in English. These rules were applied to each of the words in the Macquarie Thesaurus and if the resulting term was also a valid word in the thesaurus, then the word-pair was added to the affix-generated seed set. These sixteen rules generated 2,734 word pairs. Of course, not all of them are antonymous, for example sect–insect and coy–decoy. However, these are relatively few in 986 w1 w2 example pair X abX normal–abnormal X antiX clockwise–anticlockwise X disX interest–disinterest X imX possible–impossible X inX consiste</context>
</contexts>
<marker>Lyons, 1977</marker>
<rawString>John Lyons. 1977. Semantics, volume 1. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Abdesammad Echihabi</author>
</authors>
<title>An unsupervised approach to recognizing discourse relations.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL02),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2885" citStr="Marcu and Echihabi, 2002" startWordPosition="414" endWordPosition="417"> be considered antonym pairs by native speakers. Automatically determining the degree of antonymy between words has many uses including detecting and generating paraphrases (The dementors caught Sirius Black / Black could not escape the dementors) and detecting contradictions (Marneffe et al., 2008; Voorhees, 2008) (Kyoto has a predominantly wet climate / It is mostly dry in Kyoto). Of course, such “contradictions” may be a result of differing sentiment, new information, non-coreferent mentions, or genuinely contradictory statements. Antonyms often indicate the discourse relation of contrast (Marcu and Echihabi, 2002). They are also useful for detecting humor (Mihalcea and Strapparava, 2005), as satire and jokes tend to have contradictions and oxymorons. Lastly, it is useful to know which words are semantically contrasting to a target word, even if simply to filter them out. For example, in the automatic creation of a thesaurus it is necessary to distinguish nearsynonyms from word pairs that are semantically contrasting. Measures of distributional similarity fail to do so. Detecting antonymous words is not sufficient to solve most of these problems, but it remains a crucial, and largely unsolved, component</context>
<context position="12581" citStr="Marcu and Echihabi (2002)" startWordPosition="1937" endWordPosition="1941"> meaning than those in different paragraphs. We will take advantage of the structure of the thesaurus in our approach. 4.2 WordNet Unlike the traditional approach to antonymy, WordNet encodes antonymy as a lexical relationship—a relation between two words (not concepts) (Gross et al., 1989). Even though a synset (a WordNet concept) may be represented by more than one word, individual words across synsets are marked as (di984 rect) antonyms. Gross et al. argue that other words in the synsets form “indirect antonyms”. Even after including the indirect antonyms, WordNet’s coverage is limited. As Marcu and Echihabi (2002) point out, WordNet does not encode antonymy across part-of-speech (for example, legally–embargo). Further, the noun–noun, verb–verb, and adjective–adjective antonym pairs of WordNet largely ignore near-opposites as revealed by our experiments (Section 8 below). Also, WordNet (or any other manually-created repository of antonyms for that matter) does not encode the degree of antonymy between words. Nevertheless, we investigate the usefulness of WordNet as a source of seed antonym pairs for our approach. 4.3 Co-occurrence statistics The distributional hypothesis of closeness states that words t</context>
</contexts>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>Daniel Marcu and Abdesammad Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL02), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Anna Rafferty</author>
<author>Christopher D Manning</author>
</authors>
<title>Finding contradictions in text.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08),</booktitle>
<location>Columbus, OH.</location>
<marker>de Marneffe, Rafferty, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe, Anna Rafferty, and Christopher D. Manning. 2008. Finding contradictions in text. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08), Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carlo Strapparava</author>
</authors>
<title>Making computers laugh: Investigations in automatic humor recognition.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>531--538</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="2960" citStr="Mihalcea and Strapparava, 2005" startWordPosition="425" endWordPosition="428">ining the degree of antonymy between words has many uses including detecting and generating paraphrases (The dementors caught Sirius Black / Black could not escape the dementors) and detecting contradictions (Marneffe et al., 2008; Voorhees, 2008) (Kyoto has a predominantly wet climate / It is mostly dry in Kyoto). Of course, such “contradictions” may be a result of differing sentiment, new information, non-coreferent mentions, or genuinely contradictory statements. Antonyms often indicate the discourse relation of contrast (Marcu and Echihabi, 2002). They are also useful for detecting humor (Mihalcea and Strapparava, 2005), as satire and jokes tend to have contradictions and oxymorons. Lastly, it is useful to know which words are semantically contrasting to a target word, even if simply to filter them out. For example, in the automatic creation of a thesaurus it is necessary to distinguish nearsynonyms from word pairs that are semantically contrasting. Measures of distributional similarity fail to do so. Detecting antonymous words is not sufficient to solve most of these problems, but it remains a crucial, and largely unsolved, component. 982 Proceedings of the 2008 Conference on Empirical Methods in Natural La</context>
</contexts>
<marker>Mihalcea, Strapparava, 2005</marker>
<rawString>Rada Mihalcea and Carlo Strapparava. 2005. Making computers laugh: Investigations in automatic humor recognition. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 531–538, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Distributional measures of concept-distance: A task-oriented evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="13794" citStr="Mohammad and Hirst (2006)" startWordPosition="2134" endWordPosition="2137">that words that occur in similar contexts tend to be semantically close (Firth, 1957). Distributional measures of distance, such as those proposed by Lin (1998), quantify how similar the two sets of contexts of a target word pair are. Equation 1 is a modified form of Lin’s measure that ignores syntactic dependencies and hence it estimates semantic relatedness rather than semantic similarity: Here w1 and w2 are the target words; I x y is the pointwise mutual information between x and y; and T x is the set of all words y that have positive pointwise mutual information with the word x (I x y 0). Mohammad and Hirst (2006) showed that these distributional word-distance measures perform poorly when compared with WordNet-based concept-distance measures. They argued that this is because the word-distance measures clump together the contexts of the different senses of the target words. They proposed a way to obtain distributional distance between word senses, using any of the distributional measures such as cosine or that proposed by Lin, and showed that this approach performed markedly better than the traditional worddistance approach. They used thesaurus categories as very coarse word senses. Equation 2 shows how</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2006. Distributional measures of concept-distance: A task-oriented evaluation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Morris</author>
<author>Graeme Hirst</author>
</authors>
<title>Non-classical lexical semantic relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Computational Lexical Semantics,</booktitle>
<location>HLT, Boston, MA.</location>
<contexts>
<context position="7368" citStr="Morris and Hirst (2004)" startWordPosition="1117" endWordPosition="1120">ter-thanchance co-occurrence of antonyms in sentences is because together they convey contrast well, which is rhetorically useful, and not really the reason why they are considered antonyms in the first place. 2.2 Are semantic closeness and antonymy opposites? Two words (more precisely, two lexical units) are considered to be close in meaning if there is a lexical-semantic relation between them. Lexicalsemantic relations are of two kinds: classical and non-classical. Examples of classical relations include synonymy, hyponymy, troponymy, and meronymy. Non-classical relations, as pointed out by Morris and Hirst (2004), are much more common and include concepts pertaining to another concept (kind, chivalrous, formal pertaining to gentlemanly), and commonly co-occurring words (for example, problem–solution pairs such as homeless, shelter). Semantic distance (or closeness) in this broad sense is known as semantic relatedness. Two words are considered to be semantically similar if they are associated via the synonymy, hyponymy– hypernymy, or the troponymy relation. So terms that are semantically similar (plane–glider, doctor– surgeon) are also semantically related, but terms that are semantically related may n</context>
</contexts>
<marker>Morris, Hirst, 2004</marker>
<rawString>Jane Morris and Graeme Hirst. 2004. Non-classical lexical semantic relations. In Proceedings of the Workshop on Computational Lexical Semantics, HLT, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory L Murphy</author>
<author>Jane M Andrew</author>
</authors>
<title>The conceptual basis of antonymy and synonymy in adjectives.</title>
<date>1993</date>
<journal>Journal ofMemory and Language,</journal>
<volume>32</volume>
<issue>3</issue>
<contexts>
<context position="6725" citStr="Murphy and Andrew (1993)" startWordPosition="1021" endWordPosition="1025">imension of opposition—for example, more semantic dimensions or added connotations—then the two words are not so strongly antonymous. Most people do not think of chubby as a direct antonym of thin because it has the additional connotation of being cute and informal. (3) Cruse (1986) also postulates that word pairs are not considered strictly antonymous if it is difficult to identify the dimension of opposition (for example, city–farm). (4) Charles and Miller (1989) claim that two contrasting words are identified as antonyms if they occur together in a sentence more often than chance. However, Murphy and Andrew (1993) claim that the greater-thanchance co-occurrence of antonyms in sentences is because together they convey contrast well, which is rhetorically useful, and not really the reason why they are considered antonyms in the first place. 2.2 Are semantic closeness and antonymy opposites? Two words (more precisely, two lexical units) are considered to be close in meaning if there is a lexical-semantic relation between them. Lexicalsemantic relations are of two kinds: classical and non-classical. Examples of classical relations include synonymy, hyponymy, troponymy, and meronymy. Non-classical relations</context>
</contexts>
<marker>Murphy, Andrew, 1993</marker>
<rawString>Gregory L. Murphy and Jane M. Andrew. 1993. The conceptual basis of antonymy and synonymy in adjectives. Journal ofMemory and Language, 32(3):1–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>79--86</pages>
<location>Philadelphia, PA.</location>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 79–86, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Didier Schwab</author>
<author>Mathieu Lafourcade</author>
<author>Violaine Prince</author>
</authors>
<title>Antonymy and conceptual vectors.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING-02),</booktitle>
<pages>904--910</pages>
<contexts>
<context position="10568" citStr="Schwab et al. (2002)" startWordPosition="1608" endWordPosition="1611">hod proposed in this paper is completely unsupervised. Harabagiu et al. (2006) detected antonyms for the purpose of identifying contradictions by using WordNet chains—synsets connected by the hypernymy–hyponymy links and exactly one antonymy link. Lucerto et al. (2002) proposed detecting antonym pairs using the number of words between two words in text and also cue words such as but, from, and and. Unfortunately, they evaluated their method on only 18 word pairs. Neither of these methods determines the degree of antonymy between words and they have not been shown to have substantial coverage. Schwab et al. (2002) create “antonymous vector” for a target word. The closer this vector is to the context vectors of the other target word, the more antonymous the two target words are. However, the antonymous vectors are manually created. Further, the approach is not evaluated beyond a handful of word pairs. Work in sentiment detection and opinion mining aims at determining the polarity of words. For example, Pang, Lee and Vaithyanathan (2002) detect that adjectives such as dazzling, brilliant, and gripping cast their qualifying nouns positively whereas adjectives such as bad, cliched, and boring portray the n</context>
</contexts>
<marker>Schwab, Lafourcade, Prince, 2002</marker>
<rawString>Didier Schwab, Mathieu Lafourcade, and Violaine Prince. 2002. Antonymy and conceptual vectors. In Proceedings of the 19th International Conference on Computational Linguistics (COLING-02), pages 904– 910.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Mining the web for synonyms: PMI-IR versus LSA on TOEFL.</title>
<date>2001</date>
<booktitle>In Proceedings of the Twelfth European Conference on Machine Learning,</booktitle>
<pages>491--502</pages>
<location>Freiburg, Germany.</location>
<contexts>
<context position="28719" citStr="Turney, 2001" startWordPosition="4599" endWordPosition="4600">ive is to identify that alternative which is the closest opposite of the target. For example, consider: adulterate: a. renounce b. forbid c. purify d. criticize e. correct Here the target word is adulterate. One of the alternatives provided is correct, which as a verb has a meaning that contrasts with that of adulterate; however, purify has a greater degree of antonymy with adulterate than correct does and must be chosen in order for the instance to be marked as correctly answered. This evaluation is similar to how others have evaluated semantic distance algorithms on TOEFL synonym questions (Turney, 2001), except that in those cases the system had to choose the alternative which is closest in meaning to the target. We looked on the World Wide Web for large sets of closest antonym questions. We found two independent sets of questions designed to prepare stu988 development data test data P R F P R F 0.20 0.20 0.20 0.20 0.20 0.20 0.72 0.53 0.61 0.71 0.51 0.60 0.79 0.52 0.63 0.75 0.50 0.60 0.77 0.65 0.70 0.73 0.60 0.65 0.81 0.43 0.56 0.83 0.46 0.59 0.75 0.60 0.67 0.76 0.61 0.68 0.76 0.66 0.70 0.76 0.64 0.70 a. random baseline b. affix-generated seeds only c. WordNet seeds only d. both seed sets e.</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>Peter Turney. 2001. Mining the web for synonyms: PMI-IR versus LSA on TOEFL. In Proceedings of the Twelfth European Conference on Machine Learning, pages 491–502, Freiburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>A uniform approach to analogies, synonyms, antonyms, and associations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08),</booktitle>
<pages>905--912</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="9721" citStr="Turney (2008)" startWordPosition="1479" endWordPosition="1480">ds such as hypernyms, holonyms, meronyms, and nearsynonyms also tend to occur together more often than chance. Thus, separating antonyms from them has proven to be difficult. Lin et al. (2003) used patterns such as “from X to Y” and “either X or Y” to separate antonym word pairs from distributionally similar pairs. They evaluated their method on 80 pairs of antonyms and 80 pairs of synonyms taken from the Webster’s Collegiate Thesaurus (Kay, 1988). In this paper, we propose a method to determine the degree of antonymy between any word pair and not just those that are distributionally similar. Turney (2008) proposed a uniform method to solve word analogy problems that require identifying synonyms, antonyms, hypernyms, and other lexical-semantic relations between word pairs. However, the Turney method is supervised whereas the method proposed in this paper is completely unsupervised. Harabagiu et al. (2006) detected antonyms for the purpose of identifying contradictions by using WordNet chains—synsets connected by the hypernymy–hyponymy links and exactly one antonymy link. Lucerto et al. (2002) proposed detecting antonym pairs using the number of words between two words in text and also cue words</context>
</contexts>
<marker>Turney, 2008</marker>
<rawString>Peter Turney. 2008. A uniform approach to analogies, synonyms, antonyms, and associations. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING-08), pages 905–912, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Contradictions and justifications: Extensions to the textual entailment task.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08),</booktitle>
<location>Columbus, OH.</location>
<contexts>
<context position="2576" citStr="Voorhees, 2008" startWordPosition="372" endWordPosition="373"> the complete semantic range—a combined measure of the contrast in meaning conveyed by two words and the tendency of native speakers to call them opposites. The higher the degree of antonymy between a target word pair, the greater the semantic contrast between them and the greater their tendency to be considered antonym pairs by native speakers. Automatically determining the degree of antonymy between words has many uses including detecting and generating paraphrases (The dementors caught Sirius Black / Black could not escape the dementors) and detecting contradictions (Marneffe et al., 2008; Voorhees, 2008) (Kyoto has a predominantly wet climate / It is mostly dry in Kyoto). Of course, such “contradictions” may be a result of differing sentiment, new information, non-coreferent mentions, or genuinely contradictory statements. Antonyms often indicate the discourse relation of contrast (Marcu and Echihabi, 2002). They are also useful for detecting humor (Mihalcea and Strapparava, 2005), as satire and jokes tend to have contradictions and oxymorons. Lastly, it is useful to know which words are semantically contrasting to a target word, even if simply to filter them out. For example, in the automati</context>
</contexts>
<marker>Voorhees, 2008</marker>
<rawString>Ellen M Voorhees. 2008. Contradictions and justifications: Extensions to the textual entailment task. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-08), Columbus, OH.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>