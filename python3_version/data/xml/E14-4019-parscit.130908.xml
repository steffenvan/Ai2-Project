<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.023317">
<title confidence="0.988456">
Chinese Native Language Identification
</title>
<author confidence="0.997161">
Shervin Malmasi
</author>
<affiliation confidence="0.821069">
Centre for Language Technology
Macquarie University
Sydney, NSW, Australia
</affiliation>
<email confidence="0.995684">
shervin.malmasi@mq.edu.au
</email>
<author confidence="0.995288">
Mark Dras
</author>
<affiliation confidence="0.820484666666667">
Centre for Language Technology
Macquarie University
Sydney, NSW, Australia
</affiliation>
<email confidence="0.997912">
mark.dras@mq.edu.au
</email>
<sectionHeader confidence="0.993877" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99999575">
We present the first application of Na-
tive Language Identification (NLI) to non-
English data. Motivated by theories of lan-
guage transfer, NLI is the task of iden-
tifying a writer’s native language (L1)
based on their writings in a second lan-
guage (the L2). An NLI system was ap-
plied to Chinese learner texts using topic-
independent syntactic models to assess
their accuracy. We find that models using
part-of-speech tags, context-free grammar
production rules and function words are
highly effective, achieving a maximum ac-
curacy of 71% . Interestingly, we also find
that when applied to equivalent English
data, the model performance is almost
identical. This finding suggests a sys-
tematic pattern of cross-linguistic transfer
may exist, where the degree of transfer is
independent of the L1 and L2.
</bodyText>
<sectionHeader confidence="0.998982" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999884361702128">
Native Language Identification (NLI) is the task of
identifying an author’s native language (L1) based
on their writings in a second language (the L2).
NLI works by identifying language use patterns
that are common to groups of speakers that share
the same native language. This process is under-
pinned by the presupposition that an author’s L1
will dispose them towards particular language pro-
duction patterns in their L2, as influenced by their
mother tongue. This relates to Cross-Linguistic
Influence (CLI), a key topic in the field of Second
Language Acquisition (SLA) that analyzes trans-
fer effects from the L1 on later learned languages
(Ortega, 2009).
While NLI has applications in security, most re-
search has a strong linguistic motivation relating to
language teaching and learning. Rising numbers
of language learners have led to an increasing need
for language learning resources, which has in turn
fuelled much of the language acquisition research
of the past decade. In this context, by identify-
ing L1-specific language usage and error patterns,
NLI can be used to better understand SLA and de-
velop teaching methods, instructions and learner
feedback that is specific to their mother tongue.
However, all of the NLI research to date has fo-
cused exclusively on English L2 data. To this end
there is a need to apply NLI to other languages,
not only to gauge their applicability but also to aid
in teaching research for other emerging languages.
Interest in learning Chinese is rapidly growing,
leading to increased research in Teaching Chinese
as a Second Language (TCSL) and the develop-
ment of related resources such as learner corpora
(Chen et al., 2010). The application of these tools
and scientific methods like NLI can greatly assist
researchers in creating effective teaching practices
and is an area of active research.
The aim of this research is to evaluate the cross-
language applicability of NLI techniques by ap-
plying them to Chinese learner texts, evaluating
their efficacy and comparing the results with their
English equivalents.
To the best of our knowledge this is the first
reported application of NLI to non-English data
and we believe this is an important step in gain-
ing deeper insights about the technique.
</bodyText>
<sectionHeader confidence="0.999765" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9998551">
NLI is a fairly recent, but rapidly growing area of
research. While some research was conducted in
the early 2000s, the most significant work has only
appeared in the last few years (Wong and Dras,
2009; Wong and Dras, 2011; Swanson and Char-
niak, 2012; Tetreault et al., 2012; Bykh and Meur-
ers, 2012).
Most studies approach NLI as a multi-class su-
pervised classification task. In this experimental
design, the L1 metadata are used as class labels
</bodyText>
<page confidence="0.989194">
95
</page>
<note confidence="0.6876525">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 95–99,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999879571428571">
and the individual writings are used as training and
testing data. Using lexical and syntactic features
of increasing sophistication, researchers have ob-
tained good results under this paradigm. While a
detailed exposition of NLI has been omitted here
due to space constraints, a concise review can be
found in Bykh and Meurers (2012).
</bodyText>
<subsectionHeader confidence="0.985321">
2.1 NLI 2013 Shared Task
</subsectionHeader>
<bodyText confidence="0.999987615384615">
This increased interest brought unprecedented
level of research focus and momentum, resulting
in the first NLI shared task being held in 2013.1
The shared task aimed to facilitate the comparison
of results by providing a large NLI-specific dataset
and evaluation procedure, to enable direct compar-
ison of results achieved through different methods.
Overall, the event was considered a success, draw-
ing 29 entrants and experts from not only Compu-
tational Linguistics, but also SLA. The best teams
achieved accuracies of greater than 80% on this
11-class classification task. A detailed summary
of the results is presented in Tetreault et al. (2013).
</bodyText>
<sectionHeader confidence="0.996064" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.99998319047619">
Growing interest has led to the recent develop-
ment of the Chinese Learner Corpus (Wang et al.,
2012), the first large-scale corpus of learner texts
comprised of essays written by university stu-
dents. Learners from 59 countries are represented
and proficiency levels have been sampled repre-
sentatively across beginners, intermediate and ad-
vanced learners. However, texts by native speak-
ers of other Asian countries are disproportionately
represented, likely due to geographical proximity.
For this work we extracted 3.75 million tokens
of text from the CLC in the form of individual
sentences.2 Following the methodology of Brooke
and Hirst (2011), we combine the sentences from
the same L1 to form texts of 600 tokens on aver-
age, creating a set of documents suitable for NLI3.
We choose the top 11 languages, shown in Ta-
ble 1, to use in our experiments. This is due to
two considerations. First, while many L1s are rep-
resented in the corpus, most have relatively few
texts. Choosing the top 11 classes allows us to
</bodyText>
<footnote confidence="0.99604725">
1Organised by the Educational Testing Service and co-
located with the eighth instalment of the Building Ed-
ucational Applications Workshop at NAACL/HLT 2013.
sites.google.com/site/nlisharedtask2013/
2Full texts are not made available, only individual sen-
tences with the relevant metadata (proficiency/nationality).
3Pending permission from the CLC corpus authors, we
will attempt to release the Chinese NLI dataset publicly.
</footnote>
<table confidence="0.999844142857143">
Language Size Language Size
Filipino FIL 415 Indonesian IND 402
Thai THA 400 Laotian LAO 366
Burmese MYA 349 Korean* KOR 330
Khmer KHM 294 Vietnamese VIE 267
Japanese* JAP 180 Spanish* SPA 112
Mongolian MON 101
</table>
<tableCaption confidence="0.997528">
Table 1: Our data, broken down by language and
</tableCaption>
<bodyText confidence="0.972279571428571">
the number of texts in each class. Languages over-
lapping with the TOEFL11 corpus marked with *.
balance having a large number of classes, and also
maximizes the amount of data used. Secondly, this
is the same number of classes used in the NLI 2013
shared task, enabling us to draw cross-language
comparisons with the shared task results.
</bodyText>
<sectionHeader confidence="0.999526" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999948538461538">
We also follow the supervised classification ap-
proach described in §2. We devise and run exper-
iments using several models that capture different
types of linguistic information. For each model,
features are extracted from the texts and a clas-
sifier is trained to predict the L1 labels using the
features. As our data is not topic-balanced, we
avoid using topic-dependent lexical features such
as character or word n-grams.
Each experiment is run with two feature repre-
sentations: binary (presence/absence of a feature)
and normalized frequencies, where feature values
are normalized to text length using the l2-norm.
</bodyText>
<subsectionHeader confidence="0.945914">
4.1 Parser
</subsectionHeader>
<bodyText confidence="0.999916666666667">
The Stanford CoreNLP4 suite of NLP tools and
the provided Chinese models are used to tokenize,
PoS tag and parse the unsegmented corpus texts.
</bodyText>
<subsectionHeader confidence="0.91765">
4.2 Classifier
</subsectionHeader>
<bodyText confidence="0.997912666666667">
We use Support Vector Machines for classifica-
tion. Specifically, we use the LIBLINEAR SVM
package (Fan et al., 2008) as it is well-suited to
text classification tasks with large numbers of fea-
tures and texts. We use the L2-regularized L2-loss
support vector classification (dual) solver.
</bodyText>
<subsectionHeader confidence="0.988399">
4.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999947">
The same evaluation metrics and standards used in
the NLI2013 Shared Task are used: we report clas-
sification accuracy under 10-fold cross-validation.
We also use the same number of classes as the
shared task to facilitate comparative analyses.
</bodyText>
<footnote confidence="0.971799">
4http://nlp.stanford.edu/software/corenlp.shtml
</footnote>
<page confidence="0.981604">
96
</page>
<table confidence="0.999529384615384">
Feature Accuracy (%)
Binary Frequency
Random Baseline 9.09 9.09
PoS unigrams 20.12 35.32
Part-of-Speech bigrams 32.83 54.24
Part-of-Speech trigrams 47.24 55.60
Function Words 43.93 51.91
Production Rules 36.14 49.80
All features 61.75 70.61
ROOT
IP
VP PU
VP 。
</table>
<tableCaption confidence="0.99521">
Table 2: Chinese Native Language Identification
accuracy (%) for all of our models.
</tableCaption>
<sectionHeader confidence="0.661092" genericHeader="method">
IP
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.941269">
5.1 Part-of-Speech tag n-grams
</subsectionHeader>
<bodyText confidence="0.999985923076923">
Our first experiment assesses the utility of the
syntactic information captured by part-of-speech
(PoS) tags for Chinese NLI. The PoS tags for each
text are predicted and n-grams of size 1–3 are ex-
tracted from the tags. These n-grams capture (very
local) syntactic patterns of language use and are
used as classification features.
The results for these three features, and our
other models are shown in Table 2. The trigram
frequencies give the best accuracy of 55.60%, sug-
gesting that there exist group-specific patterns of
Chinese word order and category choice which
provide a highly discriminative cue about the L1.
</bodyText>
<subsectionHeader confidence="0.995995">
5.2 Function Words
</subsectionHeader>
<bodyText confidence="0.999925823529412">
As opposed to content words, function words are
topic-independent grammatical words that indi-
cate the relations between other words. They
include determiners, conjunctions and auxiliary
verbs. Distributions of English function words
have been found to be useful in studies of author-
ship attribution and NLI. Unlike PoS tags, this
model analyzes the author’s specific word choices.
We compiled a list of 449 Chinese function
words5 to be used as features in this model. As
shown in Table 2, the function word frequency
features provide the best accuracy of 51.91%,
significantly higher than the random baseline.
This again suggests the presence of L1-specific
grammatical and lexical choice patterns that can
help distinguish the L1, potentially due to cross-
linguistic transfer. Such lexical transfer effects
</bodyText>
<footnote confidence="0.993791">
5The function word list was compiled from Chinese lan-
guage teaching resources. The complete list can be accessed
at http://comp.mq.edu.au/˜madras/research/
data/chinese-fw.txt
</footnote>
<page confidence="0.999745">
97
</page>
<bodyText confidence="0.9999155">
imum accuracy of 70.61%. This demonstrates
that for at least some of the features, the informa-
tion they capture is orthogonal and complemen-
tary, and combining them can improve results.
</bodyText>
<sectionHeader confidence="0.998964" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999992543478261">
A key finding here is that NLI models can be suc-
cessfully applied to non-English data. This is an
important step for furthering NLI research as the
field is still relatively young and many fundamen-
tal questions have yet to be answered.
All of the tested models are effective, and they
appear to be complementary as combining them
improves overall accuracy. We also note the differ-
ence in the efficacy of the feature representations
and see a clear preference for frequency-based fea-
ture values. Others have found that binary features
are the most effective for English NLI (Brooke and
Hirst, 2012), but our results indicate frequency in-
formation is more informative in this task. The
combination of both feature types has also been
reported to be effective (Malmasi et al., 2013).
To see how these models perform across lan-
guages, we also compare the results against the
TOEFL11 corpus used in the NLI2013 shared
task. We perform the same experiments on that
dataset using the English CoreNLP models, Penn
Treebank PoS tagset and a set of 400 English func-
tion words. Figure 2 shows the results side by side.
Remarkably, we see that the model results
closely mirror each other across corpora. This is a
highly interesting finding from our study that mer-
its further investigation. There is a systematic pat-
tern occurring across data from learners of com-
pletely different L1-L2 pairs. This suggests that
manifestations of CLI via surface phenomena oc-
cur at the same levels and patternings regardless
of the L2. Cross-language studies can help re-
searchers in linguistics and cognitive science to
better understand the SLA process and language
transfer effects. They can enhance our understand-
ing of how language is processed in the brain in
ways that are not possible by just studying mono-
linguals or single L1-L2 pairs, thereby providing
us with important insights that increase our knowl-
edge and understanding of the human language
faculty.
One limitation of this work is the lack of sim-
ilar amounts of training data for each language.
However, many of the early and influential NLI
studies (e.g. Koppel et al. (2005), Tsur and Rap-
poport (2007)) were performed under similar cir-
</bodyText>
<figure confidence="0.993335166666667">
Chinese English
60
Accuracy (%) 40
20
0
PoS-1 PoS-2 PoS-3 FW PR
</figure>
<figureCaption confidence="0.995612">
Figure 2: Comparing feature performance on the
Chinese Learner Corpus and English TOEFL11
corpora. PoS-1/2/3: PoS uni/bi/trigrams, FW:
Function Words, PR: Production Rules
</figureCaption>
<bodyText confidence="0.999585285714286">
cumstances. This issue was noted at the time, but
did not deter researchers as corpora with similar
issues were used for many years. Non-English
NLI is also at a similar state where the extant cor-
pora are not optimal for the task, but no other al-
ternatives exist for conducting this research.
Finally, there are also a number of way to fur-
ther develop this work. Firstly, the experimental
scope could be expanded to use even more lin-
guistically sophisticated features such as depen-
dency parses. Model accuracy could potentially
be improved by using the metadata to develop
proficiency-segregated models. Classifier ensem-
bles could also help in increasing the accuracy.
</bodyText>
<sectionHeader confidence="0.998508" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999979538461538">
In this work we have presented the first application
of NLI to non-English data. Using the Chinese
Learner Corpus, we compare models based on
PoS tags, function words and context-free gram-
mar production rules and find that they all yield
high classification accuracies.
Comparing the models against an equivalent
English learner corpus we find that the accura-
cies are almost identical across both L2s, suggest-
ing a systematic pattern of cross-linguistic transfer
where the degree of transfer is independent of the
L1 and L2. Further research with other L2 learner
corpora is needed to investigate this phenomena.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998095">
We wish to thank Associate Professor Maolin
Wang for providing access to the CLC corpus, and
Zhendong Zhao for his assistance. We also thank
the reviewers for their constructive feedback.
</bodyText>
<page confidence="0.985193">
98
</page>
<sectionHeader confidence="0.977261" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9975687125">
Julian Brooke and Graeme Hirst. 2011. Na-
tive language detection with ‘cheap’ learner cor-
pora. In Conference of Learner Corpus Research
(LCR2011), Louvain-la-Neuve, Belgium. Presses
universitaires de Louvain.
Julian Brooke and Graeme Hirst. 2012. Robust, Lex-
icalized Native Language Identification. In Pro-
ceedings of COLING 2012, pages 391–408, Mum-
bai, India, December. The COLING 2012 Organiz-
ing Committee.
Serhiy Bykh and Detmar Meurers. 2012. Native Lan-
guage Identification using Recurring n-grams – In-
vestigating Abstraction and Domain Dependence.
In Proceedings of COLING 2012, pages 425–440,
Mumbai, India, December. The COLING 2012 Or-
ganizing Committee.
Jianguo Chen, Chuang Wang, and Jinfa Cai. 2010.
Teaching and learning Chinese: Issues and perspec-
tives. IAP.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR:
A library for large linear classification. Journal of
Machine Learning Research, 9:1871–1874.
Moshe Koppel, Jonathan Schler, and Kfir Zigdon.
2005. Automatically determining an anonymous au-
thor’s native language. In Intelligence and Security
Informatics, volume 3495 of LNCS, pages 209–217.
Springer-Verlag.
Shervin Malmasi, Sze-Meng Jojo Wong, and Mark
Dras. 2013. Nli shared task 2013: Mq submission.
In Proceedings of the Eighth Workshop on Innova-
tive Use of NLP for Building Educational Applica-
tions, pages 124–133, Atlanta, Georgia, June. Asso-
ciation for Computational Linguistics.
Terence Odlin. 1989. Language Transfer: Cross-
linguistic Influence in Language Learning. Cam-
bridge University Press, Cambridge, UK.
Lourdes Ortega. 2009. Understanding Second Lan-
guage Acquisition. Hodder Education, Oxford, UK.
Benjamin Swanson and Eugene Charniak. 2012.
Native Language Detection with Tree Substitution
Grammars. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 193–197, Jeju
Island, Korea, July. Association for Computational
Linguistics.
Joel Tetreault, Daniel Blanchard, Aoife Cahill, and
Martin Chodorow. 2012. Native tongues, lost and
found: Resources and empirical evaluations in na-
tive language identification. In Proceedings of COL-
ING 2012, pages 2585–2602, Mumbai, India, De-
cember. The COLING 2012 Organizing Committee.
Joel Tetreault, Daniel Blanchard, and Aoife Cahill.
2013. A report on the first native language identi-
fication shared task. In Proceedings of the Eighth
Workshop on Innovative Use of NLP for Build-
ing Educational Applications, pages 48–57, Atlanta,
Georgia, June. Association for Computational Lin-
guistics.
Oren Tsur and Ari Rappoport. 2007. Using classifier
features for studying the effect of native language
on the choice of written second language words. In
Proc. Workshop on Cognitive Aspects of Computat.
Language Acquisition, pages 9–16.
Maolin Wang, Qi Gong, Jie Kuang, and Ziyu Xiong.
2012. The development of a chinese learner corpus.
In Speech Database and Assessments (Oriental CO-
COSDA), 2012 International Conference on, pages
1–6. IEEE.
Sze-Meng Jojo Wong and Mark Dras. 2009. Con-
trastive Analysis and Native Language Identifica-
tion. In Proceedings of the Australasian Language
Technology Association Workshop 2009, pages 53–
61, Sydney, Australia, December.
Sze-Meng Jojo Wong and Mark Dras. 2011. Exploit-
ing Parse Structures for Native Language Identifi-
cation. In Proceedings of the 2011 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1600–1610, Edinburgh, Scotland, UK.,
July. Association for Computational Linguistics.
</reference>
<page confidence="0.998968">
99
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.258629">
<title confidence="0.9130935">Chinese Native Language Identification Shervin Centre for Language Macquarie</title>
<author confidence="0.976786">NSW Sydney</author>
<email confidence="0.993757">shervin.malmasi@mq.edu.au</email>
<author confidence="0.975467">Mark</author>
<affiliation confidence="0.881081">Centre for Language</affiliation>
<title confidence="0.45648">Macquarie</title>
<author confidence="0.890919">NSW Sydney</author>
<email confidence="0.988225">mark.dras@mq.edu.au</email>
<abstract confidence="0.997494333333333">We present the first application of Native Language Identification (NLI) to non- English data. Motivated by theories of language transfer, NLI is the task of identifying a writer’s native language (L1) based on their writings in a second language (the L2). An NLI system was applied to Chinese learner texts using topicindependent syntactic models to assess their accuracy. We find that models using part-of-speech tags, context-free grammar production rules and function words are highly effective, achieving a maximum accuracy of 71% . Interestingly, we also find that when applied to equivalent English data, the model performance is almost identical. This finding suggests a systematic pattern of cross-linguistic transfer may exist, where the degree of transfer is independent of the L1 and L2.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Julian Brooke</author>
<author>Graeme Hirst</author>
</authors>
<title>Native language detection with ‘cheap’ learner corpora.</title>
<date>2011</date>
<booktitle>In Conference of Learner Corpus Research (LCR2011), Louvain-la-Neuve, Belgium. Presses universitaires de Louvain.</booktitle>
<contexts>
<context position="5659" citStr="Brooke and Hirst (2011)" startWordPosition="889" endWordPosition="892">d to the recent development of the Chinese Learner Corpus (Wang et al., 2012), the first large-scale corpus of learner texts comprised of essays written by university students. Learners from 59 countries are represented and proficiency levels have been sampled representatively across beginners, intermediate and advanced learners. However, texts by native speakers of other Asian countries are disproportionately represented, likely due to geographical proximity. For this work we extracted 3.75 million tokens of text from the CLC in the form of individual sentences.2 Following the methodology of Brooke and Hirst (2011), we combine the sentences from the same L1 to form texts of 600 tokens on average, creating a set of documents suitable for NLI3. We choose the top 11 languages, shown in Table 1, to use in our experiments. This is due to two considerations. First, while many L1s are represented in the corpus, most have relatively few texts. Choosing the top 11 classes allows us to 1Organised by the Educational Testing Service and colocated with the eighth instalment of the Building Educational Applications Workshop at NAACL/HLT 2013. sites.google.com/site/nlisharedtask2013/ 2Full texts are not made available</context>
</contexts>
<marker>Brooke, Hirst, 2011</marker>
<rawString>Julian Brooke and Graeme Hirst. 2011. Native language detection with ‘cheap’ learner corpora. In Conference of Learner Corpus Research (LCR2011), Louvain-la-Neuve, Belgium. Presses universitaires de Louvain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Brooke</author>
<author>Graeme Hirst</author>
</authors>
<title>Robust, Lexicalized Native Language Identification.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>391--408</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="11277" citStr="Brooke and Hirst, 2012" startWordPosition="1775" endWordPosition="1778">ove results. 6 Discussion A key finding here is that NLI models can be successfully applied to non-English data. This is an important step for furthering NLI research as the field is still relatively young and many fundamental questions have yet to be answered. All of the tested models are effective, and they appear to be complementary as combining them improves overall accuracy. We also note the difference in the efficacy of the feature representations and see a clear preference for frequency-based feature values. Others have found that binary features are the most effective for English NLI (Brooke and Hirst, 2012), but our results indicate frequency information is more informative in this task. The combination of both feature types has also been reported to be effective (Malmasi et al., 2013). To see how these models perform across languages, we also compare the results against the TOEFL11 corpus used in the NLI2013 shared task. We perform the same experiments on that dataset using the English CoreNLP models, Penn Treebank PoS tagset and a set of 400 English function words. Figure 2 shows the results side by side. Remarkably, we see that the model results closely mirror each other across corpora. This </context>
</contexts>
<marker>Brooke, Hirst, 2012</marker>
<rawString>Julian Brooke and Graeme Hirst. 2012. Robust, Lexicalized Native Language Identification. In Proceedings of COLING 2012, pages 391–408, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serhiy Bykh</author>
<author>Detmar Meurers</author>
</authors>
<title>Native Language Identification using Recurring n-grams – Investigating Abstraction and Domain Dependence.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>425--440</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="3638" citStr="Bykh and Meurers, 2012" startWordPosition="577" endWordPosition="581">applying them to Chinese learner texts, evaluating their efficacy and comparing the results with their English equivalents. To the best of our knowledge this is the first reported application of NLI to non-English data and we believe this is an important step in gaining deeper insights about the technique. 2 Related Work NLI is a fairly recent, but rapidly growing area of research. While some research was conducted in the early 2000s, the most significant work has only appeared in the last few years (Wong and Dras, 2009; Wong and Dras, 2011; Swanson and Charniak, 2012; Tetreault et al., 2012; Bykh and Meurers, 2012). Most studies approach NLI as a multi-class supervised classification task. In this experimental design, the L1 metadata are used as class labels 95 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 95–99, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics and the individual writings are used as training and testing data. Using lexical and syntactic features of increasing sophistication, researchers have obtained good results under this paradigm. While a detailed exposition of NLI has been omi</context>
</contexts>
<marker>Bykh, Meurers, 2012</marker>
<rawString>Serhiy Bykh and Detmar Meurers. 2012. Native Language Identification using Recurring n-grams – Investigating Abstraction and Domain Dependence. In Proceedings of COLING 2012, pages 425–440, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianguo Chen</author>
<author>Chuang Wang</author>
<author>Jinfa Cai</author>
</authors>
<title>Teaching and learning Chinese: Issues and perspectives.</title>
<date>2010</date>
<publisher>IAP.</publisher>
<contexts>
<context position="2750" citStr="Chen et al., 2010" startWordPosition="428" endWordPosition="431">patterns, NLI can be used to better understand SLA and develop teaching methods, instructions and learner feedback that is specific to their mother tongue. However, all of the NLI research to date has focused exclusively on English L2 data. To this end there is a need to apply NLI to other languages, not only to gauge their applicability but also to aid in teaching research for other emerging languages. Interest in learning Chinese is rapidly growing, leading to increased research in Teaching Chinese as a Second Language (TCSL) and the development of related resources such as learner corpora (Chen et al., 2010). The application of these tools and scientific methods like NLI can greatly assist researchers in creating effective teaching practices and is an area of active research. The aim of this research is to evaluate the crosslanguage applicability of NLI techniques by applying them to Chinese learner texts, evaluating their efficacy and comparing the results with their English equivalents. To the best of our knowledge this is the first reported application of NLI to non-English data and we believe this is an important step in gaining deeper insights about the technique. 2 Related Work NLI is a fai</context>
</contexts>
<marker>Chen, Wang, Cai, 2010</marker>
<rawString>Jianguo Chen, Chuang Wang, and Jinfa Cai. 2010. Teaching and learning Chinese: Issues and perspectives. IAP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="7970" citStr="Fan et al., 2008" startWordPosition="1265" endWordPosition="1268">using the features. As our data is not topic-balanced, we avoid using topic-dependent lexical features such as character or word n-grams. Each experiment is run with two feature representations: binary (presence/absence of a feature) and normalized frequencies, where feature values are normalized to text length using the l2-norm. 4.1 Parser The Stanford CoreNLP4 suite of NLP tools and the provided Chinese models are used to tokenize, PoS tag and parse the unsegmented corpus texts. 4.2 Classifier We use Support Vector Machines for classification. Specifically, we use the LIBLINEAR SVM package (Fan et al., 2008) as it is well-suited to text classification tasks with large numbers of features and texts. We use the L2-regularized L2-loss support vector classification (dual) solver. 4.3 Evaluation The same evaluation metrics and standards used in the NLI2013 Shared Task are used: we report classification accuracy under 10-fold cross-validation. We also use the same number of classes as the shared task to facilitate comparative analyses. 4http://nlp.stanford.edu/software/corenlp.shtml 96 Feature Accuracy (%) Binary Frequency Random Baseline 9.09 9.09 PoS unigrams 20.12 35.32 Part-of-Speech bigrams 32.83 </context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel</author>
<author>Jonathan Schler</author>
<author>Kfir Zigdon</author>
</authors>
<title>Automatically determining an anonymous author’s native language.</title>
<date>2005</date>
<booktitle>In Intelligence and Security Informatics,</booktitle>
<volume>3495</volume>
<pages>209--217</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="12795" citStr="Koppel et al. (2005)" startWordPosition="2028" endWordPosition="2031">s of the L2. Cross-language studies can help researchers in linguistics and cognitive science to better understand the SLA process and language transfer effects. They can enhance our understanding of how language is processed in the brain in ways that are not possible by just studying monolinguals or single L1-L2 pairs, thereby providing us with important insights that increase our knowledge and understanding of the human language faculty. One limitation of this work is the lack of similar amounts of training data for each language. However, many of the early and influential NLI studies (e.g. Koppel et al. (2005), Tsur and Rappoport (2007)) were performed under similar cirChinese English 60 Accuracy (%) 40 20 0 PoS-1 PoS-2 PoS-3 FW PR Figure 2: Comparing feature performance on the Chinese Learner Corpus and English TOEFL11 corpora. PoS-1/2/3: PoS uni/bi/trigrams, FW: Function Words, PR: Production Rules cumstances. This issue was noted at the time, but did not deter researchers as corpora with similar issues were used for many years. Non-English NLI is also at a similar state where the extant corpora are not optimal for the task, but no other alternatives exist for conducting this research. Finally, t</context>
</contexts>
<marker>Koppel, Schler, Zigdon, 2005</marker>
<rawString>Moshe Koppel, Jonathan Schler, and Kfir Zigdon. 2005. Automatically determining an anonymous author’s native language. In Intelligence and Security Informatics, volume 3495 of LNCS, pages 209–217. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shervin Malmasi</author>
<author>Sze-Meng Jojo Wong</author>
<author>Mark Dras</author>
</authors>
<title>Nli shared task 2013: Mq submission.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>124--133</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="11459" citStr="Malmasi et al., 2013" startWordPosition="1805" endWordPosition="1808">till relatively young and many fundamental questions have yet to be answered. All of the tested models are effective, and they appear to be complementary as combining them improves overall accuracy. We also note the difference in the efficacy of the feature representations and see a clear preference for frequency-based feature values. Others have found that binary features are the most effective for English NLI (Brooke and Hirst, 2012), but our results indicate frequency information is more informative in this task. The combination of both feature types has also been reported to be effective (Malmasi et al., 2013). To see how these models perform across languages, we also compare the results against the TOEFL11 corpus used in the NLI2013 shared task. We perform the same experiments on that dataset using the English CoreNLP models, Penn Treebank PoS tagset and a set of 400 English function words. Figure 2 shows the results side by side. Remarkably, we see that the model results closely mirror each other across corpora. This is a highly interesting finding from our study that merits further investigation. There is a systematic pattern occurring across data from learners of completely different L1-L2 pair</context>
</contexts>
<marker>Malmasi, Wong, Dras, 2013</marker>
<rawString>Shervin Malmasi, Sze-Meng Jojo Wong, and Mark Dras. 2013. Nli shared task 2013: Mq submission. In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 124–133, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terence Odlin</author>
</authors>
<title>Language Transfer: Crosslinguistic Influence in Language Learning.</title>
<date>1989</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<marker>Odlin, 1989</marker>
<rawString>Terence Odlin. 1989. Language Transfer: Crosslinguistic Influence in Language Learning. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lourdes Ortega</author>
</authors>
<title>Understanding Second Language Acquisition. Hodder Education,</title>
<date>2009</date>
<location>Oxford, UK.</location>
<contexts>
<context position="1740" citStr="Ortega, 2009" startWordPosition="264" endWordPosition="265">task of identifying an author’s native language (L1) based on their writings in a second language (the L2). NLI works by identifying language use patterns that are common to groups of speakers that share the same native language. This process is underpinned by the presupposition that an author’s L1 will dispose them towards particular language production patterns in their L2, as influenced by their mother tongue. This relates to Cross-Linguistic Influence (CLI), a key topic in the field of Second Language Acquisition (SLA) that analyzes transfer effects from the L1 on later learned languages (Ortega, 2009). While NLI has applications in security, most research has a strong linguistic motivation relating to language teaching and learning. Rising numbers of language learners have led to an increasing need for language learning resources, which has in turn fuelled much of the language acquisition research of the past decade. In this context, by identifying L1-specific language usage and error patterns, NLI can be used to better understand SLA and develop teaching methods, instructions and learner feedback that is specific to their mother tongue. However, all of the NLI research to date has focused</context>
</contexts>
<marker>Ortega, 2009</marker>
<rawString>Lourdes Ortega. 2009. Understanding Second Language Acquisition. Hodder Education, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Swanson</author>
<author>Eugene Charniak</author>
</authors>
<title>Native Language Detection with Tree Substitution Grammars.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>193--197</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="3589" citStr="Swanson and Charniak, 2012" startWordPosition="568" endWordPosition="572">he crosslanguage applicability of NLI techniques by applying them to Chinese learner texts, evaluating their efficacy and comparing the results with their English equivalents. To the best of our knowledge this is the first reported application of NLI to non-English data and we believe this is an important step in gaining deeper insights about the technique. 2 Related Work NLI is a fairly recent, but rapidly growing area of research. While some research was conducted in the early 2000s, the most significant work has only appeared in the last few years (Wong and Dras, 2009; Wong and Dras, 2011; Swanson and Charniak, 2012; Tetreault et al., 2012; Bykh and Meurers, 2012). Most studies approach NLI as a multi-class supervised classification task. In this experimental design, the L1 metadata are used as class labels 95 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 95–99, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics and the individual writings are used as training and testing data. Using lexical and syntactic features of increasing sophistication, researchers have obtained good results under this paradigm</context>
</contexts>
<marker>Swanson, Charniak, 2012</marker>
<rawString>Benjamin Swanson and Eugene Charniak. 2012. Native Language Detection with Tree Substitution Grammars. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 193–197, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Daniel Blanchard</author>
<author>Aoife Cahill</author>
<author>Martin Chodorow</author>
</authors>
<title>Native tongues, lost and found: Resources and empirical evaluations in native language identification.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>2585--2602</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="3613" citStr="Tetreault et al., 2012" startWordPosition="573" endWordPosition="576">ty of NLI techniques by applying them to Chinese learner texts, evaluating their efficacy and comparing the results with their English equivalents. To the best of our knowledge this is the first reported application of NLI to non-English data and we believe this is an important step in gaining deeper insights about the technique. 2 Related Work NLI is a fairly recent, but rapidly growing area of research. While some research was conducted in the early 2000s, the most significant work has only appeared in the last few years (Wong and Dras, 2009; Wong and Dras, 2011; Swanson and Charniak, 2012; Tetreault et al., 2012; Bykh and Meurers, 2012). Most studies approach NLI as a multi-class supervised classification task. In this experimental design, the L1 metadata are used as class labels 95 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 95–99, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics and the individual writings are used as training and testing data. Using lexical and syntactic features of increasing sophistication, researchers have obtained good results under this paradigm. While a detailed expos</context>
</contexts>
<marker>Tetreault, Blanchard, Cahill, Chodorow, 2012</marker>
<rawString>Joel Tetreault, Daniel Blanchard, Aoife Cahill, and Martin Chodorow. 2012. Native tongues, lost and found: Resources and empirical evaluations in native language identification. In Proceedings of COLING 2012, pages 2585–2602, Mumbai, India, December. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Tetreault</author>
<author>Daniel Blanchard</author>
<author>Aoife Cahill</author>
</authors>
<title>A report on the first native language identification shared task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<pages>48--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="5004" citStr="Tetreault et al. (2013)" startWordPosition="788" endWordPosition="791">brought unprecedented level of research focus and momentum, resulting in the first NLI shared task being held in 2013.1 The shared task aimed to facilitate the comparison of results by providing a large NLI-specific dataset and evaluation procedure, to enable direct comparison of results achieved through different methods. Overall, the event was considered a success, drawing 29 entrants and experts from not only Computational Linguistics, but also SLA. The best teams achieved accuracies of greater than 80% on this 11-class classification task. A detailed summary of the results is presented in Tetreault et al. (2013). 3 Data Growing interest has led to the recent development of the Chinese Learner Corpus (Wang et al., 2012), the first large-scale corpus of learner texts comprised of essays written by university students. Learners from 59 countries are represented and proficiency levels have been sampled representatively across beginners, intermediate and advanced learners. However, texts by native speakers of other Asian countries are disproportionately represented, likely due to geographical proximity. For this work we extracted 3.75 million tokens of text from the CLC in the form of individual sentences</context>
</contexts>
<marker>Tetreault, Blanchard, Cahill, 2013</marker>
<rawString>Joel Tetreault, Daniel Blanchard, and Aoife Cahill. 2013. A report on the first native language identification shared task. In Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications, pages 48–57, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>Using classifier features for studying the effect of native language on the choice of written second language words.</title>
<date>2007</date>
<booktitle>In Proc. Workshop on Cognitive Aspects of Computat. Language Acquisition,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="12822" citStr="Tsur and Rappoport (2007)" startWordPosition="2032" endWordPosition="2036">guage studies can help researchers in linguistics and cognitive science to better understand the SLA process and language transfer effects. They can enhance our understanding of how language is processed in the brain in ways that are not possible by just studying monolinguals or single L1-L2 pairs, thereby providing us with important insights that increase our knowledge and understanding of the human language faculty. One limitation of this work is the lack of similar amounts of training data for each language. However, many of the early and influential NLI studies (e.g. Koppel et al. (2005), Tsur and Rappoport (2007)) were performed under similar cirChinese English 60 Accuracy (%) 40 20 0 PoS-1 PoS-2 PoS-3 FW PR Figure 2: Comparing feature performance on the Chinese Learner Corpus and English TOEFL11 corpora. PoS-1/2/3: PoS uni/bi/trigrams, FW: Function Words, PR: Production Rules cumstances. This issue was noted at the time, but did not deter researchers as corpora with similar issues were used for many years. Non-English NLI is also at a similar state where the extant corpora are not optimal for the task, but no other alternatives exist for conducting this research. Finally, there are also a number of w</context>
</contexts>
<marker>Tsur, Rappoport, 2007</marker>
<rawString>Oren Tsur and Ari Rappoport. 2007. Using classifier features for studying the effect of native language on the choice of written second language words. In Proc. Workshop on Cognitive Aspects of Computat. Language Acquisition, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maolin Wang</author>
<author>Qi Gong</author>
<author>Jie Kuang</author>
<author>Ziyu Xiong</author>
</authors>
<title>The development of a chinese learner corpus.</title>
<date>2012</date>
<booktitle>In Speech Database and Assessments (Oriental COCOSDA), 2012 International Conference on,</booktitle>
<pages>1--6</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="5113" citStr="Wang et al., 2012" startWordPosition="808" endWordPosition="811">013.1 The shared task aimed to facilitate the comparison of results by providing a large NLI-specific dataset and evaluation procedure, to enable direct comparison of results achieved through different methods. Overall, the event was considered a success, drawing 29 entrants and experts from not only Computational Linguistics, but also SLA. The best teams achieved accuracies of greater than 80% on this 11-class classification task. A detailed summary of the results is presented in Tetreault et al. (2013). 3 Data Growing interest has led to the recent development of the Chinese Learner Corpus (Wang et al., 2012), the first large-scale corpus of learner texts comprised of essays written by university students. Learners from 59 countries are represented and proficiency levels have been sampled representatively across beginners, intermediate and advanced learners. However, texts by native speakers of other Asian countries are disproportionately represented, likely due to geographical proximity. For this work we extracted 3.75 million tokens of text from the CLC in the form of individual sentences.2 Following the methodology of Brooke and Hirst (2011), we combine the sentences from the same L1 to form te</context>
</contexts>
<marker>Wang, Gong, Kuang, Xiong, 2012</marker>
<rawString>Maolin Wang, Qi Gong, Jie Kuang, and Ziyu Xiong. 2012. The development of a chinese learner corpus. In Speech Database and Assessments (Oriental COCOSDA), 2012 International Conference on, pages 1–6. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sze-Meng Jojo Wong</author>
<author>Mark Dras</author>
</authors>
<title>Contrastive Analysis and Native Language Identification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop</booktitle>
<pages>53--61</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="3540" citStr="Wong and Dras, 2009" startWordPosition="560" endWordPosition="563"> The aim of this research is to evaluate the crosslanguage applicability of NLI techniques by applying them to Chinese learner texts, evaluating their efficacy and comparing the results with their English equivalents. To the best of our knowledge this is the first reported application of NLI to non-English data and we believe this is an important step in gaining deeper insights about the technique. 2 Related Work NLI is a fairly recent, but rapidly growing area of research. While some research was conducted in the early 2000s, the most significant work has only appeared in the last few years (Wong and Dras, 2009; Wong and Dras, 2011; Swanson and Charniak, 2012; Tetreault et al., 2012; Bykh and Meurers, 2012). Most studies approach NLI as a multi-class supervised classification task. In this experimental design, the L1 metadata are used as class labels 95 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 95–99, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics and the individual writings are used as training and testing data. Using lexical and syntactic features of increasing sophistication, researche</context>
</contexts>
<marker>Wong, Dras, 2009</marker>
<rawString>Sze-Meng Jojo Wong and Mark Dras. 2009. Contrastive Analysis and Native Language Identification. In Proceedings of the Australasian Language Technology Association Workshop 2009, pages 53– 61, Sydney, Australia, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sze-Meng Jojo Wong</author>
<author>Mark Dras</author>
</authors>
<title>Exploiting Parse Structures for Native Language Identification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1600--1610</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="3561" citStr="Wong and Dras, 2011" startWordPosition="564" endWordPosition="567">arch is to evaluate the crosslanguage applicability of NLI techniques by applying them to Chinese learner texts, evaluating their efficacy and comparing the results with their English equivalents. To the best of our knowledge this is the first reported application of NLI to non-English data and we believe this is an important step in gaining deeper insights about the technique. 2 Related Work NLI is a fairly recent, but rapidly growing area of research. While some research was conducted in the early 2000s, the most significant work has only appeared in the last few years (Wong and Dras, 2009; Wong and Dras, 2011; Swanson and Charniak, 2012; Tetreault et al., 2012; Bykh and Meurers, 2012). Most studies approach NLI as a multi-class supervised classification task. In this experimental design, the L1 metadata are used as class labels 95 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 95–99, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics and the individual writings are used as training and testing data. Using lexical and syntactic features of increasing sophistication, researchers have obtained good</context>
</contexts>
<marker>Wong, Dras, 2011</marker>
<rawString>Sze-Meng Jojo Wong and Mark Dras. 2011. Exploiting Parse Structures for Native Language Identification. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1600–1610, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>