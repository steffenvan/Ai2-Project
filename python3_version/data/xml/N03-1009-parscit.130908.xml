<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.961072">
Proceedings of HLT-NAACL 2003
Main Papers , pp. 64-71
Edmonton, May-June 2003
</note>
<title confidence="0.9627255">
Simpler and More General Minimization
for Weighted Finite-State Automata
</title>
<author confidence="0.999269">
Jason Eisner
</author>
<affiliation confidence="0.9206035">
Department of Computer Science
Johns Hopkins University
</affiliation>
<address confidence="0.974162">
Baltimore, MD, USA 21218-2691
</address>
<email confidence="0.998178">
jason@cs.jhu.edu
</email>
<sectionHeader confidence="0.982257" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9993802">
Previous work on minimizing weighted finite-state automata
(including transducers) is limited to particular types of weights.
We present efficient new minimization algorithms that apply
much more generally, while being simpler and about as fast.
We also point out theoretical limits on minimization algo-
rithms. We characterize the kind of “well-behaved” weight
semirings where our methods work. Outside these semirings,
minimization is not well-defined (in the sense of producing a
unique minimal automaton), and even finding the minimum
number of states is in general NP-complete and inapproximable.
</bodyText>
<sectionHeader confidence="0.99517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984568965517">
It is well known how to efficiently minimize a determin-
istic finite-state automaton (DFA), in the sense of con-
structing another DFA that recognizes the same language
as the original but with as few states as possible (Aho et
al., 1974). This DFA also has as few arcs as possible.
Minimization is useful for saving memory, as when
building very large automata or deploying NLP systems
on small hand-held devices. When automata are built up
through complex regular expressions, the savings from
minimization can be considerable, especially when ap-
plied at intermediate stages of the construction, since (for
example) smaller automata can be intersected faster.
Recently the computational linguistics community has
turned its attention to weighted automata that compute
interesting functions of their input strings. A traditional
automaton only returns an boolean from the set K =
{true, falsel, which indicates whether it has accepted
the input. But a probabilistic automaton returns a prob-
ability in K = [0, 1], or equivalently, a negated log-
probability in K = [0, oo]. A transducer returns an output
string from K = A∗ (for some alphabet A).
Celebrated algorithms by Mohri (1997; 2000) have
recently made it possible to minimize deterministic au-
tomata whose weights (outputs) are log-probabilities or
strings. These cases are of central interest in language
and speech processing.
However, automata with other kinds of weights can
also be defined. The general formulation of weighted
automata (Berstel and Reutenauer, 1988) permits any
weight set K, if appropriate operations ® and (9 are pro-
vided for combining weights from the different arcs of
the automaton. The triple (K, ®, (9) is called a weight
semiring and will be explained below. K-valued func-
tions that can be computed by finite-state automata are
called rational functions.
How does minimization generalize to arbitrary weight
semirings? The question is of practical as well as theoret-
ical interest. Some NLP automata use the real semiring
(R, +, x), or its log equivalent, to compute unnormalized
probabilities or other scores outside the range [0, 1] (Laf-
ferty et al., 2001; Cortes et al., 2002). Expectation semir-
ings (Eisner, 2002) are used to handle bookkeeping when
training the parameters of a probabilistic transducer. A
byproduct of this paper is a minimization algorithm that
works fully with those semirings, a new result permitting
more efficient automaton processing in those situations.
Surprisingly, we will see that minimization is not
even well-defined for all weight semirings! We will
then (nearly) characterize the semirings where it is well-
defined, and give a recipe for constructing minimization
algorithms similar to Mohri’s in such semirings.
Finally, we follow this recipe to obtain a specific, sim-
ple and practical algorithm that works for all division
semirings. All the cases above either fall within this
framework or can be forced into it by adding multiplica-
tive inverses to the semiring. The new algorithm provides
arguably simpler minimization for the cases that Mohri
has already treated, and also handles additional cases.
</bodyText>
<sectionHeader confidence="0.706915" genericHeader="introduction">
2 Weights and Minimization
</sectionHeader>
<bodyText confidence="0.9457122">
We introduce weighted automata by example. The trans-
ducer below describes a partial function from strings to
strings. It maps aab �--&gt; xyz and bab �--&gt; wwyz. Why?
Since the transducer is deterministic, each input (such as
aab) is accepted along at most one path; the correspond-
ing output (such as xyz) is found by concatenating the
output strings found along the path. E denotes the empty
string. a:y
δ and σ standardly denote the automaton’s transition and
output functions: δ(3, a) = 2 is the state reached by the
</bodyText>
<figure confidence="0.964608571428571">
a:x
1
b:zz
b:z
2
0
b: ε
a:wwy
3
b:wwzzz
b: ε
5
4
a arc from state 3, and Q(3, a) = wwy is that arc’s output.
</figure>
<bodyText confidence="0.992320666666667">
In an automaton whose outputs (weights) were num-
bers rather than strings like wwy, concatenating them
would not be sensible; instead we would want to add or
multiply the weights along the path. In general ⊗ denotes
the chosen operation for combining weights along a path.
The ⊗ operation need not be commutative—indeed
concatenation is not—but it must be associative. K must
contain (necessarily unique) weights, denoted 1 and 0,
such that 1 ⊗ k = k ⊗ 1 = k and 0 ⊗ k = k ⊗ 0 = 0 for
all k ∈ K. An unaccepted input (e.g., aba) is assigned
the output 0. When ⊗ is string concatenation, 1 = e, and
0 is a special object ∅ defined to satisfy the axioms.
If an input such as aa were accepted along multiple
paths, we would have to use another operation ⊕ to com-
bine those paths’ weights into a single output for aa.
But that cannot happen with the deterministic automata
treated by this paper. So we omit discussion of the prop-
erties that ⊕ should have, and do not trouble to spell out
its definition for the semirings (K, ⊕, ⊗) discussed in this
paper.1 We are only concerned with the monoid (K, ⊗).
The following automaton is equivalent to the previous
one since it computes the same function:
a:yz
However, it distributes weights differently along the arcs,
and states 1 and 3 can now obviously be merged (as can 2
and 4, yielding the minimal equivalent automaton). For-
mally we know that states 1 and 3 are equivalent because
F1 = F3, where F9 denotes the suffix function of state
q—the function defined by the automaton if the start state
is taken to be q rather than 0. (Thus, F3(ab) = yz.)
Equivalent states can safely be merged, by deleting one
and rerouting its incoming arcs to the other.
We will follow Mohri’s minimization strategy:
</bodyText>
<listItem confidence="0.951100363636364">
1. Turn the first automaton above into the second. This
operation is called pushing (or quasi-determinization).
Here, for instance, it “pushed ww back” through state 3.
2. Merge equivalent states of the second automaton, by
applying ordinary unweighted DFA minimization (Aho et
al., 1974, section 4.13) as if each weighted arc label such
as a:yz were simply a letter in a large alphabet.
3. Trim the result, removing useless states and arcs that
are not on any accepting path (defined as a path whose
weight is non-0 because it has no missing arcs and its last
state is final).
</listItem>
<bodyText confidence="0.9871310625">
1Though appropriate definitions do exist for our examples.
For example, take the ⊕ of two strings to be the shorter of the
two, breaking ties by a lexicographic ordering.
Mohri (2000) proves that this technique finds the minimal
automaton, which he shows to be unique up to placement
of weights along paths.2
We will only have to modify step 1, generalizing push-
ing to other semirings. Pushing makes heavy use of left
quotients: we adopt the notation k\m for an element of
K such that k ⊗ (k\m) = m. This differs from the nota-
tion k−1 ⊗ m (in which k−1 denotes an actual element of
K) because k\m need not exist nor be unique. For exam-
ple, ww\wwzzz = zzz (a fact used above) but wwy\wwzzz
does not exist since wwzzz does not begin with wwy.
If F is a function, α is a string, and k is a weight, we
use some natural notation for functions related to F:
</bodyText>
<equation confidence="0.999450666666667">
k ⊗ F : (k ⊗F)(y) def = k ⊗ (F(y))
k\F : a function (if one exists) with k ⊗ (k\F) = F
α−1F : (α−1F)(y) def = F(αy) (standard notation)
</equation>
<bodyText confidence="0.973913">
In effect, k\F and α−1F drop output and input prefixes.
</bodyText>
<sectionHeader confidence="0.871851" genericHeader="method">
3 Pushing and Its Limitations
</sectionHeader>
<bodyText confidence="0.995530517241379">
The intuition behind pushing is to canonicalize states’
suffix functions. This increases the chance that two states
will have the same suffix function. In the example of the
previous section, we were able to replace F3 with ww\F3
(pushing the ww backwards onto state 3’s incoming arc),
making it equal to F1 so {1, 3} could merge.
Since canonicalization was also performed at states 2
and 4, F1 and F3 ended up with identical representa-
tions: arc weights were distributed identically along cor-
responding paths from 1 and 3. Hence unweighted mini-
mization could discover that F1 = F3 and merge {1, 3}.
Mohri’s pushing strategy—we will see others—is al-
ways to extract some sort of “maximum left factor” from
each suffix function F9 and push it backwards. That is,
he expresses F9 = k ⊗ G for as “large” a k ∈ K as
possible—a maximal common prefix—then pushes fac-
tor k back out of the suffix function so that it is counted
earlier on paths through q (i.e., before reaching q). q’s
suffix function now has canonical form G (i.e., k\F9).
How does Mohri’s strategy reduce to practice? For
transducers, where (K, ⊗) = (A*, concat), the maxi-
mum left factor of F9 is the longest common prefix of
the strings in range(F9).3 Thus we had range(F3) =
{wwyz, wwzzz} above with longest common prefix ww.
For the tropical semiring (R&gt;0 ∪ {∞}, min, +), where
k\m = m − k is defined only if k ≤ m, the maximum
left factor k is the minimum of range(F9).
But “maximum left factor” is not an obvious notion
for all semirings. If we extended the tropical semir-
</bodyText>
<footnote confidence="0.9157366">
2That is, any other solution is isomorphic to the one found
here if output weights are ignored.
3In general we treat F9 as a partial function, so that
range(F9) excludes 0 (the weight of unaccepted strings). Left
factors are unaffected, as anything can divide 0.
</footnote>
<figure confidence="0.979656076923077">
a:x
1
b: ε
2
0
b:ww
b:zzz
a:yz
3
b:zzz
b: ε
5
4
</figure>
<bodyText confidence="0.962677625">
ing with negative numbers, or substituted the semiring
(R≥0, +, ×), keeping the usual definition of “maximum,”
then any function would have arbitrarily large left factors.
A more fundamentally problematic example is the
semiring Z[√ −5]. It is defined as ({m+n√ −5 : m, n ∈
Z}, +, ×) where Z denotes the integers. It is a stan-
dard example of a commutative algebra in which fac-
torization is not unique. For example, 6 = 2 ⊗ 3 =
</bodyText>
<listItem confidence="0.614485333333333">
(1 + √ −5) ⊗ (1 − √ −5) and these 4 factors cannot be
factored further. This makes it impossible to canonicalize
F2 below:
</listItem>
<bodyText confidence="0.993463609756098">
What is the best left factor to extract from F2? We could
left-divide F2 by either 2 or 1 + √ −5. The former action
allows us to merge {1, 2} and the latter to merge {2,3};
but we cannot have it both ways. So this automaton has
no unique minimization! The minimum of 4 states is
achieved by two distinct answers (contrast footnote 2).
It follows that known minimization techniques will not
work in general semirings, as they assume state merge-
ability to be transitive.4 In general the result of mini-
mization is not even well-defined (i.e., unique).
Of course, given a deterministic automaton M, one
may still seek an equivalent M¯ with as few states as pos-
sible. But we will now see that even finding the minimum
number of states is NP-complete, and inapproximable.
The NP-hardness proof [which may be skipped on a
first reading] is by reduction from Minimum Clique Par-
tition. Given a graph with vertex set V = {1, 2,... n}
and edge set E, we wish to partition V into as few cliques
as possible. (S ⊆ V is a clique of the graph iff ij ∈ E
for all pairs i, j ∈ S.) Determining the minimum num-
ber of cliques is NP-complete and inapproximable: that
is, unless P=NP, we cannot even find it within a factor of
2 or 3 or any other constant factor in polynomial time.5
Given such a graph, we reduce the clique problem to
our problem. Consider the “bitwise boolean” semiring
({0,1}n, OR, AND). Each weight k is a string of n bits,
4A further wrinkle lies in deciding what and how to push; in
general semirings, it can be necessary to shift weights forward
as well as backward along paths. Modify the example above by
pushing a factor of 2 backwards through state 2. Making F2 =
F3 in this modified example now requires pushing 2 forward
and then 1 + √−5 backward through state 2.
5This problem is just the dual of Graph Coloring. For de-
tailed approximability results see (Crescenzi and Kann, 1998).
denoted k1,... kn. For each i ∈ V , define fi, ki, mi ∈
K as follows: fi j = 0 iff ij ∈ E; kij = 1 iff i = j; mi j =
0 iff either ij ∈ E or i = j. Now consider the following
automaton M over the alphabet E = {a, b, c1, ... cn}.
The states are {0, 1,... n, n + 1}; 0 is the initial state and
n + 1 is the only final state. For each i ∈ V , there is an
arc 0 ci:1n
</bodyText>
<equation confidence="0.775963">
−−→i and arcs i a:k&apos;
−−→(n + 1) and i b:m&apos; −−→(n + 1).
</equation>
<bodyText confidence="0.986188625">
A minimum-state automaton equivalent to M must
have a topology obtained by merging some states of V .
Other topologies that could accept the same language
(c1|c2 |· · · |cn)(a|b) are clearly not minimal (they can be
improved by merging final states or by trimming).
We claim that for S ⊆ {1, 2,... n}, it is possible to
merge all states in S into a single state (in the automaton)
if and only if S is a clique (in the graph):
</bodyText>
<listItem confidence="0.936865555555556">
• If S is a clique, then define k, m ∈ K by ki = 1 iff
i ∈ S, and mi = 1 iff i ∈6 S. Observe that for every
i ∈ S, we have ki = fi ⊗ k, mi = fi ⊗ m. So by
pushing back a factor of fi at each i ∈ S, one can make
all i ∈ S share a suffix function and then merge them.
• If S is not a clique, then choose i, j ∈ S so that
ij ∈6 E. Considering only bit i, there exists no bit
pair (ki, mi) ∈ {0,1}2 of which (kii, mii) = (1, 0)
and (kji, mji) = (0, 1) are both left-multiples. So there
</listItem>
<bodyText confidence="0.9270885">
can exist no weight pair (k, m) of which (ki, mi) and
(kj, mj) are both left-multiples. It is therefore not pos-
sible to equalize the suffix functions Fi and Fj by left-
dividing each of them.6 i and j cannot be merged.
Thus, the partitions of V into cliques are identical to
the partitions of V into sets of mergeable states, which are
in 1-1 correspondence with the topologies of automata
equivalent to M and derived from it by merging. There is
an N-clique partition of V iff there is an (N+2)-state au-
tomaton. It follows that finding the minimum number of
states is as hard, and as hard to approximate within a con-
stant factor, as finding the minimum number of cliques.
</bodyText>
<sectionHeader confidence="0.960058" genericHeader="method">
4 When Is Minimization Unique?
</sectionHeader>
<bodyText confidence="0.995542142857143">
The previous section demonstrated the existence of
pathological weight semirings. We now partially charac-
terize the “well-behaved” semirings (K, ⊕, ⊗) in which
all automata do have unique minimizations. Except when
otherwise stated, lowercase variables are weights ∈ K
and uppercase ones are K-valued rational functions.
[This section may be skipped, except the last paragraph.]
A crucial necessary condition is that (K, ⊗) allow
what we will call greedy factorization, meaning that
given f ⊗F = g ⊗G =6 0, it is always possible to express
6This argument only shows that pushing backward cannot
give them the same suffix function. But pushing forward cannot
help either, despite footnote 4, since 1&apos; on the arc to i has no
right factors other than itself (the identity) to push forward.
</bodyText>
<figure confidence="0.979203">
1
b:(1+sqrt(-5))
a:1
0
b:1
c:1
a:6
2 b:(2+2*sqrt(-5))
a:(1-sqrt(-5))
4
3
b:2
a:3
F = f&apos; ⊗ H and G = g&apos; ⊗ H. This condition holds for
</figure>
<bodyText confidence="0.9610595">
many practically useful semirings, commutative or other-
wise. It says, roughly, that the order in which left factors
are removed from a suffix function does not matter. We
can reach the same canonical H regardless of whether we
left-divide first by f or g.
Given a counterexample to this condition, one can con-
ply follow the plan of the Z[√−5] example, putting
struct an automaton with no unique minimization. Sim-
F1 = F, F2 = f ⊗ F = g ⊗ G, F3 = G.7 For ex-
ample, in sefm/iring (K/, ⊗) = ({Xn : n f#// 1}, con/cat), put
</bodyText>
<equation confidence="0.968242">
F2 = x2 ⊗ {(a, x3), (b, x4)} = x3 ⊗ 1(a, x2), (b, x3)}
</equation>
<bodyText confidence="0.985309216216216">
membership in two languages at once: (K, ⊕, ⊗) =
({00, 01,10,11}, OR, AND). (Let F2 = 01 ⊗
{(a,11), (b, 00)} = 01 ⊗ {(a, 01), (b,10)}.) R2 under
pointwise × (which computes a string’s probability under
two models) fails similarly. So does (sets, ∩, ∪) (which
collects features found along the accepting path).
We call H a residue of F iff F = f&apos; ⊗ H for some
f&apos;. Write F &apos; G iff F, G have a common residue. In
these terms, (K, ⊗) allows greedy factorization iff F &apos;
G when F, G are residues of the same nonzero function.
More perspicuously, one can show that this holds iff &apos; is
an equivalence relation on nonzero, K-valued functions.
So in semirings where minimization is uniquely de-
fined, &apos; is necessarily an equivalence relation. Given an
automaton M for function F, we may regard &apos; as an
equivalence relation on the states of a trimmed version
of M:8 q &apos; r iff Fq &apos; Fr. Let [r] = {r1, ... , rm}
be the (finite) equivalence class of r: we can inductively
find at least one function F[r] that is a common residue
of Fr1, ... , Frm. The idea behind minimization is to
construct a machine M¯ whose states correspond to these
equivalence classes, and where each [r] has suffix func-
tion F[r]. The Appendix shows that M¯ is then minimal.
If M has an arc qa:k
−→r, M¯ needs an arc [q]a:k�
−→[r], where
k&apos; is such that a−1F[q] = k&apos; ⊗ F[r].
The main difficulty in completing the construction of
M¯ is to ensure each weight k&apos; exists. That is, F[r] must be
carefully chosen to be a residue not only of Fr1, ... , Frm
(which ultimately does not matter, as long as F[0] is a
residue of F0, where 0 is the start state) but also of
a−1F[q]. If M is cyclic, this imposes cyclic dependen-
cies on the choices of the various F[q] and F[r] functions.
We have found no simple necessary and sufficient con-
dition on (K, ⊗) that guarantees a globally consistent set
of choices to exist. However, we have given a useful nec-
</bodyText>
<tableCaption confidence="0.46034525">
7Then factoring F2 allows state 2 to merge with either 1 or
3; but all three states cannot merge, since any suffix function
that could be shared by 1 and 3 could serve as H.
8Trimming ensures that suffix functions are nonzero.
</tableCaption>
<bodyText confidence="0.971090958333333">
essary condition (greedy factorization), and we now give
a useful sufficient condition. Say that H is a minimum
residue of G =6 0 if it is a residue of every residue of G.
(If G has several minimum residues, they are all residues
of one another.) If (K, ⊗) is such that every G has a min-
imum residue—a strictly stronger condition than greedy
factorization—then it can be shown that G has the same
minimum residues as any H &apos; G. In such a (K, ⊗),
M¯ can be constructed by choosing the suffix functions
F[r] independently. Just let F[r] = F{r1,...,rmI be a mini-
mum residue of Fr1. Now consider again M’s arc q a:k
−→r:
since a−1F[q] &apos; a−1Fq &apos; Fr &apos; Fr1, we see F[r] is a
(minimum) residue of a−1F[q], so that a weight k&apos; can be
chosen for [q]a:k�
−→[r].
A final step ensures that M¯ defines the function F. To
describe it, we must augment the formalism to allow an
initial weight ι(0) ∈ K, and a final weight φ(r) ∈ K
for each final state r. The weight of an accepting path
from the start state 0 to a final state r is now defined to
be ι(0) ⊗ (weights of arcs along the path) ⊗ φ(r). In ¯M,
we set ι([0]) to some k such that F0 = k ⊗ F[0], and set
φ([r]) = F[r](ε). The mathematical construction is done.
</bodyText>
<sectionHeader confidence="0.988721" genericHeader="method">
5 A Simple Minimization Recipe
</sectionHeader>
<bodyText confidence="0.998984714285714">
We now give an effective algorithm for minimization in
the semiring (K, ⊗). The algorithmic recipe has one in-
gredient: along with (K, ⊗), the user must give us a left-
factor functional λ that can choose a left factor λ(F) of
any function F. Formally, if Σ is the input alphabet, then
we require λ : (Σ* → K) → K to have the following
properties for any rational F : Σ* → K and any k ∈ K:
</bodyText>
<listItem confidence="0.999977666666667">
• Shifting: λ(k ⊗ F) = k ⊗ λ(F).
• Quotient: λ(F)\λ(a−1F) exists in K for any a ∈ Σ.
• Final-quotient: λ(F)\F(ε) exists in K.9
</listItem>
<bodyText confidence="0.985492827586207">
The algorithm generalizes Mohri’s strategy as outlined
in section 2. We just use λ to pick the left factors during
pushing. The λ’s used by Mohri for two semirings were
mentioned in section 3. We will define another λ in sec-
tion 6. Naturally, it can be shown that no λ can exist in a
semiring that lacks greedy factorization, such as Z[√ −5].
The 3 properties above are needed for the strategy to
work. The strategy also requires (K, ⊗) to be left can-
cellative, i.e., k ⊗ m = k ⊗ m&apos; implies m = m&apos; (if
k =6 0). In other words, left quotients by k are unique
when they exist (except for 0\0). This relieves us from
having to make arbitrary choices of weight during push-
ing. Incompatible choices might prevent arc labels from
matching as desired during the merging step of section 2.
9To show the final-quotient property given the other two, it
suffices to show that A(G) ∈ K has a right inverse in K, where
G is the function mapping a to 1 and everything else to 0.
.
Some useful semirings do fail the condition. One
is the “bitwise boolean” semiring that checks a string’s
Given an input DFA. At each state q, simultaneously,
we will push back A(Fq). This pushing construction
is trivial once the A(Fq) values are computed. An
arc q a�k
−→r should have its weight changed from k to
A(Fq)\A(a−1Fq) = A(Fq)\A(k ⊗ FT), which is well-
defined (by the quotient property and left cancellativity)10
and can be computed as A(Fq)\(k ⊗A(FT)) (by the shift-
ing property). Thus a subpath q �r−W →s, with weight
</bodyText>
<equation confidence="0.663183">
k ⊗ t, will become q+r es, with weight k&apos; ⊗ t&apos; =
(A(Fq)\(k ⊗ A(FT))) ⊗ (A(FT)\(t ⊗ A(Fs))). In this
</equation>
<bodyText confidence="0.997499814814815">
way the factor A(FT) is removed from the start of all paths
from r, and is pushed backwards through r onto the end
of all paths to r. It is possible for this factor (or part of
it) to travel back through multiple arcs and around cycles,
since k&apos; is found by removing a A(Fq) factor from all of
k ⊗ A(FT) and not merely from k.
As it replaces the arc weights, pushing also replaces
the initial weight ι(0) with ι(0) ⊗ A(F0), and replaces
each final weight O(r) with A(FT)\O(r) (which is well-
defined, by the final-quotient property). Altogether, push-
ing leaves path weights unchanged (by easy induction).11
After pushing, we finish with merging and trimming as
in section 2. While merging via unweighted DFA mini-
mization treats arc weights as part of the input symbols,
what should it do with any initial and final weights? The
start state’s initial weight should be preserved. The merg-
ing algorithm can and should be initialized with a multi-
way partition of states by final weight, instead of just a
2-way partition into final vs. non-final.12
The Appendix shows that this strategy indeed finds the
unique minimal automaton.
It is worth clarifying how this section’s effective al-
gorithm implements the mathematical construction from
the end of section 4. At each state q, pushing replaces the
suffix function Fq with A(Fq)\Fq. The quotient proper-
ties of A are designed to guarantee that this quotient is
defined,13 and the shifting property is designed to ensure
10Except in the case 0\0, which is not uniquely defined. This
arises only if F9 = 0, i.e., q is a dead state that will be trimmed
later, so any value will do for 0\0: arcs from q are irrelevant.
11One may prefer a formalism without initial or final weights.
If the original automaton is free of final weights (other than 1),
so is the pushed automaton—provided that A(F) = 1 whenever
F(E) = 1, as is true for all A’s in this paper. Initial weights can
be eliminated at the cost of duplicating state 0 (details omitted).
12Alternatively, Mohri (2000, §4.5) explains how to tem-
porarily eliminate final weights before the merging step.
13That is, A(F9)\F9(-y) exists for each -y ∈ Σ∗. One may
show by induction on |-y |that the left quotients A(F)\F(-y) ex-
ist for all F. When |-y |= 0 this is the final-quotient property.
For |-y |&gt; 0 we can write -y as a-y0, and then A(F)\F(-y) =
A(F)\F(a-y0) = A(F)\(a−1F)(-y0) = (A(F)\A(a−1F)) ⊗
(A(a−1F)\(a−1F)(-y0)), where the first factor exists by the
quotient property and the second factor exists by inductive hy-
pothesis.
that it is a minimum residue of Fq.14 In short, if the con-
ditions of this section are satisfied, so are the conditions
of section 4, and the construction is the same.
The converse is true as well, at least for right cancella-
tive semirings. If such a semiring satisfies the conditions
of section 4 (every function has a minimum residue), then
the requirements of this section can be met to obtain an
effective algorithm: there exists a A satisfying our three
properties,15 and the semiring is left cancellative.16
</bodyText>
<sectionHeader confidence="0.975165" genericHeader="method">
6 Minimization in Division Semirings
</sectionHeader>
<bodyText confidence="0.9999206">
For the most important idea of this paper, we turn to a
common special case. Suppose the semiring (K, ⊕, ⊗)
defines k\m for all m, k =6 0 ∈ K. Equivalently,17 sup-
pose every k =6 0 ∈ K has a unique two-sided inverse
k−1 ∈ K. Useful cases of such division semirings in-
clude the real semiring (R, +, ×), the tropical semiring
extended with negative numbers (R ∪ {∞}, min, +), and
expectation semirings (Eisner, 2002). Minimization has
not previously been available in these.
We propose a new left-factor functional that is fast to
compute and works in arbitrary division semirings. We
avoid the temptation to define A(F) as ® range(F): this
definition has the right properties, but in some semirings
including (R&gt;0, +, ×) the infinite summation is quite ex-
pensive to compute and may even diverge. Instead (un-
like Mohri) we will permit our A(F) to depend on more
than just range(F).
Order the space of input strings E* by length, breaking
ties lexicographically. For example, E &lt; bb &lt; aab &lt;
aba &lt; abb. Now define
</bodyText>
<equation confidence="0.992111625">
a−1(A(F) ⊗ [F]) = A(F) ⊗ a−1[F] = A
⊗ A(a−1[F]) ⊗
(F)
[a−1[F]] = A(1F) ⊗ A(a−1[F]) ⊗ [a−1F] (the last step since
a−1 F] &apos; a− . Applying right cancellativi s-1F =
1Fexists.
a
14Suppose X is any residue of F9, i.e., we can write F9 =
</equation>
<bodyText confidence="0.981189461538461">
x ⊗ X. Then we can rewrite the identity F9 = A(F9) ⊗
(A(F9)\F9), using the shifting property, as x ⊗ X = x ⊗
A(X)⊗(A(F9)\F9). As we have separately required the semir-
ing to be left cancellative, this implies that X = A(X) ⊗
(A(F9)\F9). So (A(F9)\F9) is a residue of any residue X of
F9, as claimed.
15Define A(0) = 0. From each equivalence class of nonzero
functions under &apos;, pick a single minimum residue (axiom of
choice). Given F, let [F] denote the minimum residue from its
class. Observe that F = f ⊗[F] for some f; right cancellativity
implies f is unique. So define A(F) = f. Shifting property:
A(k ⊗ F) = A(k ⊗ f ⊗ [F]) = k ⊗ f = k ⊗ A(f ⊗ [F]) =
k ⊗ A(F). Quotient property: A(a−1F) ⊗ [a−1F] = a−1F =
</bodyText>
<figure confidence="0.64304095">
A(F)
A(a
1[
, showing tha
A(F)\A(a
⊗
−
F])
t
−
exists.Fi) l-
quotientproperty: Quotient exists since F(E) = A(F)⊗[F](E).
16Let hx, yi denote the function mapping a to x, b to y, and
everything else to 0. Given km = km0, we have k ⊗ hm, 1i =
k⊗hm0, 1i. Since the minimum residue property implies greedy
factorization, we can write hm, 1i = f ⊗ ha, bi, hm0, 1i =
g ⊗ ha, bi. Then f ⊗ b = g ⊗ b, so by right cancellativity
f = g, whence m = f ⊗ a = g ⊗ a = m0.
17The equivalence is a standard exercise, though not obvious.
A(F) def J F(minsupport(F)) ∈ K if F =6 0
</figure>
<bodyText confidence="0.9994788">
= 0 if F = 0
where support(F) denotes the set of input strings to
which F assigns a non-0 weight. This A clearly has the
shifting property needed by section 5. The quotient and
final-quotient properties come for free because we are in
a division semiring and because A(F) = 0 iff F = 0.
Under this definition, what is A(Fq) for a suffix func-
tion Fq? Consider all paths of nonzero weight18 from
state q to a final state. If none exist, A(Fq) = 0. Oth-
erwise, min support(Fq) is the input string on the short-
est such path, breaking ties lexicographically.19 A(Fq) is
simply the weight of that shortest path.
To push, we must compute A(Fq) for each state q. This
is easy because A(Fq) is the weight of a single, minimum-
length and hence acyclic path from q. (Previous meth-
ods combined the weights of all paths from q, even if
infinitely many.) It also helps that the left factors at dif-
ferent states are related: if the minimum path from q be-
gins with a weight-k arc to r, then it continues along the
minimum path from r, so A(Fq) = k ⊗ A(Fr).
Below is a trivial linear-time algorithm for computing
A(Fq) at every q. Each state and arc is considered once
in a breadth-first search back from the final states. len(q)
and first(q) store the string length and first letter of a run-
ning minimum of support(Fq) ∈ E*.
</bodyText>
<listItem confidence="0.972331222222222">
1. foreach state q
2. if q is final then
3. len(q) := 0 (* min support(Fq) is ε for final q *)
4. A(Fq) := φ(q) (* Fq(ε) is just the final weight, φ(q) *)
5. enqueue q on a FIFO queue
6. else
7. len(q) := oo (* not yet discovered *)
8. A(Fq) := 0 (* assumeFq = 0 until we discover q *)
9. until the FIFO queue is empty
</listItem>
<figure confidence="0.647088333333333">
10. dequeue a state r
foreach arc q a:k
11. ��r entering r such that k =� 0
12. if len(q) = oo then enqueue q (* breadth-first search *)
13. if len(q) = oo or (len(q) = len(r) + 1
and a &lt; first(q)) then
14. first(q) := a (* reduce min support(Fq) *)
15. len(q) := len(r) + 1
16. A(Fq) := k ® A(Fr)
</figure>
<bodyText confidence="0.995967666666667">
The runtime is O(|states|+t·|arcs|) if ⊗ has runtime t.
If ⊗ is slow, this can be reduced to O(t · |states |+ |arcs|)
by removing line 16 and waiting until the end, when the
minimum path from each non-final state q is fully known,
to compute the weight A(Fq) of that path. Simply finish
up by calling FIND-A on each state q:
</bodyText>
<listItem confidence="0.67672525">
FIND-A(state q):
1. if A(Fq) = 0 and len(q) &lt; oo then
2. A(Fq) := v(q,first(q)) ® FIND-A(δ(q,first(q)))
3. return A(Fq)
</listItem>
<bodyText confidence="0.764235428571429">
18In a division semiring, these are paths free of 0-weight arcs.
19The min exists since &lt; is a well-ordering. In a purely lex-
icographic ordering, a*b C E* would have no min.
After thus computing A(Fq), we simply proceed with
pushing, merging, and trimming as in section 5.20 Push-
ing runs in time O(t·|arcs|) and trimming in O(|states|+
|arcs|). Merging is worse, with time O(|arcs |log |states|).
</bodyText>
<sectionHeader confidence="0.945833" genericHeader="method">
7 A Bonus: Non-Division Semirings
</sectionHeader>
<bodyText confidence="0.991759604651163">
The trouble with Z[√−5] was that it “lacked” needed
quotients. The example on p. 3 can easily be minimized
(down to 3 states) if we regard it instead as defined over
(C, +, ×)—letting us use any weights in C. Simply use
section 6’s algorithm.
This new change-of-semiring trick can be used for
other non-division semirings as well. One can extend the
original weight semiring (K, ⊕, ⊗) to a division semiring
by adding ⊗-inverses.21
In this way, the tropical semiring (R&gt;0 ∪ {∞},
min, +) can be augmented with the negative reals to ob-
tain (R ∪ {∞}, min, +). And the transducer semiring
(A* ∪ {∅}, min, concat)22 can be augmented by extend-
ing the alphabet A = {x, y,...} with inverse letters
{x−1, y−1, ...}.
The minimized DFA we obtain may have “weird” arc
weights drawn from the extended semiring. But the arc
weights combine along paths to produce the original au-
tomaton’s outputs, which fall in the original semiring.
Let us apply this trick to the example of section 2,
yielding the following pushed automaton in which F1 =
F3 as desired. (x−1, y−1,... are written as X, Y, ..., and
A(Fq) is displayed at each q.)
For example, the z−1y−1zzz output on the 3→4 arc was
computed as A(F3)−1 ⊗ wwzzz ⊗ A(F4) = (wwyz)−1 ⊗
wwzzz ⊗ E = z−1y−1w−1w−1wwzzz.
This trick yields new algorithms for the tropical semir-
ing and sequential transducers, which is interesting and
perhaps worthwhile. How do they compare with previ-
ous work?
Over the tropical semiring, our linear-time pushing al-
gorithm is simpler than (Mohri, 1997), and faster by a
20It is also permissible to trim the input automaton at the start,
or right after computing A (note that A(Fq) = 0 iff we should
trim q). This simplifies pushing and merging. No trimming is
then needed at the end, except to remove the one dead state that
the merging step may have added to complete the automaton.
21This is often possible but not always; the semiring must be
cancellative, and there are other conditions. Even disregarding
® because we are minimizing a deterministic automaton, it is
not simple to characterize when the monoid (K, (9) can be em-
bedded into a group (Clifford and Preston, 1967, chapter 12).
22Where min can be defined as in section 6 and footnote 1.
</bodyText>
<figure confidence="0.996144333333334">
:xyz
0
xyz
b:ZYXwwyz
a: ε
3
wwyz
1
yz
a: ε
b:ZYzzz
b:ZYzzz
a: ε
2
4
z
ε
b: ε
b: ε
5
ε
</figure>
<bodyText confidence="0.9987975">
log factor, because it does not require a priority queue.
(Though this does not help the overall complexity of min-
imization, which is dominated by the merging step.) We
also have no need to implement faster algorithms for spe-
cial cases, as Mohri proposes, because our basic algo-
rithm is already linear. Finally, our algorithm generalizes
better, as it can handle negative weight cycles in the input.
These are useful in (e.g.) conditional random fields.
On the other hand, Mohri’s algorithm guarantees a po-
tentially useful property that we do not: that the weight
of the prefix path reading α ∈ E∗ is the minimum weight
of all paths with prefix α. Commonly this approximates
− log(p(most probable string with prefix α)), perhaps a
useful value to look up for pruning.
As for transducers, how does our minimization algo-
rithm (above) compare with previous ones? Following
earlier work by Choffrut and others, Mohri (2000) de-
fines A(Fq) as the longest common prefix of range(Fq).
He constrains these values with a set of simultaneous
equations, and solves them by repeated changes of vari-
able using a complex relaxation algorithm. His imple-
mentation uses various techniques (including a trie and
a graph decomposition) to make pushing run in time
O(|states |+ |arcs |· maxq |A(Fq)|).23 Breslauer (1996)
gives a different computation of the same result.
To implement our simpler algorithm, we represent
strings in A∗ as pointers into a global trie that extends
upon lookup. The strings are actually stored reversed in
the trie so that it is fast to add and remove short pre-
fixes. Over the extended alphabet, we use the pointer
pair (k, m) to represent the string k−1m where k, m ∈
A∗ have no common prefix. Such pointer pairs can
be equality-tested in O(1) time during merging. For
k, m ∈ A∗, k ⊗ m is computed in time O(|k|), and k\m
in time O(|LCP(k, m)|) or more loosely O(|k|) (where
LCP = longest common prefix).
The total time to compute our A(Fq) values is therefore
O(|states |+ t · |arcs|), where t is the maximum length of
any arc’s weight. For each arc we then compute a new
weight as a left-quotient by a A value. So our total run-
time for pushing is O(|states |+ |arcs |· maxq |A(Fq)|).
This may appear identical to Mohri’s runtime, but in fact
our |A(Fq) |≥ Mohri’s, though the two definitions share
a worst case of t · |states|.24
Inverse letters must be eliminated from the minimized
transducer if one wishes to pass it to any specialized al-
gorithms (composition, inversion) that assume weights
23We define |E |= 1 to simplify the O(· · ·) expressions.
24The |A(F9) |term contributed by a given arc from q is a
bound on the length of the LCP of the outputs of certain paths
from q. Mohri uses all paths from q and we use just two, so our
LCP is sometimes longer. However, both LCPs probably tend to
be short in practice, especially if one bypasses LCP(k, k) with
special handling for k\k = E.
in A∗. Fortunately this is not hard. If state q of the
result was formed by merging states q1,... qj, define
ρ(q) = LCS{A(Fq,) : i = 1,... j} ∈ A∗ (where LCS =
longest common suffix). Now push the minimized trans-
ducer using ρ(q)−1 in place of A(Fq) for all q. This cor-
rects for “overpushing”: any letters ρ(q) that were unnec-
essarily pushed back before minimization are pushed for-
ward again, cancelling the inverse letters. In our running
example, state 0 will push (xyz)−1 back and the merged
state {1,3} will push (yz)−1 back. This is equivalent to
pushing ρ(0) = xyz forward through state 0 and the yz
part of it forward through {1,3}, canceling the z−1y−1 at
the start of one of the next arcs.
We must show that the resulting labels really are free
of inverse letters. Their values are as if the original push-
ing had pushed back not A(Fq,) ∈ A∗ but only its shorter
def
prefix A(qi) = A(Fq,)/ρ(qi) ∈ A∗ (note the right quo-
tient). In other words, an arc from qi to ri, with weight
k ∈ A∗ was reweighted as ˆA(qi)\(k ⊗ ˆA(ri,)). Any in-
verse letters in such new weights clearly fall at the left.
So suppose the new weight on the arc from q to r begins
with an inverse letter z−1. Then ˆA(qi) must have ended
with z for each i = 1,... j. But then ρ(qi) was not the
longest common suffix: zρ(qi) is a longer one, a contra-
diction (Q.E.D.).
Negative weights can be similarly eliminated after
minimization over the tropical semiring, if desired, by
substituting min for LCS.
The optional elimination of inverse letters or nega-
tive weights does not affect the asymptotic runtime. A
caveat here is that the resulting automaton no longer has
a canonical form. Consider a straight-line automaton:
pushing yields a canonical form as always, but inverse-
letter elimination completely undoes pushing (ˆA(qi) =
E). This is not an issue in Mohri’s approach.
</bodyText>
<sectionHeader confidence="0.925019" genericHeader="method">
8 Conclusion and Final Remarks
</sectionHeader>
<bodyText confidence="0.999995379310345">
We have characterized the semirings over which
weighted deterministic automata can be minimized (sec-
tion 4), and shown how to perform such minimization in
both general and specific cases (sections 5, 6, 7). Our
technique for division semirings and their subsemirings
pushes back, at each state q, the output of a single, easily
found, shortest accepting path from q. This is simpler and
more general than previous approaches that aggregate all
accepting paths from q.
Our new algorithm (section 6) is most important for
previously unminimizable, practically needed division
semirings: real (e.g., for probabilities), expectation (for
learning (Eisner, 2002)), and additive with negative
weights (for conditional random fields (Lafferty et al.,
2001)). It can also be used in non-division semirings,
as for transducers. It is unpatented, easy to implement,
comparable or faster in asymptotic runtime, and perhaps
faster in practice (especially for the tropical semiring,
where it seems preferable in most respects).
Our approach applies also to R-weighted sequential
transducers as in (Cortes et al., 2002). Such automata
can be regarded as weighted by the product semiring
(R × Δ∗, (+, min), (×, concat)). Equivalently, one can
push the numeric and string components independently.
Our new pushing algorithm enables not only minimiza-
tion but also equivalence-testing in more weight semir-
ings. Equivalence is efficiently tested by pushing the (de-
terministic) automata to canonicalize their arc labels and
then testing unweighted equivalence (Mohri, 1997).
</bodyText>
<sectionHeader confidence="0.98178" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.988027125">
A. V. Aho, J. E. Hopcroft, and J. D. Ullman. 1974. The Design
and Analysis of Computer Algorithms. Addison-Wesley.
Jean Berstel and Christophe Reutenauer. 1988. Rational Series
and their Languages. Springer-Verlag.
Dany Breslauer. 1996. The suffix tree of a tree and minimizing
sequential transducers. Lecture Notes in Computer Science,
1075.
A. H. Clifford and G. B. Preston. 1967. The Algebraic Theory
of Semigroups.
Corinna Cortes, Patrick Haffner, and Mehryar Mohri. 2002.
Rational kernels. In Proceedings ofNIPS, December.
Pierluigi Crescenzi and Viggo Kann. 1998. How to find the best
approximation results—a follow-up to Garey and Johnson.
ACMSIGACTNews, 29(4):90–97, December.
Jason Eisner. 2002. Parameter estimation for probabilistic
finite-state transducers. In Proc. ofACL, Philadelphia, July.
John Lafferty, Andrew McCallum, and Fernando Pereira. 2001.
Conditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proceedings of the
International Conference on Machine Learning.
Mehryar Mohri. 1997. Finite-state transducers in language and
speech processing. Computational Linguistics, 23(2).
Mehryar Mohri. 2000. Minimization algorithms for sequential
transducers. Theoretical Computer Science, 324:177–201.
</reference>
<sectionHeader confidence="0.943872" genericHeader="method">
Appendix: Remaining Proofs
</sectionHeader>
<bodyText confidence="0.9585188125">
Let M be an automaton to minimize and F : Σ∗ → K be the
function it defines. We assume (K, ⊗) allows greedy factoriza-
tion, so &apos; is an equivalence relation on nonzero functions. We
first prove that M¯ with the properties of section 4 is the minimal
automaton computing F. We will then show, following Mohri,
that the algorithm of section 5 finds such an ¯M. (Section 6 is a
special case of section 5.)
We chose in advance a desired suffix function F[r] for each
state [r] of ¯M, and used these to determine the weights of ¯M.
To show that the weights were determined correctly, let ˜F[r] be
the actual suffix function of [r]. Claim that for all α and r,
˜F[r](α) = F[r](α). This is easily proved by induction on |α|.
Our choice of initial weight then ensures that M¯ computes F.
We must now prove minimality. For α,β ∈ Σ∗, say α F∼ β
iff α−1F &apos; β−1F. Note that F∼ is an equivalence relation on
D def= {α ∈ Σ∗ : α−1F =60}.25
</bodyText>
<footnote confidence="0.425921">
25It is not an equivalence relation on all of Σ∗, since α ∈6 D is
</footnote>
<note confidence="0.614588">
Let M0 be any automaton that computes F. For α, β ∈ D,
</note>
<figure confidence="0.596964727272727">
M0
we say α ∼ β iff δM0(0, α) = δM0&lt;(0, β), i.e., the prefixes
α and β lead from the start state 0 to the same state q in M0.
M0
If α ∼ β, then α ∼F β, since α−1F = σ(0, α) ⊗ Fq &apos;
σ(0, β) ⊗ Fq = β−1F.
If α ∼F β, then α−1F &apos; β−1F, so FδM(0,α) &apos; α−1F &apos;
β−1F &apos; FδM (0,β), so δM(0, α) &apos; δM(0, β), so α M¯ ∼ β by
construction of ¯M.
M0 ∼ β ⇒ α M¯
In short, α ∼ β ⇒ α F ∼ β. So each of the three
</figure>
<bodyText confidence="0.929836823529412">
partitions of D into equivalence classes is a refinement of the
next. Hence nM0 ≥ nF ≥ n ¯M, where these are the respective
numbers of equivalence classes.
M0
Since ∼ has one equivalence class per useful state of M0 (as
defined in section 2), nM0 is the number of states in a trimmed
version of M0. Similarly n M¯ is the number of states of M¯ (after
trimming). Since M0 was arbitrary, M¯ is minimal.
Uniqueness: If M0 has the same number of states as ¯M, then
the two partitions must be equal. So two prefixes reach the same
state in M0 iff they do so in ¯M. This gives a δ-preserving iso-
morphism between M0 and
¯M.It
follows that the minimal ma-
chine is unique, except for the distribution of output labels along
paths (which may depend on arbitrary choices of residues
Now we turn to section
</bodyText>
<figure confidence="0.890118857142857">
effective construction, using
of a pushed machine
and a merged version
The proof
of minimality is essentially the same as in (Mohri, 2000). We
know that
computes the same function as M (since pushing,
merging, an
F[r]).
5’s
λ,
Mˆ
¯M.
M¯
</figure>
<bodyText confidence="0.587784533333333">
d trimming preserve this). So it suffices to show
The above proof of minimality will then go
through as before.
M and
have the same states and transition function
denote their emission functions by
and
refers to suf-
fix functions in M. Given
(so
D), use the
definition of
to write
=
and
</bodyText>
<equation confidence="0.63866475">
=
Let q =
r =
k =
For any a
write
a) =
(k
</equation>
<bodyText confidence="0.8586765">
as well. Thanks to left ca2
ncellativity, le
quotients are unique,
So
identical weights. Since
as well, the same holds at
</bodyText>
<figure confidence="0.985029971428572">
a) and
a). So by induction, regarding
as an un-
weighted automaton, exactly the same strings in
are
accepted from q and from r. So merging will merge q and r,
as
F M¯
α ∼ β ⇒ α ∼β.
Mˆ
δ;
σ
ˆσ.Fq
αF∼β
α,β∈
F∼
α−1F
kα⊗F0
β−1F
kβ⊗ F0.
δ(0,α),
δ(0,β),
σ(0,α).
∈Σ,
ˆσ(q,
λ(Fq)\λ(a−1Fq)=
⊗λ(Fq))\(k⊗ λ(a−1Fq)) = λ(k ⊗ Fq)\λ(k ⊗ a−1Fq) =
λ(α−1F)\λ(a−1(α−1F)) = λ(kα⊗F0)\λ(a−1(kα⊗F0)) =
λ(F0)\λ(a−1F0). By symmetry, ˆσ(r, a) = λ(F0)\λ(a−1F0)
6
ft
α∼ β ⇒ corresponding arcs from q and r in Mˆ output
F
αa∼Fβa
δ(q,
δ(r,
Mˆ
(Σ×K)∗
M¯
and α ∼
claimed.
related by
state can be made to merge with any state by pushing 0 back
from it, so that the arcs to it have weight 0 and the arcs from
it have arbitrary weights. Our construction of
only creates
states for the equivalence classes of D;
for
D is
undefined, not a dead state.
must check that we did not divide by 0 and obtain a
false equation.
suffices to show that k
0 and
0. Fortunately,
D implies both. (It implies
0, so
=
∼ to every β. This corresponds to the fact that a dead
F
M¯
δ(0,α)
α∈6
26We
It
=6
λ(Fq)=6
α∈
Fq=6
(γ−1Fq)(ε)
</figure>
<bodyText confidence="0.662401">
Fq(γ) =6 0 for some γ. Hence λ(Fq) =6 0
since otherwise λ(γ−1Fq) = 0 and λ(γ−1Fq)\(γ−1Fq)(ε) is
undefined, contradicting the final-quotient property.)
</bodyText>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.444478">
<note confidence="0.938856333333333">Proceedings of HLT-NAACL 2003 Main Papers , pp. 64-71 Edmonton, May-June 2003</note>
<title confidence="0.996578">Simpler and More General Minimization for Weighted Finite-State Automata</title>
<author confidence="0.998438">Jason</author>
<affiliation confidence="0.7768785">Department of Computer Johns Hopkins</affiliation>
<address confidence="0.998778">Baltimore, MD, USA</address>
<email confidence="0.99986">jason@cs.jhu.edu</email>
<abstract confidence="0.998568181818182">Previous work on minimizing weighted finite-state automata (including transducers) is limited to particular types of weights. We present efficient new minimization algorithms that apply much more generally, while being simpler and about as fast. We also point out theoretical limits on minimization algorithms. We characterize the kind of “well-behaved” weight semirings where our methods work. Outside these semirings, minimization is not well-defined (in the sense of producing a unique minimal automaton), and even finding the minimum number of states is in general NP-complete and inapproximable.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J E Hopcroft</author>
<author>J D Ullman</author>
</authors>
<title>The Design and Analysis of Computer Algorithms.</title>
<date>1974</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="1127" citStr="Aho et al., 1974" startWordPosition="161" endWordPosition="164">ut as fast. We also point out theoretical limits on minimization algorithms. We characterize the kind of “well-behaved” weight semirings where our methods work. Outside these semirings, minimization is not well-defined (in the sense of producing a unique minimal automaton), and even finding the minimum number of states is in general NP-complete and inapproximable. 1 Introduction It is well known how to efficiently minimize a deterministic finite-state automaton (DFA), in the sense of constructing another DFA that recognizes the same language as the original but with as few states as possible (Aho et al., 1974). This DFA also has as few arcs as possible. Minimization is useful for saving memory, as when building very large automata or deploying NLP systems on small hand-held devices. When automata are built up through complex regular expressions, the savings from minimization can be considerable, especially when applied at intermediate stages of the construction, since (for example) smaller automata can be intersected faster. Recently the computational linguistics community has turned its attention to weighted automata that compute interesting functions of their input strings. A traditional automato</context>
<context position="6692" citStr="Aho et al., 1974" startWordPosition="1102" endWordPosition="1105">alent because F1 = F3, where F9 denotes the suffix function of state q—the function defined by the automaton if the start state is taken to be q rather than 0. (Thus, F3(ab) = yz.) Equivalent states can safely be merged, by deleting one and rerouting its incoming arcs to the other. We will follow Mohri’s minimization strategy: 1. Turn the first automaton above into the second. This operation is called pushing (or quasi-determinization). Here, for instance, it “pushed ww back” through state 3. 2. Merge equivalent states of the second automaton, by applying ordinary unweighted DFA minimization (Aho et al., 1974, section 4.13) as if each weighted arc label such as a:yz were simply a letter in a large alphabet. 3. Trim the result, removing useless states and arcs that are not on any accepting path (defined as a path whose weight is non-0 because it has no missing arcs and its last state is final). 1Though appropriate definitions do exist for our examples. For example, take the ⊕ of two strings to be the shorter of the two, breaking ties by a lexicographic ordering. Mohri (2000) proves that this technique finds the minimal automaton, which he shows to be unique up to placement of weights along paths.2 </context>
</contexts>
<marker>Aho, Hopcroft, Ullman, 1974</marker>
<rawString>A. V. Aho, J. E. Hopcroft, and J. D. Ullman. 1974. The Design and Analysis of Computer Algorithms. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Berstel</author>
<author>Christophe Reutenauer</author>
</authors>
<title>Rational Series and their Languages.</title>
<date>1988</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="2415" citStr="Berstel and Reutenauer, 1988" startWordPosition="360" endWordPosition="363">hich indicates whether it has accepted the input. But a probabilistic automaton returns a probability in K = [0, 1], or equivalently, a negated logprobability in K = [0, oo]. A transducer returns an output string from K = A∗ (for some alphabet A). Celebrated algorithms by Mohri (1997; 2000) have recently made it possible to minimize deterministic automata whose weights (outputs) are log-probabilities or strings. These cases are of central interest in language and speech processing. However, automata with other kinds of weights can also be defined. The general formulation of weighted automata (Berstel and Reutenauer, 1988) permits any weight set K, if appropriate operations ® and (9 are provided for combining weights from the different arcs of the automaton. The triple (K, ®, (9) is called a weight semiring and will be explained below. K-valued functions that can be computed by finite-state automata are called rational functions. How does minimization generalize to arbitrary weight semirings? The question is of practical as well as theoretical interest. Some NLP automata use the real semiring (R, +, x), or its log equivalent, to compute unnormalized probabilities or other scores outside the range [0, 1] (Laffer</context>
</contexts>
<marker>Berstel, Reutenauer, 1988</marker>
<rawString>Jean Berstel and Christophe Reutenauer. 1988. Rational Series and their Languages. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dany Breslauer</author>
</authors>
<title>The suffix tree of a tree and minimizing sequential transducers.</title>
<date>1996</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>1075</pages>
<contexts>
<context position="33322" citStr="Breslauer (1996)" startWordPosition="6139" endWordPosition="6140">most probable string with prefix α)), perhaps a useful value to look up for pruning. As for transducers, how does our minimization algorithm (above) compare with previous ones? Following earlier work by Choffrut and others, Mohri (2000) defines A(Fq) as the longest common prefix of range(Fq). He constrains these values with a set of simultaneous equations, and solves them by repeated changes of variable using a complex relaxation algorithm. His implementation uses various techniques (including a trie and a graph decomposition) to make pushing run in time O(|states |+ |arcs |· maxq |A(Fq)|).23 Breslauer (1996) gives a different computation of the same result. To implement our simpler algorithm, we represent strings in A∗ as pointers into a global trie that extends upon lookup. The strings are actually stored reversed in the trie so that it is fast to add and remove short prefixes. Over the extended alphabet, we use the pointer pair (k, m) to represent the string k−1m where k, m ∈ A∗ have no common prefix. Such pointer pairs can be equality-tested in O(1) time during merging. For k, m ∈ A∗, k ⊗ m is computed in time O(|k|), and k\m in time O(|LCP(k, m)|) or more loosely O(|k|) (where LCP = longest c</context>
</contexts>
<marker>Breslauer, 1996</marker>
<rawString>Dany Breslauer. 1996. The suffix tree of a tree and minimizing sequential transducers. Lecture Notes in Computer Science, 1075.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A H Clifford</author>
<author>G B Preston</author>
</authors>
<title>The Algebraic Theory of Semigroups.</title>
<date>1967</date>
<contexts>
<context position="31863" citStr="Clifford and Preston, 1967" startWordPosition="5882" endWordPosition="5885">, and faster by a 20It is also permissible to trim the input automaton at the start, or right after computing A (note that A(Fq) = 0 iff we should trim q). This simplifies pushing and merging. No trimming is then needed at the end, except to remove the one dead state that the merging step may have added to complete the automaton. 21This is often possible but not always; the semiring must be cancellative, and there are other conditions. Even disregarding ® because we are minimizing a deterministic automaton, it is not simple to characterize when the monoid (K, (9) can be embedded into a group (Clifford and Preston, 1967, chapter 12). 22Where min can be defined as in section 6 and footnote 1. :xyz 0 xyz b:ZYXwwyz a: ε 3 wwyz 1 yz a: ε b:ZYzzz b:ZYzzz a: ε 2 4 z ε b: ε b: ε 5 ε log factor, because it does not require a priority queue. (Though this does not help the overall complexity of minimization, which is dominated by the merging step.) We also have no need to implement faster algorithms for special cases, as Mohri proposes, because our basic algorithm is already linear. Finally, our algorithm generalizes better, as it can handle negative weight cycles in the input. These are useful in (e.g.) conditional r</context>
</contexts>
<marker>Clifford, Preston, 1967</marker>
<rawString>A. H. Clifford and G. B. Preston. 1967. The Algebraic Theory of Semigroups.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Patrick Haffner</author>
<author>Mehryar Mohri</author>
</authors>
<title>Rational kernels.</title>
<date>2002</date>
<booktitle>In Proceedings ofNIPS,</booktitle>
<contexts>
<context position="3052" citStr="Cortes et al., 2002" startWordPosition="467" endWordPosition="470">ht set K, if appropriate operations ® and (9 are provided for combining weights from the different arcs of the automaton. The triple (K, ®, (9) is called a weight semiring and will be explained below. K-valued functions that can be computed by finite-state automata are called rational functions. How does minimization generalize to arbitrary weight semirings? The question is of practical as well as theoretical interest. Some NLP automata use the real semiring (R, +, x), or its log equivalent, to compute unnormalized probabilities or other scores outside the range [0, 1] (Lafferty et al., 2001; Cortes et al., 2002). Expectation semirings (Eisner, 2002) are used to handle bookkeeping when training the parameters of a probabilistic transducer. A byproduct of this paper is a minimization algorithm that works fully with those semirings, a new result permitting more efficient automaton processing in those situations. Surprisingly, we will see that minimization is not even well-defined for all weight semirings! We will then (nearly) characterize the semirings where it is welldefined, and give a recipe for constructing minimization algorithms similar to Mohri’s in such semirings. Finally, we follow this recipe</context>
</contexts>
<marker>Cortes, Haffner, Mohri, 2002</marker>
<rawString>Corinna Cortes, Patrick Haffner, and Mehryar Mohri. 2002. Rational kernels. In Proceedings ofNIPS, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierluigi Crescenzi</author>
<author>Viggo Kann</author>
</authors>
<title>How to find the best approximation results—a follow-up to Garey and Johnson.</title>
<date>1998</date>
<journal>ACMSIGACTNews,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="12344" citStr="Crescenzi and Kann, 1998" startWordPosition="2157" endWordPosition="2160">ven such a graph, we reduce the clique problem to our problem. Consider the “bitwise boolean” semiring ({0,1}n, OR, AND). Each weight k is a string of n bits, 4A further wrinkle lies in deciding what and how to push; in general semirings, it can be necessary to shift weights forward as well as backward along paths. Modify the example above by pushing a factor of 2 backwards through state 2. Making F2 = F3 in this modified example now requires pushing 2 forward and then 1 + √−5 backward through state 2. 5This problem is just the dual of Graph Coloring. For detailed approximability results see (Crescenzi and Kann, 1998). denoted k1,... kn. For each i ∈ V , define fi, ki, mi ∈ K as follows: fi j = 0 iff ij ∈ E; kij = 1 iff i = j; mi j = 0 iff either ij ∈ E or i = j. Now consider the following automaton M over the alphabet E = {a, b, c1, ... cn}. The states are {0, 1,... n, n + 1}; 0 is the initial state and n + 1 is the only final state. For each i ∈ V , there is an arc 0 ci:1n −−→i and arcs i a:k&apos; −−→(n + 1) and i b:m&apos; −−→(n + 1). A minimum-state automaton equivalent to M must have a topology obtained by merging some states of V . Other topologies that could accept the same language (c1|c2 |· · · |cn)(a|b) a</context>
</contexts>
<marker>Crescenzi, Kann, 1998</marker>
<rawString>Pierluigi Crescenzi and Viggo Kann. 1998. How to find the best approximation results—a follow-up to Garey and Johnson. ACMSIGACTNews, 29(4):90–97, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Parameter estimation for probabilistic finite-state transducers.</title>
<date>2002</date>
<booktitle>In Proc. ofACL,</booktitle>
<location>Philadelphia,</location>
<contexts>
<context position="3090" citStr="Eisner, 2002" startWordPosition="474" endWordPosition="475">are provided for combining weights from the different arcs of the automaton. The triple (K, ®, (9) is called a weight semiring and will be explained below. K-valued functions that can be computed by finite-state automata are called rational functions. How does minimization generalize to arbitrary weight semirings? The question is of practical as well as theoretical interest. Some NLP automata use the real semiring (R, +, x), or its log equivalent, to compute unnormalized probabilities or other scores outside the range [0, 1] (Lafferty et al., 2001; Cortes et al., 2002). Expectation semirings (Eisner, 2002) are used to handle bookkeeping when training the parameters of a probabilistic transducer. A byproduct of this paper is a minimization algorithm that works fully with those semirings, a new result permitting more efficient automaton processing in those situations. Surprisingly, we will see that minimization is not even well-defined for all weight semirings! We will then (nearly) characterize the semirings where it is welldefined, and give a recipe for constructing minimization algorithms similar to Mohri’s in such semirings. Finally, we follow this recipe to obtain a specific, simple and prac</context>
<context position="24826" citStr="Eisner, 2002" startWordPosition="4545" endWordPosition="4546">irements of this section can be met to obtain an effective algorithm: there exists a A satisfying our three properties,15 and the semiring is left cancellative.16 6 Minimization in Division Semirings For the most important idea of this paper, we turn to a common special case. Suppose the semiring (K, ⊕, ⊗) defines k\m for all m, k =6 0 ∈ K. Equivalently,17 suppose every k =6 0 ∈ K has a unique two-sided inverse k−1 ∈ K. Useful cases of such division semirings include the real semiring (R, +, ×), the tropical semiring extended with negative numbers (R ∪ {∞}, min, +), and expectation semirings (Eisner, 2002). Minimization has not previously been available in these. We propose a new left-factor functional that is fast to compute and works in arbitrary division semirings. We avoid the temptation to define A(F) as ® range(F): this definition has the right properties, but in some semirings including (R&gt;0, +, ×) the infinite summation is quite expensive to compute and may even diverge. Instead (unlike Mohri) we will permit our A(F) to depend on more than just range(F). Order the space of input strings E* by length, breaking ties lexicographically. For example, E &lt; bb &lt; aab &lt; aba &lt; abb. Now define a−1(</context>
<context position="37459" citStr="Eisner, 2002" startWordPosition="6876" endWordPosition="6877">ch weighted deterministic automata can be minimized (section 4), and shown how to perform such minimization in both general and specific cases (sections 5, 6, 7). Our technique for division semirings and their subsemirings pushes back, at each state q, the output of a single, easily found, shortest accepting path from q. This is simpler and more general than previous approaches that aggregate all accepting paths from q. Our new algorithm (section 6) is most important for previously unminimizable, practically needed division semirings: real (e.g., for probabilities), expectation (for learning (Eisner, 2002)), and additive with negative weights (for conditional random fields (Lafferty et al., 2001)). It can also be used in non-division semirings, as for transducers. It is unpatented, easy to implement, comparable or faster in asymptotic runtime, and perhaps faster in practice (especially for the tropical semiring, where it seems preferable in most respects). Our approach applies also to R-weighted sequential transducers as in (Cortes et al., 2002). Such automata can be regarded as weighted by the product semiring (R × Δ∗, (+, min), (×, concat)). Equivalently, one can push the numeric and string c</context>
</contexts>
<marker>Eisner, 2002</marker>
<rawString>Jason Eisner. 2002. Parameter estimation for probabilistic finite-state transducers. In Proc. ofACL, Philadelphia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Machine Learning.</booktitle>
<contexts>
<context position="3030" citStr="Lafferty et al., 2001" startWordPosition="462" endWordPosition="466"> 1988) permits any weight set K, if appropriate operations ® and (9 are provided for combining weights from the different arcs of the automaton. The triple (K, ®, (9) is called a weight semiring and will be explained below. K-valued functions that can be computed by finite-state automata are called rational functions. How does minimization generalize to arbitrary weight semirings? The question is of practical as well as theoretical interest. Some NLP automata use the real semiring (R, +, x), or its log equivalent, to compute unnormalized probabilities or other scores outside the range [0, 1] (Lafferty et al., 2001; Cortes et al., 2002). Expectation semirings (Eisner, 2002) are used to handle bookkeeping when training the parameters of a probabilistic transducer. A byproduct of this paper is a minimization algorithm that works fully with those semirings, a new result permitting more efficient automaton processing in those situations. Surprisingly, we will see that minimization is not even well-defined for all weight semirings! We will then (nearly) characterize the semirings where it is welldefined, and give a recipe for constructing minimization algorithms similar to Mohri’s in such semirings. Finally,</context>
<context position="37551" citStr="Lafferty et al., 2001" startWordPosition="6887" endWordPosition="6890">erform such minimization in both general and specific cases (sections 5, 6, 7). Our technique for division semirings and their subsemirings pushes back, at each state q, the output of a single, easily found, shortest accepting path from q. This is simpler and more general than previous approaches that aggregate all accepting paths from q. Our new algorithm (section 6) is most important for previously unminimizable, practically needed division semirings: real (e.g., for probabilities), expectation (for learning (Eisner, 2002)), and additive with negative weights (for conditional random fields (Lafferty et al., 2001)). It can also be used in non-division semirings, as for transducers. It is unpatented, easy to implement, comparable or faster in asymptotic runtime, and perhaps faster in practice (especially for the tropical semiring, where it seems preferable in most respects). Our approach applies also to R-weighted sequential transducers as in (Cortes et al., 2002). Such automata can be regarded as weighted by the product semiring (R × Δ∗, (+, min), (×, concat)). Equivalently, one can push the numeric and string components independently. Our new pushing algorithm enables not only minimization but also eq</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Finite-state transducers in language and speech processing.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>2</issue>
<contexts>
<context position="2070" citStr="Mohri (1997" startWordPosition="312" endWordPosition="313">stages of the construction, since (for example) smaller automata can be intersected faster. Recently the computational linguistics community has turned its attention to weighted automata that compute interesting functions of their input strings. A traditional automaton only returns an boolean from the set K = {true, falsel, which indicates whether it has accepted the input. But a probabilistic automaton returns a probability in K = [0, 1], or equivalently, a negated logprobability in K = [0, oo]. A transducer returns an output string from K = A∗ (for some alphabet A). Celebrated algorithms by Mohri (1997; 2000) have recently made it possible to minimize deterministic automata whose weights (outputs) are log-probabilities or strings. These cases are of central interest in language and speech processing. However, automata with other kinds of weights can also be defined. The general formulation of weighted automata (Berstel and Reutenauer, 1988) permits any weight set K, if appropriate operations ® and (9 are provided for combining weights from the different arcs of the automaton. The triple (K, ®, (9) is called a weight semiring and will be explained below. K-valued functions that can be comput</context>
<context position="31237" citStr="Mohri, 1997" startWordPosition="5773" endWordPosition="5774">original semiring. Let us apply this trick to the example of section 2, yielding the following pushed automaton in which F1 = F3 as desired. (x−1, y−1,... are written as X, Y, ..., and A(Fq) is displayed at each q.) For example, the z−1y−1zzz output on the 3→4 arc was computed as A(F3)−1 ⊗ wwzzz ⊗ A(F4) = (wwyz)−1 ⊗ wwzzz ⊗ E = z−1y−1w−1w−1wwzzz. This trick yields new algorithms for the tropical semiring and sequential transducers, which is interesting and perhaps worthwhile. How do they compare with previous work? Over the tropical semiring, our linear-time pushing algorithm is simpler than (Mohri, 1997), and faster by a 20It is also permissible to trim the input automaton at the start, or right after computing A (note that A(Fq) = 0 iff we should trim q). This simplifies pushing and merging. No trimming is then needed at the end, except to remove the one dead state that the merging step may have added to complete the automaton. 21This is often possible but not always; the semiring must be cancellative, and there are other conditions. Even disregarding ® because we are minimizing a deterministic automaton, it is not simple to characterize when the monoid (K, (9) can be embedded into a group (</context>
</contexts>
<marker>Mohri, 1997</marker>
<rawString>Mehryar Mohri. 1997. Finite-state transducers in language and speech processing. Computational Linguistics, 23(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Minimization algorithms for sequential transducers.</title>
<date>2000</date>
<journal>Theoretical Computer Science,</journal>
<pages>324--177</pages>
<contexts>
<context position="7166" citStr="Mohri (2000)" startWordPosition="1190" endWordPosition="1191">k” through state 3. 2. Merge equivalent states of the second automaton, by applying ordinary unweighted DFA minimization (Aho et al., 1974, section 4.13) as if each weighted arc label such as a:yz were simply a letter in a large alphabet. 3. Trim the result, removing useless states and arcs that are not on any accepting path (defined as a path whose weight is non-0 because it has no missing arcs and its last state is final). 1Though appropriate definitions do exist for our examples. For example, take the ⊕ of two strings to be the shorter of the two, breaking ties by a lexicographic ordering. Mohri (2000) proves that this technique finds the minimal automaton, which he shows to be unique up to placement of weights along paths.2 We will only have to modify step 1, generalizing pushing to other semirings. Pushing makes heavy use of left quotients: we adopt the notation k\m for an element of K such that k ⊗ (k\m) = m. This differs from the notation k−1 ⊗ m (in which k−1 denotes an actual element of K) because k\m need not exist nor be unique. For example, ww\wwzzz = zzz (a fact used above) but wwy\wwzzz does not exist since wwzzz does not begin with wwy. If F is a function, α is a string, and k i</context>
<context position="23349" citStr="Mohri (2000" startWordPosition="4285" endWordPosition="4286"> is defined,13 and the shifting property is designed to ensure 10Except in the case 0\0, which is not uniquely defined. This arises only if F9 = 0, i.e., q is a dead state that will be trimmed later, so any value will do for 0\0: arcs from q are irrelevant. 11One may prefer a formalism without initial or final weights. If the original automaton is free of final weights (other than 1), so is the pushed automaton—provided that A(F) = 1 whenever F(E) = 1, as is true for all A’s in this paper. Initial weights can be eliminated at the cost of duplicating state 0 (details omitted). 12Alternatively, Mohri (2000, §4.5) explains how to temporarily eliminate final weights before the merging step. 13That is, A(F9)\F9(-y) exists for each -y ∈ Σ∗. One may show by induction on |-y |that the left quotients A(F)\F(-y) exist for all F. When |-y |= 0 this is the final-quotient property. For |-y |&gt; 0 we can write -y as a-y0, and then A(F)\F(-y) = A(F)\F(a-y0) = A(F)\(a−1F)(-y0) = (A(F)\A(a−1F)) ⊗ (A(a−1F)\(a−1F)(-y0)), where the first factor exists by the quotient property and the second factor exists by inductive hypothesis. that it is a minimum residue of Fq.14 In short, if the conditions of this section are </context>
<context position="32942" citStr="Mohri (2000)" startWordPosition="6078" endWordPosition="6079">lly, our algorithm generalizes better, as it can handle negative weight cycles in the input. These are useful in (e.g.) conditional random fields. On the other hand, Mohri’s algorithm guarantees a potentially useful property that we do not: that the weight of the prefix path reading α ∈ E∗ is the minimum weight of all paths with prefix α. Commonly this approximates − log(p(most probable string with prefix α)), perhaps a useful value to look up for pruning. As for transducers, how does our minimization algorithm (above) compare with previous ones? Following earlier work by Choffrut and others, Mohri (2000) defines A(Fq) as the longest common prefix of range(Fq). He constrains these values with a set of simultaneous equations, and solves them by repeated changes of variable using a complex relaxation algorithm. His implementation uses various techniques (including a trie and a graph decomposition) to make pushing run in time O(|states |+ |arcs |· maxq |A(Fq)|).23 Breslauer (1996) gives a different computation of the same result. To implement our simpler algorithm, we represent strings in A∗ as pointers into a global trie that extends upon lookup. The strings are actually stored reversed in the t</context>
</contexts>
<marker>Mohri, 2000</marker>
<rawString>Mehryar Mohri. 2000. Minimization algorithms for sequential transducers. Theoretical Computer Science, 324:177–201.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>